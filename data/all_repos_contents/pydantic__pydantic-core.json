{"generate_self_schema.py": "\"\"\"\nThis script generates the schema for the schema - e.g.\na definition of what inputs can be provided to `SchemaValidator()`.\n\nThe schema is generated from `python/pydantic_core/core_schema.py`.\n\"\"\"\n\nfrom __future__ import annotations as _annotations\n\nimport decimal\nimport importlib.util\nimport re\nimport sys\nfrom collections.abc import Callable\nfrom datetime import date, datetime, time, timedelta\nfrom pathlib import Path\nfrom typing import TYPE_CHECKING, Any, Dict, ForwardRef, List, Pattern, Set, Type, Union\n\nfrom typing_extensions import TypedDict, get_args, get_origin, is_typeddict\n\nTypingUnionType = Type[Union[str, int]]\n\ntry:\n    from types import UnionType as TypesUnionType\n\n    UnionType = Union[TypingUnionType, TypesUnionType]\n\nexcept ImportError:\n    TypesUnionType = TypingUnionType\n    UnionType = TypingUnionType\n\n\nTHIS_DIR = Path(__file__).parent\nSAVE_PATH = THIS_DIR / 'src' / 'self_schema.py'\n\nif TYPE_CHECKING:\n    from pydantic_core import core_schema\nelse:\n    # can't import core_schema.py directly as pydantic-core might not be installed\n    core_schema_spec = importlib.util.spec_from_file_location(\n        '_typing', str(THIS_DIR / 'python' / 'pydantic_core' / 'core_schema.py')\n    )\n    core_schema = importlib.util.module_from_spec(core_schema_spec)\n    core_schema_spec.loader.exec_module(core_schema)\n\n# the validator for referencing schema (Schema is used recursively, so has to use a reference)\nschema_ref_validator = {'type': 'definition-ref', 'schema_ref': 'root-schema'}\n\n\ndef get_schema(obj: Any, definitions: dict[str, core_schema.CoreSchema]) -> core_schema.CoreSchema:  # noqa: C901\n    if isinstance(obj, str):\n        return {'type': obj}\n    elif obj in (datetime, timedelta, date, time, bool, int, float, str, decimal.Decimal):\n        return {'type': obj.__name__.lower()}\n    elif is_typeddict(obj):\n        return type_dict_schema(obj, definitions)\n    elif obj == Any or obj == type:\n        return {'type': 'any'}\n    if isinstance(obj, type) and issubclass(obj, core_schema.Protocol):\n        return {'type': 'callable'}\n\n    origin = get_origin(obj)\n    assert origin is not None, f'origin cannot be None, obj={obj}, you probably need to fix generate_self_schema.py'\n    if origin is Union or origin is TypesUnionType:\n        return union_schema(obj, definitions)\n    elif obj is Callable or origin is Callable:\n        return {'type': 'callable'}\n    elif origin is core_schema.Literal:\n        expected = all_literal_values(obj)\n        assert expected, f'literal \"expected\" cannot be empty, obj={obj}'\n        return {'type': 'literal', 'expected': expected}\n    elif issubclass(origin, List):\n        return {'type': 'list', 'items_schema': get_schema(obj.__args__[0], definitions)}\n    elif issubclass(origin, Set):\n        return {'type': 'set', 'items_schema': get_schema(obj.__args__[0], definitions)}\n    elif issubclass(origin, Dict):\n        return {\n            'type': 'dict',\n            'keys_schema': get_schema(obj.__args__[0], definitions),\n            'values_schema': get_schema(obj.__args__[1], definitions),\n        }\n    elif issubclass(origin, Type):\n        # can't really use 'is-instance' since this is used for the class_ parameter of 'is-instance' validators\n        return {'type': 'any'}\n    elif origin in (Pattern, re.Pattern):\n        # can't really use 'is-instance' easily with Pattern, so we use `any` as a placeholder for now\n        return {'type': 'any'}\n    else:\n        # debug(obj)\n        raise TypeError(f'Unknown type: {obj!r}')\n\n\ndef tagged_union(std_union_schema: Dict[str, Any], discriminator_key: str, ref: str | None = None) -> Dict[str, Any]:\n    \"\"\"\n    Build a tagged union schema from a standard union schema.\n    \"\"\"\n    tagged_choices = {}\n    for choice in std_union_schema['choices']:\n        literal = choice['fields'][discriminator_key]['schema']['expected']\n        assert isinstance(literal, list), 'literal expected must be a list'\n        assert all(isinstance(arg, str) for arg in literal), 'literal expected must be a list of strings'\n        first, *rest = literal\n        tagged_choices[first] = choice\n        for arg in rest:\n            tagged_choices[arg] = choice\n    s = {'type': 'tagged-union', 'discriminator': discriminator_key, 'choices': tagged_choices}\n    if ref is not None:\n        s['ref'] = ref\n    return s\n\n\ndefined_ser_schema = False\n\n\ndef type_dict_schema(  # noqa: C901\n    typed_dict: type[TypedDict], definitions: dict[str, core_schema.CoreSchema]\n) -> dict[str, Any]:\n    global defined_ser_schema\n\n    required_keys = getattr(typed_dict, '__required_keys__', set())\n    fields = {}\n\n    for field_name, field_type in typed_dict.__annotations__.items():\n        required = field_name in required_keys\n        schema = None\n        fr_arg = None\n        if type(field_type) == ForwardRef:\n            fr_arg = field_type.__forward_arg__\n\n            fr_arg, matched = re.subn(r'Required\\[(.+)]', r'\\1', fr_arg)\n            if matched:\n                required = True\n\n            if 'CoreSchema' == fr_arg or re.search('[^a-zA-Z]CoreSchema', fr_arg):\n                if fr_arg == 'CoreSchema':\n                    schema = schema_ref_validator\n                elif fr_arg == 'List[CoreSchema]':\n                    schema = {'type': 'list', 'items_schema': schema_ref_validator}\n                elif fr_arg == 'Dict[str, CoreSchema]':\n                    schema = {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': schema_ref_validator}\n                elif fr_arg == 'Dict[Hashable, CoreSchema]':\n                    schema = {'type': 'dict', 'keys_schema': {'type': 'any'}, 'values_schema': schema_ref_validator}\n                elif fr_arg == 'List[Union[CoreSchema, Tuple[CoreSchema, str]]]':\n                    schema = {\n                        'type': 'list',\n                        'items_schema': {\n                            'type': 'union',\n                            'choices': [\n                                schema_ref_validator,\n                                {'type': 'tuple', 'items_schema': [schema_ref_validator, {'type': 'str'}]},\n                            ],\n                        },\n                    }\n                else:\n                    raise ValueError(f'Unknown Schema forward ref: {fr_arg}')\n            else:\n                field_type = eval_forward_ref(field_type)\n\n        if schema is None:\n            if get_origin(field_type) == core_schema.Required:\n                required = True\n                field_type = field_type.__args__[0]\n\n            schema = get_schema(field_type, definitions)\n            if fr_arg == 'SerSchema':\n                if defined_ser_schema:\n                    schema = {'type': 'definition-ref', 'schema_ref': 'ser-schema'}\n                else:\n                    defined_ser_schema = True\n                    definitions['ser-schema'] = tagged_union(schema, 'type', 'ser-schema')\n                    schema = {'type': 'definition-ref', 'schema_ref': 'ser-schema'}\n            elif fr_arg.endswith('SerSchema'):\n                schema = tagged_union(schema, 'type')\n\n        # now_utc_offset is an int that must be in the range -24 hours to +24 hours, we manually add a constraint here\n        if field_name == 'now_utc_offset':\n            schema.update(gt=-86_400, lt=86_400)\n        fields[field_name] = {'schema': schema, 'required': required}\n\n    return {'type': 'typed-dict', 'fields': fields, 'extra_behavior': 'forbid'}\n\n\ndef union_schema(union_type: UnionType, definitions) -> core_schema.UnionSchema | core_schema.DefinitionReferenceSchema:\n    return {'type': 'union', 'choices': [get_schema(arg, definitions) for arg in union_type.__args__]}\n\n\ndef all_literal_values(type_: type[core_schema.Literal]) -> list[any]:\n    if get_origin(type_) is core_schema.Literal:\n        values = get_args(type_)\n        return [x for value in values for x in all_literal_values(value)]\n    else:\n        return [type_]\n\n\ndef eval_forward_ref(type_: Any) -> Any:\n    if sys.version_info < (3, 9):\n        return type_._evaluate(core_schema.__dict__, None)\n    elif sys.version_info < (3, 12, 4):\n        return type_._evaluate(core_schema.__dict__, None, recursive_guard=set())\n    else:\n        return type_._evaluate(core_schema.__dict__, None, type_params=set(), recursive_guard=set())\n\n\ndef main() -> None:\n    schema_union = core_schema.CoreSchema\n    assert get_origin(schema_union) is Union, 'expected core_schema.CoreSchema to be a Union'\n\n    definitions: dict[str, core_schema.CoreSchema] = {}\n\n    choices = {}\n    for s in schema_union.__args__:\n        type_ = s.__annotations__['type']\n        m = re.search(r\"Literal\\['(.+?)']\", type_.__forward_arg__)\n        assert m, f'Unknown schema type: {type_}'\n        key = m.group(1)\n        value = get_schema(s, definitions)\n        choices[key] = value\n\n    schema = core_schema.definitions_schema(\n        schema=core_schema.definition_reference_schema(schema_ref='root-schema'),\n        definitions=[\n            core_schema.tagged_union_schema(choices, discriminator='type', ref='root-schema'),\n            *definitions.values(),\n        ],\n    )\n    python_code = (\n        f'# this file is auto-generated by generate_self_schema.py, DO NOT edit manually\\nself_schema = {schema}\\n'\n    )\n    try:\n        from black import Mode, TargetVersion, format_file_contents\n    except ImportError:\n        pass\n    else:\n        mode = Mode(\n            line_length=120,\n            string_normalization=False,\n            magic_trailing_comma=False,\n            target_versions={TargetVersion.PY37, TargetVersion.PY38, TargetVersion.PY39, TargetVersion.PY310},\n        )\n        python_code = format_file_contents(python_code, fast=False, mode=mode)\n    SAVE_PATH.write_text(python_code)\n    print(f'Self schema definition written to {SAVE_PATH}')\n\n\nif __name__ == '__main__':\n    main()\n", "python/pydantic_core/core_schema.py": "\"\"\"\nThis module contains definitions to build schemas which `pydantic_core` can\nvalidate and serialize.\n\"\"\"\n\nfrom __future__ import annotations as _annotations\n\nimport sys\nimport warnings\nfrom collections.abc import Mapping\nfrom datetime import date, datetime, time, timedelta\nfrom decimal import Decimal\nfrom typing import TYPE_CHECKING, Any, Callable, Dict, Hashable, List, Pattern, Set, Tuple, Type, Union\n\nfrom typing_extensions import deprecated\n\nif sys.version_info < (3, 12):\n    from typing_extensions import TypedDict\nelse:\n    from typing import TypedDict\n\nif sys.version_info < (3, 11):\n    from typing_extensions import Protocol, Required, TypeAlias\nelse:\n    from typing import Protocol, Required, TypeAlias\n\nif sys.version_info < (3, 9):\n    from typing_extensions import Literal\nelse:\n    from typing import Literal\n\nif TYPE_CHECKING:\n    from pydantic_core import PydanticUndefined\nelse:\n    # The initial build of pydantic_core requires PydanticUndefined to generate\n    # the core schema; so we need to conditionally skip it. mypy doesn't like\n    # this at all, hence the TYPE_CHECKING branch above.\n    try:\n        from pydantic_core import PydanticUndefined\n    except ImportError:\n        PydanticUndefined = object()\n\n\nExtraBehavior = Literal['allow', 'forbid', 'ignore']\n\n\nclass CoreConfig(TypedDict, total=False):\n    \"\"\"\n    Base class for schema configuration options.\n\n    Attributes:\n        title: The name of the configuration.\n        strict: Whether the configuration should strictly adhere to specified rules.\n        extra_fields_behavior: The behavior for handling extra fields.\n        typed_dict_total: Whether the TypedDict should be considered total. Default is `True`.\n        from_attributes: Whether to use attributes for models, dataclasses, and tagged union keys.\n        loc_by_alias: Whether to use the used alias (or first alias for \"field required\" errors) instead of\n            `field_names` to construct error `loc`s. Default is `True`.\n        revalidate_instances: Whether instances of models and dataclasses should re-validate. Default is 'never'.\n        validate_default: Whether to validate default values during validation. Default is `False`.\n        populate_by_name: Whether an aliased field may be populated by its name as given by the model attribute,\n            as well as the alias. (Replaces 'allow_population_by_field_name' in Pydantic v1.) Default is `False`.\n        str_max_length: The maximum length for string fields.\n        str_min_length: The minimum length for string fields.\n        str_strip_whitespace: Whether to strip whitespace from string fields.\n        str_to_lower: Whether to convert string fields to lowercase.\n        str_to_upper: Whether to convert string fields to uppercase.\n        allow_inf_nan: Whether to allow infinity and NaN values for float fields. Default is `True`.\n        ser_json_timedelta: The serialization option for `timedelta` values. Default is 'iso8601'.\n        ser_json_bytes: The serialization option for `bytes` values. Default is 'utf8'.\n        ser_json_inf_nan: The serialization option for infinity and NaN values\n            in float fields. Default is 'null'.\n        hide_input_in_errors: Whether to hide input data from `ValidationError` representation.\n        validation_error_cause: Whether to add user-python excs to the __cause__ of a ValidationError.\n            Requires exceptiongroup backport pre Python 3.11.\n        coerce_numbers_to_str: Whether to enable coercion of any `Number` type to `str` (not applicable in `strict` mode).\n        regex_engine: The regex engine to use for regex pattern validation. Default is 'rust-regex'. See `StringSchema`.\n        cache_strings: Whether to cache strings. Default is `True`, `True` or `'all'` is required to cache strings\n            during general validation since validators don't know if they're in a key or a value.\n    \"\"\"\n\n    title: str\n    strict: bool\n    # settings related to typed dicts, model fields, dataclass fields\n    extra_fields_behavior: ExtraBehavior\n    typed_dict_total: bool  # default: True\n    # used for models, dataclasses, and tagged union keys\n    from_attributes: bool\n    # whether to use the used alias (or first alias for \"field required\" errors) instead of field_names\n    # to construct error `loc`s, default True\n    loc_by_alias: bool\n    # whether instances of models and dataclasses (including subclass instances) should re-validate, default 'never'\n    revalidate_instances: Literal['always', 'never', 'subclass-instances']\n    # whether to validate default values during validation, default False\n    validate_default: bool\n    # used on typed-dicts and arguments\n    populate_by_name: bool  # replaces `allow_population_by_field_name` in pydantic v1\n    # fields related to string fields only\n    str_max_length: int\n    str_min_length: int\n    str_strip_whitespace: bool\n    str_to_lower: bool\n    str_to_upper: bool\n    # fields related to float fields only\n    allow_inf_nan: bool  # default: True\n    # the config options are used to customise serialization to JSON\n    ser_json_timedelta: Literal['iso8601', 'float']  # default: 'iso8601'\n    ser_json_bytes: Literal['utf8', 'base64', 'hex']  # default: 'utf8'\n    ser_json_inf_nan: Literal['null', 'constants', 'strings']  # default: 'null'\n    # used to hide input data from ValidationError repr\n    hide_input_in_errors: bool\n    validation_error_cause: bool  # default: False\n    coerce_numbers_to_str: bool  # default: False\n    regex_engine: Literal['rust-regex', 'python-re']  # default: 'rust-regex'\n    cache_strings: Union[bool, Literal['all', 'keys', 'none']]  # default: 'True'\n\n\nIncExCall: TypeAlias = 'set[int | str] | dict[int | str, IncExCall] | None'\n\n\nclass SerializationInfo(Protocol):\n    @property\n    def include(self) -> IncExCall: ...\n\n    @property\n    def exclude(self) -> IncExCall: ...\n\n    @property\n    def context(self) -> Any | None:\n        \"\"\"Current serialization context.\"\"\"\n\n    @property\n    def mode(self) -> str: ...\n\n    @property\n    def by_alias(self) -> bool: ...\n\n    @property\n    def exclude_unset(self) -> bool: ...\n\n    @property\n    def exclude_defaults(self) -> bool: ...\n\n    @property\n    def exclude_none(self) -> bool: ...\n\n    @property\n    def serialize_as_any(self) -> bool: ...\n\n    def round_trip(self) -> bool: ...\n\n    def mode_is_json(self) -> bool: ...\n\n    def __str__(self) -> str: ...\n\n    def __repr__(self) -> str: ...\n\n\nclass FieldSerializationInfo(SerializationInfo, Protocol):\n    @property\n    def field_name(self) -> str: ...\n\n\nclass ValidationInfo(Protocol):\n    \"\"\"\n    Argument passed to validation functions.\n    \"\"\"\n\n    @property\n    def context(self) -> Any | None:\n        \"\"\"Current validation context.\"\"\"\n        ...\n\n    @property\n    def config(self) -> CoreConfig | None:\n        \"\"\"The CoreConfig that applies to this validation.\"\"\"\n        ...\n\n    @property\n    def mode(self) -> Literal['python', 'json']:\n        \"\"\"The type of input data we are currently validating\"\"\"\n        ...\n\n    @property\n    def data(self) -> Dict[str, Any]:\n        \"\"\"The data being validated for this model.\"\"\"\n        ...\n\n    @property\n    def field_name(self) -> str | None:\n        \"\"\"\n        The name of the current field being validated if this validator is\n        attached to a model field.\n        \"\"\"\n        ...\n\n\nExpectedSerializationTypes = Literal[\n    'none',\n    'int',\n    'bool',\n    'float',\n    'str',\n    'bytes',\n    'bytearray',\n    'list',\n    'tuple',\n    'set',\n    'frozenset',\n    'generator',\n    'dict',\n    'datetime',\n    'date',\n    'time',\n    'timedelta',\n    'url',\n    'multi-host-url',\n    'json',\n    'uuid',\n]\n\n\nclass SimpleSerSchema(TypedDict, total=False):\n    type: Required[ExpectedSerializationTypes]\n\n\ndef simple_ser_schema(type: ExpectedSerializationTypes) -> SimpleSerSchema:\n    \"\"\"\n    Returns a schema for serialization with a custom type.\n\n    Args:\n        type: The type to use for serialization\n    \"\"\"\n    return SimpleSerSchema(type=type)\n\n\n# (input_value: Any, /) -> Any\nGeneralPlainNoInfoSerializerFunction = Callable[[Any], Any]\n# (input_value: Any, info: FieldSerializationInfo, /) -> Any\nGeneralPlainInfoSerializerFunction = Callable[[Any, SerializationInfo], Any]\n# (model: Any, input_value: Any, /) -> Any\nFieldPlainNoInfoSerializerFunction = Callable[[Any, Any], Any]\n# (model: Any, input_value: Any, info: FieldSerializationInfo, /) -> Any\nFieldPlainInfoSerializerFunction = Callable[[Any, Any, FieldSerializationInfo], Any]\nSerializerFunction = Union[\n    GeneralPlainNoInfoSerializerFunction,\n    GeneralPlainInfoSerializerFunction,\n    FieldPlainNoInfoSerializerFunction,\n    FieldPlainInfoSerializerFunction,\n]\n\nWhenUsed = Literal['always', 'unless-none', 'json', 'json-unless-none']\n\"\"\"\nValues have the following meanings:\n\n* `'always'` means always use\n* `'unless-none'` means use unless the value is `None`\n* `'json'` means use when serializing to JSON\n* `'json-unless-none'` means use when serializing to JSON and the value is not `None`\n\"\"\"\n\n\nclass PlainSerializerFunctionSerSchema(TypedDict, total=False):\n    type: Required[Literal['function-plain']]\n    function: Required[SerializerFunction]\n    is_field_serializer: bool  # default False\n    info_arg: bool  # default False\n    return_schema: CoreSchema  # if omitted, AnySchema is used\n    when_used: WhenUsed  # default: 'always'\n\n\ndef plain_serializer_function_ser_schema(\n    function: SerializerFunction,\n    *,\n    is_field_serializer: bool | None = None,\n    info_arg: bool | None = None,\n    return_schema: CoreSchema | None = None,\n    when_used: WhenUsed = 'always',\n) -> PlainSerializerFunctionSerSchema:\n    \"\"\"\n    Returns a schema for serialization with a function, can be either a \"general\" or \"field\" function.\n\n    Args:\n        function: The function to use for serialization\n        is_field_serializer: Whether the serializer is for a field, e.g. takes `model` as the first argument,\n            and `info` includes `field_name`\n        info_arg: Whether the function takes an `info` argument\n        return_schema: Schema to use for serializing return value\n        when_used: When the function should be called\n    \"\"\"\n    if when_used == 'always':\n        # just to avoid extra elements in schema, and to use the actual default defined in rust\n        when_used = None  # type: ignore\n    return _dict_not_none(\n        type='function-plain',\n        function=function,\n        is_field_serializer=is_field_serializer,\n        info_arg=info_arg,\n        return_schema=return_schema,\n        when_used=when_used,\n    )\n\n\nclass SerializerFunctionWrapHandler(Protocol):  # pragma: no cover\n    def __call__(self, input_value: Any, index_key: int | str | None = None, /) -> Any: ...\n\n\n# (input_value: Any, serializer: SerializerFunctionWrapHandler, /) -> Any\nGeneralWrapNoInfoSerializerFunction = Callable[[Any, SerializerFunctionWrapHandler], Any]\n# (input_value: Any, serializer: SerializerFunctionWrapHandler, info: SerializationInfo, /) -> Any\nGeneralWrapInfoSerializerFunction = Callable[[Any, SerializerFunctionWrapHandler, SerializationInfo], Any]\n# (model: Any, input_value: Any, serializer: SerializerFunctionWrapHandler, /) -> Any\nFieldWrapNoInfoSerializerFunction = Callable[[Any, Any, SerializerFunctionWrapHandler], Any]\n# (model: Any, input_value: Any, serializer: SerializerFunctionWrapHandler, info: FieldSerializationInfo, /) -> Any\nFieldWrapInfoSerializerFunction = Callable[[Any, Any, SerializerFunctionWrapHandler, FieldSerializationInfo], Any]\nWrapSerializerFunction = Union[\n    GeneralWrapNoInfoSerializerFunction,\n    GeneralWrapInfoSerializerFunction,\n    FieldWrapNoInfoSerializerFunction,\n    FieldWrapInfoSerializerFunction,\n]\n\n\nclass WrapSerializerFunctionSerSchema(TypedDict, total=False):\n    type: Required[Literal['function-wrap']]\n    function: Required[WrapSerializerFunction]\n    is_field_serializer: bool  # default False\n    info_arg: bool  # default False\n    schema: CoreSchema  # if omitted, the schema on which this serializer is defined is used\n    return_schema: CoreSchema  # if omitted, AnySchema is used\n    when_used: WhenUsed  # default: 'always'\n\n\ndef wrap_serializer_function_ser_schema(\n    function: WrapSerializerFunction,\n    *,\n    is_field_serializer: bool | None = None,\n    info_arg: bool | None = None,\n    schema: CoreSchema | None = None,\n    return_schema: CoreSchema | None = None,\n    when_used: WhenUsed = 'always',\n) -> WrapSerializerFunctionSerSchema:\n    \"\"\"\n    Returns a schema for serialization with a wrap function, can be either a \"general\" or \"field\" function.\n\n    Args:\n        function: The function to use for serialization\n        is_field_serializer: Whether the serializer is for a field, e.g. takes `model` as the first argument,\n            and `info` includes `field_name`\n        info_arg: Whether the function takes an `info` argument\n        schema: The schema to use for the inner serialization\n        return_schema: Schema to use for serializing return value\n        when_used: When the function should be called\n    \"\"\"\n    if when_used == 'always':\n        # just to avoid extra elements in schema, and to use the actual default defined in rust\n        when_used = None  # type: ignore\n    return _dict_not_none(\n        type='function-wrap',\n        function=function,\n        is_field_serializer=is_field_serializer,\n        info_arg=info_arg,\n        schema=schema,\n        return_schema=return_schema,\n        when_used=when_used,\n    )\n\n\nclass FormatSerSchema(TypedDict, total=False):\n    type: Required[Literal['format']]\n    formatting_string: Required[str]\n    when_used: WhenUsed  # default: 'json-unless-none'\n\n\ndef format_ser_schema(formatting_string: str, *, when_used: WhenUsed = 'json-unless-none') -> FormatSerSchema:\n    \"\"\"\n    Returns a schema for serialization using python's `format` method.\n\n    Args:\n        formatting_string: String defining the format to use\n        when_used: Same meaning as for [general_function_plain_ser_schema], but with a different default\n    \"\"\"\n    if when_used == 'json-unless-none':\n        # just to avoid extra elements in schema, and to use the actual default defined in rust\n        when_used = None  # type: ignore\n    return _dict_not_none(type='format', formatting_string=formatting_string, when_used=when_used)\n\n\nclass ToStringSerSchema(TypedDict, total=False):\n    type: Required[Literal['to-string']]\n    when_used: WhenUsed  # default: 'json-unless-none'\n\n\ndef to_string_ser_schema(*, when_used: WhenUsed = 'json-unless-none') -> ToStringSerSchema:\n    \"\"\"\n    Returns a schema for serialization using python's `str()` / `__str__` method.\n\n    Args:\n        when_used: Same meaning as for [general_function_plain_ser_schema], but with a different default\n    \"\"\"\n    s = dict(type='to-string')\n    if when_used != 'json-unless-none':\n        # just to avoid extra elements in schema, and to use the actual default defined in rust\n        s['when_used'] = when_used\n    return s  # type: ignore\n\n\nclass ModelSerSchema(TypedDict, total=False):\n    type: Required[Literal['model']]\n    cls: Required[Type[Any]]\n    schema: Required[CoreSchema]\n\n\ndef model_ser_schema(cls: Type[Any], schema: CoreSchema) -> ModelSerSchema:\n    \"\"\"\n    Returns a schema for serialization using a model.\n\n    Args:\n        cls: The expected class type, used to generate warnings if the wrong type is passed\n        schema: Internal schema to use to serialize the model dict\n    \"\"\"\n    return ModelSerSchema(type='model', cls=cls, schema=schema)\n\n\nSerSchema = Union[\n    SimpleSerSchema,\n    PlainSerializerFunctionSerSchema,\n    WrapSerializerFunctionSerSchema,\n    FormatSerSchema,\n    ToStringSerSchema,\n    ModelSerSchema,\n]\n\n\nclass ComputedField(TypedDict, total=False):\n    type: Required[Literal['computed-field']]\n    property_name: Required[str]\n    return_schema: Required[CoreSchema]\n    alias: str\n    metadata: Any\n\n\ndef computed_field(\n    property_name: str, return_schema: CoreSchema, *, alias: str | None = None, metadata: Any = None\n) -> ComputedField:\n    \"\"\"\n    ComputedFields are properties of a model or dataclass that are included in serialization.\n\n    Args:\n        property_name: The name of the property on the model or dataclass\n        return_schema: The schema used for the type returned by the computed field\n        alias: The name to use in the serialized output\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n    \"\"\"\n    return _dict_not_none(\n        type='computed-field', property_name=property_name, return_schema=return_schema, alias=alias, metadata=metadata\n    )\n\n\nclass AnySchema(TypedDict, total=False):\n    type: Required[Literal['any']]\n    ref: str\n    metadata: Any\n    serialization: SerSchema\n\n\ndef any_schema(*, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -> AnySchema:\n    \"\"\"\n    Returns a schema that matches any value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.any_schema()\n    v = SchemaValidator(schema)\n    assert v.validate_python(1) == 1\n    ```\n\n    Args:\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(type='any', ref=ref, metadata=metadata, serialization=serialization)\n\n\nclass NoneSchema(TypedDict, total=False):\n    type: Required[Literal['none']]\n    ref: str\n    metadata: Any\n    serialization: SerSchema\n\n\ndef none_schema(*, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -> NoneSchema:\n    \"\"\"\n    Returns a schema that matches a None value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.none_schema()\n    v = SchemaValidator(schema)\n    assert v.validate_python(None) is None\n    ```\n\n    Args:\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(type='none', ref=ref, metadata=metadata, serialization=serialization)\n\n\nclass BoolSchema(TypedDict, total=False):\n    type: Required[Literal['bool']]\n    strict: bool\n    ref: str\n    metadata: Any\n    serialization: SerSchema\n\n\ndef bool_schema(\n    strict: bool | None = None, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None\n) -> BoolSchema:\n    \"\"\"\n    Returns a schema that matches a bool value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.bool_schema()\n    v = SchemaValidator(schema)\n    assert v.validate_python('True') is True\n    ```\n\n    Args:\n        strict: Whether the value should be a bool or a value that can be converted to a bool\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(type='bool', strict=strict, ref=ref, metadata=metadata, serialization=serialization)\n\n\nclass IntSchema(TypedDict, total=False):\n    type: Required[Literal['int']]\n    multiple_of: int\n    le: int\n    ge: int\n    lt: int\n    gt: int\n    strict: bool\n    ref: str\n    metadata: Any\n    serialization: SerSchema\n\n\ndef int_schema(\n    *,\n    multiple_of: int | None = None,\n    le: int | None = None,\n    ge: int | None = None,\n    lt: int | None = None,\n    gt: int | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -> IntSchema:\n    \"\"\"\n    Returns a schema that matches a int value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.int_schema(multiple_of=2, le=6, ge=2)\n    v = SchemaValidator(schema)\n    assert v.validate_python('4') == 4\n    ```\n\n    Args:\n        multiple_of: The value must be a multiple of this number\n        le: The value must be less than or equal to this number\n        ge: The value must be greater than or equal to this number\n        lt: The value must be strictly less than this number\n        gt: The value must be strictly greater than this number\n        strict: Whether the value should be a int or a value that can be converted to a int\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='int',\n        multiple_of=multiple_of,\n        le=le,\n        ge=ge,\n        lt=lt,\n        gt=gt,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n\n\nclass FloatSchema(TypedDict, total=False):\n    type: Required[Literal['float']]\n    allow_inf_nan: bool  # whether 'NaN', '+inf', '-inf' should be forbidden. default: True\n    multiple_of: float\n    le: float\n    ge: float\n    lt: float\n    gt: float\n    strict: bool\n    ref: str\n    metadata: Any\n    serialization: SerSchema\n\n\ndef float_schema(\n    *,\n    allow_inf_nan: bool | None = None,\n    multiple_of: float | None = None,\n    le: float | None = None,\n    ge: float | None = None,\n    lt: float | None = None,\n    gt: float | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -> FloatSchema:\n    \"\"\"\n    Returns a schema that matches a float value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.float_schema(le=0.8, ge=0.2)\n    v = SchemaValidator(schema)\n    assert v.validate_python('0.5') == 0.5\n    ```\n\n    Args:\n        allow_inf_nan: Whether to allow inf and nan values\n        multiple_of: The value must be a multiple of this number\n        le: The value must be less than or equal to this number\n        ge: The value must be greater than or equal to this number\n        lt: The value must be strictly less than this number\n        gt: The value must be strictly greater than this number\n        strict: Whether the value should be a float or a value that can be converted to a float\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='float',\n        allow_inf_nan=allow_inf_nan,\n        multiple_of=multiple_of,\n        le=le,\n        ge=ge,\n        lt=lt,\n        gt=gt,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n\n\nclass DecimalSchema(TypedDict, total=False):\n    type: Required[Literal['decimal']]\n    allow_inf_nan: bool  # whether 'NaN', '+inf', '-inf' should be forbidden. default: False\n    multiple_of: Decimal\n    le: Decimal\n    ge: Decimal\n    lt: Decimal\n    gt: Decimal\n    max_digits: int\n    decimal_places: int\n    strict: bool\n    ref: str\n    metadata: Any\n    serialization: SerSchema\n\n\ndef decimal_schema(\n    *,\n    allow_inf_nan: bool = None,\n    multiple_of: Decimal | None = None,\n    le: Decimal | None = None,\n    ge: Decimal | None = None,\n    lt: Decimal | None = None,\n    gt: Decimal | None = None,\n    max_digits: int | None = None,\n    decimal_places: int | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -> DecimalSchema:\n    \"\"\"\n    Returns a schema that matches a decimal value, e.g.:\n\n    ```py\n    from decimal import Decimal\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.decimal_schema(le=0.8, ge=0.2)\n    v = SchemaValidator(schema)\n    assert v.validate_python('0.5') == Decimal('0.5')\n    ```\n\n    Args:\n        allow_inf_nan: Whether to allow inf and nan values\n        multiple_of: The value must be a multiple of this number\n        le: The value must be less than or equal to this number\n        ge: The value must be greater than or equal to this number\n        lt: The value must be strictly less than this number\n        gt: The value must be strictly greater than this number\n        max_digits: The maximum number of decimal digits allowed\n        decimal_places: The maximum number of decimal places allowed\n        strict: Whether the value should be a float or a value that can be converted to a float\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='decimal',\n        gt=gt,\n        ge=ge,\n        lt=lt,\n        le=le,\n        max_digits=max_digits,\n        decimal_places=decimal_places,\n        multiple_of=multiple_of,\n        allow_inf_nan=allow_inf_nan,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n\n\nclass StringSchema(TypedDict, total=False):\n    type: Required[Literal['str']]\n    pattern: Union[str, Pattern[str]]\n    max_length: int\n    min_length: int\n    strip_whitespace: bool\n    to_lower: bool\n    to_upper: bool\n    regex_engine: Literal['rust-regex', 'python-re']  # default: 'rust-regex'\n    strict: bool\n    coerce_numbers_to_str: bool\n    ref: str\n    metadata: Any\n    serialization: SerSchema\n\n\ndef str_schema(\n    *,\n    pattern: str | Pattern[str] | None = None,\n    max_length: int | None = None,\n    min_length: int | None = None,\n    strip_whitespace: bool | None = None,\n    to_lower: bool | None = None,\n    to_upper: bool | None = None,\n    regex_engine: Literal['rust-regex', 'python-re'] | None = None,\n    strict: bool | None = None,\n    coerce_numbers_to_str: bool | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -> StringSchema:\n    \"\"\"\n    Returns a schema that matches a string value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.str_schema(max_length=10, min_length=2)\n    v = SchemaValidator(schema)\n    assert v.validate_python('hello') == 'hello'\n    ```\n\n    Args:\n        pattern: A regex pattern that the value must match\n        max_length: The value must be at most this length\n        min_length: The value must be at least this length\n        strip_whitespace: Whether to strip whitespace from the value\n        to_lower: Whether to convert the value to lowercase\n        to_upper: Whether to convert the value to uppercase\n        regex_engine: The regex engine to use for pattern validation. Default is 'rust-regex'.\n            - `rust-regex` uses the [`regex`](https://docs.rs/regex) Rust\n              crate, which is non-backtracking and therefore more DDoS\n              resistant, but does not support all regex features.\n            - `python-re` use the [`re`](https://docs.python.org/3/library/re.html) module,\n              which supports all regex features, but may be slower.\n        strict: Whether the value should be a string or a value that can be converted to a string\n        coerce_numbers_to_str: Whether to enable coercion of any `Number` type to `str` (not applicable in `strict` mode).\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='str',\n        pattern=pattern,\n        max_length=max_length,\n        min_length=min_length,\n        strip_whitespace=strip_whitespace,\n        to_lower=to_lower,\n        to_upper=to_upper,\n        regex_engine=regex_engine,\n        strict=strict,\n        coerce_numbers_to_str=coerce_numbers_to_str,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n\n\nclass BytesSchema(TypedDict, total=False):\n    type: Required[Literal['bytes']]\n    max_length: int\n    min_length: int\n    strict: bool\n    ref: str\n    metadata: Any\n    serialization: SerSchema\n\n\ndef bytes_schema(\n    *,\n    max_length: int | None = None,\n    min_length: int | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -> BytesSchema:\n    \"\"\"\n    Returns a schema that matches a bytes value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.bytes_schema(max_length=10, min_length=2)\n    v = SchemaValidator(schema)\n    assert v.validate_python(b'hello') == b'hello'\n    ```\n\n    Args:\n        max_length: The value must be at most this length\n        min_length: The value must be at least this length\n        strict: Whether the value should be a bytes or a value that can be converted to a bytes\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='bytes',\n        max_length=max_length,\n        min_length=min_length,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n\n\nclass DateSchema(TypedDict, total=False):\n    type: Required[Literal['date']]\n    strict: bool\n    le: date\n    ge: date\n    lt: date\n    gt: date\n    now_op: Literal['past', 'future']\n    # defaults to current local utc offset from `time.localtime().tm_gmtoff`\n    # value is restricted to -86_400 < offset < 86_400 by bounds in generate_self_schema.py\n    now_utc_offset: int\n    ref: str\n    metadata: Any\n    serialization: SerSchema\n\n\ndef date_schema(\n    *,\n    strict: bool | None = None,\n    le: date | None = None,\n    ge: date | None = None,\n    lt: date | None = None,\n    gt: date | None = None,\n    now_op: Literal['past', 'future'] | None = None,\n    now_utc_offset: int | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -> DateSchema:\n    \"\"\"\n    Returns a schema that matches a date value, e.g.:\n\n    ```py\n    from datetime import date\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.date_schema(le=date(2020, 1, 1), ge=date(2019, 1, 1))\n    v = SchemaValidator(schema)\n    assert v.validate_python(date(2019, 6, 1)) == date(2019, 6, 1)\n    ```\n\n    Args:\n        strict: Whether the value should be a date or a value that can be converted to a date\n        le: The value must be less than or equal to this date\n        ge: The value must be greater than or equal to this date\n        lt: The value must be strictly less than this date\n        gt: The value must be strictly greater than this date\n        now_op: The value must be in the past or future relative to the current date\n        now_utc_offset: The value must be in the past or future relative to the current date with this utc offset\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='date',\n        strict=strict,\n        le=le,\n        ge=ge,\n        lt=lt,\n        gt=gt,\n        now_op=now_op,\n        now_utc_offset=now_utc_offset,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n\n\nclass TimeSchema(TypedDict, total=False):\n    type: Required[Literal['time']]\n    strict: bool\n    le: time\n    ge: time\n    lt: time\n    gt: time\n    tz_constraint: Union[Literal['aware', 'naive'], int]\n    microseconds_precision: Literal['truncate', 'error']\n    ref: str\n    metadata: Any\n    serialization: SerSchema\n\n\ndef time_schema(\n    *,\n    strict: bool | None = None,\n    le: time | None = None,\n    ge: time | None = None,\n    lt: time | None = None,\n    gt: time | None = None,\n    tz_constraint: Literal['aware', 'naive'] | int | None = None,\n    microseconds_precision: Literal['truncate', 'error'] = 'truncate',\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -> TimeSchema:\n    \"\"\"\n    Returns a schema that matches a time value, e.g.:\n\n    ```py\n    from datetime import time\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.time_schema(le=time(12, 0, 0), ge=time(6, 0, 0))\n    v = SchemaValidator(schema)\n    assert v.validate_python(time(9, 0, 0)) == time(9, 0, 0)\n    ```\n\n    Args:\n        strict: Whether the value should be a time or a value that can be converted to a time\n        le: The value must be less than or equal to this time\n        ge: The value must be greater than or equal to this time\n        lt: The value must be strictly less than this time\n        gt: The value must be strictly greater than this time\n        tz_constraint: The value must be timezone aware or naive, or an int to indicate required tz offset\n        microseconds_precision: The behavior when seconds have more than 6 digits or microseconds is too large\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='time',\n        strict=strict,\n        le=le,\n        ge=ge,\n        lt=lt,\n        gt=gt,\n        tz_constraint=tz_constraint,\n        microseconds_precision=microseconds_precision,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n\n\nclass DatetimeSchema(TypedDict, total=False):\n    type: Required[Literal['datetime']]\n    strict: bool\n    le: datetime\n    ge: datetime\n    lt: datetime\n    gt: datetime\n    now_op: Literal['past', 'future']\n    tz_constraint: Union[Literal['aware', 'naive'], int]\n    # defaults to current local utc offset from `time.localtime().tm_gmtoff`\n    # value is restricted to -86_400 < offset < 86_400 by bounds in generate_self_schema.py\n    now_utc_offset: int\n    microseconds_precision: Literal['truncate', 'error']  # default: 'truncate'\n    ref: str\n    metadata: Any\n    serialization: SerSchema\n\n\ndef datetime_schema(\n    *,\n    strict: bool | None = None,\n    le: datetime | None = None,\n    ge: datetime | None = None,\n    lt: datetime | None = None,\n    gt: datetime | None = None,\n    now_op: Literal['past', 'future'] | None = None,\n    tz_constraint: Literal['aware', 'naive'] | int | None = None,\n    now_utc_offset: int | None = None,\n    microseconds_precision: Literal['truncate', 'error'] = 'truncate',\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -> DatetimeSchema:\n    \"\"\"\n    Returns a schema that matches a datetime value, e.g.:\n\n    ```py\n    from datetime import datetime\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.datetime_schema()\n    v = SchemaValidator(schema)\n    now = datetime.now()\n    assert v.validate_python(str(now)) == now\n    ```\n\n    Args:\n        strict: Whether the value should be a datetime or a value that can be converted to a datetime\n        le: The value must be less than or equal to this datetime\n        ge: The value must be greater than or equal to this datetime\n        lt: The value must be strictly less than this datetime\n        gt: The value must be strictly greater than this datetime\n        now_op: The value must be in the past or future relative to the current datetime\n        tz_constraint: The value must be timezone aware or naive, or an int to indicate required tz offset\n            TODO: use of a tzinfo where offset changes based on the datetime is not yet supported\n        now_utc_offset: The value must be in the past or future relative to the current datetime with this utc offset\n        microseconds_precision: The behavior when seconds have more than 6 digits or microseconds is too large\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='datetime',\n        strict=strict,\n        le=le,\n        ge=ge,\n        lt=lt,\n        gt=gt,\n        now_op=now_op,\n        tz_constraint=tz_constraint,\n        now_utc_offset=now_utc_offset,\n        microseconds_precision=microseconds_precision,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n\n\nclass TimedeltaSchema(TypedDict, total=False):\n    type: Required[Literal['timedelta']]\n    strict: bool\n    le: timedelta\n    ge: timedelta\n    lt: timedelta\n    gt: timedelta\n    microseconds_precision: Literal['truncate', 'error']\n    ref: str\n    metadata: Any\n    serialization: SerSchema\n\n\ndef timedelta_schema(\n    *,\n    strict: bool | None = None,\n    le: timedelta | None = None,\n    ge: timedelta | None = None,\n    lt: timedelta | None = None,\n    gt: timedelta | None = None,\n    microseconds_precision: Literal['truncate', 'error'] = 'truncate',\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -> TimedeltaSchema:\n    \"\"\"\n    Returns a schema that matches a timedelta value, e.g.:\n\n    ```py\n    from datetime import timedelta\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.timedelta_schema(le=timedelta(days=1), ge=timedelta(days=0))\n    v = SchemaValidator(schema)\n    assert v.validate_python(timedelta(hours=12)) == timedelta(hours=12)\n    ```\n\n    Args:\n        strict: Whether the value should be a timedelta or a value that can be converted to a timedelta\n        le: The value must be less than or equal to this timedelta\n        ge: The value must be greater than or equal to this timedelta\n        lt: The value must be strictly less than this timedelta\n        gt: The value must be strictly greater than this timedelta\n        microseconds_precision: The behavior when seconds have more than 6 digits or microseconds is too large\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='timedelta',\n        strict=strict,\n        le=le,\n        ge=ge,\n        lt=lt,\n        gt=gt,\n        microseconds_precision=microseconds_precision,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n\n\nclass LiteralSchema(TypedDict, total=False):\n    type: Required[Literal['literal']]\n    expected: Required[List[Any]]\n    ref: str\n    metadata: Any\n    serialization: SerSchema\n\n\ndef literal_schema(\n    expected: list[Any], *, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None\n) -> LiteralSchema:\n    \"\"\"\n    Returns a schema that matches a literal value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.literal_schema(['hello', 'world'])\n    v = SchemaValidator(schema)\n    assert v.validate_python('hello') == 'hello'\n    ```\n\n    Args:\n        expected: The value must be one of these values\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(type='literal', expected=expected, ref=ref, metadata=metadata, serialization=serialization)\n\n\nclass EnumSchema(TypedDict, total=False):\n    type: Required[Literal['enum']]\n    cls: Required[Any]\n    members: Required[List[Any]]\n    sub_type: Literal['str', 'int', 'float']\n    missing: Callable[[Any], Any]\n    strict: bool\n    ref: str\n    metadata: Any\n    serialization: SerSchema\n\n\ndef enum_schema(\n    cls: Any,\n    members: list[Any],\n    *,\n    sub_type: Literal['str', 'int', 'float'] | None = None,\n    missing: Callable[[Any], Any] | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -> EnumSchema:\n    \"\"\"\n    Returns a schema that matches an enum value, e.g.:\n\n    ```py\n    from enum import Enum\n    from pydantic_core import SchemaValidator, core_schema\n\n    class Color(Enum):\n        RED = 1\n        GREEN = 2\n        BLUE = 3\n\n    schema = core_schema.enum_schema(Color, list(Color.__members__.values()))\n    v = SchemaValidator(schema)\n    assert v.validate_python(2) is Color.GREEN\n    ```\n\n    Args:\n        cls: The enum class\n        members: The members of the enum, generally `list(MyEnum.__members__.values())`\n        sub_type: The type of the enum, either 'str' or 'int' or None for plain enums\n        missing: A function to use when the value is not found in the enum, from `_missing_`\n        strict: Whether to use strict mode, defaults to False\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='enum',\n        cls=cls,\n        members=members,\n        sub_type=sub_type,\n        missing=missing,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n\n\n# must match input/parse_json.rs::JsonType::try_from\nJsonType = Literal['null', 'bool', 'int', 'float', 'str', 'list', 'dict']\n\n\nclass IsInstanceSchema(TypedDict, total=False):\n    type: Required[Literal['is-instance']]\n    cls: Required[Any]\n    cls_repr: str\n    ref: str\n    metadata: Any\n    serialization: SerSchema\n\n\ndef is_instance_schema(\n    cls: Any,\n    *,\n    cls_repr: str | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -> IsInstanceSchema:\n    \"\"\"\n    Returns a schema that checks if a value is an instance of a class, equivalent to python's `isinstance` method, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    class A:\n        pass\n\n    schema = core_schema.is_instance_schema(cls=A)\n    v = SchemaValidator(schema)\n    v.validate_python(A())\n    ```\n\n    Args:\n        cls: The value must be an instance of this class\n        cls_repr: If provided this string is used in the validator name instead of `repr(cls)`\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='is-instance', cls=cls, cls_repr=cls_repr, ref=ref, metadata=metadata, serialization=serialization\n    )\n\n\nclass IsSubclassSchema(TypedDict, total=False):\n    type: Required[Literal['is-subclass']]\n    cls: Required[Type[Any]]\n    cls_repr: str\n    ref: str\n    metadata: Any\n    serialization: SerSchema\n\n\ndef is_subclass_schema(\n    cls: Type[Any],\n    *,\n    cls_repr: str | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -> IsInstanceSchema:\n    \"\"\"\n    Returns a schema that checks if a value is a subtype of a class, equivalent to python's `issubclass` method, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    class A:\n        pass\n\n    class B(A):\n        pass\n\n    schema = core_schema.is_subclass_schema(cls=A)\n    v = SchemaValidator(schema)\n    v.validate_python(B)\n    ```\n\n    Args:\n        cls: The value must be a subclass of this class\n        cls_repr: If provided this string is used in the validator name instead of `repr(cls)`\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='is-subclass', cls=cls, cls_repr=cls_repr, ref=ref, metadata=metadata, serialization=serialization\n    )\n\n\nclass CallableSchema(TypedDict, total=False):\n    type: Required[Literal['callable']]\n    ref: str\n    metadata: Any\n    serialization: SerSchema\n\n\ndef callable_schema(\n    *, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None\n) -> CallableSchema:\n    \"\"\"\n    Returns a schema that checks if a value is callable, equivalent to python's `callable` method, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.callable_schema()\n    v = SchemaValidator(schema)\n    v.validate_python(min)\n    ```\n\n    Args:\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(type='callable', ref=ref, metadata=metadata, serialization=serialization)\n\n\nclass UuidSchema(TypedDict, total=False):\n    type: Required[Literal['uuid']]\n    version: Literal[1, 3, 4, 5]\n    strict: bool\n    ref: str\n    metadata: Any\n    serialization: SerSchema\n\n\ndef uuid_schema(\n    *,\n    version: Literal[1, 3, 4, 5] | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -> UuidSchema:\n    return _dict_not_none(\n        type='uuid', version=version, strict=strict, ref=ref, metadata=metadata, serialization=serialization\n    )\n\n\nclass IncExSeqSerSchema(TypedDict, total=False):\n    type: Required[Literal['include-exclude-sequence']]\n    include: Set[int]\n    exclude: Set[int]\n\n\ndef filter_seq_schema(*, include: Set[int] | None = None, exclude: Set[int] | None = None) -> IncExSeqSerSchema:\n    return _dict_not_none(type='include-exclude-sequence', include=include, exclude=exclude)\n\n\nIncExSeqOrElseSerSchema = Union[IncExSeqSerSchema, SerSchema]\n\n\nclass ListSchema(TypedDict, total=False):\n    type: Required[Literal['list']]\n    items_schema: CoreSchema\n    min_length: int\n    max_length: int\n    fail_fast: bool\n    strict: bool\n    ref: str\n    metadata: Any\n    serialization: IncExSeqOrElseSerSchema\n\n\ndef list_schema(\n    items_schema: CoreSchema | None = None,\n    *,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    fail_fast: bool | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: IncExSeqOrElseSerSchema | None = None,\n) -> ListSchema:\n    \"\"\"\n    Returns a schema that matches a list value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.list_schema(core_schema.int_schema(), min_length=0, max_length=10)\n    v = SchemaValidator(schema)\n    assert v.validate_python(['4']) == [4]\n    ```\n\n    Args:\n        items_schema: The value must be a list of items that match this schema\n        min_length: The value must be a list with at least this many items\n        max_length: The value must be a list with at most this many items\n        fail_fast: Stop validation on the first error\n        strict: The value must be a list with exactly this many items\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='list',\n        items_schema=items_schema,\n        min_length=min_length,\n        max_length=max_length,\n        fail_fast=fail_fast,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n\n\n# @deprecated('tuple_positional_schema is deprecated. Use pydantic_core.core_schema.tuple_schema instead.')\ndef tuple_positional_schema(\n    items_schema: list[CoreSchema],\n    *,\n    extras_schema: CoreSchema | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: IncExSeqOrElseSerSchema | None = None,\n) -> TupleSchema:\n    \"\"\"\n    Returns a schema that matches a tuple of schemas, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.tuple_positional_schema(\n        [core_schema.int_schema(), core_schema.str_schema()]\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_python((1, 'hello')) == (1, 'hello')\n    ```\n\n    Args:\n        items_schema: The value must be a tuple with items that match these schemas\n        extras_schema: The value must be a tuple with items that match this schema\n            This was inspired by JSON schema's `prefixItems` and `items` fields.\n            In python's `typing.Tuple`, you can't specify a type for \"extra\" items -- they must all be the same type\n            if the length is variable. So this field won't be set from a `typing.Tuple` annotation on a pydantic model.\n        strict: The value must be a tuple with exactly this many items\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    if extras_schema is not None:\n        variadic_item_index = len(items_schema)\n        items_schema = items_schema + [extras_schema]\n    else:\n        variadic_item_index = None\n    return tuple_schema(\n        items_schema=items_schema,\n        variadic_item_index=variadic_item_index,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n\n\n# @deprecated('tuple_variable_schema is deprecated. Use pydantic_core.core_schema.tuple_schema instead.')\ndef tuple_variable_schema(\n    items_schema: CoreSchema | None = None,\n    *,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: IncExSeqOrElseSerSchema | None = None,\n) -> TupleSchema:\n    \"\"\"\n    Returns a schema that matches a tuple of a given schema, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.tuple_variable_schema(\n        items_schema=core_schema.int_schema(), min_length=0, max_length=10\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_python(('1', 2, 3)) == (1, 2, 3)\n    ```\n\n    Args:\n        items_schema: The value must be a tuple with items that match this schema\n        min_length: The value must be a tuple with at least this many items\n        max_length: The value must be a tuple with at most this many items\n        strict: The value must be a tuple with exactly this many items\n        ref: Optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return tuple_schema(\n        items_schema=[items_schema or any_schema()],\n        variadic_item_index=0,\n        min_length=min_length,\n        max_length=max_length,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n\n\nclass TupleSchema(TypedDict, total=False):\n    type: Required[Literal['tuple']]\n    items_schema: Required[List[CoreSchema]]\n    variadic_item_index: int\n    min_length: int\n    max_length: int\n    fail_fast: bool\n    strict: bool\n    ref: str\n    metadata: Any\n    serialization: IncExSeqOrElseSerSchema\n\n\ndef tuple_schema(\n    items_schema: list[CoreSchema],\n    *,\n    variadic_item_index: int | None = None,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    fail_fast: bool | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: IncExSeqOrElseSerSchema | None = None,\n) -> TupleSchema:\n    \"\"\"\n    Returns a schema that matches a tuple of schemas, with an optional variadic item, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.tuple_schema(\n        [core_schema.int_schema(), core_schema.str_schema(), core_schema.float_schema()],\n        variadic_item_index=1,\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_python((1, 'hello', 'world', 1.5)) == (1, 'hello', 'world', 1.5)\n    ```\n\n    Args:\n        items_schema: The value must be a tuple with items that match these schemas\n        variadic_item_index: The index of the schema in `items_schema` to be treated as variadic (following PEP 646)\n        min_length: The value must be a tuple with at least this many items\n        max_length: The value must be a tuple with at most this many items\n        fail_fast: Stop validation on the first error\n        strict: The value must be a tuple with exactly this many items\n        ref: Optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='tuple',\n        items_schema=items_schema,\n        variadic_item_index=variadic_item_index,\n        min_length=min_length,\n        max_length=max_length,\n        fail_fast=fail_fast,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n\n\nclass SetSchema(TypedDict, total=False):\n    type: Required[Literal['set']]\n    items_schema: CoreSchema\n    min_length: int\n    max_length: int\n    fail_fast: bool\n    strict: bool\n    ref: str\n    metadata: Any\n    serialization: SerSchema\n\n\ndef set_schema(\n    items_schema: CoreSchema | None = None,\n    *,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    fail_fast: bool | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -> SetSchema:\n    \"\"\"\n    Returns a schema that matches a set of a given schema, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.set_schema(\n        items_schema=core_schema.int_schema(), min_length=0, max_length=10\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_python({1, '2', 3}) == {1, 2, 3}\n    ```\n\n    Args:\n        items_schema: The value must be a set with items that match this schema\n        min_length: The value must be a set with at least this many items\n        max_length: The value must be a set with at most this many items\n        fail_fast: Stop validation on the first error\n        strict: The value must be a set with exactly this many items\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='set',\n        items_schema=items_schema,\n        min_length=min_length,\n        max_length=max_length,\n        fail_fast=fail_fast,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n\n\nclass FrozenSetSchema(TypedDict, total=False):\n    type: Required[Literal['frozenset']]\n    items_schema: CoreSchema\n    min_length: int\n    max_length: int\n    fail_fast: bool\n    strict: bool\n    ref: str\n    metadata: Any\n    serialization: SerSchema\n\n\ndef frozenset_schema(\n    items_schema: CoreSchema | None = None,\n    *,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    fail_fast: bool | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -> FrozenSetSchema:\n    \"\"\"\n    Returns a schema that matches a frozenset of a given schema, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.frozenset_schema(\n        items_schema=core_schema.int_schema(), min_length=0, max_length=10\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_python(frozenset(range(3))) == frozenset({0, 1, 2})\n    ```\n\n    Args:\n        items_schema: The value must be a frozenset with items that match this schema\n        min_length: The value must be a frozenset with at least this many items\n        max_length: The value must be a frozenset with at most this many items\n        fail_fast: Stop validation on the first error\n        strict: The value must be a frozenset with exactly this many items\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='frozenset',\n        items_schema=items_schema,\n        min_length=min_length,\n        max_length=max_length,\n        fail_fast=fail_fast,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n\n\nclass GeneratorSchema(TypedDict, total=False):\n    type: Required[Literal['generator']]\n    items_schema: CoreSchema\n    min_length: int\n    max_length: int\n    ref: str\n    metadata: Any\n    serialization: IncExSeqOrElseSerSchema\n\n\ndef generator_schema(\n    items_schema: CoreSchema | None = None,\n    *,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: IncExSeqOrElseSerSchema | None = None,\n) -> GeneratorSchema:\n    \"\"\"\n    Returns a schema that matches a generator value, e.g.:\n\n    ```py\n    from typing import Iterator\n    from pydantic_core import SchemaValidator, core_schema\n\n    def gen() -> Iterator[int]:\n        yield 1\n\n    schema = core_schema.generator_schema(items_schema=core_schema.int_schema())\n    v = SchemaValidator(schema)\n    v.validate_python(gen())\n    ```\n\n    Unlike other types, validated generators do not raise ValidationErrors eagerly,\n    but instead will raise a ValidationError when a violating value is actually read from the generator.\n    This is to ensure that \"validated\" generators retain the benefit of lazy evaluation.\n\n    Args:\n        items_schema: The value must be a generator with items that match this schema\n        min_length: The value must be a generator that yields at least this many items\n        max_length: The value must be a generator that yields at most this many items\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='generator',\n        items_schema=items_schema,\n        min_length=min_length,\n        max_length=max_length,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n\n\nIncExDict = Set[Union[int, str]]\n\n\nclass IncExDictSerSchema(TypedDict, total=False):\n    type: Required[Literal['include-exclude-dict']]\n    include: IncExDict\n    exclude: IncExDict\n\n\ndef filter_dict_schema(*, include: IncExDict | None = None, exclude: IncExDict | None = None) -> IncExDictSerSchema:\n    return _dict_not_none(type='include-exclude-dict', include=include, exclude=exclude)\n\n\nIncExDictOrElseSerSchema = Union[IncExDictSerSchema, SerSchema]\n\n\nclass DictSchema(TypedDict, total=False):\n    type: Required[Literal['dict']]\n    keys_schema: CoreSchema  # default: AnySchema\n    values_schema: CoreSchema  # default: AnySchema\n    min_length: int\n    max_length: int\n    strict: bool\n    ref: str\n    metadata: Any\n    serialization: IncExDictOrElseSerSchema\n\n\ndef dict_schema(\n    keys_schema: CoreSchema | None = None,\n    values_schema: CoreSchema | None = None,\n    *,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -> DictSchema:\n    \"\"\"\n    Returns a schema that matches a dict value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.dict_schema(\n        keys_schema=core_schema.str_schema(), values_schema=core_schema.int_schema()\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_python({'a': '1', 'b': 2}) == {'a': 1, 'b': 2}\n    ```\n\n    Args:\n        keys_schema: The value must be a dict with keys that match this schema\n        values_schema: The value must be a dict with values that match this schema\n        min_length: The value must be a dict with at least this many items\n        max_length: The value must be a dict with at most this many items\n        strict: Whether the keys and values should be validated with strict mode\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='dict',\n        keys_schema=keys_schema,\n        values_schema=values_schema,\n        min_length=min_length,\n        max_length=max_length,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n\n\n# (input_value: Any, /) -> Any\nNoInfoValidatorFunction = Callable[[Any], Any]\n\n\nclass NoInfoValidatorFunctionSchema(TypedDict):\n    type: Literal['no-info']\n    function: NoInfoValidatorFunction\n\n\n# (input_value: Any, info: ValidationInfo, /) -> Any\nWithInfoValidatorFunction = Callable[[Any, ValidationInfo], Any]\n\n\nclass WithInfoValidatorFunctionSchema(TypedDict, total=False):\n    type: Required[Literal['with-info']]\n    function: Required[WithInfoValidatorFunction]\n    field_name: str\n\n\nValidationFunction = Union[NoInfoValidatorFunctionSchema, WithInfoValidatorFunctionSchema]\n\n\nclass _ValidatorFunctionSchema(TypedDict, total=False):\n    function: Required[ValidationFunction]\n    schema: Required[CoreSchema]\n    ref: str\n    metadata: Any\n    serialization: SerSchema\n\n\nclass BeforeValidatorFunctionSchema(_ValidatorFunctionSchema, total=False):\n    type: Required[Literal['function-before']]\n\n\ndef no_info_before_validator_function(\n    function: NoInfoValidatorFunction,\n    schema: CoreSchema,\n    *,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -> BeforeValidatorFunctionSchema:\n    \"\"\"\n    Returns a schema that calls a validator function before validating, no `info` argument is provided, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    def fn(v: bytes) -> str:\n        return v.decode() + 'world'\n\n    func_schema = core_schema.no_info_before_validator_function(\n        function=fn, schema=core_schema.str_schema()\n    )\n    schema = core_schema.typed_dict_schema({'a': core_schema.typed_dict_field(func_schema)})\n\n    v = SchemaValidator(schema)\n    assert v.validate_python({'a': b'hello '}) == {'a': 'hello world'}\n    ```\n\n    Args:\n        function: The validator function to call\n        schema: The schema to validate the output of the validator function\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='function-before',\n        function={'type': 'no-info', 'function': function},\n        schema=schema,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n\n\ndef with_info_before_validator_function(\n    function: WithInfoValidatorFunction,\n    schema: CoreSchema,\n    *,\n    field_name: str | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -> BeforeValidatorFunctionSchema:\n    \"\"\"\n    Returns a schema that calls a validator function before validation, the function is called with\n    an `info` argument, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    def fn(v: bytes, info: core_schema.ValidationInfo) -> str:\n        assert info.data is not None\n        assert info.field_name is not None\n        return v.decode() + 'world'\n\n    func_schema = core_schema.with_info_before_validator_function(\n        function=fn, schema=core_schema.str_schema(), field_name='a'\n    )\n    schema = core_schema.typed_dict_schema({'a': core_schema.typed_dict_field(func_schema)})\n\n    v = SchemaValidator(schema)\n    assert v.validate_python({'a': b'hello '}) == {'a': 'hello world'}\n    ```\n\n    Args:\n        function: The validator function to call\n        field_name: The name of the field\n        schema: The schema to validate the output of the validator function\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='function-before',\n        function=_dict_not_none(type='with-info', function=function, field_name=field_name),\n        schema=schema,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n\n\nclass AfterValidatorFunctionSchema(_ValidatorFunctionSchema, total=False):\n    type: Required[Literal['function-after']]\n\n\ndef no_info_after_validator_function(\n    function: NoInfoValidatorFunction,\n    schema: CoreSchema,\n    *,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -> AfterValidatorFunctionSchema:\n    \"\"\"\n    Returns a schema that calls a validator function after validating, no `info` argument is provided, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    def fn(v: str) -> str:\n        return v + 'world'\n\n    func_schema = core_schema.no_info_after_validator_function(fn, core_schema.str_schema())\n    schema = core_schema.typed_dict_schema({'a': core_schema.typed_dict_field(func_schema)})\n\n    v = SchemaValidator(schema)\n    assert v.validate_python({'a': b'hello '}) == {'a': 'hello world'}\n    ```\n\n    Args:\n        function: The validator function to call after the schema is validated\n        schema: The schema to validate before the validator function\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='function-after',\n        function={'type': 'no-info', 'function': function},\n        schema=schema,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n\n\ndef with_info_after_validator_function(\n    function: WithInfoValidatorFunction,\n    schema: CoreSchema,\n    *,\n    field_name: str | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -> AfterValidatorFunctionSchema:\n    \"\"\"\n    Returns a schema that calls a validator function after validation, the function is called with\n    an `info` argument, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    def fn(v: str, info: core_schema.ValidationInfo) -> str:\n        assert info.data is not None\n        assert info.field_name is not None\n        return v + 'world'\n\n    func_schema = core_schema.with_info_after_validator_function(\n        function=fn, schema=core_schema.str_schema(), field_name='a'\n    )\n    schema = core_schema.typed_dict_schema({'a': core_schema.typed_dict_field(func_schema)})\n\n    v = SchemaValidator(schema)\n    assert v.validate_python({'a': b'hello '}) == {'a': 'hello world'}\n    ```\n\n    Args:\n        function: The validator function to call after the schema is validated\n        schema: The schema to validate before the validator function\n        field_name: The name of the field this validators is applied to, if any\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='function-after',\n        function=_dict_not_none(type='with-info', function=function, field_name=field_name),\n        schema=schema,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n\n\nclass ValidatorFunctionWrapHandler(Protocol):\n    def __call__(self, input_value: Any, outer_location: str | int | None = None, /) -> Any:  # pragma: no cover\n        ...\n\n\n# (input_value: Any, validator: ValidatorFunctionWrapHandler, /) -> Any\nNoInfoWrapValidatorFunction = Callable[[Any, ValidatorFunctionWrapHandler], Any]\n\n\nclass NoInfoWrapValidatorFunctionSchema(TypedDict):\n    type: Literal['no-info']\n    function: NoInfoWrapValidatorFunction\n\n\n# (input_value: Any, validator: ValidatorFunctionWrapHandler, info: ValidationInfo, /) -> Any\nWithInfoWrapValidatorFunction = Callable[[Any, ValidatorFunctionWrapHandler, ValidationInfo], Any]\n\n\nclass WithInfoWrapValidatorFunctionSchema(TypedDict, total=False):\n    type: Required[Literal['with-info']]\n    function: Required[WithInfoWrapValidatorFunction]\n    field_name: str\n\n\nWrapValidatorFunction = Union[NoInfoWrapValidatorFunctionSchema, WithInfoWrapValidatorFunctionSchema]\n\n\nclass WrapValidatorFunctionSchema(TypedDict, total=False):\n    type: Required[Literal['function-wrap']]\n    function: Required[WrapValidatorFunction]\n    schema: Required[CoreSchema]\n    ref: str\n    metadata: Any\n    serialization: SerSchema\n\n\ndef no_info_wrap_validator_function(\n    function: NoInfoWrapValidatorFunction,\n    schema: CoreSchema,\n    *,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -> WrapValidatorFunctionSchema:\n    \"\"\"\n    Returns a schema which calls a function with a `validator` callable argument which can\n    optionally be used to call inner validation with the function logic, this is much like the\n    \"onion\" implementation of middleware in many popular web frameworks, no `info` argument is passed, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    def fn(\n        v: str,\n        validator: core_schema.ValidatorFunctionWrapHandler,\n    ) -> str:\n        return validator(input_value=v) + 'world'\n\n    schema = core_schema.no_info_wrap_validator_function(\n        function=fn, schema=core_schema.str_schema()\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_python('hello ') == 'hello world'\n    ```\n\n    Args:\n        function: The validator function to call\n        schema: The schema to validate the output of the validator function\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='function-wrap',\n        function={'type': 'no-info', 'function': function},\n        schema=schema,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n\n\ndef with_info_wrap_validator_function(\n    function: WithInfoWrapValidatorFunction,\n    schema: CoreSchema,\n    *,\n    field_name: str | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -> WrapValidatorFunctionSchema:\n    \"\"\"\n    Returns a schema which calls a function with a `validator` callable argument which can\n    optionally be used to call inner validation with the function logic, this is much like the\n    \"onion\" implementation of middleware in many popular web frameworks, an `info` argument is also passed, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    def fn(\n        v: str,\n        validator: core_schema.ValidatorFunctionWrapHandler,\n        info: core_schema.ValidationInfo,\n    ) -> str:\n        return validator(input_value=v) + 'world'\n\n    schema = core_schema.with_info_wrap_validator_function(\n        function=fn, schema=core_schema.str_schema()\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_python('hello ') == 'hello world'\n    ```\n\n    Args:\n        function: The validator function to call\n        schema: The schema to validate the output of the validator function\n        field_name: The name of the field this validators is applied to, if any\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='function-wrap',\n        function=_dict_not_none(type='with-info', function=function, field_name=field_name),\n        schema=schema,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n\n\nclass PlainValidatorFunctionSchema(TypedDict, total=False):\n    type: Required[Literal['function-plain']]\n    function: Required[ValidationFunction]\n    ref: str\n    metadata: Any\n    serialization: SerSchema\n\n\ndef no_info_plain_validator_function(\n    function: NoInfoValidatorFunction,\n    *,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -> PlainValidatorFunctionSchema:\n    \"\"\"\n    Returns a schema that uses the provided function for validation, no `info` argument is passed, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    def fn(v: str) -> str:\n        assert 'hello' in v\n        return v + 'world'\n\n    schema = core_schema.no_info_plain_validator_function(function=fn)\n    v = SchemaValidator(schema)\n    assert v.validate_python('hello ') == 'hello world'\n    ```\n\n    Args:\n        function: The validator function to call\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='function-plain',\n        function={'type': 'no-info', 'function': function},\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n\n\ndef with_info_plain_validator_function(\n    function: WithInfoValidatorFunction,\n    *,\n    field_name: str | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -> PlainValidatorFunctionSchema:\n    \"\"\"\n    Returns a schema that uses the provided function for validation, an `info` argument is passed, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    def fn(v: str, info: core_schema.ValidationInfo) -> str:\n        assert 'hello' in v\n        return v + 'world'\n\n    schema = core_schema.with_info_plain_validator_function(function=fn)\n    v = SchemaValidator(schema)\n    assert v.validate_python('hello ') == 'hello world'\n    ```\n\n    Args:\n        function: The validator function to call\n        field_name: The name of the field this validators is applied to, if any\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='function-plain',\n        function=_dict_not_none(type='with-info', function=function, field_name=field_name),\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n\n\nclass WithDefaultSchema(TypedDict, total=False):\n    type: Required[Literal['default']]\n    schema: Required[CoreSchema]\n    default: Any\n    default_factory: Callable[[], Any]\n    on_error: Literal['raise', 'omit', 'default']  # default: 'raise'\n    validate_default: bool  # default: False\n    strict: bool\n    ref: str\n    metadata: Any\n    serialization: SerSchema\n\n\ndef with_default_schema(\n    schema: CoreSchema,\n    *,\n    default: Any = PydanticUndefined,\n    default_factory: Callable[[], Any] | None = None,\n    on_error: Literal['raise', 'omit', 'default'] | None = None,\n    validate_default: bool | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -> WithDefaultSchema:\n    \"\"\"\n    Returns a schema that adds a default value to the given schema, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.with_default_schema(core_schema.str_schema(), default='hello')\n    wrapper_schema = core_schema.typed_dict_schema(\n        {'a': core_schema.typed_dict_field(schema)}\n    )\n    v = SchemaValidator(wrapper_schema)\n    assert v.validate_python({}) == v.validate_python({'a': 'hello'})\n    ```\n\n    Args:\n        schema: The schema to add a default value to\n        default: The default value to use\n        default_factory: A function that returns the default value to use\n        on_error: What to do if the schema validation fails. One of 'raise', 'omit', 'default'\n        validate_default: Whether the default value should be validated\n        strict: Whether the underlying schema should be validated with strict mode\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    s = _dict_not_none(\n        type='default',\n        schema=schema,\n        default_factory=default_factory,\n        on_error=on_error,\n        validate_default=validate_default,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n    if default is not PydanticUndefined:\n        s['default'] = default\n    return s\n\n\nclass NullableSchema(TypedDict, total=False):\n    type: Required[Literal['nullable']]\n    schema: Required[CoreSchema]\n    strict: bool\n    ref: str\n    metadata: Any\n    serialization: SerSchema\n\n\ndef nullable_schema(\n    schema: CoreSchema,\n    *,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -> NullableSchema:\n    \"\"\"\n    Returns a schema that matches a nullable value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.nullable_schema(core_schema.str_schema())\n    v = SchemaValidator(schema)\n    assert v.validate_python(None) is None\n    ```\n\n    Args:\n        schema: The schema to wrap\n        strict: Whether the underlying schema should be validated with strict mode\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='nullable', schema=schema, strict=strict, ref=ref, metadata=metadata, serialization=serialization\n    )\n\n\nclass UnionSchema(TypedDict, total=False):\n    type: Required[Literal['union']]\n    choices: Required[List[Union[CoreSchema, Tuple[CoreSchema, str]]]]\n    # default true, whether to automatically collapse unions with one element to the inner validator\n    auto_collapse: bool\n    custom_error_type: str\n    custom_error_message: str\n    custom_error_context: Dict[str, Union[str, int, float]]\n    mode: Literal['smart', 'left_to_right']  # default: 'smart'\n    strict: bool\n    ref: str\n    metadata: Any\n    serialization: SerSchema\n\n\ndef union_schema(\n    choices: list[CoreSchema | tuple[CoreSchema, str]],\n    *,\n    auto_collapse: bool | None = None,\n    custom_error_type: str | None = None,\n    custom_error_message: str | None = None,\n    custom_error_context: dict[str, str | int] | None = None,\n    mode: Literal['smart', 'left_to_right'] | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -> UnionSchema:\n    \"\"\"\n    Returns a schema that matches a union value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.union_schema([core_schema.str_schema(), core_schema.int_schema()])\n    v = SchemaValidator(schema)\n    assert v.validate_python('hello') == 'hello'\n    assert v.validate_python(1) == 1\n    ```\n\n    Args:\n        choices: The schemas to match. If a tuple, the second item is used as the label for the case.\n        auto_collapse: whether to automatically collapse unions with one element to the inner validator, default true\n        custom_error_type: The custom error type to use if the validation fails\n        custom_error_message: The custom error message to use if the validation fails\n        custom_error_context: The custom error context to use if the validation fails\n        mode: How to select which choice to return\n            * `smart` (default) will try to return the choice which is the closest match to the input value\n            * `left_to_right` will return the first choice in `choices` which succeeds validation\n        strict: Whether the underlying schemas should be validated with strict mode\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='union',\n        choices=choices,\n        auto_collapse=auto_collapse,\n        custom_error_type=custom_error_type,\n        custom_error_message=custom_error_message,\n        custom_error_context=custom_error_context,\n        mode=mode,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n\n\nclass TaggedUnionSchema(TypedDict, total=False):\n    type: Required[Literal['tagged-union']]\n    choices: Required[Dict[Hashable, CoreSchema]]\n    discriminator: Required[Union[str, List[Union[str, int]], List[List[Union[str, int]]], Callable[[Any], Hashable]]]\n    custom_error_type: str\n    custom_error_message: str\n    custom_error_context: Dict[str, Union[str, int, float]]\n    strict: bool\n    from_attributes: bool  # default: True\n    ref: str\n    metadata: Any\n    serialization: SerSchema\n\n\ndef tagged_union_schema(\n    choices: Dict[Any, CoreSchema],\n    discriminator: str | list[str | int] | list[list[str | int]] | Callable[[Any], Any],\n    *,\n    custom_error_type: str | None = None,\n    custom_error_message: str | None = None,\n    custom_error_context: dict[str, int | str | float] | None = None,\n    strict: bool | None = None,\n    from_attributes: bool | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -> TaggedUnionSchema:\n    \"\"\"\n    Returns a schema that matches a tagged union value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    apple_schema = core_schema.typed_dict_schema(\n        {\n            'foo': core_schema.typed_dict_field(core_schema.str_schema()),\n            'bar': core_schema.typed_dict_field(core_schema.int_schema()),\n        }\n    )\n    banana_schema = core_schema.typed_dict_schema(\n        {\n            'foo': core_schema.typed_dict_field(core_schema.str_schema()),\n            'spam': core_schema.typed_dict_field(\n                core_schema.list_schema(items_schema=core_schema.int_schema())\n            ),\n        }\n    )\n    schema = core_schema.tagged_union_schema(\n        choices={\n            'apple': apple_schema,\n            'banana': banana_schema,\n        },\n        discriminator='foo',\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_python({'foo': 'apple', 'bar': '123'}) == {'foo': 'apple', 'bar': 123}\n    assert v.validate_python({'foo': 'banana', 'spam': [1, 2, 3]}) == {\n        'foo': 'banana',\n        'spam': [1, 2, 3],\n    }\n    ```\n\n    Args:\n        choices: The schemas to match\n            When retrieving a schema from `choices` using the discriminator value, if the value is a str,\n            it should be fed back into the `choices` map until a schema is obtained\n            (This approach is to prevent multiple ownership of a single schema in Rust)\n        discriminator: The discriminator to use to determine the schema to use\n            * If `discriminator` is a str, it is the name of the attribute to use as the discriminator\n            * If `discriminator` is a list of int/str, it should be used as a \"path\" to access the discriminator\n            * If `discriminator` is a list of lists, each inner list is a path, and the first path that exists is used\n            * If `discriminator` is a callable, it should return the discriminator when called on the value to validate;\n              the callable can return `None` to indicate that there is no matching discriminator present on the input\n        custom_error_type: The custom error type to use if the validation fails\n        custom_error_message: The custom error message to use if the validation fails\n        custom_error_context: The custom error context to use if the validation fails\n        strict: Whether the underlying schemas should be validated with strict mode\n        from_attributes: Whether to use the attributes of the object to retrieve the discriminator value\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='tagged-union',\n        choices=choices,\n        discriminator=discriminator,\n        custom_error_type=custom_error_type,\n        custom_error_message=custom_error_message,\n        custom_error_context=custom_error_context,\n        strict=strict,\n        from_attributes=from_attributes,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n\n\nclass ChainSchema(TypedDict, total=False):\n    type: Required[Literal['chain']]\n    steps: Required[List[CoreSchema]]\n    ref: str\n    metadata: Any\n    serialization: SerSchema\n\n\ndef chain_schema(\n    steps: list[CoreSchema], *, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None\n) -> ChainSchema:\n    \"\"\"\n    Returns a schema that chains the provided validation schemas, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    def fn(v: str, info: core_schema.ValidationInfo) -> str:\n        assert 'hello' in v\n        return v + ' world'\n\n    fn_schema = core_schema.with_info_plain_validator_function(function=fn)\n    schema = core_schema.chain_schema(\n        [fn_schema, fn_schema, fn_schema, core_schema.str_schema()]\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_python('hello') == 'hello world world world'\n    ```\n\n    Args:\n        steps: The schemas to chain\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(type='chain', steps=steps, ref=ref, metadata=metadata, serialization=serialization)\n\n\nclass LaxOrStrictSchema(TypedDict, total=False):\n    type: Required[Literal['lax-or-strict']]\n    lax_schema: Required[CoreSchema]\n    strict_schema: Required[CoreSchema]\n    strict: bool\n    ref: str\n    metadata: Any\n    serialization: SerSchema\n\n\ndef lax_or_strict_schema(\n    lax_schema: CoreSchema,\n    strict_schema: CoreSchema,\n    *,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -> LaxOrStrictSchema:\n    \"\"\"\n    Returns a schema that uses the lax or strict schema, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    def fn(v: str, info: core_schema.ValidationInfo) -> str:\n        assert 'hello' in v\n        return v + ' world'\n\n    lax_schema = core_schema.int_schema(strict=False)\n    strict_schema = core_schema.int_schema(strict=True)\n\n    schema = core_schema.lax_or_strict_schema(\n        lax_schema=lax_schema, strict_schema=strict_schema, strict=True\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_python(123) == 123\n\n    schema = core_schema.lax_or_strict_schema(\n        lax_schema=lax_schema, strict_schema=strict_schema, strict=False\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_python('123') == 123\n    ```\n\n    Args:\n        lax_schema: The lax schema to use\n        strict_schema: The strict schema to use\n        strict: Whether the strict schema should be used\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='lax-or-strict',\n        lax_schema=lax_schema,\n        strict_schema=strict_schema,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n\n\nclass JsonOrPythonSchema(TypedDict, total=False):\n    type: Required[Literal['json-or-python']]\n    json_schema: Required[CoreSchema]\n    python_schema: Required[CoreSchema]\n    ref: str\n    metadata: Any\n    serialization: SerSchema\n\n\ndef json_or_python_schema(\n    json_schema: CoreSchema,\n    python_schema: CoreSchema,\n    *,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -> JsonOrPythonSchema:\n    \"\"\"\n    Returns a schema that uses the Json or Python schema depending on the input:\n\n    ```py\n    from pydantic_core import SchemaValidator, ValidationError, core_schema\n\n    v = SchemaValidator(\n        core_schema.json_or_python_schema(\n            json_schema=core_schema.int_schema(),\n            python_schema=core_schema.int_schema(strict=True),\n        )\n    )\n\n    assert v.validate_json('\"123\"') == 123\n\n    try:\n        v.validate_python('123')\n    except ValidationError:\n        pass\n    else:\n        raise AssertionError('Validation should have failed')\n    ```\n\n    Args:\n        json_schema: The schema to use for Json inputs\n        python_schema: The schema to use for Python inputs\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='json-or-python',\n        json_schema=json_schema,\n        python_schema=python_schema,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n\n\nclass TypedDictField(TypedDict, total=False):\n    type: Required[Literal['typed-dict-field']]\n    schema: Required[CoreSchema]\n    required: bool\n    validation_alias: Union[str, List[Union[str, int]], List[List[Union[str, int]]]]\n    serialization_alias: str\n    serialization_exclude: bool  # default: False\n    metadata: Any\n\n\ndef typed_dict_field(\n    schema: CoreSchema,\n    *,\n    required: bool | None = None,\n    validation_alias: str | list[str | int] | list[list[str | int]] | None = None,\n    serialization_alias: str | None = None,\n    serialization_exclude: bool | None = None,\n    metadata: Any = None,\n) -> TypedDictField:\n    \"\"\"\n    Returns a schema that matches a typed dict field, e.g.:\n\n    ```py\n    from pydantic_core import core_schema\n\n    field = core_schema.typed_dict_field(schema=core_schema.int_schema(), required=True)\n    ```\n\n    Args:\n        schema: The schema to use for the field\n        required: Whether the field is required\n        validation_alias: The alias(es) to use to find the field in the validation data\n        serialization_alias: The alias to use as a key when serializing\n        serialization_exclude: Whether to exclude the field when serializing\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n    \"\"\"\n    return _dict_not_none(\n        type='typed-dict-field',\n        schema=schema,\n        required=required,\n        validation_alias=validation_alias,\n        serialization_alias=serialization_alias,\n        serialization_exclude=serialization_exclude,\n        metadata=metadata,\n    )\n\n\nclass TypedDictSchema(TypedDict, total=False):\n    type: Required[Literal['typed-dict']]\n    fields: Required[Dict[str, TypedDictField]]\n    computed_fields: List[ComputedField]\n    strict: bool\n    extras_schema: CoreSchema\n    # all these values can be set via config, equivalent fields have `typed_dict_` prefix\n    extra_behavior: ExtraBehavior\n    total: bool  # default: True\n    populate_by_name: bool  # replaces `allow_population_by_field_name` in pydantic v1\n    ref: str\n    metadata: Any\n    serialization: SerSchema\n    config: CoreConfig\n\n\ndef typed_dict_schema(\n    fields: Dict[str, TypedDictField],\n    *,\n    computed_fields: list[ComputedField] | None = None,\n    strict: bool | None = None,\n    extras_schema: CoreSchema | None = None,\n    extra_behavior: ExtraBehavior | None = None,\n    total: bool | None = None,\n    populate_by_name: bool | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n    config: CoreConfig | None = None,\n) -> TypedDictSchema:\n    \"\"\"\n    Returns a schema that matches a typed dict, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    wrapper_schema = core_schema.typed_dict_schema(\n        {'a': core_schema.typed_dict_field(core_schema.str_schema())}\n    )\n    v = SchemaValidator(wrapper_schema)\n    assert v.validate_python({'a': 'hello'}) == {'a': 'hello'}\n    ```\n\n    Args:\n        fields: The fields to use for the typed dict\n        computed_fields: Computed fields to use when serializing the model, only applies when directly inside a model\n        strict: Whether the typed dict is strict\n        extras_schema: The extra validator to use for the typed dict\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        extra_behavior: The extra behavior to use for the typed dict\n        total: Whether the typed dict is total\n        populate_by_name: Whether the typed dict should populate by name\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='typed-dict',\n        fields=fields,\n        computed_fields=computed_fields,\n        strict=strict,\n        extras_schema=extras_schema,\n        extra_behavior=extra_behavior,\n        total=total,\n        populate_by_name=populate_by_name,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n        config=config,\n    )\n\n\nclass ModelField(TypedDict, total=False):\n    type: Required[Literal['model-field']]\n    schema: Required[CoreSchema]\n    validation_alias: Union[str, List[Union[str, int]], List[List[Union[str, int]]]]\n    serialization_alias: str\n    serialization_exclude: bool  # default: False\n    frozen: bool\n    metadata: Any\n\n\ndef model_field(\n    schema: CoreSchema,\n    *,\n    validation_alias: str | list[str | int] | list[list[str | int]] | None = None,\n    serialization_alias: str | None = None,\n    serialization_exclude: bool | None = None,\n    frozen: bool | None = None,\n    metadata: Any = None,\n) -> ModelField:\n    \"\"\"\n    Returns a schema for a model field, e.g.:\n\n    ```py\n    from pydantic_core import core_schema\n\n    field = core_schema.model_field(schema=core_schema.int_schema())\n    ```\n\n    Args:\n        schema: The schema to use for the field\n        validation_alias: The alias(es) to use to find the field in the validation data\n        serialization_alias: The alias to use as a key when serializing\n        serialization_exclude: Whether to exclude the field when serializing\n        frozen: Whether the field is frozen\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n    \"\"\"\n    return _dict_not_none(\n        type='model-field',\n        schema=schema,\n        validation_alias=validation_alias,\n        serialization_alias=serialization_alias,\n        serialization_exclude=serialization_exclude,\n        frozen=frozen,\n        metadata=metadata,\n    )\n\n\nclass ModelFieldsSchema(TypedDict, total=False):\n    type: Required[Literal['model-fields']]\n    fields: Required[Dict[str, ModelField]]\n    model_name: str\n    computed_fields: List[ComputedField]\n    strict: bool\n    extras_schema: CoreSchema\n    # all these values can be set via config, equivalent fields have `typed_dict_` prefix\n    extra_behavior: ExtraBehavior\n    populate_by_name: bool  # replaces `allow_population_by_field_name` in pydantic v1\n    from_attributes: bool\n    ref: str\n    metadata: Any\n    serialization: SerSchema\n\n\ndef model_fields_schema(\n    fields: Dict[str, ModelField],\n    *,\n    model_name: str | None = None,\n    computed_fields: list[ComputedField] | None = None,\n    strict: bool | None = None,\n    extras_schema: CoreSchema | None = None,\n    extra_behavior: ExtraBehavior | None = None,\n    populate_by_name: bool | None = None,\n    from_attributes: bool | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -> ModelFieldsSchema:\n    \"\"\"\n    Returns a schema that matches a typed dict, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    wrapper_schema = core_schema.model_fields_schema(\n        {'a': core_schema.model_field(core_schema.str_schema())}\n    )\n    v = SchemaValidator(wrapper_schema)\n    print(v.validate_python({'a': 'hello'}))\n    #> ({'a': 'hello'}, None, {'a'})\n    ```\n\n    Args:\n        fields: The fields to use for the typed dict\n        model_name: The name of the model, used for error messages, defaults to \"Model\"\n        computed_fields: Computed fields to use when serializing the model, only applies when directly inside a model\n        strict: Whether the typed dict is strict\n        extras_schema: The extra validator to use for the typed dict\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        extra_behavior: The extra behavior to use for the typed dict\n        populate_by_name: Whether the typed dict should populate by name\n        from_attributes: Whether the typed dict should be populated from attributes\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='model-fields',\n        fields=fields,\n        model_name=model_name,\n        computed_fields=computed_fields,\n        strict=strict,\n        extras_schema=extras_schema,\n        extra_behavior=extra_behavior,\n        populate_by_name=populate_by_name,\n        from_attributes=from_attributes,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n\n\nclass ModelSchema(TypedDict, total=False):\n    type: Required[Literal['model']]\n    cls: Required[Type[Any]]\n    schema: Required[CoreSchema]\n    custom_init: bool\n    root_model: bool\n    post_init: str\n    revalidate_instances: Literal['always', 'never', 'subclass-instances']  # default: 'never'\n    strict: bool\n    frozen: bool\n    extra_behavior: ExtraBehavior\n    config: CoreConfig\n    ref: str\n    metadata: Any\n    serialization: SerSchema\n\n\ndef model_schema(\n    cls: Type[Any],\n    schema: CoreSchema,\n    *,\n    custom_init: bool | None = None,\n    root_model: bool | None = None,\n    post_init: str | None = None,\n    revalidate_instances: Literal['always', 'never', 'subclass-instances'] | None = None,\n    strict: bool | None = None,\n    frozen: bool | None = None,\n    extra_behavior: ExtraBehavior | None = None,\n    config: CoreConfig | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -> ModelSchema:\n    \"\"\"\n    A model schema generally contains a typed-dict schema.\n    It will run the typed dict validator, then create a new class\n    and set the dict and fields set returned from the typed dict validator\n    to `__dict__` and `__pydantic_fields_set__` respectively.\n\n    Example:\n\n    ```py\n    from pydantic_core import CoreConfig, SchemaValidator, core_schema\n\n    class MyModel:\n        __slots__ = (\n            '__dict__',\n            '__pydantic_fields_set__',\n            '__pydantic_extra__',\n            '__pydantic_private__',\n        )\n\n    schema = core_schema.model_schema(\n        cls=MyModel,\n        config=CoreConfig(str_max_length=5),\n        schema=core_schema.model_fields_schema(\n            fields={'a': core_schema.model_field(core_schema.str_schema())},\n        ),\n    )\n    v = SchemaValidator(schema)\n    assert v.isinstance_python({'a': 'hello'}) is True\n    assert v.isinstance_python({'a': 'too long'}) is False\n    ```\n\n    Args:\n        cls: The class to use for the model\n        schema: The schema to use for the model\n        custom_init: Whether the model has a custom init method\n        root_model: Whether the model is a `RootModel`\n        post_init: The call after init to use for the model\n        revalidate_instances: whether instances of models and dataclasses (including subclass instances)\n            should re-validate defaults to config.revalidate_instances, else 'never'\n        strict: Whether the model is strict\n        frozen: Whether the model is frozen\n        extra_behavior: The extra behavior to use for the model, used in serialization\n        config: The config to use for the model\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='model',\n        cls=cls,\n        schema=schema,\n        custom_init=custom_init,\n        root_model=root_model,\n        post_init=post_init,\n        revalidate_instances=revalidate_instances,\n        strict=strict,\n        frozen=frozen,\n        extra_behavior=extra_behavior,\n        config=config,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n\n\nclass DataclassField(TypedDict, total=False):\n    type: Required[Literal['dataclass-field']]\n    name: Required[str]\n    schema: Required[CoreSchema]\n    kw_only: bool  # default: True\n    init: bool  # default: True\n    init_only: bool  # default: False\n    frozen: bool  # default: False\n    validation_alias: Union[str, List[Union[str, int]], List[List[Union[str, int]]]]\n    serialization_alias: str\n    serialization_exclude: bool  # default: False\n    metadata: Any\n\n\ndef dataclass_field(\n    name: str,\n    schema: CoreSchema,\n    *,\n    kw_only: bool | None = None,\n    init: bool | None = None,\n    init_only: bool | None = None,\n    validation_alias: str | list[str | int] | list[list[str | int]] | None = None,\n    serialization_alias: str | None = None,\n    serialization_exclude: bool | None = None,\n    metadata: Any = None,\n    frozen: bool | None = None,\n) -> DataclassField:\n    \"\"\"\n    Returns a schema for a dataclass field, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    field = core_schema.dataclass_field(\n        name='a', schema=core_schema.str_schema(), kw_only=False\n    )\n    schema = core_schema.dataclass_args_schema('Foobar', [field])\n    v = SchemaValidator(schema)\n    assert v.validate_python({'a': 'hello'}) == ({'a': 'hello'}, None)\n    ```\n\n    Args:\n        name: The name to use for the argument parameter\n        schema: The schema to use for the argument parameter\n        kw_only: Whether the field can be set with a positional argument as well as a keyword argument\n        init: Whether the field should be validated during initialization\n        init_only: Whether the field should be omitted  from `__dict__` and passed to `__post_init__`\n        validation_alias: The alias(es) to use to find the field in the validation data\n        serialization_alias: The alias to use as a key when serializing\n        serialization_exclude: Whether to exclude the field when serializing\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        frozen: Whether the field is frozen\n    \"\"\"\n    return _dict_not_none(\n        type='dataclass-field',\n        name=name,\n        schema=schema,\n        kw_only=kw_only,\n        init=init,\n        init_only=init_only,\n        validation_alias=validation_alias,\n        serialization_alias=serialization_alias,\n        serialization_exclude=serialization_exclude,\n        metadata=metadata,\n        frozen=frozen,\n    )\n\n\nclass DataclassArgsSchema(TypedDict, total=False):\n    type: Required[Literal['dataclass-args']]\n    dataclass_name: Required[str]\n    fields: Required[List[DataclassField]]\n    computed_fields: List[ComputedField]\n    populate_by_name: bool  # default: False\n    collect_init_only: bool  # default: False\n    ref: str\n    metadata: Any\n    serialization: SerSchema\n    extra_behavior: ExtraBehavior\n\n\ndef dataclass_args_schema(\n    dataclass_name: str,\n    fields: list[DataclassField],\n    *,\n    computed_fields: List[ComputedField] | None = None,\n    populate_by_name: bool | None = None,\n    collect_init_only: bool | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n    extra_behavior: ExtraBehavior | None = None,\n) -> DataclassArgsSchema:\n    \"\"\"\n    Returns a schema for validating dataclass arguments, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    field_a = core_schema.dataclass_field(\n        name='a', schema=core_schema.str_schema(), kw_only=False\n    )\n    field_b = core_schema.dataclass_field(\n        name='b', schema=core_schema.bool_schema(), kw_only=False\n    )\n    schema = core_schema.dataclass_args_schema('Foobar', [field_a, field_b])\n    v = SchemaValidator(schema)\n    assert v.validate_python({'a': 'hello', 'b': True}) == ({'a': 'hello', 'b': True}, None)\n    ```\n\n    Args:\n        dataclass_name: The name of the dataclass being validated\n        fields: The fields to use for the dataclass\n        computed_fields: Computed fields to use when serializing the dataclass\n        populate_by_name: Whether to populate by name\n        collect_init_only: Whether to collect init only fields into a dict to pass to `__post_init__`\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n        extra_behavior: How to handle extra fields\n    \"\"\"\n    return _dict_not_none(\n        type='dataclass-args',\n        dataclass_name=dataclass_name,\n        fields=fields,\n        computed_fields=computed_fields,\n        populate_by_name=populate_by_name,\n        collect_init_only=collect_init_only,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n        extra_behavior=extra_behavior,\n    )\n\n\nclass DataclassSchema(TypedDict, total=False):\n    type: Required[Literal['dataclass']]\n    cls: Required[Type[Any]]\n    schema: Required[CoreSchema]\n    fields: Required[List[str]]\n    cls_name: str\n    post_init: bool  # default: False\n    revalidate_instances: Literal['always', 'never', 'subclass-instances']  # default: 'never'\n    strict: bool  # default: False\n    frozen: bool  # default False\n    ref: str\n    metadata: Any\n    serialization: SerSchema\n    slots: bool\n    config: CoreConfig\n\n\ndef dataclass_schema(\n    cls: Type[Any],\n    schema: CoreSchema,\n    fields: List[str],\n    *,\n    cls_name: str | None = None,\n    post_init: bool | None = None,\n    revalidate_instances: Literal['always', 'never', 'subclass-instances'] | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n    frozen: bool | None = None,\n    slots: bool | None = None,\n    config: CoreConfig | None = None,\n) -> DataclassSchema:\n    \"\"\"\n    Returns a schema for a dataclass. As with `ModelSchema`, this schema can only be used as a field within\n    another schema, not as the root type.\n\n    Args:\n        cls: The dataclass type, used to perform subclass checks\n        schema: The schema to use for the dataclass fields\n        fields: Fields of the dataclass, this is used in serialization and in validation during re-validation\n            and while validating assignment\n        cls_name: The name to use in error locs, etc; this is useful for generics (default: `cls.__name__`)\n        post_init: Whether to call `__post_init__` after validation\n        revalidate_instances: whether instances of models and dataclasses (including subclass instances)\n            should re-validate defaults to config.revalidate_instances, else 'never'\n        strict: Whether to require an exact instance of `cls`\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n        frozen: Whether the dataclass is frozen\n        slots: Whether `slots=True` on the dataclass, means each field is assigned independently, rather than\n            simply setting `__dict__`, default false\n    \"\"\"\n    return _dict_not_none(\n        type='dataclass',\n        cls=cls,\n        fields=fields,\n        cls_name=cls_name,\n        schema=schema,\n        post_init=post_init,\n        revalidate_instances=revalidate_instances,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n        frozen=frozen,\n        slots=slots,\n        config=config,\n    )\n\n\nclass ArgumentsParameter(TypedDict, total=False):\n    name: Required[str]\n    schema: Required[CoreSchema]\n    mode: Literal['positional_only', 'positional_or_keyword', 'keyword_only']  # default positional_or_keyword\n    alias: Union[str, List[Union[str, int]], List[List[Union[str, int]]]]\n\n\ndef arguments_parameter(\n    name: str,\n    schema: CoreSchema,\n    *,\n    mode: Literal['positional_only', 'positional_or_keyword', 'keyword_only'] | None = None,\n    alias: str | list[str | int] | list[list[str | int]] | None = None,\n) -> ArgumentsParameter:\n    \"\"\"\n    Returns a schema that matches an argument parameter, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    param = core_schema.arguments_parameter(\n        name='a', schema=core_schema.str_schema(), mode='positional_only'\n    )\n    schema = core_schema.arguments_schema([param])\n    v = SchemaValidator(schema)\n    assert v.validate_python(('hello',)) == (('hello',), {})\n    ```\n\n    Args:\n        name: The name to use for the argument parameter\n        schema: The schema to use for the argument parameter\n        mode: The mode to use for the argument parameter\n        alias: The alias to use for the argument parameter\n    \"\"\"\n    return _dict_not_none(name=name, schema=schema, mode=mode, alias=alias)\n\n\nclass ArgumentsSchema(TypedDict, total=False):\n    type: Required[Literal['arguments']]\n    arguments_schema: Required[List[ArgumentsParameter]]\n    populate_by_name: bool\n    var_args_schema: CoreSchema\n    var_kwargs_schema: CoreSchema\n    ref: str\n    metadata: Any\n    serialization: SerSchema\n\n\ndef arguments_schema(\n    arguments: list[ArgumentsParameter],\n    *,\n    populate_by_name: bool | None = None,\n    var_args_schema: CoreSchema | None = None,\n    var_kwargs_schema: CoreSchema | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -> ArgumentsSchema:\n    \"\"\"\n    Returns a schema that matches an arguments schema, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    param_a = core_schema.arguments_parameter(\n        name='a', schema=core_schema.str_schema(), mode='positional_only'\n    )\n    param_b = core_schema.arguments_parameter(\n        name='b', schema=core_schema.bool_schema(), mode='positional_only'\n    )\n    schema = core_schema.arguments_schema([param_a, param_b])\n    v = SchemaValidator(schema)\n    assert v.validate_python(('hello', True)) == (('hello', True), {})\n    ```\n\n    Args:\n        arguments: The arguments to use for the arguments schema\n        populate_by_name: Whether to populate by name\n        var_args_schema: The variable args schema to use for the arguments schema\n        var_kwargs_schema: The variable kwargs schema to use for the arguments schema\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='arguments',\n        arguments_schema=arguments,\n        populate_by_name=populate_by_name,\n        var_args_schema=var_args_schema,\n        var_kwargs_schema=var_kwargs_schema,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n\n\nclass CallSchema(TypedDict, total=False):\n    type: Required[Literal['call']]\n    arguments_schema: Required[CoreSchema]\n    function: Required[Callable[..., Any]]\n    function_name: str  # default function.__name__\n    return_schema: CoreSchema\n    ref: str\n    metadata: Any\n    serialization: SerSchema\n\n\ndef call_schema(\n    arguments: CoreSchema,\n    function: Callable[..., Any],\n    *,\n    function_name: str | None = None,\n    return_schema: CoreSchema | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -> CallSchema:\n    \"\"\"\n    Returns a schema that matches an arguments schema, then calls a function, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    param_a = core_schema.arguments_parameter(\n        name='a', schema=core_schema.str_schema(), mode='positional_only'\n    )\n    param_b = core_schema.arguments_parameter(\n        name='b', schema=core_schema.bool_schema(), mode='positional_only'\n    )\n    args_schema = core_schema.arguments_schema([param_a, param_b])\n\n    schema = core_schema.call_schema(\n        arguments=args_schema,\n        function=lambda a, b: a + str(not b),\n        return_schema=core_schema.str_schema(),\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_python((('hello', True))) == 'helloFalse'\n    ```\n\n    Args:\n        arguments: The arguments to use for the arguments schema\n        function: The function to use for the call schema\n        function_name: The function name to use for the call schema, if not provided `function.__name__` is used\n        return_schema: The return schema to use for the call schema\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='call',\n        arguments_schema=arguments,\n        function=function,\n        function_name=function_name,\n        return_schema=return_schema,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n\n\nclass CustomErrorSchema(TypedDict, total=False):\n    type: Required[Literal['custom-error']]\n    schema: Required[CoreSchema]\n    custom_error_type: Required[str]\n    custom_error_message: str\n    custom_error_context: Dict[str, Union[str, int, float]]\n    ref: str\n    metadata: Any\n    serialization: SerSchema\n\n\ndef custom_error_schema(\n    schema: CoreSchema,\n    custom_error_type: str,\n    *,\n    custom_error_message: str | None = None,\n    custom_error_context: dict[str, Any] | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -> CustomErrorSchema:\n    \"\"\"\n    Returns a schema that matches a custom error value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.custom_error_schema(\n        schema=core_schema.int_schema(),\n        custom_error_type='MyError',\n        custom_error_message='Error msg',\n    )\n    v = SchemaValidator(schema)\n    v.validate_python(1)\n    ```\n\n    Args:\n        schema: The schema to use for the custom error schema\n        custom_error_type: The custom error type to use for the custom error schema\n        custom_error_message: The custom error message to use for the custom error schema\n        custom_error_context: The custom error context to use for the custom error schema\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='custom-error',\n        schema=schema,\n        custom_error_type=custom_error_type,\n        custom_error_message=custom_error_message,\n        custom_error_context=custom_error_context,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n\n\nclass JsonSchema(TypedDict, total=False):\n    type: Required[Literal['json']]\n    schema: CoreSchema\n    ref: str\n    metadata: Any\n    serialization: SerSchema\n\n\ndef json_schema(\n    schema: CoreSchema | None = None,\n    *,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -> JsonSchema:\n    \"\"\"\n    Returns a schema that matches a JSON value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    dict_schema = core_schema.model_fields_schema(\n        {\n            'field_a': core_schema.model_field(core_schema.str_schema()),\n            'field_b': core_schema.model_field(core_schema.bool_schema()),\n        },\n    )\n\n    class MyModel:\n        __slots__ = (\n            '__dict__',\n            '__pydantic_fields_set__',\n            '__pydantic_extra__',\n            '__pydantic_private__',\n        )\n        field_a: str\n        field_b: bool\n\n    json_schema = core_schema.json_schema(schema=dict_schema)\n    schema = core_schema.model_schema(cls=MyModel, schema=json_schema)\n    v = SchemaValidator(schema)\n    m = v.validate_python('{\"field_a\": \"hello\", \"field_b\": true}')\n    assert isinstance(m, MyModel)\n    ```\n\n    Args:\n        schema: The schema to use for the JSON schema\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(type='json', schema=schema, ref=ref, metadata=metadata, serialization=serialization)\n\n\nclass UrlSchema(TypedDict, total=False):\n    type: Required[Literal['url']]\n    max_length: int\n    allowed_schemes: List[str]\n    host_required: bool  # default False\n    default_host: str\n    default_port: int\n    default_path: str\n    strict: bool\n    ref: str\n    metadata: Any\n    serialization: SerSchema\n\n\ndef url_schema(\n    *,\n    max_length: int | None = None,\n    allowed_schemes: list[str] | None = None,\n    host_required: bool | None = None,\n    default_host: str | None = None,\n    default_port: int | None = None,\n    default_path: str | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -> UrlSchema:\n    \"\"\"\n    Returns a schema that matches a URL value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.url_schema()\n    v = SchemaValidator(schema)\n    print(v.validate_python('https://example.com'))\n    #> https://example.com/\n    ```\n\n    Args:\n        max_length: The maximum length of the URL\n        allowed_schemes: The allowed URL schemes\n        host_required: Whether the URL must have a host\n        default_host: The default host to use if the URL does not have a host\n        default_port: The default port to use if the URL does not have a port\n        default_path: The default path to use if the URL does not have a path\n        strict: Whether to use strict URL parsing\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='url',\n        max_length=max_length,\n        allowed_schemes=allowed_schemes,\n        host_required=host_required,\n        default_host=default_host,\n        default_port=default_port,\n        default_path=default_path,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n\n\nclass MultiHostUrlSchema(TypedDict, total=False):\n    type: Required[Literal['multi-host-url']]\n    max_length: int\n    allowed_schemes: List[str]\n    host_required: bool  # default False\n    default_host: str\n    default_port: int\n    default_path: str\n    strict: bool\n    ref: str\n    metadata: Any\n    serialization: SerSchema\n\n\ndef multi_host_url_schema(\n    *,\n    max_length: int | None = None,\n    allowed_schemes: list[str] | None = None,\n    host_required: bool | None = None,\n    default_host: str | None = None,\n    default_port: int | None = None,\n    default_path: str | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -> MultiHostUrlSchema:\n    \"\"\"\n    Returns a schema that matches a URL value with possibly multiple hosts, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.multi_host_url_schema()\n    v = SchemaValidator(schema)\n    print(v.validate_python('redis://localhost,0.0.0.0,127.0.0.1'))\n    #> redis://localhost,0.0.0.0,127.0.0.1\n    ```\n\n    Args:\n        max_length: The maximum length of the URL\n        allowed_schemes: The allowed URL schemes\n        host_required: Whether the URL must have a host\n        default_host: The default host to use if the URL does not have a host\n        default_port: The default port to use if the URL does not have a port\n        default_path: The default path to use if the URL does not have a path\n        strict: Whether to use strict URL parsing\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='multi-host-url',\n        max_length=max_length,\n        allowed_schemes=allowed_schemes,\n        host_required=host_required,\n        default_host=default_host,\n        default_port=default_port,\n        default_path=default_path,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n\n\nclass DefinitionsSchema(TypedDict, total=False):\n    type: Required[Literal['definitions']]\n    schema: Required[CoreSchema]\n    definitions: Required[List[CoreSchema]]\n    metadata: Any\n    serialization: SerSchema\n\n\ndef definitions_schema(schema: CoreSchema, definitions: list[CoreSchema]) -> DefinitionsSchema:\n    \"\"\"\n    Build a schema that contains both an inner schema and a list of definitions which can be used\n    within the inner schema.\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.definitions_schema(\n        core_schema.list_schema(core_schema.definition_reference_schema('foobar')),\n        [core_schema.int_schema(ref='foobar')],\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_python([1, 2, '3']) == [1, 2, 3]\n    ```\n\n    Args:\n        schema: The inner schema\n        definitions: List of definitions which can be referenced within inner schema\n    \"\"\"\n    return DefinitionsSchema(type='definitions', schema=schema, definitions=definitions)\n\n\nclass DefinitionReferenceSchema(TypedDict, total=False):\n    type: Required[Literal['definition-ref']]\n    schema_ref: Required[str]\n    ref: str\n    metadata: Any\n    serialization: SerSchema\n\n\ndef definition_reference_schema(\n    schema_ref: str, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None\n) -> DefinitionReferenceSchema:\n    \"\"\"\n    Returns a schema that points to a schema stored in \"definitions\", this is useful for nested recursive\n    models and also when you want to define validators separately from the main schema, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema_definition = core_schema.definition_reference_schema('list-schema')\n    schema = core_schema.definitions_schema(\n        schema=schema_definition,\n        definitions=[\n            core_schema.list_schema(items_schema=schema_definition, ref='list-schema'),\n        ],\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_python([()]) == [[]]\n    ```\n\n    Args:\n        schema_ref: The schema ref to use for the definition reference schema\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='definition-ref', schema_ref=schema_ref, ref=ref, metadata=metadata, serialization=serialization\n    )\n\n\nMYPY = False\n# See https://github.com/python/mypy/issues/14034 for details, in summary mypy is extremely slow to process this\n# union which kills performance not just for pydantic, but even for code using pydantic\nif not MYPY:\n    CoreSchema = Union[\n        AnySchema,\n        NoneSchema,\n        BoolSchema,\n        IntSchema,\n        FloatSchema,\n        DecimalSchema,\n        StringSchema,\n        BytesSchema,\n        DateSchema,\n        TimeSchema,\n        DatetimeSchema,\n        TimedeltaSchema,\n        LiteralSchema,\n        EnumSchema,\n        IsInstanceSchema,\n        IsSubclassSchema,\n        CallableSchema,\n        ListSchema,\n        TupleSchema,\n        SetSchema,\n        FrozenSetSchema,\n        GeneratorSchema,\n        DictSchema,\n        AfterValidatorFunctionSchema,\n        BeforeValidatorFunctionSchema,\n        WrapValidatorFunctionSchema,\n        PlainValidatorFunctionSchema,\n        WithDefaultSchema,\n        NullableSchema,\n        UnionSchema,\n        TaggedUnionSchema,\n        ChainSchema,\n        LaxOrStrictSchema,\n        JsonOrPythonSchema,\n        TypedDictSchema,\n        ModelFieldsSchema,\n        ModelSchema,\n        DataclassArgsSchema,\n        DataclassSchema,\n        ArgumentsSchema,\n        CallSchema,\n        CustomErrorSchema,\n        JsonSchema,\n        UrlSchema,\n        MultiHostUrlSchema,\n        DefinitionsSchema,\n        DefinitionReferenceSchema,\n        UuidSchema,\n    ]\nelif False:\n    CoreSchema: TypeAlias = Mapping[str, Any]\n\n\n# to update this, call `pytest -k test_core_schema_type_literal` and copy the output\nCoreSchemaType = Literal[\n    'any',\n    'none',\n    'bool',\n    'int',\n    'float',\n    'decimal',\n    'str',\n    'bytes',\n    'date',\n    'time',\n    'datetime',\n    'timedelta',\n    'literal',\n    'enum',\n    'is-instance',\n    'is-subclass',\n    'callable',\n    'list',\n    'tuple',\n    'set',\n    'frozenset',\n    'generator',\n    'dict',\n    'function-after',\n    'function-before',\n    'function-wrap',\n    'function-plain',\n    'default',\n    'nullable',\n    'union',\n    'tagged-union',\n    'chain',\n    'lax-or-strict',\n    'json-or-python',\n    'typed-dict',\n    'model-fields',\n    'model',\n    'dataclass-args',\n    'dataclass',\n    'arguments',\n    'call',\n    'custom-error',\n    'json',\n    'url',\n    'multi-host-url',\n    'definitions',\n    'definition-ref',\n    'uuid',\n]\n\nCoreSchemaFieldType = Literal['model-field', 'dataclass-field', 'typed-dict-field', 'computed-field']\n\n\n# used in _pydantic_core.pyi::PydanticKnownError\n# to update this, call `pytest -k test_all_errors` and copy the output\nErrorType = Literal[\n    'no_such_attribute',\n    'json_invalid',\n    'json_type',\n    'recursion_loop',\n    'missing',\n    'frozen_field',\n    'frozen_instance',\n    'extra_forbidden',\n    'invalid_key',\n    'get_attribute_error',\n    'model_type',\n    'model_attributes_type',\n    'dataclass_type',\n    'dataclass_exact_type',\n    'none_required',\n    'greater_than',\n    'greater_than_equal',\n    'less_than',\n    'less_than_equal',\n    'multiple_of',\n    'finite_number',\n    'too_short',\n    'too_long',\n    'iterable_type',\n    'iteration_error',\n    'string_type',\n    'string_sub_type',\n    'string_unicode',\n    'string_too_short',\n    'string_too_long',\n    'string_pattern_mismatch',\n    'enum',\n    'dict_type',\n    'mapping_type',\n    'list_type',\n    'tuple_type',\n    'set_type',\n    'bool_type',\n    'bool_parsing',\n    'int_type',\n    'int_parsing',\n    'int_parsing_size',\n    'int_from_float',\n    'float_type',\n    'float_parsing',\n    'bytes_type',\n    'bytes_too_short',\n    'bytes_too_long',\n    'value_error',\n    'assertion_error',\n    'literal_error',\n    'date_type',\n    'date_parsing',\n    'date_from_datetime_parsing',\n    'date_from_datetime_inexact',\n    'date_past',\n    'date_future',\n    'time_type',\n    'time_parsing',\n    'datetime_type',\n    'datetime_parsing',\n    'datetime_object_invalid',\n    'datetime_from_date_parsing',\n    'datetime_past',\n    'datetime_future',\n    'timezone_naive',\n    'timezone_aware',\n    'timezone_offset',\n    'time_delta_type',\n    'time_delta_parsing',\n    'frozen_set_type',\n    'is_instance_of',\n    'is_subclass_of',\n    'callable_type',\n    'union_tag_invalid',\n    'union_tag_not_found',\n    'arguments_type',\n    'missing_argument',\n    'unexpected_keyword_argument',\n    'missing_keyword_only_argument',\n    'unexpected_positional_argument',\n    'missing_positional_only_argument',\n    'multiple_argument_values',\n    'url_type',\n    'url_parsing',\n    'url_syntax_violation',\n    'url_too_long',\n    'url_scheme',\n    'uuid_type',\n    'uuid_parsing',\n    'uuid_version',\n    'decimal_type',\n    'decimal_parsing',\n    'decimal_max_digits',\n    'decimal_max_places',\n    'decimal_whole_digits',\n]\n\n\ndef _dict_not_none(**kwargs: Any) -> Any:\n    return {k: v for k, v in kwargs.items() if v is not None}\n\n\n###############################################################################\n# All this stuff is deprecated by #980 and will be removed eventually\n# They're kept because some code external code will be using them\n\n\n@deprecated('`field_before_validator_function` is deprecated, use `with_info_before_validator_function` instead.')\ndef field_before_validator_function(function: WithInfoValidatorFunction, field_name: str, schema: CoreSchema, **kwargs):\n    warnings.warn(\n        '`field_before_validator_function` is deprecated, use `with_info_before_validator_function` instead.',\n        DeprecationWarning,\n    )\n    return with_info_before_validator_function(function, schema, field_name=field_name, **kwargs)\n\n\n@deprecated('`general_before_validator_function` is deprecated, use `with_info_before_validator_function` instead.')\ndef general_before_validator_function(*args, **kwargs):\n    warnings.warn(\n        '`general_before_validator_function` is deprecated, use `with_info_before_validator_function` instead.',\n        DeprecationWarning,\n    )\n    return with_info_before_validator_function(*args, **kwargs)\n\n\n@deprecated('`field_after_validator_function` is deprecated, use `with_info_after_validator_function` instead.')\ndef field_after_validator_function(function: WithInfoValidatorFunction, field_name: str, schema: CoreSchema, **kwargs):\n    warnings.warn(\n        '`field_after_validator_function` is deprecated, use `with_info_after_validator_function` instead.',\n        DeprecationWarning,\n    )\n    return with_info_after_validator_function(function, schema, field_name=field_name, **kwargs)\n\n\n@deprecated('`general_after_validator_function` is deprecated, use `with_info_after_validator_function` instead.')\ndef general_after_validator_function(*args, **kwargs):\n    warnings.warn(\n        '`general_after_validator_function` is deprecated, use `with_info_after_validator_function` instead.',\n        DeprecationWarning,\n    )\n    return with_info_after_validator_function(*args, **kwargs)\n\n\n@deprecated('`field_wrap_validator_function` is deprecated, use `with_info_wrap_validator_function` instead.')\ndef field_wrap_validator_function(\n    function: WithInfoWrapValidatorFunction, field_name: str, schema: CoreSchema, **kwargs\n):\n    warnings.warn(\n        '`field_wrap_validator_function` is deprecated, use `with_info_wrap_validator_function` instead.',\n        DeprecationWarning,\n    )\n    return with_info_wrap_validator_function(function, schema, field_name=field_name, **kwargs)\n\n\n@deprecated('`general_wrap_validator_function` is deprecated, use `with_info_wrap_validator_function` instead.')\ndef general_wrap_validator_function(*args, **kwargs):\n    warnings.warn(\n        '`general_wrap_validator_function` is deprecated, use `with_info_wrap_validator_function` instead.',\n        DeprecationWarning,\n    )\n    return with_info_wrap_validator_function(*args, **kwargs)\n\n\n@deprecated('`field_plain_validator_function` is deprecated, use `with_info_plain_validator_function` instead.')\ndef field_plain_validator_function(function: WithInfoValidatorFunction, field_name: str, **kwargs):\n    warnings.warn(\n        '`field_plain_validator_function` is deprecated, use `with_info_plain_validator_function` instead.',\n        DeprecationWarning,\n    )\n    return with_info_plain_validator_function(function, field_name=field_name, **kwargs)\n\n\n@deprecated('`general_plain_validator_function` is deprecated, use `with_info_plain_validator_function` instead.')\ndef general_plain_validator_function(*args, **kwargs):\n    warnings.warn(\n        '`general_plain_validator_function` is deprecated, use `with_info_plain_validator_function` instead.',\n        DeprecationWarning,\n    )\n    return with_info_plain_validator_function(*args, **kwargs)\n\n\n_deprecated_import_lookup = {\n    'FieldValidationInfo': ValidationInfo,\n    'FieldValidatorFunction': WithInfoValidatorFunction,\n    'GeneralValidatorFunction': WithInfoValidatorFunction,\n    'FieldWrapValidatorFunction': WithInfoWrapValidatorFunction,\n}\n\nif TYPE_CHECKING:\n    FieldValidationInfo = ValidationInfo\n\n\ndef __getattr__(attr_name: str) -> object:\n    new_attr = _deprecated_import_lookup.get(attr_name)\n    if new_attr is None:\n        raise AttributeError(f\"module 'pydantic_core' has no attribute '{attr_name}'\")\n    else:\n        import warnings\n\n        msg = f'`{attr_name}` is deprecated, use `{new_attr.__name__}` instead.'\n        warnings.warn(msg, DeprecationWarning, stacklevel=1)\n        return new_attr\n", "python/pydantic_core/__init__.py": "from __future__ import annotations\n\nimport sys as _sys\nfrom typing import Any as _Any\n\nfrom ._pydantic_core import (\n    ArgsKwargs,\n    MultiHostUrl,\n    PydanticCustomError,\n    PydanticKnownError,\n    PydanticOmit,\n    PydanticSerializationError,\n    PydanticSerializationUnexpectedValue,\n    PydanticUndefined,\n    PydanticUndefinedType,\n    PydanticUseDefault,\n    SchemaError,\n    SchemaSerializer,\n    SchemaValidator,\n    Some,\n    TzInfo,\n    Url,\n    ValidationError,\n    __version__,\n    from_json,\n    to_json,\n    to_jsonable_python,\n    validate_core_schema,\n)\nfrom .core_schema import CoreConfig, CoreSchema, CoreSchemaType, ErrorType\n\nif _sys.version_info < (3, 11):\n    from typing_extensions import NotRequired as _NotRequired\nelse:\n    from typing import NotRequired as _NotRequired\n\nif _sys.version_info < (3, 9):\n    from typing_extensions import TypedDict as _TypedDict\nelse:\n    from typing import TypedDict as _TypedDict\n\n__all__ = [\n    '__version__',\n    'CoreConfig',\n    'CoreSchema',\n    'CoreSchemaType',\n    'SchemaValidator',\n    'SchemaSerializer',\n    'Some',\n    'Url',\n    'MultiHostUrl',\n    'ArgsKwargs',\n    'PydanticUndefined',\n    'PydanticUndefinedType',\n    'SchemaError',\n    'ErrorDetails',\n    'InitErrorDetails',\n    'ValidationError',\n    'PydanticCustomError',\n    'PydanticKnownError',\n    'PydanticOmit',\n    'PydanticUseDefault',\n    'PydanticSerializationError',\n    'PydanticSerializationUnexpectedValue',\n    'TzInfo',\n    'to_json',\n    'from_json',\n    'to_jsonable_python',\n    'validate_core_schema',\n]\n\n\nclass ErrorDetails(_TypedDict):\n    type: str\n    \"\"\"\n    The type of error that occurred, this is an identifier designed for\n    programmatic use that will change rarely or never.\n\n    `type` is unique for each error message, and can hence be used as an identifier to build custom error messages.\n    \"\"\"\n    loc: tuple[int | str, ...]\n    \"\"\"Tuple of strings and ints identifying where in the schema the error occurred.\"\"\"\n    msg: str\n    \"\"\"A human readable error message.\"\"\"\n    input: _Any\n    \"\"\"The input data at this `loc` that caused the error.\"\"\"\n    ctx: _NotRequired[dict[str, _Any]]\n    \"\"\"\n    Values which are required to render the error message, and could hence be useful in rendering custom error messages.\n    Also useful for passing custom error data forward.\n    \"\"\"\n\n\nclass InitErrorDetails(_TypedDict):\n    type: str | PydanticCustomError\n    \"\"\"The type of error that occurred, this should a \"slug\" identifier that changes rarely or never.\"\"\"\n    loc: _NotRequired[tuple[int | str, ...]]\n    \"\"\"Tuple of strings and ints identifying where in the schema the error occurred.\"\"\"\n    input: _Any\n    \"\"\"The input data at this `loc` that caused the error.\"\"\"\n    ctx: _NotRequired[dict[str, _Any]]\n    \"\"\"\n    Values which are required to render the error message, and could hence be useful in rendering custom error messages.\n    Also useful for passing custom error data forward.\n    \"\"\"\n\n\nclass ErrorTypeInfo(_TypedDict):\n    \"\"\"\n    Gives information about errors.\n    \"\"\"\n\n    type: ErrorType\n    \"\"\"The type of error that occurred, this should a \"slug\" identifier that changes rarely or never.\"\"\"\n    message_template_python: str\n    \"\"\"String template to render a human readable error message from using context, when the input is Python.\"\"\"\n    example_message_python: str\n    \"\"\"Example of a human readable error message, when the input is Python.\"\"\"\n    message_template_json: _NotRequired[str]\n    \"\"\"String template to render a human readable error message from using context, when the input is JSON data.\"\"\"\n    example_message_json: _NotRequired[str]\n    \"\"\"Example of a human readable error message, when the input is JSON data.\"\"\"\n    example_context: dict[str, _Any] | None\n    \"\"\"Example of context values.\"\"\"\n\n\nclass MultiHostHost(_TypedDict):\n    \"\"\"\n    A host part of a multi-host URL.\n    \"\"\"\n\n    username: str | None\n    \"\"\"The username part of this host, or `None`.\"\"\"\n    password: str | None\n    \"\"\"The password part of this host, or `None`.\"\"\"\n    host: str | None\n    \"\"\"The host part of this host, or `None`.\"\"\"\n    port: int | None\n    \"\"\"The port part of this host, or `None`.\"\"\"\n", ".github/check_version.py": "#!/usr/bin/env python3\n\"\"\"\nCheck the version in Cargo.toml matches the version from `GITHUB_REF` environment variable.\n\"\"\"\nimport os\nimport re\nimport sys\nfrom pathlib import Path\n\n\ndef main() -> int:\n    cargo_path = Path('Cargo.toml')\n    if not cargo_path.is_file():\n        print(f'\u2716 path \"{cargo_path}\" does not exist')\n        return 1\n\n    version_ref = os.getenv('GITHUB_REF')\n    if version_ref:\n        version = re.sub('^refs/tags/v*', '', version_ref.lower())\n    else:\n        print(f'\u2716 \"GITHUB_REF\" env variables not found')\n        return 1\n\n    # convert from python pre-release version to rust pre-release version\n    # this is the reverse of what's done in lib.rs::_rust_notify\n    version = version.replace('a', '-alpha').replace('b', '-beta')\n\n    version_regex = re.compile(r\"\"\"^version ?= ?([\"'])(.+)\\1\"\"\", re.M)\n    cargo_content = cargo_path.read_text()\n    match = version_regex.search(cargo_content)\n    if not match:\n        print(f'\u2716 {version_regex!r} not found in {cargo_path}')\n        return 1\n\n    cargo_version = match.group(2)\n    if cargo_version == version:\n        print(f'\u2713 GITHUB_REF version matches {cargo_path} version \"{cargo_version}\"')\n        return 0\n    else:\n        print(f'\u2716 GITHUB_REF version \"{version}\" does not match {cargo_path} version \"{cargo_version}\"')\n        return 1\n\n\nif __name__ == '__main__':\n    sys.exit(main())\n", "tests/test_validate_strings.py": "import dataclasses\nimport re\nfrom datetime import date, datetime\n\nimport pytest\n\nfrom pydantic_core import SchemaValidator, ValidationError, core_schema\n\nfrom .conftest import Err\n\n\ndef test_bool():\n    v = SchemaValidator(core_schema.bool_schema())\n\n    assert v.validate_strings('true') is True\n    assert v.validate_strings('true', strict=True) is True\n    assert v.validate_strings('false') is False\n\n\n@pytest.mark.parametrize(\n    'schema,input_value,expected,strict',\n    [\n        (core_schema.int_schema(), '1', 1, False),\n        (core_schema.int_schema(), '1', 1, True),\n        (core_schema.int_schema(), 'xxx', Err('type=int_parsing'), True),\n        (core_schema.float_schema(), '1.1', 1.1, False),\n        (core_schema.float_schema(), '1.10', 1.1, False),\n        (core_schema.float_schema(), '1.1', 1.1, True),\n        (core_schema.float_schema(), '1.10', 1.1, True),\n        (core_schema.date_schema(), '2017-01-01', date(2017, 1, 1), False),\n        (core_schema.date_schema(), '2017-01-01', date(2017, 1, 1), True),\n        (core_schema.datetime_schema(), '2017-01-01T12:13:14.567', datetime(2017, 1, 1, 12, 13, 14, 567_000), False),\n        (core_schema.datetime_schema(), '2017-01-01T12:13:14.567', datetime(2017, 1, 1, 12, 13, 14, 567_000), True),\n        (core_schema.date_schema(), '2017-01-01T12:13:14.567', Err('type=date_from_datetime_inexact'), False),\n        (core_schema.date_schema(), '2017-01-01T12:13:14.567', Err('type=date_parsing'), True),\n        (core_schema.date_schema(), '2017-01-01T00:00:00', date(2017, 1, 1), False),\n        (core_schema.date_schema(), '2017-01-01T00:00:00', Err('type=date_parsing'), True),\n    ],\n    ids=repr,\n)\ndef test_validate_strings(schema, input_value, expected, strict):\n    v = SchemaValidator(schema)\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_strings(input_value, strict=strict)\n    else:\n        assert v.validate_strings(input_value, strict=strict) == expected\n\n\ndef test_dict():\n    v = SchemaValidator(core_schema.dict_schema(core_schema.int_schema(), core_schema.date_schema()))\n\n    assert v.validate_strings({'1': '2017-01-01', '2': '2017-01-02'}) == {1: date(2017, 1, 1), 2: date(2017, 1, 2)}\n    assert v.validate_strings({'1': '2017-01-01', '2': '2017-01-02'}, strict=True) == {\n        1: date(2017, 1, 1),\n        2: date(2017, 1, 2),\n    }\n\n\ndef test_model():\n    class MyModel:\n        # this is not required, but it avoids `__pydantic_fields_set__` being included in `__dict__`\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n        field_a: int\n        field_b: date\n\n    v = SchemaValidator(\n        core_schema.model_schema(\n            MyModel,\n            core_schema.model_fields_schema(\n                {\n                    'field_a': core_schema.model_field(core_schema.int_schema()),\n                    'field_b': core_schema.model_field(core_schema.date_schema()),\n                }\n            ),\n        )\n    )\n    m2 = v.validate_strings({'field_a': '1', 'field_b': '2017-01-01'})\n    assert m2.__dict__ == {'field_a': 1, 'field_b': date(2017, 1, 1)}\n    m2 = v.validate_strings({'field_a': '1', 'field_b': '2017-01-01'}, strict=True)\n    assert m2.__dict__ == {'field_a': 1, 'field_b': date(2017, 1, 1)}\n\n\ndef test_dataclass():\n    @dataclasses.dataclass\n    class MyDataClass:\n        field_a: int\n        field_b: date\n\n    v = SchemaValidator(\n        core_schema.dataclass_schema(\n            MyDataClass,\n            core_schema.dataclass_args_schema(\n                'MyDataClass',\n                [\n                    core_schema.dataclass_field('field_a', core_schema.int_schema()),\n                    core_schema.dataclass_field('field_b', core_schema.date_schema()),\n                ],\n            ),\n            ['field_a', 'field_b'],\n        )\n    )\n    m2 = v.validate_strings({'field_a': '1', 'field_b': '2017-01-01'})\n    assert m2.__dict__ == {'field_a': 1, 'field_b': date(2017, 1, 1)}\n    m2 = v.validate_strings({'field_a': '1', 'field_b': '2017-01-01'}, strict=True)\n    assert m2.__dict__ == {'field_a': 1, 'field_b': date(2017, 1, 1)}\n\n\ndef test_typed_dict():\n    v = SchemaValidator(\n        core_schema.typed_dict_schema(\n            {\n                'field_a': core_schema.typed_dict_field(core_schema.int_schema()),\n                'field_b': core_schema.typed_dict_field(core_schema.date_schema()),\n            }\n        )\n    )\n    m2 = v.validate_strings({'field_a': '1', 'field_b': '2017-01-01'})\n    assert m2 == {'field_a': 1, 'field_b': date(2017, 1, 1)}\n    m2 = v.validate_strings({'field_a': '1', 'field_b': '2017-01-01'}, strict=True)\n    assert m2 == {'field_a': 1, 'field_b': date(2017, 1, 1)}\n", "tests/test_garbage_collection.py": "import gc\nimport platform\nfrom typing import Any, Iterable\nfrom weakref import WeakValueDictionary\n\nimport pytest\n\nfrom pydantic_core import SchemaSerializer, SchemaValidator, core_schema\n\nGC_TEST_SCHEMA_INNER = core_schema.definitions_schema(\n    core_schema.definition_reference_schema(schema_ref='model'),\n    [\n        core_schema.typed_dict_schema(\n            {'x': core_schema.typed_dict_field(core_schema.definition_reference_schema(schema_ref='model'))},\n            ref='model',\n        )\n    ],\n)\n\n\n@pytest.mark.xfail(\n    condition=platform.python_implementation() == 'PyPy', reason='https://foss.heptapod.net/pypy/pypy/-/issues/3899'\n)\ndef test_gc_schema_serializer() -> None:\n    # test for https://github.com/pydantic/pydantic/issues/5136\n    class BaseModel:\n        __schema__: SchemaSerializer\n\n        def __init_subclass__(cls) -> None:\n            cls.__schema__ = SchemaSerializer(\n                core_schema.model_schema(cls, GC_TEST_SCHEMA_INNER), config={'ser_json_timedelta': 'float'}\n            )\n\n    cache: 'WeakValueDictionary[int, Any]' = WeakValueDictionary()\n\n    for _ in range(10_000):\n\n        class MyModel(BaseModel):\n            pass\n\n        cache[id(MyModel)] = MyModel\n\n        del MyModel\n\n    gc.collect(0)\n    gc.collect(1)\n    gc.collect(2)\n\n    assert len(cache) == 0\n\n\n@pytest.mark.xfail(\n    condition=platform.python_implementation() == 'PyPy', reason='https://foss.heptapod.net/pypy/pypy/-/issues/3899'\n)\ndef test_gc_schema_validator() -> None:\n    # test for https://github.com/pydantic/pydantic/issues/5136\n    class BaseModel:\n        __validator__: SchemaValidator\n\n        def __init_subclass__(cls) -> None:\n            cls.__validator__ = SchemaValidator(\n                core_schema.model_schema(cls, GC_TEST_SCHEMA_INNER),\n                config=core_schema.CoreConfig(extra_fields_behavior='allow'),\n            )\n\n    cache: 'WeakValueDictionary[int, Any]' = WeakValueDictionary()\n\n    for _ in range(10_000):\n\n        class MyModel(BaseModel):\n            pass\n\n        cache[id(MyModel)] = MyModel\n\n        del MyModel\n\n    gc.collect(0)\n    gc.collect(1)\n    gc.collect(2)\n\n    assert len(cache) == 0\n\n\n@pytest.mark.xfail(\n    condition=platform.python_implementation() == 'PyPy', reason='https://foss.heptapod.net/pypy/pypy/-/issues/3899'\n)\ndef test_gc_validator_iterator() -> None:\n    # test for https://github.com/pydantic/pydantic/issues/9243\n    class MyModel:\n        iter: Iterable[int]\n\n    v = SchemaValidator(\n        core_schema.model_schema(\n            MyModel,\n            core_schema.model_fields_schema(\n                {'iter': core_schema.model_field(core_schema.generator_schema(core_schema.int_schema()))}\n            ),\n        ),\n    )\n\n    class MyIterable:\n        def __iter__(self):\n            return self\n\n        def __next__(self):\n            raise StopIteration()\n\n    cache: 'WeakValueDictionary[int, Any]' = WeakValueDictionary()\n\n    for _ in range(10_000):\n        iterable = MyIterable()\n        cache[id(iterable)] = iterable\n        v.validate_python({'iter': iterable})\n        del iterable\n\n    gc.collect(0)\n    gc.collect(1)\n    gc.collect(2)\n\n    assert len(cache) == 0\n", "tests/test_errors.py": "import enum\nimport os\nimport pickle\nimport re\nimport subprocess\nimport sys\nfrom decimal import Decimal\nfrom typing import Any, Optional\nfrom unittest.mock import patch\n\nimport pytest\nfrom dirty_equals import HasRepr, IsInstance, IsJson, IsStr\n\nfrom pydantic_core import (\n    CoreConfig,\n    PydanticCustomError,\n    PydanticKnownError,\n    PydanticOmit,\n    SchemaValidator,\n    ValidationError,\n    core_schema,\n)\nfrom pydantic_core._pydantic_core import list_all_errors\n\nfrom .conftest import PyAndJson\n\n\ndef test_pydantic_value_error():\n    e = PydanticCustomError(\n        'my_error', 'this is a custom error {missed} {foo} {bar} {spam}', {'foo': 'X', 'bar': 42, 'spam': []}\n    )\n    assert e.message() == 'this is a custom error {missed} X 42 []'\n    assert e.message_template == 'this is a custom error {missed} {foo} {bar} {spam}'\n    assert e.type == 'my_error'\n    assert e.context == {'foo': 'X', 'bar': 42, 'spam': []}\n    assert str(e) == 'this is a custom error {missed} X 42 []'\n    assert repr(e) == (\n        \"this is a custom error {missed} X 42 [] [type=my_error, context={'foo': 'X', 'bar': 42, 'spam': []}]\"\n    )\n\n\n@pytest.mark.parametrize(\n    'msg,result_msg', [('my custom error', 'my custom error'), ('my custom error {foo}', \"my custom error {'bar': []}\")]\n)\ndef test_pydantic_value_error_nested_ctx(msg: str, result_msg: str):\n    ctx = {'foo': {'bar': []}}\n    e = PydanticCustomError('my_error', msg, ctx)\n    assert e.message() == result_msg\n    assert e.message_template == msg\n    assert e.type == 'my_error'\n    assert e.context == ctx\n    assert str(e) == result_msg\n    assert repr(e) == f'{result_msg} [type=my_error, context={ctx}]'\n\n\ndef test_pydantic_value_error_none():\n    e = PydanticCustomError('my_error', 'this is a custom error {missed}')\n    assert e.message() == 'this is a custom error {missed}'\n    assert e.message_template == 'this is a custom error {missed}'\n    assert e.type == 'my_error'\n    assert e.context is None\n    assert str(e) == 'this is a custom error {missed}'\n    assert repr(e) == 'this is a custom error {missed} [type=my_error, context=None]'\n\n\ndef test_pydantic_value_error_usage():\n    def f(input_value, info):\n        raise PydanticCustomError('my_error', 'this is a custom error {foo} {bar}', {'foo': 'FOOBAR', 'bar': 42})\n\n    v = SchemaValidator(core_schema.with_info_plain_validator_function(f))\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python(42)\n\n    assert exc_info.value.errors() == [\n        {\n            'type': 'my_error',\n            'loc': (),\n            'msg': 'this is a custom error FOOBAR 42',\n            'input': 42,\n            'ctx': {'foo': 'FOOBAR', 'bar': 42},\n        }\n    ]\n\n\ndef test_pydantic_value_error_invalid_dict():\n    def my_function(input_value, info):\n        raise PydanticCustomError('my_error', 'this is a custom error {foo}', {(): 'foobar'})\n\n    v = SchemaValidator(core_schema.with_info_plain_validator_function(my_function))\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python(42)\n\n    assert str(exc_info.value) == (\n        '1 validation error for function-plain[my_function()]\\n'\n        \"  (error rendering message: TypeError: 'tuple' object cannot be converted to 'PyString') \"\n        '[type=my_error, input_value=42, input_type=int]'\n    )\n    with pytest.raises(TypeError, match=\"'tuple' object cannot be converted to 'PyString'\"):\n        exc_info.value.errors(include_url=False)\n\n\ndef test_pydantic_value_error_invalid_type():\n    def f(input_value, info):\n        raise PydanticCustomError('my_error', 'this is a custom error {foo}', [('foo', 123)])\n\n    v = SchemaValidator(core_schema.with_info_plain_validator_function(f))\n\n    with pytest.raises(TypeError, match=\"argument 'context': 'list' object cannot be converted to 'PyDict'\"):\n        v.validate_python(42)\n\n\ndef test_validator_instance_plain():\n    class CustomValidator:\n        def __init__(self):\n            self.foo = 42\n            self.bar = 'before'\n\n        def validate(self, input_value, info):\n            return f'{input_value} {self.foo} {self.bar}'\n\n    c = CustomValidator()\n    v = SchemaValidator(core_schema.with_info_plain_validator_function(c.validate, metadata={'instance': c}))\n    c.foo += 1\n\n    assert v.validate_python('input value') == 'input value 43 before'\n    c.bar = 'changed'\n    assert v.validate_python('input value') == 'input value 43 changed'\n\n\ndef test_validator_instance_after():\n    class CustomValidator:\n        def __init__(self):\n            self.foo = 42\n\n        def validate(self, input_value, info):\n            assert isinstance(input_value, str)\n            return f'{input_value} {self.foo}'\n\n    c = CustomValidator()\n    v = SchemaValidator(\n        core_schema.with_info_after_validator_function(c.validate, core_schema.str_schema(), metadata={'instance': c})\n    )\n    c.foo += 1\n\n    assert v.validate_python('input value') == 'input value 43'\n    assert v.validate_python(b'is bytes') == 'is bytes 43'\n\n\ndef test_pydantic_error_type():\n    e = PydanticKnownError('json_invalid', {'error': 'Test'})\n    assert e.message() == 'Invalid JSON: Test'\n    assert e.type == 'json_invalid'\n    assert e.context == {'error': 'Test'}\n    assert str(e) == 'Invalid JSON: Test'\n    assert repr(e) == \"Invalid JSON: Test [type=json_invalid, context={'error': 'Test'}]\"\n\n\ndef test_pydantic_error_type_nested_ctx():\n    ctx = {'error': 'Test', 'foo': {'bar': []}}\n    e = PydanticKnownError('json_invalid', ctx)\n    assert e.message() == 'Invalid JSON: Test'\n    assert e.type == 'json_invalid'\n    assert e.context == ctx\n    assert str(e) == 'Invalid JSON: Test'\n    assert repr(e) == f'Invalid JSON: Test [type=json_invalid, context={ctx}]'\n\n\ndef test_pydantic_error_type_raise_no_ctx():\n    def f(input_value, info):\n        raise PydanticKnownError('finite_number')\n\n    v = SchemaValidator(core_schema.with_info_before_validator_function(f, core_schema.int_schema()))\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python(4)\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'finite_number', 'loc': (), 'msg': 'Input should be a finite number', 'input': 4}\n    ]\n\n\n@pytest.mark.parametrize(\n    'extra', [{}, {'foo': 1}, {'foo': {'bar': []}}, {'foo': {'bar': object()}}, {'foo': Decimal('42.1')}]\n)\ndef test_pydantic_error_type_raise_ctx(extra: dict):\n    ctx = {'gt': 42, **extra}\n\n    def f(input_value, info):\n        raise PydanticKnownError('greater_than', ctx)\n\n    v = SchemaValidator(core_schema.with_info_before_validator_function(f, core_schema.int_schema()))\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python(4)\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'greater_than', 'loc': (), 'msg': 'Input should be greater than 42', 'input': 4, 'ctx': ctx}\n    ]\n\n\n@pytest.mark.parametrize('ctx', [None, {}])\ndef test_pydantic_error_type_raise_custom_no_ctx(ctx: Optional[dict]):\n    def f(input_value, info):\n        raise PydanticKnownError('int_type', ctx)\n\n    v = SchemaValidator(core_schema.with_info_before_validator_function(f, core_schema.int_schema()))\n\n    expect_ctx = {'ctx': {}} if ctx is not None else {}\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python(4)\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'int_type', 'loc': (), 'msg': 'Input should be a valid integer', 'input': 4, **expect_ctx}\n    ]\n\n\n@pytest.mark.parametrize(\n    'extra', [{}, {'foo': 1}, {'foo': {'bar': []}}, {'foo': {'bar': object()}}, {'foo': Decimal('42.1')}]\n)\ndef test_pydantic_custom_error_type_raise_custom_ctx(extra: dict):\n    ctx = {'val': 42, **extra}\n\n    def f(input_value, info):\n        raise PydanticCustomError('my_error', 'my message with {val}', ctx)\n\n    v = SchemaValidator(core_schema.with_info_before_validator_function(f, core_schema.int_schema()))\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python(4)\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'my_error', 'loc': (), 'msg': 'my message with 42', 'input': 4, 'ctx': ctx}\n    ]\n\n\n@pytest.mark.parametrize('ctx', [None, {}])\ndef test_pydantic_custom_error_type_raise_custom_no_ctx(ctx: Optional[dict]):\n    def f(input_value, info):\n        raise PydanticCustomError('my_error', 'my message', ctx)\n\n    v = SchemaValidator(core_schema.with_info_before_validator_function(f, core_schema.int_schema()))\n\n    expect_ctx = {'ctx': {}} if ctx is not None else {}\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python(4)\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'my_error', 'loc': (), 'msg': 'my message', 'input': 4, **expect_ctx}\n    ]\n\n\nall_errors = [\n    ('no_such_attribute', \"Object has no attribute 'wrong_name'\", {'attribute': 'wrong_name'}),\n    ('json_invalid', 'Invalid JSON: foobar', {'error': 'foobar'}),\n    ('json_type', 'JSON input should be string, bytes or bytearray', None),\n    ('recursion_loop', 'Recursion error - cyclic reference detected', None),\n    ('model_type', 'Input should be a valid dictionary or instance of Foobar', {'class_name': 'Foobar'}),\n    ('model_attributes_type', 'Input should be a valid dictionary or object to extract fields from', None),\n    ('dataclass_exact_type', 'Input should be an instance of Foobar', {'class_name': 'Foobar'}),\n    ('dataclass_type', 'Input should be a dictionary or an instance of Foobar', {'class_name': 'Foobar'}),\n    ('missing', 'Field required', None),\n    ('frozen_field', 'Field is frozen', None),\n    ('frozen_instance', 'Instance is frozen', None),\n    ('extra_forbidden', 'Extra inputs are not permitted', None),\n    ('invalid_key', 'Keys should be strings', None),\n    ('get_attribute_error', 'Error extracting attribute: foo', {'error': 'foo'}),\n    ('none_required', 'Input should be None', None),\n    ('enum', 'Input should be foo', {'expected': 'foo'}),\n    ('greater_than', 'Input should be greater than 42.1', {'gt': 42.1}),\n    ('greater_than', 'Input should be greater than 42.1', {'gt': '42.1'}),\n    ('greater_than', 'Input should be greater than 2020-01-01', {'gt': '2020-01-01'}),\n    ('greater_than_equal', 'Input should be greater than or equal to 42.1', {'ge': 42.1}),\n    ('less_than', 'Input should be less than 42.1', {'lt': 42.1}),\n    ('less_than_equal', 'Input should be less than or equal to 42.1', {'le': 42.1}),\n    ('finite_number', 'Input should be a finite number', None),\n    (\n        'too_short',\n        'Foobar should have at least 42 items after validation, not 40',\n        {'field_type': 'Foobar', 'min_length': 42, 'actual_length': 40},\n    ),\n    (\n        'too_long',\n        'Foobar should have at most 42 items after validation, not 50',\n        {'field_type': 'Foobar', 'max_length': 42, 'actual_length': 50},\n    ),\n    ('string_type', 'Input should be a valid string', None),\n    ('string_sub_type', 'Input should be a string, not an instance of a subclass of str', None),\n    ('string_unicode', 'Input should be a valid string, unable to parse raw data as a unicode string', None),\n    ('string_pattern_mismatch', \"String should match pattern 'foo'\", {'pattern': 'foo'}),\n    ('string_too_short', 'String should have at least 42 characters', {'min_length': 42}),\n    ('string_too_short', 'String should have at least 1 character', {'min_length': 1}),\n    ('string_too_long', 'String should have at most 42 characters', {'max_length': 42}),\n    ('string_too_long', 'String should have at most 1 character', {'max_length': 1}),\n    ('dict_type', 'Input should be a valid dictionary', None),\n    ('mapping_type', 'Input should be a valid mapping, error: foobar', {'error': 'foobar'}),\n    ('iterable_type', 'Input should be iterable', None),\n    ('iteration_error', 'Error iterating over object, error: foobar', {'error': 'foobar'}),\n    ('list_type', 'Input should be a valid list', None),\n    ('tuple_type', 'Input should be a valid tuple', None),\n    ('set_type', 'Input should be a valid set', None),\n    ('bool_type', 'Input should be a valid boolean', None),\n    ('bool_parsing', 'Input should be a valid boolean, unable to interpret input', None),\n    ('int_type', 'Input should be a valid integer', None),\n    ('int_parsing', 'Input should be a valid integer, unable to parse string as an integer', None),\n    ('int_parsing_size', 'Unable to parse input string as an integer, exceeded maximum size', None),\n    ('int_from_float', 'Input should be a valid integer, got a number with a fractional part', None),\n    ('multiple_of', 'Input should be a multiple of 42.1', {'multiple_of': 42.1}),\n    ('greater_than', 'Input should be greater than 42.1', {'gt': 42.1}),\n    ('greater_than_equal', 'Input should be greater than or equal to 42.1', {'ge': 42.1}),\n    ('less_than', 'Input should be less than 42.1', {'lt': 42.1}),\n    ('less_than_equal', 'Input should be less than or equal to 42.1', {'le': 42.1}),\n    ('float_type', 'Input should be a valid number', None),\n    ('float_parsing', 'Input should be a valid number, unable to parse string as a number', None),\n    ('bytes_type', 'Input should be a valid bytes', None),\n    ('bytes_too_short', 'Data should have at least 42 bytes', {'min_length': 42}),\n    ('bytes_too_short', 'Data should have at least 1 byte', {'min_length': 1}),\n    ('bytes_too_long', 'Data should have at most 42 bytes', {'max_length': 42}),\n    ('bytes_too_long', 'Data should have at most 1 byte', {'max_length': 1}),\n    ('value_error', 'Value error, foobar', {'error': ValueError('foobar')}),\n    ('assertion_error', 'Assertion failed, foobar', {'error': AssertionError('foobar')}),\n    ('literal_error', 'Input should be foo', {'expected': 'foo'}),\n    ('literal_error', 'Input should be foo or bar', {'expected': 'foo or bar'}),\n    ('date_type', 'Input should be a valid date', None),\n    ('date_parsing', 'Input should be a valid date in the format YYYY-MM-DD, foobar', {'error': 'foobar'}),\n    ('date_from_datetime_parsing', 'Input should be a valid date or datetime, foobar', {'error': 'foobar'}),\n    ('date_from_datetime_inexact', 'Datetimes provided to dates should have zero time - e.g. be exact dates', None),\n    ('date_past', 'Date should be in the past', None),\n    ('date_future', 'Date should be in the future', None),\n    ('time_type', 'Input should be a valid time', None),\n    ('time_parsing', 'Input should be in a valid time format, foobar', {'error': 'foobar'}),\n    ('datetime_type', 'Input should be a valid datetime', None),\n    ('datetime_parsing', 'Input should be a valid datetime, foobar', {'error': 'foobar'}),\n    ('datetime_from_date_parsing', 'Input should be a valid datetime or date, foobar', {'error': 'foobar'}),\n    ('datetime_object_invalid', 'Invalid datetime object, got foobar', {'error': 'foobar'}),\n    ('datetime_past', 'Input should be in the past', None),\n    ('datetime_future', 'Input should be in the future', None),\n    ('timezone_naive', 'Input should not have timezone info', None),\n    ('timezone_aware', 'Input should have timezone info', None),\n    ('timezone_offset', 'Timezone offset of 0 required, got 60', {'tz_expected': 0, 'tz_actual': 60}),\n    ('time_delta_type', 'Input should be a valid timedelta', None),\n    ('time_delta_parsing', 'Input should be a valid timedelta, foobar', {'error': 'foobar'}),\n    ('frozen_set_type', 'Input should be a valid frozenset', None),\n    ('is_instance_of', 'Input should be an instance of Foo', {'class': 'Foo'}),\n    ('is_subclass_of', 'Input should be a subclass of Foo', {'class': 'Foo'}),\n    ('callable_type', 'Input should be callable', None),\n    (\n        'union_tag_invalid',\n        \"Input tag 'foo' found using bar does not match any of the expected tags: baz\",\n        {'discriminator': 'bar', 'tag': 'foo', 'expected_tags': 'baz'},\n    ),\n    ('union_tag_not_found', 'Unable to extract tag using discriminator foo', {'discriminator': 'foo'}),\n    ('arguments_type', 'Arguments must be a tuple, list or a dictionary', None),\n    ('missing_argument', 'Missing required argument', None),\n    ('unexpected_keyword_argument', 'Unexpected keyword argument', None),\n    ('missing_keyword_only_argument', 'Missing required keyword only argument', None),\n    ('unexpected_positional_argument', 'Unexpected positional argument', None),\n    ('missing_positional_only_argument', 'Missing required positional only argument', None),\n    ('multiple_argument_values', 'Got multiple values for argument', None),\n    ('url_type', 'URL input should be a string or URL', None),\n    ('url_parsing', 'Input should be a valid URL, Foobar', {'error': 'Foobar'}),\n    ('url_syntax_violation', 'Input violated strict URL syntax rules, Foobar', {'error': 'Foobar'}),\n    ('url_too_long', 'URL should have at most 42 characters', {'max_length': 42}),\n    ('url_too_long', 'URL should have at most 1 character', {'max_length': 1}),\n    ('url_scheme', 'URL scheme should be \"foo\", \"bar\" or \"spam\"', {'expected_schemes': '\"foo\", \"bar\" or \"spam\"'}),\n    ('uuid_type', 'UUID input should be a string, bytes or UUID object', None),\n    ('uuid_parsing', 'Input should be a valid UUID, Foobar', {'error': 'Foobar'}),\n    ('uuid_version', 'UUID version 42 expected', {'expected_version': 42}),\n    ('decimal_type', 'Decimal input should be an integer, float, string or Decimal object', None),\n    ('decimal_parsing', 'Input should be a valid decimal', None),\n    ('decimal_max_digits', 'Decimal input should have no more than 42 digits in total', {'max_digits': 42}),\n    ('decimal_max_digits', 'Decimal input should have no more than 1 digit in total', {'max_digits': 1}),\n    ('decimal_max_places', 'Decimal input should have no more than 42 decimal places', {'decimal_places': 42}),\n    ('decimal_max_places', 'Decimal input should have no more than 1 decimal place', {'decimal_places': 1}),\n    (\n        'decimal_whole_digits',\n        'Decimal input should have no more than 42 digits before the decimal point',\n        {'whole_digits': 42},\n    ),\n    (\n        'decimal_whole_digits',\n        'Decimal input should have no more than 1 digit before the decimal point',\n        {'whole_digits': 1},\n    ),\n]\n\n\n@pytest.mark.parametrize('error_type, message, context', all_errors)\ndef test_error_type(error_type, message, context):\n    e = PydanticKnownError(error_type, context)\n    assert e.message() == message\n    assert e.type == error_type\n    assert e.context == context\n\n\ndef test_all_errors_covered():\n    listed_types = {error_type for error_type, *_ in all_errors}\n    actual_types = {e['type'] for e in list_all_errors()}\n    assert actual_types == listed_types\n\n\ndef test_error_decimal():\n    e = PydanticKnownError('greater_than', {'gt': Decimal('42.1')})\n    assert e.message() == 'Input should be greater than 42.1'\n    assert e.type == 'greater_than'\n    assert e.context == {'gt': Decimal('42.1')}\n\n\ndef test_custom_error_decimal():\n    e = PydanticCustomError('my_error', 'this is a custom error {foobar}', {'foobar': Decimal('42.010')})\n    assert e.message() == 'this is a custom error 42.010'\n    assert e.message_template == 'this is a custom error {foobar}'\n    assert e.type == 'my_error'\n    assert e.context == {'foobar': Decimal('42.010')}\n\n\ndef test_pydantic_value_error_plain(py_and_json: PyAndJson):\n    def f(input_value, info):\n        raise PydanticCustomError\n\n    v = py_and_json(core_schema.with_info_plain_validator_function(f))\n    with pytest.raises(TypeError, match='missing 2 required positional arguments'):\n        v.validate_test('4')\n\n\n@pytest.mark.parametrize('exception', [PydanticOmit(), PydanticOmit])\ndef test_list_omit_exception(py_and_json: PyAndJson, exception):\n    def f(input_value):\n        if input_value % 2 == 0:\n            raise exception\n        return input_value\n\n    v = py_and_json(core_schema.list_schema(core_schema.no_info_after_validator_function(f, core_schema.int_schema())))\n    assert v.validate_test([1, 2, '3', '4']) == [1, 3]\n\n\ndef test_omit_exc_repr():\n    assert repr(PydanticOmit()) == 'PydanticOmit()'\n    assert str(PydanticOmit()) == 'PydanticOmit()'\n\n\n@pytest.mark.parametrize(\n    'error,ctx,expect',\n    [\n        ('greater_than', {'gt': []}, \"GreaterThan: 'gt' context value must be a Number\"),\n        ('model_type', {'class_name': []}, \"ModelType: 'class_name' context value must be a String\"),\n        ('date_parsing', {'error': []}, \"DateParsing: 'error' context value must be a String\"),\n        ('string_too_short', {'min_length': []}, \"StringTooShort: 'min_length' context value must be a usize\"),\n    ],\n)\ndef test_type_error_error(error: str, ctx: dict, expect: str):\n    with pytest.raises(TypeError, match=f'^{expect}$'):\n        PydanticKnownError(error, ctx)\n\n\ndef test_custom_context_for_simple_error():\n    err = PydanticKnownError('json_type', {'foo': 'bar'})\n    assert err.context == {'foo': 'bar'}\n\n\ndef test_all_errors():\n    errors = list_all_errors()\n    # print(f'{len(errors)=}')\n    assert len(errors) == len({e['type'] for e in errors}), 'error types are not unique'\n    # insert_assert(errors[:4])\n    assert errors[:4] == [\n        {\n            'type': 'no_such_attribute',\n            'message_template_python': \"Object has no attribute '{attribute}'\",\n            'example_message_python': \"Object has no attribute ''\",\n            'example_context': {'attribute': ''},\n        },\n        {\n            'type': 'json_invalid',\n            'message_template_python': 'Invalid JSON: {error}',\n            'example_message_python': 'Invalid JSON: ',\n            'example_context': {'error': ''},\n        },\n        {\n            'type': 'json_type',\n            'message_template_python': 'JSON input should be string, bytes or bytearray',\n            'example_message_python': 'JSON input should be string, bytes or bytearray',\n            'example_context': None,\n        },\n        {\n            'type': 'recursion_loop',\n            'message_template_python': 'Recursion error - cyclic reference detected',\n            'example_message_python': 'Recursion error - cyclic reference detected',\n            'example_context': None,\n        },\n    ]\n\n    none_required = next(e for e in errors if e['type'] == 'none_required')\n    # insert_assert(none_required)\n    assert none_required == {\n        'type': 'none_required',\n        'message_template_python': 'Input should be None',\n        'example_message_python': 'Input should be None',\n        'message_template_json': 'Input should be null',\n        'example_message_json': 'Input should be null',\n        'example_context': None,\n    }\n\n    error_types = [e['type'] for e in errors]\n    if error_types != list(core_schema.ErrorType.__args__):\n        literal = ''.join(f'\\n    {e!r},' for e in error_types)\n        print(f'python code (end of python/pydantic_core/core_schema.py):\\n\\nErrorType = Literal[{literal}\\n]')\n        pytest.fail('core_schema.ErrorType needs to be updated')\n\n\n@pytest.mark.skipif(sys.version_info < (3, 11), reason='This is the modern version used post 3.10.')\ndef test_validation_error_cause_contents():\n    enabled_config: CoreConfig = {'validation_error_cause': True}\n\n    def multi_raise_py_error(v: Any) -> Any:\n        try:\n            raise AssertionError('Wrong')\n        except AssertionError as e:\n            raise ValueError('Oh no!') from e\n\n    s2 = SchemaValidator(core_schema.no_info_plain_validator_function(multi_raise_py_error), config=enabled_config)\n    with pytest.raises(ValidationError) as exc_info:\n        s2.validate_python('anything')\n\n    cause_group = exc_info.value.__cause__\n    assert isinstance(cause_group, BaseExceptionGroup)\n    assert len(cause_group.exceptions) == 1\n\n    cause = cause_group.exceptions[0]\n    assert cause.__notes__\n    assert cause.__notes__[-1].startswith('\\nPydantic: ')\n    assert repr(cause) == repr(ValueError('Oh no!'))\n    assert cause.__traceback__ is not None\n\n    sub_cause = cause.__cause__\n    assert repr(sub_cause) == repr(AssertionError('Wrong'))\n    assert sub_cause.__cause__ is None\n    assert sub_cause.__traceback__ is not None\n\n    # Edge case: make sure a deep inner ValidationError(s) causing a validator failure doesn't cause any problems:\n    def outer_raise_py_error(v: Any) -> Any:\n        try:\n            s2.validate_python('anything')\n        except ValidationError as e:\n            raise ValueError('Sub val failure') from e\n\n    s3 = SchemaValidator(core_schema.no_info_plain_validator_function(outer_raise_py_error), config=enabled_config)\n    with pytest.raises(ValidationError) as exc_info:\n        s3.validate_python('anything')\n\n    assert isinstance(exc_info.value.__cause__, BaseExceptionGroup)\n    assert len(exc_info.value.__cause__.exceptions) == 1\n    cause = exc_info.value.__cause__.exceptions[0]\n    assert cause.__notes__ and cause.__notes__[-1].startswith('\\nPydantic: ')\n    assert repr(cause) == repr(ValueError('Sub val failure'))\n    subcause = cause.__cause__\n    assert isinstance(subcause, ValidationError)\n\n    cause_group = subcause.__cause__\n    assert isinstance(cause_group, BaseExceptionGroup)\n    assert len(cause_group.exceptions) == 1\n\n    cause = cause_group.exceptions[0]\n    assert cause.__notes__\n    assert cause.__notes__[-1].startswith('\\nPydantic: ')\n    assert repr(cause) == repr(ValueError('Oh no!'))\n    assert cause.__traceback__ is not None\n\n    sub_cause = cause.__cause__\n    assert repr(sub_cause) == repr(AssertionError('Wrong'))\n    assert sub_cause.__cause__ is None\n    assert sub_cause.__traceback__ is not None\n\n\n@pytest.mark.skipif(sys.version_info >= (3, 11), reason='This is the backport/legacy version used pre 3.11 only.')\ndef test_validation_error_cause_contents_legacy():\n    from exceptiongroup import BaseExceptionGroup\n\n    enabled_config: CoreConfig = {'validation_error_cause': True}\n\n    def multi_raise_py_error(v: Any) -> Any:\n        try:\n            raise AssertionError('Wrong')\n        except AssertionError as e:\n            raise ValueError('Oh no!') from e\n\n    s2 = SchemaValidator(core_schema.no_info_plain_validator_function(multi_raise_py_error), config=enabled_config)\n    with pytest.raises(ValidationError) as exc_info:\n        s2.validate_python('anything')\n\n    cause_group = exc_info.value.__cause__\n    assert isinstance(cause_group, BaseExceptionGroup)\n    assert len(cause_group.exceptions) == 1\n\n    cause = cause_group.exceptions[0]\n    assert repr(cause).startswith(\"UserWarning('Pydantic: \")\n\n    assert cause.__cause__ is not None\n    cause = cause.__cause__\n    assert repr(cause) == repr(ValueError('Oh no!'))\n    assert cause.__traceback__ is not None\n\n    sub_cause = cause.__cause__\n    assert repr(sub_cause) == repr(AssertionError('Wrong'))\n    assert sub_cause.__cause__ is None\n    assert sub_cause.__traceback__ is not None\n\n    # Make sure a deep inner ValidationError(s) causing a validator failure doesn't cause any problems:\n    def outer_raise_py_error(v: Any) -> Any:\n        try:\n            s2.validate_python('anything')\n        except ValidationError as e:\n            raise ValueError('Sub val failure') from e\n\n    s3 = SchemaValidator(core_schema.no_info_plain_validator_function(outer_raise_py_error), config=enabled_config)\n    with pytest.raises(ValidationError) as exc_info:\n        s3.validate_python('anything')\n\n    assert isinstance(exc_info.value.__cause__, BaseExceptionGroup)\n    assert len(exc_info.value.__cause__.exceptions) == 1\n    cause = exc_info.value.__cause__.exceptions[0]\n    assert repr(cause).startswith(\"UserWarning('Pydantic: \")\n    assert cause.__cause__ is not None\n    cause = cause.__cause__\n    assert repr(cause) == repr(ValueError('Sub val failure'))\n    subcause = cause.__cause__\n    assert isinstance(subcause, ValidationError)\n\n    cause_group = subcause.__cause__\n    assert isinstance(cause_group, BaseExceptionGroup)\n    assert len(cause_group.exceptions) == 1\n\n    cause = cause_group.exceptions[0]\n    assert repr(cause).startswith(\"UserWarning('Pydantic: \")\n    assert cause.__cause__ is not None\n    cause = cause.__cause__\n    assert repr(cause) == repr(ValueError('Oh no!'))\n    assert cause.__traceback__ is not None\n\n    sub_cause = cause.__cause__\n    assert repr(sub_cause) == repr(AssertionError('Wrong'))\n    assert sub_cause.__cause__ is None\n    assert sub_cause.__traceback__ is not None\n\n\nclass CauseResult(enum.Enum):\n    CAUSE = enum.auto()\n    NO_CAUSE = enum.auto()\n    IMPORT_ERROR = enum.auto()\n\n\n@pytest.mark.parametrize(\n    'desc,config,expected_result',\n    [  # Without the backport should still work after 3.10 as not needed:\n        (\n            'Enabled',\n            {'validation_error_cause': True},\n            CauseResult.CAUSE if sys.version_info >= (3, 11) else CauseResult.IMPORT_ERROR,\n        ),\n        ('Disabled specifically', {'validation_error_cause': False}, CauseResult.NO_CAUSE),\n        ('Disabled implicitly', {}, CauseResult.NO_CAUSE),\n    ],\n)\ndef test_validation_error_cause_config_variants(desc: str, config: CoreConfig, expected_result: CauseResult):\n    # Simulate the package being missing:\n    with patch.dict('sys.modules', {'exceptiongroup': None}):\n\n        def singular_raise_py_error(v: Any) -> Any:\n            raise ValueError('Oh no!')\n\n        s = SchemaValidator(core_schema.no_info_plain_validator_function(singular_raise_py_error), config=config)\n\n        if expected_result is CauseResult.IMPORT_ERROR:\n            # Confirm error message contains \"requires the exceptiongroup module\" in the middle of the string:\n            with pytest.raises(ImportError, match='requires the exceptiongroup module'):\n                s.validate_python('anything')\n        elif expected_result is CauseResult.CAUSE:\n            with pytest.raises(ValidationError) as exc_info:\n                s.validate_python('anything')\n            assert exc_info.value.__cause__ is not None\n            assert hasattr(exc_info.value.__cause__, 'exceptions')\n            assert len(exc_info.value.__cause__.exceptions) == 1\n            assert repr(exc_info.value.__cause__.exceptions[0]) == repr(ValueError('Oh no!'))\n        elif expected_result is CauseResult.NO_CAUSE:\n            with pytest.raises(ValidationError) as exc_info:\n                s.validate_python('anything')\n            assert exc_info.value.__cause__ is None\n        else:\n            raise AssertionError(f'Unhandled result: {expected_result}')\n\n\ndef test_validation_error_cause_traceback_preserved():\n    \"\"\"Makes sure historic bug of traceback being lost is fixed.\"\"\"\n\n    enabled_config: CoreConfig = {'validation_error_cause': True}\n\n    def singular_raise_py_error(v: Any) -> Any:\n        raise ValueError('Oh no!')\n\n    s1 = SchemaValidator(core_schema.no_info_plain_validator_function(singular_raise_py_error), config=enabled_config)\n    with pytest.raises(ValidationError) as exc_info:\n        s1.validate_python('anything')\n\n    base_errs = getattr(exc_info.value.__cause__, 'exceptions', [])\n    assert len(base_errs) == 1\n    base_err = base_errs[0]\n\n    # Get to the root error:\n    cause = base_err\n    while cause.__cause__ is not None:\n        cause = cause.__cause__\n\n    # Should still have a traceback:\n    assert cause.__traceback__ is not None\n\n\nclass BadRepr:\n    def __repr__(self):\n        raise RuntimeError('bad repr')\n\n\ndef test_error_on_repr(pydantic_version):\n    s = SchemaValidator({'type': 'int'})\n    with pytest.raises(ValidationError) as exc_info:\n        s.validate_python(BadRepr())\n\n    assert str(exc_info.value) == (\n        '1 validation error for int\\n'\n        '  Input should be a valid integer '\n        '[type=int_type, input_value=<unprintable BadRepr object>, input_type=BadRepr]\\n'\n        f'    For further information visit https://errors.pydantic.dev/{pydantic_version}/v/int_type'\n    )\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'int_type', 'loc': (), 'msg': 'Input should be a valid integer', 'input': IsInstance(BadRepr)}\n    ]\n    assert exc_info.value.json(include_url=False) == IsJson(\n        [\n            {\n                'type': 'int_type',\n                'loc': [],\n                'msg': 'Input should be a valid integer',\n                'input': '<Unserializable BadRepr object>',\n            }\n        ]\n    )\n\n\ndef test_error_json(pydantic_version):\n    s = SchemaValidator({'type': 'str', 'min_length': 3})\n    with pytest.raises(ValidationError) as exc_info:\n        s.validate_python('12')\n\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'string_too_short',\n            'loc': (),\n            'msg': 'String should have at least 3 characters',\n            'input': '12',\n            'ctx': {'min_length': 3},\n        }\n    ]\n    assert exc_info.value.json() == IsJson(\n        [\n            {\n                'type': 'string_too_short',\n                'loc': [],\n                'msg': 'String should have at least 3 characters',\n                'input': '12',\n                'ctx': {'min_length': 3},\n                'url': f'https://errors.pydantic.dev/{pydantic_version}/v/string_too_short',\n            }\n        ]\n    )\n    assert exc_info.value.json(include_url=False, include_context=False) == IsJson(\n        [{'type': 'string_too_short', 'loc': [], 'msg': 'String should have at least 3 characters', 'input': '12'}]\n    )\n    assert exc_info.value.json().startswith('[{\"type\":\"string_too_short\",')\n    assert exc_info.value.json(indent=2).startswith('[\\n  {\\n    \"type\": \"string_too_short\",')\n\n\ndef test_error_json_python_error(pydantic_version: str):\n    def raise_py_error(v: Any) -> Any:\n        try:\n            assert False\n        except AssertionError as e:\n            raise ValueError('Oh no!') from e\n\n    s = SchemaValidator(core_schema.no_info_plain_validator_function(raise_py_error))\n    with pytest.raises(ValidationError) as exc_info:\n        s.validate_python('anything')\n\n    exc = exc_info.value.errors()[0]['ctx']['error']\n    assert isinstance(exc, ValueError)\n    assert isinstance(exc.__context__, AssertionError)\n\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'value_error',\n            'loc': (),\n            'msg': 'Value error, Oh no!',\n            'input': 'anything',\n            'ctx': {'error': HasRepr(repr(ValueError('Oh no!')))},\n        }\n    ]\n    assert exc_info.value.json() == IsJson(\n        [\n            {\n                'type': 'value_error',\n                'loc': [],\n                'msg': 'Value error, Oh no!',\n                'input': 'anything',\n                'ctx': {'error': 'Oh no!'},\n                'url': f'https://errors.pydantic.dev/{pydantic_version}/v/value_error',\n            }\n        ]\n    )\n    assert exc_info.value.json(include_url=False, include_context=False) == IsJson(\n        [{'type': 'value_error', 'loc': [], 'msg': 'Value error, Oh no!', 'input': 'anything'}]\n    )\n    assert exc_info.value.json().startswith('[{\"type\":\"value_error\",')\n    assert exc_info.value.json(indent=2).startswith('[\\n  {\\n    \"type\": \"value_error\",')\n\n\ndef test_error_json_cycle():\n    s = SchemaValidator({'type': 'str', 'min_length': 3})\n    cycle = []\n    cycle.append(cycle)\n    msg = '[type=string_type, input_value=[[...]], input_type=list]'\n    with pytest.raises(ValidationError, match=re.escape(msg)) as exc_info:\n        s.validate_python(cycle)\n\n    assert exc_info.value.json(include_url=False) == IsJson(\n        [{'type': 'string_type', 'loc': [], 'msg': 'Input should be a valid string', 'input': ['...']}]\n    )\n\n\nclass Foobar:\n    pass\n\n\nclass CustomStr:\n    def __str__(self):\n        return 'custom str'\n\n\ndef test_error_json_unknown():\n    s = SchemaValidator({'type': 'str'})\n    with pytest.raises(ValidationError) as exc_info:\n        s.validate_python(Foobar())\n\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'string_type',\n            'loc': (),\n            'msg': 'Input should be a valid string',\n            'input': HasRepr(IsStr(regex='<.+.test_errors.Foobar object at 0x[a-f0-9]{5,}>', regex_flags=re.I)),\n        }\n    ]\n    # insert_assert(exc_info.value.json(include_url=False))\n    assert exc_info.value.json(include_url=False) == IsJson(\n        [\n            {\n                'type': 'string_type',\n                'loc': [],\n                'msg': 'Input should be a valid string',\n                'input': IsStr(regex='<.+.test_errors.Foobar object at 0x[a-f0-9]{5,}>', regex_flags=re.I),\n            }\n        ]\n    )\n    with pytest.raises(ValidationError) as exc_info:\n        s.validate_python(CustomStr())\n    # insert_assert(json.loads(exc_info.value.json(include_url=False)))\n    assert exc_info.value.json(include_url=False) == IsJson(\n        [{'type': 'string_type', 'loc': [], 'msg': 'Input should be a valid string', 'input': 'custom str'}]\n    )\n\n\ndef test_error_json_loc():\n    s = SchemaValidator(\n        core_schema.dict_schema(core_schema.str_schema(), core_schema.list_schema(core_schema.int_schema()))\n    )\n    with pytest.raises(ValidationError) as exc_info:\n        s.validate_python({'a': [0, 1, 'x'], 'b': [0, 'y']})\n\n    # insert_assert(exc_info.value.json())\n    assert exc_info.value.json(include_url=False) == IsJson(\n        [\n            {\n                'type': 'int_parsing',\n                'loc': ['a', 2],\n                'msg': 'Input should be a valid integer, unable to parse string as an integer',\n                'input': 'x',\n            },\n            {\n                'type': 'int_parsing',\n                'loc': ['b', 1],\n                'msg': 'Input should be a valid integer, unable to parse string as an integer',\n                'input': 'y',\n            },\n        ]\n    )\n\n\ndef test_raise_validation_error():\n    with pytest.raises(ValidationError, match='1 validation error for Foobar\\n') as exc_info:\n        raise ValidationError.from_exception_data(\n            'Foobar', [{'type': 'greater_than', 'loc': ('a', 2), 'input': 4, 'ctx': {'gt': 5}}]\n        )\n\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'greater_than', 'loc': ('a', 2), 'msg': 'Input should be greater than 5', 'input': 4, 'ctx': {'gt': 5}}\n    ]\n    with pytest.raises(TypeError, match=\"GreaterThan: 'gt' required in context\"):\n        raise ValidationError.from_exception_data('Foobar', [{'type': 'greater_than', 'loc': ('a', 2), 'input': 4}])\n\n\n@pytest.mark.parametrize(\n    'hide_input_in_errors,input_str',\n    ((False, 'type=greater_than, input_value=4, input_type=int'), (True, 'type=greater_than')),\n)\ndef test_raise_validation_error_hide_input(hide_input_in_errors, input_str):\n    with pytest.raises(ValidationError, match=re.escape(f'Input should be greater than 5 [{input_str}]')):\n        raise ValidationError.from_exception_data(\n            'Foobar',\n            [{'type': 'greater_than', 'loc': ('a', 2), 'input': 4, 'ctx': {'gt': 5}}],\n            hide_input=hide_input_in_errors,\n        )\n\n\ndef test_raise_validation_error_json():\n    with pytest.raises(ValidationError) as exc_info:\n        raise ValidationError.from_exception_data('Foobar', [{'type': 'none_required', 'loc': [-42], 'input': 'x'}])\n\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'none_required', 'loc': (-42,), 'msg': 'Input should be None', 'input': 'x'}\n    ]\n\n    with pytest.raises(ValidationError) as exc_info:\n        raise ValidationError.from_exception_data(\n            'Foobar', [{'type': 'none_required', 'loc': (), 'input': 'x'}], 'json'\n        )\n\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'none_required', 'loc': (), 'msg': 'Input should be null', 'input': 'x'}\n    ]\n\n\ndef test_raise_validation_error_custom():\n    custom_error = PydanticCustomError(\n        'my_error', 'this is a custom error {missed} {foo} {bar}', {'foo': 'X', 'bar': 42}\n    )\n    with pytest.raises(ValidationError) as exc_info:\n        raise ValidationError.from_exception_data('Foobar', [{'type': custom_error, 'input': 'x'}])\n\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'my_error',\n            'loc': (),\n            'msg': 'this is a custom error {missed} X 42',\n            'input': 'x',\n            'ctx': {'foo': 'X', 'bar': 42},\n        }\n    ]\n\n\n@pytest.mark.parametrize(\n    'msg,result_msg', [('my custom error', 'my custom error'), ('my custom error {foo}', \"my custom error {'bar': []}\")]\n)\ndef test_raise_validation_error_custom_nested_ctx(msg: str, result_msg: str):\n    ctx = {'foo': {'bar': []}}\n    custom_error = PydanticCustomError('my_error', msg, ctx)\n    with pytest.raises(ValidationError) as exc_info:\n        raise ValidationError.from_exception_data('Foobar', [{'type': custom_error, 'input': 'x'}])\n\n    expected_error_detail = {'type': 'my_error', 'loc': (), 'msg': result_msg, 'input': 'x', 'ctx': ctx}\n\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [expected_error_detail]\n    assert exc_info.value.json(include_url=False) == IsJson([{**expected_error_detail, 'loc': []}])\n\n\ndef test_raise_validation_error_known_class_ctx():\n    custom_data = Foobar()\n    ctx = {'gt': 10, 'foo': {'bar': custom_data}}\n\n    with pytest.raises(ValidationError) as exc_info:\n        raise ValidationError.from_exception_data('MyTitle', [{'type': 'greater_than', 'input': 9, 'ctx': ctx}])\n\n    expected_error_detail = {\n        'type': 'greater_than',\n        'loc': (),\n        'msg': 'Input should be greater than 10',\n        'input': 9,\n        'ctx': ctx,\n    }\n\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [expected_error_detail]\n    assert exc_info.value.json(include_url=False) == IsJson(\n        [{**expected_error_detail, 'loc': [], 'ctx': {'gt': 10, 'foo': {'bar': str(custom_data)}}}]\n    )\n\n\ndef test_raise_validation_error_custom_class_ctx():\n    custom_data = Foobar()\n    ctx = {'foo': {'bar': custom_data}}\n    custom_error = PydanticCustomError('my_error', 'my message', ctx)\n    assert custom_error.context == ctx\n\n    with pytest.raises(ValidationError) as exc_info:\n        raise ValidationError.from_exception_data('MyTitle', [{'type': custom_error, 'input': 'x'}])\n\n    expected_error_detail = {'type': 'my_error', 'loc': (), 'msg': 'my message', 'input': 'x', 'ctx': ctx}\n\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [expected_error_detail]\n    assert exc_info.value.json(include_url=False) == IsJson(\n        [{**expected_error_detail, 'loc': [], 'ctx': {'foo': {'bar': str(custom_data)}}}]\n    )\n\n\ndef test_loc_with_dots(pydantic_version):\n    v = SchemaValidator(\n        core_schema.typed_dict_schema(\n            {\n                'a': core_schema.typed_dict_field(\n                    core_schema.tuple_positional_schema([core_schema.int_schema(), core_schema.int_schema()]),\n                    validation_alias='foo.bar',\n                )\n            }\n        )\n    )\n    assert v.validate_python({'foo.bar': (41, 42)}) == {'a': (41, 42)}\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python({'foo.bar': ('x', 42)})\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'int_parsing',\n            'loc': ('foo.bar', 0),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'x',\n        }\n    ]\n    # insert_assert(str(exc_info.value))\n    assert str(exc_info.value) == (\n        '1 validation error for typed-dict\\n'\n        '`foo.bar`.0\\n'\n        '  Input should be a valid integer, unable to parse string as an integer '\n        \"[type=int_parsing, input_value='x', input_type=str]\\n\"\n        f'    For further information visit https://errors.pydantic.dev/{pydantic_version}/v/int_parsing'\n    )\n\n\ndef test_hide_input_in_error() -> None:\n    s = SchemaValidator({'type': 'int'})\n    with pytest.raises(ValidationError) as exc_info:\n        s.validate_python('definitely not an int')\n\n    for error in exc_info.value.errors(include_input=False):\n        assert 'input' not in error\n\n\ndef test_hide_input_in_json() -> None:\n    s = SchemaValidator({'type': 'int'})\n    with pytest.raises(ValidationError) as exc_info:\n        s.validate_python('definitely not an int')\n\n    for error in exc_info.value.errors(include_input=False):\n        assert 'input' not in error\n\n\n@pytest.mark.skipif(\n    sys.version_info < (3, 9) and sys.implementation.name == 'pypy',\n    reason='PyPy before 3.9 cannot pickle this correctly',\n)\ndef test_validation_error_pickle() -> None:\n    s = SchemaValidator({'type': 'int'})\n    with pytest.raises(ValidationError) as exc_info:\n        s.validate_python('definitely not an int')\n\n    original = exc_info.value\n    roundtripped = pickle.loads(pickle.dumps(original))\n    assert original.errors() == roundtripped.errors()\n\n\n@pytest.mark.skipif('PYDANTIC_ERRORS_INCLUDE_URL' in os.environ, reason=\"can't test when envvar is set\")\ndef test_errors_include_url() -> None:\n    s = SchemaValidator({'type': 'int'})\n    with pytest.raises(ValidationError) as exc_info:\n        s.validate_python('definitely not an int')\n    assert 'https://errors.pydantic.dev' in repr(exc_info.value)\n\n\n@pytest.mark.skipif(sys.platform == 'emscripten', reason='no subprocesses on emscripten')\n@pytest.mark.parametrize(\n    ('env_var', 'env_var_value', 'expected_to_have_url'),\n    [\n        ('PYDANTIC_ERRORS_INCLUDE_URL', None, True),\n        ('PYDANTIC_ERRORS_INCLUDE_URL', '1', True),\n        ('PYDANTIC_ERRORS_INCLUDE_URL', 'True', True),\n        ('PYDANTIC_ERRORS_INCLUDE_URL', 'no', False),\n        ('PYDANTIC_ERRORS_INCLUDE_URL', '0', False),\n        # Legacy environment variable, will raise a deprecation warning:\n        ('PYDANTIC_ERRORS_OMIT_URL', '1', False),\n        ('PYDANTIC_ERRORS_OMIT_URL', None, True),\n    ],\n)\ndef test_errors_include_url_envvar(env_var, env_var_value, expected_to_have_url) -> None:\n    \"\"\"\n    Test the `PYDANTIC_ERRORS_INCLUDE_URL` environment variable.\n\n    Since it can only be set before `ValidationError.__repr__()` is first called,\n    we need to spawn a subprocess to test it.\n    \"\"\"\n    code = \"import pydantic_core; pydantic_core.SchemaValidator({'type': 'int'}).validate_python('ooo')\"\n    env = os.environ.copy()\n    env.pop('PYDANTIC_ERRORS_OMIT_URL', None)  # in case the ambient environment has it set\n    if env_var_value is not None:\n        env[env_var] = env_var_value\n    env['PYTHONDEVMODE'] = '1'  # required to surface the deprecation warning\n    result = subprocess.run(\n        [sys.executable, '-c', code],\n        stdout=subprocess.PIPE,\n        stderr=subprocess.STDOUT,\n        encoding='utf-8',\n        env=env,\n    )\n    assert result.returncode == 1\n    if 'PYDANTIC_ERRORS_OMIT_URL' in env:\n        assert 'PYDANTIC_ERRORS_OMIT_URL is deprecated' in result.stdout\n    assert ('https://errors.pydantic.dev' in result.stdout) == expected_to_have_url\n", "tests/test_isinstance.py": "import pytest\n\nfrom pydantic_core import PydanticOmit, SchemaError, SchemaValidator, ValidationError, core_schema\n\nfrom .conftest import PyAndJson\n\n\ndef test_isinstance():\n    v = SchemaValidator({'type': 'int'})\n    assert v.validate_python(123) == 123\n    assert v.isinstance_python(123) is True\n    assert v.validate_python('123') == 123\n    assert v.isinstance_python('123') is True\n\n    with pytest.raises(ValidationError, match='Input should be a valid integer'):\n        v.validate_python('foo')\n\n    assert v.isinstance_python('foo') is False\n\n\ndef test_isinstance_strict():\n    v = SchemaValidator({'type': 'int', 'strict': True})\n    assert v.validate_python(123) == 123\n    assert v.isinstance_python(123) is True\n\n    with pytest.raises(ValidationError, match='Input should be a valid integer'):\n        v.validate_python('123')\n\n    assert v.isinstance_python('123') is False\n\n\ndef test_internal_error():\n    v = SchemaValidator(\n        {\n            'type': 'model',\n            'cls': int,\n            'schema': {'type': 'model-fields', 'fields': {'f': {'type': 'model-field', 'schema': {'type': 'int'}}}},\n        }\n    )\n    with pytest.raises(AttributeError, match=\"'int' object has no attribute '__dict__'\"):\n        v.validate_python({'f': 123})\n\n    with pytest.raises(AttributeError, match=\"'int' object has no attribute '__dict__'\"):\n        v.validate_json('{\"f\": 123}')\n\n    with pytest.raises(AttributeError, match=\"'int' object has no attribute '__dict__'\"):\n        v.isinstance_python({'f': 123})\n\n\ndef test_omit(py_and_json: PyAndJson):\n    def omit(v, info):\n        if v == 'omit':\n            raise PydanticOmit\n        elif v == 'error':\n            raise ValueError('error')\n        else:\n            return v\n\n    v = py_and_json(core_schema.with_info_plain_validator_function(omit))\n    assert v.validate_test('foo') == 'foo'\n    if v.validator_type == 'python':\n        assert v.isinstance_test('foo') is True\n\n    if v.validator_type == 'python':\n        assert v.isinstance_test('error') is False\n    with pytest.raises(SchemaError, match='Uncaught Omit error, please check your usage of `default` validators.'):\n        v.validate_test('omit')\n", "tests/test_config.py": "import math\nimport re\n\nimport pytest\nfrom dirty_equals import FunctionCheck, HasAttributes, IsInstance\n\nfrom pydantic_core import CoreConfig, SchemaValidator, ValidationError\n\nfrom .conftest import Err, plain_repr\n\n\ndef test_on_field():\n    v = SchemaValidator({'type': 'str', 'min_length': 2, 'max_length': 5})\n    r = plain_repr(v)\n    assert 'min_length:Some(2)' in r\n    assert 'max_length:Some(5)' in r\n    assert v.isinstance_python('test') is True\n    assert v.isinstance_python('test long') is False\n\n\ndef test_on_config():\n    v = SchemaValidator({'type': 'str'}, {'str_max_length': 5})\n    assert 'max_length:Some(5)' in plain_repr(v)\n    assert v.isinstance_python('test') is True\n    assert v.isinstance_python('test long') is False\n\n\ndef test_field_priority_arg():\n    v = SchemaValidator({'type': 'str', 'max_length': 5}, {'str_max_length': 10})\n    assert 'max_length:Some(5)' in plain_repr(v)\n    assert v.isinstance_python('test') is True\n    assert v.isinstance_python('test long') is False\n\n\nclass MyModel:\n    # this is not required, but it avoids `__pydantic_fields_set__` being included in `__dict__`\n    __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n\n\ndef test_on_model_class():\n    v = SchemaValidator(\n        {\n            'type': 'model',\n            'cls': MyModel,\n            'config': {'str_max_length': 5},\n            'schema': {'type': 'model-fields', 'fields': {'f': {'type': 'model-field', 'schema': {'type': 'str'}}}},\n        }\n    )\n    assert 'max_length:Some(5)' in plain_repr(v)\n    assert v.isinstance_python({'f': 'test'}) is True\n    assert v.isinstance_python({'f': 'test long'}) is False\n\n\ndef test_field_priority_model():\n    v = SchemaValidator(\n        {\n            'type': 'model',\n            'cls': MyModel,\n            'config': {'str_max_length': 10},\n            'schema': {\n                'type': 'model-fields',\n                'fields': {'f': {'type': 'model-field', 'schema': {'type': 'str', 'max_length': 5}}},\n            },\n        }\n    )\n    assert 'max_length:Some(5)' in plain_repr(v)\n    assert v.isinstance_python({'f': 'test'}) is True\n    assert v.isinstance_python({'f': 'test long'}) is False\n\n\n@pytest.mark.parametrize(\n    'config,float_field_schema,input_value,expected',\n    [\n        ({}, {'type': 'float'}, {'x': 'nan'}, IsInstance(MyModel) & HasAttributes(x=FunctionCheck(math.isnan))),\n        (\n            {'allow_inf_nan': True},\n            {'type': 'float'},\n            {'x': 'nan'},\n            IsInstance(MyModel) & HasAttributes(x=FunctionCheck(math.isnan)),\n        ),\n        (\n            {'allow_inf_nan': False},\n            {'type': 'float'},\n            {'x': 'nan'},\n            Err('Input should be a finite number [type=finite_number,'),\n        ),\n        # field `allow_inf_nan` (if set) should have priority over global config\n        (\n            {'allow_inf_nan': True},\n            {'type': 'float', 'allow_inf_nan': False},\n            {'x': 'nan'},\n            Err('Input should be a finite number [type=finite_number,'),\n        ),\n        (\n            {'allow_inf_nan': False},\n            {'type': 'float', 'allow_inf_nan': True},\n            {'x': 'nan'},\n            IsInstance(MyModel) & HasAttributes(x=FunctionCheck(math.isnan)),\n        ),\n    ],\n    ids=repr,\n)\ndef test_allow_inf_nan(config: CoreConfig, float_field_schema, input_value, expected):\n    v = SchemaValidator(\n        {\n            'type': 'model',\n            'cls': MyModel,\n            'schema': {'type': 'model-fields', 'fields': {'x': {'type': 'model-field', 'schema': float_field_schema}}},\n            'config': config,\n        }\n    )\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_python(input_value)\n    else:\n        output_dict = v.validate_python(input_value)\n        assert output_dict == expected\n\n\n@pytest.mark.parametrize(\n    'config,input_str',\n    (\n        ({}, 'type=string_type, input_value=123, input_type=int'),\n        ({'hide_input_in_errors': False}, 'type=string_type, input_value=123, input_type=int'),\n        ({'hide_input_in_errors': True}, 'type=string_type'),\n    ),\n)\ndef test_hide_input_in_errors(config, input_str):\n    v = SchemaValidator(\n        {\n            'type': 'model',\n            'cls': MyModel,\n            'schema': {'type': 'model-fields', 'fields': {'f': {'type': 'model-field', 'schema': {'type': 'str'}}}},\n        },\n        config,\n    )\n\n    with pytest.raises(ValidationError, match=re.escape(f'Input should be a valid string [{input_str}]')):\n        assert v.validate_python({'f': 123})\n\n\ndef test_cache_strings():\n    v = SchemaValidator({'type': 'str'})\n    assert 'cache_strings=True' in plain_repr(v)\n\n    v = SchemaValidator({'type': 'str'}, {'cache_strings': True})\n    assert 'cache_strings=True' in plain_repr(v)\n\n    v = SchemaValidator({'type': 'str'}, {'cache_strings': False})\n    assert 'cache_strings=False' in plain_repr(v)\n\n    v = SchemaValidator({'type': 'str'}, {'cache_strings': 'keys'})\n    assert \"cache_strings='keys'\" in plain_repr(v)\n", "tests/test_misc.py": "import copy\nimport pickle\nimport re\n\nimport pytest\nfrom typing_extensions import get_args\n\nfrom pydantic_core import CoreSchema, CoreSchemaType, PydanticUndefined, core_schema\nfrom pydantic_core._pydantic_core import (\n    SchemaError,\n    SchemaValidator,\n    ValidationError,\n    __version__,\n    build_info,\n    build_profile,\n)\n\n\n@pytest.mark.parametrize('obj', [ValidationError, SchemaValidator, SchemaError])\ndef test_module(obj):\n    assert obj.__module__ == 'pydantic_core._pydantic_core'\n\n\ndef test_version():\n    assert isinstance(__version__, str)\n    assert '.' in __version__\n\n\ndef test_build_profile():\n    assert build_profile in ('debug', 'release')\n\n\ndef test_build_info():\n    assert isinstance(build_info, str)\n\n\ndef test_schema_error():\n    err = SchemaError('test')\n    assert isinstance(err, Exception)\n    assert str(err) == 'test'\n    assert repr(err) == 'SchemaError(\"test\")'\n\n\ndef test_validation_error(pydantic_version):\n    v = SchemaValidator({'type': 'int'})\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python(1.5)\n\n    assert exc_info.value.title == 'int'\n    assert exc_info.value.error_count() == 1\n    assert (\n        exc_info.value.errors(include_url=False)\n        == exc_info.value.errors(include_url=False, include_context=False)\n        == [\n            {\n                'type': 'int_from_float',\n                'loc': (),\n                'msg': 'Input should be a valid integer, got a number with a fractional part',\n                'input': 1.5,\n            }\n        ]\n    )\n    # insert_assert(exc_info.value.errors())\n    assert exc_info.value.errors() == [\n        {\n            'type': 'int_from_float',\n            'loc': (),\n            'msg': 'Input should be a valid integer, got a number with a fractional part',\n            'input': 1.5,\n            'url': f'https://errors.pydantic.dev/{pydantic_version}/v/int_from_float',\n        }\n    ]\n\n\ndef test_validation_error_include_context():\n    v = SchemaValidator({'type': 'list', 'max_length': 2})\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python([1, 2, 3])\n\n    assert exc_info.value.title == 'list[any]'\n    assert exc_info.value.error_count() == 1\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'too_long',\n            'loc': (),\n            'msg': 'List should have at most 2 items after validation, not 3',\n            'input': [1, 2, 3],\n            'ctx': {'field_type': 'List', 'max_length': 2, 'actual_length': 3},\n        }\n    ]\n    # insert_assert(exc_info.value.errors(include_url=False, include_context=False))\n    assert exc_info.value.errors(include_url=False, include_context=False) == [\n        {\n            'type': 'too_long',\n            'loc': (),\n            'msg': 'List should have at most 2 items after validation, not 3',\n            'input': [1, 2, 3],\n        }\n    ]\n\n\ndef test_custom_title():\n    v = SchemaValidator({'type': 'int'}, {'title': 'MyInt'})\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python(1.5)\n\n    assert exc_info.value.title == 'MyInt'\n\n\ndef test_validation_error_multiple(pydantic_version):\n    class MyModel:\n        # this is not required, but it avoids `__pydantic_fields_set__` being included in `__dict__`\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n        field_a: str\n        field_b: int\n\n    v = SchemaValidator(\n        {\n            'type': 'model',\n            'cls': MyModel,\n            'schema': {\n                'type': 'model-fields',\n                'fields': {\n                    'x': {'type': 'model-field', 'schema': {'type': 'float'}},\n                    'y': {'type': 'model-field', 'schema': {'type': 'int'}},\n                },\n            },\n        }\n    )\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python({'x': 'x' * 60, 'y': 'y'})\n\n    assert exc_info.value.title == 'MyModel'\n    assert exc_info.value.error_count() == 2\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'float_parsing',\n            'loc': ('x',),\n            'msg': 'Input should be a valid number, unable to parse string as a number',\n            'input': 'x' * 60,\n        },\n        {\n            'type': 'int_parsing',\n            'loc': ('y',),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'y',\n        },\n    ]\n    assert repr(exc_info.value) == (\n        '2 validation errors for MyModel\\n'\n        'x\\n'\n        '  Input should be a valid number, unable to parse string as a number '\n        \"[type=float_parsing, input_value='xxxxxxxxxxxxxxxxxxxxxxxx...xxxxxxxxxxxxxxxxxxxxxxx', input_type=str]\\n\"\n        f'    For further information visit https://errors.pydantic.dev/{pydantic_version}/v/float_parsing\\n'\n        'y\\n'\n        '  Input should be a valid integer, unable to parse string as an integer '\n        \"[type=int_parsing, input_value='y', input_type=str]\\n\"\n        f'    For further information visit https://errors.pydantic.dev/{pydantic_version}/v/int_parsing'\n    )\n\n\ndef test_core_schema_type_literal():\n    def get_type_value(schema):\n        type_ = schema.__annotations__['type']\n        m = re.search(r\"Literal\\['(.+?)']\", type_.__forward_arg__)\n        assert m, f'Unknown schema type: {type_}'\n        return m.group(1)\n\n    schema_types = tuple(get_type_value(x) for x in CoreSchema.__args__)\n    schema_types = tuple(dict.fromkeys(schema_types))  # remove duplicates while preserving order\n    if get_args(CoreSchemaType) != schema_types:\n        literal = ''.join(f'\\n    {e!r},' for e in schema_types)\n        print(\n            f'python code (near end of python/pydantic_core/core_schema.py):\\n\\nCoreSchemaType = Literal[{literal}\\n]'\n        )\n        pytest.fail('core_schema.CoreSchemaType needs to be updated')\n\n\ndef test_undefined():\n    with pytest.raises(NotImplementedError, match='UndefinedType'):\n        PydanticUndefined.__class__()\n\n    undefined_copy = copy.copy(PydanticUndefined)\n    undefined_deepcopy = copy.deepcopy(PydanticUndefined)\n\n    assert undefined_copy is PydanticUndefined\n    assert undefined_deepcopy is PydanticUndefined\n\n    assert pickle.loads(pickle.dumps(PydanticUndefined)) is PydanticUndefined\n\n\ndef test_unicode_error_input_repr() -> None:\n    \"\"\"https://github.com/pydantic/pydantic/issues/6448\"\"\"\n\n    schema = core_schema.int_schema()\n\n    validator = SchemaValidator(schema)\n\n    danger_str = '\u00ff' * 1000\n    expected = \"1 validation error for int\\n  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='\u00ff\u00ff\u00ff\u00ff\u00ff\u00ff\u00ff\u00ff\u00ff\u00ff\u00ff\u00ff...\u00ff\u00ff\u00ff\u00ff\u00ff\u00ff\u00ff\u00ff\u00ff\u00ff\u00ff', input_type=str]\"\n    with pytest.raises(ValidationError) as exc_info:\n        validator.validate_python(danger_str)\n    actual = repr(exc_info.value).split('For further information visit ')[0].strip()\n\n    assert expected == actual\n\n\ndef test_core_schema_import_field_validation_info():\n    with pytest.warns(DeprecationWarning, match='`FieldValidationInfo` is deprecated, use `ValidationInfo` instead.'):\n        core_schema.FieldValidationInfo\n\n\ndef test_core_schema_import_missing():\n    with pytest.raises(AttributeError, match=\"module 'pydantic_core' has no attribute 'foobar'\"):\n        core_schema.foobar\n", "tests/test_hypothesis.py": "import json\nimport re\nimport sys\nfrom datetime import datetime, timezone\nfrom typing import Optional\n\nimport pytest\nfrom dirty_equals import AnyThing, IsBytes, IsStr, IsTuple\nfrom hypothesis import given, strategies\nfrom typing_extensions import TypedDict\n\nfrom pydantic_core import SchemaSerializer, SchemaValidator, ValidationError\nfrom pydantic_core import core_schema as cs\n\n\n@pytest.fixture(scope='module')\ndef datetime_schema():\n    return SchemaValidator({'type': 'datetime'})\n\n\n@given(strategies.datetimes())\ndef test_datetime_datetime(datetime_schema, data):\n    assert datetime_schema.validate_python(data) == data\n\n\n@pytest.mark.skipif(sys.platform == 'win32', reason='Can fail on windows, I guess due to 64-bit issue')\n@given(strategies.integers(min_value=-11_676_096_000, max_value=253_402_300_799_000))\ndef test_datetime_int(datetime_schema, data):\n    try:\n        if abs(data) > 20_000_000_000:\n            microsecond = (data % 1000) * 1000\n            expected = datetime.fromtimestamp(data // 1000, tz=timezone.utc).replace(\n                tzinfo=None, microsecond=microsecond\n            )\n        else:\n            expected = datetime.fromtimestamp(data, tz=timezone.utc).replace(tzinfo=None)\n    except OverflowError:\n        pytest.skip('OverflowError, see pyodide/pyodide#2841, this can happen on 32-bit systems')\n    else:\n        assert datetime_schema.validate_python(data).replace(tzinfo=None) == expected, data\n\n\n@given(strategies.binary())\ndef test_datetime_binary(datetime_schema, data):\n    try:\n        datetime_schema.validate_python(data)\n    except ValidationError as exc:\n        assert exc.errors(include_url=False) == [\n            {\n                'ctx': {'error': IsStr()},\n                'input': IsBytes(),\n                'loc': (),\n                'msg': IsStr(regex='Input should be a valid datetime or date, .+'),\n                'type': 'datetime_from_date_parsing',\n            },\n        ]\n\n\n@pytest.fixture(scope='module')\ndef definition_schema():\n    return SchemaValidator(\n        cs.definitions_schema(\n            cs.definition_reference_schema('Branch'),\n            [\n                cs.typed_dict_schema(\n                    {\n                        'name': cs.typed_dict_field(cs.str_schema()),\n                        'sub_branch': cs.typed_dict_field(\n                            cs.with_default_schema(\n                                cs.nullable_schema(cs.definition_reference_schema('Branch')), default=None\n                            )\n                        ),\n                    },\n                    ref='Branch',\n                )\n            ],\n        )\n    )\n\n\ndef test_definition_simple(definition_schema):\n    assert definition_schema.validate_python({'name': 'root'}) == {'name': 'root', 'sub_branch': None}\n\n\nclass BranchModel(TypedDict):\n    name: str\n    sub_branch: Optional['BranchModel']\n\n\n@pytest.mark.skipif(sys.platform == 'emscripten', reason='Seems to fail sometimes on pyodide no idea why')\n@given(strategies.from_type(BranchModel))\ndef test_recursive(definition_schema, data):\n    assert definition_schema.validate_python(data) == data\n\n\n@strategies.composite\ndef branch_models_with_cycles(draw, existing=None):\n    if existing is None:\n        existing = []\n    model = BranchModel(name=draw(strategies.text()), sub_branch=None)\n    existing.append(model)\n    model['sub_branch'] = draw(\n        strategies.none()\n        | strategies.builds(BranchModel, name=strategies.text(), sub_branch=branch_models_with_cycles(existing))\n        | strategies.sampled_from(existing)\n    )\n    return model\n\n\n@given(branch_models_with_cycles())\ndef test_definition_cycles(definition_schema, data):\n    try:\n        assert definition_schema.validate_python(data) == data\n    except ValidationError as exc:\n        assert exc.errors(include_url=False) == [\n            {\n                'type': 'recursion_loop',\n                'loc': IsTuple(length=(1, None)),\n                'msg': 'Recursion error - cyclic reference detected',\n                'input': AnyThing(),\n            }\n        ]\n\n\ndef test_definition_broken(definition_schema):\n    data = {'name': 'x'}\n    data['sub_branch'] = data\n    with pytest.raises(ValidationError, match='Recursion error - cyclic reference detected'):\n        definition_schema.validate_python(data)\n\n\n@given(strategies.timedeltas())\ndef test_pytimedelta_as_timedelta(dt):\n    v = SchemaValidator({'type': 'timedelta', 'gt': dt})\n    # simplest way to check `pytimedelta_as_timedelta` is correct is to extract duration from repr of the validator\n    m = re.search(r'Duration ?\\{\\s+positive: ?(\\w+),\\s+day: ?(\\d+),\\s+second: ?(\\d+),\\s+microsecond: ?(\\d+)', repr(v))\n    pos, day, sec, micro = m.groups()\n    total_seconds = (1 if pos == 'true' else -1) * (int(day) * 86_400 + int(sec) + int(micro) / 1_000_000)\n\n    assert total_seconds == pytest.approx(dt.total_seconds())\n\n\n@pytest.fixture(scope='module')\ndef url_validator():\n    return SchemaValidator({'type': 'url'})\n\n\n# Parsing errors which hypothesis is likely to hit\n_URL_PARSE_ERRORS = {'input is empty', 'relative URL without a base', 'empty host'}\n\n\n@given(strategies.text())\ndef test_urls_text(url_validator, text):\n    try:\n        url_validator.validate_python(text)\n    except ValidationError as exc:\n        assert exc.error_count() == 1\n        error = exc.errors(include_url=False)[0]\n        assert error['type'] == 'url_parsing'\n        assert error['ctx']['error'] in _URL_PARSE_ERRORS\n\n\n@pytest.fixture(scope='module')\ndef multi_host_url_validator():\n    return SchemaValidator({'type': 'multi-host-url'})\n\n\n@given(strategies.text())\ndef test_multi_host_urls_text(multi_host_url_validator, text):\n    try:\n        multi_host_url_validator.validate_python(text)\n    except ValidationError as exc:\n        assert exc.error_count() == 1\n        error = exc.errors(include_url=False)[0]\n        assert error['type'] == 'url_parsing'\n        assert error['ctx']['error'] in _URL_PARSE_ERRORS\n\n\n@pytest.fixture(scope='module')\ndef str_serializer():\n    return SchemaSerializer({'type': 'str'})\n\n\n@given(strategies.text())\ndef test_serialize_string(str_serializer: SchemaSerializer, data):\n    assert str_serializer.to_python(data) == data\n    assert json.loads(str_serializer.to_json(data)) == data\n", "tests/test_schema_functions.py": "import dataclasses\nimport re\nfrom datetime import date\nfrom enum import Enum\nfrom typing import Any\n\nimport pytest\n\nfrom pydantic_core import SchemaError, SchemaSerializer, SchemaValidator, ValidationError, core_schema\n\n\ndef val_function(x, *args: Any):\n    return x\n\n\ndef make_5():\n    return 5\n\n\nclass MyModel:\n    __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n\n\n@dataclasses.dataclass\nclass MyDataclass:\n    x: int\n    y: str\n\n\nclass MyEnum(int, Enum):\n    a = 1\n    b = 2\n\n\ndef ids_function(val):\n    if callable(val):\n        return val.__name__\n    elif isinstance(val, tuple) and len(val) == 2:\n        return '({})'.format(', '.join([repr(a) for a in val[0]] + [f'{k}={v!r}' for k, v in val[1].items()]))\n    else:\n        return repr(val)\n\n\ndef args(*args, **kwargs):\n    return args, kwargs\n\n\nall_schema_functions = [\n    (core_schema.any_schema, args(), {'type': 'any'}),\n    (core_schema.any_schema, args(metadata=['foot', 'spa']), {'type': 'any', 'metadata': ['foot', 'spa']}),\n    (core_schema.none_schema, args(), {'type': 'none'}),\n    (core_schema.bool_schema, args(), {'type': 'bool'}),\n    (core_schema.bool_schema, args(strict=True), {'type': 'bool', 'strict': True}),\n    (core_schema.int_schema, args(), {'type': 'int'}),\n    (core_schema.int_schema, args(metadata={'fred'}), {'type': 'int', 'metadata': {'fred'}}),\n    (core_schema.int_schema, args(multiple_of=5, gt=10, lt=20), {'type': 'int', 'multiple_of': 5, 'gt': 10, 'lt': 20}),\n    (core_schema.float_schema, args(), {'type': 'float'}),\n    (core_schema.float_schema, args(multiple_of=5, gt=1.2), {'type': 'float', 'multiple_of': 5, 'gt': 1.2}),\n    (core_schema.str_schema, args(), {'type': 'str'}),\n    (core_schema.str_schema, args(min_length=5, max_length=10), {'type': 'str', 'min_length': 5, 'max_length': 10}),\n    (core_schema.bytes_schema, args(), {'type': 'bytes'}),\n    (core_schema.bytes_schema, args(min_length=5, ref='xx'), {'type': 'bytes', 'min_length': 5, 'ref': 'xx'}),\n    (core_schema.date_schema, args(), {'type': 'date'}),\n    (core_schema.date_schema, args(gt=date(2020, 1, 1)), {'type': 'date', 'gt': date(2020, 1, 1)}),\n    (core_schema.time_schema, args(), {'type': 'time', 'microseconds_precision': 'truncate'}),\n    (core_schema.datetime_schema, args(), {'type': 'datetime', 'microseconds_precision': 'truncate'}),\n    (core_schema.timedelta_schema, args(), {'type': 'timedelta', 'microseconds_precision': 'truncate'}),\n    (\n        core_schema.time_schema,\n        args(microseconds_precision='error'),\n        {'type': 'time', 'microseconds_precision': 'error'},\n    ),\n    (\n        core_schema.datetime_schema,\n        args(microseconds_precision='error'),\n        {'type': 'datetime', 'microseconds_precision': 'error'},\n    ),\n    (\n        core_schema.timedelta_schema,\n        args(microseconds_precision='error'),\n        {'type': 'timedelta', 'microseconds_precision': 'error'},\n    ),\n    (core_schema.literal_schema, args(['a', 'b']), {'type': 'literal', 'expected': ['a', 'b']}),\n    (\n        core_schema.enum_schema,\n        args(MyEnum, list(MyEnum.__members__.values())),\n        {'type': 'enum', 'cls': MyEnum, 'members': [MyEnum.a, MyEnum.b]},\n    ),\n    (core_schema.is_instance_schema, args(int), {'type': 'is-instance', 'cls': int}),\n    (core_schema.callable_schema, args(), {'type': 'callable'}),\n    (core_schema.list_schema, args(), {'type': 'list'}),\n    (core_schema.list_schema, args({'type': 'int'}), {'type': 'list', 'items_schema': {'type': 'int'}}),\n    (core_schema.tuple_schema, args([]), {'type': 'tuple', 'items_schema': []}),\n    (\n        core_schema.set_schema,\n        args({'type': 'int'}, min_length=4),\n        {'type': 'set', 'items_schema': {'type': 'int'}, 'min_length': 4},\n    ),\n    (\n        core_schema.frozenset_schema,\n        args({'type': 'int'}, max_length=5),\n        {'type': 'frozenset', 'items_schema': {'type': 'int'}, 'max_length': 5},\n    ),\n    (core_schema.generator_schema, args({'type': 'int'}), {'type': 'generator', 'items_schema': {'type': 'int'}}),\n    (core_schema.dict_schema, args(), {'type': 'dict'}),\n    (\n        core_schema.dict_schema,\n        args({'type': 'str'}, {'type': 'int'}),\n        {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'int'}},\n    ),\n    (\n        core_schema.with_info_before_validator_function,\n        args(val_function, {'type': 'int'}),\n        {\n            'type': 'function-before',\n            'function': {'type': 'with-info', 'function': val_function},\n            'schema': {'type': 'int'},\n        },\n    ),\n    (\n        core_schema.with_info_after_validator_function,\n        args(val_function, {'type': 'int'}),\n        {\n            'type': 'function-after',\n            'function': {'type': 'with-info', 'function': val_function},\n            'schema': {'type': 'int'},\n        },\n    ),\n    (\n        core_schema.with_info_wrap_validator_function,\n        args(val_function, {'type': 'int'}),\n        {\n            'type': 'function-wrap',\n            'function': {'type': 'with-info', 'function': val_function},\n            'schema': {'type': 'int'},\n        },\n    ),\n    (\n        core_schema.with_info_plain_validator_function,\n        args(val_function),\n        core_schema.with_info_plain_validator_function(val_function),\n    ),\n    (\n        core_schema.with_default_schema,\n        args({'type': 'int'}, default=5),\n        {'type': 'default', 'schema': {'type': 'int'}, 'default': 5},\n    ),\n    (\n        core_schema.with_default_schema,\n        args({'type': 'int'}, default=None),\n        {'type': 'default', 'schema': {'type': 'int'}, 'default': None},\n    ),\n    (\n        core_schema.with_default_schema,\n        args({'type': 'int'}, default_factory=make_5),\n        {'type': 'default', 'schema': {'type': 'int'}, 'default_factory': make_5},\n    ),\n    (core_schema.nullable_schema, args({'type': 'int'}), {'type': 'nullable', 'schema': {'type': 'int'}}),\n    (\n        core_schema.union_schema,\n        args([{'type': 'int'}, {'type': 'str'}]),\n        {'type': 'union', 'choices': [{'type': 'int'}, {'type': 'str'}]},\n    ),\n    (\n        core_schema.union_schema,\n        args([{'type': 'int'}, {'type': 'str'}], custom_error_type='foobar', custom_error_message='This is Foobar'),\n        {\n            'type': 'union',\n            'choices': [{'type': 'int'}, {'type': 'str'}],\n            'custom_error_type': 'foobar',\n            'custom_error_message': 'This is Foobar',\n        },\n    ),\n    (\n        core_schema.tagged_union_schema,\n        args({'foo': {'type': 'int'}, 'bar': {'type': 'str'}}, 'foo'),\n        {'type': 'tagged-union', 'choices': {'foo': {'type': 'int'}, 'bar': {'type': 'str'}}, 'discriminator': 'foo'},\n    ),\n    (\n        core_schema.chain_schema,\n        args([{'type': 'int'}, {'type': 'str'}]),\n        {'type': 'chain', 'steps': [{'type': 'int'}, {'type': 'str'}]},\n    ),\n    (\n        core_schema.typed_dict_field,\n        args({'type': 'int'}, required=True),\n        {'type': 'typed-dict-field', 'schema': {'type': 'int'}, 'required': True},\n    ),\n    (\n        core_schema.typed_dict_schema,\n        args({'foo': core_schema.typed_dict_field({'type': 'int'})}),\n        {'type': 'typed-dict', 'fields': {'foo': {'type': 'typed-dict-field', 'schema': {'type': 'int'}}}},\n    ),\n    (\n        core_schema.model_field,\n        args({'type': 'int'}, validation_alias='foobar'),\n        {'type': 'model-field', 'schema': {'type': 'int'}, 'validation_alias': 'foobar'},\n    ),\n    (\n        core_schema.model_fields_schema,\n        args({'foo': core_schema.model_field({'type': 'int'})}),\n        {'type': 'model-fields', 'fields': {'foo': {'type': 'model-field', 'schema': {'type': 'int'}}}},\n    ),\n    (\n        core_schema.model_schema,\n        args(MyModel, {'type': 'int'}),\n        {'type': 'model', 'cls': MyModel, 'schema': {'type': 'int'}},\n    ),\n    (core_schema.arguments_parameter, args('foo', {'type': 'int'}), {'name': 'foo', 'schema': {'type': 'int'}}),\n    (\n        core_schema.arguments_schema,\n        args(\n            [\n                core_schema.arguments_parameter('foo', {'type': 'int'}),\n                core_schema.arguments_parameter('bar', {'type': 'str'}),\n            ],\n            serialization=core_schema.format_ser_schema('d'),\n        ),\n        {\n            'type': 'arguments',\n            'arguments_schema': [\n                {'name': 'foo', 'schema': {'type': 'int'}},\n                {'name': 'bar', 'schema': {'type': 'str'}},\n            ],\n            'serialization': {'type': 'format', 'formatting_string': 'd'},\n        },\n    ),\n    (\n        core_schema.call_schema,\n        args(core_schema.arguments_schema([core_schema.arguments_parameter('foo', {'type': 'int'})]), val_function),\n        {\n            'type': 'call',\n            'function': val_function,\n            'arguments_schema': {'type': 'arguments', 'arguments_schema': [{'name': 'foo', 'schema': {'type': 'int'}}]},\n        },\n    ),\n    (\n        core_schema.custom_error_schema,\n        args(core_schema.int_schema(), 'foobar', custom_error_message='Hello'),\n        {\n            'type': 'custom-error',\n            'schema': {'type': 'int'},\n            'custom_error_type': 'foobar',\n            'custom_error_message': 'Hello',\n        },\n    ),\n    (core_schema.json_schema, args({'type': 'int'}), {'type': 'json', 'schema': {'type': 'int'}}),\n    (core_schema.url_schema, args(), {'type': 'url'}),\n    (core_schema.multi_host_url_schema, args(), {'type': 'multi-host-url'}),\n    (\n        core_schema.lax_or_strict_schema,\n        args({'type': 'int'}, {'type': 'int'}),\n        {'type': 'lax-or-strict', 'lax_schema': {'type': 'int'}, 'strict_schema': {'type': 'int'}},\n    ),\n    (\n        core_schema.json_or_python_schema,\n        args({'type': 'int'}, {'type': 'str'}),\n        {'type': 'json-or-python', 'json_schema': {'type': 'int'}, 'python_schema': {'type': 'str'}},\n    ),\n    (core_schema.is_subclass_schema, args(MyModel), {'type': 'is-subclass', 'cls': MyModel}),\n    (\n        core_schema.definitions_schema,\n        args({'type': 'definition-ref', 'schema_ref': 'an-int'}, [{'type': 'int', 'ref': 'an-int'}]),\n        {\n            'type': 'definitions',\n            'schema': {'type': 'definition-ref', 'schema_ref': 'an-int'},\n            'definitions': [{'type': 'int', 'ref': 'an-int'}],\n        },\n    ),\n    (core_schema.definition_reference_schema, args('foo'), {'type': 'definition-ref', 'schema_ref': 'foo'}),\n    (\n        core_schema.dataclass_args_schema,\n        args('Foo', [{'name': 'foo', 'type': 'dataclass-field', 'schema': {'type': 'int'}}]),\n        {\n            'type': 'dataclass-args',\n            'dataclass_name': 'Foo',\n            'fields': [{'name': 'foo', 'type': 'dataclass-field', 'schema': {'type': 'int'}}],\n        },\n    ),\n    (\n        core_schema.dataclass_schema,\n        args(MyDataclass, {'type': 'int'}, ['foobar']),\n        {'type': 'dataclass', 'schema': {'type': 'int'}, 'fields': ['foobar'], 'cls': MyDataclass},\n    ),\n    (\n        core_schema.dataclass_schema,\n        args(MyDataclass, {'type': 'int'}, ['foobar'], slots=True),\n        {'type': 'dataclass', 'schema': {'type': 'int'}, 'fields': ['foobar'], 'cls': MyDataclass, 'slots': True},\n    ),\n    (core_schema.uuid_schema, args(), {'type': 'uuid'}),\n    (core_schema.decimal_schema, args(), {'type': 'decimal'}),\n    (core_schema.decimal_schema, args(multiple_of=5, gt=1.2), {'type': 'decimal', 'multiple_of': 5, 'gt': 1.2}),\n]\n\n\n@pytest.mark.parametrize('function,args_kwargs,expected_schema', all_schema_functions, ids=ids_function)\ndef test_schema_functions(function, args_kwargs, expected_schema):\n    args, kwargs = args_kwargs\n    schema = function(*args, **kwargs)\n    assert schema == expected_schema\n    if schema.get('type') in {None, 'definition-ref', 'typed-dict-field', 'model-field'}:\n        return\n\n    v = SchemaValidator(schema)\n    try:\n        v.validate_python('foobar')\n    except ValidationError:\n        pass\n\n    # also build the serializer, just to check it doesn't raise an error\n    SchemaSerializer(schema)\n\n\ndef test_all_schema_functions_used():\n    all_types = {\n        re.sub(r\".+'(.+?)'.+\", r'\\1', s.__annotations__['type'].__forward_arg__)\n        for s in core_schema.CoreSchema.__args__\n    }\n    types_used = {args['type'] for _, _, args in all_schema_functions if 'type' in args}\n\n    # isn't a CoreSchema type\n    types_used.remove('typed-dict-field')\n    types_used.remove('model-field')\n\n    assert all_types == types_used\n\n\ndef test_invalid_custom_error():\n    s = core_schema.union_schema([{'type': 'int'}, {'type': 'str'}], custom_error_type='foobar')\n    with pytest.raises(SchemaError, match=r\"KeyError: 'custom_error_message'\"):\n        SchemaValidator(s)\n\n\ndef test_invalid_custom_error_type():\n    s = core_schema.union_schema(\n        [{'type': 'int'}, {'type': 'str'}], custom_error_type='finite_number', custom_error_message='x'\n    )\n    msg = \"custom_error.message should not be provided if 'custom_error_type' matches a known error\"\n    with pytest.raises(SchemaError, match=msg):\n        SchemaValidator(s)\n\n\ndef repr_function(value, _info):\n    return repr(value)\n\n\n@pytest.mark.parametrize('return_schema', [core_schema.str_schema(), core_schema.int_schema()])\ndef test_expected_serialization_types(return_schema):\n    SchemaSerializer(\n        core_schema.any_schema(\n            serialization=core_schema.plain_serializer_function_ser_schema(\n                repr_function, info_arg=True, return_schema=return_schema\n            )\n        )\n    )\n", "tests/test_build.py": "import pickle\n\nimport pytest\n\nfrom pydantic_core import SchemaError, SchemaValidator, validate_core_schema\nfrom pydantic_core import core_schema as cs\n\n\ndef test_build_error_type():\n    with pytest.raises(SchemaError, match=\"Input tag 'foobar' found using 'type' does not match any of the\"):\n        validate_core_schema({'type': 'foobar', 'title': 'TestModel'})\n\n\ndef test_build_error_internal():\n    with pytest.raises(SchemaError, match='Input should be a valid integer, unable to parse string as an integer'):\n        validate_core_schema({'type': 'str', 'min_length': 'xxx', 'title': 'TestModel'})\n\n\ndef test_build_error_deep():\n    with pytest.raises(SchemaError, match='Input should be a valid integer, unable to parse string as an integer'):\n        validate_core_schema(\n            {\n                'title': 'MyTestModel',\n                'type': 'typed-dict',\n                'fields': {'age': {'schema': {'type': 'int', 'ge': 'not-int'}}},\n            }\n        )\n\n\ndef test_schema_as_string():\n    v = SchemaValidator({'type': 'bool'})\n    assert v.validate_python('tRuE') is True\n\n\ndef test_schema_wrong_type(pydantic_version):\n    with pytest.raises(SchemaError) as exc_info:\n        validate_core_schema(1)\n    assert str(exc_info.value) == (\n        'Invalid Schema:\\n  Input should be a valid dictionary or object to'\n        ' extract fields from [type=model_attributes_type, input_value=1, input_type=int]\\n'\n        f'    For further information visit https://errors.pydantic.dev/{pydantic_version}/v/model_attributes_type'\n    )\n    assert exc_info.value.errors() == [\n        {\n            'input': 1,\n            'loc': (),\n            'msg': 'Input should be a valid dictionary or object to extract fields from',\n            'type': 'model_attributes_type',\n        }\n    ]\n    assert exc_info.value.error_count() == 1\n\n\n@pytest.mark.parametrize('pickle_protocol', range(1, pickle.HIGHEST_PROTOCOL + 1))\ndef test_pickle(pickle_protocol: int) -> None:\n    v1 = SchemaValidator({'type': 'bool'})\n    assert v1.validate_python('tRuE') is True\n    p = pickle.dumps(v1, protocol=pickle_protocol)\n    v2 = pickle.loads(p)\n    assert v2.validate_python('tRuE') is True\n    assert repr(v1) == repr(v2)\n\n\n@pytest.mark.skip\ndef test_schema_definition_error():\n    schema = {'type': 'union', 'choices': []}\n    schema['choices'].append({'type': 'nullable', 'schema': schema})\n    with pytest.raises(SchemaError, match='Recursion error - cyclic reference detected'):\n        validate_core_schema(schema)\n\n\ndef test_not_schema_definition_error():\n    schema = {\n        'type': 'typed-dict',\n        'fields': {\n            f'f_{i}': {'type': 'typed-dict-field', 'schema': {'type': 'nullable', 'schema': {'type': 'int'}}}\n            for i in range(101)\n        },\n    }\n    v = SchemaValidator(schema)\n    assert repr(v).count('TypedDictField') == 101\n\n\ndef test_no_type():\n    with pytest.raises(SchemaError, match=\"Unable to extract tag using discriminator 'type'\"):\n        validate_core_schema({})\n\n\ndef test_wrong_type():\n    with pytest.raises(SchemaError, match=\"Input tag 'unknown' found using 'type' does not match any of the\"):\n        validate_core_schema({'type': 'unknown'})\n\n\ndef test_function_no_mode():\n    with pytest.raises(SchemaError, match=\"Input tag 'function' found using 'type' does not match any of the\"):\n        validate_core_schema({'type': 'function'})\n\n\ndef test_try_self_schema_discriminator():\n    \"\"\"Trying to use self-schema when it shouldn't be used\"\"\"\n    v = SchemaValidator({'type': 'tagged-union', 'choices': {'int': {'type': 'int'}}, 'discriminator': 'self-schema'})\n    assert 'discriminator: LookupKey' in repr(v)\n\n\ndef test_build_recursive_schema_from_defs() -> None:\n    \"\"\"\n    Validate a schema representing mutually recursive models, analogous to the following JSON schema:\n\n    ```json\n    {\n        \"$schema\": \"https://json-schema.org/draft/2019-09/schema\",\n        \"oneOf\": [{\"$ref\": \"#/$defs/a\"}],\n        \"$defs\": {\n            \"a\": {\n                \"type\": \"object\",\n                \"properties\": {\"b\": {\"type\": \"array\", \"items\": {\"$ref\": \"#/$defs/a\"}}},\n                \"required\": [\"b\"],\n            },\n            \"b\": {\n                \"type\": \"object\",\n                \"properties\": {\"a\": {\"type\": \"array\", \"items\": {\"$ref\": \"#/$defs/b\"}}},\n                \"required\": [\"a\"],\n            },\n        },\n    }\n    ```\n    \"\"\"\n\n    s = cs.definitions_schema(\n        cs.definition_reference_schema(schema_ref='a'),\n        [\n            cs.typed_dict_schema(\n                {'b': cs.typed_dict_field(cs.list_schema(cs.definition_reference_schema('b')))}, ref='a'\n            ),\n            cs.typed_dict_schema(\n                {'a': cs.typed_dict_field(cs.list_schema(cs.definition_reference_schema('a')))}, ref='b'\n            ),\n        ],\n    )\n\n    SchemaValidator(s)\n", "tests/test_validation_context.py": "import pytest\n\nfrom pydantic_core import SchemaValidator, ValidationError, core_schema\n\nfrom .conftest import PyAndJson\n\n\ndef test_after(py_and_json: PyAndJson):\n    def f(input_value, info):\n        return input_value + f'| context: {info.context}'\n\n    v = py_and_json(core_schema.with_info_after_validator_function(f, core_schema.str_schema()))\n\n    assert v.validate_test('foobar') == 'foobar| context: None'\n    assert v.validate_test('foobar', None, {1: 10}) == 'foobar| context: {1: 10}'\n    assert v.validate_test('foobar', None, 'frogspawn') == 'foobar| context: frogspawn'\n\n\ndef test_mutable_context(py_and_json: PyAndJson):\n    def f(input_value, info):\n        info.context['foo'] = input_value\n        return input_value\n\n    v = py_and_json(core_schema.with_info_before_validator_function(f, core_schema.str_schema()))\n    mutable_context = {}\n    assert v.validate_test('foobar', None, mutable_context) == 'foobar'\n    assert mutable_context == {'foo': 'foobar'}\n\n\ndef test_typed_dict(py_and_json: PyAndJson):\n    def f1(input_value, info):\n        info.context['f1'] = input_value\n        return input_value + f'| context: {info.context}'\n\n    def f2(input_value, info):\n        info.context['f2'] = input_value\n        return input_value + f'| context: {info.context}'\n\n    v = py_and_json(\n        core_schema.typed_dict_schema(\n            {\n                'f1': core_schema.typed_dict_field(core_schema.with_info_plain_validator_function(f1)),\n                'f2': core_schema.typed_dict_field(core_schema.with_info_plain_validator_function(f2)),\n            }\n        )\n    )\n\n    assert v.validate_test({'f1': '1', 'f2': '2'}, None, {'x': 'y'}) == {\n        'f1': \"1| context: {'x': 'y', 'f1': '1'}\",\n        'f2': \"2| context: {'x': 'y', 'f1': '1', 'f2': '2'}\",\n    }\n\n\ndef test_wrap(py_and_json: PyAndJson):\n    def f(input_value, validator, info):\n        return validator(input_value) + f'| context: {info.context}'\n\n    v = py_and_json(core_schema.with_info_wrap_validator_function(f, core_schema.str_schema()))\n\n    assert v.validate_test('foobar') == 'foobar| context: None'\n    assert v.validate_test('foobar', None, {1: 10}) == 'foobar| context: {1: 10}'\n    assert v.validate_test('foobar', None, 'frogspawn') == 'foobar| context: frogspawn'\n\n\ndef test_isinstance(py_and_json: PyAndJson):\n    def f(input_value, validator, info):\n        if 'error' in info.context:\n            raise ValueError('wrong')\n        return validator(input_value)\n\n    v = py_and_json(core_schema.with_info_wrap_validator_function(f, core_schema.str_schema()))\n\n    assert v.validate_python('foobar', None, {}) == 'foobar'\n\n    # internal error!, use generic bit of error message to match both cpython and pypy\n    with pytest.raises(TypeError, match='is not iterable'):\n        v.validate_test('foobar')\n\n    with pytest.raises(TypeError, match='is not iterable'):\n        v.isinstance_test('foobar')\n\n    with pytest.raises(ValidationError, match=r'Value error, wrong \\[type=value_error,'):\n        v.validate_test('foobar', None, {'error'})\n\n    assert v.isinstance_test('foobar', None, {}) is True\n\n    with pytest.raises(TypeError, match='is not iterable'):\n        v.isinstance_test('foobar')\n\n    assert v.isinstance_test('foobar', None, {'error'}) is False\n\n\ndef test_validate_assignment_with_context():\n    def f1(input_value, info):\n        info.context['f1'] = input_value\n        return input_value + f'| context: {info.context}'\n\n    def f2(input_value, info):\n        info.context['f2'] = input_value\n        return input_value + f'| context: {info.context}'\n\n    v = SchemaValidator(\n        core_schema.model_fields_schema(\n            {\n                'f1': core_schema.model_field(core_schema.with_info_plain_validator_function(f1)),\n                'f2': core_schema.model_field(core_schema.with_info_plain_validator_function(f2)),\n            }\n        )\n    )\n\n    m1, model_extra, fields_set = v.validate_python({'f1': '1', 'f2': '2'}, strict=None, context={'x': 'y'})\n    assert m1 == {'f1': \"1| context: {'x': 'y', 'f1': '1'}\", 'f2': \"2| context: {'x': 'y', 'f1': '1', 'f2': '2'}\"}\n    assert model_extra is None\n    assert fields_set == {'f1', 'f2'}\n\n    m2, model_extra, fields_set = v.validate_assignment(m1, 'f1', '3', context={'x': 'y'})\n    assert m2 == {'f1': \"3| context: {'x': 'y', 'f1': '3'}\", 'f2': \"2| context: {'x': 'y', 'f1': '1', 'f2': '2'}\"}\n    assert model_extra is None\n    assert fields_set == {'f1'}\n", "tests/conftest.py": "from __future__ import annotations as _annotations\n\nimport functools\nimport importlib.util\nimport json\nimport os\nimport re\nfrom dataclasses import dataclass\nfrom pathlib import Path\nfrom typing import Any, Type\n\nimport hypothesis\nimport pytest\nfrom typing_extensions import Literal\n\nfrom pydantic_core import ArgsKwargs, SchemaValidator, ValidationError, validate_core_schema\nfrom pydantic_core.core_schema import CoreConfig\n\n__all__ = 'Err', 'PyAndJson', 'plain_repr', 'infinite_generator'\n\nhypothesis.settings.register_profile('fast', max_examples=2)\nhypothesis.settings.register_profile('slow', max_examples=1_000)\nhypothesis.settings.load_profile(os.getenv('HYPOTHESIS_PROFILE', 'fast'))\n\n\ndef plain_repr(obj):\n    r = repr(obj)\n    r = re.sub(r',\\s*([)}])', r'\\1', r)\n    r = re.sub(r'\\s+', '', r)\n    return r\n\n\n@dataclass\nclass Err:\n    message: str\n    errors: Any | None = None\n\n    def __repr__(self):\n        if self.errors:\n            return f'Err({self.message!r}, errors={self.errors!r})'\n        else:\n            return f'Err({self.message!r})'\n\n\ndef json_default(obj):\n    if isinstance(obj, ArgsKwargs):\n        raise pytest.skip('JSON skipping ArgsKwargs')\n    else:\n        raise TypeError(f'Object of type {type(obj).__name__} is not JSON serializable')\n\n\nclass PyAndJsonValidator:\n    def __init__(\n        self, schema, config: CoreConfig | None = None, *, validator_type: Literal['json', 'python'] | None = None\n    ):\n        self.validator = SchemaValidator(validate_core_schema(schema), config)\n        self.validator_type = validator_type\n\n    def validate_python(self, py_input, strict: bool | None = None, context: Any = None):\n        return self.validator.validate_python(py_input, strict=strict, context=context)\n\n    def validate_json(self, json_str: str, strict: bool | None = None, context: Any = None):\n        return self.validator.validate_json(json_str, strict=strict, context=context)\n\n    def validate_test(self, py_input, strict: bool | None = None, context: Any = None):\n        if self.validator_type == 'json':\n            return self.validator.validate_json(\n                json.dumps(py_input, default=json_default), strict=strict, context=context\n            )\n        else:\n            assert self.validator_type == 'python', self.validator_type\n            return self.validator.validate_python(py_input, strict=strict, context=context)\n\n    def isinstance_test(self, py_input, strict: bool | None = None, context: Any = None):\n        if self.validator_type == 'json':\n            try:\n                self.validator.validate_json(json.dumps(py_input), strict=strict, context=context)\n                return True\n            except ValidationError:\n                return False\n        else:\n            assert self.validator_type == 'python', self.validator_type\n            return self.validator.isinstance_python(py_input, strict=strict, context=context)\n\n\nPyAndJson = Type[PyAndJsonValidator]\n\n\n@pytest.fixture(params=['python', 'json'])\ndef py_and_json(request) -> PyAndJson:\n    class ChosenPyAndJsonValidator(PyAndJsonValidator):\n        __init__ = functools.partialmethod(PyAndJsonValidator.__init__, validator_type=request.param)\n\n    return ChosenPyAndJsonValidator\n\n\nclass StrictModeType:\n    def __init__(self, schema: bool, extra: bool):\n        assert schema or extra\n        self.schema = schema\n        self.validator_args = {'strict': True} if extra else {}\n\n\n@pytest.fixture(\n    params=[\n        StrictModeType(schema=True, extra=False),\n        StrictModeType(schema=False, extra=True),\n        StrictModeType(schema=True, extra=True),\n    ],\n    ids=['strict-schema', 'strict-extra', 'strict-both'],\n)\ndef strict_mode_type(request) -> StrictModeType:\n    return request.param\n\n\n@pytest.fixture\ndef tmp_work_path(tmp_path: Path):\n    \"\"\"\n    Create a temporary working directory.\n    \"\"\"\n    previous_cwd = Path.cwd()\n    os.chdir(tmp_path)\n\n    yield tmp_path\n\n    os.chdir(previous_cwd)\n\n\n@pytest.fixture\ndef import_execute(request, tmp_work_path: Path):\n    def _import_execute(source: str, *, custom_module_name: 'str | None' = None):\n        module_name = custom_module_name or request.node.name\n\n        module_path = tmp_work_path / f'{module_name}.py'\n        module_path.write_text(source)\n        spec = importlib.util.spec_from_file_location('__main__', str(module_path))\n        module = importlib.util.module_from_spec(spec)\n        try:\n            spec.loader.exec_module(module)\n        except KeyboardInterrupt:\n            print('KeyboardInterrupt')\n        else:\n            return module\n\n    return _import_execute\n\n\n@pytest.fixture\ndef pydantic_version():\n    try:\n        import pydantic\n\n        # include major and minor version only\n        return '.'.join(pydantic.__version__.split('.')[:2])\n    except ImportError:\n        return 'latest'\n\n\ndef infinite_generator():\n    i = 0\n    while True:\n        yield i\n        i += 1\n", "tests/test_typing.py": "from __future__ import annotations as _annotations\n\nfrom datetime import date, datetime, time\nfrom typing import Any, Callable\n\nfrom pydantic_core import (\n    CoreSchema,\n    ErrorDetails,\n    PydanticKnownError,\n    SchemaError,\n    SchemaSerializer,\n    SchemaValidator,\n    ValidationError,\n    core_schema,\n)\n\n\nclass Foo:\n    bar: str\n\n\ndef foo(bar: str) -> None: ...\n\n\ndef validator_deprecated(value: Any, info: core_schema.FieldValidationInfo) -> None: ...\n\n\ndef validator(value: Any, info: core_schema.ValidationInfo) -> None: ...\n\n\ndef wrap_validator(value: Any, call_next: Callable[[Any], Any], info: core_schema.ValidationInfo) -> None: ...\n\n\ndef test_schema_typing() -> None:\n    # this gets run by pyright, but we also check that it executes\n    schema: CoreSchema = {\n        'type': 'union',\n        'choices': [{'type': 'int'}, {'type': 'int', 'ge': 1}, {'type': 'float', 'lt': 1.0}],\n    }\n    SchemaValidator(schema)\n    schema: CoreSchema = {\n        'type': 'tagged-union',\n        'discriminator': 'type',\n        'choices': {\n            'apple': {\n                'type': 'typed-dict',\n                'fields': {'pips': {'type': 'typed-dict-field', 'schema': {'type': 'int'}}},\n            },\n            'banana': {\n                'type': 'typed-dict',\n                'fields': {'curvature': {'type': 'typed-dict-field', 'schema': {'type': 'float'}}},\n            },\n        },\n    }\n    SchemaValidator(schema)\n    schema: CoreSchema = {'type': 'int', 'ge': 1}\n    SchemaValidator(schema)\n    schema: CoreSchema = {'type': 'float', 'lt': 1.0}\n    SchemaValidator(schema)\n    schema: CoreSchema = {'type': 'str', 'pattern': r'http://.*'}\n    SchemaValidator(schema)\n    schema: CoreSchema = {'type': 'bool', 'strict': False}\n    SchemaValidator(schema)\n    schema: CoreSchema = {'type': 'literal', 'expected': [1, '1']}\n    SchemaValidator(schema)\n    schema: CoreSchema = {'type': 'any'}\n    SchemaValidator(schema)\n    schema: CoreSchema = {'type': 'none'}\n    SchemaValidator(schema)\n    schema: CoreSchema = {'type': 'bytes'}\n    SchemaValidator(schema)\n    schema: CoreSchema = {'type': 'list', 'items_schema': {'type': 'str'}, 'min_length': 3}\n    SchemaValidator(schema)\n    schema: CoreSchema = {'type': 'set', 'items_schema': {'type': 'str'}, 'max_length': 3}\n    SchemaValidator(schema)\n    schema: CoreSchema = {'type': 'tuple', 'items_schema': [{'type': 'str'}], 'variadic_item_index': 0, 'max_length': 3}\n    SchemaValidator(schema)\n    schema: CoreSchema = {'type': 'tuple', 'items_schema': [{'type': 'str'}, {'type': 'int'}]}\n    SchemaValidator(schema)\n    schema: CoreSchema = {'type': 'frozenset', 'items_schema': {'type': 'str'}, 'max_length': 3}\n    SchemaValidator(schema)\n    schema: CoreSchema = {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}\n    SchemaValidator(schema)\n    schema: CoreSchema = {\n        'type': 'typed-dict',\n        'fields': {'bar': {'type': 'typed-dict-field', 'schema': {'type': 'str'}}},\n    }\n    SchemaValidator(schema)\n    schema: CoreSchema = {\n        'type': 'model',\n        'cls': Foo,\n        'schema': {'type': 'model-fields', 'fields': {'bar': {'type': 'model-field', 'schema': {'type': 'str'}}}},\n    }\n    SchemaValidator(schema)\n    schema: CoreSchema = {\n        'type': 'typed-dict',\n        'fields': {\n            'a': {'type': 'typed-dict-field', 'schema': {'type': 'str'}},\n            'b': {'type': 'typed-dict-field', 'schema': {'type': 'str'}, 'validation_alias': 'foobar'},\n            'c': {\n                'type': 'typed-dict-field',\n                'schema': {'type': 'str'},\n                'validation_alias': [['foobar', 0, 'bar'], ['foo']],\n            },\n            'd': {\n                'type': 'typed-dict-field',\n                'schema': {'type': 'default', 'schema': {'type': 'str'}, 'default': 'spam'},\n            },\n        },\n    }\n    SchemaValidator(schema)\n    schema: CoreSchema = {\n        'type': 'function-wrap',\n        'function': {'type': 'with-info', 'function': wrap_validator, 'field_name': 'foobar'},\n        'schema': {'type': 'str'},\n    }\n    SchemaValidator(schema)\n    schema: CoreSchema = core_schema.with_info_plain_validator_function(validator)\n    SchemaValidator(schema)\n    schema: CoreSchema = {\n        'type': 'definitions',\n        'schema': {'type': 'definition-ref', 'schema_ref': 'Branch'},\n        'definitions': [\n            {\n                'type': 'typed-dict',\n                'fields': {\n                    'name': {'type': 'typed-dict-field', 'schema': {'type': 'str'}},\n                    'sub_branch': {\n                        'type': 'typed-dict-field',\n                        'schema': {\n                            'type': 'default',\n                            'schema': {\n                                'type': 'nullable',\n                                'schema': {'type': 'definition-ref', 'schema_ref': 'Branch'},\n                            },\n                            'default': None,\n                        },\n                    },\n                },\n                'ref': 'Branch',\n            }\n        ],\n    }\n    SchemaValidator(schema)\n    schema: CoreSchema = {'type': 'date', 'le': date.today()}\n    SchemaValidator(schema)\n    schema: CoreSchema = {'type': 'time', 'lt': time(12, 13, 14)}\n    SchemaValidator(schema)\n    schema: CoreSchema = {'type': 'datetime', 'ge': datetime.now()}\n    SchemaValidator(schema)\n    schema: CoreSchema = {'type': 'is-instance', 'cls': Foo}\n    SchemaValidator(schema)\n    schema: CoreSchema = {'type': 'callable'}\n    SchemaValidator(schema)\n\n    schema: CoreSchema = {\n        'type': 'arguments',\n        'arguments_schema': [\n            {'name': 'a', 'mode': 'positional_only', 'schema': {'type': 'int'}},\n            {'name': 'b', 'schema': {'type': 'str'}},\n            {'name': 'c', 'mode': 'keyword_only', 'schema': {'type': 'bool'}},\n        ],\n    }\n    SchemaValidator(schema)\n\n    schema: CoreSchema = {'type': 'call', 'arguments_schema': {'type': 'any'}, 'function': foo}\n    SchemaValidator(schema)\n\n\ndef test_schema_typing_error() -> None:\n    _: CoreSchema = {'type': 'wrong'}  # type: ignore\n\n\ndef test_schema_validator() -> None:\n    SchemaValidator({'type': 'int'})\n\n\ndef test_schema_validator_wrong() -> None:\n    # use this instead of pytest.raises since pyright complains about input when pytest isn't installed\n    try:\n        SchemaValidator({'type': 'bad'})  # type: ignore\n    except SchemaError:\n        pass\n    else:\n        raise AssertionError('SchemaValidator did not raise SchemaError')\n\n\ndef test_correct_function_signature() -> None:\n    def my_validator(value: Any, info: Any) -> str:\n        return str(value)\n\n    v = SchemaValidator(core_schema.with_info_plain_validator_function(my_validator))\n    assert v.validate_python(1) == '1'\n\n\ndef test_wrong_function_signature() -> None:\n    def wrong_validator(value: Any) -> Any:\n        return value\n\n    v = SchemaValidator(core_schema.with_info_plain_validator_function(wrong_validator))  # type: ignore\n\n    # use this instead of pytest.raises since pyright complains about input when pytest isn't installed\n    try:\n        v.validate_python(1)\n    except TypeError as exc:\n        assert 'takes 1 positional argument but 2 were given' in str(exc)\n    else:\n        raise AssertionError('v.validate_python(1) did not raise TypeError')\n\n\ndef test_type_error():\n    try:\n        PydanticKnownError('foobar')  # type: ignore\n    except KeyError as exc:\n        assert str(exc) == '\"Invalid error type: \\'foobar\\'\"'\n    else:\n        raise AssertionError(\"PydanticKnownError('foobar') did not raise KeyError\")\n\n    e = PydanticKnownError('recursion_loop')\n    assert isinstance(e, PydanticKnownError)\n\n\ndef test_ser_function_plain():\n    def f(input: Any, info: core_schema.SerializationInfo, /) -> str:\n        return str(info)\n\n    s = SchemaSerializer(\n        core_schema.any_schema(\n            serialization=core_schema.plain_serializer_function_ser_schema(\n                f, info_arg=True, return_schema=core_schema.str_schema()\n            )\n        )\n    )\n    assert s.to_python(123) == (\n        \"SerializationInfo(include=None, exclude=None, context=None, mode='python', by_alias=True, exclude_unset=False, \"\n        'exclude_defaults=False, exclude_none=False, round_trip=False, serialize_as_any=False)'\n    )\n\n\ndef test_ser_function_wrap():\n    def f(\n        input: Any, serialize: core_schema.SerializerFunctionWrapHandler, info: core_schema.SerializationInfo, /\n    ) -> str:\n        return f'{serialize} {info}'\n\n    s = SchemaSerializer(\n        core_schema.any_schema(\n            serialization=core_schema.wrap_serializer_function_ser_schema(\n                f, info_arg=True, schema=core_schema.str_schema(), when_used='json'\n            )\n        )\n    )\n    # insert_assert(s.to_python(123, mode='json'))\n    assert s.to_python(123, mode='json') == (\n        'SerializationCallable(serializer=str) '\n        \"SerializationInfo(include=None, exclude=None, context=None, mode='json', by_alias=True, exclude_unset=False, \"\n        'exclude_defaults=False, exclude_none=False, round_trip=False, serialize_as_any=False)'\n    )\n\n\ndef test_error_details() -> None:\n    # Test that the ErrorDetails type is correctly exported.\n    def act_on_error_details(_: ErrorDetails) -> None:\n        pass\n\n    v = SchemaValidator({'type': 'int'})\n\n    try:\n        v.validate_python('not an int')\n    except ValidationError as err:\n        for details in err.errors(include_url=False):\n            act_on_error_details(details)\n", "tests/test_docstrings.py": "import sys\n\nimport pytest\n\ntry:\n    from pytest_examples import CodeExample, EvalExample, find_examples\nexcept ImportError:\n    # pytest_examples is not installed on emscripten\n    CodeExample = EvalExample = None\n\n    def find_examples(*_directories):\n        return []\n\n\n@pytest.mark.skipif(CodeExample is None or sys.platform not in {'linux', 'darwin'}, reason='Only on linux and macos')\n@pytest.mark.parametrize('example', find_examples('python/pydantic_core/core_schema.py'), ids=str)\ndef test_docstrings(example: CodeExample, eval_example: EvalExample):\n    eval_example.set_config(quotes='single')\n\n    if eval_example.update_examples:\n        eval_example.format(example)\n        eval_example.run_print_update(example)\n    else:\n        eval_example.lint(example)\n        eval_example.run_print_check(example)\n\n\n@pytest.mark.skipif(CodeExample is None or sys.platform not in {'linux', 'darwin'}, reason='Only on linux and macos')\n@pytest.mark.parametrize('example', find_examples('README.md'), ids=str)\ndef test_readme(example: CodeExample, eval_example: EvalExample):\n    eval_example.set_config(line_length=100, quotes='single')\n    if eval_example.update_examples:\n        eval_example.format(example)\n    else:\n        eval_example.lint(example)\n        eval_example.run(example)\n", "tests/__init__.py": "", "tests/test_tzinfo.py": "import copy\nimport functools\nimport pickle\nimport sys\nimport unittest\nfrom datetime import datetime, timedelta, timezone, tzinfo\n\nfrom pydantic_core import SchemaValidator, TzInfo, core_schema\n\nif sys.version_info >= (3, 9):\n    from zoneinfo import ZoneInfo, ZoneInfoNotFoundError\n\n\nclass _ALWAYS_EQ:\n    \"\"\"\n    Object that is equal to anything.\n    \"\"\"\n\n    def __eq__(self, other):\n        return True\n\n    def __ne__(self, other):\n        return False\n\n\nALWAYS_EQ = _ALWAYS_EQ()\n\n\n@functools.total_ordering\nclass _LARGEST:\n    \"\"\"\n    Object that is greater than anything (except itself).\n    \"\"\"\n\n    def __eq__(self, other):\n        return isinstance(other, _LARGEST)\n\n    def __lt__(self, other):\n        return False\n\n\nLARGEST = _LARGEST()\n\n\n@functools.total_ordering\nclass _SMALLEST:\n    \"\"\"\n    Object that is less than anything (except itself).\n    \"\"\"\n\n    def __eq__(self, other):\n        return isinstance(other, _SMALLEST)\n\n    def __gt__(self, other):\n        return False\n\n\nSMALLEST = _SMALLEST()\n\n\npickle_choices = [(pickle, pickle, proto) for proto in range(pickle.HIGHEST_PROTOCOL + 1)]\n\nHOUR = timedelta(hours=1).total_seconds()\nZERO = timedelta(0).total_seconds()\n\n\ndef first_sunday_on_or_after(dt):\n    days_to_go = 6 - dt.weekday()\n    if days_to_go:\n        dt += timedelta(days_to_go)\n    return dt\n\n\nDSTSTART = datetime(1, 4, 1, 2)\nDSTEND = datetime(1, 10, 25, 1)\n\n\nclass TestTzInfo(unittest.TestCase):\n    \"\"\"Adapted from CPython `timezone` tests\n\n    Original tests are located here https://github.com/python/cpython/blob/a0bb4a39d1ca10e4a75f50a9fbe90cc9db28d29e/Lib/test/datetimetester.py#L256\n    \"\"\"\n\n    def setUp(self):\n        self.ACDT = TzInfo(timedelta(hours=9.5).total_seconds())\n        self.EST = TzInfo(-timedelta(hours=5).total_seconds())\n        self.UTC = TzInfo(timedelta(0).total_seconds())\n        self.DT = datetime(2010, 1, 1)\n\n    def test_str(self):\n        for tz in [self.ACDT, self.EST]:\n            self.assertEqual(str(tz), tz.tzname(None))\n\n    def test_constructor(self):\n        for subminute in [timedelta(microseconds=1), timedelta(seconds=1)]:\n            tz = TzInfo(subminute.total_seconds())\n            self.assertNotEqual(tz.utcoffset(None) % timedelta(minutes=1), 0)\n        # invalid offsets\n        for invalid in [timedelta(1, 1), timedelta(1)]:\n            self.assertRaises(ValueError, TzInfo, invalid.total_seconds())\n            self.assertRaises(ValueError, TzInfo, -invalid.total_seconds())\n\n        with self.assertRaises(TypeError):\n            TzInfo(None)\n        with self.assertRaises(TypeError):\n            TzInfo(timedelta(seconds=42))\n        with self.assertRaises(TypeError):\n            TzInfo(ZERO, None)\n        with self.assertRaises(TypeError):\n            TzInfo(ZERO, 42)\n        with self.assertRaises(TypeError):\n            TzInfo(ZERO, 'ABC', 'extra')\n\n    def test_inheritance(self):\n        self.assertIsInstance(self.EST, tzinfo)\n\n    def test_utcoffset(self):\n        dummy = self.DT\n        for h in [0, 1.5, 12]:\n            offset = h * HOUR\n            self.assertEqual(timedelta(seconds=offset), TzInfo(offset).utcoffset(dummy))\n            self.assertEqual(timedelta(seconds=-offset), TzInfo(-offset).utcoffset(dummy))\n\n        self.assertEqual(self.EST.utcoffset(''), timedelta(hours=-5))\n        self.assertEqual(self.EST.utcoffset(5), timedelta(hours=-5))\n\n    def test_dst(self):\n        self.EST.dst('') is None\n        self.EST.dst(5) is None\n\n    def test_tzname(self):\n        self.assertEqual('-05:00', TzInfo(-5 * HOUR).tzname(None))\n        self.assertEqual('+09:30', TzInfo(9.5 * HOUR).tzname(None))\n        self.assertEqual('-00:01', TzInfo(timedelta(minutes=-1).total_seconds()).tzname(None))\n        # Sub-minute offsets:\n        self.assertEqual('+01:06:40', TzInfo(timedelta(0, 4000).total_seconds()).tzname(None))\n        self.assertEqual('-01:06:40', TzInfo(-timedelta(0, 4000).total_seconds()).tzname(None))\n        self.assertEqual('+01:06:40', TzInfo(timedelta(0, 4000, 1).total_seconds()).tzname(None))\n        self.assertEqual('-01:06:40', TzInfo(-timedelta(0, 4000, 1).total_seconds()).tzname(None))\n\n        self.assertEqual(self.EST.tzname(''), '-05:00')\n        self.assertEqual(self.EST.tzname(5), '-05:00')\n\n    def test_fromutc(self):\n        for tz in [self.EST, self.ACDT]:\n            utctime = self.DT.replace(tzinfo=tz)\n            local = tz.fromutc(utctime)\n            self.assertEqual(local - utctime, tz.utcoffset(local))\n            self.assertEqual(local, self.DT.replace(tzinfo=timezone.utc))\n\n    def test_comparison(self):\n        self.assertNotEqual(TzInfo(ZERO), TzInfo(HOUR))\n        self.assertEqual(TzInfo(HOUR), TzInfo(HOUR))\n        self.assertFalse(TzInfo(ZERO) < TzInfo(ZERO))\n        self.assertIn(TzInfo(ZERO), {TzInfo(ZERO)})\n        self.assertTrue(TzInfo(ZERO) is not None)\n        self.assertFalse(TzInfo(ZERO) is None)\n\n        tz = TzInfo(ZERO)\n        self.assertTrue(tz == ALWAYS_EQ)\n        self.assertFalse(tz != ALWAYS_EQ)\n        self.assertTrue(tz < LARGEST)\n        self.assertFalse(tz > LARGEST)\n        self.assertTrue(tz <= LARGEST)\n        self.assertFalse(tz >= LARGEST)\n        self.assertFalse(tz < SMALLEST)\n        self.assertTrue(tz > SMALLEST)\n        self.assertFalse(tz <= SMALLEST)\n        self.assertTrue(tz >= SMALLEST)\n\n        # offset based comparion tests for tzinfo derived classes like datetime.timezone.\n        utcdatetime = self.DT.replace(tzinfo=timezone.utc)\n        self.assertTrue(tz == utcdatetime.tzinfo)\n        estdatetime = self.DT.replace(tzinfo=timezone(-timedelta(hours=5)))\n        self.assertTrue(self.EST == estdatetime.tzinfo)\n        self.assertTrue(tz > estdatetime.tzinfo)\n\n        if sys.version_info >= (3, 9) and sys.platform == 'linux':\n            try:\n                europe_london = ZoneInfo('Europe/London')\n            except ZoneInfoNotFoundError:\n                # tz data not available\n                pass\n            else:\n                self.assertFalse(tz == europe_london)\n                with self.assertRaises(TypeError):\n                    tz > europe_london\n\n    def test_copy(self):\n        for tz in self.ACDT, self.EST:\n            tz_copy = copy.copy(tz)\n            self.assertEqual(tz_copy, tz)\n\n    def test_deepcopy(self):\n        for tz in self.ACDT, self.EST:\n            tz_copy = copy.deepcopy(tz)\n            self.assertEqual(tz_copy, tz)\n\n    def test_offset_boundaries(self):\n        # Test timedeltas close to the boundaries\n        time_deltas = [timedelta(hours=23, minutes=59), timedelta(hours=23, minutes=59, seconds=59)]\n        time_deltas.extend([-delta for delta in time_deltas])\n\n        for delta in time_deltas:\n            with self.subTest(test_type='good', delta=delta):\n                print(delta.total_seconds())\n                TzInfo(delta.total_seconds())\n\n        # Test timedeltas on and outside the boundaries\n        bad_time_deltas = [timedelta(hours=24), timedelta(hours=24, microseconds=1)]\n        bad_time_deltas.extend([-delta for delta in bad_time_deltas])\n\n        for delta in bad_time_deltas:\n            with self.subTest(test_type='bad', delta=delta):\n                with self.assertRaises(ValueError):\n                    TzInfo(delta.total_seconds())\n\n\ndef test_tzinfo_could_be_reused():\n    class Model:\n        value: datetime\n\n    v = SchemaValidator(\n        core_schema.model_schema(\n            Model, core_schema.model_fields_schema({'value': core_schema.model_field(core_schema.datetime_schema())})\n        )\n    )\n\n    m = v.validate_python({'value': '2015-10-21T15:28:00.000000+01:00'})\n\n    target = datetime(1955, 11, 12, 14, 38, tzinfo=m.value.tzinfo)\n    assert target == datetime(1955, 11, 12, 14, 38, tzinfo=timezone(timedelta(hours=1)))\n\n    now = datetime.now(tz=m.value.tzinfo)\n    assert isinstance(now, datetime)\n", "tests/test_strict.py": "from __future__ import annotations\n\nimport re\nfrom typing import Any\n\nimport pytest\n\nfrom pydantic_core import ValidationError\n\nfrom .conftest import Err, PyAndJson\n\n\n@pytest.mark.parametrize(\n    'strict_to_validator,strict_in_schema,input_value,expected',\n    [\n        (False, False, 123, 123),\n        (False, False, '123', 123),\n        (None, False, 123, 123),\n        (None, False, '123', 123),\n        (True, False, 123, 123),\n        (True, False, '123', Err('Input should be a valid integer [type=int_type')),\n        (False, True, 123, 123),\n        (False, True, '123', 123),\n        (None, True, 123, 123),\n        (None, True, '123', Err('Input should be a valid integer [type=int_type')),\n        (True, True, 123, 123),\n        (True, True, '123', Err('Input should be a valid integer [type=int_type')),\n        (False, None, 123, 123),\n        (False, None, '123', 123),\n        (None, None, 123, 123),\n        (None, None, '123', 123),\n        (True, None, 123, 123),\n        (True, None, '123', Err('Input should be a valid integer [type=int_type')),\n    ],\n)\ndef test_int_strict_argument(\n    py_and_json: PyAndJson, strict_to_validator: bool | None, strict_in_schema: bool | None, input_value, expected\n):\n    schema: dict[str, Any] = {'type': 'int'}\n    if strict_in_schema is not None:\n        schema['strict'] = strict_in_schema\n    v = py_and_json(schema)\n    if isinstance(expected, Err):\n        assert v.isinstance_test(input_value, strict_to_validator) is False\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_test(input_value, strict_to_validator)\n    else:\n        assert v.isinstance_test(input_value, strict_to_validator) is True\n        assert v.validate_test(input_value, strict_to_validator) == expected\n", "tests/test_json.py": "import json\nimport platform\nimport re\nfrom typing import List\n\nimport pytest\nfrom dirty_equals import IsFloatNan, IsList\n\nimport pydantic_core\nfrom pydantic_core import (\n    PydanticSerializationError,\n    SchemaSerializer,\n    SchemaValidator,\n    ValidationError,\n    core_schema,\n    from_json,\n    to_json,\n    to_jsonable_python,\n)\n\nfrom .conftest import Err\n\n\n@pytest.mark.parametrize(\n    'input_value,output_value',\n    [('false', False), ('true', True), ('0', False), ('1', True), ('\"yes\"', True), ('\"no\"', False)],\n)\ndef test_bool(input_value, output_value):\n    v = SchemaValidator({'type': 'bool'})\n    assert v.validate_json(input_value) == output_value\n\n\n@pytest.mark.parametrize('input_value', ['[1, 2, 3]', b'[1, 2, 3]', bytearray(b'[1, 2, 3]')])\ndef test_input_types(input_value):\n    v = SchemaValidator({'type': 'list', 'items_schema': {'type': 'int'}})\n    assert v.validate_json(input_value) == [1, 2, 3]\n\n\ndef test_input_type_invalid():\n    v = SchemaValidator({'type': 'list', 'items_schema': {'type': 'int'}})\n    with pytest.raises(ValidationError, match=r'JSON input should be string, bytes or bytearray \\[type=json_type,'):\n        v.validate_json([])\n\n\ndef test_null():\n    assert SchemaValidator({'type': 'none'}).validate_json('null') is None\n\n\ndef test_str():\n    s = SchemaValidator({'type': 'str'})\n    assert s.validate_json('\"foobar\"') == 'foobar'\n    with pytest.raises(ValidationError, match=r'Input should be a valid string \\[type=string_type,'):\n        s.validate_json('false')\n    with pytest.raises(ValidationError, match=r'Input should be a valid string \\[type=string_type,'):\n        s.validate_json('123')\n\n\ndef test_bytes():\n    s = SchemaValidator({'type': 'bytes'})\n    assert s.validate_json('\"foobar\"') == b'foobar'\n    with pytest.raises(ValidationError, match=r'Input should be a valid bytes \\[type=bytes_type,'):\n        s.validate_json('false')\n    with pytest.raises(ValidationError, match=r'Input should be a valid bytes \\[type=bytes_type,'):\n        s.validate_json('123')\n\n\n# A number well outside of i64 range\n_BIG_NUMBER_STR = '1' + ('0' * 40)\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ('123', 123),\n        ('\"123\"', 123),\n        ('123.0', 123),\n        ('\"123.0\"', 123),\n        (_BIG_NUMBER_STR, int(_BIG_NUMBER_STR)),\n        ('123.4', Err('Input should be a valid integer, got a number with a fractional part [type=int_from_float,')),\n        ('\"123.4\"', Err('Input should be a valid integer, unable to parse string as an integer [type=int_parsing,')),\n        ('\"string\"', Err('Input should be a valid integer, unable to parse string as an integer [type=int_parsing,')),\n    ],\n)\ndef test_int(input_value, expected):\n    v = SchemaValidator({'type': 'int'})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_json(input_value)\n    else:\n        assert v.validate_json(input_value) == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ('123.4', 123.4),\n        ('123.0', 123.0),\n        ('123', 123.0),\n        ('\"123.4\"', 123.4),\n        ('\"123.0\"', 123.0),\n        ('\"123\"', 123.0),\n        ('\"string\"', Err('Input should be a valid number, unable to parse string as a number [type=float_parsing,')),\n    ],\n)\ndef test_float(input_value, expected):\n    v = SchemaValidator({'type': 'float'})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_json(input_value)\n    else:\n        assert v.validate_json(input_value) == expected\n\n\ndef test_typed_dict():\n    v = SchemaValidator(\n        {\n            'type': 'typed-dict',\n            'fields': {\n                'field_a': {'type': 'typed-dict-field', 'schema': {'type': 'str'}},\n                'field_b': {'type': 'typed-dict-field', 'schema': {'type': 'int'}},\n            },\n        }\n    )\n\n    # language=json\n    input_str = '{\"field_a\": \"abc\", \"field_b\": 1}'\n    assert v.validate_json(input_str) == {'field_a': 'abc', 'field_b': 1}\n    # language=json\n    input_str = '{\"field_a\": \"a\", \"field_a\": \"b\", \"field_b\": 1}'\n    assert v.validate_json(input_str) == {'field_a': 'b', 'field_b': 1}\n    assert v.validate_json(input_str) == {'field_a': 'b', 'field_b': 1}\n\n\ndef test_float_no_remainder():\n    v = SchemaValidator({'type': 'int'})\n    assert v.validate_json('123.0') == 123\n\n\ndef test_error_loc():\n    v = SchemaValidator(\n        {\n            'type': 'typed-dict',\n            'fields': {\n                'field_a': {'type': 'typed-dict-field', 'schema': {'type': 'list', 'items_schema': {'type': 'int'}}}\n            },\n            'extras_schema': {'type': 'int'},\n            'extra_behavior': 'allow',\n        }\n    )\n\n    # assert v.validate_json('{\"field_a\": [1, 2, \"3\"]}') == ({'field_a': [1, 2, 3]}, {'field_a'})\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_json('{\"field_a\": [1, 2, \"wrong\"]}')\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'int_parsing',\n            'loc': ('field_a', 2),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'wrong',\n        }\n    ]\n\n\ndef test_dict():\n    v = SchemaValidator({'type': 'dict', 'keys_schema': {'type': 'int'}, 'values_schema': {'type': 'int'}})\n    assert v.validate_json('{\"1\": 2, \"3\": 4}') == {1: 2, 3: 4}\n\n    # duplicate keys, the last value wins, like with python\n    assert json.loads('{\"1\": 1, \"1\": 2}') == {'1': 2}\n    assert v.validate_json('{\"1\": 1, \"1\": 2}') == {1: 2}\n\n\ndef test_dict_any_value():\n    v = SchemaValidator({'type': 'dict', 'keys_schema': {'type': 'str'}})\n    assert v.validate_json('{\"1\": 1, \"2\": \"a\", \"3\": null}') == {'1': 1, '2': 'a', '3': None}\n\n\ndef test_json_invalid():\n    v = SchemaValidator({'type': 'bool'})\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_json('\"foobar')\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'json_invalid',\n            'loc': (),\n            'msg': 'Invalid JSON: EOF while parsing a string at line 1 column 7',\n            'input': '\"foobar',\n            'ctx': {'error': 'EOF while parsing a string at line 1 column 7'},\n        }\n    ]\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_json('[1,\\n2,\\n3,]')\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'json_invalid',\n            'loc': (),\n            'msg': 'Invalid JSON: trailing comma at line 3 column 3',\n            'input': '[1,\\n2,\\n3,]',\n            'ctx': {'error': 'trailing comma at line 3 column 3'},\n        }\n    ]\n\n\nclass Foobar:\n    def __str__(self):\n        return 'Foobar.__str__'\n\n\ndef fallback_func(v):\n    return f'fallback:{type(v).__name__}'\n\n\ndef test_to_json():\n    assert to_json([1, 2]) == b'[1,2]'\n    assert to_json([1, 2], indent=2) == b'[\\n  1,\\n  2\\n]'\n    assert to_json([1, b'x']) == b'[1,\"x\"]'\n\n    # kwargs required\n    with pytest.raises(TypeError, match=r'to_json\\(\\) takes 1 positional arguments but 2 were given'):\n        to_json([1, 2], 2)\n\n\ndef test_to_json_fallback():\n    with pytest.raises(PydanticSerializationError, match=r'Unable to serialize unknown type: <.+\\.Foobar'):\n        to_json(Foobar())\n\n    assert to_json(Foobar(), serialize_unknown=True) == b'\"Foobar.__str__\"'\n    assert to_json(Foobar(), serialize_unknown=True, fallback=fallback_func) == b'\"fallback:Foobar\"'\n    assert to_json(Foobar(), fallback=fallback_func) == b'\"fallback:Foobar\"'\n\n\ndef test_to_jsonable_python():\n    assert to_jsonable_python([1, 2]) == [1, 2]\n    assert to_jsonable_python({1, 2}) == IsList(1, 2, check_order=False)\n    assert to_jsonable_python([1, b'x']) == [1, 'x']\n    assert to_jsonable_python([0, 1, 2, 3, 4], exclude={1, 3}) == [0, 2, 4]\n\n\ndef test_to_jsonable_python_fallback():\n    with pytest.raises(PydanticSerializationError, match=r'Unable to serialize unknown type: <.+\\.Foobar'):\n        to_jsonable_python(Foobar())\n\n    assert to_jsonable_python(Foobar(), serialize_unknown=True) == 'Foobar.__str__'\n    assert to_jsonable_python(Foobar(), serialize_unknown=True, fallback=fallback_func) == 'fallback:Foobar'\n    assert to_jsonable_python(Foobar(), fallback=fallback_func) == 'fallback:Foobar'\n\n\ndef test_to_jsonable_python_schema_serializer():\n    class Foobar:\n        def __init__(self, my_foo: int, my_inners: List['Foobar']):\n            self.my_foo = my_foo\n            self.my_inners = my_inners\n\n    # force a recursive model to ensure we exercise the transfer of definitions from the loaded\n    # serializer\n    c = core_schema.definitions_schema(\n        core_schema.definition_reference_schema(schema_ref='foobar'),\n        [\n            core_schema.model_schema(\n                Foobar,\n                core_schema.typed_dict_schema(\n                    {\n                        'my_foo': core_schema.typed_dict_field(core_schema.int_schema(), serialization_alias='myFoo'),\n                        'my_inners': core_schema.typed_dict_field(\n                            core_schema.list_schema(core_schema.definition_reference_schema('foobar')),\n                            serialization_alias='myInners',\n                        ),\n                    }\n                ),\n                ref='foobar',\n            )\n        ],\n    )\n    v = SchemaValidator(c)\n    s = SchemaSerializer(c)\n\n    Foobar.__pydantic_validator__ = v\n    Foobar.__pydantic_serializer__ = s\n\n    instance = Foobar(my_foo=1, my_inners=[Foobar(my_foo=2, my_inners=[])])\n    assert to_jsonable_python(instance) == {'myFoo': 1, 'myInners': [{'myFoo': 2, 'myInners': []}]}\n    assert to_jsonable_python(instance, by_alias=False) == {'my_foo': 1, 'my_inners': [{'my_foo': 2, 'my_inners': []}]}\n    assert to_json(instance) == b'{\"myFoo\":1,\"myInners\":[{\"myFoo\":2,\"myInners\":[]}]}'\n    assert to_json(instance, by_alias=False) == b'{\"my_foo\":1,\"my_inners\":[{\"my_foo\":2,\"my_inners\":[]}]}'\n\n\ndef test_cycle_same():\n    def fallback_func_passthrough(obj):\n        return obj\n\n    f = Foobar()\n\n    with pytest.raises(ValueError, match=r'Circular reference detected \\(id repeated\\)'):\n        to_jsonable_python(f, fallback=fallback_func_passthrough)\n\n    with pytest.raises(ValueError, match=r'Circular reference detected \\(id repeated\\)'):\n        to_json(f, fallback=fallback_func_passthrough)\n\n\n@pytest.mark.skipif(\n    platform.python_implementation() == 'PyPy' and pydantic_core._pydantic_core.build_profile == 'debug',\n    reason='PyPy does not have enough stack space for Rust debug builds to recurse very deep',\n)\ndef test_cycle_change():\n    def fallback_func_change_id(obj):\n        return Foobar()\n\n    f = Foobar()\n\n    with pytest.raises(ValueError, match=r'Circular reference detected \\(depth exceeded\\)'):\n        to_jsonable_python(f, fallback=fallback_func_change_id)\n\n    with pytest.raises(ValueError, match=r'Circular reference detected \\(depth exceeded\\)'):\n        to_json(f, fallback=fallback_func_change_id)\n\n\nclass FoobarHash:\n    def __str__(self):\n        return 'Foobar.__str__'\n\n    def __hash__(self):\n        return 1\n\n\ndef test_json_key_fallback():\n    x = {FoobarHash(): 1}\n\n    assert to_jsonable_python(x, serialize_unknown=True) == {'Foobar.__str__': 1}\n    assert to_jsonable_python(x, fallback=fallback_func) == {'fallback:FoobarHash': 1}\n    assert to_json(x, serialize_unknown=True) == b'{\"Foobar.__str__\":1}'\n    assert to_json(x, fallback=fallback_func) == b'{\"fallback:FoobarHash\":1}'\n\n\nclass BedReprMeta(type):\n    def __repr__(self):\n        raise ValueError('bad repr')\n\n\nclass BadRepr(metaclass=BedReprMeta):\n    def __repr__(self):\n        raise ValueError('bad repr')\n\n    def __hash__(self):\n        return 1\n\n\ndef test_bad_repr():\n    b = BadRepr()\n\n    error_msg = '^Unable to serialize unknown type: <unprintable BedReprMeta object>$'\n    with pytest.raises(PydanticSerializationError, match=error_msg):\n        to_jsonable_python(b)\n\n    assert to_jsonable_python(b, serialize_unknown=True) == '<Unserializable BadRepr object>'\n\n    with pytest.raises(PydanticSerializationError, match=error_msg):\n        to_json(b)\n\n    assert to_json(b, serialize_unknown=True) == b'\"<Unserializable BadRepr object>\"'\n\n\ndef test_inf_nan_allow():\n    v = SchemaValidator(core_schema.float_schema(allow_inf_nan=True))\n    assert v.validate_json('Infinity') == float('inf')\n    assert v.validate_json('-Infinity') == float('-inf')\n    assert v.validate_json('NaN') == IsFloatNan()\n\n\ndef test_partial_parse():\n    with pytest.raises(ValueError, match='EOF while parsing a string at line 1 column 15'):\n        from_json('[\"aa\", \"bb\", \"c')\n    assert from_json('[\"aa\", \"bb\", \"c', allow_partial=True) == ['aa', 'bb']\n\n    with pytest.raises(ValueError, match='EOF while parsing a string at line 1 column 15'):\n        from_json(b'[\"aa\", \"bb\", \"c')\n    assert from_json(b'[\"aa\", \"bb\", \"c', allow_partial=True) == ['aa', 'bb']\n", "tests/validators/test_definitions.py": "import pytest\n\nfrom pydantic_core import SchemaError, SchemaValidator, core_schema, validate_core_schema\n\nfrom ..conftest import plain_repr\n\n\ndef test_list_with_def():\n    v = SchemaValidator(\n        core_schema.definitions_schema(\n            core_schema.list_schema(core_schema.definition_reference_schema('foobar')),\n            [core_schema.int_schema(ref='foobar')],\n        )\n    )\n    assert v.validate_python([1, 2, '3']) == [1, 2, 3]\n    assert v.validate_json(b'[1, 2, \"3\"]') == [1, 2, 3]\n    r = plain_repr(v)\n    assert r.startswith('SchemaValidator(title=\"list[int]\",')\n\n\ndef test_ignored_def():\n    v = SchemaValidator(\n        core_schema.definitions_schema(\n            core_schema.list_schema(core_schema.int_schema()), [core_schema.int_schema(ref='foobar')]\n        )\n    )\n    assert v.validate_python([1, 2, '3']) == [1, 2, 3]\n    r = plain_repr(v)\n    assert r.startswith('SchemaValidator(title=\"list[int]\",')\n\n\ndef test_extract_used_refs_ignores_metadata():\n    v = SchemaValidator(core_schema.any_schema(metadata={'type': 'definition-ref'}))\n    assert v.validate_python([1, 2, 3]) == [1, 2, 3]\n    assert plain_repr(v).endswith('definitions=[],cache_strings=True)')\n\n\ndef test_check_ref_used_ignores_metadata():\n    v = SchemaValidator(\n        core_schema.list_schema(\n            core_schema.int_schema(metadata={'type': 'definition-ref', 'schema_ref': 'foobar'}), ref='foobar'\n        )\n    )\n    assert v.validate_python([1, 2, 3]) == [1, 2, 3]\n    # assert plain_repr(v).endswith('definitions=[])')\n\n\ndef test_def_error():\n    with pytest.raises(SchemaError) as exc_info:\n        validate_core_schema(\n            core_schema.definitions_schema(\n                core_schema.list_schema(core_schema.definition_reference_schema('foobar')),\n                [core_schema.int_schema(ref='foobar'), {'type': 'wrong'}],\n            )\n        )\n    assert str(exc_info.value).startswith(\n        \"Invalid Schema:\\ndefinitions.definitions.1\\n  Input tag 'wrong' found using 'type'\"\n    )\n    assert exc_info.value.error_count() == 1\n\n\ndef test_dict_repeat():\n    v = SchemaValidator(\n        core_schema.definitions_schema(\n            core_schema.dict_schema(\n                core_schema.definition_reference_schema('foobar'), core_schema.definition_reference_schema('foobar')\n            ),\n            [core_schema.int_schema(ref='foobar')],\n        )\n    )\n    assert v.validate_python({'1': '2', 3: '4'}) == {1: 2, 3: 4}\n    assert v.validate_json(b'{\"1\": 2, \"3\": \"4\"}') == {1: 2, 3: 4}\n    # assert plain_repr(v).endswith('definitions=[])')\n\n\ndef test_repeated_ref():\n    with pytest.raises(SchemaError, match='SchemaError: Duplicate ref: `foobar`'):\n        SchemaValidator(\n            core_schema.tuple_positional_schema(\n                [\n                    core_schema.definitions_schema(\n                        core_schema.definition_reference_schema('foobar'), [core_schema.int_schema(ref='foobar')]\n                    ),\n                    core_schema.definitions_schema(\n                        core_schema.definition_reference_schema('foobar'), [core_schema.int_schema(ref='foobar')]\n                    ),\n                ]\n            )\n        )\n\n\ndef test_repeat_after():\n    with pytest.raises(SchemaError, match='SchemaError: Duplicate ref: `foobar`'):\n        SchemaValidator(\n            core_schema.definitions_schema(\n                core_schema.tuple_positional_schema(\n                    [\n                        core_schema.definitions_schema(\n                            core_schema.definition_reference_schema('foobar'), [core_schema.int_schema(ref='foobar')]\n                        ),\n                        core_schema.definition_reference_schema('foobar'),\n                    ]\n                ),\n                [core_schema.int_schema(ref='foobar')],\n            )\n        )\n\n\ndef test_deep():\n    v = SchemaValidator(\n        core_schema.typed_dict_schema(\n            {\n                'a': core_schema.typed_dict_field(core_schema.int_schema()),\n                'b': core_schema.typed_dict_field(\n                    core_schema.definitions_schema(\n                        core_schema.typed_dict_schema(\n                            {\n                                'c': core_schema.typed_dict_field(core_schema.int_schema()),\n                                'd': core_schema.typed_dict_field(core_schema.definition_reference_schema('foobar')),\n                            }\n                        ),\n                        [core_schema.str_schema(ref='foobar')],\n                    )\n                ),\n            }\n        )\n    )\n    assert v.validate_python({'a': 1, 'b': {'c': 2, 'd': b'dd'}}) == {'a': 1, 'b': {'c': 2, 'd': 'dd'}}\n\n\ndef test_use_after():\n    v = SchemaValidator(\n        core_schema.tuple_positional_schema(\n            [\n                core_schema.definitions_schema(\n                    core_schema.definition_reference_schema('foobar'), [core_schema.int_schema(ref='foobar')]\n                ),\n                core_schema.definition_reference_schema('foobar'),\n            ]\n        )\n    )\n    assert v.validate_python(['1', '2']) == (1, 2)\n\n\ndef test_definition_chain():\n    v = SchemaValidator(\n        core_schema.definitions_schema(\n            core_schema.definition_reference_schema('foo'),\n            [core_schema.definition_reference_schema(ref='foo', schema_ref='bar'), core_schema.int_schema(ref='bar')],\n        ),\n    )\n    assert v.validate_python('1') == 1\n", "tests/validators/test_model_fields.py": "import math\nimport re\nimport sys\nfrom dataclasses import dataclass\nfrom datetime import datetime\nfrom typing import Any, Dict, List, Mapping, Union\n\nimport pytest\nfrom dirty_equals import FunctionCheck, HasRepr, IsStr\n\nfrom pydantic_core import CoreConfig, SchemaError, SchemaValidator, ValidationError, core_schema, validate_core_schema\n\nfrom ..conftest import Err, PyAndJson\n\n\nclass Cls:\n    def __init__(self, **attributes):\n        for k, v in attributes.items():\n            setattr(self, k, v)\n\n    def __repr__(self):\n        return 'Cls({})'.format(', '.join(f'{k}={v!r}' for k, v in self.__dict__.items()))\n\n\nclass Map(Mapping):\n    def __init__(self, **kwargs):\n        self._d = kwargs\n\n    def __iter__(self):\n        return iter(self._d)\n\n    def __len__(self) -> int:\n        return len(self._d)\n\n    def __getitem__(self, k, /):\n        return self._d[k]\n\n    def __repr__(self):\n        return 'Map({})'.format(', '.join(f'{k}={v!r}' for k, v in self._d.items()))\n\n\ndef test_simple():\n    v = SchemaValidator(\n        {\n            'type': 'model-fields',\n            'fields': {\n                'field_a': {'type': 'model-field', 'schema': {'type': 'str'}},\n                'field_b': {'type': 'model-field', 'schema': {'type': 'int'}},\n            },\n        }\n    )\n\n    assert v.validate_python({'field_a': b'abc', 'field_b': 1}) == (\n        {'field_a': 'abc', 'field_b': 1},\n        None,\n        {'field_a', 'field_b'},\n    )\n\n\ndef test_strict():\n    v = SchemaValidator(\n        {\n            'type': 'model-fields',\n            'fields': {\n                'field_a': {'type': 'model-field', 'schema': {'type': 'str'}},\n                'field_b': {'type': 'model-field', 'schema': {'type': 'int'}},\n            },\n        },\n        {'strict': True},\n    )\n\n    assert v.validate_python({'field_a': 'hello', 'field_b': 12}) == (\n        {'field_a': 'hello', 'field_b': 12},\n        None,\n        {'field_a', 'field_b'},\n    )\n\n    with pytest.raises(ValidationError) as exc_info:\n        assert v.validate_python({'field_a': 123, 'field_b': '123'})\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'string_type', 'loc': ('field_a',), 'msg': 'Input should be a valid string', 'input': 123},\n        {'type': 'int_type', 'loc': ('field_b',), 'msg': 'Input should be a valid integer', 'input': '123'},\n    ]\n\n\ndef test_with_default():\n    v = SchemaValidator(\n        {\n            'type': 'model-fields',\n            'fields': {\n                'field_a': {'type': 'model-field', 'schema': {'type': 'str'}},\n                'field_b': {\n                    'type': 'model-field',\n                    'schema': {'type': 'default', 'schema': {'type': 'int'}, 'default': 666},\n                },\n            },\n        }\n    )\n\n    assert v.validate_python({'field_a': b'abc'}) == ({'field_a': 'abc', 'field_b': 666}, None, {'field_a'})\n    assert v.validate_python({'field_a': b'abc', 'field_b': 1}) == (\n        {'field_a': 'abc', 'field_b': 1},\n        None,\n        {'field_b', 'field_a'},\n    )\n\n\ndef test_missing_error(pydantic_version):\n    v = SchemaValidator(\n        {\n            'type': 'model-fields',\n            'fields': {\n                'field_a': {'type': 'model-field', 'schema': {'type': 'str'}},\n                'field_b': {'type': 'model-field', 'schema': {'type': 'int'}},\n            },\n        }\n    )\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python({'field_a': b'abc'})\n    assert (\n        str(exc_info.value)\n        == f\"\"\"\\\n1 validation error for model-fields\nfield_b\n  Field required [type=missing, input_value={{'field_a': b'abc'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/{pydantic_version}/v/missing\"\"\"\n    )\n\n\n@pytest.mark.parametrize(\n    'config,input_value,expected',\n    [\n        ({}, {'a': '123'}, ({'a': 123, 'b': 4.2}, None, {'a'})),\n        ({}, Map(a=123), ({'a': 123, 'b': 4.2}, None, {'a'})),\n        ({}, {b'a': '123'}, Err('Field required [type=missing,')),\n        ({}, {'a': '123', 'c': 4}, ({'a': 123, 'b': 4.2}, None, {'a'})),\n        ({'extra_fields_behavior': 'allow'}, {'a': '123', 'c': 4}, ({'a': 123, 'b': 4.2}, {'c': 4}, {'a', 'c'})),\n        ({'extra_fields_behavior': 'allow'}, {'a': '123', b'c': 4}, Err('Keys should be strings [type=invalid_key,')),\n        (\n            {'strict': True},\n            Map(a=123),\n            Err('Input should be a valid dictionary or instance of Model [type=model_type,'),\n        ),\n        ({}, {'a': '123', 'b': '4.7'}, ({'a': 123, 'b': 4.7}, None, {'a', 'b'})),\n        ({}, {'a': '123', 'b': 'nan'}, ({'a': 123, 'b': FunctionCheck(math.isnan)}, None, {'a', 'b'})),\n        (\n            {'allow_inf_nan': False},\n            {'a': '123', 'b': 'nan'},\n            Err('Input should be a finite number [type=finite_number,'),\n        ),\n    ],\n    ids=repr,\n)\ndef test_config(config: CoreConfig, input_value, expected):\n    v = SchemaValidator(\n        {\n            'type': 'model-fields',\n            'fields': {\n                'a': {'type': 'model-field', 'schema': {'type': 'int'}},\n                'b': {\n                    'type': 'model-field',\n                    'schema': {'type': 'default', 'schema': {'type': 'float'}, 'default': 4.2},\n                },\n            },\n        },\n        config,\n    )\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            val = v.validate_python(input_value)\n            print(f'UNEXPECTED OUTPUT: {val!r}')\n    else:\n        result = v.validate_python(input_value)\n        assert result == expected\n\n\ndef test_ignore_extra():\n    v = SchemaValidator(\n        {\n            'type': 'model-fields',\n            'fields': {\n                'field_a': {'type': 'model-field', 'schema': {'type': 'str'}},\n                'field_b': {'type': 'model-field', 'schema': {'type': 'int'}},\n            },\n        }\n    )\n\n    assert v.validate_python({'field_a': b'123', 'field_b': 1, 'field_c': 123}) == (\n        {'field_a': '123', 'field_b': 1},\n        None,\n        {'field_b', 'field_a'},\n    )\n\n\ndef test_forbid_extra():\n    v = SchemaValidator(\n        {\n            'type': 'model-fields',\n            'fields': {'field_a': {'type': 'model-field', 'schema': {'type': 'str'}}},\n            'extra_behavior': 'forbid',\n        }\n    )\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python({'field_a': 'abc', 'field_b': 1})\n\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'extra_forbidden', 'loc': ('field_b',), 'msg': 'Extra inputs are not permitted', 'input': 1}\n    ]\n\n\ndef test_allow_extra_invalid():\n    with pytest.raises(SchemaError, match='extras_schema can only be used if extra_behavior=allow'):\n        SchemaValidator(\n            {'type': 'model-fields', 'fields': {}, 'extras_schema': {'type': 'int'}, 'extra_behavior': 'ignore'}\n        )\n\n\ndef test_allow_extra_wrong():\n    with pytest.raises(SchemaError, match='Invalid extra_behavior: `wrong`'):\n        SchemaValidator({'type': 'model-fields', 'fields': {}}, {'extra_fields_behavior': 'wrong'})\n\n\ndef test_str_config():\n    v = SchemaValidator(\n        {'type': 'model-fields', 'fields': {'field_a': {'type': 'model-field', 'schema': {'type': 'str'}}}},\n        {'str_max_length': 5},\n    )\n    assert v.validate_python({'field_a': 'test'}) == ({'field_a': 'test'}, None, {'field_a'})\n\n    with pytest.raises(ValidationError, match='String should have at most 5 characters'):\n        v.validate_python({'field_a': 'test long'})\n\n\ndef test_validate_assignment():\n    v = SchemaValidator(\n        {'type': 'model-fields', 'fields': {'field_a': {'type': 'model-field', 'schema': {'type': 'str'}}}}\n    )\n\n    assert v.validate_python({'field_a': 'test'}) == ({'field_a': 'test'}, None, {'field_a'})\n\n    data = {'field_a': 'test'}\n    assert v.validate_assignment(data, 'field_a', b'abc') == ({'field_a': 'abc'}, None, {'field_a'})\n    assert data == {'field_a': 'abc'}\n\n\ndef test_validate_assignment_strict_field():\n    v = SchemaValidator(\n        {\n            'type': 'model-fields',\n            'fields': {'field_a': {'type': 'model-field', 'schema': {'type': 'str', 'strict': True}}},\n        }\n    )\n\n    assert v.validate_python({'field_a': 'test'}) == ({'field_a': 'test'}, None, {'field_a'})\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_assignment({'field_a': 'test'}, 'field_a', b'abc')\n    assert exc_info.value.errors(include_url=False) == [\n        {'input': b'abc', 'type': 'string_type', 'loc': ('field_a',), 'msg': 'Input should be a valid string'}\n    ]\n\n\ndef test_validate_assignment_functions():\n    calls: list[Any] = []\n\n    def func_a(input_value, info):\n        calls.append(('func_a', input_value))\n        return input_value * 2\n\n    def func_b(input_value, info):\n        calls.append(('func_b', input_value))\n        return input_value / 2\n\n    v = SchemaValidator(\n        {\n            'type': 'model-fields',\n            'fields': {\n                'field_a': {\n                    'type': 'model-field',\n                    'schema': {\n                        'type': 'function-after',\n                        'function': {'type': 'with-info', 'function': func_a},\n                        'schema': {'type': 'str'},\n                    },\n                },\n                'field_b': {\n                    'type': 'model-field',\n                    'schema': {\n                        'type': 'function-after',\n                        'function': {'type': 'with-info', 'function': func_b},\n                        'schema': {'type': 'int'},\n                    },\n                },\n            },\n        }\n    )\n\n    assert v.validate_python({'field_a': 'test', 'field_b': 12.0}) == (\n        {'field_a': 'testtest', 'field_b': 6},\n        None,\n        {'field_a', 'field_b'},\n    )\n\n    assert calls == [('func_a', 'test'), ('func_b', 12)]\n    calls.clear()\n\n    assert v.validate_assignment({'field_a': 'testtest', 'field_b': 6}, 'field_a', 'new-val') == (\n        {'field_a': 'new-valnew-val', 'field_b': 6},\n        None,\n        {'field_a'},\n    )\n    assert calls == [('func_a', 'new-val')]\n\n\ndef test_validate_assignment_ignore_extra():\n    v = SchemaValidator(\n        {'type': 'model-fields', 'fields': {'field_a': {'type': 'model-field', 'schema': {'type': 'str'}}}}\n    )\n\n    assert v.validate_python({'field_a': 'test'}) == ({'field_a': 'test'}, None, {'field_a'})\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_assignment({'field_a': 'test'}, 'other_field', 456)\n\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'no_such_attribute',\n            'loc': ('other_field',),\n            'msg': \"Object has no attribute 'other_field'\",\n            'input': 456,\n            'ctx': {'attribute': 'other_field'},\n        }\n    ]\n\n\ndef test_validate_assignment_allow_extra():\n    v = SchemaValidator(\n        {\n            'type': 'model-fields',\n            'fields': {'field_a': {'type': 'model-field', 'schema': {'type': 'str'}}},\n            'extra_behavior': 'allow',\n        }\n    )\n\n    assert v.validate_python({'field_a': 'test'}) == ({'field_a': 'test'}, {}, {'field_a'})\n\n    assert v.validate_assignment({'field_a': 'test'}, 'other_field', 456) == (\n        {'field_a': 'test'},\n        {'other_field': 456},\n        {'other_field'},\n    )\n\n\ndef test_validate_assignment_allow_extra_validate():\n    v = SchemaValidator(\n        {\n            'type': 'model-fields',\n            'fields': {'field_a': {'type': 'model-field', 'schema': {'type': 'str'}}},\n            'extras_schema': {'type': 'int'},\n            'extra_behavior': 'allow',\n        }\n    )\n\n    assert v.validate_assignment({'field_a': 'test'}, 'other_field', '456') == (\n        {'field_a': 'test'},\n        {'other_field': 456},\n        {'other_field'},\n    )\n\n    with pytest.raises(ValidationError) as exc_info:\n        assert v.validate_assignment({'field_a': 'test'}, 'other_field', 'xyz')\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'int_parsing',\n            'loc': ('other_field',),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'xyz',\n        }\n    ]\n\n\ndef test_validate_assignment_with_strict():\n    v = SchemaValidator(\n        {\n            'type': 'model-fields',\n            'fields': {\n                'x': {'type': 'model-field', 'schema': {'type': 'str'}},\n                'y': {'type': 'model-field', 'schema': {'type': 'int'}},\n            },\n        }\n    )\n\n    r, model_extra, fields_set = v.validate_python({'x': 'a', 'y': '123'})\n    assert r == {'x': 'a', 'y': 123}\n    assert model_extra is None\n    assert fields_set == {'x', 'y'}\n\n    v.validate_assignment(r, 'y', '124')\n    assert r == {'x': 'a', 'y': 124}\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_assignment(r, 'y', '124', strict=True)\n\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'int_type', 'loc': ('y',), 'msg': 'Input should be a valid integer', 'input': '124'}\n    ]\n\n\ndef test_json_error():\n    v = SchemaValidator(\n        {\n            'type': 'model-fields',\n            'fields': {'field_a': {'type': 'model-field', 'schema': {'type': 'list', 'items_schema': {'type': 'int'}}}},\n        }\n    )\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_json('{\"field_a\": [123, \"wrong\"]}')\n\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'int_parsing',\n            'loc': ('field_a', 1),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'wrong',\n        }\n    ]\n\n\ndef test_missing_schema_key():\n    with pytest.raises(SchemaError, match='model-fields.fields.x.schema\\n  Field required'):\n        validate_core_schema({'type': 'model-fields', 'fields': {'x': {'type': 'str'}}})\n\n\ndef test_fields_required_by_default():\n    \"\"\"By default all fields should be required\"\"\"\n    v = SchemaValidator(\n        {\n            'type': 'model-fields',\n            'fields': {\n                'x': {'type': 'model-field', 'schema': {'type': 'str'}},\n                'y': {'type': 'model-field', 'schema': {'type': 'str'}},\n            },\n        }\n    )\n\n    assert v.validate_python({'x': 'pika', 'y': 'chu'}) == ({'x': 'pika', 'y': 'chu'}, None, {'x', 'y'})\n\n    with pytest.raises(ValidationError) as exc_info:\n        assert v.validate_python({'x': 'pika'})\n\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'missing', 'loc': ('y',), 'msg': 'Field required', 'input': {'x': 'pika'}}\n    ]\n\n\ndef test_fields_required_by_default_with_default():\n    v = SchemaValidator(\n        {\n            'type': 'model-fields',\n            'fields': {\n                'x': {'type': 'model-field', 'schema': {'type': 'str'}},\n                'y': {\n                    'type': 'model-field',\n                    'schema': {'type': 'default', 'schema': {'type': 'str'}, 'default': 'bulbi'},\n                },\n            },\n        }\n    )\n\n    assert v.validate_python({'x': 'pika', 'y': 'chu'}) == ({'x': 'pika', 'y': 'chu'}, None, {'x', 'y'})\n    assert v.validate_python({'x': 'pika'}) == ({'x': 'pika', 'y': 'bulbi'}, None, {'x'})\n\n\ndef test_alias(py_and_json: PyAndJson):\n    v = py_and_json(\n        {\n            'type': 'model-fields',\n            'fields': {'field_a': {'validation_alias': 'FieldA', 'type': 'model-field', 'schema': {'type': 'int'}}},\n        }\n    )\n    assert v.validate_test({'FieldA': '123'}) == ({'field_a': 123}, None, {'field_a'})\n    with pytest.raises(ValidationError, match=r'FieldA\\n +Field required \\[type=missing,'):\n        assert v.validate_test({'foobar': '123'})\n    with pytest.raises(ValidationError, match=r'FieldA\\n +Field required \\[type=missing,'):\n        assert v.validate_test({'field_a': '123'})\n\n\ndef test_empty_string_field_name(py_and_json: PyAndJson):\n    v = py_and_json({'type': 'model-fields', 'fields': {'': {'type': 'model-field', 'schema': {'type': 'int'}}}})\n    assert v.validate_test({'': 123}) == ({'': 123}, None, {''})\n\n\ndef test_empty_string_aliases(py_and_json: PyAndJson):\n    v = py_and_json(\n        {\n            'type': 'model-fields',\n            'fields': {'field_a': {'validation_alias': '', 'type': 'model-field', 'schema': {'type': 'int'}}},\n        }\n    )\n    assert v.validate_test({'': 123}) == ({'field_a': 123}, None, {'field_a'})\n\n    v = py_and_json(\n        {\n            'type': 'model-fields',\n            'fields': {'field_a': {'validation_alias': ['', ''], 'type': 'model-field', 'schema': {'type': 'int'}}},\n        }\n    )\n    assert v.validate_test({'': {'': 123}}) == ({'field_a': 123}, None, {'field_a'})\n\n\ndef test_alias_allow_pop(py_and_json: PyAndJson):\n    v = py_and_json(\n        {\n            'type': 'model-fields',\n            'populate_by_name': True,\n            'fields': {'field_a': {'validation_alias': 'FieldA', 'type': 'model-field', 'schema': {'type': 'int'}}},\n        }\n    )\n    assert v.validate_test({'FieldA': '123'}) == ({'field_a': 123}, None, {'field_a'})\n    assert v.validate_test({'field_a': '123'}) == ({'field_a': 123}, None, {'field_a'})\n    assert v.validate_test({'FieldA': '1', 'field_a': '2'}) == ({'field_a': 1}, None, {'field_a'})\n    with pytest.raises(ValidationError, match=r'FieldA\\n +Field required \\[type=missing,'):\n        assert v.validate_test({'foobar': '123'})\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ({'foo': {'bar': '123'}}, ({'field_a': 123}, None, {'field_a'})),\n        ({'x': '123'}, Err(r'foo.bar\\n +Field required \\[type=missing,')),\n        ({'foo': '123'}, Err(r'foo.bar\\n +Field required \\[type=missing,')),\n        ({'foo': [1, 2, 3]}, Err(r'foo.bar\\n +Field required \\[type=missing,')),\n        ({'foo': {'bat': '123'}}, Err(r'foo.bar\\n +Field required \\[type=missing,')),\n    ],\n    ids=repr,\n)\ndef test_alias_path(py_and_json: PyAndJson, input_value, expected):\n    v = py_and_json(\n        {\n            'type': 'model-fields',\n            'fields': {\n                'field_a': {'validation_alias': ['foo', 'bar'], 'type': 'model-field', 'schema': {'type': 'int'}}\n            },\n        }\n    )\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=expected.message):\n            v.validate_test(input_value)\n    else:\n        output = v.validate_test(input_value)\n        assert output == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ({'foo': {'bar': {'bat': '123'}}}, ({'field_a': 123}, None, {'field_a'})),\n        ({'foo': [1, 2, 3, 4]}, ({'field_a': 4}, None, {'field_a'})),\n        ({'foo': (1, 2, 3, 4)}, ({'field_a': 4}, None, {'field_a'})),\n        ({'spam': 5}, ({'field_a': 5}, None, {'field_a'})),\n        ({'spam': 1, 'foo': {'bar': {'bat': 2}}}, ({'field_a': 2}, None, {'field_a'})),\n        ({'foo': {'x': 2}}, Err(r'field_a\\n +Field required \\[type=missing,')),\n        ({'x': '123'}, Err(r'field_a\\n +Field required \\[type=missing,')),\n        ({'x': {2: 33}}, Err(r'field_a\\n +Field required \\[type=missing,')),\n        ({'foo': '01234'}, Err(r'field_a\\n +Field required \\[type=missing,')),\n        ({'foo': [1]}, Err(r'field_a\\n +Field required \\[type=missing,')),\n    ],\n    ids=repr,\n)\ndef test_aliases_path_multiple(py_and_json: PyAndJson, input_value, expected):\n    v = py_and_json(\n        {\n            'type': 'model-fields',\n            'fields': {\n                'field_a': {\n                    'validation_alias': [['foo', 'bar', 'bat'], ['foo', 3], ['spam']],\n                    'type': 'model-field',\n                    'schema': {'type': 'int'},\n                }\n            },\n        },\n        {'loc_by_alias': False},\n    )\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=expected.message):\n            val = v.validate_test(input_value)\n            print(f'UNEXPECTED OUTPUT: {val!r}')\n    else:\n        output = v.validate_test(input_value)\n        assert output == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ({'foo': {-2: '123'}}, ({'field_a': 123}, None, {'field_a'})),\n        # negatives indexes work fine\n        ({'foo': [1, 42, 'xx']}, ({'field_a': 42}, None, {'field_a'})),\n        ({'foo': [42, 'xxx', 42]}, Err(r'Input should be a valid integer,')),\n        ({'foo': [42]}, Err(r'field_a\\n +Field required \\[type=missing,')),\n        ({'foo': {'xx': '123'}}, Err(r'field_a\\n +Field required \\[type=missing,')),\n        ({'foo': {'-2': '123'}}, Err(r'field_a\\n +Field required \\[type=missing,')),\n        ({'foo': {2: '123'}}, Err(r'field_a\\n +Field required \\[type=missing,')),\n        ({'foo': 'foobar'}, Err(r'field_a\\n +Field required \\[type=missing,')),\n        ({'foo': {0, 1, 2}}, Err(r'field_a\\n +Field required \\[type=missing,')),\n    ],\n    ids=repr,\n)\ndef test_aliases_path_negative(input_value, expected):\n    v = SchemaValidator(\n        {\n            'type': 'model-fields',\n            'fields': {'field_a': {'validation_alias': ['foo', -2], 'type': 'model-field', 'schema': {'type': 'int'}}},\n        },\n        {'loc_by_alias': False},\n    )\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=expected.message):\n            val = v.validate_python(input_value)\n            print(f'UNEXPECTED OUTPUT: {val!r}')\n    else:\n        output = v.validate_python(input_value)\n        assert output == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ({'foo': [1, 42, 'xx']}, ({'field_a': 42}, None, {'field_a'})),\n        ({'foo': [42, 'xxx', 42]}, Err(r'Input should be a valid integer,')),\n        ({'foo': [42]}, Err(r'foo.-2\\n +Field required \\[type=missing,')),\n    ],\n    ids=repr,\n)\ndef test_aliases_path_negative_json(py_and_json: PyAndJson, input_value, expected):\n    v = py_and_json(\n        {\n            'type': 'model-fields',\n            'fields': {'field_a': {'validation_alias': ['foo', -2], 'type': 'model-field', 'schema': {'type': 'int'}}},\n        }\n    )\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=expected.message):\n            val = v.validate_test(input_value)\n            print(f'UNEXPECTED OUTPUT: {val!r}')\n    else:\n        output = v.validate_test(input_value)\n        assert output == expected\n\n\ndef test_aliases_debug():\n    v = SchemaValidator(\n        {\n            'type': 'model-fields',\n            'fields': {\n                'field_a': {\n                    'validation_alias': [['foo', 'bar', 'bat'], ['foo', 3]],\n                    'type': 'model-field',\n                    'schema': {'type': 'int'},\n                }\n            },\n        }\n    )\n    print(repr(v))\n    assert repr(v).startswith('SchemaValidator(title=\"model-fields\", validator=ModelFields(')\n    assert 'PathChoices(' in repr(v)\n\n\ndef get_int_key():\n    v = SchemaValidator(\n        {\n            'type': 'model-fields',\n            'fields': {\n                'field_a': {\n                    'validation_alias': [['foo', 3], ['spam']],\n                    'type': 'model-field',\n                    'schema': {'type': 'int'},\n                }\n            },\n        }\n    )\n    assert v.validate_python({'foo': {3: 33}}) == ({'field_a': 33}, {}, {'field_a'})\n\n\nclass GetItemThing:\n    def __getitem__(self, v):\n        assert v == 'foo'\n        return 321\n\n\ndef get_custom_getitem():\n    v = SchemaValidator(\n        {\n            'type': 'model-fields',\n            'fields': {'field_a': {'validation_alias': ['foo'], 'type': 'model-field', 'schema': {'type': 'int'}}},\n        }\n    )\n    assert v.validate_python(GetItemThing()) == ({'field_a': 321}, {}, {'field_a'})\n    assert v.validate_python({'bar': GetItemThing()}) == ({'field_a': 321}, {}, {'field_a'})\n\n\n@pytest.mark.parametrize('input_value', [{'foo': {'bar': 42}}, {'foo': 42}, {'field_a': 42}], ids=repr)\ndef test_paths_allow_by_name(py_and_json: PyAndJson, input_value):\n    v = py_and_json(\n        {\n            'type': 'model-fields',\n            'fields': {\n                'field_a': {\n                    'validation_alias': [['foo', 'bar'], ['foo']],\n                    'type': 'model-field',\n                    'schema': {'type': 'int'},\n                }\n            },\n            'populate_by_name': True,\n        }\n    )\n    assert v.validate_test(input_value) == ({'field_a': 42}, None, {'field_a'})\n\n\n@pytest.mark.parametrize(\n    'alias_schema,error',\n    [\n        ({'validation_alias': ['foo', ['bar']]}, 'Input should be a valid string'),\n        ({'validation_alias': []}, 'Lookup paths should have at least one element'),\n        ({'validation_alias': [[]]}, 'Each alias path should have at least one element'),\n        ({'validation_alias': [123]}, \"TypeError: 'int' object cannot be converted to 'PyList'\"),\n        ({'validation_alias': [[[]]]}, 'Input should be a valid string'),\n        ({'validation_alias': [[1, 'foo']]}, 'TypeError: The first item in an alias path should be a string'),\n    ],\n    ids=repr,\n)\ndef test_alias_build_error(alias_schema, error):\n    with pytest.raises(SchemaError, match=error):\n        SchemaValidator(\n            validate_core_schema(\n                {\n                    'type': 'model-fields',\n                    'fields': {'field_a': {'type': 'model-field', 'schema': {'type': 'int'}, **alias_schema}},\n                }\n            )\n        )\n\n\ndef test_alias_error_loc_alias(py_and_json: PyAndJson):\n    v = py_and_json(\n        {\n            'type': 'model-fields',\n            'fields': {\n                'field_a': {\n                    'type': 'model-field',\n                    'schema': {'type': 'int'},\n                    'validation_alias': [['foo', 'x'], ['bar', 1, -1]],\n                }\n            },\n        },\n        {'loc_by_alias': True},  # this is the default\n    )\n    assert v.validate_test({'foo': {'x': 42}}) == ({'field_a': 42}, None, {'field_a'})\n    assert v.validate_python({'bar': ['x', {-1: 42}]}) == ({'field_a': 42}, None, {'field_a'})\n    assert v.validate_test({'bar': ['x', [1, 2, 42]]}) == ({'field_a': 42}, None, {'field_a'})\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_test({'foo': {'x': 'not_int'}})\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'int_parsing',\n            'loc': ('foo', 'x'),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'not_int',\n        }\n    ]\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_test({'bar': ['x', [1, 2, 'not_int']]})\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'int_parsing',\n            'loc': ('bar', 1, -1),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'not_int',\n        }\n    ]\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_test({})\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'missing', 'loc': ('foo', 'x'), 'msg': 'Field required', 'input': {}}\n    ]\n\n\ndef test_alias_error_loc_field_names(py_and_json: PyAndJson):\n    v = py_and_json(\n        {\n            'type': 'model-fields',\n            'fields': {\n                'field_a': {\n                    'type': 'model-field',\n                    'schema': {'type': 'int'},\n                    'validation_alias': [['foo'], ['bar', 1, -1]],\n                }\n            },\n        },\n        {'loc_by_alias': False},\n    )\n    assert v.validate_test({'foo': 42}) == ({'field_a': 42}, None, {'field_a'})\n    assert v.validate_test({'bar': ['x', [1, 2, 42]]}) == ({'field_a': 42}, None, {'field_a'})\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_test({'foo': 'not_int'})\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'int_parsing',\n            'loc': ('field_a',),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'not_int',\n        }\n    ]\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_test({'bar': ['x', [1, 2, 'not_int']]})\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'int_parsing',\n            'loc': ('field_a',),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'not_int',\n        }\n    ]\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_test({})\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'missing', 'loc': ('field_a',), 'msg': 'Field required', 'input': {}}\n    ]\n\n\ndef test_empty_model():\n    v = SchemaValidator({'type': 'model-fields', 'fields': {}})\n    assert v.validate_python({}) == ({}, None, set())\n    with pytest.raises(\n        ValidationError, match=re.escape('Input should be a valid dictionary or instance of Model [type=model_type,')\n    ):\n        v.validate_python('x')\n\n\ndef test_model_fields_deep():\n    v = SchemaValidator(\n        {\n            'type': 'model-fields',\n            'fields': {\n                'field_a': {'type': 'model-field', 'schema': {'type': 'str'}},\n                'field_b': {\n                    'type': 'model-field',\n                    'schema': {\n                        'type': 'model-fields',\n                        'fields': {\n                            'field_c': {'type': 'model-field', 'schema': {'type': 'str'}},\n                            'field_d': {\n                                'type': 'model-field',\n                                'schema': {\n                                    'type': 'model-fields',\n                                    'fields': {\n                                        'field_e': {'type': 'model-field', 'schema': {'type': 'str'}},\n                                        'field_f': {'type': 'model-field', 'schema': {'type': 'int'}},\n                                    },\n                                },\n                            },\n                        },\n                    },\n                },\n            },\n        }\n    )\n    model_dict, model_extra, fields_set = v.validate_python(\n        {'field_a': '1', 'field_b': {'field_c': '2', 'field_d': {'field_e': '4', 'field_f': 4}}}\n    )\n    assert model_dict == {\n        'field_a': '1',\n        'field_b': (\n            {'field_c': '2', 'field_d': ({'field_e': '4', 'field_f': 4}, None, {'field_f', 'field_e'})},\n            None,\n            {'field_d', 'field_c'},\n        ),\n    }\n    assert model_extra is None\n    assert fields_set == {'field_a', 'field_b'}\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python({'field_a': '1', 'field_b': {'field_c': '2', 'field_d': {'field_e': '4', 'field_f': 'xx'}}})\n\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'int_parsing',\n            'loc': ('field_b', 'field_d', 'field_f'),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'xx',\n        }\n    ]\n\n\nclass ClassWithAttributes:\n    def __init__(self):\n        self.a = 1\n        self.b = 2\n\n    @property\n    def c(self):\n        return 'ham'\n\n\n@dataclass\nclass MyDataclass:\n    a: int = 1\n    b: int = 2\n    c: str = 'ham'\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        (ClassWithAttributes(), ({'a': 1, 'b': 2, 'c': 'ham'}, None, {'a', 'b', 'c'})),\n        (MyDataclass(), ({'a': 1, 'b': 2, 'c': 'ham'}, None, {'a', 'b', 'c'})),\n        (Cls(a=1, b=2, c='ham'), ({'a': 1, 'b': 2, 'c': 'ham'}, None, {'a', 'b', 'c'})),\n        (dict(a=1, b=2, c='ham'), ({'a': 1, 'b': 2, 'c': 'ham'}, None, {'a', 'b', 'c'})),\n        (Map(a=1, b=2, c='ham'), ({'a': 1, 'b': 2, 'c': 'ham'}, None, {'a', 'b', 'c'})),\n        ((Cls(a=1, b=2), dict(c='ham')), ({'a': 1, 'b': 2, 'c': 'ham'}, None, {'a', 'b', 'c'})),\n        ((Cls(a=1, b=2), dict(c='bacon')), ({'a': 1, 'b': 2, 'c': 'bacon'}, None, {'a', 'b', 'c'})),\n        ((Cls(a=1, b=2, c='ham'), dict(c='bacon')), ({'a': 1, 'b': 2, 'c': 'bacon'}, None, {'a', 'b', 'c'})),\n        ((Cls(a=1, b=2, c='ham'), dict(d='bacon')), ({'a': 1, 'b': 2, 'c': 'ham'}, None, {'a', 'b', 'c'})),\n        # using type gives `__module__ == 'builtins'`\n        (type('Testing', (), {}), Err('[type=model_attributes_type,')),\n        (\n            '123',\n            Err('Input should be a valid dictionary or object to extract fields from [type=model_attributes_type,'),\n        ),\n        ([(1, 2)], Err('type=model_attributes_type,')),\n        (((1, 2),), Err('type=model_attributes_type,')),\n    ],\n    ids=repr,\n)\n@pytest.mark.parametrize('from_attributes_mode', ['schema', 'validation'])\ndef test_from_attributes(input_value, expected, from_attributes_mode):\n    v = SchemaValidator(\n        {\n            'type': 'model-fields',\n            'fields': {\n                'a': {'type': 'model-field', 'schema': {'type': 'int'}},\n                'b': {'type': 'model-field', 'schema': {'type': 'int'}},\n                'c': {'type': 'model-field', 'schema': {'type': 'str'}},\n            },\n            'from_attributes': from_attributes_mode == 'schema',\n        }\n    )\n    kwargs = {}\n    if from_attributes_mode == 'validation':\n        kwargs['from_attributes'] = True\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            val = v.validate_python(input_value, **kwargs)\n            print(f'UNEXPECTED OUTPUT: {val!r}')\n    else:\n        output = v.validate_python(input_value, **kwargs)\n        assert output == expected\n\n\ndef test_from_attributes_type_error():\n    v = SchemaValidator(\n        {\n            'type': 'model-fields',\n            'fields': {\n                'a': {'type': 'model-field', 'schema': {'type': 'int'}},\n                'b': {'type': 'model-field', 'schema': {'type': 'int'}},\n                'c': {'type': 'model-field', 'schema': {'type': 'str'}},\n            },\n            'from_attributes': True,\n            'model_name': 'MyModel',\n        }\n    )\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python('123')\n\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'model_attributes_type',\n            'loc': (),\n            'msg': 'Input should be a valid dictionary or object to extract fields from',\n            'input': '123',\n        }\n    ]\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_json('123')\n    # insert_assert(exc_info.value.errors())\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'model_type',\n            'loc': (),\n            'msg': 'Input should be an object',\n            'input': 123,\n            'ctx': {'class_name': 'MyModel'},\n        }\n    ]\n\n\ndef test_from_attributes_by_name():\n    v = SchemaValidator(\n        {\n            'type': 'model-fields',\n            'fields': {'a': {'type': 'model-field', 'schema': {'type': 'int'}, 'validation_alias': 'a_alias'}},\n            'from_attributes': True,\n            'populate_by_name': True,\n        }\n    )\n    assert v.validate_python(Cls(a_alias=1)) == ({'a': 1}, None, {'a'})\n    assert v.validate_python(Cls(a=1)) == ({'a': 1}, None, {'a'})\n\n\ndef test_from_attributes_override_true():\n    v = SchemaValidator(\n        {\n            'type': 'model-fields',\n            'fields': {'a': {'type': 'model-field', 'schema': {'type': 'int'}}},\n            'from_attributes': False,\n        }\n    )\n    with pytest.raises(ValidationError, match='Input should be a valid dictionary'):\n        v.validate_python(Cls(a=1))\n    assert v.validate_python(Cls(a=1), from_attributes=True) == ({'a': 1}, None, {'a'})\n\n    assert v.isinstance_python(Cls(a=1), from_attributes=True) is True\n    assert v.isinstance_python(Cls(a=1)) is False\n\n\ndef test_from_attributes_override_false():\n    v = SchemaValidator(\n        {\n            'type': 'model-fields',\n            'fields': {'a': {'type': 'model-field', 'schema': {'type': 'int'}}},\n            'from_attributes': True,\n        }\n    )\n    with pytest.raises(ValidationError, match='Input should be a valid dictionary'):\n        v.validate_python(Cls(a=1), from_attributes=False)\n    assert v.validate_python(Cls(a=1)) == ({'a': 1}, None, {'a'})\n\n    assert v.isinstance_python(Cls(a=1)) is True\n    assert v.isinstance_python(Cls(a=1), from_attributes=False) is False\n\n\ndef test_from_attributes_missing():\n    class Foobar:\n        def __init__(self):\n            self.a = 1\n            self.b = 2\n\n    v = SchemaValidator(\n        {\n            'type': 'model-fields',\n            'fields': {\n                'a': {'type': 'model-field', 'schema': {'type': 'int'}},\n                'b': {'type': 'model-field', 'schema': {'type': 'int'}},\n                'c': {'type': 'model-field', 'schema': {'type': 'str'}},\n            },\n            'from_attributes': True,\n        }\n    )\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python(Foobar())\n\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'missing',\n            'loc': ('c',),\n            'msg': 'Field required',\n            'input': HasRepr(IsStr(regex='.+Foobar object at.+')),\n        }\n    ]\n\n\ndef test_from_attributes_error():\n    class Foobar:\n        def __init__(self):\n            self.a = 1\n\n        @property\n        def b(self):\n            raise RuntimeError('intentional error')\n\n    v = SchemaValidator(\n        {\n            'type': 'model-fields',\n            'fields': {\n                'a': {'type': 'model-field', 'schema': {'type': 'int'}},\n                'b': {'type': 'model-field', 'schema': {'type': 'int'}},\n            },\n            'from_attributes': True,\n        }\n    )\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python(Foobar())\n\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'get_attribute_error',\n            'loc': ('b',),\n            'msg': 'Error extracting attribute: RuntimeError: intentional error',\n            'input': HasRepr(IsStr(regex='.+Foobar object at.+')),\n            'ctx': {'error': 'RuntimeError: intentional error'},\n        }\n    ]\n\n\ndef test_from_attributes_extra():\n    def another_function(x):\n        return x\n\n    class Foobar:\n        def __init__(self):\n            self.a = 1\n            self.b = 2\n            self._private_attribute = 4\n\n        @property\n        def c(self):\n            return 'ham'\n\n        @property\n        def _private_property(self):\n            return 'wrong'\n\n        @property\n        def property_error(self):\n            raise RuntimeError('xxx')\n\n        def bound_method(self):\n            return f'wrong {self.a}'\n\n        @staticmethod\n        def static_method():\n            return 'wrong'\n\n        # this is omitted along with the static method by the !PyFunction::is_type_of(attr) check in fields\n        function_attribute = another_function\n\n        @classmethod\n        def class_method(cls):\n            return 'wrong'\n\n    @dataclass\n    class MyDataclass:\n        a: int = 1\n        b: int = 2\n        c: str = 'ham'\n        _d: int = 4\n\n    v = SchemaValidator(\n        {\n            'type': 'model-fields',\n            'fields': {'a': {'type': 'model-field', 'schema': {'type': 'int'}}},\n            'from_attributes': True,\n            'extra_behavior': 'allow',\n        }\n    )\n\n    assert v.validate_python(Foobar()) == ({'a': 1}, {}, {'a'})\n    assert v.validate_python(MyDataclass()) == ({'a': 1}, {}, {'a'})\n    assert v.validate_python(Cls(a=1, b=2, c='ham')) == ({'a': 1}, {}, {'a'})\n    assert v.validate_python(Cls(a=1, b=datetime(2000, 1, 1))) == ({'a': 1}, {}, {'a'})\n    assert v.validate_python(Cls(a=1, b=datetime.now, c=lambda: 42)) == ({'a': 1}, {}, {'a'})\n\n\ndef test_from_attributes_extra_ignore_no_attributes_accessed() -> None:\n    v = SchemaValidator(\n        {\n            'type': 'model-fields',\n            'fields': {'a': {'type': 'model-field', 'schema': {'type': 'int'}}},\n            'from_attributes': True,\n            'extra_behavior': 'ignore',\n        }\n    )\n\n    accessed: List[str] = []\n\n    class Source:\n        a = 1\n        b = 2\n\n        def __getattribute__(self, name: str, /) -> Any:\n            accessed.append(name)\n            return super().__getattribute__(name)\n\n    assert v.validate_python(Source()) == ({'a': 1}, None, {'a'})\n    assert 'a' in accessed and 'b' not in accessed\n\n\ndef test_from_attributes_extra_forbid() -> None:\n    class Source:\n        a = 1\n        b = 2\n\n    v = SchemaValidator(\n        {\n            'type': 'model-fields',\n            'fields': {'a': {'type': 'model-field', 'schema': {'type': 'int'}}},\n            'from_attributes': True,\n            'extra_behavior': 'forbid',\n        }\n    )\n\n    assert v.validate_python(Source()) == ({'a': 1}, None, {'a'})\n\n\ndef foobar():\n    pass\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        (Cls(a=1), {'a': 1}),\n        (Cls(a=datetime.now), {'a': datetime.now}),\n        (Cls(a=lambda: 42), {'a': HasRepr(IsStr(regex='.+<lambda>.+'))}),\n        (Cls(a=sys.path), {'a': sys.path}),\n        (Cls(a=foobar), {'a': foobar}),\n    ],\n    ids=repr,\n)\ndef test_from_attributes_function(input_value, expected):\n    v = SchemaValidator(\n        {\n            'type': 'model-fields',\n            'fields': {'a': {'type': 'model-field', 'schema': {'type': 'any'}}},\n            'from_attributes': True,\n        }\n    )\n\n    model_dict, model_extra, fields_set = v.validate_python(input_value)\n    assert model_dict == expected\n    assert model_extra is None\n    assert fields_set == {'a'}\n\n\ndef test_from_attributes_error_error():\n    class BadError(Exception):\n        def __str__(self):\n            raise RuntimeError('intentional error inside error')\n\n    class Foobar:\n        @property\n        def x(self):\n            raise BadError('intentional error')\n\n    v = SchemaValidator(\n        {\n            'type': 'model-fields',\n            'fields': {'x': {'type': 'model-field', 'schema': {'type': 'int'}}},\n            'from_attributes': True,\n        }\n    )\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python(Foobar())\n\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'get_attribute_error',\n            'loc': ('x',),\n            'msg': IsStr(regex=r'Error extracting attribute: \\S+\\.<locals>\\.BadError: <exception str\\(\\) failed>'),\n            'input': HasRepr(IsStr(regex='.+Foobar object at.+')),\n            'ctx': {'error': IsStr(regex=r'\\S+\\.<locals>\\.BadError: <exception str\\(\\) failed>')},\n        }\n    ]\n\n    class UnInitError:\n        @property\n        def x(self):\n            raise RuntimeError\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python(UnInitError())\n\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'get_attribute_error',\n            'loc': ('x',),\n            'msg': 'Error extracting attribute: RuntimeError',\n            'input': HasRepr(IsStr(regex='.+UnInitError object at.+')),\n            'ctx': {'error': 'RuntimeError'},\n        }\n    ]\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ({'foo': {'bar': {'bat': '123'}}}, {'my_field': 123}),\n        (Cls(foo=Cls(bar=Cls(bat='123'))), {'my_field': 123}),\n        (Cls(foo={'bar': {'bat': '123'}}), {'my_field': 123}),\n        (Cls(foo=[1, 2, 3, 4]), {'my_field': 4}),\n        (Cls(foo=(1, 2, 3, 4)), {'my_field': 4}),\n        (Cls(spam=5), {'my_field': 5}),\n        (Cls(spam=1, foo=Cls(bar=Cls(bat=2))), {'my_field': 2}),\n        (Cls(x='123'), Err(r'my_field\\n +Field required \\[type=missing,')),\n        (Cls(x={2: 33}), Err(r'my_field\\n +Field required \\[type=missing,')),\n        (Cls(foo='01234'), Err(r'my_field\\n +Field required \\[type=missing,')),\n        (Cls(foo=[1]), Err(r'my_field\\n +Field required \\[type=missing,')),\n        (Cls, Err(r'Input should be a valid dictionary')),\n    ],\n    ids=repr,\n)\ndef test_from_attributes_path(input_value, expected):\n    v = SchemaValidator(\n        {\n            'type': 'model-fields',\n            'fields': {\n                'my_field': {\n                    'validation_alias': [['foo', 'bar', 'bat'], ['foo', 3], ['spam']],\n                    'type': 'model-field',\n                    'schema': {'type': 'int'},\n                }\n            },\n            'from_attributes': True,\n        },\n        {'loc_by_alias': False},\n    )\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=expected.message):\n            val = v.validate_python(input_value)\n            print(f'UNEXPECTED OUTPUT: {val!r}')\n    else:\n        model_dict, model_extra, fields_set = v.validate_python(input_value)\n        assert model_dict == expected\n        assert model_extra is None\n        assert fields_set == {'my_field'}\n\n\ndef test_from_attributes_path_error():\n    class PropertyError:\n        @property\n        def foo(self):\n            raise RuntimeError('intentional error')\n\n    v = SchemaValidator(\n        {\n            'type': 'model-fields',\n            'fields': {\n                'my_field': {\n                    'validation_alias': [['foo', 'bar', 'bat'], ['foo', 3], ['spam']],\n                    'type': 'model-field',\n                    'schema': {'type': 'int'},\n                }\n            },\n            'from_attributes': True,\n        }\n    )\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python(PropertyError())\n\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'get_attribute_error',\n            'loc': ('my_field',),\n            'msg': 'Error extracting attribute: RuntimeError: intentional error',\n            'input': HasRepr(IsStr(regex='.+PropertyError object at.+')),\n            'ctx': {'error': 'RuntimeError: intentional error'},\n        }\n    ]\n\n\ndef test_alias_extra(py_and_json: PyAndJson):\n    v = py_and_json(\n        {\n            'type': 'model-fields',\n            'extra_behavior': 'allow',\n            'fields': {\n                'field_a': {\n                    'validation_alias': [['FieldA'], ['foo', 2]],\n                    'type': 'model-field',\n                    'schema': {'type': 'int'},\n                }\n            },\n        },\n        {'loc_by_alias': False},\n    )\n    assert v.validate_test({'FieldA': 1}) == ({'field_a': 1}, {}, {'field_a'})\n    assert v.validate_test({'foo': [1, 2, 3]}) == ({'field_a': 3}, {}, {'field_a'})\n\n    # used_keys should be populated either though validation fails so \"FieldA\" is skipped in extra\n    with pytest.raises(ValidationError) as exc_info:\n        assert v.validate_test({'FieldA': '...'}) == ({'field_a': 1}, {}, {'field_a'})\n\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'int_parsing',\n            'loc': ('field_a',),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': '...',\n        }\n    ]\n\n\ndef test_alias_extra_from_attributes():\n    v = SchemaValidator(\n        {\n            'type': 'model-fields',\n            'extra_behavior': 'allow',\n            'from_attributes': True,\n            'fields': {\n                'field_a': {\n                    'validation_alias': [['FieldA'], ['foo', 2]],\n                    'type': 'model-field',\n                    'schema': {'type': 'int'},\n                }\n            },\n        }\n    )\n    assert v.validate_python({'FieldA': 1}) == ({'field_a': 1}, {}, {'field_a'})\n    assert v.validate_python(Cls(FieldA=1)) == ({'field_a': 1}, {}, {'field_a'})\n    assert v.validate_python(Cls(foo=[1, 2, 3])) == ({'field_a': 3}, {}, {'field_a'})\n    assert v.validate_python({'foo': [1, 2, 3]}) == ({'field_a': 3}, {}, {'field_a'})\n\n\ndef test_alias_extra_by_name(py_and_json: PyAndJson):\n    v = py_and_json(\n        {\n            'type': 'model-fields',\n            'extra_behavior': 'allow',\n            'from_attributes': True,\n            'populate_by_name': True,\n            'fields': {'field_a': {'validation_alias': 'FieldA', 'type': 'model-field', 'schema': {'type': 'int'}}},\n        }\n    )\n    assert v.validate_test({'FieldA': 1}) == ({'field_a': 1}, {}, {'field_a'})\n    assert v.validate_test({'field_a': 1}) == ({'field_a': 1}, {}, {'field_a'})\n    assert v.validate_python(Cls(FieldA=1)) == ({'field_a': 1}, {}, {'field_a'})\n    assert v.validate_python(Cls(field_a=1)) == ({'field_a': 1}, {}, {'field_a'})\n\n\ndef test_alias_extra_forbid(py_and_json: PyAndJson):\n    v = py_and_json(\n        {\n            'type': 'model-fields',\n            'extra_behavior': 'forbid',\n            'fields': {'field_a': {'type': 'model-field', 'validation_alias': 'FieldA', 'schema': {'type': 'int'}}},\n        }\n    )\n    assert v.validate_test({'FieldA': 1}) == ({'field_a': 1}, None, {'field_a'})\n\n\ndef test_with_default_factory():\n    v = SchemaValidator(\n        {\n            'type': 'model-fields',\n            'fields': {\n                'x': {\n                    'type': 'model-field',\n                    'schema': {'type': 'default', 'schema': {'type': 'str'}, 'default_factory': lambda: 'pikachu'},\n                }\n            },\n        }\n    )\n\n    assert v.validate_python({}) == ({'x': 'pikachu'}, None, set())\n    assert v.validate_python({'x': 'bulbi'}) == ({'x': 'bulbi'}, None, {'x'})\n\n\n@pytest.mark.parametrize(\n    'default_factory,error_message',\n    [\n        (lambda: 1 + 'a', \"unsupported operand type(s) for +: 'int' and 'str'\"),\n        (lambda x: 'a' + x, \"<lambda>() missing 1 required positional argument: 'x'\"),\n    ],\n)\ndef test_bad_default_factory(default_factory, error_message):\n    v = SchemaValidator(\n        {\n            'type': 'model-fields',\n            'fields': {\n                'x': {\n                    'type': 'model-field',\n                    'schema': {'type': 'default', 'schema': {'type': 'str'}, 'default_factory': default_factory},\n                }\n            },\n        }\n    )\n    with pytest.raises(TypeError, match=re.escape(error_message)):\n        v.validate_python({})\n\n\nclass TestOnError:\n    def test_on_error_bad_name(self):\n        with pytest.raises(SchemaError, match=\"Input should be 'raise', 'omit' or 'default'\"):\n            validate_core_schema(\n                {\n                    'type': 'model-fields',\n                    'fields': {\n                        'x': {\n                            'type': 'model-field',\n                            'schema': {'type': 'default', 'schema': {'type': 'str'}, 'on_error': 'rais'},\n                        }\n                    },\n                }\n            )\n\n    def test_on_error_bad_default(self):\n        with pytest.raises(SchemaError, match=\"'on_error = default' requires a `default` or `default_factory`\"):\n            SchemaValidator(\n                {\n                    'type': 'model-fields',\n                    'fields': {\n                        'x': {\n                            'type': 'model-field',\n                            'schema': {'type': 'default', 'schema': {'type': 'str'}, 'on_error': 'default'},\n                        }\n                    },\n                }\n            )\n\n    def test_on_error_raise_by_default(self, py_and_json: PyAndJson):\n        v = py_and_json({'type': 'model-fields', 'fields': {'x': {'type': 'model-field', 'schema': {'type': 'str'}}}})\n        assert v.validate_test({'x': 'foo'}) == ({'x': 'foo'}, None, {'x'})\n        with pytest.raises(ValidationError) as exc_info:\n            v.validate_test({'x': ['foo']})\n        assert exc_info.value.errors(include_url=False) == [\n            {'input': ['foo'], 'type': 'string_type', 'loc': ('x',), 'msg': 'Input should be a valid string'}\n        ]\n\n    def test_on_error_raise_explicit(self, py_and_json: PyAndJson):\n        v = py_and_json(\n            {\n                'type': 'model-fields',\n                'fields': {\n                    'x': {\n                        'type': 'model-field',\n                        'schema': {'type': 'default', 'schema': {'type': 'str'}, 'on_error': 'raise'},\n                    }\n                },\n            }\n        )\n        assert v.validate_test({'x': 'foo'}) == ({'x': 'foo'}, None, {'x'})\n        with pytest.raises(ValidationError) as exc_info:\n            v.validate_test({'x': ['foo']})\n        assert exc_info.value.errors(include_url=False) == [\n            {'input': ['foo'], 'type': 'string_type', 'loc': ('x',), 'msg': 'Input should be a valid string'}\n        ]\n\n    def test_on_error_default(self, py_and_json: PyAndJson):\n        v = py_and_json(\n            {\n                'type': 'model-fields',\n                'fields': {\n                    'x': {\n                        'type': 'model-field',\n                        'schema': {\n                            'type': 'default',\n                            'schema': {'type': 'str'},\n                            'on_error': 'default',\n                            'default': 'pika',\n                        },\n                    }\n                },\n            }\n        )\n        assert v.validate_test({'x': 'foo'}) == ({'x': 'foo'}, None, {'x'})\n        assert v.validate_test({'x': ['foo']}) == ({'x': 'pika'}, None, {'x'})\n\n    def test_on_error_default_factory(self, py_and_json: PyAndJson):\n        v = py_and_json(\n            {\n                'type': 'model-fields',\n                'fields': {\n                    'x': {\n                        'type': 'model-field',\n                        'schema': {\n                            'type': 'default',\n                            'schema': {'type': 'str'},\n                            'on_error': 'default',\n                            'default_factory': lambda: 'pika',\n                        },\n                    }\n                },\n            }\n        )\n        assert v.validate_test({'x': 'foo'}) == ({'x': 'foo'}, None, {'x'})\n        assert v.validate_test({'x': ['foo']}) == ({'x': 'pika'}, None, {'x'})\n\n    def test_wrap_on_error(self, py_and_json: PyAndJson):\n        def wrap_function(input_value, validator, info):\n            try:\n                return validator(input_value)\n            except ValidationError:\n                if isinstance(input_value, list):\n                    return str(len(input_value))\n                else:\n                    return repr(input_value)\n\n        v = py_and_json(\n            {\n                'type': 'model-fields',\n                'fields': {\n                    'x': {\n                        'type': 'model-field',\n                        'schema': {\n                            'type': 'default',\n                            'on_error': 'raise',\n                            'schema': {\n                                'type': 'function-wrap',\n                                'function': {'type': 'with-info', 'function': wrap_function},\n                                'schema': {'type': 'str'},\n                            },\n                        },\n                    }\n                },\n            }\n        )\n        assert v.validate_test({'x': 'foo'}) == ({'x': 'foo'}, None, {'x'})\n        assert v.validate_test({'x': ['foo']}) == ({'x': '1'}, None, {'x'})\n        assert v.validate_test({'x': ['foo', 'bar']}) == ({'x': '2'}, None, {'x'})\n        assert v.validate_test({'x': {'a': 'b'}}) == ({'x': \"{'a': 'b'}\"}, None, {'x'})\n\n\ndef test_frozen_field():\n    v = SchemaValidator(\n        {\n            'type': 'model-fields',\n            'fields': {\n                'name': {'type': 'model-field', 'schema': {'type': 'str'}},\n                'age': {'type': 'model-field', 'schema': {'type': 'int'}},\n                'is_developer': {\n                    'type': 'model-field',\n                    'schema': {'type': 'default', 'schema': {'type': 'bool'}, 'default': True},\n                    'frozen': True,\n                },\n            },\n        }\n    )\n    r1, model_extra, fields_set = v.validate_python({'name': 'Samuel', 'age': '36'})\n    assert r1 == {'name': 'Samuel', 'age': 36, 'is_developer': True}\n    assert model_extra is None\n    assert fields_set == {'name', 'age'}\n    v.validate_assignment(r1, 'age', '35')\n    assert r1 == {'name': 'Samuel', 'age': 35, 'is_developer': True}\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_assignment(r1, 'is_developer', False)\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'frozen_field', 'loc': ('is_developer',), 'msg': 'Field is frozen', 'input': False}\n    ]\n\n\n@pytest.mark.parametrize(\n    'config,schema_extra_behavior_kw',\n    [\n        (core_schema.CoreConfig(extra_fields_behavior='allow'), {}),\n        (core_schema.CoreConfig(extra_fields_behavior='allow'), {'extra_behavior': None}),\n        (core_schema.CoreConfig(), {'extra_behavior': 'allow'}),\n        (None, {'extra_behavior': 'allow'}),\n        (core_schema.CoreConfig(extra_fields_behavior='forbid'), {'extra_behavior': 'allow'}),\n    ],\n)\n@pytest.mark.parametrize(\n    'extras_schema_kw, expected_extra_value',\n    [({}, '123'), ({'extras_schema': None}, '123'), ({'extras_schema': core_schema.int_schema()}, 123)],\n    ids=['extras_schema=unset', 'extras_schema=None', 'extras_schema=int'],\n)\ndef test_extra_behavior_allow(\n    config: Union[core_schema.CoreConfig, None],\n    schema_extra_behavior_kw: Dict[str, Any],\n    extras_schema_kw: Dict[str, Any],\n    expected_extra_value: Any,\n):\n    v = SchemaValidator(\n        core_schema.model_fields_schema(\n            {'f': core_schema.model_field(core_schema.str_schema())}, **schema_extra_behavior_kw, **extras_schema_kw\n        ),\n        config=config,\n    )\n\n    m, model_extra, fields_set = v.validate_python({'f': 'x', 'extra_field': '123'})\n    assert m == {'f': 'x'}\n    assert model_extra == {'extra_field': expected_extra_value}\n    assert fields_set == {'f', 'extra_field'}\n\n    v.validate_assignment(m, 'f', 'y')\n    assert m == {'f': 'y'}\n\n    new_m, new_model_extra, new_fields_set = v.validate_assignment({**m, **model_extra}, 'not_f', '123')\n    assert new_m == {'f': 'y'}\n    assert new_model_extra == {'extra_field': expected_extra_value, 'not_f': expected_extra_value}\n    assert new_fields_set == {'not_f'}\n\n\n@pytest.mark.parametrize(\n    'config,schema_extra_behavior_kw',\n    [\n        (core_schema.CoreConfig(extra_fields_behavior='forbid'), {}),\n        (core_schema.CoreConfig(extra_fields_behavior='forbid'), {'extra_behavior': None}),\n        (core_schema.CoreConfig(), {'extra_behavior': 'forbid'}),\n        (None, {'extra_behavior': 'forbid'}),\n        (core_schema.CoreConfig(extra_fields_behavior='allow'), {'extra_behavior': 'forbid'}),\n    ],\n)\ndef test_extra_behavior_forbid(config: Union[core_schema.CoreConfig, None], schema_extra_behavior_kw: Dict[str, Any]):\n    v = SchemaValidator(\n        core_schema.model_fields_schema(\n            {'f': core_schema.model_field(core_schema.str_schema())}, **schema_extra_behavior_kw\n        ),\n        config=config,\n    )\n\n    m, model_extra, fields_set = v.validate_python({'f': 'x'})\n    assert m == {'f': 'x'}\n    assert fields_set == {'f'}\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python({'f': 'x', 'extra_field': 123})\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'extra_forbidden', 'loc': ('extra_field',), 'msg': 'Extra inputs are not permitted', 'input': 123}\n    ]\n\n    v.validate_assignment(m, 'f', 'y')\n    assert m['f'] == 'y'\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_assignment(m, 'not_f', 'xyz')\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'no_such_attribute',\n            'loc': ('not_f',),\n            'msg': \"Object has no attribute 'not_f'\",\n            'input': 'xyz',\n            'ctx': {'attribute': 'not_f'},\n        }\n    ]\n    assert 'not_f' not in m\n\n\n@pytest.mark.parametrize(\n    'config,schema_extra_behavior_kw',\n    [\n        (core_schema.CoreConfig(extra_fields_behavior='ignore'), {}),\n        (core_schema.CoreConfig(), {'extra_behavior': 'ignore'}),\n        (None, {'extra_behavior': 'ignore'}),\n        (core_schema.CoreConfig(extra_fields_behavior='forbid'), {'extra_behavior': 'ignore'}),\n        (core_schema.CoreConfig(), {}),\n        (core_schema.CoreConfig(), {'extra_behavior': None}),\n        (None, {'extra_behavior': None}),\n    ],\n)\ndef test_extra_behavior_ignore(config: Union[core_schema.CoreConfig, None], schema_extra_behavior_kw: Dict[str, Any]):\n    v = SchemaValidator(\n        core_schema.model_fields_schema(\n            {'f': core_schema.model_field(core_schema.str_schema())}, **schema_extra_behavior_kw\n        ),\n        config=config,\n    )\n\n    m, model_extra, fields_set = v.validate_python({'f': 'x', 'extra_field': 123})\n    assert m == {'f': 'x'}\n    assert model_extra is None\n    assert fields_set == {'f'}\n\n    v.validate_assignment(m, 'f', 'y')\n    assert m['f'] == 'y'\n\n    # even if we ignore extra attributes during initialization / validation\n    # we never ignore them during assignment\n    # instead if extra='ignore' was set (or nothing was set since that's the default)\n    # we treat it as if it were extra='forbid'\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_assignment(m, 'not_f', 'xyz')\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'no_such_attribute',\n            'loc': ('not_f',),\n            'msg': \"Object has no attribute 'not_f'\",\n            'input': 'xyz',\n            'ctx': {'attribute': 'not_f'},\n        }\n    ]\n    assert 'not_f' not in m\n", "tests/validators/test_pickling.py": "import pickle\nimport re\nfrom datetime import datetime, timedelta, timezone\n\nimport pytest\n\nfrom pydantic_core import core_schema, validate_core_schema\nfrom pydantic_core._pydantic_core import SchemaValidator, ValidationError\n\n\ndef test_basic_schema_validator():\n    v = SchemaValidator(\n        validate_core_schema(\n            {'type': 'dict', 'strict': True, 'keys_schema': {'type': 'int'}, 'values_schema': {'type': 'int'}}\n        )\n    )\n    v = pickle.loads(pickle.dumps(v))\n    assert v.validate_python({'1': 2, '3': 4}) == {1: 2, 3: 4}\n    assert v.validate_python({}) == {}\n    with pytest.raises(ValidationError, match=re.escape('[type=dict_type, input_value=[], input_type=list]')):\n        v.validate_python([])\n\n\ndef test_schema_validator_containing_config():\n    \"\"\"\n    Verify that the config object is not lost during (de)serialization.\n    \"\"\"\n    v = SchemaValidator(\n        core_schema.model_fields_schema({'f': core_schema.model_field(core_schema.str_schema())}),\n        config=core_schema.CoreConfig(extra_fields_behavior='allow'),\n    )\n    v = pickle.loads(pickle.dumps(v))\n\n    m, model_extra, fields_set = v.validate_python({'f': 'x', 'extra_field': '123'})\n    assert m == {'f': 'x'}\n    # If the config was lost during (de)serialization, the below checks would fail as\n    # the default behavior is to ignore extra fields.\n    assert model_extra == {'extra_field': '123'}\n    assert fields_set == {'f', 'extra_field'}\n\n    v.validate_assignment(m, 'f', 'y')\n    assert m == {'f': 'y'}\n\n\ndef test_schema_validator_tz_pickle() -> None:\n    \"\"\"\n    https://github.com/pydantic/pydantic-core/issues/589\n    \"\"\"\n    v = SchemaValidator(core_schema.datetime_schema())\n    original = datetime(2022, 6, 8, 12, 13, 14, tzinfo=timezone(timedelta(hours=-12, minutes=-15)))\n    validated = v.validate_python('2022-06-08T12:13:14-12:15')\n    assert validated == original\n    assert pickle.loads(pickle.dumps(validated)) == validated == original\n", "tests/validators/test_datetime.py": "import copy\nimport json\nimport platform\nimport re\nfrom datetime import date, datetime, time, timedelta, timezone, tzinfo\nfrom decimal import Decimal\nfrom typing import Dict\n\nimport pytest\n\ntry:\n    import zoneinfo\nexcept ImportError:\n    # TODO: can remove this once we drop support for python 3.8\n    from backports import zoneinfo\n\nfrom pydantic_core import SchemaError, SchemaValidator, ValidationError, core_schema, validate_core_schema\n\nfrom ..conftest import Err, PyAndJson\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        (datetime(2022, 6, 8, 12, 13, 14), datetime(2022, 6, 8, 12, 13, 14)),\n        (date(2022, 6, 8), datetime(2022, 6, 8)),\n        ('2022-01-01', datetime(2022, 1, 1, 0, 0, 0)),\n        ('2022-06-08T12:13:14', datetime(2022, 6, 8, 12, 13, 14)),\n        ('1000000000000', datetime(2001, 9, 9, 1, 46, 40, tzinfo=timezone.utc)),\n        (b'2022-06-08T12:13:14', datetime(2022, 6, 8, 12, 13, 14)),\n        (b'2022-06-08T12:13:14Z', datetime(2022, 6, 8, 12, 13, 14, tzinfo=timezone.utc)),\n        ((1,), Err('Input should be a valid datetime [type=datetime_type')),\n        (time(1, 2, 3), Err('Input should be a valid datetime [type=datetime_type')),\n        (Decimal('1654646400'), datetime(2022, 6, 8, tzinfo=timezone.utc)),\n        ('1654646400', datetime(2022, 6, 8, tzinfo=timezone.utc)),\n        (Decimal('1654646400.123456'), datetime(2022, 6, 8, 0, 0, 0, 123456, tzinfo=timezone.utc)),\n        (Decimal('1654646400.1234564'), datetime(2022, 6, 8, 0, 0, 0, 123456, tzinfo=timezone.utc)),\n        (Decimal('1654646400.1234568'), datetime(2022, 6, 8, 0, 0, 0, 123457, tzinfo=timezone.utc)),\n        ('1654646400.1234568', datetime(2022, 6, 8, 0, 0, 0, 123457, tzinfo=timezone.utc)),\n        (253_402_300_800_000, Err('should be a valid datetime, dates after 9999 are not supported as unix timestamps')),\n        (-20_000_000_000, Err('should be a valid datetime, dates before 1600 are not supported as unix timestamps')),\n        (float('nan'), Err('Input should be a valid datetime, NaN values not permitted [type=datetime_parsing,')),\n        (float('inf'), Err('Input should be a valid datetime, dates after 9999')),\n        (float('-inf'), Err('Input should be a valid datetime, dates before 1600')),\n        ('-', Err('Input should be a valid datetime or date, input is too short [type=datetime_from_date_parsing,')),\n        ('+', Err('Input should be a valid datetime or date, input is too short [type=datetime_from_date_parsing,')),\n        (\n            '2022-02-30',\n            Err(\n                'Input should be a valid datetime or date, day value is outside expected range [type=datetime_from_date_parsing,'\n            ),\n        ),\n    ],\n)\ndef test_datetime(input_value, expected):\n    v = SchemaValidator({'type': 'datetime'})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            result = v.validate_python(input_value)\n            print(f'input_value={input_value} result={result}')\n    else:\n        output = v.validate_python(input_value)\n        assert output == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        (datetime(2022, 6, 8, 12, 13, 14), datetime(2022, 6, 8, 12, 13, 14)),\n        (date(2022, 6, 8), Err('Input should be a valid datetime [type=datetime_type')),\n        ('2022-06-08T12:13:14', Err('Input should be a valid datetime [type=datetime_type')),\n        (b'2022-06-08T12:13:14', Err('Input should be a valid datetime [type=datetime_type')),\n        (time(1, 2, 3), Err('Input should be a valid datetime [type=datetime_type')),\n        (1654646400, Err('Input should be a valid datetime [type=datetime_type')),\n        (Decimal('1654646400'), Err('Input should be a valid datetime [type=datetime_type')),\n    ],\n)\ndef test_datetime_strict(input_value, expected):\n    v = SchemaValidator({'type': 'datetime', 'strict': True})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_python(input_value)\n    else:\n        output = v.validate_python(input_value)\n        assert output == expected\n\n\ndef test_keep_tz():\n    tz = zoneinfo.ZoneInfo('Europe/London')\n    dt = datetime(2022, 6, 14, 12, 13, 14, tzinfo=tz)\n    v = SchemaValidator({'type': 'datetime'})\n\n    output = v.validate_python(dt)\n    assert output == dt\n\n    # dst object is unaffected by validation\n    assert output.tzinfo.dst(datetime(2022, 6, 1)) == timedelta(seconds=3600)\n    assert output.tzinfo.dst(datetime(2022, 1, 1)) == timedelta(seconds=0)\n\n\ndef test_keep_tz_bound():\n    tz = zoneinfo.ZoneInfo('Europe/London')\n    dt = datetime(2022, 6, 14, 12, 13, 14, tzinfo=tz)\n    v = SchemaValidator({'type': 'datetime', 'gt': datetime(2022, 1, 1)})\n\n    output = v.validate_python(dt)\n    assert output == dt\n\n    # dst object is unaffected by validation\n    assert output.tzinfo.dst(datetime(2022, 6, 1)) == timedelta(hours=1)\n    assert output.tzinfo.dst(datetime(2022, 1, 1)) == timedelta(0)\n\n    with pytest.raises(ValidationError, match=r'Input should be greater than 2022-01-01T00:00:00 \\[type=greater_than'):\n        v.validate_python(datetime(2021, 6, 14, tzinfo=tz))\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ('2022-06-08T12:13:14', datetime(2022, 6, 8, 12, 13, 14)),\n        ('2022-06-08T12:13:14Z', datetime(2022, 6, 8, 12, 13, 14, tzinfo=timezone.utc)),\n        (\n            '2022-06-08T12:13:14+12:15',\n            datetime(2022, 6, 8, 12, 13, 14, tzinfo=timezone(timedelta(hours=12, minutes=15))),\n        ),\n        (\n            '2022-06-08T12:13:14+23:59',\n            datetime(2022, 6, 8, 12, 13, 14, tzinfo=timezone(timedelta(hours=23, minutes=59))),\n        ),\n        (1655205632, datetime(2022, 6, 14, 11, 20, 32, tzinfo=timezone.utc)),\n        (1655205632.331557, datetime(2022, 6, 14, 11, 20, 32, microsecond=331557, tzinfo=timezone.utc)),\n        (\n            '2022-06-08T12:13:14+24:00',\n            Err(\n                'Input should be a valid datetime or date, unexpected extra characters at the end of the input [type=datetime_from_date_parsing,'\n            ),\n        ),\n        (True, Err('Input should be a valid datetime [type=datetime_type')),\n        (None, Err('Input should be a valid datetime [type=datetime_type')),\n        ([1, 2, 3], Err('Input should be a valid datetime [type=datetime_type')),\n    ],\n)\ndef test_datetime_json(py_and_json: PyAndJson, input_value, expected):\n    v = py_and_json({'type': 'datetime'})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_test(input_value)\n    else:\n        output = v.validate_test(input_value)\n        assert output == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ('2022-06-08T12:13:14', datetime(2022, 6, 8, 12, 13, 14)),\n        ('2022-06-08T12:13:14Z', datetime(2022, 6, 8, 12, 13, 14, tzinfo=timezone.utc)),\n        (123, Err('Input should be a valid datetime [type=datetime_type')),\n        (123.4, Err('Input should be a valid datetime [type=datetime_type')),\n        (True, Err('Input should be a valid datetime [type=datetime_type')),\n    ],\n)\ndef test_datetime_strict_json(input_value, expected):\n    v = SchemaValidator({'type': 'datetime', 'strict': True})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_json(json.dumps(input_value))\n    else:\n        output = v.validate_json(json.dumps(input_value))\n        assert output == expected\n\n\ndef test_custom_timezone_repr():\n    output = SchemaValidator({'type': 'datetime'}).validate_python('2022-06-08T12:13:14-12:15')\n    assert output == datetime(2022, 6, 8, 12, 13, 14, tzinfo=timezone(timedelta(hours=-12, minutes=-15)))\n    assert output.tzinfo.utcoffset(output) == timedelta(hours=-12, minutes=-15)\n    assert output.tzinfo.dst(output) is None\n    assert output.tzinfo.tzname(output) == '-12:15'\n    assert str(output.tzinfo) == '-12:15'\n    assert repr(output.tzinfo) == 'TzInfo(-12:15)'\n\n\ndef test_custom_timezone_utc_repr():\n    output = SchemaValidator({'type': 'datetime'}).validate_python('2022-06-08T12:13:14Z')\n    assert output == datetime(2022, 6, 8, 12, 13, 14, tzinfo=timezone(timedelta(0)))\n    assert output.tzinfo.utcoffset(output) == timedelta(0)\n    assert output.tzinfo.dst(output) is None\n    assert output.tzinfo.tzname(output) == 'UTC'\n    assert str(output.tzinfo) == 'UTC'\n    assert repr(output.tzinfo) == 'TzInfo(UTC)'\n\n\ndef test_tz_comparison():\n    tz = zoneinfo.ZoneInfo('Europe/London')\n    uk_3pm = datetime(2022, 1, 1, 15, 0, 0, tzinfo=tz)\n\n    # two times are the same instant, therefore le and ge are both ok\n    v = SchemaValidator({'type': 'datetime', 'le': uk_3pm}).validate_python('2022-01-01T16:00:00+01:00')\n    assert v == datetime(2022, 1, 1, 16, 0, 0, tzinfo=timezone(timedelta(hours=1)))\n\n    v = SchemaValidator({'type': 'datetime', 'ge': uk_3pm}).validate_python('2022-01-01T16:00:00+01:00')\n    assert v == datetime(2022, 1, 1, 16, 0, 0, tzinfo=timezone(timedelta(hours=1)))\n\n    # but not gt\n    with pytest.raises(ValidationError, match=r'Input should be greater than 2022-01-01T15:00:00Z \\[type=greater_than'):\n        SchemaValidator({'type': 'datetime', 'gt': uk_3pm}).validate_python('2022-01-01T16:00:00+01:00')\n\n\ndef test_tz_info_deepcopy():\n    output = SchemaValidator({'type': 'datetime'}).validate_python('2023-02-15T16:23:44.037Z')\n    c = copy.deepcopy(output)\n    assert repr(output.tzinfo) == 'TzInfo(UTC)'\n    assert repr(c.tzinfo) == 'TzInfo(UTC)'\n    assert c == output\n\n\ndef test_tz_info_copy():\n    output = SchemaValidator({'type': 'datetime'}).validate_python('2023-02-15T16:23:44.037Z')\n    c = copy.copy(output)\n    assert repr(output.tzinfo) == 'TzInfo(UTC)'\n    assert repr(c.tzinfo) == 'TzInfo(UTC)'\n    assert c == output\n\n\ndef test_custom_tz():\n    class CustomTz(tzinfo):\n        def utcoffset(self, _dt):\n            return None\n\n        def dst(self, _dt):\n            return None\n\n        def tzname(self, _dt):\n            return 'CustomTZ'\n\n    schema = SchemaValidator({'type': 'datetime', 'gt': datetime(2022, 1, 1, 15, 0, 0)})\n\n    dt = datetime(2022, 1, 1, 16, 0, 0, tzinfo=CustomTz())\n    outcome = schema.validate_python(dt)\n    assert outcome == dt\n\n\ndef test_custom_invalid_tz():\n    class CustomTz(tzinfo):\n        # utcoffset is not implemented!\n\n        def tzname(self, _dt):\n            return 'CustomTZ'\n\n    schema = SchemaValidator({'type': 'datetime', 'gt': datetime(2022, 1, 1, 15, 0, 0)})\n\n    dt = datetime(2022, 1, 1, 16, 0, 0, tzinfo=CustomTz())\n    # perhaps this should be a ValidationError? but we don't catch other errors\n    with pytest.raises(ValidationError) as excinfo:\n        schema.validate_python(dt)\n\n    # exception messages differ between python and pypy\n    if platform.python_implementation() == 'PyPy':\n        error_message = 'NotImplementedError: tzinfo subclass must override utcoffset()'\n    else:\n        error_message = 'NotImplementedError: a tzinfo subclass must implement utcoffset()'\n\n    assert excinfo.value.errors(include_url=False) == [\n        {\n            'type': 'datetime_object_invalid',\n            'loc': (),\n            'msg': f'Invalid datetime object, got {error_message}',\n            'input': dt,\n            'ctx': {'error': error_message},\n        }\n    ]\n\n\ndef test_dict_py():\n    v = SchemaValidator({'type': 'dict', 'keys_schema': {'type': 'datetime'}, 'values_schema': {'type': 'int'}})\n    assert v.validate_python({datetime(2000, 1, 1): 2, datetime(2000, 1, 2): 4}) == {\n        datetime(2000, 1, 1): 2,\n        datetime(2000, 1, 2): 4,\n    }\n\n\ndef test_dict(py_and_json: PyAndJson):\n    v = py_and_json({'type': 'dict', 'keys_schema': {'type': 'datetime'}, 'values_schema': {'type': 'int'}})\n    assert v.validate_test({'2000-01-01T00:00': 2, '2000-01-02T00:00': 4}) == {\n        datetime(2000, 1, 1): 2,\n        datetime(2000, 1, 2): 4,\n    }\n\n\ndef test_union():\n    v = SchemaValidator({'type': 'union', 'choices': [{'type': 'str'}, {'type': 'datetime'}]})\n    assert v.validate_python('2022-01-02T00:00') == '2022-01-02T00:00'\n    assert v.validate_python(datetime(2022, 1, 2)) == datetime(2022, 1, 2)\n\n    v = SchemaValidator({'type': 'union', 'choices': [{'type': 'datetime'}, {'type': 'str'}]})\n    assert v.validate_python('2022-01-02T00:00') == '2022-01-02T00:00'\n    assert v.validate_python(datetime(2022, 1, 2)) == datetime(2022, 1, 2)\n\n\ndef test_invalid_constraint():\n    with pytest.raises(SchemaError, match=r'datetime\\.gt\\n  Input should be a valid datetime'):\n        validate_core_schema({'type': 'datetime', 'gt': 'foobar'})\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ('2022-06-08T12:13:14', datetime(2022, 6, 8, 12, 13, 14)),\n        ('2022-06-08T12:13:14Z', datetime(2022, 6, 8, 12, 13, 14, tzinfo=timezone.utc)),\n        (1655205632, datetime(2022, 6, 14, 11, 20, 32, tzinfo=timezone.utc)),\n        ('2068-06-08T12:13:14', Err('Input should be in the past [type=datetime_past,')),\n        (3105730800, Err('Input should be in the past [type=datetime_past,')),\n    ],\n)\ndef test_datetime_past(py_and_json: PyAndJson, input_value, expected):\n    v = py_and_json(core_schema.datetime_schema(now_utc_offset=0, now_op='past'))\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_test(input_value)\n    else:\n        output = v.validate_test(input_value)\n        assert output == expected\n\n\ndef test_datetime_past_timezone():\n    v = SchemaValidator(core_schema.datetime_schema(now_utc_offset=0, now_op='past'))\n    now_utc = datetime.now(timezone.utc) - timedelta(seconds=1)\n    assert v.isinstance_python(now_utc)\n    # \"later\" in the day\n    assert v.isinstance_python(now_utc.astimezone(zoneinfo.ZoneInfo('Europe/Istanbul')))\n    # \"earlier\" in the day\n    assert v.isinstance_python(now_utc.astimezone(zoneinfo.ZoneInfo('America/Los_Angeles')))\n\n    soon_utc = now_utc + timedelta(minutes=1)\n    assert not v.isinstance_python(soon_utc)\n\n    # \"later\" in the day\n    assert not v.isinstance_python(soon_utc.astimezone(zoneinfo.ZoneInfo('Europe/Istanbul')))\n    # \"earlier\" in the day\n    assert not v.isinstance_python(soon_utc.astimezone(zoneinfo.ZoneInfo('America/Los_Angeles')))\n\n    # input value is timezone naive, so we do a dumb comparison in these terms the istanbul time is later so fails\n    # wile the LA time is earlier so passes\n    assert not v.isinstance_python(soon_utc.astimezone(zoneinfo.ZoneInfo('Europe/Istanbul')).replace(tzinfo=None))\n    assert v.isinstance_python(soon_utc.astimezone(zoneinfo.ZoneInfo('America/Los_Angeles')).replace(tzinfo=None))\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ('2068-06-08T12:13:14', datetime(2068, 6, 8, 12, 13, 14)),\n        ('2068-06-08T12:13:14Z', datetime(2068, 6, 8, 12, 13, 14, tzinfo=timezone.utc)),\n        (3105730800, datetime(2068, 5, 31, 23, 0, tzinfo=timezone.utc)),\n        ('2022-06-08T12:13:14', Err('Input should be in the future [type=datetime_future,')),\n        (1655205632, Err('Input should be in the future [type=datetime_future,')),\n    ],\n)\ndef test_datetime_future(py_and_json: PyAndJson, input_value, expected):\n    v = py_and_json(core_schema.datetime_schema(now_utc_offset=0, now_op='future'))\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_test(input_value)\n    else:\n        output = v.validate_test(input_value)\n        assert output == expected\n\n\ndef test_datetime_future_timezone():\n    v = SchemaValidator(core_schema.datetime_schema(now_utc_offset=0, now_op='future'))\n    now_utc = datetime.now(timezone.utc)\n\n    soon_utc = now_utc + timedelta(minutes=1)\n    assert v.isinstance_python(soon_utc)\n\n    # \"later\" in the day\n    assert v.isinstance_python(soon_utc.astimezone(zoneinfo.ZoneInfo('Europe/Istanbul')))\n    # \"earlier\" in the day\n    assert v.isinstance_python(soon_utc.astimezone(zoneinfo.ZoneInfo('America/Los_Angeles')))\n\n    past_utc = now_utc - timedelta(minutes=1)\n    assert not v.isinstance_python(past_utc)\n\n    # \"later\" in the day\n    assert not v.isinstance_python(past_utc.astimezone(zoneinfo.ZoneInfo('Europe/Istanbul')))\n    # \"earlier\" in the day\n    assert not v.isinstance_python(past_utc.astimezone(zoneinfo.ZoneInfo('America/Los_Angeles')))\n\n\ndef test_mock_utc_offset_8_hours(mocker):\n    \"\"\"\n    Test that mocking time.localtime() is working, note that due to caching in datetime_etc,\n    time.localtime() will return `{'tm_gmtoff': 8 * 60 * 60}` for the rest of the session.\n    \"\"\"\n    mocker.patch('time.localtime', return_value=type('time.struct_time', (), {'tm_gmtoff': 8 * 60 * 60}))\n    v = SchemaValidator(core_schema.datetime_schema(now_op='future'))\n    future = datetime.now(timezone.utc).replace(tzinfo=None) + timedelta(hours=8, minutes=1)\n    assert v.isinstance_python(future)\n\n    future = datetime.now(timezone.utc).replace(tzinfo=None) + timedelta(hours=7, minutes=59)\n    assert not v.isinstance_python(future)\n\n\ndef test_offset_too_large():\n    with pytest.raises(SchemaError, match=r'Input should be greater than -86400 \\[type=greater_than,'):\n        validate_core_schema(core_schema.datetime_schema(now_op='past', now_utc_offset=-24 * 3600))\n\n\ndef test_raises_schema_error_for_unknown_constraint_kind():\n    with pytest.raises(\n        SchemaError,\n        match=(r'Input should be \\'aware\\' or \\'naive\\' \\[type=literal_error, input_value=\\'foo\\', input_type=str\\]'),\n    ):\n        validate_core_schema({'type': 'datetime', 'tz_constraint': 'foo'})\n\n\ndef test_aware():\n    v = SchemaValidator(core_schema.datetime_schema(tz_constraint='aware'))\n    value = datetime.now(tz=timezone.utc)\n    assert value is v.validate_python(value)\n    assert v.validate_python('2022-06-08T12:13:14Z') == datetime(2022, 6, 8, 12, 13, 14, tzinfo=timezone.utc)\n\n    value = datetime.now()\n    with pytest.raises(ValidationError, match=r'Input should have timezone info \\[type=timezone_aware,'):\n        v.validate_python(value)\n\n    with pytest.raises(ValidationError, match=r'Input should have timezone info \\[type=timezone_aware,'):\n        v.validate_python('2022-06-08T12:13:14')\n\n\ndef test_naive():\n    v = SchemaValidator(core_schema.datetime_schema(tz_constraint='naive'))\n    value = datetime.now()\n    assert value is v.validate_python(value)\n    assert v.validate_python('2022-06-08T12:13:14') == datetime(2022, 6, 8, 12, 13, 14)\n\n    value = datetime.now(tz=timezone.utc)\n    with pytest.raises(ValidationError, match=r'Input should not have timezone info \\[type=timezone_naive,'):\n        v.validate_python(value)\n\n    with pytest.raises(ValidationError, match=r'Input should not have timezone info \\[type=timezone_naive,'):\n        v.validate_python('2022-06-08T12:13:14Z')\n\n\ndef test_aware_specific():\n    v = SchemaValidator(core_schema.datetime_schema(tz_constraint=0))\n    value = datetime.now(tz=timezone.utc)\n    assert value is v.validate_python(value)\n    assert v.validate_python('2022-06-08T12:13:14Z') == datetime(2022, 6, 8, 12, 13, 14, tzinfo=timezone.utc)\n\n    value = datetime.now()\n    with pytest.raises(ValidationError, match='Input should have timezone info'):\n        v.validate_python(value)\n\n    value = datetime.now(tz=timezone(timedelta(hours=1)))\n    with pytest.raises(ValidationError, match='Timezone offset of 0 required, got 3600') as exc_info:\n        v.validate_python(value)\n\n    # insert_assert(exc_info.value.errors())\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'timezone_offset',\n            'loc': (),\n            'msg': 'Timezone offset of 0 required, got 3600',\n            'input': value,\n            'ctx': {'tz_expected': 0, 'tz_actual': 3600},\n        }\n    ]\n    with pytest.raises(ValidationError, match='Timezone offset of 0 required, got 3600'):\n        v.validate_python('2022-06-08T12:13:14+01:00')\n\n\ndef test_neg_7200():\n    v = SchemaValidator(core_schema.datetime_schema(tz_constraint=-7200))\n    value = datetime.now(tz=timezone(timedelta(hours=-2)))\n    assert value is v.validate_python(value)\n\n    value = datetime.now()\n    with pytest.raises(ValidationError, match='Input should have timezone info'):\n        v.validate_python(value)\n\n    value = datetime.now(tz=timezone.utc)\n    with pytest.raises(ValidationError, match='Timezone offset of -7200 required, got 0'):\n        v.validate_python(value)\n    with pytest.raises(ValidationError, match='Timezone offset of -7200 required, got 0'):\n        v.validate_python('2022-06-08T12:13:14Z')\n\n\ndef test_tz_constraint_too_high():\n    with pytest.raises(SchemaError, match='OverflowError: Python int too large to convert to C long'):\n        SchemaValidator(core_schema.datetime_schema(tz_constraint=2**64))\n\n\ndef test_tz_constraint_wrong():\n    with pytest.raises(SchemaError, match=\"Input should be 'aware' or 'naive\"):\n        validate_core_schema(core_schema.datetime_schema(tz_constraint='wrong'))\n\n\ndef test_tz_hash() -> None:\n    v = SchemaValidator(core_schema.datetime_schema())\n    lookup: Dict[datetime, str] = {}\n    for day in range(1, 10):\n        input_str = f'2022-06-{day:02}T12:13:14-12:15'\n        validated = v.validate_python(input_str)\n        lookup[validated] = input_str\n\n    assert len(lookup) == 9\n    assert (\n        lookup[datetime(2022, 6, 8, 12, 13, 14, tzinfo=timezone(timedelta(hours=-12, minutes=-15)))]\n        == '2022-06-08T12:13:14-12:15'\n    )\n\n\ndef test_tz_cmp() -> None:\n    v = SchemaValidator(core_schema.datetime_schema())\n    validated1 = v.validate_python('2022-06-08T12:13:14-12:15')\n    validated2 = v.validate_python('2022-06-08T12:13:14-12:14')\n\n    assert validated1 > validated2\n    assert validated2 < validated1\n", "tests/validators/test_int.py": "import json\nimport re\nfrom decimal import Decimal\nfrom typing import Any, Dict\n\nimport pytest\nfrom dirty_equals import IsStr\n\nfrom pydantic_core import SchemaValidator, ValidationError, core_schema\n\nfrom ..conftest import Err, PyAndJson, plain_repr\n\ni64_max = 9_223_372_036_854_775_807\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        (False, 0),\n        (True, 1),\n        (0, 0),\n        ('0', 0),\n        ('00', 0),\n        ('000', 0),\n        ('0_000', 0),\n        ('+0', 0),\n        ('+00', 0),\n        ('+000', 0),\n        ('+0_000', 0),\n        (1, 1),\n        ('  1  ', 1),\n        ('-1', -1),\n        ('-1.0', -1),\n        (42, 42),\n        ('42', 42),\n        (42.0, 42),\n        ('0.0', 0),\n        ('00.0', 0),\n        ('00.00', 0),\n        ('42.0', 42),\n        ('42.00', 42),\n        ('042', 42),\n        ('01', 1),\n        ('09', 9),\n        ('00_', Err('Input should be a valid integer, unable to parse string as an integer')),\n        # next character after 9 is not valid\n        ('0:', Err('Input should be a valid integer, unable to parse string as an integer')),\n        ('+4_2', 42),\n        ('+0_42', 42),\n        ('+4_2.0', 42),\n        ('+04_2.0', 42),\n        ('++4_2', Err('Input should be a valid integer, unable to parse string as an integer')),\n        ('-+1', Err('Input should be a valid integer, unable to parse string as an integer')),\n        ('+-1', Err('Input should be a valid integer, unable to parse string as an integer')),\n        ('4_2', 42),\n        ('0_42', 42),\n        ('4_2.0', 42),\n        ('04_2.0', 42),\n        ('  04_2.0 ', 42),\n        ('  0_42.0 ', 42),\n        ('  _042.0 ', Err('Input should be a valid integer, unable to parse string as an integer')),\n        ('42_', Err('Input should be a valid integer, unable to parse string as an integer')),\n        ('42_.0', Err('Input should be a valid integer, unable to parse string as an integer')),\n        ('000001', 1),\n        ('123456789.0', 123_456_789),\n        (' ', Err('Input should be a valid integer, unable to parse string as an integer')),\n        ('1.', Err('Input should be a valid integer, unable to parse string as an integer')),\n        ('42.', Err('Input should be a valid integer, unable to parse string as an integer')),\n        ('123456789123456.00001', Err('Input should be a valid integer, unable to parse string as an integer')),\n        (int(1e10), int(1e10)),\n        (i64_max, i64_max),\n        (i64_max + 1, i64_max + 1),\n        (i64_max * 2, i64_max * 2),\n        pytest.param(\n            12.5,\n            Err('Input should be a valid integer, got a number with a fractional part [type=int_from_float'),\n            id='float-remainder',\n        ),\n        pytest.param(\n            'wrong',\n            Err('Input should be a valid integer, unable to parse string as an integer [type=int_parsing'),\n            id='string',\n        ),\n        pytest.param(None, Err('Input should be a valid integer [type=int_type'), id='list'),\n        pytest.param([1, 2], Err('Input should be a valid integer [type=int_type'), id='list'),\n    ],\n)\ndef test_int_py_and_json(py_and_json: PyAndJson, input_value, expected):\n    v = py_and_json({'type': 'int'})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_test(input_value)\n    else:\n        output = v.validate_test(input_value)\n        assert output == expected\n        assert type(output) == int\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        (Decimal('1'), 1),\n        (Decimal('1' + '0' * 1_000), int('1' + '0' * 1_000)),  # a large decimal\n        (Decimal('1.0'), 1),\n        (1.0, 1),\n        (i64_max, i64_max),\n        (str(i64_max), i64_max),\n        (str(i64_max * 2), i64_max * 2),\n        (i64_max + 1, i64_max + 1),\n        (-i64_max + 1, -i64_max + 1),\n        (i64_max * 2, i64_max * 2),\n        (-i64_max * 2, -i64_max * 2),\n        pytest.param(\n            1.00000000001,\n            Err(\n                'Input should be a valid integer, got a number with a fractional part '\n                '[type=int_from_float, input_value=1.00000000001, input_type=float]'\n            ),\n            id='decimal-remainder',\n        ),\n        pytest.param(\n            Decimal('1.001'),\n            Err(\n                'Input should be a valid integer, got a number with a fractional part '\n                \"[type=int_from_float, input_value=Decimal('1.001'), input_type=Decimal]\"\n            ),\n            id='decimal-remainder',\n        ),\n        pytest.param(\n            (1, 2),\n            Err('Input should be a valid integer [type=int_type, input_value=(1, 2), input_type=tuple]'),\n            id='tuple',\n        ),\n    ],\n    ids=repr,\n)\ndef test_int(input_value, expected):\n    v = SchemaValidator({'type': 'int'})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_python(input_value)\n    else:\n        output = v.validate_python(input_value)\n        assert output == expected\n        assert isinstance(output, int)\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        pytest.param(Decimal('1'), 1),\n        pytest.param(Decimal('1.0'), 1),\n        pytest.param(i64_max, i64_max, id='i64_max'),\n        pytest.param(i64_max + 1, i64_max + 1, id='i64_max+1'),\n        pytest.param(\n            -1,\n            Err('Input should be greater than 0 [type=greater_than, input_value=-1, input_type=int]'),\n            id='-1',\n        ),\n        (\n            -i64_max + 1,\n            Err('Input should be greater than 0 [type=greater_than, input_value=-9223372036854775806, input_type=int]'),\n        ),\n        (i64_max * 2, i64_max * 2),\n        (int('9' * 30), int('9' * 30)),\n        (0, Err('Input should be greater than 0 [type=greater_than, input_value=0, input_type=int]')),\n        (-1, Err('Input should be greater than 0 [type=greater_than, input_value=-1, input_type=int]')),\n        pytest.param(\n            Decimal('1.001'),\n            Err(\n                'Input should be a valid integer, got a number with a fractional part '\n                \"[type=int_from_float, input_value=Decimal('1.001'), input_type=Decimal]\"\n            ),\n            id='decimal-remainder',\n        ),\n        pytest.param(\n            (1, 2),\n            Err('Input should be a valid integer [type=int_type, input_value=(1, 2), input_type=tuple]'),\n            id='tuple',\n        ),\n    ],\n)\ndef test_positive_int(input_value, expected):\n    v = SchemaValidator({'type': 'int', 'gt': 0})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_python(input_value)\n    else:\n        output = v.validate_python(input_value)\n        assert output == expected\n        assert isinstance(output, int)\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        (-1, -1),\n        (0, Err('Input should be less than 0 [type=less_than, input_value=0, input_type=int]')),\n        (-i64_max, -i64_max),\n        (-i64_max - 1, -i64_max - 1),\n        (-int('9' * 30), -int('9' * 30)),\n    ],\n)\ndef test_negative_int(input_value, expected):\n    v = SchemaValidator({'type': 'int', 'lt': 0})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_python(input_value)\n    else:\n        output = v.validate_python(input_value)\n        assert output == expected\n        assert isinstance(output, int)\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        (1, 1),\n        (i64_max, i64_max),\n        (i64_max + 1, i64_max + 1),\n        (i64_max * 2, i64_max * 2),\n        (int(1e30), int(1e30)),\n        (0, Err('Input should be greater than 0 [type=greater_than, input_value=0, input_type=int]')),\n        (-1, Err('Input should be greater than 0 [type=greater_than, input_value=-1, input_type=int]')),\n        pytest.param(\n            [1, 2],\n            Err('Input should be a valid integer [type=int_type, input_value=[1, 2], input_type=list]'),\n            id='list',\n        ),\n    ],\n)\ndef test_positive_json(input_value, expected):\n    v = SchemaValidator({'type': 'int', 'gt': 0})\n    json_input = json.dumps(input_value)\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_json(json_input)\n    else:\n        output = v.validate_json(json_input)\n        assert output == expected\n        assert isinstance(output, int)\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        (-1, -1),\n        (0, Err('Input should be less than 0 [type=less_than, input_value=0, input_type=int]')),\n        (-i64_max, -i64_max),\n        (-i64_max - 1, -i64_max - 1),\n        (-i64_max * 2, -i64_max * 2),\n    ],\n)\ndef test_negative_json(input_value, expected):\n    v = SchemaValidator({'type': 'int', 'lt': 0})\n    json_input = json.dumps(input_value)\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_json(json_input)\n    else:\n        output = v.validate_json(json_input)\n        assert output == expected\n        assert isinstance(output, int)\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        (0, 0),\n        (1, 1),\n        (42, 42),\n        pytest.param(\n            42.0,\n            Err('Input should be a valid integer [type=int_type, input_value=42.0, input_type=float]'),\n            id='float-exact',\n        ),\n        pytest.param(\n            42.5,\n            Err('Input should be a valid integer [type=int_type, input_value=42.5, input_type=float]'),\n            id='float-remainder',\n        ),\n        pytest.param(\n            '42', Err(\"Input should be a valid integer [type=int_type, input_value='42', input_type=str]\"), id='string'\n        ),\n        pytest.param(\n            True, Err('Input should be a valid integer [type=int_type, input_value=True, input_type=bool]'), id='bool'\n        ),\n    ],\n)\ndef test_int_strict(py_and_json: PyAndJson, input_value, expected):\n    v = py_and_json({'type': 'int', 'strict': True})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_test(input_value)\n    else:\n        assert v.validate_test(input_value) == expected\n\n\n@pytest.mark.parametrize(\n    'kwargs,input_value,expected',\n    [\n        ({}, 0, 0),\n        ({}, '123.000', 123),\n        ({'ge': 0}, 0, 0),\n        (\n            {'ge': 0},\n            -1,\n            Err(\n                'Input should be greater than or equal to 0 '\n                '[type=greater_than_equal, input_value=-1, input_type=int]'\n            ),\n        ),\n        ({'gt': 0}, 1, 1),\n        ({'gt': 0}, 0, Err('Input should be greater than 0 [type=greater_than, input_value=0, input_type=int]')),\n        ({'le': 0}, 0, 0),\n        ({'le': 0}, -1, -1),\n        ({'le': 0}, 1, Err('Input should be less than or equal to 0')),\n        ({'lt': 0}, 0, Err('Input should be less than 0')),\n        ({'lt': 0}, 1, Err('Input should be less than 0')),\n        ({'multiple_of': 5}, 15, 15),\n        ({'multiple_of': 5}, 6, Err('Input should be a multiple of 5')),\n    ],\n    ids=repr,\n)\ndef test_int_kwargs(py_and_json: PyAndJson, kwargs: Dict[str, Any], input_value, expected):\n    v = py_and_json({'type': 'int', **kwargs})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)) as exc_info:\n            v.validate_test(input_value)\n\n        errors = exc_info.value.errors(include_url=False)\n        assert len(errors) == 1\n        if 'ctx' in errors[0]:\n            assert errors[0]['ctx'] == kwargs\n    else:\n        output = v.validate_test(input_value)\n        assert output == expected\n        assert isinstance(output, int)\n\n\ndef test_union_int(py_and_json: PyAndJson):\n    v = py_and_json({'type': 'union', 'choices': [{'type': 'int', 'strict': True}, {'type': 'int', 'multiple_of': 7}]})\n    assert v.validate_test('14') == 14\n    assert v.validate_test(5) == 5\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_test('5')\n\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'int_type', 'loc': ('int',), 'msg': 'Input should be a valid integer', 'input': '5'},\n        {\n            'type': 'multiple_of',\n            'loc': ('constrained-int',),\n            'msg': 'Input should be a multiple of 7',\n            'input': '5',\n            'ctx': {'multiple_of': 7},\n        },\n    ]\n\n\ndef test_union_int_simple(py_and_json: PyAndJson):\n    v = py_and_json({'type': 'union', 'choices': [{'type': 'int'}, {'type': 'list'}]})\n    assert v.validate_test('5') == 5\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_test('xxx')\n\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'int_parsing',\n            'loc': ('int',),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'xxx',\n        },\n        {\n            'type': 'list_type',\n            'loc': ('list[any]',),\n            'msg': IsStr(regex='Input should be a valid (list|array)'),\n            'input': 'xxx',\n        },\n    ]\n\n\ndef test_int_repr():\n    v = SchemaValidator({'type': 'int'})\n    assert (\n        plain_repr(v)\n        == 'SchemaValidator(title=\"int\",validator=Int(IntValidator{strict:false}),definitions=[],cache_strings=True)'\n    )\n    v = SchemaValidator({'type': 'int', 'strict': True})\n    assert (\n        plain_repr(v)\n        == 'SchemaValidator(title=\"int\",validator=Int(IntValidator{strict:true}),definitions=[],cache_strings=True)'\n    )\n    v = SchemaValidator({'type': 'int', 'multiple_of': 7})\n    assert plain_repr(v).startswith('SchemaValidator(title=\"constrained-int\",validator=ConstrainedInt(')\n\n\ndef test_too_long(pydantic_version):\n    v = SchemaValidator({'type': 'int'})\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python('1' * 4301)\n\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'int_parsing_size',\n            'loc': (),\n            'msg': 'Unable to parse input string as an integer, exceeded maximum size',\n            'input': '1' * 4301,\n        }\n    ]\n    # insert_assert(repr(exc_info.value))\n    assert repr(exc_info.value) == (\n        '1 validation error for int\\n'\n        '  Unable to parse input string as an integer, exceeded maximum size '\n        \"[type=int_parsing_size, input_value='111111111111111111111111...11111111111111111111111', input_type=str]\\n\"\n        f'    For further information visit https://errors.pydantic.dev/{pydantic_version}/v/int_parsing_size'\n    )\n\n\ndef test_long_python():\n    v = SchemaValidator({'type': 'int'})\n\n    s = v.validate_python('1' * 4_300)\n    assert s == int('1' * 4_300)\n\n    s = v.validate_python('-' + '1' * 400)\n    assert s == -int('1' * 400)\n\n    with pytest.raises(ValidationError, match='Input should be a valid integer'):\n        v.validate_python('nan')\n\n\ndef test_long_python_inequality():\n    v = SchemaValidator({'type': 'int', 'gt': 0, 'lt': int('1' * 4_300) - 5})\n\n    s = str(int('1' * 4_300) - 6)\n    s = v.validate_python(s)\n    assert s == int('1' * 4_300) - 6\n\n    s = str(int('1' * 4_300) - 5)\n    with pytest.raises(ValidationError, match='Input should be less than 1'):\n        v.validate_python(s)\n\n\ndef test_long_json():\n    v = SchemaValidator({'type': 'int'})\n\n    assert v.validate_json('-' + '1' * 400) == int('-' + '1' * 400)\n\n    with pytest.raises(ValidationError, match=r'expected ident at line 1 column 2 \\[type=json_invalid,'):\n        v.validate_json('nan')\n\n\ndef test_int_key(py_and_json: PyAndJson):\n    v = py_and_json({'type': 'dict', 'keys_schema': {'type': 'int'}, 'values_schema': {'type': 'int'}})\n    assert v.validate_test({'1': 1, '2': 2}) == {1: 1, 2: 2}\n    with pytest.raises(ValidationError, match='Input should be a valid integer'):\n        v.validate_python({'1': 1, '2': 2}, strict=True)\n    assert v.validate_json('{\"1\": 1, \"2\": 2}', strict=True) == {1: 1, 2: 2}\n\n\ndef test_string_as_int_with_underscores() -> None:\n    v = SchemaValidator({'type': 'int'})\n    assert v.validate_python('1_000_000') == 1_000_000\n    assert v.validate_json('\"1_000_000\"') == 1_000_000\n\n    for edge_case in ('_1', '1__0', '1_0_', '1_0__0'):\n        with pytest.raises(ValidationError):\n            v.validate_python(edge_case)\n        with pytest.raises(ValidationError):\n            v.validate_json(f'\"{edge_case}\"')\n\n\nclass IntSubclass(int):\n    pass\n\n\ndef test_int_subclass() -> None:\n    v = SchemaValidator({'type': 'int'})\n    v_lax = v.validate_python(IntSubclass(1))\n    assert v_lax == 1\n    assert type(v_lax) == int\n    v_strict = v.validate_python(IntSubclass(1), strict=True)\n    assert v_strict == 1\n    assert type(v_strict) == int\n\n    assert v.validate_python(IntSubclass(1136885225876639845)) == 1136885225876639845\n    assert v.validate_python(IntSubclass(i64_max + 7)) == i64_max + 7\n    assert v.validate_python(IntSubclass(1136885225876639845), strict=True) == 1136885225876639845\n    assert v.validate_python(IntSubclass(i64_max + 7), strict=True) == i64_max + 7\n\n\ndef test_int_subclass_constraint() -> None:\n    v = SchemaValidator({'type': 'int', 'gt': 0})\n    v_lax = v.validate_python(IntSubclass(1))\n    assert v_lax == 1\n    assert type(v_lax) == int\n    v_strict = v.validate_python(IntSubclass(1), strict=True)\n    assert v_strict == 1\n    assert type(v_strict) == int\n\n    with pytest.raises(ValidationError, match='Input should be greater than 0'):\n        v.validate_python(IntSubclass(0))\n\n\nclass FloatSubclass(float):\n    pass\n\n\ndef test_float_subclass() -> None:\n    v = SchemaValidator({'type': 'int'})\n    v_lax = v.validate_python(FloatSubclass(1))\n    assert v_lax == 1\n    assert type(v_lax) == int\n\n\ndef test_int_subclass_plain_enum() -> None:\n    v = SchemaValidator({'type': 'int'})\n\n    from enum import Enum\n\n    class PlainEnum(Enum):\n        ONE = 1\n\n    v_lax = v.validate_python(PlainEnum.ONE)\n    assert v_lax == 1\n    assert type(v_lax) == int\n\n\ndef test_allow_inf_nan_true_json() -> None:\n    v = SchemaValidator(core_schema.int_schema(), core_schema.CoreConfig(allow_inf_nan=True))\n\n    assert v.validate_json('123') == 123\n    with pytest.raises(ValidationError, match=r'Input should be a finite number \\[type=finite_number'):\n        v.validate_json('NaN')\n    with pytest.raises(ValidationError, match=r'Input should be a finite number \\[type=finite_number'):\n        v.validate_json('Infinity')\n    with pytest.raises(ValidationError, match=r'Input should be a finite number \\[type=finite_number'):\n        v.validate_json('-Infinity')\n\n\ndef test_allow_inf_nan_false_json() -> None:\n    v = SchemaValidator(core_schema.int_schema(), core_schema.CoreConfig(allow_inf_nan=False))\n\n    assert v.validate_json('123') == 123\n    with pytest.raises(ValidationError, match=r'Input should be a finite number \\[type=finite_number'):\n        v.validate_json('NaN')\n    with pytest.raises(ValidationError, match=r'Input should be a finite number \\[type=finite_number'):\n        v.validate_json('Infinity')\n    with pytest.raises(ValidationError, match=r'Input should be a finite number \\[type=finite_number'):\n        v.validate_json('-Infinity')\n\n\ndef test_json_big_int_key():\n    v = SchemaValidator({'type': 'dict', 'keys_schema': {'type': 'int'}, 'values_schema': {'type': 'str'}})\n    big_integer = 1433352099889938534014333520998899385340\n    assert v.validate_python({big_integer: 'x'}) == {big_integer: 'x'}\n    assert v.validate_json('{\"' + str(big_integer) + '\": \"x\"}') == {big_integer: 'x'}\n    assert v.validate_strings({str(big_integer): 'x'}) == {big_integer: 'x'}\n", "tests/validators/test_set.py": "import re\nfrom collections import deque\nfrom typing import Any, Dict\n\nimport pytest\n\nfrom pydantic_core import SchemaValidator, ValidationError\n\nfrom ..conftest import Err, PyAndJson, infinite_generator\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ([], set()),\n        ([1, 2, 3], {1, 2, 3}),\n        ([1, 2, '3'], {1, 2, 3}),\n        ([1, 2, 3, 2, 3], {1, 2, 3}),\n        (5, Err('[type=set_type, input_value=5, input_type=int]')),\n    ],\n)\ndef test_set_ints_both(py_and_json: PyAndJson, input_value, expected):\n    v = py_and_json({'type': 'set', 'items_schema': {'type': 'int'}})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_test(input_value)\n    else:\n        assert v.validate_test(input_value) == expected\n\n\n@pytest.mark.parametrize('input_value,expected', [([1, 2.5, '3'], {1, 2.5, '3'})])\ndef test_set_no_validators_both(py_and_json: PyAndJson, input_value, expected):\n    v = py_and_json({'type': 'set'})\n    assert v.validate_test(input_value) == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ([1, 2.5, '3'], {1, 2.5, '3'}),\n        ('foo', Err('[type=set_type, input_value=foo, input_type=str]')),\n        (1, Err('[type=set_type, input_value=1.0, input_type=float]')),\n        (1.0, Err('[type=set_type, input_value=1.0, input_type=float]')),\n        (False, Err('[type=set_type, input_value=False, input_type=bool]')),\n    ],\n)\ndef test_frozenset_no_validators_both(py_and_json: PyAndJson, input_value, expected):\n    v = py_and_json({'type': 'set'})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=expected.message):\n            v.validate_test(input_value)\n    else:\n        assert v.validate_test(input_value) == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ({1, 2, 3}, {1, 2, 3}),\n        (set(), set()),\n        ([1, 2, 3, 2, 3], {1, 2, 3}),\n        ([], set()),\n        ((1, 2, 3, 2, 3), {1, 2, 3}),\n        ((), set()),\n        (frozenset([1, 2, 3, 2, 3]), {1, 2, 3}),\n        (deque((1, 2, '3')), {1, 2, 3}),\n        ({1: 10, 2: 20, '3': '30'}.keys(), {1, 2, 3}),\n        ({1: 10, 2: 20, '3': '30'}.values(), {10, 20, 30}),\n        ({1: 10, 2: 20, '3': '30'}, Err('Input should be a valid set [type=set_type,')),\n        ((x for x in [1, 2, '3']), {1, 2, 3}),\n        ({'abc'}, Err('0\\n  Input should be a valid integer')),\n        ({1: 2}, Err('1 validation error for set[int]\\n  Input should be a valid set')),\n        ('abc', Err('Input should be a valid set')),\n    ],\n)\ndef test_set_ints_python(input_value, expected):\n    v = SchemaValidator({'type': 'set', 'items_schema': {'type': 'int'}})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_python(input_value)\n    else:\n        assert v.validate_python(input_value) == expected\n\n\n@pytest.mark.parametrize('input_value,expected', [([1, 2.5, '3'], {1, 2.5, '3'}), ([(1, 2), (3, 4)], {(1, 2), (3, 4)})])\ndef test_set_no_validators_python(input_value, expected):\n    v = SchemaValidator({'type': 'set'})\n    assert v.validate_python(input_value) == expected\n\n\ndef test_set_multiple_errors():\n    v = SchemaValidator({'type': 'set', 'items_schema': {'type': 'int'}})\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python(['a', (1, 2), []])\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'int_parsing',\n            'loc': (0,),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'a',\n        },\n        {'type': 'int_type', 'loc': (1,), 'msg': 'Input should be a valid integer', 'input': (1, 2)},\n        {'type': 'int_type', 'loc': (2,), 'msg': 'Input should be a valid integer', 'input': []},\n    ]\n\n\ndef generate_repeats():\n    for i in 1, 2, 3:\n        yield i\n        yield i\n\n\n@pytest.mark.parametrize(\n    'kwargs,input_value,expected',\n    [\n        ({'strict': True}, {1, 2, 3}, {1, 2, 3}),\n        ({'strict': True}, set(), set()),\n        ({'strict': True}, [1, 2, 3, 2, 3], Err('Input should be a valid set [type=set_type,')),\n        ({'strict': True}, [], Err('Input should be a valid set [type=set_type,')),\n        ({'strict': True}, (), Err('Input should be a valid set [type=set_type,')),\n        ({'strict': True}, (1, 2, 3), Err('Input should be a valid set [type=set_type,')),\n        ({'strict': True}, frozenset([1, 2, 3]), Err('Input should be a valid set [type=set_type,')),\n        ({'strict': True}, 'abc', Err('Input should be a valid set [type=set_type,')),\n        ({'min_length': 3}, {1, 2, 3}, {1, 2, 3}),\n        ({'min_length': 3}, {1, 2}, Err('Set should have at least 3 items after validation, not 2 [type=too_short,')),\n        (\n            {'max_length': 3},\n            {1, 2, 3, 4},\n            Err('Set should have at most 3 items after validation, not more [type=too_long,'),\n        ),\n        (\n            {'max_length': 3},\n            [1, 2, 3, 4],\n            Err('Set should have at most 3 items after validation, not more [type=too_long,'),\n        ),\n        ({'max_length': 3, 'items_schema': {'type': 'int'}}, {1, 2, 3, 4}, Err('type=too_long,')),\n        ({'max_length': 3, 'items_schema': {'type': 'int'}}, [1, 2, 3, 4], Err('type=too_long,')),\n        # length check after set creation\n        ({'max_length': 3}, [1, 1, 2, 2, 3, 3], {1, 2, 3}),\n        ({'max_length': 3}, generate_repeats(), {1, 2, 3}),\n        (\n            {'max_length': 3},\n            infinite_generator(),\n            Err('Set should have at most 3 items after validation, not more [type=too_long,'),\n        ),\n    ],\n    ids=repr,\n)\ndef test_set_kwargs(kwargs: Dict[str, Any], input_value, expected):\n    v = SchemaValidator({'type': 'set', **kwargs})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            r = v.validate_python(input_value)\n            print(f'unexpected result: {r!r}')\n    else:\n        assert v.validate_python(input_value) == expected\n\n\n@pytest.mark.parametrize('input_value,expected', [({1, 2, 3}, {1, 2, 3}), ([1, 2, 3], [1, 2, 3])])\ndef test_union_set_list(input_value, expected):\n    v = SchemaValidator({'type': 'union', 'choices': [{'type': 'set'}, {'type': 'list'}]})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_python(input_value)\n    else:\n        assert v.validate_python(input_value) == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ({1, 2, 3}, {1, 2, 3}),\n        ({'a', 'b', 'c'}, {'a', 'b', 'c'}),\n        (\n            [1, 'a'],\n            Err(\n                '2 validation errors for union',\n                errors=[\n                    {\n                        'type': 'int_type',\n                        'loc': ('set[int]', 1),\n                        'msg': 'Input should be a valid integer',\n                        'input': 'a',\n                    },\n                    # second because validation on the string choice comes second\n                    {\n                        'type': 'string_type',\n                        'loc': ('set[str]', 0),\n                        'msg': 'Input should be a valid string',\n                        'input': 1,\n                    },\n                ],\n            ),\n        ),\n    ],\n)\ndef test_union_set_int_set_str(input_value, expected):\n    v = SchemaValidator(\n        {\n            'type': 'union',\n            'choices': [\n                {'type': 'set', 'items_schema': {'type': 'int', 'strict': True}},\n                {'type': 'set', 'items_schema': {'type': 'str', 'strict': True}},\n            ],\n        }\n    )\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)) as exc_info:\n            v.validate_python(input_value)\n        if expected.errors is not None:\n            assert exc_info.value.errors(include_url=False) == expected.errors\n    else:\n        assert v.validate_python(input_value) == expected\n\n\ndef test_set_as_dict_keys(py_and_json: PyAndJson):\n    v = py_and_json({'type': 'dict', 'keys_schema': {'type': 'set'}, 'values_schema': {'type': 'int'}})\n    with pytest.raises(ValidationError, match=re.escape(\"[type=set_type, input_value='foo', input_type=str]\")):\n        v.validate_test({'foo': 'bar'})\n\n\ndef test_generator_error():\n    def gen(error: bool):\n        yield 1\n        yield 2\n        if error:\n            raise RuntimeError('my error')\n        yield 3\n\n    v = SchemaValidator({'type': 'set', 'items_schema': {'type': 'int'}})\n    r = v.validate_python(gen(False))\n    assert r == {1, 2, 3}\n    assert isinstance(r, set)\n\n    msg = r'Error iterating over object, error: RuntimeError: my error \\[type=iteration_error,'\n    with pytest.raises(ValidationError, match=msg):\n        v.validate_python(gen(True))\n\n\n@pytest.mark.parametrize(\n    'input_value,items_schema,expected',\n    [\n        pytest.param(\n            {1: 10, 2: 20, '3': '30'}.items(),\n            {'type': 'tuple', 'items_schema': [{'type': 'any'}], 'variadic_item_index': 0},\n            {(1, 10), (2, 20), ('3', '30')},\n            id='Tuple[Any, Any]',\n        ),\n        pytest.param(\n            {1: 10, 2: 20, '3': '30'}.items(),\n            {'type': 'tuple', 'items_schema': [{'type': 'int'}], 'variadic_item_index': 0},\n            {(1, 10), (2, 20), (3, 30)},\n            id='Tuple[int, int]',\n        ),\n        pytest.param({1: 10, 2: 20, '3': '30'}.items(), {'type': 'any'}, {(1, 10), (2, 20), ('3', '30')}, id='Any'),\n    ],\n)\ndef test_set_from_dict_items(input_value, items_schema, expected):\n    v = SchemaValidator({'type': 'set', 'items_schema': items_schema})\n    output = v.validate_python(input_value)\n    assert isinstance(output, set)\n    assert output == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ([], set()),\n        ([1, '2', b'3'], {1, '2', b'3'}),\n        ({1, '2', b'3'}, {1, '2', b'3'}),\n        (frozenset([1, '2', b'3']), {1, '2', b'3'}),\n        (deque([1, '2', b'3']), {1, '2', b'3'}),\n    ],\n)\ndef test_set_any(input_value, expected):\n    v = SchemaValidator({'type': 'set'})\n    output = v.validate_python(input_value)\n    assert output == expected\n    assert isinstance(output, set)\n\n\n@pytest.mark.parametrize(\n    'fail_fast,expected',\n    [\n        pytest.param(\n            True,\n            [\n                {\n                    'type': 'int_parsing',\n                    'loc': (1,),\n                    'msg': 'Input should be a valid integer, unable to parse string as an integer',\n                    'input': 'not-num',\n                },\n            ],\n            id='fail_fast',\n        ),\n        pytest.param(\n            False,\n            [\n                {\n                    'type': 'int_parsing',\n                    'loc': (1,),\n                    'msg': 'Input should be a valid integer, unable to parse string as an integer',\n                    'input': 'not-num',\n                },\n                {\n                    'type': 'int_parsing',\n                    'loc': (2,),\n                    'msg': 'Input should be a valid integer, unable to parse string as an integer',\n                    'input': 'again',\n                },\n            ],\n            id='not_fail_fast',\n        ),\n    ],\n)\ndef test_set_fail_fast(fail_fast, expected):\n    v = SchemaValidator({'type': 'set', 'items_schema': {'type': 'int'}, 'fail_fast': fail_fast})\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python([1, 'not-num', 'again'])\n\n    assert exc_info.value.errors(include_url=False) == expected\n", "tests/validators/test_float.py": "import math\nimport re\nfrom decimal import Decimal\nfrom typing import Any, Dict\n\nimport pytest\nfrom dirty_equals import FunctionCheck, IsFloatNan, IsStr\n\nfrom pydantic_core import SchemaValidator, ValidationError, core_schema\n\nfrom ..conftest import Err, PyAndJson, plain_repr\n\nf64_max = 1.7976931348623157e308\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        (0, 0),\n        (1, 1),\n        (42, 42),\n        ('42', 42),\n        ('  42.1  ', 42.1),\n        ('42.123', 42.123),\n        (42.0, 42),\n        (42.5, 42.5),\n        (1e10, 1e10),\n        (True, 1),\n        (False, 0),\n        ('wrong', Err('Input should be a valid number, unable to parse string as a number [type=float_parsing')),\n        ([1, 2], Err('Input should be a valid number [type=float_type, input_value=[1, 2], input_type=list]')),\n    ],\n)\ndef test_float(py_and_json: PyAndJson, input_value, expected):\n    v = py_and_json({'type': 'float'})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_test(input_value)\n    else:\n        output = v.validate_test(input_value)\n        assert output == expected\n        assert isinstance(output, float)\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        (0, 0),\n        (1, 1),\n        (42, 42),\n        (42.0, 42.0),\n        (42.5, 42.5),\n        ('42', Err(\"Input should be a valid number [type=float_type, input_value='42', input_type=str]\")),\n        (True, Err('Input should be a valid number [type=float_type, input_value=True, input_type=bool]')),\n    ],\n    ids=repr,\n)\ndef test_float_strict(py_and_json: PyAndJson, input_value, expected):\n    v = py_and_json({'type': 'float', 'strict': True})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_test(input_value)\n    else:\n        output = v.validate_test(input_value)\n        assert output == expected\n        assert isinstance(output, float)\n\n\n@pytest.mark.parametrize(\n    'kwargs,input_value,expected',\n    [\n        ({}, 0, 0),\n        ({}, '123.456', 123.456),\n        ({'ge': 0}, 0, 0),\n        (\n            {'ge': 0},\n            -0.1,\n            Err(\n                'Input should be greater than or equal to 0 '\n                '[type=greater_than_equal, input_value=-0.1, input_type=float]'\n            ),\n        ),\n        ({'gt': 0}, 0.1, 0.1),\n        ({'gt': 0}, 0, Err('Input should be greater than 0 [type=greater_than, input_value=0, input_type=int]')),\n        ({'le': 0}, 0, 0),\n        ({'le': 0}, -1, -1),\n        ({'le': 0}, 0.1, Err('Input should be less than or equal to 0')),\n        ({'lt': 0}, 0, Err('Input should be less than 0')),\n        ({'lt': 0.123456}, 1, Err('Input should be less than 0.123456')),\n        ({'lt': 0, 'allow_inf_nan': True}, float('nan'), Err('Input should be less than 0')),\n        ({'gt': 0, 'allow_inf_nan': True}, float('inf'), float('inf')),\n    ],\n)\ndef test_float_kwargs(py_and_json: PyAndJson, kwargs: Dict[str, Any], input_value, expected):\n    v = py_and_json({'type': 'float', **kwargs})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_test(input_value)\n    else:\n        output = v.validate_test(input_value)\n        assert output == expected\n        assert isinstance(output, float)\n\n\n@pytest.mark.parametrize(\n    'multiple_of,input_value,error',\n    [\n        (0.5, 0.5, None),\n        (0.5, 1, None),\n        (0.5, 0.6, Err('Input should be a multiple of 0.5')),\n        (0.5, 0.51, Err('Input should be a multiple of 0.5')),\n        (0.5, 0.501, Err('Input should be a multiple of 0.5')),\n        (0.5, 1_000_000.5, None),\n        (0.5, 1_000_000.49, Err('Input should be a multiple of 0.5')),\n        (0.1, 0, None),\n        (0.1, 0.0, None),\n        (0.1, 0.2, None),\n        (0.1, 0.3, None),\n        (0.1, 0.4, None),\n        (0.1, 0.5, None),\n        (0.1, 0.5001, Err('Input should be a multiple of 0.1')),\n        (0.1, 1, None),\n        (0.1, 1.0, None),\n        (0.1, int(5e10), None),\n        (2.0, -2.0, None),\n    ],\n    ids=repr,\n)\ndef test_float_multiple_of(py_and_json: PyAndJson, multiple_of, input_value, error):\n    v = py_and_json({'type': 'float', 'multiple_of': multiple_of})\n    if error:\n        with pytest.raises(ValidationError, match=re.escape(error.message)):\n            v.validate_test(input_value)\n    else:\n        output = v.validate_test(input_value)\n        assert output == input_value\n        assert isinstance(output, float)\n\n\ndef test_union_float(py_and_json: PyAndJson):\n    v = py_and_json(\n        {'type': 'union', 'choices': [{'type': 'float', 'strict': True}, {'type': 'float', 'multiple_of': 7}]}\n    )\n    assert v.validate_test('14') == 14\n    assert v.validate_test(5) == 5\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_test('5')\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'float_type', 'loc': ('float',), 'msg': 'Input should be a valid number', 'input': '5'},\n        {\n            'type': 'multiple_of',\n            'loc': ('constrained-float',),\n            'msg': 'Input should be a multiple of 7',\n            'input': '5',\n            'ctx': {'multiple_of': 7.0},\n        },\n    ]\n\n\ndef test_union_float_simple(py_and_json: PyAndJson):\n    v = py_and_json({'type': 'union', 'choices': [{'type': 'float'}, {'type': 'list'}]})\n    assert v.validate_test('5') == 5\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_test('xxx')\n\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'float_parsing',\n            'loc': ('float',),\n            'msg': 'Input should be a valid number, unable to parse string as a number',\n            'input': 'xxx',\n        },\n        {\n            'type': 'list_type',\n            'loc': ('list[any]',),\n            'msg': IsStr(regex='Input should be a valid (list|array)'),\n            'input': 'xxx',\n        },\n    ]\n\n\ndef test_float_repr():\n    v = SchemaValidator({'type': 'float'})\n    assert (\n        plain_repr(v)\n        == 'SchemaValidator(title=\"float\",validator=Float(FloatValidator{strict:false,allow_inf_nan:true}),definitions=[],cache_strings=True)'\n    )\n    v = SchemaValidator({'type': 'float', 'strict': True})\n    assert (\n        plain_repr(v)\n        == 'SchemaValidator(title=\"float\",validator=Float(FloatValidator{strict:true,allow_inf_nan:true}),definitions=[],cache_strings=True)'\n    )\n    v = SchemaValidator({'type': 'float', 'multiple_of': 7})\n    assert plain_repr(v).startswith('SchemaValidator(title=\"constrained-float\",validator=ConstrainedFloat(')\n\n\n@pytest.mark.parametrize('input_value,expected', [(Decimal('1.23'), 1.23), (Decimal('1'), 1.0)])\ndef test_float_not_json(input_value, expected):\n    v = SchemaValidator({'type': 'float'})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_python(input_value)\n    else:\n        output = v.validate_python(input_value)\n        assert output == expected\n        assert isinstance(output, float)\n\n\ndef test_float_nan(py_and_json: PyAndJson):\n    v = py_and_json({'type': 'float'})\n    assert v.validate_test('1' * 800) == float('inf')\n    assert v.validate_test('-' + '1' * 800) == float('-inf')\n    r = v.validate_test('nan')\n    assert math.isnan(r)\n\n\ndef test_float_key(py_and_json: PyAndJson):\n    v = py_and_json({'type': 'dict', 'keys_schema': {'type': 'float'}, 'values_schema': {'type': 'int'}})\n    assert v.validate_test({'1': 1, '2': 2}) == {1: 1, 2: 2}\n    assert v.validate_test({'1.5': 1, '2.4': 2}) == {1.5: 1, 2.4: 2}\n    with pytest.raises(ValidationError, match='Input should be a valid number'):\n        v.validate_python({'1.5': 1, '2.5': 2}, strict=True)\n    assert v.validate_json('{\"1.5\": 1, \"2.5\": 2}', strict=True) == {1.5: 1, 2.5: 2}\n\n\n@pytest.mark.parametrize(\n    'input_value,allow_inf_nan,expected',\n    [\n        ('NaN', True, FunctionCheck(math.isnan)),\n        ('NaN', False, Err(\"Input should be a finite number [type=finite_number, input_value='NaN', input_type=str]\")),\n        ('+inf', True, FunctionCheck(lambda x: math.isinf(x) and x > 0)),\n        ('inf', True, FunctionCheck(lambda x: math.isinf(x) and x > 0)),\n        (\n            '+inf',\n            False,\n            Err(\"Input should be a finite number [type=finite_number, input_value='+inf', input_type=str]\"),\n        ),\n        ('+infinity', True, FunctionCheck(lambda x: math.isinf(x) and x > 0)),\n        (\n            '+infinity',\n            False,\n            Err(\"Input should be a finite number [type=finite_number, input_value='+infinity', input_type=str]\"),\n        ),\n        ('-inf', True, FunctionCheck(lambda x: math.isinf(x) and x < 0)),\n        (\n            '-inf',\n            False,\n            Err(\"Input should be a finite number [type=finite_number, input_value='-inf', input_type=str]\"),\n        ),\n        ('-infinity', True, FunctionCheck(lambda x: math.isinf(x) and x < 0)),\n        (\n            '-infinity',\n            False,\n            Err(\"Input should be a finite number [type=finite_number, input_value='-infinity', input_type=str]\"),\n        ),\n        ('0.7', True, 0.7),\n        ('0.7', False, 0.7),\n        (\n            'pika',\n            True,\n            Err(\n                'Input should be a valid number, unable to parse string as a number '\n                \"[type=float_parsing, input_value='pika', input_type=str]\"\n            ),\n        ),\n        (\n            'pika',\n            False,\n            Err(\n                'Input should be a valid number, unable to parse string as a number '\n                \"[type=float_parsing, input_value='pika', input_type=str]\"\n            ),\n        ),\n    ],\n)\ndef test_non_finite_json_values(py_and_json: PyAndJson, input_value, allow_inf_nan, expected):\n    v = py_and_json({'type': 'float', 'allow_inf_nan': allow_inf_nan})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_test(input_value)\n    else:\n        assert v.validate_test(input_value) == expected\n\n\n@pytest.mark.parametrize('strict', (True, False))\n@pytest.mark.parametrize(\n    'input_value,allow_inf_nan,expected',\n    [\n        (float('nan'), True, FunctionCheck(math.isnan)),\n        (\n            float('nan'),\n            False,\n            Err('Input should be a finite number [type=finite_number, input_value=nan, input_type=float]'),\n        ),\n    ],\n)\ndef test_non_finite_float_values(strict, input_value, allow_inf_nan, expected):\n    v = SchemaValidator({'type': 'float', 'allow_inf_nan': allow_inf_nan, 'strict': strict})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_python(input_value)\n    else:\n        assert v.validate_python(input_value) == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,allow_inf_nan,expected',\n    [\n        (float('+inf'), True, FunctionCheck(lambda x: math.isinf(x) and x > 0)),\n        (\n            float('+inf'),\n            False,\n            Err('Input should be a finite number [type=finite_number, input_value=inf, input_type=float]'),\n        ),\n        (\n            float('-inf'),\n            True,\n            Err('Input should be greater than 0 [type=greater_than, input_value=-inf, input_type=float]'),\n        ),\n        (\n            float('-inf'),\n            False,\n            Err('Input should be a finite number [type=finite_number, input_value=-inf, input_type=float]'),\n        ),\n    ],\n)\ndef test_non_finite_constrained_float_values(input_value, allow_inf_nan, expected):\n    v = SchemaValidator({'type': 'float', 'allow_inf_nan': allow_inf_nan, 'gt': 0})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_python(input_value)\n    else:\n        assert v.validate_python(input_value) == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        # lower e, minus\n        ('1.0e-12', 1e-12),\n        ('1e-12', 1e-12),\n        ('12e-1', 12e-1),\n        # upper E, minus\n        ('1.0E-12', 1e-12),\n        ('1E-12', 1e-12),\n        ('12E-1', 12e-1),\n        # lower E, plus\n        ('1.0e+12', 1e12),\n        ('1e+12', 1e12),\n        ('12e+1', 12e1),\n        # upper E, plus\n        ('1.0E+12', 1e12),\n        ('1E+12', 1e12),\n        ('12E+1', 12e1),\n        # lower E, unsigned\n        ('1.0e12', 1e12),\n        ('1e12', 1e12),\n        ('12e1', 12e1),\n        # upper E, unsigned\n        ('1.0E12', 1e12),\n        ('1E12', 1e12),\n        ('12E1', 12e1),\n    ],\n)\ndef test_validate_scientific_notation_from_json(input_value, expected):\n    v = SchemaValidator({'type': 'float'})\n    assert v.validate_json(input_value) == expected\n\n\ndef test_string_with_underscores() -> None:\n    v = SchemaValidator({'type': 'float'})\n    assert v.validate_python('1_000_000.0') == 1_000_000.0\n    assert v.validate_json('\"1_000_000.0\"') == 1_000_000.0\n\n    for edge_case in ('_1', '_1.0', '1__0', '1.1__1', '1_0.0_', '1._', '1_0__0.0'):\n        with pytest.raises(ValidationError):\n            v.validate_python(edge_case)\n        with pytest.raises(ValidationError):\n            v.validate_json(f'\"{edge_case}\"')\n\n\ndef test_allow_inf_nan_true_json() -> None:\n    v = SchemaValidator(core_schema.float_schema())\n\n    assert v.validate_json('123') == 123\n    assert v.validate_json('NaN') == IsFloatNan()\n    assert v.validate_json('Infinity') == float('inf')\n    assert v.validate_json('-Infinity') == float('-inf')\n\n    assert v.validate_json('\"NaN\"') == IsFloatNan()\n    assert v.validate_json('\"Infinity\"') == float('inf')\n    assert v.validate_json('\"-Infinity\"') == float('-inf')\n\n\ndef test_allow_inf_nan_false_json() -> None:\n    v = SchemaValidator(core_schema.float_schema(), core_schema.CoreConfig(allow_inf_nan=False))\n\n    assert v.validate_json('123') == 123\n    with pytest.raises(ValidationError) as exc_info1:\n        v.validate_json('NaN')\n    # insert_assert(exc_info.value.errors())\n    assert exc_info1.value.errors(include_url=False) == [\n        {'type': 'finite_number', 'loc': (), 'msg': 'Input should be a finite number', 'input': IsFloatNan()}\n    ]\n    with pytest.raises(ValidationError) as exc_info2:\n        v.validate_json('Infinity')\n    assert exc_info2.value.errors(include_url=False) == [\n        {'type': 'finite_number', 'loc': (), 'msg': 'Input should be a finite number', 'input': float('inf')}\n    ]\n    with pytest.raises(ValidationError) as exc_info3:\n        v.validate_json('-Infinity')\n    assert exc_info3.value.errors(include_url=False) == [\n        {'type': 'finite_number', 'loc': (), 'msg': 'Input should be a finite number', 'input': float('-inf')}\n    ]\n", "tests/validators/test_custom_error.py": "import pytest\n\nfrom pydantic_core import SchemaError, SchemaValidator, ValidationError, core_schema, validate_core_schema\n\nfrom ..conftest import PyAndJson\n\n\ndef test_custom_error(py_and_json: PyAndJson):\n    v = py_and_json(\n        core_schema.custom_error_schema(core_schema.int_schema(), 'foobar', custom_error_message='Hello there')\n    )\n    assert v.validate_test(1) == 1\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_test('foobar')\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'foobar', 'loc': (), 'msg': 'Hello there', 'input': 'foobar'}\n    ]\n\n\ndef test_custom_error_type(py_and_json: PyAndJson):\n    v = py_and_json(core_schema.custom_error_schema(core_schema.int_schema(), 'recursion_loop'))\n    assert v.validate_test(1) == 1\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_test('X')\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'recursion_loop', 'loc': (), 'msg': 'Recursion error - cyclic reference detected', 'input': 'X'}\n    ]\n\n\ndef test_custom_error_error():\n    with pytest.raises(SchemaError, match=r'custom_error_type\\s+Field required \\[type=missing'):\n        validate_core_schema({'type': 'custom-error', 'schema': {'type': 'int'}})\n\n\ndef test_custom_error_invalid():\n    msg = \"custom_error_message should not be provided if 'custom_error_type' matches a known error\"\n    with pytest.raises(SchemaError, match=msg):\n        SchemaValidator(\n            core_schema.custom_error_schema(core_schema.int_schema(), 'recursion_loop', custom_error_message='xxx')\n        )\n", "tests/validators/test_enums.py": "import re\nimport sys\nfrom enum import Enum, IntEnum, IntFlag\n\nimport pytest\n\nfrom pydantic_core import SchemaError, SchemaValidator, ValidationError, core_schema\n\n\ndef test_plain_enum():\n    class MyEnum(Enum):\n        a = 1\n        b = 2\n\n    v = SchemaValidator(core_schema.enum_schema(MyEnum, list(MyEnum.__members__.values())))\n\n    # debug(v)\n    assert v.validate_python(MyEnum.a) is MyEnum.a\n    assert v.validate_python(MyEnum.b) is MyEnum.b\n    assert v.validate_python(1) is MyEnum.a\n    assert v.validate_python(2) is MyEnum.b\n\n    assert v.validate_json('1') is MyEnum.a\n    # assert v.validate_json('\"1\"') is MyEnum.a\n\n    with pytest.raises(ValidationError, match=r'Input should be 1 or 2 \\[type=enum, input_value=3, input_type=int\\]'):\n        v.validate_python(3)\n\n    with pytest.raises(ValidationError, match=r\"Input should be 1 or 2 \\[type=enum, input_value='1', input_type=str\\]\"):\n        v.validate_python('1')\n\n    assert v.validate_python(MyEnum.a, strict=True) is MyEnum.a\n\n    e = (\n        'Input should be an instance of test_plain_enum.<locals>.MyEnum '\n        '[type=is_instance_of, input_value=1, input_type=int]'\n    )\n    with pytest.raises(ValidationError, match=re.escape(e)):\n        v.validate_python(1, strict=True)\n\n    assert v.validate_json('1', strict=True) is MyEnum.a\n    with pytest.raises(ValidationError, match='type=enum'):\n        v.validate_json('\"1\"', strict=True)\n\n    v_strict = SchemaValidator(core_schema.enum_schema(MyEnum, list(MyEnum.__members__.values()), strict=True))\n    assert v_strict.validate_python(MyEnum.a) is MyEnum.a\n\n    with pytest.raises(ValidationError, match=re.escape(e)):\n        v_strict.validate_python(1, strict=True)\n\n    v_strict_f = SchemaValidator(core_schema.enum_schema(MyEnum, list(MyEnum.__members__.values()), strict=True))\n    assert v_strict_f.validate_python(MyEnum.a) is MyEnum.a\n\n    with pytest.raises(ValidationError, match=re.escape(e)):\n        v_strict_f.validate_python(1, strict=True)\n\n\ndef test_int_enum():\n    class MyEnum(int, Enum):\n        a = 1\n        b = 2\n\n    v = SchemaValidator(core_schema.enum_schema(MyEnum, list(MyEnum.__members__.values()), sub_type='int'))\n\n    # debug(v)\n    assert v.validate_python(MyEnum.a) is MyEnum.a\n    assert v.validate_python(1) is MyEnum.a\n    assert v.validate_python(1.0) is MyEnum.a\n    assert v.validate_python('1') is MyEnum.a\n\n    assert v.validate_json('1') is MyEnum.a\n    assert v.validate_json('\"1\"') is MyEnum.a\n\n    with pytest.raises(ValidationError, match=r'Input should be 1 or 2 \\[type=enum, input_value=3, input_type=int\\]'):\n        v.validate_python(3)\n\n    assert v.validate_python(MyEnum.a, strict=True) is MyEnum.a\n\n    e = (\n        'Input should be an instance of test_int_enum.<locals>.MyEnum '\n        '[type=is_instance_of, input_value=1, input_type=int]'\n    )\n    with pytest.raises(ValidationError, match=re.escape(e)):\n        v.validate_python(1, strict=True)\n\n    assert v.validate_json('1', strict=True) is MyEnum.a\n\n    with pytest.raises(ValidationError, match=r\"Input should be 1 or 2 \\[type=enum, input_value='1', input_type=str\\]\"):\n        v.validate_json('\"1\"', strict=True)\n\n\ndef test_str_enum():\n    class MyEnum(str, Enum):\n        a = 'x'\n        b = 'y'\n\n    v = SchemaValidator(core_schema.enum_schema(MyEnum, list(MyEnum.__members__.values()), sub_type='str'))\n\n    # debug(v)\n    assert v.validate_python('x') is MyEnum.a\n    assert v.validate_python(MyEnum.a) is MyEnum.a\n    assert v.validate_python(b'x') is MyEnum.a\n\n    assert v.validate_json('\"x\"') is MyEnum.a\n\n    with pytest.raises(\n        ValidationError, match=r\"Input should be 'x' or 'y' \\[type=enum, input_value='a', input_type=str\\]\"\n    ):\n        v.validate_python('a')\n\n    assert v.validate_python(MyEnum.a, strict=True) is MyEnum.a\n\n    e = (\n        'Input should be an instance of test_str_enum.<locals>.MyEnum '\n        \"[type=is_instance_of, input_value='x', input_type=str]\"\n    )\n    with pytest.raises(ValidationError, match=re.escape(e)):\n        v.validate_python('x', strict=True)\n    assert v.validate_json('\"x\"', strict=True) is MyEnum.a\n\n\ndef test_float_enum():\n    class MyEnum(float, Enum):\n        a = 1.5\n        b = 2.5\n        c = 3.0\n\n    v = SchemaValidator(core_schema.enum_schema(MyEnum, list(MyEnum.__members__.values()), sub_type='float'))\n\n    # debug(v)\n    assert v.validate_python(MyEnum.a) is MyEnum.a\n    assert v.validate_python(1.5) is MyEnum.a\n    assert v.validate_python('1.5') is MyEnum.a\n    assert v.validate_python(3) is MyEnum.c\n\n    assert v.validate_json('1.5') is MyEnum.a\n    assert v.validate_json('\"1.5\"') is MyEnum.a\n\n    e = r'Input should be 1.5, 2.5 or 3.0 \\[type=enum, input_value=4.0, input_type=float\\]'\n    with pytest.raises(ValidationError, match=e):\n        v.validate_python(4.0)\n\n    assert v.validate_python(MyEnum.a, strict=True) is MyEnum.a\n\n    e = (\n        'Input should be an instance of test_float_enum.<locals>.MyEnum '\n        '[type=is_instance_of, input_value=1.5, input_type=float]'\n    )\n    with pytest.raises(ValidationError, match=re.escape(e)):\n        v.validate_python(1.5, strict=True)\n\n    assert v.validate_json('1.5', strict=True) is MyEnum.a\n\n    with pytest.raises(ValidationError, match='type=enum'):\n        v.validate_json('\"3.0\"', strict=True)\n\n\ndef test_enum_missing():\n    class MyEnum(Enum):\n        a = 1\n        b = 2\n\n        @classmethod\n        def _missing_(cls, v):\n            return cls.b\n\n    assert MyEnum(1) is MyEnum.a\n    assert MyEnum(2) is MyEnum.b\n    assert MyEnum(3) is MyEnum.b\n\n    v = SchemaValidator(core_schema.enum_schema(MyEnum, list(MyEnum.__members__.values()), missing=MyEnum._missing_))\n\n    # debug(v)\n    assert v.validate_python(MyEnum.a) is MyEnum.a\n    assert v.validate_python(1) is MyEnum.a\n    assert v.validate_python(2) is MyEnum.b\n    assert v.validate_python(3) is MyEnum.b\n\n    assert v.validate_json('1') is MyEnum.a\n    assert v.validate_json('3') is MyEnum.b\n\n\ndef test_enum_missing_none():\n    class MyEnum(Enum):\n        a = 1\n        b = 2\n\n        @classmethod\n        def _missing_(cls, v):\n            return None\n\n    assert MyEnum(1) is MyEnum.a\n    assert MyEnum(2) is MyEnum.b\n    with pytest.raises(ValueError, match='3 is not a valid'):\n        MyEnum(3)\n\n    v = SchemaValidator(core_schema.enum_schema(MyEnum, list(MyEnum.__members__.values()), missing=MyEnum._missing_))\n\n    # debug(v)\n    assert v.validate_python(MyEnum.a) is MyEnum.a\n    assert v.validate_python(1) is MyEnum.a\n    with pytest.raises(ValidationError, match=r'Input should be 1 or 2 \\[type=enum, input_value=3, input_type=int\\]'):\n        v.validate_python(3)\n\n    assert v.validate_json('1') is MyEnum.a\n    with pytest.raises(ValidationError, match=r'Input should be 1 or 2 \\[type=enum, input_value=3, input_type=int\\]'):\n        v.validate_json('3')\n\n\ndef test_enum_missing_wrong():\n    class MyEnum(Enum):\n        a = 1\n        b = 2\n\n        @classmethod\n        def _missing_(cls, v):\n            return 'foobar'\n\n    assert MyEnum(1) is MyEnum.a\n    assert MyEnum(2) is MyEnum.b\n    # different error from pypy\n    if sys.implementation.name == 'pypy':\n        e = \"returned 'foobar' instead of None or a valid member\"\n    else:\n        e = \"error in MyEnum._missing_: returned 'foobar' instead of None or a valid member\"\n    with pytest.raises(TypeError, match=e):\n        MyEnum(3)\n\n    v = SchemaValidator(core_schema.enum_schema(MyEnum, list(MyEnum.__members__.values()), missing=MyEnum._missing_))\n    with pytest.raises(TypeError, match=e):\n        v.validate_python(3)\n\n\ndef test_enum_exactness():\n    class MyEnum(int, Enum):\n        a = 1\n        b = 2\n\n    v = SchemaValidator(\n        core_schema.union_schema(\n            [\n                core_schema.enum_schema(MyEnum, list(MyEnum.__members__.values()), missing=MyEnum._missing_),\n                core_schema.int_schema(),\n            ],\n        )\n    )\n    assert v.validate_python(MyEnum.a) is MyEnum.a\n    assert v.validate_python(1) == 1\n    assert v.validate_python(1) is not MyEnum.a\n\n\ndef test_plain_enum_lists():\n    class MyEnum(Enum):\n        a = [1]\n        b = [2]\n\n    assert MyEnum([1]) is MyEnum.a\n    v = SchemaValidator(core_schema.enum_schema(MyEnum, list(MyEnum.__members__.values())))\n    assert v.validate_python(MyEnum.a) is MyEnum.a\n    assert v.validate_python([1]) is MyEnum.a\n    assert v.validate_python([2]) is MyEnum.b\n\n\ndef test_plain_enum_empty():\n    class MyEnum(Enum):\n        pass\n\n    with pytest.raises(SchemaError, match='`members` should have length > 0'):\n        SchemaValidator(core_schema.enum_schema(MyEnum, []))\n\n\ndef test_enum_with_str_subclass() -> None:\n    class MyEnum(Enum):\n        a = 'a'\n        b = 'b'\n\n    v = SchemaValidator(core_schema.enum_schema(MyEnum, list(MyEnum.__members__.values())))\n\n    assert v.validate_python(MyEnum.a) is MyEnum.a\n    assert v.validate_python('a') is MyEnum.a\n\n    class MyStr(str):\n        pass\n\n    assert v.validate_python(MyStr('a')) is MyEnum.a\n    with pytest.raises(ValidationError):\n        v.validate_python(MyStr('a'), strict=True)\n\n\ndef test_enum_with_int_subclass() -> None:\n    class MyEnum(Enum):\n        a = 1\n        b = 2\n\n    v = SchemaValidator(core_schema.enum_schema(MyEnum, list(MyEnum.__members__.values())))\n\n    assert v.validate_python(MyEnum.a) is MyEnum.a\n    assert v.validate_python(1) is MyEnum.a\n\n    class MyInt(int):\n        pass\n\n    assert v.validate_python(MyInt(1)) is MyEnum.a\n    with pytest.raises(ValidationError):\n        v.validate_python(MyInt(1), strict=True)\n\n\ndef test_validate_float_for_int_enum() -> None:\n    class MyEnum(int, Enum):\n        a = 1\n        b = 2\n\n    v = SchemaValidator(core_schema.enum_schema(MyEnum, list(MyEnum.__members__.values())))\n\n    assert v.validate_python(1.0) is MyEnum.a\n\n\ndef test_missing_error_converted_to_val_error() -> None:\n    class MyFlags(IntFlag):\n        OFF = 0\n        ON = 1\n\n    v = SchemaValidator(\n        core_schema.with_default_schema(\n            schema=core_schema.enum_schema(MyFlags, list(MyFlags.__members__.values())), default=MyFlags.OFF\n        )\n    )\n\n    assert v.validate_python(MyFlags.OFF) is MyFlags.OFF\n    assert v.validate_python(0) is MyFlags.OFF\n\n    with pytest.raises(ValidationError):\n        v.validate_python(None)\n\n\ndef test_big_int():\n    class ColorEnum(IntEnum):\n        GREEN = 1 << 63\n        BLUE = 1 << 64\n\n    v = SchemaValidator(\n        core_schema.with_default_schema(schema=core_schema.enum_schema(ColorEnum, list(ColorEnum.__members__.values())))\n    )\n\n    assert v.validate_python(ColorEnum.GREEN) is ColorEnum.GREEN\n    assert v.validate_python(1 << 63) is ColorEnum.GREEN\n", "tests/validators/test_typed_dict.py": "import gc\nimport math\nimport platform\nimport re\nimport weakref\nfrom typing import Any, Dict, Mapping, Union\n\nimport pytest\nfrom dirty_equals import FunctionCheck\n\nfrom pydantic_core import CoreConfig, SchemaError, SchemaValidator, ValidationError, core_schema, validate_core_schema\n\nfrom ..conftest import Err, PyAndJson\n\n\nclass Cls:\n    def __init__(self, **attributes):\n        for k, v in attributes.items():\n            setattr(self, k, v)\n\n    def __repr__(self):\n        return 'Cls({})'.format(', '.join(f'{k}={v!r}' for k, v in self.__dict__.items()))\n\n\nclass Map(Mapping):\n    def __init__(self, **kwargs):\n        self._d = kwargs\n\n    def __iter__(self):\n        return iter(self._d)\n\n    def __len__(self) -> int:\n        return len(self._d)\n\n    def __getitem__(self, k, /):\n        return self._d[k]\n\n    def __repr__(self):\n        return 'Map({})'.format(', '.join(f'{k}={v!r}' for k, v in self._d.items()))\n\n\ndef test_simple():\n    v = SchemaValidator(\n        {\n            'type': 'typed-dict',\n            'fields': {\n                'field_a': {'type': 'typed-dict-field', 'schema': {'type': 'str'}},\n                'field_b': {'type': 'typed-dict-field', 'schema': {'type': 'int'}},\n            },\n        }\n    )\n\n    assert v.validate_python({'field_a': b'abc', 'field_b': 1}) == {'field_a': 'abc', 'field_b': 1}\n\n\ndef test_strict():\n    v = SchemaValidator(\n        {\n            'type': 'typed-dict',\n            'fields': {\n                'field_a': {'type': 'typed-dict-field', 'schema': {'type': 'str'}},\n                'field_b': {'type': 'typed-dict-field', 'schema': {'type': 'int'}},\n            },\n            'config': {'strict': True},\n        }\n    )\n\n    assert v.validate_python({'field_a': 'hello', 'field_b': 12}) == {'field_a': 'hello', 'field_b': 12}\n\n    with pytest.raises(ValidationError) as exc_info:\n        assert v.validate_python({'field_a': 123, 'field_b': '123'})\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'string_type', 'loc': ('field_a',), 'msg': 'Input should be a valid string', 'input': 123},\n        {'type': 'int_type', 'loc': ('field_b',), 'msg': 'Input should be a valid integer', 'input': '123'},\n    ]\n\n\ndef test_with_default():\n    v = SchemaValidator(\n        {\n            'type': 'typed-dict',\n            'fields': {\n                'field_a': {'type': 'typed-dict-field', 'schema': {'type': 'str'}},\n                'field_b': {\n                    'type': 'typed-dict-field',\n                    'schema': {'type': 'default', 'schema': {'type': 'int'}, 'default': 666},\n                },\n            },\n        }\n    )\n\n    assert v.validate_python({'field_a': b'abc'}) == {'field_a': 'abc', 'field_b': 666}\n    assert v.validate_python({'field_a': b'abc', 'field_b': 1}) == {'field_a': 'abc', 'field_b': 1}\n\n\ndef test_missing_error(pydantic_version):\n    v = SchemaValidator(\n        {\n            'type': 'typed-dict',\n            'fields': {\n                'field_a': {'type': 'typed-dict-field', 'schema': {'type': 'str'}},\n                'field_b': {'type': 'typed-dict-field', 'schema': {'type': 'int'}},\n            },\n        }\n    )\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python({'field_a': b'abc'})\n    # insert_assert(str(exc_info.value))\n    assert str(exc_info.value) == (\n        '1 validation error for typed-dict\\n'\n        'field_b\\n'\n        \"  Field required [type=missing, input_value={'field_a': b'abc'}, input_type=dict]\\n\"\n        f'    For further information visit https://errors.pydantic.dev/{pydantic_version}/v/missing'\n    )\n\n\n@pytest.mark.parametrize(\n    'config,input_value,expected',\n    [\n        ({}, {'a': '123'}, {'a': 123}),\n        ({}, Map(a=123), {'a': 123}),\n        ({}, {b'a': '123'}, Err('Field required [type=missing,')),\n        ({}, {'a': '123', 'c': 4}, {'a': 123}),\n        ({'extra_fields_behavior': 'allow'}, {'a': '123', 'c': 4}, {'a': 123, 'c': 4}),\n        ({'extra_fields_behavior': 'allow'}, {'a': '123', b'c': 4}, Err('Keys should be strings [type=invalid_key,')),\n        ({'strict': True}, Map(a=123), Err('Input should be a valid dictionary [type=dict_type,')),\n        ({}, {'a': '123', 'b': '4.7'}, {'a': 123, 'b': 4.7}),\n        ({}, {'a': '123', 'b': 'nan'}, {'a': 123, 'b': FunctionCheck(math.isnan)}),\n        (\n            {'allow_inf_nan': False},\n            {'a': '123', 'b': 'nan'},\n            Err('Input should be a finite number [type=finite_number,'),\n        ),\n    ],\n    ids=repr,\n)\ndef test_config(config: CoreConfig, input_value, expected):\n    v = SchemaValidator(\n        {\n            'type': 'typed-dict',\n            'fields': {\n                'a': {'type': 'typed-dict-field', 'schema': {'type': 'int'}},\n                'b': {'type': 'typed-dict-field', 'schema': {'type': 'float'}, 'required': False},\n            },\n            'config': config,\n        }\n    )\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            val = v.validate_python(input_value)\n            print(f'UNEXPECTED OUTPUT: {val!r}')\n    else:\n        output_dict = v.validate_python(input_value)\n        assert output_dict == expected\n\n\ndef test_ignore_extra():\n    v = SchemaValidator(\n        {\n            'type': 'typed-dict',\n            'fields': {\n                'field_a': {'type': 'typed-dict-field', 'schema': {'type': 'str'}},\n                'field_b': {'type': 'typed-dict-field', 'schema': {'type': 'int'}},\n            },\n        }\n    )\n\n    assert v.validate_python({'field_a': b'123', 'field_b': 1, 'field_c': 123}) == {'field_a': '123', 'field_b': 1}\n\n\ndef test_forbid_extra():\n    v = SchemaValidator(\n        {\n            'type': 'typed-dict',\n            'fields': {'field_a': {'type': 'typed-dict-field', 'schema': {'type': 'str'}}},\n            'extra_behavior': 'forbid',\n        }\n    )\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python({'field_a': 'abc', 'field_b': 1})\n\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'extra_forbidden', 'loc': ('field_b',), 'msg': 'Extra inputs are not permitted', 'input': 1}\n    ]\n\n\ndef test_allow_extra_invalid():\n    with pytest.raises(SchemaError, match='extras_schema can only be used if extra_behavior=allow'):\n        SchemaValidator(\n            {'type': 'typed-dict', 'fields': {}, 'extras_schema': {'type': 'int'}, 'extra_behavior': 'ignore'}\n        )\n\n\ndef test_allow_extra_wrong():\n    with pytest.raises(SchemaError, match=\"Input should be 'allow', 'forbid' or 'ignore'\"):\n        validate_core_schema({'type': 'typed-dict', 'fields': {}, 'config': {'extra_fields_behavior': 'wrong'}})\n\n\ndef test_str_config():\n    v = SchemaValidator(\n        {\n            'type': 'typed-dict',\n            'fields': {'field_a': {'type': 'typed-dict-field', 'schema': {'type': 'str'}}},\n            'config': {'str_max_length': 5},\n        }\n    )\n    assert v.validate_python({'field_a': 'test'}) == {'field_a': 'test'}\n\n    with pytest.raises(ValidationError, match='String should have at most 5 characters'):\n        v.validate_python({'field_a': 'test long'})\n\n\ndef test_json_error():\n    v = SchemaValidator(\n        {\n            'type': 'typed-dict',\n            'fields': {\n                'field_a': {'type': 'typed-dict-field', 'schema': {'type': 'list', 'items_schema': {'type': 'int'}}}\n            },\n        }\n    )\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_json('{\"field_a\": [123, \"wrong\"]}')\n\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'int_parsing',\n            'loc': ('field_a', 1),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'wrong',\n        }\n    ]\n\n\ndef test_missing_schema_key():\n    with pytest.raises(SchemaError, match='typed-dict.fields.x.schema\\n  Field required'):\n        validate_core_schema({'type': 'typed-dict', 'fields': {'x': {'type': 'str'}}})\n\n\ndef test_fields_required_by_default():\n    \"\"\"By default all fields should be required\"\"\"\n    v = SchemaValidator(\n        {\n            'type': 'typed-dict',\n            'fields': {\n                'x': {'type': 'typed-dict-field', 'schema': {'type': 'str'}},\n                'y': {'type': 'typed-dict-field', 'schema': {'type': 'str'}},\n            },\n        }\n    )\n\n    assert v.validate_python({'x': 'pika', 'y': 'chu'}) == {'x': 'pika', 'y': 'chu'}\n\n    with pytest.raises(ValidationError) as exc_info:\n        assert v.validate_python({'x': 'pika'})\n\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'missing', 'loc': ('y',), 'msg': 'Field required', 'input': {'x': 'pika'}}\n    ]\n\n\ndef test_fields_required_by_default_with_optional():\n    v = SchemaValidator(\n        {\n            'type': 'typed-dict',\n            'fields': {\n                'x': {'type': 'typed-dict-field', 'schema': {'type': 'str'}},\n                'y': {'type': 'typed-dict-field', 'schema': {'type': 'str'}, 'required': False},\n            },\n        }\n    )\n\n    assert v.validate_python({'x': 'pika', 'y': 'chu'}) == {'x': 'pika', 'y': 'chu'}\n    assert v.validate_python({'x': 'pika'}) == {'x': 'pika'}\n\n\ndef test_fields_required_by_default_with_default():\n    v = SchemaValidator(\n        {\n            'type': 'typed-dict',\n            'fields': {\n                'x': {'type': 'typed-dict-field', 'schema': {'type': 'str'}},\n                'y': {\n                    'type': 'typed-dict-field',\n                    'schema': {'type': 'default', 'schema': {'type': 'str'}, 'default': 'bulbi'},\n                },\n            },\n        }\n    )\n\n    assert v.validate_python({'x': 'pika', 'y': 'chu'}) == {'x': 'pika', 'y': 'chu'}\n    assert v.validate_python({'x': 'pika'}) == {'x': 'pika', 'y': 'bulbi'}\n\n\ndef test_all_optional_fields():\n    \"\"\"By default all fields should be optional if `total` is set to `False`\"\"\"\n    v = SchemaValidator(\n        {\n            'type': 'typed-dict',\n            'total': False,\n            'fields': {\n                'x': {'type': 'typed-dict-field', 'schema': {'type': 'str', 'strict': True}},\n                'y': {'type': 'typed-dict-field', 'schema': {'type': 'str'}},\n            },\n        }\n    )\n\n    assert v.validate_python({'x': 'pika', 'y': 'chu'}) == {'x': 'pika', 'y': 'chu'}\n    assert v.validate_python({'x': 'pika'}) == {'x': 'pika'}\n    assert v.validate_python({'y': 'chu'}) == {'y': 'chu'}\n\n    with pytest.raises(ValidationError) as exc_info:\n        assert v.validate_python({'x': 123})\n\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'string_type', 'loc': ('x',), 'msg': 'Input should be a valid string', 'input': 123}\n    ]\n\n\ndef test_all_optional_fields_with_required_fields():\n    v = SchemaValidator(\n        {\n            'type': 'typed-dict',\n            'total': False,\n            'fields': {\n                'x': {'type': 'typed-dict-field', 'schema': {'type': 'str', 'strict': True}, 'required': True},\n                'y': {'type': 'typed-dict-field', 'schema': {'type': 'str'}},\n            },\n        }\n    )\n\n    assert v.validate_python({'x': 'pika', 'y': 'chu'}) == {'x': 'pika', 'y': 'chu'}\n    assert v.validate_python({'x': 'pika'}) == {'x': 'pika'}\n\n    with pytest.raises(ValidationError) as exc_info:\n        assert v.validate_python({'y': 'chu'}) == ({'y': 'chu'}, {'y'})\n\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'missing', 'loc': ('x',), 'msg': 'Field required', 'input': {'y': 'chu'}}\n    ]\n\n\ndef test_field_required_and_default():\n    \"\"\"A field cannot be required and have a default value\"\"\"\n    with pytest.raises(SchemaError, match=\"Field 'x': a required field cannot have a default value\"):\n        SchemaValidator(\n            {\n                'type': 'typed-dict',\n                'fields': {\n                    'x': {\n                        'type': 'typed-dict-field',\n                        'schema': {'type': 'default', 'schema': {'type': 'str'}, 'default': 'pika'},\n                        'required': True,\n                    }\n                },\n            }\n        )\n\n\ndef test_alias(py_and_json: PyAndJson):\n    v = py_and_json(\n        {\n            'type': 'typed-dict',\n            'fields': {\n                'field_a': {'validation_alias': 'FieldA', 'type': 'typed-dict-field', 'schema': {'type': 'int'}}\n            },\n        }\n    )\n    assert v.validate_test({'FieldA': '123'}) == {'field_a': 123}\n    with pytest.raises(ValidationError, match=r'FieldA\\n +Field required \\[type=missing,'):\n        assert v.validate_test({'foobar': '123'})\n    with pytest.raises(ValidationError, match=r'FieldA\\n +Field required \\[type=missing,'):\n        assert v.validate_test({'field_a': '123'})\n\n\ndef test_empty_string_field_name(py_and_json: PyAndJson):\n    v = py_and_json({'type': 'typed-dict', 'fields': {'': {'type': 'typed-dict-field', 'schema': {'type': 'int'}}}})\n    assert v.validate_test({'': 123}) == {'': 123}\n\n\ndef test_empty_string_aliases(py_and_json: PyAndJson):\n    v = py_and_json(\n        {\n            'type': 'typed-dict',\n            'fields': {'field_a': {'validation_alias': '', 'type': 'typed-dict-field', 'schema': {'type': 'int'}}},\n        }\n    )\n    assert v.validate_test({'': 123}) == {'field_a': 123}\n\n    v = py_and_json(\n        {\n            'type': 'typed-dict',\n            'fields': {\n                'field_a': {'validation_alias': ['', ''], 'type': 'typed-dict-field', 'schema': {'type': 'int'}}\n            },\n        }\n    )\n    assert v.validate_test({'': {'': 123}}) == {'field_a': 123}\n\n\ndef test_alias_allow_pop(py_and_json: PyAndJson):\n    v = py_and_json(\n        {\n            'type': 'typed-dict',\n            'populate_by_name': True,\n            'fields': {\n                'field_a': {'validation_alias': 'FieldA', 'type': 'typed-dict-field', 'schema': {'type': 'int'}}\n            },\n        }\n    )\n    assert v.validate_test({'FieldA': '123'}) == {'field_a': 123}\n    assert v.validate_test({'field_a': '123'}) == {'field_a': 123}\n    assert v.validate_test({'FieldA': '1', 'field_a': '2'}) == {'field_a': 1}\n    with pytest.raises(ValidationError, match=r'FieldA\\n +Field required \\[type=missing,'):\n        assert v.validate_test({'foobar': '123'})\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ({'foo': {'bar': '123'}}, {'field_a': 123}),\n        ({'x': '123'}, Err(r'foo.bar\\n +Field required \\[type=missing,')),\n        ({'foo': '123'}, Err(r'foo.bar\\n +Field required \\[type=missing,')),\n        ({'foo': [1, 2, 3]}, Err(r'foo.bar\\n +Field required \\[type=missing,')),\n        ({'foo': {'bat': '123'}}, Err(r'foo.bar\\n +Field required \\[type=missing,')),\n    ],\n    ids=repr,\n)\ndef test_alias_path(py_and_json: PyAndJson, input_value, expected):\n    v = py_and_json(\n        {\n            'type': 'typed-dict',\n            'fields': {\n                'field_a': {'validation_alias': ['foo', 'bar'], 'type': 'typed-dict-field', 'schema': {'type': 'int'}}\n            },\n        }\n    )\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=expected.message):\n            v.validate_test(input_value)\n    else:\n        output = v.validate_test(input_value)\n        assert output == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ({'foo': {'bar': {'bat': '123'}}}, {'field_a': 123}),\n        ({'foo': [1, 2, 3, 4]}, {'field_a': 4}),\n        ({'foo': (1, 2, 3, 4)}, {'field_a': 4}),\n        ({'spam': 5}, {'field_a': 5}),\n        ({'spam': 1, 'foo': {'bar': {'bat': 2}}}, {'field_a': 2}),\n        ({'foo': {'x': 2}}, Err(r'field_a\\n +Field required \\[type=missing,')),\n        ({'x': '123'}, Err(r'field_a\\n +Field required \\[type=missing,')),\n        ({'x': {2: 33}}, Err(r'field_a\\n +Field required \\[type=missing,')),\n        ({'foo': '01234'}, Err(r'field_a\\n +Field required \\[type=missing,')),\n        ({'foo': [1]}, Err(r'field_a\\n +Field required \\[type=missing,')),\n    ],\n    ids=repr,\n)\ndef test_aliases_path_multiple(py_and_json: PyAndJson, input_value, expected):\n    v = py_and_json(\n        {\n            'type': 'typed-dict',\n            'fields': {\n                'field_a': {\n                    'validation_alias': [['foo', 'bar', 'bat'], ['foo', 3], ['spam']],\n                    'type': 'typed-dict-field',\n                    'schema': {'type': 'int'},\n                }\n            },\n            'config': {'loc_by_alias': False},\n        }\n    )\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=expected.message):\n            val = v.validate_test(input_value)\n            print(f'UNEXPECTED OUTPUT: {val!r}')\n    else:\n        output = v.validate_test(input_value)\n        assert output == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ({'foo': {-2: '123'}}, {'field_a': 123}),\n        # negatives indexes work fine\n        ({'foo': [1, 42, 'xx']}, {'field_a': 42}),\n        ({'foo': [42, 'xxx', 42]}, Err(r'Input should be a valid integer,')),\n        ({'foo': [42]}, Err(r'field_a\\n +Field required \\[type=missing,')),\n        ({'foo': {'xx': '123'}}, Err(r'field_a\\n +Field required \\[type=missing,')),\n        ({'foo': {'-2': '123'}}, Err(r'field_a\\n +Field required \\[type=missing,')),\n        ({'foo': {2: '123'}}, Err(r'field_a\\n +Field required \\[type=missing,')),\n        ({'foo': 'foobar'}, Err(r'field_a\\n +Field required \\[type=missing,')),\n        ({'foo': {0, 1, 2}}, Err(r'field_a\\n +Field required \\[type=missing,')),\n    ],\n    ids=repr,\n)\ndef test_aliases_path_negative(input_value, expected):\n    v = SchemaValidator(\n        {\n            'type': 'typed-dict',\n            'fields': {\n                'field_a': {'validation_alias': ['foo', -2], 'type': 'typed-dict-field', 'schema': {'type': 'int'}}\n            },\n            'config': {'loc_by_alias': False},\n        }\n    )\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=expected.message):\n            val = v.validate_python(input_value)\n            print(f'UNEXPECTED OUTPUT: {val!r}')\n    else:\n        output = v.validate_python(input_value)\n        assert output == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ({'foo': [1, 42, 'xx']}, {'field_a': 42}),\n        ({'foo': [42, 'xxx', 42]}, Err(r'Input should be a valid integer,')),\n        ({'foo': [42]}, Err(r'foo.-2\\n +Field required \\[type=missing,')),\n    ],\n    ids=repr,\n)\ndef test_aliases_path_negative_json(py_and_json: PyAndJson, input_value, expected):\n    v = py_and_json(\n        {\n            'type': 'typed-dict',\n            'fields': {\n                'field_a': {'validation_alias': ['foo', -2], 'type': 'typed-dict-field', 'schema': {'type': 'int'}}\n            },\n        }\n    )\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=expected.message):\n            val = v.validate_test(input_value)\n            print(f'UNEXPECTED OUTPUT: {val!r}')\n    else:\n        output = v.validate_test(input_value)\n        assert output == expected\n\n\ndef test_aliases_debug():\n    v = SchemaValidator(\n        {\n            'type': 'typed-dict',\n            'fields': {\n                'field_a': {\n                    'validation_alias': [['foo', 'bar', 'bat'], ['foo', 3]],\n                    'type': 'typed-dict-field',\n                    'schema': {'type': 'int'},\n                }\n            },\n        }\n    )\n    print(repr(v))\n    assert repr(v).startswith('SchemaValidator(title=\"typed-dict\", validator=TypedDict(')\n    assert 'PathChoices(' in repr(v)\n\n\ndef get_int_key():\n    v = SchemaValidator(\n        {\n            'type': 'typed-dict',\n            'fields': {\n                'field_a': {\n                    'validation_alias': [['foo', 3], ['spam']],\n                    'type': 'typed-dict-field',\n                    'schema': {'type': 'int'},\n                }\n            },\n        }\n    )\n    assert v.validate_python({'foo': {3: 33}}) == ({'field_a': 33}, {'field_a'})\n\n\nclass GetItemThing:\n    def __getitem__(self, v):\n        assert v == 'foo'\n        return 321\n\n\ndef get_custom_getitem():\n    v = SchemaValidator(\n        {\n            'type': 'typed-dict',\n            'fields': {'field_a': {'validation_alias': ['foo'], 'type': 'typed-dict-field', 'schema': {'type': 'int'}}},\n        }\n    )\n    assert v.validate_python(GetItemThing()) == ({'field_a': 321}, {'field_a'})\n    assert v.validate_python({'bar': GetItemThing()}) == ({'field_a': 321}, {'field_a'})\n\n\n@pytest.mark.parametrize('input_value', [{'foo': {'bar': 42}}, {'foo': 42}, {'field_a': 42}], ids=repr)\ndef test_paths_allow_by_name(py_and_json: PyAndJson, input_value):\n    v = py_and_json(\n        {\n            'type': 'typed-dict',\n            'fields': {\n                'field_a': {\n                    'validation_alias': [['foo', 'bar'], ['foo']],\n                    'type': 'typed-dict-field',\n                    'schema': {'type': 'int'},\n                }\n            },\n            'populate_by_name': True,\n        }\n    )\n    assert v.validate_test(input_value) == {'field_a': 42}\n\n\n@pytest.mark.parametrize(\n    'alias_schema,error',\n    [\n        ({'validation_alias': ['foo', ['bar']]}, 'Input should be a valid string'),\n        ({'validation_alias': []}, 'Lookup paths should have at least one element'),\n        ({'validation_alias': [[]]}, 'Each alias path should have at least one element'),\n        ({'validation_alias': [123]}, \"TypeError: 'int' object cannot be converted to 'PyList'\"),\n        ({'validation_alias': [[[]]]}, 'Input should be a valid string'),\n        ({'validation_alias': [[1, 'foo']]}, 'TypeError: The first item in an alias path should be a string'),\n    ],\n    ids=repr,\n)\ndef test_alias_build_error(alias_schema, error):\n    with pytest.raises(SchemaError, match=error):\n        SchemaValidator(\n            validate_core_schema(\n                {\n                    'type': 'typed-dict',\n                    'fields': {'field_a': {'type': 'typed-dict-field', 'schema': {'type': 'int'}, **alias_schema}},\n                }\n            )\n        )\n\n\ndef test_alias_error_loc_alias(py_and_json: PyAndJson):\n    v = py_and_json(\n        {\n            'type': 'typed-dict',\n            'fields': {\n                'field_a': {\n                    'type': 'typed-dict-field',\n                    'schema': {'type': 'int'},\n                    'validation_alias': [['foo', 'x'], ['bar', 1, -1]],\n                }\n            },\n        },\n        {'loc_by_alias': True},  # this is the default\n    )\n    assert v.validate_test({'foo': {'x': 42}}) == {'field_a': 42}\n    assert v.validate_python({'bar': ['x', {-1: 42}]}) == {'field_a': 42}\n    assert v.validate_test({'bar': ['x', [1, 2, 42]]}) == {'field_a': 42}\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_test({'foo': {'x': 'not_int'}})\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'int_parsing',\n            'loc': ('foo', 'x'),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'not_int',\n        }\n    ]\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_test({'bar': ['x', [1, 2, 'not_int']]})\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'int_parsing',\n            'loc': ('bar', 1, -1),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'not_int',\n        }\n    ]\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_test({})\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'missing', 'loc': ('foo', 'x'), 'msg': 'Field required', 'input': {}}\n    ]\n\n\ndef test_alias_error_loc_field_names(py_and_json: PyAndJson):\n    v = py_and_json(\n        {\n            'type': 'typed-dict',\n            'fields': {\n                'field_a': {\n                    'type': 'typed-dict-field',\n                    'schema': {'type': 'int'},\n                    'validation_alias': [['foo'], ['bar', 1, -1]],\n                }\n            },\n            'config': {'loc_by_alias': False},\n        }\n    )\n    assert v.validate_test({'foo': 42}) == {'field_a': 42}\n    assert v.validate_test({'bar': ['x', [1, 2, 42]]}) == {'field_a': 42}\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_test({'foo': 'not_int'})\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'int_parsing',\n            'loc': ('field_a',),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'not_int',\n        }\n    ]\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_test({'bar': ['x', [1, 2, 'not_int']]})\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'int_parsing',\n            'loc': ('field_a',),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'not_int',\n        }\n    ]\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_test({})\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'missing', 'loc': ('field_a',), 'msg': 'Field required', 'input': {}}\n    ]\n\n\ndef test_empty_model():\n    v = SchemaValidator({'type': 'typed-dict', 'fields': {}})\n    assert v.validate_python({}) == {}\n    with pytest.raises(ValidationError, match=re.escape('Input should be a valid dictionary [type=dict_type,')):\n        v.validate_python('x')\n\n\ndef test_model_deep():\n    v = SchemaValidator(\n        {\n            'type': 'typed-dict',\n            'fields': {\n                'field_a': {'type': 'typed-dict-field', 'schema': {'type': 'str'}},\n                'field_b': {\n                    'type': 'typed-dict-field',\n                    'schema': {\n                        'type': 'typed-dict',\n                        'fields': {\n                            'field_c': {'type': 'typed-dict-field', 'schema': {'type': 'str'}},\n                            'field_d': {\n                                'type': 'typed-dict-field',\n                                'schema': {\n                                    'type': 'typed-dict',\n                                    'fields': {\n                                        'field_e': {'type': 'typed-dict-field', 'schema': {'type': 'str'}},\n                                        'field_f': {'type': 'typed-dict-field', 'schema': {'type': 'int'}},\n                                    },\n                                },\n                            },\n                        },\n                    },\n                },\n            },\n        }\n    )\n    output = v.validate_python({'field_a': '1', 'field_b': {'field_c': '2', 'field_d': {'field_e': '4', 'field_f': 4}}})\n    assert output == {'field_a': '1', 'field_b': ({'field_c': '2', 'field_d': {'field_e': '4', 'field_f': 4}})}\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python({'field_a': '1', 'field_b': {'field_c': '2', 'field_d': {'field_e': '4', 'field_f': 'xx'}}})\n\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'int_parsing',\n            'loc': ('field_b', 'field_d', 'field_f'),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'xx',\n        }\n    ]\n\n\ndef test_alias_extra(py_and_json: PyAndJson):\n    v = py_and_json(\n        {\n            'type': 'typed-dict',\n            'extra_behavior': 'allow',\n            'fields': {\n                'field_a': {\n                    'validation_alias': [['FieldA'], ['foo', 2]],\n                    'type': 'typed-dict-field',\n                    'schema': {'type': 'int'},\n                }\n            },\n            'config': {'loc_by_alias': False},\n        }\n    )\n    assert v.validate_test({'FieldA': 1}) == {'field_a': 1}\n    assert v.validate_test({'foo': [1, 2, 3]}) == {'field_a': 3}\n\n    # used_keys should be populated either though validation fails so \"FieldA\" is skipped in extra\n    with pytest.raises(ValidationError) as exc_info:\n        assert v.validate_test({'FieldA': '...'}) == {'field_a': 1}\n\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'int_parsing',\n            'loc': ('field_a',),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': '...',\n        }\n    ]\n\n\ndef test_alias_extra_by_name(py_and_json: PyAndJson):\n    v = py_and_json(\n        {\n            'type': 'typed-dict',\n            'extra_behavior': 'allow',\n            'populate_by_name': True,\n            'fields': {\n                'field_a': {'validation_alias': 'FieldA', 'type': 'typed-dict-field', 'schema': {'type': 'int'}}\n            },\n        }\n    )\n    assert v.validate_test({'FieldA': 1}) == {'field_a': 1}\n    assert v.validate_test({'field_a': 1}) == {'field_a': 1}\n\n\ndef test_alias_extra_forbid(py_and_json: PyAndJson):\n    v = py_and_json(\n        {\n            'type': 'typed-dict',\n            'extra_behavior': 'forbid',\n            'fields': {\n                'field_a': {'type': 'typed-dict-field', 'validation_alias': 'FieldA', 'schema': {'type': 'int'}}\n            },\n        }\n    )\n    assert v.validate_test({'FieldA': 1}) == {'field_a': 1}\n\n\ndef test_with_default_factory():\n    v = SchemaValidator(\n        {\n            'type': 'typed-dict',\n            'fields': {\n                'x': {\n                    'type': 'typed-dict-field',\n                    'schema': {'type': 'default', 'schema': {'type': 'str'}, 'default_factory': lambda: 'pikachu'},\n                }\n            },\n        }\n    )\n\n    assert v.validate_python({}) == {'x': 'pikachu'}\n    assert v.validate_python({'x': 'bulbi'}) == {'x': 'bulbi'}\n\n\ndef test_field_required_and_default_factory():\n    \"\"\"A field cannot be required and have a default factory\"\"\"\n    with pytest.raises(SchemaError, match=\"Field 'x': a required field cannot have a default value\"):\n        SchemaValidator(\n            {\n                'type': 'typed-dict',\n                'fields': {\n                    'x': {\n                        'type': 'typed-dict-field',\n                        'schema': {'type': 'default', 'schema': {'type': 'str'}, 'default_factory': lambda: 'pika'},\n                        'required': True,\n                    }\n                },\n            }\n        )\n\n\n@pytest.mark.parametrize(\n    'default_factory,error_message',\n    [\n        (lambda: 1 + 'a', \"unsupported operand type(s) for +: 'int' and 'str'\"),\n        (lambda x: 'a' + x, \"<lambda>() missing 1 required positional argument: 'x'\"),\n    ],\n)\ndef test_bad_default_factory(default_factory, error_message):\n    v = SchemaValidator(\n        {\n            'type': 'typed-dict',\n            'fields': {\n                'x': {\n                    'type': 'typed-dict-field',\n                    'schema': {'type': 'default', 'schema': {'type': 'str'}, 'default_factory': default_factory},\n                }\n            },\n        }\n    )\n    with pytest.raises(TypeError, match=re.escape(error_message)):\n        v.validate_python({})\n\n\nclass TestOnError:\n    def test_on_error_bad_name(self):\n        with pytest.raises(SchemaError, match=\"Input should be 'raise', 'omit' or 'default'\"):\n            validate_core_schema(\n                {\n                    'type': 'typed-dict',\n                    'fields': {\n                        'x': {\n                            'type': 'typed-dict-field',\n                            'schema': {'type': 'default', 'schema': {'type': 'str'}, 'on_error': 'rais'},\n                        }\n                    },\n                }\n            )\n\n    def test_on_error_bad_omit(self):\n        with pytest.raises(SchemaError, match=\"Field 'x': 'on_error = omit' cannot be set for required fields\"):\n            SchemaValidator(\n                {\n                    'type': 'typed-dict',\n                    'fields': {\n                        'x': {\n                            'type': 'typed-dict-field',\n                            'schema': {'type': 'default', 'schema': {'type': 'str'}, 'on_error': 'omit'},\n                        }\n                    },\n                }\n            )\n\n    def test_on_error_bad_default(self):\n        with pytest.raises(SchemaError, match=\"'on_error = default' requires a `default` or `default_factory`\"):\n            SchemaValidator(\n                {\n                    'type': 'typed-dict',\n                    'fields': {\n                        'x': {\n                            'type': 'typed-dict-field',\n                            'schema': {'type': 'default', 'schema': {'type': 'str'}, 'on_error': 'default'},\n                        }\n                    },\n                }\n            )\n\n    def test_on_error_raise_by_default(self, py_and_json: PyAndJson):\n        v = py_and_json(\n            {'type': 'typed-dict', 'fields': {'x': {'type': 'typed-dict-field', 'schema': {'type': 'str'}}}}\n        )\n        assert v.validate_test({'x': 'foo'}) == {'x': 'foo'}\n        with pytest.raises(ValidationError) as exc_info:\n            v.validate_test({'x': ['foo']})\n        assert exc_info.value.errors(include_url=False) == [\n            {'input': ['foo'], 'type': 'string_type', 'loc': ('x',), 'msg': 'Input should be a valid string'}\n        ]\n\n    def test_on_error_raise_explicit(self, py_and_json: PyAndJson):\n        v = py_and_json(\n            {\n                'type': 'typed-dict',\n                'fields': {\n                    'x': {\n                        'type': 'typed-dict-field',\n                        'schema': {'type': 'default', 'schema': {'type': 'str'}, 'on_error': 'raise'},\n                    }\n                },\n            }\n        )\n        assert v.validate_test({'x': 'foo'}) == {'x': 'foo'}\n        with pytest.raises(ValidationError) as exc_info:\n            v.validate_test({'x': ['foo']})\n        assert exc_info.value.errors(include_url=False) == [\n            {'input': ['foo'], 'type': 'string_type', 'loc': ('x',), 'msg': 'Input should be a valid string'}\n        ]\n\n    def test_on_error_omit(self, py_and_json: PyAndJson):\n        v = py_and_json(\n            {\n                'type': 'typed-dict',\n                'fields': {\n                    'x': {\n                        'type': 'typed-dict-field',\n                        'schema': {'type': 'default', 'schema': {'type': 'str'}, 'on_error': 'omit'},\n                        'required': False,\n                    }\n                },\n            }\n        )\n        assert v.validate_test({'x': 'foo'}) == {'x': 'foo'}\n        assert v.validate_test({}) == {}\n        assert v.validate_test({'x': ['foo']}) == {}\n\n    def test_on_error_omit_with_default(self, py_and_json: PyAndJson):\n        v = py_and_json(\n            {\n                'type': 'typed-dict',\n                'fields': {\n                    'x': {\n                        'type': 'typed-dict-field',\n                        'schema': {'type': 'default', 'schema': {'type': 'str'}, 'on_error': 'omit', 'default': 'pika'},\n                        'required': False,\n                    }\n                },\n            }\n        )\n        assert v.validate_test({'x': 'foo'}) == {'x': 'foo'}\n        assert v.validate_test({}) == {'x': 'pika'}\n        assert v.validate_test({'x': ['foo']}) == {}\n\n    def test_on_error_default(self, py_and_json: PyAndJson):\n        v = py_and_json(\n            {\n                'type': 'typed-dict',\n                'fields': {\n                    'x': {\n                        'type': 'typed-dict-field',\n                        'schema': {\n                            'type': 'default',\n                            'schema': {'type': 'str'},\n                            'on_error': 'default',\n                            'default': 'pika',\n                        },\n                    }\n                },\n            }\n        )\n        assert v.validate_test({'x': 'foo'}) == {'x': 'foo'}\n        assert v.validate_test({'x': ['foo']}) == {'x': 'pika'}\n\n    def test_on_error_default_factory(self, py_and_json: PyAndJson):\n        v = py_and_json(\n            {\n                'type': 'typed-dict',\n                'fields': {\n                    'x': {\n                        'type': 'typed-dict-field',\n                        'schema': {\n                            'type': 'default',\n                            'schema': {'type': 'str'},\n                            'on_error': 'default',\n                            'default_factory': lambda: 'pika',\n                        },\n                    }\n                },\n            }\n        )\n        assert v.validate_test({'x': 'foo'}) == {'x': 'foo'}\n        assert v.validate_test({'x': ['foo']}) == {'x': 'pika'}\n\n    def test_wrap_on_error(self, py_and_json: PyAndJson):\n        def wrap_function(input_value, validator, info):\n            try:\n                return validator(input_value)\n            except ValidationError:\n                if isinstance(input_value, list):\n                    return str(len(input_value))\n                else:\n                    return repr(input_value)\n\n        v = py_and_json(\n            {\n                'type': 'typed-dict',\n                'fields': {\n                    'x': {\n                        'type': 'typed-dict-field',\n                        'schema': {\n                            'type': 'default',\n                            'on_error': 'raise',\n                            'schema': {\n                                'type': 'function-wrap',\n                                'function': {'type': 'with-info', 'function': wrap_function},\n                                'schema': {'type': 'str'},\n                            },\n                        },\n                    }\n                },\n            }\n        )\n        assert v.validate_test({'x': 'foo'}) == {'x': 'foo'}\n        assert v.validate_test({'x': ['foo']}) == {'x': '1'}\n        assert v.validate_test({'x': ['foo', 'bar']}) == {'x': '2'}\n        assert v.validate_test({'x': {'a': 'b'}}) == {'x': \"{'a': 'b'}\"}\n\n\n@pytest.mark.parametrize(\n    'config,schema_extra_behavior_kw',\n    [\n        (core_schema.CoreConfig(extra_fields_behavior='allow'), {}),\n        (core_schema.CoreConfig(extra_fields_behavior='allow'), {'extra_behavior': None}),\n        (core_schema.CoreConfig(), {'extra_behavior': 'allow'}),\n        (None, {'extra_behavior': 'allow'}),\n        (core_schema.CoreConfig(extra_fields_behavior='forbid'), {'extra_behavior': 'allow'}),\n    ],\n)\n@pytest.mark.parametrize(\n    'extras_schema_kw, expected_extra_value',\n    [({}, '123'), ({'extras_schema': None}, '123'), ({'extras_schema': core_schema.int_schema()}, 123)],\n    ids=['extras_schema=unset', 'extras_schema=None', 'extras_schema=int'],\n)\ndef test_extra_behavior_allow(\n    config: Union[core_schema.CoreConfig, None],\n    schema_extra_behavior_kw: Dict[str, Any],\n    extras_schema_kw: Dict[str, Any],\n    expected_extra_value: Any,\n):\n    v = SchemaValidator(\n        core_schema.typed_dict_schema(\n            {'f': core_schema.typed_dict_field(core_schema.str_schema())},\n            **schema_extra_behavior_kw,\n            **extras_schema_kw,\n            config=config,\n        )\n    )\n\n    m: Dict[str, Any] = v.validate_python({'f': 'x', 'extra_field': '123'})\n    assert m == {'f': 'x', 'extra_field': expected_extra_value}\n\n\n@pytest.mark.parametrize(\n    'config,schema_extra_behavior_kw',\n    [\n        (core_schema.CoreConfig(extra_fields_behavior='forbid'), {}),\n        (core_schema.CoreConfig(extra_fields_behavior='forbid'), {'extra_behavior': None}),\n        (core_schema.CoreConfig(), {'extra_behavior': 'forbid'}),\n        (None, {'extra_behavior': 'forbid'}),\n        (core_schema.CoreConfig(extra_fields_behavior='allow'), {'extra_behavior': 'forbid'}),\n    ],\n)\ndef test_extra_behavior_forbid(config: Union[core_schema.CoreConfig, None], schema_extra_behavior_kw: Dict[str, Any]):\n    v = SchemaValidator(\n        core_schema.typed_dict_schema(\n            {'f': core_schema.typed_dict_field(core_schema.str_schema())}, **schema_extra_behavior_kw, config=config\n        )\n    )\n\n    m: Dict[str, Any] = v.validate_python({'f': 'x'})\n    assert m == {'f': 'x'}\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python({'f': 'x', 'extra_field': 123})\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'extra_forbidden', 'loc': ('extra_field',), 'msg': 'Extra inputs are not permitted', 'input': 123}\n    ]\n\n\n@pytest.mark.parametrize(\n    'config,schema_extra_behavior_kw',\n    [\n        (core_schema.CoreConfig(extra_fields_behavior='ignore'), {}),\n        (core_schema.CoreConfig(), {'extra_behavior': 'ignore'}),\n        (None, {'extra_behavior': 'ignore'}),\n        (core_schema.CoreConfig(extra_fields_behavior='forbid'), {'extra_behavior': 'ignore'}),\n        (core_schema.CoreConfig(), {}),\n        (core_schema.CoreConfig(), {'extra_behavior': None}),\n        (None, {'extra_behavior': None}),\n    ],\n)\ndef test_extra_behavior_ignore(config: Union[core_schema.CoreConfig, None], schema_extra_behavior_kw: Dict[str, Any]):\n    v = SchemaValidator(\n        core_schema.typed_dict_schema(\n            {'f': core_schema.typed_dict_field(core_schema.str_schema())}, **schema_extra_behavior_kw\n        ),\n        config=config,\n    )\n\n    m: Dict[str, Any] = v.validate_python({'f': 'x', 'extra_field': 123})\n    assert m == {'f': 'x'}\n\n\n@pytest.mark.xfail(\n    condition=platform.python_implementation() == 'PyPy', reason='https://foss.heptapod.net/pypy/pypy/-/issues/3899'\n)\ndef test_leak_typed_dict():\n    def fn():\n        def validate(v, info):\n            return v\n\n        schema = core_schema.with_info_plain_validator_function(validate)\n        schema = core_schema.typed_dict_schema(\n            {'f': core_schema.typed_dict_field(schema)}, extra_behavior='allow', extras_schema=schema\n        )\n\n        # If any of the Rust validators don't implement traversal properly,\n        # there will be an undetectable cycle created by this assignment\n        # which will keep Defaulted alive\n        validate.__pydantic_validator__ = SchemaValidator(schema)\n\n        return validate\n\n    cycle = fn()\n    ref = weakref.ref(cycle)\n    assert ref() is not None\n\n    del cycle\n    gc.collect(0)\n    gc.collect(1)\n    gc.collect(2)\n    gc.collect()\n\n    assert ref() is None\n", "tests/validators/test_is_subclass.py": "import pytest\n\nfrom pydantic_core import SchemaError, SchemaValidator, ValidationError, core_schema\n\n\nclass Foo:\n    pass\n\n\nclass Foobar(Foo):\n    pass\n\n\nclass Bar:\n    pass\n\n\ndef test_is_subclass_basic():\n    v = SchemaValidator(core_schema.is_subclass_schema(Foo))\n    assert v.validate_python(Foo) == Foo\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python(Bar)\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'is_subclass_of',\n            'loc': (),\n            'msg': 'Input should be a subclass of Foo',\n            'input': Bar,\n            'ctx': {'class': 'Foo'},\n        }\n    ]\n\n\n@pytest.mark.parametrize(\n    'input_value,valid',\n    [\n        (Foo, True),\n        (Foobar, True),\n        (Bar, False),\n        (type, False),\n        (1, False),\n        ('foo', False),\n        (Foo(), False),\n        (Foobar(), False),\n        (Bar(), False),\n    ],\n)\ndef test_is_subclass(input_value, valid):\n    v = SchemaValidator(core_schema.is_subclass_schema(Foo))\n    assert v.isinstance_python(input_value) == valid\n\n\ndef test_not_parent():\n    v = SchemaValidator(core_schema.is_subclass_schema(Foobar))\n    assert v.isinstance_python(Foobar)\n    assert not v.isinstance_python(Foo)\n\n\ndef test_invalid_type():\n    with pytest.raises(SchemaError, match=\"TypeError: 'Foo' object cannot be converted to 'PyType\"):\n        SchemaValidator(core_schema.is_subclass_schema(Foo()))\n\n\ndef test_custom_repr():\n    v = SchemaValidator(core_schema.is_subclass_schema(Foo, cls_repr='Spam'))\n    assert v.validate_python(Foo) == Foo\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python(Bar)\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'is_subclass_of',\n            'loc': (),\n            'msg': 'Input should be a subclass of Spam',\n            'input': Bar,\n            'ctx': {'class': 'Spam'},\n        }\n    ]\n", "tests/validators/test_frozenset.py": "import re\nfrom collections import deque\nfrom typing import Any, Dict\n\nimport pytest\n\nfrom pydantic_core import SchemaValidator, ValidationError\n\nfrom ..conftest import Err, PyAndJson, infinite_generator, plain_repr\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [([], frozenset()), ([1, 2, 3], {1, 2, 3}), ([1, 2, '3'], {1, 2, 3}), ([1, 2, 3, 2, 3], {1, 2, 3})],\n)\ndef test_frozenset_ints_both(py_and_json: PyAndJson, input_value, expected):\n    v = py_and_json({'type': 'frozenset', 'items_schema': {'type': 'int'}})\n    output = v.validate_test(input_value)\n    assert output == expected\n    assert isinstance(output, frozenset)\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [([], frozenset()), ([1, '2', b'3'], {1, '2', b'3'}), (frozenset([1, '2', b'3']), {1, '2', b'3'})],\n)\ndef test_frozenset_any(input_value, expected):\n    v = SchemaValidator({'type': 'frozenset'})\n    output = v.validate_python(input_value)\n    assert output == expected\n    assert isinstance(output, frozenset)\n\n\ndef test_no_copy():\n    v = SchemaValidator({'type': 'frozenset'})\n    input_value = frozenset([1, 2, 3])\n    output = v.validate_python(input_value)\n    assert output == input_value\n    assert output is not input_value\n    assert id(output) != id(input_value)\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ([1, 2.5, '3'], {1, 2.5, '3'}),\n        ('foo', Err(\"[type=frozen_set_type, input_value='foo', input_type=str]\")),\n        (1, Err('[type=frozen_set_type, input_value=1, input_type=int]')),\n        (1.0, Err('[type=frozen_set_type, input_value=1.0, input_type=float]')),\n        (False, Err('[type=frozen_set_type, input_value=False, input_type=bool]')),\n    ],\n)\ndef test_frozenset_no_validators_both(py_and_json: PyAndJson, input_value, expected):\n    v = py_and_json({'type': 'frozenset'})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_test(input_value)\n    else:\n        output = v.validate_test(input_value)\n        assert output == expected\n        assert isinstance(output, frozenset)\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ({1, 2, 3}, frozenset({1, 2, 3})),\n        (frozenset(), frozenset()),\n        ([1, 2, 3, 2, 3], frozenset({1, 2, 3})),\n        ([], frozenset()),\n        ((1, 2, 3, 2, 3), frozenset({1, 2, 3})),\n        (deque((1, 2, '3')), frozenset({1, 2, 3})),\n        ((), frozenset()),\n        (frozenset([1, 2, 3, 2, 3]), frozenset({1, 2, 3})),\n        ({1: 10, 2: 20, '3': '30'}.keys(), frozenset({1, 2, 3})),\n        ({1: 10, 2: 20, '3': '30'}.values(), frozenset({10, 20, 30})),\n        ({1: 10, 2: 20, '3': '30'}, Err('Input should be a valid frozenset [type=frozen_set_type,')),\n        ((x for x in [1, 2, '3']), frozenset({1, 2, 3})),\n        ({'abc'}, Err('0\\n  Input should be a valid integer')),\n        ({1, 2, 'wrong'}, Err('Input should be a valid integer')),\n        ({1: 2}, Err('1 validation error for frozenset[int]\\n  Input should be a valid frozenset')),\n        ('abc', Err('Input should be a valid frozenset')),\n    ],\n)\ndef test_frozenset_ints_python(input_value, expected):\n    v = SchemaValidator({'type': 'frozenset', 'items_schema': {'type': 'int'}})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_python(input_value)\n    else:\n        output = v.validate_python(input_value)\n        assert output == expected\n        assert isinstance(output, frozenset)\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [(frozenset([1, 2.5, '3']), {1, 2.5, '3'}), ([1, 2.5, '3'], {1, 2.5, '3'}), ([(1, 2), (3, 4)], {(1, 2), (3, 4)})],\n)\ndef test_frozenset_no_validators_python(input_value, expected):\n    v = SchemaValidator({'type': 'frozenset'})\n    output = v.validate_python(input_value)\n    assert output == expected\n    assert isinstance(output, frozenset)\n\n\ndef test_frozenset_multiple_errors():\n    v = SchemaValidator({'type': 'frozenset', 'items_schema': {'type': 'int'}})\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python(['a', (1, 2), []])\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'int_parsing',\n            'loc': (0,),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'a',\n        },\n        {'type': 'int_type', 'loc': (1,), 'msg': 'Input should be a valid integer', 'input': (1, 2)},\n        {'type': 'int_type', 'loc': (2,), 'msg': 'Input should be a valid integer', 'input': []},\n    ]\n\n\ndef generate_repeats():\n    for i in 1, 2, 3:\n        yield i\n        yield i\n\n\n@pytest.mark.parametrize(\n    'kwargs,input_value,expected',\n    [\n        ({'strict': True}, frozenset(), frozenset()),\n        ({'strict': True}, frozenset([1, 2, 3]), {1, 2, 3}),\n        ({'strict': True}, {1, 2, 3}, Err('Input should be a valid frozenset')),\n        ({'strict': True}, [1, 2, 3, 2, 3], Err('Input should be a valid frozenset [type=frozen_set_type,')),\n        ({'strict': True}, [], Err('Input should be a valid frozenset [type=frozen_set_type,')),\n        ({'strict': True}, (), Err('Input should be a valid frozenset [type=frozen_set_type,')),\n        ({'strict': True}, (1, 2, 3), Err('Input should be a valid frozenset [type=frozen_set_type,')),\n        ({'strict': True}, {1, 2, 3}, Err('Input should be a valid frozenset [type=frozen_set_type,')),\n        ({'strict': True}, 'abc', Err('Input should be a valid frozenset [type=frozen_set_type,')),\n        ({'min_length': 3}, {1, 2, 3}, {1, 2, 3}),\n        (\n            {'min_length': 3},\n            {1, 2},\n            Err('Frozenset should have at least 3 items after validation, not 2 [type=too_short,'),\n        ),\n        ({'max_length': 3}, {1, 2, 3}, {1, 2, 3}),\n        (\n            {'max_length': 3},\n            {1, 2, 3, 4},\n            Err('Frozenset should have at most 3 items after validation, not more [type=too_long,'),\n        ),\n        (\n            {'items_schema': {'type': 'int'}, 'max_length': 3},\n            {1, 2, 3, 4},\n            Err('Frozenset should have at most 3 items after validation, not more [type=too_long,'),\n        ),\n        # length check after set creation\n        ({'max_length': 3}, [1, 1, 2, 2, 3, 3], {1, 2, 3}),\n        ({'max_length': 3}, generate_repeats(), {1, 2, 3}),\n        (\n            {'max_length': 3},\n            infinite_generator(),\n            Err('Frozenset should have at most 3 items after validation, not more [type=too_long,'),\n        ),\n    ],\n)\ndef test_frozenset_kwargs_python(kwargs: Dict[str, Any], input_value, expected):\n    v = SchemaValidator({'type': 'frozenset', **kwargs})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_python(input_value)\n    else:\n        output = v.validate_python(input_value)\n        assert output == expected\n        assert isinstance(output, frozenset)\n\n\n@pytest.mark.parametrize('input_value,expected', [({1, 2, 3}, {1, 2, 3}), ([1, 2, 3], [1, 2, 3])])\ndef test_union_frozenset_list(input_value, expected):\n    v = SchemaValidator({'type': 'union', 'choices': [{'type': 'frozenset'}, {'type': 'list'}]})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_python(input_value)\n    else:\n        v.validate_python(input_value)\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ({1, 2, 3}, {1, 2, 3}),\n        ({'a', 'b', 'c'}, {'a', 'b', 'c'}),\n        (\n            [1, 'a'],\n            Err(\n                '2 validation errors for union',\n                errors=[\n                    {\n                        'type': 'int_type',\n                        'loc': ('frozenset[int]', 1),\n                        'msg': 'Input should be a valid integer',\n                        'input': 'a',\n                    },\n                    # second because validation on the string choice comes second\n                    {\n                        'type': 'string_type',\n                        'loc': ('frozenset[str]', 0),\n                        'msg': 'Input should be a valid string',\n                        'input': 1,\n                    },\n                ],\n            ),\n        ),\n    ],\n)\ndef test_union_frozenset_int_frozenset_str(input_value, expected):\n    v = SchemaValidator(\n        {\n            'type': 'union',\n            'choices': [\n                {'type': 'frozenset', 'items_schema': {'type': 'int', 'strict': True}},\n                {'type': 'frozenset', 'items_schema': {'type': 'str', 'strict': True}},\n            ],\n        }\n    )\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)) as exc_info:\n            v.validate_python(input_value)\n        if expected.errors is not None:\n            assert exc_info.value.errors(include_url=False) == expected.errors\n    else:\n        output = v.validate_python(input_value)\n        assert output == expected\n        assert isinstance(output, frozenset)\n\n\ndef test_frozenset_as_dict_keys(py_and_json: PyAndJson):\n    v = py_and_json({'type': 'dict', 'keys_schema': {'type': 'frozenset'}, 'values_schema': {'type': 'int'}})\n    with pytest.raises(ValidationError, match=re.escape(\"[type=int_parsing, input_value='bar', input_type=str]\")):\n        v.validate_test({'foo': 'bar'})\n\n\ndef test_repr():\n    v = SchemaValidator({'type': 'frozenset', 'strict': True, 'min_length': 42})\n    assert plain_repr(v) == (\n        'SchemaValidator('\n        'title=\"frozenset[any]\",'\n        'validator=FrozenSet(FrozenSetValidator{'\n        'strict:true,item_validator:Any(AnyValidator),min_length:Some(42),max_length:None,'\n        'name:\"frozenset[any]\",'\n        'fail_fast:false'\n        '}),'\n        'definitions=[],'\n        'cache_strings=True)'\n    )\n\n\ndef test_generator_error():\n    def gen(error: bool):\n        yield 1\n        yield 2\n        if error:\n            raise RuntimeError('my error')\n        yield 3\n\n    v = SchemaValidator({'type': 'frozenset', 'items_schema': {'type': 'int'}})\n    r = v.validate_python(gen(False))\n    assert r == {1, 2, 3}\n    assert isinstance(r, frozenset)\n\n    msg = r'Error iterating over object, error: RuntimeError: my error \\[type=iteration_error,'\n    with pytest.raises(ValidationError, match=msg):\n        v.validate_python(gen(True))\n\n\n@pytest.mark.parametrize(\n    'input_value,items_schema,expected',\n    [\n        pytest.param(\n            {1: 10, 2: 20, '3': '30'}.items(),\n            {'type': 'tuple', 'items_schema': [{'type': 'any'}], 'variadic_item_index': 0},\n            frozenset(((1, 10), (2, 20), ('3', '30'))),\n            id='Tuple[Any, Any]',\n        ),\n        pytest.param(\n            {1: 10, 2: 20, '3': '30'}.items(),\n            {'type': 'tuple', 'items_schema': [{'type': 'int'}], 'variadic_item_index': 0},\n            frozenset(((1, 10), (2, 20), (3, 30))),\n            id='Tuple[int, int]',\n        ),\n        pytest.param({1: 10, 2: 20, '3': '30'}.items(), {'type': 'any'}, {(1, 10), (2, 20), ('3', '30')}, id='Any'),\n    ],\n)\ndef test_frozenset_from_dict_items(input_value, items_schema, expected):\n    v = SchemaValidator({'type': 'frozenset', 'items_schema': items_schema})\n    output = v.validate_python(input_value)\n    assert isinstance(output, frozenset)\n    assert output == expected\n\n\n@pytest.mark.parametrize(\n    'fail_fast,expected',\n    [\n        pytest.param(\n            True,\n            [\n                {\n                    'type': 'int_parsing',\n                    'loc': (1,),\n                    'msg': 'Input should be a valid integer, unable to parse string as an integer',\n                    'input': 'not-num',\n                },\n            ],\n            id='fail_fast',\n        ),\n        pytest.param(\n            False,\n            [\n                {\n                    'type': 'int_parsing',\n                    'loc': (1,),\n                    'msg': 'Input should be a valid integer, unable to parse string as an integer',\n                    'input': 'not-num',\n                },\n                {\n                    'type': 'int_parsing',\n                    'loc': (2,),\n                    'msg': 'Input should be a valid integer, unable to parse string as an integer',\n                    'input': 'again',\n                },\n            ],\n            id='not_fail_fast',\n        ),\n    ],\n)\ndef test_frozenset_fail_fast(fail_fast, expected):\n    v = SchemaValidator({'type': 'frozenset', 'items_schema': {'type': 'int'}, 'fail_fast': fail_fast})\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python([1, 'not-num', 'again'])\n\n    assert exc_info.value.errors(include_url=False) == expected\n", "tests/validators/test_chain.py": "from decimal import Decimal\n\nimport pytest\n\nfrom pydantic_core import SchemaError, SchemaValidator, ValidationError, core_schema\n\nfrom ..conftest import PyAndJson\n\n\ndef test_chain():\n    validator = SchemaValidator(\n        {\n            'type': 'chain',\n            'steps': [{'type': 'str'}, core_schema.with_info_plain_validator_function(lambda v, info: Decimal(v))],\n        }\n    )\n\n    assert validator.validate_python('1.44') == Decimal('1.44')\n    assert validator.validate_python(b'1.44') == Decimal('1.44')\n\n\ndef test_chain_many():\n    validator = SchemaValidator(\n        {\n            'type': 'chain',\n            'steps': [\n                core_schema.with_info_plain_validator_function(lambda v, info: f'{v}-1'),\n                core_schema.with_info_plain_validator_function(lambda v, info: f'{v}-2'),\n                core_schema.with_info_plain_validator_function(lambda v, info: f'{v}-3'),\n                core_schema.with_info_plain_validator_function(lambda v, info: f'{v}-4'),\n            ],\n        }\n    )\n\n    assert validator.validate_python('input') == 'input-1-2-3-4'\n\n\ndef test_chain_error():\n    validator = SchemaValidator({'type': 'chain', 'steps': [{'type': 'str'}, {'type': 'int'}]})\n\n    assert validator.validate_python('123') == 123\n    assert validator.validate_python(b'123') == 123\n\n    with pytest.raises(ValidationError) as exc_info:\n        validator.validate_python('abc')\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'int_parsing',\n            'loc': (),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'abc',\n        }\n    ]\n\n\n@pytest.mark.parametrize(\n    'input_value,expected', [('1.44', Decimal('1.44')), (1, Decimal(1)), (1.44, pytest.approx(1.44))]\n)\ndef test_json(py_and_json: PyAndJson, input_value, expected):\n    validator = py_and_json(\n        {\n            'type': 'chain',\n            'steps': [\n                {'type': 'union', 'choices': [{'type': 'str'}, {'type': 'float'}]},\n                core_schema.with_info_plain_validator_function(lambda v, info: Decimal(v)),\n            ],\n        }\n    )\n    output = validator.validate_test(input_value)\n    assert output == expected\n    assert isinstance(output, Decimal)\n\n\ndef test_flatten():\n    validator = SchemaValidator(\n        {\n            'type': 'chain',\n            'steps': [\n                core_schema.with_info_plain_validator_function(lambda v, info: f'{v}-1'),\n                {\n                    'type': 'chain',\n                    'steps': [\n                        {\n                            'type': 'function-plain',\n                            'function': {'type': 'with-info', 'function': lambda v, info: f'{v}-2'},\n                        },\n                        {\n                            'type': 'function-plain',\n                            'function': {'type': 'with-info', 'function': lambda v, info: f'{v}-3'},\n                        },\n                    ],\n                },\n            ],\n        }\n    )\n\n    assert validator.validate_python('input') == 'input-1-2-3'\n    assert validator.title == 'chain[function-plain[<lambda>()],function-plain[<lambda>()],function-plain[<lambda>()]]'\n\n\ndef test_chain_empty():\n    with pytest.raises(SchemaError, match='One or more steps are required for a chain validator'):\n        SchemaValidator({'type': 'chain', 'steps': []})\n\n\ndef test_chain_one():\n    validator = SchemaValidator(\n        {'type': 'chain', 'steps': [core_schema.with_info_plain_validator_function(lambda v, info: f'{v}-1')]}\n    )\n    assert validator.validate_python('input') == 'input-1'\n    assert validator.title == 'function-plain[<lambda>()]'\n", "tests/validators/test_is_instance.py": "import typing\n\nimport pytest\n\nfrom pydantic_core import SchemaError, SchemaValidator, ValidationError, core_schema\n\n\nclass Foo:\n    pass\n\n\nclass Bar(Foo):\n    pass\n\n\nclass Spam:\n    pass\n\n\ndef test_validate_json() -> None:\n    v = SchemaValidator({'type': 'is-instance', 'cls': Foo})\n    with pytest.raises(NotImplementedError, match='use a JsonOrPython validator instead'):\n        v.validate_json('\"foo\"')\n\n\ndef test_is_instance():\n    v = SchemaValidator({'type': 'is-instance', 'cls': Foo})\n    foo = Foo()\n    assert v.validate_python(foo) == foo\n    assert v.isinstance_python(foo) is True\n    bar = Bar()\n    assert v.validate_python(bar) == bar\n    s = Spam()\n    assert v.isinstance_python(s) is False\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python(s)\n\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'is_instance_of',\n            'loc': (),\n            'msg': 'Input should be an instance of Foo',\n            'input': s,\n            'ctx': {'class': 'Foo'},\n        }\n    ]\n    with pytest.raises(ValidationError, match='type=is_instance_of'):\n        v.validate_python(Foo)\n\n\n@pytest.mark.parametrize(\n    'schema_class,input_val,value',\n    [\n        (Foo, Foo(), True),\n        (Foo, Foo, False),\n        (Foo, Bar(), True),\n        (Foo, Bar, False),\n        (Bar, Foo(), False),\n        (Bar, Foo, False),\n        (dict, {1: 2}, True),\n        (dict, {1, 2}, False),\n        (type, Foo, True),\n        (type, Foo(), False),\n    ],\n)\ndef test_is_instance_cases(schema_class, input_val, value):\n    v = SchemaValidator({'type': 'is-instance', 'cls': schema_class})\n    assert v.isinstance_python(input_val) == value\n\n\n@pytest.mark.parametrize('input_cls', [123, 'foo', Foo(), [], {1: 2}])\ndef test_is_instance_invalid(input_cls):\n    with pytest.raises(SchemaError, match=\"SchemaError: 'cls' must be valid as the first argument to 'isinstance'\"):\n        SchemaValidator({'type': 'is-instance', 'cls': input_cls})\n\n\nclass HasIsInstanceMeta(type):\n    def __instancecheck__(self, instance) -> bool:\n        if 'error' in repr(instance):\n            # an error here comes from a problem in the schema, not in the input value, so raise as internal error\n            raise TypeError('intentional error')\n        return 'true' in repr(instance)\n\n\nclass HasIsInstance(metaclass=HasIsInstanceMeta):\n    pass\n\n\ndef test_instancecheck():\n    v = SchemaValidator({'type': 'is-instance', 'cls': HasIsInstance})\n    assert v.validate_python('true') == 'true'\n\n    with pytest.raises(ValidationError, match='type=is_instance_of'):\n        v.validate_python('other')\n\n    with pytest.raises(TypeError, match='intentional error'):\n        v.validate_python('error')\n\n\ndef test_repr():\n    v = SchemaValidator({'type': 'union', 'choices': [{'type': 'int'}, {'type': 'is-instance', 'cls': Foo}]})\n    assert v.isinstance_python(4) is True\n    assert v.isinstance_python(Bar()) is True\n    assert v.isinstance_python('foo') is False\n\n    with pytest.raises(ValidationError, match=r'is-instance\\[Foo\\]\\s+Input should be an instance of Foo'):\n        v.validate_python('foo')\n\n\n@pytest.mark.parametrize(\n    'input_val,value',\n    [\n        (Foo, True),\n        (Foo(), False),\n        (str, True),\n        ('foo', False),\n        (int, True),\n        (1, False),\n        (type, True),\n        (type('Foobar', (), {'x': 1}), True),\n    ],\n)\ndef test_is_type(input_val, value):\n    v = SchemaValidator({'type': 'is-instance', 'cls': type})\n    assert v.isinstance_python(input_val) == value\n\n\ndef test_is_instance_dict():\n    v = SchemaValidator(\n        core_schema.dict_schema(\n            keys_schema=core_schema.is_instance_schema(str), values_schema=core_schema.is_instance_schema(int)\n        )\n    )\n    assert v.isinstance_python({'foo': 1}) is True\n    assert v.isinstance_python({1: 1}) is False\n\n\ndef test_is_instance_dict_not_str():\n    v = SchemaValidator(core_schema.dict_schema(keys_schema=core_schema.is_instance_schema(int)))\n    assert v.isinstance_python({1: 1}) is True\n    assert v.isinstance_python({'foo': 1}) is False\n\n\ndef test_is_instance_sequence():\n    v = SchemaValidator(core_schema.is_instance_schema(typing.Sequence))\n    assert v.isinstance_python(1) is False\n    assert v.isinstance_python([1]) is True\n\n    with pytest.raises(ValidationError, match=r'Input should be an instance of typing.Sequence \\[type=is_instance_of,'):\n        v.validate_python(1)\n\n\ndef test_is_instance_tuple():\n    v = SchemaValidator(core_schema.is_instance_schema((int, str)))\n    assert v.isinstance_python(1) is True\n    assert v.isinstance_python('foobar') is True\n    assert v.isinstance_python([1]) is False\n    with pytest.raises(ValidationError, match=r\"Input should be an instance of \\(<class 'int'>, <class 'str'>\\)\"):\n        v.validate_python([1])\n\n\ndef test_class_repr():\n    v = SchemaValidator(core_schema.is_instance_schema(int, cls_repr='Foobar'))\n    assert v.validate_python(1) == 1\n    with pytest.raises(ValidationError, match=r'Input should be an instance of Foobar \\[type=is_instance_of,'):\n        v.validate_python('1')\n\n\ndef test_is_instance_json_type_before_validator():\n    # See https://github.com/pydantic/pydantic/issues/6573 - when using a\n    # \"before\" validator to coerce JSON to valid Python input it should be\n    # possible to use isinstance validation. This gives a way for things\n    # such as type to have a valid input from JSON.\n\n    schema = core_schema.is_instance_schema(type)\n    v = SchemaValidator(schema)\n\n    with pytest.raises(\n        NotImplementedError,\n        match='Cannot check isinstance when validating from json, use a JsonOrPython validator instead.',\n    ):\n        v.validate_json('null')\n\n    # now wrap in a before validator\n    def set_type_to_int(input: None) -> type:\n        return int\n\n    schema = core_schema.no_info_before_validator_function(set_type_to_int, schema)\n    v = SchemaValidator(schema)\n\n    assert v.validate_json('null') == int\n", "tests/validators/test_decimal.py": "from __future__ import annotations\n\nimport json\nimport math\nimport re\nfrom decimal import Decimal\nfrom typing import Any\n\nimport pytest\nfrom dirty_equals import FunctionCheck, IsStr\n\nfrom pydantic_core import SchemaValidator, ValidationError\n\nfrom ..conftest import Err, PyAndJson, plain_repr\n\n\nclass DecimalSubclass(Decimal):\n    pass\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        (0, Decimal(0)),\n        (1, Decimal(1)),\n        (42, Decimal(42)),\n        ('42', Decimal(42)),\n        ('42.123', Decimal('42.123')),\n        (42.0, Decimal(42)),\n        (42.5, Decimal('42.5')),\n        (1e10, Decimal('1E10')),\n        (Decimal('42.0'), Decimal(42)),\n        (Decimal('42.5'), Decimal('42.5')),\n        (Decimal('1e10'), Decimal('1E10')),\n        (\n            Decimal('123456789123456789123456789.123456789123456789123456789'),\n            Decimal('123456789123456789123456789.123456789123456789123456789'),\n        ),\n        (DecimalSubclass('42.0'), Decimal(42)),\n        (DecimalSubclass('42.5'), Decimal('42.5')),\n        (DecimalSubclass('1e10'), Decimal('1E10')),\n        (\n            True,\n            Err(\n                'Decimal input should be an integer, float, string or Decimal object [type=decimal_type, input_value=True, input_type=bool]'\n            ),\n        ),\n        (\n            False,\n            Err(\n                'Decimal input should be an integer, float, string or Decimal object [type=decimal_type, input_value=False, input_type=bool]'\n            ),\n        ),\n        ('wrong', Err('Input should be a valid decimal [type=decimal_parsing')),\n        (\n            [1, 2],\n            Err(\n                'Decimal input should be an integer, float, string or Decimal object [type=decimal_type, input_value=[1, 2], input_type=list]'\n            ),\n        ),\n    ],\n)\ndef test_decimal(py_and_json: PyAndJson, input_value, expected):\n    v = py_and_json({'type': 'decimal'})\n    # Decimal types are not JSON serializable\n    if v.validator_type == 'json' and isinstance(input_value, Decimal):\n        input_value = str(input_value)\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_test(input_value)\n    else:\n        output = v.validate_test(input_value)\n        assert output == expected\n        assert isinstance(output, Decimal)\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        (Decimal(0), Decimal(0)),\n        (Decimal(1), Decimal(1)),\n        (Decimal(42), Decimal(42)),\n        (Decimal('42.0'), Decimal('42.0')),\n        (Decimal('42.5'), Decimal('42.5')),\n        (42.0, Err('Input should be an instance of Decimal [type=is_instance_of, input_value=42.0, input_type=float]')),\n        ('42', Err(\"Input should be an instance of Decimal [type=is_instance_of, input_value='42', input_type=str]\")),\n        (42, Err('Input should be an instance of Decimal [type=is_instance_of, input_value=42, input_type=int]')),\n        (True, Err('Input should be an instance of Decimal [type=is_instance_of, input_value=True, input_type=bool]')),\n    ],\n    ids=repr,\n)\ndef test_decimal_strict_py(input_value, expected):\n    v = SchemaValidator({'type': 'decimal', 'strict': True})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_python(input_value)\n    else:\n        output = v.validate_python(input_value)\n        assert output == expected\n        assert isinstance(output, Decimal)\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        (0, Decimal(0)),\n        (1, Decimal(1)),\n        (42, Decimal(42)),\n        ('42.0', Decimal('42.0')),\n        ('42.5', Decimal('42.5')),\n        (42.0, Decimal('42.0')),\n        ('42', Decimal('42')),\n        (\n            True,\n            Err(\n                'Decimal input should be an integer, float, string or Decimal object [type=decimal_type, input_value=True, input_type=bool]'\n            ),\n        ),\n    ],\n    ids=repr,\n)\ndef test_decimal_strict_json(input_value, expected):\n    v = SchemaValidator({'type': 'decimal', 'strict': True})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_json(json.dumps(input_value))\n    else:\n        output = v.validate_json(json.dumps(input_value))\n        assert output == expected\n        assert isinstance(output, Decimal)\n\n\n@pytest.mark.parametrize(\n    'kwargs,input_value,expected',\n    [\n        ({}, 0, Decimal(0)),\n        ({}, '123.456', Decimal('123.456')),\n        ({'ge': 0}, 0, Decimal(0)),\n        (\n            {'ge': 0},\n            -0.1,\n            Err(\n                'Input should be greater than or equal to 0 '\n                '[type=greater_than_equal, input_value=-0.1, input_type=float]'\n            ),\n        ),\n        ({'gt': 0}, 0.1, Decimal('0.1')),\n        ({'gt': 0}, 0, Err('Input should be greater than 0 [type=greater_than, input_value=0, input_type=int]')),\n        ({'le': 0}, 0, Decimal(0)),\n        ({'le': 0}, -1, Decimal(-1)),\n        ({'le': 0}, 0.1, Err('Input should be less than or equal to 0')),\n        ({'lt': 0, 'allow_inf_nan': True}, float('nan'), Err('Input should be less than 0')),\n        ({'gt': 0, 'allow_inf_nan': True}, float('inf'), Decimal('inf')),\n        ({'allow_inf_nan': True}, float('-inf'), Decimal('-inf')),\n        ({'allow_inf_nan': True}, float('nan'), FunctionCheck(math.isnan)),\n        ({'lt': 0}, 0, Err('Input should be less than 0')),\n        ({'lt': 0.123456}, 1, Err('Input should be less than 0.123456')),\n    ],\n)\ndef test_decimal_kwargs(py_and_json: PyAndJson, kwargs: dict[str, Any], input_value, expected):\n    v = py_and_json({'type': 'decimal', **kwargs})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_test(input_value)\n    else:\n        output = v.validate_test(input_value)\n        assert output == expected\n        assert isinstance(output, Decimal)\n\n\n@pytest.mark.parametrize(\n    'multiple_of,input_value,error',\n    [\n        (0.5, 0.5, None),\n        (0.5, 1, None),\n        (0.5, 0.6, Err('Input should be a multiple of 0.5')),\n        (0.5, 0.51, Err('Input should be a multiple of 0.5')),\n        (0.5, 0.501, Err('Input should be a multiple of 0.5')),\n        (0.5, 1_000_000.5, None),\n        (0.5, 1_000_000.49, Err('Input should be a multiple of 0.5')),\n        (0.1, 0, None),\n        (0.1, 0.0, None),\n        (0.1, 0.2, None),\n        (0.1, 0.3, None),\n        (0.1, 0.4, None),\n        (0.1, 0.5, None),\n        (0.1, 0.5001, Err('Input should be a multiple of 0.1')),\n        (0.1, 1, None),\n        (0.1, 1.0, None),\n        (0.1, int(5e10), None),\n        (2.0, -2.0, None),\n    ],\n    ids=repr,\n)\ndef test_decimal_multiple_of(py_and_json: PyAndJson, multiple_of: float, input_value: float, error: Err | None):\n    v = py_and_json({'type': 'decimal', 'multiple_of': Decimal(str(multiple_of))})\n    if error:\n        with pytest.raises(ValidationError, match=re.escape(error.message)):\n            v.validate_test(input_value)\n    else:\n        output = v.validate_test(input_value)\n        assert output == Decimal(str(input_value))\n        assert isinstance(output, Decimal)\n\n\ndef test_union_decimal_py():\n    v = SchemaValidator(\n        {'type': 'union', 'choices': [{'type': 'decimal', 'strict': True}, {'type': 'decimal', 'multiple_of': 7}]}\n    )\n    assert v.validate_python('14') == 14\n    assert v.validate_python(Decimal(5)) == 5\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python('5')\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'is_instance_of',\n            'loc': ('decimal',),\n            'msg': 'Input should be an instance of Decimal',\n            'input': '5',\n            'ctx': {'class': 'Decimal'},\n        },\n        {\n            'type': 'multiple_of',\n            'loc': ('decimal',),\n            'msg': 'Input should be a multiple of 7',\n            'input': '5',\n            'ctx': {'multiple_of': 7},\n        },\n    ]\n\n\ndef test_union_decimal_json():\n    v = SchemaValidator(\n        {'type': 'union', 'choices': [{'type': 'decimal', 'strict': True}, {'type': 'decimal', 'multiple_of': 7}]}\n    )\n    assert v.validate_json(json.dumps('14')) == 14\n    assert v.validate_json(json.dumps('5')) == 5\n\n\ndef test_union_decimal_simple(py_and_json: PyAndJson):\n    v = py_and_json({'type': 'union', 'choices': [{'type': 'decimal'}, {'type': 'list'}]})\n    assert v.validate_test('5') == 5\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_test('xxx')\n\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'decimal_parsing', 'loc': ('decimal',), 'msg': 'Input should be a valid decimal', 'input': 'xxx'},\n        {\n            'type': 'list_type',\n            'loc': ('list[any]',),\n            'msg': IsStr(regex='Input should be a valid (list|array)'),\n            'input': 'xxx',\n        },\n    ]\n\n\ndef test_decimal_repr():\n    v = SchemaValidator({'type': 'decimal'})\n    assert plain_repr(v).startswith(\n        'SchemaValidator(title=\"decimal\",validator=Decimal(DecimalValidator{strict:false,allow_inf_nan:false'\n    )\n    v = SchemaValidator({'type': 'decimal', 'strict': True})\n    assert plain_repr(v).startswith(\n        'SchemaValidator(title=\"decimal\",validator=Decimal(DecimalValidator{strict:true,allow_inf_nan:false'\n    )\n    v = SchemaValidator({'type': 'decimal', 'multiple_of': 7})\n    assert plain_repr(v).startswith('SchemaValidator(title=\"decimal\",validator=Decimal(')\n\n\n@pytest.mark.parametrize('input_value,expected', [(Decimal('1.23'), Decimal('1.23')), (Decimal('1'), Decimal('1.0'))])\ndef test_decimal_not_json(input_value, expected):\n    v = SchemaValidator({'type': 'decimal'})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_python(input_value)\n    else:\n        output = v.validate_python(input_value)\n        assert output == expected\n        assert isinstance(output, Decimal)\n\n\ndef test_decimal_nan(py_and_json: PyAndJson):\n    v = py_and_json({'type': 'decimal', 'allow_inf_nan': True})\n    assert v.validate_test('inf') == Decimal('inf')\n    assert v.validate_test('-inf') == Decimal('-inf')\n    r = v.validate_test('nan')\n    assert math.isnan(r)\n\n\ndef test_decimal_key(py_and_json: PyAndJson):\n    v = py_and_json({'type': 'dict', 'keys_schema': {'type': 'decimal'}, 'values_schema': {'type': 'int'}})\n    assert v.validate_test({'1': 1, '2': 2}) == {Decimal('1'): 1, Decimal('2'): 2}\n    assert v.validate_test({'1.5': 1, '2.4': 2}) == {Decimal('1.5'): 1, Decimal('2.4'): 2}\n    if v.validator_type == 'python':\n        with pytest.raises(ValidationError, match='Input should be an instance of Decimal'):\n            v.validate_test({'1.5': 1, '2.5': 2}, strict=True)\n    else:\n        assert v.validate_test({'1.5': 1, '2.4': 2}, strict=True) == {Decimal('1.5'): 1, Decimal('2.4'): 2}\n\n\n@pytest.mark.parametrize(\n    'input_value,allow_inf_nan,expected',\n    [\n        ('NaN', True, FunctionCheck(math.isnan)),\n        ('NaN', False, Err(\"Input should be a finite number [type=finite_number, input_value='NaN', input_type=str]\")),\n        ('+inf', True, FunctionCheck(lambda x: math.isinf(x) and x > 0)),\n        (\n            '+inf',\n            False,\n            Err(\"Input should be a finite number [type=finite_number, input_value='+inf', input_type=str]\"),\n        ),\n        ('+infinity', True, FunctionCheck(lambda x: math.isinf(x) and x > 0)),\n        (\n            '+infinity',\n            False,\n            Err(\"Input should be a finite number [type=finite_number, input_value='+infinity', input_type=str]\"),\n        ),\n        ('-inf', True, FunctionCheck(lambda x: math.isinf(x) and x < 0)),\n        (\n            '-inf',\n            False,\n            Err(\"Input should be a finite number [type=finite_number, input_value='-inf', input_type=str]\"),\n        ),\n        ('-infinity', True, FunctionCheck(lambda x: math.isinf(x) and x < 0)),\n        (\n            '-infinity',\n            False,\n            Err(\"Input should be a finite number [type=finite_number, input_value='-infinity', input_type=str]\"),\n        ),\n        ('0.7', True, Decimal('0.7')),\n        ('0.7', False, Decimal('0.7')),\n        (\n            'pika',\n            True,\n            Err(\"Input should be a valid decimal [type=decimal_parsing, input_value='pika', input_type=str]\"),\n        ),\n        (\n            'pika',\n            False,\n            Err(\"Input should be a valid decimal [type=decimal_parsing, input_value='pika', input_type=str]\"),\n        ),\n    ],\n)\ndef test_non_finite_json_values(py_and_json: PyAndJson, input_value, allow_inf_nan, expected):\n    v = py_and_json({'type': 'decimal', 'allow_inf_nan': allow_inf_nan})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_test(input_value)\n    else:\n        assert v.validate_test(input_value) == expected\n\n\n@pytest.mark.parametrize('strict', (True, False))\n@pytest.mark.parametrize(\n    'input_value,allow_inf_nan,expected',\n    [\n        (Decimal('nan'), True, FunctionCheck(math.isnan)),\n        (\n            Decimal('nan'),\n            False,\n            Err(\"Input should be a finite number [type=finite_number, input_value=Decimal('NaN'), input_type=Decimal]\"),\n        ),\n    ],\n)\ndef test_non_finite_decimal_values(strict, input_value, allow_inf_nan, expected):\n    v = SchemaValidator({'type': 'decimal', 'allow_inf_nan': allow_inf_nan, 'strict': strict})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_python(input_value)\n    else:\n        assert v.validate_python(input_value) == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,allow_inf_nan,expected',\n    [\n        (Decimal('+inf'), True, FunctionCheck(lambda x: math.isinf(x) and x > 0)),\n        (\n            Decimal('+inf'),\n            False,\n            Err(\n                \"Input should be a finite number [type=finite_number, input_value=Decimal('Infinity'), input_type=Decimal]\"\n            ),\n        ),\n        (\n            Decimal('-inf'),\n            True,\n            Err(\n                \"Input should be greater than 0 [type=greater_than, input_value=Decimal('-Infinity'), input_type=Decimal]\"\n            ),\n        ),\n        (\n            Decimal('-inf'),\n            False,\n            Err(\n                \"Input should be a finite number [type=finite_number, input_value=Decimal('-Infinity'), input_type=Decimal]\"\n            ),\n        ),\n    ],\n)\ndef test_non_finite_constrained_decimal_values(input_value, allow_inf_nan, expected):\n    v = SchemaValidator({'type': 'decimal', 'allow_inf_nan': allow_inf_nan, 'gt': 0})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_python(input_value)\n    else:\n        assert v.validate_python(input_value) == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        # lower e, minus\n        ('1.0e-12', Decimal('1e-12')),\n        ('1e-12', Decimal('1e-12')),\n        ('12e-1', Decimal('12e-1')),\n        # upper E, minus\n        ('1.0E-12', Decimal('1e-12')),\n        ('1E-12', Decimal('1e-12')),\n        ('12E-1', Decimal('12e-1')),\n        # lower E, plus\n        ('1.0e+12', Decimal(' 1e12')),\n        ('1e+12', Decimal(' 1e12')),\n        ('12e+1', Decimal(' 12e1')),\n        # upper E, plus\n        ('1.0E+12', Decimal(' 1e12')),\n        ('1E+12', Decimal(' 1e12')),\n        ('12E+1', Decimal(' 12e1')),\n        # lower E, unsigned\n        ('1.0e12', Decimal(' 1e12')),\n        ('1e12', Decimal(' 1e12')),\n        ('12e1', Decimal(' 12e1')),\n        # upper E, unsigned\n        ('1.0E12', Decimal(' 1e12')),\n        ('1E12', Decimal(' 1e12')),\n        ('12E1', Decimal(' 12e1')),\n    ],\n)\ndef test_validate_scientific_notation_from_json(input_value, expected):\n    v = SchemaValidator({'type': 'decimal'})\n    assert v.validate_json(input_value) == expected\n\n\ndef test_validate_max_digits_and_decimal_places() -> None:\n    v = SchemaValidator({'type': 'decimal', 'max_digits': 5, 'decimal_places': 2})\n\n    # valid inputs\n    assert v.validate_json('1.23') == Decimal('1.23')\n    assert v.validate_json('123.45') == Decimal('123.45')\n    assert v.validate_json('-123.45') == Decimal('-123.45')\n\n    # invalid inputs\n    with pytest.raises(ValidationError):\n        v.validate_json('1234.56')  # too many digits\n    with pytest.raises(ValidationError):\n        v.validate_json('123.456')  # too many decimal places\n    with pytest.raises(ValidationError):\n        v.validate_json('123456')  # too many digits\n    with pytest.raises(ValidationError):\n        v.validate_json('abc')  # not a valid decimal\n\n\ndef test_validate_max_digits_and_decimal_places_edge_case() -> None:\n    v = SchemaValidator({'type': 'decimal', 'max_digits': 34, 'decimal_places': 18})\n\n    # valid inputs\n    assert v.validate_python(Decimal('9999999999999999.999999999999999999')) == Decimal(\n        '9999999999999999.999999999999999999'\n    )\n", "tests/validators/test_timedelta.py": "import re\nfrom datetime import timedelta\nfrom decimal import Decimal\nfrom typing import Any, Dict\n\nimport pytest\n\nfrom pydantic_core import SchemaError, SchemaValidator, ValidationError, validate_core_schema\n\nfrom ..conftest import Err, PyAndJson\n\ntry:\n    import pandas\nexcept ImportError:\n    pandas = None\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        (\n            timedelta(days=-3, hours=2, seconds=1, milliseconds=500),\n            timedelta(days=-3, hours=2, seconds=1, milliseconds=500),\n        ),\n        (\n            timedelta(days=3, weeks=2, hours=1, minutes=2, seconds=3, milliseconds=500),\n            timedelta(days=3, weeks=2, hours=1, minutes=2, seconds=3, milliseconds=500),\n        ),\n        ('P0Y0M3D2WT1H2M3.5S', timedelta(days=3, weeks=2, hours=1, minutes=2, seconds=3, milliseconds=500)),\n        (b'P0Y0M3D2WT1H2M3.5S', timedelta(days=3, weeks=2, hours=1, minutes=2, seconds=3, milliseconds=500)),\n        ((-1,), Err('Input should be a valid timedelta [type=time_delta_type')),\n        (\n            b'-1',\n            Err(\n                'Input should be a valid timedelta, \"day\" identifier in duration '\n                'not correctly formatted [type=time_delta_parsing'\n            ),\n        ),\n        (3601, timedelta(hours=1, seconds=1)),\n        (Decimal('3601.123456'), timedelta(hours=1, seconds=1, microseconds=123456)),\n        (Decimal('3601.1234562'), timedelta(hours=1, seconds=1, microseconds=123456)),\n        (Decimal('3601.1234568'), timedelta(hours=1, seconds=1, microseconds=123457)),\n        (-3601, timedelta(hours=-2, seconds=3599)),\n        (Decimal('-3601.222222'), timedelta(hours=-2, seconds=3598, microseconds=777778)),\n        (Decimal('-3601.2222222'), timedelta(hours=-2, seconds=3598, microseconds=777778)),\n        (Decimal('-3601.2222227'), timedelta(hours=-2, seconds=3598, microseconds=777777)),\n        (float('nan'), Err('Input should be a valid timedelta, NaN values not permitted')),\n        (float('inf'), Err('Input should be a valid timedelta, durations may not exceed 999,999,999 days')),\n        (float('-inf'), Err('Input should be a valid timedelta, durations may not exceed 999,999,999 days')),\n        (timedelta.max, timedelta.max),\n        ('02:03:04.05', timedelta(hours=2, seconds=184, microseconds=50_000)),\n        (\n            '02:03:04.05broken',\n            Err('Input should be a valid timedelta, unexpected extra characters at the end of the input'),\n        ),\n    ],\n    ids=repr,\n)\ndef test_timedelta(input_value, expected):\n    v = SchemaValidator({'type': 'timedelta'})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_python(input_value)\n    else:\n        output = v.validate_python(input_value)\n        assert output == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ('\"P0Y0M3D2WT1H2M3.5S\"', timedelta(days=3, weeks=2, hours=1, minutes=2, seconds=3, milliseconds=500)),\n        ('\"errordata\"', Err('Input should be a valid duration, invalid digit in duration [type=time_delta_parsing')),\n        ('true', Err('Input should be a valid duration [type=time_delta_type')),\n        ('3601', timedelta(hours=1, seconds=1)),\n        ('3601.123456', timedelta(hours=1, seconds=1, microseconds=123456)),\n        ('-3601', timedelta(hours=-2, seconds=3599)),\n        ('-3601.222222', timedelta(hours=-2, seconds=3598, microseconds=777778)),\n        ('-3601.2222222', timedelta(hours=-2, seconds=3598, microseconds=777778)),\n        ('3600.999999', timedelta(seconds=3600, microseconds=999999)),\n    ],\n    ids=repr,\n)\ndef test_timedelta_json(input_value, expected):\n    v = SchemaValidator({'type': 'timedelta'})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_json(input_value)\n    else:\n        output = v.validate_json(input_value)\n        assert output == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        (\n            timedelta(days=3, weeks=2, hours=1, minutes=2, seconds=3, milliseconds=500),\n            timedelta(days=3, weeks=2, hours=1, minutes=2, seconds=3, milliseconds=500),\n        ),\n        ('P0Y0M3D2WT1H2M3.5S', Err('Input should be a valid timedelta [type=time_delta_type')),\n        (b'P0Y0M3D2WT1H2M3.5S', Err('Input should be a valid timedelta [type=time_delta_type')),\n    ],\n)\ndef test_timedelta_strict(input_value, expected):\n    v = SchemaValidator({'type': 'timedelta', 'strict': True})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_python(input_value)\n    else:\n        output = v.validate_python(input_value)\n        assert output == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ('\"P0Y0M3D2WT1H2M3.5S\"', timedelta(days=3, weeks=2, hours=1, minutes=2, seconds=3, milliseconds=500)),\n        ('\"12345\"', Err('Input should be a valid duration')),\n        ('true', Err('Input should be a valid duration [type=time_delta_type')),\n    ],\n)\ndef test_timedelta_strict_json(input_value, expected):\n    v = SchemaValidator({'type': 'timedelta', 'strict': True})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_json(input_value)\n    else:\n        output = v.validate_json(input_value)\n        assert output == expected\n\n\n@pytest.mark.parametrize(\n    'kwargs,input_value,expected',\n    [\n        ({}, 'P0Y0M3D2WT1H2M3S', timedelta(days=3, weeks=2, hours=1, minutes=2, seconds=3)),\n        ({'le': timedelta(days=3)}, 'P2DT1H', timedelta(days=2, hours=1)),\n        ({'le': timedelta(days=3)}, 'P3DT0H', timedelta(days=3)),\n        ({'le': timedelta(days=3)}, 'P3DT1H', Err('Input should be less than or equal to 3 days')),\n        ({'lt': timedelta(days=3)}, 'P2DT1H', timedelta(days=2, hours=1)),\n        ({'lt': timedelta(days=3)}, 'P3DT1H', Err('Input should be less than 3 days')),\n        ({'ge': timedelta(days=3)}, 'P3DT1H', timedelta(days=3, hours=1)),\n        ({'ge': timedelta(days=3)}, 'P3D', timedelta(days=3)),\n        ({'ge': timedelta(days=3)}, 'P2DT1H', Err('Input should be greater than or equal to 3 days')),\n        ({'gt': timedelta(days=3)}, 'P3DT1H', timedelta(days=3, hours=1)),\n        ({'le': timedelta(seconds=-86400.123)}, '-PT86400.123S', timedelta(seconds=-86400.123)),\n        ({'le': timedelta(seconds=-86400.123)}, '-PT86400.124S', timedelta(seconds=-86400.124)),\n        (\n            {'le': timedelta(seconds=-86400.123)},\n            '-PT86400.122S',\n            Err(\n                'Input should be less than or equal to -2 days and 23 hours and 59 minutes and 59 seconds and 877000 microseconds [type=less_than_equal'\n            ),\n        ),\n        ({'gt': timedelta(seconds=-86400.123)}, timedelta(seconds=-86400.122), timedelta(seconds=-86400.122)),\n        ({'gt': timedelta(seconds=-86400.123)}, '-PT86400.122S', timedelta(seconds=-86400.122)),\n        (\n            {'gt': timedelta(seconds=-86400.123)},\n            '-PT86400.124S',\n            Err(\n                'Input should be greater than -2 days and 23 hours and 59 minutes and 59 seconds and 877000 microseconds [type=greater_than'\n            ),\n        ),\n        (\n            {'gt': timedelta(hours=1, minutes=30)},\n            'PT180S',\n            Err('Input should be greater than 1 hour and 30 minutes [type=greater_than'),\n        ),\n        ({'gt': timedelta()}, '-P0DT0.1S', Err('Input should be greater than 0 seconds [type=greater_than')),\n        ({'gt': timedelta()}, 'P0DT0.0S', Err('Input should be greater than 0 seconds [type=greater_than')),\n        ({'ge': timedelta()}, 'P0DT0.0S', timedelta()),\n        ({'lt': timedelta()}, '-PT0S', timedelta()),\n        (\n            {'lt': timedelta(days=740, weeks=1, hours=48, minutes=60, seconds=61, microseconds=100000)},\n            'P2Y1W10DT48H60M61.100000S',\n            Err('Input should be less than 749 days and 1 hour and 1 minute and 1 second and 100000 microseconds'),\n        ),\n    ],\n    ids=repr,\n)\ndef test_timedelta_kwargs(kwargs: Dict[str, Any], input_value, expected):\n    v = SchemaValidator({'type': 'timedelta', **kwargs})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_python(input_value)\n    else:\n        output = v.validate_python(input_value)\n        assert output == expected\n\n\ndef test_timedelta_kwargs_strict():\n    v = SchemaValidator({'type': 'timedelta', 'strict': True, 'le': timedelta(days=3)})\n    output = v.validate_python(timedelta(days=2, hours=1))\n    assert output == timedelta(days=2, hours=1)\n\n\ndef test_invalid_constraint():\n    with pytest.raises(SchemaError, match='timedelta.gt\\n  Input should be a valid timedelta, invalid digit in'):\n        validate_core_schema({'type': 'timedelta', 'gt': 'foobar'})\n\n    with pytest.raises(SchemaError, match='timedelta.le\\n  Input should be a valid timedelta, invalid digit in'):\n        validate_core_schema({'type': 'timedelta', 'le': 'foobar'})\n\n\ndef test_dict_py():\n    v = SchemaValidator({'type': 'dict', 'keys_schema': {'type': 'timedelta'}, 'values_schema': {'type': 'int'}})\n    assert v.validate_python({timedelta(days=2, hours=1): 2, timedelta(days=2, hours=2): 4}) == {\n        timedelta(days=2, hours=1): 2,\n        timedelta(days=2, hours=2): 4,\n    }\n\n\ndef test_dict_key(py_and_json: PyAndJson):\n    v = py_and_json({'type': 'dict', 'keys_schema': {'type': 'timedelta'}, 'values_schema': {'type': 'int'}})\n    assert v.validate_test({'P2DT1H': 2, 'P2DT2H': 4}) == {timedelta(days=2, hours=1): 2, timedelta(days=2, hours=2): 4}\n\n    with pytest.raises(ValidationError, match=re.escape('[type=time_delta_parsing')):\n        v.validate_test({'errordata': 2})\n\n\ndef test_dict_value(py_and_json: PyAndJson):\n    v = py_and_json({'type': 'dict', 'keys_schema': {'type': 'int'}, 'values_schema': {'type': 'timedelta'}})\n    assert v.validate_test({2: 'P2DT1H', 4: 'P2DT2H'}) == {2: timedelta(days=2, hours=1), 4: timedelta(days=2, hours=2)}\n\n    with pytest.raises(ValidationError, match=re.escape('[type=time_delta_parsing')):\n        v.validate_test({4: 'errordata'})\n\n\ndef test_union():\n    v = SchemaValidator({'type': 'union', 'choices': [{'type': 'str'}, {'type': 'timedelta'}]})\n    assert v.validate_python('P2DT1H') == 'P2DT1H'\n    assert v.validate_python(timedelta(days=2, hours=1)) == timedelta(days=2, hours=1)\n\n    v = SchemaValidator({'type': 'union', 'choices': [{'type': 'timedelta'}, {'type': 'str'}]})\n    assert v.validate_python('P2DT1H') == 'P2DT1H'\n    assert v.validate_python(timedelta(days=2, hours=1)) == timedelta(days=2, hours=1)\n\n\n@pytest.mark.parametrize(\n    'constraint,expected_duration',\n    [\n        (timedelta(days=3), {'positive': True, 'day': 3, 'second': 0, 'microsecond': 0}),\n        (timedelta(days=2, seconds=42.123), {'positive': True, 'day': 2, 'second': 42, 'microsecond': 123_000}),\n        (timedelta(days=-1), {'positive': False, 'day': 1, 'second': 0, 'microsecond': 0}),\n        (timedelta(seconds=86410), {'positive': True, 'day': 1, 'second': 10, 'microsecond': 0}),\n        (timedelta(seconds=86410.123), {'positive': True, 'day': 1, 'second': 10, 'microsecond': 123_000}),\n        (timedelta(seconds=-86410), {'positive': False, 'day': 1, 'second': 10, 'microsecond': 0}),\n        (timedelta(seconds=-86410.123), {'positive': False, 'day': 1, 'second': 10, 'microsecond': 123_000}),\n        (timedelta(days=-4, hours=12), {'positive': False, 'day': 3, 'second': 43200, 'microsecond': 0}),\n        (timedelta(days=-4, microseconds=456), {'positive': False, 'day': 3, 'second': 86399, 'microsecond': 999544}),\n        (timedelta(days=-1, seconds=20_000), {'positive': False, 'day': 0, 'second': 66_400, 'microsecond': 0}),\n        (\n            timedelta(days=-1, seconds=86_399, microseconds=1),\n            {'positive': False, 'day': 0, 'second': 0, 'microsecond': 999_999},\n        ),\n        (timedelta.max, {'positive': True, 'day': 999999999, 'second': 86399, 'microsecond': 999999}),\n        (timedelta.min, {'positive': False, 'day': 999999999, 'second': 0, 'microsecond': 0}),\n    ],\n    ids=repr,\n)\ndef test_pytimedelta_as_timedelta(constraint, expected_duration):\n    v = SchemaValidator({'type': 'timedelta', 'gt': constraint})\n    # simplest way to check `pytimedelta_as_timedelta` is correct is to extract duration from repr of the validator\n    m = re.search(r'Duration ?\\{\\s+positive: ?(\\w+),\\s+day: ?(\\d+),\\s+second: ?(\\d+),\\s+microsecond: ?(\\d+)', repr(v))\n    pos, day, sec, micro = m.groups()\n    duration = {'positive': pos == 'true', 'day': int(day), 'second': int(sec), 'microsecond': int(micro)}\n    assert duration == pytest.approx(expected_duration), constraint\n\n\ndef test_large_value():\n    v = SchemaValidator({'type': 'timedelta'})\n    assert v.validate_python('123days, 12:34') == timedelta(days=123, hours=12, minutes=34)\n    assert v.validate_python(f'{999_999_999}days, 12:34') == timedelta(days=999_999_999, hours=12, minutes=34)\n    with pytest.raises(ValidationError, match='should be a valid timedelta, durations may not exceed 999,999,999 days'):\n        v.validate_python(f'{999_999_999 + 1}days, 12:34')\n\n\n@pytest.mark.skipif(not pandas, reason='pandas not installed')\ndef test_pandas():\n    v = SchemaValidator({'type': 'timedelta', 'ge': timedelta(hours=2)})\n    two_hours = pandas.Timestamp('2023-01-01T02:00:00Z') - pandas.Timestamp('2023-01-01T00:00:00Z')\n\n    assert v.validate_python(two_hours) == two_hours\n    assert v.validate_python(two_hours.to_pytimedelta()) == two_hours\n\n    one_55 = pandas.Timestamp('2023-01-01T01:55:00Z') - pandas.Timestamp('2023-01-01T00:00:00Z')\n    msg = r'Input should be greater than or equal to 2 hours'\n    with pytest.raises(ValidationError, match=msg):\n        v.validate_python(one_55)\n    with pytest.raises(ValidationError, match=msg):\n        v.validate_python(one_55.to_pytimedelta())\n", "tests/validators/test_union.py": "from dataclasses import dataclass\nfrom datetime import date, time\nfrom enum import Enum, IntEnum\nfrom itertools import permutations\nfrom typing import Any, List, Optional, Union\nfrom uuid import UUID\n\nimport pytest\nfrom dirty_equals import IsFloat, IsInt\n\nfrom pydantic_core import SchemaError, SchemaValidator, ValidationError, core_schema, validate_core_schema\n\nfrom ..conftest import plain_repr\n\n\n@pytest.mark.parametrize(\n    'input_value,expected_value',\n    [\n        (True, True),\n        (False, False),\n        ('true', True),\n        ('false', False),\n        (1, 1),\n        (0, 0),\n        (123, 123),\n        ('123', 123),\n        ('0', False),  # this case is different depending on the order of the choices\n        ('1', True),  # this case is different depending on the order of the choices\n    ],\n)\ndef test_union_bool_int(input_value, expected_value):\n    v = SchemaValidator({'type': 'union', 'choices': [{'type': 'bool'}, {'type': 'int'}]})\n    assert v.validate_python(input_value) == expected_value\n\n\n@pytest.mark.parametrize(\n    'input_value,expected_value',\n    [\n        (True, True),\n        (False, False),\n        ('true', True),\n        ('false', False),\n        (1, 1),\n        (0, 0),\n        (123, 123),\n        ('123', 123),\n        ('0', 0),  # this case is different depending on the order of the choices\n        ('1', 1),  # this case is different depending on the order of the choices\n    ],\n)\ndef test_union_int_bool(input_value, expected_value):\n    v = SchemaValidator({'type': 'union', 'choices': [{'type': 'int'}, {'type': 'bool'}]})\n    assert v.validate_python(input_value) == expected_value\n\n\nclass TestModelClass:\n    class ModelA:\n        pass\n\n    class ModelB:\n        pass\n\n    @pytest.fixture(scope='class')\n    def schema_validator(self) -> SchemaValidator:\n        return SchemaValidator(\n            {\n                'type': 'union',\n                'choices': [\n                    {\n                        'type': 'model',\n                        'cls': self.ModelA,\n                        'schema': {\n                            'type': 'model-fields',\n                            'fields': {\n                                'a': {'type': 'model-field', 'schema': {'type': 'int'}},\n                                'b': {'type': 'model-field', 'schema': {'type': 'str'}},\n                            },\n                        },\n                    },\n                    {\n                        'type': 'model',\n                        'cls': self.ModelB,\n                        'schema': {\n                            'type': 'model-fields',\n                            'fields': {\n                                'c': {'type': 'model-field', 'schema': {'type': 'int'}},\n                                'd': {'type': 'model-field', 'schema': {'type': 'str'}},\n                            },\n                        },\n                    },\n                ],\n            }\n        )\n\n    def test_model_a(self, schema_validator: SchemaValidator):\n        m_a = schema_validator.validate_python({'a': 1, 'b': 'hello'})\n        assert isinstance(m_a, self.ModelA)\n        assert m_a.a == 1\n        assert m_a.b == 'hello'\n\n    def test_model_b(self, schema_validator: SchemaValidator):\n        m_b = schema_validator.validate_python({'c': 2, 'd': 'again'})\n        assert isinstance(m_b, self.ModelB)\n        assert m_b.c == 2\n        assert m_b.d == 'again'\n\n    def test_exact_check(self, schema_validator: SchemaValidator):\n        m_b = schema_validator.validate_python({'c': 2, 'd': 'again'})\n        assert isinstance(m_b, self.ModelB)\n\n        m_b2 = schema_validator.validate_python(m_b)\n        assert m_b2 is m_b\n\n    def test_error(self, schema_validator: SchemaValidator):\n        with pytest.raises(ValidationError) as exc_info:\n            schema_validator.validate_python({'a': 2})\n        assert exc_info.value.errors(include_url=False) == [\n            {'type': 'missing', 'loc': ('ModelA', 'b'), 'msg': 'Field required', 'input': {'a': 2}},\n            {'type': 'missing', 'loc': ('ModelB', 'c'), 'msg': 'Field required', 'input': {'a': 2}},\n            {'type': 'missing', 'loc': ('ModelB', 'd'), 'msg': 'Field required', 'input': {'a': 2}},\n        ]\n\n\nclass TestModelClassSimilar:\n    class ModelA:\n        pass\n\n    class ModelB:\n        pass\n\n    @pytest.fixture(scope='class')\n    def schema_validator(self) -> SchemaValidator:\n        return SchemaValidator(\n            {\n                'type': 'union',\n                'choices': [\n                    {\n                        'type': 'model',\n                        'cls': self.ModelA,\n                        'schema': {\n                            'type': 'model-fields',\n                            'fields': {\n                                'a': {'type': 'model-field', 'schema': {'type': 'int'}},\n                                'b': {'type': 'model-field', 'schema': {'type': 'str'}},\n                            },\n                        },\n                    },\n                    {\n                        'type': 'model',\n                        'cls': self.ModelB,\n                        'schema': {\n                            'type': 'model-fields',\n                            'fields': {\n                                'a': {'type': 'model-field', 'schema': {'type': 'int'}},\n                                'b': {'type': 'model-field', 'schema': {'type': 'str'}},\n                                'c': {\n                                    'type': 'model-field',\n                                    'schema': {'type': 'default', 'schema': {'type': 'float'}, 'default': 1.0},\n                                },\n                            },\n                        },\n                    },\n                ],\n            }\n        )\n\n    def test_model_a(self, schema_validator: SchemaValidator):\n        m = schema_validator.validate_python({'a': 1, 'b': 'hello'})\n        assert isinstance(m, self.ModelA)\n        assert m.a == 1\n        assert m.b == 'hello'\n        assert not hasattr(m, 'c')\n\n    def test_model_b_preferred(self, schema_validator: SchemaValidator):\n        # Note, this is a different behavior to previous smart union behavior,\n        # where the first match would be preferred. However, we believe is it better\n        # to prefer the match with the greatest number of valid fields set.\n        m = schema_validator.validate_python({'a': 1, 'b': 'hello', 'c': 2.0})\n        assert isinstance(m, self.ModelB)\n        assert m.a == 1\n        assert m.b == 'hello'\n        assert m.c == 2.0\n\n    def test_model_b_not_ignored(self, schema_validator: SchemaValidator):\n        m1 = self.ModelB()\n        m1.a = 1\n        m1.b = 'hello'\n        m1.c = 2.0\n        m2 = schema_validator.validate_python(m1)\n        assert isinstance(m2, self.ModelB)\n        assert m2.a == 1\n        assert m2.b == 'hello'\n        assert m2.c == 2.0\n\n\ndef test_nullable_via_union():\n    v = SchemaValidator({'type': 'union', 'choices': [{'type': 'none'}, {'type': 'int'}]})\n    assert v.validate_python(None) is None\n    assert v.validate_python(1) == 1\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python('hello')\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'none_required', 'loc': ('none',), 'msg': 'Input should be None', 'input': 'hello'},\n        {\n            'type': 'int_parsing',\n            'loc': ('int',),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'hello',\n        },\n    ]\n\n\ndef test_union_list_bool_int():\n    v = SchemaValidator(\n        {\n            'type': 'union',\n            'choices': [\n                {'type': 'list', 'items_schema': {'type': 'bool'}},\n                {'type': 'list', 'items_schema': {'type': 'int'}},\n            ],\n        }\n    )\n    assert v.validate_python(['true', True, 'no']) == [True, True, False]\n    assert v.validate_python([5, 6, '789']) == [5, 6, 789]\n    assert v.validate_python(['1', '0']) == [1, 0]\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python([3, 'true'])\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'bool_parsing',\n            'loc': ('list[bool]', 0),\n            'msg': 'Input should be a valid boolean, unable to interpret input',\n            'input': 3,\n        },\n        {\n            'type': 'int_parsing',\n            'loc': ('list[int]', 1),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'true',\n        },\n    ]\n\n\ndef test_no_choices(pydantic_version):\n    with pytest.raises(SchemaError) as exc_info:\n        validate_core_schema({'type': 'union'})\n\n    assert str(exc_info.value) == (\n        'Invalid Schema:\\n'\n        'union.choices\\n'\n        \"  Field required [type=missing, input_value={'type': 'union'}, input_type=dict]\\n\"\n        f'    For further information visit https://errors.pydantic.dev/{pydantic_version}/v/missing'\n    )\n    assert exc_info.value.error_count() == 1\n    assert exc_info.value.errors() == [\n        {'input': {'type': 'union'}, 'loc': ('union', 'choices'), 'msg': 'Field required', 'type': 'missing'}\n    ]\n\n\ndef test_empty_choices():\n    msg = r'Error building \"union\" validator:\\s+SchemaError: One or more union choices required'\n    with pytest.raises(SchemaError, match=msg):\n        SchemaValidator({'type': 'union', 'choices': []})\n\n\ndef test_one_choice():\n    v = SchemaValidator({'type': 'union', 'choices': [{'type': 'str'}]})\n    assert (\n        plain_repr(v)\n        == 'SchemaValidator(title=\"str\",validator=Str(StrValidator{strict:false,coerce_numbers_to_str:false}),definitions=[],cache_strings=True)'\n    )\n    assert v.validate_python('hello') == 'hello'\n\n\ndef test_strict_union():\n    v = SchemaValidator({'type': 'union', 'strict': True, 'choices': [{'type': 'bool'}, {'type': 'int'}]})\n    assert v.validate_python(1) == 1\n    assert v.validate_python(123) == 123\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python('123')\n\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'bool_type', 'loc': ('bool',), 'msg': 'Input should be a valid boolean', 'input': '123'},\n        {'type': 'int_type', 'loc': ('int',), 'msg': 'Input should be a valid integer', 'input': '123'},\n    ]\n\n\ndef test_custom_error():\n    v = SchemaValidator(\n        {\n            'type': 'union',\n            'choices': [{'type': 'str'}, {'type': 'bytes'}],\n            'custom_error_type': 'my_error',\n            'custom_error_message': 'Input should be a string or bytes',\n        }\n    )\n    assert v.validate_python('hello') == 'hello'\n    assert v.validate_python(b'hello') == b'hello'\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python(123)\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'my_error', 'loc': (), 'msg': 'Input should be a string or bytes', 'input': 123}\n    ]\n\n\ndef test_custom_error_type():\n    v = SchemaValidator(\n        {'type': 'union', 'choices': [{'type': 'str'}, {'type': 'bytes'}], 'custom_error_type': 'string_type'}\n    )\n    assert v.validate_python('hello') == 'hello'\n    assert v.validate_python(b'hello') == b'hello'\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python(123)\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'string_type', 'loc': (), 'msg': 'Input should be a valid string', 'input': 123}\n    ]\n\n\ndef test_custom_error_type_context():\n    v = SchemaValidator(\n        {\n            'type': 'union',\n            'choices': [{'type': 'str'}, {'type': 'bytes'}],\n            'custom_error_type': 'less_than',\n            'custom_error_context': {'lt': 42},\n        }\n    )\n    assert v.validate_python('hello') == 'hello'\n    assert v.validate_python(b'hello') == b'hello'\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python(123)\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'less_than', 'loc': (), 'msg': 'Input should be less than 42', 'input': 123, 'ctx': {'lt': 42.0}}\n    ]\n\n\ndef test_dirty_behaviour():\n    \"\"\"\n    Check dirty-equals does what we expect.\n    \"\"\"\n\n    assert 1 == IsInt(approx=1, delta=0)\n    assert 1.0 != IsInt(approx=1, delta=0)\n    assert 1 != IsFloat(approx=1, delta=0)\n    assert 1.0 == IsFloat(approx=1, delta=0)\n\n\ndef test_int_float():\n    v = SchemaValidator(core_schema.union_schema([core_schema.int_schema(), core_schema.float_schema()]))\n    assert v.validate_python(1) == IsInt(approx=1, delta=0)\n    assert v.validate_json('1') == IsInt(approx=1, delta=0)\n    assert v.validate_python(1.0) == IsFloat(approx=1, delta=0)\n    assert v.validate_json('1.0') == IsFloat(approx=1, delta=0)\n\n    v = SchemaValidator(core_schema.union_schema([core_schema.float_schema(), core_schema.int_schema()]))\n    assert v.validate_python(1) == IsInt(approx=1, delta=0)\n    assert v.validate_json('1') == IsInt(approx=1, delta=0)\n    assert v.validate_python(1.0) == IsFloat(approx=1, delta=0)\n    assert v.validate_json('1.0') == IsFloat(approx=1, delta=0)\n\n\ndef test_str_float():\n    v = SchemaValidator(core_schema.union_schema([core_schema.str_schema(), core_schema.float_schema()]))\n\n    assert v.validate_python(1) == IsFloat(approx=1, delta=0)\n    assert v.validate_json('1') == IsFloat(approx=1, delta=0)\n    assert v.validate_python(1.0) == IsFloat(approx=1, delta=0)\n    assert v.validate_json('1.0') == IsFloat(approx=1, delta=0)\n\n    assert v.validate_python('1.0') == '1.0'\n    assert v.validate_python('1') == '1'\n    assert v.validate_json('\"1.0\"') == '1.0'\n    assert v.validate_json('\"1\"') == '1'\n\n    v = SchemaValidator(core_schema.union_schema([core_schema.float_schema(), core_schema.str_schema()]))\n    assert v.validate_python(1) == IsFloat(approx=1, delta=0)\n    assert v.validate_json('1') == IsFloat(approx=1, delta=0)\n    assert v.validate_python(1.0) == IsFloat(approx=1, delta=0)\n    assert v.validate_json('1.0') == IsFloat(approx=1, delta=0)\n\n    assert v.validate_python('1.0') == '1.0'\n    assert v.validate_python('1') == '1'\n    assert v.validate_json('\"1.0\"') == '1.0'\n    assert v.validate_json('\"1\"') == '1'\n\n\ndef test_no_strict_check():\n    v = SchemaValidator(core_schema.union_schema([core_schema.is_instance_schema(int), core_schema.json_schema()]))\n    assert v.validate_python(123) == 123\n    assert v.validate_python('[1, 2, 3]') == [1, 2, 3]\n\n\ndef test_strict_reference():\n    v = SchemaValidator(\n        core_schema.definitions_schema(\n            core_schema.definition_reference_schema(schema_ref='tuple-ref'),\n            [\n                core_schema.tuple_positional_schema(\n                    [\n                        core_schema.float_schema(),\n                        core_schema.union_schema(\n                            [core_schema.int_schema(), core_schema.definition_reference_schema('tuple-ref')]\n                        ),\n                    ],\n                    ref='tuple-ref',\n                )\n            ],\n        )\n    )\n\n    assert repr(v.validate_python((1, 2))) == '(1.0, 2)'\n    assert repr(v.validate_python((1.0, (2.0, 3)))) == '(1.0, (2.0, 3))'\n\n\ndef test_case_labels():\n    v = SchemaValidator(\n        {'type': 'union', 'choices': [{'type': 'none'}, ({'type': 'int'}, 'my_label'), {'type': 'str'}]}\n    )\n    assert v.validate_python(None) is None\n    assert v.validate_python(1) == 1\n    with pytest.raises(ValidationError, match=r'3 validation errors for union\\[none,my_label,str]') as exc_info:\n        v.validate_python(1.5)\n    assert exc_info.value.errors(include_url=False) == [\n        {'input': 1.5, 'loc': ('none',), 'msg': 'Input should be None', 'type': 'none_required'},\n        {\n            'input': 1.5,\n            'loc': ('my_label',),\n            'msg': 'Input should be a valid integer, got a number with a fractional part',\n            'type': 'int_from_float',\n        },\n        {'input': 1.5, 'loc': ('str',), 'msg': 'Input should be a valid string', 'type': 'string_type'},\n    ]\n\n\ndef test_left_to_right_doesnt_care_about_strict_check():\n    v = SchemaValidator(\n        core_schema.union_schema([core_schema.int_schema(), core_schema.json_schema()], mode='left_to_right')\n    )\n    assert 'strict_required' not in plain_repr(v)\n    assert 'ultra_strict_required' not in plain_repr(v)\n\n\ndef test_left_to_right_union():\n    choices = [core_schema.int_schema(), core_schema.float_schema()]\n\n    # smart union prefers float\n    v = SchemaValidator(core_schema.union_schema(choices, mode='smart'))\n    out = v.validate_python(1.0)\n    assert out == 1.0\n    assert isinstance(out, float)\n\n    # left_to_right union will select int\n    v = SchemaValidator(core_schema.union_schema(choices, mode='left_to_right'))\n    out = v.validate_python(1)\n    assert out == 1\n    assert isinstance(out, int)\n\n    out = v.validate_python(1.0)\n    assert out == 1\n    assert isinstance(out, int)\n\n    # reversing them will select float\n    v = SchemaValidator(core_schema.union_schema(list(reversed(choices)), mode='left_to_right'))\n    out = v.validate_python(1.0)\n    assert out == 1.0\n    assert isinstance(out, float)\n\n    out = v.validate_python(1)\n    assert out == 1.0\n    assert isinstance(out, float)\n\n\ndef test_left_to_right_union_strict():\n    choices = [core_schema.int_schema(), core_schema.float_schema()]\n\n    # left_to_right union will select not cast if int first (strict int will not accept float)\n    v = SchemaValidator(core_schema.union_schema(choices, mode='left_to_right', strict=True))\n    out = v.validate_python(1)\n    assert out == 1\n    assert isinstance(out, int)\n\n    out = v.validate_python(1.0)\n    assert out == 1.0\n    assert isinstance(out, float)\n\n    # reversing union will select float always (as strict float will accept int)\n    v = SchemaValidator(core_schema.union_schema(list(reversed(choices)), mode='left_to_right', strict=True))\n    out = v.validate_python(1.0)\n    assert out == 1.0\n    assert isinstance(out, float)\n\n    out = v.validate_python(1)\n    assert out == 1.0\n    assert isinstance(out, float)\n\n\ndef test_union_function_before_called_once():\n    # See https://github.com/pydantic/pydantic/issues/6830 - in particular the\n    # smart union validator used to call `remove_prefix` twice, which is not\n    # ideal from a user perspective.\n    class SpecialValues(str, Enum):\n        DEFAULT = 'default'\n        OTHER = 'other'\n\n    special_values_schema = core_schema.no_info_after_validator_function(SpecialValues, core_schema.str_schema())\n\n    validator_called_count = 0\n\n    def remove_prefix(v: str):\n        nonlocal validator_called_count\n        validator_called_count += 1\n        if v.startswith('uuid::'):\n            return v[6:]\n        return v\n\n    prefixed_uuid_schema = core_schema.no_info_before_validator_function(remove_prefix, core_schema.uuid_schema())\n\n    v = SchemaValidator(core_schema.union_schema([special_values_schema, prefixed_uuid_schema]))\n\n    assert v.validate_python('uuid::12345678-1234-5678-1234-567812345678') == UUID(\n        '12345678-1234-5678-1234-567812345678'\n    )\n    assert validator_called_count == 1\n\n\n@pytest.mark.parametrize(\n    ('schema', 'input_value', 'expected_value'),\n    (\n        (\n            core_schema.uuid_schema(),\n            '12345678-1234-5678-1234-567812345678',\n            UUID('12345678-1234-5678-1234-567812345678'),\n        ),\n        (core_schema.date_schema(), '2020-01-01', date(2020, 1, 1)),\n        (core_schema.time_schema(), '00:00:00', time(0, 0, 0)),\n        # In V2.4 these already returned strings, so we keep this behaviour in V2\n        (core_schema.datetime_schema(), '2020-01-01:00:00:00', '2020-01-01:00:00:00'),\n        (core_schema.url_schema(), 'https://foo.com', 'https://foo.com'),\n        (core_schema.multi_host_url_schema(), 'https://bar.com,foo.com', 'https://bar.com,foo.com'),\n    ),\n)\ndef test_smart_union_json_string_types(schema: core_schema.CoreSchema, input_value: str, expected_value: Any):\n    # Many types have to be represented in strings as JSON, we make sure that\n    # when parsing in JSON mode these types are preferred\n    # TODO: in V3 we will make str win in all these cases.\n\n    validator = SchemaValidator(core_schema.union_schema([schema, core_schema.str_schema()]))\n    assert validator.validate_json(f'\"{input_value}\"') == expected_value\n    # in Python mode the string will be preferred\n    assert validator.validate_python(input_value) == input_value\n\n\n@pytest.mark.parametrize(\n    ('schema', 'input_value'),\n    (\n        pytest.param(\n            core_schema.uuid_schema(),\n            '12345678-1234-5678-1234-567812345678',\n            marks=pytest.mark.xfail(reason='TODO: V3'),\n        ),\n        (core_schema.date_schema(), '2020-01-01'),\n        (core_schema.time_schema(), '00:00:00'),\n        (core_schema.datetime_schema(), '2020-01-01:00:00:00'),\n        (core_schema.url_schema(), 'https://foo.com'),\n        (core_schema.multi_host_url_schema(), 'https://bar.com,foo.com'),\n    ),\n)\ndef test_smart_union_json_string_types_str_first(schema: core_schema.CoreSchema, input_value: str):\n    # As above, but reversed order; str should always win\n    validator = SchemaValidator(core_schema.union_schema([core_schema.str_schema(), schema]))\n    assert validator.validate_json(f'\"{input_value}\"') == input_value\n    assert validator.validate_python(input_value) == input_value\n\n\ndef test_smart_union_default_fallback():\n    \"\"\"Using a default value does not affect the exactness of the smart union match.\"\"\"\n\n    class ModelA:\n        x: int\n        y: int = 1\n\n    class ModelB:\n        x: int\n\n    schema = core_schema.union_schema(\n        [\n            core_schema.model_schema(\n                ModelA,\n                core_schema.model_fields_schema(\n                    {\n                        'x': core_schema.model_field(core_schema.int_schema()),\n                        'y': core_schema.model_field(\n                            core_schema.with_default_schema(core_schema.int_schema(), default=1)\n                        ),\n                    }\n                ),\n            ),\n            core_schema.model_schema(\n                ModelB, core_schema.model_fields_schema({'x': core_schema.model_field(core_schema.int_schema())})\n            ),\n        ]\n    )\n\n    validator = SchemaValidator(schema)\n\n    result = validator.validate_python({'x': 1})\n    assert isinstance(result, ModelA)\n    assert result.x == 1\n    assert result.y == 1\n\n    # passing a ModelB explicitly will not match the default value\n    b = ModelB()\n    assert validator.validate_python(b) is b\n\n\ndef test_smart_union_model_field():\n    class ModelA:\n        x: int\n\n    class ModelB:\n        x: str\n\n    schema = core_schema.union_schema(\n        [\n            core_schema.model_schema(\n                ModelA, core_schema.model_fields_schema({'x': core_schema.model_field(core_schema.int_schema())})\n            ),\n            core_schema.model_schema(\n                ModelB, core_schema.model_fields_schema({'x': core_schema.model_field(core_schema.str_schema())})\n            ),\n        ]\n    )\n\n    validator = SchemaValidator(schema)\n\n    result = validator.validate_python({'x': 1})\n    assert isinstance(result, ModelA)\n    assert result.x == 1\n\n    result = validator.validate_python({'x': '1'})\n    assert isinstance(result, ModelB)\n    assert result.x == '1'\n\n\ndef test_smart_union_dataclass_field():\n    @dataclass\n    class ModelA:\n        x: int\n\n    @dataclass\n    class ModelB:\n        x: str\n\n    schema = core_schema.union_schema(\n        [\n            core_schema.dataclass_schema(\n                ModelA,\n                core_schema.dataclass_args_schema(\n                    'ModelA', [core_schema.dataclass_field('x', core_schema.int_schema())]\n                ),\n                ['x'],\n            ),\n            core_schema.dataclass_schema(\n                ModelB,\n                core_schema.dataclass_args_schema(\n                    'ModelB', [core_schema.dataclass_field('x', core_schema.str_schema())]\n                ),\n                ['x'],\n            ),\n        ]\n    )\n\n    validator = SchemaValidator(schema)\n\n    result = validator.validate_python({'x': 1})\n    assert isinstance(result, ModelA)\n    assert result.x == 1\n\n    result = validator.validate_python({'x': '1'})\n    assert isinstance(result, ModelB)\n    assert result.x == '1'\n\n\ndef test_smart_union_with_any():\n    \"\"\"any is preferred over lax validations\"\"\"\n\n    # str not coerced to int\n    schema = core_schema.union_schema([core_schema.int_schema(), core_schema.any_schema()])\n    validator = SchemaValidator(schema)\n    assert validator.validate_python('1') == '1'\n\n    # int *is* coerced to float, this is a strict validation\n    schema = core_schema.union_schema([core_schema.float_schema(), core_schema.any_schema()])\n    validator = SchemaValidator(schema)\n    assert repr(validator.validate_python(1)) == '1.0'\n\n\ndef test_smart_union_validator_function():\n    \"\"\"adding a validator function should not change smart union behaviour\"\"\"\n\n    inner_schema = core_schema.union_schema([core_schema.int_schema(), core_schema.float_schema()])\n\n    validator = SchemaValidator(inner_schema)\n    assert repr(validator.validate_python(1)) == '1'\n    assert repr(validator.validate_python(1.0)) == '1.0'\n\n    schema = core_schema.union_schema(\n        [core_schema.no_info_after_validator_function(lambda v: v * 2, inner_schema), core_schema.str_schema()]\n    )\n\n    validator = SchemaValidator(schema)\n    assert repr(validator.validate_python(1)) == '2'\n    assert repr(validator.validate_python(1.0)) == '2.0'\n    assert validator.validate_python('1') == '1'\n\n    schema = core_schema.union_schema(\n        [\n            core_schema.no_info_wrap_validator_function(lambda v, handler: handler(v) * 2, inner_schema),\n            core_schema.str_schema(),\n        ]\n    )\n\n    validator = SchemaValidator(schema)\n    assert repr(validator.validate_python(1)) == '2'\n    assert repr(validator.validate_python(1.0)) == '2.0'\n    assert validator.validate_python('1') == '1'\n\n\ndef test_smart_union_validator_function_one_arm():\n    \"\"\"adding a validator function should not change smart union behaviour\"\"\"\n\n    schema = core_schema.union_schema(\n        [\n            core_schema.float_schema(),\n            core_schema.no_info_after_validator_function(lambda v: v * 2, core_schema.int_schema()),\n        ]\n    )\n\n    validator = SchemaValidator(schema)\n    assert repr(validator.validate_python(1)) == '2'\n    assert repr(validator.validate_python(1.0)) == '1.0'\n\n    schema = core_schema.union_schema(\n        [\n            core_schema.float_schema(),\n            core_schema.no_info_wrap_validator_function(lambda v, handler: handler(v) * 2, core_schema.int_schema()),\n        ]\n    )\n\n    validator = SchemaValidator(schema)\n    assert repr(validator.validate_python(1)) == '2'\n    assert repr(validator.validate_python(1.0)) == '1.0'\n\n\ndef test_int_not_coerced_to_enum():\n    class BinaryEnum(IntEnum):\n        ZERO = 0\n        ONE = 1\n\n    enum_schema = core_schema.lax_or_strict_schema(\n        core_schema.no_info_after_validator_function(BinaryEnum, core_schema.int_schema()),\n        core_schema.is_instance_schema(BinaryEnum),\n    )\n\n    schema = core_schema.union_schema([enum_schema, core_schema.int_schema()])\n\n    validator = SchemaValidator(schema)\n\n    assert validator.validate_python(0) is not BinaryEnum.ZERO\n    assert validator.validate_python(1) is not BinaryEnum.ONE\n    assert validator.validate_python(BinaryEnum.ZERO) is BinaryEnum.ZERO\n    assert validator.validate_python(BinaryEnum.ONE) is BinaryEnum.ONE\n\n\ndef test_model_and_literal_union() -> None:\n    # see https://github.com/pydantic/pydantic/issues/8183\n    class ModelA:\n        pass\n\n    validator = SchemaValidator(\n        {\n            'type': 'union',\n            'choices': [\n                {\n                    'type': 'model',\n                    'cls': ModelA,\n                    'schema': {\n                        'type': 'model-fields',\n                        'fields': {\n                            'a': {'type': 'model-field', 'schema': {'type': 'int'}},\n                        },\n                    },\n                },\n                {'type': 'literal', 'expected': [True]},\n            ],\n        }\n    )\n\n    # validation against Literal[True] fails bc of the unhashable dict\n    # A ValidationError is raised, not a ValueError, which allows the validation against the union to continue\n    m = validator.validate_python({'a': 42})\n    assert isinstance(m, ModelA)\n    assert m.a == 42\n    assert validator.validate_python(True) is True\n\n\ndef permute_choices(choices: List[core_schema.CoreSchema]) -> List[List[core_schema.CoreSchema]]:\n    return [list(p) for p in permutations(choices)]\n\n\nclass TestSmartUnionWithSubclass:\n    class ModelA:\n        a: int\n\n    class ModelB(ModelA):\n        b: int\n\n    model_a_schema = core_schema.model_schema(\n        ModelA, core_schema.model_fields_schema(fields={'a': core_schema.model_field(core_schema.int_schema())})\n    )\n    model_b_schema = core_schema.model_schema(\n        ModelB,\n        core_schema.model_fields_schema(\n            fields={\n                'a': core_schema.model_field(core_schema.int_schema()),\n                'b': core_schema.model_field(core_schema.int_schema()),\n            }\n        ),\n    )\n\n    @pytest.mark.parametrize('choices', permute_choices([model_a_schema, model_b_schema]))\n    def test_more_specific_data_matches_subclass(self, choices) -> None:\n        validator = SchemaValidator(schema=core_schema.union_schema(choices))\n        assert isinstance(validator.validate_python({'a': 1}), self.ModelA)\n        assert isinstance(validator.validate_python({'a': 1, 'b': 2}), self.ModelB)\n\n        assert isinstance(validator.validate_python({'a': 1, 'b': 2}), self.ModelB)\n\n        # confirm that a model that matches in lax mode with 2 fields\n        # is preferred over a model that matches in strict mode with 1 field\n        assert isinstance(validator.validate_python({'a': '1', 'b': '2'}), self.ModelB)\n        assert isinstance(validator.validate_python({'a': '1', 'b': 2}), self.ModelB)\n        assert isinstance(validator.validate_python({'a': 1, 'b': '2'}), self.ModelB)\n\n\nclass TestSmartUnionWithDefaults:\n    class ModelA:\n        a: int = 0\n\n    class ModelB:\n        b: int = 0\n\n    model_a_schema = core_schema.model_schema(\n        ModelA,\n        core_schema.model_fields_schema(\n            fields={'a': core_schema.model_field(core_schema.with_default_schema(core_schema.int_schema(), default=0))}\n        ),\n    )\n    model_b_schema = core_schema.model_schema(\n        ModelB,\n        core_schema.model_fields_schema(\n            fields={'b': core_schema.model_field(core_schema.with_default_schema(core_schema.int_schema(), default=0))}\n        ),\n    )\n\n    @pytest.mark.parametrize('choices', permute_choices([model_a_schema, model_b_schema]))\n    def test_fields_set_ensures_best_match(self, choices) -> None:\n        validator = SchemaValidator(schema=core_schema.union_schema(choices))\n        assert isinstance(validator.validate_python({'a': 1}), self.ModelA)\n        assert isinstance(validator.validate_python({'b': 1}), self.ModelB)\n\n        # defaults to leftmost choice if there's a tie\n        assert isinstance(validator.validate_python({}), choices[0]['cls'])\n\n    @pytest.mark.parametrize('choices', permute_choices([model_a_schema, model_b_schema]))\n    def test_optional_union_with_members_having_defaults(self, choices) -> None:\n        class WrapModel:\n            val: Optional[Union[self.ModelA, self.ModelB]] = None\n\n        val = SchemaValidator(\n            core_schema.model_schema(\n                WrapModel,\n                core_schema.model_fields_schema(\n                    fields={\n                        'val': core_schema.model_field(\n                            core_schema.with_default_schema(\n                                core_schema.union_schema(choices),\n                                default=None,\n                            )\n                        )\n                    }\n                ),\n            )\n        )\n\n        assert isinstance(val.validate_python({'val': {'a': 1}}).val, self.ModelA)\n        assert isinstance(val.validate_python({'val': {'b': 1}}).val, self.ModelB)\n        assert val.validate_python({}).val is None\n\n\ndef test_dc_smart_union_by_fields_set() -> None:\n    @dataclass\n    class ModelA:\n        x: int\n\n    @dataclass\n    class ModelB(ModelA):\n        y: int\n\n    dc_a_schema = core_schema.dataclass_schema(\n        ModelA,\n        core_schema.dataclass_args_schema('ModelA', [core_schema.dataclass_field('x', core_schema.int_schema())]),\n        ['x'],\n    )\n\n    dc_b_schema = core_schema.dataclass_schema(\n        ModelB,\n        core_schema.dataclass_args_schema(\n            'ModelB',\n            [\n                core_schema.dataclass_field('x', core_schema.int_schema()),\n                core_schema.dataclass_field('y', core_schema.int_schema()),\n            ],\n        ),\n        ['x', 'y'],\n    )\n\n    for choices in permute_choices([dc_a_schema, dc_b_schema]):\n        validator = SchemaValidator(core_schema.union_schema(choices=choices))\n\n        assert isinstance(validator.validate_python({'x': 1}), ModelA)\n        assert isinstance(validator.validate_python({'x': '1'}), ModelA)\n\n        assert isinstance(validator.validate_python({'x': 1, 'y': 2}), ModelB)\n        assert isinstance(validator.validate_python({'x': 1, 'y': '2'}), ModelB)\n        assert isinstance(validator.validate_python({'x': '1', 'y': 2}), ModelB)\n        assert isinstance(validator.validate_python({'x': '1', 'y': '2'}), ModelB)\n\n\ndef test_dc_smart_union_with_defaults() -> None:\n    @dataclass\n    class ModelA:\n        a: int = 0\n\n    @dataclass\n    class ModelB:\n        b: int = 0\n\n    dc_a_schema = core_schema.dataclass_schema(\n        ModelA,\n        core_schema.dataclass_args_schema(\n            'ModelA',\n            [\n                core_schema.dataclass_field(\n                    'a', core_schema.with_default_schema(schema=core_schema.int_schema(), default=0)\n                )\n            ],\n        ),\n        ['a'],\n    )\n\n    dc_b_schema = core_schema.dataclass_schema(\n        ModelB,\n        core_schema.dataclass_args_schema(\n            'ModelB',\n            [\n                core_schema.dataclass_field(\n                    'b', core_schema.with_default_schema(schema=core_schema.int_schema(), default=0)\n                )\n            ],\n        ),\n        ['b'],\n    )\n\n    for choices in permute_choices([dc_a_schema, dc_b_schema]):\n        validator = SchemaValidator(core_schema.union_schema(choices=choices))\n\n        assert isinstance(validator.validate_python({'a': 1}), ModelA)\n        assert isinstance(validator.validate_python({'b': 1}), ModelB)\n\n\ndef test_td_smart_union_by_fields_set() -> None:\n    td_a_schema = core_schema.typed_dict_schema(\n        fields={'x': core_schema.typed_dict_field(core_schema.int_schema())},\n    )\n\n    td_b_schema = core_schema.typed_dict_schema(\n        fields={\n            'x': core_schema.typed_dict_field(core_schema.int_schema()),\n            'y': core_schema.typed_dict_field(core_schema.int_schema()),\n        },\n    )\n\n    for choices in permute_choices([td_a_schema, td_b_schema]):\n        validator = SchemaValidator(core_schema.union_schema(choices=choices))\n\n        assert set(validator.validate_python({'x': 1}).keys()) == {'x'}\n        assert set(validator.validate_python({'x': '1'}).keys()) == {'x'}\n\n        assert set(validator.validate_python({'x': 1, 'y': 2}).keys()) == {'x', 'y'}\n        assert set(validator.validate_python({'x': 1, 'y': '2'}).keys()) == {'x', 'y'}\n        assert set(validator.validate_python({'x': '1', 'y': 2}).keys()) == {'x', 'y'}\n        assert set(validator.validate_python({'x': '1', 'y': '2'}).keys()) == {'x', 'y'}\n\n\ndef test_smart_union_does_nested_model_field_counting() -> None:\n    class SubModelA:\n        x: int = 1\n\n    class SubModelB:\n        y: int = 2\n\n    class ModelA:\n        sub: SubModelA\n\n    class ModelB:\n        sub: SubModelB\n\n    model_a_schema = core_schema.model_schema(\n        ModelA,\n        core_schema.model_fields_schema(\n            fields={\n                'sub': core_schema.model_field(\n                    core_schema.model_schema(\n                        SubModelA,\n                        core_schema.model_fields_schema(\n                            fields={\n                                'x': core_schema.model_field(\n                                    core_schema.with_default_schema(core_schema.int_schema(), default=1)\n                                )\n                            }\n                        ),\n                    )\n                )\n            }\n        ),\n    )\n\n    model_b_schema = core_schema.model_schema(\n        ModelB,\n        core_schema.model_fields_schema(\n            fields={\n                'sub': core_schema.model_field(\n                    core_schema.model_schema(\n                        SubModelB,\n                        core_schema.model_fields_schema(\n                            fields={\n                                'y': core_schema.model_field(\n                                    core_schema.with_default_schema(core_schema.int_schema(), default=2)\n                                )\n                            }\n                        ),\n                    )\n                )\n            }\n        ),\n    )\n\n    for choices in permute_choices([model_a_schema, model_b_schema]):\n        validator = SchemaValidator(core_schema.union_schema(choices=choices))\n\n        assert isinstance(validator.validate_python({'sub': {'x': 1}}), ModelA)\n        assert isinstance(validator.validate_python({'sub': {'y': 3}}), ModelB)\n\n        # defaults to leftmost choice if there's a tie\n        assert isinstance(validator.validate_python({'sub': {}}), choices[0]['cls'])\n\n\ndef test_smart_union_does_nested_dataclass_field_counting() -> None:\n    @dataclass\n    class SubModelA:\n        x: int = 1\n\n    @dataclass\n    class SubModelB:\n        y: int = 2\n\n    @dataclass\n    class ModelA:\n        sub: SubModelA\n\n    @dataclass\n    class ModelB:\n        sub: SubModelB\n\n    dc_a_schema = core_schema.dataclass_schema(\n        ModelA,\n        core_schema.dataclass_args_schema(\n            'ModelA',\n            [\n                core_schema.dataclass_field(\n                    'sub',\n                    core_schema.with_default_schema(\n                        core_schema.dataclass_schema(\n                            SubModelA,\n                            core_schema.dataclass_args_schema(\n                                'SubModelA',\n                                [\n                                    core_schema.dataclass_field(\n                                        'x', core_schema.with_default_schema(core_schema.int_schema(), default=1)\n                                    )\n                                ],\n                            ),\n                            ['x'],\n                        ),\n                        default=SubModelA(),\n                    ),\n                )\n            ],\n        ),\n        ['sub'],\n    )\n\n    dc_b_schema = core_schema.dataclass_schema(\n        ModelB,\n        core_schema.dataclass_args_schema(\n            'ModelB',\n            [\n                core_schema.dataclass_field(\n                    'sub',\n                    core_schema.with_default_schema(\n                        core_schema.dataclass_schema(\n                            SubModelB,\n                            core_schema.dataclass_args_schema(\n                                'SubModelB',\n                                [\n                                    core_schema.dataclass_field(\n                                        'y', core_schema.with_default_schema(core_schema.int_schema(), default=2)\n                                    )\n                                ],\n                            ),\n                            ['y'],\n                        ),\n                        default=SubModelB(),\n                    ),\n                )\n            ],\n        ),\n        ['sub'],\n    )\n\n    for choices in permute_choices([dc_a_schema, dc_b_schema]):\n        validator = SchemaValidator(core_schema.union_schema(choices=choices))\n\n        assert isinstance(validator.validate_python({'sub': {'x': 1}}), ModelA)\n        assert isinstance(validator.validate_python({'sub': {'y': 3}}), ModelB)\n\n        # defaults to leftmost choice if there's a tie\n        assert isinstance(validator.validate_python({'sub': {}}), choices[0]['cls'])\n\n\ndef test_smart_union_does_nested_typed_dict_field_counting() -> None:\n    td_a_schema = core_schema.typed_dict_schema(\n        fields={\n            'sub': core_schema.typed_dict_field(\n                core_schema.typed_dict_schema(fields={'x': core_schema.typed_dict_field(core_schema.int_schema())})\n            )\n        }\n    )\n\n    td_b_schema = core_schema.typed_dict_schema(\n        fields={\n            'sub': core_schema.typed_dict_field(\n                core_schema.typed_dict_schema(fields={'y': core_schema.typed_dict_field(core_schema.int_schema())})\n            )\n        }\n    )\n\n    for choices in permute_choices([td_a_schema, td_b_schema]):\n        validator = SchemaValidator(core_schema.union_schema(choices=choices))\n\n        assert set(validator.validate_python({'sub': {'x': 1}})['sub'].keys()) == {'x'}\n        assert set(validator.validate_python({'sub': {'y': 2}})['sub'].keys()) == {'y'}\n\n\ndef test_nested_unions_bubble_up_field_count() -> None:\n    class SubModelX:\n        x1: int = 0\n        x2: int = 0\n        x3: int = 0\n\n    class SubModelY:\n        x1: int = 0\n        x2: int = 0\n        x3: int = 0\n\n    class SubModelZ:\n        z1: int = 0\n        z2: int = 0\n        z3: int = 0\n\n    class SubModelW:\n        w1: int = 0\n        w2: int = 0\n        w3: int = 0\n\n    class ModelA:\n        a: Union[SubModelX, SubModelY]\n\n    class ModelB:\n        b: Union[SubModelZ, SubModelW]\n\n    model_x_schema = core_schema.model_schema(\n        SubModelX,\n        core_schema.model_fields_schema(\n            fields={\n                'x1': core_schema.model_field(core_schema.with_default_schema(core_schema.int_schema(), default=0)),\n                'x2': core_schema.model_field(core_schema.with_default_schema(core_schema.int_schema(), default=0)),\n                'x3': core_schema.model_field(core_schema.with_default_schema(core_schema.int_schema(), default=0)),\n            }\n        ),\n    )\n\n    model_y_schema = core_schema.model_schema(\n        SubModelY,\n        core_schema.model_fields_schema(\n            fields={\n                'x1': core_schema.model_field(core_schema.with_default_schema(core_schema.int_schema(), default=0)),\n                'x2': core_schema.model_field(core_schema.with_default_schema(core_schema.int_schema(), default=0)),\n                'x3': core_schema.model_field(core_schema.with_default_schema(core_schema.int_schema(), default=0)),\n            }\n        ),\n    )\n\n    model_z_schema = core_schema.model_schema(\n        SubModelZ,\n        core_schema.model_fields_schema(\n            fields={\n                'z1': core_schema.model_field(core_schema.with_default_schema(core_schema.int_schema(), default=0)),\n                'z2': core_schema.model_field(core_schema.with_default_schema(core_schema.int_schema(), default=0)),\n                'z3': core_schema.model_field(core_schema.with_default_schema(core_schema.int_schema(), default=0)),\n            }\n        ),\n    )\n\n    model_w_schema = core_schema.model_schema(\n        SubModelW,\n        core_schema.model_fields_schema(\n            fields={\n                'w1': core_schema.model_field(core_schema.with_default_schema(core_schema.int_schema(), default=0)),\n                'w2': core_schema.model_field(core_schema.with_default_schema(core_schema.int_schema(), default=0)),\n                'w3': core_schema.model_field(core_schema.with_default_schema(core_schema.int_schema(), default=0)),\n            }\n        ),\n    )\n\n    model_a_schema_options = [\n        core_schema.union_schema([model_x_schema, model_y_schema]),\n        core_schema.union_schema([model_y_schema, model_x_schema]),\n    ]\n\n    model_b_schema_options = [\n        core_schema.union_schema([model_z_schema, model_w_schema]),\n        core_schema.union_schema([model_w_schema, model_z_schema]),\n    ]\n\n    for model_a_schema in model_a_schema_options:\n        for model_b_schema in model_b_schema_options:\n            validator = SchemaValidator(\n                core_schema.union_schema(\n                    [\n                        core_schema.model_schema(\n                            ModelA,\n                            core_schema.model_fields_schema(fields={'a': core_schema.model_field(model_a_schema)}),\n                        ),\n                        core_schema.model_schema(\n                            ModelB,\n                            core_schema.model_fields_schema(fields={'b': core_schema.model_field(model_b_schema)}),\n                        ),\n                    ]\n                )\n            )\n\n            result = validator.validate_python(\n                {'a': {'x1': 1, 'x2': 2, 'y1': 1, 'y2': 2}, 'b': {'w1': 1, 'w2': 2, 'w3': 3}}\n            )\n            assert isinstance(result, ModelB)\n            assert isinstance(result.b, SubModelW)\n\n\n@pytest.mark.parametrize('extra_behavior', ['forbid', 'ignore', 'allow'])\ndef test_smart_union_extra_behavior(extra_behavior) -> None:\n    class Foo:\n        foo: str = 'foo'\n\n    class Bar:\n        bar: str = 'bar'\n\n    class Model:\n        x: Union[Foo, Bar]\n\n    validator = SchemaValidator(\n        core_schema.model_schema(\n            Model,\n            core_schema.model_fields_schema(\n                fields={\n                    'x': core_schema.model_field(\n                        core_schema.union_schema(\n                            [\n                                core_schema.model_schema(\n                                    Foo,\n                                    core_schema.model_fields_schema(\n                                        fields={\n                                            'foo': core_schema.model_field(\n                                                core_schema.with_default_schema(core_schema.str_schema(), default='foo')\n                                            )\n                                        }\n                                    ),\n                                    extra_behavior=extra_behavior,\n                                ),\n                                core_schema.model_schema(\n                                    Bar,\n                                    core_schema.model_fields_schema(\n                                        fields={\n                                            'bar': core_schema.model_field(\n                                                core_schema.with_default_schema(core_schema.str_schema(), default='bar')\n                                            )\n                                        }\n                                    ),\n                                    extra_behavior=extra_behavior,\n                                ),\n                            ]\n                        )\n                    )\n                }\n            ),\n        )\n    )\n\n    assert isinstance(validator.validate_python({'x': {'foo': 'foo'}}).x, Foo)\n    assert isinstance(validator.validate_python({'x': {'bar': 'bar'}}).x, Bar)\n", "tests/validators/test_json_or_python.py": "import pytest\n\nfrom pydantic_core import SchemaValidator, ValidationError\nfrom pydantic_core import core_schema as cs\n\n\ndef test_json_or_python():\n    class Foo(str):\n        def __eq__(self, o: object) -> bool:\n            if isinstance(o, Foo) and super().__eq__(o):\n                return True\n            return False\n\n    s = cs.json_or_python_schema(\n        json_schema=cs.no_info_after_validator_function(Foo, cs.str_schema()), python_schema=cs.is_instance_schema(Foo)\n    )\n    v = SchemaValidator(s)\n\n    assert v.validate_python(Foo('abc')) == Foo('abc')\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python('abc')\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'is_instance_of',\n            'loc': (),\n            'msg': 'Input should be an instance of test_json_or_python.<locals>.Foo',\n            'input': 'abc',\n            'ctx': {'class': 'test_json_or_python.<locals>.Foo'},\n        }\n    ]\n\n    assert v.validate_json('\"abc\"') == Foo('abc')\n", "tests/validators/test_bool.py": "import re\n\nimport pytest\n\nfrom pydantic_core import SchemaValidator, ValidationError, core_schema\n\nfrom ..conftest import Err, PyAndJson, plain_repr\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        (False, False),\n        (True, True),\n        (0, False),\n        (0.0, False),\n        (1, True),\n        (1.0, True),\n        ('yes', True),\n        ('no', False),\n        ('true', True),\n        ('false', False),\n        (\n            'cheese',\n            Err(\n                'Input should be a valid boolean, '\n                \"unable to interpret input [type=bool_parsing, input_value='cheese', input_type=str]\"\n            ),\n        ),\n        (2, Err('Input should be a valid boolean, unable to interpret input [type=bool_parsing, input_value=2')),\n        ([], Err('Input should be a valid boolean [type=bool_type, input_value=[], input_type=list]')),\n        (1.1, Err('Input should be a valid boolean [type=bool_type, input_value=1.1, input_type=float]')),\n        (2, Err('unable to interpret input [type=bool_parsing, input_value=2, input_type=int]')),\n        (2.0, Err('unable to interpret input [type=bool_parsing, input_value=2.0, input_type=float]')),\n    ],\n)\ndef test_bool(py_and_json: PyAndJson, input_value, expected):\n    v = py_and_json({'type': 'bool'})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_test(input_value)\n        assert v.isinstance_test(input_value) is False\n    else:\n        assert v.validate_test(input_value) == expected\n        assert v.isinstance_test(input_value) is True\n\n\ndef test_bool_strict(py_and_json: PyAndJson):\n    v = py_and_json({'type': 'bool', 'strict': True})\n    assert v.validate_test(True) is True\n    error_message = \"Input should be a valid boolean [type=bool_type, input_value='true', input_type=str]\"\n    with pytest.raises(ValidationError, match=re.escape(error_message)):\n        v.validate_test('true')\n\n\ndef test_bool_error(pydantic_version):\n    v = SchemaValidator({'type': 'bool'})\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python('wrong')\n\n    assert str(exc_info.value) == (\n        '1 validation error for bool\\n'\n        '  Input should be a valid boolean, '\n        \"unable to interpret input [type=bool_parsing, input_value='wrong', input_type=str]\\n\"\n        f'    For further information visit https://errors.pydantic.dev/{pydantic_version}/v/bool_parsing'\n    )\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'bool_parsing',\n            'loc': (),\n            'msg': 'Input should be a valid boolean, unable to interpret input',\n            'input': 'wrong',\n        }\n    ]\n\n\ndef test_bool_repr():\n    v = SchemaValidator({'type': 'bool'})\n    assert (\n        plain_repr(v)\n        == 'SchemaValidator(title=\"bool\",validator=Bool(BoolValidator{strict:false}),definitions=[],cache_strings=True)'\n    )\n    v = SchemaValidator({'type': 'bool', 'strict': True})\n    assert (\n        plain_repr(v)\n        == 'SchemaValidator(title=\"bool\",validator=Bool(BoolValidator{strict:true}),definitions=[],cache_strings=True)'\n    )\n\n\ndef test_bool_key(py_and_json: PyAndJson):\n    v = py_and_json({'type': 'dict', 'keys_schema': {'type': 'bool'}, 'values_schema': {'type': 'int'}})\n    assert v.validate_test({True: 1, False: 2}) == {True: 1, False: 2}\n    assert v.validate_test({'true': 1, 'off': 2}) == {True: 1, False: 2}\n    assert v.validate_test({'true': 1, 'off': 2}, strict=False) == {True: 1, False: 2}\n    with pytest.raises(ValidationError, match='Input should be a valid boolean'):\n        v.validate_python({'true': 1, 'off': 2}, strict=True)\n    assert v.validate_json('{\"true\": 1, \"off\": 2}', strict=True) == {True: 1, False: 2}\n\n\ndef test_validate_assignment_not_supported() -> None:\n    \"\"\"\n    This test is not bool specific, the implementation is the\n    same for all validators (it's the default impl on the Validator trait).\n    But we need to test this somewhere, so it is going in the bool tests for now.\n    \"\"\"\n    v = SchemaValidator(core_schema.bool_schema())\n    with pytest.raises(TypeError, match='validate_assignment is not supported for bool'):\n        v.validate_assignment(False, 'foo', True)\n", "tests/validators/test_bytes.py": "import re\nfrom typing import Any, Dict\n\nimport pytest\n\nfrom pydantic_core import SchemaValidator, ValidationError\n\nfrom ..conftest import Err, PyAndJson\n\n\ndef test_strict_bytes_validator():\n    v = SchemaValidator({'type': 'bytes', 'strict': True})\n\n    assert v.validate_python(b'foo') == b'foo'\n    assert v.validate_json('\"foo\"') == b'foo'\n\n    with pytest.raises(ValidationError, match='Input should be a valid bytes'):\n        v.validate_python('foo')\n    with pytest.raises(ValidationError, match='Input should be a valid bytes'):\n        v.validate_python(bytearray(b'foo'))\n\n\ndef test_lax_bytes_validator():\n    v = SchemaValidator({'type': 'bytes'})\n\n    assert v.validate_python(b'foo') == b'foo'\n    assert v.validate_python('foo') == b'foo'\n    assert v.validate_python(bytearray(b'foo')) == b'foo'\n\n    assert v.validate_json('\"foo\"') == b'foo'\n\n    assert v.validate_python('\ud83d\udc08 Hello') == b'\\xf0\\x9f\\x90\\x88 Hello'\n    # `.to_str()` Returns a `UnicodeEncodeError` if the input is not valid unicode (containing unpaired surrogates).\n    # https://github.com/PyO3/pyo3/blob/6503128442b8f3e767c663a6a8d96376d7fb603d/src/types/string.rs#L477\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python('\ud83d\udc08 Hello \\ud800World')\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'string_unicode',\n            'loc': (),\n            'msg': 'Input should be a valid string, unable to parse raw data as a unicode string',\n            'input': '\ud83d\udc08 Hello \\ud800World',\n        }\n    ]\n\n\n@pytest.mark.parametrize(\n    'opts,input,expected',\n    [\n        ({}, b'foo', b'foo'),\n        ({'max_length': 5}, b'foo', b'foo'),\n        ({'max_length': 5}, b'foobar', Err('Data should have at most 5 bytes')),\n        ({'min_length': 2}, b'foo', b'foo'),\n        ({'min_length': 2}, b'f', Err('Data should have at least 2 bytes')),\n        ({'min_length': 1, 'max_length': 6, 'strict': True}, b'bytes?', b'bytes?'),\n    ],\n)\ndef test_constrained_bytes_python_bytes(opts: Dict[str, Any], input, expected):\n    v = SchemaValidator({'type': 'bytes', **opts})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_python(input)\n    else:\n        assert v.validate_python(input) == expected\n\n\n@pytest.mark.parametrize(\n    'opts,input,expected',\n    [\n        ({}, 'foo', b'foo'),\n        ({'max_length': 5}, 'foo', b'foo'),\n        ({'max_length': 5}, 'foobar', Err('Data should have at most 5 bytes')),\n        ({'min_length': 2}, 'foo', b'foo'),\n        ({'min_length': 2}, 'f', Err('Data should have at least 2 bytes')),\n        ({}, 1, Err('Input should be a valid bytes')),\n        ({}, 1.0, Err('Input should be a valid bytes')),\n        ({}, [], Err('Input should be a valid bytes')),\n        ({}, {}, Err('Input should be a valid bytes')),\n    ],\n)\ndef test_constrained_bytes(py_and_json: PyAndJson, opts: Dict[str, Any], input, expected):\n    v = py_and_json({'type': 'bytes', **opts})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_test(input)\n        assert v.isinstance_test(input) is False\n    else:\n        assert v.validate_test(input) == expected\n        assert v.isinstance_test(input) is True\n\n\ndef test_union():\n    v = SchemaValidator({'type': 'union', 'choices': [{'type': 'str'}, {'type': 'bytes'}], 'strict': True})\n    assert v.validate_python('oh, a string') == 'oh, a string'\n    assert v.validate_python(b'oh, bytes') == b'oh, bytes'\n\n\ndef test_length_ctx():\n    v = SchemaValidator({'type': 'bytes', 'min_length': 2, 'max_length': 3})\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python(b'1')\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'bytes_too_short',\n            'loc': (),\n            'msg': 'Data should have at least 2 bytes',\n            'input': b'1',\n            'ctx': {'min_length': 2},\n        }\n    ]\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python(b'1234')\n\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'bytes_too_long',\n            'loc': (),\n            'msg': 'Data should have at most 3 bytes',\n            'input': b'1234',\n            'ctx': {'max_length': 3},\n        }\n    ]\n", "tests/validators/test_string.py": "import re\nimport sys\nfrom decimal import Decimal\nfrom numbers import Number\nfrom typing import Any, Dict, Union\n\nimport pytest\n\nfrom pydantic_core import SchemaError, SchemaValidator, ValidationError, core_schema\n\nfrom ..conftest import Err, PyAndJson, plain_repr\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ('foobar', 'foobar'),\n        (123, Err('Input should be a valid string [type=string_type, input_value=123, input_type=int]')),\n        (123.456, Err('Input should be a valid string [type=string_type, input_value=123.456, input_type=float]')),\n        (False, Err('Input should be a valid string [type=string_type')),\n        (True, Err('Input should be a valid string [type=string_type')),\n        ([], Err('Input should be a valid string [type=string_type, input_value=[], input_type=list]')),\n    ],\n)\ndef test_str(py_and_json: PyAndJson, input_value, expected):\n    v = py_and_json({'type': 'str'})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_test(input_value)\n    else:\n        assert v.validate_test(input_value) == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ('foobar', 'foobar'),\n        ('\ud83d\udc08 Hello \\ud800World', '\ud83d\udc08 Hello \\ud800World'),\n        (b'foobar', 'foobar'),\n        (bytearray(b'foobar'), 'foobar'),\n        (\n            b'\\x81',\n            Err('Input should be a valid string, unable to parse raw data as a unicode string [type=string_unicode'),\n        ),\n        (\n            bytearray(b'\\x81'),\n            Err('Input should be a valid string, unable to parse raw data as a unicode string [type=string_unicode'),\n        ),\n        # null bytes are very annoying, but we can't really block them here\n        (b'\\x00', '\\x00'),\n        (123, Err('Input should be a valid string [type=string_type, input_value=123, input_type=int]')),\n        (\n            Decimal('123'),\n            Err(\"Input should be a valid string [type=string_type, input_value=Decimal('123'), input_type=Decimal]\"),\n        ),\n    ],\n)\ndef test_str_not_json(input_value, expected):\n    v = SchemaValidator({'type': 'str'})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_python(input_value)\n    else:\n        assert v.validate_python(input_value) == expected\n\n\n@pytest.mark.parametrize(\n    'kwargs,input_value,expected',\n    [\n        ({}, 'abc', 'abc'),\n        ({'strict': True}, 'Foobar', 'Foobar'),\n        ({'to_upper': True}, 'fooBar', 'FOOBAR'),\n        ({'to_lower': True}, 'fooBar', 'foobar'),\n        ({'strip_whitespace': True}, ' foobar  ', 'foobar'),\n        ({'strip_whitespace': True, 'to_upper': True}, ' fooBar', 'FOOBAR'),\n        ({'min_length': 5}, '12345', '12345'),\n        ({'min_length': 5}, '1234', Err('String should have at least 5 characters [type=string_too_short')),\n        ({'max_length': 5}, '12345', '12345'),\n        ({'max_length': 5}, '123456', Err('String should have at most 5 characters [type=string_too_long')),\n        ({'pattern': r'^\\d+$'}, '12345', '12345'),\n        ({'pattern': r'\\d+$'}, 'foobar 123', 'foobar 123'),\n        ({'pattern': r'^\\d+$'}, '12345a', Err(\"String should match pattern '^\\\\d+$' [type=string_pattern_mismatch\")),\n        # strip comes after length check\n        ({'max_length': 5, 'strip_whitespace': True}, '1234  ', '1234'),\n        # to_upper and strip comes after pattern check\n        ({'to_upper': True, 'pattern': 'abc'}, 'abc', 'ABC'),\n        ({'strip_whitespace': True, 'pattern': r'\\d+$'}, 'foobar 123 ', 'foobar 123'),\n        ({'min_length': 1}, '\ud83d\udc08 Hello', '\ud83d\udc08 Hello'),\n    ],\n)\ndef test_constrained_str(py_and_json: PyAndJson, kwargs: Dict[str, Any], input_value, expected):\n    v = py_and_json({'type': 'str', **kwargs})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_test(input_value)\n    else:\n        assert v.validate_test(input_value) == expected\n\n\n@pytest.mark.parametrize(\n    'kwargs,input_value,expected',\n    [\n        ({}, b'abc', 'abc'),\n        ({'strict': True}, 'Foobar', 'Foobar'),\n        (\n            {'strict': True},\n            123,\n            Err('Input should be a valid string [type=string_type, input_value=123, input_type=int]'),\n        ),\n    ],\n)\ndef test_constrained_str_py_only(kwargs: Dict[str, Any], input_value, expected):\n    v = SchemaValidator({'type': 'str', **kwargs})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_python(input_value)\n    else:\n        assert v.validate_python(input_value) == expected\n\n\ndef test_unicode_error():\n    # `.to_str()` Returns a `UnicodeEncodeError` if the input is not valid unicode (containing unpaired surrogates).\n    # https://github.com/PyO3/pyo3/blob/6503128442b8f3e767c663a6a8d96376d7fb603d/src/types/string.rs#L477\n    v = SchemaValidator({'type': 'str', 'min_length': 1})\n    assert v.validate_python('\ud83d\udc08 Hello') == '\ud83d\udc08 Hello'\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python('\ud83d\udc08 Hello \\ud800World')\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'string_unicode',\n            'loc': (),\n            'msg': 'Input should be a valid string, unable to parse raw data as a unicode string',\n            'input': '\ud83d\udc08 Hello \\ud800World',\n        }\n    ]\n\n\n@pytest.mark.parametrize(\n    ('data', 'max_length', 'error'),\n    [\n        pytest.param('test', 5, None, id='short string'),\n        pytest.param('test long', 5, 'String should have at most 5 characters', id='long string'),\n        pytest.param('\u241b\u2bcb\u2103\u25a4', 5, None, id='short string with unicode characters'),\n        pytest.param(\n            '\u241b\u2bcb\u2103\u25a4\u2a65\u282b\u2cfc\u28ea\u2a3a\u2712\u29d0\u2673\u2a5a\u23ed\u23e3\u2365\u2519\u29c3\u2c04\u253d\u23cf\u265c',\n            5,\n            'String should have at most 5 characters',\n            id='long string with unicode characters',\n        ),\n        pytest.param('\u0430' * 25, 32, None, id='a lot of `\u0430`s'),\n    ],\n)\ndef test_str_constrained(data: str, max_length: int, error: Union[re.Pattern, None]):\n    v = SchemaValidator({'type': 'str', 'max_length': max_length})\n    if error is None:\n        assert v.validate_python(data) == data\n    else:\n        with pytest.raises(ValidationError, match=error):\n            v.validate_python(data)\n\n\ndef test_str_constrained_config():\n    v = SchemaValidator({'type': 'str'}, {'str_max_length': 5})\n    assert v.validate_python('test') == 'test'\n\n    with pytest.raises(ValidationError, match='String should have at most 5 characters'):\n        v.validate_python('test long')\n\n\n@pytest.mark.parametrize('engine', [None, 'rust-regex', 'python-re'])\ndef test_invalid_regex(engine):\n    # TODO uncomment and fix once #150 is done\n    # with pytest.raises(SchemaError) as exc_info:\n    #     SchemaValidator({'type': 'str', 'pattern': 123})\n    # assert exc_info.value.args[0] == (\n    #     'Error building \"str\" validator:\\n  TypeError: \\'int\\' object cannot be converted to \\'PyString\\''\n    # )\n    with pytest.raises(SchemaError) as exc_info:\n        SchemaValidator(core_schema.str_schema(pattern='(abc', regex_engine=engine))\n\n    if engine is None or engine == 'rust-regex':\n        assert exc_info.value.args[0] == (\n            'Error building \"str\" validator:\\n'\n            '  SchemaError: regex parse error:\\n'\n            '    (abc\\n'\n            '    ^\\n'\n            'error: unclosed group'\n        )\n    elif engine == 'python-re':\n        prefix = 'PatternError' if sys.version_info >= (3, 13) else 'error'\n        assert exc_info.value.args[0] == (\n            f'Error building \"str\" validator:\\n  {prefix}: missing ), unterminated subpattern at position 0'\n        )\n\n\n@pytest.mark.parametrize('engine', [None, 'rust-regex', 'python-re'])\ndef test_regex_error(engine):\n    v = SchemaValidator(core_schema.str_schema(pattern='11', regex_engine=engine))\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python('12')\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'string_pattern_mismatch',\n            'loc': (),\n            'msg': \"String should match pattern '11'\",\n            'input': '12',\n            'ctx': {'pattern': '11'},\n        }\n    ]\n\n\ndef test_default_validator():\n    v = SchemaValidator(core_schema.str_schema(strict=True, to_lower=False), {'str_strip_whitespace': False})\n    assert (\n        plain_repr(v)\n        == 'SchemaValidator(title=\"str\",validator=Str(StrValidator{strict:true,coerce_numbers_to_str:false}),definitions=[],cache_strings=True)'\n    )\n\n\n@pytest.fixture(scope='session', name='FruitEnum')\ndef fruit_enum_fixture():\n    from enum import Enum\n\n    class FruitEnum(str, Enum):\n        pear = 'pear'\n        banana = 'banana'\n\n    return FruitEnum\n\n\n@pytest.mark.parametrize('to_lower', [False, True], ids=repr)\ndef test_strict_subclass(to_lower: bool):\n    v = SchemaValidator(core_schema.str_schema(strict=True, to_lower=to_lower))\n\n    class StrSubclass(str):\n        pass\n\n    res = v.validate_python(StrSubclass('ABC'))\n    assert res == 'abc' if to_lower else 'ABC'\n\n\n@pytest.mark.parametrize('kwargs', [{}, {'to_lower': True}], ids=repr)\ndef test_lax_subclass(FruitEnum, kwargs):\n    v = SchemaValidator(core_schema.str_schema(**kwargs))\n    assert v.validate_python('foobar') == 'foobar'\n    assert v.validate_python(b'foobar') == 'foobar'\n    p = v.validate_python(FruitEnum.pear)\n    assert p == 'pear'\n    assert type(p) is str\n    assert repr(p) == \"'pear'\"\n\n\n@pytest.mark.parametrize('kwargs', [{}, {'to_lower': True}], ids=repr)\ndef test_lax_subclass_plain_enum(kwargs):\n    v = SchemaValidator(core_schema.str_schema(**kwargs))\n\n    from enum import Enum\n\n    class PlainEnum(Enum):\n        ONE = 'one'\n\n    p = v.validate_python(PlainEnum.ONE)\n    assert p == 'one'\n    assert type(p) is str\n    assert repr(p) == \"'one'\"\n\n\ndef test_subclass_preserved() -> None:\n    class StrSubclass(str):\n        pass\n\n    v = SchemaValidator(core_schema.str_schema())\n\n    assert not isinstance(v.validate_python(StrSubclass('')), StrSubclass)\n    assert not isinstance(v.validate_python(StrSubclass(''), strict=True), StrSubclass)\n\n    # unions do a first pass in strict mode\n    # so verify that they don't match the str schema in strict mode\n    # and preserve the type\n    v = SchemaValidator(core_schema.union_schema([core_schema.str_schema(), core_schema.int_schema()]))\n\n    assert not isinstance(v.validate_python(StrSubclass('')), StrSubclass)\n    assert not isinstance(v.validate_python(StrSubclass(''), strict=True), StrSubclass)\n\n\ndef test_coerce_numbers_to_str_disabled_in_strict_mode() -> None:\n    config = core_schema.CoreConfig(coerce_numbers_to_str=True)\n\n    v = SchemaValidator(core_schema.str_schema(strict=True), config)\n    with pytest.raises(ValidationError):\n        v.validate_python(42)\n    with pytest.raises(ValidationError):\n        v.validate_json('42')\n\n\ndef test_coerce_numbers_to_str_raises_for_bool() -> None:\n    config = core_schema.CoreConfig(coerce_numbers_to_str=True)\n\n    v = SchemaValidator(core_schema.str_schema(), config)\n    with pytest.raises(ValidationError):\n        v.validate_python(True)\n    with pytest.raises(ValidationError):\n        v.validate_json(False)\n\n\n@pytest.mark.parametrize(\n    ('number', 'expected_str'),\n    [\n        pytest.param(42, '42', id='42'),\n        pytest.param(42.0, '42.0', id='42.0'),\n        pytest.param(Decimal('42.0'), '42.0', id=\"Decimal('42.0')\"),\n    ],\n)\ndef test_coerce_numbers_to_str(number: Number, expected_str: str) -> None:\n    config = core_schema.CoreConfig(coerce_numbers_to_str=True)\n\n    v = SchemaValidator(core_schema.str_schema(), config)\n    assert v.validate_python(number) == expected_str\n\n\n@pytest.mark.parametrize(\n    ('number', 'expected_str'),\n    [\n        pytest.param('42', '42', id='42'),\n        pytest.param('42.0', '42', id='42.0'),\n        pytest.param('42.13', '42.13', id='42.13'),\n    ],\n)\ndef test_coerce_numbers_to_str_from_json(number: str, expected_str: str) -> None:\n    config = core_schema.CoreConfig(coerce_numbers_to_str=True)\n\n    v = SchemaValidator(core_schema.str_schema(), config)\n    assert v.validate_json(number) == expected_str\n\n\n@pytest.mark.parametrize('mode', (None, 'schema', 'config'))\ndef test_backtracking_regex_rust_unsupported(mode) -> None:\n    pattern = r'r(#*)\".*?\"\\1'\n\n    with pytest.raises(SchemaError) as exc_info:\n        if mode is None:\n            # rust-regex is the default\n            SchemaValidator(core_schema.str_schema(pattern=pattern))\n        elif mode == 'schema':\n            SchemaValidator(core_schema.str_schema(pattern=pattern, regex_engine='rust-regex'))\n        elif mode == 'config':\n            SchemaValidator(core_schema.str_schema(pattern=pattern), core_schema.CoreConfig(regex_engine='rust-regex'))\n\n    assert exc_info.value.args[0] == (\n        'Error building \"str\" validator:\\n'\n        '  SchemaError: regex parse error:\\n'\n        '    r(#*)\".*?\"\\\\1\\n'\n        '              ^^\\n'\n        'error: backreferences are not supported'\n    )\n\n\n@pytest.mark.parametrize('mode', ('schema', 'config'))\ndef test_backtracking_regex_python(mode) -> None:\n    pattern = r'r(#*)\".*?\"\\1'\n\n    if mode == 'schema':\n        v = SchemaValidator(core_schema.str_schema(pattern=pattern, regex_engine='python-re'))\n    elif mode == 'config':\n        v = SchemaValidator(core_schema.str_schema(pattern=pattern), core_schema.CoreConfig(regex_engine='python-re'))\n    assert v.validate_python('r\"\"') == 'r\"\"'\n    assert v.validate_python('r#\"\"#') == 'r#\"\"#'\n    with pytest.raises(ValidationError):\n        # not a valid match for the pattern\n        v.validate_python('r#\"#')\n\n\n@pytest.mark.parametrize('number', (42, 443, 10242))\ndef test_coerce_numbers_to_str_schema(number: int):\n    v = SchemaValidator(core_schema.str_schema(coerce_numbers_to_str=True))\n    assert v.validate_python(number) == str(number)\n    assert v.validate_json(str(number)) == str(number)\n\n\n@pytest.mark.parametrize('number', (42, 443, 10242))\ndef test_coerce_numbers_to_str_schema_precedence(number: int):\n    config = core_schema.CoreConfig(coerce_numbers_to_str=False)\n    v = SchemaValidator(core_schema.str_schema(coerce_numbers_to_str=True), config=config)\n    assert v.validate_python(number) == str(number)\n    assert v.validate_json(str(number)) == str(number)\n\n    config = core_schema.CoreConfig(coerce_numbers_to_str=True)\n    v = SchemaValidator(core_schema.str_schema(coerce_numbers_to_str=False), config=config)\n    with pytest.raises(ValidationError):\n        v.validate_python(number)\n    with pytest.raises(ValidationError):\n        v.validate_json(str(number))\n\n\n@pytest.mark.parametrize('number', (42, 443, 10242))\ndef test_coerce_numbers_to_str_schema_with_strict_mode(number: int):\n    v = SchemaValidator(core_schema.str_schema(coerce_numbers_to_str=True, strict=True))\n    with pytest.raises(ValidationError):\n        v.validate_python(number)\n    with pytest.raises(ValidationError):\n        v.validate_json(str(number))\n\n\n@pytest.mark.parametrize('engine', [None, 'rust-regex', 'python-re'])\ndef test_compiled_regex(engine) -> None:\n    v = SchemaValidator(core_schema.str_schema(pattern=re.compile('abc', re.IGNORECASE), regex_engine=engine))\n    assert v.validate_python('abc') == 'abc'\n    assert v.validate_python('ABC') == 'ABC'\n", "tests/validators/test_model.py": "import re\nfrom copy import deepcopy\nfrom typing import Any, Callable, Dict, List, Set, Tuple\n\nimport pytest\nfrom dirty_equals import HasRepr, IsInstance\n\nfrom pydantic_core import SchemaError, SchemaValidator, ValidationError, core_schema\n\n\ndef test_model_class():\n    class MyModel:\n        # this is not required, but it avoids `__pydantic_fields_set__` being included in `__dict__`\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n        field_a: str\n        field_b: int\n\n    v = SchemaValidator(\n        core_schema.model_schema(\n            MyModel,\n            core_schema.model_fields_schema(\n                {\n                    'field_a': core_schema.model_field(core_schema.str_schema()),\n                    'field_b': core_schema.model_field(core_schema.int_schema()),\n                }\n            ),\n        )\n    )\n    assert repr(v).startswith('SchemaValidator(title=\"MyModel\", validator=Model(\\n')\n    m = v.validate_python({'field_a': 'test', 'field_b': 12})\n    assert isinstance(m, MyModel)\n    assert m.field_a == 'test'\n    assert m.field_b == 12\n    assert m.__pydantic_extra__ is None\n    assert m.__pydantic_fields_set__ == {'field_a', 'field_b'}\n    assert m.__dict__ == {'field_a': 'test', 'field_b': 12}\n\n    m2 = v.validate_python({'field_a': 'test', 'field_b': 12}, strict=True)\n    assert isinstance(m2, MyModel)\n    assert m2.field_a == 'test'\n    assert m2.field_b == 12\n    assert m2.__pydantic_extra__ is None\n    assert m2.__pydantic_fields_set__ == {'field_a', 'field_b'}\n    assert m2.__dict__ == {'field_a': 'test', 'field_b': 12}\n\n\ndef test_model_class_extra():\n    class MyModel:\n        # this is not required, but it avoids `__pydantic_fields_set__` being included in `__dict__`\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n        field_a: str\n        field_b: int\n\n    v = SchemaValidator(\n        core_schema.model_schema(\n            MyModel,\n            core_schema.model_fields_schema(\n                {\n                    'field_a': core_schema.model_field(core_schema.str_schema()),\n                    'field_b': core_schema.model_field(core_schema.int_schema()),\n                },\n                extra_behavior='allow',\n            ),\n        )\n    )\n    m = v.validate_python({'field_a': 'test', 'field_b': 12, 'field_c': 'extra'})\n    assert isinstance(m, MyModel)\n    assert m.field_a == 'test'\n    assert m.field_b == 12\n    assert m.__pydantic_extra__ == {'field_c': 'extra'}\n    assert m.__pydantic_fields_set__ == {'field_a', 'field_b', 'field_c'}\n    assert m.__dict__ == {'field_a': 'test', 'field_b': 12}\n\n\ndef test_model_class_extra_forbid():\n    class MyModel:\n        class Meta:\n            pass\n\n        # this is not required, but it avoids `__pydantic_fields_set__` being included in `__dict__`\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n        field_a: str\n        field_b: int\n\n    class Wrapper:\n        def __init__(self, inner):\n            self._inner = inner\n\n        def __dir__(self):\n            return dir(self._inner)\n\n        def __getattr__(self, key):\n            return getattr(self._inner, key)\n\n    v = SchemaValidator(\n        core_schema.model_schema(\n            MyModel,\n            core_schema.model_fields_schema(\n                {\n                    'field_a': core_schema.model_field(core_schema.str_schema()),\n                    'field_b': core_schema.model_field(core_schema.int_schema()),\n                },\n                extra_behavior='forbid',\n            ),\n        )\n    )\n    m = v.validate_python({'field_a': 'test', 'field_b': 12})\n    assert isinstance(m, MyModel)\n    assert m.field_a == 'test'\n    assert m.field_b == 12\n\n    # try revalidating from the model's attributes\n    m = v.validate_python(Wrapper(m), from_attributes=True)\n\n    with pytest.raises(ValidationError) as exc_info:\n        m = v.validate_python({'field_a': 'test', 'field_b': 12, 'field_c': 'extra'})\n\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'extra_forbidden', 'loc': ('field_c',), 'msg': 'Extra inputs are not permitted', 'input': 'extra'}\n    ]\n\n\n@pytest.mark.parametrize('extra_behavior', ['allow', 'ignore', 'forbid'])\ndef test_model_class_extra_forbid_from_attributes(extra_behavior: str):\n    # iterating attributes includes much more than just __dict__, so need\n    # careful interaction with __extra__\n\n    class MyModel:\n        # this is not required, but it avoids `__pydantic_fields_set__` being included in `__dict__`\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n        field_a: str\n        field_b: int\n\n    class Data:\n        # https://github.com/pydantic/pydantic/issues/9242\n        class Meta:\n            pass\n\n        def __init__(self, **values):\n            self.__dict__.update(values)\n\n    v = SchemaValidator(\n        core_schema.model_schema(\n            MyModel,\n            core_schema.model_fields_schema(\n                {\n                    'field_a': core_schema.model_field(core_schema.str_schema()),\n                    'field_b': core_schema.model_field(core_schema.int_schema()),\n                },\n                extra_behavior=extra_behavior,\n                from_attributes=True,\n            ),\n        )\n    )\n    m = v.validate_python(Data(field_a='test', field_b=12))\n    assert isinstance(m, MyModel)\n    assert m.field_a == 'test'\n    assert m.field_b == 12\n\n    # with from_attributes, extra is basically ignored\n    m = v.validate_python(Data(field_a='test', field_b=12, field_c='extra'))\n    assert isinstance(m, MyModel)\n    assert m.field_a == 'test'\n    assert m.field_b == 12\n    assert not hasattr(m, 'field_c')\n\n\ndef test_model_class_setattr():\n    setattr_calls = []\n\n    class MyModel:\n        field_a: str\n\n        def __setattr__(self, key, value):\n            setattr_calls.append((key, value))\n            # don't do anything\n\n    m1 = MyModel()\n    m1.foo = 'bar'\n    assert not hasattr(m1, 'foo')\n    assert setattr_calls == [('foo', 'bar')]\n    setattr_calls.clear()\n\n    v = SchemaValidator(\n        {\n            'type': 'model',\n            'cls': MyModel,\n            'schema': {\n                'type': 'model-fields',\n                'fields': {'field_a': {'type': 'model-field', 'schema': {'type': 'str'}}},\n            },\n        }\n    )\n    m = v.validate_python({'field_a': 'test'})\n    assert isinstance(m, MyModel)\n    assert m.field_a == 'test'\n    assert m.__pydantic_fields_set__ == {'field_a'}\n    assert setattr_calls == []\n\n\ndef test_model_class_root_validator_wrap():\n    class MyModel:\n        def __init__(self, **kwargs: Any) -> None:\n            self.__dict__.update(kwargs)\n\n    def f(\n        input_value: Dict[str, Any],\n        validator: Callable[[Dict[str, Any]], Dict[str, Any]],\n        info: core_schema.ValidationInfo,\n    ):\n        assert input_value['field_a'] == 123\n        output = validator(input_value)\n        return output\n\n    schema = core_schema.model_schema(\n        MyModel,\n        core_schema.with_info_wrap_validator_function(\n            f, core_schema.model_fields_schema({'field_a': core_schema.model_field(core_schema.int_schema())})\n        ),\n    )\n\n    v = SchemaValidator(schema)\n    m = v.validate_python({'field_a': 123})\n    assert m.field_a == 123\n\n    with pytest.raises(ValidationError) as e:\n        v.validate_python({'field_a': 456})\n\n    assert e.value.errors(include_url=False) == [\n        {\n            'type': 'assertion_error',\n            'loc': (),\n            'msg': 'Assertion failed, assert 456 == 123',\n            'input': {'field_a': 456},\n            'ctx': {'error': HasRepr(repr(AssertionError('assert 456 == 123')))},\n        }\n    ]\n\n\ndef test_model_class_root_validator_before():\n    class MyModel:\n        def __init__(self, **kwargs: Any) -> None:\n            self.__dict__.update(kwargs)\n\n    def f(input_value: Dict[str, Any], info: core_schema.ValidationInfo):\n        assert input_value['field_a'] == 123\n        return input_value\n\n    schema = core_schema.model_schema(\n        MyModel,\n        core_schema.with_info_before_validator_function(\n            f, core_schema.model_fields_schema({'field_a': core_schema.model_field(core_schema.int_schema())})\n        ),\n    )\n\n    v = SchemaValidator(schema)\n    m = v.validate_python({'field_a': 123})\n    assert m.field_a == 123\n\n    with pytest.raises(ValidationError) as e:\n        v.validate_python({'field_a': 456})\n\n    assert e.value.errors(include_url=False) == [\n        {\n            'type': 'assertion_error',\n            'loc': (),\n            'msg': 'Assertion failed, assert 456 == 123',\n            'input': {'field_a': 456},\n            'ctx': {'error': HasRepr(repr(AssertionError('assert 456 == 123')))},\n        }\n    ]\n\n\ndef test_model_class_root_validator_after():\n    class MyModel:\n        def __init__(self, **kwargs: Any) -> None:\n            self.__dict__.update(kwargs)\n\n    def f(input_value_and_fields_set: Tuple[Dict[str, Any], Set[str]]):\n        input_value, _, _ = input_value_and_fields_set\n        assert input_value['field_a'] == 123\n        return input_value_and_fields_set\n\n    schema = core_schema.model_schema(\n        MyModel,\n        core_schema.no_info_after_validator_function(\n            f, core_schema.model_fields_schema({'field_a': core_schema.model_field(core_schema.int_schema())})\n        ),\n    )\n\n    v = SchemaValidator(schema)\n    m = v.validate_python({'field_a': 123})\n    assert m.field_a == 123\n\n    with pytest.raises(ValidationError) as e:\n        v.validate_python({'field_a': 456})\n\n    assert e.value.errors(include_url=False) == [\n        {\n            'type': 'assertion_error',\n            'loc': (),\n            'msg': 'Assertion failed, assert 456 == 123',\n            'input': {'field_a': 456},\n            'ctx': {'error': HasRepr(repr(AssertionError('assert 456 == 123')))},\n        }\n    ]\n\n\n@pytest.mark.parametrize('mode', ['before', 'after', 'wrap'])\ndef test_function_ask(mode):\n    class MyModel:\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n\n    def f(input_value, info):\n        return input_value\n\n    SchemaValidator(\n        {\n            'type': 'model',\n            'cls': MyModel,\n            'schema': {\n                'type': f'function-{mode}',\n                'function': {'type': 'with-info', 'function': f},\n                'schema': {\n                    'type': 'model-fields',\n                    'fields': {'field_a': {'type': 'model-field', 'schema': {'type': 'str'}}},\n                },\n            },\n        }\n    )\n\n\ndef test_function_plain_ask():\n    class MyModel:\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n\n    def f(input_value):\n        return input_value, {1: 2}, {'field_a'}\n\n    v = SchemaValidator({'type': 'model', 'cls': MyModel, 'schema': core_schema.no_info_plain_validator_function(f)})\n    m = v.validate_python({'field_a': 'test'})\n    assert isinstance(m, MyModel)\n    assert m.__dict__ == {'field_a': 'test'}\n    assert m.__pydantic_extra__ == {1: 2}\n    assert m.__pydantic_fields_set__ == {'field_a'}\n\n\ndef test_union_sub_schema():\n    class MyModel:\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n\n    v = SchemaValidator(\n        {\n            'type': 'model',\n            'cls': MyModel,\n            'schema': {\n                'type': 'union',\n                'choices': [\n                    {'type': 'model-fields', 'fields': {'foo': {'type': 'model-field', 'schema': {'type': 'int'}}}},\n                    {'type': 'model-fields', 'fields': {'bar': {'type': 'model-field', 'schema': {'type': 'int'}}}},\n                ],\n            },\n        }\n    )\n    m = v.validate_python({'foo': '123'})\n    assert isinstance(m, MyModel)\n    assert m.__dict__ == {'foo': 123}\n    assert m.__pydantic_fields_set__ == {'foo'}\n    m = v.validate_python({'bar': '123'})\n    assert isinstance(m, MyModel)\n    assert m.__dict__ == {'bar': 123}\n    assert m.__pydantic_fields_set__ == {'bar'}\n\n\ndef test_tagged_union_sub_schema():\n    class MyModel:\n        pass\n\n    v = SchemaValidator(\n        {\n            'type': 'model',\n            'cls': MyModel,\n            'schema': {\n                'type': 'tagged-union',\n                'discriminator': 'foo',\n                'choices': {\n                    'apple': {\n                        'type': 'model-fields',\n                        'fields': {\n                            'foo': {'type': 'model-field', 'schema': {'type': 'str'}},\n                            'bar': {'type': 'model-field', 'schema': {'type': 'int'}},\n                        },\n                    },\n                    'banana': {\n                        'type': 'model-fields',\n                        'fields': {\n                            'foo': {'type': 'model-field', 'schema': {'type': 'str'}},\n                            'spam': {\n                                'type': 'model-field',\n                                'schema': {'type': 'list', 'items_schema': {'type': 'int'}},\n                            },\n                        },\n                    },\n                },\n            },\n        }\n    )\n    m = v.validate_python({'foo': 'apple', 'bar': '123'})\n    assert isinstance(m, MyModel)\n    assert m.__dict__ == {\n        'foo': 'apple',\n        'bar': 123,\n        '__pydantic_fields_set__': {'foo', 'bar'},\n        '__pydantic_extra__': None,\n        '__pydantic_private__': None,\n    }\n\n    m = v.validate_python({'foo': 'banana', 'spam': [1, 2, 3]})\n    assert isinstance(m, MyModel)\n    # insert_assert(m.__dict__)\n    assert m.__dict__ == {\n        'foo': 'banana',\n        'spam': [1, 2, 3],\n        '__pydantic_fields_set__': {'spam', 'foo'},\n        '__pydantic_extra__': None,\n        '__pydantic_private__': None,\n    }\n\n\ndef test_bad_sub_schema():\n    class MyModel:\n        pass\n\n    v = SchemaValidator({'type': 'model', 'cls': MyModel, 'schema': {'type': 'int'}})\n    with pytest.raises(TypeError):\n        v.validate_python(123)\n\n\ndef test_model_class_function_after():\n    class MyModel:\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n\n    def f(input_value, info):\n        input_value[0]['x'] = 'y'\n        return input_value\n\n    v = SchemaValidator(\n        {\n            'type': 'model',\n            'cls': MyModel,\n            'schema': {\n                'type': 'function-after',\n                'function': {'type': 'with-info', 'function': f},\n                'schema': {\n                    'type': 'model-fields',\n                    'fields': {'field_a': {'type': 'model-field', 'schema': {'type': 'str'}}},\n                },\n            },\n        }\n    )\n    m = v.validate_python({'field_a': 'test'})\n    assert isinstance(m, MyModel)\n    assert m.__dict__ == {'field_a': 'test', 'x': 'y'}\n    assert m.__pydantic_fields_set__ == {'field_a'}\n\n\ndef test_model_class_not_type():\n    with pytest.raises(SchemaError, match=re.escape(\"TypeError: 'int' object cannot be converted to 'PyType'\")):\n        SchemaValidator(\n            {\n                'type': 'model',\n                'cls': 123,\n                'schema': {\n                    'type': 'model-fields',\n                    'fields': {'field_a': {'type': 'model-field', 'schema': {'type': 'str'}}},\n                },\n            }\n        )\n\n\ndef test_model_class_instance_direct():\n    class MyModel:\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n        field_a: str\n\n        def __init__(self):\n            self.field_a = 'init'\n\n    v = SchemaValidator(\n        {\n            'type': 'model',\n            'cls': MyModel,\n            'schema': {\n                'type': 'model-fields',\n                'fields': {'field_a': {'type': 'model-field', 'schema': {'type': 'str'}}},\n            },\n        }\n    )\n    m1 = v.validate_python({'field_a': 'test'})\n    assert isinstance(m1, MyModel)\n    assert m1.field_a == 'test'\n    assert m1.__pydantic_fields_set__ == {'field_a'}\n\n    m2 = MyModel()\n    m3 = v.validate_python(m2)\n    assert m2 == m3\n    assert m3.field_a == 'init'\n\n\ndef test_model_class_instance_subclass():\n    post_init_calls = []\n\n    class MyModel:\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n        field_a: str\n\n        def __init__(self):\n            self.field_a = 'init_a'\n\n        def model_post_init(self, context):\n            post_init_calls.append(context)\n\n    class MySubModel(MyModel):\n        field_b: str\n\n        def __init__(self):\n            super().__init__()\n            self.field_b = 'init_b'\n\n    v = SchemaValidator(\n        {\n            'type': 'model',\n            'cls': MyModel,\n            'schema': {\n                'type': 'model-fields',\n                'fields': {'field_a': {'type': 'model-field', 'schema': {'type': 'str'}}},\n            },\n            'post_init': 'model_post_init',\n        }\n    )\n\n    m2 = MySubModel()\n    assert m2.field_a\n    m3 = v.validate_python(m2, context='call1')\n    assert m2 is m3\n    assert m3.field_a == 'init_a'\n    assert m3.field_b == 'init_b'\n    assert post_init_calls == []\n\n    m4 = v.validate_python({'field_a': b'hello'}, context='call2')\n    assert isinstance(m4, MyModel)\n    assert m4.field_a == 'hello'\n    assert m4.__pydantic_fields_set__ == {'field_a'}\n    assert post_init_calls == ['call2']\n\n\ndef test_model_class_instance_subclass_revalidate():\n    post_init_calls = []\n\n    class MyModel:\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n        field_a: str\n\n        def __init__(self):\n            self.field_a = 'init_a'\n\n        def model_post_init(self, context):\n            post_init_calls.append(context)\n\n    class MySubModel(MyModel):\n        field_b: str\n        __pydantic_fields_set__ = set()\n        __pydantic_extra__ = None\n\n        def __init__(self):\n            super().__init__()\n            self.field_b = 'init_b'\n\n    v = SchemaValidator(\n        {\n            'type': 'model',\n            'cls': MyModel,\n            'schema': {\n                'type': 'model-fields',\n                'fields': {'field_a': {'type': 'model-field', 'schema': {'type': 'str'}}},\n            },\n            'post_init': 'model_post_init',\n            'revalidate_instances': 'always',\n        }\n    )\n\n    m2 = MySubModel()\n    assert m2.field_a\n    m2.__pydantic_extra__ = {}\n    m2.__pydantic_fields_set__ = set()\n    m3 = v.validate_python(m2, context='call1')\n    assert m2 is not m3\n    assert m3.field_a == 'init_a'\n    assert not hasattr(m3, 'field_b')\n    assert post_init_calls == ['call1']\n\n    m4 = MySubModel()\n    m4.__pydantic_extra__ = {}\n    m4.__pydantic_fields_set__ = {'fruit_loop'}\n    m5 = v.validate_python(m4, context='call2')\n    assert m4 is not m5\n    assert m5.__pydantic_fields_set__ == {'fruit_loop'}\n    assert m5.field_a == 'init_a'\n    assert not hasattr(m5, 'field_b')\n    assert post_init_calls == ['call1', 'call2']\n\n\ndef test_model_class_strict():\n    class MyModel:\n        def __init__(self):\n            self.field_a = 'init_a'\n            self.field_b = 'init_b'\n\n    v = SchemaValidator(\n        {\n            'type': 'model',\n            'strict': True,\n            'cls': MyModel,\n            'schema': {\n                'type': 'model-fields',\n                'fields': {\n                    'field_a': {'type': 'model-field', 'schema': {'type': 'str'}},\n                    'field_b': {'type': 'model-field', 'schema': {'type': 'int'}},\n                },\n            },\n        }\n    )\n    assert re.search(r'revalidate: \\w+', repr(v)).group(0) == 'revalidate: Never'\n    m = MyModel()\n    m2 = v.validate_python(m)\n    assert isinstance(m, MyModel)\n    assert m is m2\n    assert m.field_a == 'init_a'\n    # note that since dict validation was not run here, there has been no check this is an int\n    assert m.field_b == 'init_b'\n    m3 = v.validate_python({'field_a': 'test', 'field_b': 12})\n    assert isinstance(m3, MyModel)\n    assert m3.field_a == 'test'\n    assert m3.field_b == 12\n\n    class MySubModel(MyModel):\n        field_c: str\n\n        def __init__(self):\n            super().__init__()\n            self.field_c = 'init_c'\n\n    # instances of subclasses are allowed in strict mode\n    m3 = MySubModel()\n    m4 = v.validate_python(m3)\n    assert m4 is m3\n\n\ndef test_model_class_strict_json():\n    class MyModel:\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n        field_a: str\n        field_b: int\n        field_c: int\n\n    v = SchemaValidator(\n        {\n            'type': 'model',\n            'strict': True,\n            'cls': MyModel,\n            'schema': {\n                'type': 'model-fields',\n                'fields': {\n                    'field_a': {'type': 'model-field', 'schema': {'type': 'str'}},\n                    'field_b': {'type': 'model-field', 'schema': {'type': 'int'}},\n                    'field_c': {\n                        'type': 'model-field',\n                        'schema': {'type': 'default', 'default': 42, 'schema': {'type': 'int'}},\n                    },\n                },\n            },\n        }\n    )\n    m = v.validate_json('{\"field_a\": \"foobar\", \"field_b\": \"123\"}')\n    assert isinstance(m, MyModel)\n    assert m.field_a == 'foobar'\n    assert m.field_b == 123\n    assert m.field_c == 42\n    assert m.__pydantic_fields_set__ == {'field_a', 'field_b'}\n\n\ndef test_internal_error():\n    v = SchemaValidator(\n        {\n            'type': 'model',\n            'cls': int,\n            'schema': {'type': 'model-fields', 'fields': {'f': {'type': 'model-field', 'schema': {'type': 'int'}}}},\n        }\n    )\n    with pytest.raises(AttributeError, match=re.escape(\"'int' object has no attribute '__dict__'\")):\n        v.validate_python({'f': 123})\n\n\ndef test_revalidate_always():\n    class MyModel:\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n\n        def __init__(self, a, b, fields_set):\n            self.field_a = a\n            self.field_b = b\n            self.__pydantic_extra__ = {}\n            if fields_set is not None:\n                self.__pydantic_fields_set__ = fields_set\n\n    v = SchemaValidator(\n        {\n            'type': 'model',\n            'cls': MyModel,\n            'revalidate_instances': 'always',\n            'schema': {\n                'type': 'model-fields',\n                'fields': {\n                    'field_a': {'type': 'model-field', 'schema': {'type': 'str'}},\n                    'field_b': {'type': 'model-field', 'schema': {'type': 'int'}},\n                },\n            },\n        }\n    )\n    assert re.search(r'revalidate: \\w+', repr(v)).group(0) == 'revalidate: Always'\n\n    m = v.validate_python({'field_a': 'test', 'field_b': 12})\n    assert isinstance(m, MyModel)\n    assert m.__dict__ == {'field_a': 'test', 'field_b': 12}\n    assert m.__pydantic_fields_set__ == {'field_a', 'field_b'}\n\n    m2 = MyModel('x', 42, {'field_a'})\n    m3 = v.validate_python(m2)\n    assert isinstance(m3, MyModel)\n    assert m3 is not m2\n    assert m3.__dict__ == {'field_a': 'x', 'field_b': 42}\n    assert m3.__pydantic_fields_set__ == {'field_a'}\n\n    m4 = MyModel('x', 'not int', {'field_a'})\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python(m4)\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'int_parsing',\n            'loc': ('field_b',),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'not int',\n        }\n    ]\n\n    m5 = MyModel('x', 5, None)\n    with pytest.raises(AttributeError, match='__pydantic_fields_set__'):\n        v.validate_python(m5)\n\n\ndef test_revalidate_subclass_instances():\n    class MyModel:\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n\n        def __init__(self):\n            self.field_a = 'init_a'\n            self.field_b = 123\n\n    class MySubModel(MyModel):\n        def __init__(self):\n            super().__init__()\n            self.field_c = 'init_c'\n\n    v = SchemaValidator(\n        {\n            'type': 'model',\n            'cls': MyModel,\n            'revalidate_instances': 'subclass-instances',\n            'schema': {\n                'type': 'model-fields',\n                'fields': {\n                    'field_a': {'type': 'model-field', 'schema': {'type': 'str'}},\n                    'field_b': {'type': 'model-field', 'schema': {'type': 'int'}},\n                },\n            },\n        }\n    )\n\n    m1 = MyModel()\n    m2 = v.validate_python(m1)\n    assert m2 is m1\n\n    m3 = MySubModel()\n    m3.__pydantic_extra__ = {}\n    m3.__pydantic_fields_set__ = set()\n    assert hasattr(m3, 'field_c')\n    m4 = v.validate_python(m3)\n    assert m4 is not m3\n    assert type(m4) is MyModel\n    assert not hasattr(m4, 'field_c')\n\n    m5 = MySubModel()\n    m5.__pydantic_extra__ = {}\n    m5.__pydantic_fields_set__ = set()\n    m5.field_b = 'not an int'\n    with pytest.raises(ValidationError, match=\"type=int_parsing, input_value='not an int', input_type=str\"):\n        v.validate_python(m5)\n\n\ndef test_revalidate_extra():\n    class MyModel:\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n\n        def __init__(self, **kwargs):\n            self.__dict__.update(kwargs)\n\n    v = SchemaValidator(\n        {\n            'type': 'model',\n            'cls': MyModel,\n            'schema': {\n                'type': 'model-fields',\n                'extra_behavior': 'allow',\n                'fields': {\n                    'field_a': {'type': 'model-field', 'schema': {'type': 'str'}},\n                    'field_b': {'type': 'model-field', 'schema': {'type': 'int'}},\n                },\n            },\n            'config': {'revalidate_instances': 'always'},\n        }\n    )\n\n    m = v.validate_python({'field_a': 'test', 'field_b': 12, 'more': (1, 2, 3)})\n    assert isinstance(m, MyModel)\n    assert m.__dict__ == {'field_a': 'test', 'field_b': 12}\n    assert m.__pydantic_extra__ == {'more': (1, 2, 3)}\n    assert m.__pydantic_fields_set__ == {'field_a', 'field_b', 'more'}\n\n    m2 = MyModel(field_a='x', field_b=42)\n    m2.__pydantic_extra__ = {'another': 42.5}\n    m2.__pydantic_fields_set__ = {'field_a', 'field_b', 'another'}\n    m3 = v.validate_python(m2)\n    assert isinstance(m3, MyModel)\n    assert m3 is not m2\n    assert m3.__dict__ == {'field_a': 'x', 'field_b': 42}\n    assert m3.__pydantic_extra__ == {'another': 42.5}\n    assert m3.__pydantic_fields_set__ == {'field_a', 'field_b', 'another'}\n\n\ndef test_post_init():\n    call_count = 0\n\n    class MyModel:\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n        field_a: str\n        field_b: int\n\n        def call_me_maybe(self, *args):\n            nonlocal call_count\n            call_count += 1\n            assert len(args) == 1\n            context = args[0]\n            assert context is None\n            assert self.field_a == 'test'\n            assert self.field_b == 12\n            assert self.__pydantic_fields_set__ == {'field_a', 'field_b'}\n\n    v = SchemaValidator(\n        {\n            'type': 'model',\n            'cls': MyModel,\n            'post_init': 'call_me_maybe',\n            'schema': {\n                'type': 'model-fields',\n                'fields': {\n                    'field_a': {'type': 'model-field', 'schema': {'type': 'str'}},\n                    'field_b': {'type': 'model-field', 'schema': {'type': 'int'}},\n                },\n            },\n        }\n    )\n    m = v.validate_python({'field_a': 'test', 'field_b': 12})\n    assert isinstance(m, MyModel)\n    assert call_count == 1\n\n\ndef test_revalidate_post_init():\n    call_count = 0\n\n    class MyModel:\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n\n        def call_me_maybe(self, context):\n            nonlocal call_count\n            call_count += 1\n            assert context is None\n\n    v = SchemaValidator(\n        {\n            'type': 'model',\n            'cls': MyModel,\n            'post_init': 'call_me_maybe',\n            'schema': {\n                'type': 'model-fields',\n                'fields': {\n                    'field_a': {'type': 'model-field', 'schema': {'type': 'str'}},\n                    'field_b': {'type': 'model-field', 'schema': {'type': 'int'}},\n                },\n            },\n            'config': {'revalidate_instances': 'always'},\n        }\n    )\n    assert re.search(r'revalidate: \\w+', repr(v)).group(0) == 'revalidate: Always'\n\n    m = v.validate_python({'field_a': 'test', 'field_b': 12})\n    assert isinstance(m, MyModel)\n    assert m.__dict__ == {'field_a': 'test', 'field_b': 12}\n    assert m.__pydantic_fields_set__ == {'field_a', 'field_b'}\n    assert call_count == 1\n\n    m2 = MyModel()\n    m2.field_a = 'x'\n    m2.field_b = 42\n    m2.__pydantic_extra__ = {}\n    m2.__pydantic_fields_set__ = {'field_a'}\n\n    m3 = v.validate_python(m2)\n    assert isinstance(m3, MyModel)\n    assert m3 is not m2\n    assert m3.__dict__ == {'field_a': 'x', 'field_b': 42}\n    assert m3.__pydantic_fields_set__ == {'field_a'}\n    assert call_count == 2\n\n\ndef test_post_init_validation_error():\n    class MyModel:\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n        field_a: str\n\n        def call_me_maybe(self, context, **kwargs):\n            if context and 'error' in context:\n                raise ValueError(f'this is broken: {self.field_a}')\n\n    v = SchemaValidator(\n        {\n            'type': 'model',\n            'cls': MyModel,\n            'post_init': 'call_me_maybe',\n            'schema': {\n                'type': 'model-fields',\n                'fields': {'field_a': {'type': 'model-field', 'schema': {'type': 'str'}}},\n            },\n        }\n    )\n    m = v.validate_python({'field_a': 'test'})\n    assert isinstance(m, MyModel)\n    assert m.field_a == 'test'\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python({'field_a': 'test'}, strict=None, context={'error': 1})\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'value_error',\n            'loc': (),\n            'msg': 'Value error, this is broken: test',\n            'input': {'field_a': 'test'},\n            'ctx': {'error': HasRepr(repr(ValueError('this is broken: test')))},\n        }\n    ]\n\n\ndef test_post_init_internal_error():\n    class MyModel:\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n        field_a: str\n\n        def wrong_signature(self):\n            pass\n\n    v = SchemaValidator(\n        {\n            'type': 'model',\n            'cls': MyModel,\n            'post_init': 'wrong_signature',\n            'schema': {\n                'type': 'model-fields',\n                'fields': {'field_a': {'type': 'model-field', 'schema': {'type': 'str'}}},\n            },\n        }\n    )\n    with pytest.raises(TypeError, match=r'wrong_signature\\(\\) takes 1 positional argument but 2 were given'):\n        v.validate_python({'field_a': 'test'})\n\n\ndef test_post_init_mutate():\n    class MyModel:\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n        field_a: str\n        field_b: int\n\n        def call_me_maybe(self, context, **kwargs):\n            self.field_a *= 2\n            self.__pydantic_fields_set__ = {'field_a'}\n\n    v = SchemaValidator(\n        {\n            'type': 'model',\n            'cls': MyModel,\n            'post_init': 'call_me_maybe',\n            'schema': {\n                'type': 'model-fields',\n                'fields': {\n                    'field_a': {'type': 'model-field', 'schema': {'type': 'str'}},\n                    'field_b': {'type': 'model-field', 'schema': {'type': 'int'}},\n                },\n            },\n        }\n    )\n    m = v.validate_python({'field_a': 'test', 'field_b': 12})\n    assert isinstance(m, MyModel)\n    assert m.field_a == 'testtest'\n    assert m.field_b == 12\n    assert m.__pydantic_fields_set__ == {'field_a'}\n    assert m.__dict__ == {'field_a': 'testtest', 'field_b': 12}\n\n\ndef test_validate_assignment():\n    class MyModel:\n        # this is not required, but it avoids `__pydantic_fields_set__` being included in `__dict__`\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n        field_a: str\n        field_b: int\n\n        def __init__(self):\n            self.__pydantic_extra__ = None\n\n    v = SchemaValidator(\n        {\n            'type': 'model',\n            'cls': MyModel,\n            'schema': {\n                'type': 'model-fields',\n                'fields': {\n                    'field_a': {'type': 'model-field', 'schema': {'type': 'str'}},\n                    'field_b': {'type': 'model-field', 'schema': {'type': 'int'}},\n                },\n            },\n        }\n    )\n\n    m = MyModel()\n    m.field_a = 'hello'\n    m.field_b = 123\n    m.__pydantic_fields_set__ = {'field_a'}\n\n    v.validate_assignment(m, 'field_b', '321')\n\n    m.field_a = 'hello'\n    assert m.field_b == 321\n    assert m.__pydantic_fields_set__ == {'field_a', 'field_b'}\n\n    v.validate_assignment(m, 'field_b', '322', from_attributes=True)\n    assert m.field_b == 322\n\n\ndef test_validate_assignment_function():\n    class MyModel:\n        # this is not required, but it avoids `__pydantic_fields_set__` being included in `__dict__`\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n        field_a: str\n        field_b: int\n        field_c: int\n\n    calls: List[Any] = []\n\n    def func(x, info):\n        calls.append(str(info))\n        return x * 2\n\n    v = SchemaValidator(\n        core_schema.model_schema(\n            MyModel,\n            core_schema.model_fields_schema(\n                {\n                    'field_a': core_schema.model_field(core_schema.str_schema()),\n                    'field_b': core_schema.model_field(\n                        core_schema.with_info_after_validator_function(\n                            func, core_schema.int_schema(), field_name='field_b'\n                        )\n                    ),\n                    'field_c': core_schema.model_field(core_schema.int_schema()),\n                }\n            ),\n        )\n    )\n\n    m = v.validate_python({'field_a': 'x', 'field_b': 123, 'field_c': 456})\n    assert m.field_a == 'x'\n    assert m.field_b == 246\n    assert m.field_c == 456\n    assert m.__pydantic_fields_set__ == {'field_a', 'field_b', 'field_c'}\n    assert calls == [\"ValidationInfo(config=None, context=None, data={'field_a': 'x'}, field_name='field_b')\"]\n\n    v.validate_assignment(m, 'field_b', '111')\n\n    assert m.field_b == 222\n    assert calls == [\n        \"ValidationInfo(config=None, context=None, data={'field_a': 'x'}, field_name='field_b')\",\n        \"ValidationInfo(config=None, context=None, data={'field_a': 'x', 'field_c': 456}, field_name='field_b')\",\n    ]\n\n\ndef test_validate_assignment_no_fields_set():\n    class MyModel:\n        __slots__ = ('__dict__', '__pydantic_extra__')\n\n        def __init__(self):\n            self.__pydantic_extra__ = None\n\n    v = SchemaValidator(\n        {\n            'type': 'model',\n            'cls': MyModel,\n            'schema': {\n                'type': 'model-fields',\n                'fields': {\n                    'field_a': {'type': 'model-field', 'schema': {'type': 'str'}},\n                    'field_b': {'type': 'model-field', 'schema': {'type': 'int'}},\n                },\n            },\n        }\n    )\n\n    m = MyModel()\n    m.field_a = 'hello'\n    m.field_b = 123\n    assert not hasattr(m, '__pydantic_fields_set__')\n\n    v.validate_assignment(m, 'field_a', b'different')\n\n    m.field_a = 'different'\n    assert m.field_b == 123\n    assert not hasattr(m, '__pydantic_fields_set__')\n\n    # wrong arguments\n    with pytest.raises(AttributeError, match=\"'str' object has no attribute '__dict__'\"):\n        v.validate_assignment('field_a', 'field_a', b'different')\n\n\ndef test_frozen():\n    class MyModel:\n        __slots__ = {'__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'}\n\n    v = SchemaValidator(\n        core_schema.model_schema(\n            MyModel,\n            core_schema.model_fields_schema({'f': core_schema.model_field(core_schema.str_schema())}),\n            frozen=True,\n        )\n    )\n\n    m = v.validate_python({'f': 'x'})\n    assert m.f == 'x'\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_assignment(m, 'f', 'y')\n\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'frozen_instance', 'loc': (), 'msg': 'Instance is frozen', 'input': 'y'}\n    ]\n\n\n@pytest.mark.parametrize(\n    'function_schema,call1, call2',\n    [\n        (\n            core_schema.with_info_after_validator_function,\n            (({'a': 1, 'b': 2}, None, {'b'}), 'ValidationInfo(config=None, context=None, data=None, field_name=None)'),\n            (({'a': 10, 'b': 2}, None, {'a'}), 'ValidationInfo(config=None, context=None, data=None, field_name=None)'),\n        ),\n        (\n            core_schema.with_info_before_validator_function,\n            ({'b': 2}, 'ValidationInfo(config=None, context=None, data=None, field_name=None)'),\n            ({'a': 10, 'b': 2}, 'ValidationInfo(config=None, context=None, data=None, field_name=None)'),\n        ),\n        (\n            core_schema.with_info_wrap_validator_function,\n            ({'b': 2}, 'ValidationInfo(config=None, context=None, data=None, field_name=None)'),\n            ({'a': 10, 'b': 2}, 'ValidationInfo(config=None, context=None, data=None, field_name=None)'),\n        ),\n    ],\n)\ndef test_validate_assignment_model_validator_function(function_schema: Any, call1: Any, call2: Any):\n    \"\"\"\n    Test handling of values and fields_set for validator functions that wrap a model when using\n    validate_assignment.\n\n    Note that we are currently not exposing this functionality in conjunction with getting\n    access to `fields_set` in a model validator, so the behavior of fields set.\n    In particular, for function_after it is not clear if the fields set passed to\n    the validator should be the fields that were assigned on this call to `validate_assignment`\n    (currently always a single field) or the fields that have been assigned in the\n    model since it was created.\n    \"\"\"\n\n    class Model:\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n\n    calls: List[Any] = []\n\n    def f(values_or_values_and_fields_set: Any, *args: Any) -> Any:\n        if len(args) == 2:\n            # wrap\n            handler, info = args\n            calls.append((deepcopy(values_or_values_and_fields_set), str(info)))\n            return handler(values_or_values_and_fields_set)\n        else:\n            info = args[0]\n            calls.append((deepcopy(values_or_values_and_fields_set), str(info)))\n            return values_or_values_and_fields_set\n\n    v = SchemaValidator(\n        core_schema.model_schema(\n            Model,\n            function_schema(\n                f,\n                core_schema.model_fields_schema(\n                    {\n                        'a': core_schema.model_field(\n                            core_schema.with_default_schema(core_schema.int_schema(), default=1)\n                        ),\n                        'b': core_schema.model_field(core_schema.int_schema()),\n                    }\n                ),\n            ),\n        )\n    )\n\n    m = v.validate_python({'b': 2})\n    assert m.a == 1\n    assert m.b == 2\n    assert m.__pydantic_fields_set__ == {'b'}\n    assert calls == [call1]\n\n    v.validate_assignment(m, 'a', 10)\n    assert m.a == 10\n    assert m.b == 2\n    assert m.__pydantic_fields_set__ == {'a', 'b'}\n    assert calls == [call1, call2]\n\n\ndef test_model_error():\n    class MyModel:\n        # this is not required, but it avoids `__pydantic_fields_set__` being included in `__dict__`\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n        field_a: str\n        field_b: int\n\n    v = SchemaValidator(\n        core_schema.model_schema(\n            MyModel,\n            core_schema.model_fields_schema(\n                {\n                    'field_a': core_schema.model_field(core_schema.str_schema()),\n                    'field_b': core_schema.model_field(core_schema.int_schema()),\n                },\n                model_name='MyModel',\n            ),\n        )\n    )\n    m = v.validate_python({'field_a': 'test', 'field_b': 12})\n    assert isinstance(m, MyModel)\n    assert m.__dict__ == {'field_a': 'test', 'field_b': 12}\n\n    m2 = MyModel()\n    m2.field_a = '1'\n    m2.field_b = 2\n\n    m3 = v.validate_python(m2)\n    assert isinstance(m3, MyModel)\n    assert m3.__dict__ == {'field_a': '1', 'field_b': 2}\n\n    m4 = v.validate_json('{\"field_a\": \"3\", \"field_b\": 4}')\n    assert isinstance(m4, MyModel)\n    assert m4.__dict__ == {'field_a': '3', 'field_b': 4}\n\n    class OtherModel:\n        pass\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python(OtherModel())\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'model_type',\n            'loc': (),\n            'msg': 'Input should be a valid dictionary or instance of MyModel',\n            'input': IsInstance(OtherModel),\n            'ctx': {'class_name': 'MyModel'},\n        }\n    ]\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_json('123')\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'model_type',\n            'loc': (),\n            'msg': 'Input should be an object',\n            'input': 123,\n            'ctx': {'class_name': 'MyModel'},\n        }\n    ]\n", "tests/validators/test_tagged_union.py": "from enum import Enum\n\nimport pytest\nfrom dirty_equals import IsAnyStr\n\nfrom pydantic_core import CoreConfig, SchemaValidator, ValidationError, core_schema\n\nfrom ..conftest import Err, PyAndJson\nfrom .test_typed_dict import Cls\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ({'foo': 'apple', 'bar': '123'}, {'foo': 'apple', 'bar': 123}),\n        ({'foo': 'banana', 'spam': [1, 2, '3']}, {'foo': 'banana', 'spam': [1, 2, 3]}),\n        (\n            {'foo': 'apple', 'bar': 'wrong'},\n            Err(\n                'Input should be a valid integer',\n                [\n                    {\n                        'type': 'int_parsing',\n                        'loc': ('apple', 'bar'),\n                        'msg': 'Input should be a valid integer, unable to parse string as an integer',\n                        'input': 'wrong',\n                    }\n                ],\n            ),\n        ),\n        (\n            {'foo': 'banana'},\n            Err(\n                'Field required',\n                [{'type': 'missing', 'loc': ('banana', 'spam'), 'msg': 'Field required', 'input': {'foo': 'banana'}}],\n            ),\n        ),\n        (\n            {'foo': 'other'},\n            Err(\n                'union_tag_invalid',\n                [\n                    {\n                        'type': 'union_tag_invalid',\n                        'loc': (),\n                        'msg': (\n                            \"Input tag 'other' found using 'foo' does not match any \"\n                            \"of the expected tags: 'apple', 'banana'\"\n                        ),\n                        'input': {'foo': 'other'},\n                        'ctx': {'discriminator': \"'foo'\", 'tag': 'other', 'expected_tags': \"'apple', 'banana'\"},\n                    }\n                ],\n            ),\n        ),\n        (\n            {},\n            Err(\n                'union_tag_not_found',\n                [\n                    {\n                        'type': 'union_tag_not_found',\n                        'loc': (),\n                        'msg': \"Unable to extract tag using discriminator 'foo'\",\n                        'input': {},\n                        'ctx': {'discriminator': \"'foo'\"},\n                    }\n                ],\n            ),\n        ),\n        (\n            'not a dict',\n            Err(\n                'dict_type',\n                [\n                    {\n                        'type': 'dict_type',\n                        'loc': (),\n                        'msg': IsAnyStr(regex='Input should be (a valid dictionary|an object)'),\n                        'input': 'not a dict',\n                    }\n                ],\n            ),\n        ),\n    ],\n    ids=repr,\n)\ndef test_simple_tagged_union(py_and_json: PyAndJson, input_value, expected):\n    v = py_and_json(\n        {\n            'type': 'tagged-union',\n            'discriminator': 'foo',\n            'from_attributes': False,\n            'choices': {\n                'apple': {\n                    'type': 'typed-dict',\n                    'fields': {\n                        'foo': {'type': 'typed-dict-field', 'schema': {'type': 'str'}},\n                        'bar': {'type': 'typed-dict-field', 'schema': {'type': 'int'}},\n                    },\n                },\n                'banana': {\n                    'type': 'typed-dict',\n                    'fields': {\n                        'foo': {'type': 'typed-dict-field', 'schema': {'type': 'str'}},\n                        'spam': {\n                            'type': 'typed-dict-field',\n                            'schema': {'type': 'list', 'items_schema': {'type': 'int'}},\n                        },\n                    },\n                },\n            },\n        }\n    )\n    assert 'discriminator: LookupKey' in repr(v.validator)\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=expected.message) as exc_info:\n            v.validate_test(input_value)\n        # debug(exc_info.value.errors(include_url=False))\n        assert exc_info.value.errors(include_url=False) == expected.errors\n    else:\n        assert v.validate_test(input_value) == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ({'foo': 123, 'bar': '123'}, {'foo': 123, 'bar': 123}),\n        ({'foo': 'banana', 'spam': [1, 2, '3']}, {'foo': 'banana', 'spam': [1, 2, 3]}),\n        (\n            {'foo': 123, 'bar': 'wrong'},\n            Err(\n                'Input should be a valid integer',\n                [\n                    {\n                        'type': 'int_parsing',\n                        'loc': (123, 'bar'),\n                        'msg': 'Input should be a valid integer, unable to parse string as an integer',\n                        'input': 'wrong',\n                    }\n                ],\n            ),\n        ),\n        (\n            {'foo': 1234567, 'bar': '123'},\n            Err(\n                'union_tag_invalid',\n                [\n                    {\n                        'type': 'union_tag_invalid',\n                        'loc': (),\n                        'msg': (\n                            \"Input tag '1234567' found using 'foo' does not match any of the \"\n                            \"expected tags: 123, 'banana'\"\n                        ),\n                        'input': {'foo': 1234567, 'bar': '123'},\n                        'ctx': {'discriminator': \"'foo'\", 'tag': '1234567', 'expected_tags': \"123, 'banana'\"},\n                    }\n                ],\n            ),\n        ),\n    ],\n)\ndef test_int_choice_keys(py_and_json: PyAndJson, input_value, expected):\n    v = py_and_json(\n        {\n            'type': 'tagged-union',\n            'discriminator': 'foo',\n            'choices': {\n                123: {\n                    'type': 'typed-dict',\n                    'fields': {\n                        'foo': {'type': 'typed-dict-field', 'schema': {'type': 'int'}},\n                        'bar': {'type': 'typed-dict-field', 'schema': {'type': 'int'}},\n                    },\n                },\n                'banana': {\n                    'type': 'typed-dict',\n                    'fields': {\n                        'foo': {'type': 'typed-dict-field', 'schema': {'type': 'str'}},\n                        'spam': {\n                            'type': 'typed-dict-field',\n                            'schema': {'type': 'list', 'items_schema': {'type': 'int'}},\n                        },\n                    },\n                },\n            },\n        }\n    )\n    assert 'discriminator: LookupKey' in repr(v.validator)\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=expected.message) as exc_info:\n            v.validate_test(input_value)\n        # debug(exc_info.value.errors(include_url=False))\n        assert exc_info.value.errors(include_url=False) == expected.errors\n    else:\n        assert v.validate_test(input_value) == expected\n\n\ndef test_enum_keys():\n    class FooEnum(str, Enum):\n        APPLE = 'apple'\n        BANANA = 'banana'\n\n    class BarEnum(int, Enum):\n        ONE = 1\n\n    class PlainEnum(Enum):\n        TWO = 'two'\n\n    v = SchemaValidator(\n        {\n            'type': 'tagged-union',\n            'discriminator': 'foo',\n            'choices': {\n                BarEnum.ONE: {\n                    'type': 'typed-dict',\n                    'fields': {\n                        'foo': {'type': 'typed-dict-field', 'schema': {'type': 'int'}},\n                        'bar': {'type': 'typed-dict-field', 'schema': {'type': 'int'}},\n                    },\n                },\n                FooEnum.BANANA: {\n                    'type': 'typed-dict',\n                    'fields': {\n                        'foo': {'type': 'typed-dict-field', 'schema': {'type': 'str'}},\n                        'spam': {\n                            'type': 'typed-dict-field',\n                            'schema': {'type': 'list', 'items_schema': {'type': 'int'}},\n                        },\n                    },\n                },\n                PlainEnum.TWO: {\n                    'type': 'typed-dict',\n                    'fields': {\n                        'foo': {'type': 'typed-dict-field', 'schema': {'type': 'any'}},\n                        'baz': {'type': 'typed-dict-field', 'schema': {'type': 'int'}},\n                    },\n                },\n            },\n        }\n    )\n\n    assert v.validate_python({'foo': FooEnum.BANANA, 'spam': [1, 2, '3']}) == {'foo': FooEnum.BANANA, 'spam': [1, 2, 3]}\n    assert v.validate_python({'foo': BarEnum.ONE, 'bar': '123'}) == {'foo': BarEnum.ONE, 'bar': 123}\n    assert v.validate_python({'foo': PlainEnum.TWO, 'baz': '123'}) == {'foo': PlainEnum.TWO, 'baz': 123}\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python({'foo': FooEnum.APPLE, 'spam': [1, 2, '3']})\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'union_tag_invalid',\n            'loc': (),\n            'msg': (\n                \"Input tag 'FooEnum.APPLE' found using 'foo' does not match any of the expected tags:\"\n                \" <BarEnum.ONE: 1>, <FooEnum.BANANA: 'banana'>, <PlainEnum.TWO: 'two'>\"\n            ),\n            'input': {'foo': FooEnum.APPLE, 'spam': [1, 2, '3']},\n            'ctx': {\n                'discriminator': \"'foo'\",\n                'tag': 'FooEnum.APPLE',\n                'expected_tags': \"<BarEnum.ONE: 1>, <FooEnum.BANANA: 'banana'>, <PlainEnum.TWO: 'two'>\",\n            },\n        }\n    ]\n\n\ndef test_discriminator_path(py_and_json: PyAndJson):\n    v = py_and_json(\n        {\n            'type': 'tagged-union',\n            'discriminator': [['food'], ['menu', 1]],\n            'choices': {\n                'apple': {\n                    'type': 'typed-dict',\n                    'fields': {\n                        'a': {'type': 'typed-dict-field', 'schema': {'type': 'str'}},\n                        'b': {'type': 'typed-dict-field', 'schema': {'type': 'int'}},\n                    },\n                },\n                'banana': {\n                    'type': 'typed-dict',\n                    'fields': {\n                        'c': {'type': 'typed-dict-field', 'schema': {'type': 'str'}},\n                        'd': {'type': 'typed-dict-field', 'schema': {'type': 'list', 'items_schema': {'type': 'int'}}},\n                    },\n                },\n            },\n        }\n    )\n    assert v.validate_test({'food': 'apple', 'a': 'apple', 'b': '13'}) == {'a': 'apple', 'b': 13}\n    assert v.validate_test({'menu': ['x', 'banana'], 'c': 'C', 'd': [1, '2']}) == {'c': 'C', 'd': [1, 2]}\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_test({})\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'union_tag_not_found',\n            'loc': (),\n            'msg': \"Unable to extract tag using discriminator 'food' | 'menu'.1\",\n            'input': {},\n            'ctx': {'discriminator': \"'food' | 'menu'.1\"},\n        }\n    ]\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ('foo', 'foo'),\n        (123, 123),\n        (\n            'baz',\n            Err(\n                'literal_error',\n                [\n                    {\n                        'type': 'literal_error',\n                        'loc': ('str',),\n                        'msg': \"Input should be 'foo' or 'bar'\",\n                        'input': 'baz',\n                        'ctx': {'expected': \"'foo' or 'bar'\"},\n                    }\n                ],\n            ),\n        ),\n        (\n            None,\n            Err(\n                'union_tag_not_found',\n                [\n                    {\n                        'type': 'union_tag_not_found',\n                        'loc': (),\n                        'msg': 'Unable to extract tag using discriminator discriminator_function()',\n                        'input': None,\n                        'ctx': {'discriminator': 'discriminator_function()'},\n                    }\n                ],\n            ),\n        ),\n        (\n            ['wrong type'],\n            Err(\n                'union_tag_invalid',\n                [\n                    {\n                        'type': 'union_tag_invalid',\n                        'loc': (),\n                        'msg': (\n                            \"Input tag 'other' found using discriminator_function() \"\n                            \"does not match any of the expected tags: 'str', 'int'\"\n                        ),\n                        'input': ['wrong type'],\n                        'ctx': {\n                            'discriminator': 'discriminator_function()',\n                            'tag': 'other',\n                            'expected_tags': \"'str', 'int'\",\n                        },\n                    }\n                ],\n            ),\n        ),\n    ],\n)\ndef test_discriminator_function(py_and_json: PyAndJson, input_value, expected):\n    def discriminator_function(obj):\n        if isinstance(obj, str):\n            return 'str'\n        elif isinstance(obj, int):\n            return 'int'\n        elif obj is None:\n            return None\n        else:\n            return 'other'\n\n    v = py_and_json(\n        {\n            'type': 'tagged-union',\n            'discriminator': discriminator_function,\n            'choices': {'str': {'type': 'literal', 'expected': ['foo', 'bar']}, 'int': {'type': 'int'}},\n        }\n    )\n    assert 'discriminator: Function' in repr(v.validator)\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=expected.message) as exc_info:\n            v.validate_python(input_value)\n        # debug(exc_info.value.errors(include_url=False))\n        assert exc_info.value.errors(include_url=False) == expected.errors\n    else:\n        assert v.validate_test(input_value) == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ('foo', 'foo'),\n        (123, 123),\n        (\n            None,\n            Err(\n                'union_tag_not_found',\n                [\n                    {\n                        'type': 'union_tag_not_found',\n                        'loc': (),\n                        'msg': 'Unable to extract tag using discriminator discriminator_function()',\n                        'input': None,\n                        'ctx': {'discriminator': 'discriminator_function()'},\n                    }\n                ],\n            ),\n        ),\n        (\n            ['wrong type'],\n            Err(\n                'union_tag_invalid',\n                [\n                    {\n                        'ctx': {'discriminator': 'discriminator_function()', 'expected_tags': \"'a', 1\", 'tag': 'other'},\n                        'input': ['wrong type'],\n                        'loc': (),\n                        'msg': \"Input tag 'other' found using discriminator_function() does not \"\n                        \"match any of the expected tags: 'a', 1\",\n                        'type': 'union_tag_invalid',\n                    }\n                ],\n            ),\n        ),\n    ],\n)\ndef test_int_discriminator_function(py_and_json: PyAndJson, input_value, expected):\n    def discriminator_function(obj):\n        if isinstance(obj, str):\n            return 'a'\n        elif isinstance(obj, int):\n            return 1\n        elif obj is None:\n            return None\n        else:\n            return 'other'\n\n    v = py_and_json(\n        {\n            'type': 'tagged-union',\n            'discriminator': discriminator_function,\n            'choices': {'a': {'type': 'str'}, 1: {'type': 'int'}},\n        }\n    )\n    assert 'discriminator: Function' in repr(v.validator)\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=expected.message) as exc_info:\n            v.validate_python(input_value)\n        # debug(exc_info.value.errors(include_url=False))\n        assert exc_info.value.errors(include_url=False) == expected.errors\n    else:\n        assert v.validate_test(input_value) == expected\n\n\ndef test_from_attributes():\n    v = SchemaValidator(\n        {\n            'type': 'tagged-union',\n            'discriminator': 'foobar',\n            'choices': {\n                'apple': {\n                    'type': 'model-fields',\n                    'fields': {\n                        'a': {'type': 'model-field', 'schema': {'type': 'str'}},\n                        'b': {'type': 'model-field', 'schema': {'type': 'int'}},\n                    },\n                },\n                'banana': {\n                    'type': 'model-fields',\n                    'fields': {\n                        'c': {'type': 'model-field', 'schema': {'type': 'str'}},\n                        'd': {'type': 'model-field', 'schema': {'type': 'int'}},\n                    },\n                },\n            },\n        },\n        {'from_attributes': True},\n    )\n    assert v.validate_python({'foobar': 'apple', 'a': 'apple', 'b': '13'}) == (\n        {'a': 'apple', 'b': 13},\n        None,\n        {'a', 'b'},\n    )\n    assert v.validate_python(Cls(foobar='apple', a='apple', b='13')) == ({'a': 'apple', 'b': 13}, None, {'a', 'b'})\n    assert v.validate_python({'foobar': 'banana', 'c': 'banana', 'd': '31'}) == (\n        {'c': 'banana', 'd': 31},\n        None,\n        {'c', 'd'},\n    )\n    assert v.validate_python(Cls(foobar='banana', c='banana', d='31')) == ({'c': 'banana', 'd': 31}, None, {'c', 'd'})\n\n\ndef test_use_ref():\n    v = SchemaValidator(\n        core_schema.definitions_schema(\n            core_schema.tagged_union_schema(\n                discriminator='foobar',\n                choices={\n                    'apple': core_schema.definition_reference_schema('apple'),\n                    'apple2': core_schema.definition_reference_schema('apple'),\n                    'banana': core_schema.typed_dict_schema(\n                        {'b': core_schema.typed_dict_field(core_schema.str_schema())}\n                    ),\n                },\n            ),\n            [core_schema.typed_dict_schema({'a': core_schema.typed_dict_field(core_schema.str_schema())}, ref='apple')],\n        ),\n        config=CoreConfig(from_attributes=True),\n    )\n    assert v.validate_python({'foobar': 'apple', 'a': 'apple'}) == {'a': 'apple'}\n    assert v.validate_python({'foobar': 'apple2', 'a': 'apple'}) == {'a': 'apple'}\n    assert v.validate_python({'foobar': 'banana', 'b': 'banana'}) == {'b': 'banana'}\n\n\ndef test_downcast_error():\n    v = SchemaValidator({'type': 'tagged-union', 'discriminator': lambda x: 123, 'choices': {'str': {'type': 'str'}}})\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python('x')\n        assert exc_info.value.errors(include_url=False) == [\n            {\n                'type': 'union_tag_invalid',\n                'loc': (),\n                'msg': \"Input tag '123' found using <lambda>() does not match any of the expected tags: 'str'\",\n                'input': 'x',\n            }\n        ]\n\n\ndef test_custom_error():\n    v = SchemaValidator(\n        {\n            'type': 'tagged-union',\n            'discriminator': 'foo',\n            'custom_error_type': 'snap',\n            'custom_error_message': 'Input should be a foo or bar',\n            'choices': {\n                'apple': {\n                    'type': 'typed-dict',\n                    'fields': {\n                        'foo': {'type': 'typed-dict-field', 'schema': {'type': 'str'}},\n                        'bar': {'type': 'typed-dict-field', 'schema': {'type': 'int'}},\n                    },\n                },\n                'banana': {\n                    'type': 'typed-dict',\n                    'fields': {\n                        'foo': {'type': 'typed-dict-field', 'schema': {'type': 'str'}},\n                        'spam': {\n                            'type': 'typed-dict-field',\n                            'schema': {'type': 'list', 'items_schema': {'type': 'int'}},\n                        },\n                    },\n                },\n            },\n        }\n    )\n    assert v.validate_python({'foo': 'apple', 'bar': '123'}) == {'foo': 'apple', 'bar': 123}\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python({'spam': 'apple', 'bar': 'Bar'})\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'snap', 'loc': (), 'msg': 'Input should be a foo or bar', 'input': {'spam': 'apple', 'bar': 'Bar'}}\n    ]\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python({'foo': 'other', 'bar': 'Bar'})\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'snap', 'loc': (), 'msg': 'Input should be a foo or bar', 'input': {'foo': 'other', 'bar': 'Bar'}}\n    ]\n\n\ndef test_custom_error_type():\n    v = SchemaValidator(\n        {\n            'type': 'tagged-union',\n            'discriminator': 'foo',\n            'custom_error_type': 'finite_number',\n            'choices': {\n                'apple': {\n                    'type': 'typed-dict',\n                    'fields': {\n                        'foo': {'type': 'typed-dict-field', 'schema': {'type': 'str'}},\n                        'bar': {'type': 'typed-dict-field', 'schema': {'type': 'int'}},\n                    },\n                },\n                'banana': {\n                    'type': 'typed-dict',\n                    'fields': {\n                        'foo': {'type': 'typed-dict-field', 'schema': {'type': 'str'}},\n                        'spam': {\n                            'type': 'typed-dict-field',\n                            'schema': {'type': 'list', 'items_schema': {'type': 'int'}},\n                        },\n                    },\n                },\n            },\n        }\n    )\n    assert v.validate_python({'foo': 'apple', 'bar': '123'}) == {'foo': 'apple', 'bar': 123}\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python({'spam': 'apple', 'bar': 'Bar'})\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'finite_number',\n            'loc': (),\n            'msg': 'Input should be a finite number',\n            'input': {'spam': 'apple', 'bar': 'Bar'},\n        }\n    ]\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python({'foo': 'other', 'bar': 'Bar'})\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'finite_number',\n            'loc': (),\n            'msg': 'Input should be a finite number',\n            'input': {'foo': 'other', 'bar': 'Bar'},\n        }\n    ]\n", "tests/validators/test_time.py": "import re\nfrom datetime import date, datetime, time, timedelta, timezone\nfrom decimal import Decimal\nfrom typing import Any, Dict\n\nimport pytest\n\nfrom pydantic_core import SchemaError, SchemaValidator, ValidationError, core_schema, validate_core_schema\n\nfrom ..conftest import Err, PyAndJson\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        pytest.param(time(12, 13, 14), time(12, 13, 14), id='time'),\n        pytest.param(time(12, 13, 14, 123), time(12, 13, 14, 123), id='time-micro'),\n        pytest.param(time(12, 13, 14, tzinfo=timezone.utc), time(12, 13, 14, tzinfo=timezone.utc), id='time-tz'),\n        pytest.param('12:13:14', time(12, 13, 14), id='str'),\n        pytest.param('12:13:14Z', time(12, 13, 14, tzinfo=timezone.utc), id='str-tz'),\n        pytest.param(b'12:13:14', time(12, 13, 14), id='bytes'),\n        pytest.param((1,), Err('Input should be a valid time [type=time_type'), id='tuple'),\n        pytest.param(date(2022, 6, 8), Err('Input should be a valid time [type=time_type'), id='date'),\n        pytest.param(datetime(2022, 6, 8), Err('Input should be a valid time [type=time_type'), id='datetime'),\n        pytest.param(123, time(0, 2, 3, tzinfo=timezone.utc), id='int'),\n        pytest.param(float('nan'), Err('valid time format, NaN values not permitted [type=time_parsing,'), id='nan'),\n        pytest.param(float('inf'), Err('valid time format, numeric times may not exceed 86,399 seconds'), id='inf'),\n        pytest.param(float('-inf'), Err('valid time format, time in seconds should be positive'), id='-inf'),\n        pytest.param(Decimal('123'), time(0, 2, 3, tzinfo=timezone.utc), id='decimal'),\n        pytest.param(Decimal('123.123456'), time(0, 2, 3, 123456, tzinfo=timezone.utc), id='decimal-6dig'),\n        pytest.param(Decimal('123.1234562'), time(0, 2, 3, 123456, tzinfo=timezone.utc), id='decimal-7dig-up'),\n        pytest.param(Decimal('123.1234568'), time(0, 2, 3, 123457, tzinfo=timezone.utc), id='decimal-7dig-down'),\n    ],\n)\ndef test_time(input_value, expected):\n    v = SchemaValidator({'type': 'time'})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_python(input_value)\n    else:\n        output = v.validate_python(input_value)\n        assert output == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        pytest.param('12:13:14', time(12, 13, 14), id='str'),\n        pytest.param('12:13:14.123', time(12, 13, 14, 123_000), id='str-micro'),\n        pytest.param('12:13:14.123456', time(12, 13, 14, 123_456), id='str-micro-6dig'),\n        pytest.param('12:13:14.123456', time(12, 13, 14, 123_456), id='str-micro-6dig'),\n        pytest.param('12:13:14.1234561', time(12, 13, 14, 123_456), id='str-micro-7dig'),\n        pytest.param(123, time(0, 2, 3, tzinfo=timezone.utc), id='int'),\n        pytest.param(123.4, time(0, 2, 3, 400_000, tzinfo=timezone.utc), id='float'),\n        pytest.param(123.0, time(0, 2, 3, tzinfo=timezone.utc), id='float.0'),\n        pytest.param(0, time(0, tzinfo=timezone.utc), id='int-zero'),\n        pytest.param(\n            86400,\n            Err(\n                'Input should be in a valid time format, numeric times may not exceed 86,399 seconds [type=time_parsing'\n            ),\n            id='too-high',\n        ),\n        pytest.param(\n            -1, Err('Input should be in a valid time format, time in seconds should be positive'), id='negative'\n        ),\n        pytest.param(2**32, Err('numeric times may not exceed 86,399 seconds'), id='too-high-2**32'),\n        pytest.param(2**64, Err('numeric times may not exceed 86,399 seconds'), id='too-high-2**64'),\n        pytest.param(2**100, Err('numeric times may not exceed 86,399 seconds'), id='too-high-2**100'),\n        pytest.param(True, Err('Input should be a valid time [type=time_type'), id='bool'),\n    ],\n)\ndef test_time_json(py_and_json: PyAndJson, input_value, expected):\n    v = py_and_json({'type': 'time'})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_test(input_value)\n    else:\n        output = v.validate_test(input_value)\n        assert output == expected\n\n\ndef test_time_error_microseconds_overflow(py_and_json: PyAndJson) -> None:\n    v = py_and_json(core_schema.time_schema(microseconds_precision='error'))\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_test('00:00:00.1234567')\n\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'time_parsing',\n            'loc': (),\n            'msg': 'Input should be in a valid time format, second fraction value is more than 6 digits long',\n            'input': '00:00:00.1234567',\n            'ctx': {'error': 'second fraction value is more than 6 digits long'},\n        }\n    ]\n\n    # insert_assert(v.validate_test('00:00:00.123456'))\n    assert v.validate_test('00:00:00.123456') == time(0, 0, 0, 123456)\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        (time(12, 13, 14, 15), time(12, 13, 14, 15)),\n        ('12:13:14', Err('Input should be a valid time [type=time_type')),\n        (b'12:13:14', Err('Input should be a valid time [type=time_type')),\n        (1654646400, Err('Input should be a valid time [type=time_type')),\n        (True, Err('Input should be a valid time [type=time_type')),\n        (date(2022, 6, 8), Err('Input should be a valid time [type=time_type')),\n        (datetime(2022, 6, 8), Err('Input should be a valid time [type=time_type')),\n    ],\n)\ndef test_time_strict(input_value, expected):\n    v = SchemaValidator({'type': 'time', 'strict': True})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_python(input_value)\n    else:\n        output = v.validate_python(input_value)\n        assert output == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ('\"12:13:14\"', time(12, 13, 14)),\n        ('\"foobar\"', Err('Input should be in a valid time format, invalid character in hour [type=time_parsing,')),\n        ('123', Err('Input should be a valid time [type=time_type')),\n    ],\n)\ndef test_time_strict_json(input_value, expected):\n    v = SchemaValidator({'type': 'time', 'strict': True})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_json(input_value)\n    else:\n        output = v.validate_json(input_value)\n        assert output == expected\n\n\n@pytest.mark.parametrize(\n    'kwargs,input_value,expected',\n    [\n        ({}, '12:13:14', time(12, 13, 14)),\n        ({'le': time(1)}, '00:12', time(0, 12)),\n        ({'le': time(1)}, '01:00', time(1, 0)),\n        ({'le': time(1)}, '01:01', Err('Input should be less than or equal to 01:00:00')),\n        ({'le': time(1)}, time(1), time(1, 0)),\n        ({'le': time(1)}, time(1, 1), Err('Input should be less than or equal to 01:00:00')),\n        ({'lt': time(1)}, '00:59', time(0, 59)),\n        ({'lt': time(1)}, '01:00', Err('Input should be less than 01:00:00')),\n        ({'ge': time(1)}, '01:00', time(1)),\n        ({'ge': time(1)}, '00:59', Err('Input should be greater than or equal to 01:00:00')),\n        ({'gt': time(12, 13, 14, 123_456)}, '12:13:14.123457', time(12, 13, 14, 123_457)),\n        ({'gt': time(12, 13, 14, 123_456)}, '12:13:14.123456', Err('Input should be greater than 12:13:14.123456')),\n    ],\n)\ndef test_time_kwargs(kwargs: Dict[str, Any], input_value, expected):\n    v = SchemaValidator({'type': 'time', **kwargs})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)) as exc_info:\n            v.validate_python(input_value)\n        errors = exc_info.value.errors(include_url=False)\n        assert len(errors) == 1\n        if len(kwargs) == 1:\n            key = list(kwargs.keys())[0]\n            assert key in errors[0]['ctx']\n    else:\n        output = v.validate_python(input_value)\n        assert output == expected\n\n\ndef test_time_bound_ctx():\n    v = SchemaValidator({'type': 'time', 'gt': time(12, 13, 14, 123_456)})\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python('12:13')\n\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'greater_than',\n            'loc': (),\n            'msg': 'Input should be greater than 12:13:14.123456',\n            'input': '12:13',\n            'ctx': {'gt': '12:13:14.123456'},\n        }\n    ]\n\n\ndef test_invalid_constraint():\n    with pytest.raises(SchemaError, match='Input should be in a valid time format'):\n        validate_core_schema({'type': 'time', 'gt': 'foobar'})\n\n\ndef test_dict_py():\n    v = SchemaValidator({'type': 'dict', 'keys_schema': {'type': 'time'}, 'values_schema': {'type': 'int'}})\n    assert v.validate_python({time(12, 1, 1): 2, time(12, 1, 2): 4}) == {time(12, 1, 1): 2, time(12, 1, 2): 4}\n\n\ndef test_dict(py_and_json: PyAndJson):\n    v = py_and_json({'type': 'dict', 'keys_schema': {'type': 'time'}, 'values_schema': {'type': 'int'}})\n    assert v.validate_test({'12:01:01': 2, '12:01:02': 4}) == {time(12, 1, 1): 2, time(12, 1, 2): 4}\n\n\ndef test_union():\n    v = SchemaValidator({'type': 'union', 'choices': [{'type': 'str'}, {'type': 'time'}]})\n    assert v.validate_python('12:01:02') == '12:01:02'\n    assert v.validate_python(time(12, 1, 2)) == time(12, 1, 2)\n\n    v = SchemaValidator({'type': 'union', 'choices': [{'type': 'time'}, {'type': 'str'}]})\n    assert v.validate_python('12:01:02') == '12:01:02'\n    assert v.validate_python(time(12, 1, 2)) == time(12, 1, 2)\n\n\ndef test_aware():\n    v = SchemaValidator(core_schema.time_schema(tz_constraint='aware'))\n    value = time(12, 13, 15, tzinfo=timezone.utc)\n    assert value is v.validate_python(value)\n    assert v.validate_python('12:13:14Z') == time(12, 13, 14, tzinfo=timezone.utc)\n\n    value = time(12, 13, 15)\n    with pytest.raises(ValidationError, match=r'Input should have timezone info'):\n        v.validate_python(value)\n\n    with pytest.raises(ValidationError, match=r'Input should have timezone info'):\n        v.validate_python('12:13:14')\n\n\ndef test_naive():\n    v = SchemaValidator(core_schema.time_schema(tz_constraint='naive'))\n    value = time(12, 13, 15)\n    assert value is v.validate_python(value)\n    assert v.validate_python('12:13:14') == time(12, 13, 14)\n\n    value = time(12, 13, 15, tzinfo=timezone.utc)\n    with pytest.raises(ValidationError, match=r'Input should not have timezone info'):\n        v.validate_python(value)\n\n    with pytest.raises(ValidationError, match=r'Input should not have timezone info'):\n        v.validate_python('12:13:14Z')\n\n\ndef test_aware_specific():\n    v = SchemaValidator(core_schema.time_schema(tz_constraint=0))\n    value = time(12, 13, 15, tzinfo=timezone.utc)\n    assert value is v.validate_python(value)\n    assert v.validate_python('12:13:14Z') == time(12, 13, 14, tzinfo=timezone.utc)\n\n    value = time(12, 13, 14)\n    with pytest.raises(ValidationError, match='Input should have timezone info'):\n        v.validate_python(value)\n\n    value = time(12, 13, 15, tzinfo=timezone(timedelta(hours=1)))\n    with pytest.raises(ValidationError, match='Timezone offset of 0 required, got 3600') as exc_info:\n        v.validate_python(value)\n\n    # insert_assert(exc_info.value.errors())\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'timezone_offset',\n            'loc': (),\n            'msg': 'Timezone offset of 0 required, got 3600',\n            'input': value,\n            'ctx': {'tz_expected': 0, 'tz_actual': 3600},\n        }\n    ]\n    with pytest.raises(ValidationError, match='Timezone offset of 0 required, got 3600'):\n        v.validate_python('12:13:14+01:00')\n\n\ndef test_neg_7200():\n    v = SchemaValidator(core_schema.time_schema(tz_constraint=-7200))\n    value = time(12, 13, 15, tzinfo=timezone(timedelta(hours=-2)))\n    assert value is v.validate_python(value)\n\n    value = time(12, 13, 14)\n    with pytest.raises(ValidationError, match='Input should have timezone info'):\n        v.validate_python(value)\n\n    value = time(12, 13, 15, tzinfo=timezone.utc)\n    with pytest.raises(ValidationError, match='Timezone offset of -7200 required, got 0'):\n        v.validate_python(value)\n    with pytest.raises(ValidationError, match='Timezone offset of -7200 required, got 0'):\n        v.validate_python('12:13:14Z')\n\n\ndef test_tz_constraint_too_high():\n    with pytest.raises(SchemaError, match='OverflowError: Python int too large to convert to C long'):\n        SchemaValidator(core_schema.time_schema(tz_constraint=2**64))\n\n\ndef test_tz_constraint_wrong():\n    with pytest.raises(SchemaError, match=\"Input should be 'aware' or 'naive\"):\n        validate_core_schema(core_schema.time_schema(tz_constraint='wrong'))\n", "tests/validators/test_model_root.py": "from typing import List\n\nimport pytest\n\nfrom pydantic_core import PydanticUndefined, SchemaValidator, ValidationError, core_schema\n\n\ndef test_model_root():\n    class RootModel:\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n        root: List[int]\n\n    v = SchemaValidator(\n        core_schema.model_schema(RootModel, core_schema.list_schema(core_schema.int_schema()), root_model=True)\n    )\n    assert repr(v).startswith('SchemaValidator(title=\"RootModel\", validator=Model(\\n')\n\n    m = v.validate_python([1, 2, '3'])\n    assert isinstance(m, RootModel)\n    assert m.root == [1, 2, 3]\n    assert m.__dict__ == {'root': [1, 2, 3]}\n\n    m = v.validate_json('[1, 2, \"3\"]')\n    assert isinstance(m, RootModel)\n    assert m.root == [1, 2, 3]\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python('wrong')\n\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'list_type', 'loc': (), 'msg': 'Input should be a valid list', 'input': 'wrong'}\n    ]\n\n\ndef test_revalidate():\n    class RootModel:\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n        root: List[int]\n\n    v = SchemaValidator(\n        core_schema.model_schema(\n            RootModel, core_schema.list_schema(core_schema.int_schema()), root_model=True, revalidate_instances='always'\n        )\n    )\n    m = RootModel()\n    m = v.validate_python([1, '2'], self_instance=m)\n    assert isinstance(m, RootModel)\n    assert m.root == [1, 2]\n    assert m.__pydantic_fields_set__ == {'root'}\n\n    m2 = v.validate_python(m)\n    assert m2 is not m\n    assert isinstance(m2, RootModel)\n    assert m2.root == [1, 2]\n    assert m.__pydantic_fields_set__ == {'root'}\n\n\ndef test_revalidate_with_default():\n    class RootModel:\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n        root: int = 42\n\n    v = SchemaValidator(\n        core_schema.model_schema(\n            RootModel,\n            core_schema.with_default_schema(core_schema.int_schema(), default=42),\n            root_model=True,\n            revalidate_instances='always',\n        )\n    )\n    m = RootModel()\n    m = v.validate_python(PydanticUndefined, self_instance=m)\n    assert isinstance(m, RootModel)\n    assert m.root == 42\n    assert m.__pydantic_fields_set__ == set()\n\n    m2 = v.validate_python(m)\n    assert m2 is not m\n    assert isinstance(m2, RootModel)\n    assert m2.root == 42\n    assert m.__pydantic_fields_set__ == set()\n\n\ndef test_init():\n    class RootModel:\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n        root: str\n\n    v = SchemaValidator(\n        core_schema.model_schema(RootModel, core_schema.str_schema(), root_model=True, revalidate_instances='always')\n    )\n\n    m = RootModel()\n    ans = v.validate_python('foobar', self_instance=m)\n    assert ans is m\n    assert ans.root == 'foobar'\n\n\ndef test_assignment():\n    class RootModel:\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n        root: str\n\n    v = SchemaValidator(core_schema.model_schema(RootModel, core_schema.str_schema(), root_model=True))\n\n    m = v.validate_python('foobar')\n    assert m.root == 'foobar'\n\n    m2 = v.validate_assignment(m, 'root', 'baz')\n    assert m2 is m\n    assert m.root == 'baz'\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_assignment(m, 'different', 'baz')\n\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'no_such_attribute',\n            'loc': ('different',),\n            'msg': \"Object has no attribute 'different'\",\n            'input': 'baz',\n            'ctx': {'attribute': 'different'},\n        }\n    ]\n\n\ndef test_field_function():\n    call_infos = []\n\n    class RootModel:\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n        root: str\n\n    def f(input_value: str, info):\n        call_infos.append(repr(info))\n        return input_value + ' validated'\n\n    v = SchemaValidator(\n        core_schema.model_schema(\n            RootModel,\n            core_schema.with_info_after_validator_function(f, core_schema.str_schema(), field_name='root'),\n            root_model=True,\n        )\n    )\n    m = v.validate_python('foobar', context='call 1')\n    assert isinstance(m, RootModel)\n    assert m.root == 'foobar validated'\n    assert call_infos == [\"ValidationInfo(config=None, context='call 1', data=None, field_name='root')\"]\n\n    m2 = v.validate_assignment(m, 'root', 'baz', context='assignment call')\n    assert m2 is m\n    assert m.root == 'baz validated'\n    assert call_infos == [\n        \"ValidationInfo(config=None, context='call 1', data=None, field_name='root')\",\n        \"ValidationInfo(config=None, context='assignment call', data=None, field_name='root')\",\n    ]\n\n\ndef test_extra():\n    class RootModel:\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n        root: int\n\n    v = SchemaValidator(core_schema.model_schema(RootModel, core_schema.int_schema(), root_model=True))\n\n    m = v.validate_python(1)\n\n    with pytest.raises(AttributeError):\n        m.__pydantic_extra__\n\n\ndef test_fields_set():\n    assert core_schema.PydanticUndefined is PydanticUndefined\n\n    class RootModel:\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n        root: int = 42\n\n    v = SchemaValidator(\n        core_schema.model_schema(\n            RootModel, core_schema.with_default_schema(core_schema.int_schema(), default=42), root_model=True\n        )\n    )\n\n    m = RootModel()\n    v.validate_python(1, self_instance=m)\n    assert m.root == 1\n    assert m.__pydantic_fields_set__ == {'root'}\n\n    v.validate_python(PydanticUndefined, self_instance=m)\n    assert m.root == 42\n    assert m.__pydantic_fields_set__ == set()\n\n\ndef test_construct_from_validate_default():\n    class RootModel:\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n        root: int\n\n    class Model:\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n        value: RootModel = 42\n\n    v = SchemaValidator(\n        core_schema.model_schema(\n            Model,\n            core_schema.model_fields_schema(\n                {\n                    'value': core_schema.model_field(\n                        core_schema.with_default_schema(\n                            core_schema.model_schema(RootModel, core_schema.int_schema(), root_model=True),\n                            default=42,\n                            validate_default=True,\n                        )\n                    )\n                }\n            ),\n        )\n    )\n\n    m = Model()\n    v.validate_python({}, self_instance=m)\n\n    assert m.value.root == 42\n    assert m.value.__pydantic_fields_set__ == {'root'}\n", "tests/validators/test_nullable.py": "import gc\nimport platform\nimport weakref\n\nimport pytest\n\nfrom pydantic_core import SchemaValidator, ValidationError, core_schema\n\n\ndef test_nullable():\n    v = SchemaValidator({'type': 'nullable', 'schema': {'type': 'int'}})\n    assert v.validate_python(None) is None\n    assert v.validate_python(1) == 1\n    assert v.validate_python('123') == 123\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python('hello')\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'int_parsing',\n            'loc': (),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'hello',\n        }\n    ]\n\n\ndef test_union_nullable_bool_int():\n    v = SchemaValidator(\n        {\n            'type': 'union',\n            'choices': [\n                {'type': 'nullable', 'schema': {'type': 'bool'}},\n                {'type': 'nullable', 'schema': {'type': 'int'}},\n            ],\n        }\n    )\n    assert v.validate_python(None) is None\n    assert v.validate_python(True) is True\n    assert v.validate_python(1) == 1\n\n\n@pytest.mark.xfail(\n    condition=platform.python_implementation() == 'PyPy', reason='https://foss.heptapod.net/pypy/pypy/-/issues/3899'\n)\ndef test_leak_nullable():\n    def fn():\n        def validate(v, info):\n            return v\n\n        schema = core_schema.with_info_plain_validator_function(validate)\n        schema = core_schema.nullable_schema(schema)\n\n        # If any of the Rust validators don't implement traversal properly,\n        # there will be an undetectable cycle created by this assignment\n        # which will keep Defaulted alive\n        validate.__pydantic_validator__ = SchemaValidator(schema)\n\n        return validate\n\n    cycle = fn()\n    ref = weakref.ref(cycle)\n    assert ref() is not None\n\n    del cycle\n    gc.collect(0)\n    gc.collect(1)\n    gc.collect(2)\n    gc.collect()\n\n    assert ref() is None\n", "tests/validators/test_none.py": "import pytest\n\nfrom pydantic_core import SchemaValidator, ValidationError\n\n\ndef test_python_none():\n    v = SchemaValidator({'type': 'none'})\n    assert v.validate_python(None) is None\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python(1)\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'none_required', 'loc': (), 'msg': 'Input should be None', 'input': 1}\n    ]\n\n\ndef test_json_none():\n    v = SchemaValidator({'type': 'none'})\n    assert v.validate_json('null') is None\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_json('1')\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'none_required', 'loc': (), 'msg': 'Input should be null', 'input': 1}\n    ]\n", "tests/validators/test_list.py": "import collections.abc\nimport re\nfrom collections import deque\nfrom dataclasses import dataclass\nfrom typing import Any, Dict, Iterator, List, Union\n\nimport pytest\nfrom dirty_equals import Contains, HasRepr, IsInstance, IsList, IsStr\n\nfrom pydantic_core import SchemaValidator, ValidationError, core_schema\n\nfrom ..conftest import Err, PyAndJson, infinite_generator\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ([1, 2, 3], [1, 2, 3]),\n        ([1, 2, '3'], [1, 2, 3]),\n        (5, Err(r'Input should be a valid (list|array) \\[type=list_type, input_value=5, input_type=int\\]')),\n        ('5', Err(r\"Input should be a valid (list|array) \\[type=list_type, input_value='5', input_type=str\\]\")),\n    ],\n    ids=repr,\n)\ndef test_list_py_or_json(py_and_json: PyAndJson, input_value, expected):\n    v = py_and_json({'type': 'list', 'items_schema': {'type': 'int'}})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=expected.message):\n            v.validate_test(input_value)\n    else:\n        assert v.validate_test(input_value) == expected\n\n\ndef test_list_strict():\n    v = SchemaValidator({'type': 'list', 'items_schema': {'type': 'int'}, 'strict': True})\n    assert v.validate_python([1, 2, '33']) == [1, 2, 33]\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python((1, 2, '33'))\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'list_type', 'loc': (), 'msg': 'Input should be a valid list', 'input': (1, 2, '33')}\n    ]\n\n\ndef test_list_no_copy():\n    v = SchemaValidator({'type': 'list'})\n    assert v.validate_python([1, 2, 3]) is not [1, 2, 3]\n\n\ndef gen_ints():\n    yield 1\n    yield 2\n    yield '3'\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ([1, 2, '3'], [1, 2, 3]),\n        ((1, 2, '3'), [1, 2, 3]),\n        (deque((1, 2, '3')), [1, 2, 3]),\n        ({1, 2, '3'}, IsList(1, 2, 3, check_order=False)),\n        (gen_ints(), [1, 2, 3]),\n        (frozenset({1, 2, '3'}), IsList(1, 2, 3, check_order=False)),\n        ({1: 10, 2: 20, '3': '30'}.keys(), [1, 2, 3]),\n        ({1: 10, 2: 20, '3': '30'}.values(), [10, 20, 30]),\n        ({1: 10, 2: 20, '3': '30'}, Err('Input should be a valid list [type=list_type,')),\n        ((x for x in [1, 2, '3']), [1, 2, 3]),\n        ('456', Err(\"Input should be a valid list [type=list_type, input_value='456', input_type=str]\")),\n        (b'789', Err(\"Input should be a valid list [type=list_type, input_value=b'789', input_type=bytes]\")),\n    ],\n    ids=repr,\n)\ndef test_list_int(input_value, expected):\n    v = SchemaValidator({'type': 'list', 'items_schema': {'type': 'int'}})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_python(input_value)\n    else:\n        assert v.validate_python(input_value) == expected\n\n\ndef test_list_json():\n    v = SchemaValidator({'type': 'list', 'items_schema': {'type': 'int'}})\n    assert v.validate_json('[1, \"2\", 3]') == [1, 2, 3]\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_json('1')\n\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'list_type', 'loc': (), 'msg': 'Input should be a valid array', 'input': 1}\n    ]\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ([], []),\n        ([1, '2', b'3'], [1, '2', b'3']),\n        (frozenset([1, '2', b'3']), IsList(1, '2', b'3', check_order=False)),\n        ((), []),\n        ((1, '2', b'3'), [1, '2', b'3']),\n        (deque([1, '2', b'3']), [1, '2', b'3']),\n        ({1, '2', b'3'}, IsList(1, '2', b'3', check_order=False)),\n    ],\n)\ndef test_list_any(input_value, expected):\n    v = SchemaValidator({'type': 'list'})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_python(input_value)\n    else:\n        assert v.validate_python(input_value) == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,index',\n    [\n        (['wrong'], 0),\n        (('wrong',), 0),\n        (deque(['wrong']), 0),\n        ([1, 2, 3, 'wrong'], 3),\n        ((1, 2, 3, 'wrong', 4), 3),\n        (deque([1, 2, 3, 'wrong']), 3),\n    ],\n)\ndef test_list_error(input_value, index):\n    v = SchemaValidator({'type': 'list', 'items_schema': {'type': 'int'}})\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python(input_value)\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'int_parsing',\n            'loc': (index,),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'wrong',\n        }\n    ]\n\n\n@pytest.mark.parametrize(\n    'kwargs,input_value,expected',\n    [\n        ({}, [1, 2, 3, 4], [1, 2, 3, 4]),\n        ({'min_length': 3}, [1, 2, 3, 4], [1, 2, 3, 4]),\n        ({'min_length': 3}, [1, 2], Err('List should have at least 3 items after validation, not 2 [type=too_short,')),\n        ({'min_length': 1}, [], Err('List should have at least 1 item after validation, not 0 [type=too_short,')),\n        ({'max_length': 4}, [1, 2, 3, 4], [1, 2, 3, 4]),\n        (\n            {'max_length': 3},\n            [1, 2, 3, 4],\n            Err('List should have at most 3 items after validation, not 4 [type=too_long,'),\n        ),\n        (\n            {'max_length': 3},\n            [1, 2, 3, 4, 5, 6, 7],\n            Err('List should have at most 3 items after validation, not 7 [type=too_long,'),\n        ),\n        ({'max_length': 1}, [1, 2], Err('List should have at most 1 item after validation, not 2 [type=too_long,')),\n        (\n            {'max_length': 44},\n            infinite_generator(),\n            Err('List should have at most 44 items after validation, not more [type=too_long,'),\n        ),\n        (\n            {'max_length': 4, 'items_schema': {'type': 'int'}},\n            [0, 1, 2, 3, 4, 5, 6, 7, 8],\n            Err('List should have at most 4 items after validation, not 9 [type=too_long,'),\n        ),\n    ],\n)\ndef test_list_length_constraints(kwargs: Dict[str, Any], input_value, expected):\n    v = SchemaValidator({'type': 'list', **kwargs})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_python(input_value)\n    else:\n        assert v.validate_python(input_value) == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ([1, 2, 3, 4], [1, 2, 3, 4]),\n        ([1, 2, 3, 4, 5], Err('List should have at most 4 items after validation, not 5 [type=too_long,')),\n        ([1, 2, 3, 'x', 4], [1, 2, 3, 4]),\n    ],\n)\ndef test_list_length_constraints_omit(input_value, expected):\n    v = SchemaValidator(\n        {\n            'type': 'list',\n            'items_schema': {'type': 'default', 'schema': {'type': 'int'}, 'on_error': 'omit'},\n            'max_length': 4,\n        }\n    )\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_python(input_value)\n    else:\n        assert v.validate_python(input_value) == expected\n\n\ndef test_length_ctx():\n    v = SchemaValidator({'type': 'list', 'min_length': 2, 'max_length': 3})\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python([1])\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'too_short',\n            'loc': (),\n            'msg': 'List should have at least 2 items after validation, not 1',\n            'input': [1],\n            'ctx': {'field_type': 'List', 'min_length': 2, 'actual_length': 1},\n        }\n    ]\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python([1, 2, 3, 4])\n\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'too_long',\n            'loc': (),\n            'msg': 'List should have at most 3 items after validation, not 4',\n            'input': [1, 2, 3, 4],\n            'ctx': {'field_type': 'List', 'max_length': 3, 'actual_length': 4},\n        }\n    ]\n\n\ndef test_list_function():\n    def f(input_value, info):\n        return input_value * 2\n\n    v = SchemaValidator({'type': 'list', 'items_schema': core_schema.with_info_plain_validator_function(f)})\n\n    assert v.validate_python([1, 2, 3]) == [2, 4, 6]\n\n\ndef test_list_function_val_error():\n    def f(input_value, info):\n        raise ValueError(f'error {input_value}')\n\n    v = SchemaValidator({'type': 'list', 'items_schema': core_schema.with_info_plain_validator_function(f)})\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python([1, 2])\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'value_error',\n            'loc': (0,),\n            'msg': 'Value error, error 1',\n            'input': 1,\n            'ctx': {'error': HasRepr(repr(ValueError('error 1')))},\n        },\n        {\n            'type': 'value_error',\n            'loc': (1,),\n            'msg': 'Value error, error 2',\n            'input': 2,\n            'ctx': {'error': HasRepr(repr(ValueError('error 2')))},\n        },\n    ]\n\n\ndef test_list_function_internal_error():\n    def f(input_value, info):\n        raise RuntimeError(f'error {input_value}')\n\n    v = SchemaValidator({'type': 'list', 'items_schema': core_schema.with_info_plain_validator_function(f)})\n\n    with pytest.raises(RuntimeError, match='^error 1$') as exc_info:\n        v.validate_python([1, 2])\n    assert exc_info.value.args[0] == 'error 1'\n\n\ndef test_generator_error():\n    def gen(error: bool):\n        yield 1\n        yield 2\n        if error:\n            raise RuntimeError('error')\n        yield 3\n\n    v = SchemaValidator({'type': 'list', 'items_schema': {'type': 'int'}})\n    assert v.validate_python(gen(False)) == [1, 2, 3]\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python(gen(True))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'iteration_error',\n            'loc': (2,),\n            'msg': 'Error iterating over object, error: RuntimeError: error',\n            'input': HasRepr(IsStr(regex='<generator object test_generator_error.<locals>.gen at 0x[0-9a-fA-F]+>')),\n            'ctx': {'error': 'RuntimeError: error'},\n        }\n    ]\n\n\n@pytest.mark.parametrize(\n    'input_value,items_schema,expected',\n    [\n        pytest.param(\n            {1: 10, 2: 20, '3': '30'}.items(),\n            {'type': 'tuple', 'items_schema': [{'type': 'any'}], 'variadic_item_index': 0},\n            [(1, 10), (2, 20), ('3', '30')],\n            id='Tuple[Any, Any]',\n        ),\n        pytest.param(\n            {1: 10, 2: 20, '3': '30'}.items(),\n            {'type': 'tuple', 'items_schema': [{'type': 'int'}], 'variadic_item_index': 0},\n            [(1, 10), (2, 20), (3, 30)],\n            id='Tuple[int, int]',\n        ),\n        pytest.param({1: 10, 2: 20, '3': '30'}.items(), {'type': 'any'}, [(1, 10), (2, 20), ('3', '30')], id='Any'),\n    ],\n)\ndef test_list_from_dict_items(input_value, items_schema, expected):\n    v = SchemaValidator({'type': 'list', 'items_schema': items_schema})\n    output = v.validate_python(input_value)\n    assert isinstance(output, list)\n    assert output == expected\n\n\n@pytest.mark.parametrize('items_schema', ['int', 'any'])\ndef test_bad_iter(items_schema):\n    class BadIter:\n        def __init__(self, success: bool):\n            self._success = success\n            self._index = 0\n\n        def __iter__(self):\n            return self\n\n        def __len__(self):\n            return 2\n\n        def __next__(self):\n            self._index += 1\n            if self._index == 1:\n                return 1\n            elif self._success:\n                raise StopIteration()\n            else:\n                raise RuntimeError('broken')\n\n    v = SchemaValidator({'type': 'list', 'items_schema': {'type': items_schema}})\n    assert v.validate_python(BadIter(True)) == [1]\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python(BadIter(False))\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'iteration_error',\n            'loc': (1,),\n            'msg': 'Error iterating over object, error: RuntimeError: broken',\n            'input': IsInstance(BadIter),\n            'ctx': {'error': 'RuntimeError: broken'},\n        }\n    ]\n\n\n@pytest.mark.parametrize('error_in_func', [True, False])\ndef test_max_length_fail_fast(error_in_func: bool) -> None:\n    calls: list[int] = []\n\n    def f(v: int) -> int:\n        calls.append(v)\n        if error_in_func:\n            assert v < 10\n        return v\n\n    s = core_schema.list_schema(\n        core_schema.no_info_after_validator_function(f, core_schema.int_schema()), max_length=10\n    )\n\n    v = SchemaValidator(s)\n\n    data = list(range(15))\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python(data)\n\n    assert len(calls) <= 11, len(calls)  # we still run validation on the \"extra\" item\n\n    assert exc_info.value.errors(include_url=False) == Contains(\n        {\n            'type': 'too_long',\n            'loc': (),\n            'msg': 'List should have at most 10 items after validation, not 15',\n            'input': data,\n            'ctx': {'field_type': 'List', 'max_length': 10, 'actual_length': 15},\n        }\n    )\n\n\n@pytest.mark.parametrize(\n    'fail_fast,expected',\n    [\n        pytest.param(\n            True,\n            [\n                {\n                    'type': 'int_parsing',\n                    'loc': (1,),\n                    'msg': 'Input should be a valid integer, unable to parse string as an integer',\n                    'input': 'not-num',\n                }\n            ],\n            id='fail_fast',\n        ),\n        pytest.param(\n            False,\n            [\n                {\n                    'type': 'int_parsing',\n                    'loc': (1,),\n                    'msg': 'Input should be a valid integer, unable to parse string as an integer',\n                    'input': 'not-num',\n                },\n                {\n                    'type': 'int_parsing',\n                    'loc': (2,),\n                    'msg': 'Input should be a valid integer, unable to parse string as an integer',\n                    'input': 'again',\n                },\n            ],\n            id='not_fail_fast',\n        ),\n    ],\n)\ndef test_list_fail_fast(fail_fast, expected):\n    s = core_schema.list_schema(core_schema.int_schema(), fail_fast=fail_fast)\n    v = SchemaValidator(s)\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python([1, 'not-num', 'again'])\n\n    assert exc_info.value.errors(include_url=False) == expected\n\n\nclass MySequence(collections.abc.Sequence):\n    def __init__(self, data: List[Any]):\n        self._data = data\n\n    def __getitem__(self, index: int) -> Any:\n        return self._data[index]\n\n    def __len__(self):\n        return len(self._data)\n\n    def __repr__(self) -> str:\n        return f'MySequence({repr(self._data)})'\n\n\nclass MyMapping(collections.abc.Mapping):\n    def __init__(self, data: Dict[Any, Any]) -> None:\n        self._data = data\n\n    def __getitem__(self, key: Any) -> Any:\n        return self._data[key]\n\n    def __iter__(self) -> Iterator[Any]:\n        return iter(self._data)\n\n    def __len__(self) -> int:\n        return len(self._data)\n\n    def __repr__(self) -> str:\n        return f'MyMapping({repr(self._data)})'\n\n\n@dataclass\nclass ListInputTestCase:\n    input: Any\n    output: Union[Any, Err]\n    strict: Union[bool, None] = None\n\n\nLAX_MODE_INPUTS: List[Any] = [\n    (1, 2, 3),\n    frozenset((1, 2, 3)),\n    {1, 2, 3},\n    deque([1, 2, 3]),\n    {1: 'a', 2: 'b', 3: 'c'}.keys(),\n    {'a': 1, 'b': 2, 'c': 3}.values(),\n    MySequence([1, 2, 3]),\n    MyMapping({1: 'a', 2: 'b', 3: 'c'}).keys(),\n    MyMapping({'a': 1, 'b': 2, 'c': 3}).values(),\n    (x for x in [1, 2, 3]),\n]\n\n\n@pytest.mark.parametrize(\n    'testcase',\n    [\n        *[ListInputTestCase([1, 2, 3], [1, 2, 3], strict) for strict in (True, False, None)],\n        *[\n            ListInputTestCase(inp, Err('Input should be a valid list [type=list_type,'), True)\n            for inp in [*LAX_MODE_INPUTS, '123', b'123']\n        ],\n        *[ListInputTestCase(inp, [1, 2, 3], False) for inp in LAX_MODE_INPUTS],\n        *[\n            ListInputTestCase(inp, Err('Input should be a valid list [type=list_type,'), False)\n            for inp in ['123', b'123', MyMapping({1: 'a', 2: 'b', 3: 'c'}), {1: 'a', 2: 'b', 3: 'c'}]\n        ],\n    ],\n    ids=repr,\n)\ndef test_list_allowed_inputs_python(testcase: ListInputTestCase):\n    v = SchemaValidator(core_schema.list_schema(core_schema.int_schema(), strict=testcase.strict))\n    if isinstance(testcase.output, Err):\n        with pytest.raises(ValidationError, match=re.escape(testcase.output.message)):\n            v.validate_python(testcase.input)\n    else:\n        output = v.validate_python(testcase.input)\n        assert output == testcase.output\n        assert output is not testcase.input\n\n\n@pytest.mark.parametrize(\n    'testcase',\n    [\n        ListInputTestCase({1: 1, 2: 2, 3: 3}.items(), Err('Input should be a valid list [type=list_type,'), True),\n        ListInputTestCase(\n            MyMapping({1: 1, 2: 2, 3: 3}).items(), Err('Input should be a valid list [type=list_type,'), True\n        ),\n        ListInputTestCase({1: 1, 2: 2, 3: 3}.items(), [(1, 1), (2, 2), (3, 3)], False),\n        ListInputTestCase(MyMapping({1: 1, 2: 2, 3: 3}).items(), [(1, 1), (2, 2), (3, 3)], False),\n    ],\n    ids=repr,\n)\ndef test_list_dict_items_input(testcase: ListInputTestCase) -> None:\n    v = SchemaValidator(\n        core_schema.list_schema(\n            core_schema.tuple_positional_schema([core_schema.int_schema(), core_schema.int_schema()]),\n            strict=testcase.strict,\n        )\n    )\n    if isinstance(testcase.output, Err):\n        with pytest.raises(ValidationError, match=re.escape(testcase.output.message)):\n            v.validate_python(testcase.input)\n    else:\n        output = v.validate_python(testcase.input)\n        assert output == testcase.output\n        assert output is not testcase.input\n", "tests/validators/test_uuid.py": "import copy\nimport re\nfrom uuid import UUID\n\nimport pytest\n\nfrom pydantic_core import SchemaValidator, ValidationError, core_schema\n\nfrom ..conftest import Err, PyAndJson\n\n\nclass MyStr(str): ...\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        # Valid UUIDs\n        ('12345678-1234-1234-1234-567812345678', UUID('12345678-1234-1234-1234-567812345678')),\n        ('550e8400-e29b-41d4-a716-446655440000', UUID('550e8400-e29b-41d4-a716-446655440000')),\n        ('f47ac10b-58cc-4372-a567-0e02b2c3d479', UUID('f47ac10b-58cc-4372-a567-0e02b2c3d479')),\n        ('123e4567-e89b-12d3-a456-426655440000', UUID('123e4567-e89b-12d3-a456-426655440000')),\n        ('de305d54-75b4-431b-adb2-eb6b9e546014', UUID('de305d54-75b4-431b-adb2-eb6b9e546014')),\n        ('00000000-0000-0000-0000-000000000000', UUID('00000000-0000-0000-0000-000000000000')),\n        ('1b4e28ba-2fa1-11d2-883f-0016d3cca427', UUID('1b4e28ba-2fa1-11d2-883f-0016d3cca427')),\n        ('6ba7b810-9dad-11d1-80b4-00c04fd430c8', UUID('6ba7b810-9dad-11d1-80b4-00c04fd430c8')),\n        ('886313e1-3b8a-5372-9b90-0c9aee199e5d', UUID('886313e1-3b8a-5372-9b90-0c9aee199e5d')),\n        ('c0a8f9a8-aa5e-482b-a067-9cb3a51f5c11', UUID('c0a8f9a8-aa5e-482b-a067-9cb3a51f5c11')),\n        ('00000000-8000-4000-8000-000000000000', UUID('00000000-8000-4000-8000-000000000000')),\n        ('00000000-0000-4000-0000-000000000000', UUID('00000000-0000-4000-0000-000000000000')),\n        (MyStr('00000000-0000-4000-0000-000000000000'), UUID('00000000-0000-4000-0000-000000000000')),\n        (b'\\x12\\x34\\x56\\x78' * 4, UUID('12345678-1234-5678-1234-567812345678')),\n        (b'\\x00\\x00\\x00\\x00' * 4, UUID('00000000-0000-0000-0000-000000000000')),\n        (b'ebcdab58-6eb8-46fb-a190-d07a33e9eac8', UUID('ebcdab58-6eb8-46fb-a190-d07a33e9eac8')),\n        (UUID('12345678-1234-5678-1234-567812345678'), UUID('12345678-1234-5678-1234-567812345678')),\n        (UUID('550e8400-e29b-41d4-a716-446655440000'), UUID('550e8400-e29b-41d4-a716-446655440000')),\n        # Invalid UUIDs\n        (\n            'not-a-valid-uuid',\n            Err(\n                'Input should be a valid UUID, invalid character: expected an optional prefix of'\n                + ' `urn:uuid:` followed by [0-9a-fA-F-], found `n` at 1'\n            ),\n        ),\n        (\n            '12345678-1234-5678-1234-5678123456789',\n            Err('Input should be a valid UUID, invalid group length in group 4: expected 12, found 13'),\n        ),\n        (\n            '12345678-1234-1234-1234-1234567890123',\n            Err('Input should be a valid UUID, invalid group length in group 4: expected 12, found 13'),\n        ),\n        (b'\\x00\\x00\\x00\\x000' * 4, Err('Input should be a valid UUID, invalid length: expected 16 bytes, found 20')),\n        ('550e8400-e29b-41d4-a716', Err('Input should be a valid UUID, invalid group count: expected 5, found 4')),\n        (\n            'f47ac10b-58cc-4372-a567-0e02b2c3d47',\n            Err('Input should be a valid UUID, invalid group length in group 4: expected 12, found 11'),\n        ),\n        (\n            'de305d54-75b4-431b-adb2-eb6b9e54601',\n            Err('Input should be a valid UUID, invalid group length in group 4: expected 12, found 11'),\n        ),\n        (\n            '1b4e28ba-2fa1-11d2-883f-0016d3cca42',\n            Err('Input should be a valid UUID, invalid group length in group 4: expected 12, found 11'),\n        ),\n        (\n            '6ba7b810-9dad-11d1-80b4-00c04fd430c',\n            Err('Input should be a valid UUID, invalid group length in group 4: expected 12, found 11'),\n        ),\n        (\n            '886313e1-3b8a-5372-9b90-0c9aee199e5',\n            Err('Input should be a valid UUID, invalid group length in group 4: expected 12, found 11'),\n        ),\n        (\n            'c0a8f9a8-aa5e-482b-a067-9cb3a51f5c1',\n            Err('Input should be a valid UUID, invalid group length in group 4: expected 12, found 11'),\n        ),\n        (0xA1A2A3A4B1B2C1C2D1D2D3D4D5D6D7D8, Err('UUID input should be a string, bytes or UUID object')),\n        (00000000000000000000000000, Err('UUID input should be a string, bytes or UUID object')),\n    ],\n)\ndef test_uuid(input_value, expected):\n    v = SchemaValidator({'type': 'uuid'})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            result = v.validate_python(input_value)\n            print(f'input_value={input_value} result={result}')\n    else:\n        output = v.validate_python(input_value)\n        assert output == expected\n        assert isinstance(output, UUID)\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        (UUID('12345678-1234-5678-1234-567812345678'), UUID('12345678-1234-5678-1234-567812345678')),\n        ('12345678-1234-5678-1234-567812345678', Err('Input should be an instance of UUID [type=is_instance_of,')),\n        (b'12345678-1234-5678-1234-567812345678', Err('Input should be an instance of UUID [type=is_instance_of,')),\n        (1654646400, Err('Input should be an instance of UUID [type=is_instance_of')),\n    ],\n)\ndef test_uuid_strict(input_value, expected):\n    v = SchemaValidator({'type': 'uuid', 'strict': True})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_python(input_value)\n    else:\n        output = v.validate_python(input_value)\n        assert output == expected\n        assert isinstance(output, UUID)\n\n\n@pytest.mark.parametrize(\n    'input_value, version, expected',\n    [\n        # Valid UUIDs\n        ('a6cc5730-2261-11ee-9c43-2eb5a363657c', 1, UUID('a6cc5730-2261-11ee-9c43-2eb5a363657c')),\n        (UUID('a6cc5730-2261-11ee-9c43-2eb5a363657c'), 1, UUID('a6cc5730-2261-11ee-9c43-2eb5a363657c')),\n        ('04e4aeb3-8f20-30d0-8852-d295e1265eed', 3, UUID('04e4aeb3-8f20-30d0-8852-d295e1265eed')),\n        (UUID('04e4aeb3-8f20-30d0-8852-d295e1265eed'), 3, UUID('04e4aeb3-8f20-30d0-8852-d295e1265eed')),\n        ('0e7ac198-9acd-4c0c-b4b4-761974bf71d7', 4, UUID('0e7ac198-9acd-4c0c-b4b4-761974bf71d7')),\n        (UUID('0e7ac198-9acd-4c0c-b4b4-761974bf71d7'), 4, UUID('0e7ac198-9acd-4c0c-b4b4-761974bf71d7')),\n        ('0e7ac198-9acd-4c0c-b4b4-761974bf71d7', 4, UUID('0e7ac198-9acd-4c0c-b4b4-761974bf71d7')),\n        (UUID('0e7ac198-9acd-4c0c-b4b4-761974bf71d7'), 4, UUID('0e7ac198-9acd-4c0c-b4b4-761974bf71d7')),\n        # Cases from pydantic#7355 and pydantic#7537\n        # `UUID.version` makes sense for RFC 4122 UUIDs only. For non RFC 4122 UUIDs Python uses `UUID.version=None`\n        ('00000000-8000-4000-8000-000000000000', 4, UUID('00000000-8000-4000-8000-000000000000')),\n        (UUID('00000000-8000-4000-8000-000000000000'), 4, UUID('00000000-8000-4000-8000-000000000000')),\n        ('00000000-0000-4000-0000-000000000000', None, UUID('00000000-0000-4000-0000-000000000000')),\n        (UUID('00000000-0000-4000-0000-000000000000'), None, UUID('00000000-0000-4000-0000-000000000000')),\n        ('00000000-7fff-4000-7fff-000000000000', None, UUID('00000000-7fff-4000-7fff-000000000000')),\n        (UUID('00000000-7fff-4000-7fff-000000000000'), None, UUID('00000000-7fff-4000-7fff-000000000000')),\n        (UUID('00000000-7fff-4000-7fff-000000000000'), 4, Err('UUID version 4 expected')),\n        ('b34b6755-f49c-3bd2-6f06-131a708c2bf3', None, UUID('b34b6755-f49c-3bd2-6f06-131a708c2bf3')),\n        (UUID('b34b6755-f49c-3bd2-6f06-131a708c2bf3'), None, UUID('b34b6755-f49c-3bd2-6f06-131a708c2bf3')),\n        (UUID('b34b6755-f49c-3bd2-6f06-131a708c2bf3'), 4, Err('UUID version 4 expected')),\n        # Invalid UUIDs\n        ('a6cc5730-2261-11ee-9c43-2eb5a363657c', 5, Err('UUID version 5 expected')),\n        (UUID('a6cc5730-2261-11ee-9c43-2eb5a363657c'), 5, Err('UUID version 5 expected')),\n        ('04e4aeb3-8f20-30d0-8852-d295e1265eed', 4, Err('UUID version 4 expected')),\n        (UUID('04e4aeb3-8f20-30d0-8852-d295e1265eed'), 4, Err('UUID version 4 expected')),\n        ('0e7ac198-9acd-4c0c-b4b4-761974bf71d7', 3, Err('UUID version 3 expected')),\n        (UUID('0e7ac198-9acd-4c0c-b4b4-761974bf71d7'), 3, Err('UUID version 3 expected')),\n        ('08ed0736-fb95-5cc5-85ed-37e4f3df9b29', 1, Err('UUID version 1 expected')),\n        (UUID('08ed0736-fb95-5cc5-85ed-37e4f3df9b29'), 1, Err('UUID version 1 expected')),\n        ('00000000-0000-4000-0000-000000000000', 4, Err('UUID version 4 expected')),\n        (UUID('00000000-0000-4000-0000-000000000000'), 4, Err('UUID version 4 expected')),\n    ],\n)\ndef test_uuid_version(input_value, version, expected):\n    schema = {'type': 'uuid'}\n    if version is not None:\n        schema['version'] = version\n\n    v = SchemaValidator(schema)\n\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_python(input_value)\n    else:\n        output = v.validate_python(input_value)\n        assert output == expected\n        assert isinstance(output, UUID)\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ('a6cc5730-2261-11ee-9c43-2eb5a363657c', UUID('a6cc5730-2261-11ee-9c43-2eb5a363657c')),\n        ('12345678123456781234567812345678', UUID('12345678-1234-5678-1234-567812345678')),\n        (\n            'c0a8f9a8-aa5e-482b-a067-9cb3a51f5c1',\n            Err('Input should be a valid UUID, invalid group length in group 4: expected 12, found 11'),\n        ),\n        (1e1, Err('input should be a string, bytes or UUID object')),\n        (None, Err('input should be a string, bytes or UUID object')),\n        (True, Err('input should be a string, bytes or UUID object')),\n        (0xA1A2A3A4B1B2C1C2D1D2D3D4D5D6D7D8, Err('input should be a string, bytes or UUID object')),\n        (0x12345678123456781234567812345678, Err('input should be a string, bytes or UUID object')),\n    ],\n)\ndef test_uuid_json(py_and_json: PyAndJson, input_value, expected):\n    v = py_and_json({'type': 'uuid'})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_test(input_value)\n    else:\n        output = v.validate_test(input_value)\n        assert output == expected\n        assert isinstance(output, UUID)\n\n\ndef test_uuid_deepcopy():\n    output = SchemaValidator({'type': 'uuid'}).validate_python('a6cc5730-2261-11ee-9c43-2eb5a363657c')\n    c = copy.deepcopy(output)\n    assert repr(output) == \"UUID('a6cc5730-2261-11ee-9c43-2eb5a363657c')\"\n    assert c == output\n    assert isinstance(output, UUID)\n\n\ndef test_uuid_copy():\n    output = SchemaValidator({'type': 'uuid'}).validate_python('a6cc5730-2261-11ee-9c43-2eb5a363657c')\n    c = copy.copy(output)\n    assert repr(output) == \"UUID('a6cc5730-2261-11ee-9c43-2eb5a363657c')\"\n    assert c == output\n    assert isinstance(output, UUID)\n\n\ndef test_uuid_wrap_json():\n    # https://github.com/pydantic/pydantic/issues/8147\n    schema = core_schema.no_info_wrap_validator_function(lambda v, handler: handler(v), core_schema.uuid_schema())\n    v = SchemaValidator(schema)\n\n    assert v.validate_python(UUID('a6cc5730-2261-11ee-9c43-2eb5a363657c'), strict=True) == UUID(\n        'a6cc5730-2261-11ee-9c43-2eb5a363657c'\n    )\n    assert v.validate_json('\"a6cc5730-2261-11ee-9c43-2eb5a363657c\"', strict=True) == UUID(\n        'a6cc5730-2261-11ee-9c43-2eb5a363657c'\n    )\n", "tests/validators/test_with_default.py": "import gc\nimport platform\nimport sys\nimport weakref\nfrom collections import deque\nfrom typing import Any, Callable, Dict, List, Union, cast\n\nimport pytest\n\nfrom pydantic_core import (\n    ArgsKwargs,\n    PydanticUseDefault,\n    SchemaError,\n    SchemaValidator,\n    Some,\n    ValidationError,\n    core_schema,\n)\n\nfrom ..conftest import PyAndJson\n\n\ndef test_typed_dict_default():\n    v = SchemaValidator(\n        {\n            'type': 'typed-dict',\n            'fields': {\n                'x': {'type': 'typed-dict-field', 'schema': {'type': 'str'}},\n                'y': {\n                    'type': 'typed-dict-field',\n                    'schema': {'type': 'default', 'schema': {'type': 'str'}, 'default': '[default]'},\n                },\n            },\n        }\n    )\n    assert v.validate_python({'x': 'x', 'y': 'y'}) == {'x': 'x', 'y': 'y'}\n    assert v.validate_python({'x': 'x'}) == {'x': 'x', 'y': '[default]'}\n\n\ndef test_typed_dict_omit():\n    v = SchemaValidator(\n        {\n            'type': 'typed-dict',\n            'fields': {\n                'x': {'type': 'typed-dict-field', 'schema': {'type': 'str'}},\n                'y': {\n                    'type': 'typed-dict-field',\n                    'schema': {'type': 'default', 'schema': {'type': 'str'}, 'on_error': 'omit'},\n                    'required': False,\n                },\n            },\n        }\n    )\n    assert v.validate_python({'x': 'x', 'y': 'y'}) == {'x': 'x', 'y': 'y'}\n    assert v.validate_python({'x': 'x'}) == {'x': 'x'}\n    assert v.validate_python({'x': 'x', 'y': 42}) == {'x': 'x'}\n\n\ndef test_arguments():\n    v = SchemaValidator(\n        {\n            'type': 'arguments',\n            'arguments_schema': [\n                {\n                    'name': 'a',\n                    'mode': 'positional_or_keyword',\n                    'schema': {'type': 'default', 'schema': {'type': 'int'}, 'default_factory': lambda: 1},\n                }\n            ],\n        }\n    )\n    assert v.validate_python({'a': 2}) == ((), {'a': 2})\n    assert v.validate_python(ArgsKwargs((2,))) == ((2,), {})\n    assert v.validate_python(ArgsKwargs((2,), {})) == ((2,), {})\n    assert v.validate_python(()) == ((), {'a': 1})\n\n\ndef test_arguments_omit():\n    with pytest.raises(SchemaError, match=\"Parameter 'a': omit_on_error cannot be used with arguments\"):\n        SchemaValidator(\n            {\n                'type': 'arguments',\n                'arguments_schema': [\n                    {\n                        'name': 'a',\n                        'mode': 'positional_or_keyword',\n                        'schema': {'type': 'default', 'schema': {'type': 'int'}, 'default': 1, 'on_error': 'omit'},\n                    }\n                ],\n            }\n        )\n\n\n@pytest.mark.parametrize(\n    'input_value,expected', [([1, 2, 3], [1, 2, 3]), ([1, '2', 3], [1, 2, 3]), ([1, 'wrong', 3], [1, 3])]\n)\ndef test_list_json(py_and_json: PyAndJson, input_value, expected):\n    v = py_and_json(\n        {'type': 'list', 'items_schema': {'type': 'default', 'schema': {'type': 'int'}, 'on_error': 'omit'}}\n    )\n    assert v.validate_test(input_value) == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ([1, '2', 3], [1, 2, 3]),\n        ([1, 'wrong', 3], [1, 3]),\n        ((1, '2', 3), [1, 2, 3]),\n        ((1, 'wrong', 3), [1, 3]),\n        (deque([1, '2', 3]), [1, 2, 3]),\n        (deque([1, 'wrong', 3]), [1, 3]),\n    ],\n)\ndef test_list(input_value, expected):\n    v = SchemaValidator(\n        {'type': 'list', 'items_schema': {'type': 'default', 'schema': {'type': 'int'}, 'on_error': 'omit'}}\n    )\n    assert v.validate_python(input_value) == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ({1, '2', 3}, {1, 2, 3}),\n        ([1, '2', 3], {1, 2, 3}),\n        ([1, 'wrong', 3], {1, 3}),\n        (deque([1, '2', 3]), {1, 2, 3}),\n        (deque([1, 'wrong', 3]), {1, 3}),\n    ],\n)\ndef test_set(input_value, expected):\n    v = SchemaValidator(\n        {'type': 'set', 'items_schema': {'type': 'default', 'schema': {'type': 'int'}, 'on_error': 'omit'}}\n    )\n    assert v.validate_python(input_value) == expected\n\n\ndef test_dict_values(py_and_json: PyAndJson):\n    v = py_and_json(\n        {\n            'type': 'dict',\n            'keys_schema': {'type': 'str'},\n            'values_schema': {'type': 'default', 'schema': {'type': 'int'}, 'on_error': 'omit'},\n        }\n    )\n    assert v.validate_test({'a': 1, 'b': '2'}) == {'a': 1, 'b': 2}\n    assert v.validate_test({'a': 1, 'b': 'wrong'}) == {'a': 1}\n    assert v.validate_test({'a': 1, 'b': 'wrong', 'c': '3'}) == {'a': 1, 'c': 3}\n\n\ndef test_dict_keys():\n    v = SchemaValidator(\n        {\n            'type': 'dict',\n            'keys_schema': {'type': 'default', 'schema': {'type': 'int'}, 'on_error': 'omit'},\n            'values_schema': {'type': 'str'},\n        }\n    )\n    assert v.validate_python({1: 'a', '2': 'b'}) == {1: 'a', 2: 'b'}\n    assert v.validate_python({1: 'a', 'wrong': 'b'}) == {1: 'a'}\n    assert v.validate_python({1: 'a', 'wrong': 'b', 3: 'c'}) == {1: 'a', 3: 'c'}\n\n\ndef test_tuple_variable(py_and_json: PyAndJson):\n    v = py_and_json(\n        {\n            'type': 'tuple',\n            'items_schema': [{'type': 'default', 'schema': {'type': 'int'}, 'on_error': 'omit'}],\n            'variadic_item_index': 0,\n        }\n    )\n    assert v.validate_python((1, 2, 3)) == (1, 2, 3)\n    assert v.validate_python([1, '2', 3]) == (1, 2, 3)\n    assert v.validate_python([1, 'wrong', 3]) == (1, 3)\n\n\ndef test_tuple_positional():\n    v = SchemaValidator(\n        {\n            'type': 'tuple',\n            'items_schema': [{'type': 'int'}, {'type': 'default', 'schema': {'type': 'int'}, 'default': 42}],\n        }\n    )\n    assert v.validate_python((1, '2')) == (1, 2)\n    assert v.validate_python([1, '2']) == (1, 2)\n    assert v.validate_json('[1, \"2\"]') == (1, 2)\n    assert v.validate_python((1,)) == (1, 42)\n\n\ndef test_tuple_positional_omit():\n    v = SchemaValidator(\n        {\n            'type': 'tuple',\n            'items_schema': [\n                {'type': 'int'},\n                {'type': 'int'},\n                {'type': 'default', 'schema': {'type': 'int'}, 'on_error': 'omit'},\n            ],\n            'variadic_item_index': 2,\n        }\n    )\n    assert v.validate_python((1, '2')) == (1, 2)\n    assert v.validate_python((1, '2', 3, '4')) == (1, 2, 3, 4)\n    assert v.validate_python((1, '2', 'wrong', '4')) == (1, 2, 4)\n    assert v.validate_python((1, '2', 3, 'x4')) == (1, 2, 3)\n    assert v.validate_json('[1, \"2\", 3, \"x4\"]') == (1, 2, 3)\n\n\ndef test_on_error_default():\n    v = SchemaValidator({'type': 'default', 'schema': {'type': 'int'}, 'default': 2, 'on_error': 'default'})\n    assert v.validate_python(42) == 42\n    assert v.validate_python('42') == 42\n    assert v.validate_python('wrong') == 2\n\n\ndef test_factory_runtime_error():\n    def broken():\n        raise RuntimeError('this is broken')\n\n    v = SchemaValidator(\n        {'type': 'default', 'schema': {'type': 'int'}, 'on_error': 'default', 'default_factory': broken}\n    )\n    assert v.validate_python(42) == 42\n    assert v.validate_python('42') == 42\n    with pytest.raises(RuntimeError, match='this is broken'):\n        v.validate_python('wrong')\n\n\ndef test_factory_type_error():\n    def broken(x):\n        return 7\n\n    v = SchemaValidator(\n        {'type': 'default', 'schema': {'type': 'int'}, 'on_error': 'default', 'default_factory': broken}\n    )\n    assert v.validate_python(42) == 42\n    assert v.validate_python('42') == 42\n    with pytest.raises(TypeError, match=r\"broken\\(\\) missing 1 required positional argument: 'x'\"):\n        v.validate_python('wrong')\n\n\ndef test_typed_dict_error():\n    v = SchemaValidator(\n        {\n            'type': 'typed-dict',\n            'fields': {\n                'x': {'type': 'typed-dict-field', 'schema': {'type': 'str'}},\n                'y': {\n                    'type': 'typed-dict-field',\n                    'schema': {'type': 'default', 'schema': {'type': 'str'}, 'default_factory': lambda y: y * 2},\n                },\n            },\n        }\n    )\n    assert v.validate_python({'x': 'x', 'y': 'y'}) == {'x': 'x', 'y': 'y'}\n    with pytest.raises(TypeError, match=r\"<lambda>\\(\\) missing 1 required positional argument: 'y'\"):\n        v.validate_python({'x': 'x'})\n\n\ndef test_on_error_default_not_int():\n    v = SchemaValidator({'type': 'default', 'schema': {'type': 'int'}, 'default': [1, 2, 3], 'on_error': 'default'})\n    assert v.validate_python(42) == 42\n    assert v.validate_python('42') == 42\n    assert v.validate_python('wrong') == [1, 2, 3]\n\n\ndef test_on_error_default_factory():\n    v = SchemaValidator(\n        {'type': 'default', 'schema': {'type': 'int'}, 'default_factory': lambda: 17, 'on_error': 'default'}\n    )\n    assert v.validate_python(42) == 42\n    assert v.validate_python('42') == 42\n    assert v.validate_python('wrong') == 17\n\n\ndef test_on_error_omit():\n    v = SchemaValidator({'type': 'default', 'schema': {'type': 'int'}, 'on_error': 'omit'})\n    assert v.validate_python(42) == 42\n    with pytest.raises(SchemaError, match='Uncaught Omit error, please check your usage of `default` validators.'):\n        v.validate_python('wrong')\n\n\ndef test_on_error_wrong():\n    with pytest.raises(SchemaError, match=\"'on_error = default' requires a `default` or `default_factory`\"):\n        SchemaValidator({'type': 'default', 'schema': {'type': 'int'}, 'on_error': 'default'})\n\n\ndef test_build_default_and_default_factory():\n    with pytest.raises(SchemaError, match=\"'default' and 'default_factory' cannot be used together\"):\n        SchemaValidator({'type': 'default', 'schema': {'type': 'int'}, 'default_factory': lambda: 1, 'default': 2})\n\n\ndef test_model_class():\n    class MyModel:\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n        field_a: str\n        field_b: int\n\n    v = SchemaValidator(\n        {\n            'type': 'model',\n            'cls': MyModel,\n            'schema': {\n                'type': 'default',\n                'schema': {\n                    'type': 'model-fields',\n                    'fields': {\n                        'field_a': {'type': 'model-field', 'schema': {'type': 'str'}},\n                        'field_b': {'type': 'model-field', 'schema': {'type': 'int'}},\n                    },\n                },\n                'default': ({'field_a': '[default-a]', 'field_b': '[default-b]'}, None, set()),\n                'on_error': 'default',\n            },\n        }\n    )\n    m = v.validate_python({'field_a': 'test', 'field_b': 12})\n    assert isinstance(m, MyModel)\n    assert m.field_a == 'test'\n    assert m.field_b == 12\n    assert m.__pydantic_fields_set__ == {'field_a', 'field_b'}\n    m = v.validate_python({'field_a': 'test', 'field_b': 'wrong'})\n    assert isinstance(m, MyModel)\n    assert m.field_a == '[default-a]'\n    assert m.field_b == '[default-b]'\n    assert m.__pydantic_fields_set__ == set()\n\n\n@pytest.mark.parametrize('config_validate_default', [True, False, None])\n@pytest.mark.parametrize('schema_validate_default', [True, False, None])\n@pytest.mark.parametrize(\n    'inner_schema',\n    [\n        core_schema.no_info_after_validator_function(lambda x: x * 2, core_schema.int_schema()),\n        core_schema.no_info_before_validator_function(lambda x: str(int(x) * 2), core_schema.int_schema()),\n        core_schema.no_info_wrap_validator_function(lambda x, h: h(str(int(x) * 2)), core_schema.int_schema()),\n        core_schema.no_info_wrap_validator_function(lambda x, h: h(x) * 2, core_schema.int_schema()),\n    ],\n    ids=['after', 'before', 'wrap-before', 'wrap-after'],\n)\ndef test_validate_default(\n    config_validate_default: Union[bool, None],\n    schema_validate_default: Union[bool, None],\n    inner_schema: core_schema.CoreSchema,\n):\n    if config_validate_default is not None:\n        config = core_schema.CoreConfig(validate_default=config_validate_default)\n    else:\n        config = None\n    v = SchemaValidator(\n        core_schema.typed_dict_schema(\n            {\n                'x': core_schema.typed_dict_field(\n                    core_schema.with_default_schema(\n                        inner_schema, default='42', validate_default=schema_validate_default\n                    )\n                )\n            },\n            config=config,\n        )\n    )\n    assert v.validate_python({'x': '2'}) == {'x': 4}\n    expected = (\n        84\n        if (config_validate_default is True and schema_validate_default is not False or schema_validate_default is True)\n        else '42'\n    )\n    assert v.validate_python({}) == {'x': expected}\n\n\ndef test_validate_default_factory():\n    v = SchemaValidator(\n        core_schema.tuple_positional_schema(\n            [core_schema.with_default_schema(core_schema.int_schema(), default_factory=lambda: '42')]\n        ),\n        config=dict(validate_default=True),\n    )\n    assert v.validate_python(('2',)) == (2,)\n    assert v.validate_python(()) == (42,)\n\n\ndef test_validate_default_error_tuple():\n    v = SchemaValidator(\n        core_schema.tuple_positional_schema(\n            [core_schema.with_default_schema(core_schema.int_schema(), default='wrong', validate_default=True)]\n        )\n    )\n    assert v.validate_python(('2',)) == (2,)\n    with pytest.raises(ValidationError, match='Input should be a valid integer,') as exc_info:\n        v.validate_python(())\n\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'int_parsing',\n            'loc': (0,),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'wrong',\n        }\n    ]\n\n\ndef test_validate_default_error_typed_dict():\n    v = SchemaValidator(\n        core_schema.typed_dict_schema(\n            {\n                'x': core_schema.typed_dict_field(\n                    core_schema.with_default_schema(core_schema.int_schema(), default='xx', validate_default=True)\n                )\n            }\n        )\n    )\n    assert v.validate_python({'x': '2'}) == {'x': 2}\n    with pytest.raises(ValidationError, match='Input should be a valid integer,') as exc_info:\n        v.validate_python({})\n\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'int_parsing',\n            'loc': ('x',),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'xx',\n        }\n    ]\n\n\ndef test_deepcopy_mutable_defaults():\n    stored_empty_list = []\n    stored_empty_dict = {}\n\n    class Model:\n        int_list_with_default: List[int] = stored_empty_list\n        str_dict_with_default: Dict[str, str] = stored_empty_dict\n\n    v = SchemaValidator(\n        {\n            'type': 'model',\n            'cls': Model,\n            'schema': {\n                'type': 'model-fields',\n                'fields': {\n                    'int_list_with_default': {\n                        'type': 'model-field',\n                        'schema': {\n                            'type': 'default',\n                            'schema': {'type': 'list', 'items_schema': {'type': 'int'}},\n                            'default': stored_empty_list,\n                        },\n                    },\n                    'str_dict_with_default': {\n                        'type': 'model-field',\n                        'schema': {\n                            'type': 'default',\n                            'schema': {\n                                'type': 'dict',\n                                'keys_schema': {'type': 'str'},\n                                'values_schema': {'type': 'str'},\n                            },\n                            'default': stored_empty_dict,\n                        },\n                    },\n                },\n            },\n        }\n    )\n\n    m1 = v.validate_python({})\n\n    assert m1.int_list_with_default == []\n    assert m1.str_dict_with_default == {}\n\n    assert m1.int_list_with_default is not stored_empty_list\n    assert m1.str_dict_with_default is not stored_empty_dict\n\n    m1.int_list_with_default.append(1)\n    m1.str_dict_with_default['a'] = 'abc'\n\n    m2 = v.validate_python({})\n\n    assert m2.int_list_with_default == []\n    assert m2.str_dict_with_default == {}\n\n    assert m2.int_list_with_default is not m1.int_list_with_default\n    assert m2.str_dict_with_default is not m1.str_dict_with_default\n\n\ndef test_default_value() -> None:\n    s = core_schema.with_default_schema(core_schema.list_schema(core_schema.int_schema()), default=[1, 2, 3])\n\n    v = SchemaValidator(s)\n\n    r = v.get_default_value()\n    assert r is not None\n    assert r.value == [1, 2, 3]\n\n\ndef test_default_value_validate_default() -> None:\n    s = core_schema.with_default_schema(core_schema.list_schema(core_schema.int_schema()), default=['1', '2', '3'])\n\n    v = SchemaValidator(s, core_schema.CoreConfig(validate_default=True))\n\n    r = v.get_default_value()\n    assert r is not None\n    assert r.value == [1, 2, 3]\n\n\ndef test_default_value_validate_default_fail() -> None:\n    s = core_schema.with_default_schema(core_schema.list_schema(core_schema.int_schema()), default=['a'])\n\n    v = SchemaValidator(s, core_schema.CoreConfig(validate_default=True))\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.get_default_value()\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'int_parsing',\n            'loc': (0,),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'a',\n        }\n    ]\n\n\ndef test_default_value_validate_default_strict_pass() -> None:\n    s = core_schema.with_default_schema(core_schema.list_schema(core_schema.int_schema()), default=[1, 2, 3])\n\n    v = SchemaValidator(s, core_schema.CoreConfig(validate_default=True))\n\n    r = v.get_default_value(strict=True)\n    assert r is not None\n    assert r.value == [1, 2, 3]\n\n\ndef test_default_value_validate_default_strict_fail() -> None:\n    s = core_schema.with_default_schema(core_schema.list_schema(core_schema.int_schema()), default=['1'])\n\n    v = SchemaValidator(s, core_schema.CoreConfig(validate_default=True))\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.get_default_value(strict=True)\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'int_type', 'loc': (0,), 'msg': 'Input should be a valid integer', 'input': '1'}\n    ]\n\n\n@pytest.mark.parametrize('validate_default', [True, False])\ndef test_no_default_value(validate_default: bool) -> None:\n    s = core_schema.list_schema(core_schema.int_schema())\n    v = SchemaValidator(s, core_schema.CoreConfig(validate_default=validate_default))\n\n    assert v.get_default_value() is None\n\n\n@pytest.mark.parametrize('validate_default', [True, False])\ndef test_some(validate_default: bool) -> None:\n    def get_default() -> Union[Some[int], None]:\n        s = core_schema.with_default_schema(core_schema.int_schema(), default=42)\n        return SchemaValidator(s).get_default_value()\n\n    res = get_default()\n    assert res is not None\n    assert res.value == 42\n    assert repr(res) == 'Some(42)'\n\n\n@pytest.mark.skipif(sys.version_info < (3, 10), reason='pattern matching was added in 3.10')\ndef test_some_pattern_match() -> None:\n    code = \"\"\"\\\ndef f(v: Union[Some[Any], None]) -> str:\n    match v:\n        case Some(1):\n            return 'case1'\n        case Some(value=2):\n            return 'case2'\n        case Some(int(value)):\n            return f'case3: {value}'\n        case Some(value):\n            return f'case4: {type(value).__name__}({value})'\n        case None:\n            return 'case5'\n\"\"\"\n\n    local_vars = {}\n    exec(code, globals(), local_vars)\n    f = cast(Callable[[Union[Some[Any], None]], str], local_vars['f'])\n\n    res = f(SchemaValidator(core_schema.with_default_schema(core_schema.int_schema(), default=1)).get_default_value())\n    assert res == 'case1'\n\n    res = f(SchemaValidator(core_schema.with_default_schema(core_schema.int_schema(), default=2)).get_default_value())\n    assert res == 'case2'\n\n    res = f(SchemaValidator(core_schema.with_default_schema(core_schema.int_schema(), default=3)).get_default_value())\n    assert res == 'case3: 3'\n\n    res = f(SchemaValidator(core_schema.with_default_schema(core_schema.int_schema(), default='4')).get_default_value())\n    assert res == 'case4: str(4)'\n\n    res = f(SchemaValidator(core_schema.int_schema()).get_default_value())\n    assert res == 'case5'\n\n\ndef test_use_default_error() -> None:\n    def val_func(v: Any, handler: core_schema.ValidatorFunctionWrapHandler) -> Any:\n        if isinstance(v, str) and v == '':\n            raise PydanticUseDefault\n        return handler(v)\n\n    validator = SchemaValidator(\n        core_schema.with_default_schema(\n            core_schema.no_info_wrap_validator_function(val_func, core_schema.int_schema()), default=10\n        )\n    )\n\n    assert validator.validate_python('1') == 1\n    assert validator.validate_python('') == 10\n\n    # without a default value the error bubbles up\n    # the error message is the same as the error message produced by PydanticOmit\n    validator = SchemaValidator(\n        core_schema.with_default_schema(core_schema.no_info_wrap_validator_function(val_func, core_schema.int_schema()))\n    )\n    with pytest.raises(SchemaError, match='Uncaught UseDefault error, please check your usage of `default` validators'):\n        validator.validate_python('')\n\n    # same if there is no WithDefault validator\n    validator = SchemaValidator(core_schema.no_info_wrap_validator_function(val_func, core_schema.int_schema()))\n    with pytest.raises(SchemaError, match='Uncaught UseDefault error, please check your usage of `default` validators'):\n        validator.validate_python('')\n\n\n@pytest.mark.xfail(\n    condition=platform.python_implementation() == 'PyPy', reason='https://foss.heptapod.net/pypy/pypy/-/issues/3899'\n)\ndef test_leak_with_default():\n    def fn():\n        class Defaulted(int):\n            @classmethod\n            def _validator(cls, v, info):\n                return Defaulted(v)\n\n        schema = core_schema.with_info_plain_validator_function(Defaulted._validator)\n        schema = core_schema.with_default_schema(schema, default=Defaulted(0))\n\n        # If any of the Rust validators don't implement traversal properly,\n        # there will be an undetectable cycle created by this assignment\n        # which will keep Defaulted alive\n        Defaulted.__pydantic_validator__ = SchemaValidator(schema)\n\n        return Defaulted\n\n    klass = fn()\n    ref = weakref.ref(klass)\n    assert ref() is not None\n\n    del klass\n    gc.collect(0)\n    gc.collect(1)\n    gc.collect(2)\n    gc.collect()\n\n    assert ref() is None\n\n\nvalidate_default_raises_examples = [\n    (\n        {},\n        [\n            {'type': 'assertion_error', 'loc': ('x',), 'msg': 'Assertion failed, ', 'input': None},\n            {'type': 'assertion_error', 'loc': ('y',), 'msg': 'Assertion failed, ', 'input': None},\n            {'type': 'missing', 'loc': ('z',), 'msg': 'Field required', 'input': {}},\n        ],\n    ),\n    (\n        {'z': 'some str'},\n        [\n            {'type': 'assertion_error', 'loc': ('x',), 'msg': 'Assertion failed, ', 'input': None},\n            {'type': 'assertion_error', 'loc': ('y',), 'msg': 'Assertion failed, ', 'input': None},\n        ],\n    ),\n    (\n        {'x': None},\n        [\n            {'type': 'assertion_error', 'loc': ('x',), 'msg': 'Assertion failed, ', 'input': None},\n            {'type': 'assertion_error', 'loc': ('y',), 'msg': 'Assertion failed, ', 'input': None},\n            {'type': 'missing', 'loc': ('z',), 'msg': 'Field required', 'input': {'x': None}},\n        ],\n    ),\n    (\n        {'x': None, 'z': 'some str'},\n        [\n            {'type': 'assertion_error', 'loc': ('x',), 'msg': 'Assertion failed, ', 'input': None},\n            {'type': 'assertion_error', 'loc': ('y',), 'msg': 'Assertion failed, ', 'input': None},\n        ],\n    ),\n    (\n        {'y': None},\n        [\n            {'type': 'assertion_error', 'loc': ('x',), 'msg': 'Assertion failed, ', 'input': None},\n            {'type': 'assertion_error', 'loc': ('y',), 'msg': 'Assertion failed, ', 'input': None},\n            {'type': 'missing', 'loc': ('z',), 'msg': 'Field required', 'input': {'y': None}},\n        ],\n    ),\n    (\n        {'y': None, 'z': 'some str'},\n        [\n            {'type': 'assertion_error', 'loc': ('x',), 'msg': 'Assertion failed, ', 'input': None},\n            {'type': 'assertion_error', 'loc': ('y',), 'msg': 'Assertion failed, ', 'input': None},\n        ],\n    ),\n    (\n        {'x': None, 'y': None},\n        [\n            {'type': 'assertion_error', 'loc': ('x',), 'msg': 'Assertion failed, ', 'input': None},\n            {'type': 'assertion_error', 'loc': ('y',), 'msg': 'Assertion failed, ', 'input': None},\n            {'type': 'missing', 'loc': ('z',), 'msg': 'Field required', 'input': {'x': None, 'y': None}},\n        ],\n    ),\n    (\n        {'x': None, 'y': None, 'z': 'some str'},\n        [\n            {'type': 'assertion_error', 'loc': ('x',), 'msg': 'Assertion failed, ', 'input': None},\n            {'type': 'assertion_error', 'loc': ('y',), 'msg': 'Assertion failed, ', 'input': None},\n        ],\n    ),\n    (\n        {'x': 1, 'y': None, 'z': 'some str'},\n        [\n            {'type': 'assertion_error', 'loc': ('x',), 'msg': 'Assertion failed, ', 'input': 1},\n            {'type': 'assertion_error', 'loc': ('y',), 'msg': 'Assertion failed, ', 'input': None},\n        ],\n    ),\n    (\n        {'x': None, 'y': 1, 'z': 'some str'},\n        [\n            {'type': 'assertion_error', 'loc': ('x',), 'msg': 'Assertion failed, ', 'input': None},\n            {'type': 'assertion_error', 'loc': ('y',), 'msg': 'Assertion failed, ', 'input': 1},\n        ],\n    ),\n    (\n        {'x': 1, 'y': 1, 'z': 'some str'},\n        [\n            {'type': 'assertion_error', 'loc': ('x',), 'msg': 'Assertion failed, ', 'input': 1},\n            {'type': 'assertion_error', 'loc': ('y',), 'msg': 'Assertion failed, ', 'input': 1},\n        ],\n    ),\n]\n\n\n@pytest.mark.parametrize(\n    'core_schema_constructor,field_constructor',\n    [\n        (core_schema.model_fields_schema, core_schema.model_field),\n        (core_schema.typed_dict_schema, core_schema.typed_dict_field),\n    ],\n)\n@pytest.mark.parametrize('input_value,expected', validate_default_raises_examples)\ndef test_validate_default_raises(\n    core_schema_constructor: Union[core_schema.ModelFieldsSchema, core_schema.TypedDictSchema],\n    field_constructor: Union[core_schema.model_field, core_schema.typed_dict_field],\n    input_value: dict,\n    expected: Any,\n) -> None:\n    def _raise(ex: Exception) -> None:\n        raise ex()\n\n    inner_schema = core_schema.no_info_after_validator_function(\n        lambda x: _raise(AssertionError), core_schema.nullable_schema(core_schema.int_schema())\n    )\n\n    v = SchemaValidator(\n        core_schema_constructor(\n            {\n                'x': field_constructor(\n                    core_schema.with_default_schema(inner_schema, default=None, validate_default=True)\n                ),\n                'y': field_constructor(\n                    core_schema.with_default_schema(inner_schema, default=None, validate_default=True)\n                ),\n                'z': field_constructor(core_schema.str_schema()),\n            }\n        )\n    )\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python(input_value)\n        assert exc_info.value.errors(include_url=False, include_context=False) == expected\n\n\n@pytest.mark.parametrize('input_value,expected', validate_default_raises_examples)\ndef test_validate_default_raises_dataclass(input_value: dict, expected: Any) -> None:\n    def _raise(ex: Exception) -> None:\n        raise ex()\n\n    inner_schema = core_schema.no_info_after_validator_function(\n        lambda x: _raise(AssertionError), core_schema.nullable_schema(core_schema.int_schema())\n    )\n\n    x = core_schema.dataclass_field(\n        name='x', schema=core_schema.with_default_schema(inner_schema, default=None, validate_default=True)\n    )\n    y = core_schema.dataclass_field(\n        name='y', schema=core_schema.with_default_schema(inner_schema, default=None, validate_default=True)\n    )\n    z = core_schema.dataclass_field(name='z', schema=core_schema.str_schema())\n\n    v = SchemaValidator(core_schema.dataclass_args_schema('XYZ', [x, y, z]))\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python(input_value)\n\n    assert exc_info.value.errors(include_url=False, include_context=False) == expected\n", "tests/validators/test_generator.py": "import re\n\nimport pytest\nfrom dirty_equals import HasRepr, IsStr\n\nfrom pydantic_core import SchemaValidator, ValidationError\n\nfrom ..conftest import Err, PyAndJson\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ([1, 2, 3], [1, 2, 3]),\n        ([1, 2, '3'], [1, 2, 3]),\n        ({1: 2, 3: 4}, [1, 3]),\n        ('123', [1, 2, 3]),\n        (5, Err('[type=iterable_type, input_value=5, input_type=int]')),\n        ([1, 'wrong'], Err(\"[type=int_parsing, input_value='wrong', input_type=str]\")),\n    ],\n    ids=repr,\n)\ndef test_generator_json_int(py_and_json: PyAndJson, input_value, expected):\n    v = py_and_json({'type': 'generator', 'items_schema': {'type': 'int'}})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            list(v.validate_test(input_value))\n\n    else:\n        assert list(v.validate_test(input_value)) == expected\n\n\n@pytest.mark.parametrize(\n    'config,input_str',\n    (\n        ({}, 'type=iterable_type, input_value=5, input_type=int'),\n        ({'hide_input_in_errors': False}, 'type=iterable_type, input_value=5, input_type=int'),\n        ({'hide_input_in_errors': True}, 'type=iterable_type'),\n    ),\n)\ndef test_generator_json_hide_input(py_and_json: PyAndJson, config, input_str):\n    v = py_and_json({'type': 'generator', 'items_schema': {'type': 'int'}}, config)\n    with pytest.raises(ValidationError, match=re.escape(f'[{input_str}]')):\n        list(v.validate_test(5))\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ([1, 2, 3], [1, 2, 3]),\n        ([1, 2, '3'], [1, 2, '3']),\n        ({'1': 2, '3': 4}, ['1', '3']),\n        ('123', ['1', '2', '3']),\n        (5, Err('[type=iterable_type, input_value=5, input_type=int]')),\n        ([1, 'wrong'], [1, 'wrong']),\n    ],\n    ids=repr,\n)\ndef test_generator_json_any(py_and_json: PyAndJson, input_value, expected):\n    v = py_and_json({'type': 'generator'})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            list(v.validate_test(input_value))\n\n    else:\n        assert list(v.validate_test(input_value)) == expected\n\n\ndef test_error_index(py_and_json: PyAndJson):\n    v = py_and_json({'type': 'generator', 'items_schema': {'type': 'int'}})\n    gen = v.validate_test(['wrong'])\n    assert gen.index == 0\n    with pytest.raises(ValidationError) as exc_info:\n        next(gen)\n    assert gen.index == 1\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.title == 'ValidatorIterator'\n    assert str(exc_info.value).startswith('1 validation error for ValidatorIterator\\n')\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'int_parsing',\n            'loc': (0,),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'wrong',\n        }\n    ]\n    gen = v.validate_test([1, 2, 3, 'wrong', 4])\n    assert gen.index == 0\n    assert next(gen) == 1\n    assert gen.index == 1\n    assert next(gen) == 2\n    assert gen.index == 2\n    assert next(gen) == 3\n    assert gen.index == 3\n    with pytest.raises(ValidationError) as exc_info:\n        next(gen)\n    assert gen.index == 4\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'int_parsing',\n            'loc': (3,),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'wrong',\n        }\n    ]\n    assert next(gen) == 4\n    assert gen.index == 5\n\n\ndef test_too_long(py_and_json: PyAndJson):\n    v = py_and_json({'type': 'generator', 'items_schema': {'type': 'int'}, 'max_length': 2})\n    assert list(v.validate_test([1])) == [1]\n    assert list(v.validate_test([1, 2])) == [1, 2]\n    with pytest.raises(ValidationError) as exc_info:\n        list(v.validate_test([1, 2, 3]))\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'too_long',\n            'loc': (),\n            'msg': 'Generator should have at most 2 items after validation, not more',\n            'input': [1, 2, 3],\n            'ctx': {'field_type': 'Generator', 'max_length': 2, 'actual_length': None},\n        }\n    ]\n\n\ndef test_too_short(py_and_json: PyAndJson):\n    v = py_and_json({'type': 'generator', 'items_schema': {'type': 'int'}, 'min_length': 2})\n    assert list(v.validate_test([1, 2, 3])) == [1, 2, 3]\n    assert list(v.validate_test([1, 2])) == [1, 2]\n    with pytest.raises(ValidationError) as exc_info:\n        list(v.validate_test([1]))\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'too_short',\n            'loc': (),\n            'msg': 'Generator should have at least 2 items after validation, not 1',\n            'input': [1],\n            'ctx': {'field_type': 'Generator', 'min_length': 2, 'actual_length': 1},\n        }\n    ]\n\n\ndef gen():\n    yield 1\n    yield 2\n    yield 3\n\n\ndef test_generator_too_long():\n    v = SchemaValidator({'type': 'generator', 'items_schema': {'type': 'int'}, 'max_length': 2})\n\n    validating_iterator = v.validate_python(gen())\n\n    # Ensure the error happens at exactly the right step:\n    assert next(validating_iterator) == 1\n    assert next(validating_iterator) == 2\n    with pytest.raises(ValidationError) as exc_info:\n        next(validating_iterator)\n\n    errors = exc_info.value.errors(include_url=False)\n    # insert_assert(errors)\n    assert errors == [\n        {\n            'type': 'too_long',\n            'loc': (),\n            'input': HasRepr(IsStr(regex='<generator object gen at .+>')),\n            'msg': 'Generator should have at most 2 items after validation, not more',\n            'ctx': {'field_type': 'Generator', 'max_length': 2, 'actual_length': None},\n        }\n    ]\n\n\ndef test_generator_too_short():\n    v = SchemaValidator({'type': 'generator', 'items_schema': {'type': 'int'}, 'min_length': 4})\n\n    validating_iterator = v.validate_python(gen())\n\n    # Ensure the error happens at exactly the right step:\n    assert next(validating_iterator) == 1\n    assert next(validating_iterator) == 2\n    assert next(validating_iterator) == 3\n    with pytest.raises(ValidationError) as exc_info:\n        next(validating_iterator)\n\n    errors = exc_info.value.errors(include_url=False)\n    # insert_assert(errors)\n    assert errors == [\n        {\n            'type': 'too_short',\n            'input': HasRepr(IsStr(regex='<generator object gen at .+>')),\n            'loc': (),\n            'msg': 'Generator should have at least 4 items after validation, not 3',\n            'ctx': {'field_type': 'Generator', 'min_length': 4, 'actual_length': 3},\n        }\n    ]\n", "tests/validators/test_definitions_recursive.py": "import datetime\nimport platform\nfrom dataclasses import dataclass\nfrom typing import List, Optional\n\nimport pytest\nfrom dirty_equals import AnyThing, HasAttributes, IsList, IsPartialDict, IsStr, IsTuple\n\nimport pydantic_core\nfrom pydantic_core import SchemaError, SchemaValidator, ValidationError, core_schema\n\nfrom ..conftest import Err, plain_repr\nfrom .test_typed_dict import Cls\n\n\ndef test_branch_nullable():\n    v = SchemaValidator(\n        core_schema.definitions_schema(\n            {'type': 'definition-ref', 'schema_ref': 'Branch'},\n            [\n                {\n                    'type': 'typed-dict',\n                    'ref': 'Branch',\n                    'fields': {\n                        'name': {'type': 'typed-dict-field', 'schema': {'type': 'str'}},\n                        'sub_branch': {\n                            'type': 'typed-dict-field',\n                            'schema': {\n                                'type': 'default',\n                                'schema': {\n                                    'type': 'nullable',\n                                    'schema': {'type': 'definition-ref', 'schema_ref': 'Branch'},\n                                },\n                                'default': None,\n                            },\n                        },\n                    },\n                }\n            ],\n        )\n    )\n\n    assert v.validate_python({'name': 'root'}) == {'name': 'root', 'sub_branch': None}\n\n    assert v.validate_python({'name': 'root', 'sub_branch': {'name': 'b1'}}) == (\n        {'name': 'root', 'sub_branch': {'name': 'b1', 'sub_branch': None}}\n    )\n    assert v.validate_python({'name': 'root', 'sub_branch': {'name': 'b1', 'sub_branch': {'name': 'b2'}}}) == (\n        {'name': 'root', 'sub_branch': {'name': 'b1', 'sub_branch': {'name': 'b2', 'sub_branch': None}}}\n    )\n    assert ',definitions=[TypedDict(TypedDictValidator{' in plain_repr(v)\n\n\ndef test_unused_ref():\n    v = SchemaValidator(\n        {\n            'type': 'typed-dict',\n            'ref': 'Branch',\n            'fields': {\n                'name': {'type': 'typed-dict-field', 'schema': {'type': 'str'}},\n                'other': {'type': 'typed-dict-field', 'schema': {'type': 'int'}},\n            },\n        }\n    )\n    assert v.validate_python({'name': 'root', 'other': '4'}) == {'name': 'root', 'other': 4}\n\n\ndef test_nullable_error():\n    v = SchemaValidator(\n        core_schema.definitions_schema(\n            core_schema.definition_reference_schema('Branch'),\n            [\n                core_schema.typed_dict_schema(\n                    {\n                        'width': core_schema.typed_dict_field(core_schema.int_schema()),\n                        'sub_branch': core_schema.typed_dict_field(\n                            core_schema.with_default_schema(\n                                core_schema.union_schema(\n                                    [core_schema.none_schema(), core_schema.definition_reference_schema('Branch')]\n                                ),\n                                default=None,\n                            )\n                        ),\n                    },\n                    ref='Branch',\n                )\n            ],\n        )\n    )\n    assert v.validate_python({'width': 123, 'sub_branch': {'width': 321}}) == (\n        {'width': 123, 'sub_branch': {'width': 321, 'sub_branch': None}}\n    )\n    with pytest.raises(ValidationError) as exc_info:\n        assert v.validate_python({'width': 123, 'sub_branch': {'width': 'wrong'}})\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'none_required',\n            'loc': ('sub_branch', 'none'),\n            'msg': 'Input should be None',\n            'input': {'width': 'wrong'},\n        },\n        {\n            'type': 'int_parsing',\n            'loc': ('sub_branch', 'typed-dict', 'width'),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'wrong',\n        },\n    ]\n\n\ndef test_list():\n    v = SchemaValidator(\n        core_schema.definitions_schema(\n            core_schema.definition_reference_schema('BranchList'),\n            [\n                core_schema.typed_dict_schema(\n                    {\n                        'width': core_schema.typed_dict_field(core_schema.int_schema()),\n                        'branches': core_schema.typed_dict_field(\n                            core_schema.with_default_schema(\n                                core_schema.list_schema(core_schema.definition_reference_schema('BranchList')),\n                                default=None,\n                            )\n                        ),\n                    },\n                    ref='BranchList',\n                )\n            ],\n        )\n    )\n    assert v.validate_python({'width': 1, 'branches': [{'width': 2}, {'width': 3, 'branches': [{'width': 4}]}]}) == (\n        {\n            'width': 1,\n            'branches': [{'width': 2, 'branches': None}, {'width': 3, 'branches': [{'width': 4, 'branches': None}]}],\n        }\n    )\n    assert ',definitions=[TypedDict(TypedDictValidator{' in plain_repr(v)\n\n\ndef test_multiple_intertwined():\n    \"\"\"\n    like:\n    from typing import List, Optional\n    class Foo:\n        height: int\n        class Bar:\n            width: int\n            bars: List['Bar']\n            foo: Optional['Foo']\n        bar = Bar\n    \"\"\"\n\n    v = SchemaValidator(\n        core_schema.definitions_schema(\n            core_schema.definition_reference_schema('Foo'),\n            [\n                core_schema.typed_dict_schema(\n                    {\n                        'height': core_schema.typed_dict_field(core_schema.int_schema()),\n                        'bar': core_schema.typed_dict_field(core_schema.definition_reference_schema('Bar')),\n                    },\n                    ref='Foo',\n                ),\n                core_schema.typed_dict_schema(\n                    {\n                        'width': core_schema.typed_dict_field(core_schema.int_schema()),\n                        'bars': core_schema.typed_dict_field(\n                            core_schema.with_default_schema(\n                                core_schema.list_schema(core_schema.definition_reference_schema('Bar')), default=None\n                            )\n                        ),\n                        'foo': core_schema.typed_dict_field(\n                            core_schema.with_default_schema(\n                                core_schema.union_schema(\n                                    [core_schema.none_schema(), core_schema.definition_reference_schema('Foo')]\n                                ),\n                                default=None,\n                            )\n                        ),\n                    },\n                    ref='Bar',\n                ),\n            ],\n        )\n    )\n    v.validate_python(\n        {\n            'height': 1,\n            'bar': {\n                'width': 2,\n                'bars': [{'width': 3}],\n                'foo': {'height': 4, 'bar': {'width': 5, 'bars': [], 'foo': None}},\n            },\n        }\n    )\n\n\ndef test_model_class():\n    class Branch:\n        # this is not required, but it avoids `__pydantic_fields_set__` being included in `__dict__`\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n        # these are here just as decoration\n        width: int\n        branch: Optional['Branch']\n\n    v = SchemaValidator(\n        core_schema.definitions_schema(\n            core_schema.definition_reference_schema('Branch'),\n            [\n                core_schema.model_schema(\n                    Branch,\n                    core_schema.model_fields_schema(\n                        {\n                            'width': core_schema.model_field(core_schema.int_schema()),\n                            'branch': core_schema.model_field(\n                                core_schema.with_default_schema(\n                                    core_schema.union_schema(\n                                        [core_schema.none_schema(), core_schema.definition_reference_schema('Branch')]\n                                    ),\n                                    default=None,\n                                )\n                            ),\n                        }\n                    ),\n                    ref='Branch',\n                )\n            ],\n        )\n    )\n    m1: Branch = v.validate_python({'width': '1'})\n    assert isinstance(m1, Branch)\n    assert m1.__pydantic_fields_set__ == {'width'}\n    assert m1.__dict__ == {'width': 1, 'branch': None}\n    assert m1.width == 1\n    assert m1.branch is None\n\n    m2: Branch = v.validate_python({'width': '10', 'branch': {'width': 20}})\n    assert isinstance(m2, Branch)\n    assert m2.__pydantic_fields_set__ == {'width', 'branch'}\n    assert m2.width == 10\n    assert isinstance(m2.branch, Branch)\n    assert m2.branch.width == 20\n    assert m2.branch.branch is None\n\n\ndef test_invalid_schema():\n    with pytest.raises(SchemaError, match='Definitions error: definition `Branch` was never filled'):\n        SchemaValidator(\n            {\n                'type': 'list',\n                'items_schema': {\n                    'type': 'typed-dict',\n                    'fields': {\n                        'width': {'type': 'typed-dict-field', 'schema': {'type': 'int'}},\n                        'branch': {\n                            'type': 'typed-dict-field',\n                            'schema': {\n                                'type': 'default',\n                                'schema': {\n                                    'type': 'nullable',\n                                    'schema': {'type': 'definition-ref', 'schema_ref': 'Branch'},\n                                },\n                                'default': None,\n                            },\n                        },\n                    },\n                },\n            }\n        )\n\n\ndef test_outside_parent():\n    v = SchemaValidator(\n        core_schema.definitions_schema(\n            core_schema.typed_dict_schema(\n                {\n                    'tuple1': core_schema.typed_dict_field(core_schema.definition_reference_schema('tuple-iis')),\n                    'tuple2': core_schema.typed_dict_field(core_schema.definition_reference_schema('tuple-iis')),\n                }\n            ),\n            [\n                core_schema.tuple_schema(\n                    [core_schema.int_schema(), core_schema.int_schema(), core_schema.str_schema()], ref='tuple-iis'\n                )\n            ],\n        )\n    )\n\n    assert v.validate_python({'tuple1': [1, '1', 'frog'], 'tuple2': [2, '2', 'toad']}) == {\n        'tuple1': (1, 1, 'frog'),\n        'tuple2': (2, 2, 'toad'),\n    }\n\n\ndef test_recursion_branch():\n    v = SchemaValidator(\n        core_schema.definitions_schema(\n            core_schema.definition_reference_schema('Branch'),\n            [\n                core_schema.typed_dict_schema(\n                    {\n                        'name': core_schema.typed_dict_field(core_schema.str_schema()),\n                        'branch': core_schema.typed_dict_field(\n                            core_schema.with_default_schema(\n                                core_schema.nullable_schema(core_schema.definition_reference_schema('Branch')),\n                                default=None,\n                            )\n                        ),\n                    },\n                    ref='Branch',\n                )\n            ],\n        ),\n        {'from_attributes': True},\n    )\n    assert ',definitions=[TypedDict(TypedDictValidator{' in plain_repr(v)\n\n    assert v.validate_python({'name': 'root'}) == {'name': 'root', 'branch': None}\n    assert v.validate_python({'name': 'root', 'branch': {'name': 'b1', 'branch': None}}) == {\n        'name': 'root',\n        'branch': {'name': 'b1', 'branch': None},\n    }\n\n    b = {'name': 'recursive'}\n    b['branch'] = b\n    with pytest.raises(ValidationError) as exc_info:\n        assert v.validate_python(b)\n    assert exc_info.value.title == 'typed-dict'\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'recursion_loop',\n            'loc': ('branch',),\n            'msg': 'Recursion error - cyclic reference detected',\n            'input': {'name': 'recursive', 'branch': IsPartialDict(name='recursive')},\n        }\n    ]\n\n\ndef test_recursion_branch_from_attributes():\n    v = SchemaValidator(\n        core_schema.definitions_schema(\n            core_schema.definition_reference_schema('Branch'),\n            [\n                core_schema.model_fields_schema(\n                    {\n                        'name': core_schema.model_field(core_schema.str_schema()),\n                        'branch': core_schema.model_field(\n                            core_schema.with_default_schema(\n                                core_schema.nullable_schema(core_schema.definition_reference_schema('Branch')),\n                                default=None,\n                            )\n                        ),\n                    },\n                    ref='Branch',\n                )\n            ],\n        ),\n        {'from_attributes': True},\n    )\n\n    assert v.validate_python({'name': 'root'}) == ({'name': 'root', 'branch': None}, None, {'name'})\n    model_dict, model_extra, fields_set = v.validate_python({'name': 'root', 'branch': {'name': 'b1', 'branch': None}})\n    assert model_dict == {'name': 'root', 'branch': ({'name': 'b1', 'branch': None}, None, {'name', 'branch'})}\n    assert model_extra is None\n    assert fields_set == {'name', 'branch'}\n\n    data = Cls(name='root')\n    data.branch = Cls(name='b1', branch=None)\n    model_dict, model_extra, fields_set = v.validate_python(data)\n    assert model_dict == {'name': 'root', 'branch': ({'name': 'b1', 'branch': None}, None, {'name', 'branch'})}\n    assert model_extra is None\n    assert fields_set == {'name', 'branch'}\n\n    data = Cls(name='root')\n    data.branch = data\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python(data)\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'recursion_loop',\n            'loc': ('branch',),\n            'msg': 'Recursion error - cyclic reference detected',\n            'input': HasAttributes(name='root', branch=AnyThing()),\n        }\n    ]\n\n\ndef test_definition_list():\n    v = SchemaValidator(\n        core_schema.definitions_schema(\n            core_schema.definition_reference_schema('the-list'),\n            [core_schema.list_schema(core_schema.definition_reference_schema('the-list'), ref='the-list')],\n        )\n    )\n    assert ',definitions=[List(ListValidator{' in plain_repr(v)\n    assert v.validate_python([]) == []\n    assert v.validate_python([[]]) == [[]]\n\n    data = list()\n    data.append(data)\n    with pytest.raises(ValidationError) as exc_info:\n        assert v.validate_python(data)\n    assert exc_info.value.title == 'list[...]'\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'recursion_loop',\n            'loc': (0,),\n            'msg': 'Recursion error - cyclic reference detected',\n            'input': [IsList(length=1)],\n        }\n    ]\n\n\n@pytest.fixture(scope='module')\ndef multiple_tuple_schema() -> SchemaValidator:\n    return SchemaValidator(\n        core_schema.definitions_schema(\n            core_schema.typed_dict_schema(\n                {\n                    'f1': core_schema.typed_dict_field(core_schema.definition_reference_schema('t')),\n                    'f2': core_schema.typed_dict_field(\n                        core_schema.with_default_schema(\n                            core_schema.nullable_schema(core_schema.definition_reference_schema('t')), default=None\n                        )\n                    ),\n                }\n            ),\n            [\n                core_schema.tuple_schema(\n                    [\n                        core_schema.int_schema(),\n                        core_schema.nullable_schema(core_schema.definition_reference_schema('t')),\n                    ],\n                    ref='t',\n                )\n            ],\n        )\n    )\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ({'f1': [1, None]}, {'f1': (1, None), 'f2': None}),\n        ({'f1': [1, None], 'f2': [2, None]}, {'f1': (1, None), 'f2': (2, None)}),\n        (\n            {'f1': [1, (3, None)], 'f2': [2, (4, (4, (5, None)))]},\n            {'f1': (1, (3, None)), 'f2': (2, (4, (4, (5, None))))},\n        ),\n        ({'f1': [1, 2]}, Err(r'f1.1\\s+Input should be a valid tuple')),\n        ({'f1': [1, (3, None)], 'f2': [2, (4, (4, (5, 6)))]}, Err(r'f2.1.1.1.1\\s+Input should be a valid tuple')),\n    ],\n)\ndef test_multiple_tuple_param(multiple_tuple_schema: SchemaValidator, input_value, expected):\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=expected.message):\n            multiple_tuple_schema.validate_python(input_value)\n        # debug(repr(exc_info.value))\n    else:\n        assert multiple_tuple_schema.validate_python(input_value) == expected\n\n\ndef test_multiple_tuple_repeat(multiple_tuple_schema: SchemaValidator):\n    t = (42, None)\n    assert multiple_tuple_schema.validate_python({'f1': (1, t), 'f2': (2, t)}) == {\n        'f1': (1, (42, None)),\n        'f2': (2, (42, None)),\n    }\n\n\ndef test_multiple_tuple_recursion(multiple_tuple_schema: SchemaValidator):\n    data = [1]\n    data.append(data)\n    with pytest.raises(ValidationError) as exc_info:\n        multiple_tuple_schema.validate_python({'f1': data, 'f2': data})\n\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'recursion_loop',\n            'loc': ('f1', 1),\n            'msg': 'Recursion error - cyclic reference detected',\n            'input': [1, IsList(length=2)],\n        },\n        {\n            'type': 'recursion_loop',\n            'loc': ('f2', 1),\n            'msg': 'Recursion error - cyclic reference detected',\n            'input': [1, IsList(length=2)],\n        },\n    ]\n\n\ndef test_multiple_tuple_recursion_once(multiple_tuple_schema: SchemaValidator):\n    data = [1]\n    data.append(data)\n    with pytest.raises(ValidationError) as exc_info:\n        multiple_tuple_schema.validate_python({'f1': data, 'f2': data})\n\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'recursion_loop',\n            'loc': ('f1', 1),\n            'msg': 'Recursion error - cyclic reference detected',\n            'input': [1, IsList(length=2)],\n        },\n        {\n            'type': 'recursion_loop',\n            'loc': ('f2', 1),\n            'msg': 'Recursion error - cyclic reference detected',\n            'input': [1, IsList(length=2)],\n        },\n    ]\n\n\ndef test_definition_wrap():\n    def wrap_func(input_value, validator, info):\n        return validator(input_value) + (42,)\n\n    v = SchemaValidator(\n        core_schema.definitions_schema(\n            core_schema.definition_reference_schema('wrapper'),\n            [\n                core_schema.with_info_wrap_validator_function(\n                    wrap_func,\n                    core_schema.tuple_schema(\n                        [\n                            core_schema.int_schema(),\n                            core_schema.nullable_schema(core_schema.definition_reference_schema('wrapper')),\n                        ]\n                    ),\n                    ref='wrapper',\n                )\n            ],\n        )\n    )\n    assert v.validate_python((1, None)) == (1, None, 42)\n    assert v.validate_python((1, (2, (3, None)))) == (1, (2, (3, None, 42), 42), 42)\n    t = [1]\n    t.append(t)\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python(t)\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'recursion_loop',\n            'loc': (1,),\n            'msg': 'Recursion error - cyclic reference detected',\n            'input': IsList(positions={0: 1}, length=2),\n        }\n    ]\n\n\ndef test_union_ref_strictness():\n    v = SchemaValidator(\n        core_schema.definitions_schema(\n            core_schema.typed_dict_schema(\n                {\n                    'a': core_schema.typed_dict_field(core_schema.definition_reference_schema('int-type')),\n                    'b': core_schema.typed_dict_field(\n                        core_schema.union_schema(\n                            [core_schema.definition_reference_schema('int-type'), core_schema.str_schema()]\n                        )\n                    ),\n                }\n            ),\n            [core_schema.int_schema(ref='int-type')],\n        )\n    )\n    assert v.validate_python({'a': 1, 'b': '2'}) == {'a': 1, 'b': '2'}\n    assert v.validate_python({'a': 1, 'b': 2}) == {'a': 1, 'b': 2}\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python({'a': 1, 'b': []})\n\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'int_type', 'loc': ('b', 'int'), 'msg': 'Input should be a valid integer', 'input': []},\n        {'type': 'string_type', 'loc': ('b', 'str'), 'msg': 'Input should be a valid string', 'input': []},\n    ]\n\n\ndef test_union_container_strictness():\n    v = SchemaValidator(\n        core_schema.definitions_schema(\n            core_schema.typed_dict_schema(\n                {\n                    'b': core_schema.typed_dict_field(\n                        core_schema.union_schema(\n                            [core_schema.definition_reference_schema('int-type'), core_schema.str_schema()]\n                        )\n                    ),\n                    'a': core_schema.typed_dict_field(core_schema.definition_reference_schema('int-type')),\n                }\n            ),\n            [core_schema.int_schema(ref='int-type')],\n        )\n    )\n    assert v.validate_python({'a': 1, 'b': '2'}) == {'a': 1, 'b': '2'}\n    assert v.validate_python({'a': 1, 'b': 2}) == {'a': 1, 'b': 2}\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python({'a': 1, 'b': []})\n\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'int_type', 'loc': ('b', 'int'), 'msg': 'Input should be a valid integer', 'input': []},\n        {'type': 'string_type', 'loc': ('b', 'str'), 'msg': 'Input should be a valid string', 'input': []},\n    ]\n\n\n@pytest.mark.parametrize('strict', [True, False], ids=lambda s: f'strict={s}')\ndef test_union_cycle(strict: bool):\n    s = SchemaValidator(\n        core_schema.definitions_schema(\n            core_schema.definition_reference_schema('root-schema'),\n            [\n                core_schema.union_schema(\n                    [\n                        core_schema.typed_dict_schema(\n                            {\n                                'foobar': core_schema.typed_dict_field(\n                                    core_schema.list_schema(core_schema.definition_reference_schema('root-schema'))\n                                )\n                            }\n                        )\n                    ],\n                    auto_collapse=False,\n                    strict=strict,\n                    ref='root-schema',\n                )\n            ],\n        )\n    )\n\n    data = {'foobar': []}\n    data['foobar'].append(data)\n\n    with pytest.raises(ValidationError) as exc_info:\n        s.validate_python(data)\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'recursion_loop',\n            'loc': ('typed-dict', 'foobar', 0),\n            'msg': 'Recursion error - cyclic reference detected',\n            'input': {'foobar': [{'foobar': IsList(length=1)}]},\n        }\n    ]\n\n\ndef test_function_name():\n    def f(input_value, info):\n        return input_value + ' Changed'\n\n    v = SchemaValidator(\n        core_schema.definitions_schema(\n            core_schema.definition_reference_schema('root-schema'),\n            [\n                core_schema.union_schema(\n                    [\n                        core_schema.with_info_after_validator_function(\n                            f, core_schema.definition_reference_schema('root-schema')\n                        ),\n                        core_schema.int_schema(),\n                    ],\n                    ref='root-schema',\n                )\n            ],\n        )\n    )\n\n    assert v.validate_python(123) == 123\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python('input value')\n\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'recursion_loop',\n            'loc': ('function-after[f(), ...]',),\n            'msg': 'Recursion error - cyclic reference detected',\n            'input': 'input value',\n        },\n        {\n            'type': 'int_parsing',\n            'loc': ('int',),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'input value',\n        },\n    ]\n\n\n@pytest.mark.skipif(\n    platform.python_implementation() == 'PyPy' and pydantic_core._pydantic_core.build_profile == 'debug',\n    reason='PyPy does not have enough stack space for Rust debug builds to recurse very deep',\n)\n@pytest.mark.parametrize('strict', [True, False], ids=lambda s: f'strict={s}')\ndef test_function_change_id(strict: bool):\n    def f(input_value, info):\n        _, count = input_value.split('-')\n        return f'f-{int(count) + 1}'\n\n    v = SchemaValidator(\n        core_schema.definitions_schema(\n            core_schema.definition_reference_schema('root-schema'),\n            [\n                core_schema.union_schema(\n                    [\n                        core_schema.with_info_before_validator_function(\n                            f, core_schema.definition_reference_schema('root-schema')\n                        )\n                    ],\n                    auto_collapse=False,\n                    strict=strict,\n                    ref='root-schema',\n                )\n            ],\n        )\n    )\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python('start-0')\n\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'recursion_loop',\n            'loc': IsTuple(length=(1, 255)),\n            'msg': 'Recursion error - cyclic reference detected',\n            'input': IsStr(regex=r'f-\\d+'),\n        }\n    ]\n\n\ndef test_many_uses_of_ref():\n    # check we can safely exceed RECURSION_GUARD_LIMIT without upsetting the recursion guard\n    v = SchemaValidator(\n        core_schema.definitions_schema(\n            core_schema.definition_reference_schema('Branch'),\n            [\n                core_schema.typed_dict_schema(\n                    {\n                        'name': core_schema.typed_dict_field(core_schema.definition_reference_schema('limited-string')),\n                        'other_names': core_schema.typed_dict_field(\n                            core_schema.list_schema(core_schema.definition_reference_schema('limited-string'))\n                        ),\n                    },\n                    ref='Branch',\n                ),\n                core_schema.str_schema(max_length=8, ref='limited-string'),\n            ],\n        )\n    )\n\n    assert v.validate_python({'name': 'Anne', 'other_names': ['Bob', 'Charlie']}) == {\n        'name': 'Anne',\n        'other_names': ['Bob', 'Charlie'],\n    }\n\n    with pytest.raises(ValidationError, match=r'other_names.2\\s+String should have at most 8 characters'):\n        v.validate_python({'name': 'Anne', 'other_names': ['Bob', 'Charlie', 'Daveeeeee']})\n\n    long_input = {'name': 'Anne', 'other_names': [f'p-{i}' for i in range(300)]}\n    assert v.validate_python(long_input) == long_input\n\n\ndef test_error_inside_definition_wrapper():\n    with pytest.raises(SchemaError) as exc_info:\n        SchemaValidator(\n            {\n                'type': 'typed-dict',\n                'ref': 'Branch',\n                'fields': {\n                    'sub_branch': {\n                        'type': 'typed-dict-field',\n                        'schema': {\n                            'type': 'default',\n                            'schema': {\n                                'type': 'nullable',\n                                'schema': {'type': 'definition-ref', 'schema_ref': 'Branch'},\n                            },\n                            'default': None,\n                            'default_factory': lambda x: 'foobar',\n                        },\n                    }\n                },\n            }\n        )\n    assert str(exc_info.value) == (\n        'Error building \"typed-dict\" validator:\\n'\n        '  SchemaError: Field \"sub_branch\":\\n'\n        '  SchemaError: Error building \"default\" validator:\\n'\n        \"  SchemaError: 'default' and 'default_factory' cannot be used together\"\n    )\n\n\ndef test_recursive_definitions_schema(pydantic_version) -> None:\n    s = core_schema.definitions_schema(\n        core_schema.definition_reference_schema('a'),\n        [\n            core_schema.typed_dict_schema(\n                {\n                    'b': core_schema.typed_dict_field(\n                        core_schema.list_schema(core_schema.definition_reference_schema('b'))\n                    )\n                },\n                ref='a',\n            ),\n            core_schema.typed_dict_schema(\n                {\n                    'a': core_schema.typed_dict_field(\n                        core_schema.list_schema(core_schema.definition_reference_schema('a'))\n                    )\n                },\n                ref='b',\n            ),\n        ],\n    )\n\n    v = SchemaValidator(s)\n\n    assert v.validate_python({'b': [{'a': []}]}) == {'b': [{'a': []}]}\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python({'b': [{'a': {}}]})\n\n    assert exc_info.value.errors() == [\n        {\n            'type': 'list_type',\n            'loc': ('b', 0, 'a'),\n            'msg': 'Input should be a valid list',\n            'input': {},\n            'url': f'https://errors.pydantic.dev/{pydantic_version}/v/list_type',\n        }\n    ]\n\n\ndef test_unsorted_definitions_schema() -> None:\n    s = core_schema.definitions_schema(\n        core_schema.definition_reference_schema('td'),\n        [\n            core_schema.typed_dict_schema(\n                {'x': core_schema.typed_dict_field(core_schema.definition_reference_schema('int'))}, ref='td'\n            ),\n            core_schema.int_schema(ref='int'),\n        ],\n    )\n\n    v = SchemaValidator(s)\n\n    assert v.validate_python({'x': 123}) == {'x': 123}\n\n    with pytest.raises(ValidationError):\n        v.validate_python({'x': 'abc'})\n\n\ndef test_validate_assignment(pydantic_version) -> None:\n    @dataclass\n    class Model:\n        x: List['Model']\n\n    schema = core_schema.definitions_schema(\n        core_schema.definition_reference_schema('model'),\n        [\n            core_schema.dataclass_schema(\n                Model,\n                core_schema.dataclass_args_schema(\n                    'Model',\n                    [\n                        core_schema.dataclass_field(\n                            name='x',\n                            schema=core_schema.list_schema(core_schema.definition_reference_schema('model')),\n                            kw_only=False,\n                        )\n                    ],\n                ),\n                ['x'],\n                ref='model',\n                config=core_schema.CoreConfig(revalidate_instances='always'),\n            )\n        ],\n    )\n\n    v = SchemaValidator(schema)\n\n    data = [Model(x=[Model(x=[])])]\n    instance = Model(x=[])\n    v.validate_assignment(instance, 'x', data)\n    assert instance.x == data\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_assignment(instance, 'x', [Model(x=[Model(x=[Model(x=[123])])])])\n\n    assert exc_info.value.errors() == [\n        {\n            'type': 'dataclass_type',\n            'loc': ('x', 0, 'x', 0, 'x', 0, 'x', 0),\n            'msg': 'Input should be a dictionary or an instance of Model',\n            'input': 123,\n            'ctx': {'class_name': 'Model'},\n            'url': f'https://errors.pydantic.dev/{pydantic_version}/v/dataclass_type',\n        }\n    ]\n\n\ndef test_cyclic_data() -> None:\n    cyclic_data = {}\n    cyclic_data['b'] = {'a': cyclic_data}\n\n    schema = core_schema.definitions_schema(\n        core_schema.definition_reference_schema('a'),\n        [\n            core_schema.typed_dict_schema(\n                {\n                    'b': core_schema.typed_dict_field(\n                        core_schema.nullable_schema(core_schema.definition_reference_schema('b'))\n                    )\n                },\n                ref='a',\n            ),\n            core_schema.typed_dict_schema(\n                {\n                    'a': core_schema.typed_dict_field(\n                        core_schema.nullable_schema(core_schema.definition_reference_schema('a'))\n                    )\n                },\n                ref='b',\n            ),\n        ],\n    )\n\n    validator = SchemaValidator(schema)\n\n    with pytest.raises(ValidationError) as exc_info:\n        validator.validate_python(cyclic_data)\n\n    assert exc_info.value.title == 'typed-dict'\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'recursion_loop',\n            'loc': ('b', 'a'),\n            'msg': 'Recursion error - cyclic reference detected',\n            'input': cyclic_data,\n        }\n    ]\n\n\ndef test_cyclic_data_threeway() -> None:\n    cyclic_data = {}\n    cyclic_data['b'] = {'c': {'a': cyclic_data}}\n\n    schema = core_schema.definitions_schema(\n        core_schema.definition_reference_schema('a'),\n        [\n            core_schema.typed_dict_schema(\n                {\n                    'b': core_schema.typed_dict_field(\n                        core_schema.nullable_schema(core_schema.definition_reference_schema('b'))\n                    )\n                },\n                ref='a',\n            ),\n            core_schema.typed_dict_schema(\n                {\n                    'c': core_schema.typed_dict_field(\n                        core_schema.nullable_schema(core_schema.definition_reference_schema('c'))\n                    )\n                },\n                ref='b',\n            ),\n            core_schema.typed_dict_schema(\n                {\n                    'a': core_schema.typed_dict_field(\n                        core_schema.nullable_schema(core_schema.definition_reference_schema('a'))\n                    )\n                },\n                ref='c',\n            ),\n        ],\n    )\n\n    validator = SchemaValidator(schema)\n\n    with pytest.raises(ValidationError) as exc_info:\n        validator.validate_python(cyclic_data)\n\n    assert exc_info.value.title == 'typed-dict'\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'recursion_loop',\n            'loc': ('b', 'c', 'a'),\n            'msg': 'Recursion error - cyclic reference detected',\n            'input': cyclic_data,\n        }\n    ]\n\n\ndef test_complex_recursive_type() -> None:\n    schema = core_schema.definitions_schema(\n        core_schema.definition_reference_schema('JsonType'),\n        [\n            core_schema.nullable_schema(\n                core_schema.union_schema(\n                    [\n                        core_schema.list_schema(core_schema.definition_reference_schema('JsonType')),\n                        core_schema.dict_schema(\n                            core_schema.str_schema(), core_schema.definition_reference_schema('JsonType')\n                        ),\n                        core_schema.str_schema(),\n                        core_schema.int_schema(),\n                        core_schema.float_schema(),\n                        core_schema.bool_schema(),\n                    ]\n                ),\n                ref='JsonType',\n            )\n        ],\n    )\n\n    validator = SchemaValidator(schema)\n\n    with pytest.raises(ValidationError) as exc_info:\n        validator.validate_python({'a': datetime.date(year=1992, month=12, day=11)})\n\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'list_type',\n            'loc': ('list[nullable[union[list[...],dict[str,...],str,int,float,bool]]]',),\n            'msg': 'Input should be a valid list',\n            'input': {'a': datetime.date(1992, 12, 11)},\n        },\n        {\n            'type': 'list_type',\n            'loc': ('dict[str,...]', 'a', 'list[nullable[union[list[...],dict[str,...],str,int,float,bool]]]'),\n            'msg': 'Input should be a valid list',\n            'input': datetime.date(1992, 12, 11),\n        },\n        {\n            'type': 'dict_type',\n            'loc': ('dict[str,...]', 'a', 'dict[str,...]'),\n            'msg': 'Input should be a valid dictionary',\n            'input': datetime.date(1992, 12, 11),\n        },\n        {\n            'type': 'string_type',\n            'loc': ('dict[str,...]', 'a', 'str'),\n            'msg': 'Input should be a valid string',\n            'input': datetime.date(1992, 12, 11),\n        },\n        {\n            'type': 'int_type',\n            'loc': ('dict[str,...]', 'a', 'int'),\n            'msg': 'Input should be a valid integer',\n            'input': datetime.date(1992, 12, 11),\n        },\n        {\n            'type': 'float_type',\n            'loc': ('dict[str,...]', 'a', 'float'),\n            'msg': 'Input should be a valid number',\n            'input': datetime.date(1992, 12, 11),\n        },\n        {\n            'type': 'bool_type',\n            'loc': ('dict[str,...]', 'a', 'bool'),\n            'msg': 'Input should be a valid boolean',\n            'input': datetime.date(1992, 12, 11),\n        },\n        {\n            'type': 'string_type',\n            'loc': ('str',),\n            'msg': 'Input should be a valid string',\n            'input': {'a': datetime.date(1992, 12, 11)},\n        },\n        {\n            'type': 'int_type',\n            'loc': ('int',),\n            'msg': 'Input should be a valid integer',\n            'input': {'a': datetime.date(1992, 12, 11)},\n        },\n        {\n            'type': 'float_type',\n            'loc': ('float',),\n            'msg': 'Input should be a valid number',\n            'input': {'a': datetime.date(1992, 12, 11)},\n        },\n        {\n            'type': 'bool_type',\n            'loc': ('bool',),\n            'msg': 'Input should be a valid boolean',\n            'input': {'a': datetime.date(1992, 12, 11)},\n        },\n    ]\n\n\ndef test_no_exponential_blowup():\n    \"\"\"See https://github.com/pydantic/pydantic/issues/8049\n\n    There was a performance bug which led to exponential blowup when trying to\n    build a schema with many intermingled recursive definitions.\n    \"\"\"\n    unions = core_schema.union_schema([core_schema.definition_reference_schema(f'foo_{i}') for i in range(100)])\n\n    schema = core_schema.definitions_schema(\n        core_schema.typed_dict_schema({'x': core_schema.typed_dict_field(unions)}),\n        definitions=[\n            core_schema.typed_dict_schema({'a': core_schema.typed_dict_field(unions)}, ref=f'foo_{i}')\n            for i in range(100)\n        ],\n    )\n\n    SchemaValidator(schema)\n", "tests/validators/test_tuple.py": "import re\nfrom collections import deque\nfrom typing import Any, Dict, Type\n\nimport pytest\nfrom dirty_equals import IsNonNegative, IsTuple\n\nfrom pydantic_core import SchemaValidator, ValidationError, core_schema\n\nfrom ..conftest import Err, PyAndJson, infinite_generator\n\n\n@pytest.mark.parametrize(\n    'variadic_item_index,items,input_value,expected',\n    [\n        (0, [{'type': 'int'}], [1, 2, 3], (1, 2, 3)),\n        (0, [{'type': 'int'}], 1, Err('[type=tuple_type, input_value=1, input_type=int]')),\n        (None, [{'type': 'int'}, {'type': 'int'}, {'type': 'int'}], [1, 2, '3'], (1, 2, 3)),\n        (\n            None,\n            [{'type': 'int'}, {'type': 'int'}, {'type': 'int'}],\n            5,\n            Err('[type=tuple_type, input_value=5, input_type=int]'),\n        ),\n    ],\n    ids=repr,\n)\ndef test_tuple_json(py_and_json: PyAndJson, variadic_item_index, items, input_value, expected):\n    v = py_and_json(core_schema.tuple_schema(items_schema=items, variadic_item_index=variadic_item_index))\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_test(input_value)\n    else:\n        assert v.validate_test(input_value) == expected\n\n\ndef test_any_no_copy():\n    v = SchemaValidator({'type': 'tuple', 'items_schema': [{'type': 'any'}], 'variadic_item_index': 0})\n    input_value = (1, '2', b'3')\n    output = v.validate_python(input_value)\n    assert output == input_value\n    assert output is not input_value\n    assert id(output) != id(input_value)\n\n\n@pytest.mark.parametrize(\n    'variadic_item_index,items,input_value,expected',\n    [\n        (0, [{'type': 'int'}], (1, 2, '33'), (1, 2, 33)),\n        (0, [{'type': 'str'}], (b'1', b'2', '33'), ('1', '2', '33')),\n        (None, [{'type': 'int'}, {'type': 'str'}, {'type': 'float'}], (1, b'a', 33), (1, 'a', 33.0)),\n    ],\n)\ndef test_tuple_strict_passes_with_tuple(variadic_item_index, items, input_value, expected):\n    v = SchemaValidator(\n        core_schema.tuple_schema(items_schema=items, variadic_item_index=variadic_item_index, strict=True)\n    )\n    assert v.validate_python(input_value) == expected\n\n\n@pytest.mark.parametrize('fail_fast', [True, False])\ndef test_empty_positional_tuple(fail_fast):\n    v = SchemaValidator({'type': 'tuple', 'items_schema': [], 'fail_fast': fail_fast})\n    assert v.validate_python(()) == ()\n    assert v.validate_python([]) == ()\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python((1,))\n\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'too_long',\n            'loc': (),\n            'msg': 'Tuple should have at most 0 items after validation, not 1',\n            'input': (1,),\n            'ctx': {'field_type': 'Tuple', 'max_length': 0, 'actual_length': 1},\n        }\n    ]\n\n\n@pytest.mark.parametrize(\n    'variadic_item_index,items', [(0, [{'type': 'int'}]), (None, [{'type': 'int'}, {'type': 'int'}, {'type': 'int'}])]\n)\n@pytest.mark.parametrize('wrong_coll_type', [list, set, frozenset])\ndef test_tuple_strict_fails_without_tuple(wrong_coll_type: Type[Any], variadic_item_index, items):\n    v = SchemaValidator(\n        core_schema.tuple_schema(variadic_item_index=variadic_item_index, items_schema=items, strict=True)\n    )\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python(wrong_coll_type([1, 2, '33']))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'tuple_type',\n            'loc': (),\n            'msg': 'Input should be a valid tuple',\n            'input': wrong_coll_type([1, 2, '33']),\n        }\n    ]\n\n\n@pytest.mark.parametrize(\n    'kwargs,input_value,expected',\n    [\n        ({}, (1, 2, 3, 4), (1, 2, 3, 4)),\n        ({'min_length': 3}, (1, 2, 3, 4), (1, 2, 3, 4)),\n        ({'min_length': 3}, (1, 2), Err('Tuple should have at least 3 items after validation, not 2 [type=too_short,')),\n        ({'max_length': 4}, (1, 2, 3, 4), (1, 2, 3, 4)),\n        (\n            {'max_length': 3},\n            (1, 2, 3, 4),\n            Err('Tuple should have at most 3 items after validation, not 4 [type=too_long,'),\n        ),\n        (\n            {'max_length': 3},\n            [1, 2, 3, 4, 5],\n            Err('Tuple should have at most 3 items after validation, not 5 [type=too_long,'),\n        ),\n        (\n            {'max_length': 3},\n            infinite_generator(),\n            Err('Tuple should have at most 3 items after validation, not more [type=too_long,'),\n        ),\n    ],\n    ids=repr,\n)\ndef test_tuple_var_len_kwargs(kwargs: Dict[str, Any], input_value, expected):\n    v = SchemaValidator({'type': 'tuple', 'items_schema': [{'type': 'any'}], 'variadic_item_index': 0, **kwargs})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_python(input_value)\n    else:\n        assert v.validate_python(input_value) == expected\n\n\n@pytest.mark.parametrize(\n    'variadic_item_index,items', [(0, [{'type': 'int'}]), (None, [{'type': 'int'}, {'type': 'int'}, {'type': 'int'}])]\n)\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ((1, 2, '3'), (1, 2, 3)),\n        ([1, 2, '3'], (1, 2, 3)),\n        (deque((1, 2, '3')), (1, 2, 3)),\n        ({1: 10, 2: 20, '3': '30'}.keys(), (1, 2, 3)),\n        ({1: 10, 2: 20, '3': '30'}.values(), (10, 20, 30)),\n        ({1: 10, 2: 20, '3': '30'}, Err('Input should be a valid tuple [type=tuple_type,')),\n        ({1, 2, '3'}, IsTuple(1, 2, 3, check_order=False)),\n        (frozenset([1, 2, '3']), IsTuple(1, 2, 3, check_order=False)),\n    ],\n    ids=repr,\n)\ndef test_tuple_validate(input_value, expected, variadic_item_index, items):\n    v = SchemaValidator(core_schema.tuple_schema(items_schema=items, variadic_item_index=variadic_item_index))\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_python(input_value)\n    else:\n        assert v.validate_python(input_value) == expected\n\n\n# Since `test_tuple_validate` is parametrized above, the generator is consumed\n# on the first test run. This is a workaround to make sure the generator is\n# always recreated.\n@pytest.mark.parametrize(\n    'variadic_item_index,items', [(0, [{'type': 'int'}]), (None, [{'type': 'int'}, {'type': 'int'}, {'type': 'int'}])]\n)\ndef test_tuple_validate_iterator(variadic_item_index, items):\n    v = SchemaValidator(core_schema.tuple_schema(items_schema=items, variadic_item_index=variadic_item_index))\n    assert v.validate_python(x for x in [1, 2, '3']) == (1, 2, 3)\n\n\n@pytest.mark.parametrize(\n    'input_value,index',\n    [\n        (['wrong'], 0),\n        (('wrong',), 0),\n        ((1, 2, 3, 'wrong'), 3),\n        ((1, 2, 3, 'wrong', 4), 3),\n        ((1, 2, 'wrong'), IsNonNegative()),\n    ],\n)\ndef test_tuple_var_len_errors(input_value, index):\n    v = SchemaValidator({'type': 'tuple', 'items_schema': [{'type': 'int'}], 'variadic_item_index': 0})\n    with pytest.raises(ValidationError) as exc_info:\n        assert v.validate_python(input_value)\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'int_parsing',\n            'loc': (index,),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'wrong',\n        }\n    ]\n\n\n@pytest.mark.parametrize(\n    'input_value,items,index',\n    [\n        (['wrong'], [{'type': 'int'}], 0),\n        (('wrong',), [{'type': 'int'}], 0),\n        ((1, 2, 3, 'wrong'), [{'type': 'int'}, {'type': 'int'}, {'type': 'int'}, {'type': 'int'}], 3),\n        (\n            (1, 2, 3, 'wrong', 4),\n            [{'type': 'int'}, {'type': 'int'}, {'type': 'int'}, {'type': 'int'}, {'type': 'int'}],\n            3,\n        ),\n        ((1, 2, 'wrong'), [{'type': 'int'}, {'type': 'int'}, {'type': 'int'}], IsNonNegative()),\n    ],\n)\ndef test_tuple_fix_len_errors(input_value, items, index):\n    v = SchemaValidator({'type': 'tuple', 'items_schema': items})\n    with pytest.raises(ValidationError) as exc_info:\n        assert v.validate_python(input_value)\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'int_parsing',\n            'loc': (index,),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'wrong',\n        }\n    ]\n\n\ndef test_multiple_missing(py_and_json: PyAndJson):\n    v = py_and_json(\n        {'type': 'tuple', 'items_schema': [{'type': 'int'}, {'type': 'int'}, {'type': 'int'}, {'type': 'int'}]}\n    )\n    assert v.validate_test([1, 2, 3, 4]) == (1, 2, 3, 4)\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_test([1])\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'missing', 'loc': (1,), 'msg': 'Field required', 'input': [1]},\n        {'type': 'missing', 'loc': (2,), 'msg': 'Field required', 'input': [1]},\n        {'type': 'missing', 'loc': (3,), 'msg': 'Field required', 'input': [1]},\n    ]\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_test([1, 2, 3])\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'missing', 'loc': (3,), 'msg': 'Field required', 'input': [1, 2, 3]}\n    ]\n\n\ndef test_extra_arguments(py_and_json: PyAndJson):\n    v = py_and_json({'type': 'tuple', 'items_schema': [{'type': 'int'}, {'type': 'int'}]})\n    assert v.validate_test([1, 2]) == (1, 2)\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_test([1, 2, 3, 4])\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'too_long',\n            'loc': (),\n            'msg': 'Tuple should have at most 2 items after validation, not 4',\n            'input': [1, 2, 3, 4],\n            'ctx': {'field_type': 'Tuple', 'max_length': 2, 'actual_length': 4},\n        }\n    ]\n\n\ndef test_positional_empty(py_and_json: PyAndJson):\n    v = py_and_json({'type': 'tuple', 'items_schema': []})\n    assert v.validate_test([]) == ()\n    assert v.validate_python(()) == ()\n    with pytest.raises(ValidationError, match='type=too_long,'):\n        v.validate_test([1])\n\n\ndef test_positional_empty_extra(py_and_json: PyAndJson):\n    v = py_and_json({'type': 'tuple', 'items_schema': [{'type': 'int'}], 'variadic_item_index': 0})\n    assert v.validate_test([]) == ()\n    assert v.validate_python(()) == ()\n    assert v.validate_test([1]) == (1,)\n    assert v.validate_test(list(range(100))) == tuple(range(100))\n\n\n@pytest.mark.parametrize('input_value,expected', [((1, 2, 3), (1, 2, 3)), ([1, 2, 3], [1, 2, 3])])\ndef test_union_tuple_list(input_value, expected):\n    v = SchemaValidator(\n        {\n            'type': 'union',\n            'choices': [\n                {'type': 'tuple', 'items_schema': [{'type': 'any'}], 'variadic_item_index': 0},\n                {'type': 'list'},\n            ],\n        }\n    )\n    assert v.validate_python(input_value) == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ((1, 2, 3), (1, 2, 3)),\n        (('a', 'b', 'c'), ('a', 'b', 'c')),\n        (('a', b'a', 'c'), ('a', 'a', 'c')),\n        (\n            [5],\n            Err(\n                '2 validation errors for union',\n                errors=[\n                    {\n                        # first of all, not a tuple of ints ..\n                        'type': 'tuple_type',\n                        'loc': ('tuple[int, ...]',),\n                        'msg': 'Input should be a valid tuple',\n                        'input': [5],\n                    },\n                    # .. and not a tuple of strings, either\n                    {\n                        'type': 'tuple_type',\n                        'loc': ('tuple[str, ...]',),\n                        'msg': 'Input should be a valid tuple',\n                        'input': [5],\n                    },\n                ],\n            ),\n        ),\n    ],\n    ids=repr,\n)\ndef test_union_tuple_var_len(input_value, expected):\n    v = SchemaValidator(\n        {\n            'type': 'union',\n            'choices': [\n                {'type': 'tuple', 'items_schema': [{'type': 'int'}], 'variadic_item_index': 0, 'strict': True},\n                {'type': 'tuple', 'items_schema': [{'type': 'str'}], 'variadic_item_index': 0, 'strict': True},\n            ],\n        }\n    )\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)) as exc_info:\n            v.validate_python(input_value)\n        if expected.errors is not None:\n            assert exc_info.value.errors(include_url=False) == expected.errors\n    else:\n        assert v.validate_python(input_value) == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ((1, 2, 3), (1, 2, 3)),\n        (('a', 'b', 'c'), ('a', 'b', 'c')),\n        (\n            [5, '1', 1],\n            Err(\n                '2 validation errors for union',\n                errors=[\n                    {\n                        'type': 'tuple_type',\n                        'loc': ('tuple[int, int, int]',),\n                        'msg': 'Input should be a valid tuple',\n                        'input': [5, '1', 1],\n                    },\n                    {\n                        'type': 'tuple_type',\n                        'loc': ('tuple[str, str, str]',),\n                        'msg': 'Input should be a valid tuple',\n                        'input': [5, '1', 1],\n                    },\n                ],\n            ),\n        ),\n    ],\n    ids=repr,\n)\ndef test_union_tuple_fix_len(input_value, expected):\n    v = SchemaValidator(\n        {\n            'type': 'union',\n            'choices': [\n                {'type': 'tuple', 'items_schema': [{'type': 'int'}, {'type': 'int'}, {'type': 'int'}], 'strict': True},\n                {'type': 'tuple', 'items_schema': [{'type': 'str'}, {'type': 'str'}, {'type': 'str'}], 'strict': True},\n            ],\n        }\n    )\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)) as exc_info:\n            v.validate_python(input_value)\n        if expected.errors is not None:\n            assert exc_info.value.errors(include_url=False) == expected.errors\n    else:\n        assert v.validate_python(input_value) == expected\n\n\ndef test_tuple_fix_error():\n    v = SchemaValidator({'type': 'tuple', 'items_schema': [{'type': 'int'}, {'type': 'str'}]})\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python([1])\n\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'missing', 'loc': (1,), 'msg': 'Field required', 'input': [1]}\n    ]\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ([1, 'a'], (1, 'a')),\n        ((1, 'a'), (1, 'a')),\n        ((1, 'a', 'b'), (1, 'a', 'b')),\n        ([1, 'a', 'b', 'c', 'd'], (1, 'a', 'b', 'c', 'd')),\n        (deque([1, 'a', 'b', 'c', 'd']), (1, 'a', 'b', 'c', 'd')),\n        ([1], Err('type=missing', errors=[{'type': 'missing', 'loc': (1,), 'msg': 'Field required', 'input': [1]}])),\n    ],\n)\ndef test_tuple_fix_extra(input_value, expected):\n    v = SchemaValidator(\n        {'type': 'tuple', 'items_schema': [{'type': 'int'}, {'type': 'str'}, {'type': 'str'}], 'variadic_item_index': 2}\n    )\n\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)) as exc_info:\n            v.validate_python(input_value)\n        assert exc_info.value.errors(include_url=False) == expected.errors\n    else:\n        assert v.validate_python(input_value) == expected\n\n\ndef test_tuple_fix_extra_any():\n    v = SchemaValidator({'type': 'tuple', 'items_schema': [{'type': 'str'}, {'type': 'any'}], 'variadic_item_index': 1})\n    assert v.validate_python([b'1']) == ('1',)\n    assert v.validate_python([b'1', 2]) == ('1', 2)\n    assert v.validate_python((b'1', 2)) == ('1', 2)\n    assert v.validate_python([b'1', 2, b'3']) == ('1', 2, b'3')\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python([])\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'missing', 'loc': (0,), 'msg': 'Field required', 'input': []}\n    ]\n\n\ndef test_generator_error():\n    def gen(error: bool):\n        yield 1\n        yield 2\n        if error:\n            raise RuntimeError('error')\n        yield 3\n\n    v = SchemaValidator({'type': 'tuple', 'items_schema': [{'type': 'int'}], 'variadic_item_index': 0})\n    assert v.validate_python(gen(False)) == (1, 2, 3)\n\n    msg = r'Error iterating over object, error: RuntimeError: error \\[type=iteration_error,'\n    with pytest.raises(ValidationError, match=msg):\n        v.validate_python(gen(True))\n\n\n@pytest.mark.parametrize(\n    'input_value,items_schema,expected',\n    [\n        pytest.param(\n            {1: 10, 2: 20, '3': '30'}.items(),\n            {'type': 'tuple', 'items_schema': [{'type': 'any'}], 'variadic_item_index': 0},\n            ((1, 10), (2, 20), ('3', '30')),\n            id='Tuple[Any, Any]',\n        ),\n        pytest.param(\n            {1: 10, 2: 20, '3': '30'}.items(),\n            {'type': 'tuple', 'items_schema': [{'type': 'int'}], 'variadic_item_index': 0},\n            ((1, 10), (2, 20), (3, 30)),\n            id='Tuple[int, int]',\n        ),\n        pytest.param({1: 10, 2: 20, '3': '30'}.items(), {'type': 'any'}, ((1, 10), (2, 20), ('3', '30')), id='Any'),\n    ],\n)\ndef test_frozenset_from_dict_items(input_value, items_schema, expected):\n    v = SchemaValidator({'type': 'tuple', 'items_schema': [items_schema], 'variadic_item_index': 0})\n    output = v.validate_python(input_value)\n    assert isinstance(output, tuple)\n    assert output == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ([1, 2, 3, 4], (1, 2, 3, 4)),\n        ([1, 2, 3, 4, 5], Err('Tuple should have at most 4 items after validation, not 5 [type=too_long,')),\n        ([1, 2, 3, 'x', 4], (1, 2, 3, 4)),\n    ],\n)\ndef test_length_constraints_omit(input_value, expected):\n    v = SchemaValidator(\n        {\n            'type': 'tuple',\n            'items_schema': [{'type': 'default', 'schema': {'type': 'int'}, 'on_error': 'omit'}],\n            'variadic_item_index': 0,\n            'max_length': 4,\n        }\n    )\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_python(input_value)\n    else:\n        assert v.validate_python(input_value) == expected\n\n\n@pytest.mark.parametrize(\n    'fail_fast,expected',\n    [\n        pytest.param(\n            True,\n            [\n                {\n                    'type': 'int_parsing',\n                    'loc': (1,),\n                    'msg': 'Input should be a valid integer, unable to parse string as an integer',\n                    'input': 'not-num',\n                }\n            ],\n            id='fail_fast',\n        ),\n        pytest.param(\n            False,\n            [\n                {\n                    'type': 'int_parsing',\n                    'loc': (1,),\n                    'msg': 'Input should be a valid integer, unable to parse string as an integer',\n                    'input': 'not-num',\n                },\n                {\n                    'type': 'float_parsing',\n                    'loc': (2,),\n                    'msg': 'Input should be a valid number, unable to parse string as a number',\n                    'input': 'again',\n                },\n            ],\n            id='not_fail_fast',\n        ),\n    ],\n)\ndef test_tuple_fail_fast(fail_fast, expected):\n    s = core_schema.tuple_schema(\n        [\n            core_schema.str_schema(),\n            core_schema.int_schema(),\n            core_schema.float_schema(),\n        ],\n        variadic_item_index=None,\n        fail_fast=fail_fast,\n    )\n    v = SchemaValidator(s)\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python(['str', 'not-num', 'again'])\n\n    assert exc_info.value.errors(include_url=False) == expected\n", "tests/validators/test_url.py": "import re\nfrom copy import deepcopy\nfrom typing import Dict, Optional, Union\n\nimport pytest\nfrom dirty_equals import HasRepr, IsInstance\n\nfrom pydantic_core import MultiHostUrl, SchemaError, SchemaValidator, Url, ValidationError, core_schema\n\nfrom ..conftest import Err, PyAndJson\n\n\ndef test_url_ok(py_and_json: PyAndJson):\n    v = py_and_json(core_schema.url_schema())\n    url = v.validate_test('https://example.com/foo/bar?baz=qux#quux')\n\n    assert isinstance(url, Url)\n    assert str(url) == 'https://example.com/foo/bar?baz=qux#quux'\n    assert repr(url) == \"Url('https://example.com/foo/bar?baz=qux#quux')\"\n    assert url.unicode_string() == 'https://example.com/foo/bar?baz=qux#quux'\n    assert url.scheme == 'https'\n    assert url.host == 'example.com'\n    assert url.unicode_host() == 'example.com'\n    assert url.path == '/foo/bar'\n    assert url.query == 'baz=qux'\n    assert url.query_params() == [('baz', 'qux')]\n    assert url.fragment == 'quux'\n    assert url.username is None\n    assert url.password is None\n    assert url.port == 443\n\n\ndef test_url_from_constructor_ok():\n    url = Url('https://example.com/foo/bar?baz=qux#quux')\n\n    assert isinstance(url, Url)\n    assert str(url) == 'https://example.com/foo/bar?baz=qux#quux'\n    assert repr(url) == \"Url('https://example.com/foo/bar?baz=qux#quux')\"\n    assert url.unicode_string() == 'https://example.com/foo/bar?baz=qux#quux'\n    assert url.scheme == 'https'\n    assert url.host == 'example.com'\n    assert url.unicode_host() == 'example.com'\n    assert url.path == '/foo/bar'\n    assert url.query == 'baz=qux'\n    assert url.query_params() == [('baz', 'qux')]\n    assert url.fragment == 'quux'\n    assert url.username is None\n    assert url.password is None\n    assert url.port == 443\n\n\n@pytest.fixture(scope='module', name='url_validator')\ndef url_validator_fixture():\n    return SchemaValidator(core_schema.url_schema())\n\n\nSCHEMA_VALIDATOR_MODE = 'SCHEMA_VALIDATOR'\nURL_CLASS_MODE = 'URI_CLASS'\nMULTI_URL_CLASS_MODE = 'MULTI_URL_CLASS'\n\n\ndef url_test_case_helper(\n    url: str, expected: Union[Err, str], validator_mode: str, url_validator: Optional[SchemaValidator] = None\n):\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError) as exc_info:\n            if validator_mode == SCHEMA_VALIDATOR_MODE:\n                url_validator.validate_python(url)\n            elif validator_mode == URL_CLASS_MODE:\n                Url(url)\n            else:  # validator_mode == MULTI_URL_CLASS_MODE:\n                MultiHostUrl(url)\n        assert exc_info.value.error_count() == 1\n        error = exc_info.value.errors(include_url=False)[0]\n        assert error['type'] == 'url_parsing'\n        assert error['ctx']['error'] == expected.message\n    else:\n        if validator_mode == SCHEMA_VALIDATOR_MODE:\n            output_url = url_validator.validate_python(url)\n        elif validator_mode == URL_CLASS_MODE:\n            output_url = Url(url)\n        elif validator_mode == MULTI_URL_CLASS_MODE:\n            output_url = MultiHostUrl(url)\n        else:\n            raise ValueError(f'Unknown validator mode: {validator_mode}')\n        assert isinstance(output_url, (Url, MultiHostUrl))\n        if isinstance(expected, str):\n            assert str(output_url) == expected\n        else:\n            assert isinstance(expected, dict)\n            output_parts = {}\n            for key in expected:\n                if key == 'str()':\n                    output_parts[key] = str(output_url)\n                elif key.endswith('()'):\n                    output_parts[key] = getattr(output_url, key[:-2])()\n                else:\n                    output_parts[key] = getattr(output_url, key)\n            assert output_parts == expected\n\n\n@pytest.mark.parametrize('mode', [SCHEMA_VALIDATOR_MODE, URL_CLASS_MODE])\n@pytest.mark.parametrize(\n    'url,expected',\n    [\n        ('', Err('input is empty')),\n        (':,', Err('relative URL without a base')),\n        (\n            'http://example.com',\n            {\n                'str()': 'http://example.com/',\n                'host': 'example.com',\n                'unicode_host()': 'example.com',\n                'unicode_string()': 'http://example.com/',\n            },\n        ),\n        ('http://exa\\nmple.com', {'str()': 'http://example.com/', 'host': 'example.com'}),\n        ('xxx', Err('relative URL without a base')),\n        ('http://', Err('empty host')),\n        ('https://xn---', Err('invalid international domain name')),\n        ('http://example.com:65535', 'http://example.com:65535/'),\n        ('http:\\\\\\\\example.com', 'http://example.com/'),\n        ('http:example.com', 'http://example.com/'),\n        ('http://example.com:65536', Err('invalid port number')),\n        ('http://1...1', Err('invalid IPv4 address')),\n        ('https://[2001:0db8:85a3:0000:0000:8a2e:0370:7334[', Err('invalid IPv6 address')),\n        ('https://[', Err('invalid IPv6 address')),\n        ('https://example com', Err('invalid domain character')),\n        ('http://exam%ple.com', Err('invalid domain character')),\n        ('http:// /', Err('invalid domain character')),\n        ('/more', Err('relative URL without a base')),\n        ('http://example.com./foobar', {'str()': 'http://example.com./foobar'}),\n        # works since we're in lax mode\n        (b'http://example.com', {'str()': 'http://example.com/', 'unicode_host()': 'example.com'}),\n        ('http:/foo', {'str()': 'http://foo/'}),\n        ('http:///foo', {'str()': 'http://foo/'}),\n        ('http://exam_ple.com', {'str()': 'http://exam_ple.com/'}),\n        ('http://exam-ple.com', {'str()': 'http://exam-ple.com/'}),\n        ('http://example-.com', {'str()': 'http://example-.com/'}),\n        ('https://\u00a3\u00a3\u00a3.com', {'str()': 'https://xn--9aaa.com/'}),\n        ('https://foobar.\u00a3\u00a3\u00a3.com', {'str()': 'https://foobar.xn--9aaa.com/'}),\n        ('https://foo.\u00a3$.money.com', {'str()': 'https://foo.xn--$-9ba.money.com/'}),\n        ('https://xn--9aaa.com/', {'str()': 'https://xn--9aaa.com/'}),\n        ('https://m\u00fcnchen/', {'str()': 'https://xn--mnchen-3ya/'}),\n        ('http://\u00e0.\u05d0\u0308.com', {'str()': 'http://xn--0ca.xn--ssa73l.com/'}),\n        ('ssh://xn--9aaa.com/', 'ssh://xn--9aaa.com/'),\n        ('ssh://m\u00fcnchen.com/', 'ssh://m%C3%BCnchen.com/'),\n        ('ssh://example/', 'ssh://example/'),\n        ('ssh://\u00a3\u00a3\u00a3/', 'ssh://%C2%A3%C2%A3%C2%A3/'),\n        ('ssh://%C2%A3%C2%A3%C2%A3/', 'ssh://%C2%A3%C2%A3%C2%A3/'),\n        ('ftp://127.0.0.1', {'str()': 'ftp://127.0.0.1/', 'path': '/'}),\n        ('wss://1.1.1.1', {'str()': 'wss://1.1.1.1/', 'host': '1.1.1.1', 'unicode_host()': '1.1.1.1'}),\n        ('snap://[::1]', {'str()': 'snap://[::1]', 'host': '[::1]', 'unicode_host()': '[::1]'}),\n        (\n            'ftp://[2001:0db8:85a3:0000:0000:8a2e:0370:7334]',\n            {\n                'str()': 'ftp://[2001:db8:85a3::8a2e:370:7334]/',\n                'host': '[2001:db8:85a3::8a2e:370:7334]',\n                'unicode_host()': '[2001:db8:85a3::8a2e:370:7334]',\n            },\n        ),\n        ('foobar://127.0.0.1', {'str()': 'foobar://127.0.0.1', 'path': None}),\n        (\n            'mysql://[2001:0db8:85a3:0000:0000:8a2e:0370:7334]',\n            {'str()': 'mysql://[2001:db8:85a3::8a2e:370:7334]', 'path': None},\n        ),\n        (\n            'mysql://[2001:0db8:85a3:0000:0000:8a2e:0370:7334]/thing',\n            {'str()': 'mysql://[2001:db8:85a3::8a2e:370:7334]/thing', 'path': '/thing'},\n        ),\n        ('https:/more', {'str()': 'https://more/', 'host': 'more'}),\n        ('https:more', {'str()': 'https://more/', 'host': 'more'}),\n        ('file:///foobar', {'str()': 'file:///foobar', 'host': None, 'unicode_host()': None}),\n        ('file:///:80', {'str()': 'file:///:80'}),\n        ('file://:80', Err('invalid domain character')),\n        ('foobar://:80', Err('empty host')),\n        # with bashslashes\n        ('file:\\\\\\\\foobar\\\\more', {'str()': 'file://foobar/more', 'host': 'foobar', 'path': '/more'}),\n        ('http:\\\\\\\\foobar\\\\more', {'str()': 'http://foobar/more', 'host': 'foobar', 'path': '/more'}),\n        ('mongo:\\\\\\\\foobar\\\\more', {'str()': 'mongo:\\\\\\\\foobar\\\\more', 'host': None, 'path': '\\\\\\\\foobar\\\\more'}),\n        ('mongodb+srv://server.example.com/', 'mongodb+srv://server.example.com/'),\n        ('http://example.com.', {'host': 'example.com.', 'unicode_host()': 'example.com.'}),\n        ('http:/example.com', {'host': 'example.com', 'unicode_host()': 'example.com'}),\n        ('http:/foo', {'host': 'foo', 'unicode_host()': 'foo'}),\n        ('http://foo', {'host': 'foo', 'unicode_host()': 'foo'}),\n        ('http:///foo', {'host': 'foo', 'unicode_host()': 'foo'}),\n        ('http:////foo', {'host': 'foo', 'unicode_host()': 'foo'}),\n        ('http://-', {'host': '-', 'unicode_host()': '-'}),\n        ('http:////example.com', {'host': 'example.com', 'unicode_host()': 'example.com'}),\n        ('https://\u00a3\u00a3\u00a3.com', {'host': 'xn--9aaa.com', 'unicode_host()': '\u00a3\u00a3\u00a3.com'}),\n        ('https://\u00a3\u00a3\u00a3.com.', {'host': 'xn--9aaa.com.', 'unicode_host()': '\u00a3\u00a3\u00a3.com.'}),\n        ('https://xn--9aaa.com/', {'host': 'xn--9aaa.com', 'unicode_host()': '\u00a3\u00a3\u00a3.com'}),\n        (\n            'https://m\u00fcnchen/',\n            {'host': 'xn--mnchen-3ya', 'unicode_host()': 'm\u00fcnchen', 'unicode_string()': 'https://m\u00fcnchen/'},\n        ),\n        ('http://\u00e0.\u05d0\u0308.com', {'host': 'xn--0ca.xn--ssa73l.com', 'unicode_host()': '\u00e0.\u05d0\u0308.com'}),\n        ('ftp://xn--0ca.xn--ssa73l.com', {'host': 'xn--0ca.xn--ssa73l.com', 'unicode_host()': '\u00e0.\u05d0\u0308.com'}),\n        ('https://foobar.\u00a3\u00a3\u00a3.com/', {'host': 'foobar.xn--9aaa.com', 'unicode_host()': 'foobar.\u00a3\u00a3\u00a3.com'}),\n        ('https://\u00a3\u00a3\u00a3.com', {'unicode_string()': 'https://\u00a3\u00a3\u00a3.com/'}),\n        ('https://xn--9aaa.com/', {'unicode_string()': 'https://\u00a3\u00a3\u00a3.com/'}),\n        ('wss://1.1.1.1', {'unicode_string()': 'wss://1.1.1.1/'}),\n        ('file:///foobar', {'unicode_string()': 'file:///foobar'}),\n        (\n            'postgresql+py-postgresql://user:pass@localhost:5432/app',\n            {\n                'str()': 'postgresql+py-postgresql://user:pass@localhost:5432/app',\n                'username': 'user',\n                'password': 'pass',\n            },\n        ),\n        ('https://https/', {'host': 'https', 'unicode_host()': 'https'}),\n        ('http://user:@example.org', {'str()': 'http://user@example.org/', 'username': 'user', 'password': None}),\n        (\n            'http://us@er:p[ass@example.org',\n            {'str()': 'http://us%40er:p%5Bass@example.org/', 'username': 'us%40er', 'password': 'p%5Bass'},\n        ),\n        (\n            'http://us%40er:p%5Bass@example.org',\n            {'str()': 'http://us%40er:p%5Bass@example.org/', 'username': 'us%40er', 'password': 'p%5Bass'},\n        ),\n        (\n            'http://us[]er:p,ass@example.org',\n            {'str()': 'http://us%5B%5Der:p,ass@example.org/', 'username': 'us%5B%5Der', 'password': 'p,ass'},\n        ),\n        ('http://%2F:@example.org', {'str()': 'http://%2F@example.org/', 'username': '%2F', 'password': None}),\n        ('foo://user:@example.org', {'str()': 'foo://user@example.org', 'username': 'user', 'password': None}),\n        (\n            'foo://us@er:p[ass@example.org',\n            {'str()': 'foo://us%40er:p%5Bass@example.org', 'username': 'us%40er', 'password': 'p%5Bass'},\n        ),\n        (\n            'foo://us%40er:p%5Bass@example.org',\n            {'str()': 'foo://us%40er:p%5Bass@example.org', 'username': 'us%40er', 'password': 'p%5Bass'},\n        ),\n        (\n            'foo://us[]er:p,ass@example.org',\n            {'str()': 'foo://us%5B%5Der:p,ass@example.org', 'username': 'us%5B%5Der', 'password': 'p,ass'},\n        ),\n        ('foo://%2F:@example.org', {'str()': 'foo://%2F@example.org', 'username': '%2F', 'password': None}),\n        ('HTTP://EXAMPLE.ORG', {'str()': 'http://example.org/'}),\n        ('HTTP://EXAMPLE.org', {'str()': 'http://example.org/'}),\n        ('POSTGRES://EXAMPLE.ORG', {'str()': 'postgres://EXAMPLE.ORG'}),\n        ('https://twitter.com/@handle', {'str()': 'https://twitter.com/@handle', 'path': '/@handle'}),\n        ('  https://www.example.com \\n', 'https://www.example.com/'),\n        # https://www.xudongz.com/blog/2017/idn-phishing/ accepted but converted\n        ('https://www.\u0430\u0440\u0440\u04cf\u0435.com/', 'https://www.xn--80ak6aa92e.com/'),\n        ('https://exampl\u00a3e.org', 'https://xn--example-gia.org/'),\n        ('https://example.\u73e0\u5b9d', 'https://example.xn--pbt977c/'),\n        ('https://example.verm\u00f6gensberatung', 'https://example.xn--vermgensberatung-pwb/'),\n        ('https://example.\u0440\u0444', 'https://example.xn--p1ai/'),\n        ('https://exampl\u00a3e.\u73e0\u5b9d', 'https://xn--example-gia.xn--pbt977c/'),\n        ('ht\ud83d\udca3tp://example.org', Err('relative URL without a base')),\n        (\n            'http://us\u00dfer:pas\u211ds@a\ud83d\udca3b.com:123/c?d=e&d=f#g',\n            {\n                'str()': 'http://us%C3%9Fer:pas%E2%84%9Ds@xn--ab-qt72a.com:123/c?d=e&d=f#g',\n                'username': 'us%C3%9Fer',\n                'password': 'pas%E2%84%9Ds',\n                'host': 'xn--ab-qt72a.com',\n                'port': 123,\n                'path': '/c',\n                'query': 'd=e&d=f',\n                'query_params()': [('d', 'e'), ('d', 'f')],\n                'fragment': 'g',\n            },\n        ),\n    ],\n)\ndef test_url_cases(url_validator, url, expected, mode):\n    url_test_case_helper(url, expected, mode, url_validator)\n\n\n@pytest.mark.parametrize(\n    'validator_kwargs,url,expected',\n    [\n        (\n            dict(default_port=1234, default_path='/baz'),\n            'http://example.org',\n            {'str()': 'http://example.org:1234/baz', 'host': 'example.org', 'port': 1234, 'path': '/baz'},\n        ),\n        (dict(default_host='localhost'), 'redis://', {'str()': 'redis://localhost', 'host': 'localhost'}),\n    ],\n)\ndef test_url_defaults_single_url(validator_kwargs, url, expected):\n    s = SchemaValidator(core_schema.url_schema(**validator_kwargs))\n    url_test_case_helper(url, expected, SCHEMA_VALIDATOR_MODE, s)\n\n\n@pytest.mark.parametrize(\n    'validator_kwargs,url,expected',\n    [\n        (\n            dict(default_port=1234, default_path='/baz'),\n            'http://example.org',\n            {\n                'str()': 'http://example.org:1234/baz',\n                'hosts()': [{'host': 'example.org', 'password': None, 'port': 1234, 'username': None}],\n                'path': '/baz',\n            },\n        ),\n        (\n            dict(default_host='localhost'),\n            'redis://',\n            {\n                'str()': 'redis://localhost',\n                'hosts()': [{'host': 'localhost', 'password': None, 'port': None, 'username': None}],\n            },\n        ),\n        (\n            {},\n            'redis://localhost,127.0.0.1',\n            {\n                'str()': 'redis://localhost,127.0.0.1',\n                'hosts()': [\n                    {'host': 'localhost', 'password': None, 'port': None, 'username': None},\n                    {'host': '127.0.0.1', 'password': None, 'port': None, 'username': None},\n                ],\n            },\n        ),\n        ({}, 'redis://', {'str()': 'redis://', 'hosts()': []}),\n    ],\n)\ndef test_url_defaults_multi_host_url(validator_kwargs, url, expected):\n    s = SchemaValidator(core_schema.multi_host_url_schema(**validator_kwargs))\n    url_test_case_helper(url, expected, SCHEMA_VALIDATOR_MODE, s)\n\n\n@pytest.mark.parametrize(\n    'url,expected',\n    [\n        (\n            'http://example.org:1234/baz',\n            {\n                'str()': 'http://example.org:1234/baz',\n                'hosts()': [{'host': 'example.org', 'password': None, 'port': 1234, 'username': None}],\n                'path': '/baz',\n            },\n        ),\n        (\n            'redis://localhost,127.0.0.1',\n            {\n                'str()': 'redis://localhost,127.0.0.1',\n                'hosts()': [\n                    {'host': 'localhost', 'password': None, 'port': None, 'username': None},\n                    {'host': '127.0.0.1', 'password': None, 'port': None, 'username': None},\n                ],\n            },\n        ),\n        ('redis://', {'str()': 'redis://', 'hosts()': []}),\n    ],\n)\ndef test_multi_host_url(url, expected):\n    url_test_case_helper(url, expected, MULTI_URL_CLASS_MODE, None)\n\n\ndef test_multi_host_default_host_no_comma():\n    with pytest.raises(SchemaError, match='default_host cannot contain a comma, see pydantic-core#326'):\n        SchemaValidator(core_schema.multi_host_url_schema(default_host='foo,bar'))\n\n\n@pytest.fixture(scope='module', name='strict_url_validator')\ndef strict_url_validator_fixture():\n    return SchemaValidator(core_schema.url_schema(), {'strict': True})\n\n\n@pytest.mark.parametrize(\n    'url,expected',\n    [\n        ('http://example.com', {'str()': 'http://example.com/', 'host': 'example.com'}),\n        ('http://exa\\nmple.com', Err('tabs or newlines are ignored in URLs', 'url_syntax_violation')),\n        ('xxx', Err('relative URL without a base', 'url_parsing')),\n        ('http:/foo', Err('expected //', 'url_syntax_violation')),\n        ('http:///foo', Err('expected //', 'url_syntax_violation')),\n        ('http:////foo', Err('expected //', 'url_syntax_violation')),\n        ('http://exam_ple.com', {'str()': 'http://exam_ple.com/'}),\n        ('https:/more', Err('expected //', 'url_syntax_violation')),\n        ('https:more', Err('expected //', 'url_syntax_violation')),\n        ('file:///foobar', {'str()': 'file:///foobar', 'host': None, 'unicode_host()': None}),\n        ('file://:80', Err('invalid domain character', 'url_parsing')),\n        ('file:/xx', Err('expected // after file:', 'url_syntax_violation')),\n        ('foobar://:80', Err('empty host', 'url_parsing')),\n        ('mongodb+srv://server.example.com/', 'mongodb+srv://server.example.com/'),\n        ('http://user:@example.org', 'http://user@example.org/'),\n        ('http://us[er:@example.org', Err('non-URL code point', 'url_syntax_violation')),\n        ('http://us%5Ber:bar@example.org', 'http://us%5Ber:bar@example.org/'),\n        ('http://user:@example.org', 'http://user@example.org/'),\n        ('mongodb://us%5Ber:bar@example.org', 'mongodb://us%5Ber:bar@example.org'),\n        ('mongodb://us@er@example.org', Err('unencoded @ sign in username or password', 'url_syntax_violation')),\n    ],\n)\ndef test_url_error(strict_url_validator, url, expected):\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError) as exc_info:\n            strict_url_validator.validate_python(url)\n        assert exc_info.value.error_count() == 1\n        error = exc_info.value.errors(include_url=False)[0]\n        assert error['ctx']['error'] == expected.message\n        assert error['type'] == expected.errors\n    else:\n        output_url = strict_url_validator.validate_python(url)\n        assert isinstance(output_url, Url)\n        if isinstance(expected, str):\n            assert str(output_url) == expected\n        else:\n            assert isinstance(expected, dict)\n            output_parts = {}\n            for key in expected:\n                if key == 'str()':\n                    output_parts[key] = str(output_url)\n                elif key.endswith('()'):\n                    output_parts[key] = getattr(output_url, key[:-2])()\n                else:\n                    output_parts[key] = getattr(output_url, key)\n            assert output_parts == expected\n\n\ndef test_no_host(url_validator):\n    url = url_validator.validate_python('data:text/plain,Stuff')\n    assert str(url) == 'data:text/plain,Stuff'\n    assert url.host is None\n    assert url.scheme == 'data'\n    assert url.path == 'text/plain,Stuff'\n\n\ndef test_max_length():\n    v = SchemaValidator(core_schema.url_schema(max_length=25))\n    assert str(v.validate_python('https://example.com')) == 'https://example.com/'\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python('https://example.com/foo/bar')\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'url_too_long',\n            'loc': (),\n            'msg': 'URL should have at most 25 characters',\n            'input': 'https://example.com/foo/bar',\n            'ctx': {'max_length': 25},\n        }\n    ]\n\n\ndef test_allowed_schemes_ok():\n    v = SchemaValidator(core_schema.url_schema(allowed_schemes=['http', 'https']))\n    url = v.validate_python(' https://example.com ')\n    assert url.host == 'example.com'\n    assert url.scheme == 'https'\n    assert str(url) == 'https://example.com/'\n    assert str(v.validate_python('http://other.com')) == 'http://other.com/'\n\n\ndef test_allowed_schemes_error():\n    v = SchemaValidator(core_schema.url_schema(allowed_schemes=['http', 'https']))\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python('unix:/run/foo.socket')\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'url_scheme',\n            'loc': (),\n            'msg': \"URL scheme should be 'http' or 'https'\",\n            'input': 'unix:/run/foo.socket',\n            'ctx': {'expected_schemes': \"'http' or 'https'\"},\n        }\n    ]\n\n\ndef test_allowed_schemes_errors():\n    v = SchemaValidator(core_schema.url_schema(allowed_schemes=['a', 'b', 'c']))\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python('unix:/run/foo.socket')\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'url_scheme',\n            'loc': (),\n            'msg': \"URL scheme should be 'a', 'b' or 'c'\",\n            'input': 'unix:/run/foo.socket',\n            'ctx': {'expected_schemes': \"'a', 'b' or 'c'\"},\n        }\n    ]\n\n\ndef test_url_query_repeat(url_validator):\n    url: Url = url_validator.validate_python('https://example.com/foo/bar?a=1&a=2')\n    assert str(url) == 'https://example.com/foo/bar?a=1&a=2'\n    assert url.query_params() == [('a', '1'), ('a', '2')]\n\n\ndef test_url_to_url(url_validator, multi_host_url_validator):\n    url: Url = url_validator.validate_python('https://example.com')\n    assert isinstance(url, Url)\n    assert str(url) == 'https://example.com/'\n\n    url2 = url_validator.validate_python(url)\n    assert isinstance(url2, Url)\n    assert str(url2) == 'https://example.com/'\n    assert url is url2\n\n    multi_url = multi_host_url_validator.validate_python('https://example.com')\n    assert isinstance(multi_url, MultiHostUrl)\n\n    url3 = url_validator.validate_python(multi_url)\n    assert isinstance(url3, Url)\n    assert str(url3) == 'https://example.com/'\n\n    multi_url2 = multi_host_url_validator.validate_python('foobar://x:y@foo,x:y@bar.com')\n    assert isinstance(multi_url2, MultiHostUrl)\n\n    url4 = url_validator.validate_python(multi_url2)\n    assert isinstance(url4, Url)\n    assert str(url4) == 'foobar://x:y%40foo,x%3Ay@bar.com'\n    assert url4.host == 'bar.com'\n\n\ndef test_url_to_constraint():\n    v1 = SchemaValidator(core_schema.url_schema())\n    url: Url = v1.validate_python('http://example.com/foobar/bar')\n    assert str(url) == 'http://example.com/foobar/bar'\n\n    v2 = SchemaValidator(core_schema.url_schema(max_length=25))\n\n    with pytest.raises(ValidationError) as exc_info:\n        v2.validate_python(url)\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'url_too_long',\n            'loc': (),\n            'msg': 'URL should have at most 25 characters',\n            'input': IsInstance(Url) & HasRepr(\"Url('http://example.com/foobar/bar')\"),\n            'ctx': {'max_length': 25},\n        }\n    ]\n\n    v3 = SchemaValidator(core_schema.url_schema(allowed_schemes=['https']))\n\n    with pytest.raises(ValidationError) as exc_info:\n        v3.validate_python(url)\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'url_scheme',\n            'loc': (),\n            'msg': \"URL scheme should be 'https'\",\n            'input': IsInstance(Url) & HasRepr(\"Url('http://example.com/foobar/bar')\"),\n            'ctx': {'expected_schemes': \"'https'\"},\n        }\n    ]\n\n\ndef test_wrong_type_lax(url_validator):\n    assert str(url_validator.validate_python('http://example.com/foobar/bar')) == 'http://example.com/foobar/bar'\n    assert str(url_validator.validate_python(b'http://example.com/foobar/bar')) == 'http://example.com/foobar/bar'\n    with pytest.raises(ValidationError, match=r'URL input should be a string or URL \\[type=url_type,'):\n        url_validator.validate_python(123)\n\n    # runtime strict\n    with pytest.raises(ValidationError, match=r'URL input should be a string or URL \\[type=url_type,'):\n        url_validator.validate_python(b'http://example.com/foobar/bar', strict=True)\n\n\ndef test_wrong_type_strict(strict_url_validator):\n    url = strict_url_validator.validate_python('http://example.com/foobar/bar')\n    assert str(url) == 'http://example.com/foobar/bar'\n    assert str(strict_url_validator.validate_python(url)) == 'http://example.com/foobar/bar'\n    with pytest.raises(ValidationError, match=r'URL input should be a string or URL \\[type=url_type,'):\n        strict_url_validator.validate_python(b'http://example.com/foobar/bar')\n    with pytest.raises(ValidationError, match=r'URL input should be a string or URL \\[type=url_type,'):\n        strict_url_validator.validate_python(123)\n\n\n@pytest.mark.parametrize(\n    'input_value,expected,username,password',\n    [\n        ('https://apple:pie@example.com/foo', 'https://apple:pie@example.com/foo', 'apple', 'pie'),\n        ('https://apple:@example.com/foo', 'https://apple@example.com/foo', 'apple', None),\n        ('https://app$le:pie@example.com/foo', 'https://app$le:pie@example.com/foo', 'app$le', 'pie'),\n        ('https://app le:pie@example.com/foo', 'https://app%20le:pie@example.com/foo', 'app%20le', 'pie'),\n    ],\n)\ndef test_username(url_validator, input_value, expected, username, password):\n    url: Url = url_validator.validate_python(input_value)\n    assert isinstance(url, Url)\n    assert str(url) == expected\n    assert url.username == username\n    assert url.password == password\n\n\ndef test_strict_not_strict(url_validator, strict_url_validator, multi_host_url_validator):\n    url = url_validator.validate_python('http:/example.com/foobar/bar')\n    assert str(url) == 'http://example.com/foobar/bar'\n\n    url2 = strict_url_validator.validate_python(url)\n    assert str(url2) == 'http://example.com/foobar/bar'\n\n    multi_url = multi_host_url_validator.validate_python('https://example.com')\n    assert isinstance(multi_url, MultiHostUrl)\n\n    url3 = strict_url_validator.validate_python(multi_url)\n    assert isinstance(url3, Url)\n    assert str(url3) == 'https://example.com/'\n\n    multi_url2 = multi_host_url_validator.validate_python('foobar://x:y@foo,x:y@bar.com')\n    assert isinstance(multi_url2, MultiHostUrl)\n\n    with pytest.raises(ValidationError, match=r'unencoded @ sign in username or password \\[type=url_syntax_violation'):\n        strict_url_validator.validate_python(multi_url2)\n\n\ndef test_multi_host_url_ok_single(py_and_json: PyAndJson):\n    v = py_and_json(core_schema.multi_host_url_schema())\n    url: MultiHostUrl = v.validate_test('https://example.com/foo/bar?a=b')\n    assert isinstance(url, MultiHostUrl)\n    assert str(url) == 'https://example.com/foo/bar?a=b'\n    assert repr(url) == \"MultiHostUrl('https://example.com/foo/bar?a=b')\"\n    assert url.scheme == 'https'\n    assert url.path == '/foo/bar'\n    assert url.query == 'a=b'\n    assert url.query_params() == [('a', 'b')]\n    assert url.fragment is None\n    # insert_assert(url.hosts())\n    assert url.hosts() == [{'username': None, 'password': None, 'host': 'example.com', 'port': 443}]\n\n    url: MultiHostUrl = v.validate_test('postgres://foo:bar@example.com:1234')\n    assert isinstance(url, MultiHostUrl)\n    assert str(url) == 'postgres://foo:bar@example.com:1234'\n    assert url.scheme == 'postgres'\n    # insert_assert(url.hosts())\n    assert url.hosts() == [{'username': 'foo', 'password': 'bar', 'host': 'example.com', 'port': 1234}]\n\n\ndef test_multi_host_url_ok_2(py_and_json: PyAndJson):\n    v = py_and_json(core_schema.multi_host_url_schema())\n    url: MultiHostUrl = v.validate_test('https://foo.com,bar.com/path')\n    assert isinstance(url, MultiHostUrl)\n    assert str(url) == 'https://foo.com,bar.com/path'\n    assert url.scheme == 'https'\n    assert url.path == '/path'\n    # insert_assert(url.hosts())\n    assert url.hosts() == [\n        {'username': None, 'password': None, 'host': 'foo.com', 'port': 443},\n        {'username': None, 'password': None, 'host': 'bar.com', 'port': 443},\n    ]\n\n\n@pytest.fixture(scope='module', name='multi_host_url_validator')\ndef multi_host_url_validator_fixture():\n    return SchemaValidator(core_schema.multi_host_url_schema())\n\n\n@pytest.mark.parametrize(\n    'url,expected',\n    [\n        ('', Err('input is empty')),\n        (\n            'http://example.com',\n            {\n                'str()': 'http://example.com/',\n                'hosts()': [{'host': 'example.com', 'password': None, 'port': 80, 'username': None}],\n                'unicode_string()': 'http://example.com/',\n            },\n        ),\n        (\n            'postgres://example.com',\n            {\n                'str()': 'postgres://example.com',\n                'scheme': 'postgres',\n                'hosts()': [{'host': 'example.com', 'password': None, 'port': None, 'username': None}],\n            },\n        ),\n        (\n            'mongodb://foo,bar,spam/xxx',\n            {\n                'str()': 'mongodb://foo,bar,spam/xxx',\n                'scheme': 'mongodb',\n                'hosts()': [\n                    {'host': 'foo', 'password': None, 'port': None, 'username': None},\n                    {'host': 'bar', 'password': None, 'port': None, 'username': None},\n                    {'host': 'spam', 'password': None, 'port': None, 'username': None},\n                ],\n            },\n        ),\n        ('  mongodb://foo,bar,spam/xxx  ', 'mongodb://foo,bar,spam/xxx'),\n        (' \\n\\r\\t mongodb://foo,bar,spam/xxx', 'mongodb://foo,bar,spam/xxx'),\n        (\n            'mongodb+srv://foo,bar,spam/xxx',\n            {\n                'str()': 'mongodb+srv://foo,bar,spam/xxx',\n                'scheme': 'mongodb+srv',\n                'hosts()': [\n                    {'host': 'foo', 'password': None, 'port': None, 'username': None},\n                    {'host': 'bar', 'password': None, 'port': None, 'username': None},\n                    {'host': 'spam', 'password': None, 'port': None, 'username': None},\n                ],\n            },\n        ),\n        (\n            'https://foo:bar@example.com,fo%20o:bar@example.com',\n            {\n                'str()': 'https://foo:bar@example.com,fo%20o:bar@example.com/',\n                'scheme': 'https',\n                'hosts()': [\n                    {'host': 'example.com', 'password': 'bar', 'port': 443, 'username': 'foo'},\n                    {'host': 'example.com', 'password': 'bar', 'port': 443, 'username': 'fo%20o'},\n                ],\n            },\n        ),\n        (\n            'postgres://foo:bar@example.com,fo%20o:bar@example.com',\n            {\n                'str()': 'postgres://foo:bar@example.com,fo%20o:bar@example.com',\n                'scheme': 'postgres',\n                'hosts()': [\n                    {'host': 'example.com', 'password': 'bar', 'port': None, 'username': 'foo'},\n                    {'host': 'example.com', 'password': 'bar', 'port': None, 'username': 'fo%20o'},\n                ],\n            },\n        ),\n        ('postgres://', {'str()': 'postgres://', 'scheme': 'postgres', 'hosts()': []}),\n        ('postgres://,', Err('empty host')),\n        ('postgres://,,', Err('empty host')),\n        ('postgres://foo,\\n,bar', Err('empty host')),\n        ('postgres://\\n,bar', Err('empty host')),\n        ('postgres://foo,\\n', Err('empty host')),\n        ('postgres://foo,', Err('empty host')),\n        ('postgres://,foo', Err('empty host')),\n        ('http://', Err('empty host')),\n        ('http://,', Err('empty host')),\n        ('http://,,', Err('empty host')),\n        ('http://foo,\\n,bar', Err('empty host')),\n        ('http://\\n,bar', Err('empty host')),\n        ('http://foo,\\n', Err('empty host')),\n        ('http://foo,', Err('empty host')),\n        ('http://,foo', Err('empty host')),\n        ('http@foobar', Err('relative URL without a base')),\n        (\n            'mongodb://foo\\n,b\\nar,\\nspam/xxx',\n            {\n                'str()': 'mongodb://foo,bar,spam/xxx',\n                'scheme': 'mongodb',\n                'hosts()': [\n                    {'host': 'foo', 'password': None, 'port': None, 'username': None},\n                    {'host': 'bar', 'password': None, 'port': None, 'username': None},\n                    {'host': 'spam', 'password': None, 'port': None, 'username': None},\n                ],\n            },\n        ),\n        (\n            'postgres://user:pass@host1.db.net:4321,host2.db.net:6432/app',\n            {\n                'str()': 'postgres://user:pass@host1.db.net:4321,host2.db.net:6432/app',\n                'scheme': 'postgres',\n                'hosts()': [\n                    {'host': 'host1.db.net', 'password': 'pass', 'port': 4321, 'username': 'user'},\n                    {'host': 'host2.db.net', 'password': None, 'port': 6432, 'username': None},\n                ],\n                'path': '/app',\n            },\n        ),\n        (\n            'postgresql+py-postgresql://user:pass@localhost:5432/app',\n            {\n                'str()': 'postgresql+py-postgresql://user:pass@localhost:5432/app',\n                'hosts()': [{'host': 'localhost', 'password': 'pass', 'port': 5432, 'username': 'user'}],\n            },\n        ),\n        ('http://foo#bar', 'http://foo/#bar'),\n        ('mongodb://foo#bar', 'mongodb://foo#bar'),\n        ('http://foo,bar#spam', 'http://foo,bar/#spam'),\n        ('mongodb://foo,bar#spam', 'mongodb://foo,bar#spam'),\n        ('http://foo,bar?x=y', 'http://foo,bar/?x=y'),\n        ('mongodb://foo,bar?x=y', 'mongodb://foo,bar?x=y'),\n        ('foo://foo,bar?x=y', 'foo://foo,bar?x=y'),\n        (\n            (\n                'mongodb://mongodb1.example.com:27317,mongodb2.example.com:27017/'\n                'mydatabase?replicaSet=mySet&authSource=authDB'\n            ),\n            {\n                'str()': (\n                    'mongodb://mongodb1.example.com:27317,mongodb2.example.com:27017/'\n                    'mydatabase?replicaSet=mySet&authSource=authDB'\n                ),\n                'hosts()': [\n                    {'host': 'mongodb1.example.com', 'password': None, 'port': 27317, 'username': None},\n                    {'host': 'mongodb2.example.com', 'password': None, 'port': 27017, 'username': None},\n                ],\n                'query_params()': [('replicaSet', 'mySet'), ('authSource', 'authDB')],\n            },\n        ),\n        # with bashslashes\n        (\n            'FILE:\\\\\\\\foo,bar\\\\more',\n            {\n                'str()': 'file://foo,bar/more',\n                'path': '/more',\n                'hosts()': [\n                    {'host': 'foo', 'password': None, 'port': None, 'username': None},\n                    {'host': 'bar', 'password': None, 'port': None, 'username': None},\n                ],\n            },\n        ),\n        (\n            'http:\\\\\\\\foo,bar\\\\more',\n            {\n                'str()': 'http://foo,bar/more',\n                'path': '/more',\n                'hosts()': [\n                    {'host': 'foo', 'password': None, 'port': 80, 'username': None},\n                    {'host': 'bar', 'password': None, 'port': 80, 'username': None},\n                ],\n            },\n        ),\n        ('mongo:\\\\\\\\foo,bar\\\\more', Err('empty host')),\n        (\n            'foobar://foo[]bar:x@y@whatever,foo[]bar:x@y@whichever',\n            {\n                'str()': 'foobar://foo%5B%5Dbar:x%40y@whatever,foo%5B%5Dbar:x%40y@whichever',\n                'hosts()': [\n                    {'host': 'whatever', 'password': 'x%40y', 'port': None, 'username': 'foo%5B%5Dbar'},\n                    {'host': 'whichever', 'password': 'x%40y', 'port': None, 'username': 'foo%5B%5Dbar'},\n                ],\n            },\n        ),\n        (\n            'foobar://foo%2Cbar:x@y@whatever,snap',\n            {\n                'str()': 'foobar://foo%2Cbar:x%40y@whatever,snap',\n                'hosts()': [\n                    {'host': 'whatever', 'password': 'x%40y', 'port': None, 'username': 'foo%2Cbar'},\n                    {'host': 'snap', 'password': None, 'port': None, 'username': None},\n                ],\n            },\n        ),\n        (\n            'mongodb://x:y@[::1],1.1.1.1:888/xxx',\n            {\n                'str()': 'mongodb://x:y@[::1],1.1.1.1:888/xxx',\n                'scheme': 'mongodb',\n                'hosts()': [\n                    {'host': '[::1]', 'password': 'y', 'port': None, 'username': 'x'},\n                    {'host': '1.1.1.1', 'password': None, 'port': 888, 'username': None},\n                ],\n            },\n        ),\n        (\n            'http://foo.co.uk,bar.spam.things.com',\n            {\n                'str()': 'http://foo.co.uk,bar.spam.things.com/',\n                'hosts()': [\n                    {'host': 'foo.co.uk', 'password': None, 'port': 80, 'username': None},\n                    {'host': 'bar.spam.things.com', 'password': None, 'port': 80, 'username': None},\n                ],\n            },\n        ),\n        ('ht\ud83d\udca3tp://example.com', Err('relative URL without a base')),\n        # punycode \u00df\n        (\n            'http://\u00a3\u00a3\u00a3.com',\n            {\n                'str()': 'http://xn--9aaa.com/',\n                'hosts()': [{'host': 'xn--9aaa.com', 'password': None, 'port': 80, 'username': None}],\n                'unicode_string()': 'http://\u00a3\u00a3\u00a3.com/',\n            },\n        ),\n        (\n            'http://\u00a3\u00a3\u00a3.co.uk,m\u00fcnchen.com/foo?bar=baz#qux',\n            {\n                'str()': 'http://xn--9aaa.co.uk,xn--mnchen-3ya.com/foo?bar=baz#qux',\n                'hosts()': [\n                    {'host': 'xn--9aaa.co.uk', 'password': None, 'port': 80, 'username': None},\n                    {'host': 'xn--mnchen-3ya.com', 'password': None, 'port': 80, 'username': None},\n                ],\n                'unicode_string()': 'http://\u00a3\u00a3\u00a3.co.uk,m\u00fcnchen.com/foo?bar=baz#qux',\n            },\n        ),\n        (\n            'postgres://\u00a3\u00a3\u00a3.co.uk,m\u00fcnchen.com/foo?bar=baz#qux',\n            {\n                'str()': 'postgres://%C2%A3%C2%A3%C2%A3.co.uk,m%C3%BCnchen.com/foo?bar=baz#qux',\n                'hosts()': [\n                    {'host': '%C2%A3%C2%A3%C2%A3.co.uk', 'password': None, 'port': None, 'username': None},\n                    {'host': 'm%C3%BCnchen.com', 'password': None, 'port': None, 'username': None},\n                ],\n                'unicode_string()': 'postgres://%C2%A3%C2%A3%C2%A3.co.uk,m%C3%BCnchen.com/foo?bar=baz#qux',\n            },\n        ),\n    ],\n)\ndef test_multi_url_cases(multi_host_url_validator, url, expected):\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError) as exc_info:\n            multi_host_url_validator.validate_python(url)\n        assert exc_info.value.error_count() == 1\n        error = exc_info.value.errors(include_url=False)[0]\n        assert error['type'] == 'url_parsing'\n        assert error['ctx']['error'] == expected.message\n    else:\n        output_url = multi_host_url_validator.validate_python(url)\n        assert isinstance(output_url, MultiHostUrl)\n        if isinstance(expected, str):\n            assert str(output_url) == expected\n        else:\n            assert isinstance(expected, dict)\n            output_parts = {}\n            for key in expected:\n                if key == 'str()':\n                    output_parts[key] = str(output_url)\n                elif key.endswith('()'):\n                    output_parts[key] = getattr(output_url, key[:-2])()\n                else:\n                    output_parts[key] = getattr(output_url, key)\n            # debug(output_parts)\n            assert output_parts == expected\n\n\n@pytest.fixture(scope='module', name='strict_multi_host_url_validator')\ndef strict_multi_host_url_validator_fixture():\n    return SchemaValidator(core_schema.multi_host_url_schema(strict=True))\n\n\n@pytest.mark.parametrize(\n    'url,expected',\n    [\n        ('http://example.com', 'http://example.com/'),\n        (\n            '  mongodb://foo,bar,spam/xxx  ',\n            Err('leading or trailing control or space character are ignored in URLs', 'url_syntax_violation'),\n        ),\n        (\n            ' \\n\\r\\t mongodb://foo,bar,spam/xxx',\n            Err('leading or trailing control or space character are ignored in URLs', 'url_syntax_violation'),\n        ),\n        # with bashslashes\n        ('file:\\\\\\\\foo,bar\\\\more', Err('backslash', 'url_syntax_violation')),\n        ('http:\\\\\\\\foo,bar\\\\more', Err('backslash', 'url_syntax_violation')),\n        ('mongo:\\\\\\\\foo,bar\\\\more', Err('non-URL code point', 'url_syntax_violation')),\n        ('foobar://foo[]bar:x@y@whatever,foo[]bar:x@y@whichever', Err('non-URL code point', 'url_syntax_violation')),\n        (\n            'foobar://foo%2Cbar:x@y@whatever,snap',\n            Err('unencoded @ sign in username or password', 'url_syntax_violation'),\n        ),\n        ('foobar://foo%2Cbar:x%40y@whatever,snap', 'foobar://foo%2Cbar:x%40y@whatever,snap'),\n    ],\n)\ndef test_multi_url_cases_strict(strict_multi_host_url_validator, url, expected):\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError) as exc_info:\n            strict_multi_host_url_validator.validate_python(url)\n        assert exc_info.value.error_count() == 1\n        error = exc_info.value.errors(include_url=False)[0]\n        assert error['type'] == expected.errors\n        assert error['ctx']['error'] == expected.message\n    else:\n        output_url = strict_multi_host_url_validator.validate_python(url)\n        assert isinstance(output_url, MultiHostUrl)\n        if isinstance(expected, str):\n            assert str(output_url) == expected\n        else:\n            assert isinstance(expected, dict)\n            output_parts = {}\n            for key in expected:\n                if key == 'str()':\n                    output_parts[key] = str(output_url)\n                elif key.endswith('()'):\n                    output_parts[key] = getattr(output_url, key[:-2])()\n                else:\n                    output_parts[key] = getattr(output_url, key)\n            assert output_parts == expected\n\n\ndef test_url_to_multi_url(url_validator, multi_host_url_validator):\n    url: Url = url_validator.validate_python('https://example.com')\n    assert isinstance(url, Url)\n    assert str(url) == 'https://example.com/'\n\n    url2 = multi_host_url_validator.validate_python(url)\n    assert isinstance(url2, MultiHostUrl)\n    assert str(url2) == 'https://example.com/'\n    assert url is not url2\n\n    url3 = multi_host_url_validator.validate_python(url2)\n    assert isinstance(url3, MultiHostUrl)\n    assert str(url3) == 'https://example.com/'\n    assert url2 is url3\n\n\ndef test_multi_wrong_type(multi_host_url_validator):\n    assert str(multi_host_url_validator.validate_python('http://example.com')) == 'http://example.com/'\n    with pytest.raises(ValidationError, match=r'URL input should be a string or URL \\[type=url_type,'):\n        multi_host_url_validator.validate_python(42)\n\n\ndef test_multi_allowed_schemas():\n    v = SchemaValidator(core_schema.multi_host_url_schema(allowed_schemes=['http', 'foo']))\n    assert str(v.validate_python('http://example.com')) == 'http://example.com/'\n    assert str(v.validate_python('foo://example.com')) == 'foo://example.com'\n    with pytest.raises(ValidationError, match=r\"URL scheme should be 'http' or 'foo' \\[type=url_scheme,\"):\n        v.validate_python('https://example.com')\n\n\ndef test_multi_max_length(url_validator):\n    v = SchemaValidator(core_schema.multi_host_url_schema(max_length=25))\n    assert str(v.validate_python('http://example.com')) == 'http://example.com/'\n    with pytest.raises(ValidationError, match=r'URL should have at most 25 characters \\[type=url_too_long,'):\n        v.validate_python('https://example.com/this-is-too-long')\n\n    url = v.validate_python('http://example.com')\n    assert str(v.validate_python(url)) == 'http://example.com/'\n\n    simple_url = url_validator.validate_python('http://example.com')\n    assert isinstance(simple_url, Url)\n    assert str(v.validate_python(simple_url)) == 'http://example.com/'\n\n    long_simple_url = url_validator.validate_python('http://example.com/this-is-too-long')\n    with pytest.raises(ValidationError, match=r'URL should have at most 25 characters \\[type=url_too_long,'):\n        v.validate_python(long_simple_url)\n\n\ndef test_zero_schemas():\n    with pytest.raises(SchemaError, match='`allowed_schemes` should have length > 0'):\n        SchemaValidator(core_schema.multi_host_url_schema(allowed_schemes=[]))\n\n\n@pytest.mark.parametrize(\n    'url,expected',\n    [\n        # urlparse doesn't follow RFC 3986 Section 3.2\n        (\n            'http://google.com#@evil.com/',\n            dict(\n                scheme='http',\n                host='google.com',\n                # path='', CHANGED\n                path='/',\n                fragment='@evil.com/',\n            ),\n        ),\n        # CVE-2016-5699\n        (\n            'http://127.0.0.1%0d%0aConnection%3a%20keep-alive',\n            # dict(scheme='http', host='127.0.0.1%0d%0aconnection%3a%20keep-alive'), CHANGED\n            Err('Input should be a valid URL, invalid domain character [type=url_parsing,'),\n        ),\n        # NodeJS unicode -> double dot\n        ('http://google.com/\\uff2e\\uff2e/abc', dict(scheme='http', host='google.com', path='/%EF%BC%AE%EF%BC%AE/abc')),\n        # Scheme without ://\n        (\n            \"javascript:a='@google.com:12345/';alert(0)\",\n            dict(scheme='javascript', path=\"a='@google.com:12345/';alert(0)\"),\n        ),\n        (\n            '//google.com/a/b/c',\n            # dict(host='google.com', path='/a/b/c'),\n            Err('Input should be a valid URL, relative URL without a base [type=url_parsing,'),\n        ),\n        # International URLs\n        (\n            'http://\u30d2:\u30ad@\u30d2.abc.\u30cb/\u30d2?\u30ad#\u30ef',\n            dict(\n                scheme='http',\n                host='xn--pdk.abc.xn--idk',\n                auth='%E3%83%92:%E3%82%AD',\n                path='/%E3%83%92',\n                query='%E3%82%AD',\n                fragment='%E3%83%AF',\n            ),\n        ),\n        # Injected headers (CVE-2016-5699, CVE-2019-9740, CVE-2019-9947)\n        (\n            '10.251.0.83:7777?a=1 HTTP/1.1\\r\\nX-injected: header',\n            # dict( CHANGED\n            #     host='10.251.0.83',\n            #     port=7777,\n            #     path='',\n            #     query='a=1%20HTTP/1.1%0D%0AX-injected:%20header',\n            # ),\n            Err('Input should be a valid URL, relative URL without a base [type=url_parsing,'),\n        ),\n        # ADDED, similar to the above with scheme added\n        (\n            'http://10.251.0.83:7777?a=1 HTTP/1.1\\r\\nX-injected: header',\n            dict(\n                host='10.251.0.83',\n                port=7777,\n                path='/',\n                # query='a=1%20HTTP/1.1%0D%0AX-injected:%20header', CHANGED\n                query='a=1%20HTTP/1.1X-injected:%20header',\n            ),\n        ),\n        (\n            'http://127.0.0.1:6379?\\r\\nSET test failure12\\r\\n:8080/test/?test=a',\n            dict(\n                scheme='http',\n                host='127.0.0.1',\n                port=6379,\n                # path='',\n                path='/',\n                # query='%0D%0ASET%20test%20failure12%0D%0A:8080/test/?test=a', CHANGED\n                query='SET%20test%20failure12:8080/test/?test=a',\n            ),\n        ),\n        # See https://bugs.xdavidhu.me/google/2020/03/08/the-unexpected-google-wide-domain-check-bypass/\n        (\n            'https://user:pass@xdavidhu.me\\\\test.corp.google.com:8080/path/to/something?param=value#hash',\n            dict(\n                scheme='https',\n                auth='user:pass',\n                host='xdavidhu.me',\n                # path='/%5Ctest.corp.google.com:8080/path/to/something', CHANGED\n                path='/test.corp.google.com:8080/path/to/something',\n                query='param=value',\n                fragment='hash',\n            ),\n        ),\n        # # Tons of '@' causing backtracking\n        (\n            'https://' + ('@' * 10000) + '[',\n            # False, CHANGED\n            Err('Input should be a valid URL, invalid IPv6 address [type=url_parsing,'),\n        ),\n        (\n            'https://user:' + ('@' * 10000) + 'example.com',\n            dict(scheme='https', auth='user:' + ('%40' * 9999), host='example.com'),\n        ),\n    ],\n)\ndef test_url_vulnerabilities(url_validator, url, expected):\n    \"\"\"\n    Test cases from\n    https://github.com/urllib3/urllib3/blob/7ef7444fd0fc22a825be6624af85343cefa36fef/test/test_util.py#L422\n    \"\"\"\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            url_validator.validate_python(url)\n    else:\n        output_url = url_validator.validate_python(url)\n        assert isinstance(output_url, Url)\n        output_parts = {}\n        for key in expected:\n            # one tweak required to match urllib3 logic\n            if key == 'auth':\n                output_parts[key] = f'{output_url.username}:{output_url.password}'\n            else:\n                output_parts[key] = getattr(output_url, key)\n        assert output_parts == expected\n\n\ndef test_multi_host_url_comparison() -> None:\n    assert MultiHostUrl('http://example.com,www.example.com') == MultiHostUrl('http://example.com,www.example.com')\n    assert MultiHostUrl('http://example.com,www.example.com') == MultiHostUrl('http://example.com,www.example.com/')\n    assert MultiHostUrl('http://example.com,www.example.com') != MultiHostUrl('http://example.com,www.example.com/123')\n    assert MultiHostUrl('http://example.com,www.example.com/123') > MultiHostUrl('http://example.com,www.example.com')\n    assert MultiHostUrl('http://example.com,www.example.com/123') >= MultiHostUrl('http://example.com,www.example.com')\n    assert MultiHostUrl('http://example.com,www.example.com') >= MultiHostUrl('http://example.com,www.example.com')\n    assert MultiHostUrl('http://example.com,www.example.com') < MultiHostUrl('http://example.com,www.example.com/123')\n    assert MultiHostUrl('http://example.com,www.example.com') <= MultiHostUrl('http://example.com,www.example.com/123')\n    assert MultiHostUrl('http://example.com,www.example.com') <= MultiHostUrl('http://example.com')\n\n\ndef test_multi_host_url_bool() -> None:\n    assert bool(MultiHostUrl('http://example.com,www.example.com')) is True\n\n\ndef test_multi_host_url_hash() -> None:\n    data: Dict[MultiHostUrl, int] = {}\n\n    data[MultiHostUrl('http://example.com,www.example.com')] = 1\n    assert data == {MultiHostUrl('http://example.com,www.example.com/'): 1}\n\n    data[MultiHostUrl('http://example.com,www.example.com/123')] = 2\n    assert data == {\n        MultiHostUrl('http://example.com,www.example.com/'): 1,\n        MultiHostUrl('http://example.com,www.example.com/123'): 2,\n    }\n\n    data[MultiHostUrl('http://example.com,www.example.com')] = 3\n    assert data == {\n        MultiHostUrl('http://example.com,www.example.com/'): 3,\n        MultiHostUrl('http://example.com,www.example.com/123'): 2,\n    }\n\n\ndef test_multi_host_url_deepcopy() -> None:\n    assert deepcopy(MultiHostUrl('http://example.com')) == MultiHostUrl('http://example.com/')\n\n\ndef test_url_comparison() -> None:\n    assert Url('http://example.com') == Url('http://example.com')\n    assert Url('http://example.com') == Url('http://example.com/')\n    assert Url('http://example.com') != Url('http://example.com/123')\n    assert Url('http://example.com/123') > Url('http://example.com')\n    assert Url('http://example.com/123') >= Url('http://example.com')\n    assert Url('http://example.com') >= Url('http://example.com')\n    assert Url('http://example.com') < Url('http://example.com/123')\n    assert Url('http://example.com') <= Url('http://example.com/123')\n    assert Url('http://example.com') <= Url('http://example.com')\n\n\ndef test_url_bool() -> None:\n    assert bool(Url('http://example.com')) is True\n\n\ndef test_url_hash() -> None:\n    data: Dict[Url, int] = {}\n\n    data[Url('http://example.com')] = 1\n    assert data == {Url('http://example.com/'): 1}\n\n    data[Url('http://example.com/123')] = 2\n    assert data == {Url('http://example.com/'): 1, Url('http://example.com/123'): 2}\n\n    data[Url('http://example.com')] = 3\n    assert data == {Url('http://example.com/'): 3, Url('http://example.com/123'): 2}\n\n\ndef test_url_deepcopy() -> None:\n    assert deepcopy(Url('http://example.com')) == Url('http://example.com/')\n\n\ndef test_multi_url_build() -> None:\n    url = MultiHostUrl.build(\n        scheme='postgresql',\n        username='testuser',\n        password='testpassword',\n        host='127.0.0.1',\n        port=5432,\n        path='database',\n        query='sslmode=require',\n        fragment='test',\n    )\n    assert url == MultiHostUrl('postgresql://testuser:testpassword@127.0.0.1:5432/database?sslmode=require#test')\n    assert str(url) == 'postgresql://testuser:testpassword@127.0.0.1:5432/database?sslmode=require#test'\n\n\n@pytest.mark.parametrize('field', ['host', 'password', 'username', 'port'])\ndef test_multi_url_build_hosts_set_with_single_value(field) -> None:\n    \"\"\"Hosts can't be provided with any single url values.\"\"\"\n    hosts = [\n        {'host': '127.0.0.1', 'password': 'testpassword', 'username': 'testuser', 'port': 5432},\n        {'host': '127.0.0.1', 'password': 'testpassword', 'username': 'testuser', 'port': 5432},\n    ]\n    kwargs = dict(scheme='postgresql', hosts=hosts, path='database', query='sslmode=require', fragment='test')\n    if field == 'port':\n        kwargs[field] = 5432\n    else:\n        kwargs[field] = 'test'\n    with pytest.raises(ValueError):\n        MultiHostUrl.build(**kwargs)\n\n\ndef test_multi_url_build_hosts_empty_host() -> None:\n    \"\"\"Hosts can't be provided with any single url values.\"\"\"\n    hosts = [{}]\n    with pytest.raises(ValueError):\n        MultiHostUrl.build(scheme='postgresql', hosts=hosts, path='database', query='sslmode=require', fragment='test')\n\n\ndef test_multi_url_build_hosts() -> None:\n    \"\"\"Hosts can't be provided with any single url values.\"\"\"\n    hosts = [\n        {'host': '127.0.0.1', 'password': 'testpassword', 'username': 'testuser', 'port': 5431},\n        {'host': '127.0.0.1', 'password': 'testpassword', 'username': 'testuser', 'port': 5433},\n    ]\n    kwargs = dict(scheme='postgresql', hosts=hosts, path='database', query='sslmode=require', fragment='test')\n    url = MultiHostUrl.build(**kwargs)\n    assert url == MultiHostUrl(\n        'postgresql://testuser:testpassword@127.0.0.1:5431,testuser:testpassword@127.0.0.1:5433/database?sslmode=require#test'\n    )\n    assert (\n        str(url)\n        == 'postgresql://testuser:testpassword@127.0.0.1:5431,testuser:testpassword@127.0.0.1:5433/database?sslmode=require#test'\n    )\n\n\ndef test_multi_url_build_neither_host_and_hosts_set() -> None:\n    with pytest.raises(ValueError):\n        MultiHostUrl.build(\n            scheme='postgresql',\n            username='testuser',\n            password='testpassword',\n            port=5432,\n            path='database',\n            query='sslmode=require',\n            fragment='test',\n        )\n\n\ndef test_url_build() -> None:\n    url = Url.build(\n        scheme='postgresql',\n        username='testuser',\n        password='testpassword',\n        host='127.0.0.1',\n        port=5432,\n        path='database',\n        query='sslmode=require',\n        fragment='test',\n    )\n    assert url == Url('postgresql://testuser:testpassword@127.0.0.1:5432/database?sslmode=require#test')\n    assert str(url) == 'postgresql://testuser:testpassword@127.0.0.1:5432/database?sslmode=require#test'\n", "tests/validators/test_lax_or_strict.py": "import pytest\n\nfrom pydantic_core import SchemaValidator, ValidationError, core_schema\n\n\ndef test_lax_or_strict():\n    v = SchemaValidator(core_schema.lax_or_strict_schema(core_schema.str_schema(), core_schema.int_schema()))\n    # validator is default - lax so with no runtime arg, we're in lax mode, and we use the string validator\n    assert v.validate_python('aaa') == 'aaa'\n    # the strict validator is itself lax\n    assert v.validate_python(b'aaa') == 'aaa'\n    # in strict mode\n    assert v.validate_python(123, strict=True) == 123\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python('123', strict=True)\n\n    # location is not changed\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'int_type', 'loc': (), 'msg': 'Input should be a valid integer', 'input': '123'}\n    ]\n\n\ndef test_lax_or_strict_default_strict():\n    v = SchemaValidator(\n        core_schema.lax_or_strict_schema(core_schema.str_schema(), core_schema.int_schema(), strict=True)\n    )\n    assert v.validate_python('aaa', strict=False) == 'aaa'\n    assert v.validate_python(b'aaa', strict=False) == 'aaa'\n    # in strict mode\n    assert v.validate_python(123) == 123\n    assert v.validate_python(123, strict=True) == 123\n    # the int validator isn't strict since it wasn't configured that way and strictness wasn't overridden at runtime\n    assert v.validate_python('123') == 123\n\n    # but it is if we set `strict` to True\n    with pytest.raises(ValidationError, match='Input should be a valid integer'):\n        v.validate_python('123', strict=True)\n", "tests/validators/test_literal.py": "import re\nfrom enum import Enum\nfrom typing import Any, Callable, List\n\nimport pytest\n\nfrom pydantic_core import SchemaError, SchemaValidator, ValidationError, core_schema\n\nfrom ..conftest import Err, PyAndJson, plain_repr\n\n\n@pytest.mark.parametrize(\n    'kwarg_expected,input_value,expected',\n    [\n        ([1], 1, 1),\n        pytest.param(\n            [1],\n            2,\n            Err(\n                'Input should be 1 [type=literal_error, input_value=2, input_type=int]',\n                [\n                    {\n                        'type': 'literal_error',\n                        'loc': (),\n                        'msg': 'Input should be 1',\n                        'input': 2,\n                        'ctx': {'expected': '1'},\n                    }\n                ],\n            ),\n            id='wrong-single-int',\n        ),\n        (['foo'], 'foo', 'foo'),\n        pytest.param(\n            ['foo'],\n            'bar',\n            Err(\n                \"Input should be 'foo' [type=literal_error, input_value='bar', input_type=str]\",\n                [\n                    {\n                        'type': 'literal_error',\n                        'loc': (),\n                        'msg': \"Input should be 'foo'\",\n                        'input': 'bar',\n                        'ctx': {'expected': \"'foo'\"},\n                    }\n                ],\n            ),\n            id='wrong-single-str',\n        ),\n        ([1, 2], 1, 1),\n        ([1, 2], 2, 2),\n        pytest.param(\n            [1, 2],\n            3,\n            Err('Input should be 1 or 2 [type=literal_error, input_value=3, input_type=int]'),\n            id='wrong-multiple-int',\n        ),\n        ([1, 2, 3, 4], 4, 4),\n        pytest.param(\n            [1, 2, 3, 4],\n            5,\n            Err(\n                'Input should be 1, 2, 3 or 4 [type=literal_error, input_value=5, input_type=int]',\n                [\n                    {\n                        'type': 'literal_error',\n                        'loc': (),\n                        'msg': 'Input should be 1, 2, 3 or 4',\n                        'input': 5,\n                        'ctx': {'expected': '1, 2, 3 or 4'},\n                    }\n                ],\n            ),\n            id='wrong-multiple-int',\n        ),\n        (['a', 'b'], 'a', 'a'),\n        pytest.param(\n            ['a', 'b'],\n            'c',\n            Err(\"Input should be 'a' or 'b' [type=literal_error, input_value='c', input_type=str]\"),\n            id='wrong-multiple-str',\n        ),\n        ([1, '1'], 1, 1),\n        ([1, '1'], '1', '1'),\n        pytest.param(\n            [1, '1'],\n            '2',\n            Err(\n                \"Input should be 1 or '1' [type=literal_error, input_value='2', input_type=str]\",\n                [\n                    {\n                        'type': 'literal_error',\n                        'loc': (),\n                        'msg': \"Input should be 1 or '1'\",\n                        'input': '2',\n                        'ctx': {'expected': \"1 or '1'\"},\n                    }\n                ],\n            ),\n            id='wrong-str-int',\n        ),\n    ],\n)\ndef test_literal_py_and_json(py_and_json: PyAndJson, kwarg_expected, input_value, expected):\n    v = py_and_json({'type': 'literal', 'expected': kwarg_expected})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)) as exc_info:\n            v.validate_test(input_value)\n        if expected.errors is not None:\n            # debug(exc_info.value.errors(include_url=False))\n            assert exc_info.value.errors(include_url=False) == expected.errors\n    else:\n        assert v.validate_test(input_value) == expected\n\n\n@pytest.mark.parametrize(\n    'kwarg_expected,input_value,expected',\n    [\n        ([1, b'whatever'], b'whatever', b'whatever'),\n        ([(1, 2), (3, 4)], (1, 2), (1, 2)),\n        ([(1, 2), (3, 4)], (3, 4), (3, 4)),\n        pytest.param(\n            [1, b'whatever'],\n            3,\n            Err(\"Input should be 1 or b'whatever' [type=literal_error, input_value=3, input_type=int]\"),\n            id='wrong-general',\n        ),\n        ([b'bite'], b'bite', b'bite'),\n        pytest.param(\n            [b'bite'],\n            'spoon',\n            Err(\n                \"Input should be b'bite' [type=literal_error, input_value='spoon', input_type=str]\",\n                [\n                    {\n                        'type': 'literal_error',\n                        'loc': (),\n                        'msg': \"Input should be 1 or '1'\",\n                        'input': '2',\n                        'ctx': {'expected': \"1 or '1'\"},\n                    }\n                ],\n            ),\n            id='single-byte',\n        ),\n    ],\n)\ndef test_literal_not_json(kwarg_expected, input_value, expected):\n    v = SchemaValidator({'type': 'literal', 'expected': kwarg_expected})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)) as exc_info:\n            v.validate_python(input_value)\n            if expected.errors is not None:\n                # debug(exc_info.value.errors(include_url=False))\n                assert exc_info.value.errors(include_url=False) == expected.errors\n    else:\n        assert v.validate_python(input_value) == expected\n\n\ndef test_build_error():\n    with pytest.raises(SchemaError, match='SchemaError: `expected` should have length > 0'):\n        SchemaValidator({'type': 'literal', 'expected': []})\n\n\ndef test_literal_none():\n    v = SchemaValidator(core_schema.literal_schema([None]))\n    assert v.isinstance_python(None) is True\n    assert v.isinstance_python(0) is False\n    expected_repr_start = 'SchemaValidator(title=\"literal[None]\"'\n    assert plain_repr(v)[: len(expected_repr_start)] == expected_repr_start\n\n\ndef test_union():\n    v = SchemaValidator(core_schema.union_schema([core_schema.literal_schema(['a', 'b']), core_schema.int_schema()]))\n    assert v.validate_python('a') == 'a'\n    assert v.validate_python(4) == 4\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python('c')\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'literal_error',\n            'loc': (\"literal['a','b']\",),\n            'msg': \"Input should be 'a' or 'b'\",\n            'input': 'c',\n            'ctx': {'expected': \"'a' or 'b'\"},\n        },\n        {\n            'type': 'int_parsing',\n            'loc': ('int',),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'c',\n        },\n    ]\n\n\ndef test_enum_value():\n    class FooEnum(Enum):\n        foo = 'foo_value'\n        bar = 'bar_value'\n\n    v = SchemaValidator(core_schema.literal_schema([FooEnum.foo]))\n    assert v.validate_python(FooEnum.foo) == FooEnum.foo\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python('foo_value')\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'literal_error',\n            'loc': (),\n            'msg': \"Input should be <FooEnum.foo: 'foo_value'>\",\n            'input': 'foo_value',\n            'ctx': {'expected': \"<FooEnum.foo: 'foo_value'>\"},\n        }\n    ]\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python('unknown')\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'literal_error',\n            'loc': (),\n            'msg': \"Input should be <FooEnum.foo: 'foo_value'>\",\n            'input': 'unknown',\n            'ctx': {'expected': \"<FooEnum.foo: 'foo_value'>\"},\n        }\n    ]\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_json('\"foo_value\"')\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'literal_error',\n            'loc': (),\n            'msg': \"Input should be <FooEnum.foo: 'foo_value'>\",\n            'input': 'foo_value',\n            'ctx': {'expected': \"<FooEnum.foo: 'foo_value'>\"},\n        }\n    ]\n\n\ndef test_str_enum_values():\n    class Foo(str, Enum):\n        foo = 'foo_value'\n        bar = 'bar_value'\n\n    v = SchemaValidator(core_schema.literal_schema([Foo.foo]))\n\n    assert v.validate_python(Foo.foo) == Foo.foo\n    assert v.validate_python('foo_value') == Foo.foo\n    assert v.validate_json('\"foo_value\"') == Foo.foo\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python('unknown')\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'literal_error',\n            'loc': (),\n            'msg': \"Input should be <Foo.foo: 'foo_value'>\",\n            'input': 'unknown',\n            'ctx': {'expected': \"<Foo.foo: 'foo_value'>\"},\n        }\n    ]\n\n\ndef test_int_enum_values():\n    class Foo(int, Enum):\n        foo = 2\n        bar = 3\n\n    v = SchemaValidator(core_schema.literal_schema([Foo.foo]))\n\n    assert v.validate_python(Foo.foo) == Foo.foo\n    assert v.validate_python(2) == Foo.foo\n    assert v.validate_json('2') == Foo.foo\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python(4)\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'literal_error',\n            'loc': (),\n            'msg': 'Input should be <Foo.foo: 2>',\n            'input': 4,\n            'ctx': {'expected': '<Foo.foo: 2>'},\n        }\n    ]\n\n\n@pytest.mark.parametrize(\n    'reverse, err',\n    [\n        (\n            lambda x: list(reversed(x)),\n            [\n                {\n                    'type': 'literal_error',\n                    'loc': (),\n                    'msg': 'Input should be <Foo.foo: 1> or 1',\n                    'input': 2,\n                    'ctx': {'expected': '<Foo.foo: 1> or 1'},\n                }\n            ],\n        ),\n        (\n            lambda x: x,\n            [\n                {\n                    'type': 'literal_error',\n                    'loc': (),\n                    'msg': 'Input should be 1 or <Foo.foo: 1>',\n                    'input': 2,\n                    'ctx': {'expected': '1 or <Foo.foo: 1>'},\n                }\n            ],\n        ),\n    ],\n)\ndef test_mix_int_enum_with_int(reverse: Callable[[List[Any]], List[Any]], err: Any):\n    class Foo(int, Enum):\n        foo = 1\n\n    v = SchemaValidator(core_schema.literal_schema(reverse([1, Foo.foo])))\n\n    assert v.validate_python(Foo.foo) is Foo.foo\n    val = v.validate_python(1)\n    assert val == 1 and val is not Foo.foo\n    val = v.validate_json('1')\n    assert val == 1 and val is not Foo.foo\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python(2)\n    assert exc_info.value.errors(include_url=False) == err\n\n\n@pytest.mark.parametrize(\n    'reverse, err',\n    [\n        (\n            lambda x: list(reversed(x)),\n            [\n                {\n                    'type': 'literal_error',\n                    'loc': (),\n                    'msg': \"Input should be <Foo.foo: 'foo_val'> or 'foo_val'\",\n                    'input': 'bar_val',\n                    'ctx': {'expected': \"<Foo.foo: 'foo_val'> or 'foo_val'\"},\n                }\n            ],\n        ),\n        (\n            lambda x: x,\n            [\n                {\n                    'type': 'literal_error',\n                    'loc': (),\n                    'msg': \"Input should be 'foo_val' or <Foo.foo: 'foo_val'>\",\n                    'input': 'bar_val',\n                    'ctx': {'expected': \"'foo_val' or <Foo.foo: 'foo_val'>\"},\n                }\n            ],\n        ),\n    ],\n)\ndef test_mix_str_enum_with_str(reverse: Callable[[List[Any]], List[Any]], err: Any):\n    class Foo(str, Enum):\n        foo = 'foo_val'\n\n    v = SchemaValidator(core_schema.literal_schema(reverse(['foo_val', Foo.foo])))\n\n    assert v.validate_python(Foo.foo) is Foo.foo\n    val = v.validate_python('foo_val')\n    assert val == 'foo_val' and val is not Foo.foo\n    val = v.validate_json('\"foo_val\"')\n    assert val == 'foo_val' and val is not Foo.foo\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python('bar_val')\n    assert exc_info.value.errors(include_url=False) == err\n\n\ndef test_big_int():\n    big_int = 2**64 + 1\n    massive_int = 2**128 + 1\n    v = SchemaValidator(core_schema.literal_schema([big_int, massive_int]))\n    assert v.validate_python(big_int) == big_int\n    assert v.validate_python(massive_int) == massive_int\n    m = r'Input should be 18446744073709551617 or 340282366920938463463374607431768211457 \\[type=literal_error'\n    with pytest.raises(ValidationError, match=m):\n        v.validate_python(37)\n", "tests/validators/test_date.py": "from __future__ import annotations\n\nimport re\nfrom datetime import date, datetime, time, timedelta, timezone\nfrom decimal import Decimal\nfrom typing import Any\n\nimport pytest\n\nfrom pydantic_core import SchemaError, SchemaValidator, ValidationError, core_schema, validate_core_schema\n\nfrom ..conftest import Err, PyAndJson\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        pytest.param(date(2022, 6, 8), date(2022, 6, 8), id='date'),\n        pytest.param('2022-06-08', date(2022, 6, 8), id='str'),\n        pytest.param(b'2022-06-08', date(2022, 6, 8), id='bytes'),\n        pytest.param((1,), Err('Input should be a valid date [type=date_type'), id='tuple'),\n        pytest.param(1654646400, date(2022, 6, 8), id='int'),\n        pytest.param('1654646400', date(2022, 6, 8), id='int-as-str'),\n        pytest.param(1654646400.00, date(2022, 6, 8), id='float'),\n        pytest.param('1654646400.00', date(2022, 6, 8), id='float-as-str'),\n        pytest.param(Decimal('1654646400'), date(2022, 6, 8), id='decimal'),\n        # (253_402_300_800_000, Err('format YYYY-MM-DD, dates after 9999 are not supported as unix timestamps')),\n        pytest.param(253_402_300_800_000, Err('Input should be a valid date'), id='int-too-high'),\n        # (-20_000_000_000, Err('format YYYY-MM-DD, dates before 1600 are not supported as unix timestamps')),\n        pytest.param(-20_000_000_000, Err('Input should be a valid date'), id='int-too-low'),\n        pytest.param(datetime(2022, 6, 8), date(2022, 6, 8), id='datetime-exact'),\n        pytest.param(\n            datetime(2022, 6, 8, 12),\n            Err(\n                'Datetimes provided to dates should have zero time '\n                '- e.g. be exact dates [type=date_from_datetime_inexact'\n            ),\n            id='datetime-inexact',\n        ),\n        pytest.param(1654646400 + 4, Err('type=date_from_datetime_inexact'), id='int-inexact'),\n        pytest.param(1654646400.1, Err('type=date_from_datetime_inexact'), id='float-inexact'),\n        pytest.param('1654646404', Err('type=date_from_datetime_inexact'), id='int-str-inexact'),\n        pytest.param('1654646400.1', Err('type=date_from_datetime_inexact'), id='float-str-inexact'),\n        pytest.param(True, Err('Input should be a valid date'), id='bool'),\n        pytest.param(time(1, 2, 3), Err('Input should be a valid date [type=date_type'), id='time'),\n        pytest.param(\n            float('nan'),\n            Err('Input should be a valid date or datetime, NaN values not permitted [type=date_from_datetime_parsing,'),\n            id='nan',\n        ),\n        pytest.param(\n            float('inf'),\n            Err(\n                'Input should be a valid date or datetime, dates after 9999 are not supported as unix timestamps '\n                '[type=date_from_datetime_parsing,'\n            ),\n            id='inf',\n        ),\n        pytest.param(\n            float('-inf'),\n            Err(\n                'Input should be a valid date or datetime, dates before 1600 are not supported as unix timestamps '\n                '[type=date_from_datetime_parsing,'\n            ),\n            id='-inf',\n        ),\n        pytest.param('-', Err('Input should be a valid date or datetime, input is too short'), id='minus'),\n        pytest.param('+', Err('Input should be a valid date or datetime, input is too short'), id='pus'),\n    ],\n)\ndef test_date(input_value, expected):\n    v = SchemaValidator({'type': 'date'})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            result = v.validate_python(input_value)\n            print(f'input_value={input_value!r} result={result}')\n        assert v.isinstance_python(input_value) is False\n    else:\n        output = v.validate_python(input_value)\n        assert output == expected\n        assert v.isinstance_python(input_value) is True\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ('2022-06-08', date(2022, 6, 8)),\n        ('1453-01-28', date(1453, 1, 28)),\n        (1654646400, date(2022, 6, 8)),\n        (1654646400.0, date(2022, 6, 8)),\n        (\n            1654646401,\n            Err(\n                'Datetimes provided to dates should have zero time '\n                '- e.g. be exact dates [type=date_from_datetime_inexact'\n            ),\n        ),\n        ('wrong', Err('Input should be a valid date or datetime, input is too short [type=date_from_datetime_parsing')),\n        ('2000-02-29', date(2000, 2, 29)),\n        (\n            '2001-02-29',\n            Err(\n                'Input should be a valid date or datetime, '\n                'day value is outside expected range [type=date_from_datetime_parsing'\n            ),\n        ),\n        ([1], Err('Input should be a valid date [type=date_type')),\n    ],\n)\ndef test_date_json(py_and_json: PyAndJson, input_value, expected):\n    v = py_and_json({'type': 'date'})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_test(input_value)\n        assert v.isinstance_test(input_value) is False\n    else:\n        output = v.validate_test(input_value)\n        assert output == expected\n        assert v.isinstance_test(input_value) is True\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        (date(2022, 6, 8), date(2022, 6, 8)),\n        ('2022-06-08', Err('Input should be a valid date [type=date_type')),\n        (b'2022-06-08', Err('Input should be a valid date [type=date_type')),\n        (1654646400, Err('Input should be a valid date [type=date_type')),\n        (True, Err('Input should be a valid date [type=date_type')),\n        (datetime(2022, 6, 8), Err('Input should be a valid date [type=date_type')),\n    ],\n    ids=repr,\n)\ndef test_date_strict(input_value, expected, strict_mode_type):\n    v = SchemaValidator({'type': 'date', 'strict': strict_mode_type.schema})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_python(input_value, **strict_mode_type.validator_args)\n    else:\n        output = v.validate_python(input_value, **strict_mode_type.validator_args)\n        assert output == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ('\"2022-06-08\"', date(2022, 6, 8)),\n        (\n            '\"foobar\"',\n            Err('Input should be a valid date in the format YYYY-MM-DD, input is too short [type=date_parsing,'),\n        ),\n        ('1654646400', Err('Input should be a valid date [type=date_type')),\n    ],\n)\ndef test_date_strict_json(input_value, expected, strict_mode_type):\n    v = SchemaValidator({'type': 'date', 'strict': strict_mode_type.schema})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_json(input_value, **strict_mode_type.validator_args)\n    else:\n        output = v.validate_json(input_value, **strict_mode_type.validator_args)\n        assert output == expected\n\n\ndef test_date_strict_json_ctx():\n    v = SchemaValidator({'type': 'date', 'strict': True})\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_json('\"foobar\"')\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'date_parsing',\n            'loc': (),\n            'msg': 'Input should be a valid date in the format YYYY-MM-DD, input is too short',\n            'input': 'foobar',\n            'ctx': {'error': 'input is too short'},\n        }\n    ]\n\n\n@pytest.mark.parametrize(\n    'kwargs,input_value,expected',\n    [\n        ({}, '2000-01-01', date(2000, 1, 1)),\n        ({'le': date(2000, 1, 1)}, '2000-01-01', date(2000, 1, 1)),\n        (\n            {'le': date(2000, 1, 1)},\n            '2000-01-02',\n            Err('Input should be less than or equal to 2000-01-01 [type=less_than_equal,'),\n        ),\n        ({'lt': date(2000, 1, 1)}, '1999-12-31', date(1999, 12, 31)),\n        ({'lt': date(2000, 1, 1)}, '2000-01-01', Err('Input should be less than 2000-01-01 [type=less_than,')),\n        ({'ge': date(2000, 1, 1)}, '2000-01-01', date(2000, 1, 1)),\n        (\n            {'ge': date(2000, 1, 1)},\n            '1999-12-31',\n            Err('Input should be greater than or equal to 2000-01-01 [type=greater_than_equal,'),\n        ),\n        ({'gt': date(2000, 1, 1)}, '2000-01-02', date(2000, 1, 2)),\n        ({'gt': date(2000, 1, 1)}, '2000-01-01', Err('Input should be greater than 2000-01-01 [type=greater_than,')),\n    ],\n)\ndef test_date_kwargs(kwargs: dict[str, Any], input_value: date, expected: Err | date):\n    v = SchemaValidator({'type': 'date', **kwargs})  # type: ignore\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_python(input_value)\n    else:\n        output = v.validate_python(input_value)\n        assert output == expected\n\n\ndef test_invalid_constraint():\n    with pytest.raises(SchemaError, match=r'date\\.gt\\n  Input should be a valid date or datetime'):\n        validate_core_schema({'type': 'date', 'gt': 'foobar'})\n\n\ndef test_dict_py():\n    v = SchemaValidator({'type': 'dict', 'keys_schema': {'type': 'date'}, 'values_schema': {'type': 'int'}})\n    assert v.validate_python({date(2000, 1, 1): 2, date(2000, 1, 2): 4}) == {date(2000, 1, 1): 2, date(2000, 1, 2): 4}\n\n\ndef test_dict(py_and_json: PyAndJson):\n    v = py_and_json({'type': 'dict', 'keys_schema': {'type': 'date'}, 'values_schema': {'type': 'int'}})\n    assert v.validate_test({'2000-01-01': 2, '2000-01-02': 4}) == {date(2000, 1, 1): 2, date(2000, 1, 2): 4}\n\n\ndef test_union():\n    v = SchemaValidator({'type': 'union', 'choices': [{'type': 'str'}, {'type': 'date'}]})\n    assert v.validate_python('2022-01-02') == '2022-01-02'\n    assert v.validate_python(date(2022, 1, 2)) == date(2022, 1, 2)\n\n    v = SchemaValidator({'type': 'union', 'choices': [{'type': 'date'}, {'type': 'str'}]})\n    assert v.validate_python('2022-01-02') == '2022-01-02'\n    assert v.validate_python(date(2022, 1, 2)) == date(2022, 1, 2)\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ('2022-06-08', date(2022, 6, 8)),\n        (1654646400, date(2022, 6, 8)),\n        ('2068-06-08', Err('Date should be in the past [type=date_past,')),\n        (3105734400, Err('Date should be in the past [type=date_past,')),\n    ],\n)\ndef test_date_past(py_and_json: PyAndJson, input_value, expected):\n    # now_utc_offset must be set for all these tests to allow mocking in test_datetime.py!\n    v = py_and_json(core_schema.date_schema(now_op='past', now_utc_offset=0))\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_test(input_value)\n        assert v.isinstance_test(input_value) is False\n    else:\n        output = v.validate_test(input_value)\n        assert output == expected\n        assert v.isinstance_test(input_value) is True\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ('2022-06-08', Err('Date should be in the future [type=date_future,')),\n        (1654646400, Err('Date should be in the future [type=date_future,')),\n        ('2068-06-08', date(2068, 6, 8)),\n        (3105734400, date(2068, 6, 1)),\n    ],\n)\ndef test_date_future(py_and_json: PyAndJson, input_value, expected):\n    v = py_and_json(core_schema.date_schema(now_op='future', now_utc_offset=0))\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_test(input_value)\n        assert v.isinstance_test(input_value) is False\n    else:\n        output = v.validate_test(input_value)\n        assert output == expected\n        assert v.isinstance_test(input_value) is True\n\n\ndef test_date_past_future_today():\n    v = SchemaValidator(core_schema.date_schema(now_op='past', now_utc_offset=0))\n    today = datetime.now(timezone.utc).date()\n    assert v.isinstance_python(today) is False\n    assert v.isinstance_python(today - timedelta(days=1)) is True\n    assert v.isinstance_python(today + timedelta(days=1)) is False\n\n    v = SchemaValidator(core_schema.date_schema(now_op='future', now_utc_offset=0))\n    assert v.isinstance_python(today) is False\n    assert v.isinstance_python(today - timedelta(days=1)) is False\n    assert v.isinstance_python(today + timedelta(days=1)) is True\n\n\ndef test_offset_too_large():\n    with pytest.raises(SchemaError, match=r'Input should be less than 86400 \\[type=less_than,'):\n        validate_core_schema(core_schema.date_schema(now_op='past', now_utc_offset=24 * 3600))\n", "tests/validators/__init__.py": "", "tests/validators/test_dict.py": "import re\nfrom collections import OrderedDict\nfrom collections.abc import Mapping\nfrom typing import Any, Dict\n\nimport pytest\nfrom dirty_equals import HasRepr, IsStr\n\nfrom pydantic_core import SchemaValidator, ValidationError\n\nfrom ..conftest import Err, PyAndJson\n\n\ndef test_dict(py_and_json: PyAndJson):\n    v = py_and_json({'type': 'dict', 'keys_schema': {'type': 'int'}, 'values_schema': {'type': 'int'}})\n    assert v.validate_test({'1': 2, '3': 4}) == {1: 2, 3: 4}\n    v = py_and_json({'type': 'dict', 'strict': True, 'keys_schema': {'type': 'int'}, 'values_schema': {'type': 'int'}})\n    assert v.validate_test({'1': 2, '3': 4}) == {1: 2, 3: 4}\n    assert v.validate_test({}) == {}\n    with pytest.raises(ValidationError, match=re.escape('[type=dict_type, input_value=[], input_type=list]')):\n        v.validate_test([])\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ({'1': b'1', '2': b'2'}, {'1': '1', '2': '2'}),\n        (OrderedDict(a=b'1', b='2'), {'a': '1', 'b': '2'}),\n        ({}, {}),\n        ('foobar', Err(\"Input should be a valid dictionary [type=dict_type, input_value='foobar', input_type=str]\")),\n        ([], Err('Input should be a valid dictionary [type=dict_type,')),\n        ([('x', 'y')], Err('Input should be a valid dictionary [type=dict_type,')),\n        ([('x', 'y'), ('z', 'z')], Err('Input should be a valid dictionary [type=dict_type,')),\n        ((), Err('Input should be a valid dictionary [type=dict_type,')),\n        ((('x', 'y'),), Err('Input should be a valid dictionary [type=dict_type,')),\n        ((type('Foobar', (), {'x': 1})()), Err('Input should be a valid dictionary [type=dict_type,')),\n    ],\n    ids=repr,\n)\ndef test_dict_cases(input_value, expected):\n    v = SchemaValidator({'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'str'}})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_python(input_value)\n    else:\n        assert v.validate_python(input_value) == expected\n\n\ndef test_dict_value_error(py_and_json: PyAndJson):\n    v = py_and_json({'type': 'dict', 'values_schema': {'type': 'int'}})\n    assert v.validate_test({'a': 2, 'b': '4'}) == {'a': 2, 'b': 4}\n    with pytest.raises(ValidationError, match='Input should be a valid integer') as exc_info:\n        v.validate_test({'a': 2, 'b': 'wrong'})\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'int_parsing',\n            'loc': ('b',),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'wrong',\n        }\n    ]\n\n\ndef test_dict_error_key_int():\n    v = SchemaValidator({'type': 'dict', 'values_schema': {'type': 'int'}})\n    with pytest.raises(ValidationError, match='Input should be a valid integer') as exc_info:\n        v.validate_python({1: 2, 3: 'wrong', -4: 'wrong2'})\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'int_parsing',\n            'loc': (3,),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'wrong',\n        },\n        {\n            'type': 'int_parsing',\n            'loc': (-4,),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'wrong2',\n        },\n    ]\n\n\ndef test_dict_error_key_other():\n    v = SchemaValidator({'type': 'dict', 'values_schema': {'type': 'int'}})\n    with pytest.raises(ValidationError, match='Input should be a valid integer') as exc_info:\n        v.validate_python({1: 2, (1, 2): 'wrong'})\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'int_parsing',\n            'loc': ('(1, 2)',),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'wrong',\n        }\n    ]\n\n\ndef test_dict_any_value():\n    v = SchemaValidator({'type': 'dict', 'keys_schema': {'type': 'str'}})\n    v = SchemaValidator({'type': 'dict', 'keys_schema': {'type': 'str'}})\n    assert v.validate_python({'1': 1, '2': 'a', '3': None}) == {'1': 1, '2': 'a', '3': None}\n\n\ndef test_mapping():\n    class MyMapping(Mapping):\n        def __init__(self, d):\n            self._d = d\n\n        def __getitem__(self, key):\n            return self._d[key]\n\n        def __iter__(self):\n            return iter(self._d)\n\n        def __len__(self):\n            return len(self._d)\n\n    v = SchemaValidator({'type': 'dict', 'keys_schema': {'type': 'int'}, 'values_schema': {'type': 'int'}})\n    assert v.validate_python(MyMapping({'1': 2, 3: '4'})) == {1: 2, 3: 4}\n    v = SchemaValidator(\n        {'type': 'dict', 'strict': True, 'keys_schema': {'type': 'int'}, 'values_schema': {'type': 'int'}}\n    )\n    with pytest.raises(ValidationError, match='Input should be a valid dictionary'):\n        v.validate_python(MyMapping({'1': 2, 3: '4'}))\n\n\ndef test_key_error():\n    v = SchemaValidator({'type': 'dict', 'keys_schema': {'type': 'int'}, 'values_schema': {'type': 'int'}})\n    assert v.validate_python({'1': True}) == {1: 1}\n    with pytest.raises(ValidationError, match=re.escape('x.[key]\\n  Input should be a valid integer')) as exc_info:\n        v.validate_python({'x': 1})\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'int_parsing',\n            'loc': ('x', '[key]'),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'x',\n        }\n    ]\n\n\ndef test_mapping_error():\n    class BadMapping(Mapping):\n        def __getitem__(self, key):\n            raise None\n\n        def __iter__(self):\n            raise RuntimeError('intentional error')\n\n        def __len__(self):\n            return 1\n\n    v = SchemaValidator({'type': 'dict', 'keys_schema': {'type': 'int'}, 'values_schema': {'type': 'int'}})\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python(BadMapping())\n\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'mapping_type',\n            'loc': (),\n            'msg': 'Input should be a valid mapping, error: RuntimeError: intentional error',\n            'input': HasRepr(IsStr(regex='.+BadMapping object at.+')),\n            'ctx': {'error': 'RuntimeError: intentional error'},\n        }\n    ]\n\n\n@pytest.mark.parametrize('mapping_items', [[(1,)], ['foobar'], [(1, 2, 3)], 'not list'])\ndef test_mapping_error_yield_1(mapping_items):\n    class BadMapping(Mapping):\n        def items(self):\n            return mapping_items\n\n        def __iter__(self):\n            pytest.fail('unexpected call to __iter__')\n\n        def __getitem__(self, key):\n            pytest.fail('unexpected call to __getitem__')\n\n        def __len__(self):\n            return 1\n\n    v = SchemaValidator({'type': 'dict', 'keys_schema': {'type': 'int'}, 'values_schema': {'type': 'int'}})\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python(BadMapping())\n\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'mapping_type',\n            'loc': (),\n            'msg': 'Input should be a valid mapping, error: Mapping items must be tuples of (key, value) pairs',\n            'input': HasRepr(IsStr(regex='.+BadMapping object at.+')),\n            'ctx': {'error': 'Mapping items must be tuples of (key, value) pairs'},\n        }\n    ]\n\n\n@pytest.mark.parametrize(\n    'kwargs,input_value,expected',\n    [\n        ({}, {'1': 1, '2': 2}, {'1': 1, '2': 2}),\n        (\n            {'min_length': 3},\n            {'1': 1, '2': 2, '3': 3.0, '4': [1, 2, 3, 4]},\n            {'1': 1, '2': 2, '3': 3.0, '4': [1, 2, 3, 4]},\n        ),\n        (\n            {'min_length': 3},\n            {1: '2', 3: '4'},\n            Err('Dictionary should have at least 3 items after validation, not 2 [type=too_short,'),\n        ),\n        ({'max_length': 4}, {'1': 1, '2': 2, '3': 3.0}, {'1': 1, '2': 2, '3': 3.0}),\n        (\n            {'max_length': 3},\n            {'1': 1, '2': 2, '3': 3.0, '4': [1, 2, 3, 4]},\n            Err('Dictionary should have at most 3 items after validation, not 4 [type=too_long,'),\n        ),\n    ],\n)\ndef test_dict_length_constraints(kwargs: Dict[str, Any], input_value, expected):\n    v = SchemaValidator({'type': 'dict', **kwargs})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_python(input_value)\n    else:\n        assert v.validate_python(input_value) == expected\n\n\ndef test_json_dict():\n    v = SchemaValidator({'type': 'dict', 'keys_schema': {'type': 'int'}, 'values_schema': {'type': 'int'}})\n    assert v.validate_json('{\"1\": 2, \"3\": 4}') == {1: 2, 3: 4}\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_json('1')\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'dict_type', 'loc': (), 'msg': 'Input should be an object', 'input': 1}\n    ]\n", "tests/validators/test_call.py": "import dataclasses\nimport re\nfrom collections import namedtuple\nfrom functools import partial\n\nimport pytest\n\nfrom pydantic_core import ArgsKwargs, SchemaValidator, ValidationError\n\nfrom ..conftest import Err, PyAndJson, plain_repr\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        [(1, 2, 3), 6],\n        [{'a': 1, 'b': 1, 'c': 1}, 3],\n        [ArgsKwargs((1,), {'b': 1, 'c': 1}), 3],\n        [(1, 2, 'x'), Err('2\\n  Input should be a valid integer,')],\n        [(3, 3, 4), 10],\n        [(3, 3, 5), Err('return\\n  Input should be less than or equal to 10')],\n    ],\n)\ndef test_function_call_arguments(py_and_json: PyAndJson, input_value, expected):\n    def my_function(a, b, c):\n        return a + b + c\n\n    v = py_and_json(\n        {\n            'type': 'call',\n            'function': my_function,\n            'arguments_schema': {\n                'type': 'arguments',\n                'arguments_schema': [\n                    {'name': 'a', 'mode': 'positional_or_keyword', 'schema': {'type': 'int'}},\n                    {'name': 'b', 'mode': 'positional_or_keyword', 'schema': {'type': 'int'}},\n                    {'name': 'c', 'mode': 'positional_or_keyword', 'schema': {'type': 'int'}},\n                ],\n            },\n            'return_schema': {'type': 'int', 'le': 10},\n        }\n    )\n\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)) as exc_info:\n            v.validate_python(input_value)\n        # debug(exc_info.value.errors(include_url=False))\n        if expected.errors is not None:\n            assert exc_info.value.errors(include_url=False) == expected.errors\n    else:\n        assert v.validate_python(input_value) == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        [((1, 2, 3), {}), 6],\n        [((1, 2, 3), {}), 6],\n        [{'a': 1, 'b': 1, 'c': 1}, 3],\n        ['x', TypeError('Arguments validator should return a tuple')],\n        # lists are not allowed, input must strictly be a tuple\n        [[(1, 2, 3), {}], TypeError('Arguments validator should return a tuple')],\n        [((1, 2, 3, 4), {}), TypeError('my_function() takes 3 positional arguments but 4 were given')],\n        [{'a': 1, 'b': 1, 'c': 1, 'd': 1}, TypeError(\"my_function() got an unexpected keyword argument 'd'\")],\n    ],\n)\ndef test_function_args_any(input_value, expected):\n    def my_function(a, b, c):\n        return a + b + c\n\n    v = SchemaValidator(\n        {'type': 'call', 'function': my_function, 'arguments_schema': {'type': 'any'}, 'return_schema': {'type': 'int'}}\n    )\n\n    if isinstance(expected, Exception):\n        with pytest.raises(type(expected), match=re.escape(str(expected))):\n            v.validate_python(input_value)\n    else:\n        assert v.validate_python(input_value) == expected\n\n\n@pytest.mark.parametrize('input_value,expected', [[((1,), {}), 1], [(('abc',), {}), 'abc']])\ndef test_function_return_any(input_value, expected):\n    def my_function(a):\n        return a\n\n    v = SchemaValidator({'type': 'call', 'function': my_function, 'arguments_schema': {'type': 'any'}})\n    assert 'name:\"call[my_function]\"' in plain_repr(v)\n\n    assert v.validate_python(input_value) == expected\n\n\ndef test_in_union():\n    def my_function(a):\n        return a\n\n    v = SchemaValidator(\n        {\n            'type': 'union',\n            'choices': [\n                {\n                    'type': 'call',\n                    'function': my_function,\n                    'arguments_schema': {\n                        'type': 'arguments',\n                        'arguments_schema': [{'name': 'a', 'mode': 'positional_or_keyword', 'schema': {'type': 'int'}}],\n                    },\n                },\n                {'type': 'int'},\n            ],\n        }\n    )\n    assert v.validate_python((1,)) == 1\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python((1, 2))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'unexpected_positional_argument',\n            'loc': ('call[my_function]', 1),\n            'msg': 'Unexpected positional argument',\n            'input': 2,\n        },\n        {'type': 'int_type', 'loc': ('int',), 'msg': 'Input should be a valid integer', 'input': (1, 2)},\n    ]\n\n\ndef test_dataclass():\n    @dataclasses.dataclass\n    class my_dataclass:\n        a: int\n        b: str\n\n    v = SchemaValidator(\n        {\n            'type': 'call',\n            'function': my_dataclass,\n            'arguments_schema': {\n                'type': 'arguments',\n                'arguments_schema': [\n                    {'name': 'a', 'mode': 'positional_or_keyword', 'schema': {'type': 'int'}},\n                    {'name': 'b', 'mode': 'positional_or_keyword', 'schema': {'type': 'str'}},\n                ],\n            },\n        }\n    )\n    d = v.validate_python(('1', b'2'))\n    assert dataclasses.is_dataclass(d)\n    assert d.a == 1\n    assert d.b == '2'\n    d = v.validate_python({'a': 1, 'b': '2'})\n    assert dataclasses.is_dataclass(d)\n    assert d.a == 1\n    assert d.b == '2'\n    assert 'name:\"call[my_dataclass]\"' in plain_repr(v)\n\n\ndef test_named_tuple():\n    Point = namedtuple('Point', ['x', 'y'])\n\n    v = SchemaValidator(\n        {\n            'type': 'call',\n            'function': Point,\n            'arguments_schema': {\n                'type': 'arguments',\n                'arguments_schema': [\n                    {'name': 'x', 'mode': 'positional_or_keyword', 'schema': {'type': 'float'}},\n                    {'name': 'y', 'mode': 'positional_or_keyword', 'schema': {'type': 'float'}},\n                ],\n            },\n        }\n    )\n    d = v.validate_python(('1.1', '2.2'))\n    assert isinstance(d, Point)\n    assert d.x == 1.1\n    assert d.y == 2.2\n\n    d = v.validate_python({'x': 1.1, 'y': 2.2})\n    assert isinstance(d, Point)\n    assert d.x == 1.1\n    assert d.y == 2.2\n\n\ndef test_function_call_partial():\n    def my_function(a, b, c):\n        return a + b + c\n\n    v = SchemaValidator(\n        {\n            'type': 'call',\n            'function': partial(my_function, c=3),\n            'arguments_schema': {\n                'type': 'arguments',\n                'arguments_schema': [\n                    {'name': 'a', 'mode': 'positional_or_keyword', 'schema': {'type': 'int'}},\n                    {'name': 'b', 'mode': 'positional_or_keyword', 'schema': {'type': 'int'}},\n                ],\n            },\n        }\n    )\n    assert 'name:\"call[my_function]\"' in plain_repr(v)\n    assert v.validate_python((1, 2)) == 6\n    assert v.validate_python((1, '2')) == 6\n\n\ndef test_custom_name():\n    def my_function(a):\n        return a\n\n    v = SchemaValidator(\n        {\n            'type': 'call',\n            'function': my_function,\n            'function_name': 'foobar',\n            'arguments_schema': {\n                'type': 'arguments',\n                'arguments_schema': [{'name': 'a', 'mode': 'positional_or_keyword', 'schema': {'type': 'int'}}],\n            },\n        }\n    )\n    assert 'name:\"call[foobar]\"' in plain_repr(v)\n    assert v.validate_python((1,)) == 1\n    assert v.validate_python(('2',)) == 2\n", "tests/validators/test_callable.py": "import pytest\n\nfrom pydantic_core import SchemaValidator, ValidationError\n\n\ndef func():\n    return 42\n\n\nclass Foo:\n    pass\n\n\nclass CallableClass:\n    def __call__(self, *args, **kwargs):\n        pass\n\n\ndef test_callable():\n    v = SchemaValidator({'type': 'callable'})\n    assert v.validate_python(func) == func\n    assert v.isinstance_python(func) is True\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python(42)\n\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'callable_type', 'loc': (), 'msg': 'Input should be callable', 'input': 42}\n    ]\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        (func, True),\n        (lambda: 42, True),\n        (lambda x: 2 * 42, True),\n        (dict, True),\n        (Foo, True),\n        (Foo(), False),\n        (4, False),\n        ('ddd', False),\n        ([], False),\n        ((1,), False),\n        (CallableClass, True),\n        (CallableClass(), True),\n    ],\n)\ndef test_callable_cases(input_value, expected):\n    v = SchemaValidator({'type': 'callable'})\n    assert v.isinstance_python(input_value) == expected\n\n\ndef test_repr():\n    v = SchemaValidator({'type': 'union', 'choices': [{'type': 'int'}, {'type': 'callable'}]})\n    assert v.isinstance_python(4) is True\n    assert v.isinstance_python(func) is True\n    assert v.isinstance_python('foo') is False\n\n    with pytest.raises(ValidationError, match=r'callable\\s+Input should be callable'):\n        v.validate_python('foo')\n", "tests/validators/test_arguments.py": "import re\nimport sys\nfrom functools import wraps\nfrom inspect import Parameter, signature\nfrom typing import Any, get_type_hints\n\nimport pytest\n\nfrom pydantic_core import ArgsKwargs, SchemaError, SchemaValidator, ValidationError, core_schema\n\nfrom ..conftest import Err, PyAndJson, plain_repr\n\n\ndef test_args_kwargs():\n    ak = ArgsKwargs(('hello', True))\n    assert str(ak) == \"ArgsKwargs(('hello', True))\"\n    assert repr(ak) == \"ArgsKwargs(('hello', True))\"\n    assert ak.args == ('hello', True)\n    assert ak.kwargs is None\n    ak2 = ArgsKwargs((), {'a': 123})\n    assert repr(ak2) == \"ArgsKwargs((), {'a': 123})\"\n    assert ak2.args == ()\n    assert ak2.kwargs == {'a': 123}\n    ak3 = ArgsKwargs(('hello', True), {'a': 123, 'b': b'bytes'})\n    assert repr(ak3) == \"ArgsKwargs(('hello', True), {'a': 123, 'b': b'bytes'})\"\n\n    assert ak != ak2\n\n    assert ak == ArgsKwargs(('hello', True))\n    assert ak3 == ArgsKwargs(('hello', True), {'a': 123, 'b': b'bytes'})\n    assert ak3 != ArgsKwargs(('hello', True), {'a': 123, 'b': b'different'})\n    assert ArgsKwargs((1,), {}) == ArgsKwargs((1,), None) == ArgsKwargs((1,))\n\n    assert repr(ArgsKwargs((1,))) == 'ArgsKwargs((1,))'\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        [(1, 'a', True), ((1, 'a', True), {})],\n        [[1, 'a', True], ((1, 'a', True), {})],\n        [ArgsKwargs((1, 'a', True)), ((1, 'a', True), {})],\n        [(1, 'a', 'true'), ((1, 'a', True), {})],\n        ['x', Err('type=arguments_type,')],\n        [\n            ArgsKwargs((1, 'a', True), {'x': 1}),\n            Err(\n                '',\n                [\n                    {\n                        'type': 'unexpected_keyword_argument',\n                        'loc': ('x',),\n                        'msg': 'Unexpected keyword argument',\n                        'input': 1,\n                    }\n                ],\n            ),\n        ],\n        [\n            [1],\n            Err(\n                '',\n                [\n                    {\n                        'type': 'missing_positional_only_argument',\n                        'loc': (1,),\n                        'msg': 'Missing required positional only argument',\n                        'input': [1],\n                    },\n                    {\n                        'type': 'missing_positional_only_argument',\n                        'loc': (2,),\n                        'msg': 'Missing required positional only argument',\n                        'input': [1],\n                    },\n                ],\n            ),\n        ],\n        [\n            [1, 'a', True, 4],\n            Err(\n                '',\n                [\n                    {\n                        'type': 'unexpected_positional_argument',\n                        'loc': (3,),\n                        'msg': 'Unexpected positional argument',\n                        'input': 4,\n                    }\n                ],\n            ),\n        ],\n        [\n            [1, 'a', True, 4, 5],\n            Err(\n                '',\n                [\n                    {\n                        'type': 'unexpected_positional_argument',\n                        'loc': (3,),\n                        'msg': 'Unexpected positional argument',\n                        'input': 4,\n                    },\n                    {\n                        'type': 'unexpected_positional_argument',\n                        'loc': (4,),\n                        'msg': 'Unexpected positional argument',\n                        'input': 5,\n                    },\n                ],\n            ),\n        ],\n        [\n            ('x', 'a', 'wrong'),\n            Err(\n                '',\n                [\n                    {\n                        'type': 'int_parsing',\n                        'loc': (0,),\n                        'msg': 'Input should be a valid integer, unable to parse string as an integer',\n                        'input': 'x',\n                    },\n                    {\n                        'type': 'bool_parsing',\n                        'loc': (2,),\n                        'msg': 'Input should be a valid boolean, unable to interpret input',\n                        'input': 'wrong',\n                    },\n                ],\n            ),\n        ],\n        [\n            ArgsKwargs(()),\n            Err(\n                '3 validation errors for arguments',\n                [\n                    {\n                        'type': 'missing_positional_only_argument',\n                        'loc': (0,),\n                        'msg': 'Missing required positional only argument',\n                        'input': ArgsKwargs(()),\n                    },\n                    {\n                        'type': 'missing_positional_only_argument',\n                        'loc': (1,),\n                        'msg': 'Missing required positional only argument',\n                        'input': ArgsKwargs(()),\n                    },\n                    {\n                        'type': 'missing_positional_only_argument',\n                        'loc': (2,),\n                        'msg': 'Missing required positional only argument',\n                        'input': ArgsKwargs(()),\n                    },\n                ],\n            ),\n        ],\n    ],\n    ids=repr,\n)\ndef test_positional_args(py_and_json: PyAndJson, input_value, expected):\n    v = py_and_json(\n        {\n            'type': 'arguments',\n            'arguments_schema': [\n                {'name': 'a', 'mode': 'positional_only', 'schema': {'type': 'int'}},\n                {'name': 'b', 'mode': 'positional_only', 'schema': {'type': 'str'}},\n                {'name': 'c', 'mode': 'positional_only', 'schema': {'type': 'bool'}},\n            ],\n        }\n    )\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)) as exc_info:\n            v.validate_test(input_value)\n        # debug(exc_info.value.errors(include_url=False))\n        if expected.errors is not None:\n            assert exc_info.value.errors(include_url=False) == expected.errors\n    else:\n        assert v.validate_test(input_value) == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        [ArgsKwargs((), {'a': 1, 'b': 'a', 'c': True}), ((), {'a': 1, 'b': 'a', 'c': True})],\n        [{'a': 1, 'b': 'a', 'c': True}, ((), {'a': 1, 'b': 'a', 'c': True})],\n        [ArgsKwargs((), {'a': '1', 'b': 'a', 'c': 'True'}), ((), {'a': 1, 'b': 'a', 'c': True})],\n        [ArgsKwargs((), {'a': 1, 'b': 'a', 'c': True}), ((), {'a': 1, 'b': 'a', 'c': True})],\n        [ArgsKwargs((1,), {'a': 1, 'b': 'a', 'c': True}), Err('type=unexpected_positional_argument,')],\n        [\n            ArgsKwargs((), {'a': 1, 'b': 'a', 'c': True, 'd': 'wrong'}),\n            Err(\n                'type=unexpected_keyword_argument,',\n                [\n                    {\n                        'type': 'unexpected_keyword_argument',\n                        'loc': ('d',),\n                        'msg': 'Unexpected keyword argument',\n                        'input': 'wrong',\n                    }\n                ],\n            ),\n        ],\n        [\n            ArgsKwargs((), {'a': 1, 'b': 'a'}),\n            Err(\n                'type=missing_keyword_only_argument,',\n                [\n                    {\n                        'type': 'missing_keyword_only_argument',\n                        'loc': ('c',),\n                        'msg': 'Missing required keyword only argument',\n                        'input': ArgsKwargs((), {'a': 1, 'b': 'a'}),\n                    }\n                ],\n            ),\n        ],\n        [\n            ArgsKwargs((), {'a': 'x', 'b': 'a', 'c': 'wrong'}),\n            Err(\n                '',\n                [\n                    {\n                        'type': 'int_parsing',\n                        'loc': ('a',),\n                        'msg': 'Input should be a valid integer, unable to parse string as an integer',\n                        'input': 'x',\n                    },\n                    {\n                        'type': 'bool_parsing',\n                        'loc': ('c',),\n                        'msg': 'Input should be a valid boolean, unable to interpret input',\n                        'input': 'wrong',\n                    },\n                ],\n            ),\n        ],\n        [\n            ArgsKwargs(()),\n            Err(\n                '',\n                [\n                    {\n                        'type': 'missing_keyword_only_argument',\n                        'loc': ('a',),\n                        'msg': 'Missing required keyword only argument',\n                        'input': ArgsKwargs(()),\n                    },\n                    {\n                        'type': 'missing_keyword_only_argument',\n                        'loc': ('b',),\n                        'msg': 'Missing required keyword only argument',\n                        'input': ArgsKwargs(()),\n                    },\n                    {\n                        'type': 'missing_keyword_only_argument',\n                        'loc': ('c',),\n                        'msg': 'Missing required keyword only argument',\n                        'input': ArgsKwargs(()),\n                    },\n                ],\n            ),\n        ],\n    ],\n    ids=repr,\n)\ndef test_keyword_args(py_and_json: PyAndJson, input_value, expected):\n    v = py_and_json(\n        {\n            'type': 'arguments',\n            'arguments_schema': [\n                {'name': 'a', 'mode': 'keyword_only', 'schema': {'type': 'int'}},\n                {'name': 'b', 'mode': 'keyword_only', 'schema': {'type': 'str'}},\n                {'name': 'c', 'mode': 'keyword_only', 'schema': {'type': 'bool'}},\n            ],\n        }\n    )\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)) as exc_info:\n            v.validate_test(input_value)\n        # debug(exc_info.value.errors(include_url=False))\n        if expected.errors is not None:\n            assert exc_info.value.errors(include_url=False) == expected.errors\n    else:\n        assert v.validate_test(input_value) == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        [{'a': 1, 'b': 'bb', 'c': True}, ((), {'a': 1, 'b': 'bb', 'c': True})],\n        [ArgsKwargs((), {'a': 1, 'b': 'bb', 'c': True}), ((), {'a': 1, 'b': 'bb', 'c': True})],\n        [ArgsKwargs((1, 'bb'), {'c': True}), ((1, 'bb'), {'c': True})],\n        [ArgsKwargs((1,), {'b': 'bb', 'c': True}), ((1,), {'b': 'bb', 'c': True})],\n        [\n            ArgsKwargs((1,), {'a': 11, 'b': 'bb', 'c': True}),\n            Err(\n                'type=multiple_argument_values,',\n                [\n                    {\n                        'type': 'multiple_argument_values',\n                        'loc': ('a',),\n                        'msg': 'Got multiple values for argument',\n                        'input': 11,\n                    }\n                ],\n            ),\n        ],\n        [\n            ArgsKwargs((1, 'bb', 'cc'), {'b': 'bb', 'c': True}),\n            Err(\n                'type=unexpected_positional_argument,',\n                [\n                    {\n                        'type': 'multiple_argument_values',\n                        'loc': ('b',),\n                        'msg': 'Got multiple values for argument',\n                        'input': 'bb',\n                    },\n                    {\n                        'type': 'unexpected_positional_argument',\n                        'loc': (2,),\n                        'msg': 'Unexpected positional argument',\n                        'input': 'cc',\n                    },\n                ],\n            ),\n        ],\n        [\n            ArgsKwargs((1, 'b1'), {'a': 11, 'b': 'b2', 'c': True}),\n            Err(\n                'type=multiple_argument_values,',\n                [\n                    {\n                        'type': 'multiple_argument_values',\n                        'loc': ('a',),\n                        'msg': 'Got multiple values for argument',\n                        'input': 11,\n                    },\n                    {\n                        'type': 'multiple_argument_values',\n                        'loc': ('b',),\n                        'msg': 'Got multiple values for argument',\n                        'input': 'b2',\n                    },\n                ],\n            ),\n        ],\n    ],\n    ids=repr,\n)\ndef test_positional_or_keyword(py_and_json: PyAndJson, input_value, expected):\n    v = py_and_json(\n        {\n            'type': 'arguments',\n            'arguments_schema': [\n                {'name': 'a', 'mode': 'positional_or_keyword', 'schema': {'type': 'int'}},\n                {'name': 'b', 'schema': {'type': 'str'}},  # default mode is positional_or_keyword\n                {'name': 'c', 'mode': 'keyword_only', 'schema': {'type': 'bool'}},\n            ],\n        }\n    )\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)) as exc_info:\n            v.validate_test(input_value)\n        # debug(exc_info.value.errors(include_url=False))\n        if expected.errors is not None:\n            assert exc_info.value.errors(include_url=False) == expected.errors\n    else:\n        assert v.validate_test(input_value) == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,expected,arguments_schema',\n    [\n        (\n            {'a': 1, 'b': 2, 'e': 3.14},\n            ((), {'a': 1, 'b': 2, 'c': 5, 'd': 'default', 'e': 3.14}),\n            [\n                {'name': 'a', 'mode': 'positional_or_keyword', 'schema': {'type': 'int'}},\n                {'name': 'b', 'mode': 'positional_or_keyword', 'schema': {'type': 'int'}},\n                {\n                    'name': 'c',\n                    'mode': 'keyword_only',\n                    'schema': {'type': 'default', 'schema': {'type': 'int'}, 'default': 5},\n                },\n                {\n                    'name': 'd',\n                    'mode': 'keyword_only',\n                    'schema': {'type': 'default', 'schema': {'type': 'str'}, 'default': 'default'},\n                },\n                {'name': 'e', 'mode': 'keyword_only', 'schema': {'type': 'float'}},\n            ],\n        ),\n        (\n            {'y': 'test'},\n            ((), {'x': 1, 'y': 'test'}),\n            [\n                {\n                    'name': 'x',\n                    'mode': 'keyword_only',\n                    'schema': {'type': 'default', 'schema': {'type': 'int'}, 'default': 1},\n                },\n                {'name': 'y', 'mode': 'keyword_only', 'schema': {'type': 'str'}},\n            ],\n        ),\n        (\n            {'a': 1, 'd': 3.14},\n            ((), {'a': 1, 'b': 10, 'c': 'hello', 'd': 3.14}),\n            [\n                {'name': 'a', 'mode': 'positional_or_keyword', 'schema': {'type': 'int'}},\n                {\n                    'name': 'b',\n                    'mode': 'positional_or_keyword',\n                    'schema': {'type': 'default', 'schema': {'type': 'int'}, 'default': 10},\n                },\n                {\n                    'name': 'c',\n                    'mode': 'keyword_only',\n                    'schema': {'type': 'default', 'schema': {'type': 'str'}, 'default': 'hello'},\n                },\n                {'name': 'd', 'mode': 'keyword_only', 'schema': {'type': 'float'}},\n            ],\n        ),\n        (\n            {'x': 3, 'y': 'custom', 'z': 4},\n            ((), {'x': 3, 'y': 'custom', 'z': 4}),\n            [\n                {'name': 'x', 'mode': 'positional_or_keyword', 'schema': {'type': 'int'}},\n                {\n                    'name': 'y',\n                    'mode': 'keyword_only',\n                    'schema': {'type': 'default', 'schema': {'type': 'str'}, 'default': 'default'},\n                },\n                {'name': 'z', 'mode': 'keyword_only', 'schema': {'type': 'int'}},\n            ],\n        ),\n    ],\n)\ndef test_keyword_only_non_default(py_and_json: PyAndJson, input_value, expected, arguments_schema):\n    v = py_and_json(\n        {\n            'type': 'arguments',\n            'arguments_schema': arguments_schema,\n        }\n    )\n    assert v.validate_test(input_value) == expected\n\n\n@pytest.mark.parametrize('input_value,expected', [[(1,), ((1,), {})], [(), ((42,), {})]], ids=repr)\ndef test_positional_optional(py_and_json: PyAndJson, input_value, expected):\n    v = py_and_json(\n        {\n            'type': 'arguments',\n            'arguments_schema': [\n                {\n                    'name': 'a',\n                    'mode': 'positional_only',\n                    'schema': {'type': 'default', 'schema': {'type': 'int'}, 'default': 42},\n                }\n            ],\n        }\n    )\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)) as exc_info:\n            v.validate_test(input_value)\n        # debug(exc_info.value.errors(include_url=False))\n        if expected.errors is not None:\n            assert exc_info.value.errors(include_url=False) == expected.errors\n    else:\n        assert v.validate_test(input_value) == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        [{'a': 1}, ((), {'a': 1})],\n        [ArgsKwargs((), {'a': 1}), ((), {'a': 1})],\n        [ArgsKwargs((), {'a': 1}), ((), {'a': 1})],\n        [ArgsKwargs(()), ((), {'a': 1})],\n    ],\n    ids=repr,\n)\ndef test_p_or_k_optional(py_and_json: PyAndJson, input_value, expected):\n    v = py_and_json(\n        {\n            'type': 'arguments',\n            'arguments_schema': [\n                {\n                    'name': 'a',\n                    'mode': 'positional_or_keyword',\n                    'schema': {'type': 'default', 'schema': {'type': 'int'}, 'default': 1},\n                }\n            ],\n        }\n    )\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)) as exc_info:\n            v.validate_test(input_value)\n        # debug(exc_info.value.errors(include_url=False))\n        if expected.errors is not None:\n            assert exc_info.value.errors(include_url=False) == expected.errors\n    else:\n        assert v.validate_test(input_value) == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        [[1, 2, 3], ((1, 2, 3), {})],\n        [ArgsKwargs((1, 2, 3)), ((1, 2, 3), {})],\n        [[1], ((1,), {})],\n        [[], ((), {})],\n        [ArgsKwargs((1, 2, 3), {'a': 1}), Err('a\\n  Unexpected keyword argument [type=unexpected_keyword_argument,')],\n    ],\n    ids=repr,\n)\ndef test_var_args_only(py_and_json: PyAndJson, input_value, expected):\n    v = py_and_json({'type': 'arguments', 'arguments_schema': [], 'var_args_schema': {'type': 'int'}})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)) as exc_info:\n            v.validate_test(input_value)\n        # debug(exc_info.value.errors(include_url=False))\n        if expected.errors is not None:\n            assert exc_info.value.errors(include_url=False) == expected.errors\n    else:\n        assert v.validate_test(input_value) == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        [[1, 2, 3], ((1, 2, 3), {})],\n        [['1', '2', '3'], ((1, 2, 3), {})],\n        [[1], ((1,), {})],\n        [[], Err('0\\n  Missing required positional only argument')],\n        [\n            ['x'],\n            Err(\n                'type=int_parsing,',\n                [\n                    {\n                        'type': 'int_parsing',\n                        'loc': (0,),\n                        'msg': 'Input should be a valid integer, unable to parse string as an integer',\n                        'input': 'x',\n                    }\n                ],\n            ),\n        ],\n        [\n            [1, 'x', 'y'],\n            Err(\n                'type=int_parsing,',\n                [\n                    {\n                        'type': 'int_parsing',\n                        'loc': (1,),\n                        'msg': 'Input should be a valid integer, unable to parse string as an integer',\n                        'input': 'x',\n                    },\n                    {\n                        'type': 'int_parsing',\n                        'loc': (2,),\n                        'msg': 'Input should be a valid integer, unable to parse string as an integer',\n                        'input': 'y',\n                    },\n                ],\n            ),\n        ],\n        [ArgsKwargs((1, 2, 3), {'a': 1}), Err('a\\n  Unexpected keyword argument [type=unexpected_keyword_argument,')],\n    ],\n    ids=repr,\n)\ndef test_args_var_args_only(py_and_json: PyAndJson, input_value, expected):\n    v = py_and_json(\n        {\n            'type': 'arguments',\n            'arguments_schema': [{'name': 'a', 'mode': 'positional_only', 'schema': {'type': 'int'}}],\n            'var_args_schema': {'type': 'int'},\n        }\n    )\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)) as exc_info:\n            v.validate_test(input_value)\n        # debug(exc_info.value.errors(include_url=False))\n        if expected.errors is not None:\n            assert exc_info.value.errors(include_url=False) == expected.errors\n    else:\n        assert v.validate_test(input_value) == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        [ArgsKwargs((1, 'a', 'true'), {'b': 'bb', 'c': 3}), ((1, 'a', True), {'b': 'bb', 'c': 3})],\n        [ArgsKwargs((1, 'a'), {'a': 'true', 'b': 'bb', 'c': 3}), ((1, 'a'), {'a': True, 'b': 'bb', 'c': 3})],\n        [\n            ArgsKwargs((1, 'a', 'true', 4, 5), {'b': 'bb', 'c': 3}),\n            Err(\n                'type=unexpected_positional_argument,',\n                [\n                    {\n                        'type': 'unexpected_positional_argument',\n                        'loc': (3,),\n                        'msg': 'Unexpected positional argument',\n                        'input': 4,\n                    },\n                    {\n                        'type': 'unexpected_positional_argument',\n                        'loc': (4,),\n                        'msg': 'Unexpected positional argument',\n                        'input': 5,\n                    },\n                ],\n            ),\n        ],\n    ],\n    ids=repr,\n)\ndef test_both(py_and_json: PyAndJson, input_value, expected):\n    v = py_and_json(\n        {\n            'type': 'arguments',\n            'arguments_schema': [\n                {'name': '1', 'mode': 'positional_only', 'schema': {'type': 'int'}},\n                {'name': '2', 'mode': 'positional_only', 'schema': {'type': 'str'}},\n                {'name': 'a', 'mode': 'positional_or_keyword', 'schema': {'type': 'bool'}},\n                {'name': 'b', 'mode': 'keyword_only', 'schema': {'type': 'str'}},\n                {'name': 'c', 'mode': 'keyword_only', 'schema': {'type': 'int'}},\n            ],\n        }\n    )\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)) as exc_info:\n            v.validate_test(input_value)\n        if expected.errors is not None:\n            assert exc_info.value.errors(include_url=False) == expected.errors\n    else:\n        assert v.validate_test(input_value) == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        [ArgsKwargs(()), ((), {})],\n        [[], ((), {})],\n        [[1], Err('0\\n  Unexpected positional argument [type=unexpected_positional_argument,')],\n        [{'a': 1}, Err('a\\n  Unexpected keyword argument [type=unexpected_keyword_argument,')],\n        [\n            ArgsKwargs((1,), {'a': 2}),\n            Err(\n                '[type=unexpected_keyword_argument,',\n                [\n                    {\n                        'type': 'unexpected_positional_argument',\n                        'loc': (0,),\n                        'msg': 'Unexpected positional argument',\n                        'input': 1,\n                    },\n                    {\n                        'type': 'unexpected_keyword_argument',\n                        'loc': ('a',),\n                        'msg': 'Unexpected keyword argument',\n                        'input': 2,\n                    },\n                ],\n            ),\n        ],\n    ],\n    ids=repr,\n)\ndef test_no_args(py_and_json: PyAndJson, input_value, expected):\n    v = py_and_json({'type': 'arguments', 'arguments_schema': []})\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)) as exc_info:\n            v.validate_test(input_value)\n        # debug(exc_info.value.errors(include_url=False))\n        if expected.errors is not None:\n            assert exc_info.value.errors(include_url=False) == expected.errors\n    else:\n        assert v.validate_test(input_value) == expected\n\n\ndef double_or_bust(input_value, info):\n    if input_value == 1:\n        raise RuntimeError('bust')\n    return input_value * 2\n\n\ndef test_internal_error(py_and_json: PyAndJson):\n    v = py_and_json(\n        {\n            'type': 'arguments',\n            'arguments_schema': [\n                {'name': 'a', 'mode': 'positional_only', 'schema': {'type': 'int'}},\n                {\n                    'name': 'b',\n                    'mode': 'positional_only',\n                    'schema': core_schema.with_info_plain_validator_function(double_or_bust),\n                },\n            ],\n        }\n    )\n    assert v.validate_test((1, 2)) == ((1, 4), {})\n    with pytest.raises(RuntimeError, match='bust'):\n        v.validate_test((1, 1))\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        [ArgsKwargs((1, 2)), ((1, 2), {})],\n        [ArgsKwargs((1,)), ((1,), {'b': 42})],\n        [ArgsKwargs((1,), {'b': 3}), ((1,), {'b': 3})],\n        [ArgsKwargs((), {'a': 1}), ((), {'a': 1, 'b': 42})],\n    ],\n    ids=repr,\n)\ndef test_default_factory(py_and_json: PyAndJson, input_value, expected):\n    v = py_and_json(\n        {\n            'type': 'arguments',\n            'arguments_schema': [\n                {'name': 'a', 'mode': 'positional_or_keyword', 'schema': {'type': 'int'}},\n                {\n                    'name': 'b',\n                    'mode': 'positional_or_keyword',\n                    'schema': {'type': 'default', 'schema': {'type': 'int'}, 'default_factory': lambda: 42},\n                },\n            ],\n        }\n    )\n    assert v.validate_test(input_value) == expected\n\n\ndef test_repr():\n    v = SchemaValidator(\n        {\n            'type': 'arguments',\n            'arguments_schema': [\n                {'name': 'b', 'mode': 'positional_or_keyword', 'schema': {'type': 'int'}},\n                {\n                    'name': 'a',\n                    'mode': 'keyword_only',\n                    'schema': {'type': 'default', 'schema': {'type': 'int'}, 'default_factory': lambda: 42},\n                },\n            ],\n        }\n    )\n    assert 'positional_params_count:1,' in plain_repr(v)\n\n\ndef test_build_non_default_follows():\n    with pytest.raises(SchemaError, match=\"Non-default argument 'b' follows default argument\"):\n        SchemaValidator(\n            {\n                'type': 'arguments',\n                'arguments_schema': [\n                    {\n                        'name': 'a',\n                        'mode': 'positional_or_keyword',\n                        'schema': {'type': 'default', 'schema': {'type': 'int'}, 'default_factory': lambda: 42},\n                    },\n                    {'name': 'b', 'mode': 'positional_or_keyword', 'schema': {'type': 'int'}},\n                ],\n            }\n        )\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        [ArgsKwargs((1, 2)), ((1, 2), {})],\n        [ArgsKwargs((1,), {'b': '4', 'c': 'a'}), ((1,), {'b': 4, 'c': 'a'})],\n        [ArgsKwargs((1, 2), {'x': 'abc'}), ((1, 2), {'x': 'abc'})],\n    ],\n    ids=repr,\n)\ndef test_kwargs(py_and_json: PyAndJson, input_value, expected):\n    v = py_and_json(\n        {\n            'type': 'arguments',\n            'arguments_schema': [\n                {'name': 'a', 'mode': 'positional_only', 'schema': {'type': 'int'}},\n                {'name': 'b', 'mode': 'positional_or_keyword', 'schema': {'type': 'int'}},\n            ],\n            'var_kwargs_schema': {'type': 'str'},\n        }\n    )\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_test(input_value)\n    else:\n        assert v.validate_test(input_value) == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        [ArgsKwargs((1,)), ((1,), {})],\n        [ArgsKwargs((), {'Foo': 1}), ((), {'a': 1})],\n        [ArgsKwargs((), {'a': 1}), Err('Foo\\n  Missing required argument [type=missing_argument,')],\n    ],\n    ids=repr,\n)\ndef test_alias(py_and_json: PyAndJson, input_value, expected):\n    v = py_and_json(\n        {\n            'type': 'arguments',\n            'arguments_schema': [\n                {'name': 'a', 'mode': 'positional_or_keyword', 'schema': {'type': 'int'}, 'alias': 'Foo'}\n            ],\n        }\n    )\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_test(input_value)\n    else:\n        assert v.validate_test(input_value) == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        [ArgsKwargs((1,)), ((1,), {})],\n        [ArgsKwargs((), {'Foo': 1}), ((), {'a': 1})],\n        [ArgsKwargs((), {'a': 1}), ((), {'a': 1})],\n        [ArgsKwargs((), {'a': 1, 'b': 2}), Err('b\\n  Unexpected keyword argument [type=unexpected_keyword_argument,')],\n        [\n            ArgsKwargs((), {'a': 1, 'Foo': 2}),\n            Err('a\\n  Unexpected keyword argument [type=unexpected_keyword_argument,'),\n        ],\n    ],\n    ids=repr,\n)\ndef test_alias_populate_by_name(py_and_json: PyAndJson, input_value, expected):\n    v = py_and_json(\n        {\n            'type': 'arguments',\n            'arguments_schema': [\n                {'name': 'a', 'mode': 'positional_or_keyword', 'schema': {'type': 'int'}, 'alias': 'Foo'}\n            ],\n            'populate_by_name': True,\n        }\n    )\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_test(input_value)\n    else:\n        assert v.validate_test(input_value) == expected\n\n\ndef validate(config=None):\n    def decorator(function):\n        parameters = signature(function).parameters\n        type_hints = get_type_hints(function)\n        mode_lookup = {\n            Parameter.POSITIONAL_ONLY: 'positional_only',\n            Parameter.POSITIONAL_OR_KEYWORD: 'positional_or_keyword',\n            Parameter.KEYWORD_ONLY: 'keyword_only',\n        }\n\n        arguments_schema = []\n        schema = {'type': 'arguments', 'arguments_schema': arguments_schema}\n        for i, (name, p) in enumerate(parameters.items()):\n            if p.annotation is p.empty:\n                annotation = Any\n            else:\n                annotation = type_hints[name]\n\n            assert annotation in (bool, int, float, str, Any), f'schema for {annotation} not implemented'\n            if annotation in (bool, int, float, str):\n                arg_schema = {'type': annotation.__name__}\n            else:\n                assert annotation is Any\n                arg_schema = {'type': 'any'}\n\n            if p.kind in mode_lookup:\n                if p.default is not p.empty:\n                    arg_schema = {'type': 'default', 'schema': arg_schema, 'default': p.default}\n                s = {'name': name, 'mode': mode_lookup[p.kind], 'schema': arg_schema}\n                arguments_schema.append(s)\n            elif p.kind == Parameter.VAR_POSITIONAL:\n                schema['var_args_schema'] = arg_schema\n            else:\n                assert p.kind == Parameter.VAR_KEYWORD, p.kind\n                schema['var_kwargs_schema'] = arg_schema\n\n        validator = SchemaValidator(schema, config=config)\n\n        @wraps(function)\n        def wrapper(*args, **kwargs):\n            # Validate arguments using the original schema\n            validated_args, validated_kwargs = validator.validate_python(ArgsKwargs(args, kwargs))\n            return function(*validated_args, **validated_kwargs)\n\n        return wrapper\n\n    return decorator\n\n\ndef test_function_any():\n    @validate()\n    def foobar(a, b, c):\n        return a, b, c\n\n    assert foobar(1, 2, 3) == (1, 2, 3)\n    assert foobar(1, 2, 3) == (1, 2, 3)\n    assert foobar(a=1, b=2, c=3) == (1, 2, 3)\n    assert foobar(1, b=2, c=3) == (1, 2, 3)\n\n    with pytest.raises(ValidationError, match='Unexpected positional argument'):\n        foobar(1, 2, 3, 4)\n\n    with pytest.raises(ValidationError, match='d\\n  Unexpected keyword argument'):\n        foobar(1, 2, 3, d=4)\n\n\ndef test_function_types():\n    @validate()\n    def foobar(a: int, b: int, *, c: int):\n        return a, b, c\n\n    assert foobar(1, 2, c='3') == (1, 2, 3)\n    assert foobar(a=1, b='2', c=3) == (1, 2, 3)\n\n    with pytest.raises(ValidationError, match='Unexpected positional argument'):\n        foobar(1, 2, 3)\n\n    with pytest.raises(ValidationError) as exc_info:\n        foobar(1, 'b')\n\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'int_parsing',\n            'loc': (1,),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'b',\n        },\n        {\n            'type': 'missing_keyword_only_argument',\n            'loc': ('c',),\n            'msg': 'Missing required keyword only argument',\n            'input': ArgsKwargs((1, 'b')),\n        },\n    ]\n\n    with pytest.raises(ValidationError) as exc_info:\n        foobar(1, 'b', c='c')\n\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'int_parsing',\n            'loc': (1,),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'b',\n        },\n        {\n            'type': 'int_parsing',\n            'loc': ('c',),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'c',\n        },\n    ]\n\n\n@pytest.mark.skipif(sys.version_info < (3, 10), reason='requires python3.10 or higher')\ndef test_function_positional_only(import_execute):\n    # language=Python\n    m = import_execute(\n        \"\"\"\ndef create_function(validate, config = None):\n    @validate(config = config)\n    def foobar(a: int, b: int, /, c: int):\n        return a, b, c\n    return foobar\n\"\"\"\n    )\n    foobar = m.create_function(validate)\n    assert foobar('1', 2, 3) == (1, 2, 3)\n    assert foobar('1', 2, c=3) == (1, 2, 3)\n    with pytest.raises(ValidationError) as exc_info:\n        foobar('1', b=2, c=3)\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'missing_positional_only_argument',\n            'loc': (1,),\n            'msg': 'Missing required positional only argument',\n            'input': ArgsKwargs(('1',), {'b': 2, 'c': 3}),\n        },\n        {'type': 'unexpected_keyword_argument', 'loc': ('b',), 'msg': 'Unexpected keyword argument', 'input': 2},\n    ]\n    # Allowing extras using the config\n    foobar = m.create_function(validate, config={'title': 'func', 'extra_fields_behavior': 'allow'})\n    assert foobar('1', '2', c=3, d=4) == (1, 2, 3)\n    # Ignore works similar than allow\n    foobar = m.create_function(validate, config={'title': 'func', 'extra_fields_behavior': 'ignore'})\n    assert foobar('1', '2', c=3, d=4) == (1, 2, 3)\n\n\n@pytest.mark.skipif(sys.version_info < (3, 10), reason='requires python3.10 or higher')\ndef test_function_positional_only_default(import_execute):\n    # language=Python\n    m = import_execute(\n        \"\"\"\ndef create_function(validate):\n    @validate()\n    def foobar(a: int, b: int = 42, /):\n        return a, b\n    return foobar\n\"\"\"\n    )\n    foobar = m.create_function(validate)\n    assert foobar('1', 2) == (1, 2)\n    assert foobar('1') == (1, 42)\n\n\n@pytest.mark.skipif(sys.version_info < (3, 10), reason='requires python3.10 or higher')\ndef test_function_positional_kwargs(import_execute):\n    # language=Python\n    m = import_execute(\n        \"\"\"\ndef create_function(validate):\n    @validate()\n    def foobar(a: int, b: int, /, **kwargs: bool):\n        return a, b, kwargs\n    return foobar\n\"\"\"\n    )\n    foobar = m.create_function(validate)\n    assert foobar('1', 2) == (1, 2, {})\n    assert foobar('1', 2, c=True) == (1, 2, {'c': True})\n    assert foobar('1', 2, a='false') == (1, 2, {'a': False})\n\n\ndef test_function_args_kwargs():\n    @validate()\n    def foobar(*args, **kwargs):\n        return args, kwargs\n\n    assert foobar(1, 2, 3, a=4, b=5) == ((1, 2, 3), {'a': 4, 'b': 5})\n    assert foobar(1, 2, 3) == ((1, 2, 3), {})\n    assert foobar(a=1, b=2, c=3) == ((), {'a': 1, 'b': 2, 'c': 3})\n    assert foobar() == ((), {})\n\n\ndef test_invalid_schema():\n    with pytest.raises(SchemaError, match=\"'default' and 'default_factory' cannot be used together\"):\n        SchemaValidator(\n            {\n                'type': 'arguments',\n                'arguments_schema': [\n                    {\n                        'name': 'a',\n                        'mode': 'positional_or_keyword',\n                        'schema': {\n                            'type': 'default',\n                            'schema': {'type': 'int'},\n                            'default': 1,\n                            'default_factory': lambda: 2,\n                        },\n                    }\n                ],\n            }\n        )\n\n\ndef test_error_display(pydantic_version):\n    v = SchemaValidator(\n        core_schema.arguments_schema(\n            [\n                core_schema.arguments_parameter('a', core_schema.int_schema()),\n                core_schema.arguments_parameter('b', core_schema.int_schema()),\n            ]\n        )\n    )\n    assert v.validate_python(ArgsKwargs((1,), {'b': '2'})) == ((1,), {'b': 2})\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python(ArgsKwargs((), {'a': 1}))\n\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'missing_argument',\n            'loc': ('b',),\n            'msg': 'Missing required argument',\n            'input': ArgsKwargs((), {'a': 1}),\n        }\n    ]\n    # insert_assert(str(exc_info.value))\n    assert str(exc_info.value) == (\n        '1 validation error for arguments\\n'\n        'b\\n'\n        '  Missing required argument [type=missing_argument, '\n        \"input_value=ArgsKwargs((), {'a': 1}), input_type=ArgsKwargs]\\n\"\n        f'    For further information visit https://errors.pydantic.dev/{pydantic_version}/v/missing_argument'\n    )\n    # insert_assert(exc_info.value.json(include_url=False))\n    assert exc_info.value.json(include_url=False) == (\n        '[{\"type\":\"missing_argument\",\"loc\":[\"b\"],\"msg\":\"Missing required argument\",'\n        '\"input\":\"ArgsKwargs((), {\\'a\\': 1})\"}]'\n    )\n", "tests/validators/test_dataclasses.py": "import dataclasses\nimport gc\nimport platform\nimport re\nimport sys\nimport weakref\nfrom typing import Any, ClassVar, Dict, List, Optional, Union\n\nimport pytest\nfrom dirty_equals import IsListOrTuple, IsStr\n\nfrom pydantic_core import ArgsKwargs, SchemaValidator, ValidationError, core_schema\n\nfrom ..conftest import Err, PyAndJson\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        (ArgsKwargs(('hello', True)), ({'a': 'hello', 'b': True}, None)),\n        ({'a': 'hello', 'b': True}, ({'a': 'hello', 'b': True}, None)),\n        ({'a': 'hello', 'b': 'true'}, ({'a': 'hello', 'b': True}, None)),\n        (ArgsKwargs(('hello', True)), ({'a': 'hello', 'b': True}, None)),\n        (ArgsKwargs((), {'a': 'hello', 'b': True}), ({'a': 'hello', 'b': True}, None)),\n        (\n            ArgsKwargs(('hello',), {'a': 'hello', 'b': True}),\n            Err(\n                'Got multiple values for argument',\n                errors=[\n                    {\n                        'type': 'multiple_argument_values',\n                        'loc': ('a',),\n                        'msg': 'Got multiple values for argument',\n                        'input': 'hello',\n                    }\n                ],\n            ),\n        ),\n        (\n            {'a': 'hello'},\n            Err(\n                'Field required',\n                errors=[{'type': 'missing', 'loc': ('b',), 'msg': 'Field required', 'input': {'a': 'hello'}}],\n            ),\n        ),\n    ],\n)\ndef test_dataclass_args(py_and_json: PyAndJson, input_value, expected):\n    schema = core_schema.dataclass_args_schema(\n        'MyDataclass',\n        [\n            core_schema.dataclass_field(name='a', schema=core_schema.str_schema(), kw_only=False),\n            core_schema.dataclass_field(name='b', schema=core_schema.bool_schema(), kw_only=False),\n        ],\n    )\n    v = py_and_json(schema)\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)) as exc_info:\n            v.validate_test(input_value)\n\n        # debug(exc_info.value.errors(include_url=False))\n        if expected.errors is not None:\n            assert exc_info.value.errors(include_url=False) == expected.errors\n    else:\n        assert v.validate_test(input_value) == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        (ArgsKwargs(('hello', True)), ({'a': 'hello'}, (True,))),\n        (ArgsKwargs(('hello', 'true')), ({'a': 'hello'}, (True,))),\n        (ArgsKwargs(('hello', True)), ({'a': 'hello'}, (True,))),\n        (ArgsKwargs((), {'a': 'hello', 'b': True}), ({'a': 'hello'}, (True,))),\n        (\n            ArgsKwargs(('hello',), {'a': 'hello', 'b': True}),\n            Err(\n                'Got multiple values for argument',\n                errors=[\n                    {\n                        'type': 'multiple_argument_values',\n                        'loc': ('a',),\n                        'msg': 'Got multiple values for argument',\n                        'input': 'hello',\n                    }\n                ],\n            ),\n        ),\n        (\n            {'a': 'hello'},\n            Err(\n                'Field required',\n                errors=[{'type': 'missing', 'loc': ('b',), 'msg': 'Field required', 'input': {'a': 'hello'}}],\n            ),\n        ),\n        (\n            {'a': 'hello', 'b': 'wrong'},\n            Err(\n                'Input should be a valid boolean, unable to interpret input',\n                errors=[\n                    {\n                        'type': 'bool_parsing',\n                        'loc': ('b',),\n                        'msg': 'Input should be a valid boolean, unable to interpret input',\n                        'input': 'wrong',\n                    }\n                ],\n            ),\n        ),\n    ],\n)\ndef test_dataclass_args_init_only(py_and_json: PyAndJson, input_value, expected):\n    schema = core_schema.dataclass_args_schema(\n        'MyDataclass',\n        [\n            core_schema.dataclass_field(name='a', schema=core_schema.str_schema(), kw_only=False),\n            core_schema.dataclass_field(name='b', schema=core_schema.bool_schema(), kw_only=False, init_only=True),\n        ],\n        collect_init_only=True,\n    )\n    v = py_and_json(schema)\n\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)) as exc_info:\n            v.validate_test(input_value)\n\n        # debug(exc_info.value.errors(include_url=False))\n        if expected.errors is not None:\n            assert exc_info.value.errors(include_url=False) == expected.errors\n    else:\n        assert v.validate_test(input_value) == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ({'a': 'hello'}, ({'a': 'hello'}, ())),\n        (ArgsKwargs((), {'a': 'hello'}), ({'a': 'hello'}, ())),\n        (\n            ('hello',),\n            Err(\n                'Input should be (an object|a dictionary or an instance of MyDataclass)',\n                errors=[\n                    {\n                        'type': 'dataclass_type',\n                        'loc': (),\n                        'msg': IsStr(regex='Input should be (an object|a dictionary or an instance of MyDataclass)'),\n                        'input': IsListOrTuple('hello'),\n                        'ctx': {'class_name': 'MyDataclass'},\n                    }\n                ],\n            ),\n        ),\n    ],\n)\ndef test_dataclass_args_init_only_no_fields(py_and_json: PyAndJson, input_value, expected):\n    schema = core_schema.dataclass_args_schema(\n        'MyDataclass', [core_schema.dataclass_field(name='a', schema=core_schema.str_schema())], collect_init_only=True\n    )\n    v = py_and_json(schema)\n\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=expected.message) as exc_info:\n            v.validate_test(input_value)\n\n        # debug(exc_info.value.errors(include_url=False))\n        if expected.errors is not None:\n            assert exc_info.value.errors(include_url=False) == expected.errors\n    else:\n        assert v.validate_test(input_value) == expected\n\n\ndef test_aliases(py_and_json: PyAndJson):\n    schema = core_schema.dataclass_args_schema(\n        'MyDataclass',\n        [\n            core_schema.dataclass_field(name='a', schema=core_schema.str_schema(), validation_alias='Apple'),\n            core_schema.dataclass_field(name='b', schema=core_schema.bool_schema(), validation_alias=['Banana', 1]),\n            core_schema.dataclass_field(\n                name='c', schema=core_schema.int_schema(), validation_alias=['Carrot', 'v'], init_only=True\n            ),\n        ],\n        collect_init_only=True,\n    )\n    v = py_and_json(schema)\n    assert v.validate_test({'Apple': 'a', 'Banana': ['x', 'false'], 'Carrot': {'v': '42'}}) == (\n        {'a': 'a', 'b': False},\n        (42,),\n    )\n\n\n@dataclasses.dataclass\nclass FooDataclass:\n    a: str\n    b: bool\n\n\ndef test_dataclass():\n    schema = core_schema.dataclass_schema(\n        FooDataclass,\n        core_schema.dataclass_args_schema(\n            'FooDataclass',\n            [\n                core_schema.dataclass_field(name='a', schema=core_schema.str_schema()),\n                core_schema.dataclass_field(name='b', schema=core_schema.bool_schema()),\n            ],\n        ),\n        ['a', 'b'],\n    )\n\n    v = SchemaValidator(schema)\n    foo = v.validate_python({'a': 'hello', 'b': True})\n    assert dataclasses.is_dataclass(foo)\n    assert foo.a == 'hello'\n    assert foo.b is True\n\n    assert dataclasses.asdict(v.validate_python(FooDataclass(a='hello', b=True))) == {'a': 'hello', 'b': True}\n\n    with pytest.raises(ValidationError, match='Input should be an instance of FooDataclass') as exc_info:\n        v.validate_python({'a': 'hello', 'b': True}, strict=True)\n\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'dataclass_exact_type',\n            'loc': (),\n            'msg': 'Input should be an instance of FooDataclass',\n            'input': {'a': 'hello', 'b': True},\n            'ctx': {'class_name': 'FooDataclass'},\n        }\n    ]\n\n\n@dataclasses.dataclass\nclass FooDataclassSame(FooDataclass):\n    pass\n\n\n@dataclasses.dataclass\nclass FooDataclassMore(FooDataclass):\n    c: str\n\n\n@dataclasses.dataclass\nclass DuplicateDifferent:\n    a: str\n    b: bool\n\n\n@pytest.mark.parametrize(\n    'revalidate_instances,input_value,expected',\n    [\n        ('always', {'a': 'hello', 'b': True}, {'a': 'hello', 'b': True}),\n        ('always', FooDataclass(a='hello', b=True), {'a': 'hello', 'b': True}),\n        ('always', FooDataclassSame(a='hello', b=True), {'a': 'hello', 'b': True}),\n        # no error because we only look for fields in schema['fields']\n        ('always', FooDataclassMore(a='hello', b=True, c='more'), {'a': 'hello', 'b': True}),\n        ('always', FooDataclassSame(a='hello', b='wrong'), Err(r'b\\s+Input should be a valid boolean,')),\n        ('always', DuplicateDifferent(a='hello', b=True), Err('should be a dictionary or an instance of FooDataclass')),\n        # revalidate_instances='subclass-instances'\n        ('subclass-instances', {'a': 'hello', 'b': True}, {'a': 'hello', 'b': True}),\n        ('subclass-instances', FooDataclass(a='hello', b=True), {'a': 'hello', 'b': True}),\n        ('subclass-instances', FooDataclass(a=b'hello', b='true'), {'a': b'hello', 'b': 'true'}),\n        ('subclass-instances', FooDataclassSame(a='hello', b=True), {'a': 'hello', 'b': True}),\n        ('subclass-instances', FooDataclassSame(a=b'hello', b='true'), {'a': 'hello', 'b': True}),\n        # no error because we only look for fields in schema['fields']\n        ('subclass-instances', FooDataclassMore(a='hello', b=True, c='more'), {'a': 'hello', 'b': True}),\n        ('subclass-instances', FooDataclassSame(a='hello', b='wrong'), Err(r'b\\s+Input should be a valid boolean,')),\n        ('subclass-instances', DuplicateDifferent(a='hello', b=True), Err('dictionary or an instance of FooDataclass')),\n        # revalidate_instances='never'\n        ('never', {'a': 'hello', 'b': True}, {'a': 'hello', 'b': True}),\n        ('never', FooDataclass(a='hello', b=True), {'a': 'hello', 'b': True}),\n        ('never', FooDataclassSame(a='hello', b=True), {'a': 'hello', 'b': True}),\n        ('never', FooDataclassMore(a='hello', b=True, c='more'), {'a': 'hello', 'b': True, 'c': 'more'}),\n        ('never', FooDataclassMore(a='hello', b='wrong', c='more'), {'a': 'hello', 'b': 'wrong', 'c': 'more'}),\n        ('never', DuplicateDifferent(a='hello', b=True), Err('should be a dictionary or an instance of FooDataclass')),\n    ],\n)\ndef test_dataclass_subclass(revalidate_instances, input_value, expected):\n    schema = core_schema.dataclass_schema(\n        FooDataclass,\n        core_schema.dataclass_args_schema(\n            'FooDataclass',\n            [\n                core_schema.dataclass_field(name='a', schema=core_schema.str_schema()),\n                core_schema.dataclass_field(name='b', schema=core_schema.bool_schema()),\n            ],\n            extra_behavior='forbid',\n        ),\n        ['a', 'b'],\n        revalidate_instances=revalidate_instances,\n    )\n    v = SchemaValidator(schema)\n\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=expected.message) as exc_info:\n            print(v.validate_python(input_value))\n\n        # debug(exc_info.value.errors(include_url=False))\n        if expected.errors is not None:\n            assert exc_info.value.errors(include_url=False) == expected.errors\n    else:\n        dc = v.validate_python(input_value)\n        assert dataclasses.is_dataclass(dc)\n        assert dataclasses.asdict(dc) == expected\n\n\ndef test_dataclass_subclass_strict_never_revalidate():\n    v = SchemaValidator(\n        core_schema.dataclass_schema(\n            FooDataclass,\n            core_schema.dataclass_args_schema(\n                'FooDataclass',\n                [\n                    core_schema.dataclass_field(name='a', schema=core_schema.str_schema()),\n                    core_schema.dataclass_field(name='b', schema=core_schema.bool_schema()),\n                ],\n            ),\n            ['a', 'b'],\n            revalidate_instances='never',\n            strict=True,\n        )\n    )\n\n    foo = FooDataclass(a='hello', b=True)\n    assert v.validate_python(foo) is foo\n    sub_foo = FooDataclassSame(a='hello', b=True)\n    assert v.validate_python(sub_foo) is sub_foo\n\n    # this fails but that's fine, in realty `ArgsKwargs` should only be used via validate_init\n    with pytest.raises(ValidationError, match='Input should be an instance of FooDataclass'):\n        v.validate_python(ArgsKwargs((), {'a': 'hello', 'b': True}))\n\n\ndef test_dataclass_subclass_subclass_revalidate():\n    v = SchemaValidator(\n        core_schema.dataclass_schema(\n            FooDataclass,\n            core_schema.dataclass_args_schema(\n                'FooDataclass',\n                [\n                    core_schema.dataclass_field(name='a', schema=core_schema.str_schema()),\n                    core_schema.dataclass_field(name='b', schema=core_schema.bool_schema()),\n                ],\n            ),\n            ['a', 'b'],\n            revalidate_instances='subclass-instances',\n            strict=True,\n        )\n    )\n\n    foo = FooDataclass(a='hello', b=True)\n    assert v.validate_python(foo) is foo\n    sub_foo = FooDataclassSame(a='hello', b='True')\n    sub_foo2 = v.validate_python(sub_foo)\n    assert sub_foo2 is not sub_foo\n    assert type(sub_foo2) is FooDataclass\n    assert dataclasses.asdict(sub_foo2) == dict(a='hello', b=True)\n\n\ndef test_dataclass_post_init():\n    @dataclasses.dataclass\n    class Foo:\n        a: str\n        b: bool\n\n        def __post_init__(self):\n            self.a = self.a.upper()\n\n    schema = core_schema.dataclass_schema(\n        Foo,\n        core_schema.dataclass_args_schema(\n            'Foo',\n            [\n                core_schema.dataclass_field(name='a', schema=core_schema.str_schema()),\n                core_schema.dataclass_field(name='b', schema=core_schema.bool_schema()),\n            ],\n        ),\n        ['a', 'b'],\n        post_init=True,\n    )\n\n    v = SchemaValidator(schema)\n    foo = v.validate_python({'a': 'hello', 'b': True})\n    assert foo.a == 'HELLO'\n    assert foo.b is True\n\n\ndef test_dataclass_post_init_args():\n    c_value = None\n\n    @dataclasses.dataclass\n    class Foo:\n        a: str\n        b: bool\n        c: dataclasses.InitVar[int]\n\n        def __post_init__(self, c: int):\n            nonlocal c_value\n            c_value = c\n\n    schema = core_schema.dataclass_schema(\n        Foo,\n        core_schema.dataclass_args_schema(\n            'Foo',\n            [\n                core_schema.dataclass_field(name='a', schema=core_schema.str_schema()),\n                core_schema.dataclass_field(name='b', schema=core_schema.bool_schema()),\n                core_schema.dataclass_field(name='c', schema=core_schema.int_schema(), init_only=True),\n            ],\n            collect_init_only=True,\n        ),\n        ['a', 'b'],\n        post_init=True,\n    )\n\n    v = SchemaValidator(schema)\n    foo = v.validate_python({'a': b'hello', 'b': 'true', 'c': '42'})\n    assert foo.a == 'hello'\n    assert foo.b is True\n    assert not hasattr(foo, 'c')\n    assert c_value == 42\n\n\ndef test_dataclass_post_init_args_multiple():\n    dc_args = None\n\n    @dataclasses.dataclass\n    class Foo:\n        a: str\n        b: dataclasses.InitVar[bool]\n        c: dataclasses.InitVar[int]\n\n        def __post_init__(self, *args):\n            nonlocal dc_args\n            dc_args = args\n\n    schema = core_schema.dataclass_schema(\n        Foo,\n        core_schema.dataclass_args_schema(\n            'Foo',\n            [\n                core_schema.dataclass_field(name='a', schema=core_schema.str_schema()),\n                core_schema.dataclass_field(name='b', schema=core_schema.bool_schema(), init_only=True),\n                core_schema.dataclass_field(name='c', schema=core_schema.int_schema(), init_only=True),\n            ],\n            collect_init_only=True,\n        ),\n        ['a', 'b'],\n        post_init=True,\n    )\n\n    v = SchemaValidator(schema)\n    foo = v.validate_python({'a': b'hello', 'b': 'true', 'c': '42'})\n    assert dataclasses.asdict(foo) == {'a': 'hello'}\n    assert dc_args == (True, 42)\n\n\n@pytest.mark.parametrize(\n    'revalidate_instances,input_value,expected',\n    [\n        ('always', {'a': b'hello', 'b': 'true'}, {'a': 'hello', 'b': True}),\n        ('always', FooDataclass(a='hello', b=True), {'a': 'hello', 'b': True}),\n        ('always', FooDataclass(a=b'hello', b='true'), {'a': 'hello', 'b': True}),\n        ('never', {'a': b'hello', 'b': 'true'}, {'a': 'hello', 'b': True}),\n        ('never', FooDataclass(a='hello', b=True), {'a': 'hello', 'b': True}),\n        ('never', FooDataclass(a=b'hello', b='true'), {'a': b'hello', 'b': 'true'}),\n    ],\n)\ndef test_dataclass_exact_validation(revalidate_instances, input_value, expected):\n    schema = core_schema.dataclass_schema(\n        FooDataclass,\n        core_schema.dataclass_args_schema(\n            'FooDataclass',\n            [\n                core_schema.dataclass_field(name='a', schema=core_schema.str_schema()),\n                core_schema.dataclass_field(name='b', schema=core_schema.bool_schema()),\n            ],\n        ),\n        ['a', 'b'],\n        revalidate_instances=revalidate_instances,\n    )\n\n    v = SchemaValidator(schema)\n    foo = v.validate_python(input_value)\n    assert dataclasses.asdict(foo) == expected\n\n\ndef test_dataclass_field_after_validator():\n    @dataclasses.dataclass\n    class Foo:\n        a: int\n        b: str\n\n        @classmethod\n        def validate_b(cls, v: str, info: core_schema.ValidationInfo) -> str:\n            assert v == 'hello'\n            assert info.field_name == 'b'\n            assert info.data == {'a': 1}\n            return 'hello world!'\n\n    schema = core_schema.dataclass_schema(\n        Foo,\n        core_schema.dataclass_args_schema(\n            'Foo',\n            [\n                core_schema.dataclass_field(name='a', schema=core_schema.int_schema()),\n                core_schema.dataclass_field(\n                    name='b',\n                    schema=core_schema.with_info_after_validator_function(\n                        Foo.validate_b, core_schema.str_schema(), field_name='b'\n                    ),\n                ),\n            ],\n        ),\n        ['a', 'b'],\n    )\n\n    v = SchemaValidator(schema)\n    foo = v.validate_python({'a': 1, 'b': b'hello'})\n    assert dataclasses.asdict(foo) == {'a': 1, 'b': 'hello world!'}\n\n\ndef test_dataclass_field_plain_validator():\n    @dataclasses.dataclass\n    class Foo:\n        a: int\n        b: str\n\n        @classmethod\n        def validate_b(cls, v: bytes, info: core_schema.ValidationInfo) -> str:\n            assert v == b'hello'\n            assert info.field_name == 'b'\n            assert info.data == {'a': 1}\n            return 'hello world!'\n\n    schema = core_schema.dataclass_schema(\n        Foo,\n        core_schema.dataclass_args_schema(\n            'Foo',\n            [\n                core_schema.dataclass_field(name='a', schema=core_schema.int_schema()),\n                core_schema.dataclass_field(\n                    name='b', schema=core_schema.with_info_plain_validator_function(Foo.validate_b, field_name='b')\n                ),\n            ],\n        ),\n        ['a', 'b'],\n    )\n\n    v = SchemaValidator(schema)\n    foo = v.validate_python({'a': 1, 'b': b'hello'})\n    assert dataclasses.asdict(foo) == {'a': 1, 'b': 'hello world!'}\n\n\ndef test_dataclass_field_before_validator():\n    @dataclasses.dataclass\n    class Foo:\n        a: int\n        b: str\n\n        @classmethod\n        def validate_b(cls, v: bytes, info: core_schema.ValidationInfo) -> bytes:\n            assert v == b'hello'\n            assert info.field_name == 'b'\n            assert info.data == {'a': 1}\n            return b'hello world!'\n\n    schema = core_schema.dataclass_schema(\n        Foo,\n        core_schema.dataclass_args_schema(\n            'Foo',\n            [\n                core_schema.dataclass_field(name='a', schema=core_schema.int_schema()),\n                core_schema.dataclass_field(\n                    name='b',\n                    schema=core_schema.with_info_before_validator_function(\n                        Foo.validate_b, core_schema.str_schema(), field_name='b'\n                    ),\n                ),\n            ],\n        ),\n        ['a', 'b'],\n    )\n\n    v = SchemaValidator(schema)\n    foo = v.validate_python({'a': 1, 'b': b'hello'})\n    assert dataclasses.asdict(foo) == {'a': 1, 'b': 'hello world!'}\n\n\ndef test_dataclass_field_wrap_validator1():\n    @dataclasses.dataclass\n    class Foo:\n        a: int\n        b: str\n\n        @classmethod\n        def validate_b(\n            cls, v: bytes, nxt: core_schema.ValidatorFunctionWrapHandler, info: core_schema.ValidationInfo\n        ) -> str:\n            assert v == b'hello'\n            v = nxt(v)\n            assert v == 'hello'\n            assert info.field_name == 'b'\n            assert info.data == {'a': 1}\n            return 'hello world!'\n\n    schema = core_schema.dataclass_schema(\n        Foo,\n        core_schema.dataclass_args_schema(\n            'Foo',\n            [\n                core_schema.dataclass_field(name='a', schema=core_schema.int_schema()),\n                core_schema.dataclass_field(\n                    name='b',\n                    schema=core_schema.with_info_wrap_validator_function(\n                        Foo.validate_b, core_schema.str_schema(), field_name='b'\n                    ),\n                ),\n            ],\n        ),\n        ['a', 'b'],\n    )\n\n    v = SchemaValidator(schema)\n    foo = v.validate_python({'a': 1, 'b': b'hello'})\n    assert dataclasses.asdict(foo) == {'a': 1, 'b': 'hello world!'}\n\n\ndef test_dataclass_field_wrap_validator2():\n    @dataclasses.dataclass\n    class Foo:\n        a: int\n        b: str\n\n        @classmethod\n        def validate_b(\n            cls, v: bytes, nxt: core_schema.ValidatorFunctionWrapHandler, info: core_schema.ValidationInfo\n        ) -> bytes:\n            assert v == b'hello'\n            assert info.field_name == 'b'\n            assert info.data == {'a': 1}\n            return nxt(b'hello world!')\n\n    schema = core_schema.dataclass_schema(\n        Foo,\n        core_schema.dataclass_args_schema(\n            'Foo',\n            [\n                core_schema.dataclass_field(name='a', schema=core_schema.int_schema()),\n                core_schema.dataclass_field(\n                    name='b',\n                    schema=core_schema.with_info_wrap_validator_function(\n                        Foo.validate_b, core_schema.str_schema(), field_name='b'\n                    ),\n                ),\n            ],\n        ),\n        ['a', 'b'],\n    )\n\n    v = SchemaValidator(schema)\n    foo = v.validate_python({'a': 1, 'b': b'hello'})\n    assert dataclasses.asdict(foo) == {'a': 1, 'b': 'hello world!'}\n\n\ndef test_dataclass_self_init():\n    @dataclasses.dataclass(init=False)\n    class Foo:\n        a: str\n        b: bool\n\n        def __init__(self, *args, **kwargs):\n            v.validate_python(ArgsKwargs(args, kwargs), self_instance=self)\n\n    schema = core_schema.dataclass_schema(\n        Foo,\n        core_schema.dataclass_args_schema(\n            'Foo',\n            [\n                core_schema.dataclass_field(name='a', schema=core_schema.str_schema(), kw_only=False),\n                core_schema.dataclass_field(name='b', schema=core_schema.bool_schema(), kw_only=False),\n            ],\n        ),\n        ['a', 'b'],\n    )\n    v = SchemaValidator(schema)\n\n    foo = Foo(b'hello', 'True')\n    assert dataclasses.is_dataclass(foo)\n    assert dataclasses.asdict(foo) == {'a': 'hello', 'b': True}\n\n\ndef test_dataclass_self_init_alias():\n    @dataclasses.dataclass(init=False)\n    class Foo:\n        a: str\n        b: bool\n\n    schema = core_schema.dataclass_schema(\n        Foo,\n        core_schema.dataclass_args_schema(\n            'Foo',\n            [\n                core_schema.dataclass_field(name='a', schema=core_schema.str_schema(), validation_alias='aAlias'),\n                core_schema.dataclass_field(name='b', schema=core_schema.bool_schema(), validation_alias=['bAlias', 0]),\n            ],\n        ),\n        ['a', 'b'],\n    )\n    v = SchemaValidator(schema)\n\n    def __init__(self, *args, **kwargs):\n        v.validate_python(ArgsKwargs(args, kwargs), self_instance=self)\n\n    Foo.__init__ = __init__\n\n    foo = Foo(aAlias=b'hello', bAlias=['True'])\n    assert dataclasses.is_dataclass(foo)\n    assert dataclasses.asdict(foo) == {'a': 'hello', 'b': True}\n\n    with pytest.raises(ValidationError) as exc_info:\n        Foo(aAlias=b'hello', bAlias=['wrong'])\n\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'bool_parsing',\n            'loc': ('bAlias', 0),\n            'msg': 'Input should be a valid boolean, unable to interpret input',\n            'input': 'wrong',\n        }\n    ]\n\n\ndef test_dataclass_self_init_alias_field_name():\n    @dataclasses.dataclass(init=False)\n    class Foo:\n        a: str\n        b: bool\n\n    schema = core_schema.dataclass_schema(\n        Foo,\n        core_schema.dataclass_args_schema(\n            'Foo',\n            [\n                core_schema.dataclass_field(name='a', schema=core_schema.str_schema(), validation_alias='aAlias'),\n                core_schema.dataclass_field(name='b', schema=core_schema.bool_schema(), validation_alias=['bAlias', 0]),\n            ],\n        ),\n        ['a', 'b'],\n        config={'loc_by_alias': False},\n    )\n    v = SchemaValidator(schema)\n\n    def __init__(self, *args, **kwargs):\n        v.validate_python(ArgsKwargs(args, kwargs), self_instance=self)\n\n    Foo.__init__ = __init__\n\n    foo = Foo(aAlias=b'hello', bAlias=['True'])\n    assert dataclasses.asdict(foo) == {'a': 'hello', 'b': True}\n\n    with pytest.raises(ValidationError) as exc_info:\n        Foo(aAlias=b'hello', bAlias=['wrong'])\n\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'bool_parsing',\n            'loc': ('b',),\n            'msg': 'Input should be a valid boolean, unable to interpret input',\n            'input': 'wrong',\n        }\n    ]\n\n\ndef test_dataclass_self_init_post_init():\n    calls = []\n\n    @dataclasses.dataclass(init=False)\n    class Foo:\n        a: str\n        b: bool\n        # _: dataclasses.KW_ONLY\n        c: dataclasses.InitVar[int]\n\n        def __init__(self, *args, **kwargs):\n            v.validate_python(ArgsKwargs(args, kwargs), self_instance=self)\n\n        def __post_init__(self, c):\n            calls.append(c)\n\n    schema = core_schema.dataclass_schema(\n        Foo,\n        core_schema.dataclass_args_schema(\n            'Foo',\n            [\n                core_schema.dataclass_field(name='a', schema=core_schema.str_schema(), kw_only=False),\n                core_schema.dataclass_field(name='b', schema=core_schema.bool_schema(), kw_only=False),\n                core_schema.dataclass_field(name='c', schema=core_schema.int_schema(), init_only=True),\n            ],\n            collect_init_only=True,\n        ),\n        ['a', 'b', 'c'],\n        post_init=True,\n    )\n    v = SchemaValidator(schema)\n\n    foo = Foo(b'hello', 'True', c='123')\n    assert dataclasses.is_dataclass(foo)\n    assert dataclasses.asdict(foo) == {'a': 'hello', 'b': True}\n    assert calls == [123]\n\n\ndef test_dataclass_validate_assignment():\n    schema = core_schema.dataclass_schema(\n        FooDataclass,\n        core_schema.dataclass_args_schema(\n            'FooDataclass',\n            [\n                core_schema.dataclass_field(name='a', schema=core_schema.str_schema(), kw_only=False),\n                core_schema.dataclass_field(name='b', schema=core_schema.bool_schema(), kw_only=False),\n            ],\n        ),\n        ['a', 'b'],\n    )\n    v = SchemaValidator(schema)\n\n    foo = v.validate_python({'a': 'hello', 'b': 'True'})\n    assert dataclasses.asdict(foo) == {'a': 'hello', 'b': True}\n    v.validate_assignment(foo, 'a', b'world')\n    assert dataclasses.asdict(foo) == {'a': 'world', 'b': True}\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_assignment(foo, 'a', 123)\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'string_type', 'loc': ('a',), 'msg': 'Input should be a valid string', 'input': 123}\n    ]\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_assignment(foo, 'c', '123')\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'no_such_attribute',\n            'loc': ('c',),\n            'msg': \"Object has no attribute 'c'\",\n            'input': '123',\n            'ctx': {'attribute': 'c'},\n        }\n    ]\n    assert not hasattr(foo, 'c')\n\n    # wrong arguments\n    with pytest.raises(AttributeError, match=\"'str' object has no attribute 'a'\"):\n        v.validate_assignment('field_a', 'c', 123)\n\n\ndef test_validate_assignment_function():\n    @dataclasses.dataclass\n    class MyDataclass:\n        field_a: str\n        field_b: int\n        field_c: int\n\n    calls = []\n\n    def func(x, info):\n        calls.append(str(info))\n        return x * 2\n\n    v = SchemaValidator(\n        core_schema.dataclass_schema(\n            MyDataclass,\n            core_schema.dataclass_args_schema(\n                'MyDataclass',\n                [\n                    core_schema.dataclass_field('field_a', core_schema.str_schema()),\n                    core_schema.dataclass_field(\n                        'field_b',\n                        core_schema.with_info_after_validator_function(\n                            func, core_schema.int_schema(), field_name='field_b'\n                        ),\n                    ),\n                    core_schema.dataclass_field('field_c', core_schema.int_schema()),\n                ],\n            ),\n            ['field_a', 'field_b', 'field_c'],\n        )\n    )\n\n    m = v.validate_python({'field_a': 'x', 'field_b': 123, 'field_c': 456})\n    assert m.field_a == 'x'\n    assert m.field_b == 246\n    assert m.field_c == 456\n    assert calls == [\"ValidationInfo(config=None, context=None, data={'field_a': 'x'}, field_name='field_b')\"]\n\n    v.validate_assignment(m, 'field_b', '111')\n\n    assert m.field_b == 222\n    assert calls == [\n        \"ValidationInfo(config=None, context=None, data={'field_a': 'x'}, field_name='field_b')\",\n        \"ValidationInfo(config=None, context=None, data={'field_a': 'x', 'field_c': 456}, field_name='field_b')\",\n    ]\n\n\ndef test_frozen():\n    @dataclasses.dataclass\n    class MyModel:\n        f: str\n\n    v = SchemaValidator(\n        core_schema.dataclass_schema(\n            MyModel,\n            core_schema.dataclass_args_schema('MyModel', [core_schema.dataclass_field('f', core_schema.str_schema())]),\n            ['f'],\n            frozen=True,\n        )\n    )\n\n    m = v.validate_python({'f': 'x'})\n    assert m.f == 'x'\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_assignment(m, 'f', 'y')\n\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'frozen_instance', 'loc': (), 'msg': 'Instance is frozen', 'input': 'y'}\n    ]\n\n\ndef test_frozen_field():\n    @dataclasses.dataclass\n    class MyModel:\n        f: str\n\n    v = SchemaValidator(\n        core_schema.dataclass_schema(\n            MyModel,\n            core_schema.dataclass_args_schema(\n                'MyModel', [core_schema.dataclass_field('f', core_schema.str_schema(), frozen=True)]\n            ),\n            ['f'],\n        )\n    )\n\n    m = v.validate_python({'f': 'x'})\n    assert m.f == 'x'\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_assignment(m, 'f', 'y')\n\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'frozen_field', 'loc': ('f',), 'msg': 'Field is frozen', 'input': 'y'}\n    ]\n\n\n@pytest.mark.parametrize(\n    'config,schema_extra_behavior_kw',\n    [\n        (core_schema.CoreConfig(extra_fields_behavior='ignore'), {}),\n        (core_schema.CoreConfig(extra_fields_behavior='ignore'), {'extra_behavior': None}),\n        (core_schema.CoreConfig(), {'extra_behavior': 'ignore'}),\n        (None, {'extra_behavior': 'ignore'}),\n        (core_schema.CoreConfig(extra_fields_behavior='allow'), {'extra_behavior': 'ignore'}),\n    ],\n)\ndef test_extra_behavior_ignore(config: Union[core_schema.CoreConfig, None], schema_extra_behavior_kw: Dict[str, Any]):\n    @dataclasses.dataclass\n    class MyModel:\n        f: str\n\n    v = SchemaValidator(\n        core_schema.dataclass_schema(\n            MyModel,\n            core_schema.dataclass_args_schema(\n                'MyModel', [core_schema.dataclass_field('f', core_schema.str_schema())], **schema_extra_behavior_kw\n            ),\n            ['f'],\n        ),\n        config=config,\n    )\n\n    m: MyModel = v.validate_python({'f': 'x', 'extra_field': 123})\n    assert m.f == 'x'\n    assert not hasattr(m, 'extra_field')\n\n    v.validate_assignment(m, 'f', 'y')\n    assert m.f == 'y'\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_assignment(m, 'not_f', 'xyz')\n\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'no_such_attribute',\n            'loc': ('not_f',),\n            'msg': \"Object has no attribute 'not_f'\",\n            'input': 'xyz',\n            'ctx': {'attribute': 'not_f'},\n        }\n    ]\n    assert not hasattr(m, 'not_f')\n\n\n@pytest.mark.parametrize(\n    'config,schema_extra_behavior_kw',\n    [\n        (core_schema.CoreConfig(extra_fields_behavior='forbid'), {}),\n        (core_schema.CoreConfig(extra_fields_behavior='forbid'), {'extra_behavior': None}),\n        (core_schema.CoreConfig(), {'extra_behavior': 'forbid'}),\n        (None, {'extra_behavior': 'forbid'}),\n        (core_schema.CoreConfig(extra_fields_behavior='ignore'), {'extra_behavior': 'forbid'}),\n    ],\n)\ndef test_extra_behavior_forbid(config: Union[core_schema.CoreConfig, None], schema_extra_behavior_kw: Dict[str, Any]):\n    @dataclasses.dataclass\n    class MyModel:\n        f: str\n\n    v = SchemaValidator(\n        core_schema.dataclass_schema(\n            MyModel,\n            core_schema.dataclass_args_schema(\n                'MyModel', [core_schema.dataclass_field('f', core_schema.str_schema())], **schema_extra_behavior_kw\n            ),\n            ['f'],\n        ),\n        config=config,\n    )\n\n    m: MyModel = v.validate_python({'f': 'x'})\n    assert m.f == 'x'\n\n    v.validate_assignment(m, 'f', 'y')\n    assert m.f == 'y'\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_assignment(m, 'not_f', 'xyz')\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'no_such_attribute',\n            'loc': ('not_f',),\n            'msg': \"Object has no attribute 'not_f'\",\n            'input': 'xyz',\n            'ctx': {'attribute': 'not_f'},\n        }\n    ]\n    assert not hasattr(m, 'not_f')\n\n\n@pytest.mark.parametrize(\n    'config,schema_extra_behavior_kw',\n    [\n        (core_schema.CoreConfig(extra_fields_behavior='allow'), {}),\n        (core_schema.CoreConfig(extra_fields_behavior='allow'), {'extra_behavior': None}),\n        (core_schema.CoreConfig(), {'extra_behavior': 'allow'}),\n        (None, {'extra_behavior': 'allow'}),\n        (core_schema.CoreConfig(extra_fields_behavior='forbid'), {'extra_behavior': 'allow'}),\n    ],\n)\ndef test_extra_behavior_allow(config: Union[core_schema.CoreConfig, None], schema_extra_behavior_kw: Dict[str, Any]):\n    @dataclasses.dataclass\n    class MyModel:\n        f: str\n\n    v = SchemaValidator(\n        core_schema.dataclass_schema(\n            MyModel,\n            core_schema.dataclass_args_schema(\n                'MyModel', [core_schema.dataclass_field('f', core_schema.str_schema())], **schema_extra_behavior_kw\n            ),\n            ['f'],\n            config=config,\n        )\n    )\n\n    m: MyModel = v.validate_python({'f': 'x', 'extra_field': '123'})\n    assert m.f == 'x'\n    assert getattr(m, 'extra_field') == '123'\n\n    v.validate_assignment(m, 'f', 'y')\n    assert m.f == 'y'\n\n    v.validate_assignment(m, 'not_f', '123')\n    assert getattr(m, 'not_f') == '123'\n\n\ndef test_function_validator_wrapping_args_schema_after() -> None:\n    calls: List[Any] = []\n\n    def func(*args: Any) -> Any:\n        calls.append(args)\n        return args[0]\n\n    @dataclasses.dataclass\n    class Model:\n        number: int = 1\n\n    cs = core_schema.dataclass_schema(\n        Model,\n        core_schema.no_info_after_validator_function(\n            func,\n            core_schema.dataclass_args_schema(\n                'Model', [core_schema.dataclass_field('number', core_schema.int_schema())]\n            ),\n        ),\n        ['number'],\n    )\n\n    v = SchemaValidator(cs)\n\n    instance: Model = v.validate_python({'number': 1})\n    assert instance.number == 1\n    assert calls == [(({'number': 1}, None),)]\n    v.validate_assignment(instance, 'number', 2)\n    assert instance.number == 2\n    assert calls == [(({'number': 1}, None),), (({'number': 2}, None),)]\n\n\ndef test_function_validator_wrapping_args_schema_before() -> None:\n    calls: List[Any] = []\n\n    def func(*args: Any) -> Any:\n        calls.append(args)\n        return args[0]\n\n    @dataclasses.dataclass\n    class Model:\n        number: int = 1\n\n    cs = core_schema.dataclass_schema(\n        Model,\n        core_schema.no_info_before_validator_function(\n            func,\n            core_schema.dataclass_args_schema(\n                'Model', [core_schema.dataclass_field('number', core_schema.int_schema())]\n            ),\n        ),\n        ['number'],\n    )\n\n    v = SchemaValidator(cs)\n\n    instance: Model = v.validate_python({'number': 1})\n    assert instance.number == 1\n    assert calls == [({'number': 1},)]\n    v.validate_assignment(instance, 'number', 2)\n    assert instance.number == 2\n    assert calls == [({'number': 1},), ({'number': 2},)]\n\n\ndef test_function_validator_wrapping_args_schema_wrap() -> None:\n    calls: List[Any] = []\n\n    def func(*args: Any) -> Any:\n        assert len(args) == 2\n        input, handler = args\n        output = handler(input)\n        calls.append((input, output))\n        return output\n\n    @dataclasses.dataclass\n    class Model:\n        number: int = 1\n\n    cs = core_schema.dataclass_schema(\n        Model,\n        core_schema.no_info_wrap_validator_function(\n            func,\n            core_schema.dataclass_args_schema(\n                'Model', [core_schema.dataclass_field('number', core_schema.int_schema())]\n            ),\n        ),\n        ['number'],\n    )\n\n    v = SchemaValidator(cs)\n\n    instance: Model = v.validate_python({'number': 1})\n    assert instance.number == 1\n    assert calls == [({'number': 1}, ({'number': 1}, None))]\n    v.validate_assignment(instance, 'number', 2)\n    assert instance.number == 2\n    assert calls == [({'number': 1}, ({'number': 1}, None)), ({'number': 2}, ({'number': 2}, None))]\n\n\n@dataclasses.dataclass\nclass FooParentDataclass:\n    foo: Optional[FooDataclass]\n\n\ndef test_custom_dataclass_names():\n    # Note: normally you would use the same values for DataclassArgsSchema.dataclass_name and DataclassSchema.cls_name,\n    # but I have purposely made them different here to show which parts of the errors are affected by which.\n    # I have used square brackets in the names to hint that the most likely reason for using a value different from\n    # cls.__name__ is for use with generic types.\n    schema = core_schema.dataclass_schema(\n        FooParentDataclass,\n        core_schema.dataclass_args_schema(\n            'FooParentDataclass',\n            [\n                core_schema.dataclass_field(\n                    name='foo',\n                    schema=core_schema.union_schema(\n                        [\n                            core_schema.dataclass_schema(\n                                FooDataclass,\n                                core_schema.dataclass_args_schema(\n                                    'FooDataclass[dataclass_args_schema]',\n                                    [\n                                        core_schema.dataclass_field(name='a', schema=core_schema.str_schema()),\n                                        core_schema.dataclass_field(name='b', schema=core_schema.bool_schema()),\n                                    ],\n                                ),\n                                ['a', 'b'],\n                                cls_name='FooDataclass[cls_name]',\n                            ),\n                            core_schema.none_schema(),\n                        ]\n                    ),\n                )\n            ],\n        ),\n        ['foo'],\n    )\n\n    v = SchemaValidator(schema)\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python({'foo': 123})\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'ctx': {'class_name': 'FooDataclass[dataclass_args_schema]'},\n            'input': 123,\n            'loc': ('foo', 'FooDataclass[cls_name]'),\n            'msg': 'Input should be a dictionary or an instance of FooDataclass[dataclass_args_schema]',\n            'type': 'dataclass_type',\n        },\n        {'input': 123, 'loc': ('foo', 'none'), 'msg': 'Input should be None', 'type': 'none_required'},\n    ]\n\n\n@pytest.mark.skipif(sys.version_info < (3, 10), reason='slots are only supported for dataclasses in Python >= 3.10')\ndef test_slots() -> None:\n    @dataclasses.dataclass(slots=True)\n    class Model:\n        x: int\n\n    schema = core_schema.dataclass_schema(\n        Model,\n        core_schema.dataclass_args_schema(\n            'Model', [core_schema.dataclass_field(name='x', schema=core_schema.int_schema())]\n        ),\n        ['x'],\n        slots=True,\n    )\n\n    val = SchemaValidator(schema)\n    m: Model\n\n    m = val.validate_python({'x': 123})\n    assert m == Model(x=123)\n\n    with pytest.raises(ValidationError):\n        val.validate_python({'x': 'abc'})\n\n    val.validate_assignment(m, 'x', 456)\n    assert m.x == 456\n\n    with pytest.raises(ValidationError):\n        val.validate_assignment(m, 'x', 'abc')\n\n\n@pytest.mark.skipif(sys.version_info < (3, 10), reason='slots are only supported for dataclasses in Python >= 3.10')\ndef test_dataclass_slots_field_before_validator():\n    @dataclasses.dataclass(slots=True)\n    class Foo:\n        a: int\n        b: str\n\n        @classmethod\n        def validate_b(cls, v: bytes, info: core_schema.ValidationInfo) -> bytes:\n            assert v == b'hello'\n            assert info.field_name == 'b'\n            assert info.data == {'a': 1}\n            return b'hello world!'\n\n    schema = core_schema.dataclass_schema(\n        Foo,\n        core_schema.dataclass_args_schema(\n            'Foo',\n            [\n                core_schema.dataclass_field(name='a', schema=core_schema.int_schema()),\n                core_schema.dataclass_field(\n                    name='b',\n                    schema=core_schema.with_info_before_validator_function(\n                        Foo.validate_b, core_schema.str_schema(), field_name='b'\n                    ),\n                ),\n            ],\n        ),\n        ['a', 'b'],\n        slots=True,\n    )\n\n    v = SchemaValidator(schema)\n    foo = v.validate_python({'a': 1, 'b': b'hello'})\n    assert dataclasses.asdict(foo) == {'a': 1, 'b': 'hello world!'}\n\n\n@pytest.mark.skipif(sys.version_info < (3, 10), reason='slots are only supported for dataclasses in Python >= 3.10')\ndef test_dataclass_slots_field_after_validator():\n    @dataclasses.dataclass(slots=True)\n    class Foo:\n        a: int\n        b: str\n\n        @classmethod\n        def validate_b(cls, v: str, info: core_schema.ValidationInfo) -> str:\n            assert v == 'hello'\n            assert info.field_name == 'b'\n            assert info.data == {'a': 1}\n            return 'hello world!'\n\n    schema = core_schema.dataclass_schema(\n        Foo,\n        core_schema.dataclass_args_schema(\n            'Foo',\n            [\n                core_schema.dataclass_field(name='a', schema=core_schema.int_schema()),\n                core_schema.dataclass_field(\n                    name='b',\n                    schema=core_schema.with_info_after_validator_function(\n                        Foo.validate_b, core_schema.str_schema(), field_name='b'\n                    ),\n                ),\n            ],\n        ),\n        ['a', 'b'],\n        slots=True,\n    )\n\n    v = SchemaValidator(schema)\n    foo = v.validate_python({'a': 1, 'b': b'hello'})\n    assert dataclasses.asdict(foo) == {'a': 1, 'b': 'hello world!'}\n\n\nif sys.version_info < (3, 10):\n    kwargs = {}\nelse:\n    kwargs = {'slots': True}\n\n\n@dataclasses.dataclass(**kwargs)\nclass FooDataclassSlots:\n    a: str\n    b: bool\n\n\n@dataclasses.dataclass(**kwargs)\nclass FooDataclassSameSlots(FooDataclassSlots):\n    pass\n\n\n@dataclasses.dataclass(**kwargs)\nclass FooDataclassMoreSlots(FooDataclassSlots):\n    c: str\n\n\n@dataclasses.dataclass(**kwargs)\nclass DuplicateDifferentSlots:\n    a: str\n    b: bool\n\n\n@pytest.mark.parametrize(\n    'revalidate_instances,input_value,expected',\n    [\n        ('always', {'a': 'hello', 'b': True}, {'a': 'hello', 'b': True}),\n        ('always', FooDataclassSlots(a='hello', b=True), {'a': 'hello', 'b': True}),\n        ('always', FooDataclassSameSlots(a='hello', b=True), {'a': 'hello', 'b': True}),\n        ('always', FooDataclassMoreSlots(a='hello', b=True, c='more'), {'a': 'hello', 'b': True}),\n        (\n            'always',\n            DuplicateDifferentSlots(a='hello', b=True),\n            Err('should be a dictionary or an instance of FooDataclass'),\n        ),\n        # revalidate_instances='subclass-instances'\n        ('subclass-instances', {'a': 'hello', 'b': True}, {'a': 'hello', 'b': True}),\n        ('subclass-instances', FooDataclassSlots(a='hello', b=True), {'a': 'hello', 'b': True}),\n        ('subclass-instances', FooDataclassSlots(a=b'hello', b='true'), {'a': b'hello', 'b': 'true'}),\n        ('subclass-instances', FooDataclassSameSlots(a='hello', b=True), {'a': 'hello', 'b': True}),\n        ('subclass-instances', FooDataclassSameSlots(a=b'hello', b='true'), {'a': 'hello', 'b': True}),\n        # no error because we don't look for fields unless their in schema['fields']\n        ('subclass-instances', FooDataclassMoreSlots(a='hello', b=True, c='more'), {'a': 'hello', 'b': True}),\n        ('subclass-instances', FooDataclassSameSlots(a=b'hello', b='wrong'), Err('Input should be a valid boolean,')),\n        (\n            'subclass-instances',\n            DuplicateDifferentSlots(a='hello', b=True),\n            Err('dictionary or an instance of FooDataclass'),\n        ),\n        # revalidate_instances='never'\n        ('never', {'a': 'hello', 'b': True}, {'a': 'hello', 'b': True}),\n        ('never', FooDataclassSlots(a='hello', b=True), {'a': 'hello', 'b': True}),\n        ('never', FooDataclassSameSlots(a='hello', b=True), {'a': 'hello', 'b': True}),\n        ('never', FooDataclassMoreSlots(a='hello', b=True, c='more'), {'a': 'hello', 'b': True, 'c': 'more'}),\n        ('never', FooDataclassMoreSlots(a='hello', b='wrong', c='more'), {'a': 'hello', 'b': 'wrong', 'c': 'more'}),\n        (\n            'never',\n            DuplicateDifferentSlots(a='hello', b=True),\n            Err('should be a dictionary or an instance of FooDataclass'),\n        ),\n    ],\n)\n@pytest.mark.skipif(sys.version_info < (3, 10), reason='slots are only supported for dataclasses in Python >= 3.10')\ndef test_slots_dataclass_subclass(revalidate_instances, input_value, expected):\n    schema = core_schema.dataclass_schema(\n        FooDataclassSlots,\n        core_schema.dataclass_args_schema(\n            'FooDataclass',\n            [\n                core_schema.dataclass_field(name='a', schema=core_schema.str_schema()),\n                core_schema.dataclass_field(name='b', schema=core_schema.bool_schema()),\n            ],\n            extra_behavior='forbid',\n        ),\n        ['a', 'b'],\n        revalidate_instances=revalidate_instances,\n        slots=True,\n    )\n    v = SchemaValidator(schema)\n\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=expected.message) as exc_info:\n            print(v.validate_python(input_value))\n\n        # debug(exc_info.value.errors(include_url=False))\n        if expected.errors is not None:\n            assert exc_info.value.errors(include_url=False) == expected.errors\n    else:\n        dc = v.validate_python(input_value)\n        assert dataclasses.is_dataclass(dc)\n        assert dataclasses.asdict(dc) == expected\n\n\n@pytest.mark.skipif(sys.version_info < (3, 10), reason='slots are only supported for dataclasses in Python >= 3.10')\ndef test_slots_mixed():\n    @dataclasses.dataclass(slots=True)\n    class Model:\n        x: int\n        y: dataclasses.InitVar[str]\n        z: ClassVar[str] = 'z-classvar'\n\n    @dataclasses.dataclass\n    class SubModel(Model):\n        x2: int\n        y2: dataclasses.InitVar[str]\n        z2: ClassVar[str] = 'z2-classvar'\n\n    schema = core_schema.dataclass_schema(\n        SubModel,\n        core_schema.dataclass_args_schema(\n            'SubModel',\n            [\n                core_schema.dataclass_field(name='x', schema=core_schema.int_schema()),\n                core_schema.dataclass_field(name='y', init_only=True, schema=core_schema.str_schema()),\n                core_schema.dataclass_field(name='x2', schema=core_schema.int_schema()),\n                core_schema.dataclass_field(name='y2', init_only=True, schema=core_schema.str_schema()),\n            ],\n        ),\n        ['x'],\n        slots=True,\n    )\n    v = SchemaValidator(schema)\n    dc = v.validate_python({'x': 1, 'y': 'a', 'x2': 2, 'y2': 'b'})\n    assert dc.x == 1\n    assert dc.x2 == 2\n    assert dataclasses.asdict(dc) == {'x': 1, 'x2': 2}\n\n\ndef test_dataclass_json():\n    schema = core_schema.dataclass_schema(\n        FooDataclass,\n        core_schema.dataclass_args_schema(\n            'FooDataclass',\n            [\n                core_schema.dataclass_field(name='a', schema=core_schema.str_schema()),\n                core_schema.dataclass_field(name='b', schema=core_schema.bool_schema()),\n            ],\n        ),\n        ['a', 'b'],\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_json('{\"a\": \"hello\", \"b\": true}') == FooDataclass(a='hello', b=True)\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_json('[\"a\", \"b\"]')\n\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'ctx': {'class_name': 'FooDataclass'},\n            'input': ['a', 'b'],\n            'loc': (),\n            'msg': 'Input should be an object',\n            'type': 'dataclass_type',\n        }\n    ]\n\n\ndef test_dataclass_wrap_json():\n    # https://github.com/pydantic/pydantic/issues/8147\n    schema = core_schema.no_info_wrap_validator_function(\n        lambda v, handler: handler(v),\n        core_schema.dataclass_schema(\n            FooDataclass,\n            core_schema.dataclass_args_schema(\n                'FooDataclass',\n                [\n                    core_schema.dataclass_field(name='a', schema=core_schema.str_schema()),\n                    core_schema.dataclass_field(name='b', schema=core_schema.bool_schema()),\n                ],\n            ),\n            ['a', 'b'],\n        ),\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_json('{\"a\": \"hello\", \"b\": true}') == FooDataclass(a='hello', b=True)\n    assert v.validate_json('{\"a\": \"hello\", \"b\": true}', strict=True) == FooDataclass(a='hello', b=True)\n\n\n@pytest.mark.xfail(\n    condition=platform.python_implementation() == 'PyPy', reason='https://foss.heptapod.net/pypy/pypy/-/issues/3899'\n)\n@pytest.mark.parametrize('validator', [None, 'field', 'dataclass'])\ndef test_leak_dataclass(validator):\n    def fn():\n        @dataclasses.dataclass\n        class Dataclass:\n            a: int\n\n            @classmethod\n            def _validator(cls, v, info):\n                return v\n\n            @classmethod\n            def _wrap_validator(cls, v, validator, info):\n                return validator(v)\n\n        field_schema = core_schema.int_schema()\n        if validator == 'field':\n            field_schema = core_schema.with_info_before_validator_function(\n                Dataclass._validator, field_schema, field_name='a'\n            )\n            field_schema = core_schema.with_info_wrap_validator_function(\n                Dataclass._wrap_validator, field_schema, field_name='a'\n            )\n            field_schema = core_schema.with_info_after_validator_function(\n                Dataclass._validator, field_schema, field_name='a'\n            )\n\n        dataclass_schema = core_schema.dataclass_schema(\n            Dataclass,\n            core_schema.dataclass_args_schema('Dataclass', [core_schema.dataclass_field('a', field_schema)]),\n            ['a'],\n        )\n\n        if validator == 'dataclass':\n            dataclass_schema = core_schema.with_info_before_validator_function(Dataclass._validator, dataclass_schema)\n            dataclass_schema = core_schema.with_info_wrap_validator_function(\n                Dataclass._wrap_validator, dataclass_schema\n            )\n            dataclass_schema = core_schema.with_info_after_validator_function(Dataclass._validator, dataclass_schema)\n\n        # If any of the Rust validators don't implement traversal properly,\n        # there will be an undetectable cycle created by this assignment\n        # which will keep Dataclass alive\n        Dataclass.__pydantic_validator__ = SchemaValidator(dataclass_schema)\n\n        return Dataclass\n\n    klass = fn()\n    ref = weakref.ref(klass)\n    assert ref() is not None\n\n    del klass\n    gc.collect(0)\n    gc.collect(1)\n    gc.collect(2)\n    gc.collect()\n\n    assert ref() is None\n\n\ninit_test_cases = [\n    ({'a': 'hello', 'b': 'bye'}, 'ignore', {'a': 'hello', 'b': 'HELLO'}),\n    ({'a': 'hello'}, 'ignore', {'a': 'hello', 'b': 'HELLO'}),\n    # note, for the case below, we don't actually support this case in Pydantic\n    # it's disallowed in Pydantic to have a model with extra='allow' and a field\n    # with init=False, so this case isn't really possible at the momment\n    # however, no conflict arises here because we don't pass in the value for b\n    # to __init__\n    ({'a': 'hello'}, 'allow', {'a': 'hello', 'b': 'HELLO'}),\n    (\n        {'a': 'hello', 'b': 'bye'},\n        'forbid',\n        Err(\n            'Unexpected keyword argument',\n            errors=[\n                {\n                    'type': 'unexpected_keyword_argument',\n                    'loc': ('b',),\n                    'msg': 'Unexpected keyword argument',\n                    'input': 'bye',\n                }\n            ],\n        ),\n    ),\n    ({'a': 'hello'}, 'forbid', {'a': 'hello', 'b': 'HELLO'}),\n]\n\n\n@pytest.mark.parametrize(\n    'input_value,extra_behavior,expected',\n    [\n        *init_test_cases,\n        # special case - when init=False, extra='allow', and the value is provided\n        # currently, it's disallowed in Pydantic to have a model with extra='allow'\n        # and a field with init=False, so this case isn't really possible at the momment\n        # TODO: open to changing this behavior, and changes won't be significantly breaking\n        # because we currently don't support this case\n        ({'a': 'hello', 'b': 'bye'}, 'allow', {'a': 'hello', 'b': 'HELLO'}),\n    ],\n)\ndef test_dataclass_args_init(input_value, extra_behavior, expected):\n    @dataclasses.dataclass\n    class Foo:\n        a: str\n        b: str\n\n        def __post_init__(self):\n            self.b = self.a.upper()\n\n    schema = core_schema.dataclass_schema(\n        Foo,\n        core_schema.dataclass_args_schema(\n            'Foo',\n            [\n                core_schema.dataclass_field(name='a', schema=core_schema.str_schema()),\n                core_schema.dataclass_field(name='b', schema=core_schema.str_schema(), init=False),\n            ],\n            extra_behavior=extra_behavior,\n        ),\n        ['a', 'b'],\n        post_init=True,\n    )\n\n    v = SchemaValidator(schema)\n\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)) as exc_info:\n            v.validate_python(input_value)\n\n        if expected.errors is not None:\n            assert exc_info.value.errors(include_url=False) == expected.errors\n    else:\n        assert dataclasses.asdict(v.validate_python(input_value)) == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,extra_behavior,expected',\n    [\n        *init_test_cases,\n        # special case - allow override of default, even when init=False, if extra='allow'\n        # TODO: we haven't really decided if this should be allowed or not\n        # currently, it's disallowed in Pydantic to have a model with extra='allow'\n        # and a field with init=False, so this case isn't really possible at the momment\n        ({'a': 'hello', 'b': 'bye'}, 'allow', {'a': 'hello', 'b': 'bye'}),\n    ],\n)\ndef test_dataclass_args_init_with_default(input_value, extra_behavior, expected):\n    @dataclasses.dataclass\n    class Foo:\n        a: str\n        b: str\n\n    schema = core_schema.dataclass_schema(\n        Foo,\n        core_schema.dataclass_args_schema(\n            'Foo',\n            [\n                core_schema.dataclass_field(name='a', schema=core_schema.str_schema()),\n                core_schema.dataclass_field(\n                    name='b',\n                    schema=core_schema.with_default_schema(schema=core_schema.str_schema(), default='HELLO'),\n                    init=False,\n                ),\n            ],\n            extra_behavior=extra_behavior,\n        ),\n        ['a', 'b'],\n    )\n\n    v = SchemaValidator(schema)\n\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)) as exc_info:\n            v.validate_python(input_value)\n\n        if expected.errors is not None:\n            assert exc_info.value.errors(include_url=False) == expected.errors\n    else:\n        assert dataclasses.asdict(v.validate_python(input_value)) == expected\n", "tests/validators/test_function.py": "import datetime\nimport platform\nimport re\nfrom copy import deepcopy\nfrom typing import Any, Dict, List, Type\n\nimport pytest\nfrom dirty_equals import HasRepr\n\nfrom pydantic_core import SchemaError, SchemaValidator, ValidationError, core_schema, validate_core_schema\n\nfrom ..conftest import plain_repr\n\n\ndef deepcopy_info(info: core_schema.ValidationInfo) -> Dict[str, Any]:\n    return {\n        'context': deepcopy(info.context),\n        'data': deepcopy(info.data),\n        'field_name': deepcopy(info.field_name),\n        'config': deepcopy(info.config),\n    }\n\n\ndef test_function_before():\n    def f(input_value, _info):\n        return input_value + ' Changed'\n\n    v = SchemaValidator(core_schema.with_info_before_validator_function(f, core_schema.str_schema()))\n\n    assert v.validate_python('input value') == 'input value Changed'\n\n\ndef test_function_before_no_info():\n    def f(input_value):\n        return input_value + ' Changed'\n\n    v = SchemaValidator(core_schema.no_info_before_validator_function(f, core_schema.str_schema()))\n\n    assert v.validate_python('input value') == 'input value Changed'\n\n\ndef test_function_before_raise():\n    def f(input_value, info):\n        raise ValueError('foobar')\n\n    v = SchemaValidator(core_schema.with_info_before_validator_function(f, core_schema.str_schema()))\n\n    with pytest.raises(ValidationError) as exc_info:\n        assert v.validate_python('input value') == 'input value Changed'\n    # debug(str(exc_info.value))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'value_error',\n            'loc': (),\n            'msg': 'Value error, foobar',\n            'input': 'input value',\n            'ctx': {'error': HasRepr(repr(ValueError('foobar')))},\n        }\n    ]\n\n\ndef test_function_before_error():\n    def my_function(input_value, info):\n        return input_value + 'x'\n\n    v = SchemaValidator(\n        {\n            'type': 'function-before',\n            'function': {'type': 'with-info', 'function': my_function},\n            'schema': {'type': 'str', 'max_length': 5},\n        }\n    )\n\n    assert v.validate_python('1234') == '1234x'\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python('12345')\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'string_too_long',\n            'loc': (),\n            'msg': 'String should have at most 5 characters',\n            'input': '12345x',\n            'ctx': {'max_length': 5},\n        }\n    ]\n    assert repr(exc_info.value).startswith('1 validation error for function-before[my_function(), constrained-str]\\n')\n\n\n@pytest.mark.parametrize(\n    'config,input_str',\n    (\n        ({}, \"type=string_too_long, input_value='12345x', input_type=str\"),\n        ({'hide_input_in_errors': False}, \"type=string_too_long, input_value='12345x', input_type=str\"),\n        ({'hide_input_in_errors': True}, 'type=string_too_long'),\n    ),\n)\ndef test_function_before_error_hide_input(config, input_str):\n    def my_function(input_value, info):\n        return input_value + 'x'\n\n    v = SchemaValidator(\n        {\n            'type': 'function-before',\n            'function': {'type': 'with-info', 'function': my_function},\n            'schema': {'type': 'str', 'max_length': 5},\n        },\n        config,\n    )\n\n    with pytest.raises(ValidationError, match=re.escape(f'String should have at most 5 characters [{input_str}]')):\n        v.validate_python('12345')\n\n\ndef test_function_before_error_model():\n    def f(input_value, info):\n        if 'my_field' in input_value:\n            input_value['my_field'] += 'x'\n        return input_value\n\n    v = SchemaValidator(\n        {\n            'type': 'function-before',\n            'function': {'type': 'with-info', 'function': f},\n            'schema': {\n                'type': 'typed-dict',\n                'fields': {'my_field': {'type': 'typed-dict-field', 'schema': {'type': 'str', 'max_length': 5}}},\n            },\n        }\n    )\n\n    assert v.validate_python({'my_field': '1234'}) == {'my_field': '1234x'}\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python({'my_field': '12345'})\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'string_too_long',\n            'loc': ('my_field',),\n            'msg': 'String should have at most 5 characters',\n            'input': '12345x',\n            'ctx': {'max_length': 5},\n        }\n    ]\n\n\n@pytest.mark.parametrize(\n    'config,kwargs,expected_repr',\n    [\n        (None, {}, 'ValidationInfo(config=None, context=None, data=None, field_name=None)'),\n        (None, {'context': {1: 2}}, 'ValidationInfo(config=None, context={1: 2}, data=None, field_name=None)'),\n        (None, {'context': None}, 'ValidationInfo(config=None, context=None, data=None, field_name=None)'),\n        ({'title': 'hello'}, {}, \"ValidationInfo(config={'title': 'hello'}, context=None, data=None, field_name=None)\"),\n    ],\n)\ndef test_val_info_repr(config, kwargs, expected_repr):\n    def f(input_value, info: core_schema.ValidationInfo):\n        assert repr(info) == expected_repr\n        assert str(info) == expected_repr\n        return input_value\n\n    v = SchemaValidator(core_schema.with_info_before_validator_function(f, core_schema.str_schema()), config)\n\n    assert v.validate_python('input value', **kwargs) == 'input value'\n\n\ndef test_function_wrap():\n    def f(input_value, validator, info):\n        return validator(input_value=input_value) + ' Changed'\n\n    v = SchemaValidator(core_schema.with_info_wrap_validator_function(f, core_schema.str_schema()))\n\n    assert v.validate_python('input value') == 'input value Changed'\n\n\ndef test_function_wrap_no_info():\n    def f(input_value, validator):\n        return validator(input_value=input_value) + ' Changed'\n\n    v = SchemaValidator(core_schema.no_info_wrap_validator_function(f, core_schema.str_schema()))\n\n    assert v.validate_python('input value') == 'input value Changed'\n\n\ndef test_function_wrap_repr():\n    def f(input_value, validator, info):\n        assert repr(validator) == str(validator)\n        return plain_repr(validator)\n\n    v = SchemaValidator(core_schema.with_info_wrap_validator_function(f, core_schema.str_schema()))\n\n    assert (\n        v.validate_python('input value')\n        == 'ValidatorCallable(Str(StrValidator{strict:false,coerce_numbers_to_str:false}))'\n    )\n\n\ndef test_function_wrap_str():\n    def f(input_value, validator, info):\n        return plain_repr(validator)\n\n    v = SchemaValidator(core_schema.with_info_wrap_validator_function(f, core_schema.str_schema()))\n\n    assert (\n        v.validate_python('input value')\n        == 'ValidatorCallable(Str(StrValidator{strict:false,coerce_numbers_to_str:false}))'\n    )\n\n\ndef test_function_wrap_not_callable():\n    with pytest.raises(SchemaError, match='function-wrap.function.typed-dict.function\\n  Input should be callable'):\n        validate_core_schema(core_schema.with_info_wrap_validator_function([], core_schema.str_schema()))\n\n    with pytest.raises(SchemaError, match='function-wrap.function\\n  Field required'):\n        validate_core_schema({'type': 'function-wrap', 'schema': {'type': 'str'}})\n\n\ndef test_wrap_error():\n    def f(input_value, validator, info):\n        try:\n            return validator(input_value) * 2\n        except ValidationError as e:\n            assert e.title == 'ValidatorCallable'\n            assert str(e).startswith('1 validation error for ValidatorCallable\\n')\n            raise e\n\n    v = SchemaValidator(core_schema.with_info_wrap_validator_function(f, core_schema.int_schema()))\n\n    assert v.validate_python('42') == 84\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python('wrong')\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'int_parsing',\n            'loc': (),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'wrong',\n        }\n    ]\n\n\n@pytest.mark.parametrize(\n    'config,input_str',\n    (\n        ({}, \"type=int_parsing, input_value='wrong', input_type=str\"),\n        ({'hide_input_in_errors': False}, \"type=int_parsing, input_value='wrong', input_type=str\"),\n        ({'hide_input_in_errors': True}, 'type=int_parsing'),\n    ),\n)\ndef test_function_wrap_error_hide_input(config, input_str):\n    def f(input_value, validator, info):\n        try:\n            return validator(input_value) * 2\n        except ValidationError as e:\n            assert e.title == 'ValidatorCallable'\n            assert str(e).startswith('1 validation error for ValidatorCallable\\n')\n            raise e\n\n    v = SchemaValidator(core_schema.with_info_wrap_validator_function(f, core_schema.int_schema()), config)\n\n    with pytest.raises(\n        ValidationError,\n        match=re.escape(f'Input should be a valid integer, unable to parse string as an integer [{input_str}]'),\n    ):\n        v.validate_python('wrong')\n\n\ndef test_function_wrap_location():\n    def f(input_value, validator, info):\n        return validator(input_value, outer_location='foo') + 2\n\n    v = SchemaValidator(core_schema.with_info_wrap_validator_function(f, core_schema.int_schema()))\n\n    assert v.validate_python(4) == 6\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python('wrong')\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'int_parsing',\n            'loc': ('foo',),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'wrong',\n        }\n    ]\n\n\ndef test_function_wrap_invalid_location():\n    def f(input_value, validator, info):\n        return validator(input_value, ('4',)) + 2\n\n    v = SchemaValidator(core_schema.with_info_wrap_validator_function(f, core_schema.int_schema()))\n\n    assert v.validate_python(4) == 6\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python('wrong')\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'int_parsing',\n            'loc': (\"('4',)\",),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'wrong',\n        }\n    ]\n\n\ndef test_function_after():\n    def f(input_value, _info):\n        return input_value + ' Changed'\n\n    v = SchemaValidator(core_schema.with_info_after_validator_function(f, core_schema.str_schema()))\n\n    assert v.validate_python('input value') == 'input value Changed'\n\n\ndef test_function_no_info():\n    def f(input_value):\n        return input_value + ' Changed'\n\n    v = SchemaValidator(core_schema.no_info_after_validator_function(f, core_schema.str_schema()))\n\n    assert v.validate_python('input value') == 'input value Changed'\n\n\ndef test_function_after_raise():\n    def f(input_value, info):\n        raise ValueError('foobar')\n\n    v = SchemaValidator(core_schema.with_info_after_validator_function(f, core_schema.str_schema()))\n\n    with pytest.raises(ValidationError) as exc_info:\n        assert v.validate_python('input value') == 'input value Changed'\n    # debug(str(exc_info.value))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'value_error',\n            'loc': (),\n            'msg': 'Value error, foobar',\n            'input': 'input value',\n            'ctx': {'error': HasRepr(repr(ValueError('foobar')))},\n        }\n    ]\n\n\n@pytest.mark.parametrize(\n    'config,input_str',\n    (\n        ({}, \"type=value_error, input_value='input value', input_type=str\"),\n        ({'hide_input_in_errors': False}, \"type=value_error, input_value='input value', input_type=str\"),\n        ({'hide_input_in_errors': True}, 'type=value_error'),\n    ),\n)\ndef test_function_after_error_hide_input(config, input_str):\n    def f(input_value, info):\n        raise ValueError('foobar')\n\n    v = SchemaValidator(core_schema.with_info_after_validator_function(f, core_schema.str_schema()), config)\n\n    with pytest.raises(ValidationError, match=re.escape(f'Value error, foobar [{input_str}]')):\n        v.validate_python('input value')\n\n\ndef test_function_after_config():\n    f_kwargs = None\n\n    def f(input_value, info):\n        nonlocal f_kwargs\n        f_kwargs = deepcopy_info(info)\n        return input_value + ' Changed'\n\n    v = SchemaValidator(\n        {\n            'type': 'typed-dict',\n            'fields': {\n                'test_field': {\n                    'type': 'typed-dict-field',\n                    'schema': {\n                        'type': 'function-after',\n                        'function': {'type': 'with-info', 'function': f, 'field_name': 'test_field'},\n                        'schema': {'type': 'str'},\n                    },\n                }\n            },\n            'config': {'allow_inf_nan': True},\n        }\n    )\n\n    assert v.validate_python({'test_field': b'321'}) == {'test_field': '321 Changed'}\n    assert f_kwargs == {'data': {}, 'config': {'allow_inf_nan': True}, 'context': None, 'field_name': 'test_field'}\n\n\ndef test_config_no_model():\n    f_kwargs = None\n\n    def f(input_value, info: core_schema.ValidationInfo):\n        nonlocal f_kwargs\n        f_kwargs = deepcopy_info(info)\n        return input_value + ' Changed'\n\n    v = SchemaValidator(core_schema.with_info_after_validator_function(f, core_schema.str_schema()))\n\n    assert v.validate_python(b'abc') == 'abc Changed'\n    assert f_kwargs == {'data': None, 'config': None, 'context': None, 'field_name': None}\n\n\ndef test_function_plain():\n    def f(input_value, _info):\n        return input_value * 2\n\n    v = SchemaValidator(core_schema.with_info_plain_validator_function(f))\n\n    assert v.validate_python(1) == 2\n    assert v.validate_python('x') == 'xx'\n\n\ndef test_function_plain_no_info():\n    def f(input_value):\n        return input_value * 2\n\n    v = SchemaValidator(core_schema.no_info_plain_validator_function(f))\n\n    assert v.validate_python(1) == 2\n    assert v.validate_python('x') == 'xx'\n\n\ndef test_plain_with_schema():\n    with pytest.raises(SchemaError, match='function-plain.schema\\n  Extra inputs are not permitted'):\n        validate_core_schema(\n            {\n                'type': 'function-plain',\n                'function': {'type': 'with-info', 'function': lambda x: x},\n                'schema': {'type': 'str'},\n            }\n        )\n\n\ndef test_validate_assignment():\n    def f(input_value):\n        input_value.more = 'foobar'\n        return input_value\n\n    class Model:\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n        field_a: str\n\n        def __init__(self):\n            self.__pydantic_extra__ = None  # this attribute must be present for validate_assignment\n\n    v = SchemaValidator(\n        core_schema.no_info_after_validator_function(\n            f,\n            core_schema.model_schema(\n                Model, core_schema.model_fields_schema({'field_a': core_schema.model_field(core_schema.str_schema())})\n            ),\n        )\n    )\n    m = v.validate_python({'field_a': 'test'})\n    assert isinstance(m, Model)\n    assert m.field_a == 'test'\n    assert m.__pydantic_fields_set__ == {'field_a'}\n    assert m.__dict__ == {'field_a': 'test', 'more': 'foobar'}\n    assert m.__pydantic_extra__ is None\n\n    m2 = Model()\n    m2.field_a = 'test'\n    assert v.validate_assignment(m2, 'field_a', b'abc') is m2\n    assert m2.__dict__ == {'field_a': 'abc', 'more': 'foobar'}\n    assert not hasattr(m2, '__pydantic_fields_set__')\n\n\ndef test_function_wrong_sig():\n    def f(input_value):\n        return input_value + ' Changed'\n\n    v = SchemaValidator(core_schema.with_info_before_validator_function(f, core_schema.str_schema()))\n\n    # exception messages differ between python and pypy\n    if platform.python_implementation() == 'PyPy':\n        error_message = 'f() takes 1 positional argument but 2 were given'\n    else:\n        error_message = 'f() takes 1 positional argument but 2 were given'\n\n    with pytest.raises(TypeError, match=re.escape(error_message)):\n        v.validate_python('input value')\n\n\ndef test_class_with_validator():\n    class Foobar:\n        a: int\n\n        def __init__(self, a):\n            self.a = a\n\n        @classmethod\n        def __validate__(cls, input_value, info):\n            return Foobar(input_value * 2)\n\n    v = SchemaValidator(\n        {\n            'type': 'function-after',\n            'function': {'type': 'with-info', 'function': Foobar.__validate__},\n            'schema': {'type': 'str'},\n        }\n    )\n\n    f = v.validate_python('foo')\n    assert isinstance(f, Foobar)\n    assert f.a == 'foofoo'\n\n    f = v.validate_python(b'a')\n    assert isinstance(f, Foobar)\n    assert f.a == 'aa'\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python(True)\n\n    assert exc_info.value.errors(include_url=False) == [\n        {'type': 'string_type', 'loc': (), 'msg': 'Input should be a valid string', 'input': True}\n    ]\n\n\ndef test_raise_assertion_error():\n    def f(input_value, info):\n        raise AssertionError('foobar')\n\n    v = SchemaValidator(core_schema.with_info_before_validator_function(f, core_schema.str_schema()))\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python('input value')\n\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'assertion_error',\n            'loc': (),\n            'msg': 'Assertion failed, foobar',\n            'input': 'input value',\n            'ctx': {'error': HasRepr(repr(AssertionError('foobar')))},\n        }\n    ]\n\n\ndef test_raise_assertion_error_plain():\n    def f(input_value, info):\n        raise AssertionError\n\n    v = SchemaValidator(core_schema.with_info_before_validator_function(f, core_schema.str_schema()))\n\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_python('input value')\n\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'assertion_error',\n            'loc': (),\n            'msg': 'Assertion failed, ',\n            'input': 'input value',\n            'ctx': {'error': HasRepr(repr(AssertionError()))},\n        }\n    ]\n\n\n@pytest.mark.parametrize('base_error', [ValueError, AssertionError])\ndef test_error_with_error(base_error: Type[Exception]):\n    class MyError(base_error):\n        def __str__(self):\n            raise RuntimeError('internal error')\n\n    def f(input_value, info):\n        raise MyError()\n\n    v = SchemaValidator(core_schema.with_info_before_validator_function(f, core_schema.str_schema()))\n\n    with pytest.raises(RuntimeError, match='internal error'):\n        v.validate_python('input value')\n\n\ndef test_raise_type_error():\n    def f(input_value, info):\n        raise TypeError('foobar')\n\n    v = SchemaValidator(core_schema.with_info_before_validator_function(f, core_schema.str_schema()))\n\n    with pytest.raises(TypeError, match='^foobar$'):\n        v.validate_python('input value')\n\n\ndef test_model_field_before_validator() -> None:\n    class Model:\n        x: str\n\n    def f(input_value: Any, info: core_schema.ValidationInfo) -> Any:\n        assert info.field_name == 'x'\n        assert info.data == {}\n        assert repr(info) == \"ValidationInfo(config=None, context=None, data={}, field_name='x')\"\n        assert str(info) == \"ValidationInfo(config=None, context=None, data={}, field_name='x')\"\n        assert isinstance(input_value, bytes)\n        return f'input: {input_value.decode()}'\n\n    v = SchemaValidator(\n        core_schema.model_schema(\n            Model,\n            core_schema.model_fields_schema(\n                {\n                    'x': core_schema.model_field(\n                        core_schema.with_info_before_validator_function(f, core_schema.str_schema(), field_name='x')\n                    )\n                }\n            ),\n        )\n    )\n\n    assert v.validate_python({'x': b'foo'}).x == 'input: foo'\n\n\ndef test_model_field_after_validator() -> None:\n    class Model:\n        x: str\n\n    def f(input_value: str, info: core_schema.ValidationInfo) -> Any:\n        assert info.field_name == 'x'\n        assert info.data == {}\n        assert isinstance(input_value, str)\n        return f'input: {input_value}'\n\n    v = SchemaValidator(\n        core_schema.model_schema(\n            Model,\n            core_schema.model_fields_schema(\n                {\n                    'x': core_schema.model_field(\n                        core_schema.with_info_after_validator_function(f, core_schema.str_schema(), field_name='x')\n                    )\n                }\n            ),\n        )\n    )\n\n    assert v.validate_python({'x': b'foo'}).x == 'input: foo'\n\n\ndef test_model_field_plain_validator() -> None:\n    class Model:\n        x: str\n\n    def f(input_value: Any, info: core_schema.ValidationInfo) -> Any:\n        assert info.field_name == 'x'\n        assert info.data == {}\n        assert isinstance(input_value, bytes)\n        return f'input: {input_value.decode()}'\n\n    v = SchemaValidator(\n        core_schema.model_schema(\n            Model,\n            core_schema.model_fields_schema(\n                {'x': core_schema.model_field(core_schema.with_info_plain_validator_function(f, field_name='x'))}\n            ),\n        )\n    )\n\n    assert v.validate_python({'x': b'foo'}).x == 'input: foo'\n\n\ndef test_model_field_wrap_validator() -> None:\n    class Model:\n        x: str\n\n    def f(input_value: Any, val: core_schema.ValidatorFunctionWrapHandler, info: core_schema.ValidationInfo) -> Any:\n        assert info.field_name == 'x'\n        assert info.data == {}\n        assert isinstance(input_value, bytes)\n        return f'input: {val(input_value)}'\n\n    v = SchemaValidator(\n        core_schema.model_schema(\n            Model,\n            core_schema.model_fields_schema(\n                {\n                    'x': core_schema.model_field(\n                        core_schema.with_info_wrap_validator_function(f, core_schema.str_schema(), field_name='x')\n                    )\n                }\n            ),\n        )\n    )\n\n    assert v.validate_python({'x': b'foo'}).x == 'input: foo'\n\n\ndef check_info_field_name_none(info: core_schema.ValidationInfo) -> None:\n    assert info.field_name is None\n    assert info.data == {}\n\n\ndef test_non_model_field_before_validator_tries_to_access_field_info() -> None:\n    class Model:\n        x: str\n\n    def f(input_value: Any, info: core_schema.ValidationInfo) -> Any:\n        check_info_field_name_none(info)\n        assert isinstance(input_value, bytes)\n        return f'input: {input_value.decode()}'\n\n    v = SchemaValidator(\n        core_schema.model_schema(\n            Model,\n            core_schema.model_fields_schema(\n                {\n                    'x': core_schema.model_field(\n                        core_schema.with_info_before_validator_function(f, core_schema.str_schema())\n                    )\n                }\n            ),\n        )\n    )\n\n    assert v.validate_python({'x': b'foo'}).x == 'input: foo'\n\n\ndef test_non_model_field_after_validator_tries_to_access_field_info() -> None:\n    class Model:\n        x: str\n\n    def f(input_value: Any, info: core_schema.ValidationInfo) -> Any:\n        check_info_field_name_none(info)\n        return f'input: {input_value}'\n\n    v = SchemaValidator(\n        core_schema.model_schema(\n            Model,\n            core_schema.model_fields_schema(\n                {\n                    'x': core_schema.model_field(\n                        core_schema.with_info_after_validator_function(f, core_schema.str_schema())\n                    )\n                }\n            ),\n        )\n    )\n\n    assert v.validate_python({'x': b'foo'}).x == 'input: foo'\n\n\ndef test_non_model_field_plain_validator_tries_to_access_field_info() -> None:\n    class Model:\n        x: str\n\n    def f(input_value: Any, info: core_schema.ValidationInfo) -> Any:\n        check_info_field_name_none(info)\n        assert isinstance(input_value, bytes)\n        return f'input: {input_value.decode()}'\n\n    v = SchemaValidator(\n        core_schema.model_schema(\n            Model,\n            core_schema.model_fields_schema(\n                {'x': core_schema.model_field(core_schema.with_info_plain_validator_function(f))}\n            ),\n        )\n    )\n\n    assert v.validate_python({'x': b'foo'}).x == 'input: foo'\n\n\ndef test_non_model_field_wrap_validator_tries_to_access_field_info() -> None:\n    class Model:\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n        x: str\n\n    def f(input_value: Any, val: core_schema.ValidatorFunctionWrapHandler, info: core_schema.ValidationInfo) -> Any:\n        check_info_field_name_none(info)\n        return f'input: {val(input_value)}'\n\n    v = SchemaValidator(\n        core_schema.model_schema(\n            Model,\n            core_schema.model_fields_schema(\n                {\n                    'x': core_schema.model_field(\n                        core_schema.with_info_wrap_validator_function(f, core_schema.str_schema())\n                    )\n                }\n            ),\n        )\n    )\n\n    assert v.validate_python({'x': b'foo'}).x == 'input: foo'\n\n\ndef test_typed_dict_data() -> None:\n    info_stuff = None\n\n    def f(input_value: Any, info: core_schema.ValidationInfo) -> Any:\n        nonlocal info_stuff\n        info_stuff = {'field_name': info.field_name, 'data': info.data.copy()}\n        assert isinstance(input_value, str)\n        return f'input: {input_value}'\n\n    v = SchemaValidator(\n        core_schema.typed_dict_schema(\n            {\n                'a': core_schema.typed_dict_field(core_schema.int_schema()),\n                'b': core_schema.typed_dict_field(core_schema.int_schema()),\n                'c': core_schema.typed_dict_field(\n                    core_schema.with_info_after_validator_function(f, core_schema.str_schema(), field_name='c')\n                ),\n            }\n        )\n    )\n\n    data = v.validate_python({'a': 1, 'b': '2', 'c': b'foo'})\n    assert data == {'a': 1, 'b': 2, 'c': 'input: foo'}\n    assert info_stuff == {'field_name': 'c', 'data': {'a': 1, 'b': 2}}\n\n    info_stuff = None\n\n    with pytest.raises(ValidationError, match=r'b\\s+Input should be a valid integer'):\n        v.validate_python({'a': 1, 'b': 'wrong', 'c': b'foo'})\n\n    assert info_stuff == {'field_name': 'c', 'data': {'a': 1}}\n\n\n@pytest.mark.parametrize(\n    'mode,calls1,calls2',\n    [\n        ('before', {'value': {'x': b'input', 'y': '123'}}, {'value': {'x': 'different', 'y': 123}}),\n        (\n            'after',\n            {'value': ({'x': 'input', 'y': 123}, None, {'y', 'x'})},\n            {'value': ({'x': 'different', 'y': 123}, None, {'x'})},\n        ),\n        ('wrap', {'value': {'x': b'input', 'y': '123'}}, {'value': {'x': 'different', 'y': 123}}),\n    ],\n    ids=('before', 'after', 'wrap'),\n)\ndef test_model_root_function_assignment(mode: str, calls1: Any, calls2: Any):\n    calls: list[Any] = []\n\n    class Model:\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n        x: str\n        y: int\n\n        def __init__(self, **kwargs: Any) -> None:\n            self.__dict__.update(kwargs)\n\n    def f(input_value: Any, *args: Any) -> Any:\n        if mode == 'wrap':\n            handler, _ = args\n            calls.append({'value': input_value})\n            return handler(input_value)\n        else:\n            calls.append({'value': input_value})\n            return input_value\n\n    v = SchemaValidator(\n        core_schema.model_schema(\n            Model,\n            {\n                'type': f'function-{mode}',\n                'function': {'type': 'with-info', 'function': f},\n                'schema': core_schema.model_fields_schema(\n                    {\n                        'x': core_schema.model_field(core_schema.str_schema()),\n                        'y': core_schema.model_field(core_schema.int_schema()),\n                    }\n                ),\n            },\n        )\n    )\n\n    m = Model()\n    v.validate_python({'x': b'input', 'y': '123'}, self_instance=m)\n    assert m.x == 'input'\n    assert m.y == 123\n    assert calls == [calls1]\n\n    v.validate_assignment(m, 'x', b'different')\n    assert calls == [calls1, calls2]\n\n\ndef test_function_validation_info_mode():\n    calls: list[str] = []\n\n    def f(v: Any, info: core_schema.ValidationInfo) -> Any:\n        calls.append(info.mode)\n        return v\n\n    v = SchemaValidator(core_schema.with_info_before_validator_function(f, core_schema.int_schema()))\n    assert v.validate_python(1) == 1\n    assert calls == ['python']\n    calls.clear()\n    assert v.validate_json('1') == 1\n    assert calls == ['json']\n    calls.clear()\n\n    v = SchemaValidator(core_schema.with_info_after_validator_function(f, core_schema.int_schema()))\n    assert v.validate_python(1) == 1\n    assert calls == ['python']\n    calls.clear()\n    assert v.validate_json('1') == 1\n    assert calls == ['json']\n    calls.clear()\n\n    def f_w(v: Any, handler: core_schema.ValidatorFunctionWrapHandler, info: core_schema.ValidationInfo) -> Any:\n        calls.append(info.mode)\n        return handler(v)\n\n    v = SchemaValidator(core_schema.with_info_wrap_validator_function(f_w, core_schema.int_schema()))\n    assert v.validate_python(1) == 1\n    assert calls == ['python']\n    calls.clear()\n    assert v.validate_json('1') == 1\n    assert calls == ['json']\n    calls.clear()\n\n\ndef test_reprs() -> None:\n    reprs: List[str] = []\n\n    def sample_repr(v: Any, info: core_schema.ValidationInfo) -> Any:\n        reprs.append(repr(info))\n        return v\n\n    v = SchemaValidator(\n        core_schema.chain_schema(\n            [\n                core_schema.with_info_plain_validator_function(sample_repr),\n                core_schema.with_info_plain_validator_function(sample_repr, field_name='x'),\n            ]\n        )\n    )\n\n    class Foo:\n        def __repr__(self) -> str:\n            return 'This is Foo!'\n\n    v.validate_python(Foo())\n\n    # insert_assert(reprs)\n    assert reprs == [\n        'ValidationInfo(config=None, context=None, data=None, field_name=None)',\n        \"ValidationInfo(config=None, context=None, data=None, field_name='x')\",\n    ]\n\n\ndef test_function_after_doesnt_change_mode() -> None:\n    # https://github.com/pydantic/pydantic/issues/7468 - function-after was\n    # incorrectly forcing Python validation mode\n\n    def identity(v):\n        return v\n\n    schema = core_schema.no_info_after_validator_function(identity, core_schema.date_schema(strict=True))\n    v = SchemaValidator(schema)\n\n    # this input should be valid JSON input, but isn't valid Python input, so\n    # the following tests will pass if the after_validator is not\n    # forcing the mode to Python\n    assert v.validate_json(b'\"2000-01-01\"') == datetime.date(2000, 1, 1)\n    with pytest.raises(ValidationError):\n        v.validate_python(b'\"2000-01-01\"')\n", "tests/validators/test_model_init.py": "import gc\nimport platform\nimport weakref\n\nimport pytest\nfrom dirty_equals import IsInstance\n\nfrom pydantic_core import CoreConfig, SchemaValidator, core_schema\n\n\nclass MyModel:\n    # this is not required, but it avoids `__pydantic_fields_set__` being included in `__dict__`\n    __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n    field_a: str\n    field_b: int\n\n\ndef test_model_init():\n    v = SchemaValidator(\n        {\n            'type': 'model',\n            'cls': MyModel,\n            'schema': {\n                'type': 'model-fields',\n                'fields': {\n                    'field_a': {'type': 'model-field', 'schema': {'type': 'str'}},\n                    'field_b': {'type': 'model-field', 'schema': {'type': 'int'}},\n                },\n            },\n        }\n    )\n    m = v.validate_python({'field_a': 'test', 'field_b': 12})\n    assert isinstance(m, MyModel)\n    assert m.field_a == 'test'\n    assert m.field_b == 12\n    assert m.__pydantic_fields_set__ == {'field_a', 'field_b'}\n\n    m2 = MyModel()\n    ans = v.validate_python({'field_a': 'test', 'field_b': 12}, self_instance=m2)\n    assert ans == m2\n    assert ans.field_a == 'test'\n    assert ans.field_b == 12\n    assert ans.__pydantic_fields_set__ == {'field_a', 'field_b'}\n\n\ndef test_model_init_nested():\n    class MyModel:\n        # this is not required, but it avoids `__pydantic_fields_set__` being included in `__dict__`\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n\n    v = SchemaValidator(\n        {\n            'type': 'model',\n            'cls': MyModel,\n            'schema': {\n                'type': 'model-fields',\n                'fields': {\n                    'field_a': {'type': 'model-field', 'schema': {'type': 'str'}},\n                    'field_b': {\n                        'type': 'model-field',\n                        'schema': {\n                            'type': 'model',\n                            'cls': MyModel,\n                            'schema': {\n                                'type': 'model-fields',\n                                'fields': {\n                                    'x_a': {'type': 'model-field', 'schema': {'type': 'str'}},\n                                    'x_b': {'type': 'model-field', 'schema': {'type': 'int'}},\n                                },\n                            },\n                        },\n                    },\n                },\n            },\n        }\n    )\n    m = v.validate_python({'field_a': 'test', 'field_b': {'x_a': 'foo', 'x_b': 12}})\n    assert isinstance(m, MyModel)\n    assert m.field_a == 'test'\n    assert isinstance(m.field_b, MyModel)\n    assert m.field_b.x_a == 'foo'\n    assert m.field_b.x_b == 12\n\n    m2 = MyModel()\n    v.validate_python({'field_a': 'test', 'field_b': {'x_a': 'foo', 'x_b': 12}}, self_instance=m2)\n    assert m2.field_a == 'test'\n    assert isinstance(m2.field_b, MyModel)\n    assert m2.field_b.x_a == 'foo'\n    assert m2.field_b.x_b == 12\n\n    assert m2.__pydantic_fields_set__ == {'field_a', 'field_b'}\n\n\ndef test_function_before():\n    def f(input_value, _info):\n        assert isinstance(input_value, dict)\n        input_value['field_a'] += b' XX'\n        return input_value\n\n    v = SchemaValidator(\n        {\n            'type': 'function-before',\n            'function': {'type': 'with-info', 'function': f},\n            'schema': {\n                'type': 'model',\n                'cls': MyModel,\n                'schema': {\n                    'type': 'model-fields',\n                    'fields': {\n                        'field_a': {'type': 'model-field', 'schema': {'type': 'str'}},\n                        'field_b': {'type': 'model-field', 'schema': {'type': 'int'}},\n                    },\n                },\n            },\n        }\n    )\n\n    m = v.validate_python({'field_a': b'321', 'field_b': '12'})\n    assert isinstance(m, MyModel)\n    assert m.field_a == '321 XX'\n    assert m.field_b == 12\n\n    m2 = MyModel()\n    v.validate_python({'field_a': b'321', 'field_b': '12'}, self_instance=m2)\n    assert m2.__dict__ == {'field_a': '321 XX', 'field_b': 12}\n    assert m2.__pydantic_fields_set__ == {'field_a', 'field_b'}\n\n\ndef test_function_after():\n    def f(input_value, _info):\n        # always a model here, because even with `self_instance` the validator returns a model, e.g. m2 here\n        assert isinstance(input_value, MyModel)\n        input_value.field_a += ' Changed'\n        return input_value\n\n    v = SchemaValidator(\n        {\n            'type': 'function-after',\n            'function': {'type': 'with-info', 'function': f},\n            'schema': {\n                'type': 'model',\n                'cls': MyModel,\n                'schema': {\n                    'type': 'model-fields',\n                    'fields': {\n                        'field_a': {'type': 'model-field', 'schema': {'type': 'str'}},\n                        'field_b': {'type': 'model-field', 'schema': {'type': 'int'}},\n                    },\n                },\n            },\n        }\n    )\n\n    m = v.validate_python({'field_a': b'321', 'field_b': '12'})\n    assert isinstance(m, MyModel)\n    assert m.field_a == '321 Changed'\n    assert m.field_b == 12\n\n    m2 = MyModel()\n    v.validate_python({'field_a': b'321', 'field_b': '12'}, self_instance=m2)\n    assert m2.__dict__ == {'field_a': '321 Changed', 'field_b': 12}\n    assert m2.__pydantic_fields_set__ == {'field_a', 'field_b'}\n\n\ndef test_function_wrap():\n    def f(input_value, handler, _info):\n        assert isinstance(input_value, dict)\n        v = handler(input_value)\n        # always a model here, because even with `self_instance` the validator returns a model, e.g. m2 here\n        assert isinstance(v, MyModel)\n        v.field_a += ' Changed'\n        return v\n\n    v = SchemaValidator(\n        {\n            'type': 'function-wrap',\n            'function': {'type': 'with-info', 'function': f},\n            'schema': {\n                'type': 'model',\n                'cls': MyModel,\n                'schema': {\n                    'type': 'model-fields',\n                    'fields': {\n                        'field_a': {'type': 'model-field', 'schema': {'type': 'str'}},\n                        'field_b': {'type': 'model-field', 'schema': {'type': 'int'}},\n                    },\n                },\n            },\n        }\n    )\n\n    m = v.validate_python({'field_a': b'321', 'field_b': '12'})\n    assert isinstance(m, MyModel)\n    assert m.field_a == '321 Changed'\n    assert m.field_b == 12\n\n    m2 = MyModel()\n    v.validate_python({'field_a': b'321', 'field_b': '12'}, self_instance=m2)\n    assert m2.__dict__ == {'field_a': '321 Changed', 'field_b': 12}\n    assert m2.__pydantic_fields_set__ == {'field_a', 'field_b'}\n\n\ndef test_simple():\n    v = SchemaValidator({'type': 'str'})\n    assert v.validate_python(b'abc') == 'abc'\n    assert v.isinstance_python(b'abc') is True\n\n    assert v.validate_python(b'abc', self_instance='foobar') == 'abc'\n    assert v.isinstance_python(b'abc', self_instance='foobar') is True\n\n    assert v.validate_json('\"abc\"') == 'abc'\n\n    assert v.validate_json('\"abc\"', self_instance='foobar') == 'abc'\n\n\ndef test_model_custom_init():\n    calls = []\n\n    class Model:\n        def __init__(self, **kwargs):\n            calls.append(repr(kwargs))\n            if 'a' in kwargs:\n                kwargs['a'] *= 2\n            self.__pydantic_validator__.validate_python(kwargs, self_instance=self)\n            self.c = self.a + 2\n\n    v = SchemaValidator(\n        core_schema.model_schema(\n            Model,\n            core_schema.model_fields_schema(\n                {\n                    'a': core_schema.model_field(core_schema.with_default_schema(core_schema.int_schema(), default=1)),\n                    'b': core_schema.model_field(core_schema.int_schema()),\n                }\n            ),\n            custom_init=True,\n        )\n    )\n    Model.__pydantic_validator__ = v\n\n    m = v.validate_python({'b': 2})\n    assert m.a == 1\n    assert m.b == 2\n    assert m.c == 3\n    assert m.__pydantic_fields_set__ == {'b'}\n    assert calls == [\"{'b': 2}\"]\n\n    m2 = v.validate_python({'a': 5, 'b': 3})\n    assert m2.a == 10\n    assert m2.b == 3\n    assert m2.c == 12\n    assert m2.__pydantic_fields_set__ == {'a', 'b'}\n    assert calls == [\"{'b': 2}\", \"{'a': 5, 'b': 3}\"]\n\n    m3 = v.validate_json('{\"a\":10, \"b\": 4}')\n    assert m3.a == 20\n    assert m3.b == 4\n    assert m3.c == 22\n    assert m3.__pydantic_fields_set__ == {'a', 'b'}\n    assert calls == [\"{'b': 2}\", \"{'a': 5, 'b': 3}\", \"{'a': 10, 'b': 4}\"]\n\n\ndef test_model_custom_init_nested():\n    calls = []\n\n    class ModelInner:\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n        a: int\n        b: int\n\n        def __init__(self, **data):\n            calls.append(f'inner: {data!r}')\n            self.__pydantic_validator__.validate_python(data, self_instance=self)\n\n    inner_schema = core_schema.model_schema(\n        ModelInner,\n        core_schema.model_fields_schema(\n            {\n                'a': core_schema.model_field(core_schema.with_default_schema(core_schema.int_schema(), default=1)),\n                'b': core_schema.model_field(core_schema.int_schema()),\n            }\n        ),\n        custom_init=True,\n    )\n    ModelInner.__pydantic_validator__ = SchemaValidator(inner_schema)\n\n    class ModelOuter:\n        __slots__ = '__dict__', '__pydantic_fields_set__'\n        a: int\n        b: ModelInner\n\n        def __init__(self, **data):\n            calls.append(f'outer: {data!r}')\n            self.__pydantic_validator__.validate_python(data, self_instance=self)\n\n    ModelOuter.__pydantic_validator__ = SchemaValidator(\n        core_schema.model_schema(\n            ModelOuter,\n            core_schema.model_fields_schema(\n                {\n                    'a': core_schema.model_field(core_schema.with_default_schema(core_schema.int_schema(), default=1)),\n                    'b': core_schema.model_field(inner_schema),\n                }\n            ),\n            custom_init=True,\n        )\n    )\n\n    m = ModelOuter(a=2, b={'b': 3})\n    assert m.__pydantic_fields_set__ == {'a', 'b'}\n    assert m.a == 2\n    assert isinstance(m.b, ModelInner)\n    assert m.b.a == 1\n    assert m.b.b == 3\n    # insert_assert(calls)\n    assert calls == [\"outer: {'a': 2, 'b': {'b': 3}}\", \"inner: {'b': 3}\"]\n\n\ndef test_model_custom_init_extra():\n    calls = []\n\n    class ModelInner:\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n        a: int\n        b: int\n\n        def __getattr__(self, item):\n            return self.__pydantic_extra__[item]\n\n        def __init__(self, **data):\n            self.__pydantic_validator__.validate_python(data, self_instance=self)\n            calls.append(('inner', self.__dict__, self.__pydantic_fields_set__, self.__pydantic_extra__))\n\n    inner_schema = core_schema.model_schema(\n        ModelInner,\n        core_schema.model_fields_schema(\n            {\n                'a': core_schema.model_field(core_schema.with_default_schema(core_schema.int_schema(), default=1)),\n                'b': core_schema.model_field(core_schema.int_schema()),\n            }\n        ),\n        config=CoreConfig(extra_fields_behavior='allow'),\n        custom_init=True,\n    )\n    ModelInner.__pydantic_validator__ = SchemaValidator(inner_schema)\n\n    class ModelOuter:\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n        a: int\n        b: ModelInner\n\n        def __getattr__(self, item):\n            return self.__pydantic_extra__[item]\n\n        def __init__(self, **data):\n            data['b']['z'] = 1\n            self.__pydantic_validator__.validate_python(data, self_instance=self)\n            calls.append(('outer', self.__dict__, self.__pydantic_fields_set__, self.__pydantic_extra__))\n\n    ModelOuter.__pydantic_validator__ = SchemaValidator(\n        core_schema.model_schema(\n            ModelOuter,\n            core_schema.model_fields_schema(\n                {\n                    'a': core_schema.model_field(core_schema.with_default_schema(core_schema.int_schema(), default=1)),\n                    'b': core_schema.model_field(inner_schema),\n                }\n            ),\n            config=CoreConfig(extra_fields_behavior='allow'),\n            custom_init=True,\n        )\n    )\n\n    m = ModelOuter(a=2, b={'b': 3}, c=1)\n    assert m.__pydantic_fields_set__ == {'a', 'b', 'c'}\n    assert m.a == 2\n    assert m.c == 1\n    assert isinstance(m.b, ModelInner)\n    assert m.b.a == 1\n    assert m.b.b == 3\n    assert m.b.z == 1\n    # insert_assert(calls)\n    assert calls == [\n        ('inner', {'a': 1, 'b': 3}, {'b', 'z'}, {'z': 1}),\n        ('outer', {'a': 2, 'b': IsInstance(ModelInner)}, {'c', 'a', 'b'}, {'c': 1}),\n    ]\n\n\ndef test_model_custom_init_revalidate():\n    calls = []\n\n    class Model:\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n\n        def __init__(self, **kwargs):\n            calls.append(repr(kwargs))\n            self.__dict__.update(kwargs)\n            self.__pydantic_fields_set__ = {'custom'}\n            self.__pydantic_extra__ = None\n\n    v = SchemaValidator(\n        core_schema.model_schema(\n            Model,\n            core_schema.model_fields_schema({'a': core_schema.model_field(core_schema.int_schema())}),\n            custom_init=True,\n            config=dict(revalidate_instances='always'),\n        )\n    )\n\n    m = v.validate_python({'a': '1'})\n    assert isinstance(m, Model)\n    assert m.a == '1'\n    assert m.__pydantic_fields_set__ == {'custom'}\n    assert calls == [\"{'a': '1'}\"]\n    m.x = 4\n\n    m2 = v.validate_python(m)\n    assert m2 is not m\n    assert isinstance(m2, Model)\n    assert m2.a == '1'\n    assert m2.__dict__ == {'a': '1', 'x': 4}\n    assert m2.__pydantic_fields_set__ == {'custom'}\n    assert calls == [\"{'a': '1'}\", \"{'a': '1', 'x': 4}\"]\n\n\n@pytest.mark.xfail(\n    condition=platform.python_implementation() == 'PyPy', reason='https://foss.heptapod.net/pypy/pypy/-/issues/3899'\n)\n@pytest.mark.parametrize('validator', [None, 'field', 'model'])\ndef test_leak_model(validator):\n    def fn():\n        class Model:\n            a: int\n\n            @classmethod\n            def _validator(cls, v, info):\n                return v\n\n            @classmethod\n            def _wrap_validator(cls, v, validator, info):\n                return validator(v)\n\n        field_schema = core_schema.int_schema()\n        if validator == 'field':\n            field_schema = core_schema.with_info_before_validator_function(\n                Model._validator, field_schema, field_name='a'\n            )\n            field_schema = core_schema.with_info_wrap_validator_function(\n                Model._wrap_validator, field_schema, field_name='a'\n            )\n            field_schema = core_schema.with_info_after_validator_function(\n                Model._validator, field_schema, field_name='a'\n            )\n\n        model_schema = core_schema.model_schema(\n            Model, core_schema.model_fields_schema({'a': core_schema.model_field(field_schema)})\n        )\n\n        if validator == 'model':\n            model_schema = core_schema.with_info_before_validator_function(Model._validator, model_schema)\n            model_schema = core_schema.with_info_wrap_validator_function(Model._wrap_validator, model_schema)\n            model_schema = core_schema.with_info_after_validator_function(Model._validator, model_schema)\n\n        # If any of the Rust validators don't implement traversal properly,\n        # there will be an undetectable cycle created by this assignment\n        # which will keep Model alive\n        Model.__pydantic_validator__ = SchemaValidator(model_schema)\n\n        return Model\n\n    klass = fn()\n    ref = weakref.ref(klass)\n    assert ref() is not None\n\n    del klass\n    gc.collect(0)\n    gc.collect(1)\n    gc.collect(2)\n    gc.collect()\n\n    assert ref() is None\n\n\ndef test_model_custom_init_with_union() -> None:\n    class A:\n        def __init__(self, **kwargs):\n            assert 'a' in kwargs\n            self.a = kwargs.get('a')\n\n    class B:\n        def __init__(self, **kwargs):\n            assert 'b' in kwargs\n            self.b = kwargs.get('b')\n\n    schema = {\n        'type': 'union',\n        'choices': [\n            {\n                'type': 'model',\n                'cls': A,\n                'schema': {\n                    'type': 'model-fields',\n                    'fields': {'a': {'type': 'model-field', 'schema': {'type': 'bool'}}},\n                    'model_name': 'A',\n                },\n                'custom_init': True,\n                'ref': '__main__.A:4947206928',\n            },\n            {\n                'type': 'model',\n                'cls': B,\n                'schema': {\n                    'type': 'model-fields',\n                    'fields': {'b': {'type': 'model-field', 'schema': {'type': 'bool'}}},\n                    'model_name': 'B',\n                },\n                'custom_init': True,\n                'ref': '__main__.B:4679932848',\n            },\n        ],\n    }\n\n    validator = SchemaValidator(schema)\n\n    assert validator.validate_python({'a': False}).a is False\n    assert validator.validate_python({'b': True}).b is True\n", "tests/validators/test_json.py": "import re\nfrom enum import Enum\n\nimport pytest\n\nfrom pydantic_core import SchemaValidator, ValidationError, core_schema\n\nfrom ..conftest import Err, PyAndJson, plain_repr\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ('{\"a\": 1}', {'a': 1}),\n        ('\"a\"', 'a'),\n        ('1', 1),\n        ('[1, 2, 3, \"4\"]', [1, 2, 3, '4']),\n        (\n            '{1: 2}',\n            Err(\n                'Invalid JSON: key must be a string at line 1 column 2 [type=json_invalid,',\n                [\n                    {\n                        'type': 'json_invalid',\n                        'loc': (),\n                        'msg': 'Invalid JSON: key must be a string at line 1 column 2',\n                        'input': '{1: 2}',\n                        'ctx': {'error': 'key must be a string at line 1 column 2'},\n                    }\n                ],\n            ),\n        ),\n        (44, Err('JSON input should be string, bytes or bytearray [type=json_type, input_value=44, input_type=int')),\n    ],\n)\ndef test_any(py_and_json: PyAndJson, input_value, expected):\n    v = py_and_json(core_schema.json_schema())\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)) as exc_info:\n            v.validate_test(input_value)\n\n        if expected.errors is not None:\n            # debug(exc_info.value.errors(include_url=False))\n            assert exc_info.value.errors(include_url=False) == expected.errors\n    else:\n        assert v.validate_test(input_value) == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        pytest.param('{\"a\": 1}', {'a': 1}, id='str'),\n        pytest.param(b'{\"a\": 1}', {'a': 1}, id='bytes'),\n        pytest.param(\n            '\ud83d\udc08 Hello \\ud800World',\n            Err(\n                'Input should be a valid string, unable to parse raw data as a unicode string '\n                \"[type=string_unicode, input_value='\ud83d\udc08 Hello \\\\ud800World', input_type=str]\"\n            ),\n            id='str_unicode',\n        ),\n        pytest.param(bytearray(b'{\"a\": 1}'), {'a': 1}, id='bytearray'),\n        pytest.param(\n            'xx',\n            Err(\n                'Invalid JSON: expected value at line 1 column 1 '\n                \"[type=json_invalid, input_value='xx', input_type=str]\"\n            ),\n            id='str_invalid',\n        ),\n        pytest.param(\n            b'xx',\n            Err(\n                'Invalid JSON: expected value at line 1 column 1 '\n                \"[type=json_invalid, input_value=b'xx', input_type=bytes]\"\n            ),\n            id='bytes_invalid',\n        ),\n        pytest.param(\n            bytearray(b'xx'),\n            Err(\n                'Invalid JSON: expected value at line 1 column 1 '\n                \"[type=json_invalid, input_value=bytearray(b'xx'), input_type=bytearray]\"\n            ),\n            id='bytearray_invalid',\n        ),\n    ],\n)\ndef test_any_python(input_value, expected):\n    v = SchemaValidator(core_schema.json_schema())\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=re.escape(expected.message)):\n            v.validate_python(input_value)\n    else:\n        assert v.validate_python(input_value) == expected\n\n\n@pytest.mark.parametrize(\n    'input_value,expected',\n    [\n        ('[1]', [1]),\n        ('[1, 2, 3, \"4\"]', [1, 2, 3, 4]),\n        ('44', Err(r'Input should be a valid (list|array) \\[type=list_type, input_value=44, input_type=int')),\n        ('\"x\"', Err(r\"Input should be a valid (list|array) \\[type=list_type, input_value='x', input_type=str\")),\n        (\n            '[1, 2, 3, \"err\"]',\n            Err(\n                r'Input should be a valid integer, unable to parse string as an integer \\[type=int_parsing,',\n                [\n                    {\n                        'type': 'int_parsing',\n                        'loc': (3,),\n                        'msg': 'Input should be a valid integer, unable to parse string as an integer',\n                        'input': 'err',\n                    }\n                ],\n            ),\n        ),\n    ],\n)\ndef test_list_int(py_and_json: PyAndJson, input_value, expected):\n    v = py_and_json(core_schema.json_schema(core_schema.list_schema(core_schema.int_schema())))\n    if isinstance(expected, Err):\n        with pytest.raises(ValidationError, match=expected.message) as exc_info:\n            v.validate_test(input_value)\n\n        if expected.errors is not None:\n            # debug(exc_info.value.errors(include_url=False))\n            assert exc_info.value.errors(include_url=False) == expected.errors\n    else:\n        assert v.validate_test(input_value) == expected\n\n\ndef test_dict_key(py_and_json: PyAndJson):\n    v = py_and_json(\n        core_schema.dict_schema(\n            core_schema.json_schema(core_schema.tuple_positional_schema([core_schema.int_schema()])),\n            core_schema.int_schema(),\n        )\n    )\n    assert v.validate_test({'[1]': 4}) == {(1,): 4}\n    with pytest.raises(ValidationError) as exc_info:\n        v.validate_test({'x': 4})\n    # insert_assert(exc_info.value.errors(include_url=False))\n    assert exc_info.value.errors(include_url=False) == [\n        {\n            'type': 'json_invalid',\n            'loc': ('x', '[key]'),\n            'msg': 'Invalid JSON: expected value at line 1 column 1',\n            'input': 'x',\n            'ctx': {'error': 'expected value at line 1 column 1'},\n        }\n    ]\n\n\ndef test_enum() -> None:\n    class MyEnum(Enum):\n        a = 'a'\n        b = 'b'\n\n    enum_schema = core_schema.lax_or_strict_schema(\n        core_schema.no_info_after_validator_function(MyEnum, core_schema.str_schema()),\n        core_schema.is_instance_schema(MyEnum),\n    )\n    v = core_schema.json_schema(enum_schema)\n    v = SchemaValidator(v)\n    assert v.validate_python('\"a\"') == MyEnum.a\n    assert v.validate_python('\"b\"') == MyEnum.b\n    with pytest.raises(ValidationError):\n        v.validate_python('\"c\"')\n\n\ndef test_any_schema_no_schema():\n    v = SchemaValidator(core_schema.json_schema())\n    assert 'validator:None' in plain_repr(v)\n    v = SchemaValidator(core_schema.json_schema(core_schema.any_schema()))\n    assert 'validator:None' in plain_repr(v)\n    v = SchemaValidator(core_schema.json_schema(core_schema.int_schema()))\n    assert 'validator:Some(' in plain_repr(v)\n", "tests/benchmarks/test_serialization_micro.py": "import json\nfrom dataclasses import dataclass\nfrom datetime import date, datetime\nfrom uuid import UUID\n\nimport pytest\n\nfrom pydantic_core import SchemaSerializer, SchemaValidator, core_schema, to_json\n\n\nclass TestBenchmarkSimpleModel:\n    @pytest.fixture(scope='class')\n    def core_schema(self):\n        class CoreModel:\n            __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n\n        return {\n            'type': 'model',\n            'cls': CoreModel,\n            'schema': {\n                'type': 'model-fields',\n                'fields': {\n                    'name': {'type': 'model-field', 'schema': {'type': 'str'}},\n                    'age': {'type': 'model-field', 'schema': {'type': 'int'}},\n                    'friends': {'type': 'model-field', 'schema': {'type': 'list', 'items_schema': {'type': 'int'}}},\n                    'settings': {\n                        'type': 'model-field',\n                        'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'float'}},\n                    },\n                },\n            },\n        }\n\n    @pytest.fixture(scope='class')\n    def core_validator(self, core_schema):\n        return SchemaValidator(core_schema)\n\n    @pytest.fixture(scope='class')\n    def core_serializer(self, core_schema):\n        return SchemaSerializer(core_schema)\n\n    data = {'name': 'John', 'age': 42, 'friends': list(range(200)), 'settings': {f'v_{i}': i / 2.0 for i in range(50)}}\n\n    @pytest.mark.benchmark(group='serialize simple model - python')\n    def test_core_dict(self, core_validator: SchemaValidator, core_serializer: SchemaSerializer, benchmark):\n        m = core_validator.validate_python(self.data)\n        assert core_serializer.to_python(m) == self.data\n        benchmark(core_serializer.to_python, m)\n\n    @pytest.mark.benchmark(group='serialize simple model - python filter')\n    def test_core_dict_filter(self, core_validator: SchemaValidator, core_serializer: SchemaSerializer, benchmark):\n        m = core_validator.validate_python(self.data)\n        exclude = {'age': ..., 'fields': {41, 42}}\n\n        @benchmark\n        def _():\n            core_serializer.to_python(m, exclude=exclude)\n\n    @pytest.mark.benchmark(group='serialize simple model - JSON')\n    def test_core_json(self, core_validator: SchemaValidator, core_serializer: SchemaSerializer, benchmark):\n        m = core_validator.validate_python(self.data)\n        assert json.loads(core_serializer.to_json(m)) == self.data\n        benchmark(core_serializer.to_json, m)\n\n\n@pytest.mark.benchmark(group='list-of-str')\ndef test_json_direct_list_str(benchmark):\n    serializer = SchemaSerializer({'type': 'list', 'items_schema': {'type': 'str'}})\n    assert serializer.to_json(list(map(str, range(5)))) == b'[\"0\",\"1\",\"2\",\"3\",\"4\"]'\n\n    items = list(map(str, range(1000)))\n    benchmark(serializer.to_json, items)\n\n\n@pytest.mark.benchmark(group='list-of-str')\ndef test_python_json_list_str(benchmark):\n    serializer = SchemaSerializer({'type': 'list', 'items_schema': {'type': 'str'}})\n    assert serializer.to_python(list(map(str, range(5))), mode='json') == ['0', '1', '2', '3', '4']\n\n    items = list(map(str, range(1000)))\n\n    @benchmark\n    def t():\n        serializer.to_python(items, mode='json')\n\n\n@pytest.mark.benchmark(group='list-of-str')\ndef test_json_any_list_str(benchmark):\n    serializer = SchemaSerializer({'type': 'list', 'items_schema': {'type': 'any'}})\n    assert serializer.to_json(list(map(str, range(5)))) == b'[\"0\",\"1\",\"2\",\"3\",\"4\"]'\n\n    items = list(map(str, range(1000)))\n    benchmark(serializer.to_json, items)\n\n\n@pytest.mark.benchmark(group='list-of-int')\ndef test_json_direct_list_int(benchmark):\n    serializer = SchemaSerializer({'type': 'list', 'items_schema': {'type': 'int'}})\n    assert serializer.to_json(list(range(5))) == b'[0,1,2,3,4]'\n\n    items = list(range(1000))\n    benchmark(serializer.to_json, items)\n\n\n@pytest.mark.benchmark(group='list-of-int')\ndef test_json_any_list_int(benchmark):\n    serializer = SchemaSerializer({'type': 'list', 'items_schema': {'type': 'any'}})\n    assert serializer.to_json(list(range(5))) == b'[0,1,2,3,4]'\n\n    items = list(range(1000))\n    benchmark(serializer.to_json, items)\n\n\n@pytest.mark.benchmark(group='list-of-int')\ndef test_python_json_list_int(benchmark):\n    serializer = SchemaSerializer({'type': 'list', 'items_schema': {'type': 'int'}})\n    assert serializer.to_python(list(range(5)), mode='json') == [0, 1, 2, 3, 4]\n\n    items = list(range(1000))\n\n    @benchmark\n    def t():\n        serializer.to_python(items, mode='json')\n\n\n@pytest.mark.benchmark(group='list-of-bool')\ndef test_python_json_list_none(benchmark):\n    serializer = SchemaSerializer({'type': 'list', 'items_schema': {'type': 'none'}})\n    assert serializer.to_python([None, None, None], mode='json') == [None, None, None]\n\n    items = [None for v in range(1000)]\n\n    @benchmark\n    def t():\n        serializer.to_python(items, mode='json')\n\n\n@pytest.mark.benchmark(group='date-format')\ndef test_date_format(benchmark):\n    serializer = SchemaSerializer(\n        {'type': 'any', 'serialization': {'type': 'format', 'formatting_string': '%Y-%m-%d', 'when_used': 'always'}}\n    )\n    d = date(2022, 11, 20)\n    assert serializer.to_python(d) == '2022-11-20'\n\n    benchmark(serializer.to_python, d)\n\n\n@pytest.mark.benchmark(group='date-format')\ndef test_date_format_function(benchmark):\n    def fmt(value, info):\n        return value.strftime('%Y-%m-%d')\n\n    serializer = SchemaSerializer(\n        core_schema.any_schema(\n            serialization=core_schema.plain_serializer_function_ser_schema(\n                fmt, info_arg=True, return_schema=core_schema.str_schema()\n            )\n        )\n    )\n    d = date(2022, 11, 20)\n    assert serializer.to_python(d) == '2022-11-20'\n\n    benchmark(serializer.to_python, d)\n\n\n@pytest.mark.benchmark(group='date-format')\ndef test_date_format_function_no_info(benchmark):\n    def fmt(value):\n        return value.strftime('%Y-%m-%d')\n\n    serializer = SchemaSerializer(\n        core_schema.any_schema(\n            serialization=core_schema.plain_serializer_function_ser_schema(fmt, return_schema=core_schema.str_schema())\n        )\n    )\n    d = date(2022, 11, 20)\n    assert serializer.to_python(d) == '2022-11-20'\n\n    benchmark(serializer.to_python, d)\n\n\nclass BasicModel:\n    def __init__(self, **kwargs):\n        for key, value in kwargs.items():\n            setattr(self, key, value)\n\n\n@pytest.fixture(scope='module', name='basic_model_serializer')\ndef basic_model_serializer_fixture():\n    return SchemaSerializer(\n        core_schema.model_schema(\n            BasicModel,\n            core_schema.model_fields_schema(\n                {\n                    'a': core_schema.model_field(core_schema.int_schema()),\n                    'b': core_schema.model_field(core_schema.int_schema()),\n                    'c': core_schema.model_field(core_schema.int_schema()),\n                    'd': core_schema.model_field(core_schema.int_schema()),\n                    'e': core_schema.model_field(core_schema.int_schema()),\n                    'f': core_schema.model_field(core_schema.int_schema()),\n                    'g': core_schema.model_field(core_schema.int_schema()),\n                    'h': core_schema.model_field(core_schema.int_schema()),\n                }\n            ),\n        )\n    )\n\n\n@pytest.mark.benchmark(group='model-python')\ndef test_core_model_py(benchmark, basic_model_serializer):\n    m = BasicModel(a=1, b=2, c=3, d=4, e=5, f=6, g=7, h=8)\n    assert basic_model_serializer.to_python(m) == {'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8}\n    benchmark(basic_model_serializer.to_python, m)\n\n\n@pytest.fixture(scope='module', name='basic_model_serializer_extra')\ndef basic_model_serializer_extra_fixture():\n    return SchemaSerializer(\n        core_schema.model_schema(\n            BasicModel,\n            core_schema.model_fields_schema(\n                {\n                    'a': core_schema.model_field(core_schema.int_schema()),\n                    'b': core_schema.model_field(core_schema.int_schema()),\n                    'c': core_schema.model_field(core_schema.int_schema()),\n                    'd': core_schema.model_field(core_schema.int_schema()),\n                    'e': core_schema.model_field(core_schema.int_schema()),\n                    'f': core_schema.model_field(core_schema.int_schema()),\n                    'g': core_schema.model_field(core_schema.int_schema()),\n                    'h': core_schema.model_field(core_schema.int_schema()),\n                },\n                extra_behavior='allow',\n            ),\n            extra_behavior='allow',\n        )\n    )\n\n\n@pytest.mark.benchmark(group='model-python')\ndef test_core_model_py_extra(benchmark, basic_model_serializer_extra):\n    m = BasicModel(a=1, b=2, c=3, d=4, e=5, f=6, g=7, h=8, __pydantic_extra__={'i': 9})\n    assert basic_model_serializer_extra.to_python(m) == {\n        'a': 1,\n        'b': 2,\n        'c': 3,\n        'd': 4,\n        'e': 5,\n        'f': 6,\n        'g': 7,\n        'h': 8,\n        'i': 9,\n    }\n    benchmark(basic_model_serializer_extra.to_python, m)\n\n\n@pytest.mark.benchmark(group='model-json')\ndef test_core_model_json(benchmark, basic_model_serializer):\n    m = BasicModel(a=1, b=2, c=3, d=4, e=5, f=6, g=7, h=8)\n    assert basic_model_serializer.to_json(m) == b'{\"a\":1,\"b\":2,\"c\":3,\"d\":4,\"e\":5,\"f\":6,\"g\":7,\"h\":8}'\n    benchmark(basic_model_serializer.to_json, m)\n\n\n@pytest.mark.benchmark(group='model-json')\ndef test_core_model_json_extra(benchmark, basic_model_serializer_extra):\n    m = BasicModel(a=1, b=2, c=3, d=4, e=5, f=6, g=7, h=8, __pydantic_extra__={'i': 9})\n    assert basic_model_serializer_extra.to_json(m) == b'{\"a\":1,\"b\":2,\"c\":3,\"d\":4,\"e\":5,\"f\":6,\"g\":7,\"h\":8,\"i\":9}'\n    benchmark(basic_model_serializer_extra.to_json, m)\n\n\nclass FieldsSetModel:\n    __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n\n    def __init__(self, **kwargs):\n        for key, value in kwargs.items():\n            setattr(self, key, value)\n\n\n@pytest.fixture(scope='module', name='fs_model_serializer')\ndef fs_model_serializer_fixture():\n    return SchemaSerializer(\n        core_schema.model_schema(\n            FieldsSetModel,\n            core_schema.model_fields_schema(\n                {\n                    'a': core_schema.model_field(core_schema.int_schema()),\n                    'b': core_schema.model_field(core_schema.int_schema()),\n                    'c': core_schema.model_field(core_schema.int_schema()),\n                    'd': core_schema.model_field(core_schema.int_schema()),\n                    'e': core_schema.model_field(core_schema.int_schema()),\n                    'f': core_schema.model_field(core_schema.int_schema()),\n                    'g': core_schema.model_field(core_schema.int_schema()),\n                    'h': core_schema.model_field(core_schema.int_schema()),\n                }\n            ),\n        )\n    )\n\n\n@pytest.mark.benchmark(group='model-exclude-unset')\ndef test_model_exclude_unset_false(benchmark, fs_model_serializer):\n    m = FieldsSetModel(a=1, b=2, c=3, d=4, e=5, f=6, g=7, h=8, __pydantic_fields_set__={'a', 'b', 'c', 'd', 'e', 'f'})\n    assert fs_model_serializer.to_python(m) == {'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8}\n    assert fs_model_serializer.to_python(m, exclude_unset=True) == {'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6}\n\n    @benchmark\n    def r():\n        fs_model_serializer.to_python(m)\n\n\n@pytest.mark.benchmark(group='model-exclude-unset')\ndef test_model_exclude_unset_true(benchmark, fs_model_serializer):\n    m = FieldsSetModel(a=1, b=2, c=3, d=4, e=5, f=6, g=7, h=8, __pydantic_fields_set__={'a', 'b', 'c', 'd', 'e', 'f'})\n    assert fs_model_serializer.to_python(m) == {'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8}\n    assert fs_model_serializer.to_python(m, exclude_unset=True) == {'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6}\n\n    @benchmark\n    def r():\n        fs_model_serializer.to_python(m, exclude_unset=True)\n\n\n@pytest.mark.benchmark(group='model-list-json')\ndef test_model_list_core_json(benchmark):\n    s = SchemaSerializer(\n        core_schema.model_schema(\n            BasicModel,\n            core_schema.model_fields_schema(\n                {\n                    'a': core_schema.model_field(\n                        core_schema.list_schema(\n                            core_schema.int_schema(), serialization=core_schema.filter_seq_schema(exclude={1, 2})\n                        )\n                    )\n                }\n            ),\n        )\n    )\n\n    m = BasicModel(a=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n    assert s.to_json(m) == b'{\"a\":[0,3,4,5,6,7,8,9]}'\n\n    m_big = BasicModel(a=list(range(1000)))\n    j = s.to_json(m_big)\n    assert j.startswith(b'{\"a\":[0,3,4')\n    assert j.endswith(b'998,999]}')\n\n    @benchmark\n    def r():\n        s.to_json(m_big)\n\n\n@pytest.mark.benchmark(group='model-list-json')\ndef test_datetime(benchmark):\n    v = SchemaSerializer(core_schema.datetime_schema())\n    d = datetime(2022, 12, 2, 12, 13, 14)\n    assert v.to_python(d, mode='json') == '2022-12-02T12:13:14'\n\n    @benchmark\n    def r():\n        v.to_python(d, mode='json')\n\n\n@pytest.mark.benchmark(group='model-list-json')\ndef test_uuid(benchmark):\n    v = SchemaSerializer(core_schema.uuid_schema())\n    u = UUID('12345678-1234-5678-1234-567812345678')\n    assert v.to_python(u, mode='json') == '12345678-1234-5678-1234-567812345678'\n\n    @benchmark\n    def r():\n        v.to_python(u, mode='json')\n\n\n@pytest.mark.benchmark(group='to-string')\ndef test_to_string_format(benchmark):\n    s = SchemaSerializer(core_schema.any_schema(serialization=core_schema.format_ser_schema('d')))\n    assert s.to_json(123) == b'\"123\"'\n\n    benchmark(s.to_json, 123)\n\n\n@pytest.mark.benchmark(group='to-string')\ndef test_to_string_direct(benchmark):\n    s = SchemaSerializer(core_schema.any_schema(serialization={'type': 'to-string'}))\n    assert s.to_json(123) == b'\"123\"'\n\n    benchmark(s.to_json, 123)\n\n\n@pytest.mark.benchmark(group='filter')\ndef test_filter(benchmark):\n    v = SchemaSerializer(core_schema.list_schema(core_schema.any_schema()))\n    assert v.to_python(['a', 'b', 'c', 'd', 'e'], include={-1, -2}) == ['d', 'e']\n\n    @benchmark\n    def t():\n        v.to_python(['a', 'b', 'c', 'd', 'e'], include={-1, -2})\n\n\n@pytest.mark.benchmark(group='list-of-lists')\ndef test_to_json_list_of_lists(benchmark):\n    data = [[i + j for j in range(10)] for i in range(1000)]\n\n    benchmark(to_json, data)\n\n\n@pytest.mark.benchmark(group='list-of-lists')\ndef test_ser_list_of_lists(benchmark):\n    s = SchemaSerializer(core_schema.list_schema(core_schema.list_schema(core_schema.int_schema())))\n    data = [[i + j for j in range(10)] for i in range(1000)]\n\n    benchmark(s.to_json, data)\n\n\n@dataclass\nclass Foo:\n    a: str\n    b: bytes\n    c: int\n    d: float\n\n\ndataclass_schema = core_schema.dataclass_schema(\n    Foo,\n    core_schema.dataclass_args_schema(\n        'Foo',\n        [\n            core_schema.dataclass_field(name='a', schema=core_schema.str_schema()),\n            core_schema.dataclass_field(name='b', schema=core_schema.bytes_schema()),\n            core_schema.dataclass_field(name='c', schema=core_schema.int_schema()),\n            core_schema.dataclass_field(name='d', schema=core_schema.float_schema()),\n        ],\n    ),\n    ['a', 'b', 'c', 'd'],\n)\n\n\n@pytest.mark.benchmark(group='dataclass-ser')\ndef test_dataclass_serialization_python(benchmark):\n    s = SchemaSerializer(dataclass_schema)\n    dc = Foo(a='hello', b=b'more', c=123, d=1.23)\n    assert s.to_python(dc) == {'a': 'hello', 'b': b'more', 'c': 123, 'd': 1.23}\n    benchmark(s.to_python, dc)\n\n\n@pytest.mark.benchmark(group='dataclass-ser')\ndef test_dataclass_serialization_json(benchmark):\n    s = SchemaSerializer(dataclass_schema)\n    dc = Foo(a='hello', b=b'more', c=123, d=1.23)\n    assert s.to_python(dc) == {'a': 'hello', 'b': b'more', 'c': 123, 'd': 1.23}\n    benchmark(s.to_json, dc)\n\n\n@pytest.mark.benchmark(group='dataclass-ser')\ndef test_dataclass_to_json(benchmark):\n    dc = Foo(a='hello', b=b'more', c=123, d=1.23)\n    benchmark(to_json, dc)\n", "tests/benchmarks/complete_schema.py": "from decimal import Decimal\n\n\ndef schema(*, strict: bool = False) -> dict:\n    class MyModel:\n        # __slots__ is not required, but it avoids __pydantic_fields_set__ falling into __dict__\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n\n    def append_func(input_value, info):\n        return f'{input_value} Changed'\n\n    def wrap_function(input_value, validator, info):\n        return f'Input {validator(input_value)} Changed'\n\n    return {\n        'type': 'model',\n        'cls': MyModel,\n        'config': {'strict': strict},\n        'schema': {\n            'type': 'model-fields',\n            'fields': {\n                'field_str': {'type': 'model-field', 'schema': {'type': 'str'}},\n                'field_str_con': {\n                    'type': 'model-field',\n                    'schema': {'type': 'str', 'min_length': 3, 'max_length': 5, 'pattern': '^[a-z]+$'},\n                },\n                'field_int': {'type': 'model-field', 'schema': {'type': 'int'}},\n                'field_int_con': {\n                    'type': 'model-field',\n                    'schema': {'type': 'int', 'gt': 1, 'lt': 10, 'multiple_of': 2},\n                },\n                'field_float': {'type': 'model-field', 'schema': {'type': 'float'}},\n                'field_float_con': {\n                    'type': 'model-field',\n                    'schema': {'type': 'float', 'ge': 1.0, 'le': 10.0, 'multiple_of': 0.5},\n                },\n                'field_decimal': {'type': 'model-field', 'schema': {'type': 'decimal'}},\n                'field_bool': {'type': 'model-field', 'schema': {'type': 'bool'}},\n                'field_bytes': {'type': 'model-field', 'schema': {'type': 'bytes'}},\n                'field_bytes_con': {\n                    'type': 'model-field',\n                    'schema': {'type': 'bytes', 'min_length': 6, 'max_length': 1000},\n                },\n                'field_date': {'type': 'model-field', 'schema': {'type': 'date'}},\n                'field_date_con': {\n                    'type': 'model-field',\n                    'schema': {'type': 'date', 'ge': '2020-01-01', 'lt': '2020-01-02'},\n                },\n                'field_time': {'type': 'model-field', 'schema': {'type': 'time'}},\n                'field_time_con': {\n                    'type': 'model-field',\n                    'schema': {'type': 'time', 'ge': '06:00:00', 'lt': '12:13:14'},\n                },\n                'field_datetime': {'type': 'model-field', 'schema': {'type': 'datetime'}},\n                'field_datetime_con': {\n                    'type': 'model-field',\n                    'schema': {'type': 'datetime', 'ge': '2000-01-01T06:00:00', 'lt': '2020-01-02T12:13:14'},\n                },\n                'field_uuid': {'type': 'model-field', 'schema': {'type': 'uuid'}},\n                'field_list_any': {'type': 'model-field', 'schema': {'type': 'list'}},\n                'field_list_str': {'type': 'model-field', 'schema': {'type': 'list', 'items_schema': {'type': 'str'}}},\n                'field_list_str_con': {\n                    'type': 'model-field',\n                    'schema': {'type': 'list', 'items_schema': {'type': 'str'}, 'min_length': 3, 'max_length': 42},\n                },\n                'field_set_any': {'type': 'model-field', 'schema': {'type': 'set'}},\n                'field_set_int': {'type': 'model-field', 'schema': {'type': 'set', 'items_schema': {'type': 'int'}}},\n                'field_set_int_con': {\n                    'type': 'model-field',\n                    'schema': {'type': 'set', 'items_schema': {'type': 'int'}, 'min_length': 3, 'max_length': 42},\n                },\n                'field_frozenset_any': {'type': 'model-field', 'schema': {'type': 'frozenset'}},\n                'field_frozenset_bytes': {\n                    'type': 'model-field',\n                    'schema': {'type': 'frozenset', 'items_schema': {'type': 'bytes'}},\n                },\n                'field_frozenset_bytes_con': {\n                    'type': 'model-field',\n                    'schema': {\n                        'type': 'frozenset',\n                        'items_schema': {'type': 'bytes'},\n                        'min_length': 3,\n                        'max_length': 42,\n                    },\n                },\n                'field_tuple_var_len_any': {\n                    'type': 'model-field',\n                    'schema': {'type': 'tuple', 'items_schema': [{'type': 'any'}], 'variadic_item_index': 0},\n                },\n                'field_tuple_var_len_float': {\n                    'type': 'model-field',\n                    'schema': {'type': 'tuple', 'items_schema': [{'type': 'float'}], 'variadic_item_index': 0},\n                },\n                'field_tuple_var_len_float_con': {\n                    'type': 'model-field',\n                    'schema': {\n                        'type': 'tuple',\n                        'items_schema': [{'type': 'float'}],\n                        'variadic_item_index': 0,\n                        'min_length': 3,\n                        'max_length': 42,\n                    },\n                },\n                'field_tuple_fix_len': {\n                    'type': 'model-field',\n                    'schema': {\n                        'type': 'tuple',\n                        'items_schema': [{'type': 'str'}, {'type': 'int'}, {'type': 'float'}, {'type': 'bool'}],\n                    },\n                },\n                'field_dict_any': {'type': 'model-field', 'schema': {'type': 'dict'}},\n                'field_dict_str_float': {\n                    'type': 'model-field',\n                    'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'float'}},\n                },\n                'field_literal_1_int': {'type': 'model-field', 'schema': {'type': 'literal', 'expected': [1]}},\n                'field_literal_1_str': {'type': 'model-field', 'schema': {'type': 'literal', 'expected': ['foobar']}},\n                'field_literal_mult_int': {'type': 'model-field', 'schema': {'type': 'literal', 'expected': [1, 2, 3]}},\n                'field_literal_mult_str': {\n                    'type': 'model-field',\n                    'schema': {'type': 'literal', 'expected': ['foo', 'bar', 'baz']},\n                },\n                'field_literal_assorted': {\n                    'type': 'model-field',\n                    'schema': {'type': 'literal', 'expected': [1, 'foo', True]},\n                },\n                'field_list_nullable_int': {\n                    'type': 'model-field',\n                    'schema': {'type': 'list', 'items_schema': {'type': 'nullable', 'schema': {'type': 'int'}}},\n                },\n                'field_union': {\n                    'type': 'model-field',\n                    'schema': {\n                        'type': 'union',\n                        'choices': [\n                            {'type': 'str'},\n                            {\n                                'type': 'typed-dict',\n                                'fields': {\n                                    'field_str': {'type': 'typed-dict-field', 'schema': {'type': 'str'}},\n                                    'field_int': {'type': 'typed-dict-field', 'schema': {'type': 'int'}},\n                                    'field_float': {'type': 'typed-dict-field', 'schema': {'type': 'float'}},\n                                },\n                            },\n                            {\n                                'type': 'typed-dict',\n                                'fields': {\n                                    'field_float': {'type': 'typed-dict-field', 'schema': {'type': 'float'}},\n                                    'field_bytes': {'type': 'typed-dict-field', 'schema': {'type': 'bytes'}},\n                                    'field_date': {'type': 'typed-dict-field', 'schema': {'type': 'date'}},\n                                },\n                            },\n                        ],\n                    },\n                },\n                'field_functions_model': {\n                    'type': 'model-field',\n                    'schema': {\n                        'type': 'typed-dict',\n                        'fields': {\n                            'field_before': {\n                                'type': 'typed-dict-field',\n                                'schema': {\n                                    'type': 'function-before',\n                                    'function': {'type': 'with-info', 'function': append_func},\n                                    'schema': {'type': 'str'},\n                                },\n                            },\n                            'field_after': {\n                                'type': 'typed-dict-field',\n                                'schema': {\n                                    'type': 'function-after',\n                                    'function': {'type': 'with-info', 'function': append_func},\n                                    'schema': {'type': 'str'},\n                                },\n                            },\n                            'field_wrap': {\n                                'type': 'typed-dict-field',\n                                'schema': {\n                                    'type': 'function-wrap',\n                                    'function': {'type': 'with-info', 'function': wrap_function},\n                                    'schema': {'type': 'str'},\n                                },\n                            },\n                            'field_plain': {\n                                'type': 'typed-dict-field',\n                                'schema': {\n                                    'type': 'function-plain',\n                                    'function': {'type': 'with-info', 'function': append_func},\n                                },\n                            },\n                        },\n                    },\n                },\n                'field_recursive': {\n                    'type': 'model-field',\n                    'schema': {\n                        'type': 'definitions',\n                        'schema': {'type': 'definition-ref', 'schema_ref': 'Branch'},\n                        'definitions': [\n                            {\n                                'type': 'typed-dict',\n                                'fields': {\n                                    'name': {'type': 'typed-dict-field', 'schema': {'type': 'str'}},\n                                    'sub_branch': {\n                                        'type': 'typed-dict-field',\n                                        'schema': {\n                                            'type': 'default',\n                                            'schema': {\n                                                'type': 'nullable',\n                                                'schema': {'type': 'definition-ref', 'schema_ref': 'Branch'},\n                                            },\n                                            'default': None,\n                                        },\n                                    },\n                                },\n                                'ref': 'Branch',\n                            }\n                        ],\n                    },\n                },\n            },\n        },\n    }\n\n\ndef input_data_lax():\n    return {\n        'field_str': 'fo',\n        'field_str_con': 'fooba',\n        'field_int': 1,\n        'field_int_con': 8,\n        'field_float': 1.0,\n        'field_float_con': 10.0,\n        'field_decimal': 42.0,\n        'field_bool': True,\n        'field_bytes': b'foobar',\n        'field_bytes_con': b'foobar',\n        'field_date': '2010-02-03',\n        'field_date_con': '2020-01-01',\n        'field_time': '12:00:00',\n        'field_time_con': '12:00:00',\n        'field_datetime': '2020-01-01T12:13:14',\n        'field_datetime_con': '2020-01-01T00:00:00',\n        'field_uuid': '12345678-1234-5678-1234-567812345678',\n        'field_list_any': ['a', b'b', True, 1.0, None] * 10,\n        'field_list_str': ['a', 'b', 'c'] * 10,\n        'field_list_str_con': ['a', 'b', 'c'] * 10,\n        'field_set_any': {'a', b'b', True, 1.0, None},\n        'field_set_int': set(range(100)),\n        'field_set_int_con': set(range(42)),\n        'field_frozenset_any': frozenset({'a', b'b', True, 1.0, None}),\n        'field_frozenset_bytes': frozenset([f'{i}'.encode() for i in range(100)]),\n        'field_frozenset_bytes_con': frozenset([f'{i}'.encode() for i in range(42)]),\n        'field_tuple_var_len_any': ('a', b'b', True, 1.0, None),\n        'field_tuple_var_len_float': tuple(i + 0.5 for i in range(100)),\n        'field_tuple_var_len_float_con': tuple(i + 0.5 for i in range(42)),\n        'field_tuple_fix_len': ('a', 1, 1.0, True),\n        'field_dict_any': {'a': 'b', 1: True, 1.0: 1.0},\n        'field_dict_str_float': {f'{i}': i + 0.5 for i in range(100)},\n        'field_literal_1_int': 1,\n        'field_literal_1_str': 'foobar',\n        'field_literal_mult_int': 3,\n        'field_literal_mult_str': 'foo',\n        'field_literal_assorted': 'foo',\n        'field_list_nullable_int': [1, None, 2, None, 3, None, 4, None],\n        'field_union': {'field_str': 'foo', 'field_int': 1, 'field_float': 1.0},\n        'field_functions_model': {\n            'field_before': 'foo',\n            'field_after': 'foo',\n            'field_wrap': 'foo',\n            'field_plain': 'foo',\n        },\n        'field_recursive': {\n            'name': 'foo',\n            'sub_branch': {'name': 'bar', 'sub_branch': {'name': 'baz', 'sub_branch': None}},\n        },\n    }\n\n\ndef input_data_strict():\n    from datetime import date, datetime, time\n    from uuid import UUID\n\n    input_data = input_data_lax()\n    input_data.update(\n        field_date=date(2010, 2, 3),\n        field_date_con=date(2020, 1, 1),\n        field_time=time(12, 0, 0),\n        field_time_con=time(12, 0, 0),\n        field_datetime=datetime(2020, 1, 1, 12, 13, 14),\n        field_datetime_con=datetime(2020, 1, 1),\n        field_uuid=UUID('12345678-1234-5678-1234-567812345678'),\n        field_decimal=Decimal('42.0'),\n    )\n    return input_data\n\n\ndef input_data_wrong():\n    return {\n        'field_str': ['fo'],\n        'field_str_con': 'f',\n        'field_int': 1.5,\n        'field_int_con': 11,\n        'field_float': False,\n        'field_float_con': 10.1,\n        'field_decimal': 'wrong',\n        'field_bool': 4,\n        'field_bytes': 42,\n        'field_bytes_con': b'foo',\n        'field_date': 'wrong',\n        'field_date_con': '2000-01-01',\n        'field_time': 'boom',\n        'field_time_con': '23:00:00',\n        'field_datetime': b'smash',\n        'field_datetime_con': '1900-01-01T00:00:00',\n        'field_uuid': '12345678-1234-5678-1234-567812345678',\n        'field_list_any': {1: 2, 3: 4},\n        'field_list_str': [(i,) for i in range(100)],\n        'field_list_str_con': ['a', 'b'],\n        'field_set_any': {'a': b'b', True: 1.0, None: 5},\n        'field_set_int': {f'x{i}' for i in range(100)},\n        'field_set_int_con': {i for i in range(40)},\n        'field_frozenset_any': 'wrong',\n        'field_frozenset_bytes': frozenset([i for i in range(100)]),\n        'field_frozenset_bytes_con': frozenset({b'a', b'b'}),\n        'field_tuple_var_len_any': b'wrong',\n        'field_tuple_var_len_float': tuple(f'x{i}' for i in range(100)),\n        'field_tuple_var_len_float_con': (1.0, 2.0),\n        'field_tuple_fix_len': ('a', 1, 1.0, True, 'more'),\n        'field_dict_any': {'a', 'b', 1, True, 1.0, 2.0},\n        'field_dict_str_float': {(i,): f'x{i}' for i in range(100)},\n        'field_literal_1_int': 2,\n        'field_literal_1_str': 'bat',\n        'field_literal_mult_int': 42,\n        'field_literal_mult_str': 'wrong',\n        'field_literal_assorted': 'wrong',\n        'field_list_nullable_int': [f'x{i}' for i in range(100)],\n        'field_union': {'field_str': ('foo',), 'field_int': 'x', 'field_float': b'y'},\n        'field_functions_model': {'field_before': 1, 'field_after': 1, 'field_wrap': 1, 'field_plain': 1},\n        'field_recursive': {'name': 'foo', 'sub_branch': {'name': 'bar', 'sub_branch': {}}},\n    }\n", "tests/benchmarks/test_complete_benchmark.py": "\"\"\"\nGeneral benchmarks that attempt to cover all field types, through by no means all uses of all field types.\n\"\"\"\n\nimport json\nfrom datetime import date, datetime, time\nfrom decimal import Decimal\nfrom uuid import UUID\n\nimport pytest\n\nfrom pydantic_core import SchemaSerializer, SchemaValidator, ValidationError, validate_core_schema\n\nfrom .complete_schema import input_data_lax, input_data_strict, input_data_wrong, schema\n\n\ndef test_complete_valid():\n    lax_schema = schema()\n    cls = lax_schema['cls']\n    lax_validator = SchemaValidator(validate_core_schema(lax_schema))\n    output = lax_validator.validate_python(input_data_lax())\n    assert isinstance(output, cls)\n    assert len(output.__pydantic_fields_set__) == 41\n    output_dict = output.__dict__\n    assert output_dict == {\n        'field_str': 'fo',\n        'field_str_con': 'fooba',\n        'field_int': 1,\n        'field_int_con': 8,\n        'field_float': 1.0,\n        'field_float_con': 10.0,\n        'field_decimal': Decimal('42.0'),\n        'field_bool': True,\n        'field_bytes': b'foobar',\n        'field_bytes_con': b'foobar',\n        'field_date': date(2010, 2, 3),\n        'field_date_con': date(2020, 1, 1),\n        'field_time': time(12, 0),\n        'field_time_con': time(12, 0),\n        'field_datetime': datetime(2020, 1, 1, 12, 13, 14),\n        'field_datetime_con': datetime(2020, 1, 1),\n        'field_uuid': UUID('12345678-1234-5678-1234-567812345678'),\n        'field_list_any': ['a', b'b', True, 1.0, None] * 10,\n        'field_list_str': ['a', 'b', 'c'] * 10,\n        'field_list_str_con': ['a', 'b', 'c'] * 10,\n        'field_set_any': {'a', b'b', True, 1.0, None},\n        'field_set_int': set(range(100)),\n        'field_set_int_con': set(range(42)),\n        'field_frozenset_any': frozenset({'a', b'b', True, 1.0, None}),\n        'field_frozenset_bytes': frozenset([f'{i}'.encode() for i in range(100)]),\n        'field_frozenset_bytes_con': frozenset([f'{i}'.encode() for i in range(42)]),\n        'field_tuple_var_len_any': ('a', b'b', True, 1.0, None),\n        'field_tuple_var_len_float': tuple(i + 0.5 for i in range(100)),\n        'field_tuple_var_len_float_con': tuple(i + 0.5 for i in range(42)),\n        'field_tuple_fix_len': ('a', 1, 1.0, True),\n        'field_dict_any': {'a': 'b', 1: True, 1.0: 1.0},\n        'field_dict_str_float': {f'{i}': i + 0.5 for i in range(100)},\n        'field_literal_1_int': 1,\n        'field_literal_1_str': 'foobar',\n        'field_literal_mult_int': 3,\n        'field_literal_mult_str': 'foo',\n        'field_literal_assorted': 'foo',\n        'field_list_nullable_int': [1, None, 2, None, 3, None, 4, None],\n        'field_union': {'field_str': 'foo', 'field_int': 1, 'field_float': 1.0},\n        'field_functions_model': {\n            'field_before': 'foo Changed',\n            'field_after': 'foo Changed',\n            'field_wrap': 'Input foo Changed',\n            'field_plain': 'foo Changed',\n        },\n        'field_recursive': {\n            'name': 'foo',\n            'sub_branch': {'name': 'bar', 'sub_branch': {'name': 'baz', 'sub_branch': None}},\n        },\n    }\n\n    strict_validator = SchemaValidator(validate_core_schema(schema(strict=True)))\n    output2 = strict_validator.validate_python(input_data_strict())\n    assert output_dict == output2.__dict__\n\n\ndef test_complete_invalid():\n    lax_schema = schema()\n    lax_validator = SchemaValidator(validate_core_schema(lax_schema))\n    with pytest.raises(ValidationError) as exc_info:\n        lax_validator.validate_python(input_data_wrong())\n    assert len(exc_info.value.errors(include_url=False)) == 739\n\n\n@pytest.mark.benchmark(group='complete')\ndef test_complete_core_lax(benchmark):\n    v = SchemaValidator(validate_core_schema(schema()))\n    benchmark(v.validate_python, input_data_lax())\n\n\n@pytest.mark.benchmark(group='complete')\ndef test_complete_core_strict(benchmark):\n    v = SchemaValidator(validate_core_schema(schema(strict=True)))\n    benchmark(v.validate_python, input_data_strict())\n\n\n@pytest.mark.benchmark(group='complete-to-python')\ndef test_complete_core_serializer_to_python(benchmark):\n    core_schema = validate_core_schema(schema())\n    v = SchemaValidator(core_schema)\n    model = v.validate_python(input_data_lax())\n    serializer = SchemaSerializer(core_schema)\n    assert serializer.to_python(model) == model.__dict__\n    benchmark(serializer.to_python, model)\n\n\n@pytest.mark.benchmark(group='complete-to-json')\ndef test_complete_core_serializer_to_json(benchmark):\n    core_schema = validate_core_schema(schema())\n    v = SchemaValidator(core_schema)\n    model = v.validate_python(input_data_lax())\n    serializer = SchemaSerializer(core_schema)\n    benchmark(serializer.to_json, model)\n\n\n@pytest.mark.benchmark(group='complete-wrong')\ndef test_complete_core_error(benchmark):\n    v = SchemaValidator(validate_core_schema(schema()))\n    data = input_data_wrong()\n\n    @benchmark\n    def f():\n        try:\n            v.validate_python(data)\n        except ValueError:\n            pass\n        else:\n            raise RuntimeError('expected ValueError')\n\n\n@pytest.mark.benchmark(group='complete-wrong')\ndef test_complete_core_isinstance(benchmark):\n    v = SchemaValidator(validate_core_schema(schema()))\n    data = input_data_wrong()\n    assert v.isinstance_python(data) is False\n\n    @benchmark\n    def f():\n        v.isinstance_python(data)\n\n\ndef default_json_encoder(obj):\n    if isinstance(obj, bytes):\n        return obj.decode('utf-8')\n    if isinstance(obj, (set, frozenset)):\n        return list(obj)\n    else:\n        raise TypeError(f'Object of type {type(obj)} is not JSON serializable')\n\n\n@pytest.mark.benchmark(group='complete-json')\ndef test_complete_core_json(benchmark):\n    v = SchemaValidator(validate_core_schema(schema()))\n    json_data = json.dumps(input_data_lax(), default=default_json_encoder)\n    benchmark(v.validate_json, json_data)\n\n\n@pytest.mark.benchmark(group='build')\ndef test_build_schema(benchmark):\n    lax_schema = schema()\n    benchmark(lambda s: SchemaValidator(validate_core_schema(s)), lax_schema)\n", "tests/benchmarks/test_nested_benchmark.py": "\"\"\"\nBenchmarks for nested / recursive schemas using definitions.\n\"\"\"\n\nfrom typing import Callable\n\nfrom pydantic_core import SchemaValidator\n\nfrom .nested_schema import inlined_schema, input_data_valid, schema_using_defs\n\n\ndef test_nested_schema_using_defs(benchmark: Callable[..., None]) -> None:\n    v = SchemaValidator(schema_using_defs())\n    data = input_data_valid()\n    v.validate_python(data)\n    benchmark(v.validate_python, data)\n\n\ndef test_nested_schema_inlined(benchmark: Callable[..., None]) -> None:\n    v = SchemaValidator(inlined_schema())\n    data = input_data_valid()\n    v.validate_python(data)\n    benchmark(v.validate_python, data)\n", "tests/benchmarks/nested_schema.py": "from __future__ import annotations\n\nfrom typing import TYPE_CHECKING, Any\n\nif TYPE_CHECKING:\n    from pydantic_core import core_schema as cs\n\nN = 5  # arbitrary number that takes ~0.05s per run\n\n\nclass MyModel:\n    # __slots__ is not required, but it avoids __pydantic_fields_set__ falling into __dict__\n    __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n\n\ndef schema_using_defs() -> cs.CoreSchema:\n    definitions: list[cs.CoreSchema] = [\n        {'type': 'int', 'ref': 'int'},\n        {\n            'type': 'model',\n            'cls': MyModel,\n            'schema': {\n                'type': 'model-fields',\n                'fields': {\n                    str(c): {'type': 'model-field', 'schema': {'type': 'definition-ref', 'schema_ref': 'int'}}\n                    for c in range(N)\n                },\n            },\n            'ref': f'model_{N}',\n        },\n    ]\n    level = N\n    for level in reversed(range(N)):\n        definitions.append(\n            {\n                'type': 'model',\n                'cls': MyModel,\n                'schema': {\n                    'type': 'model-fields',\n                    'fields': {\n                        str(c): {\n                            'type': 'model-field',\n                            'schema': {'type': 'definition-ref', 'schema_ref': f'model_{level+1}'},\n                        }\n                        for c in range(N)\n                    },\n                },\n                'ref': f'model_{level}',\n            }\n        )\n    return {\n        'type': 'definitions',\n        'definitions': definitions,\n        'schema': {'type': 'definition-ref', 'schema_ref': 'model_0'},\n    }\n\n\ndef inlined_schema() -> cs.CoreSchema:\n    level = N\n    schema: cs.CoreSchema = {\n        'type': 'model',\n        'cls': MyModel,\n        'schema': {\n            'type': 'model-fields',\n            'fields': {str(c): {'type': 'model-field', 'schema': {'type': 'int'}} for c in range(N)},\n        },\n        'ref': f'model_{N}',\n    }\n    for level in reversed(range(N)):\n        schema = {\n            'type': 'model',\n            'cls': MyModel,\n            'schema': {\n                'type': 'model-fields',\n                'fields': {str(c): {'type': 'model-field', 'schema': schema} for c in range(N)},\n            },\n            'ref': f'model_{level}',\n        }\n    return schema\n\n\ndef input_data_valid(levels: int = N) -> Any:\n    data = {str(c): 1 for c in range(N)}\n    for _ in range(levels):\n        data = {str(c): data for c in range(N)}\n    return data\n\n\nif __name__ == '__main__':\n    from pydantic_core import SchemaValidator\n\n    SchemaValidator(schema_using_defs()).validate_python(input_data_valid())\n    SchemaValidator(inlined_schema()).validate_python(input_data_valid())\n", "tests/benchmarks/test_micro_benchmarks.py": "\"\"\"\nNumerous benchmarks of specific functionality.\n\"\"\"\n\nimport decimal\nimport json\nimport platform\nimport sys\nfrom datetime import date, datetime, timedelta, timezone\nfrom decimal import Decimal\nfrom enum import Enum\nfrom typing import Any, List\nfrom uuid import UUID\n\nimport pytest\nfrom dirty_equals import IsStr\n\nimport pydantic_core\nfrom pydantic_core import (\n    ArgsKwargs,\n    PydanticCustomError,\n    PydanticKnownError,\n    SchemaValidator,\n    ValidationError,\n    core_schema,\n)\nfrom pydantic_core import ValidationError as CoreValidationError\n\nskip_pypy_deep_stack = pytest.mark.skipif(\n    platform.python_implementation() == 'PyPy' and pydantic_core._pydantic_core.build_profile == 'debug',\n    reason='PyPy does not have enough stack space for Rust debug builds to recurse very deep',\n)\n\nskip_wasm_deep_stack = pytest.mark.skipif(\n    sys.platform == 'emscripten', reason='wasm does not have enough stack space to recurse very deep'\n)\n\n\nclass TestBenchmarkSimpleModel:\n    @pytest.fixture(scope='class')\n    def core_validator_fs(self):\n        class CoreModel:\n            __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n\n        return SchemaValidator(\n            {\n                'type': 'model',\n                'cls': CoreModel,\n                'schema': {\n                    'type': 'model-fields',\n                    'fields': {\n                        'name': {'type': 'model-field', 'schema': {'type': 'str'}},\n                        'age': {'type': 'model-field', 'schema': {'type': 'int'}},\n                        'friends': {'type': 'model-field', 'schema': {'type': 'list', 'items_schema': {'type': 'int'}}},\n                        'settings': {\n                            'type': 'model-field',\n                            'schema': {\n                                'type': 'dict',\n                                'keys_schema': {'type': 'str'},\n                                'values_schema': {'type': 'float'},\n                            },\n                        },\n                    },\n                },\n            }\n        )\n\n    data = {'name': 'John', 'age': 42, 'friends': list(range(200)), 'settings': {f'v_{i}': i / 2.0 for i in range(50)}}\n\n    @pytest.mark.benchmark(group='simple model - python')\n    def test_core_python_fs(self, core_validator_fs, benchmark):\n        m = core_validator_fs.validate_python(self.data)\n        assert m.name == 'John'\n        assert m.__dict__.keys() == {'name', 'age', 'friends', 'settings'}\n        assert m.__pydantic_fields_set__ == {'name', 'age', 'friends', 'settings'}\n        benchmark(core_validator_fs.validate_python, self.data)\n\n    @pytest.mark.benchmark(group='simple model - JSON')\n    def test_core_json_fs(self, core_validator_fs, benchmark):\n        json_data = json.dumps(self.data)\n        benchmark(core_validator_fs.validate_json, json_data)\n\n\nclass TestModelLarge:\n    @pytest.fixture(scope='class')\n    def core_model_validator(self):\n        class CoreModel:\n            __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n\n        return SchemaValidator(\n            {\n                'type': 'model',\n                'cls': CoreModel,\n                'schema': {\n                    'type': 'model-fields',\n                    'extra_behavior': 'allow',\n                    'fields': {f'field_{i}': {'type': 'model-field', 'schema': {'type': 'int'}} for i in range(100)},\n                },\n            }\n        )\n\n    data = {f'field_{99 - i}': i for i in range(100)}\n    data['more'] = 'more data'\n\n    @pytest.mark.benchmark(group='large model - python')\n    def test_core_python(self, core_model_validator, benchmark):\n        m = core_model_validator.validate_python(self.data)\n        assert m.field_0 == 99\n        assert m.field_1 == 98\n        assert m.field_97 == 2\n        assert m.__pydantic_extra__ == {'more': 'more data'}\n        benchmark(core_model_validator.validate_python, self.data)\n\n    @pytest.mark.benchmark(group='large model - JSON')\n    def test_core_json_fs(self, core_model_validator, benchmark):\n        json_data = json.dumps(self.data)\n        m = core_model_validator.validate_json(json_data)\n        assert m.field_0 == 99\n        assert m.field_1 == 98\n        assert m.field_97 == 2\n        assert m.__pydantic_extra__ == {'more': 'more data'}\n        benchmark(core_model_validator.validate_json, json_data)\n\n\nbool_cases = [True, False, 0, 1, '0', '1', 'true', 'false', 'True', 'False']\n\n\n@pytest.mark.benchmark(group='bool')\ndef test_bool_core(benchmark):\n    schema_validator = SchemaValidator({'type': 'bool'})\n\n    @benchmark\n    def t():\n        for case in bool_cases:\n            schema_validator.validate_python(case)\n\n\nsmall_class_data = {'name': 'John', 'age': 42}\n\n\n@pytest.mark.benchmark(group='create small model')\ndef test_small_class_core_dict(benchmark):\n    model_schema = {\n        'type': 'typed-dict',\n        'fields': {\n            'name': {'type': 'typed-dict-field', 'schema': {'type': 'str'}},\n            'age': {'type': 'typed-dict-field', 'schema': {'type': 'int'}},\n        },\n    }\n    dict_schema_validator = SchemaValidator(model_schema)\n    benchmark(dict_schema_validator.validate_python, small_class_data)\n\n\n@pytest.mark.benchmark(group='create small model')\ndef test_small_class_core_model(benchmark):\n    class MyCoreModel:\n        # this is not required, but it avoids `__pydantic_fields_set__` being included in `__dict__`\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n        # these are here just as decoration\n        name: str\n        age: int\n\n    model_schema_validator = SchemaValidator(\n        {\n            'type': 'model',\n            'cls': MyCoreModel,\n            'schema': {\n                'type': 'model-fields',\n                'fields': {\n                    'name': {'type': 'model-field', 'schema': {'type': 'str'}},\n                    'age': {'type': 'model-field', 'schema': {'type': 'int'}},\n                },\n            },\n        }\n    )\n    benchmark(model_schema_validator.validate_python, small_class_data)\n\n\n@pytest.mark.benchmark(group='string')\ndef test_core_string_lax(benchmark):\n    validator = SchemaValidator(core_schema.str_schema())\n    input_str = 'Hello ' * 20\n\n    assert validator.validate_python(input_str) == input_str\n\n    benchmark(validator.validate_python, input_str)\n\n\n@pytest.mark.benchmark(group='string')\ndef test_core_string_lax_wrong(benchmark):\n    validator = SchemaValidator(core_schema.str_schema())\n\n    with pytest.raises(ValidationError, match='Input should be a valid string'):\n        validator.validate_python(123)\n\n    @benchmark\n    def t():\n        try:\n            validator.validate_python(123)\n        except ValidationError:\n            pass\n\n\n@pytest.mark.benchmark(group='string')\ndef test_core_string_strict(benchmark):\n    validator = SchemaValidator(core_schema.str_schema(strict=True))\n    input_str = 'Hello ' * 20\n\n    assert validator.validate_python(input_str) == input_str\n\n    benchmark(validator.validate_python, input_str)\n\n\n@pytest.mark.benchmark(group='string')\ndef test_core_string_strict_wrong(benchmark):\n    validator = SchemaValidator(core_schema.str_schema(strict=True))\n\n    with pytest.raises(ValidationError, match='Input should be a valid string'):\n        validator.validate_python(123)\n\n    @benchmark\n    def t():\n        try:\n            validator.validate_python(123)\n        except ValidationError:\n            pass\n\n\n@pytest.mark.benchmark(group='string')\ndef test_core_string_strict_wrong_str_e(benchmark):\n    validator = SchemaValidator(core_schema.str_schema(strict=True))\n\n    with pytest.raises(ValidationError, match='Input should be a valid string'):\n        validator.validate_python(123)\n\n    @benchmark\n    def t():\n        try:\n            validator.validate_python(123)\n        except ValidationError as e:\n            str(e)\n\n\n@pytest.mark.benchmark(group='isinstance-string')\ndef test_isinstance_string_lax_true(benchmark):\n    validator = SchemaValidator(core_schema.str_schema())\n    input_str = 'Hello ' * 20\n\n    assert validator.isinstance_python(input_str) is True\n\n    benchmark(validator.isinstance_python, input_str)\n\n\n@pytest.mark.benchmark(group='isinstance-string')\ndef test_isinstance_string_lax_false(benchmark):\n    validator = SchemaValidator(core_schema.str_schema())\n\n    assert validator.isinstance_python(123) is False\n\n    benchmark(validator.isinstance_python, 123)\n\n\n@pytest.mark.benchmark(group='isinstance-string')\ndef test_isinstance_string_strict_true(benchmark):\n    validator = SchemaValidator(core_schema.str_schema(strict=True))\n    input_str = 'Hello ' * 20\n\n    assert validator.isinstance_python(input_str) is True\n\n    benchmark(validator.isinstance_python, input_str)\n\n\n@pytest.mark.benchmark(group='isinstance-string')\ndef test_isinstance_string_strict_false(benchmark):\n    validator = SchemaValidator(core_schema.str_schema(strict=True))\n\n    assert validator.isinstance_python(123) is False\n\n    benchmark(validator.isinstance_python, 123)\n\n\n@pytest.fixture\ndef definition_model_data():\n    data = {'width': -1}\n\n    _data = data\n    for i in range(pydantic_core._pydantic_core._recursion_limit - 2):\n        _data['branch'] = {'width': i}\n        _data = _data['branch']\n    return data\n\n\n@skip_pypy_deep_stack\n@skip_wasm_deep_stack\n@pytest.mark.benchmark(group='recursive model')\ndef test_definition_model_core(definition_model_data, benchmark):\n    class CoreBranch:\n        # this is not required, but it avoids `__pydantic_fields_set__` being included in `__dict__`\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n\n    v = SchemaValidator(\n        core_schema.definitions_schema(\n            core_schema.definition_reference_schema(schema_ref='Branch'),\n            [\n                core_schema.model_schema(\n                    CoreBranch,\n                    core_schema.model_fields_schema(\n                        {\n                            'width': core_schema.model_field(core_schema.int_schema()),\n                            'branch': core_schema.model_field(\n                                core_schema.with_default_schema(\n                                    core_schema.nullable_schema(\n                                        core_schema.definition_reference_schema(schema_ref='Branch')\n                                    ),\n                                    default=None,\n                                )\n                            ),\n                        }\n                    ),\n                    ref='Branch',\n                )\n            ],\n        )\n    )\n    benchmark(v.validate_python, definition_model_data)\n\n\n@pytest.mark.benchmark(group='List[TypedDict]')\ndef test_list_of_dict_models_core(benchmark):\n    v = SchemaValidator(\n        {\n            'type': 'list',\n            'items_schema': {\n                'type': 'typed-dict',\n                'fields': {'width': {'type': 'typed-dict-field', 'schema': {'type': 'int'}}},\n            },\n        }\n    )\n\n    data = [{'width': i} for i in range(100)]\n    benchmark(v.validate_python, data)\n\n\nlist_of_ints_data = ([i for i in range(1000)], [str(i) for i in range(1000)])\n\n\n@pytest.mark.benchmark(group='List[int]')\ndef test_list_of_ints_core_py(benchmark):\n    v = SchemaValidator({'type': 'list', 'items_schema': {'type': 'int'}})\n\n    @benchmark\n    def t():\n        v.validate_python(list_of_ints_data[0])\n        v.validate_python(list_of_ints_data[1])\n\n\n@pytest.mark.benchmark(group='List[int] JSON')\ndef test_list_of_ints_core_json(benchmark):\n    v = SchemaValidator({'type': 'list', 'items_schema': {'type': 'int'}})\n\n    json_data = [json.dumps(d) for d in list_of_ints_data]\n\n    @benchmark\n    def t():\n        v.validate_json(json_data[0])\n        v.validate_json(json_data[1])\n\n\nlist_of_strs_data = [str(i) for i in range(1000)]\n\n\n@pytest.mark.benchmark(group='list[str]')\ndef test_list_of_strs_py_cached(benchmark):\n    v = SchemaValidator(core_schema.list_schema(core_schema.str_schema()))\n\n    benchmark(v.validate_python, list_of_strs_data)\n\n\n@pytest.mark.benchmark(group='list[str]')\ndef test_list_of_strs_json_cached(benchmark):\n    v = SchemaValidator(core_schema.list_schema(core_schema.str_schema()))\n\n    json_data = json.dumps(list_of_strs_data)\n    benchmark(v.validate_json, json_data)\n\n\n@pytest.mark.benchmark(group='list[str]')\ndef test_list_of_strs_json_uncached(benchmark):\n    v = SchemaValidator(core_schema.list_schema(core_schema.str_schema()), {'cache_strings': False})\n\n    json_data = json.dumps(list_of_strs_data)\n    benchmark(v.validate_json, json_data)\n\n\n@pytest.mark.benchmark(group='List[Any]')\ndef test_list_of_any_core_py(benchmark):\n    v = SchemaValidator({'type': 'list'})\n\n    @benchmark\n    def t():\n        v.validate_python(list_of_ints_data[0])\n        v.validate_python(list_of_ints_data[1])\n\n\nset_of_ints_data = ({i for i in range(1000)}, {str(i) for i in range(1000)})\nset_of_ints_duplicates = ([i for i in range(100)] * 10, [str(i) for i in range(100)] * 10)\n\n\n@pytest.mark.benchmark(group='Set[int]')\ndef test_set_of_ints_core(benchmark):\n    v = SchemaValidator({'type': 'set', 'items_schema': {'type': 'int'}})\n\n    @benchmark\n    def t():\n        v.validate_python(set_of_ints_data[0])\n        v.validate_python(set_of_ints_data[1])\n\n\n@pytest.mark.benchmark(group='Set[int]')\ndef test_set_of_ints_core_duplicates(benchmark):\n    v = SchemaValidator({'type': 'set', 'items_schema': {'type': 'int'}})\n\n    @benchmark\n    def t():\n        v.validate_python(set_of_ints_duplicates[0])\n        v.validate_python(set_of_ints_duplicates[1])\n\n\n@pytest.mark.benchmark(group='Set[int]')\ndef test_set_of_ints_core_length(benchmark):\n    v = SchemaValidator({'type': 'set', 'items_schema': {'type': 'int'}, 'max_length': 2000})\n\n    @benchmark\n    def t():\n        v.validate_python(set_of_ints_data[0])\n        v.validate_python(set_of_ints_data[1])\n\n\n@pytest.mark.benchmark(group='Set[int] JSON')\ndef test_set_of_ints_core_json(benchmark):\n    v = SchemaValidator({'type': 'set', 'items_schema': {'type': 'int'}})\n\n    json_data = [json.dumps(list(d)) for d in set_of_ints_data]\n\n    @benchmark\n    def t():\n        v.validate_json(json_data[0])\n        v.validate_json(json_data[1])\n\n\n@pytest.mark.benchmark(group='Set[int] JSON')\ndef test_set_of_ints_core_json_duplicates(benchmark):\n    v = SchemaValidator({'type': 'set', 'items_schema': {'type': 'int'}})\n\n    json_data = [json.dumps(list(d)) for d in set_of_ints_duplicates]\n\n    @benchmark\n    def t():\n        v.validate_json(json_data[0])\n        v.validate_json(json_data[1])\n\n\nfrozenset_of_ints = frozenset({i for i in range(1000)})\nfrozenset_of_ints_duplicates = [i for i in range(100)] * 10\n\n\n@pytest.mark.benchmark(group='FrozenSet[int]')\ndef test_frozenset_of_ints_core(benchmark):\n    v = SchemaValidator({'type': 'frozenset', 'items_schema': {'type': 'int'}})\n\n    benchmark(v.validate_python, frozenset_of_ints)\n\n\n@pytest.mark.benchmark(group='FrozenSet[int]')\ndef test_frozenset_of_ints_duplicates_core(benchmark):\n    v = SchemaValidator({'type': 'frozenset', 'items_schema': {'type': 'int'}})\n\n    benchmark(v.validate_python, frozenset_of_ints_duplicates)\n\n\ndict_of_ints_data = ({str(i): i for i in range(1000)}, {str(i): str(i) for i in range(1000)})\n\n\n@pytest.mark.benchmark(group='Dict[str, int]')\ndef test_dict_of_ints_core(benchmark):\n    v = SchemaValidator({'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'int'}})\n\n    @benchmark\n    def t():\n        v.validate_python(dict_of_ints_data[0])\n        v.validate_python(dict_of_ints_data[1])\n\n\n@pytest.mark.benchmark(group='Dict[any, any]')\ndef test_dict_of_any_core(benchmark):\n    v = SchemaValidator({'type': 'dict'})\n\n    @benchmark\n    def t():\n        v.validate_python(dict_of_ints_data[0])\n        v.validate_python(dict_of_ints_data[1])\n\n\n@pytest.mark.benchmark(group='Dict[str, int] JSON')\ndef test_dict_of_ints_core_json(benchmark):\n    v = SchemaValidator({'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'int'}})\n\n    json_data = [json.dumps(d) for d in dict_of_ints_data]\n\n    @benchmark\n    def t():\n        v.validate_json(json_data[0])\n        v.validate_json(json_data[1])\n\n\nmany_models_data = [{'age': i} for i in range(1000)]\n\n\n@pytest.mark.benchmark(group='List[DictSimpleMode]')\ndef test_many_models_core_dict(benchmark):\n    model_schema = {\n        'type': 'list',\n        'items_schema': {\n            'type': 'typed-dict',\n            'fields': {'age': {'type': 'typed-dict-field', 'schema': {'type': 'int'}}},\n        },\n    }\n    v = SchemaValidator(model_schema)\n    benchmark(v.validate_python, many_models_data)\n\n\n@pytest.mark.benchmark(group='List[SimpleMode]')\ndef test_many_models_core_model(benchmark):\n    class MyCoreModel:\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n\n    v = SchemaValidator(\n        {\n            'type': 'list',\n            'items_schema': {\n                'type': 'model',\n                'cls': MyCoreModel,\n                'schema': {\n                    'type': 'model-fields',\n                    'fields': {'age': {'type': 'model-field', 'schema': {'type': 'int'}}},\n                },\n            },\n        }\n    )\n    benchmark(v.validate_python, many_models_data)\n\n\nlist_of_nullable_data = [None if i % 2 else i for i in range(1000)]\n\n\n@pytest.mark.benchmark(group='List[Nullable[int]]')\ndef test_list_of_nullable_core(benchmark):\n    v = SchemaValidator({'type': 'list', 'items_schema': {'type': 'nullable', 'schema': {'type': 'int'}}})\n\n    benchmark(v.validate_python, list_of_nullable_data)\n\n\nsome_bytes = b'0' * 1000\n\n\n@pytest.mark.benchmark(group='bytes')\ndef test_bytes_core(benchmark):\n    v = SchemaValidator({'type': 'bytes'})\n\n    benchmark(v.validate_python, some_bytes)\n\n\nclass TestBenchmarkDateTime:\n    @pytest.fixture(scope='class')\n    def core_validator(self):\n        class CoreModel:\n            __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n\n        return SchemaValidator(\n            {\n                'type': 'model',\n                'cls': CoreModel,\n                'schema': {\n                    'type': 'model-fields',\n                    'fields': {'dt': {'type': 'model-field', 'schema': {'type': 'datetime'}}},\n                },\n            }\n        )\n\n    @pytest.fixture(scope='class')\n    def datetime_raw(self):\n        return datetime.now(timezone.utc) + timedelta(days=1)\n\n    @pytest.fixture(scope='class')\n    def datetime_str(self, datetime_raw):\n        return str(datetime_raw)\n\n    @pytest.fixture(scope='class')\n    def python_data_dict(self, datetime_raw):\n        return {'dt': datetime_raw}\n\n    @pytest.fixture(scope='class')\n    def json_dict_data(self, datetime_str):\n        return json.dumps({'dt': datetime_str})\n\n    @pytest.mark.benchmark(group='datetime model - python')\n    def test_core_python(self, core_validator, benchmark, python_data_dict):\n        benchmark(core_validator.validate_python, python_data_dict)\n\n    @pytest.mark.benchmark(group='datetime model - JSON')\n    def test_model_core_json(self, core_validator, benchmark, json_dict_data):\n        benchmark(core_validator.validate_json, json_dict_data)\n\n    @pytest.mark.benchmark(group='datetime datetime')\n    def test_core_raw(self, benchmark, datetime_raw):\n        v = SchemaValidator({'type': 'datetime'})\n\n        benchmark(v.validate_python, datetime_raw)\n\n    @pytest.mark.benchmark(group='datetime str')\n    def test_core_str(self, benchmark, datetime_str):\n        v = SchemaValidator({'type': 'datetime'})\n\n        benchmark(v.validate_python, datetime_str)\n\n    @pytest.mark.benchmark(group='datetime future')\n    def test_core_future(self, benchmark, datetime_raw):\n        v = SchemaValidator({'type': 'datetime', 'gt': datetime.now()})\n\n        benchmark(v.validate_python, datetime_raw)\n\n    @pytest.mark.benchmark(group='datetime future')\n    def test_core_future_str(self, benchmark, datetime_str):\n        v = SchemaValidator({'type': 'datetime', 'gt': datetime.now()})\n\n        benchmark(v.validate_python, datetime_str)\n\n\nclass TestBenchmarkDateX:\n    @pytest.fixture(scope='class')\n    def validator(self):\n        return SchemaValidator({'type': 'date'})\n\n    @pytest.mark.benchmark(group='date from date')\n    def test_date_from_date(self, benchmark, validator):\n        benchmark(validator.validate_python, date.today())\n\n    @pytest.mark.benchmark(group='date from str')\n    def test_date_from_str(self, benchmark, validator):\n        benchmark(validator.validate_python, str(date.today()))\n\n    @pytest.mark.benchmark(group='date from datetime')\n    def test_date_from_datetime(self, benchmark, validator):\n        benchmark(validator.validate_python, datetime(2000, 1, 1))\n\n    @pytest.mark.benchmark(group='date from datetime str')\n    def test_date_from_datetime_str(self, benchmark, validator):\n        benchmark(validator.validate_python, str(datetime(2000, 1, 1)))\n\n    @pytest.mark.benchmark(group='date future')\n    def test_core_future(self, benchmark):\n        v = SchemaValidator({'type': 'date', 'gt': date.today()})\n\n        benchmark(v.validate_python, date(2932, 1, 1))\n\n    @pytest.mark.benchmark(group='date future')\n    def test_core_future_str(self, benchmark):\n        v = SchemaValidator({'type': 'date', 'gt': date.today()})\n\n        benchmark(v.validate_python, str(date(2932, 1, 1)))\n\n\nclass TestBenchmarkUnion:\n    @pytest.mark.benchmark(group='smart-union')\n    def test_smart_union_core(self, benchmark):\n        v = SchemaValidator({'type': 'union', 'choices': [{'type': 'bool'}, {'type': 'int'}, {'type': 'str'}]})\n\n        benchmark(v.validate_python, 1)\n\n    @pytest.mark.benchmark(group='smart-union-coerce')\n    def test_smart_union_coerce_core(self, benchmark):\n        v = SchemaValidator({'type': 'union', 'choices': [{'type': 'bool'}, {'type': 'str'}]})\n\n        benchmark(v.validate_python, 1)  # will be True\n\n    @pytest.mark.benchmark(group='strict-union')\n    def test_strict_union_core(self, benchmark):\n        v = SchemaValidator(\n            {'type': 'union', 'strict': True, 'choices': [{'type': 'bool'}, {'type': 'int'}, {'type': 'str'}]}\n        )\n\n        benchmark(v.validate_python, 1)\n\n    @pytest.mark.benchmark(group='strict-union-error')\n    def test_strict_union_error_core(self, benchmark):\n        v = SchemaValidator({'type': 'union', 'strict': True, 'choices': [{'type': 'bool'}, {'type': 'str'}]})\n\n        def validate_with_expected_error():\n            try:\n                v.validate_python(2)\n                assert False\n            except CoreValidationError:\n                assert True\n\n        benchmark(validate_with_expected_error)\n\n\nclass TestBenchmarkUUID:\n    @pytest.fixture(scope='class')\n    def core_validator(self):\n        class CoreModel:\n            __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n\n        return SchemaValidator(\n            {\n                'type': 'model',\n                'cls': CoreModel,\n                'schema': {\n                    'type': 'model-fields',\n                    'fields': {'u': {'type': 'model-field', 'schema': {'type': 'uuid'}}},\n                },\n            }\n        )\n\n    @pytest.fixture(scope='class')\n    def validator(self):\n        return SchemaValidator({'type': 'uuid'})\n\n    @pytest.fixture(scope='class')\n    def pydantic_validator(self):\n        def to_UUID(v: Any) -> UUID:\n            if isinstance(v, UUID):\n                return v\n            try:\n                if isinstance(v, str):\n                    return UUID(v)\n                else:\n                    try:\n                        return UUID(v.decode())\n                    except ValueError:\n                        # 16 bytes in big-endian order as the bytes argument fail\n                        # the above check\n                        return UUID(bytes=v)\n            except ValueError:\n                raise PydanticCustomError(\n                    'uuid_parsing', 'Input should be a valid UUID, unable to parse string as an UUID'\n                )\n\n        json_schema = core_schema.no_info_after_validator_function(\n            to_UUID, core_schema.str_schema(strict=True, strip_whitespace=True)\n        )\n        schema = core_schema.json_or_python_schema(\n            json_schema=json_schema,\n            python_schema=core_schema.lax_or_strict_schema(\n                lax_schema=core_schema.union_schema([core_schema.is_instance_schema(UUID), json_schema]),\n                strict_schema=core_schema.is_instance_schema(UUID),\n            ),\n            serialization=core_schema.to_string_ser_schema(when_used='json'),\n        )\n\n        return SchemaValidator(schema)\n\n    @pytest.mark.benchmark(group='uuid from str')\n    def test_uuid_from_string_core(self, benchmark, validator):\n        benchmark(validator.validate_python, '12345678-1234-5678-1234-567812345678')\n\n    @pytest.mark.benchmark(group='uuid from str')\n    def test_uuid_from_string_pyd(self, benchmark, pydantic_validator):\n        benchmark(pydantic_validator.validate_python, '12345678-1234-5678-1234-567812345678')\n\n    @pytest.mark.benchmark(group='uuid from UUID')\n    def test_uuid_from_uuid_core(self, benchmark, validator):\n        benchmark(validator.validate_python, UUID('12345678-1234-5678-1234-567812345678'))\n\n    @pytest.mark.benchmark(group='uuid from UUID')\n    def test_uuid_from_uuid_pyd(self, benchmark, pydantic_validator):\n        benchmark(pydantic_validator.validate_python, UUID('12345678-1234-5678-1234-567812345678'))\n\n    @pytest.fixture(scope='class')\n    def uuid_raw(self):\n        return UUID('12345678-1234-5678-1234-567812345678')\n\n    @pytest.fixture(scope='class')\n    def uuid_str(self, uuid_raw):\n        return str(uuid_raw)\n\n    @pytest.fixture(scope='class')\n    def python_data_dict(self, uuid_raw):\n        return {'u': uuid_raw}\n\n    @pytest.fixture(scope='class')\n    def json_dict_data(self, uuid_str):\n        return json.dumps({'u': uuid_str})\n\n    @pytest.mark.benchmark(group='uuid model - python')\n    def test_core_python(self, core_validator, benchmark, python_data_dict):\n        benchmark(core_validator.validate_python, python_data_dict)\n\n    @pytest.mark.benchmark(group='uuid model - JSON')\n    def test_model_core_json(self, core_validator, benchmark, json_dict_data):\n        benchmark(core_validator.validate_json, json_dict_data)\n\n    @pytest.mark.benchmark(group='uuid uuid')\n    def test_core_raw(self, benchmark, uuid_raw):\n        v = SchemaValidator({'type': 'uuid'})\n\n        benchmark(v.validate_python, uuid_raw)\n\n    @pytest.mark.benchmark(group='uuid str')\n    def test_core_str(self, benchmark, uuid_str):\n        v = SchemaValidator({'type': 'uuid'})\n\n        benchmark(v.validate_python, uuid_str)\n\n\n@pytest.mark.benchmark(group='raise-error')\ndef test_dont_raise_error(benchmark):\n    def f(input_value, info):\n        return input_value\n\n    v = SchemaValidator(core_schema.with_info_plain_validator_function(f))\n\n    @benchmark\n    def t():\n        v.validate_python(42)\n\n\n@pytest.mark.benchmark(group='raise-error')\ndef test_dont_raise_error_no_info(benchmark):\n    def f(input_value):\n        return input_value\n\n    v = SchemaValidator(core_schema.no_info_plain_validator_function(f))\n\n    @benchmark\n    def t():\n        v.validate_python(42)\n\n\n@pytest.mark.benchmark(group='raise-error')\ndef test_raise_error_value_error(benchmark):\n    def f(input_value, info):\n        raise ValueError('this is a custom error')\n\n    v = SchemaValidator(core_schema.with_info_plain_validator_function(f))\n\n    @benchmark\n    def t():\n        try:\n            v.validate_python(42)\n        except ValidationError:\n            pass\n        else:\n            raise RuntimeError('expected ValidationError')\n\n\n@pytest.mark.benchmark(group='raise-error')\ndef test_raise_error_custom(benchmark):\n    def f(input_value, info):\n        raise PydanticCustomError('my_error', 'this is a custom error {foo}', {'foo': 'FOOBAR'})\n\n    v = SchemaValidator(core_schema.with_info_plain_validator_function(f))\n\n    @benchmark\n    def t():\n        try:\n            v.validate_python(42)\n        except ValidationError:\n            pass\n        else:\n            raise RuntimeError('expected ValidationError')\n\n\n@pytest.mark.benchmark(group='tuple')\ndef test_positional_tuple(benchmark):\n    v = SchemaValidator(\n        {\n            'type': 'tuple',\n            'items_schema': [{'type': 'int'}, {'type': 'int'}, {'type': 'int'}, {'type': 'int'}, {'type': 'int'}],\n        }\n    )\n    assert v.validate_python((1, 2, 3, '4', 5)) == (1, 2, 3, 4, 5)\n\n    benchmark(v.validate_python, (1, 2, 3, '4', 5))\n\n\n@pytest.mark.benchmark(group='tuple')\ndef test_variable_tuple(benchmark):\n    v = SchemaValidator({'type': 'tuple', 'items_schema': [{'type': 'int'}], 'variadic_item_index': 0})\n    assert v.validate_python((1, 2, 3, '4', 5)) == (1, 2, 3, 4, 5)\n\n    benchmark(v.validate_python, (1, 2, 3, '4', 5))\n\n\n@pytest.mark.benchmark(group='tuple-many')\ndef test_tuple_many_variable(benchmark):\n    v = SchemaValidator({'type': 'tuple', 'items_schema': [{'type': 'int'}], 'variadic_item_index': 0})\n    assert v.validate_python(list(range(10))) == tuple(range(10))\n\n    benchmark(v.validate_python, list(range(10)))\n\n\n@pytest.mark.benchmark(group='tuple-many')\ndef test_tuple_many_positional(benchmark):\n    v = SchemaValidator({'type': 'tuple', 'items_schema': [{'type': 'int'}], 'variadic_item_index': 0})\n    assert v.validate_python(list(range(10))) == tuple(range(10))\n\n    benchmark(v.validate_python, list(range(10)))\n\n\n@pytest.mark.benchmark(group='arguments')\ndef test_arguments(benchmark):\n    v = SchemaValidator(\n        {\n            'type': 'arguments',\n            'arguments_schema': [\n                {'name': 'args1', 'mode': 'positional_only', 'schema': {'type': 'int'}},\n                {'name': 'args2', 'mode': 'positional_only', 'schema': {'type': 'str'}},\n                {'name': 'a', 'mode': 'positional_or_keyword', 'schema': {'type': 'bool'}},\n                {'name': 'b', 'mode': 'keyword_only', 'schema': {'type': 'str'}},\n                {'name': 'c', 'mode': 'keyword_only', 'schema': {'type': 'int'}},\n            ],\n        }\n    )\n    assert v.validate_python(ArgsKwargs((1, 'a', 'true'), {'b': 'bb', 'c': 3})) == ((1, 'a', True), {'b': 'bb', 'c': 3})\n\n    benchmark(v.validate_python, ArgsKwargs((1, 'a', 'true'), {'b': 'bb', 'c': 3}))\n\n\n@pytest.mark.benchmark(group='defaults')\ndef test_with_default(benchmark):\n    v = SchemaValidator(\n        {\n            'type': 'typed-dict',\n            'fields': {\n                'name': {\n                    'type': 'typed-dict-field',\n                    'schema': {'type': 'default', 'schema': {'type': 'str'}, 'default': 'John'},\n                }\n            },\n        }\n    )\n    assert v.validate_python({'name': 'Foo'}) == {'name': 'Foo'}\n    assert v.validate_python({}) == {'name': 'John'}\n\n    @benchmark\n    def t():\n        v.validate_python({'name': 'Foo'})\n        v.validate_python({})\n\n\n@pytest.mark.benchmark(group='chain')\ndef test_chain_list(benchmark):\n    validator = SchemaValidator(\n        {\n            'type': 'chain',\n            'steps': [{'type': 'str'}, core_schema.with_info_plain_validator_function(lambda v, info: Decimal(v))],\n        }\n    )\n    assert validator.validate_python('42.42') == Decimal('42.42')\n\n    benchmark(validator.validate_python, '42.42')\n\n\n@pytest.mark.benchmark(group='chain')\ndef test_chain_function(benchmark):\n    validator = SchemaValidator(\n        {\n            'type': 'function-after',\n            'schema': {'type': 'str'},\n            'function': {'type': 'with-info', 'function': lambda v, info: Decimal(v)},\n        }\n    )\n    assert validator.validate_python('42.42') == Decimal('42.42')\n\n    benchmark(validator.validate_python, '42.42')\n\n\n@pytest.mark.benchmark(group='chain-functions')\ndef test_chain_two_functions(benchmark):\n    validator = SchemaValidator(\n        {\n            'type': 'chain',\n            'steps': [\n                {'type': 'str'},\n                core_schema.with_info_plain_validator_function(lambda v, info: Decimal(v)),\n                core_schema.with_info_plain_validator_function(lambda v, info: v * 2),\n            ],\n        }\n    )\n    assert validator.validate_python('42.42') == Decimal('84.84')\n\n    benchmark(validator.validate_python, '42.42')\n\n\n@pytest.mark.benchmark(group='chain-functions')\ndef test_chain_nested_functions(benchmark):\n    validator = SchemaValidator(\n        {\n            'type': 'function-after',\n            'schema': {\n                'type': 'function-after',\n                'schema': {'type': 'str'},\n                'function': {'type': 'with-info', 'function': lambda v, info: Decimal(v)},\n            },\n            'function': {'type': 'with-info', 'function': lambda v, info: v * 2},\n        }\n    )\n    assert validator.validate_python('42.42') == Decimal('84.84')\n\n    benchmark(validator.validate_python, '42.42')\n\n\ndef validate_yield(iterable, validator):\n    for item in iterable:\n        yield validator(item)\n\n\ndef generator_gen_python(v, validator, info):\n    try:\n        iterable = iter(v)\n    except TypeError:\n        raise PydanticCustomError('iterable_type', 'Input should be a valid iterable')\n    return validate_yield(iterable, validator)\n\n\n@pytest.mark.benchmark(group='generator')\ndef test_generator_python(benchmark):\n    schema = core_schema.with_info_wrap_validator_function(generator_gen_python, {'type': 'int'})\n    v = SchemaValidator(schema)\n    input_value = tuple(range(100))\n\n    assert sum(v.validate_python(input_value)) == 4950\n\n    benchmark(v.validate_python, input_value)\n\n\ndef generator_gen_rust(v, *, validator, **_kwargs):\n    try:\n        generator = iter(v)\n    except TypeError:\n        raise PydanticCustomError('generator_type', 'Input should be a valid generator')\n    return validator.iter(generator)\n\n\n@pytest.mark.benchmark(group='generator')\ndef test_generator_rust(benchmark):\n    schema = {'type': 'generator', 'items_schema': {'type': 'int'}}\n    v = SchemaValidator(schema)\n    input_value = tuple(range(100))\n\n    assert sum(v.validate_python(input_value)) == 4950\n\n    benchmark(v.validate_python, input_value)\n\n\n@pytest.mark.benchmark(group='isinstance-json')\ndef test_isinstance_json(benchmark):\n    validator = SchemaValidator(core_schema.json_or_python_schema(core_schema.str_schema(), core_schema.int_schema()))\n    assert validator.validate_json('\"foo\"') == 'foo'\n    with pytest.raises(ValidationError):\n        validator.validate_json('123')\n\n    @benchmark\n    def t():\n        validator.validate_json('\"foo\"')\n\n\n@pytest.mark.benchmark(group='error')\ndef test_int_error(benchmark):\n    validator = SchemaValidator(core_schema.int_schema())\n    try:\n        validator.validate_python('bar')\n    except ValidationError as e:\n        # insert_assert(e.errors())\n        assert e.errors() == [\n            {\n                'type': 'int_parsing',\n                'loc': (),\n                'msg': 'Input should be a valid integer, unable to parse string as an integer',\n                'input': 'bar',\n                'url': IsStr(regex=r'https://errors.pydantic.dev/.*?/v/int_parsing'),\n            }\n        ]\n    else:\n        raise AssertionError('ValidationError not raised')\n\n    @benchmark\n    def t():\n        try:\n            validator.validate_python('foobar', strict=True)\n        except ValidationError as e:\n            e.errors()\n\n\n@pytest.mark.benchmark(group='definition')\ndef test_definition_in_tree(benchmark):\n    validator = SchemaValidator(core_schema.list_schema(core_schema.int_schema()))\n    values = [1, 2, 3.0, '4', '5', '6'] * 1000\n    benchmark(validator.validate_python, values)\n\n\n@pytest.mark.benchmark(group='definition')\ndef test_definition_out_of_tree(benchmark):\n    validator = SchemaValidator(\n        core_schema.definitions_schema(\n            core_schema.list_schema(core_schema.definition_reference_schema('foobar')),\n            [core_schema.int_schema(ref='foobar')],\n        )\n    )\n    values = [1, 2, 3.0, '4', '5', '6'] * 1000\n    benchmark(validator.validate_python, values)\n\n\n@pytest.mark.benchmark(group='model_instance')\ndef test_model_instance(benchmark):\n    class MyModel:\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n\n        def __init__(self, **d):\n            self.__dict__ = d\n            self.__pydantic_extra__ = {}\n            self.__pydantic_fields_set__ = set(d)\n\n    validator = SchemaValidator(\n        core_schema.model_schema(\n            MyModel,\n            core_schema.model_fields_schema(\n                {\n                    'foo': core_schema.model_field(core_schema.int_schema()),\n                    'bar': core_schema.model_field(core_schema.int_schema()),\n                }\n            ),\n            revalidate_instances='always',\n        )\n    )\n    m1 = MyModel(foo=1, bar='2')\n    m2 = validator.validate_python(m1)\n    assert m1 is not m2\n    assert m2.foo == 1\n    assert m2.bar == 2\n\n    benchmark(validator.validate_python, m1)\n\n\n@pytest.mark.benchmark(group='model_instance')\ndef test_model_instance_abc(benchmark):\n    import abc\n\n    class MyMeta(abc.ABCMeta):\n        def __instancecheck__(self, instance) -> bool:\n            return hasattr(instance, '__pydantic_validator__') and super().__instancecheck__(instance)\n\n    class BaseModel(metaclass=MyMeta):\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n        __pydantic_validator__ = True\n\n        def __init__(self, **d):\n            self.__dict__ = d\n            self.__pydantic_extra__ = {}\n            self.__pydantic_fields_set__ = set(d)\n\n    class MyModel(BaseModel):\n        pass\n\n    validator = SchemaValidator(\n        core_schema.model_schema(\n            MyModel,\n            core_schema.model_fields_schema(\n                {\n                    'foo': core_schema.model_field(core_schema.int_schema()),\n                    'bar': core_schema.model_field(core_schema.int_schema()),\n                }\n            ),\n            revalidate_instances='always',\n        )\n    )\n    m1 = MyModel(foo=1, bar='2')\n    m2 = validator.validate_python(m1)\n    assert m1 is not m2\n    assert m2.foo == 1\n    assert m2.bar == 2\n\n    assert validator.isinstance_python(m1)\n\n    benchmark(validator.validate_python, m1)\n\n\nclass SomeStrEnum(str, Enum):\n    foo = 'foo_val'\n    bar = 'bar_val'\n    baz = 'baz_val'\n\n\nLARGE_STR_PREFIX = 'a' * 50\n\n\n@pytest.mark.benchmark(group='validate_literal')\n@pytest.mark.parametrize(\n    'allowed_values,input,expected_val_res',\n    [\n        (list(range(5)), 4, 4),\n        ([f'abc{i}' for i in range(5)], 'abc4', 'abc4'),\n        ([LARGE_STR_PREFIX + f'{i}' for i in range(5)], f'{LARGE_STR_PREFIX}4', f'{LARGE_STR_PREFIX}4'),\n        ([SomeStrEnum.foo, SomeStrEnum.bar], SomeStrEnum.bar, SomeStrEnum.bar),\n        (list(range(100)), 5, 5),\n        ([f'abc{i}' for i in range(100)], 'abc99', 'abc99'),\n        ([LARGE_STR_PREFIX + f'{i}' for i in range(100)], f'{LARGE_STR_PREFIX}99', f'{LARGE_STR_PREFIX}99'),\n        (['null', None, -1, SomeStrEnum.baz], None, None),\n    ],\n    ids=[\n        'few_ints',\n        'few_small_strings',\n        'few_large_strings',\n        'few_str_enum',\n        'many_ints',\n        'many_small_strings',\n        'many_large_strings',\n        'few_mixed',\n    ],\n)\n@pytest.mark.parametrize('py_or_json', ['python', 'json'])\ndef test_validate_literal(\n    benchmark: Any, allowed_values: List[Any], input: Any, expected_val_res: Any, py_or_json: str\n) -> None:\n    validator = SchemaValidator(core_schema.literal_schema(expected=allowed_values))\n\n    if py_or_json == 'python':\n        res = validator.validate_python(input)\n        assert res == expected_val_res\n\n        benchmark(validator.validate_python, input)\n    else:\n        input_json = json.dumps(input)\n        res = validator.validate_json(input_json)\n        assert res == expected_val_res\n\n        benchmark(validator.validate_json, input_json)\n\n\n@pytest.mark.benchmark(group='root_model')\ndef test_core_root_model(benchmark):\n    class MyModel:\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n        root: List[int]\n\n    v = SchemaValidator(\n        core_schema.model_schema(MyModel, core_schema.list_schema(core_schema.int_schema()), root_model=True)\n    )\n    assert v.validate_python([1, 2, '3']).root == [1, 2, 3]\n    input_data = list(range(100))\n    benchmark(v.validate_python, input_data)\n\n\n@pytest.mark.benchmark(group='strict_int')\ndef test_strict_int(benchmark):\n    v = SchemaValidator(core_schema.int_schema(strict=True))\n\n    benchmark(v.validate_python, 42)\n\n\n@pytest.mark.benchmark(group='strict_int')\ndef test_strict_int_fails(benchmark):\n    v = SchemaValidator(core_schema.int_schema(strict=True))\n\n    @benchmark\n    def t():\n        try:\n            v.validate_python(())\n        except ValidationError:\n            pass\n\n\n@pytest.mark.benchmark(group='int_range')\ndef test_int_range(benchmark):\n    v = SchemaValidator(core_schema.int_schema(gt=0, lt=100))\n\n    assert v.validate_python(42) == 42\n    with pytest.raises(ValidationError, match='Input should be greater than 0'):\n        v.validate_python(0)\n\n    benchmark(v.validate_python, 42)\n\n\n@pytest.mark.benchmark(group='int_range')\ndef test_int_range_json(benchmark):\n    v = SchemaValidator(core_schema.int_schema(gt=0, lt=100))\n\n    assert v.validate_json('42') == 42\n    with pytest.raises(ValidationError, match='Input should be greater than 0'):\n        v.validate_python('0')\n\n    benchmark(v.validate_json, '42')\n\n\n@pytest.mark.benchmark(group='tagged_union_ints')\ndef test_tagged_union_int_keys_python(benchmark):\n    inner_schema = core_schema.typed_dict_schema(\n        {\n            'x': core_schema.typed_dict_field(core_schema.int_schema()),\n            'y': core_schema.typed_dict_field(core_schema.int_schema()),\n        }\n    )\n    v = SchemaValidator(core_schema.tagged_union_schema({x: inner_schema for x in range(1000)}, discriminator='x'))\n\n    payload = {'x': 999, 'y': '1'}\n    assert v.validate_python(payload) == {'x': 999, 'y': 1}\n    with pytest.raises(\n        ValidationError, match=\"Input tag '1001' found using 'x' does not match any of the expected tags\"\n    ):\n        v.validate_python({'x': 1001, 'y': '1'})\n\n    benchmark(v.validate_python, payload)\n\n\n@pytest.mark.benchmark(group='tagged_union_ints')\ndef test_tagged_union_int_keys_json(benchmark):\n    inner_schema = core_schema.typed_dict_schema(\n        {\n            'x': core_schema.typed_dict_field(core_schema.int_schema()),\n            'y': core_schema.typed_dict_field(core_schema.int_schema()),\n        }\n    )\n    v = SchemaValidator(core_schema.tagged_union_schema({x: inner_schema for x in range(1000)}, discriminator='x'))\n\n    payload = '{\"x\": 999, \"y\": \"1\"}'\n    assert v.validate_json(payload) == {'x': 999, 'y': 1}\n    with pytest.raises(\n        ValidationError, match=\"Input tag '1001' found using 'x' does not match any of the expected tags\"\n    ):\n        v.validate_json('{\"x\": 1001, \"y\": \"1\"}')\n\n    benchmark(v.validate_json, payload)\n\n\n@skip_pypy_deep_stack\n@skip_wasm_deep_stack\n@pytest.mark.benchmark(group='field_function_validator')\ndef test_field_function_validator(benchmark) -> None:\n    def f(v: int, info: core_schema.ValidationInfo) -> int:\n        assert info.field_name == 'x'\n        return v + 1\n\n    schema: core_schema.CoreSchema = core_schema.int_schema()\n    limit = pydantic_core._pydantic_core._recursion_limit - 3\n\n    for _ in range(limit):\n        schema = core_schema.with_info_after_validator_function(f, schema, field_name='x')\n\n    schema = core_schema.typed_dict_schema({'x': core_schema.typed_dict_field(schema)})\n\n    v = SchemaValidator(schema)\n    payload = {'x': 0}\n    assert v.validate_python(payload) == {'x': limit}\n\n    benchmark(v.validate_python, payload)\n\n\nclass TestBenchmarkDecimal:\n    @pytest.fixture(scope='class')\n    def validator(self):\n        return SchemaValidator({'type': 'decimal'})\n\n    @pytest.fixture(scope='class')\n    def pydantic_validator(self):\n        Decimal = decimal.Decimal\n\n        def to_decimal(v: str) -> decimal.Decimal:\n            try:\n                return Decimal(v)\n            except decimal.DecimalException as e:\n                raise PydanticCustomError('decimal_parsing', 'Input should be a valid decimal') from e\n\n        primitive_schema = core_schema.union_schema(\n            [\n                # if it's an int keep it like that and pass it straight to Decimal\n                # but if it's not make it a string\n                # we don't use JSON -> float because parsing to any float will cause\n                # loss of precision\n                core_schema.int_schema(strict=True),\n                core_schema.str_schema(strict=True, strip_whitespace=True),\n                core_schema.no_info_plain_validator_function(str),\n            ]\n        )\n        json_schema = core_schema.no_info_after_validator_function(to_decimal, primitive_schema)\n        schema = core_schema.json_or_python_schema(\n            json_schema=json_schema,\n            python_schema=core_schema.lax_or_strict_schema(\n                lax_schema=core_schema.union_schema([core_schema.is_instance_schema(decimal.Decimal), json_schema]),\n                strict_schema=core_schema.is_instance_schema(decimal.Decimal),\n            ),\n            serialization=core_schema.to_string_ser_schema(when_used='json'),\n        )\n\n        def check_finite(value: decimal.Decimal) -> decimal.Decimal:\n            if not value.is_finite():\n                raise PydanticKnownError('finite_number')\n            return value\n\n        schema = core_schema.no_info_after_validator_function(check_finite, schema)\n\n        return SchemaValidator(schema)\n\n    @pytest.mark.benchmark(group='decimal from str')\n    def test_decimal_from_string_core(self, benchmark, validator):\n        benchmark(validator.validate_python, '123.456789')\n\n    @pytest.mark.benchmark(group='decimal from str')\n    def test_decimal_from_string_pyd(self, benchmark, pydantic_validator):\n        benchmark(pydantic_validator.validate_python, '123.456789')\n\n    @pytest.mark.benchmark(group='decimal from str')\n    def test_decimal_from_string_limit(self, benchmark):\n        benchmark(decimal.Decimal, '123.456789')\n\n\nclass FooInt(int, Enum):\n    a = 1\n    b = 2\n    c = 3\n\n\n@pytest.mark.benchmark(group='enum int')\ndef test_enum_int_python(benchmark):\n    def to_enum(input_value: Any, /) -> Enum:\n        try:\n            return FooInt(input_value)\n        except ValueError:\n            raise PydanticCustomError('enum', 'Input should be {expected}', {'expected': '1, 2 or 3'})\n\n    v = SchemaValidator(core_schema.no_info_after_validator_function(to_enum, core_schema.int_schema()))\n\n    assert v.validate_python(1) is FooInt.a\n\n    benchmark(v.validate_python, 1)\n\n\n@pytest.mark.benchmark(group='enum int')\ndef test_enum_int_core(benchmark):\n    v = SchemaValidator(core_schema.enum_schema(FooInt, list(FooInt.__members__.values()), sub_type='int'))\n\n    assert v.validate_python(1) is FooInt.a\n\n    benchmark(v.validate_python, 1)\n\n\nclass FooStr(str, Enum):\n    a = 'apple'\n    b = 'banana'\n    c = 'carrot'\n\n\n@pytest.mark.benchmark(group='enum str')\ndef test_enum_str_python(benchmark):\n    def to_enum(input_value: Any, /) -> Enum:\n        try:\n            return FooStr(input_value)\n        except ValueError:\n            raise PydanticCustomError('enum', 'Input should be {expected}', {'expected': 'apple, banana or carrot'})\n\n    v = SchemaValidator(core_schema.no_info_after_validator_function(to_enum, core_schema.str_schema()))\n\n    assert v.validate_python('apple') is FooStr.a\n\n    benchmark(v.validate_python, 'apple')\n\n\n@pytest.mark.benchmark(group='enum str')\ndef test_enum_str_core(benchmark):\n    v = SchemaValidator(core_schema.enum_schema(FooStr, list(FooStr.__members__.values()), sub_type='str'))\n\n    assert v.validate_python('apple') is FooStr.a\n\n    benchmark(v.validate_python, 'apple')\n", "tests/benchmarks/__init__.py": "", "tests/serializers/test_definitions.py": "import pytest\n\nfrom pydantic_core import SchemaError, SchemaSerializer, core_schema, validate_core_schema\n\n\ndef test_custom_ser():\n    s = SchemaSerializer(\n        core_schema.definitions_schema(\n            core_schema.list_schema(core_schema.definition_reference_schema('foobar')),\n            [core_schema.int_schema(ref='foobar', serialization=core_schema.to_string_ser_schema(when_used='always'))],\n        )\n    )\n    assert s.to_python([1, 2, 3]) == ['1', '2', '3']\n\n\ndef test_ignored_def():\n    s = SchemaSerializer(\n        core_schema.definitions_schema(\n            core_schema.list_schema(core_schema.int_schema()),\n            [core_schema.int_schema(ref='foobar', serialization=core_schema.to_string_ser_schema(when_used='always'))],\n        )\n    )\n    assert s.to_python([1, 2, 3]) == [1, 2, 3]\n\n\ndef test_def_error():\n    with pytest.raises(SchemaError) as exc_info:\n        validate_core_schema(\n            core_schema.definitions_schema(\n                core_schema.list_schema(core_schema.definition_reference_schema('foobar')),\n                [core_schema.int_schema(ref='foobar'), {'type': 'wrong'}],\n            )\n        )\n\n    assert str(exc_info.value).startswith(\n        \"Invalid Schema:\\ndefinitions.definitions.1\\n  Input tag 'wrong' found using 'type'\"\n    )\n\n\ndef test_repeated_ref():\n    with pytest.raises(SchemaError, match='SchemaError: Duplicate ref: `foobar`'):\n        SchemaSerializer(\n            core_schema.tuple_positional_schema(\n                [\n                    core_schema.definitions_schema(\n                        core_schema.definition_reference_schema('foobar'), [core_schema.int_schema(ref='foobar')]\n                    ),\n                    core_schema.definitions_schema(\n                        core_schema.definition_reference_schema('foobar'), [core_schema.int_schema(ref='foobar')]\n                    ),\n                ]\n            )\n        )\n\n\ndef test_repeat_after():\n    with pytest.raises(SchemaError, match='SchemaError: Duplicate ref: `foobar`'):\n        SchemaSerializer(\n            core_schema.definitions_schema(\n                core_schema.tuple_positional_schema(\n                    [\n                        core_schema.definitions_schema(\n                            core_schema.definition_reference_schema('foobar'), [core_schema.int_schema(ref='foobar')]\n                        ),\n                        core_schema.definition_reference_schema('foobar'),\n                    ]\n                ),\n                [core_schema.int_schema(ref='foobar')],\n            )\n        )\n\n\ndef test_deep():\n    v = SchemaSerializer(\n        core_schema.typed_dict_schema(\n            {\n                'a': core_schema.typed_dict_field(core_schema.int_schema()),\n                'b': core_schema.typed_dict_field(\n                    core_schema.definitions_schema(\n                        core_schema.typed_dict_schema(\n                            {\n                                'c': core_schema.typed_dict_field(core_schema.int_schema()),\n                                'd': core_schema.typed_dict_field(core_schema.definition_reference_schema('foobar')),\n                            }\n                        ),\n                        [\n                            core_schema.int_schema(\n                                ref='foobar', serialization=core_schema.to_string_ser_schema(when_used='always')\n                            )\n                        ],\n                    )\n                ),\n            }\n        )\n    )\n    assert v.to_python({'a': 1, 'b': {'c': 2, 'd': 3}}) == {'a': 1, 'b': {'c': 2, 'd': '3'}}\n\n\ndef test_use_after():\n    v = SchemaSerializer(\n        core_schema.tuple_positional_schema(\n            [\n                core_schema.definitions_schema(\n                    core_schema.definition_reference_schema('foobar'),\n                    [\n                        core_schema.int_schema(\n                            ref='foobar', serialization=core_schema.to_string_ser_schema(when_used='always')\n                        )\n                    ],\n                ),\n                core_schema.definition_reference_schema('foobar'),\n            ]\n        )\n    )\n    assert v.to_python((1, 2)) == ('1', '2')\n\n\ndef test_defs_with_dict():\n    s = SchemaSerializer(\n        core_schema.definitions_schema(\n            schema=core_schema.typed_dict_schema(\n                {\n                    'foo': core_schema.typed_dict_field(\n                        core_schema.dict_schema(\n                            keys_schema=core_schema.definition_reference_schema('key'),\n                            values_schema=core_schema.definition_reference_schema('val'),\n                        )\n                    )\n                }\n            ),\n            definitions=[core_schema.str_schema(ref='key'), core_schema.str_schema(ref='val')],\n        )\n    )\n\n    assert s.to_json({'foo': {'key': 'val'}}) == b'{\"foo\":{\"key\":\"val\"}}'\n    assert s.to_python({'foo': {'key': 'val'}}) == {'foo': {'key': 'val'}}\n", "tests/serializers/test_pickling.py": "import json\nimport pickle\nfrom datetime import timedelta\n\nimport pytest\n\nfrom pydantic_core import core_schema\nfrom pydantic_core._pydantic_core import SchemaSerializer\n\n\ndef repr_function(value, _info):\n    return repr(value)\n\n\ndef test_basic_schema_serializer():\n    s = SchemaSerializer(core_schema.dict_schema())\n    s = pickle.loads(pickle.dumps(s))\n    assert s.to_python({'a': 1, b'b': 2, 33: 3}) == {'a': 1, b'b': 2, 33: 3}\n    assert s.to_python({'a': 1, b'b': 2, 33: 3, True: 4}, mode='json') == {'a': 1, 'b': 2, '33': 3, 'true': 4}\n    assert s.to_json({'a': 1, b'b': 2, 33: 3, True: 4}) == b'{\"a\":1,\"b\":2,\"33\":3,\"true\":4}'\n\n    assert s.to_python({(1, 2): 3}) == {(1, 2): 3}\n    assert s.to_python({(1, 2): 3}, mode='json') == {'1,2': 3}\n    assert s.to_json({(1, 2): 3}) == b'{\"1,2\":3}'\n\n\n@pytest.mark.parametrize(\n    'value,expected_python,expected_json',\n    [(None, 'None', b'\"None\"'), (1, '1', b'\"1\"'), ([1, 2, 3], '[1, 2, 3]', b'\"[1, 2, 3]\"')],\n)\ndef test_schema_serializer_capturing_function(value, expected_python, expected_json):\n    # Test a SchemaSerializer that captures a function.\n    s = SchemaSerializer(\n        core_schema.any_schema(\n            serialization=core_schema.plain_serializer_function_ser_schema(repr_function, info_arg=True)\n        )\n    )\n    s = pickle.loads(pickle.dumps(s))\n    assert s.to_python(value) == expected_python\n    assert s.to_json(value) == expected_json\n    assert s.to_python(value, mode='json') == json.loads(expected_json)\n\n\ndef test_schema_serializer_containing_config():\n    s = SchemaSerializer(core_schema.timedelta_schema(), config={'ser_json_timedelta': 'float'})\n    s = pickle.loads(pickle.dumps(s))\n\n    assert s.to_python(timedelta(seconds=4, microseconds=500_000)) == timedelta(seconds=4, microseconds=500_000)\n    assert s.to_python(timedelta(seconds=4, microseconds=500_000), mode='json') == 4.5\n    assert s.to_json(timedelta(seconds=4, microseconds=500_000)) == b'4.5'\n", "tests/serializers/test_other.py": "import pytest\n\nfrom pydantic_core import SchemaSerializer, SchemaValidator, core_schema\n\nfrom ..conftest import plain_repr\n\n\ndef test_chain():\n    s = SchemaSerializer(core_schema.chain_schema([core_schema.str_schema(), core_schema.int_schema()]))\n\n    # insert_assert(plain_repr(s))\n    assert plain_repr(s) == 'SchemaSerializer(serializer=Int(IntSerializer),definitions=[])'\n\n    assert s.to_python(1) == 1\n    assert s.to_json(1) == b'1'\n\n\ndef test_function_plain():\n    s = SchemaSerializer(core_schema.with_info_plain_validator_function(lambda v, info: v + 1))\n    # can't infer the type from plain function validators\n    # insert_assert(plain_repr(s))\n    assert plain_repr(s) == 'SchemaSerializer(serializer=Any(AnySerializer),definitions=[])'\n\n\ndef test_function_before():\n    s = SchemaSerializer(\n        core_schema.with_info_before_validator_function(lambda v, info: v + 1, core_schema.int_schema())\n    )\n    # insert_assert(plain_repr(s))\n    assert plain_repr(s) == 'SchemaSerializer(serializer=Int(IntSerializer),definitions=[])'\n\n\ndef test_function_after():\n    s = SchemaSerializer(\n        core_schema.with_info_after_validator_function(lambda v, info: v + 1, core_schema.int_schema())\n    )\n    # insert_assert(plain_repr(s))\n    assert plain_repr(s) == 'SchemaSerializer(serializer=Int(IntSerializer),definitions=[])'\n\n\ndef test_lax_or_strict():\n    s = SchemaSerializer(core_schema.lax_or_strict_schema(core_schema.int_schema(), core_schema.str_schema()))\n    # insert_assert(plain_repr(s))\n    assert plain_repr(s) == 'SchemaSerializer(serializer=Str(StrSerializer),definitions=[])'\n\n    assert s.to_json('abc') == b'\"abc\"'\n    with pytest.warns(UserWarning, match='Expected `str` but got `int` - serialized value may not be as expected'):\n        assert s.to_json(123) == b'123'\n\n\ndef test_lax_or_strict_custom_ser():\n    s = SchemaSerializer(\n        core_schema.lax_or_strict_schema(\n            core_schema.int_schema(),\n            core_schema.str_schema(),\n            serialization=core_schema.format_ser_schema('^5s', when_used='always'),\n        )\n    )\n\n    assert s.to_python('abc') == ' abc '\n    assert s.to_python('abc', mode='json') == ' abc '\n    assert s.to_json('abc') == b'\" abc \"'\n\n\ndef test_serialize_with_extra_on_superclass() -> None:\n    class Parent:\n        x: int\n\n    class Other(Parent):\n        y: str\n\n    Parent.__pydantic_core_schema__ = core_schema.model_schema(\n        Parent,\n        core_schema.model_fields_schema(\n            {\n                'x': core_schema.model_field(core_schema.int_schema()),\n            }\n        ),\n        config=core_schema.CoreConfig(extra_fields_behavior='allow'),\n    )\n    Parent.__pydantic_validator__ = SchemaValidator(Parent.__pydantic_core_schema__)\n    Parent.__pydantic_serializer__ = SchemaSerializer(Parent.__pydantic_core_schema__)\n\n    Other.__pydantic_core_schema__ = core_schema.model_schema(\n        Other,\n        core_schema.model_fields_schema(\n            {\n                'x': core_schema.model_field(core_schema.int_schema()),\n                'y': core_schema.model_field(core_schema.str_schema()),\n            }\n        ),\n        config=core_schema.CoreConfig(extra_fields_behavior='forbid'),\n    )\n    Other.__pydantic_validator__ = SchemaValidator(Other.__pydantic_core_schema__)\n    Other.__pydantic_serializer__ = SchemaSerializer(Other.__pydantic_core_schema__)\n\n    other = Other.__pydantic_validator__.validate_python({'x': 1, 'y': 'some string'})\n    assert Parent.__pydantic_serializer__.to_python(other) == {'x': 1}\n", "tests/serializers/test_simple.py": "import json\nfrom enum import IntEnum\n\nimport pytest\n\nfrom pydantic_core import SchemaSerializer, core_schema\n\ntry:\n    import numpy\nexcept ImportError:\n    numpy = None\n\n\nclass IntSubClass(int):\n    pass\n\n\nclass MyIntEnum(IntEnum):\n    one = 1\n    two = 2\n\n\nclass FloatSubClass(float):\n    pass\n\n\n# A number well outside of i64 range\n_BIG_NUMBER_BYTES = b'1' + (b'0' * 40)\n\n\n@pytest.mark.parametrize('custom_type_schema', [None, 'any'])\n@pytest.mark.parametrize(\n    'schema_type,value,expected_python,expected_json',\n    [\n        ('int', 1, 1, b'1'),\n        ('int', int(_BIG_NUMBER_BYTES), int(_BIG_NUMBER_BYTES), _BIG_NUMBER_BYTES),\n        ('bool', True, True, b'true'),\n        ('bool', False, False, b'false'),\n        ('float', 1.0, 1.0, b'1.0'),\n        ('float', 42.31415, 42.31415, b'42.31415'),\n        ('none', None, None, b'null'),\n        ('int', IntSubClass(42), IntSubClass(42), b'42'),\n        ('int', MyIntEnum.one, MyIntEnum.one, b'1'),\n        ('float', FloatSubClass(42), FloatSubClass(42), b'42.0'),\n    ],\n)\ndef test_simple_serializers(schema_type, value, expected_python, expected_json, custom_type_schema):\n    if custom_type_schema is None:\n        schema = {'type': schema_type}\n    else:\n        schema = {'type': custom_type_schema}\n\n    s = SchemaSerializer(schema)\n    v = s.to_python(value)\n    assert v == expected_python\n    assert type(v) == type(expected_python)\n\n    assert s.to_json(value) == expected_json\n\n    v_json = s.to_python(value, mode='json')\n    v_json_expected = json.loads(expected_json)\n    assert v_json == v_json_expected\n    assert type(v_json) == type(v_json_expected)\n\n\ndef test_int_to_float():\n    \"\"\"\n    See https://github.com/pydantic/pydantic-core/pull/866\n    \"\"\"\n    s = SchemaSerializer(core_schema.float_schema())\n    v_plain = s.to_python(1)\n    assert v_plain == 1\n    assert type(v_plain) == int\n\n    v_plain_subclass = s.to_python(IntSubClass(1))\n    assert v_plain_subclass == IntSubClass(1)\n    assert type(v_plain_subclass) == IntSubClass\n\n    v_json = s.to_python(1, mode='json')\n    assert v_json == 1.0\n    assert type(v_json) == float\n\n    v_json_subclass = s.to_python(IntSubClass(1), mode='json')\n    assert v_json_subclass == 1\n    assert type(v_json_subclass) == float\n\n    assert s.to_json(1) == b'1.0'\n    assert s.to_json(IntSubClass(1)) == b'1.0'\n\n\ndef test_int_to_float_key():\n    \"\"\"\n    See https://github.com/pydantic/pydantic-core/pull/866\n    \"\"\"\n    s = SchemaSerializer(core_schema.dict_schema(core_schema.float_schema(), core_schema.float_schema()))\n    v_plain = s.to_python({1: 1})\n    assert v_plain == {1: 1}\n    assert type(list(v_plain.keys())[0]) == int\n    assert type(v_plain[1]) == int\n\n    v_json = s.to_python({1: 1}, mode='json')\n    assert v_json == {'1': 1.0}\n    assert type(v_json['1']) == float\n\n    assert s.to_json({1: 1}) == b'{\"1\":1.0}'\n\n\n@pytest.mark.parametrize('schema_type', ['int', 'bool', 'float', 'none'])\ndef test_simple_serializers_fallback(schema_type):\n    s = SchemaSerializer({'type': schema_type})\n    with pytest.warns(\n        UserWarning, match=f'Expected `{schema_type}` but got `list` - serialized value may not be as expected'\n    ):\n        assert s.to_python([1, 2, 3]) == [1, 2, 3]\n\n    with pytest.warns(\n        UserWarning, match=f'Expected `{schema_type}` but got `list` - serialized value may not be as expected'\n    ):\n        assert s.to_python([1, 2, b'bytes'], mode='json') == [1, 2, 'bytes']\n\n    with pytest.warns(\n        UserWarning, match=f'Expected `{schema_type}` but got `list` - serialized value may not be as expected'\n    ):\n        assert s.to_json([1, 2, 3]) == b'[1,2,3]'\n\n\n@pytest.mark.skipif(numpy is None, reason='numpy is not installed')\ndef test_numpy():\n    s = SchemaSerializer(core_schema.float_schema())\n    v = s.to_python(numpy.float64(1.0))\n    assert v == 1.0\n    assert type(v) == numpy.float64\n\n    v = s.to_python(numpy.float64(1.0), mode='json')\n    assert v == 1.0\n    assert type(v) == float\n\n    assert s.to_json(numpy.float64(1.0)) == b'1.0'\n\n\n@pytest.mark.parametrize(\n    'value,expected_json,config',\n    [\n        # default values of ser_json_inf_nan\n        (float('inf'), 'null', {}),\n        (float('-inf'), 'null', {}),\n        (float('nan'), 'null', {}),\n        # explicit values of ser_json_inf_nan\n        (float('inf'), 'null', {'ser_json_inf_nan': 'null'}),\n        (float('-inf'), 'null', {'ser_json_inf_nan': 'null'}),\n        (float('nan'), 'null', {'ser_json_inf_nan': 'null'}),\n        (float('inf'), 'Infinity', {'ser_json_inf_nan': 'constants'}),\n        (float('-inf'), '-Infinity', {'ser_json_inf_nan': 'constants'}),\n        (float('nan'), 'NaN', {'ser_json_inf_nan': 'constants'}),\n        (float('inf'), '\"Infinity\"', {'ser_json_inf_nan': 'strings'}),\n        (float('-inf'), '\"-Infinity\"', {'ser_json_inf_nan': 'strings'}),\n        (float('nan'), '\"NaN\"', {'ser_json_inf_nan': 'strings'}),\n    ],\n)\ndef test_float_inf_and_nan_serializers(value, expected_json, config):\n    s = SchemaSerializer(core_schema.float_schema(), config)\n\n    # Python can represent these values without needing any changes\n    assert s.to_python(value) is value\n    assert s.to_python(value, mode='json') is value\n\n    # Serialized JSON value respects the ser_json_inf_nan setting\n    assert s.to_json(value).decode() == expected_json\n", "tests/serializers/test_datetime.py": "from datetime import date, datetime, time, timedelta, timezone\n\nimport pytest\n\nfrom pydantic_core import SchemaSerializer, core_schema\n\n\ndef test_datetime():\n    v = SchemaSerializer(core_schema.datetime_schema())\n    assert v.to_python(datetime(2022, 12, 2, 12, 13, 14)) == datetime(2022, 12, 2, 12, 13, 14)\n\n    assert v.to_python(datetime(2022, 12, 2, 12, 13, 14), mode='json') == '2022-12-02T12:13:14'\n    assert v.to_json(datetime(2022, 12, 2, 12, 13, 14)) == b'\"2022-12-02T12:13:14\"'\n\n    with pytest.warns(UserWarning, match='Expected `datetime` but got `int` - serialized value may not be as expected'):\n        assert v.to_python(123, mode='json') == 123\n\n    with pytest.warns(UserWarning, match='Expected `datetime` but got `int` - serialized value may not be as expected'):\n        assert v.to_json(123) == b'123'\n\n\ndef test_datetime_key():\n    v = SchemaSerializer(core_schema.dict_schema(core_schema.datetime_schema(), core_schema.datetime_schema()))\n    assert v.to_python({datetime(2022, 12, 2, 12, 13, 14): datetime(2022, 12, 2, 12, 13, 14)}) == {\n        datetime(2022, 12, 2, 12, 13, 14): datetime(2022, 12, 2, 12, 13, 14)\n    }\n    assert v.to_python({datetime(2022, 12, 2, 12, 13, 14): datetime(2022, 12, 2, 12, 13, 14)}, mode='json') == {\n        '2022-12-02T12:13:14': '2022-12-02T12:13:14'\n    }\n    assert (\n        v.to_json({datetime(2022, 12, 2, 12, 13, 14): datetime(2022, 12, 2, 12, 13, 14)})\n        == b'{\"2022-12-02T12:13:14\":\"2022-12-02T12:13:14\"}'\n    )\n\n\ndef tz(**kwargs):\n    return timezone(timedelta(**kwargs))\n\n\n@pytest.mark.parametrize(\n    'value,expected',\n    [\n        (datetime(2022, 12, 2, 12, 13, 14), '2022-12-02T12:13:14'),\n        (datetime(2022, 12, 2, 12, tzinfo=timezone.utc), '2022-12-02T12:00:00Z'),\n        (datetime(2022, 12, 2, 12, tzinfo=tz(hours=2)), '2022-12-02T12:00:00+02:00'),\n        (datetime(2022, 12, 2, 12, tzinfo=tz(hours=2, minutes=30)), '2022-12-02T12:00:00+02:30'),\n        (datetime(2022, 12, 2, 12, tzinfo=tz(hours=-2)), '2022-12-02T12:00:00-02:00'),\n        (datetime(2022, 12, 2, 12, tzinfo=tz(hours=-2, minutes=-30)), '2022-12-02T12:00:00-02:30'),\n        (datetime(2022, 12, 2, 12, 13, 14, 123456), '2022-12-02T12:13:14.123456'),\n        (datetime(2022, 12, 2, 12, 13, 14, 123), '2022-12-02T12:13:14.000123'),\n        (datetime(2022, 12, 2, 12, 13, 14, 123_000), '2022-12-02T12:13:14.123000'),\n        (datetime(2022, 12, 2, 12, 13, 14, 123456, tzinfo=tz(hours=-2)), '2022-12-02T12:13:14.123456-02:00'),\n    ],\n)\ndef test_datetime_json(value, expected):\n    v = SchemaSerializer(core_schema.datetime_schema())\n    assert v.to_python(value, mode='json') == expected\n    assert v.to_json(value).decode() == f'\"{expected}\"'\n\n\ndef test_date():\n    v = SchemaSerializer(core_schema.date_schema())\n    assert v.to_python(date(2022, 12, 2)) == date(2022, 12, 2)\n\n    assert v.to_python(date(2022, 12, 2), mode='json') == '2022-12-02'\n    assert v.to_json(date(2022, 12, 2)) == b'\"2022-12-02\"'\n\n\ndef test_date_key():\n    v = SchemaSerializer(core_schema.dict_schema(core_schema.date_schema(), core_schema.date_schema()))\n    assert v.to_python({date(2022, 12, 2): date(2022, 12, 2)}) == {date(2022, 12, 2): date(2022, 12, 2)}\n    assert v.to_python({date(2022, 12, 2): date(2022, 12, 2)}, mode='json') == {'2022-12-02': '2022-12-02'}\n    assert v.to_json({date(2022, 12, 2): date(2022, 12, 2)}) == b'{\"2022-12-02\":\"2022-12-02\"}'\n\n\ndef test_time():\n    v = SchemaSerializer(core_schema.time_schema())\n    assert v.to_python(time(12, 13, 14)) == time(12, 13, 14)\n\n    assert v.to_python(time(12, 13, 14), mode='json') == '12:13:14'\n    assert v.to_python(time(12, 13, 14, 123456), mode='json') == '12:13:14.123456'\n\n    assert v.to_json(time(12, 13, 14)) == b'\"12:13:14\"'\n    assert v.to_json(time(12, 13, 14, 123_456)) == b'\"12:13:14.123456\"'\n    assert v.to_json(time(12, 13, 14, 123)) == b'\"12:13:14.000123\"'\n    assert v.to_json(time(12, 13, 14, 123_000)) == b'\"12:13:14.123000\"'\n\n\ndef test_time_key():\n    v = SchemaSerializer(core_schema.dict_schema(core_schema.time_schema(), core_schema.time_schema()))\n    assert v.to_python({time(12, 13, 14): time(12, 13, 14)}) == {time(12, 13, 14): time(12, 13, 14)}\n    assert v.to_python({time(12, 13, 14): time(12, 13, 14)}, mode='json') == {'12:13:14': '12:13:14'}\n    assert v.to_json({time(12, 13, 14): time(12, 13, 14)}) == b'{\"12:13:14\":\"12:13:14\"}'\n\n\ndef test_any_datetime_key():\n    v = SchemaSerializer(core_schema.dict_schema())\n    input_value = {datetime(2022, 12, 2, 12, 13, 14): 1, date(2022, 12, 2): 2, time(12, 13, 14): 3}\n    # assert v.to_python(input_value) == v\n    assert v.to_python(input_value, mode='json') == {'2022-12-02T12:13:14': 1, '2022-12-02': 2, '12:13:14': 3}\n    assert v.to_json(input_value) == b'{\"2022-12-02T12:13:14\":1,\"2022-12-02\":2,\"12:13:14\":3}'\n\n\ndef test_date_datetime_union():\n    # See https://github.com/pydantic/pydantic/issues/7039#issuecomment-1671986746\n    v = SchemaSerializer(core_schema.union_schema([core_schema.date_schema(), core_schema.datetime_schema()]))\n    assert v.to_python(datetime(2022, 12, 2, 1)) == datetime(2022, 12, 2, 1)\n    assert v.to_python(datetime(2022, 12, 2, 1), mode='json') == '2022-12-02T01:00:00'\n    assert v.to_json(datetime(2022, 12, 2, 1)) == b'\"2022-12-02T01:00:00\"'\n", "tests/serializers/test_format.py": "import json\nimport re\nfrom datetime import date\nfrom uuid import UUID\n\nimport pytest\n\nfrom pydantic_core import PydanticSerializationError, SchemaSerializer, core_schema\n\n\n@pytest.mark.parametrize(\n    'value,formatting_string,expected_python,expected_json',\n    [\n        (42.12345, '0.4f', 42.12345, b'\"42.1234\"'),\n        (42.12, '0.4f', 42.12, b'\"42.1200\"'),\n        (42.12, '', 42.12, b'\"42.12\"'),\n        (42.1234567, '', 42.1234567, b'\"42.1234567\"'),\n        (date(2022, 11, 20), '%Y-%m-%d', date(2022, 11, 20), b'\"2022-11-20\"'),\n        ('foo', '^5s', 'foo', b'\" foo \"'),\n        (\n            UUID('ebcdab58-6eb8-46fb-a190-d07a33e9eac8'),\n            '',\n            UUID('ebcdab58-6eb8-46fb-a190-d07a33e9eac8'),\n            b'\"ebcdab58-6eb8-46fb-a190-d07a33e9eac8\"',\n        ),\n    ],\n)\ndef test_format(value, formatting_string, expected_python, expected_json):\n    s = SchemaSerializer(core_schema.any_schema(serialization=core_schema.format_ser_schema(formatting_string)))\n    assert s.to_python(value) == expected_python\n    assert s.to_json(value) == expected_json\n    assert s.to_python(value, mode='json') == json.loads(expected_json)\n\n\ndef test_format_when_used_unless_none():\n    s = SchemaSerializer(\n        core_schema.any_schema(serialization=core_schema.format_ser_schema('0.1f', when_used='unless-none'))\n    )\n    assert 'FormatSerializer' in repr(s)\n    assert 'ToStringSerializer' not in repr(s)\n    assert s.to_python(42.12345) == '42.1'\n    assert s.to_python(42.12345, mode='json') == '42.1'\n    assert s.to_json(42.12345) == b'\"42.1\"'\n\n\ndef test_format_when_used_json():\n    s = SchemaSerializer(core_schema.any_schema(serialization=core_schema.format_ser_schema('0.1f', when_used='json')))\n    assert s.to_python(42.12345) == 42.12345\n    assert s.to_python(None) is None\n    assert s.to_python(42.12345, mode='json') == '42.1'\n    assert s.to_json(42.12345) == b'\"42.1\"'\n    # fails because you can't format `None`\n    with pytest.raises(PydanticSerializationError, match=r'Error calling `format\\(value, \\'0.1f\\'\\)`: TypeError:'):\n        s.to_json(None)\n\n\ndef test_to_string_when_used_always():\n    s = SchemaSerializer(core_schema.any_schema(serialization=core_schema.format_ser_schema('', when_used='always')))\n    assert s.to_python(123) == '123'\n    assert s.to_python(None) == 'None'\n    assert s.to_python(123, mode='json') == '123'\n    assert s.to_python(None, mode='json') == 'None'\n    assert s.to_json(None) == b'\"None\"'\n    assert s.to_json(123) == b'\"123\"'\n\n\ndef test_to_string_when_used_unless_none():\n    s = SchemaSerializer(\n        core_schema.any_schema(serialization=core_schema.format_ser_schema('', when_used='unless-none'))\n    )\n    assert 'ToStringSerializer' in repr(s)\n    assert 'FormatSerializer' not in repr(s)\n    assert s.to_python(42) == '42'\n    assert s.to_python(42, mode='json') == '42'\n    assert s.to_json(42) == b'\"42\"'\n\n\ndef test_format_error():\n    s = SchemaSerializer(core_schema.any_schema(serialization=core_schema.format_ser_schema('^5d')))\n    assert s.to_python(123) == 123\n\n    # the actual error message differs slightly between cpython and pypy\n    msg = \"Error calling `format(value, '^5d')`: ValueError:\"\n    with pytest.raises(PydanticSerializationError, match=re.escape(msg)):\n        s.to_python('x', mode='json')\n\n    with pytest.raises(PydanticSerializationError, match=re.escape(msg)):\n        s.to_json('x')\n\n\ndef test_dict_keys():\n    s = SchemaSerializer(\n        core_schema.dict_schema(core_schema.float_schema(serialization=core_schema.format_ser_schema('0.4f')))\n    )\n    assert s.to_python({1: True}, mode='json') == {'1.0000': True}\n\n\ndef test_format_fallback():\n    s = SchemaSerializer(core_schema.any_schema(serialization=core_schema.format_ser_schema('^5s')))\n    assert s.to_python('abc') == 'abc'\n    assert s.to_python('abc', mode='json') == ' abc '\n    assert s.to_json('abc') == b'\" abc \"'\n\n    assert s.to_python(None) is None\n    assert s.to_python(None, mode='json') is None\n    assert s.to_json(None) == b'null'\n\n\nclass BrokenToString:\n    def __str__(self):\n        raise ValueError('broken')\n\n    def __repr__(self):\n        return 'BrokenToString()'\n\n\ndef test_to_string():\n    s = SchemaSerializer(core_schema.any_schema(serialization={'type': 'to-string'}))\n    assert s.to_python(123, mode='json') == '123'\n    assert s.to_python(None, mode='json') is None\n    uuid = UUID('ebcdab58-6eb8-46fb-a190-d07a33e9eac8')\n    assert s.to_python(uuid, mode='json') == str(uuid)\n    assert s.to_json(uuid) == b'\"%s\"' % str(uuid).encode('utf-8')\n    with pytest.raises(ValueError, match='broken'):\n        s.to_python(BrokenToString(), mode='json')\n", "tests/serializers/test_typed_dict.py": "import json\nfrom typing import Any, Dict\n\nimport pytest\nfrom dirty_equals import IsStrictDict\nfrom typing_extensions import TypedDict\n\nfrom pydantic_core import SchemaSerializer, core_schema\n\n\n@pytest.mark.parametrize('extra_behavior_kw', [{}, {'extra_behavior': 'ignore'}, {'extra_behavior': None}])\ndef test_typed_dict(extra_behavior_kw: Dict[str, Any]):\n    v = SchemaSerializer(\n        core_schema.typed_dict_schema(\n            {\n                'foo': core_schema.typed_dict_field(core_schema.int_schema()),\n                'bar': core_schema.typed_dict_field(core_schema.bytes_schema()),\n            },\n            **extra_behavior_kw,\n        )\n    )\n    assert v.to_python({'foo': 1, 'bar': b'more'}) == IsStrictDict(foo=1, bar=b'more')\n    assert v.to_python({'bar': b'more', 'foo': 1}) == IsStrictDict(bar=b'more', foo=1)\n    assert v.to_python({'foo': 1, 'bar': b'more', 'c': 3}) == IsStrictDict(foo=1, bar=b'more')\n    assert v.to_python({'bar': b'more', 'foo': 1, 'c': 3}, mode='json') == IsStrictDict(bar='more', foo=1)\n\n    assert v.to_json({'bar': b'more', 'foo': 1, 'c': 3}) == b'{\"bar\":\"more\",\"foo\":1}'\n\n\ndef test_typed_dict_fields_has_type():\n    typed_dict_field = core_schema.typed_dict_field(core_schema.bytes_schema())\n\n    assert typed_dict_field['type'] == 'typed-dict-field'\n\n\ndef test_typed_dict_allow_extra():\n    v = SchemaSerializer(\n        core_schema.typed_dict_schema(\n            {\n                'foo': core_schema.typed_dict_field(core_schema.int_schema()),\n                'bar': core_schema.typed_dict_field(core_schema.bytes_schema()),\n            },\n            extra_behavior='allow',\n        )\n    )\n    # extra fields go last but retain their order\n    assert v.to_python({'bar': b'more', 'b': 3, 'foo': 1, 'a': 4}) == IsStrictDict(bar=b'more', b=3, foo=1, a=4)\n    assert v.to_python({'bar': b'more', 'c': 3, 'foo': 1}, mode='json') == IsStrictDict(bar='more', c=3, foo=1)\n\n    assert v.to_json({'bar': b'more', 'c': 3, 'foo': 1, 'cc': 4}) == b'{\"bar\":\"more\",\"c\":3,\"foo\":1,\"cc\":4}'\n\n\n@pytest.mark.parametrize(\n    'params',\n    [\n        dict(include=None, exclude=None, expected={'0': 0, '1': 1, '2': 2, '3': 3}),\n        dict(include={'0', '1'}, exclude=None, expected={'0': 0, '1': 1}),\n        dict(include={'0': ..., '1': ...}, exclude=None, expected={'0': 0, '1': 1}),\n        dict(include={'0': {1}, '1': {1}}, exclude=None, expected={'0': 0, '1': 1}),\n        dict(include=None, exclude={'0', '1'}, expected={'2': 2, '3': 3}),\n        dict(include=None, exclude={'0': ..., '1': ...}, expected={'2': 2, '3': 3}),\n        dict(include={'0', '1'}, exclude={'1', '2'}, expected={'0': 0}),\n        dict(include=None, exclude={'3': {1}}, expected={'0': 0, '1': 1, '2': 2, '3': 3}),\n        dict(include={'0', '1'}, exclude={'3': {1}}, expected={'0': 0, '1': 1}),\n        dict(include={'0', '1'}, exclude={'1': {1}}, expected={'0': 0, '1': 1}),\n        dict(include={'0', '1'}, exclude={'1': ...}, expected={'0': 0}),\n    ],\n)\ndef test_include_exclude_args(params):\n    s = SchemaSerializer(\n        core_schema.typed_dict_schema(\n            {\n                '0': core_schema.typed_dict_field(core_schema.int_schema()),\n                '1': core_schema.typed_dict_field(core_schema.int_schema()),\n                '2': core_schema.typed_dict_field(core_schema.int_schema()),\n                '3': core_schema.typed_dict_field(core_schema.int_schema()),\n            }\n        )\n    )\n\n    # user IsStrictDict to check dict order\n    include, exclude, expected = params['include'], params['exclude'], IsStrictDict(params['expected'])\n    value = {'0': 0, '1': 1, '2': 2, '3': 3}\n    assert s.to_python(value, include=include, exclude=exclude) == expected\n    assert s.to_python(value, mode='json', include=include, exclude=exclude) == expected\n    assert json.loads(s.to_json(value, include=include, exclude=exclude)) == expected\n\n\ndef test_include_exclude_schema():\n    s = SchemaSerializer(\n        core_schema.typed_dict_schema(\n            {\n                '0': core_schema.typed_dict_field(core_schema.int_schema(), serialization_exclude=True),\n                '1': core_schema.typed_dict_field(core_schema.int_schema()),\n                '2': core_schema.typed_dict_field(core_schema.int_schema(), serialization_exclude=True),\n                '3': core_schema.typed_dict_field(core_schema.int_schema(), serialization_exclude=False),\n            }\n        )\n    )\n    value = {'0': 0, '1': 1, '2': 2, '3': 3}\n    assert s.to_python(value) == {'1': 1, '3': 3}\n    assert s.to_python(value, mode='json') == {'1': 1, '3': 3}\n    assert json.loads(s.to_json(value)) == {'1': 1, '3': 3}\n\n\ndef test_alias():\n    s = SchemaSerializer(\n        core_schema.typed_dict_schema(\n            {\n                'cat': core_schema.typed_dict_field(core_schema.int_schema(), serialization_alias='Meow'),\n                'dog': core_schema.typed_dict_field(core_schema.int_schema(), serialization_alias='Woof'),\n                'bird': core_schema.typed_dict_field(core_schema.int_schema()),\n            }\n        )\n    )\n    value = {'cat': 0, 'dog': 1, 'bird': 2}\n    assert s.to_python(value) == IsStrictDict(Meow=0, Woof=1, bird=2)\n    assert s.to_python(value, exclude={'dog'}) == IsStrictDict(Meow=0, bird=2)\n    assert s.to_python(value, by_alias=False) == IsStrictDict(cat=0, dog=1, bird=2)\n\n    assert s.to_python(value, mode='json') == IsStrictDict(Meow=0, Woof=1, bird=2)\n    assert s.to_python(value, mode='json', include={'cat'}) == IsStrictDict(Meow=0)\n    assert s.to_python(value, mode='json', by_alias=False) == IsStrictDict(cat=0, dog=1, bird=2)\n\n    assert json.loads(s.to_json(value)) == IsStrictDict(Meow=0, Woof=1, bird=2)\n    assert json.loads(s.to_json(value, include={'cat', 'bird'})) == IsStrictDict(Meow=0, bird=2)\n    assert json.loads(s.to_json(value, by_alias=False)) == IsStrictDict(cat=0, dog=1, bird=2)\n\n\ndef test_exclude_none():\n    v = SchemaSerializer(\n        core_schema.typed_dict_schema(\n            {\n                'foo': core_schema.typed_dict_field(core_schema.nullable_schema(core_schema.int_schema())),\n                'bar': core_schema.typed_dict_field(core_schema.bytes_schema()),\n            },\n            extra_behavior='allow',\n        )\n    )\n    assert v.to_python({'foo': 1, 'bar': b'more', 'c': 3}) == {'foo': 1, 'bar': b'more', 'c': 3}\n    assert v.to_python({'foo': None, 'bar': b'more', 'c': None}) == {'foo': None, 'bar': b'more', 'c': None}\n    assert v.to_python({'foo': None, 'bar': b'more', 'c': None}, exclude_none=True) == {'bar': b'more'}\n\n    assert v.to_python({'foo': None, 'bar': b'more', 'c': None}, mode='json') == {'foo': None, 'bar': 'more', 'c': None}\n    assert v.to_python({'foo': None, 'bar': b'more', 'c': None}, mode='json', exclude_none=True) == {'bar': 'more'}\n\n    assert v.to_json({'foo': 1, 'bar': b'more', 'c': None}) == b'{\"foo\":1,\"bar\":\"more\",\"c\":null}'\n    assert v.to_json({'foo': None, 'bar': b'more'}) == b'{\"foo\":null,\"bar\":\"more\"}'\n    assert v.to_json({'foo': None, 'bar': b'more', 'c': None}, exclude_none=True) == b'{\"bar\":\"more\"}'\n\n\ndef test_exclude_default():\n    v = SchemaSerializer(\n        core_schema.typed_dict_schema(\n            {\n                'foo': core_schema.typed_dict_field(core_schema.nullable_schema(core_schema.int_schema())),\n                'bar': core_schema.typed_dict_field(\n                    core_schema.with_default_schema(core_schema.bytes_schema(), default=b'[default]')\n                ),\n            }\n        )\n    )\n    assert v.to_python({'foo': 1, 'bar': b'x'}) == {'foo': 1, 'bar': b'x'}\n    assert v.to_python({'foo': 1, 'bar': b'[default]'}) == {'foo': 1, 'bar': b'[default]'}\n    assert v.to_python({'foo': 1, 'bar': b'[default]'}, exclude_defaults=True) == {'foo': 1}\n    assert v.to_python({'foo': 1, 'bar': b'[default]'}, mode='json') == {'foo': 1, 'bar': '[default]'}\n    assert v.to_python({'foo': 1, 'bar': b'[default]'}, exclude_defaults=True, mode='json') == {'foo': 1}\n\n    assert v.to_json({'foo': 1, 'bar': b'[default]'}) == b'{\"foo\":1,\"bar\":\"[default]\"}'\n    assert v.to_json({'foo': 1, 'bar': b'[default]'}, exclude_defaults=True) == b'{\"foo\":1}'\n\n\ndef test_function_plain_field_serializer_to_python():\n    class Model(TypedDict):\n        x: int\n\n    def ser_x(data: Model, v: Any, _) -> str:\n        assert data['x'] == 1_000\n        return f'{v:_}'\n\n    s = SchemaSerializer(\n        core_schema.typed_dict_schema(\n            {\n                'x': core_schema.typed_dict_field(\n                    core_schema.int_schema(\n                        serialization=core_schema.plain_serializer_function_ser_schema(\n                            ser_x, is_field_serializer=True, info_arg=True\n                        )\n                    )\n                )\n            }\n        )\n    )\n    assert s.to_python(Model(x=1000)) == {'x': '1_000'}\n\n\ndef test_function_wrap_field_serializer_to_python():\n    class Model(TypedDict):\n        x: int\n\n    def ser_x(data: Model, v: Any, serializer: core_schema.SerializerFunctionWrapHandler, _) -> str:\n        x = serializer(v)\n        assert data['x'] == 1_000\n        return f'{x:_}'\n\n    s = SchemaSerializer(\n        core_schema.typed_dict_schema(\n            {\n                'x': core_schema.typed_dict_field(\n                    core_schema.int_schema(\n                        serialization=core_schema.wrap_serializer_function_ser_schema(\n                            ser_x, is_field_serializer=True, info_arg=True, schema=core_schema.any_schema()\n                        )\n                    )\n                )\n            }\n        )\n    )\n    assert s.to_python(Model(x=1000)) == {'x': '1_000'}\n\n\ndef test_function_plain_field_serializer_to_json():\n    class Model(TypedDict):\n        x: int\n\n    def ser_x(data: Model, v: Any, info: core_schema.FieldSerializationInfo) -> str:\n        assert data['x'] == 1_000\n        return f'{v:_}-{info.field_name}'\n\n    s = SchemaSerializer(\n        core_schema.typed_dict_schema(\n            {\n                'x': core_schema.typed_dict_field(\n                    core_schema.int_schema(\n                        serialization=core_schema.plain_serializer_function_ser_schema(\n                            ser_x, is_field_serializer=True, info_arg=True\n                        )\n                    )\n                )\n            }\n        )\n    )\n    assert json.loads(s.to_json(Model(x=1000))) == {'x': '1_000-x'}\n\n\ndef test_function_plain_field_serializer_to_json_no_info():\n    class Model(TypedDict):\n        x: int\n\n    def ser_x(data: Model, v: Any) -> str:\n        assert data['x'] == 1_000\n        return f'{v:_}'\n\n    s = SchemaSerializer(\n        core_schema.typed_dict_schema(\n            {\n                'x': core_schema.typed_dict_field(\n                    core_schema.int_schema(\n                        serialization=core_schema.plain_serializer_function_ser_schema(ser_x, is_field_serializer=True)\n                    )\n                )\n            }\n        )\n    )\n    assert json.loads(s.to_json(Model(x=1000))) == {'x': '1_000'}\n\n\ndef test_function_wrap_field_serializer_to_json():\n    class Model(TypedDict):\n        x: int\n\n    def ser_x(\n        data: Model,\n        v: Any,\n        serializer: core_schema.SerializerFunctionWrapHandler,\n        info: core_schema.FieldSerializationInfo,\n    ) -> str:\n        assert data['x'] == 1_000\n        x = serializer(v)\n        return f'{x:_}-{info.field_name}'\n\n    s = SchemaSerializer(\n        core_schema.typed_dict_schema(\n            {\n                'x': core_schema.typed_dict_field(\n                    core_schema.int_schema(\n                        serialization=core_schema.wrap_serializer_function_ser_schema(\n                            ser_x, is_field_serializer=True, info_arg=True, schema=core_schema.any_schema()\n                        )\n                    )\n                )\n            }\n        )\n    )\n    assert json.loads(s.to_json(Model(x=1000))) == {'x': '1_000-x'}\n\n\ndef test_function_wrap_field_serializer_to_json_no_info():\n    class Model(TypedDict):\n        x: int\n\n    def ser_x(data: Model, v: Any, serializer: core_schema.SerializerFunctionWrapHandler) -> str:\n        assert data['x'] == 1_000\n        x = serializer(v)\n        return f'{x:_}'\n\n    s = SchemaSerializer(\n        core_schema.typed_dict_schema(\n            {\n                'x': core_schema.typed_dict_field(\n                    core_schema.int_schema(\n                        serialization=core_schema.wrap_serializer_function_ser_schema(\n                            ser_x, is_field_serializer=True, schema=core_schema.any_schema()\n                        )\n                    )\n                )\n            }\n        )\n    )\n    assert json.loads(s.to_json(Model(x=1000))) == {'x': '1_000'}\n\n\ndef test_extra_custom_serializer():\n    schema = core_schema.typed_dict_schema(\n        {},\n        extra_behavior='allow',\n        extras_schema=core_schema.any_schema(\n            serialization=core_schema.plain_serializer_function_ser_schema(lambda v: v + ' bam!')\n        ),\n    )\n    s = SchemaSerializer(schema)\n\n    m = {'extra': 'extra'}\n\n    assert s.to_python(m) == {'extra': 'extra bam!'}\n", "tests/serializers/test_serialize_as_any.py": "from dataclasses import dataclass\n\nfrom typing_extensions import TypedDict\n\nfrom pydantic_core import SchemaSerializer, SchemaValidator, core_schema\n\n\ndef test_serialize_as_any_with_models() -> None:\n    class Parent:\n        x: int\n\n    class Child(Parent):\n        y: str\n\n    Parent.__pydantic_core_schema__ = core_schema.model_schema(\n        Parent,\n        core_schema.model_fields_schema(\n            {\n                'x': core_schema.model_field(core_schema.int_schema()),\n            }\n        ),\n    )\n    Parent.__pydantic_validator__ = SchemaValidator(Parent.__pydantic_core_schema__)\n    Parent.__pydantic_serializer__ = SchemaSerializer(Parent.__pydantic_core_schema__)\n\n    Child.__pydantic_core_schema__ = core_schema.model_schema(\n        Child,\n        core_schema.model_fields_schema(\n            {\n                'x': core_schema.model_field(core_schema.int_schema()),\n                'y': core_schema.model_field(core_schema.str_schema()),\n            }\n        ),\n    )\n    Child.__pydantic_validator__ = SchemaValidator(Child.__pydantic_core_schema__)\n    Child.__pydantic_serializer__ = SchemaSerializer(Child.__pydantic_core_schema__)\n\n    child = Child.__pydantic_validator__.validate_python({'x': 1, 'y': 'hopefully not a secret'})\n    assert Parent.__pydantic_serializer__.to_python(child, serialize_as_any=False) == {'x': 1}\n    assert Parent.__pydantic_serializer__.to_python(child, serialize_as_any=True) == {\n        'x': 1,\n        'y': 'hopefully not a secret',\n    }\n\n\ndef test_serialize_as_any_with_dataclass() -> None:\n    @dataclass\n    class Parent:\n        x: int\n\n    class Child(Parent):\n        y: str\n\n    Parent.__pydantic_core_schema__ = core_schema.dataclass_schema(\n        Parent,\n        core_schema.dataclass_args_schema(\n            'Parent',\n            [\n                core_schema.dataclass_field(name='x', schema=core_schema.int_schema()),\n            ],\n        ),\n        ['x'],\n    )\n    Parent.__pydantic_validator__ = SchemaValidator(Parent.__pydantic_core_schema__)\n    Parent.__pydantic_serializer__ = SchemaSerializer(Parent.__pydantic_core_schema__)\n\n    Child.__pydantic_core_schema__ = core_schema.dataclass_schema(\n        Child,\n        core_schema.dataclass_args_schema(\n            'Child',\n            [\n                core_schema.dataclass_field(name='x', schema=core_schema.int_schema()),\n                core_schema.dataclass_field(name='y', schema=core_schema.str_schema()),\n            ],\n        ),\n        ['x', 'y'],\n    )\n    Child.__pydantic_validator__ = SchemaValidator(Child.__pydantic_core_schema__)\n    Child.__pydantic_serializer__ = SchemaSerializer(Child.__pydantic_core_schema__)\n\n    child = Child.__pydantic_validator__.validate_python({'x': 1, 'y': 'hopefully not a secret'})\n    assert Parent.__pydantic_serializer__.to_python(child, serialize_as_any=False) == {'x': 1}\n    assert Parent.__pydantic_serializer__.to_python(child, serialize_as_any=True) == {\n        'x': 1,\n        'y': 'hopefully not a secret',\n    }\n\n\ndef test_serialize_as_any_with_typeddict() -> None:\n    class Parent(TypedDict):\n        x: int\n\n    class Child(Parent):\n        y: str\n\n    Parent.__pydantic_core_schema__ = core_schema.typed_dict_schema(\n        {\n            'x': core_schema.typed_dict_field(core_schema.int_schema()),\n        }\n    )\n    Parent.__pydantic_validator__ = SchemaValidator(Parent.__pydantic_core_schema__)\n    Parent.__pydantic_serializer__ = SchemaSerializer(Parent.__pydantic_core_schema__)\n\n    Child.__pydantic_core_schema__ = core_schema.typed_dict_schema(\n        {\n            'x': core_schema.typed_dict_field(core_schema.int_schema()),\n            'y': core_schema.typed_dict_field(core_schema.str_schema()),\n        }\n    )\n    Child.__pydantic_validator__ = SchemaValidator(Child.__pydantic_core_schema__)\n    Child.__pydantic_serializer__ = SchemaSerializer(Child.__pydantic_core_schema__)\n\n    child = Child.__pydantic_validator__.validate_python({'x': 1, 'y': 'hopefully not a secret'})\n    assert Parent.__pydantic_serializer__.to_python(child, serialize_as_any=False) == {'x': 1}\n    assert Parent.__pydantic_serializer__.to_python(child, serialize_as_any=True) == {\n        'x': 1,\n        'y': 'hopefully not a secret',\n    }\n\n\ndef test_serialize_as_any_with_unrelated_models() -> None:\n    class Parent:\n        x: int\n\n    class Other:\n        y: str\n\n    Parent.__pydantic_core_schema__ = core_schema.model_schema(\n        Parent,\n        core_schema.model_fields_schema(\n            {\n                'x': core_schema.model_field(core_schema.int_schema()),\n            }\n        ),\n    )\n    Parent.__pydantic_validator__ = SchemaValidator(Parent.__pydantic_core_schema__)\n    Parent.__pydantic_serializer__ = SchemaSerializer(Parent.__pydantic_core_schema__)\n\n    Other.__pydantic_core_schema__ = core_schema.model_schema(\n        Other,\n        core_schema.model_fields_schema(\n            {\n                'y': core_schema.model_field(core_schema.str_schema()),\n            }\n        ),\n        config=core_schema.CoreConfig(extra_fields_behavior='allow'),\n    )\n    Other.__pydantic_validator__ = SchemaValidator(Other.__pydantic_core_schema__)\n    Other.__pydantic_serializer__ = SchemaSerializer(Other.__pydantic_core_schema__)\n\n    other = Other.__pydantic_validator__.validate_python({'x': 1, 'y': 'hopefully not a secret'})\n    assert Parent.__pydantic_serializer__.to_python(other, serialize_as_any=False) == {}\n    # note, without extra='allow', the 'x' field would not be included, as it's not in the schema\n    assert Parent.__pydantic_serializer__.to_python(other, serialize_as_any=True) == {\n        'x': 1,\n        'y': 'hopefully not a secret',\n    }\n", "tests/serializers/test_set_frozenset.py": "import json\n\nimport pytest\nfrom dirty_equals import IsList\n\nfrom pydantic_core import SchemaSerializer, core_schema\n\n\ndef test_set_any():\n    v = SchemaSerializer(core_schema.set_schema(core_schema.any_schema()))\n    assert v.to_python({'a', 'b', 'c'}) == {'a', 'b', 'c'}\n    assert v.to_python({'a', 'b', 'c'}, mode='json') == IsList('a', 'b', 'c', check_order=False)\n    assert json.loads(v.to_json({'a', 'b', 'c'})) == IsList('a', 'b', 'c', check_order=False)\n\n\ndef test_frozenset_any():\n    v = SchemaSerializer(core_schema.frozenset_schema(core_schema.any_schema()))\n    fs = frozenset(['a', 'b', 'c'])\n    output = v.to_python(fs)\n    assert output == {'a', 'b', 'c'}\n    assert type(output) == frozenset\n    assert v.to_python(fs, mode='json') == IsList('a', 'b', 'c', check_order=False)\n    assert json.loads(v.to_json(fs)) == IsList('a', 'b', 'c', check_order=False)\n\n\n@pytest.mark.parametrize(\n    'input_value,json_output,warning_type',\n    [\n        ('apple', 'apple', r'`set\\[int\\]` but got `str`'),\n        ([1, 2, 3], [1, 2, 3], r'`set\\[int\\]` but got `list`'),\n        ((1, 2, 3), [1, 2, 3], r'`set\\[int\\]` but got `tuple`'),\n        (frozenset([1, 2, 3]), IsList(1, 2, 3, check_order=False), r'`set\\[int\\]` but got `frozenset`'),\n        ({1, 2, 'a'}, IsList(1, 2, 'a', check_order=False), '`int` but got `str`'),\n    ],\n)\ndef test_set_fallback(input_value, json_output, warning_type):\n    v = SchemaSerializer(core_schema.set_schema(core_schema.int_schema()))\n    assert v.to_python({1, 2, 3}) == {1, 2, 3}\n\n    with pytest.warns(UserWarning, match=f'Expected {warning_type} - serialized value may not be as expected'):\n        assert v.to_python(input_value) == input_value\n\n    with pytest.warns(UserWarning, match=f'Expected {warning_type} - serialized value may not be as expected'):\n        assert v.to_python(input_value, mode='json') == json_output\n\n    with pytest.warns(UserWarning, match=f'Expected {warning_type} - serialized value may not be as expected'):\n        assert json.loads(v.to_json(input_value)) == json_output\n", "tests/serializers/test_functions.py": "import json\nimport platform\nimport re\nimport sys\nfrom collections import deque\nfrom operator import attrgetter\nfrom pathlib import Path\n\nimport pytest\n\nfrom pydantic_core import (\n    PydanticOmit,\n    PydanticSerializationError,\n    PydanticSerializationUnexpectedValue,\n    SchemaSerializer,\n    core_schema,\n)\n\n\ndef repr_function(value, _info):\n    return repr(value)\n\n\n@pytest.mark.parametrize(\n    'value,expected_python,expected_json',\n    [(None, 'None', b'\"None\"'), (1, '1', b'\"1\"'), ([1, 2, 3], '[1, 2, 3]', b'\"[1, 2, 3]\"')],\n)\ndef test_function_general(value, expected_python, expected_json):\n    s = SchemaSerializer(\n        core_schema.any_schema(\n            serialization=core_schema.plain_serializer_function_ser_schema(repr_function, info_arg=True)\n        )\n    )\n    assert s.to_python(value) == expected_python\n    assert s.to_json(value) == expected_json\n    assert s.to_python(value, mode='json') == json.loads(expected_json)\n\n\ndef repr_function_no_info(value):\n    return repr(value)\n\n\n@pytest.mark.parametrize(\n    'value,expected_python,expected_json',\n    [(None, 'None', b'\"None\"'), (1, '1', b'\"1\"'), ([1, 2, 3], '[1, 2, 3]', b'\"[1, 2, 3]\"')],\n)\ndef test_function_no_info(value, expected_python, expected_json):\n    s = SchemaSerializer(\n        core_schema.any_schema(serialization=core_schema.plain_serializer_function_ser_schema(repr_function_no_info))\n    )\n    assert s.to_python(value) == expected_python\n    assert s.to_json(value) == expected_json\n    assert s.to_python(value, mode='json') == json.loads(expected_json)\n\n\ndef test_function_args():\n    f_info = None\n\n    def double(value, info):\n        nonlocal f_info\n        f_info = vars(info)\n        return value * 2\n\n    s = SchemaSerializer(\n        core_schema.any_schema(serialization=core_schema.plain_serializer_function_ser_schema(double, info_arg=True))\n    )\n    assert s.to_python(4) == 8\n    # insert_assert(f_info)\n    assert f_info == {\n        'mode': 'python',\n        'by_alias': True,\n        'exclude_unset': False,\n        'exclude_defaults': False,\n        'exclude_none': False,\n        'round_trip': False,\n        'serialize_as_any': False,\n    }\n    assert s.to_python('x') == 'xx'\n\n    assert s.to_python(4, mode='foobar') == 8\n    # insert_assert(f_info)\n    assert f_info == {\n        'mode': 'foobar',\n        'by_alias': True,\n        'exclude_unset': False,\n        'exclude_defaults': False,\n        'exclude_none': False,\n        'round_trip': False,\n        'serialize_as_any': False,\n    }\n\n    assert s.to_json(42) == b'84'\n    # insert_assert(f_info)\n    assert f_info == {\n        'mode': 'json',\n        'by_alias': True,\n        'exclude_unset': False,\n        'exclude_defaults': False,\n        'exclude_none': False,\n        'round_trip': False,\n        'serialize_as_any': False,\n    }\n\n    assert s.to_python(7, mode='json', by_alias=False, exclude_unset=True) == 14\n    # insert_assert(f_info)\n    assert f_info == {\n        'mode': 'json',\n        'by_alias': False,\n        'exclude_unset': True,\n        'exclude_defaults': False,\n        'exclude_none': False,\n        'round_trip': False,\n        'serialize_as_any': False,\n    }\n\n    assert s.to_python(1, include={1, 2, 3}, exclude={'foo': {'bar'}}) == 2\n    # insert_assert(f_info)\n    assert f_info == {\n        'include': {3, 2, 1},\n        'exclude': {'foo': {'bar'}},\n        'mode': 'python',\n        'by_alias': True,\n        'exclude_unset': False,\n        'exclude_defaults': False,\n        'exclude_none': False,\n        'round_trip': False,\n        'serialize_as_any': False,\n    }\n\n    assert s.to_python(1, context='context') == 2\n    # insert_assert(f_info)\n    assert f_info == {\n        'context': 'context',\n        'mode': 'python',\n        'by_alias': True,\n        'exclude_unset': False,\n        'exclude_defaults': False,\n        'exclude_none': False,\n        'round_trip': False,\n        'serialize_as_any': False,\n    }\n\n\ndef test_function_error():\n    def raise_error(value, _info):\n        raise TypeError('foo')\n\n    s = SchemaSerializer(\n        core_schema.any_schema(\n            serialization=core_schema.plain_serializer_function_ser_schema(raise_error, info_arg=True)\n        )\n    )\n\n    msg = 'Error calling function `raise_error`: TypeError: foo$'\n    with pytest.raises(PydanticSerializationError, match=msg) as exc_info:\n        s.to_python('abc')\n    assert isinstance(exc_info.value.__cause__, TypeError)\n\n    with pytest.raises(PydanticSerializationError, match=msg) as exc_info:\n        s.to_python('abc', mode='json')\n    assert isinstance(exc_info.value.__cause__, TypeError)\n\n    with pytest.raises(PydanticSerializationError, match=msg):\n        s.to_json('foo')\n\n\ndef test_function_error_keys():\n    def raise_error(value, _info):\n        raise TypeError('foo')\n\n    s = SchemaSerializer(\n        core_schema.dict_schema(\n            core_schema.any_schema(\n                serialization=core_schema.plain_serializer_function_ser_schema(raise_error, info_arg=True)\n            ),\n            core_schema.int_schema(),\n        )\n    )\n\n    msg = 'Error calling function `raise_error`: TypeError: foo$'\n    with pytest.raises(PydanticSerializationError, match=msg) as exc_info:\n        s.to_python({'abc': 1})\n    assert isinstance(exc_info.value.__cause__, TypeError)\n\n    with pytest.raises(PydanticSerializationError, match=msg) as exc_info:\n        s.to_python({'abc': 1}, mode='json')\n    assert isinstance(exc_info.value.__cause__, TypeError)\n\n    with pytest.raises(PydanticSerializationError, match=msg):\n        s.to_json({'abc': 1})\n\n\ndef test_function_known_type():\n    def append_42(value, _info):\n        if isinstance(value, list):\n            value.append(42)\n        return value\n\n    s = SchemaSerializer(\n        core_schema.any_schema(\n            serialization=core_schema.plain_serializer_function_ser_schema(\n                append_42, info_arg=True, return_schema=core_schema.list_schema(core_schema.int_schema())\n            )\n        )\n    )\n    assert s.to_python([1, 2, 3]) == [1, 2, 3, 42]\n    assert s.to_python([1, 2, 3], mode='json') == [1, 2, 3, 42]\n    assert s.to_json([1, 2, 3]) == b'[1,2,3,42]'\n\n    msg = r'Expected `list\\[int\\]` but got `str` - serialized value may not be as expected'\n    with pytest.warns(UserWarning, match=msg):\n        assert s.to_python('abc') == 'abc'\n\n    with pytest.warns(UserWarning, match=msg):\n        assert s.to_python('abc', mode='json') == 'abc'\n\n    with pytest.warns(UserWarning, match=msg):\n        assert s.to_json('abc') == b'\"abc\"'\n\n\ndef test_function_args_str():\n    def append_args(value, info):\n        return f'{value} info={info}'\n\n    s = SchemaSerializer(\n        core_schema.any_schema(\n            serialization=core_schema.plain_serializer_function_ser_schema(\n                append_args, info_arg=True, return_schema=core_schema.str_schema()\n            )\n        )\n    )\n    assert s.to_python(123) == (\n        \"123 info=SerializationInfo(include=None, exclude=None, context=None, mode='python', by_alias=True, exclude_unset=False, \"\n        'exclude_defaults=False, exclude_none=False, round_trip=False, serialize_as_any=False)'\n    )\n    assert s.to_python(123, mode='other') == (\n        \"123 info=SerializationInfo(include=None, exclude=None, context=None, mode='other', by_alias=True, exclude_unset=False, \"\n        'exclude_defaults=False, exclude_none=False, round_trip=False, serialize_as_any=False)'\n    )\n    assert s.to_python(123, include={'x'}) == (\n        \"123 info=SerializationInfo(include={'x'}, exclude=None, context=None, mode='python', by_alias=True, exclude_unset=False, \"\n        'exclude_defaults=False, exclude_none=False, round_trip=False, serialize_as_any=False)'\n    )\n    assert s.to_python(123, context='context') == (\n        \"123 info=SerializationInfo(include=None, exclude=None, context='context', mode='python', by_alias=True, exclude_unset=False, \"\n        'exclude_defaults=False, exclude_none=False, round_trip=False, serialize_as_any=False)'\n    )\n    assert s.to_python(123, mode='json', exclude={1: {2}}) == (\n        \"123 info=SerializationInfo(include=None, exclude={1: {2}}, context=None, mode='json', by_alias=True, exclude_unset=False, \"\n        'exclude_defaults=False, exclude_none=False, round_trip=False, serialize_as_any=False)'\n    )\n    assert s.to_json(123) == (\n        b\"\\\"123 info=SerializationInfo(include=None, exclude=None, context=None, mode='json', by_alias=True, exclude_unset=False, \"\n        b'exclude_defaults=False, exclude_none=False, round_trip=False, serialize_as_any=False)\"'\n    )\n\n\ndef test_dict_keys():\n    def fmt(value, _info):\n        return f'<{value}>'\n\n    s = SchemaSerializer(\n        core_schema.dict_schema(\n            core_schema.int_schema(serialization=core_schema.plain_serializer_function_ser_schema(fmt, info_arg=True))\n        )\n    )\n    assert s.to_python({1: True}) == {'<1>': True}\n\n\ndef test_function_as_key():\n    s = SchemaSerializer(\n        core_schema.dict_schema(\n            core_schema.any_schema(\n                serialization=core_schema.plain_serializer_function_ser_schema(repr_function, info_arg=True)\n            ),\n            core_schema.any_schema(),\n        )\n    )\n    assert s.to_python({123: 4}) == {'123': 4}\n    assert s.to_python({123: 4}, mode='json') == {'123': 4}\n    assert s.to_json({123: 4}) == b'{\"123\":4}'\n\n\ndef test_function_only_json():\n    def double(value, _):\n        return value * 2\n\n    s = SchemaSerializer(\n        core_schema.any_schema(\n            serialization=core_schema.plain_serializer_function_ser_schema(double, info_arg=True, when_used='json')\n        )\n    )\n    assert s.to_python(4) == 4\n    assert s.to_python(4, mode='foobar') == 4\n\n    assert s.to_python(4, mode='json') == 8\n    assert s.to_json(4) == b'8'\n\n\ndef test_function_unless_none():\n    s = SchemaSerializer(\n        core_schema.any_schema(\n            serialization=core_schema.plain_serializer_function_ser_schema(\n                repr_function, info_arg=True, when_used='unless-none'\n            )\n        )\n    )\n    assert s.to_python(4) == '4'\n    assert s.to_python(None) is None\n\n    assert s.to_python(4, mode='json') == '4'\n    assert s.to_python(None, mode='json') is None\n    assert s.to_json(4) == b'\"4\"'\n    assert s.to_json(None) == b'null'\n\n\ndef test_wrong_return_type():\n    s = SchemaSerializer(\n        core_schema.any_schema(\n            serialization=core_schema.plain_serializer_function_ser_schema(\n                repr_function, info_arg=True, return_schema=core_schema.int_schema()\n            )\n        )\n    )\n    with pytest.warns(UserWarning, match='Expected `int` but got `str` - serialized value may not be as expected'):\n        assert s.to_python(123) == '123'\n    with pytest.warns(UserWarning, match='Expected `int` but got `str` - serialized value may not be as expected'):\n        assert s.to_python(123, mode='json') == '123'\n    with pytest.warns(UserWarning, match='Expected `int` but got `str` - serialized value may not be as expected'):\n        assert s.to_json(123) == b'\"123\"'\n\n\ndef test_function_wrap():\n    def f(value, serializer, _info):\n        return f'result={serializer(len(value))} repr={serializer!r}'\n\n    s = SchemaSerializer(\n        core_schema.int_schema(serialization=core_schema.wrap_serializer_function_ser_schema(f, info_arg=True))\n    )\n    assert s.to_python('foo') == 'result=3 repr=SerializationCallable(serializer=int)'\n    assert s.to_python('foo', mode='json') == 'result=3 repr=SerializationCallable(serializer=int)'\n    assert s.to_json('foo') == b'\"result=3 repr=SerializationCallable(serializer=int)\"'\n\n\ndef test_function_wrap_return_scheam():\n    def f(value, serializer):\n        if value == 42:\n            return 42\n        return f'result={serializer(value)}'\n\n    s = SchemaSerializer(\n        core_schema.int_schema(\n            serialization=core_schema.wrap_serializer_function_ser_schema(f, return_schema=core_schema.str_schema())\n        )\n    )\n    assert s.to_python(3) == 'result=3'\n    assert s.to_python(3, mode='json') == 'result=3'\n    assert s.to_json(3) == b'\"result=3\"'\n    with pytest.warns(UserWarning, match='Expected `str` but got `int` - serialized value may not be as expected'):\n        assert s.to_python(42) == 42\n    with pytest.warns(UserWarning, match='Expected `str` but got `int` - serialized value may not be as expected'):\n        assert s.to_python(42, mode='json') == 42\n    with pytest.warns(UserWarning, match='Expected `str` but got `int` - serialized value may not be as expected'):\n        assert s.to_json(42) == b'42'\n\n\ndef test_function_wrap_no_info():\n    def f(value, serializer):\n        return f'result={serializer(len(value))} repr={serializer!r}'\n\n    s = SchemaSerializer(core_schema.int_schema(serialization=core_schema.wrap_serializer_function_ser_schema(f)))\n    assert s.to_python('foo') == 'result=3 repr=SerializationCallable(serializer=int)'\n    assert s.to_python('foo', mode='json') == 'result=3 repr=SerializationCallable(serializer=int)'\n    assert s.to_json('foo') == b'\"result=3 repr=SerializationCallable(serializer=int)\"'\n\n\ndef test_function_wrap_custom_schema():\n    def f(value, serializer, _info):\n        return f'result={serializer(len(value))} repr={serializer!r}'\n\n    s = SchemaSerializer(\n        core_schema.any_schema(\n            serialization=core_schema.wrap_serializer_function_ser_schema(\n                f, info_arg=True, schema=core_schema.int_schema()\n            )\n        )\n    )\n    assert s.to_python('foo') == 'result=3 repr=SerializationCallable(serializer=int)'\n    assert s.to_python('foo', mode='json') == 'result=3 repr=SerializationCallable(serializer=int)'\n    assert s.to_json('foo') == b'\"result=3 repr=SerializationCallable(serializer=int)\"'\n\n\nclass Foobar:\n    def __str__(self):\n        return 'foobar!'\n\n\ndef test_function_wrap_fallback():\n    def f(value, serializer, _info):\n        return f'result={serializer(value)}'\n\n    def fallback(v):\n        return f'fallback:{v}'\n\n    s = SchemaSerializer(\n        core_schema.any_schema(\n            serialization=core_schema.wrap_serializer_function_ser_schema(\n                f, info_arg=True, schema=core_schema.any_schema()\n            )\n        )\n    )\n    assert s.to_python('foo') == 'result=foo'\n    assert s.to_python('foo', mode='json') == 'result=foo'\n    assert s.to_json('foo') == b'\"result=foo\"'\n\n    assert s.to_python(Foobar()) == 'result=foobar!'\n    with pytest.raises(PydanticSerializationError, match='Unable to serialize unknown type:'):\n        s.to_python(Foobar(), mode='json')\n    with pytest.raises(PydanticSerializationError, match='Unable to serialize unknown type:'):\n        s.to_json(Foobar())\n\n    assert s.to_python(Foobar(), fallback=fallback) == 'result=fallback:foobar!'\n    assert s.to_python(Foobar(), mode='json', fallback=fallback) == 'result=fallback:foobar!'\n    assert s.to_json(Foobar(), fallback=fallback) == b'\"result=fallback:foobar!\"'\n\n\ndef test_deque():\n    def serialize_deque(value, serializer, info: core_schema.SerializationInfo):\n        items = []\n        for index, item in enumerate(value):\n            try:\n                v = serializer(item, index)\n            except PydanticOmit:\n                pass\n            else:\n                items.append(v)\n        if info.mode_is_json():\n            return items\n        else:\n            return deque(items)\n\n    s = SchemaSerializer(\n        core_schema.any_schema(\n            serialization=core_schema.wrap_serializer_function_ser_schema(\n                serialize_deque, info_arg=True, schema=core_schema.any_schema()\n            )\n        )\n    )\n    assert s.to_python(deque([1, 2, 3])) == deque([1, 2, 3])\n    assert s.to_python(deque([1, 2, 3]), exclude={2}) == deque([1, 2])\n    assert s.to_python(deque([1, 2, 3]), include={0}) == deque([1])\n    assert s.to_python(deque([1, 2, 3]), mode='json') == [1, 2, 3]\n    assert s.to_python(deque([1, 2, 3]), mode='json', exclude={2}) == [1, 2]\n    assert s.to_json(deque([1, 2, 3])) == b'[1,2,3]'\n    assert s.to_json(deque([1, 2, 3]), exclude={2}) == b'[1,2]'\n\n\ndef test_custom_mapping():\n    def serialize_custom_mapping(value, serializer, _info):\n        items = {}\n        for k, v in value.items():\n            try:\n                v = serializer(v, k)\n            except PydanticOmit:\n                pass\n            else:\n                items[k] = v\n        return ' '.join(f'{k}={v}' for k, v in items.items())\n\n    s = SchemaSerializer(\n        core_schema.any_schema(\n            serialization=core_schema.wrap_serializer_function_ser_schema(\n                serialize_custom_mapping, info_arg=True, schema=core_schema.int_schema()\n            )\n        )\n    )\n    assert s.to_python({'a': 1, 'b': 2}) == 'a=1 b=2'\n    assert s.to_python({'a': 1, 'b': 2}, exclude={'b'}) == 'a=1'\n    assert s.to_python({'a': 1, 'b': 2}, mode='json') == 'a=1 b=2'\n    assert s.to_python({'a': 1, 'b': 2}, mode='json', include={'a'}) == 'a=1'\n    assert s.to_json({'a': 1, 'b': 2}) == b'\"a=1 b=2\"'\n    assert s.to_json({'a': 1, 'b': 2}, exclude={'b'}) == b'\"a=1\"'\n\n\ndef test_function_wrap_model():\n    calls = 0\n\n    def wrap_function(value, handler, _info):\n        nonlocal calls\n        calls += 1\n        return handler(value)\n\n    class MyModel:\n        def __init__(self, **kwargs):\n            self.__dict__.update(kwargs)\n\n    s = SchemaSerializer(\n        core_schema.model_schema(\n            MyModel,\n            core_schema.typed_dict_schema(\n                {\n                    'a': core_schema.typed_dict_field(core_schema.any_schema()),\n                    'b': core_schema.typed_dict_field(core_schema.any_schema()),\n                    'c': core_schema.typed_dict_field(core_schema.any_schema(), serialization_exclude=True),\n                }\n            ),\n            serialization=core_schema.wrap_serializer_function_ser_schema(wrap_function, info_arg=True),\n        )\n    )\n    m = MyModel(a=1, b=b'foobar', c='excluded')\n    assert calls == 0\n    assert s.to_python(m) == {'a': 1, 'b': b'foobar'}\n    assert calls == 1\n    assert s.to_python(m, mode='json') == {'a': 1, 'b': 'foobar'}\n    assert calls == 2\n    assert s.to_json(m) == b'{\"a\":1,\"b\":\"foobar\"}'\n    assert calls == 3\n\n    assert s.to_python(m, exclude={'b'}) == {'a': 1}\n    assert calls == 4\n    assert s.to_python(m, mode='json', exclude={'b'}) == {'a': 1}\n    assert calls == 5\n    assert s.to_json(m, exclude={'b'}) == b'{\"a\":1}'\n    assert calls == 6\n\n\ndef test_function_plain_model():\n    calls = 0\n\n    def wrap_function(value, _info):\n        nonlocal calls\n        calls += 1\n        return value.__dict__\n\n    class MyModel:\n        def __init__(self, **kwargs):\n            self.__dict__.update(kwargs)\n\n    s = SchemaSerializer(\n        core_schema.model_schema(\n            MyModel,\n            core_schema.typed_dict_schema(\n                {\n                    'a': core_schema.typed_dict_field(core_schema.any_schema()),\n                    'b': core_schema.typed_dict_field(core_schema.any_schema()),\n                    'c': core_schema.typed_dict_field(core_schema.any_schema(), serialization_exclude=True),\n                }\n            ),\n            serialization=core_schema.plain_serializer_function_ser_schema(wrap_function, info_arg=True),\n        )\n    )\n    m = MyModel(a=1, b=b'foobar', c='not excluded')\n    assert calls == 0\n    assert s.to_python(m) == {'a': 1, 'b': b'foobar', 'c': 'not excluded'}\n    assert calls == 1\n    assert s.to_python(m, mode='json') == {'a': 1, 'b': 'foobar', 'c': 'not excluded'}\n    assert calls == 2\n    assert s.to_json(m) == b'{\"a\":1,\"b\":\"foobar\",\"c\":\"not excluded\"}'\n    assert calls == 3\n\n    assert s.to_python(m, exclude={'b'}) == {'a': 1, 'b': b'foobar', 'c': 'not excluded'}\n    assert calls == 4\n    assert s.to_python(m, mode='json', exclude={'b'}) == {'a': 1, 'b': 'foobar', 'c': 'not excluded'}\n    assert calls == 5\n    assert s.to_json(m, exclude={'b'}) == b'{\"a\":1,\"b\":\"foobar\",\"c\":\"not excluded\"}'\n    assert calls == 6\n\n\n@pytest.mark.skipif(sys.platform == 'win32', reason='Path output different on windows')\ndef test_wrap_return_type():\n    def to_path(value, handler, _info):\n        return Path(handler(value)).with_suffix('.new')\n\n    s = SchemaSerializer(\n        core_schema.str_schema(\n            serialization=core_schema.wrap_serializer_function_ser_schema(\n                to_path, info_arg=True, return_schema=core_schema.any_schema()\n            )\n        )\n    )\n    assert s.to_python('foobar') == Path('foobar.new')\n    assert s.to_python('foobar', mode='json') == 'foobar.new'\n    assert s.to_json('foobar') == b'\"foobar.new\"'\n\n\ndef test_raise_unexpected():\n    def raise_unexpected(_value):\n        raise PydanticSerializationUnexpectedValue('unexpected')\n\n    s = SchemaSerializer(\n        core_schema.any_schema(serialization=core_schema.plain_serializer_function_ser_schema(raise_unexpected))\n    )\n    with pytest.warns(UserWarning, match=r'PydanticSerializationUnexpectedValue\\(unexpected\\)'):\n        assert s.to_python('foo') == 'foo'\n\n    with pytest.warns(UserWarning, match=r'PydanticSerializationUnexpectedValue\\(unexpected\\)'):\n        assert s.to_json('foo') == b'\"foo\"'\n\n\ndef test_pydantic_serialization_unexpected_value():\n    v = PydanticSerializationUnexpectedValue('abc')\n    assert str(v) == 'abc'\n    assert repr(v) == 'PydanticSerializationUnexpectedValue(abc)'\n    v = PydanticSerializationUnexpectedValue()\n    assert str(v) == 'Unexpected Value'\n    assert repr(v) == 'PydanticSerializationUnexpectedValue(Unexpected Value)'\n\n\ndef test_function_after_preserves_wrapped_serialization():\n    def f(value, _info):\n        return value\n\n    s = SchemaSerializer(core_schema.with_info_after_validator_function(f, core_schema.int_schema()))\n    with pytest.warns(UserWarning, match='Expected `int` but got `str` - serialized value may not be as expected'):\n        assert s.to_python('abc') == 'abc'\n\n\ndef test_function_wrap_preserves_wrapped_serialization():\n    def f(value, handler, _info):\n        return handler(value)\n\n    s = SchemaSerializer(core_schema.with_info_wrap_validator_function(f, core_schema.int_schema()))\n    with pytest.warns(UserWarning, match='Expected `int` but got `str` - serialized value may not be as expected'):\n        assert s.to_python('abc') == 'abc'\n\n\n@pytest.mark.skipif(\n    platform.python_implementation() == 'PyPy' or sys.platform in {'emscripten', 'win32'},\n    reason='fails on pypy, emscripten and windows',\n)\ndef test_recursive_call():\n    def bad_recursive(value):\n        return s.to_python(value)\n\n    s = SchemaSerializer(\n        core_schema.any_schema(serialization=core_schema.plain_serializer_function_ser_schema(bad_recursive))\n    )\n    with pytest.raises(PydanticSerializationError) as exc_info:\n        s.to_python(42)\n    # insert_assert(str(exc_info.value))\n    assert str(exc_info.value) == 'Error calling function `bad_recursive`: RecursionError'\n\n    with pytest.raises(PydanticSerializationError) as exc_info:\n        s.to_python(42, mode='json')\n    # insert_assert(str(exc_info.value))\n    assert str(exc_info.value) == 'Error calling function `bad_recursive`: RecursionError'\n\n    with pytest.raises(PydanticSerializationError) as exc_info:\n        s.to_json(42)\n    # insert_assert(str(exc_info.value))\n    assert str(exc_info.value) == (\n        'Error serializing to JSON: PydanticSerializationError: Error calling function `bad_recursive`: RecursionError'\n    )\n\n\ndef test_serialize_pattern():\n    ser = core_schema.plain_serializer_function_ser_schema(\n        attrgetter('pattern'), when_used='json', return_schema=core_schema.str_schema()\n    )\n    s = SchemaSerializer(core_schema.any_schema(serialization=ser))\n\n    pattern = re.compile('^regex$')\n    assert s.to_python(pattern) == pattern\n    assert s.to_python(pattern, mode='json') == '^regex$'\n    assert s.to_json(pattern) == b'\"^regex$\"'\n", "tests/serializers/test_decimal.py": "from decimal import Decimal\n\nimport pytest\n\nfrom pydantic_core import SchemaSerializer, core_schema\n\n\ndef test_decimal():\n    v = SchemaSerializer(core_schema.decimal_schema())\n    assert v.to_python(Decimal('123.456')) == Decimal('123.456')\n\n    assert v.to_python(Decimal('123.456'), mode='json') == '123.456'\n    assert v.to_json(Decimal('123.456')) == b'\"123.456\"'\n\n    assert v.to_python(Decimal('123456789123456789123456789.123456789123456789123456789')) == Decimal(\n        '123456789123456789123456789.123456789123456789123456789'\n    )\n    assert (\n        v.to_json(Decimal('123456789123456789123456789.123456789123456789123456789'))\n        == b'\"123456789123456789123456789.123456789123456789123456789\"'\n    )\n\n    with pytest.warns(UserWarning, match='Expected `decimal` but got `int` - serialized value may not be as expected'):\n        assert v.to_python(123, mode='json') == 123\n\n    with pytest.warns(UserWarning, match='Expected `decimal` but got `int` - serialized value may not be as expected'):\n        assert v.to_json(123) == b'123'\n\n\ndef test_decimal_key():\n    v = SchemaSerializer(core_schema.dict_schema(core_schema.decimal_schema(), core_schema.decimal_schema()))\n    assert v.to_python({Decimal('123.456'): Decimal('123.456')}) == {Decimal('123.456'): Decimal('123.456')}\n    assert v.to_python({Decimal('123.456'): Decimal('123.456')}, mode='json') == {'123.456': '123.456'}\n    assert v.to_json({Decimal('123.456'): Decimal('123.456')}) == b'{\"123.456\":\"123.456\"}'\n\n\n@pytest.mark.parametrize(\n    'value,expected',\n    [\n        (Decimal('123.456'), '123.456'),\n        (Decimal('Infinity'), 'Infinity'),\n        (Decimal('-Infinity'), '-Infinity'),\n        (Decimal('NaN'), 'NaN'),\n    ],\n)\ndef test_decimal_json(value, expected):\n    v = SchemaSerializer(core_schema.decimal_schema())\n    assert v.to_python(value, mode='json') == expected\n    assert v.to_json(value).decode() == f'\"{expected}\"'\n\n\ndef test_any_decimal_key():\n    v = SchemaSerializer(core_schema.dict_schema())\n    input_value = {Decimal('123.456'): 1}\n\n    assert v.to_python(input_value, mode='json') == {'123.456': 1}\n    assert v.to_json(input_value) == b'{\"123.456\":1}'\n", "tests/serializers/test_misc.py": "import pytest\n\nfrom pydantic_core import SchemaError, core_schema, validate_core_schema\n\n\n@pytest.mark.parametrize(\n    'ser_schema,msg',\n    [\n        ({'invalid': 'schema'}, \"Unable to extract tag using discriminator 'type'\"),\n        ({'type': 'unknown'}, \"Input tag 'unknown' found using 'type' does not match any of the expected tags:\"),\n    ],\n)\ndef test_invalid_ser_schema(ser_schema, msg):\n    with pytest.raises(SchemaError, match=msg):\n        validate_core_schema(core_schema.any_schema(serialization=ser_schema))\n", "tests/serializers/test_timedelta.py": "from datetime import timedelta\n\nimport pytest\n\nfrom pydantic_core import SchemaSerializer, core_schema\n\ntry:\n    import pandas\nexcept ImportError:\n    pandas = None\n\n\ndef test_timedelta():\n    v = SchemaSerializer(core_schema.timedelta_schema())\n    assert v.to_python(timedelta(days=2, hours=3, minutes=4)) == timedelta(days=2, hours=3, minutes=4)\n\n    assert v.to_python(timedelta(days=2, hours=3, minutes=4), mode='json') == 'P2DT3H4M'\n    assert v.to_json(timedelta(days=2, hours=3, minutes=4)) == b'\"P2DT3H4M\"'\n\n    with pytest.warns(\n        UserWarning, match='Expected `timedelta` but got `int` - serialized value may not be as expected'\n    ):\n        assert v.to_python(123, mode='json') == 123\n\n    with pytest.warns(\n        UserWarning, match='Expected `timedelta` but got `int` - serialized value may not be as expected'\n    ):\n        assert v.to_json(123) == b'123'\n\n\ndef test_timedelta_float():\n    v = SchemaSerializer(core_schema.timedelta_schema(), config={'ser_json_timedelta': 'float'})\n    assert v.to_python(timedelta(seconds=4, microseconds=500_000)) == timedelta(seconds=4, microseconds=500_000)\n\n    assert v.to_python(timedelta(seconds=4, microseconds=500_000), mode='json') == 4.5\n    assert v.to_json(timedelta(seconds=4, microseconds=500_000)) == b'4.5'\n\n\ndef test_timedelta_key():\n    v = SchemaSerializer(core_schema.dict_schema(core_schema.timedelta_schema(), core_schema.int_schema()))\n    assert v.to_python({timedelta(days=2, hours=3, minutes=4): 1}) == {timedelta(days=2, hours=3, minutes=4): 1}\n    assert v.to_python({timedelta(days=2, hours=3, minutes=4): 1}, mode='json') == {'P2DT3H4M': 1}\n    assert v.to_json({timedelta(days=2, hours=3, minutes=4): 1}) == b'{\"P2DT3H4M\":1}'\n\n\n@pytest.mark.skipif(not pandas, reason='pandas not installed')\ndef test_pandas():\n    v = SchemaSerializer(core_schema.timedelta_schema())\n    d = pandas.Timestamp('2023-01-01T02:00:00Z') - pandas.Timestamp('2023-01-01T00:00:00Z')\n    assert v.to_python(d) == d\n    assert v.to_python(d, mode='json') == 'PT2H'\n    assert v.to_json(d) == b'\"PT2H\"'\n", "tests/serializers/test_union.py": "import dataclasses\nimport json\nimport re\nimport uuid\nfrom decimal import Decimal\nfrom typing import Any, ClassVar, Union\n\nimport pytest\nfrom typing_extensions import Literal\n\nfrom pydantic_core import PydanticSerializationUnexpectedValue, SchemaSerializer, core_schema\n\n\nclass BaseModel:\n    def __init__(self, **kwargs) -> None:\n        for name, value in kwargs.items():\n            setattr(self, name, value)\n\n\n@pytest.mark.parametrize('bool_case_label', [False, True])\n@pytest.mark.parametrize('int_case_label', [False, True])\n@pytest.mark.parametrize('input_value,expected_value', [(True, True), (False, False), (1, 1), (123, 123), (-42, -42)])\ndef test_union_bool_int(input_value, expected_value, bool_case_label, int_case_label):\n    bool_case = core_schema.bool_schema() if not bool_case_label else (core_schema.bool_schema(), 'my_bool_label')\n    int_case = core_schema.int_schema() if not int_case_label else (core_schema.int_schema(), 'my_int_label')\n    s = SchemaSerializer(core_schema.union_schema([bool_case, int_case]))\n\n    assert s.to_python(input_value) == expected_value\n    assert s.to_python(input_value, mode='json') == expected_value\n    assert s.to_json(input_value) == json.dumps(expected_value).encode()\n\n\ndef test_union_error():\n    s = SchemaSerializer(core_schema.union_schema([core_schema.bool_schema(), core_schema.int_schema()]))\n    msg = 'Expected `Union[bool, int]` but got `str` - serialized value may not be as expected'\n    with pytest.warns(UserWarning, match=re.escape(msg)):\n        assert s.to_python('a string') == 'a string'\n\n\nclass ModelA:\n    def __init__(self, a, b):\n        self.a = a\n        self.b = b\n\n\nclass ModelB:\n    def __init__(self, c, d):\n        self.c = c\n        self.d = d\n\n\n@pytest.fixture(scope='module')\ndef model_serializer() -> SchemaSerializer:\n    return SchemaSerializer(\n        {\n            'type': 'union',\n            'choices': [\n                {\n                    'type': 'model',\n                    'cls': ModelA,\n                    'schema': {\n                        'type': 'model-fields',\n                        'fields': {\n                            'a': {'type': 'model-field', 'schema': {'type': 'bytes'}},\n                            'b': {\n                                'type': 'model-field',\n                                'schema': {\n                                    'type': 'float',\n                                    'serialization': {\n                                        'type': 'format',\n                                        'formatting_string': '0.1f',\n                                        'when_used': 'unless-none',\n                                    },\n                                },\n                            },\n                        },\n                    },\n                },\n                {\n                    'type': 'model',\n                    'cls': ModelB,\n                    'schema': {\n                        'type': 'model-fields',\n                        'fields': {\n                            'c': {'type': 'model-field', 'schema': {'type': 'bytes'}},\n                            'd': {\n                                'type': 'model-field',\n                                'schema': {\n                                    'type': 'float',\n                                    'serialization': {\n                                        'type': 'format',\n                                        'formatting_string': '0.2f',\n                                        'when_used': 'unless-none',\n                                    },\n                                },\n                            },\n                        },\n                    },\n                },\n            ],\n        }\n    )\n\n\nclass SubclassA(ModelA):\n    pass\n\n\n@pytest.mark.parametrize('input_value', [ModelA(b'bite', 2.3456), SubclassA(b'bite', 2.3456)])\ndef test_model_a(model_serializer: SchemaSerializer, input_value):\n    assert model_serializer.to_python(input_value) == {'a': b'bite', 'b': '2.3'}\n    assert model_serializer.to_python(input_value, mode='json') == {'a': 'bite', 'b': '2.3'}\n    assert model_serializer.to_json(input_value) == b'{\"a\":\"bite\",\"b\":\"2.3\"}'\n\n\nclass SubclassB(ModelB):\n    pass\n\n\n@pytest.mark.parametrize('input_value', [ModelB(b'bite', 2.3456), SubclassB(b'bite', 2.3456)])\ndef test_model_b(model_serializer: SchemaSerializer, input_value):\n    assert model_serializer.to_python(input_value) == {'c': b'bite', 'd': '2.35'}\n    assert model_serializer.to_python(input_value, mode='json') == {'c': 'bite', 'd': '2.35'}\n    assert model_serializer.to_json(input_value) == b'{\"c\":\"bite\",\"d\":\"2.35\"}'\n\n\ndef test_keys():\n    s = SchemaSerializer(\n        core_schema.dict_schema(\n            core_schema.union_schema(\n                [\n                    core_schema.int_schema(),\n                    core_schema.float_schema(serialization=core_schema.format_ser_schema('0.0f')),\n                ]\n            ),\n            core_schema.int_schema(),\n        )\n    )\n    assert s.to_python({1: 2, 2.111: 3}) == {1: 2, 2.111: 3}\n    assert s.to_python({1: 2, 2.111: 3}, mode='json') == {'1': 2, '2': 3}\n    assert s.to_json({1: 2, 2.111: 3}) == b'{\"1\":2,\"2\":3}'\n\n\ndef test_union_of_functions():\n    def repr_function(value, _info):\n        if value == 'unexpected':\n            raise PydanticSerializationUnexpectedValue()\n        return f'func: {value!r}'\n\n    s = SchemaSerializer(\n        core_schema.union_schema(\n            [\n                core_schema.any_schema(\n                    serialization=core_schema.plain_serializer_function_ser_schema(repr_function, info_arg=True)\n                ),\n                core_schema.float_schema(serialization=core_schema.format_ser_schema('_^14')),\n            ]\n        )\n    )\n    assert s.to_python('foobar') == \"func: 'foobar'\"\n    assert s.to_python('foobar', mode='json') == \"func: 'foobar'\"\n    assert s.to_json('foobar') == b'\"func: \\'foobar\\'\"'\n\n    assert s.to_python('unexpected') == 'unexpected'\n    assert s.to_python('unexpected', mode='json') == '__unexpected__'\n    assert s.to_json('unexpected') == b'\"__unexpected__\"'\n\n\ndef test_typed_dict_literal():\n    s = SchemaSerializer(\n        core_schema.union_schema(\n            [\n                core_schema.typed_dict_schema(\n                    dict(\n                        pet_type=core_schema.typed_dict_field(core_schema.literal_schema(['cat'])),\n                        sound=core_schema.typed_dict_field(\n                            core_schema.int_schema(serialization=core_schema.format_ser_schema('04d'))\n                        ),\n                    )\n                ),\n                core_schema.typed_dict_schema(\n                    dict(\n                        pet_type=core_schema.typed_dict_field(core_schema.literal_schema(['dog'])),\n                        sound=core_schema.typed_dict_field(\n                            core_schema.float_schema(serialization=core_schema.format_ser_schema('0.3f'))\n                        ),\n                    )\n                ),\n            ]\n        )\n    )\n\n    assert s.to_python(dict(pet_type='cat', sound=3), mode='json') == {'pet_type': 'cat', 'sound': '0003'}\n    assert s.to_python(dict(pet_type='dog', sound=3), mode='json') == {'pet_type': 'dog', 'sound': '3.000'}\n\n\ndef test_typed_dict_missing():\n    s = SchemaSerializer(\n        core_schema.union_schema(\n            [\n                core_schema.typed_dict_schema(dict(foo=core_schema.typed_dict_field(core_schema.int_schema()))),\n                core_schema.typed_dict_schema(\n                    dict(\n                        foo=core_schema.typed_dict_field(\n                            core_schema.int_schema(\n                                serialization=core_schema.format_ser_schema('04d', when_used='always')\n                            )\n                        ),\n                        bar=core_schema.typed_dict_field(core_schema.int_schema()),\n                    )\n                ),\n            ]\n        )\n    )\n\n    assert s.to_python(dict(foo=1)) == {'foo': 1}\n    assert s.to_python(dict(foo=1), mode='json') == {'foo': 1}\n    assert s.to_json(dict(foo=1)) == b'{\"foo\":1}'\n\n    assert s.to_python(dict(foo=1, bar=2)) == {'foo': '0001', 'bar': 2}\n    assert s.to_python(dict(foo=1, bar=2), mode='json') == {'foo': '0001', 'bar': 2}\n    assert s.to_json(dict(foo=1, bar=2)) == b'{\"foo\":\"0001\",\"bar\":2}'\n\n\ndef test_typed_dict_extra():\n    \"\"\"\n    TODO, needs tests for each case\n    \"\"\"\n    s = SchemaSerializer(\n        core_schema.union_schema(\n            [\n                core_schema.typed_dict_schema(\n                    dict(\n                        foo=core_schema.typed_dict_field(core_schema.int_schema()),\n                        bar=core_schema.typed_dict_field(core_schema.int_schema()),\n                    )\n                ),\n                core_schema.typed_dict_schema(\n                    dict(\n                        foo=core_schema.typed_dict_field(\n                            core_schema.int_schema(serialization=core_schema.format_ser_schema('04d'))\n                        )\n                    )\n                ),\n            ]\n        )\n    )\n\n    assert s.to_python(dict(foo=1, bar=2)) == {'foo': 1, 'bar': 2}\n    assert s.to_python(dict(foo=1, bar=2), mode='json') == {'foo': 1, 'bar': 2}\n    assert s.to_json(dict(foo=1, bar=2)) == b'{\"foo\":1,\"bar\":2}'\n    assert s.to_python(dict(foo=1)) == {'foo': 1}\n    assert s.to_python(dict(foo=1), mode='json') == {'foo': '0001'}\n    assert s.to_json(dict(foo=1)) == b'{\"foo\":\"0001\"}'\n\n\ndef test_typed_dict_different_fields():\n    \"\"\"\n    TODO, needs tests for each case\n    \"\"\"\n    s = SchemaSerializer(\n        core_schema.union_schema(\n            [\n                core_schema.typed_dict_schema(\n                    dict(\n                        foo=core_schema.typed_dict_field(core_schema.int_schema()),\n                        bar=core_schema.typed_dict_field(core_schema.int_schema()),\n                    )\n                ),\n                core_schema.typed_dict_schema(\n                    dict(\n                        spam=core_schema.typed_dict_field(core_schema.int_schema()),\n                        ham=core_schema.typed_dict_field(\n                            core_schema.int_schema(serialization=core_schema.format_ser_schema('04d'))\n                        ),\n                    )\n                ),\n            ]\n        )\n    )\n\n    assert s.to_python(dict(foo=1, bar=2)) == {'foo': 1, 'bar': 2}\n    assert s.to_python(dict(foo=1, bar=2), mode='json') == {'foo': 1, 'bar': 2}\n    assert s.to_json(dict(foo=1, bar=2)) == b'{\"foo\":1,\"bar\":2}'\n    assert s.to_python(dict(spam=1, ham=2)) == {'spam': 1, 'ham': 2}\n    assert s.to_python(dict(spam=1, ham=2), mode='json') == {'spam': 1, 'ham': '0002'}\n    assert s.to_json(dict(spam=1, ham=2)) == b'{\"spam\":1,\"ham\":\"0002\"}'\n\n\ndef test_dataclass_union():\n    @dataclasses.dataclass\n    class BaseUser:\n        name: str\n\n    @dataclasses.dataclass\n    class User(BaseUser):\n        surname: str\n\n    @dataclasses.dataclass\n    class DBUser(User):\n        password_hash: str\n\n    @dataclasses.dataclass\n    class Item:\n        name: str\n        price: float\n\n    user_schema = core_schema.dataclass_schema(\n        User,\n        core_schema.dataclass_args_schema(\n            'User',\n            [\n                core_schema.dataclass_field(name='name', schema=core_schema.str_schema()),\n                core_schema.dataclass_field(name='surname', schema=core_schema.str_schema()),\n            ],\n        ),\n        ['name', 'surname'],\n    )\n    item_schema = core_schema.dataclass_schema(\n        Item,\n        core_schema.dataclass_args_schema(\n            'Item',\n            [\n                core_schema.dataclass_field(name='name', schema=core_schema.str_schema()),\n                core_schema.dataclass_field(name='price', schema=core_schema.float_schema()),\n            ],\n        ),\n        ['name', 'price'],\n    )\n    s = SchemaSerializer(core_schema.union_schema([user_schema, item_schema]))\n    assert s.to_python(User(name='foo', surname='bar')) == {'name': 'foo', 'surname': 'bar'}\n    assert s.to_python(DBUser(name='foo', surname='bar', password_hash='x')) == {'name': 'foo', 'surname': 'bar'}\n    assert s.to_json(DBUser(name='foo', surname='bar', password_hash='x')) == b'{\"name\":\"foo\",\"surname\":\"bar\"}'\n\n\ndef test_model_union():\n    class BaseUser:\n        def __init__(self, name: str):\n            self.name = name\n\n    class User(BaseUser):\n        def __init__(self, name: str, surname: str):\n            super().__init__(name)\n            self.surname = surname\n\n    class DBUser(User):\n        def __init__(self, name: str, surname: str, password_hash: str):\n            super().__init__(name, surname)\n            self.password_hash = password_hash\n\n    class Item:\n        def __init__(self, name: str, price: float):\n            self.name = name\n            self.price = price\n\n    user_schema = core_schema.model_schema(\n        User,\n        core_schema.model_fields_schema(\n            {\n                'name': core_schema.model_field(schema=core_schema.str_schema()),\n                'surname': core_schema.model_field(schema=core_schema.str_schema()),\n            }\n        ),\n    )\n    item_schema = core_schema.model_schema(\n        Item,\n        core_schema.model_fields_schema(\n            {\n                'name': core_schema.model_field(schema=core_schema.str_schema()),\n                'price': core_schema.model_field(schema=core_schema.float_schema()),\n            }\n        ),\n    )\n    s = SchemaSerializer(core_schema.union_schema([user_schema, item_schema]))\n    assert s.to_python(User(name='foo', surname='bar')) == {'name': 'foo', 'surname': 'bar'}\n    assert s.to_python(DBUser(name='foo', surname='bar', password_hash='x')) == {'name': 'foo', 'surname': 'bar'}\n    assert s.to_json(DBUser(name='foo', surname='bar', password_hash='x')) == b'{\"name\":\"foo\",\"surname\":\"bar\"}'\n\n\n@pytest.mark.parametrize(('data', 'json_value'), [(False, 'false'), ('abc', '\"abc\"')])\ndef test_union_literal_with_other_type(data, json_value):\n    class Model(BaseModel):\n        value: Union[Literal[False], str]\n        value_types_reversed: Union[str, Literal[False]]\n\n    s = SchemaSerializer(\n        core_schema.model_schema(\n            Model,\n            core_schema.model_fields_schema(\n                {\n                    'value': core_schema.model_field(\n                        core_schema.union_schema([core_schema.literal_schema([False]), core_schema.str_schema()])\n                    ),\n                    'value_types_reversed': core_schema.model_field(\n                        core_schema.union_schema([core_schema.str_schema(), core_schema.literal_schema([False])])\n                    ),\n                }\n            ),\n        )\n    )\n\n    m = Model(value=data, value_types_reversed=data)\n\n    assert s.to_python(m) == {'value': data, 'value_types_reversed': data}\n    assert s.to_json(m) == f'{{\"value\":{json_value},\"value_types_reversed\":{json_value}}}'.encode()\n\n\ndef test_union_serializes_model_subclass_from_definition() -> None:\n    class BaseModel:\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n\n        def __init__(self, **kwargs: Any):\n            for key, value in kwargs.items():\n                setattr(self, key, value)\n\n    class User(BaseModel):\n        name: str\n\n    class DBUser(User):\n        password: str\n        __pydantic_serializer__: ClassVar[SchemaSerializer]\n\n    DBUser.__pydantic_serializer__ = SchemaSerializer(\n        core_schema.model_schema(\n            DBUser,\n            core_schema.model_fields_schema(\n                {\n                    'name': core_schema.model_field(core_schema.str_schema()),\n                    'password': core_schema.model_field(core_schema.str_schema()),\n                }\n            ),\n        )\n    )\n\n    class Item(BaseModel):\n        price: float\n\n    s = SchemaSerializer(\n        core_schema.definitions_schema(\n            core_schema.union_schema(\n                [core_schema.definition_reference_schema('User'), core_schema.definition_reference_schema('Item')]\n            ),\n            [\n                core_schema.model_schema(\n                    User,\n                    core_schema.model_fields_schema({'name': core_schema.model_field(core_schema.str_schema())}),\n                    ref='User',\n                ),\n                core_schema.model_schema(\n                    Item,\n                    core_schema.model_fields_schema({'price': core_schema.model_field(core_schema.float_schema())}),\n                    ref='Item',\n                ),\n            ],\n        )\n    )\n\n    assert s.to_python(DBUser(name='John', password='secret')) == {'name': 'John'}\n\n\ndef test_union_serializes_list_of_model_subclass_from_definition() -> None:\n    class BaseModel:\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n\n        def __init__(self, **kwargs: Any):\n            for key, value in kwargs.items():\n                setattr(self, key, value)\n\n    class User(BaseModel):\n        name: str\n\n    class DBUser(User):\n        password: str\n        __pydantic_serializer__: ClassVar[SchemaSerializer]\n\n    DBUser.__pydantic_serializer__ = SchemaSerializer(\n        core_schema.model_schema(\n            DBUser,\n            core_schema.model_fields_schema(\n                {\n                    'name': core_schema.model_field(core_schema.str_schema()),\n                    'password': core_schema.model_field(core_schema.str_schema()),\n                }\n            ),\n        )\n    )\n\n    class Item(BaseModel):\n        price: float\n\n    s = SchemaSerializer(\n        core_schema.definitions_schema(\n            core_schema.union_schema(\n                [\n                    core_schema.list_schema(core_schema.definition_reference_schema('User'), strict=False),\n                    core_schema.list_schema(core_schema.definition_reference_schema('Item'), strict=False),\n                ]\n            ),\n            [\n                core_schema.model_schema(\n                    User,\n                    core_schema.model_fields_schema({'name': core_schema.model_field(core_schema.str_schema())}),\n                    ref='User',\n                ),\n                core_schema.model_schema(\n                    Item,\n                    core_schema.model_fields_schema({'price': core_schema.model_field(core_schema.float_schema())}),\n                    ref='Item',\n                ),\n            ],\n        )\n    )\n\n    assert s.to_python([DBUser(name='John', password='secret')]) == [{'name': 'John'}]\n\n\nEXAMPLE_UUID = uuid.uuid4()\n\n\nclass IntSubclass(int):\n    pass\n\n\n@pytest.mark.parametrize('reverse', [False, True])\n@pytest.mark.parametrize(\n    'core_schema_left,core_schema_right,input_value,expected_value',\n    [\n        (core_schema.int_schema(), core_schema.bool_schema(), True, True),\n        (core_schema.int_schema(), core_schema.bool_schema(), 1, 1),\n        (core_schema.str_schema(), core_schema.int_schema(), 1, 1),\n        (core_schema.str_schema(), core_schema.int_schema(), '1', '1'),\n        (core_schema.int_schema(), core_schema.bool_schema(), IntSubclass(1), 1),\n        (\n            core_schema.decimal_schema(),\n            core_schema.int_schema(),\n            Decimal('1'),\n            Decimal('1'),\n        ),\n        (core_schema.decimal_schema(), core_schema.int_schema(), 1, 1),\n        (\n            core_schema.decimal_schema(),\n            core_schema.float_schema(),\n            Decimal('1.'),\n            Decimal('1.'),\n        ),\n        (\n            core_schema.decimal_schema(),\n            core_schema.str_schema(),\n            Decimal('_1'),\n            Decimal('_1'),\n        ),\n        (\n            core_schema.decimal_schema(),\n            core_schema.str_schema(),\n            '_1',\n            '_1',\n        ),\n        (\n            core_schema.uuid_schema(),\n            core_schema.str_schema(),\n            EXAMPLE_UUID,\n            EXAMPLE_UUID,\n        ),\n        (\n            core_schema.uuid_schema(),\n            core_schema.str_schema(),\n            str(EXAMPLE_UUID),\n            str(EXAMPLE_UUID),\n        ),\n    ],\n)\ndef test_union_serializer_picks_exact_type_over_subclass(\n    core_schema_left, core_schema_right, input_value, expected_value, reverse\n):\n    s = SchemaSerializer(\n        core_schema.union_schema(\n            [core_schema_right, core_schema_left] if reverse else [core_schema_left, core_schema_right]\n        )\n    )\n    assert s.to_python(input_value) == expected_value\n\n\n@pytest.mark.parametrize('reverse', [False, True])\n@pytest.mark.parametrize(\n    'core_schema_left,core_schema_right,input_value,expected_value',\n    [\n        (core_schema.int_schema(), core_schema.bool_schema(), True, True),\n        (core_schema.int_schema(), core_schema.bool_schema(), 1, 1),\n        (core_schema.str_schema(), core_schema.int_schema(), 1, 1),\n        (core_schema.str_schema(), core_schema.int_schema(), '1', '1'),\n        (core_schema.int_schema(), core_schema.bool_schema(), IntSubclass(1), 1),\n        (\n            core_schema.decimal_schema(),\n            core_schema.int_schema(),\n            Decimal('1'),\n            '1',\n        ),\n        (core_schema.decimal_schema(), core_schema.int_schema(), 1, 1),\n        (\n            core_schema.decimal_schema(),\n            core_schema.float_schema(),\n            Decimal('1.'),\n            '1',\n        ),\n        (\n            core_schema.decimal_schema(),\n            core_schema.str_schema(),\n            Decimal('_1'),\n            '1',\n        ),\n        (\n            core_schema.decimal_schema(),\n            core_schema.str_schema(),\n            '_1',\n            '_1',\n        ),\n    ],\n)\ndef test_union_serializer_picks_exact_type_over_subclass_json(\n    core_schema_left, core_schema_right, input_value, expected_value, reverse\n):\n    s = SchemaSerializer(\n        core_schema.union_schema(\n            [core_schema_right, core_schema_left] if reverse else [core_schema_left, core_schema_right]\n        )\n    )\n    assert s.to_python(input_value, mode='json') == expected_value\n    assert s.to_json(input_value) == json.dumps(expected_value).encode()\n", "tests/serializers/test_json_or_python.py": "from enum import Enum\n\nfrom pydantic_core import SchemaSerializer, core_schema\n\n\ndef test_json_or_python():\n    def s1(v: int) -> int:\n        return v + 1\n\n    def s2(v: int) -> int:\n        return v + 2\n\n    s = SchemaSerializer(\n        core_schema.json_or_python_schema(\n            core_schema.int_schema(serialization=core_schema.plain_serializer_function_ser_schema(s1)),\n            core_schema.int_schema(serialization=core_schema.plain_serializer_function_ser_schema(s2)),\n        )\n    )\n\n    assert s.to_json(0) == b'1'\n    assert s.to_python(0) == 2\n\n\ndef test_json_or_python_enum_dict_key():\n    # See https://github.com/pydantic/pydantic/issues/6795\n    class MyEnum(str, Enum):\n        A = 'A'\n        B = 'B'\n\n    print(MyEnum('A'))\n\n    s = SchemaSerializer(\n        core_schema.dict_schema(\n            core_schema.json_or_python_schema(\n                core_schema.str_schema(), core_schema.no_info_after_validator_function(MyEnum, core_schema.str_schema())\n            ),\n            core_schema.int_schema(),\n        )\n    )\n\n    assert s.to_json({MyEnum.A: 1, MyEnum.B: 2}) == b'{\"A\":1,\"B\":2}'\n    assert s.to_python({MyEnum.A: 1, MyEnum.B: 2}) == {MyEnum.A: 1, MyEnum.B: 2}\n", "tests/serializers/test_bytes.py": "import base64\nimport json\nfrom enum import Enum\n\nimport pytest\n\nfrom pydantic_core import PydanticSerializationError, SchemaSerializer, core_schema, to_json\n\n\ndef test_bytes():\n    s = SchemaSerializer(core_schema.bytes_schema())\n    assert s.to_python(b'foobar') == b'foobar'\n    assert s.to_python('emoji \ud83d\udca9'.encode()) == 'emoji \ud83d\udca9'.encode()\n    assert s.to_json(b'foobar') == b'\"foobar\"'\n    assert s.to_python(b'foobar', mode='json') == 'foobar'\n\n    json_emoji = s.to_json('emoji \ud83d\udca9'.encode())\n    # note! serde_json serializes unicode characters differently\n    assert json_emoji == b'\"emoji \\xf0\\x9f\\x92\\xa9\"'\n    assert json.loads(json_emoji) == 'emoji \ud83d\udca9'\n\n\ndef test_bytes_invalid_all():\n    s = SchemaSerializer(core_schema.bytes_schema())\n    assert s.to_python(b'\\x81') == b'\\x81'\n\n    msg = 'Error serializing to JSON: invalid utf-8 sequence of 1 bytes from index 0'\n    with pytest.raises(PydanticSerializationError, match=msg):\n        s.to_json(b'\\x81')\n\n\ndef test_bytes_invalid_cpython():\n    # PyO3/pyo3#2770 is now fixed\n    s = SchemaSerializer(core_schema.bytes_schema())\n\n    with pytest.raises(UnicodeDecodeError, match=\"'utf-8' codec can't decode byte 0x81 in position 0: invalid utf-8\"):\n        s.to_python(b'\\x81', mode='json')\n\n\ndef test_bytes_dict_key():\n    s = SchemaSerializer(core_schema.dict_schema(core_schema.bytes_schema(), core_schema.int_schema()))\n    assert s.to_python({b'foobar': 123}) == {b'foobar': 123}\n    assert s.to_python({b'foobar': 123}, mode='json') == {'foobar': 123}\n    assert s.to_json({b'foobar': 123}) == b'{\"foobar\":123}'\n\n\ndef test_bytes_fallback():\n    s = SchemaSerializer(core_schema.bytes_schema())\n    with pytest.warns(UserWarning, match='Expected `bytes` but got `int` - serialized value may not be as expected'):\n        assert s.to_python(123) == 123\n    with pytest.warns(UserWarning, match='Expected `bytes` but got `int` - serialized value may not be as expected'):\n        assert s.to_python(123, mode='json') == 123\n    with pytest.warns(UserWarning, match='Expected `bytes` but got `int` - serialized value may not be as expected'):\n        assert s.to_json(123) == b'123'\n    with pytest.warns(UserWarning, match='Expected `bytes` but got `str` - serialized value may not be as expected'):\n        assert s.to_json('foo') == b'\"foo\"'\n\n\nclass BytesSubclass(bytes):\n    pass\n\n\nclass BasicClass:\n    pass\n\n\nclass BytesMixin(bytes, BasicClass):\n    pass\n\n\nclass BytesEnum(bytes, Enum):\n    foo = b'foo-value'\n    bar = b'bar-value'\n\n\n@pytest.mark.parametrize('schema_type', ['bytes', 'any'])\n@pytest.mark.parametrize(\n    'input_value,expected_json',\n    [(BytesSubclass(b'foo'), 'foo'), (BytesMixin(b'foo'), 'foo'), (BytesEnum.foo, 'foo-value')],\n)\ndef test_subclass_bytes(schema_type, input_value, expected_json):\n    s = SchemaSerializer({'type': schema_type})\n    v = s.to_python(input_value)\n    assert v == input_value\n    assert type(v) == type(input_value)\n\n    v = s.to_python(input_value, mode='json')\n    assert v == expected_json\n    assert type(v) == str\n\n    assert s.to_json(input_value) == json.dumps(expected_json).encode('utf-8')\n\n\ndef test_bytes_base64():\n    s = SchemaSerializer(core_schema.bytes_schema(), {'ser_json_bytes': 'base64'})\n    assert s.to_python(b'foobar') == b'foobar'\n\n    assert s.to_json(b'foobar') == b'\"Zm9vYmFy\"'\n    assert s.to_python(b'foobar', mode='json') == 'Zm9vYmFy'\n    assert base64.b64decode(s.to_python(b'foobar', mode='json').encode()) == b'foobar'\n\n    # with padding\n    assert s.to_json(b'foo bar') == b'\"Zm9vIGJhcg==\"'\n    assert s.to_python(b'foo bar', mode='json') == 'Zm9vIGJhcg=='\n    assert base64.b64decode(s.to_python(b'foo bar', mode='json').encode()) == b'foo bar'\n\n\ndef test_bytes_hex():\n    s = SchemaSerializer(core_schema.bytes_schema(), {'ser_json_bytes': 'hex'})\n    assert s.to_python(b'\\xff\\xff') == b'\\xff\\xff'\n    assert s.to_json(b'\\xff\\xff') == b'\"ffff\"'\n    assert s.to_python(b'\\xff\\xff', mode='json') == 'ffff' == b'\\xff\\xff'.hex()\n\n\ndef test_bytes_base64_dict_key():\n    s = SchemaSerializer(core_schema.dict_schema(core_schema.bytes_schema()), {'ser_json_bytes': 'base64'})\n\n    assert s.to_python({b'foo bar': 123}, mode='json') == {'Zm9vIGJhcg==': 123}\n    assert s.to_json({b'foo bar': 123}) == b'{\"Zm9vIGJhcg==\":123}'\n\n\ndef test_any_bytes_base64():\n    s = SchemaSerializer(core_schema.any_schema(), {'ser_json_bytes': 'base64'})\n    assert s.to_python(b'foobar') == b'foobar'\n\n    assert s.to_json(b'foobar') == b'\"Zm9vYmFy\"'\n    assert s.to_json({b'foobar': 123}) == b'{\"Zm9vYmFy\":123}'\n    assert s.to_python({b'foobar': 123}, mode='json') == {'Zm9vYmFy': 123}\n\n\nclass BasicModel:\n    def __init__(self, **kwargs):\n        for key, value in kwargs.items():\n            setattr(self, key, value)\n\n\ndef test_bytes_mode_set_via_model_config_not_serializer_config():\n    s = SchemaSerializer(\n        core_schema.model_schema(\n            BasicModel,\n            core_schema.model_fields_schema(\n                {\n                    'foo': core_schema.model_field(core_schema.bytes_schema()),\n                }\n            ),\n            config=core_schema.CoreConfig(ser_json_bytes='base64'),\n        )\n    )\n\n    bm = BasicModel(foo=b'foobar')\n    assert s.to_python(bm) == {'foo': b'foobar'}\n    assert s.to_json(bm) == b'{\"foo\":\"Zm9vYmFy\"}'\n    assert s.to_python(bm, mode='json') == {'foo': 'Zm9vYmFy'}\n\n    # assert doesn't override serializer config\n    # in V3, we can change the serialization settings provided to to_json to override model config settings,\n    # but that'd be a breaking change\n    BasicModel.__pydantic_serializer__ = s\n    assert to_json(bm, bytes_mode='utf8') == b'{\"foo\":\"Zm9vYmFy\"}'\n\n    assert to_json({'foo': b'some bytes'}, bytes_mode='base64') == b'{\"foo\":\"c29tZSBieXRlcw==\"}'\n    assert to_json({'bar': bm}, bytes_mode='base64') == b'{\"bar\":{\"foo\":\"Zm9vYmFy\"}}'\n", "tests/serializers/test_string.py": "import json\nfrom enum import Enum\n\nimport pytest\n\nfrom pydantic_core import PydanticSerializationError, SchemaSerializer, core_schema\n\n\ndef test_str():\n    v = SchemaSerializer(core_schema.str_schema())\n    assert v.to_python('foobar') == 'foobar'\n    assert v.to_python('emoji \ud83d\udca9') == 'emoji \ud83d\udca9'\n    assert v.to_json('foobar') == b'\"foobar\"'\n    assert v.to_json('foobar', indent=2) == b'\"foobar\"'\n    assert v.to_json('emoji \ud83d\udca9') == b'\"emoji \\xf0\\x9f\\x92\\xa9\"'\n    assert json.loads(v.to_json('emoji \ud83d\udca9')) == 'emoji \ud83d\udca9'\n\n    assert v.to_python('foobar', mode='json') == 'foobar'\n\n    json_emoji = v.to_json('emoji \ud83d\udca9')\n    # note! serde_json serializes unicode characters differently to json.dumps, but it's still valid JSON\n    assert json_emoji == b'\"emoji \\xf0\\x9f\\x92\\xa9\"'\n    assert json.loads(json_emoji) == 'emoji \ud83d\udca9'\n\n\ndef test_str_fallback():\n    s = SchemaSerializer(core_schema.str_schema())\n    assert s.to_python(None) is None\n    assert s.to_python(None, mode='json') is None\n    assert s.to_json(None) == b'null'\n    with pytest.warns(UserWarning, match='Expected `str` but got `int` - serialized value may not be as expected'):\n        assert s.to_python(123) == 123\n    with pytest.warns(UserWarning, match='Expected `str` but got `int` - serialized value may not be as expected'):\n        assert s.to_python(123, mode='json') == 123\n    with pytest.warns(UserWarning, match='Expected `str` but got `int` - serialized value may not be as expected'):\n        assert s.to_json(123) == b'123'\n    with pytest.warns(UserWarning, match='Expected `str` but got `int` - serialized value may not be as expected'):\n        assert s.to_python(123, warnings='warn') == 123\n    with pytest.warns(UserWarning, match='Expected `str` but got `int` - serialized value may not be as expected'):\n        assert s.to_python(123, mode='json', warnings='warn') == 123\n    with pytest.warns(UserWarning, match='Expected `str` but got `int` - serialized value may not be as expected'):\n        assert s.to_json(123, warnings='warn') == b'123'\n    with pytest.warns(UserWarning, match='Expected `str` but got `int` - serialized value may not be as expected'):\n        assert s.to_python(123, warnings=True) == 123\n    with pytest.warns(UserWarning, match='Expected `str` but got `int` - serialized value may not be as expected'):\n        assert s.to_python(123, mode='json', warnings=True) == 123\n    with pytest.warns(UserWarning, match='Expected `str` but got `int` - serialized value may not be as expected'):\n        assert s.to_json(123, warnings=True) == b'123'\n\n\ndef test_str_no_warnings():\n    s = SchemaSerializer(core_schema.str_schema())\n    assert s.to_python(123, warnings=False) == 123\n    assert s.to_python(123, warnings='none') == 123\n    assert s.to_python(123, mode='json', warnings=False) == 123\n    assert s.to_python(123, mode='json', warnings='none') == 123\n    assert s.to_json(123, warnings=False) == b'123'\n    assert s.to_json(123, warnings='none') == b'123'\n\n\ndef test_str_errors():\n    s = SchemaSerializer(core_schema.str_schema())\n    with pytest.raises(\n        PydanticSerializationError, match='Expected `str` but got `int` - serialized value may not be as expected'\n    ):\n        assert s.to_python(123, warnings='error') == 123\n    with pytest.raises(\n        PydanticSerializationError, match='Expected `str` but got `int` - serialized value may not be as expected'\n    ):\n        assert s.to_python(123, mode='json', warnings='error') == 123\n    with pytest.raises(\n        PydanticSerializationError, match='Expected `str` but got `int` - serialized value may not be as expected'\n    ):\n        assert s.to_json(123, warnings='error') == b'123'\n\n\nclass StrSubclass(str):\n    pass\n\n\nclass BasicClass:\n    pass\n\n\nclass StrMixin(str, BasicClass):\n    pass\n\n\nclass StrEnum(str, Enum):\n    foo = 'foo-value'\n    bar = 'bar-value'\n\n\n@pytest.mark.parametrize('schema_type', ['str', 'any'])\n@pytest.mark.parametrize(\n    'input_value,expected', [(StrSubclass('foo'), 'foo'), (StrMixin('foo'), 'foo'), (StrEnum.foo, 'foo-value')]\n)\ndef test_subclass_str(schema_type, input_value, expected):\n    s = SchemaSerializer({'type': schema_type})\n    v = s.to_python(input_value)\n    assert v == input_value\n    assert type(v) == type(input_value)\n\n    v = s.to_python(input_value, mode='json')\n    assert v == expected\n    assert type(v) == str\n\n    assert s.to_json(input_value) == json.dumps(expected).encode('utf-8')\n", "tests/serializers/test_model.py": "import dataclasses\nimport json\nimport platform\nfrom random import randint\nfrom typing import Any, ClassVar, Dict\n\ntry:\n    from functools import cached_property\nexcept ImportError:\n    cached_property = None\n\nimport pytest\nfrom dirty_equals import IsJson\n\nfrom pydantic_core import PydanticSerializationError, SchemaSerializer, SchemaValidator, core_schema\n\nfrom ..conftest import plain_repr\n\non_pypy = platform.python_implementation() == 'PyPy'\n# pypy doesn't seem to maintain order of `__dict__`\nif on_pypy:\n    IsStrictDict = dict\nelse:\n    from dirty_equals import IsStrictDict\n\n\nclass BasicModel:\n    def __init__(self, **kwargs):\n        for key, value in kwargs.items():\n            setattr(self, key, value)\n\n\nclass BasicSubModel(BasicModel):\n    pass\n\n\ndef test_model():\n    s = SchemaSerializer(\n        core_schema.model_schema(\n            BasicModel,\n            core_schema.model_fields_schema(\n                {\n                    'foo': core_schema.model_field(core_schema.int_schema()),\n                    'bar': core_schema.model_field(core_schema.bytes_schema()),\n                }\n            ),\n        )\n    )\n    assert 'mode:SimpleDict' in plain_repr(s)\n    assert 'has_extra:false' in plain_repr(s)\n    assert s.to_python(BasicModel(foo=1, bar=b'more')) == IsStrictDict(foo=1, bar=b'more')\n    assert s.to_python(BasicSubModel(foo=1, bar=b'more')) == IsStrictDict(foo=1, bar=b'more')\n    assert s.to_python(BasicModel(bar=b'more', foo=1)) == IsStrictDict(bar=b'more', foo=1)\n    assert s.to_python(BasicModel(foo=1, c=3, bar=b'more')) == IsStrictDict(foo=1, bar=b'more')\n    assert s.to_python(BasicModel(bar=b'more', foo=1, c=3), mode='json') == IsStrictDict(bar='more', foo=1)\n    assert s.to_python(BasicSubModel(bar=b'more', foo=1, c=3), mode='json') == IsStrictDict(bar='more', foo=1)\n\n    j = s.to_json(BasicModel(bar=b'more', foo=1, c=3))\n    if on_pypy:\n        assert json.loads(j) == {'bar': 'more', 'foo': 1}\n    else:\n        assert j == b'{\"bar\":\"more\",\"foo\":1}'\n\n    assert json.loads(s.to_json(BasicSubModel(bar=b'more', foo=1, c=3))) == {'bar': 'more', 'foo': 1}\n\n\n@dataclasses.dataclass\nclass DataClass:\n    class_var: ClassVar[int] = 1\n    foo: int\n    bar: str\n    spam: bytes\n    frog: dataclasses.InitVar[int]\n\n\ndef test_dataclass():\n    schema = core_schema.call_schema(\n        core_schema.arguments_schema(\n            [\n                core_schema.arguments_parameter('foo', core_schema.int_schema()),\n                core_schema.arguments_parameter('bar', core_schema.str_schema()),\n                core_schema.arguments_parameter('spam', core_schema.bytes_schema(), mode='keyword_only'),\n                core_schema.arguments_parameter('frog', core_schema.int_schema(), mode='keyword_only'),\n            ]\n        ),\n        DataClass,\n        serialization=core_schema.model_ser_schema(\n            DataClass,\n            core_schema.model_fields_schema(\n                {\n                    'foo': core_schema.model_field(core_schema.int_schema()),\n                    'bar': core_schema.model_field(core_schema.str_schema()),\n                    'spam': core_schema.model_field(core_schema.bytes_schema()),\n                }\n            ),\n        ),\n    )\n    # just check validation works as expected\n    v = SchemaValidator(schema)\n    dc = v.validate_python({'foo': 1, 'bar': 'bar-str', 'spam': 'bite', 'frog': 123})\n    assert dc == DataClass(foo=1, bar='bar-str', spam=b'bite', frog=123)\n    dc.class_var = 2\n    assert dataclasses.is_dataclass(dc)\n\n    s = SchemaSerializer(schema)\n\n    assert dataclasses.asdict(dc) == IsStrictDict(foo=1, bar='bar-str', spam=b'bite')\n    assert s.to_python(dc) == IsStrictDict(foo=1, bar='bar-str', spam=b'bite')\n\n    assert s.to_python(dc, mode='json') == {'foo': 1, 'bar': 'bar-str', 'spam': 'bite'}\n    assert json.loads(s.to_json(dc)) == {'foo': 1, 'bar': 'bar-str', 'spam': 'bite'}\n\n\ndef test_model_allow_extra():\n    s = SchemaSerializer(\n        core_schema.model_schema(\n            BasicModel,\n            core_schema.model_fields_schema(\n                {\n                    'foo': core_schema.model_field(core_schema.int_schema()),\n                    'bar': core_schema.model_field(core_schema.bytes_schema()),\n                },\n                extra_behavior='allow',\n            ),\n            extra_behavior='allow',\n        )\n    )\n    assert s.to_python(BasicModel(foo=1, bar=b'more', __pydantic_extra__={})) == IsStrictDict(foo=1, bar=b'more')\n    assert s.to_python(BasicModel(bar=b'more', foo=1, __pydantic_extra__={})) == IsStrictDict(bar=b'more', foo=1)\n    assert s.to_python(BasicModel(foo=1, __pydantic_extra__=dict(c=3), bar=b'more')) == IsStrictDict(\n        foo=1, bar=b'more', c=3\n    )\n    assert s.to_python(BasicModel(bar=b'more', __pydantic_extra__=dict(c=3, foo=1)), mode='json') == IsStrictDict(\n        bar='more', c=3, foo=1\n    )\n\n    j = s.to_json(BasicModel(bar=b'more', foo=1, __pydantic_extra__=dict(c=3)))\n    if on_pypy:\n        assert j == IsJson({'bar': 'more', 'foo': 1, 'c': 3})\n    else:\n        assert j == b'{\"bar\":\"more\",\"foo\":1,\"c\":3}'\n\n\ndef test_model_recursive_in_extra():\n    # See https://github.com/pydantic/pydantic/issues/6571\n\n    class Model(BasicModel):\n        __slots__ = '__pydantic_extra__'\n\n    s = SchemaSerializer(\n        core_schema.model_schema(\n            Model, core_schema.model_fields_schema({}, extra_behavior='allow'), extra_behavior='allow'\n        )\n    )\n    Model.__pydantic_serializer__ = s\n\n    assert s.to_json(Model(__pydantic_extra__=dict(other=Model(__pydantic_extra__={})))) == b'{\"other\":{}}'\n\n\n@pytest.mark.parametrize(\n    'params',\n    [\n        dict(include=None, exclude=None, expected={'a': 0, 'b': 1, 'c': 2, 'd': 3}),\n        dict(include={'a', 'b'}, exclude=None, expected={'a': 0, 'b': 1}),\n        dict(include={'a': ..., 'b': ...}, exclude=None, expected={'a': 0, 'b': 1}),\n        dict(include={'a': {1}, 'b': {1}}, exclude=None, expected={'a': 0, 'b': 1}),\n        dict(include=None, exclude={'a', 'b'}, expected={'c': 2, 'd': 3}),\n        dict(include=None, exclude={'a': ..., 'b': ...}, expected={'c': 2, 'd': 3}),\n        dict(include={'a', 'b'}, exclude={'b', 'c'}, expected={'a': 0}),\n        dict(include=None, exclude={'d': {1}}, expected={'a': 0, 'b': 1, 'c': 2, 'd': 3}),\n        dict(include={'a', 'b'}, exclude={'d': {1}}, expected={'a': 0, 'b': 1}),\n        dict(include={'a', 'b'}, exclude={'b': {1}}, expected={'a': 0, 'b': 1}),\n        dict(include={'a', 'b'}, exclude={'b': ...}, expected={'a': 0}),\n        dict(include=None, exclude={'__all__'}, expected={}),\n    ],\n)\ndef test_include_exclude_args(params):\n    s = SchemaSerializer(\n        core_schema.model_schema(\n            BasicModel,\n            core_schema.model_fields_schema(\n                {\n                    'a': core_schema.model_field(core_schema.int_schema()),\n                    'b': core_schema.model_field(core_schema.int_schema()),\n                    'c': core_schema.model_field(core_schema.int_schema()),\n                    'd': core_schema.model_field(core_schema.int_schema()),\n                }\n            ),\n        )\n    )\n\n    # user IsStrictDict to check dict order\n    include, exclude, expected = params['include'], params['exclude'], IsStrictDict(params['expected'])\n    value = BasicModel(a=0, b=1, c=2, d=3)\n    assert s.to_python(value, include=include, exclude=exclude) == expected\n    assert s.to_python(value, mode='json', include=include, exclude=exclude) == expected\n    assert json.loads(s.to_json(value, include=include, exclude=exclude)) == expected\n\n\ndef test_alias():\n    s = SchemaSerializer(\n        core_schema.model_schema(\n            BasicModel,\n            core_schema.model_fields_schema(\n                {\n                    'cat': core_schema.model_field(core_schema.int_schema(), serialization_alias='Meow'),\n                    'dog': core_schema.model_field(core_schema.int_schema(), serialization_alias='Woof'),\n                    'bird': core_schema.model_field(core_schema.int_schema()),\n                }\n            ),\n        )\n    )\n    value = BasicModel(cat=0, dog=1, bird=2)\n    assert s.to_python(value) == IsStrictDict(Meow=0, Woof=1, bird=2)\n\n\ndef test_model_wrong_warn():\n    s = SchemaSerializer(\n        core_schema.model_schema(\n            type('MyModel', (), {}),\n            core_schema.model_fields_schema(\n                {\n                    'foo': core_schema.model_field(core_schema.int_schema()),\n                    'bar': core_schema.model_field(core_schema.bytes_schema()),\n                }\n            ),\n        )\n    )\n    assert s.to_python(None) is None\n    assert s.to_python(None, mode='json') is None\n    assert s.to_json(None) == b'null'\n\n    with pytest.warns(UserWarning, match='Expected `MyModel` but got `int` - serialized value may.+'):\n        assert s.to_python(123) == 123\n    with pytest.warns(UserWarning, match='Expected `MyModel` but got `int` - serialized value may.+'):\n        assert s.to_python(123, mode='json') == 123\n    with pytest.warns(UserWarning, match='Expected `MyModel` but got `int` - serialized value may.+'):\n        assert s.to_json(123) == b'123'\n\n    with pytest.warns(UserWarning, match='Expected `MyModel` but got `dict` - serialized value may.+'):\n        assert s.to_python({'foo': 1, 'bar': b'more'}) == {'foo': 1, 'bar': b'more'}\n\n\ndef test_exclude_none():\n    s = SchemaSerializer(\n        core_schema.model_schema(\n            BasicModel,\n            core_schema.model_fields_schema(\n                {\n                    'foo': core_schema.model_field(core_schema.nullable_schema(core_schema.int_schema())),\n                    'bar': core_schema.model_field(core_schema.bytes_schema()),\n                },\n                extra_behavior='ignore',  # this is the default\n            ),\n        )\n    )\n    assert s.to_python(BasicModel(foo=1, bar=b'more')) == {'foo': 1, 'bar': b'more'}\n    assert s.to_python(BasicModel(foo=None, bar=b'more')) == {'foo': None, 'bar': b'more'}\n    assert s.to_python(BasicModel(foo=None, bar=b'more'), exclude_none=True) == {'bar': b'more'}\n\n    assert s.to_python(BasicModel(foo=None, bar=b'more'), mode='json') == {'foo': None, 'bar': 'more'}\n    assert s.to_python(BasicModel(foo=None, bar=b'more'), mode='json', exclude_none=True) == {'bar': 'more'}\n\n    assert s.to_json(BasicModel(foo=1, bar=b'more')) == b'{\"foo\":1,\"bar\":\"more\"}'\n    assert s.to_json(BasicModel(foo=None, bar=b'more')) == b'{\"foo\":null,\"bar\":\"more\"}'\n    assert s.to_json(BasicModel(foo=None, bar=b'more'), exclude_none=True) == b'{\"bar\":\"more\"}'\n\n\nclass FieldsSetModel:\n    __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n\n    def __init__(self, **kwargs):\n        for key, value in kwargs.items():\n            setattr(self, key, value)\n\n\ndef test_exclude_unset():\n    s = SchemaSerializer(\n        core_schema.model_schema(\n            FieldsSetModel,\n            core_schema.model_fields_schema(\n                {\n                    'foo': core_schema.model_field(core_schema.int_schema()),\n                    'bar': core_schema.model_field(core_schema.int_schema()),\n                    'spam': core_schema.model_field(core_schema.int_schema()),\n                },\n                extra_behavior='ignore',  # this is the default\n            ),\n        )\n    )\n    m = FieldsSetModel(foo=1, bar=2, spam=3, __pydantic_fields_set__={'bar', 'spam'})\n    assert s.to_python(m) == {'foo': 1, 'bar': 2, 'spam': 3}\n    assert s.to_python(m, exclude_unset=True) == {'bar': 2, 'spam': 3}\n    assert s.to_python(m, exclude=None, exclude_unset=True) == {'bar': 2, 'spam': 3}\n    assert s.to_python(m, exclude={'bar'}, exclude_unset=True) == {'spam': 3}\n    assert s.to_python(m, exclude={'bar': ...}, exclude_unset=True) == {'spam': 3}\n    assert s.to_python(m, exclude={'bar': {}}, exclude_unset=True) == {'bar': 2, 'spam': 3}\n\n    assert s.to_json(m, exclude=None, exclude_unset=True) == b'{\"bar\":2,\"spam\":3}'\n    assert s.to_json(m, exclude={'bar'}, exclude_unset=True) == b'{\"spam\":3}'\n    assert s.to_json(m, exclude={'bar': ...}, exclude_unset=True) == b'{\"spam\":3}'\n    assert s.to_json(m, exclude={'bar': {}}, exclude_unset=True) == b'{\"bar\":2,\"spam\":3}'\n\n    m2 = FieldsSetModel(foo=1, bar=2, spam=3, __pydantic_fields_set__={'bar', 'spam', 'missing'})\n    assert s.to_python(m2) == {'foo': 1, 'bar': 2, 'spam': 3}\n    assert s.to_python(m2, exclude_unset=True) == {'bar': 2, 'spam': 3}\n\n\n@pytest.mark.parametrize(\n    'exclude,expected',\n    [\n        pytest.param(\n            {'subs': {'__all__': {'subsubs': {'__all__': {'i'}}}}},\n            {'subs': [{'k': 1, 'subsubs': [{'j': 1}, {'j': 2}]}, {'k': 2, 'subsubs': [{'j': 3}]}]},\n            id='Normal nested __all__',\n        ),\n        pytest.param(\n            {'subs': {'__all__': {'subsubs': {'__all__': {'i'}}}, 0: {'subsubs': {'__all__': {'j'}}}}},\n            {'subs': [{'k': 1, 'subsubs': [{}, {}]}, {'k': 2, 'subsubs': [{'j': 3}]}]},\n            id='Merge sub dicts 1',\n        ),\n        pytest.param(\n            {'subs': {'__all__': {'subsubs': ...}, 0: {'subsubs': {'__all__': {'j'}}}}},\n            {'subs': [{'k': 1, 'subsubs': [{'i': 1}, {'i': 2}]}, {'k': 2}]},\n            # {'subs': [{'k': 1                                 }, {'k': 2}]}\n            id='Merge sub sets 2',\n        ),\n        pytest.param(\n            {'subs': {'__all__': {'subsubs': {'__all__': {'j'}}}, 0: {'subsubs': ...}}},\n            {'subs': [{'k': 1}, {'k': 2, 'subsubs': [{'i': 3}]}]},\n            id='Merge sub sets 3',\n        ),\n        pytest.param(\n            {'subs': {'__all__': {'subsubs': {0}}, 0: {'subsubs': {1}}}},\n            {'subs': [{'k': 1, 'subsubs': []}, {'k': 2, 'subsubs': []}]},\n            id='Merge sub sets 1',\n        ),\n        pytest.param(\n            {'subs': {'__all__': {'subsubs': {0: {'i'}}}, 0: {'subsubs': {1}}}},\n            {'subs': [{'k': 1, 'subsubs': [{'j': 1}]}, {'k': 2, 'subsubs': [{'j': 3}]}]},\n            id='Merge sub dict-set',\n        ),\n        pytest.param({'subs': {'__all__': {'subsubs'}, 0: {'k'}}}, {'subs': [{}, {'k': 2}]}, id='Different keys 1'),\n        pytest.param(\n            {'subs': {'__all__': {'subsubs': ...}, 0: {'k'}}}, {'subs': [{}, {'k': 2}]}, id='Different keys 2'\n        ),\n        pytest.param(\n            {'subs': {'__all__': {'subsubs'}, 0: {'k': ...}}}, {'subs': [{}, {'k': 2}]}, id='Different keys 3'\n        ),\n        pytest.param(\n            {'subs': {'__all__': {'subsubs': {'__all__': {'i'}, 0: {'j'}}}}},\n            {'subs': [{'k': 1, 'subsubs': [{}, {'j': 2}]}, {'k': 2, 'subsubs': [{}]}]},\n            id='Nested different keys 1',\n        ),\n        pytest.param(\n            {'subs': {'__all__': {'subsubs': {'__all__': {'i': ...}, 0: {'j'}}}}},\n            {'subs': [{'k': 1, 'subsubs': [{}, {'j': 2}]}, {'k': 2, 'subsubs': [{}]}]},\n            id='Nested different keys 2',\n        ),\n        pytest.param(\n            {'subs': {'__all__': {'subsubs': {'__all__': {'i'}, 0: {'j': ...}}}}},\n            {'subs': [{'k': 1, 'subsubs': [{}, {'j': 2}]}, {'k': 2, 'subsubs': [{}]}]},\n            id='Nested different keys 3',\n        ),\n        pytest.param(\n            {'subs': {'__all__': {'subsubs'}, 0: {'subsubs': {'__all__': {'j'}}}}},\n            {'subs': [{'k': 1, 'subsubs': [{'i': 1}, {'i': 2}]}, {'k': 2}]},\n            id='Ignore __all__ for index with defined exclude 1',\n        ),\n        pytest.param(\n            {'subs': {'__all__': {'subsubs': {'__all__': {'j'}}}, 0: ...}},\n            {'subs': [{'k': 2, 'subsubs': [{'i': 3}]}]},\n            id='Ignore __all__ for index with defined exclude 2',\n        ),\n        pytest.param(\n            {'subs': {'__all__': ..., 0: {'subsubs'}}},\n            {'subs': [{'k': 1}]},\n            id='Ignore __all__ for index with defined exclude 3',\n        ),\n    ],\n)\ndef test_advanced_exclude_nested_lists(exclude, expected):\n    \"\"\"\n    Taken from pydantic and modified to generate the schema directly.\n    \"\"\"\n    # class SubSubModel(BaseModel):\n    #     i: int\n    #     j: int\n\n    sub_sub_model_schema = core_schema.model_schema(\n        type('SubSubModel', (), {}),\n        core_schema.model_fields_schema(\n            dict(\n                i=core_schema.model_field(core_schema.int_schema()), j=core_schema.model_field(core_schema.int_schema())\n            )\n        ),\n    )\n\n    # class SubModel(BaseModel):\n    #     k: int\n    #     subsubs: List[SubSubModel]\n\n    sub_model_schema = core_schema.model_schema(\n        type('SubModel', (), {}),\n        core_schema.model_fields_schema(\n            dict(\n                k=core_schema.model_field(core_schema.int_schema()),\n                subsubs=core_schema.model_field(core_schema.list_schema(sub_sub_model_schema)),\n            )\n        ),\n    )\n\n    # class Model(BaseModel):\n    #     subs: List[SubModel]\n\n    model_schema = core_schema.model_schema(\n        BasicModel,\n        core_schema.model_fields_schema(dict(subs=core_schema.model_field(core_schema.list_schema(sub_model_schema)))),\n    )\n    v = SchemaValidator(model_schema)\n\n    data = v.validate_python(\n        dict(subs=[dict(k=1, subsubs=[dict(i=1, j=1), dict(i=2, j=2)]), dict(k=2, subsubs=[dict(i=3, j=3)])])\n    )\n\n    s = SchemaSerializer(model_schema)\n\n    assert s.to_python(data, exclude=exclude) == expected\n\n\ndef test_function_plain_field_serializer_to_python():\n    @dataclasses.dataclass\n    class Model:\n        x: int\n\n        def ser_x(self, v: Any, _) -> str:\n            assert self.x == 1_000\n            return f'{v:_}'\n\n    s = SchemaSerializer(\n        core_schema.model_schema(\n            Model,\n            core_schema.model_fields_schema(\n                {\n                    'x': core_schema.model_field(\n                        core_schema.int_schema(\n                            serialization=core_schema.plain_serializer_function_ser_schema(\n                                Model.ser_x, is_field_serializer=True, info_arg=True\n                            )\n                        )\n                    )\n                }\n            ),\n        )\n    )\n    assert s.to_python(Model(x=1000)) == {'x': '1_000'}\n\n\n@pytest.mark.skipif(cached_property is None, reason='cached_property is not available')\ndef test_field_serializer_cached_property():\n    @dataclasses.dataclass\n    class Model:\n        x: int\n        y: int\n\n        @cached_property\n        def x_formatted(self) -> str:\n            return f'{self.x:_}'\n\n        # This is a @computed_field\n        @cached_property\n        def y_formatted(self) -> str:\n            return f'{self.y:_}'\n\n        def ser_x(self, v: Any, _) -> str:\n            assert self.x == 1_000 == v\n            return self.x_formatted\n\n        def ser_y(self, v: Any, _) -> str:\n            assert self.y == 2_000 == v\n            return self.y_formatted\n\n    s = SchemaSerializer(\n        core_schema.model_schema(\n            Model,\n            core_schema.model_fields_schema(\n                {\n                    'x': core_schema.model_field(\n                        core_schema.int_schema(\n                            serialization=core_schema.plain_serializer_function_ser_schema(\n                                Model.ser_x, is_field_serializer=True, info_arg=True\n                            )\n                        )\n                    ),\n                    'y': core_schema.model_field(\n                        core_schema.int_schema(\n                            serialization=core_schema.plain_serializer_function_ser_schema(\n                                Model.ser_y, is_field_serializer=True, info_arg=True\n                            )\n                        )\n                    ),\n                },\n                computed_fields=[core_schema.computed_field('y_formatted', core_schema.str_schema())],\n            ),\n        )\n    )\n    assert s.to_python(Model(x=1000, y=2000)) == {'x': '1_000', 'y': '2_000', 'y_formatted': '2_000'}\n    assert s.to_json(Model(x=1000, y=2000)) == b'{\"x\":\"1_000\",\"y\":\"2_000\",\"y_formatted\":\"2_000\"}'\n\n\ndef test_function_wrap_field_serializer_to_python():\n    @dataclasses.dataclass\n    class Model:\n        x: int\n\n        def ser_x(self, v: Any, serializer: core_schema.SerializerFunctionWrapHandler, _) -> str:\n            x = serializer(v)\n            assert self.x == 1_000\n            return f'{x:_}'\n\n    s = SchemaSerializer(\n        core_schema.model_schema(\n            Model,\n            core_schema.model_fields_schema(\n                {\n                    'x': core_schema.model_field(\n                        core_schema.int_schema(\n                            serialization=core_schema.wrap_serializer_function_ser_schema(\n                                Model.ser_x, is_field_serializer=True, info_arg=True, schema=core_schema.any_schema()\n                            )\n                        )\n                    )\n                }\n            ),\n        )\n    )\n    assert s.to_python(Model(x=1000)) == {'x': '1_000'}\n\n\ndef test_function_plain_field_serializer_to_json():\n    @dataclasses.dataclass\n    class Model:\n        x: int\n\n        def ser_x(self, v: Any, _) -> str:\n            assert self.x == 1_000\n            return f'{v:_}'\n\n    s = SchemaSerializer(\n        core_schema.model_schema(\n            Model,\n            core_schema.model_fields_schema(\n                {\n                    'x': core_schema.model_field(\n                        core_schema.int_schema(\n                            serialization=core_schema.plain_serializer_function_ser_schema(\n                                Model.ser_x, is_field_serializer=True, info_arg=True\n                            )\n                        )\n                    )\n                }\n            ),\n        )\n    )\n    assert json.loads(s.to_json(Model(x=1000))) == {'x': '1_000'}\n\n\ndef test_function_wrap_field_serializer_to_json():\n    @dataclasses.dataclass\n    class Model:\n        x: int\n\n        def ser_x(self, v: Any, serializer: core_schema.SerializerFunctionWrapHandler, _) -> str:\n            assert self.x == 1_000\n            x = serializer(v)\n            return f'{x:_}'\n\n    s = SchemaSerializer(\n        core_schema.model_schema(\n            Model,\n            core_schema.model_fields_schema(\n                {\n                    'x': core_schema.model_field(\n                        core_schema.int_schema(\n                            serialization=core_schema.wrap_serializer_function_ser_schema(\n                                Model.ser_x, is_field_serializer=True, info_arg=True, schema=core_schema.any_schema()\n                            )\n                        )\n                    )\n                }\n            ),\n        )\n    )\n    assert json.loads(s.to_json(Model(x=1000))) == {'x': '1_000'}\n\n\ndef test_property():\n    @dataclasses.dataclass\n    class Model:\n        def __init__(self, **kwargs):\n            for key, value in kwargs.items():\n                setattr(self, key, value)\n\n        @property\n        def area(self) -> bytes:\n            a = self.width * self.height\n            return b'%d' % a\n\n    s = SchemaSerializer(\n        core_schema.model_schema(\n            Model,\n            core_schema.model_fields_schema(\n                {\n                    'width': core_schema.model_field(core_schema.int_schema()),\n                    'height': core_schema.model_field(core_schema.int_schema()),\n                },\n                computed_fields=[core_schema.computed_field('area', core_schema.bytes_schema())],\n            ),\n        )\n    )\n    assert s.to_python(Model(width=3, height=4)) == {'width': 3, 'height': 4, 'area': b'12'}\n    assert s.to_python(Model(width=3, height=4), mode='json') == {'width': 3, 'height': 4, 'area': '12'}\n    assert s.to_json(Model(width=3, height=4)) == b'{\"width\":3,\"height\":4,\"area\":\"12\"}'\n\n    assert s.to_python(Model(width=3, height=4), round_trip=True) == {'width': 3, 'height': 4}\n    assert s.to_json(Model(width=3, height=4), round_trip=True) == b'{\"width\":3,\"height\":4}'\n\n\ndef test_property_alias():\n    @dataclasses.dataclass\n    class Model:\n        width: int\n        height: int\n\n        @property\n        def area(self) -> int:\n            return self.width * self.height\n\n        @property\n        def volume(self) -> int:\n            return self.area * self.height\n\n    s = SchemaSerializer(\n        core_schema.model_schema(\n            Model,\n            core_schema.model_fields_schema(\n                {\n                    'width': core_schema.model_field(core_schema.int_schema()),\n                    'height': core_schema.model_field(core_schema.int_schema()),\n                },\n                computed_fields=[\n                    core_schema.computed_field('area', core_schema.int_schema(), alias='Area'),\n                    core_schema.computed_field('volume', core_schema.int_schema()),\n                ],\n            ),\n        )\n    )\n    assert s.to_python(Model(3, 4)) == {'width': 3, 'height': 4, 'Area': 12, 'volume': 48}\n    assert s.to_python(Model(3, 4), mode='json') == {'width': 3, 'height': 4, 'Area': 12, 'volume': 48}\n    assert s.to_json(Model(3, 4)) == b'{\"width\":3,\"height\":4,\"Area\":12,\"volume\":48}'\n\n\ndef test_computed_field_exclude_none():\n    @dataclasses.dataclass\n    class Model:\n        width: int\n        height: int\n\n        @property\n        def area(self) -> int:\n            return self.width * self.height\n\n        @property\n        def volume(self) -> None:\n            return None\n\n    s = SchemaSerializer(\n        core_schema.model_schema(\n            Model,\n            core_schema.model_fields_schema(\n                {\n                    'width': core_schema.model_field(core_schema.int_schema()),\n                    'height': core_schema.model_field(core_schema.int_schema()),\n                },\n                computed_fields=[\n                    core_schema.computed_field('area', core_schema.int_schema(), alias='Area'),\n                    core_schema.computed_field('volume', core_schema.int_schema()),\n                ],\n            ),\n        )\n    )\n    assert s.to_python(Model(3, 4), exclude_none=False) == {'width': 3, 'height': 4, 'Area': 12, 'volume': None}\n    assert s.to_python(Model(3, 4), exclude_none=True) == {'width': 3, 'height': 4, 'Area': 12}\n    assert s.to_python(Model(3, 4), mode='json', exclude_none=False) == {\n        'width': 3,\n        'height': 4,\n        'Area': 12,\n        'volume': None,\n    }\n    assert s.to_python(Model(3, 4), mode='json', exclude_none=True) == {'width': 3, 'height': 4, 'Area': 12}\n    assert s.to_json(Model(3, 4), exclude_none=False) == b'{\"width\":3,\"height\":4,\"Area\":12,\"volume\":null}'\n    assert s.to_json(Model(3, 4), exclude_none=True) == b'{\"width\":3,\"height\":4,\"Area\":12}'\n\n\ndef test_computed_field_exclude_none_different_order():\n    # verify that order of computed fields doesn't matter\n    # issue originally reported via: https://github.com/pydantic/pydantic/issues/8691\n\n    @dataclasses.dataclass\n    class Model:\n        width: int\n        height: int\n\n        @property\n        def volume(self) -> None:\n            return None\n\n        @property\n        def area(self) -> int:\n            return self.width * self.height\n\n    s = SchemaSerializer(\n        core_schema.model_schema(\n            Model,\n            core_schema.model_fields_schema(\n                {\n                    'width': core_schema.model_field(core_schema.int_schema()),\n                    'height': core_schema.model_field(core_schema.int_schema()),\n                },\n                computed_fields=[\n                    core_schema.computed_field('volume', core_schema.int_schema()),\n                    core_schema.computed_field('area', core_schema.int_schema(), alias='Area'),\n                ],\n            ),\n        )\n    )\n    assert s.to_python(Model(3, 4), exclude_none=False) == {'width': 3, 'height': 4, 'Area': 12, 'volume': None}\n    assert s.to_python(Model(3, 4), exclude_none=True) == {'width': 3, 'height': 4, 'Area': 12}\n    assert s.to_python(Model(3, 4), mode='json', exclude_none=False) == {\n        'width': 3,\n        'height': 4,\n        'Area': 12,\n        'volume': None,\n    }\n    assert s.to_python(Model(3, 4), mode='json', exclude_none=True) == {'width': 3, 'height': 4, 'Area': 12}\n    assert s.to_json(Model(3, 4), exclude_none=False) == b'{\"width\":3,\"height\":4,\"volume\":null,\"Area\":12}'\n    assert s.to_json(Model(3, 4), exclude_none=True) == b'{\"width\":3,\"height\":4,\"Area\":12}'\n\n\n@pytest.mark.skipif(cached_property is None, reason='cached_property is not available')\ndef test_cached_property_alias():\n    @dataclasses.dataclass\n    class Model:\n        width: int\n        height: int\n\n        @cached_property\n        def area(self) -> int:\n            return self.width * self.height\n\n    s = SchemaSerializer(\n        core_schema.model_schema(\n            Model,\n            core_schema.model_fields_schema(\n                {\n                    'width': core_schema.model_field(core_schema.int_schema()),\n                    'height': core_schema.model_field(core_schema.int_schema()),\n                },\n                computed_fields=[core_schema.computed_field('area', core_schema.int_schema())],\n            ),\n        )\n    )\n    assert s.to_python(Model(3, 4)) == {'width': 3, 'height': 4, 'area': 12}\n    assert s.to_python(Model(3, 4), mode='json') == {'width': 3, 'height': 4, 'area': 12}\n    assert s.to_json(Model(3, 4)) == b'{\"width\":3,\"height\":4,\"area\":12}'\n\n\ndef test_property_attribute_error():\n    @dataclasses.dataclass\n    class Model:\n        width: int\n\n    s = SchemaSerializer(\n        core_schema.model_schema(\n            Model,\n            core_schema.model_fields_schema(\n                {'width': core_schema.model_field(core_schema.int_schema())},\n                computed_fields=[core_schema.computed_field('area', core_schema.bytes_schema())],\n            ),\n        )\n    )\n    with pytest.raises(AttributeError, match=\"^'Model' object has no attribute 'area'$\"):\n        s.to_python(Model(3))\n    with pytest.raises(AttributeError, match=\"^'Model' object has no attribute 'area'$\"):\n        s.to_python(Model(3), mode='json')\n\n    e = \"^Error serializing to JSON: AttributeError: 'Model' object has no attribute 'area'$\"\n    with pytest.raises(PydanticSerializationError, match=e):\n        s.to_json(Model(3))\n\n\ndef test_property_other_error():\n    @dataclasses.dataclass\n    class Model:\n        width: int\n\n        @property\n        def area(self) -> int:\n            raise ValueError('xxx')\n\n    s = SchemaSerializer(\n        core_schema.model_schema(\n            Model,\n            core_schema.model_fields_schema(\n                {'width': core_schema.model_field(core_schema.int_schema())},\n                computed_fields=[core_schema.computed_field('area', core_schema.bytes_schema())],\n            ),\n        )\n    )\n    with pytest.raises(ValueError, match='^xxx$'):\n        s.to_python(Model(3))\n\n    with pytest.raises(ValueError, match='^xxx$'):\n        s.to_python(Model(3), mode='json')\n\n    e = '^Error serializing to JSON: ValueError: xxx$'\n    with pytest.raises(PydanticSerializationError, match=e):\n        s.to_json(Model(3))\n\n\ndef test_property_include_exclude():\n    @dataclasses.dataclass\n    class Model:\n        a: int\n\n        @property\n        def b(self):\n            return [1, 2, b'3']\n\n    s = SchemaSerializer(\n        core_schema.model_schema(\n            Model,\n            core_schema.model_fields_schema(\n                {'a': core_schema.model_field(core_schema.int_schema())},\n                computed_fields=[core_schema.computed_field('b', core_schema.list_schema())],\n            ),\n        )\n    )\n    assert s.to_python(Model(1)) == {'a': 1, 'b': [1, 2, b'3']}\n    assert s.to_python(Model(1), exclude={'b'}) == {'a': 1}\n    assert s.to_python(Model(1), include={'a'}) == {'a': 1}\n    assert s.to_python(Model(1), exclude={'b': [0]}) == {'a': 1, 'b': [2, b'3']}\n\n    assert s.to_python(Model(1), mode='json') == {'a': 1, 'b': [1, 2, '3']}\n    assert s.to_python(Model(1), mode='json', exclude={'b'}) == {'a': 1}\n    assert s.to_python(Model(1), mode='json', include={'a'}) == {'a': 1}\n    assert s.to_python(Model(1), mode='json', exclude={'b': [0]}) == {'a': 1, 'b': [2, '3']}\n\n    assert s.to_json(Model(1)) == b'{\"a\":1,\"b\":[1,2,\"3\"]}'\n    assert s.to_json(Model(1), exclude={'b'}) == b'{\"a\":1}'\n    assert s.to_json(Model(1), include={'a'}) == b'{\"a\":1}'\n    assert s.to_json(Model(1), exclude={'b': [0]}) == b'{\"a\":1,\"b\":[2,\"3\"]}'\n\n\n@pytest.mark.skipif(cached_property is None, reason='cached_property is not available')\ndef test_property_setter():\n    class Square:\n        side: float\n\n        def __init__(self, **kwargs):\n            self.__dict__ = kwargs\n\n        @property\n        def area(self) -> float:\n            return self.side**2\n\n        @area.setter\n        def area(self, area: float) -> None:\n            self.side = area**0.5\n\n        @area.deleter\n        def area(self) -> None:\n            self.side = 0.0\n\n        @cached_property\n        def random_n(self) -> int:\n            return randint(0, 1_000)\n\n    s = SchemaSerializer(\n        core_schema.model_schema(\n            Square,\n            core_schema.model_fields_schema(\n                {'side': core_schema.model_field(core_schema.float_schema())},\n                computed_fields=[\n                    core_schema.computed_field('area', core_schema.float_schema()),\n                    core_schema.computed_field('random_n', core_schema.int_schema(), alias='The random number'),\n                ],\n            ),\n        )\n    )\n\n    sq = Square(side=10.0)\n    the_random_n = sq.random_n\n    assert s.to_python(sq, by_alias=True) == {'side': 10.0, 'area': 100.0, 'The random number': the_random_n}\n    assert s.to_json(sq, by_alias=True) == b'{\"side\":10.0,\"area\":100.0,\"The random number\":%d}' % the_random_n\n    sq.area = 49.0\n    assert s.to_python(sq, by_alias=False) == {'side': 7, 'area': 49, 'random_n': the_random_n}\n    assert s.to_json(sq, by_alias=False) == b'{\"side\":7.0,\"area\":49.0,\"random_n\":%d}' % the_random_n\n    del sq.area\n    assert s.to_python(sq, by_alias=False) == {'side': 0, 'area': 0, 'random_n': the_random_n}\n    assert s.to_python(sq, exclude={'random_n'}) == {'side': 0, 'area': 0}\n\n\ndef test_extra():\n    class MyModel:\n        # this is not required, but it avoids `__pydantic_fields_set__` being included in `__dict__`\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n        field_a: str\n        field_b: int\n\n    schema = core_schema.model_schema(\n        MyModel,\n        core_schema.model_fields_schema(\n            {\n                'field_a': core_schema.model_field(core_schema.bytes_schema()),\n                'field_b': core_schema.model_field(core_schema.int_schema()),\n            },\n            extra_behavior='allow',\n        ),\n        extra_behavior='allow',\n    )\n    v = SchemaValidator(schema)\n    m = v.validate_python({'field_a': b'test', 'field_b': 12, 'field_c': 'extra'})\n    assert isinstance(m, MyModel)\n    assert m.__dict__ == {'field_a': b'test', 'field_b': 12}\n    assert m.__pydantic_extra__ == {'field_c': 'extra'}\n    assert m.__pydantic_fields_set__ == {'field_a', 'field_b', 'field_c'}\n\n    s = SchemaSerializer(schema)\n    assert 'mode:ModelExtra' in plain_repr(s)\n    assert 'has_extra:true' in plain_repr(s)\n    assert s.to_python(m) == {'field_a': b'test', 'field_b': 12, 'field_c': 'extra'}\n    assert s.to_python(m, mode='json') == {'field_a': 'test', 'field_b': 12, 'field_c': 'extra'}\n    assert s.to_json(m) == b'{\"field_a\":\"test\",\"field_b\":12,\"field_c\":\"extra\"}'\n\n    # test filtering\n    m = v.validate_python({'field_a': b'test', 'field_b': 12, 'field_c': None, 'field_d': [1, 2, 3]})\n    assert isinstance(m, MyModel)\n    assert m.__dict__ == {'field_a': b'test', 'field_b': 12}\n    assert m.__pydantic_extra__ == {'field_c': None, 'field_d': [1, 2, 3]}\n    assert m.__pydantic_fields_set__ == {'field_a', 'field_b', 'field_c', 'field_d'}\n\n    assert s.to_python(m) == {'field_a': b'test', 'field_b': 12, 'field_c': None, 'field_d': [1, 2, 3]}\n    assert s.to_json(m) == b'{\"field_a\":\"test\",\"field_b\":12,\"field_c\":null,\"field_d\":[1,2,3]}'\n\n    assert s.to_python(m, exclude_none=True) == {'field_a': b'test', 'field_b': 12, 'field_d': [1, 2, 3]}\n    assert s.to_json(m, exclude_none=True) == b'{\"field_a\":\"test\",\"field_b\":12,\"field_d\":[1,2,3]}'\n\n    assert s.to_python(m, exclude={'field_c'}) == {'field_a': b'test', 'field_b': 12, 'field_d': [1, 2, 3]}\n    assert s.to_json(m, exclude={'field_c'}) == b'{\"field_a\":\"test\",\"field_b\":12,\"field_d\":[1,2,3]}'\n\n    assert s.to_python(m, exclude={'field_d': [0]}) == {\n        'field_a': b'test',\n        'field_b': 12,\n        'field_c': None,\n        'field_d': [2, 3],\n    }\n    assert s.to_json(m, exclude={'field_d': [0]}) == b'{\"field_a\":\"test\",\"field_b\":12,\"field_c\":null,\"field_d\":[2,3]}'\n\n\ndef test_extra_config():\n    class MyModel:\n        # this is not required, but it avoids `__pydantic_fields_set__` being included in `__dict__`\n        __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n        field_a: str\n        field_b: int\n\n    schema = core_schema.model_schema(\n        MyModel,\n        core_schema.model_fields_schema(\n            {\n                'field_a': core_schema.model_field(core_schema.bytes_schema()),\n                'field_b': core_schema.model_field(core_schema.int_schema()),\n            }\n        ),\n        config=core_schema.CoreConfig(extra_fields_behavior='allow'),\n    )\n    s = SchemaSerializer(schema)\n    assert 'mode:ModelExtra' in plain_repr(s)\n    assert 'has_extra:true' in plain_repr(s)\n\n\ndef test_extra_config_nested_model():\n    class OuterModel:\n        pass\n\n    class InnerModel:\n        pass\n\n    schema = core_schema.model_schema(\n        OuterModel,\n        core_schema.model_fields_schema(\n            {\n                'sub_model': core_schema.model_field(\n                    core_schema.model_schema(\n                        InnerModel,\n                        core_schema.model_fields_schema({'int': core_schema.model_field(core_schema.int_schema())}),\n                        config=core_schema.CoreConfig(extra_fields_behavior='allow'),\n                    )\n                )\n            }\n        ),\n        config={},\n    )\n    s = SchemaSerializer(schema)\n    # debug(s)\n    s_repr = plain_repr(s)\n    assert 'has_extra:true,root_model:false,name:\"InnerModel\"' in s_repr\n    assert 'has_extra:false,root_model:false,name:\"OuterModel\"' in s_repr\n\n\ndef test_extra_custom_serializer():\n    class Model:\n        __slots__ = ('__pydantic_extra__', '__dict__')\n        __pydantic_extra__: Dict[str, Any]\n\n    schema = core_schema.model_schema(\n        Model,\n        core_schema.model_fields_schema(\n            {},\n            extra_behavior='allow',\n            extras_schema=core_schema.any_schema(\n                serialization=core_schema.plain_serializer_function_ser_schema(lambda v: v + ' bam!')\n            ),\n        ),\n        extra_behavior='allow',\n    )\n    s = SchemaSerializer(schema)\n\n    m = Model()\n    m.__pydantic_extra__ = {'extra': 'extra'}\n\n    assert s.to_python(m) == {'extra': 'extra bam!'}\n", "tests/serializers/test_model_root.py": "import json\nimport platform\nfrom typing import Any, List, Union\n\nimport pytest\n\ntry:\n    from functools import cached_property\nexcept ImportError:\n    cached_property = None\n\n\nfrom pydantic_core import SchemaSerializer, core_schema\n\nfrom ..conftest import plain_repr\n\non_pypy = platform.python_implementation() == 'PyPy'\n# pypy doesn't seem to maintain order of `__dict__`\nif on_pypy:\n    IsStrictDict = dict\nelse:\n    pass\n\n\nclass BaseModel:\n    __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n\n    def __init__(self, **kwargs):\n        for key, value in kwargs.items():\n            setattr(self, key, value)\n\n\nclass RootModel:\n    __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n    root: str\n\n    def __init__(self, data):\n        self.root = data\n\n\nclass RootSubModel(RootModel):\n    pass\n\n\ndef test_model_root():\n    s = SchemaSerializer(core_schema.model_schema(RootModel, core_schema.int_schema(), root_model=True))\n    print(plain_repr(s))\n    # TODO: assert 'mode:RootModel' in plain_repr(s)\n    assert 'has_extra:false' in plain_repr(s)\n    assert s.to_python(RootModel(1)) == 1\n    assert s.to_python(RootSubModel(1)) == 1\n\n    j = s.to_json(RootModel(1))\n    if on_pypy:\n        assert json.loads(j) == 1\n    else:\n        assert j == b'1'\n\n    assert json.loads(s.to_json(RootSubModel(1))) == 1\n\n\ndef test_function_plain_field_serializer_to_python():\n    class Model(RootModel):\n        def ser_root(self, v: Any, _) -> str:\n            assert self.root == 1_000\n            return f'{v:_}'\n\n    s = SchemaSerializer(\n        core_schema.model_schema(\n            Model,\n            core_schema.int_schema(\n                serialization=core_schema.plain_serializer_function_ser_schema(\n                    Model.ser_root, is_field_serializer=True, info_arg=True\n                )\n            ),\n            root_model=True,\n        )\n    )\n    assert s.to_python(Model(1000)) == '1_000'\n\n\ndef test_function_wrap_field_serializer_to_python():\n    class Model(RootModel):\n        def ser_root(self, v: Any, serializer: core_schema.SerializerFunctionWrapHandler, _) -> str:\n            root = serializer(v)\n            assert self.root == 1_000\n            return f'{root:_}'\n\n    s = SchemaSerializer(\n        core_schema.model_schema(\n            Model,\n            core_schema.int_schema(\n                serialization=core_schema.wrap_serializer_function_ser_schema(\n                    Model.ser_root, is_field_serializer=True, info_arg=True, schema=core_schema.any_schema()\n                )\n            ),\n            root_model=True,\n        )\n    )\n    assert s.to_python(Model(1000)) == '1_000'\n\n\ndef test_function_plain_field_serializer_to_json():\n    class Model(RootModel):\n        def ser_root(self, v: Any, _) -> str:\n            assert self.root == 1_000\n            return f'{v:_}'\n\n    s = SchemaSerializer(\n        core_schema.model_schema(\n            Model,\n            core_schema.int_schema(\n                serialization=core_schema.plain_serializer_function_ser_schema(\n                    Model.ser_root, is_field_serializer=True, info_arg=True\n                )\n            ),\n            root_model=True,\n        )\n    )\n    assert json.loads(s.to_json(Model(1000))) == '1_000'\n\n\ndef test_function_wrap_field_serializer_to_json():\n    class Model(RootModel):\n        def ser_root(self, v: Any, serializer: core_schema.SerializerFunctionWrapHandler, _) -> str:\n            assert self.root == 1_000\n            root = serializer(v)\n            return f'{root:_}'\n\n    s = SchemaSerializer(\n        core_schema.model_schema(\n            Model,\n            core_schema.int_schema(\n                serialization=core_schema.wrap_serializer_function_ser_schema(\n                    Model.ser_root, is_field_serializer=True, info_arg=True, schema=core_schema.any_schema()\n                )\n            ),\n            root_model=True,\n        )\n    )\n    assert json.loads(s.to_json(Model(1000))) == '1_000'\n\n\n@pytest.mark.parametrize('order', ['BR', 'RB'])\ndef test_root_model_dump_with_base_model(order):\n    class BModel(BaseModel):\n        value: str\n\n    b_schema = core_schema.model_schema(\n        BModel, core_schema.model_fields_schema({'value': core_schema.model_field(core_schema.str_schema())})\n    )\n\n    class RModel(RootModel):\n        root: int\n\n    r_schema = core_schema.model_schema(RModel, core_schema.int_schema(), root_model=True)\n\n    if order == 'BR':\n\n        class Model(RootModel):\n            root: List[Union[BModel, RModel]]\n\n        choices = [b_schema, r_schema]\n\n    elif order == 'RB':\n\n        class Model(RootModel):\n            root: List[Union[RModel, BModel]]\n\n        choices = [r_schema, b_schema]\n\n    s = SchemaSerializer(\n        core_schema.model_schema(\n            Model, core_schema.list_schema(core_schema.union_schema(choices=choices)), root_model=True\n        )\n    )\n\n    m = Model([RModel(1), RModel(2), BModel(value='abc')])\n\n    assert s.to_python(m) == [1, 2, {'value': 'abc'}]\n    assert s.to_json(m) == b'[1,2,{\"value\":\"abc\"}]'\n\n\ndef test_construct_nested():\n    class RModel(RootModel):\n        root: int\n\n    class BModel(BaseModel):\n        value: RModel\n\n    s = SchemaSerializer(\n        core_schema.model_schema(\n            BModel,\n            core_schema.model_fields_schema(\n                {\n                    'value': core_schema.model_field(\n                        core_schema.model_schema(RModel, core_schema.int_schema(), root_model=True)\n                    )\n                }\n            ),\n        )\n    )\n\n    m = BModel(value=42)\n\n    with pytest.raises(AttributeError, match=\"'int' object has no attribute 'root'\"):\n        s.to_python(m)\n", "tests/serializers/test_nullable.py": "import pytest\n\nfrom pydantic_core import SchemaSerializer, core_schema\n\n\ndef test_nullable():\n    s = SchemaSerializer(core_schema.nullable_schema(core_schema.int_schema()))\n    assert s.to_python(None) is None\n    assert s.to_python(1) == 1\n    assert s.to_python(None, mode='json') is None\n    assert s.to_python(1, mode='json') == 1\n    assert s.to_json(1) == b'1'\n    assert s.to_json(None) == b'null'\n    with pytest.warns(UserWarning, match='Expected `int` but got `str` - serialized value may not be as expected'):\n        assert s.to_json('aaa') == b'\"aaa\"'\n", "tests/serializers/test_list_tuple.py": "import json\nimport re\nfrom functools import partial\n\nimport pytest\n\nfrom pydantic_core import PydanticSerializationError, SchemaError, SchemaSerializer, core_schema, validate_core_schema\n\n\ndef test_list_any():\n    v = SchemaSerializer(core_schema.list_schema(core_schema.any_schema()))\n    assert v.to_python(['a', 'b', 'c']) == ['a', 'b', 'c']\n    assert v.to_python(['a', 'b', 'c'], mode='json') == ['a', 'b', 'c']\n    assert v.to_json(['a', 'b', 'c']) == b'[\"a\",\"b\",\"c\"]'\n\n    assert v.to_json(['a', 'b', 'c'], indent=2) == b'[\\n  \"a\",\\n  \"b\",\\n  \"c\"\\n]'\n\n\ndef test_list_fallback():\n    v = SchemaSerializer(core_schema.list_schema(core_schema.any_schema()))\n    msg = 'Expected `list[any]` but got `str` - serialized value may not be as expected'\n    with pytest.warns(UserWarning, match=re.escape(msg)):\n        assert v.to_python('apple') == 'apple'\n\n    with pytest.warns(UserWarning) as warning_info:\n        assert v.to_json('apple') == b'\"apple\"'\n    assert [w.message.args[0] for w in warning_info.list] == [\n        'Pydantic serializer warnings:\\n  Expected `list[any]` but got `str` - serialized value may not be as expected'\n    ]\n\n    msg = 'Expected `list[any]` but got `bytes` - serialized value may not be as expected'\n    with pytest.warns(UserWarning, match=re.escape(msg)):\n        assert v.to_json(b'apple') == b'\"apple\"'\n\n    msg = 'Expected `list[any]` but got `tuple` - serialized value may not be as expected'\n    with pytest.warns(UserWarning, match=re.escape(msg)):\n        assert v.to_python((1, 2, 3)) == (1, 2, 3)\n\n    # # even though we're in the fallback state, non JSON types should still be converted to JSON here\n    msg = 'Expected `list[any]` but got `tuple` - serialized value may not be as expected'\n    with pytest.warns(UserWarning, match=re.escape(msg)):\n        assert v.to_python((1, 2, 3), mode='json') == [1, 2, 3]\n\n\ndef test_list_str_fallback():\n    v = SchemaSerializer(core_schema.list_schema(core_schema.str_schema()))\n    with pytest.warns(UserWarning) as warning_info:\n        assert v.to_json([1, 2, 3]) == b'[1,2,3]'\n    assert [w.message.args[0] for w in warning_info.list] == [\n        'Pydantic serializer warnings:\\n'\n        '  Expected `str` but got `int` - serialized value may not be as expected\\n'\n        '  Expected `str` but got `int` - serialized value may not be as expected\\n'\n        '  Expected `str` but got `int` - serialized value may not be as expected'\n    ]\n    with pytest.raises(PydanticSerializationError) as warning_ex:\n        v.to_json([1, 2, 3], warnings='error')\n    assert str(warning_ex.value) == ''.join(\n        [\n            'Pydantic serializer warnings:\\n'\n            '  Expected `str` but got `int` - serialized value may not be as expected\\n'\n            '  Expected `str` but got `int` - serialized value may not be as expected\\n'\n            '  Expected `str` but got `int` - serialized value may not be as expected'\n        ]\n    )\n\n\ndef test_tuple_any():\n    v = SchemaSerializer(core_schema.tuple_variable_schema(core_schema.any_schema()))\n    assert v.to_python(('a', 'b', 'c')) == ('a', 'b', 'c')\n    assert v.to_python(('a', 'b', 'c'), mode='json') == ['a', 'b', 'c']\n    assert v.to_json(('a', 'b', 'c')) == b'[\"a\",\"b\",\"c\"]'\n\n    assert v.to_json(('a', 'b', 'c'), indent=2) == b'[\\n  \"a\",\\n  \"b\",\\n  \"c\"\\n]'\n\n\ndef as_list(*items):\n    return list(items)\n\n\ndef as_tuple(*items):\n    return tuple(items)\n\n\n@pytest.mark.parametrize(\n    'schema_func,seq_f', [(core_schema.list_schema, as_list), (core_schema.tuple_variable_schema, as_tuple)]\n)\ndef test_include(schema_func, seq_f):\n    v = SchemaSerializer(\n        schema_func(core_schema.any_schema(), serialization=core_schema.filter_seq_schema(include={1, 3, 5}))\n    )\n    assert v.to_python(seq_f(0, 1, 2, 3)) == seq_f(1, 3)\n    assert v.to_python(seq_f('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h')) == seq_f('b', 'd', 'f')\n    assert v.to_python(seq_f('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'), mode='json') == ['b', 'd', 'f']\n    assert v.to_json(seq_f('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h')) == b'[\"b\",\"d\",\"f\"]'\n    # the two include lists are now combined via UNION! unlike in pydantic v1\n    assert v.to_python(seq_f('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'), include={6}) == seq_f('b', 'd', 'f', 'g')\n    assert v.to_python(seq_f('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'), include=[6]) == seq_f('b', 'd', 'f', 'g')\n    assert v.to_json(seq_f('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'), include={6}) == b'[\"b\",\"d\",\"f\",\"g\"]'\n    assert v.to_python(seq_f('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'), include={6: None}) == seq_f('b', 'd', 'f', 'g')\n    assert v.to_python(seq_f('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'), include={-1: None, -2: None}, mode='json') == [\n        'b',\n        'd',\n        'f',\n        'g',\n        'h',\n    ]\n\n\n@pytest.mark.parametrize(\n    'schema_func,seq_f', [(core_schema.list_schema, as_list), (core_schema.tuple_variable_schema, as_tuple)]\n)\ndef test_negative(schema_func, seq_f):\n    v = SchemaSerializer(schema_func(core_schema.any_schema()))\n    assert v.to_python(seq_f('a', 'b', 'c', 'd', 'e')) == seq_f('a', 'b', 'c', 'd', 'e')\n    assert v.to_python(seq_f('a', 'b', 'c', 'd', 'e'), include={-1, -2}) == seq_f('d', 'e')\n    assert v.to_python(seq_f('a', 'b', 'c', 'd', 'e'), include={-1: None, -2: None}) == seq_f('d', 'e')\n    assert v.to_python(seq_f('a', 'b', 'c', 'd', 'e'), include={-1, -2}, mode='json') == ['d', 'e']\n    assert v.to_python(seq_f('a', 'b', 'c', 'd', 'e'), include={-1: None, -2: None}, mode='json') == ['d', 'e']\n    assert v.to_json(seq_f('a', 'b', 'c', 'd', 'e'), include={-1, -2}) == b'[\"d\",\"e\"]'\n\n\n@pytest.mark.parametrize(\n    'schema_func,seq_f', [(core_schema.list_schema, as_list), (core_schema.tuple_variable_schema, as_tuple)]\n)\ndef test_include_dict(schema_func, seq_f):\n    v = SchemaSerializer(\n        schema_func(core_schema.any_schema(), serialization=core_schema.filter_seq_schema(include={1, 3, 5}))\n    )\n    assert v.to_python(seq_f(0, 1, 2, 3, 4)) == seq_f(1, 3)\n    assert v.to_python(seq_f('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h')) == seq_f('b', 'd', 'f')\n    assert v.to_python(seq_f(0, 1, 2, 3, 4), include={2: None}) == seq_f(1, 2, 3)\n    assert v.to_python(seq_f(0, 1, 2, 3, 4), include={2: {1, 2}}) == seq_f(1, 2, 3)\n    assert v.to_python(seq_f(0, 1, 2, 3, 4), include={2}) == seq_f(1, 2, 3)\n\n\n@pytest.mark.parametrize(\n    'schema_func,seq_f', [(core_schema.list_schema, as_list), (core_schema.tuple_variable_schema, as_tuple)]\n)\ndef test_exclude(schema_func, seq_f):\n    v = SchemaSerializer(\n        schema_func(core_schema.any_schema(), serialization=core_schema.filter_seq_schema(exclude={1, 3, 5}))\n    )\n    assert v.to_python(seq_f(0, 1, 2, 3)) == seq_f(0, 2)\n    assert v.to_python(seq_f('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h')) == seq_f('a', 'c', 'e', 'g', 'h')\n    assert v.to_python(seq_f('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'), mode='json') == ['a', 'c', 'e', 'g', 'h']\n    assert v.to_json(seq_f('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h')) == b'[\"a\",\"c\",\"e\",\"g\",\"h\"]'\n    # the two exclude lists are combined via union as they used to be\n    assert v.to_python(seq_f('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'), exclude={6}) == seq_f('a', 'c', 'e', 'h')\n    assert v.to_python(seq_f('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'), exclude={-1, -2}) == seq_f('a', 'c', 'e')\n    assert v.to_json(seq_f('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'), exclude={6}) == b'[\"a\",\"c\",\"e\",\"h\"]'\n    assert v.to_json(seq_f('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'), exclude={-1, -2}) == b'[\"a\",\"c\",\"e\"]'\n\n\n@pytest.mark.parametrize('include,exclude', [({1, 3, 5}, {5, 6}), ([1, 3, 5], [5, 6])])\ndef test_filter(include, exclude):\n    v = SchemaSerializer(\n        validate_core_schema(\n            core_schema.list_schema(\n                core_schema.any_schema(), serialization=core_schema.filter_seq_schema(include=include, exclude=exclude)\n            )\n        )\n    )\n    assert v.to_python([0, 1, 2, 3, 4, 5, 6, 7]) == [1, 3]\n\n\ndef test_filter_runtime():\n    v = SchemaSerializer(\n        core_schema.list_schema(core_schema.any_schema(), serialization=core_schema.filter_seq_schema(exclude={0, 1}))\n    )\n    assert v.to_python([0, 1, 2, 3]) == [2, 3]\n    # `include` as a call argument trumps schema `exclude`\n    assert v.to_python([0, 1, 2, 3], include={1, 2}) == [1, 2]\n\n\nclass ImplicitContains:\n    def __iter__(self):\n        return iter([1, 2, 5])\n\n\nclass ExplicitContains(ImplicitContains):\n    def __contains__(self, item):\n        return item in {2, 5}\n\n\nclass RemovedContains(ImplicitContains):\n    __contains__ = None  # This might be done to explicitly force the `x in RemovedContains()` check to not be allowed\n\n\n@pytest.mark.parametrize(\n    'include_value,error_msg',\n    [\n        ('foobar', 'Input should be a valid set'),\n        ({'a': 'dict'}, 'Input should be a valid set'),\n        ({4.2}, 'Input should be a valid integer, got a number with a fractional part'),\n        ({'a'}, 'Input should be a valid integer, unable to parse string as an integer'),\n    ],\n)\n@pytest.mark.parametrize('schema_func', [core_schema.list_schema, core_schema.tuple_variable_schema])\ndef test_include_error(schema_func, include_value, error_msg):\n    with pytest.raises(SchemaError, match=error_msg):\n        validate_core_schema(\n            schema_func(core_schema.any_schema(), serialization=core_schema.filter_seq_schema(include=include_value))\n        )\n\n\n@pytest.mark.parametrize(\n    'include,exclude,expected',\n    [\n        ({1, 3}, None, ['b', 'd']),\n        ({1, 3, 5}, {5}, ['b', 'd']),\n        ({2: None, 3: None, 5: None}.keys(), {5}, ['c', 'd']),\n        (ExplicitContains(), set(), ['c', 'f']),\n        (ExplicitContains(), {5}, ['c']),\n        ({2, 3}, ExplicitContains(), ['d']),\n        ([1, 2, 3], [2, 3], ['b']),\n    ],\n)\ndef test_filter_runtime_more(include, exclude, expected):\n    v = SchemaSerializer(core_schema.list_schema(core_schema.any_schema()))\n    assert v.to_python(list('abcdefgh'), include=include, exclude=exclude) == expected\n\n\n@pytest.mark.parametrize(\n    'schema_func,seq_f', [(core_schema.list_schema, as_list), (core_schema.tuple_variable_schema, as_tuple)]\n)\n@pytest.mark.parametrize(\n    'include,exclude',\n    [\n        (ImplicitContains(), None),\n        (RemovedContains(), None),\n        (1, None),\n        (None, ImplicitContains()),\n        (None, RemovedContains()),\n        (None, 1),\n    ],\n)\ndef test_include_error_call_time(schema_func, seq_f, include, exclude):\n    kind = 'include' if include is not None else 'exclude'\n    v = SchemaSerializer(schema_func(core_schema.any_schema()))\n    with pytest.raises(TypeError, match=f'`{kind}` argument must be a set or dict.'):\n        v.to_python(seq_f(0, 1, 2, 3), include=include, exclude=exclude)\n\n\ndef test_tuple_fallback():\n    v = SchemaSerializer(core_schema.tuple_variable_schema(core_schema.any_schema()))\n    msg = 'Expected `tuple[any, ...]` but got `str` - serialized value may not be as expected'\n    with pytest.warns(UserWarning, match=re.escape(msg)):\n        assert v.to_python('apple') == 'apple'\n\n    with pytest.warns(UserWarning) as warning_info:\n        assert v.to_json([1, 2, 3]) == b'[1,2,3]'\n    assert [w.message.args[0] for w in warning_info.list] == [\n        'Pydantic serializer warnings:\\n  Expected `tuple[any, ...]` but got `list` - '\n        'serialized value may not be as expected'\n    ]\n\n    msg = 'Expected `tuple[any, ...]` but got `bytes` - serialized value may not be as expected'\n    with pytest.warns(UserWarning, match=re.escape(msg)):\n        assert v.to_json(b'apple') == b'\"apple\"'\n\n    assert v.to_python((1, 2, 3)) == (1, 2, 3)\n\n    # even though we're in the fallback state, non JSON types should still be converted to JSON here\n    msg = 'Expected `tuple[any, ...]` but got `list` - serialized value may not be as expected'\n    with pytest.warns(UserWarning, match=re.escape(msg)):\n        assert v.to_python([1, 2, 3], mode='json') == [1, 2, 3]\n\n\n@pytest.mark.parametrize(\n    'params',\n    [\n        dict(include=None, exclude=None, expected=['0', '1', '2', '3']),\n        dict(include={0, 1}, exclude=None, expected=['0', '1']),\n        dict(include={0: ..., 1: ...}, exclude=None, expected=['0', '1']),\n        dict(include={0: True, 1: True}, exclude=None, expected=['0', '1']),\n        dict(include={0: {1}, 1: {1}}, exclude=None, expected=['0', '1']),\n        dict(include=None, exclude={0, 1}, expected=['2', '3']),\n        dict(include=None, exclude={0: ..., 1: ...}, expected=['2', '3']),\n        dict(include={0, 1}, exclude={1, 2}, expected=['0']),\n        dict(include=None, exclude={3: {1}}, expected=['0', '1', '2', '3']),\n        dict(include={0, 1}, exclude={3: {1}}, expected=['0', '1']),\n        dict(include={0, 1}, exclude={1: {1}}, expected=['0', '1']),\n        dict(include={0, 1}, exclude={1: ...}, expected=['0']),\n        dict(include={1}, exclude={1}, expected=[]),\n        dict(include={0}, exclude={1}, expected=['0']),\n        dict(include={'__all__'}, exclude={1}, expected=['0', '2', '3']),\n        dict(include=None, exclude={1}, expected=['0', '2', '3']),\n        dict(include=None, exclude={'__all__'}, expected=[]),\n    ],\n)\ndef test_filter_args(params):\n    s = SchemaSerializer(core_schema.list_schema())\n\n    include, exclude, expected = params['include'], params['exclude'], params['expected']\n    value = ['0', '1', '2', '3']\n    assert s.to_python(value, include=include, exclude=exclude) == expected\n    assert s.to_python(value, mode='json', include=include, exclude=exclude) == expected\n    assert json.loads(s.to_json(value, include=include, exclude=exclude)) == expected\n\n\n@pytest.mark.parametrize(\n    'params',\n    [\n        dict(include=None, exclude=None, expected=[[0], [0, 1], [0, 1, 2], [0, 1, 2, 3]]),\n        dict(include=None, exclude={1: {0}}, expected=[[0], [1], [0, 1, 2], [0, 1, 2, 3]]),\n        dict(include=None, exclude={1: {0}, 2: ...}, expected=[[0], [1], [0, 1, 2, 3]]),\n        dict(include=None, exclude={1: {0}, 2: True}, expected=[[0], [1], [0, 1, 2, 3]]),\n        dict(include={1: {0}}, exclude=None, expected=[[0]]),\n    ],\n)\ndef test_filter_args_nested(params):\n    s = SchemaSerializer(core_schema.list_schema(core_schema.list_schema()))\n\n    include, exclude, expected = params['include'], params['exclude'], params['expected']\n    value = [[0], [0, 1], [0, 1, 2], [0, 1, 2, 3]]\n    assert s.to_python(value, include=include, exclude=exclude) == expected\n    assert s.to_python(value, mode='json', include=include, exclude=exclude) == expected\n    assert json.loads(s.to_json(value, include=include, exclude=exclude)) == expected\n\n\ndef test_filter_list_of_dicts():\n    s = SchemaSerializer(core_schema.list_schema(core_schema.dict_schema()))\n    v = [{'a': 1, 'b': 2}, {'a': 3, 'b': 4}]\n    assert s.to_python(v) == v\n    assert s.to_python(v, exclude={0: {'a'}}) == [{'b': 2}, {'a': 3, 'b': 4}]\n    assert s.to_python(v, exclude={0: {'__all__'}}) == [{}, {'a': 3, 'b': 4}]\n    assert s.to_python(v, exclude={'__all__': {'a'}}) == [{'b': 2}, {'b': 4}]\n\n    assert s.to_json(v) == b'[{\"a\":1,\"b\":2},{\"a\":3,\"b\":4}]'\n    assert s.to_json(v, exclude={0: {'a'}}) == b'[{\"b\":2},{\"a\":3,\"b\":4}]'\n    assert s.to_json(v, exclude={0: {'__all__'}}) == b'[{},{\"a\":3,\"b\":4}]'\n    assert s.to_json(v, exclude={'__all__': {'a'}}) == b'[{\"b\":2},{\"b\":4}]'\n\n    assert s.to_python(v, include={0: {'a'}, 1: None}) == [{'a': 1}, {'a': 3, 'b': 4}]\n    assert s.to_python(v, include={'__all__': {'a'}}) == [{'a': 1}, {'a': 3}]\n\n    assert s.to_json(v, include={0: {'a'}, 1: None}) == b'[{\"a\":1},{\"a\":3,\"b\":4}]'\n    assert s.to_json(v, include={'__all__': {'a'}}) == b'[{\"a\":1},{\"a\":3}]'\n\n\ndef test_positional_tuple():\n    s = SchemaSerializer({'type': 'tuple', 'items_schema': [{'type': 'int'}, {'type': 'bytes'}, {'type': 'float'}]})\n    assert s.to_python((1, b'2', 3.0)) == (1, b'2', 3.0)\n    with pytest.warns(UserWarning, match='Unexpected extra items present in tuple'):\n        assert s.to_python((1, b'2', 3.0, 123)) == (1, b'2', 3.0, 123)\n    assert s.to_python((1, b'2')) == (1, b'2')\n\n    assert s.to_python((1, b'2', 3.0), mode='json') == [1, '2', 3.0]\n    with pytest.warns(UserWarning, match='Unexpected extra items present in tuple'):\n        assert s.to_python((1, b'2', 3.0, 123), mode='json') == [1, '2', 3.0, 123]\n    assert s.to_python((1, b'2'), mode='json') == [1, '2']\n\n    assert s.to_json((1, b'2', 3.0)) == b'[1,\"2\",3.0]'\n    with pytest.warns(UserWarning, match='Unexpected extra items present in tuple'):\n        assert s.to_json((1, b'2', 3.0, 123)) == b'[1,\"2\",3.0,123]'\n    assert s.to_json((1, b'2')) == b'[1,\"2\"]'\n\n\ndef test_function_positional_tuple():\n    def f(prefix, value, _info):\n        return f'{prefix}{value}'\n\n    s = SchemaSerializer(\n        {\n            'type': 'tuple',\n            'items_schema': [\n                core_schema.any_schema(\n                    serialization=core_schema.plain_serializer_function_ser_schema(partial(f, 'a'), info_arg=True)\n                ),\n                core_schema.any_schema(\n                    serialization=core_schema.plain_serializer_function_ser_schema(partial(f, 'b'), info_arg=True)\n                ),\n                core_schema.any_schema(\n                    serialization=core_schema.plain_serializer_function_ser_schema(partial(f, 'extra'), info_arg=True)\n                ),\n            ],\n            'variadic_item_index': 2,\n        }\n    )\n    assert s.to_python((1,)) == ('a1',)\n    assert s.to_python((1, 2)) == ('a1', 'b2')\n    assert s.to_python((1, 2, 3)) == ('a1', 'b2', 'extra3')\n\n    assert s.to_python((1,), mode='json') == ['a1']\n    assert s.to_python((1, 2), mode='json') == ['a1', 'b2']\n    assert s.to_python((1, 2, 3), mode='json') == ['a1', 'b2', 'extra3']\n\n    assert s.to_json((1,)) == b'[\"a1\"]'\n    assert s.to_json((1, 2)) == b'[\"a1\",\"b2\"]'\n    assert s.to_json((1, 2, 3)) == b'[\"a1\",\"b2\",\"extra3\"]'\n\n\ndef test_list_dict_key():\n    s = SchemaSerializer(core_schema.dict_schema(core_schema.list_schema(), core_schema.int_schema()))\n    with pytest.warns(UserWarning, match=r'Expected `list\\[any\\]` but got `str`'):\n        assert s.to_python({'xx': 1}) == {'xx': 1}\n\n\ndef test_tuple_var_dict_key():\n    s = SchemaSerializer(core_schema.dict_schema(core_schema.tuple_variable_schema(), core_schema.int_schema()))\n    with pytest.warns(UserWarning, match=r'Expected `tuple\\[any, ...\\]` but got `str`'):\n        assert s.to_python({'xx': 1}) == {'xx': 1}\n\n    assert s.to_python({(1, 2): 1}) == {(1, 2): 1}\n    assert s.to_python({(1, 2): 1}, mode='json') == {'1,2': 1}\n    assert s.to_json({(1, 2): 1}) == b'{\"1,2\":1}'\n\n\ndef test_tuple_pos_dict_key():\n    s = SchemaSerializer(\n        core_schema.dict_schema(\n            core_schema.tuple_positional_schema(\n                [core_schema.int_schema(), core_schema.str_schema()], extras_schema=core_schema.int_schema()\n            ),\n            core_schema.int_schema(),\n        )\n    )\n    assert s.to_python({(1, 'a'): 1}) == {(1, 'a'): 1}\n    assert s.to_python({(1, 'a', 2): 1}) == {(1, 'a', 2): 1}\n    assert s.to_python({(1, 'a'): 1}, mode='json') == {'1,a': 1}\n    assert s.to_python({(1, 'a', 2): 1}, mode='json') == {'1,a,2': 1}\n    assert s.to_json({(1, 'a'): 1}) == b'{\"1,a\":1}'\n    assert s.to_json({(1, 'a', 2): 1}) == b'{\"1,a,2\":1}'\n\n\ndef test_tuple_wrong_size_union():\n    # See https://github.com/pydantic/pydantic/issues/8677\n\n    f = core_schema.float_schema()\n    s = SchemaSerializer(\n        core_schema.union_schema([core_schema.tuple_schema([f, f]), core_schema.tuple_schema([f, f, f])])\n    )\n    assert s.to_python((1.0, 2.0)) == (1.0, 2.0)\n    assert s.to_python((1.0, 2.0, 3.0)) == (1.0, 2.0, 3.0)\n\n    with pytest.warns(UserWarning, match='Unexpected extra items present in tuple'):\n        s.to_python((1.0, 2.0, 3.0, 4.0))\n\n    assert s.to_python((1.0, 2.0), mode='json') == [1.0, 2.0]\n    assert s.to_python((1.0, 2.0, 3.0), mode='json') == [1.0, 2.0, 3.0]\n\n    with pytest.warns(UserWarning, match='Unexpected extra items present in tuple'):\n        s.to_python((1.0, 2.0, 3.0, 4.0), mode='json')\n\n    assert s.to_json((1.0, 2.0)) == b'[1.0,2.0]'\n    assert s.to_json((1.0, 2.0, 3.0)) == b'[1.0,2.0,3.0]'\n\n    with pytest.warns(UserWarning, match='Unexpected extra items present in tuple'):\n        s.to_json((1.0, 2.0, 3.0, 4.0))\n", "tests/serializers/test_none.py": "import pytest\n\nfrom pydantic_core import SchemaSerializer, core_schema\n\nall_scalars = (\n    'int',\n    'bool',\n    'float',\n    'none',\n    'str',\n    'bytes',\n    'datetime',\n    'date',\n    'time',\n    'timedelta',\n    'url',\n    'multi-host-url',\n)\nall_types = all_scalars + ('list', 'dict', 'set', 'frozenset')\n\n\n@pytest.mark.parametrize('schema_type', all_types)\ndef test_none_fallback(schema_type):\n    s = SchemaSerializer({'type': schema_type})\n    assert s.to_python(None) is None\n\n    assert s.to_python(None, mode='json') is None\n\n    assert s.to_json(None) == b'null'\n\n\n@pytest.mark.parametrize('schema_type', all_scalars)\ndef test_none_fallback_key(schema_type):\n    s = SchemaSerializer(core_schema.dict_schema({'type': schema_type}, core_schema.int_schema()))\n    assert s.to_python({None: 1}) == {None: 1}\n\n    assert s.to_python({None: 1}, mode='json') == {'None': 1}\n\n    assert s.to_json({None: 1}) == b'{\"None\":1}'\n", "tests/serializers/test_uuid.py": "from uuid import UUID\n\nimport pytest\n\nfrom pydantic_core import SchemaSerializer, core_schema\n\n\ndef test_uuid():\n    v = SchemaSerializer(core_schema.uuid_schema())\n    assert v.to_python(UUID('12345678-1234-5678-1234-567812345678')) == UUID('12345678-1234-5678-1234-567812345678')\n\n    assert (\n        v.to_python(UUID('12345678-1234-5678-1234-567812345678'), mode='json') == '12345678-1234-5678-1234-567812345678'\n    )\n    assert v.to_json(UUID('12345678-1234-5678-1234-567812345678')) == b'\"12345678-1234-5678-1234-567812345678\"'\n\n    with pytest.warns(UserWarning, match='Expected `uuid` but got `int` - serialized value may not be as expected'):\n        assert v.to_python(123, mode='json') == 123\n\n    with pytest.warns(UserWarning, match='Expected `uuid` but got `int` - serialized value may not be as expected'):\n        assert v.to_json(123) == b'123'\n\n\ndef test_uuid_key():\n    v = SchemaSerializer(core_schema.dict_schema(core_schema.uuid_schema(), core_schema.uuid_schema()))\n    assert v.to_python(\n        {UUID('12345678-1234-5678-1234-567812345678'): UUID('12345678-1234-5678-1234-567812345678')}\n    ) == {UUID('12345678-1234-5678-1234-567812345678'): UUID('12345678-1234-5678-1234-567812345678')}\n    assert v.to_python(\n        {UUID('12345678-1234-5678-1234-567812345678'): UUID('12345678-1234-5678-1234-567812345678')}, mode='json'\n    ) == {'12345678-1234-5678-1234-567812345678': '12345678-1234-5678-1234-567812345678'}\n    assert (\n        v.to_json({UUID('12345678-1234-5678-1234-567812345678'): UUID('12345678-1234-5678-1234-567812345678')})\n        == b'{\"12345678-1234-5678-1234-567812345678\":\"12345678-1234-5678-1234-567812345678\"}'\n    )\n\n\n@pytest.mark.parametrize(\n    'value,expected',\n    [\n        (UUID('12345678-1234-5678-1234-567812345678'), '12345678-1234-5678-1234-567812345678'),\n        (UUID('550e8400-e29b-41d4-a716-446655440000'), '550e8400-e29b-41d4-a716-446655440000'),\n        (UUID('123e4567-e89b-12d3-a456-426655440000'), '123e4567-e89b-12d3-a456-426655440000'),\n        (UUID('00000000-0000-0000-0000-000000000000'), '00000000-0000-0000-0000-000000000000'),\n    ],\n)\ndef test_uuid_json(value, expected):\n    v = SchemaSerializer(core_schema.uuid_schema())\n    assert v.to_python(value, mode='json') == expected\n    assert v.to_json(value).decode() == f'\"{expected}\"'\n\n\ndef test_any_uuid_key():\n    v = SchemaSerializer(core_schema.dict_schema())\n    input_value = {UUID('12345678-1234-5678-1234-567812345678'): 1}\n\n    assert v.to_python(input_value, mode='json') == {'12345678-1234-5678-1234-567812345678': 1}\n    assert v.to_json(input_value) == b'{\"12345678-1234-5678-1234-567812345678\":1}'\n", "tests/serializers/test_enum.py": "from enum import Enum\n\nimport pytest\n\nfrom pydantic_core import SchemaSerializer, core_schema\n\n\ndef test_plain_enum():\n    class MyEnum(Enum):\n        a = 1\n        b = 2\n\n    v = SchemaSerializer(core_schema.enum_schema(MyEnum, list(MyEnum.__members__.values())))\n\n    # debug(v)\n    assert v.to_python(MyEnum.a) is MyEnum.a\n    assert v.to_python(MyEnum.a, mode='json') == 1\n    assert v.to_json(MyEnum.a) == b'1'\n\n    with pytest.warns(UserWarning, match='Expected `enum` but got `int` - serialized value may not be as expected'):\n        assert v.to_python(1) == 1\n    with pytest.warns(UserWarning, match='Expected `enum` but got `int` - serialized value may not be as expected'):\n        assert v.to_json(1) == b'1'\n\n\ndef test_int_enum():\n    class MyEnum(int, Enum):\n        a = 1\n        b = 2\n\n    v = SchemaSerializer(core_schema.enum_schema(MyEnum, list(MyEnum.__members__.values()), sub_type='int'))\n\n    # debug(v)\n    assert v.to_python(MyEnum.a) is MyEnum.a\n    assert v.to_python(MyEnum.a, mode='json') == 1\n    assert v.to_json(MyEnum.a) == b'1'\n\n    with pytest.warns(UserWarning, match='Expected `enum` but got `int` - serialized value may not be as expected'):\n        assert v.to_python(1) == 1\n    with pytest.warns(UserWarning, match='Expected `enum` but got `int` - serialized value may not be as expected'):\n        assert v.to_json(1) == b'1'\n\n\ndef test_str_enum():\n    class MyEnum(str, Enum):\n        a = 'a'\n        b = 'b'\n\n    v = SchemaSerializer(core_schema.enum_schema(MyEnum, list(MyEnum.__members__.values()), sub_type='str'))\n\n    # debug(v)\n    assert v.to_python(MyEnum.a) is MyEnum.a\n    assert v.to_python(MyEnum.a, mode='json') == 'a'\n    assert v.to_json(MyEnum.a) == b'\"a\"'\n\n    with pytest.warns(UserWarning, match='Expected `enum` but got `str` - serialized value may not be as expected'):\n        assert v.to_python('a') == 'a'\n    with pytest.warns(UserWarning, match='Expected `enum` but got `str` - serialized value may not be as expected'):\n        assert v.to_json('a') == b'\"a\"'\n\n\ndef test_plain_dict_key():\n    class MyEnum(Enum):\n        a = 1\n        b = 2\n\n    v = SchemaSerializer(\n        core_schema.dict_schema(\n            core_schema.enum_schema(MyEnum, list(MyEnum.__members__.values())),\n            core_schema.str_schema(),\n        )\n    )\n\n    # debug(v)\n    assert v.to_python({MyEnum.a: 'x'}) == {MyEnum.a: 'x'}\n    assert v.to_python({MyEnum.a: 'x'}, mode='json') == {'1': 'x'}\n    assert v.to_json({MyEnum.a: 'x'}) == b'{\"1\":\"x\"}'\n\n    with pytest.warns(UserWarning, match='Expected `enum` but got `str` - serialized value may not be as expected'):\n        assert v.to_python({'x': 'x'}) == {'x': 'x'}\n    with pytest.warns(UserWarning, match='Expected `enum` but got `str` - serialized value may not be as expected'):\n        assert v.to_json({'x': 'x'}) == b'{\"x\":\"x\"}'\n\n\ndef test_int_dict_key():\n    class MyEnum(int, Enum):\n        a = 1\n        b = 2\n\n    v = SchemaSerializer(\n        core_schema.dict_schema(\n            core_schema.enum_schema(MyEnum, list(MyEnum.__members__.values()), sub_type='int'),\n            core_schema.str_schema(),\n        )\n    )\n\n    # debug(v)\n    assert v.to_python({MyEnum.a: 'x'}) == {MyEnum.a: 'x'}\n    assert v.to_python({MyEnum.a: 'x'}, mode='json') == {'1': 'x'}\n    assert v.to_json({MyEnum.a: 'x'}) == b'{\"1\":\"x\"}'\n\n    with pytest.warns(UserWarning, match='Expected `enum` but got `str` - serialized value may not be as expected'):\n        assert v.to_python({'x': 'x'}) == {'x': 'x'}\n    with pytest.warns(UserWarning, match='Expected `enum` but got `str` - serialized value may not be as expected'):\n        assert v.to_json({'x': 'x'}) == b'{\"x\":\"x\"}'\n", "tests/serializers/test_generator.py": "import pytest\nfrom dirty_equals import IsStr\n\nfrom pydantic_core import SchemaSerializer, core_schema\n\n\ndef gen_ok(*things):\n    yield from things\n\n\ndef gen_error(*things):\n    yield from things\n    raise ValueError('oops')\n\n\ndef test_generator_any_iter():\n    s = SchemaSerializer(core_schema.generator_schema(core_schema.any_schema()))\n    gen = s.to_python(gen_ok('a', b'b', 3))\n    assert repr(gen) == IsStr(regex=r'SerializationIterator\\(index=0, iterator=<generator object gen_ok at 0x\\w+>\\)')\n    assert str(gen) == repr(gen)\n    assert gen.index == 0\n    assert next(gen) == 'a'\n    assert gen.index == 1\n    assert repr(gen) == IsStr(regex=r'SerializationIterator\\(index=1, iterator=<generator object gen_ok at 0x\\w+>\\)')\n    assert next(gen) == b'b'\n    assert gen.index == 2\n    assert next(gen) == 3\n    assert gen.index == 3\n    with pytest.raises(StopIteration):\n        next(gen)\n    assert gen.index == 3\n\n\ndef test_any_iter():\n    s = SchemaSerializer(core_schema.any_schema())\n    gen = s.to_python(gen_ok('a', b'b', 3))\n    assert repr(gen) == IsStr(regex=r'SerializationIterator\\(index=0, iterator=<generator object gen_ok at 0x\\w+>\\)')\n    assert str(gen) == repr(gen)\n    assert next(gen) == 'a'\n    assert repr(gen) == IsStr(regex=r'SerializationIterator\\(index=1, iterator=<generator object gen_ok at 0x\\w+>\\)')\n    assert next(gen) == b'b'\n    assert next(gen) == 3\n    with pytest.raises(StopIteration):\n        next(gen)\n\n\ndef test_generator_any():\n    s = SchemaSerializer(core_schema.generator_schema(core_schema.any_schema()))\n    assert list(s.to_python(iter(['a', b'b', 3]))) == ['a', b'b', 3]\n    assert list(s.to_python(gen_ok('a', b'b', 3))) == ['a', b'b', 3]\n\n    assert s.to_python(iter(['a', b'b', 3]), mode='json') == ['a', 'b', 3]\n\n    assert s.to_json(iter(['a', b'b', 3])) == b'[\"a\",\"b\",3]'\n    assert s.to_json(gen_ok('a', b'b', 3)) == b'[\"a\",\"b\",3]'\n\n    msg = 'Expected `generator` but got `int` - serialized value may not be as expected'\n    with pytest.warns(UserWarning, match=msg):\n        assert s.to_python(4) == 4\n    with pytest.warns(UserWarning, match='Expected `generator` but got `tuple`'):\n        assert s.to_python(('a', b'b', 3)) == ('a', b'b', 3)\n    with pytest.warns(UserWarning, match='Expected `generator` but got `str`'):\n        assert s.to_python('abc') == 'abc'\n\n    with pytest.raises(ValueError, match='oops'):\n        list(s.to_python(gen_error(1, 2)))\n\n    with pytest.raises(ValueError, match='oops'):\n        s.to_python(gen_error(1, 2), mode='json')\n\n    with pytest.raises(ValueError, match='oops'):\n        s.to_json(gen_error(1, 2))\n\n\ndef test_generator_int():\n    s = SchemaSerializer(core_schema.generator_schema(core_schema.int_schema()))\n    assert list(s.to_python(iter([1, 2, 3]))) == [1, 2, 3]\n    assert list(s.to_python(gen_ok(1, 2, 3))) == [1, 2, 3]\n\n    assert s.to_python(iter([1, 2, 3]), mode='json') == [1, 2, 3]\n\n    assert s.to_json(iter([1, 2, 3])) == b'[1,2,3]'\n    assert s.to_json(gen_ok(1, 2, 3)) == b'[1,2,3]'\n\n    with pytest.raises(ValueError, match='oops'):\n        list(s.to_python(gen_error(1, 2)))\n\n    with pytest.raises(ValueError, match='oops'):\n        s.to_json(gen_error(1, 2))\n\n    with pytest.warns(UserWarning, match='Expected `int` but got `str` - serialized value may not be as expected'):\n        s.to_json(gen_ok(1, 'a'))\n\n    gen = s.to_python(gen_ok(1, 'a'))\n    assert next(gen) == 1\n    with pytest.warns(UserWarning, match='Expected `int` but got `str` - serialized value may not be as expected'):\n        assert next(gen) == 'a'\n    with pytest.warns(UserWarning, match='Expected `generator` but got `tuple` - serialized value may not.+'):\n        s.to_python((1, 2, 3))\n\n\ndef test_include():\n    v = SchemaSerializer(\n        core_schema.generator_schema(\n            core_schema.any_schema(), serialization=core_schema.filter_seq_schema(include={1, 3, 5})\n        )\n    )\n    assert v.to_python(gen_ok(0, 1, 2, 3), mode='json') == [1, 3]\n    assert list(v.to_python(gen_ok(0, 1, 2, 3))) == [1, 3]\n    assert v.to_python(gen_ok('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'), mode='json') == ['b', 'd', 'f']\n    assert v.to_python(gen_ok('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'), mode='json') == ['b', 'd', 'f']\n    assert v.to_json(gen_ok('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h')) == b'[\"b\",\"d\",\"f\"]'\n    # the two include lists are now combined via UNION! unlike in pydantic v1\n    assert v.to_python(gen_ok('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'), include={6}, mode='json') == ['b', 'd', 'f', 'g']\n    assert list(v.to_python(gen_ok('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'), include={6})) == ['b', 'd', 'f', 'g']\n    assert v.to_json(gen_ok('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'), include={6}) == b'[\"b\",\"d\",\"f\",\"g\"]'\n    assert v.to_python(gen_ok('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'), include={6: None}, mode='json') == [\n        'b',\n        'd',\n        'f',\n        'g',\n    ]\n    with pytest.raises(ValueError, match='Negative indices cannot be used to exclude items on unsized iterables'):\n        v.to_python(gen_ok('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'), include={-1: None, -2: None}, mode='json')\n    # Non-integer keys are ignored\n    v.to_python(gen_ok('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'), include={'__all__': None}, mode='json')\n\n\ndef test_custom_serializer():\n    s = SchemaSerializer(core_schema.any_schema(serialization=core_schema.simple_ser_schema('generator')))\n    assert s.to_python(gen_ok(1, 2), mode='json') == [1, 2]\n    assert s.to_json(gen_ok(1, 2)) == b'[1,2]'\n", "tests/serializers/test_definitions_recursive.py": "import pytest\n\nfrom pydantic_core import SchemaSerializer, core_schema\n\n\ndef test_branch_nullable():\n    s = SchemaSerializer(\n        core_schema.definitions_schema(\n            core_schema.definition_reference_schema('Branch'),\n            [\n                core_schema.typed_dict_schema(\n                    {\n                        'name': core_schema.typed_dict_field(core_schema.str_schema()),\n                        'sub_branch': core_schema.typed_dict_field(\n                            core_schema.nullable_schema(core_schema.definition_reference_schema('Branch'))\n                        ),\n                    },\n                    ref='Branch',\n                )\n            ],\n        )\n    )\n    assert s.to_python({'name': 'root', 'sub_branch': {'name': 'branch', 'sub_branch': None}}) == {\n        'name': 'root',\n        'sub_branch': {'name': 'branch', 'sub_branch': None},\n    }\n    assert s.to_python({'name': 'root', 'sub_branch': {'name': 'branch', 'sub_branch': None}}, exclude_none=True) == {\n        'name': 'root',\n        'sub_branch': {'name': 'branch'},\n    }\n\n\ndef test_cyclic_recursion():\n    s = SchemaSerializer(\n        core_schema.definitions_schema(\n            core_schema.definition_reference_schema('Branch'),\n            [\n                core_schema.typed_dict_schema(\n                    {\n                        'name': core_schema.typed_dict_field(core_schema.str_schema()),\n                        'sub_branch': core_schema.typed_dict_field(\n                            core_schema.nullable_schema(core_schema.definition_reference_schema('Branch'))\n                        ),\n                    },\n                    ref='Branch',\n                )\n            ],\n        )\n    )\n    v = {'name': 'root'}\n    v['sub_branch'] = v\n    with pytest.raises(ValueError, match=r'Circular reference detected \\(id repeated\\)'):\n        s.to_python(v)\n    with pytest.raises(ValueError, match=r'Circular reference detected \\(id repeated\\)'):\n        s.to_python(v, mode='json')\n    with pytest.raises(ValueError, match=r'Circular reference detected \\(id repeated\\)'):\n        s.to_json(v)\n\n\ndef test_custom_ser():\n    s = SchemaSerializer(\n        core_schema.definitions_schema(\n            core_schema.definition_reference_schema('Branch'),\n            [\n                core_schema.typed_dict_schema(\n                    {\n                        'name': core_schema.typed_dict_field(core_schema.str_schema()),\n                        'sub_branch': core_schema.typed_dict_field(\n                            core_schema.nullable_schema(\n                                core_schema.definition_reference_schema(\n                                    'Branch', serialization=core_schema.to_string_ser_schema(when_used='always')\n                                )\n                            )\n                        ),\n                    },\n                    ref='Branch',\n                )\n            ],\n        )\n    )\n    assert s.to_python({'name': 'root', 'sub_branch': {'name': 'branch', 'sub_branch': None}}) == {\n        'name': 'root',\n        'sub_branch': \"{'name': 'branch', 'sub_branch': None}\",\n    }\n\n\ndef test_recursive_function():\n    s = SchemaSerializer(\n        core_schema.definitions_schema(\n            core_schema.definition_reference_schema('my_ref'),\n            [\n                core_schema.typed_dict_schema(\n                    {'root': core_schema.typed_dict_field(core_schema.definition_reference_schema('my_ref'))},\n                    ref='my_ref',\n                    serialization=core_schema.wrap_serializer_function_ser_schema(function=lambda x, _handler: x),\n                )\n            ],\n        )\n    )\n    assert s.to_python({'root': {'root': {}}}) == {'root': {'root': {}}}\n\n\ndef test_recursive_function_deeper_ref():\n    s = SchemaSerializer(\n        core_schema.typed_dict_schema(\n            {\n                'a': core_schema.typed_dict_field(\n                    core_schema.definitions_schema(\n                        core_schema.definition_reference_schema('my_ref'),\n                        [\n                            core_schema.typed_dict_schema(\n                                {'b': core_schema.typed_dict_field(core_schema.definition_reference_schema('my_ref'))},\n                                ref='my_ref',\n                            )\n                        ],\n                    )\n                )\n            },\n            serialization=core_schema.wrap_serializer_function_ser_schema(\n                function=lambda x, _handler: x, is_field_serializer=False\n            ),\n        )\n    )\n    assert s.to_python({'a': {'b': {'b': {}}}}) == {'a': {'b': {'b': {}}}}\n", "tests/serializers/test_url.py": "import pickle\n\nimport pytest\n\nfrom pydantic_core import MultiHostUrl, SchemaSerializer, SchemaValidator, Url, core_schema\n\n\ndef test_url():\n    v = SchemaValidator(core_schema.url_schema())\n    s = SchemaSerializer(core_schema.url_schema())\n\n    url = v.validate_python('https://example.com')\n    assert isinstance(url, Url)\n    assert str(url) == 'https://example.com/'\n    assert url.host == 'example.com'\n\n    assert s.to_python(url) == url\n    assert s.to_python(url, mode='json') == 'https://example.com/'\n    assert s.to_json(url) == b'\"https://example.com/\"'\n\n    with pytest.warns(UserWarning, match='Expected `url` but got `str` - serialized value may not be as expected'):\n        assert s.to_python('https://example.com', mode='json') == 'https://example.com'\n\n\ndef test_multi_host_url():\n    v = SchemaValidator(core_schema.multi_host_url_schema())\n    s = SchemaSerializer(core_schema.multi_host_url_schema())\n\n    url = v.validate_python('https://example.com,example.org/path')\n    assert isinstance(url, MultiHostUrl)\n    assert str(url) == 'https://example.com,example.org/path'\n    assert [h['host'] for h in url.hosts()] == ['example.com', 'example.org']\n\n    assert s.to_python(url) == url\n    assert s.to_python(url, mode='json') == 'https://example.com,example.org/path'\n    assert s.to_json(url) == b'\"https://example.com,example.org/path\"'\n\n    with pytest.warns(\n        UserWarning, match='Expected `multi-host-url` but got `str` - serialized value may not be as expected'\n    ):\n        assert s.to_python('https://ex.com,ex.org/path', mode='json') == 'https://ex.com,ex.org/path'\n\n\ndef test_url_dict_keys():\n    v = SchemaValidator(core_schema.url_schema())\n\n    s = SchemaSerializer(core_schema.dict_schema(core_schema.url_schema()))\n    url = v.validate_python('https://example.com')\n    assert s.to_python({url: 'foo'}) == {url: 'foo'}\n    assert s.to_python({url: 'foo'}, mode='json') == {'https://example.com/': 'foo'}\n    assert s.to_json({url: 'foo'}) == b'{\"https://example.com/\":\"foo\"}'\n\n\ndef test_multi_host_url_dict_keys():\n    v = SchemaValidator(core_schema.multi_host_url_schema())\n\n    s = SchemaSerializer(core_schema.dict_schema(core_schema.multi_host_url_schema()))\n    url = v.validate_python('https://example.com,example.org/path')\n    assert s.to_python({url: 'foo'}) == {url: 'foo'}\n    assert s.to_python({url: 'foo'}, mode='json') == {'https://example.com,example.org/path': 'foo'}\n    assert s.to_json({url: 'foo'}) == b'{\"https://example.com,example.org/path\":\"foo\"}'\n\n\ndef test_any():\n    url = Url('https://ex.com')\n    multi_host_url = MultiHostUrl('https://ex.com,ex.org/path')\n\n    s = SchemaSerializer(core_schema.any_schema())\n    assert s.to_python(url) == url\n    assert type(s.to_python(url)) == Url\n    assert s.to_python(multi_host_url) == multi_host_url\n    assert type(s.to_python(multi_host_url)) == MultiHostUrl\n    assert s.to_python(url, mode='json') == 'https://ex.com/'\n    assert s.to_python(multi_host_url, mode='json') == 'https://ex.com,ex.org/path'\n    assert s.to_json(url) == b'\"https://ex.com/\"'\n    assert s.to_json(multi_host_url) == b'\"https://ex.com,ex.org/path\"'\n\n    assert s.to_python({url: 1, multi_host_url: 2}) == {url: 1, multi_host_url: 2}\n    assert s.to_python({url: 1, multi_host_url: 2}, mode='json') == {\n        'https://ex.com/': 1,\n        'https://ex.com,ex.org/path': 2,\n    }\n    assert s.to_json({url: 1, multi_host_url: 2}) == b'{\"https://ex.com/\":1,\"https://ex.com,ex.org/path\":2}'\n\n\ndef test_custom_serializer():\n    s = SchemaSerializer(core_schema.any_schema(serialization=core_schema.simple_ser_schema('multi-host-url')))\n\n    multi_host_url = MultiHostUrl('https://ex.com,ex.org/path')\n    assert s.to_python(multi_host_url) == multi_host_url\n\n\n@pytest.mark.parametrize('base_class', [Url, MultiHostUrl])\ndef test_url_subclass(base_class):\n    class MyUrl(base_class):\n        def some_method(self):\n            return self.path + '-success'\n\n    m = MyUrl('http://ex.com/path')\n    assert m.some_method() == '/path-success'\n\n\n@pytest.mark.parametrize('value', (Url('https://example.com'), MultiHostUrl('https://example.com,example.org/path')))\ndef test_url_pickle(value):\n    pickled = pickle.dumps(value)\n    unpickled = pickle.loads(pickled)\n    assert value == unpickled\n", "tests/serializers/test_literal.py": "import pytest\n\nfrom pydantic_core import SchemaError, SchemaSerializer, core_schema\n\nfrom ..conftest import plain_repr\n\n\ndef test_int_literal():\n    s = SchemaSerializer(core_schema.literal_schema([1, 2, 3]))\n    r = plain_repr(s)\n    assert 'expected_int:{' in r\n    assert 'expected_str:{}' in r\n    assert 'expected_py:None' in r\n\n    assert s.to_python(1) == 1\n    assert s.to_python(1, mode='json') == 1\n    assert s.to_python(44) == 44\n    assert s.to_json(1) == b'1'\n\n    # with pytest.warns(UserWarning, match='Expected `int` but got `str` - serialized value may not be as expected'):\n    assert s.to_python('a', mode='json') == 'a'\n\n    # with pytest.warns(UserWarning, match='Expected `int` but got `str` - serialized value may not be as expected'):\n    assert s.to_json('a') == b'\"a\"'\n\n\ndef test_str_literal():\n    s = SchemaSerializer(core_schema.literal_schema(['a', 'b', 'c']))\n    r = plain_repr(s)\n    assert 'expected_str:{' in r\n    assert 'expected_int:{}' in r\n    assert 'expected_py:None' in r\n\n    assert s.to_python('a') == 'a'\n    assert s.to_python('a', mode='json') == 'a'\n    assert s.to_python('not in literal') == 'not in literal'\n    assert s.to_json('a') == b'\"a\"'\n\n    # with pytest.warns(UserWarning, match='Expected `str` but got `int` - serialized value may not be as expected'):\n    assert s.to_python(1, mode='json') == 1\n\n    # with pytest.warns(UserWarning, match='Expected `str` but got `int` - serialized value may not be as expected'):\n    assert s.to_json(1) == b'1'\n\n\ndef test_other_literal():\n    s = SchemaSerializer(core_schema.literal_schema(['a', 1]))\n    assert 'expected_int:{1},expected_str:{\"a\"},expected_py:None' in plain_repr(s)\n\n    assert s.to_python('a') == 'a'\n    assert s.to_python('a', mode='json') == 'a'\n    assert s.to_python('not in literal') == 'not in literal'\n    assert s.to_json('a') == b'\"a\"'\n\n    assert s.to_python(1) == 1\n    assert s.to_python(1, mode='json') == 1\n    assert s.to_python(44) == 44\n    assert s.to_json(1) == b'1'\n\n\ndef test_empty_literal():\n    with pytest.raises(SchemaError, match='`expected` should have length > 0'):\n        SchemaSerializer(core_schema.literal_schema([]))\n\n\ndef test_bool_literal():\n    s = SchemaSerializer(core_schema.literal_schema([False]))\n    assert 'expected_int:{},expected_str:{},expected_py:Some(Py(' in plain_repr(s)\n\n    assert s.to_python(False) is False\n    assert s.to_python(False, mode='json') is False\n    assert s.to_python(True) is True\n    assert s.to_json(False) == b'false'\n", "tests/serializers/__init__.py": "", "tests/serializers/test_dict.py": "import json\n\nimport pytest\nfrom dirty_equals import IsStrictDict\n\nfrom pydantic_core import SchemaError, SchemaSerializer, core_schema, validate_core_schema\n\n\ndef test_dict_str_int():\n    v = SchemaSerializer(core_schema.dict_schema(core_schema.str_schema(), core_schema.int_schema()))\n    assert v.to_python({'a': 1, 'b': 2, 'c': 3}) == {'a': 1, 'b': 2, 'c': 3}\n    assert v.to_python({'a': 1, 'b': 2, 'c': 3}, mode='json') == {'a': 1, 'b': 2, 'c': 3}\n    assert v.to_json({'a': 1, 'b': 2, 'c': 3}) == b'{\"a\":1,\"b\":2,\"c\":3}'\n\n    assert v.to_json({'a': 1, 'b': 2, 'c': 3}, indent=2) == b'{\\n  \"a\": 1,\\n  \"b\": 2,\\n  \"c\": 3\\n}'\n\n\ndef test_dict_any_any():\n    v = SchemaSerializer(core_schema.dict_schema())\n    assert v.to_python({'a': 1, b'b': 2, 33: 3}) == {'a': 1, b'b': 2, 33: 3}\n    assert v.to_python({'a': 1, b'b': 2, 33: 3, True: 4}, mode='json') == {'a': 1, 'b': 2, '33': 3, 'true': 4}\n    assert v.to_json({'a': 1, b'b': 2, 33: 3, True: 4}) == b'{\"a\":1,\"b\":2,\"33\":3,\"true\":4}'\n\n    assert v.to_python({(1, 2): 3}) == {(1, 2): 3}\n    assert v.to_python({(1, 2): 3}, mode='json') == {'1,2': 3}\n    assert v.to_json({(1, 2): 3}) == b'{\"1,2\":3}'\n\n\ndef test_include():\n    s = SchemaSerializer(core_schema.dict_schema(serialization=core_schema.filter_dict_schema(include={'a', 'c'})))\n\n    assert s.to_python({'a': 1, 'b': 2, 'c': 3, 'd': 4}) == {'a': 1, 'c': 3}\n    assert s.to_json({'a': 1, 'b': 2, 'c': 3, 'd': 4}) == b'{\"a\":1,\"c\":3}'\n\n    assert s.to_python({'a': 1, 'b': 2, 'd': 4}, include={'d'}) == {'a': 1, 'd': 4}\n    assert s.to_python({'a': 1, 'b': 2, 'd': 4}, include={'d': None}) == {'a': 1, 'd': 4}\n    assert s.to_python({'a': 1, 'b': 2, 'd': 4}, include={'d': {1}}) == {'a': 1, 'd': 4}\n\n    assert s.to_python({'a': 1, 'b': 2, 'd': 4, 5: 6}, include={5}) == {'a': 1, 5: 6}\n    assert s.to_python({'a': 1, 'b': 2, 'd': 4, 5: 6}, mode='json', include={5}) == {'a': 1, '5': 6}\n    assert s.to_json({'a': 1, 'b': 2, 'd': 4, 5: 6}, include={5}) == b'{\"a\":1,\"5\":6}'\n\n\ndef test_exclude():\n    s = SchemaSerializer(core_schema.dict_schema(serialization=core_schema.filter_dict_schema(exclude={'a', 'c'})))\n\n    assert s.to_python({'a': 1, 'b': 2, 'c': 3, 'd': 4}) == {'b': 2, 'd': 4}\n    assert s.to_json({'a': 1, 'b': 2, 'c': 3, 'd': 4}) == b'{\"b\":2,\"d\":4}'\n\n    assert s.to_python({'a': 1, 'b': 2, 'c': 3, 'd': 4}, exclude={'d'}) == {'b': 2}\n    assert s.to_python({'a': 1, 'b': 2, 'c': 3, 'd': 4}, exclude={'__all__'}) == {}\n    assert s.to_python({'a': 1, 'b': 2, 'c': 3, 'd': 4}, exclude={'d': ...}) == {'b': 2}\n    assert s.to_python({'a': 1, 'b': 2, 'c': 3, 'd': 4}, exclude={'d': {1}}) == {'b': 2, 'd': 4}\n\n    assert s.to_json({'a': 1, 'b': 2, 'c': 3, 'd': 4}, exclude={'d'}) == b'{\"b\":2}'\n\n\ndef test_filter():\n    s = SchemaSerializer(\n        core_schema.dict_schema(\n            serialization=core_schema.filter_dict_schema(include={'1', '3', '5'}, exclude={'5', '6'})\n        )\n    )\n\n    assert s.to_python({'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7}) == {'1': 1, '3': 3}\n\n\n@pytest.mark.parametrize(\n    'params',\n    [\n        dict(include=None, exclude=None, expected={'0': 0, '1': 1, '2': 2, '3': 3}),\n        dict(include={'0', '1'}, exclude=None, expected={'0': 0, '1': 1}),\n        dict(include={'0': ..., '1': ...}, exclude=None, expected={'0': 0, '1': 1}),\n        dict(include={'0': {1}, '1': {1}}, exclude=None, expected={'0': 0, '1': 1}),\n        dict(include=None, exclude={'0', '1'}, expected={'2': 2, '3': 3}),\n        dict(include=None, exclude={'0': ..., '1': ...}, expected={'2': 2, '3': 3}),\n        dict(include={'0', '1'}, exclude={'1', '2'}, expected={'0': 0}),\n        dict(include=None, exclude={'3': {1}}, expected={'0': 0, '1': 1, '2': 2, '3': 3}),\n        dict(include={'0', '1'}, exclude={'3': {1}}, expected={'0': 0, '1': 1}),\n        dict(include={'0', '1'}, exclude={'1': {1}}, expected={'0': 0, '1': 1}),\n        dict(include={'0', '1'}, exclude={'1': ...}, expected={'0': 0}),\n        dict(include=None, exclude={'__all__'}, expected={}),\n    ],\n)\ndef test_filter_args(params):\n    s = SchemaSerializer(core_schema.dict_schema())\n\n    # user IsStrictDict to check dict order\n    include, exclude, expected = params['include'], params['exclude'], IsStrictDict(params['expected'])\n    value = {'0': 0, '1': 1, '2': 2, '3': 3}\n    assert s.to_python(value, include=include, exclude=exclude) == expected\n    assert s.to_python(value, mode='json', include=include, exclude=exclude) == expected\n    assert json.loads(s.to_json(value, include=include, exclude=exclude)) == expected\n\n\n@pytest.mark.parametrize(\n    'params',\n    [\n        dict(include=None, exclude=None, expected={'0': [0], '1': [0, 1], '2': [0, 1, 2], '3': [0, 1, 2, 3]}),\n        dict(include=None, exclude={'1': {0}}, expected={'0': [0], '1': [1], '2': [0, 1, 2], '3': [0, 1, 2, 3]}),\n        dict(include={'1': {0}}, exclude=None, expected={'1': [0]}),\n        dict(include={'__all__': {0}}, exclude=None, expected={'0': [0], '1': [0], '2': [0], '3': [0]}),\n        dict(\n            include=None, exclude={'0': {'__all__'}}, expected={'0': [], '1': [0, 1], '2': [0, 1, 2], '3': [0, 1, 2, 3]}\n        ),\n        dict(include=None, exclude={'__all__': {'__all__'}}, expected={'0': [], '1': [], '2': [], '3': []}),\n        dict(include=None, exclude={'__all__': {0}}, expected={'0': [], '1': [1], '2': [1, 2], '3': [1, 2, 3]}),\n        dict(include=None, exclude={'__all__': {0}, '3': {1}}, expected={'0': [], '1': [1], '2': [1, 2], '3': [2, 3]}),\n    ],\n)\ndef test_filter_args_nested(params):\n    s = SchemaSerializer(core_schema.dict_schema(core_schema.str_schema(), core_schema.list_schema()))\n\n    include, exclude, expected = params['include'], params['exclude'], params['expected']\n    value = {'0': [0], '1': [0, 1], '2': [0, 1, 2], '3': [0, 1, 2, 3]}\n    assert s.to_python(value, include=include, exclude=exclude) == expected\n    assert s.to_python(value, mode='json', include=include, exclude=exclude) == expected\n    assert json.loads(s.to_json(value, include=include, exclude=exclude)) == expected\n\n\ndef test_filter_int():\n    s = SchemaSerializer(\n        core_schema.dict_schema(\n            core_schema.any_schema(), serialization=core_schema.filter_dict_schema(include={1, 3, 5}, exclude={5, 6})\n        )\n    )\n\n    assert s.to_python({0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7}) == {1: 1, 3: 3}\n\n\ndef test_filter_runtime():\n    s = SchemaSerializer(\n        core_schema.dict_schema(\n            core_schema.any_schema(), serialization=core_schema.filter_dict_schema(exclude={'0', '1'})\n        )\n    )\n    assert s.to_python({'0': 0, '1': 1, '2': 2, '3': 3}, include={'1', '2'}) == {'1': 1, '2': 2}\n    assert s.to_python({'0': 0, '1': 1, '2': 2, '3': 3}, include={'1', '2'}, exclude={'2', '3'}) == {'1': 1}\n\n\ndef test_filter_runtime_int():\n    s = SchemaSerializer(\n        core_schema.dict_schema(core_schema.any_schema(), serialization=core_schema.filter_dict_schema(exclude={0, 1}))\n    )\n    assert s.to_python({0: 0, 1: 1, 2: 2, 3: 3}, include={1, 2}) == {1: 1, 2: 2}\n\n\n@pytest.mark.parametrize(\n    'include_value,error_msg',\n    [\n        ('foobar', 'Input should be a valid set'),\n        ({'a': 'dict'}, 'Input should be a valid set'),\n        ({4.2}, 'Input should be a valid integer, got a number with a fractional part'),\n    ],\n)\ndef test_include_error(include_value, error_msg):\n    with pytest.raises(SchemaError, match=error_msg):\n        validate_core_schema(\n            core_schema.dict_schema(serialization=core_schema.filter_dict_schema(include=include_value))\n        )\n", "tests/serializers/test_dataclasses.py": "import dataclasses\nimport json\nimport platform\nimport sys\nfrom typing import ClassVar\n\nimport pytest\n\nfrom pydantic_core import SchemaSerializer, SchemaValidator, core_schema\n\non_pypy = platform.python_implementation() == 'PyPy'\n# pypy doesn't seem to maintain order of `__dict__`\nif on_pypy:\n    IsStrictDict = dict\nelse:\n    from dirty_equals import IsStrictDict\n\n\n@dataclasses.dataclass\nclass Foo:\n    a: str\n    b: bytes\n\n\ndef test_dataclass():\n    schema = core_schema.dataclass_schema(\n        Foo,\n        core_schema.dataclass_args_schema(\n            'Foo',\n            [\n                core_schema.dataclass_field(name='a', schema=core_schema.str_schema()),\n                core_schema.dataclass_field(name='b', schema=core_schema.bytes_schema()),\n            ],\n        ),\n        ['a', 'b'],\n    )\n    s = SchemaSerializer(schema)\n    assert s.to_python(Foo(a='hello', b=b'more')) == IsStrictDict(a='hello', b=b'more')\n    assert s.to_python(Foo(a='hello', b=b'more'), mode='json') == IsStrictDict(a='hello', b='more')\n    j = s.to_json(Foo(a='hello', b=b'more'))\n\n    if on_pypy:\n        assert json.loads(j) == {'a': 'hello', 'b': 'more'}\n    else:\n        assert j == b'{\"a\":\"hello\",\"b\":\"more\"}'\n\n    assert s.to_python(Foo(a='hello', b=b'more'), exclude={'b'}) == IsStrictDict(a='hello')\n    assert s.to_json(Foo(a='hello', b=b'more'), include={'a'}) == b'{\"a\":\"hello\"}'\n\n\ndef test_serialization_exclude():\n    schema = core_schema.dataclass_schema(\n        Foo,\n        core_schema.dataclass_args_schema(\n            'Foo',\n            [\n                core_schema.dataclass_field(name='a', schema=core_schema.str_schema()),\n                core_schema.dataclass_field(name='b', schema=core_schema.bytes_schema(), serialization_exclude=True),\n            ],\n        ),\n        ['a', 'b'],\n    )\n    s = SchemaSerializer(schema)\n    assert s.to_python(Foo(a='hello', b=b'more')) == {'a': 'hello'}\n    assert s.to_python(Foo(a='hello', b=b'more'), mode='json') == {'a': 'hello'}\n    j = s.to_json(Foo(a='hello', b=b'more'))\n\n    if on_pypy:\n        assert json.loads(j) == {'a': 'hello'}\n    else:\n        assert j == b'{\"a\":\"hello\"}'\n\n\ndef test_serialization_alias():\n    schema = core_schema.dataclass_schema(\n        Foo,\n        core_schema.dataclass_args_schema(\n            'Foo',\n            [\n                core_schema.dataclass_field(name='a', schema=core_schema.str_schema()),\n                core_schema.dataclass_field(name='b', schema=core_schema.bytes_schema(), serialization_alias='BAR'),\n            ],\n        ),\n        ['a', 'b'],\n    )\n    s = SchemaSerializer(schema)\n    assert s.to_python(Foo(a='hello', b=b'more')) == IsStrictDict(a='hello', BAR=b'more')\n    assert s.to_python(Foo(a='hello', b=b'more'), mode='json') == IsStrictDict(a='hello', BAR='more')\n    j = s.to_json(Foo(a='hello', b=b'more'))\n\n    if on_pypy:\n        assert json.loads(j) == {'a': 'hello', 'BAR': 'more'}\n    else:\n        assert j == b'{\"a\":\"hello\",\"BAR\":\"more\"}'\n\n\ndef test_properties():\n    @dataclasses.dataclass\n    class FooProp:\n        a: str\n        b: bytes\n\n        @property\n        def c(self) -> str:\n            return f'{self.a} {self.b.decode()}'\n\n    schema = core_schema.dataclass_schema(\n        Foo,\n        core_schema.dataclass_args_schema(\n            'FooProp',\n            [\n                core_schema.dataclass_field(name='a', schema=core_schema.str_schema()),\n                core_schema.dataclass_field(name='b', schema=core_schema.bytes_schema()),\n            ],\n            computed_fields=[core_schema.computed_field('c', core_schema.str_schema())],\n        ),\n        ['a', 'b'],\n    )\n    s = SchemaSerializer(schema)\n    assert s.to_python(FooProp(a='hello', b=b'more')) == IsStrictDict(a='hello', b=b'more', c='hello more')\n    assert s.to_python(FooProp(a='hello', b=b'more'), mode='json') == IsStrictDict(a='hello', b='more', c='hello more')\n    j = s.to_json(FooProp(a='hello', b=b'more'))\n\n    if on_pypy:\n        assert json.loads(j) == {'a': 'hello', 'b': 'more', 'c': 'hello more'}\n    else:\n        assert j == b'{\"a\":\"hello\",\"b\":\"more\",\"c\":\"hello more\"}'\n\n    assert s.to_python(FooProp(a='hello', b=b'more'), exclude={'b'}) == IsStrictDict(a='hello', c='hello more')\n    assert s.to_json(FooProp(a='hello', b=b'more'), include={'a'}) == b'{\"a\":\"hello\"}'\n\n\n@pytest.mark.skipif(sys.version_info < (3, 10), reason='slots are only supported for dataclasses in Python > 3.10')\ndef test_slots_mixed():\n    @dataclasses.dataclass(slots=True)\n    class Model:\n        x: int\n        y: dataclasses.InitVar[str]\n        z: ClassVar[str] = 'z-classvar'\n\n    @dataclasses.dataclass\n    class SubModel(Model):\n        x2: int\n        y2: dataclasses.InitVar[str]\n        z2: ClassVar[str] = 'z2-classvar'\n\n    schema = core_schema.dataclass_schema(\n        SubModel,\n        core_schema.dataclass_args_schema(\n            'SubModel',\n            [\n                core_schema.dataclass_field(name='x', schema=core_schema.int_schema()),\n                core_schema.dataclass_field(name='y', init_only=True, schema=core_schema.str_schema()),\n                core_schema.dataclass_field(name='x2', schema=core_schema.int_schema()),\n                core_schema.dataclass_field(name='y2', init_only=True, schema=core_schema.str_schema()),\n            ],\n        ),\n        ['x', 'x2'],\n        slots=True,\n    )\n    dc = SubModel(x=1, y='a', x2=2, y2='b')\n    assert dataclasses.asdict(dc) == {'x': 1, 'x2': 2}\n\n    s = SchemaSerializer(schema)\n    assert s.to_python(dc) == {'x': 1, 'x2': 2}\n    assert s.to_json(dc) == b'{\"x\":1,\"x2\":2}'\n\n\n@pytest.mark.xfail(reason='dataclasses do not serialize extras')\ndef test_extra_custom_serializer():\n    @dataclasses.dataclass\n    class Model:\n        pass\n\n    schema = core_schema.dataclass_schema(\n        Model,\n        core_schema.dataclass_args_schema(\n            'Model',\n            [],\n            extra_behavior='allow',\n            # extras_schema=core_schema.any_schema(\n            #     serialization=core_schema.plain_serializer_function_ser_schema(\n            #         lambda v: v + ' bam!',\n            #     )\n            # )\n        ),\n        [],\n    )\n    s = SchemaSerializer(schema)\n    v = SchemaValidator(schema)\n\n    m = v.validate_python({'extra': 'extra'})\n\n    assert s.to_python(m) == {'extra': 'extra bam!'}\n", "tests/serializers/test_any.py": "import dataclasses\nimport json\nimport platform\nimport re\nimport sys\nfrom collections import namedtuple\nfrom datetime import date, datetime, time, timedelta, timezone\nfrom decimal import Decimal\nfrom enum import Enum\nfrom math import inf, isinf, isnan, nan\nfrom pathlib import Path\nfrom typing import ClassVar\n\nimport pytest\nfrom dirty_equals import HasRepr, IsList\n\nimport pydantic_core\nfrom pydantic_core import PydanticSerializationError, SchemaSerializer, SchemaValidator, core_schema, to_json\n\nfrom ..conftest import plain_repr\nfrom .test_dataclasses import IsStrictDict, on_pypy\nfrom .test_list_tuple import as_list, as_tuple\n\ntry:\n    import numpy\nexcept ImportError:\n    numpy = None\n\n\n@pytest.fixture(scope='module')\ndef any_serializer():\n    return SchemaSerializer(core_schema.any_schema())\n\n\ndef test_repr(any_serializer):\n    assert plain_repr(any_serializer) == 'SchemaSerializer(serializer=Any(AnySerializer),definitions=[])'\n\n\n@dataclasses.dataclass(frozen=True)\nclass MyDataclass:\n    class_var: ClassVar[int] = 1\n    a: int\n    b: str\n    frog: dataclasses.InitVar[int]\n\n\nclass MyModel:\n    def __init__(self, **kwargs):\n        fields = {}\n        for key, value in kwargs.items():\n            setattr(self, key, value)\n            fields[key] = core_schema.model_field(core_schema.any_schema())\n        self.__pydantic_serializer__ = SchemaSerializer(\n            core_schema.model_schema(MyModel, core_schema.model_fields_schema(fields))\n        )\n\n    def __repr__(self):\n        return f'MyModel({self.__dict__})'\n\n\n@pytest.mark.parametrize('value', [None, 1, 1.0, True, 'foo', [1, 2, 3], {'a': 1, 'b': 2}])\ndef test_any_json_round_trip(any_serializer, value):\n    assert any_serializer.to_python(value) == value\n    assert json.loads(any_serializer.to_json(value)) == value\n    assert any_serializer.to_python(value, mode='json') == value\n\n\n@pytest.mark.parametrize(\n    'input_value,expected_plain,expected_json_obj',\n    [\n        (MyDataclass(1, 'foo', 3), {'a': 1, 'b': 'foo'}, {'a': 1, 'b': 'foo'}),\n        (MyModel(a=1, b='foo'), {'a': 1, 'b': 'foo'}, {'a': 1, 'b': 'foo'}),\n        ({1, 2, 3}, {1, 2, 3}, IsList(1, 2, 3, check_order=False)),\n        ({1, '2', b'3'}, {1, '2', b'3'}, IsList(1, '2', '3', check_order=False)),\n    ],\n    ids=repr,\n)\ndef test_any_python(any_serializer, input_value, expected_plain, expected_json_obj):\n    assert any_serializer.to_python(input_value) == expected_plain\n    assert any_serializer.to_python(input_value, mode='json') == expected_json_obj\n    assert json.loads(any_serializer.to_json(input_value)) == expected_json_obj\n\n\ndef test_set_member_db(any_serializer):\n    input_value = {MyDataclass(1, 'a', 2), MyDataclass(2, 'b', 2)}\n    expected_json_obj = IsList({'a': 1, 'b': 'a'}, {'a': 2, 'b': 'b'}, check_order=False)\n    assert any_serializer.to_python(input_value, mode='json') == expected_json_obj\n    assert json.loads(any_serializer.to_json(input_value)) == expected_json_obj\n    with pytest.raises(TypeError, match=\"unhashable type: 'dict'\"):\n        any_serializer.to_python(input_value)\n\n\n@pytest.mark.parametrize(\n    'value,expected_json',\n    [\n        (None, b'null'),\n        (1, b'1'),\n        (Decimal('1.123'), b'\"1.123\"'),\n        (b'foobar', b'\"foobar\"'),\n        (bytearray(b'foobar'), b'\"foobar\"'),\n        ((1, 2, 3), b'[1,2,3]'),\n        ({1: 2, 'a': 4}, b'{\"1\":2,\"a\":4}'),\n        ({(1, 'a', 2): 3}, b'{\"1,a,2\":3}'),\n        ({(1,): 3}, b'{\"1\":3}'),\n        (datetime(2022, 12, 3, 12, 30, 45), b'\"2022-12-03T12:30:45\"'),\n        (datetime(2032, 1, 1, 1, 1), b'\"2032-01-01T01:01:00\"'),\n        (date(2022, 12, 3), b'\"2022-12-03\"'),\n        (time(12, 30, 45), b'\"12:30:45\"'),\n        (timedelta(hours=2), b'\"PT2H\"'),\n        (MyDataclass(1, 'foo', 2), b'{\"a\":1,\"b\":\"foo\"}'),\n        (MyModel(a=1, b='foo'), b'{\"a\":1,\"b\":\"foo\"}'),\n        ([MyDataclass(1, 'a', 2), MyModel(a=2, b='b')], b'[{\"a\":1,\"b\":\"a\"},{\"a\":2,\"b\":\"b\"}]'),\n        pytest.param(\n            Path('/foo/bar/spam.svg'),\n            b'\"/foo/bar/spam.svg\"',\n            marks=pytest.mark.skipif(sys.platform == 'win32', reason='Path output different on windows'),\n        ),\n        pytest.param(\n            Path(r'C:\\\\foo\\\\bar\\\\spam.svg'),\n            b'\"C:\\\\\\\\foo\\\\\\\\bar\\\\\\\\spam.svg\"',\n            marks=pytest.mark.skipif(sys.platform != 'win32', reason='Path output different on windows'),\n        ),\n        # I'm open to adding custom logic to make namedtuples behave like dataclasses or models\n        (namedtuple('Point', ['x', 'y'])(1, 2), b'[1,2]'),\n    ],\n)\ndef test_any_json(any_serializer, value, expected_json):\n    assert any_serializer.to_json(value) == expected_json\n    assert any_serializer.to_python(value, mode='json') == json.loads(expected_json)\n\n\ndef test_other_type():\n    \"\"\"Types with no serializer, fall back to any serializer\"\"\"\n    v = SchemaSerializer(core_schema.is_instance_schema(int))\n    assert plain_repr(v) == 'SchemaSerializer(serializer=Any(AnySerializer),definitions=[])'\n    assert v.to_json('foobar') == b'\"foobar\"'\n\n\n@pytest.mark.parametrize('value', [b'\\x81', bytearray(b'\\x81')])\ndef test_any_json_decode_error(any_serializer, value):\n    assert any_serializer.to_python(value) == value\n\n    msg = 'Error serializing to JSON: invalid utf-8 sequence of 1 bytes from index 0'\n    with pytest.raises(PydanticSerializationError, match=msg):\n        any_serializer.to_json(value)\n\n    with pytest.raises(ValueError):\n        any_serializer.to_python(value, mode='json')\n\n\ndef test_any_with_date_serializer():\n    s = SchemaSerializer(core_schema.any_schema(serialization={'type': 'date'}))\n    assert s.to_python(date(2022, 12, 3)) == date(2022, 12, 3)\n    assert s.to_python(date(2022, 12, 3), mode='json') == '2022-12-03'\n    assert s.to_json(date(2022, 12, 3)) == b'\"2022-12-03\"'\n\n    with pytest.warns(UserWarning) as warning_info:\n        assert s.to_python(b'bang', mode='json') == 'bang'\n\n    assert [w.message.args[0] for w in warning_info.list] == [\n        'Pydantic serializer warnings:\\n  Expected `date` but got `bytes` - serialized value may not be as expected'\n    ]\n\n\ndef test_any_with_timedelta_serializer():\n    s = SchemaSerializer(core_schema.any_schema(serialization={'type': 'timedelta'}))\n    assert s.to_python(timedelta(hours=2)) == timedelta(hours=2)\n    assert s.to_python(timedelta(hours=2), mode='json') == 'PT2H'\n    assert s.to_json(timedelta(hours=2)) == b'\"PT2H\"'\n\n    with pytest.warns(UserWarning) as warning_info:\n        assert s.to_python(b'bang', mode='json') == 'bang'\n\n    assert [w.message.args[0] for w in warning_info.list] == [\n        'Pydantic serializer warnings:\\n  Expected `timedelta` but got `bytes` - '\n        'serialized value may not be as expected'\n    ]\n\n\ndef test_any_config_timedelta_float():\n    s = SchemaSerializer(core_schema.any_schema(), config={'ser_json_timedelta': 'float'})\n    h2 = timedelta(hours=2)\n    assert s.to_python(h2) == h2\n    assert s.to_python(h2, mode='json') == 7200.0\n    assert s.to_json(h2) == b'7200.0'\n\n    assert s.to_python({h2: 'foo'}) == {h2: 'foo'}\n    assert s.to_python({h2: 'foo'}, mode='json') == {'7200': 'foo'}\n    assert s.to_json({h2: 'foo'}) == b'{\"7200\":\"foo\"}'\n\n\ndef test_any_config_timedelta_float_faction():\n    s = SchemaSerializer(core_schema.any_schema(), config={'ser_json_timedelta': 'float'})\n    one_half_s = timedelta(seconds=1.5)\n    assert s.to_python(one_half_s) == one_half_s\n    assert s.to_python(one_half_s, mode='json') == 1.5\n    assert s.to_json(one_half_s) == b'1.5'\n\n    assert s.to_python({one_half_s: 'foo'}) == {one_half_s: 'foo'}\n    assert s.to_python({one_half_s: 'foo'}, mode='json') == {'1.5': 'foo'}\n    assert s.to_json({one_half_s: 'foo'}) == b'{\"1.5\":\"foo\"}'\n\n\ndef test_recursion(any_serializer):\n    v = [1, 2]\n    v.append(v)\n    assert any_serializer.to_python(v) == v\n    with pytest.raises(ValueError, match=r'Circular reference detected \\(id repeated\\)'):\n        any_serializer.to_python(v, mode='json')\n    with pytest.raises(ValueError, match=r'Circular reference detected \\(id repeated\\)'):\n        any_serializer.to_json(v)\n\n\n@pytest.mark.parametrize('seq_f', [as_list, as_tuple])\ndef test_include_list_tuple(any_serializer, seq_f):\n    assert any_serializer.to_python(seq_f(0, 1, 2, 3)) == seq_f(0, 1, 2, 3)\n    assert any_serializer.to_python(seq_f('a', 'b', 'c')) == seq_f('a', 'b', 'c')\n    assert any_serializer.to_python(seq_f('a', 'b', 'c'), mode='json') == ['a', 'b', 'c']\n    assert any_serializer.to_json(seq_f('a', 'b', 'c')) == b'[\"a\",\"b\",\"c\"]'\n\n    assert any_serializer.to_python(seq_f(0, 1, 2, 3), include={1, 2}) == seq_f(1, 2)\n    assert any_serializer.to_python(seq_f(0, 1, 2, 3), include={-1, -2}) == seq_f(2, 3)\n    assert any_serializer.to_python(seq_f(0, 1, 2, 3), include={1, 2}, mode='json') == [1, 2]\n    assert any_serializer.to_python(seq_f('a', 'b', 'c', 'd'), include={1, 2}) == seq_f('b', 'c')\n    assert any_serializer.to_python(seq_f('a', 'b', 'c', 'd'), include={1, 2}, mode='json') == ['b', 'c']\n    assert any_serializer.to_json(seq_f('a', 'b', 'c', 'd'), include={1, 2}) == b'[\"b\",\"c\"]'\n\n\ndef as_generator(*items):\n    return (v for v in items)\n\n\ndef test_include_generator(any_serializer):\n    assert any_serializer.to_python(as_generator('a', 'b', 'c'), mode='json') == ['a', 'b', 'c']\n    assert any_serializer.to_json(as_generator('a', 'b', 'c')) == b'[\"a\",\"b\",\"c\"]'\n\n    assert any_serializer.to_python(as_generator(0, 1, 2, 3), include={1, 2}, mode='json') == [1, 2]\n    assert any_serializer.to_python(as_generator('a', 'b', 'c', 'd'), include={1, 2}, mode='json') == ['b', 'c']\n    assert any_serializer.to_json(as_generator('a', 'b', 'c', 'd'), include={1, 2}) == b'[\"b\",\"c\"]'\n\n\ndef test_include_dict(any_serializer):\n    assert any_serializer.to_python({1: 2, '3': 4}) == {1: 2, '3': 4}\n    assert any_serializer.to_python(MyDataclass(a=1, b='foo', frog=2)) == {'a': 1, 'b': 'foo'}\n    assert any_serializer.to_python({1: 2, '3': 4}, mode='json') == {'1': 2, '3': 4}\n    assert any_serializer.to_json({1: 2, '3': 4}) == b'{\"1\":2,\"3\":4}'\n    assert any_serializer.to_json(MyDataclass(a=1, b='foo', frog=2)) == b'{\"a\":1,\"b\":\"foo\"}'\n\n    assert any_serializer.to_python({1: 2, '3': 4}, include={1}) == {1: 2}\n    assert any_serializer.to_python({1: 2, '3': 4}, include={'3'}) == {'3': 4}\n    assert any_serializer.to_python(MyDataclass(a=1, b='foo', frog=2), include={'a'}) == {'a': 1}\n    assert any_serializer.to_python(MyDataclass(a=1, b='foo', frog=2), include={'a'}, mode='json') == {'a': 1}\n    assert any_serializer.to_python(MyModel(a=1, b='foo'), include={'a'}) == {'a': 1}\n    assert any_serializer.to_python(MyModel(a=1, b='foo'), include={'a'}, mode='json') == {'a': 1}\n    assert any_serializer.to_python({1: 2, '3': 4}, include={1}, mode='json') == {'1': 2}\n    assert any_serializer.to_python({1: 2, '3': 4}, include={'3'}, mode='json') == {'3': 4}\n    assert any_serializer.to_json({1: 2, '3': 4}, include={1}) == b'{\"1\":2}'\n    assert any_serializer.to_json({1: 2, '3': 4}, include={'3'}) == b'{\"3\":4}'\n    assert any_serializer.to_json(MyDataclass(a=1, b='foo', frog=2), include={'a'}) == b'{\"a\":1}'\n\n\ndef test_exclude_dict(any_serializer):\n    assert any_serializer.to_python({1: 2, '3': 4}) == {1: 2, '3': 4}\n    assert any_serializer.to_python({1: 2, 3: 4}, exclude={1}) == {3: 4}\n    assert any_serializer.to_python({1: 2, 3: 4}, exclude={-1}) == {1: 2, 3: 4}\n\n\nclass FieldsSetModel:\n    __pydantic_serializer__ = 42\n    __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n\n    def __init__(self, **kwargs):\n        fields = {}\n        for key, value in kwargs.items():\n            setattr(self, key, value)\n            fields[key] = core_schema.model_field(core_schema.any_schema())\n        self.__pydantic_serializer__ = SchemaSerializer(\n            core_schema.model_schema(MyModel, core_schema.model_fields_schema(fields))\n        )\n\n\ndef test_exclude_unset(any_serializer):\n    # copied from test of the same name in test_model.py\n    m = FieldsSetModel(foo=1, bar=2, spam=3, __pydantic_fields_set__={'bar', 'spam'})\n    assert any_serializer.to_python(m) == {'foo': 1, 'bar': 2, 'spam': 3}\n    assert any_serializer.to_python(m, exclude_unset=True) == {'bar': 2, 'spam': 3}\n    assert any_serializer.to_python(m, exclude=None, exclude_unset=True) == {'bar': 2, 'spam': 3}\n    assert any_serializer.to_python(m, exclude={'bar'}, exclude_unset=True) == {'spam': 3}\n    assert any_serializer.to_python(m, exclude={'bar': ...}, exclude_unset=True) == {'spam': 3}\n    assert any_serializer.to_python(m, exclude={'bar': {}}, exclude_unset=True) == {'bar': 2, 'spam': 3}\n\n    assert any_serializer.to_json(m, exclude=None, exclude_unset=True) == b'{\"bar\":2,\"spam\":3}'\n    assert any_serializer.to_json(m, exclude={'bar'}, exclude_unset=True) == b'{\"spam\":3}'\n    assert any_serializer.to_json(m, exclude={'bar': ...}, exclude_unset=True) == b'{\"spam\":3}'\n    assert any_serializer.to_json(m, exclude={'bar': {}}, exclude_unset=True) == b'{\"bar\":2,\"spam\":3}'\n\n    m2 = FieldsSetModel(foo=1, bar=2, spam=3, __pydantic_fields_set__={'bar', 'spam', 'missing'})\n    assert any_serializer.to_python(m2) == {'foo': 1, 'bar': 2, 'spam': 3}\n    assert any_serializer.to_python(m2, exclude_unset=True) == {'bar': 2, 'spam': 3}\n\n\nclass Foobar:\n    def __repr__(self):\n        return '<Foobar repr>'\n\n\ndef test_unknown_type(any_serializer: SchemaSerializer):\n    f = Foobar()\n    assert any_serializer.to_python(f) == f\n\n    with pytest.raises(PydanticSerializationError, match=\"Unable to serialize unknown type: <class '.+Foobar'>\"):\n        any_serializer.to_python(f, mode='json')\n\n    with pytest.raises(PydanticSerializationError, match=\"Unable to serialize unknown type: <class '.+Foobar'>\"):\n        any_serializer.to_json(f)\n\n\ndef test_unknown_type_fallback(any_serializer: SchemaSerializer):\n    def fallback_func(obj):\n        return f'fallback:{obj!r}'\n\n    f = Foobar()\n    assert any_serializer.to_python(f) == f\n\n    assert any_serializer.to_python(f, mode='json', fallback=fallback_func) == 'fallback:<Foobar repr>'\n    assert any_serializer.to_python(f, fallback=fallback_func) == 'fallback:<Foobar repr>'\n    assert any_serializer.to_json(f, fallback=fallback_func) == b'\"fallback:<Foobar repr>\"'\n\n\ndef test_fallback_cycle_same(any_serializer: SchemaSerializer):\n    def fallback_func(obj):\n        return obj\n\n    f = Foobar()\n    assert any_serializer.to_python(f) == f\n\n    with pytest.raises(ValueError, match=r'Circular reference detected \\(id repeated\\)'):\n        any_serializer.to_python(f, mode='json', fallback=fallback_func)\n\n    # because when recursion is detected and we're in mode python, we just return the value\n    assert any_serializer.to_python(f, fallback=fallback_func) == f\n\n    with pytest.raises(ValueError, match=r'Circular reference detected \\(id repeated\\)'):\n        any_serializer.to_json(f, fallback=fallback_func)\n\n\nclass FoobarCount:\n    def __init__(self, v):\n        self.v = v\n\n    def __repr__(self):\n        return f'<FoobarCount {self.v} repr>'\n\n\n@pytest.mark.skipif(\n    platform.python_implementation() == 'PyPy' and pydantic_core._pydantic_core.build_profile == 'debug',\n    reason='PyPy does not have enough stack space for Rust debug builds to recurse very deep',\n)\ndef test_fallback_cycle_change(any_serializer: SchemaSerializer):\n    v = 1\n\n    def fallback_func(obj):\n        nonlocal v\n        v += 1\n        return FoobarCount(v)\n\n    f = FoobarCount(0)\n    assert any_serializer.to_python(f) == f\n\n    with pytest.raises(ValueError, match=r'Circular reference detected \\(depth exceeded\\)'):\n        any_serializer.to_python(f, mode='json', fallback=fallback_func)\n\n    f = FoobarCount(0)\n    v = 0\n    # when recursion is detected and we're in mode python, we just return the value\n    expected_visits = pydantic_core._pydantic_core._recursion_limit\n    assert any_serializer.to_python(f, fallback=fallback_func) == HasRepr(f'<FoobarCount {expected_visits} repr>')\n\n    with pytest.raises(ValueError, match=r'Circular reference detected \\(depth exceeded\\)'):\n        any_serializer.to_json(f, fallback=fallback_func)\n\n\nclass MyEnum(Enum):\n    a = 1\n    b = 'b'\n\n\ndef test_enum(any_serializer):\n    assert any_serializer.to_python(MyEnum.a) == MyEnum.a\n    assert any_serializer.to_python(MyEnum.b) == MyEnum.b\n    assert any_serializer.to_python({MyEnum.a: 42}) == {MyEnum.a: 42}\n    assert any_serializer.to_python({MyEnum.b: 42}) == {MyEnum.b: 42}\n\n    assert any_serializer.to_python(MyEnum.a, mode='json') == 1\n    assert any_serializer.to_python(MyEnum.b, mode='json') == 'b'\n    assert any_serializer.to_python({MyEnum.a: 42}, mode='json') == {'1': 42}\n    assert any_serializer.to_python({MyEnum.b: 42}, mode='json') == {'b': 42}\n\n    assert any_serializer.to_json(MyEnum.a) == b'1'\n    assert any_serializer.to_json(MyEnum.b) == b'\"b\"'\n    assert any_serializer.to_json({MyEnum.a: 42}) == b'{\"1\":42}'\n    assert any_serializer.to_json({MyEnum.b: 42}) == b'{\"b\":42}'\n\n\ndef test_base64():\n    s = SchemaSerializer(core_schema.any_schema(), core_schema.CoreConfig(ser_json_bytes='base64'))\n    assert s.to_python(b'foo') == b'foo'\n    assert s.to_python(b'foo', mode='json') == 'Zm9v'\n    assert s.to_json(b'foo') == b'\"Zm9v\"'\n    assert s.to_python(bytearray(b'foo')) == b'foo'\n    assert s.to_python(bytearray(b'foo'), mode='json') == 'Zm9v'\n    assert s.to_json(bytearray(b'foo')) == b'\"Zm9v\"'\n\n\n@pytest.mark.parametrize(\n    'gen_input,kwargs,expected_json',\n    [\n        # (lambda: UUID('ebcdab58-6eb8-46fb-a190-d07a33e9eac8'), '\"ebcdab58-6eb8-46fb-a190-d07a33e9eac8\"'),\n        (lambda: datetime(2032, 1, 1, 1, 1), {}, b'\"2032-01-01T01:01:00\"'),\n        (lambda: datetime(2032, 1, 1, 1, 1, tzinfo=timezone.utc), {}, b'\"2032-01-01T01:01:00Z\"'),\n        (lambda: datetime(2032, 1, 1, 1, 1, tzinfo=timezone(timedelta(hours=2))), {}, b'\"2032-01-01T01:01:00+02:00\"'),\n        (lambda: datetime(2032, 1, 1), {}, b'\"2032-01-01T00:00:00\"'),\n        (lambda: time(12, 34, 56), {}, b'\"12:34:56\"'),\n        (lambda: timedelta(days=12, seconds=34, microseconds=56), {}, b'\"P12DT34.000056S\"'),\n        (lambda: timedelta(days=12, seconds=34, microseconds=56), dict(timedelta_mode='float'), b'1036834.000056'),\n        (lambda: timedelta(seconds=-1), {}, b'\"-PT1S\"'),\n        (lambda: timedelta(seconds=-1), dict(timedelta_mode='float'), b'-1.0'),\n        (lambda: {1, 2, 3}, {}, b'[1,2,3]'),\n        (lambda: frozenset([1, 2, 3]), {}, b'[1,2,3]'),\n        (lambda: (v for v in range(4)), {}, b'[0,1,2,3]'),\n        (lambda: iter([0, 1, 2, 3]), {}, b'[0,1,2,3]'),\n        (lambda: iter((0, 1, 2, 3)), {}, b'[0,1,2,3]'),\n        (lambda: iter(range(4)), {}, b'[0,1,2,3]'),\n        (lambda: b'this is bytes', {}, b'\"this is bytes\"'),\n        (lambda: b'this is bytes', dict(bytes_mode='base64'), b'\"dGhpcyBpcyBieXRlcw==\"'),\n        (lambda: bytearray(b'this is bytes'), {}, b'\"this is bytes\"'),\n        (lambda: bytearray(b'this is bytes'), dict(bytes_mode='base64'), b'\"dGhpcyBpcyBieXRlcw==\"'),\n        (lambda: Decimal('12.34'), {}, b'\"12.34\"'),\n        (lambda: MyEnum.a, {}, b'1'),\n        (lambda: MyEnum.b, {}, b'\"b\"'),\n        (lambda: [MyDataclass(1, 'a', 2), MyModel(a=2, b='b')], {}, b'[{\"a\":1,\"b\":\"a\"},{\"a\":2,\"b\":\"b\"}]'),\n        (lambda: re.compile('^regex$'), {}, b'\"^regex$\"'),\n    ],\n)\ndef test_encoding(any_serializer, gen_input, kwargs, expected_json):\n    assert to_json(gen_input(), **kwargs) == expected_json\n    if not kwargs:\n        assert any_serializer.to_python(gen_input(), mode='json') == json.loads(expected_json)\n\n\ndef test_any_dataclass():\n    @dataclasses.dataclass\n    class Foo:\n        a: str\n        b: bytes\n\n    # Build a schema that does not include the field 'b', to test that it is not serialized\n    schema = core_schema.dataclass_schema(\n        Foo,\n        core_schema.dataclass_args_schema(\n            'Foo', [core_schema.dataclass_field(name='a', schema=core_schema.str_schema())]\n        ),\n        ['a'],\n    )\n    Foo.__pydantic_serializer__ = SchemaSerializer(schema)\n\n    s = SchemaSerializer(core_schema.any_schema())\n    assert s.to_python(Foo(a='hello', b=b'more')) == IsStrictDict(a='hello')\n    assert s.to_python(Foo(a='hello', b=b'more'), mode='json') == IsStrictDict(a='hello')\n    j = s.to_json(Foo(a='hello', b=b'more'))\n\n    if on_pypy:\n        assert json.loads(j) == {'a': 'hello'}\n    else:\n        assert j == b'{\"a\":\"hello\"}'\n\n    assert s.to_python(Foo(a='hello', b=b'more'), exclude={'a'}) == IsStrictDict()\n\n\ndef test_any_model():\n    @dataclasses.dataclass\n    class Foo:\n        a: str\n        b: bytes\n\n    # Build a schema that does not include the field 'b', to test that it is not serialized\n    schema = core_schema.dataclass_schema(\n        Foo,\n        core_schema.dataclass_args_schema(\n            'Foo', [core_schema.dataclass_field(name='a', schema=core_schema.str_schema())]\n        ),\n        ['a'],\n    )\n    Foo.__pydantic_validator__ = SchemaValidator(schema)\n    Foo.__pydantic_serializer__ = SchemaSerializer(schema)\n\n    s = SchemaSerializer(core_schema.any_schema())\n    assert s.to_python(Foo(a='hello', b=b'more')) == IsStrictDict(a='hello')\n    assert s.to_python(Foo(a='hello', b=b'more'), mode='json') == IsStrictDict(a='hello')\n    j = s.to_json(Foo(a='hello', b=b'more'))\n\n    if on_pypy:\n        assert json.loads(j) == {'a': 'hello'}\n    else:\n        assert j == b'{\"a\":\"hello\"}'\n\n    assert s.to_python(Foo(a='hello', b=b'more'), exclude={'a'}) == IsStrictDict()\n    assert s.to_json(Foo(a='hello', b=b'more'), exclude={'a'}) == b'{}'\n\n    assert s.to_python(Foo) == Foo\n    with pytest.raises(PydanticSerializationError, match=r\"Unable to serialize unknown type: <class 'type'>\"):\n        s.to_python(Foo, mode='json')\n    with pytest.raises(PydanticSerializationError, match=r\"Unable to serialize unknown type: <class 'type'>\"):\n        s.to_json(Foo)\n    assert s.to_python(Foo, mode='json', fallback=lambda x: x.__name__) == 'Foo'\n    assert s.to_json(Foo, fallback=lambda x: x.__name__) == b'\"Foo\"'\n\n\ndef test_dataclass_classvar(any_serializer):\n    @dataclasses.dataclass\n    class Foo:\n        a: int\n        b: str\n        c: ClassVar[int] = 1\n\n    foo = Foo(1, 'a')\n    assert any_serializer.to_python(foo) == IsStrictDict(a=1, b='a')\n    assert any_serializer.to_json(foo) == b'{\"a\":1,\"b\":\"a\"}'\n\n    @dataclasses.dataclass\n    class Foo2(Foo):\n        pass\n\n    foo2 = Foo2(2, 'b')\n    assert any_serializer.to_python(foo2) == IsStrictDict(a=2, b='b')\n    assert any_serializer.to_json(foo2) == b'{\"a\":2,\"b\":\"b\"}'\n\n\n@pytest.mark.skipif(sys.version_info < (3, 10), reason='slots are only supported for dataclasses in Python >= 3.10')\ndef test_dataclass_slots(any_serializer):\n    @dataclasses.dataclass(slots=True)\n    class Foo:\n        a: int\n        b: str\n\n    foo = Foo(1, 'a')\n    assert any_serializer.to_python(foo) == IsStrictDict(a=1, b='a')\n    assert any_serializer.to_json(foo) == b'{\"a\":1,\"b\":\"a\"}'\n\n    @dataclasses.dataclass(slots=True)\n    class Foo2(Foo):\n        pass\n\n    foo2 = Foo2(2, 'b')\n    assert any_serializer.to_python(foo2) == IsStrictDict(a=2, b='b')\n    assert any_serializer.to_json(foo2) == b'{\"a\":2,\"b\":\"b\"}'\n\n\n@pytest.mark.skipif(sys.version_info < (3, 10), reason='slots are only supported for dataclasses in Python >= 3.10')\ndef test_dataclass_slots_init_vars(any_serializer):\n    @dataclasses.dataclass(slots=True)\n    class Foo:\n        a: int\n        b: str\n        c: dataclasses.InitVar[int]\n        d: ClassVar[int] = 42\n\n    foo = Foo(1, 'a', 42)\n    assert any_serializer.to_python(foo) == IsStrictDict(a=1, b='a')\n    assert any_serializer.to_json(foo) == b'{\"a\":1,\"b\":\"a\"}'\n\n\n@pytest.mark.skipif(sys.version_info < (3, 10), reason='slots are only supported for dataclasses in Python > 3.10')\ndef test_slots_mixed(any_serializer):\n    @dataclasses.dataclass(slots=True)\n    class Model:\n        x: int\n        y: dataclasses.InitVar[str]\n        z: ClassVar[str] = 'z-classvar'\n\n    @dataclasses.dataclass\n    class SubModel(Model):\n        x2: int\n        y2: dataclasses.InitVar[str]\n        z2: ClassVar[str] = 'z2-classvar'\n\n    dc = SubModel(x=1, y='a', x2=2, y2='b')\n    assert dataclasses.asdict(dc) == {'x': 1, 'x2': 2}\n\n    assert any_serializer.to_python(dc) == {'x': 1, 'x2': 2}\n    assert any_serializer.to_json(dc) == b'{\"x\":1,\"x2\":2}'\n\n\n@pytest.mark.skipif(numpy is None, reason='numpy is not installed')\ndef test_numpy_float(any_serializer):\n    assert any_serializer.to_python(numpy.float64(1.0)) == 1.0\n    assert any_serializer.to_python(numpy.float64(1.0), mode='json') == 1.0\n    assert any_serializer.to_json(numpy.float64(1.0)) == b'1.0'\n\n    # float16 is not a subclass of float\n    assert not isinstance(numpy.float16(1.0), float)\n    assert any_serializer.to_python(numpy.float16(1.0)) == 1.0\n    with pytest.raises(PydanticSerializationError, match=r\"Unable to serialize unknown type: <class 'numpy\\.float16'>\"):\n        any_serializer.to_python(numpy.float16(1.0), mode='json')\n    with pytest.raises(PydanticSerializationError, match=r\"Unable to serialize unknown type: <class 'numpy\\.float16'>\"):\n        any_serializer.to_json(numpy.float16(1.0))\n\n\ndef test_ser_json_inf_nan_with_any() -> None:\n    s = SchemaSerializer(core_schema.any_schema(), core_schema.CoreConfig(ser_json_inf_nan='constants'))\n    assert isinf(s.to_python(inf))\n    assert isinf(s.to_python(inf, mode='json'))\n    assert s.to_json(inf) == b'Infinity'\n    assert isnan(s.to_python(nan))\n    assert isnan(s.to_python(nan, mode='json'))\n    assert s.to_json(nan) == b'NaN'\n\n    s = SchemaSerializer(core_schema.any_schema(), core_schema.CoreConfig(ser_json_inf_nan='null'))\n    assert isinf(s.to_python(inf))\n    assert s.to_python(inf, mode='json') is None\n    assert s.to_json(inf) == b'null'\n    assert isnan(s.to_python(nan))\n    assert s.to_python(nan, mode='json') is None\n    assert s.to_json(nan) == b'null'\n\n    s = SchemaSerializer(core_schema.any_schema(), core_schema.CoreConfig(ser_json_inf_nan='strings'))\n    assert isinf(s.to_python(inf))\n    assert isinf(s.to_python(inf, mode='json'))\n    assert s.to_json(inf) == b'\"Infinity\"'\n    assert isnan(s.to_python(nan))\n    assert isnan(s.to_python(nan, mode='json'))\n    assert s.to_json(nan) == b'\"NaN\"'\n\n\ndef test_ser_json_inf_nan_with_list_of_any() -> None:\n    s = SchemaSerializer(\n        core_schema.list_schema(core_schema.any_schema()), core_schema.CoreConfig(ser_json_inf_nan='constants')\n    )\n    assert isinf(s.to_python([inf])[0])\n    assert isinf(s.to_python([inf], mode='json')[0])\n    assert s.to_json([inf]) == b'[Infinity]'\n    assert isnan(s.to_python([nan])[0])\n    assert isnan(s.to_python([nan], mode='json')[0])\n    assert s.to_json([nan]) == b'[NaN]'\n\n    s = SchemaSerializer(\n        core_schema.list_schema(core_schema.any_schema()), core_schema.CoreConfig(ser_json_inf_nan='null')\n    )\n    assert isinf(s.to_python([inf])[0])\n    assert s.to_python([inf], mode='json')[0] is None\n    assert s.to_json([inf]) == b'[null]'\n    assert isnan(s.to_python([nan])[0])\n    assert s.to_python([nan], mode='json')[0] is None\n    assert s.to_json([nan]) == b'[null]'\n", "tests/serializers/test_json.py": "from pydantic_core import SchemaSerializer, core_schema\n\n\ndef test_json_int():\n    s = SchemaSerializer(core_schema.json_schema(core_schema.int_schema()))\n\n    assert s.to_python(1) == 1\n    assert s.to_python(1, round_trip=True) == '1'\n    assert s.to_python(1, mode='json') == 1\n    assert s.to_python(1, mode='json', round_trip=True) == '1'\n    assert s.to_json(1) == b'1'\n    assert s.to_json(1, round_trip=True) == b'\"1\"'\n\n\ndef test_list_json():\n    s = SchemaSerializer(core_schema.list_schema(core_schema.json_schema()))\n\n    v = ['a', [1, 2], None]\n    assert s.to_python(v) == v\n    assert s.to_python(v, round_trip=True) == ['\"a\"', '[1,2]', 'null']\n    assert s.to_python(v, mode='json') == v\n    assert s.to_python(v, mode='json', round_trip=True) == ['\"a\"', '[1,2]', 'null']\n    assert s.to_json(v) == b'[\"a\",[1,2],null]'\n    assert s.to_json(v, round_trip=True) == b'[\"\\\\\"a\\\\\"\",\"[1,2]\",\"null\"]'\n\n\ndef test_dict_key_json():\n    s = SchemaSerializer(core_schema.dict_schema(core_schema.json_schema(), core_schema.any_schema()))\n\n    v = {(1, 2): 3, (4, 5): 9}\n    assert s.to_python(v) == v\n    assert s.to_python(v, round_trip=True) == {'[1,2]': 3, '[4,5]': 9}\n\n    assert s.to_python(v, mode='json') == {'1,2': 3, '4,5': 9}\n    assert s.to_python(v, mode='json', round_trip=True) == {'[1,2]': 3, '[4,5]': 9}\n\n    assert s.to_json(v) == b'{\"1,2\":3,\"4,5\":9}'\n    assert s.to_json(v, round_trip=True) == b'{\"[1,2]\":3,\"[4,5]\":9}'\n\n\ndef test_custom_serializer():\n    s = SchemaSerializer(core_schema.any_schema(serialization=core_schema.simple_ser_schema('json')))\n    assert s.to_python({1: 2}) == {1: 2}\n    assert s.to_python({1: 2}, mode='json') == {'1': 2}\n    assert s.to_python({1: 2}, mode='json', round_trip=True) == '{\"1\":2}'\n    assert s.to_json({1: 2}) == b'{\"1\":2}'\n    assert s.to_json({1: 2}, round_trip=True) == b'\"{\\\\\"1\\\\\":2}\"'\n", "wasm-preview/run_tests.py": "import base64\nimport importlib\nimport re\nimport sys\nimport traceback\nfrom io import BytesIO\nfrom pathlib import Path\nfrom zipfile import ZipFile\n\nimport micropip\nimport pyodide\nimport pytest\n\n# this seems to be required for me on M1 Mac\nsys.setrecursionlimit(200)\n\n\nasync def main(tests_zip: str, tag_name: str):\n    print(f'Using pyodide version: {pyodide.__version__}')\n    print(f'Extracting test files (size: {len(tests_zip):,})...')\n    # File saved on the GH release\n    pydantic_core_wheel = (\n        'https://githubproxy.samuelcolvin.workers.dev/pydantic/pydantic-core/releases/'\n        f'download/{tag_name}/pydantic_core-{tag_name.lstrip(\"v\")}-cp311-cp311-emscripten_3_1_46_wasm32.whl'\n    )\n    zip_file = ZipFile(BytesIO(base64.b64decode(tests_zip)))\n    count = 0\n    for name in zip_file.namelist():\n        if name.endswith('.py'):\n            path, subs = re.subn(r'^pydantic-core-.+?/tests/', 'tests/', name)\n            if subs:\n                count += 1\n                path = Path(path)\n                path.parent.mkdir(parents=True, exist_ok=True)\n                with zip_file.open(name, 'r') as f:\n                    path.write_bytes(f.read())\n\n    print(f'Mounted {count} test files, installing dependencies...')\n\n    await micropip.install(['dirty-equals', 'hypothesis', 'pytest-speed', 'pytest-mock', pydantic_core_wheel, 'tzdata'])\n    importlib.invalidate_caches()\n\n    # print('installed packages:')\n    # print(micropip.list())\n    print('Running tests...')\n    pytest.main()\n\n\ntry:\n    await main(tests_zip, pydantic_core_version)  # noqa: F821,F704\nexcept Exception:\n    traceback.print_exc()\n    raise\n"}