{"update.py": "import dataclasses\nimport io\nimport itertools\nimport logging\nimport os\nimport pathlib\nimport re\nimport shutil\nimport subprocess\nimport sys\nimport tarfile\nimport tempfile\nimport textwrap\nfrom collections.abc import Iterable, Iterator, Mapping, Sequence\nfrom datetime import datetime, timezone\n\nimport click\nimport parver  # type: ignore\nimport requests\n\nIANA_LATEST_LOCATION = \"https://www.iana.org/time-zones/repository/tzdata-latest.tar.gz\"\nSOURCE = \"https://data.iana.org/time-zones/releases\"\nWORKING_DIR = pathlib.Path(\"tmp\")\nREPO_ROOT = pathlib.Path(__file__).parent\nPKG_BASE = REPO_ROOT / \"src\"\nTEMPLATES_DIR = REPO_ROOT / \"templates\"\n\nSKIP_NEWS_HEADINGS = {\n    \"Changes to code\",\n    \"Changes to build procedure\",\n}\n\n\ndef download_tzdb_tarballs(\n    version: str, base_url: str = SOURCE, working_dir: pathlib.Path = WORKING_DIR\n) -> Sequence[pathlib.Path]:\n    \"\"\"Download the tzdata and tzcode tarballs.\"\"\"\n    tzdata_file = f\"tzdata{version}.tar.gz\"\n    tzcode_file = f\"tzcode{version}.tar.gz\"\n\n    target_dir = working_dir / version / \"download\"\n    # mkdir -p target_dir\n    target_dir.mkdir(parents=True, exist_ok=True)\n\n    download_locations = []\n    for filename in [tzdata_file, tzcode_file]:\n        download_location = target_dir / filename\n        download_locations.append(download_location)\n\n        if download_location.exists():\n            logging.info(\"File %s already exists, skipping\", download_location)\n            continue\n\n        url = f\"{base_url}/{filename}\"\n        logging.info(\"Downloading %s from %s\", filename, url)\n\n        r = requests.get(url)\n        with open(download_location, \"wb\") as f:\n            f.write(r.content)\n\n    return download_locations\n\n\ndef retrieve_local_tarballs(\n    version: str, source_dir: pathlib.Path, working_dir: pathlib.Path = WORKING_DIR\n) -> Sequence[pathlib.Path]:\n    \"\"\"Retrieve the tzdata and tzcode tarballs from a folder.\n\n    This is useful when building against a local, patched version of tzdb.\n    \"\"\"\n    tzdata_file = f\"tzdata{version}.tar.gz\"\n    tzcode_file = f\"tzcode{version}.tar.gz\"\n\n    target_dir = working_dir / version / \"download\"\n\n    # mkdir -p target_dir\n    target_dir.mkdir(parents=True, exist_ok=True)\n\n    dest_locations = []\n\n    for filename in [tzdata_file, tzcode_file]:\n        source_location = source_dir / filename\n        dest_location = target_dir / filename\n\n        if dest_location.exists():\n            logging.info(\"File %s exists, overwriting\", dest_location)\n\n        shutil.copy(source_location, dest_location)\n\n        dest_locations.append(dest_location)\n\n    return dest_locations\n\n\ndef unpack_tzdb_tarballs(\n    download_locations: Sequence[pathlib.Path],\n) -> pathlib.Path:\n    assert len(download_locations) == 2\n    assert download_locations[0].parent == download_locations[1].parent\n    base_dir = download_locations[0].parent.parent\n    target_dir = base_dir / \"tzdb\"\n\n    # Remove the directory and re-create it if it does not exist\n    if target_dir.exists():\n        shutil.rmtree(target_dir)\n\n    target_dir.mkdir()\n\n    for tarball in download_locations:\n        logging.info(\"Unpacking %s to %s\", tarball, target_dir)\n        subprocess.run(\n            [\"tar\", \"-xf\", os.fspath(tarball.absolute())],\n            cwd=target_dir,\n            check=True,\n        )\n\n    return target_dir\n\n\ndef load_zonefiles(\n    base_dir: pathlib.Path,\n) -> tuple[Sequence[str], pathlib.Path]:\n    target_dir = base_dir.parent / \"zoneinfo\"\n    if target_dir.exists():\n        shutil.rmtree(target_dir)\n\n    with tempfile.TemporaryDirectory() as td:\n        td_path = pathlib.Path(td)\n\n        # First run the makefile, which does all kinds of other random stuff\n        subprocess.run(\n            [\"make\", f\"DESTDIR={td}\", \"POSIXRULES=\", \"ZFLAGS=-b slim\", \"install\"],\n            cwd=base_dir,\n            check=True,\n        )\n\n        proc = subprocess.run(\n            [\"make\", \"zonenames\"], cwd=base_dir, stdout=subprocess.PIPE, check=True\n        )\n        zonenames = list(map(str.strip, proc.stdout.decode(\"utf-8\").split(\"\\n\")))\n\n        # Move the zoneinfo files into the target directory\n        src_dir = td_path / \"usr\" / \"share\" / \"zoneinfo\"\n        shutil.move(os.fspath(src_dir), os.fspath(target_dir))\n\n    return zonenames, target_dir\n\n\ndef create_package(version: str, zonenames: Sequence[str], zoneinfo_dir: pathlib.Path):\n    \"\"\"Creates the tzdata package.\"\"\"\n    # Start out at rc0\n    base_version = parver.Version.parse(translate_version(version))\n    rc_version = base_version.replace(pre_tag=\"rc\", pre=0)\n    package_version = str(rc_version)\n\n    # First remove the existing package contents\n    target_dir = PKG_BASE / \"tzdata\"\n    if target_dir.exists():\n        shutil.rmtree(target_dir)\n\n    data_dir = target_dir / \"zoneinfo\"\n\n    # Next move the zoneinfo file to the target location\n    shutil.move(os.fspath(zoneinfo_dir), data_dir)\n\n    # Generate the base __init__.py from a template\n    with open(TEMPLATES_DIR / \"__init__.py.in\", \"r\") as f_in:\n        contents = f_in.read()\n        contents = contents.replace(\"%%IANA_VERSION%%\", f'\"{version}\"')\n        contents = contents.replace(\"%%PACKAGE_VERSION%%\", f'\"{package_version}\"')\n\n        with open(target_dir / \"__init__.py\", \"w\") as f_out:\n            f_out.write(contents)\n\n    with open(REPO_ROOT / \"VERSION\", \"w\") as f:\n        f.write(package_version)\n\n    # Generate the \"zones\" file as a newline-delimited list\n    with open(target_dir / \"zones\", \"w\") as f:\n        f.write(\"\\n\".join(zonenames))\n\n    # Now recursively create __init__.py files in every directory we need to\n    for dirpath, _, filenames in os.walk(data_dir):\n        if \"__init__.py\" not in filenames:\n            init_file = pathlib.Path(dirpath) / \"__init__.py\"\n            init_file.touch()\n\n\ndef find_latest_version() -> str:\n    r = requests.get(IANA_LATEST_LOCATION)\n    fobj = io.BytesIO(r.content)\n    with tarfile.open(fileobj=fobj, mode=\"r:gz\") as tf:\n        vfile = tf.extractfile(\"version\")\n\n        assert vfile is not None, \"version file is not a regular file\"\n        version = vfile.read().decode(\"utf-8\").strip()\n\n    assert re.match(\"\\d{4}[a-z]$\", version), version\n\n    target_dir = WORKING_DIR / version / \"download\"\n    target_dir.mkdir(parents=True, exist_ok=True)\n\n    fobj.seek(0)\n    with open(target_dir / f\"tzdata{version}.tar.gz\", \"wb\") as f:\n        f.write(fobj.read())\n\n    return version\n\n\ndef translate_version(iana_version: str) -> str:\n    \"\"\"Translates from an IANA version to a PEP 440 version string.\n\n    E.g. 2020a -> 2020.1\n    \"\"\"\n\n    if (\n        len(iana_version) < 5\n        or not iana_version[0:4].isdigit()\n        or not iana_version[4:].isalpha()\n    ):\n        raise ValueError(\n            \"IANA version string must be of the format YYYYx where YYYY represents the \"\n            f\"year and x is in [a-z], found: {iana_version}\"\n        )\n\n    version_year = iana_version[0:4]\n    patch_letters = iana_version[4:]\n\n    # From tz-link.html:\n    #\n    # Since 1996, each version has been a four-digit year followed by\n    # lower-case letter (a through z, then za through zz, then zza through zzz,\n    # and so on).\n    if len(patch_letters) > 1 and not all(c == \"z\" for c in patch_letters[0:-1]):\n        raise ValueError(\n            f\"Invalid IANA version number (only the last character may be a letter \"\n            f\"other than z), found: {iana_version}\"\n        )\n\n    final_patch_number = ord(patch_letters[-1]) - ord(\"a\") + 1\n    patch_number = (26 * (len(patch_letters) - 1)) + final_patch_number\n\n    return f\"{version_year}.{patch_number:d}\"\n\n\n##\n# News entry handling\n@dataclasses.dataclass\nclass NewsEntry:\n    version: str\n    release_date: datetime\n    categories: Mapping[str, str]\n\n    def to_file(self) -> None:\n        fpath = pathlib.Path(\"news.d\") / (self.version + \".md\")\n        release_date = self.release_date.astimezone(timezone.utc)\n        translated_version = translate_version(self.version)\n\n        contents = [f\"# Version {translated_version}\"]\n        contents.append(\n            f\"Upstream version {self.version} released {release_date.isoformat()}\"\n        )\n        contents.append(\"\")\n\n        for category, entry in self.categories.items():\n            contents.append(f\"## {category}\")\n            contents.append(\"\")\n            contents.append(entry)\n            contents.append(\"\")\n\n        with open(fpath, \"wt\") as f:\n            f.write((\"\\n\".join(contents)).strip())\n\n\nINDENT_RE = re.compile(\"[^ ]\")\n\n\ndef get_indent(s: str) -> int:\n    s = s.rstrip()\n    if not s:\n        return 0\n\n    m = INDENT_RE.search(s)\n    assert m is not None\n    return m.span()[0]\n\n\ndef read_block(\n    lines: Iterator[str],\n) -> tuple[Sequence[str], Iterator[str]]:\n    lines, peek = itertools.tee(lines)\n    while not (first_line := next(peek)):\n        next(lines)\n\n    block_indent = get_indent(first_line)\n    block = []\n\n    # The way this loop works: `peek` is always one line ahead of `lines`. It\n    # starts out where `lines` is pointing to the first non-empty line, and\n    # peek is the line after that. We know that if the body of the loop is\n    # reached, the next value in `lines` is part of the block.\n    #\n    # It is done this way so that we can return an iterable pointing at the\n    # first line *after* the block that we just read.\n    for line in peek:\n        block.append(next(lines))\n\n        if not line:\n            block.append(line)\n            continue\n\n        line_indent = get_indent(line)\n        if line_indent < block_indent:\n            # We've dedented, so this is the end of the block.\n            break\n    else:\n        # If we've exhausted `peek` because we're reading the last block in the\n        # file, we won't hit the `break` condition, but we'll still have a\n        # valid line in the `lines` queue.\n        block.append(next(lines))\n\n    return block, lines\n\n\ndef parse_categories(news_block: Sequence[str]) -> Mapping[str, str]:\n    blocks = iter(news_block)\n\n    output = {}\n    while True:\n        try:\n            while not (heading := next(blocks)):\n                pass\n        except StopIteration:\n            break\n\n        content_lines, blocks = read_block(blocks)\n\n        heading = heading.strip()\n        if heading in SKIP_NEWS_HEADINGS:\n            continue\n\n        # Merge the contents into paragraphs by grouping into consecutive blocks\n        # of non-empty lines, then joining those lines on a newline.\n        content_paragraphs: Iterable[str] = (\n            \"\\n\".join(paragraph)\n            for _, paragraph in itertools.groupby(content_lines, key=bool)\n        )\n\n        # Now dedent each paragraph and wrap it to 80 characters. This needs to\n        # be done at the per-paragraph level, because `textwrap.wrap` doesn't\n        # recognize paragraph breaks.\n        content_paragraphs = map(textwrap.dedent, content_paragraphs)\n        content_paragraphs = map(\n            \"\\n\".join,\n            (textwrap.wrap(paragraph, width=80) for paragraph in content_paragraphs),\n        )\n\n        # Finally we can join the paragraphs into a single string and trim\n        # whitespace from it\n        contents = \"\\n\".join(content_paragraphs)\n        contents = contents.strip()\n\n        output[heading] = contents\n\n    return output\n\n\ndef read_news(tzdb_loc: pathlib.Path, version: str | None = None) -> NewsEntry:\n    release_re = re.compile(\"^Release (?P<version>\\d{4}[a-z]) - (?P<date>.*$)\")\n    with open(tzdb_loc / \"NEWS\", \"rt\") as f:\n        f_lines = map(str.rstrip, f)\n        for line in f_lines:\n            if ((m := release_re.match(line)) is not None) and (\n                version is None or m.group(\"version\") == version\n            ):\n                break\n        else:\n            if version is None:\n                message = \"No releases found!\"\n            else:\n                message = f\"No release found with version {version}\"\n\n        assert m is not None\n        version_date = datetime.strptime(m.group(\"date\"), \"%Y-%m-%d %H:%M:%S %z\")\n        release_version = m.group(\"version\")\n        release_contents, _ = read_block(f_lines)\n\n    # Now we further parse the contents of the news and filter out some\n    # irrelevant categories.\n    categories = parse_categories(release_contents)\n\n    return NewsEntry(release_version, version_date, categories)\n\n\ndef update_news(news_entry: NewsEntry):\n    # news.d contains fragments for each tzdata version, and the NEWS file\n    # is assembled by stitching these together each time. First thing we'll do\n    # is add a new fragment.\n    news_entry.to_file()\n\n    # Now go through and join all the files together\n    news_fragment_files = sorted(\n        pathlib.Path(\"news.d\").glob(\"*.md\"), key=lambda p: p.name, reverse=True\n    )\n\n    news_fragments = [p.read_text() for p in news_fragment_files]\n\n    with open(\"NEWS.md\", \"wt\") as f:\n        f.write(\"\\n\\n---\\n\\n\".join(news_fragments))\n\n\n@click.command()\n@click.option(\n    \"--version\", \"-v\", default=None, help=\"The version of the tzdata file to download\"\n)\n@click.option(\n    \"--source-dir\",\n    \"-s\",\n    default=None,\n    help=\"A local source directory containing tarballs (must be used together with --version)\",\n    type=click.Path(\n        exists=True, file_okay=False, dir_okay=True, path_type=pathlib.Path\n    ),  # type: ignore\n)\n@click.option(\n    \"--news-only/--no-news-only\",\n    help=\"Flag to disable data updates and only update the news entry\",\n)\ndef main(\n    version: str | None,\n    news_only: bool,\n    source_dir: pathlib.Path | None,\n):\n    logging.basicConfig(level=logging.INFO)\n\n    if source_dir is not None:\n        if version is None:\n            logging.error(\n                \"--source-dir specified without --version: \"\n                \"If using --source-dir, --version must also be used.\"\n            )\n            sys.exit(-1)\n        download_locations = retrieve_local_tarballs(version, source_dir)\n    else:\n        if version is None:\n            version = find_latest_version()\n\n        download_locations = download_tzdb_tarballs(version)\n\n    tzdb_location = unpack_tzdb_tarballs(download_locations)\n\n    # Update the news entry\n    news_entry = read_news(tzdb_location, version=version)\n    update_news(news_entry)\n\n    if not news_only:\n        zonenames, zonefile_path = load_zonefiles(tzdb_location)\n        create_package(version, zonenames, zonefile_path)\n\n\nif __name__ == \"__main__\":\n    main()\n", "bump_version.py": "import argparse\nimport io\nimport pathlib\n\nimport parver  # type: ignore\n\nREPO_ROOT = pathlib.Path(__file__).parent\nVERSION = REPO_ROOT / pathlib.Path(\"VERSION\")\n\n\ndef get_current_version() -> parver.Version:\n    with open(VERSION, \"rt\") as f:\n        return parver.Version.parse(f.read().strip())\n\n\ndef write_version(version: parver.Version):\n    with open(VERSION, \"wt\") as f:\n        f.write(str(version))\n\n\ndef update_package_version(version: parver.Version):\n    new_init = io.StringIO()\n    version_set = False\n    init = REPO_ROOT / \"src\" / \"tzdata\" / \"__init__.py\"\n    with open(init, \"rt\") as f:\n        for line in f:\n            if not version_set and line.startswith(\"__version__\"):\n                line = f'__version__ = \"{version}\"\\n'\n                version_set = True\n            new_init.write(line)\n\n    if not version_set:\n        raise ValueError(\"Version not found in __init__.py!\")\n\n    new_init.seek(0)\n\n    with open(init, \"wt\") as f:\n        f.write(new_init.read())\n\n\ndef bump_version(version: parver.Version, args) -> parver.Version:\n    if args.release:\n        return version.base_version()\n\n    if args.dev:\n        if args.to is not None:\n            return version.replace(dev=args.to)\n        else:\n            return version.bump_dev()\n\n    version = version.replace(dev=None)\n\n    if args.post:\n        if args.to is not None:\n            return version.replace(post=args.to)\n        else:\n            return version.bump_post()\n\n    if args.rc:\n        if version.is_postrelease:\n            version = version.replace(post=None)\n\n        if args.to is not None:\n            return version.replace(pre_tag=\"rc\", pre=args.to)\n        else:\n            return version.bump_pre(\"rc\")\n\n    return version\n\n\ndef main(args):\n    original_version = get_current_version()\n    bumped_version = bump_version(original_version, args)\n\n    print(f\"{original_version} \u2192 {bumped_version}\")\n    if not args.dry_run:\n        write_version(bumped_version)\n        update_package_version(bumped_version)\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Manipulate the package version\")\n\n    group = parser.add_mutually_exclusive_group(required=True)\n\n    group.add_argument(\"--rc\", action=\"store_true\", help=\"Bump the release candidate\")\n    group.add_argument(\"--dev\", action=\"store_true\", help=\"Bump the dev version\")\n    group.add_argument(\n        \"--release\",\n        action=\"store_true\",\n        help=\"Bump from release candidate / dev to release\",\n    )\n    group.add_argument(\n        \"--post\", action=\"store_true\", help=\"Bump the post release version\"\n    )\n    parser.add_argument(\n        \"--to\",\n        type=int,\n        default=None,\n        help=\"Set the specified component to a specific number\",\n    )\n    parser.add_argument(\n        \"--dry-run\",\n        action=\"store_true\",\n        help=\"Preview what the new version will be without writing any files.\",\n    )\n\n    args = parser.parse_args()\n\n    if args.to is not None and args.release:\n        raise ValueError(\"Cannot combine --to and --release\")\n\n    main(args)\n", "docs/conf.py": "# Configuration file for the Sphinx documentation builder.\n#\n# This file only contains a selection of the most common options. For a full\n# list see the documentation:\n# https://www.sphinx-doc.org/en/master/usage/configuration.html\n\nimport sphinx_bootstrap_theme\n\nimport tzdata\n\n# -- Project information -----------------------------------------------------\n\nproject = \"tzdata\"\ncopyright = \"2020, Python Software Foundation\"\nauthor = \"Python Software Foundation\"\nversion = tzdata.__version__\n\n\n# -- General configuration ---------------------------------------------------\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom\n# ones.\nextensions = [\"sphinx.ext.intersphinx\"]\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\"_templates\"]\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This pattern also affects html_static_path and html_extra_path.\nexclude_patterns = [\"_build\", \"Thumbs.db\", \".DS_Store\"]\n\n\n# -- Options for HTML output -------------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\nhtml_theme = \"bootstrap\"\nhtml_theme_path = sphinx_bootstrap_theme.get_html_theme_path()\nhtml_theme_options = {\n    \"bootswatch_theme\": \"cosmo\",\n}\n\n# For cross-links to other documentation\nintersphinx_mapping = {\n    \"python\": (\"https://docs.python.org/3\", None),\n    \"dateutil\": (\"https://dateutil.readthedocs.io/en/stable/\", None),\n}\n", "tests/test_version.py": "import os\n\nimport tzdata\n\nREPO_ROOT = os.path.split(os.path.split(__file__)[0])[0]\nVERSION_FILE = os.path.join(REPO_ROOT, \"VERSION\")\n\n\ndef test_version():\n    with open(VERSION_FILE, \"rt\") as f:\n        version_from_file = f.read()\n\n    assert version_from_file == tzdata.__version__\n", "tests/test_contents.py": "import sys\n\nimport pytest\n\ntry:\n    from importlib import resources\nexcept ImportError:\n    import importlib_resources as resources\n\n\nif sys.version_info < (3, 6):\n    # pytest-subtests does not support Python < 3.6, but having the tests\n    # separated into clean subtests is nice but not required, so we will create\n    # a stub that does nothing but at least doesn't fail for lack of a fixture.\n    import contextlib\n\n    class _SubTestStub:\n        @contextlib.contextmanager\n        def test(self, **kwargs):\n            yield\n\n    _sub_test_stub = _SubTestStub()\n\n    @pytest.fixture\n    def subtests():\n        yield _sub_test_stub\n\n\ndef get_magic(zone_name):\n    components = zone_name.split(\"/\")\n    package_name = \".\".join([\"tzdata.zoneinfo\"] + components[:-1])\n    resource_name = components[-1]\n\n    with resources.open_binary(package_name, resource_name) as f:\n        return f.read(4)\n\n\n@pytest.mark.parametrize(\n    \"zone_name\",\n    [\n        \"Africa/Cairo\",\n        \"Africa/Casablanca\",\n        \"Africa/Lome\",\n        \"America/Argentina/San_Luis\",\n        \"America/Denver\",\n        \"America/Los_Angeles\",\n        \"America/New_York\",\n        \"America/Thunder_Bay\",\n        \"Antarctica/South_Pole\",\n        \"Asia/Calcutta\",\n        \"Asia/Damascus\",\n        \"Asia/Seoul\",\n        \"Atlantic/Reykjavik\",\n        \"Australia/Perth\",\n        \"Egypt\",\n        \"Etc/GMT-9\",\n        \"Europe/Dublin\",\n        \"Europe/London\",\n        \"Europe/Prague\",\n        \"Hongkong\",\n        \"Indian/Cocos\",\n        \"Indian/Mayotte\",\n        \"Mexico/BajaNorte\",\n        \"Pacific/Guam\",\n        \"Pacific/Kiritimati\",\n        \"US/Eastern\",\n        \"UTC\",\n    ],\n)\ndef test_zone_valid(zone_name):\n    \"\"\"Test an assortment of hard-coded zone names.\n\n    This test checks that the zone resource can be loaded and that it starts\n    with the 4-byte magic indicating a TZif file.\n    \"\"\"\n    magic = get_magic(zone_name)\n    assert magic == b\"TZif\"\n\n\ndef test_no_posixrules():\n    assert not resources.is_resource(\"tzdata.zoneinfo\", \"posixrules\")\n\n\ndef test_load_zones(subtests):\n    with resources.open_text(\"tzdata\", \"zones\") as f:\n        zones = [z.strip() for z in f]\n\n    for zone in zones:\n        with subtests.test(zone=zone):\n            magic = get_magic(zone)\n            assert magic == b\"TZif\"\n", "src/tzdata/__init__.py": "# IANA versions like 2020a are not valid PEP 440 identifiers; the recommended\n# way to translate the version is to use YYYY.n where `n` is a 0-based index.\n__version__ = \"2024.1\"\n\n# This exposes the original IANA version number.\nIANA_VERSION = \"2024a\"\n", "src/tzdata/zoneinfo/__init__.py": "", "src/tzdata/zoneinfo/Antarctica/__init__.py": "", "src/tzdata/zoneinfo/Arctic/__init__.py": "", "src/tzdata/zoneinfo/Pacific/__init__.py": "", "src/tzdata/zoneinfo/US/__init__.py": "", "src/tzdata/zoneinfo/Atlantic/__init__.py": "", "src/tzdata/zoneinfo/Africa/__init__.py": "", "src/tzdata/zoneinfo/Australia/__init__.py": "", "src/tzdata/zoneinfo/Asia/__init__.py": "", "src/tzdata/zoneinfo/Mexico/__init__.py": "", "src/tzdata/zoneinfo/Brazil/__init__.py": "", "src/tzdata/zoneinfo/Canada/__init__.py": "", "src/tzdata/zoneinfo/Etc/__init__.py": "", "src/tzdata/zoneinfo/Indian/__init__.py": "", "src/tzdata/zoneinfo/America/__init__.py": "", "src/tzdata/zoneinfo/America/Argentina/__init__.py": "", "src/tzdata/zoneinfo/America/Indiana/__init__.py": "", "src/tzdata/zoneinfo/America/North_Dakota/__init__.py": "", "src/tzdata/zoneinfo/America/Kentucky/__init__.py": "", "src/tzdata/zoneinfo/Chile/__init__.py": "", "src/tzdata/zoneinfo/Europe/__init__.py": ""}