{"noxfile.py": "# Copyright 2016 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import absolute_import\nimport os\nimport pathlib\nimport re\nimport shutil\nimport unittest\n\n# https://github.com/google/importlab/issues/25\nimport nox  # pytype: disable=import-error\n\n\nBLACK_VERSION = \"black==22.3.0\"\nBLACK_PATHS = [\"docs\", \"google\", \"tests\", \"noxfile.py\", \"setup.py\"]\n# Black and flake8 clash on the syntax for ignoring flake8's F401 in this file.\nBLACK_EXCLUDES = [\"--exclude\", \"^/google/api_core/operations_v1/__init__.py\"]\n\nPYTHON_VERSIONS = [\"3.7\", \"3.8\", \"3.9\", \"3.10\", \"3.11\", \"3.12\"]\n\nDEFAULT_PYTHON_VERSION = \"3.10\"\nCURRENT_DIRECTORY = pathlib.Path(__file__).parent.absolute()\n\n# 'docfx' is excluded since it only needs to run in 'docs-presubmit'\nnox.options.sessions = [\n    \"unit\",\n    \"unit_grpc_gcp\",\n    \"unit_wo_grpc\",\n    \"cover\",\n    \"pytype\",\n    \"mypy\",\n    \"lint\",\n    \"lint_setup_py\",\n    \"blacken\",\n    \"docs\",\n]\n\n\n@nox.session(python=DEFAULT_PYTHON_VERSION)\ndef lint(session):\n    \"\"\"Run linters.\n\n    Returns a failure if the linters find linting errors or sufficiently\n    serious code quality issues.\n    \"\"\"\n    session.install(\"flake8\", BLACK_VERSION)\n    session.install(\".\")\n    session.run(\n        \"black\",\n        \"--check\",\n        *BLACK_EXCLUDES,\n        *BLACK_PATHS,\n    )\n    session.run(\"flake8\", \"google\", \"tests\")\n\n\n@nox.session(python=DEFAULT_PYTHON_VERSION)\ndef blacken(session):\n    \"\"\"Run black.\n\n    Format code to uniform standard.\n    \"\"\"\n    session.install(BLACK_VERSION)\n    session.run(\"black\", *BLACK_EXCLUDES, *BLACK_PATHS)\n\n\ndef install_prerelease_dependencies(session, constraints_path):\n    with open(constraints_path, encoding=\"utf-8\") as constraints_file:\n        constraints_text = constraints_file.read()\n        # Ignore leading whitespace and comment lines.\n        constraints_deps = [\n            match.group(1)\n            for match in re.finditer(\n                r\"^\\s*(\\S+)(?===\\S+)\", constraints_text, flags=re.MULTILINE\n            )\n        ]\n        session.install(*constraints_deps)\n        prerel_deps = [\n            \"google-auth\",\n            \"googleapis-common-protos\",\n            \"grpcio\",\n            \"grpcio-status\",\n            \"proto-plus\",\n            \"protobuf\",\n        ]\n\n        for dep in prerel_deps:\n            session.install(\"--pre\", \"--no-deps\", \"--upgrade\", dep)\n\n        # Remaining dependencies\n        other_deps = [\n            \"requests\",\n        ]\n        session.install(*other_deps)\n\n\ndef default(session, install_grpc=True, prerelease=False):\n    \"\"\"Default unit test session.\n\n    This is intended to be run **without** an interpreter set, so\n    that the current ``python`` (on the ``PATH``) or the version of\n    Python corresponding to the ``nox`` binary the ``PATH`` can\n    run the tests.\n    \"\"\"\n    if prerelease and not install_grpc:\n        unittest.skip(\"The pre-release session cannot be run without grpc\")\n\n    session.install(\n        \"dataclasses\",\n        \"mock\",\n        \"pytest\",\n        \"pytest-cov\",\n        \"pytest-xdist\",\n    )\n\n    constraints_dir = str(CURRENT_DIRECTORY / \"testing\")\n\n    if prerelease:\n        install_prerelease_dependencies(\n            session, f\"{constraints_dir}/constraints-{PYTHON_VERSIONS[0]}.txt\"\n        )\n        # This *must* be the last install command to get the package from source.\n        session.install(\"-e\", \".\", \"--no-deps\")\n    else:\n        session.install(\n            \"-e\",\n            \".[grpc]\" if install_grpc else \".\",\n            \"-c\",\n            f\"{constraints_dir}/constraints-{session.python}.txt\",\n        )\n\n    # Print out package versions of dependencies\n    session.run(\n        \"python\", \"-c\", \"import google.protobuf; print(google.protobuf.__version__)\"\n    )\n    # Support for proto.version was added in v1.23.0\n    # https://github.com/googleapis/proto-plus-python/releases/tag/v1.23.0\n    session.run(\n        \"python\",\n        \"-c\",\n        \"\"\"import proto; hasattr(proto, \"version\") and print(proto.version.__version__)\"\"\",\n    )\n    if install_grpc:\n        session.run(\"python\", \"-c\", \"import grpc; print(grpc.__version__)\")\n    session.run(\"python\", \"-c\", \"import google.auth; print(google.auth.__version__)\")\n\n    pytest_args = [\n        \"python\",\n        \"-m\",\n        \"pytest\",\n        *(\n            # Helpful for running a single test or testfile.\n            session.posargs\n            or [\n                \"--quiet\",\n                \"--cov=google.api_core\",\n                \"--cov=tests.unit\",\n                \"--cov-append\",\n                \"--cov-config=.coveragerc\",\n                \"--cov-report=\",\n                \"--cov-fail-under=0\",\n                # Running individual tests with parallelism enabled is usually not helpful.\n                \"-n=auto\",\n                os.path.join(\"tests\", \"unit\"),\n            ]\n        ),\n    ]\n\n    session.install(\"asyncmock\", \"pytest-asyncio\")\n\n    # Having positional arguments means the user wants to run specific tests.\n    # Best not to add additional tests to that list.\n    if not session.posargs:\n        pytest_args.append(\"--cov=tests.asyncio\")\n        pytest_args.append(os.path.join(\"tests\", \"asyncio\"))\n\n    session.run(*pytest_args)\n\n\n@nox.session(python=PYTHON_VERSIONS)\ndef unit(session):\n    \"\"\"Run the unit test suite.\"\"\"\n    default(session)\n\n\n@nox.session(python=PYTHON_VERSIONS)\ndef unit_with_prerelease_deps(session):\n    \"\"\"Run the unit test suite.\"\"\"\n    default(session, prerelease=True)\n\n\n@nox.session(python=PYTHON_VERSIONS)\ndef unit_grpc_gcp(session):\n    \"\"\"\n    Run the unit test suite with grpcio-gcp installed.\n    `grpcio-gcp` doesn't support protobuf 4+.\n    Remove extra `grpcgcp` when protobuf 3.x is dropped.\n    https://github.com/googleapis/python-api-core/issues/594\n    \"\"\"\n    constraints_path = str(\n        CURRENT_DIRECTORY / \"testing\" / f\"constraints-{session.python}.txt\"\n    )\n    # Install grpcio-gcp\n    session.install(\"-e\", \".[grpcgcp]\", \"-c\", constraints_path)\n    # Install protobuf < 4.0.0\n    session.install(\"protobuf<4.0.0\")\n\n    default(session)\n\n\n@nox.session(python=PYTHON_VERSIONS)\ndef unit_wo_grpc(session):\n    \"\"\"Run the unit test suite w/o grpcio installed\"\"\"\n    default(session, install_grpc=False)\n\n\n@nox.session(python=DEFAULT_PYTHON_VERSION)\ndef lint_setup_py(session):\n    \"\"\"Verify that setup.py is valid (including RST check).\"\"\"\n\n    session.install(\"docutils\", \"Pygments\")\n    session.run(\"python\", \"setup.py\", \"check\", \"--restructuredtext\", \"--strict\")\n\n\n@nox.session(python=DEFAULT_PYTHON_VERSION)\ndef pytype(session):\n    \"\"\"Run type-checking.\"\"\"\n    session.install(\".[grpc]\", \"pytype\")\n    session.run(\"pytype\")\n\n\n@nox.session(python=DEFAULT_PYTHON_VERSION)\ndef mypy(session):\n    \"\"\"Run type-checking.\"\"\"\n    session.install(\".[grpc]\", \"mypy\")\n    session.install(\n        \"types-setuptools\",\n        \"types-requests\",\n        \"types-protobuf\",\n        \"types-mock\",\n        \"types-dataclasses\",\n    )\n    session.run(\"mypy\", \"google\", \"tests\")\n\n\n@nox.session(python=DEFAULT_PYTHON_VERSION)\ndef cover(session):\n    \"\"\"Run the final coverage report.\n\n    This outputs the coverage report aggregating coverage from the unit\n    test runs (not system test runs), and then erases coverage data.\n    \"\"\"\n    session.install(\"coverage\", \"pytest-cov\")\n    session.run(\"coverage\", \"report\", \"--show-missing\", \"--fail-under=100\")\n    session.run(\"coverage\", \"erase\")\n\n\n@nox.session(python=\"3.9\")\ndef docs(session):\n    \"\"\"Build the docs for this library.\"\"\"\n\n    session.install(\"-e\", \".[grpc]\")\n    session.install(\n        # We need to pin to specific versions of the `sphinxcontrib-*` packages\n        # which still support sphinx 4.x.\n        # See https://github.com/googleapis/sphinx-docfx-yaml/issues/344\n        # and https://github.com/googleapis/sphinx-docfx-yaml/issues/345.\n        \"sphinxcontrib-applehelp==1.0.4\",\n        \"sphinxcontrib-devhelp==1.0.2\",\n        \"sphinxcontrib-htmlhelp==2.0.1\",\n        \"sphinxcontrib-qthelp==1.0.3\",\n        \"sphinxcontrib-serializinghtml==1.1.5\",\n        \"sphinx==4.5.0\",\n        \"alabaster\",\n        \"recommonmark\",\n    )\n\n    shutil.rmtree(os.path.join(\"docs\", \"_build\"), ignore_errors=True)\n    session.run(\n        \"sphinx-build\",\n        \"-W\",  # warnings as errors\n        \"-T\",  # show full traceback on exception\n        \"-N\",  # no colors\n        \"-b\",\n        \"html\",\n        \"-d\",\n        os.path.join(\"docs\", \"_build\", \"doctrees\", \"\"),\n        os.path.join(\"docs\", \"\"),\n        os.path.join(\"docs\", \"_build\", \"html\", \"\"),\n    )\n\n\n@nox.session(python=\"3.10\")\ndef docfx(session):\n    \"\"\"Build the docfx yaml files for this library.\"\"\"\n\n    session.install(\"-e\", \".\")\n    session.install(\n        # We need to pin to specific versions of the `sphinxcontrib-*` packages\n        # which still support sphinx 4.x.\n        # See https://github.com/googleapis/sphinx-docfx-yaml/issues/344\n        # and https://github.com/googleapis/sphinx-docfx-yaml/issues/345.\n        \"sphinxcontrib-applehelp==1.0.4\",\n        \"sphinxcontrib-devhelp==1.0.2\",\n        \"sphinxcontrib-htmlhelp==2.0.1\",\n        \"sphinxcontrib-qthelp==1.0.3\",\n        \"sphinxcontrib-serializinghtml==1.1.5\",\n        \"gcp-sphinx-docfx-yaml\",\n        \"alabaster\",\n        \"recommonmark\",\n    )\n\n    shutil.rmtree(os.path.join(\"docs\", \"_build\"), ignore_errors=True)\n    session.run(\n        \"sphinx-build\",\n        \"-T\",  # show full traceback on exception\n        \"-N\",  # no colors\n        \"-D\",\n        (\n            \"extensions=sphinx.ext.autodoc,\"\n            \"sphinx.ext.autosummary,\"\n            \"docfx_yaml.extension,\"\n            \"sphinx.ext.intersphinx,\"\n            \"sphinx.ext.coverage,\"\n            \"sphinx.ext.napoleon,\"\n            \"sphinx.ext.todo,\"\n            \"sphinx.ext.viewcode,\"\n            \"recommonmark\"\n        ),\n        \"-b\",\n        \"html\",\n        \"-d\",\n        os.path.join(\"docs\", \"_build\", \"doctrees\", \"\"),\n        os.path.join(\"docs\", \"\"),\n        os.path.join(\"docs\", \"_build\", \"html\", \"\"),\n    )\n", "setup.py": "# Copyright 2018 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport io\nimport os\n\nimport setuptools\n\n\n# Package metadata.\n\nname = \"google-api-core\"\ndescription = \"Google API client core library\"\n\n# Should be one of:\n# 'Development Status :: 3 - Alpha'\n# 'Development Status :: 4 - Beta'\n# 'Development Status :: 5 - Production/Stable'\nrelease_status = \"Development Status :: 5 - Production/Stable\"\ndependencies = [\n    \"googleapis-common-protos >= 1.56.2, < 2.0.dev0\",\n    \"protobuf>=3.19.5,<6.0.0.dev0,!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5\",\n    \"proto-plus >= 1.22.3, <2.0.0dev\",\n    \"google-auth >= 2.14.1, < 3.0.dev0\",\n    \"requests >= 2.18.0, < 3.0.0.dev0\",\n]\nextras = {\n    \"grpc\": [\n        \"grpcio >= 1.33.2, < 2.0dev\",\n        \"grpcio >= 1.49.1, < 2.0dev; python_version>='3.11'\",\n        \"grpcio-status >= 1.33.2, < 2.0.dev0\",\n        \"grpcio-status >= 1.49.1, < 2.0.dev0; python_version>='3.11'\",\n    ],\n    \"grpcgcp\": \"grpcio-gcp >= 0.2.2, < 1.0.dev0\",\n    \"grpcio-gcp\": \"grpcio-gcp >= 0.2.2, < 1.0.dev0\",\n}\n\n\n# Setup boilerplate below this line.\n\npackage_root = os.path.abspath(os.path.dirname(__file__))\n\n\nversion = {}\nwith open(os.path.join(package_root, \"google/api_core/version.py\")) as fp:\n    exec(fp.read(), version)\nversion = version[\"__version__\"]\n\nreadme_filename = os.path.join(package_root, \"README.rst\")\nwith io.open(readme_filename, encoding=\"utf-8\") as readme_file:\n    readme = readme_file.read()\n\n# Only include packages under the 'google' namespace. Do not include tests,\n# benchmarks, etc.\npackages = [\n    package\n    for package in setuptools.find_namespace_packages()\n    if package.startswith(\"google\")\n]\n\nsetuptools.setup(\n    name=name,\n    version=version,\n    description=description,\n    long_description=readme,\n    author=\"Google LLC\",\n    author_email=\"googleapis-packages@google.com\",\n    license=\"Apache 2.0\",\n    url=\"https://github.com/googleapis/python-api-core\",\n    classifiers=[\n        release_status,\n        \"Intended Audience :: Developers\",\n        \"License :: OSI Approved :: Apache Software License\",\n        \"Programming Language :: Python\",\n        \"Programming Language :: Python :: 3\",\n        \"Programming Language :: Python :: 3.7\",\n        \"Programming Language :: Python :: 3.8\",\n        \"Programming Language :: Python :: 3.9\",\n        \"Programming Language :: Python :: 3.10\",\n        \"Programming Language :: Python :: 3.11\",\n        \"Programming Language :: Python :: 3.12\",\n        \"Operating System :: OS Independent\",\n        \"Topic :: Internet\",\n    ],\n    platforms=\"Posix; MacOS X; Windows\",\n    packages=packages,\n    install_requires=dependencies,\n    extras_require=extras,\n    python_requires=\">=3.7\",\n    include_package_data=True,\n    zip_safe=False,\n)\n", "owlbot.py": "# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"This script is used to synthesize generated parts of this library.\"\"\"\n\nimport synthtool as s\nfrom synthtool import gcp\nfrom synthtool.languages import python\n\ncommon = gcp.CommonTemplates()\n\n# ----------------------------------------------------------------------------\n# Add templated files\n# ----------------------------------------------------------------------------\nexcludes = [\n    \"noxfile.py\",  # pytype\n    \"setup.cfg\",  # pytype\n    \".flake8\",  # flake8-import-order, layout\n    \".coveragerc\",  # layout\n    \"CONTRIBUTING.rst\",  # no systests\n    \".github/workflows/unittest.yml\",  # exclude unittest gh action\n    \".github/workflows/lint.yml\",  # exclude lint gh action\n    \"README.rst\",\n]\ntemplated_files = common.py_library(microgenerator=True, cov_level=100)\ns.move(templated_files, excludes=excludes)\n\n# Add pytype support\ns.replace(\n    \".gitignore\",\n    \"\"\"\\\n.pytest_cache\n\"\"\",\n    \"\"\"\\\n.pytest_cache\n.pytype\n\"\"\",\n)\n\npython.configure_previous_major_version_branches()\n\ns.shell.run([\"nox\", \"-s\", \"blacken\"], hide_output=False)\n", "scripts/readme-gen/readme_gen.py": "#!/usr/bin/env python\n\n# Copyright 2023 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Generates READMEs using configuration defined in yaml.\"\"\"\n\nimport argparse\nimport io\nimport os\nimport subprocess\n\nimport jinja2\nimport yaml\n\n\njinja_env = jinja2.Environment(\n    trim_blocks=True,\n    loader=jinja2.FileSystemLoader(\n        os.path.abspath(os.path.join(os.path.dirname(__file__), \"templates\"))\n    ),\n    autoescape=True,\n)\n\nREADME_TMPL = jinja_env.get_template(\"README.tmpl.rst\")\n\n\ndef get_help(file):\n    return subprocess.check_output([\"python\", file, \"--help\"]).decode()\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"source\")\n    parser.add_argument(\"--destination\", default=\"README.rst\")\n\n    args = parser.parse_args()\n\n    source = os.path.abspath(args.source)\n    root = os.path.dirname(source)\n    destination = os.path.join(root, args.destination)\n\n    jinja_env.globals[\"get_help\"] = get_help\n\n    with io.open(source, \"r\") as f:\n        config = yaml.load(f)\n\n    # This allows get_help to execute in the right directory.\n    os.chdir(root)\n\n    output = README_TMPL.render(config)\n\n    with io.open(destination, \"w\") as f:\n        f.write(output)\n\n\nif __name__ == \"__main__\":\n    main()\n", "docs/conf.py": "# -*- coding: utf-8 -*-\n# Copyright 2023 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# google-api-core documentation build configuration file\n#\n# This file is execfile()d with the current directory set to its\n# containing dir.\n#\n# Note that not all possible configuration values are present in this\n# autogenerated file.\n#\n# All configuration values have a default; values that are commented out\n# serve to show the default.\n\nimport sys\nimport os\nimport shlex\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\nsys.path.insert(0, os.path.abspath(\"..\"))\n\n# For plugins that can not read conf.py.\n# See also: https://github.com/docascode/sphinx-docfx-yaml/issues/85\nsys.path.insert(0, os.path.abspath(\".\"))\n\n__version__ = \"\"\n\n# -- General configuration ------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\nneeds_sphinx = \"1.5.5\"\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom\n# ones.\nextensions = [\n    \"sphinx.ext.autodoc\",\n    \"sphinx.ext.autosummary\",\n    \"sphinx.ext.intersphinx\",\n    \"sphinx.ext.coverage\",\n    \"sphinx.ext.doctest\",\n    \"sphinx.ext.napoleon\",\n    \"sphinx.ext.todo\",\n    \"sphinx.ext.viewcode\",\n    \"recommonmark\",\n]\n\n# autodoc/autosummary flags\nautoclass_content = \"both\"\nautodoc_default_options = {\"members\": True}\nautosummary_generate = True\n\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\"_templates\"]\n\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n# source_suffix = ['.rst', '.md']\nsource_suffix = [\".rst\", \".md\"]\n\n# The encoding of source files.\n# source_encoding = 'utf-8-sig'\n\n# The root toctree document.\nroot_doc = \"index\"\n\n# General information about the project.\nproject = \"google-api-core\"\ncopyright = \"2019, Google\"\nauthor = \"Google APIs\"\n\n# The version info for the project you're documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.\n#\n# The full version, including alpha/beta/rc tags.\nrelease = __version__\n# The short X.Y version.\nversion = \".\".join(release.split(\".\")[0:2])\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set \"language\" from the command line for these cases.\nlanguage = None\n\n# There are two options for replacing |today|: either, you set today to some\n# non-false value, then it is used:\n# today = ''\n# Else, today_fmt is used as the format for a strftime call.\n# today_fmt = '%B %d, %Y'\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\nexclude_patterns = [\n    \"_build\",\n    \"**/.nox/**/*\",\n    \"samples/AUTHORING_GUIDE.md\",\n    \"samples/CONTRIBUTING.md\",\n    \"samples/snippets/README.rst\",\n]\n\n# The reST default role (used for this markup: `text`) to use for all\n# documents.\n# default_role = None\n\n# If true, '()' will be appended to :func: etc. cross-reference text.\n# add_function_parentheses = True\n\n# If true, the current module name will be prepended to all description\n# unit titles (such as .. function::).\n# add_module_names = True\n\n# If true, sectionauthor and moduleauthor directives will be shown in the\n# output. They are ignored by default.\n# show_authors = False\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = \"sphinx\"\n\n# A list of ignored prefixes for module index sorting.\n# modindex_common_prefix = []\n\n# If true, keep warnings as \"system message\" paragraphs in the built documents.\n# keep_warnings = False\n\n# If true, `todo` and `todoList` produce output, else they produce nothing.\ntodo_include_todos = True\n\n\n# -- Options for HTML output ----------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\nhtml_theme = \"alabaster\"\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\nhtml_theme_options = {\n    \"description\": \"Google Cloud Client Libraries for google-api-core\",\n    \"github_user\": \"googleapis\",\n    \"github_repo\": \"python-api-core\",\n    \"github_banner\": True,\n    \"font_family\": \"'Roboto', Georgia, sans\",\n    \"head_font_family\": \"'Roboto', Georgia, serif\",\n    \"code_font_family\": \"'Roboto Mono', 'Consolas', monospace\",\n}\n\n# Add any paths that contain custom themes here, relative to this directory.\n# html_theme_path = []\n\n# The name for this set of Sphinx documents.  If None, it defaults to\n# \"<project> v<release> documentation\".\n# html_title = None\n\n# A shorter title for the navigation bar.  Default is the same as html_title.\n# html_short_title = None\n\n# The name of an image file (relative to this directory) to place at the top\n# of the sidebar.\n# html_logo = None\n\n# The name of an image file (within the static path) to use as favicon of the\n# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32\n# pixels large.\n# html_favicon = None\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named \"default.css\" will overwrite the builtin \"default.css\".\nhtml_static_path = [\"_static\"]\n\n# Add any extra paths that contain custom files (such as robots.txt or\n# .htaccess) here, relative to this directory. These files are copied\n# directly to the root of the documentation.\n# html_extra_path = []\n\n# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,\n# using the given strftime format.\n# html_last_updated_fmt = '%b %d, %Y'\n\n# If true, SmartyPants will be used to convert quotes and dashes to\n# typographically correct entities.\n# html_use_smartypants = True\n\n# Custom sidebar templates, maps document names to template names.\n# html_sidebars = {}\n\n# Additional templates that should be rendered to pages, maps page names to\n# template names.\n# html_additional_pages = {}\n\n# If false, no module index is generated.\n# html_domain_indices = True\n\n# If false, no index is generated.\n# html_use_index = True\n\n# If true, the index is split into individual pages for each letter.\n# html_split_index = False\n\n# If true, links to the reST sources are added to the pages.\n# html_show_sourcelink = True\n\n# If true, \"Created using Sphinx\" is shown in the HTML footer. Default is True.\n# html_show_sphinx = True\n\n# If true, \"(C) Copyright ...\" is shown in the HTML footer. Default is True.\n# html_show_copyright = True\n\n# If true, an OpenSearch description file will be output, and all pages will\n# contain a <link> tag referring to it.  The value of this option must be the\n# base URL from which the finished HTML is served.\n# html_use_opensearch = ''\n\n# This is the file name suffix for HTML files (e.g. \".xhtml\").\n# html_file_suffix = None\n\n# Language to be used for generating the HTML full-text search index.\n# Sphinx supports the following languages:\n#   'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'\n#   'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'\n# html_search_language = 'en'\n\n# A dictionary with options for the search language support, empty by default.\n# Now only 'ja' uses this config value\n# html_search_options = {'type': 'default'}\n\n# The name of a javascript file (relative to the configuration directory) that\n# implements a search results scorer. If empty, the default will be used.\n# html_search_scorer = 'scorer.js'\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = \"google-api-core-doc\"\n\n# -- Options for warnings ------------------------------------------------------\n\n\nsuppress_warnings = [\n    # Temporarily suppress this to avoid \"more than one target found for\n    # cross-reference\" warning, which are intractable for us to avoid while in\n    # a mono-repo.\n    # See https://github.com/sphinx-doc/sphinx/blob\n    # /2a65ffeef5c107c19084fabdd706cdff3f52d93c/sphinx/domains/python.py#L843\n    \"ref.python\"\n]\n\n# -- Options for LaTeX output ---------------------------------------------\n\nlatex_elements = {\n    # The paper size ('letterpaper' or 'a4paper').\n    #'papersize': 'letterpaper',\n    # The font size ('10pt', '11pt' or '12pt').\n    #'pointsize': '10pt',\n    # Additional stuff for the LaTeX preamble.\n    #'preamble': '',\n    # Latex figure (float) alignment\n    #'figure_align': 'htbp',\n}\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title,\n#  author, documentclass [howto, manual, or own class]).\nlatex_documents = [\n    (\n        root_doc,\n        \"google-api-core.tex\",\n        \"google-api-core Documentation\",\n        author,\n        \"manual\",\n    )\n]\n\n# The name of an image file (relative to this directory) to place at the top of\n# the title page.\n# latex_logo = None\n\n# For \"manual\" documents, if this is true, then toplevel headings are parts,\n# not chapters.\n# latex_use_parts = False\n\n# If true, show page references after internal links.\n# latex_show_pagerefs = False\n\n# If true, show URL addresses after external links.\n# latex_show_urls = False\n\n# Documents to append as an appendix to all manuals.\n# latex_appendices = []\n\n# If false, no module index is generated.\n# latex_domain_indices = True\n\n\n# -- Options for manual page output ---------------------------------------\n\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [\n    (\n        root_doc,\n        \"google-api-core\",\n        \"google-api-core Documentation\",\n        [author],\n        1,\n    )\n]\n\n# If true, show URL addresses after external links.\n# man_show_urls = False\n\n\n# -- Options for Texinfo output -------------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n    (\n        root_doc,\n        \"google-api-core\",\n        \"google-api-core Documentation\",\n        author,\n        \"google-api-core\",\n        \"google-api-core Library\",\n        \"APIs\",\n    )\n]\n\n# Documents to append as an appendix to all manuals.\n# texinfo_appendices = []\n\n# If false, no module index is generated.\n# texinfo_domain_indices = True\n\n# How to display URL addresses: 'footnote', 'no', or 'inline'.\n# texinfo_show_urls = 'footnote'\n\n# If true, do not generate a @detailmenu in the \"Top\" node's menu.\n# texinfo_no_detailmenu = False\n\n\n# Example configuration for intersphinx: refer to the Python standard library.\nintersphinx_mapping = {\n    \"python\": (\"https://python.readthedocs.org/en/latest/\", None),\n    \"google-auth\": (\"https://googleapis.dev/python/google-auth/latest/\", None),\n    \"google.api_core\": (\n        \"https://googleapis.dev/python/google-api-core/latest/\",\n        None,\n    ),\n    \"grpc\": (\"https://grpc.github.io/grpc/python/\", None),\n    \"proto-plus\": (\"https://proto-plus-python.readthedocs.io/en/latest/\", None),\n    \"protobuf\": (\"https://googleapis.dev/python/protobuf/latest/\", None),\n}\n\n\n# Napoleon settings\nnapoleon_google_docstring = True\nnapoleon_numpy_docstring = True\nnapoleon_include_private_with_doc = False\nnapoleon_include_special_with_doc = True\nnapoleon_use_admonition_for_examples = False\nnapoleon_use_admonition_for_notes = False\nnapoleon_use_admonition_for_references = False\nnapoleon_use_ivar = False\nnapoleon_use_param = True\nnapoleon_use_rtype = True\n", "tests/__init__.py": "", "tests/asyncio/test_operation_async.py": "# Copyright 2017, Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\nimport mock\nimport pytest\n\ntry:\n    import grpc  # noqa: F401\nexcept ImportError:  # pragma: NO COVER\n    pytest.skip(\"No GRPC\", allow_module_level=True)\n\nfrom google.api_core import exceptions\nfrom google.api_core import operation_async\nfrom google.api_core import operations_v1\nfrom google.api_core import retry_async\nfrom google.longrunning import operations_pb2\nfrom google.protobuf import struct_pb2\nfrom google.rpc import code_pb2\nfrom google.rpc import status_pb2\n\nTEST_OPERATION_NAME = \"test/operation\"\n\n\ndef make_operation_proto(\n    name=TEST_OPERATION_NAME, metadata=None, response=None, error=None, **kwargs\n):\n    operation_proto = operations_pb2.Operation(name=name, **kwargs)\n\n    if metadata is not None:\n        operation_proto.metadata.Pack(metadata)\n\n    if response is not None:\n        operation_proto.response.Pack(response)\n\n    if error is not None:\n        operation_proto.error.CopyFrom(error)\n\n    return operation_proto\n\n\ndef make_operation_future(client_operations_responses=None):\n    if client_operations_responses is None:\n        client_operations_responses = [make_operation_proto()]\n\n    refresh = mock.AsyncMock(spec=[\"__call__\"], side_effect=client_operations_responses)\n    refresh.responses = client_operations_responses\n    cancel = mock.AsyncMock(spec=[\"__call__\"])\n    operation_future = operation_async.AsyncOperation(\n        client_operations_responses[0],\n        refresh,\n        cancel,\n        result_type=struct_pb2.Struct,\n        metadata_type=struct_pb2.Struct,\n    )\n\n    return operation_future, refresh, cancel\n\n\n@pytest.mark.asyncio\nasync def test_constructor():\n    future, refresh, _ = make_operation_future()\n\n    assert future.operation == refresh.responses[0]\n    assert future.operation.done is False\n    assert future.operation.name == TEST_OPERATION_NAME\n    assert future.metadata is None\n    assert await future.running()\n\n\ndef test_metadata():\n    expected_metadata = struct_pb2.Struct()\n    future, _, _ = make_operation_future(\n        [make_operation_proto(metadata=expected_metadata)]\n    )\n\n    assert future.metadata == expected_metadata\n\n\n@pytest.mark.asyncio\nasync def test_cancellation():\n    responses = [\n        make_operation_proto(),\n        # Second response indicates that the operation was cancelled.\n        make_operation_proto(\n            done=True, error=status_pb2.Status(code=code_pb2.CANCELLED)\n        ),\n    ]\n    future, _, cancel = make_operation_future(responses)\n\n    assert await future.cancel()\n    assert await future.cancelled()\n    cancel.assert_called_once_with()\n\n    # Cancelling twice should have no effect.\n    assert not await future.cancel()\n    cancel.assert_called_once_with()\n\n\n@pytest.mark.asyncio\nasync def test_result():\n    expected_result = struct_pb2.Struct()\n    responses = [\n        make_operation_proto(),\n        # Second operation response includes the result.\n        make_operation_proto(done=True, response=expected_result),\n    ]\n    future, _, _ = make_operation_future(responses)\n\n    result = await future.result()\n\n    assert result == expected_result\n    assert await future.done()\n\n\n@pytest.mark.asyncio\nasync def test_done_w_retry():\n    RETRY_PREDICATE = retry_async.if_exception_type(exceptions.TooManyRequests)\n    test_retry = retry_async.AsyncRetry(predicate=RETRY_PREDICATE)\n\n    expected_result = struct_pb2.Struct()\n    responses = [\n        make_operation_proto(),\n        # Second operation response includes the result.\n        make_operation_proto(done=True, response=expected_result),\n    ]\n    future, refresh, _ = make_operation_future(responses)\n\n    await future.done(retry=test_retry)\n    refresh.assert_called_once_with(retry=test_retry)\n\n\n@pytest.mark.asyncio\nasync def test_exception():\n    expected_exception = status_pb2.Status(message=\"meep\")\n    responses = [\n        make_operation_proto(),\n        # Second operation response includes the error.\n        make_operation_proto(done=True, error=expected_exception),\n    ]\n    future, _, _ = make_operation_future(responses)\n\n    exception = await future.exception()\n\n    assert expected_exception.message in \"{!r}\".format(exception)\n\n\n@mock.patch(\"asyncio.sleep\", autospec=True)\n@pytest.mark.asyncio\nasync def test_unexpected_result(unused_sleep):\n    responses = [\n        make_operation_proto(),\n        # Second operation response is done, but has not error or response.\n        make_operation_proto(done=True),\n    ]\n    future, _, _ = make_operation_future(responses)\n\n    exception = await future.exception()\n\n    assert \"Unexpected state\" in \"{!r}\".format(exception)\n\n\ndef test_from_gapic():\n    operation_proto = make_operation_proto(done=True)\n    operations_client = mock.create_autospec(\n        operations_v1.OperationsClient, instance=True\n    )\n\n    future = operation_async.from_gapic(\n        operation_proto,\n        operations_client,\n        struct_pb2.Struct,\n        metadata_type=struct_pb2.Struct,\n        grpc_metadata=[(\"x-goog-request-params\", \"foo\")],\n    )\n\n    assert future._result_type == struct_pb2.Struct\n    assert future._metadata_type == struct_pb2.Struct\n    assert future.operation.name == TEST_OPERATION_NAME\n    assert future.done\n    assert future._refresh.keywords[\"metadata\"] == [(\"x-goog-request-params\", \"foo\")]\n    assert future._cancel.keywords[\"metadata\"] == [(\"x-goog-request-params\", \"foo\")]\n\n\ndef test_deserialize():\n    op = make_operation_proto(name=\"foobarbaz\")\n    serialized = op.SerializeToString()\n    deserialized_op = operation_async.AsyncOperation.deserialize(serialized)\n    assert op.name == deserialized_op.name\n    assert type(op) is type(deserialized_op)\n", "tests/asyncio/test_grpc_helpers_async.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport mock\nimport pytest  # noqa: I202\n\ntry:\n    import grpc\n    from grpc import aio\nexcept ImportError:  # pragma: NO COVER\n    grpc = aio = None\n\n\nif grpc is None:  # pragma: NO COVER\n    pytest.skip(\"No GRPC\", allow_module_level=True)\n\n\nfrom google.api_core import exceptions\nfrom google.api_core import grpc_helpers_async\nimport google.auth.credentials\n\n\nclass RpcErrorImpl(grpc.RpcError, grpc.Call):\n    def __init__(self, code):\n        super(RpcErrorImpl, self).__init__()\n        self._code = code\n\n    def code(self):\n        return self._code\n\n    def details(self):\n        return None\n\n    def trailing_metadata(self):\n        return None\n\n\n@pytest.mark.asyncio\nasync def test_wrap_unary_errors():\n    grpc_error = RpcErrorImpl(grpc.StatusCode.INVALID_ARGUMENT)\n    callable_ = mock.AsyncMock(spec=[\"__call__\"], side_effect=grpc_error)\n\n    wrapped_callable = grpc_helpers_async._wrap_unary_errors(callable_)\n\n    with pytest.raises(exceptions.InvalidArgument) as exc_info:\n        await wrapped_callable(1, 2, three=\"four\")\n\n    callable_.assert_called_once_with(1, 2, three=\"four\")\n    assert exc_info.value.response == grpc_error\n\n\n@pytest.mark.asyncio\nasync def test_common_methods_in_wrapped_call():\n    mock_call = mock.Mock(aio.UnaryUnaryCall, autospec=True)\n    wrapped_call = grpc_helpers_async._WrappedUnaryUnaryCall().with_call(mock_call)\n\n    await wrapped_call.initial_metadata()\n    assert mock_call.initial_metadata.call_count == 1\n\n    await wrapped_call.trailing_metadata()\n    assert mock_call.trailing_metadata.call_count == 1\n\n    await wrapped_call.code()\n    assert mock_call.code.call_count == 1\n\n    await wrapped_call.details()\n    assert mock_call.details.call_count == 1\n\n    wrapped_call.cancelled()\n    assert mock_call.cancelled.call_count == 1\n\n    wrapped_call.done()\n    assert mock_call.done.call_count == 1\n\n    wrapped_call.time_remaining()\n    assert mock_call.time_remaining.call_count == 1\n\n    wrapped_call.cancel()\n    assert mock_call.cancel.call_count == 1\n\n    callback = mock.sentinel.callback\n    wrapped_call.add_done_callback(callback)\n    mock_call.add_done_callback.assert_called_once_with(callback)\n\n    await wrapped_call.wait_for_connection()\n    assert mock_call.wait_for_connection.call_count == 1\n\n\n@pytest.mark.asyncio\n@pytest.mark.parametrize(\n    \"callable_type,expected_wrapper_type\",\n    [\n        (grpc.aio.UnaryStreamMultiCallable, grpc_helpers_async._WrappedUnaryStreamCall),\n        (grpc.aio.StreamUnaryMultiCallable, grpc_helpers_async._WrappedStreamUnaryCall),\n        (\n            grpc.aio.StreamStreamMultiCallable,\n            grpc_helpers_async._WrappedStreamStreamCall,\n        ),\n    ],\n)\nasync def test_wrap_errors_w_stream_type(callable_type, expected_wrapper_type):\n    class ConcreteMulticallable(callable_type):\n        def __call__(self, *args, **kwargs):\n            raise NotImplementedError(\"Should not be called\")\n\n    with mock.patch.object(\n        grpc_helpers_async, \"_wrap_stream_errors\"\n    ) as wrap_stream_errors:\n        callable_ = ConcreteMulticallable()\n        grpc_helpers_async.wrap_errors(callable_)\n        assert wrap_stream_errors.call_count == 1\n        wrap_stream_errors.assert_called_once_with(callable_, expected_wrapper_type)\n\n\n@pytest.mark.asyncio\nasync def test_wrap_stream_errors_unary_stream():\n    mock_call = mock.Mock(aio.UnaryStreamCall, autospec=True)\n    multicallable = mock.Mock(return_value=mock_call)\n\n    wrapped_callable = grpc_helpers_async._wrap_stream_errors(\n        multicallable, grpc_helpers_async._WrappedUnaryStreamCall\n    )\n\n    await wrapped_callable(1, 2, three=\"four\")\n    multicallable.assert_called_once_with(1, 2, three=\"four\")\n    assert mock_call.wait_for_connection.call_count == 1\n\n\n@pytest.mark.asyncio\nasync def test_wrap_stream_errors_stream_unary():\n    mock_call = mock.Mock(aio.StreamUnaryCall, autospec=True)\n    multicallable = mock.Mock(return_value=mock_call)\n\n    wrapped_callable = grpc_helpers_async._wrap_stream_errors(\n        multicallable, grpc_helpers_async._WrappedStreamUnaryCall\n    )\n\n    await wrapped_callable(1, 2, three=\"four\")\n    multicallable.assert_called_once_with(1, 2, three=\"four\")\n    assert mock_call.wait_for_connection.call_count == 1\n\n\n@pytest.mark.asyncio\nasync def test_wrap_stream_errors_stream_stream():\n    mock_call = mock.Mock(aio.StreamStreamCall, autospec=True)\n    multicallable = mock.Mock(return_value=mock_call)\n\n    wrapped_callable = grpc_helpers_async._wrap_stream_errors(\n        multicallable, grpc_helpers_async._WrappedStreamStreamCall\n    )\n\n    await wrapped_callable(1, 2, three=\"four\")\n    multicallable.assert_called_once_with(1, 2, three=\"four\")\n    assert mock_call.wait_for_connection.call_count == 1\n\n\n@pytest.mark.asyncio\nasync def test_wrap_stream_errors_raised():\n    grpc_error = RpcErrorImpl(grpc.StatusCode.INVALID_ARGUMENT)\n    mock_call = mock.Mock(aio.StreamStreamCall, autospec=True)\n    mock_call.wait_for_connection = mock.AsyncMock(side_effect=[grpc_error])\n    multicallable = mock.Mock(return_value=mock_call)\n\n    wrapped_callable = grpc_helpers_async._wrap_stream_errors(\n        multicallable, grpc_helpers_async._WrappedStreamStreamCall\n    )\n\n    with pytest.raises(exceptions.InvalidArgument):\n        await wrapped_callable()\n    assert mock_call.wait_for_connection.call_count == 1\n\n\n@pytest.mark.asyncio\nasync def test_wrap_stream_errors_read():\n    grpc_error = RpcErrorImpl(grpc.StatusCode.INVALID_ARGUMENT)\n\n    mock_call = mock.Mock(aio.StreamStreamCall, autospec=True)\n    mock_call.read = mock.AsyncMock(side_effect=grpc_error)\n    multicallable = mock.Mock(return_value=mock_call)\n\n    wrapped_callable = grpc_helpers_async._wrap_stream_errors(\n        multicallable, grpc_helpers_async._WrappedStreamStreamCall\n    )\n\n    wrapped_call = await wrapped_callable(1, 2, three=\"four\")\n    multicallable.assert_called_once_with(1, 2, three=\"four\")\n    assert mock_call.wait_for_connection.call_count == 1\n\n    with pytest.raises(exceptions.InvalidArgument) as exc_info:\n        await wrapped_call.read()\n    assert exc_info.value.response == grpc_error\n\n\n@pytest.mark.asyncio\nasync def test_wrap_stream_errors_aiter():\n    grpc_error = RpcErrorImpl(grpc.StatusCode.INVALID_ARGUMENT)\n\n    mock_call = mock.Mock(aio.StreamStreamCall, autospec=True)\n    mocked_aiter = mock.Mock(spec=[\"__anext__\"])\n    mocked_aiter.__anext__ = mock.AsyncMock(\n        side_effect=[mock.sentinel.response, grpc_error]\n    )\n    mock_call.__aiter__ = mock.Mock(return_value=mocked_aiter)\n    multicallable = mock.Mock(return_value=mock_call)\n\n    wrapped_callable = grpc_helpers_async._wrap_stream_errors(\n        multicallable, grpc_helpers_async._WrappedStreamStreamCall\n    )\n    wrapped_call = await wrapped_callable()\n\n    with pytest.raises(exceptions.InvalidArgument) as exc_info:\n        async for response in wrapped_call:\n            assert response == mock.sentinel.response\n    assert exc_info.value.response == grpc_error\n\n\n@pytest.mark.asyncio\nasync def test_wrap_stream_errors_aiter_non_rpc_error():\n    non_grpc_error = TypeError(\"Not a gRPC error\")\n\n    mock_call = mock.Mock(aio.StreamStreamCall, autospec=True)\n    mocked_aiter = mock.Mock(spec=[\"__anext__\"])\n    mocked_aiter.__anext__ = mock.AsyncMock(\n        side_effect=[mock.sentinel.response, non_grpc_error]\n    )\n    mock_call.__aiter__ = mock.Mock(return_value=mocked_aiter)\n    multicallable = mock.Mock(return_value=mock_call)\n\n    wrapped_callable = grpc_helpers_async._wrap_stream_errors(\n        multicallable, grpc_helpers_async._WrappedStreamStreamCall\n    )\n    wrapped_call = await wrapped_callable()\n\n    with pytest.raises(TypeError) as exc_info:\n        async for response in wrapped_call:\n            assert response == mock.sentinel.response\n    assert exc_info.value == non_grpc_error\n\n\n@pytest.mark.asyncio\nasync def test_wrap_stream_errors_aiter_called_multiple_times():\n    mock_call = mock.Mock(aio.StreamStreamCall, autospec=True)\n    multicallable = mock.Mock(return_value=mock_call)\n\n    wrapped_callable = grpc_helpers_async._wrap_stream_errors(\n        multicallable, grpc_helpers_async._WrappedStreamStreamCall\n    )\n    wrapped_call = await wrapped_callable()\n\n    assert wrapped_call.__aiter__() == wrapped_call.__aiter__()\n\n\n@pytest.mark.asyncio\nasync def test_wrap_stream_errors_write():\n    grpc_error = RpcErrorImpl(grpc.StatusCode.INVALID_ARGUMENT)\n\n    mock_call = mock.Mock(aio.StreamStreamCall, autospec=True)\n    mock_call.write = mock.AsyncMock(side_effect=[None, grpc_error])\n    mock_call.done_writing = mock.AsyncMock(side_effect=[None, grpc_error])\n    multicallable = mock.Mock(return_value=mock_call)\n\n    wrapped_callable = grpc_helpers_async._wrap_stream_errors(\n        multicallable, grpc_helpers_async._WrappedStreamStreamCall\n    )\n\n    wrapped_call = await wrapped_callable()\n\n    await wrapped_call.write(mock.sentinel.request)\n    with pytest.raises(exceptions.InvalidArgument) as exc_info:\n        await wrapped_call.write(mock.sentinel.request)\n    assert mock_call.write.call_count == 2\n    assert exc_info.value.response == grpc_error\n\n    await wrapped_call.done_writing()\n    with pytest.raises(exceptions.InvalidArgument) as exc_info:\n        await wrapped_call.done_writing()\n    assert mock_call.done_writing.call_count == 2\n    assert exc_info.value.response == grpc_error\n\n\n@mock.patch(\"google.api_core.grpc_helpers_async._wrap_unary_errors\")\ndef test_wrap_errors_non_streaming(wrap_unary_errors):\n    callable_ = mock.create_autospec(aio.UnaryUnaryMultiCallable)\n\n    result = grpc_helpers_async.wrap_errors(callable_)\n\n    assert result == wrap_unary_errors.return_value\n    wrap_unary_errors.assert_called_once_with(callable_)\n\n\ndef test_grpc_async_stream():\n    \"\"\"\n    GrpcAsyncStream type should be both an AsyncIterator and a grpc.aio.Call.\n    \"\"\"\n    instance = grpc_helpers_async.GrpcAsyncStream[int]()\n    assert isinstance(instance, grpc.aio.Call)\n    # should implement __aiter__ and __anext__\n    assert hasattr(instance, \"__aiter__\")\n    it = instance.__aiter__()\n    assert hasattr(it, \"__anext__\")\n\n\ndef test_awaitable_grpc_call():\n    \"\"\"\n    AwaitableGrpcCall type should be an Awaitable and a grpc.aio.Call.\n    \"\"\"\n    instance = grpc_helpers_async.AwaitableGrpcCall[int]()\n    assert isinstance(instance, grpc.aio.Call)\n    # should implement __await__\n    assert hasattr(instance, \"__await__\")\n\n\n@mock.patch(\"google.api_core.grpc_helpers_async._wrap_stream_errors\")\ndef test_wrap_errors_streaming(wrap_stream_errors):\n    callable_ = mock.create_autospec(aio.UnaryStreamMultiCallable)\n\n    result = grpc_helpers_async.wrap_errors(callable_)\n\n    assert result == wrap_stream_errors.return_value\n    wrap_stream_errors.assert_called_once_with(\n        callable_, grpc_helpers_async._WrappedUnaryStreamCall\n    )\n\n\n@pytest.mark.parametrize(\n    \"attempt_direct_path,target,expected_target\",\n    [\n        (None, \"example.com:443\", \"example.com:443\"),\n        (False, \"example.com:443\", \"example.com:443\"),\n        (True, \"example.com:443\", \"google-c2p:///example.com\"),\n        (True, \"dns:///example.com\", \"google-c2p:///example.com\"),\n        (True, \"another-c2p:///example.com\", \"another-c2p:///example.com\"),\n    ],\n)\n@mock.patch(\"grpc.compute_engine_channel_credentials\")\n@mock.patch(\n    \"google.auth.default\",\n    autospec=True,\n    return_value=(mock.sentinel.credentials, mock.sentinel.project),\n)\n@mock.patch(\"grpc.aio.secure_channel\")\ndef test_create_channel_implicit(\n    grpc_secure_channel,\n    google_auth_default,\n    composite_creds_call,\n    attempt_direct_path,\n    target,\n    expected_target,\n):\n    composite_creds = composite_creds_call.return_value\n\n    channel = grpc_helpers_async.create_channel(\n        target, attempt_direct_path=attempt_direct_path\n    )\n\n    assert channel is grpc_secure_channel.return_value\n\n    google_auth_default.assert_called_once_with(scopes=None, default_scopes=None)\n    grpc_secure_channel.assert_called_once_with(\n        expected_target, composite_creds, compression=None\n    )\n\n\n@pytest.mark.parametrize(\n    \"attempt_direct_path,target, expected_target\",\n    [\n        (None, \"example.com:443\", \"example.com:443\"),\n        (False, \"example.com:443\", \"example.com:443\"),\n        (True, \"example.com:443\", \"google-c2p:///example.com\"),\n        (True, \"dns:///example.com\", \"google-c2p:///example.com\"),\n        (True, \"another-c2p:///example.com\", \"another-c2p:///example.com\"),\n    ],\n)\n@mock.patch(\"google.auth.transport.grpc.AuthMetadataPlugin\", autospec=True)\n@mock.patch(\n    \"google.auth.transport.requests.Request\",\n    autospec=True,\n    return_value=mock.sentinel.Request,\n)\n@mock.patch(\"grpc.compute_engine_channel_credentials\")\n@mock.patch(\n    \"google.auth.default\",\n    autospec=True,\n    return_value=(mock.sentinel.credentials, mock.sentinel.project),\n)\n@mock.patch(\"grpc.aio.secure_channel\")\ndef test_create_channel_implicit_with_default_host(\n    grpc_secure_channel,\n    google_auth_default,\n    composite_creds_call,\n    request,\n    auth_metadata_plugin,\n    attempt_direct_path,\n    target,\n    expected_target,\n):\n    default_host = \"example.com\"\n    composite_creds = composite_creds_call.return_value\n\n    channel = grpc_helpers_async.create_channel(\n        target, default_host=default_host, attempt_direct_path=attempt_direct_path\n    )\n\n    assert channel is grpc_secure_channel.return_value\n\n    google_auth_default.assert_called_once_with(scopes=None, default_scopes=None)\n    auth_metadata_plugin.assert_called_once_with(\n        mock.sentinel.credentials, mock.sentinel.Request, default_host=default_host\n    )\n    grpc_secure_channel.assert_called_once_with(\n        expected_target, composite_creds, compression=None\n    )\n\n\n@pytest.mark.parametrize(\n    \"attempt_direct_path\",\n    [\n        None,\n        False,\n    ],\n)\n@mock.patch(\"grpc.composite_channel_credentials\")\n@mock.patch(\n    \"google.auth.default\",\n    return_value=(mock.sentinel.credentials, mock.sentinel.project),\n)\n@mock.patch(\"grpc.aio.secure_channel\")\ndef test_create_channel_implicit_with_ssl_creds(\n    grpc_secure_channel, default, composite_creds_call, attempt_direct_path\n):\n    target = \"example.com:443\"\n\n    ssl_creds = grpc.ssl_channel_credentials()\n\n    grpc_helpers_async.create_channel(\n        target, ssl_credentials=ssl_creds, attempt_direct_path=attempt_direct_path\n    )\n\n    default.assert_called_once_with(scopes=None, default_scopes=None)\n    composite_creds_call.assert_called_once_with(ssl_creds, mock.ANY)\n    composite_creds = composite_creds_call.return_value\n    grpc_secure_channel.assert_called_once_with(\n        target, composite_creds, compression=None\n    )\n\n\ndef test_create_channel_implicit_with_ssl_creds_attempt_direct_path_true():\n    target = \"example.com:443\"\n    ssl_creds = grpc.ssl_channel_credentials()\n    with pytest.raises(\n        ValueError, match=\"Using ssl_credentials with Direct Path is not supported\"\n    ):\n        grpc_helpers_async.create_channel(\n            target, ssl_credentials=ssl_creds, attempt_direct_path=True\n        )\n\n\n@mock.patch(\"grpc.compute_engine_channel_credentials\")\n@mock.patch(\n    \"google.auth.default\",\n    autospec=True,\n    return_value=(mock.sentinel.credentials, mock.sentinel.project),\n)\n@mock.patch(\"grpc.aio.secure_channel\")\ndef test_create_channel_implicit_with_scopes(\n    grpc_secure_channel, default, composite_creds_call\n):\n    target = \"example.com:443\"\n    composite_creds = composite_creds_call.return_value\n\n    channel = grpc_helpers_async.create_channel(target, scopes=[\"one\", \"two\"])\n\n    assert channel is grpc_secure_channel.return_value\n\n    default.assert_called_once_with(scopes=[\"one\", \"two\"], default_scopes=None)\n    grpc_secure_channel.assert_called_once_with(\n        target, composite_creds, compression=None\n    )\n\n\n@mock.patch(\"grpc.compute_engine_channel_credentials\")\n@mock.patch(\n    \"google.auth.default\",\n    autospec=True,\n    return_value=(mock.sentinel.credentials, mock.sentinel.project),\n)\n@mock.patch(\"grpc.aio.secure_channel\")\ndef test_create_channel_implicit_with_default_scopes(\n    grpc_secure_channel, default, composite_creds_call\n):\n    target = \"example.com:443\"\n    composite_creds = composite_creds_call.return_value\n\n    channel = grpc_helpers_async.create_channel(\n        target, default_scopes=[\"three\", \"four\"], compression=grpc.Compression.Gzip\n    )\n\n    assert channel is grpc_secure_channel.return_value\n\n    default.assert_called_once_with(scopes=None, default_scopes=[\"three\", \"four\"])\n    grpc_secure_channel.assert_called_once_with(\n        target, composite_creds, compression=grpc.Compression.Gzip\n    )\n\n\ndef test_create_channel_explicit_with_duplicate_credentials():\n    target = \"example:443\"\n\n    with pytest.raises(exceptions.DuplicateCredentialArgs) as excinfo:\n        grpc_helpers_async.create_channel(\n            target,\n            credentials_file=\"credentials.json\",\n            credentials=mock.sentinel.credentials,\n        )\n\n    assert \"mutually exclusive\" in str(excinfo.value)\n\n\n@mock.patch(\"grpc.compute_engine_channel_credentials\")\n@mock.patch(\"google.auth.credentials.with_scopes_if_required\", autospec=True)\n@mock.patch(\"grpc.aio.secure_channel\")\ndef test_create_channel_explicit(grpc_secure_channel, auth_creds, composite_creds_call):\n    target = \"example.com:443\"\n    composite_creds = composite_creds_call.return_value\n\n    channel = grpc_helpers_async.create_channel(\n        target, credentials=mock.sentinel.credentials, compression=grpc.Compression.Gzip\n    )\n\n    auth_creds.assert_called_once_with(\n        mock.sentinel.credentials, scopes=None, default_scopes=None\n    )\n    assert channel is grpc_secure_channel.return_value\n    grpc_secure_channel.assert_called_once_with(\n        target, composite_creds, compression=grpc.Compression.Gzip\n    )\n\n\n@mock.patch(\"grpc.compute_engine_channel_credentials\")\n@mock.patch(\"grpc.aio.secure_channel\")\ndef test_create_channel_explicit_scoped(grpc_secure_channel, composite_creds_call):\n    target = \"example.com:443\"\n    scopes = [\"1\", \"2\"]\n    composite_creds = composite_creds_call.return_value\n\n    credentials = mock.create_autospec(google.auth.credentials.Scoped, instance=True)\n    credentials.requires_scopes = True\n\n    channel = grpc_helpers_async.create_channel(\n        target,\n        credentials=credentials,\n        scopes=scopes,\n        compression=grpc.Compression.Gzip,\n    )\n\n    credentials.with_scopes.assert_called_once_with(scopes, default_scopes=None)\n    assert channel is grpc_secure_channel.return_value\n    grpc_secure_channel.assert_called_once_with(\n        target, composite_creds, compression=grpc.Compression.Gzip\n    )\n\n\n@mock.patch(\"grpc.compute_engine_channel_credentials\")\n@mock.patch(\"grpc.aio.secure_channel\")\ndef test_create_channel_explicit_default_scopes(\n    grpc_secure_channel, composite_creds_call\n):\n    target = \"example.com:443\"\n    default_scopes = [\"3\", \"4\"]\n    composite_creds = composite_creds_call.return_value\n\n    credentials = mock.create_autospec(google.auth.credentials.Scoped, instance=True)\n    credentials.requires_scopes = True\n\n    channel = grpc_helpers_async.create_channel(\n        target,\n        credentials=credentials,\n        default_scopes=default_scopes,\n        compression=grpc.Compression.Gzip,\n    )\n\n    credentials.with_scopes.assert_called_once_with(\n        scopes=None, default_scopes=default_scopes\n    )\n    assert channel is grpc_secure_channel.return_value\n    grpc_secure_channel.assert_called_once_with(\n        target, composite_creds, compression=grpc.Compression.Gzip\n    )\n\n\n@mock.patch(\"grpc.compute_engine_channel_credentials\")\n@mock.patch(\"grpc.aio.secure_channel\")\ndef test_create_channel_explicit_with_quota_project(\n    grpc_secure_channel, composite_creds_call\n):\n    target = \"example.com:443\"\n    composite_creds = composite_creds_call.return_value\n\n    credentials = mock.create_autospec(\n        google.auth.credentials.CredentialsWithQuotaProject, instance=True\n    )\n\n    channel = grpc_helpers_async.create_channel(\n        target, credentials=credentials, quota_project_id=\"project-foo\"\n    )\n\n    credentials.with_quota_project.assert_called_once_with(\"project-foo\")\n    assert channel is grpc_secure_channel.return_value\n    grpc_secure_channel.assert_called_once_with(\n        target, composite_creds, compression=None\n    )\n\n\n@mock.patch(\"grpc.compute_engine_channel_credentials\")\n@mock.patch(\"grpc.aio.secure_channel\")\n@mock.patch(\n    \"google.auth.load_credentials_from_file\",\n    autospec=True,\n    return_value=(mock.sentinel.credentials, mock.sentinel.project),\n)\ndef test_create_channel_with_credentials_file(\n    load_credentials_from_file, grpc_secure_channel, composite_creds_call\n):\n    target = \"example.com:443\"\n\n    credentials_file = \"/path/to/credentials/file.json\"\n    composite_creds = composite_creds_call.return_value\n\n    channel = grpc_helpers_async.create_channel(\n        target, credentials_file=credentials_file\n    )\n\n    google.auth.load_credentials_from_file.assert_called_once_with(\n        credentials_file, scopes=None, default_scopes=None\n    )\n    assert channel is grpc_secure_channel.return_value\n    grpc_secure_channel.assert_called_once_with(\n        target, composite_creds, compression=None\n    )\n\n\n@mock.patch(\"grpc.compute_engine_channel_credentials\")\n@mock.patch(\"grpc.aio.secure_channel\")\n@mock.patch(\n    \"google.auth.load_credentials_from_file\",\n    autospec=True,\n    return_value=(mock.sentinel.credentials, mock.sentinel.project),\n)\ndef test_create_channel_with_credentials_file_and_scopes(\n    load_credentials_from_file, grpc_secure_channel, composite_creds_call\n):\n    target = \"example.com:443\"\n    scopes = [\"1\", \"2\"]\n\n    credentials_file = \"/path/to/credentials/file.json\"\n    composite_creds = composite_creds_call.return_value\n\n    channel = grpc_helpers_async.create_channel(\n        target, credentials_file=credentials_file, scopes=scopes\n    )\n\n    google.auth.load_credentials_from_file.assert_called_once_with(\n        credentials_file, scopes=scopes, default_scopes=None\n    )\n    assert channel is grpc_secure_channel.return_value\n    grpc_secure_channel.assert_called_once_with(\n        target, composite_creds, compression=None\n    )\n\n\n@mock.patch(\"grpc.compute_engine_channel_credentials\")\n@mock.patch(\"grpc.aio.secure_channel\")\n@mock.patch(\n    \"google.auth.load_credentials_from_file\",\n    autospec=True,\n    return_value=(mock.sentinel.credentials, mock.sentinel.project),\n)\ndef test_create_channel_with_credentials_file_and_default_scopes(\n    load_credentials_from_file, grpc_secure_channel, composite_creds_call\n):\n    target = \"example.com:443\"\n    default_scopes = [\"3\", \"4\"]\n\n    credentials_file = \"/path/to/credentials/file.json\"\n    composite_creds = composite_creds_call.return_value\n\n    channel = grpc_helpers_async.create_channel(\n        target, credentials_file=credentials_file, default_scopes=default_scopes\n    )\n\n    google.auth.load_credentials_from_file.assert_called_once_with(\n        credentials_file, scopes=None, default_scopes=default_scopes\n    )\n    assert channel is grpc_secure_channel.return_value\n    grpc_secure_channel.assert_called_once_with(\n        target, composite_creds, compression=None\n    )\n\n\n@mock.patch(\"grpc.aio.secure_channel\")\ndef test_create_channel(grpc_secure_channel):\n    target = \"example.com:443\"\n    scopes = [\"test_scope\"]\n\n    credentials = mock.create_autospec(google.auth.credentials.Scoped, instance=True)\n    credentials.requires_scopes = True\n\n    grpc_helpers_async.create_channel(target, credentials=credentials, scopes=scopes)\n    grpc_secure_channel.assert_called()\n    credentials.with_scopes.assert_called_once_with(scopes, default_scopes=None)\n\n\n@pytest.mark.asyncio\nasync def test_fake_stream_unary_call():\n    fake_call = grpc_helpers_async.FakeStreamUnaryCall()\n    await fake_call.wait_for_connection()\n    response = await fake_call\n    assert fake_call.response == response\n", "tests/asyncio/test_page_iterator_async.py": "# Copyright 2015 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport inspect\n\nimport mock\nimport pytest\n\nfrom google.api_core import page_iterator_async\n\n\nclass PageAsyncIteratorImpl(page_iterator_async.AsyncIterator):\n    async def _next_page(self):\n        return mock.create_autospec(page_iterator_async.Page, instance=True)\n\n\nclass TestAsyncIterator:\n    def test_constructor(self):\n        client = mock.sentinel.client\n        item_to_value = mock.sentinel.item_to_value\n        token = \"ab13nceor03\"\n        max_results = 1337\n\n        iterator = PageAsyncIteratorImpl(\n            client, item_to_value, page_token=token, max_results=max_results\n        )\n\n        assert not iterator._started\n        assert iterator.client is client\n        assert iterator.item_to_value == item_to_value\n        assert iterator.max_results == max_results\n        # Changing attributes.\n        assert iterator.page_number == 0\n        assert iterator.next_page_token == token\n        assert iterator.num_results == 0\n\n    @pytest.mark.asyncio\n    async def test_anext(self):\n        parent = mock.sentinel.parent\n        page_1 = page_iterator_async.Page(\n            parent,\n            (\"item 1.1\", \"item 1.2\"),\n            page_iterator_async._item_to_value_identity,\n        )\n        page_2 = page_iterator_async.Page(\n            parent, (\"item 2.1\",), page_iterator_async._item_to_value_identity\n        )\n\n        async_iterator = PageAsyncIteratorImpl(None, None)\n        async_iterator._next_page = mock.AsyncMock(side_effect=[page_1, page_2, None])\n\n        # Consume items and check the state of the async_iterator.\n        assert async_iterator.num_results == 0\n        assert await async_iterator.__anext__() == \"item 1.1\"\n        assert async_iterator.num_results == 1\n\n        assert await async_iterator.__anext__() == \"item 1.2\"\n        assert async_iterator.num_results == 2\n\n        assert await async_iterator.__anext__() == \"item 2.1\"\n        assert async_iterator.num_results == 3\n\n        with pytest.raises(StopAsyncIteration):\n            await async_iterator.__anext__()\n\n    def test_pages_property_starts(self):\n        iterator = PageAsyncIteratorImpl(None, None)\n\n        assert not iterator._started\n\n        assert inspect.isasyncgen(iterator.pages)\n\n        assert iterator._started\n\n    def test_pages_property_restart(self):\n        iterator = PageAsyncIteratorImpl(None, None)\n\n        assert iterator.pages\n\n        # Make sure we cannot restart.\n        with pytest.raises(ValueError):\n            assert iterator.pages\n\n    @pytest.mark.asyncio\n    async def test__page_aiter_increment(self):\n        iterator = PageAsyncIteratorImpl(None, None)\n        page = page_iterator_async.Page(\n            iterator, (\"item\",), page_iterator_async._item_to_value_identity\n        )\n        iterator._next_page = mock.AsyncMock(side_effect=[page, None])\n\n        assert iterator.num_results == 0\n\n        page_aiter = iterator._page_aiter(increment=True)\n        await page_aiter.__anext__()\n\n        assert iterator.num_results == 1\n\n    @pytest.mark.asyncio\n    async def test__page_aiter_no_increment(self):\n        iterator = PageAsyncIteratorImpl(None, None)\n\n        assert iterator.num_results == 0\n\n        page_aiter = iterator._page_aiter(increment=False)\n        await page_aiter.__anext__()\n\n        # results should still be 0 after fetching a page.\n        assert iterator.num_results == 0\n\n    @pytest.mark.asyncio\n    async def test__items_aiter(self):\n        # Items to be returned.\n        item1 = 17\n        item2 = 100\n        item3 = 211\n\n        # Make pages from mock responses\n        parent = mock.sentinel.parent\n        page1 = page_iterator_async.Page(\n            parent, (item1, item2), page_iterator_async._item_to_value_identity\n        )\n        page2 = page_iterator_async.Page(\n            parent, (item3,), page_iterator_async._item_to_value_identity\n        )\n\n        iterator = PageAsyncIteratorImpl(None, None)\n        iterator._next_page = mock.AsyncMock(side_effect=[page1, page2, None])\n\n        items_aiter = iterator._items_aiter()\n\n        assert inspect.isasyncgen(items_aiter)\n\n        # Consume items and check the state of the iterator.\n        assert iterator.num_results == 0\n        assert await items_aiter.__anext__() == item1\n        assert iterator.num_results == 1\n\n        assert await items_aiter.__anext__() == item2\n        assert iterator.num_results == 2\n\n        assert await items_aiter.__anext__() == item3\n        assert iterator.num_results == 3\n\n        with pytest.raises(StopAsyncIteration):\n            await items_aiter.__anext__()\n\n    @pytest.mark.asyncio\n    async def test___aiter__(self):\n        async_iterator = PageAsyncIteratorImpl(None, None)\n        async_iterator._next_page = mock.AsyncMock(side_effect=[(1, 2), (3,), None])\n\n        assert not async_iterator._started\n\n        result = []\n        async for item in async_iterator:\n            result.append(item)\n\n        assert result == [1, 2, 3]\n        assert async_iterator._started\n\n    def test___aiter__restart(self):\n        iterator = PageAsyncIteratorImpl(None, None)\n\n        iterator.__aiter__()\n\n        # Make sure we cannot restart.\n        with pytest.raises(ValueError):\n            iterator.__aiter__()\n\n    def test___aiter___restart_after_page(self):\n        iterator = PageAsyncIteratorImpl(None, None)\n\n        assert iterator.pages\n\n        # Make sure we cannot restart after starting the page iterator\n        with pytest.raises(ValueError):\n            iterator.__aiter__()\n\n\nclass TestAsyncGRPCIterator(object):\n    def test_constructor(self):\n        client = mock.sentinel.client\n        items_field = \"items\"\n        iterator = page_iterator_async.AsyncGRPCIterator(\n            client, mock.sentinel.method, mock.sentinel.request, items_field\n        )\n\n        assert not iterator._started\n        assert iterator.client is client\n        assert iterator.max_results is None\n        assert iterator.item_to_value is page_iterator_async._item_to_value_identity\n        assert iterator._method == mock.sentinel.method\n        assert iterator._request == mock.sentinel.request\n        assert iterator._items_field == items_field\n        assert (\n            iterator._request_token_field\n            == page_iterator_async.AsyncGRPCIterator._DEFAULT_REQUEST_TOKEN_FIELD\n        )\n        assert (\n            iterator._response_token_field\n            == page_iterator_async.AsyncGRPCIterator._DEFAULT_RESPONSE_TOKEN_FIELD\n        )\n        # Changing attributes.\n        assert iterator.page_number == 0\n        assert iterator.next_page_token is None\n        assert iterator.num_results == 0\n\n    def test_constructor_options(self):\n        client = mock.sentinel.client\n        items_field = \"items\"\n        request_field = \"request\"\n        response_field = \"response\"\n        iterator = page_iterator_async.AsyncGRPCIterator(\n            client,\n            mock.sentinel.method,\n            mock.sentinel.request,\n            items_field,\n            item_to_value=mock.sentinel.item_to_value,\n            request_token_field=request_field,\n            response_token_field=response_field,\n            max_results=42,\n        )\n\n        assert iterator.client is client\n        assert iterator.max_results == 42\n        assert iterator.item_to_value is mock.sentinel.item_to_value\n        assert iterator._method == mock.sentinel.method\n        assert iterator._request == mock.sentinel.request\n        assert iterator._items_field == items_field\n        assert iterator._request_token_field == request_field\n        assert iterator._response_token_field == response_field\n\n    @pytest.mark.asyncio\n    async def test_iterate(self):\n        request = mock.Mock(spec=[\"page_token\"], page_token=None)\n        response1 = mock.Mock(items=[\"a\", \"b\"], next_page_token=\"1\")\n        response2 = mock.Mock(items=[\"c\"], next_page_token=\"2\")\n        response3 = mock.Mock(items=[\"d\"], next_page_token=\"\")\n        method = mock.AsyncMock(side_effect=[response1, response2, response3])\n        iterator = page_iterator_async.AsyncGRPCIterator(\n            mock.sentinel.client, method, request, \"items\"\n        )\n\n        assert iterator.num_results == 0\n\n        items = []\n        async for item in iterator:\n            items.append(item)\n\n        assert items == [\"a\", \"b\", \"c\", \"d\"]\n\n        method.assert_called_with(request)\n        assert method.call_count == 3\n        assert request.page_token == \"2\"\n\n    @pytest.mark.asyncio\n    async def test_iterate_with_max_results(self):\n        request = mock.Mock(spec=[\"page_token\"], page_token=None)\n        response1 = mock.Mock(items=[\"a\", \"b\"], next_page_token=\"1\")\n        response2 = mock.Mock(items=[\"c\"], next_page_token=\"2\")\n        response3 = mock.Mock(items=[\"d\"], next_page_token=\"\")\n        method = mock.AsyncMock(side_effect=[response1, response2, response3])\n        iterator = page_iterator_async.AsyncGRPCIterator(\n            mock.sentinel.client, method, request, \"items\", max_results=3\n        )\n\n        assert iterator.num_results == 0\n\n        items = []\n        async for item in iterator:\n            items.append(item)\n\n        assert items == [\"a\", \"b\", \"c\"]\n        assert iterator.num_results == 3\n\n        method.assert_called_with(request)\n        assert method.call_count == 2\n        assert request.page_token == \"1\"\n", "tests/asyncio/__init__.py": "", "tests/asyncio/operations_v1/test_operations_async_client.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport mock\nimport pytest\n\ntry:\n    from grpc import aio, Compression\nexcept ImportError:  # pragma: NO COVER\n    pytest.skip(\"No GRPC\", allow_module_level=True)\n\nfrom google.api_core import grpc_helpers_async\nfrom google.api_core import operations_v1\nfrom google.api_core import page_iterator_async\nfrom google.longrunning import operations_pb2\nfrom google.protobuf import empty_pb2\n\n\ndef _mock_grpc_objects(response):\n    fake_call = grpc_helpers_async.FakeUnaryUnaryCall(response)\n    method = mock.Mock(spec=aio.UnaryUnaryMultiCallable, return_value=fake_call)\n    mocked_channel = mock.Mock()\n    mocked_channel.unary_unary = mock.Mock(return_value=method)\n    return mocked_channel, method, fake_call\n\n\n@pytest.mark.asyncio\nasync def test_get_operation():\n    mocked_channel, method, fake_call = _mock_grpc_objects(\n        operations_pb2.Operation(name=\"meep\")\n    )\n    client = operations_v1.OperationsAsyncClient(mocked_channel)\n\n    response = await client.get_operation(\n        \"name\", metadata=[(\"header\", \"foo\")], compression=Compression.Gzip\n    )\n    assert method.call_count == 1\n    assert tuple(method.call_args_list[0])[0][0].name == \"name\"\n    assert (\"header\", \"foo\") in tuple(method.call_args_list[0])[1][\"metadata\"]\n    assert tuple(method.call_args_list[0])[1][\"compression\"] == Compression.Gzip\n    assert (\"x-goog-request-params\", \"name=name\") in tuple(method.call_args_list[0])[1][\n        \"metadata\"\n    ]\n    assert response == fake_call.response\n\n\n@pytest.mark.asyncio\nasync def test_list_operations():\n    operations = [\n        operations_pb2.Operation(name=\"1\"),\n        operations_pb2.Operation(name=\"2\"),\n    ]\n    list_response = operations_pb2.ListOperationsResponse(operations=operations)\n\n    mocked_channel, method, fake_call = _mock_grpc_objects(list_response)\n    client = operations_v1.OperationsAsyncClient(mocked_channel)\n\n    pager = await client.list_operations(\n        \"name\", \"filter\", metadata=[(\"header\", \"foo\")], compression=Compression.Gzip\n    )\n\n    assert isinstance(pager, page_iterator_async.AsyncIterator)\n    responses = []\n    async for response in pager:\n        responses.append(response)\n\n    assert responses == operations\n\n    assert method.call_count == 1\n    assert (\"header\", \"foo\") in tuple(method.call_args_list[0])[1][\"metadata\"]\n    assert tuple(method.call_args_list[0])[1][\"compression\"] == Compression.Gzip\n    assert (\"x-goog-request-params\", \"name=name\") in tuple(method.call_args_list[0])[1][\n        \"metadata\"\n    ]\n    request = tuple(method.call_args_list[0])[0][0]\n    assert isinstance(request, operations_pb2.ListOperationsRequest)\n    assert request.name == \"name\"\n    assert request.filter == \"filter\"\n\n\n@pytest.mark.asyncio\nasync def test_delete_operation():\n    mocked_channel, method, fake_call = _mock_grpc_objects(empty_pb2.Empty())\n    client = operations_v1.OperationsAsyncClient(mocked_channel)\n\n    await client.delete_operation(\n        \"name\", metadata=[(\"header\", \"foo\")], compression=Compression.Gzip\n    )\n\n    assert method.call_count == 1\n    assert tuple(method.call_args_list[0])[0][0].name == \"name\"\n    assert (\"header\", \"foo\") in tuple(method.call_args_list[0])[1][\"metadata\"]\n    assert tuple(method.call_args_list[0])[1][\"compression\"] == Compression.Gzip\n    assert (\"x-goog-request-params\", \"name=name\") in tuple(method.call_args_list[0])[1][\n        \"metadata\"\n    ]\n\n\n@pytest.mark.asyncio\nasync def test_cancel_operation():\n    mocked_channel, method, fake_call = _mock_grpc_objects(empty_pb2.Empty())\n    client = operations_v1.OperationsAsyncClient(mocked_channel)\n\n    await client.cancel_operation(\n        \"name\", metadata=[(\"header\", \"foo\")], compression=Compression.Gzip\n    )\n\n    assert method.call_count == 1\n    assert tuple(method.call_args_list[0])[0][0].name == \"name\"\n    assert (\"header\", \"foo\") in tuple(method.call_args_list[0])[1][\"metadata\"]\n    assert tuple(method.call_args_list[0])[1][\"compression\"] == Compression.Gzip\n    assert (\"x-goog-request-params\", \"name=name\") in tuple(method.call_args_list[0])[1][\n        \"metadata\"\n    ]\n", "tests/asyncio/operations_v1/__init__.py": "", "tests/asyncio/gapic/test_config_async.py": "# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\nimport pytest\n\ntry:\n    import grpc  # noqa: F401\nexcept ImportError:\n    pytest.skip(\"No GRPC\", allow_module_level=True)\n\nfrom google.api_core import exceptions\nfrom google.api_core.gapic_v1 import config_async\n\n\nINTERFACE_CONFIG = {\n    \"retry_codes\": {\n        \"idempotent\": [\"DEADLINE_EXCEEDED\", \"UNAVAILABLE\"],\n        \"other\": [\"FAILED_PRECONDITION\"],\n        \"non_idempotent\": [],\n    },\n    \"retry_params\": {\n        \"default\": {\n            \"initial_retry_delay_millis\": 1000,\n            \"retry_delay_multiplier\": 2.5,\n            \"max_retry_delay_millis\": 120000,\n            \"initial_rpc_timeout_millis\": 120000,\n            \"rpc_timeout_multiplier\": 1.0,\n            \"max_rpc_timeout_millis\": 120000,\n            \"total_timeout_millis\": 600000,\n        },\n        \"other\": {\n            \"initial_retry_delay_millis\": 1000,\n            \"retry_delay_multiplier\": 1,\n            \"max_retry_delay_millis\": 1000,\n            \"initial_rpc_timeout_millis\": 1000,\n            \"rpc_timeout_multiplier\": 1,\n            \"max_rpc_timeout_millis\": 1000,\n            \"total_timeout_millis\": 1000,\n        },\n    },\n    \"methods\": {\n        \"AnnotateVideo\": {\n            \"timeout_millis\": 60000,\n            \"retry_codes_name\": \"idempotent\",\n            \"retry_params_name\": \"default\",\n        },\n        \"Other\": {\n            \"timeout_millis\": 60000,\n            \"retry_codes_name\": \"other\",\n            \"retry_params_name\": \"other\",\n        },\n        \"Plain\": {\"timeout_millis\": 30000},\n    },\n}\n\n\ndef test_create_method_configs():\n    method_configs = config_async.parse_method_configs(INTERFACE_CONFIG)\n\n    retry, timeout = method_configs[\"AnnotateVideo\"]\n    assert retry._predicate(exceptions.DeadlineExceeded(None))\n    assert retry._predicate(exceptions.ServiceUnavailable(None))\n    assert retry._initial == 1.0\n    assert retry._multiplier == 2.5\n    assert retry._maximum == 120.0\n    assert retry._deadline == 600.0\n    assert timeout._initial == 120.0\n    assert timeout._multiplier == 1.0\n    assert timeout._maximum == 120.0\n\n    retry, timeout = method_configs[\"Other\"]\n    assert retry._predicate(exceptions.FailedPrecondition(None))\n    assert retry._initial == 1.0\n    assert retry._multiplier == 1.0\n    assert retry._maximum == 1.0\n    assert retry._deadline == 1.0\n    assert timeout._initial == 1.0\n    assert timeout._multiplier == 1.0\n    assert timeout._maximum == 1.0\n\n    retry, timeout = method_configs[\"Plain\"]\n    assert retry is None\n    assert timeout._timeout == 30.0\n", "tests/asyncio/gapic/test_method_async.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport datetime\n\nimport mock\nimport pytest\n\ntry:\n    from grpc import aio, Compression\nexcept ImportError:\n    pytest.skip(\"No GRPC\", allow_module_level=True)\n\nfrom google.api_core import exceptions\nfrom google.api_core import gapic_v1\nfrom google.api_core import grpc_helpers_async\nfrom google.api_core import retry_async\nfrom google.api_core import timeout\n\n\ndef _utcnow_monotonic():\n    current_time = datetime.datetime.min\n    delta = datetime.timedelta(seconds=0.5)\n    while True:\n        yield current_time\n        current_time += delta\n\n\n@pytest.mark.asyncio\nasync def test_wrap_method_basic():\n    fake_call = grpc_helpers_async.FakeUnaryUnaryCall(42)\n    method = mock.Mock(spec=aio.UnaryUnaryMultiCallable, return_value=fake_call)\n\n    wrapped_method = gapic_v1.method_async.wrap_method(method)\n\n    result = await wrapped_method(1, 2, meep=\"moop\")\n\n    assert result == 42\n    method.assert_called_once_with(1, 2, meep=\"moop\", metadata=mock.ANY)\n\n    # Check that the default client info was specified in the metadata.\n    metadata = method.call_args[1][\"metadata\"]\n    assert len(metadata) == 1\n    client_info = gapic_v1.client_info.DEFAULT_CLIENT_INFO\n    user_agent_metadata = client_info.to_grpc_metadata()\n    assert user_agent_metadata in metadata\n\n\n@pytest.mark.asyncio\nasync def test_wrap_method_with_no_client_info():\n    fake_call = grpc_helpers_async.FakeUnaryUnaryCall()\n    method = mock.Mock(spec=aio.UnaryUnaryMultiCallable, return_value=fake_call)\n\n    wrapped_method = gapic_v1.method_async.wrap_method(method, client_info=None)\n\n    await wrapped_method(1, 2, meep=\"moop\")\n\n    method.assert_called_once_with(1, 2, meep=\"moop\")\n\n\n@pytest.mark.asyncio\nasync def test_wrap_method_with_custom_client_info():\n    client_info = gapic_v1.client_info.ClientInfo(\n        python_version=1,\n        grpc_version=2,\n        api_core_version=3,\n        gapic_version=4,\n        client_library_version=5,\n    )\n    fake_call = grpc_helpers_async.FakeUnaryUnaryCall()\n    method = mock.Mock(spec=aio.UnaryUnaryMultiCallable, return_value=fake_call)\n\n    wrapped_method = gapic_v1.method_async.wrap_method(method, client_info=client_info)\n\n    await wrapped_method(1, 2, meep=\"moop\")\n\n    method.assert_called_once_with(1, 2, meep=\"moop\", metadata=mock.ANY)\n\n    # Check that the custom client info was specified in the metadata.\n    metadata = method.call_args[1][\"metadata\"]\n    assert client_info.to_grpc_metadata() in metadata\n\n\n@pytest.mark.asyncio\nasync def test_wrap_method_with_no_compression():\n    fake_call = grpc_helpers_async.FakeUnaryUnaryCall()\n    method = mock.Mock(spec=aio.UnaryUnaryMultiCallable, return_value=fake_call)\n\n    wrapped_method = gapic_v1.method_async.wrap_method(method)\n\n    await wrapped_method(1, 2, meep=\"moop\", compression=None)\n\n    method.assert_called_once_with(1, 2, meep=\"moop\", metadata=mock.ANY)\n\n\n@pytest.mark.asyncio\nasync def test_wrap_method_with_custom_compression():\n    compression = Compression.Gzip\n    fake_call = grpc_helpers_async.FakeUnaryUnaryCall()\n    method = mock.Mock(spec=aio.UnaryUnaryMultiCallable, return_value=fake_call)\n\n    wrapped_method = gapic_v1.method_async.wrap_method(\n        method, default_compression=compression\n    )\n\n    await wrapped_method(1, 2, meep=\"moop\", compression=Compression.Deflate)\n\n    method.assert_called_once_with(\n        1, 2, meep=\"moop\", metadata=mock.ANY, compression=Compression.Deflate\n    )\n\n\n@pytest.mark.asyncio\nasync def test_invoke_wrapped_method_with_metadata():\n    fake_call = grpc_helpers_async.FakeUnaryUnaryCall()\n    method = mock.Mock(spec=aio.UnaryUnaryMultiCallable, return_value=fake_call)\n\n    wrapped_method = gapic_v1.method_async.wrap_method(method)\n\n    await wrapped_method(mock.sentinel.request, metadata=[(\"a\", \"b\")])\n\n    method.assert_called_once_with(mock.sentinel.request, metadata=mock.ANY)\n    metadata = method.call_args[1][\"metadata\"]\n    # Metadata should have two items: the client info metadata and our custom\n    # metadata.\n    assert len(metadata) == 2\n    assert (\"a\", \"b\") in metadata\n\n\n@pytest.mark.asyncio\nasync def test_invoke_wrapped_method_with_metadata_as_none():\n    fake_call = grpc_helpers_async.FakeUnaryUnaryCall()\n    method = mock.Mock(spec=aio.UnaryUnaryMultiCallable, return_value=fake_call)\n\n    wrapped_method = gapic_v1.method_async.wrap_method(method)\n\n    await wrapped_method(mock.sentinel.request, metadata=None)\n\n    method.assert_called_once_with(mock.sentinel.request, metadata=mock.ANY)\n    metadata = method.call_args[1][\"metadata\"]\n    # Metadata should have just one items: the client info metadata.\n    assert len(metadata) == 1\n\n\n@mock.patch(\"asyncio.sleep\")\n@pytest.mark.asyncio\nasync def test_wrap_method_with_default_retry_timeout_and_compression(unused_sleep):\n    fake_call = grpc_helpers_async.FakeUnaryUnaryCall(42)\n    method = mock.Mock(\n        spec=aio.UnaryUnaryMultiCallable,\n        side_effect=[exceptions.InternalServerError(None), fake_call],\n    )\n\n    default_retry = retry_async.AsyncRetry()\n    default_timeout = timeout.ConstantTimeout(60)\n    default_compression = Compression.Gzip\n    wrapped_method = gapic_v1.method_async.wrap_method(\n        method, default_retry, default_timeout, default_compression\n    )\n\n    result = await wrapped_method()\n\n    assert result == 42\n    assert method.call_count == 2\n    method.assert_called_with(\n        timeout=60, compression=default_compression, metadata=mock.ANY\n    )\n\n\n@mock.patch(\"asyncio.sleep\")\n@pytest.mark.asyncio\nasync def test_wrap_method_with_default_retry_and_timeout_using_sentinel(unused_sleep):\n    fake_call = grpc_helpers_async.FakeUnaryUnaryCall(42)\n    method = mock.Mock(\n        spec=aio.UnaryUnaryMultiCallable,\n        side_effect=[exceptions.InternalServerError(None), fake_call],\n    )\n\n    default_retry = retry_async.AsyncRetry()\n    default_timeout = timeout.ConstantTimeout(60)\n    default_compression = Compression.Gzip\n    wrapped_method = gapic_v1.method_async.wrap_method(\n        method, default_retry, default_timeout, default_compression\n    )\n\n    result = await wrapped_method(\n        retry=gapic_v1.method_async.DEFAULT,\n        timeout=gapic_v1.method_async.DEFAULT,\n        compression=gapic_v1.method_async.DEFAULT,\n    )\n\n    assert result == 42\n    assert method.call_count == 2\n    method.assert_called_with(\n        timeout=60, compression=Compression.Gzip, metadata=mock.ANY\n    )\n\n\n@mock.patch(\"asyncio.sleep\")\n@pytest.mark.asyncio\nasync def test_wrap_method_with_overriding_retry_timeout_and_compression(unused_sleep):\n    fake_call = grpc_helpers_async.FakeUnaryUnaryCall(42)\n    method = mock.Mock(\n        spec=aio.UnaryUnaryMultiCallable,\n        side_effect=[exceptions.NotFound(None), fake_call],\n    )\n\n    default_retry = retry_async.AsyncRetry()\n    default_timeout = timeout.ConstantTimeout(60)\n    default_compression = Compression.Gzip\n    wrapped_method = gapic_v1.method_async.wrap_method(\n        method, default_retry, default_timeout, default_compression\n    )\n\n    result = await wrapped_method(\n        retry=retry_async.AsyncRetry(\n            retry_async.if_exception_type(exceptions.NotFound)\n        ),\n        timeout=timeout.ConstantTimeout(22),\n        compression=Compression.Deflate,\n    )\n\n    assert result == 42\n    assert method.call_count == 2\n    method.assert_called_with(\n        timeout=22, compression=Compression.Deflate, metadata=mock.ANY\n    )\n\n\n@pytest.mark.asyncio\nasync def test_wrap_method_with_overriding_timeout_as_a_number():\n    fake_call = grpc_helpers_async.FakeUnaryUnaryCall(42)\n    method = mock.Mock(spec=aio.UnaryUnaryMultiCallable, return_value=fake_call)\n    default_retry = retry_async.AsyncRetry()\n    default_timeout = timeout.ConstantTimeout(60)\n    wrapped_method = gapic_v1.method_async.wrap_method(\n        method, default_retry, default_timeout\n    )\n\n    result = await wrapped_method(timeout=22)\n\n    assert result == 42\n    method.assert_called_once_with(timeout=22, metadata=mock.ANY)\n", "tests/asyncio/retry/test_retry_streaming_async.py": "# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport datetime\nimport re\nimport asyncio\n\nimport mock\nimport pytest\n\nfrom google.api_core import exceptions\nfrom google.api_core import retry_async\nfrom google.api_core.retry import retry_streaming_async\n\nfrom ...unit.retry.test_retry_base import Test_BaseRetry\n\n\n@pytest.mark.asyncio\nasync def test_retry_streaming_target_bad_sleep_generator():\n    from google.api_core.retry.retry_streaming_async import retry_target_stream\n\n    with pytest.raises(ValueError, match=\"Sleep generator\"):\n        await retry_target_stream(None, None, [], None).__anext__()\n\n\nclass TestAsyncStreamingRetry(Test_BaseRetry):\n    def _make_one(self, *args, **kwargs):\n        return retry_streaming_async.AsyncStreamingRetry(*args, **kwargs)\n\n    def test___str__(self):\n        def if_exception_type(exc):\n            return bool(exc)  # pragma: NO COVER\n\n        # Explicitly set all attributes as changed Retry defaults should not\n        # cause this test to start failing.\n        retry_ = retry_streaming_async.AsyncStreamingRetry(\n            predicate=if_exception_type,\n            initial=1.0,\n            maximum=60.0,\n            multiplier=2.0,\n            timeout=120.0,\n            on_error=None,\n        )\n        assert re.match(\n            (\n                r\"<AsyncStreamingRetry predicate=<function.*?if_exception_type.*?>, \"\n                r\"initial=1.0, maximum=60.0, multiplier=2.0, timeout=120.0, \"\n                r\"on_error=None>\"\n            ),\n            str(retry_),\n        )\n\n    async def _generator_mock(\n        self,\n        num=5,\n        error_on=None,\n        exceptions_seen=None,\n        sleep_time=0,\n    ):\n        \"\"\"\n        Helper to create a mock generator that yields a number of values\n        Generator can optionally raise an exception on a specific iteration\n\n        Args:\n          - num (int): the number of values to yield\n          - error_on (int): if given, the generator will raise a ValueError on the specified iteration\n          - exceptions_seen (list): if given, the generator will append any exceptions to this list before raising\n          - sleep_time (int): if given, the generator will asyncio.sleep for this many seconds before yielding each value\n        \"\"\"\n        try:\n            for i in range(num):\n                if sleep_time:\n                    await asyncio.sleep(sleep_time)\n                if error_on and i == error_on:\n                    raise ValueError(\"generator mock error\")\n                yield i\n        except (Exception, BaseException, GeneratorExit) as e:\n            # keep track of exceptions seen by generator\n            if exceptions_seen is not None:\n                exceptions_seen.append(e)\n            raise\n\n    @mock.patch(\"asyncio.sleep\", autospec=True)\n    @pytest.mark.asyncio\n    async def test___call___generator_success(self, sleep):\n        \"\"\"\n        Test that a retry-decorated generator yields values as expected\n        This test checks a generator with no issues\n        \"\"\"\n        from collections.abc import AsyncGenerator\n\n        retry_ = retry_streaming_async.AsyncStreamingRetry()\n        decorated = retry_(self._generator_mock)\n\n        num = 10\n        generator = await decorated(num)\n        # check types\n        assert isinstance(generator, AsyncGenerator)\n        assert isinstance(self._generator_mock(num), AsyncGenerator)\n        # check yield contents\n        unpacked = [i async for i in generator]\n        assert len(unpacked) == num\n        expected = [i async for i in self._generator_mock(num)]\n        for a, b in zip(unpacked, expected):\n            assert a == b\n        sleep.assert_not_called()\n\n    @mock.patch(\"asyncio.sleep\", autospec=True)\n    @pytest.mark.asyncio\n    async def test___call___generator_retry(self, sleep):\n        \"\"\"\n        Tests that a retry-decorated generator will retry on errors\n        \"\"\"\n        on_error = mock.Mock(return_value=None)\n        retry_ = retry_streaming_async.AsyncStreamingRetry(\n            on_error=on_error,\n            predicate=retry_async.if_exception_type(ValueError),\n            timeout=None,\n        )\n        generator = await retry_(self._generator_mock)(error_on=3)\n        # error thrown on 3\n        # generator should contain 0, 1, 2 looping\n        unpacked = [await generator.__anext__() for i in range(10)]\n        assert unpacked == [0, 1, 2, 0, 1, 2, 0, 1, 2, 0]\n        assert on_error.call_count == 3\n\n    @mock.patch(\"random.uniform\", autospec=True, side_effect=lambda m, n: n)\n    @mock.patch(\"asyncio.sleep\", autospec=True)\n    @pytest.mark.parametrize(\"use_deadline_arg\", [True, False])\n    @pytest.mark.asyncio\n    async def test___call___generator_retry_hitting_timeout(\n        self, sleep, uniform, use_deadline_arg\n    ):\n        \"\"\"\n        Tests that a retry-decorated generator will throw a RetryError\n        after using the time budget\n        \"\"\"\n        import time\n\n        timeout_val = 9.9\n        # support \"deadline\" as an alias for \"timeout\"\n        timeout_kwarg = (\n            {\"timeout\": timeout_val}\n            if not use_deadline_arg\n            else {\"deadline\": timeout_val}\n        )\n\n        on_error = mock.Mock()\n        retry_ = retry_streaming_async.AsyncStreamingRetry(\n            predicate=retry_async.if_exception_type(ValueError),\n            initial=1.0,\n            maximum=1024.0,\n            multiplier=2.0,\n            **timeout_kwarg,\n        )\n\n        time_now = time.monotonic()\n        now_patcher = mock.patch(\n            \"time.monotonic\",\n            return_value=time_now,\n        )\n\n        decorated = retry_(self._generator_mock, on_error=on_error)\n        generator = await decorated(error_on=1)\n\n        with now_patcher as patched_now:\n            # Make sure that calls to fake asyncio.sleep() also advance the mocked\n            # time clock.\n            def increase_time(sleep_delay):\n                patched_now.return_value += sleep_delay\n\n            sleep.side_effect = increase_time\n\n            with pytest.raises(exceptions.RetryError):\n                [i async for i in generator]\n\n        assert on_error.call_count == 4\n        # check the delays\n        assert sleep.call_count == 3  # once between each successive target calls\n        last_wait = sleep.call_args.args[0]\n        total_wait = sum(call_args.args[0] for call_args in sleep.call_args_list)\n        # next wait would have put us over, so ended early\n        assert last_wait == 4\n        assert total_wait == 7\n\n    @pytest.mark.asyncio\n    async def test___call___generator_cancellations(self):\n        \"\"\"\n        cancel calls should propagate to the generator\n        \"\"\"\n        # test without cancel as retryable\n        retry_ = retry_streaming_async.AsyncStreamingRetry()\n        utcnow = datetime.datetime.now(datetime.timezone.utc)\n        mock.patch(\"google.api_core.datetime_helpers.utcnow\", return_value=utcnow)\n        generator = await retry_(self._generator_mock)(sleep_time=0.2)\n        assert await generator.__anext__() == 0\n        task = asyncio.create_task(generator.__anext__())\n        task.cancel()\n        with pytest.raises(asyncio.CancelledError):\n            await task\n        with pytest.raises(StopAsyncIteration):\n            await generator.__anext__()\n\n    @mock.patch(\"asyncio.sleep\", autospec=True)\n    @pytest.mark.asyncio\n    async def test___call___with_generator_send(self, sleep):\n        \"\"\"\n        Send should be passed through retry into target generator\n        \"\"\"\n\n        async def _mock_send_gen():\n            \"\"\"\n            always yield whatever was sent in\n            \"\"\"\n            in_ = yield\n            while True:\n                in_ = yield in_\n\n        retry_ = retry_streaming_async.AsyncStreamingRetry()\n\n        decorated = retry_(_mock_send_gen)\n\n        generator = await decorated()\n        result = await generator.__anext__()\n        # first yield should be None\n        assert result is None\n        in_messages = [\"test_1\", \"hello\", \"world\"]\n        out_messages = []\n        for msg in in_messages:\n            recv = await generator.asend(msg)\n            out_messages.append(recv)\n        assert in_messages == out_messages\n\n    @mock.patch(\"asyncio.sleep\", autospec=True)\n    @pytest.mark.asyncio\n    async def test___call___generator_send_retry(self, sleep):\n        \"\"\"\n        Send should be retried if target generator raises an error\n        \"\"\"\n        on_error = mock.Mock(return_value=None)\n        retry_ = retry_streaming_async.AsyncStreamingRetry(\n            on_error=on_error,\n            predicate=retry_async.if_exception_type(ValueError),\n            timeout=None,\n        )\n        generator = await retry_(self._generator_mock)(error_on=3)\n        with pytest.raises(TypeError) as exc_info:\n            await generator.asend(\"cannot send to fresh generator\")\n            assert exc_info.match(\"can't send non-None value\")\n\n        # error thrown on 3\n        # generator should contain 0, 1, 2 looping\n        generator = await retry_(self._generator_mock)(error_on=3)\n        assert await generator.__anext__() == 0\n        unpacked = [await generator.asend(i) for i in range(10)]\n        assert unpacked == [1, 2, 0, 1, 2, 0, 1, 2, 0, 1]\n        assert on_error.call_count == 3\n\n    @mock.patch(\"asyncio.sleep\", autospec=True)\n    @pytest.mark.asyncio\n    async def test___call___with_generator_close(self, sleep):\n        \"\"\"\n        Close should be passed through retry into target generator\n        \"\"\"\n        retry_ = retry_streaming_async.AsyncStreamingRetry()\n        decorated = retry_(self._generator_mock)\n        exception_list = []\n        generator = await decorated(10, exceptions_seen=exception_list)\n        for i in range(2):\n            await generator.__anext__()\n        await generator.aclose()\n\n        assert isinstance(exception_list[0], GeneratorExit)\n        with pytest.raises(StopAsyncIteration):\n            # calling next on closed generator should raise error\n            await generator.__anext__()\n\n    @mock.patch(\"asyncio.sleep\", autospec=True)\n    @pytest.mark.asyncio\n    async def test___call___with_new_generator_close(self, sleep):\n        \"\"\"\n        Close should be passed through retry into target generator,\n        even when it hasn't been iterated yet\n        \"\"\"\n        retry_ = retry_streaming_async.AsyncStreamingRetry()\n        decorated = retry_(self._generator_mock)\n        exception_list = []\n        generator = await decorated(10, exceptions_seen=exception_list)\n        await generator.aclose()\n\n        with pytest.raises(StopAsyncIteration):\n            # calling next on closed generator should raise error\n            await generator.__anext__()\n\n    @mock.patch(\"asyncio.sleep\", autospec=True)\n    @pytest.mark.asyncio\n    async def test___call___with_generator_throw(self, sleep):\n        \"\"\"\n        Throw should be passed through retry into target generator\n        \"\"\"\n\n        # The generator should not retry when it encounters a non-retryable error\n        retry_ = retry_streaming_async.AsyncStreamingRetry(\n            predicate=retry_async.if_exception_type(ValueError),\n        )\n        decorated = retry_(self._generator_mock)\n        exception_list = []\n        generator = await decorated(10, exceptions_seen=exception_list)\n        for i in range(2):\n            await generator.__anext__()\n        with pytest.raises(BufferError):\n            await generator.athrow(BufferError(\"test\"))\n        assert isinstance(exception_list[0], BufferError)\n        with pytest.raises(StopAsyncIteration):\n            # calling next on closed generator should raise error\n            await generator.__anext__()\n\n        # In contrast, the generator should retry if we throw a retryable exception\n        exception_list = []\n        generator = await decorated(10, exceptions_seen=exception_list)\n        for i in range(2):\n            await generator.__anext__()\n        throw_val = await generator.athrow(ValueError(\"test\"))\n        assert throw_val == 0\n        assert isinstance(exception_list[0], ValueError)\n        # calling next on generator should not raise error, because it was retried\n        assert await generator.__anext__() == 1\n\n    @pytest.mark.parametrize(\"awaitable_wrapped\", [True, False])\n    @mock.patch(\"asyncio.sleep\", autospec=True)\n    @pytest.mark.asyncio\n    async def test___call___with_iterable_send(self, sleep, awaitable_wrapped):\n        \"\"\"\n        Send should work like next if the wrapped iterable does not support it\n        \"\"\"\n        retry_ = retry_streaming_async.AsyncStreamingRetry()\n\n        def iterable_fn():\n            class CustomIterable:\n                def __init__(self):\n                    self.i = -1\n\n                def __aiter__(self):\n                    return self\n\n                async def __anext__(self):\n                    self.i += 1\n                    return self.i\n\n            return CustomIterable()\n\n        if awaitable_wrapped:\n\n            async def wrapper():\n                return iterable_fn()\n\n            decorated = retry_(wrapper)\n        else:\n            decorated = retry_(iterable_fn)\n\n        retryable = await decorated()\n        # initiate the generator by calling next\n        result = await retryable.__anext__()\n        assert result == 0\n        # test sending values\n        assert await retryable.asend(\"test\") == 1\n        assert await retryable.asend(\"test2\") == 2\n        assert await retryable.asend(\"test3\") == 3\n\n    @pytest.mark.parametrize(\"awaitable_wrapped\", [True, False])\n    @mock.patch(\"asyncio.sleep\", autospec=True)\n    @pytest.mark.asyncio\n    async def test___call___with_iterable_close(self, sleep, awaitable_wrapped):\n        \"\"\"\n        close should be handled by wrapper if wrapped iterable does not support it\n        \"\"\"\n        retry_ = retry_streaming_async.AsyncStreamingRetry()\n\n        def iterable_fn():\n            class CustomIterable:\n                def __init__(self):\n                    self.i = -1\n\n                def __aiter__(self):\n                    return self\n\n                async def __anext__(self):\n                    self.i += 1\n                    return self.i\n\n            return CustomIterable()\n\n        if awaitable_wrapped:\n\n            async def wrapper():\n                return iterable_fn()\n\n            decorated = retry_(wrapper)\n        else:\n            decorated = retry_(iterable_fn)\n\n        # try closing active generator\n        retryable = await decorated()\n        assert await retryable.__anext__() == 0\n        await retryable.aclose()\n        with pytest.raises(StopAsyncIteration):\n            await retryable.__anext__()\n        # try closing new generator\n        new_retryable = await decorated()\n        await new_retryable.aclose()\n        with pytest.raises(StopAsyncIteration):\n            await new_retryable.__anext__()\n\n    @pytest.mark.parametrize(\"awaitable_wrapped\", [True, False])\n    @mock.patch(\"asyncio.sleep\", autospec=True)\n    @pytest.mark.asyncio\n    async def test___call___with_iterable_throw(self, sleep, awaitable_wrapped):\n        \"\"\"\n        Throw should work even if the wrapped iterable does not support it\n        \"\"\"\n\n        predicate = retry_async.if_exception_type(ValueError)\n        retry_ = retry_streaming_async.AsyncStreamingRetry(predicate=predicate)\n\n        def iterable_fn():\n            class CustomIterable:\n                def __init__(self):\n                    self.i = -1\n\n                def __aiter__(self):\n                    return self\n\n                async def __anext__(self):\n                    self.i += 1\n                    return self.i\n\n            return CustomIterable()\n\n        if awaitable_wrapped:\n\n            async def wrapper():\n                return iterable_fn()\n\n            decorated = retry_(wrapper)\n        else:\n            decorated = retry_(iterable_fn)\n\n        # try throwing with active generator\n        retryable = await decorated()\n        assert await retryable.__anext__() == 0\n        # should swallow errors in predicate\n        await retryable.athrow(ValueError(\"test\"))\n        # should raise errors not in predicate\n        with pytest.raises(BufferError):\n            await retryable.athrow(BufferError(\"test\"))\n        with pytest.raises(StopAsyncIteration):\n            await retryable.__anext__()\n        # try throwing with new generator\n        new_retryable = await decorated()\n        with pytest.raises(BufferError):\n            await new_retryable.athrow(BufferError(\"test\"))\n        with pytest.raises(StopAsyncIteration):\n            await new_retryable.__anext__()\n\n    @pytest.mark.asyncio\n    async def test_exc_factory_non_retryable_error(self):\n        \"\"\"\n        generator should give the option to override exception creation logic\n        test when non-retryable error is thrown\n        \"\"\"\n        from google.api_core.retry import RetryFailureReason\n        from google.api_core.retry.retry_streaming_async import retry_target_stream\n\n        timeout = 6\n        sent_errors = [ValueError(\"test\"), ValueError(\"test2\"), BufferError(\"test3\")]\n        expected_final_err = RuntimeError(\"done\")\n        expected_source_err = ZeroDivisionError(\"test4\")\n\n        def factory(*args, **kwargs):\n            assert len(kwargs) == 0\n            assert args[0] == sent_errors\n            assert args[1] == RetryFailureReason.NON_RETRYABLE_ERROR\n            assert args[2] == timeout\n            return expected_final_err, expected_source_err\n\n        generator = retry_target_stream(\n            self._generator_mock,\n            retry_async.if_exception_type(ValueError),\n            [0] * 3,\n            timeout=timeout,\n            exception_factory=factory,\n        )\n        # initialize the generator\n        await generator.__anext__()\n        # trigger some retryable errors\n        await generator.athrow(sent_errors[0])\n        await generator.athrow(sent_errors[1])\n        # trigger a non-retryable error\n        with pytest.raises(expected_final_err.__class__) as exc_info:\n            await generator.athrow(sent_errors[2])\n        assert exc_info.value == expected_final_err\n        assert exc_info.value.__cause__ == expected_source_err\n\n    @pytest.mark.asyncio\n    async def test_exc_factory_timeout(self):\n        \"\"\"\n        generator should give the option to override exception creation logic\n        test when timeout is exceeded\n        \"\"\"\n        import time\n        from google.api_core.retry import RetryFailureReason\n        from google.api_core.retry.retry_streaming_async import retry_target_stream\n\n        timeout = 2\n        time_now = time.monotonic()\n        now_patcher = mock.patch(\n            \"time.monotonic\",\n            return_value=time_now,\n        )\n\n        with now_patcher as patched_now:\n            timeout = 2\n            sent_errors = [ValueError(\"test\"), ValueError(\"test2\"), ValueError(\"test3\")]\n            expected_final_err = RuntimeError(\"done\")\n            expected_source_err = ZeroDivisionError(\"test4\")\n\n            def factory(*args, **kwargs):\n                assert len(kwargs) == 0\n                assert args[0] == sent_errors\n                assert args[1] == RetryFailureReason.TIMEOUT\n                assert args[2] == timeout\n                return expected_final_err, expected_source_err\n\n            generator = retry_target_stream(\n                self._generator_mock,\n                retry_async.if_exception_type(ValueError),\n                [0] * 3,\n                timeout=timeout,\n                exception_factory=factory,\n            )\n            # initialize the generator\n            await generator.__anext__()\n            # trigger some retryable errors\n            await generator.athrow(sent_errors[0])\n            await generator.athrow(sent_errors[1])\n            # trigger a timeout\n            patched_now.return_value += timeout + 1\n            with pytest.raises(expected_final_err.__class__) as exc_info:\n                await generator.athrow(sent_errors[2])\n            assert exc_info.value == expected_final_err\n            assert exc_info.value.__cause__ == expected_source_err\n", "tests/asyncio/retry/__init__.py": "", "tests/asyncio/retry/test_retry_unary_async.py": "# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport datetime\nimport re\n\nimport mock\nimport pytest\n\nfrom google.api_core import exceptions\nfrom google.api_core import retry_async\n\nfrom ...unit.retry.test_retry_base import Test_BaseRetry\n\n\n@mock.patch(\"asyncio.sleep\", autospec=True)\n@mock.patch(\n    \"google.api_core.datetime_helpers.utcnow\",\n    return_value=datetime.datetime.min,\n    autospec=True,\n)\n@pytest.mark.asyncio\nasync def test_retry_target_success(utcnow, sleep):\n    predicate = retry_async.if_exception_type(ValueError)\n    call_count = [0]\n\n    async def target():\n        call_count[0] += 1\n        if call_count[0] < 3:\n            raise ValueError()\n        return 42\n\n    result = await retry_async.retry_target(target, predicate, range(10), None)\n\n    assert result == 42\n    assert call_count[0] == 3\n    sleep.assert_has_calls([mock.call(0), mock.call(1)])\n\n\n@mock.patch(\"asyncio.sleep\", autospec=True)\n@mock.patch(\n    \"google.api_core.datetime_helpers.utcnow\",\n    return_value=datetime.datetime.min,\n    autospec=True,\n)\n@pytest.mark.asyncio\nasync def test_retry_target_w_on_error(utcnow, sleep):\n    predicate = retry_async.if_exception_type(ValueError)\n    call_count = {\"target\": 0}\n    to_raise = ValueError()\n\n    async def target():\n        call_count[\"target\"] += 1\n        if call_count[\"target\"] < 3:\n            raise to_raise\n        return 42\n\n    on_error = mock.Mock()\n\n    result = await retry_async.retry_target(\n        target, predicate, range(10), None, on_error=on_error\n    )\n\n    assert result == 42\n    assert call_count[\"target\"] == 3\n\n    on_error.assert_has_calls([mock.call(to_raise), mock.call(to_raise)])\n    sleep.assert_has_calls([mock.call(0), mock.call(1)])\n\n\n@mock.patch(\"asyncio.sleep\", autospec=True)\n@mock.patch(\n    \"google.api_core.datetime_helpers.utcnow\",\n    return_value=datetime.datetime.min,\n    autospec=True,\n)\n@pytest.mark.asyncio\nasync def test_retry_target_non_retryable_error(utcnow, sleep):\n    predicate = retry_async.if_exception_type(ValueError)\n    exception = TypeError()\n    target = mock.Mock(side_effect=exception)\n\n    with pytest.raises(TypeError) as exc_info:\n        await retry_async.retry_target(target, predicate, range(10), None)\n\n    assert exc_info.value == exception\n    sleep.assert_not_called()\n\n\n@mock.patch(\"asyncio.sleep\", autospec=True)\n@mock.patch(\"time.monotonic\", autospec=True)\n@pytest.mark.parametrize(\"use_deadline_arg\", [True, False])\n@pytest.mark.asyncio\nasync def test_retry_target_timeout_exceeded(monotonic, sleep, use_deadline_arg):\n    predicate = retry_async.if_exception_type(ValueError)\n    exception = ValueError(\"meep\")\n    target = mock.Mock(side_effect=exception)\n    # Setup the timeline so that the first call takes 5 seconds but the second\n    # call takes 6, which puts the retry over the timeout.\n    monotonic.side_effect = [0, 5, 11]\n\n    timeout_val = 10\n    # support \"deadline\" as an alias for \"timeout\"\n    timeout_kwarg = (\n        {\"timeout\": timeout_val} if not use_deadline_arg else {\"deadline\": timeout_val}\n    )\n\n    with pytest.raises(exceptions.RetryError) as exc_info:\n        await retry_async.retry_target(target, predicate, range(10), **timeout_kwarg)\n\n    assert exc_info.value.cause == exception\n    assert exc_info.match(\"Timeout of 10.0s exceeded\")\n    assert exc_info.match(\"last exception: meep\")\n    assert target.call_count == 2\n\n    # Ensure the exception message does not include the target fn:\n    # it may be a partial with user data embedded\n    assert str(target) not in exc_info.exconly()\n\n\n@pytest.mark.asyncio\nasync def test_retry_target_bad_sleep_generator():\n    with pytest.raises(ValueError, match=\"Sleep generator\"):\n        await retry_async.retry_target(\n            mock.sentinel.target, mock.sentinel.predicate, [], None\n        )\n\n\nclass TestAsyncRetry(Test_BaseRetry):\n    def _make_one(self, *args, **kwargs):\n        return retry_async.AsyncRetry(*args, **kwargs)\n\n    def test___str__(self):\n        def if_exception_type(exc):\n            return bool(exc)  # pragma: NO COVER\n\n        # Explicitly set all attributes as changed Retry defaults should not\n        # cause this test to start failing.\n        retry_ = retry_async.AsyncRetry(\n            predicate=if_exception_type,\n            initial=1.0,\n            maximum=60.0,\n            multiplier=2.0,\n            timeout=120.0,\n            on_error=None,\n        )\n        assert re.match(\n            (\n                r\"<AsyncRetry predicate=<function.*?if_exception_type.*?>, \"\n                r\"initial=1.0, maximum=60.0, multiplier=2.0, timeout=120.0, \"\n                r\"on_error=None>\"\n            ),\n            str(retry_),\n        )\n\n    @mock.patch(\"asyncio.sleep\", autospec=True)\n    @pytest.mark.asyncio\n    async def test___call___and_execute_success(self, sleep):\n        retry_ = retry_async.AsyncRetry()\n        target = mock.AsyncMock(spec=[\"__call__\"], return_value=42)\n        # __name__ is needed by functools.partial.\n        target.__name__ = \"target\"\n\n        decorated = retry_(target)\n        target.assert_not_called()\n\n        result = await decorated(\"meep\")\n\n        assert result == 42\n        target.assert_called_once_with(\"meep\")\n        sleep.assert_not_called()\n\n    @mock.patch(\"random.uniform\", autospec=True, side_effect=lambda m, n: n)\n    @mock.patch(\"asyncio.sleep\", autospec=True)\n    @pytest.mark.asyncio\n    async def test___call___and_execute_retry(self, sleep, uniform):\n        on_error = mock.Mock(spec=[\"__call__\"], side_effect=[None])\n        retry_ = retry_async.AsyncRetry(\n            predicate=retry_async.if_exception_type(ValueError)\n        )\n\n        target = mock.AsyncMock(spec=[\"__call__\"], side_effect=[ValueError(), 42])\n        # __name__ is needed by functools.partial.\n        target.__name__ = \"target\"\n\n        decorated = retry_(target, on_error=on_error)\n        target.assert_not_called()\n\n        result = await decorated(\"meep\")\n\n        assert result == 42\n        assert target.call_count == 2\n        target.assert_has_calls([mock.call(\"meep\"), mock.call(\"meep\")])\n        sleep.assert_called_once_with(retry_._initial)\n        assert on_error.call_count == 1\n\n    @mock.patch(\"random.uniform\", autospec=True, side_effect=lambda m, n: n)\n    @mock.patch(\"asyncio.sleep\", autospec=True)\n    @pytest.mark.asyncio\n    async def test___call___and_execute_retry_hitting_timeout(self, sleep, uniform):\n        on_error = mock.Mock(spec=[\"__call__\"], side_effect=[None] * 10)\n        retry_ = retry_async.AsyncRetry(\n            predicate=retry_async.if_exception_type(ValueError),\n            initial=1.0,\n            maximum=1024.0,\n            multiplier=2.0,\n            timeout=30.9,\n        )\n\n        monotonic_patcher = mock.patch(\"time.monotonic\", return_value=0)\n\n        target = mock.AsyncMock(spec=[\"__call__\"], side_effect=[ValueError()] * 10)\n        # __name__ is needed by functools.partial.\n        target.__name__ = \"target\"\n\n        decorated = retry_(target, on_error=on_error)\n        target.assert_not_called()\n\n        with monotonic_patcher as patched_monotonic:\n            # Make sure that calls to fake asyncio.sleep() also advance the mocked\n            # time clock.\n            def increase_time(sleep_delay):\n                patched_monotonic.return_value += sleep_delay\n\n            sleep.side_effect = increase_time\n\n            with pytest.raises(exceptions.RetryError):\n                await decorated(\"meep\")\n\n        assert target.call_count == 5\n        target.assert_has_calls([mock.call(\"meep\")] * 5)\n        assert on_error.call_count == 5\n\n        # check the delays\n        assert sleep.call_count == 4  # once between each successive target calls\n        last_wait = sleep.call_args.args[0]\n        total_wait = sum(call_args.args[0] for call_args in sleep.call_args_list)\n\n        assert last_wait == 8.0\n        # Next attempt would be scheduled in 16 secs, 15 + 16 = 31 > 30.9, thus\n        # we do not even wait for it to be scheduled (30.9 is configured timeout).\n        # This changes the previous logic of shortening the last attempt to fit\n        # in the timeout. The previous logic was removed to make Python retry\n        # logic consistent with the other languages and to not disrupt the\n        # randomized retry delays distribution by artificially increasing a\n        # probability of scheduling two (instead of one) last attempts with very\n        # short delay between them, while the second retry having very low chance\n        # of succeeding anyways.\n        assert total_wait == 15.0\n\n    @mock.patch(\"asyncio.sleep\", autospec=True)\n    @pytest.mark.asyncio\n    async def test___init___without_retry_executed(self, sleep):\n        _some_function = mock.Mock()\n\n        retry_ = retry_async.AsyncRetry(\n            predicate=retry_async.if_exception_type(ValueError), on_error=_some_function\n        )\n        # check the proper creation of the class\n        assert retry_._on_error is _some_function\n\n        target = mock.AsyncMock(spec=[\"__call__\"], side_effect=[42])\n        # __name__ is needed by functools.partial.\n        target.__name__ = \"target\"\n\n        wrapped = retry_(target)\n\n        result = await wrapped(\"meep\")\n\n        assert result == 42\n        target.assert_called_once_with(\"meep\")\n        sleep.assert_not_called()\n        _some_function.assert_not_called()\n\n    @mock.patch(\"random.uniform\", autospec=True, side_effect=lambda m, n: n)\n    @mock.patch(\"asyncio.sleep\", autospec=True)\n    @pytest.mark.asyncio\n    async def test___init___when_retry_is_executed(self, sleep, uniform):\n        _some_function = mock.Mock()\n\n        retry_ = retry_async.AsyncRetry(\n            predicate=retry_async.if_exception_type(ValueError), on_error=_some_function\n        )\n        # check the proper creation of the class\n        assert retry_._on_error is _some_function\n\n        target = mock.AsyncMock(\n            spec=[\"__call__\"], side_effect=[ValueError(), ValueError(), 42]\n        )\n        # __name__ is needed by functools.partial.\n        target.__name__ = \"target\"\n\n        wrapped = retry_(target)\n        target.assert_not_called()\n\n        result = await wrapped(\"meep\")\n\n        assert result == 42\n        assert target.call_count == 3\n        assert _some_function.call_count == 2\n        target.assert_has_calls([mock.call(\"meep\"), mock.call(\"meep\")])\n        sleep.assert_any_call(retry_._initial)\n", "tests/asyncio/future/test_async_future.py": "# Copyright 2017, Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport asyncio\n\nimport mock\nimport pytest\n\nfrom google.api_core import exceptions\nfrom google.api_core.future import async_future\n\n\nclass AsyncFuture(async_future.AsyncFuture):\n    async def done(self):\n        return False\n\n    async def cancel(self):\n        return True\n\n    async def cancelled(self):\n        return False\n\n    async def running(self):\n        return True\n\n\n@pytest.mark.asyncio\nasync def test_polling_future_constructor():\n    future = AsyncFuture()\n    assert not await future.done()\n    assert not await future.cancelled()\n    assert await future.running()\n    assert await future.cancel()\n\n\n@pytest.mark.asyncio\nasync def test_set_result():\n    future = AsyncFuture()\n\n    future.set_result(1)\n\n    assert await future.result() == 1\n    callback_called = asyncio.Event()\n\n    def callback(unused_future):\n        callback_called.set()\n\n    future.add_done_callback(callback)\n    await callback_called.wait()\n\n\n@pytest.mark.asyncio\nasync def test_set_exception():\n    future = AsyncFuture()\n    exception = ValueError(\"meep\")\n\n    future.set_exception(exception)\n\n    assert await future.exception() == exception\n    with pytest.raises(ValueError):\n        await future.result()\n\n    callback_called = asyncio.Event()\n\n    def callback(unused_future):\n        callback_called.set()\n\n    future.add_done_callback(callback)\n    await callback_called.wait()\n\n\n@pytest.mark.asyncio\nasync def test_invoke_callback_exception():\n    future = AsyncFuture()\n    future.set_result(42)\n\n    # This should not raise, despite the callback causing an exception.\n    callback_called = asyncio.Event()\n\n    def callback(unused_future):\n        callback_called.set()\n        raise ValueError()\n\n    future.add_done_callback(callback)\n    await callback_called.wait()\n\n\nclass AsyncFutureWithPoll(AsyncFuture):\n    def __init__(self):\n        super().__init__()\n        self.poll_count = 0\n        self.event = asyncio.Event()\n\n    async def done(self):\n        self.poll_count += 1\n        await self.event.wait()\n        self.set_result(42)\n        return True\n\n\n@pytest.mark.asyncio\nasync def test_result_with_polling():\n    future = AsyncFutureWithPoll()\n\n    future.event.set()\n    result = await future.result()\n\n    assert result == 42\n    assert future.poll_count == 1\n    # Repeated calls should not cause additional polling\n    assert await future.result() == result\n    assert future.poll_count == 1\n\n\nclass AsyncFutureTimeout(AsyncFutureWithPoll):\n    async def done(self):\n        await asyncio.sleep(0.2)\n        return False\n\n\n@pytest.mark.asyncio\nasync def test_result_timeout():\n    future = AsyncFutureTimeout()\n    with pytest.raises(asyncio.TimeoutError):\n        await future.result(timeout=0.2)\n\n\n@pytest.mark.asyncio\nasync def test_exception_timeout():\n    future = AsyncFutureTimeout()\n    with pytest.raises(asyncio.TimeoutError):\n        await future.exception(timeout=0.2)\n\n\n@pytest.mark.asyncio\nasync def test_result_timeout_with_retry():\n    future = AsyncFutureTimeout()\n    with pytest.raises(asyncio.TimeoutError):\n        await future.exception(timeout=0.4)\n\n\nclass AsyncFutureTransient(AsyncFutureWithPoll):\n    def __init__(self, errors):\n        super().__init__()\n        self._errors = errors\n\n    async def done(self):\n        if self._errors:\n            error, self._errors = self._errors[0], self._errors[1:]\n            raise error(\"testing\")\n        self.poll_count += 1\n        self.set_result(42)\n        return True\n\n\n@mock.patch(\"asyncio.sleep\", autospec=True)\n@pytest.mark.asyncio\nasync def test_result_transient_error(unused_sleep):\n    future = AsyncFutureTransient(\n        (\n            exceptions.TooManyRequests,\n            exceptions.InternalServerError,\n            exceptions.BadGateway,\n        )\n    )\n    result = await future.result()\n    assert result == 42\n    assert future.poll_count == 1\n    # Repeated calls should not cause additional polling\n    assert await future.result() == result\n    assert future.poll_count == 1\n\n\n@pytest.mark.asyncio\nasync def test_callback_concurrency():\n    future = AsyncFutureWithPoll()\n\n    callback_called = asyncio.Event()\n\n    def callback(unused_future):\n        callback_called.set()\n\n    future.add_done_callback(callback)\n\n    # Give the thread a second to poll\n    await asyncio.sleep(1)\n    assert future.poll_count == 1\n\n    future.event.set()\n    await callback_called.wait()\n\n\n@pytest.mark.asyncio\nasync def test_double_callback_concurrency():\n    future = AsyncFutureWithPoll()\n\n    callback_called = asyncio.Event()\n\n    def callback(unused_future):\n        callback_called.set()\n\n    callback_called2 = asyncio.Event()\n\n    def callback2(unused_future):\n        callback_called2.set()\n\n    future.add_done_callback(callback)\n    future.add_done_callback(callback2)\n\n    # Give the thread a second to poll\n    await asyncio.sleep(1)\n    future.event.set()\n\n    assert future.poll_count == 1\n    await callback_called.wait()\n    await callback_called2.wait()\n", "tests/asyncio/future/__init__.py": "", "tests/unit/test_grpc_helpers.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport mock\nimport pytest\n\ntry:\n    import grpc\nexcept ImportError:  # pragma: NO COVER\n    pytest.skip(\"No GRPC\", allow_module_level=True)\n\nfrom google.api_core import exceptions\nfrom google.api_core import grpc_helpers\nimport google.auth.credentials\nfrom google.longrunning import operations_pb2\n\n\ndef test__patch_callable_name():\n    callable = mock.Mock(spec=[\"__class__\"])\n    callable.__class__ = mock.Mock(spec=[\"__name__\"])\n    callable.__class__.__name__ = \"TestCallable\"\n\n    grpc_helpers._patch_callable_name(callable)\n\n    assert callable.__name__ == \"TestCallable\"\n\n\ndef test__patch_callable_name_no_op():\n    callable = mock.Mock(spec=[\"__name__\"])\n    callable.__name__ = \"test_callable\"\n\n    grpc_helpers._patch_callable_name(callable)\n\n    assert callable.__name__ == \"test_callable\"\n\n\nclass RpcErrorImpl(grpc.RpcError, grpc.Call):\n    def __init__(self, code):\n        super(RpcErrorImpl, self).__init__()\n        self._code = code\n\n    def code(self):\n        return self._code\n\n    def details(self):\n        return None\n\n    def trailing_metadata(self):\n        return None\n\n\ndef test_wrap_unary_errors():\n    grpc_error = RpcErrorImpl(grpc.StatusCode.INVALID_ARGUMENT)\n    callable_ = mock.Mock(spec=[\"__call__\"], side_effect=grpc_error)\n\n    wrapped_callable = grpc_helpers._wrap_unary_errors(callable_)\n\n    with pytest.raises(exceptions.InvalidArgument) as exc_info:\n        wrapped_callable(1, 2, three=\"four\")\n\n    callable_.assert_called_once_with(1, 2, three=\"four\")\n    assert exc_info.value.response == grpc_error\n\n\nclass Test_StreamingResponseIterator:\n    @staticmethod\n    def _make_wrapped(*items):\n        return iter(items)\n\n    @staticmethod\n    def _make_one(wrapped, **kw):\n        return grpc_helpers._StreamingResponseIterator(wrapped, **kw)\n\n    def test_ctor_defaults(self):\n        wrapped = self._make_wrapped(\"a\", \"b\", \"c\")\n        iterator = self._make_one(wrapped)\n        assert iterator._stored_first_result == \"a\"\n        assert list(wrapped) == [\"b\", \"c\"]\n\n    def test_ctor_explicit(self):\n        wrapped = self._make_wrapped(\"a\", \"b\", \"c\")\n        iterator = self._make_one(wrapped, prefetch_first_result=False)\n        assert getattr(iterator, \"_stored_first_result\", self) is self\n        assert list(wrapped) == [\"a\", \"b\", \"c\"]\n\n    def test_ctor_w_rpc_error_on_prefetch(self):\n        wrapped = mock.MagicMock()\n        wrapped.__next__.side_effect = grpc.RpcError()\n\n        with pytest.raises(grpc.RpcError):\n            self._make_one(wrapped)\n\n    def test___iter__(self):\n        wrapped = self._make_wrapped(\"a\", \"b\", \"c\")\n        iterator = self._make_one(wrapped)\n        assert iter(iterator) is iterator\n\n    def test___next___w_cached_first_result(self):\n        wrapped = self._make_wrapped(\"a\", \"b\", \"c\")\n        iterator = self._make_one(wrapped)\n        assert next(iterator) == \"a\"\n        iterator = self._make_one(wrapped, prefetch_first_result=False)\n        assert next(iterator) == \"b\"\n        assert next(iterator) == \"c\"\n\n    def test___next___wo_cached_first_result(self):\n        wrapped = self._make_wrapped(\"a\", \"b\", \"c\")\n        iterator = self._make_one(wrapped, prefetch_first_result=False)\n        assert next(iterator) == \"a\"\n        assert next(iterator) == \"b\"\n        assert next(iterator) == \"c\"\n\n    def test___next___w_rpc_error(self):\n        wrapped = mock.MagicMock()\n        wrapped.__next__.side_effect = grpc.RpcError()\n        iterator = self._make_one(wrapped, prefetch_first_result=False)\n\n        with pytest.raises(exceptions.GoogleAPICallError):\n            next(iterator)\n\n    def test_add_callback(self):\n        wrapped = mock.MagicMock()\n        callback = mock.Mock(spec={})\n        iterator = self._make_one(wrapped, prefetch_first_result=False)\n\n        assert iterator.add_callback(callback) is wrapped.add_callback.return_value\n\n        wrapped.add_callback.assert_called_once_with(callback)\n\n    def test_cancel(self):\n        wrapped = mock.MagicMock()\n        iterator = self._make_one(wrapped, prefetch_first_result=False)\n\n        assert iterator.cancel() is wrapped.cancel.return_value\n\n        wrapped.cancel.assert_called_once_with()\n\n    def test_code(self):\n        wrapped = mock.MagicMock()\n        iterator = self._make_one(wrapped, prefetch_first_result=False)\n\n        assert iterator.code() is wrapped.code.return_value\n\n        wrapped.code.assert_called_once_with()\n\n    def test_details(self):\n        wrapped = mock.MagicMock()\n        iterator = self._make_one(wrapped, prefetch_first_result=False)\n\n        assert iterator.details() is wrapped.details.return_value\n\n        wrapped.details.assert_called_once_with()\n\n    def test_initial_metadata(self):\n        wrapped = mock.MagicMock()\n        iterator = self._make_one(wrapped, prefetch_first_result=False)\n\n        assert iterator.initial_metadata() is wrapped.initial_metadata.return_value\n\n        wrapped.initial_metadata.assert_called_once_with()\n\n    def test_is_active(self):\n        wrapped = mock.MagicMock()\n        iterator = self._make_one(wrapped, prefetch_first_result=False)\n\n        assert iterator.is_active() is wrapped.is_active.return_value\n\n        wrapped.is_active.assert_called_once_with()\n\n    def test_time_remaining(self):\n        wrapped = mock.MagicMock()\n        iterator = self._make_one(wrapped, prefetch_first_result=False)\n\n        assert iterator.time_remaining() is wrapped.time_remaining.return_value\n\n        wrapped.time_remaining.assert_called_once_with()\n\n    def test_trailing_metadata(self):\n        wrapped = mock.MagicMock()\n        iterator = self._make_one(wrapped, prefetch_first_result=False)\n\n        assert iterator.trailing_metadata() is wrapped.trailing_metadata.return_value\n\n        wrapped.trailing_metadata.assert_called_once_with()\n\n\nclass TestGrpcStream(Test_StreamingResponseIterator):\n    @staticmethod\n    def _make_one(wrapped, **kw):\n        return grpc_helpers.GrpcStream(wrapped, **kw)\n\n    def test_grpc_stream_attributes(self):\n        \"\"\"\n        Should be both a grpc.Call and an iterable\n        \"\"\"\n        call = self._make_one(None)\n        assert isinstance(call, grpc.Call)\n        # should implement __iter__\n        assert hasattr(call, \"__iter__\")\n        it = call.__iter__()\n        assert hasattr(it, \"__next__\")\n\n\ndef test_wrap_stream_okay():\n    expected_responses = [1, 2, 3]\n    callable_ = mock.Mock(spec=[\"__call__\"], return_value=iter(expected_responses))\n\n    wrapped_callable = grpc_helpers._wrap_stream_errors(callable_)\n\n    got_iterator = wrapped_callable(1, 2, three=\"four\")\n\n    responses = list(got_iterator)\n\n    callable_.assert_called_once_with(1, 2, three=\"four\")\n    assert responses == expected_responses\n\n\ndef test_wrap_stream_prefetch_disabled():\n    responses = [1, 2, 3]\n    iter_responses = iter(responses)\n    callable_ = mock.Mock(spec=[\"__call__\"], return_value=iter_responses)\n    callable_._prefetch_first_result_ = False\n\n    wrapped_callable = grpc_helpers._wrap_stream_errors(callable_)\n    wrapped_callable(1, 2, three=\"four\")\n\n    assert list(iter_responses) == responses  # no items should have been pre-fetched\n    callable_.assert_called_once_with(1, 2, three=\"four\")\n\n\ndef test_wrap_stream_iterable_interface():\n    response_iter = mock.create_autospec(grpc.Call, instance=True)\n    callable_ = mock.Mock(spec=[\"__call__\"], return_value=response_iter)\n\n    wrapped_callable = grpc_helpers._wrap_stream_errors(callable_)\n\n    got_iterator = wrapped_callable()\n\n    callable_.assert_called_once_with()\n\n    # Check each aliased method in the grpc.Call interface\n    got_iterator.add_callback(mock.sentinel.callback)\n    response_iter.add_callback.assert_called_once_with(mock.sentinel.callback)\n\n    got_iterator.cancel()\n    response_iter.cancel.assert_called_once_with()\n\n    got_iterator.code()\n    response_iter.code.assert_called_once_with()\n\n    got_iterator.details()\n    response_iter.details.assert_called_once_with()\n\n    got_iterator.initial_metadata()\n    response_iter.initial_metadata.assert_called_once_with()\n\n    got_iterator.is_active()\n    response_iter.is_active.assert_called_once_with()\n\n    got_iterator.time_remaining()\n    response_iter.time_remaining.assert_called_once_with()\n\n    got_iterator.trailing_metadata()\n    response_iter.trailing_metadata.assert_called_once_with()\n\n\ndef test_wrap_stream_errors_invocation():\n    grpc_error = RpcErrorImpl(grpc.StatusCode.INVALID_ARGUMENT)\n    callable_ = mock.Mock(spec=[\"__call__\"], side_effect=grpc_error)\n\n    wrapped_callable = grpc_helpers._wrap_stream_errors(callable_)\n\n    with pytest.raises(exceptions.InvalidArgument) as exc_info:\n        wrapped_callable(1, 2, three=\"four\")\n\n    callable_.assert_called_once_with(1, 2, three=\"four\")\n    assert exc_info.value.response == grpc_error\n\n\ndef test_wrap_stream_empty_iterator():\n    expected_responses = []\n    callable_ = mock.Mock(spec=[\"__call__\"], return_value=iter(expected_responses))\n\n    wrapped_callable = grpc_helpers._wrap_stream_errors(callable_)\n\n    got_iterator = wrapped_callable()\n\n    responses = list(got_iterator)\n\n    callable_.assert_called_once_with()\n    assert responses == expected_responses\n\n\nclass RpcResponseIteratorImpl(object):\n    def __init__(self, iterable):\n        self._iterable = iter(iterable)\n\n    def next(self):\n        next_item = next(self._iterable)\n        if isinstance(next_item, RpcErrorImpl):\n            raise next_item\n        return next_item\n\n    __next__ = next\n\n\ndef test_wrap_stream_errors_iterator_initialization():\n    grpc_error = RpcErrorImpl(grpc.StatusCode.UNAVAILABLE)\n    response_iter = RpcResponseIteratorImpl([grpc_error])\n    callable_ = mock.Mock(spec=[\"__call__\"], return_value=response_iter)\n\n    wrapped_callable = grpc_helpers._wrap_stream_errors(callable_)\n\n    with pytest.raises(exceptions.ServiceUnavailable) as exc_info:\n        wrapped_callable(1, 2, three=\"four\")\n\n    callable_.assert_called_once_with(1, 2, three=\"four\")\n    assert exc_info.value.response == grpc_error\n\n\ndef test_wrap_stream_errors_during_iteration():\n    grpc_error = RpcErrorImpl(grpc.StatusCode.UNAVAILABLE)\n    response_iter = RpcResponseIteratorImpl([1, grpc_error])\n    callable_ = mock.Mock(spec=[\"__call__\"], return_value=response_iter)\n\n    wrapped_callable = grpc_helpers._wrap_stream_errors(callable_)\n    got_iterator = wrapped_callable(1, 2, three=\"four\")\n    next(got_iterator)\n\n    with pytest.raises(exceptions.ServiceUnavailable) as exc_info:\n        next(got_iterator)\n\n    callable_.assert_called_once_with(1, 2, three=\"four\")\n    assert exc_info.value.response == grpc_error\n\n\n@mock.patch(\"google.api_core.grpc_helpers._wrap_unary_errors\")\ndef test_wrap_errors_non_streaming(wrap_unary_errors):\n    callable_ = mock.create_autospec(grpc.UnaryUnaryMultiCallable)\n\n    result = grpc_helpers.wrap_errors(callable_)\n\n    assert result == wrap_unary_errors.return_value\n    wrap_unary_errors.assert_called_once_with(callable_)\n\n\n@mock.patch(\"google.api_core.grpc_helpers._wrap_stream_errors\")\ndef test_wrap_errors_streaming(wrap_stream_errors):\n    callable_ = mock.create_autospec(grpc.UnaryStreamMultiCallable)\n\n    result = grpc_helpers.wrap_errors(callable_)\n\n    assert result == wrap_stream_errors.return_value\n    wrap_stream_errors.assert_called_once_with(callable_)\n\n\n@pytest.mark.parametrize(\n    \"attempt_direct_path,target,expected_target\",\n    [\n        (None, \"example.com:443\", \"example.com:443\"),\n        (False, \"example.com:443\", \"example.com:443\"),\n        (True, \"example.com:443\", \"google-c2p:///example.com\"),\n        (True, \"dns:///example.com\", \"google-c2p:///example.com\"),\n        (True, \"another-c2p:///example.com\", \"another-c2p:///example.com\"),\n    ],\n)\n@mock.patch(\"grpc.compute_engine_channel_credentials\")\n@mock.patch(\n    \"google.auth.default\",\n    autospec=True,\n    return_value=(mock.sentinel.credentials, mock.sentinel.project),\n)\n@mock.patch(\"grpc.secure_channel\")\ndef test_create_channel_implicit(\n    grpc_secure_channel,\n    google_auth_default,\n    composite_creds_call,\n    attempt_direct_path,\n    target,\n    expected_target,\n):\n    composite_creds = composite_creds_call.return_value\n\n    channel = grpc_helpers.create_channel(\n        target,\n        compression=grpc.Compression.Gzip,\n        attempt_direct_path=attempt_direct_path,\n    )\n\n    assert channel is grpc_secure_channel.return_value\n\n    google_auth_default.assert_called_once_with(scopes=None, default_scopes=None)\n\n    if grpc_helpers.HAS_GRPC_GCP:  # pragma: NO COVER\n        # The original target is the expected target\n        expected_target = target\n        grpc_secure_channel.assert_called_once_with(\n            expected_target, composite_creds, None\n        )\n    else:\n        grpc_secure_channel.assert_called_once_with(\n            expected_target, composite_creds, compression=grpc.Compression.Gzip\n        )\n\n\n@pytest.mark.parametrize(\n    \"attempt_direct_path,target, expected_target\",\n    [\n        (None, \"example.com:443\", \"example.com:443\"),\n        (False, \"example.com:443\", \"example.com:443\"),\n        (True, \"example.com:443\", \"google-c2p:///example.com\"),\n        (True, \"dns:///example.com\", \"google-c2p:///example.com\"),\n        (True, \"another-c2p:///example.com\", \"another-c2p:///example.com\"),\n    ],\n)\n@mock.patch(\"google.auth.transport.grpc.AuthMetadataPlugin\", autospec=True)\n@mock.patch(\n    \"google.auth.transport.requests.Request\",\n    autospec=True,\n    return_value=mock.sentinel.Request,\n)\n@mock.patch(\"grpc.compute_engine_channel_credentials\")\n@mock.patch(\n    \"google.auth.default\",\n    autospec=True,\n    return_value=(mock.sentinel.credentials, mock.sentinel.project),\n)\n@mock.patch(\"grpc.secure_channel\")\ndef test_create_channel_implicit_with_default_host(\n    grpc_secure_channel,\n    google_auth_default,\n    composite_creds_call,\n    request,\n    auth_metadata_plugin,\n    attempt_direct_path,\n    target,\n    expected_target,\n):\n    default_host = \"example.com\"\n    composite_creds = composite_creds_call.return_value\n\n    channel = grpc_helpers.create_channel(\n        target, default_host=default_host, attempt_direct_path=attempt_direct_path\n    )\n\n    assert channel is grpc_secure_channel.return_value\n\n    google_auth_default.assert_called_once_with(scopes=None, default_scopes=None)\n    auth_metadata_plugin.assert_called_once_with(\n        mock.sentinel.credentials, mock.sentinel.Request, default_host=default_host\n    )\n\n    if grpc_helpers.HAS_GRPC_GCP:  # pragma: NO COVER\n        # The original target is the expected target\n        expected_target = target\n        grpc_secure_channel.assert_called_once_with(\n            expected_target, composite_creds, None\n        )\n    else:\n        grpc_secure_channel.assert_called_once_with(\n            expected_target, composite_creds, compression=None\n        )\n\n\n@pytest.mark.parametrize(\n    \"attempt_direct_path\",\n    [\n        None,\n        False,\n    ],\n)\n@mock.patch(\"grpc.composite_channel_credentials\")\n@mock.patch(\n    \"google.auth.default\",\n    autospec=True,\n    return_value=(mock.sentinel.credentials, mock.sentinel.project),\n)\n@mock.patch(\"grpc.secure_channel\")\ndef test_create_channel_implicit_with_ssl_creds(\n    grpc_secure_channel, default, composite_creds_call, attempt_direct_path\n):\n    target = \"example.com:443\"\n\n    ssl_creds = grpc.ssl_channel_credentials()\n\n    grpc_helpers.create_channel(\n        target, ssl_credentials=ssl_creds, attempt_direct_path=attempt_direct_path\n    )\n\n    default.assert_called_once_with(scopes=None, default_scopes=None)\n\n    composite_creds_call.assert_called_once_with(ssl_creds, mock.ANY)\n    composite_creds = composite_creds_call.return_value\n\n    if grpc_helpers.HAS_GRPC_GCP:  # pragma: NO COVER\n        grpc_secure_channel.assert_called_once_with(target, composite_creds, None)\n    else:\n        grpc_secure_channel.assert_called_once_with(\n            target, composite_creds, compression=None\n        )\n\n\ndef test_create_channel_implicit_with_ssl_creds_attempt_direct_path_true():\n    target = \"example.com:443\"\n    ssl_creds = grpc.ssl_channel_credentials()\n    with pytest.raises(\n        ValueError, match=\"Using ssl_credentials with Direct Path is not supported\"\n    ):\n        grpc_helpers.create_channel(\n            target, ssl_credentials=ssl_creds, attempt_direct_path=True\n        )\n\n\n@mock.patch(\"grpc.compute_engine_channel_credentials\")\n@mock.patch(\n    \"google.auth.default\",\n    autospec=True,\n    return_value=(mock.sentinel.credentials, mock.sentinel.project),\n)\n@mock.patch(\"grpc.secure_channel\")\ndef test_create_channel_implicit_with_scopes(\n    grpc_secure_channel, default, composite_creds_call\n):\n    target = \"example.com:443\"\n    composite_creds = composite_creds_call.return_value\n\n    channel = grpc_helpers.create_channel(target, scopes=[\"one\", \"two\"])\n\n    assert channel is grpc_secure_channel.return_value\n\n    default.assert_called_once_with(scopes=[\"one\", \"two\"], default_scopes=None)\n\n    if grpc_helpers.HAS_GRPC_GCP:  # pragma: NO COVER\n        grpc_secure_channel.assert_called_once_with(target, composite_creds, None)\n    else:\n        grpc_secure_channel.assert_called_once_with(\n            target, composite_creds, compression=None\n        )\n\n\n@mock.patch(\"grpc.compute_engine_channel_credentials\")\n@mock.patch(\n    \"google.auth.default\",\n    autospec=True,\n    return_value=(mock.sentinel.credentials, mock.sentinel.project),\n)\n@mock.patch(\"grpc.secure_channel\")\ndef test_create_channel_implicit_with_default_scopes(\n    grpc_secure_channel, default, composite_creds_call\n):\n    target = \"example.com:443\"\n    composite_creds = composite_creds_call.return_value\n\n    channel = grpc_helpers.create_channel(target, default_scopes=[\"three\", \"four\"])\n\n    assert channel is grpc_secure_channel.return_value\n\n    default.assert_called_once_with(scopes=None, default_scopes=[\"three\", \"four\"])\n\n    if grpc_helpers.HAS_GRPC_GCP:  # pragma: NO COVER\n        grpc_secure_channel.assert_called_once_with(target, composite_creds, None)\n    else:\n        grpc_secure_channel.assert_called_once_with(\n            target, composite_creds, compression=None\n        )\n\n\ndef test_create_channel_explicit_with_duplicate_credentials():\n    target = \"example.com:443\"\n\n    with pytest.raises(exceptions.DuplicateCredentialArgs):\n        grpc_helpers.create_channel(\n            target,\n            credentials_file=\"credentials.json\",\n            credentials=mock.sentinel.credentials,\n        )\n\n\n@mock.patch(\"grpc.compute_engine_channel_credentials\")\n@mock.patch(\"google.auth.credentials.with_scopes_if_required\", autospec=True)\n@mock.patch(\"grpc.secure_channel\")\ndef test_create_channel_explicit(grpc_secure_channel, auth_creds, composite_creds_call):\n    target = \"example.com:443\"\n    composite_creds = composite_creds_call.return_value\n\n    channel = grpc_helpers.create_channel(target, credentials=mock.sentinel.credentials)\n\n    auth_creds.assert_called_once_with(\n        mock.sentinel.credentials, scopes=None, default_scopes=None\n    )\n\n    assert channel is grpc_secure_channel.return_value\n\n    if grpc_helpers.HAS_GRPC_GCP:  # pragma: NO COVER\n        grpc_secure_channel.assert_called_once_with(target, composite_creds, None)\n    else:\n        grpc_secure_channel.assert_called_once_with(\n            target, composite_creds, compression=None\n        )\n\n\n@mock.patch(\"grpc.compute_engine_channel_credentials\")\n@mock.patch(\"grpc.secure_channel\")\ndef test_create_channel_explicit_scoped(grpc_secure_channel, composite_creds_call):\n    target = \"example.com:443\"\n    scopes = [\"1\", \"2\"]\n    composite_creds = composite_creds_call.return_value\n\n    credentials = mock.create_autospec(google.auth.credentials.Scoped, instance=True)\n    credentials.requires_scopes = True\n\n    channel = grpc_helpers.create_channel(\n        target, credentials=credentials, scopes=scopes\n    )\n\n    credentials.with_scopes.assert_called_once_with(scopes, default_scopes=None)\n\n    assert channel is grpc_secure_channel.return_value\n\n    if grpc_helpers.HAS_GRPC_GCP:  # pragma: NO COVER\n        grpc_secure_channel.assert_called_once_with(target, composite_creds, None)\n    else:\n        grpc_secure_channel.assert_called_once_with(\n            target, composite_creds, compression=None\n        )\n\n\n@mock.patch(\"grpc.compute_engine_channel_credentials\")\n@mock.patch(\"grpc.secure_channel\")\ndef test_create_channel_explicit_default_scopes(\n    grpc_secure_channel, composite_creds_call\n):\n    target = \"example.com:443\"\n    default_scopes = [\"3\", \"4\"]\n    composite_creds = composite_creds_call.return_value\n\n    credentials = mock.create_autospec(google.auth.credentials.Scoped, instance=True)\n    credentials.requires_scopes = True\n\n    channel = grpc_helpers.create_channel(\n        target, credentials=credentials, default_scopes=default_scopes\n    )\n\n    credentials.with_scopes.assert_called_once_with(\n        scopes=None, default_scopes=default_scopes\n    )\n\n    assert channel is grpc_secure_channel.return_value\n\n    if grpc_helpers.HAS_GRPC_GCP:  # pragma: NO COVER\n        grpc_secure_channel.assert_called_once_with(target, composite_creds, None)\n    else:\n        grpc_secure_channel.assert_called_once_with(\n            target, composite_creds, compression=None\n        )\n\n\n@mock.patch(\"grpc.compute_engine_channel_credentials\")\n@mock.patch(\"grpc.secure_channel\")\ndef test_create_channel_explicit_with_quota_project(\n    grpc_secure_channel, composite_creds_call\n):\n    target = \"example.com:443\"\n    composite_creds = composite_creds_call.return_value\n\n    credentials = mock.create_autospec(\n        google.auth.credentials.CredentialsWithQuotaProject, instance=True\n    )\n\n    channel = grpc_helpers.create_channel(\n        target, credentials=credentials, quota_project_id=\"project-foo\"\n    )\n\n    credentials.with_quota_project.assert_called_once_with(\"project-foo\")\n\n    assert channel is grpc_secure_channel.return_value\n\n    if grpc_helpers.HAS_GRPC_GCP:  # pragma: NO COVER\n        grpc_secure_channel.assert_called_once_with(target, composite_creds, None)\n    else:\n        grpc_secure_channel.assert_called_once_with(\n            target, composite_creds, compression=None\n        )\n\n\n@mock.patch(\"grpc.compute_engine_channel_credentials\")\n@mock.patch(\"grpc.secure_channel\")\n@mock.patch(\n    \"google.auth.load_credentials_from_file\",\n    autospec=True,\n    return_value=(mock.sentinel.credentials, mock.sentinel.project),\n)\ndef test_create_channel_with_credentials_file(\n    load_credentials_from_file, grpc_secure_channel, composite_creds_call\n):\n    target = \"example.com:443\"\n\n    credentials_file = \"/path/to/credentials/file.json\"\n    composite_creds = composite_creds_call.return_value\n\n    channel = grpc_helpers.create_channel(target, credentials_file=credentials_file)\n\n    google.auth.load_credentials_from_file.assert_called_once_with(\n        credentials_file, scopes=None, default_scopes=None\n    )\n\n    assert channel is grpc_secure_channel.return_value\n\n    if grpc_helpers.HAS_GRPC_GCP:  # pragma: NO COVER\n        grpc_secure_channel.assert_called_once_with(target, composite_creds, None)\n    else:\n        grpc_secure_channel.assert_called_once_with(\n            target, composite_creds, compression=None\n        )\n\n\n@mock.patch(\"grpc.compute_engine_channel_credentials\")\n@mock.patch(\"grpc.secure_channel\")\n@mock.patch(\n    \"google.auth.load_credentials_from_file\",\n    autospec=True,\n    return_value=(mock.sentinel.credentials, mock.sentinel.project),\n)\ndef test_create_channel_with_credentials_file_and_scopes(\n    load_credentials_from_file, grpc_secure_channel, composite_creds_call\n):\n    target = \"example.com:443\"\n    scopes = [\"1\", \"2\"]\n\n    credentials_file = \"/path/to/credentials/file.json\"\n    composite_creds = composite_creds_call.return_value\n\n    channel = grpc_helpers.create_channel(\n        target, credentials_file=credentials_file, scopes=scopes\n    )\n\n    google.auth.load_credentials_from_file.assert_called_once_with(\n        credentials_file, scopes=scopes, default_scopes=None\n    )\n\n    assert channel is grpc_secure_channel.return_value\n\n    if grpc_helpers.HAS_GRPC_GCP:  # pragma: NO COVER\n        grpc_secure_channel.assert_called_once_with(target, composite_creds, None)\n    else:\n        grpc_secure_channel.assert_called_once_with(\n            target, composite_creds, compression=None\n        )\n\n\n@mock.patch(\"grpc.compute_engine_channel_credentials\")\n@mock.patch(\"grpc.secure_channel\")\n@mock.patch(\n    \"google.auth.load_credentials_from_file\",\n    autospec=True,\n    return_value=(mock.sentinel.credentials, mock.sentinel.project),\n)\ndef test_create_channel_with_credentials_file_and_default_scopes(\n    load_credentials_from_file, grpc_secure_channel, composite_creds_call\n):\n    target = \"example.com:443\"\n    default_scopes = [\"3\", \"4\"]\n\n    credentials_file = \"/path/to/credentials/file.json\"\n    composite_creds = composite_creds_call.return_value\n\n    channel = grpc_helpers.create_channel(\n        target, credentials_file=credentials_file, default_scopes=default_scopes\n    )\n\n    load_credentials_from_file.assert_called_once_with(\n        credentials_file, scopes=None, default_scopes=default_scopes\n    )\n\n    assert channel is grpc_secure_channel.return_value\n\n    if grpc_helpers.HAS_GRPC_GCP:  # pragma: NO COVER\n        grpc_secure_channel.assert_called_once_with(target, composite_creds, None)\n    else:\n        grpc_secure_channel.assert_called_once_with(\n            target, composite_creds, compression=None\n        )\n\n\n@pytest.mark.skipif(\n    not grpc_helpers.HAS_GRPC_GCP, reason=\"grpc_gcp module not available\"\n)\n@mock.patch(\"grpc_gcp.secure_channel\")\ndef test_create_channel_with_grpc_gcp(grpc_gcp_secure_channel):  # pragma: NO COVER\n    target = \"example.com:443\"\n    scopes = [\"test_scope\"]\n\n    credentials = mock.create_autospec(google.auth.credentials.Scoped, instance=True)\n    credentials.requires_scopes = True\n\n    grpc_helpers.create_channel(target, credentials=credentials, scopes=scopes)\n    grpc_gcp_secure_channel.assert_called()\n\n    credentials.with_scopes.assert_called_once_with(scopes, default_scopes=None)\n\n\n@pytest.mark.skipif(grpc_helpers.HAS_GRPC_GCP, reason=\"grpc_gcp module not available\")\n@mock.patch(\"grpc.secure_channel\")\ndef test_create_channel_without_grpc_gcp(grpc_secure_channel):\n    target = \"example.com:443\"\n    scopes = [\"test_scope\"]\n\n    credentials = mock.create_autospec(google.auth.credentials.Scoped, instance=True)\n    credentials.requires_scopes = True\n\n    grpc_helpers.create_channel(target, credentials=credentials, scopes=scopes)\n    grpc_secure_channel.assert_called()\n\n    credentials.with_scopes.assert_called_once_with(scopes, default_scopes=None)\n\n\nclass TestChannelStub(object):\n    def test_single_response(self):\n        channel = grpc_helpers.ChannelStub()\n        stub = operations_pb2.OperationsStub(channel)\n        expected_request = operations_pb2.GetOperationRequest(name=\"meep\")\n        expected_response = operations_pb2.Operation(name=\"moop\")\n\n        channel.GetOperation.response = expected_response\n\n        response = stub.GetOperation(expected_request)\n\n        assert response == expected_response\n        assert channel.requests == [(\"GetOperation\", expected_request)]\n        assert channel.GetOperation.requests == [expected_request]\n\n    def test_no_response(self):\n        channel = grpc_helpers.ChannelStub()\n        stub = operations_pb2.OperationsStub(channel)\n        expected_request = operations_pb2.GetOperationRequest(name=\"meep\")\n\n        with pytest.raises(ValueError) as exc_info:\n            stub.GetOperation(expected_request)\n\n        assert exc_info.match(\"GetOperation\")\n\n    def test_missing_method(self):\n        channel = grpc_helpers.ChannelStub()\n\n        with pytest.raises(AttributeError):\n            channel.DoesNotExist.response\n\n    def test_exception_response(self):\n        channel = grpc_helpers.ChannelStub()\n        stub = operations_pb2.OperationsStub(channel)\n        expected_request = operations_pb2.GetOperationRequest(name=\"meep\")\n\n        channel.GetOperation.response = RuntimeError()\n\n        with pytest.raises(RuntimeError):\n            stub.GetOperation(expected_request)\n\n    def test_callable_response(self):\n        channel = grpc_helpers.ChannelStub()\n        stub = operations_pb2.OperationsStub(channel)\n        expected_request = operations_pb2.GetOperationRequest(name=\"meep\")\n        expected_response = operations_pb2.Operation(name=\"moop\")\n\n        on_get_operation = mock.Mock(spec=(\"__call__\",), return_value=expected_response)\n\n        channel.GetOperation.response = on_get_operation\n\n        response = stub.GetOperation(expected_request)\n\n        assert response == expected_response\n        on_get_operation.assert_called_once_with(expected_request)\n\n    def test_multiple_responses(self):\n        channel = grpc_helpers.ChannelStub()\n        stub = operations_pb2.OperationsStub(channel)\n        expected_request = operations_pb2.GetOperationRequest(name=\"meep\")\n        expected_responses = [\n            operations_pb2.Operation(name=\"foo\"),\n            operations_pb2.Operation(name=\"bar\"),\n            operations_pb2.Operation(name=\"baz\"),\n        ]\n\n        channel.GetOperation.responses = iter(expected_responses)\n\n        response1 = stub.GetOperation(expected_request)\n        response2 = stub.GetOperation(expected_request)\n        response3 = stub.GetOperation(expected_request)\n\n        assert response1 == expected_responses[0]\n        assert response2 == expected_responses[1]\n        assert response3 == expected_responses[2]\n        assert channel.requests == [(\"GetOperation\", expected_request)] * 3\n        assert channel.GetOperation.requests == [expected_request] * 3\n\n        with pytest.raises(StopIteration):\n            stub.GetOperation(expected_request)\n\n    def test_multiple_responses_and_single_response_error(self):\n        channel = grpc_helpers.ChannelStub()\n        stub = operations_pb2.OperationsStub(channel)\n        channel.GetOperation.responses = []\n        channel.GetOperation.response = mock.sentinel.response\n\n        with pytest.raises(ValueError):\n            stub.GetOperation(operations_pb2.GetOperationRequest())\n\n    def test_call_info(self):\n        channel = grpc_helpers.ChannelStub()\n        stub = operations_pb2.OperationsStub(channel)\n        expected_request = operations_pb2.GetOperationRequest(name=\"meep\")\n        expected_response = operations_pb2.Operation(name=\"moop\")\n        expected_compression = grpc.Compression.NoCompression\n        expected_metadata = [(\"red\", \"blue\"), (\"two\", \"shoe\")]\n        expected_credentials = mock.sentinel.credentials\n        channel.GetOperation.response = expected_response\n\n        response = stub.GetOperation(\n            expected_request,\n            timeout=42,\n            compression=expected_compression,\n            metadata=expected_metadata,\n            credentials=expected_credentials,\n        )\n\n        assert response == expected_response\n        assert channel.requests == [(\"GetOperation\", expected_request)]\n        assert channel.GetOperation.calls == [\n            (\n                expected_request,\n                42,\n                expected_metadata,\n                expected_credentials,\n                expected_compression,\n            )\n        ]\n\n    def test_unary_unary(self):\n        channel = grpc_helpers.ChannelStub()\n        method_name = \"GetOperation\"\n        callable_stub = channel.unary_unary(method_name)\n        assert callable_stub._method == method_name\n        assert callable_stub._channel == channel\n\n    def test_unary_stream(self):\n        channel = grpc_helpers.ChannelStub()\n        method_name = \"GetOperation\"\n        callable_stub = channel.unary_stream(method_name)\n        assert callable_stub._method == method_name\n        assert callable_stub._channel == channel\n\n    def test_stream_unary(self):\n        channel = grpc_helpers.ChannelStub()\n        method_name = \"GetOperation\"\n        callable_stub = channel.stream_unary(method_name)\n        assert callable_stub._method == method_name\n        assert callable_stub._channel == channel\n\n    def test_stream_stream(self):\n        channel = grpc_helpers.ChannelStub()\n        method_name = \"GetOperation\"\n        callable_stub = channel.stream_stream(method_name)\n        assert callable_stub._method == method_name\n        assert callable_stub._channel == channel\n\n    def test_subscribe_unsubscribe(self):\n        channel = grpc_helpers.ChannelStub()\n        assert channel.subscribe(None) is None\n        assert channel.unsubscribe(None) is None\n\n    def test_close(self):\n        channel = grpc_helpers.ChannelStub()\n        assert channel.close() is None\n", "tests/unit/test_universe.py": "# Copyright 2024 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport pytest\nfrom google.api_core import universe\n\n\nclass _Fake_Credentials:\n    def __init__(self, universe_domain=None):\n        if universe_domain:\n            self.universe_domain = universe_domain\n\n\ndef test_determine_domain():\n    domain_client = \"foo.com\"\n    domain_env = \"bar.com\"\n\n    assert universe.determine_domain(domain_client, domain_env) == domain_client\n    assert universe.determine_domain(None, domain_env) == domain_env\n    assert universe.determine_domain(domain_client, None) == domain_client\n    assert universe.determine_domain(None, None) == universe.DEFAULT_UNIVERSE\n\n    with pytest.raises(universe.EmptyUniverseError):\n        universe.determine_domain(\"\", None)\n\n    with pytest.raises(universe.EmptyUniverseError):\n        universe.determine_domain(None, \"\")\n\n\ndef test_compare_domains():\n    fake_domain = \"foo.com\"\n    another_fake_domain = \"bar.com\"\n\n    assert universe.compare_domains(universe.DEFAULT_UNIVERSE, _Fake_Credentials())\n    assert universe.compare_domains(fake_domain, _Fake_Credentials(fake_domain))\n\n    with pytest.raises(universe.UniverseMismatchError) as excinfo:\n        universe.compare_domains(\n            universe.DEFAULT_UNIVERSE, _Fake_Credentials(fake_domain)\n        )\n    assert str(excinfo.value).find(universe.DEFAULT_UNIVERSE) >= 0\n    assert str(excinfo.value).find(fake_domain) >= 0\n\n    with pytest.raises(universe.UniverseMismatchError) as excinfo:\n        universe.compare_domains(fake_domain, _Fake_Credentials())\n    assert str(excinfo.value).find(fake_domain) >= 0\n    assert str(excinfo.value).find(universe.DEFAULT_UNIVERSE) >= 0\n\n    with pytest.raises(universe.UniverseMismatchError) as excinfo:\n        universe.compare_domains(fake_domain, _Fake_Credentials(another_fake_domain))\n    assert str(excinfo.value).find(fake_domain) >= 0\n    assert str(excinfo.value).find(another_fake_domain) >= 0\n", "tests/unit/test_version_header.py": "# Copyright 2024 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport pytest\n\nfrom google.api_core import version_header\n\n\n@pytest.mark.parametrize(\"version_identifier\", [\"some_value\", \"\"])\ndef test_to_api_version_header(version_identifier):\n    value = version_header.to_api_version_header(version_identifier)\n    assert value == (version_header.API_VERSION_METADATA_KEY, version_identifier)\n", "tests/unit/test_client_options.py": "# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom re import match\nimport pytest\n\nfrom google.api_core import client_options\n\n\ndef get_client_cert():\n    return b\"cert\", b\"key\"\n\n\ndef get_client_encrypted_cert():\n    return \"cert_path\", \"key_path\", b\"passphrase\"\n\n\ndef test_constructor():\n\n    options = client_options.ClientOptions(\n        api_endpoint=\"foo.googleapis.com\",\n        client_cert_source=get_client_cert,\n        quota_project_id=\"quote-proj\",\n        credentials_file=\"path/to/credentials.json\",\n        scopes=[\n            \"https://www.googleapis.com/auth/cloud-platform\",\n            \"https://www.googleapis.com/auth/cloud-platform.read-only\",\n        ],\n        api_audience=\"foo2.googleapis.com\",\n        universe_domain=\"googleapis.com\",\n    )\n\n    assert options.api_endpoint == \"foo.googleapis.com\"\n    assert options.client_cert_source() == (b\"cert\", b\"key\")\n    assert options.quota_project_id == \"quote-proj\"\n    assert options.credentials_file == \"path/to/credentials.json\"\n    assert options.scopes == [\n        \"https://www.googleapis.com/auth/cloud-platform\",\n        \"https://www.googleapis.com/auth/cloud-platform.read-only\",\n    ]\n    assert options.api_audience == \"foo2.googleapis.com\"\n    assert options.universe_domain == \"googleapis.com\"\n\n\ndef test_constructor_with_encrypted_cert_source():\n\n    options = client_options.ClientOptions(\n        api_endpoint=\"foo.googleapis.com\",\n        client_encrypted_cert_source=get_client_encrypted_cert,\n    )\n\n    assert options.api_endpoint == \"foo.googleapis.com\"\n    assert options.client_encrypted_cert_source() == (\n        \"cert_path\",\n        \"key_path\",\n        b\"passphrase\",\n    )\n\n\ndef test_constructor_with_both_cert_sources():\n    with pytest.raises(ValueError):\n        client_options.ClientOptions(\n            api_endpoint=\"foo.googleapis.com\",\n            client_cert_source=get_client_cert,\n            client_encrypted_cert_source=get_client_encrypted_cert,\n        )\n\n\ndef test_constructor_with_api_key():\n\n    options = client_options.ClientOptions(\n        api_endpoint=\"foo.googleapis.com\",\n        client_cert_source=get_client_cert,\n        quota_project_id=\"quote-proj\",\n        api_key=\"api-key\",\n        scopes=[\n            \"https://www.googleapis.com/auth/cloud-platform\",\n            \"https://www.googleapis.com/auth/cloud-platform.read-only\",\n        ],\n    )\n\n    assert options.api_endpoint == \"foo.googleapis.com\"\n    assert options.client_cert_source() == (b\"cert\", b\"key\")\n    assert options.quota_project_id == \"quote-proj\"\n    assert options.api_key == \"api-key\"\n    assert options.scopes == [\n        \"https://www.googleapis.com/auth/cloud-platform\",\n        \"https://www.googleapis.com/auth/cloud-platform.read-only\",\n    ]\n\n\ndef test_constructor_with_both_api_key_and_credentials_file():\n    with pytest.raises(ValueError):\n        client_options.ClientOptions(\n            api_key=\"api-key\",\n            credentials_file=\"path/to/credentials.json\",\n        )\n\n\ndef test_from_dict():\n    options = client_options.from_dict(\n        {\n            \"api_endpoint\": \"foo.googleapis.com\",\n            \"universe_domain\": \"googleapis.com\",\n            \"client_cert_source\": get_client_cert,\n            \"quota_project_id\": \"quote-proj\",\n            \"credentials_file\": \"path/to/credentials.json\",\n            \"scopes\": [\n                \"https://www.googleapis.com/auth/cloud-platform\",\n                \"https://www.googleapis.com/auth/cloud-platform.read-only\",\n            ],\n            \"api_audience\": \"foo2.googleapis.com\",\n        }\n    )\n\n    assert options.api_endpoint == \"foo.googleapis.com\"\n    assert options.universe_domain == \"googleapis.com\"\n    assert options.client_cert_source() == (b\"cert\", b\"key\")\n    assert options.quota_project_id == \"quote-proj\"\n    assert options.credentials_file == \"path/to/credentials.json\"\n    assert options.scopes == [\n        \"https://www.googleapis.com/auth/cloud-platform\",\n        \"https://www.googleapis.com/auth/cloud-platform.read-only\",\n    ]\n    assert options.api_key is None\n    assert options.api_audience == \"foo2.googleapis.com\"\n\n\ndef test_from_dict_bad_argument():\n    with pytest.raises(ValueError):\n        client_options.from_dict(\n            {\n                \"api_endpoint\": \"foo.googleapis.com\",\n                \"bad_arg\": \"1234\",\n                \"client_cert_source\": get_client_cert,\n            }\n        )\n\n\ndef test_repr():\n    expected_keys = set(\n        [\n            \"api_endpoint\",\n            \"universe_domain\",\n            \"client_cert_source\",\n            \"client_encrypted_cert_source\",\n            \"quota_project_id\",\n            \"credentials_file\",\n            \"scopes\",\n            \"api_key\",\n            \"api_audience\",\n        ]\n    )\n    options = client_options.ClientOptions(api_endpoint=\"foo.googleapis.com\")\n    options_repr = repr(options)\n    options_keys = vars(options).keys()\n    assert match(r\"ClientOptions:\", options_repr)\n    assert match(r\".*'api_endpoint': 'foo.googleapis.com'.*\", options_repr)\n    assert options_keys == expected_keys\n", "tests/unit/test_operation.py": "# Copyright 2017, Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\nimport mock\nimport pytest\n\ntry:\n    import grpc  # noqa: F401\nexcept ImportError:  # pragma: NO COVER\n    pytest.skip(\"No GRPC\", allow_module_level=True)\n\nfrom google.api_core import exceptions\nfrom google.api_core import operation\nfrom google.api_core import operations_v1\nfrom google.api_core import retry\nfrom google.longrunning import operations_pb2\nfrom google.protobuf import struct_pb2\nfrom google.rpc import code_pb2\nfrom google.rpc import status_pb2\n\nTEST_OPERATION_NAME = \"test/operation\"\n\n\ndef make_operation_proto(\n    name=TEST_OPERATION_NAME, metadata=None, response=None, error=None, **kwargs\n):\n    operation_proto = operations_pb2.Operation(name=name, **kwargs)\n\n    if metadata is not None:\n        operation_proto.metadata.Pack(metadata)\n\n    if response is not None:\n        operation_proto.response.Pack(response)\n\n    if error is not None:\n        operation_proto.error.CopyFrom(error)\n\n    return operation_proto\n\n\ndef make_operation_future(client_operations_responses=None):\n    if client_operations_responses is None:\n        client_operations_responses = [make_operation_proto()]\n\n    refresh = mock.Mock(spec=[\"__call__\"], side_effect=client_operations_responses)\n    refresh.responses = client_operations_responses\n    cancel = mock.Mock(spec=[\"__call__\"])\n    operation_future = operation.Operation(\n        client_operations_responses[0],\n        refresh,\n        cancel,\n        result_type=struct_pb2.Struct,\n        metadata_type=struct_pb2.Struct,\n    )\n\n    return operation_future, refresh, cancel\n\n\ndef test_constructor():\n    future, refresh, _ = make_operation_future()\n\n    assert future.operation == refresh.responses[0]\n    assert future.operation.done is False\n    assert future.operation.name == TEST_OPERATION_NAME\n    assert future.metadata is None\n    assert future.running()\n\n\ndef test_metadata():\n    expected_metadata = struct_pb2.Struct()\n    future, _, _ = make_operation_future(\n        [make_operation_proto(metadata=expected_metadata)]\n    )\n\n    assert future.metadata == expected_metadata\n\n\ndef test_cancellation():\n    responses = [\n        make_operation_proto(),\n        # Second response indicates that the operation was cancelled.\n        make_operation_proto(\n            done=True, error=status_pb2.Status(code=code_pb2.CANCELLED)\n        ),\n    ]\n    future, _, cancel = make_operation_future(responses)\n\n    assert future.cancel()\n    assert future.cancelled()\n    cancel.assert_called_once_with()\n\n    # Cancelling twice should have no effect.\n    assert not future.cancel()\n    cancel.assert_called_once_with()\n\n\ndef test_result():\n    expected_result = struct_pb2.Struct()\n    responses = [\n        make_operation_proto(),\n        # Second operation response includes the result.\n        make_operation_proto(done=True, response=expected_result),\n    ]\n    future, _, _ = make_operation_future(responses)\n\n    result = future.result()\n\n    assert result == expected_result\n    assert future.done()\n\n\ndef test_done_w_retry():\n    RETRY_PREDICATE = retry.if_exception_type(exceptions.TooManyRequests)\n    test_retry = retry.Retry(predicate=RETRY_PREDICATE)\n\n    expected_result = struct_pb2.Struct()\n    responses = [\n        make_operation_proto(),\n        # Second operation response includes the result.\n        make_operation_proto(done=True, response=expected_result),\n    ]\n    future, _, _ = make_operation_future(responses)\n    future._refresh = mock.Mock()\n\n    future.done(retry=test_retry)\n    future._refresh.assert_called_once_with(retry=test_retry)\n\n\ndef test_exception():\n    expected_exception = status_pb2.Status(message=\"meep\")\n    responses = [\n        make_operation_proto(),\n        # Second operation response includes the error.\n        make_operation_proto(done=True, error=expected_exception),\n    ]\n    future, _, _ = make_operation_future(responses)\n\n    exception = future.exception()\n\n    assert expected_exception.message in \"{!r}\".format(exception)\n\n\ndef test_exception_with_error_code():\n    expected_exception = status_pb2.Status(message=\"meep\", code=5)\n    responses = [\n        make_operation_proto(),\n        # Second operation response includes the error.\n        make_operation_proto(done=True, error=expected_exception),\n    ]\n    future, _, _ = make_operation_future(responses)\n\n    exception = future.exception()\n\n    assert expected_exception.message in \"{!r}\".format(exception)\n    # Status Code 5 maps to Not Found\n    # https://developers.google.com/maps-booking/reference/grpc-api/status_codes\n    assert isinstance(exception, exceptions.NotFound)\n\n\ndef test_unexpected_result():\n    responses = [\n        make_operation_proto(),\n        # Second operation response is done, but has not error or response.\n        make_operation_proto(done=True),\n    ]\n    future, _, _ = make_operation_future(responses)\n\n    exception = future.exception()\n\n    assert \"Unexpected state\" in \"{!r}\".format(exception)\n\n\ndef test__refresh_http():\n    json_response = {\"name\": TEST_OPERATION_NAME, \"done\": True}\n    api_request = mock.Mock(return_value=json_response)\n\n    result = operation._refresh_http(api_request, TEST_OPERATION_NAME)\n\n    assert isinstance(result, operations_pb2.Operation)\n    assert result.name == TEST_OPERATION_NAME\n    assert result.done is True\n\n    api_request.assert_called_once_with(\n        method=\"GET\", path=\"operations/{}\".format(TEST_OPERATION_NAME)\n    )\n\n\ndef test__refresh_http_w_retry():\n    json_response = {\"name\": TEST_OPERATION_NAME, \"done\": True}\n    api_request = mock.Mock()\n    retry = mock.Mock()\n    retry.return_value.return_value = json_response\n\n    result = operation._refresh_http(api_request, TEST_OPERATION_NAME, retry=retry)\n\n    assert isinstance(result, operations_pb2.Operation)\n    assert result.name == TEST_OPERATION_NAME\n    assert result.done is True\n\n    api_request.assert_not_called()\n    retry.assert_called_once_with(api_request)\n    retry.return_value.assert_called_once_with(\n        method=\"GET\", path=\"operations/{}\".format(TEST_OPERATION_NAME)\n    )\n\n\ndef test__cancel_http():\n    api_request = mock.Mock()\n\n    operation._cancel_http(api_request, TEST_OPERATION_NAME)\n\n    api_request.assert_called_once_with(\n        method=\"POST\", path=\"operations/{}:cancel\".format(TEST_OPERATION_NAME)\n    )\n\n\ndef test_from_http_json():\n    operation_json = {\"name\": TEST_OPERATION_NAME, \"done\": True}\n    api_request = mock.sentinel.api_request\n\n    future = operation.from_http_json(\n        operation_json, api_request, struct_pb2.Struct, metadata_type=struct_pb2.Struct\n    )\n\n    assert future._result_type == struct_pb2.Struct\n    assert future._metadata_type == struct_pb2.Struct\n    assert future.operation.name == TEST_OPERATION_NAME\n    assert future.done\n\n\ndef test__refresh_grpc():\n    operations_stub = mock.Mock(spec=[\"GetOperation\"])\n    expected_result = make_operation_proto(done=True)\n    operations_stub.GetOperation.return_value = expected_result\n\n    result = operation._refresh_grpc(operations_stub, TEST_OPERATION_NAME)\n\n    assert result == expected_result\n    expected_request = operations_pb2.GetOperationRequest(name=TEST_OPERATION_NAME)\n    operations_stub.GetOperation.assert_called_once_with(expected_request)\n\n\ndef test__refresh_grpc_w_retry():\n    operations_stub = mock.Mock(spec=[\"GetOperation\"])\n    expected_result = make_operation_proto(done=True)\n    retry = mock.Mock()\n    retry.return_value.return_value = expected_result\n\n    result = operation._refresh_grpc(operations_stub, TEST_OPERATION_NAME, retry=retry)\n\n    assert result == expected_result\n    expected_request = operations_pb2.GetOperationRequest(name=TEST_OPERATION_NAME)\n    operations_stub.GetOperation.assert_not_called()\n    retry.assert_called_once_with(operations_stub.GetOperation)\n    retry.return_value.assert_called_once_with(expected_request)\n\n\ndef test__cancel_grpc():\n    operations_stub = mock.Mock(spec=[\"CancelOperation\"])\n\n    operation._cancel_grpc(operations_stub, TEST_OPERATION_NAME)\n\n    expected_request = operations_pb2.CancelOperationRequest(name=TEST_OPERATION_NAME)\n    operations_stub.CancelOperation.assert_called_once_with(expected_request)\n\n\ndef test_from_grpc():\n    operation_proto = make_operation_proto(done=True)\n    operations_stub = mock.sentinel.operations_stub\n\n    future = operation.from_grpc(\n        operation_proto,\n        operations_stub,\n        struct_pb2.Struct,\n        metadata_type=struct_pb2.Struct,\n        grpc_metadata=[(\"x-goog-request-params\", \"foo\")],\n    )\n\n    assert future._result_type == struct_pb2.Struct\n    assert future._metadata_type == struct_pb2.Struct\n    assert future.operation.name == TEST_OPERATION_NAME\n    assert future.done\n    assert future._refresh.keywords[\"metadata\"] == [(\"x-goog-request-params\", \"foo\")]\n    assert future._cancel.keywords[\"metadata\"] == [(\"x-goog-request-params\", \"foo\")]\n\n\ndef test_from_gapic():\n    operation_proto = make_operation_proto(done=True)\n    operations_client = mock.create_autospec(\n        operations_v1.OperationsClient, instance=True\n    )\n\n    future = operation.from_gapic(\n        operation_proto,\n        operations_client,\n        struct_pb2.Struct,\n        metadata_type=struct_pb2.Struct,\n        grpc_metadata=[(\"x-goog-request-params\", \"foo\")],\n    )\n\n    assert future._result_type == struct_pb2.Struct\n    assert future._metadata_type == struct_pb2.Struct\n    assert future.operation.name == TEST_OPERATION_NAME\n    assert future.done\n    assert future._refresh.keywords[\"metadata\"] == [(\"x-goog-request-params\", \"foo\")]\n    assert future._cancel.keywords[\"metadata\"] == [(\"x-goog-request-params\", \"foo\")]\n\n\ndef test_deserialize():\n    op = make_operation_proto(name=\"foobarbaz\")\n    serialized = op.SerializeToString()\n    deserialized_op = operation.Operation.deserialize(serialized)\n    assert op.name == deserialized_op.name\n    assert type(op) is type(deserialized_op)\n", "tests/unit/test_bidi.py": "# Copyright 2018, Google LLC All rights reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport datetime\nimport logging\nimport queue\nimport threading\n\nimport mock\nimport pytest\n\ntry:\n    import grpc\nexcept ImportError:  # pragma: NO COVER\n    pytest.skip(\"No GRPC\", allow_module_level=True)\n\nfrom google.api_core import bidi\nfrom google.api_core import exceptions\n\n\nclass Test_RequestQueueGenerator(object):\n    def test_bounded_consume(self):\n        call = mock.create_autospec(grpc.Call, instance=True)\n        call.is_active.return_value = True\n\n        def queue_generator(rpc):\n            yield mock.sentinel.A\n            yield queue.Empty()\n            yield mock.sentinel.B\n            rpc.is_active.return_value = False\n            yield mock.sentinel.C\n\n        q = mock.create_autospec(queue.Queue, instance=True)\n        q.get.side_effect = queue_generator(call)\n\n        generator = bidi._RequestQueueGenerator(q)\n        generator.call = call\n\n        items = list(generator)\n\n        assert items == [mock.sentinel.A, mock.sentinel.B]\n\n    def test_yield_initial_and_exit(self):\n        q = mock.create_autospec(queue.Queue, instance=True)\n        q.get.side_effect = queue.Empty()\n        call = mock.create_autospec(grpc.Call, instance=True)\n        call.is_active.return_value = False\n\n        generator = bidi._RequestQueueGenerator(q, initial_request=mock.sentinel.A)\n        generator.call = call\n\n        items = list(generator)\n\n        assert items == [mock.sentinel.A]\n\n    def test_yield_initial_callable_and_exit(self):\n        q = mock.create_autospec(queue.Queue, instance=True)\n        q.get.side_effect = queue.Empty()\n        call = mock.create_autospec(grpc.Call, instance=True)\n        call.is_active.return_value = False\n\n        generator = bidi._RequestQueueGenerator(\n            q, initial_request=lambda: mock.sentinel.A\n        )\n        generator.call = call\n\n        items = list(generator)\n\n        assert items == [mock.sentinel.A]\n\n    def test_exit_when_inactive_with_item(self):\n        q = mock.create_autospec(queue.Queue, instance=True)\n        q.get.side_effect = [mock.sentinel.A, queue.Empty()]\n        call = mock.create_autospec(grpc.Call, instance=True)\n        call.is_active.return_value = False\n\n        generator = bidi._RequestQueueGenerator(q)\n        generator.call = call\n\n        items = list(generator)\n\n        assert items == []\n        # Make sure it put the item back.\n        q.put.assert_called_once_with(mock.sentinel.A)\n\n    def test_exit_when_inactive_empty(self):\n        q = mock.create_autospec(queue.Queue, instance=True)\n        q.get.side_effect = queue.Empty()\n        call = mock.create_autospec(grpc.Call, instance=True)\n        call.is_active.return_value = False\n\n        generator = bidi._RequestQueueGenerator(q)\n        generator.call = call\n\n        items = list(generator)\n\n        assert items == []\n\n    def test_exit_with_stop(self):\n        q = mock.create_autospec(queue.Queue, instance=True)\n        q.get.side_effect = [None, queue.Empty()]\n        call = mock.create_autospec(grpc.Call, instance=True)\n        call.is_active.return_value = True\n\n        generator = bidi._RequestQueueGenerator(q)\n        generator.call = call\n\n        items = list(generator)\n\n        assert items == []\n\n\nclass Test_Throttle(object):\n    def test_repr(self):\n        delta = datetime.timedelta(seconds=4.5)\n        instance = bidi._Throttle(access_limit=42, time_window=delta)\n        assert repr(instance) == \"_Throttle(access_limit=42, time_window={})\".format(\n            repr(delta)\n        )\n\n    def test_raises_error_on_invalid_init_arguments(self):\n        with pytest.raises(ValueError) as exc_info:\n            bidi._Throttle(access_limit=10, time_window=datetime.timedelta(seconds=0.0))\n        assert \"time_window\" in str(exc_info.value)\n        assert \"must be a positive timedelta\" in str(exc_info.value)\n\n        with pytest.raises(ValueError) as exc_info:\n            bidi._Throttle(access_limit=0, time_window=datetime.timedelta(seconds=10))\n        assert \"access_limit\" in str(exc_info.value)\n        assert \"must be positive\" in str(exc_info.value)\n\n    def test_does_not_delay_entry_attempts_under_threshold(self):\n        throttle = bidi._Throttle(\n            access_limit=3, time_window=datetime.timedelta(seconds=1)\n        )\n        entries = []\n\n        for _ in range(3):\n            with throttle as time_waited:\n                entry_info = {\n                    \"entered_at\": datetime.datetime.now(),\n                    \"reported_wait\": time_waited,\n                }\n                entries.append(entry_info)\n\n        # check the reported wait times ...\n        assert all(entry[\"reported_wait\"] == 0.0 for entry in entries)\n\n        # .. and the actual wait times\n        delta = entries[1][\"entered_at\"] - entries[0][\"entered_at\"]\n        assert delta.total_seconds() < 0.1\n        delta = entries[2][\"entered_at\"] - entries[1][\"entered_at\"]\n        assert delta.total_seconds() < 0.1\n\n    def test_delays_entry_attempts_above_threshold(self):\n        throttle = bidi._Throttle(\n            access_limit=3, time_window=datetime.timedelta(seconds=1)\n        )\n        entries = []\n\n        for _ in range(6):\n            with throttle as time_waited:\n                entry_info = {\n                    \"entered_at\": datetime.datetime.now(),\n                    \"reported_wait\": time_waited,\n                }\n                entries.append(entry_info)\n\n        # For each group of 4 consecutive entries the time difference between\n        # the first and the last entry must have been greater than time_window,\n        # because a maximum of 3 are allowed in each time_window.\n        for i, entry in enumerate(entries[3:], start=3):\n            first_entry = entries[i - 3]\n            delta = entry[\"entered_at\"] - first_entry[\"entered_at\"]\n            assert delta.total_seconds() > 1.0\n\n        # check the reported wait times\n        # (NOTE: not using assert all(...), b/c the coverage check would complain)\n        for i, entry in enumerate(entries):\n            if i != 3:\n                assert entry[\"reported_wait\"] == 0.0\n\n        # The delayed entry is expected to have been delayed for a significant\n        # chunk of the full second, and the actual and reported delay times\n        # should reflect that.\n        assert entries[3][\"reported_wait\"] > 0.7\n        delta = entries[3][\"entered_at\"] - entries[2][\"entered_at\"]\n        assert delta.total_seconds() > 0.7\n\n\nclass _CallAndFuture(grpc.Call, grpc.Future):\n    pass\n\n\ndef make_rpc():\n    \"\"\"Makes a mock RPC used to test Bidi classes.\"\"\"\n    call = mock.create_autospec(_CallAndFuture, instance=True)\n    rpc = mock.create_autospec(grpc.StreamStreamMultiCallable, instance=True)\n\n    def rpc_side_effect(request, metadata=None):\n        call.is_active.return_value = True\n        call.request = request\n        call.metadata = metadata\n        return call\n\n    rpc.side_effect = rpc_side_effect\n\n    def cancel_side_effect():\n        call.is_active.return_value = False\n\n    call.cancel.side_effect = cancel_side_effect\n\n    return rpc, call\n\n\nclass ClosedCall(object):\n    def __init__(self, exception):\n        self.exception = exception\n\n    def __next__(self):\n        raise self.exception\n\n    def is_active(self):\n        return False\n\n\nclass TestBidiRpc(object):\n    def test_initial_state(self):\n        bidi_rpc = bidi.BidiRpc(None)\n\n        assert bidi_rpc.is_active is False\n\n    def test_done_callbacks(self):\n        bidi_rpc = bidi.BidiRpc(None)\n        callback = mock.Mock(spec=[\"__call__\"])\n\n        bidi_rpc.add_done_callback(callback)\n        bidi_rpc._on_call_done(mock.sentinel.future)\n\n        callback.assert_called_once_with(mock.sentinel.future)\n\n    def test_metadata(self):\n        rpc, call = make_rpc()\n        bidi_rpc = bidi.BidiRpc(rpc, metadata=mock.sentinel.A)\n        assert bidi_rpc._rpc_metadata == mock.sentinel.A\n\n        bidi_rpc.open()\n        assert bidi_rpc.call == call\n        assert bidi_rpc.call.metadata == mock.sentinel.A\n\n    def test_open(self):\n        rpc, call = make_rpc()\n        bidi_rpc = bidi.BidiRpc(rpc)\n\n        bidi_rpc.open()\n\n        assert bidi_rpc.call == call\n        assert bidi_rpc.is_active\n        call.add_done_callback.assert_called_once_with(bidi_rpc._on_call_done)\n\n    def test_open_error_already_open(self):\n        rpc, _ = make_rpc()\n        bidi_rpc = bidi.BidiRpc(rpc)\n\n        bidi_rpc.open()\n\n        with pytest.raises(ValueError):\n            bidi_rpc.open()\n\n    def test_close(self):\n        rpc, call = make_rpc()\n        bidi_rpc = bidi.BidiRpc(rpc)\n        bidi_rpc.open()\n\n        bidi_rpc.close()\n\n        call.cancel.assert_called_once()\n        assert bidi_rpc.call == call\n        assert bidi_rpc.is_active is False\n        # ensure the request queue was signaled to stop.\n        assert bidi_rpc.pending_requests == 1\n        assert bidi_rpc._request_queue.get() is None\n\n    def test_close_no_rpc(self):\n        bidi_rpc = bidi.BidiRpc(None)\n        bidi_rpc.close()\n\n    def test_send(self):\n        rpc, call = make_rpc()\n        bidi_rpc = bidi.BidiRpc(rpc)\n        bidi_rpc.open()\n\n        bidi_rpc.send(mock.sentinel.request)\n\n        assert bidi_rpc.pending_requests == 1\n        assert bidi_rpc._request_queue.get() is mock.sentinel.request\n\n    def test_send_not_open(self):\n        rpc, call = make_rpc()\n        bidi_rpc = bidi.BidiRpc(rpc)\n\n        with pytest.raises(ValueError):\n            bidi_rpc.send(mock.sentinel.request)\n\n    def test_send_dead_rpc(self):\n        error = ValueError()\n        bidi_rpc = bidi.BidiRpc(None)\n        bidi_rpc.call = ClosedCall(error)\n\n        with pytest.raises(ValueError) as exc_info:\n            bidi_rpc.send(mock.sentinel.request)\n\n        assert exc_info.value == error\n\n    def test_recv(self):\n        bidi_rpc = bidi.BidiRpc(None)\n        bidi_rpc.call = iter([mock.sentinel.response])\n\n        response = bidi_rpc.recv()\n\n        assert response == mock.sentinel.response\n\n    def test_recv_not_open(self):\n        rpc, call = make_rpc()\n        bidi_rpc = bidi.BidiRpc(rpc)\n\n        with pytest.raises(ValueError):\n            bidi_rpc.recv()\n\n\nclass CallStub(object):\n    def __init__(self, values, active=True):\n        self.values = iter(values)\n        self._is_active = active\n        self.cancelled = False\n\n    def __next__(self):\n        item = next(self.values)\n        if isinstance(item, Exception):\n            self._is_active = False\n            raise item\n        return item\n\n    def is_active(self):\n        return self._is_active\n\n    def add_done_callback(self, callback):\n        pass\n\n    def cancel(self):\n        self.cancelled = True\n\n\nclass TestResumableBidiRpc(object):\n    def test_ctor_defaults(self):\n        start_rpc = mock.Mock()\n        should_recover = mock.Mock()\n        bidi_rpc = bidi.ResumableBidiRpc(start_rpc, should_recover)\n\n        assert bidi_rpc.is_active is False\n        assert bidi_rpc._finalized is False\n        assert bidi_rpc._start_rpc is start_rpc\n        assert bidi_rpc._should_recover is should_recover\n        assert bidi_rpc._should_terminate is bidi._never_terminate\n        assert bidi_rpc._initial_request is None\n        assert bidi_rpc._rpc_metadata is None\n        assert bidi_rpc._reopen_throttle is None\n\n    def test_ctor_explicit(self):\n        start_rpc = mock.Mock()\n        should_recover = mock.Mock()\n        should_terminate = mock.Mock()\n        initial_request = mock.Mock()\n        metadata = {\"x-foo\": \"bar\"}\n        bidi_rpc = bidi.ResumableBidiRpc(\n            start_rpc,\n            should_recover,\n            should_terminate=should_terminate,\n            initial_request=initial_request,\n            metadata=metadata,\n            throttle_reopen=True,\n        )\n\n        assert bidi_rpc.is_active is False\n        assert bidi_rpc._finalized is False\n        assert bidi_rpc._should_recover is should_recover\n        assert bidi_rpc._should_terminate is should_terminate\n        assert bidi_rpc._initial_request is initial_request\n        assert bidi_rpc._rpc_metadata == metadata\n        assert isinstance(bidi_rpc._reopen_throttle, bidi._Throttle)\n\n    def test_done_callbacks_terminate(self):\n        cancellation = mock.Mock()\n        start_rpc = mock.Mock()\n        should_recover = mock.Mock(spec=[\"__call__\"], return_value=True)\n        should_terminate = mock.Mock(spec=[\"__call__\"], return_value=True)\n        bidi_rpc = bidi.ResumableBidiRpc(\n            start_rpc, should_recover, should_terminate=should_terminate\n        )\n        callback = mock.Mock(spec=[\"__call__\"])\n\n        bidi_rpc.add_done_callback(callback)\n        bidi_rpc._on_call_done(cancellation)\n\n        should_terminate.assert_called_once_with(cancellation)\n        should_recover.assert_not_called()\n        callback.assert_called_once_with(cancellation)\n        assert not bidi_rpc.is_active\n\n    def test_done_callbacks_recoverable(self):\n        start_rpc = mock.create_autospec(grpc.StreamStreamMultiCallable, instance=True)\n        should_recover = mock.Mock(spec=[\"__call__\"], return_value=True)\n        bidi_rpc = bidi.ResumableBidiRpc(start_rpc, should_recover)\n        callback = mock.Mock(spec=[\"__call__\"])\n\n        bidi_rpc.add_done_callback(callback)\n        bidi_rpc._on_call_done(mock.sentinel.future)\n\n        callback.assert_not_called()\n        start_rpc.assert_called_once()\n        should_recover.assert_called_once_with(mock.sentinel.future)\n        assert bidi_rpc.is_active\n\n    def test_done_callbacks_non_recoverable(self):\n        start_rpc = mock.create_autospec(grpc.StreamStreamMultiCallable, instance=True)\n        should_recover = mock.Mock(spec=[\"__call__\"], return_value=False)\n        bidi_rpc = bidi.ResumableBidiRpc(start_rpc, should_recover)\n        callback = mock.Mock(spec=[\"__call__\"])\n\n        bidi_rpc.add_done_callback(callback)\n        bidi_rpc._on_call_done(mock.sentinel.future)\n\n        callback.assert_called_once_with(mock.sentinel.future)\n        should_recover.assert_called_once_with(mock.sentinel.future)\n        assert not bidi_rpc.is_active\n\n    def test_send_terminate(self):\n        cancellation = ValueError()\n        call_1 = CallStub([cancellation], active=False)\n        call_2 = CallStub([])\n        start_rpc = mock.create_autospec(\n            grpc.StreamStreamMultiCallable, instance=True, side_effect=[call_1, call_2]\n        )\n        should_recover = mock.Mock(spec=[\"__call__\"], return_value=False)\n        should_terminate = mock.Mock(spec=[\"__call__\"], return_value=True)\n        bidi_rpc = bidi.ResumableBidiRpc(\n            start_rpc, should_recover, should_terminate=should_terminate\n        )\n\n        bidi_rpc.open()\n\n        bidi_rpc.send(mock.sentinel.request)\n\n        assert bidi_rpc.pending_requests == 1\n        assert bidi_rpc._request_queue.get() is None\n\n        should_recover.assert_not_called()\n        should_terminate.assert_called_once_with(cancellation)\n        assert bidi_rpc.call == call_1\n        assert bidi_rpc.is_active is False\n        assert call_1.cancelled is True\n\n    def test_send_recover(self):\n        error = ValueError()\n        call_1 = CallStub([error], active=False)\n        call_2 = CallStub([])\n        start_rpc = mock.create_autospec(\n            grpc.StreamStreamMultiCallable, instance=True, side_effect=[call_1, call_2]\n        )\n        should_recover = mock.Mock(spec=[\"__call__\"], return_value=True)\n        bidi_rpc = bidi.ResumableBidiRpc(start_rpc, should_recover)\n\n        bidi_rpc.open()\n\n        bidi_rpc.send(mock.sentinel.request)\n\n        assert bidi_rpc.pending_requests == 1\n        assert bidi_rpc._request_queue.get() is mock.sentinel.request\n\n        should_recover.assert_called_once_with(error)\n        assert bidi_rpc.call == call_2\n        assert bidi_rpc.is_active is True\n\n    def test_send_failure(self):\n        error = ValueError()\n        call = CallStub([error], active=False)\n        start_rpc = mock.create_autospec(\n            grpc.StreamStreamMultiCallable, instance=True, return_value=call\n        )\n        should_recover = mock.Mock(spec=[\"__call__\"], return_value=False)\n        bidi_rpc = bidi.ResumableBidiRpc(start_rpc, should_recover)\n\n        bidi_rpc.open()\n\n        with pytest.raises(ValueError) as exc_info:\n            bidi_rpc.send(mock.sentinel.request)\n\n        assert exc_info.value == error\n        should_recover.assert_called_once_with(error)\n        assert bidi_rpc.call == call\n        assert bidi_rpc.is_active is False\n        assert call.cancelled is True\n        assert bidi_rpc.pending_requests == 1\n        assert bidi_rpc._request_queue.get() is None\n\n    def test_recv_terminate(self):\n        cancellation = ValueError()\n        call = CallStub([cancellation])\n        start_rpc = mock.create_autospec(\n            grpc.StreamStreamMultiCallable, instance=True, return_value=call\n        )\n        should_recover = mock.Mock(spec=[\"__call__\"], return_value=False)\n        should_terminate = mock.Mock(spec=[\"__call__\"], return_value=True)\n        bidi_rpc = bidi.ResumableBidiRpc(\n            start_rpc, should_recover, should_terminate=should_terminate\n        )\n\n        bidi_rpc.open()\n\n        bidi_rpc.recv()\n\n        should_recover.assert_not_called()\n        should_terminate.assert_called_once_with(cancellation)\n        assert bidi_rpc.call == call\n        assert bidi_rpc.is_active is False\n        assert call.cancelled is True\n\n    def test_recv_recover(self):\n        error = ValueError()\n        call_1 = CallStub([1, error])\n        call_2 = CallStub([2, 3])\n        start_rpc = mock.create_autospec(\n            grpc.StreamStreamMultiCallable, instance=True, side_effect=[call_1, call_2]\n        )\n        should_recover = mock.Mock(spec=[\"__call__\"], return_value=True)\n        bidi_rpc = bidi.ResumableBidiRpc(start_rpc, should_recover)\n\n        bidi_rpc.open()\n\n        values = []\n        for n in range(3):\n            values.append(bidi_rpc.recv())\n\n        assert values == [1, 2, 3]\n        should_recover.assert_called_once_with(error)\n        assert bidi_rpc.call == call_2\n        assert bidi_rpc.is_active is True\n\n    def test_recv_recover_already_recovered(self):\n        call_1 = CallStub([])\n        call_2 = CallStub([])\n        start_rpc = mock.create_autospec(\n            grpc.StreamStreamMultiCallable, instance=True, side_effect=[call_1, call_2]\n        )\n        callback = mock.Mock()\n        callback.return_value = True\n        bidi_rpc = bidi.ResumableBidiRpc(start_rpc, callback)\n\n        bidi_rpc.open()\n\n        bidi_rpc._reopen()\n\n        assert bidi_rpc.call is call_1\n        assert bidi_rpc.is_active is True\n\n    def test_recv_failure(self):\n        error = ValueError()\n        call = CallStub([error])\n        start_rpc = mock.create_autospec(\n            grpc.StreamStreamMultiCallable, instance=True, return_value=call\n        )\n        should_recover = mock.Mock(spec=[\"__call__\"], return_value=False)\n        bidi_rpc = bidi.ResumableBidiRpc(start_rpc, should_recover)\n\n        bidi_rpc.open()\n\n        with pytest.raises(ValueError) as exc_info:\n            bidi_rpc.recv()\n\n        assert exc_info.value == error\n        should_recover.assert_called_once_with(error)\n        assert bidi_rpc.call == call\n        assert bidi_rpc.is_active is False\n        assert call.cancelled is True\n\n    def test_close(self):\n        call = mock.create_autospec(_CallAndFuture, instance=True)\n\n        def cancel_side_effect():\n            call.is_active.return_value = False\n\n        call.cancel.side_effect = cancel_side_effect\n        start_rpc = mock.create_autospec(\n            grpc.StreamStreamMultiCallable, instance=True, return_value=call\n        )\n        should_recover = mock.Mock(spec=[\"__call__\"], return_value=False)\n        bidi_rpc = bidi.ResumableBidiRpc(start_rpc, should_recover)\n        bidi_rpc.open()\n\n        bidi_rpc.close()\n\n        should_recover.assert_not_called()\n        call.cancel.assert_called_once()\n        assert bidi_rpc.call == call\n        assert bidi_rpc.is_active is False\n        # ensure the request queue was signaled to stop.\n        assert bidi_rpc.pending_requests == 1\n        assert bidi_rpc._request_queue.get() is None\n        assert bidi_rpc._finalized\n\n    def test_reopen_failure_on_rpc_restart(self):\n        error1 = ValueError(\"1\")\n        error2 = ValueError(\"2\")\n        call = CallStub([error1])\n        # Invoking start RPC a second time will trigger an error.\n        start_rpc = mock.create_autospec(\n            grpc.StreamStreamMultiCallable, instance=True, side_effect=[call, error2]\n        )\n        should_recover = mock.Mock(spec=[\"__call__\"], return_value=True)\n        callback = mock.Mock(spec=[\"__call__\"])\n\n        bidi_rpc = bidi.ResumableBidiRpc(start_rpc, should_recover)\n        bidi_rpc.add_done_callback(callback)\n\n        bidi_rpc.open()\n\n        with pytest.raises(ValueError) as exc_info:\n            bidi_rpc.recv()\n\n        assert exc_info.value == error2\n        should_recover.assert_called_once_with(error1)\n        assert bidi_rpc.call is None\n        assert bidi_rpc.is_active is False\n        callback.assert_called_once_with(error2)\n\n    def test_using_throttle_on_reopen_requests(self):\n        call = CallStub([])\n        start_rpc = mock.create_autospec(\n            grpc.StreamStreamMultiCallable, instance=True, return_value=call\n        )\n        should_recover = mock.Mock(spec=[\"__call__\"], return_value=True)\n        bidi_rpc = bidi.ResumableBidiRpc(\n            start_rpc, should_recover, throttle_reopen=True\n        )\n\n        patcher = mock.patch.object(bidi_rpc._reopen_throttle.__class__, \"__enter__\")\n        with patcher as mock_enter:\n            bidi_rpc._reopen()\n\n        mock_enter.assert_called_once()\n\n    def test_send_not_open(self):\n        bidi_rpc = bidi.ResumableBidiRpc(None, lambda _: False)\n\n        with pytest.raises(ValueError):\n            bidi_rpc.send(mock.sentinel.request)\n\n    def test_recv_not_open(self):\n        bidi_rpc = bidi.ResumableBidiRpc(None, lambda _: False)\n\n        with pytest.raises(ValueError):\n            bidi_rpc.recv()\n\n    def test_finalize_idempotent(self):\n        error1 = ValueError(\"1\")\n        error2 = ValueError(\"2\")\n        callback = mock.Mock(spec=[\"__call__\"])\n        should_recover = mock.Mock(spec=[\"__call__\"], return_value=False)\n\n        bidi_rpc = bidi.ResumableBidiRpc(mock.sentinel.start_rpc, should_recover)\n\n        bidi_rpc.add_done_callback(callback)\n\n        bidi_rpc._on_call_done(error1)\n        bidi_rpc._on_call_done(error2)\n\n        callback.assert_called_once_with(error1)\n\n\nclass TestBackgroundConsumer(object):\n    def test_consume_once_then_exit(self):\n        bidi_rpc = mock.create_autospec(bidi.BidiRpc, instance=True)\n        bidi_rpc.is_active = True\n        bidi_rpc.recv.side_effect = [mock.sentinel.response_1]\n        recved = threading.Event()\n\n        def on_response(response):\n            assert response == mock.sentinel.response_1\n            bidi_rpc.is_active = False\n            recved.set()\n\n        consumer = bidi.BackgroundConsumer(bidi_rpc, on_response)\n\n        consumer.start()\n\n        recved.wait()\n\n        bidi_rpc.recv.assert_called_once()\n        assert bidi_rpc.is_active is False\n\n        consumer.stop()\n\n        bidi_rpc.close.assert_called_once()\n        assert consumer.is_active is False\n\n    def test_pause_resume_and_close(self):\n        # This test is relatively complex. It attempts to start the consumer,\n        # consume one item, pause the consumer, check the state of the world,\n        # then resume the consumer. Doing this in a deterministic fashion\n        # requires a bit more mocking and patching than usual.\n\n        bidi_rpc = mock.create_autospec(bidi.BidiRpc, instance=True)\n        bidi_rpc.is_active = True\n\n        def close_side_effect():\n            bidi_rpc.is_active = False\n\n        bidi_rpc.close.side_effect = close_side_effect\n\n        # These are used to coordinate the two threads to ensure deterministic\n        # execution.\n        should_continue = threading.Event()\n        responses_and_events = {\n            mock.sentinel.response_1: threading.Event(),\n            mock.sentinel.response_2: threading.Event(),\n        }\n        bidi_rpc.recv.side_effect = [mock.sentinel.response_1, mock.sentinel.response_2]\n\n        recved_responses = []\n        consumer = None\n\n        def on_response(response):\n            if response == mock.sentinel.response_1:\n                consumer.pause()\n\n            recved_responses.append(response)\n            responses_and_events[response].set()\n            should_continue.wait()\n\n        consumer = bidi.BackgroundConsumer(bidi_rpc, on_response)\n\n        consumer.start()\n\n        # Wait for the first response to be recved.\n        responses_and_events[mock.sentinel.response_1].wait()\n\n        # Ensure only one item has been recved and that the consumer is paused.\n        assert recved_responses == [mock.sentinel.response_1]\n        assert consumer.is_paused is True\n        assert consumer.is_active is True\n\n        # Unpause the consumer, wait for the second item, then close the\n        # consumer.\n        should_continue.set()\n        consumer.resume()\n\n        responses_and_events[mock.sentinel.response_2].wait()\n\n        assert recved_responses == [mock.sentinel.response_1, mock.sentinel.response_2]\n\n        consumer.stop()\n\n        assert consumer.is_active is False\n\n    def test_wake_on_error(self):\n        should_continue = threading.Event()\n\n        bidi_rpc = mock.create_autospec(bidi.BidiRpc, instance=True)\n        bidi_rpc.is_active = True\n        bidi_rpc.add_done_callback.side_effect = lambda _: should_continue.set()\n\n        consumer = bidi.BackgroundConsumer(bidi_rpc, mock.sentinel.on_response)\n\n        # Start the consumer paused, which should immediately put it into wait\n        # state.\n        consumer.pause()\n        consumer.start()\n\n        # Wait for add_done_callback to be called\n        should_continue.wait()\n        bidi_rpc.add_done_callback.assert_called_once_with(consumer._on_call_done)\n\n        # The consumer should now be blocked on waiting to be unpaused.\n        assert consumer.is_active\n        assert consumer.is_paused\n\n        # Trigger the done callback, it should unpause the consumer and cause\n        # it to exit.\n        bidi_rpc.is_active = False\n        consumer._on_call_done(bidi_rpc)\n\n        # It may take a few cycles for the thread to exit.\n        while consumer.is_active:\n            pass\n\n    def test_rpc_callback_fires_when_consumer_start_fails(self):\n        expected_exception = exceptions.InvalidArgument(\n            \"test\", response=grpc.StatusCode.INVALID_ARGUMENT\n        )\n        callback = mock.Mock(spec=[\"__call__\"])\n\n        rpc, _ = make_rpc()\n        bidi_rpc = bidi.BidiRpc(rpc)\n        bidi_rpc.add_done_callback(callback)\n        bidi_rpc._start_rpc.side_effect = expected_exception\n\n        consumer = bidi.BackgroundConsumer(bidi_rpc, on_response=None)\n        consumer.start()\n        assert callback.call_args.args[0] == grpc.StatusCode.INVALID_ARGUMENT\n\n    def test_consumer_expected_error(self, caplog):\n        caplog.set_level(logging.DEBUG)\n\n        bidi_rpc = mock.create_autospec(bidi.BidiRpc, instance=True)\n        bidi_rpc.is_active = True\n        bidi_rpc.recv.side_effect = exceptions.ServiceUnavailable(\"Gone away\")\n\n        on_response = mock.Mock(spec=[\"__call__\"])\n\n        consumer = bidi.BackgroundConsumer(bidi_rpc, on_response)\n\n        consumer.start()\n\n        # Wait for the consumer's thread to exit.\n        while consumer.is_active:\n            pass\n\n        on_response.assert_not_called()\n        bidi_rpc.recv.assert_called_once()\n        assert \"caught error\" in caplog.text\n\n    def test_consumer_unexpected_error(self, caplog):\n        caplog.set_level(logging.DEBUG)\n\n        bidi_rpc = mock.create_autospec(bidi.BidiRpc, instance=True)\n        bidi_rpc.is_active = True\n        bidi_rpc.recv.side_effect = ValueError()\n\n        on_response = mock.Mock(spec=[\"__call__\"])\n\n        consumer = bidi.BackgroundConsumer(bidi_rpc, on_response)\n\n        consumer.start()\n\n        # Wait for the consumer's thread to exit.\n        while consumer.is_active:\n            pass  # pragma: NO COVER (race condition)\n\n        on_response.assert_not_called()\n        bidi_rpc.recv.assert_called_once()\n        assert \"caught unexpected exception\" in caplog.text\n\n    def test_double_stop(self, caplog):\n        caplog.set_level(logging.DEBUG)\n        bidi_rpc = mock.create_autospec(bidi.BidiRpc, instance=True)\n        bidi_rpc.is_active = True\n        on_response = mock.Mock(spec=[\"__call__\"])\n\n        def close_side_effect():\n            bidi_rpc.is_active = False\n\n        bidi_rpc.close.side_effect = close_side_effect\n\n        consumer = bidi.BackgroundConsumer(bidi_rpc, on_response)\n\n        consumer.start()\n        assert consumer.is_active is True\n\n        consumer.stop()\n        assert consumer.is_active is False\n\n        # calling stop twice should not result in an error.\n        consumer.stop()\n", "tests/unit/test_packaging.py": "# Copyright 2023 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport os\nimport subprocess\nimport sys\n\n\ndef test_namespace_package_compat(tmp_path):\n    # The ``google`` namespace package should not be masked\n    # by the presence of ``google-api-core``.\n    google = tmp_path / \"google\"\n    google.mkdir()\n    google.joinpath(\"othermod.py\").write_text(\"\")\n    env = dict(os.environ, PYTHONPATH=str(tmp_path))\n    cmd = [sys.executable, \"-m\", \"google.othermod\"]\n    subprocess.check_call(cmd, env=env)\n", "tests/unit/test_iam.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport pytest\n\nfrom google.api_core.iam import _DICT_ACCESS_MSG, InvalidOperationException\n\n\nclass TestPolicy:\n    @staticmethod\n    def _get_target_class():\n        from google.api_core.iam import Policy\n\n        return Policy\n\n    def _make_one(self, *args, **kw):\n        return self._get_target_class()(*args, **kw)\n\n    def test_ctor_defaults(self):\n        empty = frozenset()\n        policy = self._make_one()\n        assert policy.etag is None\n        assert policy.version is None\n        assert policy.owners == empty\n        assert policy.editors == empty\n        assert policy.viewers == empty\n        assert len(policy) == 0\n        assert dict(policy) == {}\n\n    def test_ctor_explicit(self):\n        VERSION = 1\n        ETAG = \"ETAG\"\n        empty = frozenset()\n        policy = self._make_one(ETAG, VERSION)\n        assert policy.etag == ETAG\n        assert policy.version == VERSION\n        assert policy.owners == empty\n        assert policy.editors == empty\n        assert policy.viewers == empty\n        assert len(policy) == 0\n        assert dict(policy) == {}\n\n    def test___getitem___miss(self):\n        policy = self._make_one()\n        assert policy[\"nonesuch\"] == set()\n\n    def test__getitem___and_set(self):\n        from google.api_core.iam import OWNER_ROLE\n\n        policy = self._make_one()\n\n        # get the policy using the getter and then modify it\n        policy[OWNER_ROLE].add(\"user:phred@example.com\")\n        assert dict(policy) == {OWNER_ROLE: {\"user:phred@example.com\"}}\n\n    def test___getitem___version3(self):\n        policy = self._make_one(\"DEADBEEF\", 3)\n        with pytest.raises(InvalidOperationException, match=_DICT_ACCESS_MSG):\n            policy[\"role\"]\n\n    def test___getitem___with_conditions(self):\n        USER = \"user:phred@example.com\"\n        CONDITION = {\"expression\": \"2 > 1\"}\n        policy = self._make_one(\"DEADBEEF\", 1)\n        policy.bindings = [\n            {\"role\": \"role/reader\", \"members\": [USER], \"condition\": CONDITION}\n        ]\n        with pytest.raises(InvalidOperationException, match=_DICT_ACCESS_MSG):\n            policy[\"role/reader\"]\n\n    def test___setitem__(self):\n        USER = \"user:phred@example.com\"\n        PRINCIPALS = set([USER])\n        policy = self._make_one()\n        policy[\"rolename\"] = [USER]\n        assert policy[\"rolename\"] == PRINCIPALS\n        assert len(policy) == 1\n        assert dict(policy) == {\"rolename\": PRINCIPALS}\n\n    def test__set_item__overwrite(self):\n        GROUP = \"group:test@group.com\"\n        USER = \"user:phred@example.com\"\n        ALL_USERS = \"allUsers\"\n        MEMBERS = set([ALL_USERS])\n        GROUPS = set([GROUP])\n        policy = self._make_one()\n        policy[\"first\"] = [GROUP]\n        policy[\"second\"] = [USER]\n        policy[\"second\"] = [ALL_USERS]\n        assert policy[\"second\"] == MEMBERS\n        assert len(policy) == 2\n        assert dict(policy) == {\"first\": GROUPS, \"second\": MEMBERS}\n\n    def test___setitem___version3(self):\n        policy = self._make_one(\"DEADBEEF\", 3)\n        with pytest.raises(InvalidOperationException, match=_DICT_ACCESS_MSG):\n            policy[\"role/reader\"] = [\"user:phred@example.com\"]\n\n    def test___setitem___with_conditions(self):\n        USER = \"user:phred@example.com\"\n        CONDITION = {\"expression\": \"2 > 1\"}\n        policy = self._make_one(\"DEADBEEF\", 1)\n        policy.bindings = [\n            {\"role\": \"role/reader\", \"members\": set([USER]), \"condition\": CONDITION}\n        ]\n        with pytest.raises(InvalidOperationException, match=_DICT_ACCESS_MSG):\n            policy[\"role/reader\"] = [\"user:phred@example.com\"]\n\n    def test___delitem___hit(self):\n        policy = self._make_one()\n        policy.bindings = [\n            {\"role\": \"to/keep\", \"members\": set([\"phred@example.com\"])},\n            {\"role\": \"to/remove\", \"members\": set([\"phred@example.com\"])},\n        ]\n        del policy[\"to/remove\"]\n        assert len(policy) == 1\n        assert dict(policy) == {\"to/keep\": set([\"phred@example.com\"])}\n\n    def test___delitem___miss(self):\n        policy = self._make_one()\n        with pytest.raises(KeyError):\n            del policy[\"nonesuch\"]\n\n    def test___delitem___version3(self):\n        policy = self._make_one(\"DEADBEEF\", 3)\n        with pytest.raises(InvalidOperationException, match=_DICT_ACCESS_MSG):\n            del policy[\"role/reader\"]\n\n    def test___delitem___with_conditions(self):\n        USER = \"user:phred@example.com\"\n        CONDITION = {\"expression\": \"2 > 1\"}\n        policy = self._make_one(\"DEADBEEF\", 1)\n        policy.bindings = [\n            {\"role\": \"role/reader\", \"members\": set([USER]), \"condition\": CONDITION}\n        ]\n        with pytest.raises(InvalidOperationException, match=_DICT_ACCESS_MSG):\n            del policy[\"role/reader\"]\n\n    def test_bindings_property(self):\n        USER = \"user:phred@example.com\"\n        CONDITION = {\"expression\": \"2 > 1\"}\n        policy = self._make_one()\n        BINDINGS = [\n            {\"role\": \"role/reader\", \"members\": set([USER]), \"condition\": CONDITION}\n        ]\n        policy.bindings = BINDINGS\n        assert policy.bindings == BINDINGS\n\n    def test_owners_getter(self):\n        from google.api_core.iam import OWNER_ROLE\n\n        MEMBER = \"user:phred@example.com\"\n        expected = frozenset([MEMBER])\n        policy = self._make_one()\n        policy[OWNER_ROLE] = [MEMBER]\n        assert policy.owners == expected\n\n    def test_owners_setter(self):\n        from google.api_core.iam import OWNER_ROLE\n\n        MEMBER = \"user:phred@example.com\"\n        expected = set([MEMBER])\n        policy = self._make_one()\n\n        with pytest.warns(\n            DeprecationWarning, match=\"Assigning to 'owners' is deprecated.\"\n        ) as warned:\n            policy.owners = [MEMBER]\n\n        (warning,) = warned\n        assert warning.category is DeprecationWarning\n        assert policy[OWNER_ROLE] == expected\n\n    def test_editors_getter(self):\n        from google.api_core.iam import EDITOR_ROLE\n\n        MEMBER = \"user:phred@example.com\"\n        expected = frozenset([MEMBER])\n        policy = self._make_one()\n        policy[EDITOR_ROLE] = [MEMBER]\n        assert policy.editors == expected\n\n    def test_editors_setter(self):\n        from google.api_core.iam import EDITOR_ROLE\n\n        MEMBER = \"user:phred@example.com\"\n        expected = set([MEMBER])\n        policy = self._make_one()\n\n        with pytest.warns(\n            DeprecationWarning, match=\"Assigning to 'editors' is deprecated.\"\n        ) as warned:\n            policy.editors = [MEMBER]\n\n        (warning,) = warned\n        assert warning.category is DeprecationWarning\n        assert policy[EDITOR_ROLE] == expected\n\n    def test_viewers_getter(self):\n        from google.api_core.iam import VIEWER_ROLE\n\n        MEMBER = \"user:phred@example.com\"\n        expected = frozenset([MEMBER])\n        policy = self._make_one()\n        policy[VIEWER_ROLE] = [MEMBER]\n        assert policy.viewers == expected\n\n    def test_viewers_setter(self):\n        from google.api_core.iam import VIEWER_ROLE\n\n        MEMBER = \"user:phred@example.com\"\n        expected = set([MEMBER])\n        policy = self._make_one()\n\n        with pytest.warns(\n            DeprecationWarning, match=\"Assigning to 'viewers' is deprecated.\"\n        ) as warned:\n            policy.viewers = [MEMBER]\n\n        (warning,) = warned\n        assert warning.category is DeprecationWarning\n        assert policy[VIEWER_ROLE] == expected\n\n    def test_user(self):\n        EMAIL = \"phred@example.com\"\n        MEMBER = \"user:%s\" % (EMAIL,)\n        policy = self._make_one()\n        assert policy.user(EMAIL) == MEMBER\n\n    def test_service_account(self):\n        EMAIL = \"phred@example.com\"\n        MEMBER = \"serviceAccount:%s\" % (EMAIL,)\n        policy = self._make_one()\n        assert policy.service_account(EMAIL) == MEMBER\n\n    def test_group(self):\n        EMAIL = \"phred@example.com\"\n        MEMBER = \"group:%s\" % (EMAIL,)\n        policy = self._make_one()\n        assert policy.group(EMAIL) == MEMBER\n\n    def test_domain(self):\n        DOMAIN = \"example.com\"\n        MEMBER = \"domain:%s\" % (DOMAIN,)\n        policy = self._make_one()\n        assert policy.domain(DOMAIN) == MEMBER\n\n    def test_all_users(self):\n        policy = self._make_one()\n        assert policy.all_users() == \"allUsers\"\n\n    def test_authenticated_users(self):\n        policy = self._make_one()\n        assert policy.authenticated_users() == \"allAuthenticatedUsers\"\n\n    def test_from_api_repr_only_etag(self):\n        empty = frozenset()\n        RESOURCE = {\"etag\": \"ACAB\"}\n        klass = self._get_target_class()\n        policy = klass.from_api_repr(RESOURCE)\n        assert policy.etag == \"ACAB\"\n        assert policy.version is None\n        assert policy.owners == empty\n        assert policy.editors == empty\n        assert policy.viewers == empty\n        assert dict(policy) == {}\n\n    def test_from_api_repr_complete(self):\n        from google.api_core.iam import OWNER_ROLE, EDITOR_ROLE, VIEWER_ROLE\n\n        OWNER1 = \"group:cloud-logs@google.com\"\n        OWNER2 = \"user:phred@example.com\"\n        EDITOR1 = \"domain:google.com\"\n        EDITOR2 = \"user:phred@example.com\"\n        VIEWER1 = \"serviceAccount:1234-abcdef@service.example.com\"\n        VIEWER2 = \"user:phred@example.com\"\n        RESOURCE = {\n            \"etag\": \"DEADBEEF\",\n            \"version\": 1,\n            \"bindings\": [\n                {\"role\": OWNER_ROLE, \"members\": [OWNER1, OWNER2]},\n                {\"role\": EDITOR_ROLE, \"members\": [EDITOR1, EDITOR2]},\n                {\"role\": VIEWER_ROLE, \"members\": [VIEWER1, VIEWER2]},\n            ],\n        }\n        klass = self._get_target_class()\n        policy = klass.from_api_repr(RESOURCE)\n        assert policy.etag == \"DEADBEEF\"\n        assert policy.version == 1\n        assert policy.owners, frozenset([OWNER1 == OWNER2])\n        assert policy.editors, frozenset([EDITOR1 == EDITOR2])\n        assert policy.viewers, frozenset([VIEWER1 == VIEWER2])\n        assert dict(policy) == {\n            OWNER_ROLE: set([OWNER1, OWNER2]),\n            EDITOR_ROLE: set([EDITOR1, EDITOR2]),\n            VIEWER_ROLE: set([VIEWER1, VIEWER2]),\n        }\n        assert policy.bindings == [\n            {\"role\": OWNER_ROLE, \"members\": set([OWNER1, OWNER2])},\n            {\"role\": EDITOR_ROLE, \"members\": set([EDITOR1, EDITOR2])},\n            {\"role\": VIEWER_ROLE, \"members\": set([VIEWER1, VIEWER2])},\n        ]\n\n    def test_from_api_repr_unknown_role(self):\n        USER = \"user:phred@example.com\"\n        GROUP = \"group:cloud-logs@google.com\"\n        RESOURCE = {\n            \"etag\": \"DEADBEEF\",\n            \"version\": 1,\n            \"bindings\": [{\"role\": \"unknown\", \"members\": [USER, GROUP]}],\n        }\n        klass = self._get_target_class()\n        policy = klass.from_api_repr(RESOURCE)\n        assert policy.etag == \"DEADBEEF\"\n        assert policy.version == 1\n        assert dict(policy), {\"unknown\": set([GROUP == USER])}\n\n    def test_to_api_repr_defaults(self):\n        policy = self._make_one()\n        assert policy.to_api_repr() == {}\n\n    def test_to_api_repr_only_etag(self):\n        policy = self._make_one(\"DEADBEEF\")\n        assert policy.to_api_repr() == {\"etag\": \"DEADBEEF\"}\n\n    def test_to_api_repr_binding_wo_members(self):\n        policy = self._make_one()\n        policy[\"empty\"] = []\n        assert policy.to_api_repr() == {}\n\n    def test_to_api_repr_binding_w_duplicates(self):\n        from google.api_core.iam import OWNER_ROLE\n\n        OWNER = \"group:cloud-logs@google.com\"\n        policy = self._make_one()\n        with pytest.warns(\n            DeprecationWarning, match=\"Assigning to 'owners' is deprecated.\"\n        ):\n            policy.owners = [OWNER, OWNER]\n        assert policy.to_api_repr() == {\n            \"bindings\": [{\"role\": OWNER_ROLE, \"members\": [OWNER]}]\n        }\n\n    def test_to_api_repr_full(self):\n        import operator\n        from google.api_core.iam import OWNER_ROLE, EDITOR_ROLE, VIEWER_ROLE\n\n        OWNER1 = \"group:cloud-logs@google.com\"\n        OWNER2 = \"user:phred@example.com\"\n        EDITOR1 = \"domain:google.com\"\n        EDITOR2 = \"user:phred@example.com\"\n        VIEWER1 = \"serviceAccount:1234-abcdef@service.example.com\"\n        VIEWER2 = \"user:phred@example.com\"\n        CONDITION = {\n            \"title\": \"title\",\n            \"description\": \"description\",\n            \"expression\": \"true\",\n        }\n        BINDINGS = [\n            {\"role\": OWNER_ROLE, \"members\": [OWNER1, OWNER2]},\n            {\"role\": EDITOR_ROLE, \"members\": [EDITOR1, EDITOR2]},\n            {\"role\": VIEWER_ROLE, \"members\": [VIEWER1, VIEWER2]},\n            {\n                \"role\": VIEWER_ROLE,\n                \"members\": [VIEWER1, VIEWER2],\n                \"condition\": CONDITION,\n            },\n        ]\n        policy = self._make_one(\"DEADBEEF\", 1)\n        policy.bindings = BINDINGS\n        resource = policy.to_api_repr()\n        assert resource[\"etag\"] == \"DEADBEEF\"\n        assert resource[\"version\"] == 1\n        key = operator.itemgetter(\"role\")\n        assert sorted(resource[\"bindings\"], key=key) == sorted(BINDINGS, key=key)\n", "tests/unit/test_exceptions.py": "# Copyright 2014 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport http.client\nimport json\n\nimport mock\nimport pytest\nimport requests\n\ntry:\n    import grpc\n    from grpc_status import rpc_status\nexcept ImportError:  # pragma: NO COVER\n    grpc = rpc_status = None\n\nfrom google.api_core import exceptions\nfrom google.protobuf import any_pb2, json_format\nfrom google.rpc import error_details_pb2, status_pb2\n\n\ndef test_create_google_cloud_error():\n    exception = exceptions.GoogleAPICallError(\"Testing\")\n    exception.code = 600\n    assert str(exception) == \"600 Testing\"\n    assert exception.message == \"Testing\"\n    assert exception.errors == []\n    assert exception.response is None\n\n\ndef test_create_google_cloud_error_with_args():\n    error = {\n        \"code\": 600,\n        \"message\": \"Testing\",\n    }\n    response = mock.sentinel.response\n    exception = exceptions.GoogleAPICallError(\"Testing\", [error], response=response)\n    exception.code = 600\n    assert str(exception) == \"600 Testing\"\n    assert exception.message == \"Testing\"\n    assert exception.errors == [error]\n    assert exception.response == response\n\n\ndef test_from_http_status():\n    message = \"message\"\n    exception = exceptions.from_http_status(http.client.NOT_FOUND, message)\n    assert exception.code == http.client.NOT_FOUND\n    assert exception.message == message\n    assert exception.errors == []\n\n\ndef test_from_http_status_with_errors_and_response():\n    message = \"message\"\n    errors = [\"1\", \"2\"]\n    response = mock.sentinel.response\n    exception = exceptions.from_http_status(\n        http.client.NOT_FOUND, message, errors=errors, response=response\n    )\n\n    assert isinstance(exception, exceptions.NotFound)\n    assert exception.code == http.client.NOT_FOUND\n    assert exception.message == message\n    assert exception.errors == errors\n    assert exception.response == response\n\n\ndef test_from_http_status_unknown_code():\n    message = \"message\"\n    status_code = 156\n    exception = exceptions.from_http_status(status_code, message)\n    assert exception.code == status_code\n    assert exception.message == message\n\n\ndef make_response(content):\n    response = requests.Response()\n    response._content = content\n    response.status_code = http.client.NOT_FOUND\n    response.request = requests.Request(\n        method=\"POST\", url=\"https://example.com\"\n    ).prepare()\n    return response\n\n\ndef test_from_http_response_no_content():\n    response = make_response(None)\n\n    exception = exceptions.from_http_response(response)\n\n    assert isinstance(exception, exceptions.NotFound)\n    assert exception.code == http.client.NOT_FOUND\n    assert exception.message == \"POST https://example.com/: unknown error\"\n    assert exception.response == response\n\n\ndef test_from_http_response_text_content():\n    response = make_response(b\"message\")\n    response.encoding = \"UTF8\"  # suppress charset_normalizer warning\n\n    exception = exceptions.from_http_response(response)\n\n    assert isinstance(exception, exceptions.NotFound)\n    assert exception.code == http.client.NOT_FOUND\n    assert exception.message == \"POST https://example.com/: message\"\n\n\ndef test_from_http_response_json_content():\n    response = make_response(\n        json.dumps({\"error\": {\"message\": \"json message\", \"errors\": [\"1\", \"2\"]}}).encode(\n            \"utf-8\"\n        )\n    )\n\n    exception = exceptions.from_http_response(response)\n\n    assert isinstance(exception, exceptions.NotFound)\n    assert exception.code == http.client.NOT_FOUND\n    assert exception.message == \"POST https://example.com/: json message\"\n    assert exception.errors == [\"1\", \"2\"]\n\n\ndef test_from_http_response_bad_json_content():\n    response = make_response(json.dumps({\"meep\": \"moop\"}).encode(\"utf-8\"))\n\n    exception = exceptions.from_http_response(response)\n\n    assert isinstance(exception, exceptions.NotFound)\n    assert exception.code == http.client.NOT_FOUND\n    assert exception.message == \"POST https://example.com/: unknown error\"\n\n\ndef test_from_http_response_json_unicode_content():\n    response = make_response(\n        json.dumps(\n            {\"error\": {\"message\": \"\\u2019 message\", \"errors\": [\"1\", \"2\"]}}\n        ).encode(\"utf-8\")\n    )\n\n    exception = exceptions.from_http_response(response)\n\n    assert isinstance(exception, exceptions.NotFound)\n    assert exception.code == http.client.NOT_FOUND\n    assert exception.message == \"POST https://example.com/: \\u2019 message\"\n    assert exception.errors == [\"1\", \"2\"]\n\n\n@pytest.mark.skipif(grpc is None, reason=\"No grpc\")\ndef test_from_grpc_status():\n    message = \"message\"\n    exception = exceptions.from_grpc_status(grpc.StatusCode.OUT_OF_RANGE, message)\n    assert isinstance(exception, exceptions.BadRequest)\n    assert isinstance(exception, exceptions.OutOfRange)\n    assert exception.code == http.client.BAD_REQUEST\n    assert exception.grpc_status_code == grpc.StatusCode.OUT_OF_RANGE\n    assert exception.message == message\n    assert exception.errors == []\n\n\n@pytest.mark.skipif(grpc is None, reason=\"No grpc\")\ndef test_from_grpc_status_as_int():\n    message = \"message\"\n    exception = exceptions.from_grpc_status(11, message)\n    assert isinstance(exception, exceptions.BadRequest)\n    assert isinstance(exception, exceptions.OutOfRange)\n    assert exception.code == http.client.BAD_REQUEST\n    assert exception.grpc_status_code == grpc.StatusCode.OUT_OF_RANGE\n    assert exception.message == message\n    assert exception.errors == []\n\n\n@pytest.mark.skipif(grpc is None, reason=\"No grpc\")\ndef test_from_grpc_status_with_errors_and_response():\n    message = \"message\"\n    response = mock.sentinel.response\n    errors = [\"1\", \"2\"]\n    exception = exceptions.from_grpc_status(\n        grpc.StatusCode.OUT_OF_RANGE, message, errors=errors, response=response\n    )\n\n    assert isinstance(exception, exceptions.OutOfRange)\n    assert exception.message == message\n    assert exception.errors == errors\n    assert exception.response == response\n\n\n@pytest.mark.skipif(grpc is None, reason=\"No grpc\")\ndef test_from_grpc_status_unknown_code():\n    message = \"message\"\n    exception = exceptions.from_grpc_status(grpc.StatusCode.OK, message)\n    assert exception.grpc_status_code == grpc.StatusCode.OK\n    assert exception.message == message\n\n\n@pytest.mark.skipif(grpc is None, reason=\"No grpc\")\ndef test_from_grpc_error():\n    message = \"message\"\n    error = mock.create_autospec(grpc.Call, instance=True)\n    error.code.return_value = grpc.StatusCode.INVALID_ARGUMENT\n    error.details.return_value = message\n\n    exception = exceptions.from_grpc_error(error)\n\n    assert isinstance(exception, exceptions.BadRequest)\n    assert isinstance(exception, exceptions.InvalidArgument)\n    assert exception.code == http.client.BAD_REQUEST\n    assert exception.grpc_status_code == grpc.StatusCode.INVALID_ARGUMENT\n    assert exception.message == message\n    assert exception.errors == [error]\n    assert exception.response == error\n\n\n@pytest.mark.skipif(grpc is None, reason=\"No grpc\")\ndef test_from_grpc_error_non_call():\n    message = \"message\"\n    error = mock.create_autospec(grpc.RpcError, instance=True)\n    error.__str__.return_value = message\n\n    exception = exceptions.from_grpc_error(error)\n\n    assert isinstance(exception, exceptions.GoogleAPICallError)\n    assert exception.code is None\n    assert exception.grpc_status_code is None\n    assert exception.message == message\n    assert exception.errors == [error]\n    assert exception.response == error\n\n\n@pytest.mark.skipif(grpc is None, reason=\"No grpc\")\ndef test_from_grpc_error_bare_call():\n    message = \"Testing\"\n\n    class TestingError(grpc.Call, grpc.RpcError):\n        def __init__(self, exception):\n            self.exception = exception\n\n        def code(self):\n            return self.exception.grpc_status_code\n\n        def details(self):\n            return message\n\n    nested_message = \"message\"\n    error = TestingError(exceptions.GoogleAPICallError(nested_message))\n\n    exception = exceptions.from_grpc_error(error)\n\n    assert isinstance(exception, exceptions.GoogleAPICallError)\n    assert exception.code is None\n    assert exception.grpc_status_code is None\n    assert exception.message == message\n    assert exception.errors == [error]\n    assert exception.response == error\n    assert exception.details == []\n\n\ndef create_bad_request_details():\n    bad_request_details = error_details_pb2.BadRequest()\n    field_violation = bad_request_details.field_violations.add()\n    field_violation.field = \"document.content\"\n    field_violation.description = \"Must have some text content to annotate.\"\n    status_detail = any_pb2.Any()\n    status_detail.Pack(bad_request_details)\n    return status_detail\n\n\ndef create_error_info_details():\n    info = error_details_pb2.ErrorInfo(\n        reason=\"SERVICE_DISABLED\",\n        domain=\"googleapis.com\",\n        metadata={\n            \"consumer\": \"projects/455411330361\",\n            \"service\": \"translate.googleapis.com\",\n        },\n    )\n    status_detail = any_pb2.Any()\n    status_detail.Pack(info)\n    return status_detail\n\n\ndef test_error_details_from_rest_response():\n    bad_request_detail = create_bad_request_details()\n    error_info_detail = create_error_info_details()\n    status = status_pb2.Status()\n    status.code = 3\n    status.message = (\n        \"3 INVALID_ARGUMENT: One of content, or gcs_content_uri must be set.\"\n    )\n    status.details.append(bad_request_detail)\n    status.details.append(error_info_detail)\n\n    # See JSON schema in https://cloud.google.com/apis/design/errors#http_mapping\n    http_response = make_response(\n        json.dumps(\n            {\"error\": json.loads(json_format.MessageToJson(status, sort_keys=True))}\n        ).encode(\"utf-8\")\n    )\n    exception = exceptions.from_http_response(http_response)\n    want_error_details = [\n        json.loads(json_format.MessageToJson(bad_request_detail)),\n        json.loads(json_format.MessageToJson(error_info_detail)),\n    ]\n    assert want_error_details == exception.details\n\n    # 404 POST comes from make_response.\n    assert str(exception) == (\n        \"404 POST https://example.com/: 3 INVALID_ARGUMENT:\"\n        \" One of content, or gcs_content_uri must be set.\"\n        \" [{'@type': 'type.googleapis.com/google.rpc.BadRequest',\"\n        \" 'fieldViolations': [{'description': 'Must have some text content to annotate.',\"\n        \" 'field': 'document.content'}]},\"\n        \" {'@type': 'type.googleapis.com/google.rpc.ErrorInfo',\"\n        \" 'domain': 'googleapis.com',\"\n        \" 'metadata': {'consumer': 'projects/455411330361',\"\n        \" 'service': 'translate.googleapis.com'},\"\n        \" 'reason': 'SERVICE_DISABLED'}]\"\n    )\n\n\ndef test_error_details_from_v1_rest_response():\n    response = make_response(\n        json.dumps(\n            {\"error\": {\"message\": \"\\u2019 message\", \"errors\": [\"1\", \"2\"]}}\n        ).encode(\"utf-8\")\n    )\n    exception = exceptions.from_http_response(response)\n    assert exception.details == []\n    assert (\n        exception.reason is None\n        and exception.domain is None\n        and exception.metadata is None\n    )\n\n\n@pytest.mark.skipif(grpc is None, reason=\"gRPC not importable\")\ndef test_error_details_from_grpc_response():\n    status = rpc_status.status_pb2.Status()\n    status.code = 3\n    status.message = (\n        \"3 INVALID_ARGUMENT: One of content, or gcs_content_uri must be set.\"\n    )\n    status_br_detail = create_bad_request_details()\n    status_ei_detail = create_error_info_details()\n    status.details.append(status_br_detail)\n    status.details.append(status_ei_detail)\n\n    # The actual error doesn't matter as long as its grpc.Call,\n    # because from_call is mocked.\n    error = mock.create_autospec(grpc.Call, instance=True)\n    with mock.patch(\"grpc_status.rpc_status.from_call\") as m:\n        m.return_value = status\n        exception = exceptions.from_grpc_error(error)\n\n    bad_request_detail = error_details_pb2.BadRequest()\n    error_info_detail = error_details_pb2.ErrorInfo()\n    status_br_detail.Unpack(bad_request_detail)\n    status_ei_detail.Unpack(error_info_detail)\n    assert exception.details == [bad_request_detail, error_info_detail]\n    assert exception.reason == error_info_detail.reason\n    assert exception.domain == error_info_detail.domain\n    assert exception.metadata == error_info_detail.metadata\n\n\n@pytest.mark.skipif(grpc is None, reason=\"gRPC not importable\")\ndef test_error_details_from_grpc_response_unknown_error():\n    status_detail = any_pb2.Any()\n\n    status = rpc_status.status_pb2.Status()\n    status.code = 3\n    status.message = (\n        \"3 INVALID_ARGUMENT: One of content, or gcs_content_uri must be set.\"\n    )\n    status.details.append(status_detail)\n\n    error = mock.create_autospec(grpc.Call, instance=True)\n    with mock.patch(\"grpc_status.rpc_status.from_call\") as m:\n        m.return_value = status\n        exception = exceptions.from_grpc_error(error)\n    assert exception.details == [status_detail]\n    assert (\n        exception.reason is None\n        and exception.domain is None\n        and exception.metadata is None\n    )\n", "tests/unit/test_extended_operation.py": "# Copyright 2022 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport dataclasses\nimport enum\nimport typing\n\nimport mock\nimport pytest\n\nfrom google.api_core import exceptions\nfrom google.api_core import extended_operation\nfrom google.api_core import retry\n\nTEST_OPERATION_NAME = \"test/extended_operation\"\n\n\n@dataclasses.dataclass(frozen=True)\nclass CustomOperation:\n    class StatusCode(enum.Enum):\n        UNKNOWN = 0\n        DONE = 1\n        PENDING = 2\n\n    class LROCustomErrors:\n        class LROCustomError:\n            def __init__(self, code: str = \"\", message: str = \"\"):\n                self.code = code\n                self.message = message\n\n        def __init__(self, errors: typing.List[LROCustomError] = []):\n            self.errors = errors\n\n    name: str\n    status: StatusCode\n    error_code: typing.Optional[int] = None\n    error_message: typing.Optional[str] = None\n    armor_class: typing.Optional[int] = None\n    # Note: `error` can be removed once proposal A from\n    # b/284179390 is implemented.\n    error: typing.Optional[LROCustomErrors] = None\n\n    # Note: in generated clients, this property must be generated for each\n    # extended operation message type.\n    # The status may be an enum, a string, or a bool. If it's a string or enum,\n    # its text is compared to the string \"DONE\".\n    @property\n    def done(self):\n        return self.status.name == \"DONE\"\n\n\ndef make_extended_operation(responses=None):\n    client_operations_responses = responses or [\n        CustomOperation(\n            name=TEST_OPERATION_NAME, status=CustomOperation.StatusCode.PENDING\n        )\n    ]\n\n    refresh = mock.Mock(spec=[\"__call__\"], side_effect=client_operations_responses)\n    refresh.responses = client_operations_responses\n    cancel = mock.Mock(spec=[\"__call__\"])\n    extended_operation_future = extended_operation.ExtendedOperation.make(\n        refresh,\n        cancel,\n        client_operations_responses[0],\n    )\n\n    return extended_operation_future, refresh, cancel\n\n\ndef test_constructor():\n    ex_op, refresh, _ = make_extended_operation()\n    assert ex_op._extended_operation == refresh.responses[0]\n    assert not ex_op.cancelled()\n    assert not ex_op.done()\n    assert ex_op.name == TEST_OPERATION_NAME\n    assert ex_op.status == CustomOperation.StatusCode.PENDING\n    assert ex_op.error_code is None\n    assert ex_op.error_message is None\n\n\ndef test_done():\n    responses = [\n        CustomOperation(\n            name=TEST_OPERATION_NAME, status=CustomOperation.StatusCode.PENDING\n        ),\n        # Second response indicates that the operation has finished.\n        CustomOperation(\n            name=TEST_OPERATION_NAME, status=CustomOperation.StatusCode.DONE\n        ),\n        # Bumper to make sure we stop polling on DONE.\n        CustomOperation(\n            name=TEST_OPERATION_NAME,\n            status=CustomOperation.StatusCode.DONE,\n            error_message=\"Gone too far!\",\n        ),\n    ]\n    ex_op, refresh, _ = make_extended_operation(responses)\n\n    # Start out not done.\n    assert not ex_op.done()\n    assert refresh.call_count == 1\n\n    # Refresh brings us to the done state.\n    assert ex_op.done()\n    assert refresh.call_count == 2\n    assert not ex_op.error_message\n\n    # Make sure that subsequent checks are no-ops.\n    assert ex_op.done()\n    assert refresh.call_count == 2\n    assert not ex_op.error_message\n\n\ndef test_cancellation():\n    responses = [\n        CustomOperation(\n            name=TEST_OPERATION_NAME, status=CustomOperation.StatusCode.PENDING\n        ),\n        # Second response indicates that the operation was cancelled.\n        CustomOperation(\n            name=TEST_OPERATION_NAME, status=CustomOperation.StatusCode.DONE\n        ),\n    ]\n    ex_op, _, cancel = make_extended_operation(responses)\n\n    assert not ex_op.cancelled()\n\n    assert ex_op.cancel()\n    assert ex_op.cancelled()\n    cancel.assert_called_once_with()\n\n    # Cancelling twice should have no effect.\n    assert not ex_op.cancel()\n    cancel.assert_called_once_with()\n\n\ndef test_done_w_retry():\n    # Not sure what's going on here with the coverage, so just ignore it.\n    test_retry = retry.Retry(predicate=lambda x: True)  # pragma: NO COVER\n\n    responses = [\n        CustomOperation(\n            name=TEST_OPERATION_NAME, status=CustomOperation.StatusCode.PENDING\n        ),\n        CustomOperation(\n            name=TEST_OPERATION_NAME, status=CustomOperation.StatusCode.DONE\n        ),\n    ]\n\n    ex_op, refresh, _ = make_extended_operation(responses)\n\n    ex_op.done(retry=test_retry)\n\n    refresh.assert_called_once_with(retry=test_retry)\n\n\ndef test_error():\n    responses = [\n        CustomOperation(\n            name=TEST_OPERATION_NAME,\n            status=CustomOperation.StatusCode.DONE,\n            error_code=400,\n            error_message=\"Bad request\",\n        ),\n    ]\n\n    ex_op, _, _ = make_extended_operation(responses)\n\n    # Defaults to CallError when grpc is not installed\n    with pytest.raises(exceptions.BadRequest):\n        ex_op.result()\n\n    # Test GCE custom LRO Error. See b/284179390\n    # Note: This test case can be removed once proposal A from\n    # b/284179390 is implemented.\n    _EXCEPTION_CODE = \"INCOMPATIBLE_BACKEND_SERVICES\"\n    _EXCEPTION_MESSAGE = \"Validation failed for instance group\"\n    responses = [\n        CustomOperation(\n            name=TEST_OPERATION_NAME,\n            status=CustomOperation.StatusCode.DONE,\n            error_code=400,\n            error_message=\"Bad request\",\n            error=CustomOperation.LROCustomErrors(\n                errors=[\n                    CustomOperation.LROCustomErrors.LROCustomError(\n                        code=_EXCEPTION_CODE, message=_EXCEPTION_MESSAGE\n                    )\n                ]\n            ),\n        ),\n    ]\n\n    ex_op, _, _ = make_extended_operation(responses)\n\n    # Defaults to CallError when grpc is not installed\n    with pytest.raises(\n        exceptions.BadRequest, match=f\"{_EXCEPTION_CODE}: {_EXCEPTION_MESSAGE}\"\n    ):\n        ex_op.result()\n\n    # Inconsistent result\n    responses = [\n        CustomOperation(\n            name=TEST_OPERATION_NAME,\n            status=CustomOperation.StatusCode.DONE,\n            error_code=2112,\n        ),\n    ]\n\n    ex_op, _, _ = make_extended_operation(responses)\n\n    with pytest.raises(exceptions.GoogleAPICallError):\n        ex_op.result()\n\n\ndef test_pass_through():\n    responses = [\n        CustomOperation(\n            name=TEST_OPERATION_NAME,\n            status=CustomOperation.StatusCode.PENDING,\n            armor_class=10,\n        ),\n        CustomOperation(\n            name=TEST_OPERATION_NAME,\n            status=CustomOperation.StatusCode.DONE,\n            armor_class=20,\n        ),\n    ]\n    ex_op, _, _ = make_extended_operation(responses)\n\n    assert ex_op.armor_class == 10\n    ex_op.result()\n    assert ex_op.armor_class == 20\n", "tests/unit/test_path_template.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import unicode_literals\n\nimport mock\nimport pytest\n\nfrom google.api import auth_pb2\nfrom google.api_core import path_template\n\n\n@pytest.mark.parametrize(\n    \"tmpl, args, kwargs, expected_result\",\n    [\n        # Basic positional params\n        [\"/v1/*\", [\"a\"], {}, \"/v1/a\"],\n        [\"/v1/**\", [\"a/b\"], {}, \"/v1/a/b\"],\n        [\"/v1/*/*\", [\"a\", \"b\"], {}, \"/v1/a/b\"],\n        [\"/v1/*/*/**\", [\"a\", \"b\", \"c/d\"], {}, \"/v1/a/b/c/d\"],\n        # Basic named params\n        [\"/v1/{name}\", [], {\"name\": \"parent\"}, \"/v1/parent\"],\n        [\"/v1/{name=**}\", [], {\"name\": \"parent/child\"}, \"/v1/parent/child\"],\n        # Named params with a sub-template\n        [\"/v1/{name=parent/*}\", [], {\"name\": \"parent/child\"}, \"/v1/parent/child\"],\n        [\n            \"/v1/{name=parent/**}\",\n            [],\n            {\"name\": \"parent/child/object\"},\n            \"/v1/parent/child/object\",\n        ],\n        # Combining positional and named params\n        [\"/v1/*/{name}\", [\"a\"], {\"name\": \"parent\"}, \"/v1/a/parent\"],\n        [\"/v1/{name}/*\", [\"a\"], {\"name\": \"parent\"}, \"/v1/parent/a\"],\n        [\n            \"/v1/{parent}/*/{child}/*\",\n            [\"a\", \"b\"],\n            {\"parent\": \"thor\", \"child\": \"thorson\"},\n            \"/v1/thor/a/thorson/b\",\n        ],\n        [\"/v1/{name}/**\", [\"a/b\"], {\"name\": \"parent\"}, \"/v1/parent/a/b\"],\n        # Combining positional and named params with sub-templates.\n        [\n            \"/v1/{name=parent/*}/*\",\n            [\"a\"],\n            {\"name\": \"parent/child\"},\n            \"/v1/parent/child/a\",\n        ],\n        [\n            \"/v1/*/{name=parent/**}\",\n            [\"a\"],\n            {\"name\": \"parent/child/object\"},\n            \"/v1/a/parent/child/object\",\n        ],\n    ],\n)\ndef test_expand_success(tmpl, args, kwargs, expected_result):\n    result = path_template.expand(tmpl, *args, **kwargs)\n    assert result == expected_result\n    assert path_template.validate(tmpl, result)\n\n\n@pytest.mark.parametrize(\n    \"tmpl, args, kwargs, exc_match\",\n    [\n        # Missing positional arg.\n        [\"v1/*\", [], {}, \"Positional\"],\n        # Missing named arg.\n        [\"v1/{name}\", [], {}, \"Named\"],\n    ],\n)\ndef test_expanded_failure(tmpl, args, kwargs, exc_match):\n    with pytest.raises(ValueError, match=exc_match):\n        path_template.expand(tmpl, *args, **kwargs)\n\n\n@pytest.mark.parametrize(\n    \"request_obj, field, expected_result\",\n    [\n        [{\"field\": \"stringValue\"}, \"field\", \"stringValue\"],\n        [{\"field\": \"stringValue\"}, \"nosuchfield\", None],\n        [{\"field\": \"stringValue\"}, \"field.subfield\", None],\n        [{\"field\": {\"subfield\": \"stringValue\"}}, \"field\", None],\n        [{\"field\": {\"subfield\": \"stringValue\"}}, \"field.subfield\", \"stringValue\"],\n        [{\"field\": {\"subfield\": [1, 2, 3]}}, \"field.subfield\", [1, 2, 3]],\n        [{\"field\": {\"subfield\": \"stringValue\"}}, \"field\", None],\n        [{\"field\": {\"subfield\": \"stringValue\"}}, \"field.nosuchfield\", None],\n        [\n            {\"field\": {\"subfield\": {\"subsubfield\": \"stringValue\"}}},\n            \"field.subfield.subsubfield\",\n            \"stringValue\",\n        ],\n        [\"string\", \"field\", None],\n    ],\n)\ndef test_get_field(request_obj, field, expected_result):\n    result = path_template.get_field(request_obj, field)\n    assert result == expected_result\n\n\n@pytest.mark.parametrize(\n    \"request_obj, field, expected_result\",\n    [\n        [{\"field\": \"stringValue\"}, \"field\", {}],\n        [{\"field\": \"stringValue\"}, \"nosuchfield\", {\"field\": \"stringValue\"}],\n        [{\"field\": \"stringValue\"}, \"field.subfield\", {\"field\": \"stringValue\"}],\n        [{\"field\": {\"subfield\": \"stringValue\"}}, \"field.subfield\", {\"field\": {}}],\n        [\n            {\"field\": {\"subfield\": \"stringValue\", \"q\": \"w\"}, \"e\": \"f\"},\n            \"field.subfield\",\n            {\"field\": {\"q\": \"w\"}, \"e\": \"f\"},\n        ],\n        [\n            {\"field\": {\"subfield\": \"stringValue\"}},\n            \"field.nosuchfield\",\n            {\"field\": {\"subfield\": \"stringValue\"}},\n        ],\n        [\n            {\"field\": {\"subfield\": {\"subsubfield\": \"stringValue\", \"q\": \"w\"}}},\n            \"field.subfield.subsubfield\",\n            {\"field\": {\"subfield\": {\"q\": \"w\"}}},\n        ],\n        [\"string\", \"field\", \"string\"],\n        [\"string\", \"field.subfield\", \"string\"],\n    ],\n)\ndef test_delete_field(request_obj, field, expected_result):\n    path_template.delete_field(request_obj, field)\n    assert request_obj == expected_result\n\n\n@pytest.mark.parametrize(\n    \"tmpl, path\",\n    [\n        # Single segment template, but multi segment value\n        [\"v1/*\", \"v1/a/b\"],\n        [\"v1/*/*\", \"v1/a/b/c\"],\n        # Single segement named template, but multi segment value\n        [\"v1/{name}\", \"v1/a/b\"],\n        [\"v1/{name}/{value}\", \"v1/a/b/c\"],\n        # Named value with a sub-template but invalid value\n        [\"v1/{name=parent/*}\", \"v1/grandparent/child\"],\n    ],\n)\ndef test_validate_failure(tmpl, path):\n    assert not path_template.validate(tmpl, path)\n\n\ndef test__expand_variable_match_unexpected():\n    match = mock.Mock(spec=[\"group\"])\n    match.group.return_value = None\n    with pytest.raises(ValueError, match=\"Unknown\"):\n        path_template._expand_variable_match([], {}, match)\n\n\ndef test__replace_variable_with_pattern():\n    match = mock.Mock(spec=[\"group\"])\n    match.group.return_value = None\n    with pytest.raises(ValueError, match=\"Unknown\"):\n        path_template._replace_variable_with_pattern(match)\n\n\n@pytest.mark.parametrize(\n    \"http_options, message, request_kwargs, expected_result\",\n    [\n        [\n            [[\"get\", \"/v1/no/template\", \"\"]],\n            None,\n            {\"foo\": \"bar\"},\n            [\"get\", \"/v1/no/template\", {}, {\"foo\": \"bar\"}],\n        ],\n        [\n            [[\"get\", \"/v1/no/template\", \"\"]],\n            auth_pb2.AuthenticationRule(selector=\"bar\"),\n            {},\n            [\n                \"get\",\n                \"/v1/no/template\",\n                None,\n                auth_pb2.AuthenticationRule(selector=\"bar\"),\n            ],\n        ],\n        # Single templates\n        [\n            [[\"get\", \"/v1/{field}\", \"\"]],\n            None,\n            {\"field\": \"parent\"},\n            [\"get\", \"/v1/parent\", {}, {}],\n        ],\n        [\n            [[\"get\", \"/v1/{selector}\", \"\"]],\n            auth_pb2.AuthenticationRule(selector=\"parent\"),\n            {},\n            [\"get\", \"/v1/parent\", None, auth_pb2.AuthenticationRule()],\n        ],\n        [\n            [[\"get\", \"/v1/{field.sub}\", \"\"]],\n            None,\n            {\"field\": {\"sub\": \"parent\"}, \"foo\": \"bar\"},\n            [\"get\", \"/v1/parent\", {}, {\"field\": {}, \"foo\": \"bar\"}],\n        ],\n        [\n            [[\"get\", \"/v1/{oauth.canonical_scopes}\", \"\"]],\n            auth_pb2.AuthenticationRule(\n                selector=\"bar\",\n                oauth=auth_pb2.OAuthRequirements(canonical_scopes=\"parent\"),\n            ),\n            {},\n            [\n                \"get\",\n                \"/v1/parent\",\n                None,\n                auth_pb2.AuthenticationRule(\n                    selector=\"bar\", oauth=auth_pb2.OAuthRequirements()\n                ),\n            ],\n        ],\n    ],\n)\ndef test_transcode_base_case(http_options, message, request_kwargs, expected_result):\n    http_options, expected_result = helper_test_transcode(http_options, expected_result)\n    result = path_template.transcode(http_options, message, **request_kwargs)\n    assert result == expected_result\n\n\n@pytest.mark.parametrize(\n    \"http_options, message, request_kwargs, expected_result\",\n    [\n        [\n            [[\"get\", \"/v1/{field.subfield}\", \"\"]],\n            None,\n            {\"field\": {\"subfield\": \"parent\"}, \"foo\": \"bar\"},\n            [\"get\", \"/v1/parent\", {}, {\"field\": {}, \"foo\": \"bar\"}],\n        ],\n        [\n            [[\"get\", \"/v1/{oauth.canonical_scopes}\", \"\"]],\n            auth_pb2.AuthenticationRule(\n                selector=\"bar\",\n                oauth=auth_pb2.OAuthRequirements(canonical_scopes=\"parent\"),\n            ),\n            {},\n            [\n                \"get\",\n                \"/v1/parent\",\n                None,\n                auth_pb2.AuthenticationRule(\n                    selector=\"bar\", oauth=auth_pb2.OAuthRequirements()\n                ),\n            ],\n        ],\n        [\n            [[\"get\", \"/v1/{field.subfield.subsubfield}\", \"\"]],\n            None,\n            {\"field\": {\"subfield\": {\"subsubfield\": \"parent\"}}, \"foo\": \"bar\"},\n            [\"get\", \"/v1/parent\", {}, {\"field\": {\"subfield\": {}}, \"foo\": \"bar\"}],\n        ],\n        [\n            [[\"get\", \"/v1/{field.subfield1}/{field.subfield2}\", \"\"]],\n            None,\n            {\"field\": {\"subfield1\": \"parent\", \"subfield2\": \"child\"}, \"foo\": \"bar\"},\n            [\"get\", \"/v1/parent/child\", {}, {\"field\": {}, \"foo\": \"bar\"}],\n        ],\n        [\n            [[\"get\", \"/v1/{selector}/{oauth.canonical_scopes}\", \"\"]],\n            auth_pb2.AuthenticationRule(\n                selector=\"parent\",\n                oauth=auth_pb2.OAuthRequirements(canonical_scopes=\"child\"),\n            ),\n            {\"field\": {\"subfield1\": \"parent\", \"subfield2\": \"child\"}, \"foo\": \"bar\"},\n            [\n                \"get\",\n                \"/v1/parent/child\",\n                None,\n                auth_pb2.AuthenticationRule(oauth=auth_pb2.OAuthRequirements()),\n            ],\n        ],\n    ],\n)\ndef test_transcode_subfields(http_options, message, request_kwargs, expected_result):\n    http_options, expected_result = helper_test_transcode(http_options, expected_result)\n    result = path_template.transcode(http_options, message, **request_kwargs)\n    assert result == expected_result\n\n\n@pytest.mark.parametrize(\n    \"http_options, message, request_kwargs, expected_result\",\n    [\n        # Single segment wildcard\n        [\n            [[\"get\", \"/v1/{field=*}\", \"\"]],\n            None,\n            {\"field\": \"parent\"},\n            [\"get\", \"/v1/parent\", {}, {}],\n        ],\n        [\n            [[\"get\", \"/v1/{selector=*}\", \"\"]],\n            auth_pb2.AuthenticationRule(selector=\"parent\"),\n            {},\n            [\"get\", \"/v1/parent\", None, auth_pb2.AuthenticationRule()],\n        ],\n        [\n            [[\"get\", \"/v1/{field=a/*/b/*}\", \"\"]],\n            None,\n            {\"field\": \"a/parent/b/child\", \"foo\": \"bar\"},\n            [\"get\", \"/v1/a/parent/b/child\", {}, {\"foo\": \"bar\"}],\n        ],\n        [\n            [[\"get\", \"/v1/{selector=a/*/b/*}\", \"\"]],\n            auth_pb2.AuthenticationRule(\n                selector=\"a/parent/b/child\", allow_without_credential=True\n            ),\n            {},\n            [\n                \"get\",\n                \"/v1/a/parent/b/child\",\n                None,\n                auth_pb2.AuthenticationRule(allow_without_credential=True),\n            ],\n        ],\n        # Double segment wildcard\n        [\n            [[\"get\", \"/v1/{field=**}\", \"\"]],\n            None,\n            {\"field\": \"parent/p1\"},\n            [\"get\", \"/v1/parent/p1\", {}, {}],\n        ],\n        [\n            [[\"get\", \"/v1/{selector=**}\", \"\"]],\n            auth_pb2.AuthenticationRule(selector=\"parent/p1\"),\n            {},\n            [\"get\", \"/v1/parent/p1\", None, auth_pb2.AuthenticationRule()],\n        ],\n        [\n            [[\"get\", \"/v1/{field=a/**/b/**}\", \"\"]],\n            None,\n            {\"field\": \"a/parent/p1/b/child/c1\", \"foo\": \"bar\"},\n            [\"get\", \"/v1/a/parent/p1/b/child/c1\", {}, {\"foo\": \"bar\"}],\n        ],\n        [\n            [[\"get\", \"/v1/{selector=a/**/b/**}\", \"\"]],\n            auth_pb2.AuthenticationRule(\n                selector=\"a/parent/p1/b/child/c1\", allow_without_credential=True\n            ),\n            {},\n            [\n                \"get\",\n                \"/v1/a/parent/p1/b/child/c1\",\n                None,\n                auth_pb2.AuthenticationRule(allow_without_credential=True),\n            ],\n        ],\n        # Combined single and double segment wildcard\n        [\n            [[\"get\", \"/v1/{field=a/*/b/**}\", \"\"]],\n            None,\n            {\"field\": \"a/parent/b/child/c1\"},\n            [\"get\", \"/v1/a/parent/b/child/c1\", {}, {}],\n        ],\n        [\n            [[\"get\", \"/v1/{selector=a/*/b/**}\", \"\"]],\n            auth_pb2.AuthenticationRule(selector=\"a/parent/b/child/c1\"),\n            {},\n            [\"get\", \"/v1/a/parent/b/child/c1\", None, auth_pb2.AuthenticationRule()],\n        ],\n        [\n            [[\"get\", \"/v1/{field=a/**/b/*}/v2/{name}\", \"\"]],\n            None,\n            {\"field\": \"a/parent/p1/b/child\", \"name\": \"first\", \"foo\": \"bar\"},\n            [\"get\", \"/v1/a/parent/p1/b/child/v2/first\", {}, {\"foo\": \"bar\"}],\n        ],\n        [\n            [[\"get\", \"/v1/{selector=a/**/b/*}/v2/{oauth.canonical_scopes}\", \"\"]],\n            auth_pb2.AuthenticationRule(\n                selector=\"a/parent/p1/b/child\",\n                oauth=auth_pb2.OAuthRequirements(canonical_scopes=\"first\"),\n            ),\n            {\"field\": \"a/parent/p1/b/child\", \"name\": \"first\", \"foo\": \"bar\"},\n            [\n                \"get\",\n                \"/v1/a/parent/p1/b/child/v2/first\",\n                None,\n                auth_pb2.AuthenticationRule(oauth=auth_pb2.OAuthRequirements()),\n            ],\n        ],\n    ],\n)\ndef test_transcode_with_wildcard(\n    http_options, message, request_kwargs, expected_result\n):\n    http_options, expected_result = helper_test_transcode(http_options, expected_result)\n    result = path_template.transcode(http_options, message, **request_kwargs)\n    assert result == expected_result\n\n\n@pytest.mark.parametrize(\n    \"http_options, message, request_kwargs, expected_result\",\n    [\n        # Single field body\n        [\n            [[\"post\", \"/v1/no/template\", \"data\"]],\n            None,\n            {\"data\": {\"id\": 1, \"info\": \"some info\"}, \"foo\": \"bar\"},\n            [\"post\", \"/v1/no/template\", {\"id\": 1, \"info\": \"some info\"}, {\"foo\": \"bar\"}],\n        ],\n        [\n            [[\"post\", \"/v1/no/template\", \"oauth\"]],\n            auth_pb2.AuthenticationRule(\n                selector=\"bar\",\n                oauth=auth_pb2.OAuthRequirements(canonical_scopes=\"child\"),\n            ),\n            {},\n            [\n                \"post\",\n                \"/v1/no/template\",\n                auth_pb2.OAuthRequirements(canonical_scopes=\"child\"),\n                auth_pb2.AuthenticationRule(selector=\"bar\"),\n            ],\n        ],\n        [\n            [[\"post\", \"/v1/{field=a/*}/b/{name=**}\", \"data\"]],\n            None,\n            {\n                \"field\": \"a/parent\",\n                \"name\": \"first/last\",\n                \"data\": {\"id\": 1, \"info\": \"some info\"},\n                \"foo\": \"bar\",\n            },\n            [\n                \"post\",\n                \"/v1/a/parent/b/first/last\",\n                {\"id\": 1, \"info\": \"some info\"},\n                {\"foo\": \"bar\"},\n            ],\n        ],\n        [\n            [[\"post\", \"/v1/{selector=a/*}/b/{oauth.canonical_scopes=**}\", \"oauth\"]],\n            auth_pb2.AuthenticationRule(\n                selector=\"a/parent\",\n                allow_without_credential=True,\n                requirements=[auth_pb2.AuthRequirement(provider_id=\"p\")],\n                oauth=auth_pb2.OAuthRequirements(canonical_scopes=\"first/last\"),\n            ),\n            {},\n            [\n                \"post\",\n                \"/v1/a/parent/b/first/last\",\n                auth_pb2.OAuthRequirements(),\n                auth_pb2.AuthenticationRule(\n                    requirements=[auth_pb2.AuthRequirement(provider_id=\"p\")],\n                    allow_without_credential=True,\n                ),\n            ],\n        ],\n        # Wildcard body\n        [\n            [[\"post\", \"/v1/{field=a/*}/b/{name=**}\", \"*\"]],\n            None,\n            {\n                \"field\": \"a/parent\",\n                \"name\": \"first/last\",\n                \"data\": {\"id\": 1, \"info\": \"some info\"},\n                \"foo\": \"bar\",\n            },\n            [\n                \"post\",\n                \"/v1/a/parent/b/first/last\",\n                {\"data\": {\"id\": 1, \"info\": \"some info\"}, \"foo\": \"bar\"},\n                {},\n            ],\n        ],\n        [\n            [[\"post\", \"/v1/{selector=a/*}/b/{oauth.canonical_scopes=**}\", \"*\"]],\n            auth_pb2.AuthenticationRule(\n                selector=\"a/parent\",\n                allow_without_credential=True,\n                oauth=auth_pb2.OAuthRequirements(canonical_scopes=\"first/last\"),\n            ),\n            {\n                \"field\": \"a/parent\",\n                \"name\": \"first/last\",\n                \"data\": {\"id\": 1, \"info\": \"some info\"},\n                \"foo\": \"bar\",\n            },\n            [\n                \"post\",\n                \"/v1/a/parent/b/first/last\",\n                auth_pb2.AuthenticationRule(\n                    allow_without_credential=True, oauth=auth_pb2.OAuthRequirements()\n                ),\n                auth_pb2.AuthenticationRule(),\n            ],\n        ],\n    ],\n)\ndef test_transcode_with_body(http_options, message, request_kwargs, expected_result):\n    http_options, expected_result = helper_test_transcode(http_options, expected_result)\n    result = path_template.transcode(http_options, message, **request_kwargs)\n    assert result == expected_result\n\n\n@pytest.mark.parametrize(\n    \"http_options, message, request_kwargs, expected_result\",\n    [\n        # Additional bindings\n        [\n            [\n                [\"post\", \"/v1/{field=a/*}/b/{name=**}\", \"extra_data\"],\n                [\"post\", \"/v1/{field=a/*}/b/{name=**}\", \"*\"],\n            ],\n            None,\n            {\n                \"field\": \"a/parent\",\n                \"name\": \"first/last\",\n                \"data\": {\"id\": 1, \"info\": \"some info\"},\n                \"foo\": \"bar\",\n            },\n            [\n                \"post\",\n                \"/v1/a/parent/b/first/last\",\n                {\"data\": {\"id\": 1, \"info\": \"some info\"}, \"foo\": \"bar\"},\n                {},\n            ],\n        ],\n        [\n            [\n                [\n                    \"post\",\n                    \"/v1/{selector=a/*}/b/{oauth.canonical_scopes=**}\",\n                    \"extra_data\",\n                ],\n                [\"post\", \"/v1/{selector=a/*}/b/{oauth.canonical_scopes=**}\", \"*\"],\n            ],\n            auth_pb2.AuthenticationRule(\n                selector=\"a/parent\",\n                allow_without_credential=True,\n                oauth=auth_pb2.OAuthRequirements(canonical_scopes=\"first/last\"),\n            ),\n            {},\n            [\n                \"post\",\n                \"/v1/a/parent/b/first/last\",\n                auth_pb2.AuthenticationRule(\n                    allow_without_credential=True, oauth=auth_pb2.OAuthRequirements()\n                ),\n                auth_pb2.AuthenticationRule(),\n            ],\n        ],\n        [\n            [\n                [\"get\", \"/v1/{field=a/*}/b/{name=**}\", \"\"],\n                [\"get\", \"/v1/{field=a/*}/b/first/last\", \"\"],\n            ],\n            None,\n            {\"field\": \"a/parent\", \"foo\": \"bar\"},\n            [\"get\", \"/v1/a/parent/b/first/last\", {}, {\"foo\": \"bar\"}],\n        ],\n        [\n            [\n                [\"get\", \"/v1/{selector=a/*}/b/{oauth.allow_without_credential=**}\", \"\"],\n                [\"get\", \"/v1/{selector=a/*}/b/first/last\", \"\"],\n            ],\n            auth_pb2.AuthenticationRule(\n                selector=\"a/parent\",\n                allow_without_credential=True,\n                oauth=auth_pb2.OAuthRequirements(),\n            ),\n            {},\n            [\n                \"get\",\n                \"/v1/a/parent/b/first/last\",\n                None,\n                auth_pb2.AuthenticationRule(\n                    allow_without_credential=True, oauth=auth_pb2.OAuthRequirements()\n                ),\n            ],\n        ],\n    ],\n)\ndef test_transcode_with_additional_bindings(\n    http_options, message, request_kwargs, expected_result\n):\n    http_options, expected_result = helper_test_transcode(http_options, expected_result)\n    result = path_template.transcode(http_options, message, **request_kwargs)\n    assert result == expected_result\n\n\n@pytest.mark.parametrize(\n    \"http_options, message, request_kwargs\",\n    [\n        [[[\"get\", \"/v1/{name}\", \"\"]], None, {\"foo\": \"bar\"}],\n        [[[\"get\", \"/v1/{selector}\", \"\"]], auth_pb2.AuthenticationRule(), {}],\n        [[[\"get\", \"/v1/{name}\", \"\"]], auth_pb2.AuthenticationRule(), {}],\n        [[[\"get\", \"/v1/{name}\", \"\"]], None, {\"name\": \"first/last\"}],\n        [\n            [[\"get\", \"/v1/{selector}\", \"\"]],\n            auth_pb2.AuthenticationRule(selector=\"first/last\"),\n            {},\n        ],\n        [[[\"get\", \"/v1/{name=mr/*/*}\", \"\"]], None, {\"name\": \"first/last\"}],\n        [\n            [[\"get\", \"/v1/{selector=mr/*/*}\", \"\"]],\n            auth_pb2.AuthenticationRule(selector=\"first/last\"),\n            {},\n        ],\n        [[[\"post\", \"/v1/{name}\", \"data\"]], None, {\"name\": \"first/last\"}],\n        [\n            [[\"post\", \"/v1/{selector}\", \"data\"]],\n            auth_pb2.AuthenticationRule(selector=\"first\"),\n            {},\n        ],\n        [[[\"post\", \"/v1/{first_name}\", \"data\"]], None, {\"last_name\": \"last\"}],\n        [\n            [[\"post\", \"/v1/{first_name}\", \"\"]],\n            auth_pb2.AuthenticationRule(selector=\"first\"),\n            {},\n        ],\n    ],\n)\ndef test_transcode_fails(http_options, message, request_kwargs):\n    http_options, _ = helper_test_transcode(http_options, range(4))\n    with pytest.raises(ValueError) as exc_info:\n        path_template.transcode(http_options, message, **request_kwargs)\n    assert str(exc_info.value).count(\"URI\") == len(http_options)\n\n\ndef helper_test_transcode(http_options_list, expected_result_list):\n    http_options = []\n    for opt_list in http_options_list:\n        http_option = {\"method\": opt_list[0], \"uri\": opt_list[1]}\n        if opt_list[2]:\n            http_option[\"body\"] = opt_list[2]\n        http_options.append(http_option)\n\n    expected_result = {\n        \"method\": expected_result_list[0],\n        \"uri\": expected_result_list[1],\n        \"query_params\": expected_result_list[3],\n    }\n    if expected_result_list[2]:\n        expected_result[\"body\"] = expected_result_list[2]\n    return (http_options, expected_result)\n", "tests/unit/test_timeout.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport datetime\nimport itertools\n\nimport mock\n\nfrom google.api_core import timeout as timeouts\n\n\ndef test__exponential_timeout_generator_base_2():\n    gen = timeouts._exponential_timeout_generator(1.0, 60.0, 2.0, deadline=None)\n\n    result = list(itertools.islice(gen, 8))\n    assert result == [1, 2, 4, 8, 16, 32, 60, 60]\n\n\n@mock.patch(\"google.api_core.datetime_helpers.utcnow\", autospec=True)\ndef test__exponential_timeout_generator_base_deadline(utcnow):\n    # Make each successive call to utcnow() advance one second.\n    utcnow.side_effect = [\n        datetime.datetime.min + datetime.timedelta(seconds=n) for n in range(15)\n    ]\n\n    gen = timeouts._exponential_timeout_generator(1.0, 60.0, 2.0, deadline=30.0)\n\n    result = list(itertools.islice(gen, 14))\n    # Should grow until the cumulative time is > 30s, then start decreasing as\n    # the cumulative time approaches 60s.\n    assert result == [1, 2, 4, 8, 16, 24, 23, 22, 21, 20, 19, 18, 17, 16]\n\n\nclass TestTimeToDeadlineTimeout(object):\n    def test_constructor(self):\n        timeout_ = timeouts.TimeToDeadlineTimeout()\n        assert timeout_._timeout is None\n\n    def test_constructor_args(self):\n        timeout_ = timeouts.TimeToDeadlineTimeout(42.0)\n        assert timeout_._timeout == 42.0\n\n    def test___str__(self):\n        timeout_ = timeouts.TimeToDeadlineTimeout(1)\n        assert str(timeout_) == \"<TimeToDeadlineTimeout timeout=1.0>\"\n\n    def test_apply(self):\n        target = mock.Mock(spec=[\"__call__\", \"__name__\"], __name__=\"target\")\n\n        datetime.datetime.now(tz=datetime.timezone.utc)\n        datetime.timedelta(seconds=1)\n\n        now = datetime.datetime.now(tz=datetime.timezone.utc)\n\n        times = [\n            now,\n            now + datetime.timedelta(seconds=0.0009),\n            now + datetime.timedelta(seconds=1),\n            now + datetime.timedelta(seconds=39),\n            now + datetime.timedelta(seconds=42),\n            now + datetime.timedelta(seconds=43),\n        ]\n\n        def _clock():\n            return times.pop(0)\n\n        timeout_ = timeouts.TimeToDeadlineTimeout(42.0, _clock)\n        wrapped = timeout_(target)\n\n        wrapped()\n        target.assert_called_with(timeout=42.0)\n        wrapped()\n        target.assert_called_with(timeout=41.0)\n        wrapped()\n        target.assert_called_with(timeout=3.0)\n        wrapped()\n        target.assert_called_with(timeout=0.0)\n        wrapped()\n        target.assert_called_with(timeout=0.0)\n\n    def test_apply_no_timeout(self):\n        target = mock.Mock(spec=[\"__call__\", \"__name__\"], __name__=\"target\")\n\n        datetime.datetime.now(tz=datetime.timezone.utc)\n        datetime.timedelta(seconds=1)\n\n        now = datetime.datetime.now(tz=datetime.timezone.utc)\n\n        times = [\n            now,\n            now + datetime.timedelta(seconds=0.0009),\n            now + datetime.timedelta(seconds=1),\n            now + datetime.timedelta(seconds=2),\n        ]\n\n        def _clock():\n            return times.pop(0)\n\n        timeout_ = timeouts.TimeToDeadlineTimeout(clock=_clock)\n        wrapped = timeout_(target)\n\n        wrapped()\n        target.assert_called_with()\n        wrapped()\n        target.assert_called_with()\n\n    def test_apply_passthrough(self):\n        target = mock.Mock(spec=[\"__call__\", \"__name__\"], __name__=\"target\")\n        timeout_ = timeouts.TimeToDeadlineTimeout(42.0)\n        wrapped = timeout_(target)\n\n        wrapped(1, 2, meep=\"moop\")\n\n        target.assert_called_once_with(1, 2, meep=\"moop\", timeout=42.0)\n\n\nclass TestConstantTimeout(object):\n    def test_constructor(self):\n        timeout_ = timeouts.ConstantTimeout()\n        assert timeout_._timeout is None\n\n    def test_constructor_args(self):\n        timeout_ = timeouts.ConstantTimeout(42.0)\n        assert timeout_._timeout == 42.0\n\n    def test___str__(self):\n        timeout_ = timeouts.ConstantTimeout(1)\n        assert str(timeout_) == \"<ConstantTimeout timeout=1.0>\"\n\n    def test_apply(self):\n        target = mock.Mock(spec=[\"__call__\", \"__name__\"], __name__=\"target\")\n        timeout_ = timeouts.ConstantTimeout(42.0)\n        wrapped = timeout_(target)\n\n        wrapped()\n\n        target.assert_called_once_with(timeout=42.0)\n\n    def test_apply_passthrough(self):\n        target = mock.Mock(spec=[\"__call__\", \"__name__\"], __name__=\"target\")\n        timeout_ = timeouts.ConstantTimeout(42.0)\n        wrapped = timeout_(target)\n\n        wrapped(1, 2, meep=\"moop\")\n\n        target.assert_called_once_with(1, 2, meep=\"moop\", timeout=42.0)\n\n\nclass TestExponentialTimeout(object):\n    def test_constructor(self):\n        timeout_ = timeouts.ExponentialTimeout()\n        assert timeout_._initial == timeouts._DEFAULT_INITIAL_TIMEOUT\n        assert timeout_._maximum == timeouts._DEFAULT_MAXIMUM_TIMEOUT\n        assert timeout_._multiplier == timeouts._DEFAULT_TIMEOUT_MULTIPLIER\n        assert timeout_._deadline == timeouts._DEFAULT_DEADLINE\n\n    def test_constructor_args(self):\n        timeout_ = timeouts.ExponentialTimeout(1, 2, 3, 4)\n        assert timeout_._initial == 1\n        assert timeout_._maximum == 2\n        assert timeout_._multiplier == 3\n        assert timeout_._deadline == 4\n\n    def test_with_timeout(self):\n        original_timeout = timeouts.ExponentialTimeout()\n        timeout_ = original_timeout.with_deadline(42)\n        assert original_timeout is not timeout_\n        assert timeout_._initial == timeouts._DEFAULT_INITIAL_TIMEOUT\n        assert timeout_._maximum == timeouts._DEFAULT_MAXIMUM_TIMEOUT\n        assert timeout_._multiplier == timeouts._DEFAULT_TIMEOUT_MULTIPLIER\n        assert timeout_._deadline == 42\n\n    def test___str__(self):\n        timeout_ = timeouts.ExponentialTimeout(1, 2, 3, 4)\n        assert str(timeout_) == (\n            \"<ExponentialTimeout initial=1.0, maximum=2.0, multiplier=3.0, \"\n            \"deadline=4.0>\"\n        )\n\n    def test_apply(self):\n        target = mock.Mock(spec=[\"__call__\", \"__name__\"], __name__=\"target\")\n        timeout_ = timeouts.ExponentialTimeout(1, 10, 2)\n        wrapped = timeout_(target)\n\n        wrapped()\n        target.assert_called_with(timeout=1)\n\n        wrapped()\n        target.assert_called_with(timeout=2)\n\n        wrapped()\n        target.assert_called_with(timeout=4)\n\n    def test_apply_passthrough(self):\n        target = mock.Mock(spec=[\"__call__\", \"__name__\"], __name__=\"target\")\n        timeout_ = timeouts.ExponentialTimeout(42.0, 100, 2)\n        wrapped = timeout_(target)\n\n        wrapped(1, 2, meep=\"moop\")\n\n        target.assert_called_once_with(1, 2, meep=\"moop\", timeout=42.0)\n", "tests/unit/test_page_iterator.py": "# Copyright 2015 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport math\nimport types\n\nimport mock\nimport pytest\n\nfrom google.api_core import page_iterator\n\n\ndef test__do_nothing_page_start():\n    assert page_iterator._do_nothing_page_start(None, None, None) is None\n\n\nclass TestPage(object):\n    def test_constructor(self):\n        parent = mock.sentinel.parent\n        item_to_value = mock.sentinel.item_to_value\n\n        page = page_iterator.Page(parent, (1, 2, 3), item_to_value)\n\n        assert page.num_items == 3\n        assert page.remaining == 3\n        assert page._parent is parent\n        assert page._item_to_value is item_to_value\n        assert page.raw_page is None\n\n    def test___iter__(self):\n        page = page_iterator.Page(None, (), None, None)\n        assert iter(page) is page\n\n    def test_iterator_calls_parent_item_to_value(self):\n        parent = mock.sentinel.parent\n\n        item_to_value = mock.Mock(\n            side_effect=lambda iterator, value: value, spec=[\"__call__\"]\n        )\n\n        page = page_iterator.Page(parent, (10, 11, 12), item_to_value)\n        page._remaining = 100\n\n        assert item_to_value.call_count == 0\n        assert page.remaining == 100\n\n        assert next(page) == 10\n        assert item_to_value.call_count == 1\n        item_to_value.assert_called_with(parent, 10)\n        assert page.remaining == 99\n\n        assert next(page) == 11\n        assert item_to_value.call_count == 2\n        item_to_value.assert_called_with(parent, 11)\n        assert page.remaining == 98\n\n        assert next(page) == 12\n        assert item_to_value.call_count == 3\n        item_to_value.assert_called_with(parent, 12)\n        assert page.remaining == 97\n\n    def test_raw_page(self):\n        parent = mock.sentinel.parent\n        item_to_value = mock.sentinel.item_to_value\n\n        raw_page = mock.sentinel.raw_page\n\n        page = page_iterator.Page(parent, (1, 2, 3), item_to_value, raw_page=raw_page)\n        assert page.raw_page is raw_page\n\n        with pytest.raises(AttributeError):\n            page.raw_page = None\n\n\nclass PageIteratorImpl(page_iterator.Iterator):\n    def _next_page(self):\n        return mock.create_autospec(page_iterator.Page, instance=True)\n\n\nclass TestIterator(object):\n    def test_constructor(self):\n        client = mock.sentinel.client\n        item_to_value = mock.sentinel.item_to_value\n        token = \"ab13nceor03\"\n        max_results = 1337\n\n        iterator = PageIteratorImpl(\n            client, item_to_value, page_token=token, max_results=max_results\n        )\n\n        assert not iterator._started\n        assert iterator.client is client\n        assert iterator.item_to_value == item_to_value\n        assert iterator.max_results == max_results\n        # Changing attributes.\n        assert iterator.page_number == 0\n        assert iterator.next_page_token == token\n        assert iterator.num_results == 0\n\n    def test_next(self):\n        iterator = PageIteratorImpl(None, None)\n        page_1 = page_iterator.Page(\n            iterator, (\"item 1.1\", \"item 1.2\"), page_iterator._item_to_value_identity\n        )\n        page_2 = page_iterator.Page(\n            iterator, (\"item 2.1\",), page_iterator._item_to_value_identity\n        )\n        iterator._next_page = mock.Mock(side_effect=[page_1, page_2, None])\n\n        result = next(iterator)\n        assert result == \"item 1.1\"\n        result = next(iterator)\n        assert result == \"item 1.2\"\n        result = next(iterator)\n        assert result == \"item 2.1\"\n\n        with pytest.raises(StopIteration):\n            next(iterator)\n\n    def test_pages_property_starts(self):\n        iterator = PageIteratorImpl(None, None)\n\n        assert not iterator._started\n\n        assert isinstance(iterator.pages, types.GeneratorType)\n\n        assert iterator._started\n\n    def test_pages_property_restart(self):\n        iterator = PageIteratorImpl(None, None)\n\n        assert iterator.pages\n\n        # Make sure we cannot restart.\n        with pytest.raises(ValueError):\n            assert iterator.pages\n\n    def test__page_iter_increment(self):\n        iterator = PageIteratorImpl(None, None)\n        page = page_iterator.Page(\n            iterator, (\"item\",), page_iterator._item_to_value_identity\n        )\n        iterator._next_page = mock.Mock(side_effect=[page, None])\n\n        assert iterator.num_results == 0\n\n        page_iter = iterator._page_iter(increment=True)\n        next(page_iter)\n\n        assert iterator.num_results == 1\n\n    def test__page_iter_no_increment(self):\n        iterator = PageIteratorImpl(None, None)\n\n        assert iterator.num_results == 0\n\n        page_iter = iterator._page_iter(increment=False)\n        next(page_iter)\n\n        # results should still be 0 after fetching a page.\n        assert iterator.num_results == 0\n\n    def test__items_iter(self):\n        # Items to be returned.\n        item1 = 17\n        item2 = 100\n        item3 = 211\n\n        # Make pages from mock responses\n        parent = mock.sentinel.parent\n        page1 = page_iterator.Page(\n            parent, (item1, item2), page_iterator._item_to_value_identity\n        )\n        page2 = page_iterator.Page(\n            parent, (item3,), page_iterator._item_to_value_identity\n        )\n\n        iterator = PageIteratorImpl(None, None)\n        iterator._next_page = mock.Mock(side_effect=[page1, page2, None])\n\n        items_iter = iterator._items_iter()\n\n        assert isinstance(items_iter, types.GeneratorType)\n\n        # Consume items and check the state of the iterator.\n        assert iterator.num_results == 0\n\n        assert next(items_iter) == item1\n        assert iterator.num_results == 1\n\n        assert next(items_iter) == item2\n        assert iterator.num_results == 2\n\n        assert next(items_iter) == item3\n        assert iterator.num_results == 3\n\n        with pytest.raises(StopIteration):\n            next(items_iter)\n\n    def test___iter__(self):\n        iterator = PageIteratorImpl(None, None)\n        iterator._next_page = mock.Mock(side_effect=[(1, 2), (3,), None])\n\n        assert not iterator._started\n\n        result = list(iterator)\n\n        assert result == [1, 2, 3]\n        assert iterator._started\n\n    def test___iter__restart(self):\n        iterator = PageIteratorImpl(None, None)\n\n        iter(iterator)\n\n        # Make sure we cannot restart.\n        with pytest.raises(ValueError):\n            iter(iterator)\n\n    def test___iter___restart_after_page(self):\n        iterator = PageIteratorImpl(None, None)\n\n        assert iterator.pages\n\n        # Make sure we cannot restart after starting the page iterator\n        with pytest.raises(ValueError):\n            iter(iterator)\n\n\nclass TestHTTPIterator(object):\n    def test_constructor(self):\n        client = mock.sentinel.client\n        path = \"/foo\"\n        iterator = page_iterator.HTTPIterator(\n            client, mock.sentinel.api_request, path, mock.sentinel.item_to_value\n        )\n\n        assert not iterator._started\n        assert iterator.client is client\n        assert iterator.path == path\n        assert iterator.item_to_value is mock.sentinel.item_to_value\n        assert iterator._items_key == \"items\"\n        assert iterator.max_results is None\n        assert iterator.extra_params == {}\n        assert iterator._page_start == page_iterator._do_nothing_page_start\n        # Changing attributes.\n        assert iterator.page_number == 0\n        assert iterator.next_page_token is None\n        assert iterator.num_results == 0\n        assert iterator._page_size is None\n\n    def test_constructor_w_extra_param_collision(self):\n        extra_params = {\"pageToken\": \"val\"}\n\n        with pytest.raises(ValueError):\n            page_iterator.HTTPIterator(\n                mock.sentinel.client,\n                mock.sentinel.api_request,\n                mock.sentinel.path,\n                mock.sentinel.item_to_value,\n                extra_params=extra_params,\n            )\n\n    def test_iterate(self):\n        path = \"/foo\"\n        item1 = {\"name\": \"1\"}\n        item2 = {\"name\": \"2\"}\n        api_request = mock.Mock(return_value={\"items\": [item1, item2]})\n        iterator = page_iterator.HTTPIterator(\n            mock.sentinel.client,\n            api_request,\n            path=path,\n            item_to_value=page_iterator._item_to_value_identity,\n        )\n\n        assert iterator.num_results == 0\n\n        items_iter = iter(iterator)\n\n        val1 = next(items_iter)\n        assert val1 == item1\n        assert iterator.num_results == 1\n\n        val2 = next(items_iter)\n        assert val2 == item2\n        assert iterator.num_results == 2\n\n        with pytest.raises(StopIteration):\n            next(items_iter)\n\n        api_request.assert_called_once_with(method=\"GET\", path=path, query_params={})\n\n    def test__has_next_page_new(self):\n        iterator = page_iterator.HTTPIterator(\n            mock.sentinel.client,\n            mock.sentinel.api_request,\n            mock.sentinel.path,\n            mock.sentinel.item_to_value,\n        )\n\n        # The iterator should *always* indicate that it has a next page\n        # when created so that it can fetch the initial page.\n        assert iterator._has_next_page()\n\n    def test__has_next_page_without_token(self):\n        iterator = page_iterator.HTTPIterator(\n            mock.sentinel.client,\n            mock.sentinel.api_request,\n            mock.sentinel.path,\n            mock.sentinel.item_to_value,\n        )\n\n        iterator.page_number = 1\n\n        # The iterator should not indicate that it has a new page if the\n        # initial page has been requested and there's no page token.\n        assert not iterator._has_next_page()\n\n    def test__has_next_page_w_number_w_token(self):\n        iterator = page_iterator.HTTPIterator(\n            mock.sentinel.client,\n            mock.sentinel.api_request,\n            mock.sentinel.path,\n            mock.sentinel.item_to_value,\n        )\n\n        iterator.page_number = 1\n        iterator.next_page_token = mock.sentinel.token\n\n        # The iterator should indicate that it has a new page if the\n        # initial page has been requested and there's is a page token.\n        assert iterator._has_next_page()\n\n    def test__has_next_page_w_max_results_not_done(self):\n        iterator = page_iterator.HTTPIterator(\n            mock.sentinel.client,\n            mock.sentinel.api_request,\n            mock.sentinel.path,\n            mock.sentinel.item_to_value,\n            max_results=3,\n            page_token=mock.sentinel.token,\n        )\n\n        iterator.page_number = 1\n\n        # The iterator should indicate that it has a new page if there\n        # is a page token and it has not consumed more than max_results.\n        assert iterator.num_results < iterator.max_results\n        assert iterator._has_next_page()\n\n    def test__has_next_page_w_max_results_done(self):\n\n        iterator = page_iterator.HTTPIterator(\n            mock.sentinel.client,\n            mock.sentinel.api_request,\n            mock.sentinel.path,\n            mock.sentinel.item_to_value,\n            max_results=3,\n            page_token=mock.sentinel.token,\n        )\n\n        iterator.page_number = 1\n        iterator.num_results = 3\n\n        # The iterator should not indicate that it has a new page if there\n        # if it has consumed more than max_results.\n        assert iterator.num_results == iterator.max_results\n        assert not iterator._has_next_page()\n\n    def test__get_query_params_no_token(self):\n        iterator = page_iterator.HTTPIterator(\n            mock.sentinel.client,\n            mock.sentinel.api_request,\n            mock.sentinel.path,\n            mock.sentinel.item_to_value,\n        )\n\n        assert iterator._get_query_params() == {}\n\n    def test__get_query_params_w_token(self):\n        iterator = page_iterator.HTTPIterator(\n            mock.sentinel.client,\n            mock.sentinel.api_request,\n            mock.sentinel.path,\n            mock.sentinel.item_to_value,\n        )\n        iterator.next_page_token = \"token\"\n\n        assert iterator._get_query_params() == {\"pageToken\": iterator.next_page_token}\n\n    def test__get_query_params_w_max_results(self):\n        max_results = 3\n        iterator = page_iterator.HTTPIterator(\n            mock.sentinel.client,\n            mock.sentinel.api_request,\n            mock.sentinel.path,\n            mock.sentinel.item_to_value,\n            max_results=max_results,\n        )\n\n        iterator.num_results = 1\n        local_max = max_results - iterator.num_results\n\n        assert iterator._get_query_params() == {\"maxResults\": local_max}\n\n    def test__get_query_params_extra_params(self):\n        extra_params = {\"key\": \"val\"}\n        iterator = page_iterator.HTTPIterator(\n            mock.sentinel.client,\n            mock.sentinel.api_request,\n            mock.sentinel.path,\n            mock.sentinel.item_to_value,\n            extra_params=extra_params,\n        )\n\n        assert iterator._get_query_params() == extra_params\n\n    def test__get_next_page_response_with_post(self):\n        path = \"/foo\"\n        page_response = {\"items\": [\"one\", \"two\"]}\n        api_request = mock.Mock(return_value=page_response)\n        iterator = page_iterator.HTTPIterator(\n            mock.sentinel.client,\n            api_request,\n            path=path,\n            item_to_value=page_iterator._item_to_value_identity,\n        )\n        iterator._HTTP_METHOD = \"POST\"\n\n        response = iterator._get_next_page_response()\n\n        assert response == page_response\n\n        api_request.assert_called_once_with(method=\"POST\", path=path, data={})\n\n    def test__get_next_page_bad_http_method(self):\n        iterator = page_iterator.HTTPIterator(\n            mock.sentinel.client,\n            mock.sentinel.api_request,\n            mock.sentinel.path,\n            mock.sentinel.item_to_value,\n        )\n        iterator._HTTP_METHOD = \"NOT-A-VERB\"\n\n        with pytest.raises(ValueError):\n            iterator._get_next_page_response()\n\n    @pytest.mark.parametrize(\n        \"page_size,max_results,pages\",\n        [(3, None, False), (3, 8, False), (3, None, True), (3, 8, True)],\n    )\n    def test_page_size_items(self, page_size, max_results, pages):\n        path = \"/foo\"\n        NITEMS = 10\n\n        n = [0]  # blast you python 2!\n\n        def api_request(*args, **kw):\n            assert not args\n            query_params = dict(\n                maxResults=(\n                    page_size\n                    if max_results is None\n                    else min(page_size, max_results - n[0])\n                )\n            )\n            if n[0]:\n                query_params.update(pageToken=\"test\")\n            assert kw == {\"method\": \"GET\", \"path\": \"/foo\", \"query_params\": query_params}\n            n_items = min(kw[\"query_params\"][\"maxResults\"], NITEMS - n[0])\n            items = [dict(name=str(i + n[0])) for i in range(n_items)]\n            n[0] += n_items\n            result = dict(items=items)\n            if n[0] < NITEMS:\n                result.update(nextPageToken=\"test\")\n            return result\n\n        iterator = page_iterator.HTTPIterator(\n            mock.sentinel.client,\n            api_request,\n            path=path,\n            item_to_value=page_iterator._item_to_value_identity,\n            page_size=page_size,\n            max_results=max_results,\n        )\n\n        assert iterator.num_results == 0\n\n        n_results = max_results if max_results is not None else NITEMS\n        if pages:\n            items_iter = iter(iterator.pages)\n            npages = int(math.ceil(float(n_results) / page_size))\n            for ipage in range(npages):\n                assert list(next(items_iter)) == [\n                    dict(name=str(i))\n                    for i in range(\n                        ipage * page_size,\n                        min((ipage + 1) * page_size, n_results),\n                    )\n                ]\n        else:\n            items_iter = iter(iterator)\n            for i in range(n_results):\n                assert next(items_iter) == dict(name=str(i))\n                assert iterator.num_results == i + 1\n\n        with pytest.raises(StopIteration):\n            next(items_iter)\n\n\nclass TestGRPCIterator(object):\n    def test_constructor(self):\n        client = mock.sentinel.client\n        items_field = \"items\"\n        iterator = page_iterator.GRPCIterator(\n            client, mock.sentinel.method, mock.sentinel.request, items_field\n        )\n\n        assert not iterator._started\n        assert iterator.client is client\n        assert iterator.max_results is None\n        assert iterator.item_to_value is page_iterator._item_to_value_identity\n        assert iterator._method == mock.sentinel.method\n        assert iterator._request == mock.sentinel.request\n        assert iterator._items_field == items_field\n        assert (\n            iterator._request_token_field\n            == page_iterator.GRPCIterator._DEFAULT_REQUEST_TOKEN_FIELD\n        )\n        assert (\n            iterator._response_token_field\n            == page_iterator.GRPCIterator._DEFAULT_RESPONSE_TOKEN_FIELD\n        )\n        # Changing attributes.\n        assert iterator.page_number == 0\n        assert iterator.next_page_token is None\n        assert iterator.num_results == 0\n\n    def test_constructor_options(self):\n        client = mock.sentinel.client\n        items_field = \"items\"\n        request_field = \"request\"\n        response_field = \"response\"\n        iterator = page_iterator.GRPCIterator(\n            client,\n            mock.sentinel.method,\n            mock.sentinel.request,\n            items_field,\n            item_to_value=mock.sentinel.item_to_value,\n            request_token_field=request_field,\n            response_token_field=response_field,\n            max_results=42,\n        )\n\n        assert iterator.client is client\n        assert iterator.max_results == 42\n        assert iterator.item_to_value is mock.sentinel.item_to_value\n        assert iterator._method == mock.sentinel.method\n        assert iterator._request == mock.sentinel.request\n        assert iterator._items_field == items_field\n        assert iterator._request_token_field == request_field\n        assert iterator._response_token_field == response_field\n\n    def test_iterate(self):\n        request = mock.Mock(spec=[\"page_token\"], page_token=None)\n        response1 = mock.Mock(items=[\"a\", \"b\"], next_page_token=\"1\")\n        response2 = mock.Mock(items=[\"c\"], next_page_token=\"2\")\n        response3 = mock.Mock(items=[\"d\"], next_page_token=\"\")\n        method = mock.Mock(side_effect=[response1, response2, response3])\n        iterator = page_iterator.GRPCIterator(\n            mock.sentinel.client, method, request, \"items\"\n        )\n\n        assert iterator.num_results == 0\n\n        items = list(iterator)\n        assert items == [\"a\", \"b\", \"c\", \"d\"]\n\n        method.assert_called_with(request)\n        assert method.call_count == 3\n        assert request.page_token == \"2\"\n\n    def test_iterate_with_max_results(self):\n        request = mock.Mock(spec=[\"page_token\"], page_token=None)\n        response1 = mock.Mock(items=[\"a\", \"b\"], next_page_token=\"1\")\n        response2 = mock.Mock(items=[\"c\"], next_page_token=\"2\")\n        response3 = mock.Mock(items=[\"d\"], next_page_token=\"\")\n        method = mock.Mock(side_effect=[response1, response2, response3])\n        iterator = page_iterator.GRPCIterator(\n            mock.sentinel.client, method, request, \"items\", max_results=3\n        )\n\n        assert iterator.num_results == 0\n\n        items = list(iterator)\n\n        assert items == [\"a\", \"b\", \"c\"]\n        assert iterator.num_results == 3\n\n        method.assert_called_with(request)\n        assert method.call_count == 2\n        assert request.page_token == \"1\"\n\n\nclass GAXPageIterator(object):\n    \"\"\"Fake object that matches gax.PageIterator\"\"\"\n\n    def __init__(self, pages, page_token=None):\n        self._pages = iter(pages)\n        self.page_token = page_token\n\n    def next(self):\n        return next(self._pages)\n\n    __next__ = next\n\n\nclass TestGAXIterator(object):\n    def test_constructor(self):\n        client = mock.sentinel.client\n        token = \"zzzyy78kl\"\n        page_iter = GAXPageIterator((), page_token=token)\n        item_to_value = page_iterator._item_to_value_identity\n        max_results = 1337\n        iterator = page_iterator._GAXIterator(\n            client, page_iter, item_to_value, max_results=max_results\n        )\n\n        assert not iterator._started\n        assert iterator.client is client\n        assert iterator.item_to_value is item_to_value\n        assert iterator.max_results == max_results\n        assert iterator._gax_page_iter is page_iter\n        # Changing attributes.\n        assert iterator.page_number == 0\n        assert iterator.next_page_token == token\n        assert iterator.num_results == 0\n\n    def test__next_page(self):\n        page_items = (29, 31)\n        page_token = \"2sde98ds2s0hh\"\n        page_iter = GAXPageIterator([page_items], page_token=page_token)\n        iterator = page_iterator._GAXIterator(\n            mock.sentinel.client, page_iter, page_iterator._item_to_value_identity\n        )\n\n        page = iterator._next_page()\n\n        assert iterator.next_page_token == page_token\n        assert isinstance(page, page_iterator.Page)\n        assert list(page) == list(page_items)\n\n        next_page = iterator._next_page()\n\n        assert next_page is None\n", "tests/unit/test_datetime_helpers.py": "# Copyright 2017, Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport calendar\nimport datetime\n\nimport pytest\n\nfrom google.api_core import datetime_helpers\nfrom google.protobuf import timestamp_pb2\n\n\nONE_MINUTE_IN_MICROSECONDS = 60 * 1e6\n\n\ndef test_utcnow():\n    result = datetime_helpers.utcnow()\n    assert isinstance(result, datetime.datetime)\n\n\ndef test_to_milliseconds():\n    dt = datetime.datetime(1970, 1, 1, 0, 0, 1, tzinfo=datetime.timezone.utc)\n    assert datetime_helpers.to_milliseconds(dt) == 1000\n\n\ndef test_to_microseconds():\n    microseconds = 314159\n    dt = datetime.datetime(1970, 1, 1, 0, 0, 0, microsecond=microseconds)\n    assert datetime_helpers.to_microseconds(dt) == microseconds\n\n\ndef test_to_microseconds_non_utc():\n    zone = datetime.timezone(datetime.timedelta(minutes=-1))\n    dt = datetime.datetime(1970, 1, 1, 0, 0, 0, tzinfo=zone)\n    assert datetime_helpers.to_microseconds(dt) == ONE_MINUTE_IN_MICROSECONDS\n\n\ndef test_to_microseconds_naive():\n    microseconds = 314159\n    dt = datetime.datetime(1970, 1, 1, 0, 0, 0, microsecond=microseconds, tzinfo=None)\n    assert datetime_helpers.to_microseconds(dt) == microseconds\n\n\ndef test_from_microseconds():\n    five_mins_from_epoch_in_microseconds = 5 * ONE_MINUTE_IN_MICROSECONDS\n    five_mins_from_epoch_datetime = datetime.datetime(\n        1970, 1, 1, 0, 5, 0, tzinfo=datetime.timezone.utc\n    )\n\n    result = datetime_helpers.from_microseconds(five_mins_from_epoch_in_microseconds)\n\n    assert result == five_mins_from_epoch_datetime\n\n\ndef test_from_iso8601_date():\n    today = datetime.date.today()\n    iso_8601_today = today.strftime(\"%Y-%m-%d\")\n\n    assert datetime_helpers.from_iso8601_date(iso_8601_today) == today\n\n\ndef test_from_iso8601_time():\n    assert datetime_helpers.from_iso8601_time(\"12:09:42\") == datetime.time(12, 9, 42)\n\n\ndef test_from_rfc3339():\n    value = \"2009-12-17T12:44:32.123456Z\"\n    assert datetime_helpers.from_rfc3339(value) == datetime.datetime(\n        2009, 12, 17, 12, 44, 32, 123456, datetime.timezone.utc\n    )\n\n\ndef test_from_rfc3339_nanos():\n    value = \"2009-12-17T12:44:32.123456Z\"\n    assert datetime_helpers.from_rfc3339_nanos(value) == datetime.datetime(\n        2009, 12, 17, 12, 44, 32, 123456, datetime.timezone.utc\n    )\n\n\ndef test_from_rfc3339_without_nanos():\n    value = \"2009-12-17T12:44:32Z\"\n    assert datetime_helpers.from_rfc3339(value) == datetime.datetime(\n        2009, 12, 17, 12, 44, 32, 0, datetime.timezone.utc\n    )\n\n\ndef test_from_rfc3339_nanos_without_nanos():\n    value = \"2009-12-17T12:44:32Z\"\n    assert datetime_helpers.from_rfc3339_nanos(value) == datetime.datetime(\n        2009, 12, 17, 12, 44, 32, 0, datetime.timezone.utc\n    )\n\n\n@pytest.mark.parametrize(\n    \"truncated, micros\",\n    [\n        (\"12345678\", 123456),\n        (\"1234567\", 123456),\n        (\"123456\", 123456),\n        (\"12345\", 123450),\n        (\"1234\", 123400),\n        (\"123\", 123000),\n        (\"12\", 120000),\n        (\"1\", 100000),\n    ],\n)\ndef test_from_rfc3339_with_truncated_nanos(truncated, micros):\n    value = \"2009-12-17T12:44:32.{}Z\".format(truncated)\n    assert datetime_helpers.from_rfc3339(value) == datetime.datetime(\n        2009, 12, 17, 12, 44, 32, micros, datetime.timezone.utc\n    )\n\n\ndef test_from_rfc3339_nanos_is_deprecated():\n    value = \"2009-12-17T12:44:32.123456Z\"\n\n    result = datetime_helpers.from_rfc3339(value)\n    result_nanos = datetime_helpers.from_rfc3339_nanos(value)\n\n    assert result == result_nanos\n\n\n@pytest.mark.parametrize(\n    \"truncated, micros\",\n    [\n        (\"12345678\", 123456),\n        (\"1234567\", 123456),\n        (\"123456\", 123456),\n        (\"12345\", 123450),\n        (\"1234\", 123400),\n        (\"123\", 123000),\n        (\"12\", 120000),\n        (\"1\", 100000),\n    ],\n)\ndef test_from_rfc3339_nanos_with_truncated_nanos(truncated, micros):\n    value = \"2009-12-17T12:44:32.{}Z\".format(truncated)\n    assert datetime_helpers.from_rfc3339_nanos(value) == datetime.datetime(\n        2009, 12, 17, 12, 44, 32, micros, datetime.timezone.utc\n    )\n\n\ndef test_from_rfc3339_wo_nanos_raise_exception():\n    value = \"2009-12-17T12:44:32\"\n    with pytest.raises(ValueError):\n        datetime_helpers.from_rfc3339(value)\n\n\ndef test_from_rfc3339_w_nanos_raise_exception():\n    value = \"2009-12-17T12:44:32.123456\"\n    with pytest.raises(ValueError):\n        datetime_helpers.from_rfc3339(value)\n\n\ndef test_to_rfc3339():\n    value = datetime.datetime(2016, 4, 5, 13, 30, 0)\n    expected = \"2016-04-05T13:30:00.000000Z\"\n    assert datetime_helpers.to_rfc3339(value) == expected\n\n\ndef test_to_rfc3339_with_utc():\n    value = datetime.datetime(2016, 4, 5, 13, 30, 0, tzinfo=datetime.timezone.utc)\n    expected = \"2016-04-05T13:30:00.000000Z\"\n    assert datetime_helpers.to_rfc3339(value, ignore_zone=False) == expected\n\n\ndef test_to_rfc3339_with_non_utc():\n    zone = datetime.timezone(datetime.timedelta(minutes=-60))\n    value = datetime.datetime(2016, 4, 5, 13, 30, 0, tzinfo=zone)\n    expected = \"2016-04-05T14:30:00.000000Z\"\n    assert datetime_helpers.to_rfc3339(value, ignore_zone=False) == expected\n\n\ndef test_to_rfc3339_with_non_utc_ignore_zone():\n    zone = datetime.timezone(datetime.timedelta(minutes=-60))\n    value = datetime.datetime(2016, 4, 5, 13, 30, 0, tzinfo=zone)\n    expected = \"2016-04-05T13:30:00.000000Z\"\n    assert datetime_helpers.to_rfc3339(value, ignore_zone=True) == expected\n\n\nclass Test_DateTimeWithNanos(object):\n    @staticmethod\n    def test_ctor_wo_nanos():\n        stamp = datetime_helpers.DatetimeWithNanoseconds(\n            2016, 12, 20, 21, 13, 47, 123456\n        )\n        assert stamp.year == 2016\n        assert stamp.month == 12\n        assert stamp.day == 20\n        assert stamp.hour == 21\n        assert stamp.minute == 13\n        assert stamp.second == 47\n        assert stamp.microsecond == 123456\n        assert stamp.nanosecond == 0\n\n    @staticmethod\n    def test_ctor_w_nanos():\n        stamp = datetime_helpers.DatetimeWithNanoseconds(\n            2016, 12, 20, 21, 13, 47, nanosecond=123456789\n        )\n        assert stamp.year == 2016\n        assert stamp.month == 12\n        assert stamp.day == 20\n        assert stamp.hour == 21\n        assert stamp.minute == 13\n        assert stamp.second == 47\n        assert stamp.microsecond == 123456\n        assert stamp.nanosecond == 123456789\n\n    @staticmethod\n    def test_ctor_w_micros_positional_and_nanos():\n        with pytest.raises(TypeError):\n            datetime_helpers.DatetimeWithNanoseconds(\n                2016, 12, 20, 21, 13, 47, 123456, nanosecond=123456789\n            )\n\n    @staticmethod\n    def test_ctor_w_micros_keyword_and_nanos():\n        with pytest.raises(TypeError):\n            datetime_helpers.DatetimeWithNanoseconds(\n                2016, 12, 20, 21, 13, 47, microsecond=123456, nanosecond=123456789\n            )\n\n    @staticmethod\n    def test_rfc3339_wo_nanos():\n        stamp = datetime_helpers.DatetimeWithNanoseconds(\n            2016, 12, 20, 21, 13, 47, 123456\n        )\n        assert stamp.rfc3339() == \"2016-12-20T21:13:47.123456Z\"\n\n    @staticmethod\n    def test_rfc3339_wo_nanos_w_leading_zero():\n        stamp = datetime_helpers.DatetimeWithNanoseconds(2016, 12, 20, 21, 13, 47, 1234)\n        assert stamp.rfc3339() == \"2016-12-20T21:13:47.001234Z\"\n\n    @staticmethod\n    def test_rfc3339_w_nanos():\n        stamp = datetime_helpers.DatetimeWithNanoseconds(\n            2016, 12, 20, 21, 13, 47, nanosecond=123456789\n        )\n        assert stamp.rfc3339() == \"2016-12-20T21:13:47.123456789Z\"\n\n    @staticmethod\n    def test_rfc3339_w_nanos_w_leading_zero():\n        stamp = datetime_helpers.DatetimeWithNanoseconds(\n            2016, 12, 20, 21, 13, 47, nanosecond=1234567\n        )\n        assert stamp.rfc3339() == \"2016-12-20T21:13:47.001234567Z\"\n\n    @staticmethod\n    def test_rfc3339_w_nanos_no_trailing_zeroes():\n        stamp = datetime_helpers.DatetimeWithNanoseconds(\n            2016, 12, 20, 21, 13, 47, nanosecond=100000000\n        )\n        assert stamp.rfc3339() == \"2016-12-20T21:13:47.1Z\"\n\n    @staticmethod\n    def test_rfc3339_w_nanos_w_leading_zero_and_no_trailing_zeros():\n        stamp = datetime_helpers.DatetimeWithNanoseconds(\n            2016, 12, 20, 21, 13, 47, nanosecond=1234500\n        )\n        assert stamp.rfc3339() == \"2016-12-20T21:13:47.0012345Z\"\n\n    @staticmethod\n    def test_from_rfc3339_w_invalid():\n        stamp = \"2016-12-20T21:13:47\"\n        with pytest.raises(ValueError):\n            datetime_helpers.DatetimeWithNanoseconds.from_rfc3339(stamp)\n\n    @staticmethod\n    def test_from_rfc3339_wo_fraction():\n        timestamp = \"2016-12-20T21:13:47Z\"\n        expected = datetime_helpers.DatetimeWithNanoseconds(\n            2016, 12, 20, 21, 13, 47, tzinfo=datetime.timezone.utc\n        )\n        stamp = datetime_helpers.DatetimeWithNanoseconds.from_rfc3339(timestamp)\n        assert stamp == expected\n\n    @staticmethod\n    def test_from_rfc3339_w_partial_precision():\n        timestamp = \"2016-12-20T21:13:47.1Z\"\n        expected = datetime_helpers.DatetimeWithNanoseconds(\n            2016, 12, 20, 21, 13, 47, microsecond=100000, tzinfo=datetime.timezone.utc\n        )\n        stamp = datetime_helpers.DatetimeWithNanoseconds.from_rfc3339(timestamp)\n        assert stamp == expected\n\n    @staticmethod\n    def test_from_rfc3339_w_full_precision():\n        timestamp = \"2016-12-20T21:13:47.123456789Z\"\n        expected = datetime_helpers.DatetimeWithNanoseconds(\n            2016, 12, 20, 21, 13, 47, nanosecond=123456789, tzinfo=datetime.timezone.utc\n        )\n        stamp = datetime_helpers.DatetimeWithNanoseconds.from_rfc3339(timestamp)\n        assert stamp == expected\n\n    @staticmethod\n    @pytest.mark.parametrize(\n        \"fractional, nanos\",\n        [\n            (\"12345678\", 123456780),\n            (\"1234567\", 123456700),\n            (\"123456\", 123456000),\n            (\"12345\", 123450000),\n            (\"1234\", 123400000),\n            (\"123\", 123000000),\n            (\"12\", 120000000),\n            (\"1\", 100000000),\n        ],\n    )\n    def test_from_rfc3339_test_nanoseconds(fractional, nanos):\n        value = \"2009-12-17T12:44:32.{}Z\".format(fractional)\n        assert (\n            datetime_helpers.DatetimeWithNanoseconds.from_rfc3339(value).nanosecond\n            == nanos\n        )\n\n    @staticmethod\n    def test_timestamp_pb_wo_nanos_naive():\n        stamp = datetime_helpers.DatetimeWithNanoseconds(\n            2016, 12, 20, 21, 13, 47, 123456\n        )\n        delta = (\n            stamp.replace(tzinfo=datetime.timezone.utc) - datetime_helpers._UTC_EPOCH\n        )\n        seconds = int(delta.total_seconds())\n        nanos = 123456000\n        timestamp = timestamp_pb2.Timestamp(seconds=seconds, nanos=nanos)\n        assert stamp.timestamp_pb() == timestamp\n\n    @staticmethod\n    def test_timestamp_pb_w_nanos():\n        stamp = datetime_helpers.DatetimeWithNanoseconds(\n            2016, 12, 20, 21, 13, 47, nanosecond=123456789, tzinfo=datetime.timezone.utc\n        )\n        delta = stamp - datetime_helpers._UTC_EPOCH\n        timestamp = timestamp_pb2.Timestamp(\n            seconds=int(delta.total_seconds()), nanos=123456789\n        )\n        assert stamp.timestamp_pb() == timestamp\n\n    @staticmethod\n    def test_from_timestamp_pb_wo_nanos():\n        when = datetime.datetime(\n            2016, 12, 20, 21, 13, 47, 123456, tzinfo=datetime.timezone.utc\n        )\n        delta = when - datetime_helpers._UTC_EPOCH\n        seconds = int(delta.total_seconds())\n        timestamp = timestamp_pb2.Timestamp(seconds=seconds)\n\n        stamp = datetime_helpers.DatetimeWithNanoseconds.from_timestamp_pb(timestamp)\n\n        assert _to_seconds(when) == _to_seconds(stamp)\n        assert stamp.microsecond == 0\n        assert stamp.nanosecond == 0\n        assert stamp.tzinfo == datetime.timezone.utc\n\n    @staticmethod\n    def test_from_timestamp_pb_w_nanos():\n        when = datetime.datetime(\n            2016, 12, 20, 21, 13, 47, 123456, tzinfo=datetime.timezone.utc\n        )\n        delta = when - datetime_helpers._UTC_EPOCH\n        seconds = int(delta.total_seconds())\n        timestamp = timestamp_pb2.Timestamp(seconds=seconds, nanos=123456789)\n\n        stamp = datetime_helpers.DatetimeWithNanoseconds.from_timestamp_pb(timestamp)\n\n        assert _to_seconds(when) == _to_seconds(stamp)\n        assert stamp.microsecond == 123456\n        assert stamp.nanosecond == 123456789\n        assert stamp.tzinfo == datetime.timezone.utc\n\n\ndef _to_seconds(value):\n    \"\"\"Convert a datetime to seconds since the unix epoch.\n\n    Args:\n        value (datetime.datetime): The datetime to covert.\n\n    Returns:\n        int: Microseconds since the unix epoch.\n    \"\"\"\n    assert value.tzinfo is datetime.timezone.utc\n    return calendar.timegm(value.timetuple())\n", "tests/unit/__init__.py": "", "tests/unit/test_rest_streaming.py": "# Copyright 2021 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport datetime\nimport logging\nimport random\nimport time\nfrom typing import List\nfrom unittest.mock import patch\n\nimport proto\nimport pytest\nimport requests\n\nfrom google.api_core import rest_streaming\nfrom google.api import http_pb2\nfrom google.api import httpbody_pb2\nfrom google.protobuf import duration_pb2\nfrom google.protobuf import timestamp_pb2\nfrom google.protobuf.json_format import MessageToJson\n\n\n__protobuf__ = proto.module(package=__name__)\nSEED = int(time.time())\nlogging.info(f\"Starting rest streaming tests with random seed: {SEED}\")\nrandom.seed(SEED)\n\n\nclass Genre(proto.Enum):\n    GENRE_UNSPECIFIED = 0\n    CLASSICAL = 1\n    JAZZ = 2\n    ROCK = 3\n\n\nclass Composer(proto.Message):\n    given_name = proto.Field(proto.STRING, number=1)\n    family_name = proto.Field(proto.STRING, number=2)\n    relateds = proto.RepeatedField(proto.STRING, number=3)\n    indices = proto.MapField(proto.STRING, proto.STRING, number=4)\n\n\nclass Song(proto.Message):\n    composer = proto.Field(Composer, number=1)\n    title = proto.Field(proto.STRING, number=2)\n    lyrics = proto.Field(proto.STRING, number=3)\n    year = proto.Field(proto.INT32, number=4)\n    genre = proto.Field(Genre, number=5)\n    is_five_mins_longer = proto.Field(proto.BOOL, number=6)\n    score = proto.Field(proto.DOUBLE, number=7)\n    likes = proto.Field(proto.INT64, number=8)\n    duration = proto.Field(duration_pb2.Duration, number=9)\n    date_added = proto.Field(timestamp_pb2.Timestamp, number=10)\n\n\nclass EchoResponse(proto.Message):\n    content = proto.Field(proto.STRING, number=1)\n\n\nclass ResponseMock(requests.Response):\n    class _ResponseItr:\n        def __init__(self, _response_bytes: bytes, random_split=False):\n            self._responses_bytes = _response_bytes\n            self._i = 0\n            self._random_split = random_split\n\n        def __next__(self):\n            if self._i == len(self._responses_bytes):\n                raise StopIteration\n            if self._random_split:\n                n = random.randint(1, len(self._responses_bytes[self._i :]))\n            else:\n                n = 1\n            x = self._responses_bytes[self._i : self._i + n]\n            self._i += n\n            return x.decode(\"utf-8\")\n\n    def __init__(\n        self,\n        responses: List[proto.Message],\n        response_cls,\n        random_split=False,\n    ):\n        super().__init__()\n        self._responses = responses\n        self._random_split = random_split\n        self._response_message_cls = response_cls\n\n    def _parse_responses(self, responses: List[proto.Message]) -> bytes:\n        # json.dumps returns a string surrounded with quotes that need to be stripped\n        # in order to be an actual JSON.\n        json_responses = [\n            (\n                self._response_message_cls.to_json(r).strip('\"')\n                if issubclass(self._response_message_cls, proto.Message)\n                else MessageToJson(r).strip('\"')\n            )\n            for r in responses\n        ]\n        logging.info(f\"Sending JSON stream: {json_responses}\")\n        ret_val = \"[{}]\".format(\",\".join(json_responses))\n        return bytes(ret_val, \"utf-8\")\n\n    def close(self):\n        raise NotImplementedError()\n\n    def iter_content(self, *args, **kwargs):\n        return self._ResponseItr(\n            self._parse_responses(self._responses),\n            random_split=self._random_split,\n        )\n\n\n@pytest.mark.parametrize(\n    \"random_split,resp_message_is_proto_plus\",\n    [(False, True), (False, False)],\n)\ndef test_next_simple(random_split, resp_message_is_proto_plus):\n    if resp_message_is_proto_plus:\n        response_type = EchoResponse\n        responses = [EchoResponse(content=\"hello world\"), EchoResponse(content=\"yes\")]\n    else:\n        response_type = httpbody_pb2.HttpBody\n        responses = [\n            httpbody_pb2.HttpBody(content_type=\"hello world\"),\n            httpbody_pb2.HttpBody(content_type=\"yes\"),\n        ]\n\n    resp = ResponseMock(\n        responses=responses, random_split=random_split, response_cls=response_type\n    )\n    itr = rest_streaming.ResponseIterator(resp, response_type)\n    assert list(itr) == responses\n\n\n@pytest.mark.parametrize(\n    \"random_split,resp_message_is_proto_plus\",\n    [\n        (True, True),\n        (False, True),\n        (True, False),\n        (False, False),\n    ],\n)\ndef test_next_nested(random_split, resp_message_is_proto_plus):\n    if resp_message_is_proto_plus:\n        response_type = Song\n        responses = [\n            Song(title=\"some song\", composer=Composer(given_name=\"some name\")),\n            Song(title=\"another song\", date_added=datetime.datetime(2021, 12, 17)),\n        ]\n    else:\n        # Although `http_pb2.HttpRule`` is used in the response, any response message\n        # can be used which meets this criteria for the test of having a nested field.\n        response_type = http_pb2.HttpRule\n        responses = [\n            http_pb2.HttpRule(\n                selector=\"some selector\",\n                custom=http_pb2.CustomHttpPattern(kind=\"some kind\"),\n            ),\n            http_pb2.HttpRule(\n                selector=\"another selector\",\n                custom=http_pb2.CustomHttpPattern(path=\"some path\"),\n            ),\n        ]\n    resp = ResponseMock(\n        responses=responses, random_split=random_split, response_cls=response_type\n    )\n    itr = rest_streaming.ResponseIterator(resp, response_type)\n    assert list(itr) == responses\n\n\n@pytest.mark.parametrize(\n    \"random_split,resp_message_is_proto_plus\",\n    [\n        (True, True),\n        (False, True),\n        (True, False),\n        (False, False),\n    ],\n)\ndef test_next_stress(random_split, resp_message_is_proto_plus):\n    n = 50\n    if resp_message_is_proto_plus:\n        response_type = Song\n        responses = [\n            Song(title=\"title_%d\" % i, composer=Composer(given_name=\"name_%d\" % i))\n            for i in range(n)\n        ]\n    else:\n        response_type = http_pb2.HttpRule\n        responses = [\n            http_pb2.HttpRule(\n                selector=\"selector_%d\" % i,\n                custom=http_pb2.CustomHttpPattern(path=\"path_%d\" % i),\n            )\n            for i in range(n)\n        ]\n    resp = ResponseMock(\n        responses=responses, random_split=random_split, response_cls=response_type\n    )\n    itr = rest_streaming.ResponseIterator(resp, response_type)\n    assert list(itr) == responses\n\n\n@pytest.mark.parametrize(\n    \"random_split,resp_message_is_proto_plus\",\n    [\n        (True, True),\n        (False, True),\n        (True, False),\n        (False, False),\n    ],\n)\ndef test_next_escaped_characters_in_string(random_split, resp_message_is_proto_plus):\n    if resp_message_is_proto_plus:\n        response_type = Song\n        composer_with_relateds = Composer()\n        relateds = [\"Artist A\", \"Artist B\"]\n        composer_with_relateds.relateds = relateds\n\n        responses = [\n            Song(\n                title='ti\"tle\\nfoo\\tbar{}', composer=Composer(given_name=\"name\\n\\n\\n\")\n            ),\n            Song(\n                title='{\"this is weird\": \"totally\"}',\n                composer=Composer(given_name=\"\\\\{}\\\\\"),\n            ),\n            Song(title='\\\\{\"key\": [\"value\",]}\\\\', composer=composer_with_relateds),\n        ]\n    else:\n        response_type = http_pb2.Http\n        responses = [\n            http_pb2.Http(\n                rules=[\n                    http_pb2.HttpRule(\n                        selector='ti\"tle\\nfoo\\tbar{}',\n                        custom=http_pb2.CustomHttpPattern(kind=\"name\\n\\n\\n\"),\n                    )\n                ]\n            ),\n            http_pb2.Http(\n                rules=[\n                    http_pb2.HttpRule(\n                        selector='{\"this is weird\": \"totally\"}',\n                        custom=http_pb2.CustomHttpPattern(kind=\"\\\\{}\\\\\"),\n                    )\n                ]\n            ),\n            http_pb2.Http(\n                rules=[\n                    http_pb2.HttpRule(\n                        selector='\\\\{\"key\": [\"value\",]}\\\\',\n                        custom=http_pb2.CustomHttpPattern(kind=\"\\\\{}\\\\\"),\n                    )\n                ]\n            ),\n        ]\n    resp = ResponseMock(\n        responses=responses, random_split=random_split, response_cls=response_type\n    )\n    itr = rest_streaming.ResponseIterator(resp, response_type)\n    assert list(itr) == responses\n\n\n@pytest.mark.parametrize(\"response_type\", [EchoResponse, httpbody_pb2.HttpBody])\ndef test_next_not_array(response_type):\n    with patch.object(\n        ResponseMock, \"iter_content\", return_value=iter('{\"hello\": 0}')\n    ) as mock_method:\n        resp = ResponseMock(responses=[], response_cls=response_type)\n        itr = rest_streaming.ResponseIterator(resp, response_type)\n        with pytest.raises(ValueError):\n            next(itr)\n        mock_method.assert_called_once()\n\n\n@pytest.mark.parametrize(\"response_type\", [EchoResponse, httpbody_pb2.HttpBody])\ndef test_cancel(response_type):\n    with patch.object(ResponseMock, \"close\", return_value=None) as mock_method:\n        resp = ResponseMock(responses=[], response_cls=response_type)\n        itr = rest_streaming.ResponseIterator(resp, response_type)\n        itr.cancel()\n        mock_method.assert_called_once()\n\n\n@pytest.mark.parametrize(\n    \"response_type,return_value\",\n    [\n        (EchoResponse, bytes('[{\"content\": \"hello\"}, {', \"utf-8\")),\n        (httpbody_pb2.HttpBody, bytes('[{\"content_type\": \"hello\"}, {', \"utf-8\")),\n    ],\n)\ndef test_check_buffer(response_type, return_value):\n    with patch.object(\n        ResponseMock,\n        \"_parse_responses\",\n        return_value=return_value,\n    ):\n        resp = ResponseMock(responses=[], response_cls=response_type)\n        itr = rest_streaming.ResponseIterator(resp, response_type)\n        with pytest.raises(ValueError):\n            next(itr)\n            next(itr)\n\n\n@pytest.mark.parametrize(\"response_type\", [EchoResponse, httpbody_pb2.HttpBody])\ndef test_next_html(response_type):\n    with patch.object(\n        ResponseMock, \"iter_content\", return_value=iter(\"<!DOCTYPE html><html></html>\")\n    ) as mock_method:\n        resp = ResponseMock(responses=[], response_cls=response_type)\n        itr = rest_streaming.ResponseIterator(resp, response_type)\n        with pytest.raises(ValueError):\n            next(itr)\n        mock_method.assert_called_once()\n\n\ndef test_invalid_response_class():\n    class SomeClass:\n        pass\n\n    resp = ResponseMock(responses=[], response_cls=SomeClass)\n    response_iterator = rest_streaming.ResponseIterator(resp, SomeClass)\n    with pytest.raises(\n        ValueError,\n        match=\"Response message class must be a subclass of proto.Message or google.protobuf.message.Message\",\n    ):\n        response_iterator._grab()\n", "tests/unit/test_client_info.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\ntry:\n    import grpc\nexcept ImportError:  # pragma: NO COVER\n    grpc = None\n\nfrom google.api_core import client_info\n\n\ndef test_constructor_defaults():\n    info = client_info.ClientInfo()\n\n    assert info.python_version is not None\n\n    if grpc is not None:  # pragma: NO COVER\n        assert info.grpc_version is not None\n    else:  # pragma: NO COVER\n        assert info.grpc_version is None\n\n    assert info.api_core_version is not None\n    assert info.gapic_version is None\n    assert info.client_library_version is None\n    assert info.rest_version is None\n\n\ndef test_constructor_options():\n    info = client_info.ClientInfo(\n        python_version=\"1\",\n        grpc_version=\"2\",\n        api_core_version=\"3\",\n        gapic_version=\"4\",\n        client_library_version=\"5\",\n        user_agent=\"6\",\n        rest_version=\"7\",\n    )\n\n    assert info.python_version == \"1\"\n    assert info.grpc_version == \"2\"\n    assert info.api_core_version == \"3\"\n    assert info.gapic_version == \"4\"\n    assert info.client_library_version == \"5\"\n    assert info.user_agent == \"6\"\n    assert info.rest_version == \"7\"\n\n\ndef test_to_user_agent_minimal():\n    info = client_info.ClientInfo(\n        python_version=\"1\", api_core_version=\"2\", grpc_version=None\n    )\n\n    user_agent = info.to_user_agent()\n\n    assert user_agent == \"gl-python/1 gax/2\"\n\n\ndef test_to_user_agent_full():\n    info = client_info.ClientInfo(\n        python_version=\"1\",\n        grpc_version=\"2\",\n        api_core_version=\"3\",\n        gapic_version=\"4\",\n        client_library_version=\"5\",\n        user_agent=\"app-name/1.0\",\n    )\n\n    user_agent = info.to_user_agent()\n\n    assert user_agent == \"app-name/1.0 gl-python/1 grpc/2 gax/3 gapic/4 gccl/5\"\n\n\ndef test_to_user_agent_rest():\n    info = client_info.ClientInfo(\n        python_version=\"1\",\n        grpc_version=None,\n        rest_version=\"2\",\n        api_core_version=\"3\",\n        gapic_version=\"4\",\n        client_library_version=\"5\",\n        user_agent=\"app-name/1.0\",\n    )\n\n    user_agent = info.to_user_agent()\n\n    assert user_agent == \"app-name/1.0 gl-python/1 rest/2 gax/3 gapic/4 gccl/5\"\n", "tests/unit/test_protobuf_helpers.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport pytest\n\nfrom google.api import http_pb2\nfrom google.api_core import protobuf_helpers\nfrom google.longrunning import operations_pb2\nfrom google.protobuf import any_pb2\nfrom google.protobuf import message\nfrom google.protobuf import source_context_pb2\nfrom google.protobuf import struct_pb2\nfrom google.protobuf import timestamp_pb2\nfrom google.protobuf import type_pb2\nfrom google.protobuf import wrappers_pb2\nfrom google.type import color_pb2\nfrom google.type import date_pb2\nfrom google.type import timeofday_pb2\n\n\ndef test_from_any_pb_success():\n    in_message = date_pb2.Date(year=1990)\n    in_message_any = any_pb2.Any()\n    in_message_any.Pack(in_message)\n    out_message = protobuf_helpers.from_any_pb(date_pb2.Date, in_message_any)\n\n    assert in_message == out_message\n\n\ndef test_from_any_pb_wrapped_success():\n    # Declare a message class conforming to wrapped messages.\n    class WrappedDate(object):\n        def __init__(self, **kwargs):\n            self._pb = date_pb2.Date(**kwargs)\n\n        def __eq__(self, other):\n            return self._pb == other\n\n        @classmethod\n        def pb(cls, msg):\n            return msg._pb\n\n    # Run the same test as `test_from_any_pb_success`, but using the\n    # wrapped class.\n    in_message = date_pb2.Date(year=1990)\n    in_message_any = any_pb2.Any()\n    in_message_any.Pack(in_message)\n    out_message = protobuf_helpers.from_any_pb(WrappedDate, in_message_any)\n\n    assert out_message == in_message\n\n\ndef test_from_any_pb_failure():\n    in_message = any_pb2.Any()\n    in_message.Pack(date_pb2.Date(year=1990))\n\n    with pytest.raises(TypeError):\n        protobuf_helpers.from_any_pb(timeofday_pb2.TimeOfDay, in_message)\n\n\ndef test_check_protobuf_helpers_ok():\n    assert protobuf_helpers.check_oneof() is None\n    assert protobuf_helpers.check_oneof(foo=\"bar\") is None\n    assert protobuf_helpers.check_oneof(foo=\"bar\", baz=None) is None\n    assert protobuf_helpers.check_oneof(foo=None, baz=\"bacon\") is None\n    assert protobuf_helpers.check_oneof(foo=\"bar\", spam=None, eggs=None) is None\n\n\ndef test_check_protobuf_helpers_failures():\n    with pytest.raises(ValueError):\n        protobuf_helpers.check_oneof(foo=\"bar\", spam=\"eggs\")\n    with pytest.raises(ValueError):\n        protobuf_helpers.check_oneof(foo=\"bar\", baz=\"bacon\", spam=\"eggs\")\n    with pytest.raises(ValueError):\n        protobuf_helpers.check_oneof(foo=\"bar\", spam=0, eggs=None)\n\n\ndef test_get_messages():\n    answer = protobuf_helpers.get_messages(date_pb2)\n\n    # Ensure that Date was exported properly.\n    assert answer[\"Date\"] is date_pb2.Date\n\n    # Ensure that no non-Message objects were exported.\n    for value in answer.values():\n        assert issubclass(value, message.Message)\n\n\ndef test_get_dict_absent():\n    with pytest.raises(KeyError):\n        assert protobuf_helpers.get({}, \"foo\")\n\n\ndef test_get_dict_present():\n    assert protobuf_helpers.get({\"foo\": \"bar\"}, \"foo\") == \"bar\"\n\n\ndef test_get_dict_default():\n    assert protobuf_helpers.get({}, \"foo\", default=\"bar\") == \"bar\"\n\n\ndef test_get_dict_nested():\n    assert protobuf_helpers.get({\"foo\": {\"bar\": \"baz\"}}, \"foo.bar\") == \"baz\"\n\n\ndef test_get_dict_nested_default():\n    assert protobuf_helpers.get({}, \"foo.baz\", default=\"bacon\") == \"bacon\"\n    assert protobuf_helpers.get({\"foo\": {}}, \"foo.baz\", default=\"bacon\") == \"bacon\"\n\n\ndef test_get_msg_sentinel():\n    msg = timestamp_pb2.Timestamp()\n    with pytest.raises(KeyError):\n        assert protobuf_helpers.get(msg, \"foo\")\n\n\ndef test_get_msg_present():\n    msg = timestamp_pb2.Timestamp(seconds=42)\n    assert protobuf_helpers.get(msg, \"seconds\") == 42\n\n\ndef test_get_msg_default():\n    msg = timestamp_pb2.Timestamp()\n    assert protobuf_helpers.get(msg, \"foo\", default=\"bar\") == \"bar\"\n\n\ndef test_invalid_object():\n    with pytest.raises(TypeError):\n        protobuf_helpers.get(object(), \"foo\", \"bar\")\n\n\ndef test_set_dict():\n    mapping = {}\n    protobuf_helpers.set(mapping, \"foo\", \"bar\")\n    assert mapping == {\"foo\": \"bar\"}\n\n\ndef test_set_msg():\n    msg = timestamp_pb2.Timestamp()\n    protobuf_helpers.set(msg, \"seconds\", 42)\n    assert msg.seconds == 42\n\n\ndef test_set_dict_nested():\n    mapping = {}\n    protobuf_helpers.set(mapping, \"foo.bar\", \"baz\")\n    assert mapping == {\"foo\": {\"bar\": \"baz\"}}\n\n\ndef test_set_invalid_object():\n    with pytest.raises(TypeError):\n        protobuf_helpers.set(object(), \"foo\", \"bar\")\n\n\ndef test_set_list():\n    list_ops_response = operations_pb2.ListOperationsResponse()\n\n    protobuf_helpers.set(\n        list_ops_response,\n        \"operations\",\n        [{\"name\": \"foo\"}, operations_pb2.Operation(name=\"bar\")],\n    )\n\n    assert len(list_ops_response.operations) == 2\n\n    for operation in list_ops_response.operations:\n        assert isinstance(operation, operations_pb2.Operation)\n\n    assert list_ops_response.operations[0].name == \"foo\"\n    assert list_ops_response.operations[1].name == \"bar\"\n\n\ndef test_set_list_clear_existing():\n    list_ops_response = operations_pb2.ListOperationsResponse(\n        operations=[{\"name\": \"baz\"}]\n    )\n\n    protobuf_helpers.set(\n        list_ops_response,\n        \"operations\",\n        [{\"name\": \"foo\"}, operations_pb2.Operation(name=\"bar\")],\n    )\n\n    assert len(list_ops_response.operations) == 2\n    for operation in list_ops_response.operations:\n        assert isinstance(operation, operations_pb2.Operation)\n    assert list_ops_response.operations[0].name == \"foo\"\n    assert list_ops_response.operations[1].name == \"bar\"\n\n\ndef test_set_msg_with_msg_field():\n    rule = http_pb2.HttpRule()\n    pattern = http_pb2.CustomHttpPattern(kind=\"foo\", path=\"bar\")\n\n    protobuf_helpers.set(rule, \"custom\", pattern)\n\n    assert rule.custom.kind == \"foo\"\n    assert rule.custom.path == \"bar\"\n\n\ndef test_set_msg_with_dict_field():\n    rule = http_pb2.HttpRule()\n    pattern = {\"kind\": \"foo\", \"path\": \"bar\"}\n\n    protobuf_helpers.set(rule, \"custom\", pattern)\n\n    assert rule.custom.kind == \"foo\"\n    assert rule.custom.path == \"bar\"\n\n\ndef test_set_msg_nested_key():\n    rule = http_pb2.HttpRule(custom=http_pb2.CustomHttpPattern(kind=\"foo\", path=\"bar\"))\n\n    protobuf_helpers.set(rule, \"custom.kind\", \"baz\")\n\n    assert rule.custom.kind == \"baz\"\n    assert rule.custom.path == \"bar\"\n\n\ndef test_setdefault_dict_unset():\n    mapping = {}\n    protobuf_helpers.setdefault(mapping, \"foo\", \"bar\")\n    assert mapping == {\"foo\": \"bar\"}\n\n\ndef test_setdefault_dict_falsy():\n    mapping = {\"foo\": None}\n    protobuf_helpers.setdefault(mapping, \"foo\", \"bar\")\n    assert mapping == {\"foo\": \"bar\"}\n\n\ndef test_setdefault_dict_truthy():\n    mapping = {\"foo\": \"bar\"}\n    protobuf_helpers.setdefault(mapping, \"foo\", \"baz\")\n    assert mapping == {\"foo\": \"bar\"}\n\n\ndef test_setdefault_pb2_falsy():\n    operation = operations_pb2.Operation()\n    protobuf_helpers.setdefault(operation, \"name\", \"foo\")\n    assert operation.name == \"foo\"\n\n\ndef test_setdefault_pb2_truthy():\n    operation = operations_pb2.Operation(name=\"bar\")\n    protobuf_helpers.setdefault(operation, \"name\", \"foo\")\n    assert operation.name == \"bar\"\n\n\ndef test_field_mask_invalid_args():\n    with pytest.raises(ValueError):\n        protobuf_helpers.field_mask(\"foo\", any_pb2.Any())\n    with pytest.raises(ValueError):\n        protobuf_helpers.field_mask(any_pb2.Any(), \"bar\")\n    with pytest.raises(ValueError):\n        protobuf_helpers.field_mask(any_pb2.Any(), operations_pb2.Operation())\n\n\ndef test_field_mask_equal_values():\n    assert protobuf_helpers.field_mask(None, None).paths == []\n\n    original = struct_pb2.Value(number_value=1.0)\n    modified = struct_pb2.Value(number_value=1.0)\n    assert protobuf_helpers.field_mask(original, modified).paths == []\n\n    original = color_pb2.Color(alpha=wrappers_pb2.FloatValue(value=1.0))\n    modified = color_pb2.Color(alpha=wrappers_pb2.FloatValue(value=1.0))\n    assert protobuf_helpers.field_mask(original, modified).paths == []\n\n    original = struct_pb2.ListValue(values=[struct_pb2.Value(number_value=1.0)])\n    modified = struct_pb2.ListValue(values=[struct_pb2.Value(number_value=1.0)])\n    assert protobuf_helpers.field_mask(original, modified).paths == []\n\n    original = struct_pb2.Struct(fields={\"bar\": struct_pb2.Value(number_value=1.0)})\n    modified = struct_pb2.Struct(fields={\"bar\": struct_pb2.Value(number_value=1.0)})\n    assert protobuf_helpers.field_mask(original, modified).paths == []\n\n\ndef test_field_mask_zero_values():\n    # Singular Values\n    original = color_pb2.Color(red=0.0)\n    modified = None\n    assert protobuf_helpers.field_mask(original, modified).paths == []\n\n    original = None\n    modified = color_pb2.Color(red=0.0)\n    assert protobuf_helpers.field_mask(original, modified).paths == []\n\n    # Repeated Values\n    original = struct_pb2.ListValue(values=[])\n    modified = None\n    assert protobuf_helpers.field_mask(original, modified).paths == []\n\n    original = None\n    modified = struct_pb2.ListValue(values=[])\n    assert protobuf_helpers.field_mask(original, modified).paths == []\n\n    # Maps\n    original = struct_pb2.Struct(fields={})\n    modified = None\n    assert protobuf_helpers.field_mask(original, modified).paths == []\n\n    original = None\n    modified = struct_pb2.Struct(fields={})\n    assert protobuf_helpers.field_mask(original, modified).paths == []\n\n    # Oneofs\n    original = struct_pb2.Value(number_value=0.0)\n    modified = None\n    assert protobuf_helpers.field_mask(original, modified).paths == []\n\n    original = None\n    modified = struct_pb2.Value(number_value=0.0)\n    assert protobuf_helpers.field_mask(original, modified).paths == []\n\n\ndef test_field_mask_singular_field_diffs():\n    original = type_pb2.Type(name=\"name\")\n    modified = type_pb2.Type()\n    assert protobuf_helpers.field_mask(original, modified).paths == [\"name\"]\n\n    original = type_pb2.Type(name=\"name\")\n    modified = type_pb2.Type()\n    assert protobuf_helpers.field_mask(original, modified).paths == [\"name\"]\n\n    original = None\n    modified = type_pb2.Type(name=\"name\")\n    assert protobuf_helpers.field_mask(original, modified).paths == [\"name\"]\n\n    original = type_pb2.Type(name=\"name\")\n    modified = None\n    assert protobuf_helpers.field_mask(original, modified).paths == [\"name\"]\n\n\ndef test_field_mask_message_diffs():\n    original = type_pb2.Type()\n    modified = type_pb2.Type(\n        source_context=source_context_pb2.SourceContext(file_name=\"name\")\n    )\n    assert protobuf_helpers.field_mask(original, modified).paths == [\n        \"source_context.file_name\"\n    ]\n\n    original = type_pb2.Type(\n        source_context=source_context_pb2.SourceContext(file_name=\"name\")\n    )\n    modified = type_pb2.Type()\n    assert protobuf_helpers.field_mask(original, modified).paths == [\"source_context\"]\n\n    original = type_pb2.Type(\n        source_context=source_context_pb2.SourceContext(file_name=\"name\")\n    )\n    modified = type_pb2.Type(\n        source_context=source_context_pb2.SourceContext(file_name=\"other_name\")\n    )\n    assert protobuf_helpers.field_mask(original, modified).paths == [\n        \"source_context.file_name\"\n    ]\n\n    original = None\n    modified = type_pb2.Type(\n        source_context=source_context_pb2.SourceContext(file_name=\"name\")\n    )\n    assert protobuf_helpers.field_mask(original, modified).paths == [\n        \"source_context.file_name\"\n    ]\n\n    original = type_pb2.Type(\n        source_context=source_context_pb2.SourceContext(file_name=\"name\")\n    )\n    modified = None\n    assert protobuf_helpers.field_mask(original, modified).paths == [\"source_context\"]\n\n\ndef test_field_mask_wrapper_type_diffs():\n    original = color_pb2.Color()\n    modified = color_pb2.Color(alpha=wrappers_pb2.FloatValue(value=1.0))\n    assert protobuf_helpers.field_mask(original, modified).paths == [\"alpha\"]\n\n    original = color_pb2.Color(alpha=wrappers_pb2.FloatValue(value=1.0))\n    modified = color_pb2.Color()\n    assert protobuf_helpers.field_mask(original, modified).paths == [\"alpha\"]\n\n    original = color_pb2.Color(alpha=wrappers_pb2.FloatValue(value=1.0))\n    modified = color_pb2.Color(alpha=wrappers_pb2.FloatValue(value=2.0))\n    assert protobuf_helpers.field_mask(original, modified).paths == [\"alpha\"]\n\n    original = None\n    modified = color_pb2.Color(alpha=wrappers_pb2.FloatValue(value=2.0))\n    assert protobuf_helpers.field_mask(original, modified).paths == [\"alpha\"]\n\n    original = color_pb2.Color(alpha=wrappers_pb2.FloatValue(value=1.0))\n    modified = None\n    assert protobuf_helpers.field_mask(original, modified).paths == [\"alpha\"]\n\n\ndef test_field_mask_repeated_diffs():\n    original = struct_pb2.ListValue()\n    modified = struct_pb2.ListValue(\n        values=[struct_pb2.Value(number_value=1.0), struct_pb2.Value(number_value=2.0)]\n    )\n    assert protobuf_helpers.field_mask(original, modified).paths == [\"values\"]\n\n    original = struct_pb2.ListValue(\n        values=[struct_pb2.Value(number_value=1.0), struct_pb2.Value(number_value=2.0)]\n    )\n    modified = struct_pb2.ListValue()\n    assert protobuf_helpers.field_mask(original, modified).paths == [\"values\"]\n\n    original = None\n    modified = struct_pb2.ListValue(\n        values=[struct_pb2.Value(number_value=1.0), struct_pb2.Value(number_value=2.0)]\n    )\n    assert protobuf_helpers.field_mask(original, modified).paths == [\"values\"]\n\n    original = struct_pb2.ListValue(\n        values=[struct_pb2.Value(number_value=1.0), struct_pb2.Value(number_value=2.0)]\n    )\n    modified = None\n    assert protobuf_helpers.field_mask(original, modified).paths == [\"values\"]\n\n    original = struct_pb2.ListValue(\n        values=[struct_pb2.Value(number_value=1.0), struct_pb2.Value(number_value=2.0)]\n    )\n    modified = struct_pb2.ListValue(\n        values=[struct_pb2.Value(number_value=2.0), struct_pb2.Value(number_value=1.0)]\n    )\n    assert protobuf_helpers.field_mask(original, modified).paths == [\"values\"]\n\n\ndef test_field_mask_map_diffs():\n    original = struct_pb2.Struct()\n    modified = struct_pb2.Struct(fields={\"foo\": struct_pb2.Value(number_value=1.0)})\n    assert protobuf_helpers.field_mask(original, modified).paths == [\"fields\"]\n\n    original = struct_pb2.Struct(fields={\"foo\": struct_pb2.Value(number_value=1.0)})\n    modified = struct_pb2.Struct()\n    assert protobuf_helpers.field_mask(original, modified).paths == [\"fields\"]\n\n    original = None\n    modified = struct_pb2.Struct(fields={\"foo\": struct_pb2.Value(number_value=1.0)})\n    assert protobuf_helpers.field_mask(original, modified).paths == [\"fields\"]\n\n    original = struct_pb2.Struct(fields={\"foo\": struct_pb2.Value(number_value=1.0)})\n    modified = None\n    assert protobuf_helpers.field_mask(original, modified).paths == [\"fields\"]\n\n    original = struct_pb2.Struct(fields={\"foo\": struct_pb2.Value(number_value=1.0)})\n    modified = struct_pb2.Struct(fields={\"foo\": struct_pb2.Value(number_value=2.0)})\n    assert protobuf_helpers.field_mask(original, modified).paths == [\"fields\"]\n\n    original = struct_pb2.Struct(fields={\"foo\": struct_pb2.Value(number_value=1.0)})\n    modified = struct_pb2.Struct(fields={\"bar\": struct_pb2.Value(number_value=1.0)})\n    assert protobuf_helpers.field_mask(original, modified).paths == [\"fields\"]\n\n\ndef test_field_mask_different_level_diffs():\n    original = color_pb2.Color(alpha=wrappers_pb2.FloatValue(value=1.0))\n    modified = color_pb2.Color(alpha=wrappers_pb2.FloatValue(value=2.0), red=1.0)\n    assert sorted(protobuf_helpers.field_mask(original, modified).paths) == [\n        \"alpha\",\n        \"red\",\n    ]\n\n\ndef test_field_mask_ignore_trailing_underscore():\n    import proto\n\n    class Foo(proto.Message):\n        type_ = proto.Field(proto.STRING, number=1)\n        input_config = proto.Field(proto.STRING, number=2)\n\n    modified = Foo(type_=\"bar\", input_config=\"baz\")\n\n    assert sorted(protobuf_helpers.field_mask(None, Foo.pb(modified)).paths) == [\n        \"input_config\",\n        \"type\",\n    ]\n\n\ndef test_field_mask_ignore_trailing_underscore_with_nesting():\n    import proto\n\n    class Bar(proto.Message):\n        class Baz(proto.Message):\n            input_config = proto.Field(proto.STRING, number=1)\n\n        type_ = proto.Field(Baz, number=1)\n\n    modified = Bar()\n    modified.type_.input_config = \"foo\"\n\n    assert sorted(protobuf_helpers.field_mask(None, Bar.pb(modified)).paths) == [\n        \"type.input_config\",\n    ]\n", "tests/unit/test_rest_helpers.py": "# Copyright 2021 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport pytest\n\nfrom google.api_core import rest_helpers\n\n\ndef test_flatten_simple_value():\n    with pytest.raises(TypeError):\n        rest_helpers.flatten_query_params(\"abc\")\n\n\ndef test_flatten_list():\n    with pytest.raises(TypeError):\n        rest_helpers.flatten_query_params([\"abc\", \"def\"])\n\n\ndef test_flatten_none():\n    assert rest_helpers.flatten_query_params(None) == []\n\n\ndef test_flatten_empty_dict():\n    assert rest_helpers.flatten_query_params({}) == []\n\n\ndef test_flatten_simple_dict():\n    obj = {\"a\": \"abc\", \"b\": \"def\", \"c\": True, \"d\": False, \"e\": 10, \"f\": -3.76}\n    assert rest_helpers.flatten_query_params(obj) == [\n        (\"a\", \"abc\"),\n        (\"b\", \"def\"),\n        (\"c\", True),\n        (\"d\", False),\n        (\"e\", 10),\n        (\"f\", -3.76),\n    ]\n\n\ndef test_flatten_simple_dict_strict():\n    obj = {\"a\": \"abc\", \"b\": \"def\", \"c\": True, \"d\": False, \"e\": 10, \"f\": -3.76}\n    assert rest_helpers.flatten_query_params(obj, strict=True) == [\n        (\"a\", \"abc\"),\n        (\"b\", \"def\"),\n        (\"c\", \"true\"),\n        (\"d\", \"false\"),\n        (\"e\", \"10\"),\n        (\"f\", \"-3.76\"),\n    ]\n\n\ndef test_flatten_repeated_field():\n    assert rest_helpers.flatten_query_params({\"a\": [\"x\", \"y\", \"z\", None]}) == [\n        (\"a\", \"x\"),\n        (\"a\", \"y\"),\n        (\"a\", \"z\"),\n    ]\n\n\ndef test_flatten_nested_dict():\n    obj = {\"a\": {\"b\": {\"c\": [\"x\", \"y\", \"z\"]}}, \"d\": {\"e\": \"uvw\"}}\n    expected_result = [(\"a.b.c\", \"x\"), (\"a.b.c\", \"y\"), (\"a.b.c\", \"z\"), (\"d.e\", \"uvw\")]\n\n    assert rest_helpers.flatten_query_params(obj) == expected_result\n\n\ndef test_flatten_repeated_dict():\n    obj = {\n        \"a\": {\"b\": {\"c\": [{\"v\": 1}, {\"v\": 2}]}},\n        \"d\": \"uvw\",\n    }\n\n    with pytest.raises(ValueError):\n        rest_helpers.flatten_query_params(obj)\n\n\ndef test_flatten_repeated_list():\n    obj = {\n        \"a\": {\"b\": {\"c\": [[\"e\", \"f\"], [\"g\", \"h\"]]}},\n        \"d\": \"uvw\",\n    }\n\n    with pytest.raises(ValueError):\n        rest_helpers.flatten_query_params(obj)\n", "tests/unit/operations_v1/test_operations_rest_client.py": "# -*- coding: utf-8 -*-\n# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\nimport os\n\nimport mock\nimport pytest\n\ntry:\n    import grpc  # noqa: F401\nexcept ImportError:  # pragma: NO COVER\n    pytest.skip(\"No GRPC\", allow_module_level=True)\nfrom requests import Response  # noqa I201\nfrom requests.sessions import Session\n\nfrom google.api_core import client_options\nfrom google.api_core import exceptions as core_exceptions\nfrom google.api_core import gapic_v1\nfrom google.api_core.operations_v1 import AbstractOperationsClient\nfrom google.api_core.operations_v1 import pagers\nfrom google.api_core.operations_v1 import transports\nimport google.auth\nfrom google.auth import credentials as ga_credentials\nfrom google.auth.exceptions import MutualTLSChannelError\nfrom google.longrunning import operations_pb2\nfrom google.oauth2 import service_account\nfrom google.protobuf import json_format  # type: ignore\nfrom google.rpc import status_pb2  # type: ignore\n\n\nHTTP_OPTIONS = {\n    \"google.longrunning.Operations.CancelOperation\": [\n        {\"method\": \"post\", \"uri\": \"/v3/{name=operations/*}:cancel\", \"body\": \"*\"},\n    ],\n    \"google.longrunning.Operations.DeleteOperation\": [\n        {\"method\": \"delete\", \"uri\": \"/v3/{name=operations/*}\"},\n    ],\n    \"google.longrunning.Operations.GetOperation\": [\n        {\"method\": \"get\", \"uri\": \"/v3/{name=operations/*}\"},\n    ],\n    \"google.longrunning.Operations.ListOperations\": [\n        {\"method\": \"get\", \"uri\": \"/v3/{name=operations}\"},\n    ],\n}\n\n\ndef client_cert_source_callback():\n    return b\"cert bytes\", b\"key bytes\"\n\n\ndef _get_operations_client(http_options=HTTP_OPTIONS):\n    transport = transports.rest.OperationsRestTransport(\n        credentials=ga_credentials.AnonymousCredentials(), http_options=http_options\n    )\n\n    return AbstractOperationsClient(transport=transport)\n\n\n# If default endpoint is localhost, then default mtls endpoint will be the same.\n# This method modifies the default endpoint so the client can produce a different\n# mtls endpoint for endpoint testing purposes.\ndef modify_default_endpoint(client):\n    return (\n        \"foo.googleapis.com\"\n        if (\"localhost\" in client.DEFAULT_ENDPOINT)\n        else client.DEFAULT_ENDPOINT\n    )\n\n\ndef test__get_default_mtls_endpoint():\n    api_endpoint = \"example.googleapis.com\"\n    api_mtls_endpoint = \"example.mtls.googleapis.com\"\n    sandbox_endpoint = \"example.sandbox.googleapis.com\"\n    sandbox_mtls_endpoint = \"example.mtls.sandbox.googleapis.com\"\n    non_googleapi = \"api.example.com\"\n\n    assert AbstractOperationsClient._get_default_mtls_endpoint(None) is None\n    assert (\n        AbstractOperationsClient._get_default_mtls_endpoint(api_endpoint)\n        == api_mtls_endpoint\n    )\n    assert (\n        AbstractOperationsClient._get_default_mtls_endpoint(api_mtls_endpoint)\n        == api_mtls_endpoint\n    )\n    assert (\n        AbstractOperationsClient._get_default_mtls_endpoint(sandbox_endpoint)\n        == sandbox_mtls_endpoint\n    )\n    assert (\n        AbstractOperationsClient._get_default_mtls_endpoint(sandbox_mtls_endpoint)\n        == sandbox_mtls_endpoint\n    )\n    assert (\n        AbstractOperationsClient._get_default_mtls_endpoint(non_googleapi)\n        == non_googleapi\n    )\n\n\n@pytest.mark.parametrize(\"client_class\", [AbstractOperationsClient])\ndef test_operations_client_from_service_account_info(client_class):\n    creds = ga_credentials.AnonymousCredentials()\n    with mock.patch.object(\n        service_account.Credentials, \"from_service_account_info\"\n    ) as factory:\n        factory.return_value = creds\n        info = {\"valid\": True}\n        client = client_class.from_service_account_info(info)\n        assert client.transport._credentials == creds\n        assert isinstance(client, client_class)\n\n        assert client.transport._host == \"https://longrunning.googleapis.com\"\n\n\n@pytest.mark.parametrize(\n    \"transport_class,transport_name\", [(transports.OperationsRestTransport, \"rest\")]\n)\ndef test_operations_client_service_account_always_use_jwt(\n    transport_class, transport_name\n):\n    with mock.patch.object(\n        service_account.Credentials, \"with_always_use_jwt_access\", create=True\n    ) as use_jwt:\n        creds = service_account.Credentials(None, None, None)\n        transport_class(credentials=creds, always_use_jwt_access=True)\n        use_jwt.assert_called_once_with(True)\n\n    with mock.patch.object(\n        service_account.Credentials, \"with_always_use_jwt_access\", create=True\n    ) as use_jwt:\n        creds = service_account.Credentials(None, None, None)\n        transport_class(credentials=creds, always_use_jwt_access=False)\n        use_jwt.assert_not_called()\n\n\n@pytest.mark.parametrize(\"client_class\", [AbstractOperationsClient])\ndef test_operations_client_from_service_account_file(client_class):\n    creds = ga_credentials.AnonymousCredentials()\n    with mock.patch.object(\n        service_account.Credentials, \"from_service_account_file\"\n    ) as factory:\n        factory.return_value = creds\n        client = client_class.from_service_account_file(\"dummy/file/path.json\")\n        assert client.transport._credentials == creds\n        assert isinstance(client, client_class)\n\n        client = client_class.from_service_account_json(\"dummy/file/path.json\")\n        assert client.transport._credentials == creds\n        assert isinstance(client, client_class)\n\n        assert client.transport._host == \"https://longrunning.googleapis.com\"\n\n\ndef test_operations_client_get_transport_class():\n    transport = AbstractOperationsClient.get_transport_class()\n    available_transports = [\n        transports.OperationsRestTransport,\n    ]\n    assert transport in available_transports\n\n    transport = AbstractOperationsClient.get_transport_class(\"rest\")\n    assert transport == transports.OperationsRestTransport\n\n\n@pytest.mark.parametrize(\n    \"client_class,transport_class,transport_name\",\n    [(AbstractOperationsClient, transports.OperationsRestTransport, \"rest\")],\n)\n@mock.patch.object(\n    AbstractOperationsClient,\n    \"DEFAULT_ENDPOINT\",\n    modify_default_endpoint(AbstractOperationsClient),\n)\ndef test_operations_client_client_options(\n    client_class, transport_class, transport_name\n):\n    # Check that if channel is provided we won't create a new one.\n    with mock.patch.object(AbstractOperationsClient, \"get_transport_class\") as gtc:\n        transport = transport_class(credentials=ga_credentials.AnonymousCredentials())\n        client = client_class(transport=transport)\n        gtc.assert_not_called()\n\n    # Check that if channel is provided via str we will create a new one.\n    with mock.patch.object(AbstractOperationsClient, \"get_transport_class\") as gtc:\n        client = client_class(transport=transport_name)\n        gtc.assert_called()\n\n    # Check the case api_endpoint is provided.\n    options = client_options.ClientOptions(api_endpoint=\"squid.clam.whelk\")\n    with mock.patch.object(transport_class, \"__init__\") as patched:\n        patched.return_value = None\n        client = client_class(client_options=options)\n        patched.assert_called_once_with(\n            credentials=None,\n            credentials_file=None,\n            host=\"squid.clam.whelk\",\n            scopes=None,\n            client_cert_source_for_mtls=None,\n            quota_project_id=None,\n            client_info=transports.base.DEFAULT_CLIENT_INFO,\n            always_use_jwt_access=True,\n        )\n\n    # Check the case api_endpoint is not provided and GOOGLE_API_USE_MTLS_ENDPOINT is\n    # \"never\".\n    with mock.patch.dict(os.environ, {\"GOOGLE_API_USE_MTLS_ENDPOINT\": \"never\"}):\n        with mock.patch.object(transport_class, \"__init__\") as patched:\n            patched.return_value = None\n            client = client_class()\n            patched.assert_called_once_with(\n                credentials=None,\n                credentials_file=None,\n                host=client.DEFAULT_ENDPOINT,\n                scopes=None,\n                client_cert_source_for_mtls=None,\n                quota_project_id=None,\n                client_info=transports.base.DEFAULT_CLIENT_INFO,\n                always_use_jwt_access=True,\n            )\n\n    # Check the case api_endpoint is not provided and GOOGLE_API_USE_MTLS_ENDPOINT is\n    # \"always\".\n    with mock.patch.dict(os.environ, {\"GOOGLE_API_USE_MTLS_ENDPOINT\": \"always\"}):\n        with mock.patch.object(transport_class, \"__init__\") as patched:\n            patched.return_value = None\n            client = client_class()\n            patched.assert_called_once_with(\n                credentials=None,\n                credentials_file=None,\n                host=client.DEFAULT_MTLS_ENDPOINT,\n                scopes=None,\n                client_cert_source_for_mtls=None,\n                quota_project_id=None,\n                client_info=transports.base.DEFAULT_CLIENT_INFO,\n                always_use_jwt_access=True,\n            )\n\n    # Check the case api_endpoint is not provided and GOOGLE_API_USE_MTLS_ENDPOINT has\n    # unsupported value.\n    with mock.patch.dict(os.environ, {\"GOOGLE_API_USE_MTLS_ENDPOINT\": \"Unsupported\"}):\n        with pytest.raises(MutualTLSChannelError):\n            client = client_class()\n\n    # Check the case GOOGLE_API_USE_CLIENT_CERTIFICATE has unsupported value.\n    with mock.patch.dict(\n        os.environ, {\"GOOGLE_API_USE_CLIENT_CERTIFICATE\": \"Unsupported\"}\n    ):\n        with pytest.raises(ValueError):\n            client = client_class()\n\n    # Check the case quota_project_id is provided\n    options = client_options.ClientOptions(quota_project_id=\"octopus\")\n    with mock.patch.object(transport_class, \"__init__\") as patched:\n        patched.return_value = None\n        client = client_class(client_options=options)\n        patched.assert_called_once_with(\n            credentials=None,\n            credentials_file=None,\n            host=client.DEFAULT_ENDPOINT,\n            scopes=None,\n            client_cert_source_for_mtls=None,\n            quota_project_id=\"octopus\",\n            client_info=transports.base.DEFAULT_CLIENT_INFO,\n            always_use_jwt_access=True,\n        )\n\n\n@pytest.mark.parametrize(\n    \"client_class,transport_class,transport_name,use_client_cert_env\",\n    [\n        (AbstractOperationsClient, transports.OperationsRestTransport, \"rest\", \"true\"),\n        (AbstractOperationsClient, transports.OperationsRestTransport, \"rest\", \"false\"),\n    ],\n)\n@mock.patch.object(\n    AbstractOperationsClient,\n    \"DEFAULT_ENDPOINT\",\n    modify_default_endpoint(AbstractOperationsClient),\n)\n@mock.patch.dict(os.environ, {\"GOOGLE_API_USE_MTLS_ENDPOINT\": \"auto\"})\ndef test_operations_client_mtls_env_auto(\n    client_class, transport_class, transport_name, use_client_cert_env\n):\n    # This tests the endpoint autoswitch behavior. Endpoint is autoswitched to the default\n    # mtls endpoint, if GOOGLE_API_USE_CLIENT_CERTIFICATE is \"true\" and client cert exists.\n\n    # Check the case client_cert_source is provided. Whether client cert is used depends on\n    # GOOGLE_API_USE_CLIENT_CERTIFICATE value.\n    with mock.patch.dict(\n        os.environ, {\"GOOGLE_API_USE_CLIENT_CERTIFICATE\": use_client_cert_env}\n    ):\n        options = client_options.ClientOptions(\n            client_cert_source=client_cert_source_callback\n        )\n\n        def fake_init(client_cert_source_for_mtls=None, **kwargs):\n            \"\"\"Invoke client_cert source if provided.\"\"\"\n\n            if client_cert_source_for_mtls:\n                client_cert_source_for_mtls()\n                return None\n\n        with mock.patch.object(transport_class, \"__init__\") as patched:\n            patched.side_effect = fake_init\n            client = client_class(client_options=options)\n\n            if use_client_cert_env == \"false\":\n                expected_client_cert_source = None\n                expected_host = client.DEFAULT_ENDPOINT\n            else:\n                expected_client_cert_source = client_cert_source_callback\n                expected_host = client.DEFAULT_MTLS_ENDPOINT\n\n            patched.assert_called_once_with(\n                credentials=None,\n                credentials_file=None,\n                host=expected_host,\n                scopes=None,\n                client_cert_source_for_mtls=expected_client_cert_source,\n                quota_project_id=None,\n                client_info=transports.base.DEFAULT_CLIENT_INFO,\n                always_use_jwt_access=True,\n            )\n\n    # Check the case ADC client cert is provided. Whether client cert is used depends on\n    # GOOGLE_API_USE_CLIENT_CERTIFICATE value.\n    with mock.patch.dict(\n        os.environ, {\"GOOGLE_API_USE_CLIENT_CERTIFICATE\": use_client_cert_env}\n    ):\n        with mock.patch.object(transport_class, \"__init__\") as patched:\n            with mock.patch(\n                \"google.auth.transport.mtls.has_default_client_cert_source\",\n                return_value=True,\n            ):\n                with mock.patch(\n                    \"google.auth.transport.mtls.default_client_cert_source\",\n                    return_value=client_cert_source_callback,\n                ):\n                    if use_client_cert_env == \"false\":\n                        expected_host = client.DEFAULT_ENDPOINT\n                        expected_client_cert_source = None\n                    else:\n                        expected_host = client.DEFAULT_MTLS_ENDPOINT\n                        expected_client_cert_source = client_cert_source_callback\n\n                    patched.return_value = None\n                    client = client_class()\n                    patched.assert_called_once_with(\n                        credentials=None,\n                        credentials_file=None,\n                        host=expected_host,\n                        scopes=None,\n                        client_cert_source_for_mtls=expected_client_cert_source,\n                        quota_project_id=None,\n                        client_info=transports.base.DEFAULT_CLIENT_INFO,\n                        always_use_jwt_access=True,\n                    )\n\n    # Check the case client_cert_source and ADC client cert are not provided.\n    with mock.patch.dict(\n        os.environ, {\"GOOGLE_API_USE_CLIENT_CERTIFICATE\": use_client_cert_env}\n    ):\n        with mock.patch.object(transport_class, \"__init__\") as patched:\n            with mock.patch(\n                \"google.auth.transport.mtls.has_default_client_cert_source\",\n                return_value=False,\n            ):\n                patched.return_value = None\n                client = client_class()\n                patched.assert_called_once_with(\n                    credentials=None,\n                    credentials_file=None,\n                    host=client.DEFAULT_ENDPOINT,\n                    scopes=None,\n                    client_cert_source_for_mtls=None,\n                    quota_project_id=None,\n                    client_info=transports.base.DEFAULT_CLIENT_INFO,\n                    always_use_jwt_access=True,\n                )\n\n\n@pytest.mark.parametrize(\n    \"client_class,transport_class,transport_name\",\n    [(AbstractOperationsClient, transports.OperationsRestTransport, \"rest\")],\n)\ndef test_operations_client_client_options_scopes(\n    client_class, transport_class, transport_name\n):\n    # Check the case scopes are provided.\n    options = client_options.ClientOptions(\n        scopes=[\"1\", \"2\"],\n    )\n    with mock.patch.object(transport_class, \"__init__\") as patched:\n        patched.return_value = None\n        client = client_class(client_options=options)\n        patched.assert_called_once_with(\n            credentials=None,\n            credentials_file=None,\n            host=client.DEFAULT_ENDPOINT,\n            scopes=[\"1\", \"2\"],\n            client_cert_source_for_mtls=None,\n            quota_project_id=None,\n            client_info=transports.base.DEFAULT_CLIENT_INFO,\n            always_use_jwt_access=True,\n        )\n\n\n@pytest.mark.parametrize(\n    \"client_class,transport_class,transport_name\",\n    [(AbstractOperationsClient, transports.OperationsRestTransport, \"rest\")],\n)\ndef test_operations_client_client_options_credentials_file(\n    client_class, transport_class, transport_name\n):\n    # Check the case credentials file is provided.\n    options = client_options.ClientOptions(credentials_file=\"credentials.json\")\n    with mock.patch.object(transport_class, \"__init__\") as patched:\n        patched.return_value = None\n        client = client_class(client_options=options)\n        patched.assert_called_once_with(\n            credentials=None,\n            credentials_file=\"credentials.json\",\n            host=client.DEFAULT_ENDPOINT,\n            scopes=None,\n            client_cert_source_for_mtls=None,\n            quota_project_id=None,\n            client_info=transports.base.DEFAULT_CLIENT_INFO,\n            always_use_jwt_access=True,\n        )\n\n\ndef test_list_operations_rest(\n    transport: str = \"rest\", request_type=operations_pb2.ListOperationsRequest\n):\n    client = _get_operations_client()\n\n    # Mock the http request call within the method and fake a response.\n    with mock.patch.object(Session, \"request\") as req:\n        # Designate an appropriate value for the returned response.\n        return_value = operations_pb2.ListOperationsResponse(\n            next_page_token=\"next_page_token_value\",\n        )\n\n        # Wrap the value into a proper Response obj\n        response_value = Response()\n        response_value.status_code = 200\n        json_return_value = json_format.MessageToJson(return_value)\n        response_value._content = json_return_value.encode(\"UTF-8\")\n        req.return_value = response_value\n        response = client.list_operations(\n            name=\"operations\", filter_=\"my_filter\", page_size=10, page_token=\"abc\"\n        )\n\n        actual_args = req.call_args\n        assert actual_args.args[0] == \"GET\"\n        assert actual_args.args[1] == \"https://longrunning.googleapis.com/v3/operations\"\n        assert actual_args.kwargs[\"params\"] == [\n            (\"filter\", \"my_filter\"),\n            (\"pageSize\", 10),\n            (\"pageToken\", \"abc\"),\n        ]\n\n    # Establish that the response is the type that we expect.\n    assert isinstance(response, pagers.ListOperationsPager)\n    assert response.next_page_token == \"next_page_token_value\"\n\n\ndef test_list_operations_rest_failure():\n    client = _get_operations_client(http_options=None)\n\n    with mock.patch.object(Session, \"request\") as req:\n        response_value = Response()\n        response_value.status_code = 400\n        mock_request = mock.MagicMock()\n        mock_request.method = \"GET\"\n        mock_request.url = \"https://longrunning.googleapis.com:443/v1/operations\"\n        response_value.request = mock_request\n        req.return_value = response_value\n        with pytest.raises(core_exceptions.GoogleAPIError):\n            client.list_operations(name=\"operations\")\n\n\ndef test_list_operations_rest_pager():\n    client = AbstractOperationsClient(\n        credentials=ga_credentials.AnonymousCredentials(),\n    )\n\n    # Mock the http request call within the method and fake a response.\n    with mock.patch.object(Session, \"request\") as req:\n        # TODO(kbandes): remove this mock unless there's a good reason for it.\n        # with mock.patch.object(path_template, 'transcode') as transcode:\n        # Set the response as a series of pages\n        response = (\n            operations_pb2.ListOperationsResponse(\n                operations=[\n                    operations_pb2.Operation(),\n                    operations_pb2.Operation(),\n                    operations_pb2.Operation(),\n                ],\n                next_page_token=\"abc\",\n            ),\n            operations_pb2.ListOperationsResponse(\n                operations=[],\n                next_page_token=\"def\",\n            ),\n            operations_pb2.ListOperationsResponse(\n                operations=[operations_pb2.Operation()],\n                next_page_token=\"ghi\",\n            ),\n            operations_pb2.ListOperationsResponse(\n                operations=[operations_pb2.Operation(), operations_pb2.Operation()],\n            ),\n        )\n        # Two responses for two calls\n        response = response + response\n\n        # Wrap the values into proper Response objs\n        response = tuple(json_format.MessageToJson(x) for x in response)\n        return_values = tuple(Response() for i in response)\n        for return_val, response_val in zip(return_values, response):\n            return_val._content = response_val.encode(\"UTF-8\")\n            return_val.status_code = 200\n        req.side_effect = return_values\n\n        pager = client.list_operations(name=\"operations\")\n\n        results = list(pager)\n        assert len(results) == 6\n        assert all(isinstance(i, operations_pb2.Operation) for i in results)\n\n        pages = list(client.list_operations(name=\"operations\").pages)\n        for page_, token in zip(pages, [\"abc\", \"def\", \"ghi\", \"\"]):\n            assert page_.next_page_token == token\n\n\ndef test_get_operation_rest(\n    transport: str = \"rest\", request_type=operations_pb2.GetOperationRequest\n):\n    client = _get_operations_client()\n\n    # Mock the http request call within the method and fake a response.\n    with mock.patch.object(Session, \"request\") as req:\n        # Designate an appropriate value for the returned response.\n        return_value = operations_pb2.Operation(\n            name=\"operations/sample1\",\n            done=True,\n            error=status_pb2.Status(code=411),\n        )\n\n        # Wrap the value into a proper Response obj\n        response_value = Response()\n        response_value.status_code = 200\n        json_return_value = json_format.MessageToJson(return_value)\n        response_value._content = json_return_value.encode(\"UTF-8\")\n        req.return_value = response_value\n        response = client.get_operation(\"operations/sample1\")\n\n    actual_args = req.call_args\n    assert actual_args.args[0] == \"GET\"\n    assert (\n        actual_args.args[1]\n        == \"https://longrunning.googleapis.com/v3/operations/sample1\"\n    )\n\n    # Establish that the response is the type that we expect.\n    assert isinstance(response, operations_pb2.Operation)\n    assert response.name == \"operations/sample1\"\n    assert response.done is True\n\n\ndef test_get_operation_rest_failure():\n    client = _get_operations_client(http_options=None)\n\n    with mock.patch.object(Session, \"request\") as req:\n        response_value = Response()\n        response_value.status_code = 400\n        mock_request = mock.MagicMock()\n        mock_request.method = \"GET\"\n        mock_request.url = \"https://longrunning.googleapis.com/v1/operations/sample1\"\n        response_value.request = mock_request\n        req.return_value = response_value\n        with pytest.raises(core_exceptions.GoogleAPIError):\n            client.get_operation(\"sample0/operations/sample1\")\n\n\ndef test_delete_operation_rest(\n    transport: str = \"rest\", request_type=operations_pb2.DeleteOperationRequest\n):\n    client = _get_operations_client()\n\n    # Mock the http request call within the method and fake a response.\n    with mock.patch.object(Session, \"request\") as req:\n        # Wrap the value into a proper Response obj\n        response_value = Response()\n        response_value.status_code = 200\n        json_return_value = \"\"\n        response_value._content = json_return_value.encode(\"UTF-8\")\n        req.return_value = response_value\n        client.delete_operation(name=\"operations/sample1\")\n        assert req.call_count == 1\n        actual_args = req.call_args\n        assert actual_args.args[0] == \"DELETE\"\n        assert (\n            actual_args.args[1]\n            == \"https://longrunning.googleapis.com/v3/operations/sample1\"\n        )\n\n\ndef test_delete_operation_rest_failure():\n    client = _get_operations_client(http_options=None)\n\n    with mock.patch.object(Session, \"request\") as req:\n        response_value = Response()\n        response_value.status_code = 400\n        mock_request = mock.MagicMock()\n        mock_request.method = \"DELETE\"\n        mock_request.url = \"https://longrunning.googleapis.com/v1/operations/sample1\"\n        response_value.request = mock_request\n        req.return_value = response_value\n        with pytest.raises(core_exceptions.GoogleAPIError):\n            client.delete_operation(name=\"sample0/operations/sample1\")\n\n\ndef test_cancel_operation_rest(transport: str = \"rest\"):\n    client = _get_operations_client()\n\n    # Mock the http request call within the method and fake a response.\n    with mock.patch.object(Session, \"request\") as req:\n        # Wrap the value into a proper Response obj\n        response_value = Response()\n        response_value.status_code = 200\n        json_return_value = \"\"\n        response_value._content = json_return_value.encode(\"UTF-8\")\n        req.return_value = response_value\n        client.cancel_operation(name=\"operations/sample1\")\n        assert req.call_count == 1\n        actual_args = req.call_args\n        assert actual_args.args[0] == \"POST\"\n        assert (\n            actual_args.args[1]\n            == \"https://longrunning.googleapis.com/v3/operations/sample1:cancel\"\n        )\n\n\ndef test_cancel_operation_rest_failure():\n    client = _get_operations_client(http_options=None)\n\n    with mock.patch.object(Session, \"request\") as req:\n        response_value = Response()\n        response_value.status_code = 400\n        mock_request = mock.MagicMock()\n        mock_request.method = \"POST\"\n        mock_request.url = (\n            \"https://longrunning.googleapis.com/v1/operations/sample1:cancel\"\n        )\n        response_value.request = mock_request\n        req.return_value = response_value\n        with pytest.raises(core_exceptions.GoogleAPIError):\n            client.cancel_operation(name=\"sample0/operations/sample1\")\n\n\ndef test_credentials_transport_error():\n    # It is an error to provide credentials and a transport instance.\n    transport = transports.OperationsRestTransport(\n        credentials=ga_credentials.AnonymousCredentials(),\n    )\n    with pytest.raises(ValueError):\n        AbstractOperationsClient(\n            credentials=ga_credentials.AnonymousCredentials(),\n            transport=transport,\n        )\n\n    # It is an error to provide a credentials file and a transport instance.\n    transport = transports.OperationsRestTransport(\n        credentials=ga_credentials.AnonymousCredentials(),\n    )\n    with pytest.raises(ValueError):\n        AbstractOperationsClient(\n            client_options={\"credentials_file\": \"credentials.json\"},\n            transport=transport,\n        )\n\n    # It is an error to provide scopes and a transport instance.\n    transport = transports.OperationsRestTransport(\n        credentials=ga_credentials.AnonymousCredentials(),\n    )\n    with pytest.raises(ValueError):\n        AbstractOperationsClient(\n            client_options={\"scopes\": [\"1\", \"2\"]},\n            transport=transport,\n        )\n\n\ndef test_transport_instance():\n    # A client may be instantiated with a custom transport instance.\n    transport = transports.OperationsRestTransport(\n        credentials=ga_credentials.AnonymousCredentials(),\n    )\n    client = AbstractOperationsClient(transport=transport)\n    assert client.transport is transport\n\n\n@pytest.mark.parametrize(\"transport_class\", [transports.OperationsRestTransport])\ndef test_transport_adc(transport_class):\n    # Test default credentials are used if not provided.\n    with mock.patch.object(google.auth, \"default\") as adc:\n        adc.return_value = (ga_credentials.AnonymousCredentials(), None)\n        transport_class()\n        adc.assert_called_once()\n\n\ndef test_operations_base_transport_error():\n    # Passing both a credentials object and credentials_file should raise an error\n    with pytest.raises(core_exceptions.DuplicateCredentialArgs):\n        transports.OperationsTransport(\n            credentials=ga_credentials.AnonymousCredentials(),\n            credentials_file=\"credentials.json\",\n        )\n\n\ndef test_operations_base_transport():\n    # Instantiate the base transport.\n    with mock.patch(\n        \"google.api_core.operations_v1.transports.OperationsTransport.__init__\"\n    ) as Transport:\n        Transport.return_value = None\n        transport = transports.OperationsTransport(\n            credentials=ga_credentials.AnonymousCredentials(),\n        )\n\n    # Every method on the transport should just blindly\n    # raise NotImplementedError.\n    methods = (\n        \"list_operations\",\n        \"get_operation\",\n        \"delete_operation\",\n        \"cancel_operation\",\n    )\n    for method in methods:\n        with pytest.raises(NotImplementedError):\n            getattr(transport, method)(request=object())\n\n    with pytest.raises(NotImplementedError):\n        transport.close()\n\n\ndef test_operations_base_transport_with_credentials_file():\n    # Instantiate the base transport with a credentials file\n    with mock.patch.object(\n        google.auth, \"load_credentials_from_file\", autospec=True\n    ) as load_creds, mock.patch(\n        \"google.api_core.operations_v1.transports.OperationsTransport._prep_wrapped_messages\"\n    ) as Transport:\n        Transport.return_value = None\n        load_creds.return_value = (ga_credentials.AnonymousCredentials(), None)\n        transports.OperationsTransport(\n            credentials_file=\"credentials.json\",\n            quota_project_id=\"octopus\",\n        )\n        load_creds.assert_called_once_with(\n            \"credentials.json\",\n            scopes=None,\n            default_scopes=(),\n            quota_project_id=\"octopus\",\n        )\n\n\ndef test_operations_base_transport_with_adc():\n    # Test the default credentials are used if credentials and credentials_file are None.\n    with mock.patch.object(google.auth, \"default\", autospec=True) as adc, mock.patch(\n        \"google.api_core.operations_v1.transports.OperationsTransport._prep_wrapped_messages\"\n    ) as Transport:\n        Transport.return_value = None\n        adc.return_value = (ga_credentials.AnonymousCredentials(), None)\n        transports.OperationsTransport()\n        adc.assert_called_once()\n\n\ndef test_operations_auth_adc():\n    # If no credentials are provided, we should use ADC credentials.\n    with mock.patch.object(google.auth, \"default\", autospec=True) as adc:\n        adc.return_value = (ga_credentials.AnonymousCredentials(), None)\n        AbstractOperationsClient()\n        adc.assert_called_once_with(\n            scopes=None,\n            default_scopes=(),\n            quota_project_id=None,\n        )\n\n\ndef test_operations_http_transport_client_cert_source_for_mtls():\n    cred = ga_credentials.AnonymousCredentials()\n    with mock.patch(\n        \"google.auth.transport.requests.AuthorizedSession.configure_mtls_channel\"\n    ) as mock_configure_mtls_channel:\n        transports.OperationsRestTransport(\n            credentials=cred, client_cert_source_for_mtls=client_cert_source_callback\n        )\n        mock_configure_mtls_channel.assert_called_once_with(client_cert_source_callback)\n\n\ndef test_operations_host_no_port():\n    client = AbstractOperationsClient(\n        credentials=ga_credentials.AnonymousCredentials(),\n        client_options=client_options.ClientOptions(\n            api_endpoint=\"longrunning.googleapis.com\"\n        ),\n    )\n    assert client.transport._host == \"https://longrunning.googleapis.com\"\n\n\ndef test_operations_host_with_port():\n    client = AbstractOperationsClient(\n        credentials=ga_credentials.AnonymousCredentials(),\n        client_options=client_options.ClientOptions(\n            api_endpoint=\"longrunning.googleapis.com:8000\"\n        ),\n    )\n    assert client.transport._host == \"https://longrunning.googleapis.com:8000\"\n\n\ndef test_common_billing_account_path():\n    billing_account = \"squid\"\n    expected = \"billingAccounts/{billing_account}\".format(\n        billing_account=billing_account,\n    )\n    actual = AbstractOperationsClient.common_billing_account_path(billing_account)\n    assert expected == actual\n\n\ndef test_parse_common_billing_account_path():\n    expected = {\n        \"billing_account\": \"clam\",\n    }\n    path = AbstractOperationsClient.common_billing_account_path(**expected)\n\n    # Check that the path construction is reversible.\n    actual = AbstractOperationsClient.parse_common_billing_account_path(path)\n    assert expected == actual\n\n\ndef test_common_folder_path():\n    folder = \"whelk\"\n    expected = \"folders/{folder}\".format(\n        folder=folder,\n    )\n    actual = AbstractOperationsClient.common_folder_path(folder)\n    assert expected == actual\n\n\ndef test_parse_common_folder_path():\n    expected = {\n        \"folder\": \"octopus\",\n    }\n    path = AbstractOperationsClient.common_folder_path(**expected)\n\n    # Check that the path construction is reversible.\n    actual = AbstractOperationsClient.parse_common_folder_path(path)\n    assert expected == actual\n\n\ndef test_common_organization_path():\n    organization = \"oyster\"\n    expected = \"organizations/{organization}\".format(\n        organization=organization,\n    )\n    actual = AbstractOperationsClient.common_organization_path(organization)\n    assert expected == actual\n\n\ndef test_parse_common_organization_path():\n    expected = {\n        \"organization\": \"nudibranch\",\n    }\n    path = AbstractOperationsClient.common_organization_path(**expected)\n\n    # Check that the path construction is reversible.\n    actual = AbstractOperationsClient.parse_common_organization_path(path)\n    assert expected == actual\n\n\ndef test_common_project_path():\n    project = \"cuttlefish\"\n    expected = \"projects/{project}\".format(\n        project=project,\n    )\n    actual = AbstractOperationsClient.common_project_path(project)\n    assert expected == actual\n\n\ndef test_parse_common_project_path():\n    expected = {\n        \"project\": \"mussel\",\n    }\n    path = AbstractOperationsClient.common_project_path(**expected)\n\n    # Check that the path construction is reversible.\n    actual = AbstractOperationsClient.parse_common_project_path(path)\n    assert expected == actual\n\n\ndef test_common_location_path():\n    project = \"winkle\"\n    location = \"nautilus\"\n    expected = \"projects/{project}/locations/{location}\".format(\n        project=project,\n        location=location,\n    )\n    actual = AbstractOperationsClient.common_location_path(project, location)\n    assert expected == actual\n\n\ndef test_parse_common_location_path():\n    expected = {\n        \"project\": \"scallop\",\n        \"location\": \"abalone\",\n    }\n    path = AbstractOperationsClient.common_location_path(**expected)\n\n    # Check that the path construction is reversible.\n    actual = AbstractOperationsClient.parse_common_location_path(path)\n    assert expected == actual\n\n\ndef test_client_withDEFAULT_CLIENT_INFO():\n    client_info = gapic_v1.client_info.ClientInfo()\n\n    with mock.patch.object(\n        transports.OperationsTransport, \"_prep_wrapped_messages\"\n    ) as prep:\n        AbstractOperationsClient(\n            credentials=ga_credentials.AnonymousCredentials(),\n            client_info=client_info,\n        )\n        prep.assert_called_once_with(client_info)\n\n    with mock.patch.object(\n        transports.OperationsTransport, \"_prep_wrapped_messages\"\n    ) as prep:\n        transport_class = AbstractOperationsClient.get_transport_class()\n        transport_class(\n            credentials=ga_credentials.AnonymousCredentials(),\n            client_info=client_info,\n        )\n        prep.assert_called_once_with(client_info)\n", "tests/unit/operations_v1/test_operations_client.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport pytest\n\ntry:\n    import grpc  # noqa: F401\nexcept ImportError:  # pragma: NO COVER\n    pytest.skip(\"No GRPC\", allow_module_level=True)\n\nfrom google.api_core import grpc_helpers\nfrom google.api_core import operations_v1\nfrom google.api_core import page_iterator\nfrom google.api_core.operations_v1 import operations_client_config\nfrom google.longrunning import operations_pb2\nfrom google.protobuf import empty_pb2\n\n\ndef test_get_operation():\n    channel = grpc_helpers.ChannelStub()\n    client = operations_v1.OperationsClient(channel)\n    channel.GetOperation.response = operations_pb2.Operation(name=\"meep\")\n\n    response = client.get_operation(\"name\", metadata=[(\"header\", \"foo\")])\n\n    assert (\"header\", \"foo\") in channel.GetOperation.calls[0].metadata\n    assert (\"x-goog-request-params\", \"name=name\") in channel.GetOperation.calls[\n        0\n    ].metadata\n    assert len(channel.GetOperation.requests) == 1\n    assert channel.GetOperation.requests[0].name == \"name\"\n    assert response == channel.GetOperation.response\n\n\ndef test_list_operations():\n    channel = grpc_helpers.ChannelStub()\n    client = operations_v1.OperationsClient(channel)\n    operations = [\n        operations_pb2.Operation(name=\"1\"),\n        operations_pb2.Operation(name=\"2\"),\n    ]\n    list_response = operations_pb2.ListOperationsResponse(operations=operations)\n    channel.ListOperations.response = list_response\n\n    response = client.list_operations(\"name\", \"filter\", metadata=[(\"header\", \"foo\")])\n\n    assert isinstance(response, page_iterator.Iterator)\n    assert list(response) == operations\n\n    assert (\"header\", \"foo\") in channel.ListOperations.calls[0].metadata\n    assert (\"x-goog-request-params\", \"name=name\") in channel.ListOperations.calls[\n        0\n    ].metadata\n    assert len(channel.ListOperations.requests) == 1\n    request = channel.ListOperations.requests[0]\n    assert isinstance(request, operations_pb2.ListOperationsRequest)\n    assert request.name == \"name\"\n    assert request.filter == \"filter\"\n\n\ndef test_delete_operation():\n    channel = grpc_helpers.ChannelStub()\n    client = operations_v1.OperationsClient(channel)\n    channel.DeleteOperation.response = empty_pb2.Empty()\n\n    client.delete_operation(\"name\", metadata=[(\"header\", \"foo\")])\n\n    assert (\"header\", \"foo\") in channel.DeleteOperation.calls[0].metadata\n    assert (\"x-goog-request-params\", \"name=name\") in channel.DeleteOperation.calls[\n        0\n    ].metadata\n    assert len(channel.DeleteOperation.requests) == 1\n    assert channel.DeleteOperation.requests[0].name == \"name\"\n\n\ndef test_cancel_operation():\n    channel = grpc_helpers.ChannelStub()\n    client = operations_v1.OperationsClient(channel)\n    channel.CancelOperation.response = empty_pb2.Empty()\n\n    client.cancel_operation(\"name\", metadata=[(\"header\", \"foo\")])\n\n    assert (\"header\", \"foo\") in channel.CancelOperation.calls[0].metadata\n    assert (\"x-goog-request-params\", \"name=name\") in channel.CancelOperation.calls[\n        0\n    ].metadata\n    assert len(channel.CancelOperation.requests) == 1\n    assert channel.CancelOperation.requests[0].name == \"name\"\n\n\ndef test_operations_client_config():\n    assert operations_client_config.config[\"interfaces\"]\n", "tests/unit/operations_v1/__init__.py": "", "tests/unit/gapic/test_config.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport pytest\n\ntry:\n    import grpc  # noqa: F401\nexcept ImportError:\n    pytest.skip(\"No GRPC\", allow_module_level=True)\n\nfrom google.api_core import exceptions\nfrom google.api_core.gapic_v1 import config\n\n\nINTERFACE_CONFIG = {\n    \"retry_codes\": {\n        \"idempotent\": [\"DEADLINE_EXCEEDED\", \"UNAVAILABLE\"],\n        \"other\": [\"FAILED_PRECONDITION\"],\n        \"non_idempotent\": [],\n    },\n    \"retry_params\": {\n        \"default\": {\n            \"initial_retry_delay_millis\": 1000,\n            \"retry_delay_multiplier\": 2.5,\n            \"max_retry_delay_millis\": 120000,\n            \"initial_rpc_timeout_millis\": 120000,\n            \"rpc_timeout_multiplier\": 1.0,\n            \"max_rpc_timeout_millis\": 120000,\n            \"total_timeout_millis\": 600000,\n        },\n        \"other\": {\n            \"initial_retry_delay_millis\": 1000,\n            \"retry_delay_multiplier\": 1,\n            \"max_retry_delay_millis\": 1000,\n            \"initial_rpc_timeout_millis\": 1000,\n            \"rpc_timeout_multiplier\": 1,\n            \"max_rpc_timeout_millis\": 1000,\n            \"total_timeout_millis\": 1000,\n        },\n    },\n    \"methods\": {\n        \"AnnotateVideo\": {\n            \"timeout_millis\": 60000,\n            \"retry_codes_name\": \"idempotent\",\n            \"retry_params_name\": \"default\",\n        },\n        \"Other\": {\n            \"timeout_millis\": 60000,\n            \"retry_codes_name\": \"other\",\n            \"retry_params_name\": \"other\",\n        },\n        \"Plain\": {\"timeout_millis\": 30000},\n    },\n}\n\n\ndef test_create_method_configs():\n    method_configs = config.parse_method_configs(INTERFACE_CONFIG)\n\n    retry, timeout = method_configs[\"AnnotateVideo\"]\n    assert retry._predicate(exceptions.DeadlineExceeded(None))\n    assert retry._predicate(exceptions.ServiceUnavailable(None))\n    assert retry._initial == 1.0\n    assert retry._multiplier == 2.5\n    assert retry._maximum == 120.0\n    assert retry._deadline == 600.0\n    assert timeout._initial == 120.0\n    assert timeout._multiplier == 1.0\n    assert timeout._maximum == 120.0\n\n    retry, timeout = method_configs[\"Other\"]\n    assert retry._predicate(exceptions.FailedPrecondition(None))\n    assert retry._initial == 1.0\n    assert retry._multiplier == 1.0\n    assert retry._maximum == 1.0\n    assert retry._deadline == 1.0\n    assert timeout._initial == 1.0\n    assert timeout._multiplier == 1.0\n    assert timeout._maximum == 1.0\n\n    retry, timeout = method_configs[\"Plain\"]\n    assert retry is None\n    assert timeout._timeout == 30.0\n", "tests/unit/gapic/test_routing_header.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom enum import Enum\n\nimport pytest\n\ntry:\n    import grpc  # noqa: F401\nexcept ImportError:\n    pytest.skip(\"No GRPC\", allow_module_level=True)\n\n\nfrom google.api_core.gapic_v1 import routing_header\n\n\ndef test_to_routing_header():\n    params = [(\"name\", \"meep\"), (\"book.read\", \"1\")]\n    value = routing_header.to_routing_header(params)\n    assert value == \"name=meep&book.read=1\"\n\n\ndef test_to_routing_header_with_slashes():\n    params = [(\"name\", \"me/ep\"), (\"book.read\", \"1&2\")]\n    value = routing_header.to_routing_header(params)\n    assert value == \"name=me/ep&book.read=1%262\"\n\n\ndef test_enum_fully_qualified():\n    class Message:\n        class Color(Enum):\n            RED = 1\n            GREEN = 2\n            BLUE = 3\n\n    params = [(\"color\", Message.Color.RED)]\n    value = routing_header.to_routing_header(params)\n    assert value == \"color=Color.RED\"\n    value = routing_header.to_routing_header(params, qualified_enums=True)\n    assert value == \"color=Color.RED\"\n\n\ndef test_enum_nonqualified():\n    class Message:\n        class Color(Enum):\n            RED = 1\n            GREEN = 2\n            BLUE = 3\n\n    params = [(\"color\", Message.Color.RED), (\"num\", 5)]\n    value = routing_header.to_routing_header(params, qualified_enums=False)\n    assert value == \"color=RED&num=5\"\n    params = {\"color\": Message.Color.RED, \"num\": 5}\n    value = routing_header.to_routing_header(params, qualified_enums=False)\n    assert value == \"color=RED&num=5\"\n\n\ndef test_to_grpc_metadata():\n    params = [(\"name\", \"meep\"), (\"book.read\", \"1\")]\n    metadata = routing_header.to_grpc_metadata(params)\n    assert metadata == (routing_header.ROUTING_METADATA_KEY, \"name=meep&book.read=1\")\n\n\n@pytest.mark.parametrize(\n    \"key,value,expected\",\n    [\n        (\"book.read\", \"1\", \"book.read=1\"),\n        (\"name\", \"me/ep\", \"name=me/ep\"),\n        (\"\\\\\", \"=\", \"%5C=%3D\"),\n        (b\"hello\", \"world\", \"hello=world\"),\n        (\"\u2714\ufe0f\", \"\u270c\ufe0f\", \"%E2%9C%94%EF%B8%8F=%E2%9C%8C%EF%B8%8F\"),\n    ],\n)\ndef test__urlencode_param(key, value, expected):\n    result = routing_header._urlencode_param(key, value)\n    assert result == expected\n\n\ndef test__urlencode_param_caching_performance():\n    import time\n\n    key = \"key\" * 100\n    value = \"value\" * 100\n    # time with empty cache\n    start_time = time.perf_counter()\n    routing_header._urlencode_param(key, value)\n    duration = time.perf_counter() - start_time\n    second_start_time = time.perf_counter()\n    routing_header._urlencode_param(key, value)\n    second_duration = time.perf_counter() - second_start_time\n    # second call should be approximately 10 times faster\n    assert second_duration < duration / 10\n", "tests/unit/gapic/test_method.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport datetime\n\nimport mock\nimport pytest\n\ntry:\n    import grpc  # noqa: F401\nexcept ImportError:\n    pytest.skip(\"No GRPC\", allow_module_level=True)\n\n\nfrom google.api_core import exceptions\nfrom google.api_core import retry\nfrom google.api_core import timeout\nimport google.api_core.gapic_v1.client_info\nimport google.api_core.gapic_v1.method\nimport google.api_core.page_iterator\n\n\ndef _utcnow_monotonic():\n    curr_value = datetime.datetime.min\n    delta = datetime.timedelta(seconds=0.5)\n    while True:\n        yield curr_value\n        curr_value += delta\n\n\ndef test_wrap_method_basic():\n    method = mock.Mock(spec=[\"__call__\"], return_value=42)\n\n    wrapped_method = google.api_core.gapic_v1.method.wrap_method(method)\n\n    result = wrapped_method(1, 2, meep=\"moop\")\n\n    assert result == 42\n    method.assert_called_once_with(1, 2, meep=\"moop\", metadata=mock.ANY)\n\n    # Check that the default client info was specified in the metadata.\n    metadata = method.call_args[1][\"metadata\"]\n    assert len(metadata) == 1\n    client_info = google.api_core.gapic_v1.client_info.DEFAULT_CLIENT_INFO\n    user_agent_metadata = client_info.to_grpc_metadata()\n    assert user_agent_metadata in metadata\n\n\ndef test_wrap_method_with_no_client_info():\n    method = mock.Mock(spec=[\"__call__\"])\n\n    wrapped_method = google.api_core.gapic_v1.method.wrap_method(\n        method, client_info=None\n    )\n\n    wrapped_method(1, 2, meep=\"moop\")\n\n    method.assert_called_once_with(1, 2, meep=\"moop\")\n\n\ndef test_wrap_method_with_custom_client_info():\n    client_info = google.api_core.gapic_v1.client_info.ClientInfo(\n        python_version=1,\n        grpc_version=2,\n        api_core_version=3,\n        gapic_version=4,\n        client_library_version=5,\n    )\n    method = mock.Mock(spec=[\"__call__\"])\n\n    wrapped_method = google.api_core.gapic_v1.method.wrap_method(\n        method, client_info=client_info\n    )\n\n    wrapped_method(1, 2, meep=\"moop\")\n\n    method.assert_called_once_with(1, 2, meep=\"moop\", metadata=mock.ANY)\n\n    # Check that the custom client info was specified in the metadata.\n    metadata = method.call_args[1][\"metadata\"]\n    assert client_info.to_grpc_metadata() in metadata\n\n\ndef test_invoke_wrapped_method_with_metadata():\n    method = mock.Mock(spec=[\"__call__\"])\n\n    wrapped_method = google.api_core.gapic_v1.method.wrap_method(method)\n\n    wrapped_method(mock.sentinel.request, metadata=[(\"a\", \"b\")])\n\n    method.assert_called_once_with(mock.sentinel.request, metadata=mock.ANY)\n    metadata = method.call_args[1][\"metadata\"]\n    # Metadata should have two items: the client info metadata and our custom\n    # metadata.\n    assert len(metadata) == 2\n    assert (\"a\", \"b\") in metadata\n\n\ndef test_invoke_wrapped_method_with_metadata_as_none():\n    method = mock.Mock(spec=[\"__call__\"])\n\n    wrapped_method = google.api_core.gapic_v1.method.wrap_method(method)\n\n    wrapped_method(mock.sentinel.request, metadata=None)\n\n    method.assert_called_once_with(mock.sentinel.request, metadata=mock.ANY)\n    metadata = method.call_args[1][\"metadata\"]\n    # Metadata should have just one items: the client info metadata.\n    assert len(metadata) == 1\n\n\n@mock.patch(\"time.sleep\")\ndef test_wrap_method_with_default_retry_and_timeout_and_compression(unused_sleep):\n    method = mock.Mock(\n        spec=[\"__call__\"], side_effect=[exceptions.InternalServerError(None), 42]\n    )\n    default_retry = retry.Retry()\n    default_timeout = timeout.ConstantTimeout(60)\n    default_compression = grpc.Compression.Gzip\n    wrapped_method = google.api_core.gapic_v1.method.wrap_method(\n        method, default_retry, default_timeout, default_compression\n    )\n\n    result = wrapped_method()\n\n    assert result == 42\n    assert method.call_count == 2\n    method.assert_called_with(\n        timeout=60, compression=default_compression, metadata=mock.ANY\n    )\n\n\n@mock.patch(\"time.sleep\")\ndef test_wrap_method_with_default_retry_and_timeout_using_sentinel(unused_sleep):\n    method = mock.Mock(\n        spec=[\"__call__\"], side_effect=[exceptions.InternalServerError(None), 42]\n    )\n    default_retry = retry.Retry()\n    default_timeout = timeout.ConstantTimeout(60)\n    default_compression = grpc.Compression.Gzip\n    wrapped_method = google.api_core.gapic_v1.method.wrap_method(\n        method, default_retry, default_timeout, default_compression\n    )\n\n    result = wrapped_method(\n        retry=google.api_core.gapic_v1.method.DEFAULT,\n        timeout=google.api_core.gapic_v1.method.DEFAULT,\n        compression=google.api_core.gapic_v1.method.DEFAULT,\n    )\n\n    assert result == 42\n    assert method.call_count == 2\n    method.assert_called_with(\n        timeout=60, compression=default_compression, metadata=mock.ANY\n    )\n\n\n@mock.patch(\"time.sleep\")\ndef test_wrap_method_with_overriding_retry_timeout_compression(unused_sleep):\n    method = mock.Mock(spec=[\"__call__\"], side_effect=[exceptions.NotFound(None), 42])\n    default_retry = retry.Retry()\n    default_timeout = timeout.ConstantTimeout(60)\n    default_compression = grpc.Compression.Gzip\n    wrapped_method = google.api_core.gapic_v1.method.wrap_method(\n        method, default_retry, default_timeout, default_compression\n    )\n\n    result = wrapped_method(\n        retry=retry.Retry(retry.if_exception_type(exceptions.NotFound)),\n        timeout=timeout.ConstantTimeout(22),\n        compression=grpc.Compression.Deflate,\n    )\n\n    assert result == 42\n    assert method.call_count == 2\n    method.assert_called_with(\n        timeout=22, compression=grpc.Compression.Deflate, metadata=mock.ANY\n    )\n\n\ndef test_wrap_method_with_overriding_timeout_as_a_number():\n    method = mock.Mock(spec=[\"__call__\"], return_value=42)\n    default_retry = retry.Retry()\n    default_timeout = timeout.ConstantTimeout(60)\n    wrapped_method = google.api_core.gapic_v1.method.wrap_method(\n        method, default_retry, default_timeout\n    )\n\n    result = wrapped_method(timeout=22)\n\n    assert result == 42\n    method.assert_called_once_with(timeout=22, metadata=mock.ANY)\n\n\ndef test_wrap_method_with_call():\n    method = mock.Mock()\n    mock_call = mock.Mock()\n    method.with_call.return_value = 42, mock_call\n\n    wrapped_method = google.api_core.gapic_v1.method.wrap_method(method, with_call=True)\n    result = wrapped_method()\n    assert len(result) == 2\n    assert result[0] == 42\n    assert result[1] == mock_call\n\n\ndef test_wrap_method_with_call_not_supported():\n    \"\"\"Raises an error if wrapped callable doesn't have with_call method.\"\"\"\n    method = lambda: None  # noqa: E731\n\n    with pytest.raises(ValueError) as exc_info:\n        google.api_core.gapic_v1.method.wrap_method(method, with_call=True)\n    assert \"with_call=True is only supported for unary calls\" in str(exc_info.value)\n", "tests/unit/gapic/test_client_info.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport pytest\n\ntry:\n    import grpc  # noqa: F401\nexcept ImportError:\n    pytest.skip(\"No GRPC\", allow_module_level=True)\n\n\nfrom google.api_core.gapic_v1 import client_info\n\n\ndef test_to_grpc_metadata():\n    info = client_info.ClientInfo()\n\n    metadata = info.to_grpc_metadata()\n\n    assert metadata == (client_info.METRICS_METADATA_KEY, info.to_user_agent())\n", "tests/unit/retry/test_retry_imports.py": "# Copyright 2024 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\ndef test_legacy_imports_retry_unary_sync():\n    # TODO: Delete this test when when we revert these imports on the\n    #       next major version release\n    #       (https://github.com/googleapis/python-api-core/issues/576)\n    from google.api_core.retry import datetime_helpers  # noqa: F401\n    from google.api_core.retry import exceptions  # noqa: F401\n    from google.api_core.retry import auth_exceptions  # noqa: F401\n\n\ndef test_legacy_imports_retry_unary_async():\n    # TODO: Delete this test when when we revert these imports on the\n    #       next major version release\n    #       (https://github.com/googleapis/python-api-core/issues/576)\n    from google.api_core import retry_async  # noqa: F401\n\n    # See https://github.com/googleapis/python-api-core/issues/586\n    # for context on why we need to test this import this explicitly.\n    from google.api_core.retry_async import AsyncRetry  # noqa: F401\n", "tests/unit/retry/test_retry_streaming.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport re\n\nimport mock\nimport pytest\n\nfrom google.api_core import exceptions\nfrom google.api_core import retry\nfrom google.api_core.retry import retry_streaming\n\nfrom .test_retry_base import Test_BaseRetry\n\n\ndef test_retry_streaming_target_bad_sleep_generator():\n    with pytest.raises(\n        ValueError, match=\"Sleep generator stopped yielding sleep values\"\n    ):\n        next(retry_streaming.retry_target_stream(None, None, [], None))\n\n\nclass TestStreamingRetry(Test_BaseRetry):\n    def _make_one(self, *args, **kwargs):\n        return retry_streaming.StreamingRetry(*args, **kwargs)\n\n    def test___str__(self):\n        def if_exception_type(exc):\n            return bool(exc)  # pragma: NO COVER\n\n        # Explicitly set all attributes as changed Retry defaults should not\n        # cause this test to start failing.\n        retry_ = retry_streaming.StreamingRetry(\n            predicate=if_exception_type,\n            initial=1.0,\n            maximum=60.0,\n            multiplier=2.0,\n            timeout=120.0,\n            on_error=None,\n        )\n        assert re.match(\n            (\n                r\"<StreamingRetry predicate=<function.*?if_exception_type.*?>, \"\n                r\"initial=1.0, maximum=60.0, multiplier=2.0, timeout=120.0, \"\n                r\"on_error=None>\"\n            ),\n            str(retry_),\n        )\n\n    def _generator_mock(\n        self,\n        num=5,\n        error_on=None,\n        return_val=None,\n        exceptions_seen=None,\n    ):\n        \"\"\"\n        Helper to create a mock generator that yields a number of values\n        Generator can optionally raise an exception on a specific iteration\n\n        Args:\n          - num (int): the number of values to yield. After this, the generator will return `return_val`\n          - error_on (int): if given, the generator will raise a ValueError on the specified iteration\n          - return_val (any): if given, the generator will return this value after yielding num values\n          - exceptions_seen (list): if given, the generator will append any exceptions to this list before raising\n        \"\"\"\n        try:\n            for i in range(num):\n                if error_on and i == error_on:\n                    raise ValueError(\"generator mock error\")\n                yield i\n            return return_val\n        except (Exception, BaseException, GeneratorExit) as e:\n            # keep track of exceptions seen by generator\n            if exceptions_seen is not None:\n                exceptions_seen.append(e)\n            raise\n\n    @mock.patch(\"time.sleep\", autospec=True)\n    def test___call___success(self, sleep):\n        \"\"\"\n        Test that a retry-decorated generator yields values as expected\n        This test checks a generator with no issues\n        \"\"\"\n        import types\n        import collections\n\n        retry_ = retry_streaming.StreamingRetry()\n\n        decorated = retry_(self._generator_mock)\n\n        num = 10\n        result = decorated(num)\n        # check types\n        assert isinstance(decorated(num), collections.abc.Iterable)\n        assert isinstance(decorated(num), types.GeneratorType)\n        assert isinstance(self._generator_mock(num), collections.abc.Iterable)\n        assert isinstance(self._generator_mock(num), types.GeneratorType)\n        # check yield contents\n        unpacked = [i for i in result]\n        assert len(unpacked) == num\n        for a, b in zip(unpacked, self._generator_mock(num)):\n            assert a == b\n        sleep.assert_not_called()\n\n    @mock.patch(\"time.sleep\", autospec=True)\n    def test___call___retry(self, sleep):\n        \"\"\"\n        Tests that a retry-decorated generator will retry on errors\n        \"\"\"\n        on_error = mock.Mock(return_value=None)\n        retry_ = retry_streaming.StreamingRetry(\n            on_error=on_error,\n            predicate=retry.if_exception_type(ValueError),\n            timeout=None,\n        )\n        result = retry_(self._generator_mock)(error_on=3)\n        # error thrown on 3\n        # generator should contain 0, 1, 2 looping\n        unpacked = [next(result) for i in range(10)]\n        assert unpacked == [0, 1, 2, 0, 1, 2, 0, 1, 2, 0]\n        assert on_error.call_count == 3\n\n    @mock.patch(\"random.uniform\", autospec=True, side_effect=lambda m, n: n)\n    @mock.patch(\"time.sleep\", autospec=True)\n    @pytest.mark.parametrize(\"use_deadline_arg\", [True, False])\n    def test___call___retry_hitting_timeout(self, sleep, uniform, use_deadline_arg):\n        \"\"\"\n        Tests that a retry-decorated generator will throw a RetryError\n        after using the time budget\n        \"\"\"\n        import time\n\n        timeout_val = 30.9\n        # support \"deadline\" as an alias for \"timeout\"\n        timeout_kwarg = (\n            {\"timeout\": timeout_val}\n            if not use_deadline_arg\n            else {\"deadline\": timeout_val}\n        )\n\n        on_error = mock.Mock(return_value=None)\n        retry_ = retry_streaming.StreamingRetry(\n            predicate=retry.if_exception_type(ValueError),\n            initial=1.0,\n            maximum=1024.0,\n            multiplier=2.0,\n            **timeout_kwarg,\n        )\n\n        timenow = time.monotonic()\n        now_patcher = mock.patch(\n            \"time.monotonic\",\n            return_value=timenow,\n        )\n\n        decorated = retry_(self._generator_mock, on_error=on_error)\n        generator = decorated(error_on=1)\n        with now_patcher as patched_now:\n            # Make sure that calls to fake time.sleep() also advance the mocked\n            # time clock.\n            def increase_time(sleep_delay):\n                patched_now.return_value += sleep_delay\n\n            sleep.side_effect = increase_time\n            with pytest.raises(exceptions.RetryError):\n                [i for i in generator]\n\n        assert on_error.call_count == 5\n        # check the delays\n        assert sleep.call_count == 4  # once between each successive target calls\n        last_wait = sleep.call_args.args[0]\n        total_wait = sum(call_args.args[0] for call_args in sleep.call_args_list)\n        assert last_wait == 8.0\n        assert total_wait == 15.0\n\n    @mock.patch(\"time.sleep\", autospec=True)\n    def test___call___with_generator_send(self, sleep):\n        \"\"\"\n        Send should be passed through retry into target generator\n        \"\"\"\n\n        def _mock_send_gen():\n            \"\"\"\n            always yield whatever was sent in\n            \"\"\"\n            in_ = yield\n            while True:\n                in_ = yield in_\n\n        retry_ = retry_streaming.StreamingRetry()\n\n        decorated = retry_(_mock_send_gen)\n\n        generator = decorated()\n        result = next(generator)\n        # first yield should be None\n        assert result is None\n        in_messages = [\"test_1\", \"hello\", \"world\"]\n        out_messages = []\n        for msg in in_messages:\n            recv = generator.send(msg)\n            out_messages.append(recv)\n        assert in_messages == out_messages\n\n    @mock.patch(\"time.sleep\", autospec=True)\n    def test___call___with_generator_send_retry(self, sleep):\n        \"\"\"\n        Send should support retries like next\n        \"\"\"\n        on_error = mock.Mock(return_value=None)\n        retry_ = retry_streaming.StreamingRetry(\n            on_error=on_error,\n            predicate=retry.if_exception_type(ValueError),\n            timeout=None,\n        )\n        result = retry_(self._generator_mock)(error_on=3)\n        with pytest.raises(TypeError) as exc_info:\n            # calling first send with non-None input should raise a TypeError\n            result.send(\"can not send to fresh generator\")\n            assert exc_info.match(\"can't send non-None value\")\n        # initiate iteration with None\n        result = retry_(self._generator_mock)(error_on=3)\n        assert result.send(None) == 0\n        # error thrown on 3\n        # generator should contain 0, 1, 2 looping\n        unpacked = [result.send(i) for i in range(10)]\n        assert unpacked == [1, 2, 0, 1, 2, 0, 1, 2, 0, 1]\n        assert on_error.call_count == 3\n\n    @mock.patch(\"time.sleep\", autospec=True)\n    def test___call___with_iterable_send(self, sleep):\n        \"\"\"\n        send should raise attribute error if wrapped iterator does not support it\n        \"\"\"\n        retry_ = retry_streaming.StreamingRetry()\n\n        def iterable_fn(n):\n            return iter(range(n))\n\n        decorated = retry_(iterable_fn)\n        generator = decorated(5)\n        # initialize\n        next(generator)\n        # call send\n        with pytest.raises(AttributeError):\n            generator.send(\"test\")\n\n    @mock.patch(\"time.sleep\", autospec=True)\n    def test___call___with_iterable_close(self, sleep):\n        \"\"\"\n        close should be handled by wrapper if wrapped iterable does not support it\n        \"\"\"\n        retry_ = retry_streaming.StreamingRetry()\n\n        def iterable_fn(n):\n            return iter(range(n))\n\n        decorated = retry_(iterable_fn)\n\n        # try closing active generator\n        retryable = decorated(10)\n        assert next(retryable) == 0\n        retryable.close()\n        with pytest.raises(StopIteration):\n            next(retryable)\n\n        # try closing a new generator\n        retryable = decorated(10)\n        retryable.close()\n        with pytest.raises(StopIteration):\n            next(retryable)\n\n    @mock.patch(\"time.sleep\", autospec=True)\n    def test___call___with_iterable_throw(self, sleep):\n        \"\"\"\n        Throw should work even if the wrapped iterable does not support it\n        \"\"\"\n        predicate = retry.if_exception_type(ValueError)\n        retry_ = retry_streaming.StreamingRetry(predicate=predicate)\n\n        def iterable_fn(n):\n            return iter(range(n))\n\n        decorated = retry_(iterable_fn)\n\n        # try throwing with active generator\n        retryable = decorated(10)\n        assert next(retryable) == 0\n        # should swallow errors in predicate\n        retryable.throw(ValueError)\n        assert next(retryable) == 1\n        # should raise on other errors\n        with pytest.raises(TypeError):\n            retryable.throw(TypeError)\n        with pytest.raises(StopIteration):\n            next(retryable)\n\n        # try throwing with a new generator\n        retryable = decorated(10)\n        with pytest.raises(ValueError):\n            retryable.throw(ValueError)\n        with pytest.raises(StopIteration):\n            next(retryable)\n\n    @mock.patch(\"time.sleep\", autospec=True)\n    def test___call___with_generator_return(self, sleep):\n        \"\"\"\n        Generator return value should be passed through retry decorator\n        \"\"\"\n        retry_ = retry_streaming.StreamingRetry()\n\n        decorated = retry_(self._generator_mock)\n\n        expected_value = \"done\"\n        generator = decorated(5, return_val=expected_value)\n        found_value = None\n        try:\n            while True:\n                next(generator)\n        except StopIteration as e:\n            found_value = e.value\n        assert found_value == expected_value\n\n    @mock.patch(\"time.sleep\", autospec=True)\n    def test___call___with_generator_close(self, sleep):\n        \"\"\"\n        Close should be passed through retry into target generator\n        \"\"\"\n        retry_ = retry_streaming.StreamingRetry()\n\n        decorated = retry_(self._generator_mock)\n\n        exception_list = []\n        generator = decorated(10, exceptions_seen=exception_list)\n        for i in range(2):\n            next(generator)\n        generator.close()\n        assert isinstance(exception_list[0], GeneratorExit)\n        with pytest.raises(StopIteration):\n            # calling next on closed generator should raise error\n            next(generator)\n\n    @mock.patch(\"time.sleep\", autospec=True)\n    def test___call___with_generator_throw(self, sleep):\n        \"\"\"\n        Throw should be passed through retry into target generator\n        \"\"\"\n        retry_ = retry_streaming.StreamingRetry(\n            predicate=retry.if_exception_type(ValueError),\n        )\n        decorated = retry_(self._generator_mock)\n\n        exception_list = []\n        generator = decorated(10, exceptions_seen=exception_list)\n        for i in range(2):\n            next(generator)\n        with pytest.raises(BufferError):\n            generator.throw(BufferError(\"test\"))\n        assert isinstance(exception_list[0], BufferError)\n        with pytest.raises(StopIteration):\n            # calling next on closed generator should raise error\n            next(generator)\n        # should retry if throw retryable exception\n        exception_list = []\n        generator = decorated(10, exceptions_seen=exception_list)\n        for i in range(2):\n            next(generator)\n        val = generator.throw(ValueError(\"test\"))\n        assert val == 0\n        assert isinstance(exception_list[0], ValueError)\n        # calling next on closed generator should not raise error\n        assert next(generator) == 1\n\n    def test_exc_factory_non_retryable_error(self):\n        \"\"\"\n        generator should give the option to override exception creation logic\n        test when non-retryable error is thrown\n        \"\"\"\n        from google.api_core.retry import RetryFailureReason\n        from google.api_core.retry.retry_streaming import retry_target_stream\n\n        timeout = None\n        sent_errors = [ValueError(\"test\"), ValueError(\"test2\"), BufferError(\"test3\")]\n        expected_final_err = RuntimeError(\"done\")\n        expected_source_err = ZeroDivisionError(\"test4\")\n\n        def factory(*args, **kwargs):\n            assert len(kwargs) == 0\n            assert args[0] == sent_errors\n            assert args[1] == RetryFailureReason.NON_RETRYABLE_ERROR\n            assert args[2] == timeout\n            return expected_final_err, expected_source_err\n\n        generator = retry_target_stream(\n            self._generator_mock,\n            retry.if_exception_type(ValueError),\n            [0] * 3,\n            timeout=timeout,\n            exception_factory=factory,\n        )\n        # initialize generator\n        next(generator)\n        # trigger some retryable errors\n        generator.throw(sent_errors[0])\n        generator.throw(sent_errors[1])\n        # trigger a non-retryable error\n        with pytest.raises(expected_final_err.__class__) as exc_info:\n            generator.throw(sent_errors[2])\n        assert exc_info.value == expected_final_err\n        assert exc_info.value.__cause__ == expected_source_err\n\n    def test_exc_factory_timeout(self):\n        \"\"\"\n        generator should give the option to override exception creation logic\n        test when timeout is exceeded\n        \"\"\"\n        import time\n        from google.api_core.retry import RetryFailureReason\n        from google.api_core.retry.retry_streaming import retry_target_stream\n\n        timeout = 2\n        time_now = time.monotonic()\n        now_patcher = mock.patch(\n            \"time.monotonic\",\n            return_value=time_now,\n        )\n\n        with now_patcher as patched_now:\n            timeout = 2\n            sent_errors = [ValueError(\"test\"), ValueError(\"test2\"), ValueError(\"test3\")]\n            expected_final_err = RuntimeError(\"done\")\n            expected_source_err = ZeroDivisionError(\"test4\")\n\n            def factory(*args, **kwargs):\n                assert len(kwargs) == 0\n                assert args[0] == sent_errors\n                assert args[1] == RetryFailureReason.TIMEOUT\n                assert args[2] == timeout\n                return expected_final_err, expected_source_err\n\n            generator = retry_target_stream(\n                self._generator_mock,\n                retry.if_exception_type(ValueError),\n                [0] * 3,\n                timeout=timeout,\n                exception_factory=factory,\n                check_timeout_on_yield=True,\n            )\n            # initialize generator\n            next(generator)\n            # trigger some retryable errors\n            generator.throw(sent_errors[0])\n            generator.throw(sent_errors[1])\n            # trigger a timeout\n            patched_now.return_value += timeout + 1\n            with pytest.raises(expected_final_err.__class__) as exc_info:\n                generator.throw(sent_errors[2])\n            assert exc_info.value == expected_final_err\n            assert exc_info.value.__cause__ == expected_source_err\n", "tests/unit/retry/test_retry_base.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport itertools\nimport re\n\nimport mock\nimport pytest\nimport requests.exceptions\n\nfrom google.api_core import exceptions\nfrom google.api_core import retry\nfrom google.auth import exceptions as auth_exceptions\n\n\ndef test_if_exception_type():\n    predicate = retry.if_exception_type(ValueError)\n\n    assert predicate(ValueError())\n    assert not predicate(TypeError())\n\n\ndef test_if_exception_type_multiple():\n    predicate = retry.if_exception_type(ValueError, TypeError)\n\n    assert predicate(ValueError())\n    assert predicate(TypeError())\n    assert not predicate(RuntimeError())\n\n\ndef test_if_transient_error():\n    assert retry.if_transient_error(exceptions.InternalServerError(\"\"))\n    assert retry.if_transient_error(exceptions.TooManyRequests(\"\"))\n    assert retry.if_transient_error(exceptions.ServiceUnavailable(\"\"))\n    assert retry.if_transient_error(requests.exceptions.ConnectionError(\"\"))\n    assert retry.if_transient_error(requests.exceptions.ChunkedEncodingError(\"\"))\n    assert retry.if_transient_error(auth_exceptions.TransportError(\"\"))\n    assert not retry.if_transient_error(exceptions.InvalidArgument(\"\"))\n\n\n# Make uniform return half of its maximum, which will be the calculated\n# sleep time.\n@mock.patch(\"random.uniform\", autospec=True, side_effect=lambda m, n: n)\ndef test_exponential_sleep_generator_base_2(uniform):\n    gen = retry.exponential_sleep_generator(1, 60, multiplier=2)\n\n    result = list(itertools.islice(gen, 8))\n    assert result == [1, 2, 4, 8, 16, 32, 60, 60]\n\n\ndef test_build_retry_error_empty_list():\n    \"\"\"\n    attempt to build a retry error with no errors encountered\n    should return a generic RetryError\n    \"\"\"\n    from google.api_core.retry import build_retry_error\n    from google.api_core.retry import RetryFailureReason\n\n    reason = RetryFailureReason.NON_RETRYABLE_ERROR\n    src, cause = build_retry_error([], reason, 10)\n    assert isinstance(src, exceptions.RetryError)\n    assert cause is None\n    assert src.message == \"Unknown error\"\n\n\ndef test_build_retry_error_timeout_message():\n    \"\"\"\n    should provide helpful error message when timeout is reached\n    \"\"\"\n    from google.api_core.retry import build_retry_error\n    from google.api_core.retry import RetryFailureReason\n\n    reason = RetryFailureReason.TIMEOUT\n    cause = RuntimeError(\"timeout\")\n    src, found_cause = build_retry_error([ValueError(), cause], reason, 10)\n    assert isinstance(src, exceptions.RetryError)\n    assert src.message == \"Timeout of 10.0s exceeded\"\n    # should attach appropriate cause\n    assert found_cause is cause\n\n\ndef test_build_retry_error_empty_timeout():\n    \"\"\"\n    attempt to build a retry error when timeout is None\n    should return a generic timeout error message\n    \"\"\"\n    from google.api_core.retry import build_retry_error\n    from google.api_core.retry import RetryFailureReason\n\n    reason = RetryFailureReason.TIMEOUT\n    src, _ = build_retry_error([], reason, None)\n    assert isinstance(src, exceptions.RetryError)\n    assert src.message == \"Timeout exceeded\"\n\n\nclass Test_BaseRetry(object):\n    def _make_one(self, *args, **kwargs):\n        return retry.retry_base._BaseRetry(*args, **kwargs)\n\n    def test_constructor_defaults(self):\n        retry_ = self._make_one()\n        assert retry_._predicate == retry.if_transient_error\n        assert retry_._initial == 1\n        assert retry_._maximum == 60\n        assert retry_._multiplier == 2\n        assert retry_._timeout == 120\n        assert retry_._on_error is None\n        assert retry_.timeout == 120\n        assert retry_.timeout == 120\n\n    def test_constructor_options(self):\n        _some_function = mock.Mock()\n\n        retry_ = self._make_one(\n            predicate=mock.sentinel.predicate,\n            initial=1,\n            maximum=2,\n            multiplier=3,\n            timeout=4,\n            on_error=_some_function,\n        )\n        assert retry_._predicate == mock.sentinel.predicate\n        assert retry_._initial == 1\n        assert retry_._maximum == 2\n        assert retry_._multiplier == 3\n        assert retry_._timeout == 4\n        assert retry_._on_error is _some_function\n\n    @pytest.mark.parametrize(\"use_deadline\", [True, False])\n    @pytest.mark.parametrize(\"value\", [None, 0, 1, 4, 42, 5.5])\n    def test_with_timeout(self, use_deadline, value):\n        retry_ = self._make_one(\n            predicate=mock.sentinel.predicate,\n            initial=1,\n            maximum=2,\n            multiplier=3,\n            timeout=4,\n            on_error=mock.sentinel.on_error,\n        )\n        new_retry = (\n            retry_.with_timeout(value)\n            if not use_deadline\n            else retry_.with_deadline(value)\n        )\n        assert retry_ is not new_retry\n        assert new_retry._timeout == value\n        assert (\n            new_retry.timeout == value\n            if not use_deadline\n            else new_retry.deadline == value\n        )\n\n        # the rest of the attributes should remain the same\n        assert new_retry._predicate is retry_._predicate\n        assert new_retry._initial == retry_._initial\n        assert new_retry._maximum == retry_._maximum\n        assert new_retry._multiplier == retry_._multiplier\n        assert new_retry._on_error is retry_._on_error\n\n    def test_with_predicate(self):\n        retry_ = self._make_one(\n            predicate=mock.sentinel.predicate,\n            initial=1,\n            maximum=2,\n            multiplier=3,\n            timeout=4,\n            on_error=mock.sentinel.on_error,\n        )\n        new_retry = retry_.with_predicate(mock.sentinel.predicate)\n        assert retry_ is not new_retry\n        assert new_retry._predicate == mock.sentinel.predicate\n\n        # the rest of the attributes should remain the same\n        assert new_retry._timeout == retry_._timeout\n        assert new_retry._initial == retry_._initial\n        assert new_retry._maximum == retry_._maximum\n        assert new_retry._multiplier == retry_._multiplier\n        assert new_retry._on_error is retry_._on_error\n\n    def test_with_delay_noop(self):\n        retry_ = self._make_one(\n            predicate=mock.sentinel.predicate,\n            initial=1,\n            maximum=2,\n            multiplier=3,\n            timeout=4,\n            on_error=mock.sentinel.on_error,\n        )\n        new_retry = retry_.with_delay()\n        assert retry_ is not new_retry\n        assert new_retry._initial == retry_._initial\n        assert new_retry._maximum == retry_._maximum\n        assert new_retry._multiplier == retry_._multiplier\n\n    @pytest.mark.parametrize(\n        \"originals,updated,expected\",\n        [\n            [(1, 2, 3), (4, 5, 6), (4, 5, 6)],\n            [(1, 2, 3), (0, 0, 0), (0, 0, 0)],\n            [(1, 2, 3), (None, None, None), (1, 2, 3)],\n            [(0, 0, 0), (None, None, None), (0, 0, 0)],\n            [(1, 2, 3), (None, 0.5, None), (1, 0.5, 3)],\n            [(1, 2, 3), (None, 0.5, 4), (1, 0.5, 4)],\n            [(1, 2, 3), (9, None, None), (9, 2, 3)],\n        ],\n    )\n    def test_with_delay(self, originals, updated, expected):\n        retry_ = self._make_one(\n            predicate=mock.sentinel.predicate,\n            initial=originals[0],\n            maximum=originals[1],\n            multiplier=originals[2],\n            timeout=14,\n            on_error=mock.sentinel.on_error,\n        )\n        new_retry = retry_.with_delay(\n            initial=updated[0], maximum=updated[1], multiplier=updated[2]\n        )\n        assert retry_ is not new_retry\n        assert new_retry._initial == expected[0]\n        assert new_retry._maximum == expected[1]\n        assert new_retry._multiplier == expected[2]\n\n        # the rest of the attributes should remain the same\n        assert new_retry._timeout == retry_._timeout\n        assert new_retry._predicate is retry_._predicate\n        assert new_retry._on_error is retry_._on_error\n\n    def test_with_delay_partial_options(self):\n        retry_ = self._make_one(\n            predicate=mock.sentinel.predicate,\n            initial=1,\n            maximum=2,\n            multiplier=3,\n            timeout=4,\n            on_error=mock.sentinel.on_error,\n        )\n        new_retry = retry_.with_delay(initial=4)\n        assert retry_ is not new_retry\n        assert new_retry._initial == 4\n        assert new_retry._maximum == 2\n        assert new_retry._multiplier == 3\n\n        new_retry = retry_.with_delay(maximum=4)\n        assert retry_ is not new_retry\n        assert new_retry._initial == 1\n        assert new_retry._maximum == 4\n        assert new_retry._multiplier == 3\n\n        new_retry = retry_.with_delay(multiplier=4)\n        assert retry_ is not new_retry\n        assert new_retry._initial == 1\n        assert new_retry._maximum == 2\n        assert new_retry._multiplier == 4\n\n        # the rest of the attributes should remain the same\n        assert new_retry._timeout == retry_._timeout\n        assert new_retry._predicate is retry_._predicate\n        assert new_retry._on_error is retry_._on_error\n\n    def test___str__(self):\n        def if_exception_type(exc):\n            return bool(exc)  # pragma: NO COVER\n\n        # Explicitly set all attributes as changed Retry defaults should not\n        # cause this test to start failing.\n        retry_ = self._make_one(\n            predicate=if_exception_type,\n            initial=1.0,\n            maximum=60.0,\n            multiplier=2.0,\n            timeout=120.0,\n            on_error=None,\n        )\n        assert re.match(\n            (\n                r\"<_BaseRetry predicate=<function.*?if_exception_type.*?>, \"\n                r\"initial=1.0, maximum=60.0, multiplier=2.0, timeout=120.0, \"\n                r\"on_error=None>\"\n            ),\n            str(retry_),\n        )\n", "tests/unit/retry/test_retry_unary.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport datetime\nimport re\n\nimport mock\nimport pytest\n\nfrom google.api_core import exceptions\nfrom google.api_core import retry\n\nfrom .test_retry_base import Test_BaseRetry\n\n\n@mock.patch(\"time.sleep\", autospec=True)\n@mock.patch(\n    \"google.api_core.datetime_helpers.utcnow\",\n    return_value=datetime.datetime.min,\n    autospec=True,\n)\ndef test_retry_target_success(utcnow, sleep):\n    predicate = retry.if_exception_type(ValueError)\n    call_count = [0]\n\n    def target():\n        call_count[0] += 1\n        if call_count[0] < 3:\n            raise ValueError()\n        return 42\n\n    result = retry.retry_target(target, predicate, range(10), None)\n\n    assert result == 42\n    assert call_count[0] == 3\n    sleep.assert_has_calls([mock.call(0), mock.call(1)])\n\n\n@mock.patch(\"time.sleep\", autospec=True)\n@mock.patch(\n    \"google.api_core.datetime_helpers.utcnow\",\n    return_value=datetime.datetime.min,\n    autospec=True,\n)\ndef test_retry_target_w_on_error(utcnow, sleep):\n    predicate = retry.if_exception_type(ValueError)\n    call_count = {\"target\": 0}\n    to_raise = ValueError()\n\n    def target():\n        call_count[\"target\"] += 1\n        if call_count[\"target\"] < 3:\n            raise to_raise\n        return 42\n\n    on_error = mock.Mock()\n\n    result = retry.retry_target(target, predicate, range(10), None, on_error=on_error)\n\n    assert result == 42\n    assert call_count[\"target\"] == 3\n\n    on_error.assert_has_calls([mock.call(to_raise), mock.call(to_raise)])\n    sleep.assert_has_calls([mock.call(0), mock.call(1)])\n\n\n@mock.patch(\"time.sleep\", autospec=True)\n@mock.patch(\n    \"google.api_core.datetime_helpers.utcnow\",\n    return_value=datetime.datetime.min,\n    autospec=True,\n)\ndef test_retry_target_non_retryable_error(utcnow, sleep):\n    predicate = retry.if_exception_type(ValueError)\n    exception = TypeError()\n    target = mock.Mock(side_effect=exception)\n\n    with pytest.raises(TypeError) as exc_info:\n        retry.retry_target(target, predicate, range(10), None)\n\n    assert exc_info.value == exception\n    sleep.assert_not_called()\n\n\n@mock.patch(\"asyncio.sleep\", autospec=True)\n@mock.patch(\n    \"google.api_core.datetime_helpers.utcnow\",\n    return_value=datetime.datetime.min,\n    autospec=True,\n)\n@pytest.mark.asyncio\nasync def test_retry_target_warning_for_retry(utcnow, sleep):\n    predicate = retry.if_exception_type(ValueError)\n    target = mock.AsyncMock(spec=[\"__call__\"])\n\n    with pytest.warns(Warning) as exc_info:\n        # Note: predicate is just a filler and doesn't affect the test\n        retry.retry_target(target, predicate, range(10), None)\n\n    assert len(exc_info) == 2\n    assert str(exc_info[0].message) == retry.retry_unary._ASYNC_RETRY_WARNING\n    sleep.assert_not_called()\n\n\n@mock.patch(\"time.sleep\", autospec=True)\n@mock.patch(\"time.monotonic\", autospec=True)\n@pytest.mark.parametrize(\"use_deadline_arg\", [True, False])\ndef test_retry_target_timeout_exceeded(monotonic, sleep, use_deadline_arg):\n    predicate = retry.if_exception_type(ValueError)\n    exception = ValueError(\"meep\")\n    target = mock.Mock(side_effect=exception)\n    # Setup the timeline so that the first call takes 5 seconds but the second\n    # call takes 6, which puts the retry over the timeout.\n    monotonic.side_effect = [0, 5, 11]\n\n    # support \"deadline\" as an alias for \"timeout\"\n    kwargs = {\"timeout\": 10} if not use_deadline_arg else {\"deadline\": 10}\n\n    with pytest.raises(exceptions.RetryError) as exc_info:\n        retry.retry_target(target, predicate, range(10), **kwargs)\n\n    assert exc_info.value.cause == exception\n    assert exc_info.match(\"Timeout of 10.0s exceeded\")\n    assert exc_info.match(\"last exception: meep\")\n    assert target.call_count == 2\n\n    # Ensure the exception message does not include the target fn:\n    # it may be a partial with user data embedded\n    assert str(target) not in exc_info.exconly()\n\n\ndef test_retry_target_bad_sleep_generator():\n    with pytest.raises(ValueError, match=\"Sleep generator\"):\n        retry.retry_target(mock.sentinel.target, mock.sentinel.predicate, [], None)\n\n\nclass TestRetry(Test_BaseRetry):\n    def _make_one(self, *args, **kwargs):\n        return retry.Retry(*args, **kwargs)\n\n    def test___str__(self):\n        def if_exception_type(exc):\n            return bool(exc)  # pragma: NO COVER\n\n        # Explicitly set all attributes as changed Retry defaults should not\n        # cause this test to start failing.\n        retry_ = retry.Retry(\n            predicate=if_exception_type,\n            initial=1.0,\n            maximum=60.0,\n            multiplier=2.0,\n            timeout=120.0,\n            on_error=None,\n        )\n        assert re.match(\n            (\n                r\"<Retry predicate=<function.*?if_exception_type.*?>, \"\n                r\"initial=1.0, maximum=60.0, multiplier=2.0, timeout=120.0, \"\n                r\"on_error=None>\"\n            ),\n            str(retry_),\n        )\n\n    @mock.patch(\"time.sleep\", autospec=True)\n    def test___call___and_execute_success(self, sleep):\n        retry_ = retry.Retry()\n        target = mock.Mock(spec=[\"__call__\"], return_value=42)\n        # __name__ is needed by functools.partial.\n        target.__name__ = \"target\"\n\n        decorated = retry_(target)\n        target.assert_not_called()\n\n        result = decorated(\"meep\")\n\n        assert result == 42\n        target.assert_called_once_with(\"meep\")\n        sleep.assert_not_called()\n\n    @mock.patch(\"random.uniform\", autospec=True, side_effect=lambda m, n: n)\n    @mock.patch(\"time.sleep\", autospec=True)\n    def test___call___and_execute_retry(self, sleep, uniform):\n        on_error = mock.Mock(spec=[\"__call__\"], side_effect=[None])\n        retry_ = retry.Retry(predicate=retry.if_exception_type(ValueError))\n\n        target = mock.Mock(spec=[\"__call__\"], side_effect=[ValueError(), 42])\n        # __name__ is needed by functools.partial.\n        target.__name__ = \"target\"\n\n        decorated = retry_(target, on_error=on_error)\n        target.assert_not_called()\n\n        result = decorated(\"meep\")\n\n        assert result == 42\n        assert target.call_count == 2\n        target.assert_has_calls([mock.call(\"meep\"), mock.call(\"meep\")])\n        sleep.assert_called_once_with(retry_._initial)\n        assert on_error.call_count == 1\n\n    @mock.patch(\"random.uniform\", autospec=True, side_effect=lambda m, n: n)\n    @mock.patch(\"time.sleep\", autospec=True)\n    def test___call___and_execute_retry_hitting_timeout(self, sleep, uniform):\n        on_error = mock.Mock(spec=[\"__call__\"], side_effect=[None] * 10)\n        retry_ = retry.Retry(\n            predicate=retry.if_exception_type(ValueError),\n            initial=1.0,\n            maximum=1024.0,\n            multiplier=2.0,\n            timeout=30.9,\n        )\n\n        monotonic_patcher = mock.patch(\"time.monotonic\", return_value=0)\n\n        target = mock.Mock(spec=[\"__call__\"], side_effect=[ValueError()] * 10)\n        # __name__ is needed by functools.partial.\n        target.__name__ = \"target\"\n\n        decorated = retry_(target, on_error=on_error)\n        target.assert_not_called()\n\n        with monotonic_patcher as patched_monotonic:\n            # Make sure that calls to fake time.sleep() also advance the mocked\n            # time clock.\n            def increase_time(sleep_delay):\n                patched_monotonic.return_value += sleep_delay\n\n            sleep.side_effect = increase_time\n\n            with pytest.raises(exceptions.RetryError):\n                decorated(\"meep\")\n\n        assert target.call_count == 5\n        target.assert_has_calls([mock.call(\"meep\")] * 5)\n        assert on_error.call_count == 5\n\n        # check the delays\n        assert sleep.call_count == 4  # once between each successive target calls\n        last_wait = sleep.call_args.args[0]\n        total_wait = sum(call_args.args[0] for call_args in sleep.call_args_list)\n\n        assert last_wait == 8.0\n        # Next attempt would be scheduled in 16 secs, 15 + 16 = 31 > 30.9, thus\n        # we do not even wait for it to be scheduled (30.9 is configured timeout).\n        # This changes the previous logic of shortening the last attempt to fit\n        # in the timeout. The previous logic was removed to make Python retry\n        # logic consistent with the other languages and to not disrupt the\n        # randomized retry delays distribution by artificially increasing a\n        # probability of scheduling two (instead of one) last attempts with very\n        # short delay between them, while the second retry having very low chance\n        # of succeeding anyways.\n        assert total_wait == 15.0\n\n    @mock.patch(\"time.sleep\", autospec=True)\n    def test___init___without_retry_executed(self, sleep):\n        _some_function = mock.Mock()\n\n        retry_ = retry.Retry(\n            predicate=retry.if_exception_type(ValueError), on_error=_some_function\n        )\n        # check the proper creation of the class\n        assert retry_._on_error is _some_function\n\n        target = mock.Mock(spec=[\"__call__\"], side_effect=[42])\n        # __name__ is needed by functools.partial.\n        target.__name__ = \"target\"\n\n        wrapped = retry_(target)\n\n        result = wrapped(\"meep\")\n\n        assert result == 42\n        target.assert_called_once_with(\"meep\")\n        sleep.assert_not_called()\n        _some_function.assert_not_called()\n\n    @mock.patch(\"random.uniform\", autospec=True, side_effect=lambda m, n: n)\n    @mock.patch(\"time.sleep\", autospec=True)\n    def test___init___when_retry_is_executed(self, sleep, uniform):\n        _some_function = mock.Mock()\n\n        retry_ = retry.Retry(\n            predicate=retry.if_exception_type(ValueError), on_error=_some_function\n        )\n        # check the proper creation of the class\n        assert retry_._on_error is _some_function\n\n        target = mock.Mock(\n            spec=[\"__call__\"], side_effect=[ValueError(), ValueError(), 42]\n        )\n        # __name__ is needed by functools.partial.\n        target.__name__ = \"target\"\n\n        wrapped = retry_(target)\n        target.assert_not_called()\n\n        result = wrapped(\"meep\")\n\n        assert result == 42\n        assert target.call_count == 3\n        assert _some_function.call_count == 2\n        target.assert_has_calls([mock.call(\"meep\"), mock.call(\"meep\")])\n        sleep.assert_any_call(retry_._initial)\n", "tests/unit/retry/__init__.py": "", "tests/unit/future/test_polling.py": "# Copyright 2017, Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport concurrent.futures\nimport threading\nimport time\n\nimport mock\nimport pytest\n\nfrom google.api_core import exceptions, retry\nfrom google.api_core.future import polling\n\n\nclass PollingFutureImpl(polling.PollingFuture):\n    def done(self, retry=None):\n        return False\n\n    def cancel(self):\n        return True\n\n    def cancelled(self):\n        return False\n\n\ndef test_polling_future_constructor():\n    future = PollingFutureImpl()\n    assert not future.done()\n    assert not future.cancelled()\n    assert future.running()\n    assert future.cancel()\n    with mock.patch.object(future, \"done\", return_value=True):\n        future.result()\n\n\ndef test_set_result():\n    future = PollingFutureImpl()\n    callback = mock.Mock()\n\n    future.set_result(1)\n\n    assert future.result() == 1\n    future.add_done_callback(callback)\n    callback.assert_called_once_with(future)\n\n\ndef test_set_exception():\n    future = PollingFutureImpl()\n    exception = ValueError(\"meep\")\n\n    future.set_exception(exception)\n\n    assert future.exception() == exception\n    with pytest.raises(ValueError):\n        future.result()\n\n    callback = mock.Mock()\n    future.add_done_callback(callback)\n    callback.assert_called_once_with(future)\n\n\ndef test_invoke_callback_exception():\n    future = PollingFutureImplWithPoll()\n    future.set_result(42)\n\n    # This should not raise, despite the callback causing an exception.\n    callback = mock.Mock(side_effect=ValueError)\n    future.add_done_callback(callback)\n    callback.assert_called_once_with(future)\n\n\nclass PollingFutureImplWithPoll(PollingFutureImpl):\n    def __init__(self, max_poll_count=1):\n        super(PollingFutureImplWithPoll, self).__init__()\n        self.poll_count = 0\n        self.event = threading.Event()\n        self.max_poll_count = max_poll_count\n\n    def done(self, retry=None):\n        self.poll_count += 1\n        if self.max_poll_count > self.poll_count:\n            return False\n        self.event.wait()\n        self.set_result(42)\n        return True\n\n\ndef test_result_with_one_polling():\n    future = PollingFutureImplWithPoll(max_poll_count=1)\n\n    future.event.set()\n    result = future.result()\n\n    assert result == 42\n    assert future.poll_count == 1\n    # Repeated calls should not cause additional polling\n    assert future.result() == result\n    assert future.poll_count == 1\n\n\ndef test_result_with_two_pollings():\n    future = PollingFutureImplWithPoll(max_poll_count=2)\n\n    future.event.set()\n    result = future.result()\n\n    assert result == 42\n    assert future.poll_count == 2\n    # Repeated calls should not cause additional polling\n    assert future.result() == result\n    assert future.poll_count == 2\n\n\ndef test_result_with_two_pollings_custom_retry():\n    future = PollingFutureImplWithPoll(max_poll_count=2)\n\n    future.event.set()\n    result = future.result()\n\n    assert result == 42\n    assert future.poll_count == 2\n    # Repeated calls should not cause additional polling\n    assert future.result() == result\n    assert future.poll_count == 2\n\n\nclass PollingFutureImplTimeout(PollingFutureImplWithPoll):\n    def done(self, retry=None):\n        time.sleep(1)\n        return False\n\n\ndef test_result_timeout():\n    future = PollingFutureImplTimeout()\n    with pytest.raises(concurrent.futures.TimeoutError):\n        future.result(timeout=1)\n\n\ndef test_exception_timeout():\n    future = PollingFutureImplTimeout()\n    with pytest.raises(concurrent.futures.TimeoutError):\n        future.exception(timeout=1)\n\n\nclass PollingFutureImplTransient(PollingFutureImplWithPoll):\n    def __init__(self, errors):\n        super(PollingFutureImplTransient, self).__init__()\n        self._errors = errors\n\n    def done(self, retry=None):\n        self.poll_count += 1\n        if self._errors:\n            error, self._errors = self._errors[0], self._errors[1:]\n            raise error(\"testing\")\n        self.set_result(42)\n        return True\n\n\ndef test_result_transient_error():\n    future = PollingFutureImplTransient(\n        (\n            polling._OperationNotComplete,\n            polling._OperationNotComplete,\n            polling._OperationNotComplete,\n        )\n    )\n    result = future.result()\n    assert result == 42\n    assert future.poll_count == 4\n    # Repeated calls should not cause additional polling\n    assert future.result() == result\n    assert future.poll_count == 4\n\n\ndef test_callback_background_thread():\n    future = PollingFutureImplWithPoll()\n    callback = mock.Mock()\n\n    future.add_done_callback(callback)\n\n    assert future._polling_thread is not None\n\n    # Give the thread a second to poll\n    time.sleep(1)\n    assert future.poll_count == 1\n\n    future.event.set()\n    future._polling_thread.join()\n\n    callback.assert_called_once_with(future)\n\n\ndef test_double_callback_background_thread():\n    future = PollingFutureImplWithPoll()\n    callback = mock.Mock()\n    callback2 = mock.Mock()\n\n    future.add_done_callback(callback)\n    current_thread = future._polling_thread\n    assert current_thread is not None\n\n    # only one polling thread should be created.\n    future.add_done_callback(callback2)\n    assert future._polling_thread is current_thread\n\n    future.event.set()\n    future._polling_thread.join()\n\n    assert future.poll_count == 1\n    callback.assert_called_once_with(future)\n    callback2.assert_called_once_with(future)\n\n\nclass PollingFutureImplWithoutRetry(PollingFutureImpl):\n    def done(self, retry=None):\n        return True\n\n    def result(self, timeout=None, retry=None, polling=None):\n        return super(PollingFutureImplWithoutRetry, self).result()\n\n    def _blocking_poll(self, timeout=None, retry=None, polling=None):\n        return super(PollingFutureImplWithoutRetry, self)._blocking_poll(\n            timeout=timeout\n        )\n\n\nclass PollingFutureImplWith_done_or_raise(PollingFutureImpl):\n    def done(self, retry=None):\n        return True\n\n    def _done_or_raise(self, retry=None):\n        return super(PollingFutureImplWith_done_or_raise, self)._done_or_raise()\n\n\ndef test_polling_future_without_retry():\n    custom_retry = retry.Retry(\n        predicate=retry.if_exception_type(exceptions.TooManyRequests)\n    )\n    future = PollingFutureImplWithoutRetry()\n    assert future.done()\n    assert not future.running()\n    assert future.result() is None\n\n    with mock.patch.object(future, \"done\") as done_mock:\n        future._done_or_raise()\n        done_mock.assert_called_once_with(retry=None)\n\n    with mock.patch.object(future, \"done\") as done_mock:\n        future._done_or_raise(retry=custom_retry)\n        done_mock.assert_called_once_with(retry=custom_retry)\n\n\ndef test_polling_future_with__done_or_raise():\n    future = PollingFutureImplWith_done_or_raise()\n    assert future.done()\n    assert not future.running()\n    assert future.result() is None\n", "tests/unit/future/test__helpers.py": "# Copyright 2017, Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport mock\n\nfrom google.api_core.future import _helpers\n\n\n@mock.patch(\"threading.Thread\", autospec=True)\ndef test_start_deamon_thread(unused_thread):\n    deamon_thread = _helpers.start_daemon_thread(target=mock.sentinel.target)\n    assert deamon_thread.daemon is True\n\n\ndef test_safe_invoke_callback():\n    callback = mock.Mock(spec=[\"__call__\"], return_value=42)\n    result = _helpers.safe_invoke_callback(callback, \"a\", b=\"c\")\n    assert result == 42\n    callback.assert_called_once_with(\"a\", b=\"c\")\n\n\ndef test_safe_invoke_callback_exception():\n    callback = mock.Mock(spec=[\"__call__\"], side_effect=ValueError())\n    result = _helpers.safe_invoke_callback(callback, \"a\", b=\"c\")\n    assert result is None\n    callback.assert_called_once_with(\"a\", b=\"c\")\n", "tests/unit/future/__init__.py": "", "google/api_core/grpc_helpers.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Helpers for :mod:`grpc`.\"\"\"\nfrom typing import Generic, Iterator, Optional, TypeVar\n\nimport collections\nimport functools\nimport warnings\n\nimport grpc\n\nfrom google.api_core import exceptions\nimport google.auth\nimport google.auth.credentials\nimport google.auth.transport.grpc\nimport google.auth.transport.requests\nimport google.protobuf\n\nPROTOBUF_VERSION = google.protobuf.__version__\n\n# The grpcio-gcp package only has support for protobuf < 4\nif PROTOBUF_VERSION[0:2] == \"3.\":  # pragma: NO COVER\n    try:\n        import grpc_gcp\n\n        warnings.warn(\n            \"\"\"Support for grpcio-gcp is deprecated. This feature will be\n            removed from `google-api-core` after January 1, 2024. If you need to\n            continue to use this feature, please pin to a specific version of\n            `google-api-core`.\"\"\",\n            DeprecationWarning,\n        )\n        HAS_GRPC_GCP = True\n    except ImportError:\n        HAS_GRPC_GCP = False\nelse:\n    HAS_GRPC_GCP = False\n\n\n# The list of gRPC Callable interfaces that return iterators.\n_STREAM_WRAP_CLASSES = (grpc.UnaryStreamMultiCallable, grpc.StreamStreamMultiCallable)\n\n# denotes the proto response type for grpc calls\nP = TypeVar(\"P\")\n\n\ndef _patch_callable_name(callable_):\n    \"\"\"Fix-up gRPC callable attributes.\n\n    gRPC callable lack the ``__name__`` attribute which causes\n    :func:`functools.wraps` to error. This adds the attribute if needed.\n    \"\"\"\n    if not hasattr(callable_, \"__name__\"):\n        callable_.__name__ = callable_.__class__.__name__\n\n\ndef _wrap_unary_errors(callable_):\n    \"\"\"Map errors for Unary-Unary and Stream-Unary gRPC callables.\"\"\"\n    _patch_callable_name(callable_)\n\n    @functools.wraps(callable_)\n    def error_remapped_callable(*args, **kwargs):\n        try:\n            return callable_(*args, **kwargs)\n        except grpc.RpcError as exc:\n            raise exceptions.from_grpc_error(exc) from exc\n\n    return error_remapped_callable\n\n\nclass _StreamingResponseIterator(Generic[P], grpc.Call):\n    def __init__(self, wrapped, prefetch_first_result=True):\n        self._wrapped = wrapped\n\n        # This iterator is used in a retry context, and returned outside after init.\n        # gRPC will not throw an exception until the stream is consumed, so we need\n        # to retrieve the first result, in order to fail, in order to trigger a retry.\n        try:\n            if prefetch_first_result:\n                self._stored_first_result = next(self._wrapped)\n        except TypeError:\n            # It is possible the wrapped method isn't an iterable (a grpc.Call\n            # for instance). If this happens don't store the first result.\n            pass\n        except StopIteration:\n            # ignore stop iteration at this time. This should be handled outside of retry.\n            pass\n\n    def __iter__(self) -> Iterator[P]:\n        \"\"\"This iterator is also an iterable that returns itself.\"\"\"\n        return self\n\n    def __next__(self) -> P:\n        \"\"\"Get the next response from the stream.\n\n        Returns:\n            protobuf.Message: A single response from the stream.\n        \"\"\"\n        try:\n            if hasattr(self, \"_stored_first_result\"):\n                result = self._stored_first_result\n                del self._stored_first_result\n                return result\n            return next(self._wrapped)\n        except grpc.RpcError as exc:\n            # If the stream has already returned data, we cannot recover here.\n            raise exceptions.from_grpc_error(exc) from exc\n\n    # grpc.Call & grpc.RpcContext interface\n\n    def add_callback(self, callback):\n        return self._wrapped.add_callback(callback)\n\n    def cancel(self):\n        return self._wrapped.cancel()\n\n    def code(self):\n        return self._wrapped.code()\n\n    def details(self):\n        return self._wrapped.details()\n\n    def initial_metadata(self):\n        return self._wrapped.initial_metadata()\n\n    def is_active(self):\n        return self._wrapped.is_active()\n\n    def time_remaining(self):\n        return self._wrapped.time_remaining()\n\n    def trailing_metadata(self):\n        return self._wrapped.trailing_metadata()\n\n\n# public type alias denoting the return type of streaming gapic calls\nGrpcStream = _StreamingResponseIterator[P]\n\n\ndef _wrap_stream_errors(callable_):\n    \"\"\"Wrap errors for Unary-Stream and Stream-Stream gRPC callables.\n\n    The callables that return iterators require a bit more logic to re-map\n    errors when iterating. This wraps both the initial invocation and the\n    iterator of the return value to re-map errors.\n    \"\"\"\n    _patch_callable_name(callable_)\n\n    @functools.wraps(callable_)\n    def error_remapped_callable(*args, **kwargs):\n        try:\n            result = callable_(*args, **kwargs)\n            # Auto-fetching the first result causes PubSub client's streaming pull\n            # to hang when re-opening the stream, thus we need examine the hacky\n            # hidden flag to see if pre-fetching is disabled.\n            # https://github.com/googleapis/python-pubsub/issues/93#issuecomment-630762257\n            prefetch_first = getattr(callable_, \"_prefetch_first_result_\", True)\n            return _StreamingResponseIterator(\n                result, prefetch_first_result=prefetch_first\n            )\n        except grpc.RpcError as exc:\n            raise exceptions.from_grpc_error(exc) from exc\n\n    return error_remapped_callable\n\n\ndef wrap_errors(callable_):\n    \"\"\"Wrap a gRPC callable and map :class:`grpc.RpcErrors` to friendly error\n    classes.\n\n    Errors raised by the gRPC callable are mapped to the appropriate\n    :class:`google.api_core.exceptions.GoogleAPICallError` subclasses.\n    The original `grpc.RpcError` (which is usually also a `grpc.Call`) is\n    available from the ``response`` property on the mapped exception. This\n    is useful for extracting metadata from the original error.\n\n    Args:\n        callable_ (Callable): A gRPC callable.\n\n    Returns:\n        Callable: The wrapped gRPC callable.\n    \"\"\"\n    if isinstance(callable_, _STREAM_WRAP_CLASSES):\n        return _wrap_stream_errors(callable_)\n    else:\n        return _wrap_unary_errors(callable_)\n\n\ndef _create_composite_credentials(\n    credentials=None,\n    credentials_file=None,\n    default_scopes=None,\n    scopes=None,\n    ssl_credentials=None,\n    quota_project_id=None,\n    default_host=None,\n):\n    \"\"\"Create the composite credentials for secure channels.\n\n    Args:\n        credentials (google.auth.credentials.Credentials): The credentials. If\n            not specified, then this function will attempt to ascertain the\n            credentials from the environment using :func:`google.auth.default`.\n        credentials_file (str): A file with credentials that can be loaded with\n            :func:`google.auth.load_credentials_from_file`. This argument is\n            mutually exclusive with credentials.\n        default_scopes (Sequence[str]): A optional list of scopes needed for this\n            service. These are only used when credentials are not specified and\n            are passed to :func:`google.auth.default`.\n        scopes (Sequence[str]): A optional list of scopes needed for this\n            service. These are only used when credentials are not specified and\n            are passed to :func:`google.auth.default`.\n        ssl_credentials (grpc.ChannelCredentials): Optional SSL channel\n            credentials. This can be used to specify different certificates.\n        quota_project_id (str): An optional project to use for billing and quota.\n        default_host (str): The default endpoint. e.g., \"pubsub.googleapis.com\".\n\n    Returns:\n        grpc.ChannelCredentials: The composed channel credentials object.\n\n    Raises:\n        google.api_core.DuplicateCredentialArgs: If both a credentials object and credentials_file are passed.\n    \"\"\"\n    if credentials and credentials_file:\n        raise exceptions.DuplicateCredentialArgs(\n            \"'credentials' and 'credentials_file' are mutually exclusive.\"\n        )\n\n    if credentials_file:\n        credentials, _ = google.auth.load_credentials_from_file(\n            credentials_file, scopes=scopes, default_scopes=default_scopes\n        )\n    elif credentials:\n        credentials = google.auth.credentials.with_scopes_if_required(\n            credentials, scopes=scopes, default_scopes=default_scopes\n        )\n    else:\n        credentials, _ = google.auth.default(\n            scopes=scopes, default_scopes=default_scopes\n        )\n\n    if quota_project_id and isinstance(\n        credentials, google.auth.credentials.CredentialsWithQuotaProject\n    ):\n        credentials = credentials.with_quota_project(quota_project_id)\n\n    request = google.auth.transport.requests.Request()\n\n    # Create the metadata plugin for inserting the authorization header.\n    metadata_plugin = google.auth.transport.grpc.AuthMetadataPlugin(\n        credentials,\n        request,\n        default_host=default_host,\n    )\n\n    # Create a set of grpc.CallCredentials using the metadata plugin.\n    google_auth_credentials = grpc.metadata_call_credentials(metadata_plugin)\n\n    # if `ssl_credentials` is set, use `grpc.composite_channel_credentials` instead of\n    # `grpc.compute_engine_channel_credentials` as the former supports passing\n    # `ssl_credentials` via `channel_credentials` which is needed for mTLS.\n    if ssl_credentials:\n        # Combine the ssl credentials and the authorization credentials.\n        # See https://grpc.github.io/grpc/python/grpc.html#grpc.composite_channel_credentials\n        return grpc.composite_channel_credentials(\n            ssl_credentials, google_auth_credentials\n        )\n    else:\n        # Use grpc.compute_engine_channel_credentials in order to support Direct Path.\n        # See https://grpc.github.io/grpc/python/grpc.html#grpc.compute_engine_channel_credentials\n        # TODO(https://github.com/googleapis/python-api-core/issues/598):\n        # Although `grpc.compute_engine_channel_credentials` returns channel credentials\n        # outside of a Google Compute Engine environment (GCE), we should determine if\n        # there is a way to reliably detect a GCE environment so that\n        # `grpc.compute_engine_channel_credentials` is not called outside of GCE.\n        return grpc.compute_engine_channel_credentials(google_auth_credentials)\n\n\ndef create_channel(\n    target,\n    credentials=None,\n    scopes=None,\n    ssl_credentials=None,\n    credentials_file=None,\n    quota_project_id=None,\n    default_scopes=None,\n    default_host=None,\n    compression=None,\n    attempt_direct_path: Optional[bool] = False,\n    **kwargs,\n):\n    \"\"\"Create a secure channel with credentials.\n\n    Args:\n        target (str): The target service address in the format 'hostname:port'.\n        credentials (google.auth.credentials.Credentials): The credentials. If\n            not specified, then this function will attempt to ascertain the\n            credentials from the environment using :func:`google.auth.default`.\n        scopes (Sequence[str]): A optional list of scopes needed for this\n            service. These are only used when credentials are not specified and\n            are passed to :func:`google.auth.default`.\n        ssl_credentials (grpc.ChannelCredentials): Optional SSL channel\n            credentials. This can be used to specify different certificates.\n        credentials_file (str): A file with credentials that can be loaded with\n            :func:`google.auth.load_credentials_from_file`. This argument is\n            mutually exclusive with credentials.\n        quota_project_id (str): An optional project to use for billing and quota.\n        default_scopes (Sequence[str]): Default scopes passed by a Google client\n            library. Use 'scopes' for user-defined scopes.\n        default_host (str): The default endpoint. e.g., \"pubsub.googleapis.com\".\n        compression (grpc.Compression): An optional value indicating the\n            compression method to be used over the lifetime of the channel.\n        attempt_direct_path (Optional[bool]): If set, Direct Path will be attempted\n            when the request is made. Direct Path is only available within a Google\n            Compute Engine (GCE) environment and provides a proxyless connection\n            which increases the available throughput, reduces latency, and increases\n            reliability. Note:\n\n            - This argument should only be set in a GCE environment and for Services\n              that are known to support Direct Path.\n            - If this argument is set outside of GCE, then this request will fail\n              unless the back-end service happens to have configured fall-back to DNS.\n            - If the request causes a `ServiceUnavailable` response, it is recommended\n              that the client repeat the request with `attempt_direct_path` set to\n              `False` as the Service may not support Direct Path.\n            - Using `ssl_credentials` with `attempt_direct_path` set to `True` will\n              result in `ValueError` as this combination  is not yet supported.\n\n        kwargs: Additional key-word args passed to\n            :func:`grpc_gcp.secure_channel` or :func:`grpc.secure_channel`.\n            Note: `grpc_gcp` is only supported in environments with protobuf < 4.0.0.\n\n    Returns:\n        grpc.Channel: The created channel.\n\n    Raises:\n        google.api_core.DuplicateCredentialArgs: If both a credentials object and credentials_file are passed.\n        ValueError: If `ssl_credentials` is set and `attempt_direct_path` is set to `True`.\n    \"\"\"\n\n    # If `ssl_credentials` is set and `attempt_direct_path` is set to `True`,\n    # raise ValueError as this is not yet supported.\n    # See https://github.com/googleapis/python-api-core/issues/590\n    if ssl_credentials and attempt_direct_path:\n        raise ValueError(\"Using ssl_credentials with Direct Path is not supported\")\n\n    composite_credentials = _create_composite_credentials(\n        credentials=credentials,\n        credentials_file=credentials_file,\n        default_scopes=default_scopes,\n        scopes=scopes,\n        ssl_credentials=ssl_credentials,\n        quota_project_id=quota_project_id,\n        default_host=default_host,\n    )\n\n    # Note that grpcio-gcp is deprecated\n    if HAS_GRPC_GCP:  # pragma: NO COVER\n        if compression is not None and compression != grpc.Compression.NoCompression:\n            warnings.warn(\n                \"The `compression` argument is ignored for grpc_gcp.secure_channel creation.\",\n                DeprecationWarning,\n            )\n        if attempt_direct_path:\n            warnings.warn(\n                \"\"\"The `attempt_direct_path` argument is ignored for grpc_gcp.secure_channel creation.\"\"\",\n                DeprecationWarning,\n            )\n        return grpc_gcp.secure_channel(target, composite_credentials, **kwargs)\n\n    if attempt_direct_path:\n        target = _modify_target_for_direct_path(target)\n\n    return grpc.secure_channel(\n        target, composite_credentials, compression=compression, **kwargs\n    )\n\n\ndef _modify_target_for_direct_path(target: str) -> str:\n    \"\"\"\n    Given a target, return a modified version which is compatible with Direct Path.\n\n    Args:\n        target (str): The target service address in the format 'hostname[:port]' or\n            'dns://hostname[:port]'.\n\n    Returns:\n        target (str): The target service address which is converted into a format compatible with Direct Path.\n            If the target contains `dns:///` or does not contain `:///`, the target will be converted in\n            a format compatible with Direct Path; otherwise the original target will be returned as the\n            original target may already denote Direct Path.\n    \"\"\"\n\n    # A DNS prefix may be included with the target to indicate the endpoint is living in the Internet,\n    # outside of Google Cloud Platform.\n    dns_prefix = \"dns:///\"\n    # Remove \"dns:///\" if `attempt_direct_path` is set to True as\n    # the Direct Path prefix `google-c2p:///` will be used instead.\n    target = target.replace(dns_prefix, \"\")\n\n    direct_path_separator = \":///\"\n    if direct_path_separator not in target:\n        target_without_port = target.split(\":\")[0]\n        # Modify the target to use Direct Path by adding the `google-c2p:///` prefix\n        target = f\"google-c2p{direct_path_separator}{target_without_port}\"\n    return target\n\n\n_MethodCall = collections.namedtuple(\n    \"_MethodCall\", (\"request\", \"timeout\", \"metadata\", \"credentials\", \"compression\")\n)\n\n_ChannelRequest = collections.namedtuple(\"_ChannelRequest\", (\"method\", \"request\"))\n\n\nclass _CallableStub(object):\n    \"\"\"Stub for the grpc.*MultiCallable interfaces.\"\"\"\n\n    def __init__(self, method, channel):\n        self._method = method\n        self._channel = channel\n        self.response = None\n        \"\"\"Union[protobuf.Message, Callable[protobuf.Message], exception]:\n        The response to give when invoking this callable. If this is a\n        callable, it will be invoked with the request protobuf. If it's an\n        exception, the exception will be raised when this is invoked.\n        \"\"\"\n        self.responses = None\n        \"\"\"Iterator[\n            Union[protobuf.Message, Callable[protobuf.Message], exception]]:\n        An iterator of responses. If specified, self.response will be populated\n        on each invocation by calling ``next(self.responses)``.\"\"\"\n        self.requests = []\n        \"\"\"List[protobuf.Message]: All requests sent to this callable.\"\"\"\n        self.calls = []\n        \"\"\"List[Tuple]: All invocations of this callable. Each tuple is the\n        request, timeout, metadata, compression, and credentials.\"\"\"\n\n    def __call__(\n        self, request, timeout=None, metadata=None, credentials=None, compression=None\n    ):\n        self._channel.requests.append(_ChannelRequest(self._method, request))\n        self.calls.append(\n            _MethodCall(request, timeout, metadata, credentials, compression)\n        )\n        self.requests.append(request)\n\n        response = self.response\n        if self.responses is not None:\n            if response is None:\n                response = next(self.responses)\n            else:\n                raise ValueError(\n                    \"{method}.response and {method}.responses are mutually \"\n                    \"exclusive.\".format(method=self._method)\n                )\n\n        if callable(response):\n            return response(request)\n\n        if isinstance(response, Exception):\n            raise response\n\n        if response is not None:\n            return response\n\n        raise ValueError('Method stub for \"{}\" has no response.'.format(self._method))\n\n\ndef _simplify_method_name(method):\n    \"\"\"Simplifies a gRPC method name.\n\n    When gRPC invokes the channel to create a callable, it gives a full\n    method name like \"/google.pubsub.v1.Publisher/CreateTopic\". This\n    returns just the name of the method, in this case \"CreateTopic\".\n\n    Args:\n        method (str): The name of the method.\n\n    Returns:\n        str: The simplified name of the method.\n    \"\"\"\n    return method.rsplit(\"/\", 1).pop()\n\n\nclass ChannelStub(grpc.Channel):\n    \"\"\"A testing stub for the grpc.Channel interface.\n\n    This can be used to test any client that eventually uses a gRPC channel\n    to communicate. By passing in a channel stub, you can configure which\n    responses are returned and track which requests are made.\n\n    For example:\n\n    .. code-block:: python\n\n        channel_stub = grpc_helpers.ChannelStub()\n        client = FooClient(channel=channel_stub)\n\n        channel_stub.GetFoo.response = foo_pb2.Foo(name='bar')\n\n        foo = client.get_foo(labels=['baz'])\n\n        assert foo.name == 'bar'\n        assert channel_stub.GetFoo.requests[0].labels = ['baz']\n\n    Each method on the stub can be accessed and configured on the channel.\n    Here's some examples of various configurations:\n\n    .. code-block:: python\n\n        # Return a basic response:\n\n        channel_stub.GetFoo.response = foo_pb2.Foo(name='bar')\n        assert client.get_foo().name == 'bar'\n\n        # Raise an exception:\n        channel_stub.GetFoo.response = NotFound('...')\n\n        with pytest.raises(NotFound):\n            client.get_foo()\n\n        # Use a sequence of responses:\n        channel_stub.GetFoo.responses = iter([\n            foo_pb2.Foo(name='bar'),\n            foo_pb2.Foo(name='baz'),\n        ])\n\n        assert client.get_foo().name == 'bar'\n        assert client.get_foo().name == 'baz'\n\n        # Use a callable\n\n        def on_get_foo(request):\n            return foo_pb2.Foo(name='bar' + request.id)\n\n        channel_stub.GetFoo.response = on_get_foo\n\n        assert client.get_foo(id='123').name == 'bar123'\n    \"\"\"\n\n    def __init__(self, responses=[]):\n        self.requests = []\n        \"\"\"Sequence[Tuple[str, protobuf.Message]]: A list of all requests made\n        on this channel in order. The tuple is of method name, request\n        message.\"\"\"\n        self._method_stubs = {}\n\n    def _stub_for_method(self, method):\n        method = _simplify_method_name(method)\n        self._method_stubs[method] = _CallableStub(method, self)\n        return self._method_stubs[method]\n\n    def __getattr__(self, key):\n        try:\n            return self._method_stubs[key]\n        except KeyError:\n            raise AttributeError\n\n    def unary_unary(\n        self,\n        method,\n        request_serializer=None,\n        response_deserializer=None,\n        _registered_method=False,\n    ):\n        \"\"\"grpc.Channel.unary_unary implementation.\"\"\"\n        return self._stub_for_method(method)\n\n    def unary_stream(\n        self,\n        method,\n        request_serializer=None,\n        response_deserializer=None,\n        _registered_method=False,\n    ):\n        \"\"\"grpc.Channel.unary_stream implementation.\"\"\"\n        return self._stub_for_method(method)\n\n    def stream_unary(\n        self,\n        method,\n        request_serializer=None,\n        response_deserializer=None,\n        _registered_method=False,\n    ):\n        \"\"\"grpc.Channel.stream_unary implementation.\"\"\"\n        return self._stub_for_method(method)\n\n    def stream_stream(\n        self,\n        method,\n        request_serializer=None,\n        response_deserializer=None,\n        _registered_method=False,\n    ):\n        \"\"\"grpc.Channel.stream_stream implementation.\"\"\"\n        return self._stub_for_method(method)\n\n    def subscribe(self, callback, try_to_connect=False):\n        \"\"\"grpc.Channel.subscribe implementation.\"\"\"\n        pass\n\n    def unsubscribe(self, callback):\n        \"\"\"grpc.Channel.unsubscribe implementation.\"\"\"\n        pass\n\n    def close(self):\n        \"\"\"grpc.Channel.close implementation.\"\"\"\n        pass\n", "google/api_core/iam.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\"Non-API-specific IAM policy definitions\n\nFor allowed roles / permissions, see:\nhttps://cloud.google.com/iam/docs/understanding-roles\n\nExample usage:\n\n.. code-block:: python\n\n   # ``get_iam_policy`` returns a :class:'~google.api_core.iam.Policy`.\n   policy = resource.get_iam_policy(requested_policy_version=3)\n\n   phred = \"user:phred@example.com\"\n   admin_group = \"group:admins@groups.example.com\"\n   account = \"serviceAccount:account-1234@accounts.example.com\"\n\n   policy.version = 3\n   policy.bindings = [\n       {\n           \"role\": \"roles/owner\",\n           \"members\": {phred, admin_group, account}\n       },\n       {\n           \"role\": \"roles/editor\",\n           \"members\": {\"allAuthenticatedUsers\"}\n       },\n       {\n           \"role\": \"roles/viewer\",\n           \"members\": {\"allUsers\"}\n           \"condition\": {\n               \"title\": \"request_time\",\n               \"description\": \"Requests made before 2021-01-01T00:00:00Z\",\n               \"expression\": \"request.time < timestamp(\\\"2021-01-01T00:00:00Z\\\")\"\n           }\n       }\n   ]\n\n   resource.set_iam_policy(policy)\n\"\"\"\n\nimport collections\nimport collections.abc\nimport operator\nimport warnings\n\n# Generic IAM roles\n\nOWNER_ROLE = \"roles/owner\"\n\"\"\"Generic role implying all rights to an object.\"\"\"\n\nEDITOR_ROLE = \"roles/editor\"\n\"\"\"Generic role implying rights to modify an object.\"\"\"\n\nVIEWER_ROLE = \"roles/viewer\"\n\"\"\"Generic role implying rights to access an object.\"\"\"\n\n_ASSIGNMENT_DEPRECATED_MSG = \"\"\"\\\nAssigning to '{}' is deprecated. Use the `policy.bindings` property to modify bindings instead.\"\"\"\n\n_DICT_ACCESS_MSG = \"\"\"\\\nDict access is not supported on policies with version > 1 or with conditional bindings.\"\"\"\n\n\nclass InvalidOperationException(Exception):\n    \"\"\"Raised when trying to use Policy class as a dict.\"\"\"\n\n    pass\n\n\nclass Policy(collections.abc.MutableMapping):\n    \"\"\"IAM Policy\n\n    Args:\n        etag (Optional[str]): ETag used to identify a unique of the policy\n        version (Optional[int]): The syntax schema version of the policy.\n\n    Note:\n        Using conditions in bindings requires the policy's version to be set\n        to `3` or greater, depending on the versions that are currently supported.\n\n        Accessing the policy using dict operations will raise InvalidOperationException\n        when the policy's version is set to 3.\n\n        Use the policy.bindings getter/setter to retrieve and modify the policy's bindings.\n\n    See:\n        IAM Policy https://cloud.google.com/iam/reference/rest/v1/Policy\n        Policy versions https://cloud.google.com/iam/docs/policies#versions\n        Conditions overview https://cloud.google.com/iam/docs/conditions-overview.\n    \"\"\"\n\n    _OWNER_ROLES = (OWNER_ROLE,)\n    \"\"\"Roles mapped onto our ``owners`` attribute.\"\"\"\n\n    _EDITOR_ROLES = (EDITOR_ROLE,)\n    \"\"\"Roles mapped onto our ``editors`` attribute.\"\"\"\n\n    _VIEWER_ROLES = (VIEWER_ROLE,)\n    \"\"\"Roles mapped onto our ``viewers`` attribute.\"\"\"\n\n    def __init__(self, etag=None, version=None):\n        self.etag = etag\n        self.version = version\n        self._bindings = []\n\n    def __iter__(self):\n        self.__check_version__()\n        # Exclude bindings with no members\n        return (binding[\"role\"] for binding in self._bindings if binding[\"members\"])\n\n    def __len__(self):\n        self.__check_version__()\n        # Exclude bindings with no members\n        return len(list(self.__iter__()))\n\n    def __getitem__(self, key):\n        self.__check_version__()\n        for b in self._bindings:\n            if b[\"role\"] == key:\n                return b[\"members\"]\n        # If the binding does not yet exist, create one\n        # NOTE: This will create bindings with no members\n        # which are ignored by __iter__ and __len__\n        new_binding = {\"role\": key, \"members\": set()}\n        self._bindings.append(new_binding)\n        return new_binding[\"members\"]\n\n    def __setitem__(self, key, value):\n        self.__check_version__()\n        value = set(value)\n        for binding in self._bindings:\n            if binding[\"role\"] == key:\n                binding[\"members\"] = value\n                return\n        self._bindings.append({\"role\": key, \"members\": value})\n\n    def __delitem__(self, key):\n        self.__check_version__()\n        for b in self._bindings:\n            if b[\"role\"] == key:\n                self._bindings.remove(b)\n                return\n        raise KeyError(key)\n\n    def __check_version__(self):\n        \"\"\"Raise InvalidOperationException if version is greater than 1 or policy contains conditions.\"\"\"\n        raise_version = self.version is not None and self.version > 1\n\n        if raise_version or self._contains_conditions():\n            raise InvalidOperationException(_DICT_ACCESS_MSG)\n\n    def _contains_conditions(self):\n        for b in self._bindings:\n            if b.get(\"condition\") is not None:\n                return True\n        return False\n\n    @property\n    def bindings(self):\n        \"\"\"The policy's list of bindings.\n\n        A binding is specified by a dictionary with keys:\n\n        * role (str): Role that is assigned to `members`.\n\n        * members (:obj:`set` of str): Specifies the identities associated to this binding.\n\n        * condition (:obj:`dict` of str:str): Specifies a condition under which this binding will apply.\n\n          * title (str): Title for the condition.\n\n          * description (:obj:str, optional): Description of the condition.\n\n          * expression: A CEL expression.\n\n        Type:\n           :obj:`list` of :obj:`dict`\n\n        See:\n           Policy versions https://cloud.google.com/iam/docs/policies#versions\n           Conditions overview https://cloud.google.com/iam/docs/conditions-overview.\n\n        Example:\n\n        .. code-block:: python\n\n           USER = \"user:phred@example.com\"\n           ADMIN_GROUP = \"group:admins@groups.example.com\"\n           SERVICE_ACCOUNT = \"serviceAccount:account-1234@accounts.example.com\"\n           CONDITION = {\n               \"title\": \"request_time\",\n               \"description\": \"Requests made before 2021-01-01T00:00:00Z\", # Optional\n               \"expression\": \"request.time < timestamp(\\\"2021-01-01T00:00:00Z\\\")\"\n           }\n\n           # Set policy's version to 3 before setting bindings containing conditions.\n           policy.version = 3\n\n           policy.bindings = [\n               {\n                   \"role\": \"roles/viewer\",\n                   \"members\": {USER, ADMIN_GROUP, SERVICE_ACCOUNT},\n                   \"condition\": CONDITION\n               },\n               ...\n           ]\n        \"\"\"\n        return self._bindings\n\n    @bindings.setter\n    def bindings(self, bindings):\n        self._bindings = bindings\n\n    @property\n    def owners(self):\n        \"\"\"Legacy access to owner role.\n\n        Raise InvalidOperationException if version is greater than 1 or policy contains conditions.\n\n        DEPRECATED:  use `policy.bindings` to access bindings instead.\n        \"\"\"\n        result = set()\n        for role in self._OWNER_ROLES:\n            for member in self.get(role, ()):\n                result.add(member)\n        return frozenset(result)\n\n    @owners.setter\n    def owners(self, value):\n        \"\"\"Update owners.\n\n        Raise InvalidOperationException if version is greater than 1 or policy contains conditions.\n\n        DEPRECATED:  use `policy.bindings` to access bindings instead.\n        \"\"\"\n        warnings.warn(\n            _ASSIGNMENT_DEPRECATED_MSG.format(\"owners\", OWNER_ROLE), DeprecationWarning\n        )\n        self[OWNER_ROLE] = value\n\n    @property\n    def editors(self):\n        \"\"\"Legacy access to editor role.\n\n        Raise InvalidOperationException if version is greater than 1 or policy contains conditions.\n\n        DEPRECATED:  use `policy.bindings` to access bindings instead.\n        \"\"\"\n        result = set()\n        for role in self._EDITOR_ROLES:\n            for member in self.get(role, ()):\n                result.add(member)\n        return frozenset(result)\n\n    @editors.setter\n    def editors(self, value):\n        \"\"\"Update editors.\n\n        Raise InvalidOperationException if version is greater than 1 or policy contains conditions.\n\n        DEPRECATED:  use `policy.bindings` to modify bindings instead.\n        \"\"\"\n        warnings.warn(\n            _ASSIGNMENT_DEPRECATED_MSG.format(\"editors\", EDITOR_ROLE),\n            DeprecationWarning,\n        )\n        self[EDITOR_ROLE] = value\n\n    @property\n    def viewers(self):\n        \"\"\"Legacy access to viewer role.\n\n        Raise InvalidOperationException if version is greater than 1 or policy contains conditions.\n\n        DEPRECATED:  use `policy.bindings` to modify bindings instead.\n        \"\"\"\n        result = set()\n        for role in self._VIEWER_ROLES:\n            for member in self.get(role, ()):\n                result.add(member)\n        return frozenset(result)\n\n    @viewers.setter\n    def viewers(self, value):\n        \"\"\"Update viewers.\n\n        Raise InvalidOperationException if version is greater than 1 or policy contains conditions.\n\n        DEPRECATED:  use `policy.bindings` to modify bindings instead.\n        \"\"\"\n        warnings.warn(\n            _ASSIGNMENT_DEPRECATED_MSG.format(\"viewers\", VIEWER_ROLE),\n            DeprecationWarning,\n        )\n        self[VIEWER_ROLE] = value\n\n    @staticmethod\n    def user(email):\n        \"\"\"Factory method for a user member.\n\n        Args:\n            email (str): E-mail for this particular user.\n\n        Returns:\n            str: A member string corresponding to the given user.\n        \"\"\"\n        return \"user:%s\" % (email,)\n\n    @staticmethod\n    def service_account(email):\n        \"\"\"Factory method for a service account member.\n\n        Args:\n            email (str): E-mail for this particular service account.\n\n        Returns:\n            str: A member string corresponding to the given service account.\n\n        \"\"\"\n        return \"serviceAccount:%s\" % (email,)\n\n    @staticmethod\n    def group(email):\n        \"\"\"Factory method for a group member.\n\n        Args:\n            email (str): An id or e-mail for this particular group.\n\n        Returns:\n            str: A member string corresponding to the given group.\n        \"\"\"\n        return \"group:%s\" % (email,)\n\n    @staticmethod\n    def domain(domain):\n        \"\"\"Factory method for a domain member.\n\n        Args:\n            domain (str): The domain for this member.\n\n        Returns:\n            str: A member string corresponding to the given domain.\n        \"\"\"\n        return \"domain:%s\" % (domain,)\n\n    @staticmethod\n    def all_users():\n        \"\"\"Factory method for a member representing all users.\n\n        Returns:\n            str: A member string representing all users.\n        \"\"\"\n        return \"allUsers\"\n\n    @staticmethod\n    def authenticated_users():\n        \"\"\"Factory method for a member representing all authenticated users.\n\n        Returns:\n            str: A member string representing all authenticated users.\n        \"\"\"\n        return \"allAuthenticatedUsers\"\n\n    @classmethod\n    def from_api_repr(cls, resource):\n        \"\"\"Factory: create a policy from a JSON resource.\n\n        Args:\n            resource (dict): policy resource returned by ``getIamPolicy`` API.\n\n        Returns:\n            :class:`Policy`: the parsed policy\n        \"\"\"\n        version = resource.get(\"version\")\n        etag = resource.get(\"etag\")\n        policy = cls(etag, version)\n        policy.bindings = resource.get(\"bindings\", [])\n\n        for binding in policy.bindings:\n            binding[\"members\"] = set(binding.get(\"members\", ()))\n\n        return policy\n\n    def to_api_repr(self):\n        \"\"\"Render a JSON policy resource.\n\n        Returns:\n            dict: a resource to be passed to the ``setIamPolicy`` API.\n        \"\"\"\n        resource = {}\n\n        if self.etag is not None:\n            resource[\"etag\"] = self.etag\n\n        if self.version is not None:\n            resource[\"version\"] = self.version\n\n        if self._bindings and len(self._bindings) > 0:\n            bindings = []\n            for binding in self._bindings:\n                members = binding.get(\"members\")\n                if members:\n                    new_binding = {\"role\": binding[\"role\"], \"members\": sorted(members)}\n                    condition = binding.get(\"condition\")\n                    if condition:\n                        new_binding[\"condition\"] = condition\n                    bindings.append(new_binding)\n\n            if bindings:\n                # Sort bindings by role\n                key = operator.itemgetter(\"role\")\n                resource[\"bindings\"] = sorted(bindings, key=key)\n\n        return resource\n", "google/api_core/protobuf_helpers.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Helpers for :mod:`protobuf`.\"\"\"\n\nimport collections\nimport collections.abc\nimport copy\nimport inspect\n\nfrom google.protobuf import field_mask_pb2\nfrom google.protobuf import message\nfrom google.protobuf import wrappers_pb2\n\n\n_SENTINEL = object()\n_WRAPPER_TYPES = (\n    wrappers_pb2.BoolValue,\n    wrappers_pb2.BytesValue,\n    wrappers_pb2.DoubleValue,\n    wrappers_pb2.FloatValue,\n    wrappers_pb2.Int32Value,\n    wrappers_pb2.Int64Value,\n    wrappers_pb2.StringValue,\n    wrappers_pb2.UInt32Value,\n    wrappers_pb2.UInt64Value,\n)\n\n\ndef from_any_pb(pb_type, any_pb):\n    \"\"\"Converts an ``Any`` protobuf to the specified message type.\n\n    Args:\n        pb_type (type): the type of the message that any_pb stores an instance\n            of.\n        any_pb (google.protobuf.any_pb2.Any): the object to be converted.\n\n    Returns:\n        pb_type: An instance of the pb_type message.\n\n    Raises:\n        TypeError: if the message could not be converted.\n    \"\"\"\n    msg = pb_type()\n\n    # Unwrap proto-plus wrapped messages.\n    if callable(getattr(pb_type, \"pb\", None)):\n        msg_pb = pb_type.pb(msg)\n    else:\n        msg_pb = msg\n\n    # Unpack the Any object and populate the protobuf message instance.\n    if not any_pb.Unpack(msg_pb):\n        raise TypeError(\n            \"Could not convert {} to {}\".format(\n                any_pb.__class__.__name__, pb_type.__name__\n            )\n        )\n\n    # Done; return the message.\n    return msg\n\n\ndef check_oneof(**kwargs):\n    \"\"\"Raise ValueError if more than one keyword argument is not ``None``.\n\n    Args:\n        kwargs (dict): The keyword arguments sent to the function.\n\n    Raises:\n        ValueError: If more than one entry in ``kwargs`` is not ``None``.\n    \"\"\"\n    # Sanity check: If no keyword arguments were sent, this is fine.\n    if not kwargs:\n        return\n\n    not_nones = [val for val in kwargs.values() if val is not None]\n    if len(not_nones) > 1:\n        raise ValueError(\n            \"Only one of {fields} should be set.\".format(\n                fields=\", \".join(sorted(kwargs.keys()))\n            )\n        )\n\n\ndef get_messages(module):\n    \"\"\"Discovers all protobuf Message classes in a given import module.\n\n    Args:\n        module (module): A Python module; :func:`dir` will be run against this\n            module to find Message subclasses.\n\n    Returns:\n        dict[str, google.protobuf.message.Message]: A dictionary with the\n            Message class names as keys, and the Message subclasses themselves\n            as values.\n    \"\"\"\n    answer = collections.OrderedDict()\n    for name in dir(module):\n        candidate = getattr(module, name)\n        if inspect.isclass(candidate) and issubclass(candidate, message.Message):\n            answer[name] = candidate\n    return answer\n\n\ndef _resolve_subkeys(key, separator=\".\"):\n    \"\"\"Resolve a potentially nested key.\n\n    If the key contains the ``separator`` (e.g. ``.``) then the key will be\n    split on the first instance of the subkey::\n\n       >>> _resolve_subkeys('a.b.c')\n       ('a', 'b.c')\n       >>> _resolve_subkeys('d|e|f', separator='|')\n       ('d', 'e|f')\n\n    If not, the subkey will be :data:`None`::\n\n        >>> _resolve_subkeys('foo')\n        ('foo', None)\n\n    Args:\n        key (str): A string that may or may not contain the separator.\n        separator (str): The namespace separator. Defaults to `.`.\n\n    Returns:\n        Tuple[str, str]: The key and subkey(s).\n    \"\"\"\n    parts = key.split(separator, 1)\n\n    if len(parts) > 1:\n        return parts\n    else:\n        return parts[0], None\n\n\ndef get(msg_or_dict, key, default=_SENTINEL):\n    \"\"\"Retrieve a key's value from a protobuf Message or dictionary.\n\n    Args:\n        mdg_or_dict (Union[~google.protobuf.message.Message, Mapping]): the\n            object.\n        key (str): The key to retrieve from the object.\n        default (Any): If the key is not present on the object, and a default\n            is set, returns that default instead. A type-appropriate falsy\n            default is generally recommended, as protobuf messages almost\n            always have default values for unset values and it is not always\n            possible to tell the difference between a falsy value and an\n            unset one. If no default is set then :class:`KeyError` will be\n            raised if the key is not present in the object.\n\n    Returns:\n        Any: The return value from the underlying Message or dict.\n\n    Raises:\n        KeyError: If the key is not found. Note that, for unset values,\n            messages and dictionaries may not have consistent behavior.\n        TypeError: If ``msg_or_dict`` is not a Message or Mapping.\n    \"\"\"\n    # We may need to get a nested key. Resolve this.\n    key, subkey = _resolve_subkeys(key)\n\n    # Attempt to get the value from the two types of objects we know about.\n    # If we get something else, complain.\n    if isinstance(msg_or_dict, message.Message):\n        answer = getattr(msg_or_dict, key, default)\n    elif isinstance(msg_or_dict, collections.abc.Mapping):\n        answer = msg_or_dict.get(key, default)\n    else:\n        raise TypeError(\n            \"get() expected a dict or protobuf message, got {!r}.\".format(\n                type(msg_or_dict)\n            )\n        )\n\n    # If the object we got back is our sentinel, raise KeyError; this is\n    # a \"not found\" case.\n    if answer is _SENTINEL:\n        raise KeyError(key)\n\n    # If a subkey exists, call this method recursively against the answer.\n    if subkey is not None and answer is not default:\n        return get(answer, subkey, default=default)\n\n    return answer\n\n\ndef _set_field_on_message(msg, key, value):\n    \"\"\"Set helper for protobuf Messages.\"\"\"\n    # Attempt to set the value on the types of objects we know how to deal\n    # with.\n    if isinstance(value, (collections.abc.MutableSequence, tuple)):\n        # Clear the existing repeated protobuf message of any elements\n        # currently inside it.\n        while getattr(msg, key):\n            getattr(msg, key).pop()\n\n        # Write our new elements to the repeated field.\n        for item in value:\n            if isinstance(item, collections.abc.Mapping):\n                getattr(msg, key).add(**item)\n            else:\n                # protobuf's RepeatedCompositeContainer doesn't support\n                # append.\n                getattr(msg, key).extend([item])\n    elif isinstance(value, collections.abc.Mapping):\n        # Assign the dictionary values to the protobuf message.\n        for item_key, item_value in value.items():\n            set(getattr(msg, key), item_key, item_value)\n    elif isinstance(value, message.Message):\n        getattr(msg, key).CopyFrom(value)\n    else:\n        setattr(msg, key, value)\n\n\ndef set(msg_or_dict, key, value):\n    \"\"\"Set a key's value on a protobuf Message or dictionary.\n\n    Args:\n        msg_or_dict (Union[~google.protobuf.message.Message, Mapping]): the\n            object.\n        key (str): The key to set.\n        value (Any): The value to set.\n\n    Raises:\n        TypeError: If ``msg_or_dict`` is not a Message or dictionary.\n    \"\"\"\n    # Sanity check: Is our target object valid?\n    if not isinstance(msg_or_dict, (collections.abc.MutableMapping, message.Message)):\n        raise TypeError(\n            \"set() expected a dict or protobuf message, got {!r}.\".format(\n                type(msg_or_dict)\n            )\n        )\n\n    # We may be setting a nested key. Resolve this.\n    basekey, subkey = _resolve_subkeys(key)\n\n    # If a subkey exists, then get that object and call this method\n    # recursively against it using the subkey.\n    if subkey is not None:\n        if isinstance(msg_or_dict, collections.abc.MutableMapping):\n            msg_or_dict.setdefault(basekey, {})\n        set(get(msg_or_dict, basekey), subkey, value)\n        return\n\n    if isinstance(msg_or_dict, collections.abc.MutableMapping):\n        msg_or_dict[key] = value\n    else:\n        _set_field_on_message(msg_or_dict, key, value)\n\n\ndef setdefault(msg_or_dict, key, value):\n    \"\"\"Set the key on a protobuf Message or dictionary to a given value if the\n    current value is falsy.\n\n    Because protobuf Messages do not distinguish between unset values and\n    falsy ones particularly well (by design), this method treats any falsy\n    value (e.g. 0, empty list) as a target to be overwritten, on both Messages\n    and dictionaries.\n\n    Args:\n        msg_or_dict (Union[~google.protobuf.message.Message, Mapping]): the\n            object.\n        key (str): The key on the object in question.\n        value (Any): The value to set.\n\n    Raises:\n        TypeError: If ``msg_or_dict`` is not a Message or dictionary.\n    \"\"\"\n    if not get(msg_or_dict, key, default=None):\n        set(msg_or_dict, key, value)\n\n\ndef field_mask(original, modified):\n    \"\"\"Create a field mask by comparing two messages.\n\n    Args:\n        original (~google.protobuf.message.Message): the original message.\n            If set to None, this field will be interpreted as an empty\n            message.\n        modified (~google.protobuf.message.Message): the modified message.\n            If set to None, this field will be interpreted as an empty\n            message.\n\n    Returns:\n        google.protobuf.field_mask_pb2.FieldMask: field mask that contains\n        the list of field names that have different values between the two\n        messages. If the messages are equivalent, then the field mask is empty.\n\n    Raises:\n        ValueError: If the ``original`` or ``modified`` are not the same type.\n    \"\"\"\n    if original is None and modified is None:\n        return field_mask_pb2.FieldMask()\n\n    if original is None and modified is not None:\n        original = copy.deepcopy(modified)\n        original.Clear()\n\n    if modified is None and original is not None:\n        modified = copy.deepcopy(original)\n        modified.Clear()\n\n    if not isinstance(original, type(modified)):\n        raise ValueError(\n            \"expected that both original and modified should be of the \"\n            'same type, received \"{!r}\" and \"{!r}\".'.format(\n                type(original), type(modified)\n            )\n        )\n\n    return field_mask_pb2.FieldMask(paths=_field_mask_helper(original, modified))\n\n\ndef _field_mask_helper(original, modified, current=\"\"):\n    answer = []\n\n    for name in original.DESCRIPTOR.fields_by_name:\n        field_path = _get_path(current, name)\n\n        original_val = getattr(original, name)\n        modified_val = getattr(modified, name)\n\n        if _is_message(original_val) or _is_message(modified_val):\n            if original_val != modified_val:\n                # Wrapper types do not need to include the .value part of the\n                # path.\n                if _is_wrapper(original_val) or _is_wrapper(modified_val):\n                    answer.append(field_path)\n                elif not modified_val.ListFields():\n                    answer.append(field_path)\n                else:\n                    answer.extend(\n                        _field_mask_helper(original_val, modified_val, field_path)\n                    )\n        else:\n            if original_val != modified_val:\n                answer.append(field_path)\n\n    return answer\n\n\ndef _get_path(current, name):\n    # gapic-generator-python appends underscores to field names\n    # that collide with python keywords.\n    # `_` is stripped away as it is not possible to\n    # natively define a field with a trailing underscore in protobuf.\n    # APIs will reject field masks if fields have trailing underscores.\n    # See https://github.com/googleapis/python-api-core/issues/227\n    name = name.rstrip(\"_\")\n    if not current:\n        return name\n    return \"%s.%s\" % (current, name)\n\n\ndef _is_message(value):\n    return isinstance(value, message.Message)\n\n\ndef _is_wrapper(value):\n    return type(value) in _WRAPPER_TYPES\n", "google/api_core/exceptions.py": "# Copyright 2014 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Exceptions raised by Google API core & clients.\n\nThis module provides base classes for all errors raised by libraries based\non :mod:`google.api_core`, including both HTTP and gRPC clients.\n\"\"\"\n\nfrom __future__ import absolute_import\nfrom __future__ import unicode_literals\n\nimport http.client\nfrom typing import Dict\nfrom typing import Union\nimport warnings\n\nfrom google.rpc import error_details_pb2\n\ntry:\n    import grpc\n\n    try:\n        from grpc_status import rpc_status\n    except ImportError:  # pragma: NO COVER\n        warnings.warn(\n            \"Please install grpcio-status to obtain helpful grpc error messages.\",\n            ImportWarning,\n        )\n        rpc_status = None\nexcept ImportError:  # pragma: NO COVER\n    grpc = None\n\n# Lookup tables for mapping exceptions from HTTP and gRPC transports.\n# Populated by _GoogleAPICallErrorMeta\n_HTTP_CODE_TO_EXCEPTION: Dict[int, Exception] = {}\n_GRPC_CODE_TO_EXCEPTION: Dict[int, Exception] = {}\n\n# Additional lookup table to map integer status codes to grpc status code\n# grpc does not currently support initializing enums from ints\n# i.e., grpc.StatusCode(5) raises an error\n_INT_TO_GRPC_CODE = {}\nif grpc is not None:  # pragma: no branch\n    for x in grpc.StatusCode:\n        _INT_TO_GRPC_CODE[x.value[0]] = x\n\n\nclass GoogleAPIError(Exception):\n    \"\"\"Base class for all exceptions raised by Google API Clients.\"\"\"\n\n    pass\n\n\nclass DuplicateCredentialArgs(GoogleAPIError):\n    \"\"\"Raised when multiple credentials are passed.\"\"\"\n\n    pass\n\n\nclass RetryError(GoogleAPIError):\n    \"\"\"Raised when a function has exhausted all of its available retries.\n\n    Args:\n        message (str): The exception message.\n        cause (Exception): The last exception raised when retrying the\n            function.\n    \"\"\"\n\n    def __init__(self, message, cause):\n        super(RetryError, self).__init__(message)\n        self.message = message\n        self._cause = cause\n\n    @property\n    def cause(self):\n        \"\"\"The last exception raised when retrying the function.\"\"\"\n        return self._cause\n\n    def __str__(self):\n        return \"{}, last exception: {}\".format(self.message, self.cause)\n\n\nclass _GoogleAPICallErrorMeta(type):\n    \"\"\"Metaclass for registering GoogleAPICallError subclasses.\"\"\"\n\n    def __new__(mcs, name, bases, class_dict):\n        cls = type.__new__(mcs, name, bases, class_dict)\n        if cls.code is not None:\n            _HTTP_CODE_TO_EXCEPTION.setdefault(cls.code, cls)\n        if cls.grpc_status_code is not None:\n            _GRPC_CODE_TO_EXCEPTION.setdefault(cls.grpc_status_code, cls)\n        return cls\n\n\nclass GoogleAPICallError(GoogleAPIError, metaclass=_GoogleAPICallErrorMeta):\n    \"\"\"Base class for exceptions raised by calling API methods.\n\n    Args:\n        message (str): The exception message.\n        errors (Sequence[Any]): An optional list of error details.\n        details (Sequence[Any]): An optional list of objects defined in google.rpc.error_details.\n        response (Union[requests.Request, grpc.Call]): The response or\n            gRPC call metadata.\n        error_info (Union[error_details_pb2.ErrorInfo, None]): An optional object containing error info\n            (google.rpc.error_details.ErrorInfo).\n    \"\"\"\n\n    code: Union[int, None] = None\n    \"\"\"Optional[int]: The HTTP status code associated with this error.\n\n    This may be ``None`` if the exception does not have a direct mapping\n    to an HTTP error.\n\n    See http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html\n    \"\"\"\n\n    grpc_status_code = None\n    \"\"\"Optional[grpc.StatusCode]: The gRPC status code associated with this\n    error.\n\n    This may be ``None`` if the exception does not match up to a gRPC error.\n    \"\"\"\n\n    def __init__(self, message, errors=(), details=(), response=None, error_info=None):\n        super(GoogleAPICallError, self).__init__(message)\n        self.message = message\n        \"\"\"str: The exception message.\"\"\"\n        self._errors = errors\n        self._details = details\n        self._response = response\n        self._error_info = error_info\n\n    def __str__(self):\n        error_msg = \"{} {}\".format(self.code, self.message)\n        if self.details:\n            error_msg = \"{} {}\".format(error_msg, self.details)\n        # Note: This else condition can be removed once proposal A from\n        # b/284179390 is implemented.\n        else:\n            if self.errors:\n                errors = [\n                    f\"{error.code}: {error.message}\"\n                    for error in self.errors\n                    if hasattr(error, \"code\") and hasattr(error, \"message\")\n                ]\n                if errors:\n                    error_msg = \"{} {}\".format(error_msg, \"\\n\".join(errors))\n        return error_msg\n\n    @property\n    def reason(self):\n        \"\"\"The reason of the error.\n\n        Reference:\n            https://github.com/googleapis/googleapis/blob/master/google/rpc/error_details.proto#L112\n\n        Returns:\n            Union[str, None]: An optional string containing reason of the error.\n        \"\"\"\n        return self._error_info.reason if self._error_info else None\n\n    @property\n    def domain(self):\n        \"\"\"The logical grouping to which the \"reason\" belongs.\n\n        Reference:\n            https://github.com/googleapis/googleapis/blob/master/google/rpc/error_details.proto#L112\n\n        Returns:\n            Union[str, None]: An optional string containing a logical grouping to which the \"reason\" belongs.\n        \"\"\"\n        return self._error_info.domain if self._error_info else None\n\n    @property\n    def metadata(self):\n        \"\"\"Additional structured details about this error.\n\n        Reference:\n            https://github.com/googleapis/googleapis/blob/master/google/rpc/error_details.proto#L112\n\n        Returns:\n            Union[Dict[str, str], None]: An optional object containing structured details about the error.\n        \"\"\"\n        return self._error_info.metadata if self._error_info else None\n\n    @property\n    def errors(self):\n        \"\"\"Detailed error information.\n\n        Returns:\n            Sequence[Any]: A list of additional error details.\n        \"\"\"\n        return list(self._errors)\n\n    @property\n    def details(self):\n        \"\"\"Information contained in google.rpc.status.details.\n\n        Reference:\n            https://github.com/googleapis/googleapis/blob/master/google/rpc/status.proto\n            https://github.com/googleapis/googleapis/blob/master/google/rpc/error_details.proto\n\n        Returns:\n            Sequence[Any]: A list of structured objects from error_details.proto\n        \"\"\"\n        return list(self._details)\n\n    @property\n    def response(self):\n        \"\"\"Optional[Union[requests.Request, grpc.Call]]: The response or\n        gRPC call metadata.\"\"\"\n        return self._response\n\n\nclass Redirection(GoogleAPICallError):\n    \"\"\"Base class for for all redirection (HTTP 3xx) responses.\"\"\"\n\n\nclass MovedPermanently(Redirection):\n    \"\"\"Exception mapping a ``301 Moved Permanently`` response.\"\"\"\n\n    code = http.client.MOVED_PERMANENTLY\n\n\nclass NotModified(Redirection):\n    \"\"\"Exception mapping a ``304 Not Modified`` response.\"\"\"\n\n    code = http.client.NOT_MODIFIED\n\n\nclass TemporaryRedirect(Redirection):\n    \"\"\"Exception mapping a ``307 Temporary Redirect`` response.\"\"\"\n\n    code = http.client.TEMPORARY_REDIRECT\n\n\nclass ResumeIncomplete(Redirection):\n    \"\"\"Exception mapping a ``308 Resume Incomplete`` response.\n\n    .. note:: :attr:`http.client.PERMANENT_REDIRECT` is ``308``, but Google\n        APIs differ in their use of this status code.\n    \"\"\"\n\n    code = 308\n\n\nclass ClientError(GoogleAPICallError):\n    \"\"\"Base class for all client error (HTTP 4xx) responses.\"\"\"\n\n\nclass BadRequest(ClientError):\n    \"\"\"Exception mapping a ``400 Bad Request`` response.\"\"\"\n\n    code = http.client.BAD_REQUEST\n\n\nclass InvalidArgument(BadRequest):\n    \"\"\"Exception mapping a :attr:`grpc.StatusCode.INVALID_ARGUMENT` error.\"\"\"\n\n    grpc_status_code = grpc.StatusCode.INVALID_ARGUMENT if grpc is not None else None\n\n\nclass FailedPrecondition(BadRequest):\n    \"\"\"Exception mapping a :attr:`grpc.StatusCode.FAILED_PRECONDITION`\n    error.\"\"\"\n\n    grpc_status_code = grpc.StatusCode.FAILED_PRECONDITION if grpc is not None else None\n\n\nclass OutOfRange(BadRequest):\n    \"\"\"Exception mapping a :attr:`grpc.StatusCode.OUT_OF_RANGE` error.\"\"\"\n\n    grpc_status_code = grpc.StatusCode.OUT_OF_RANGE if grpc is not None else None\n\n\nclass Unauthorized(ClientError):\n    \"\"\"Exception mapping a ``401 Unauthorized`` response.\"\"\"\n\n    code = http.client.UNAUTHORIZED\n\n\nclass Unauthenticated(Unauthorized):\n    \"\"\"Exception mapping a :attr:`grpc.StatusCode.UNAUTHENTICATED` error.\"\"\"\n\n    grpc_status_code = grpc.StatusCode.UNAUTHENTICATED if grpc is not None else None\n\n\nclass Forbidden(ClientError):\n    \"\"\"Exception mapping a ``403 Forbidden`` response.\"\"\"\n\n    code = http.client.FORBIDDEN\n\n\nclass PermissionDenied(Forbidden):\n    \"\"\"Exception mapping a :attr:`grpc.StatusCode.PERMISSION_DENIED` error.\"\"\"\n\n    grpc_status_code = grpc.StatusCode.PERMISSION_DENIED if grpc is not None else None\n\n\nclass NotFound(ClientError):\n    \"\"\"Exception mapping a ``404 Not Found`` response or a\n    :attr:`grpc.StatusCode.NOT_FOUND` error.\"\"\"\n\n    code = http.client.NOT_FOUND\n    grpc_status_code = grpc.StatusCode.NOT_FOUND if grpc is not None else None\n\n\nclass MethodNotAllowed(ClientError):\n    \"\"\"Exception mapping a ``405 Method Not Allowed`` response.\"\"\"\n\n    code = http.client.METHOD_NOT_ALLOWED\n\n\nclass Conflict(ClientError):\n    \"\"\"Exception mapping a ``409 Conflict`` response.\"\"\"\n\n    code = http.client.CONFLICT\n\n\nclass AlreadyExists(Conflict):\n    \"\"\"Exception mapping a :attr:`grpc.StatusCode.ALREADY_EXISTS` error.\"\"\"\n\n    grpc_status_code = grpc.StatusCode.ALREADY_EXISTS if grpc is not None else None\n\n\nclass Aborted(Conflict):\n    \"\"\"Exception mapping a :attr:`grpc.StatusCode.ABORTED` error.\"\"\"\n\n    grpc_status_code = grpc.StatusCode.ABORTED if grpc is not None else None\n\n\nclass LengthRequired(ClientError):\n    \"\"\"Exception mapping a ``411 Length Required`` response.\"\"\"\n\n    code = http.client.LENGTH_REQUIRED\n\n\nclass PreconditionFailed(ClientError):\n    \"\"\"Exception mapping a ``412 Precondition Failed`` response.\"\"\"\n\n    code = http.client.PRECONDITION_FAILED\n\n\nclass RequestRangeNotSatisfiable(ClientError):\n    \"\"\"Exception mapping a ``416 Request Range Not Satisfiable`` response.\"\"\"\n\n    code = http.client.REQUESTED_RANGE_NOT_SATISFIABLE\n\n\nclass TooManyRequests(ClientError):\n    \"\"\"Exception mapping a ``429 Too Many Requests`` response.\"\"\"\n\n    code = http.client.TOO_MANY_REQUESTS\n\n\nclass ResourceExhausted(TooManyRequests):\n    \"\"\"Exception mapping a :attr:`grpc.StatusCode.RESOURCE_EXHAUSTED` error.\"\"\"\n\n    grpc_status_code = grpc.StatusCode.RESOURCE_EXHAUSTED if grpc is not None else None\n\n\nclass Cancelled(ClientError):\n    \"\"\"Exception mapping a :attr:`grpc.StatusCode.CANCELLED` error.\"\"\"\n\n    # This maps to HTTP status code 499. See\n    # https://github.com/googleapis/googleapis/blob/master/google/rpc/code.proto\n    code = 499\n    grpc_status_code = grpc.StatusCode.CANCELLED if grpc is not None else None\n\n\nclass ServerError(GoogleAPICallError):\n    \"\"\"Base for 5xx responses.\"\"\"\n\n\nclass InternalServerError(ServerError):\n    \"\"\"Exception mapping a ``500 Internal Server Error`` response. or a\n    :attr:`grpc.StatusCode.INTERNAL` error.\"\"\"\n\n    code = http.client.INTERNAL_SERVER_ERROR\n    grpc_status_code = grpc.StatusCode.INTERNAL if grpc is not None else None\n\n\nclass Unknown(ServerError):\n    \"\"\"Exception mapping a :attr:`grpc.StatusCode.UNKNOWN` error.\"\"\"\n\n    grpc_status_code = grpc.StatusCode.UNKNOWN if grpc is not None else None\n\n\nclass DataLoss(ServerError):\n    \"\"\"Exception mapping a :attr:`grpc.StatusCode.DATA_LOSS` error.\"\"\"\n\n    grpc_status_code = grpc.StatusCode.DATA_LOSS if grpc is not None else None\n\n\nclass MethodNotImplemented(ServerError):\n    \"\"\"Exception mapping a ``501 Not Implemented`` response or a\n    :attr:`grpc.StatusCode.UNIMPLEMENTED` error.\"\"\"\n\n    code = http.client.NOT_IMPLEMENTED\n    grpc_status_code = grpc.StatusCode.UNIMPLEMENTED if grpc is not None else None\n\n\nclass BadGateway(ServerError):\n    \"\"\"Exception mapping a ``502 Bad Gateway`` response.\"\"\"\n\n    code = http.client.BAD_GATEWAY\n\n\nclass ServiceUnavailable(ServerError):\n    \"\"\"Exception mapping a ``503 Service Unavailable`` response or a\n    :attr:`grpc.StatusCode.UNAVAILABLE` error.\"\"\"\n\n    code = http.client.SERVICE_UNAVAILABLE\n    grpc_status_code = grpc.StatusCode.UNAVAILABLE if grpc is not None else None\n\n\nclass GatewayTimeout(ServerError):\n    \"\"\"Exception mapping a ``504 Gateway Timeout`` response.\"\"\"\n\n    code = http.client.GATEWAY_TIMEOUT\n\n\nclass DeadlineExceeded(GatewayTimeout):\n    \"\"\"Exception mapping a :attr:`grpc.StatusCode.DEADLINE_EXCEEDED` error.\"\"\"\n\n    grpc_status_code = grpc.StatusCode.DEADLINE_EXCEEDED if grpc is not None else None\n\n\ndef exception_class_for_http_status(status_code):\n    \"\"\"Return the exception class for a specific HTTP status code.\n\n    Args:\n        status_code (int): The HTTP status code.\n\n    Returns:\n        :func:`type`: the appropriate subclass of :class:`GoogleAPICallError`.\n    \"\"\"\n    return _HTTP_CODE_TO_EXCEPTION.get(status_code, GoogleAPICallError)\n\n\ndef from_http_status(status_code, message, **kwargs):\n    \"\"\"Create a :class:`GoogleAPICallError` from an HTTP status code.\n\n    Args:\n        status_code (int): The HTTP status code.\n        message (str): The exception message.\n        kwargs: Additional arguments passed to the :class:`GoogleAPICallError`\n            constructor.\n\n    Returns:\n        GoogleAPICallError: An instance of the appropriate subclass of\n            :class:`GoogleAPICallError`.\n    \"\"\"\n    error_class = exception_class_for_http_status(status_code)\n    error = error_class(message, **kwargs)\n\n    if error.code is None:\n        error.code = status_code\n\n    return error\n\n\ndef from_http_response(response):\n    \"\"\"Create a :class:`GoogleAPICallError` from a :class:`requests.Response`.\n\n    Args:\n        response (requests.Response): The HTTP response.\n\n    Returns:\n        GoogleAPICallError: An instance of the appropriate subclass of\n            :class:`GoogleAPICallError`, with the message and errors populated\n            from the response.\n    \"\"\"\n    try:\n        payload = response.json()\n    except ValueError:\n        payload = {\"error\": {\"message\": response.text or \"unknown error\"}}\n\n    error_message = payload.get(\"error\", {}).get(\"message\", \"unknown error\")\n    errors = payload.get(\"error\", {}).get(\"errors\", ())\n    # In JSON, details are already formatted in developer-friendly way.\n    details = payload.get(\"error\", {}).get(\"details\", ())\n    error_info = list(\n        filter(\n            lambda detail: detail.get(\"@type\", \"\")\n            == \"type.googleapis.com/google.rpc.ErrorInfo\",\n            details,\n        )\n    )\n    error_info = error_info[0] if error_info else None\n\n    message = \"{method} {url}: {error}\".format(\n        method=response.request.method,\n        url=response.request.url,\n        error=error_message,\n    )\n\n    exception = from_http_status(\n        response.status_code,\n        message,\n        errors=errors,\n        details=details,\n        response=response,\n        error_info=error_info,\n    )\n    return exception\n\n\ndef exception_class_for_grpc_status(status_code):\n    \"\"\"Return the exception class for a specific :class:`grpc.StatusCode`.\n\n    Args:\n        status_code (grpc.StatusCode): The gRPC status code.\n\n    Returns:\n        :func:`type`: the appropriate subclass of :class:`GoogleAPICallError`.\n    \"\"\"\n    return _GRPC_CODE_TO_EXCEPTION.get(status_code, GoogleAPICallError)\n\n\ndef from_grpc_status(status_code, message, **kwargs):\n    \"\"\"Create a :class:`GoogleAPICallError` from a :class:`grpc.StatusCode`.\n\n    Args:\n        status_code (Union[grpc.StatusCode, int]): The gRPC status code.\n        message (str): The exception message.\n        kwargs: Additional arguments passed to the :class:`GoogleAPICallError`\n            constructor.\n\n    Returns:\n        GoogleAPICallError: An instance of the appropriate subclass of\n            :class:`GoogleAPICallError`.\n    \"\"\"\n\n    if isinstance(status_code, int):\n        status_code = _INT_TO_GRPC_CODE.get(status_code, status_code)\n\n    error_class = exception_class_for_grpc_status(status_code)\n    error = error_class(message, **kwargs)\n\n    if error.grpc_status_code is None:\n        error.grpc_status_code = status_code\n\n    return error\n\n\ndef _is_informative_grpc_error(rpc_exc):\n    return hasattr(rpc_exc, \"code\") and hasattr(rpc_exc, \"details\")\n\n\ndef _parse_grpc_error_details(rpc_exc):\n    try:\n        status = rpc_status.from_call(rpc_exc)\n    except NotImplementedError:  # workaround\n        return [], None\n\n    if not status:\n        return [], None\n\n    possible_errors = [\n        error_details_pb2.BadRequest,\n        error_details_pb2.PreconditionFailure,\n        error_details_pb2.QuotaFailure,\n        error_details_pb2.ErrorInfo,\n        error_details_pb2.RetryInfo,\n        error_details_pb2.ResourceInfo,\n        error_details_pb2.RequestInfo,\n        error_details_pb2.DebugInfo,\n        error_details_pb2.Help,\n        error_details_pb2.LocalizedMessage,\n    ]\n    error_info = None\n    error_details = []\n    for detail in status.details:\n        matched_detail_cls = list(\n            filter(lambda x: detail.Is(x.DESCRIPTOR), possible_errors)\n        )\n        # If nothing matched, use detail directly.\n        if len(matched_detail_cls) == 0:\n            info = detail\n        else:\n            info = matched_detail_cls[0]()\n            detail.Unpack(info)\n        error_details.append(info)\n        if isinstance(info, error_details_pb2.ErrorInfo):\n            error_info = info\n    return error_details, error_info\n\n\ndef from_grpc_error(rpc_exc):\n    \"\"\"Create a :class:`GoogleAPICallError` from a :class:`grpc.RpcError`.\n\n    Args:\n        rpc_exc (grpc.RpcError): The gRPC error.\n\n    Returns:\n        GoogleAPICallError: An instance of the appropriate subclass of\n            :class:`GoogleAPICallError`.\n    \"\"\"\n    # NOTE(lidiz) All gRPC error shares the parent class grpc.RpcError.\n    # However, check for grpc.RpcError breaks backward compatibility.\n    if (\n        grpc is not None and isinstance(rpc_exc, grpc.Call)\n    ) or _is_informative_grpc_error(rpc_exc):\n        details, err_info = _parse_grpc_error_details(rpc_exc)\n        return from_grpc_status(\n            rpc_exc.code(),\n            rpc_exc.details(),\n            errors=(rpc_exc,),\n            details=details,\n            response=rpc_exc,\n            error_info=err_info,\n        )\n    else:\n        return GoogleAPICallError(str(rpc_exc), errors=(rpc_exc,), response=rpc_exc)\n", "google/api_core/universe.py": "# Copyright 2024 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Helpers for universe domain.\"\"\"\n\nfrom typing import Any, Optional\n\nDEFAULT_UNIVERSE = \"googleapis.com\"\n\n\nclass EmptyUniverseError(ValueError):\n    def __init__(self):\n        message = \"Universe Domain cannot be an empty string.\"\n        super().__init__(message)\n\n\nclass UniverseMismatchError(ValueError):\n    def __init__(self, client_universe, credentials_universe):\n        message = (\n            f\"The configured universe domain ({client_universe}) does not match the universe domain \"\n            f\"found in the credentials ({credentials_universe}). \"\n            \"If you haven't configured the universe domain explicitly, \"\n            f\"`{DEFAULT_UNIVERSE}` is the default.\"\n        )\n        super().__init__(message)\n\n\ndef determine_domain(\n    client_universe_domain: Optional[str], universe_domain_env: Optional[str]\n) -> str:\n    \"\"\"Return the universe domain used by the client.\n\n    Args:\n        client_universe_domain (Optional[str]): The universe domain configured via the client options.\n        universe_domain_env (Optional[str]): The universe domain configured via the\n        \"GOOGLE_CLOUD_UNIVERSE_DOMAIN\" environment variable.\n\n    Returns:\n        str: The universe domain to be used by the client.\n\n    Raises:\n        ValueError: If the universe domain is an empty string.\n    \"\"\"\n    universe_domain = DEFAULT_UNIVERSE\n    if client_universe_domain is not None:\n        universe_domain = client_universe_domain\n    elif universe_domain_env is not None:\n        universe_domain = universe_domain_env\n    if len(universe_domain.strip()) == 0:\n        raise EmptyUniverseError\n    return universe_domain\n\n\ndef compare_domains(client_universe: str, credentials: Any) -> bool:\n    \"\"\"Returns True iff the universe domains used by the client and credentials match.\n\n    Args:\n        client_universe (str): The universe domain configured via the client options.\n        credentials Any: The credentials being used in the client.\n\n    Returns:\n        bool: True iff client_universe matches the universe in credentials.\n\n    Raises:\n        ValueError: when client_universe does not match the universe in credentials.\n    \"\"\"\n    credentials_universe = getattr(credentials, \"universe_domain\", DEFAULT_UNIVERSE)\n\n    if client_universe != credentials_universe:\n        raise UniverseMismatchError(client_universe, credentials_universe)\n    return True\n", "google/api_core/page_iterator_async.py": "# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"AsyncIO iterators for paging through paged API methods.\n\nThese iterators simplify the process of paging through API responses\nwhere the request takes a page token and the response is a list of results with\na token for the next page. See `list pagination`_ in the Google API Style Guide\nfor more details.\n\n.. _list pagination:\n    https://cloud.google.com/apis/design/design_patterns#list_pagination\n\nAPI clients that have methods that follow the list pagination pattern can\nreturn an :class:`.AsyncIterator`:\n\n    >>> results_iterator = await client.list_resources()\n\nOr you can walk your way through items and call off the search early if\nyou find what you're looking for (resulting in possibly fewer requests)::\n\n    >>> async for resource in results_iterator:\n    ...     print(resource.name)\n    ...     if not resource.is_valid:\n    ...         break\n\nAt any point, you may check the number of items consumed by referencing the\n``num_results`` property of the iterator::\n\n    >>> async for my_item in results_iterator:\n    ...     if results_iterator.num_results >= 10:\n    ...         break\n\nWhen iterating, not every new item will send a request to the server.\nTo iterate based on each page of items (where a page corresponds to\na request)::\n\n    >>> async for page in results_iterator.pages:\n    ...     print('=' * 20)\n    ...     print('    Page number: {:d}'.format(iterator.page_number))\n    ...     print('  Items in page: {:d}'.format(page.num_items))\n    ...     print('     First item: {!r}'.format(next(page)))\n    ...     print('Items remaining: {:d}'.format(page.remaining))\n    ...     print('Next page token: {}'.format(iterator.next_page_token))\n    ====================\n        Page number: 1\n      Items in page: 1\n         First item: <MyItemClass at 0x7f1d3cccf690>\n    Items remaining: 0\n    Next page token: eav1OzQB0OM8rLdGXOEsyQWSG\n    ====================\n        Page number: 2\n      Items in page: 19\n         First item: <MyItemClass at 0x7f1d3cccffd0>\n    Items remaining: 18\n    Next page token: None\n\"\"\"\n\nimport abc\n\nfrom google.api_core.page_iterator import Page\n\n\ndef _item_to_value_identity(iterator, item):\n    \"\"\"An item to value transformer that returns the item un-changed.\"\"\"\n    # pylint: disable=unused-argument\n    # We are conforming to the interface defined by Iterator.\n    return item\n\n\nclass AsyncIterator(abc.ABC):\n    \"\"\"A generic class for iterating through API list responses.\n\n    Args:\n        client(google.cloud.client.Client): The API client.\n        item_to_value (Callable[google.api_core.page_iterator_async.AsyncIterator, Any]):\n            Callable to convert an item from the type in the raw API response\n            into the native object. Will be called with the iterator and a\n            single item.\n        page_token (str): A token identifying a page in a result set to start\n            fetching results from.\n        max_results (int): The maximum number of results to fetch.\n    \"\"\"\n\n    def __init__(\n        self,\n        client,\n        item_to_value=_item_to_value_identity,\n        page_token=None,\n        max_results=None,\n    ):\n        self._started = False\n        self.__active_aiterator = None\n\n        self.client = client\n        \"\"\"Optional[Any]: The client that created this iterator.\"\"\"\n        self.item_to_value = item_to_value\n        \"\"\"Callable[Iterator, Any]: Callable to convert an item from the type\n            in the raw API response into the native object. Will be called with\n            the iterator and a\n            single item.\n        \"\"\"\n        self.max_results = max_results\n        \"\"\"int: The maximum number of results to fetch.\"\"\"\n\n        # The attributes below will change over the life of the iterator.\n        self.page_number = 0\n        \"\"\"int: The current page of results.\"\"\"\n        self.next_page_token = page_token\n        \"\"\"str: The token for the next page of results. If this is set before\n            the iterator starts, it effectively offsets the iterator to a\n            specific starting point.\"\"\"\n        self.num_results = 0\n        \"\"\"int: The total number of results fetched so far.\"\"\"\n\n    @property\n    def pages(self):\n        \"\"\"Iterator of pages in the response.\n\n        returns:\n            types.GeneratorType[google.api_core.page_iterator.Page]: A\n                generator of page instances.\n\n        raises:\n            ValueError: If the iterator has already been started.\n        \"\"\"\n        if self._started:\n            raise ValueError(\"Iterator has already started\", self)\n        self._started = True\n        return self._page_aiter(increment=True)\n\n    async def _items_aiter(self):\n        \"\"\"Iterator for each item returned.\"\"\"\n        async for page in self._page_aiter(increment=False):\n            for item in page:\n                self.num_results += 1\n                yield item\n\n    def __aiter__(self):\n        \"\"\"Iterator for each item returned.\n\n        Returns:\n            types.GeneratorType[Any]: A generator of items from the API.\n\n        Raises:\n            ValueError: If the iterator has already been started.\n        \"\"\"\n        if self._started:\n            raise ValueError(\"Iterator has already started\", self)\n        self._started = True\n        return self._items_aiter()\n\n    async def __anext__(self):\n        if self.__active_aiterator is None:\n            self.__active_aiterator = self.__aiter__()\n        return await self.__active_aiterator.__anext__()\n\n    async def _page_aiter(self, increment):\n        \"\"\"Generator of pages of API responses.\n\n        Args:\n            increment (bool): Flag indicating if the total number of results\n                should be incremented on each page. This is useful since a page\n                iterator will want to increment by results per page while an\n                items iterator will want to increment per item.\n\n        Yields:\n            Page: each page of items from the API.\n        \"\"\"\n        page = await self._next_page()\n        while page is not None:\n            self.page_number += 1\n            if increment:\n                self.num_results += page.num_items\n            yield page\n            page = await self._next_page()\n\n    @abc.abstractmethod\n    async def _next_page(self):\n        \"\"\"Get the next page in the iterator.\n\n        This does nothing and is intended to be over-ridden by subclasses\n        to return the next :class:`Page`.\n\n        Raises:\n            NotImplementedError: Always, this method is abstract.\n        \"\"\"\n        raise NotImplementedError\n\n\nclass AsyncGRPCIterator(AsyncIterator):\n    \"\"\"A generic class for iterating through gRPC list responses.\n\n    .. note:: The class does not take a ``page_token`` argument because it can\n        just be specified in the ``request``.\n\n    Args:\n        client (google.cloud.client.Client): The API client. This unused by\n            this class, but kept to satisfy the :class:`Iterator` interface.\n        method (Callable[protobuf.Message]): A bound gRPC method that should\n            take a single message for the request.\n        request (protobuf.Message): The request message.\n        items_field (str): The field in the response message that has the\n            items for the page.\n        item_to_value (Callable[GRPCIterator, Any]): Callable to convert an\n            item from the type in the JSON response into a native object. Will\n            be called with the iterator and a single item.\n        request_token_field (str): The field in the request message used to\n            specify the page token.\n        response_token_field (str): The field in the response message that has\n            the token for the next page.\n        max_results (int): The maximum number of results to fetch.\n\n    .. autoattribute:: pages\n    \"\"\"\n\n    _DEFAULT_REQUEST_TOKEN_FIELD = \"page_token\"\n    _DEFAULT_RESPONSE_TOKEN_FIELD = \"next_page_token\"\n\n    def __init__(\n        self,\n        client,\n        method,\n        request,\n        items_field,\n        item_to_value=_item_to_value_identity,\n        request_token_field=_DEFAULT_REQUEST_TOKEN_FIELD,\n        response_token_field=_DEFAULT_RESPONSE_TOKEN_FIELD,\n        max_results=None,\n    ):\n        super().__init__(client, item_to_value, max_results=max_results)\n        self._method = method\n        self._request = request\n        self._items_field = items_field\n        self._request_token_field = request_token_field\n        self._response_token_field = response_token_field\n\n    async def _next_page(self):\n        \"\"\"Get the next page in the iterator.\n\n        Returns:\n            Page: The next page in the iterator or :data:`None` if\n                there are no pages left.\n        \"\"\"\n        if not self._has_next_page():\n            return None\n\n        if self.next_page_token is not None:\n            setattr(self._request, self._request_token_field, self.next_page_token)\n\n        response = await self._method(self._request)\n\n        self.next_page_token = getattr(response, self._response_token_field)\n        items = getattr(response, self._items_field)\n        page = Page(self, items, self.item_to_value, raw_page=response)\n\n        return page\n\n    def _has_next_page(self):\n        \"\"\"Determines whether or not there are more pages with results.\n\n        Returns:\n            bool: Whether the iterator has more pages.\n        \"\"\"\n        if self.page_number == 0:\n            return True\n\n        # Note: intentionally a falsy check instead of a None check. The RPC\n        # can return an empty string indicating no more pages.\n        if self.max_results is not None:\n            if self.num_results >= self.max_results:\n                return False\n\n        return True if self.next_page_token else False\n", "google/api_core/client_info.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Helpers for providing client information.\n\nClient information is used to send information about the calling client,\nsuch as the library and Python version, to API services.\n\"\"\"\n\nimport platform\nfrom typing import Union\n\nfrom google.api_core import version as api_core_version\n\n_PY_VERSION = platform.python_version()\n_API_CORE_VERSION = api_core_version.__version__\n\n_GRPC_VERSION: Union[str, None]\n\ntry:\n    import grpc\n\n    _GRPC_VERSION = grpc.__version__\nexcept ImportError:  # pragma: NO COVER\n    _GRPC_VERSION = None\n\n\nclass ClientInfo(object):\n    \"\"\"Client information used to generate a user-agent for API calls.\n\n    This user-agent information is sent along with API calls to allow the\n    receiving service to do analytics on which versions of Python and Google\n    libraries are being used.\n\n    Args:\n        python_version (str): The Python interpreter version, for example,\n            ``'3.9.6'``.\n        grpc_version (Optional[str]): The gRPC library version.\n        api_core_version (str): The google-api-core library version.\n        gapic_version (Optional[str]): The version of gapic-generated client\n            library, if the library was generated by gapic.\n        client_library_version (Optional[str]): The version of the client\n            library, generally used if the client library was not generated\n            by gapic or if additional functionality was built on top of\n            a gapic client library.\n        user_agent (Optional[str]): Prefix to the user agent header. This is\n            used to supply information such as application name or partner tool.\n            Recommended format: ``application-or-tool-ID/major.minor.version``.\n        rest_version (Optional[str]): The requests library version.\n    \"\"\"\n\n    def __init__(\n        self,\n        python_version=_PY_VERSION,\n        grpc_version=_GRPC_VERSION,\n        api_core_version=_API_CORE_VERSION,\n        gapic_version=None,\n        client_library_version=None,\n        user_agent=None,\n        rest_version=None,\n    ):\n        self.python_version = python_version\n        self.grpc_version = grpc_version\n        self.api_core_version = api_core_version\n        self.gapic_version = gapic_version\n        self.client_library_version = client_library_version\n        self.user_agent = user_agent\n        self.rest_version = rest_version\n\n    def to_user_agent(self):\n        \"\"\"Returns the user-agent string for this client info.\"\"\"\n\n        # Note: the order here is important as the internal metrics system\n        # expects these items to be in specific locations.\n        ua = \"\"\n\n        if self.user_agent is not None:\n            ua += \"{user_agent} \"\n\n        ua += \"gl-python/{python_version} \"\n\n        if self.grpc_version is not None:\n            ua += \"grpc/{grpc_version} \"\n\n        if self.rest_version is not None:\n            ua += \"rest/{rest_version} \"\n\n        ua += \"gax/{api_core_version} \"\n\n        if self.gapic_version is not None:\n            ua += \"gapic/{gapic_version} \"\n\n        if self.client_library_version is not None:\n            ua += \"gccl/{client_library_version} \"\n\n        return ua.format(**self.__dict__).strip()\n", "google/api_core/extended_operation.py": "# Copyright 2022 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Futures for extended long-running operations returned from Google Cloud APIs.\n\nThese futures can be used to synchronously wait for the result of a\nlong-running operations using :meth:`ExtendedOperation.result`:\n\n.. code-block:: python\n\n    extended_operation = my_api_client.long_running_method()\n\n    extended_operation.result()\n\nOr asynchronously using callbacks and :meth:`Operation.add_done_callback`:\n\n.. code-block:: python\n\n    extended_operation = my_api_client.long_running_method()\n\n    def my_callback(ex_op):\n        print(f\"Operation {ex_op.name} completed\")\n\n    extended_operation.add_done_callback(my_callback)\n\n\"\"\"\n\nimport threading\n\nfrom google.api_core import exceptions\nfrom google.api_core.future import polling\n\n\nclass ExtendedOperation(polling.PollingFuture):\n    \"\"\"An ExtendedOperation future for interacting with a Google API Long-Running Operation.\n\n    Args:\n        extended_operation (proto.Message): The initial operation.\n        refresh (Callable[[], type(extended_operation)]): A callable that returns\n            the latest state of the operation.\n        cancel (Callable[[], None]): A callable that tries to cancel the operation.\n        polling Optional(google.api_core.retry.Retry): The configuration used\n            for polling. This can be used to control how often :meth:`done`\n            is polled. If the ``timeout`` argument to :meth:`result` is\n            specified it will override the ``polling.timeout`` property.\n        retry Optional(google.api_core.retry.Retry): DEPRECATED use ``polling``\n            instead. If specified it will override ``polling`` parameter to\n            maintain backward compatibility.\n\n    Note: Most long-running API methods use google.api_core.operation.Operation\n    This class is a wrapper for a subset of methods that use alternative\n    Long-Running Operation (LRO) semantics.\n\n    Note: there is not a concrete type the extended operation must be.\n    It MUST have fields that correspond to the following, POSSIBLY WITH DIFFERENT NAMES:\n    * name: str\n    * status: Union[str, bool, enum.Enum]\n    * error_code: int\n    * error_message: str\n    \"\"\"\n\n    def __init__(\n        self,\n        extended_operation,\n        refresh,\n        cancel,\n        polling=polling.DEFAULT_POLLING,\n        **kwargs,\n    ):\n        super().__init__(polling=polling, **kwargs)\n        self._extended_operation = extended_operation\n        self._refresh = refresh\n        self._cancel = cancel\n        # Note: the extended operation does not give a good way to indicate cancellation.\n        # We make do with manually tracking cancellation and checking for doneness.\n        self._cancelled = False\n        self._completion_lock = threading.Lock()\n        # Invoke in case the operation came back already complete.\n        self._handle_refreshed_operation()\n\n    # Note: the following four properties MUST be overridden in a subclass\n    # if, and only if, the fields in the corresponding extended operation message\n    # have different names.\n    #\n    # E.g. we have an extended operation class that looks like\n    #\n    # class MyOperation(proto.Message):\n    #     moniker = proto.Field(proto.STRING, number=1)\n    #     status_msg = proto.Field(proto.STRING, number=2)\n    #     optional http_error_code = proto.Field(proto.INT32, number=3)\n    #     optional http_error_msg = proto.Field(proto.STRING, number=4)\n    #\n    # the ExtendedOperation subclass would provide property overrides that map\n    # to these (poorly named) fields.\n    @property\n    def name(self):\n        return self._extended_operation.name\n\n    @property\n    def status(self):\n        return self._extended_operation.status\n\n    @property\n    def error_code(self):\n        return self._extended_operation.error_code\n\n    @property\n    def error_message(self):\n        return self._extended_operation.error_message\n\n    def __getattr__(self, name):\n        return getattr(self._extended_operation, name)\n\n    def done(self, retry=None):\n        self._refresh_and_update(retry)\n        return self._extended_operation.done\n\n    def cancel(self):\n        if self.done():\n            return False\n\n        self._cancel()\n        self._cancelled = True\n        return True\n\n    def cancelled(self):\n        # TODO(dovs): there is not currently a good way to determine whether the\n        # operation has been cancelled.\n        # The best we can do is manually keep track of cancellation\n        # and check for doneness.\n        if not self._cancelled:\n            return False\n\n        self._refresh_and_update()\n        return self._extended_operation.done\n\n    def _refresh_and_update(self, retry=None):\n        if not self._extended_operation.done:\n            self._extended_operation = (\n                self._refresh(retry=retry) if retry else self._refresh()\n            )\n            self._handle_refreshed_operation()\n\n    def _handle_refreshed_operation(self):\n        with self._completion_lock:\n            if not self._extended_operation.done:\n                return\n\n            if self.error_code and self.error_message:\n                # Note: `errors` can be removed once proposal A from\n                # b/284179390 is implemented.\n                errors = []\n                if hasattr(self, \"error\") and hasattr(self.error, \"errors\"):\n                    errors = self.error.errors\n                exception = exceptions.from_http_status(\n                    status_code=self.error_code,\n                    message=self.error_message,\n                    response=self._extended_operation,\n                    errors=errors,\n                )\n                self.set_exception(exception)\n            elif self.error_code or self.error_message:\n                exception = exceptions.GoogleAPICallError(\n                    f\"Unexpected error {self.error_code}: {self.error_message}\"\n                )\n                self.set_exception(exception)\n            else:\n                # Extended operations have no payload.\n                self.set_result(None)\n\n    @classmethod\n    def make(cls, refresh, cancel, extended_operation, **kwargs):\n        \"\"\"\n        Return an instantiated ExtendedOperation (or child) that wraps\n        * a refresh callable\n        * a cancel callable (can be a no-op)\n        * an initial result\n\n        .. note::\n            It is the caller's responsibility to set up refresh and cancel\n            with their correct request argument.\n            The reason for this is that the services that use Extended Operations\n            have rpcs that look something like the following:\n\n            // service.proto\n            service MyLongService {\n                rpc StartLongTask(StartLongTaskRequest) returns (ExtendedOperation) {\n                    option (google.cloud.operation_service) = \"CustomOperationService\";\n                }\n            }\n\n            service CustomOperationService {\n                rpc Get(GetOperationRequest) returns (ExtendedOperation) {\n                    option (google.cloud.operation_polling_method) = true;\n                }\n            }\n\n            Any info needed for the poll, e.g. a name, path params, etc.\n            is held in the request, which the initial client method is in a much\n            better position to make made because the caller made the initial request.\n\n            TL;DR: the caller sets up closures for refresh and cancel that carry\n            the properly configured requests.\n\n        Args:\n            refresh (Callable[Optional[Retry]][type(extended_operation)]): A callable that\n                returns the latest state of the operation.\n            cancel (Callable[][Any]): A callable that tries to cancel the operation\n                on a best effort basis.\n            extended_operation (Any): The initial response of the long running method.\n                See the docstring for ExtendedOperation.__init__ for requirements on\n                the type and fields of extended_operation\n        \"\"\"\n        return cls(extended_operation, refresh, cancel, **kwargs)\n", "google/api_core/general_helpers.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# This import for backward compatibility only.\nfrom functools import wraps  # noqa: F401 pragma: NO COVER\n", "google/api_core/version.py": "# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n__version__ = \"2.19.1\"\n", "google/api_core/datetime_helpers.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Helpers for :mod:`datetime`.\"\"\"\n\nimport calendar\nimport datetime\nimport re\n\nfrom google.protobuf import timestamp_pb2\n\n\n_UTC_EPOCH = datetime.datetime(1970, 1, 1, tzinfo=datetime.timezone.utc)\n_RFC3339_MICROS = \"%Y-%m-%dT%H:%M:%S.%fZ\"\n_RFC3339_NO_FRACTION = \"%Y-%m-%dT%H:%M:%S\"\n# datetime.strptime cannot handle nanosecond precision:  parse w/ regex\n_RFC3339_NANOS = re.compile(\n    r\"\"\"\n    (?P<no_fraction>\n        \\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}  # YYYY-MM-DDTHH:MM:SS\n    )\n    (                                        # Optional decimal part\n     \\.                                      # decimal point\n     (?P<nanos>\\d{1,9})                      # nanoseconds, maybe truncated\n    )?\n    Z                                        # Zulu\n\"\"\",\n    re.VERBOSE,\n)\n\n\ndef utcnow():\n    \"\"\"A :meth:`datetime.datetime.utcnow()` alias to allow mocking in tests.\"\"\"\n    return datetime.datetime.now(tz=datetime.timezone.utc).replace(tzinfo=None)\n\n\ndef to_milliseconds(value):\n    \"\"\"Convert a zone-aware datetime to milliseconds since the unix epoch.\n\n    Args:\n        value (datetime.datetime): The datetime to covert.\n\n    Returns:\n        int: Milliseconds since the unix epoch.\n    \"\"\"\n    micros = to_microseconds(value)\n    return micros // 1000\n\n\ndef from_microseconds(value):\n    \"\"\"Convert timestamp in microseconds since the unix epoch to datetime.\n\n    Args:\n        value (float): The timestamp to convert, in microseconds.\n\n    Returns:\n        datetime.datetime: The datetime object equivalent to the timestamp in\n            UTC.\n    \"\"\"\n    return _UTC_EPOCH + datetime.timedelta(microseconds=value)\n\n\ndef to_microseconds(value):\n    \"\"\"Convert a datetime to microseconds since the unix epoch.\n\n    Args:\n        value (datetime.datetime): The datetime to covert.\n\n    Returns:\n        int: Microseconds since the unix epoch.\n    \"\"\"\n    if not value.tzinfo:\n        value = value.replace(tzinfo=datetime.timezone.utc)\n    # Regardless of what timezone is on the value, convert it to UTC.\n    value = value.astimezone(datetime.timezone.utc)\n    # Convert the datetime to a microsecond timestamp.\n    return int(calendar.timegm(value.timetuple()) * 1e6) + value.microsecond\n\n\ndef from_iso8601_date(value):\n    \"\"\"Convert a ISO8601 date string to a date.\n\n    Args:\n        value (str): The ISO8601 date string.\n\n    Returns:\n        datetime.date: A date equivalent to the date string.\n    \"\"\"\n    return datetime.datetime.strptime(value, \"%Y-%m-%d\").date()\n\n\ndef from_iso8601_time(value):\n    \"\"\"Convert a zoneless ISO8601 time string to a time.\n\n    Args:\n        value (str): The ISO8601 time string.\n\n    Returns:\n        datetime.time: A time equivalent to the time string.\n    \"\"\"\n    return datetime.datetime.strptime(value, \"%H:%M:%S\").time()\n\n\ndef from_rfc3339(value):\n    \"\"\"Convert an RFC3339-format timestamp to a native datetime.\n\n    Supported formats include those without fractional seconds, or with\n    any fraction up to nanosecond precision.\n\n    .. note::\n        Python datetimes do not support nanosecond precision; this function\n        therefore truncates such values to microseconds.\n\n    Args:\n        value (str): The RFC3339 string to convert.\n\n    Returns:\n        datetime.datetime: The datetime object equivalent to the timestamp\n        in UTC.\n\n    Raises:\n        ValueError: If the timestamp does not match the RFC3339\n            regular expression.\n    \"\"\"\n    with_nanos = _RFC3339_NANOS.match(value)\n\n    if with_nanos is None:\n        raise ValueError(\n            \"Timestamp: {!r}, does not match pattern: {!r}\".format(\n                value, _RFC3339_NANOS.pattern\n            )\n        )\n\n    bare_seconds = datetime.datetime.strptime(\n        with_nanos.group(\"no_fraction\"), _RFC3339_NO_FRACTION\n    )\n    fraction = with_nanos.group(\"nanos\")\n\n    if fraction is None:\n        micros = 0\n    else:\n        scale = 9 - len(fraction)\n        nanos = int(fraction) * (10**scale)\n        micros = nanos // 1000\n\n    return bare_seconds.replace(microsecond=micros, tzinfo=datetime.timezone.utc)\n\n\nfrom_rfc3339_nanos = from_rfc3339  # from_rfc3339_nanos method was deprecated.\n\n\ndef to_rfc3339(value, ignore_zone=True):\n    \"\"\"Convert a datetime to an RFC3339 timestamp string.\n\n    Args:\n        value (datetime.datetime):\n            The datetime object to be converted to a string.\n        ignore_zone (bool): If True, then the timezone (if any) of the\n            datetime object is ignored and the datetime is treated as UTC.\n\n    Returns:\n        str: The RFC3339 formatted string representing the datetime.\n    \"\"\"\n    if not ignore_zone and value.tzinfo is not None:\n        # Convert to UTC and remove the time zone info.\n        value = value.replace(tzinfo=None) - value.utcoffset()\n\n    return value.strftime(_RFC3339_MICROS)\n\n\nclass DatetimeWithNanoseconds(datetime.datetime):\n    \"\"\"Track nanosecond in addition to normal datetime attrs.\n\n    Nanosecond can be passed only as a keyword argument.\n    \"\"\"\n\n    __slots__ = (\"_nanosecond\",)\n\n    # pylint: disable=arguments-differ\n    def __new__(cls, *args, **kw):\n        nanos = kw.pop(\"nanosecond\", 0)\n        if nanos > 0:\n            if \"microsecond\" in kw:\n                raise TypeError(\"Specify only one of 'microsecond' or 'nanosecond'\")\n            kw[\"microsecond\"] = nanos // 1000\n        inst = datetime.datetime.__new__(cls, *args, **kw)\n        inst._nanosecond = nanos or 0\n        return inst\n\n    # pylint: disable=arguments-differ\n\n    @property\n    def nanosecond(self):\n        \"\"\"Read-only: nanosecond precision.\"\"\"\n        return self._nanosecond\n\n    def rfc3339(self):\n        \"\"\"Return an RFC3339-compliant timestamp.\n\n        Returns:\n            (str): Timestamp string according to RFC3339 spec.\n        \"\"\"\n        if self._nanosecond == 0:\n            return to_rfc3339(self)\n        nanos = str(self._nanosecond).rjust(9, \"0\").rstrip(\"0\")\n        return \"{}.{}Z\".format(self.strftime(_RFC3339_NO_FRACTION), nanos)\n\n    @classmethod\n    def from_rfc3339(cls, stamp):\n        \"\"\"Parse RFC3339-compliant timestamp, preserving nanoseconds.\n\n        Args:\n            stamp (str): RFC3339 stamp, with up to nanosecond precision\n\n        Returns:\n            :class:`DatetimeWithNanoseconds`:\n                an instance matching the timestamp string\n\n        Raises:\n            ValueError: if `stamp` does not match the expected format\n        \"\"\"\n        with_nanos = _RFC3339_NANOS.match(stamp)\n        if with_nanos is None:\n            raise ValueError(\n                \"Timestamp: {}, does not match pattern: {}\".format(\n                    stamp, _RFC3339_NANOS.pattern\n                )\n            )\n        bare = datetime.datetime.strptime(\n            with_nanos.group(\"no_fraction\"), _RFC3339_NO_FRACTION\n        )\n        fraction = with_nanos.group(\"nanos\")\n        if fraction is None:\n            nanos = 0\n        else:\n            scale = 9 - len(fraction)\n            nanos = int(fraction) * (10**scale)\n        return cls(\n            bare.year,\n            bare.month,\n            bare.day,\n            bare.hour,\n            bare.minute,\n            bare.second,\n            nanosecond=nanos,\n            tzinfo=datetime.timezone.utc,\n        )\n\n    def timestamp_pb(self):\n        \"\"\"Return a timestamp message.\n\n        Returns:\n            (:class:`~google.protobuf.timestamp_pb2.Timestamp`): Timestamp message\n        \"\"\"\n        inst = (\n            self\n            if self.tzinfo is not None\n            else self.replace(tzinfo=datetime.timezone.utc)\n        )\n        delta = inst - _UTC_EPOCH\n        seconds = int(delta.total_seconds())\n        nanos = self._nanosecond or self.microsecond * 1000\n        return timestamp_pb2.Timestamp(seconds=seconds, nanos=nanos)\n\n    @classmethod\n    def from_timestamp_pb(cls, stamp):\n        \"\"\"Parse RFC3339-compliant timestamp, preserving nanoseconds.\n\n        Args:\n            stamp (:class:`~google.protobuf.timestamp_pb2.Timestamp`): timestamp message\n\n        Returns:\n            :class:`DatetimeWithNanoseconds`:\n                an instance matching the timestamp message\n        \"\"\"\n        microseconds = int(stamp.seconds * 1e6)\n        bare = from_microseconds(microseconds)\n        return cls(\n            bare.year,\n            bare.month,\n            bare.day,\n            bare.hour,\n            bare.minute,\n            bare.second,\n            nanosecond=stamp.nanos,\n            tzinfo=datetime.timezone.utc,\n        )\n", "google/api_core/timeout.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Decorators for applying timeout arguments to functions.\n\nThese decorators are used to wrap API methods to apply either a\nDeadline-dependent (recommended), constant (DEPRECATED) or exponential\n(DEPRECATED) timeout argument.\n\nFor example, imagine an API method that can take a while to return results,\nsuch as one that might block until a resource is ready:\n\n.. code-block:: python\n\n    def is_thing_ready(timeout=None):\n        response = requests.get('https://example.com/is_thing_ready')\n        response.raise_for_status()\n        return response.json()\n\nThis module allows a function like this to be wrapped so that timeouts are\nautomatically determined, for example:\n\n.. code-block:: python\n\n    timeout_ = timeout.ExponentialTimeout()\n    is_thing_ready_with_timeout = timeout_(is_thing_ready)\n\n    for n in range(10):\n        try:\n            is_thing_ready_with_timeout({'example': 'data'})\n        except:\n            pass\n\nIn this example the first call to ``is_thing_ready`` will have a relatively\nsmall timeout (like 1 second). If the resource is available and the request\ncompletes quickly, the loop exits. But, if the resource isn't yet available\nand the request times out, it'll be retried - this time with a larger timeout.\n\nIn the broader context these decorators are typically combined with\n:mod:`google.api_core.retry` to implement API methods with a signature that\nmatches ``api_method(request, timeout=None, retry=None)``.\n\"\"\"\n\nfrom __future__ import unicode_literals\n\nimport datetime\nimport functools\n\nfrom google.api_core import datetime_helpers\n\n_DEFAULT_INITIAL_TIMEOUT = 5.0  # seconds\n_DEFAULT_MAXIMUM_TIMEOUT = 30.0  # seconds\n_DEFAULT_TIMEOUT_MULTIPLIER = 2.0\n# If specified, must be in seconds. If none, deadline is not used in the\n# timeout calculation.\n_DEFAULT_DEADLINE = None\n\n\nclass TimeToDeadlineTimeout(object):\n    \"\"\"A decorator that decreases timeout set for an RPC based on how much time\n    has left till its deadline. The deadline is calculated as\n    ``now + initial_timeout`` when this decorator is first called for an rpc.\n\n    In other words this decorator implements deadline semantics in terms of a\n    sequence of decreasing timeouts t0 > t1 > t2 ... tn >= 0.\n\n    Args:\n        timeout (Optional[float]): the timeout (in seconds) to applied to the\n            wrapped function. If `None`, the target function is expected to\n            never timeout.\n    \"\"\"\n\n    def __init__(self, timeout=None, clock=datetime_helpers.utcnow):\n        self._timeout = timeout\n        self._clock = clock\n\n    def __call__(self, func):\n        \"\"\"Apply the timeout decorator.\n\n        Args:\n            func (Callable): The function to apply the timeout argument to.\n                This function must accept a timeout keyword argument.\n\n        Returns:\n            Callable: The wrapped function.\n        \"\"\"\n\n        first_attempt_timestamp = self._clock().timestamp()\n\n        @functools.wraps(func)\n        def func_with_timeout(*args, **kwargs):\n            \"\"\"Wrapped function that adds timeout.\"\"\"\n\n            remaining_timeout = self._timeout\n            if remaining_timeout is not None:\n                # All calculations are in seconds\n                now_timestamp = self._clock().timestamp()\n\n                # To avoid usage of nonlocal but still have round timeout\n                # numbers for first attempt (in most cases the only attempt made\n                # for an RPC.\n                if now_timestamp - first_attempt_timestamp < 0.001:\n                    now_timestamp = first_attempt_timestamp\n\n                time_since_first_attempt = now_timestamp - first_attempt_timestamp\n                # Avoid setting negative timeout\n                kwargs[\"timeout\"] = max(0, self._timeout - time_since_first_attempt)\n\n            return func(*args, **kwargs)\n\n        return func_with_timeout\n\n    def __str__(self):\n        return \"<TimeToDeadlineTimeout timeout={:.1f}>\".format(self._timeout)\n\n\nclass ConstantTimeout(object):\n    \"\"\"A decorator that adds a constant timeout argument.\n\n    DEPRECATED: use ``TimeToDeadlineTimeout`` instead.\n\n    This is effectively equivalent to\n    ``functools.partial(func, timeout=timeout)``.\n\n    Args:\n        timeout (Optional[float]): the timeout (in seconds) to applied to the\n            wrapped function. If `None`, the target function is expected to\n            never timeout.\n    \"\"\"\n\n    def __init__(self, timeout=None):\n        self._timeout = timeout\n\n    def __call__(self, func):\n        \"\"\"Apply the timeout decorator.\n\n        Args:\n            func (Callable): The function to apply the timeout argument to.\n                This function must accept a timeout keyword argument.\n\n        Returns:\n            Callable: The wrapped function.\n        \"\"\"\n\n        @functools.wraps(func)\n        def func_with_timeout(*args, **kwargs):\n            \"\"\"Wrapped function that adds timeout.\"\"\"\n            kwargs[\"timeout\"] = self._timeout\n            return func(*args, **kwargs)\n\n        return func_with_timeout\n\n    def __str__(self):\n        return \"<ConstantTimeout timeout={:.1f}>\".format(self._timeout)\n\n\ndef _exponential_timeout_generator(initial, maximum, multiplier, deadline):\n    \"\"\"A generator that yields exponential timeout values.\n\n    Args:\n        initial (float): The initial timeout.\n        maximum (float): The maximum timeout.\n        multiplier (float): The multiplier applied to the timeout.\n        deadline (float): The overall deadline across all invocations.\n\n    Yields:\n        float: A timeout value.\n    \"\"\"\n    if deadline is not None:\n        deadline_datetime = datetime_helpers.utcnow() + datetime.timedelta(\n            seconds=deadline\n        )\n    else:\n        deadline_datetime = datetime.datetime.max\n\n    timeout = initial\n    while True:\n        now = datetime_helpers.utcnow()\n        yield min(\n            # The calculated timeout based on invocations.\n            timeout,\n            # The set maximum timeout.\n            maximum,\n            # The remaining time before the deadline is reached.\n            float((deadline_datetime - now).seconds),\n        )\n        timeout = timeout * multiplier\n\n\nclass ExponentialTimeout(object):\n    \"\"\"A decorator that adds an exponentially increasing timeout argument.\n\n    DEPRECATED: the concept of incrementing timeout exponentially has been\n    deprecated. Use ``TimeToDeadlineTimeout`` instead.\n\n    This is useful if a function is called multiple times. Each time the\n    function is called this decorator will calculate a new timeout parameter\n    based on the the number of times the function has been called.\n\n    For example\n\n    .. code-block:: python\n\n    Args:\n        initial (float): The initial timeout to pass.\n        maximum (float): The maximum timeout for any one call.\n        multiplier (float): The multiplier applied to the timeout for each\n            invocation.\n        deadline (Optional[float]): The overall deadline across all\n            invocations. This is used to prevent a very large calculated\n            timeout from pushing the overall execution time over the deadline.\n            This is especially useful in conjunction with\n            :mod:`google.api_core.retry`. If ``None``, the timeouts will not\n            be adjusted to accommodate an overall deadline.\n    \"\"\"\n\n    def __init__(\n        self,\n        initial=_DEFAULT_INITIAL_TIMEOUT,\n        maximum=_DEFAULT_MAXIMUM_TIMEOUT,\n        multiplier=_DEFAULT_TIMEOUT_MULTIPLIER,\n        deadline=_DEFAULT_DEADLINE,\n    ):\n        self._initial = initial\n        self._maximum = maximum\n        self._multiplier = multiplier\n        self._deadline = deadline\n\n    def with_deadline(self, deadline):\n        \"\"\"Return a copy of this timeout with the given deadline.\n\n        Args:\n            deadline (float): The overall deadline across all invocations.\n\n        Returns:\n            ExponentialTimeout: A new instance with the given deadline.\n        \"\"\"\n        return ExponentialTimeout(\n            initial=self._initial,\n            maximum=self._maximum,\n            multiplier=self._multiplier,\n            deadline=deadline,\n        )\n\n    def __call__(self, func):\n        \"\"\"Apply the timeout decorator.\n\n        Args:\n            func (Callable): The function to apply the timeout argument to.\n                This function must accept a timeout keyword argument.\n\n        Returns:\n            Callable: The wrapped function.\n        \"\"\"\n        timeouts = _exponential_timeout_generator(\n            self._initial, self._maximum, self._multiplier, self._deadline\n        )\n\n        @functools.wraps(func)\n        def func_with_timeout(*args, **kwargs):\n            \"\"\"Wrapped function that adds timeout.\"\"\"\n            kwargs[\"timeout\"] = next(timeouts)\n            return func(*args, **kwargs)\n\n        return func_with_timeout\n\n    def __str__(self):\n        return (\n            \"<ExponentialTimeout initial={:.1f}, maximum={:.1f}, \"\n            \"multiplier={:.1f}, deadline={:.1f}>\".format(\n                self._initial, self._maximum, self._multiplier, self._deadline\n            )\n        )\n", "google/api_core/rest_streaming.py": "# Copyright 2021 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Helpers for server-side streaming in REST.\"\"\"\n\nfrom collections import deque\nimport string\nfrom typing import Deque, Union\n\nimport proto\nimport requests\nimport google.protobuf.message\nfrom google.protobuf.json_format import Parse\n\n\nclass ResponseIterator:\n    \"\"\"Iterator over REST API responses.\n\n    Args:\n        response (requests.Response): An API response object.\n        response_message_cls (Union[proto.Message, google.protobuf.message.Message]): A response\n        class expected to be returned from an API.\n\n    Raises:\n        ValueError: If `response_message_cls` is not a subclass of `proto.Message` or `google.protobuf.message.Message`.\n    \"\"\"\n\n    def __init__(\n        self,\n        response: requests.Response,\n        response_message_cls: Union[proto.Message, google.protobuf.message.Message],\n    ):\n        self._response = response\n        self._response_message_cls = response_message_cls\n        # Inner iterator over HTTP response's content.\n        self._response_itr = self._response.iter_content(decode_unicode=True)\n        # Contains a list of JSON responses ready to be sent to user.\n        self._ready_objs: Deque[str] = deque()\n        # Current JSON response being built.\n        self._obj = \"\"\n        # Keeps track of the nesting level within a JSON object.\n        self._level = 0\n        # Keeps track whether HTTP response is currently sending values\n        # inside of a string value.\n        self._in_string = False\n        # Whether an escape symbol \"\\\" was encountered.\n        self._escape_next = False\n\n    def cancel(self):\n        \"\"\"Cancel existing streaming operation.\"\"\"\n        self._response.close()\n\n    def _process_chunk(self, chunk: str):\n        if self._level == 0:\n            if chunk[0] != \"[\":\n                raise ValueError(\n                    \"Can only parse array of JSON objects, instead got %s\" % chunk\n                )\n        for char in chunk:\n            if char == \"{\":\n                if self._level == 1:\n                    # Level 1 corresponds to the outermost JSON object\n                    # (i.e. the one we care about).\n                    self._obj = \"\"\n                if not self._in_string:\n                    self._level += 1\n                self._obj += char\n            elif char == \"}\":\n                self._obj += char\n                if not self._in_string:\n                    self._level -= 1\n                if not self._in_string and self._level == 1:\n                    self._ready_objs.append(self._obj)\n            elif char == '\"':\n                # Helps to deal with an escaped quotes inside of a string.\n                if not self._escape_next:\n                    self._in_string = not self._in_string\n                self._obj += char\n            elif char in string.whitespace:\n                if self._in_string:\n                    self._obj += char\n            elif char == \"[\":\n                if self._level == 0:\n                    self._level += 1\n                else:\n                    self._obj += char\n            elif char == \"]\":\n                if self._level == 1:\n                    self._level -= 1\n                else:\n                    self._obj += char\n            else:\n                self._obj += char\n            self._escape_next = not self._escape_next if char == \"\\\\\" else False\n\n    def __next__(self):\n        while not self._ready_objs:\n            try:\n                chunk = next(self._response_itr)\n                self._process_chunk(chunk)\n            except StopIteration as e:\n                if self._level > 0:\n                    raise ValueError(\"Unfinished stream: %s\" % self._obj)\n                raise e\n        return self._grab()\n\n    def _grab(self):\n        # Add extra quotes to make json.loads happy.\n        if issubclass(self._response_message_cls, proto.Message):\n            return self._response_message_cls.from_json(\n                self._ready_objs.popleft(), ignore_unknown_fields=True\n            )\n        elif issubclass(self._response_message_cls, google.protobuf.message.Message):\n            return Parse(self._ready_objs.popleft(), self._response_message_cls())\n        else:\n            raise ValueError(\n                \"Response message class must be a subclass of proto.Message or google.protobuf.message.Message.\"\n            )\n\n    def __iter__(self):\n        return self\n", "google/api_core/client_options.py": "# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Client options class.\n\nClient options provide a consistent interface for user options to be defined\nacross clients.\n\nYou can pass a client options object to a client.\n\n.. code-block:: python\n\n    from google.api_core.client_options import ClientOptions\n    from google.cloud.vision_v1 import ImageAnnotatorClient\n\n    def get_client_cert():\n        # code to load client certificate and private key.\n        return client_cert_bytes, client_private_key_bytes\n\n    options = ClientOptions(api_endpoint=\"foo.googleapis.com\",\n        client_cert_source=get_client_cert)\n\n    client = ImageAnnotatorClient(client_options=options)\n\nYou can also pass a mapping object.\n\n.. code-block:: python\n\n    from google.cloud.vision_v1 import ImageAnnotatorClient\n\n    client = ImageAnnotatorClient(\n        client_options={\n            \"api_endpoint\": \"foo.googleapis.com\",\n            \"client_cert_source\" : get_client_cert\n        })\n\n\n\"\"\"\n\n\nclass ClientOptions(object):\n    \"\"\"Client Options used to set options on clients.\n\n    Args:\n        api_endpoint (Optional[str]): The desired API endpoint, e.g.,\n            compute.googleapis.com\n        client_cert_source (Optional[Callable[[], (bytes, bytes)]]): A callback\n            which returns client certificate bytes and private key bytes both in\n            PEM format. ``client_cert_source`` and ``client_encrypted_cert_source``\n            are mutually exclusive.\n        client_encrypted_cert_source (Optional[Callable[[], (str, str, bytes)]]):\n            A callback which returns client certificate file path, encrypted\n            private key file path, and the passphrase bytes.``client_cert_source``\n            and ``client_encrypted_cert_source`` are mutually exclusive.\n        quota_project_id (Optional[str]): A project name that a client's\n            quota belongs to.\n        credentials_file (Optional[str]): A path to a file storing credentials.\n            ``credentials_file` and ``api_key`` are mutually exclusive.\n        scopes (Optional[Sequence[str]]): OAuth access token override scopes.\n        api_key (Optional[str]): Google API key. ``credentials_file`` and\n            ``api_key`` are mutually exclusive.\n        api_audience (Optional[str]): The intended audience for the API calls\n            to the service that will be set when using certain 3rd party\n            authentication flows. Audience is typically a resource identifier.\n            If not set, the service endpoint value will be used as a default.\n            An example of a valid ``api_audience`` is: \"https://language.googleapis.com\".\n        universe_domain (Optional[str]): The desired universe domain. This must match\n            the one in credentials. If not set, the default universe domain is\n            `googleapis.com`. If both `api_endpoint` and `universe_domain` are set,\n            then `api_endpoint` is used as the service endpoint. If `api_endpoint` is\n            not specified, the format will be `{service}.{universe_domain}`.\n\n    Raises:\n        ValueError: If both ``client_cert_source`` and ``client_encrypted_cert_source``\n            are provided, or both ``credentials_file`` and ``api_key`` are provided.\n    \"\"\"\n\n    def __init__(\n        self,\n        api_endpoint=None,\n        client_cert_source=None,\n        client_encrypted_cert_source=None,\n        quota_project_id=None,\n        credentials_file=None,\n        scopes=None,\n        api_key=None,\n        api_audience=None,\n        universe_domain=None,\n    ):\n        if client_cert_source and client_encrypted_cert_source:\n            raise ValueError(\n                \"client_cert_source and client_encrypted_cert_source are mutually exclusive\"\n            )\n        if api_key and credentials_file:\n            raise ValueError(\"api_key and credentials_file are mutually exclusive\")\n        self.api_endpoint = api_endpoint\n        self.client_cert_source = client_cert_source\n        self.client_encrypted_cert_source = client_encrypted_cert_source\n        self.quota_project_id = quota_project_id\n        self.credentials_file = credentials_file\n        self.scopes = scopes\n        self.api_key = api_key\n        self.api_audience = api_audience\n        self.universe_domain = universe_domain\n\n    def __repr__(self):\n        return \"ClientOptions: \" + repr(self.__dict__)\n\n\ndef from_dict(options):\n    \"\"\"Construct a client options object from a mapping object.\n\n    Args:\n        options (collections.abc.Mapping): A mapping object with client options.\n            See the docstring for ClientOptions for details on valid arguments.\n    \"\"\"\n\n    client_options = ClientOptions()\n\n    for key, value in options.items():\n        if hasattr(client_options, key):\n            setattr(client_options, key, value)\n        else:\n            raise ValueError(\"ClientOptions does not accept an option '\" + key + \"'\")\n\n    return client_options\n", "google/api_core/retry_async.py": "# Copyright 2024 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# The following imports are for backwards compatibility with https://github.com/googleapis/python-api-core/blob/4d7d2edee2c108d43deb151e6e0fdceb56b73275/google/api_core/retry_async.py\n#\n# TODO: Revert these imports on the next major version release (https://github.com/googleapis/python-api-core/issues/576)\nfrom google.api_core import datetime_helpers  # noqa: F401\nfrom google.api_core import exceptions  # noqa: F401\nfrom google.api_core.retry import exponential_sleep_generator  # noqa: F401\nfrom google.api_core.retry import if_exception_type  # noqa: F401\nfrom google.api_core.retry import if_transient_error  # noqa: F401\nfrom google.api_core.retry.retry_unary_async import AsyncRetry\nfrom google.api_core.retry.retry_unary_async import retry_target\n\n__all__ = (\n    \"AsyncRetry\",\n    \"datetime_helpers\",\n    \"exceptions\",\n    \"exponential_sleep_generator\",\n    \"if_exception_type\",\n    \"if_transient_error\",\n    \"retry_target\",\n)\n", "google/api_core/operation_async.py": "# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"AsyncIO futures for long-running operations returned from Google Cloud APIs.\n\nThese futures can be used to await for the result of a long-running operation\nusing :meth:`AsyncOperation.result`:\n\n\n.. code-block:: python\n\n    operation = my_api_client.long_running_method()\n    result = await operation.result()\n\nOr asynchronously using callbacks and :meth:`Operation.add_done_callback`:\n\n.. code-block:: python\n\n    operation = my_api_client.long_running_method()\n\n    def my_callback(future):\n        result = await future.result()\n\n    operation.add_done_callback(my_callback)\n\n\"\"\"\n\nimport functools\nimport threading\n\nfrom google.api_core import exceptions\nfrom google.api_core import protobuf_helpers\nfrom google.api_core.future import async_future\nfrom google.longrunning import operations_pb2\nfrom google.rpc import code_pb2\n\n\nclass AsyncOperation(async_future.AsyncFuture):\n    \"\"\"A Future for interacting with a Google API Long-Running Operation.\n\n    Args:\n        operation (google.longrunning.operations_pb2.Operation): The\n            initial operation.\n        refresh (Callable[[], ~.api_core.operation.Operation]): A callable that\n            returns the latest state of the operation.\n        cancel (Callable[[], None]): A callable that tries to cancel\n            the operation.\n        result_type (func:`type`): The protobuf type for the operation's\n            result.\n        metadata_type (func:`type`): The protobuf type for the operation's\n            metadata.\n        retry (google.api_core.retry.Retry): The retry configuration used\n            when polling. This can be used to control how often :meth:`done`\n            is polled. Regardless of the retry's ``deadline``, it will be\n            overridden by the ``timeout`` argument to :meth:`result`.\n    \"\"\"\n\n    def __init__(\n        self,\n        operation,\n        refresh,\n        cancel,\n        result_type,\n        metadata_type=None,\n        retry=async_future.DEFAULT_RETRY,\n    ):\n        super().__init__(retry=retry)\n        self._operation = operation\n        self._refresh = refresh\n        self._cancel = cancel\n        self._result_type = result_type\n        self._metadata_type = metadata_type\n        self._completion_lock = threading.Lock()\n        # Invoke this in case the operation came back already complete.\n        self._set_result_from_operation()\n\n    @property\n    def operation(self):\n        \"\"\"google.longrunning.Operation: The current long-running operation.\"\"\"\n        return self._operation\n\n    @property\n    def metadata(self):\n        \"\"\"google.protobuf.Message: the current operation metadata.\"\"\"\n        if not self._operation.HasField(\"metadata\"):\n            return None\n\n        return protobuf_helpers.from_any_pb(\n            self._metadata_type, self._operation.metadata\n        )\n\n    @classmethod\n    def deserialize(cls, payload):\n        \"\"\"Deserialize a ``google.longrunning.Operation`` protocol buffer.\n\n        Args:\n            payload (bytes): A serialized operation protocol buffer.\n\n        Returns:\n            ~.operations_pb2.Operation: An Operation protobuf object.\n        \"\"\"\n        return operations_pb2.Operation.FromString(payload)\n\n    def _set_result_from_operation(self):\n        \"\"\"Set the result or exception from the operation if it is complete.\"\"\"\n        # This must be done in a lock to prevent the async_future thread\n        # and main thread from both executing the completion logic\n        # at the same time.\n        with self._completion_lock:\n            # If the operation isn't complete or if the result has already been\n            # set, do not call set_result/set_exception again.\n            if not self._operation.done or self._future.done():\n                return\n\n            if self._operation.HasField(\"response\"):\n                response = protobuf_helpers.from_any_pb(\n                    self._result_type, self._operation.response\n                )\n                self.set_result(response)\n            elif self._operation.HasField(\"error\"):\n                exception = exceptions.GoogleAPICallError(\n                    self._operation.error.message,\n                    errors=(self._operation.error,),\n                    response=self._operation,\n                )\n                self.set_exception(exception)\n            else:\n                exception = exceptions.GoogleAPICallError(\n                    \"Unexpected state: Long-running operation had neither \"\n                    \"response nor error set.\"\n                )\n                self.set_exception(exception)\n\n    async def _refresh_and_update(self, retry=async_future.DEFAULT_RETRY):\n        \"\"\"Refresh the operation and update the result if needed.\n\n        Args:\n            retry (google.api_core.retry.Retry): (Optional) How to retry the RPC.\n        \"\"\"\n        # If the currently cached operation is done, no need to make another\n        # RPC as it will not change once done.\n        if not self._operation.done:\n            self._operation = await self._refresh(retry=retry)\n            self._set_result_from_operation()\n\n    async def done(self, retry=async_future.DEFAULT_RETRY):\n        \"\"\"Checks to see if the operation is complete.\n\n        Args:\n            retry (google.api_core.retry.Retry): (Optional) How to retry the RPC.\n\n        Returns:\n            bool: True if the operation is complete, False otherwise.\n        \"\"\"\n        await self._refresh_and_update(retry)\n        return self._operation.done\n\n    async def cancel(self):\n        \"\"\"Attempt to cancel the operation.\n\n        Returns:\n            bool: True if the cancel RPC was made, False if the operation is\n                already complete.\n        \"\"\"\n        result = await self.done()\n        if result:\n            return False\n        else:\n            await self._cancel()\n            return True\n\n    async def cancelled(self):\n        \"\"\"True if the operation was cancelled.\"\"\"\n        await self._refresh_and_update()\n        return (\n            self._operation.HasField(\"error\")\n            and self._operation.error.code == code_pb2.CANCELLED\n        )\n\n\ndef from_gapic(operation, operations_client, result_type, grpc_metadata=None, **kwargs):\n    \"\"\"Create an operation future from a gapic client.\n\n    This interacts with the long-running operations `service`_ (specific\n    to a given API) via a gapic client.\n\n    .. _service: https://github.com/googleapis/googleapis/blob/\\\n                 050400df0fdb16f63b63e9dee53819044bffc857/\\\n                 google/longrunning/operations.proto#L38\n\n    Args:\n        operation (google.longrunning.operations_pb2.Operation): The operation.\n        operations_client (google.api_core.operations_v1.OperationsClient):\n            The operations client.\n        result_type (:func:`type`): The protobuf result type.\n        grpc_metadata (Optional[List[Tuple[str, str]]]): Additional metadata to pass\n            to the rpc.\n        kwargs: Keyword args passed into the :class:`Operation` constructor.\n\n    Returns:\n        ~.api_core.operation.Operation: The operation future to track the given\n            operation.\n    \"\"\"\n    refresh = functools.partial(\n        operations_client.get_operation,\n        operation.name,\n        metadata=grpc_metadata,\n    )\n    cancel = functools.partial(\n        operations_client.cancel_operation,\n        operation.name,\n        metadata=grpc_metadata,\n    )\n    return AsyncOperation(operation, refresh, cancel, result_type, **kwargs)\n", "google/api_core/path_template.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Expand and validate URL path templates.\n\nThis module provides the :func:`expand` and :func:`validate` functions for\ninteracting with Google-style URL `path templates`_ which are commonly used\nin Google APIs for `resource names`_.\n\n.. _path templates: https://github.com/googleapis/googleapis/blob\n    /57e2d376ac7ef48681554204a3ba78a414f2c533/google/api/http.proto#L212\n.. _resource names: https://cloud.google.com/apis/design/resource_names\n\"\"\"\n\nfrom __future__ import unicode_literals\n\nfrom collections import deque\nimport copy\nimport functools\nimport re\n\n# Regular expression for extracting variable parts from a path template.\n# The variables can be expressed as:\n#\n# - \"*\": a single-segment positional variable, for example: \"books/*\"\n# - \"**\": a multi-segment positional variable, for example: \"shelf/**/book/*\"\n# - \"{name}\": a single-segment wildcard named variable, for example\n#   \"books/{name}\"\n# - \"{name=*}: same as above.\n# - \"{name=**}\": a multi-segment wildcard named variable, for example\n#   \"shelf/{name=**}\"\n# - \"{name=/path/*/**}\": a multi-segment named variable with a sub-template.\n_VARIABLE_RE = re.compile(\n    r\"\"\"\n    (  # Capture the entire variable expression\n        (?P<positional>\\*\\*?)  # Match & capture * and ** positional variables.\n        |\n        # Match & capture named variables {name}\n        {\n            (?P<name>[^/]+?)\n            # Optionally match and capture the named variable's template.\n            (?:=(?P<template>.+?))?\n        }\n    )\n    \"\"\",\n    re.VERBOSE,\n)\n\n# Segment expressions used for validating paths against a template.\n_SINGLE_SEGMENT_PATTERN = r\"([^/]+)\"\n_MULTI_SEGMENT_PATTERN = r\"(.+)\"\n\n\ndef _expand_variable_match(positional_vars, named_vars, match):\n    \"\"\"Expand a matched variable with its value.\n\n    Args:\n        positional_vars (list): A list of positional variables. This list will\n            be modified.\n        named_vars (dict): A dictionary of named variables.\n        match (re.Match): A regular expression match.\n\n    Returns:\n        str: The expanded variable to replace the match.\n\n    Raises:\n        ValueError: If a positional or named variable is required by the\n            template but not specified or if an unexpected template expression\n            is encountered.\n    \"\"\"\n    positional = match.group(\"positional\")\n    name = match.group(\"name\")\n    if name is not None:\n        try:\n            return str(named_vars[name])\n        except KeyError:\n            raise ValueError(\n                \"Named variable '{}' not specified and needed by template \"\n                \"`{}` at position {}\".format(name, match.string, match.start())\n            )\n    elif positional is not None:\n        try:\n            return str(positional_vars.pop(0))\n        except IndexError:\n            raise ValueError(\n                \"Positional variable not specified and needed by template \"\n                \"`{}` at position {}\".format(match.string, match.start())\n            )\n    else:\n        raise ValueError(\"Unknown template expression {}\".format(match.group(0)))\n\n\ndef expand(tmpl, *args, **kwargs):\n    \"\"\"Expand a path template with the given variables.\n\n    .. code-block:: python\n\n        >>> expand('users/*/messages/*', 'me', '123')\n        users/me/messages/123\n        >>> expand('/v1/{name=shelves/*/books/*}', name='shelves/1/books/3')\n        /v1/shelves/1/books/3\n\n    Args:\n        tmpl (str): The path template.\n        args: The positional variables for the path.\n        kwargs: The named variables for the path.\n\n    Returns:\n        str: The expanded path\n\n    Raises:\n        ValueError: If a positional or named variable is required by the\n            template but not specified or if an unexpected template expression\n            is encountered.\n    \"\"\"\n    replacer = functools.partial(_expand_variable_match, list(args), kwargs)\n    return _VARIABLE_RE.sub(replacer, tmpl)\n\n\ndef _replace_variable_with_pattern(match):\n    \"\"\"Replace a variable match with a pattern that can be used to validate it.\n\n    Args:\n        match (re.Match): A regular expression match\n\n    Returns:\n        str: A regular expression pattern that can be used to validate the\n            variable in an expanded path.\n\n    Raises:\n        ValueError: If an unexpected template expression is encountered.\n    \"\"\"\n    positional = match.group(\"positional\")\n    name = match.group(\"name\")\n    template = match.group(\"template\")\n    if name is not None:\n        if not template:\n            return _SINGLE_SEGMENT_PATTERN.format(name)\n        elif template == \"**\":\n            return _MULTI_SEGMENT_PATTERN.format(name)\n        else:\n            return _generate_pattern_for_template(template)\n    elif positional == \"*\":\n        return _SINGLE_SEGMENT_PATTERN\n    elif positional == \"**\":\n        return _MULTI_SEGMENT_PATTERN\n    else:\n        raise ValueError(\"Unknown template expression {}\".format(match.group(0)))\n\n\ndef _generate_pattern_for_template(tmpl):\n    \"\"\"Generate a pattern that can validate a path template.\n\n    Args:\n        tmpl (str): The path template\n\n    Returns:\n        str: A regular expression pattern that can be used to validate an\n            expanded path template.\n    \"\"\"\n    return _VARIABLE_RE.sub(_replace_variable_with_pattern, tmpl)\n\n\ndef get_field(request, field):\n    \"\"\"Get the value of a field from a given dictionary.\n\n    Args:\n        request (dict | Message): A dictionary or a Message object.\n        field (str): The key to the request in dot notation.\n\n    Returns:\n        The value of the field.\n    \"\"\"\n    parts = field.split(\".\")\n    value = request\n\n    for part in parts:\n        if not isinstance(value, dict):\n            value = getattr(value, part, None)\n        else:\n            value = value.get(part)\n    if isinstance(value, dict):\n        return\n    return value\n\n\ndef delete_field(request, field):\n    \"\"\"Delete the value of a field from a given dictionary.\n\n    Args:\n        request (dict | Message): A dictionary object or a Message.\n        field (str): The key to the request in dot notation.\n    \"\"\"\n    parts = deque(field.split(\".\"))\n    while len(parts) > 1:\n        part = parts.popleft()\n        if not isinstance(request, dict):\n            if hasattr(request, part):\n                request = getattr(request, part, None)\n            else:\n                return\n        else:\n            request = request.get(part)\n    part = parts.popleft()\n    if not isinstance(request, dict):\n        if hasattr(request, part):\n            request.ClearField(part)\n        else:\n            return\n    else:\n        request.pop(part, None)\n\n\ndef validate(tmpl, path):\n    \"\"\"Validate a path against the path template.\n\n    .. code-block:: python\n\n        >>> validate('users/*/messages/*', 'users/me/messages/123')\n        True\n        >>> validate('users/*/messages/*', 'users/me/drafts/123')\n        False\n        >>> validate('/v1/{name=shelves/*/books/*}', /v1/shelves/1/books/3)\n        True\n        >>> validate('/v1/{name=shelves/*/books/*}', /v1/shelves/1/tapes/3)\n        False\n\n    Args:\n        tmpl (str): The path template.\n        path (str): The expanded path.\n\n    Returns:\n        bool: True if the path matches.\n    \"\"\"\n    pattern = _generate_pattern_for_template(tmpl) + \"$\"\n    return True if re.match(pattern, path) is not None else False\n\n\ndef transcode(http_options, message=None, **request_kwargs):\n    \"\"\"Transcodes a grpc request pattern into a proper HTTP request following the rules outlined here,\n    https://github.com/googleapis/googleapis/blob/master/google/api/http.proto#L44-L312\n\n     Args:\n         http_options (list(dict)): A list of dicts which consist of these keys,\n             'method'    (str): The http method\n             'uri'       (str): The path template\n             'body'      (str): The body field name (optional)\n             (This is a simplified representation of the proto option `google.api.http`)\n\n         message (Message) : A request object (optional)\n         request_kwargs (dict) : A dict representing the request object\n\n     Returns:\n         dict: The transcoded request with these keys,\n             'method'        (str)   : The http method\n             'uri'           (str)   : The expanded uri\n             'body'          (dict | Message)  : A dict or a Message representing the body (optional)\n             'query_params'  (dict | Message)  : A dict or Message mapping query parameter variables and values\n\n     Raises:\n         ValueError: If the request does not match the given template.\n    \"\"\"\n    transcoded_value = message or request_kwargs\n    bindings = []\n    for http_option in http_options:\n        request = {}\n\n        # Assign path\n        uri_template = http_option[\"uri\"]\n        fields = [\n            (m.group(\"name\"), m.group(\"template\"))\n            for m in _VARIABLE_RE.finditer(uri_template)\n        ]\n        bindings.append((uri_template, fields))\n\n        path_args = {field: get_field(transcoded_value, field) for field, _ in fields}\n        request[\"uri\"] = expand(uri_template, **path_args)\n\n        if not validate(uri_template, request[\"uri\"]) or not all(path_args.values()):\n            continue\n\n        # Remove fields used in uri path from request\n        leftovers = copy.deepcopy(transcoded_value)\n        for path_field, _ in fields:\n            delete_field(leftovers, path_field)\n\n        # Assign body and query params\n        body = http_option.get(\"body\")\n\n        if body:\n            if body == \"*\":\n                request[\"body\"] = leftovers\n                if message:\n                    request[\"query_params\"] = message.__class__()\n                else:\n                    request[\"query_params\"] = {}\n            else:\n                try:\n                    if message:\n                        request[\"body\"] = getattr(leftovers, body)\n                        delete_field(leftovers, body)\n                    else:\n                        request[\"body\"] = leftovers.pop(body)\n                except (KeyError, AttributeError):\n                    continue\n                request[\"query_params\"] = leftovers\n        else:\n            request[\"query_params\"] = leftovers\n        request[\"method\"] = http_option[\"method\"]\n        return request\n\n    bindings_description = [\n        '\\n\\tURI: \"{}\"'\n        \"\\n\\tRequired request fields:\\n\\t\\t{}\".format(\n            uri,\n            \"\\n\\t\\t\".join(\n                [\n                    'field: \"{}\", pattern: \"{}\"'.format(n, p if p else \"*\")\n                    for n, p in fields\n                ]\n            ),\n        )\n        for uri, fields in bindings\n    ]\n\n    raise ValueError(\n        \"Invalid request.\"\n        \"\\nSome of the fields of the request message are either not initialized or \"\n        \"initialized with an invalid value.\"\n        \"\\nPlease make sure your request matches at least one accepted HTTP binding.\"\n        \"\\nTo match a binding the request message must have all the required fields \"\n        \"initialized with values matching their patterns as listed below:{}\".format(\n            \"\\n\".join(bindings_description)\n        )\n    )\n", "google/api_core/grpc_helpers_async.py": "# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"AsyncIO helpers for :mod:`grpc` supporting 3.7+.\n\nPlease combine more detailed docstring in grpc_helpers.py to use following\nfunctions. This module is implementing the same surface with AsyncIO semantics.\n\"\"\"\n\nimport asyncio\nimport functools\n\nfrom typing import AsyncGenerator, Generic, Iterator, Optional, TypeVar\n\nimport grpc\nfrom grpc import aio\n\nfrom google.api_core import exceptions, grpc_helpers\n\n# denotes the proto response type for grpc calls\nP = TypeVar(\"P\")\n\n# NOTE(lidiz) Alternatively, we can hack \"__getattribute__\" to perform\n# automatic patching for us. But that means the overhead of creating an\n# extra Python function spreads to every single send and receive.\n\n\nclass _WrappedCall(aio.Call):\n    def __init__(self):\n        self._call = None\n\n    def with_call(self, call):\n        \"\"\"Supplies the call object separately to keep __init__ clean.\"\"\"\n        self._call = call\n        return self\n\n    async def initial_metadata(self):\n        return await self._call.initial_metadata()\n\n    async def trailing_metadata(self):\n        return await self._call.trailing_metadata()\n\n    async def code(self):\n        return await self._call.code()\n\n    async def details(self):\n        return await self._call.details()\n\n    def cancelled(self):\n        return self._call.cancelled()\n\n    def done(self):\n        return self._call.done()\n\n    def time_remaining(self):\n        return self._call.time_remaining()\n\n    def cancel(self):\n        return self._call.cancel()\n\n    def add_done_callback(self, callback):\n        self._call.add_done_callback(callback)\n\n    async def wait_for_connection(self):\n        try:\n            await self._call.wait_for_connection()\n        except grpc.RpcError as rpc_error:\n            raise exceptions.from_grpc_error(rpc_error) from rpc_error\n\n\nclass _WrappedUnaryResponseMixin(Generic[P], _WrappedCall):\n    def __await__(self) -> Iterator[P]:\n        try:\n            response = yield from self._call.__await__()\n            return response\n        except grpc.RpcError as rpc_error:\n            raise exceptions.from_grpc_error(rpc_error) from rpc_error\n\n\nclass _WrappedStreamResponseMixin(Generic[P], _WrappedCall):\n    def __init__(self):\n        self._wrapped_async_generator = None\n\n    async def read(self) -> P:\n        try:\n            return await self._call.read()\n        except grpc.RpcError as rpc_error:\n            raise exceptions.from_grpc_error(rpc_error) from rpc_error\n\n    async def _wrapped_aiter(self) -> AsyncGenerator[P, None]:\n        try:\n            # NOTE(lidiz) coverage doesn't understand the exception raised from\n            # __anext__ method. It is covered by test case:\n            #     test_wrap_stream_errors_aiter_non_rpc_error\n            async for response in self._call:  # pragma: no branch\n                yield response\n        except grpc.RpcError as rpc_error:\n            raise exceptions.from_grpc_error(rpc_error) from rpc_error\n\n    def __aiter__(self) -> AsyncGenerator[P, None]:\n        if not self._wrapped_async_generator:\n            self._wrapped_async_generator = self._wrapped_aiter()\n        return self._wrapped_async_generator\n\n\nclass _WrappedStreamRequestMixin(_WrappedCall):\n    async def write(self, request):\n        try:\n            await self._call.write(request)\n        except grpc.RpcError as rpc_error:\n            raise exceptions.from_grpc_error(rpc_error) from rpc_error\n\n    async def done_writing(self):\n        try:\n            await self._call.done_writing()\n        except grpc.RpcError as rpc_error:\n            raise exceptions.from_grpc_error(rpc_error) from rpc_error\n\n\n# NOTE(lidiz) Implementing each individual class separately, so we don't\n# expose any API that should not be seen. E.g., __aiter__ in unary-unary\n# RPC, or __await__ in stream-stream RPC.\nclass _WrappedUnaryUnaryCall(_WrappedUnaryResponseMixin[P], aio.UnaryUnaryCall):\n    \"\"\"Wrapped UnaryUnaryCall to map exceptions.\"\"\"\n\n\nclass _WrappedUnaryStreamCall(_WrappedStreamResponseMixin[P], aio.UnaryStreamCall):\n    \"\"\"Wrapped UnaryStreamCall to map exceptions.\"\"\"\n\n\nclass _WrappedStreamUnaryCall(\n    _WrappedUnaryResponseMixin[P], _WrappedStreamRequestMixin, aio.StreamUnaryCall\n):\n    \"\"\"Wrapped StreamUnaryCall to map exceptions.\"\"\"\n\n\nclass _WrappedStreamStreamCall(\n    _WrappedStreamRequestMixin, _WrappedStreamResponseMixin[P], aio.StreamStreamCall\n):\n    \"\"\"Wrapped StreamStreamCall to map exceptions.\"\"\"\n\n\n# public type alias denoting the return type of async streaming gapic calls\nGrpcAsyncStream = _WrappedStreamResponseMixin[P]\n# public type alias denoting the return type of unary gapic calls\nAwaitableGrpcCall = _WrappedUnaryResponseMixin[P]\n\n\ndef _wrap_unary_errors(callable_):\n    \"\"\"Map errors for Unary-Unary async callables.\"\"\"\n\n    @functools.wraps(callable_)\n    def error_remapped_callable(*args, **kwargs):\n        call = callable_(*args, **kwargs)\n        return _WrappedUnaryUnaryCall().with_call(call)\n\n    return error_remapped_callable\n\n\ndef _wrap_stream_errors(callable_, wrapper_type):\n    \"\"\"Map errors for streaming RPC async callables.\"\"\"\n\n    @functools.wraps(callable_)\n    async def error_remapped_callable(*args, **kwargs):\n        call = callable_(*args, **kwargs)\n        call = wrapper_type().with_call(call)\n        await call.wait_for_connection()\n        return call\n\n    return error_remapped_callable\n\n\ndef wrap_errors(callable_):\n    \"\"\"Wrap a gRPC async callable and map :class:`grpc.RpcErrors` to\n    friendly error classes.\n\n    Errors raised by the gRPC callable are mapped to the appropriate\n    :class:`google.api_core.exceptions.GoogleAPICallError` subclasses. The\n    original `grpc.RpcError` (which is usually also a `grpc.Call`) is\n    available from the ``response`` property on the mapped exception. This\n    is useful for extracting metadata from the original error.\n\n    Args:\n        callable_ (Callable): A gRPC callable.\n\n    Returns: Callable: The wrapped gRPC callable.\n    \"\"\"\n    grpc_helpers._patch_callable_name(callable_)\n\n    if isinstance(callable_, aio.UnaryStreamMultiCallable):\n        return _wrap_stream_errors(callable_, _WrappedUnaryStreamCall)\n    elif isinstance(callable_, aio.StreamUnaryMultiCallable):\n        return _wrap_stream_errors(callable_, _WrappedStreamUnaryCall)\n    elif isinstance(callable_, aio.StreamStreamMultiCallable):\n        return _wrap_stream_errors(callable_, _WrappedStreamStreamCall)\n    else:\n        return _wrap_unary_errors(callable_)\n\n\ndef create_channel(\n    target,\n    credentials=None,\n    scopes=None,\n    ssl_credentials=None,\n    credentials_file=None,\n    quota_project_id=None,\n    default_scopes=None,\n    default_host=None,\n    compression=None,\n    attempt_direct_path: Optional[bool] = False,\n    **kwargs\n):\n    \"\"\"Create an AsyncIO secure channel with credentials.\n\n    Args:\n        target (str): The target service address in the format 'hostname:port'.\n        credentials (google.auth.credentials.Credentials): The credentials. If\n            not specified, then this function will attempt to ascertain the\n            credentials from the environment using :func:`google.auth.default`.\n        scopes (Sequence[str]): A optional list of scopes needed for this\n            service. These are only used when credentials are not specified and\n            are passed to :func:`google.auth.default`.\n        ssl_credentials (grpc.ChannelCredentials): Optional SSL channel\n            credentials. This can be used to specify different certificates.\n        credentials_file (str): A file with credentials that can be loaded with\n            :func:`google.auth.load_credentials_from_file`. This argument is\n            mutually exclusive with credentials.\n        quota_project_id (str): An optional project to use for billing and quota.\n        default_scopes (Sequence[str]): Default scopes passed by a Google client\n            library. Use 'scopes' for user-defined scopes.\n        default_host (str): The default endpoint. e.g., \"pubsub.googleapis.com\".\n        compression (grpc.Compression): An optional value indicating the\n            compression method to be used over the lifetime of the channel.\n        attempt_direct_path (Optional[bool]): If set, Direct Path will be attempted\n            when the request is made. Direct Path is only available within a Google\n            Compute Engine (GCE) environment and provides a proxyless connection\n            which increases the available throughput, reduces latency, and increases\n            reliability. Note:\n\n            - This argument should only be set in a GCE environment and for Services\n              that are known to support Direct Path.\n            - If this argument is set outside of GCE, then this request will fail\n              unless the back-end service happens to have configured fall-back to DNS.\n            - If the request causes a `ServiceUnavailable` response, it is recommended\n              that the client repeat the request with `attempt_direct_path` set to\n              `False` as the Service may not support Direct Path.\n            - Using `ssl_credentials` with `attempt_direct_path` set to `True` will\n              result in `ValueError` as this combination  is not yet supported.\n\n        kwargs: Additional key-word args passed to :func:`aio.secure_channel`.\n\n    Returns:\n        aio.Channel: The created channel.\n\n    Raises:\n        google.api_core.DuplicateCredentialArgs: If both a credentials object and credentials_file are passed.\n        ValueError: If `ssl_credentials` is set and `attempt_direct_path` is set to `True`.\n    \"\"\"\n\n    # If `ssl_credentials` is set and `attempt_direct_path` is set to `True`,\n    # raise ValueError as this is not yet supported.\n    # See https://github.com/googleapis/python-api-core/issues/590\n    if ssl_credentials and attempt_direct_path:\n        raise ValueError(\"Using ssl_credentials with Direct Path is not supported\")\n\n    composite_credentials = grpc_helpers._create_composite_credentials(\n        credentials=credentials,\n        credentials_file=credentials_file,\n        scopes=scopes,\n        default_scopes=default_scopes,\n        ssl_credentials=ssl_credentials,\n        quota_project_id=quota_project_id,\n        default_host=default_host,\n    )\n\n    if attempt_direct_path:\n        target = grpc_helpers._modify_target_for_direct_path(target)\n\n    return aio.secure_channel(\n        target, composite_credentials, compression=compression, **kwargs\n    )\n\n\nclass FakeUnaryUnaryCall(_WrappedUnaryUnaryCall):\n    \"\"\"Fake implementation for unary-unary RPCs.\n\n    It is a dummy object for response message. Supply the intended response\n    upon the initialization, and the coroutine will return the exact response\n    message.\n    \"\"\"\n\n    def __init__(self, response=object()):\n        self.response = response\n        self._future = asyncio.get_event_loop().create_future()\n        self._future.set_result(self.response)\n\n    def __await__(self):\n        response = yield from self._future.__await__()\n        return response\n\n\nclass FakeStreamUnaryCall(_WrappedStreamUnaryCall):\n    \"\"\"Fake implementation for stream-unary RPCs.\n\n    It is a dummy object for response message. Supply the intended response\n    upon the initialization, and the coroutine will return the exact response\n    message.\n    \"\"\"\n\n    def __init__(self, response=object()):\n        self.response = response\n        self._future = asyncio.get_event_loop().create_future()\n        self._future.set_result(self.response)\n\n    def __await__(self):\n        response = yield from self._future.__await__()\n        return response\n\n    async def wait_for_connection(self):\n        pass\n", "google/api_core/version_header.py": "# Copyright 2024 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nAPI_VERSION_METADATA_KEY = \"x-goog-api-version\"\n\n\ndef to_api_version_header(version_identifier):\n    \"\"\"Returns data for the API Version header for the given `version_identifier`.\n\n    Args:\n        version_identifier (str): The version identifier to be used in the\n            tuple returned.\n\n    Returns:\n        Tuple(str, str): A tuple containing the API Version metadata key and\n            value.\n    \"\"\"\n    return (API_VERSION_METADATA_KEY, version_identifier)\n", "google/api_core/bidi.py": "# Copyright 2017, Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Bi-directional streaming RPC helpers.\"\"\"\n\nimport collections\nimport datetime\nimport logging\nimport queue as queue_module\nimport threading\nimport time\n\nfrom google.api_core import exceptions\n\n_LOGGER = logging.getLogger(__name__)\n_BIDIRECTIONAL_CONSUMER_NAME = \"Thread-ConsumeBidirectionalStream\"\n\n\nclass _RequestQueueGenerator(object):\n    \"\"\"A helper for sending requests to a gRPC stream from a Queue.\n\n    This generator takes requests off a given queue and yields them to gRPC.\n\n    This helper is useful when you have an indeterminate, indefinite, or\n    otherwise open-ended set of requests to send through a request-streaming\n    (or bidirectional) RPC.\n\n    The reason this is necessary is because gRPC takes an iterator as the\n    request for request-streaming RPCs. gRPC consumes this iterator in another\n    thread to allow it to block while generating requests for the stream.\n    However, if the generator blocks indefinitely gRPC will not be able to\n    clean up the thread as it'll be blocked on `next(iterator)` and not be able\n    to check the channel status to stop iterating. This helper mitigates that\n    by waiting on the queue with a timeout and checking the RPC state before\n    yielding.\n\n    Finally, it allows for retrying without swapping queues because if it does\n    pull an item off the queue when the RPC is inactive, it'll immediately put\n    it back and then exit. This is necessary because yielding the item in this\n    case will cause gRPC to discard it. In practice, this means that the order\n    of messages is not guaranteed. If such a thing is necessary it would be\n    easy to use a priority queue.\n\n    Example::\n\n        requests = request_queue_generator(q)\n        call = stub.StreamingRequest(iter(requests))\n        requests.call = call\n\n        for response in call:\n            print(response)\n            q.put(...)\n\n    Note that it is possible to accomplish this behavior without \"spinning\"\n    (using a queue timeout). One possible way would be to use more threads to\n    multiplex the grpc end event with the queue, another possible way is to\n    use selectors and a custom event/queue object. Both of these approaches\n    are significant from an engineering perspective for small benefit - the\n    CPU consumed by spinning is pretty minuscule.\n\n    Args:\n        queue (queue_module.Queue): The request queue.\n        period (float): The number of seconds to wait for items from the queue\n            before checking if the RPC is cancelled. In practice, this\n            determines the maximum amount of time the request consumption\n            thread will live after the RPC is cancelled.\n        initial_request (Union[protobuf.Message,\n                Callable[None, protobuf.Message]]): The initial request to\n            yield. This is done independently of the request queue to allow fo\n            easily restarting streams that require some initial configuration\n            request.\n    \"\"\"\n\n    def __init__(self, queue, period=1, initial_request=None):\n        self._queue = queue\n        self._period = period\n        self._initial_request = initial_request\n        self.call = None\n\n    def _is_active(self):\n        # Note: there is a possibility that this starts *before* the call\n        # property is set. So we have to check if self.call is set before\n        # seeing if it's active. We need to return True if self.call is None.\n        # See https://github.com/googleapis/python-api-core/issues/560.\n        return self.call is None or self.call.is_active()\n\n    def __iter__(self):\n        if self._initial_request is not None:\n            if callable(self._initial_request):\n                yield self._initial_request()\n            else:\n                yield self._initial_request\n\n        while True:\n            try:\n                item = self._queue.get(timeout=self._period)\n            except queue_module.Empty:\n                if not self._is_active():\n                    _LOGGER.debug(\n                        \"Empty queue and inactive call, exiting request \" \"generator.\"\n                    )\n                    return\n                else:\n                    # call is still active, keep waiting for queue items.\n                    continue\n\n            # The consumer explicitly sent \"None\", indicating that the request\n            # should end.\n            if item is None:\n                _LOGGER.debug(\"Cleanly exiting request generator.\")\n                return\n\n            if not self._is_active():\n                # We have an item, but the call is closed. We should put the\n                # item back on the queue so that the next call can consume it.\n                self._queue.put(item)\n                _LOGGER.debug(\n                    \"Inactive call, replacing item on queue and exiting \"\n                    \"request generator.\"\n                )\n                return\n\n            yield item\n\n\nclass _Throttle(object):\n    \"\"\"A context manager limiting the total entries in a sliding time window.\n\n    If more than ``access_limit`` attempts are made to enter the context manager\n    instance in the last ``time window`` interval, the exceeding requests block\n    until enough time elapses.\n\n    The context manager instances are thread-safe and can be shared between\n    multiple threads. If multiple requests are blocked and waiting to enter,\n    the exact order in which they are allowed to proceed is not determined.\n\n    Example::\n\n        max_three_per_second = _Throttle(\n            access_limit=3, time_window=datetime.timedelta(seconds=1)\n        )\n\n        for i in range(5):\n            with max_three_per_second as time_waited:\n                print(\"{}: Waited {} seconds to enter\".format(i, time_waited))\n\n    Args:\n        access_limit (int): the maximum number of entries allowed in the time window\n        time_window (datetime.timedelta): the width of the sliding time window\n    \"\"\"\n\n    def __init__(self, access_limit, time_window):\n        if access_limit < 1:\n            raise ValueError(\"access_limit argument must be positive\")\n\n        if time_window <= datetime.timedelta(0):\n            raise ValueError(\"time_window argument must be a positive timedelta\")\n\n        self._time_window = time_window\n        self._access_limit = access_limit\n        self._past_entries = collections.deque(\n            maxlen=access_limit\n        )  # least recent first\n        self._entry_lock = threading.Lock()\n\n    def __enter__(self):\n        with self._entry_lock:\n            cutoff_time = datetime.datetime.now() - self._time_window\n\n            # drop the entries that are too old, as they are no longer relevant\n            while self._past_entries and self._past_entries[0] < cutoff_time:\n                self._past_entries.popleft()\n\n            if len(self._past_entries) < self._access_limit:\n                self._past_entries.append(datetime.datetime.now())\n                return 0.0  # no waiting was needed\n\n            to_wait = (self._past_entries[0] - cutoff_time).total_seconds()\n            time.sleep(to_wait)\n\n            self._past_entries.append(datetime.datetime.now())\n            return to_wait\n\n    def __exit__(self, *_):\n        pass\n\n    def __repr__(self):\n        return \"{}(access_limit={}, time_window={})\".format(\n            self.__class__.__name__, self._access_limit, repr(self._time_window)\n        )\n\n\nclass BidiRpc(object):\n    \"\"\"A helper for consuming a bi-directional streaming RPC.\n\n    This maps gRPC's built-in interface which uses a request iterator and a\n    response iterator into a socket-like :func:`send` and :func:`recv`. This\n    is a more useful pattern for long-running or asymmetric streams (streams\n    where there is not a direct correlation between the requests and\n    responses).\n\n    Example::\n\n        initial_request = example_pb2.StreamingRpcRequest(\n            setting='example')\n        rpc = BidiRpc(\n            stub.StreamingRpc,\n            initial_request=initial_request,\n            metadata=[('name', 'value')]\n        )\n\n        rpc.open()\n\n        while rpc.is_active():\n            print(rpc.recv())\n            rpc.send(example_pb2.StreamingRpcRequest(\n                data='example'))\n\n    This does *not* retry the stream on errors. See :class:`ResumableBidiRpc`.\n\n    Args:\n        start_rpc (grpc.StreamStreamMultiCallable): The gRPC method used to\n            start the RPC.\n        initial_request (Union[protobuf.Message,\n                Callable[None, protobuf.Message]]): The initial request to\n            yield. This is useful if an initial request is needed to start the\n            stream.\n        metadata (Sequence[Tuple(str, str)]): RPC metadata to include in\n            the request.\n    \"\"\"\n\n    def __init__(self, start_rpc, initial_request=None, metadata=None):\n        self._start_rpc = start_rpc\n        self._initial_request = initial_request\n        self._rpc_metadata = metadata\n        self._request_queue = queue_module.Queue()\n        self._request_generator = None\n        self._is_active = False\n        self._callbacks = []\n        self.call = None\n\n    def add_done_callback(self, callback):\n        \"\"\"Adds a callback that will be called when the RPC terminates.\n\n        This occurs when the RPC errors or is successfully terminated.\n\n        Args:\n            callback (Callable[[grpc.Future], None]): The callback to execute.\n                It will be provided with the same gRPC future as the underlying\n                stream which will also be a :class:`grpc.Call`.\n        \"\"\"\n        self._callbacks.append(callback)\n\n    def _on_call_done(self, future):\n        # This occurs when the RPC errors or is successfully terminated.\n        # Note that grpc's \"future\" here can also be a grpc.RpcError.\n        # See note in https://github.com/grpc/grpc/issues/10885#issuecomment-302651331\n        # that `grpc.RpcError` is also `grpc.call`.\n        for callback in self._callbacks:\n            callback(future)\n\n    def open(self):\n        \"\"\"Opens the stream.\"\"\"\n        if self.is_active:\n            raise ValueError(\"Can not open an already open stream.\")\n\n        request_generator = _RequestQueueGenerator(\n            self._request_queue, initial_request=self._initial_request\n        )\n        try:\n            call = self._start_rpc(iter(request_generator), metadata=self._rpc_metadata)\n        except exceptions.GoogleAPICallError as exc:\n            # The original `grpc.RpcError` (which is usually also a `grpc.Call`) is\n            # available from the ``response`` property on the mapped exception.\n            self._on_call_done(exc.response)\n            raise\n\n        request_generator.call = call\n\n        # TODO: api_core should expose the future interface for wrapped\n        # callables as well.\n        if hasattr(call, \"_wrapped\"):  # pragma: NO COVER\n            call._wrapped.add_done_callback(self._on_call_done)\n        else:\n            call.add_done_callback(self._on_call_done)\n\n        self._request_generator = request_generator\n        self.call = call\n\n    def close(self):\n        \"\"\"Closes the stream.\"\"\"\n        if self.call is None:\n            return\n\n        self._request_queue.put(None)\n        self.call.cancel()\n        self._request_generator = None\n        # Don't set self.call to None. Keep it around so that send/recv can\n        # raise the error.\n\n    def send(self, request):\n        \"\"\"Queue a message to be sent on the stream.\n\n        Send is non-blocking.\n\n        If the underlying RPC has been closed, this will raise.\n\n        Args:\n            request (protobuf.Message): The request to send.\n        \"\"\"\n        if self.call is None:\n            raise ValueError(\"Can not send() on an RPC that has never been open()ed.\")\n\n        # Don't use self.is_active(), as ResumableBidiRpc will overload it\n        # to mean something semantically different.\n        if self.call.is_active():\n            self._request_queue.put(request)\n        else:\n            # calling next should cause the call to raise.\n            next(self.call)\n\n    def recv(self):\n        \"\"\"Wait for a message to be returned from the stream.\n\n        Recv is blocking.\n\n        If the underlying RPC has been closed, this will raise.\n\n        Returns:\n            protobuf.Message: The received message.\n        \"\"\"\n        if self.call is None:\n            raise ValueError(\"Can not recv() on an RPC that has never been open()ed.\")\n\n        return next(self.call)\n\n    @property\n    def is_active(self):\n        \"\"\"bool: True if this stream is currently open and active.\"\"\"\n        return self.call is not None and self.call.is_active()\n\n    @property\n    def pending_requests(self):\n        \"\"\"int: Returns an estimate of the number of queued requests.\"\"\"\n        return self._request_queue.qsize()\n\n\ndef _never_terminate(future_or_error):\n    \"\"\"By default, no errors cause BiDi termination.\"\"\"\n    return False\n\n\nclass ResumableBidiRpc(BidiRpc):\n    \"\"\"A :class:`BidiRpc` that can automatically resume the stream on errors.\n\n    It uses the ``should_recover`` arg to determine if it should re-establish\n    the stream on error.\n\n    Example::\n\n        def should_recover(exc):\n            return (\n                isinstance(exc, grpc.RpcError) and\n                exc.code() == grpc.StatusCode.UNAVAILABLE)\n\n        initial_request = example_pb2.StreamingRpcRequest(\n            setting='example')\n\n        metadata = [('header_name', 'value')]\n\n        rpc = ResumableBidiRpc(\n            stub.StreamingRpc,\n            should_recover=should_recover,\n            initial_request=initial_request,\n            metadata=metadata\n        )\n\n        rpc.open()\n\n        while rpc.is_active():\n            print(rpc.recv())\n            rpc.send(example_pb2.StreamingRpcRequest(\n                data='example'))\n\n    Args:\n        start_rpc (grpc.StreamStreamMultiCallable): The gRPC method used to\n            start the RPC.\n        initial_request (Union[protobuf.Message,\n                Callable[None, protobuf.Message]]): The initial request to\n            yield. This is useful if an initial request is needed to start the\n            stream.\n        should_recover (Callable[[Exception], bool]): A function that returns\n            True if the stream should be recovered. This will be called\n            whenever an error is encountered on the stream.\n        should_terminate (Callable[[Exception], bool]): A function that returns\n            True if the stream should be terminated. This will be called\n            whenever an error is encountered on the stream.\n        metadata Sequence[Tuple(str, str)]: RPC metadata to include in\n            the request.\n        throttle_reopen (bool): If ``True``, throttling will be applied to\n            stream reopen calls. Defaults to ``False``.\n    \"\"\"\n\n    def __init__(\n        self,\n        start_rpc,\n        should_recover,\n        should_terminate=_never_terminate,\n        initial_request=None,\n        metadata=None,\n        throttle_reopen=False,\n    ):\n        super(ResumableBidiRpc, self).__init__(start_rpc, initial_request, metadata)\n        self._should_recover = should_recover\n        self._should_terminate = should_terminate\n        self._operational_lock = threading.RLock()\n        self._finalized = False\n        self._finalize_lock = threading.Lock()\n\n        if throttle_reopen:\n            self._reopen_throttle = _Throttle(\n                access_limit=5, time_window=datetime.timedelta(seconds=10)\n            )\n        else:\n            self._reopen_throttle = None\n\n    def _finalize(self, result):\n        with self._finalize_lock:\n            if self._finalized:\n                return\n\n            for callback in self._callbacks:\n                callback(result)\n\n            self._finalized = True\n\n    def _on_call_done(self, future):\n        # Unlike the base class, we only execute the callbacks on a terminal\n        # error, not for errors that we can recover from. Note that grpc's\n        # \"future\" here is also a grpc.RpcError.\n        with self._operational_lock:\n            if self._should_terminate(future):\n                self._finalize(future)\n            elif not self._should_recover(future):\n                self._finalize(future)\n            else:\n                _LOGGER.debug(\"Re-opening stream from gRPC callback.\")\n                self._reopen()\n\n    def _reopen(self):\n        with self._operational_lock:\n            # Another thread already managed to re-open this stream.\n            if self.call is not None and self.call.is_active():\n                _LOGGER.debug(\"Stream was already re-established.\")\n                return\n\n            self.call = None\n            # Request generator should exit cleanly since the RPC its bound to\n            # has exited.\n            self._request_generator = None\n\n            # Note: we do not currently do any sort of backoff here. The\n            # assumption is that re-establishing the stream under normal\n            # circumstances will happen in intervals greater than 60s.\n            # However, it is possible in a degenerative case that the server\n            # closes the stream rapidly which would lead to thrashing here,\n            # but hopefully in those cases the server would return a non-\n            # retryable error.\n\n            try:\n                if self._reopen_throttle:\n                    with self._reopen_throttle:\n                        self.open()\n                else:\n                    self.open()\n            # If re-opening or re-calling the method fails for any reason,\n            # consider it a terminal error and finalize the stream.\n            except Exception as exc:\n                _LOGGER.debug(\"Failed to re-open stream due to %s\", exc)\n                self._finalize(exc)\n                raise\n\n            _LOGGER.info(\"Re-established stream\")\n\n    def _recoverable(self, method, *args, **kwargs):\n        \"\"\"Wraps a method to recover the stream and retry on error.\n\n        If a retryable error occurs while making the call, then the stream will\n        be re-opened and the method will be retried. This happens indefinitely\n        so long as the error is a retryable one. If an error occurs while\n        re-opening the stream, then this method will raise immediately and\n        trigger finalization of this object.\n\n        Args:\n            method (Callable[..., Any]): The method to call.\n            args: The args to pass to the method.\n            kwargs: The kwargs to pass to the method.\n        \"\"\"\n        while True:\n            try:\n                return method(*args, **kwargs)\n\n            except Exception as exc:\n                with self._operational_lock:\n                    _LOGGER.debug(\"Call to retryable %r caused %s.\", method, exc)\n\n                    if self._should_terminate(exc):\n                        self.close()\n                        _LOGGER.debug(\"Terminating %r due to %s.\", method, exc)\n                        self._finalize(exc)\n                        break\n\n                    if not self._should_recover(exc):\n                        self.close()\n                        _LOGGER.debug(\"Not retrying %r due to %s.\", method, exc)\n                        self._finalize(exc)\n                        raise exc\n\n                    _LOGGER.debug(\"Re-opening stream from retryable %r.\", method)\n                    self._reopen()\n\n    def _send(self, request):\n        # Grab a reference to the RPC call. Because another thread (notably\n        # the gRPC error thread) can modify self.call (by invoking reopen),\n        # we should ensure our reference can not change underneath us.\n        # If self.call is modified (such as replaced with a new RPC call) then\n        # this will use the \"old\" RPC, which should result in the same\n        # exception passed into gRPC's error handler being raised here, which\n        # will be handled by the usual error handling in retryable.\n        with self._operational_lock:\n            call = self.call\n\n        if call is None:\n            raise ValueError(\"Can not send() on an RPC that has never been open()ed.\")\n\n        # Don't use self.is_active(), as ResumableBidiRpc will overload it\n        # to mean something semantically different.\n        if call.is_active():\n            self._request_queue.put(request)\n            pass\n        else:\n            # calling next should cause the call to raise.\n            next(call)\n\n    def send(self, request):\n        return self._recoverable(self._send, request)\n\n    def _recv(self):\n        with self._operational_lock:\n            call = self.call\n\n        if call is None:\n            raise ValueError(\"Can not recv() on an RPC that has never been open()ed.\")\n\n        return next(call)\n\n    def recv(self):\n        return self._recoverable(self._recv)\n\n    def close(self):\n        self._finalize(None)\n        super(ResumableBidiRpc, self).close()\n\n    @property\n    def is_active(self):\n        \"\"\"bool: True if this stream is currently open and active.\"\"\"\n        # Use the operational lock. It's entirely possible for something\n        # to check the active state *while* the RPC is being retried.\n        # Also, use finalized to track the actual terminal state here.\n        # This is because if the stream is re-established by the gRPC thread\n        # it's technically possible to check this between when gRPC marks the\n        # RPC as inactive and when gRPC executes our callback that re-opens\n        # the stream.\n        with self._operational_lock:\n            return self.call is not None and not self._finalized\n\n\nclass BackgroundConsumer(object):\n    \"\"\"A bi-directional stream consumer that runs in a separate thread.\n\n    This maps the consumption of a stream into a callback-based model. It also\n    provides :func:`pause` and :func:`resume` to allow for flow-control.\n\n    Example::\n\n        def should_recover(exc):\n            return (\n                isinstance(exc, grpc.RpcError) and\n                exc.code() == grpc.StatusCode.UNAVAILABLE)\n\n        initial_request = example_pb2.StreamingRpcRequest(\n            setting='example')\n\n        rpc = ResumeableBidiRpc(\n            stub.StreamingRpc,\n            initial_request=initial_request,\n            should_recover=should_recover)\n\n        def on_response(response):\n            print(response)\n\n        consumer = BackgroundConsumer(rpc, on_response)\n        consumer.start()\n\n    Note that error handling *must* be done by using the provided\n    ``bidi_rpc``'s ``add_done_callback``. This helper will automatically exit\n    whenever the RPC itself exits and will not provide any error details.\n\n    Args:\n        bidi_rpc (BidiRpc): The RPC to consume. Should not have been\n            ``open()``ed yet.\n        on_response (Callable[[protobuf.Message], None]): The callback to\n            be called for every response on the stream.\n    \"\"\"\n\n    def __init__(self, bidi_rpc, on_response):\n        self._bidi_rpc = bidi_rpc\n        self._on_response = on_response\n        self._paused = False\n        self._wake = threading.Condition()\n        self._thread = None\n        self._operational_lock = threading.Lock()\n\n    def _on_call_done(self, future):\n        # Resume the thread if it's paused, this prevents blocking forever\n        # when the RPC has terminated.\n        self.resume()\n\n    def _thread_main(self, ready):\n        try:\n            ready.set()\n            self._bidi_rpc.add_done_callback(self._on_call_done)\n            self._bidi_rpc.open()\n\n            while self._bidi_rpc.is_active:\n                # Do not allow the paused status to change at all during this\n                # section. There is a condition where we could be resumed\n                # between checking if we are paused and calling wake.wait(),\n                # which means that we will miss the notification to wake up\n                # (oops!) and wait for a notification that will never come.\n                # Keeping the lock throughout avoids that.\n                # In the future, we could use `Condition.wait_for` if we drop\n                # Python 2.7.\n                # See: https://github.com/googleapis/python-api-core/issues/211\n                with self._wake:\n                    while self._paused:\n                        _LOGGER.debug(\"paused, waiting for waking.\")\n                        self._wake.wait()\n                        _LOGGER.debug(\"woken.\")\n\n                _LOGGER.debug(\"waiting for recv.\")\n                response = self._bidi_rpc.recv()\n                _LOGGER.debug(\"recved response.\")\n                self._on_response(response)\n\n        except exceptions.GoogleAPICallError as exc:\n            _LOGGER.debug(\n                \"%s caught error %s and will exit. Generally this is due to \"\n                \"the RPC itself being cancelled and the error will be \"\n                \"surfaced to the calling code.\",\n                _BIDIRECTIONAL_CONSUMER_NAME,\n                exc,\n                exc_info=True,\n            )\n\n        except Exception as exc:\n            _LOGGER.exception(\n                \"%s caught unexpected exception %s and will exit.\",\n                _BIDIRECTIONAL_CONSUMER_NAME,\n                exc,\n            )\n\n        _LOGGER.info(\"%s exiting\", _BIDIRECTIONAL_CONSUMER_NAME)\n\n    def start(self):\n        \"\"\"Start the background thread and begin consuming the thread.\"\"\"\n        with self._operational_lock:\n            ready = threading.Event()\n            thread = threading.Thread(\n                name=_BIDIRECTIONAL_CONSUMER_NAME,\n                target=self._thread_main,\n                args=(ready,),\n            )\n            thread.daemon = True\n            thread.start()\n            # Other parts of the code rely on `thread.is_alive` which\n            # isn't sufficient to know if a thread is active, just that it may\n            # soon be active. This can cause races. Further protect\n            # against races by using a ready event and wait on it to be set.\n            ready.wait()\n            self._thread = thread\n            _LOGGER.debug(\"Started helper thread %s\", thread.name)\n\n    def stop(self):\n        \"\"\"Stop consuming the stream and shutdown the background thread.\"\"\"\n        with self._operational_lock:\n            self._bidi_rpc.close()\n\n            if self._thread is not None:\n                # Resume the thread to wake it up in case it is sleeping.\n                self.resume()\n                # The daemonized thread may itself block, so don't wait\n                # for it longer than a second.\n                self._thread.join(1.0)\n                if self._thread.is_alive():  # pragma: NO COVER\n                    _LOGGER.warning(\"Background thread did not exit.\")\n\n            self._thread = None\n\n    @property\n    def is_active(self):\n        \"\"\"bool: True if the background thread is active.\"\"\"\n        return self._thread is not None and self._thread.is_alive()\n\n    def pause(self):\n        \"\"\"Pauses the response stream.\n\n        This does *not* pause the request stream.\n        \"\"\"\n        with self._wake:\n            self._paused = True\n\n    def resume(self):\n        \"\"\"Resumes the response stream.\"\"\"\n        with self._wake:\n            self._paused = False\n            self._wake.notify_all()\n\n    @property\n    def is_paused(self):\n        \"\"\"bool: True if the response stream is paused.\"\"\"\n        return self._paused\n", "google/api_core/page_iterator.py": "# Copyright 2015 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Iterators for paging through paged API methods.\n\nThese iterators simplify the process of paging through API responses\nwhere the request takes a page token and the response is a list of results with\na token for the next page. See `list pagination`_ in the Google API Style Guide\nfor more details.\n\n.. _list pagination:\n    https://cloud.google.com/apis/design/design_patterns#list_pagination\n\nAPI clients that have methods that follow the list pagination pattern can\nreturn an :class:`.Iterator`. You can use this iterator to get **all** of\nthe results across all pages::\n\n    >>> results_iterator = client.list_resources()\n    >>> list(results_iterator)  # Convert to a list (consumes all values).\n\nOr you can walk your way through items and call off the search early if\nyou find what you're looking for (resulting in possibly fewer requests)::\n\n    >>> for resource in results_iterator:\n    ...     print(resource.name)\n    ...     if not resource.is_valid:\n    ...         break\n\nAt any point, you may check the number of items consumed by referencing the\n``num_results`` property of the iterator::\n\n    >>> for my_item in results_iterator:\n    ...     if results_iterator.num_results >= 10:\n    ...         break\n\nWhen iterating, not every new item will send a request to the server.\nTo iterate based on each page of items (where a page corresponds to\na request)::\n\n    >>> for page in results_iterator.pages:\n    ...     print('=' * 20)\n    ...     print('    Page number: {:d}'.format(iterator.page_number))\n    ...     print('  Items in page: {:d}'.format(page.num_items))\n    ...     print('     First item: {!r}'.format(next(page)))\n    ...     print('Items remaining: {:d}'.format(page.remaining))\n    ...     print('Next page token: {}'.format(iterator.next_page_token))\n    ====================\n        Page number: 1\n      Items in page: 1\n         First item: <MyItemClass at 0x7f1d3cccf690>\n    Items remaining: 0\n    Next page token: eav1OzQB0OM8rLdGXOEsyQWSG\n    ====================\n        Page number: 2\n      Items in page: 19\n         First item: <MyItemClass at 0x7f1d3cccffd0>\n    Items remaining: 18\n    Next page token: None\n\nThen, for each page you can get all the resources on that page by iterating\nthrough it or using :func:`list`::\n\n    >>> list(page)\n    [\n        <MyItemClass at 0x7fd64a098ad0>,\n        <MyItemClass at 0x7fd64a098ed0>,\n        <MyItemClass at 0x7fd64a098e90>,\n    ]\n\"\"\"\n\nimport abc\n\n\nclass Page(object):\n    \"\"\"Single page of results in an iterator.\n\n    Args:\n        parent (google.api_core.page_iterator.Iterator): The iterator that owns\n            the current page.\n        items (Sequence[Any]): An iterable (that also defines __len__) of items\n            from a raw API response.\n        item_to_value (Callable[google.api_core.page_iterator.Iterator, Any]):\n            Callable to convert an item from the type in the raw API response\n            into the native object. Will be called with the iterator and a\n            single item.\n        raw_page Optional[google.protobuf.message.Message]:\n            The raw page response.\n    \"\"\"\n\n    def __init__(self, parent, items, item_to_value, raw_page=None):\n        self._parent = parent\n        self._num_items = len(items)\n        self._remaining = self._num_items\n        self._item_iter = iter(items)\n        self._item_to_value = item_to_value\n        self._raw_page = raw_page\n\n    @property\n    def raw_page(self):\n        \"\"\"google.protobuf.message.Message\"\"\"\n        return self._raw_page\n\n    @property\n    def num_items(self):\n        \"\"\"int: Total items in the page.\"\"\"\n        return self._num_items\n\n    @property\n    def remaining(self):\n        \"\"\"int: Remaining items in the page.\"\"\"\n        return self._remaining\n\n    def __iter__(self):\n        \"\"\"The :class:`Page` is an iterator of items.\"\"\"\n        return self\n\n    def __next__(self):\n        \"\"\"Get the next value in the page.\"\"\"\n        item = next(self._item_iter)\n        result = self._item_to_value(self._parent, item)\n        # Since we've successfully got the next value from the\n        # iterator, we update the number of remaining.\n        self._remaining -= 1\n        return result\n\n\ndef _item_to_value_identity(iterator, item):\n    \"\"\"An item to value transformer that returns the item un-changed.\"\"\"\n    # pylint: disable=unused-argument\n    # We are conforming to the interface defined by Iterator.\n    return item\n\n\nclass Iterator(object, metaclass=abc.ABCMeta):\n    \"\"\"A generic class for iterating through API list responses.\n\n    Args:\n        client(google.cloud.client.Client): The API client.\n        item_to_value (Callable[google.api_core.page_iterator.Iterator, Any]):\n            Callable to convert an item from the type in the raw API response\n            into the native object. Will be called with the iterator and a\n            single item.\n        page_token (str): A token identifying a page in a result set to start\n            fetching results from.\n        max_results (int): The maximum number of results to fetch.\n    \"\"\"\n\n    def __init__(\n        self,\n        client,\n        item_to_value=_item_to_value_identity,\n        page_token=None,\n        max_results=None,\n    ):\n        self._started = False\n        self.__active_iterator = None\n\n        self.client = client\n        \"\"\"Optional[Any]: The client that created this iterator.\"\"\"\n        self.item_to_value = item_to_value\n        \"\"\"Callable[Iterator, Any]: Callable to convert an item from the type\n            in the raw API response into the native object. Will be called with\n            the iterator and a\n            single item.\n        \"\"\"\n        self.max_results = max_results\n        \"\"\"int: The maximum number of results to fetch\"\"\"\n\n        # The attributes below will change over the life of the iterator.\n        self.page_number = 0\n        \"\"\"int: The current page of results.\"\"\"\n        self.next_page_token = page_token\n        \"\"\"str: The token for the next page of results. If this is set before\n            the iterator starts, it effectively offsets the iterator to a\n            specific starting point.\"\"\"\n        self.num_results = 0\n        \"\"\"int: The total number of results fetched so far.\"\"\"\n\n    @property\n    def pages(self):\n        \"\"\"Iterator of pages in the response.\n\n        returns:\n            types.GeneratorType[google.api_core.page_iterator.Page]: A\n                generator of page instances.\n\n        raises:\n            ValueError: If the iterator has already been started.\n        \"\"\"\n        if self._started:\n            raise ValueError(\"Iterator has already started\", self)\n        self._started = True\n        return self._page_iter(increment=True)\n\n    def _items_iter(self):\n        \"\"\"Iterator for each item returned.\"\"\"\n        for page in self._page_iter(increment=False):\n            for item in page:\n                self.num_results += 1\n                yield item\n\n    def __iter__(self):\n        \"\"\"Iterator for each item returned.\n\n        Returns:\n            types.GeneratorType[Any]: A generator of items from the API.\n\n        Raises:\n            ValueError: If the iterator has already been started.\n        \"\"\"\n        if self._started:\n            raise ValueError(\"Iterator has already started\", self)\n        self._started = True\n        return self._items_iter()\n\n    def __next__(self):\n        if self.__active_iterator is None:\n            self.__active_iterator = iter(self)\n        return next(self.__active_iterator)\n\n    def _page_iter(self, increment):\n        \"\"\"Generator of pages of API responses.\n\n        Args:\n            increment (bool): Flag indicating if the total number of results\n                should be incremented on each page. This is useful since a page\n                iterator will want to increment by results per page while an\n                items iterator will want to increment per item.\n\n        Yields:\n            Page: each page of items from the API.\n        \"\"\"\n        page = self._next_page()\n        while page is not None:\n            self.page_number += 1\n            if increment:\n                self.num_results += page.num_items\n            yield page\n            page = self._next_page()\n\n    @abc.abstractmethod\n    def _next_page(self):\n        \"\"\"Get the next page in the iterator.\n\n        This does nothing and is intended to be over-ridden by subclasses\n        to return the next :class:`Page`.\n\n        Raises:\n            NotImplementedError: Always, this method is abstract.\n        \"\"\"\n        raise NotImplementedError\n\n\ndef _do_nothing_page_start(iterator, page, response):\n    \"\"\"Helper to provide custom behavior after a :class:`Page` is started.\n\n    This is a do-nothing stand-in as the default value.\n\n    Args:\n        iterator (Iterator): An iterator that holds some request info.\n        page (Page): The page that was just created.\n        response (Any): The API response for a page.\n    \"\"\"\n    # pylint: disable=unused-argument\n    pass\n\n\nclass HTTPIterator(Iterator):\n    \"\"\"A generic class for iterating through HTTP/JSON API list responses.\n\n    To make an iterator work, you'll need to provide a way to convert a JSON\n    item returned from the API into the object of your choice (via\n    ``item_to_value``). You also may need to specify a custom ``items_key`` so\n    that a given response (containing a page of results) can be parsed into an\n    iterable page of the actual objects you want.\n\n    Args:\n        client (google.cloud.client.Client): The API client.\n        api_request (Callable): The function to use to make API requests.\n            Generally, this will be\n            :meth:`google.cloud._http.JSONConnection.api_request`.\n        path (str): The method path to query for the list of items.\n        item_to_value (Callable[google.api_core.page_iterator.Iterator, Any]):\n            Callable to convert an item from the type in the JSON response into\n            a native object. Will be called with the iterator and a single\n            item.\n        items_key (str): The key in the API response where the list of items\n            can be found.\n        page_token (str): A token identifying a page in a result set to start\n            fetching results from.\n        page_size (int): The maximum number of results to fetch per page\n        max_results (int): The maximum number of results to fetch\n        extra_params (dict): Extra query string parameters for the\n            API call.\n        page_start (Callable[\n            google.api_core.page_iterator.Iterator,\n            google.api_core.page_iterator.Page, dict]): Callable to provide\n            any special behavior after a new page has been created. Assumed\n            signature takes the :class:`.Iterator` that started the page,\n            the :class:`.Page` that was started and the dictionary containing\n            the page response.\n        next_token (str): The name of the field used in the response for page\n            tokens.\n\n    .. autoattribute:: pages\n    \"\"\"\n\n    _DEFAULT_ITEMS_KEY = \"items\"\n    _PAGE_TOKEN = \"pageToken\"\n    _MAX_RESULTS = \"maxResults\"\n    _NEXT_TOKEN = \"nextPageToken\"\n    _RESERVED_PARAMS = frozenset([_PAGE_TOKEN])\n    _HTTP_METHOD = \"GET\"\n\n    def __init__(\n        self,\n        client,\n        api_request,\n        path,\n        item_to_value,\n        items_key=_DEFAULT_ITEMS_KEY,\n        page_token=None,\n        page_size=None,\n        max_results=None,\n        extra_params=None,\n        page_start=_do_nothing_page_start,\n        next_token=_NEXT_TOKEN,\n    ):\n        super(HTTPIterator, self).__init__(\n            client, item_to_value, page_token=page_token, max_results=max_results\n        )\n        self.api_request = api_request\n        self.path = path\n        self._items_key = items_key\n        self.extra_params = extra_params\n        self._page_size = page_size\n        self._page_start = page_start\n        self._next_token = next_token\n        # Verify inputs / provide defaults.\n        if self.extra_params is None:\n            self.extra_params = {}\n        self._verify_params()\n\n    def _verify_params(self):\n        \"\"\"Verifies the parameters don't use any reserved parameter.\n\n        Raises:\n            ValueError: If a reserved parameter is used.\n        \"\"\"\n        reserved_in_use = self._RESERVED_PARAMS.intersection(self.extra_params)\n        if reserved_in_use:\n            raise ValueError(\"Using a reserved parameter\", reserved_in_use)\n\n    def _next_page(self):\n        \"\"\"Get the next page in the iterator.\n\n        Returns:\n            Optional[Page]: The next page in the iterator or :data:`None` if\n                there are no pages left.\n        \"\"\"\n        if self._has_next_page():\n            response = self._get_next_page_response()\n            items = response.get(self._items_key, ())\n            page = Page(self, items, self.item_to_value, raw_page=response)\n            self._page_start(self, page, response)\n            self.next_page_token = response.get(self._next_token)\n            return page\n        else:\n            return None\n\n    def _has_next_page(self):\n        \"\"\"Determines whether or not there are more pages with results.\n\n        Returns:\n            bool: Whether the iterator has more pages.\n        \"\"\"\n        if self.page_number == 0:\n            return True\n\n        if self.max_results is not None:\n            if self.num_results >= self.max_results:\n                return False\n\n        return self.next_page_token is not None\n\n    def _get_query_params(self):\n        \"\"\"Getter for query parameters for the next request.\n\n        Returns:\n            dict: A dictionary of query parameters.\n        \"\"\"\n        result = {}\n        if self.next_page_token is not None:\n            result[self._PAGE_TOKEN] = self.next_page_token\n\n        page_size = None\n        if self.max_results is not None:\n            page_size = self.max_results - self.num_results\n            if self._page_size is not None:\n                page_size = min(page_size, self._page_size)\n        elif self._page_size is not None:\n            page_size = self._page_size\n\n        if page_size is not None:\n            result[self._MAX_RESULTS] = page_size\n\n        result.update(self.extra_params)\n        return result\n\n    def _get_next_page_response(self):\n        \"\"\"Requests the next page from the path provided.\n\n        Returns:\n            dict: The parsed JSON response of the next page's contents.\n\n        Raises:\n            ValueError: If the HTTP method is not ``GET`` or ``POST``.\n        \"\"\"\n        params = self._get_query_params()\n        if self._HTTP_METHOD == \"GET\":\n            return self.api_request(\n                method=self._HTTP_METHOD, path=self.path, query_params=params\n            )\n        elif self._HTTP_METHOD == \"POST\":\n            return self.api_request(\n                method=self._HTTP_METHOD, path=self.path, data=params\n            )\n        else:\n            raise ValueError(\"Unexpected HTTP method\", self._HTTP_METHOD)\n\n\nclass _GAXIterator(Iterator):\n    \"\"\"A generic class for iterating through Cloud gRPC APIs list responses.\n\n    Any:\n        client (google.cloud.client.Client): The API client.\n        page_iter (google.gax.PageIterator): A GAX page iterator to be wrapped\n            to conform to the :class:`Iterator` interface.\n        item_to_value (Callable[Iterator, Any]): Callable to convert an item\n            from the protobuf response into a native object. Will\n            be called with the iterator and a single item.\n        max_results (int): The maximum number of results to fetch.\n\n    .. autoattribute:: pages\n    \"\"\"\n\n    def __init__(self, client, page_iter, item_to_value, max_results=None):\n        super(_GAXIterator, self).__init__(\n            client,\n            item_to_value,\n            page_token=page_iter.page_token,\n            max_results=max_results,\n        )\n        self._gax_page_iter = page_iter\n\n    def _next_page(self):\n        \"\"\"Get the next page in the iterator.\n\n        Wraps the response from the :class:`~google.gax.PageIterator` in a\n        :class:`Page` instance and captures some state at each page.\n\n        Returns:\n            Optional[Page]: The next page in the iterator or :data:`None` if\n                  there are no pages left.\n        \"\"\"\n        try:\n            items = next(self._gax_page_iter)\n            page = Page(self, items, self.item_to_value)\n            self.next_page_token = self._gax_page_iter.page_token or None\n            return page\n        except StopIteration:\n            return None\n\n\nclass GRPCIterator(Iterator):\n    \"\"\"A generic class for iterating through gRPC list responses.\n\n    .. note:: The class does not take a ``page_token`` argument because it can\n        just be specified in the ``request``.\n\n    Args:\n        client (google.cloud.client.Client): The API client. This unused by\n            this class, but kept to satisfy the :class:`Iterator` interface.\n        method (Callable[protobuf.Message]): A bound gRPC method that should\n            take a single message for the request.\n        request (protobuf.Message): The request message.\n        items_field (str): The field in the response message that has the\n            items for the page.\n        item_to_value (Callable[GRPCIterator, Any]): Callable to convert an\n            item from the type in the JSON response into a native object. Will\n            be called with the iterator and a single item.\n        request_token_field (str): The field in the request message used to\n            specify the page token.\n        response_token_field (str): The field in the response message that has\n            the token for the next page.\n        max_results (int): The maximum number of results to fetch.\n\n    .. autoattribute:: pages\n    \"\"\"\n\n    _DEFAULT_REQUEST_TOKEN_FIELD = \"page_token\"\n    _DEFAULT_RESPONSE_TOKEN_FIELD = \"next_page_token\"\n\n    def __init__(\n        self,\n        client,\n        method,\n        request,\n        items_field,\n        item_to_value=_item_to_value_identity,\n        request_token_field=_DEFAULT_REQUEST_TOKEN_FIELD,\n        response_token_field=_DEFAULT_RESPONSE_TOKEN_FIELD,\n        max_results=None,\n    ):\n        super(GRPCIterator, self).__init__(\n            client, item_to_value, max_results=max_results\n        )\n        self._method = method\n        self._request = request\n        self._items_field = items_field\n        self._request_token_field = request_token_field\n        self._response_token_field = response_token_field\n\n    def _next_page(self):\n        \"\"\"Get the next page in the iterator.\n\n        Returns:\n            Page: The next page in the iterator or :data:`None` if\n                there are no pages left.\n        \"\"\"\n        if not self._has_next_page():\n            return None\n\n        if self.next_page_token is not None:\n            setattr(self._request, self._request_token_field, self.next_page_token)\n\n        response = self._method(self._request)\n\n        self.next_page_token = getattr(response, self._response_token_field)\n        items = getattr(response, self._items_field)\n        page = Page(self, items, self.item_to_value, raw_page=response)\n\n        return page\n\n    def _has_next_page(self):\n        \"\"\"Determines whether or not there are more pages with results.\n\n        Returns:\n            bool: Whether the iterator has more pages.\n        \"\"\"\n        if self.page_number == 0:\n            return True\n\n        if self.max_results is not None:\n            if self.num_results >= self.max_results:\n                return False\n\n        # Note: intentionally a falsy check instead of a None check. The RPC\n        # can return an empty string indicating no more pages.\n        return True if self.next_page_token else False\n", "google/api_core/__init__.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Google API Core.\n\nThis package contains common code and utilities used by Google client libraries.\n\"\"\"\n\nfrom google.api_core import version as api_core_version\n\n__version__ = api_core_version.__version__\n", "google/api_core/rest_helpers.py": "# Copyright 2021 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Helpers for rest transports.\"\"\"\n\nimport functools\nimport operator\n\n\ndef flatten_query_params(obj, strict=False):\n    \"\"\"Flatten a dict into a list of (name,value) tuples.\n\n    The result is suitable for setting query params on an http request.\n\n    .. code-block:: python\n\n        >>> obj = {'a':\n        ...         {'b':\n        ...           {'c': ['x', 'y', 'z']} },\n        ...      'd': 'uvw',\n        ...      'e': True, }\n        >>> flatten_query_params(obj, strict=True)\n        [('a.b.c', 'x'), ('a.b.c', 'y'), ('a.b.c', 'z'), ('d', 'uvw'), ('e', 'true')]\n\n    Note that, as described in\n    https://github.com/googleapis/googleapis/blob/48d9fb8c8e287c472af500221c6450ecd45d7d39/google/api/http.proto#L117,\n    repeated fields (i.e. list-valued fields) may only contain primitive types (not lists or dicts).\n    This is enforced in this function.\n\n    Args:\n      obj: a possibly nested dictionary (from json), or None\n      strict: a bool, defaulting to False, to enforce that all values in the\n              result tuples be strings and, if boolean, lower-cased.\n\n    Returns: a list of tuples, with each tuple having a (possibly) multi-part name\n      and a scalar value.\n\n    Raises:\n      TypeError if obj is not a dict or None\n      ValueError if obj contains a list of non-primitive values.\n    \"\"\"\n\n    if obj is not None and not isinstance(obj, dict):\n        raise TypeError(\"flatten_query_params must be called with dict object\")\n\n    return _flatten(obj, key_path=[], strict=strict)\n\n\ndef _flatten(obj, key_path, strict=False):\n    if obj is None:\n        return []\n    if isinstance(obj, dict):\n        return _flatten_dict(obj, key_path=key_path, strict=strict)\n    if isinstance(obj, list):\n        return _flatten_list(obj, key_path=key_path, strict=strict)\n    return _flatten_value(obj, key_path=key_path, strict=strict)\n\n\ndef _is_primitive_value(obj):\n    if obj is None:\n        return False\n\n    if isinstance(obj, (list, dict)):\n        raise ValueError(\"query params may not contain repeated dicts or lists\")\n\n    return True\n\n\ndef _flatten_value(obj, key_path, strict=False):\n    return [(\".\".join(key_path), _canonicalize(obj, strict=strict))]\n\n\ndef _flatten_dict(obj, key_path, strict=False):\n    items = (\n        _flatten(value, key_path=key_path + [key], strict=strict)\n        for key, value in obj.items()\n    )\n    return functools.reduce(operator.concat, items, [])\n\n\ndef _flatten_list(elems, key_path, strict=False):\n    # Only lists of scalar values are supported.\n    # The name (key_path) is repeated for each value.\n    items = (\n        _flatten_value(elem, key_path=key_path, strict=strict)\n        for elem in elems\n        if _is_primitive_value(elem)\n    )\n    return functools.reduce(operator.concat, items, [])\n\n\ndef _canonicalize(obj, strict=False):\n    if strict:\n        value = str(obj)\n        if isinstance(obj, bool):\n            value = value.lower()\n        return value\n    return obj\n", "google/api_core/operation.py": "# Copyright 2016 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Futures for long-running operations returned from Google Cloud APIs.\n\nThese futures can be used to synchronously wait for the result of a\nlong-running operation using :meth:`Operation.result`:\n\n\n.. code-block:: python\n\n    operation = my_api_client.long_running_method()\n    result = operation.result()\n\nOr asynchronously using callbacks and :meth:`Operation.add_done_callback`:\n\n.. code-block:: python\n\n    operation = my_api_client.long_running_method()\n\n    def my_callback(future):\n        result = future.result()\n\n    operation.add_done_callback(my_callback)\n\n\"\"\"\n\nimport functools\nimport threading\n\nfrom google.api_core import exceptions\nfrom google.api_core import protobuf_helpers\nfrom google.api_core.future import polling\nfrom google.longrunning import operations_pb2\nfrom google.protobuf import json_format\nfrom google.rpc import code_pb2\n\n\nclass Operation(polling.PollingFuture):\n    \"\"\"A Future for interacting with a Google API Long-Running Operation.\n\n    Args:\n        operation (google.longrunning.operations_pb2.Operation): The\n            initial operation.\n        refresh (Callable[[], ~.api_core.operation.Operation]): A callable that\n            returns the latest state of the operation.\n        cancel (Callable[[], None]): A callable that tries to cancel\n            the operation.\n        result_type (func:`type`): The protobuf type for the operation's\n            result.\n        metadata_type (func:`type`): The protobuf type for the operation's\n            metadata.\n        polling (google.api_core.retry.Retry): The configuration used for polling.\n            This parameter controls how often :meth:`done` is polled. If the\n            ``timeout`` argument is specified in the :meth:`result` method, it will\n            override the ``polling.timeout`` property.\n        retry (google.api_core.retry.Retry): DEPRECATED: use ``polling`` instead.\n            If specified it will override ``polling`` parameter to maintain\n            backward compatibility.\n    \"\"\"\n\n    def __init__(\n        self,\n        operation,\n        refresh,\n        cancel,\n        result_type,\n        metadata_type=None,\n        polling=polling.DEFAULT_POLLING,\n        **kwargs\n    ):\n        super(Operation, self).__init__(polling=polling, **kwargs)\n        self._operation = operation\n        self._refresh = refresh\n        self._cancel = cancel\n        self._result_type = result_type\n        self._metadata_type = metadata_type\n        self._completion_lock = threading.Lock()\n        # Invoke this in case the operation came back already complete.\n        self._set_result_from_operation()\n\n    @property\n    def operation(self):\n        \"\"\"google.longrunning.Operation: The current long-running operation.\"\"\"\n        return self._operation\n\n    @property\n    def metadata(self):\n        \"\"\"google.protobuf.Message: the current operation metadata.\"\"\"\n        if not self._operation.HasField(\"metadata\"):\n            return None\n\n        return protobuf_helpers.from_any_pb(\n            self._metadata_type, self._operation.metadata\n        )\n\n    @classmethod\n    def deserialize(self, payload):\n        \"\"\"Deserialize a ``google.longrunning.Operation`` protocol buffer.\n\n        Args:\n            payload (bytes): A serialized operation protocol buffer.\n\n        Returns:\n            ~.operations_pb2.Operation: An Operation protobuf object.\n        \"\"\"\n        return operations_pb2.Operation.FromString(payload)\n\n    def _set_result_from_operation(self):\n        \"\"\"Set the result or exception from the operation if it is complete.\"\"\"\n        # This must be done in a lock to prevent the polling thread\n        # and main thread from both executing the completion logic\n        # at the same time.\n        with self._completion_lock:\n            # If the operation isn't complete or if the result has already been\n            # set, do not call set_result/set_exception again.\n            # Note: self._result_set is set to True in set_result and\n            # set_exception, in case those methods are invoked directly.\n            if not self._operation.done or self._result_set:\n                return\n\n            if self._operation.HasField(\"response\"):\n                response = protobuf_helpers.from_any_pb(\n                    self._result_type, self._operation.response\n                )\n                self.set_result(response)\n            elif self._operation.HasField(\"error\"):\n                exception = exceptions.from_grpc_status(\n                    status_code=self._operation.error.code,\n                    message=self._operation.error.message,\n                    errors=(self._operation.error,),\n                    response=self._operation,\n                )\n                self.set_exception(exception)\n            else:\n                exception = exceptions.GoogleAPICallError(\n                    \"Unexpected state: Long-running operation had neither \"\n                    \"response nor error set.\"\n                )\n                self.set_exception(exception)\n\n    def _refresh_and_update(self, retry=None):\n        \"\"\"Refresh the operation and update the result if needed.\n\n        Args:\n            retry (google.api_core.retry.Retry): (Optional) How to retry the RPC.\n        \"\"\"\n        # If the currently cached operation is done, no need to make another\n        # RPC as it will not change once done.\n        if not self._operation.done:\n            self._operation = self._refresh(retry=retry) if retry else self._refresh()\n            self._set_result_from_operation()\n\n    def done(self, retry=None):\n        \"\"\"Checks to see if the operation is complete.\n\n        Args:\n            retry (google.api_core.retry.Retry): (Optional) How to retry the RPC.\n\n        Returns:\n            bool: True if the operation is complete, False otherwise.\n        \"\"\"\n        self._refresh_and_update(retry)\n        return self._operation.done\n\n    def cancel(self):\n        \"\"\"Attempt to cancel the operation.\n\n        Returns:\n            bool: True if the cancel RPC was made, False if the operation is\n                already complete.\n        \"\"\"\n        if self.done():\n            return False\n\n        self._cancel()\n        return True\n\n    def cancelled(self):\n        \"\"\"True if the operation was cancelled.\"\"\"\n        self._refresh_and_update()\n        return (\n            self._operation.HasField(\"error\")\n            and self._operation.error.code == code_pb2.CANCELLED\n        )\n\n\ndef _refresh_http(api_request, operation_name, retry=None):\n    \"\"\"Refresh an operation using a JSON/HTTP client.\n\n    Args:\n        api_request (Callable): A callable used to make an API request. This\n            should generally be\n            :meth:`google.cloud._http.Connection.api_request`.\n        operation_name (str): The name of the operation.\n        retry (google.api_core.retry.Retry): (Optional) retry policy\n\n    Returns:\n        google.longrunning.operations_pb2.Operation: The operation.\n    \"\"\"\n    path = \"operations/{}\".format(operation_name)\n\n    if retry is not None:\n        api_request = retry(api_request)\n\n    api_response = api_request(method=\"GET\", path=path)\n    return json_format.ParseDict(api_response, operations_pb2.Operation())\n\n\ndef _cancel_http(api_request, operation_name):\n    \"\"\"Cancel an operation using a JSON/HTTP client.\n\n    Args:\n        api_request (Callable): A callable used to make an API request. This\n            should generally be\n            :meth:`google.cloud._http.Connection.api_request`.\n        operation_name (str): The name of the operation.\n    \"\"\"\n    path = \"operations/{}:cancel\".format(operation_name)\n    api_request(method=\"POST\", path=path)\n\n\ndef from_http_json(operation, api_request, result_type, **kwargs):\n    \"\"\"Create an operation future using a HTTP/JSON client.\n\n    This interacts with the long-running operations `service`_ (specific\n    to a given API) via `HTTP/JSON`_.\n\n    .. _HTTP/JSON: https://cloud.google.com/speech/reference/rest/\\\n            v1beta1/operations#Operation\n\n    Args:\n        operation (dict): Operation as a dictionary.\n        api_request (Callable): A callable used to make an API request. This\n            should generally be\n            :meth:`google.cloud._http.Connection.api_request`.\n        result_type (:func:`type`): The protobuf result type.\n        kwargs: Keyword args passed into the :class:`Operation` constructor.\n\n    Returns:\n        ~.api_core.operation.Operation: The operation future to track the given\n            operation.\n    \"\"\"\n    operation_proto = json_format.ParseDict(operation, operations_pb2.Operation())\n    refresh = functools.partial(_refresh_http, api_request, operation_proto.name)\n    cancel = functools.partial(_cancel_http, api_request, operation_proto.name)\n    return Operation(operation_proto, refresh, cancel, result_type, **kwargs)\n\n\ndef _refresh_grpc(operations_stub, operation_name, retry=None):\n    \"\"\"Refresh an operation using a gRPC client.\n\n    Args:\n        operations_stub (google.longrunning.operations_pb2.OperationsStub):\n            The gRPC operations stub.\n        operation_name (str): The name of the operation.\n        retry (google.api_core.retry.Retry): (Optional) retry policy\n\n    Returns:\n        google.longrunning.operations_pb2.Operation: The operation.\n    \"\"\"\n    request_pb = operations_pb2.GetOperationRequest(name=operation_name)\n\n    rpc = operations_stub.GetOperation\n    if retry is not None:\n        rpc = retry(rpc)\n\n    return rpc(request_pb)\n\n\ndef _cancel_grpc(operations_stub, operation_name):\n    \"\"\"Cancel an operation using a gRPC client.\n\n    Args:\n        operations_stub (google.longrunning.operations_pb2.OperationsStub):\n            The gRPC operations stub.\n        operation_name (str): The name of the operation.\n    \"\"\"\n    request_pb = operations_pb2.CancelOperationRequest(name=operation_name)\n    operations_stub.CancelOperation(request_pb)\n\n\ndef from_grpc(operation, operations_stub, result_type, grpc_metadata=None, **kwargs):\n    \"\"\"Create an operation future using a gRPC client.\n\n    This interacts with the long-running operations `service`_ (specific\n    to a given API) via gRPC.\n\n    .. _service: https://github.com/googleapis/googleapis/blob/\\\n                 050400df0fdb16f63b63e9dee53819044bffc857/\\\n                 google/longrunning/operations.proto#L38\n\n    Args:\n        operation (google.longrunning.operations_pb2.Operation): The operation.\n        operations_stub (google.longrunning.operations_pb2.OperationsStub):\n            The operations stub.\n        result_type (:func:`type`): The protobuf result type.\n        grpc_metadata (Optional[List[Tuple[str, str]]]): Additional metadata to pass\n            to the rpc.\n        kwargs: Keyword args passed into the :class:`Operation` constructor.\n\n    Returns:\n        ~.api_core.operation.Operation: The operation future to track the given\n            operation.\n    \"\"\"\n    refresh = functools.partial(\n        _refresh_grpc,\n        operations_stub,\n        operation.name,\n        metadata=grpc_metadata,\n    )\n    cancel = functools.partial(\n        _cancel_grpc,\n        operations_stub,\n        operation.name,\n        metadata=grpc_metadata,\n    )\n    return Operation(operation, refresh, cancel, result_type, **kwargs)\n\n\ndef from_gapic(operation, operations_client, result_type, grpc_metadata=None, **kwargs):\n    \"\"\"Create an operation future from a gapic client.\n\n    This interacts with the long-running operations `service`_ (specific\n    to a given API) via a gapic client.\n\n    .. _service: https://github.com/googleapis/googleapis/blob/\\\n                 050400df0fdb16f63b63e9dee53819044bffc857/\\\n                 google/longrunning/operations.proto#L38\n\n    Args:\n        operation (google.longrunning.operations_pb2.Operation): The operation.\n        operations_client (google.api_core.operations_v1.OperationsClient):\n            The operations client.\n        result_type (:func:`type`): The protobuf result type.\n        grpc_metadata (Optional[List[Tuple[str, str]]]): Additional metadata to pass\n            to the rpc.\n        kwargs: Keyword args passed into the :class:`Operation` constructor.\n\n    Returns:\n        ~.api_core.operation.Operation: The operation future to track the given\n            operation.\n    \"\"\"\n    refresh = functools.partial(\n        operations_client.get_operation,\n        operation.name,\n        metadata=grpc_metadata,\n    )\n    cancel = functools.partial(\n        operations_client.cancel_operation,\n        operation.name,\n        metadata=grpc_metadata,\n    )\n    return Operation(operation, refresh, cancel, result_type, **kwargs)\n", "google/api_core/operations_v1/operations_client.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"A client for the google.longrunning.operations meta-API.\n\nThis is a client that deals with long-running operations that follow the\npattern outlined by the `Google API Style Guide`_.\n\nWhen an API method normally takes long time to complete, it can be designed to\nreturn ``Operation`` to the client, and the client can use this interface to\nreceive the real response asynchronously by polling the operation resource to\nreceive the response.\n\nIt is not a separate service, but rather an interface implemented by a larger\nservice. The protocol-level definition is available at\n`google/longrunning/operations.proto`_. Typically, this will be constructed\nautomatically by another client class to deal with operations.\n\n.. _Google API Style Guide:\n    https://cloud.google.com/apis/design/design_pattern\n    s#long_running_operations\n.. _google/longrunning/operations.proto:\n    https://github.com/googleapis/googleapis/blob/master/google/longrunning\n    /operations.proto\n\"\"\"\n\nimport functools\n\nfrom google.api_core import exceptions as core_exceptions\nfrom google.api_core import gapic_v1\nfrom google.api_core import page_iterator\nfrom google.api_core import retry as retries\nfrom google.api_core import timeout as timeouts\nfrom google.longrunning import operations_pb2\nfrom grpc import Compression\n\n\nclass OperationsClient(object):\n    \"\"\"Client for interacting with long-running operations within a service.\n\n    Args:\n        channel (grpc.Channel): The gRPC channel associated with the service\n            that implements the ``google.longrunning.operations`` interface.\n        client_config (dict):\n            A dictionary of call options for each method. If not specified\n            the default configuration is used.\n    \"\"\"\n\n    def __init__(self, channel, client_config=None):\n        # Create the gRPC client stub.\n        self.operations_stub = operations_pb2.OperationsStub(channel)\n\n        default_retry = retries.Retry(\n            initial=0.1,  # seconds\n            maximum=60.0,  # seconds\n            multiplier=1.3,\n            predicate=retries.if_exception_type(\n                core_exceptions.DeadlineExceeded,\n                core_exceptions.ServiceUnavailable,\n            ),\n            timeout=600.0,  # seconds\n        )\n        default_timeout = timeouts.TimeToDeadlineTimeout(timeout=600.0)\n\n        default_compression = Compression.NoCompression\n\n        self._get_operation = gapic_v1.method.wrap_method(\n            self.operations_stub.GetOperation,\n            default_retry=default_retry,\n            default_timeout=default_timeout,\n            default_compression=default_compression,\n        )\n\n        self._list_operations = gapic_v1.method.wrap_method(\n            self.operations_stub.ListOperations,\n            default_retry=default_retry,\n            default_timeout=default_timeout,\n            default_compression=default_compression,\n        )\n\n        self._cancel_operation = gapic_v1.method.wrap_method(\n            self.operations_stub.CancelOperation,\n            default_retry=default_retry,\n            default_timeout=default_timeout,\n            default_compression=default_compression,\n        )\n\n        self._delete_operation = gapic_v1.method.wrap_method(\n            self.operations_stub.DeleteOperation,\n            default_retry=default_retry,\n            default_timeout=default_timeout,\n            default_compression=default_compression,\n        )\n\n    # Service calls\n    def get_operation(\n        self,\n        name,\n        retry=gapic_v1.method.DEFAULT,\n        timeout=gapic_v1.method.DEFAULT,\n        compression=gapic_v1.method.DEFAULT,\n        metadata=None,\n    ):\n        \"\"\"Gets the latest state of a long-running operation.\n\n        Clients can use this method to poll the operation result at intervals\n        as recommended by the API service.\n\n        Example:\n            >>> from google.api_core import operations_v1\n            >>> api = operations_v1.OperationsClient()\n            >>> name = ''\n            >>> response = api.get_operation(name)\n\n        Args:\n            name (str): The name of the operation resource.\n            retry (google.api_core.retry.Retry): The retry strategy to use\n                when invoking the RPC. If unspecified, the default retry from\n                the client configuration will be used. If ``None``, then this\n                method will not retry the RPC at all.\n            timeout (float): The amount of time in seconds to wait for the RPC\n                to complete. Note that if ``retry`` is used, this timeout\n                applies to each individual attempt and the overall time it\n                takes for this method to complete may be longer. If\n                unspecified, the the default timeout in the client\n                configuration is used. If ``None``, then the RPC method will\n                not time out.\n            compression (grpc.Compression): An element of grpc.compression\n                e.g. grpc.compression.Gzip.\n            metadata (Optional[List[Tuple[str, str]]]):\n                Additional gRPC metadata.\n\n        Returns:\n            google.longrunning.operations_pb2.Operation: The state of the\n                operation.\n\n        Raises:\n            google.api_core.exceptions.GoogleAPICallError: If an error occurred\n                while invoking the RPC, the appropriate ``GoogleAPICallError``\n                subclass will be raised.\n        \"\"\"\n        request = operations_pb2.GetOperationRequest(name=name)\n\n        # Add routing header\n        metadata = metadata or []\n        metadata.append(gapic_v1.routing_header.to_grpc_metadata({\"name\": name}))\n\n        return self._get_operation(\n            request,\n            retry=retry,\n            timeout=timeout,\n            compression=compression,\n            metadata=metadata,\n        )\n\n    def list_operations(\n        self,\n        name,\n        filter_,\n        retry=gapic_v1.method.DEFAULT,\n        timeout=gapic_v1.method.DEFAULT,\n        compression=gapic_v1.method.DEFAULT,\n        metadata=None,\n    ):\n        \"\"\"\n        Lists operations that match the specified filter in the request.\n\n        Example:\n            >>> from google.api_core import operations_v1\n            >>> api = operations_v1.OperationsClient()\n            >>> name = ''\n            >>>\n            >>> # Iterate over all results\n            >>> for operation in api.list_operations(name):\n            >>>   # process operation\n            >>>   pass\n            >>>\n            >>> # Or iterate over results one page at a time\n            >>> iter = api.list_operations(name)\n            >>> for page in iter.pages:\n            >>>   for operation in page:\n            >>>     # process operation\n            >>>     pass\n\n        Args:\n            name (str): The name of the operation collection.\n            filter_ (str): The standard list filter.\n            retry (google.api_core.retry.Retry): The retry strategy to use\n                when invoking the RPC. If unspecified, the default retry from\n                the client configuration will be used. If ``None``, then this\n                method will not retry the RPC at all.\n            timeout (float): The amount of time in seconds to wait for the RPC\n                to complete. Note that if ``retry`` is used, this timeout\n                applies to each individual attempt and the overall time it\n                takes for this method to complete may be longer. If\n                unspecified, the the default timeout in the client\n                configuration is used. If ``None``, then the RPC method will\n                not time out.\n            compression (grpc.Compression): An element of grpc.compression\n                e.g. grpc.compression.Gzip.\n            metadata (Optional[List[Tuple[str, str]]]): Additional gRPC\n                metadata.\n\n        Returns:\n            google.api_core.page_iterator.Iterator: An iterator that yields\n                :class:`google.longrunning.operations_pb2.Operation` instances.\n\n        Raises:\n            google.api_core.exceptions.MethodNotImplemented: If the server\n                does not support this method. Services are not required to\n                implement this method.\n            google.api_core.exceptions.GoogleAPICallError: If an error occurred\n                while invoking the RPC, the appropriate ``GoogleAPICallError``\n                subclass will be raised.\n        \"\"\"\n        # Create the request object.\n        request = operations_pb2.ListOperationsRequest(name=name, filter=filter_)\n\n        # Add routing header\n        metadata = metadata or []\n        metadata.append(gapic_v1.routing_header.to_grpc_metadata({\"name\": name}))\n\n        # Create the method used to fetch pages\n        method = functools.partial(\n            self._list_operations,\n            retry=retry,\n            timeout=timeout,\n            compression=compression,\n            metadata=metadata,\n        )\n\n        iterator = page_iterator.GRPCIterator(\n            client=None,\n            method=method,\n            request=request,\n            items_field=\"operations\",\n            request_token_field=\"page_token\",\n            response_token_field=\"next_page_token\",\n        )\n\n        return iterator\n\n    def cancel_operation(\n        self,\n        name,\n        retry=gapic_v1.method.DEFAULT,\n        timeout=gapic_v1.method.DEFAULT,\n        compression=gapic_v1.method.DEFAULT,\n        metadata=None,\n    ):\n        \"\"\"Starts asynchronous cancellation on a long-running operation.\n\n        The server makes a best effort to cancel the operation, but success is\n        not guaranteed. Clients can use :meth:`get_operation` or service-\n        specific methods to check whether the cancellation succeeded or whether\n        the operation completed despite cancellation. On successful\n        cancellation, the operation is not deleted; instead, it becomes an\n        operation with an ``Operation.error`` value with a\n        ``google.rpc.Status.code`` of ``1``, corresponding to\n        ``Code.CANCELLED``.\n\n        Example:\n            >>> from google.api_core import operations_v1\n            >>> api = operations_v1.OperationsClient()\n            >>> name = ''\n            >>> api.cancel_operation(name)\n\n        Args:\n            name (str): The name of the operation resource to be cancelled.\n            retry (google.api_core.retry.Retry): The retry strategy to use\n                when invoking the RPC. If unspecified, the default retry from\n                the client configuration will be used. If ``None``, then this\n                method will not retry the RPC at all.\n            timeout (float): The amount of time in seconds to wait for the RPC\n                to complete. Note that if ``retry`` is used, this timeout\n                applies to each individual attempt and the overall time it\n                takes for this method to complete may be longer. If\n                unspecified, the the default timeout in the client\n                configuration is used. If ``None``, then the RPC method will\n                not time out.\n            compression (grpc.Compression): An element of grpc.compression\n                e.g. grpc.compression.Gzip.\n            metadata (Optional[List[Tuple[str, str]]]): Additional gRPC\n                metadata.\n\n        Raises:\n            google.api_core.exceptions.MethodNotImplemented: If the server\n                does not support this method. Services are not required to\n                implement this method.\n            google.api_core.exceptions.GoogleAPICallError: If an error occurred\n                while invoking the RPC, the appropriate ``GoogleAPICallError``\n                subclass will be raised.\n        \"\"\"\n        # Create the request object.\n        request = operations_pb2.CancelOperationRequest(name=name)\n\n        # Add routing header\n        metadata = metadata or []\n        metadata.append(gapic_v1.routing_header.to_grpc_metadata({\"name\": name}))\n\n        self._cancel_operation(\n            request,\n            retry=retry,\n            timeout=timeout,\n            compression=compression,\n            metadata=metadata,\n        )\n\n    def delete_operation(\n        self,\n        name,\n        retry=gapic_v1.method.DEFAULT,\n        timeout=gapic_v1.method.DEFAULT,\n        compression=gapic_v1.method.DEFAULT,\n        metadata=None,\n    ):\n        \"\"\"Deletes a long-running operation.\n\n        This method indicates that the client is no longer interested in the\n        operation result. It does not cancel the operation.\n\n        Example:\n            >>> from google.api_core import operations_v1\n            >>> api = operations_v1.OperationsClient()\n            >>> name = ''\n            >>> api.delete_operation(name)\n\n        Args:\n            name (str): The name of the operation resource to be deleted.\n            retry (google.api_core.retry.Retry): The retry strategy to use\n                when invoking the RPC. If unspecified, the default retry from\n                the client configuration will be used. If ``None``, then this\n                method will not retry the RPC at all.\n            timeout (float): The amount of time in seconds to wait for the RPC\n                to complete. Note that if ``retry`` is used, this timeout\n                applies to each individual attempt and the overall time it\n                takes for this method to complete may be longer. If\n                unspecified, the the default timeout in the client\n                configuration is used. If ``None``, then the RPC method will\n                not time out.\n            compression (grpc.Compression): An element of grpc.compression\n                e.g. grpc.compression.Gzip.\n            metadata (Optional[List[Tuple[str, str]]]): Additional gRPC\n                metadata.\n\n        Raises:\n            google.api_core.exceptions.MethodNotImplemented: If the server\n                does not support this method. Services are not required to\n                implement this method.\n            google.api_core.exceptions.GoogleAPICallError: If an error occurred\n                while invoking the RPC, the appropriate ``GoogleAPICallError``\n                subclass will be raised.\n        \"\"\"\n        # Create the request object.\n        request = operations_pb2.DeleteOperationRequest(name=name)\n\n        # Add routing header\n        metadata = metadata or []\n        metadata.append(gapic_v1.routing_header.to_grpc_metadata({\"name\": name}))\n\n        self._delete_operation(\n            request,\n            retry=retry,\n            timeout=timeout,\n            compression=compression,\n            metadata=metadata,\n        )\n", "google/api_core/operations_v1/abstract_operations_client.py": "# -*- coding: utf-8 -*-\n# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\nfrom collections import OrderedDict\nimport os\nimport re\nfrom typing import Dict, Optional, Sequence, Tuple, Type, Union\n\nfrom google.api_core import client_options as client_options_lib  # type: ignore\nfrom google.api_core import gapic_v1  # type: ignore\nfrom google.api_core import retry as retries  # type: ignore\nfrom google.api_core.operations_v1 import pagers\nfrom google.api_core.operations_v1.transports.base import (\n    DEFAULT_CLIENT_INFO,\n    OperationsTransport,\n)\nfrom google.api_core.operations_v1.transports.rest import OperationsRestTransport\nfrom google.auth import credentials as ga_credentials  # type: ignore\nfrom google.auth.exceptions import MutualTLSChannelError  # type: ignore\nfrom google.auth.transport import mtls  # type: ignore\nfrom google.longrunning import operations_pb2\nfrom google.oauth2 import service_account  # type: ignore\nimport grpc\n\nOptionalRetry = Union[retries.Retry, object]\n\n\nclass AbstractOperationsClientMeta(type):\n    \"\"\"Metaclass for the Operations client.\n\n    This provides class-level methods for building and retrieving\n    support objects (e.g. transport) without polluting the client instance\n    objects.\n    \"\"\"\n\n    _transport_registry = OrderedDict()  # type: Dict[str, Type[OperationsTransport]]\n    _transport_registry[\"rest\"] = OperationsRestTransport\n\n    def get_transport_class(\n        cls,\n        label: Optional[str] = None,\n    ) -> Type[OperationsTransport]:\n        \"\"\"Returns an appropriate transport class.\n\n        Args:\n            label: The name of the desired transport. If none is\n                provided, then the first transport in the registry is used.\n\n        Returns:\n            The transport class to use.\n        \"\"\"\n        # If a specific transport is requested, return that one.\n        if label:\n            return cls._transport_registry[label]\n\n        # No transport is requested; return the default (that is, the first one\n        # in the dictionary).\n        return next(iter(cls._transport_registry.values()))\n\n\nclass AbstractOperationsClient(metaclass=AbstractOperationsClientMeta):\n    \"\"\"Manages long-running operations with an API service.\n\n    When an API method normally takes long time to complete, it can be\n    designed to return [Operation][google.api_core.operations_v1.Operation] to the\n    client, and the client can use this interface to receive the real\n    response asynchronously by polling the operation resource, or pass\n    the operation resource to another API (such as Google Cloud Pub/Sub\n    API) to receive the response. Any API service that returns\n    long-running operations should implement the ``Operations``\n    interface so developers can have a consistent client experience.\n    \"\"\"\n\n    @staticmethod\n    def _get_default_mtls_endpoint(api_endpoint):\n        \"\"\"Converts api endpoint to mTLS endpoint.\n\n        Convert \"*.sandbox.googleapis.com\" and \"*.googleapis.com\" to\n        \"*.mtls.sandbox.googleapis.com\" and \"*.mtls.googleapis.com\" respectively.\n        Args:\n            api_endpoint (Optional[str]): the api endpoint to convert.\n        Returns:\n            str: converted mTLS api endpoint.\n        \"\"\"\n        if not api_endpoint:\n            return api_endpoint\n\n        mtls_endpoint_re = re.compile(\n            r\"(?P<name>[^.]+)(?P<mtls>\\.mtls)?(?P<sandbox>\\.sandbox)?(?P<googledomain>\\.googleapis\\.com)?\"\n        )\n\n        m = mtls_endpoint_re.match(api_endpoint)\n        name, mtls, sandbox, googledomain = m.groups()\n        if mtls or not googledomain:\n            return api_endpoint\n\n        if sandbox:\n            return api_endpoint.replace(\n                \"sandbox.googleapis.com\", \"mtls.sandbox.googleapis.com\"\n            )\n\n        return api_endpoint.replace(\".googleapis.com\", \".mtls.googleapis.com\")\n\n    DEFAULT_ENDPOINT = \"longrunning.googleapis.com\"\n    DEFAULT_MTLS_ENDPOINT = _get_default_mtls_endpoint.__func__(  # type: ignore\n        DEFAULT_ENDPOINT\n    )\n\n    @classmethod\n    def from_service_account_info(cls, info: dict, *args, **kwargs):\n        \"\"\"Creates an instance of this client using the provided credentials\n            info.\n\n        Args:\n            info (dict): The service account private key info.\n            args: Additional arguments to pass to the constructor.\n            kwargs: Additional arguments to pass to the constructor.\n\n        Returns:\n            AbstractOperationsClient: The constructed client.\n        \"\"\"\n        credentials = service_account.Credentials.from_service_account_info(info)\n        kwargs[\"credentials\"] = credentials\n        return cls(*args, **kwargs)\n\n    @classmethod\n    def from_service_account_file(cls, filename: str, *args, **kwargs):\n        \"\"\"Creates an instance of this client using the provided credentials\n            file.\n\n        Args:\n            filename (str): The path to the service account private key json\n                file.\n            args: Additional arguments to pass to the constructor.\n            kwargs: Additional arguments to pass to the constructor.\n\n        Returns:\n            AbstractOperationsClient: The constructed client.\n        \"\"\"\n        credentials = service_account.Credentials.from_service_account_file(filename)\n        kwargs[\"credentials\"] = credentials\n        return cls(*args, **kwargs)\n\n    from_service_account_json = from_service_account_file\n\n    @property\n    def transport(self) -> OperationsTransport:\n        \"\"\"Returns the transport used by the client instance.\n\n        Returns:\n            OperationsTransport: The transport used by the client\n                instance.\n        \"\"\"\n        return self._transport\n\n    @staticmethod\n    def common_billing_account_path(\n        billing_account: str,\n    ) -> str:\n        \"\"\"Returns a fully-qualified billing_account string.\"\"\"\n        return \"billingAccounts/{billing_account}\".format(\n            billing_account=billing_account,\n        )\n\n    @staticmethod\n    def parse_common_billing_account_path(path: str) -> Dict[str, str]:\n        \"\"\"Parse a billing_account path into its component segments.\"\"\"\n        m = re.match(r\"^billingAccounts/(?P<billing_account>.+?)$\", path)\n        return m.groupdict() if m else {}\n\n    @staticmethod\n    def common_folder_path(\n        folder: str,\n    ) -> str:\n        \"\"\"Returns a fully-qualified folder string.\"\"\"\n        return \"folders/{folder}\".format(\n            folder=folder,\n        )\n\n    @staticmethod\n    def parse_common_folder_path(path: str) -> Dict[str, str]:\n        \"\"\"Parse a folder path into its component segments.\"\"\"\n        m = re.match(r\"^folders/(?P<folder>.+?)$\", path)\n        return m.groupdict() if m else {}\n\n    @staticmethod\n    def common_organization_path(\n        organization: str,\n    ) -> str:\n        \"\"\"Returns a fully-qualified organization string.\"\"\"\n        return \"organizations/{organization}\".format(\n            organization=organization,\n        )\n\n    @staticmethod\n    def parse_common_organization_path(path: str) -> Dict[str, str]:\n        \"\"\"Parse a organization path into its component segments.\"\"\"\n        m = re.match(r\"^organizations/(?P<organization>.+?)$\", path)\n        return m.groupdict() if m else {}\n\n    @staticmethod\n    def common_project_path(\n        project: str,\n    ) -> str:\n        \"\"\"Returns a fully-qualified project string.\"\"\"\n        return \"projects/{project}\".format(\n            project=project,\n        )\n\n    @staticmethod\n    def parse_common_project_path(path: str) -> Dict[str, str]:\n        \"\"\"Parse a project path into its component segments.\"\"\"\n        m = re.match(r\"^projects/(?P<project>.+?)$\", path)\n        return m.groupdict() if m else {}\n\n    @staticmethod\n    def common_location_path(\n        project: str,\n        location: str,\n    ) -> str:\n        \"\"\"Returns a fully-qualified location string.\"\"\"\n        return \"projects/{project}/locations/{location}\".format(\n            project=project,\n            location=location,\n        )\n\n    @staticmethod\n    def parse_common_location_path(path: str) -> Dict[str, str]:\n        \"\"\"Parse a location path into its component segments.\"\"\"\n        m = re.match(r\"^projects/(?P<project>.+?)/locations/(?P<location>.+?)$\", path)\n        return m.groupdict() if m else {}\n\n    def __init__(\n        self,\n        *,\n        credentials: Optional[ga_credentials.Credentials] = None,\n        transport: Union[str, OperationsTransport, None] = None,\n        client_options: Optional[client_options_lib.ClientOptions] = None,\n        client_info: gapic_v1.client_info.ClientInfo = DEFAULT_CLIENT_INFO,\n    ) -> None:\n        \"\"\"Instantiates the operations client.\n\n        Args:\n            credentials (Optional[google.auth.credentials.Credentials]): The\n                authorization credentials to attach to requests. These\n                credentials identify the application to the service; if none\n                are specified, the client will attempt to ascertain the\n                credentials from the environment.\n            transport (Union[str, OperationsTransport]): The\n                transport to use. If set to None, a transport is chosen\n                automatically.\n            client_options (google.api_core.client_options.ClientOptions): Custom options for the\n                client. It won't take effect if a ``transport`` instance is provided.\n                (1) The ``api_endpoint`` property can be used to override the\n                default endpoint provided by the client. GOOGLE_API_USE_MTLS_ENDPOINT\n                environment variable can also be used to override the endpoint:\n                \"always\" (always use the default mTLS endpoint), \"never\" (always\n                use the default regular endpoint) and \"auto\" (auto switch to the\n                default mTLS endpoint if client certificate is present, this is\n                the default value). However, the ``api_endpoint`` property takes\n                precedence if provided.\n                (2) If GOOGLE_API_USE_CLIENT_CERTIFICATE environment variable\n                is \"true\", then the ``client_cert_source`` property can be used\n                to provide client certificate for mutual TLS transport. If\n                not provided, the default SSL client certificate will be used if\n                present. If GOOGLE_API_USE_CLIENT_CERTIFICATE is \"false\" or not\n                set, no client certificate will be used.\n            client_info (google.api_core.gapic_v1.client_info.ClientInfo):\n                The client info used to send a user-agent string along with\n                API requests. If ``None``, then default info will be used.\n                Generally, you only need to set this if you're developing\n                your own client library.\n\n        Raises:\n            google.auth.exceptions.MutualTLSChannelError: If mutual TLS transport\n                creation failed for any reason.\n        \"\"\"\n        if isinstance(client_options, dict):\n            client_options = client_options_lib.from_dict(client_options)\n        if client_options is None:\n            client_options = client_options_lib.ClientOptions()\n\n        # Create SSL credentials for mutual TLS if needed.\n        use_client_cert = os.getenv(\n            \"GOOGLE_API_USE_CLIENT_CERTIFICATE\", \"false\"\n        ).lower()\n        if use_client_cert not in (\"true\", \"false\"):\n            raise ValueError(\n                \"Environment variable `GOOGLE_API_USE_CLIENT_CERTIFICATE` must be either `true` or `false`\"\n            )\n        client_cert_source_func = None\n        is_mtls = False\n        if use_client_cert == \"true\":\n            if client_options.client_cert_source:\n                is_mtls = True\n                client_cert_source_func = client_options.client_cert_source\n            else:\n                is_mtls = mtls.has_default_client_cert_source()\n                if is_mtls:\n                    client_cert_source_func = mtls.default_client_cert_source()\n                else:\n                    client_cert_source_func = None\n\n        # Figure out which api endpoint to use.\n        if client_options.api_endpoint is not None:\n            api_endpoint = client_options.api_endpoint\n        else:\n            use_mtls_env = os.getenv(\"GOOGLE_API_USE_MTLS_ENDPOINT\", \"auto\")\n            if use_mtls_env == \"never\":\n                api_endpoint = self.DEFAULT_ENDPOINT\n            elif use_mtls_env == \"always\":\n                api_endpoint = self.DEFAULT_MTLS_ENDPOINT\n            elif use_mtls_env == \"auto\":\n                if is_mtls:\n                    api_endpoint = self.DEFAULT_MTLS_ENDPOINT\n                else:\n                    api_endpoint = self.DEFAULT_ENDPOINT\n            else:\n                raise MutualTLSChannelError(\n                    \"Unsupported GOOGLE_API_USE_MTLS_ENDPOINT value. Accepted \"\n                    \"values: never, auto, always\"\n                )\n\n        # Save or instantiate the transport.\n        # Ordinarily, we provide the transport, but allowing a custom transport\n        # instance provides an extensibility point for unusual situations.\n        if isinstance(transport, OperationsTransport):\n            # transport is a OperationsTransport instance.\n            if credentials or client_options.credentials_file:\n                raise ValueError(\n                    \"When providing a transport instance, \"\n                    \"provide its credentials directly.\"\n                )\n            if client_options.scopes:\n                raise ValueError(\n                    \"When providing a transport instance, provide its scopes \"\n                    \"directly.\"\n                )\n            self._transport = transport\n        else:\n            Transport = type(self).get_transport_class(transport)\n            self._transport = Transport(\n                credentials=credentials,\n                credentials_file=client_options.credentials_file,\n                host=api_endpoint,\n                scopes=client_options.scopes,\n                client_cert_source_for_mtls=client_cert_source_func,\n                quota_project_id=client_options.quota_project_id,\n                client_info=client_info,\n                always_use_jwt_access=True,\n            )\n\n    def list_operations(\n        self,\n        name: str,\n        filter_: Optional[str] = None,\n        *,\n        page_size: Optional[int] = None,\n        page_token: Optional[str] = None,\n        retry: OptionalRetry = gapic_v1.method.DEFAULT,\n        timeout: Optional[float] = None,\n        compression: Optional[grpc.Compression] = gapic_v1.method.DEFAULT,\n        metadata: Sequence[Tuple[str, str]] = (),\n    ) -> pagers.ListOperationsPager:\n        r\"\"\"Lists operations that match the specified filter in the request.\n        If the server doesn't support this method, it returns\n        ``UNIMPLEMENTED``.\n\n        NOTE: the ``name`` binding allows API services to override the\n        binding to use different resource name schemes, such as\n        ``users/*/operations``. To override the binding, API services\n        can add a binding such as ``\"/v1/{name=users/*}/operations\"`` to\n        their service configuration. For backwards compatibility, the\n        default name includes the operations collection id, however\n        overriding users must ensure the name binding is the parent\n        resource, without the operations collection id.\n\n        Args:\n            name (str):\n                The name of the operation's parent\n                resource.\n            filter_ (str):\n                The standard list filter.\n                This corresponds to the ``filter`` field\n                on the ``request`` instance; if ``request`` is provided, this\n                should not be set.\n            retry (google.api_core.retry.Retry): Designation of what errors, if any,\n                should be retried.\n            timeout (float): The timeout for this request.\n            metadata (Sequence[Tuple[str, str]]): Strings which should be\n                sent along with the request as metadata.\n\n        Returns:\n            google.api_core.operations_v1.pagers.ListOperationsPager:\n                The response message for\n                [Operations.ListOperations][google.api_core.operations_v1.Operations.ListOperations].\n\n                Iterating over this object will yield results and\n                resolve additional pages automatically.\n\n        \"\"\"\n        # Create a protobuf request object.\n        request = operations_pb2.ListOperationsRequest(name=name, filter=filter_)\n        if page_size is not None:\n            request.page_size = page_size\n        if page_token is not None:\n            request.page_token = page_token\n\n        # Wrap the RPC method; this adds retry and timeout information,\n        # and friendly error handling.\n        rpc = self._transport._wrapped_methods[self._transport.list_operations]\n\n        # Certain fields should be provided within the metadata header;\n        # add these here.\n        metadata = tuple(metadata or ()) + (\n            gapic_v1.routing_header.to_grpc_metadata(((\"name\", request.name),)),\n        )\n\n        # Send the request.\n        response = rpc(\n            request,\n            retry=retry,\n            timeout=timeout,\n            compression=compression,\n            metadata=metadata,\n        )\n\n        # This method is paged; wrap the response in a pager, which provides\n        # an `__iter__` convenience method.\n        response = pagers.ListOperationsPager(\n            method=rpc,\n            request=request,\n            response=response,\n            metadata=metadata,\n        )\n\n        # Done; return the response.\n        return response\n\n    def get_operation(\n        self,\n        name: str,\n        *,\n        retry: OptionalRetry = gapic_v1.method.DEFAULT,\n        timeout: Optional[float] = None,\n        compression: Optional[grpc.Compression] = gapic_v1.method.DEFAULT,\n        metadata: Sequence[Tuple[str, str]] = (),\n    ) -> operations_pb2.Operation:\n        r\"\"\"Gets the latest state of a long-running operation.\n        Clients can use this method to poll the operation result\n        at intervals as recommended by the API service.\n\n        Args:\n            name (str):\n                The name of the operation resource.\n            retry (google.api_core.retry.Retry): Designation of what errors, if any,\n                should be retried.\n            timeout (float): The timeout for this request.\n            metadata (Sequence[Tuple[str, str]]): Strings which should be\n                sent along with the request as metadata.\n\n        Returns:\n            google.longrunning.operations_pb2.Operation:\n                This resource represents a long-\n                running operation that is the result of a\n                network API call.\n\n        \"\"\"\n\n        request = operations_pb2.GetOperationRequest(name=name)\n\n        # Wrap the RPC method; this adds retry and timeout information,\n        # and friendly error handling.\n        rpc = self._transport._wrapped_methods[self._transport.get_operation]\n\n        # Certain fields should be provided within the metadata header;\n        # add these here.\n        metadata = tuple(metadata or ()) + (\n            gapic_v1.routing_header.to_grpc_metadata(((\"name\", request.name),)),\n        )\n\n        # Send the request.\n        response = rpc(\n            request,\n            retry=retry,\n            timeout=timeout,\n            compression=compression,\n            metadata=metadata,\n        )\n\n        # Done; return the response.\n        return response\n\n    def delete_operation(\n        self,\n        name: str,\n        *,\n        retry: OptionalRetry = gapic_v1.method.DEFAULT,\n        timeout: Optional[float] = None,\n        compression: Optional[grpc.Compression] = gapic_v1.method.DEFAULT,\n        metadata: Sequence[Tuple[str, str]] = (),\n    ) -> None:\n        r\"\"\"Deletes a long-running operation. This method indicates that the\n        client is no longer interested in the operation result. It does\n        not cancel the operation. If the server doesn't support this\n        method, it returns ``google.rpc.Code.UNIMPLEMENTED``.\n\n        Args:\n            name (str):\n                The name of the operation resource to\n                be deleted.\n\n                This corresponds to the ``name`` field\n                on the ``request`` instance; if ``request`` is provided, this\n                should not be set.\n            retry (google.api_core.retry.Retry): Designation of what errors, if any,\n                should be retried.\n            timeout (float): The timeout for this request.\n            metadata (Sequence[Tuple[str, str]]): Strings which should be\n                sent along with the request as metadata.\n        \"\"\"\n        # Create the request object.\n        request = operations_pb2.DeleteOperationRequest(name=name)\n\n        # Wrap the RPC method; this adds retry and timeout information,\n        # and friendly error handling.\n        rpc = self._transport._wrapped_methods[self._transport.delete_operation]\n\n        # Certain fields should be provided within the metadata header;\n        # add these here.\n        metadata = tuple(metadata or ()) + (\n            gapic_v1.routing_header.to_grpc_metadata(((\"name\", request.name),)),\n        )\n\n        # Send the request.\n        rpc(\n            request,\n            retry=retry,\n            timeout=timeout,\n            compression=compression,\n            metadata=metadata,\n        )\n\n    def cancel_operation(\n        self,\n        name: Optional[str] = None,\n        *,\n        retry: OptionalRetry = gapic_v1.method.DEFAULT,\n        timeout: Optional[float] = None,\n        compression: Optional[grpc.Compression] = gapic_v1.method.DEFAULT,\n        metadata: Sequence[Tuple[str, str]] = (),\n    ) -> None:\n        r\"\"\"Starts asynchronous cancellation on a long-running operation.\n        The server makes a best effort to cancel the operation, but\n        success is not guaranteed. If the server doesn't support this\n        method, it returns ``google.rpc.Code.UNIMPLEMENTED``. Clients\n        can use\n        [Operations.GetOperation][google.api_core.operations_v1.Operations.GetOperation]\n        or other methods to check whether the cancellation succeeded or\n        whether the operation completed despite cancellation. On\n        successful cancellation, the operation is not deleted; instead,\n        it becomes an operation with an\n        [Operation.error][google.api_core.operations_v1.Operation.error] value with\n        a [google.rpc.Status.code][google.rpc.Status.code] of 1,\n        corresponding to ``Code.CANCELLED``.\n\n        Args:\n            name (str):\n                The name of the operation resource to\n                be cancelled.\n\n                This corresponds to the ``name`` field\n                on the ``request`` instance; if ``request`` is provided, this\n                should not be set.\n            retry (google.api_core.retry.Retry): Designation of what errors, if any,\n                should be retried.\n            timeout (float): The timeout for this request.\n            metadata (Sequence[Tuple[str, str]]): Strings which should be\n                sent along with the request as metadata.\n        \"\"\"\n        # Create the request object.\n        request = operations_pb2.CancelOperationRequest(name=name)\n\n        # Wrap the RPC method; this adds retry and timeout information,\n        # and friendly error handling.\n        rpc = self._transport._wrapped_methods[self._transport.cancel_operation]\n\n        # Certain fields should be provided within the metadata header;\n        # add these here.\n        metadata = tuple(metadata or ()) + (\n            gapic_v1.routing_header.to_grpc_metadata(((\"name\", request.name),)),\n        )\n\n        # Send the request.\n        rpc(\n            request,\n            retry=retry,\n            timeout=timeout,\n            compression=compression,\n            metadata=metadata,\n        )\n", "google/api_core/operations_v1/operations_async_client.py": "# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"An async client for the google.longrunning.operations meta-API.\n\n.. _Google API Style Guide:\n    https://cloud.google.com/apis/design/design_pattern\n    s#long_running_operations\n.. _google/longrunning/operations.proto:\n    https://github.com/googleapis/googleapis/blob/master/google/longrunning\n    /operations.proto\n\"\"\"\n\nimport functools\n\nfrom google.api_core import exceptions as core_exceptions\nfrom google.api_core import gapic_v1, page_iterator_async\nfrom google.api_core import retry_async as retries\nfrom google.api_core import timeout as timeouts\nfrom google.longrunning import operations_pb2\nfrom grpc import Compression\n\n\nclass OperationsAsyncClient:\n    \"\"\"Async client for interacting with long-running operations.\n\n    Args:\n        channel (aio.Channel): The gRPC AsyncIO channel associated with the\n            service that implements the ``google.longrunning.operations``\n            interface.\n        client_config (dict):\n            A dictionary of call options for each method. If not specified\n            the default configuration is used.\n    \"\"\"\n\n    def __init__(self, channel, client_config=None):\n        # Create the gRPC client stub with gRPC AsyncIO channel.\n        self.operations_stub = operations_pb2.OperationsStub(channel)\n\n        default_retry = retries.AsyncRetry(\n            initial=0.1,  # seconds\n            maximum=60.0,  # seconds\n            multiplier=1.3,\n            predicate=retries.if_exception_type(\n                core_exceptions.DeadlineExceeded,\n                core_exceptions.ServiceUnavailable,\n            ),\n            timeout=600.0,  # seconds\n        )\n        default_timeout = timeouts.TimeToDeadlineTimeout(timeout=600.0)\n\n        default_compression = Compression.NoCompression\n\n        self._get_operation = gapic_v1.method_async.wrap_method(\n            self.operations_stub.GetOperation,\n            default_retry=default_retry,\n            default_timeout=default_timeout,\n            default_compression=default_compression,\n        )\n\n        self._list_operations = gapic_v1.method_async.wrap_method(\n            self.operations_stub.ListOperations,\n            default_retry=default_retry,\n            default_timeout=default_timeout,\n            default_compression=default_compression,\n        )\n\n        self._cancel_operation = gapic_v1.method_async.wrap_method(\n            self.operations_stub.CancelOperation,\n            default_retry=default_retry,\n            default_timeout=default_timeout,\n            default_compression=default_compression,\n        )\n\n        self._delete_operation = gapic_v1.method_async.wrap_method(\n            self.operations_stub.DeleteOperation,\n            default_retry=default_retry,\n            default_timeout=default_timeout,\n            default_compression=default_compression,\n        )\n\n    async def get_operation(\n        self,\n        name,\n        retry=gapic_v1.method_async.DEFAULT,\n        timeout=gapic_v1.method_async.DEFAULT,\n        compression=gapic_v1.method_async.DEFAULT,\n        metadata=None,\n    ):\n        \"\"\"Gets the latest state of a long-running operation.\n\n        Clients can use this method to poll the operation result at intervals\n        as recommended by the API service.\n\n        Example:\n            >>> from google.api_core import operations_v1\n            >>> api = operations_v1.OperationsClient()\n            >>> name = ''\n            >>> response = await api.get_operation(name)\n\n        Args:\n            name (str): The name of the operation resource.\n            retry (google.api_core.retry.Retry): The retry strategy to use\n                when invoking the RPC. If unspecified, the default retry from\n                the client configuration will be used. If ``None``, then this\n                method will not retry the RPC at all.\n            timeout (float): The amount of time in seconds to wait for the RPC\n                to complete. Note that if ``retry`` is used, this timeout\n                applies to each individual attempt and the overall time it\n                takes for this method to complete may be longer. If\n                unspecified, the the default timeout in the client\n                configuration is used. If ``None``, then the RPC method will\n                not time out.\n            compression (grpc.Compression): An element of grpc.compression\n                e.g. grpc.compression.Gzip.\n            metadata (Optional[List[Tuple[str, str]]]):\n                Additional gRPC metadata.\n\n        Returns:\n            google.longrunning.operations_pb2.Operation: The state of the\n                operation.\n\n        Raises:\n            google.api_core.exceptions.GoogleAPICallError: If an error occurred\n                while invoking the RPC, the appropriate ``GoogleAPICallError``\n                subclass will be raised.\n        \"\"\"\n        request = operations_pb2.GetOperationRequest(name=name)\n\n        # Add routing header\n        metadata = metadata or []\n        metadata.append(gapic_v1.routing_header.to_grpc_metadata({\"name\": name}))\n\n        return await self._get_operation(\n            request,\n            retry=retry,\n            timeout=timeout,\n            compression=compression,\n            metadata=metadata,\n        )\n\n    async def list_operations(\n        self,\n        name,\n        filter_,\n        retry=gapic_v1.method_async.DEFAULT,\n        timeout=gapic_v1.method_async.DEFAULT,\n        compression=gapic_v1.method_async.DEFAULT,\n        metadata=None,\n    ):\n        \"\"\"\n        Lists operations that match the specified filter in the request.\n\n        Example:\n            >>> from google.api_core import operations_v1\n            >>> api = operations_v1.OperationsClient()\n            >>> name = ''\n            >>>\n            >>> # Iterate over all results\n            >>> for operation in await api.list_operations(name):\n            >>>   # process operation\n            >>>   pass\n            >>>\n            >>> # Or iterate over results one page at a time\n            >>> iter = await api.list_operations(name)\n            >>> for page in iter.pages:\n            >>>   for operation in page:\n            >>>     # process operation\n            >>>     pass\n\n        Args:\n            name (str): The name of the operation collection.\n            filter_ (str): The standard list filter.\n            retry (google.api_core.retry.Retry): The retry strategy to use\n                when invoking the RPC. If unspecified, the default retry from\n                the client configuration will be used. If ``None``, then this\n                method will not retry the RPC at all.\n            timeout (float): The amount of time in seconds to wait for the RPC\n                to complete. Note that if ``retry`` is used, this timeout\n                applies to each individual attempt and the overall time it\n                takes for this method to complete may be longer. If\n                unspecified, the the default timeout in the client\n                configuration is used. If ``None``, then the RPC method will\n                not time out.\n            compression (grpc.Compression): An element of grpc.compression\n                e.g. grpc.compression.Gzip.\n            metadata (Optional[List[Tuple[str, str]]]): Additional gRPC\n                metadata.\n\n        Returns:\n            google.api_core.page_iterator.Iterator: An iterator that yields\n                :class:`google.longrunning.operations_pb2.Operation` instances.\n\n        Raises:\n            google.api_core.exceptions.MethodNotImplemented: If the server\n                does not support this method. Services are not required to\n                implement this method.\n            google.api_core.exceptions.GoogleAPICallError: If an error occurred\n                while invoking the RPC, the appropriate ``GoogleAPICallError``\n                subclass will be raised.\n        \"\"\"\n        # Create the request object.\n        request = operations_pb2.ListOperationsRequest(name=name, filter=filter_)\n\n        # Add routing header\n        metadata = metadata or []\n        metadata.append(gapic_v1.routing_header.to_grpc_metadata({\"name\": name}))\n\n        # Create the method used to fetch pages\n        method = functools.partial(\n            self._list_operations,\n            retry=retry,\n            timeout=timeout,\n            compression=compression,\n            metadata=metadata,\n        )\n\n        iterator = page_iterator_async.AsyncGRPCIterator(\n            client=None,\n            method=method,\n            request=request,\n            items_field=\"operations\",\n            request_token_field=\"page_token\",\n            response_token_field=\"next_page_token\",\n        )\n\n        return iterator\n\n    async def cancel_operation(\n        self,\n        name,\n        retry=gapic_v1.method_async.DEFAULT,\n        timeout=gapic_v1.method_async.DEFAULT,\n        compression=gapic_v1.method_async.DEFAULT,\n        metadata=None,\n    ):\n        \"\"\"Starts asynchronous cancellation on a long-running operation.\n\n        The server makes a best effort to cancel the operation, but success is\n        not guaranteed. Clients can use :meth:`get_operation` or service-\n        specific methods to check whether the cancellation succeeded or whether\n        the operation completed despite cancellation. On successful\n        cancellation, the operation is not deleted; instead, it becomes an\n        operation with an ``Operation.error`` value with a\n        ``google.rpc.Status.code`` of ``1``, corresponding to\n        ``Code.CANCELLED``.\n\n        Example:\n            >>> from google.api_core import operations_v1\n            >>> api = operations_v1.OperationsClient()\n            >>> name = ''\n            >>> api.cancel_operation(name)\n\n        Args:\n            name (str): The name of the operation resource to be cancelled.\n            retry (google.api_core.retry.Retry): The retry strategy to use\n                when invoking the RPC. If unspecified, the default retry from\n                the client configuration will be used. If ``None``, then this\n                method will not retry the RPC at all.\n            timeout (float): The amount of time in seconds to wait for the RPC\n                to complete. Note that if ``retry`` is used, this timeout\n                applies to each individual attempt and the overall time it\n                takes for this method to complete may be longer. If\n                unspecified, the the default timeout in the client\n                configuration is used. If ``None``, then the RPC method will\n                not time out.\n\n        Raises:\n            google.api_core.exceptions.MethodNotImplemented: If the server\n                does not support this method. Services are not required to\n                implement this method.\n            google.api_core.exceptions.GoogleAPICallError: If an error occurred\n                while invoking the RPC, the appropriate ``GoogleAPICallError``\n                subclass will be raised.\n            compression (grpc.Compression): An element of grpc.compression\n                e.g. grpc.compression.Gzip.\n            metadata (Optional[List[Tuple[str, str]]]): Additional gRPC\n                metadata.\n        \"\"\"\n        # Create the request object.\n        request = operations_pb2.CancelOperationRequest(name=name)\n\n        # Add routing header\n        metadata = metadata or []\n        metadata.append(gapic_v1.routing_header.to_grpc_metadata({\"name\": name}))\n\n        await self._cancel_operation(\n            request,\n            retry=retry,\n            timeout=timeout,\n            compression=compression,\n            metadata=metadata,\n        )\n\n    async def delete_operation(\n        self,\n        name,\n        retry=gapic_v1.method_async.DEFAULT,\n        timeout=gapic_v1.method_async.DEFAULT,\n        compression=gapic_v1.method_async.DEFAULT,\n        metadata=None,\n    ):\n        \"\"\"Deletes a long-running operation.\n\n        This method indicates that the client is no longer interested in the\n        operation result. It does not cancel the operation.\n\n        Example:\n            >>> from google.api_core import operations_v1\n            >>> api = operations_v1.OperationsClient()\n            >>> name = ''\n            >>> api.delete_operation(name)\n\n        Args:\n            name (str): The name of the operation resource to be deleted.\n            retry (google.api_core.retry.Retry): The retry strategy to use\n                when invoking the RPC. If unspecified, the default retry from\n                the client configuration will be used. If ``None``, then this\n                method will not retry the RPC at all.\n            timeout (float): The amount of time in seconds to wait for the RPC\n                to complete. Note that if ``retry`` is used, this timeout\n                applies to each individual attempt and the overall time it\n                takes for this method to complete may be longer. If\n                unspecified, the the default timeout in the client\n                configuration is used. If ``None``, then the RPC method will\n                not time out.\n            compression (grpc.Compression): An element of grpc.compression\n                e.g. grpc.compression.Gzip.\n            metadata (Optional[List[Tuple[str, str]]]): Additional gRPC\n                metadata.\n\n        Raises:\n            google.api_core.exceptions.MethodNotImplemented: If the server\n                does not support this method. Services are not required to\n                implement this method.\n            google.api_core.exceptions.GoogleAPICallError: If an error occurred\n                while invoking the RPC, the appropriate ``GoogleAPICallError``\n                subclass will be raised.\n        \"\"\"\n        # Create the request object.\n        request = operations_pb2.DeleteOperationRequest(name=name)\n\n        # Add routing header\n        metadata = metadata or []\n        metadata.append(gapic_v1.routing_header.to_grpc_metadata({\"name\": name}))\n\n        await self._delete_operation(\n            request,\n            retry=retry,\n            timeout=timeout,\n            compression=compression,\n            metadata=metadata,\n        )\n", "google/api_core/operations_v1/pagers.py": "# -*- coding: utf-8 -*-\n# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\nfrom typing import (\n    Any,\n    Callable,\n    Iterator,\n    Sequence,\n    Tuple,\n)\n\nfrom google.longrunning import operations_pb2\n\n\nclass ListOperationsPager:\n    \"\"\"A pager for iterating through ``list_operations`` requests.\n\n    This class thinly wraps an initial\n    :class:`google.longrunning.operations_pb2.ListOperationsResponse` object, and\n    provides an ``__iter__`` method to iterate through its\n    ``operations`` field.\n\n    If there are more pages, the ``__iter__`` method will make additional\n    ``ListOperations`` requests and continue to iterate\n    through the ``operations`` field on the\n    corresponding responses.\n\n    All the usual :class:`google.longrunning.operations_pb2.ListOperationsResponse`\n    attributes are available on the pager. If multiple requests are made, only\n    the most recent response is retained, and thus used for attribute lookup.\n    \"\"\"\n\n    def __init__(\n        self,\n        method: Callable[..., operations_pb2.ListOperationsResponse],\n        request: operations_pb2.ListOperationsRequest,\n        response: operations_pb2.ListOperationsResponse,\n        *,\n        metadata: Sequence[Tuple[str, str]] = ()\n    ):\n        \"\"\"Instantiate the pager.\n\n        Args:\n            method (Callable): The method that was originally called, and\n                which instantiated this pager.\n            request (google.longrunning.operations_pb2.ListOperationsRequest):\n                The initial request object.\n            response (google.longrunning.operations_pb2.ListOperationsResponse):\n                The initial response object.\n            metadata (Sequence[Tuple[str, str]]): Strings which should be\n                sent along with the request as metadata.\n        \"\"\"\n        self._method = method\n        self._request = request\n        self._response = response\n        self._metadata = metadata\n\n    def __getattr__(self, name: str) -> Any:\n        return getattr(self._response, name)\n\n    @property\n    def pages(self) -> Iterator[operations_pb2.ListOperationsResponse]:\n        yield self._response\n        while self._response.next_page_token:\n            self._request.page_token = self._response.next_page_token\n            self._response = self._method(self._request, metadata=self._metadata)\n            yield self._response\n\n    def __iter__(self) -> Iterator[operations_pb2.Operation]:\n        for page in self.pages:\n            yield from page.operations\n\n    def __repr__(self) -> str:\n        return \"{0}<{1!r}>\".format(self.__class__.__name__, self._response)\n", "google/api_core/operations_v1/__init__.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Package for interacting with the google.longrunning.operations meta-API.\"\"\"\n\nfrom google.api_core.operations_v1.abstract_operations_client import (\n    AbstractOperationsClient,\n)\nfrom google.api_core.operations_v1.operations_async_client import OperationsAsyncClient\nfrom google.api_core.operations_v1.operations_client import OperationsClient\nfrom google.api_core.operations_v1.transports.rest import OperationsRestTransport\n\n__all__ = [\n    \"AbstractOperationsClient\",\n    \"OperationsAsyncClient\",\n    \"OperationsClient\",\n    \"OperationsRestTransport\",\n]\n", "google/api_core/operations_v1/operations_client_config.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"gapic configuration for the google.longrunning.operations client.\"\"\"\n\n# DEPRECATED: retry and timeout classes are instantiated directly\nconfig = {\n    \"interfaces\": {\n        \"google.longrunning.Operations\": {\n            \"retry_codes\": {\n                \"idempotent\": [\"DEADLINE_EXCEEDED\", \"UNAVAILABLE\"],\n                \"non_idempotent\": [],\n            },\n            \"retry_params\": {\n                \"default\": {\n                    \"initial_retry_delay_millis\": 100,\n                    \"retry_delay_multiplier\": 1.3,\n                    \"max_retry_delay_millis\": 60000,\n                    \"initial_rpc_timeout_millis\": 20000,\n                    \"rpc_timeout_multiplier\": 1.0,\n                    \"max_rpc_timeout_millis\": 600000,\n                    \"total_timeout_millis\": 600000,\n                }\n            },\n            \"methods\": {\n                \"GetOperation\": {\n                    \"timeout_millis\": 60000,\n                    \"retry_codes_name\": \"idempotent\",\n                    \"retry_params_name\": \"default\",\n                },\n                \"ListOperations\": {\n                    \"timeout_millis\": 60000,\n                    \"retry_codes_name\": \"idempotent\",\n                    \"retry_params_name\": \"default\",\n                },\n                \"CancelOperation\": {\n                    \"timeout_millis\": 60000,\n                    \"retry_codes_name\": \"idempotent\",\n                    \"retry_params_name\": \"default\",\n                },\n                \"DeleteOperation\": {\n                    \"timeout_millis\": 60000,\n                    \"retry_codes_name\": \"idempotent\",\n                    \"retry_params_name\": \"default\",\n                },\n            },\n        }\n    }\n}\n", "google/api_core/operations_v1/transports/rest.py": "# -*- coding: utf-8 -*-\n# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\nimport re\nfrom typing import Callable, Dict, Optional, Sequence, Tuple, Union\n\nfrom requests import __version__ as requests_version\n\nfrom google.api_core import exceptions as core_exceptions  # type: ignore\nfrom google.api_core import gapic_v1  # type: ignore\nfrom google.api_core import path_template  # type: ignore\nfrom google.api_core import rest_helpers  # type: ignore\nfrom google.api_core import retry as retries  # type: ignore\nfrom google.auth import credentials as ga_credentials  # type: ignore\nfrom google.auth.transport.requests import AuthorizedSession  # type: ignore\nfrom google.longrunning import operations_pb2  # type: ignore\nfrom google.protobuf import empty_pb2  # type: ignore\nfrom google.protobuf import json_format  # type: ignore\nimport google.protobuf\n\nimport grpc\nfrom .base import DEFAULT_CLIENT_INFO as BASE_DEFAULT_CLIENT_INFO, OperationsTransport\n\nPROTOBUF_VERSION = google.protobuf.__version__\n\nOptionalRetry = Union[retries.Retry, object]\n\nDEFAULT_CLIENT_INFO = gapic_v1.client_info.ClientInfo(\n    gapic_version=BASE_DEFAULT_CLIENT_INFO.gapic_version,\n    grpc_version=None,\n    rest_version=requests_version,\n)\n\n\nclass OperationsRestTransport(OperationsTransport):\n    \"\"\"REST backend transport for Operations.\n\n    Manages long-running operations with an API service.\n\n    When an API method normally takes long time to complete, it can be\n    designed to return [Operation][google.api_core.operations_v1.Operation] to the\n    client, and the client can use this interface to receive the real\n    response asynchronously by polling the operation resource, or pass\n    the operation resource to another API (such as Google Cloud Pub/Sub\n    API) to receive the response. Any API service that returns\n    long-running operations should implement the ``Operations``\n    interface so developers can have a consistent client experience.\n\n    This class defines the same methods as the primary client, so the\n    primary client can load the underlying transport implementation\n    and call it.\n\n    It sends JSON representations of protocol buffers over HTTP/1.1\n    \"\"\"\n\n    def __init__(\n        self,\n        *,\n        host: str = \"longrunning.googleapis.com\",\n        credentials: Optional[ga_credentials.Credentials] = None,\n        credentials_file: Optional[str] = None,\n        scopes: Optional[Sequence[str]] = None,\n        client_cert_source_for_mtls: Optional[Callable[[], Tuple[bytes, bytes]]] = None,\n        quota_project_id: Optional[str] = None,\n        client_info: gapic_v1.client_info.ClientInfo = DEFAULT_CLIENT_INFO,\n        always_use_jwt_access: Optional[bool] = False,\n        url_scheme: str = \"https\",\n        http_options: Optional[Dict] = None,\n        path_prefix: str = \"v1\",\n    ) -> None:\n        \"\"\"Instantiate the transport.\n\n        Args:\n            host (Optional[str]):\n                 The hostname to connect to.\n            credentials (Optional[google.auth.credentials.Credentials]): The\n                authorization credentials to attach to requests. These\n                credentials identify the application to the service; if none\n                are specified, the client will attempt to ascertain the\n                credentials from the environment.\n\n            credentials_file (Optional[str]): A file with credentials that can\n                be loaded with :func:`google.auth.load_credentials_from_file`.\n                This argument is ignored if ``channel`` is provided.\n            scopes (Optional(Sequence[str])): A list of scopes. This argument is\n                ignored if ``channel`` is provided.\n            client_cert_source_for_mtls (Callable[[], Tuple[bytes, bytes]]): Client\n                certificate to configure mutual TLS HTTP channel. It is ignored\n                if ``channel`` is provided.\n            quota_project_id (Optional[str]): An optional project to use for billing\n                and quota.\n            client_info (google.api_core.gapic_v1.client_info.ClientInfo):\n                The client info used to send a user-agent string along with\n                API requests. If ``None``, then default info will be used.\n                Generally, you only need to set this if you're developing\n                your own client library.\n            always_use_jwt_access (Optional[bool]): Whether self signed JWT should\n                be used for service account credentials.\n            url_scheme: the protocol scheme for the API endpoint.  Normally\n                \"https\", but for testing or local servers,\n                \"http\" can be specified.\n            http_options: a dictionary of http_options for transcoding, to override\n                the defaults from operations.proto.  Each method has an entry\n                with the corresponding http rules as value.\n            path_prefix: path prefix (usually represents API version). Set to\n                \"v1\" by default.\n\n        \"\"\"\n        # Run the base constructor\n        # TODO(yon-mg): resolve other ctor params i.e. scopes, quota, etc.\n        # TODO: When custom host (api_endpoint) is set, `scopes` must *also* be set on the\n        # credentials object\n        maybe_url_match = re.match(\"^(?P<scheme>http(?:s)?://)?(?P<host>.*)$\", host)\n        if maybe_url_match is None:\n            raise ValueError(\n                f\"Unexpected hostname structure: {host}\"\n            )  # pragma: NO COVER\n\n        url_match_items = maybe_url_match.groupdict()\n\n        host = f\"{url_scheme}://{host}\" if not url_match_items[\"scheme\"] else host\n\n        super().__init__(\n            host=host,\n            credentials=credentials,\n            client_info=client_info,\n            always_use_jwt_access=always_use_jwt_access,\n        )\n        self._session = AuthorizedSession(\n            self._credentials, default_host=self.DEFAULT_HOST\n        )\n        if client_cert_source_for_mtls:\n            self._session.configure_mtls_channel(client_cert_source_for_mtls)\n        self._prep_wrapped_messages(client_info)\n        self._http_options = http_options or {}\n        self._path_prefix = path_prefix\n\n    def _list_operations(\n        self,\n        request: operations_pb2.ListOperationsRequest,\n        *,\n        retry: OptionalRetry = gapic_v1.method.DEFAULT,\n        timeout: Optional[float] = None,\n        compression: Optional[grpc.Compression] = gapic_v1.method.DEFAULT,\n        metadata: Sequence[Tuple[str, str]] = (),\n    ) -> operations_pb2.ListOperationsResponse:\n        r\"\"\"Call the list operations method over HTTP.\n\n        Args:\n            request (~.operations_pb2.ListOperationsRequest):\n                The request object. The request message for\n                [Operations.ListOperations][google.api_core.operations_v1.Operations.ListOperations].\n\n            retry (google.api_core.retry.Retry): Designation of what errors, if any,\n                should be retried.\n            timeout (float): The timeout for this request.\n            metadata (Sequence[Tuple[str, str]]): Strings which should be\n                sent along with the request as metadata.\n\n        Returns:\n            ~.operations_pb2.ListOperationsResponse:\n                The response message for\n                [Operations.ListOperations][google.api_core.operations_v1.Operations.ListOperations].\n\n        \"\"\"\n\n        http_options = [\n            {\n                \"method\": \"get\",\n                \"uri\": \"/{}/{{name=**}}/operations\".format(self._path_prefix),\n            },\n        ]\n        if \"google.longrunning.Operations.ListOperations\" in self._http_options:\n            http_options = self._http_options[\n                \"google.longrunning.Operations.ListOperations\"\n            ]\n\n        request_kwargs = self._convert_protobuf_message_to_dict(request)\n        transcoded_request = path_template.transcode(http_options, **request_kwargs)\n\n        uri = transcoded_request[\"uri\"]\n        method = transcoded_request[\"method\"]\n\n        # Jsonify the query params\n        query_params_request = operations_pb2.ListOperationsRequest()\n        json_format.ParseDict(transcoded_request[\"query_params\"], query_params_request)\n        query_params = json_format.MessageToDict(\n            query_params_request,\n            preserving_proto_field_name=False,\n            use_integers_for_enums=False,\n        )\n\n        # Send the request\n        headers = dict(metadata)\n        headers[\"Content-Type\"] = \"application/json\"\n        response = getattr(self._session, method)(\n            \"{host}{uri}\".format(host=self._host, uri=uri),\n            timeout=timeout,\n            headers=headers,\n            params=rest_helpers.flatten_query_params(query_params),\n        )\n\n        # In case of error, raise the appropriate core_exceptions.GoogleAPICallError exception\n        # subclass.\n        if response.status_code >= 400:\n            raise core_exceptions.from_http_response(response)\n\n        # Return the response\n        api_response = operations_pb2.ListOperationsResponse()\n        json_format.Parse(response.content, api_response, ignore_unknown_fields=False)\n        return api_response\n\n    def _get_operation(\n        self,\n        request: operations_pb2.GetOperationRequest,\n        *,\n        retry: OptionalRetry = gapic_v1.method.DEFAULT,\n        timeout: Optional[float] = None,\n        compression: Optional[grpc.Compression] = gapic_v1.method.DEFAULT,\n        metadata: Sequence[Tuple[str, str]] = (),\n    ) -> operations_pb2.Operation:\n        r\"\"\"Call the get operation method over HTTP.\n\n        Args:\n            request (~.operations_pb2.GetOperationRequest):\n                The request object. The request message for\n                [Operations.GetOperation][google.api_core.operations_v1.Operations.GetOperation].\n\n            retry (google.api_core.retry.Retry): Designation of what errors, if any,\n                should be retried.\n            timeout (float): The timeout for this request.\n            metadata (Sequence[Tuple[str, str]]): Strings which should be\n                sent along with the request as metadata.\n\n        Returns:\n            ~.operations_pb2.Operation:\n                This resource represents a long-\n                running operation that is the result of a\n                network API call.\n\n        \"\"\"\n\n        http_options = [\n            {\n                \"method\": \"get\",\n                \"uri\": \"/{}/{{name=**/operations/*}}\".format(self._path_prefix),\n            },\n        ]\n        if \"google.longrunning.Operations.GetOperation\" in self._http_options:\n            http_options = self._http_options[\n                \"google.longrunning.Operations.GetOperation\"\n            ]\n\n        request_kwargs = self._convert_protobuf_message_to_dict(request)\n        transcoded_request = path_template.transcode(http_options, **request_kwargs)\n\n        uri = transcoded_request[\"uri\"]\n        method = transcoded_request[\"method\"]\n\n        # Jsonify the query params\n        query_params_request = operations_pb2.GetOperationRequest()\n        json_format.ParseDict(transcoded_request[\"query_params\"], query_params_request)\n        query_params = json_format.MessageToDict(\n            query_params_request,\n            preserving_proto_field_name=False,\n            use_integers_for_enums=False,\n        )\n\n        # Send the request\n        headers = dict(metadata)\n        headers[\"Content-Type\"] = \"application/json\"\n        response = getattr(self._session, method)(\n            \"{host}{uri}\".format(host=self._host, uri=uri),\n            timeout=timeout,\n            headers=headers,\n            params=rest_helpers.flatten_query_params(query_params),\n        )\n\n        # In case of error, raise the appropriate core_exceptions.GoogleAPICallError exception\n        # subclass.\n        if response.status_code >= 400:\n            raise core_exceptions.from_http_response(response)\n\n        # Return the response\n        api_response = operations_pb2.Operation()\n        json_format.Parse(response.content, api_response, ignore_unknown_fields=False)\n        return api_response\n\n    def _delete_operation(\n        self,\n        request: operations_pb2.DeleteOperationRequest,\n        *,\n        retry: OptionalRetry = gapic_v1.method.DEFAULT,\n        timeout: Optional[float] = None,\n        compression: Optional[grpc.Compression] = gapic_v1.method.DEFAULT,\n        metadata: Sequence[Tuple[str, str]] = (),\n    ) -> empty_pb2.Empty:\n        r\"\"\"Call the delete operation method over HTTP.\n\n        Args:\n            request (~.operations_pb2.DeleteOperationRequest):\n                The request object. The request message for\n                [Operations.DeleteOperation][google.api_core.operations_v1.Operations.DeleteOperation].\n\n            retry (google.api_core.retry.Retry): Designation of what errors, if any,\n                should be retried.\n            timeout (float): The timeout for this request.\n            metadata (Sequence[Tuple[str, str]]): Strings which should be\n                sent along with the request as metadata.\n        \"\"\"\n\n        http_options = [\n            {\n                \"method\": \"delete\",\n                \"uri\": \"/{}/{{name=**/operations/*}}\".format(self._path_prefix),\n            },\n        ]\n        if \"google.longrunning.Operations.DeleteOperation\" in self._http_options:\n            http_options = self._http_options[\n                \"google.longrunning.Operations.DeleteOperation\"\n            ]\n\n        request_kwargs = self._convert_protobuf_message_to_dict(request)\n        transcoded_request = path_template.transcode(http_options, **request_kwargs)\n\n        uri = transcoded_request[\"uri\"]\n        method = transcoded_request[\"method\"]\n\n        # Jsonify the query params\n        query_params_request = operations_pb2.DeleteOperationRequest()\n        json_format.ParseDict(transcoded_request[\"query_params\"], query_params_request)\n        query_params = json_format.MessageToDict(\n            query_params_request,\n            preserving_proto_field_name=False,\n            use_integers_for_enums=False,\n        )\n\n        # Send the request\n        headers = dict(metadata)\n        headers[\"Content-Type\"] = \"application/json\"\n        response = getattr(self._session, method)(\n            \"{host}{uri}\".format(host=self._host, uri=uri),\n            timeout=timeout,\n            headers=headers,\n            params=rest_helpers.flatten_query_params(query_params),\n        )\n\n        # In case of error, raise the appropriate core_exceptions.GoogleAPICallError exception\n        # subclass.\n        if response.status_code >= 400:\n            raise core_exceptions.from_http_response(response)\n\n        return empty_pb2.Empty()\n\n    def _cancel_operation(\n        self,\n        request: operations_pb2.CancelOperationRequest,\n        *,\n        retry: OptionalRetry = gapic_v1.method.DEFAULT,\n        timeout: Optional[float] = None,\n        compression: Optional[grpc.Compression] = gapic_v1.method.DEFAULT,\n        metadata: Sequence[Tuple[str, str]] = (),\n    ) -> empty_pb2.Empty:\n        r\"\"\"Call the cancel operation method over HTTP.\n\n        Args:\n            request (~.operations_pb2.CancelOperationRequest):\n                The request object. The request message for\n                [Operations.CancelOperation][google.api_core.operations_v1.Operations.CancelOperation].\n\n            retry (google.api_core.retry.Retry): Designation of what errors, if any,\n                should be retried.\n            timeout (float): The timeout for this request.\n            metadata (Sequence[Tuple[str, str]]): Strings which should be\n                sent along with the request as metadata.\n        \"\"\"\n\n        http_options = [\n            {\n                \"method\": \"post\",\n                \"uri\": \"/{}/{{name=**/operations/*}}:cancel\".format(self._path_prefix),\n                \"body\": \"*\",\n            },\n        ]\n        if \"google.longrunning.Operations.CancelOperation\" in self._http_options:\n            http_options = self._http_options[\n                \"google.longrunning.Operations.CancelOperation\"\n            ]\n\n        request_kwargs = self._convert_protobuf_message_to_dict(request)\n        transcoded_request = path_template.transcode(http_options, **request_kwargs)\n\n        # Jsonify the request body\n        body_request = operations_pb2.CancelOperationRequest()\n        json_format.ParseDict(transcoded_request[\"body\"], body_request)\n        body = json_format.MessageToDict(\n            body_request,\n            preserving_proto_field_name=False,\n            use_integers_for_enums=False,\n        )\n        uri = transcoded_request[\"uri\"]\n        method = transcoded_request[\"method\"]\n\n        # Jsonify the query params\n        query_params_request = operations_pb2.CancelOperationRequest()\n        json_format.ParseDict(transcoded_request[\"query_params\"], query_params_request)\n        query_params = json_format.MessageToDict(\n            query_params_request,\n            preserving_proto_field_name=False,\n            use_integers_for_enums=False,\n        )\n\n        # Send the request\n        headers = dict(metadata)\n        headers[\"Content-Type\"] = \"application/json\"\n        response = getattr(self._session, method)(\n            \"{host}{uri}\".format(host=self._host, uri=uri),\n            timeout=timeout,\n            headers=headers,\n            params=rest_helpers.flatten_query_params(query_params),\n            data=body,\n        )\n\n        # In case of error, raise the appropriate core_exceptions.GoogleAPICallError exception\n        # subclass.\n        if response.status_code >= 400:\n            raise core_exceptions.from_http_response(response)\n\n        return empty_pb2.Empty()\n\n    def _convert_protobuf_message_to_dict(\n        self, message: google.protobuf.message.Message\n    ):\n        r\"\"\"Converts protobuf message to a dictionary.\n\n        When the dictionary is encoded to JSON, it conforms to proto3 JSON spec.\n\n        Args:\n            message(google.protobuf.message.Message): The protocol buffers message\n                instance to serialize.\n\n        Returns:\n            A dict representation of the protocol buffer message.\n        \"\"\"\n        # For backwards compatibility with protobuf 3.x 4.x\n        # Remove once support for protobuf 3.x and 4.x is dropped\n        # https://github.com/googleapis/python-api-core/issues/643\n        if PROTOBUF_VERSION[0:2] in [\"3.\", \"4.\"]:\n            result = json_format.MessageToDict(\n                message,\n                preserving_proto_field_name=True,\n                including_default_value_fields=True,  # type: ignore # backward compatibility\n            )\n        else:\n            result = json_format.MessageToDict(\n                message,\n                preserving_proto_field_name=True,\n                always_print_fields_with_no_presence=True,\n            )\n\n        return result\n\n    @property\n    def list_operations(\n        self,\n    ) -> Callable[\n        [operations_pb2.ListOperationsRequest], operations_pb2.ListOperationsResponse\n    ]:\n        return self._list_operations\n\n    @property\n    def get_operation(\n        self,\n    ) -> Callable[[operations_pb2.GetOperationRequest], operations_pb2.Operation]:\n        return self._get_operation\n\n    @property\n    def delete_operation(\n        self,\n    ) -> Callable[[operations_pb2.DeleteOperationRequest], empty_pb2.Empty]:\n        return self._delete_operation\n\n    @property\n    def cancel_operation(\n        self,\n    ) -> Callable[[operations_pb2.CancelOperationRequest], empty_pb2.Empty]:\n        return self._cancel_operation\n\n\n__all__ = (\"OperationsRestTransport\",)\n", "google/api_core/operations_v1/transports/base.py": "# -*- coding: utf-8 -*-\n# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\nimport abc\nfrom typing import Awaitable, Callable, Optional, Sequence, Union\n\nimport google.api_core  # type: ignore\nfrom google.api_core import exceptions as core_exceptions  # type: ignore\nfrom google.api_core import gapic_v1  # type: ignore\nfrom google.api_core import retry as retries  # type: ignore\nfrom google.api_core import version\nimport google.auth  # type: ignore\nfrom google.auth import credentials as ga_credentials  # type: ignore\nfrom google.longrunning import operations_pb2\nfrom google.oauth2 import service_account  # type: ignore\nfrom google.protobuf import empty_pb2  # type: ignore\nfrom grpc import Compression\n\n\nDEFAULT_CLIENT_INFO = gapic_v1.client_info.ClientInfo(\n    gapic_version=version.__version__,\n)\n\n\nclass OperationsTransport(abc.ABC):\n    \"\"\"Abstract transport class for Operations.\"\"\"\n\n    AUTH_SCOPES = ()\n\n    DEFAULT_HOST: str = \"longrunning.googleapis.com\"\n\n    def __init__(\n        self,\n        *,\n        host: str = DEFAULT_HOST,\n        credentials: Optional[ga_credentials.Credentials] = None,\n        credentials_file: Optional[str] = None,\n        scopes: Optional[Sequence[str]] = None,\n        quota_project_id: Optional[str] = None,\n        client_info: gapic_v1.client_info.ClientInfo = DEFAULT_CLIENT_INFO,\n        always_use_jwt_access: Optional[bool] = False,\n        **kwargs,\n    ) -> None:\n        \"\"\"Instantiate the transport.\n\n        Args:\n            host (Optional[str]):\n                 The hostname to connect to.\n            credentials (Optional[google.auth.credentials.Credentials]): The\n                authorization credentials to attach to requests. These\n                credentials identify the application to the service; if none\n                are specified, the client will attempt to ascertain the\n                credentials from the environment.\n            credentials_file (Optional[str]): A file with credentials that can\n                be loaded with :func:`google.auth.load_credentials_from_file`.\n                This argument is mutually exclusive with credentials.\n            scopes (Optional[Sequence[str]]): A list of scopes.\n            quota_project_id (Optional[str]): An optional project to use for billing\n                and quota.\n            client_info (google.api_core.gapic_v1.client_info.ClientInfo):\n                The client info used to send a user-agent string along with\n                API requests. If ``None``, then default info will be used.\n                Generally, you only need to set this if you're developing\n                your own client library.\n            always_use_jwt_access (Optional[bool]): Whether self signed JWT should\n                be used for service account credentials.\n        \"\"\"\n        # Save the hostname. Default to port 443 (HTTPS) if none is specified.\n        if \":\" not in host:\n            host += \":443\"\n        self._host = host\n\n        scopes_kwargs = {\"scopes\": scopes, \"default_scopes\": self.AUTH_SCOPES}\n\n        # Save the scopes.\n        self._scopes = scopes\n\n        # If no credentials are provided, then determine the appropriate\n        # defaults.\n        if credentials and credentials_file:\n            raise core_exceptions.DuplicateCredentialArgs(\n                \"'credentials_file' and 'credentials' are mutually exclusive\"\n            )\n\n        if credentials_file is not None:\n            credentials, _ = google.auth.load_credentials_from_file(\n                credentials_file, **scopes_kwargs, quota_project_id=quota_project_id\n            )\n\n        elif credentials is None:\n            credentials, _ = google.auth.default(\n                **scopes_kwargs, quota_project_id=quota_project_id\n            )\n\n        # If the credentials are service account credentials, then always try to use self signed JWT.\n        if (\n            always_use_jwt_access\n            and isinstance(credentials, service_account.Credentials)\n            and hasattr(service_account.Credentials, \"with_always_use_jwt_access\")\n        ):\n            credentials = credentials.with_always_use_jwt_access(True)\n\n        # Save the credentials.\n        self._credentials = credentials\n\n    def _prep_wrapped_messages(self, client_info):\n        # Precompute the wrapped methods.\n        self._wrapped_methods = {\n            self.list_operations: gapic_v1.method.wrap_method(\n                self.list_operations,\n                default_retry=retries.Retry(\n                    initial=0.5,\n                    maximum=10.0,\n                    multiplier=2.0,\n                    predicate=retries.if_exception_type(\n                        core_exceptions.ServiceUnavailable,\n                    ),\n                    deadline=10.0,\n                ),\n                default_timeout=10.0,\n                default_compression=Compression.NoCompression,\n                client_info=client_info,\n            ),\n            self.get_operation: gapic_v1.method.wrap_method(\n                self.get_operation,\n                default_retry=retries.Retry(\n                    initial=0.5,\n                    maximum=10.0,\n                    multiplier=2.0,\n                    predicate=retries.if_exception_type(\n                        core_exceptions.ServiceUnavailable,\n                    ),\n                    deadline=10.0,\n                ),\n                default_timeout=10.0,\n                default_compression=Compression.NoCompression,\n                client_info=client_info,\n            ),\n            self.delete_operation: gapic_v1.method.wrap_method(\n                self.delete_operation,\n                default_retry=retries.Retry(\n                    initial=0.5,\n                    maximum=10.0,\n                    multiplier=2.0,\n                    predicate=retries.if_exception_type(\n                        core_exceptions.ServiceUnavailable,\n                    ),\n                    deadline=10.0,\n                ),\n                default_timeout=10.0,\n                default_compression=Compression.NoCompression,\n                client_info=client_info,\n            ),\n            self.cancel_operation: gapic_v1.method.wrap_method(\n                self.cancel_operation,\n                default_retry=retries.Retry(\n                    initial=0.5,\n                    maximum=10.0,\n                    multiplier=2.0,\n                    predicate=retries.if_exception_type(\n                        core_exceptions.ServiceUnavailable,\n                    ),\n                    deadline=10.0,\n                ),\n                default_timeout=10.0,\n                default_compression=Compression.NoCompression,\n                client_info=client_info,\n            ),\n        }\n\n    def close(self):\n        \"\"\"Closes resources associated with the transport.\n\n        .. warning::\n             Only call this method if the transport is NOT shared\n             with other clients - this may cause errors in other clients!\n        \"\"\"\n        raise NotImplementedError()\n\n    @property\n    def list_operations(\n        self,\n    ) -> Callable[\n        [operations_pb2.ListOperationsRequest],\n        Union[\n            operations_pb2.ListOperationsResponse,\n            Awaitable[operations_pb2.ListOperationsResponse],\n        ],\n    ]:\n        raise NotImplementedError()\n\n    @property\n    def get_operation(\n        self,\n    ) -> Callable[\n        [operations_pb2.GetOperationRequest],\n        Union[operations_pb2.Operation, Awaitable[operations_pb2.Operation]],\n    ]:\n        raise NotImplementedError()\n\n    @property\n    def delete_operation(\n        self,\n    ) -> Callable[\n        [operations_pb2.DeleteOperationRequest],\n        Union[empty_pb2.Empty, Awaitable[empty_pb2.Empty]],\n    ]:\n        raise NotImplementedError()\n\n    @property\n    def cancel_operation(\n        self,\n    ) -> Callable[\n        [operations_pb2.CancelOperationRequest],\n        Union[empty_pb2.Empty, Awaitable[empty_pb2.Empty]],\n    ]:\n        raise NotImplementedError()\n\n\n__all__ = (\"OperationsTransport\",)\n", "google/api_core/operations_v1/transports/__init__.py": "# -*- coding: utf-8 -*-\n# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\nfrom collections import OrderedDict\n\nfrom .base import OperationsTransport\nfrom .rest import OperationsRestTransport\n\n\n# Compile a registry of transports.\n_transport_registry = OrderedDict()\n_transport_registry[\"rest\"] = OperationsRestTransport\n\n__all__ = (\n    \"OperationsTransport\",\n    \"OperationsRestTransport\",\n)\n", "google/api_core/retry/retry_streaming_async.py": "# Copyright 2023 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"\nGenerator wrapper for retryable async streaming RPCs.\n\"\"\"\nfrom __future__ import annotations\n\nfrom typing import (\n    cast,\n    Any,\n    Callable,\n    Iterable,\n    AsyncIterator,\n    AsyncIterable,\n    Awaitable,\n    TypeVar,\n    AsyncGenerator,\n    TYPE_CHECKING,\n)\n\nimport asyncio\nimport time\nimport sys\nimport functools\n\nfrom google.api_core.retry.retry_base import _BaseRetry\nfrom google.api_core.retry.retry_base import _retry_error_helper\nfrom google.api_core.retry import exponential_sleep_generator\nfrom google.api_core.retry import build_retry_error\nfrom google.api_core.retry import RetryFailureReason\n\n\nif TYPE_CHECKING:\n    if sys.version_info >= (3, 10):\n        from typing import ParamSpec\n    else:\n        from typing_extensions import ParamSpec\n\n    _P = ParamSpec(\"_P\")  # target function call parameters\n    _Y = TypeVar(\"_Y\")  # yielded values\n\n\nasync def retry_target_stream(\n    target: Callable[_P, AsyncIterable[_Y] | Awaitable[AsyncIterable[_Y]]],\n    predicate: Callable[[Exception], bool],\n    sleep_generator: Iterable[float],\n    timeout: float | None = None,\n    on_error: Callable[[Exception], None] | None = None,\n    exception_factory: Callable[\n        [list[Exception], RetryFailureReason, float | None],\n        tuple[Exception, Exception | None],\n    ] = build_retry_error,\n    init_args: _P.args = (),\n    init_kwargs: _P.kwargs = {},\n    **kwargs,\n) -> AsyncGenerator[_Y, None]:\n    \"\"\"Create a generator wrapper that retries the wrapped stream if it fails.\n\n    This is the lowest-level retry helper. Generally, you'll use the\n    higher-level retry helper :class:`AsyncRetry`.\n\n    Args:\n        target: The generator function to call and retry.\n        predicate: A callable used to determine if an\n            exception raised by the target should be considered retryable.\n            It should return True to retry or False otherwise.\n        sleep_generator: An infinite iterator that determines\n            how long to sleep between retries.\n        timeout: How long to keep retrying the target.\n            Note: timeout is only checked before initiating a retry, so the target may\n            run past the timeout value as long as it is healthy.\n        on_error: If given, the on_error callback will be called with each\n            retryable exception raised by the target. Any error raised by this\n            function will *not* be caught.\n        exception_factory: A function that is called when the retryable reaches\n            a terminal failure state, used to construct an exception to be raised.\n            It takes a list of all exceptions encountered, a retry.RetryFailureReason\n            enum indicating the failure cause, and the original timeout value\n            as arguments. It should return a tuple of the exception to be raised,\n            along with the cause exception if any. The default implementation will raise\n            a RetryError on timeout, or the last exception encountered otherwise.\n        init_args: Positional arguments to pass to the target function.\n        init_kwargs: Keyword arguments to pass to the target function.\n\n    Returns:\n        AsyncGenerator: A retryable generator that wraps the target generator function.\n\n    Raises:\n        ValueError: If the sleep generator stops yielding values.\n        Exception: a custom exception specified by the exception_factory if provided.\n            If no exception_factory is provided:\n                google.api_core.RetryError: If the timeout is exceeded while retrying.\n                Exception: If the target raises an error that isn't retryable.\n    \"\"\"\n    target_iterator: AsyncIterator[_Y] | None = None\n    timeout = kwargs.get(\"deadline\", timeout)\n    deadline = time.monotonic() + timeout if timeout else None\n    # keep track of retryable exceptions we encounter to pass in to exception_factory\n    error_list: list[Exception] = []\n    target_is_generator: bool | None = None\n\n    for sleep in sleep_generator:\n        # Start a new retry loop\n        try:\n            # Note: in the future, we can add a ResumptionStrategy object\n            # to generate new args between calls. For now, use the same args\n            # for each attempt.\n            target_output: AsyncIterable[_Y] | Awaitable[AsyncIterable[_Y]] = target(\n                *init_args, **init_kwargs\n            )\n            try:\n                # gapic functions return the generator behind an awaitable\n                # unwrap the awaitable so we can work with the generator directly\n                target_output = await target_output  # type: ignore\n            except TypeError:\n                # was not awaitable, continue\n                pass\n            target_iterator = cast(AsyncIterable[\"_Y\"], target_output).__aiter__()\n\n            if target_is_generator is None:\n                # Check if target supports generator features (asend, athrow, aclose)\n                target_is_generator = bool(getattr(target_iterator, \"asend\", None))\n\n            sent_in = None\n            while True:\n                ## Read from target_iterator\n                # If the target is a generator, we will advance it with `asend`\n                # otherwise, we will use `anext`\n                if target_is_generator:\n                    next_value = await target_iterator.asend(sent_in)  # type: ignore\n                else:\n                    next_value = await target_iterator.__anext__()\n                ## Yield from Wrapper to caller\n                try:\n                    # yield latest value from target\n                    # exceptions from `athrow` and `aclose` are injected here\n                    sent_in = yield next_value\n                except GeneratorExit:\n                    # if wrapper received `aclose` while waiting on yield,\n                    # it will raise GeneratorExit here\n                    if target_is_generator:\n                        # pass to inner target_iterator for handling\n                        await cast(AsyncGenerator[\"_Y\", None], target_iterator).aclose()\n                    else:\n                        raise\n                    return\n                except:  # noqa: E722\n                    # bare except catches any exception passed to `athrow`\n                    if target_is_generator:\n                        # delegate error handling to target_iterator\n                        await cast(AsyncGenerator[\"_Y\", None], target_iterator).athrow(\n                            cast(BaseException, sys.exc_info()[1])\n                        )\n                    else:\n                        raise\n            return\n        except StopAsyncIteration:\n            # if iterator exhausted, return\n            return\n        # handle exceptions raised by the target_iterator\n        # pylint: disable=broad-except\n        # This function explicitly must deal with broad exceptions.\n        except Exception as exc:\n            # defer to shared logic for handling errors\n            _retry_error_helper(\n                exc,\n                deadline,\n                sleep,\n                error_list,\n                predicate,\n                on_error,\n                exception_factory,\n                timeout,\n            )\n            # if exception not raised, sleep before next attempt\n            await asyncio.sleep(sleep)\n        finally:\n            if target_is_generator and target_iterator is not None:\n                await cast(AsyncGenerator[\"_Y\", None], target_iterator).aclose()\n    raise ValueError(\"Sleep generator stopped yielding sleep values.\")\n\n\nclass AsyncStreamingRetry(_BaseRetry):\n    \"\"\"Exponential retry decorator for async streaming rpcs.\n\n    This class returns an AsyncGenerator when called, which wraps the target\n    stream in retry logic. If any exception is raised by the target, the\n    entire stream will be retried within the wrapper.\n\n    Although the default behavior is to retry transient API errors, a\n    different predicate can be provided to retry other exceptions.\n\n    Important Note: when a stream is encounters a retryable error, it will\n    silently construct a fresh iterator instance in the background\n    and continue yielding (likely duplicate) values as if no error occurred.\n    This is the most general way to retry a stream, but it often is not the\n    desired behavior. Example: iter([1, 2, 1/0]) -> [1, 2, 1, 2, ...]\n\n    There are two ways to build more advanced retry logic for streams:\n\n    1. Wrap the target\n        Use a ``target`` that maintains state between retries, and creates a\n        different generator on each retry call. For example, you can wrap a\n        grpc call in a function that modifies the request based on what has\n        already been returned:\n\n        .. code-block:: python\n\n            async def attempt_with_modified_request(target, request, seen_items=[]):\n                # remove seen items from request on each attempt\n                new_request = modify_request(request, seen_items)\n                new_generator = await target(new_request)\n                async for item in new_generator:\n                    yield item\n                    seen_items.append(item)\n\n            retry_wrapped = AsyncRetry(is_stream=True,...)(attempt_with_modified_request, target, request, [])\n\n        2. Wrap the retry generator\n            Alternatively, you can wrap the retryable generator itself before\n            passing it to the end-user to add a filter on the stream. For\n            example, you can keep track of the items that were successfully yielded\n            in previous retry attempts, and only yield new items when the\n            new attempt surpasses the previous ones:\n\n            .. code-block:: python\n\n                async def retryable_with_filter(target):\n                    stream_idx = 0\n                    # reset stream_idx when the stream is retried\n                    def on_error(e):\n                        nonlocal stream_idx\n                        stream_idx = 0\n                    # build retryable\n                    retryable_gen = AsyncRetry(is_stream=True, ...)(target)\n                    # keep track of what has been yielded out of filter\n                    seen_items = []\n                    async for item in retryable_gen:\n                        if stream_idx >= len(seen_items):\n                            yield item\n                            seen_items.append(item)\n                        elif item != previous_stream[stream_idx]:\n                            raise ValueError(\"Stream differs from last attempt\")\"\n                        stream_idx += 1\n\n                filter_retry_wrapped = retryable_with_filter(target)\n\n    Args:\n        predicate (Callable[Exception]): A callable that should return ``True``\n            if the given exception is retryable.\n        initial (float): The minimum amount of time to delay in seconds. This\n            must be greater than 0.\n        maximum (float): The maximum amount of time to delay in seconds.\n        multiplier (float): The multiplier applied to the delay.\n        timeout (Optional[float]): How long to keep retrying in seconds.\n            Note: timeout is only checked before initiating a retry, so the target may\n            run past the timeout value as long as it is healthy.\n        on_error (Optional[Callable[Exception]]): A function to call while processing\n            a retryable exception. Any error raised by this function will\n            *not* be caught.\n        is_stream (bool): Indicates whether the input function\n            should be treated as a stream function (i.e. an AsyncGenerator,\n            or function or coroutine that returns an AsyncIterable).\n            If True, the iterable will be wrapped with retry logic, and any\n            failed outputs will restart the stream. If False, only the input\n            function call itself will be retried. Defaults to False.\n            To avoid duplicate values, retryable streams should typically be\n            wrapped in additional filter logic before use.\n        deadline (float): DEPRECATED use ``timeout`` instead. If set it will\n        override ``timeout`` parameter.\n    \"\"\"\n\n    def __call__(\n        self,\n        func: Callable[..., AsyncIterable[_Y] | Awaitable[AsyncIterable[_Y]]],\n        on_error: Callable[[Exception], Any] | None = None,\n    ) -> Callable[_P, Awaitable[AsyncGenerator[_Y, None]]]:\n        \"\"\"Wrap a callable with retry behavior.\n\n        Args:\n            func (Callable): The callable or stream to add retry behavior to.\n            on_error (Optional[Callable[Exception]]): If given, the\n                on_error callback will be called with each retryable exception\n                raised by the wrapped function. Any error raised by this\n                function will *not* be caught. If on_error was specified in the\n                constructor, this value will be ignored.\n\n        Returns:\n            Callable: A callable that will invoke ``func`` with retry\n                behavior.\n        \"\"\"\n        if self._on_error is not None:\n            on_error = self._on_error\n\n        @functools.wraps(func)\n        async def retry_wrapped_func(\n            *args: _P.args, **kwargs: _P.kwargs\n        ) -> AsyncGenerator[_Y, None]:\n            \"\"\"A wrapper that calls target function with retry.\"\"\"\n            sleep_generator = exponential_sleep_generator(\n                self._initial, self._maximum, multiplier=self._multiplier\n            )\n            return retry_target_stream(\n                func,\n                self._predicate,\n                sleep_generator,\n                self._timeout,\n                on_error,\n                init_args=args,\n                init_kwargs=kwargs,\n            )\n\n        return retry_wrapped_func\n", "google/api_core/retry/retry_streaming.py": "# Copyright 2023 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"\nGenerator wrapper for retryable streaming RPCs.\n\"\"\"\nfrom __future__ import annotations\n\nfrom typing import (\n    Callable,\n    Optional,\n    List,\n    Tuple,\n    Iterable,\n    Generator,\n    TypeVar,\n    Any,\n    TYPE_CHECKING,\n)\n\nimport sys\nimport time\nimport functools\n\nfrom google.api_core.retry.retry_base import _BaseRetry\nfrom google.api_core.retry.retry_base import _retry_error_helper\nfrom google.api_core.retry import exponential_sleep_generator\nfrom google.api_core.retry import build_retry_error\nfrom google.api_core.retry import RetryFailureReason\n\nif TYPE_CHECKING:\n    if sys.version_info >= (3, 10):\n        from typing import ParamSpec\n    else:\n        from typing_extensions import ParamSpec\n\n    _P = ParamSpec(\"_P\")  # target function call parameters\n    _Y = TypeVar(\"_Y\")  # yielded values\n\n\ndef retry_target_stream(\n    target: Callable[_P, Iterable[_Y]],\n    predicate: Callable[[Exception], bool],\n    sleep_generator: Iterable[float],\n    timeout: Optional[float] = None,\n    on_error: Optional[Callable[[Exception], None]] = None,\n    exception_factory: Callable[\n        [List[Exception], RetryFailureReason, Optional[float]],\n        Tuple[Exception, Optional[Exception]],\n    ] = build_retry_error,\n    init_args: _P.args = (),\n    init_kwargs: _P.kwargs = {},\n    **kwargs,\n) -> Generator[_Y, Any, None]:\n    \"\"\"Create a generator wrapper that retries the wrapped stream if it fails.\n\n    This is the lowest-level retry helper. Generally, you'll use the\n    higher-level retry helper :class:`Retry`.\n\n    Args:\n        target: The generator function to call and retry.\n        predicate: A callable used to determine if an\n            exception raised by the target should be considered retryable.\n            It should return True to retry or False otherwise.\n        sleep_generator: An infinite iterator that determines\n            how long to sleep between retries.\n        timeout: How long to keep retrying the target.\n            Note: timeout is only checked before initiating a retry, so the target may\n            run past the timeout value as long as it is healthy.\n        on_error: If given, the on_error callback will be called with each\n            retryable exception raised by the target. Any error raised by this\n            function will *not* be caught.\n        exception_factory: A function that is called when the retryable reaches\n            a terminal failure state, used to construct an exception to be raised.\n            It takes a list of all exceptions encountered, a retry.RetryFailureReason\n            enum indicating the failure cause, and the original timeout value\n            as arguments. It should return a tuple of the exception to be raised,\n            along with the cause exception if any. The default implementation will raise\n            a RetryError on timeout, or the last exception encountered otherwise.\n        init_args: Positional arguments to pass to the target function.\n        init_kwargs: Keyword arguments to pass to the target function.\n\n    Returns:\n        Generator: A retryable generator that wraps the target generator function.\n\n    Raises:\n        ValueError: If the sleep generator stops yielding values.\n        Exception: a custom exception specified by the exception_factory if provided.\n            If no exception_factory is provided:\n                google.api_core.RetryError: If the timeout is exceeded while retrying.\n                Exception: If the target raises an error that isn't retryable.\n    \"\"\"\n\n    timeout = kwargs.get(\"deadline\", timeout)\n    deadline: Optional[float] = (\n        time.monotonic() + timeout if timeout is not None else None\n    )\n    error_list: list[Exception] = []\n\n    for sleep in sleep_generator:\n        # Start a new retry loop\n        try:\n            # Note: in the future, we can add a ResumptionStrategy object\n            # to generate new args between calls. For now, use the same args\n            # for each attempt.\n            subgenerator = target(*init_args, **init_kwargs)\n            return (yield from subgenerator)\n        # handle exceptions raised by the subgenerator\n        # pylint: disable=broad-except\n        # This function explicitly must deal with broad exceptions.\n        except Exception as exc:\n            # defer to shared logic for handling errors\n            _retry_error_helper(\n                exc,\n                deadline,\n                sleep,\n                error_list,\n                predicate,\n                on_error,\n                exception_factory,\n                timeout,\n            )\n            # if exception not raised, sleep before next attempt\n            time.sleep(sleep)\n\n    raise ValueError(\"Sleep generator stopped yielding sleep values.\")\n\n\nclass StreamingRetry(_BaseRetry):\n    \"\"\"Exponential retry decorator for streaming synchronous RPCs.\n\n    This class returns a Generator when called, which wraps the target\n    stream in retry logic. If any exception is raised by the target, the\n    entire stream will be retried within the wrapper.\n\n    Although the default behavior is to retry transient API errors, a\n    different predicate can be provided to retry other exceptions.\n\n    Important Note: when a stream encounters a retryable error, it will\n    silently construct a fresh iterator instance in the background\n    and continue yielding (likely duplicate) values as if no error occurred.\n    This is the most general way to retry a stream, but it often is not the\n    desired behavior. Example: iter([1, 2, 1/0]) -> [1, 2, 1, 2, ...]\n\n    There are two ways to build more advanced retry logic for streams:\n\n    1. Wrap the target\n        Use a ``target`` that maintains state between retries, and creates a\n        different generator on each retry call. For example, you can wrap a\n        network call in a function that modifies the request based on what has\n        already been returned:\n\n        .. code-block:: python\n\n            def attempt_with_modified_request(target, request, seen_items=[]):\n                # remove seen items from request on each attempt\n                new_request = modify_request(request, seen_items)\n                new_generator = target(new_request)\n                for item in new_generator:\n                    yield item\n                    seen_items.append(item)\n\n            retry_wrapped_fn = StreamingRetry()(attempt_with_modified_request)\n            retryable_generator = retry_wrapped_fn(target, request)\n\n    2. Wrap the retry generator\n        Alternatively, you can wrap the retryable generator itself before\n        passing it to the end-user to add a filter on the stream. For\n        example, you can keep track of the items that were successfully yielded\n        in previous retry attempts, and only yield new items when the\n        new attempt surpasses the previous ones:\n\n        .. code-block:: python\n\n            def retryable_with_filter(target):\n                stream_idx = 0\n                # reset stream_idx when the stream is retried\n                def on_error(e):\n                    nonlocal stream_idx\n                    stream_idx = 0\n                # build retryable\n                retryable_gen = StreamingRetry(...)(target)\n                # keep track of what has been yielded out of filter\n                seen_items = []\n                for item in retryable_gen():\n                    if stream_idx >= len(seen_items):\n                        seen_items.append(item)\n                        yield item\n                    elif item != seen_items[stream_idx]:\n                        raise ValueError(\"Stream differs from last attempt\")\n                    stream_idx += 1\n\n            filter_retry_wrapped = retryable_with_filter(target)\n\n    Args:\n        predicate (Callable[Exception]): A callable that should return ``True``\n            if the given exception is retryable.\n        initial (float): The minimum amount of time to delay in seconds. This\n            must be greater than 0.\n        maximum (float): The maximum amount of time to delay in seconds.\n        multiplier (float): The multiplier applied to the delay.\n        timeout (float): How long to keep retrying, in seconds.\n            Note: timeout is only checked before initiating a retry, so the target may\n            run past the timeout value as long as it is healthy.\n        on_error (Callable[Exception]): A function to call while processing\n            a retryable exception. Any error raised by this function will\n            *not* be caught.\n        deadline (float): DEPRECATED: use `timeout` instead. For backward\n            compatibility, if specified it will override the ``timeout`` parameter.\n    \"\"\"\n\n    def __call__(\n        self,\n        func: Callable[_P, Iterable[_Y]],\n        on_error: Callable[[Exception], Any] | None = None,\n    ) -> Callable[_P, Generator[_Y, Any, None]]:\n        \"\"\"Wrap a callable with retry behavior.\n\n        Args:\n            func (Callable): The callable to add retry behavior to.\n            on_error (Optional[Callable[Exception]]): If given, the\n                on_error callback will be called with each retryable exception\n                raised by the wrapped function. Any error raised by this\n                function will *not* be caught. If on_error was specified in the\n                constructor, this value will be ignored.\n\n        Returns:\n            Callable: A callable that will invoke ``func`` with retry\n                behavior.\n        \"\"\"\n        if self._on_error is not None:\n            on_error = self._on_error\n\n        @functools.wraps(func)\n        def retry_wrapped_func(\n            *args: _P.args, **kwargs: _P.kwargs\n        ) -> Generator[_Y, Any, None]:\n            \"\"\"A wrapper that calls target function with retry.\"\"\"\n            sleep_generator = exponential_sleep_generator(\n                self._initial, self._maximum, multiplier=self._multiplier\n            )\n            return retry_target_stream(\n                func,\n                predicate=self._predicate,\n                sleep_generator=sleep_generator,\n                timeout=self._timeout,\n                on_error=on_error,\n                init_args=args,\n                init_kwargs=kwargs,\n            )\n\n        return retry_wrapped_func\n", "google/api_core/retry/retry_unary_async.py": "# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Helpers for retrying coroutine functions with exponential back-off.\n\nThe :class:`AsyncRetry` decorator shares most functionality and behavior with\n:class:`Retry`, but supports coroutine functions. Please refer to description\nof :class:`Retry` for more details.\n\nBy default, this decorator will retry transient\nAPI errors (see :func:`if_transient_error`). For example:\n\n.. code-block:: python\n\n    @retry_async.AsyncRetry()\n    async def call_flaky_rpc():\n        return await client.flaky_rpc()\n\n    # Will retry flaky_rpc() if it raises transient API errors.\n    result = await call_flaky_rpc()\n\nYou can pass a custom predicate to retry on different exceptions, such as\nwaiting for an eventually consistent item to be available:\n\n.. code-block:: python\n\n    @retry_async.AsyncRetry(predicate=retry_async.if_exception_type(exceptions.NotFound))\n    async def check_if_exists():\n        return await client.does_thing_exist()\n\n    is_available = await check_if_exists()\n\nSome client library methods apply retry automatically. These methods can accept\na ``retry`` parameter that allows you to configure the behavior:\n\n.. code-block:: python\n\n    my_retry = retry_async.AsyncRetry(timeout=60)\n    result = await client.some_method(retry=my_retry)\n\n\"\"\"\n\nfrom __future__ import annotations\n\nimport asyncio\nimport time\nimport functools\nfrom typing import (\n    Awaitable,\n    Any,\n    Callable,\n    Iterable,\n    TypeVar,\n    TYPE_CHECKING,\n)\n\nfrom google.api_core.retry.retry_base import _BaseRetry\nfrom google.api_core.retry.retry_base import _retry_error_helper\nfrom google.api_core.retry.retry_base import exponential_sleep_generator\nfrom google.api_core.retry.retry_base import build_retry_error\nfrom google.api_core.retry.retry_base import RetryFailureReason\n\n# for backwards compatibility, expose helpers in this module\nfrom google.api_core.retry.retry_base import if_exception_type  # noqa\nfrom google.api_core.retry.retry_base import if_transient_error  # noqa\n\nif TYPE_CHECKING:\n    import sys\n\n    if sys.version_info >= (3, 10):\n        from typing import ParamSpec\n    else:\n        from typing_extensions import ParamSpec\n\n    _P = ParamSpec(\"_P\")  # target function call parameters\n    _R = TypeVar(\"_R\")  # target function returned value\n\n_DEFAULT_INITIAL_DELAY = 1.0  # seconds\n_DEFAULT_MAXIMUM_DELAY = 60.0  # seconds\n_DEFAULT_DELAY_MULTIPLIER = 2.0\n_DEFAULT_DEADLINE = 60.0 * 2.0  # seconds\n_DEFAULT_TIMEOUT = 60.0 * 2.0  # seconds\n\n\nasync def retry_target(\n    target: Callable[_P, Awaitable[_R]],\n    predicate: Callable[[Exception], bool],\n    sleep_generator: Iterable[float],\n    timeout: float | None = None,\n    on_error: Callable[[Exception], None] | None = None,\n    exception_factory: Callable[\n        [list[Exception], RetryFailureReason, float | None],\n        tuple[Exception, Exception | None],\n    ] = build_retry_error,\n    **kwargs,\n):\n    \"\"\"Await a coroutine and retry if it fails.\n\n    This is the lowest-level retry helper. Generally, you'll use the\n    higher-level retry helper :class:`Retry`.\n\n    Args:\n        target(Callable[[], Any]): The function to call and retry. This must be a\n            nullary function - apply arguments with `functools.partial`.\n        predicate (Callable[Exception]): A callable used to determine if an\n            exception raised by the target should be considered retryable.\n            It should return True to retry or False otherwise.\n        sleep_generator (Iterable[float]): An infinite iterator that determines\n            how long to sleep between retries.\n        timeout (Optional[float]): How long to keep retrying the target, in seconds.\n            Note: timeout is only checked before initiating a retry, so the target may\n            run past the timeout value as long as it is healthy.\n        on_error (Optional[Callable[Exception]]): If given, the on_error\n            callback will be called with each retryable exception raised by the\n            target. Any error raised by this function will *not* be caught.\n        exception_factory: A function that is called when the retryable reaches\n            a terminal failure state, used to construct an exception to be raised.\n            It takes a list of all exceptions encountered, a retry.RetryFailureReason\n            enum indicating the failure cause, and the original timeout value\n            as arguments. It should return a tuple of the exception to be raised,\n            along with the cause exception if any. The default implementation will raise\n            a RetryError on timeout, or the last exception encountered otherwise.\n        deadline (float): DEPRECATED use ``timeout`` instead. For backward\n            compatibility, if set it will override the ``timeout`` parameter.\n\n    Returns:\n        Any: the return value of the target function.\n\n    Raises:\n        ValueError: If the sleep generator stops yielding values.\n        Exception: a custom exception specified by the exception_factory if provided.\n            If no exception_factory is provided:\n                google.api_core.RetryError: If the timeout is exceeded while retrying.\n                Exception: If the target raises an error that isn't retryable.\n    \"\"\"\n\n    timeout = kwargs.get(\"deadline\", timeout)\n\n    deadline = time.monotonic() + timeout if timeout is not None else None\n    error_list: list[Exception] = []\n\n    for sleep in sleep_generator:\n        try:\n            return await target()\n        # pylint: disable=broad-except\n        # This function explicitly must deal with broad exceptions.\n        except Exception as exc:\n            # defer to shared logic for handling errors\n            _retry_error_helper(\n                exc,\n                deadline,\n                sleep,\n                error_list,\n                predicate,\n                on_error,\n                exception_factory,\n                timeout,\n            )\n            # if exception not raised, sleep before next attempt\n            await asyncio.sleep(sleep)\n\n    raise ValueError(\"Sleep generator stopped yielding sleep values.\")\n\n\nclass AsyncRetry(_BaseRetry):\n    \"\"\"Exponential retry decorator for async coroutines.\n\n    This class is a decorator used to add exponential back-off retry behavior\n    to an RPC call.\n\n    Although the default behavior is to retry transient API errors, a\n    different predicate can be provided to retry other exceptions.\n\n    Args:\n        predicate (Callable[Exception]): A callable that should return ``True``\n            if the given exception is retryable.\n        initial (float): The minimum amount of time to delay in seconds. This\n            must be greater than 0.\n        maximum (float): The maximum amount of time to delay in seconds.\n        multiplier (float): The multiplier applied to the delay.\n        timeout (Optional[float]): How long to keep retrying in seconds.\n            Note: timeout is only checked before initiating a retry, so the target may\n            run past the timeout value as long as it is healthy.\n        on_error (Optional[Callable[Exception]]): A function to call while processing\n            a retryable exception. Any error raised by this function will\n            *not* be caught.\n        deadline (float): DEPRECATED use ``timeout`` instead. If set it will\n        override ``timeout`` parameter.\n    \"\"\"\n\n    def __call__(\n        self,\n        func: Callable[..., Awaitable[_R]],\n        on_error: Callable[[Exception], Any] | None = None,\n    ) -> Callable[_P, Awaitable[_R]]:\n        \"\"\"Wrap a callable with retry behavior.\n\n        Args:\n            func (Callable): The callable or stream to add retry behavior to.\n            on_error (Optional[Callable[Exception]]): If given, the\n                on_error callback will be called with each retryable exception\n                raised by the wrapped function. Any error raised by this\n                function will *not* be caught. If on_error was specified in the\n                constructor, this value will be ignored.\n\n        Returns:\n            Callable: A callable that will invoke ``func`` with retry\n                behavior.\n        \"\"\"\n        if self._on_error is not None:\n            on_error = self._on_error\n\n        @functools.wraps(func)\n        async def retry_wrapped_func(*args: _P.args, **kwargs: _P.kwargs) -> _R:\n            \"\"\"A wrapper that calls target function with retry.\"\"\"\n            sleep_generator = exponential_sleep_generator(\n                self._initial, self._maximum, multiplier=self._multiplier\n            )\n            return await retry_target(\n                functools.partial(func, *args, **kwargs),\n                predicate=self._predicate,\n                sleep_generator=sleep_generator,\n                timeout=self._timeout,\n                on_error=on_error,\n            )\n\n        return retry_wrapped_func\n", "google/api_core/retry/retry_unary.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Helpers for retrying functions with exponential back-off.\n\nThe :class:`Retry` decorator can be used to retry functions that raise\nexceptions using exponential backoff. Because a exponential sleep algorithm is\nused, the retry is limited by a `timeout`. The timeout determines the window\nin which retries will be attempted. This is used instead of total number of retries\nbecause it is difficult to ascertain the amount of time a function can block\nwhen using total number of retries and exponential backoff.\n\nBy default, this decorator will retry transient\nAPI errors (see :func:`if_transient_error`). For example:\n\n.. code-block:: python\n\n    @retry.Retry()\n    def call_flaky_rpc():\n        return client.flaky_rpc()\n\n    # Will retry flaky_rpc() if it raises transient API errors.\n    result = call_flaky_rpc()\n\nYou can pass a custom predicate to retry on different exceptions, such as\nwaiting for an eventually consistent item to be available:\n\n.. code-block:: python\n\n    @retry.Retry(predicate=if_exception_type(exceptions.NotFound))\n    def check_if_exists():\n        return client.does_thing_exist()\n\n    is_available = check_if_exists()\n\nSome client library methods apply retry automatically. These methods can accept\na ``retry`` parameter that allows you to configure the behavior:\n\n.. code-block:: python\n\n    my_retry = retry.Retry(timeout=60)\n    result = client.some_method(retry=my_retry)\n\n\"\"\"\n\nfrom __future__ import annotations\n\nimport functools\nimport sys\nimport time\nimport inspect\nimport warnings\nfrom typing import Any, Callable, Iterable, TypeVar, TYPE_CHECKING\n\nfrom google.api_core.retry.retry_base import _BaseRetry\nfrom google.api_core.retry.retry_base import _retry_error_helper\nfrom google.api_core.retry.retry_base import exponential_sleep_generator\nfrom google.api_core.retry.retry_base import build_retry_error\nfrom google.api_core.retry.retry_base import RetryFailureReason\n\n\nif TYPE_CHECKING:\n    if sys.version_info >= (3, 10):\n        from typing import ParamSpec\n    else:\n        from typing_extensions import ParamSpec\n\n    _P = ParamSpec(\"_P\")  # target function call parameters\n    _R = TypeVar(\"_R\")  # target function returned value\n\n_ASYNC_RETRY_WARNING = \"Using the synchronous google.api_core.retry.Retry with asynchronous calls may lead to unexpected results. Please use google.api_core.retry_async.AsyncRetry instead.\"\n\n\ndef retry_target(\n    target: Callable[_P, _R],\n    predicate: Callable[[Exception], bool],\n    sleep_generator: Iterable[float],\n    timeout: float | None = None,\n    on_error: Callable[[Exception], None] | None = None,\n    exception_factory: Callable[\n        [list[Exception], RetryFailureReason, float | None],\n        tuple[Exception, Exception | None],\n    ] = build_retry_error,\n    **kwargs,\n):\n    \"\"\"Call a function and retry if it fails.\n\n    This is the lowest-level retry helper. Generally, you'll use the\n    higher-level retry helper :class:`Retry`.\n\n    Args:\n        target(Callable): The function to call and retry. This must be a\n            nullary function - apply arguments with `functools.partial`.\n        predicate (Callable[Exception]): A callable used to determine if an\n            exception raised by the target should be considered retryable.\n            It should return True to retry or False otherwise.\n        sleep_generator (Iterable[float]): An infinite iterator that determines\n            how long to sleep between retries.\n        timeout (Optional[float]): How long to keep retrying the target.\n            Note: timeout is only checked before initiating a retry, so the target may\n            run past the timeout value as long as it is healthy.\n        on_error (Optional[Callable[Exception]]): If given, the on_error\n            callback will be called with each retryable exception raised by the\n            target. Any error raised by this function will *not* be caught.\n        exception_factory: A function that is called when the retryable reaches\n            a terminal failure state, used to construct an exception to be raised.\n            It takes a list of all exceptions encountered, a retry.RetryFailureReason\n            enum indicating the failure cause, and the original timeout value\n            as arguments. It should return a tuple of the exception to be raised,\n            along with the cause exception if any. The default implementation will raise\n            a RetryError on timeout, or the last exception encountered otherwise.\n        deadline (float): DEPRECATED: use ``timeout`` instead. For backward\n            compatibility, if specified it will override ``timeout`` parameter.\n\n    Returns:\n        Any: the return value of the target function.\n\n    Raises:\n        ValueError: If the sleep generator stops yielding values.\n        Exception: a custom exception specified by the exception_factory if provided.\n            If no exception_factory is provided:\n                google.api_core.RetryError: If the timeout is exceeded while retrying.\n                Exception: If the target raises an error that isn't retryable.\n    \"\"\"\n\n    timeout = kwargs.get(\"deadline\", timeout)\n\n    deadline = time.monotonic() + timeout if timeout is not None else None\n    error_list: list[Exception] = []\n\n    for sleep in sleep_generator:\n        try:\n            result = target()\n            if inspect.isawaitable(result):\n                warnings.warn(_ASYNC_RETRY_WARNING)\n            return result\n\n        # pylint: disable=broad-except\n        # This function explicitly must deal with broad exceptions.\n        except Exception as exc:\n            # defer to shared logic for handling errors\n            _retry_error_helper(\n                exc,\n                deadline,\n                sleep,\n                error_list,\n                predicate,\n                on_error,\n                exception_factory,\n                timeout,\n            )\n            # if exception not raised, sleep before next attempt\n            time.sleep(sleep)\n\n    raise ValueError(\"Sleep generator stopped yielding sleep values.\")\n\n\nclass Retry(_BaseRetry):\n    \"\"\"Exponential retry decorator for unary synchronous RPCs.\n\n    This class is a decorator used to add retry or polling behavior to an RPC\n    call.\n\n    Although the default behavior is to retry transient API errors, a\n    different predicate can be provided to retry other exceptions.\n\n    There are two important concepts that retry/polling behavior may operate on,\n    Deadline and Timeout, which need to be properly defined for the correct\n    usage of this class and the rest of the library.\n\n    Deadline: a fixed point in time by which a certain operation must\n    terminate. For example, if a certain operation has a deadline\n    \"2022-10-18T23:30:52.123Z\" it must terminate (successfully or with an\n    error) by that time, regardless of when it was started or whether it\n    was started at all.\n\n    Timeout: the maximum duration of time after which a certain operation\n    must terminate (successfully or with an error). The countdown begins right\n    after an operation was started. For example, if an operation was started at\n    09:24:00 with timeout of 75 seconds, it must terminate no later than\n    09:25:15.\n\n    Unfortunately, in the past this class (and the api-core library as a whole) has not\n    been properly distinguishing the concepts of \"timeout\" and \"deadline\", and the\n    ``deadline`` parameter has meant ``timeout``. That is why\n    ``deadline`` has been deprecated and ``timeout`` should be used instead. If the\n    ``deadline`` parameter is set, it will override the ``timeout`` parameter.\n    In other words, ``retry.deadline`` should be treated as just a deprecated alias for\n    ``retry.timeout``.\n\n    Said another way, it is safe to assume that this class and the rest of this\n    library operate in terms of timeouts (not deadlines) unless explicitly\n    noted the usage of deadline semantics.\n\n    It is also important to\n    understand the three most common applications of the Timeout concept in the\n    context of this library.\n\n    Usually the generic Timeout term may stand for one of the following actual\n    timeouts: RPC Timeout, Retry Timeout, or Polling Timeout.\n\n    RPC Timeout: a value supplied by the client to the server so\n    that the server side knows the maximum amount of time it is expected to\n    spend handling that specific RPC. For example, in the case of gRPC transport,\n    RPC Timeout is represented by setting \"grpc-timeout\" header in the HTTP2\n    request. The `timeout` property of this class normally never represents the\n    RPC Timeout as it is handled separately by the ``google.api_core.timeout``\n    module of this library.\n\n    Retry Timeout: this is the most common meaning of the ``timeout`` property\n    of this class, and defines how long a certain RPC may be retried in case\n    the server returns an error.\n\n    Polling Timeout: defines how long the\n    client side is allowed to call the polling RPC repeatedly to check a status of a\n    long-running operation. Each polling RPC is\n    expected to succeed (its errors are supposed to be handled by the retry\n    logic). The decision as to whether a new polling attempt needs to be made is based\n    not on the RPC status code but  on the status of the returned\n    status of an operation. In other words: we will poll a long-running operation until\n    the operation is done or the polling timeout expires. Each poll will inform us of\n    the status of the operation. The poll consists of an RPC to the server that may\n    itself be retried as per the poll-specific retry settings in case of errors. The\n    operation-level retry settings do NOT apply to polling-RPC retries.\n\n    With the actual timeout types being defined above, the client libraries\n    often refer to just Timeout without clarifying which type specifically\n    that is. In that case the actual timeout type (sometimes also referred to as\n    Logical Timeout) can be determined from the context. If it is a unary rpc\n    call (i.e. a regular one) Timeout usually stands for the RPC Timeout (if\n    provided directly as a standalone value) or Retry Timeout (if provided as\n    ``retry.timeout`` property of the unary RPC's retry config). For\n    ``Operation`` or ``PollingFuture`` in general Timeout stands for\n    Polling Timeout.\n\n    Args:\n        predicate (Callable[Exception]): A callable that should return ``True``\n            if the given exception is retryable.\n        initial (float): The minimum amount of time to delay in seconds. This\n            must be greater than 0.\n        maximum (float): The maximum amount of time to delay in seconds.\n        multiplier (float): The multiplier applied to the delay.\n        timeout (Optional[float]): How long to keep retrying, in seconds.\n            Note: timeout is only checked before initiating a retry, so the target may\n            run past the timeout value as long as it is healthy.\n        on_error (Callable[Exception]): A function to call while processing\n            a retryable exception. Any error raised by this function will\n            *not* be caught.\n        deadline (float): DEPRECATED: use `timeout` instead. For backward\n            compatibility, if specified it will override the ``timeout`` parameter.\n    \"\"\"\n\n    def __call__(\n        self,\n        func: Callable[_P, _R],\n        on_error: Callable[[Exception], Any] | None = None,\n    ) -> Callable[_P, _R]:\n        \"\"\"Wrap a callable with retry behavior.\n\n        Args:\n            func (Callable): The callable to add retry behavior to.\n            on_error (Optional[Callable[Exception]]): If given, the\n                on_error callback will be called with each retryable exception\n                raised by the wrapped function. Any error raised by this\n                function will *not* be caught. If on_error was specified in the\n                constructor, this value will be ignored.\n\n        Returns:\n            Callable: A callable that will invoke ``func`` with retry\n                behavior.\n        \"\"\"\n        if self._on_error is not None:\n            on_error = self._on_error\n\n        @functools.wraps(func)\n        def retry_wrapped_func(*args: _P.args, **kwargs: _P.kwargs) -> _R:\n            \"\"\"A wrapper that calls target function with retry.\"\"\"\n            target = functools.partial(func, *args, **kwargs)\n            sleep_generator = exponential_sleep_generator(\n                self._initial, self._maximum, multiplier=self._multiplier\n            )\n            return retry_target(\n                target,\n                self._predicate,\n                sleep_generator,\n                timeout=self._timeout,\n                on_error=on_error,\n            )\n\n        return retry_wrapped_func\n", "google/api_core/retry/__init__.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Retry implementation for Google API client libraries.\"\"\"\n\nfrom .retry_base import exponential_sleep_generator\nfrom .retry_base import if_exception_type\nfrom .retry_base import if_transient_error\nfrom .retry_base import build_retry_error\nfrom .retry_base import RetryFailureReason\nfrom .retry_unary import Retry\nfrom .retry_unary import retry_target\nfrom .retry_unary_async import AsyncRetry\nfrom .retry_unary_async import retry_target as retry_target_async\nfrom .retry_streaming import StreamingRetry\nfrom .retry_streaming import retry_target_stream\nfrom .retry_streaming_async import AsyncStreamingRetry\nfrom .retry_streaming_async import retry_target_stream as retry_target_stream_async\n\n# The following imports are for backwards compatibility with https://github.com/googleapis/python-api-core/blob/4d7d2edee2c108d43deb151e6e0fdceb56b73275/google/api_core/retry.py\n#\n# TODO: Revert these imports on the next major version release (https://github.com/googleapis/python-api-core/issues/576)\nfrom google.api_core import datetime_helpers  # noqa: F401\nfrom google.api_core import exceptions  # noqa: F401\nfrom google.auth import exceptions as auth_exceptions  # noqa: F401\n\n__all__ = (\n    \"exponential_sleep_generator\",\n    \"if_exception_type\",\n    \"if_transient_error\",\n    \"build_retry_error\",\n    \"RetryFailureReason\",\n    \"Retry\",\n    \"AsyncRetry\",\n    \"StreamingRetry\",\n    \"AsyncStreamingRetry\",\n    \"retry_target\",\n    \"retry_target_async\",\n    \"retry_target_stream\",\n    \"retry_target_stream_async\",\n)\n", "google/api_core/retry/retry_base.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Shared classes and functions for retrying requests.\n\n:class:`_BaseRetry` is the base class for :class:`Retry`,\n:class:`AsyncRetry`, :class:`StreamingRetry`, and :class:`AsyncStreamingRetry`.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport logging\nimport random\nimport time\n\nfrom enum import Enum\nfrom typing import Any, Callable, Optional, TYPE_CHECKING\n\nimport requests.exceptions\n\nfrom google.api_core import exceptions\nfrom google.auth import exceptions as auth_exceptions\n\nif TYPE_CHECKING:\n    import sys\n\n    if sys.version_info >= (3, 11):\n        from typing import Self\n    else:\n        from typing_extensions import Self\n\n_DEFAULT_INITIAL_DELAY = 1.0  # seconds\n_DEFAULT_MAXIMUM_DELAY = 60.0  # seconds\n_DEFAULT_DELAY_MULTIPLIER = 2.0\n_DEFAULT_DEADLINE = 60.0 * 2.0  # seconds\n\n_LOGGER = logging.getLogger(\"google.api_core.retry\")\n\n\ndef if_exception_type(\n    *exception_types: type[Exception],\n) -> Callable[[Exception], bool]:\n    \"\"\"Creates a predicate to check if the exception is of a given type.\n\n    Args:\n        exception_types (Sequence[:func:`type`]): The exception types to check\n            for.\n\n    Returns:\n        Callable[Exception]: A predicate that returns True if the provided\n            exception is of the given type(s).\n    \"\"\"\n\n    def if_exception_type_predicate(exception: Exception) -> bool:\n        \"\"\"Bound predicate for checking an exception type.\"\"\"\n        return isinstance(exception, exception_types)\n\n    return if_exception_type_predicate\n\n\n# pylint: disable=invalid-name\n# Pylint sees this as a constant, but it is also an alias that should be\n# considered a function.\nif_transient_error = if_exception_type(\n    exceptions.InternalServerError,\n    exceptions.TooManyRequests,\n    exceptions.ServiceUnavailable,\n    requests.exceptions.ConnectionError,\n    requests.exceptions.ChunkedEncodingError,\n    auth_exceptions.TransportError,\n)\n\"\"\"A predicate that checks if an exception is a transient API error.\n\nThe following server errors are considered transient:\n\n- :class:`google.api_core.exceptions.InternalServerError` - HTTP 500, gRPC\n    ``INTERNAL(13)`` and its subclasses.\n- :class:`google.api_core.exceptions.TooManyRequests` - HTTP 429\n- :class:`google.api_core.exceptions.ServiceUnavailable` - HTTP 503\n- :class:`requests.exceptions.ConnectionError`\n- :class:`requests.exceptions.ChunkedEncodingError` - The server declared\n    chunked encoding but sent an invalid chunk.\n- :class:`google.auth.exceptions.TransportError` - Used to indicate an\n    error occurred during an HTTP request.\n\"\"\"\n# pylint: enable=invalid-name\n\n\ndef exponential_sleep_generator(\n    initial: float, maximum: float, multiplier: float = _DEFAULT_DELAY_MULTIPLIER\n):\n    \"\"\"Generates sleep intervals based on the exponential back-off algorithm.\n\n    This implements the `Truncated Exponential Back-off`_ algorithm.\n\n    .. _Truncated Exponential Back-off:\n        https://cloud.google.com/storage/docs/exponential-backoff\n\n    Args:\n        initial (float): The minimum amount of time to delay. This must\n            be greater than 0.\n        maximum (float): The maximum amount of time to delay.\n        multiplier (float): The multiplier applied to the delay.\n\n    Yields:\n        float: successive sleep intervals.\n    \"\"\"\n    max_delay = min(initial, maximum)\n    while True:\n        yield random.uniform(0.0, max_delay)\n        max_delay = min(max_delay * multiplier, maximum)\n\n\nclass RetryFailureReason(Enum):\n    \"\"\"\n    The cause of a failed retry, used when building exceptions\n    \"\"\"\n\n    TIMEOUT = 0\n    NON_RETRYABLE_ERROR = 1\n\n\ndef build_retry_error(\n    exc_list: list[Exception],\n    reason: RetryFailureReason,\n    timeout_val: float | None,\n    **kwargs: Any,\n) -> tuple[Exception, Exception | None]:\n    \"\"\"\n    Default exception_factory implementation.\n\n    Returns a RetryError if the failure is due to a timeout, otherwise\n    returns the last exception encountered.\n\n    Args:\n      - exc_list: list of exceptions that occurred during the retry\n      - reason: reason for the retry failure.\n            Can be TIMEOUT or NON_RETRYABLE_ERROR\n      - timeout_val: the original timeout value for the retry (in seconds), for use in the exception message\n\n    Returns:\n      - tuple: a tuple of the exception to be raised, and the cause exception if any\n    \"\"\"\n    if reason == RetryFailureReason.TIMEOUT:\n        # return RetryError with the most recent exception as the cause\n        src_exc = exc_list[-1] if exc_list else None\n        timeout_val_str = f\"of {timeout_val:0.1f}s \" if timeout_val is not None else \"\"\n        return (\n            exceptions.RetryError(\n                f\"Timeout {timeout_val_str}exceeded\",\n                src_exc,\n            ),\n            src_exc,\n        )\n    elif exc_list:\n        # return most recent exception encountered\n        return exc_list[-1], None\n    else:\n        # no exceptions were given in exc_list. Raise generic RetryError\n        return exceptions.RetryError(\"Unknown error\", None), None\n\n\ndef _retry_error_helper(\n    exc: Exception,\n    deadline: float | None,\n    next_sleep: float,\n    error_list: list[Exception],\n    predicate_fn: Callable[[Exception], bool],\n    on_error_fn: Callable[[Exception], None] | None,\n    exc_factory_fn: Callable[\n        [list[Exception], RetryFailureReason, float | None],\n        tuple[Exception, Exception | None],\n    ],\n    original_timeout: float | None,\n):\n    \"\"\"\n    Shared logic for handling an error for all retry implementations\n\n    - Raises an error on timeout or non-retryable error\n    - Calls on_error_fn if provided\n    - Logs the error\n\n    Args:\n       - exc: the exception that was raised\n       - deadline: the deadline for the retry, calculated as a diff from time.monotonic()\n       - next_sleep: the next sleep interval\n       - error_list: the list of exceptions that have been raised so far\n       - predicate_fn: takes `exc` and returns true if the operation should be retried\n       - on_error_fn: callback to execute when a retryable error occurs\n       - exc_factory_fn: callback used to build the exception to be raised on terminal failure\n       - original_timeout_val: the original timeout value for the retry (in seconds),\n           to be passed to the exception factory for building an error message\n    \"\"\"\n    error_list.append(exc)\n    if not predicate_fn(exc):\n        final_exc, source_exc = exc_factory_fn(\n            error_list,\n            RetryFailureReason.NON_RETRYABLE_ERROR,\n            original_timeout,\n        )\n        raise final_exc from source_exc\n    if on_error_fn is not None:\n        on_error_fn(exc)\n    if deadline is not None and time.monotonic() + next_sleep > deadline:\n        final_exc, source_exc = exc_factory_fn(\n            error_list,\n            RetryFailureReason.TIMEOUT,\n            original_timeout,\n        )\n        raise final_exc from source_exc\n    _LOGGER.debug(\n        \"Retrying due to {}, sleeping {:.1f}s ...\".format(error_list[-1], next_sleep)\n    )\n\n\nclass _BaseRetry(object):\n    \"\"\"\n    Base class for retry configuration objects. This class is intended to capture retry\n    and backoff configuration that is common to both synchronous and asynchronous retries,\n    for both unary and streaming RPCs. It is not intended to be instantiated directly,\n    but rather to be subclassed by the various retry configuration classes.\n    \"\"\"\n\n    def __init__(\n        self,\n        predicate: Callable[[Exception], bool] = if_transient_error,\n        initial: float = _DEFAULT_INITIAL_DELAY,\n        maximum: float = _DEFAULT_MAXIMUM_DELAY,\n        multiplier: float = _DEFAULT_DELAY_MULTIPLIER,\n        timeout: Optional[float] = _DEFAULT_DEADLINE,\n        on_error: Optional[Callable[[Exception], Any]] = None,\n        **kwargs: Any,\n    ) -> None:\n        self._predicate = predicate\n        self._initial = initial\n        self._multiplier = multiplier\n        self._maximum = maximum\n        self._timeout = kwargs.get(\"deadline\", timeout)\n        self._deadline = self._timeout\n        self._on_error = on_error\n\n    def __call__(self, *args, **kwargs) -> Any:\n        raise NotImplementedError(\"Not implemented in base class\")\n\n    @property\n    def deadline(self) -> float | None:\n        \"\"\"\n        DEPRECATED: use ``timeout`` instead.  Refer to the ``Retry`` class\n        documentation for details.\n        \"\"\"\n        return self._timeout\n\n    @property\n    def timeout(self) -> float | None:\n        return self._timeout\n\n    def with_deadline(self, deadline: float | None) -> Self:\n        \"\"\"Return a copy of this retry with the given timeout.\n\n        DEPRECATED: use :meth:`with_timeout` instead. Refer to the ``Retry`` class\n        documentation for details.\n\n        Args:\n            deadline (float|None): How long to keep retrying, in seconds. If None,\n                no timeout is enforced.\n\n        Returns:\n            Retry: A new retry instance with the given timeout.\n        \"\"\"\n        return self.with_timeout(deadline)\n\n    def with_timeout(self, timeout: float | None) -> Self:\n        \"\"\"Return a copy of this retry with the given timeout.\n\n        Args:\n            timeout (float): How long to keep retrying, in seconds. If None,\n                no timeout will be enforced.\n\n        Returns:\n            Retry: A new retry instance with the given timeout.\n        \"\"\"\n        return type(self)(\n            predicate=self._predicate,\n            initial=self._initial,\n            maximum=self._maximum,\n            multiplier=self._multiplier,\n            timeout=timeout,\n            on_error=self._on_error,\n        )\n\n    def with_predicate(self, predicate: Callable[[Exception], bool]) -> Self:\n        \"\"\"Return a copy of this retry with the given predicate.\n\n        Args:\n            predicate (Callable[Exception]): A callable that should return\n                ``True`` if the given exception is retryable.\n\n        Returns:\n            Retry: A new retry instance with the given predicate.\n        \"\"\"\n        return type(self)(\n            predicate=predicate,\n            initial=self._initial,\n            maximum=self._maximum,\n            multiplier=self._multiplier,\n            timeout=self._timeout,\n            on_error=self._on_error,\n        )\n\n    def with_delay(\n        self,\n        initial: Optional[float] = None,\n        maximum: Optional[float] = None,\n        multiplier: Optional[float] = None,\n    ) -> Self:\n        \"\"\"Return a copy of this retry with the given delay options.\n\n        Args:\n            initial (float): The minimum amount of time to delay (in seconds). This must\n                be greater than 0. If None, the current value is used.\n            maximum (float): The maximum amount of time to delay (in seconds). If None, the\n                current value is used.\n            multiplier (float): The multiplier applied to the delay. If None, the current\n                value is used.\n\n        Returns:\n            Retry: A new retry instance with the given delay options.\n        \"\"\"\n        return type(self)(\n            predicate=self._predicate,\n            initial=initial if initial is not None else self._initial,\n            maximum=maximum if maximum is not None else self._maximum,\n            multiplier=multiplier if multiplier is not None else self._multiplier,\n            timeout=self._timeout,\n            on_error=self._on_error,\n        )\n\n    def __str__(self) -> str:\n        return (\n            \"<{} predicate={}, initial={:.1f}, maximum={:.1f}, \"\n            \"multiplier={:.1f}, timeout={}, on_error={}>\".format(\n                type(self).__name__,\n                self._predicate,\n                self._initial,\n                self._maximum,\n                self._multiplier,\n                self._timeout,  # timeout can be None, thus no {:.1f}\n                self._on_error,\n            )\n        )\n", "google/api_core/gapic_v1/config.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Helpers for loading gapic configuration data.\n\nThe Google API generator creates supplementary configuration for each RPC\nmethod to tell the client library how to deal with retries and timeouts.\n\"\"\"\n\nimport collections\n\nimport grpc\n\nfrom google.api_core import exceptions\nfrom google.api_core import retry\nfrom google.api_core import timeout\n\n\n_MILLIS_PER_SECOND = 1000.0\n\n\ndef _exception_class_for_grpc_status_name(name):\n    \"\"\"Returns the Google API exception class for a gRPC error code name.\n\n    DEPRECATED: use ``exceptions.exception_class_for_grpc_status`` method\n    directly instead.\n\n    Args:\n        name (str): The name of the gRPC status code, for example,\n            ``UNAVAILABLE``.\n\n    Returns:\n        :func:`type`: The appropriate subclass of\n            :class:`google.api_core.exceptions.GoogleAPICallError`.\n    \"\"\"\n    return exceptions.exception_class_for_grpc_status(getattr(grpc.StatusCode, name))\n\n\ndef _retry_from_retry_config(retry_params, retry_codes, retry_impl=retry.Retry):\n    \"\"\"Creates a Retry object given a gapic retry configuration.\n\n    DEPRECATED: instantiate retry and timeout classes directly instead.\n\n    Args:\n        retry_params (dict): The retry parameter values, for example::\n\n            {\n                \"initial_retry_delay_millis\": 1000,\n                \"retry_delay_multiplier\": 2.5,\n                \"max_retry_delay_millis\": 120000,\n                \"initial_rpc_timeout_millis\": 120000,\n                \"rpc_timeout_multiplier\": 1.0,\n                \"max_rpc_timeout_millis\": 120000,\n                \"total_timeout_millis\": 600000\n            }\n\n        retry_codes (sequence[str]): The list of retryable gRPC error code\n            names.\n\n    Returns:\n        google.api_core.retry.Retry: The default retry object for the method.\n    \"\"\"\n    exception_classes = [\n        _exception_class_for_grpc_status_name(code) for code in retry_codes\n    ]\n    return retry_impl(\n        retry.if_exception_type(*exception_classes),\n        initial=(retry_params[\"initial_retry_delay_millis\"] / _MILLIS_PER_SECOND),\n        maximum=(retry_params[\"max_retry_delay_millis\"] / _MILLIS_PER_SECOND),\n        multiplier=retry_params[\"retry_delay_multiplier\"],\n        deadline=retry_params[\"total_timeout_millis\"] / _MILLIS_PER_SECOND,\n    )\n\n\ndef _timeout_from_retry_config(retry_params):\n    \"\"\"Creates a ExponentialTimeout object given a gapic retry configuration.\n\n    DEPRECATED: instantiate retry and timeout classes directly instead.\n\n    Args:\n        retry_params (dict): The retry parameter values, for example::\n\n            {\n                \"initial_retry_delay_millis\": 1000,\n                \"retry_delay_multiplier\": 2.5,\n                \"max_retry_delay_millis\": 120000,\n                \"initial_rpc_timeout_millis\": 120000,\n                \"rpc_timeout_multiplier\": 1.0,\n                \"max_rpc_timeout_millis\": 120000,\n                \"total_timeout_millis\": 600000\n            }\n\n    Returns:\n        google.api_core.retry.ExponentialTimeout: The default time object for\n            the method.\n    \"\"\"\n    return timeout.ExponentialTimeout(\n        initial=(retry_params[\"initial_rpc_timeout_millis\"] / _MILLIS_PER_SECOND),\n        maximum=(retry_params[\"max_rpc_timeout_millis\"] / _MILLIS_PER_SECOND),\n        multiplier=retry_params[\"rpc_timeout_multiplier\"],\n        deadline=(retry_params[\"total_timeout_millis\"] / _MILLIS_PER_SECOND),\n    )\n\n\nMethodConfig = collections.namedtuple(\"MethodConfig\", [\"retry\", \"timeout\"])\n\n\ndef parse_method_configs(interface_config, retry_impl=retry.Retry):\n    \"\"\"Creates default retry and timeout objects for each method in a gapic\n    interface config.\n\n    DEPRECATED: instantiate retry and timeout classes directly instead.\n\n    Args:\n        interface_config (Mapping): The interface config section of the full\n            gapic library config. For example, If the full configuration has\n            an interface named ``google.example.v1.ExampleService`` you would\n            pass in just that interface's configuration, for example\n            ``gapic_config['interfaces']['google.example.v1.ExampleService']``.\n        retry_impl (Callable): The constructor that creates a retry decorator\n            that will be applied to the method based on method configs.\n\n    Returns:\n        Mapping[str, MethodConfig]: A mapping of RPC method names to their\n            configuration.\n    \"\"\"\n    # Grab all the retry codes\n    retry_codes_map = {\n        name: retry_codes\n        for name, retry_codes in interface_config.get(\"retry_codes\", {}).items()\n    }\n\n    # Grab all of the retry params\n    retry_params_map = {\n        name: retry_params\n        for name, retry_params in interface_config.get(\"retry_params\", {}).items()\n    }\n\n    # Iterate through all the API methods and create a flat MethodConfig\n    # instance for each one.\n    method_configs = {}\n\n    for method_name, method_params in interface_config.get(\"methods\", {}).items():\n        retry_params_name = method_params.get(\"retry_params_name\")\n\n        if retry_params_name is not None:\n            retry_params = retry_params_map[retry_params_name]\n            retry_ = _retry_from_retry_config(\n                retry_params,\n                retry_codes_map[method_params[\"retry_codes_name\"]],\n                retry_impl,\n            )\n            timeout_ = _timeout_from_retry_config(retry_params)\n\n        # No retry config, so this is a non-retryable method.\n        else:\n            retry_ = None\n            timeout_ = timeout.ConstantTimeout(\n                method_params[\"timeout_millis\"] / _MILLIS_PER_SECOND\n            )\n\n        method_configs[method_name] = MethodConfig(retry=retry_, timeout=timeout_)\n\n    return method_configs\n", "google/api_core/gapic_v1/method_async.py": "# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\"AsyncIO helpers for wrapping gRPC methods with common functionality.\n\nThis is used by gapic clients to provide common error mapping, retry, timeout,\ncompression, pagination, and long-running operations to gRPC methods.\n\"\"\"\n\nimport functools\n\nfrom google.api_core import grpc_helpers_async\nfrom google.api_core.gapic_v1 import client_info\nfrom google.api_core.gapic_v1.method import _GapicCallable\nfrom google.api_core.gapic_v1.method import DEFAULT  # noqa: F401\nfrom google.api_core.gapic_v1.method import USE_DEFAULT_METADATA  # noqa: F401\n\n\ndef wrap_method(\n    func,\n    default_retry=None,\n    default_timeout=None,\n    default_compression=None,\n    client_info=client_info.DEFAULT_CLIENT_INFO,\n):\n    \"\"\"Wrap an async RPC method with common behavior.\n\n    Returns:\n        Callable: A new callable that takes optional ``retry``, ``timeout``,\n            and ``compression`` arguments and applies the common error mapping,\n            retry, timeout, metadata, and compression behavior to the low-level RPC method.\n    \"\"\"\n    func = grpc_helpers_async.wrap_errors(func)\n\n    metadata = [client_info.to_grpc_metadata()] if client_info is not None else None\n\n    return functools.wraps(func)(\n        _GapicCallable(\n            func,\n            default_retry,\n            default_timeout,\n            default_compression,\n            metadata=metadata,\n        )\n    )\n", "google/api_core/gapic_v1/client_info.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Helpers for providing client information.\n\nClient information is used to send information about the calling client,\nsuch as the library and Python version, to API services.\n\"\"\"\n\nfrom google.api_core import client_info\n\n\nMETRICS_METADATA_KEY = \"x-goog-api-client\"\n\n\nclass ClientInfo(client_info.ClientInfo):\n    \"\"\"Client information used to generate a user-agent for API calls.\n\n    This user-agent information is sent along with API calls to allow the\n    receiving service to do analytics on which versions of Python and Google\n    libraries are being used.\n\n    Args:\n        python_version (str): The Python interpreter version, for example,\n            ``'3.9.6'``.\n        grpc_version (Optional[str]): The gRPC library version.\n        api_core_version (str): The google-api-core library version.\n        gapic_version (Optional[str]): The version of gapic-generated client\n            library, if the library was generated by gapic.\n        client_library_version (Optional[str]): The version of the client\n            library, generally used if the client library was not generated\n            by gapic or if additional functionality was built on top of\n            a gapic client library.\n        user_agent (Optional[str]): Prefix to the user agent header. This is\n            used to supply information such as application name or partner tool.\n            Recommended format: ``application-or-tool-ID/major.minor.version``.\n    \"\"\"\n\n    def to_grpc_metadata(self):\n        \"\"\"Returns the gRPC metadata for this client info.\"\"\"\n        return (METRICS_METADATA_KEY, self.to_user_agent())\n\n\nDEFAULT_CLIENT_INFO = ClientInfo()\n", "google/api_core/gapic_v1/method.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Helpers for wrapping low-level gRPC methods with common functionality.\n\nThis is used by gapic clients to provide common error mapping, retry, timeout,\ncompression, pagination, and long-running operations to gRPC methods.\n\"\"\"\n\nimport enum\nimport functools\n\nfrom google.api_core import grpc_helpers\nfrom google.api_core.gapic_v1 import client_info\nfrom google.api_core.timeout import TimeToDeadlineTimeout\n\nUSE_DEFAULT_METADATA = object()\n\n\nclass _MethodDefault(enum.Enum):\n    # Uses enum so that pytype/mypy knows that this is the only possible value.\n    # https://stackoverflow.com/a/60605919/101923\n    #\n    # Literal[_DEFAULT_VALUE] is an alternative, but only added in Python 3.8.\n    # https://docs.python.org/3/library/typing.html#typing.Literal\n    _DEFAULT_VALUE = object()\n\n\nDEFAULT = _MethodDefault._DEFAULT_VALUE\n\"\"\"Sentinel value indicating that a retry, timeout, or compression argument was unspecified,\nso the default should be used.\"\"\"\n\n\ndef _is_not_none_or_false(value):\n    return value is not None and value is not False\n\n\ndef _apply_decorators(func, decorators):\n    \"\"\"Apply a list of decorators to a given function.\n\n    ``decorators`` may contain items that are ``None`` or ``False`` which will\n    be ignored.\n    \"\"\"\n    filtered_decorators = filter(_is_not_none_or_false, reversed(decorators))\n\n    for decorator in filtered_decorators:\n        func = decorator(func)\n\n    return func\n\n\nclass _GapicCallable(object):\n    \"\"\"Callable that applies retry, timeout, and metadata logic.\n\n    Args:\n        target (Callable): The low-level RPC method.\n        retry (google.api_core.retry.Retry): The default retry for the\n            callable. If ``None``, this callable will not retry by default\n        timeout (google.api_core.timeout.Timeout): The default timeout for the\n            callable (i.e. duration of time within which an RPC must terminate\n            after its start, not to be confused with deadline). If ``None``,\n            this callable will not specify a timeout argument to the low-level\n            RPC method.\n        compression (grpc.Compression): The default compression for the callable.\n            If ``None``, this callable will not specify a compression argument\n            to the low-level RPC method.\n        metadata (Sequence[Tuple[str, str]]): Additional metadata that is\n            provided to the RPC method on every invocation. This is merged with\n            any metadata specified during invocation. If ``None``, no\n            additional metadata will be passed to the RPC method.\n    \"\"\"\n\n    def __init__(\n        self,\n        target,\n        retry,\n        timeout,\n        compression,\n        metadata=None,\n    ):\n        self._target = target\n        self._retry = retry\n        self._timeout = timeout\n        self._compression = compression\n        self._metadata = metadata\n\n    def __call__(\n        self, *args, timeout=DEFAULT, retry=DEFAULT, compression=DEFAULT, **kwargs\n    ):\n        \"\"\"Invoke the low-level RPC with retry, timeout, compression, and metadata.\"\"\"\n\n        if retry is DEFAULT:\n            retry = self._retry\n\n        if timeout is DEFAULT:\n            timeout = self._timeout\n\n        if compression is DEFAULT:\n            compression = self._compression\n\n        if isinstance(timeout, (int, float)):\n            timeout = TimeToDeadlineTimeout(timeout=timeout)\n\n        # Apply all applicable decorators.\n        wrapped_func = _apply_decorators(self._target, [retry, timeout])\n\n        # Add the user agent metadata to the call.\n        if self._metadata is not None:\n            metadata = kwargs.get(\"metadata\", [])\n            # Due to the nature of invocation, None should be treated the same\n            # as not specified.\n            if metadata is None:\n                metadata = []\n            metadata = list(metadata)\n            metadata.extend(self._metadata)\n            kwargs[\"metadata\"] = metadata\n        if self._compression is not None:\n            kwargs[\"compression\"] = compression\n\n        return wrapped_func(*args, **kwargs)\n\n\ndef wrap_method(\n    func,\n    default_retry=None,\n    default_timeout=None,\n    default_compression=None,\n    client_info=client_info.DEFAULT_CLIENT_INFO,\n    *,\n    with_call=False,\n):\n    \"\"\"Wrap an RPC method with common behavior.\n\n    This applies common error wrapping, retry, timeout, and compression behavior to a function.\n    The wrapped function will take optional ``retry``, ``timeout``, and ``compression``\n    arguments.\n\n    For example::\n\n        import google.api_core.gapic_v1.method\n        from google.api_core import retry\n        from google.api_core import timeout\n        from grpc import Compression\n\n        # The original RPC method.\n        def get_topic(name, timeout=None):\n            request = publisher_v2.GetTopicRequest(name=name)\n            return publisher_stub.GetTopic(request, timeout=timeout)\n\n        default_retry = retry.Retry(deadline=60)\n        default_timeout = timeout.Timeout(deadline=60)\n        default_compression = Compression.NoCompression\n        wrapped_get_topic = google.api_core.gapic_v1.method.wrap_method(\n            get_topic, default_retry)\n\n        # Execute get_topic with default retry and timeout:\n        response = wrapped_get_topic()\n\n        # Execute get_topic without doing any retying but with the default\n        # timeout:\n        response = wrapped_get_topic(retry=None)\n\n        # Execute get_topic but only retry on 5xx errors:\n        my_retry = retry.Retry(retry.if_exception_type(\n            exceptions.InternalServerError))\n        response = wrapped_get_topic(retry=my_retry)\n\n    The way this works is by late-wrapping the given function with the retry\n    and timeout decorators. Essentially, when ``wrapped_get_topic()`` is\n    called:\n\n    * ``get_topic()`` is first wrapped with the ``timeout`` into\n      ``get_topic_with_timeout``.\n    * ``get_topic_with_timeout`` is wrapped with the ``retry`` into\n      ``get_topic_with_timeout_and_retry()``.\n    * The final ``get_topic_with_timeout_and_retry`` is called passing through\n      the ``args``  and ``kwargs``.\n\n    The callstack is therefore::\n\n        method.__call__() ->\n            Retry.__call__() ->\n                Timeout.__call__() ->\n                    wrap_errors() ->\n                        get_topic()\n\n    Note that if ``timeout`` or ``retry`` is ``None``, then they are not\n    applied to the function. For example,\n    ``wrapped_get_topic(timeout=None, retry=None)`` is more or less\n    equivalent to just calling ``get_topic`` but with error re-mapping.\n\n    Args:\n        func (Callable[Any]): The function to wrap. It should accept an\n            optional ``timeout`` argument. If ``metadata`` is not ``None``, it\n            should accept a ``metadata`` argument.\n        default_retry (Optional[google.api_core.Retry]): The default retry\n            strategy. If ``None``, the method will not retry by default.\n        default_timeout (Optional[google.api_core.Timeout]): The default\n            timeout strategy. Can also be specified as an int or float. If\n            ``None``, the method will not have timeout specified by default.\n        default_compression (Optional[grpc.Compression]): The default\n            grpc.Compression. If ``None``, the method will not have\n            compression specified by default.\n        client_info\n            (Optional[google.api_core.gapic_v1.client_info.ClientInfo]):\n                Client information used to create a user-agent string that's\n                passed as gRPC metadata to the method. If unspecified, then\n                a sane default will be used. If ``None``, then no user agent\n                metadata will be provided to the RPC method.\n        with_call (bool): If True, wrapped grpc.UnaryUnaryMulticallables will\n            return a tuple of (response, grpc.Call) instead of just the response.\n            This is useful for extracting trailing metadata from unary calls.\n            Defaults to False.\n\n    Returns:\n        Callable: A new callable that takes optional ``retry``, ``timeout``,\n            and ``compression``\n            arguments and applies the common error mapping, retry, timeout, compression,\n            and metadata behavior to the low-level RPC method.\n    \"\"\"\n    if with_call:\n        try:\n            func = func.with_call\n        except AttributeError as exc:\n            raise ValueError(\n                \"with_call=True is only supported for unary calls.\"\n            ) from exc\n    func = grpc_helpers.wrap_errors(func)\n    if client_info is not None:\n        user_agent_metadata = [client_info.to_grpc_metadata()]\n    else:\n        user_agent_metadata = None\n\n    return functools.wraps(func)(\n        _GapicCallable(\n            func,\n            default_retry,\n            default_timeout,\n            default_compression,\n            metadata=user_agent_metadata,\n        )\n    )\n", "google/api_core/gapic_v1/routing_header.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Helpers for constructing routing headers.\n\nThese headers are used by Google infrastructure to determine how to route\nrequests, especially for services that are regional.\n\nGenerally, these headers are specified as gRPC metadata.\n\"\"\"\n\nimport functools\nfrom enum import Enum\nfrom urllib.parse import urlencode\n\nROUTING_METADATA_KEY = \"x-goog-request-params\"\n# This is the value for the `maxsize` argument of @functools.lru_cache\n# https://docs.python.org/3/library/functools.html#functools.lru_cache\n# This represents the number of recent function calls to store.\nROUTING_PARAM_CACHE_SIZE = 32\n\n\ndef to_routing_header(params, qualified_enums=True):\n    \"\"\"Returns a routing header string for the given request parameters.\n\n    Args:\n        params (Mapping[str, str | bytes | Enum]): A dictionary containing the request\n            parameters used for routing.\n        qualified_enums (bool): Whether to represent enum values\n            as their type-qualified symbol names instead of as their\n            unqualified symbol names.\n\n    Returns:\n        str: The routing header string.\n    \"\"\"\n    tuples = params.items() if isinstance(params, dict) else params\n    if not qualified_enums:\n        tuples = [(x[0], x[1].name) if isinstance(x[1], Enum) else x for x in tuples]\n    return \"&\".join([_urlencode_param(*t) for t in tuples])\n\n\ndef to_grpc_metadata(params, qualified_enums=True):\n    \"\"\"Returns the gRPC metadata containing the routing headers for the given\n    request parameters.\n\n    Args:\n        params (Mapping[str, str | bytes | Enum]): A dictionary containing the request\n            parameters used for routing.\n        qualified_enums (bool): Whether to represent enum values\n            as their type-qualified symbol names instead of as their\n            unqualified symbol names.\n\n    Returns:\n        Tuple(str, str): The gRPC metadata containing the routing header key\n            and value.\n    \"\"\"\n    return (ROUTING_METADATA_KEY, to_routing_header(params, qualified_enums))\n\n\n# use caching to avoid repeated computation\n@functools.lru_cache(maxsize=ROUTING_PARAM_CACHE_SIZE)\ndef _urlencode_param(key, value):\n    \"\"\"Cacheable wrapper over urlencode\n\n    Args:\n        key (str): The key of the parameter to encode.\n        value (str | bytes | Enum): The value of the parameter to encode.\n\n    Returns:\n        str: The encoded parameter.\n    \"\"\"\n    return urlencode(\n        {key: value},\n        # Per Google API policy (go/api-url-encoding), / is not encoded.\n        safe=\"/\",\n    )\n", "google/api_core/gapic_v1/config_async.py": "# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\"AsyncIO helpers for loading gapic configuration data.\n\nThe Google API generator creates supplementary configuration for each RPC\nmethod to tell the client library how to deal with retries and timeouts.\n\"\"\"\n\nfrom google.api_core import retry_async\nfrom google.api_core.gapic_v1 import config\nfrom google.api_core.gapic_v1.config import MethodConfig  # noqa: F401\n\n\ndef parse_method_configs(interface_config):\n    \"\"\"Creates default retry and timeout objects for each method in a gapic\n    interface config with AsyncIO semantics.\n\n    Args:\n        interface_config (Mapping): The interface config section of the full\n            gapic library config. For example, If the full configuration has\n            an interface named ``google.example.v1.ExampleService`` you would\n            pass in just that interface's configuration, for example\n            ``gapic_config['interfaces']['google.example.v1.ExampleService']``.\n\n    Returns:\n        Mapping[str, MethodConfig]: A mapping of RPC method names to their\n            configuration.\n    \"\"\"\n    return config.parse_method_configs(\n        interface_config, retry_impl=retry_async.AsyncRetry\n    )\n", "google/api_core/gapic_v1/__init__.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom google.api_core.gapic_v1 import client_info\nfrom google.api_core.gapic_v1 import config\nfrom google.api_core.gapic_v1 import config_async\nfrom google.api_core.gapic_v1 import method\nfrom google.api_core.gapic_v1 import method_async\nfrom google.api_core.gapic_v1 import routing_header\n\n__all__ = [\n    \"client_info\",\n    \"config\",\n    \"config_async\",\n    \"method\",\n    \"method_async\",\n    \"routing_header\",\n]\n", "google/api_core/future/polling.py": "# Copyright 2017, Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Abstract and helper bases for Future implementations.\"\"\"\n\nimport abc\nimport concurrent.futures\n\nfrom google.api_core import exceptions\nfrom google.api_core import retry as retries\nfrom google.api_core.future import _helpers\nfrom google.api_core.future import base\n\n\nclass _OperationNotComplete(Exception):\n    \"\"\"Private exception used for polling via retry.\"\"\"\n\n    pass\n\n\n# DEPRECATED as it conflates RPC retry and polling concepts into one.\n# Use POLLING_PREDICATE instead to configure polling.\nRETRY_PREDICATE = retries.if_exception_type(\n    _OperationNotComplete,\n    exceptions.TooManyRequests,\n    exceptions.InternalServerError,\n    exceptions.BadGateway,\n    exceptions.ServiceUnavailable,\n)\n\n# DEPRECATED: use DEFAULT_POLLING to configure LRO polling logic. Construct\n# Retry object using its default values as a baseline for any custom retry logic\n# (not to be confused with polling logic).\nDEFAULT_RETRY = retries.Retry(predicate=RETRY_PREDICATE)\n\n# POLLING_PREDICATE is supposed to poll only on _OperationNotComplete.\n# Any RPC-specific errors (like ServiceUnavailable) will be handled\n# by retry logic (not to be confused with polling logic) which is triggered for\n# every polling RPC independently of polling logic but within its context.\nPOLLING_PREDICATE = retries.if_exception_type(\n    _OperationNotComplete,\n)\n\n# Default polling configuration\nDEFAULT_POLLING = retries.Retry(\n    predicate=POLLING_PREDICATE,\n    initial=1.0,  # seconds\n    maximum=20.0,  # seconds\n    multiplier=1.5,\n    timeout=900,  # seconds\n)\n\n\nclass PollingFuture(base.Future):\n    \"\"\"A Future that needs to poll some service to check its status.\n\n    The :meth:`done` method should be implemented by subclasses. The polling\n    behavior will repeatedly call ``done`` until it returns True.\n\n    The actual polling logic is encapsulated in :meth:`result` method. See\n    documentation for that method for details on how polling works.\n\n    .. note::\n\n        Privacy here is intended to prevent the final class from\n        overexposing, not to prevent subclasses from accessing methods.\n\n    Args:\n        polling (google.api_core.retry.Retry): The configuration used for polling.\n            This parameter controls how often :meth:`done` is polled. If the\n            ``timeout`` argument is specified in :meth:`result` method it will\n            override the ``polling.timeout`` property.\n        retry (google.api_core.retry.Retry): DEPRECATED use ``polling`` instead.\n            If set, it will override ``polling`` parameter for backward\n            compatibility.\n    \"\"\"\n\n    _DEFAULT_VALUE = object()\n\n    def __init__(self, polling=DEFAULT_POLLING, **kwargs):\n        super(PollingFuture, self).__init__()\n        self._polling = kwargs.get(\"retry\", polling)\n        self._result = None\n        self._exception = None\n        self._result_set = False\n        \"\"\"bool: Set to True when the result has been set via set_result or\n        set_exception.\"\"\"\n        self._polling_thread = None\n        self._done_callbacks = []\n\n    @abc.abstractmethod\n    def done(self, retry=None):\n        \"\"\"Checks to see if the operation is complete.\n\n        Args:\n            retry (google.api_core.retry.Retry): (Optional) How to retry the\n                polling RPC (to not be confused with polling configuration. See\n                the documentation for :meth:`result` for details).\n\n        Returns:\n            bool: True if the operation is complete, False otherwise.\n        \"\"\"\n        # pylint: disable=redundant-returns-doc, missing-raises-doc\n        raise NotImplementedError()\n\n    def _done_or_raise(self, retry=None):\n        \"\"\"Check if the future is done and raise if it's not.\"\"\"\n        if not self.done(retry=retry):\n            raise _OperationNotComplete()\n\n    def running(self):\n        \"\"\"True if the operation is currently running.\"\"\"\n        return not self.done()\n\n    def _blocking_poll(self, timeout=_DEFAULT_VALUE, retry=None, polling=None):\n        \"\"\"Poll and wait for the Future to be resolved.\"\"\"\n\n        if self._result_set:\n            return\n\n        polling = polling or self._polling\n        if timeout is not PollingFuture._DEFAULT_VALUE:\n            polling = polling.with_timeout(timeout)\n\n        try:\n            polling(self._done_or_raise)(retry=retry)\n        except exceptions.RetryError:\n            raise concurrent.futures.TimeoutError(\n                f\"Operation did not complete within the designated timeout of \"\n                f\"{polling.timeout} seconds.\"\n            )\n\n    def result(self, timeout=_DEFAULT_VALUE, retry=None, polling=None):\n        \"\"\"Get the result of the operation.\n\n        This method will poll for operation status periodically, blocking if\n        necessary. If you just want to make sure that this method does not block\n        for more than X seconds and you do not care about the nitty-gritty of\n        how this method operates, just call it with ``result(timeout=X)``. The\n        other parameters are for advanced use only.\n\n        Every call to this method is controlled by the following three\n        parameters, each of which has a specific, distinct role, even though all three\n        may look very similar: ``timeout``, ``retry`` and ``polling``. In most\n        cases users do not need to specify any custom values for any of these\n        parameters and may simply rely on default ones instead.\n\n        If you choose to specify custom parameters, please make sure you've\n        read the documentation below carefully.\n\n        First, please check :class:`google.api_core.retry.Retry`\n        class documentation for the proper definition of timeout and deadline\n        terms and for the definition the three different types of timeouts.\n        This class operates in terms of Retry Timeout and Polling Timeout. It\n        does not let customizing RPC timeout and the user is expected to rely on\n        default behavior for it.\n\n        The roles of each argument of this method are as follows:\n\n        ``timeout`` (int): (Optional) The Polling Timeout as defined in\n        :class:`google.api_core.retry.Retry`. If the operation does not complete\n        within this timeout an exception will be thrown. This parameter affects\n        neither Retry Timeout nor RPC Timeout.\n\n        ``retry`` (google.api_core.retry.Retry): (Optional) How to retry the\n        polling RPC. The ``retry.timeout`` property of this parameter is the\n        Retry Timeout as defined in :class:`google.api_core.retry.Retry`.\n        This parameter defines ONLY how the polling RPC call is retried\n        (i.e. what to do if the RPC we used for polling returned an error). It\n        does NOT define how the polling is done (i.e. how frequently and for\n        how long to call the polling RPC); use the ``polling`` parameter for that.\n        If a polling RPC throws and error and retrying it fails, the whole\n        future fails with the corresponding exception. If you want to tune which\n        server response error codes are not fatal for operation polling, use this\n        parameter to control that (``retry.predicate`` in particular).\n\n        ``polling`` (google.api_core.retry.Retry): (Optional) How often and\n        for how long to call the polling RPC periodically (i.e. what to do if\n        a polling rpc returned successfully but its returned result indicates\n        that the long running operation is not completed yet, so we need to\n        check it again at some point in future). This parameter does NOT define\n        how to retry each individual polling RPC in case of an error; use the\n        ``retry`` parameter for that. The ``polling.timeout`` of this parameter\n        is Polling Timeout as defined in as defined in\n        :class:`google.api_core.retry.Retry`.\n\n        For each of the arguments, there are also default values in place, which\n        will be used if a user does not specify their own. The default values\n        for the three parameters are not to be confused with the default values\n        for the corresponding arguments in this method (those serve as \"not set\"\n        markers for the resolution logic).\n\n        If ``timeout`` is provided (i.e.``timeout is not _DEFAULT VALUE``; note\n        the ``None`` value means \"infinite timeout\"), it will be used to control\n        the actual Polling Timeout. Otherwise, the ``polling.timeout`` value\n        will be used instead (see below for how the ``polling`` config itself\n        gets resolved). In other words, this parameter  effectively overrides\n        the ``polling.timeout`` value if specified. This is so to preserve\n        backward compatibility.\n\n        If ``retry`` is provided (i.e. ``retry is not None``) it will be used to\n        control retry behavior for the polling RPC and the ``retry.timeout``\n        will determine the Retry Timeout. If not provided, the\n        polling RPC will be called with whichever default retry config was\n        specified for the polling RPC at the moment of the construction of the\n        polling RPC's client. For example, if the polling RPC is\n        ``operations_client.get_operation()``, the ``retry`` parameter will be\n        controlling its retry behavior (not polling  behavior) and, if not\n        specified, that specific method (``operations_client.get_operation()``)\n        will be retried according to the default retry config provided during\n        creation of ``operations_client`` client instead. This argument exists\n        mainly for backward compatibility; users are very unlikely to ever need\n        to set this parameter explicitly.\n\n        If ``polling`` is provided (i.e. ``polling is not None``), it will be used\n        to control the overall polling behavior and ``polling.timeout`` will\n        control Polling Timeout unless it is overridden by ``timeout`` parameter\n        as described above. If not provided, the``polling`` parameter specified\n        during construction of this future (the ``polling`` argument in the\n        constructor) will be used instead. Note: since the ``timeout`` argument may\n        override ``polling.timeout`` value, this parameter should be viewed as\n        coupled with the ``timeout`` parameter as described above.\n\n        Args:\n            timeout (int): (Optional) How long (in seconds) to wait for the\n                operation to complete. If None, wait indefinitely.\n            retry (google.api_core.retry.Retry): (Optional) How to retry the\n                polling RPC. This defines ONLY how the polling RPC call is\n                retried (i.e. what to do if the RPC we used for polling returned\n                an error). It does  NOT define how the polling is done (i.e. how\n                frequently and for how long to call the polling RPC).\n            polling (google.api_core.retry.Retry): (Optional) How often and\n                for how long to call polling RPC periodically. This parameter\n                does NOT define how to retry each individual polling RPC call\n                (use the ``retry`` parameter for that).\n\n        Returns:\n            google.protobuf.Message: The Operation's result.\n\n        Raises:\n            google.api_core.GoogleAPICallError: If the operation errors or if\n                the timeout is reached before the operation completes.\n        \"\"\"\n\n        self._blocking_poll(timeout=timeout, retry=retry, polling=polling)\n\n        if self._exception is not None:\n            # pylint: disable=raising-bad-type\n            # Pylint doesn't recognize that this is valid in this case.\n            raise self._exception\n\n        return self._result\n\n    def exception(self, timeout=_DEFAULT_VALUE):\n        \"\"\"Get the exception from the operation, blocking if necessary.\n\n        See the documentation for the :meth:`result` method for details on how\n        this method operates, as both ``result`` and this method rely on the\n        exact same polling logic. The only difference is that this method does\n        not accept ``retry`` and ``polling`` arguments but relies on the default ones\n        instead.\n\n        Args:\n            timeout (int): How long to wait for the operation to complete.\n            If None, wait indefinitely.\n\n        Returns:\n            Optional[google.api_core.GoogleAPICallError]: The operation's\n                error.\n        \"\"\"\n        self._blocking_poll(timeout=timeout)\n        return self._exception\n\n    def add_done_callback(self, fn):\n        \"\"\"Add a callback to be executed when the operation is complete.\n\n        If the operation is not already complete, this will start a helper\n        thread to poll for the status of the operation in the background.\n\n        Args:\n            fn (Callable[Future]): The callback to execute when the operation\n                is complete.\n        \"\"\"\n        if self._result_set:\n            _helpers.safe_invoke_callback(fn, self)\n            return\n\n        self._done_callbacks.append(fn)\n\n        if self._polling_thread is None:\n            # The polling thread will exit on its own as soon as the operation\n            # is done.\n            self._polling_thread = _helpers.start_daemon_thread(\n                target=self._blocking_poll\n            )\n\n    def _invoke_callbacks(self, *args, **kwargs):\n        \"\"\"Invoke all done callbacks.\"\"\"\n        for callback in self._done_callbacks:\n            _helpers.safe_invoke_callback(callback, *args, **kwargs)\n\n    def set_result(self, result):\n        \"\"\"Set the Future's result.\"\"\"\n        self._result = result\n        self._result_set = True\n        self._invoke_callbacks(self)\n\n    def set_exception(self, exception):\n        \"\"\"Set the Future's exception.\"\"\"\n        self._exception = exception\n        self._result_set = True\n        self._invoke_callbacks(self)\n", "google/api_core/future/base.py": "# Copyright 2017, Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Abstract and helper bases for Future implementations.\"\"\"\n\nimport abc\n\n\nclass Future(object, metaclass=abc.ABCMeta):\n    # pylint: disable=missing-docstring\n    # We inherit the interfaces here from concurrent.futures.\n\n    \"\"\"Future interface.\n\n    This interface is based on :class:`concurrent.futures.Future`.\n    \"\"\"\n\n    @abc.abstractmethod\n    def cancel(self):\n        raise NotImplementedError()\n\n    @abc.abstractmethod\n    def cancelled(self):\n        raise NotImplementedError()\n\n    @abc.abstractmethod\n    def running(self):\n        raise NotImplementedError()\n\n    @abc.abstractmethod\n    def done(self):\n        raise NotImplementedError()\n\n    @abc.abstractmethod\n    def result(self, timeout=None):\n        raise NotImplementedError()\n\n    @abc.abstractmethod\n    def exception(self, timeout=None):\n        raise NotImplementedError()\n\n    @abc.abstractmethod\n    def add_done_callback(self, fn):\n        # pylint: disable=invalid-name\n        raise NotImplementedError()\n\n    @abc.abstractmethod\n    def set_result(self, result):\n        raise NotImplementedError()\n\n    @abc.abstractmethod\n    def set_exception(self, exception):\n        raise NotImplementedError()\n", "google/api_core/future/async_future.py": "# Copyright 2020, Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"AsyncIO implementation of the abstract base Future class.\"\"\"\n\nimport asyncio\n\nfrom google.api_core import exceptions\nfrom google.api_core import retry\nfrom google.api_core import retry_async\nfrom google.api_core.future import base\n\n\nclass _OperationNotComplete(Exception):\n    \"\"\"Private exception used for polling via retry.\"\"\"\n\n    pass\n\n\nRETRY_PREDICATE = retry.if_exception_type(\n    _OperationNotComplete,\n    exceptions.TooManyRequests,\n    exceptions.InternalServerError,\n    exceptions.BadGateway,\n)\nDEFAULT_RETRY = retry_async.AsyncRetry(predicate=RETRY_PREDICATE)\n\n\nclass AsyncFuture(base.Future):\n    \"\"\"A Future that polls peer service to self-update.\n\n    The :meth:`done` method should be implemented by subclasses. The polling\n    behavior will repeatedly call ``done`` until it returns True.\n\n    .. note::\n\n        Privacy here is intended to prevent the final class from\n        overexposing, not to prevent subclasses from accessing methods.\n\n    Args:\n        retry (google.api_core.retry.Retry): The retry configuration used\n            when polling. This can be used to control how often :meth:`done`\n            is polled. Regardless of the retry's ``deadline``, it will be\n            overridden by the ``timeout`` argument to :meth:`result`.\n    \"\"\"\n\n    def __init__(self, retry=DEFAULT_RETRY):\n        super().__init__()\n        self._retry = retry\n        self._future = asyncio.get_event_loop().create_future()\n        self._background_task = None\n\n    async def done(self, retry=DEFAULT_RETRY):\n        \"\"\"Checks to see if the operation is complete.\n\n        Args:\n            retry (google.api_core.retry.Retry): (Optional) How to retry the RPC.\n\n        Returns:\n            bool: True if the operation is complete, False otherwise.\n        \"\"\"\n        # pylint: disable=redundant-returns-doc, missing-raises-doc\n        raise NotImplementedError()\n\n    async def _done_or_raise(self):\n        \"\"\"Check if the future is done and raise if it's not.\"\"\"\n        result = await self.done()\n        if not result:\n            raise _OperationNotComplete()\n\n    async def running(self):\n        \"\"\"True if the operation is currently running.\"\"\"\n        result = await self.done()\n        return not result\n\n    async def _blocking_poll(self, timeout=None):\n        \"\"\"Poll and await for the Future to be resolved.\n\n        Args:\n            timeout (int):\n                How long (in seconds) to wait for the operation to complete.\n                If None, wait indefinitely.\n        \"\"\"\n        if self._future.done():\n            return\n\n        retry_ = self._retry.with_timeout(timeout)\n\n        try:\n            await retry_(self._done_or_raise)()\n        except exceptions.RetryError:\n            raise asyncio.TimeoutError(\n                \"Operation did not complete within the designated \" \"timeout.\"\n            )\n\n    async def result(self, timeout=None):\n        \"\"\"Get the result of the operation.\n\n        Args:\n            timeout (int):\n                How long (in seconds) to wait for the operation to complete.\n                If None, wait indefinitely.\n\n        Returns:\n            google.protobuf.Message: The Operation's result.\n\n        Raises:\n            google.api_core.GoogleAPICallError: If the operation errors or if\n                the timeout is reached before the operation completes.\n        \"\"\"\n        await self._blocking_poll(timeout=timeout)\n        return self._future.result()\n\n    async def exception(self, timeout=None):\n        \"\"\"Get the exception from the operation.\n\n        Args:\n            timeout (int): How long to wait for the operation to complete.\n                If None, wait indefinitely.\n\n        Returns:\n            Optional[google.api_core.GoogleAPICallError]: The operation's\n                error.\n        \"\"\"\n        await self._blocking_poll(timeout=timeout)\n        return self._future.exception()\n\n    def add_done_callback(self, fn):\n        \"\"\"Add a callback to be executed when the operation is complete.\n\n        If the operation is completed, the callback will be scheduled onto the\n        event loop. Otherwise, the callback will be stored and invoked when the\n        future is done.\n\n        Args:\n            fn (Callable[Future]): The callback to execute when the operation\n                is complete.\n        \"\"\"\n        if self._background_task is None:\n            self._background_task = asyncio.get_event_loop().create_task(\n                self._blocking_poll()\n            )\n        self._future.add_done_callback(fn)\n\n    def set_result(self, result):\n        \"\"\"Set the Future's result.\"\"\"\n        self._future.set_result(result)\n\n    def set_exception(self, exception):\n        \"\"\"Set the Future's exception.\"\"\"\n        self._future.set_exception(exception)\n", "google/api_core/future/__init__.py": "# Copyright 2017, Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Futures for dealing with asynchronous operations.\"\"\"\n\nfrom google.api_core.future.base import Future\n\n__all__ = [\"Future\"]\n", "google/api_core/future/_helpers.py": "# Copyright 2017, Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Private helpers for futures.\"\"\"\n\nimport logging\nimport threading\n\n\n_LOGGER = logging.getLogger(__name__)\n\n\ndef start_daemon_thread(*args, **kwargs):\n    \"\"\"Starts a thread and marks it as a daemon thread.\"\"\"\n    thread = threading.Thread(*args, **kwargs)\n    thread.daemon = True\n    thread.start()\n    return thread\n\n\ndef safe_invoke_callback(callback, *args, **kwargs):\n    \"\"\"Invoke a callback, swallowing and logging any exceptions.\"\"\"\n    # pylint: disable=bare-except\n    # We intentionally want to swallow all exceptions.\n    try:\n        return callback(*args, **kwargs)\n    except Exception:\n        _LOGGER.exception(\"Error while executing Future callback.\")\n"}