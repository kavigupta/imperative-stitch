{"noxfile.py": "# Copyright 2016 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import absolute_import\nimport os\nimport pathlib\nimport re\nimport shutil\nimport unittest\n\n# https://github.com/google/importlab/issues/25\nimport nox  # pytype: disable=import-error\n\n\nBLACK_VERSION = \"black==22.3.0\"\nBLACK_PATHS = [\"docs\", \"google\", \"tests\", \"noxfile.py\", \"setup.py\"]\n# Black and flake8 clash on the syntax for ignoring flake8's F401 in this file.\nBLACK_EXCLUDES = [\"--exclude\", \"^/google/api_core/operations_v1/__init__.py\"]\n\nPYTHON_VERSIONS = [\"3.7\", \"3.8\", \"3.9\", \"3.10\", \"3.11\", \"3.12\"]\n\nDEFAULT_PYTHON_VERSION = \"3.10\"\nCURRENT_DIRECTORY = pathlib.Path(__file__).parent.absolute()\n\n# 'docfx' is excluded since it only needs to run in 'docs-presubmit'\nnox.options.sessions = [\n    \"unit\",\n    \"unit_grpc_gcp\",\n    \"unit_wo_grpc\",\n    \"cover\",\n    \"pytype\",\n    \"mypy\",\n    \"lint\",\n    \"lint_setup_py\",\n    \"blacken\",\n    \"docs\",\n]\n\n\n@nox.session(python=DEFAULT_PYTHON_VERSION)\ndef lint(session):\n    \"\"\"Run linters.\n\n    Returns a failure if the linters find linting errors or sufficiently\n    serious code quality issues.\n    \"\"\"\n    session.install(\"flake8\", BLACK_VERSION)\n    session.install(\".\")\n    session.run(\n        \"black\",\n        \"--check\",\n        *BLACK_EXCLUDES,\n        *BLACK_PATHS,\n    )\n    session.run(\"flake8\", \"google\", \"tests\")\n\n\n@nox.session(python=DEFAULT_PYTHON_VERSION)\ndef blacken(session):\n    \"\"\"Run black.\n\n    Format code to uniform standard.\n    \"\"\"\n    session.install(BLACK_VERSION)\n    session.run(\"black\", *BLACK_EXCLUDES, *BLACK_PATHS)\n\n\ndef install_prerelease_dependencies(session, constraints_path):\n    with open(constraints_path, encoding=\"utf-8\") as constraints_file:\n        constraints_text = constraints_file.read()\n        # Ignore leading whitespace and comment lines.\n        constraints_deps = [\n            match.group(1)\n            for match in re.finditer(\n                r\"^\\s*(\\S+)(?===\\S+)\", constraints_text, flags=re.MULTILINE\n            )\n        ]\n        session.install(*constraints_deps)\n        prerel_deps = [\n            \"google-auth\",\n            \"googleapis-common-protos\",\n            \"grpcio\",\n            \"grpcio-status\",\n            \"proto-plus\",\n            \"protobuf\",\n        ]\n\n        for dep in prerel_deps:\n            session.install(\"--pre\", \"--no-deps\", \"--upgrade\", dep)\n\n        # Remaining dependencies\n        other_deps = [\n            \"requests\",\n        ]\n        session.install(*other_deps)\n\n\ndef default(session, install_grpc=True, prerelease=False):\n    \"\"\"Default unit test session.\n\n    This is intended to be run **without** an interpreter set, so\n    that the current ``python`` (on the ``PATH``) or the version of\n    Python corresponding to the ``nox`` binary the ``PATH`` can\n    run the tests.\n    \"\"\"\n    if prerelease and not install_grpc:\n        unittest.skip(\"The pre-release session cannot be run without grpc\")\n\n    session.install(\n        \"dataclasses\",\n        \"mock\",\n        \"pytest\",\n        \"pytest-cov\",\n        \"pytest-xdist\",\n    )\n\n    constraints_dir = str(CURRENT_DIRECTORY / \"testing\")\n\n    if prerelease:\n        install_prerelease_dependencies(\n            session, f\"{constraints_dir}/constraints-{PYTHON_VERSIONS[0]}.txt\"\n        )\n        # This *must* be the last install command to get the package from source.\n        session.install(\"-e\", \".\", \"--no-deps\")\n    else:\n        session.install(\n            \"-e\",\n            \".[grpc]\" if install_grpc else \".\",\n            \"-c\",\n            f\"{constraints_dir}/constraints-{session.python}.txt\",\n        )\n\n    # Print out package versions of dependencies\n    session.run(\n        \"python\", \"-c\", \"import google.protobuf; print(google.protobuf.__version__)\"\n    )\n    # Support for proto.version was added in v1.23.0\n    # https://github.com/googleapis/proto-plus-python/releases/tag/v1.23.0\n    session.run(\n        \"python\",\n        \"-c\",\n        \"\"\"import proto; hasattr(proto, \"version\") and print(proto.version.__version__)\"\"\",\n    )\n    if install_grpc:\n        session.run(\"python\", \"-c\", \"import grpc; print(grpc.__version__)\")\n    session.run(\"python\", \"-c\", \"import google.auth; print(google.auth.__version__)\")\n\n    pytest_args = [\n        \"python\",\n        \"-m\",\n        \"pytest\",\n        *(\n            # Helpful for running a single test or testfile.\n            session.posargs\n            or [\n                \"--quiet\",\n                \"--cov=google.api_core\",\n                \"--cov=tests.unit\",\n                \"--cov-append\",\n                \"--cov-config=.coveragerc\",\n                \"--cov-report=\",\n                \"--cov-fail-under=0\",\n                # Running individual tests with parallelism enabled is usually not helpful.\n                \"-n=auto\",\n                os.path.join(\"tests\", \"unit\"),\n            ]\n        ),\n    ]\n\n    session.install(\"asyncmock\", \"pytest-asyncio\")\n\n    # Having positional arguments means the user wants to run specific tests.\n    # Best not to add additional tests to that list.\n    if not session.posargs:\n        pytest_args.append(\"--cov=tests.asyncio\")\n        pytest_args.append(os.path.join(\"tests\", \"asyncio\"))\n\n    session.run(*pytest_args)\n\n\n@nox.session(python=PYTHON_VERSIONS)\ndef unit(session):\n    \"\"\"Run the unit test suite.\"\"\"\n    default(session)\n\n\n@nox.session(python=PYTHON_VERSIONS)\ndef unit_with_prerelease_deps(session):\n    \"\"\"Run the unit test suite.\"\"\"\n    default(session, prerelease=True)\n\n\n@nox.session(python=PYTHON_VERSIONS)\ndef unit_grpc_gcp(session):\n    \"\"\"\n    Run the unit test suite with grpcio-gcp installed.\n    `grpcio-gcp` doesn't support protobuf 4+.\n    Remove extra `grpcgcp` when protobuf 3.x is dropped.\n    https://github.com/googleapis/python-api-core/issues/594\n    \"\"\"\n    constraints_path = str(\n        CURRENT_DIRECTORY / \"testing\" / f\"constraints-{session.python}.txt\"\n    )\n    # Install grpcio-gcp\n    session.install(\"-e\", \".[grpcgcp]\", \"-c\", constraints_path)\n    # Install protobuf < 4.0.0\n    session.install(\"protobuf<4.0.0\")\n\n    default(session)\n\n\n@nox.session(python=PYTHON_VERSIONS)\ndef unit_wo_grpc(session):\n    \"\"\"Run the unit test suite w/o grpcio installed\"\"\"\n    default(session, install_grpc=False)\n\n\n@nox.session(python=DEFAULT_PYTHON_VERSION)\ndef lint_setup_py(session):\n    \"\"\"Verify that setup.py is valid (including RST check).\"\"\"\n\n    session.install(\"docutils\", \"Pygments\")\n    session.run(\"python\", \"setup.py\", \"check\", \"--restructuredtext\", \"--strict\")\n\n\n@nox.session(python=DEFAULT_PYTHON_VERSION)\ndef pytype(session):\n    \"\"\"Run type-checking.\"\"\"\n    session.install(\".[grpc]\", \"pytype\")\n    session.run(\"pytype\")\n\n\n@nox.session(python=DEFAULT_PYTHON_VERSION)\ndef mypy(session):\n    \"\"\"Run type-checking.\"\"\"\n    session.install(\".[grpc]\", \"mypy\")\n    session.install(\n        \"types-setuptools\",\n        \"types-requests\",\n        \"types-protobuf\",\n        \"types-mock\",\n        \"types-dataclasses\",\n    )\n    session.run(\"mypy\", \"google\", \"tests\")\n\n\n@nox.session(python=DEFAULT_PYTHON_VERSION)\ndef cover(session):\n    \"\"\"Run the final coverage report.\n\n    This outputs the coverage report aggregating coverage from the unit\n    test runs (not system test runs), and then erases coverage data.\n    \"\"\"\n    session.install(\"coverage\", \"pytest-cov\")\n    session.run(\"coverage\", \"report\", \"--show-missing\", \"--fail-under=100\")\n    session.run(\"coverage\", \"erase\")\n\n\n@nox.session(python=\"3.9\")\ndef docs(session):\n    \"\"\"Build the docs for this library.\"\"\"\n\n    session.install(\"-e\", \".[grpc]\")\n    session.install(\n        # We need to pin to specific versions of the `sphinxcontrib-*` packages\n        # which still support sphinx 4.x.\n        # See https://github.com/googleapis/sphinx-docfx-yaml/issues/344\n        # and https://github.com/googleapis/sphinx-docfx-yaml/issues/345.\n        \"sphinxcontrib-applehelp==1.0.4\",\n        \"sphinxcontrib-devhelp==1.0.2\",\n        \"sphinxcontrib-htmlhelp==2.0.1\",\n        \"sphinxcontrib-qthelp==1.0.3\",\n        \"sphinxcontrib-serializinghtml==1.1.5\",\n        \"sphinx==4.5.0\",\n        \"alabaster\",\n        \"recommonmark\",\n    )\n\n    shutil.rmtree(os.path.join(\"docs\", \"_build\"), ignore_errors=True)\n    session.run(\n        \"sphinx-build\",\n        \"-W\",  # warnings as errors\n        \"-T\",  # show full traceback on exception\n        \"-N\",  # no colors\n        \"-b\",\n        \"html\",\n        \"-d\",\n        os.path.join(\"docs\", \"_build\", \"doctrees\", \"\"),\n        os.path.join(\"docs\", \"\"),\n        os.path.join(\"docs\", \"_build\", \"html\", \"\"),\n    )\n\n\n@nox.session(python=\"3.10\")\ndef docfx(session):\n    \"\"\"Build the docfx yaml files for this library.\"\"\"\n\n    session.install(\"-e\", \".\")\n    session.install(\n        # We need to pin to specific versions of the `sphinxcontrib-*` packages\n        # which still support sphinx 4.x.\n        # See https://github.com/googleapis/sphinx-docfx-yaml/issues/344\n        # and https://github.com/googleapis/sphinx-docfx-yaml/issues/345.\n        \"sphinxcontrib-applehelp==1.0.4\",\n        \"sphinxcontrib-devhelp==1.0.2\",\n        \"sphinxcontrib-htmlhelp==2.0.1\",\n        \"sphinxcontrib-qthelp==1.0.3\",\n        \"sphinxcontrib-serializinghtml==1.1.5\",\n        \"gcp-sphinx-docfx-yaml\",\n        \"alabaster\",\n        \"recommonmark\",\n    )\n\n    shutil.rmtree(os.path.join(\"docs\", \"_build\"), ignore_errors=True)\n    session.run(\n        \"sphinx-build\",\n        \"-T\",  # show full traceback on exception\n        \"-N\",  # no colors\n        \"-D\",\n        (\n            \"extensions=sphinx.ext.autodoc,\"\n            \"sphinx.ext.autosummary,\"\n            \"docfx_yaml.extension,\"\n            \"sphinx.ext.intersphinx,\"\n            \"sphinx.ext.coverage,\"\n            \"sphinx.ext.napoleon,\"\n            \"sphinx.ext.todo,\"\n            \"sphinx.ext.viewcode,\"\n            \"recommonmark\"\n        ),\n        \"-b\",\n        \"html\",\n        \"-d\",\n        os.path.join(\"docs\", \"_build\", \"doctrees\", \"\"),\n        os.path.join(\"docs\", \"\"),\n        os.path.join(\"docs\", \"_build\", \"html\", \"\"),\n    )\n", "setup.py": "# Copyright 2018 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport io\nimport os\n\nimport setuptools\n\n\n# Package metadata.\n\nname = \"google-api-core\"\ndescription = \"Google API client core library\"\n\n# Should be one of:\n# 'Development Status :: 3 - Alpha'\n# 'Development Status :: 4 - Beta'\n# 'Development Status :: 5 - Production/Stable'\nrelease_status = \"Development Status :: 5 - Production/Stable\"\ndependencies = [\n    \"googleapis-common-protos >= 1.56.2, < 2.0.dev0\",\n    \"protobuf>=3.19.5,<6.0.0.dev0,!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5\",\n    \"proto-plus >= 1.22.3, <2.0.0dev\",\n    \"google-auth >= 2.14.1, < 3.0.dev0\",\n    \"requests >= 2.18.0, < 3.0.0.dev0\",\n]\nextras = {\n    \"grpc\": [\n        \"grpcio >= 1.33.2, < 2.0dev\",\n        \"grpcio >= 1.49.1, < 2.0dev; python_version>='3.11'\",\n        \"grpcio-status >= 1.33.2, < 2.0.dev0\",\n        \"grpcio-status >= 1.49.1, < 2.0.dev0; python_version>='3.11'\",\n    ],\n    \"grpcgcp\": \"grpcio-gcp >= 0.2.2, < 1.0.dev0\",\n    \"grpcio-gcp\": \"grpcio-gcp >= 0.2.2, < 1.0.dev0\",\n}\n\n\n# Setup boilerplate below this line.\n\npackage_root = os.path.abspath(os.path.dirname(__file__))\n\n\nversion = {}\nwith open(os.path.join(package_root, \"google/api_core/version.py\")) as fp:\n    exec(fp.read(), version)\nversion = version[\"__version__\"]\n\nreadme_filename = os.path.join(package_root, \"README.rst\")\nwith io.open(readme_filename, encoding=\"utf-8\") as readme_file:\n    readme = readme_file.read()\n\n# Only include packages under the 'google' namespace. Do not include tests,\n# benchmarks, etc.\npackages = [\n    package\n    for package in setuptools.find_namespace_packages()\n    if package.startswith(\"google\")\n]\n\nsetuptools.setup(\n    name=name,\n    version=version,\n    description=description,\n    long_description=readme,\n    author=\"Google LLC\",\n    author_email=\"googleapis-packages@google.com\",\n    license=\"Apache 2.0\",\n    url=\"https://github.com/googleapis/python-api-core\",\n    classifiers=[\n        release_status,\n        \"Intended Audience :: Developers\",\n        \"License :: OSI Approved :: Apache Software License\",\n        \"Programming Language :: Python\",\n        \"Programming Language :: Python :: 3\",\n        \"Programming Language :: Python :: 3.7\",\n        \"Programming Language :: Python :: 3.8\",\n        \"Programming Language :: Python :: 3.9\",\n        \"Programming Language :: Python :: 3.10\",\n        \"Programming Language :: Python :: 3.11\",\n        \"Programming Language :: Python :: 3.12\",\n        \"Operating System :: OS Independent\",\n        \"Topic :: Internet\",\n    ],\n    platforms=\"Posix; MacOS X; Windows\",\n    packages=packages,\n    install_requires=dependencies,\n    extras_require=extras,\n    python_requires=\">=3.7\",\n    include_package_data=True,\n    zip_safe=False,\n)\n", "owlbot.py": "# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"This script is used to synthesize generated parts of this library.\"\"\"\n\nimport synthtool as s\nfrom synthtool import gcp\nfrom synthtool.languages import python\n\ncommon = gcp.CommonTemplates()\n\n# ----------------------------------------------------------------------------\n# Add templated files\n# ----------------------------------------------------------------------------\nexcludes = [\n    \"noxfile.py\",  # pytype\n    \"setup.cfg\",  # pytype\n    \".flake8\",  # flake8-import-order, layout\n    \".coveragerc\",  # layout\n    \"CONTRIBUTING.rst\",  # no systests\n    \".github/workflows/unittest.yml\",  # exclude unittest gh action\n    \".github/workflows/lint.yml\",  # exclude lint gh action\n    \"README.rst\",\n]\ntemplated_files = common.py_library(microgenerator=True, cov_level=100)\ns.move(templated_files, excludes=excludes)\n\n# Add pytype support\ns.replace(\n    \".gitignore\",\n    \"\"\"\\\n.pytest_cache\n\"\"\",\n    \"\"\"\\\n.pytest_cache\n.pytype\n\"\"\",\n)\n\npython.configure_previous_major_version_branches()\n\ns.shell.run([\"nox\", \"-s\", \"blacken\"], hide_output=False)\n", "scripts/readme-gen/readme_gen.py": "#!/usr/bin/env python\n\n# Copyright 2023 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Generates READMEs using configuration defined in yaml.\"\"\"\n\nimport argparse\nimport io\nimport os\nimport subprocess\n\nimport jinja2\nimport yaml\n\n\njinja_env = jinja2.Environment(\n    trim_blocks=True,\n    loader=jinja2.FileSystemLoader(\n        os.path.abspath(os.path.join(os.path.dirname(__file__), \"templates\"))\n    ),\n    autoescape=True,\n)\n\nREADME_TMPL = jinja_env.get_template(\"README.tmpl.rst\")\n\n\ndef get_help(file):\n    return subprocess.check_output([\"python\", file, \"--help\"]).decode()\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"source\")\n    parser.add_argument(\"--destination\", default=\"README.rst\")\n\n    args = parser.parse_args()\n\n    source = os.path.abspath(args.source)\n    root = os.path.dirname(source)\n    destination = os.path.join(root, args.destination)\n\n    jinja_env.globals[\"get_help\"] = get_help\n\n    with io.open(source, \"r\") as f:\n        config = yaml.load(f)\n\n    # This allows get_help to execute in the right directory.\n    os.chdir(root)\n\n    output = README_TMPL.render(config)\n\n    with io.open(destination, \"w\") as f:\n        f.write(output)\n\n\nif __name__ == \"__main__\":\n    main()\n", "google/api_core/grpc_helpers.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Helpers for :mod:`grpc`.\"\"\"\nfrom typing import Generic, Iterator, Optional, TypeVar\n\nimport collections\nimport functools\nimport warnings\n\nimport grpc\n\nfrom google.api_core import exceptions\nimport google.auth\nimport google.auth.credentials\nimport google.auth.transport.grpc\nimport google.auth.transport.requests\nimport google.protobuf\n\nPROTOBUF_VERSION = google.protobuf.__version__\n\n# The grpcio-gcp package only has support for protobuf < 4\nif PROTOBUF_VERSION[0:2] == \"3.\":  # pragma: NO COVER\n    try:\n        import grpc_gcp\n\n        warnings.warn(\n            \"\"\"Support for grpcio-gcp is deprecated. This feature will be\n            removed from `google-api-core` after January 1, 2024. If you need to\n            continue to use this feature, please pin to a specific version of\n            `google-api-core`.\"\"\",\n            DeprecationWarning,\n        )\n        HAS_GRPC_GCP = True\n    except ImportError:\n        HAS_GRPC_GCP = False\nelse:\n    HAS_GRPC_GCP = False\n\n\n# The list of gRPC Callable interfaces that return iterators.\n_STREAM_WRAP_CLASSES = (grpc.UnaryStreamMultiCallable, grpc.StreamStreamMultiCallable)\n\n# denotes the proto response type for grpc calls\nP = TypeVar(\"P\")\n\n\ndef _patch_callable_name(callable_):\n    \"\"\"Fix-up gRPC callable attributes.\n\n    gRPC callable lack the ``__name__`` attribute which causes\n    :func:`functools.wraps` to error. This adds the attribute if needed.\n    \"\"\"\n    if not hasattr(callable_, \"__name__\"):\n        callable_.__name__ = callable_.__class__.__name__\n\n\ndef _wrap_unary_errors(callable_):\n    \"\"\"Map errors for Unary-Unary and Stream-Unary gRPC callables.\"\"\"\n    _patch_callable_name(callable_)\n\n    @functools.wraps(callable_)\n    def error_remapped_callable(*args, **kwargs):\n        try:\n            return callable_(*args, **kwargs)\n        except grpc.RpcError as exc:\n            raise exceptions.from_grpc_error(exc) from exc\n\n    return error_remapped_callable\n\n\nclass _StreamingResponseIterator(Generic[P], grpc.Call):\n    def __init__(self, wrapped, prefetch_first_result=True):\n        self._wrapped = wrapped\n\n        # This iterator is used in a retry context, and returned outside after init.\n        # gRPC will not throw an exception until the stream is consumed, so we need\n        # to retrieve the first result, in order to fail, in order to trigger a retry.\n        try:\n            if prefetch_first_result:\n                self._stored_first_result = next(self._wrapped)\n        except TypeError:\n            # It is possible the wrapped method isn't an iterable (a grpc.Call\n            # for instance). If this happens don't store the first result.\n            pass\n        except StopIteration:\n            # ignore stop iteration at this time. This should be handled outside of retry.\n            pass\n\n    def __iter__(self) -> Iterator[P]:\n        \"\"\"This iterator is also an iterable that returns itself.\"\"\"\n        return self\n\n    def __next__(self) -> P:\n        \"\"\"Get the next response from the stream.\n\n        Returns:\n            protobuf.Message: A single response from the stream.\n        \"\"\"\n        try:\n            if hasattr(self, \"_stored_first_result\"):\n                result = self._stored_first_result\n                del self._stored_first_result\n                return result\n            return next(self._wrapped)\n        except grpc.RpcError as exc:\n            # If the stream has already returned data, we cannot recover here.\n            raise exceptions.from_grpc_error(exc) from exc\n\n    # grpc.Call & grpc.RpcContext interface\n\n    def add_callback(self, callback):\n        return self._wrapped.add_callback(callback)\n\n    def cancel(self):\n        return self._wrapped.cancel()\n\n    def code(self):\n        return self._wrapped.code()\n\n    def details(self):\n        return self._wrapped.details()\n\n    def initial_metadata(self):\n        return self._wrapped.initial_metadata()\n\n    def is_active(self):\n        return self._wrapped.is_active()\n\n    def time_remaining(self):\n        return self._wrapped.time_remaining()\n\n    def trailing_metadata(self):\n        return self._wrapped.trailing_metadata()\n\n\n# public type alias denoting the return type of streaming gapic calls\nGrpcStream = _StreamingResponseIterator[P]\n\n\ndef _wrap_stream_errors(callable_):\n    \"\"\"Wrap errors for Unary-Stream and Stream-Stream gRPC callables.\n\n    The callables that return iterators require a bit more logic to re-map\n    errors when iterating. This wraps both the initial invocation and the\n    iterator of the return value to re-map errors.\n    \"\"\"\n    _patch_callable_name(callable_)\n\n    @functools.wraps(callable_)\n    def error_remapped_callable(*args, **kwargs):\n        try:\n            result = callable_(*args, **kwargs)\n            # Auto-fetching the first result causes PubSub client's streaming pull\n            # to hang when re-opening the stream, thus we need examine the hacky\n            # hidden flag to see if pre-fetching is disabled.\n            # https://github.com/googleapis/python-pubsub/issues/93#issuecomment-630762257\n            prefetch_first = getattr(callable_, \"_prefetch_first_result_\", True)\n            return _StreamingResponseIterator(\n                result, prefetch_first_result=prefetch_first\n            )\n        except grpc.RpcError as exc:\n            raise exceptions.from_grpc_error(exc) from exc\n\n    return error_remapped_callable\n\n\ndef wrap_errors(callable_):\n    \"\"\"Wrap a gRPC callable and map :class:`grpc.RpcErrors` to friendly error\n    classes.\n\n    Errors raised by the gRPC callable are mapped to the appropriate\n    :class:`google.api_core.exceptions.GoogleAPICallError` subclasses.\n    The original `grpc.RpcError` (which is usually also a `grpc.Call`) is\n    available from the ``response`` property on the mapped exception. This\n    is useful for extracting metadata from the original error.\n\n    Args:\n        callable_ (Callable): A gRPC callable.\n\n    Returns:\n        Callable: The wrapped gRPC callable.\n    \"\"\"\n    if isinstance(callable_, _STREAM_WRAP_CLASSES):\n        return _wrap_stream_errors(callable_)\n    else:\n        return _wrap_unary_errors(callable_)\n\n\ndef _create_composite_credentials(\n    credentials=None,\n    credentials_file=None,\n    default_scopes=None,\n    scopes=None,\n    ssl_credentials=None,\n    quota_project_id=None,\n    default_host=None,\n):\n    \"\"\"Create the composite credentials for secure channels.\n\n    Args:\n        credentials (google.auth.credentials.Credentials): The credentials. If\n            not specified, then this function will attempt to ascertain the\n            credentials from the environment using :func:`google.auth.default`.\n        credentials_file (str): A file with credentials that can be loaded with\n            :func:`google.auth.load_credentials_from_file`. This argument is\n            mutually exclusive with credentials.\n        default_scopes (Sequence[str]): A optional list of scopes needed for this\n            service. These are only used when credentials are not specified and\n            are passed to :func:`google.auth.default`.\n        scopes (Sequence[str]): A optional list of scopes needed for this\n            service. These are only used when credentials are not specified and\n            are passed to :func:`google.auth.default`.\n        ssl_credentials (grpc.ChannelCredentials): Optional SSL channel\n            credentials. This can be used to specify different certificates.\n        quota_project_id (str): An optional project to use for billing and quota.\n        default_host (str): The default endpoint. e.g., \"pubsub.googleapis.com\".\n\n    Returns:\n        grpc.ChannelCredentials: The composed channel credentials object.\n\n    Raises:\n        google.api_core.DuplicateCredentialArgs: If both a credentials object and credentials_file are passed.\n    \"\"\"\n    if credentials and credentials_file:\n        raise exceptions.DuplicateCredentialArgs(\n            \"'credentials' and 'credentials_file' are mutually exclusive.\"\n        )\n\n    if credentials_file:\n        credentials, _ = google.auth.load_credentials_from_file(\n            credentials_file, scopes=scopes, default_scopes=default_scopes\n        )\n    elif credentials:\n        credentials = google.auth.credentials.with_scopes_if_required(\n            credentials, scopes=scopes, default_scopes=default_scopes\n        )\n    else:\n        credentials, _ = google.auth.default(\n            scopes=scopes, default_scopes=default_scopes\n        )\n\n    if quota_project_id and isinstance(\n        credentials, google.auth.credentials.CredentialsWithQuotaProject\n    ):\n        credentials = credentials.with_quota_project(quota_project_id)\n\n    request = google.auth.transport.requests.Request()\n\n    # Create the metadata plugin for inserting the authorization header.\n    metadata_plugin = google.auth.transport.grpc.AuthMetadataPlugin(\n        credentials,\n        request,\n        default_host=default_host,\n    )\n\n    # Create a set of grpc.CallCredentials using the metadata plugin.\n    google_auth_credentials = grpc.metadata_call_credentials(metadata_plugin)\n\n    # if `ssl_credentials` is set, use `grpc.composite_channel_credentials` instead of\n    # `grpc.compute_engine_channel_credentials` as the former supports passing\n    # `ssl_credentials` via `channel_credentials` which is needed for mTLS.\n    if ssl_credentials:\n        # Combine the ssl credentials and the authorization credentials.\n        # See https://grpc.github.io/grpc/python/grpc.html#grpc.composite_channel_credentials\n        return grpc.composite_channel_credentials(\n            ssl_credentials, google_auth_credentials\n        )\n    else:\n        # Use grpc.compute_engine_channel_credentials in order to support Direct Path.\n        # See https://grpc.github.io/grpc/python/grpc.html#grpc.compute_engine_channel_credentials\n        # TODO(https://github.com/googleapis/python-api-core/issues/598):\n        # Although `grpc.compute_engine_channel_credentials` returns channel credentials\n        # outside of a Google Compute Engine environment (GCE), we should determine if\n        # there is a way to reliably detect a GCE environment so that\n        # `grpc.compute_engine_channel_credentials` is not called outside of GCE.\n        return grpc.compute_engine_channel_credentials(google_auth_credentials)\n\n\ndef create_channel(\n    target,\n    credentials=None,\n    scopes=None,\n    ssl_credentials=None,\n    credentials_file=None,\n    quota_project_id=None,\n    default_scopes=None,\n    default_host=None,\n    compression=None,\n    attempt_direct_path: Optional[bool] = False,\n    **kwargs,\n):\n    \"\"\"Create a secure channel with credentials.\n\n    Args:\n        target (str): The target service address in the format 'hostname:port'.\n        credentials (google.auth.credentials.Credentials): The credentials. If\n            not specified, then this function will attempt to ascertain the\n            credentials from the environment using :func:`google.auth.default`.\n        scopes (Sequence[str]): A optional list of scopes needed for this\n            service. These are only used when credentials are not specified and\n            are passed to :func:`google.auth.default`.\n        ssl_credentials (grpc.ChannelCredentials): Optional SSL channel\n            credentials. This can be used to specify different certificates.\n        credentials_file (str): A file with credentials that can be loaded with\n            :func:`google.auth.load_credentials_from_file`. This argument is\n            mutually exclusive with credentials.\n        quota_project_id (str): An optional project to use for billing and quota.\n        default_scopes (Sequence[str]): Default scopes passed by a Google client\n            library. Use 'scopes' for user-defined scopes.\n        default_host (str): The default endpoint. e.g., \"pubsub.googleapis.com\".\n        compression (grpc.Compression): An optional value indicating the\n            compression method to be used over the lifetime of the channel.\n        attempt_direct_path (Optional[bool]): If set, Direct Path will be attempted\n            when the request is made. Direct Path is only available within a Google\n            Compute Engine (GCE) environment and provides a proxyless connection\n            which increases the available throughput, reduces latency, and increases\n            reliability. Note:\n\n            - This argument should only be set in a GCE environment and for Services\n              that are known to support Direct Path.\n            - If this argument is set outside of GCE, then this request will fail\n              unless the back-end service happens to have configured fall-back to DNS.\n            - If the request causes a `ServiceUnavailable` response, it is recommended\n              that the client repeat the request with `attempt_direct_path` set to\n              `False` as the Service may not support Direct Path.\n            - Using `ssl_credentials` with `attempt_direct_path` set to `True` will\n              result in `ValueError` as this combination  is not yet supported.\n\n        kwargs: Additional key-word args passed to\n            :func:`grpc_gcp.secure_channel` or :func:`grpc.secure_channel`.\n            Note: `grpc_gcp` is only supported in environments with protobuf < 4.0.0.\n\n    Returns:\n        grpc.Channel: The created channel.\n\n    Raises:\n        google.api_core.DuplicateCredentialArgs: If both a credentials object and credentials_file are passed.\n        ValueError: If `ssl_credentials` is set and `attempt_direct_path` is set to `True`.\n    \"\"\"\n\n    # If `ssl_credentials` is set and `attempt_direct_path` is set to `True`,\n    # raise ValueError as this is not yet supported.\n    # See https://github.com/googleapis/python-api-core/issues/590\n    if ssl_credentials and attempt_direct_path:\n        raise ValueError(\"Using ssl_credentials with Direct Path is not supported\")\n\n    composite_credentials = _create_composite_credentials(\n        credentials=credentials,\n        credentials_file=credentials_file,\n        default_scopes=default_scopes,\n        scopes=scopes,\n        ssl_credentials=ssl_credentials,\n        quota_project_id=quota_project_id,\n        default_host=default_host,\n    )\n\n    # Note that grpcio-gcp is deprecated\n    if HAS_GRPC_GCP:  # pragma: NO COVER\n        if compression is not None and compression != grpc.Compression.NoCompression:\n            warnings.warn(\n                \"The `compression` argument is ignored for grpc_gcp.secure_channel creation.\",\n                DeprecationWarning,\n            )\n        if attempt_direct_path:\n            warnings.warn(\n                \"\"\"The `attempt_direct_path` argument is ignored for grpc_gcp.secure_channel creation.\"\"\",\n                DeprecationWarning,\n            )\n        return grpc_gcp.secure_channel(target, composite_credentials, **kwargs)\n\n    if attempt_direct_path:\n        target = _modify_target_for_direct_path(target)\n\n    return grpc.secure_channel(\n        target, composite_credentials, compression=compression, **kwargs\n    )\n\n\ndef _modify_target_for_direct_path(target: str) -> str:\n    \"\"\"\n    Given a target, return a modified version which is compatible with Direct Path.\n\n    Args:\n        target (str): The target service address in the format 'hostname[:port]' or\n            'dns://hostname[:port]'.\n\n    Returns:\n        target (str): The target service address which is converted into a format compatible with Direct Path.\n            If the target contains `dns:///` or does not contain `:///`, the target will be converted in\n            a format compatible with Direct Path; otherwise the original target will be returned as the\n            original target may already denote Direct Path.\n    \"\"\"\n\n    # A DNS prefix may be included with the target to indicate the endpoint is living in the Internet,\n    # outside of Google Cloud Platform.\n    dns_prefix = \"dns:///\"\n    # Remove \"dns:///\" if `attempt_direct_path` is set to True as\n    # the Direct Path prefix `google-c2p:///` will be used instead.\n    target = target.replace(dns_prefix, \"\")\n\n    direct_path_separator = \":///\"\n    if direct_path_separator not in target:\n        target_without_port = target.split(\":\")[0]\n        # Modify the target to use Direct Path by adding the `google-c2p:///` prefix\n        target = f\"google-c2p{direct_path_separator}{target_without_port}\"\n    return target\n\n\n_MethodCall = collections.namedtuple(\n    \"_MethodCall\", (\"request\", \"timeout\", \"metadata\", \"credentials\", \"compression\")\n)\n\n_ChannelRequest = collections.namedtuple(\"_ChannelRequest\", (\"method\", \"request\"))\n\n\nclass _CallableStub(object):\n    \"\"\"Stub for the grpc.*MultiCallable interfaces.\"\"\"\n\n    def __init__(self, method, channel):\n        self._method = method\n        self._channel = channel\n        self.response = None\n        \"\"\"Union[protobuf.Message, Callable[protobuf.Message], exception]:\n        The response to give when invoking this callable. If this is a\n        callable, it will be invoked with the request protobuf. If it's an\n        exception, the exception will be raised when this is invoked.\n        \"\"\"\n        self.responses = None\n        \"\"\"Iterator[\n            Union[protobuf.Message, Callable[protobuf.Message], exception]]:\n        An iterator of responses. If specified, self.response will be populated\n        on each invocation by calling ``next(self.responses)``.\"\"\"\n        self.requests = []\n        \"\"\"List[protobuf.Message]: All requests sent to this callable.\"\"\"\n        self.calls = []\n        \"\"\"List[Tuple]: All invocations of this callable. Each tuple is the\n        request, timeout, metadata, compression, and credentials.\"\"\"\n\n    def __call__(\n        self, request, timeout=None, metadata=None, credentials=None, compression=None\n    ):\n        self._channel.requests.append(_ChannelRequest(self._method, request))\n        self.calls.append(\n            _MethodCall(request, timeout, metadata, credentials, compression)\n        )\n        self.requests.append(request)\n\n        response = self.response\n        if self.responses is not None:\n            if response is None:\n                response = next(self.responses)\n            else:\n                raise ValueError(\n                    \"{method}.response and {method}.responses are mutually \"\n                    \"exclusive.\".format(method=self._method)\n                )\n\n        if callable(response):\n            return response(request)\n\n        if isinstance(response, Exception):\n            raise response\n\n        if response is not None:\n            return response\n\n        raise ValueError('Method stub for \"{}\" has no response.'.format(self._method))\n\n\ndef _simplify_method_name(method):\n    \"\"\"Simplifies a gRPC method name.\n\n    When gRPC invokes the channel to create a callable, it gives a full\n    method name like \"/google.pubsub.v1.Publisher/CreateTopic\". This\n    returns just the name of the method, in this case \"CreateTopic\".\n\n    Args:\n        method (str): The name of the method.\n\n    Returns:\n        str: The simplified name of the method.\n    \"\"\"\n    return method.rsplit(\"/\", 1).pop()\n\n\nclass ChannelStub(grpc.Channel):\n    \"\"\"A testing stub for the grpc.Channel interface.\n\n    This can be used to test any client that eventually uses a gRPC channel\n    to communicate. By passing in a channel stub, you can configure which\n    responses are returned and track which requests are made.\n\n    For example:\n\n    .. code-block:: python\n\n        channel_stub = grpc_helpers.ChannelStub()\n        client = FooClient(channel=channel_stub)\n\n        channel_stub.GetFoo.response = foo_pb2.Foo(name='bar')\n\n        foo = client.get_foo(labels=['baz'])\n\n        assert foo.name == 'bar'\n        assert channel_stub.GetFoo.requests[0].labels = ['baz']\n\n    Each method on the stub can be accessed and configured on the channel.\n    Here's some examples of various configurations:\n\n    .. code-block:: python\n\n        # Return a basic response:\n\n        channel_stub.GetFoo.response = foo_pb2.Foo(name='bar')\n        assert client.get_foo().name == 'bar'\n\n        # Raise an exception:\n        channel_stub.GetFoo.response = NotFound('...')\n\n        with pytest.raises(NotFound):\n            client.get_foo()\n\n        # Use a sequence of responses:\n        channel_stub.GetFoo.responses = iter([\n            foo_pb2.Foo(name='bar'),\n            foo_pb2.Foo(name='baz'),\n        ])\n\n        assert client.get_foo().name == 'bar'\n        assert client.get_foo().name == 'baz'\n\n        # Use a callable\n\n        def on_get_foo(request):\n            return foo_pb2.Foo(name='bar' + request.id)\n\n        channel_stub.GetFoo.response = on_get_foo\n\n        assert client.get_foo(id='123').name == 'bar123'\n    \"\"\"\n\n    def __init__(self, responses=[]):\n        self.requests = []\n        \"\"\"Sequence[Tuple[str, protobuf.Message]]: A list of all requests made\n        on this channel in order. The tuple is of method name, request\n        message.\"\"\"\n        self._method_stubs = {}\n\n    def _stub_for_method(self, method):\n        method = _simplify_method_name(method)\n        self._method_stubs[method] = _CallableStub(method, self)\n        return self._method_stubs[method]\n\n    def __getattr__(self, key):\n        try:\n            return self._method_stubs[key]\n        except KeyError:\n            raise AttributeError\n\n    def unary_unary(\n        self,\n        method,\n        request_serializer=None,\n        response_deserializer=None,\n        _registered_method=False,\n    ):\n        \"\"\"grpc.Channel.unary_unary implementation.\"\"\"\n        return self._stub_for_method(method)\n\n    def unary_stream(\n        self,\n        method,\n        request_serializer=None,\n        response_deserializer=None,\n        _registered_method=False,\n    ):\n        \"\"\"grpc.Channel.unary_stream implementation.\"\"\"\n        return self._stub_for_method(method)\n\n    def stream_unary(\n        self,\n        method,\n        request_serializer=None,\n        response_deserializer=None,\n        _registered_method=False,\n    ):\n        \"\"\"grpc.Channel.stream_unary implementation.\"\"\"\n        return self._stub_for_method(method)\n\n    def stream_stream(\n        self,\n        method,\n        request_serializer=None,\n        response_deserializer=None,\n        _registered_method=False,\n    ):\n        \"\"\"grpc.Channel.stream_stream implementation.\"\"\"\n        return self._stub_for_method(method)\n\n    def subscribe(self, callback, try_to_connect=False):\n        \"\"\"grpc.Channel.subscribe implementation.\"\"\"\n        pass\n\n    def unsubscribe(self, callback):\n        \"\"\"grpc.Channel.unsubscribe implementation.\"\"\"\n        pass\n\n    def close(self):\n        \"\"\"grpc.Channel.close implementation.\"\"\"\n        pass\n", "google/api_core/iam.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\"Non-API-specific IAM policy definitions\n\nFor allowed roles / permissions, see:\nhttps://cloud.google.com/iam/docs/understanding-roles\n\nExample usage:\n\n.. code-block:: python\n\n   # ``get_iam_policy`` returns a :class:'~google.api_core.iam.Policy`.\n   policy = resource.get_iam_policy(requested_policy_version=3)\n\n   phred = \"user:phred@example.com\"\n   admin_group = \"group:admins@groups.example.com\"\n   account = \"serviceAccount:account-1234@accounts.example.com\"\n\n   policy.version = 3\n   policy.bindings = [\n       {\n           \"role\": \"roles/owner\",\n           \"members\": {phred, admin_group, account}\n       },\n       {\n           \"role\": \"roles/editor\",\n           \"members\": {\"allAuthenticatedUsers\"}\n       },\n       {\n           \"role\": \"roles/viewer\",\n           \"members\": {\"allUsers\"}\n           \"condition\": {\n               \"title\": \"request_time\",\n               \"description\": \"Requests made before 2021-01-01T00:00:00Z\",\n               \"expression\": \"request.time < timestamp(\\\"2021-01-01T00:00:00Z\\\")\"\n           }\n       }\n   ]\n\n   resource.set_iam_policy(policy)\n\"\"\"\n\nimport collections\nimport collections.abc\nimport operator\nimport warnings\n\n# Generic IAM roles\n\nOWNER_ROLE = \"roles/owner\"\n\"\"\"Generic role implying all rights to an object.\"\"\"\n\nEDITOR_ROLE = \"roles/editor\"\n\"\"\"Generic role implying rights to modify an object.\"\"\"\n\nVIEWER_ROLE = \"roles/viewer\"\n\"\"\"Generic role implying rights to access an object.\"\"\"\n\n_ASSIGNMENT_DEPRECATED_MSG = \"\"\"\\\nAssigning to '{}' is deprecated. Use the `policy.bindings` property to modify bindings instead.\"\"\"\n\n_DICT_ACCESS_MSG = \"\"\"\\\nDict access is not supported on policies with version > 1 or with conditional bindings.\"\"\"\n\n\nclass InvalidOperationException(Exception):\n    \"\"\"Raised when trying to use Policy class as a dict.\"\"\"\n\n    pass\n\n\nclass Policy(collections.abc.MutableMapping):\n    \"\"\"IAM Policy\n\n    Args:\n        etag (Optional[str]): ETag used to identify a unique of the policy\n        version (Optional[int]): The syntax schema version of the policy.\n\n    Note:\n        Using conditions in bindings requires the policy's version to be set\n        to `3` or greater, depending on the versions that are currently supported.\n\n        Accessing the policy using dict operations will raise InvalidOperationException\n        when the policy's version is set to 3.\n\n        Use the policy.bindings getter/setter to retrieve and modify the policy's bindings.\n\n    See:\n        IAM Policy https://cloud.google.com/iam/reference/rest/v1/Policy\n        Policy versions https://cloud.google.com/iam/docs/policies#versions\n        Conditions overview https://cloud.google.com/iam/docs/conditions-overview.\n    \"\"\"\n\n    _OWNER_ROLES = (OWNER_ROLE,)\n    \"\"\"Roles mapped onto our ``owners`` attribute.\"\"\"\n\n    _EDITOR_ROLES = (EDITOR_ROLE,)\n    \"\"\"Roles mapped onto our ``editors`` attribute.\"\"\"\n\n    _VIEWER_ROLES = (VIEWER_ROLE,)\n    \"\"\"Roles mapped onto our ``viewers`` attribute.\"\"\"\n\n    def __init__(self, etag=None, version=None):\n        self.etag = etag\n        self.version = version\n        self._bindings = []\n\n    def __iter__(self):\n        self.__check_version__()\n        # Exclude bindings with no members\n        return (binding[\"role\"] for binding in self._bindings if binding[\"members\"])\n\n    def __len__(self):\n        self.__check_version__()\n        # Exclude bindings with no members\n        return len(list(self.__iter__()))\n\n    def __getitem__(self, key):\n        self.__check_version__()\n        for b in self._bindings:\n            if b[\"role\"] == key:\n                return b[\"members\"]\n        # If the binding does not yet exist, create one\n        # NOTE: This will create bindings with no members\n        # which are ignored by __iter__ and __len__\n        new_binding = {\"role\": key, \"members\": set()}\n        self._bindings.append(new_binding)\n        return new_binding[\"members\"]\n\n    def __setitem__(self, key, value):\n        self.__check_version__()\n        value = set(value)\n        for binding in self._bindings:\n            if binding[\"role\"] == key:\n                binding[\"members\"] = value\n                return\n        self._bindings.append({\"role\": key, \"members\": value})\n\n    def __delitem__(self, key):\n        self.__check_version__()\n        for b in self._bindings:\n            if b[\"role\"] == key:\n                self._bindings.remove(b)\n                return\n        raise KeyError(key)\n\n    def __check_version__(self):\n        \"\"\"Raise InvalidOperationException if version is greater than 1 or policy contains conditions.\"\"\"\n        raise_version = self.version is not None and self.version > 1\n\n        if raise_version or self._contains_conditions():\n            raise InvalidOperationException(_DICT_ACCESS_MSG)\n\n    def _contains_conditions(self):\n        for b in self._bindings:\n            if b.get(\"condition\") is not None:\n                return True\n        return False\n\n    @property\n    def bindings(self):\n        \"\"\"The policy's list of bindings.\n\n        A binding is specified by a dictionary with keys:\n\n        * role (str): Role that is assigned to `members`.\n\n        * members (:obj:`set` of str): Specifies the identities associated to this binding.\n\n        * condition (:obj:`dict` of str:str): Specifies a condition under which this binding will apply.\n\n          * title (str): Title for the condition.\n\n          * description (:obj:str, optional): Description of the condition.\n\n          * expression: A CEL expression.\n\n        Type:\n           :obj:`list` of :obj:`dict`\n\n        See:\n           Policy versions https://cloud.google.com/iam/docs/policies#versions\n           Conditions overview https://cloud.google.com/iam/docs/conditions-overview.\n\n        Example:\n\n        .. code-block:: python\n\n           USER = \"user:phred@example.com\"\n           ADMIN_GROUP = \"group:admins@groups.example.com\"\n           SERVICE_ACCOUNT = \"serviceAccount:account-1234@accounts.example.com\"\n           CONDITION = {\n               \"title\": \"request_time\",\n               \"description\": \"Requests made before 2021-01-01T00:00:00Z\", # Optional\n               \"expression\": \"request.time < timestamp(\\\"2021-01-01T00:00:00Z\\\")\"\n           }\n\n           # Set policy's version to 3 before setting bindings containing conditions.\n           policy.version = 3\n\n           policy.bindings = [\n               {\n                   \"role\": \"roles/viewer\",\n                   \"members\": {USER, ADMIN_GROUP, SERVICE_ACCOUNT},\n                   \"condition\": CONDITION\n               },\n               ...\n           ]\n        \"\"\"\n        return self._bindings\n\n    @bindings.setter\n    def bindings(self, bindings):\n        self._bindings = bindings\n\n    @property\n    def owners(self):\n        \"\"\"Legacy access to owner role.\n\n        Raise InvalidOperationException if version is greater than 1 or policy contains conditions.\n\n        DEPRECATED:  use `policy.bindings` to access bindings instead.\n        \"\"\"\n        result = set()\n        for role in self._OWNER_ROLES:\n            for member in self.get(role, ()):\n                result.add(member)\n        return frozenset(result)\n\n    @owners.setter\n    def owners(self, value):\n        \"\"\"Update owners.\n\n        Raise InvalidOperationException if version is greater than 1 or policy contains conditions.\n\n        DEPRECATED:  use `policy.bindings` to access bindings instead.\n        \"\"\"\n        warnings.warn(\n            _ASSIGNMENT_DEPRECATED_MSG.format(\"owners\", OWNER_ROLE), DeprecationWarning\n        )\n        self[OWNER_ROLE] = value\n\n    @property\n    def editors(self):\n        \"\"\"Legacy access to editor role.\n\n        Raise InvalidOperationException if version is greater than 1 or policy contains conditions.\n\n        DEPRECATED:  use `policy.bindings` to access bindings instead.\n        \"\"\"\n        result = set()\n        for role in self._EDITOR_ROLES:\n            for member in self.get(role, ()):\n                result.add(member)\n        return frozenset(result)\n\n    @editors.setter\n    def editors(self, value):\n        \"\"\"Update editors.\n\n        Raise InvalidOperationException if version is greater than 1 or policy contains conditions.\n\n        DEPRECATED:  use `policy.bindings` to modify bindings instead.\n        \"\"\"\n        warnings.warn(\n            _ASSIGNMENT_DEPRECATED_MSG.format(\"editors\", EDITOR_ROLE),\n            DeprecationWarning,\n        )\n        self[EDITOR_ROLE] = value\n\n    @property\n    def viewers(self):\n        \"\"\"Legacy access to viewer role.\n\n        Raise InvalidOperationException if version is greater than 1 or policy contains conditions.\n\n        DEPRECATED:  use `policy.bindings` to modify bindings instead.\n        \"\"\"\n        result = set()\n        for role in self._VIEWER_ROLES:\n            for member in self.get(role, ()):\n                result.add(member)\n        return frozenset(result)\n\n    @viewers.setter\n    def viewers(self, value):\n        \"\"\"Update viewers.\n\n        Raise InvalidOperationException if version is greater than 1 or policy contains conditions.\n\n        DEPRECATED:  use `policy.bindings` to modify bindings instead.\n        \"\"\"\n        warnings.warn(\n            _ASSIGNMENT_DEPRECATED_MSG.format(\"viewers\", VIEWER_ROLE),\n            DeprecationWarning,\n        )\n        self[VIEWER_ROLE] = value\n\n    @staticmethod\n    def user(email):\n        \"\"\"Factory method for a user member.\n\n        Args:\n            email (str): E-mail for this particular user.\n\n        Returns:\n            str: A member string corresponding to the given user.\n        \"\"\"\n        return \"user:%s\" % (email,)\n\n    @staticmethod\n    def service_account(email):\n        \"\"\"Factory method for a service account member.\n\n        Args:\n            email (str): E-mail for this particular service account.\n\n        Returns:\n            str: A member string corresponding to the given service account.\n\n        \"\"\"\n        return \"serviceAccount:%s\" % (email,)\n\n    @staticmethod\n    def group(email):\n        \"\"\"Factory method for a group member.\n\n        Args:\n            email (str): An id or e-mail for this particular group.\n\n        Returns:\n            str: A member string corresponding to the given group.\n        \"\"\"\n        return \"group:%s\" % (email,)\n\n    @staticmethod\n    def domain(domain):\n        \"\"\"Factory method for a domain member.\n\n        Args:\n            domain (str): The domain for this member.\n\n        Returns:\n            str: A member string corresponding to the given domain.\n        \"\"\"\n        return \"domain:%s\" % (domain,)\n\n    @staticmethod\n    def all_users():\n        \"\"\"Factory method for a member representing all users.\n\n        Returns:\n            str: A member string representing all users.\n        \"\"\"\n        return \"allUsers\"\n\n    @staticmethod\n    def authenticated_users():\n        \"\"\"Factory method for a member representing all authenticated users.\n\n        Returns:\n            str: A member string representing all authenticated users.\n        \"\"\"\n        return \"allAuthenticatedUsers\"\n\n    @classmethod\n    def from_api_repr(cls, resource):\n        \"\"\"Factory: create a policy from a JSON resource.\n\n        Args:\n            resource (dict): policy resource returned by ``getIamPolicy`` API.\n\n        Returns:\n            :class:`Policy`: the parsed policy\n        \"\"\"\n        version = resource.get(\"version\")\n        etag = resource.get(\"etag\")\n        policy = cls(etag, version)\n        policy.bindings = resource.get(\"bindings\", [])\n\n        for binding in policy.bindings:\n            binding[\"members\"] = set(binding.get(\"members\", ()))\n\n        return policy\n\n    def to_api_repr(self):\n        \"\"\"Render a JSON policy resource.\n\n        Returns:\n            dict: a resource to be passed to the ``setIamPolicy`` API.\n        \"\"\"\n        resource = {}\n\n        if self.etag is not None:\n            resource[\"etag\"] = self.etag\n\n        if self.version is not None:\n            resource[\"version\"] = self.version\n\n        if self._bindings and len(self._bindings) > 0:\n            bindings = []\n            for binding in self._bindings:\n                members = binding.get(\"members\")\n                if members:\n                    new_binding = {\"role\": binding[\"role\"], \"members\": sorted(members)}\n                    condition = binding.get(\"condition\")\n                    if condition:\n                        new_binding[\"condition\"] = condition\n                    bindings.append(new_binding)\n\n            if bindings:\n                # Sort bindings by role\n                key = operator.itemgetter(\"role\")\n                resource[\"bindings\"] = sorted(bindings, key=key)\n\n        return resource\n", "google/api_core/protobuf_helpers.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Helpers for :mod:`protobuf`.\"\"\"\n\nimport collections\nimport collections.abc\nimport copy\nimport inspect\n\nfrom google.protobuf import field_mask_pb2\nfrom google.protobuf import message\nfrom google.protobuf import wrappers_pb2\n\n\n_SENTINEL = object()\n_WRAPPER_TYPES = (\n    wrappers_pb2.BoolValue,\n    wrappers_pb2.BytesValue,\n    wrappers_pb2.DoubleValue,\n    wrappers_pb2.FloatValue,\n    wrappers_pb2.Int32Value,\n    wrappers_pb2.Int64Value,\n    wrappers_pb2.StringValue,\n    wrappers_pb2.UInt32Value,\n    wrappers_pb2.UInt64Value,\n)\n\n\ndef from_any_pb(pb_type, any_pb):\n    \"\"\"Converts an ``Any`` protobuf to the specified message type.\n\n    Args:\n        pb_type (type): the type of the message that any_pb stores an instance\n            of.\n        any_pb (google.protobuf.any_pb2.Any): the object to be converted.\n\n    Returns:\n        pb_type: An instance of the pb_type message.\n\n    Raises:\n        TypeError: if the message could not be converted.\n    \"\"\"\n    msg = pb_type()\n\n    # Unwrap proto-plus wrapped messages.\n    if callable(getattr(pb_type, \"pb\", None)):\n        msg_pb = pb_type.pb(msg)\n    else:\n        msg_pb = msg\n\n    # Unpack the Any object and populate the protobuf message instance.\n    if not any_pb.Unpack(msg_pb):\n        raise TypeError(\n            \"Could not convert {} to {}\".format(\n                any_pb.__class__.__name__, pb_type.__name__\n            )\n        )\n\n    # Done; return the message.\n    return msg\n\n\ndef check_oneof(**kwargs):\n    \"\"\"Raise ValueError if more than one keyword argument is not ``None``.\n\n    Args:\n        kwargs (dict): The keyword arguments sent to the function.\n\n    Raises:\n        ValueError: If more than one entry in ``kwargs`` is not ``None``.\n    \"\"\"\n    # Sanity check: If no keyword arguments were sent, this is fine.\n    if not kwargs:\n        return\n\n    not_nones = [val for val in kwargs.values() if val is not None]\n    if len(not_nones) > 1:\n        raise ValueError(\n            \"Only one of {fields} should be set.\".format(\n                fields=\", \".join(sorted(kwargs.keys()))\n            )\n        )\n\n\ndef get_messages(module):\n    \"\"\"Discovers all protobuf Message classes in a given import module.\n\n    Args:\n        module (module): A Python module; :func:`dir` will be run against this\n            module to find Message subclasses.\n\n    Returns:\n        dict[str, google.protobuf.message.Message]: A dictionary with the\n            Message class names as keys, and the Message subclasses themselves\n            as values.\n    \"\"\"\n    answer = collections.OrderedDict()\n    for name in dir(module):\n        candidate = getattr(module, name)\n        if inspect.isclass(candidate) and issubclass(candidate, message.Message):\n            answer[name] = candidate\n    return answer\n\n\ndef _resolve_subkeys(key, separator=\".\"):\n    \"\"\"Resolve a potentially nested key.\n\n    If the key contains the ``separator`` (e.g. ``.``) then the key will be\n    split on the first instance of the subkey::\n\n       >>> _resolve_subkeys('a.b.c')\n       ('a', 'b.c')\n       >>> _resolve_subkeys('d|e|f', separator='|')\n       ('d', 'e|f')\n\n    If not, the subkey will be :data:`None`::\n\n        >>> _resolve_subkeys('foo')\n        ('foo', None)\n\n    Args:\n        key (str): A string that may or may not contain the separator.\n        separator (str): The namespace separator. Defaults to `.`.\n\n    Returns:\n        Tuple[str, str]: The key and subkey(s).\n    \"\"\"\n    parts = key.split(separator, 1)\n\n    if len(parts) > 1:\n        return parts\n    else:\n        return parts[0], None\n\n\ndef get(msg_or_dict, key, default=_SENTINEL):\n    \"\"\"Retrieve a key's value from a protobuf Message or dictionary.\n\n    Args:\n        mdg_or_dict (Union[~google.protobuf.message.Message, Mapping]): the\n            object.\n        key (str): The key to retrieve from the object.\n        default (Any): If the key is not present on the object, and a default\n            is set, returns that default instead. A type-appropriate falsy\n            default is generally recommended, as protobuf messages almost\n            always have default values for unset values and it is not always\n            possible to tell the difference between a falsy value and an\n            unset one. If no default is set then :class:`KeyError` will be\n            raised if the key is not present in the object.\n\n    Returns:\n        Any: The return value from the underlying Message or dict.\n\n    Raises:\n        KeyError: If the key is not found. Note that, for unset values,\n            messages and dictionaries may not have consistent behavior.\n        TypeError: If ``msg_or_dict`` is not a Message or Mapping.\n    \"\"\"\n    # We may need to get a nested key. Resolve this.\n    key, subkey = _resolve_subkeys(key)\n\n    # Attempt to get the value from the two types of objects we know about.\n    # If we get something else, complain.\n    if isinstance(msg_or_dict, message.Message):\n        answer = getattr(msg_or_dict, key, default)\n    elif isinstance(msg_or_dict, collections.abc.Mapping):\n        answer = msg_or_dict.get(key, default)\n    else:\n        raise TypeError(\n            \"get() expected a dict or protobuf message, got {!r}.\".format(\n                type(msg_or_dict)\n            )\n        )\n\n    # If the object we got back is our sentinel, raise KeyError; this is\n    # a \"not found\" case.\n    if answer is _SENTINEL:\n        raise KeyError(key)\n\n    # If a subkey exists, call this method recursively against the answer.\n    if subkey is not None and answer is not default:\n        return get(answer, subkey, default=default)\n\n    return answer\n\n\ndef _set_field_on_message(msg, key, value):\n    \"\"\"Set helper for protobuf Messages.\"\"\"\n    # Attempt to set the value on the types of objects we know how to deal\n    # with.\n    if isinstance(value, (collections.abc.MutableSequence, tuple)):\n        # Clear the existing repeated protobuf message of any elements\n        # currently inside it.\n        while getattr(msg, key):\n            getattr(msg, key).pop()\n\n        # Write our new elements to the repeated field.\n        for item in value:\n            if isinstance(item, collections.abc.Mapping):\n                getattr(msg, key).add(**item)\n            else:\n                # protobuf's RepeatedCompositeContainer doesn't support\n                # append.\n                getattr(msg, key).extend([item])\n    elif isinstance(value, collections.abc.Mapping):\n        # Assign the dictionary values to the protobuf message.\n        for item_key, item_value in value.items():\n            set(getattr(msg, key), item_key, item_value)\n    elif isinstance(value, message.Message):\n        getattr(msg, key).CopyFrom(value)\n    else:\n        setattr(msg, key, value)\n\n\ndef set(msg_or_dict, key, value):\n    \"\"\"Set a key's value on a protobuf Message or dictionary.\n\n    Args:\n        msg_or_dict (Union[~google.protobuf.message.Message, Mapping]): the\n            object.\n        key (str): The key to set.\n        value (Any): The value to set.\n\n    Raises:\n        TypeError: If ``msg_or_dict`` is not a Message or dictionary.\n    \"\"\"\n    # Sanity check: Is our target object valid?\n    if not isinstance(msg_or_dict, (collections.abc.MutableMapping, message.Message)):\n        raise TypeError(\n            \"set() expected a dict or protobuf message, got {!r}.\".format(\n                type(msg_or_dict)\n            )\n        )\n\n    # We may be setting a nested key. Resolve this.\n    basekey, subkey = _resolve_subkeys(key)\n\n    # If a subkey exists, then get that object and call this method\n    # recursively against it using the subkey.\n    if subkey is not None:\n        if isinstance(msg_or_dict, collections.abc.MutableMapping):\n            msg_or_dict.setdefault(basekey, {})\n        set(get(msg_or_dict, basekey), subkey, value)\n        return\n\n    if isinstance(msg_or_dict, collections.abc.MutableMapping):\n        msg_or_dict[key] = value\n    else:\n        _set_field_on_message(msg_or_dict, key, value)\n\n\ndef setdefault(msg_or_dict, key, value):\n    \"\"\"Set the key on a protobuf Message or dictionary to a given value if the\n    current value is falsy.\n\n    Because protobuf Messages do not distinguish between unset values and\n    falsy ones particularly well (by design), this method treats any falsy\n    value (e.g. 0, empty list) as a target to be overwritten, on both Messages\n    and dictionaries.\n\n    Args:\n        msg_or_dict (Union[~google.protobuf.message.Message, Mapping]): the\n            object.\n        key (str): The key on the object in question.\n        value (Any): The value to set.\n\n    Raises:\n        TypeError: If ``msg_or_dict`` is not a Message or dictionary.\n    \"\"\"\n    if not get(msg_or_dict, key, default=None):\n        set(msg_or_dict, key, value)\n\n\ndef field_mask(original, modified):\n    \"\"\"Create a field mask by comparing two messages.\n\n    Args:\n        original (~google.protobuf.message.Message): the original message.\n            If set to None, this field will be interpreted as an empty\n            message.\n        modified (~google.protobuf.message.Message): the modified message.\n            If set to None, this field will be interpreted as an empty\n            message.\n\n    Returns:\n        google.protobuf.field_mask_pb2.FieldMask: field mask that contains\n        the list of field names that have different values between the two\n        messages. If the messages are equivalent, then the field mask is empty.\n\n    Raises:\n        ValueError: If the ``original`` or ``modified`` are not the same type.\n    \"\"\"\n    if original is None and modified is None:\n        return field_mask_pb2.FieldMask()\n\n    if original is None and modified is not None:\n        original = copy.deepcopy(modified)\n        original.Clear()\n\n    if modified is None and original is not None:\n        modified = copy.deepcopy(original)\n        modified.Clear()\n\n    if not isinstance(original, type(modified)):\n        raise ValueError(\n            \"expected that both original and modified should be of the \"\n            'same type, received \"{!r}\" and \"{!r}\".'.format(\n                type(original), type(modified)\n            )\n        )\n\n    return field_mask_pb2.FieldMask(paths=_field_mask_helper(original, modified))\n\n\ndef _field_mask_helper(original, modified, current=\"\"):\n    answer = []\n\n    for name in original.DESCRIPTOR.fields_by_name:\n        field_path = _get_path(current, name)\n\n        original_val = getattr(original, name)\n        modified_val = getattr(modified, name)\n\n        if _is_message(original_val) or _is_message(modified_val):\n            if original_val != modified_val:\n                # Wrapper types do not need to include the .value part of the\n                # path.\n                if _is_wrapper(original_val) or _is_wrapper(modified_val):\n                    answer.append(field_path)\n                elif not modified_val.ListFields():\n                    answer.append(field_path)\n                else:\n                    answer.extend(\n                        _field_mask_helper(original_val, modified_val, field_path)\n                    )\n        else:\n            if original_val != modified_val:\n                answer.append(field_path)\n\n    return answer\n\n\ndef _get_path(current, name):\n    # gapic-generator-python appends underscores to field names\n    # that collide with python keywords.\n    # `_` is stripped away as it is not possible to\n    # natively define a field with a trailing underscore in protobuf.\n    # APIs will reject field masks if fields have trailing underscores.\n    # See https://github.com/googleapis/python-api-core/issues/227\n    name = name.rstrip(\"_\")\n    if not current:\n        return name\n    return \"%s.%s\" % (current, name)\n\n\ndef _is_message(value):\n    return isinstance(value, message.Message)\n\n\ndef _is_wrapper(value):\n    return type(value) in _WRAPPER_TYPES\n", "google/api_core/exceptions.py": "# Copyright 2014 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Exceptions raised by Google API core & clients.\n\nThis module provides base classes for all errors raised by libraries based\non :mod:`google.api_core`, including both HTTP and gRPC clients.\n\"\"\"\n\nfrom __future__ import absolute_import\nfrom __future__ import unicode_literals\n\nimport http.client\nfrom typing import Dict\nfrom typing import Union\nimport warnings\n\nfrom google.rpc import error_details_pb2\n\ntry:\n    import grpc\n\n    try:\n        from grpc_status import rpc_status\n    except ImportError:  # pragma: NO COVER\n        warnings.warn(\n            \"Please install grpcio-status to obtain helpful grpc error messages.\",\n            ImportWarning,\n        )\n        rpc_status = None\nexcept ImportError:  # pragma: NO COVER\n    grpc = None\n\n# Lookup tables for mapping exceptions from HTTP and gRPC transports.\n# Populated by _GoogleAPICallErrorMeta\n_HTTP_CODE_TO_EXCEPTION: Dict[int, Exception] = {}\n_GRPC_CODE_TO_EXCEPTION: Dict[int, Exception] = {}\n\n# Additional lookup table to map integer status codes to grpc status code\n# grpc does not currently support initializing enums from ints\n# i.e., grpc.StatusCode(5) raises an error\n_INT_TO_GRPC_CODE = {}\nif grpc is not None:  # pragma: no branch\n    for x in grpc.StatusCode:\n        _INT_TO_GRPC_CODE[x.value[0]] = x\n\n\nclass GoogleAPIError(Exception):\n    \"\"\"Base class for all exceptions raised by Google API Clients.\"\"\"\n\n    pass\n\n\nclass DuplicateCredentialArgs(GoogleAPIError):\n    \"\"\"Raised when multiple credentials are passed.\"\"\"\n\n    pass\n\n\nclass RetryError(GoogleAPIError):\n    \"\"\"Raised when a function has exhausted all of its available retries.\n\n    Args:\n        message (str): The exception message.\n        cause (Exception): The last exception raised when retrying the\n            function.\n    \"\"\"\n\n    def __init__(self, message, cause):\n        super(RetryError, self).__init__(message)\n        self.message = message\n        self._cause = cause\n\n    @property\n    def cause(self):\n        \"\"\"The last exception raised when retrying the function.\"\"\"\n        return self._cause\n\n    def __str__(self):\n        return \"{}, last exception: {}\".format(self.message, self.cause)\n\n\nclass _GoogleAPICallErrorMeta(type):\n    \"\"\"Metaclass for registering GoogleAPICallError subclasses.\"\"\"\n\n    def __new__(mcs, name, bases, class_dict):\n        cls = type.__new__(mcs, name, bases, class_dict)\n        if cls.code is not None:\n            _HTTP_CODE_TO_EXCEPTION.setdefault(cls.code, cls)\n        if cls.grpc_status_code is not None:\n            _GRPC_CODE_TO_EXCEPTION.setdefault(cls.grpc_status_code, cls)\n        return cls\n\n\nclass GoogleAPICallError(GoogleAPIError, metaclass=_GoogleAPICallErrorMeta):\n    \"\"\"Base class for exceptions raised by calling API methods.\n\n    Args:\n        message (str): The exception message.\n        errors (Sequence[Any]): An optional list of error details.\n        details (Sequence[Any]): An optional list of objects defined in google.rpc.error_details.\n        response (Union[requests.Request, grpc.Call]): The response or\n            gRPC call metadata.\n        error_info (Union[error_details_pb2.ErrorInfo, None]): An optional object containing error info\n            (google.rpc.error_details.ErrorInfo).\n    \"\"\"\n\n    code: Union[int, None] = None\n    \"\"\"Optional[int]: The HTTP status code associated with this error.\n\n    This may be ``None`` if the exception does not have a direct mapping\n    to an HTTP error.\n\n    See http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html\n    \"\"\"\n\n    grpc_status_code = None\n    \"\"\"Optional[grpc.StatusCode]: The gRPC status code associated with this\n    error.\n\n    This may be ``None`` if the exception does not match up to a gRPC error.\n    \"\"\"\n\n    def __init__(self, message, errors=(), details=(), response=None, error_info=None):\n        super(GoogleAPICallError, self).__init__(message)\n        self.message = message\n        \"\"\"str: The exception message.\"\"\"\n        self._errors = errors\n        self._details = details\n        self._response = response\n        self._error_info = error_info\n\n    def __str__(self):\n        error_msg = \"{} {}\".format(self.code, self.message)\n        if self.details:\n            error_msg = \"{} {}\".format(error_msg, self.details)\n        # Note: This else condition can be removed once proposal A from\n        # b/284179390 is implemented.\n        else:\n            if self.errors:\n                errors = [\n                    f\"{error.code}: {error.message}\"\n                    for error in self.errors\n                    if hasattr(error, \"code\") and hasattr(error, \"message\")\n                ]\n                if errors:\n                    error_msg = \"{} {}\".format(error_msg, \"\\n\".join(errors))\n        return error_msg\n\n    @property\n    def reason(self):\n        \"\"\"The reason of the error.\n\n        Reference:\n            https://github.com/googleapis/googleapis/blob/master/google/rpc/error_details.proto#L112\n\n        Returns:\n            Union[str, None]: An optional string containing reason of the error.\n        \"\"\"\n        return self._error_info.reason if self._error_info else None\n\n    @property\n    def domain(self):\n        \"\"\"The logical grouping to which the \"reason\" belongs.\n\n        Reference:\n            https://github.com/googleapis/googleapis/blob/master/google/rpc/error_details.proto#L112\n\n        Returns:\n            Union[str, None]: An optional string containing a logical grouping to which the \"reason\" belongs.\n        \"\"\"\n        return self._error_info.domain if self._error_info else None\n\n    @property\n    def metadata(self):\n        \"\"\"Additional structured details about this error.\n\n        Reference:\n            https://github.com/googleapis/googleapis/blob/master/google/rpc/error_details.proto#L112\n\n        Returns:\n            Union[Dict[str, str], None]: An optional object containing structured details about the error.\n        \"\"\"\n        return self._error_info.metadata if self._error_info else None\n\n    @property\n    def errors(self):\n        \"\"\"Detailed error information.\n\n        Returns:\n            Sequence[Any]: A list of additional error details.\n        \"\"\"\n        return list(self._errors)\n\n    @property\n    def details(self):\n        \"\"\"Information contained in google.rpc.status.details.\n\n        Reference:\n            https://github.com/googleapis/googleapis/blob/master/google/rpc/status.proto\n            https://github.com/googleapis/googleapis/blob/master/google/rpc/error_details.proto\n\n        Returns:\n            Sequence[Any]: A list of structured objects from error_details.proto\n        \"\"\"\n        return list(self._details)\n\n    @property\n    def response(self):\n        \"\"\"Optional[Union[requests.Request, grpc.Call]]: The response or\n        gRPC call metadata.\"\"\"\n        return self._response\n\n\nclass Redirection(GoogleAPICallError):\n    \"\"\"Base class for for all redirection (HTTP 3xx) responses.\"\"\"\n\n\nclass MovedPermanently(Redirection):\n    \"\"\"Exception mapping a ``301 Moved Permanently`` response.\"\"\"\n\n    code = http.client.MOVED_PERMANENTLY\n\n\nclass NotModified(Redirection):\n    \"\"\"Exception mapping a ``304 Not Modified`` response.\"\"\"\n\n    code = http.client.NOT_MODIFIED\n\n\nclass TemporaryRedirect(Redirection):\n    \"\"\"Exception mapping a ``307 Temporary Redirect`` response.\"\"\"\n\n    code = http.client.TEMPORARY_REDIRECT\n\n\nclass ResumeIncomplete(Redirection):\n    \"\"\"Exception mapping a ``308 Resume Incomplete`` response.\n\n    .. note:: :attr:`http.client.PERMANENT_REDIRECT` is ``308``, but Google\n        APIs differ in their use of this status code.\n    \"\"\"\n\n    code = 308\n\n\nclass ClientError(GoogleAPICallError):\n    \"\"\"Base class for all client error (HTTP 4xx) responses.\"\"\"\n\n\nclass BadRequest(ClientError):\n    \"\"\"Exception mapping a ``400 Bad Request`` response.\"\"\"\n\n    code = http.client.BAD_REQUEST\n\n\nclass InvalidArgument(BadRequest):\n    \"\"\"Exception mapping a :attr:`grpc.StatusCode.INVALID_ARGUMENT` error.\"\"\"\n\n    grpc_status_code = grpc.StatusCode.INVALID_ARGUMENT if grpc is not None else None\n\n\nclass FailedPrecondition(BadRequest):\n    \"\"\"Exception mapping a :attr:`grpc.StatusCode.FAILED_PRECONDITION`\n    error.\"\"\"\n\n    grpc_status_code = grpc.StatusCode.FAILED_PRECONDITION if grpc is not None else None\n\n\nclass OutOfRange(BadRequest):\n    \"\"\"Exception mapping a :attr:`grpc.StatusCode.OUT_OF_RANGE` error.\"\"\"\n\n    grpc_status_code = grpc.StatusCode.OUT_OF_RANGE if grpc is not None else None\n\n\nclass Unauthorized(ClientError):\n    \"\"\"Exception mapping a ``401 Unauthorized`` response.\"\"\"\n\n    code = http.client.UNAUTHORIZED\n\n\nclass Unauthenticated(Unauthorized):\n    \"\"\"Exception mapping a :attr:`grpc.StatusCode.UNAUTHENTICATED` error.\"\"\"\n\n    grpc_status_code = grpc.StatusCode.UNAUTHENTICATED if grpc is not None else None\n\n\nclass Forbidden(ClientError):\n    \"\"\"Exception mapping a ``403 Forbidden`` response.\"\"\"\n\n    code = http.client.FORBIDDEN\n\n\nclass PermissionDenied(Forbidden):\n    \"\"\"Exception mapping a :attr:`grpc.StatusCode.PERMISSION_DENIED` error.\"\"\"\n\n    grpc_status_code = grpc.StatusCode.PERMISSION_DENIED if grpc is not None else None\n\n\nclass NotFound(ClientError):\n    \"\"\"Exception mapping a ``404 Not Found`` response or a\n    :attr:`grpc.StatusCode.NOT_FOUND` error.\"\"\"\n\n    code = http.client.NOT_FOUND\n    grpc_status_code = grpc.StatusCode.NOT_FOUND if grpc is not None else None\n\n\nclass MethodNotAllowed(ClientError):\n    \"\"\"Exception mapping a ``405 Method Not Allowed`` response.\"\"\"\n\n    code = http.client.METHOD_NOT_ALLOWED\n\n\nclass Conflict(ClientError):\n    \"\"\"Exception mapping a ``409 Conflict`` response.\"\"\"\n\n    code = http.client.CONFLICT\n\n\nclass AlreadyExists(Conflict):\n    \"\"\"Exception mapping a :attr:`grpc.StatusCode.ALREADY_EXISTS` error.\"\"\"\n\n    grpc_status_code = grpc.StatusCode.ALREADY_EXISTS if grpc is not None else None\n\n\nclass Aborted(Conflict):\n    \"\"\"Exception mapping a :attr:`grpc.StatusCode.ABORTED` error.\"\"\"\n\n    grpc_status_code = grpc.StatusCode.ABORTED if grpc is not None else None\n\n\nclass LengthRequired(ClientError):\n    \"\"\"Exception mapping a ``411 Length Required`` response.\"\"\"\n\n    code = http.client.LENGTH_REQUIRED\n\n\nclass PreconditionFailed(ClientError):\n    \"\"\"Exception mapping a ``412 Precondition Failed`` response.\"\"\"\n\n    code = http.client.PRECONDITION_FAILED\n\n\nclass RequestRangeNotSatisfiable(ClientError):\n    \"\"\"Exception mapping a ``416 Request Range Not Satisfiable`` response.\"\"\"\n\n    code = http.client.REQUESTED_RANGE_NOT_SATISFIABLE\n\n\nclass TooManyRequests(ClientError):\n    \"\"\"Exception mapping a ``429 Too Many Requests`` response.\"\"\"\n\n    code = http.client.TOO_MANY_REQUESTS\n\n\nclass ResourceExhausted(TooManyRequests):\n    \"\"\"Exception mapping a :attr:`grpc.StatusCode.RESOURCE_EXHAUSTED` error.\"\"\"\n\n    grpc_status_code = grpc.StatusCode.RESOURCE_EXHAUSTED if grpc is not None else None\n\n\nclass Cancelled(ClientError):\n    \"\"\"Exception mapping a :attr:`grpc.StatusCode.CANCELLED` error.\"\"\"\n\n    # This maps to HTTP status code 499. See\n    # https://github.com/googleapis/googleapis/blob/master/google/rpc/code.proto\n    code = 499\n    grpc_status_code = grpc.StatusCode.CANCELLED if grpc is not None else None\n\n\nclass ServerError(GoogleAPICallError):\n    \"\"\"Base for 5xx responses.\"\"\"\n\n\nclass InternalServerError(ServerError):\n    \"\"\"Exception mapping a ``500 Internal Server Error`` response. or a\n    :attr:`grpc.StatusCode.INTERNAL` error.\"\"\"\n\n    code = http.client.INTERNAL_SERVER_ERROR\n    grpc_status_code = grpc.StatusCode.INTERNAL if grpc is not None else None\n\n\nclass Unknown(ServerError):\n    \"\"\"Exception mapping a :attr:`grpc.StatusCode.UNKNOWN` error.\"\"\"\n\n    grpc_status_code = grpc.StatusCode.UNKNOWN if grpc is not None else None\n\n\nclass DataLoss(ServerError):\n    \"\"\"Exception mapping a :attr:`grpc.StatusCode.DATA_LOSS` error.\"\"\"\n\n    grpc_status_code = grpc.StatusCode.DATA_LOSS if grpc is not None else None\n\n\nclass MethodNotImplemented(ServerError):\n    \"\"\"Exception mapping a ``501 Not Implemented`` response or a\n    :attr:`grpc.StatusCode.UNIMPLEMENTED` error.\"\"\"\n\n    code = http.client.NOT_IMPLEMENTED\n    grpc_status_code = grpc.StatusCode.UNIMPLEMENTED if grpc is not None else None\n\n\nclass BadGateway(ServerError):\n    \"\"\"Exception mapping a ``502 Bad Gateway`` response.\"\"\"\n\n    code = http.client.BAD_GATEWAY\n\n\nclass ServiceUnavailable(ServerError):\n    \"\"\"Exception mapping a ``503 Service Unavailable`` response or a\n    :attr:`grpc.StatusCode.UNAVAILABLE` error.\"\"\"\n\n    code = http.client.SERVICE_UNAVAILABLE\n    grpc_status_code = grpc.StatusCode.UNAVAILABLE if grpc is not None else None\n\n\nclass GatewayTimeout(ServerError):\n    \"\"\"Exception mapping a ``504 Gateway Timeout`` response.\"\"\"\n\n    code = http.client.GATEWAY_TIMEOUT\n\n\nclass DeadlineExceeded(GatewayTimeout):\n    \"\"\"Exception mapping a :attr:`grpc.StatusCode.DEADLINE_EXCEEDED` error.\"\"\"\n\n    grpc_status_code = grpc.StatusCode.DEADLINE_EXCEEDED if grpc is not None else None\n\n\ndef exception_class_for_http_status(status_code):\n    \"\"\"Return the exception class for a specific HTTP status code.\n\n    Args:\n        status_code (int): The HTTP status code.\n\n    Returns:\n        :func:`type`: the appropriate subclass of :class:`GoogleAPICallError`.\n    \"\"\"\n    return _HTTP_CODE_TO_EXCEPTION.get(status_code, GoogleAPICallError)\n\n\ndef from_http_status(status_code, message, **kwargs):\n    \"\"\"Create a :class:`GoogleAPICallError` from an HTTP status code.\n\n    Args:\n        status_code (int): The HTTP status code.\n        message (str): The exception message.\n        kwargs: Additional arguments passed to the :class:`GoogleAPICallError`\n            constructor.\n\n    Returns:\n        GoogleAPICallError: An instance of the appropriate subclass of\n            :class:`GoogleAPICallError`.\n    \"\"\"\n    error_class = exception_class_for_http_status(status_code)\n    error = error_class(message, **kwargs)\n\n    if error.code is None:\n        error.code = status_code\n\n    return error\n\n\ndef from_http_response(response):\n    \"\"\"Create a :class:`GoogleAPICallError` from a :class:`requests.Response`.\n\n    Args:\n        response (requests.Response): The HTTP response.\n\n    Returns:\n        GoogleAPICallError: An instance of the appropriate subclass of\n            :class:`GoogleAPICallError`, with the message and errors populated\n            from the response.\n    \"\"\"\n    try:\n        payload = response.json()\n    except ValueError:\n        payload = {\"error\": {\"message\": response.text or \"unknown error\"}}\n\n    error_message = payload.get(\"error\", {}).get(\"message\", \"unknown error\")\n    errors = payload.get(\"error\", {}).get(\"errors\", ())\n    # In JSON, details are already formatted in developer-friendly way.\n    details = payload.get(\"error\", {}).get(\"details\", ())\n    error_info = list(\n        filter(\n            lambda detail: detail.get(\"@type\", \"\")\n            == \"type.googleapis.com/google.rpc.ErrorInfo\",\n            details,\n        )\n    )\n    error_info = error_info[0] if error_info else None\n\n    message = \"{method} {url}: {error}\".format(\n        method=response.request.method,\n        url=response.request.url,\n        error=error_message,\n    )\n\n    exception = from_http_status(\n        response.status_code,\n        message,\n        errors=errors,\n        details=details,\n        response=response,\n        error_info=error_info,\n    )\n    return exception\n\n\ndef exception_class_for_grpc_status(status_code):\n    \"\"\"Return the exception class for a specific :class:`grpc.StatusCode`.\n\n    Args:\n        status_code (grpc.StatusCode): The gRPC status code.\n\n    Returns:\n        :func:`type`: the appropriate subclass of :class:`GoogleAPICallError`.\n    \"\"\"\n    return _GRPC_CODE_TO_EXCEPTION.get(status_code, GoogleAPICallError)\n\n\ndef from_grpc_status(status_code, message, **kwargs):\n    \"\"\"Create a :class:`GoogleAPICallError` from a :class:`grpc.StatusCode`.\n\n    Args:\n        status_code (Union[grpc.StatusCode, int]): The gRPC status code.\n        message (str): The exception message.\n        kwargs: Additional arguments passed to the :class:`GoogleAPICallError`\n            constructor.\n\n    Returns:\n        GoogleAPICallError: An instance of the appropriate subclass of\n            :class:`GoogleAPICallError`.\n    \"\"\"\n\n    if isinstance(status_code, int):\n        status_code = _INT_TO_GRPC_CODE.get(status_code, status_code)\n\n    error_class = exception_class_for_grpc_status(status_code)\n    error = error_class(message, **kwargs)\n\n    if error.grpc_status_code is None:\n        error.grpc_status_code = status_code\n\n    return error\n\n\ndef _is_informative_grpc_error(rpc_exc):\n    return hasattr(rpc_exc, \"code\") and hasattr(rpc_exc, \"details\")\n\n\ndef _parse_grpc_error_details(rpc_exc):\n    try:\n        status = rpc_status.from_call(rpc_exc)\n    except NotImplementedError:  # workaround\n        return [], None\n\n    if not status:\n        return [], None\n\n    possible_errors = [\n        error_details_pb2.BadRequest,\n        error_details_pb2.PreconditionFailure,\n        error_details_pb2.QuotaFailure,\n        error_details_pb2.ErrorInfo,\n        error_details_pb2.RetryInfo,\n        error_details_pb2.ResourceInfo,\n        error_details_pb2.RequestInfo,\n        error_details_pb2.DebugInfo,\n        error_details_pb2.Help,\n        error_details_pb2.LocalizedMessage,\n    ]\n    error_info = None\n    error_details = []\n    for detail in status.details:\n        matched_detail_cls = list(\n            filter(lambda x: detail.Is(x.DESCRIPTOR), possible_errors)\n        )\n        # If nothing matched, use detail directly.\n        if len(matched_detail_cls) == 0:\n            info = detail\n        else:\n            info = matched_detail_cls[0]()\n            detail.Unpack(info)\n        error_details.append(info)\n        if isinstance(info, error_details_pb2.ErrorInfo):\n            error_info = info\n    return error_details, error_info\n\n\ndef from_grpc_error(rpc_exc):\n    \"\"\"Create a :class:`GoogleAPICallError` from a :class:`grpc.RpcError`.\n\n    Args:\n        rpc_exc (grpc.RpcError): The gRPC error.\n\n    Returns:\n        GoogleAPICallError: An instance of the appropriate subclass of\n            :class:`GoogleAPICallError`.\n    \"\"\"\n    # NOTE(lidiz) All gRPC error shares the parent class grpc.RpcError.\n    # However, check for grpc.RpcError breaks backward compatibility.\n    if (\n        grpc is not None and isinstance(rpc_exc, grpc.Call)\n    ) or _is_informative_grpc_error(rpc_exc):\n        details, err_info = _parse_grpc_error_details(rpc_exc)\n        return from_grpc_status(\n            rpc_exc.code(),\n            rpc_exc.details(),\n            errors=(rpc_exc,),\n            details=details,\n            response=rpc_exc,\n            error_info=err_info,\n        )\n    else:\n        return GoogleAPICallError(str(rpc_exc), errors=(rpc_exc,), response=rpc_exc)\n", "google/api_core/universe.py": "# Copyright 2024 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Helpers for universe domain.\"\"\"\n\nfrom typing import Any, Optional\n\nDEFAULT_UNIVERSE = \"googleapis.com\"\n\n\nclass EmptyUniverseError(ValueError):\n    def __init__(self):\n        message = \"Universe Domain cannot be an empty string.\"\n        super().__init__(message)\n\n\nclass UniverseMismatchError(ValueError):\n    def __init__(self, client_universe, credentials_universe):\n        message = (\n            f\"The configured universe domain ({client_universe}) does not match the universe domain \"\n            f\"found in the credentials ({credentials_universe}). \"\n            \"If you haven't configured the universe domain explicitly, \"\n            f\"`{DEFAULT_UNIVERSE}` is the default.\"\n        )\n        super().__init__(message)\n\n\ndef determine_domain(\n    client_universe_domain: Optional[str], universe_domain_env: Optional[str]\n) -> str:\n    \"\"\"Return the universe domain used by the client.\n\n    Args:\n        client_universe_domain (Optional[str]): The universe domain configured via the client options.\n        universe_domain_env (Optional[str]): The universe domain configured via the\n        \"GOOGLE_CLOUD_UNIVERSE_DOMAIN\" environment variable.\n\n    Returns:\n        str: The universe domain to be used by the client.\n\n    Raises:\n        ValueError: If the universe domain is an empty string.\n    \"\"\"\n    universe_domain = DEFAULT_UNIVERSE\n    if client_universe_domain is not None:\n        universe_domain = client_universe_domain\n    elif universe_domain_env is not None:\n        universe_domain = universe_domain_env\n    if len(universe_domain.strip()) == 0:\n        raise EmptyUniverseError\n    return universe_domain\n\n\ndef compare_domains(client_universe: str, credentials: Any) -> bool:\n    \"\"\"Returns True iff the universe domains used by the client and credentials match.\n\n    Args:\n        client_universe (str): The universe domain configured via the client options.\n        credentials Any: The credentials being used in the client.\n\n    Returns:\n        bool: True iff client_universe matches the universe in credentials.\n\n    Raises:\n        ValueError: when client_universe does not match the universe in credentials.\n    \"\"\"\n    credentials_universe = getattr(credentials, \"universe_domain\", DEFAULT_UNIVERSE)\n\n    if client_universe != credentials_universe:\n        raise UniverseMismatchError(client_universe, credentials_universe)\n    return True\n", "google/api_core/page_iterator_async.py": "# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"AsyncIO iterators for paging through paged API methods.\n\nThese iterators simplify the process of paging through API responses\nwhere the request takes a page token and the response is a list of results with\na token for the next page. See `list pagination`_ in the Google API Style Guide\nfor more details.\n\n.. _list pagination:\n    https://cloud.google.com/apis/design/design_patterns#list_pagination\n\nAPI clients that have methods that follow the list pagination pattern can\nreturn an :class:`.AsyncIterator`:\n\n    >>> results_iterator = await client.list_resources()\n\nOr you can walk your way through items and call off the search early if\nyou find what you're looking for (resulting in possibly fewer requests)::\n\n    >>> async for resource in results_iterator:\n    ...     print(resource.name)\n    ...     if not resource.is_valid:\n    ...         break\n\nAt any point, you may check the number of items consumed by referencing the\n``num_results`` property of the iterator::\n\n    >>> async for my_item in results_iterator:\n    ...     if results_iterator.num_results >= 10:\n    ...         break\n\nWhen iterating, not every new item will send a request to the server.\nTo iterate based on each page of items (where a page corresponds to\na request)::\n\n    >>> async for page in results_iterator.pages:\n    ...     print('=' * 20)\n    ...     print('    Page number: {:d}'.format(iterator.page_number))\n    ...     print('  Items in page: {:d}'.format(page.num_items))\n    ...     print('     First item: {!r}'.format(next(page)))\n    ...     print('Items remaining: {:d}'.format(page.remaining))\n    ...     print('Next page token: {}'.format(iterator.next_page_token))\n    ====================\n        Page number: 1\n      Items in page: 1\n         First item: <MyItemClass at 0x7f1d3cccf690>\n    Items remaining: 0\n    Next page token: eav1OzQB0OM8rLdGXOEsyQWSG\n    ====================\n        Page number: 2\n      Items in page: 19\n         First item: <MyItemClass at 0x7f1d3cccffd0>\n    Items remaining: 18\n    Next page token: None\n\"\"\"\n\nimport abc\n\nfrom google.api_core.page_iterator import Page\n\n\ndef _item_to_value_identity(iterator, item):\n    \"\"\"An item to value transformer that returns the item un-changed.\"\"\"\n    # pylint: disable=unused-argument\n    # We are conforming to the interface defined by Iterator.\n    return item\n\n\nclass AsyncIterator(abc.ABC):\n    \"\"\"A generic class for iterating through API list responses.\n\n    Args:\n        client(google.cloud.client.Client): The API client.\n        item_to_value (Callable[google.api_core.page_iterator_async.AsyncIterator, Any]):\n            Callable to convert an item from the type in the raw API response\n            into the native object. Will be called with the iterator and a\n            single item.\n        page_token (str): A token identifying a page in a result set to start\n            fetching results from.\n        max_results (int): The maximum number of results to fetch.\n    \"\"\"\n\n    def __init__(\n        self,\n        client,\n        item_to_value=_item_to_value_identity,\n        page_token=None,\n        max_results=None,\n    ):\n        self._started = False\n        self.__active_aiterator = None\n\n        self.client = client\n        \"\"\"Optional[Any]: The client that created this iterator.\"\"\"\n        self.item_to_value = item_to_value\n        \"\"\"Callable[Iterator, Any]: Callable to convert an item from the type\n            in the raw API response into the native object. Will be called with\n            the iterator and a\n            single item.\n        \"\"\"\n        self.max_results = max_results\n        \"\"\"int: The maximum number of results to fetch.\"\"\"\n\n        # The attributes below will change over the life of the iterator.\n        self.page_number = 0\n        \"\"\"int: The current page of results.\"\"\"\n        self.next_page_token = page_token\n        \"\"\"str: The token for the next page of results. If this is set before\n            the iterator starts, it effectively offsets the iterator to a\n            specific starting point.\"\"\"\n        self.num_results = 0\n        \"\"\"int: The total number of results fetched so far.\"\"\"\n\n    @property\n    def pages(self):\n        \"\"\"Iterator of pages in the response.\n\n        returns:\n            types.GeneratorType[google.api_core.page_iterator.Page]: A\n                generator of page instances.\n\n        raises:\n            ValueError: If the iterator has already been started.\n        \"\"\"\n        if self._started:\n            raise ValueError(\"Iterator has already started\", self)\n        self._started = True\n        return self._page_aiter(increment=True)\n\n    async def _items_aiter(self):\n        \"\"\"Iterator for each item returned.\"\"\"\n        async for page in self._page_aiter(increment=False):\n            for item in page:\n                self.num_results += 1\n                yield item\n\n    def __aiter__(self):\n        \"\"\"Iterator for each item returned.\n\n        Returns:\n            types.GeneratorType[Any]: A generator of items from the API.\n\n        Raises:\n            ValueError: If the iterator has already been started.\n        \"\"\"\n        if self._started:\n            raise ValueError(\"Iterator has already started\", self)\n        self._started = True\n        return self._items_aiter()\n\n    async def __anext__(self):\n        if self.__active_aiterator is None:\n            self.__active_aiterator = self.__aiter__()\n        return await self.__active_aiterator.__anext__()\n\n    async def _page_aiter(self, increment):\n        \"\"\"Generator of pages of API responses.\n\n        Args:\n            increment (bool): Flag indicating if the total number of results\n                should be incremented on each page. This is useful since a page\n                iterator will want to increment by results per page while an\n                items iterator will want to increment per item.\n\n        Yields:\n            Page: each page of items from the API.\n        \"\"\"\n        page = await self._next_page()\n        while page is not None:\n            self.page_number += 1\n            if increment:\n                self.num_results += page.num_items\n            yield page\n            page = await self._next_page()\n\n    @abc.abstractmethod\n    async def _next_page(self):\n        \"\"\"Get the next page in the iterator.\n\n        This does nothing and is intended to be over-ridden by subclasses\n        to return the next :class:`Page`.\n\n        Raises:\n            NotImplementedError: Always, this method is abstract.\n        \"\"\"\n        raise NotImplementedError\n\n\nclass AsyncGRPCIterator(AsyncIterator):\n    \"\"\"A generic class for iterating through gRPC list responses.\n\n    .. note:: The class does not take a ``page_token`` argument because it can\n        just be specified in the ``request``.\n\n    Args:\n        client (google.cloud.client.Client): The API client. This unused by\n            this class, but kept to satisfy the :class:`Iterator` interface.\n        method (Callable[protobuf.Message]): A bound gRPC method that should\n            take a single message for the request.\n        request (protobuf.Message): The request message.\n        items_field (str): The field in the response message that has the\n            items for the page.\n        item_to_value (Callable[GRPCIterator, Any]): Callable to convert an\n            item from the type in the JSON response into a native object. Will\n            be called with the iterator and a single item.\n        request_token_field (str): The field in the request message used to\n            specify the page token.\n        response_token_field (str): The field in the response message that has\n            the token for the next page.\n        max_results (int): The maximum number of results to fetch.\n\n    .. autoattribute:: pages\n    \"\"\"\n\n    _DEFAULT_REQUEST_TOKEN_FIELD = \"page_token\"\n    _DEFAULT_RESPONSE_TOKEN_FIELD = \"next_page_token\"\n\n    def __init__(\n        self,\n        client,\n        method,\n        request,\n        items_field,\n        item_to_value=_item_to_value_identity,\n        request_token_field=_DEFAULT_REQUEST_TOKEN_FIELD,\n        response_token_field=_DEFAULT_RESPONSE_TOKEN_FIELD,\n        max_results=None,\n    ):\n        super().__init__(client, item_to_value, max_results=max_results)\n        self._method = method\n        self._request = request\n        self._items_field = items_field\n        self._request_token_field = request_token_field\n        self._response_token_field = response_token_field\n\n    async def _next_page(self):\n        \"\"\"Get the next page in the iterator.\n\n        Returns:\n            Page: The next page in the iterator or :data:`None` if\n                there are no pages left.\n        \"\"\"\n        if not self._has_next_page():\n            return None\n\n        if self.next_page_token is not None:\n            setattr(self._request, self._request_token_field, self.next_page_token)\n\n        response = await self._method(self._request)\n\n        self.next_page_token = getattr(response, self._response_token_field)\n        items = getattr(response, self._items_field)\n        page = Page(self, items, self.item_to_value, raw_page=response)\n\n        return page\n\n    def _has_next_page(self):\n        \"\"\"Determines whether or not there are more pages with results.\n\n        Returns:\n            bool: Whether the iterator has more pages.\n        \"\"\"\n        if self.page_number == 0:\n            return True\n\n        # Note: intentionally a falsy check instead of a None check. The RPC\n        # can return an empty string indicating no more pages.\n        if self.max_results is not None:\n            if self.num_results >= self.max_results:\n                return False\n\n        return True if self.next_page_token else False\n", "google/api_core/client_info.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Helpers for providing client information.\n\nClient information is used to send information about the calling client,\nsuch as the library and Python version, to API services.\n\"\"\"\n\nimport platform\nfrom typing import Union\n\nfrom google.api_core import version as api_core_version\n\n_PY_VERSION = platform.python_version()\n_API_CORE_VERSION = api_core_version.__version__\n\n_GRPC_VERSION: Union[str, None]\n\ntry:\n    import grpc\n\n    _GRPC_VERSION = grpc.__version__\nexcept ImportError:  # pragma: NO COVER\n    _GRPC_VERSION = None\n\n\nclass ClientInfo(object):\n    \"\"\"Client information used to generate a user-agent for API calls.\n\n    This user-agent information is sent along with API calls to allow the\n    receiving service to do analytics on which versions of Python and Google\n    libraries are being used.\n\n    Args:\n        python_version (str): The Python interpreter version, for example,\n            ``'3.9.6'``.\n        grpc_version (Optional[str]): The gRPC library version.\n        api_core_version (str): The google-api-core library version.\n        gapic_version (Optional[str]): The version of gapic-generated client\n            library, if the library was generated by gapic.\n        client_library_version (Optional[str]): The version of the client\n            library, generally used if the client library was not generated\n            by gapic or if additional functionality was built on top of\n            a gapic client library.\n        user_agent (Optional[str]): Prefix to the user agent header. This is\n            used to supply information such as application name or partner tool.\n            Recommended format: ``application-or-tool-ID/major.minor.version``.\n        rest_version (Optional[str]): The requests library version.\n    \"\"\"\n\n    def __init__(\n        self,\n        python_version=_PY_VERSION,\n        grpc_version=_GRPC_VERSION,\n        api_core_version=_API_CORE_VERSION,\n        gapic_version=None,\n        client_library_version=None,\n        user_agent=None,\n        rest_version=None,\n    ):\n        self.python_version = python_version\n        self.grpc_version = grpc_version\n        self.api_core_version = api_core_version\n        self.gapic_version = gapic_version\n        self.client_library_version = client_library_version\n        self.user_agent = user_agent\n        self.rest_version = rest_version\n\n    def to_user_agent(self):\n        \"\"\"Returns the user-agent string for this client info.\"\"\"\n\n        # Note: the order here is important as the internal metrics system\n        # expects these items to be in specific locations.\n        ua = \"\"\n\n        if self.user_agent is not None:\n            ua += \"{user_agent} \"\n\n        ua += \"gl-python/{python_version} \"\n\n        if self.grpc_version is not None:\n            ua += \"grpc/{grpc_version} \"\n\n        if self.rest_version is not None:\n            ua += \"rest/{rest_version} \"\n\n        ua += \"gax/{api_core_version} \"\n\n        if self.gapic_version is not None:\n            ua += \"gapic/{gapic_version} \"\n\n        if self.client_library_version is not None:\n            ua += \"gccl/{client_library_version} \"\n\n        return ua.format(**self.__dict__).strip()\n", "google/api_core/extended_operation.py": "# Copyright 2022 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Futures for extended long-running operations returned from Google Cloud APIs.\n\nThese futures can be used to synchronously wait for the result of a\nlong-running operations using :meth:`ExtendedOperation.result`:\n\n.. code-block:: python\n\n    extended_operation = my_api_client.long_running_method()\n\n    extended_operation.result()\n\nOr asynchronously using callbacks and :meth:`Operation.add_done_callback`:\n\n.. code-block:: python\n\n    extended_operation = my_api_client.long_running_method()\n\n    def my_callback(ex_op):\n        print(f\"Operation {ex_op.name} completed\")\n\n    extended_operation.add_done_callback(my_callback)\n\n\"\"\"\n\nimport threading\n\nfrom google.api_core import exceptions\nfrom google.api_core.future import polling\n\n\nclass ExtendedOperation(polling.PollingFuture):\n    \"\"\"An ExtendedOperation future for interacting with a Google API Long-Running Operation.\n\n    Args:\n        extended_operation (proto.Message): The initial operation.\n        refresh (Callable[[], type(extended_operation)]): A callable that returns\n            the latest state of the operation.\n        cancel (Callable[[], None]): A callable that tries to cancel the operation.\n        polling Optional(google.api_core.retry.Retry): The configuration used\n            for polling. This can be used to control how often :meth:`done`\n            is polled. If the ``timeout`` argument to :meth:`result` is\n            specified it will override the ``polling.timeout`` property.\n        retry Optional(google.api_core.retry.Retry): DEPRECATED use ``polling``\n            instead. If specified it will override ``polling`` parameter to\n            maintain backward compatibility.\n\n    Note: Most long-running API methods use google.api_core.operation.Operation\n    This class is a wrapper for a subset of methods that use alternative\n    Long-Running Operation (LRO) semantics.\n\n    Note: there is not a concrete type the extended operation must be.\n    It MUST have fields that correspond to the following, POSSIBLY WITH DIFFERENT NAMES:\n    * name: str\n    * status: Union[str, bool, enum.Enum]\n    * error_code: int\n    * error_message: str\n    \"\"\"\n\n    def __init__(\n        self,\n        extended_operation,\n        refresh,\n        cancel,\n        polling=polling.DEFAULT_POLLING,\n        **kwargs,\n    ):\n        super().__init__(polling=polling, **kwargs)\n        self._extended_operation = extended_operation\n        self._refresh = refresh\n        self._cancel = cancel\n        # Note: the extended operation does not give a good way to indicate cancellation.\n        # We make do with manually tracking cancellation and checking for doneness.\n        self._cancelled = False\n        self._completion_lock = threading.Lock()\n        # Invoke in case the operation came back already complete.\n        self._handle_refreshed_operation()\n\n    # Note: the following four properties MUST be overridden in a subclass\n    # if, and only if, the fields in the corresponding extended operation message\n    # have different names.\n    #\n    # E.g. we have an extended operation class that looks like\n    #\n    # class MyOperation(proto.Message):\n    #     moniker = proto.Field(proto.STRING, number=1)\n    #     status_msg = proto.Field(proto.STRING, number=2)\n    #     optional http_error_code = proto.Field(proto.INT32, number=3)\n    #     optional http_error_msg = proto.Field(proto.STRING, number=4)\n    #\n    # the ExtendedOperation subclass would provide property overrides that map\n    # to these (poorly named) fields.\n    @property\n    def name(self):\n        return self._extended_operation.name\n\n    @property\n    def status(self):\n        return self._extended_operation.status\n\n    @property\n    def error_code(self):\n        return self._extended_operation.error_code\n\n    @property\n    def error_message(self):\n        return self._extended_operation.error_message\n\n    def __getattr__(self, name):\n        return getattr(self._extended_operation, name)\n\n    def done(self, retry=None):\n        self._refresh_and_update(retry)\n        return self._extended_operation.done\n\n    def cancel(self):\n        if self.done():\n            return False\n\n        self._cancel()\n        self._cancelled = True\n        return True\n\n    def cancelled(self):\n        # TODO(dovs): there is not currently a good way to determine whether the\n        # operation has been cancelled.\n        # The best we can do is manually keep track of cancellation\n        # and check for doneness.\n        if not self._cancelled:\n            return False\n\n        self._refresh_and_update()\n        return self._extended_operation.done\n\n    def _refresh_and_update(self, retry=None):\n        if not self._extended_operation.done:\n            self._extended_operation = (\n                self._refresh(retry=retry) if retry else self._refresh()\n            )\n            self._handle_refreshed_operation()\n\n    def _handle_refreshed_operation(self):\n        with self._completion_lock:\n            if not self._extended_operation.done:\n                return\n\n            if self.error_code and self.error_message:\n                # Note: `errors` can be removed once proposal A from\n                # b/284179390 is implemented.\n                errors = []\n                if hasattr(self, \"error\") and hasattr(self.error, \"errors\"):\n                    errors = self.error.errors\n                exception = exceptions.from_http_status(\n                    status_code=self.error_code,\n                    message=self.error_message,\n                    response=self._extended_operation,\n                    errors=errors,\n                )\n                self.set_exception(exception)\n            elif self.error_code or self.error_message:\n                exception = exceptions.GoogleAPICallError(\n                    f\"Unexpected error {self.error_code}: {self.error_message}\"\n                )\n                self.set_exception(exception)\n            else:\n                # Extended operations have no payload.\n                self.set_result(None)\n\n    @classmethod\n    def make(cls, refresh, cancel, extended_operation, **kwargs):\n        \"\"\"\n        Return an instantiated ExtendedOperation (or child) that wraps\n        * a refresh callable\n        * a cancel callable (can be a no-op)\n        * an initial result\n\n        .. note::\n            It is the caller's responsibility to set up refresh and cancel\n            with their correct request argument.\n            The reason for this is that the services that use Extended Operations\n            have rpcs that look something like the following:\n\n            // service.proto\n            service MyLongService {\n                rpc StartLongTask(StartLongTaskRequest) returns (ExtendedOperation) {\n                    option (google.cloud.operation_service) = \"CustomOperationService\";\n                }\n            }\n\n            service CustomOperationService {\n                rpc Get(GetOperationRequest) returns (ExtendedOperation) {\n                    option (google.cloud.operation_polling_method) = true;\n                }\n            }\n\n            Any info needed for the poll, e.g. a name, path params, etc.\n            is held in the request, which the initial client method is in a much\n            better position to make made because the caller made the initial request.\n\n            TL;DR: the caller sets up closures for refresh and cancel that carry\n            the properly configured requests.\n\n        Args:\n            refresh (Callable[Optional[Retry]][type(extended_operation)]): A callable that\n                returns the latest state of the operation.\n            cancel (Callable[][Any]): A callable that tries to cancel the operation\n                on a best effort basis.\n            extended_operation (Any): The initial response of the long running method.\n                See the docstring for ExtendedOperation.__init__ for requirements on\n                the type and fields of extended_operation\n        \"\"\"\n        return cls(extended_operation, refresh, cancel, **kwargs)\n", "google/api_core/general_helpers.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# This import for backward compatibility only.\nfrom functools import wraps  # noqa: F401 pragma: NO COVER\n", "google/api_core/version.py": "# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n__version__ = \"2.19.1\"\n", "google/api_core/datetime_helpers.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Helpers for :mod:`datetime`.\"\"\"\n\nimport calendar\nimport datetime\nimport re\n\nfrom google.protobuf import timestamp_pb2\n\n\n_UTC_EPOCH = datetime.datetime(1970, 1, 1, tzinfo=datetime.timezone.utc)\n_RFC3339_MICROS = \"%Y-%m-%dT%H:%M:%S.%fZ\"\n_RFC3339_NO_FRACTION = \"%Y-%m-%dT%H:%M:%S\"\n# datetime.strptime cannot handle nanosecond precision:  parse w/ regex\n_RFC3339_NANOS = re.compile(\n    r\"\"\"\n    (?P<no_fraction>\n        \\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}  # YYYY-MM-DDTHH:MM:SS\n    )\n    (                                        # Optional decimal part\n     \\.                                      # decimal point\n     (?P<nanos>\\d{1,9})                      # nanoseconds, maybe truncated\n    )?\n    Z                                        # Zulu\n\"\"\",\n    re.VERBOSE,\n)\n\n\ndef utcnow():\n    \"\"\"A :meth:`datetime.datetime.utcnow()` alias to allow mocking in tests.\"\"\"\n    return datetime.datetime.now(tz=datetime.timezone.utc).replace(tzinfo=None)\n\n\ndef to_milliseconds(value):\n    \"\"\"Convert a zone-aware datetime to milliseconds since the unix epoch.\n\n    Args:\n        value (datetime.datetime): The datetime to covert.\n\n    Returns:\n        int: Milliseconds since the unix epoch.\n    \"\"\"\n    micros = to_microseconds(value)\n    return micros // 1000\n\n\ndef from_microseconds(value):\n    \"\"\"Convert timestamp in microseconds since the unix epoch to datetime.\n\n    Args:\n        value (float): The timestamp to convert, in microseconds.\n\n    Returns:\n        datetime.datetime: The datetime object equivalent to the timestamp in\n            UTC.\n    \"\"\"\n    return _UTC_EPOCH + datetime.timedelta(microseconds=value)\n\n\ndef to_microseconds(value):\n    \"\"\"Convert a datetime to microseconds since the unix epoch.\n\n    Args:\n        value (datetime.datetime): The datetime to covert.\n\n    Returns:\n        int: Microseconds since the unix epoch.\n    \"\"\"\n    if not value.tzinfo:\n        value = value.replace(tzinfo=datetime.timezone.utc)\n    # Regardless of what timezone is on the value, convert it to UTC.\n    value = value.astimezone(datetime.timezone.utc)\n    # Convert the datetime to a microsecond timestamp.\n    return int(calendar.timegm(value.timetuple()) * 1e6) + value.microsecond\n\n\ndef from_iso8601_date(value):\n    \"\"\"Convert a ISO8601 date string to a date.\n\n    Args:\n        value (str): The ISO8601 date string.\n\n    Returns:\n        datetime.date: A date equivalent to the date string.\n    \"\"\"\n    return datetime.datetime.strptime(value, \"%Y-%m-%d\").date()\n\n\ndef from_iso8601_time(value):\n    \"\"\"Convert a zoneless ISO8601 time string to a time.\n\n    Args:\n        value (str): The ISO8601 time string.\n\n    Returns:\n        datetime.time: A time equivalent to the time string.\n    \"\"\"\n    return datetime.datetime.strptime(value, \"%H:%M:%S\").time()\n\n\ndef from_rfc3339(value):\n    \"\"\"Convert an RFC3339-format timestamp to a native datetime.\n\n    Supported formats include those without fractional seconds, or with\n    any fraction up to nanosecond precision.\n\n    .. note::\n        Python datetimes do not support nanosecond precision; this function\n        therefore truncates such values to microseconds.\n\n    Args:\n        value (str): The RFC3339 string to convert.\n\n    Returns:\n        datetime.datetime: The datetime object equivalent to the timestamp\n        in UTC.\n\n    Raises:\n        ValueError: If the timestamp does not match the RFC3339\n            regular expression.\n    \"\"\"\n    with_nanos = _RFC3339_NANOS.match(value)\n\n    if with_nanos is None:\n        raise ValueError(\n            \"Timestamp: {!r}, does not match pattern: {!r}\".format(\n                value, _RFC3339_NANOS.pattern\n            )\n        )\n\n    bare_seconds = datetime.datetime.strptime(\n        with_nanos.group(\"no_fraction\"), _RFC3339_NO_FRACTION\n    )\n    fraction = with_nanos.group(\"nanos\")\n\n    if fraction is None:\n        micros = 0\n    else:\n        scale = 9 - len(fraction)\n        nanos = int(fraction) * (10**scale)\n        micros = nanos // 1000\n\n    return bare_seconds.replace(microsecond=micros, tzinfo=datetime.timezone.utc)\n\n\nfrom_rfc3339_nanos = from_rfc3339  # from_rfc3339_nanos method was deprecated.\n\n\ndef to_rfc3339(value, ignore_zone=True):\n    \"\"\"Convert a datetime to an RFC3339 timestamp string.\n\n    Args:\n        value (datetime.datetime):\n            The datetime object to be converted to a string.\n        ignore_zone (bool): If True, then the timezone (if any) of the\n            datetime object is ignored and the datetime is treated as UTC.\n\n    Returns:\n        str: The RFC3339 formatted string representing the datetime.\n    \"\"\"\n    if not ignore_zone and value.tzinfo is not None:\n        # Convert to UTC and remove the time zone info.\n        value = value.replace(tzinfo=None) - value.utcoffset()\n\n    return value.strftime(_RFC3339_MICROS)\n\n\nclass DatetimeWithNanoseconds(datetime.datetime):\n    \"\"\"Track nanosecond in addition to normal datetime attrs.\n\n    Nanosecond can be passed only as a keyword argument.\n    \"\"\"\n\n    __slots__ = (\"_nanosecond\",)\n\n    # pylint: disable=arguments-differ\n    def __new__(cls, *args, **kw):\n        nanos = kw.pop(\"nanosecond\", 0)\n        if nanos > 0:\n            if \"microsecond\" in kw:\n                raise TypeError(\"Specify only one of 'microsecond' or 'nanosecond'\")\n            kw[\"microsecond\"] = nanos // 1000\n        inst = datetime.datetime.__new__(cls, *args, **kw)\n        inst._nanosecond = nanos or 0\n        return inst\n\n    # pylint: disable=arguments-differ\n\n    @property\n    def nanosecond(self):\n        \"\"\"Read-only: nanosecond precision.\"\"\"\n        return self._nanosecond\n\n    def rfc3339(self):\n        \"\"\"Return an RFC3339-compliant timestamp.\n\n        Returns:\n            (str): Timestamp string according to RFC3339 spec.\n        \"\"\"\n        if self._nanosecond == 0:\n            return to_rfc3339(self)\n        nanos = str(self._nanosecond).rjust(9, \"0\").rstrip(\"0\")\n        return \"{}.{}Z\".format(self.strftime(_RFC3339_NO_FRACTION), nanos)\n\n    @classmethod\n    def from_rfc3339(cls, stamp):\n        \"\"\"Parse RFC3339-compliant timestamp, preserving nanoseconds.\n\n        Args:\n            stamp (str): RFC3339 stamp, with up to nanosecond precision\n\n        Returns:\n            :class:`DatetimeWithNanoseconds`:\n                an instance matching the timestamp string\n\n        Raises:\n            ValueError: if `stamp` does not match the expected format\n        \"\"\"\n        with_nanos = _RFC3339_NANOS.match(stamp)\n        if with_nanos is None:\n            raise ValueError(\n                \"Timestamp: {}, does not match pattern: {}\".format(\n                    stamp, _RFC3339_NANOS.pattern\n                )\n            )\n        bare = datetime.datetime.strptime(\n            with_nanos.group(\"no_fraction\"), _RFC3339_NO_FRACTION\n        )\n        fraction = with_nanos.group(\"nanos\")\n        if fraction is None:\n            nanos = 0\n        else:\n            scale = 9 - len(fraction)\n            nanos = int(fraction) * (10**scale)\n        return cls(\n            bare.year,\n            bare.month,\n            bare.day,\n            bare.hour,\n            bare.minute,\n            bare.second,\n            nanosecond=nanos,\n            tzinfo=datetime.timezone.utc,\n        )\n\n    def timestamp_pb(self):\n        \"\"\"Return a timestamp message.\n\n        Returns:\n            (:class:`~google.protobuf.timestamp_pb2.Timestamp`): Timestamp message\n        \"\"\"\n        inst = (\n            self\n            if self.tzinfo is not None\n            else self.replace(tzinfo=datetime.timezone.utc)\n        )\n        delta = inst - _UTC_EPOCH\n        seconds = int(delta.total_seconds())\n        nanos = self._nanosecond or self.microsecond * 1000\n        return timestamp_pb2.Timestamp(seconds=seconds, nanos=nanos)\n\n    @classmethod\n    def from_timestamp_pb(cls, stamp):\n        \"\"\"Parse RFC3339-compliant timestamp, preserving nanoseconds.\n\n        Args:\n            stamp (:class:`~google.protobuf.timestamp_pb2.Timestamp`): timestamp message\n\n        Returns:\n            :class:`DatetimeWithNanoseconds`:\n                an instance matching the timestamp message\n        \"\"\"\n        microseconds = int(stamp.seconds * 1e6)\n        bare = from_microseconds(microseconds)\n        return cls(\n            bare.year,\n            bare.month,\n            bare.day,\n            bare.hour,\n            bare.minute,\n            bare.second,\n            nanosecond=stamp.nanos,\n            tzinfo=datetime.timezone.utc,\n        )\n", "google/api_core/timeout.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Decorators for applying timeout arguments to functions.\n\nThese decorators are used to wrap API methods to apply either a\nDeadline-dependent (recommended), constant (DEPRECATED) or exponential\n(DEPRECATED) timeout argument.\n\nFor example, imagine an API method that can take a while to return results,\nsuch as one that might block until a resource is ready:\n\n.. code-block:: python\n\n    def is_thing_ready(timeout=None):\n        response = requests.get('https://example.com/is_thing_ready')\n        response.raise_for_status()\n        return response.json()\n\nThis module allows a function like this to be wrapped so that timeouts are\nautomatically determined, for example:\n\n.. code-block:: python\n\n    timeout_ = timeout.ExponentialTimeout()\n    is_thing_ready_with_timeout = timeout_(is_thing_ready)\n\n    for n in range(10):\n        try:\n            is_thing_ready_with_timeout({'example': 'data'})\n        except:\n            pass\n\nIn this example the first call to ``is_thing_ready`` will have a relatively\nsmall timeout (like 1 second). If the resource is available and the request\ncompletes quickly, the loop exits. But, if the resource isn't yet available\nand the request times out, it'll be retried - this time with a larger timeout.\n\nIn the broader context these decorators are typically combined with\n:mod:`google.api_core.retry` to implement API methods with a signature that\nmatches ``api_method(request, timeout=None, retry=None)``.\n\"\"\"\n\nfrom __future__ import unicode_literals\n\nimport datetime\nimport functools\n\nfrom google.api_core import datetime_helpers\n\n_DEFAULT_INITIAL_TIMEOUT = 5.0  # seconds\n_DEFAULT_MAXIMUM_TIMEOUT = 30.0  # seconds\n_DEFAULT_TIMEOUT_MULTIPLIER = 2.0\n# If specified, must be in seconds. If none, deadline is not used in the\n# timeout calculation.\n_DEFAULT_DEADLINE = None\n\n\nclass TimeToDeadlineTimeout(object):\n    \"\"\"A decorator that decreases timeout set for an RPC based on how much time\n    has left till its deadline. The deadline is calculated as\n    ``now + initial_timeout`` when this decorator is first called for an rpc.\n\n    In other words this decorator implements deadline semantics in terms of a\n    sequence of decreasing timeouts t0 > t1 > t2 ... tn >= 0.\n\n    Args:\n        timeout (Optional[float]): the timeout (in seconds) to applied to the\n            wrapped function. If `None`, the target function is expected to\n            never timeout.\n    \"\"\"\n\n    def __init__(self, timeout=None, clock=datetime_helpers.utcnow):\n        self._timeout = timeout\n        self._clock = clock\n\n    def __call__(self, func):\n        \"\"\"Apply the timeout decorator.\n\n        Args:\n            func (Callable): The function to apply the timeout argument to.\n                This function must accept a timeout keyword argument.\n\n        Returns:\n            Callable: The wrapped function.\n        \"\"\"\n\n        first_attempt_timestamp = self._clock().timestamp()\n\n        @functools.wraps(func)\n        def func_with_timeout(*args, **kwargs):\n            \"\"\"Wrapped function that adds timeout.\"\"\"\n\n            remaining_timeout = self._timeout\n            if remaining_timeout is not None:\n                # All calculations are in seconds\n                now_timestamp = self._clock().timestamp()\n\n                # To avoid usage of nonlocal but still have round timeout\n                # numbers for first attempt (in most cases the only attempt made\n                # for an RPC.\n                if now_timestamp - first_attempt_timestamp < 0.001:\n                    now_timestamp = first_attempt_timestamp\n\n                time_since_first_attempt = now_timestamp - first_attempt_timestamp\n                # Avoid setting negative timeout\n                kwargs[\"timeout\"] = max(0, self._timeout - time_since_first_attempt)\n\n            return func(*args, **kwargs)\n\n        return func_with_timeout\n\n    def __str__(self):\n        return \"<TimeToDeadlineTimeout timeout={:.1f}>\".format(self._timeout)\n\n\nclass ConstantTimeout(object):\n    \"\"\"A decorator that adds a constant timeout argument.\n\n    DEPRECATED: use ``TimeToDeadlineTimeout`` instead.\n\n    This is effectively equivalent to\n    ``functools.partial(func, timeout=timeout)``.\n\n    Args:\n        timeout (Optional[float]): the timeout (in seconds) to applied to the\n            wrapped function. If `None`, the target function is expected to\n            never timeout.\n    \"\"\"\n\n    def __init__(self, timeout=None):\n        self._timeout = timeout\n\n    def __call__(self, func):\n        \"\"\"Apply the timeout decorator.\n\n        Args:\n            func (Callable): The function to apply the timeout argument to.\n                This function must accept a timeout keyword argument.\n\n        Returns:\n            Callable: The wrapped function.\n        \"\"\"\n\n        @functools.wraps(func)\n        def func_with_timeout(*args, **kwargs):\n            \"\"\"Wrapped function that adds timeout.\"\"\"\n            kwargs[\"timeout\"] = self._timeout\n            return func(*args, **kwargs)\n\n        return func_with_timeout\n\n    def __str__(self):\n        return \"<ConstantTimeout timeout={:.1f}>\".format(self._timeout)\n\n\ndef _exponential_timeout_generator(initial, maximum, multiplier, deadline):\n    \"\"\"A generator that yields exponential timeout values.\n\n    Args:\n        initial (float): The initial timeout.\n        maximum (float): The maximum timeout.\n        multiplier (float): The multiplier applied to the timeout.\n        deadline (float): The overall deadline across all invocations.\n\n    Yields:\n        float: A timeout value.\n    \"\"\"\n    if deadline is not None:\n        deadline_datetime = datetime_helpers.utcnow() + datetime.timedelta(\n            seconds=deadline\n        )\n    else:\n        deadline_datetime = datetime.datetime.max\n\n    timeout = initial\n    while True:\n        now = datetime_helpers.utcnow()\n        yield min(\n            # The calculated timeout based on invocations.\n            timeout,\n            # The set maximum timeout.\n            maximum,\n            # The remaining time before the deadline is reached.\n            float((deadline_datetime - now).seconds),\n        )\n        timeout = timeout * multiplier\n\n\nclass ExponentialTimeout(object):\n    \"\"\"A decorator that adds an exponentially increasing timeout argument.\n\n    DEPRECATED: the concept of incrementing timeout exponentially has been\n    deprecated. Use ``TimeToDeadlineTimeout`` instead.\n\n    This is useful if a function is called multiple times. Each time the\n    function is called this decorator will calculate a new timeout parameter\n    based on the the number of times the function has been called.\n\n    For example\n\n    .. code-block:: python\n\n    Args:\n        initial (float): The initial timeout to pass.\n        maximum (float): The maximum timeout for any one call.\n        multiplier (float): The multiplier applied to the timeout for each\n            invocation.\n        deadline (Optional[float]): The overall deadline across all\n            invocations. This is used to prevent a very large calculated\n            timeout from pushing the overall execution time over the deadline.\n            This is especially useful in conjunction with\n            :mod:`google.api_core.retry`. If ``None``, the timeouts will not\n            be adjusted to accommodate an overall deadline.\n    \"\"\"\n\n    def __init__(\n        self,\n        initial=_DEFAULT_INITIAL_TIMEOUT,\n        maximum=_DEFAULT_MAXIMUM_TIMEOUT,\n        multiplier=_DEFAULT_TIMEOUT_MULTIPLIER,\n        deadline=_DEFAULT_DEADLINE,\n    ):\n        self._initial = initial\n        self._maximum = maximum\n        self._multiplier = multiplier\n        self._deadline = deadline\n\n    def with_deadline(self, deadline):\n        \"\"\"Return a copy of this timeout with the given deadline.\n\n        Args:\n            deadline (float): The overall deadline across all invocations.\n\n        Returns:\n            ExponentialTimeout: A new instance with the given deadline.\n        \"\"\"\n        return ExponentialTimeout(\n            initial=self._initial,\n            maximum=self._maximum,\n            multiplier=self._multiplier,\n            deadline=deadline,\n        )\n\n    def __call__(self, func):\n        \"\"\"Apply the timeout decorator.\n\n        Args:\n            func (Callable): The function to apply the timeout argument to.\n                This function must accept a timeout keyword argument.\n\n        Returns:\n            Callable: The wrapped function.\n        \"\"\"\n        timeouts = _exponential_timeout_generator(\n            self._initial, self._maximum, self._multiplier, self._deadline\n        )\n\n        @functools.wraps(func)\n        def func_with_timeout(*args, **kwargs):\n            \"\"\"Wrapped function that adds timeout.\"\"\"\n            kwargs[\"timeout\"] = next(timeouts)\n            return func(*args, **kwargs)\n\n        return func_with_timeout\n\n    def __str__(self):\n        return (\n            \"<ExponentialTimeout initial={:.1f}, maximum={:.1f}, \"\n            \"multiplier={:.1f}, deadline={:.1f}>\".format(\n                self._initial, self._maximum, self._multiplier, self._deadline\n            )\n        )\n", "google/api_core/rest_streaming.py": "# Copyright 2021 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Helpers for server-side streaming in REST.\"\"\"\n\nfrom collections import deque\nimport string\nfrom typing import Deque, Union\n\nimport proto\nimport requests\nimport google.protobuf.message\nfrom google.protobuf.json_format import Parse\n\n\nclass ResponseIterator:\n    \"\"\"Iterator over REST API responses.\n\n    Args:\n        response (requests.Response): An API response object.\n        response_message_cls (Union[proto.Message, google.protobuf.message.Message]): A response\n        class expected to be returned from an API.\n\n    Raises:\n        ValueError: If `response_message_cls` is not a subclass of `proto.Message` or `google.protobuf.message.Message`.\n    \"\"\"\n\n    def __init__(\n        self,\n        response: requests.Response,\n        response_message_cls: Union[proto.Message, google.protobuf.message.Message],\n    ):\n        self._response = response\n        self._response_message_cls = response_message_cls\n        # Inner iterator over HTTP response's content.\n        self._response_itr = self._response.iter_content(decode_unicode=True)\n        # Contains a list of JSON responses ready to be sent to user.\n        self._ready_objs: Deque[str] = deque()\n        # Current JSON response being built.\n        self._obj = \"\"\n        # Keeps track of the nesting level within a JSON object.\n        self._level = 0\n        # Keeps track whether HTTP response is currently sending values\n        # inside of a string value.\n        self._in_string = False\n        # Whether an escape symbol \"\\\" was encountered.\n        self._escape_next = False\n\n    def cancel(self):\n        \"\"\"Cancel existing streaming operation.\"\"\"\n        self._response.close()\n\n    def _process_chunk(self, chunk: str):\n        if self._level == 0:\n            if chunk[0] != \"[\":\n                raise ValueError(\n                    \"Can only parse array of JSON objects, instead got %s\" % chunk\n                )\n        for char in chunk:\n            if char == \"{\":\n                if self._level == 1:\n                    # Level 1 corresponds to the outermost JSON object\n                    # (i.e. the one we care about).\n                    self._obj = \"\"\n                if not self._in_string:\n                    self._level += 1\n                self._obj += char\n            elif char == \"}\":\n                self._obj += char\n                if not self._in_string:\n                    self._level -= 1\n                if not self._in_string and self._level == 1:\n                    self._ready_objs.append(self._obj)\n            elif char == '\"':\n                # Helps to deal with an escaped quotes inside of a string.\n                if not self._escape_next:\n                    self._in_string = not self._in_string\n                self._obj += char\n            elif char in string.whitespace:\n                if self._in_string:\n                    self._obj += char\n            elif char == \"[\":\n                if self._level == 0:\n                    self._level += 1\n                else:\n                    self._obj += char\n            elif char == \"]\":\n                if self._level == 1:\n                    self._level -= 1\n                else:\n                    self._obj += char\n            else:\n                self._obj += char\n            self._escape_next = not self._escape_next if char == \"\\\\\" else False\n\n    def __next__(self):\n        while not self._ready_objs:\n            try:\n                chunk = next(self._response_itr)\n                self._process_chunk(chunk)\n            except StopIteration as e:\n                if self._level > 0:\n                    raise ValueError(\"Unfinished stream: %s\" % self._obj)\n                raise e\n        return self._grab()\n\n    def _grab(self):\n        # Add extra quotes to make json.loads happy.\n        if issubclass(self._response_message_cls, proto.Message):\n            return self._response_message_cls.from_json(\n                self._ready_objs.popleft(), ignore_unknown_fields=True\n            )\n        elif issubclass(self._response_message_cls, google.protobuf.message.Message):\n            return Parse(self._ready_objs.popleft(), self._response_message_cls())\n        else:\n            raise ValueError(\n                \"Response message class must be a subclass of proto.Message or google.protobuf.message.Message.\"\n            )\n\n    def __iter__(self):\n        return self\n", "google/api_core/client_options.py": "# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Client options class.\n\nClient options provide a consistent interface for user options to be defined\nacross clients.\n\nYou can pass a client options object to a client.\n\n.. code-block:: python\n\n    from google.api_core.client_options import ClientOptions\n    from google.cloud.vision_v1 import ImageAnnotatorClient\n\n    def get_client_cert():\n        # code to load client certificate and private key.\n        return client_cert_bytes, client_private_key_bytes\n\n    options = ClientOptions(api_endpoint=\"foo.googleapis.com\",\n        client_cert_source=get_client_cert)\n\n    client = ImageAnnotatorClient(client_options=options)\n\nYou can also pass a mapping object.\n\n.. code-block:: python\n\n    from google.cloud.vision_v1 import ImageAnnotatorClient\n\n    client = ImageAnnotatorClient(\n        client_options={\n            \"api_endpoint\": \"foo.googleapis.com\",\n            \"client_cert_source\" : get_client_cert\n        })\n\n\n\"\"\"\n\n\nclass ClientOptions(object):\n    \"\"\"Client Options used to set options on clients.\n\n    Args:\n        api_endpoint (Optional[str]): The desired API endpoint, e.g.,\n            compute.googleapis.com\n        client_cert_source (Optional[Callable[[], (bytes, bytes)]]): A callback\n            which returns client certificate bytes and private key bytes both in\n            PEM format. ``client_cert_source`` and ``client_encrypted_cert_source``\n            are mutually exclusive.\n        client_encrypted_cert_source (Optional[Callable[[], (str, str, bytes)]]):\n            A callback which returns client certificate file path, encrypted\n            private key file path, and the passphrase bytes.``client_cert_source``\n            and ``client_encrypted_cert_source`` are mutually exclusive.\n        quota_project_id (Optional[str]): A project name that a client's\n            quota belongs to.\n        credentials_file (Optional[str]): A path to a file storing credentials.\n            ``credentials_file` and ``api_key`` are mutually exclusive.\n        scopes (Optional[Sequence[str]]): OAuth access token override scopes.\n        api_key (Optional[str]): Google API key. ``credentials_file`` and\n            ``api_key`` are mutually exclusive.\n        api_audience (Optional[str]): The intended audience for the API calls\n            to the service that will be set when using certain 3rd party\n            authentication flows. Audience is typically a resource identifier.\n            If not set, the service endpoint value will be used as a default.\n            An example of a valid ``api_audience`` is: \"https://language.googleapis.com\".\n        universe_domain (Optional[str]): The desired universe domain. This must match\n            the one in credentials. If not set, the default universe domain is\n            `googleapis.com`. If both `api_endpoint` and `universe_domain` are set,\n            then `api_endpoint` is used as the service endpoint. If `api_endpoint` is\n            not specified, the format will be `{service}.{universe_domain}`.\n\n    Raises:\n        ValueError: If both ``client_cert_source`` and ``client_encrypted_cert_source``\n            are provided, or both ``credentials_file`` and ``api_key`` are provided.\n    \"\"\"\n\n    def __init__(\n        self,\n        api_endpoint=None,\n        client_cert_source=None,\n        client_encrypted_cert_source=None,\n        quota_project_id=None,\n        credentials_file=None,\n        scopes=None,\n        api_key=None,\n        api_audience=None,\n        universe_domain=None,\n    ):\n        if client_cert_source and client_encrypted_cert_source:\n            raise ValueError(\n                \"client_cert_source and client_encrypted_cert_source are mutually exclusive\"\n            )\n        if api_key and credentials_file:\n            raise ValueError(\"api_key and credentials_file are mutually exclusive\")\n        self.api_endpoint = api_endpoint\n        self.client_cert_source = client_cert_source\n        self.client_encrypted_cert_source = client_encrypted_cert_source\n        self.quota_project_id = quota_project_id\n        self.credentials_file = credentials_file\n        self.scopes = scopes\n        self.api_key = api_key\n        self.api_audience = api_audience\n        self.universe_domain = universe_domain\n\n    def __repr__(self):\n        return \"ClientOptions: \" + repr(self.__dict__)\n\n\ndef from_dict(options):\n    \"\"\"Construct a client options object from a mapping object.\n\n    Args:\n        options (collections.abc.Mapping): A mapping object with client options.\n            See the docstring for ClientOptions for details on valid arguments.\n    \"\"\"\n\n    client_options = ClientOptions()\n\n    for key, value in options.items():\n        if hasattr(client_options, key):\n            setattr(client_options, key, value)\n        else:\n            raise ValueError(\"ClientOptions does not accept an option '\" + key + \"'\")\n\n    return client_options\n", "google/api_core/retry_async.py": "# Copyright 2024 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# The following imports are for backwards compatibility with https://github.com/googleapis/python-api-core/blob/4d7d2edee2c108d43deb151e6e0fdceb56b73275/google/api_core/retry_async.py\n#\n# TODO: Revert these imports on the next major version release (https://github.com/googleapis/python-api-core/issues/576)\nfrom google.api_core import datetime_helpers  # noqa: F401\nfrom google.api_core import exceptions  # noqa: F401\nfrom google.api_core.retry import exponential_sleep_generator  # noqa: F401\nfrom google.api_core.retry import if_exception_type  # noqa: F401\nfrom google.api_core.retry import if_transient_error  # noqa: F401\nfrom google.api_core.retry.retry_unary_async import AsyncRetry\nfrom google.api_core.retry.retry_unary_async import retry_target\n\n__all__ = (\n    \"AsyncRetry\",\n    \"datetime_helpers\",\n    \"exceptions\",\n    \"exponential_sleep_generator\",\n    \"if_exception_type\",\n    \"if_transient_error\",\n    \"retry_target\",\n)\n", "google/api_core/operation_async.py": "# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"AsyncIO futures for long-running operations returned from Google Cloud APIs.\n\nThese futures can be used to await for the result of a long-running operation\nusing :meth:`AsyncOperation.result`:\n\n\n.. code-block:: python\n\n    operation = my_api_client.long_running_method()\n    result = await operation.result()\n\nOr asynchronously using callbacks and :meth:`Operation.add_done_callback`:\n\n.. code-block:: python\n\n    operation = my_api_client.long_running_method()\n\n    def my_callback(future):\n        result = await future.result()\n\n    operation.add_done_callback(my_callback)\n\n\"\"\"\n\nimport functools\nimport threading\n\nfrom google.api_core import exceptions\nfrom google.api_core import protobuf_helpers\nfrom google.api_core.future import async_future\nfrom google.longrunning import operations_pb2\nfrom google.rpc import code_pb2\n\n\nclass AsyncOperation(async_future.AsyncFuture):\n    \"\"\"A Future for interacting with a Google API Long-Running Operation.\n\n    Args:\n        operation (google.longrunning.operations_pb2.Operation): The\n            initial operation.\n        refresh (Callable[[], ~.api_core.operation.Operation]): A callable that\n            returns the latest state of the operation.\n        cancel (Callable[[], None]): A callable that tries to cancel\n            the operation.\n        result_type (func:`type`): The protobuf type for the operation's\n            result.\n        metadata_type (func:`type`): The protobuf type for the operation's\n            metadata.\n        retry (google.api_core.retry.Retry): The retry configuration used\n            when polling. This can be used to control how often :meth:`done`\n            is polled. Regardless of the retry's ``deadline``, it will be\n            overridden by the ``timeout`` argument to :meth:`result`.\n    \"\"\"\n\n    def __init__(\n        self,\n        operation,\n        refresh,\n        cancel,\n        result_type,\n        metadata_type=None,\n        retry=async_future.DEFAULT_RETRY,\n    ):\n        super().__init__(retry=retry)\n        self._operation = operation\n        self._refresh = refresh\n        self._cancel = cancel\n        self._result_type = result_type\n        self._metadata_type = metadata_type\n        self._completion_lock = threading.Lock()\n        # Invoke this in case the operation came back already complete.\n        self._set_result_from_operation()\n\n    @property\n    def operation(self):\n        \"\"\"google.longrunning.Operation: The current long-running operation.\"\"\"\n        return self._operation\n\n    @property\n    def metadata(self):\n        \"\"\"google.protobuf.Message: the current operation metadata.\"\"\"\n        if not self._operation.HasField(\"metadata\"):\n            return None\n\n        return protobuf_helpers.from_any_pb(\n            self._metadata_type, self._operation.metadata\n        )\n\n    @classmethod\n    def deserialize(cls, payload):\n        \"\"\"Deserialize a ``google.longrunning.Operation`` protocol buffer.\n\n        Args:\n            payload (bytes): A serialized operation protocol buffer.\n\n        Returns:\n            ~.operations_pb2.Operation: An Operation protobuf object.\n        \"\"\"\n        return operations_pb2.Operation.FromString(payload)\n\n    def _set_result_from_operation(self):\n        \"\"\"Set the result or exception from the operation if it is complete.\"\"\"\n        # This must be done in a lock to prevent the async_future thread\n        # and main thread from both executing the completion logic\n        # at the same time.\n        with self._completion_lock:\n            # If the operation isn't complete or if the result has already been\n            # set, do not call set_result/set_exception again.\n            if not self._operation.done or self._future.done():\n                return\n\n            if self._operation.HasField(\"response\"):\n                response = protobuf_helpers.from_any_pb(\n                    self._result_type, self._operation.response\n                )\n                self.set_result(response)\n            elif self._operation.HasField(\"error\"):\n                exception = exceptions.GoogleAPICallError(\n                    self._operation.error.message,\n                    errors=(self._operation.error,),\n                    response=self._operation,\n                )\n                self.set_exception(exception)\n            else:\n                exception = exceptions.GoogleAPICallError(\n                    \"Unexpected state: Long-running operation had neither \"\n                    \"response nor error set.\"\n                )\n                self.set_exception(exception)\n\n    async def _refresh_and_update(self, retry=async_future.DEFAULT_RETRY):\n        \"\"\"Refresh the operation and update the result if needed.\n\n        Args:\n            retry (google.api_core.retry.Retry): (Optional) How to retry the RPC.\n        \"\"\"\n        # If the currently cached operation is done, no need to make another\n        # RPC as it will not change once done.\n        if not self._operation.done:\n            self._operation = await self._refresh(retry=retry)\n            self._set_result_from_operation()\n\n    async def done(self, retry=async_future.DEFAULT_RETRY):\n        \"\"\"Checks to see if the operation is complete.\n\n        Args:\n            retry (google.api_core.retry.Retry): (Optional) How to retry the RPC.\n\n        Returns:\n            bool: True if the operation is complete, False otherwise.\n        \"\"\"\n        await self._refresh_and_update(retry)\n        return self._operation.done\n\n    async def cancel(self):\n        \"\"\"Attempt to cancel the operation.\n\n        Returns:\n            bool: True if the cancel RPC was made, False if the operation is\n                already complete.\n        \"\"\"\n        result = await self.done()\n        if result:\n            return False\n        else:\n            await self._cancel()\n            return True\n\n    async def cancelled(self):\n        \"\"\"True if the operation was cancelled.\"\"\"\n        await self._refresh_and_update()\n        return (\n            self._operation.HasField(\"error\")\n            and self._operation.error.code == code_pb2.CANCELLED\n        )\n\n\ndef from_gapic(operation, operations_client, result_type, grpc_metadata=None, **kwargs):\n    \"\"\"Create an operation future from a gapic client.\n\n    This interacts with the long-running operations `service`_ (specific\n    to a given API) via a gapic client.\n\n    .. _service: https://github.com/googleapis/googleapis/blob/\\\n                 050400df0fdb16f63b63e9dee53819044bffc857/\\\n                 google/longrunning/operations.proto#L38\n\n    Args:\n        operation (google.longrunning.operations_pb2.Operation): The operation.\n        operations_client (google.api_core.operations_v1.OperationsClient):\n            The operations client.\n        result_type (:func:`type`): The protobuf result type.\n        grpc_metadata (Optional[List[Tuple[str, str]]]): Additional metadata to pass\n            to the rpc.\n        kwargs: Keyword args passed into the :class:`Operation` constructor.\n\n    Returns:\n        ~.api_core.operation.Operation: The operation future to track the given\n            operation.\n    \"\"\"\n    refresh = functools.partial(\n        operations_client.get_operation,\n        operation.name,\n        metadata=grpc_metadata,\n    )\n    cancel = functools.partial(\n        operations_client.cancel_operation,\n        operation.name,\n        metadata=grpc_metadata,\n    )\n    return AsyncOperation(operation, refresh, cancel, result_type, **kwargs)\n", "google/api_core/path_template.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Expand and validate URL path templates.\n\nThis module provides the :func:`expand` and :func:`validate` functions for\ninteracting with Google-style URL `path templates`_ which are commonly used\nin Google APIs for `resource names`_.\n\n.. _path templates: https://github.com/googleapis/googleapis/blob\n    /57e2d376ac7ef48681554204a3ba78a414f2c533/google/api/http.proto#L212\n.. _resource names: https://cloud.google.com/apis/design/resource_names\n\"\"\"\n\nfrom __future__ import unicode_literals\n\nfrom collections import deque\nimport copy\nimport functools\nimport re\n\n# Regular expression for extracting variable parts from a path template.\n# The variables can be expressed as:\n#\n# - \"*\": a single-segment positional variable, for example: \"books/*\"\n# - \"**\": a multi-segment positional variable, for example: \"shelf/**/book/*\"\n# - \"{name}\": a single-segment wildcard named variable, for example\n#   \"books/{name}\"\n# - \"{name=*}: same as above.\n# - \"{name=**}\": a multi-segment wildcard named variable, for example\n#   \"shelf/{name=**}\"\n# - \"{name=/path/*/**}\": a multi-segment named variable with a sub-template.\n_VARIABLE_RE = re.compile(\n    r\"\"\"\n    (  # Capture the entire variable expression\n        (?P<positional>\\*\\*?)  # Match & capture * and ** positional variables.\n        |\n        # Match & capture named variables {name}\n        {\n            (?P<name>[^/]+?)\n            # Optionally match and capture the named variable's template.\n            (?:=(?P<template>.+?))?\n        }\n    )\n    \"\"\",\n    re.VERBOSE,\n)\n\n# Segment expressions used for validating paths against a template.\n_SINGLE_SEGMENT_PATTERN = r\"([^/]+)\"\n_MULTI_SEGMENT_PATTERN = r\"(.+)\"\n\n\ndef _expand_variable_match(positional_vars, named_vars, match):\n    \"\"\"Expand a matched variable with its value.\n\n    Args:\n        positional_vars (list): A list of positional variables. This list will\n            be modified.\n        named_vars (dict): A dictionary of named variables.\n        match (re.Match): A regular expression match.\n\n    Returns:\n        str: The expanded variable to replace the match.\n\n    Raises:\n        ValueError: If a positional or named variable is required by the\n            template but not specified or if an unexpected template expression\n            is encountered.\n    \"\"\"\n    positional = match.group(\"positional\")\n    name = match.group(\"name\")\n    if name is not None:\n        try:\n            return str(named_vars[name])\n        except KeyError:\n            raise ValueError(\n                \"Named variable '{}' not specified and needed by template \"\n                \"`{}` at position {}\".format(name, match.string, match.start())\n            )\n    elif positional is not None:\n        try:\n            return str(positional_vars.pop(0))\n        except IndexError:\n            raise ValueError(\n                \"Positional variable not specified and needed by template \"\n                \"`{}` at position {}\".format(match.string, match.start())\n            )\n    else:\n        raise ValueError(\"Unknown template expression {}\".format(match.group(0)))\n\n\ndef expand(tmpl, *args, **kwargs):\n    \"\"\"Expand a path template with the given variables.\n\n    .. code-block:: python\n\n        >>> expand('users/*/messages/*', 'me', '123')\n        users/me/messages/123\n        >>> expand('/v1/{name=shelves/*/books/*}', name='shelves/1/books/3')\n        /v1/shelves/1/books/3\n\n    Args:\n        tmpl (str): The path template.\n        args: The positional variables for the path.\n        kwargs: The named variables for the path.\n\n    Returns:\n        str: The expanded path\n\n    Raises:\n        ValueError: If a positional or named variable is required by the\n            template but not specified or if an unexpected template expression\n            is encountered.\n    \"\"\"\n    replacer = functools.partial(_expand_variable_match, list(args), kwargs)\n    return _VARIABLE_RE.sub(replacer, tmpl)\n\n\ndef _replace_variable_with_pattern(match):\n    \"\"\"Replace a variable match with a pattern that can be used to validate it.\n\n    Args:\n        match (re.Match): A regular expression match\n\n    Returns:\n        str: A regular expression pattern that can be used to validate the\n            variable in an expanded path.\n\n    Raises:\n        ValueError: If an unexpected template expression is encountered.\n    \"\"\"\n    positional = match.group(\"positional\")\n    name = match.group(\"name\")\n    template = match.group(\"template\")\n    if name is not None:\n        if not template:\n            return _SINGLE_SEGMENT_PATTERN.format(name)\n        elif template == \"**\":\n            return _MULTI_SEGMENT_PATTERN.format(name)\n        else:\n            return _generate_pattern_for_template(template)\n    elif positional == \"*\":\n        return _SINGLE_SEGMENT_PATTERN\n    elif positional == \"**\":\n        return _MULTI_SEGMENT_PATTERN\n    else:\n        raise ValueError(\"Unknown template expression {}\".format(match.group(0)))\n\n\ndef _generate_pattern_for_template(tmpl):\n    \"\"\"Generate a pattern that can validate a path template.\n\n    Args:\n        tmpl (str): The path template\n\n    Returns:\n        str: A regular expression pattern that can be used to validate an\n            expanded path template.\n    \"\"\"\n    return _VARIABLE_RE.sub(_replace_variable_with_pattern, tmpl)\n\n\ndef get_field(request, field):\n    \"\"\"Get the value of a field from a given dictionary.\n\n    Args:\n        request (dict | Message): A dictionary or a Message object.\n        field (str): The key to the request in dot notation.\n\n    Returns:\n        The value of the field.\n    \"\"\"\n    parts = field.split(\".\")\n    value = request\n\n    for part in parts:\n        if not isinstance(value, dict):\n            value = getattr(value, part, None)\n        else:\n            value = value.get(part)\n    if isinstance(value, dict):\n        return\n    return value\n\n\ndef delete_field(request, field):\n    \"\"\"Delete the value of a field from a given dictionary.\n\n    Args:\n        request (dict | Message): A dictionary object or a Message.\n        field (str): The key to the request in dot notation.\n    \"\"\"\n    parts = deque(field.split(\".\"))\n    while len(parts) > 1:\n        part = parts.popleft()\n        if not isinstance(request, dict):\n            if hasattr(request, part):\n                request = getattr(request, part, None)\n            else:\n                return\n        else:\n            request = request.get(part)\n    part = parts.popleft()\n    if not isinstance(request, dict):\n        if hasattr(request, part):\n            request.ClearField(part)\n        else:\n            return\n    else:\n        request.pop(part, None)\n\n\ndef validate(tmpl, path):\n    \"\"\"Validate a path against the path template.\n\n    .. code-block:: python\n\n        >>> validate('users/*/messages/*', 'users/me/messages/123')\n        True\n        >>> validate('users/*/messages/*', 'users/me/drafts/123')\n        False\n        >>> validate('/v1/{name=shelves/*/books/*}', /v1/shelves/1/books/3)\n        True\n        >>> validate('/v1/{name=shelves/*/books/*}', /v1/shelves/1/tapes/3)\n        False\n\n    Args:\n        tmpl (str): The path template.\n        path (str): The expanded path.\n\n    Returns:\n        bool: True if the path matches.\n    \"\"\"\n    pattern = _generate_pattern_for_template(tmpl) + \"$\"\n    return True if re.match(pattern, path) is not None else False\n\n\ndef transcode(http_options, message=None, **request_kwargs):\n    \"\"\"Transcodes a grpc request pattern into a proper HTTP request following the rules outlined here,\n    https://github.com/googleapis/googleapis/blob/master/google/api/http.proto#L44-L312\n\n     Args:\n         http_options (list(dict)): A list of dicts which consist of these keys,\n             'method'    (str): The http method\n             'uri'       (str): The path template\n             'body'      (str): The body field name (optional)\n             (This is a simplified representation of the proto option `google.api.http`)\n\n         message (Message) : A request object (optional)\n         request_kwargs (dict) : A dict representing the request object\n\n     Returns:\n         dict: The transcoded request with these keys,\n             'method'        (str)   : The http method\n             'uri'           (str)   : The expanded uri\n             'body'          (dict | Message)  : A dict or a Message representing the body (optional)\n             'query_params'  (dict | Message)  : A dict or Message mapping query parameter variables and values\n\n     Raises:\n         ValueError: If the request does not match the given template.\n    \"\"\"\n    transcoded_value = message or request_kwargs\n    bindings = []\n    for http_option in http_options:\n        request = {}\n\n        # Assign path\n        uri_template = http_option[\"uri\"]\n        fields = [\n            (m.group(\"name\"), m.group(\"template\"))\n            for m in _VARIABLE_RE.finditer(uri_template)\n        ]\n        bindings.append((uri_template, fields))\n\n        path_args = {field: get_field(transcoded_value, field) for field, _ in fields}\n        request[\"uri\"] = expand(uri_template, **path_args)\n\n        if not validate(uri_template, request[\"uri\"]) or not all(path_args.values()):\n            continue\n\n        # Remove fields used in uri path from request\n        leftovers = copy.deepcopy(transcoded_value)\n        for path_field, _ in fields:\n            delete_field(leftovers, path_field)\n\n        # Assign body and query params\n        body = http_option.get(\"body\")\n\n        if body:\n            if body == \"*\":\n                request[\"body\"] = leftovers\n                if message:\n                    request[\"query_params\"] = message.__class__()\n                else:\n                    request[\"query_params\"] = {}\n            else:\n                try:\n                    if message:\n                        request[\"body\"] = getattr(leftovers, body)\n                        delete_field(leftovers, body)\n                    else:\n                        request[\"body\"] = leftovers.pop(body)\n                except (KeyError, AttributeError):\n                    continue\n                request[\"query_params\"] = leftovers\n        else:\n            request[\"query_params\"] = leftovers\n        request[\"method\"] = http_option[\"method\"]\n        return request\n\n    bindings_description = [\n        '\\n\\tURI: \"{}\"'\n        \"\\n\\tRequired request fields:\\n\\t\\t{}\".format(\n            uri,\n            \"\\n\\t\\t\".join(\n                [\n                    'field: \"{}\", pattern: \"{}\"'.format(n, p if p else \"*\")\n                    for n, p in fields\n                ]\n            ),\n        )\n        for uri, fields in bindings\n    ]\n\n    raise ValueError(\n        \"Invalid request.\"\n        \"\\nSome of the fields of the request message are either not initialized or \"\n        \"initialized with an invalid value.\"\n        \"\\nPlease make sure your request matches at least one accepted HTTP binding.\"\n        \"\\nTo match a binding the request message must have all the required fields \"\n        \"initialized with values matching their patterns as listed below:{}\".format(\n            \"\\n\".join(bindings_description)\n        )\n    )\n", "google/api_core/grpc_helpers_async.py": "# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"AsyncIO helpers for :mod:`grpc` supporting 3.7+.\n\nPlease combine more detailed docstring in grpc_helpers.py to use following\nfunctions. This module is implementing the same surface with AsyncIO semantics.\n\"\"\"\n\nimport asyncio\nimport functools\n\nfrom typing import AsyncGenerator, Generic, Iterator, Optional, TypeVar\n\nimport grpc\nfrom grpc import aio\n\nfrom google.api_core import exceptions, grpc_helpers\n\n# denotes the proto response type for grpc calls\nP = TypeVar(\"P\")\n\n# NOTE(lidiz) Alternatively, we can hack \"__getattribute__\" to perform\n# automatic patching for us. But that means the overhead of creating an\n# extra Python function spreads to every single send and receive.\n\n\nclass _WrappedCall(aio.Call):\n    def __init__(self):\n        self._call = None\n\n    def with_call(self, call):\n        \"\"\"Supplies the call object separately to keep __init__ clean.\"\"\"\n        self._call = call\n        return self\n\n    async def initial_metadata(self):\n        return await self._call.initial_metadata()\n\n    async def trailing_metadata(self):\n        return await self._call.trailing_metadata()\n\n    async def code(self):\n        return await self._call.code()\n\n    async def details(self):\n        return await self._call.details()\n\n    def cancelled(self):\n        return self._call.cancelled()\n\n    def done(self):\n        return self._call.done()\n\n    def time_remaining(self):\n        return self._call.time_remaining()\n\n    def cancel(self):\n        return self._call.cancel()\n\n    def add_done_callback(self, callback):\n        self._call.add_done_callback(callback)\n\n    async def wait_for_connection(self):\n        try:\n            await self._call.wait_for_connection()\n        except grpc.RpcError as rpc_error:\n            raise exceptions.from_grpc_error(rpc_error) from rpc_error\n\n\nclass _WrappedUnaryResponseMixin(Generic[P], _WrappedCall):\n    def __await__(self) -> Iterator[P]:\n        try:\n            response = yield from self._call.__await__()\n            return response\n        except grpc.RpcError as rpc_error:\n            raise exceptions.from_grpc_error(rpc_error) from rpc_error\n\n\nclass _WrappedStreamResponseMixin(Generic[P], _WrappedCall):\n    def __init__(self):\n        self._wrapped_async_generator = None\n\n    async def read(self) -> P:\n        try:\n            return await self._call.read()\n        except grpc.RpcError as rpc_error:\n            raise exceptions.from_grpc_error(rpc_error) from rpc_error\n\n    async def _wrapped_aiter(self) -> AsyncGenerator[P, None]:\n        try:\n            # NOTE(lidiz) coverage doesn't understand the exception raised from\n            # __anext__ method. It is covered by test case:\n            #     test_wrap_stream_errors_aiter_non_rpc_error\n            async for response in self._call:  # pragma: no branch\n                yield response\n        except grpc.RpcError as rpc_error:\n            raise exceptions.from_grpc_error(rpc_error) from rpc_error\n\n    def __aiter__(self) -> AsyncGenerator[P, None]:\n        if not self._wrapped_async_generator:\n            self._wrapped_async_generator = self._wrapped_aiter()\n        return self._wrapped_async_generator\n\n\nclass _WrappedStreamRequestMixin(_WrappedCall):\n    async def write(self, request):\n        try:\n            await self._call.write(request)\n        except grpc.RpcError as rpc_error:\n            raise exceptions.from_grpc_error(rpc_error) from rpc_error\n\n    async def done_writing(self):\n        try:\n            await self._call.done_writing()\n        except grpc.RpcError as rpc_error:\n            raise exceptions.from_grpc_error(rpc_error) from rpc_error\n\n\n# NOTE(lidiz) Implementing each individual class separately, so we don't\n# expose any API that should not be seen. E.g., __aiter__ in unary-unary\n# RPC, or __await__ in stream-stream RPC.\nclass _WrappedUnaryUnaryCall(_WrappedUnaryResponseMixin[P], aio.UnaryUnaryCall):\n    \"\"\"Wrapped UnaryUnaryCall to map exceptions.\"\"\"\n\n\nclass _WrappedUnaryStreamCall(_WrappedStreamResponseMixin[P], aio.UnaryStreamCall):\n    \"\"\"Wrapped UnaryStreamCall to map exceptions.\"\"\"\n\n\nclass _WrappedStreamUnaryCall(\n    _WrappedUnaryResponseMixin[P], _WrappedStreamRequestMixin, aio.StreamUnaryCall\n):\n    \"\"\"Wrapped StreamUnaryCall to map exceptions.\"\"\"\n\n\nclass _WrappedStreamStreamCall(\n    _WrappedStreamRequestMixin, _WrappedStreamResponseMixin[P], aio.StreamStreamCall\n):\n    \"\"\"Wrapped StreamStreamCall to map exceptions.\"\"\"\n\n\n# public type alias denoting the return type of async streaming gapic calls\nGrpcAsyncStream = _WrappedStreamResponseMixin[P]\n# public type alias denoting the return type of unary gapic calls\nAwaitableGrpcCall = _WrappedUnaryResponseMixin[P]\n\n\ndef _wrap_unary_errors(callable_):\n    \"\"\"Map errors for Unary-Unary async callables.\"\"\"\n\n    @functools.wraps(callable_)\n    def error_remapped_callable(*args, **kwargs):\n        call = callable_(*args, **kwargs)\n        return _WrappedUnaryUnaryCall().with_call(call)\n\n    return error_remapped_callable\n\n\ndef _wrap_stream_errors(callable_, wrapper_type):\n    \"\"\"Map errors for streaming RPC async callables.\"\"\"\n\n    @functools.wraps(callable_)\n    async def error_remapped_callable(*args, **kwargs):\n        call = callable_(*args, **kwargs)\n        call = wrapper_type().with_call(call)\n        await call.wait_for_connection()\n        return call\n\n    return error_remapped_callable\n\n\ndef wrap_errors(callable_):\n    \"\"\"Wrap a gRPC async callable and map :class:`grpc.RpcErrors` to\n    friendly error classes.\n\n    Errors raised by the gRPC callable are mapped to the appropriate\n    :class:`google.api_core.exceptions.GoogleAPICallError` subclasses. The\n    original `grpc.RpcError` (which is usually also a `grpc.Call`) is\n    available from the ``response`` property on the mapped exception. This\n    is useful for extracting metadata from the original error.\n\n    Args:\n        callable_ (Callable): A gRPC callable.\n\n    Returns: Callable: The wrapped gRPC callable.\n    \"\"\"\n    grpc_helpers._patch_callable_name(callable_)\n\n    if isinstance(callable_, aio.UnaryStreamMultiCallable):\n        return _wrap_stream_errors(callable_, _WrappedUnaryStreamCall)\n    elif isinstance(callable_, aio.StreamUnaryMultiCallable):\n        return _wrap_stream_errors(callable_, _WrappedStreamUnaryCall)\n    elif isinstance(callable_, aio.StreamStreamMultiCallable):\n        return _wrap_stream_errors(callable_, _WrappedStreamStreamCall)\n    else:\n        return _wrap_unary_errors(callable_)\n\n\ndef create_channel(\n    target,\n    credentials=None,\n    scopes=None,\n    ssl_credentials=None,\n    credentials_file=None,\n    quota_project_id=None,\n    default_scopes=None,\n    default_host=None,\n    compression=None,\n    attempt_direct_path: Optional[bool] = False,\n    **kwargs\n):\n    \"\"\"Create an AsyncIO secure channel with credentials.\n\n    Args:\n        target (str): The target service address in the format 'hostname:port'.\n        credentials (google.auth.credentials.Credentials): The credentials. If\n            not specified, then this function will attempt to ascertain the\n            credentials from the environment using :func:`google.auth.default`.\n        scopes (Sequence[str]): A optional list of scopes needed for this\n            service. These are only used when credentials are not specified and\n            are passed to :func:`google.auth.default`.\n        ssl_credentials (grpc.ChannelCredentials): Optional SSL channel\n            credentials. This can be used to specify different certificates.\n        credentials_file (str): A file with credentials that can be loaded with\n            :func:`google.auth.load_credentials_from_file`. This argument is\n            mutually exclusive with credentials.\n        quota_project_id (str): An optional project to use for billing and quota.\n        default_scopes (Sequence[str]): Default scopes passed by a Google client\n            library. Use 'scopes' for user-defined scopes.\n        default_host (str): The default endpoint. e.g., \"pubsub.googleapis.com\".\n        compression (grpc.Compression): An optional value indicating the\n            compression method to be used over the lifetime of the channel.\n        attempt_direct_path (Optional[bool]): If set, Direct Path will be attempted\n            when the request is made. Direct Path is only available within a Google\n            Compute Engine (GCE) environment and provides a proxyless connection\n            which increases the available throughput, reduces latency, and increases\n            reliability. Note:\n\n            - This argument should only be set in a GCE environment and for Services\n              that are known to support Direct Path.\n            - If this argument is set outside of GCE, then this request will fail\n              unless the back-end service happens to have configured fall-back to DNS.\n            - If the request causes a `ServiceUnavailable` response, it is recommended\n              that the client repeat the request with `attempt_direct_path` set to\n              `False` as the Service may not support Direct Path.\n            - Using `ssl_credentials` with `attempt_direct_path` set to `True` will\n              result in `ValueError` as this combination  is not yet supported.\n\n        kwargs: Additional key-word args passed to :func:`aio.secure_channel`.\n\n    Returns:\n        aio.Channel: The created channel.\n\n    Raises:\n        google.api_core.DuplicateCredentialArgs: If both a credentials object and credentials_file are passed.\n        ValueError: If `ssl_credentials` is set and `attempt_direct_path` is set to `True`.\n    \"\"\"\n\n    # If `ssl_credentials` is set and `attempt_direct_path` is set to `True`,\n    # raise ValueError as this is not yet supported.\n    # See https://github.com/googleapis/python-api-core/issues/590\n    if ssl_credentials and attempt_direct_path:\n        raise ValueError(\"Using ssl_credentials with Direct Path is not supported\")\n\n    composite_credentials = grpc_helpers._create_composite_credentials(\n        credentials=credentials,\n        credentials_file=credentials_file,\n        scopes=scopes,\n        default_scopes=default_scopes,\n        ssl_credentials=ssl_credentials,\n        quota_project_id=quota_project_id,\n        default_host=default_host,\n    )\n\n    if attempt_direct_path:\n        target = grpc_helpers._modify_target_for_direct_path(target)\n\n    return aio.secure_channel(\n        target, composite_credentials, compression=compression, **kwargs\n    )\n\n\nclass FakeUnaryUnaryCall(_WrappedUnaryUnaryCall):\n    \"\"\"Fake implementation for unary-unary RPCs.\n\n    It is a dummy object for response message. Supply the intended response\n    upon the initialization, and the coroutine will return the exact response\n    message.\n    \"\"\"\n\n    def __init__(self, response=object()):\n        self.response = response\n        self._future = asyncio.get_event_loop().create_future()\n        self._future.set_result(self.response)\n\n    def __await__(self):\n        response = yield from self._future.__await__()\n        return response\n\n\nclass FakeStreamUnaryCall(_WrappedStreamUnaryCall):\n    \"\"\"Fake implementation for stream-unary RPCs.\n\n    It is a dummy object for response message. Supply the intended response\n    upon the initialization, and the coroutine will return the exact response\n    message.\n    \"\"\"\n\n    def __init__(self, response=object()):\n        self.response = response\n        self._future = asyncio.get_event_loop().create_future()\n        self._future.set_result(self.response)\n\n    def __await__(self):\n        response = yield from self._future.__await__()\n        return response\n\n    async def wait_for_connection(self):\n        pass\n", "google/api_core/version_header.py": "# Copyright 2024 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nAPI_VERSION_METADATA_KEY = \"x-goog-api-version\"\n\n\ndef to_api_version_header(version_identifier):\n    \"\"\"Returns data for the API Version header for the given `version_identifier`.\n\n    Args:\n        version_identifier (str): The version identifier to be used in the\n            tuple returned.\n\n    Returns:\n        Tuple(str, str): A tuple containing the API Version metadata key and\n            value.\n    \"\"\"\n    return (API_VERSION_METADATA_KEY, version_identifier)\n", "google/api_core/bidi.py": "# Copyright 2017, Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Bi-directional streaming RPC helpers.\"\"\"\n\nimport collections\nimport datetime\nimport logging\nimport queue as queue_module\nimport threading\nimport time\n\nfrom google.api_core import exceptions\n\n_LOGGER = logging.getLogger(__name__)\n_BIDIRECTIONAL_CONSUMER_NAME = \"Thread-ConsumeBidirectionalStream\"\n\n\nclass _RequestQueueGenerator(object):\n    \"\"\"A helper for sending requests to a gRPC stream from a Queue.\n\n    This generator takes requests off a given queue and yields them to gRPC.\n\n    This helper is useful when you have an indeterminate, indefinite, or\n    otherwise open-ended set of requests to send through a request-streaming\n    (or bidirectional) RPC.\n\n    The reason this is necessary is because gRPC takes an iterator as the\n    request for request-streaming RPCs. gRPC consumes this iterator in another\n    thread to allow it to block while generating requests for the stream.\n    However, if the generator blocks indefinitely gRPC will not be able to\n    clean up the thread as it'll be blocked on `next(iterator)` and not be able\n    to check the channel status to stop iterating. This helper mitigates that\n    by waiting on the queue with a timeout and checking the RPC state before\n    yielding.\n\n    Finally, it allows for retrying without swapping queues because if it does\n    pull an item off the queue when the RPC is inactive, it'll immediately put\n    it back and then exit. This is necessary because yielding the item in this\n    case will cause gRPC to discard it. In practice, this means that the order\n    of messages is not guaranteed. If such a thing is necessary it would be\n    easy to use a priority queue.\n\n    Example::\n\n        requests = request_queue_generator(q)\n        call = stub.StreamingRequest(iter(requests))\n        requests.call = call\n\n        for response in call:\n            print(response)\n            q.put(...)\n\n    Note that it is possible to accomplish this behavior without \"spinning\"\n    (using a queue timeout). One possible way would be to use more threads to\n    multiplex the grpc end event with the queue, another possible way is to\n    use selectors and a custom event/queue object. Both of these approaches\n    are significant from an engineering perspective for small benefit - the\n    CPU consumed by spinning is pretty minuscule.\n\n    Args:\n        queue (queue_module.Queue): The request queue.\n        period (float): The number of seconds to wait for items from the queue\n            before checking if the RPC is cancelled. In practice, this\n            determines the maximum amount of time the request consumption\n            thread will live after the RPC is cancelled.\n        initial_request (Union[protobuf.Message,\n                Callable[None, protobuf.Message]]): The initial request to\n            yield. This is done independently of the request queue to allow fo\n            easily restarting streams that require some initial configuration\n            request.\n    \"\"\"\n\n    def __init__(self, queue, period=1, initial_request=None):\n        self._queue = queue\n        self._period = period\n        self._initial_request = initial_request\n        self.call = None\n\n    def _is_active(self):\n        # Note: there is a possibility that this starts *before* the call\n        # property is set. So we have to check if self.call is set before\n        # seeing if it's active. We need to return True if self.call is None.\n        # See https://github.com/googleapis/python-api-core/issues/560.\n        return self.call is None or self.call.is_active()\n\n    def __iter__(self):\n        if self._initial_request is not None:\n            if callable(self._initial_request):\n                yield self._initial_request()\n            else:\n                yield self._initial_request\n\n        while True:\n            try:\n                item = self._queue.get(timeout=self._period)\n            except queue_module.Empty:\n                if not self._is_active():\n                    _LOGGER.debug(\n                        \"Empty queue and inactive call, exiting request \" \"generator.\"\n                    )\n                    return\n                else:\n                    # call is still active, keep waiting for queue items.\n                    continue\n\n            # The consumer explicitly sent \"None\", indicating that the request\n            # should end.\n            if item is None:\n                _LOGGER.debug(\"Cleanly exiting request generator.\")\n                return\n\n            if not self._is_active():\n                # We have an item, but the call is closed. We should put the\n                # item back on the queue so that the next call can consume it.\n                self._queue.put(item)\n                _LOGGER.debug(\n                    \"Inactive call, replacing item on queue and exiting \"\n                    \"request generator.\"\n                )\n                return\n\n            yield item\n\n\nclass _Throttle(object):\n    \"\"\"A context manager limiting the total entries in a sliding time window.\n\n    If more than ``access_limit`` attempts are made to enter the context manager\n    instance in the last ``time window`` interval, the exceeding requests block\n    until enough time elapses.\n\n    The context manager instances are thread-safe and can be shared between\n    multiple threads. If multiple requests are blocked and waiting to enter,\n    the exact order in which they are allowed to proceed is not determined.\n\n    Example::\n\n        max_three_per_second = _Throttle(\n            access_limit=3, time_window=datetime.timedelta(seconds=1)\n        )\n\n        for i in range(5):\n            with max_three_per_second as time_waited:\n                print(\"{}: Waited {} seconds to enter\".format(i, time_waited))\n\n    Args:\n        access_limit (int): the maximum number of entries allowed in the time window\n        time_window (datetime.timedelta): the width of the sliding time window\n    \"\"\"\n\n    def __init__(self, access_limit, time_window):\n        if access_limit < 1:\n            raise ValueError(\"access_limit argument must be positive\")\n\n        if time_window <= datetime.timedelta(0):\n            raise ValueError(\"time_window argument must be a positive timedelta\")\n\n        self._time_window = time_window\n        self._access_limit = access_limit\n        self._past_entries = collections.deque(\n            maxlen=access_limit\n        )  # least recent first\n        self._entry_lock = threading.Lock()\n\n    def __enter__(self):\n        with self._entry_lock:\n            cutoff_time = datetime.datetime.now() - self._time_window\n\n            # drop the entries that are too old, as they are no longer relevant\n            while self._past_entries and self._past_entries[0] < cutoff_time:\n                self._past_entries.popleft()\n\n            if len(self._past_entries) < self._access_limit:\n                self._past_entries.append(datetime.datetime.now())\n                return 0.0  # no waiting was needed\n\n            to_wait = (self._past_entries[0] - cutoff_time).total_seconds()\n            time.sleep(to_wait)\n\n            self._past_entries.append(datetime.datetime.now())\n            return to_wait\n\n    def __exit__(self, *_):\n        pass\n\n    def __repr__(self):\n        return \"{}(access_limit={}, time_window={})\".format(\n            self.__class__.__name__, self._access_limit, repr(self._time_window)\n        )\n\n\nclass BidiRpc(object):\n    \"\"\"A helper for consuming a bi-directional streaming RPC.\n\n    This maps gRPC's built-in interface which uses a request iterator and a\n    response iterator into a socket-like :func:`send` and :func:`recv`. This\n    is a more useful pattern for long-running or asymmetric streams (streams\n    where there is not a direct correlation between the requests and\n    responses).\n\n    Example::\n\n        initial_request = example_pb2.StreamingRpcRequest(\n            setting='example')\n        rpc = BidiRpc(\n            stub.StreamingRpc,\n            initial_request=initial_request,\n            metadata=[('name', 'value')]\n        )\n\n        rpc.open()\n\n        while rpc.is_active():\n            print(rpc.recv())\n            rpc.send(example_pb2.StreamingRpcRequest(\n                data='example'))\n\n    This does *not* retry the stream on errors. See :class:`ResumableBidiRpc`.\n\n    Args:\n        start_rpc (grpc.StreamStreamMultiCallable): The gRPC method used to\n            start the RPC.\n        initial_request (Union[protobuf.Message,\n                Callable[None, protobuf.Message]]): The initial request to\n            yield. This is useful if an initial request is needed to start the\n            stream.\n        metadata (Sequence[Tuple(str, str)]): RPC metadata to include in\n            the request.\n    \"\"\"\n\n    def __init__(self, start_rpc, initial_request=None, metadata=None):\n        self._start_rpc = start_rpc\n        self._initial_request = initial_request\n        self._rpc_metadata = metadata\n        self._request_queue = queue_module.Queue()\n        self._request_generator = None\n        self._is_active = False\n        self._callbacks = []\n        self.call = None\n\n    def add_done_callback(self, callback):\n        \"\"\"Adds a callback that will be called when the RPC terminates.\n\n        This occurs when the RPC errors or is successfully terminated.\n\n        Args:\n            callback (Callable[[grpc.Future], None]): The callback to execute.\n                It will be provided with the same gRPC future as the underlying\n                stream which will also be a :class:`grpc.Call`.\n        \"\"\"\n        self._callbacks.append(callback)\n\n    def _on_call_done(self, future):\n        # This occurs when the RPC errors or is successfully terminated.\n        # Note that grpc's \"future\" here can also be a grpc.RpcError.\n        # See note in https://github.com/grpc/grpc/issues/10885#issuecomment-302651331\n        # that `grpc.RpcError` is also `grpc.call`.\n        for callback in self._callbacks:\n            callback(future)\n\n    def open(self):\n        \"\"\"Opens the stream.\"\"\"\n        if self.is_active:\n            raise ValueError(\"Can not open an already open stream.\")\n\n        request_generator = _RequestQueueGenerator(\n            self._request_queue, initial_request=self._initial_request\n        )\n        try:\n            call = self._start_rpc(iter(request_generator), metadata=self._rpc_metadata)\n        except exceptions.GoogleAPICallError as exc:\n            # The original `grpc.RpcError` (which is usually also a `grpc.Call`) is\n            # available from the ``response`` property on the mapped exception.\n            self._on_call_done(exc.response)\n            raise\n\n        request_generator.call = call\n\n        # TODO: api_core should expose the future interface for wrapped\n        # callables as well.\n        if hasattr(call, \"_wrapped\"):  # pragma: NO COVER\n            call._wrapped.add_done_callback(self._on_call_done)\n        else:\n            call.add_done_callback(self._on_call_done)\n\n        self._request_generator = request_generator\n        self.call = call\n\n    def close(self):\n        \"\"\"Closes the stream.\"\"\"\n        if self.call is None:\n            return\n\n        self._request_queue.put(None)\n        self.call.cancel()\n        self._request_generator = None\n        # Don't set self.call to None. Keep it around so that send/recv can\n        # raise the error.\n\n    def send(self, request):\n        \"\"\"Queue a message to be sent on the stream.\n\n        Send is non-blocking.\n\n        If the underlying RPC has been closed, this will raise.\n\n        Args:\n            request (protobuf.Message): The request to send.\n        \"\"\"\n        if self.call is None:\n            raise ValueError(\"Can not send() on an RPC that has never been open()ed.\")\n\n        # Don't use self.is_active(), as ResumableBidiRpc will overload it\n        # to mean something semantically different.\n        if self.call.is_active():\n            self._request_queue.put(request)\n        else:\n            # calling next should cause the call to raise.\n            next(self.call)\n\n    def recv(self):\n        \"\"\"Wait for a message to be returned from the stream.\n\n        Recv is blocking.\n\n        If the underlying RPC has been closed, this will raise.\n\n        Returns:\n            protobuf.Message: The received message.\n        \"\"\"\n        if self.call is None:\n            raise ValueError(\"Can not recv() on an RPC that has never been open()ed.\")\n\n        return next(self.call)\n\n    @property\n    def is_active(self):\n        \"\"\"bool: True if this stream is currently open and active.\"\"\"\n        return self.call is not None and self.call.is_active()\n\n    @property\n    def pending_requests(self):\n        \"\"\"int: Returns an estimate of the number of queued requests.\"\"\"\n        return self._request_queue.qsize()\n\n\ndef _never_terminate(future_or_error):\n    \"\"\"By default, no errors cause BiDi termination.\"\"\"\n    return False\n\n\nclass ResumableBidiRpc(BidiRpc):\n    \"\"\"A :class:`BidiRpc` that can automatically resume the stream on errors.\n\n    It uses the ``should_recover`` arg to determine if it should re-establish\n    the stream on error.\n\n    Example::\n\n        def should_recover(exc):\n            return (\n                isinstance(exc, grpc.RpcError) and\n                exc.code() == grpc.StatusCode.UNAVAILABLE)\n\n        initial_request = example_pb2.StreamingRpcRequest(\n            setting='example')\n\n        metadata = [('header_name', 'value')]\n\n        rpc = ResumableBidiRpc(\n            stub.StreamingRpc,\n            should_recover=should_recover,\n            initial_request=initial_request,\n            metadata=metadata\n        )\n\n        rpc.open()\n\n        while rpc.is_active():\n            print(rpc.recv())\n            rpc.send(example_pb2.StreamingRpcRequest(\n                data='example'))\n\n    Args:\n        start_rpc (grpc.StreamStreamMultiCallable): The gRPC method used to\n            start the RPC.\n        initial_request (Union[protobuf.Message,\n                Callable[None, protobuf.Message]]): The initial request to\n            yield. This is useful if an initial request is needed to start the\n            stream.\n        should_recover (Callable[[Exception], bool]): A function that returns\n            True if the stream should be recovered. This will be called\n            whenever an error is encountered on the stream.\n        should_terminate (Callable[[Exception], bool]): A function that returns\n            True if the stream should be terminated. This will be called\n            whenever an error is encountered on the stream.\n        metadata Sequence[Tuple(str, str)]: RPC metadata to include in\n            the request.\n        throttle_reopen (bool): If ``True``, throttling will be applied to\n            stream reopen calls. Defaults to ``False``.\n    \"\"\"\n\n    def __init__(\n        self,\n        start_rpc,\n        should_recover,\n        should_terminate=_never_terminate,\n        initial_request=None,\n        metadata=None,\n        throttle_reopen=False,\n    ):\n        super(ResumableBidiRpc, self).__init__(start_rpc, initial_request, metadata)\n        self._should_recover = should_recover\n        self._should_terminate = should_terminate\n        self._operational_lock = threading.RLock()\n        self._finalized = False\n        self._finalize_lock = threading.Lock()\n\n        if throttle_reopen:\n            self._reopen_throttle = _Throttle(\n                access_limit=5, time_window=datetime.timedelta(seconds=10)\n            )\n        else:\n            self._reopen_throttle = None\n\n    def _finalize(self, result):\n        with self._finalize_lock:\n            if self._finalized:\n                return\n\n            for callback in self._callbacks:\n                callback(result)\n\n            self._finalized = True\n\n    def _on_call_done(self, future):\n        # Unlike the base class, we only execute the callbacks on a terminal\n        # error, not for errors that we can recover from. Note that grpc's\n        # \"future\" here is also a grpc.RpcError.\n        with self._operational_lock:\n            if self._should_terminate(future):\n                self._finalize(future)\n            elif not self._should_recover(future):\n                self._finalize(future)\n            else:\n                _LOGGER.debug(\"Re-opening stream from gRPC callback.\")\n                self._reopen()\n\n    def _reopen(self):\n        with self._operational_lock:\n            # Another thread already managed to re-open this stream.\n            if self.call is not None and self.call.is_active():\n                _LOGGER.debug(\"Stream was already re-established.\")\n                return\n\n            self.call = None\n            # Request generator should exit cleanly since the RPC its bound to\n            # has exited.\n            self._request_generator = None\n\n            # Note: we do not currently do any sort of backoff here. The\n            # assumption is that re-establishing the stream under normal\n            # circumstances will happen in intervals greater than 60s.\n            # However, it is possible in a degenerative case that the server\n            # closes the stream rapidly which would lead to thrashing here,\n            # but hopefully in those cases the server would return a non-\n            # retryable error.\n\n            try:\n                if self._reopen_throttle:\n                    with self._reopen_throttle:\n                        self.open()\n                else:\n                    self.open()\n            # If re-opening or re-calling the method fails for any reason,\n            # consider it a terminal error and finalize the stream.\n            except Exception as exc:\n                _LOGGER.debug(\"Failed to re-open stream due to %s\", exc)\n                self._finalize(exc)\n                raise\n\n            _LOGGER.info(\"Re-established stream\")\n\n    def _recoverable(self, method, *args, **kwargs):\n        \"\"\"Wraps a method to recover the stream and retry on error.\n\n        If a retryable error occurs while making the call, then the stream will\n        be re-opened and the method will be retried. This happens indefinitely\n        so long as the error is a retryable one. If an error occurs while\n        re-opening the stream, then this method will raise immediately and\n        trigger finalization of this object.\n\n        Args:\n            method (Callable[..., Any]): The method to call.\n            args: The args to pass to the method.\n            kwargs: The kwargs to pass to the method.\n        \"\"\"\n        while True:\n            try:\n                return method(*args, **kwargs)\n\n            except Exception as exc:\n                with self._operational_lock:\n                    _LOGGER.debug(\"Call to retryable %r caused %s.\", method, exc)\n\n                    if self._should_terminate(exc):\n                        self.close()\n                        _LOGGER.debug(\"Terminating %r due to %s.\", method, exc)\n                        self._finalize(exc)\n                        break\n\n                    if not self._should_recover(exc):\n                        self.close()\n                        _LOGGER.debug(\"Not retrying %r due to %s.\", method, exc)\n                        self._finalize(exc)\n                        raise exc\n\n                    _LOGGER.debug(\"Re-opening stream from retryable %r.\", method)\n                    self._reopen()\n\n    def _send(self, request):\n        # Grab a reference to the RPC call. Because another thread (notably\n        # the gRPC error thread) can modify self.call (by invoking reopen),\n        # we should ensure our reference can not change underneath us.\n        # If self.call is modified (such as replaced with a new RPC call) then\n        # this will use the \"old\" RPC, which should result in the same\n        # exception passed into gRPC's error handler being raised here, which\n        # will be handled by the usual error handling in retryable.\n        with self._operational_lock:\n            call = self.call\n\n        if call is None:\n            raise ValueError(\"Can not send() on an RPC that has never been open()ed.\")\n\n        # Don't use self.is_active(), as ResumableBidiRpc will overload it\n        # to mean something semantically different.\n        if call.is_active():\n            self._request_queue.put(request)\n            pass\n        else:\n            # calling next should cause the call to raise.\n            next(call)\n\n    def send(self, request):\n        return self._recoverable(self._send, request)\n\n    def _recv(self):\n        with self._operational_lock:\n            call = self.call\n\n        if call is None:\n            raise ValueError(\"Can not recv() on an RPC that has never been open()ed.\")\n\n        return next(call)\n\n    def recv(self):\n        return self._recoverable(self._recv)\n\n    def close(self):\n        self._finalize(None)\n        super(ResumableBidiRpc, self).close()\n\n    @property\n    def is_active(self):\n        \"\"\"bool: True if this stream is currently open and active.\"\"\"\n        # Use the operational lock. It's entirely possible for something\n        # to check the active state *while* the RPC is being retried.\n        # Also, use finalized to track the actual terminal state here.\n        # This is because if the stream is re-established by the gRPC thread\n        # it's technically possible to check this between when gRPC marks the\n        # RPC as inactive and when gRPC executes our callback that re-opens\n        # the stream.\n        with self._operational_lock:\n            return self.call is not None and not self._finalized\n\n\nclass BackgroundConsumer(object):\n    \"\"\"A bi-directional stream consumer that runs in a separate thread.\n\n    This maps the consumption of a stream into a callback-based model. It also\n    provides :func:`pause` and :func:`resume` to allow for flow-control.\n\n    Example::\n\n        def should_recover(exc):\n            return (\n                isinstance(exc, grpc.RpcError) and\n                exc.code() == grpc.StatusCode.UNAVAILABLE)\n\n        initial_request = example_pb2.StreamingRpcRequest(\n            setting='example')\n\n        rpc = ResumeableBidiRpc(\n            stub.StreamingRpc,\n            initial_request=initial_request,\n            should_recover=should_recover)\n\n        def on_response(response):\n            print(response)\n\n        consumer = BackgroundConsumer(rpc, on_response)\n        consumer.start()\n\n    Note that error handling *must* be done by using the provided\n    ``bidi_rpc``'s ``add_done_callback``. This helper will automatically exit\n    whenever the RPC itself exits and will not provide any error details.\n\n    Args:\n        bidi_rpc (BidiRpc): The RPC to consume. Should not have been\n            ``open()``ed yet.\n        on_response (Callable[[protobuf.Message], None]): The callback to\n            be called for every response on the stream.\n    \"\"\"\n\n    def __init__(self, bidi_rpc, on_response):\n        self._bidi_rpc = bidi_rpc\n        self._on_response = on_response\n        self._paused = False\n        self._wake = threading.Condition()\n        self._thread = None\n        self._operational_lock = threading.Lock()\n\n    def _on_call_done(self, future):\n        # Resume the thread if it's paused, this prevents blocking forever\n        # when the RPC has terminated.\n        self.resume()\n\n    def _thread_main(self, ready):\n        try:\n            ready.set()\n            self._bidi_rpc.add_done_callback(self._on_call_done)\n            self._bidi_rpc.open()\n\n            while self._bidi_rpc.is_active:\n                # Do not allow the paused status to change at all during this\n                # section. There is a condition where we could be resumed\n                # between checking if we are paused and calling wake.wait(),\n                # which means that we will miss the notification to wake up\n                # (oops!) and wait for a notification that will never come.\n                # Keeping the lock throughout avoids that.\n                # In the future, we could use `Condition.wait_for` if we drop\n                # Python 2.7.\n                # See: https://github.com/googleapis/python-api-core/issues/211\n                with self._wake:\n                    while self._paused:\n                        _LOGGER.debug(\"paused, waiting for waking.\")\n                        self._wake.wait()\n                        _LOGGER.debug(\"woken.\")\n\n                _LOGGER.debug(\"waiting for recv.\")\n                response = self._bidi_rpc.recv()\n                _LOGGER.debug(\"recved response.\")\n                self._on_response(response)\n\n        except exceptions.GoogleAPICallError as exc:\n            _LOGGER.debug(\n                \"%s caught error %s and will exit. Generally this is due to \"\n                \"the RPC itself being cancelled and the error will be \"\n                \"surfaced to the calling code.\",\n                _BIDIRECTIONAL_CONSUMER_NAME,\n                exc,\n                exc_info=True,\n            )\n\n        except Exception as exc:\n            _LOGGER.exception(\n                \"%s caught unexpected exception %s and will exit.\",\n                _BIDIRECTIONAL_CONSUMER_NAME,\n                exc,\n            )\n\n        _LOGGER.info(\"%s exiting\", _BIDIRECTIONAL_CONSUMER_NAME)\n\n    def start(self):\n        \"\"\"Start the background thread and begin consuming the thread.\"\"\"\n        with self._operational_lock:\n            ready = threading.Event()\n            thread = threading.Thread(\n                name=_BIDIRECTIONAL_CONSUMER_NAME,\n                target=self._thread_main,\n                args=(ready,),\n            )\n            thread.daemon = True\n            thread.start()\n            # Other parts of the code rely on `thread.is_alive` which\n            # isn't sufficient to know if a thread is active, just that it may\n            # soon be active. This can cause races. Further protect\n            # against races by using a ready event and wait on it to be set.\n            ready.wait()\n            self._thread = thread\n            _LOGGER.debug(\"Started helper thread %s\", thread.name)\n\n    def stop(self):\n        \"\"\"Stop consuming the stream and shutdown the background thread.\"\"\"\n        with self._operational_lock:\n            self._bidi_rpc.close()\n\n            if self._thread is not None:\n                # Resume the thread to wake it up in case it is sleeping.\n                self.resume()\n                # The daemonized thread may itself block, so don't wait\n                # for it longer than a second.\n                self._thread.join(1.0)\n                if self._thread.is_alive():  # pragma: NO COVER\n                    _LOGGER.warning(\"Background thread did not exit.\")\n\n            self._thread = None\n\n    @property\n    def is_active(self):\n        \"\"\"bool: True if the background thread is active.\"\"\"\n        return self._thread is not None and self._thread.is_alive()\n\n    def pause(self):\n        \"\"\"Pauses the response stream.\n\n        This does *not* pause the request stream.\n        \"\"\"\n        with self._wake:\n            self._paused = True\n\n    def resume(self):\n        \"\"\"Resumes the response stream.\"\"\"\n        with self._wake:\n            self._paused = False\n            self._wake.notify_all()\n\n    @property\n    def is_paused(self):\n        \"\"\"bool: True if the response stream is paused.\"\"\"\n        return self._paused\n", "google/api_core/page_iterator.py": "# Copyright 2015 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Iterators for paging through paged API methods.\n\nThese iterators simplify the process of paging through API responses\nwhere the request takes a page token and the response is a list of results with\na token for the next page. See `list pagination`_ in the Google API Style Guide\nfor more details.\n\n.. _list pagination:\n    https://cloud.google.com/apis/design/design_patterns#list_pagination\n\nAPI clients that have methods that follow the list pagination pattern can\nreturn an :class:`.Iterator`. You can use this iterator to get **all** of\nthe results across all pages::\n\n    >>> results_iterator = client.list_resources()\n    >>> list(results_iterator)  # Convert to a list (consumes all values).\n\nOr you can walk your way through items and call off the search early if\nyou find what you're looking for (resulting in possibly fewer requests)::\n\n    >>> for resource in results_iterator:\n    ...     print(resource.name)\n    ...     if not resource.is_valid:\n    ...         break\n\nAt any point, you may check the number of items consumed by referencing the\n``num_results`` property of the iterator::\n\n    >>> for my_item in results_iterator:\n    ...     if results_iterator.num_results >= 10:\n    ...         break\n\nWhen iterating, not every new item will send a request to the server.\nTo iterate based on each page of items (where a page corresponds to\na request)::\n\n    >>> for page in results_iterator.pages:\n    ...     print('=' * 20)\n    ...     print('    Page number: {:d}'.format(iterator.page_number))\n    ...     print('  Items in page: {:d}'.format(page.num_items))\n    ...     print('     First item: {!r}'.format(next(page)))\n    ...     print('Items remaining: {:d}'.format(page.remaining))\n    ...     print('Next page token: {}'.format(iterator.next_page_token))\n    ====================\n        Page number: 1\n      Items in page: 1\n         First item: <MyItemClass at 0x7f1d3cccf690>\n    Items remaining: 0\n    Next page token: eav1OzQB0OM8rLdGXOEsyQWSG\n    ====================\n        Page number: 2\n      Items in page: 19\n         First item: <MyItemClass at 0x7f1d3cccffd0>\n    Items remaining: 18\n    Next page token: None\n\nThen, for each page you can get all the resources on that page by iterating\nthrough it or using :func:`list`::\n\n    >>> list(page)\n    [\n        <MyItemClass at 0x7fd64a098ad0>,\n        <MyItemClass at 0x7fd64a098ed0>,\n        <MyItemClass at 0x7fd64a098e90>,\n    ]\n\"\"\"\n\nimport abc\n\n\nclass Page(object):\n    \"\"\"Single page of results in an iterator.\n\n    Args:\n        parent (google.api_core.page_iterator.Iterator): The iterator that owns\n            the current page.\n        items (Sequence[Any]): An iterable (that also defines __len__) of items\n            from a raw API response.\n        item_to_value (Callable[google.api_core.page_iterator.Iterator, Any]):\n            Callable to convert an item from the type in the raw API response\n            into the native object. Will be called with the iterator and a\n            single item.\n        raw_page Optional[google.protobuf.message.Message]:\n            The raw page response.\n    \"\"\"\n\n    def __init__(self, parent, items, item_to_value, raw_page=None):\n        self._parent = parent\n        self._num_items = len(items)\n        self._remaining = self._num_items\n        self._item_iter = iter(items)\n        self._item_to_value = item_to_value\n        self._raw_page = raw_page\n\n    @property\n    def raw_page(self):\n        \"\"\"google.protobuf.message.Message\"\"\"\n        return self._raw_page\n\n    @property\n    def num_items(self):\n        \"\"\"int: Total items in the page.\"\"\"\n        return self._num_items\n\n    @property\n    def remaining(self):\n        \"\"\"int: Remaining items in the page.\"\"\"\n        return self._remaining\n\n    def __iter__(self):\n        \"\"\"The :class:`Page` is an iterator of items.\"\"\"\n        return self\n\n    def __next__(self):\n        \"\"\"Get the next value in the page.\"\"\"\n        item = next(self._item_iter)\n        result = self._item_to_value(self._parent, item)\n        # Since we've successfully got the next value from the\n        # iterator, we update the number of remaining.\n        self._remaining -= 1\n        return result\n\n\ndef _item_to_value_identity(iterator, item):\n    \"\"\"An item to value transformer that returns the item un-changed.\"\"\"\n    # pylint: disable=unused-argument\n    # We are conforming to the interface defined by Iterator.\n    return item\n\n\nclass Iterator(object, metaclass=abc.ABCMeta):\n    \"\"\"A generic class for iterating through API list responses.\n\n    Args:\n        client(google.cloud.client.Client): The API client.\n        item_to_value (Callable[google.api_core.page_iterator.Iterator, Any]):\n            Callable to convert an item from the type in the raw API response\n            into the native object. Will be called with the iterator and a\n            single item.\n        page_token (str): A token identifying a page in a result set to start\n            fetching results from.\n        max_results (int): The maximum number of results to fetch.\n    \"\"\"\n\n    def __init__(\n        self,\n        client,\n        item_to_value=_item_to_value_identity,\n        page_token=None,\n        max_results=None,\n    ):\n        self._started = False\n        self.__active_iterator = None\n\n        self.client = client\n        \"\"\"Optional[Any]: The client that created this iterator.\"\"\"\n        self.item_to_value = item_to_value\n        \"\"\"Callable[Iterator, Any]: Callable to convert an item from the type\n            in the raw API response into the native object. Will be called with\n            the iterator and a\n            single item.\n        \"\"\"\n        self.max_results = max_results\n        \"\"\"int: The maximum number of results to fetch\"\"\"\n\n        # The attributes below will change over the life of the iterator.\n        self.page_number = 0\n        \"\"\"int: The current page of results.\"\"\"\n        self.next_page_token = page_token\n        \"\"\"str: The token for the next page of results. If this is set before\n            the iterator starts, it effectively offsets the iterator to a\n            specific starting point.\"\"\"\n        self.num_results = 0\n        \"\"\"int: The total number of results fetched so far.\"\"\"\n\n    @property\n    def pages(self):\n        \"\"\"Iterator of pages in the response.\n\n        returns:\n            types.GeneratorType[google.api_core.page_iterator.Page]: A\n                generator of page instances.\n\n        raises:\n            ValueError: If the iterator has already been started.\n        \"\"\"\n        if self._started:\n            raise ValueError(\"Iterator has already started\", self)\n        self._started = True\n        return self._page_iter(increment=True)\n\n    def _items_iter(self):\n        \"\"\"Iterator for each item returned.\"\"\"\n        for page in self._page_iter(increment=False):\n            for item in page:\n                self.num_results += 1\n                yield item\n\n    def __iter__(self):\n        \"\"\"Iterator for each item returned.\n\n        Returns:\n            types.GeneratorType[Any]: A generator of items from the API.\n\n        Raises:\n            ValueError: If the iterator has already been started.\n        \"\"\"\n        if self._started:\n            raise ValueError(\"Iterator has already started\", self)\n        self._started = True\n        return self._items_iter()\n\n    def __next__(self):\n        if self.__active_iterator is None:\n            self.__active_iterator = iter(self)\n        return next(self.__active_iterator)\n\n    def _page_iter(self, increment):\n        \"\"\"Generator of pages of API responses.\n\n        Args:\n            increment (bool): Flag indicating if the total number of results\n                should be incremented on each page. This is useful since a page\n                iterator will want to increment by results per page while an\n                items iterator will want to increment per item.\n\n        Yields:\n            Page: each page of items from the API.\n        \"\"\"\n        page = self._next_page()\n        while page is not None:\n            self.page_number += 1\n            if increment:\n                self.num_results += page.num_items\n            yield page\n            page = self._next_page()\n\n    @abc.abstractmethod\n    def _next_page(self):\n        \"\"\"Get the next page in the iterator.\n\n        This does nothing and is intended to be over-ridden by subclasses\n        to return the next :class:`Page`.\n\n        Raises:\n            NotImplementedError: Always, this method is abstract.\n        \"\"\"\n        raise NotImplementedError\n\n\ndef _do_nothing_page_start(iterator, page, response):\n    \"\"\"Helper to provide custom behavior after a :class:`Page` is started.\n\n    This is a do-nothing stand-in as the default value.\n\n    Args:\n        iterator (Iterator): An iterator that holds some request info.\n        page (Page): The page that was just created.\n        response (Any): The API response for a page.\n    \"\"\"\n    # pylint: disable=unused-argument\n    pass\n\n\nclass HTTPIterator(Iterator):\n    \"\"\"A generic class for iterating through HTTP/JSON API list responses.\n\n    To make an iterator work, you'll need to provide a way to convert a JSON\n    item returned from the API into the object of your choice (via\n    ``item_to_value``). You also may need to specify a custom ``items_key`` so\n    that a given response (containing a page of results) can be parsed into an\n    iterable page of the actual objects you want.\n\n    Args:\n        client (google.cloud.client.Client): The API client.\n        api_request (Callable): The function to use to make API requests.\n            Generally, this will be\n            :meth:`google.cloud._http.JSONConnection.api_request`.\n        path (str): The method path to query for the list of items.\n        item_to_value (Callable[google.api_core.page_iterator.Iterator, Any]):\n            Callable to convert an item from the type in the JSON response into\n            a native object. Will be called with the iterator and a single\n            item.\n        items_key (str): The key in the API response where the list of items\n            can be found.\n        page_token (str): A token identifying a page in a result set to start\n            fetching results from.\n        page_size (int): The maximum number of results to fetch per page\n        max_results (int): The maximum number of results to fetch\n        extra_params (dict): Extra query string parameters for the\n            API call.\n        page_start (Callable[\n            google.api_core.page_iterator.Iterator,\n            google.api_core.page_iterator.Page, dict]): Callable to provide\n            any special behavior after a new page has been created. Assumed\n            signature takes the :class:`.Iterator` that started the page,\n            the :class:`.Page` that was started and the dictionary containing\n            the page response.\n        next_token (str): The name of the field used in the response for page\n            tokens.\n\n    .. autoattribute:: pages\n    \"\"\"\n\n    _DEFAULT_ITEMS_KEY = \"items\"\n    _PAGE_TOKEN = \"pageToken\"\n    _MAX_RESULTS = \"maxResults\"\n    _NEXT_TOKEN = \"nextPageToken\"\n    _RESERVED_PARAMS = frozenset([_PAGE_TOKEN])\n    _HTTP_METHOD = \"GET\"\n\n    def __init__(\n        self,\n        client,\n        api_request,\n        path,\n        item_to_value,\n        items_key=_DEFAULT_ITEMS_KEY,\n        page_token=None,\n        page_size=None,\n        max_results=None,\n        extra_params=None,\n        page_start=_do_nothing_page_start,\n        next_token=_NEXT_TOKEN,\n    ):\n        super(HTTPIterator, self).__init__(\n            client, item_to_value, page_token=page_token, max_results=max_results\n        )\n        self.api_request = api_request\n        self.path = path\n        self._items_key = items_key\n        self.extra_params = extra_params\n        self._page_size = page_size\n        self._page_start = page_start\n        self._next_token = next_token\n        # Verify inputs / provide defaults.\n        if self.extra_params is None:\n            self.extra_params = {}\n        self._verify_params()\n\n    def _verify_params(self):\n        \"\"\"Verifies the parameters don't use any reserved parameter.\n\n        Raises:\n            ValueError: If a reserved parameter is used.\n        \"\"\"\n        reserved_in_use = self._RESERVED_PARAMS.intersection(self.extra_params)\n        if reserved_in_use:\n            raise ValueError(\"Using a reserved parameter\", reserved_in_use)\n\n    def _next_page(self):\n        \"\"\"Get the next page in the iterator.\n\n        Returns:\n            Optional[Page]: The next page in the iterator or :data:`None` if\n                there are no pages left.\n        \"\"\"\n        if self._has_next_page():\n            response = self._get_next_page_response()\n            items = response.get(self._items_key, ())\n            page = Page(self, items, self.item_to_value, raw_page=response)\n            self._page_start(self, page, response)\n            self.next_page_token = response.get(self._next_token)\n            return page\n        else:\n            return None\n\n    def _has_next_page(self):\n        \"\"\"Determines whether or not there are more pages with results.\n\n        Returns:\n            bool: Whether the iterator has more pages.\n        \"\"\"\n        if self.page_number == 0:\n            return True\n\n        if self.max_results is not None:\n            if self.num_results >= self.max_results:\n                return False\n\n        return self.next_page_token is not None\n\n    def _get_query_params(self):\n        \"\"\"Getter for query parameters for the next request.\n\n        Returns:\n            dict: A dictionary of query parameters.\n        \"\"\"\n        result = {}\n        if self.next_page_token is not None:\n            result[self._PAGE_TOKEN] = self.next_page_token\n\n        page_size = None\n        if self.max_results is not None:\n            page_size = self.max_results - self.num_results\n            if self._page_size is not None:\n                page_size = min(page_size, self._page_size)\n        elif self._page_size is not None:\n            page_size = self._page_size\n\n        if page_size is not None:\n            result[self._MAX_RESULTS] = page_size\n\n        result.update(self.extra_params)\n        return result\n\n    def _get_next_page_response(self):\n        \"\"\"Requests the next page from the path provided.\n\n        Returns:\n            dict: The parsed JSON response of the next page's contents.\n\n        Raises:\n            ValueError: If the HTTP method is not ``GET`` or ``POST``.\n        \"\"\"\n        params = self._get_query_params()\n        if self._HTTP_METHOD == \"GET\":\n            return self.api_request(\n                method=self._HTTP_METHOD, path=self.path, query_params=params\n            )\n        elif self._HTTP_METHOD == \"POST\":\n            return self.api_request(\n                method=self._HTTP_METHOD, path=self.path, data=params\n            )\n        else:\n            raise ValueError(\"Unexpected HTTP method\", self._HTTP_METHOD)\n\n\nclass _GAXIterator(Iterator):\n    \"\"\"A generic class for iterating through Cloud gRPC APIs list responses.\n\n    Any:\n        client (google.cloud.client.Client): The API client.\n        page_iter (google.gax.PageIterator): A GAX page iterator to be wrapped\n            to conform to the :class:`Iterator` interface.\n        item_to_value (Callable[Iterator, Any]): Callable to convert an item\n            from the protobuf response into a native object. Will\n            be called with the iterator and a single item.\n        max_results (int): The maximum number of results to fetch.\n\n    .. autoattribute:: pages\n    \"\"\"\n\n    def __init__(self, client, page_iter, item_to_value, max_results=None):\n        super(_GAXIterator, self).__init__(\n            client,\n            item_to_value,\n            page_token=page_iter.page_token,\n            max_results=max_results,\n        )\n        self._gax_page_iter = page_iter\n\n    def _next_page(self):\n        \"\"\"Get the next page in the iterator.\n\n        Wraps the response from the :class:`~google.gax.PageIterator` in a\n        :class:`Page` instance and captures some state at each page.\n\n        Returns:\n            Optional[Page]: The next page in the iterator or :data:`None` if\n                  there are no pages left.\n        \"\"\"\n        try:\n            items = next(self._gax_page_iter)\n            page = Page(self, items, self.item_to_value)\n            self.next_page_token = self._gax_page_iter.page_token or None\n            return page\n        except StopIteration:\n            return None\n\n\nclass GRPCIterator(Iterator):\n    \"\"\"A generic class for iterating through gRPC list responses.\n\n    .. note:: The class does not take a ``page_token`` argument because it can\n        just be specified in the ``request``.\n\n    Args:\n        client (google.cloud.client.Client): The API client. This unused by\n            this class, but kept to satisfy the :class:`Iterator` interface.\n        method (Callable[protobuf.Message]): A bound gRPC method that should\n            take a single message for the request.\n        request (protobuf.Message): The request message.\n        items_field (str): The field in the response message that has the\n            items for the page.\n        item_to_value (Callable[GRPCIterator, Any]): Callable to convert an\n            item from the type in the JSON response into a native object. Will\n            be called with the iterator and a single item.\n        request_token_field (str): The field in the request message used to\n            specify the page token.\n        response_token_field (str): The field in the response message that has\n            the token for the next page.\n        max_results (int): The maximum number of results to fetch.\n\n    .. autoattribute:: pages\n    \"\"\"\n\n    _DEFAULT_REQUEST_TOKEN_FIELD = \"page_token\"\n    _DEFAULT_RESPONSE_TOKEN_FIELD = \"next_page_token\"\n\n    def __init__(\n        self,\n        client,\n        method,\n        request,\n        items_field,\n        item_to_value=_item_to_value_identity,\n        request_token_field=_DEFAULT_REQUEST_TOKEN_FIELD,\n        response_token_field=_DEFAULT_RESPONSE_TOKEN_FIELD,\n        max_results=None,\n    ):\n        super(GRPCIterator, self).__init__(\n            client, item_to_value, max_results=max_results\n        )\n        self._method = method\n        self._request = request\n        self._items_field = items_field\n        self._request_token_field = request_token_field\n        self._response_token_field = response_token_field\n\n    def _next_page(self):\n        \"\"\"Get the next page in the iterator.\n\n        Returns:\n            Page: The next page in the iterator or :data:`None` if\n                there are no pages left.\n        \"\"\"\n        if not self._has_next_page():\n            return None\n\n        if self.next_page_token is not None:\n            setattr(self._request, self._request_token_field, self.next_page_token)\n\n        response = self._method(self._request)\n\n        self.next_page_token = getattr(response, self._response_token_field)\n        items = getattr(response, self._items_field)\n        page = Page(self, items, self.item_to_value, raw_page=response)\n\n        return page\n\n    def _has_next_page(self):\n        \"\"\"Determines whether or not there are more pages with results.\n\n        Returns:\n            bool: Whether the iterator has more pages.\n        \"\"\"\n        if self.page_number == 0:\n            return True\n\n        if self.max_results is not None:\n            if self.num_results >= self.max_results:\n                return False\n\n        # Note: intentionally a falsy check instead of a None check. The RPC\n        # can return an empty string indicating no more pages.\n        return True if self.next_page_token else False\n", "google/api_core/__init__.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Google API Core.\n\nThis package contains common code and utilities used by Google client libraries.\n\"\"\"\n\nfrom google.api_core import version as api_core_version\n\n__version__ = api_core_version.__version__\n", "google/api_core/rest_helpers.py": "# Copyright 2021 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Helpers for rest transports.\"\"\"\n\nimport functools\nimport operator\n\n\ndef flatten_query_params(obj, strict=False):\n    \"\"\"Flatten a dict into a list of (name,value) tuples.\n\n    The result is suitable for setting query params on an http request.\n\n    .. code-block:: python\n\n        >>> obj = {'a':\n        ...         {'b':\n        ...           {'c': ['x', 'y', 'z']} },\n        ...      'd': 'uvw',\n        ...      'e': True, }\n        >>> flatten_query_params(obj, strict=True)\n        [('a.b.c', 'x'), ('a.b.c', 'y'), ('a.b.c', 'z'), ('d', 'uvw'), ('e', 'true')]\n\n    Note that, as described in\n    https://github.com/googleapis/googleapis/blob/48d9fb8c8e287c472af500221c6450ecd45d7d39/google/api/http.proto#L117,\n    repeated fields (i.e. list-valued fields) may only contain primitive types (not lists or dicts).\n    This is enforced in this function.\n\n    Args:\n      obj: a possibly nested dictionary (from json), or None\n      strict: a bool, defaulting to False, to enforce that all values in the\n              result tuples be strings and, if boolean, lower-cased.\n\n    Returns: a list of tuples, with each tuple having a (possibly) multi-part name\n      and a scalar value.\n\n    Raises:\n      TypeError if obj is not a dict or None\n      ValueError if obj contains a list of non-primitive values.\n    \"\"\"\n\n    if obj is not None and not isinstance(obj, dict):\n        raise TypeError(\"flatten_query_params must be called with dict object\")\n\n    return _flatten(obj, key_path=[], strict=strict)\n\n\ndef _flatten(obj, key_path, strict=False):\n    if obj is None:\n        return []\n    if isinstance(obj, dict):\n        return _flatten_dict(obj, key_path=key_path, strict=strict)\n    if isinstance(obj, list):\n        return _flatten_list(obj, key_path=key_path, strict=strict)\n    return _flatten_value(obj, key_path=key_path, strict=strict)\n\n\ndef _is_primitive_value(obj):\n    if obj is None:\n        return False\n\n    if isinstance(obj, (list, dict)):\n        raise ValueError(\"query params may not contain repeated dicts or lists\")\n\n    return True\n\n\ndef _flatten_value(obj, key_path, strict=False):\n    return [(\".\".join(key_path), _canonicalize(obj, strict=strict))]\n\n\ndef _flatten_dict(obj, key_path, strict=False):\n    items = (\n        _flatten(value, key_path=key_path + [key], strict=strict)\n        for key, value in obj.items()\n    )\n    return functools.reduce(operator.concat, items, [])\n\n\ndef _flatten_list(elems, key_path, strict=False):\n    # Only lists of scalar values are supported.\n    # The name (key_path) is repeated for each value.\n    items = (\n        _flatten_value(elem, key_path=key_path, strict=strict)\n        for elem in elems\n        if _is_primitive_value(elem)\n    )\n    return functools.reduce(operator.concat, items, [])\n\n\ndef _canonicalize(obj, strict=False):\n    if strict:\n        value = str(obj)\n        if isinstance(obj, bool):\n            value = value.lower()\n        return value\n    return obj\n", "google/api_core/operation.py": "# Copyright 2016 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Futures for long-running operations returned from Google Cloud APIs.\n\nThese futures can be used to synchronously wait for the result of a\nlong-running operation using :meth:`Operation.result`:\n\n\n.. code-block:: python\n\n    operation = my_api_client.long_running_method()\n    result = operation.result()\n\nOr asynchronously using callbacks and :meth:`Operation.add_done_callback`:\n\n.. code-block:: python\n\n    operation = my_api_client.long_running_method()\n\n    def my_callback(future):\n        result = future.result()\n\n    operation.add_done_callback(my_callback)\n\n\"\"\"\n\nimport functools\nimport threading\n\nfrom google.api_core import exceptions\nfrom google.api_core import protobuf_helpers\nfrom google.api_core.future import polling\nfrom google.longrunning import operations_pb2\nfrom google.protobuf import json_format\nfrom google.rpc import code_pb2\n\n\nclass Operation(polling.PollingFuture):\n    \"\"\"A Future for interacting with a Google API Long-Running Operation.\n\n    Args:\n        operation (google.longrunning.operations_pb2.Operation): The\n            initial operation.\n        refresh (Callable[[], ~.api_core.operation.Operation]): A callable that\n            returns the latest state of the operation.\n        cancel (Callable[[], None]): A callable that tries to cancel\n            the operation.\n        result_type (func:`type`): The protobuf type for the operation's\n            result.\n        metadata_type (func:`type`): The protobuf type for the operation's\n            metadata.\n        polling (google.api_core.retry.Retry): The configuration used for polling.\n            This parameter controls how often :meth:`done` is polled. If the\n            ``timeout`` argument is specified in the :meth:`result` method, it will\n            override the ``polling.timeout`` property.\n        retry (google.api_core.retry.Retry): DEPRECATED: use ``polling`` instead.\n            If specified it will override ``polling`` parameter to maintain\n            backward compatibility.\n    \"\"\"\n\n    def __init__(\n        self,\n        operation,\n        refresh,\n        cancel,\n        result_type,\n        metadata_type=None,\n        polling=polling.DEFAULT_POLLING,\n        **kwargs\n    ):\n        super(Operation, self).__init__(polling=polling, **kwargs)\n        self._operation = operation\n        self._refresh = refresh\n        self._cancel = cancel\n        self._result_type = result_type\n        self._metadata_type = metadata_type\n        self._completion_lock = threading.Lock()\n        # Invoke this in case the operation came back already complete.\n        self._set_result_from_operation()\n\n    @property\n    def operation(self):\n        \"\"\"google.longrunning.Operation: The current long-running operation.\"\"\"\n        return self._operation\n\n    @property\n    def metadata(self):\n        \"\"\"google.protobuf.Message: the current operation metadata.\"\"\"\n        if not self._operation.HasField(\"metadata\"):\n            return None\n\n        return protobuf_helpers.from_any_pb(\n            self._metadata_type, self._operation.metadata\n        )\n\n    @classmethod\n    def deserialize(self, payload):\n        \"\"\"Deserialize a ``google.longrunning.Operation`` protocol buffer.\n\n        Args:\n            payload (bytes): A serialized operation protocol buffer.\n\n        Returns:\n            ~.operations_pb2.Operation: An Operation protobuf object.\n        \"\"\"\n        return operations_pb2.Operation.FromString(payload)\n\n    def _set_result_from_operation(self):\n        \"\"\"Set the result or exception from the operation if it is complete.\"\"\"\n        # This must be done in a lock to prevent the polling thread\n        # and main thread from both executing the completion logic\n        # at the same time.\n        with self._completion_lock:\n            # If the operation isn't complete or if the result has already been\n            # set, do not call set_result/set_exception again.\n            # Note: self._result_set is set to True in set_result and\n            # set_exception, in case those methods are invoked directly.\n            if not self._operation.done or self._result_set:\n                return\n\n            if self._operation.HasField(\"response\"):\n                response = protobuf_helpers.from_any_pb(\n                    self._result_type, self._operation.response\n                )\n                self.set_result(response)\n            elif self._operation.HasField(\"error\"):\n                exception = exceptions.from_grpc_status(\n                    status_code=self._operation.error.code,\n                    message=self._operation.error.message,\n                    errors=(self._operation.error,),\n                    response=self._operation,\n                )\n                self.set_exception(exception)\n            else:\n                exception = exceptions.GoogleAPICallError(\n                    \"Unexpected state: Long-running operation had neither \"\n                    \"response nor error set.\"\n                )\n                self.set_exception(exception)\n\n    def _refresh_and_update(self, retry=None):\n        \"\"\"Refresh the operation and update the result if needed.\n\n        Args:\n            retry (google.api_core.retry.Retry): (Optional) How to retry the RPC.\n        \"\"\"\n        # If the currently cached operation is done, no need to make another\n        # RPC as it will not change once done.\n        if not self._operation.done:\n            self._operation = self._refresh(retry=retry) if retry else self._refresh()\n            self._set_result_from_operation()\n\n    def done(self, retry=None):\n        \"\"\"Checks to see if the operation is complete.\n\n        Args:\n            retry (google.api_core.retry.Retry): (Optional) How to retry the RPC.\n\n        Returns:\n            bool: True if the operation is complete, False otherwise.\n        \"\"\"\n        self._refresh_and_update(retry)\n        return self._operation.done\n\n    def cancel(self):\n        \"\"\"Attempt to cancel the operation.\n\n        Returns:\n            bool: True if the cancel RPC was made, False if the operation is\n                already complete.\n        \"\"\"\n        if self.done():\n            return False\n\n        self._cancel()\n        return True\n\n    def cancelled(self):\n        \"\"\"True if the operation was cancelled.\"\"\"\n        self._refresh_and_update()\n        return (\n            self._operation.HasField(\"error\")\n            and self._operation.error.code == code_pb2.CANCELLED\n        )\n\n\ndef _refresh_http(api_request, operation_name, retry=None):\n    \"\"\"Refresh an operation using a JSON/HTTP client.\n\n    Args:\n        api_request (Callable): A callable used to make an API request. This\n            should generally be\n            :meth:`google.cloud._http.Connection.api_request`.\n        operation_name (str): The name of the operation.\n        retry (google.api_core.retry.Retry): (Optional) retry policy\n\n    Returns:\n        google.longrunning.operations_pb2.Operation: The operation.\n    \"\"\"\n    path = \"operations/{}\".format(operation_name)\n\n    if retry is not None:\n        api_request = retry(api_request)\n\n    api_response = api_request(method=\"GET\", path=path)\n    return json_format.ParseDict(api_response, operations_pb2.Operation())\n\n\ndef _cancel_http(api_request, operation_name):\n    \"\"\"Cancel an operation using a JSON/HTTP client.\n\n    Args:\n        api_request (Callable): A callable used to make an API request. This\n            should generally be\n            :meth:`google.cloud._http.Connection.api_request`.\n        operation_name (str): The name of the operation.\n    \"\"\"\n    path = \"operations/{}:cancel\".format(operation_name)\n    api_request(method=\"POST\", path=path)\n\n\ndef from_http_json(operation, api_request, result_type, **kwargs):\n    \"\"\"Create an operation future using a HTTP/JSON client.\n\n    This interacts with the long-running operations `service`_ (specific\n    to a given API) via `HTTP/JSON`_.\n\n    .. _HTTP/JSON: https://cloud.google.com/speech/reference/rest/\\\n            v1beta1/operations#Operation\n\n    Args:\n        operation (dict): Operation as a dictionary.\n        api_request (Callable): A callable used to make an API request. This\n            should generally be\n            :meth:`google.cloud._http.Connection.api_request`.\n        result_type (:func:`type`): The protobuf result type.\n        kwargs: Keyword args passed into the :class:`Operation` constructor.\n\n    Returns:\n        ~.api_core.operation.Operation: The operation future to track the given\n            operation.\n    \"\"\"\n    operation_proto = json_format.ParseDict(operation, operations_pb2.Operation())\n    refresh = functools.partial(_refresh_http, api_request, operation_proto.name)\n    cancel = functools.partial(_cancel_http, api_request, operation_proto.name)\n    return Operation(operation_proto, refresh, cancel, result_type, **kwargs)\n\n\ndef _refresh_grpc(operations_stub, operation_name, retry=None):\n    \"\"\"Refresh an operation using a gRPC client.\n\n    Args:\n        operations_stub (google.longrunning.operations_pb2.OperationsStub):\n            The gRPC operations stub.\n        operation_name (str): The name of the operation.\n        retry (google.api_core.retry.Retry): (Optional) retry policy\n\n    Returns:\n        google.longrunning.operations_pb2.Operation: The operation.\n    \"\"\"\n    request_pb = operations_pb2.GetOperationRequest(name=operation_name)\n\n    rpc = operations_stub.GetOperation\n    if retry is not None:\n        rpc = retry(rpc)\n\n    return rpc(request_pb)\n\n\ndef _cancel_grpc(operations_stub, operation_name):\n    \"\"\"Cancel an operation using a gRPC client.\n\n    Args:\n        operations_stub (google.longrunning.operations_pb2.OperationsStub):\n            The gRPC operations stub.\n        operation_name (str): The name of the operation.\n    \"\"\"\n    request_pb = operations_pb2.CancelOperationRequest(name=operation_name)\n    operations_stub.CancelOperation(request_pb)\n\n\ndef from_grpc(operation, operations_stub, result_type, grpc_metadata=None, **kwargs):\n    \"\"\"Create an operation future using a gRPC client.\n\n    This interacts with the long-running operations `service`_ (specific\n    to a given API) via gRPC.\n\n    .. _service: https://github.com/googleapis/googleapis/blob/\\\n                 050400df0fdb16f63b63e9dee53819044bffc857/\\\n                 google/longrunning/operations.proto#L38\n\n    Args:\n        operation (google.longrunning.operations_pb2.Operation): The operation.\n        operations_stub (google.longrunning.operations_pb2.OperationsStub):\n            The operations stub.\n        result_type (:func:`type`): The protobuf result type.\n        grpc_metadata (Optional[List[Tuple[str, str]]]): Additional metadata to pass\n            to the rpc.\n        kwargs: Keyword args passed into the :class:`Operation` constructor.\n\n    Returns:\n        ~.api_core.operation.Operation: The operation future to track the given\n            operation.\n    \"\"\"\n    refresh = functools.partial(\n        _refresh_grpc,\n        operations_stub,\n        operation.name,\n        metadata=grpc_metadata,\n    )\n    cancel = functools.partial(\n        _cancel_grpc,\n        operations_stub,\n        operation.name,\n        metadata=grpc_metadata,\n    )\n    return Operation(operation, refresh, cancel, result_type, **kwargs)\n\n\ndef from_gapic(operation, operations_client, result_type, grpc_metadata=None, **kwargs):\n    \"\"\"Create an operation future from a gapic client.\n\n    This interacts with the long-running operations `service`_ (specific\n    to a given API) via a gapic client.\n\n    .. _service: https://github.com/googleapis/googleapis/blob/\\\n                 050400df0fdb16f63b63e9dee53819044bffc857/\\\n                 google/longrunning/operations.proto#L38\n\n    Args:\n        operation (google.longrunning.operations_pb2.Operation): The operation.\n        operations_client (google.api_core.operations_v1.OperationsClient):\n            The operations client.\n        result_type (:func:`type`): The protobuf result type.\n        grpc_metadata (Optional[List[Tuple[str, str]]]): Additional metadata to pass\n            to the rpc.\n        kwargs: Keyword args passed into the :class:`Operation` constructor.\n\n    Returns:\n        ~.api_core.operation.Operation: The operation future to track the given\n            operation.\n    \"\"\"\n    refresh = functools.partial(\n        operations_client.get_operation,\n        operation.name,\n        metadata=grpc_metadata,\n    )\n    cancel = functools.partial(\n        operations_client.cancel_operation,\n        operation.name,\n        metadata=grpc_metadata,\n    )\n    return Operation(operation, refresh, cancel, result_type, **kwargs)\n", "google/api_core/operations_v1/operations_client.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"A client for the google.longrunning.operations meta-API.\n\nThis is a client that deals with long-running operations that follow the\npattern outlined by the `Google API Style Guide`_.\n\nWhen an API method normally takes long time to complete, it can be designed to\nreturn ``Operation`` to the client, and the client can use this interface to\nreceive the real response asynchronously by polling the operation resource to\nreceive the response.\n\nIt is not a separate service, but rather an interface implemented by a larger\nservice. The protocol-level definition is available at\n`google/longrunning/operations.proto`_. Typically, this will be constructed\nautomatically by another client class to deal with operations.\n\n.. _Google API Style Guide:\n    https://cloud.google.com/apis/design/design_pattern\n    s#long_running_operations\n.. _google/longrunning/operations.proto:\n    https://github.com/googleapis/googleapis/blob/master/google/longrunning\n    /operations.proto\n\"\"\"\n\nimport functools\n\nfrom google.api_core import exceptions as core_exceptions\nfrom google.api_core import gapic_v1\nfrom google.api_core import page_iterator\nfrom google.api_core import retry as retries\nfrom google.api_core import timeout as timeouts\nfrom google.longrunning import operations_pb2\nfrom grpc import Compression\n\n\nclass OperationsClient(object):\n    \"\"\"Client for interacting with long-running operations within a service.\n\n    Args:\n        channel (grpc.Channel): The gRPC channel associated with the service\n            that implements the ``google.longrunning.operations`` interface.\n        client_config (dict):\n            A dictionary of call options for each method. If not specified\n            the default configuration is used.\n    \"\"\"\n\n    def __init__(self, channel, client_config=None):\n        # Create the gRPC client stub.\n        self.operations_stub = operations_pb2.OperationsStub(channel)\n\n        default_retry = retries.Retry(\n            initial=0.1,  # seconds\n            maximum=60.0,  # seconds\n            multiplier=1.3,\n            predicate=retries.if_exception_type(\n                core_exceptions.DeadlineExceeded,\n                core_exceptions.ServiceUnavailable,\n            ),\n            timeout=600.0,  # seconds\n        )\n        default_timeout = timeouts.TimeToDeadlineTimeout(timeout=600.0)\n\n        default_compression = Compression.NoCompression\n\n        self._get_operation = gapic_v1.method.wrap_method(\n            self.operations_stub.GetOperation,\n            default_retry=default_retry,\n            default_timeout=default_timeout,\n            default_compression=default_compression,\n        )\n\n        self._list_operations = gapic_v1.method.wrap_method(\n            self.operations_stub.ListOperations,\n            default_retry=default_retry,\n            default_timeout=default_timeout,\n            default_compression=default_compression,\n        )\n\n        self._cancel_operation = gapic_v1.method.wrap_method(\n            self.operations_stub.CancelOperation,\n            default_retry=default_retry,\n            default_timeout=default_timeout,\n            default_compression=default_compression,\n        )\n\n        self._delete_operation = gapic_v1.method.wrap_method(\n            self.operations_stub.DeleteOperation,\n            default_retry=default_retry,\n            default_timeout=default_timeout,\n            default_compression=default_compression,\n        )\n\n    # Service calls\n    def get_operation(\n        self,\n        name,\n        retry=gapic_v1.method.DEFAULT,\n        timeout=gapic_v1.method.DEFAULT,\n        compression=gapic_v1.method.DEFAULT,\n        metadata=None,\n    ):\n        \"\"\"Gets the latest state of a long-running operation.\n\n        Clients can use this method to poll the operation result at intervals\n        as recommended by the API service.\n\n        Example:\n            >>> from google.api_core import operations_v1\n            >>> api = operations_v1.OperationsClient()\n            >>> name = ''\n            >>> response = api.get_operation(name)\n\n        Args:\n            name (str): The name of the operation resource.\n            retry (google.api_core.retry.Retry): The retry strategy to use\n                when invoking the RPC. If unspecified, the default retry from\n                the client configuration will be used. If ``None``, then this\n                method will not retry the RPC at all.\n            timeout (float): The amount of time in seconds to wait for the RPC\n                to complete. Note that if ``retry`` is used, this timeout\n                applies to each individual attempt and the overall time it\n                takes for this method to complete may be longer. If\n                unspecified, the the default timeout in the client\n                configuration is used. If ``None``, then the RPC method will\n                not time out.\n            compression (grpc.Compression): An element of grpc.compression\n                e.g. grpc.compression.Gzip.\n            metadata (Optional[List[Tuple[str, str]]]):\n                Additional gRPC metadata.\n\n        Returns:\n            google.longrunning.operations_pb2.Operation: The state of the\n                operation.\n\n        Raises:\n            google.api_core.exceptions.GoogleAPICallError: If an error occurred\n                while invoking the RPC, the appropriate ``GoogleAPICallError``\n                subclass will be raised.\n        \"\"\"\n        request = operations_pb2.GetOperationRequest(name=name)\n\n        # Add routing header\n        metadata = metadata or []\n        metadata.append(gapic_v1.routing_header.to_grpc_metadata({\"name\": name}))\n\n        return self._get_operation(\n            request,\n            retry=retry,\n            timeout=timeout,\n            compression=compression,\n            metadata=metadata,\n        )\n\n    def list_operations(\n        self,\n        name,\n        filter_,\n        retry=gapic_v1.method.DEFAULT,\n        timeout=gapic_v1.method.DEFAULT,\n        compression=gapic_v1.method.DEFAULT,\n        metadata=None,\n    ):\n        \"\"\"\n        Lists operations that match the specified filter in the request.\n\n        Example:\n            >>> from google.api_core import operations_v1\n            >>> api = operations_v1.OperationsClient()\n            >>> name = ''\n            >>>\n            >>> # Iterate over all results\n            >>> for operation in api.list_operations(name):\n            >>>   # process operation\n            >>>   pass\n            >>>\n            >>> # Or iterate over results one page at a time\n            >>> iter = api.list_operations(name)\n            >>> for page in iter.pages:\n            >>>   for operation in page:\n            >>>     # process operation\n            >>>     pass\n\n        Args:\n            name (str): The name of the operation collection.\n            filter_ (str): The standard list filter.\n            retry (google.api_core.retry.Retry): The retry strategy to use\n                when invoking the RPC. If unspecified, the default retry from\n                the client configuration will be used. If ``None``, then this\n                method will not retry the RPC at all.\n            timeout (float): The amount of time in seconds to wait for the RPC\n                to complete. Note that if ``retry`` is used, this timeout\n                applies to each individual attempt and the overall time it\n                takes for this method to complete may be longer. If\n                unspecified, the the default timeout in the client\n                configuration is used. If ``None``, then the RPC method will\n                not time out.\n            compression (grpc.Compression): An element of grpc.compression\n                e.g. grpc.compression.Gzip.\n            metadata (Optional[List[Tuple[str, str]]]): Additional gRPC\n                metadata.\n\n        Returns:\n            google.api_core.page_iterator.Iterator: An iterator that yields\n                :class:`google.longrunning.operations_pb2.Operation` instances.\n\n        Raises:\n            google.api_core.exceptions.MethodNotImplemented: If the server\n                does not support this method. Services are not required to\n                implement this method.\n            google.api_core.exceptions.GoogleAPICallError: If an error occurred\n                while invoking the RPC, the appropriate ``GoogleAPICallError``\n                subclass will be raised.\n        \"\"\"\n        # Create the request object.\n        request = operations_pb2.ListOperationsRequest(name=name, filter=filter_)\n\n        # Add routing header\n        metadata = metadata or []\n        metadata.append(gapic_v1.routing_header.to_grpc_metadata({\"name\": name}))\n\n        # Create the method used to fetch pages\n        method = functools.partial(\n            self._list_operations,\n            retry=retry,\n            timeout=timeout,\n            compression=compression,\n            metadata=metadata,\n        )\n\n        iterator = page_iterator.GRPCIterator(\n            client=None,\n            method=method,\n            request=request,\n            items_field=\"operations\",\n            request_token_field=\"page_token\",\n            response_token_field=\"next_page_token\",\n        )\n\n        return iterator\n\n    def cancel_operation(\n        self,\n        name,\n        retry=gapic_v1.method.DEFAULT,\n        timeout=gapic_v1.method.DEFAULT,\n        compression=gapic_v1.method.DEFAULT,\n        metadata=None,\n    ):\n        \"\"\"Starts asynchronous cancellation on a long-running operation.\n\n        The server makes a best effort to cancel the operation, but success is\n        not guaranteed. Clients can use :meth:`get_operation` or service-\n        specific methods to check whether the cancellation succeeded or whether\n        the operation completed despite cancellation. On successful\n        cancellation, the operation is not deleted; instead, it becomes an\n        operation with an ``Operation.error`` value with a\n        ``google.rpc.Status.code`` of ``1``, corresponding to\n        ``Code.CANCELLED``.\n\n        Example:\n            >>> from google.api_core import operations_v1\n            >>> api = operations_v1.OperationsClient()\n            >>> name = ''\n            >>> api.cancel_operation(name)\n\n        Args:\n            name (str): The name of the operation resource to be cancelled.\n            retry (google.api_core.retry.Retry): The retry strategy to use\n                when invoking the RPC. If unspecified, the default retry from\n                the client configuration will be used. If ``None``, then this\n                method will not retry the RPC at all.\n            timeout (float): The amount of time in seconds to wait for the RPC\n                to complete. Note that if ``retry`` is used, this timeout\n                applies to each individual attempt and the overall time it\n                takes for this method to complete may be longer. If\n                unspecified, the the default timeout in the client\n                configuration is used. If ``None``, then the RPC method will\n                not time out.\n            compression (grpc.Compression): An element of grpc.compression\n                e.g. grpc.compression.Gzip.\n            metadata (Optional[List[Tuple[str, str]]]): Additional gRPC\n                metadata.\n\n        Raises:\n            google.api_core.exceptions.MethodNotImplemented: If the server\n                does not support this method. Services are not required to\n                implement this method.\n            google.api_core.exceptions.GoogleAPICallError: If an error occurred\n                while invoking the RPC, the appropriate ``GoogleAPICallError``\n                subclass will be raised.\n        \"\"\"\n        # Create the request object.\n        request = operations_pb2.CancelOperationRequest(name=name)\n\n        # Add routing header\n        metadata = metadata or []\n        metadata.append(gapic_v1.routing_header.to_grpc_metadata({\"name\": name}))\n\n        self._cancel_operation(\n            request,\n            retry=retry,\n            timeout=timeout,\n            compression=compression,\n            metadata=metadata,\n        )\n\n    def delete_operation(\n        self,\n        name,\n        retry=gapic_v1.method.DEFAULT,\n        timeout=gapic_v1.method.DEFAULT,\n        compression=gapic_v1.method.DEFAULT,\n        metadata=None,\n    ):\n        \"\"\"Deletes a long-running operation.\n\n        This method indicates that the client is no longer interested in the\n        operation result. It does not cancel the operation.\n\n        Example:\n            >>> from google.api_core import operations_v1\n            >>> api = operations_v1.OperationsClient()\n            >>> name = ''\n            >>> api.delete_operation(name)\n\n        Args:\n            name (str): The name of the operation resource to be deleted.\n            retry (google.api_core.retry.Retry): The retry strategy to use\n                when invoking the RPC. If unspecified, the default retry from\n                the client configuration will be used. If ``None``, then this\n                method will not retry the RPC at all.\n            timeout (float): The amount of time in seconds to wait for the RPC\n                to complete. Note that if ``retry`` is used, this timeout\n                applies to each individual attempt and the overall time it\n                takes for this method to complete may be longer. If\n                unspecified, the the default timeout in the client\n                configuration is used. If ``None``, then the RPC method will\n                not time out.\n            compression (grpc.Compression): An element of grpc.compression\n                e.g. grpc.compression.Gzip.\n            metadata (Optional[List[Tuple[str, str]]]): Additional gRPC\n                metadata.\n\n        Raises:\n            google.api_core.exceptions.MethodNotImplemented: If the server\n                does not support this method. Services are not required to\n                implement this method.\n            google.api_core.exceptions.GoogleAPICallError: If an error occurred\n                while invoking the RPC, the appropriate ``GoogleAPICallError``\n                subclass will be raised.\n        \"\"\"\n        # Create the request object.\n        request = operations_pb2.DeleteOperationRequest(name=name)\n\n        # Add routing header\n        metadata = metadata or []\n        metadata.append(gapic_v1.routing_header.to_grpc_metadata({\"name\": name}))\n\n        self._delete_operation(\n            request,\n            retry=retry,\n            timeout=timeout,\n            compression=compression,\n            metadata=metadata,\n        )\n", "google/api_core/operations_v1/abstract_operations_client.py": "# -*- coding: utf-8 -*-\n# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\nfrom collections import OrderedDict\nimport os\nimport re\nfrom typing import Dict, Optional, Sequence, Tuple, Type, Union\n\nfrom google.api_core import client_options as client_options_lib  # type: ignore\nfrom google.api_core import gapic_v1  # type: ignore\nfrom google.api_core import retry as retries  # type: ignore\nfrom google.api_core.operations_v1 import pagers\nfrom google.api_core.operations_v1.transports.base import (\n    DEFAULT_CLIENT_INFO,\n    OperationsTransport,\n)\nfrom google.api_core.operations_v1.transports.rest import OperationsRestTransport\nfrom google.auth import credentials as ga_credentials  # type: ignore\nfrom google.auth.exceptions import MutualTLSChannelError  # type: ignore\nfrom google.auth.transport import mtls  # type: ignore\nfrom google.longrunning import operations_pb2\nfrom google.oauth2 import service_account  # type: ignore\nimport grpc\n\nOptionalRetry = Union[retries.Retry, object]\n\n\nclass AbstractOperationsClientMeta(type):\n    \"\"\"Metaclass for the Operations client.\n\n    This provides class-level methods for building and retrieving\n    support objects (e.g. transport) without polluting the client instance\n    objects.\n    \"\"\"\n\n    _transport_registry = OrderedDict()  # type: Dict[str, Type[OperationsTransport]]\n    _transport_registry[\"rest\"] = OperationsRestTransport\n\n    def get_transport_class(\n        cls,\n        label: Optional[str] = None,\n    ) -> Type[OperationsTransport]:\n        \"\"\"Returns an appropriate transport class.\n\n        Args:\n            label: The name of the desired transport. If none is\n                provided, then the first transport in the registry is used.\n\n        Returns:\n            The transport class to use.\n        \"\"\"\n        # If a specific transport is requested, return that one.\n        if label:\n            return cls._transport_registry[label]\n\n        # No transport is requested; return the default (that is, the first one\n        # in the dictionary).\n        return next(iter(cls._transport_registry.values()))\n\n\nclass AbstractOperationsClient(metaclass=AbstractOperationsClientMeta):\n    \"\"\"Manages long-running operations with an API service.\n\n    When an API method normally takes long time to complete, it can be\n    designed to return [Operation][google.api_core.operations_v1.Operation] to the\n    client, and the client can use this interface to receive the real\n    response asynchronously by polling the operation resource, or pass\n    the operation resource to another API (such as Google Cloud Pub/Sub\n    API) to receive the response. Any API service that returns\n    long-running operations should implement the ``Operations``\n    interface so developers can have a consistent client experience.\n    \"\"\"\n\n    @staticmethod\n    def _get_default_mtls_endpoint(api_endpoint):\n        \"\"\"Converts api endpoint to mTLS endpoint.\n\n        Convert \"*.sandbox.googleapis.com\" and \"*.googleapis.com\" to\n        \"*.mtls.sandbox.googleapis.com\" and \"*.mtls.googleapis.com\" respectively.\n        Args:\n            api_endpoint (Optional[str]): the api endpoint to convert.\n        Returns:\n            str: converted mTLS api endpoint.\n        \"\"\"\n        if not api_endpoint:\n            return api_endpoint\n\n        mtls_endpoint_re = re.compile(\n            r\"(?P<name>[^.]+)(?P<mtls>\\.mtls)?(?P<sandbox>\\.sandbox)?(?P<googledomain>\\.googleapis\\.com)?\"\n        )\n\n        m = mtls_endpoint_re.match(api_endpoint)\n        name, mtls, sandbox, googledomain = m.groups()\n        if mtls or not googledomain:\n            return api_endpoint\n\n        if sandbox:\n            return api_endpoint.replace(\n                \"sandbox.googleapis.com\", \"mtls.sandbox.googleapis.com\"\n            )\n\n        return api_endpoint.replace(\".googleapis.com\", \".mtls.googleapis.com\")\n\n    DEFAULT_ENDPOINT = \"longrunning.googleapis.com\"\n    DEFAULT_MTLS_ENDPOINT = _get_default_mtls_endpoint.__func__(  # type: ignore\n        DEFAULT_ENDPOINT\n    )\n\n    @classmethod\n    def from_service_account_info(cls, info: dict, *args, **kwargs):\n        \"\"\"Creates an instance of this client using the provided credentials\n            info.\n\n        Args:\n            info (dict): The service account private key info.\n            args: Additional arguments to pass to the constructor.\n            kwargs: Additional arguments to pass to the constructor.\n\n        Returns:\n            AbstractOperationsClient: The constructed client.\n        \"\"\"\n        credentials = service_account.Credentials.from_service_account_info(info)\n        kwargs[\"credentials\"] = credentials\n        return cls(*args, **kwargs)\n\n    @classmethod\n    def from_service_account_file(cls, filename: str, *args, **kwargs):\n        \"\"\"Creates an instance of this client using the provided credentials\n            file.\n\n        Args:\n            filename (str): The path to the service account private key json\n                file.\n            args: Additional arguments to pass to the constructor.\n            kwargs: Additional arguments to pass to the constructor.\n\n        Returns:\n            AbstractOperationsClient: The constructed client.\n        \"\"\"\n        credentials = service_account.Credentials.from_service_account_file(filename)\n        kwargs[\"credentials\"] = credentials\n        return cls(*args, **kwargs)\n\n    from_service_account_json = from_service_account_file\n\n    @property\n    def transport(self) -> OperationsTransport:\n        \"\"\"Returns the transport used by the client instance.\n\n        Returns:\n            OperationsTransport: The transport used by the client\n                instance.\n        \"\"\"\n        return self._transport\n\n    @staticmethod\n    def common_billing_account_path(\n        billing_account: str,\n    ) -> str:\n        \"\"\"Returns a fully-qualified billing_account string.\"\"\"\n        return \"billingAccounts/{billing_account}\".format(\n            billing_account=billing_account,\n        )\n\n    @staticmethod\n    def parse_common_billing_account_path(path: str) -> Dict[str, str]:\n        \"\"\"Parse a billing_account path into its component segments.\"\"\"\n        m = re.match(r\"^billingAccounts/(?P<billing_account>.+?)$\", path)\n        return m.groupdict() if m else {}\n\n    @staticmethod\n    def common_folder_path(\n        folder: str,\n    ) -> str:\n        \"\"\"Returns a fully-qualified folder string.\"\"\"\n        return \"folders/{folder}\".format(\n            folder=folder,\n        )\n\n    @staticmethod\n    def parse_common_folder_path(path: str) -> Dict[str, str]:\n        \"\"\"Parse a folder path into its component segments.\"\"\"\n        m = re.match(r\"^folders/(?P<folder>.+?)$\", path)\n        return m.groupdict() if m else {}\n\n    @staticmethod\n    def common_organization_path(\n        organization: str,\n    ) -> str:\n        \"\"\"Returns a fully-qualified organization string.\"\"\"\n        return \"organizations/{organization}\".format(\n            organization=organization,\n        )\n\n    @staticmethod\n    def parse_common_organization_path(path: str) -> Dict[str, str]:\n        \"\"\"Parse a organization path into its component segments.\"\"\"\n        m = re.match(r\"^organizations/(?P<organization>.+?)$\", path)\n        return m.groupdict() if m else {}\n\n    @staticmethod\n    def common_project_path(\n        project: str,\n    ) -> str:\n        \"\"\"Returns a fully-qualified project string.\"\"\"\n        return \"projects/{project}\".format(\n            project=project,\n        )\n\n    @staticmethod\n    def parse_common_project_path(path: str) -> Dict[str, str]:\n        \"\"\"Parse a project path into its component segments.\"\"\"\n        m = re.match(r\"^projects/(?P<project>.+?)$\", path)\n        return m.groupdict() if m else {}\n\n    @staticmethod\n    def common_location_path(\n        project: str,\n        location: str,\n    ) -> str:\n        \"\"\"Returns a fully-qualified location string.\"\"\"\n        return \"projects/{project}/locations/{location}\".format(\n            project=project,\n            location=location,\n        )\n\n    @staticmethod\n    def parse_common_location_path(path: str) -> Dict[str, str]:\n        \"\"\"Parse a location path into its component segments.\"\"\"\n        m = re.match(r\"^projects/(?P<project>.+?)/locations/(?P<location>.+?)$\", path)\n        return m.groupdict() if m else {}\n\n    def __init__(\n        self,\n        *,\n        credentials: Optional[ga_credentials.Credentials] = None,\n        transport: Union[str, OperationsTransport, None] = None,\n        client_options: Optional[client_options_lib.ClientOptions] = None,\n        client_info: gapic_v1.client_info.ClientInfo = DEFAULT_CLIENT_INFO,\n    ) -> None:\n        \"\"\"Instantiates the operations client.\n\n        Args:\n            credentials (Optional[google.auth.credentials.Credentials]): The\n                authorization credentials to attach to requests. These\n                credentials identify the application to the service; if none\n                are specified, the client will attempt to ascertain the\n                credentials from the environment.\n            transport (Union[str, OperationsTransport]): The\n                transport to use. If set to None, a transport is chosen\n                automatically.\n            client_options (google.api_core.client_options.ClientOptions): Custom options for the\n                client. It won't take effect if a ``transport`` instance is provided.\n                (1) The ``api_endpoint`` property can be used to override the\n                default endpoint provided by the client. GOOGLE_API_USE_MTLS_ENDPOINT\n                environment variable can also be used to override the endpoint:\n                \"always\" (always use the default mTLS endpoint), \"never\" (always\n                use the default regular endpoint) and \"auto\" (auto switch to the\n                default mTLS endpoint if client certificate is present, this is\n                the default value). However, the ``api_endpoint`` property takes\n                precedence if provided.\n                (2) If GOOGLE_API_USE_CLIENT_CERTIFICATE environment variable\n                is \"true\", then the ``client_cert_source`` property can be used\n                to provide client certificate for mutual TLS transport. If\n                not provided, the default SSL client certificate will be used if\n                present. If GOOGLE_API_USE_CLIENT_CERTIFICATE is \"false\" or not\n                set, no client certificate will be used.\n            client_info (google.api_core.gapic_v1.client_info.ClientInfo):\n                The client info used to send a user-agent string along with\n                API requests. If ``None``, then default info will be used.\n                Generally, you only need to set this if you're developing\n                your own client library.\n\n        Raises:\n            google.auth.exceptions.MutualTLSChannelError: If mutual TLS transport\n                creation failed for any reason.\n        \"\"\"\n        if isinstance(client_options, dict):\n            client_options = client_options_lib.from_dict(client_options)\n        if client_options is None:\n            client_options = client_options_lib.ClientOptions()\n\n        # Create SSL credentials for mutual TLS if needed.\n        use_client_cert = os.getenv(\n            \"GOOGLE_API_USE_CLIENT_CERTIFICATE\", \"false\"\n        ).lower()\n        if use_client_cert not in (\"true\", \"false\"):\n            raise ValueError(\n                \"Environment variable `GOOGLE_API_USE_CLIENT_CERTIFICATE` must be either `true` or `false`\"\n            )\n        client_cert_source_func = None\n        is_mtls = False\n        if use_client_cert == \"true\":\n            if client_options.client_cert_source:\n                is_mtls = True\n                client_cert_source_func = client_options.client_cert_source\n            else:\n                is_mtls = mtls.has_default_client_cert_source()\n                if is_mtls:\n                    client_cert_source_func = mtls.default_client_cert_source()\n                else:\n                    client_cert_source_func = None\n\n        # Figure out which api endpoint to use.\n        if client_options.api_endpoint is not None:\n            api_endpoint = client_options.api_endpoint\n        else:\n            use_mtls_env = os.getenv(\"GOOGLE_API_USE_MTLS_ENDPOINT\", \"auto\")\n            if use_mtls_env == \"never\":\n                api_endpoint = self.DEFAULT_ENDPOINT\n            elif use_mtls_env == \"always\":\n                api_endpoint = self.DEFAULT_MTLS_ENDPOINT\n            elif use_mtls_env == \"auto\":\n                if is_mtls:\n                    api_endpoint = self.DEFAULT_MTLS_ENDPOINT\n                else:\n                    api_endpoint = self.DEFAULT_ENDPOINT\n            else:\n                raise MutualTLSChannelError(\n                    \"Unsupported GOOGLE_API_USE_MTLS_ENDPOINT value. Accepted \"\n                    \"values: never, auto, always\"\n                )\n\n        # Save or instantiate the transport.\n        # Ordinarily, we provide the transport, but allowing a custom transport\n        # instance provides an extensibility point for unusual situations.\n        if isinstance(transport, OperationsTransport):\n            # transport is a OperationsTransport instance.\n            if credentials or client_options.credentials_file:\n                raise ValueError(\n                    \"When providing a transport instance, \"\n                    \"provide its credentials directly.\"\n                )\n            if client_options.scopes:\n                raise ValueError(\n                    \"When providing a transport instance, provide its scopes \"\n                    \"directly.\"\n                )\n            self._transport = transport\n        else:\n            Transport = type(self).get_transport_class(transport)\n            self._transport = Transport(\n                credentials=credentials,\n                credentials_file=client_options.credentials_file,\n                host=api_endpoint,\n                scopes=client_options.scopes,\n                client_cert_source_for_mtls=client_cert_source_func,\n                quota_project_id=client_options.quota_project_id,\n                client_info=client_info,\n                always_use_jwt_access=True,\n            )\n\n    def list_operations(\n        self,\n        name: str,\n        filter_: Optional[str] = None,\n        *,\n        page_size: Optional[int] = None,\n        page_token: Optional[str] = None,\n        retry: OptionalRetry = gapic_v1.method.DEFAULT,\n        timeout: Optional[float] = None,\n        compression: Optional[grpc.Compression] = gapic_v1.method.DEFAULT,\n        metadata: Sequence[Tuple[str, str]] = (),\n    ) -> pagers.ListOperationsPager:\n        r\"\"\"Lists operations that match the specified filter in the request.\n        If the server doesn't support this method, it returns\n        ``UNIMPLEMENTED``.\n\n        NOTE: the ``name`` binding allows API services to override the\n        binding to use different resource name schemes, such as\n        ``users/*/operations``. To override the binding, API services\n        can add a binding such as ``\"/v1/{name=users/*}/operations\"`` to\n        their service configuration. For backwards compatibility, the\n        default name includes the operations collection id, however\n        overriding users must ensure the name binding is the parent\n        resource, without the operations collection id.\n\n        Args:\n            name (str):\n                The name of the operation's parent\n                resource.\n            filter_ (str):\n                The standard list filter.\n                This corresponds to the ``filter`` field\n                on the ``request`` instance; if ``request`` is provided, this\n                should not be set.\n            retry (google.api_core.retry.Retry): Designation of what errors, if any,\n                should be retried.\n            timeout (float): The timeout for this request.\n            metadata (Sequence[Tuple[str, str]]): Strings which should be\n                sent along with the request as metadata.\n\n        Returns:\n            google.api_core.operations_v1.pagers.ListOperationsPager:\n                The response message for\n                [Operations.ListOperations][google.api_core.operations_v1.Operations.ListOperations].\n\n                Iterating over this object will yield results and\n                resolve additional pages automatically.\n\n        \"\"\"\n        # Create a protobuf request object.\n        request = operations_pb2.ListOperationsRequest(name=name, filter=filter_)\n        if page_size is not None:\n            request.page_size = page_size\n        if page_token is not None:\n            request.page_token = page_token\n\n        # Wrap the RPC method; this adds retry and timeout information,\n        # and friendly error handling.\n        rpc = self._transport._wrapped_methods[self._transport.list_operations]\n\n        # Certain fields should be provided within the metadata header;\n        # add these here.\n        metadata = tuple(metadata or ()) + (\n            gapic_v1.routing_header.to_grpc_metadata(((\"name\", request.name),)),\n        )\n\n        # Send the request.\n        response = rpc(\n            request,\n            retry=retry,\n            timeout=timeout,\n            compression=compression,\n            metadata=metadata,\n        )\n\n        # This method is paged; wrap the response in a pager, which provides\n        # an `__iter__` convenience method.\n        response = pagers.ListOperationsPager(\n            method=rpc,\n            request=request,\n            response=response,\n            metadata=metadata,\n        )\n\n        # Done; return the response.\n        return response\n\n    def get_operation(\n        self,\n        name: str,\n        *,\n        retry: OptionalRetry = gapic_v1.method.DEFAULT,\n        timeout: Optional[float] = None,\n        compression: Optional[grpc.Compression] = gapic_v1.method.DEFAULT,\n        metadata: Sequence[Tuple[str, str]] = (),\n    ) -> operations_pb2.Operation:\n        r\"\"\"Gets the latest state of a long-running operation.\n        Clients can use this method to poll the operation result\n        at intervals as recommended by the API service.\n\n        Args:\n            name (str):\n                The name of the operation resource.\n            retry (google.api_core.retry.Retry): Designation of what errors, if any,\n                should be retried.\n            timeout (float): The timeout for this request.\n            metadata (Sequence[Tuple[str, str]]): Strings which should be\n                sent along with the request as metadata.\n\n        Returns:\n            google.longrunning.operations_pb2.Operation:\n                This resource represents a long-\n                running operation that is the result of a\n                network API call.\n\n        \"\"\"\n\n        request = operations_pb2.GetOperationRequest(name=name)\n\n        # Wrap the RPC method; this adds retry and timeout information,\n        # and friendly error handling.\n        rpc = self._transport._wrapped_methods[self._transport.get_operation]\n\n        # Certain fields should be provided within the metadata header;\n        # add these here.\n        metadata = tuple(metadata or ()) + (\n            gapic_v1.routing_header.to_grpc_metadata(((\"name\", request.name),)),\n        )\n\n        # Send the request.\n        response = rpc(\n            request,\n            retry=retry,\n            timeout=timeout,\n            compression=compression,\n            metadata=metadata,\n        )\n\n        # Done; return the response.\n        return response\n\n    def delete_operation(\n        self,\n        name: str,\n        *,\n        retry: OptionalRetry = gapic_v1.method.DEFAULT,\n        timeout: Optional[float] = None,\n        compression: Optional[grpc.Compression] = gapic_v1.method.DEFAULT,\n        metadata: Sequence[Tuple[str, str]] = (),\n    ) -> None:\n        r\"\"\"Deletes a long-running operation. This method indicates that the\n        client is no longer interested in the operation result. It does\n        not cancel the operation. If the server doesn't support this\n        method, it returns ``google.rpc.Code.UNIMPLEMENTED``.\n\n        Args:\n            name (str):\n                The name of the operation resource to\n                be deleted.\n\n                This corresponds to the ``name`` field\n                on the ``request`` instance; if ``request`` is provided, this\n                should not be set.\n            retry (google.api_core.retry.Retry): Designation of what errors, if any,\n                should be retried.\n            timeout (float): The timeout for this request.\n            metadata (Sequence[Tuple[str, str]]): Strings which should be\n                sent along with the request as metadata.\n        \"\"\"\n        # Create the request object.\n        request = operations_pb2.DeleteOperationRequest(name=name)\n\n        # Wrap the RPC method; this adds retry and timeout information,\n        # and friendly error handling.\n        rpc = self._transport._wrapped_methods[self._transport.delete_operation]\n\n        # Certain fields should be provided within the metadata header;\n        # add these here.\n        metadata = tuple(metadata or ()) + (\n            gapic_v1.routing_header.to_grpc_metadata(((\"name\", request.name),)),\n        )\n\n        # Send the request.\n        rpc(\n            request,\n            retry=retry,\n            timeout=timeout,\n            compression=compression,\n            metadata=metadata,\n        )\n\n    def cancel_operation(\n        self,\n        name: Optional[str] = None,\n        *,\n        retry: OptionalRetry = gapic_v1.method.DEFAULT,\n        timeout: Optional[float] = None,\n        compression: Optional[grpc.Compression] = gapic_v1.method.DEFAULT,\n        metadata: Sequence[Tuple[str, str]] = (),\n    ) -> None:\n        r\"\"\"Starts asynchronous cancellation on a long-running operation.\n        The server makes a best effort to cancel the operation, but\n        success is not guaranteed. If the server doesn't support this\n        method, it returns ``google.rpc.Code.UNIMPLEMENTED``. Clients\n        can use\n        [Operations.GetOperation][google.api_core.operations_v1.Operations.GetOperation]\n        or other methods to check whether the cancellation succeeded or\n        whether the operation completed despite cancellation. On\n        successful cancellation, the operation is not deleted; instead,\n        it becomes an operation with an\n        [Operation.error][google.api_core.operations_v1.Operation.error] value with\n        a [google.rpc.Status.code][google.rpc.Status.code] of 1,\n        corresponding to ``Code.CANCELLED``.\n\n        Args:\n            name (str):\n                The name of the operation resource to\n                be cancelled.\n\n                This corresponds to the ``name`` field\n                on the ``request`` instance; if ``request`` is provided, this\n                should not be set.\n            retry (google.api_core.retry.Retry): Designation of what errors, if any,\n                should be retried.\n            timeout (float): The timeout for this request.\n            metadata (Sequence[Tuple[str, str]]): Strings which should be\n                sent along with the request as metadata.\n        \"\"\"\n        # Create the request object.\n        request = operations_pb2.CancelOperationRequest(name=name)\n\n        # Wrap the RPC method; this adds retry and timeout information,\n        # and friendly error handling.\n        rpc = self._transport._wrapped_methods[self._transport.cancel_operation]\n\n        # Certain fields should be provided within the metadata header;\n        # add these here.\n        metadata = tuple(metadata or ()) + (\n            gapic_v1.routing_header.to_grpc_metadata(((\"name\", request.name),)),\n        )\n\n        # Send the request.\n        rpc(\n            request,\n            retry=retry,\n            timeout=timeout,\n            compression=compression,\n            metadata=metadata,\n        )\n", "google/api_core/operations_v1/operations_async_client.py": "# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"An async client for the google.longrunning.operations meta-API.\n\n.. _Google API Style Guide:\n    https://cloud.google.com/apis/design/design_pattern\n    s#long_running_operations\n.. _google/longrunning/operations.proto:\n    https://github.com/googleapis/googleapis/blob/master/google/longrunning\n    /operations.proto\n\"\"\"\n\nimport functools\n\nfrom google.api_core import exceptions as core_exceptions\nfrom google.api_core import gapic_v1, page_iterator_async\nfrom google.api_core import retry_async as retries\nfrom google.api_core import timeout as timeouts\nfrom google.longrunning import operations_pb2\nfrom grpc import Compression\n\n\nclass OperationsAsyncClient:\n    \"\"\"Async client for interacting with long-running operations.\n\n    Args:\n        channel (aio.Channel): The gRPC AsyncIO channel associated with the\n            service that implements the ``google.longrunning.operations``\n            interface.\n        client_config (dict):\n            A dictionary of call options for each method. If not specified\n            the default configuration is used.\n    \"\"\"\n\n    def __init__(self, channel, client_config=None):\n        # Create the gRPC client stub with gRPC AsyncIO channel.\n        self.operations_stub = operations_pb2.OperationsStub(channel)\n\n        default_retry = retries.AsyncRetry(\n            initial=0.1,  # seconds\n            maximum=60.0,  # seconds\n            multiplier=1.3,\n            predicate=retries.if_exception_type(\n                core_exceptions.DeadlineExceeded,\n                core_exceptions.ServiceUnavailable,\n            ),\n            timeout=600.0,  # seconds\n        )\n        default_timeout = timeouts.TimeToDeadlineTimeout(timeout=600.0)\n\n        default_compression = Compression.NoCompression\n\n        self._get_operation = gapic_v1.method_async.wrap_method(\n            self.operations_stub.GetOperation,\n            default_retry=default_retry,\n            default_timeout=default_timeout,\n            default_compression=default_compression,\n        )\n\n        self._list_operations = gapic_v1.method_async.wrap_method(\n            self.operations_stub.ListOperations,\n            default_retry=default_retry,\n            default_timeout=default_timeout,\n            default_compression=default_compression,\n        )\n\n        self._cancel_operation = gapic_v1.method_async.wrap_method(\n            self.operations_stub.CancelOperation,\n            default_retry=default_retry,\n            default_timeout=default_timeout,\n            default_compression=default_compression,\n        )\n\n        self._delete_operation = gapic_v1.method_async.wrap_method(\n            self.operations_stub.DeleteOperation,\n            default_retry=default_retry,\n            default_timeout=default_timeout,\n            default_compression=default_compression,\n        )\n\n    async def get_operation(\n        self,\n        name,\n        retry=gapic_v1.method_async.DEFAULT,\n        timeout=gapic_v1.method_async.DEFAULT,\n        compression=gapic_v1.method_async.DEFAULT,\n        metadata=None,\n    ):\n        \"\"\"Gets the latest state of a long-running operation.\n\n        Clients can use this method to poll the operation result at intervals\n        as recommended by the API service.\n\n        Example:\n            >>> from google.api_core import operations_v1\n            >>> api = operations_v1.OperationsClient()\n            >>> name = ''\n            >>> response = await api.get_operation(name)\n\n        Args:\n            name (str): The name of the operation resource.\n            retry (google.api_core.retry.Retry): The retry strategy to use\n                when invoking the RPC. If unspecified, the default retry from\n                the client configuration will be used. If ``None``, then this\n                method will not retry the RPC at all.\n            timeout (float): The amount of time in seconds to wait for the RPC\n                to complete. Note that if ``retry`` is used, this timeout\n                applies to each individual attempt and the overall time it\n                takes for this method to complete may be longer. If\n                unspecified, the the default timeout in the client\n                configuration is used. If ``None``, then the RPC method will\n                not time out.\n            compression (grpc.Compression): An element of grpc.compression\n                e.g. grpc.compression.Gzip.\n            metadata (Optional[List[Tuple[str, str]]]):\n                Additional gRPC metadata.\n\n        Returns:\n            google.longrunning.operations_pb2.Operation: The state of the\n                operation.\n\n        Raises:\n            google.api_core.exceptions.GoogleAPICallError: If an error occurred\n                while invoking the RPC, the appropriate ``GoogleAPICallError``\n                subclass will be raised.\n        \"\"\"\n        request = operations_pb2.GetOperationRequest(name=name)\n\n        # Add routing header\n        metadata = metadata or []\n        metadata.append(gapic_v1.routing_header.to_grpc_metadata({\"name\": name}))\n\n        return await self._get_operation(\n            request,\n            retry=retry,\n            timeout=timeout,\n            compression=compression,\n            metadata=metadata,\n        )\n\n    async def list_operations(\n        self,\n        name,\n        filter_,\n        retry=gapic_v1.method_async.DEFAULT,\n        timeout=gapic_v1.method_async.DEFAULT,\n        compression=gapic_v1.method_async.DEFAULT,\n        metadata=None,\n    ):\n        \"\"\"\n        Lists operations that match the specified filter in the request.\n\n        Example:\n            >>> from google.api_core import operations_v1\n            >>> api = operations_v1.OperationsClient()\n            >>> name = ''\n            >>>\n            >>> # Iterate over all results\n            >>> for operation in await api.list_operations(name):\n            >>>   # process operation\n            >>>   pass\n            >>>\n            >>> # Or iterate over results one page at a time\n            >>> iter = await api.list_operations(name)\n            >>> for page in iter.pages:\n            >>>   for operation in page:\n            >>>     # process operation\n            >>>     pass\n\n        Args:\n            name (str): The name of the operation collection.\n            filter_ (str): The standard list filter.\n            retry (google.api_core.retry.Retry): The retry strategy to use\n                when invoking the RPC. If unspecified, the default retry from\n                the client configuration will be used. If ``None``, then this\n                method will not retry the RPC at all.\n            timeout (float): The amount of time in seconds to wait for the RPC\n                to complete. Note that if ``retry`` is used, this timeout\n                applies to each individual attempt and the overall time it\n                takes for this method to complete may be longer. If\n                unspecified, the the default timeout in the client\n                configuration is used. If ``None``, then the RPC method will\n                not time out.\n            compression (grpc.Compression): An element of grpc.compression\n                e.g. grpc.compression.Gzip.\n            metadata (Optional[List[Tuple[str, str]]]): Additional gRPC\n                metadata.\n\n        Returns:\n            google.api_core.page_iterator.Iterator: An iterator that yields\n                :class:`google.longrunning.operations_pb2.Operation` instances.\n\n        Raises:\n            google.api_core.exceptions.MethodNotImplemented: If the server\n                does not support this method. Services are not required to\n                implement this method.\n            google.api_core.exceptions.GoogleAPICallError: If an error occurred\n                while invoking the RPC, the appropriate ``GoogleAPICallError``\n                subclass will be raised.\n        \"\"\"\n        # Create the request object.\n        request = operations_pb2.ListOperationsRequest(name=name, filter=filter_)\n\n        # Add routing header\n        metadata = metadata or []\n        metadata.append(gapic_v1.routing_header.to_grpc_metadata({\"name\": name}))\n\n        # Create the method used to fetch pages\n        method = functools.partial(\n            self._list_operations,\n            retry=retry,\n            timeout=timeout,\n            compression=compression,\n            metadata=metadata,\n        )\n\n        iterator = page_iterator_async.AsyncGRPCIterator(\n            client=None,\n            method=method,\n            request=request,\n            items_field=\"operations\",\n            request_token_field=\"page_token\",\n            response_token_field=\"next_page_token\",\n        )\n\n        return iterator\n\n    async def cancel_operation(\n        self,\n        name,\n        retry=gapic_v1.method_async.DEFAULT,\n        timeout=gapic_v1.method_async.DEFAULT,\n        compression=gapic_v1.method_async.DEFAULT,\n        metadata=None,\n    ):\n        \"\"\"Starts asynchronous cancellation on a long-running operation.\n\n        The server makes a best effort to cancel the operation, but success is\n        not guaranteed. Clients can use :meth:`get_operation` or service-\n        specific methods to check whether the cancellation succeeded or whether\n        the operation completed despite cancellation. On successful\n        cancellation, the operation is not deleted; instead, it becomes an\n        operation with an ``Operation.error`` value with a\n        ``google.rpc.Status.code`` of ``1``, corresponding to\n        ``Code.CANCELLED``.\n\n        Example:\n            >>> from google.api_core import operations_v1\n            >>> api = operations_v1.OperationsClient()\n            >>> name = ''\n            >>> api.cancel_operation(name)\n\n        Args:\n            name (str): The name of the operation resource to be cancelled.\n            retry (google.api_core.retry.Retry): The retry strategy to use\n                when invoking the RPC. If unspecified, the default retry from\n                the client configuration will be used. If ``None``, then this\n                method will not retry the RPC at all.\n            timeout (float): The amount of time in seconds to wait for the RPC\n                to complete. Note that if ``retry`` is used, this timeout\n                applies to each individual attempt and the overall time it\n                takes for this method to complete may be longer. If\n                unspecified, the the default timeout in the client\n                configuration is used. If ``None``, then the RPC method will\n                not time out.\n\n        Raises:\n            google.api_core.exceptions.MethodNotImplemented: If the server\n                does not support this method. Services are not required to\n                implement this method.\n            google.api_core.exceptions.GoogleAPICallError: If an error occurred\n                while invoking the RPC, the appropriate ``GoogleAPICallError``\n                subclass will be raised.\n            compression (grpc.Compression): An element of grpc.compression\n                e.g. grpc.compression.Gzip.\n            metadata (Optional[List[Tuple[str, str]]]): Additional gRPC\n                metadata.\n        \"\"\"\n        # Create the request object.\n        request = operations_pb2.CancelOperationRequest(name=name)\n\n        # Add routing header\n        metadata = metadata or []\n        metadata.append(gapic_v1.routing_header.to_grpc_metadata({\"name\": name}))\n\n        await self._cancel_operation(\n            request,\n            retry=retry,\n            timeout=timeout,\n            compression=compression,\n            metadata=metadata,\n        )\n\n    async def delete_operation(\n        self,\n        name,\n        retry=gapic_v1.method_async.DEFAULT,\n        timeout=gapic_v1.method_async.DEFAULT,\n        compression=gapic_v1.method_async.DEFAULT,\n        metadata=None,\n    ):\n        \"\"\"Deletes a long-running operation.\n\n        This method indicates that the client is no longer interested in the\n        operation result. It does not cancel the operation.\n\n        Example:\n            >>> from google.api_core import operations_v1\n            >>> api = operations_v1.OperationsClient()\n            >>> name = ''\n            >>> api.delete_operation(name)\n\n        Args:\n            name (str): The name of the operation resource to be deleted.\n            retry (google.api_core.retry.Retry): The retry strategy to use\n                when invoking the RPC. If unspecified, the default retry from\n                the client configuration will be used. If ``None``, then this\n                method will not retry the RPC at all.\n            timeout (float): The amount of time in seconds to wait for the RPC\n                to complete. Note that if ``retry`` is used, this timeout\n                applies to each individual attempt and the overall time it\n                takes for this method to complete may be longer. If\n                unspecified, the the default timeout in the client\n                configuration is used. If ``None``, then the RPC method will\n                not time out.\n            compression (grpc.Compression): An element of grpc.compression\n                e.g. grpc.compression.Gzip.\n            metadata (Optional[List[Tuple[str, str]]]): Additional gRPC\n                metadata.\n\n        Raises:\n            google.api_core.exceptions.MethodNotImplemented: If the server\n                does not support this method. Services are not required to\n                implement this method.\n            google.api_core.exceptions.GoogleAPICallError: If an error occurred\n                while invoking the RPC, the appropriate ``GoogleAPICallError``\n                subclass will be raised.\n        \"\"\"\n        # Create the request object.\n        request = operations_pb2.DeleteOperationRequest(name=name)\n\n        # Add routing header\n        metadata = metadata or []\n        metadata.append(gapic_v1.routing_header.to_grpc_metadata({\"name\": name}))\n\n        await self._delete_operation(\n            request,\n            retry=retry,\n            timeout=timeout,\n            compression=compression,\n            metadata=metadata,\n        )\n", "google/api_core/operations_v1/pagers.py": "# -*- coding: utf-8 -*-\n# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\nfrom typing import (\n    Any,\n    Callable,\n    Iterator,\n    Sequence,\n    Tuple,\n)\n\nfrom google.longrunning import operations_pb2\n\n\nclass ListOperationsPager:\n    \"\"\"A pager for iterating through ``list_operations`` requests.\n\n    This class thinly wraps an initial\n    :class:`google.longrunning.operations_pb2.ListOperationsResponse` object, and\n    provides an ``__iter__`` method to iterate through its\n    ``operations`` field.\n\n    If there are more pages, the ``__iter__`` method will make additional\n    ``ListOperations`` requests and continue to iterate\n    through the ``operations`` field on the\n    corresponding responses.\n\n    All the usual :class:`google.longrunning.operations_pb2.ListOperationsResponse`\n    attributes are available on the pager. If multiple requests are made, only\n    the most recent response is retained, and thus used for attribute lookup.\n    \"\"\"\n\n    def __init__(\n        self,\n        method: Callable[..., operations_pb2.ListOperationsResponse],\n        request: operations_pb2.ListOperationsRequest,\n        response: operations_pb2.ListOperationsResponse,\n        *,\n        metadata: Sequence[Tuple[str, str]] = ()\n    ):\n        \"\"\"Instantiate the pager.\n\n        Args:\n            method (Callable): The method that was originally called, and\n                which instantiated this pager.\n            request (google.longrunning.operations_pb2.ListOperationsRequest):\n                The initial request object.\n            response (google.longrunning.operations_pb2.ListOperationsResponse):\n                The initial response object.\n            metadata (Sequence[Tuple[str, str]]): Strings which should be\n                sent along with the request as metadata.\n        \"\"\"\n        self._method = method\n        self._request = request\n        self._response = response\n        self._metadata = metadata\n\n    def __getattr__(self, name: str) -> Any:\n        return getattr(self._response, name)\n\n    @property\n    def pages(self) -> Iterator[operations_pb2.ListOperationsResponse]:\n        yield self._response\n        while self._response.next_page_token:\n            self._request.page_token = self._response.next_page_token\n            self._response = self._method(self._request, metadata=self._metadata)\n            yield self._response\n\n    def __iter__(self) -> Iterator[operations_pb2.Operation]:\n        for page in self.pages:\n            yield from page.operations\n\n    def __repr__(self) -> str:\n        return \"{0}<{1!r}>\".format(self.__class__.__name__, self._response)\n", "google/api_core/operations_v1/__init__.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Package for interacting with the google.longrunning.operations meta-API.\"\"\"\n\nfrom google.api_core.operations_v1.abstract_operations_client import (\n    AbstractOperationsClient,\n)\nfrom google.api_core.operations_v1.operations_async_client import OperationsAsyncClient\nfrom google.api_core.operations_v1.operations_client import OperationsClient\nfrom google.api_core.operations_v1.transports.rest import OperationsRestTransport\n\n__all__ = [\n    \"AbstractOperationsClient\",\n    \"OperationsAsyncClient\",\n    \"OperationsClient\",\n    \"OperationsRestTransport\",\n]\n", "google/api_core/operations_v1/operations_client_config.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"gapic configuration for the google.longrunning.operations client.\"\"\"\n\n# DEPRECATED: retry and timeout classes are instantiated directly\nconfig = {\n    \"interfaces\": {\n        \"google.longrunning.Operations\": {\n            \"retry_codes\": {\n                \"idempotent\": [\"DEADLINE_EXCEEDED\", \"UNAVAILABLE\"],\n                \"non_idempotent\": [],\n            },\n            \"retry_params\": {\n                \"default\": {\n                    \"initial_retry_delay_millis\": 100,\n                    \"retry_delay_multiplier\": 1.3,\n                    \"max_retry_delay_millis\": 60000,\n                    \"initial_rpc_timeout_millis\": 20000,\n                    \"rpc_timeout_multiplier\": 1.0,\n                    \"max_rpc_timeout_millis\": 600000,\n                    \"total_timeout_millis\": 600000,\n                }\n            },\n            \"methods\": {\n                \"GetOperation\": {\n                    \"timeout_millis\": 60000,\n                    \"retry_codes_name\": \"idempotent\",\n                    \"retry_params_name\": \"default\",\n                },\n                \"ListOperations\": {\n                    \"timeout_millis\": 60000,\n                    \"retry_codes_name\": \"idempotent\",\n                    \"retry_params_name\": \"default\",\n                },\n                \"CancelOperation\": {\n                    \"timeout_millis\": 60000,\n                    \"retry_codes_name\": \"idempotent\",\n                    \"retry_params_name\": \"default\",\n                },\n                \"DeleteOperation\": {\n                    \"timeout_millis\": 60000,\n                    \"retry_codes_name\": \"idempotent\",\n                    \"retry_params_name\": \"default\",\n                },\n            },\n        }\n    }\n}\n", "google/api_core/operations_v1/transports/rest.py": "# -*- coding: utf-8 -*-\n# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\nimport re\nfrom typing import Callable, Dict, Optional, Sequence, Tuple, Union\n\nfrom requests import __version__ as requests_version\n\nfrom google.api_core import exceptions as core_exceptions  # type: ignore\nfrom google.api_core import gapic_v1  # type: ignore\nfrom google.api_core import path_template  # type: ignore\nfrom google.api_core import rest_helpers  # type: ignore\nfrom google.api_core import retry as retries  # type: ignore\nfrom google.auth import credentials as ga_credentials  # type: ignore\nfrom google.auth.transport.requests import AuthorizedSession  # type: ignore\nfrom google.longrunning import operations_pb2  # type: ignore\nfrom google.protobuf import empty_pb2  # type: ignore\nfrom google.protobuf import json_format  # type: ignore\nimport google.protobuf\n\nimport grpc\nfrom .base import DEFAULT_CLIENT_INFO as BASE_DEFAULT_CLIENT_INFO, OperationsTransport\n\nPROTOBUF_VERSION = google.protobuf.__version__\n\nOptionalRetry = Union[retries.Retry, object]\n\nDEFAULT_CLIENT_INFO = gapic_v1.client_info.ClientInfo(\n    gapic_version=BASE_DEFAULT_CLIENT_INFO.gapic_version,\n    grpc_version=None,\n    rest_version=requests_version,\n)\n\n\nclass OperationsRestTransport(OperationsTransport):\n    \"\"\"REST backend transport for Operations.\n\n    Manages long-running operations with an API service.\n\n    When an API method normally takes long time to complete, it can be\n    designed to return [Operation][google.api_core.operations_v1.Operation] to the\n    client, and the client can use this interface to receive the real\n    response asynchronously by polling the operation resource, or pass\n    the operation resource to another API (such as Google Cloud Pub/Sub\n    API) to receive the response. Any API service that returns\n    long-running operations should implement the ``Operations``\n    interface so developers can have a consistent client experience.\n\n    This class defines the same methods as the primary client, so the\n    primary client can load the underlying transport implementation\n    and call it.\n\n    It sends JSON representations of protocol buffers over HTTP/1.1\n    \"\"\"\n\n    def __init__(\n        self,\n        *,\n        host: str = \"longrunning.googleapis.com\",\n        credentials: Optional[ga_credentials.Credentials] = None,\n        credentials_file: Optional[str] = None,\n        scopes: Optional[Sequence[str]] = None,\n        client_cert_source_for_mtls: Optional[Callable[[], Tuple[bytes, bytes]]] = None,\n        quota_project_id: Optional[str] = None,\n        client_info: gapic_v1.client_info.ClientInfo = DEFAULT_CLIENT_INFO,\n        always_use_jwt_access: Optional[bool] = False,\n        url_scheme: str = \"https\",\n        http_options: Optional[Dict] = None,\n        path_prefix: str = \"v1\",\n    ) -> None:\n        \"\"\"Instantiate the transport.\n\n        Args:\n            host (Optional[str]):\n                 The hostname to connect to.\n            credentials (Optional[google.auth.credentials.Credentials]): The\n                authorization credentials to attach to requests. These\n                credentials identify the application to the service; if none\n                are specified, the client will attempt to ascertain the\n                credentials from the environment.\n\n            credentials_file (Optional[str]): A file with credentials that can\n                be loaded with :func:`google.auth.load_credentials_from_file`.\n                This argument is ignored if ``channel`` is provided.\n            scopes (Optional(Sequence[str])): A list of scopes. This argument is\n                ignored if ``channel`` is provided.\n            client_cert_source_for_mtls (Callable[[], Tuple[bytes, bytes]]): Client\n                certificate to configure mutual TLS HTTP channel. It is ignored\n                if ``channel`` is provided.\n            quota_project_id (Optional[str]): An optional project to use for billing\n                and quota.\n            client_info (google.api_core.gapic_v1.client_info.ClientInfo):\n                The client info used to send a user-agent string along with\n                API requests. If ``None``, then default info will be used.\n                Generally, you only need to set this if you're developing\n                your own client library.\n            always_use_jwt_access (Optional[bool]): Whether self signed JWT should\n                be used for service account credentials.\n            url_scheme: the protocol scheme for the API endpoint.  Normally\n                \"https\", but for testing or local servers,\n                \"http\" can be specified.\n            http_options: a dictionary of http_options for transcoding, to override\n                the defaults from operations.proto.  Each method has an entry\n                with the corresponding http rules as value.\n            path_prefix: path prefix (usually represents API version). Set to\n                \"v1\" by default.\n\n        \"\"\"\n        # Run the base constructor\n        # TODO(yon-mg): resolve other ctor params i.e. scopes, quota, etc.\n        # TODO: When custom host (api_endpoint) is set, `scopes` must *also* be set on the\n        # credentials object\n        maybe_url_match = re.match(\"^(?P<scheme>http(?:s)?://)?(?P<host>.*)$\", host)\n        if maybe_url_match is None:\n            raise ValueError(\n                f\"Unexpected hostname structure: {host}\"\n            )  # pragma: NO COVER\n\n        url_match_items = maybe_url_match.groupdict()\n\n        host = f\"{url_scheme}://{host}\" if not url_match_items[\"scheme\"] else host\n\n        super().__init__(\n            host=host,\n            credentials=credentials,\n            client_info=client_info,\n            always_use_jwt_access=always_use_jwt_access,\n        )\n        self._session = AuthorizedSession(\n            self._credentials, default_host=self.DEFAULT_HOST\n        )\n        if client_cert_source_for_mtls:\n            self._session.configure_mtls_channel(client_cert_source_for_mtls)\n        self._prep_wrapped_messages(client_info)\n        self._http_options = http_options or {}\n        self._path_prefix = path_prefix\n\n    def _list_operations(\n        self,\n        request: operations_pb2.ListOperationsRequest,\n        *,\n        retry: OptionalRetry = gapic_v1.method.DEFAULT,\n        timeout: Optional[float] = None,\n        compression: Optional[grpc.Compression] = gapic_v1.method.DEFAULT,\n        metadata: Sequence[Tuple[str, str]] = (),\n    ) -> operations_pb2.ListOperationsResponse:\n        r\"\"\"Call the list operations method over HTTP.\n\n        Args:\n            request (~.operations_pb2.ListOperationsRequest):\n                The request object. The request message for\n                [Operations.ListOperations][google.api_core.operations_v1.Operations.ListOperations].\n\n            retry (google.api_core.retry.Retry): Designation of what errors, if any,\n                should be retried.\n            timeout (float): The timeout for this request.\n            metadata (Sequence[Tuple[str, str]]): Strings which should be\n                sent along with the request as metadata.\n\n        Returns:\n            ~.operations_pb2.ListOperationsResponse:\n                The response message for\n                [Operations.ListOperations][google.api_core.operations_v1.Operations.ListOperations].\n\n        \"\"\"\n\n        http_options = [\n            {\n                \"method\": \"get\",\n                \"uri\": \"/{}/{{name=**}}/operations\".format(self._path_prefix),\n            },\n        ]\n        if \"google.longrunning.Operations.ListOperations\" in self._http_options:\n            http_options = self._http_options[\n                \"google.longrunning.Operations.ListOperations\"\n            ]\n\n        request_kwargs = self._convert_protobuf_message_to_dict(request)\n        transcoded_request = path_template.transcode(http_options, **request_kwargs)\n\n        uri = transcoded_request[\"uri\"]\n        method = transcoded_request[\"method\"]\n\n        # Jsonify the query params\n        query_params_request = operations_pb2.ListOperationsRequest()\n        json_format.ParseDict(transcoded_request[\"query_params\"], query_params_request)\n        query_params = json_format.MessageToDict(\n            query_params_request,\n            preserving_proto_field_name=False,\n            use_integers_for_enums=False,\n        )\n\n        # Send the request\n        headers = dict(metadata)\n        headers[\"Content-Type\"] = \"application/json\"\n        response = getattr(self._session, method)(\n            \"{host}{uri}\".format(host=self._host, uri=uri),\n            timeout=timeout,\n            headers=headers,\n            params=rest_helpers.flatten_query_params(query_params),\n        )\n\n        # In case of error, raise the appropriate core_exceptions.GoogleAPICallError exception\n        # subclass.\n        if response.status_code >= 400:\n            raise core_exceptions.from_http_response(response)\n\n        # Return the response\n        api_response = operations_pb2.ListOperationsResponse()\n        json_format.Parse(response.content, api_response, ignore_unknown_fields=False)\n        return api_response\n\n    def _get_operation(\n        self,\n        request: operations_pb2.GetOperationRequest,\n        *,\n        retry: OptionalRetry = gapic_v1.method.DEFAULT,\n        timeout: Optional[float] = None,\n        compression: Optional[grpc.Compression] = gapic_v1.method.DEFAULT,\n        metadata: Sequence[Tuple[str, str]] = (),\n    ) -> operations_pb2.Operation:\n        r\"\"\"Call the get operation method over HTTP.\n\n        Args:\n            request (~.operations_pb2.GetOperationRequest):\n                The request object. The request message for\n                [Operations.GetOperation][google.api_core.operations_v1.Operations.GetOperation].\n\n            retry (google.api_core.retry.Retry): Designation of what errors, if any,\n                should be retried.\n            timeout (float): The timeout for this request.\n            metadata (Sequence[Tuple[str, str]]): Strings which should be\n                sent along with the request as metadata.\n\n        Returns:\n            ~.operations_pb2.Operation:\n                This resource represents a long-\n                running operation that is the result of a\n                network API call.\n\n        \"\"\"\n\n        http_options = [\n            {\n                \"method\": \"get\",\n                \"uri\": \"/{}/{{name=**/operations/*}}\".format(self._path_prefix),\n            },\n        ]\n        if \"google.longrunning.Operations.GetOperation\" in self._http_options:\n            http_options = self._http_options[\n                \"google.longrunning.Operations.GetOperation\"\n            ]\n\n        request_kwargs = self._convert_protobuf_message_to_dict(request)\n        transcoded_request = path_template.transcode(http_options, **request_kwargs)\n\n        uri = transcoded_request[\"uri\"]\n        method = transcoded_request[\"method\"]\n\n        # Jsonify the query params\n        query_params_request = operations_pb2.GetOperationRequest()\n        json_format.ParseDict(transcoded_request[\"query_params\"], query_params_request)\n        query_params = json_format.MessageToDict(\n            query_params_request,\n            preserving_proto_field_name=False,\n            use_integers_for_enums=False,\n        )\n\n        # Send the request\n        headers = dict(metadata)\n        headers[\"Content-Type\"] = \"application/json\"\n        response = getattr(self._session, method)(\n            \"{host}{uri}\".format(host=self._host, uri=uri),\n            timeout=timeout,\n            headers=headers,\n            params=rest_helpers.flatten_query_params(query_params),\n        )\n\n        # In case of error, raise the appropriate core_exceptions.GoogleAPICallError exception\n        # subclass.\n        if response.status_code >= 400:\n            raise core_exceptions.from_http_response(response)\n\n        # Return the response\n        api_response = operations_pb2.Operation()\n        json_format.Parse(response.content, api_response, ignore_unknown_fields=False)\n        return api_response\n\n    def _delete_operation(\n        self,\n        request: operations_pb2.DeleteOperationRequest,\n        *,\n        retry: OptionalRetry = gapic_v1.method.DEFAULT,\n        timeout: Optional[float] = None,\n        compression: Optional[grpc.Compression] = gapic_v1.method.DEFAULT,\n        metadata: Sequence[Tuple[str, str]] = (),\n    ) -> empty_pb2.Empty:\n        r\"\"\"Call the delete operation method over HTTP.\n\n        Args:\n            request (~.operations_pb2.DeleteOperationRequest):\n                The request object. The request message for\n                [Operations.DeleteOperation][google.api_core.operations_v1.Operations.DeleteOperation].\n\n            retry (google.api_core.retry.Retry): Designation of what errors, if any,\n                should be retried.\n            timeout (float): The timeout for this request.\n            metadata (Sequence[Tuple[str, str]]): Strings which should be\n                sent along with the request as metadata.\n        \"\"\"\n\n        http_options = [\n            {\n                \"method\": \"delete\",\n                \"uri\": \"/{}/{{name=**/operations/*}}\".format(self._path_prefix),\n            },\n        ]\n        if \"google.longrunning.Operations.DeleteOperation\" in self._http_options:\n            http_options = self._http_options[\n                \"google.longrunning.Operations.DeleteOperation\"\n            ]\n\n        request_kwargs = self._convert_protobuf_message_to_dict(request)\n        transcoded_request = path_template.transcode(http_options, **request_kwargs)\n\n        uri = transcoded_request[\"uri\"]\n        method = transcoded_request[\"method\"]\n\n        # Jsonify the query params\n        query_params_request = operations_pb2.DeleteOperationRequest()\n        json_format.ParseDict(transcoded_request[\"query_params\"], query_params_request)\n        query_params = json_format.MessageToDict(\n            query_params_request,\n            preserving_proto_field_name=False,\n            use_integers_for_enums=False,\n        )\n\n        # Send the request\n        headers = dict(metadata)\n        headers[\"Content-Type\"] = \"application/json\"\n        response = getattr(self._session, method)(\n            \"{host}{uri}\".format(host=self._host, uri=uri),\n            timeout=timeout,\n            headers=headers,\n            params=rest_helpers.flatten_query_params(query_params),\n        )\n\n        # In case of error, raise the appropriate core_exceptions.GoogleAPICallError exception\n        # subclass.\n        if response.status_code >= 400:\n            raise core_exceptions.from_http_response(response)\n\n        return empty_pb2.Empty()\n\n    def _cancel_operation(\n        self,\n        request: operations_pb2.CancelOperationRequest,\n        *,\n        retry: OptionalRetry = gapic_v1.method.DEFAULT,\n        timeout: Optional[float] = None,\n        compression: Optional[grpc.Compression] = gapic_v1.method.DEFAULT,\n        metadata: Sequence[Tuple[str, str]] = (),\n    ) -> empty_pb2.Empty:\n        r\"\"\"Call the cancel operation method over HTTP.\n\n        Args:\n            request (~.operations_pb2.CancelOperationRequest):\n                The request object. The request message for\n                [Operations.CancelOperation][google.api_core.operations_v1.Operations.CancelOperation].\n\n            retry (google.api_core.retry.Retry): Designation of what errors, if any,\n                should be retried.\n            timeout (float): The timeout for this request.\n            metadata (Sequence[Tuple[str, str]]): Strings which should be\n                sent along with the request as metadata.\n        \"\"\"\n\n        http_options = [\n            {\n                \"method\": \"post\",\n                \"uri\": \"/{}/{{name=**/operations/*}}:cancel\".format(self._path_prefix),\n                \"body\": \"*\",\n            },\n        ]\n        if \"google.longrunning.Operations.CancelOperation\" in self._http_options:\n            http_options = self._http_options[\n                \"google.longrunning.Operations.CancelOperation\"\n            ]\n\n        request_kwargs = self._convert_protobuf_message_to_dict(request)\n        transcoded_request = path_template.transcode(http_options, **request_kwargs)\n\n        # Jsonify the request body\n        body_request = operations_pb2.CancelOperationRequest()\n        json_format.ParseDict(transcoded_request[\"body\"], body_request)\n        body = json_format.MessageToDict(\n            body_request,\n            preserving_proto_field_name=False,\n            use_integers_for_enums=False,\n        )\n        uri = transcoded_request[\"uri\"]\n        method = transcoded_request[\"method\"]\n\n        # Jsonify the query params\n        query_params_request = operations_pb2.CancelOperationRequest()\n        json_format.ParseDict(transcoded_request[\"query_params\"], query_params_request)\n        query_params = json_format.MessageToDict(\n            query_params_request,\n            preserving_proto_field_name=False,\n            use_integers_for_enums=False,\n        )\n\n        # Send the request\n        headers = dict(metadata)\n        headers[\"Content-Type\"] = \"application/json\"\n        response = getattr(self._session, method)(\n            \"{host}{uri}\".format(host=self._host, uri=uri),\n            timeout=timeout,\n            headers=headers,\n            params=rest_helpers.flatten_query_params(query_params),\n            data=body,\n        )\n\n        # In case of error, raise the appropriate core_exceptions.GoogleAPICallError exception\n        # subclass.\n        if response.status_code >= 400:\n            raise core_exceptions.from_http_response(response)\n\n        return empty_pb2.Empty()\n\n    def _convert_protobuf_message_to_dict(\n        self, message: google.protobuf.message.Message\n    ):\n        r\"\"\"Converts protobuf message to a dictionary.\n\n        When the dictionary is encoded to JSON, it conforms to proto3 JSON spec.\n\n        Args:\n            message(google.protobuf.message.Message): The protocol buffers message\n                instance to serialize.\n\n        Returns:\n            A dict representation of the protocol buffer message.\n        \"\"\"\n        # For backwards compatibility with protobuf 3.x 4.x\n        # Remove once support for protobuf 3.x and 4.x is dropped\n        # https://github.com/googleapis/python-api-core/issues/643\n        if PROTOBUF_VERSION[0:2] in [\"3.\", \"4.\"]:\n            result = json_format.MessageToDict(\n                message,\n                preserving_proto_field_name=True,\n                including_default_value_fields=True,  # type: ignore # backward compatibility\n            )\n        else:\n            result = json_format.MessageToDict(\n                message,\n                preserving_proto_field_name=True,\n                always_print_fields_with_no_presence=True,\n            )\n\n        return result\n\n    @property\n    def list_operations(\n        self,\n    ) -> Callable[\n        [operations_pb2.ListOperationsRequest], operations_pb2.ListOperationsResponse\n    ]:\n        return self._list_operations\n\n    @property\n    def get_operation(\n        self,\n    ) -> Callable[[operations_pb2.GetOperationRequest], operations_pb2.Operation]:\n        return self._get_operation\n\n    @property\n    def delete_operation(\n        self,\n    ) -> Callable[[operations_pb2.DeleteOperationRequest], empty_pb2.Empty]:\n        return self._delete_operation\n\n    @property\n    def cancel_operation(\n        self,\n    ) -> Callable[[operations_pb2.CancelOperationRequest], empty_pb2.Empty]:\n        return self._cancel_operation\n\n\n__all__ = (\"OperationsRestTransport\",)\n", "google/api_core/operations_v1/transports/base.py": "# -*- coding: utf-8 -*-\n# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\nimport abc\nfrom typing import Awaitable, Callable, Optional, Sequence, Union\n\nimport google.api_core  # type: ignore\nfrom google.api_core import exceptions as core_exceptions  # type: ignore\nfrom google.api_core import gapic_v1  # type: ignore\nfrom google.api_core import retry as retries  # type: ignore\nfrom google.api_core import version\nimport google.auth  # type: ignore\nfrom google.auth import credentials as ga_credentials  # type: ignore\nfrom google.longrunning import operations_pb2\nfrom google.oauth2 import service_account  # type: ignore\nfrom google.protobuf import empty_pb2  # type: ignore\nfrom grpc import Compression\n\n\nDEFAULT_CLIENT_INFO = gapic_v1.client_info.ClientInfo(\n    gapic_version=version.__version__,\n)\n\n\nclass OperationsTransport(abc.ABC):\n    \"\"\"Abstract transport class for Operations.\"\"\"\n\n    AUTH_SCOPES = ()\n\n    DEFAULT_HOST: str = \"longrunning.googleapis.com\"\n\n    def __init__(\n        self,\n        *,\n        host: str = DEFAULT_HOST,\n        credentials: Optional[ga_credentials.Credentials] = None,\n        credentials_file: Optional[str] = None,\n        scopes: Optional[Sequence[str]] = None,\n        quota_project_id: Optional[str] = None,\n        client_info: gapic_v1.client_info.ClientInfo = DEFAULT_CLIENT_INFO,\n        always_use_jwt_access: Optional[bool] = False,\n        **kwargs,\n    ) -> None:\n        \"\"\"Instantiate the transport.\n\n        Args:\n            host (Optional[str]):\n                 The hostname to connect to.\n            credentials (Optional[google.auth.credentials.Credentials]): The\n                authorization credentials to attach to requests. These\n                credentials identify the application to the service; if none\n                are specified, the client will attempt to ascertain the\n                credentials from the environment.\n            credentials_file (Optional[str]): A file with credentials that can\n                be loaded with :func:`google.auth.load_credentials_from_file`.\n                This argument is mutually exclusive with credentials.\n            scopes (Optional[Sequence[str]]): A list of scopes.\n            quota_project_id (Optional[str]): An optional project to use for billing\n                and quota.\n            client_info (google.api_core.gapic_v1.client_info.ClientInfo):\n                The client info used to send a user-agent string along with\n                API requests. If ``None``, then default info will be used.\n                Generally, you only need to set this if you're developing\n                your own client library.\n            always_use_jwt_access (Optional[bool]): Whether self signed JWT should\n                be used for service account credentials.\n        \"\"\"\n        # Save the hostname. Default to port 443 (HTTPS) if none is specified.\n        if \":\" not in host:\n            host += \":443\"\n        self._host = host\n\n        scopes_kwargs = {\"scopes\": scopes, \"default_scopes\": self.AUTH_SCOPES}\n\n        # Save the scopes.\n        self._scopes = scopes\n\n        # If no credentials are provided, then determine the appropriate\n        # defaults.\n        if credentials and credentials_file:\n            raise core_exceptions.DuplicateCredentialArgs(\n                \"'credentials_file' and 'credentials' are mutually exclusive\"\n            )\n\n        if credentials_file is not None:\n            credentials, _ = google.auth.load_credentials_from_file(\n                credentials_file, **scopes_kwargs, quota_project_id=quota_project_id\n            )\n\n        elif credentials is None:\n            credentials, _ = google.auth.default(\n                **scopes_kwargs, quota_project_id=quota_project_id\n            )\n\n        # If the credentials are service account credentials, then always try to use self signed JWT.\n        if (\n            always_use_jwt_access\n            and isinstance(credentials, service_account.Credentials)\n            and hasattr(service_account.Credentials, \"with_always_use_jwt_access\")\n        ):\n            credentials = credentials.with_always_use_jwt_access(True)\n\n        # Save the credentials.\n        self._credentials = credentials\n\n    def _prep_wrapped_messages(self, client_info):\n        # Precompute the wrapped methods.\n        self._wrapped_methods = {\n            self.list_operations: gapic_v1.method.wrap_method(\n                self.list_operations,\n                default_retry=retries.Retry(\n                    initial=0.5,\n                    maximum=10.0,\n                    multiplier=2.0,\n                    predicate=retries.if_exception_type(\n                        core_exceptions.ServiceUnavailable,\n                    ),\n                    deadline=10.0,\n                ),\n                default_timeout=10.0,\n                default_compression=Compression.NoCompression,\n                client_info=client_info,\n            ),\n            self.get_operation: gapic_v1.method.wrap_method(\n                self.get_operation,\n                default_retry=retries.Retry(\n                    initial=0.5,\n                    maximum=10.0,\n                    multiplier=2.0,\n                    predicate=retries.if_exception_type(\n                        core_exceptions.ServiceUnavailable,\n                    ),\n                    deadline=10.0,\n                ),\n                default_timeout=10.0,\n                default_compression=Compression.NoCompression,\n                client_info=client_info,\n            ),\n            self.delete_operation: gapic_v1.method.wrap_method(\n                self.delete_operation,\n                default_retry=retries.Retry(\n                    initial=0.5,\n                    maximum=10.0,\n                    multiplier=2.0,\n                    predicate=retries.if_exception_type(\n                        core_exceptions.ServiceUnavailable,\n                    ),\n                    deadline=10.0,\n                ),\n                default_timeout=10.0,\n                default_compression=Compression.NoCompression,\n                client_info=client_info,\n            ),\n            self.cancel_operation: gapic_v1.method.wrap_method(\n                self.cancel_operation,\n                default_retry=retries.Retry(\n                    initial=0.5,\n                    maximum=10.0,\n                    multiplier=2.0,\n                    predicate=retries.if_exception_type(\n                        core_exceptions.ServiceUnavailable,\n                    ),\n                    deadline=10.0,\n                ),\n                default_timeout=10.0,\n                default_compression=Compression.NoCompression,\n                client_info=client_info,\n            ),\n        }\n\n    def close(self):\n        \"\"\"Closes resources associated with the transport.\n\n        .. warning::\n             Only call this method if the transport is NOT shared\n             with other clients - this may cause errors in other clients!\n        \"\"\"\n        raise NotImplementedError()\n\n    @property\n    def list_operations(\n        self,\n    ) -> Callable[\n        [operations_pb2.ListOperationsRequest],\n        Union[\n            operations_pb2.ListOperationsResponse,\n            Awaitable[operations_pb2.ListOperationsResponse],\n        ],\n    ]:\n        raise NotImplementedError()\n\n    @property\n    def get_operation(\n        self,\n    ) -> Callable[\n        [operations_pb2.GetOperationRequest],\n        Union[operations_pb2.Operation, Awaitable[operations_pb2.Operation]],\n    ]:\n        raise NotImplementedError()\n\n    @property\n    def delete_operation(\n        self,\n    ) -> Callable[\n        [operations_pb2.DeleteOperationRequest],\n        Union[empty_pb2.Empty, Awaitable[empty_pb2.Empty]],\n    ]:\n        raise NotImplementedError()\n\n    @property\n    def cancel_operation(\n        self,\n    ) -> Callable[\n        [operations_pb2.CancelOperationRequest],\n        Union[empty_pb2.Empty, Awaitable[empty_pb2.Empty]],\n    ]:\n        raise NotImplementedError()\n\n\n__all__ = (\"OperationsTransport\",)\n", "google/api_core/operations_v1/transports/__init__.py": "# -*- coding: utf-8 -*-\n# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\nfrom collections import OrderedDict\n\nfrom .base import OperationsTransport\nfrom .rest import OperationsRestTransport\n\n\n# Compile a registry of transports.\n_transport_registry = OrderedDict()\n_transport_registry[\"rest\"] = OperationsRestTransport\n\n__all__ = (\n    \"OperationsTransport\",\n    \"OperationsRestTransport\",\n)\n", "google/api_core/retry/retry_streaming_async.py": "# Copyright 2023 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"\nGenerator wrapper for retryable async streaming RPCs.\n\"\"\"\nfrom __future__ import annotations\n\nfrom typing import (\n    cast,\n    Any,\n    Callable,\n    Iterable,\n    AsyncIterator,\n    AsyncIterable,\n    Awaitable,\n    TypeVar,\n    AsyncGenerator,\n    TYPE_CHECKING,\n)\n\nimport asyncio\nimport time\nimport sys\nimport functools\n\nfrom google.api_core.retry.retry_base import _BaseRetry\nfrom google.api_core.retry.retry_base import _retry_error_helper\nfrom google.api_core.retry import exponential_sleep_generator\nfrom google.api_core.retry import build_retry_error\nfrom google.api_core.retry import RetryFailureReason\n\n\nif TYPE_CHECKING:\n    if sys.version_info >= (3, 10):\n        from typing import ParamSpec\n    else:\n        from typing_extensions import ParamSpec\n\n    _P = ParamSpec(\"_P\")  # target function call parameters\n    _Y = TypeVar(\"_Y\")  # yielded values\n\n\nasync def retry_target_stream(\n    target: Callable[_P, AsyncIterable[_Y] | Awaitable[AsyncIterable[_Y]]],\n    predicate: Callable[[Exception], bool],\n    sleep_generator: Iterable[float],\n    timeout: float | None = None,\n    on_error: Callable[[Exception], None] | None = None,\n    exception_factory: Callable[\n        [list[Exception], RetryFailureReason, float | None],\n        tuple[Exception, Exception | None],\n    ] = build_retry_error,\n    init_args: _P.args = (),\n    init_kwargs: _P.kwargs = {},\n    **kwargs,\n) -> AsyncGenerator[_Y, None]:\n    \"\"\"Create a generator wrapper that retries the wrapped stream if it fails.\n\n    This is the lowest-level retry helper. Generally, you'll use the\n    higher-level retry helper :class:`AsyncRetry`.\n\n    Args:\n        target: The generator function to call and retry.\n        predicate: A callable used to determine if an\n            exception raised by the target should be considered retryable.\n            It should return True to retry or False otherwise.\n        sleep_generator: An infinite iterator that determines\n            how long to sleep between retries.\n        timeout: How long to keep retrying the target.\n            Note: timeout is only checked before initiating a retry, so the target may\n            run past the timeout value as long as it is healthy.\n        on_error: If given, the on_error callback will be called with each\n            retryable exception raised by the target. Any error raised by this\n            function will *not* be caught.\n        exception_factory: A function that is called when the retryable reaches\n            a terminal failure state, used to construct an exception to be raised.\n            It takes a list of all exceptions encountered, a retry.RetryFailureReason\n            enum indicating the failure cause, and the original timeout value\n            as arguments. It should return a tuple of the exception to be raised,\n            along with the cause exception if any. The default implementation will raise\n            a RetryError on timeout, or the last exception encountered otherwise.\n        init_args: Positional arguments to pass to the target function.\n        init_kwargs: Keyword arguments to pass to the target function.\n\n    Returns:\n        AsyncGenerator: A retryable generator that wraps the target generator function.\n\n    Raises:\n        ValueError: If the sleep generator stops yielding values.\n        Exception: a custom exception specified by the exception_factory if provided.\n            If no exception_factory is provided:\n                google.api_core.RetryError: If the timeout is exceeded while retrying.\n                Exception: If the target raises an error that isn't retryable.\n    \"\"\"\n    target_iterator: AsyncIterator[_Y] | None = None\n    timeout = kwargs.get(\"deadline\", timeout)\n    deadline = time.monotonic() + timeout if timeout else None\n    # keep track of retryable exceptions we encounter to pass in to exception_factory\n    error_list: list[Exception] = []\n    target_is_generator: bool | None = None\n\n    for sleep in sleep_generator:\n        # Start a new retry loop\n        try:\n            # Note: in the future, we can add a ResumptionStrategy object\n            # to generate new args between calls. For now, use the same args\n            # for each attempt.\n            target_output: AsyncIterable[_Y] | Awaitable[AsyncIterable[_Y]] = target(\n                *init_args, **init_kwargs\n            )\n            try:\n                # gapic functions return the generator behind an awaitable\n                # unwrap the awaitable so we can work with the generator directly\n                target_output = await target_output  # type: ignore\n            except TypeError:\n                # was not awaitable, continue\n                pass\n            target_iterator = cast(AsyncIterable[\"_Y\"], target_output).__aiter__()\n\n            if target_is_generator is None:\n                # Check if target supports generator features (asend, athrow, aclose)\n                target_is_generator = bool(getattr(target_iterator, \"asend\", None))\n\n            sent_in = None\n            while True:\n                ## Read from target_iterator\n                # If the target is a generator, we will advance it with `asend`\n                # otherwise, we will use `anext`\n                if target_is_generator:\n                    next_value = await target_iterator.asend(sent_in)  # type: ignore\n                else:\n                    next_value = await target_iterator.__anext__()\n                ## Yield from Wrapper to caller\n                try:\n                    # yield latest value from target\n                    # exceptions from `athrow` and `aclose` are injected here\n                    sent_in = yield next_value\n                except GeneratorExit:\n                    # if wrapper received `aclose` while waiting on yield,\n                    # it will raise GeneratorExit here\n                    if target_is_generator:\n                        # pass to inner target_iterator for handling\n                        await cast(AsyncGenerator[\"_Y\", None], target_iterator).aclose()\n                    else:\n                        raise\n                    return\n                except:  # noqa: E722\n                    # bare except catches any exception passed to `athrow`\n                    if target_is_generator:\n                        # delegate error handling to target_iterator\n                        await cast(AsyncGenerator[\"_Y\", None], target_iterator).athrow(\n                            cast(BaseException, sys.exc_info()[1])\n                        )\n                    else:\n                        raise\n            return\n        except StopAsyncIteration:\n            # if iterator exhausted, return\n            return\n        # handle exceptions raised by the target_iterator\n        # pylint: disable=broad-except\n        # This function explicitly must deal with broad exceptions.\n        except Exception as exc:\n            # defer to shared logic for handling errors\n            _retry_error_helper(\n                exc,\n                deadline,\n                sleep,\n                error_list,\n                predicate,\n                on_error,\n                exception_factory,\n                timeout,\n            )\n            # if exception not raised, sleep before next attempt\n            await asyncio.sleep(sleep)\n        finally:\n            if target_is_generator and target_iterator is not None:\n                await cast(AsyncGenerator[\"_Y\", None], target_iterator).aclose()\n    raise ValueError(\"Sleep generator stopped yielding sleep values.\")\n\n\nclass AsyncStreamingRetry(_BaseRetry):\n    \"\"\"Exponential retry decorator for async streaming rpcs.\n\n    This class returns an AsyncGenerator when called, which wraps the target\n    stream in retry logic. If any exception is raised by the target, the\n    entire stream will be retried within the wrapper.\n\n    Although the default behavior is to retry transient API errors, a\n    different predicate can be provided to retry other exceptions.\n\n    Important Note: when a stream is encounters a retryable error, it will\n    silently construct a fresh iterator instance in the background\n    and continue yielding (likely duplicate) values as if no error occurred.\n    This is the most general way to retry a stream, but it often is not the\n    desired behavior. Example: iter([1, 2, 1/0]) -> [1, 2, 1, 2, ...]\n\n    There are two ways to build more advanced retry logic for streams:\n\n    1. Wrap the target\n        Use a ``target`` that maintains state between retries, and creates a\n        different generator on each retry call. For example, you can wrap a\n        grpc call in a function that modifies the request based on what has\n        already been returned:\n\n        .. code-block:: python\n\n            async def attempt_with_modified_request(target, request, seen_items=[]):\n                # remove seen items from request on each attempt\n                new_request = modify_request(request, seen_items)\n                new_generator = await target(new_request)\n                async for item in new_generator:\n                    yield item\n                    seen_items.append(item)\n\n            retry_wrapped = AsyncRetry(is_stream=True,...)(attempt_with_modified_request, target, request, [])\n\n        2. Wrap the retry generator\n            Alternatively, you can wrap the retryable generator itself before\n            passing it to the end-user to add a filter on the stream. For\n            example, you can keep track of the items that were successfully yielded\n            in previous retry attempts, and only yield new items when the\n            new attempt surpasses the previous ones:\n\n            .. code-block:: python\n\n                async def retryable_with_filter(target):\n                    stream_idx = 0\n                    # reset stream_idx when the stream is retried\n                    def on_error(e):\n                        nonlocal stream_idx\n                        stream_idx = 0\n                    # build retryable\n                    retryable_gen = AsyncRetry(is_stream=True, ...)(target)\n                    # keep track of what has been yielded out of filter\n                    seen_items = []\n                    async for item in retryable_gen:\n                        if stream_idx >= len(seen_items):\n                            yield item\n                            seen_items.append(item)\n                        elif item != previous_stream[stream_idx]:\n                            raise ValueError(\"Stream differs from last attempt\")\"\n                        stream_idx += 1\n\n                filter_retry_wrapped = retryable_with_filter(target)\n\n    Args:\n        predicate (Callable[Exception]): A callable that should return ``True``\n            if the given exception is retryable.\n        initial (float): The minimum amount of time to delay in seconds. This\n            must be greater than 0.\n        maximum (float): The maximum amount of time to delay in seconds.\n        multiplier (float): The multiplier applied to the delay.\n        timeout (Optional[float]): How long to keep retrying in seconds.\n            Note: timeout is only checked before initiating a retry, so the target may\n            run past the timeout value as long as it is healthy.\n        on_error (Optional[Callable[Exception]]): A function to call while processing\n            a retryable exception. Any error raised by this function will\n            *not* be caught.\n        is_stream (bool): Indicates whether the input function\n            should be treated as a stream function (i.e. an AsyncGenerator,\n            or function or coroutine that returns an AsyncIterable).\n            If True, the iterable will be wrapped with retry logic, and any\n            failed outputs will restart the stream. If False, only the input\n            function call itself will be retried. Defaults to False.\n            To avoid duplicate values, retryable streams should typically be\n            wrapped in additional filter logic before use.\n        deadline (float): DEPRECATED use ``timeout`` instead. If set it will\n        override ``timeout`` parameter.\n    \"\"\"\n\n    def __call__(\n        self,\n        func: Callable[..., AsyncIterable[_Y] | Awaitable[AsyncIterable[_Y]]],\n        on_error: Callable[[Exception], Any] | None = None,\n    ) -> Callable[_P, Awaitable[AsyncGenerator[_Y, None]]]:\n        \"\"\"Wrap a callable with retry behavior.\n\n        Args:\n            func (Callable): The callable or stream to add retry behavior to.\n            on_error (Optional[Callable[Exception]]): If given, the\n                on_error callback will be called with each retryable exception\n                raised by the wrapped function. Any error raised by this\n                function will *not* be caught. If on_error was specified in the\n                constructor, this value will be ignored.\n\n        Returns:\n            Callable: A callable that will invoke ``func`` with retry\n                behavior.\n        \"\"\"\n        if self._on_error is not None:\n            on_error = self._on_error\n\n        @functools.wraps(func)\n        async def retry_wrapped_func(\n            *args: _P.args, **kwargs: _P.kwargs\n        ) -> AsyncGenerator[_Y, None]:\n            \"\"\"A wrapper that calls target function with retry.\"\"\"\n            sleep_generator = exponential_sleep_generator(\n                self._initial, self._maximum, multiplier=self._multiplier\n            )\n            return retry_target_stream(\n                func,\n                self._predicate,\n                sleep_generator,\n                self._timeout,\n                on_error,\n                init_args=args,\n                init_kwargs=kwargs,\n            )\n\n        return retry_wrapped_func\n", "google/api_core/retry/retry_streaming.py": "# Copyright 2023 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"\nGenerator wrapper for retryable streaming RPCs.\n\"\"\"\nfrom __future__ import annotations\n\nfrom typing import (\n    Callable,\n    Optional,\n    List,\n    Tuple,\n    Iterable,\n    Generator,\n    TypeVar,\n    Any,\n    TYPE_CHECKING,\n)\n\nimport sys\nimport time\nimport functools\n\nfrom google.api_core.retry.retry_base import _BaseRetry\nfrom google.api_core.retry.retry_base import _retry_error_helper\nfrom google.api_core.retry import exponential_sleep_generator\nfrom google.api_core.retry import build_retry_error\nfrom google.api_core.retry import RetryFailureReason\n\nif TYPE_CHECKING:\n    if sys.version_info >= (3, 10):\n        from typing import ParamSpec\n    else:\n        from typing_extensions import ParamSpec\n\n    _P = ParamSpec(\"_P\")  # target function call parameters\n    _Y = TypeVar(\"_Y\")  # yielded values\n\n\ndef retry_target_stream(\n    target: Callable[_P, Iterable[_Y]],\n    predicate: Callable[[Exception], bool],\n    sleep_generator: Iterable[float],\n    timeout: Optional[float] = None,\n    on_error: Optional[Callable[[Exception], None]] = None,\n    exception_factory: Callable[\n        [List[Exception], RetryFailureReason, Optional[float]],\n        Tuple[Exception, Optional[Exception]],\n    ] = build_retry_error,\n    init_args: _P.args = (),\n    init_kwargs: _P.kwargs = {},\n    **kwargs,\n) -> Generator[_Y, Any, None]:\n    \"\"\"Create a generator wrapper that retries the wrapped stream if it fails.\n\n    This is the lowest-level retry helper. Generally, you'll use the\n    higher-level retry helper :class:`Retry`.\n\n    Args:\n        target: The generator function to call and retry.\n        predicate: A callable used to determine if an\n            exception raised by the target should be considered retryable.\n            It should return True to retry or False otherwise.\n        sleep_generator: An infinite iterator that determines\n            how long to sleep between retries.\n        timeout: How long to keep retrying the target.\n            Note: timeout is only checked before initiating a retry, so the target may\n            run past the timeout value as long as it is healthy.\n        on_error: If given, the on_error callback will be called with each\n            retryable exception raised by the target. Any error raised by this\n            function will *not* be caught.\n        exception_factory: A function that is called when the retryable reaches\n            a terminal failure state, used to construct an exception to be raised.\n            It takes a list of all exceptions encountered, a retry.RetryFailureReason\n            enum indicating the failure cause, and the original timeout value\n            as arguments. It should return a tuple of the exception to be raised,\n            along with the cause exception if any. The default implementation will raise\n            a RetryError on timeout, or the last exception encountered otherwise.\n        init_args: Positional arguments to pass to the target function.\n        init_kwargs: Keyword arguments to pass to the target function.\n\n    Returns:\n        Generator: A retryable generator that wraps the target generator function.\n\n    Raises:\n        ValueError: If the sleep generator stops yielding values.\n        Exception: a custom exception specified by the exception_factory if provided.\n            If no exception_factory is provided:\n                google.api_core.RetryError: If the timeout is exceeded while retrying.\n                Exception: If the target raises an error that isn't retryable.\n    \"\"\"\n\n    timeout = kwargs.get(\"deadline\", timeout)\n    deadline: Optional[float] = (\n        time.monotonic() + timeout if timeout is not None else None\n    )\n    error_list: list[Exception] = []\n\n    for sleep in sleep_generator:\n        # Start a new retry loop\n        try:\n            # Note: in the future, we can add a ResumptionStrategy object\n            # to generate new args between calls. For now, use the same args\n            # for each attempt.\n            subgenerator = target(*init_args, **init_kwargs)\n            return (yield from subgenerator)\n        # handle exceptions raised by the subgenerator\n        # pylint: disable=broad-except\n        # This function explicitly must deal with broad exceptions.\n        except Exception as exc:\n            # defer to shared logic for handling errors\n            _retry_error_helper(\n                exc,\n                deadline,\n                sleep,\n                error_list,\n                predicate,\n                on_error,\n                exception_factory,\n                timeout,\n            )\n            # if exception not raised, sleep before next attempt\n            time.sleep(sleep)\n\n    raise ValueError(\"Sleep generator stopped yielding sleep values.\")\n\n\nclass StreamingRetry(_BaseRetry):\n    \"\"\"Exponential retry decorator for streaming synchronous RPCs.\n\n    This class returns a Generator when called, which wraps the target\n    stream in retry logic. If any exception is raised by the target, the\n    entire stream will be retried within the wrapper.\n\n    Although the default behavior is to retry transient API errors, a\n    different predicate can be provided to retry other exceptions.\n\n    Important Note: when a stream encounters a retryable error, it will\n    silently construct a fresh iterator instance in the background\n    and continue yielding (likely duplicate) values as if no error occurred.\n    This is the most general way to retry a stream, but it often is not the\n    desired behavior. Example: iter([1, 2, 1/0]) -> [1, 2, 1, 2, ...]\n\n    There are two ways to build more advanced retry logic for streams:\n\n    1. Wrap the target\n        Use a ``target`` that maintains state between retries, and creates a\n        different generator on each retry call. For example, you can wrap a\n        network call in a function that modifies the request based on what has\n        already been returned:\n\n        .. code-block:: python\n\n            def attempt_with_modified_request(target, request, seen_items=[]):\n                # remove seen items from request on each attempt\n                new_request = modify_request(request, seen_items)\n                new_generator = target(new_request)\n                for item in new_generator:\n                    yield item\n                    seen_items.append(item)\n\n            retry_wrapped_fn = StreamingRetry()(attempt_with_modified_request)\n            retryable_generator = retry_wrapped_fn(target, request)\n\n    2. Wrap the retry generator\n        Alternatively, you can wrap the retryable generator itself before\n        passing it to the end-user to add a filter on the stream. For\n        example, you can keep track of the items that were successfully yielded\n        in previous retry attempts, and only yield new items when the\n        new attempt surpasses the previous ones:\n\n        .. code-block:: python\n\n            def retryable_with_filter(target):\n                stream_idx = 0\n                # reset stream_idx when the stream is retried\n                def on_error(e):\n                    nonlocal stream_idx\n                    stream_idx = 0\n                # build retryable\n                retryable_gen = StreamingRetry(...)(target)\n                # keep track of what has been yielded out of filter\n                seen_items = []\n                for item in retryable_gen():\n                    if stream_idx >= len(seen_items):\n                        seen_items.append(item)\n                        yield item\n                    elif item != seen_items[stream_idx]:\n                        raise ValueError(\"Stream differs from last attempt\")\n                    stream_idx += 1\n\n            filter_retry_wrapped = retryable_with_filter(target)\n\n    Args:\n        predicate (Callable[Exception]): A callable that should return ``True``\n            if the given exception is retryable.\n        initial (float): The minimum amount of time to delay in seconds. This\n            must be greater than 0.\n        maximum (float): The maximum amount of time to delay in seconds.\n        multiplier (float): The multiplier applied to the delay.\n        timeout (float): How long to keep retrying, in seconds.\n            Note: timeout is only checked before initiating a retry, so the target may\n            run past the timeout value as long as it is healthy.\n        on_error (Callable[Exception]): A function to call while processing\n            a retryable exception. Any error raised by this function will\n            *not* be caught.\n        deadline (float): DEPRECATED: use `timeout` instead. For backward\n            compatibility, if specified it will override the ``timeout`` parameter.\n    \"\"\"\n\n    def __call__(\n        self,\n        func: Callable[_P, Iterable[_Y]],\n        on_error: Callable[[Exception], Any] | None = None,\n    ) -> Callable[_P, Generator[_Y, Any, None]]:\n        \"\"\"Wrap a callable with retry behavior.\n\n        Args:\n            func (Callable): The callable to add retry behavior to.\n            on_error (Optional[Callable[Exception]]): If given, the\n                on_error callback will be called with each retryable exception\n                raised by the wrapped function. Any error raised by this\n                function will *not* be caught. If on_error was specified in the\n                constructor, this value will be ignored.\n\n        Returns:\n            Callable: A callable that will invoke ``func`` with retry\n                behavior.\n        \"\"\"\n        if self._on_error is not None:\n            on_error = self._on_error\n\n        @functools.wraps(func)\n        def retry_wrapped_func(\n            *args: _P.args, **kwargs: _P.kwargs\n        ) -> Generator[_Y, Any, None]:\n            \"\"\"A wrapper that calls target function with retry.\"\"\"\n            sleep_generator = exponential_sleep_generator(\n                self._initial, self._maximum, multiplier=self._multiplier\n            )\n            return retry_target_stream(\n                func,\n                predicate=self._predicate,\n                sleep_generator=sleep_generator,\n                timeout=self._timeout,\n                on_error=on_error,\n                init_args=args,\n                init_kwargs=kwargs,\n            )\n\n        return retry_wrapped_func\n", "google/api_core/retry/retry_unary_async.py": "# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Helpers for retrying coroutine functions with exponential back-off.\n\nThe :class:`AsyncRetry` decorator shares most functionality and behavior with\n:class:`Retry`, but supports coroutine functions. Please refer to description\nof :class:`Retry` for more details.\n\nBy default, this decorator will retry transient\nAPI errors (see :func:`if_transient_error`). For example:\n\n.. code-block:: python\n\n    @retry_async.AsyncRetry()\n    async def call_flaky_rpc():\n        return await client.flaky_rpc()\n\n    # Will retry flaky_rpc() if it raises transient API errors.\n    result = await call_flaky_rpc()\n\nYou can pass a custom predicate to retry on different exceptions, such as\nwaiting for an eventually consistent item to be available:\n\n.. code-block:: python\n\n    @retry_async.AsyncRetry(predicate=retry_async.if_exception_type(exceptions.NotFound))\n    async def check_if_exists():\n        return await client.does_thing_exist()\n\n    is_available = await check_if_exists()\n\nSome client library methods apply retry automatically. These methods can accept\na ``retry`` parameter that allows you to configure the behavior:\n\n.. code-block:: python\n\n    my_retry = retry_async.AsyncRetry(timeout=60)\n    result = await client.some_method(retry=my_retry)\n\n\"\"\"\n\nfrom __future__ import annotations\n\nimport asyncio\nimport time\nimport functools\nfrom typing import (\n    Awaitable,\n    Any,\n    Callable,\n    Iterable,\n    TypeVar,\n    TYPE_CHECKING,\n)\n\nfrom google.api_core.retry.retry_base import _BaseRetry\nfrom google.api_core.retry.retry_base import _retry_error_helper\nfrom google.api_core.retry.retry_base import exponential_sleep_generator\nfrom google.api_core.retry.retry_base import build_retry_error\nfrom google.api_core.retry.retry_base import RetryFailureReason\n\n# for backwards compatibility, expose helpers in this module\nfrom google.api_core.retry.retry_base import if_exception_type  # noqa\nfrom google.api_core.retry.retry_base import if_transient_error  # noqa\n\nif TYPE_CHECKING:\n    import sys\n\n    if sys.version_info >= (3, 10):\n        from typing import ParamSpec\n    else:\n        from typing_extensions import ParamSpec\n\n    _P = ParamSpec(\"_P\")  # target function call parameters\n    _R = TypeVar(\"_R\")  # target function returned value\n\n_DEFAULT_INITIAL_DELAY = 1.0  # seconds\n_DEFAULT_MAXIMUM_DELAY = 60.0  # seconds\n_DEFAULT_DELAY_MULTIPLIER = 2.0\n_DEFAULT_DEADLINE = 60.0 * 2.0  # seconds\n_DEFAULT_TIMEOUT = 60.0 * 2.0  # seconds\n\n\nasync def retry_target(\n    target: Callable[_P, Awaitable[_R]],\n    predicate: Callable[[Exception], bool],\n    sleep_generator: Iterable[float],\n    timeout: float | None = None,\n    on_error: Callable[[Exception], None] | None = None,\n    exception_factory: Callable[\n        [list[Exception], RetryFailureReason, float | None],\n        tuple[Exception, Exception | None],\n    ] = build_retry_error,\n    **kwargs,\n):\n    \"\"\"Await a coroutine and retry if it fails.\n\n    This is the lowest-level retry helper. Generally, you'll use the\n    higher-level retry helper :class:`Retry`.\n\n    Args:\n        target(Callable[[], Any]): The function to call and retry. This must be a\n            nullary function - apply arguments with `functools.partial`.\n        predicate (Callable[Exception]): A callable used to determine if an\n            exception raised by the target should be considered retryable.\n            It should return True to retry or False otherwise.\n        sleep_generator (Iterable[float]): An infinite iterator that determines\n            how long to sleep between retries.\n        timeout (Optional[float]): How long to keep retrying the target, in seconds.\n            Note: timeout is only checked before initiating a retry, so the target may\n            run past the timeout value as long as it is healthy.\n        on_error (Optional[Callable[Exception]]): If given, the on_error\n            callback will be called with each retryable exception raised by the\n            target. Any error raised by this function will *not* be caught.\n        exception_factory: A function that is called when the retryable reaches\n            a terminal failure state, used to construct an exception to be raised.\n            It takes a list of all exceptions encountered, a retry.RetryFailureReason\n            enum indicating the failure cause, and the original timeout value\n            as arguments. It should return a tuple of the exception to be raised,\n            along with the cause exception if any. The default implementation will raise\n            a RetryError on timeout, or the last exception encountered otherwise.\n        deadline (float): DEPRECATED use ``timeout`` instead. For backward\n            compatibility, if set it will override the ``timeout`` parameter.\n\n    Returns:\n        Any: the return value of the target function.\n\n    Raises:\n        ValueError: If the sleep generator stops yielding values.\n        Exception: a custom exception specified by the exception_factory if provided.\n            If no exception_factory is provided:\n                google.api_core.RetryError: If the timeout is exceeded while retrying.\n                Exception: If the target raises an error that isn't retryable.\n    \"\"\"\n\n    timeout = kwargs.get(\"deadline\", timeout)\n\n    deadline = time.monotonic() + timeout if timeout is not None else None\n    error_list: list[Exception] = []\n\n    for sleep in sleep_generator:\n        try:\n            return await target()\n        # pylint: disable=broad-except\n        # This function explicitly must deal with broad exceptions.\n        except Exception as exc:\n            # defer to shared logic for handling errors\n            _retry_error_helper(\n                exc,\n                deadline,\n                sleep,\n                error_list,\n                predicate,\n                on_error,\n                exception_factory,\n                timeout,\n            )\n            # if exception not raised, sleep before next attempt\n            await asyncio.sleep(sleep)\n\n    raise ValueError(\"Sleep generator stopped yielding sleep values.\")\n\n\nclass AsyncRetry(_BaseRetry):\n    \"\"\"Exponential retry decorator for async coroutines.\n\n    This class is a decorator used to add exponential back-off retry behavior\n    to an RPC call.\n\n    Although the default behavior is to retry transient API errors, a\n    different predicate can be provided to retry other exceptions.\n\n    Args:\n        predicate (Callable[Exception]): A callable that should return ``True``\n            if the given exception is retryable.\n        initial (float): The minimum amount of time to delay in seconds. This\n            must be greater than 0.\n        maximum (float): The maximum amount of time to delay in seconds.\n        multiplier (float): The multiplier applied to the delay.\n        timeout (Optional[float]): How long to keep retrying in seconds.\n            Note: timeout is only checked before initiating a retry, so the target may\n            run past the timeout value as long as it is healthy.\n        on_error (Optional[Callable[Exception]]): A function to call while processing\n            a retryable exception. Any error raised by this function will\n            *not* be caught.\n        deadline (float): DEPRECATED use ``timeout`` instead. If set it will\n        override ``timeout`` parameter.\n    \"\"\"\n\n    def __call__(\n        self,\n        func: Callable[..., Awaitable[_R]],\n        on_error: Callable[[Exception], Any] | None = None,\n    ) -> Callable[_P, Awaitable[_R]]:\n        \"\"\"Wrap a callable with retry behavior.\n\n        Args:\n            func (Callable): The callable or stream to add retry behavior to.\n            on_error (Optional[Callable[Exception]]): If given, the\n                on_error callback will be called with each retryable exception\n                raised by the wrapped function. Any error raised by this\n                function will *not* be caught. If on_error was specified in the\n                constructor, this value will be ignored.\n\n        Returns:\n            Callable: A callable that will invoke ``func`` with retry\n                behavior.\n        \"\"\"\n        if self._on_error is not None:\n            on_error = self._on_error\n\n        @functools.wraps(func)\n        async def retry_wrapped_func(*args: _P.args, **kwargs: _P.kwargs) -> _R:\n            \"\"\"A wrapper that calls target function with retry.\"\"\"\n            sleep_generator = exponential_sleep_generator(\n                self._initial, self._maximum, multiplier=self._multiplier\n            )\n            return await retry_target(\n                functools.partial(func, *args, **kwargs),\n                predicate=self._predicate,\n                sleep_generator=sleep_generator,\n                timeout=self._timeout,\n                on_error=on_error,\n            )\n\n        return retry_wrapped_func\n", "google/api_core/retry/retry_unary.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Helpers for retrying functions with exponential back-off.\n\nThe :class:`Retry` decorator can be used to retry functions that raise\nexceptions using exponential backoff. Because a exponential sleep algorithm is\nused, the retry is limited by a `timeout`. The timeout determines the window\nin which retries will be attempted. This is used instead of total number of retries\nbecause it is difficult to ascertain the amount of time a function can block\nwhen using total number of retries and exponential backoff.\n\nBy default, this decorator will retry transient\nAPI errors (see :func:`if_transient_error`). For example:\n\n.. code-block:: python\n\n    @retry.Retry()\n    def call_flaky_rpc():\n        return client.flaky_rpc()\n\n    # Will retry flaky_rpc() if it raises transient API errors.\n    result = call_flaky_rpc()\n\nYou can pass a custom predicate to retry on different exceptions, such as\nwaiting for an eventually consistent item to be available:\n\n.. code-block:: python\n\n    @retry.Retry(predicate=if_exception_type(exceptions.NotFound))\n    def check_if_exists():\n        return client.does_thing_exist()\n\n    is_available = check_if_exists()\n\nSome client library methods apply retry automatically. These methods can accept\na ``retry`` parameter that allows you to configure the behavior:\n\n.. code-block:: python\n\n    my_retry = retry.Retry(timeout=60)\n    result = client.some_method(retry=my_retry)\n\n\"\"\"\n\nfrom __future__ import annotations\n\nimport functools\nimport sys\nimport time\nimport inspect\nimport warnings\nfrom typing import Any, Callable, Iterable, TypeVar, TYPE_CHECKING\n\nfrom google.api_core.retry.retry_base import _BaseRetry\nfrom google.api_core.retry.retry_base import _retry_error_helper\nfrom google.api_core.retry.retry_base import exponential_sleep_generator\nfrom google.api_core.retry.retry_base import build_retry_error\nfrom google.api_core.retry.retry_base import RetryFailureReason\n\n\nif TYPE_CHECKING:\n    if sys.version_info >= (3, 10):\n        from typing import ParamSpec\n    else:\n        from typing_extensions import ParamSpec\n\n    _P = ParamSpec(\"_P\")  # target function call parameters\n    _R = TypeVar(\"_R\")  # target function returned value\n\n_ASYNC_RETRY_WARNING = \"Using the synchronous google.api_core.retry.Retry with asynchronous calls may lead to unexpected results. Please use google.api_core.retry_async.AsyncRetry instead.\"\n\n\ndef retry_target(\n    target: Callable[_P, _R],\n    predicate: Callable[[Exception], bool],\n    sleep_generator: Iterable[float],\n    timeout: float | None = None,\n    on_error: Callable[[Exception], None] | None = None,\n    exception_factory: Callable[\n        [list[Exception], RetryFailureReason, float | None],\n        tuple[Exception, Exception | None],\n    ] = build_retry_error,\n    **kwargs,\n):\n    \"\"\"Call a function and retry if it fails.\n\n    This is the lowest-level retry helper. Generally, you'll use the\n    higher-level retry helper :class:`Retry`.\n\n    Args:\n        target(Callable): The function to call and retry. This must be a\n            nullary function - apply arguments with `functools.partial`.\n        predicate (Callable[Exception]): A callable used to determine if an\n            exception raised by the target should be considered retryable.\n            It should return True to retry or False otherwise.\n        sleep_generator (Iterable[float]): An infinite iterator that determines\n            how long to sleep between retries.\n        timeout (Optional[float]): How long to keep retrying the target.\n            Note: timeout is only checked before initiating a retry, so the target may\n            run past the timeout value as long as it is healthy.\n        on_error (Optional[Callable[Exception]]): If given, the on_error\n            callback will be called with each retryable exception raised by the\n            target. Any error raised by this function will *not* be caught.\n        exception_factory: A function that is called when the retryable reaches\n            a terminal failure state, used to construct an exception to be raised.\n            It takes a list of all exceptions encountered, a retry.RetryFailureReason\n            enum indicating the failure cause, and the original timeout value\n            as arguments. It should return a tuple of the exception to be raised,\n            along with the cause exception if any. The default implementation will raise\n            a RetryError on timeout, or the last exception encountered otherwise.\n        deadline (float): DEPRECATED: use ``timeout`` instead. For backward\n            compatibility, if specified it will override ``timeout`` parameter.\n\n    Returns:\n        Any: the return value of the target function.\n\n    Raises:\n        ValueError: If the sleep generator stops yielding values.\n        Exception: a custom exception specified by the exception_factory if provided.\n            If no exception_factory is provided:\n                google.api_core.RetryError: If the timeout is exceeded while retrying.\n                Exception: If the target raises an error that isn't retryable.\n    \"\"\"\n\n    timeout = kwargs.get(\"deadline\", timeout)\n\n    deadline = time.monotonic() + timeout if timeout is not None else None\n    error_list: list[Exception] = []\n\n    for sleep in sleep_generator:\n        try:\n            result = target()\n            if inspect.isawaitable(result):\n                warnings.warn(_ASYNC_RETRY_WARNING)\n            return result\n\n        # pylint: disable=broad-except\n        # This function explicitly must deal with broad exceptions.\n        except Exception as exc:\n            # defer to shared logic for handling errors\n            _retry_error_helper(\n                exc,\n                deadline,\n                sleep,\n                error_list,\n                predicate,\n                on_error,\n                exception_factory,\n                timeout,\n            )\n            # if exception not raised, sleep before next attempt\n            time.sleep(sleep)\n\n    raise ValueError(\"Sleep generator stopped yielding sleep values.\")\n\n\nclass Retry(_BaseRetry):\n    \"\"\"Exponential retry decorator for unary synchronous RPCs.\n\n    This class is a decorator used to add retry or polling behavior to an RPC\n    call.\n\n    Although the default behavior is to retry transient API errors, a\n    different predicate can be provided to retry other exceptions.\n\n    There are two important concepts that retry/polling behavior may operate on,\n    Deadline and Timeout, which need to be properly defined for the correct\n    usage of this class and the rest of the library.\n\n    Deadline: a fixed point in time by which a certain operation must\n    terminate. For example, if a certain operation has a deadline\n    \"2022-10-18T23:30:52.123Z\" it must terminate (successfully or with an\n    error) by that time, regardless of when it was started or whether it\n    was started at all.\n\n    Timeout: the maximum duration of time after which a certain operation\n    must terminate (successfully or with an error). The countdown begins right\n    after an operation was started. For example, if an operation was started at\n    09:24:00 with timeout of 75 seconds, it must terminate no later than\n    09:25:15.\n\n    Unfortunately, in the past this class (and the api-core library as a whole) has not\n    been properly distinguishing the concepts of \"timeout\" and \"deadline\", and the\n    ``deadline`` parameter has meant ``timeout``. That is why\n    ``deadline`` has been deprecated and ``timeout`` should be used instead. If the\n    ``deadline`` parameter is set, it will override the ``timeout`` parameter.\n    In other words, ``retry.deadline`` should be treated as just a deprecated alias for\n    ``retry.timeout``.\n\n    Said another way, it is safe to assume that this class and the rest of this\n    library operate in terms of timeouts (not deadlines) unless explicitly\n    noted the usage of deadline semantics.\n\n    It is also important to\n    understand the three most common applications of the Timeout concept in the\n    context of this library.\n\n    Usually the generic Timeout term may stand for one of the following actual\n    timeouts: RPC Timeout, Retry Timeout, or Polling Timeout.\n\n    RPC Timeout: a value supplied by the client to the server so\n    that the server side knows the maximum amount of time it is expected to\n    spend handling that specific RPC. For example, in the case of gRPC transport,\n    RPC Timeout is represented by setting \"grpc-timeout\" header in the HTTP2\n    request. The `timeout` property of this class normally never represents the\n    RPC Timeout as it is handled separately by the ``google.api_core.timeout``\n    module of this library.\n\n    Retry Timeout: this is the most common meaning of the ``timeout`` property\n    of this class, and defines how long a certain RPC may be retried in case\n    the server returns an error.\n\n    Polling Timeout: defines how long the\n    client side is allowed to call the polling RPC repeatedly to check a status of a\n    long-running operation. Each polling RPC is\n    expected to succeed (its errors are supposed to be handled by the retry\n    logic). The decision as to whether a new polling attempt needs to be made is based\n    not on the RPC status code but  on the status of the returned\n    status of an operation. In other words: we will poll a long-running operation until\n    the operation is done or the polling timeout expires. Each poll will inform us of\n    the status of the operation. The poll consists of an RPC to the server that may\n    itself be retried as per the poll-specific retry settings in case of errors. The\n    operation-level retry settings do NOT apply to polling-RPC retries.\n\n    With the actual timeout types being defined above, the client libraries\n    often refer to just Timeout without clarifying which type specifically\n    that is. In that case the actual timeout type (sometimes also referred to as\n    Logical Timeout) can be determined from the context. If it is a unary rpc\n    call (i.e. a regular one) Timeout usually stands for the RPC Timeout (if\n    provided directly as a standalone value) or Retry Timeout (if provided as\n    ``retry.timeout`` property of the unary RPC's retry config). For\n    ``Operation`` or ``PollingFuture`` in general Timeout stands for\n    Polling Timeout.\n\n    Args:\n        predicate (Callable[Exception]): A callable that should return ``True``\n            if the given exception is retryable.\n        initial (float): The minimum amount of time to delay in seconds. This\n            must be greater than 0.\n        maximum (float): The maximum amount of time to delay in seconds.\n        multiplier (float): The multiplier applied to the delay.\n        timeout (Optional[float]): How long to keep retrying, in seconds.\n            Note: timeout is only checked before initiating a retry, so the target may\n            run past the timeout value as long as it is healthy.\n        on_error (Callable[Exception]): A function to call while processing\n            a retryable exception. Any error raised by this function will\n            *not* be caught.\n        deadline (float): DEPRECATED: use `timeout` instead. For backward\n            compatibility, if specified it will override the ``timeout`` parameter.\n    \"\"\"\n\n    def __call__(\n        self,\n        func: Callable[_P, _R],\n        on_error: Callable[[Exception], Any] | None = None,\n    ) -> Callable[_P, _R]:\n        \"\"\"Wrap a callable with retry behavior.\n\n        Args:\n            func (Callable): The callable to add retry behavior to.\n            on_error (Optional[Callable[Exception]]): If given, the\n                on_error callback will be called with each retryable exception\n                raised by the wrapped function. Any error raised by this\n                function will *not* be caught. If on_error was specified in the\n                constructor, this value will be ignored.\n\n        Returns:\n            Callable: A callable that will invoke ``func`` with retry\n                behavior.\n        \"\"\"\n        if self._on_error is not None:\n            on_error = self._on_error\n\n        @functools.wraps(func)\n        def retry_wrapped_func(*args: _P.args, **kwargs: _P.kwargs) -> _R:\n            \"\"\"A wrapper that calls target function with retry.\"\"\"\n            target = functools.partial(func, *args, **kwargs)\n            sleep_generator = exponential_sleep_generator(\n                self._initial, self._maximum, multiplier=self._multiplier\n            )\n            return retry_target(\n                target,\n                self._predicate,\n                sleep_generator,\n                timeout=self._timeout,\n                on_error=on_error,\n            )\n\n        return retry_wrapped_func\n", "google/api_core/retry/__init__.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Retry implementation for Google API client libraries.\"\"\"\n\nfrom .retry_base import exponential_sleep_generator\nfrom .retry_base import if_exception_type\nfrom .retry_base import if_transient_error\nfrom .retry_base import build_retry_error\nfrom .retry_base import RetryFailureReason\nfrom .retry_unary import Retry\nfrom .retry_unary import retry_target\nfrom .retry_unary_async import AsyncRetry\nfrom .retry_unary_async import retry_target as retry_target_async\nfrom .retry_streaming import StreamingRetry\nfrom .retry_streaming import retry_target_stream\nfrom .retry_streaming_async import AsyncStreamingRetry\nfrom .retry_streaming_async import retry_target_stream as retry_target_stream_async\n\n# The following imports are for backwards compatibility with https://github.com/googleapis/python-api-core/blob/4d7d2edee2c108d43deb151e6e0fdceb56b73275/google/api_core/retry.py\n#\n# TODO: Revert these imports on the next major version release (https://github.com/googleapis/python-api-core/issues/576)\nfrom google.api_core import datetime_helpers  # noqa: F401\nfrom google.api_core import exceptions  # noqa: F401\nfrom google.auth import exceptions as auth_exceptions  # noqa: F401\n\n__all__ = (\n    \"exponential_sleep_generator\",\n    \"if_exception_type\",\n    \"if_transient_error\",\n    \"build_retry_error\",\n    \"RetryFailureReason\",\n    \"Retry\",\n    \"AsyncRetry\",\n    \"StreamingRetry\",\n    \"AsyncStreamingRetry\",\n    \"retry_target\",\n    \"retry_target_async\",\n    \"retry_target_stream\",\n    \"retry_target_stream_async\",\n)\n", "google/api_core/retry/retry_base.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Shared classes and functions for retrying requests.\n\n:class:`_BaseRetry` is the base class for :class:`Retry`,\n:class:`AsyncRetry`, :class:`StreamingRetry`, and :class:`AsyncStreamingRetry`.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport logging\nimport random\nimport time\n\nfrom enum import Enum\nfrom typing import Any, Callable, Optional, TYPE_CHECKING\n\nimport requests.exceptions\n\nfrom google.api_core import exceptions\nfrom google.auth import exceptions as auth_exceptions\n\nif TYPE_CHECKING:\n    import sys\n\n    if sys.version_info >= (3, 11):\n        from typing import Self\n    else:\n        from typing_extensions import Self\n\n_DEFAULT_INITIAL_DELAY = 1.0  # seconds\n_DEFAULT_MAXIMUM_DELAY = 60.0  # seconds\n_DEFAULT_DELAY_MULTIPLIER = 2.0\n_DEFAULT_DEADLINE = 60.0 * 2.0  # seconds\n\n_LOGGER = logging.getLogger(\"google.api_core.retry\")\n\n\ndef if_exception_type(\n    *exception_types: type[Exception],\n) -> Callable[[Exception], bool]:\n    \"\"\"Creates a predicate to check if the exception is of a given type.\n\n    Args:\n        exception_types (Sequence[:func:`type`]): The exception types to check\n            for.\n\n    Returns:\n        Callable[Exception]: A predicate that returns True if the provided\n            exception is of the given type(s).\n    \"\"\"\n\n    def if_exception_type_predicate(exception: Exception) -> bool:\n        \"\"\"Bound predicate for checking an exception type.\"\"\"\n        return isinstance(exception, exception_types)\n\n    return if_exception_type_predicate\n\n\n# pylint: disable=invalid-name\n# Pylint sees this as a constant, but it is also an alias that should be\n# considered a function.\nif_transient_error = if_exception_type(\n    exceptions.InternalServerError,\n    exceptions.TooManyRequests,\n    exceptions.ServiceUnavailable,\n    requests.exceptions.ConnectionError,\n    requests.exceptions.ChunkedEncodingError,\n    auth_exceptions.TransportError,\n)\n\"\"\"A predicate that checks if an exception is a transient API error.\n\nThe following server errors are considered transient:\n\n- :class:`google.api_core.exceptions.InternalServerError` - HTTP 500, gRPC\n    ``INTERNAL(13)`` and its subclasses.\n- :class:`google.api_core.exceptions.TooManyRequests` - HTTP 429\n- :class:`google.api_core.exceptions.ServiceUnavailable` - HTTP 503\n- :class:`requests.exceptions.ConnectionError`\n- :class:`requests.exceptions.ChunkedEncodingError` - The server declared\n    chunked encoding but sent an invalid chunk.\n- :class:`google.auth.exceptions.TransportError` - Used to indicate an\n    error occurred during an HTTP request.\n\"\"\"\n# pylint: enable=invalid-name\n\n\ndef exponential_sleep_generator(\n    initial: float, maximum: float, multiplier: float = _DEFAULT_DELAY_MULTIPLIER\n):\n    \"\"\"Generates sleep intervals based on the exponential back-off algorithm.\n\n    This implements the `Truncated Exponential Back-off`_ algorithm.\n\n    .. _Truncated Exponential Back-off:\n        https://cloud.google.com/storage/docs/exponential-backoff\n\n    Args:\n        initial (float): The minimum amount of time to delay. This must\n            be greater than 0.\n        maximum (float): The maximum amount of time to delay.\n        multiplier (float): The multiplier applied to the delay.\n\n    Yields:\n        float: successive sleep intervals.\n    \"\"\"\n    max_delay = min(initial, maximum)\n    while True:\n        yield random.uniform(0.0, max_delay)\n        max_delay = min(max_delay * multiplier, maximum)\n\n\nclass RetryFailureReason(Enum):\n    \"\"\"\n    The cause of a failed retry, used when building exceptions\n    \"\"\"\n\n    TIMEOUT = 0\n    NON_RETRYABLE_ERROR = 1\n\n\ndef build_retry_error(\n    exc_list: list[Exception],\n    reason: RetryFailureReason,\n    timeout_val: float | None,\n    **kwargs: Any,\n) -> tuple[Exception, Exception | None]:\n    \"\"\"\n    Default exception_factory implementation.\n\n    Returns a RetryError if the failure is due to a timeout, otherwise\n    returns the last exception encountered.\n\n    Args:\n      - exc_list: list of exceptions that occurred during the retry\n      - reason: reason for the retry failure.\n            Can be TIMEOUT or NON_RETRYABLE_ERROR\n      - timeout_val: the original timeout value for the retry (in seconds), for use in the exception message\n\n    Returns:\n      - tuple: a tuple of the exception to be raised, and the cause exception if any\n    \"\"\"\n    if reason == RetryFailureReason.TIMEOUT:\n        # return RetryError with the most recent exception as the cause\n        src_exc = exc_list[-1] if exc_list else None\n        timeout_val_str = f\"of {timeout_val:0.1f}s \" if timeout_val is not None else \"\"\n        return (\n            exceptions.RetryError(\n                f\"Timeout {timeout_val_str}exceeded\",\n                src_exc,\n            ),\n            src_exc,\n        )\n    elif exc_list:\n        # return most recent exception encountered\n        return exc_list[-1], None\n    else:\n        # no exceptions were given in exc_list. Raise generic RetryError\n        return exceptions.RetryError(\"Unknown error\", None), None\n\n\ndef _retry_error_helper(\n    exc: Exception,\n    deadline: float | None,\n    next_sleep: float,\n    error_list: list[Exception],\n    predicate_fn: Callable[[Exception], bool],\n    on_error_fn: Callable[[Exception], None] | None,\n    exc_factory_fn: Callable[\n        [list[Exception], RetryFailureReason, float | None],\n        tuple[Exception, Exception | None],\n    ],\n    original_timeout: float | None,\n):\n    \"\"\"\n    Shared logic for handling an error for all retry implementations\n\n    - Raises an error on timeout or non-retryable error\n    - Calls on_error_fn if provided\n    - Logs the error\n\n    Args:\n       - exc: the exception that was raised\n       - deadline: the deadline for the retry, calculated as a diff from time.monotonic()\n       - next_sleep: the next sleep interval\n       - error_list: the list of exceptions that have been raised so far\n       - predicate_fn: takes `exc` and returns true if the operation should be retried\n       - on_error_fn: callback to execute when a retryable error occurs\n       - exc_factory_fn: callback used to build the exception to be raised on terminal failure\n       - original_timeout_val: the original timeout value for the retry (in seconds),\n           to be passed to the exception factory for building an error message\n    \"\"\"\n    error_list.append(exc)\n    if not predicate_fn(exc):\n        final_exc, source_exc = exc_factory_fn(\n            error_list,\n            RetryFailureReason.NON_RETRYABLE_ERROR,\n            original_timeout,\n        )\n        raise final_exc from source_exc\n    if on_error_fn is not None:\n        on_error_fn(exc)\n    if deadline is not None and time.monotonic() + next_sleep > deadline:\n        final_exc, source_exc = exc_factory_fn(\n            error_list,\n            RetryFailureReason.TIMEOUT,\n            original_timeout,\n        )\n        raise final_exc from source_exc\n    _LOGGER.debug(\n        \"Retrying due to {}, sleeping {:.1f}s ...\".format(error_list[-1], next_sleep)\n    )\n\n\nclass _BaseRetry(object):\n    \"\"\"\n    Base class for retry configuration objects. This class is intended to capture retry\n    and backoff configuration that is common to both synchronous and asynchronous retries,\n    for both unary and streaming RPCs. It is not intended to be instantiated directly,\n    but rather to be subclassed by the various retry configuration classes.\n    \"\"\"\n\n    def __init__(\n        self,\n        predicate: Callable[[Exception], bool] = if_transient_error,\n        initial: float = _DEFAULT_INITIAL_DELAY,\n        maximum: float = _DEFAULT_MAXIMUM_DELAY,\n        multiplier: float = _DEFAULT_DELAY_MULTIPLIER,\n        timeout: Optional[float] = _DEFAULT_DEADLINE,\n        on_error: Optional[Callable[[Exception], Any]] = None,\n        **kwargs: Any,\n    ) -> None:\n        self._predicate = predicate\n        self._initial = initial\n        self._multiplier = multiplier\n        self._maximum = maximum\n        self._timeout = kwargs.get(\"deadline\", timeout)\n        self._deadline = self._timeout\n        self._on_error = on_error\n\n    def __call__(self, *args, **kwargs) -> Any:\n        raise NotImplementedError(\"Not implemented in base class\")\n\n    @property\n    def deadline(self) -> float | None:\n        \"\"\"\n        DEPRECATED: use ``timeout`` instead.  Refer to the ``Retry`` class\n        documentation for details.\n        \"\"\"\n        return self._timeout\n\n    @property\n    def timeout(self) -> float | None:\n        return self._timeout\n\n    def with_deadline(self, deadline: float | None) -> Self:\n        \"\"\"Return a copy of this retry with the given timeout.\n\n        DEPRECATED: use :meth:`with_timeout` instead. Refer to the ``Retry`` class\n        documentation for details.\n\n        Args:\n            deadline (float|None): How long to keep retrying, in seconds. If None,\n                no timeout is enforced.\n\n        Returns:\n            Retry: A new retry instance with the given timeout.\n        \"\"\"\n        return self.with_timeout(deadline)\n\n    def with_timeout(self, timeout: float | None) -> Self:\n        \"\"\"Return a copy of this retry with the given timeout.\n\n        Args:\n            timeout (float): How long to keep retrying, in seconds. If None,\n                no timeout will be enforced.\n\n        Returns:\n            Retry: A new retry instance with the given timeout.\n        \"\"\"\n        return type(self)(\n            predicate=self._predicate,\n            initial=self._initial,\n            maximum=self._maximum,\n            multiplier=self._multiplier,\n            timeout=timeout,\n            on_error=self._on_error,\n        )\n\n    def with_predicate(self, predicate: Callable[[Exception], bool]) -> Self:\n        \"\"\"Return a copy of this retry with the given predicate.\n\n        Args:\n            predicate (Callable[Exception]): A callable that should return\n                ``True`` if the given exception is retryable.\n\n        Returns:\n            Retry: A new retry instance with the given predicate.\n        \"\"\"\n        return type(self)(\n            predicate=predicate,\n            initial=self._initial,\n            maximum=self._maximum,\n            multiplier=self._multiplier,\n            timeout=self._timeout,\n            on_error=self._on_error,\n        )\n\n    def with_delay(\n        self,\n        initial: Optional[float] = None,\n        maximum: Optional[float] = None,\n        multiplier: Optional[float] = None,\n    ) -> Self:\n        \"\"\"Return a copy of this retry with the given delay options.\n\n        Args:\n            initial (float): The minimum amount of time to delay (in seconds). This must\n                be greater than 0. If None, the current value is used.\n            maximum (float): The maximum amount of time to delay (in seconds). If None, the\n                current value is used.\n            multiplier (float): The multiplier applied to the delay. If None, the current\n                value is used.\n\n        Returns:\n            Retry: A new retry instance with the given delay options.\n        \"\"\"\n        return type(self)(\n            predicate=self._predicate,\n            initial=initial if initial is not None else self._initial,\n            maximum=maximum if maximum is not None else self._maximum,\n            multiplier=multiplier if multiplier is not None else self._multiplier,\n            timeout=self._timeout,\n            on_error=self._on_error,\n        )\n\n    def __str__(self) -> str:\n        return (\n            \"<{} predicate={}, initial={:.1f}, maximum={:.1f}, \"\n            \"multiplier={:.1f}, timeout={}, on_error={}>\".format(\n                type(self).__name__,\n                self._predicate,\n                self._initial,\n                self._maximum,\n                self._multiplier,\n                self._timeout,  # timeout can be None, thus no {:.1f}\n                self._on_error,\n            )\n        )\n", "google/api_core/gapic_v1/config.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Helpers for loading gapic configuration data.\n\nThe Google API generator creates supplementary configuration for each RPC\nmethod to tell the client library how to deal with retries and timeouts.\n\"\"\"\n\nimport collections\n\nimport grpc\n\nfrom google.api_core import exceptions\nfrom google.api_core import retry\nfrom google.api_core import timeout\n\n\n_MILLIS_PER_SECOND = 1000.0\n\n\ndef _exception_class_for_grpc_status_name(name):\n    \"\"\"Returns the Google API exception class for a gRPC error code name.\n\n    DEPRECATED: use ``exceptions.exception_class_for_grpc_status`` method\n    directly instead.\n\n    Args:\n        name (str): The name of the gRPC status code, for example,\n            ``UNAVAILABLE``.\n\n    Returns:\n        :func:`type`: The appropriate subclass of\n            :class:`google.api_core.exceptions.GoogleAPICallError`.\n    \"\"\"\n    return exceptions.exception_class_for_grpc_status(getattr(grpc.StatusCode, name))\n\n\ndef _retry_from_retry_config(retry_params, retry_codes, retry_impl=retry.Retry):\n    \"\"\"Creates a Retry object given a gapic retry configuration.\n\n    DEPRECATED: instantiate retry and timeout classes directly instead.\n\n    Args:\n        retry_params (dict): The retry parameter values, for example::\n\n            {\n                \"initial_retry_delay_millis\": 1000,\n                \"retry_delay_multiplier\": 2.5,\n                \"max_retry_delay_millis\": 120000,\n                \"initial_rpc_timeout_millis\": 120000,\n                \"rpc_timeout_multiplier\": 1.0,\n                \"max_rpc_timeout_millis\": 120000,\n                \"total_timeout_millis\": 600000\n            }\n\n        retry_codes (sequence[str]): The list of retryable gRPC error code\n            names.\n\n    Returns:\n        google.api_core.retry.Retry: The default retry object for the method.\n    \"\"\"\n    exception_classes = [\n        _exception_class_for_grpc_status_name(code) for code in retry_codes\n    ]\n    return retry_impl(\n        retry.if_exception_type(*exception_classes),\n        initial=(retry_params[\"initial_retry_delay_millis\"] / _MILLIS_PER_SECOND),\n        maximum=(retry_params[\"max_retry_delay_millis\"] / _MILLIS_PER_SECOND),\n        multiplier=retry_params[\"retry_delay_multiplier\"],\n        deadline=retry_params[\"total_timeout_millis\"] / _MILLIS_PER_SECOND,\n    )\n\n\ndef _timeout_from_retry_config(retry_params):\n    \"\"\"Creates a ExponentialTimeout object given a gapic retry configuration.\n\n    DEPRECATED: instantiate retry and timeout classes directly instead.\n\n    Args:\n        retry_params (dict): The retry parameter values, for example::\n\n            {\n                \"initial_retry_delay_millis\": 1000,\n                \"retry_delay_multiplier\": 2.5,\n                \"max_retry_delay_millis\": 120000,\n                \"initial_rpc_timeout_millis\": 120000,\n                \"rpc_timeout_multiplier\": 1.0,\n                \"max_rpc_timeout_millis\": 120000,\n                \"total_timeout_millis\": 600000\n            }\n\n    Returns:\n        google.api_core.retry.ExponentialTimeout: The default time object for\n            the method.\n    \"\"\"\n    return timeout.ExponentialTimeout(\n        initial=(retry_params[\"initial_rpc_timeout_millis\"] / _MILLIS_PER_SECOND),\n        maximum=(retry_params[\"max_rpc_timeout_millis\"] / _MILLIS_PER_SECOND),\n        multiplier=retry_params[\"rpc_timeout_multiplier\"],\n        deadline=(retry_params[\"total_timeout_millis\"] / _MILLIS_PER_SECOND),\n    )\n\n\nMethodConfig = collections.namedtuple(\"MethodConfig\", [\"retry\", \"timeout\"])\n\n\ndef parse_method_configs(interface_config, retry_impl=retry.Retry):\n    \"\"\"Creates default retry and timeout objects for each method in a gapic\n    interface config.\n\n    DEPRECATED: instantiate retry and timeout classes directly instead.\n\n    Args:\n        interface_config (Mapping): The interface config section of the full\n            gapic library config. For example, If the full configuration has\n            an interface named ``google.example.v1.ExampleService`` you would\n            pass in just that interface's configuration, for example\n            ``gapic_config['interfaces']['google.example.v1.ExampleService']``.\n        retry_impl (Callable): The constructor that creates a retry decorator\n            that will be applied to the method based on method configs.\n\n    Returns:\n        Mapping[str, MethodConfig]: A mapping of RPC method names to their\n            configuration.\n    \"\"\"\n    # Grab all the retry codes\n    retry_codes_map = {\n        name: retry_codes\n        for name, retry_codes in interface_config.get(\"retry_codes\", {}).items()\n    }\n\n    # Grab all of the retry params\n    retry_params_map = {\n        name: retry_params\n        for name, retry_params in interface_config.get(\"retry_params\", {}).items()\n    }\n\n    # Iterate through all the API methods and create a flat MethodConfig\n    # instance for each one.\n    method_configs = {}\n\n    for method_name, method_params in interface_config.get(\"methods\", {}).items():\n        retry_params_name = method_params.get(\"retry_params_name\")\n\n        if retry_params_name is not None:\n            retry_params = retry_params_map[retry_params_name]\n            retry_ = _retry_from_retry_config(\n                retry_params,\n                retry_codes_map[method_params[\"retry_codes_name\"]],\n                retry_impl,\n            )\n            timeout_ = _timeout_from_retry_config(retry_params)\n\n        # No retry config, so this is a non-retryable method.\n        else:\n            retry_ = None\n            timeout_ = timeout.ConstantTimeout(\n                method_params[\"timeout_millis\"] / _MILLIS_PER_SECOND\n            )\n\n        method_configs[method_name] = MethodConfig(retry=retry_, timeout=timeout_)\n\n    return method_configs\n", "google/api_core/gapic_v1/method_async.py": "# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\"AsyncIO helpers for wrapping gRPC methods with common functionality.\n\nThis is used by gapic clients to provide common error mapping, retry, timeout,\ncompression, pagination, and long-running operations to gRPC methods.\n\"\"\"\n\nimport functools\n\nfrom google.api_core import grpc_helpers_async\nfrom google.api_core.gapic_v1 import client_info\nfrom google.api_core.gapic_v1.method import _GapicCallable\nfrom google.api_core.gapic_v1.method import DEFAULT  # noqa: F401\nfrom google.api_core.gapic_v1.method import USE_DEFAULT_METADATA  # noqa: F401\n\n\ndef wrap_method(\n    func,\n    default_retry=None,\n    default_timeout=None,\n    default_compression=None,\n    client_info=client_info.DEFAULT_CLIENT_INFO,\n):\n    \"\"\"Wrap an async RPC method with common behavior.\n\n    Returns:\n        Callable: A new callable that takes optional ``retry``, ``timeout``,\n            and ``compression`` arguments and applies the common error mapping,\n            retry, timeout, metadata, and compression behavior to the low-level RPC method.\n    \"\"\"\n    func = grpc_helpers_async.wrap_errors(func)\n\n    metadata = [client_info.to_grpc_metadata()] if client_info is not None else None\n\n    return functools.wraps(func)(\n        _GapicCallable(\n            func,\n            default_retry,\n            default_timeout,\n            default_compression,\n            metadata=metadata,\n        )\n    )\n", "google/api_core/gapic_v1/client_info.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Helpers for providing client information.\n\nClient information is used to send information about the calling client,\nsuch as the library and Python version, to API services.\n\"\"\"\n\nfrom google.api_core import client_info\n\n\nMETRICS_METADATA_KEY = \"x-goog-api-client\"\n\n\nclass ClientInfo(client_info.ClientInfo):\n    \"\"\"Client information used to generate a user-agent for API calls.\n\n    This user-agent information is sent along with API calls to allow the\n    receiving service to do analytics on which versions of Python and Google\n    libraries are being used.\n\n    Args:\n        python_version (str): The Python interpreter version, for example,\n            ``'3.9.6'``.\n        grpc_version (Optional[str]): The gRPC library version.\n        api_core_version (str): The google-api-core library version.\n        gapic_version (Optional[str]): The version of gapic-generated client\n            library, if the library was generated by gapic.\n        client_library_version (Optional[str]): The version of the client\n            library, generally used if the client library was not generated\n            by gapic or if additional functionality was built on top of\n            a gapic client library.\n        user_agent (Optional[str]): Prefix to the user agent header. This is\n            used to supply information such as application name or partner tool.\n            Recommended format: ``application-or-tool-ID/major.minor.version``.\n    \"\"\"\n\n    def to_grpc_metadata(self):\n        \"\"\"Returns the gRPC metadata for this client info.\"\"\"\n        return (METRICS_METADATA_KEY, self.to_user_agent())\n\n\nDEFAULT_CLIENT_INFO = ClientInfo()\n", "google/api_core/gapic_v1/method.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Helpers for wrapping low-level gRPC methods with common functionality.\n\nThis is used by gapic clients to provide common error mapping, retry, timeout,\ncompression, pagination, and long-running operations to gRPC methods.\n\"\"\"\n\nimport enum\nimport functools\n\nfrom google.api_core import grpc_helpers\nfrom google.api_core.gapic_v1 import client_info\nfrom google.api_core.timeout import TimeToDeadlineTimeout\n\nUSE_DEFAULT_METADATA = object()\n\n\nclass _MethodDefault(enum.Enum):\n    # Uses enum so that pytype/mypy knows that this is the only possible value.\n    # https://stackoverflow.com/a/60605919/101923\n    #\n    # Literal[_DEFAULT_VALUE] is an alternative, but only added in Python 3.8.\n    # https://docs.python.org/3/library/typing.html#typing.Literal\n    _DEFAULT_VALUE = object()\n\n\nDEFAULT = _MethodDefault._DEFAULT_VALUE\n\"\"\"Sentinel value indicating that a retry, timeout, or compression argument was unspecified,\nso the default should be used.\"\"\"\n\n\ndef _is_not_none_or_false(value):\n    return value is not None and value is not False\n\n\ndef _apply_decorators(func, decorators):\n    \"\"\"Apply a list of decorators to a given function.\n\n    ``decorators`` may contain items that are ``None`` or ``False`` which will\n    be ignored.\n    \"\"\"\n    filtered_decorators = filter(_is_not_none_or_false, reversed(decorators))\n\n    for decorator in filtered_decorators:\n        func = decorator(func)\n\n    return func\n\n\nclass _GapicCallable(object):\n    \"\"\"Callable that applies retry, timeout, and metadata logic.\n\n    Args:\n        target (Callable): The low-level RPC method.\n        retry (google.api_core.retry.Retry): The default retry for the\n            callable. If ``None``, this callable will not retry by default\n        timeout (google.api_core.timeout.Timeout): The default timeout for the\n            callable (i.e. duration of time within which an RPC must terminate\n            after its start, not to be confused with deadline). If ``None``,\n            this callable will not specify a timeout argument to the low-level\n            RPC method.\n        compression (grpc.Compression): The default compression for the callable.\n            If ``None``, this callable will not specify a compression argument\n            to the low-level RPC method.\n        metadata (Sequence[Tuple[str, str]]): Additional metadata that is\n            provided to the RPC method on every invocation. This is merged with\n            any metadata specified during invocation. If ``None``, no\n            additional metadata will be passed to the RPC method.\n    \"\"\"\n\n    def __init__(\n        self,\n        target,\n        retry,\n        timeout,\n        compression,\n        metadata=None,\n    ):\n        self._target = target\n        self._retry = retry\n        self._timeout = timeout\n        self._compression = compression\n        self._metadata = metadata\n\n    def __call__(\n        self, *args, timeout=DEFAULT, retry=DEFAULT, compression=DEFAULT, **kwargs\n    ):\n        \"\"\"Invoke the low-level RPC with retry, timeout, compression, and metadata.\"\"\"\n\n        if retry is DEFAULT:\n            retry = self._retry\n\n        if timeout is DEFAULT:\n            timeout = self._timeout\n\n        if compression is DEFAULT:\n            compression = self._compression\n\n        if isinstance(timeout, (int, float)):\n            timeout = TimeToDeadlineTimeout(timeout=timeout)\n\n        # Apply all applicable decorators.\n        wrapped_func = _apply_decorators(self._target, [retry, timeout])\n\n        # Add the user agent metadata to the call.\n        if self._metadata is not None:\n            metadata = kwargs.get(\"metadata\", [])\n            # Due to the nature of invocation, None should be treated the same\n            # as not specified.\n            if metadata is None:\n                metadata = []\n            metadata = list(metadata)\n            metadata.extend(self._metadata)\n            kwargs[\"metadata\"] = metadata\n        if self._compression is not None:\n            kwargs[\"compression\"] = compression\n\n        return wrapped_func(*args, **kwargs)\n\n\ndef wrap_method(\n    func,\n    default_retry=None,\n    default_timeout=None,\n    default_compression=None,\n    client_info=client_info.DEFAULT_CLIENT_INFO,\n    *,\n    with_call=False,\n):\n    \"\"\"Wrap an RPC method with common behavior.\n\n    This applies common error wrapping, retry, timeout, and compression behavior to a function.\n    The wrapped function will take optional ``retry``, ``timeout``, and ``compression``\n    arguments.\n\n    For example::\n\n        import google.api_core.gapic_v1.method\n        from google.api_core import retry\n        from google.api_core import timeout\n        from grpc import Compression\n\n        # The original RPC method.\n        def get_topic(name, timeout=None):\n            request = publisher_v2.GetTopicRequest(name=name)\n            return publisher_stub.GetTopic(request, timeout=timeout)\n\n        default_retry = retry.Retry(deadline=60)\n        default_timeout = timeout.Timeout(deadline=60)\n        default_compression = Compression.NoCompression\n        wrapped_get_topic = google.api_core.gapic_v1.method.wrap_method(\n            get_topic, default_retry)\n\n        # Execute get_topic with default retry and timeout:\n        response = wrapped_get_topic()\n\n        # Execute get_topic without doing any retying but with the default\n        # timeout:\n        response = wrapped_get_topic(retry=None)\n\n        # Execute get_topic but only retry on 5xx errors:\n        my_retry = retry.Retry(retry.if_exception_type(\n            exceptions.InternalServerError))\n        response = wrapped_get_topic(retry=my_retry)\n\n    The way this works is by late-wrapping the given function with the retry\n    and timeout decorators. Essentially, when ``wrapped_get_topic()`` is\n    called:\n\n    * ``get_topic()`` is first wrapped with the ``timeout`` into\n      ``get_topic_with_timeout``.\n    * ``get_topic_with_timeout`` is wrapped with the ``retry`` into\n      ``get_topic_with_timeout_and_retry()``.\n    * The final ``get_topic_with_timeout_and_retry`` is called passing through\n      the ``args``  and ``kwargs``.\n\n    The callstack is therefore::\n\n        method.__call__() ->\n            Retry.__call__() ->\n                Timeout.__call__() ->\n                    wrap_errors() ->\n                        get_topic()\n\n    Note that if ``timeout`` or ``retry`` is ``None``, then they are not\n    applied to the function. For example,\n    ``wrapped_get_topic(timeout=None, retry=None)`` is more or less\n    equivalent to just calling ``get_topic`` but with error re-mapping.\n\n    Args:\n        func (Callable[Any]): The function to wrap. It should accept an\n            optional ``timeout`` argument. If ``metadata`` is not ``None``, it\n            should accept a ``metadata`` argument.\n        default_retry (Optional[google.api_core.Retry]): The default retry\n            strategy. If ``None``, the method will not retry by default.\n        default_timeout (Optional[google.api_core.Timeout]): The default\n            timeout strategy. Can also be specified as an int or float. If\n            ``None``, the method will not have timeout specified by default.\n        default_compression (Optional[grpc.Compression]): The default\n            grpc.Compression. If ``None``, the method will not have\n            compression specified by default.\n        client_info\n            (Optional[google.api_core.gapic_v1.client_info.ClientInfo]):\n                Client information used to create a user-agent string that's\n                passed as gRPC metadata to the method. If unspecified, then\n                a sane default will be used. If ``None``, then no user agent\n                metadata will be provided to the RPC method.\n        with_call (bool): If True, wrapped grpc.UnaryUnaryMulticallables will\n            return a tuple of (response, grpc.Call) instead of just the response.\n            This is useful for extracting trailing metadata from unary calls.\n            Defaults to False.\n\n    Returns:\n        Callable: A new callable that takes optional ``retry``, ``timeout``,\n            and ``compression``\n            arguments and applies the common error mapping, retry, timeout, compression,\n            and metadata behavior to the low-level RPC method.\n    \"\"\"\n    if with_call:\n        try:\n            func = func.with_call\n        except AttributeError as exc:\n            raise ValueError(\n                \"with_call=True is only supported for unary calls.\"\n            ) from exc\n    func = grpc_helpers.wrap_errors(func)\n    if client_info is not None:\n        user_agent_metadata = [client_info.to_grpc_metadata()]\n    else:\n        user_agent_metadata = None\n\n    return functools.wraps(func)(\n        _GapicCallable(\n            func,\n            default_retry,\n            default_timeout,\n            default_compression,\n            metadata=user_agent_metadata,\n        )\n    )\n", "google/api_core/gapic_v1/routing_header.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Helpers for constructing routing headers.\n\nThese headers are used by Google infrastructure to determine how to route\nrequests, especially for services that are regional.\n\nGenerally, these headers are specified as gRPC metadata.\n\"\"\"\n\nimport functools\nfrom enum import Enum\nfrom urllib.parse import urlencode\n\nROUTING_METADATA_KEY = \"x-goog-request-params\"\n# This is the value for the `maxsize` argument of @functools.lru_cache\n# https://docs.python.org/3/library/functools.html#functools.lru_cache\n# This represents the number of recent function calls to store.\nROUTING_PARAM_CACHE_SIZE = 32\n\n\ndef to_routing_header(params, qualified_enums=True):\n    \"\"\"Returns a routing header string for the given request parameters.\n\n    Args:\n        params (Mapping[str, str | bytes | Enum]): A dictionary containing the request\n            parameters used for routing.\n        qualified_enums (bool): Whether to represent enum values\n            as their type-qualified symbol names instead of as their\n            unqualified symbol names.\n\n    Returns:\n        str: The routing header string.\n    \"\"\"\n    tuples = params.items() if isinstance(params, dict) else params\n    if not qualified_enums:\n        tuples = [(x[0], x[1].name) if isinstance(x[1], Enum) else x for x in tuples]\n    return \"&\".join([_urlencode_param(*t) for t in tuples])\n\n\ndef to_grpc_metadata(params, qualified_enums=True):\n    \"\"\"Returns the gRPC metadata containing the routing headers for the given\n    request parameters.\n\n    Args:\n        params (Mapping[str, str | bytes | Enum]): A dictionary containing the request\n            parameters used for routing.\n        qualified_enums (bool): Whether to represent enum values\n            as their type-qualified symbol names instead of as their\n            unqualified symbol names.\n\n    Returns:\n        Tuple(str, str): The gRPC metadata containing the routing header key\n            and value.\n    \"\"\"\n    return (ROUTING_METADATA_KEY, to_routing_header(params, qualified_enums))\n\n\n# use caching to avoid repeated computation\n@functools.lru_cache(maxsize=ROUTING_PARAM_CACHE_SIZE)\ndef _urlencode_param(key, value):\n    \"\"\"Cacheable wrapper over urlencode\n\n    Args:\n        key (str): The key of the parameter to encode.\n        value (str | bytes | Enum): The value of the parameter to encode.\n\n    Returns:\n        str: The encoded parameter.\n    \"\"\"\n    return urlencode(\n        {key: value},\n        # Per Google API policy (go/api-url-encoding), / is not encoded.\n        safe=\"/\",\n    )\n", "google/api_core/gapic_v1/config_async.py": "# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\"AsyncIO helpers for loading gapic configuration data.\n\nThe Google API generator creates supplementary configuration for each RPC\nmethod to tell the client library how to deal with retries and timeouts.\n\"\"\"\n\nfrom google.api_core import retry_async\nfrom google.api_core.gapic_v1 import config\nfrom google.api_core.gapic_v1.config import MethodConfig  # noqa: F401\n\n\ndef parse_method_configs(interface_config):\n    \"\"\"Creates default retry and timeout objects for each method in a gapic\n    interface config with AsyncIO semantics.\n\n    Args:\n        interface_config (Mapping): The interface config section of the full\n            gapic library config. For example, If the full configuration has\n            an interface named ``google.example.v1.ExampleService`` you would\n            pass in just that interface's configuration, for example\n            ``gapic_config['interfaces']['google.example.v1.ExampleService']``.\n\n    Returns:\n        Mapping[str, MethodConfig]: A mapping of RPC method names to their\n            configuration.\n    \"\"\"\n    return config.parse_method_configs(\n        interface_config, retry_impl=retry_async.AsyncRetry\n    )\n", "google/api_core/gapic_v1/__init__.py": "# Copyright 2017 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom google.api_core.gapic_v1 import client_info\nfrom google.api_core.gapic_v1 import config\nfrom google.api_core.gapic_v1 import config_async\nfrom google.api_core.gapic_v1 import method\nfrom google.api_core.gapic_v1 import method_async\nfrom google.api_core.gapic_v1 import routing_header\n\n__all__ = [\n    \"client_info\",\n    \"config\",\n    \"config_async\",\n    \"method\",\n    \"method_async\",\n    \"routing_header\",\n]\n", "google/api_core/future/polling.py": "# Copyright 2017, Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Abstract and helper bases for Future implementations.\"\"\"\n\nimport abc\nimport concurrent.futures\n\nfrom google.api_core import exceptions\nfrom google.api_core import retry as retries\nfrom google.api_core.future import _helpers\nfrom google.api_core.future import base\n\n\nclass _OperationNotComplete(Exception):\n    \"\"\"Private exception used for polling via retry.\"\"\"\n\n    pass\n\n\n# DEPRECATED as it conflates RPC retry and polling concepts into one.\n# Use POLLING_PREDICATE instead to configure polling.\nRETRY_PREDICATE = retries.if_exception_type(\n    _OperationNotComplete,\n    exceptions.TooManyRequests,\n    exceptions.InternalServerError,\n    exceptions.BadGateway,\n    exceptions.ServiceUnavailable,\n)\n\n# DEPRECATED: use DEFAULT_POLLING to configure LRO polling logic. Construct\n# Retry object using its default values as a baseline for any custom retry logic\n# (not to be confused with polling logic).\nDEFAULT_RETRY = retries.Retry(predicate=RETRY_PREDICATE)\n\n# POLLING_PREDICATE is supposed to poll only on _OperationNotComplete.\n# Any RPC-specific errors (like ServiceUnavailable) will be handled\n# by retry logic (not to be confused with polling logic) which is triggered for\n# every polling RPC independently of polling logic but within its context.\nPOLLING_PREDICATE = retries.if_exception_type(\n    _OperationNotComplete,\n)\n\n# Default polling configuration\nDEFAULT_POLLING = retries.Retry(\n    predicate=POLLING_PREDICATE,\n    initial=1.0,  # seconds\n    maximum=20.0,  # seconds\n    multiplier=1.5,\n    timeout=900,  # seconds\n)\n\n\nclass PollingFuture(base.Future):\n    \"\"\"A Future that needs to poll some service to check its status.\n\n    The :meth:`done` method should be implemented by subclasses. The polling\n    behavior will repeatedly call ``done`` until it returns True.\n\n    The actual polling logic is encapsulated in :meth:`result` method. See\n    documentation for that method for details on how polling works.\n\n    .. note::\n\n        Privacy here is intended to prevent the final class from\n        overexposing, not to prevent subclasses from accessing methods.\n\n    Args:\n        polling (google.api_core.retry.Retry): The configuration used for polling.\n            This parameter controls how often :meth:`done` is polled. If the\n            ``timeout`` argument is specified in :meth:`result` method it will\n            override the ``polling.timeout`` property.\n        retry (google.api_core.retry.Retry): DEPRECATED use ``polling`` instead.\n            If set, it will override ``polling`` parameter for backward\n            compatibility.\n    \"\"\"\n\n    _DEFAULT_VALUE = object()\n\n    def __init__(self, polling=DEFAULT_POLLING, **kwargs):\n        super(PollingFuture, self).__init__()\n        self._polling = kwargs.get(\"retry\", polling)\n        self._result = None\n        self._exception = None\n        self._result_set = False\n        \"\"\"bool: Set to True when the result has been set via set_result or\n        set_exception.\"\"\"\n        self._polling_thread = None\n        self._done_callbacks = []\n\n    @abc.abstractmethod\n    def done(self, retry=None):\n        \"\"\"Checks to see if the operation is complete.\n\n        Args:\n            retry (google.api_core.retry.Retry): (Optional) How to retry the\n                polling RPC (to not be confused with polling configuration. See\n                the documentation for :meth:`result` for details).\n\n        Returns:\n            bool: True if the operation is complete, False otherwise.\n        \"\"\"\n        # pylint: disable=redundant-returns-doc, missing-raises-doc\n        raise NotImplementedError()\n\n    def _done_or_raise(self, retry=None):\n        \"\"\"Check if the future is done and raise if it's not.\"\"\"\n        if not self.done(retry=retry):\n            raise _OperationNotComplete()\n\n    def running(self):\n        \"\"\"True if the operation is currently running.\"\"\"\n        return not self.done()\n\n    def _blocking_poll(self, timeout=_DEFAULT_VALUE, retry=None, polling=None):\n        \"\"\"Poll and wait for the Future to be resolved.\"\"\"\n\n        if self._result_set:\n            return\n\n        polling = polling or self._polling\n        if timeout is not PollingFuture._DEFAULT_VALUE:\n            polling = polling.with_timeout(timeout)\n\n        try:\n            polling(self._done_or_raise)(retry=retry)\n        except exceptions.RetryError:\n            raise concurrent.futures.TimeoutError(\n                f\"Operation did not complete within the designated timeout of \"\n                f\"{polling.timeout} seconds.\"\n            )\n\n    def result(self, timeout=_DEFAULT_VALUE, retry=None, polling=None):\n        \"\"\"Get the result of the operation.\n\n        This method will poll for operation status periodically, blocking if\n        necessary. If you just want to make sure that this method does not block\n        for more than X seconds and you do not care about the nitty-gritty of\n        how this method operates, just call it with ``result(timeout=X)``. The\n        other parameters are for advanced use only.\n\n        Every call to this method is controlled by the following three\n        parameters, each of which has a specific, distinct role, even though all three\n        may look very similar: ``timeout``, ``retry`` and ``polling``. In most\n        cases users do not need to specify any custom values for any of these\n        parameters and may simply rely on default ones instead.\n\n        If you choose to specify custom parameters, please make sure you've\n        read the documentation below carefully.\n\n        First, please check :class:`google.api_core.retry.Retry`\n        class documentation for the proper definition of timeout and deadline\n        terms and for the definition the three different types of timeouts.\n        This class operates in terms of Retry Timeout and Polling Timeout. It\n        does not let customizing RPC timeout and the user is expected to rely on\n        default behavior for it.\n\n        The roles of each argument of this method are as follows:\n\n        ``timeout`` (int): (Optional) The Polling Timeout as defined in\n        :class:`google.api_core.retry.Retry`. If the operation does not complete\n        within this timeout an exception will be thrown. This parameter affects\n        neither Retry Timeout nor RPC Timeout.\n\n        ``retry`` (google.api_core.retry.Retry): (Optional) How to retry the\n        polling RPC. The ``retry.timeout`` property of this parameter is the\n        Retry Timeout as defined in :class:`google.api_core.retry.Retry`.\n        This parameter defines ONLY how the polling RPC call is retried\n        (i.e. what to do if the RPC we used for polling returned an error). It\n        does NOT define how the polling is done (i.e. how frequently and for\n        how long to call the polling RPC); use the ``polling`` parameter for that.\n        If a polling RPC throws and error and retrying it fails, the whole\n        future fails with the corresponding exception. If you want to tune which\n        server response error codes are not fatal for operation polling, use this\n        parameter to control that (``retry.predicate`` in particular).\n\n        ``polling`` (google.api_core.retry.Retry): (Optional) How often and\n        for how long to call the polling RPC periodically (i.e. what to do if\n        a polling rpc returned successfully but its returned result indicates\n        that the long running operation is not completed yet, so we need to\n        check it again at some point in future). This parameter does NOT define\n        how to retry each individual polling RPC in case of an error; use the\n        ``retry`` parameter for that. The ``polling.timeout`` of this parameter\n        is Polling Timeout as defined in as defined in\n        :class:`google.api_core.retry.Retry`.\n\n        For each of the arguments, there are also default values in place, which\n        will be used if a user does not specify their own. The default values\n        for the three parameters are not to be confused with the default values\n        for the corresponding arguments in this method (those serve as \"not set\"\n        markers for the resolution logic).\n\n        If ``timeout`` is provided (i.e.``timeout is not _DEFAULT VALUE``; note\n        the ``None`` value means \"infinite timeout\"), it will be used to control\n        the actual Polling Timeout. Otherwise, the ``polling.timeout`` value\n        will be used instead (see below for how the ``polling`` config itself\n        gets resolved). In other words, this parameter  effectively overrides\n        the ``polling.timeout`` value if specified. This is so to preserve\n        backward compatibility.\n\n        If ``retry`` is provided (i.e. ``retry is not None``) it will be used to\n        control retry behavior for the polling RPC and the ``retry.timeout``\n        will determine the Retry Timeout. If not provided, the\n        polling RPC will be called with whichever default retry config was\n        specified for the polling RPC at the moment of the construction of the\n        polling RPC's client. For example, if the polling RPC is\n        ``operations_client.get_operation()``, the ``retry`` parameter will be\n        controlling its retry behavior (not polling  behavior) and, if not\n        specified, that specific method (``operations_client.get_operation()``)\n        will be retried according to the default retry config provided during\n        creation of ``operations_client`` client instead. This argument exists\n        mainly for backward compatibility; users are very unlikely to ever need\n        to set this parameter explicitly.\n\n        If ``polling`` is provided (i.e. ``polling is not None``), it will be used\n        to control the overall polling behavior and ``polling.timeout`` will\n        control Polling Timeout unless it is overridden by ``timeout`` parameter\n        as described above. If not provided, the``polling`` parameter specified\n        during construction of this future (the ``polling`` argument in the\n        constructor) will be used instead. Note: since the ``timeout`` argument may\n        override ``polling.timeout`` value, this parameter should be viewed as\n        coupled with the ``timeout`` parameter as described above.\n\n        Args:\n            timeout (int): (Optional) How long (in seconds) to wait for the\n                operation to complete. If None, wait indefinitely.\n            retry (google.api_core.retry.Retry): (Optional) How to retry the\n                polling RPC. This defines ONLY how the polling RPC call is\n                retried (i.e. what to do if the RPC we used for polling returned\n                an error). It does  NOT define how the polling is done (i.e. how\n                frequently and for how long to call the polling RPC).\n            polling (google.api_core.retry.Retry): (Optional) How often and\n                for how long to call polling RPC periodically. This parameter\n                does NOT define how to retry each individual polling RPC call\n                (use the ``retry`` parameter for that).\n\n        Returns:\n            google.protobuf.Message: The Operation's result.\n\n        Raises:\n            google.api_core.GoogleAPICallError: If the operation errors or if\n                the timeout is reached before the operation completes.\n        \"\"\"\n\n        self._blocking_poll(timeout=timeout, retry=retry, polling=polling)\n\n        if self._exception is not None:\n            # pylint: disable=raising-bad-type\n            # Pylint doesn't recognize that this is valid in this case.\n            raise self._exception\n\n        return self._result\n\n    def exception(self, timeout=_DEFAULT_VALUE):\n        \"\"\"Get the exception from the operation, blocking if necessary.\n\n        See the documentation for the :meth:`result` method for details on how\n        this method operates, as both ``result`` and this method rely on the\n        exact same polling logic. The only difference is that this method does\n        not accept ``retry`` and ``polling`` arguments but relies on the default ones\n        instead.\n\n        Args:\n            timeout (int): How long to wait for the operation to complete.\n            If None, wait indefinitely.\n\n        Returns:\n            Optional[google.api_core.GoogleAPICallError]: The operation's\n                error.\n        \"\"\"\n        self._blocking_poll(timeout=timeout)\n        return self._exception\n\n    def add_done_callback(self, fn):\n        \"\"\"Add a callback to be executed when the operation is complete.\n\n        If the operation is not already complete, this will start a helper\n        thread to poll for the status of the operation in the background.\n\n        Args:\n            fn (Callable[Future]): The callback to execute when the operation\n                is complete.\n        \"\"\"\n        if self._result_set:\n            _helpers.safe_invoke_callback(fn, self)\n            return\n\n        self._done_callbacks.append(fn)\n\n        if self._polling_thread is None:\n            # The polling thread will exit on its own as soon as the operation\n            # is done.\n            self._polling_thread = _helpers.start_daemon_thread(\n                target=self._blocking_poll\n            )\n\n    def _invoke_callbacks(self, *args, **kwargs):\n        \"\"\"Invoke all done callbacks.\"\"\"\n        for callback in self._done_callbacks:\n            _helpers.safe_invoke_callback(callback, *args, **kwargs)\n\n    def set_result(self, result):\n        \"\"\"Set the Future's result.\"\"\"\n        self._result = result\n        self._result_set = True\n        self._invoke_callbacks(self)\n\n    def set_exception(self, exception):\n        \"\"\"Set the Future's exception.\"\"\"\n        self._exception = exception\n        self._result_set = True\n        self._invoke_callbacks(self)\n", "google/api_core/future/base.py": "# Copyright 2017, Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Abstract and helper bases for Future implementations.\"\"\"\n\nimport abc\n\n\nclass Future(object, metaclass=abc.ABCMeta):\n    # pylint: disable=missing-docstring\n    # We inherit the interfaces here from concurrent.futures.\n\n    \"\"\"Future interface.\n\n    This interface is based on :class:`concurrent.futures.Future`.\n    \"\"\"\n\n    @abc.abstractmethod\n    def cancel(self):\n        raise NotImplementedError()\n\n    @abc.abstractmethod\n    def cancelled(self):\n        raise NotImplementedError()\n\n    @abc.abstractmethod\n    def running(self):\n        raise NotImplementedError()\n\n    @abc.abstractmethod\n    def done(self):\n        raise NotImplementedError()\n\n    @abc.abstractmethod\n    def result(self, timeout=None):\n        raise NotImplementedError()\n\n    @abc.abstractmethod\n    def exception(self, timeout=None):\n        raise NotImplementedError()\n\n    @abc.abstractmethod\n    def add_done_callback(self, fn):\n        # pylint: disable=invalid-name\n        raise NotImplementedError()\n\n    @abc.abstractmethod\n    def set_result(self, result):\n        raise NotImplementedError()\n\n    @abc.abstractmethod\n    def set_exception(self, exception):\n        raise NotImplementedError()\n", "google/api_core/future/async_future.py": "# Copyright 2020, Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"AsyncIO implementation of the abstract base Future class.\"\"\"\n\nimport asyncio\n\nfrom google.api_core import exceptions\nfrom google.api_core import retry\nfrom google.api_core import retry_async\nfrom google.api_core.future import base\n\n\nclass _OperationNotComplete(Exception):\n    \"\"\"Private exception used for polling via retry.\"\"\"\n\n    pass\n\n\nRETRY_PREDICATE = retry.if_exception_type(\n    _OperationNotComplete,\n    exceptions.TooManyRequests,\n    exceptions.InternalServerError,\n    exceptions.BadGateway,\n)\nDEFAULT_RETRY = retry_async.AsyncRetry(predicate=RETRY_PREDICATE)\n\n\nclass AsyncFuture(base.Future):\n    \"\"\"A Future that polls peer service to self-update.\n\n    The :meth:`done` method should be implemented by subclasses. The polling\n    behavior will repeatedly call ``done`` until it returns True.\n\n    .. note::\n\n        Privacy here is intended to prevent the final class from\n        overexposing, not to prevent subclasses from accessing methods.\n\n    Args:\n        retry (google.api_core.retry.Retry): The retry configuration used\n            when polling. This can be used to control how often :meth:`done`\n            is polled. Regardless of the retry's ``deadline``, it will be\n            overridden by the ``timeout`` argument to :meth:`result`.\n    \"\"\"\n\n    def __init__(self, retry=DEFAULT_RETRY):\n        super().__init__()\n        self._retry = retry\n        self._future = asyncio.get_event_loop().create_future()\n        self._background_task = None\n\n    async def done(self, retry=DEFAULT_RETRY):\n        \"\"\"Checks to see if the operation is complete.\n\n        Args:\n            retry (google.api_core.retry.Retry): (Optional) How to retry the RPC.\n\n        Returns:\n            bool: True if the operation is complete, False otherwise.\n        \"\"\"\n        # pylint: disable=redundant-returns-doc, missing-raises-doc\n        raise NotImplementedError()\n\n    async def _done_or_raise(self):\n        \"\"\"Check if the future is done and raise if it's not.\"\"\"\n        result = await self.done()\n        if not result:\n            raise _OperationNotComplete()\n\n    async def running(self):\n        \"\"\"True if the operation is currently running.\"\"\"\n        result = await self.done()\n        return not result\n\n    async def _blocking_poll(self, timeout=None):\n        \"\"\"Poll and await for the Future to be resolved.\n\n        Args:\n            timeout (int):\n                How long (in seconds) to wait for the operation to complete.\n                If None, wait indefinitely.\n        \"\"\"\n        if self._future.done():\n            return\n\n        retry_ = self._retry.with_timeout(timeout)\n\n        try:\n            await retry_(self._done_or_raise)()\n        except exceptions.RetryError:\n            raise asyncio.TimeoutError(\n                \"Operation did not complete within the designated \" \"timeout.\"\n            )\n\n    async def result(self, timeout=None):\n        \"\"\"Get the result of the operation.\n\n        Args:\n            timeout (int):\n                How long (in seconds) to wait for the operation to complete.\n                If None, wait indefinitely.\n\n        Returns:\n            google.protobuf.Message: The Operation's result.\n\n        Raises:\n            google.api_core.GoogleAPICallError: If the operation errors or if\n                the timeout is reached before the operation completes.\n        \"\"\"\n        await self._blocking_poll(timeout=timeout)\n        return self._future.result()\n\n    async def exception(self, timeout=None):\n        \"\"\"Get the exception from the operation.\n\n        Args:\n            timeout (int): How long to wait for the operation to complete.\n                If None, wait indefinitely.\n\n        Returns:\n            Optional[google.api_core.GoogleAPICallError]: The operation's\n                error.\n        \"\"\"\n        await self._blocking_poll(timeout=timeout)\n        return self._future.exception()\n\n    def add_done_callback(self, fn):\n        \"\"\"Add a callback to be executed when the operation is complete.\n\n        If the operation is completed, the callback will be scheduled onto the\n        event loop. Otherwise, the callback will be stored and invoked when the\n        future is done.\n\n        Args:\n            fn (Callable[Future]): The callback to execute when the operation\n                is complete.\n        \"\"\"\n        if self._background_task is None:\n            self._background_task = asyncio.get_event_loop().create_task(\n                self._blocking_poll()\n            )\n        self._future.add_done_callback(fn)\n\n    def set_result(self, result):\n        \"\"\"Set the Future's result.\"\"\"\n        self._future.set_result(result)\n\n    def set_exception(self, exception):\n        \"\"\"Set the Future's exception.\"\"\"\n        self._future.set_exception(exception)\n", "google/api_core/future/__init__.py": "# Copyright 2017, Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Futures for dealing with asynchronous operations.\"\"\"\n\nfrom google.api_core.future.base import Future\n\n__all__ = [\"Future\"]\n", "google/api_core/future/_helpers.py": "# Copyright 2017, Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Private helpers for futures.\"\"\"\n\nimport logging\nimport threading\n\n\n_LOGGER = logging.getLogger(__name__)\n\n\ndef start_daemon_thread(*args, **kwargs):\n    \"\"\"Starts a thread and marks it as a daemon thread.\"\"\"\n    thread = threading.Thread(*args, **kwargs)\n    thread.daemon = True\n    thread.start()\n    return thread\n\n\ndef safe_invoke_callback(callback, *args, **kwargs):\n    \"\"\"Invoke a callback, swallowing and logging any exceptions.\"\"\"\n    # pylint: disable=bare-except\n    # We intentionally want to swallow all exceptions.\n    try:\n        return callback(*args, **kwargs)\n    except Exception:\n        _LOGGER.exception(\"Error while executing Future callback.\")\n"}