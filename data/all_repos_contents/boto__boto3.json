{"setup.py": "#!/usr/bin/env python\n\n\"\"\"\ndistutils/setuptools install script.\n\"\"\"\n\nimport os\nimport re\n\nfrom setuptools import find_packages, setup\n\nROOT = os.path.dirname(__file__)\nVERSION_RE = re.compile(r'''__version__ = ['\"]([0-9.]+)['\"]''')\n\n\nrequires = [\n    'botocore>=1.34.132,<1.35.0',\n    'jmespath>=0.7.1,<2.0.0',\n    's3transfer>=0.10.0,<0.11.0',\n]\n\n\ndef get_version():\n    init = open(os.path.join(ROOT, 'boto3', '__init__.py')).read()\n    return VERSION_RE.search(init).group(1)\n\n\nsetup(\n    name='boto3',\n    version=get_version(),\n    description='The AWS SDK for Python',\n    long_description=open('README.rst').read(),\n    author='Amazon Web Services',\n    url='https://github.com/boto/boto3',\n    scripts=[],\n    packages=find_packages(exclude=['tests*']),\n    package_data={'boto3': ['data/aws/resources/*.json', 'examples/*.rst']},\n    include_package_data=True,\n    install_requires=requires,\n    license=\"Apache License 2.0\",\n    python_requires=\">= 3.8\",\n    classifiers=[\n        'Development Status :: 5 - Production/Stable',\n        'Intended Audience :: Developers',\n        'Natural Language :: English',\n        'License :: OSI Approved :: Apache Software License',\n        'Programming Language :: Python',\n        'Programming Language :: Python :: 3',\n        'Programming Language :: Python :: 3 :: Only',\n        'Programming Language :: Python :: 3.8',\n        'Programming Language :: Python :: 3.9',\n        'Programming Language :: Python :: 3.10',\n        'Programming Language :: Python :: 3.11',\n        'Programming Language :: Python :: 3.12',\n    ],\n    project_urls={\n        'Documentation': 'https://boto3.amazonaws.com/v1/documentation/api/latest/index.html',\n        'Source': 'https://github.com/boto/boto3',\n    },\n)\n", "boto3/exceptions.py": "# Copyright 2014 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n\n# All exceptions in this class should subclass from Boto3Error.\nimport botocore.exceptions\n\n\n# All exceptions should subclass from Boto3Error in this module.\nclass Boto3Error(Exception):\n    \"\"\"Base class for all Boto3 errors.\"\"\"\n\n\nclass ResourceLoadException(Boto3Error):\n    pass\n\n\n# NOTE: This doesn't appear to be used anywhere.\n# It's probably safe to remove this.\nclass NoVersionFound(Boto3Error):\n    pass\n\n\n# We're subclassing from botocore.exceptions.DataNotFoundError\n# to keep backwards compatibility with anyone that was catching\n# this low level Botocore error before this exception was\n# introduced in boto3.\n# Same thing for ResourceNotExistsError below.\nclass UnknownAPIVersionError(\n    Boto3Error, botocore.exceptions.DataNotFoundError\n):\n    def __init__(self, service_name, bad_api_version, available_api_versions):\n        msg = (\n            f\"The '{service_name}' resource does not support an API version of: {bad_api_version}\\n\"\n            f\"Valid API versions are: {available_api_versions}\"\n        )\n        # Not using super because we don't want the DataNotFoundError\n        # to be called, it has a different __init__ signature.\n        Boto3Error.__init__(self, msg)\n\n\nclass ResourceNotExistsError(\n    Boto3Error, botocore.exceptions.DataNotFoundError\n):\n    \"\"\"Raised when you attempt to create a resource that does not exist.\"\"\"\n\n    def __init__(self, service_name, available_services, has_low_level_client):\n        msg = (\n            \"The '{}' resource does not exist.\\n\"\n            \"The available resources are:\\n\"\n            \"   - {}\\n\".format(\n                service_name, '\\n   - '.join(available_services)\n            )\n        )\n        if has_low_level_client:\n            msg = (\n                f\"{msg}\\nConsider using a boto3.client('{service_name}') \"\n                f\"instead of a resource for '{service_name}'\"\n            )\n        # Not using super because we don't want the DataNotFoundError\n        # to be called, it has a different __init__ signature.\n        Boto3Error.__init__(self, msg)\n\n\nclass RetriesExceededError(Boto3Error):\n    def __init__(self, last_exception, msg='Max Retries Exceeded'):\n        super().__init__(msg)\n        self.last_exception = last_exception\n\n\nclass S3TransferFailedError(Boto3Error):\n    pass\n\n\nclass S3UploadFailedError(Boto3Error):\n    pass\n\n\nclass DynamoDBOperationNotSupportedError(Boto3Error):\n    \"\"\"Raised for operations that are not supported for an operand.\"\"\"\n\n    def __init__(self, operation, value):\n        msg = (\n            f'{operation} operation cannot be applied to value {value} of type '\n            f'{type(value)} directly. Must use AttributeBase object methods '\n            f'(i.e. Attr().eq()). to generate ConditionBase instances first.'\n        )\n        Exception.__init__(self, msg)\n\n\n# FIXME: Backward compatibility\nDynanmoDBOperationNotSupportedError = DynamoDBOperationNotSupportedError\n\n\nclass DynamoDBNeedsConditionError(Boto3Error):\n    \"\"\"Raised when input is not a condition\"\"\"\n\n    def __init__(self, value):\n        msg = (\n            f'Expecting a ConditionBase object. Got {value} of type {type(value)}. '\n            f'Use AttributeBase object methods (i.e. Attr().eq()). to '\n            f'generate ConditionBase instances.'\n        )\n        Exception.__init__(self, msg)\n\n\nclass DynamoDBNeedsKeyConditionError(Boto3Error):\n    pass\n\n\nclass PythonDeprecationWarning(Warning):\n    \"\"\"\n    Python version being used is scheduled to become unsupported\n    in an future release. See warning for specifics.\n    \"\"\"\n\n    pass\n", "boto3/utils.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport sys\nfrom collections import namedtuple\n\n_ServiceContext = namedtuple(\n    'ServiceContext',\n    [\n        'service_name',\n        'service_model',\n        'service_waiter_model',\n        'resource_json_definitions',\n    ],\n)\n\n\nclass ServiceContext(_ServiceContext):\n    \"\"\"Provides important service-wide, read-only information about a service\n\n    :type service_name: str\n    :param service_name: The name of the service\n\n    :type service_model: :py:class:`botocore.model.ServiceModel`\n    :param service_model: The model of the service.\n\n    :type service_waiter_model: :py:class:`botocore.waiter.WaiterModel` or\n        a waiter model-like object such as\n        :py:class:`boto3.utils.LazyLoadedWaiterModel`\n    :param service_waiter_model: The waiter model of the service.\n\n    :type resource_json_definitions: dict\n    :param resource_json_definitions: The loaded json models of all resource\n        shapes for a service. It is equivalient of loading a\n        ``resource-1.json`` and retrieving the value at the key \"resources\".\n    \"\"\"\n\n    pass\n\n\ndef import_module(name):\n    \"\"\"Import module given a name.\n\n    Does not support relative imports.\n\n    \"\"\"\n    __import__(name)\n    return sys.modules[name]\n\n\ndef lazy_call(full_name, **kwargs):\n    parent_kwargs = kwargs\n\n    def _handler(**kwargs):\n        module, function_name = full_name.rsplit('.', 1)\n        module = import_module(module)\n        kwargs.update(parent_kwargs)\n        return getattr(module, function_name)(**kwargs)\n\n    return _handler\n\n\ndef inject_attribute(class_attributes, name, value):\n    if name in class_attributes:\n        raise RuntimeError(\n            f'Cannot inject class attribute \"{name}\", attribute '\n            f'already exists in class dict.'\n        )\n    else:\n        class_attributes[name] = value\n\n\nclass LazyLoadedWaiterModel:\n    \"\"\"A lazily loaded waiter model\n\n    This does not load the service waiter model until an attempt is made\n    to retrieve the waiter model for a specific waiter. This is helpful\n    in docstring generation where we do not need to actually need to grab\n    the waiter-2.json until it is accessed through a ``get_waiter`` call\n    when the docstring is generated/accessed.\n    \"\"\"\n\n    def __init__(self, bc_session, service_name, api_version):\n        self._session = bc_session\n        self._service_name = service_name\n        self._api_version = api_version\n\n    def get_waiter(self, waiter_name):\n        return self._session.get_waiter_model(\n            self._service_name, self._api_version\n        ).get_waiter(waiter_name)\n", "boto3/__init__.py": "# Copyright 2014 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n\nimport logging\n\nfrom boto3.compat import _warn_deprecated_python\nfrom boto3.session import Session\n\n__author__ = 'Amazon Web Services'\n__version__ = '1.34.132'\n\n\n# The default Boto3 session; autoloaded when needed.\nDEFAULT_SESSION = None\n\n\ndef setup_default_session(**kwargs):\n    \"\"\"\n    Set up a default session, passing through any parameters to the session\n    constructor. There is no need to call this unless you wish to pass custom\n    parameters, because a default session will be created for you.\n    \"\"\"\n    global DEFAULT_SESSION\n    DEFAULT_SESSION = Session(**kwargs)\n\n\ndef set_stream_logger(name='boto3', level=logging.DEBUG, format_string=None):\n    \"\"\"\n    Add a stream handler for the given name and level to the logging module.\n    By default, this logs all boto3 messages to ``stdout``.\n\n        >>> import boto3\n        >>> boto3.set_stream_logger('boto3.resources', logging.INFO)\n\n    For debugging purposes a good choice is to set the stream logger to ``''``\n    which is equivalent to saying \"log everything\".\n\n    .. WARNING::\n       Be aware that when logging anything from ``'botocore'`` the full wire\n       trace will appear in your logs. If your payloads contain sensitive data\n       this should not be used in production.\n\n    :type name: string\n    :param name: Log name\n    :type level: int\n    :param level: Logging level, e.g. ``logging.INFO``\n    :type format_string: str\n    :param format_string: Log message format\n    \"\"\"\n    if format_string is None:\n        format_string = \"%(asctime)s %(name)s [%(levelname)s] %(message)s\"\n\n    logger = logging.getLogger(name)\n    logger.setLevel(level)\n    handler = logging.StreamHandler()\n    handler.setLevel(level)\n    formatter = logging.Formatter(format_string)\n    handler.setFormatter(formatter)\n    logger.addHandler(handler)\n\n\ndef _get_default_session():\n    \"\"\"\n    Get the default session, creating one if needed.\n\n    :rtype: :py:class:`~boto3.session.Session`\n    :return: The default session\n    \"\"\"\n    if DEFAULT_SESSION is None:\n        setup_default_session()\n    _warn_deprecated_python()\n\n    return DEFAULT_SESSION\n\n\ndef client(*args, **kwargs):\n    \"\"\"\n    Create a low-level service client by name using the default session.\n\n    See :py:meth:`boto3.session.Session.client`.\n    \"\"\"\n    return _get_default_session().client(*args, **kwargs)\n\n\ndef resource(*args, **kwargs):\n    \"\"\"\n    Create a resource service client by name using the default session.\n\n    See :py:meth:`boto3.session.Session.resource`.\n    \"\"\"\n    return _get_default_session().resource(*args, **kwargs)\n\n\n# Set up logging to ``/dev/null`` like a library is supposed to.\n# https://docs.python.org/3.3/howto/logging.html#configuring-logging-for-a-library\nclass NullHandler(logging.Handler):\n    def emit(self, record):\n        pass\n\n\nlogging.getLogger('boto3').addHandler(NullHandler())\n", "boto3/compat.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport sys\nimport os\nimport errno\nimport socket\nimport warnings\n\nfrom boto3.exceptions import PythonDeprecationWarning\n\n# In python3, socket.error is OSError, which is too general\n# for what we want (i.e FileNotFoundError is a subclass of OSError).\n# In py3 all the socket related errors are in a newly created\n# ConnectionError\nSOCKET_ERROR = ConnectionError\n\nimport collections.abc as collections_abc\n\n\nif sys.platform.startswith('win'):\n    def rename_file(current_filename, new_filename):\n        try:\n            os.remove(new_filename)\n        except OSError as e:\n            if not e.errno == errno.ENOENT:\n                # We only want to a ignore trying to remove\n                # a file that does not exist.  If it fails\n                # for any other reason we should be propagating\n                # that exception.\n                raise\n        os.rename(current_filename, new_filename)\nelse:\n    rename_file = os.rename\n\n\ndef filter_python_deprecation_warnings():\n    \"\"\"\n    Invoking this filter acknowledges your runtime will soon be deprecated\n    at which time you will stop receiving all updates to your client.\n    \"\"\"\n    warnings.filterwarnings(\n        'ignore',\n        message=\".*Boto3 will no longer support Python.*\",\n        category=PythonDeprecationWarning,\n        module=r\".*boto3\\.compat\"\n    )\n\n\ndef _warn_deprecated_python():\n    \"\"\"Use this template for future deprecation campaigns as needed.\"\"\"\n    py_37_params = {\n        'date': 'December 13, 2023',\n        'blog_link': (\n            'https://aws.amazon.com/blogs/developer/'\n            'python-support-policy-updates-for-aws-sdks-and-tools/'\n        )\n    }\n    deprecated_versions = {\n        # Example template for future deprecations\n        (3, 7): py_37_params,\n    }\n    py_version = sys.version_info[:2]\n\n    if py_version in deprecated_versions:\n        params = deprecated_versions[py_version]\n        warning = (\n            \"Boto3 will no longer support Python {}.{} \"\n            \"starting {}. To continue receiving service updates, \"\n            \"bug fixes, and security updates please upgrade to Python 3.8 or \"\n            \"later. More information can be found here: {}\"\n        ).format(py_version[0], py_version[1], params['date'], params['blog_link'])\n        warnings.warn(warning, PythonDeprecationWarning)\n", "boto3/crt.py": "# Copyright 2023 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n\"\"\"\nThis file contains private functionality for interacting with the AWS\nCommon Runtime library (awscrt) in boto3.\n\nAll code contained within this file is for internal usage within this\nproject and is not intended for external consumption. All interfaces\ncontained within are subject to abrupt breaking changes.\n\"\"\"\n\nimport threading\n\nimport botocore.exceptions\nfrom botocore.session import Session\nfrom s3transfer.crt import (\n    BotocoreCRTCredentialsWrapper,\n    BotocoreCRTRequestSerializer,\n    CRTTransferManager,\n    acquire_crt_s3_process_lock,\n    create_s3_crt_client,\n)\n\n# Singletons for CRT-backed transfers\nCRT_S3_CLIENT = None\nBOTOCORE_CRT_SERIALIZER = None\n\nCLIENT_CREATION_LOCK = threading.Lock()\nPROCESS_LOCK_NAME = 'boto3'\n\n\ndef _create_crt_client(session, config, region_name, cred_provider):\n    \"\"\"Create a CRT S3 Client for file transfer.\n\n    Instantiating many of these may lead to degraded performance or\n    system resource exhaustion.\n    \"\"\"\n    create_crt_client_kwargs = {\n        'region': region_name,\n        'use_ssl': True,\n        'crt_credentials_provider': cred_provider,\n    }\n    return create_s3_crt_client(**create_crt_client_kwargs)\n\n\ndef _create_crt_request_serializer(session, region_name):\n    return BotocoreCRTRequestSerializer(\n        session, {'region_name': region_name, 'endpoint_url': None}\n    )\n\n\ndef _create_crt_s3_client(\n    session, config, region_name, credentials, lock, **kwargs\n):\n    \"\"\"Create boto3 wrapper class to manage crt lock reference and S3 client.\"\"\"\n    cred_wrapper = BotocoreCRTCredentialsWrapper(credentials)\n    cred_provider = cred_wrapper.to_crt_credentials_provider()\n    return CRTS3Client(\n        _create_crt_client(session, config, region_name, cred_provider),\n        lock,\n        region_name,\n        cred_wrapper,\n    )\n\n\ndef _initialize_crt_transfer_primatives(client, config):\n    lock = acquire_crt_s3_process_lock(PROCESS_LOCK_NAME)\n    if lock is None:\n        # If we're unable to acquire the lock, we cannot\n        # use the CRT in this process and should default to\n        # the classic s3transfer manager.\n        return None, None\n\n    session = Session()\n    region_name = client.meta.region_name\n    credentials = client._get_credentials()\n\n    serializer = _create_crt_request_serializer(session, region_name)\n    s3_client = _create_crt_s3_client(\n        session, config, region_name, credentials, lock\n    )\n    return serializer, s3_client\n\n\ndef get_crt_s3_client(client, config):\n    global CRT_S3_CLIENT\n    global BOTOCORE_CRT_SERIALIZER\n\n    with CLIENT_CREATION_LOCK:\n        if CRT_S3_CLIENT is None:\n            serializer, s3_client = _initialize_crt_transfer_primatives(\n                client, config\n            )\n            BOTOCORE_CRT_SERIALIZER = serializer\n            CRT_S3_CLIENT = s3_client\n\n    return CRT_S3_CLIENT\n\n\nclass CRTS3Client:\n    \"\"\"\n    This wrapper keeps track of our underlying CRT client, the lock used to\n    acquire it and the region we've used to instantiate the client.\n\n    Due to limitations in the existing CRT interfaces, we can only make calls\n    in a single region and does not support redirects. We track the region to\n    ensure we don't use the CRT client when a successful request cannot be made.\n    \"\"\"\n\n    def __init__(self, crt_client, process_lock, region, cred_provider):\n        self.crt_client = crt_client\n        self.process_lock = process_lock\n        self.region = region\n        self.cred_provider = cred_provider\n\n\ndef is_crt_compatible_request(client, crt_s3_client):\n    \"\"\"\n    Boto3 client must use same signing region and credentials\n    as the CRT_S3_CLIENT singleton. Otherwise fallback to classic.\n    \"\"\"\n    if crt_s3_client is None:\n        return False\n\n    boto3_creds = client._get_credentials()\n    if boto3_creds is None:\n        return False\n\n    is_same_identity = compare_identity(\n        boto3_creds.get_frozen_credentials(), crt_s3_client.cred_provider\n    )\n    is_same_region = client.meta.region_name == crt_s3_client.region\n    return is_same_region and is_same_identity\n\n\ndef compare_identity(boto3_creds, crt_s3_creds):\n    try:\n        crt_creds = crt_s3_creds()\n    except botocore.exceptions.NoCredentialsError:\n        return False\n\n    is_matching_identity = (\n        boto3_creds.access_key == crt_creds.access_key_id\n        and boto3_creds.secret_key == crt_creds.secret_access_key\n        and boto3_creds.token == crt_creds.session_token\n    )\n    return is_matching_identity\n\n\ndef create_crt_transfer_manager(client, config):\n    \"\"\"Create a CRTTransferManager for optimized data transfer.\"\"\"\n    crt_s3_client = get_crt_s3_client(client, config)\n    if is_crt_compatible_request(client, crt_s3_client):\n        return CRTTransferManager(\n            crt_s3_client.crt_client, BOTOCORE_CRT_SERIALIZER\n        )\n    return None\n", "boto3/session.py": "# Copyright 2014 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n\nimport copy\nimport os\n\nimport botocore.session\nfrom botocore.client import Config\nfrom botocore.exceptions import DataNotFoundError, UnknownServiceError\n\nimport boto3\nimport boto3.utils\nfrom boto3.exceptions import ResourceNotExistsError, UnknownAPIVersionError\n\nfrom .resources.factory import ResourceFactory\n\n\nclass Session:\n    \"\"\"\n    A session stores configuration state and allows you to create service\n    clients and resources.\n\n    :type aws_access_key_id: string\n    :param aws_access_key_id: AWS access key ID\n    :type aws_secret_access_key: string\n    :param aws_secret_access_key: AWS secret access key\n    :type aws_session_token: string\n    :param aws_session_token: AWS temporary session token\n    :type region_name: string\n    :param region_name: Default region when creating new connections\n    :type botocore_session: botocore.session.Session\n    :param botocore_session: Use this Botocore session instead of creating\n                             a new default one.\n    :type profile_name: string\n    :param profile_name: The name of a profile to use. If not given, then\n                         the default profile is used.\n    \"\"\"\n\n    def __init__(\n        self,\n        aws_access_key_id=None,\n        aws_secret_access_key=None,\n        aws_session_token=None,\n        region_name=None,\n        botocore_session=None,\n        profile_name=None,\n    ):\n        if botocore_session is not None:\n            self._session = botocore_session\n        else:\n            # Create a new default session\n            self._session = botocore.session.get_session()\n\n        # Setup custom user-agent string if it isn't already customized\n        if self._session.user_agent_name == 'Botocore':\n            botocore_info = f'Botocore/{self._session.user_agent_version}'\n            if self._session.user_agent_extra:\n                self._session.user_agent_extra += ' ' + botocore_info\n            else:\n                self._session.user_agent_extra = botocore_info\n            self._session.user_agent_name = 'Boto3'\n            self._session.user_agent_version = boto3.__version__\n\n        if profile_name is not None:\n            self._session.set_config_variable('profile', profile_name)\n\n        if aws_access_key_id or aws_secret_access_key or aws_session_token:\n            self._session.set_credentials(\n                aws_access_key_id, aws_secret_access_key, aws_session_token\n            )\n\n        if region_name is not None:\n            self._session.set_config_variable('region', region_name)\n\n        self.resource_factory = ResourceFactory(\n            self._session.get_component('event_emitter')\n        )\n        self._setup_loader()\n        self._register_default_handlers()\n\n    def __repr__(self):\n        return '{}(region_name={})'.format(\n            self.__class__.__name__,\n            repr(self._session.get_config_variable('region')),\n        )\n\n    @property\n    def profile_name(self):\n        \"\"\"\n        The **read-only** profile name.\n        \"\"\"\n        return self._session.profile or 'default'\n\n    @property\n    def region_name(self):\n        \"\"\"\n        The **read-only** region name.\n        \"\"\"\n        return self._session.get_config_variable('region')\n\n    @property\n    def events(self):\n        \"\"\"\n        The event emitter for a session\n        \"\"\"\n        return self._session.get_component('event_emitter')\n\n    @property\n    def available_profiles(self):\n        \"\"\"\n        The profiles available to the session credentials\n        \"\"\"\n        return self._session.available_profiles\n\n    def _setup_loader(self):\n        \"\"\"\n        Setup loader paths so that we can load resources.\n        \"\"\"\n        self._loader = self._session.get_component('data_loader')\n        self._loader.search_paths.append(\n            os.path.join(os.path.dirname(__file__), 'data')\n        )\n\n    def get_available_services(self):\n        \"\"\"\n        Get a list of available services that can be loaded as low-level\n        clients via :py:meth:`Session.client`.\n\n        :rtype: list\n        :return: List of service names\n        \"\"\"\n        return self._session.get_available_services()\n\n    def get_available_resources(self):\n        \"\"\"\n        Get a list of available services that can be loaded as resource\n        clients via :py:meth:`Session.resource`.\n\n        :rtype: list\n        :return: List of service names\n        \"\"\"\n        return self._loader.list_available_services(type_name='resources-1')\n\n    def get_available_partitions(self):\n        \"\"\"Lists the available partitions\n\n        :rtype: list\n        :return: Returns a list of partition names (e.g., [\"aws\", \"aws-cn\"])\n        \"\"\"\n        return self._session.get_available_partitions()\n\n    def get_available_regions(\n        self, service_name, partition_name='aws', allow_non_regional=False\n    ):\n        \"\"\"Lists the region and endpoint names of a particular partition.\n\n        The list of regions returned by this method are regions that are\n        explicitly known by the client to exist and is not comprehensive. A\n        region not returned in this list may still be available for the\n        provided service.\n\n        :type service_name: string\n        :param service_name: Name of a service to list endpoint for (e.g., s3).\n\n        :type partition_name: string\n        :param partition_name: Name of the partition to limit endpoints to.\n            (e.g., aws for the public AWS endpoints, aws-cn for AWS China\n            endpoints, aws-us-gov for AWS GovCloud (US) Endpoints, etc.)\n\n        :type allow_non_regional: bool\n        :param allow_non_regional: Set to True to include endpoints that are\n             not regional endpoints (e.g., s3-external-1,\n             fips-us-gov-west-1, etc).\n\n        :return: Returns a list of endpoint names (e.g., [\"us-east-1\"]).\n        \"\"\"\n        return self._session.get_available_regions(\n            service_name=service_name,\n            partition_name=partition_name,\n            allow_non_regional=allow_non_regional,\n        )\n\n    def get_credentials(self):\n        \"\"\"\n        Return the :class:`botocore.credentials.Credentials` object\n        associated with this session.  If the credentials have not\n        yet been loaded, this will attempt to load them.  If they\n        have already been loaded, this will return the cached\n        credentials.\n        \"\"\"\n        return self._session.get_credentials()\n\n    def get_partition_for_region(self, region_name):\n        \"\"\"Lists the partition name of a particular region.\n\n        :type region_name: string\n        :param region_name: Name of the region to list partition for (e.g.,\n             us-east-1).\n\n        :rtype: string\n        :return: Returns the respective partition name (e.g., aws).\n        \"\"\"\n        return self._session.get_partition_for_region(region_name)\n\n    def client(\n        self,\n        service_name,\n        region_name=None,\n        api_version=None,\n        use_ssl=True,\n        verify=None,\n        endpoint_url=None,\n        aws_access_key_id=None,\n        aws_secret_access_key=None,\n        aws_session_token=None,\n        config=None,\n    ):\n        \"\"\"\n        Create a low-level service client by name.\n\n        :type service_name: string\n        :param service_name: The name of a service, e.g. 's3' or 'ec2'. You\n            can get a list of available services via\n            :py:meth:`get_available_services`.\n\n        :type region_name: string\n        :param region_name: The name of the region associated with the client.\n            A client is associated with a single region.\n\n        :type api_version: string\n        :param api_version: The API version to use.  By default, botocore will\n            use the latest API version when creating a client.  You only need\n            to specify this parameter if you want to use a previous API version\n            of the client.\n\n        :type use_ssl: boolean\n        :param use_ssl: Whether or not to use SSL.  By default, SSL is used.\n            Note that not all services support non-ssl connections.\n\n        :type verify: boolean/string\n        :param verify: Whether or not to verify SSL certificates.  By default\n            SSL certificates are verified.  You can provide the following\n            values:\n\n            * False - do not validate SSL certificates.  SSL will still be\n              used (unless use_ssl is False), but SSL certificates\n              will not be verified.\n            * path/to/cert/bundle.pem - A filename of the CA cert bundle to\n              uses.  You can specify this argument if you want to use a\n              different CA cert bundle than the one used by botocore.\n\n        :type endpoint_url: string\n        :param endpoint_url: The complete URL to use for the constructed\n            client. Normally, botocore will automatically construct the\n            appropriate URL to use when communicating with a service.  You\n            can specify a complete URL (including the \"http/https\" scheme)\n            to override this behavior.  If this value is provided,\n            then ``use_ssl`` is ignored.\n\n        :type aws_access_key_id: string\n        :param aws_access_key_id: The access key to use when creating\n            the client.  This is entirely optional, and if not provided,\n            the credentials configured for the session will automatically\n            be used.  You only need to provide this argument if you want\n            to override the credentials used for this specific client.\n\n        :type aws_secret_access_key: string\n        :param aws_secret_access_key: The secret key to use when creating\n            the client.  Same semantics as aws_access_key_id above.\n\n        :type aws_session_token: string\n        :param aws_session_token: The session token to use when creating\n            the client.  Same semantics as aws_access_key_id above.\n\n        :type config: botocore.client.Config\n        :param config: Advanced client configuration options. If region_name\n            is specified in the client config, its value will take precedence\n            over environment variables and configuration values, but not over\n            a region_name value passed explicitly to the method. See\n            `botocore config documentation\n            <https://botocore.amazonaws.com/v1/documentation/api/latest/reference/config.html>`_\n            for more details.\n\n        :return: Service client instance\n\n        \"\"\"\n        return self._session.create_client(\n            service_name,\n            region_name=region_name,\n            api_version=api_version,\n            use_ssl=use_ssl,\n            verify=verify,\n            endpoint_url=endpoint_url,\n            aws_access_key_id=aws_access_key_id,\n            aws_secret_access_key=aws_secret_access_key,\n            aws_session_token=aws_session_token,\n            config=config,\n        )\n\n    def resource(\n        self,\n        service_name,\n        region_name=None,\n        api_version=None,\n        use_ssl=True,\n        verify=None,\n        endpoint_url=None,\n        aws_access_key_id=None,\n        aws_secret_access_key=None,\n        aws_session_token=None,\n        config=None,\n    ):\n        \"\"\"\n        Create a resource service client by name.\n\n        :type service_name: string\n        :param service_name: The name of a service, e.g. 's3' or 'ec2'. You\n            can get a list of available services via\n            :py:meth:`get_available_resources`.\n\n        :type region_name: string\n        :param region_name: The name of the region associated with the client.\n            A client is associated with a single region.\n\n        :type api_version: string\n        :param api_version: The API version to use.  By default, botocore will\n            use the latest API version when creating a client.  You only need\n            to specify this parameter if you want to use a previous API version\n            of the client.\n\n        :type use_ssl: boolean\n        :param use_ssl: Whether or not to use SSL.  By default, SSL is used.\n            Note that not all services support non-ssl connections.\n\n        :type verify: boolean/string\n        :param verify: Whether or not to verify SSL certificates.  By default\n            SSL certificates are verified.  You can provide the following\n            values:\n\n            * False - do not validate SSL certificates.  SSL will still be\n              used (unless use_ssl is False), but SSL certificates\n              will not be verified.\n            * path/to/cert/bundle.pem - A filename of the CA cert bundle to\n              uses.  You can specify this argument if you want to use a\n              different CA cert bundle than the one used by botocore.\n\n        :type endpoint_url: string\n        :param endpoint_url: The complete URL to use for the constructed\n            client. Normally, botocore will automatically construct the\n            appropriate URL to use when communicating with a service.  You\n            can specify a complete URL (including the \"http/https\" scheme)\n            to override this behavior.  If this value is provided,\n            then ``use_ssl`` is ignored.\n\n        :type aws_access_key_id: string\n        :param aws_access_key_id: The access key to use when creating\n            the client.  This is entirely optional, and if not provided,\n            the credentials configured for the session will automatically\n            be used.  You only need to provide this argument if you want\n            to override the credentials used for this specific client.\n\n        :type aws_secret_access_key: string\n        :param aws_secret_access_key: The secret key to use when creating\n            the client.  Same semantics as aws_access_key_id above.\n\n        :type aws_session_token: string\n        :param aws_session_token: The session token to use when creating\n            the client.  Same semantics as aws_access_key_id above.\n\n        :type config: botocore.client.Config\n        :param config: Advanced client configuration options. If region_name\n            is specified in the client config, its value will take precedence\n            over environment variables and configuration values, but not over\n            a region_name value passed explicitly to the method.  If\n            user_agent_extra is specified in the client config, it overrides\n            the default user_agent_extra provided by the resource API. See\n            `botocore config documentation\n            <https://botocore.amazonaws.com/v1/documentation/api/latest/reference/config.html>`_\n            for more details.\n\n        :return: Subclass of :py:class:`~boto3.resources.base.ServiceResource`\n        \"\"\"\n        try:\n            resource_model = self._loader.load_service_model(\n                service_name, 'resources-1', api_version\n            )\n        except UnknownServiceError:\n            available = self.get_available_resources()\n            has_low_level_client = (\n                service_name in self.get_available_services()\n            )\n            raise ResourceNotExistsError(\n                service_name, available, has_low_level_client\n            )\n        except DataNotFoundError:\n            # This is because we've provided an invalid API version.\n            available_api_versions = self._loader.list_api_versions(\n                service_name, 'resources-1'\n            )\n            raise UnknownAPIVersionError(\n                service_name, api_version, ', '.join(available_api_versions)\n            )\n\n        if api_version is None:\n            # Even though botocore's load_service_model() can handle\n            # using the latest api_version if not provided, we need\n            # to track this api_version in boto3 in order to ensure\n            # we're pairing a resource model with a client model\n            # of the same API version.  It's possible for the latest\n            # API version of a resource model in boto3 to not be\n            # the same API version as a service model in botocore.\n            # So we need to look up the api_version if one is not\n            # provided to ensure we load the same API version of the\n            # client.\n            #\n            # Note: This is relying on the fact that\n            #   loader.load_service_model(..., api_version=None)\n            # and loader.determine_latest_version(..., 'resources-1')\n            # both load the same api version of the file.\n            api_version = self._loader.determine_latest_version(\n                service_name, 'resources-1'\n            )\n\n        # Creating a new resource instance requires the low-level client\n        # and service model, the resource version and resource JSON data.\n        # We pass these to the factory and get back a class, which is\n        # instantiated on top of the low-level client.\n        if config is not None:\n            if config.user_agent_extra is None:\n                config = copy.deepcopy(config)\n                config.user_agent_extra = 'Resource'\n        else:\n            config = Config(user_agent_extra='Resource')\n        client = self.client(\n            service_name,\n            region_name=region_name,\n            api_version=api_version,\n            use_ssl=use_ssl,\n            verify=verify,\n            endpoint_url=endpoint_url,\n            aws_access_key_id=aws_access_key_id,\n            aws_secret_access_key=aws_secret_access_key,\n            aws_session_token=aws_session_token,\n            config=config,\n        )\n        service_model = client.meta.service_model\n\n        # Create a ServiceContext object to serve as a reference to\n        # important read-only information about the general service.\n        service_context = boto3.utils.ServiceContext(\n            service_name=service_name,\n            service_model=service_model,\n            resource_json_definitions=resource_model['resources'],\n            service_waiter_model=boto3.utils.LazyLoadedWaiterModel(\n                self._session, service_name, api_version\n            ),\n        )\n\n        # Create the service resource class.\n        cls = self.resource_factory.load_from_definition(\n            resource_name=service_name,\n            single_resource_json_definition=resource_model['service'],\n            service_context=service_context,\n        )\n\n        return cls(client=client)\n\n    def _register_default_handlers(self):\n        # S3 customizations\n        self._session.register(\n            'creating-client-class.s3',\n            boto3.utils.lazy_call(\n                'boto3.s3.inject.inject_s3_transfer_methods'\n            ),\n        )\n        self._session.register(\n            'creating-resource-class.s3.Bucket',\n            boto3.utils.lazy_call('boto3.s3.inject.inject_bucket_methods'),\n        )\n        self._session.register(\n            'creating-resource-class.s3.Object',\n            boto3.utils.lazy_call('boto3.s3.inject.inject_object_methods'),\n        )\n        self._session.register(\n            'creating-resource-class.s3.ObjectSummary',\n            boto3.utils.lazy_call(\n                'boto3.s3.inject.inject_object_summary_methods'\n            ),\n        )\n\n        # DynamoDb customizations\n        self._session.register(\n            'creating-resource-class.dynamodb',\n            boto3.utils.lazy_call(\n                'boto3.dynamodb.transform.register_high_level_interface'\n            ),\n            unique_id='high-level-dynamodb',\n        )\n        self._session.register(\n            'creating-resource-class.dynamodb.Table',\n            boto3.utils.lazy_call(\n                'boto3.dynamodb.table.register_table_methods'\n            ),\n            unique_id='high-level-dynamodb-table',\n        )\n\n        # EC2 Customizations\n        self._session.register(\n            'creating-resource-class.ec2.ServiceResource',\n            boto3.utils.lazy_call('boto3.ec2.createtags.inject_create_tags'),\n        )\n\n        self._session.register(\n            'creating-resource-class.ec2.Instance',\n            boto3.utils.lazy_call(\n                'boto3.ec2.deletetags.inject_delete_tags',\n                event_emitter=self.events,\n            ),\n        )\n", "boto3/resources/response.py": "# Copyright 2014 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n\nimport jmespath\nfrom botocore import xform_name\n\nfrom .params import get_data_member\n\n\ndef all_not_none(iterable):\n    \"\"\"\n    Return True if all elements of the iterable are not None (or if the\n    iterable is empty). This is like the built-in ``all``, except checks\n    against None, so 0 and False are allowable values.\n    \"\"\"\n    for element in iterable:\n        if element is None:\n            return False\n    return True\n\n\ndef build_identifiers(identifiers, parent, params=None, raw_response=None):\n    \"\"\"\n    Builds a mapping of identifier names to values based on the\n    identifier source location, type, and target. Identifier\n    values may be scalars or lists depending on the source type\n    and location.\n\n    :type identifiers: list\n    :param identifiers: List of :py:class:`~boto3.resources.model.Parameter`\n                        definitions\n    :type parent: ServiceResource\n    :param parent: The resource instance to which this action is attached.\n    :type params: dict\n    :param params: Request parameters sent to the service.\n    :type raw_response: dict\n    :param raw_response: Low-level operation response.\n    :rtype: list\n    :return: An ordered list of ``(name, value)`` identifier tuples.\n    \"\"\"\n    results = []\n\n    for identifier in identifiers:\n        source = identifier.source\n        target = identifier.target\n\n        if source == 'response':\n            value = jmespath.search(identifier.path, raw_response)\n        elif source == 'requestParameter':\n            value = jmespath.search(identifier.path, params)\n        elif source == 'identifier':\n            value = getattr(parent, xform_name(identifier.name))\n        elif source == 'data':\n            # If this is a data member then it may incur a load\n            # action before returning the value.\n            value = get_data_member(parent, identifier.path)\n        elif source == 'input':\n            # This value is set by the user, so ignore it here\n            continue\n        else:\n            raise NotImplementedError(f'Unsupported source type: {source}')\n\n        results.append((xform_name(target), value))\n\n    return results\n\n\ndef build_empty_response(search_path, operation_name, service_model):\n    \"\"\"\n    Creates an appropriate empty response for the type that is expected,\n    based on the service model's shape type. For example, a value that\n    is normally a list would then return an empty list. A structure would\n    return an empty dict, and a number would return None.\n\n    :type search_path: string\n    :param search_path: JMESPath expression to search in the response\n    :type operation_name: string\n    :param operation_name: Name of the underlying service operation.\n    :type service_model: :ref:`botocore.model.ServiceModel`\n    :param service_model: The Botocore service model\n    :rtype: dict, list, or None\n    :return: An appropriate empty value\n    \"\"\"\n    response = None\n\n    operation_model = service_model.operation_model(operation_name)\n    shape = operation_model.output_shape\n\n    if search_path:\n        # Walk the search path and find the final shape. For example, given\n        # a path of ``foo.bar[0].baz``, we first find the shape for ``foo``,\n        # then the shape for ``bar`` (ignoring the indexing), and finally\n        # the shape for ``baz``.\n        for item in search_path.split('.'):\n            item = item.strip('[0123456789]$')\n\n            if shape.type_name == 'structure':\n                shape = shape.members[item]\n            elif shape.type_name == 'list':\n                shape = shape.member\n            else:\n                raise NotImplementedError(\n                    f'Search path hits shape type {shape.type_name} from {item}'\n                )\n\n    # Anything not handled here is set to None\n    if shape.type_name == 'structure':\n        response = {}\n    elif shape.type_name == 'list':\n        response = []\n    elif shape.type_name == 'map':\n        response = {}\n\n    return response\n\n\nclass RawHandler:\n    \"\"\"\n    A raw action response handler. This passed through the response\n    dictionary, optionally after performing a JMESPath search if one\n    has been defined for the action.\n\n    :type search_path: string\n    :param search_path: JMESPath expression to search in the response\n    :rtype: dict\n    :return: Service response\n    \"\"\"\n\n    def __init__(self, search_path):\n        self.search_path = search_path\n\n    def __call__(self, parent, params, response):\n        \"\"\"\n        :type parent: ServiceResource\n        :param parent: The resource instance to which this action is attached.\n        :type params: dict\n        :param params: Request parameters sent to the service.\n        :type response: dict\n        :param response: Low-level operation response.\n        \"\"\"\n        # TODO: Remove the '$' check after JMESPath supports it\n        if self.search_path and self.search_path != '$':\n            response = jmespath.search(self.search_path, response)\n\n        return response\n\n\nclass ResourceHandler:\n    \"\"\"\n    Creates a new resource or list of new resources from the low-level\n    response based on the given response resource definition.\n\n    :type search_path: string\n    :param search_path: JMESPath expression to search in the response\n\n    :type factory: ResourceFactory\n    :param factory: The factory that created the resource class to which\n                    this action is attached.\n\n    :type resource_model: :py:class:`~boto3.resources.model.ResponseResource`\n    :param resource_model: Response resource model.\n\n    :type service_context: :py:class:`~boto3.utils.ServiceContext`\n    :param service_context: Context about the AWS service\n\n    :type operation_name: string\n    :param operation_name: Name of the underlying service operation, if it\n                           exists.\n\n    :rtype: ServiceResource or list\n    :return: New resource instance(s).\n    \"\"\"\n\n    def __init__(\n        self,\n        search_path,\n        factory,\n        resource_model,\n        service_context,\n        operation_name=None,\n    ):\n        self.search_path = search_path\n        self.factory = factory\n        self.resource_model = resource_model\n        self.operation_name = operation_name\n        self.service_context = service_context\n\n    def __call__(self, parent, params, response):\n        \"\"\"\n        :type parent: ServiceResource\n        :param parent: The resource instance to which this action is attached.\n        :type params: dict\n        :param params: Request parameters sent to the service.\n        :type response: dict\n        :param response: Low-level operation response.\n        \"\"\"\n        resource_name = self.resource_model.type\n        json_definition = self.service_context.resource_json_definitions.get(\n            resource_name\n        )\n\n        # Load the new resource class that will result from this action.\n        resource_cls = self.factory.load_from_definition(\n            resource_name=resource_name,\n            single_resource_json_definition=json_definition,\n            service_context=self.service_context,\n        )\n        raw_response = response\n        search_response = None\n\n        # Anytime a path is defined, it means the response contains the\n        # resource's attributes, so resource_data gets set here. It\n        # eventually ends up in resource.meta.data, which is where\n        # the attribute properties look for data.\n        if self.search_path:\n            search_response = jmespath.search(self.search_path, raw_response)\n\n        # First, we parse all the identifiers, then create the individual\n        # response resources using them. Any identifiers that are lists\n        # will have one item consumed from the front of the list for each\n        # resource that is instantiated. Items which are not a list will\n        # be set as the same value on each new resource instance.\n        identifiers = dict(\n            build_identifiers(\n                self.resource_model.identifiers, parent, params, raw_response\n            )\n        )\n\n        # If any of the identifiers is a list, then the response is plural\n        plural = [v for v in identifiers.values() if isinstance(v, list)]\n\n        if plural:\n            response = []\n\n            # The number of items in an identifier that is a list will\n            # determine how many resource instances to create.\n            for i in range(len(plural[0])):\n                # Response item data is *only* available if a search path\n                # was given. This prevents accidentally loading unrelated\n                # data that may be in the response.\n                response_item = None\n                if search_response:\n                    response_item = search_response[i]\n                response.append(\n                    self.handle_response_item(\n                        resource_cls, parent, identifiers, response_item\n                    )\n                )\n        elif all_not_none(identifiers.values()):\n            # All identifiers must always exist, otherwise the resource\n            # cannot be instantiated.\n            response = self.handle_response_item(\n                resource_cls, parent, identifiers, search_response\n            )\n        else:\n            # The response should be empty, but that may mean an\n            # empty dict, list, or None based on whether we make\n            # a remote service call and what shape it is expected\n            # to return.\n            response = None\n            if self.operation_name is not None:\n                # A remote service call was made, so try and determine\n                # its shape.\n                response = build_empty_response(\n                    self.search_path,\n                    self.operation_name,\n                    self.service_context.service_model,\n                )\n\n        return response\n\n    def handle_response_item(\n        self, resource_cls, parent, identifiers, resource_data\n    ):\n        \"\"\"\n        Handles the creation of a single response item by setting\n        parameters and creating the appropriate resource instance.\n\n        :type resource_cls: ServiceResource subclass\n        :param resource_cls: The resource class to instantiate.\n        :type parent: ServiceResource\n        :param parent: The resource instance to which this action is attached.\n        :type identifiers: dict\n        :param identifiers: Map of identifier names to value or values.\n        :type resource_data: dict or None\n        :param resource_data: Data for resource attributes.\n        :rtype: ServiceResource\n        :return: New resource instance.\n        \"\"\"\n        kwargs = {\n            'client': parent.meta.client,\n        }\n\n        for name, value in identifiers.items():\n            # If value is a list, then consume the next item\n            if isinstance(value, list):\n                value = value.pop(0)\n\n            kwargs[name] = value\n\n        resource = resource_cls(**kwargs)\n\n        if resource_data is not None:\n            resource.meta.data = resource_data\n\n        return resource\n", "boto3/resources/model.py": "# Copyright 2014 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n\n\"\"\"\nThe models defined in this file represent the resource JSON description\nformat and provide a layer of abstraction from the raw JSON. The advantages\nof this are:\n\n* Pythonic interface (e.g. ``action.request.operation``)\n* Consumers need not change for minor JSON changes (e.g. renamed field)\n\nThese models are used both by the resource factory to generate resource\nclasses as well as by the documentation generator.\n\"\"\"\n\nimport logging\n\nfrom botocore import xform_name\n\nlogger = logging.getLogger(__name__)\n\n\nclass Identifier:\n    \"\"\"\n    A resource identifier, given by its name.\n\n    :type name: string\n    :param name: The name of the identifier\n    \"\"\"\n\n    def __init__(self, name, member_name=None):\n        #: (``string``) The name of the identifier\n        self.name = name\n        self.member_name = member_name\n\n\nclass Action:\n    \"\"\"\n    A service operation action.\n\n    :type name: string\n    :param name: The name of the action\n    :type definition: dict\n    :param definition: The JSON definition\n    :type resource_defs: dict\n    :param resource_defs: All resources defined in the service\n    \"\"\"\n\n    def __init__(self, name, definition, resource_defs):\n        self._definition = definition\n\n        #: (``string``) The name of the action\n        self.name = name\n        #: (:py:class:`Request`) This action's request or ``None``\n        self.request = None\n        if 'request' in definition:\n            self.request = Request(definition.get('request', {}))\n        #: (:py:class:`ResponseResource`) This action's resource or ``None``\n        self.resource = None\n        if 'resource' in definition:\n            self.resource = ResponseResource(\n                definition.get('resource', {}), resource_defs\n            )\n        #: (``string``) The JMESPath search path or ``None``\n        self.path = definition.get('path')\n\n\nclass DefinitionWithParams:\n    \"\"\"\n    An item which has parameters exposed via the ``params`` property.\n    A request has an operation and parameters, while a waiter has\n    a name, a low-level waiter name and parameters.\n\n    :type definition: dict\n    :param definition: The JSON definition\n    \"\"\"\n\n    def __init__(self, definition):\n        self._definition = definition\n\n    @property\n    def params(self):\n        \"\"\"\n        Get a list of auto-filled parameters for this request.\n\n        :type: list(:py:class:`Parameter`)\n        \"\"\"\n        params = []\n\n        for item in self._definition.get('params', []):\n            params.append(Parameter(**item))\n\n        return params\n\n\nclass Parameter:\n    \"\"\"\n    An auto-filled parameter which has a source and target. For example,\n    the ``QueueUrl`` may be auto-filled from a resource's ``url`` identifier\n    when making calls to ``queue.receive_messages``.\n\n    :type target: string\n    :param target: The destination parameter name, e.g. ``QueueUrl``\n    :type source_type: string\n    :param source_type: Where the source is defined.\n    :type source: string\n    :param source: The source name, e.g. ``Url``\n    \"\"\"\n\n    def __init__(\n        self, target, source, name=None, path=None, value=None, **kwargs\n    ):\n        #: (``string``) The destination parameter name\n        self.target = target\n        #: (``string``) Where the source is defined\n        self.source = source\n        #: (``string``) The name of the source, if given\n        self.name = name\n        #: (``string``) The JMESPath query of the source\n        self.path = path\n        #: (``string|int|float|bool``) The source constant value\n        self.value = value\n\n        # Complain if we encounter any unknown values.\n        if kwargs:\n            logger.warning('Unknown parameter options found: %s', kwargs)\n\n\nclass Request(DefinitionWithParams):\n    \"\"\"\n    A service operation action request.\n\n    :type definition: dict\n    :param definition: The JSON definition\n    \"\"\"\n\n    def __init__(self, definition):\n        super().__init__(definition)\n\n        #: (``string``) The name of the low-level service operation\n        self.operation = definition.get('operation')\n\n\nclass Waiter(DefinitionWithParams):\n    \"\"\"\n    An event waiter specification.\n\n    :type name: string\n    :param name: Name of the waiter\n    :type definition: dict\n    :param definition: The JSON definition\n    \"\"\"\n\n    PREFIX = 'WaitUntil'\n\n    def __init__(self, name, definition):\n        super().__init__(definition)\n\n        #: (``string``) The name of this waiter\n        self.name = name\n\n        #: (``string``) The name of the underlying event waiter\n        self.waiter_name = definition.get('waiterName')\n\n\nclass ResponseResource:\n    \"\"\"\n    A resource response to create after performing an action.\n\n    :type definition: dict\n    :param definition: The JSON definition\n    :type resource_defs: dict\n    :param resource_defs: All resources defined in the service\n    \"\"\"\n\n    def __init__(self, definition, resource_defs):\n        self._definition = definition\n        self._resource_defs = resource_defs\n\n        #: (``string``) The name of the response resource type\n        self.type = definition.get('type')\n\n        #: (``string``) The JMESPath search query or ``None``\n        self.path = definition.get('path')\n\n    @property\n    def identifiers(self):\n        \"\"\"\n        A list of resource identifiers.\n\n        :type: list(:py:class:`Identifier`)\n        \"\"\"\n        identifiers = []\n\n        for item in self._definition.get('identifiers', []):\n            identifiers.append(Parameter(**item))\n\n        return identifiers\n\n    @property\n    def model(self):\n        \"\"\"\n        Get the resource model for the response resource.\n\n        :type: :py:class:`ResourceModel`\n        \"\"\"\n        return ResourceModel(\n            self.type, self._resource_defs[self.type], self._resource_defs\n        )\n\n\nclass Collection(Action):\n    \"\"\"\n    A group of resources. See :py:class:`Action`.\n\n    :type name: string\n    :param name: The name of the collection\n    :type definition: dict\n    :param definition: The JSON definition\n    :type resource_defs: dict\n    :param resource_defs: All resources defined in the service\n    \"\"\"\n\n    @property\n    def batch_actions(self):\n        \"\"\"\n        Get a list of batch actions supported by the resource type\n        contained in this action. This is a shortcut for accessing\n        the same information through the resource model.\n\n        :rtype: list(:py:class:`Action`)\n        \"\"\"\n        return self.resource.model.batch_actions\n\n\nclass ResourceModel:\n    \"\"\"\n    A model representing a resource, defined via a JSON description\n    format. A resource has identifiers, attributes, actions,\n    sub-resources, references and collections. For more information\n    on resources, see :ref:`guide_resources`.\n\n    :type name: string\n    :param name: The name of this resource, e.g. ``sqs`` or ``Queue``\n    :type definition: dict\n    :param definition: The JSON definition\n    :type resource_defs: dict\n    :param resource_defs: All resources defined in the service\n    \"\"\"\n\n    def __init__(self, name, definition, resource_defs):\n        self._definition = definition\n        self._resource_defs = resource_defs\n        self._renamed = {}\n\n        #: (``string``) The name of this resource\n        self.name = name\n        #: (``string``) The service shape name for this resource or ``None``\n        self.shape = definition.get('shape')\n\n    def load_rename_map(self, shape=None):\n        \"\"\"\n        Load a name translation map given a shape. This will set\n        up renamed values for any collisions, e.g. if the shape,\n        an action, and a subresource all are all named ``foo``\n        then the resource will have an action ``foo``, a subresource\n        named ``Foo`` and a property named ``foo_attribute``.\n        This is the order of precedence, from most important to\n        least important:\n\n        * Load action (resource.load)\n        * Identifiers\n        * Actions\n        * Subresources\n        * References\n        * Collections\n        * Waiters\n        * Attributes (shape members)\n\n        Batch actions are only exposed on collections, so do not\n        get modified here. Subresources use upper camel casing, so\n        are unlikely to collide with anything but other subresources.\n\n        Creates a structure like this::\n\n            renames = {\n                ('action', 'id'): 'id_action',\n                ('collection', 'id'): 'id_collection',\n                ('attribute', 'id'): 'id_attribute'\n            }\n\n            # Get the final name for an action named 'id'\n            name = renames.get(('action', 'id'), 'id')\n\n        :type shape: botocore.model.Shape\n        :param shape: The underlying shape for this resource.\n        \"\"\"\n        # Meta is a reserved name for resources\n        names = {'meta'}\n        self._renamed = {}\n\n        if self._definition.get('load'):\n            names.add('load')\n\n        for item in self._definition.get('identifiers', []):\n            self._load_name_with_category(names, item['name'], 'identifier')\n\n        for name in self._definition.get('actions', {}):\n            self._load_name_with_category(names, name, 'action')\n\n        for name, ref in self._get_has_definition().items():\n            # Subresources require no data members, just typically\n            # identifiers and user input.\n            data_required = False\n            for identifier in ref['resource']['identifiers']:\n                if identifier['source'] == 'data':\n                    data_required = True\n                    break\n\n            if not data_required:\n                self._load_name_with_category(\n                    names, name, 'subresource', snake_case=False\n                )\n            else:\n                self._load_name_with_category(names, name, 'reference')\n\n        for name in self._definition.get('hasMany', {}):\n            self._load_name_with_category(names, name, 'collection')\n\n        for name in self._definition.get('waiters', {}):\n            self._load_name_with_category(\n                names, Waiter.PREFIX + name, 'waiter'\n            )\n\n        if shape is not None:\n            for name in shape.members.keys():\n                self._load_name_with_category(names, name, 'attribute')\n\n    def _load_name_with_category(self, names, name, category, snake_case=True):\n        \"\"\"\n        Load a name with a given category, possibly renaming it\n        if that name is already in use. The name will be stored\n        in ``names`` and possibly be set up in ``self._renamed``.\n\n        :type names: set\n        :param names: Existing names (Python attributes, properties, or\n                      methods) on the resource.\n        :type name: string\n        :param name: The original name of the value.\n        :type category: string\n        :param category: The value type, such as 'identifier' or 'action'\n        :type snake_case: bool\n        :param snake_case: True (default) if the name should be snake cased.\n        \"\"\"\n        if snake_case:\n            name = xform_name(name)\n\n        if name in names:\n            logger.debug(f'Renaming {self.name} {category} {name}')\n            self._renamed[(category, name)] = name + '_' + category\n            name += '_' + category\n\n            if name in names:\n                # This isn't good, let's raise instead of trying to keep\n                # renaming this value.\n                raise ValueError(\n                    f'Problem renaming {self.name} {category} to {name}!'\n                )\n\n        names.add(name)\n\n    def _get_name(self, category, name, snake_case=True):\n        \"\"\"\n        Get a possibly renamed value given a category and name. This\n        uses the rename map set up in ``load_rename_map``, so that\n        method must be called once first.\n\n        :type category: string\n        :param category: The value type, such as 'identifier' or 'action'\n        :type name: string\n        :param name: The original name of the value\n        :type snake_case: bool\n        :param snake_case: True (default) if the name should be snake cased.\n        :rtype: string\n        :return: Either the renamed value if it is set, otherwise the\n                 original name.\n        \"\"\"\n        if snake_case:\n            name = xform_name(name)\n\n        return self._renamed.get((category, name), name)\n\n    def get_attributes(self, shape):\n        \"\"\"\n        Get a dictionary of attribute names to original name and shape\n        models that represent the attributes of this resource. Looks\n        like the following:\n\n            {\n                'some_name': ('SomeName', <Shape...>)\n            }\n\n        :type shape: botocore.model.Shape\n        :param shape: The underlying shape for this resource.\n        :rtype: dict\n        :return: Mapping of resource attributes.\n        \"\"\"\n        attributes = {}\n        identifier_names = [i.name for i in self.identifiers]\n\n        for name, member in shape.members.items():\n            snake_cased = xform_name(name)\n            if snake_cased in identifier_names:\n                # Skip identifiers, these are set through other means\n                continue\n            snake_cased = self._get_name(\n                'attribute', snake_cased, snake_case=False\n            )\n            attributes[snake_cased] = (name, member)\n\n        return attributes\n\n    @property\n    def identifiers(self):\n        \"\"\"\n        Get a list of resource identifiers.\n\n        :type: list(:py:class:`Identifier`)\n        \"\"\"\n        identifiers = []\n\n        for item in self._definition.get('identifiers', []):\n            name = self._get_name('identifier', item['name'])\n            member_name = item.get('memberName', None)\n            if member_name:\n                member_name = self._get_name('attribute', member_name)\n            identifiers.append(Identifier(name, member_name))\n\n        return identifiers\n\n    @property\n    def load(self):\n        \"\"\"\n        Get the load action for this resource, if it is defined.\n\n        :type: :py:class:`Action` or ``None``\n        \"\"\"\n        action = self._definition.get('load')\n\n        if action is not None:\n            action = Action('load', action, self._resource_defs)\n\n        return action\n\n    @property\n    def actions(self):\n        \"\"\"\n        Get a list of actions for this resource.\n\n        :type: list(:py:class:`Action`)\n        \"\"\"\n        actions = []\n\n        for name, item in self._definition.get('actions', {}).items():\n            name = self._get_name('action', name)\n            actions.append(Action(name, item, self._resource_defs))\n\n        return actions\n\n    @property\n    def batch_actions(self):\n        \"\"\"\n        Get a list of batch actions for this resource.\n\n        :type: list(:py:class:`Action`)\n        \"\"\"\n        actions = []\n\n        for name, item in self._definition.get('batchActions', {}).items():\n            name = self._get_name('batch_action', name)\n            actions.append(Action(name, item, self._resource_defs))\n\n        return actions\n\n    def _get_has_definition(self):\n        \"\"\"\n        Get a ``has`` relationship definition from a model, where the\n        service resource model is treated special in that it contains\n        a relationship to every resource defined for the service. This\n        allows things like ``s3.Object('bucket-name', 'key')`` to\n        work even though the JSON doesn't define it explicitly.\n\n        :rtype: dict\n        :return: Mapping of names to subresource and reference\n                 definitions.\n        \"\"\"\n        if self.name not in self._resource_defs:\n            # This is the service resource, so let us expose all of\n            # the defined resources as subresources.\n            definition = {}\n\n            for name, resource_def in self._resource_defs.items():\n                # It's possible for the service to have renamed a\n                # resource or to have defined multiple names that\n                # point to the same resource type, so we need to\n                # take that into account.\n                found = False\n                has_items = self._definition.get('has', {}).items()\n                for has_name, has_def in has_items:\n                    if has_def.get('resource', {}).get('type') == name:\n                        definition[has_name] = has_def\n                        found = True\n\n                if not found:\n                    # Create a relationship definition and attach it\n                    # to the model, such that all identifiers must be\n                    # supplied by the user. It will look something like:\n                    #\n                    # {\n                    #   'resource': {\n                    #     'type': 'ResourceName',\n                    #     'identifiers': [\n                    #       {'target': 'Name1', 'source': 'input'},\n                    #       {'target': 'Name2', 'source': 'input'},\n                    #       ...\n                    #     ]\n                    #   }\n                    # }\n                    #\n                    fake_has = {'resource': {'type': name, 'identifiers': []}}\n\n                    for identifier in resource_def.get('identifiers', []):\n                        fake_has['resource']['identifiers'].append(\n                            {'target': identifier['name'], 'source': 'input'}\n                        )\n\n                    definition[name] = fake_has\n        else:\n            definition = self._definition.get('has', {})\n\n        return definition\n\n    def _get_related_resources(self, subresources):\n        \"\"\"\n        Get a list of sub-resources or references.\n\n        :type subresources: bool\n        :param subresources: ``True`` to get sub-resources, ``False`` to\n                             get references.\n        :rtype: list(:py:class:`Action`)\n        \"\"\"\n        resources = []\n\n        for name, definition in self._get_has_definition().items():\n            if subresources:\n                name = self._get_name('subresource', name, snake_case=False)\n            else:\n                name = self._get_name('reference', name)\n            action = Action(name, definition, self._resource_defs)\n\n            data_required = False\n            for identifier in action.resource.identifiers:\n                if identifier.source == 'data':\n                    data_required = True\n                    break\n\n            if subresources and not data_required:\n                resources.append(action)\n            elif not subresources and data_required:\n                resources.append(action)\n\n        return resources\n\n    @property\n    def subresources(self):\n        \"\"\"\n        Get a list of sub-resources.\n\n        :type: list(:py:class:`Action`)\n        \"\"\"\n        return self._get_related_resources(True)\n\n    @property\n    def references(self):\n        \"\"\"\n        Get a list of reference resources.\n\n        :type: list(:py:class:`Action`)\n        \"\"\"\n        return self._get_related_resources(False)\n\n    @property\n    def collections(self):\n        \"\"\"\n        Get a list of collections for this resource.\n\n        :type: list(:py:class:`Collection`)\n        \"\"\"\n        collections = []\n\n        for name, item in self._definition.get('hasMany', {}).items():\n            name = self._get_name('collection', name)\n            collections.append(Collection(name, item, self._resource_defs))\n\n        return collections\n\n    @property\n    def waiters(self):\n        \"\"\"\n        Get a list of waiters for this resource.\n\n        :type: list(:py:class:`Waiter`)\n        \"\"\"\n        waiters = []\n\n        for name, item in self._definition.get('waiters', {}).items():\n            name = self._get_name('waiter', Waiter.PREFIX + name)\n            waiters.append(Waiter(name, item))\n\n        return waiters\n", "boto3/resources/action.py": "# Copyright 2014 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n\nimport logging\n\nfrom botocore import xform_name\n\nfrom boto3.docs.docstring import ActionDocstring\nfrom boto3.utils import inject_attribute\n\nfrom .model import Action\nfrom .params import create_request_parameters\nfrom .response import RawHandler, ResourceHandler\n\nlogger = logging.getLogger(__name__)\n\n\nclass ServiceAction:\n    \"\"\"\n    A class representing a callable action on a resource, for example\n    ``sqs.get_queue_by_name(...)`` or ``s3.Bucket('foo').delete()``.\n    The action may construct parameters from existing resource identifiers\n    and may return either a raw response or a new resource instance.\n\n    :type action_model: :py:class`~boto3.resources.model.Action`\n    :param action_model: The action model.\n\n    :type factory: ResourceFactory\n    :param factory: The factory that created the resource class to which\n                    this action is attached.\n\n    :type service_context: :py:class:`~boto3.utils.ServiceContext`\n    :param service_context: Context about the AWS service\n    \"\"\"\n\n    def __init__(self, action_model, factory=None, service_context=None):\n        self._action_model = action_model\n\n        # In the simplest case we just return the response, but if a\n        # resource is defined, then we must create these before returning.\n        resource_response_model = action_model.resource\n        if resource_response_model:\n            self._response_handler = ResourceHandler(\n                search_path=resource_response_model.path,\n                factory=factory,\n                resource_model=resource_response_model,\n                service_context=service_context,\n                operation_name=action_model.request.operation,\n            )\n        else:\n            self._response_handler = RawHandler(action_model.path)\n\n    def __call__(self, parent, *args, **kwargs):\n        \"\"\"\n        Perform the action's request operation after building operation\n        parameters and build any defined resources from the response.\n\n        :type parent: :py:class:`~boto3.resources.base.ServiceResource`\n        :param parent: The resource instance to which this action is attached.\n        :rtype: dict or ServiceResource or list(ServiceResource)\n        :return: The response, either as a raw dict or resource instance(s).\n        \"\"\"\n        operation_name = xform_name(self._action_model.request.operation)\n\n        # First, build predefined params and then update with the\n        # user-supplied kwargs, which allows overriding the pre-built\n        # params if needed.\n        params = create_request_parameters(parent, self._action_model.request)\n        params.update(kwargs)\n\n        logger.debug(\n            'Calling %s:%s with %r',\n            parent.meta.service_name,\n            operation_name,\n            params,\n        )\n\n        response = getattr(parent.meta.client, operation_name)(*args, **params)\n\n        logger.debug('Response: %r', response)\n\n        return self._response_handler(parent, params, response)\n\n\nclass BatchAction(ServiceAction):\n    \"\"\"\n    An action which operates on a batch of items in a collection, typically\n    a single page of results from the collection's underlying service\n    operation call. For example, this allows you to delete up to 999\n    S3 objects in a single operation rather than calling ``.delete()`` on\n    each one individually.\n\n    :type action_model: :py:class`~boto3.resources.model.Action`\n    :param action_model: The action model.\n\n    :type factory: ResourceFactory\n    :param factory: The factory that created the resource class to which\n                    this action is attached.\n\n    :type service_context: :py:class:`~boto3.utils.ServiceContext`\n    :param service_context: Context about the AWS service\n    \"\"\"\n\n    def __call__(self, parent, *args, **kwargs):\n        \"\"\"\n        Perform the batch action's operation on every page of results\n        from the collection.\n\n        :type parent:\n            :py:class:`~boto3.resources.collection.ResourceCollection`\n        :param parent: The collection iterator to which this action\n                       is attached.\n        :rtype: list(dict)\n        :return: A list of low-level response dicts from each call.\n        \"\"\"\n        service_name = None\n        client = None\n        responses = []\n        operation_name = xform_name(self._action_model.request.operation)\n\n        # Unlike the simple action above, a batch action must operate\n        # on batches (or pages) of items. So we get each page, construct\n        # the necessary parameters and call the batch operation.\n        for page in parent.pages():\n            params = {}\n            for index, resource in enumerate(page):\n                # There is no public interface to get a service name\n                # or low-level client from a collection, so we get\n                # these from the first resource in the collection.\n                if service_name is None:\n                    service_name = resource.meta.service_name\n                if client is None:\n                    client = resource.meta.client\n\n                create_request_parameters(\n                    resource,\n                    self._action_model.request,\n                    params=params,\n                    index=index,\n                )\n\n            if not params:\n                # There are no items, no need to make a call.\n                break\n\n            params.update(kwargs)\n\n            logger.debug(\n                'Calling %s:%s with %r', service_name, operation_name, params\n            )\n\n            response = getattr(client, operation_name)(*args, **params)\n\n            logger.debug('Response: %r', response)\n\n            responses.append(self._response_handler(parent, params, response))\n\n        return responses\n\n\nclass WaiterAction:\n    \"\"\"\n    A class representing a callable waiter action on a resource, for example\n    ``s3.Bucket('foo').wait_until_bucket_exists()``.\n    The waiter action may construct parameters from existing resource\n    identifiers.\n\n    :type waiter_model: :py:class`~boto3.resources.model.Waiter`\n    :param waiter_model: The action waiter.\n    :type waiter_resource_name: string\n    :param waiter_resource_name: The name of the waiter action for the\n                                 resource. It usually begins with a\n                                 ``wait_until_``\n    \"\"\"\n\n    def __init__(self, waiter_model, waiter_resource_name):\n        self._waiter_model = waiter_model\n        self._waiter_resource_name = waiter_resource_name\n\n    def __call__(self, parent, *args, **kwargs):\n        \"\"\"\n        Perform the wait operation after building operation\n        parameters.\n\n        :type parent: :py:class:`~boto3.resources.base.ServiceResource`\n        :param parent: The resource instance to which this action is attached.\n        \"\"\"\n        client_waiter_name = xform_name(self._waiter_model.waiter_name)\n\n        # First, build predefined params and then update with the\n        # user-supplied kwargs, which allows overriding the pre-built\n        # params if needed.\n        params = create_request_parameters(parent, self._waiter_model)\n        params.update(kwargs)\n\n        logger.debug(\n            'Calling %s:%s with %r',\n            parent.meta.service_name,\n            self._waiter_resource_name,\n            params,\n        )\n\n        client = parent.meta.client\n        waiter = client.get_waiter(client_waiter_name)\n        response = waiter.wait(**params)\n\n        logger.debug('Response: %r', response)\n\n\nclass CustomModeledAction:\n    \"\"\"A custom, modeled action to inject into a resource.\"\"\"\n\n    def __init__(self, action_name, action_model, function, event_emitter):\n        \"\"\"\n        :type action_name: str\n        :param action_name: The name of the action to inject, e.g.\n            'delete_tags'\n\n        :type action_model: dict\n        :param action_model: A JSON definition of the action, as if it were\n            part of the resource model.\n\n        :type function: function\n        :param function: The function to perform when the action is called.\n            The first argument should be 'self', which will be the resource\n            the function is to be called on.\n\n        :type event_emitter: :py:class:`botocore.hooks.BaseEventHooks`\n        :param event_emitter: The session event emitter.\n        \"\"\"\n        self.name = action_name\n        self.model = action_model\n        self.function = function\n        self.emitter = event_emitter\n\n    def inject(self, class_attributes, service_context, event_name, **kwargs):\n        resource_name = event_name.rsplit(\".\")[-1]\n        action = Action(self.name, self.model, {})\n        self.function.__name__ = self.name\n        self.function.__doc__ = ActionDocstring(\n            resource_name=resource_name,\n            event_emitter=self.emitter,\n            action_model=action,\n            service_model=service_context.service_model,\n            include_signature=False,\n        )\n        inject_attribute(class_attributes, self.name, self.function)\n", "boto3/resources/factory.py": "# Copyright 2014 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n\nimport logging\nfrom functools import partial\n\nfrom ..docs import docstring\nfrom ..exceptions import ResourceLoadException\nfrom .action import ServiceAction, WaiterAction\nfrom .base import ResourceMeta, ServiceResource\nfrom .collection import CollectionFactory\nfrom .model import ResourceModel\nfrom .response import ResourceHandler, build_identifiers\n\nlogger = logging.getLogger(__name__)\n\n\nclass ResourceFactory:\n    \"\"\"\n    A factory to create new :py:class:`~boto3.resources.base.ServiceResource`\n    classes from a :py:class:`~boto3.resources.model.ResourceModel`. There are\n    two types of lookups that can be done: one on the service itself (e.g. an\n    SQS resource) and another on models contained within the service (e.g. an\n    SQS Queue resource).\n    \"\"\"\n\n    def __init__(self, emitter):\n        self._collection_factory = CollectionFactory()\n        self._emitter = emitter\n\n    def load_from_definition(\n        self, resource_name, single_resource_json_definition, service_context\n    ):\n        \"\"\"\n        Loads a resource from a model, creating a new\n        :py:class:`~boto3.resources.base.ServiceResource` subclass\n        with the correct properties and methods, named based on the service\n        and resource name, e.g. EC2.Instance.\n\n        :type resource_name: string\n        :param resource_name: Name of the resource to look up. For services,\n                              this should match the ``service_name``.\n\n        :type single_resource_json_definition: dict\n        :param single_resource_json_definition:\n            The loaded json of a single service resource or resource\n            definition.\n\n        :type service_context: :py:class:`~boto3.utils.ServiceContext`\n        :param service_context: Context about the AWS service\n\n        :rtype: Subclass of :py:class:`~boto3.resources.base.ServiceResource`\n        :return: The service or resource class.\n        \"\"\"\n        logger.debug(\n            'Loading %s:%s', service_context.service_name, resource_name\n        )\n\n        # Using the loaded JSON create a ResourceModel object.\n        resource_model = ResourceModel(\n            resource_name,\n            single_resource_json_definition,\n            service_context.resource_json_definitions,\n        )\n\n        # Do some renaming of the shape if there was a naming collision\n        # that needed to be accounted for.\n        shape = None\n        if resource_model.shape:\n            shape = service_context.service_model.shape_for(\n                resource_model.shape\n            )\n        resource_model.load_rename_map(shape)\n\n        # Set some basic info\n        meta = ResourceMeta(\n            service_context.service_name, resource_model=resource_model\n        )\n        attrs = {\n            'meta': meta,\n        }\n\n        # Create and load all of attributes of the resource class based\n        # on the models.\n\n        # Identifiers\n        self._load_identifiers(\n            attrs=attrs,\n            meta=meta,\n            resource_name=resource_name,\n            resource_model=resource_model,\n        )\n\n        # Load/Reload actions\n        self._load_actions(\n            attrs=attrs,\n            resource_name=resource_name,\n            resource_model=resource_model,\n            service_context=service_context,\n        )\n\n        # Attributes that get auto-loaded\n        self._load_attributes(\n            attrs=attrs,\n            meta=meta,\n            resource_name=resource_name,\n            resource_model=resource_model,\n            service_context=service_context,\n        )\n\n        # Collections and their corresponding methods\n        self._load_collections(\n            attrs=attrs,\n            resource_model=resource_model,\n            service_context=service_context,\n        )\n\n        # References and Subresources\n        self._load_has_relations(\n            attrs=attrs,\n            resource_name=resource_name,\n            resource_model=resource_model,\n            service_context=service_context,\n        )\n\n        # Waiter resource actions\n        self._load_waiters(\n            attrs=attrs,\n            resource_name=resource_name,\n            resource_model=resource_model,\n            service_context=service_context,\n        )\n\n        # Create the name based on the requested service and resource\n        cls_name = resource_name\n        if service_context.service_name == resource_name:\n            cls_name = 'ServiceResource'\n        cls_name = service_context.service_name + '.' + cls_name\n\n        base_classes = [ServiceResource]\n        if self._emitter is not None:\n            self._emitter.emit(\n                f'creating-resource-class.{cls_name}',\n                class_attributes=attrs,\n                base_classes=base_classes,\n                service_context=service_context,\n            )\n        return type(str(cls_name), tuple(base_classes), attrs)\n\n    def _load_identifiers(self, attrs, meta, resource_model, resource_name):\n        \"\"\"\n        Populate required identifiers. These are arguments without which\n        the resource cannot be used. Identifiers become arguments for\n        operations on the resource.\n        \"\"\"\n        for identifier in resource_model.identifiers:\n            meta.identifiers.append(identifier.name)\n            attrs[identifier.name] = self._create_identifier(\n                identifier, resource_name\n            )\n\n    def _load_actions(\n        self, attrs, resource_name, resource_model, service_context\n    ):\n        \"\"\"\n        Actions on the resource become methods, with the ``load`` method\n        being a special case which sets internal data for attributes, and\n        ``reload`` is an alias for ``load``.\n        \"\"\"\n        if resource_model.load:\n            attrs['load'] = self._create_action(\n                action_model=resource_model.load,\n                resource_name=resource_name,\n                service_context=service_context,\n                is_load=True,\n            )\n            attrs['reload'] = attrs['load']\n\n        for action in resource_model.actions:\n            attrs[action.name] = self._create_action(\n                action_model=action,\n                resource_name=resource_name,\n                service_context=service_context,\n            )\n\n    def _load_attributes(\n        self, attrs, meta, resource_name, resource_model, service_context\n    ):\n        \"\"\"\n        Load resource attributes based on the resource shape. The shape\n        name is referenced in the resource JSON, but the shape itself\n        is defined in the Botocore service JSON, hence the need for\n        access to the ``service_model``.\n        \"\"\"\n        if not resource_model.shape:\n            return\n\n        shape = service_context.service_model.shape_for(resource_model.shape)\n\n        identifiers = {\n            i.member_name: i\n            for i in resource_model.identifiers\n            if i.member_name\n        }\n        attributes = resource_model.get_attributes(shape)\n        for name, (orig_name, member) in attributes.items():\n            if name in identifiers:\n                prop = self._create_identifier_alias(\n                    resource_name=resource_name,\n                    identifier=identifiers[name],\n                    member_model=member,\n                    service_context=service_context,\n                )\n            else:\n                prop = self._create_autoload_property(\n                    resource_name=resource_name,\n                    name=orig_name,\n                    snake_cased=name,\n                    member_model=member,\n                    service_context=service_context,\n                )\n            attrs[name] = prop\n\n    def _load_collections(self, attrs, resource_model, service_context):\n        \"\"\"\n        Load resource collections from the model. Each collection becomes\n        a :py:class:`~boto3.resources.collection.CollectionManager` instance\n        on the resource instance, which allows you to iterate and filter\n        through the collection's items.\n        \"\"\"\n        for collection_model in resource_model.collections:\n            attrs[collection_model.name] = self._create_collection(\n                resource_name=resource_model.name,\n                collection_model=collection_model,\n                service_context=service_context,\n            )\n\n    def _load_has_relations(\n        self, attrs, resource_name, resource_model, service_context\n    ):\n        \"\"\"\n        Load related resources, which are defined via a ``has``\n        relationship but conceptually come in two forms:\n\n        1. A reference, which is a related resource instance and can be\n           ``None``, such as an EC2 instance's ``vpc``.\n        2. A subresource, which is a resource constructor that will always\n           return a resource instance which shares identifiers/data with\n           this resource, such as ``s3.Bucket('name').Object('key')``.\n        \"\"\"\n        for reference in resource_model.references:\n            # This is a dangling reference, i.e. we have all\n            # the data we need to create the resource, so\n            # this instance becomes an attribute on the class.\n            attrs[reference.name] = self._create_reference(\n                reference_model=reference,\n                resource_name=resource_name,\n                service_context=service_context,\n            )\n\n        for subresource in resource_model.subresources:\n            # This is a sub-resource class you can create\n            # by passing in an identifier, e.g. s3.Bucket(name).\n            attrs[subresource.name] = self._create_class_partial(\n                subresource_model=subresource,\n                resource_name=resource_name,\n                service_context=service_context,\n            )\n\n        self._create_available_subresources_command(\n            attrs, resource_model.subresources\n        )\n\n    def _create_available_subresources_command(self, attrs, subresources):\n        _subresources = [subresource.name for subresource in subresources]\n        _subresources = sorted(_subresources)\n\n        def get_available_subresources(factory_self):\n            \"\"\"\n            Returns a list of all the available sub-resources for this\n            Resource.\n\n            :returns: A list containing the name of each sub-resource for this\n                resource\n            :rtype: list of str\n            \"\"\"\n            return _subresources\n\n        attrs['get_available_subresources'] = get_available_subresources\n\n    def _load_waiters(\n        self, attrs, resource_name, resource_model, service_context\n    ):\n        \"\"\"\n        Load resource waiters from the model. Each waiter allows you to\n        wait until a resource reaches a specific state by polling the state\n        of the resource.\n        \"\"\"\n        for waiter in resource_model.waiters:\n            attrs[waiter.name] = self._create_waiter(\n                resource_waiter_model=waiter,\n                resource_name=resource_name,\n                service_context=service_context,\n            )\n\n    def _create_identifier(factory_self, identifier, resource_name):\n        \"\"\"\n        Creates a read-only property for identifier attributes.\n        \"\"\"\n\n        def get_identifier(self):\n            # The default value is set to ``None`` instead of\n            # raising an AttributeError because when resources are\n            # instantiated a check is made such that none of the\n            # identifiers have a value ``None``. If any are ``None``,\n            # a more informative user error than a generic AttributeError\n            # is raised.\n            return getattr(self, '_' + identifier.name, None)\n\n        get_identifier.__name__ = str(identifier.name)\n        get_identifier.__doc__ = docstring.IdentifierDocstring(\n            resource_name=resource_name,\n            identifier_model=identifier,\n            include_signature=False,\n        )\n\n        return property(get_identifier)\n\n    def _create_identifier_alias(\n        factory_self, resource_name, identifier, member_model, service_context\n    ):\n        \"\"\"\n        Creates a read-only property that aliases an identifier.\n        \"\"\"\n\n        def get_identifier(self):\n            return getattr(self, '_' + identifier.name, None)\n\n        get_identifier.__name__ = str(identifier.member_name)\n        get_identifier.__doc__ = docstring.AttributeDocstring(\n            service_name=service_context.service_name,\n            resource_name=resource_name,\n            attr_name=identifier.member_name,\n            event_emitter=factory_self._emitter,\n            attr_model=member_model,\n            include_signature=False,\n        )\n\n        return property(get_identifier)\n\n    def _create_autoload_property(\n        factory_self,\n        resource_name,\n        name,\n        snake_cased,\n        member_model,\n        service_context,\n    ):\n        \"\"\"\n        Creates a new property on the resource to lazy-load its value\n        via the resource's ``load`` method (if it exists).\n        \"\"\"\n\n        # The property loader will check to see if this resource has already\n        # been loaded and return the cached value if possible. If not, then\n        # it first checks to see if it CAN be loaded (raise if not), then\n        # calls the load before returning the value.\n        def property_loader(self):\n            if self.meta.data is None:\n                if hasattr(self, 'load'):\n                    self.load()\n                else:\n                    raise ResourceLoadException(\n                        f'{self.__class__.__name__} has no load method'\n                    )\n\n            return self.meta.data.get(name)\n\n        property_loader.__name__ = str(snake_cased)\n        property_loader.__doc__ = docstring.AttributeDocstring(\n            service_name=service_context.service_name,\n            resource_name=resource_name,\n            attr_name=snake_cased,\n            event_emitter=factory_self._emitter,\n            attr_model=member_model,\n            include_signature=False,\n        )\n\n        return property(property_loader)\n\n    def _create_waiter(\n        factory_self, resource_waiter_model, resource_name, service_context\n    ):\n        \"\"\"\n        Creates a new wait method for each resource where both a waiter and\n        resource model is defined.\n        \"\"\"\n        waiter = WaiterAction(\n            resource_waiter_model,\n            waiter_resource_name=resource_waiter_model.name,\n        )\n\n        def do_waiter(self, *args, **kwargs):\n            waiter(self, *args, **kwargs)\n\n        do_waiter.__name__ = str(resource_waiter_model.name)\n        do_waiter.__doc__ = docstring.ResourceWaiterDocstring(\n            resource_name=resource_name,\n            event_emitter=factory_self._emitter,\n            service_model=service_context.service_model,\n            resource_waiter_model=resource_waiter_model,\n            service_waiter_model=service_context.service_waiter_model,\n            include_signature=False,\n        )\n        return do_waiter\n\n    def _create_collection(\n        factory_self, resource_name, collection_model, service_context\n    ):\n        \"\"\"\n        Creates a new property on the resource to lazy-load a collection.\n        \"\"\"\n        cls = factory_self._collection_factory.load_from_definition(\n            resource_name=resource_name,\n            collection_model=collection_model,\n            service_context=service_context,\n            event_emitter=factory_self._emitter,\n        )\n\n        def get_collection(self):\n            return cls(\n                collection_model=collection_model,\n                parent=self,\n                factory=factory_self,\n                service_context=service_context,\n            )\n\n        get_collection.__name__ = str(collection_model.name)\n        get_collection.__doc__ = docstring.CollectionDocstring(\n            collection_model=collection_model, include_signature=False\n        )\n        return property(get_collection)\n\n    def _create_reference(\n        factory_self, reference_model, resource_name, service_context\n    ):\n        \"\"\"\n        Creates a new property on the resource to lazy-load a reference.\n        \"\"\"\n        # References are essentially an action with no request\n        # or response, so we can re-use the response handlers to\n        # build up resources from identifiers and data members.\n        handler = ResourceHandler(\n            search_path=reference_model.resource.path,\n            factory=factory_self,\n            resource_model=reference_model.resource,\n            service_context=service_context,\n        )\n\n        # Are there any identifiers that need access to data members?\n        # This is important when building the resource below since\n        # it requires the data to be loaded.\n        needs_data = any(\n            i.source == 'data' for i in reference_model.resource.identifiers\n        )\n\n        def get_reference(self):\n            # We need to lazy-evaluate the reference to handle circular\n            # references between resources. We do this by loading the class\n            # when first accessed.\n            # This is using a *response handler* so we need to make sure\n            # our data is loaded (if possible) and pass that data into\n            # the handler as if it were a response. This allows references\n            # to have their data loaded properly.\n            if needs_data and self.meta.data is None and hasattr(self, 'load'):\n                self.load()\n            return handler(self, {}, self.meta.data)\n\n        get_reference.__name__ = str(reference_model.name)\n        get_reference.__doc__ = docstring.ReferenceDocstring(\n            reference_model=reference_model, include_signature=False\n        )\n        return property(get_reference)\n\n    def _create_class_partial(\n        factory_self, subresource_model, resource_name, service_context\n    ):\n        \"\"\"\n        Creates a new method which acts as a functools.partial, passing\n        along the instance's low-level `client` to the new resource\n        class' constructor.\n        \"\"\"\n        name = subresource_model.resource.type\n\n        def create_resource(self, *args, **kwargs):\n            # We need a new method here because we want access to the\n            # instance's client.\n            positional_args = []\n\n            # We lazy-load the class to handle circular references.\n            json_def = service_context.resource_json_definitions.get(name, {})\n            resource_cls = factory_self.load_from_definition(\n                resource_name=name,\n                single_resource_json_definition=json_def,\n                service_context=service_context,\n            )\n\n            # Assumes that identifiers are in order, which lets you do\n            # e.g. ``sqs.Queue('foo').Message('bar')`` to create a new message\n            # linked with the ``foo`` queue and which has a ``bar`` receipt\n            # handle. If we did kwargs here then future positional arguments\n            # would lead to failure.\n            identifiers = subresource_model.resource.identifiers\n            if identifiers is not None:\n                for identifier, value in build_identifiers(identifiers, self):\n                    positional_args.append(value)\n\n            return partial(\n                resource_cls, *positional_args, client=self.meta.client\n            )(*args, **kwargs)\n\n        create_resource.__name__ = str(name)\n        create_resource.__doc__ = docstring.SubResourceDocstring(\n            resource_name=resource_name,\n            sub_resource_model=subresource_model,\n            service_model=service_context.service_model,\n            include_signature=False,\n        )\n        return create_resource\n\n    def _create_action(\n        factory_self,\n        action_model,\n        resource_name,\n        service_context,\n        is_load=False,\n    ):\n        \"\"\"\n        Creates a new method which makes a request to the underlying\n        AWS service.\n        \"\"\"\n        # Create the action in in this closure but before the ``do_action``\n        # method below is invoked, which allows instances of the resource\n        # to share the ServiceAction instance.\n        action = ServiceAction(\n            action_model, factory=factory_self, service_context=service_context\n        )\n\n        # A resource's ``load`` method is special because it sets\n        # values on the resource instead of returning the response.\n        if is_load:\n            # We need a new method here because we want access to the\n            # instance via ``self``.\n            def do_action(self, *args, **kwargs):\n                response = action(self, *args, **kwargs)\n                self.meta.data = response\n\n            # Create the docstring for the load/reload methods.\n            lazy_docstring = docstring.LoadReloadDocstring(\n                action_name=action_model.name,\n                resource_name=resource_name,\n                event_emitter=factory_self._emitter,\n                load_model=action_model,\n                service_model=service_context.service_model,\n                include_signature=False,\n            )\n        else:\n            # We need a new method here because we want access to the\n            # instance via ``self``.\n            def do_action(self, *args, **kwargs):\n                response = action(self, *args, **kwargs)\n\n                if hasattr(self, 'load'):\n                    # Clear cached data. It will be reloaded the next\n                    # time that an attribute is accessed.\n                    # TODO: Make this configurable in the future?\n                    self.meta.data = None\n\n                return response\n\n            lazy_docstring = docstring.ActionDocstring(\n                resource_name=resource_name,\n                event_emitter=factory_self._emitter,\n                action_model=action_model,\n                service_model=service_context.service_model,\n                include_signature=False,\n            )\n\n        do_action.__name__ = str(action_model.name)\n        do_action.__doc__ = lazy_docstring\n        return do_action\n", "boto3/resources/base.py": "# Copyright 2014 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n\nimport logging\n\nimport boto3\n\nlogger = logging.getLogger(__name__)\n\n\nclass ResourceMeta:\n    \"\"\"\n    An object containing metadata about a resource.\n    \"\"\"\n\n    def __init__(\n        self,\n        service_name,\n        identifiers=None,\n        client=None,\n        data=None,\n        resource_model=None,\n    ):\n        #: (``string``) The service name, e.g. 's3'\n        self.service_name = service_name\n\n        if identifiers is None:\n            identifiers = []\n        #: (``list``) List of identifier names\n        self.identifiers = identifiers\n\n        #: (:py:class:`~botocore.client.BaseClient`) Low-level Botocore client\n        self.client = client\n        #: (``dict``) Loaded resource data attributes\n        self.data = data\n\n        # The resource model for that resource\n        self.resource_model = resource_model\n\n    def __repr__(self):\n        return f'ResourceMeta(\\'{self.service_name}\\', identifiers={self.identifiers})'\n\n    def __eq__(self, other):\n        # Two metas are equal if their components are all equal\n        if other.__class__.__name__ != self.__class__.__name__:\n            return False\n\n        return self.__dict__ == other.__dict__\n\n    def copy(self):\n        \"\"\"\n        Create a copy of this metadata object.\n        \"\"\"\n        params = self.__dict__.copy()\n        service_name = params.pop('service_name')\n        return ResourceMeta(service_name, **params)\n\n\nclass ServiceResource:\n    \"\"\"\n    A base class for resources.\n\n    :type client: botocore.client\n    :param client: A low-level Botocore client instance\n    \"\"\"\n\n    meta = None\n    \"\"\"\n    Stores metadata about this resource instance, such as the\n    ``service_name``, the low-level ``client`` and any cached ``data``\n    from when the instance was hydrated. For example::\n\n        # Get a low-level client from a resource instance\n        client = resource.meta.client\n        response = client.operation(Param='foo')\n\n        # Print the resource instance's service short name\n        print(resource.meta.service_name)\n\n    See :py:class:`ResourceMeta` for more information.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        # Always work on a copy of meta, otherwise we would affect other\n        # instances of the same subclass.\n        self.meta = self.meta.copy()\n\n        # Create a default client if none was passed\n        if kwargs.get('client') is not None:\n            self.meta.client = kwargs.get('client')\n        else:\n            self.meta.client = boto3.client(self.meta.service_name)\n\n        # Allow setting identifiers as positional arguments in the order\n        # in which they were defined in the ResourceJSON.\n        for i, value in enumerate(args):\n            setattr(self, '_' + self.meta.identifiers[i], value)\n\n        # Allow setting identifiers via keyword arguments. Here we need\n        # extra logic to ignore other keyword arguments like ``client``.\n        for name, value in kwargs.items():\n            if name == 'client':\n                continue\n\n            if name not in self.meta.identifiers:\n                raise ValueError(f'Unknown keyword argument: {name}')\n\n            setattr(self, '_' + name, value)\n\n        # Validate that all identifiers have been set.\n        for identifier in self.meta.identifiers:\n            if getattr(self, identifier) is None:\n                raise ValueError(f'Required parameter {identifier} not set')\n\n    def __repr__(self):\n        identifiers = []\n        for identifier in self.meta.identifiers:\n            identifiers.append(\n                f'{identifier}={repr(getattr(self, identifier))}'\n            )\n        return \"{}({})\".format(\n            self.__class__.__name__,\n            ', '.join(identifiers),\n        )\n\n    def __eq__(self, other):\n        # Should be instances of the same resource class\n        if other.__class__.__name__ != self.__class__.__name__:\n            return False\n\n        # Each of the identifiers should have the same value in both\n        # instances, e.g. two buckets need the same name to be equal.\n        for identifier in self.meta.identifiers:\n            if getattr(self, identifier) != getattr(other, identifier):\n                return False\n\n        return True\n\n    def __hash__(self):\n        identifiers = []\n        for identifier in self.meta.identifiers:\n            identifiers.append(getattr(self, identifier))\n        return hash((self.__class__.__name__, tuple(identifiers)))\n", "boto3/resources/params.py": "# Copyright 2014 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n\nimport re\n\nimport jmespath\nfrom botocore import xform_name\n\nfrom ..exceptions import ResourceLoadException\n\nINDEX_RE = re.compile(r'\\[(.*)\\]$')\n\n\ndef get_data_member(parent, path):\n    \"\"\"\n    Get a data member from a parent using a JMESPath search query,\n    loading the parent if required. If the parent cannot be loaded\n    and no data is present then an exception is raised.\n\n    :type parent: ServiceResource\n    :param parent: The resource instance to which contains data we\n                   are interested in.\n    :type path: string\n    :param path: The JMESPath expression to query\n    :raises ResourceLoadException: When no data is present and the\n                                   resource cannot be loaded.\n    :returns: The queried data or ``None``.\n    \"\"\"\n    # Ensure the parent has its data loaded, if possible.\n    if parent.meta.data is None:\n        if hasattr(parent, 'load'):\n            parent.load()\n        else:\n            raise ResourceLoadException(\n                f'{parent.__class__.__name__} has no load method!'\n            )\n\n    return jmespath.search(path, parent.meta.data)\n\n\ndef create_request_parameters(parent, request_model, params=None, index=None):\n    \"\"\"\n    Handle request parameters that can be filled in from identifiers,\n    resource data members or constants.\n\n    By passing ``params``, you can invoke this method multiple times and\n    build up a parameter dict over time, which is particularly useful\n    for reverse JMESPath expressions that append to lists.\n\n    :type parent: ServiceResource\n    :param parent: The resource instance to which this action is attached.\n    :type request_model: :py:class:`~boto3.resources.model.Request`\n    :param request_model: The action request model.\n    :type params: dict\n    :param params: If set, then add to this existing dict. It is both\n                   edited in-place and returned.\n    :type index: int\n    :param index: The position of an item within a list\n    :rtype: dict\n    :return: Pre-filled parameters to be sent to the request operation.\n    \"\"\"\n    if params is None:\n        params = {}\n\n    for param in request_model.params:\n        source = param.source\n        target = param.target\n\n        if source == 'identifier':\n            # Resource identifier, e.g. queue.url\n            value = getattr(parent, xform_name(param.name))\n        elif source == 'data':\n            # If this is a data member then it may incur a load\n            # action before returning the value.\n            value = get_data_member(parent, param.path)\n        elif source in ['string', 'integer', 'boolean']:\n            # These are hard-coded values in the definition\n            value = param.value\n        elif source == 'input':\n            # This is provided by the user, so ignore it here\n            continue\n        else:\n            raise NotImplementedError(f'Unsupported source type: {source}')\n\n        build_param_structure(params, target, value, index)\n\n    return params\n\n\ndef build_param_structure(params, target, value, index=None):\n    \"\"\"\n    This method provides a basic reverse JMESPath implementation that\n    lets you go from a JMESPath-like string to a possibly deeply nested\n    object. The ``params`` are mutated in-place, so subsequent calls\n    can modify the same element by its index.\n\n        >>> build_param_structure(params, 'test[0]', 1)\n        >>> print(params)\n        {'test': [1]}\n\n        >>> build_param_structure(params, 'foo.bar[0].baz', 'hello world')\n        >>> print(params)\n        {'test': [1], 'foo': {'bar': [{'baz': 'hello, world'}]}}\n\n    \"\"\"\n    pos = params\n    parts = target.split('.')\n\n    # First, split into parts like 'foo', 'bar[0]', 'baz' and process\n    # each piece. It can either be a list or a dict, depending on if\n    # an index like `[0]` is present. We detect this via a regular\n    # expression, and keep track of where we are in params via the\n    # pos variable, walking down to the last item. Once there, we\n    # set the value.\n    for i, part in enumerate(parts):\n        # Is it indexing an array?\n        result = INDEX_RE.search(part)\n        if result:\n            if result.group(1):\n                if result.group(1) == '*':\n                    part = part[:-3]\n                else:\n                    # We have an explicit index\n                    index = int(result.group(1))\n                    part = part[: -len(str(index) + '[]')]\n            else:\n                # Index will be set after we know the proper part\n                # name and that it's a list instance.\n                index = None\n                part = part[:-2]\n\n            if part not in pos or not isinstance(pos[part], list):\n                pos[part] = []\n\n            # This means we should append, e.g. 'foo[]'\n            if index is None:\n                index = len(pos[part])\n\n            while len(pos[part]) <= index:\n                # Assume it's a dict until we set the final value below\n                pos[part].append({})\n\n            # Last item? Set the value, otherwise set the new position\n            if i == len(parts) - 1:\n                pos[part][index] = value\n            else:\n                # The new pos is the *item* in the array, not the array!\n                pos = pos[part][index]\n        else:\n            if part not in pos:\n                pos[part] = {}\n\n            # Last item? Set the value, otherwise set the new position\n            if i == len(parts) - 1:\n                pos[part] = value\n            else:\n                pos = pos[part]\n", "boto3/resources/collection.py": "# Copyright 2014 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n\nimport copy\nimport logging\n\nfrom botocore import xform_name\nfrom botocore.utils import merge_dicts\n\nfrom ..docs import docstring\nfrom .action import BatchAction\nfrom .params import create_request_parameters\nfrom .response import ResourceHandler\n\nlogger = logging.getLogger(__name__)\n\n\nclass ResourceCollection:\n    \"\"\"\n    Represents a collection of resources, which can be iterated through,\n    optionally with filtering. Collections automatically handle pagination\n    for you.\n\n    See :ref:`guide_collections` for a high-level overview of collections,\n    including when remote service requests are performed.\n\n    :type model: :py:class:`~boto3.resources.model.Collection`\n    :param model: Collection model\n    :type parent: :py:class:`~boto3.resources.base.ServiceResource`\n    :param parent: The collection's parent resource\n    :type handler: :py:class:`~boto3.resources.response.ResourceHandler`\n    :param handler: The resource response handler used to create resource\n                    instances\n    \"\"\"\n\n    def __init__(self, model, parent, handler, **kwargs):\n        self._model = model\n        self._parent = parent\n        self._py_operation_name = xform_name(model.request.operation)\n        self._handler = handler\n        self._params = copy.deepcopy(kwargs)\n\n    def __repr__(self):\n        return '{}({}, {})'.format(\n            self.__class__.__name__,\n            self._parent,\n            f'{self._parent.meta.service_name}.{self._model.resource.type}',\n        )\n\n    def __iter__(self):\n        \"\"\"\n        A generator which yields resource instances after doing the\n        appropriate service operation calls and handling any pagination\n        on your behalf.\n\n        Page size, item limit, and filter parameters are applied\n        if they have previously been set.\n\n            >>> bucket = s3.Bucket('boto3')\n            >>> for obj in bucket.objects.all():\n            ...     print(obj.key)\n            'key1'\n            'key2'\n\n        \"\"\"\n        limit = self._params.get('limit', None)\n\n        count = 0\n        for page in self.pages():\n            for item in page:\n                yield item\n\n                # If the limit is set and has been reached, then\n                # we stop processing items here.\n                count += 1\n                if limit is not None and count >= limit:\n                    return\n\n    def _clone(self, **kwargs):\n        \"\"\"\n        Create a clone of this collection. This is used by the methods\n        below to provide a chainable interface that returns copies\n        rather than the original. This allows things like:\n\n            >>> base = collection.filter(Param1=1)\n            >>> query1 = base.filter(Param2=2)\n            >>> query2 = base.filter(Param3=3)\n            >>> query1.params\n            {'Param1': 1, 'Param2': 2}\n            >>> query2.params\n            {'Param1': 1, 'Param3': 3}\n\n        :rtype: :py:class:`ResourceCollection`\n        :return: A clone of this resource collection\n        \"\"\"\n        params = copy.deepcopy(self._params)\n        merge_dicts(params, kwargs, append_lists=True)\n        clone = self.__class__(\n            self._model, self._parent, self._handler, **params\n        )\n        return clone\n\n    def pages(self):\n        \"\"\"\n        A generator which yields pages of resource instances after\n        doing the appropriate service operation calls and handling\n        any pagination on your behalf. Non-paginated calls will\n        return a single page of items.\n\n        Page size, item limit, and filter parameters are applied\n        if they have previously been set.\n\n            >>> bucket = s3.Bucket('boto3')\n            >>> for page in bucket.objects.pages():\n            ...     for obj in page:\n            ...         print(obj.key)\n            'key1'\n            'key2'\n\n        :rtype: list(:py:class:`~boto3.resources.base.ServiceResource`)\n        :return: List of resource instances\n        \"\"\"\n        client = self._parent.meta.client\n        cleaned_params = self._params.copy()\n        limit = cleaned_params.pop('limit', None)\n        page_size = cleaned_params.pop('page_size', None)\n        params = create_request_parameters(self._parent, self._model.request)\n        merge_dicts(params, cleaned_params, append_lists=True)\n\n        # Is this a paginated operation? If so, we need to get an\n        # iterator for the various pages. If not, then we simply\n        # call the operation and return the result as a single\n        # page in a list. For non-paginated results, we just ignore\n        # the page size parameter.\n        if client.can_paginate(self._py_operation_name):\n            logger.debug(\n                'Calling paginated %s:%s with %r',\n                self._parent.meta.service_name,\n                self._py_operation_name,\n                params,\n            )\n            paginator = client.get_paginator(self._py_operation_name)\n            pages = paginator.paginate(\n                PaginationConfig={'MaxItems': limit, 'PageSize': page_size},\n                **params,\n            )\n        else:\n            logger.debug(\n                'Calling %s:%s with %r',\n                self._parent.meta.service_name,\n                self._py_operation_name,\n                params,\n            )\n            pages = [getattr(client, self._py_operation_name)(**params)]\n\n        # Now that we have a page iterator or single page of results\n        # we start processing and yielding individual items.\n        count = 0\n        for page in pages:\n            page_items = []\n            for item in self._handler(self._parent, params, page):\n                page_items.append(item)\n\n                # If the limit is set and has been reached, then\n                # we stop processing items here.\n                count += 1\n                if limit is not None and count >= limit:\n                    break\n\n            yield page_items\n\n            # Stop reading pages if we've reached out limit\n            if limit is not None and count >= limit:\n                break\n\n    def all(self):\n        \"\"\"\n        Get all items from the collection, optionally with a custom\n        page size and item count limit.\n\n        This method returns an iterable generator which yields\n        individual resource instances. Example use::\n\n            # Iterate through items\n            >>> for queue in sqs.queues.all():\n            ...     print(queue.url)\n            'https://url1'\n            'https://url2'\n\n            # Convert to list\n            >>> queues = list(sqs.queues.all())\n            >>> len(queues)\n            2\n        \"\"\"\n        return self._clone()\n\n    def filter(self, **kwargs):\n        \"\"\"\n        Get items from the collection, passing keyword arguments along\n        as parameters to the underlying service operation, which are\n        typically used to filter the results.\n\n        This method returns an iterable generator which yields\n        individual resource instances. Example use::\n\n            # Iterate through items\n            >>> for queue in sqs.queues.filter(Param='foo'):\n            ...     print(queue.url)\n            'https://url1'\n            'https://url2'\n\n            # Convert to list\n            >>> queues = list(sqs.queues.filter(Param='foo'))\n            >>> len(queues)\n            2\n\n        :rtype: :py:class:`ResourceCollection`\n        \"\"\"\n        return self._clone(**kwargs)\n\n    def limit(self, count):\n        \"\"\"\n        Return at most this many resources.\n\n            >>> for bucket in s3.buckets.limit(5):\n            ...     print(bucket.name)\n            'bucket1'\n            'bucket2'\n            'bucket3'\n            'bucket4'\n            'bucket5'\n\n        :type count: int\n        :param count: Return no more than this many items\n        :rtype: :py:class:`ResourceCollection`\n        \"\"\"\n        return self._clone(limit=count)\n\n    def page_size(self, count):\n        \"\"\"\n        Fetch at most this many resources per service request.\n\n            >>> for obj in s3.Bucket('boto3').objects.page_size(100):\n            ...     print(obj.key)\n\n        :type count: int\n        :param count: Fetch this many items per request\n        :rtype: :py:class:`ResourceCollection`\n        \"\"\"\n        return self._clone(page_size=count)\n\n\nclass CollectionManager:\n    \"\"\"\n    A collection manager provides access to resource collection instances,\n    which can be iterated and filtered. The manager exposes some\n    convenience functions that are also found on resource collections,\n    such as :py:meth:`~ResourceCollection.all` and\n    :py:meth:`~ResourceCollection.filter`.\n\n    Get all items::\n\n        >>> for bucket in s3.buckets.all():\n        ...     print(bucket.name)\n\n    Get only some items via filtering::\n\n        >>> for queue in sqs.queues.filter(QueueNamePrefix='AWS'):\n        ...     print(queue.url)\n\n    Get whole pages of items:\n\n        >>> for page in s3.Bucket('boto3').objects.pages():\n        ...     for obj in page:\n        ...         print(obj.key)\n\n    A collection manager is not iterable. You **must** call one of the\n    methods that return a :py:class:`ResourceCollection` before trying\n    to iterate, slice, or convert to a list.\n\n    See the :ref:`guide_collections` guide for a high-level overview\n    of collections, including when remote service requests are performed.\n\n    :type collection_model: :py:class:`~boto3.resources.model.Collection`\n    :param model: Collection model\n\n    :type parent: :py:class:`~boto3.resources.base.ServiceResource`\n    :param parent: The collection's parent resource\n\n    :type factory: :py:class:`~boto3.resources.factory.ResourceFactory`\n    :param factory: The resource factory to create new resources\n\n    :type service_context: :py:class:`~boto3.utils.ServiceContext`\n    :param service_context: Context about the AWS service\n    \"\"\"\n\n    # The class to use when creating an iterator\n    _collection_cls = ResourceCollection\n\n    def __init__(self, collection_model, parent, factory, service_context):\n        self._model = collection_model\n        operation_name = self._model.request.operation\n        self._parent = parent\n\n        search_path = collection_model.resource.path\n        self._handler = ResourceHandler(\n            search_path=search_path,\n            factory=factory,\n            resource_model=collection_model.resource,\n            service_context=service_context,\n            operation_name=operation_name,\n        )\n\n    def __repr__(self):\n        return '{}({}, {})'.format(\n            self.__class__.__name__,\n            self._parent,\n            f'{self._parent.meta.service_name}.{self._model.resource.type}',\n        )\n\n    def iterator(self, **kwargs):\n        \"\"\"\n        Get a resource collection iterator from this manager.\n\n        :rtype: :py:class:`ResourceCollection`\n        :return: An iterable representing the collection of resources\n        \"\"\"\n        return self._collection_cls(\n            self._model, self._parent, self._handler, **kwargs\n        )\n\n    # Set up some methods to proxy ResourceCollection methods\n    def all(self):\n        return self.iterator()\n\n    all.__doc__ = ResourceCollection.all.__doc__\n\n    def filter(self, **kwargs):\n        return self.iterator(**kwargs)\n\n    filter.__doc__ = ResourceCollection.filter.__doc__\n\n    def limit(self, count):\n        return self.iterator(limit=count)\n\n    limit.__doc__ = ResourceCollection.limit.__doc__\n\n    def page_size(self, count):\n        return self.iterator(page_size=count)\n\n    page_size.__doc__ = ResourceCollection.page_size.__doc__\n\n    def pages(self):\n        return self.iterator().pages()\n\n    pages.__doc__ = ResourceCollection.pages.__doc__\n\n\nclass CollectionFactory:\n    \"\"\"\n    A factory to create new\n    :py:class:`CollectionManager` and :py:class:`ResourceCollection`\n    subclasses from a :py:class:`~boto3.resources.model.Collection`\n    model. These subclasses include methods to perform batch operations.\n    \"\"\"\n\n    def load_from_definition(\n        self, resource_name, collection_model, service_context, event_emitter\n    ):\n        \"\"\"\n        Loads a collection from a model, creating a new\n        :py:class:`CollectionManager` subclass\n        with the correct properties and methods, named based on the service\n        and resource name, e.g. ec2.InstanceCollectionManager. It also\n        creates a new :py:class:`ResourceCollection` subclass which is used\n        by the new manager class.\n\n        :type resource_name: string\n        :param resource_name: Name of the resource to look up. For services,\n                              this should match the ``service_name``.\n\n        :type service_context: :py:class:`~boto3.utils.ServiceContext`\n        :param service_context: Context about the AWS service\n\n        :type event_emitter: :py:class:`~botocore.hooks.HierarchialEmitter`\n        :param event_emitter: An event emitter\n\n        :rtype: Subclass of :py:class:`CollectionManager`\n        :return: The collection class.\n        \"\"\"\n        attrs = {}\n        collection_name = collection_model.name\n\n        # Create the batch actions for a collection\n        self._load_batch_actions(\n            attrs,\n            resource_name,\n            collection_model,\n            service_context.service_model,\n            event_emitter,\n        )\n        # Add the documentation to the collection class's methods\n        self._load_documented_collection_methods(\n            attrs=attrs,\n            resource_name=resource_name,\n            collection_model=collection_model,\n            service_model=service_context.service_model,\n            event_emitter=event_emitter,\n            base_class=ResourceCollection,\n        )\n\n        if service_context.service_name == resource_name:\n            cls_name = (\n                f'{service_context.service_name}.{collection_name}Collection'\n            )\n        else:\n            cls_name = f'{service_context.service_name}.{resource_name}.{collection_name}Collection'\n\n        collection_cls = type(str(cls_name), (ResourceCollection,), attrs)\n\n        # Add the documentation to the collection manager's methods\n        self._load_documented_collection_methods(\n            attrs=attrs,\n            resource_name=resource_name,\n            collection_model=collection_model,\n            service_model=service_context.service_model,\n            event_emitter=event_emitter,\n            base_class=CollectionManager,\n        )\n        attrs['_collection_cls'] = collection_cls\n        cls_name += 'Manager'\n\n        return type(str(cls_name), (CollectionManager,), attrs)\n\n    def _load_batch_actions(\n        self,\n        attrs,\n        resource_name,\n        collection_model,\n        service_model,\n        event_emitter,\n    ):\n        \"\"\"\n        Batch actions on the collection become methods on both\n        the collection manager and iterators.\n        \"\"\"\n        for action_model in collection_model.batch_actions:\n            snake_cased = xform_name(action_model.name)\n            attrs[snake_cased] = self._create_batch_action(\n                resource_name,\n                snake_cased,\n                action_model,\n                collection_model,\n                service_model,\n                event_emitter,\n            )\n\n    def _load_documented_collection_methods(\n        factory_self,\n        attrs,\n        resource_name,\n        collection_model,\n        service_model,\n        event_emitter,\n        base_class,\n    ):\n        # The base class already has these methods defined. However\n        # the docstrings are generic and not based for a particular service\n        # or resource. So we override these methods by proxying to the\n        # base class's builtin method and adding a docstring\n        # that pertains to the resource.\n\n        # A collection's all() method.\n        def all(self):\n            return base_class.all(self)\n\n        all.__doc__ = docstring.CollectionMethodDocstring(\n            resource_name=resource_name,\n            action_name='all',\n            event_emitter=event_emitter,\n            collection_model=collection_model,\n            service_model=service_model,\n            include_signature=False,\n        )\n        attrs['all'] = all\n\n        # The collection's filter() method.\n        def filter(self, **kwargs):\n            return base_class.filter(self, **kwargs)\n\n        filter.__doc__ = docstring.CollectionMethodDocstring(\n            resource_name=resource_name,\n            action_name='filter',\n            event_emitter=event_emitter,\n            collection_model=collection_model,\n            service_model=service_model,\n            include_signature=False,\n        )\n        attrs['filter'] = filter\n\n        # The collection's limit method.\n        def limit(self, count):\n            return base_class.limit(self, count)\n\n        limit.__doc__ = docstring.CollectionMethodDocstring(\n            resource_name=resource_name,\n            action_name='limit',\n            event_emitter=event_emitter,\n            collection_model=collection_model,\n            service_model=service_model,\n            include_signature=False,\n        )\n        attrs['limit'] = limit\n\n        # The collection's page_size method.\n        def page_size(self, count):\n            return base_class.page_size(self, count)\n\n        page_size.__doc__ = docstring.CollectionMethodDocstring(\n            resource_name=resource_name,\n            action_name='page_size',\n            event_emitter=event_emitter,\n            collection_model=collection_model,\n            service_model=service_model,\n            include_signature=False,\n        )\n        attrs['page_size'] = page_size\n\n    def _create_batch_action(\n        factory_self,\n        resource_name,\n        snake_cased,\n        action_model,\n        collection_model,\n        service_model,\n        event_emitter,\n    ):\n        \"\"\"\n        Creates a new method which makes a batch operation request\n        to the underlying service API.\n        \"\"\"\n        action = BatchAction(action_model)\n\n        def batch_action(self, *args, **kwargs):\n            return action(self, *args, **kwargs)\n\n        batch_action.__name__ = str(snake_cased)\n        batch_action.__doc__ = docstring.BatchActionDocstring(\n            resource_name=resource_name,\n            event_emitter=event_emitter,\n            batch_action_model=action_model,\n            service_model=service_model,\n            collection_model=collection_model,\n            include_signature=False,\n        )\n        return batch_action\n", "boto3/resources/__init__.py": "", "boto3/dynamodb/table.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport logging\n\nlogger = logging.getLogger(__name__)\n\n\ndef register_table_methods(base_classes, **kwargs):\n    base_classes.insert(0, TableResource)\n\n\n# This class can be used to add any additional methods we want\n# onto a table resource.  Ideally to avoid creating a new\n# base class for every method we can just update this\n# class instead.  Just be sure to move the bulk of the\n# actual method implementation to another class.\nclass TableResource:\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n    def batch_writer(self, overwrite_by_pkeys=None):\n        \"\"\"Create a batch writer object.\n\n        This method creates a context manager for writing\n        objects to Amazon DynamoDB in batch.\n\n        The batch writer will automatically handle buffering and sending items\n        in batches.  In addition, the batch writer will also automatically\n        handle any unprocessed items and resend them as needed.  All you need\n        to do is call ``put_item`` for any items you want to add, and\n        ``delete_item`` for any items you want to delete.\n\n        Example usage::\n\n            with table.batch_writer() as batch:\n                for _ in range(1000000):\n                    batch.put_item(Item={'HashKey': '...',\n                                         'Otherstuff': '...'})\n                # You can also delete_items in a batch.\n                batch.delete_item(Key={'HashKey': 'SomeHashKey'})\n\n        :type overwrite_by_pkeys: list(string)\n        :param overwrite_by_pkeys: De-duplicate request items in buffer\n            if match new request item on specified primary keys. i.e\n            ``[\"partition_key1\", \"sort_key2\", \"sort_key3\"]``\n\n        \"\"\"\n        return BatchWriter(\n            self.name, self.meta.client, overwrite_by_pkeys=overwrite_by_pkeys\n        )\n\n\nclass BatchWriter:\n    \"\"\"Automatically handle batch writes to DynamoDB for a single table.\"\"\"\n\n    def __init__(\n        self, table_name, client, flush_amount=25, overwrite_by_pkeys=None\n    ):\n        \"\"\"\n\n        :type table_name: str\n        :param table_name: The name of the table.  The class handles\n            batch writes to a single table.\n\n        :type client: ``botocore.client.Client``\n        :param client: A botocore client.  Note this client\n            **must** have the dynamodb customizations applied\n            to it for transforming AttributeValues into the\n            wire protocol.  What this means in practice is that\n            you need to use a client that comes from a DynamoDB\n            resource if you're going to instantiate this class\n            directly, i.e\n            ``boto3.resource('dynamodb').Table('foo').meta.client``.\n\n        :type flush_amount: int\n        :param flush_amount: The number of items to keep in\n            a local buffer before sending a batch_write_item\n            request to DynamoDB.\n\n        :type overwrite_by_pkeys: list(string)\n        :param overwrite_by_pkeys: De-duplicate request items in buffer\n            if match new request item on specified primary keys. i.e\n            ``[\"partition_key1\", \"sort_key2\", \"sort_key3\"]``\n\n        \"\"\"\n        self._table_name = table_name\n        self._client = client\n        self._items_buffer = []\n        self._flush_amount = flush_amount\n        self._overwrite_by_pkeys = overwrite_by_pkeys\n\n    def put_item(self, Item):\n        self._add_request_and_process({'PutRequest': {'Item': Item}})\n\n    def delete_item(self, Key):\n        self._add_request_and_process({'DeleteRequest': {'Key': Key}})\n\n    def _add_request_and_process(self, request):\n        if self._overwrite_by_pkeys:\n            self._remove_dup_pkeys_request_if_any(request)\n        self._items_buffer.append(request)\n        self._flush_if_needed()\n\n    def _remove_dup_pkeys_request_if_any(self, request):\n        pkey_values_new = self._extract_pkey_values(request)\n        for item in self._items_buffer:\n            if self._extract_pkey_values(item) == pkey_values_new:\n                self._items_buffer.remove(item)\n                logger.debug(\n                    \"With overwrite_by_pkeys enabled, skipping \" \"request:%s\",\n                    item,\n                )\n\n    def _extract_pkey_values(self, request):\n        if request.get('PutRequest'):\n            return [\n                request['PutRequest']['Item'][key]\n                for key in self._overwrite_by_pkeys\n            ]\n        elif request.get('DeleteRequest'):\n            return [\n                request['DeleteRequest']['Key'][key]\n                for key in self._overwrite_by_pkeys\n            ]\n        return None\n\n    def _flush_if_needed(self):\n        if len(self._items_buffer) >= self._flush_amount:\n            self._flush()\n\n    def _flush(self):\n        items_to_send = self._items_buffer[: self._flush_amount]\n        self._items_buffer = self._items_buffer[self._flush_amount :]\n        response = self._client.batch_write_item(\n            RequestItems={self._table_name: items_to_send}\n        )\n        unprocessed_items = response['UnprocessedItems']\n        if not unprocessed_items:\n            unprocessed_items = {}\n        item_list = unprocessed_items.get(self._table_name, [])\n        # Any unprocessed_items are immediately added to the\n        # next batch we send.\n        self._items_buffer.extend(item_list)\n        logger.debug(\n            \"Batch write sent %s, unprocessed: %s\",\n            len(items_to_send),\n            len(self._items_buffer),\n        )\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_value, tb):\n        # When we exit, we need to keep flushing whatever's left\n        # until there's nothing left in our items buffer.\n        while self._items_buffer:\n            self._flush()\n", "boto3/dynamodb/types.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom decimal import (\n    Clamped,\n    Context,\n    Decimal,\n    Inexact,\n    Overflow,\n    Rounded,\n    Underflow,\n)\n\nfrom boto3.compat import collections_abc\n\nSTRING = 'S'\nNUMBER = 'N'\nBINARY = 'B'\nSTRING_SET = 'SS'\nNUMBER_SET = 'NS'\nBINARY_SET = 'BS'\nNULL = 'NULL'\nBOOLEAN = 'BOOL'\nMAP = 'M'\nLIST = 'L'\n\n\nDYNAMODB_CONTEXT = Context(\n    Emin=-128,\n    Emax=126,\n    prec=38,\n    traps=[Clamped, Overflow, Inexact, Rounded, Underflow],\n)\n\n\nBINARY_TYPES = (bytearray, bytes)\n\n\nclass Binary:\n    \"\"\"A class for representing Binary in dynamodb\n\n    Especially for Python 2, use this class to explicitly specify\n    binary data for item in DynamoDB. It is essentially a wrapper around\n    binary. Unicode and Python 3 string types are not allowed.\n    \"\"\"\n\n    def __init__(self, value):\n        if not isinstance(value, BINARY_TYPES):\n            types = ', '.join([str(t) for t in BINARY_TYPES])\n            raise TypeError(f'Value must be of the following types: {types}')\n        self.value = value\n\n    def __eq__(self, other):\n        if isinstance(other, Binary):\n            return self.value == other.value\n        return self.value == other\n\n    def __ne__(self, other):\n        return not self.__eq__(other)\n\n    def __repr__(self):\n        return f'Binary({self.value!r})'\n\n    def __str__(self):\n        return self.value\n\n    def __bytes__(self):\n        return self.value\n\n    def __hash__(self):\n        return hash(self.value)\n\n\nclass TypeSerializer:\n    \"\"\"This class serializes Python data types to DynamoDB types.\"\"\"\n\n    def serialize(self, value):\n        \"\"\"The method to serialize the Python data types.\n\n        :param value: A python value to be serialized to DynamoDB. Here are\n            the various conversions:\n\n            Python                                  DynamoDB\n            ------                                  --------\n            None                                    {'NULL': True}\n            True/False                              {'BOOL': True/False}\n            int/Decimal                             {'N': str(value)}\n            string                                  {'S': string}\n            Binary/bytearray/bytes (py3 only)       {'B': bytes}\n            set([int/Decimal])                      {'NS': [str(value)]}\n            set([string])                           {'SS': [string])\n            set([Binary/bytearray/bytes])           {'BS': [bytes]}\n            list                                    {'L': list}\n            dict                                    {'M': dict}\n\n            For types that involve numbers, it is recommended that ``Decimal``\n            objects are used to be able to round-trip the Python type.\n            For types that involve binary, it is recommended that ``Binary``\n            objects are used to be able to round-trip the Python type.\n\n        :rtype: dict\n        :returns: A dictionary that represents a dynamoDB data type. These\n            dictionaries can be directly passed to botocore methods.\n        \"\"\"\n        dynamodb_type = self._get_dynamodb_type(value)\n        serializer = getattr(self, f'_serialize_{dynamodb_type}'.lower())\n        return {dynamodb_type: serializer(value)}\n\n    def _get_dynamodb_type(self, value):\n        dynamodb_type = None\n\n        if self._is_null(value):\n            dynamodb_type = NULL\n\n        elif self._is_boolean(value):\n            dynamodb_type = BOOLEAN\n\n        elif self._is_number(value):\n            dynamodb_type = NUMBER\n\n        elif self._is_string(value):\n            dynamodb_type = STRING\n\n        elif self._is_binary(value):\n            dynamodb_type = BINARY\n\n        elif self._is_type_set(value, self._is_number):\n            dynamodb_type = NUMBER_SET\n\n        elif self._is_type_set(value, self._is_string):\n            dynamodb_type = STRING_SET\n\n        elif self._is_type_set(value, self._is_binary):\n            dynamodb_type = BINARY_SET\n\n        elif self._is_map(value):\n            dynamodb_type = MAP\n\n        elif self._is_listlike(value):\n            dynamodb_type = LIST\n\n        else:\n            msg = f'Unsupported type \"{type(value)}\" for value \"{value}\"'\n            raise TypeError(msg)\n\n        return dynamodb_type\n\n    def _is_null(self, value):\n        if value is None:\n            return True\n        return False\n\n    def _is_boolean(self, value):\n        if isinstance(value, bool):\n            return True\n        return False\n\n    def _is_number(self, value):\n        if isinstance(value, (int, Decimal)):\n            return True\n        elif isinstance(value, float):\n            raise TypeError(\n                'Float types are not supported. Use Decimal types instead.'\n            )\n        return False\n\n    def _is_string(self, value):\n        if isinstance(value, str):\n            return True\n        return False\n\n    def _is_binary(self, value):\n        if isinstance(value, (Binary, bytearray, bytes)):\n            return True\n        return False\n\n    def _is_set(self, value):\n        if isinstance(value, collections_abc.Set):\n            return True\n        return False\n\n    def _is_type_set(self, value, type_validator):\n        if self._is_set(value):\n            if False not in map(type_validator, value):\n                return True\n        return False\n\n    def _is_map(self, value):\n        if isinstance(value, collections_abc.Mapping):\n            return True\n        return False\n\n    def _is_listlike(self, value):\n        if isinstance(value, (list, tuple)):\n            return True\n        return False\n\n    def _serialize_null(self, value):\n        return True\n\n    def _serialize_bool(self, value):\n        return value\n\n    def _serialize_n(self, value):\n        number = str(DYNAMODB_CONTEXT.create_decimal(value))\n        if number in ['Infinity', 'NaN']:\n            raise TypeError('Infinity and NaN not supported')\n        return number\n\n    def _serialize_s(self, value):\n        return value\n\n    def _serialize_b(self, value):\n        if isinstance(value, Binary):\n            value = value.value\n        return value\n\n    def _serialize_ss(self, value):\n        return [self._serialize_s(s) for s in value]\n\n    def _serialize_ns(self, value):\n        return [self._serialize_n(n) for n in value]\n\n    def _serialize_bs(self, value):\n        return [self._serialize_b(b) for b in value]\n\n    def _serialize_l(self, value):\n        return [self.serialize(v) for v in value]\n\n    def _serialize_m(self, value):\n        return {k: self.serialize(v) for k, v in value.items()}\n\n\nclass TypeDeserializer:\n    \"\"\"This class deserializes DynamoDB types to Python types.\"\"\"\n\n    def deserialize(self, value):\n        \"\"\"The method to deserialize the DynamoDB data types.\n\n        :param value: A DynamoDB value to be deserialized to a pythonic value.\n            Here are the various conversions:\n\n            DynamoDB                                Python\n            --------                                ------\n            {'NULL': True}                          None\n            {'BOOL': True/False}                    True/False\n            {'N': str(value)}                       Decimal(str(value))\n            {'S': string}                           string\n            {'B': bytes}                            Binary(bytes)\n            {'NS': [str(value)]}                    set([Decimal(str(value))])\n            {'SS': [string]}                        set([string])\n            {'BS': [bytes]}                         set([bytes])\n            {'L': list}                             list\n            {'M': dict}                             dict\n\n        :returns: The pythonic value of the DynamoDB type.\n        \"\"\"\n\n        if not value:\n            raise TypeError(\n                'Value must be a nonempty dictionary whose key '\n                'is a valid dynamodb type.'\n            )\n        dynamodb_type = list(value.keys())[0]\n        try:\n            deserializer = getattr(\n                self, f'_deserialize_{dynamodb_type}'.lower()\n            )\n        except AttributeError:\n            raise TypeError(f'Dynamodb type {dynamodb_type} is not supported')\n        return deserializer(value[dynamodb_type])\n\n    def _deserialize_null(self, value):\n        return None\n\n    def _deserialize_bool(self, value):\n        return value\n\n    def _deserialize_n(self, value):\n        return DYNAMODB_CONTEXT.create_decimal(value)\n\n    def _deserialize_s(self, value):\n        return value\n\n    def _deserialize_b(self, value):\n        return Binary(value)\n\n    def _deserialize_ns(self, value):\n        return set(map(self._deserialize_n, value))\n\n    def _deserialize_ss(self, value):\n        return set(map(self._deserialize_s, value))\n\n    def _deserialize_bs(self, value):\n        return set(map(self._deserialize_b, value))\n\n    def _deserialize_l(self, value):\n        return [self.deserialize(v) for v in value]\n\n    def _deserialize_m(self, value):\n        return {k: self.deserialize(v) for k, v in value.items()}\n", "boto3/dynamodb/conditions.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport re\nfrom collections import namedtuple\n\nfrom boto3.exceptions import (\n    DynamoDBNeedsConditionError,\n    DynamoDBNeedsKeyConditionError,\n    DynamoDBOperationNotSupportedError,\n)\n\nATTR_NAME_REGEX = re.compile(r'[^.\\[\\]]+(?![^\\[]*\\])')\n\n\nclass ConditionBase:\n    expression_format = ''\n    expression_operator = ''\n    has_grouped_values = False\n\n    def __init__(self, *values):\n        self._values = values\n\n    def __and__(self, other):\n        if not isinstance(other, ConditionBase):\n            raise DynamoDBOperationNotSupportedError('AND', other)\n        return And(self, other)\n\n    def __or__(self, other):\n        if not isinstance(other, ConditionBase):\n            raise DynamoDBOperationNotSupportedError('OR', other)\n        return Or(self, other)\n\n    def __invert__(self):\n        return Not(self)\n\n    def get_expression(self):\n        return {\n            'format': self.expression_format,\n            'operator': self.expression_operator,\n            'values': self._values,\n        }\n\n    def __eq__(self, other):\n        if isinstance(other, type(self)):\n            if self._values == other._values:\n                return True\n        return False\n\n    def __ne__(self, other):\n        return not self.__eq__(other)\n\n\nclass AttributeBase:\n    def __init__(self, name):\n        self.name = name\n\n    def __and__(self, value):\n        raise DynamoDBOperationNotSupportedError('AND', self)\n\n    def __or__(self, value):\n        raise DynamoDBOperationNotSupportedError('OR', self)\n\n    def __invert__(self):\n        raise DynamoDBOperationNotSupportedError('NOT', self)\n\n    def eq(self, value):\n        \"\"\"Creates a condition where the attribute is equal to the value.\n\n        :param value: The value that the attribute is equal to.\n        \"\"\"\n        return Equals(self, value)\n\n    def lt(self, value):\n        \"\"\"Creates a condition where the attribute is less than the value.\n\n        :param value: The value that the attribute is less than.\n        \"\"\"\n        return LessThan(self, value)\n\n    def lte(self, value):\n        \"\"\"Creates a condition where the attribute is less than or equal to the\n           value.\n\n        :param value: The value that the attribute is less than or equal to.\n        \"\"\"\n        return LessThanEquals(self, value)\n\n    def gt(self, value):\n        \"\"\"Creates a condition where the attribute is greater than the value.\n\n        :param value: The value that the attribute is greater than.\n        \"\"\"\n        return GreaterThan(self, value)\n\n    def gte(self, value):\n        \"\"\"Creates a condition where the attribute is greater than or equal to\n           the value.\n\n        :param value: The value that the attribute is greater than or equal to.\n        \"\"\"\n        return GreaterThanEquals(self, value)\n\n    def begins_with(self, value):\n        \"\"\"Creates a condition where the attribute begins with the value.\n\n        :param value: The value that the attribute begins with.\n        \"\"\"\n        return BeginsWith(self, value)\n\n    def between(self, low_value, high_value):\n        \"\"\"Creates a condition where the attribute is greater than or equal\n        to the low value and less than or equal to the high value.\n\n        :param low_value: The value that the attribute is greater than or equal to.\n        :param high_value: The value that the attribute is less than or equal to.\n        \"\"\"\n        return Between(self, low_value, high_value)\n\n    def __eq__(self, other):\n        return isinstance(other, type(self)) and self.name == other.name\n\n    def __ne__(self, other):\n        return not self.__eq__(other)\n\n\nclass ConditionAttributeBase(ConditionBase, AttributeBase):\n    \"\"\"This base class is for conditions that can have attribute methods.\n\n    One example is the Size condition. To complete a condition, you need\n    to apply another AttributeBase method like eq().\n    \"\"\"\n\n    def __init__(self, *values):\n        ConditionBase.__init__(self, *values)\n        # This is assuming the first value to the condition is the attribute\n        # in which can be used to generate its attribute base.\n        AttributeBase.__init__(self, values[0].name)\n\n    def __eq__(self, other):\n        return ConditionBase.__eq__(self, other) and AttributeBase.__eq__(\n            self, other\n        )\n\n    def __ne__(self, other):\n        return not self.__eq__(other)\n\n\nclass ComparisonCondition(ConditionBase):\n    expression_format = '{0} {operator} {1}'\n\n\nclass Equals(ComparisonCondition):\n    expression_operator = '='\n\n\nclass NotEquals(ComparisonCondition):\n    expression_operator = '<>'\n\n\nclass LessThan(ComparisonCondition):\n    expression_operator = '<'\n\n\nclass LessThanEquals(ComparisonCondition):\n    expression_operator = '<='\n\n\nclass GreaterThan(ComparisonCondition):\n    expression_operator = '>'\n\n\nclass GreaterThanEquals(ComparisonCondition):\n    expression_operator = '>='\n\n\nclass In(ComparisonCondition):\n    expression_operator = 'IN'\n    has_grouped_values = True\n\n\nclass Between(ConditionBase):\n    expression_operator = 'BETWEEN'\n    expression_format = '{0} {operator} {1} AND {2}'\n\n\nclass BeginsWith(ConditionBase):\n    expression_operator = 'begins_with'\n    expression_format = '{operator}({0}, {1})'\n\n\nclass Contains(ConditionBase):\n    expression_operator = 'contains'\n    expression_format = '{operator}({0}, {1})'\n\n\nclass Size(ConditionAttributeBase):\n    expression_operator = 'size'\n    expression_format = '{operator}({0})'\n\n\nclass AttributeType(ConditionBase):\n    expression_operator = 'attribute_type'\n    expression_format = '{operator}({0}, {1})'\n\n\nclass AttributeExists(ConditionBase):\n    expression_operator = 'attribute_exists'\n    expression_format = '{operator}({0})'\n\n\nclass AttributeNotExists(ConditionBase):\n    expression_operator = 'attribute_not_exists'\n    expression_format = '{operator}({0})'\n\n\nclass And(ConditionBase):\n    expression_operator = 'AND'\n    expression_format = '({0} {operator} {1})'\n\n\nclass Or(ConditionBase):\n    expression_operator = 'OR'\n    expression_format = '({0} {operator} {1})'\n\n\nclass Not(ConditionBase):\n    expression_operator = 'NOT'\n    expression_format = '({operator} {0})'\n\n\nclass Key(AttributeBase):\n    pass\n\n\nclass Attr(AttributeBase):\n    \"\"\"Represents an DynamoDB item's attribute.\"\"\"\n\n    def ne(self, value):\n        \"\"\"Creates a condition where the attribute is not equal to the value\n\n        :param value: The value that the attribute is not equal to.\n        \"\"\"\n        return NotEquals(self, value)\n\n    def is_in(self, value):\n        \"\"\"Creates a condition where the attribute is in the value,\n\n        :type value: list\n        :param value: The value that the attribute is in.\n        \"\"\"\n        return In(self, value)\n\n    def exists(self):\n        \"\"\"Creates a condition where the attribute exists.\"\"\"\n        return AttributeExists(self)\n\n    def not_exists(self):\n        \"\"\"Creates a condition where the attribute does not exist.\"\"\"\n        return AttributeNotExists(self)\n\n    def contains(self, value):\n        \"\"\"Creates a condition where the attribute contains the value.\n\n        :param value: The value the attribute contains.\n        \"\"\"\n        return Contains(self, value)\n\n    def size(self):\n        \"\"\"Creates a condition for the attribute size.\n\n        Note another AttributeBase method must be called on the returned\n        size condition to be a valid DynamoDB condition.\n        \"\"\"\n        return Size(self)\n\n    def attribute_type(self, value):\n        \"\"\"Creates a condition for the attribute type.\n\n        :param value: The type of the attribute.\n        \"\"\"\n        return AttributeType(self, value)\n\n\nBuiltConditionExpression = namedtuple(\n    'BuiltConditionExpression',\n    [\n        'condition_expression',\n        'attribute_name_placeholders',\n        'attribute_value_placeholders',\n    ],\n)\n\n\nclass ConditionExpressionBuilder:\n    \"\"\"This class is used to build condition expressions with placeholders\"\"\"\n\n    def __init__(self):\n        self._name_count = 0\n        self._value_count = 0\n        self._name_placeholder = 'n'\n        self._value_placeholder = 'v'\n\n    def _get_name_placeholder(self):\n        return '#' + self._name_placeholder + str(self._name_count)\n\n    def _get_value_placeholder(self):\n        return ':' + self._value_placeholder + str(self._value_count)\n\n    def reset(self):\n        \"\"\"Resets the placeholder name and values\"\"\"\n        self._name_count = 0\n        self._value_count = 0\n\n    def build_expression(self, condition, is_key_condition=False):\n        \"\"\"Builds the condition expression and the dictionary of placeholders.\n\n        :type condition: ConditionBase\n        :param condition: A condition to be built into a condition expression\n            string with any necessary placeholders.\n\n        :type is_key_condition: Boolean\n        :param is_key_condition: True if the expression is for a\n            KeyConditionExpression. False otherwise.\n\n        :rtype: (string, dict, dict)\n        :returns: Will return a string representing the condition with\n            placeholders inserted where necessary, a dictionary of\n            placeholders for attribute names, and a dictionary of\n            placeholders for attribute values. Here is a sample return value:\n\n            ('#n0 = :v0', {'#n0': 'myattribute'}, {':v1': 'myvalue'})\n        \"\"\"\n        if not isinstance(condition, ConditionBase):\n            raise DynamoDBNeedsConditionError(condition)\n        attribute_name_placeholders = {}\n        attribute_value_placeholders = {}\n        condition_expression = self._build_expression(\n            condition,\n            attribute_name_placeholders,\n            attribute_value_placeholders,\n            is_key_condition=is_key_condition,\n        )\n        return BuiltConditionExpression(\n            condition_expression=condition_expression,\n            attribute_name_placeholders=attribute_name_placeholders,\n            attribute_value_placeholders=attribute_value_placeholders,\n        )\n\n    def _build_expression(\n        self,\n        condition,\n        attribute_name_placeholders,\n        attribute_value_placeholders,\n        is_key_condition,\n    ):\n        expression_dict = condition.get_expression()\n        replaced_values = []\n        for value in expression_dict['values']:\n            # Build the necessary placeholders for that value.\n            # Placeholders are built for both attribute names and values.\n            replaced_value = self._build_expression_component(\n                value,\n                attribute_name_placeholders,\n                attribute_value_placeholders,\n                condition.has_grouped_values,\n                is_key_condition,\n            )\n            replaced_values.append(replaced_value)\n        # Fill out the expression using the operator and the\n        # values that have been replaced with placeholders.\n        return expression_dict['format'].format(\n            *replaced_values, operator=expression_dict['operator']\n        )\n\n    def _build_expression_component(\n        self,\n        value,\n        attribute_name_placeholders,\n        attribute_value_placeholders,\n        has_grouped_values,\n        is_key_condition,\n    ):\n        # Continue to recurse if the value is a ConditionBase in order\n        # to extract out all parts of the expression.\n        if isinstance(value, ConditionBase):\n            return self._build_expression(\n                value,\n                attribute_name_placeholders,\n                attribute_value_placeholders,\n                is_key_condition,\n            )\n        # If it is not a ConditionBase, we can recurse no further.\n        # So we check if it is an attribute and add placeholders for\n        # its name\n        elif isinstance(value, AttributeBase):\n            if is_key_condition and not isinstance(value, Key):\n                raise DynamoDBNeedsKeyConditionError(\n                    f'Attribute object {value.name} is of type {type(value)}. '\n                    f'KeyConditionExpression only supports Attribute objects '\n                    f'of type Key'\n                )\n            return self._build_name_placeholder(\n                value, attribute_name_placeholders\n            )\n        # If it is anything else, we treat it as a value and thus placeholders\n        # are needed for the value.\n        else:\n            return self._build_value_placeholder(\n                value, attribute_value_placeholders, has_grouped_values\n            )\n\n    def _build_name_placeholder(self, value, attribute_name_placeholders):\n        attribute_name = value.name\n        # Figure out which parts of the attribute name that needs replacement.\n        attribute_name_parts = ATTR_NAME_REGEX.findall(attribute_name)\n\n        # Add a temporary placeholder for each of these parts.\n        placeholder_format = ATTR_NAME_REGEX.sub('%s', attribute_name)\n        str_format_args = []\n        for part in attribute_name_parts:\n            name_placeholder = self._get_name_placeholder()\n            self._name_count += 1\n            str_format_args.append(name_placeholder)\n            # Add the placeholder and value to dictionary of name placeholders.\n            attribute_name_placeholders[name_placeholder] = part\n        # Replace the temporary placeholders with the designated placeholders.\n        return placeholder_format % tuple(str_format_args)\n\n    def _build_value_placeholder(\n        self, value, attribute_value_placeholders, has_grouped_values=False\n    ):\n        # If the values are grouped, we need to add a placeholder for\n        # each element inside of the actual value.\n        if has_grouped_values:\n            placeholder_list = []\n            for v in value:\n                value_placeholder = self._get_value_placeholder()\n                self._value_count += 1\n                placeholder_list.append(value_placeholder)\n                attribute_value_placeholders[value_placeholder] = v\n            # Assuming the values are grouped by parenthesis.\n            # IN is the currently the only one that uses this so it maybe\n            # needed to be changed in future.\n            return '(' + ', '.join(placeholder_list) + ')'\n        # Otherwise, treat the value as a single value that needs only\n        # one placeholder.\n        else:\n            value_placeholder = self._get_value_placeholder()\n            self._value_count += 1\n            attribute_value_placeholders[value_placeholder] = value\n            return value_placeholder\n", "boto3/dynamodb/__init__.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n", "boto3/dynamodb/transform.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport copy\n\nfrom boto3.compat import collections_abc\nfrom boto3.docs.utils import DocumentModifiedShape\nfrom boto3.dynamodb.conditions import ConditionBase, ConditionExpressionBuilder\nfrom boto3.dynamodb.types import TypeDeserializer, TypeSerializer\n\n\ndef register_high_level_interface(base_classes, **kwargs):\n    base_classes.insert(0, DynamoDBHighLevelResource)\n\n\nclass _ForgetfulDict(dict):\n    \"\"\"A dictionary that discards any items set on it. For use as `memo` in\n    `copy.deepcopy()` when every instance of a repeated object in the deepcopied\n    data structure should result in a separate copy.\n    \"\"\"\n\n    def __setitem__(self, key, value):\n        pass\n\n\ndef copy_dynamodb_params(params, **kwargs):\n    return copy.deepcopy(params, memo=_ForgetfulDict())\n\n\nclass DynamoDBHighLevelResource:\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n        # Apply handler that creates a copy of the user provided dynamodb\n        # item such that it can be modified.\n        self.meta.client.meta.events.register(\n            'provide-client-params.dynamodb',\n            copy_dynamodb_params,\n            unique_id='dynamodb-create-params-copy',\n        )\n\n        self._injector = TransformationInjector()\n        # Apply the handler that generates condition expressions including\n        # placeholders.\n        self.meta.client.meta.events.register(\n            'before-parameter-build.dynamodb',\n            self._injector.inject_condition_expressions,\n            unique_id='dynamodb-condition-expression',\n        )\n\n        # Apply the handler that serializes the request from python\n        # types to dynamodb types.\n        self.meta.client.meta.events.register(\n            'before-parameter-build.dynamodb',\n            self._injector.inject_attribute_value_input,\n            unique_id='dynamodb-attr-value-input',\n        )\n\n        # Apply the handler that deserializes the response from dynamodb\n        # types to python types.\n        self.meta.client.meta.events.register(\n            'after-call.dynamodb',\n            self._injector.inject_attribute_value_output,\n            unique_id='dynamodb-attr-value-output',\n        )\n\n        # Apply the documentation customizations to account for\n        # the transformations.\n        attr_value_shape_docs = DocumentModifiedShape(\n            'AttributeValue',\n            new_type='valid DynamoDB type',\n            new_description=(\n                '- The value of the attribute. The valid value types are '\n                'listed in the '\n                ':ref:`DynamoDB Reference Guide<ref_valid_dynamodb_types>`.'\n            ),\n            new_example_value=(\n                '\\'string\\'|123|Binary(b\\'bytes\\')|True|None|set([\\'string\\'])'\n                '|set([123])|set([Binary(b\\'bytes\\')])|[]|{}'\n            ),\n        )\n\n        key_expression_shape_docs = DocumentModifiedShape(\n            'KeyExpression',\n            new_type=(\n                'condition from :py:class:`boto3.dynamodb.conditions.Key` '\n                'method'\n            ),\n            new_description=(\n                'The condition(s) a key(s) must meet. Valid conditions are '\n                'listed in the '\n                ':ref:`DynamoDB Reference Guide<ref_dynamodb_conditions>`.'\n            ),\n            new_example_value='Key(\\'mykey\\').eq(\\'myvalue\\')',\n        )\n\n        con_expression_shape_docs = DocumentModifiedShape(\n            'ConditionExpression',\n            new_type=(\n                'condition from :py:class:`boto3.dynamodb.conditions.Attr` '\n                'method'\n            ),\n            new_description=(\n                'The condition(s) an attribute(s) must meet. Valid conditions '\n                'are listed in the '\n                ':ref:`DynamoDB Reference Guide<ref_dynamodb_conditions>`.'\n            ),\n            new_example_value='Attr(\\'myattribute\\').eq(\\'myvalue\\')',\n        )\n\n        self.meta.client.meta.events.register(\n            'docs.*.dynamodb.*.complete-section',\n            attr_value_shape_docs.replace_documentation_for_matching_shape,\n            unique_id='dynamodb-attr-value-docs',\n        )\n\n        self.meta.client.meta.events.register(\n            'docs.*.dynamodb.*.complete-section',\n            key_expression_shape_docs.replace_documentation_for_matching_shape,\n            unique_id='dynamodb-key-expression-docs',\n        )\n\n        self.meta.client.meta.events.register(\n            'docs.*.dynamodb.*.complete-section',\n            con_expression_shape_docs.replace_documentation_for_matching_shape,\n            unique_id='dynamodb-cond-expression-docs',\n        )\n\n\nclass TransformationInjector:\n    \"\"\"Injects the transformations into the user provided parameters.\"\"\"\n\n    def __init__(\n        self,\n        transformer=None,\n        condition_builder=None,\n        serializer=None,\n        deserializer=None,\n    ):\n        self._transformer = transformer\n        if transformer is None:\n            self._transformer = ParameterTransformer()\n\n        self._condition_builder = condition_builder\n        if condition_builder is None:\n            self._condition_builder = ConditionExpressionBuilder()\n\n        self._serializer = serializer\n        if serializer is None:\n            self._serializer = TypeSerializer()\n\n        self._deserializer = deserializer\n        if deserializer is None:\n            self._deserializer = TypeDeserializer()\n\n    def inject_condition_expressions(self, params, model, **kwargs):\n        \"\"\"Injects the condition expression transformation into the parameters\n\n        This injection includes transformations for ConditionExpression shapes\n        and KeyExpression shapes. It also handles any placeholder names and\n        values that are generated when transforming the condition expressions.\n        \"\"\"\n        self._condition_builder.reset()\n        generated_names = {}\n        generated_values = {}\n\n        # Create and apply the Condition Expression transformation.\n        transformation = ConditionExpressionTransformation(\n            self._condition_builder,\n            placeholder_names=generated_names,\n            placeholder_values=generated_values,\n            is_key_condition=False,\n        )\n        self._transformer.transform(\n            params, model.input_shape, transformation, 'ConditionExpression'\n        )\n\n        # Create and apply the Key Condition Expression transformation.\n        transformation = ConditionExpressionTransformation(\n            self._condition_builder,\n            placeholder_names=generated_names,\n            placeholder_values=generated_values,\n            is_key_condition=True,\n        )\n        self._transformer.transform(\n            params, model.input_shape, transformation, 'KeyExpression'\n        )\n\n        expr_attr_names_input = 'ExpressionAttributeNames'\n        expr_attr_values_input = 'ExpressionAttributeValues'\n\n        # Now that all of the condition expression transformation are done,\n        # update the placeholder dictionaries in the request.\n        if expr_attr_names_input in params:\n            params[expr_attr_names_input].update(generated_names)\n        else:\n            if generated_names:\n                params[expr_attr_names_input] = generated_names\n\n        if expr_attr_values_input in params:\n            params[expr_attr_values_input].update(generated_values)\n        else:\n            if generated_values:\n                params[expr_attr_values_input] = generated_values\n\n    def inject_attribute_value_input(self, params, model, **kwargs):\n        \"\"\"Injects DynamoDB serialization into parameter input\"\"\"\n        self._transformer.transform(\n            params,\n            model.input_shape,\n            self._serializer.serialize,\n            'AttributeValue',\n        )\n\n    def inject_attribute_value_output(self, parsed, model, **kwargs):\n        \"\"\"Injects DynamoDB deserialization into responses\"\"\"\n        if model.output_shape is not None:\n            self._transformer.transform(\n                parsed,\n                model.output_shape,\n                self._deserializer.deserialize,\n                'AttributeValue',\n            )\n\n\nclass ConditionExpressionTransformation:\n    \"\"\"Provides a transformation for condition expressions\n\n    The ``ParameterTransformer`` class can call this class directly\n    to transform the condition expressions in the parameters provided.\n    \"\"\"\n\n    def __init__(\n        self,\n        condition_builder,\n        placeholder_names,\n        placeholder_values,\n        is_key_condition=False,\n    ):\n        self._condition_builder = condition_builder\n        self._placeholder_names = placeholder_names\n        self._placeholder_values = placeholder_values\n        self._is_key_condition = is_key_condition\n\n    def __call__(self, value):\n        if isinstance(value, ConditionBase):\n            # Create a conditional expression string with placeholders\n            # for the provided condition.\n            built_expression = self._condition_builder.build_expression(\n                value, is_key_condition=self._is_key_condition\n            )\n\n            self._placeholder_names.update(\n                built_expression.attribute_name_placeholders\n            )\n            self._placeholder_values.update(\n                built_expression.attribute_value_placeholders\n            )\n\n            return built_expression.condition_expression\n        # Use the user provided value if it is not a ConditonBase object.\n        return value\n\n\nclass ParameterTransformer:\n    \"\"\"Transforms the input to and output from botocore based on shape\"\"\"\n\n    def transform(self, params, model, transformation, target_shape):\n        \"\"\"Transforms the dynamodb input to or output from botocore\n\n        It applies a specified transformation whenever a specific shape name\n        is encountered while traversing the parameters in the dictionary.\n\n        :param params: The parameters structure to transform.\n        :param model: The operation model.\n        :param transformation: The function to apply the parameter\n        :param target_shape: The name of the shape to apply the\n            transformation to\n        \"\"\"\n        self._transform_parameters(model, params, transformation, target_shape)\n\n    def _transform_parameters(\n        self, model, params, transformation, target_shape\n    ):\n        type_name = model.type_name\n        if type_name in ('structure', 'map', 'list'):\n            getattr(self, f'_transform_{type_name}')(\n                model, params, transformation, target_shape\n            )\n\n    def _transform_structure(\n        self, model, params, transformation, target_shape\n    ):\n        if not isinstance(params, collections_abc.Mapping):\n            return\n        for param in params:\n            if param in model.members:\n                member_model = model.members[param]\n                member_shape = member_model.name\n                if member_shape == target_shape:\n                    params[param] = transformation(params[param])\n                else:\n                    self._transform_parameters(\n                        member_model,\n                        params[param],\n                        transformation,\n                        target_shape,\n                    )\n\n    def _transform_map(self, model, params, transformation, target_shape):\n        if not isinstance(params, collections_abc.Mapping):\n            return\n        value_model = model.value\n        value_shape = value_model.name\n        for key, value in params.items():\n            if value_shape == target_shape:\n                params[key] = transformation(value)\n            else:\n                self._transform_parameters(\n                    value_model, params[key], transformation, target_shape\n                )\n\n    def _transform_list(self, model, params, transformation, target_shape):\n        if not isinstance(params, collections_abc.MutableSequence):\n            return\n        member_model = model.member\n        member_shape = member_model.name\n        for i, item in enumerate(params):\n            if member_shape == target_shape:\n                params[i] = transformation(item)\n            else:\n                self._transform_parameters(\n                    member_model, params[i], transformation, target_shape\n                )\n", "boto3/ec2/deletetags.py": "# Copyright 2016 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom boto3.resources.action import CustomModeledAction\n\n\ndef inject_delete_tags(event_emitter, **kwargs):\n    action_model = {\n        'request': {\n            'operation': 'DeleteTags',\n            'params': [\n                {\n                    'target': 'Resources[0]',\n                    'source': 'identifier',\n                    'name': 'Id',\n                }\n            ],\n        }\n    }\n    action = CustomModeledAction(\n        'delete_tags', action_model, delete_tags, event_emitter\n    )\n    action.inject(**kwargs)\n\n\ndef delete_tags(self, **kwargs):\n    kwargs['Resources'] = [self.id]\n    return self.meta.client.delete_tags(**kwargs)\n", "boto3/ec2/createtags.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n\n\ndef inject_create_tags(event_name, class_attributes, **kwargs):\n    \"\"\"This injects a custom create_tags method onto the ec2 service resource\n\n    This is needed because the resource model is not able to express\n    creating multiple tag resources based on the fact you can apply a set\n    of tags to multiple ec2 resources.\n    \"\"\"\n    class_attributes['create_tags'] = create_tags\n\n\ndef create_tags(self, **kwargs):\n    # Call the client method\n    self.meta.client.create_tags(**kwargs)\n    resources = kwargs.get('Resources', [])\n    tags = kwargs.get('Tags', [])\n    tag_resources = []\n\n    # Generate all of the tag resources that just were created with the\n    # preceding client call.\n    for resource in resources:\n        for tag in tags:\n            # Add each tag from the tag set for each resource to the list\n            # that is returned by the method.\n            tag_resource = self.Tag(resource, tag['Key'], tag['Value'])\n            tag_resources.append(tag_resource)\n    return tag_resources\n", "boto3/ec2/__init__.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n", "boto3/s3/inject.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport copy as python_copy\n\nfrom botocore.exceptions import ClientError\n\nfrom boto3 import utils\nfrom boto3.s3.transfer import (\n    ProgressCallbackInvoker,\n    S3Transfer,\n    TransferConfig,\n    create_transfer_manager,\n)\n\n\ndef inject_s3_transfer_methods(class_attributes, **kwargs):\n    utils.inject_attribute(class_attributes, 'upload_file', upload_file)\n    utils.inject_attribute(class_attributes, 'download_file', download_file)\n    utils.inject_attribute(class_attributes, 'copy', copy)\n    utils.inject_attribute(class_attributes, 'upload_fileobj', upload_fileobj)\n    utils.inject_attribute(\n        class_attributes, 'download_fileobj', download_fileobj\n    )\n\n\ndef inject_bucket_methods(class_attributes, **kwargs):\n    utils.inject_attribute(class_attributes, 'load', bucket_load)\n    utils.inject_attribute(class_attributes, 'upload_file', bucket_upload_file)\n    utils.inject_attribute(\n        class_attributes, 'download_file', bucket_download_file\n    )\n    utils.inject_attribute(class_attributes, 'copy', bucket_copy)\n    utils.inject_attribute(\n        class_attributes, 'upload_fileobj', bucket_upload_fileobj\n    )\n    utils.inject_attribute(\n        class_attributes, 'download_fileobj', bucket_download_fileobj\n    )\n\n\ndef inject_object_methods(class_attributes, **kwargs):\n    utils.inject_attribute(class_attributes, 'upload_file', object_upload_file)\n    utils.inject_attribute(\n        class_attributes, 'download_file', object_download_file\n    )\n    utils.inject_attribute(class_attributes, 'copy', object_copy)\n    utils.inject_attribute(\n        class_attributes, 'upload_fileobj', object_upload_fileobj\n    )\n    utils.inject_attribute(\n        class_attributes, 'download_fileobj', object_download_fileobj\n    )\n\n\ndef inject_object_summary_methods(class_attributes, **kwargs):\n    utils.inject_attribute(class_attributes, 'load', object_summary_load)\n\n\ndef bucket_load(self, *args, **kwargs):\n    \"\"\"\n    Calls s3.Client.list_buckets() to update the attributes of the Bucket\n    resource.\n    \"\"\"\n    # The docstring above is phrased this way to match what the autogenerated\n    # docs produce.\n\n    # We can't actually get the bucket's attributes from a HeadBucket,\n    # so we need to use a ListBuckets and search for our bucket.\n    # However, we may fail if we lack permissions to ListBuckets\n    # or the bucket is in another account. In which case, creation_date\n    # will be None.\n    self.meta.data = {}\n    try:\n        response = self.meta.client.list_buckets()\n        for bucket_data in response['Buckets']:\n            if bucket_data['Name'] == self.name:\n                self.meta.data = bucket_data\n                break\n    except ClientError as e:\n        if not e.response.get('Error', {}).get('Code') == 'AccessDenied':\n            raise\n\n\ndef object_summary_load(self, *args, **kwargs):\n    \"\"\"\n    Calls s3.Client.head_object to update the attributes of the ObjectSummary\n    resource.\n    \"\"\"\n    response = self.meta.client.head_object(\n        Bucket=self.bucket_name, Key=self.key\n    )\n    if 'ContentLength' in response:\n        response['Size'] = response.pop('ContentLength')\n    self.meta.data = response\n\n\ndef upload_file(\n    self, Filename, Bucket, Key, ExtraArgs=None, Callback=None, Config=None\n):\n    \"\"\"Upload a file to an S3 object.\n\n    Usage::\n\n        import boto3\n        s3 = boto3.client('s3')\n        s3.upload_file('/tmp/hello.txt', 'mybucket', 'hello.txt')\n\n    Similar behavior as S3Transfer's upload_file() method, except that\n    argument names are capitalized. Detailed examples can be found at\n    :ref:`S3Transfer's Usage <ref_s3transfer_usage>`.\n\n    :type Filename: str\n    :param Filename: The path to the file to upload.\n\n    :type Bucket: str\n    :param Bucket: The name of the bucket to upload to.\n\n    :type Key: str\n    :param Key: The name of the key to upload to.\n\n    :type ExtraArgs: dict\n    :param ExtraArgs: Extra arguments that may be passed to the\n        client operation. For allowed upload arguments see\n        boto3.s3.transfer.S3Transfer.ALLOWED_UPLOAD_ARGS.\n\n    :type Callback: function\n    :param Callback: A method which takes a number of bytes transferred to\n        be periodically called during the upload.\n\n    :type Config: boto3.s3.transfer.TransferConfig\n    :param Config: The transfer configuration to be used when performing the\n        transfer.\n    \"\"\"\n    with S3Transfer(self, Config) as transfer:\n        return transfer.upload_file(\n            filename=Filename,\n            bucket=Bucket,\n            key=Key,\n            extra_args=ExtraArgs,\n            callback=Callback,\n        )\n\n\ndef download_file(\n    self, Bucket, Key, Filename, ExtraArgs=None, Callback=None, Config=None\n):\n    \"\"\"Download an S3 object to a file.\n\n    Usage::\n\n        import boto3\n        s3 = boto3.client('s3')\n        s3.download_file('mybucket', 'hello.txt', '/tmp/hello.txt')\n\n    Similar behavior as S3Transfer's download_file() method,\n    except that parameters are capitalized. Detailed examples can be found at\n    :ref:`S3Transfer's Usage <ref_s3transfer_usage>`.\n\n    :type Bucket: str\n    :param Bucket: The name of the bucket to download from.\n\n    :type Key: str\n    :param Key: The name of the key to download from.\n\n    :type Filename: str\n    :param Filename: The path to the file to download to.\n\n    :type ExtraArgs: dict\n    :param ExtraArgs: Extra arguments that may be passed to the\n        client operation. For allowed download arguments see\n        boto3.s3.transfer.S3Transfer.ALLOWED_DOWNLOAD_ARGS.\n\n    :type Callback: function\n    :param Callback: A method which takes a number of bytes transferred to\n        be periodically called during the download.\n\n    :type Config: boto3.s3.transfer.TransferConfig\n    :param Config: The transfer configuration to be used when performing the\n        transfer.\n    \"\"\"\n    with S3Transfer(self, Config) as transfer:\n        return transfer.download_file(\n            bucket=Bucket,\n            key=Key,\n            filename=Filename,\n            extra_args=ExtraArgs,\n            callback=Callback,\n        )\n\n\ndef bucket_upload_file(\n    self, Filename, Key, ExtraArgs=None, Callback=None, Config=None\n):\n    \"\"\"Upload a file to an S3 object.\n\n    Usage::\n\n        import boto3\n        s3 = boto3.resource('s3')\n        s3.Bucket('mybucket').upload_file('/tmp/hello.txt', 'hello.txt')\n\n    Similar behavior as S3Transfer's upload_file() method,\n    except that parameters are capitalized. Detailed examples can be found at\n    :ref:`S3Transfer's Usage <ref_s3transfer_usage>`.\n\n    :type Filename: str\n    :param Filename: The path to the file to upload.\n\n    :type Key: str\n    :param Key: The name of the key to upload to.\n\n    :type ExtraArgs: dict\n    :param ExtraArgs: Extra arguments that may be passed to the\n        client operation. For allowed upload arguments see\n        boto3.s3.transfer.S3Transfer.ALLOWED_UPLOAD_ARGS.\n\n    :type Callback: function\n    :param Callback: A method which takes a number of bytes transferred to\n        be periodically called during the upload.\n\n    :type Config: boto3.s3.transfer.TransferConfig\n    :param Config: The transfer configuration to be used when performing the\n        transfer.\n    \"\"\"\n    return self.meta.client.upload_file(\n        Filename=Filename,\n        Bucket=self.name,\n        Key=Key,\n        ExtraArgs=ExtraArgs,\n        Callback=Callback,\n        Config=Config,\n    )\n\n\ndef bucket_download_file(\n    self, Key, Filename, ExtraArgs=None, Callback=None, Config=None\n):\n    \"\"\"Download an S3 object to a file.\n\n    Usage::\n\n        import boto3\n        s3 = boto3.resource('s3')\n        s3.Bucket('mybucket').download_file('hello.txt', '/tmp/hello.txt')\n\n    Similar behavior as S3Transfer's download_file() method,\n    except that parameters are capitalized. Detailed examples can be found at\n    :ref:`S3Transfer's Usage <ref_s3transfer_usage>`.\n\n    :type Key: str\n    :param Key: The name of the key to download from.\n\n    :type Filename: str\n    :param Filename: The path to the file to download to.\n\n    :type ExtraArgs: dict\n    :param ExtraArgs: Extra arguments that may be passed to the\n        client operation. For allowed download arguments see\n        boto3.s3.transfer.S3Transfer.ALLOWED_DOWNLOAD_ARGS.\n\n    :type Callback: function\n    :param Callback: A method which takes a number of bytes transferred to\n        be periodically called during the download.\n\n    :type Config: boto3.s3.transfer.TransferConfig\n    :param Config: The transfer configuration to be used when performing the\n        transfer.\n    \"\"\"\n    return self.meta.client.download_file(\n        Bucket=self.name,\n        Key=Key,\n        Filename=Filename,\n        ExtraArgs=ExtraArgs,\n        Callback=Callback,\n        Config=Config,\n    )\n\n\ndef object_upload_file(\n    self, Filename, ExtraArgs=None, Callback=None, Config=None\n):\n    \"\"\"Upload a file to an S3 object.\n\n    Usage::\n\n        import boto3\n        s3 = boto3.resource('s3')\n        s3.Object('mybucket', 'hello.txt').upload_file('/tmp/hello.txt')\n\n    Similar behavior as S3Transfer's upload_file() method,\n    except that parameters are capitalized. Detailed examples can be found at\n    :ref:`S3Transfer's Usage <ref_s3transfer_usage>`.\n\n    :type Filename: str\n    :param Filename: The path to the file to upload.\n\n    :type ExtraArgs: dict\n    :param ExtraArgs: Extra arguments that may be passed to the\n        client operation. For allowed upload arguments see\n        boto3.s3.transfer.S3Transfer.ALLOWED_UPLOAD_ARGS.\n\n    :type Callback: function\n    :param Callback: A method which takes a number of bytes transferred to\n        be periodically called during the upload.\n\n    :type Config: boto3.s3.transfer.TransferConfig\n    :param Config: The transfer configuration to be used when performing the\n        transfer.\n    \"\"\"\n    return self.meta.client.upload_file(\n        Filename=Filename,\n        Bucket=self.bucket_name,\n        Key=self.key,\n        ExtraArgs=ExtraArgs,\n        Callback=Callback,\n        Config=Config,\n    )\n\n\ndef object_download_file(\n    self, Filename, ExtraArgs=None, Callback=None, Config=None\n):\n    \"\"\"Download an S3 object to a file.\n\n    Usage::\n\n        import boto3\n        s3 = boto3.resource('s3')\n        s3.Object('mybucket', 'hello.txt').download_file('/tmp/hello.txt')\n\n    Similar behavior as S3Transfer's download_file() method,\n    except that parameters are capitalized. Detailed examples can be found at\n    :ref:`S3Transfer's Usage <ref_s3transfer_usage>`.\n\n    :type Filename: str\n    :param Filename: The path to the file to download to.\n\n    :type ExtraArgs: dict\n    :param ExtraArgs: Extra arguments that may be passed to the\n        client operation. For allowed download arguments see\n        boto3.s3.transfer.S3Transfer.ALLOWED_DOWNLOAD_ARGS.\n\n    :type Callback: function\n    :param Callback: A method which takes a number of bytes transferred to\n        be periodically called during the download.\n\n    :type Config: boto3.s3.transfer.TransferConfig\n    :param Config: The transfer configuration to be used when performing the\n        transfer.\n    \"\"\"\n    return self.meta.client.download_file(\n        Bucket=self.bucket_name,\n        Key=self.key,\n        Filename=Filename,\n        ExtraArgs=ExtraArgs,\n        Callback=Callback,\n        Config=Config,\n    )\n\n\ndef copy(\n    self,\n    CopySource,\n    Bucket,\n    Key,\n    ExtraArgs=None,\n    Callback=None,\n    SourceClient=None,\n    Config=None,\n):\n    \"\"\"Copy an object from one S3 location to another.\n\n    This is a managed transfer which will perform a multipart copy in\n    multiple threads if necessary.\n\n    Usage::\n\n        import boto3\n        s3 = boto3.resource('s3')\n        copy_source = {\n            'Bucket': 'mybucket',\n            'Key': 'mykey'\n        }\n        s3.meta.client.copy(copy_source, 'otherbucket', 'otherkey')\n\n    :type CopySource: dict\n    :param CopySource: The name of the source bucket, key name of the\n        source object, and optional version ID of the source object. The\n        dictionary format is:\n        ``{'Bucket': 'bucket', 'Key': 'key', 'VersionId': 'id'}``. Note\n        that the ``VersionId`` key is optional and may be omitted.\n\n    :type Bucket: str\n    :param Bucket: The name of the bucket to copy to\n\n    :type Key: str\n    :param Key: The name of the key to copy to\n\n    :type ExtraArgs: dict\n    :param ExtraArgs: Extra arguments that may be passed to the\n        client operation. For allowed download arguments see\n        boto3.s3.transfer.S3Transfer.ALLOWED_DOWNLOAD_ARGS.\n\n    :type Callback: function\n    :param Callback: A method which takes a number of bytes transferred to\n        be periodically called during the copy.\n\n    :type SourceClient: botocore or boto3 Client\n    :param SourceClient: The client to be used for operation that\n        may happen at the source object. For example, this client is\n        used for the head_object that determines the size of the copy.\n        If no client is provided, the current client is used as the client\n        for the source object.\n\n    :type Config: boto3.s3.transfer.TransferConfig\n    :param Config: The transfer configuration to be used when performing the\n        copy.\n    \"\"\"\n    subscribers = None\n    if Callback is not None:\n        subscribers = [ProgressCallbackInvoker(Callback)]\n\n    config = Config\n    if config is None:\n        config = TransferConfig()\n\n    # copy is not supported in the CRT\n    new_config = python_copy.copy(config)\n    new_config.preferred_transfer_client = \"classic\"\n\n    with create_transfer_manager(self, new_config) as manager:\n        future = manager.copy(\n            copy_source=CopySource,\n            bucket=Bucket,\n            key=Key,\n            extra_args=ExtraArgs,\n            subscribers=subscribers,\n            source_client=SourceClient,\n        )\n        return future.result()\n\n\ndef bucket_copy(\n    self,\n    CopySource,\n    Key,\n    ExtraArgs=None,\n    Callback=None,\n    SourceClient=None,\n    Config=None,\n):\n    \"\"\"Copy an object from one S3 location to an object in this bucket.\n\n    This is a managed transfer which will perform a multipart copy in\n    multiple threads if necessary.\n\n    Usage::\n\n        import boto3\n        s3 = boto3.resource('s3')\n        copy_source = {\n            'Bucket': 'mybucket',\n            'Key': 'mykey'\n        }\n        bucket = s3.Bucket('otherbucket')\n        bucket.copy(copy_source, 'otherkey')\n\n    :type CopySource: dict\n    :param CopySource: The name of the source bucket, key name of the\n        source object, and optional version ID of the source object. The\n        dictionary format is:\n        ``{'Bucket': 'bucket', 'Key': 'key', 'VersionId': 'id'}``. Note\n        that the ``VersionId`` key is optional and may be omitted.\n\n    :type Key: str\n    :param Key: The name of the key to copy to\n\n    :type ExtraArgs: dict\n    :param ExtraArgs: Extra arguments that may be passed to the\n        client operation. For allowed download arguments see\n        boto3.s3.transfer.S3Transfer.ALLOWED_DOWNLOAD_ARGS.\n\n    :type Callback: function\n    :param Callback: A method which takes a number of bytes transferred to\n        be periodically called during the copy.\n\n    :type SourceClient: botocore or boto3 Client\n    :param SourceClient: The client to be used for operation that\n        may happen at the source object. For example, this client is\n        used for the head_object that determines the size of the copy.\n        If no client is provided, the current client is used as the client\n        for the source object.\n\n    :type Config: boto3.s3.transfer.TransferConfig\n    :param Config: The transfer configuration to be used when performing the\n        copy.\n    \"\"\"\n    return self.meta.client.copy(\n        CopySource=CopySource,\n        Bucket=self.name,\n        Key=Key,\n        ExtraArgs=ExtraArgs,\n        Callback=Callback,\n        SourceClient=SourceClient,\n        Config=Config,\n    )\n\n\ndef object_copy(\n    self,\n    CopySource,\n    ExtraArgs=None,\n    Callback=None,\n    SourceClient=None,\n    Config=None,\n):\n    \"\"\"Copy an object from one S3 location to this object.\n\n    This is a managed transfer which will perform a multipart copy in\n    multiple threads if necessary.\n\n    Usage::\n\n        import boto3\n        s3 = boto3.resource('s3')\n        copy_source = {\n            'Bucket': 'mybucket',\n            'Key': 'mykey'\n        }\n        bucket = s3.Bucket('otherbucket')\n        obj = bucket.Object('otherkey')\n        obj.copy(copy_source)\n\n    :type CopySource: dict\n    :param CopySource: The name of the source bucket, key name of the\n        source object, and optional version ID of the source object. The\n        dictionary format is:\n        ``{'Bucket': 'bucket', 'Key': 'key', 'VersionId': 'id'}``. Note\n        that the ``VersionId`` key is optional and may be omitted.\n\n    :type ExtraArgs: dict\n    :param ExtraArgs: Extra arguments that may be passed to the\n        client operation. For allowed download arguments see\n        boto3.s3.transfer.S3Transfer.ALLOWED_DOWNLOAD_ARGS.\n\n    :type Callback: function\n    :param Callback: A method which takes a number of bytes transferred to\n        be periodically called during the copy.\n\n    :type SourceClient: botocore or boto3 Client\n    :param SourceClient: The client to be used for operation that\n        may happen at the source object. For example, this client is\n        used for the head_object that determines the size of the copy.\n        If no client is provided, the current client is used as the client\n        for the source object.\n\n    :type Config: boto3.s3.transfer.TransferConfig\n    :param Config: The transfer configuration to be used when performing the\n        copy.\n    \"\"\"\n    return self.meta.client.copy(\n        CopySource=CopySource,\n        Bucket=self.bucket_name,\n        Key=self.key,\n        ExtraArgs=ExtraArgs,\n        Callback=Callback,\n        SourceClient=SourceClient,\n        Config=Config,\n    )\n\n\ndef upload_fileobj(\n    self, Fileobj, Bucket, Key, ExtraArgs=None, Callback=None, Config=None\n):\n    \"\"\"Upload a file-like object to S3.\n\n    The file-like object must be in binary mode.\n\n    This is a managed transfer which will perform a multipart upload in\n    multiple threads if necessary.\n\n    Usage::\n\n        import boto3\n        s3 = boto3.client('s3')\n\n        with open('filename', 'rb') as data:\n            s3.upload_fileobj(data, 'mybucket', 'mykey')\n\n    :type Fileobj: a file-like object\n    :param Fileobj: A file-like object to upload. At a minimum, it must\n        implement the `read` method, and must return bytes.\n\n    :type Bucket: str\n    :param Bucket: The name of the bucket to upload to.\n\n    :type Key: str\n    :param Key: The name of the key to upload to.\n\n    :type ExtraArgs: dict\n    :param ExtraArgs: Extra arguments that may be passed to the\n        client operation. For allowed upload arguments see\n        boto3.s3.transfer.S3Transfer.ALLOWED_UPLOAD_ARGS.\n\n    :type Callback: function\n    :param Callback: A method which takes a number of bytes transferred to\n        be periodically called during the upload.\n\n    :type Config: boto3.s3.transfer.TransferConfig\n    :param Config: The transfer configuration to be used when performing the\n        upload.\n    \"\"\"\n    if not hasattr(Fileobj, 'read'):\n        raise ValueError('Fileobj must implement read')\n\n    subscribers = None\n    if Callback is not None:\n        subscribers = [ProgressCallbackInvoker(Callback)]\n\n    config = Config\n    if config is None:\n        config = TransferConfig()\n\n    with create_transfer_manager(self, config) as manager:\n        future = manager.upload(\n            fileobj=Fileobj,\n            bucket=Bucket,\n            key=Key,\n            extra_args=ExtraArgs,\n            subscribers=subscribers,\n        )\n        return future.result()\n\n\ndef bucket_upload_fileobj(\n    self, Fileobj, Key, ExtraArgs=None, Callback=None, Config=None\n):\n    \"\"\"Upload a file-like object to this bucket.\n\n    The file-like object must be in binary mode.\n\n    This is a managed transfer which will perform a multipart upload in\n    multiple threads if necessary.\n\n    Usage::\n\n        import boto3\n        s3 = boto3.resource('s3')\n        bucket = s3.Bucket('mybucket')\n\n        with open('filename', 'rb') as data:\n            bucket.upload_fileobj(data, 'mykey')\n\n    :type Fileobj: a file-like object\n    :param Fileobj: A file-like object to upload. At a minimum, it must\n        implement the `read` method, and must return bytes.\n\n    :type Key: str\n    :param Key: The name of the key to upload to.\n\n    :type ExtraArgs: dict\n    :param ExtraArgs: Extra arguments that may be passed to the\n        client operation. For allowed upload arguments see\n        boto3.s3.transfer.S3Transfer.ALLOWED_UPLOAD_ARGS.\n\n    :type Callback: function\n    :param Callback: A method which takes a number of bytes transferred to\n        be periodically called during the upload.\n\n    :type Config: boto3.s3.transfer.TransferConfig\n    :param Config: The transfer configuration to be used when performing the\n        upload.\n    \"\"\"\n    return self.meta.client.upload_fileobj(\n        Fileobj=Fileobj,\n        Bucket=self.name,\n        Key=Key,\n        ExtraArgs=ExtraArgs,\n        Callback=Callback,\n        Config=Config,\n    )\n\n\ndef object_upload_fileobj(\n    self, Fileobj, ExtraArgs=None, Callback=None, Config=None\n):\n    \"\"\"Upload a file-like object to this object.\n\n    The file-like object must be in binary mode.\n\n    This is a managed transfer which will perform a multipart upload in\n    multiple threads if necessary.\n\n    Usage::\n\n        import boto3\n        s3 = boto3.resource('s3')\n        bucket = s3.Bucket('mybucket')\n        obj = bucket.Object('mykey')\n\n        with open('filename', 'rb') as data:\n            obj.upload_fileobj(data)\n\n    :type Fileobj: a file-like object\n    :param Fileobj: A file-like object to upload. At a minimum, it must\n        implement the `read` method, and must return bytes.\n\n    :type ExtraArgs: dict\n    :param ExtraArgs: Extra arguments that may be passed to the\n        client operation. For allowed upload arguments see\n        boto3.s3.transfer.S3Transfer.ALLOWED_UPLOAD_ARGS.\n\n    :type Callback: function\n    :param Callback: A method which takes a number of bytes transferred to\n        be periodically called during the upload.\n\n    :type Config: boto3.s3.transfer.TransferConfig\n    :param Config: The transfer configuration to be used when performing the\n        upload.\n    \"\"\"\n    return self.meta.client.upload_fileobj(\n        Fileobj=Fileobj,\n        Bucket=self.bucket_name,\n        Key=self.key,\n        ExtraArgs=ExtraArgs,\n        Callback=Callback,\n        Config=Config,\n    )\n\n\ndef download_fileobj(\n    self, Bucket, Key, Fileobj, ExtraArgs=None, Callback=None, Config=None\n):\n    \"\"\"Download an object from S3 to a file-like object.\n\n    The file-like object must be in binary mode.\n\n    This is a managed transfer which will perform a multipart download in\n    multiple threads if necessary.\n\n    Usage::\n\n        import boto3\n        s3 = boto3.client('s3')\n\n        with open('filename', 'wb') as data:\n            s3.download_fileobj('mybucket', 'mykey', data)\n\n    :type Bucket: str\n    :param Bucket: The name of the bucket to download from.\n\n    :type Key: str\n    :param Key: The name of the key to download from.\n\n    :type Fileobj: a file-like object\n    :param Fileobj: A file-like object to download into. At a minimum, it must\n        implement the `write` method and must accept bytes.\n\n    :type ExtraArgs: dict\n    :param ExtraArgs: Extra arguments that may be passed to the\n        client operation. For allowed download arguments see\n        boto3.s3.transfer.S3Transfer.ALLOWED_DOWNLOAD_ARGS.\n\n    :type Callback: function\n    :param Callback: A method which takes a number of bytes transferred to\n        be periodically called during the download.\n\n    :type Config: boto3.s3.transfer.TransferConfig\n    :param Config: The transfer configuration to be used when performing the\n        download.\n    \"\"\"\n    if not hasattr(Fileobj, 'write'):\n        raise ValueError('Fileobj must implement write')\n\n    subscribers = None\n    if Callback is not None:\n        subscribers = [ProgressCallbackInvoker(Callback)]\n\n    config = Config\n    if config is None:\n        config = TransferConfig()\n\n    with create_transfer_manager(self, config) as manager:\n        future = manager.download(\n            bucket=Bucket,\n            key=Key,\n            fileobj=Fileobj,\n            extra_args=ExtraArgs,\n            subscribers=subscribers,\n        )\n        return future.result()\n\n\ndef bucket_download_fileobj(\n    self, Key, Fileobj, ExtraArgs=None, Callback=None, Config=None\n):\n    \"\"\"Download an object from this bucket to a file-like-object.\n\n    The file-like object must be in binary mode.\n\n    This is a managed transfer which will perform a multipart download in\n    multiple threads if necessary.\n\n    Usage::\n\n        import boto3\n        s3 = boto3.resource('s3')\n        bucket = s3.Bucket('mybucket')\n\n        with open('filename', 'wb') as data:\n            bucket.download_fileobj('mykey', data)\n\n    :type Fileobj: a file-like object\n    :param Fileobj: A file-like object to download into. At a minimum, it must\n        implement the `write` method and must accept bytes.\n\n    :type Key: str\n    :param Key: The name of the key to download from.\n\n    :type ExtraArgs: dict\n    :param ExtraArgs: Extra arguments that may be passed to the\n        client operation. For allowed download arguments see\n        boto3.s3.transfer.S3Transfer.ALLOWED_DOWNLOAD_ARGS.\n\n    :type Callback: function\n    :param Callback: A method which takes a number of bytes transferred to\n        be periodically called during the download.\n\n    :type Config: boto3.s3.transfer.TransferConfig\n    :param Config: The transfer configuration to be used when performing the\n        download.\n    \"\"\"\n    return self.meta.client.download_fileobj(\n        Bucket=self.name,\n        Key=Key,\n        Fileobj=Fileobj,\n        ExtraArgs=ExtraArgs,\n        Callback=Callback,\n        Config=Config,\n    )\n\n\ndef object_download_fileobj(\n    self, Fileobj, ExtraArgs=None, Callback=None, Config=None\n):\n    \"\"\"Download this object from S3 to a file-like object.\n\n    The file-like object must be in binary mode.\n\n    This is a managed transfer which will perform a multipart download in\n    multiple threads if necessary.\n\n    Usage::\n\n        import boto3\n        s3 = boto3.resource('s3')\n        bucket = s3.Bucket('mybucket')\n        obj = bucket.Object('mykey')\n\n        with open('filename', 'wb') as data:\n            obj.download_fileobj(data)\n\n    :type Fileobj: a file-like object\n    :param Fileobj: A file-like object to download into. At a minimum, it must\n        implement the `write` method and must accept bytes.\n\n    :type ExtraArgs: dict\n    :param ExtraArgs: Extra arguments that may be passed to the\n        client operation. For allowed download arguments see\n        boto3.s3.transfer.S3Transfer.ALLOWED_DOWNLOAD_ARGS.\n\n    :type Callback: function\n    :param Callback: A method which takes a number of bytes transferred to\n        be periodically called during the download.\n\n    :type Config: boto3.s3.transfer.TransferConfig\n    :param Config: The transfer configuration to be used when performing the\n        download.\n    \"\"\"\n    return self.meta.client.download_fileobj(\n        Bucket=self.bucket_name,\n        Key=self.key,\n        Fileobj=Fileobj,\n        ExtraArgs=ExtraArgs,\n        Callback=Callback,\n        Config=Config,\n    )\n", "boto3/s3/transfer.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n\"\"\"Abstractions over S3's upload/download operations.\n\nThis module provides high level abstractions for efficient\nuploads/downloads.  It handles several things for the user:\n\n* Automatically switching to multipart transfers when\n  a file is over a specific size threshold\n* Uploading/downloading a file in parallel\n* Progress callbacks to monitor transfers\n* Retries.  While botocore handles retries for streaming uploads,\n  it is not possible for it to handle retries for streaming\n  downloads.  This module handles retries for both cases so\n  you don't need to implement any retry logic yourself.\n\nThis module has a reasonable set of defaults.  It also allows you\nto configure many aspects of the transfer process including:\n\n* Multipart threshold size\n* Max parallel downloads\n* Socket timeouts\n* Retry amounts\n\nThere is no support for s3->s3 multipart copies at this\ntime.\n\n\n.. _ref_s3transfer_usage:\n\nUsage\n=====\n\nThe simplest way to use this module is:\n\n.. code-block:: python\n\n    client = boto3.client('s3', 'us-west-2')\n    transfer = S3Transfer(client)\n    # Upload /tmp/myfile to s3://bucket/key\n    transfer.upload_file('/tmp/myfile', 'bucket', 'key')\n\n    # Download s3://bucket/key to /tmp/myfile\n    transfer.download_file('bucket', 'key', '/tmp/myfile')\n\nThe ``upload_file`` and ``download_file`` methods also accept\n``**kwargs``, which will be forwarded through to the corresponding\nclient operation.  Here are a few examples using ``upload_file``::\n\n    # Making the object public\n    transfer.upload_file('/tmp/myfile', 'bucket', 'key',\n                         extra_args={'ACL': 'public-read'})\n\n    # Setting metadata\n    transfer.upload_file('/tmp/myfile', 'bucket', 'key',\n                         extra_args={'Metadata': {'a': 'b', 'c': 'd'}})\n\n    # Setting content type\n    transfer.upload_file('/tmp/myfile.json', 'bucket', 'key',\n                         extra_args={'ContentType': \"application/json\"})\n\n\nThe ``S3Transfer`` class also supports progress callbacks so you can\nprovide transfer progress to users.  Both the ``upload_file`` and\n``download_file`` methods take an optional ``callback`` parameter.\nHere's an example of how to print a simple progress percentage\nto the user:\n\n.. code-block:: python\n\n    class ProgressPercentage(object):\n        def __init__(self, filename):\n            self._filename = filename\n            self._size = float(os.path.getsize(filename))\n            self._seen_so_far = 0\n            self._lock = threading.Lock()\n\n        def __call__(self, bytes_amount):\n            # To simplify we'll assume this is hooked up\n            # to a single filename.\n            with self._lock:\n                self._seen_so_far += bytes_amount\n                percentage = (self._seen_so_far / self._size) * 100\n                sys.stdout.write(\n                    \"\\r%s  %s / %s  (%.2f%%)\" % (\n                        self._filename, self._seen_so_far, self._size,\n                        percentage))\n                sys.stdout.flush()\n\n\n    transfer = S3Transfer(boto3.client('s3', 'us-west-2'))\n    # Upload /tmp/myfile to s3://bucket/key and print upload progress.\n    transfer.upload_file('/tmp/myfile', 'bucket', 'key',\n                         callback=ProgressPercentage('/tmp/myfile'))\n\n\n\nYou can also provide a TransferConfig object to the S3Transfer\nobject that gives you more fine grained control over the\ntransfer.  For example:\n\n.. code-block:: python\n\n    client = boto3.client('s3', 'us-west-2')\n    config = TransferConfig(\n        multipart_threshold=8 * 1024 * 1024,\n        max_concurrency=10,\n        num_download_attempts=10,\n    )\n    transfer = S3Transfer(client, config)\n    transfer.upload_file('/tmp/foo', 'bucket', 'key')\n\n\n\"\"\"\n\nimport logging\nimport threading\nfrom os import PathLike, fspath, getpid\n\nfrom botocore.compat import HAS_CRT\nfrom botocore.exceptions import ClientError\nfrom s3transfer.exceptions import (\n    RetriesExceededError as S3TransferRetriesExceededError,\n)\nfrom s3transfer.futures import NonThreadedExecutor\nfrom s3transfer.manager import TransferConfig as S3TransferConfig\nfrom s3transfer.manager import TransferManager\nfrom s3transfer.subscribers import BaseSubscriber\nfrom s3transfer.utils import OSUtils\n\nimport boto3.s3.constants as constants\nfrom boto3.exceptions import RetriesExceededError, S3UploadFailedError\n\nif HAS_CRT:\n    import awscrt.s3\n\n    from boto3.crt import create_crt_transfer_manager\n\nKB = 1024\nMB = KB * KB\n\nlogger = logging.getLogger(__name__)\n\n\ndef create_transfer_manager(client, config, osutil=None):\n    \"\"\"Creates a transfer manager based on configuration\n\n    :type client: boto3.client\n    :param client: The S3 client to use\n\n    :type config: boto3.s3.transfer.TransferConfig\n    :param config: The transfer config to use\n\n    :type osutil: s3transfer.utils.OSUtils\n    :param osutil: The os utility to use\n\n    :rtype: s3transfer.manager.TransferManager\n    :returns: A transfer manager based on parameters provided\n    \"\"\"\n    if _should_use_crt(config):\n        crt_transfer_manager = create_crt_transfer_manager(client, config)\n        if crt_transfer_manager is not None:\n            logger.debug(\n                f\"Using CRT client. pid: {getpid()}, thread: {threading.get_ident()}\"\n            )\n            return crt_transfer_manager\n\n    # If we don't resolve something above, fallback to the default.\n    logger.debug(\n        f\"Using default client. pid: {getpid()}, thread: {threading.get_ident()}\"\n    )\n    return _create_default_transfer_manager(client, config, osutil)\n\n\ndef _should_use_crt(config):\n    # This feature requires awscrt>=0.19.18\n    if HAS_CRT and has_minimum_crt_version((0, 19, 18)):\n        is_optimized_instance = awscrt.s3.is_optimized_for_system()\n    else:\n        is_optimized_instance = False\n    pref_transfer_client = config.preferred_transfer_client.lower()\n\n    if (\n        is_optimized_instance\n        and pref_transfer_client == constants.AUTO_RESOLVE_TRANSFER_CLIENT\n    ):\n        logger.debug(\n            \"Attempting to use CRTTransferManager. Config settings may be ignored.\"\n        )\n        return True\n\n    logger.debug(\n        \"Opting out of CRT Transfer Manager. Preferred client: \"\n        f\"{pref_transfer_client}, CRT available: {HAS_CRT}, \"\n        f\"Instance Optimized: {is_optimized_instance}.\"\n    )\n    return False\n\n\ndef has_minimum_crt_version(minimum_version):\n    \"\"\"Not intended for use outside boto3.\"\"\"\n    if not HAS_CRT:\n        return False\n\n    crt_version_str = awscrt.__version__\n    try:\n        crt_version_ints = map(int, crt_version_str.split(\".\"))\n        crt_version_tuple = tuple(crt_version_ints)\n    except (TypeError, ValueError):\n        return False\n\n    return crt_version_tuple >= minimum_version\n\n\ndef _create_default_transfer_manager(client, config, osutil):\n    \"\"\"Create the default TransferManager implementation for s3transfer.\"\"\"\n    executor_cls = None\n    if not config.use_threads:\n        executor_cls = NonThreadedExecutor\n    return TransferManager(client, config, osutil, executor_cls)\n\n\nclass TransferConfig(S3TransferConfig):\n    ALIAS = {\n        'max_concurrency': 'max_request_concurrency',\n        'max_io_queue': 'max_io_queue_size',\n    }\n\n    def __init__(\n        self,\n        multipart_threshold=8 * MB,\n        max_concurrency=10,\n        multipart_chunksize=8 * MB,\n        num_download_attempts=5,\n        max_io_queue=100,\n        io_chunksize=256 * KB,\n        use_threads=True,\n        max_bandwidth=None,\n        preferred_transfer_client=constants.AUTO_RESOLVE_TRANSFER_CLIENT,\n    ):\n        \"\"\"Configuration object for managed S3 transfers\n\n        :param multipart_threshold: The transfer size threshold for which\n            multipart uploads, downloads, and copies will automatically be\n            triggered.\n\n        :param max_concurrency: The maximum number of threads that will be\n            making requests to perform a transfer. If ``use_threads`` is\n            set to ``False``, the value provided is ignored as the transfer\n            will only ever use the current thread.\n\n        :param multipart_chunksize: The partition size of each part for a\n            multipart transfer.\n\n        :param num_download_attempts: The number of download attempts that\n            will be retried upon errors with downloading an object in S3.\n            Note that these retries account for errors that occur when\n            streaming  down the data from s3 (i.e. socket errors and read\n            timeouts that occur after receiving an OK response from s3).\n            Other retryable exceptions such as throttling errors and 5xx\n            errors are already retried by botocore (this default is 5). This\n            does not take into account the number of exceptions retried by\n            botocore.\n\n        :param max_io_queue: The maximum amount of read parts that can be\n            queued in memory to be written for a download. The size of each\n            of these read parts is at most the size of ``io_chunksize``.\n\n        :param io_chunksize: The max size of each chunk in the io queue.\n            Currently, this is size used when ``read`` is called on the\n            downloaded stream as well.\n\n        :param use_threads: If True, threads will be used when performing\n            S3 transfers. If False, no threads will be used in\n            performing transfers; all logic will be run in the current thread.\n\n        :param max_bandwidth: The maximum bandwidth that will be consumed\n            in uploading and downloading file content. The value is an integer\n            in terms of bytes per second.\n\n        :param preferred_transfer_client: String specifying preferred transfer\n            client for transfer operations.\n\n            Current supported settings are:\n              * auto (default) - Use the CRTTransferManager when calls\n                  are made with supported environment and settings.\n              * classic - Only use the origin S3TransferManager with\n                  requests. Disables possible CRT upgrade on requests.\n        \"\"\"\n        super().__init__(\n            multipart_threshold=multipart_threshold,\n            max_request_concurrency=max_concurrency,\n            multipart_chunksize=multipart_chunksize,\n            num_download_attempts=num_download_attempts,\n            max_io_queue_size=max_io_queue,\n            io_chunksize=io_chunksize,\n            max_bandwidth=max_bandwidth,\n        )\n        # Some of the argument names are not the same as the inherited\n        # S3TransferConfig so we add aliases so you can still access the\n        # old version of the names.\n        for alias in self.ALIAS:\n            setattr(self, alias, getattr(self, self.ALIAS[alias]))\n        self.use_threads = use_threads\n        self.preferred_transfer_client = preferred_transfer_client\n\n    def __setattr__(self, name, value):\n        # If the alias name is used, make sure we set the name that it points\n        # to as that is what actually is used in governing the TransferManager.\n        if name in self.ALIAS:\n            super().__setattr__(self.ALIAS[name], value)\n        # Always set the value of the actual name provided.\n        super().__setattr__(name, value)\n\n\nclass S3Transfer:\n    ALLOWED_DOWNLOAD_ARGS = TransferManager.ALLOWED_DOWNLOAD_ARGS\n    ALLOWED_UPLOAD_ARGS = TransferManager.ALLOWED_UPLOAD_ARGS\n\n    def __init__(self, client=None, config=None, osutil=None, manager=None):\n        if not client and not manager:\n            raise ValueError(\n                'Either a boto3.Client or s3transfer.manager.TransferManager '\n                'must be provided'\n            )\n        if manager and any([client, config, osutil]):\n            raise ValueError(\n                'Manager cannot be provided with client, config, '\n                'nor osutil. These parameters are mutually exclusive.'\n            )\n        if config is None:\n            config = TransferConfig()\n        if osutil is None:\n            osutil = OSUtils()\n        if manager:\n            self._manager = manager\n        else:\n            self._manager = create_transfer_manager(client, config, osutil)\n\n    def upload_file(\n        self, filename, bucket, key, callback=None, extra_args=None\n    ):\n        \"\"\"Upload a file to an S3 object.\n\n        Variants have also been injected into S3 client, Bucket and Object.\n        You don't have to use S3Transfer.upload_file() directly.\n\n        .. seealso::\n            :py:meth:`S3.Client.upload_file`\n            :py:meth:`S3.Client.upload_fileobj`\n        \"\"\"\n        if isinstance(filename, PathLike):\n            filename = fspath(filename)\n        if not isinstance(filename, str):\n            raise ValueError('Filename must be a string or a path-like object')\n\n        subscribers = self._get_subscribers(callback)\n        future = self._manager.upload(\n            filename, bucket, key, extra_args, subscribers\n        )\n        try:\n            future.result()\n        # If a client error was raised, add the backwards compatibility layer\n        # that raises a S3UploadFailedError. These specific errors were only\n        # ever thrown for upload_parts but now can be thrown for any related\n        # client error.\n        except ClientError as e:\n            raise S3UploadFailedError(\n                \"Failed to upload {} to {}: {}\".format(\n                    filename, '/'.join([bucket, key]), e\n                )\n            )\n\n    def download_file(\n        self, bucket, key, filename, extra_args=None, callback=None\n    ):\n        \"\"\"Download an S3 object to a file.\n\n        Variants have also been injected into S3 client, Bucket and Object.\n        You don't have to use S3Transfer.download_file() directly.\n\n        .. seealso::\n            :py:meth:`S3.Client.download_file`\n            :py:meth:`S3.Client.download_fileobj`\n        \"\"\"\n        if isinstance(filename, PathLike):\n            filename = fspath(filename)\n        if not isinstance(filename, str):\n            raise ValueError('Filename must be a string or a path-like object')\n\n        subscribers = self._get_subscribers(callback)\n        future = self._manager.download(\n            bucket, key, filename, extra_args, subscribers\n        )\n        try:\n            future.result()\n        # This is for backwards compatibility where when retries are\n        # exceeded we need to throw the same error from boto3 instead of\n        # s3transfer's built in RetriesExceededError as current users are\n        # catching the boto3 one instead of the s3transfer exception to do\n        # their own retries.\n        except S3TransferRetriesExceededError as e:\n            raise RetriesExceededError(e.last_exception)\n\n    def _get_subscribers(self, callback):\n        if not callback:\n            return None\n        return [ProgressCallbackInvoker(callback)]\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *args):\n        self._manager.__exit__(*args)\n\n\nclass ProgressCallbackInvoker(BaseSubscriber):\n    \"\"\"A back-compat wrapper to invoke a provided callback via a subscriber\n\n    :param callback: A callable that takes a single positional argument for\n        how many bytes were transferred.\n    \"\"\"\n\n    def __init__(self, callback):\n        self._callback = callback\n\n    def on_progress(self, bytes_transferred, **kwargs):\n        self._callback(bytes_transferred)\n", "boto3/s3/constants.py": "# Copyright 2023 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n\n\n# TransferConfig preferred_transfer_client settings\nCLASSIC_TRANSFER_CLIENT = \"classic\"\nAUTO_RESOLVE_TRANSFER_CLIENT = \"auto\"\n", "boto3/s3/__init__.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n"}