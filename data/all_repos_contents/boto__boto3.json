{"setup.py": "#!/usr/bin/env python\n\n\"\"\"\ndistutils/setuptools install script.\n\"\"\"\n\nimport os\nimport re\n\nfrom setuptools import find_packages, setup\n\nROOT = os.path.dirname(__file__)\nVERSION_RE = re.compile(r'''__version__ = ['\"]([0-9.]+)['\"]''')\n\n\nrequires = [\n    'botocore>=1.34.132,<1.35.0',\n    'jmespath>=0.7.1,<2.0.0',\n    's3transfer>=0.10.0,<0.11.0',\n]\n\n\ndef get_version():\n    init = open(os.path.join(ROOT, 'boto3', '__init__.py')).read()\n    return VERSION_RE.search(init).group(1)\n\n\nsetup(\n    name='boto3',\n    version=get_version(),\n    description='The AWS SDK for Python',\n    long_description=open('README.rst').read(),\n    author='Amazon Web Services',\n    url='https://github.com/boto/boto3',\n    scripts=[],\n    packages=find_packages(exclude=['tests*']),\n    package_data={'boto3': ['data/aws/resources/*.json', 'examples/*.rst']},\n    include_package_data=True,\n    install_requires=requires,\n    license=\"Apache License 2.0\",\n    python_requires=\">= 3.8\",\n    classifiers=[\n        'Development Status :: 5 - Production/Stable',\n        'Intended Audience :: Developers',\n        'Natural Language :: English',\n        'License :: OSI Approved :: Apache Software License',\n        'Programming Language :: Python',\n        'Programming Language :: Python :: 3',\n        'Programming Language :: Python :: 3 :: Only',\n        'Programming Language :: Python :: 3.8',\n        'Programming Language :: Python :: 3.9',\n        'Programming Language :: Python :: 3.10',\n        'Programming Language :: Python :: 3.11',\n        'Programming Language :: Python :: 3.12',\n    ],\n    project_urls={\n        'Documentation': 'https://boto3.amazonaws.com/v1/documentation/api/latest/index.html',\n        'Source': 'https://github.com/boto/boto3',\n    },\n)\n", "boto3/exceptions.py": "# Copyright 2014 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n\n# All exceptions in this class should subclass from Boto3Error.\nimport botocore.exceptions\n\n\n# All exceptions should subclass from Boto3Error in this module.\nclass Boto3Error(Exception):\n    \"\"\"Base class for all Boto3 errors.\"\"\"\n\n\nclass ResourceLoadException(Boto3Error):\n    pass\n\n\n# NOTE: This doesn't appear to be used anywhere.\n# It's probably safe to remove this.\nclass NoVersionFound(Boto3Error):\n    pass\n\n\n# We're subclassing from botocore.exceptions.DataNotFoundError\n# to keep backwards compatibility with anyone that was catching\n# this low level Botocore error before this exception was\n# introduced in boto3.\n# Same thing for ResourceNotExistsError below.\nclass UnknownAPIVersionError(\n    Boto3Error, botocore.exceptions.DataNotFoundError\n):\n    def __init__(self, service_name, bad_api_version, available_api_versions):\n        msg = (\n            f\"The '{service_name}' resource does not support an API version of: {bad_api_version}\\n\"\n            f\"Valid API versions are: {available_api_versions}\"\n        )\n        # Not using super because we don't want the DataNotFoundError\n        # to be called, it has a different __init__ signature.\n        Boto3Error.__init__(self, msg)\n\n\nclass ResourceNotExistsError(\n    Boto3Error, botocore.exceptions.DataNotFoundError\n):\n    \"\"\"Raised when you attempt to create a resource that does not exist.\"\"\"\n\n    def __init__(self, service_name, available_services, has_low_level_client):\n        msg = (\n            \"The '{}' resource does not exist.\\n\"\n            \"The available resources are:\\n\"\n            \"   - {}\\n\".format(\n                service_name, '\\n   - '.join(available_services)\n            )\n        )\n        if has_low_level_client:\n            msg = (\n                f\"{msg}\\nConsider using a boto3.client('{service_name}') \"\n                f\"instead of a resource for '{service_name}'\"\n            )\n        # Not using super because we don't want the DataNotFoundError\n        # to be called, it has a different __init__ signature.\n        Boto3Error.__init__(self, msg)\n\n\nclass RetriesExceededError(Boto3Error):\n    def __init__(self, last_exception, msg='Max Retries Exceeded'):\n        super().__init__(msg)\n        self.last_exception = last_exception\n\n\nclass S3TransferFailedError(Boto3Error):\n    pass\n\n\nclass S3UploadFailedError(Boto3Error):\n    pass\n\n\nclass DynamoDBOperationNotSupportedError(Boto3Error):\n    \"\"\"Raised for operations that are not supported for an operand.\"\"\"\n\n    def __init__(self, operation, value):\n        msg = (\n            f'{operation} operation cannot be applied to value {value} of type '\n            f'{type(value)} directly. Must use AttributeBase object methods '\n            f'(i.e. Attr().eq()). to generate ConditionBase instances first.'\n        )\n        Exception.__init__(self, msg)\n\n\n# FIXME: Backward compatibility\nDynanmoDBOperationNotSupportedError = DynamoDBOperationNotSupportedError\n\n\nclass DynamoDBNeedsConditionError(Boto3Error):\n    \"\"\"Raised when input is not a condition\"\"\"\n\n    def __init__(self, value):\n        msg = (\n            f'Expecting a ConditionBase object. Got {value} of type {type(value)}. '\n            f'Use AttributeBase object methods (i.e. Attr().eq()). to '\n            f'generate ConditionBase instances.'\n        )\n        Exception.__init__(self, msg)\n\n\nclass DynamoDBNeedsKeyConditionError(Boto3Error):\n    pass\n\n\nclass PythonDeprecationWarning(Warning):\n    \"\"\"\n    Python version being used is scheduled to become unsupported\n    in an future release. See warning for specifics.\n    \"\"\"\n\n    pass\n", "boto3/utils.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport sys\nfrom collections import namedtuple\n\n_ServiceContext = namedtuple(\n    'ServiceContext',\n    [\n        'service_name',\n        'service_model',\n        'service_waiter_model',\n        'resource_json_definitions',\n    ],\n)\n\n\nclass ServiceContext(_ServiceContext):\n    \"\"\"Provides important service-wide, read-only information about a service\n\n    :type service_name: str\n    :param service_name: The name of the service\n\n    :type service_model: :py:class:`botocore.model.ServiceModel`\n    :param service_model: The model of the service.\n\n    :type service_waiter_model: :py:class:`botocore.waiter.WaiterModel` or\n        a waiter model-like object such as\n        :py:class:`boto3.utils.LazyLoadedWaiterModel`\n    :param service_waiter_model: The waiter model of the service.\n\n    :type resource_json_definitions: dict\n    :param resource_json_definitions: The loaded json models of all resource\n        shapes for a service. It is equivalient of loading a\n        ``resource-1.json`` and retrieving the value at the key \"resources\".\n    \"\"\"\n\n    pass\n\n\ndef import_module(name):\n    \"\"\"Import module given a name.\n\n    Does not support relative imports.\n\n    \"\"\"\n    __import__(name)\n    return sys.modules[name]\n\n\ndef lazy_call(full_name, **kwargs):\n    parent_kwargs = kwargs\n\n    def _handler(**kwargs):\n        module, function_name = full_name.rsplit('.', 1)\n        module = import_module(module)\n        kwargs.update(parent_kwargs)\n        return getattr(module, function_name)(**kwargs)\n\n    return _handler\n\n\ndef inject_attribute(class_attributes, name, value):\n    if name in class_attributes:\n        raise RuntimeError(\n            f'Cannot inject class attribute \"{name}\", attribute '\n            f'already exists in class dict.'\n        )\n    else:\n        class_attributes[name] = value\n\n\nclass LazyLoadedWaiterModel:\n    \"\"\"A lazily loaded waiter model\n\n    This does not load the service waiter model until an attempt is made\n    to retrieve the waiter model for a specific waiter. This is helpful\n    in docstring generation where we do not need to actually need to grab\n    the waiter-2.json until it is accessed through a ``get_waiter`` call\n    when the docstring is generated/accessed.\n    \"\"\"\n\n    def __init__(self, bc_session, service_name, api_version):\n        self._session = bc_session\n        self._service_name = service_name\n        self._api_version = api_version\n\n    def get_waiter(self, waiter_name):\n        return self._session.get_waiter_model(\n            self._service_name, self._api_version\n        ).get_waiter(waiter_name)\n", "boto3/__init__.py": "# Copyright 2014 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n\nimport logging\n\nfrom boto3.compat import _warn_deprecated_python\nfrom boto3.session import Session\n\n__author__ = 'Amazon Web Services'\n__version__ = '1.34.132'\n\n\n# The default Boto3 session; autoloaded when needed.\nDEFAULT_SESSION = None\n\n\ndef setup_default_session(**kwargs):\n    \"\"\"\n    Set up a default session, passing through any parameters to the session\n    constructor. There is no need to call this unless you wish to pass custom\n    parameters, because a default session will be created for you.\n    \"\"\"\n    global DEFAULT_SESSION\n    DEFAULT_SESSION = Session(**kwargs)\n\n\ndef set_stream_logger(name='boto3', level=logging.DEBUG, format_string=None):\n    \"\"\"\n    Add a stream handler for the given name and level to the logging module.\n    By default, this logs all boto3 messages to ``stdout``.\n\n        >>> import boto3\n        >>> boto3.set_stream_logger('boto3.resources', logging.INFO)\n\n    For debugging purposes a good choice is to set the stream logger to ``''``\n    which is equivalent to saying \"log everything\".\n\n    .. WARNING::\n       Be aware that when logging anything from ``'botocore'`` the full wire\n       trace will appear in your logs. If your payloads contain sensitive data\n       this should not be used in production.\n\n    :type name: string\n    :param name: Log name\n    :type level: int\n    :param level: Logging level, e.g. ``logging.INFO``\n    :type format_string: str\n    :param format_string: Log message format\n    \"\"\"\n    if format_string is None:\n        format_string = \"%(asctime)s %(name)s [%(levelname)s] %(message)s\"\n\n    logger = logging.getLogger(name)\n    logger.setLevel(level)\n    handler = logging.StreamHandler()\n    handler.setLevel(level)\n    formatter = logging.Formatter(format_string)\n    handler.setFormatter(formatter)\n    logger.addHandler(handler)\n\n\ndef _get_default_session():\n    \"\"\"\n    Get the default session, creating one if needed.\n\n    :rtype: :py:class:`~boto3.session.Session`\n    :return: The default session\n    \"\"\"\n    if DEFAULT_SESSION is None:\n        setup_default_session()\n    _warn_deprecated_python()\n\n    return DEFAULT_SESSION\n\n\ndef client(*args, **kwargs):\n    \"\"\"\n    Create a low-level service client by name using the default session.\n\n    See :py:meth:`boto3.session.Session.client`.\n    \"\"\"\n    return _get_default_session().client(*args, **kwargs)\n\n\ndef resource(*args, **kwargs):\n    \"\"\"\n    Create a resource service client by name using the default session.\n\n    See :py:meth:`boto3.session.Session.resource`.\n    \"\"\"\n    return _get_default_session().resource(*args, **kwargs)\n\n\n# Set up logging to ``/dev/null`` like a library is supposed to.\n# https://docs.python.org/3.3/howto/logging.html#configuring-logging-for-a-library\nclass NullHandler(logging.Handler):\n    def emit(self, record):\n        pass\n\n\nlogging.getLogger('boto3').addHandler(NullHandler())\n", "boto3/compat.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport sys\nimport os\nimport errno\nimport socket\nimport warnings\n\nfrom boto3.exceptions import PythonDeprecationWarning\n\n# In python3, socket.error is OSError, which is too general\n# for what we want (i.e FileNotFoundError is a subclass of OSError).\n# In py3 all the socket related errors are in a newly created\n# ConnectionError\nSOCKET_ERROR = ConnectionError\n\nimport collections.abc as collections_abc\n\n\nif sys.platform.startswith('win'):\n    def rename_file(current_filename, new_filename):\n        try:\n            os.remove(new_filename)\n        except OSError as e:\n            if not e.errno == errno.ENOENT:\n                # We only want to a ignore trying to remove\n                # a file that does not exist.  If it fails\n                # for any other reason we should be propagating\n                # that exception.\n                raise\n        os.rename(current_filename, new_filename)\nelse:\n    rename_file = os.rename\n\n\ndef filter_python_deprecation_warnings():\n    \"\"\"\n    Invoking this filter acknowledges your runtime will soon be deprecated\n    at which time you will stop receiving all updates to your client.\n    \"\"\"\n    warnings.filterwarnings(\n        'ignore',\n        message=\".*Boto3 will no longer support Python.*\",\n        category=PythonDeprecationWarning,\n        module=r\".*boto3\\.compat\"\n    )\n\n\ndef _warn_deprecated_python():\n    \"\"\"Use this template for future deprecation campaigns as needed.\"\"\"\n    py_37_params = {\n        'date': 'December 13, 2023',\n        'blog_link': (\n            'https://aws.amazon.com/blogs/developer/'\n            'python-support-policy-updates-for-aws-sdks-and-tools/'\n        )\n    }\n    deprecated_versions = {\n        # Example template for future deprecations\n        (3, 7): py_37_params,\n    }\n    py_version = sys.version_info[:2]\n\n    if py_version in deprecated_versions:\n        params = deprecated_versions[py_version]\n        warning = (\n            \"Boto3 will no longer support Python {}.{} \"\n            \"starting {}. To continue receiving service updates, \"\n            \"bug fixes, and security updates please upgrade to Python 3.8 or \"\n            \"later. More information can be found here: {}\"\n        ).format(py_version[0], py_version[1], params['date'], params['blog_link'])\n        warnings.warn(warning, PythonDeprecationWarning)\n", "boto3/crt.py": "# Copyright 2023 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n\"\"\"\nThis file contains private functionality for interacting with the AWS\nCommon Runtime library (awscrt) in boto3.\n\nAll code contained within this file is for internal usage within this\nproject and is not intended for external consumption. All interfaces\ncontained within are subject to abrupt breaking changes.\n\"\"\"\n\nimport threading\n\nimport botocore.exceptions\nfrom botocore.session import Session\nfrom s3transfer.crt import (\n    BotocoreCRTCredentialsWrapper,\n    BotocoreCRTRequestSerializer,\n    CRTTransferManager,\n    acquire_crt_s3_process_lock,\n    create_s3_crt_client,\n)\n\n# Singletons for CRT-backed transfers\nCRT_S3_CLIENT = None\nBOTOCORE_CRT_SERIALIZER = None\n\nCLIENT_CREATION_LOCK = threading.Lock()\nPROCESS_LOCK_NAME = 'boto3'\n\n\ndef _create_crt_client(session, config, region_name, cred_provider):\n    \"\"\"Create a CRT S3 Client for file transfer.\n\n    Instantiating many of these may lead to degraded performance or\n    system resource exhaustion.\n    \"\"\"\n    create_crt_client_kwargs = {\n        'region': region_name,\n        'use_ssl': True,\n        'crt_credentials_provider': cred_provider,\n    }\n    return create_s3_crt_client(**create_crt_client_kwargs)\n\n\ndef _create_crt_request_serializer(session, region_name):\n    return BotocoreCRTRequestSerializer(\n        session, {'region_name': region_name, 'endpoint_url': None}\n    )\n\n\ndef _create_crt_s3_client(\n    session, config, region_name, credentials, lock, **kwargs\n):\n    \"\"\"Create boto3 wrapper class to manage crt lock reference and S3 client.\"\"\"\n    cred_wrapper = BotocoreCRTCredentialsWrapper(credentials)\n    cred_provider = cred_wrapper.to_crt_credentials_provider()\n    return CRTS3Client(\n        _create_crt_client(session, config, region_name, cred_provider),\n        lock,\n        region_name,\n        cred_wrapper,\n    )\n\n\ndef _initialize_crt_transfer_primatives(client, config):\n    lock = acquire_crt_s3_process_lock(PROCESS_LOCK_NAME)\n    if lock is None:\n        # If we're unable to acquire the lock, we cannot\n        # use the CRT in this process and should default to\n        # the classic s3transfer manager.\n        return None, None\n\n    session = Session()\n    region_name = client.meta.region_name\n    credentials = client._get_credentials()\n\n    serializer = _create_crt_request_serializer(session, region_name)\n    s3_client = _create_crt_s3_client(\n        session, config, region_name, credentials, lock\n    )\n    return serializer, s3_client\n\n\ndef get_crt_s3_client(client, config):\n    global CRT_S3_CLIENT\n    global BOTOCORE_CRT_SERIALIZER\n\n    with CLIENT_CREATION_LOCK:\n        if CRT_S3_CLIENT is None:\n            serializer, s3_client = _initialize_crt_transfer_primatives(\n                client, config\n            )\n            BOTOCORE_CRT_SERIALIZER = serializer\n            CRT_S3_CLIENT = s3_client\n\n    return CRT_S3_CLIENT\n\n\nclass CRTS3Client:\n    \"\"\"\n    This wrapper keeps track of our underlying CRT client, the lock used to\n    acquire it and the region we've used to instantiate the client.\n\n    Due to limitations in the existing CRT interfaces, we can only make calls\n    in a single region and does not support redirects. We track the region to\n    ensure we don't use the CRT client when a successful request cannot be made.\n    \"\"\"\n\n    def __init__(self, crt_client, process_lock, region, cred_provider):\n        self.crt_client = crt_client\n        self.process_lock = process_lock\n        self.region = region\n        self.cred_provider = cred_provider\n\n\ndef is_crt_compatible_request(client, crt_s3_client):\n    \"\"\"\n    Boto3 client must use same signing region and credentials\n    as the CRT_S3_CLIENT singleton. Otherwise fallback to classic.\n    \"\"\"\n    if crt_s3_client is None:\n        return False\n\n    boto3_creds = client._get_credentials()\n    if boto3_creds is None:\n        return False\n\n    is_same_identity = compare_identity(\n        boto3_creds.get_frozen_credentials(), crt_s3_client.cred_provider\n    )\n    is_same_region = client.meta.region_name == crt_s3_client.region\n    return is_same_region and is_same_identity\n\n\ndef compare_identity(boto3_creds, crt_s3_creds):\n    try:\n        crt_creds = crt_s3_creds()\n    except botocore.exceptions.NoCredentialsError:\n        return False\n\n    is_matching_identity = (\n        boto3_creds.access_key == crt_creds.access_key_id\n        and boto3_creds.secret_key == crt_creds.secret_access_key\n        and boto3_creds.token == crt_creds.session_token\n    )\n    return is_matching_identity\n\n\ndef create_crt_transfer_manager(client, config):\n    \"\"\"Create a CRTTransferManager for optimized data transfer.\"\"\"\n    crt_s3_client = get_crt_s3_client(client, config)\n    if is_crt_compatible_request(client, crt_s3_client):\n        return CRTTransferManager(\n            crt_s3_client.crt_client, BOTOCORE_CRT_SERIALIZER\n        )\n    return None\n", "boto3/session.py": "# Copyright 2014 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n\nimport copy\nimport os\n\nimport botocore.session\nfrom botocore.client import Config\nfrom botocore.exceptions import DataNotFoundError, UnknownServiceError\n\nimport boto3\nimport boto3.utils\nfrom boto3.exceptions import ResourceNotExistsError, UnknownAPIVersionError\n\nfrom .resources.factory import ResourceFactory\n\n\nclass Session:\n    \"\"\"\n    A session stores configuration state and allows you to create service\n    clients and resources.\n\n    :type aws_access_key_id: string\n    :param aws_access_key_id: AWS access key ID\n    :type aws_secret_access_key: string\n    :param aws_secret_access_key: AWS secret access key\n    :type aws_session_token: string\n    :param aws_session_token: AWS temporary session token\n    :type region_name: string\n    :param region_name: Default region when creating new connections\n    :type botocore_session: botocore.session.Session\n    :param botocore_session: Use this Botocore session instead of creating\n                             a new default one.\n    :type profile_name: string\n    :param profile_name: The name of a profile to use. If not given, then\n                         the default profile is used.\n    \"\"\"\n\n    def __init__(\n        self,\n        aws_access_key_id=None,\n        aws_secret_access_key=None,\n        aws_session_token=None,\n        region_name=None,\n        botocore_session=None,\n        profile_name=None,\n    ):\n        if botocore_session is not None:\n            self._session = botocore_session\n        else:\n            # Create a new default session\n            self._session = botocore.session.get_session()\n\n        # Setup custom user-agent string if it isn't already customized\n        if self._session.user_agent_name == 'Botocore':\n            botocore_info = f'Botocore/{self._session.user_agent_version}'\n            if self._session.user_agent_extra:\n                self._session.user_agent_extra += ' ' + botocore_info\n            else:\n                self._session.user_agent_extra = botocore_info\n            self._session.user_agent_name = 'Boto3'\n            self._session.user_agent_version = boto3.__version__\n\n        if profile_name is not None:\n            self._session.set_config_variable('profile', profile_name)\n\n        if aws_access_key_id or aws_secret_access_key or aws_session_token:\n            self._session.set_credentials(\n                aws_access_key_id, aws_secret_access_key, aws_session_token\n            )\n\n        if region_name is not None:\n            self._session.set_config_variable('region', region_name)\n\n        self.resource_factory = ResourceFactory(\n            self._session.get_component('event_emitter')\n        )\n        self._setup_loader()\n        self._register_default_handlers()\n\n    def __repr__(self):\n        return '{}(region_name={})'.format(\n            self.__class__.__name__,\n            repr(self._session.get_config_variable('region')),\n        )\n\n    @property\n    def profile_name(self):\n        \"\"\"\n        The **read-only** profile name.\n        \"\"\"\n        return self._session.profile or 'default'\n\n    @property\n    def region_name(self):\n        \"\"\"\n        The **read-only** region name.\n        \"\"\"\n        return self._session.get_config_variable('region')\n\n    @property\n    def events(self):\n        \"\"\"\n        The event emitter for a session\n        \"\"\"\n        return self._session.get_component('event_emitter')\n\n    @property\n    def available_profiles(self):\n        \"\"\"\n        The profiles available to the session credentials\n        \"\"\"\n        return self._session.available_profiles\n\n    def _setup_loader(self):\n        \"\"\"\n        Setup loader paths so that we can load resources.\n        \"\"\"\n        self._loader = self._session.get_component('data_loader')\n        self._loader.search_paths.append(\n            os.path.join(os.path.dirname(__file__), 'data')\n        )\n\n    def get_available_services(self):\n        \"\"\"\n        Get a list of available services that can be loaded as low-level\n        clients via :py:meth:`Session.client`.\n\n        :rtype: list\n        :return: List of service names\n        \"\"\"\n        return self._session.get_available_services()\n\n    def get_available_resources(self):\n        \"\"\"\n        Get a list of available services that can be loaded as resource\n        clients via :py:meth:`Session.resource`.\n\n        :rtype: list\n        :return: List of service names\n        \"\"\"\n        return self._loader.list_available_services(type_name='resources-1')\n\n    def get_available_partitions(self):\n        \"\"\"Lists the available partitions\n\n        :rtype: list\n        :return: Returns a list of partition names (e.g., [\"aws\", \"aws-cn\"])\n        \"\"\"\n        return self._session.get_available_partitions()\n\n    def get_available_regions(\n        self, service_name, partition_name='aws', allow_non_regional=False\n    ):\n        \"\"\"Lists the region and endpoint names of a particular partition.\n\n        The list of regions returned by this method are regions that are\n        explicitly known by the client to exist and is not comprehensive. A\n        region not returned in this list may still be available for the\n        provided service.\n\n        :type service_name: string\n        :param service_name: Name of a service to list endpoint for (e.g., s3).\n\n        :type partition_name: string\n        :param partition_name: Name of the partition to limit endpoints to.\n            (e.g., aws for the public AWS endpoints, aws-cn for AWS China\n            endpoints, aws-us-gov for AWS GovCloud (US) Endpoints, etc.)\n\n        :type allow_non_regional: bool\n        :param allow_non_regional: Set to True to include endpoints that are\n             not regional endpoints (e.g., s3-external-1,\n             fips-us-gov-west-1, etc).\n\n        :return: Returns a list of endpoint names (e.g., [\"us-east-1\"]).\n        \"\"\"\n        return self._session.get_available_regions(\n            service_name=service_name,\n            partition_name=partition_name,\n            allow_non_regional=allow_non_regional,\n        )\n\n    def get_credentials(self):\n        \"\"\"\n        Return the :class:`botocore.credentials.Credentials` object\n        associated with this session.  If the credentials have not\n        yet been loaded, this will attempt to load them.  If they\n        have already been loaded, this will return the cached\n        credentials.\n        \"\"\"\n        return self._session.get_credentials()\n\n    def get_partition_for_region(self, region_name):\n        \"\"\"Lists the partition name of a particular region.\n\n        :type region_name: string\n        :param region_name: Name of the region to list partition for (e.g.,\n             us-east-1).\n\n        :rtype: string\n        :return: Returns the respective partition name (e.g., aws).\n        \"\"\"\n        return self._session.get_partition_for_region(region_name)\n\n    def client(\n        self,\n        service_name,\n        region_name=None,\n        api_version=None,\n        use_ssl=True,\n        verify=None,\n        endpoint_url=None,\n        aws_access_key_id=None,\n        aws_secret_access_key=None,\n        aws_session_token=None,\n        config=None,\n    ):\n        \"\"\"\n        Create a low-level service client by name.\n\n        :type service_name: string\n        :param service_name: The name of a service, e.g. 's3' or 'ec2'. You\n            can get a list of available services via\n            :py:meth:`get_available_services`.\n\n        :type region_name: string\n        :param region_name: The name of the region associated with the client.\n            A client is associated with a single region.\n\n        :type api_version: string\n        :param api_version: The API version to use.  By default, botocore will\n            use the latest API version when creating a client.  You only need\n            to specify this parameter if you want to use a previous API version\n            of the client.\n\n        :type use_ssl: boolean\n        :param use_ssl: Whether or not to use SSL.  By default, SSL is used.\n            Note that not all services support non-ssl connections.\n\n        :type verify: boolean/string\n        :param verify: Whether or not to verify SSL certificates.  By default\n            SSL certificates are verified.  You can provide the following\n            values:\n\n            * False - do not validate SSL certificates.  SSL will still be\n              used (unless use_ssl is False), but SSL certificates\n              will not be verified.\n            * path/to/cert/bundle.pem - A filename of the CA cert bundle to\n              uses.  You can specify this argument if you want to use a\n              different CA cert bundle than the one used by botocore.\n\n        :type endpoint_url: string\n        :param endpoint_url: The complete URL to use for the constructed\n            client. Normally, botocore will automatically construct the\n            appropriate URL to use when communicating with a service.  You\n            can specify a complete URL (including the \"http/https\" scheme)\n            to override this behavior.  If this value is provided,\n            then ``use_ssl`` is ignored.\n\n        :type aws_access_key_id: string\n        :param aws_access_key_id: The access key to use when creating\n            the client.  This is entirely optional, and if not provided,\n            the credentials configured for the session will automatically\n            be used.  You only need to provide this argument if you want\n            to override the credentials used for this specific client.\n\n        :type aws_secret_access_key: string\n        :param aws_secret_access_key: The secret key to use when creating\n            the client.  Same semantics as aws_access_key_id above.\n\n        :type aws_session_token: string\n        :param aws_session_token: The session token to use when creating\n            the client.  Same semantics as aws_access_key_id above.\n\n        :type config: botocore.client.Config\n        :param config: Advanced client configuration options. If region_name\n            is specified in the client config, its value will take precedence\n            over environment variables and configuration values, but not over\n            a region_name value passed explicitly to the method. See\n            `botocore config documentation\n            <https://botocore.amazonaws.com/v1/documentation/api/latest/reference/config.html>`_\n            for more details.\n\n        :return: Service client instance\n\n        \"\"\"\n        return self._session.create_client(\n            service_name,\n            region_name=region_name,\n            api_version=api_version,\n            use_ssl=use_ssl,\n            verify=verify,\n            endpoint_url=endpoint_url,\n            aws_access_key_id=aws_access_key_id,\n            aws_secret_access_key=aws_secret_access_key,\n            aws_session_token=aws_session_token,\n            config=config,\n        )\n\n    def resource(\n        self,\n        service_name,\n        region_name=None,\n        api_version=None,\n        use_ssl=True,\n        verify=None,\n        endpoint_url=None,\n        aws_access_key_id=None,\n        aws_secret_access_key=None,\n        aws_session_token=None,\n        config=None,\n    ):\n        \"\"\"\n        Create a resource service client by name.\n\n        :type service_name: string\n        :param service_name: The name of a service, e.g. 's3' or 'ec2'. You\n            can get a list of available services via\n            :py:meth:`get_available_resources`.\n\n        :type region_name: string\n        :param region_name: The name of the region associated with the client.\n            A client is associated with a single region.\n\n        :type api_version: string\n        :param api_version: The API version to use.  By default, botocore will\n            use the latest API version when creating a client.  You only need\n            to specify this parameter if you want to use a previous API version\n            of the client.\n\n        :type use_ssl: boolean\n        :param use_ssl: Whether or not to use SSL.  By default, SSL is used.\n            Note that not all services support non-ssl connections.\n\n        :type verify: boolean/string\n        :param verify: Whether or not to verify SSL certificates.  By default\n            SSL certificates are verified.  You can provide the following\n            values:\n\n            * False - do not validate SSL certificates.  SSL will still be\n              used (unless use_ssl is False), but SSL certificates\n              will not be verified.\n            * path/to/cert/bundle.pem - A filename of the CA cert bundle to\n              uses.  You can specify this argument if you want to use a\n              different CA cert bundle than the one used by botocore.\n\n        :type endpoint_url: string\n        :param endpoint_url: The complete URL to use for the constructed\n            client. Normally, botocore will automatically construct the\n            appropriate URL to use when communicating with a service.  You\n            can specify a complete URL (including the \"http/https\" scheme)\n            to override this behavior.  If this value is provided,\n            then ``use_ssl`` is ignored.\n\n        :type aws_access_key_id: string\n        :param aws_access_key_id: The access key to use when creating\n            the client.  This is entirely optional, and if not provided,\n            the credentials configured for the session will automatically\n            be used.  You only need to provide this argument if you want\n            to override the credentials used for this specific client.\n\n        :type aws_secret_access_key: string\n        :param aws_secret_access_key: The secret key to use when creating\n            the client.  Same semantics as aws_access_key_id above.\n\n        :type aws_session_token: string\n        :param aws_session_token: The session token to use when creating\n            the client.  Same semantics as aws_access_key_id above.\n\n        :type config: botocore.client.Config\n        :param config: Advanced client configuration options. If region_name\n            is specified in the client config, its value will take precedence\n            over environment variables and configuration values, but not over\n            a region_name value passed explicitly to the method.  If\n            user_agent_extra is specified in the client config, it overrides\n            the default user_agent_extra provided by the resource API. See\n            `botocore config documentation\n            <https://botocore.amazonaws.com/v1/documentation/api/latest/reference/config.html>`_\n            for more details.\n\n        :return: Subclass of :py:class:`~boto3.resources.base.ServiceResource`\n        \"\"\"\n        try:\n            resource_model = self._loader.load_service_model(\n                service_name, 'resources-1', api_version\n            )\n        except UnknownServiceError:\n            available = self.get_available_resources()\n            has_low_level_client = (\n                service_name in self.get_available_services()\n            )\n            raise ResourceNotExistsError(\n                service_name, available, has_low_level_client\n            )\n        except DataNotFoundError:\n            # This is because we've provided an invalid API version.\n            available_api_versions = self._loader.list_api_versions(\n                service_name, 'resources-1'\n            )\n            raise UnknownAPIVersionError(\n                service_name, api_version, ', '.join(available_api_versions)\n            )\n\n        if api_version is None:\n            # Even though botocore's load_service_model() can handle\n            # using the latest api_version if not provided, we need\n            # to track this api_version in boto3 in order to ensure\n            # we're pairing a resource model with a client model\n            # of the same API version.  It's possible for the latest\n            # API version of a resource model in boto3 to not be\n            # the same API version as a service model in botocore.\n            # So we need to look up the api_version if one is not\n            # provided to ensure we load the same API version of the\n            # client.\n            #\n            # Note: This is relying on the fact that\n            #   loader.load_service_model(..., api_version=None)\n            # and loader.determine_latest_version(..., 'resources-1')\n            # both load the same api version of the file.\n            api_version = self._loader.determine_latest_version(\n                service_name, 'resources-1'\n            )\n\n        # Creating a new resource instance requires the low-level client\n        # and service model, the resource version and resource JSON data.\n        # We pass these to the factory and get back a class, which is\n        # instantiated on top of the low-level client.\n        if config is not None:\n            if config.user_agent_extra is None:\n                config = copy.deepcopy(config)\n                config.user_agent_extra = 'Resource'\n        else:\n            config = Config(user_agent_extra='Resource')\n        client = self.client(\n            service_name,\n            region_name=region_name,\n            api_version=api_version,\n            use_ssl=use_ssl,\n            verify=verify,\n            endpoint_url=endpoint_url,\n            aws_access_key_id=aws_access_key_id,\n            aws_secret_access_key=aws_secret_access_key,\n            aws_session_token=aws_session_token,\n            config=config,\n        )\n        service_model = client.meta.service_model\n\n        # Create a ServiceContext object to serve as a reference to\n        # important read-only information about the general service.\n        service_context = boto3.utils.ServiceContext(\n            service_name=service_name,\n            service_model=service_model,\n            resource_json_definitions=resource_model['resources'],\n            service_waiter_model=boto3.utils.LazyLoadedWaiterModel(\n                self._session, service_name, api_version\n            ),\n        )\n\n        # Create the service resource class.\n        cls = self.resource_factory.load_from_definition(\n            resource_name=service_name,\n            single_resource_json_definition=resource_model['service'],\n            service_context=service_context,\n        )\n\n        return cls(client=client)\n\n    def _register_default_handlers(self):\n        # S3 customizations\n        self._session.register(\n            'creating-client-class.s3',\n            boto3.utils.lazy_call(\n                'boto3.s3.inject.inject_s3_transfer_methods'\n            ),\n        )\n        self._session.register(\n            'creating-resource-class.s3.Bucket',\n            boto3.utils.lazy_call('boto3.s3.inject.inject_bucket_methods'),\n        )\n        self._session.register(\n            'creating-resource-class.s3.Object',\n            boto3.utils.lazy_call('boto3.s3.inject.inject_object_methods'),\n        )\n        self._session.register(\n            'creating-resource-class.s3.ObjectSummary',\n            boto3.utils.lazy_call(\n                'boto3.s3.inject.inject_object_summary_methods'\n            ),\n        )\n\n        # DynamoDb customizations\n        self._session.register(\n            'creating-resource-class.dynamodb',\n            boto3.utils.lazy_call(\n                'boto3.dynamodb.transform.register_high_level_interface'\n            ),\n            unique_id='high-level-dynamodb',\n        )\n        self._session.register(\n            'creating-resource-class.dynamodb.Table',\n            boto3.utils.lazy_call(\n                'boto3.dynamodb.table.register_table_methods'\n            ),\n            unique_id='high-level-dynamodb-table',\n        )\n\n        # EC2 Customizations\n        self._session.register(\n            'creating-resource-class.ec2.ServiceResource',\n            boto3.utils.lazy_call('boto3.ec2.createtags.inject_create_tags'),\n        )\n\n        self._session.register(\n            'creating-resource-class.ec2.Instance',\n            boto3.utils.lazy_call(\n                'boto3.ec2.deletetags.inject_delete_tags',\n                event_emitter=self.events,\n            ),\n        )\n", "boto3/resources/response.py": "# Copyright 2014 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n\nimport jmespath\nfrom botocore import xform_name\n\nfrom .params import get_data_member\n\n\ndef all_not_none(iterable):\n    \"\"\"\n    Return True if all elements of the iterable are not None (or if the\n    iterable is empty). This is like the built-in ``all``, except checks\n    against None, so 0 and False are allowable values.\n    \"\"\"\n    for element in iterable:\n        if element is None:\n            return False\n    return True\n\n\ndef build_identifiers(identifiers, parent, params=None, raw_response=None):\n    \"\"\"\n    Builds a mapping of identifier names to values based on the\n    identifier source location, type, and target. Identifier\n    values may be scalars or lists depending on the source type\n    and location.\n\n    :type identifiers: list\n    :param identifiers: List of :py:class:`~boto3.resources.model.Parameter`\n                        definitions\n    :type parent: ServiceResource\n    :param parent: The resource instance to which this action is attached.\n    :type params: dict\n    :param params: Request parameters sent to the service.\n    :type raw_response: dict\n    :param raw_response: Low-level operation response.\n    :rtype: list\n    :return: An ordered list of ``(name, value)`` identifier tuples.\n    \"\"\"\n    results = []\n\n    for identifier in identifiers:\n        source = identifier.source\n        target = identifier.target\n\n        if source == 'response':\n            value = jmespath.search(identifier.path, raw_response)\n        elif source == 'requestParameter':\n            value = jmespath.search(identifier.path, params)\n        elif source == 'identifier':\n            value = getattr(parent, xform_name(identifier.name))\n        elif source == 'data':\n            # If this is a data member then it may incur a load\n            # action before returning the value.\n            value = get_data_member(parent, identifier.path)\n        elif source == 'input':\n            # This value is set by the user, so ignore it here\n            continue\n        else:\n            raise NotImplementedError(f'Unsupported source type: {source}')\n\n        results.append((xform_name(target), value))\n\n    return results\n\n\ndef build_empty_response(search_path, operation_name, service_model):\n    \"\"\"\n    Creates an appropriate empty response for the type that is expected,\n    based on the service model's shape type. For example, a value that\n    is normally a list would then return an empty list. A structure would\n    return an empty dict, and a number would return None.\n\n    :type search_path: string\n    :param search_path: JMESPath expression to search in the response\n    :type operation_name: string\n    :param operation_name: Name of the underlying service operation.\n    :type service_model: :ref:`botocore.model.ServiceModel`\n    :param service_model: The Botocore service model\n    :rtype: dict, list, or None\n    :return: An appropriate empty value\n    \"\"\"\n    response = None\n\n    operation_model = service_model.operation_model(operation_name)\n    shape = operation_model.output_shape\n\n    if search_path:\n        # Walk the search path and find the final shape. For example, given\n        # a path of ``foo.bar[0].baz``, we first find the shape for ``foo``,\n        # then the shape for ``bar`` (ignoring the indexing), and finally\n        # the shape for ``baz``.\n        for item in search_path.split('.'):\n            item = item.strip('[0123456789]$')\n\n            if shape.type_name == 'structure':\n                shape = shape.members[item]\n            elif shape.type_name == 'list':\n                shape = shape.member\n            else:\n                raise NotImplementedError(\n                    f'Search path hits shape type {shape.type_name} from {item}'\n                )\n\n    # Anything not handled here is set to None\n    if shape.type_name == 'structure':\n        response = {}\n    elif shape.type_name == 'list':\n        response = []\n    elif shape.type_name == 'map':\n        response = {}\n\n    return response\n\n\nclass RawHandler:\n    \"\"\"\n    A raw action response handler. This passed through the response\n    dictionary, optionally after performing a JMESPath search if one\n    has been defined for the action.\n\n    :type search_path: string\n    :param search_path: JMESPath expression to search in the response\n    :rtype: dict\n    :return: Service response\n    \"\"\"\n\n    def __init__(self, search_path):\n        self.search_path = search_path\n\n    def __call__(self, parent, params, response):\n        \"\"\"\n        :type parent: ServiceResource\n        :param parent: The resource instance to which this action is attached.\n        :type params: dict\n        :param params: Request parameters sent to the service.\n        :type response: dict\n        :param response: Low-level operation response.\n        \"\"\"\n        # TODO: Remove the '$' check after JMESPath supports it\n        if self.search_path and self.search_path != '$':\n            response = jmespath.search(self.search_path, response)\n\n        return response\n\n\nclass ResourceHandler:\n    \"\"\"\n    Creates a new resource or list of new resources from the low-level\n    response based on the given response resource definition.\n\n    :type search_path: string\n    :param search_path: JMESPath expression to search in the response\n\n    :type factory: ResourceFactory\n    :param factory: The factory that created the resource class to which\n                    this action is attached.\n\n    :type resource_model: :py:class:`~boto3.resources.model.ResponseResource`\n    :param resource_model: Response resource model.\n\n    :type service_context: :py:class:`~boto3.utils.ServiceContext`\n    :param service_context: Context about the AWS service\n\n    :type operation_name: string\n    :param operation_name: Name of the underlying service operation, if it\n                           exists.\n\n    :rtype: ServiceResource or list\n    :return: New resource instance(s).\n    \"\"\"\n\n    def __init__(\n        self,\n        search_path,\n        factory,\n        resource_model,\n        service_context,\n        operation_name=None,\n    ):\n        self.search_path = search_path\n        self.factory = factory\n        self.resource_model = resource_model\n        self.operation_name = operation_name\n        self.service_context = service_context\n\n    def __call__(self, parent, params, response):\n        \"\"\"\n        :type parent: ServiceResource\n        :param parent: The resource instance to which this action is attached.\n        :type params: dict\n        :param params: Request parameters sent to the service.\n        :type response: dict\n        :param response: Low-level operation response.\n        \"\"\"\n        resource_name = self.resource_model.type\n        json_definition = self.service_context.resource_json_definitions.get(\n            resource_name\n        )\n\n        # Load the new resource class that will result from this action.\n        resource_cls = self.factory.load_from_definition(\n            resource_name=resource_name,\n            single_resource_json_definition=json_definition,\n            service_context=self.service_context,\n        )\n        raw_response = response\n        search_response = None\n\n        # Anytime a path is defined, it means the response contains the\n        # resource's attributes, so resource_data gets set here. It\n        # eventually ends up in resource.meta.data, which is where\n        # the attribute properties look for data.\n        if self.search_path:\n            search_response = jmespath.search(self.search_path, raw_response)\n\n        # First, we parse all the identifiers, then create the individual\n        # response resources using them. Any identifiers that are lists\n        # will have one item consumed from the front of the list for each\n        # resource that is instantiated. Items which are not a list will\n        # be set as the same value on each new resource instance.\n        identifiers = dict(\n            build_identifiers(\n                self.resource_model.identifiers, parent, params, raw_response\n            )\n        )\n\n        # If any of the identifiers is a list, then the response is plural\n        plural = [v for v in identifiers.values() if isinstance(v, list)]\n\n        if plural:\n            response = []\n\n            # The number of items in an identifier that is a list will\n            # determine how many resource instances to create.\n            for i in range(len(plural[0])):\n                # Response item data is *only* available if a search path\n                # was given. This prevents accidentally loading unrelated\n                # data that may be in the response.\n                response_item = None\n                if search_response:\n                    response_item = search_response[i]\n                response.append(\n                    self.handle_response_item(\n                        resource_cls, parent, identifiers, response_item\n                    )\n                )\n        elif all_not_none(identifiers.values()):\n            # All identifiers must always exist, otherwise the resource\n            # cannot be instantiated.\n            response = self.handle_response_item(\n                resource_cls, parent, identifiers, search_response\n            )\n        else:\n            # The response should be empty, but that may mean an\n            # empty dict, list, or None based on whether we make\n            # a remote service call and what shape it is expected\n            # to return.\n            response = None\n            if self.operation_name is not None:\n                # A remote service call was made, so try and determine\n                # its shape.\n                response = build_empty_response(\n                    self.search_path,\n                    self.operation_name,\n                    self.service_context.service_model,\n                )\n\n        return response\n\n    def handle_response_item(\n        self, resource_cls, parent, identifiers, resource_data\n    ):\n        \"\"\"\n        Handles the creation of a single response item by setting\n        parameters and creating the appropriate resource instance.\n\n        :type resource_cls: ServiceResource subclass\n        :param resource_cls: The resource class to instantiate.\n        :type parent: ServiceResource\n        :param parent: The resource instance to which this action is attached.\n        :type identifiers: dict\n        :param identifiers: Map of identifier names to value or values.\n        :type resource_data: dict or None\n        :param resource_data: Data for resource attributes.\n        :rtype: ServiceResource\n        :return: New resource instance.\n        \"\"\"\n        kwargs = {\n            'client': parent.meta.client,\n        }\n\n        for name, value in identifiers.items():\n            # If value is a list, then consume the next item\n            if isinstance(value, list):\n                value = value.pop(0)\n\n            kwargs[name] = value\n\n        resource = resource_cls(**kwargs)\n\n        if resource_data is not None:\n            resource.meta.data = resource_data\n\n        return resource\n", "boto3/resources/model.py": "# Copyright 2014 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n\n\"\"\"\nThe models defined in this file represent the resource JSON description\nformat and provide a layer of abstraction from the raw JSON. The advantages\nof this are:\n\n* Pythonic interface (e.g. ``action.request.operation``)\n* Consumers need not change for minor JSON changes (e.g. renamed field)\n\nThese models are used both by the resource factory to generate resource\nclasses as well as by the documentation generator.\n\"\"\"\n\nimport logging\n\nfrom botocore import xform_name\n\nlogger = logging.getLogger(__name__)\n\n\nclass Identifier:\n    \"\"\"\n    A resource identifier, given by its name.\n\n    :type name: string\n    :param name: The name of the identifier\n    \"\"\"\n\n    def __init__(self, name, member_name=None):\n        #: (``string``) The name of the identifier\n        self.name = name\n        self.member_name = member_name\n\n\nclass Action:\n    \"\"\"\n    A service operation action.\n\n    :type name: string\n    :param name: The name of the action\n    :type definition: dict\n    :param definition: The JSON definition\n    :type resource_defs: dict\n    :param resource_defs: All resources defined in the service\n    \"\"\"\n\n    def __init__(self, name, definition, resource_defs):\n        self._definition = definition\n\n        #: (``string``) The name of the action\n        self.name = name\n        #: (:py:class:`Request`) This action's request or ``None``\n        self.request = None\n        if 'request' in definition:\n            self.request = Request(definition.get('request', {}))\n        #: (:py:class:`ResponseResource`) This action's resource or ``None``\n        self.resource = None\n        if 'resource' in definition:\n            self.resource = ResponseResource(\n                definition.get('resource', {}), resource_defs\n            )\n        #: (``string``) The JMESPath search path or ``None``\n        self.path = definition.get('path')\n\n\nclass DefinitionWithParams:\n    \"\"\"\n    An item which has parameters exposed via the ``params`` property.\n    A request has an operation and parameters, while a waiter has\n    a name, a low-level waiter name and parameters.\n\n    :type definition: dict\n    :param definition: The JSON definition\n    \"\"\"\n\n    def __init__(self, definition):\n        self._definition = definition\n\n    @property\n    def params(self):\n        \"\"\"\n        Get a list of auto-filled parameters for this request.\n\n        :type: list(:py:class:`Parameter`)\n        \"\"\"\n        params = []\n\n        for item in self._definition.get('params', []):\n            params.append(Parameter(**item))\n\n        return params\n\n\nclass Parameter:\n    \"\"\"\n    An auto-filled parameter which has a source and target. For example,\n    the ``QueueUrl`` may be auto-filled from a resource's ``url`` identifier\n    when making calls to ``queue.receive_messages``.\n\n    :type target: string\n    :param target: The destination parameter name, e.g. ``QueueUrl``\n    :type source_type: string\n    :param source_type: Where the source is defined.\n    :type source: string\n    :param source: The source name, e.g. ``Url``\n    \"\"\"\n\n    def __init__(\n        self, target, source, name=None, path=None, value=None, **kwargs\n    ):\n        #: (``string``) The destination parameter name\n        self.target = target\n        #: (``string``) Where the source is defined\n        self.source = source\n        #: (``string``) The name of the source, if given\n        self.name = name\n        #: (``string``) The JMESPath query of the source\n        self.path = path\n        #: (``string|int|float|bool``) The source constant value\n        self.value = value\n\n        # Complain if we encounter any unknown values.\n        if kwargs:\n            logger.warning('Unknown parameter options found: %s', kwargs)\n\n\nclass Request(DefinitionWithParams):\n    \"\"\"\n    A service operation action request.\n\n    :type definition: dict\n    :param definition: The JSON definition\n    \"\"\"\n\n    def __init__(self, definition):\n        super().__init__(definition)\n\n        #: (``string``) The name of the low-level service operation\n        self.operation = definition.get('operation')\n\n\nclass Waiter(DefinitionWithParams):\n    \"\"\"\n    An event waiter specification.\n\n    :type name: string\n    :param name: Name of the waiter\n    :type definition: dict\n    :param definition: The JSON definition\n    \"\"\"\n\n    PREFIX = 'WaitUntil'\n\n    def __init__(self, name, definition):\n        super().__init__(definition)\n\n        #: (``string``) The name of this waiter\n        self.name = name\n\n        #: (``string``) The name of the underlying event waiter\n        self.waiter_name = definition.get('waiterName')\n\n\nclass ResponseResource:\n    \"\"\"\n    A resource response to create after performing an action.\n\n    :type definition: dict\n    :param definition: The JSON definition\n    :type resource_defs: dict\n    :param resource_defs: All resources defined in the service\n    \"\"\"\n\n    def __init__(self, definition, resource_defs):\n        self._definition = definition\n        self._resource_defs = resource_defs\n\n        #: (``string``) The name of the response resource type\n        self.type = definition.get('type')\n\n        #: (``string``) The JMESPath search query or ``None``\n        self.path = definition.get('path')\n\n    @property\n    def identifiers(self):\n        \"\"\"\n        A list of resource identifiers.\n\n        :type: list(:py:class:`Identifier`)\n        \"\"\"\n        identifiers = []\n\n        for item in self._definition.get('identifiers', []):\n            identifiers.append(Parameter(**item))\n\n        return identifiers\n\n    @property\n    def model(self):\n        \"\"\"\n        Get the resource model for the response resource.\n\n        :type: :py:class:`ResourceModel`\n        \"\"\"\n        return ResourceModel(\n            self.type, self._resource_defs[self.type], self._resource_defs\n        )\n\n\nclass Collection(Action):\n    \"\"\"\n    A group of resources. See :py:class:`Action`.\n\n    :type name: string\n    :param name: The name of the collection\n    :type definition: dict\n    :param definition: The JSON definition\n    :type resource_defs: dict\n    :param resource_defs: All resources defined in the service\n    \"\"\"\n\n    @property\n    def batch_actions(self):\n        \"\"\"\n        Get a list of batch actions supported by the resource type\n        contained in this action. This is a shortcut for accessing\n        the same information through the resource model.\n\n        :rtype: list(:py:class:`Action`)\n        \"\"\"\n        return self.resource.model.batch_actions\n\n\nclass ResourceModel:\n    \"\"\"\n    A model representing a resource, defined via a JSON description\n    format. A resource has identifiers, attributes, actions,\n    sub-resources, references and collections. For more information\n    on resources, see :ref:`guide_resources`.\n\n    :type name: string\n    :param name: The name of this resource, e.g. ``sqs`` or ``Queue``\n    :type definition: dict\n    :param definition: The JSON definition\n    :type resource_defs: dict\n    :param resource_defs: All resources defined in the service\n    \"\"\"\n\n    def __init__(self, name, definition, resource_defs):\n        self._definition = definition\n        self._resource_defs = resource_defs\n        self._renamed = {}\n\n        #: (``string``) The name of this resource\n        self.name = name\n        #: (``string``) The service shape name for this resource or ``None``\n        self.shape = definition.get('shape')\n\n    def load_rename_map(self, shape=None):\n        \"\"\"\n        Load a name translation map given a shape. This will set\n        up renamed values for any collisions, e.g. if the shape,\n        an action, and a subresource all are all named ``foo``\n        then the resource will have an action ``foo``, a subresource\n        named ``Foo`` and a property named ``foo_attribute``.\n        This is the order of precedence, from most important to\n        least important:\n\n        * Load action (resource.load)\n        * Identifiers\n        * Actions\n        * Subresources\n        * References\n        * Collections\n        * Waiters\n        * Attributes (shape members)\n\n        Batch actions are only exposed on collections, so do not\n        get modified here. Subresources use upper camel casing, so\n        are unlikely to collide with anything but other subresources.\n\n        Creates a structure like this::\n\n            renames = {\n                ('action', 'id'): 'id_action',\n                ('collection', 'id'): 'id_collection',\n                ('attribute', 'id'): 'id_attribute'\n            }\n\n            # Get the final name for an action named 'id'\n            name = renames.get(('action', 'id'), 'id')\n\n        :type shape: botocore.model.Shape\n        :param shape: The underlying shape for this resource.\n        \"\"\"\n        # Meta is a reserved name for resources\n        names = {'meta'}\n        self._renamed = {}\n\n        if self._definition.get('load'):\n            names.add('load')\n\n        for item in self._definition.get('identifiers', []):\n            self._load_name_with_category(names, item['name'], 'identifier')\n\n        for name in self._definition.get('actions', {}):\n            self._load_name_with_category(names, name, 'action')\n\n        for name, ref in self._get_has_definition().items():\n            # Subresources require no data members, just typically\n            # identifiers and user input.\n            data_required = False\n            for identifier in ref['resource']['identifiers']:\n                if identifier['source'] == 'data':\n                    data_required = True\n                    break\n\n            if not data_required:\n                self._load_name_with_category(\n                    names, name, 'subresource', snake_case=False\n                )\n            else:\n                self._load_name_with_category(names, name, 'reference')\n\n        for name in self._definition.get('hasMany', {}):\n            self._load_name_with_category(names, name, 'collection')\n\n        for name in self._definition.get('waiters', {}):\n            self._load_name_with_category(\n                names, Waiter.PREFIX + name, 'waiter'\n            )\n\n        if shape is not None:\n            for name in shape.members.keys():\n                self._load_name_with_category(names, name, 'attribute')\n\n    def _load_name_with_category(self, names, name, category, snake_case=True):\n        \"\"\"\n        Load a name with a given category, possibly renaming it\n        if that name is already in use. The name will be stored\n        in ``names`` and possibly be set up in ``self._renamed``.\n\n        :type names: set\n        :param names: Existing names (Python attributes, properties, or\n                      methods) on the resource.\n        :type name: string\n        :param name: The original name of the value.\n        :type category: string\n        :param category: The value type, such as 'identifier' or 'action'\n        :type snake_case: bool\n        :param snake_case: True (default) if the name should be snake cased.\n        \"\"\"\n        if snake_case:\n            name = xform_name(name)\n\n        if name in names:\n            logger.debug(f'Renaming {self.name} {category} {name}')\n            self._renamed[(category, name)] = name + '_' + category\n            name += '_' + category\n\n            if name in names:\n                # This isn't good, let's raise instead of trying to keep\n                # renaming this value.\n                raise ValueError(\n                    f'Problem renaming {self.name} {category} to {name}!'\n                )\n\n        names.add(name)\n\n    def _get_name(self, category, name, snake_case=True):\n        \"\"\"\n        Get a possibly renamed value given a category and name. This\n        uses the rename map set up in ``load_rename_map``, so that\n        method must be called once first.\n\n        :type category: string\n        :param category: The value type, such as 'identifier' or 'action'\n        :type name: string\n        :param name: The original name of the value\n        :type snake_case: bool\n        :param snake_case: True (default) if the name should be snake cased.\n        :rtype: string\n        :return: Either the renamed value if it is set, otherwise the\n                 original name.\n        \"\"\"\n        if snake_case:\n            name = xform_name(name)\n\n        return self._renamed.get((category, name), name)\n\n    def get_attributes(self, shape):\n        \"\"\"\n        Get a dictionary of attribute names to original name and shape\n        models that represent the attributes of this resource. Looks\n        like the following:\n\n            {\n                'some_name': ('SomeName', <Shape...>)\n            }\n\n        :type shape: botocore.model.Shape\n        :param shape: The underlying shape for this resource.\n        :rtype: dict\n        :return: Mapping of resource attributes.\n        \"\"\"\n        attributes = {}\n        identifier_names = [i.name for i in self.identifiers]\n\n        for name, member in shape.members.items():\n            snake_cased = xform_name(name)\n            if snake_cased in identifier_names:\n                # Skip identifiers, these are set through other means\n                continue\n            snake_cased = self._get_name(\n                'attribute', snake_cased, snake_case=False\n            )\n            attributes[snake_cased] = (name, member)\n\n        return attributes\n\n    @property\n    def identifiers(self):\n        \"\"\"\n        Get a list of resource identifiers.\n\n        :type: list(:py:class:`Identifier`)\n        \"\"\"\n        identifiers = []\n\n        for item in self._definition.get('identifiers', []):\n            name = self._get_name('identifier', item['name'])\n            member_name = item.get('memberName', None)\n            if member_name:\n                member_name = self._get_name('attribute', member_name)\n            identifiers.append(Identifier(name, member_name))\n\n        return identifiers\n\n    @property\n    def load(self):\n        \"\"\"\n        Get the load action for this resource, if it is defined.\n\n        :type: :py:class:`Action` or ``None``\n        \"\"\"\n        action = self._definition.get('load')\n\n        if action is not None:\n            action = Action('load', action, self._resource_defs)\n\n        return action\n\n    @property\n    def actions(self):\n        \"\"\"\n        Get a list of actions for this resource.\n\n        :type: list(:py:class:`Action`)\n        \"\"\"\n        actions = []\n\n        for name, item in self._definition.get('actions', {}).items():\n            name = self._get_name('action', name)\n            actions.append(Action(name, item, self._resource_defs))\n\n        return actions\n\n    @property\n    def batch_actions(self):\n        \"\"\"\n        Get a list of batch actions for this resource.\n\n        :type: list(:py:class:`Action`)\n        \"\"\"\n        actions = []\n\n        for name, item in self._definition.get('batchActions', {}).items():\n            name = self._get_name('batch_action', name)\n            actions.append(Action(name, item, self._resource_defs))\n\n        return actions\n\n    def _get_has_definition(self):\n        \"\"\"\n        Get a ``has`` relationship definition from a model, where the\n        service resource model is treated special in that it contains\n        a relationship to every resource defined for the service. This\n        allows things like ``s3.Object('bucket-name', 'key')`` to\n        work even though the JSON doesn't define it explicitly.\n\n        :rtype: dict\n        :return: Mapping of names to subresource and reference\n                 definitions.\n        \"\"\"\n        if self.name not in self._resource_defs:\n            # This is the service resource, so let us expose all of\n            # the defined resources as subresources.\n            definition = {}\n\n            for name, resource_def in self._resource_defs.items():\n                # It's possible for the service to have renamed a\n                # resource or to have defined multiple names that\n                # point to the same resource type, so we need to\n                # take that into account.\n                found = False\n                has_items = self._definition.get('has', {}).items()\n                for has_name, has_def in has_items:\n                    if has_def.get('resource', {}).get('type') == name:\n                        definition[has_name] = has_def\n                        found = True\n\n                if not found:\n                    # Create a relationship definition and attach it\n                    # to the model, such that all identifiers must be\n                    # supplied by the user. It will look something like:\n                    #\n                    # {\n                    #   'resource': {\n                    #     'type': 'ResourceName',\n                    #     'identifiers': [\n                    #       {'target': 'Name1', 'source': 'input'},\n                    #       {'target': 'Name2', 'source': 'input'},\n                    #       ...\n                    #     ]\n                    #   }\n                    # }\n                    #\n                    fake_has = {'resource': {'type': name, 'identifiers': []}}\n\n                    for identifier in resource_def.get('identifiers', []):\n                        fake_has['resource']['identifiers'].append(\n                            {'target': identifier['name'], 'source': 'input'}\n                        )\n\n                    definition[name] = fake_has\n        else:\n            definition = self._definition.get('has', {})\n\n        return definition\n\n    def _get_related_resources(self, subresources):\n        \"\"\"\n        Get a list of sub-resources or references.\n\n        :type subresources: bool\n        :param subresources: ``True`` to get sub-resources, ``False`` to\n                             get references.\n        :rtype: list(:py:class:`Action`)\n        \"\"\"\n        resources = []\n\n        for name, definition in self._get_has_definition().items():\n            if subresources:\n                name = self._get_name('subresource', name, snake_case=False)\n            else:\n                name = self._get_name('reference', name)\n            action = Action(name, definition, self._resource_defs)\n\n            data_required = False\n            for identifier in action.resource.identifiers:\n                if identifier.source == 'data':\n                    data_required = True\n                    break\n\n            if subresources and not data_required:\n                resources.append(action)\n            elif not subresources and data_required:\n                resources.append(action)\n\n        return resources\n\n    @property\n    def subresources(self):\n        \"\"\"\n        Get a list of sub-resources.\n\n        :type: list(:py:class:`Action`)\n        \"\"\"\n        return self._get_related_resources(True)\n\n    @property\n    def references(self):\n        \"\"\"\n        Get a list of reference resources.\n\n        :type: list(:py:class:`Action`)\n        \"\"\"\n        return self._get_related_resources(False)\n\n    @property\n    def collections(self):\n        \"\"\"\n        Get a list of collections for this resource.\n\n        :type: list(:py:class:`Collection`)\n        \"\"\"\n        collections = []\n\n        for name, item in self._definition.get('hasMany', {}).items():\n            name = self._get_name('collection', name)\n            collections.append(Collection(name, item, self._resource_defs))\n\n        return collections\n\n    @property\n    def waiters(self):\n        \"\"\"\n        Get a list of waiters for this resource.\n\n        :type: list(:py:class:`Waiter`)\n        \"\"\"\n        waiters = []\n\n        for name, item in self._definition.get('waiters', {}).items():\n            name = self._get_name('waiter', Waiter.PREFIX + name)\n            waiters.append(Waiter(name, item))\n\n        return waiters\n", "boto3/resources/action.py": "# Copyright 2014 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n\nimport logging\n\nfrom botocore import xform_name\n\nfrom boto3.docs.docstring import ActionDocstring\nfrom boto3.utils import inject_attribute\n\nfrom .model import Action\nfrom .params import create_request_parameters\nfrom .response import RawHandler, ResourceHandler\n\nlogger = logging.getLogger(__name__)\n\n\nclass ServiceAction:\n    \"\"\"\n    A class representing a callable action on a resource, for example\n    ``sqs.get_queue_by_name(...)`` or ``s3.Bucket('foo').delete()``.\n    The action may construct parameters from existing resource identifiers\n    and may return either a raw response or a new resource instance.\n\n    :type action_model: :py:class`~boto3.resources.model.Action`\n    :param action_model: The action model.\n\n    :type factory: ResourceFactory\n    :param factory: The factory that created the resource class to which\n                    this action is attached.\n\n    :type service_context: :py:class:`~boto3.utils.ServiceContext`\n    :param service_context: Context about the AWS service\n    \"\"\"\n\n    def __init__(self, action_model, factory=None, service_context=None):\n        self._action_model = action_model\n\n        # In the simplest case we just return the response, but if a\n        # resource is defined, then we must create these before returning.\n        resource_response_model = action_model.resource\n        if resource_response_model:\n            self._response_handler = ResourceHandler(\n                search_path=resource_response_model.path,\n                factory=factory,\n                resource_model=resource_response_model,\n                service_context=service_context,\n                operation_name=action_model.request.operation,\n            )\n        else:\n            self._response_handler = RawHandler(action_model.path)\n\n    def __call__(self, parent, *args, **kwargs):\n        \"\"\"\n        Perform the action's request operation after building operation\n        parameters and build any defined resources from the response.\n\n        :type parent: :py:class:`~boto3.resources.base.ServiceResource`\n        :param parent: The resource instance to which this action is attached.\n        :rtype: dict or ServiceResource or list(ServiceResource)\n        :return: The response, either as a raw dict or resource instance(s).\n        \"\"\"\n        operation_name = xform_name(self._action_model.request.operation)\n\n        # First, build predefined params and then update with the\n        # user-supplied kwargs, which allows overriding the pre-built\n        # params if needed.\n        params = create_request_parameters(parent, self._action_model.request)\n        params.update(kwargs)\n\n        logger.debug(\n            'Calling %s:%s with %r',\n            parent.meta.service_name,\n            operation_name,\n            params,\n        )\n\n        response = getattr(parent.meta.client, operation_name)(*args, **params)\n\n        logger.debug('Response: %r', response)\n\n        return self._response_handler(parent, params, response)\n\n\nclass BatchAction(ServiceAction):\n    \"\"\"\n    An action which operates on a batch of items in a collection, typically\n    a single page of results from the collection's underlying service\n    operation call. For example, this allows you to delete up to 999\n    S3 objects in a single operation rather than calling ``.delete()`` on\n    each one individually.\n\n    :type action_model: :py:class`~boto3.resources.model.Action`\n    :param action_model: The action model.\n\n    :type factory: ResourceFactory\n    :param factory: The factory that created the resource class to which\n                    this action is attached.\n\n    :type service_context: :py:class:`~boto3.utils.ServiceContext`\n    :param service_context: Context about the AWS service\n    \"\"\"\n\n    def __call__(self, parent, *args, **kwargs):\n        \"\"\"\n        Perform the batch action's operation on every page of results\n        from the collection.\n\n        :type parent:\n            :py:class:`~boto3.resources.collection.ResourceCollection`\n        :param parent: The collection iterator to which this action\n                       is attached.\n        :rtype: list(dict)\n        :return: A list of low-level response dicts from each call.\n        \"\"\"\n        service_name = None\n        client = None\n        responses = []\n        operation_name = xform_name(self._action_model.request.operation)\n\n        # Unlike the simple action above, a batch action must operate\n        # on batches (or pages) of items. So we get each page, construct\n        # the necessary parameters and call the batch operation.\n        for page in parent.pages():\n            params = {}\n            for index, resource in enumerate(page):\n                # There is no public interface to get a service name\n                # or low-level client from a collection, so we get\n                # these from the first resource in the collection.\n                if service_name is None:\n                    service_name = resource.meta.service_name\n                if client is None:\n                    client = resource.meta.client\n\n                create_request_parameters(\n                    resource,\n                    self._action_model.request,\n                    params=params,\n                    index=index,\n                )\n\n            if not params:\n                # There are no items, no need to make a call.\n                break\n\n            params.update(kwargs)\n\n            logger.debug(\n                'Calling %s:%s with %r', service_name, operation_name, params\n            )\n\n            response = getattr(client, operation_name)(*args, **params)\n\n            logger.debug('Response: %r', response)\n\n            responses.append(self._response_handler(parent, params, response))\n\n        return responses\n\n\nclass WaiterAction:\n    \"\"\"\n    A class representing a callable waiter action on a resource, for example\n    ``s3.Bucket('foo').wait_until_bucket_exists()``.\n    The waiter action may construct parameters from existing resource\n    identifiers.\n\n    :type waiter_model: :py:class`~boto3.resources.model.Waiter`\n    :param waiter_model: The action waiter.\n    :type waiter_resource_name: string\n    :param waiter_resource_name: The name of the waiter action for the\n                                 resource. It usually begins with a\n                                 ``wait_until_``\n    \"\"\"\n\n    def __init__(self, waiter_model, waiter_resource_name):\n        self._waiter_model = waiter_model\n        self._waiter_resource_name = waiter_resource_name\n\n    def __call__(self, parent, *args, **kwargs):\n        \"\"\"\n        Perform the wait operation after building operation\n        parameters.\n\n        :type parent: :py:class:`~boto3.resources.base.ServiceResource`\n        :param parent: The resource instance to which this action is attached.\n        \"\"\"\n        client_waiter_name = xform_name(self._waiter_model.waiter_name)\n\n        # First, build predefined params and then update with the\n        # user-supplied kwargs, which allows overriding the pre-built\n        # params if needed.\n        params = create_request_parameters(parent, self._waiter_model)\n        params.update(kwargs)\n\n        logger.debug(\n            'Calling %s:%s with %r',\n            parent.meta.service_name,\n            self._waiter_resource_name,\n            params,\n        )\n\n        client = parent.meta.client\n        waiter = client.get_waiter(client_waiter_name)\n        response = waiter.wait(**params)\n\n        logger.debug('Response: %r', response)\n\n\nclass CustomModeledAction:\n    \"\"\"A custom, modeled action to inject into a resource.\"\"\"\n\n    def __init__(self, action_name, action_model, function, event_emitter):\n        \"\"\"\n        :type action_name: str\n        :param action_name: The name of the action to inject, e.g.\n            'delete_tags'\n\n        :type action_model: dict\n        :param action_model: A JSON definition of the action, as if it were\n            part of the resource model.\n\n        :type function: function\n        :param function: The function to perform when the action is called.\n            The first argument should be 'self', which will be the resource\n            the function is to be called on.\n\n        :type event_emitter: :py:class:`botocore.hooks.BaseEventHooks`\n        :param event_emitter: The session event emitter.\n        \"\"\"\n        self.name = action_name\n        self.model = action_model\n        self.function = function\n        self.emitter = event_emitter\n\n    def inject(self, class_attributes, service_context, event_name, **kwargs):\n        resource_name = event_name.rsplit(\".\")[-1]\n        action = Action(self.name, self.model, {})\n        self.function.__name__ = self.name\n        self.function.__doc__ = ActionDocstring(\n            resource_name=resource_name,\n            event_emitter=self.emitter,\n            action_model=action,\n            service_model=service_context.service_model,\n            include_signature=False,\n        )\n        inject_attribute(class_attributes, self.name, self.function)\n", "boto3/resources/factory.py": "# Copyright 2014 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n\nimport logging\nfrom functools import partial\n\nfrom ..docs import docstring\nfrom ..exceptions import ResourceLoadException\nfrom .action import ServiceAction, WaiterAction\nfrom .base import ResourceMeta, ServiceResource\nfrom .collection import CollectionFactory\nfrom .model import ResourceModel\nfrom .response import ResourceHandler, build_identifiers\n\nlogger = logging.getLogger(__name__)\n\n\nclass ResourceFactory:\n    \"\"\"\n    A factory to create new :py:class:`~boto3.resources.base.ServiceResource`\n    classes from a :py:class:`~boto3.resources.model.ResourceModel`. There are\n    two types of lookups that can be done: one on the service itself (e.g. an\n    SQS resource) and another on models contained within the service (e.g. an\n    SQS Queue resource).\n    \"\"\"\n\n    def __init__(self, emitter):\n        self._collection_factory = CollectionFactory()\n        self._emitter = emitter\n\n    def load_from_definition(\n        self, resource_name, single_resource_json_definition, service_context\n    ):\n        \"\"\"\n        Loads a resource from a model, creating a new\n        :py:class:`~boto3.resources.base.ServiceResource` subclass\n        with the correct properties and methods, named based on the service\n        and resource name, e.g. EC2.Instance.\n\n        :type resource_name: string\n        :param resource_name: Name of the resource to look up. For services,\n                              this should match the ``service_name``.\n\n        :type single_resource_json_definition: dict\n        :param single_resource_json_definition:\n            The loaded json of a single service resource or resource\n            definition.\n\n        :type service_context: :py:class:`~boto3.utils.ServiceContext`\n        :param service_context: Context about the AWS service\n\n        :rtype: Subclass of :py:class:`~boto3.resources.base.ServiceResource`\n        :return: The service or resource class.\n        \"\"\"\n        logger.debug(\n            'Loading %s:%s', service_context.service_name, resource_name\n        )\n\n        # Using the loaded JSON create a ResourceModel object.\n        resource_model = ResourceModel(\n            resource_name,\n            single_resource_json_definition,\n            service_context.resource_json_definitions,\n        )\n\n        # Do some renaming of the shape if there was a naming collision\n        # that needed to be accounted for.\n        shape = None\n        if resource_model.shape:\n            shape = service_context.service_model.shape_for(\n                resource_model.shape\n            )\n        resource_model.load_rename_map(shape)\n\n        # Set some basic info\n        meta = ResourceMeta(\n            service_context.service_name, resource_model=resource_model\n        )\n        attrs = {\n            'meta': meta,\n        }\n\n        # Create and load all of attributes of the resource class based\n        # on the models.\n\n        # Identifiers\n        self._load_identifiers(\n            attrs=attrs,\n            meta=meta,\n            resource_name=resource_name,\n            resource_model=resource_model,\n        )\n\n        # Load/Reload actions\n        self._load_actions(\n            attrs=attrs,\n            resource_name=resource_name,\n            resource_model=resource_model,\n            service_context=service_context,\n        )\n\n        # Attributes that get auto-loaded\n        self._load_attributes(\n            attrs=attrs,\n            meta=meta,\n            resource_name=resource_name,\n            resource_model=resource_model,\n            service_context=service_context,\n        )\n\n        # Collections and their corresponding methods\n        self._load_collections(\n            attrs=attrs,\n            resource_model=resource_model,\n            service_context=service_context,\n        )\n\n        # References and Subresources\n        self._load_has_relations(\n            attrs=attrs,\n            resource_name=resource_name,\n            resource_model=resource_model,\n            service_context=service_context,\n        )\n\n        # Waiter resource actions\n        self._load_waiters(\n            attrs=attrs,\n            resource_name=resource_name,\n            resource_model=resource_model,\n            service_context=service_context,\n        )\n\n        # Create the name based on the requested service and resource\n        cls_name = resource_name\n        if service_context.service_name == resource_name:\n            cls_name = 'ServiceResource'\n        cls_name = service_context.service_name + '.' + cls_name\n\n        base_classes = [ServiceResource]\n        if self._emitter is not None:\n            self._emitter.emit(\n                f'creating-resource-class.{cls_name}',\n                class_attributes=attrs,\n                base_classes=base_classes,\n                service_context=service_context,\n            )\n        return type(str(cls_name), tuple(base_classes), attrs)\n\n    def _load_identifiers(self, attrs, meta, resource_model, resource_name):\n        \"\"\"\n        Populate required identifiers. These are arguments without which\n        the resource cannot be used. Identifiers become arguments for\n        operations on the resource.\n        \"\"\"\n        for identifier in resource_model.identifiers:\n            meta.identifiers.append(identifier.name)\n            attrs[identifier.name] = self._create_identifier(\n                identifier, resource_name\n            )\n\n    def _load_actions(\n        self, attrs, resource_name, resource_model, service_context\n    ):\n        \"\"\"\n        Actions on the resource become methods, with the ``load`` method\n        being a special case which sets internal data for attributes, and\n        ``reload`` is an alias for ``load``.\n        \"\"\"\n        if resource_model.load:\n            attrs['load'] = self._create_action(\n                action_model=resource_model.load,\n                resource_name=resource_name,\n                service_context=service_context,\n                is_load=True,\n            )\n            attrs['reload'] = attrs['load']\n\n        for action in resource_model.actions:\n            attrs[action.name] = self._create_action(\n                action_model=action,\n                resource_name=resource_name,\n                service_context=service_context,\n            )\n\n    def _load_attributes(\n        self, attrs, meta, resource_name, resource_model, service_context\n    ):\n        \"\"\"\n        Load resource attributes based on the resource shape. The shape\n        name is referenced in the resource JSON, but the shape itself\n        is defined in the Botocore service JSON, hence the need for\n        access to the ``service_model``.\n        \"\"\"\n        if not resource_model.shape:\n            return\n\n        shape = service_context.service_model.shape_for(resource_model.shape)\n\n        identifiers = {\n            i.member_name: i\n            for i in resource_model.identifiers\n            if i.member_name\n        }\n        attributes = resource_model.get_attributes(shape)\n        for name, (orig_name, member) in attributes.items():\n            if name in identifiers:\n                prop = self._create_identifier_alias(\n                    resource_name=resource_name,\n                    identifier=identifiers[name],\n                    member_model=member,\n                    service_context=service_context,\n                )\n            else:\n                prop = self._create_autoload_property(\n                    resource_name=resource_name,\n                    name=orig_name,\n                    snake_cased=name,\n                    member_model=member,\n                    service_context=service_context,\n                )\n            attrs[name] = prop\n\n    def _load_collections(self, attrs, resource_model, service_context):\n        \"\"\"\n        Load resource collections from the model. Each collection becomes\n        a :py:class:`~boto3.resources.collection.CollectionManager` instance\n        on the resource instance, which allows you to iterate and filter\n        through the collection's items.\n        \"\"\"\n        for collection_model in resource_model.collections:\n            attrs[collection_model.name] = self._create_collection(\n                resource_name=resource_model.name,\n                collection_model=collection_model,\n                service_context=service_context,\n            )\n\n    def _load_has_relations(\n        self, attrs, resource_name, resource_model, service_context\n    ):\n        \"\"\"\n        Load related resources, which are defined via a ``has``\n        relationship but conceptually come in two forms:\n\n        1. A reference, which is a related resource instance and can be\n           ``None``, such as an EC2 instance's ``vpc``.\n        2. A subresource, which is a resource constructor that will always\n           return a resource instance which shares identifiers/data with\n           this resource, such as ``s3.Bucket('name').Object('key')``.\n        \"\"\"\n        for reference in resource_model.references:\n            # This is a dangling reference, i.e. we have all\n            # the data we need to create the resource, so\n            # this instance becomes an attribute on the class.\n            attrs[reference.name] = self._create_reference(\n                reference_model=reference,\n                resource_name=resource_name,\n                service_context=service_context,\n            )\n\n        for subresource in resource_model.subresources:\n            # This is a sub-resource class you can create\n            # by passing in an identifier, e.g. s3.Bucket(name).\n            attrs[subresource.name] = self._create_class_partial(\n                subresource_model=subresource,\n                resource_name=resource_name,\n                service_context=service_context,\n            )\n\n        self._create_available_subresources_command(\n            attrs, resource_model.subresources\n        )\n\n    def _create_available_subresources_command(self, attrs, subresources):\n        _subresources = [subresource.name for subresource in subresources]\n        _subresources = sorted(_subresources)\n\n        def get_available_subresources(factory_self):\n            \"\"\"\n            Returns a list of all the available sub-resources for this\n            Resource.\n\n            :returns: A list containing the name of each sub-resource for this\n                resource\n            :rtype: list of str\n            \"\"\"\n            return _subresources\n\n        attrs['get_available_subresources'] = get_available_subresources\n\n    def _load_waiters(\n        self, attrs, resource_name, resource_model, service_context\n    ):\n        \"\"\"\n        Load resource waiters from the model. Each waiter allows you to\n        wait until a resource reaches a specific state by polling the state\n        of the resource.\n        \"\"\"\n        for waiter in resource_model.waiters:\n            attrs[waiter.name] = self._create_waiter(\n                resource_waiter_model=waiter,\n                resource_name=resource_name,\n                service_context=service_context,\n            )\n\n    def _create_identifier(factory_self, identifier, resource_name):\n        \"\"\"\n        Creates a read-only property for identifier attributes.\n        \"\"\"\n\n        def get_identifier(self):\n            # The default value is set to ``None`` instead of\n            # raising an AttributeError because when resources are\n            # instantiated a check is made such that none of the\n            # identifiers have a value ``None``. If any are ``None``,\n            # a more informative user error than a generic AttributeError\n            # is raised.\n            return getattr(self, '_' + identifier.name, None)\n\n        get_identifier.__name__ = str(identifier.name)\n        get_identifier.__doc__ = docstring.IdentifierDocstring(\n            resource_name=resource_name,\n            identifier_model=identifier,\n            include_signature=False,\n        )\n\n        return property(get_identifier)\n\n    def _create_identifier_alias(\n        factory_self, resource_name, identifier, member_model, service_context\n    ):\n        \"\"\"\n        Creates a read-only property that aliases an identifier.\n        \"\"\"\n\n        def get_identifier(self):\n            return getattr(self, '_' + identifier.name, None)\n\n        get_identifier.__name__ = str(identifier.member_name)\n        get_identifier.__doc__ = docstring.AttributeDocstring(\n            service_name=service_context.service_name,\n            resource_name=resource_name,\n            attr_name=identifier.member_name,\n            event_emitter=factory_self._emitter,\n            attr_model=member_model,\n            include_signature=False,\n        )\n\n        return property(get_identifier)\n\n    def _create_autoload_property(\n        factory_self,\n        resource_name,\n        name,\n        snake_cased,\n        member_model,\n        service_context,\n    ):\n        \"\"\"\n        Creates a new property on the resource to lazy-load its value\n        via the resource's ``load`` method (if it exists).\n        \"\"\"\n\n        # The property loader will check to see if this resource has already\n        # been loaded and return the cached value if possible. If not, then\n        # it first checks to see if it CAN be loaded (raise if not), then\n        # calls the load before returning the value.\n        def property_loader(self):\n            if self.meta.data is None:\n                if hasattr(self, 'load'):\n                    self.load()\n                else:\n                    raise ResourceLoadException(\n                        f'{self.__class__.__name__} has no load method'\n                    )\n\n            return self.meta.data.get(name)\n\n        property_loader.__name__ = str(snake_cased)\n        property_loader.__doc__ = docstring.AttributeDocstring(\n            service_name=service_context.service_name,\n            resource_name=resource_name,\n            attr_name=snake_cased,\n            event_emitter=factory_self._emitter,\n            attr_model=member_model,\n            include_signature=False,\n        )\n\n        return property(property_loader)\n\n    def _create_waiter(\n        factory_self, resource_waiter_model, resource_name, service_context\n    ):\n        \"\"\"\n        Creates a new wait method for each resource where both a waiter and\n        resource model is defined.\n        \"\"\"\n        waiter = WaiterAction(\n            resource_waiter_model,\n            waiter_resource_name=resource_waiter_model.name,\n        )\n\n        def do_waiter(self, *args, **kwargs):\n            waiter(self, *args, **kwargs)\n\n        do_waiter.__name__ = str(resource_waiter_model.name)\n        do_waiter.__doc__ = docstring.ResourceWaiterDocstring(\n            resource_name=resource_name,\n            event_emitter=factory_self._emitter,\n            service_model=service_context.service_model,\n            resource_waiter_model=resource_waiter_model,\n            service_waiter_model=service_context.service_waiter_model,\n            include_signature=False,\n        )\n        return do_waiter\n\n    def _create_collection(\n        factory_self, resource_name, collection_model, service_context\n    ):\n        \"\"\"\n        Creates a new property on the resource to lazy-load a collection.\n        \"\"\"\n        cls = factory_self._collection_factory.load_from_definition(\n            resource_name=resource_name,\n            collection_model=collection_model,\n            service_context=service_context,\n            event_emitter=factory_self._emitter,\n        )\n\n        def get_collection(self):\n            return cls(\n                collection_model=collection_model,\n                parent=self,\n                factory=factory_self,\n                service_context=service_context,\n            )\n\n        get_collection.__name__ = str(collection_model.name)\n        get_collection.__doc__ = docstring.CollectionDocstring(\n            collection_model=collection_model, include_signature=False\n        )\n        return property(get_collection)\n\n    def _create_reference(\n        factory_self, reference_model, resource_name, service_context\n    ):\n        \"\"\"\n        Creates a new property on the resource to lazy-load a reference.\n        \"\"\"\n        # References are essentially an action with no request\n        # or response, so we can re-use the response handlers to\n        # build up resources from identifiers and data members.\n        handler = ResourceHandler(\n            search_path=reference_model.resource.path,\n            factory=factory_self,\n            resource_model=reference_model.resource,\n            service_context=service_context,\n        )\n\n        # Are there any identifiers that need access to data members?\n        # This is important when building the resource below since\n        # it requires the data to be loaded.\n        needs_data = any(\n            i.source == 'data' for i in reference_model.resource.identifiers\n        )\n\n        def get_reference(self):\n            # We need to lazy-evaluate the reference to handle circular\n            # references between resources. We do this by loading the class\n            # when first accessed.\n            # This is using a *response handler* so we need to make sure\n            # our data is loaded (if possible) and pass that data into\n            # the handler as if it were a response. This allows references\n            # to have their data loaded properly.\n            if needs_data and self.meta.data is None and hasattr(self, 'load'):\n                self.load()\n            return handler(self, {}, self.meta.data)\n\n        get_reference.__name__ = str(reference_model.name)\n        get_reference.__doc__ = docstring.ReferenceDocstring(\n            reference_model=reference_model, include_signature=False\n        )\n        return property(get_reference)\n\n    def _create_class_partial(\n        factory_self, subresource_model, resource_name, service_context\n    ):\n        \"\"\"\n        Creates a new method which acts as a functools.partial, passing\n        along the instance's low-level `client` to the new resource\n        class' constructor.\n        \"\"\"\n        name = subresource_model.resource.type\n\n        def create_resource(self, *args, **kwargs):\n            # We need a new method here because we want access to the\n            # instance's client.\n            positional_args = []\n\n            # We lazy-load the class to handle circular references.\n            json_def = service_context.resource_json_definitions.get(name, {})\n            resource_cls = factory_self.load_from_definition(\n                resource_name=name,\n                single_resource_json_definition=json_def,\n                service_context=service_context,\n            )\n\n            # Assumes that identifiers are in order, which lets you do\n            # e.g. ``sqs.Queue('foo').Message('bar')`` to create a new message\n            # linked with the ``foo`` queue and which has a ``bar`` receipt\n            # handle. If we did kwargs here then future positional arguments\n            # would lead to failure.\n            identifiers = subresource_model.resource.identifiers\n            if identifiers is not None:\n                for identifier, value in build_identifiers(identifiers, self):\n                    positional_args.append(value)\n\n            return partial(\n                resource_cls, *positional_args, client=self.meta.client\n            )(*args, **kwargs)\n\n        create_resource.__name__ = str(name)\n        create_resource.__doc__ = docstring.SubResourceDocstring(\n            resource_name=resource_name,\n            sub_resource_model=subresource_model,\n            service_model=service_context.service_model,\n            include_signature=False,\n        )\n        return create_resource\n\n    def _create_action(\n        factory_self,\n        action_model,\n        resource_name,\n        service_context,\n        is_load=False,\n    ):\n        \"\"\"\n        Creates a new method which makes a request to the underlying\n        AWS service.\n        \"\"\"\n        # Create the action in in this closure but before the ``do_action``\n        # method below is invoked, which allows instances of the resource\n        # to share the ServiceAction instance.\n        action = ServiceAction(\n            action_model, factory=factory_self, service_context=service_context\n        )\n\n        # A resource's ``load`` method is special because it sets\n        # values on the resource instead of returning the response.\n        if is_load:\n            # We need a new method here because we want access to the\n            # instance via ``self``.\n            def do_action(self, *args, **kwargs):\n                response = action(self, *args, **kwargs)\n                self.meta.data = response\n\n            # Create the docstring for the load/reload methods.\n            lazy_docstring = docstring.LoadReloadDocstring(\n                action_name=action_model.name,\n                resource_name=resource_name,\n                event_emitter=factory_self._emitter,\n                load_model=action_model,\n                service_model=service_context.service_model,\n                include_signature=False,\n            )\n        else:\n            # We need a new method here because we want access to the\n            # instance via ``self``.\n            def do_action(self, *args, **kwargs):\n                response = action(self, *args, **kwargs)\n\n                if hasattr(self, 'load'):\n                    # Clear cached data. It will be reloaded the next\n                    # time that an attribute is accessed.\n                    # TODO: Make this configurable in the future?\n                    self.meta.data = None\n\n                return response\n\n            lazy_docstring = docstring.ActionDocstring(\n                resource_name=resource_name,\n                event_emitter=factory_self._emitter,\n                action_model=action_model,\n                service_model=service_context.service_model,\n                include_signature=False,\n            )\n\n        do_action.__name__ = str(action_model.name)\n        do_action.__doc__ = lazy_docstring\n        return do_action\n", "boto3/resources/base.py": "# Copyright 2014 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n\nimport logging\n\nimport boto3\n\nlogger = logging.getLogger(__name__)\n\n\nclass ResourceMeta:\n    \"\"\"\n    An object containing metadata about a resource.\n    \"\"\"\n\n    def __init__(\n        self,\n        service_name,\n        identifiers=None,\n        client=None,\n        data=None,\n        resource_model=None,\n    ):\n        #: (``string``) The service name, e.g. 's3'\n        self.service_name = service_name\n\n        if identifiers is None:\n            identifiers = []\n        #: (``list``) List of identifier names\n        self.identifiers = identifiers\n\n        #: (:py:class:`~botocore.client.BaseClient`) Low-level Botocore client\n        self.client = client\n        #: (``dict``) Loaded resource data attributes\n        self.data = data\n\n        # The resource model for that resource\n        self.resource_model = resource_model\n\n    def __repr__(self):\n        return f'ResourceMeta(\\'{self.service_name}\\', identifiers={self.identifiers})'\n\n    def __eq__(self, other):\n        # Two metas are equal if their components are all equal\n        if other.__class__.__name__ != self.__class__.__name__:\n            return False\n\n        return self.__dict__ == other.__dict__\n\n    def copy(self):\n        \"\"\"\n        Create a copy of this metadata object.\n        \"\"\"\n        params = self.__dict__.copy()\n        service_name = params.pop('service_name')\n        return ResourceMeta(service_name, **params)\n\n\nclass ServiceResource:\n    \"\"\"\n    A base class for resources.\n\n    :type client: botocore.client\n    :param client: A low-level Botocore client instance\n    \"\"\"\n\n    meta = None\n    \"\"\"\n    Stores metadata about this resource instance, such as the\n    ``service_name``, the low-level ``client`` and any cached ``data``\n    from when the instance was hydrated. For example::\n\n        # Get a low-level client from a resource instance\n        client = resource.meta.client\n        response = client.operation(Param='foo')\n\n        # Print the resource instance's service short name\n        print(resource.meta.service_name)\n\n    See :py:class:`ResourceMeta` for more information.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        # Always work on a copy of meta, otherwise we would affect other\n        # instances of the same subclass.\n        self.meta = self.meta.copy()\n\n        # Create a default client if none was passed\n        if kwargs.get('client') is not None:\n            self.meta.client = kwargs.get('client')\n        else:\n            self.meta.client = boto3.client(self.meta.service_name)\n\n        # Allow setting identifiers as positional arguments in the order\n        # in which they were defined in the ResourceJSON.\n        for i, value in enumerate(args):\n            setattr(self, '_' + self.meta.identifiers[i], value)\n\n        # Allow setting identifiers via keyword arguments. Here we need\n        # extra logic to ignore other keyword arguments like ``client``.\n        for name, value in kwargs.items():\n            if name == 'client':\n                continue\n\n            if name not in self.meta.identifiers:\n                raise ValueError(f'Unknown keyword argument: {name}')\n\n            setattr(self, '_' + name, value)\n\n        # Validate that all identifiers have been set.\n        for identifier in self.meta.identifiers:\n            if getattr(self, identifier) is None:\n                raise ValueError(f'Required parameter {identifier} not set')\n\n    def __repr__(self):\n        identifiers = []\n        for identifier in self.meta.identifiers:\n            identifiers.append(\n                f'{identifier}={repr(getattr(self, identifier))}'\n            )\n        return \"{}({})\".format(\n            self.__class__.__name__,\n            ', '.join(identifiers),\n        )\n\n    def __eq__(self, other):\n        # Should be instances of the same resource class\n        if other.__class__.__name__ != self.__class__.__name__:\n            return False\n\n        # Each of the identifiers should have the same value in both\n        # instances, e.g. two buckets need the same name to be equal.\n        for identifier in self.meta.identifiers:\n            if getattr(self, identifier) != getattr(other, identifier):\n                return False\n\n        return True\n\n    def __hash__(self):\n        identifiers = []\n        for identifier in self.meta.identifiers:\n            identifiers.append(getattr(self, identifier))\n        return hash((self.__class__.__name__, tuple(identifiers)))\n", "boto3/resources/params.py": "# Copyright 2014 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n\nimport re\n\nimport jmespath\nfrom botocore import xform_name\n\nfrom ..exceptions import ResourceLoadException\n\nINDEX_RE = re.compile(r'\\[(.*)\\]$')\n\n\ndef get_data_member(parent, path):\n    \"\"\"\n    Get a data member from a parent using a JMESPath search query,\n    loading the parent if required. If the parent cannot be loaded\n    and no data is present then an exception is raised.\n\n    :type parent: ServiceResource\n    :param parent: The resource instance to which contains data we\n                   are interested in.\n    :type path: string\n    :param path: The JMESPath expression to query\n    :raises ResourceLoadException: When no data is present and the\n                                   resource cannot be loaded.\n    :returns: The queried data or ``None``.\n    \"\"\"\n    # Ensure the parent has its data loaded, if possible.\n    if parent.meta.data is None:\n        if hasattr(parent, 'load'):\n            parent.load()\n        else:\n            raise ResourceLoadException(\n                f'{parent.__class__.__name__} has no load method!'\n            )\n\n    return jmespath.search(path, parent.meta.data)\n\n\ndef create_request_parameters(parent, request_model, params=None, index=None):\n    \"\"\"\n    Handle request parameters that can be filled in from identifiers,\n    resource data members or constants.\n\n    By passing ``params``, you can invoke this method multiple times and\n    build up a parameter dict over time, which is particularly useful\n    for reverse JMESPath expressions that append to lists.\n\n    :type parent: ServiceResource\n    :param parent: The resource instance to which this action is attached.\n    :type request_model: :py:class:`~boto3.resources.model.Request`\n    :param request_model: The action request model.\n    :type params: dict\n    :param params: If set, then add to this existing dict. It is both\n                   edited in-place and returned.\n    :type index: int\n    :param index: The position of an item within a list\n    :rtype: dict\n    :return: Pre-filled parameters to be sent to the request operation.\n    \"\"\"\n    if params is None:\n        params = {}\n\n    for param in request_model.params:\n        source = param.source\n        target = param.target\n\n        if source == 'identifier':\n            # Resource identifier, e.g. queue.url\n            value = getattr(parent, xform_name(param.name))\n        elif source == 'data':\n            # If this is a data member then it may incur a load\n            # action before returning the value.\n            value = get_data_member(parent, param.path)\n        elif source in ['string', 'integer', 'boolean']:\n            # These are hard-coded values in the definition\n            value = param.value\n        elif source == 'input':\n            # This is provided by the user, so ignore it here\n            continue\n        else:\n            raise NotImplementedError(f'Unsupported source type: {source}')\n\n        build_param_structure(params, target, value, index)\n\n    return params\n\n\ndef build_param_structure(params, target, value, index=None):\n    \"\"\"\n    This method provides a basic reverse JMESPath implementation that\n    lets you go from a JMESPath-like string to a possibly deeply nested\n    object. The ``params`` are mutated in-place, so subsequent calls\n    can modify the same element by its index.\n\n        >>> build_param_structure(params, 'test[0]', 1)\n        >>> print(params)\n        {'test': [1]}\n\n        >>> build_param_structure(params, 'foo.bar[0].baz', 'hello world')\n        >>> print(params)\n        {'test': [1], 'foo': {'bar': [{'baz': 'hello, world'}]}}\n\n    \"\"\"\n    pos = params\n    parts = target.split('.')\n\n    # First, split into parts like 'foo', 'bar[0]', 'baz' and process\n    # each piece. It can either be a list or a dict, depending on if\n    # an index like `[0]` is present. We detect this via a regular\n    # expression, and keep track of where we are in params via the\n    # pos variable, walking down to the last item. Once there, we\n    # set the value.\n    for i, part in enumerate(parts):\n        # Is it indexing an array?\n        result = INDEX_RE.search(part)\n        if result:\n            if result.group(1):\n                if result.group(1) == '*':\n                    part = part[:-3]\n                else:\n                    # We have an explicit index\n                    index = int(result.group(1))\n                    part = part[: -len(str(index) + '[]')]\n            else:\n                # Index will be set after we know the proper part\n                # name and that it's a list instance.\n                index = None\n                part = part[:-2]\n\n            if part not in pos or not isinstance(pos[part], list):\n                pos[part] = []\n\n            # This means we should append, e.g. 'foo[]'\n            if index is None:\n                index = len(pos[part])\n\n            while len(pos[part]) <= index:\n                # Assume it's a dict until we set the final value below\n                pos[part].append({})\n\n            # Last item? Set the value, otherwise set the new position\n            if i == len(parts) - 1:\n                pos[part][index] = value\n            else:\n                # The new pos is the *item* in the array, not the array!\n                pos = pos[part][index]\n        else:\n            if part not in pos:\n                pos[part] = {}\n\n            # Last item? Set the value, otherwise set the new position\n            if i == len(parts) - 1:\n                pos[part] = value\n            else:\n                pos = pos[part]\n", "boto3/resources/collection.py": "# Copyright 2014 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n\nimport copy\nimport logging\n\nfrom botocore import xform_name\nfrom botocore.utils import merge_dicts\n\nfrom ..docs import docstring\nfrom .action import BatchAction\nfrom .params import create_request_parameters\nfrom .response import ResourceHandler\n\nlogger = logging.getLogger(__name__)\n\n\nclass ResourceCollection:\n    \"\"\"\n    Represents a collection of resources, which can be iterated through,\n    optionally with filtering. Collections automatically handle pagination\n    for you.\n\n    See :ref:`guide_collections` for a high-level overview of collections,\n    including when remote service requests are performed.\n\n    :type model: :py:class:`~boto3.resources.model.Collection`\n    :param model: Collection model\n    :type parent: :py:class:`~boto3.resources.base.ServiceResource`\n    :param parent: The collection's parent resource\n    :type handler: :py:class:`~boto3.resources.response.ResourceHandler`\n    :param handler: The resource response handler used to create resource\n                    instances\n    \"\"\"\n\n    def __init__(self, model, parent, handler, **kwargs):\n        self._model = model\n        self._parent = parent\n        self._py_operation_name = xform_name(model.request.operation)\n        self._handler = handler\n        self._params = copy.deepcopy(kwargs)\n\n    def __repr__(self):\n        return '{}({}, {})'.format(\n            self.__class__.__name__,\n            self._parent,\n            f'{self._parent.meta.service_name}.{self._model.resource.type}',\n        )\n\n    def __iter__(self):\n        \"\"\"\n        A generator which yields resource instances after doing the\n        appropriate service operation calls and handling any pagination\n        on your behalf.\n\n        Page size, item limit, and filter parameters are applied\n        if they have previously been set.\n\n            >>> bucket = s3.Bucket('boto3')\n            >>> for obj in bucket.objects.all():\n            ...     print(obj.key)\n            'key1'\n            'key2'\n\n        \"\"\"\n        limit = self._params.get('limit', None)\n\n        count = 0\n        for page in self.pages():\n            for item in page:\n                yield item\n\n                # If the limit is set and has been reached, then\n                # we stop processing items here.\n                count += 1\n                if limit is not None and count >= limit:\n                    return\n\n    def _clone(self, **kwargs):\n        \"\"\"\n        Create a clone of this collection. This is used by the methods\n        below to provide a chainable interface that returns copies\n        rather than the original. This allows things like:\n\n            >>> base = collection.filter(Param1=1)\n            >>> query1 = base.filter(Param2=2)\n            >>> query2 = base.filter(Param3=3)\n            >>> query1.params\n            {'Param1': 1, 'Param2': 2}\n            >>> query2.params\n            {'Param1': 1, 'Param3': 3}\n\n        :rtype: :py:class:`ResourceCollection`\n        :return: A clone of this resource collection\n        \"\"\"\n        params = copy.deepcopy(self._params)\n        merge_dicts(params, kwargs, append_lists=True)\n        clone = self.__class__(\n            self._model, self._parent, self._handler, **params\n        )\n        return clone\n\n    def pages(self):\n        \"\"\"\n        A generator which yields pages of resource instances after\n        doing the appropriate service operation calls and handling\n        any pagination on your behalf. Non-paginated calls will\n        return a single page of items.\n\n        Page size, item limit, and filter parameters are applied\n        if they have previously been set.\n\n            >>> bucket = s3.Bucket('boto3')\n            >>> for page in bucket.objects.pages():\n            ...     for obj in page:\n            ...         print(obj.key)\n            'key1'\n            'key2'\n\n        :rtype: list(:py:class:`~boto3.resources.base.ServiceResource`)\n        :return: List of resource instances\n        \"\"\"\n        client = self._parent.meta.client\n        cleaned_params = self._params.copy()\n        limit = cleaned_params.pop('limit', None)\n        page_size = cleaned_params.pop('page_size', None)\n        params = create_request_parameters(self._parent, self._model.request)\n        merge_dicts(params, cleaned_params, append_lists=True)\n\n        # Is this a paginated operation? If so, we need to get an\n        # iterator for the various pages. If not, then we simply\n        # call the operation and return the result as a single\n        # page in a list. For non-paginated results, we just ignore\n        # the page size parameter.\n        if client.can_paginate(self._py_operation_name):\n            logger.debug(\n                'Calling paginated %s:%s with %r',\n                self._parent.meta.service_name,\n                self._py_operation_name,\n                params,\n            )\n            paginator = client.get_paginator(self._py_operation_name)\n            pages = paginator.paginate(\n                PaginationConfig={'MaxItems': limit, 'PageSize': page_size},\n                **params,\n            )\n        else:\n            logger.debug(\n                'Calling %s:%s with %r',\n                self._parent.meta.service_name,\n                self._py_operation_name,\n                params,\n            )\n            pages = [getattr(client, self._py_operation_name)(**params)]\n\n        # Now that we have a page iterator or single page of results\n        # we start processing and yielding individual items.\n        count = 0\n        for page in pages:\n            page_items = []\n            for item in self._handler(self._parent, params, page):\n                page_items.append(item)\n\n                # If the limit is set and has been reached, then\n                # we stop processing items here.\n                count += 1\n                if limit is not None and count >= limit:\n                    break\n\n            yield page_items\n\n            # Stop reading pages if we've reached out limit\n            if limit is not None and count >= limit:\n                break\n\n    def all(self):\n        \"\"\"\n        Get all items from the collection, optionally with a custom\n        page size and item count limit.\n\n        This method returns an iterable generator which yields\n        individual resource instances. Example use::\n\n            # Iterate through items\n            >>> for queue in sqs.queues.all():\n            ...     print(queue.url)\n            'https://url1'\n            'https://url2'\n\n            # Convert to list\n            >>> queues = list(sqs.queues.all())\n            >>> len(queues)\n            2\n        \"\"\"\n        return self._clone()\n\n    def filter(self, **kwargs):\n        \"\"\"\n        Get items from the collection, passing keyword arguments along\n        as parameters to the underlying service operation, which are\n        typically used to filter the results.\n\n        This method returns an iterable generator which yields\n        individual resource instances. Example use::\n\n            # Iterate through items\n            >>> for queue in sqs.queues.filter(Param='foo'):\n            ...     print(queue.url)\n            'https://url1'\n            'https://url2'\n\n            # Convert to list\n            >>> queues = list(sqs.queues.filter(Param='foo'))\n            >>> len(queues)\n            2\n\n        :rtype: :py:class:`ResourceCollection`\n        \"\"\"\n        return self._clone(**kwargs)\n\n    def limit(self, count):\n        \"\"\"\n        Return at most this many resources.\n\n            >>> for bucket in s3.buckets.limit(5):\n            ...     print(bucket.name)\n            'bucket1'\n            'bucket2'\n            'bucket3'\n            'bucket4'\n            'bucket5'\n\n        :type count: int\n        :param count: Return no more than this many items\n        :rtype: :py:class:`ResourceCollection`\n        \"\"\"\n        return self._clone(limit=count)\n\n    def page_size(self, count):\n        \"\"\"\n        Fetch at most this many resources per service request.\n\n            >>> for obj in s3.Bucket('boto3').objects.page_size(100):\n            ...     print(obj.key)\n\n        :type count: int\n        :param count: Fetch this many items per request\n        :rtype: :py:class:`ResourceCollection`\n        \"\"\"\n        return self._clone(page_size=count)\n\n\nclass CollectionManager:\n    \"\"\"\n    A collection manager provides access to resource collection instances,\n    which can be iterated and filtered. The manager exposes some\n    convenience functions that are also found on resource collections,\n    such as :py:meth:`~ResourceCollection.all` and\n    :py:meth:`~ResourceCollection.filter`.\n\n    Get all items::\n\n        >>> for bucket in s3.buckets.all():\n        ...     print(bucket.name)\n\n    Get only some items via filtering::\n\n        >>> for queue in sqs.queues.filter(QueueNamePrefix='AWS'):\n        ...     print(queue.url)\n\n    Get whole pages of items:\n\n        >>> for page in s3.Bucket('boto3').objects.pages():\n        ...     for obj in page:\n        ...         print(obj.key)\n\n    A collection manager is not iterable. You **must** call one of the\n    methods that return a :py:class:`ResourceCollection` before trying\n    to iterate, slice, or convert to a list.\n\n    See the :ref:`guide_collections` guide for a high-level overview\n    of collections, including when remote service requests are performed.\n\n    :type collection_model: :py:class:`~boto3.resources.model.Collection`\n    :param model: Collection model\n\n    :type parent: :py:class:`~boto3.resources.base.ServiceResource`\n    :param parent: The collection's parent resource\n\n    :type factory: :py:class:`~boto3.resources.factory.ResourceFactory`\n    :param factory: The resource factory to create new resources\n\n    :type service_context: :py:class:`~boto3.utils.ServiceContext`\n    :param service_context: Context about the AWS service\n    \"\"\"\n\n    # The class to use when creating an iterator\n    _collection_cls = ResourceCollection\n\n    def __init__(self, collection_model, parent, factory, service_context):\n        self._model = collection_model\n        operation_name = self._model.request.operation\n        self._parent = parent\n\n        search_path = collection_model.resource.path\n        self._handler = ResourceHandler(\n            search_path=search_path,\n            factory=factory,\n            resource_model=collection_model.resource,\n            service_context=service_context,\n            operation_name=operation_name,\n        )\n\n    def __repr__(self):\n        return '{}({}, {})'.format(\n            self.__class__.__name__,\n            self._parent,\n            f'{self._parent.meta.service_name}.{self._model.resource.type}',\n        )\n\n    def iterator(self, **kwargs):\n        \"\"\"\n        Get a resource collection iterator from this manager.\n\n        :rtype: :py:class:`ResourceCollection`\n        :return: An iterable representing the collection of resources\n        \"\"\"\n        return self._collection_cls(\n            self._model, self._parent, self._handler, **kwargs\n        )\n\n    # Set up some methods to proxy ResourceCollection methods\n    def all(self):\n        return self.iterator()\n\n    all.__doc__ = ResourceCollection.all.__doc__\n\n    def filter(self, **kwargs):\n        return self.iterator(**kwargs)\n\n    filter.__doc__ = ResourceCollection.filter.__doc__\n\n    def limit(self, count):\n        return self.iterator(limit=count)\n\n    limit.__doc__ = ResourceCollection.limit.__doc__\n\n    def page_size(self, count):\n        return self.iterator(page_size=count)\n\n    page_size.__doc__ = ResourceCollection.page_size.__doc__\n\n    def pages(self):\n        return self.iterator().pages()\n\n    pages.__doc__ = ResourceCollection.pages.__doc__\n\n\nclass CollectionFactory:\n    \"\"\"\n    A factory to create new\n    :py:class:`CollectionManager` and :py:class:`ResourceCollection`\n    subclasses from a :py:class:`~boto3.resources.model.Collection`\n    model. These subclasses include methods to perform batch operations.\n    \"\"\"\n\n    def load_from_definition(\n        self, resource_name, collection_model, service_context, event_emitter\n    ):\n        \"\"\"\n        Loads a collection from a model, creating a new\n        :py:class:`CollectionManager` subclass\n        with the correct properties and methods, named based on the service\n        and resource name, e.g. ec2.InstanceCollectionManager. It also\n        creates a new :py:class:`ResourceCollection` subclass which is used\n        by the new manager class.\n\n        :type resource_name: string\n        :param resource_name: Name of the resource to look up. For services,\n                              this should match the ``service_name``.\n\n        :type service_context: :py:class:`~boto3.utils.ServiceContext`\n        :param service_context: Context about the AWS service\n\n        :type event_emitter: :py:class:`~botocore.hooks.HierarchialEmitter`\n        :param event_emitter: An event emitter\n\n        :rtype: Subclass of :py:class:`CollectionManager`\n        :return: The collection class.\n        \"\"\"\n        attrs = {}\n        collection_name = collection_model.name\n\n        # Create the batch actions for a collection\n        self._load_batch_actions(\n            attrs,\n            resource_name,\n            collection_model,\n            service_context.service_model,\n            event_emitter,\n        )\n        # Add the documentation to the collection class's methods\n        self._load_documented_collection_methods(\n            attrs=attrs,\n            resource_name=resource_name,\n            collection_model=collection_model,\n            service_model=service_context.service_model,\n            event_emitter=event_emitter,\n            base_class=ResourceCollection,\n        )\n\n        if service_context.service_name == resource_name:\n            cls_name = (\n                f'{service_context.service_name}.{collection_name}Collection'\n            )\n        else:\n            cls_name = f'{service_context.service_name}.{resource_name}.{collection_name}Collection'\n\n        collection_cls = type(str(cls_name), (ResourceCollection,), attrs)\n\n        # Add the documentation to the collection manager's methods\n        self._load_documented_collection_methods(\n            attrs=attrs,\n            resource_name=resource_name,\n            collection_model=collection_model,\n            service_model=service_context.service_model,\n            event_emitter=event_emitter,\n            base_class=CollectionManager,\n        )\n        attrs['_collection_cls'] = collection_cls\n        cls_name += 'Manager'\n\n        return type(str(cls_name), (CollectionManager,), attrs)\n\n    def _load_batch_actions(\n        self,\n        attrs,\n        resource_name,\n        collection_model,\n        service_model,\n        event_emitter,\n    ):\n        \"\"\"\n        Batch actions on the collection become methods on both\n        the collection manager and iterators.\n        \"\"\"\n        for action_model in collection_model.batch_actions:\n            snake_cased = xform_name(action_model.name)\n            attrs[snake_cased] = self._create_batch_action(\n                resource_name,\n                snake_cased,\n                action_model,\n                collection_model,\n                service_model,\n                event_emitter,\n            )\n\n    def _load_documented_collection_methods(\n        factory_self,\n        attrs,\n        resource_name,\n        collection_model,\n        service_model,\n        event_emitter,\n        base_class,\n    ):\n        # The base class already has these methods defined. However\n        # the docstrings are generic and not based for a particular service\n        # or resource. So we override these methods by proxying to the\n        # base class's builtin method and adding a docstring\n        # that pertains to the resource.\n\n        # A collection's all() method.\n        def all(self):\n            return base_class.all(self)\n\n        all.__doc__ = docstring.CollectionMethodDocstring(\n            resource_name=resource_name,\n            action_name='all',\n            event_emitter=event_emitter,\n            collection_model=collection_model,\n            service_model=service_model,\n            include_signature=False,\n        )\n        attrs['all'] = all\n\n        # The collection's filter() method.\n        def filter(self, **kwargs):\n            return base_class.filter(self, **kwargs)\n\n        filter.__doc__ = docstring.CollectionMethodDocstring(\n            resource_name=resource_name,\n            action_name='filter',\n            event_emitter=event_emitter,\n            collection_model=collection_model,\n            service_model=service_model,\n            include_signature=False,\n        )\n        attrs['filter'] = filter\n\n        # The collection's limit method.\n        def limit(self, count):\n            return base_class.limit(self, count)\n\n        limit.__doc__ = docstring.CollectionMethodDocstring(\n            resource_name=resource_name,\n            action_name='limit',\n            event_emitter=event_emitter,\n            collection_model=collection_model,\n            service_model=service_model,\n            include_signature=False,\n        )\n        attrs['limit'] = limit\n\n        # The collection's page_size method.\n        def page_size(self, count):\n            return base_class.page_size(self, count)\n\n        page_size.__doc__ = docstring.CollectionMethodDocstring(\n            resource_name=resource_name,\n            action_name='page_size',\n            event_emitter=event_emitter,\n            collection_model=collection_model,\n            service_model=service_model,\n            include_signature=False,\n        )\n        attrs['page_size'] = page_size\n\n    def _create_batch_action(\n        factory_self,\n        resource_name,\n        snake_cased,\n        action_model,\n        collection_model,\n        service_model,\n        event_emitter,\n    ):\n        \"\"\"\n        Creates a new method which makes a batch operation request\n        to the underlying service API.\n        \"\"\"\n        action = BatchAction(action_model)\n\n        def batch_action(self, *args, **kwargs):\n            return action(self, *args, **kwargs)\n\n        batch_action.__name__ = str(snake_cased)\n        batch_action.__doc__ = docstring.BatchActionDocstring(\n            resource_name=resource_name,\n            event_emitter=event_emitter,\n            batch_action_model=action_model,\n            service_model=service_model,\n            collection_model=collection_model,\n            include_signature=False,\n        )\n        return batch_action\n", "boto3/resources/__init__.py": "", "boto3/dynamodb/table.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport logging\n\nlogger = logging.getLogger(__name__)\n\n\ndef register_table_methods(base_classes, **kwargs):\n    base_classes.insert(0, TableResource)\n\n\n# This class can be used to add any additional methods we want\n# onto a table resource.  Ideally to avoid creating a new\n# base class for every method we can just update this\n# class instead.  Just be sure to move the bulk of the\n# actual method implementation to another class.\nclass TableResource:\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n    def batch_writer(self, overwrite_by_pkeys=None):\n        \"\"\"Create a batch writer object.\n\n        This method creates a context manager for writing\n        objects to Amazon DynamoDB in batch.\n\n        The batch writer will automatically handle buffering and sending items\n        in batches.  In addition, the batch writer will also automatically\n        handle any unprocessed items and resend them as needed.  All you need\n        to do is call ``put_item`` for any items you want to add, and\n        ``delete_item`` for any items you want to delete.\n\n        Example usage::\n\n            with table.batch_writer() as batch:\n                for _ in range(1000000):\n                    batch.put_item(Item={'HashKey': '...',\n                                         'Otherstuff': '...'})\n                # You can also delete_items in a batch.\n                batch.delete_item(Key={'HashKey': 'SomeHashKey'})\n\n        :type overwrite_by_pkeys: list(string)\n        :param overwrite_by_pkeys: De-duplicate request items in buffer\n            if match new request item on specified primary keys. i.e\n            ``[\"partition_key1\", \"sort_key2\", \"sort_key3\"]``\n\n        \"\"\"\n        return BatchWriter(\n            self.name, self.meta.client, overwrite_by_pkeys=overwrite_by_pkeys\n        )\n\n\nclass BatchWriter:\n    \"\"\"Automatically handle batch writes to DynamoDB for a single table.\"\"\"\n\n    def __init__(\n        self, table_name, client, flush_amount=25, overwrite_by_pkeys=None\n    ):\n        \"\"\"\n\n        :type table_name: str\n        :param table_name: The name of the table.  The class handles\n            batch writes to a single table.\n\n        :type client: ``botocore.client.Client``\n        :param client: A botocore client.  Note this client\n            **must** have the dynamodb customizations applied\n            to it for transforming AttributeValues into the\n            wire protocol.  What this means in practice is that\n            you need to use a client that comes from a DynamoDB\n            resource if you're going to instantiate this class\n            directly, i.e\n            ``boto3.resource('dynamodb').Table('foo').meta.client``.\n\n        :type flush_amount: int\n        :param flush_amount: The number of items to keep in\n            a local buffer before sending a batch_write_item\n            request to DynamoDB.\n\n        :type overwrite_by_pkeys: list(string)\n        :param overwrite_by_pkeys: De-duplicate request items in buffer\n            if match new request item on specified primary keys. i.e\n            ``[\"partition_key1\", \"sort_key2\", \"sort_key3\"]``\n\n        \"\"\"\n        self._table_name = table_name\n        self._client = client\n        self._items_buffer = []\n        self._flush_amount = flush_amount\n        self._overwrite_by_pkeys = overwrite_by_pkeys\n\n    def put_item(self, Item):\n        self._add_request_and_process({'PutRequest': {'Item': Item}})\n\n    def delete_item(self, Key):\n        self._add_request_and_process({'DeleteRequest': {'Key': Key}})\n\n    def _add_request_and_process(self, request):\n        if self._overwrite_by_pkeys:\n            self._remove_dup_pkeys_request_if_any(request)\n        self._items_buffer.append(request)\n        self._flush_if_needed()\n\n    def _remove_dup_pkeys_request_if_any(self, request):\n        pkey_values_new = self._extract_pkey_values(request)\n        for item in self._items_buffer:\n            if self._extract_pkey_values(item) == pkey_values_new:\n                self._items_buffer.remove(item)\n                logger.debug(\n                    \"With overwrite_by_pkeys enabled, skipping \" \"request:%s\",\n                    item,\n                )\n\n    def _extract_pkey_values(self, request):\n        if request.get('PutRequest'):\n            return [\n                request['PutRequest']['Item'][key]\n                for key in self._overwrite_by_pkeys\n            ]\n        elif request.get('DeleteRequest'):\n            return [\n                request['DeleteRequest']['Key'][key]\n                for key in self._overwrite_by_pkeys\n            ]\n        return None\n\n    def _flush_if_needed(self):\n        if len(self._items_buffer) >= self._flush_amount:\n            self._flush()\n\n    def _flush(self):\n        items_to_send = self._items_buffer[: self._flush_amount]\n        self._items_buffer = self._items_buffer[self._flush_amount :]\n        response = self._client.batch_write_item(\n            RequestItems={self._table_name: items_to_send}\n        )\n        unprocessed_items = response['UnprocessedItems']\n        if not unprocessed_items:\n            unprocessed_items = {}\n        item_list = unprocessed_items.get(self._table_name, [])\n        # Any unprocessed_items are immediately added to the\n        # next batch we send.\n        self._items_buffer.extend(item_list)\n        logger.debug(\n            \"Batch write sent %s, unprocessed: %s\",\n            len(items_to_send),\n            len(self._items_buffer),\n        )\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_value, tb):\n        # When we exit, we need to keep flushing whatever's left\n        # until there's nothing left in our items buffer.\n        while self._items_buffer:\n            self._flush()\n", "boto3/dynamodb/types.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom decimal import (\n    Clamped,\n    Context,\n    Decimal,\n    Inexact,\n    Overflow,\n    Rounded,\n    Underflow,\n)\n\nfrom boto3.compat import collections_abc\n\nSTRING = 'S'\nNUMBER = 'N'\nBINARY = 'B'\nSTRING_SET = 'SS'\nNUMBER_SET = 'NS'\nBINARY_SET = 'BS'\nNULL = 'NULL'\nBOOLEAN = 'BOOL'\nMAP = 'M'\nLIST = 'L'\n\n\nDYNAMODB_CONTEXT = Context(\n    Emin=-128,\n    Emax=126,\n    prec=38,\n    traps=[Clamped, Overflow, Inexact, Rounded, Underflow],\n)\n\n\nBINARY_TYPES = (bytearray, bytes)\n\n\nclass Binary:\n    \"\"\"A class for representing Binary in dynamodb\n\n    Especially for Python 2, use this class to explicitly specify\n    binary data for item in DynamoDB. It is essentially a wrapper around\n    binary. Unicode and Python 3 string types are not allowed.\n    \"\"\"\n\n    def __init__(self, value):\n        if not isinstance(value, BINARY_TYPES):\n            types = ', '.join([str(t) for t in BINARY_TYPES])\n            raise TypeError(f'Value must be of the following types: {types}')\n        self.value = value\n\n    def __eq__(self, other):\n        if isinstance(other, Binary):\n            return self.value == other.value\n        return self.value == other\n\n    def __ne__(self, other):\n        return not self.__eq__(other)\n\n    def __repr__(self):\n        return f'Binary({self.value!r})'\n\n    def __str__(self):\n        return self.value\n\n    def __bytes__(self):\n        return self.value\n\n    def __hash__(self):\n        return hash(self.value)\n\n\nclass TypeSerializer:\n    \"\"\"This class serializes Python data types to DynamoDB types.\"\"\"\n\n    def serialize(self, value):\n        \"\"\"The method to serialize the Python data types.\n\n        :param value: A python value to be serialized to DynamoDB. Here are\n            the various conversions:\n\n            Python                                  DynamoDB\n            ------                                  --------\n            None                                    {'NULL': True}\n            True/False                              {'BOOL': True/False}\n            int/Decimal                             {'N': str(value)}\n            string                                  {'S': string}\n            Binary/bytearray/bytes (py3 only)       {'B': bytes}\n            set([int/Decimal])                      {'NS': [str(value)]}\n            set([string])                           {'SS': [string])\n            set([Binary/bytearray/bytes])           {'BS': [bytes]}\n            list                                    {'L': list}\n            dict                                    {'M': dict}\n\n            For types that involve numbers, it is recommended that ``Decimal``\n            objects are used to be able to round-trip the Python type.\n            For types that involve binary, it is recommended that ``Binary``\n            objects are used to be able to round-trip the Python type.\n\n        :rtype: dict\n        :returns: A dictionary that represents a dynamoDB data type. These\n            dictionaries can be directly passed to botocore methods.\n        \"\"\"\n        dynamodb_type = self._get_dynamodb_type(value)\n        serializer = getattr(self, f'_serialize_{dynamodb_type}'.lower())\n        return {dynamodb_type: serializer(value)}\n\n    def _get_dynamodb_type(self, value):\n        dynamodb_type = None\n\n        if self._is_null(value):\n            dynamodb_type = NULL\n\n        elif self._is_boolean(value):\n            dynamodb_type = BOOLEAN\n\n        elif self._is_number(value):\n            dynamodb_type = NUMBER\n\n        elif self._is_string(value):\n            dynamodb_type = STRING\n\n        elif self._is_binary(value):\n            dynamodb_type = BINARY\n\n        elif self._is_type_set(value, self._is_number):\n            dynamodb_type = NUMBER_SET\n\n        elif self._is_type_set(value, self._is_string):\n            dynamodb_type = STRING_SET\n\n        elif self._is_type_set(value, self._is_binary):\n            dynamodb_type = BINARY_SET\n\n        elif self._is_map(value):\n            dynamodb_type = MAP\n\n        elif self._is_listlike(value):\n            dynamodb_type = LIST\n\n        else:\n            msg = f'Unsupported type \"{type(value)}\" for value \"{value}\"'\n            raise TypeError(msg)\n\n        return dynamodb_type\n\n    def _is_null(self, value):\n        if value is None:\n            return True\n        return False\n\n    def _is_boolean(self, value):\n        if isinstance(value, bool):\n            return True\n        return False\n\n    def _is_number(self, value):\n        if isinstance(value, (int, Decimal)):\n            return True\n        elif isinstance(value, float):\n            raise TypeError(\n                'Float types are not supported. Use Decimal types instead.'\n            )\n        return False\n\n    def _is_string(self, value):\n        if isinstance(value, str):\n            return True\n        return False\n\n    def _is_binary(self, value):\n        if isinstance(value, (Binary, bytearray, bytes)):\n            return True\n        return False\n\n    def _is_set(self, value):\n        if isinstance(value, collections_abc.Set):\n            return True\n        return False\n\n    def _is_type_set(self, value, type_validator):\n        if self._is_set(value):\n            if False not in map(type_validator, value):\n                return True\n        return False\n\n    def _is_map(self, value):\n        if isinstance(value, collections_abc.Mapping):\n            return True\n        return False\n\n    def _is_listlike(self, value):\n        if isinstance(value, (list, tuple)):\n            return True\n        return False\n\n    def _serialize_null(self, value):\n        return True\n\n    def _serialize_bool(self, value):\n        return value\n\n    def _serialize_n(self, value):\n        number = str(DYNAMODB_CONTEXT.create_decimal(value))\n        if number in ['Infinity', 'NaN']:\n            raise TypeError('Infinity and NaN not supported')\n        return number\n\n    def _serialize_s(self, value):\n        return value\n\n    def _serialize_b(self, value):\n        if isinstance(value, Binary):\n            value = value.value\n        return value\n\n    def _serialize_ss(self, value):\n        return [self._serialize_s(s) for s in value]\n\n    def _serialize_ns(self, value):\n        return [self._serialize_n(n) for n in value]\n\n    def _serialize_bs(self, value):\n        return [self._serialize_b(b) for b in value]\n\n    def _serialize_l(self, value):\n        return [self.serialize(v) for v in value]\n\n    def _serialize_m(self, value):\n        return {k: self.serialize(v) for k, v in value.items()}\n\n\nclass TypeDeserializer:\n    \"\"\"This class deserializes DynamoDB types to Python types.\"\"\"\n\n    def deserialize(self, value):\n        \"\"\"The method to deserialize the DynamoDB data types.\n\n        :param value: A DynamoDB value to be deserialized to a pythonic value.\n            Here are the various conversions:\n\n            DynamoDB                                Python\n            --------                                ------\n            {'NULL': True}                          None\n            {'BOOL': True/False}                    True/False\n            {'N': str(value)}                       Decimal(str(value))\n            {'S': string}                           string\n            {'B': bytes}                            Binary(bytes)\n            {'NS': [str(value)]}                    set([Decimal(str(value))])\n            {'SS': [string]}                        set([string])\n            {'BS': [bytes]}                         set([bytes])\n            {'L': list}                             list\n            {'M': dict}                             dict\n\n        :returns: The pythonic value of the DynamoDB type.\n        \"\"\"\n\n        if not value:\n            raise TypeError(\n                'Value must be a nonempty dictionary whose key '\n                'is a valid dynamodb type.'\n            )\n        dynamodb_type = list(value.keys())[0]\n        try:\n            deserializer = getattr(\n                self, f'_deserialize_{dynamodb_type}'.lower()\n            )\n        except AttributeError:\n            raise TypeError(f'Dynamodb type {dynamodb_type} is not supported')\n        return deserializer(value[dynamodb_type])\n\n    def _deserialize_null(self, value):\n        return None\n\n    def _deserialize_bool(self, value):\n        return value\n\n    def _deserialize_n(self, value):\n        return DYNAMODB_CONTEXT.create_decimal(value)\n\n    def _deserialize_s(self, value):\n        return value\n\n    def _deserialize_b(self, value):\n        return Binary(value)\n\n    def _deserialize_ns(self, value):\n        return set(map(self._deserialize_n, value))\n\n    def _deserialize_ss(self, value):\n        return set(map(self._deserialize_s, value))\n\n    def _deserialize_bs(self, value):\n        return set(map(self._deserialize_b, value))\n\n    def _deserialize_l(self, value):\n        return [self.deserialize(v) for v in value]\n\n    def _deserialize_m(self, value):\n        return {k: self.deserialize(v) for k, v in value.items()}\n", "boto3/dynamodb/conditions.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport re\nfrom collections import namedtuple\n\nfrom boto3.exceptions import (\n    DynamoDBNeedsConditionError,\n    DynamoDBNeedsKeyConditionError,\n    DynamoDBOperationNotSupportedError,\n)\n\nATTR_NAME_REGEX = re.compile(r'[^.\\[\\]]+(?![^\\[]*\\])')\n\n\nclass ConditionBase:\n    expression_format = ''\n    expression_operator = ''\n    has_grouped_values = False\n\n    def __init__(self, *values):\n        self._values = values\n\n    def __and__(self, other):\n        if not isinstance(other, ConditionBase):\n            raise DynamoDBOperationNotSupportedError('AND', other)\n        return And(self, other)\n\n    def __or__(self, other):\n        if not isinstance(other, ConditionBase):\n            raise DynamoDBOperationNotSupportedError('OR', other)\n        return Or(self, other)\n\n    def __invert__(self):\n        return Not(self)\n\n    def get_expression(self):\n        return {\n            'format': self.expression_format,\n            'operator': self.expression_operator,\n            'values': self._values,\n        }\n\n    def __eq__(self, other):\n        if isinstance(other, type(self)):\n            if self._values == other._values:\n                return True\n        return False\n\n    def __ne__(self, other):\n        return not self.__eq__(other)\n\n\nclass AttributeBase:\n    def __init__(self, name):\n        self.name = name\n\n    def __and__(self, value):\n        raise DynamoDBOperationNotSupportedError('AND', self)\n\n    def __or__(self, value):\n        raise DynamoDBOperationNotSupportedError('OR', self)\n\n    def __invert__(self):\n        raise DynamoDBOperationNotSupportedError('NOT', self)\n\n    def eq(self, value):\n        \"\"\"Creates a condition where the attribute is equal to the value.\n\n        :param value: The value that the attribute is equal to.\n        \"\"\"\n        return Equals(self, value)\n\n    def lt(self, value):\n        \"\"\"Creates a condition where the attribute is less than the value.\n\n        :param value: The value that the attribute is less than.\n        \"\"\"\n        return LessThan(self, value)\n\n    def lte(self, value):\n        \"\"\"Creates a condition where the attribute is less than or equal to the\n           value.\n\n        :param value: The value that the attribute is less than or equal to.\n        \"\"\"\n        return LessThanEquals(self, value)\n\n    def gt(self, value):\n        \"\"\"Creates a condition where the attribute is greater than the value.\n\n        :param value: The value that the attribute is greater than.\n        \"\"\"\n        return GreaterThan(self, value)\n\n    def gte(self, value):\n        \"\"\"Creates a condition where the attribute is greater than or equal to\n           the value.\n\n        :param value: The value that the attribute is greater than or equal to.\n        \"\"\"\n        return GreaterThanEquals(self, value)\n\n    def begins_with(self, value):\n        \"\"\"Creates a condition where the attribute begins with the value.\n\n        :param value: The value that the attribute begins with.\n        \"\"\"\n        return BeginsWith(self, value)\n\n    def between(self, low_value, high_value):\n        \"\"\"Creates a condition where the attribute is greater than or equal\n        to the low value and less than or equal to the high value.\n\n        :param low_value: The value that the attribute is greater than or equal to.\n        :param high_value: The value that the attribute is less than or equal to.\n        \"\"\"\n        return Between(self, low_value, high_value)\n\n    def __eq__(self, other):\n        return isinstance(other, type(self)) and self.name == other.name\n\n    def __ne__(self, other):\n        return not self.__eq__(other)\n\n\nclass ConditionAttributeBase(ConditionBase, AttributeBase):\n    \"\"\"This base class is for conditions that can have attribute methods.\n\n    One example is the Size condition. To complete a condition, you need\n    to apply another AttributeBase method like eq().\n    \"\"\"\n\n    def __init__(self, *values):\n        ConditionBase.__init__(self, *values)\n        # This is assuming the first value to the condition is the attribute\n        # in which can be used to generate its attribute base.\n        AttributeBase.__init__(self, values[0].name)\n\n    def __eq__(self, other):\n        return ConditionBase.__eq__(self, other) and AttributeBase.__eq__(\n            self, other\n        )\n\n    def __ne__(self, other):\n        return not self.__eq__(other)\n\n\nclass ComparisonCondition(ConditionBase):\n    expression_format = '{0} {operator} {1}'\n\n\nclass Equals(ComparisonCondition):\n    expression_operator = '='\n\n\nclass NotEquals(ComparisonCondition):\n    expression_operator = '<>'\n\n\nclass LessThan(ComparisonCondition):\n    expression_operator = '<'\n\n\nclass LessThanEquals(ComparisonCondition):\n    expression_operator = '<='\n\n\nclass GreaterThan(ComparisonCondition):\n    expression_operator = '>'\n\n\nclass GreaterThanEquals(ComparisonCondition):\n    expression_operator = '>='\n\n\nclass In(ComparisonCondition):\n    expression_operator = 'IN'\n    has_grouped_values = True\n\n\nclass Between(ConditionBase):\n    expression_operator = 'BETWEEN'\n    expression_format = '{0} {operator} {1} AND {2}'\n\n\nclass BeginsWith(ConditionBase):\n    expression_operator = 'begins_with'\n    expression_format = '{operator}({0}, {1})'\n\n\nclass Contains(ConditionBase):\n    expression_operator = 'contains'\n    expression_format = '{operator}({0}, {1})'\n\n\nclass Size(ConditionAttributeBase):\n    expression_operator = 'size'\n    expression_format = '{operator}({0})'\n\n\nclass AttributeType(ConditionBase):\n    expression_operator = 'attribute_type'\n    expression_format = '{operator}({0}, {1})'\n\n\nclass AttributeExists(ConditionBase):\n    expression_operator = 'attribute_exists'\n    expression_format = '{operator}({0})'\n\n\nclass AttributeNotExists(ConditionBase):\n    expression_operator = 'attribute_not_exists'\n    expression_format = '{operator}({0})'\n\n\nclass And(ConditionBase):\n    expression_operator = 'AND'\n    expression_format = '({0} {operator} {1})'\n\n\nclass Or(ConditionBase):\n    expression_operator = 'OR'\n    expression_format = '({0} {operator} {1})'\n\n\nclass Not(ConditionBase):\n    expression_operator = 'NOT'\n    expression_format = '({operator} {0})'\n\n\nclass Key(AttributeBase):\n    pass\n\n\nclass Attr(AttributeBase):\n    \"\"\"Represents an DynamoDB item's attribute.\"\"\"\n\n    def ne(self, value):\n        \"\"\"Creates a condition where the attribute is not equal to the value\n\n        :param value: The value that the attribute is not equal to.\n        \"\"\"\n        return NotEquals(self, value)\n\n    def is_in(self, value):\n        \"\"\"Creates a condition where the attribute is in the value,\n\n        :type value: list\n        :param value: The value that the attribute is in.\n        \"\"\"\n        return In(self, value)\n\n    def exists(self):\n        \"\"\"Creates a condition where the attribute exists.\"\"\"\n        return AttributeExists(self)\n\n    def not_exists(self):\n        \"\"\"Creates a condition where the attribute does not exist.\"\"\"\n        return AttributeNotExists(self)\n\n    def contains(self, value):\n        \"\"\"Creates a condition where the attribute contains the value.\n\n        :param value: The value the attribute contains.\n        \"\"\"\n        return Contains(self, value)\n\n    def size(self):\n        \"\"\"Creates a condition for the attribute size.\n\n        Note another AttributeBase method must be called on the returned\n        size condition to be a valid DynamoDB condition.\n        \"\"\"\n        return Size(self)\n\n    def attribute_type(self, value):\n        \"\"\"Creates a condition for the attribute type.\n\n        :param value: The type of the attribute.\n        \"\"\"\n        return AttributeType(self, value)\n\n\nBuiltConditionExpression = namedtuple(\n    'BuiltConditionExpression',\n    [\n        'condition_expression',\n        'attribute_name_placeholders',\n        'attribute_value_placeholders',\n    ],\n)\n\n\nclass ConditionExpressionBuilder:\n    \"\"\"This class is used to build condition expressions with placeholders\"\"\"\n\n    def __init__(self):\n        self._name_count = 0\n        self._value_count = 0\n        self._name_placeholder = 'n'\n        self._value_placeholder = 'v'\n\n    def _get_name_placeholder(self):\n        return '#' + self._name_placeholder + str(self._name_count)\n\n    def _get_value_placeholder(self):\n        return ':' + self._value_placeholder + str(self._value_count)\n\n    def reset(self):\n        \"\"\"Resets the placeholder name and values\"\"\"\n        self._name_count = 0\n        self._value_count = 0\n\n    def build_expression(self, condition, is_key_condition=False):\n        \"\"\"Builds the condition expression and the dictionary of placeholders.\n\n        :type condition: ConditionBase\n        :param condition: A condition to be built into a condition expression\n            string with any necessary placeholders.\n\n        :type is_key_condition: Boolean\n        :param is_key_condition: True if the expression is for a\n            KeyConditionExpression. False otherwise.\n\n        :rtype: (string, dict, dict)\n        :returns: Will return a string representing the condition with\n            placeholders inserted where necessary, a dictionary of\n            placeholders for attribute names, and a dictionary of\n            placeholders for attribute values. Here is a sample return value:\n\n            ('#n0 = :v0', {'#n0': 'myattribute'}, {':v1': 'myvalue'})\n        \"\"\"\n        if not isinstance(condition, ConditionBase):\n            raise DynamoDBNeedsConditionError(condition)\n        attribute_name_placeholders = {}\n        attribute_value_placeholders = {}\n        condition_expression = self._build_expression(\n            condition,\n            attribute_name_placeholders,\n            attribute_value_placeholders,\n            is_key_condition=is_key_condition,\n        )\n        return BuiltConditionExpression(\n            condition_expression=condition_expression,\n            attribute_name_placeholders=attribute_name_placeholders,\n            attribute_value_placeholders=attribute_value_placeholders,\n        )\n\n    def _build_expression(\n        self,\n        condition,\n        attribute_name_placeholders,\n        attribute_value_placeholders,\n        is_key_condition,\n    ):\n        expression_dict = condition.get_expression()\n        replaced_values = []\n        for value in expression_dict['values']:\n            # Build the necessary placeholders for that value.\n            # Placeholders are built for both attribute names and values.\n            replaced_value = self._build_expression_component(\n                value,\n                attribute_name_placeholders,\n                attribute_value_placeholders,\n                condition.has_grouped_values,\n                is_key_condition,\n            )\n            replaced_values.append(replaced_value)\n        # Fill out the expression using the operator and the\n        # values that have been replaced with placeholders.\n        return expression_dict['format'].format(\n            *replaced_values, operator=expression_dict['operator']\n        )\n\n    def _build_expression_component(\n        self,\n        value,\n        attribute_name_placeholders,\n        attribute_value_placeholders,\n        has_grouped_values,\n        is_key_condition,\n    ):\n        # Continue to recurse if the value is a ConditionBase in order\n        # to extract out all parts of the expression.\n        if isinstance(value, ConditionBase):\n            return self._build_expression(\n                value,\n                attribute_name_placeholders,\n                attribute_value_placeholders,\n                is_key_condition,\n            )\n        # If it is not a ConditionBase, we can recurse no further.\n        # So we check if it is an attribute and add placeholders for\n        # its name\n        elif isinstance(value, AttributeBase):\n            if is_key_condition and not isinstance(value, Key):\n                raise DynamoDBNeedsKeyConditionError(\n                    f'Attribute object {value.name} is of type {type(value)}. '\n                    f'KeyConditionExpression only supports Attribute objects '\n                    f'of type Key'\n                )\n            return self._build_name_placeholder(\n                value, attribute_name_placeholders\n            )\n        # If it is anything else, we treat it as a value and thus placeholders\n        # are needed for the value.\n        else:\n            return self._build_value_placeholder(\n                value, attribute_value_placeholders, has_grouped_values\n            )\n\n    def _build_name_placeholder(self, value, attribute_name_placeholders):\n        attribute_name = value.name\n        # Figure out which parts of the attribute name that needs replacement.\n        attribute_name_parts = ATTR_NAME_REGEX.findall(attribute_name)\n\n        # Add a temporary placeholder for each of these parts.\n        placeholder_format = ATTR_NAME_REGEX.sub('%s', attribute_name)\n        str_format_args = []\n        for part in attribute_name_parts:\n            name_placeholder = self._get_name_placeholder()\n            self._name_count += 1\n            str_format_args.append(name_placeholder)\n            # Add the placeholder and value to dictionary of name placeholders.\n            attribute_name_placeholders[name_placeholder] = part\n        # Replace the temporary placeholders with the designated placeholders.\n        return placeholder_format % tuple(str_format_args)\n\n    def _build_value_placeholder(\n        self, value, attribute_value_placeholders, has_grouped_values=False\n    ):\n        # If the values are grouped, we need to add a placeholder for\n        # each element inside of the actual value.\n        if has_grouped_values:\n            placeholder_list = []\n            for v in value:\n                value_placeholder = self._get_value_placeholder()\n                self._value_count += 1\n                placeholder_list.append(value_placeholder)\n                attribute_value_placeholders[value_placeholder] = v\n            # Assuming the values are grouped by parenthesis.\n            # IN is the currently the only one that uses this so it maybe\n            # needed to be changed in future.\n            return '(' + ', '.join(placeholder_list) + ')'\n        # Otherwise, treat the value as a single value that needs only\n        # one placeholder.\n        else:\n            value_placeholder = self._get_value_placeholder()\n            self._value_count += 1\n            attribute_value_placeholders[value_placeholder] = value\n            return value_placeholder\n", "boto3/dynamodb/__init__.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n", "boto3/dynamodb/transform.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport copy\n\nfrom boto3.compat import collections_abc\nfrom boto3.docs.utils import DocumentModifiedShape\nfrom boto3.dynamodb.conditions import ConditionBase, ConditionExpressionBuilder\nfrom boto3.dynamodb.types import TypeDeserializer, TypeSerializer\n\n\ndef register_high_level_interface(base_classes, **kwargs):\n    base_classes.insert(0, DynamoDBHighLevelResource)\n\n\nclass _ForgetfulDict(dict):\n    \"\"\"A dictionary that discards any items set on it. For use as `memo` in\n    `copy.deepcopy()` when every instance of a repeated object in the deepcopied\n    data structure should result in a separate copy.\n    \"\"\"\n\n    def __setitem__(self, key, value):\n        pass\n\n\ndef copy_dynamodb_params(params, **kwargs):\n    return copy.deepcopy(params, memo=_ForgetfulDict())\n\n\nclass DynamoDBHighLevelResource:\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n        # Apply handler that creates a copy of the user provided dynamodb\n        # item such that it can be modified.\n        self.meta.client.meta.events.register(\n            'provide-client-params.dynamodb',\n            copy_dynamodb_params,\n            unique_id='dynamodb-create-params-copy',\n        )\n\n        self._injector = TransformationInjector()\n        # Apply the handler that generates condition expressions including\n        # placeholders.\n        self.meta.client.meta.events.register(\n            'before-parameter-build.dynamodb',\n            self._injector.inject_condition_expressions,\n            unique_id='dynamodb-condition-expression',\n        )\n\n        # Apply the handler that serializes the request from python\n        # types to dynamodb types.\n        self.meta.client.meta.events.register(\n            'before-parameter-build.dynamodb',\n            self._injector.inject_attribute_value_input,\n            unique_id='dynamodb-attr-value-input',\n        )\n\n        # Apply the handler that deserializes the response from dynamodb\n        # types to python types.\n        self.meta.client.meta.events.register(\n            'after-call.dynamodb',\n            self._injector.inject_attribute_value_output,\n            unique_id='dynamodb-attr-value-output',\n        )\n\n        # Apply the documentation customizations to account for\n        # the transformations.\n        attr_value_shape_docs = DocumentModifiedShape(\n            'AttributeValue',\n            new_type='valid DynamoDB type',\n            new_description=(\n                '- The value of the attribute. The valid value types are '\n                'listed in the '\n                ':ref:`DynamoDB Reference Guide<ref_valid_dynamodb_types>`.'\n            ),\n            new_example_value=(\n                '\\'string\\'|123|Binary(b\\'bytes\\')|True|None|set([\\'string\\'])'\n                '|set([123])|set([Binary(b\\'bytes\\')])|[]|{}'\n            ),\n        )\n\n        key_expression_shape_docs = DocumentModifiedShape(\n            'KeyExpression',\n            new_type=(\n                'condition from :py:class:`boto3.dynamodb.conditions.Key` '\n                'method'\n            ),\n            new_description=(\n                'The condition(s) a key(s) must meet. Valid conditions are '\n                'listed in the '\n                ':ref:`DynamoDB Reference Guide<ref_dynamodb_conditions>`.'\n            ),\n            new_example_value='Key(\\'mykey\\').eq(\\'myvalue\\')',\n        )\n\n        con_expression_shape_docs = DocumentModifiedShape(\n            'ConditionExpression',\n            new_type=(\n                'condition from :py:class:`boto3.dynamodb.conditions.Attr` '\n                'method'\n            ),\n            new_description=(\n                'The condition(s) an attribute(s) must meet. Valid conditions '\n                'are listed in the '\n                ':ref:`DynamoDB Reference Guide<ref_dynamodb_conditions>`.'\n            ),\n            new_example_value='Attr(\\'myattribute\\').eq(\\'myvalue\\')',\n        )\n\n        self.meta.client.meta.events.register(\n            'docs.*.dynamodb.*.complete-section',\n            attr_value_shape_docs.replace_documentation_for_matching_shape,\n            unique_id='dynamodb-attr-value-docs',\n        )\n\n        self.meta.client.meta.events.register(\n            'docs.*.dynamodb.*.complete-section',\n            key_expression_shape_docs.replace_documentation_for_matching_shape,\n            unique_id='dynamodb-key-expression-docs',\n        )\n\n        self.meta.client.meta.events.register(\n            'docs.*.dynamodb.*.complete-section',\n            con_expression_shape_docs.replace_documentation_for_matching_shape,\n            unique_id='dynamodb-cond-expression-docs',\n        )\n\n\nclass TransformationInjector:\n    \"\"\"Injects the transformations into the user provided parameters.\"\"\"\n\n    def __init__(\n        self,\n        transformer=None,\n        condition_builder=None,\n        serializer=None,\n        deserializer=None,\n    ):\n        self._transformer = transformer\n        if transformer is None:\n            self._transformer = ParameterTransformer()\n\n        self._condition_builder = condition_builder\n        if condition_builder is None:\n            self._condition_builder = ConditionExpressionBuilder()\n\n        self._serializer = serializer\n        if serializer is None:\n            self._serializer = TypeSerializer()\n\n        self._deserializer = deserializer\n        if deserializer is None:\n            self._deserializer = TypeDeserializer()\n\n    def inject_condition_expressions(self, params, model, **kwargs):\n        \"\"\"Injects the condition expression transformation into the parameters\n\n        This injection includes transformations for ConditionExpression shapes\n        and KeyExpression shapes. It also handles any placeholder names and\n        values that are generated when transforming the condition expressions.\n        \"\"\"\n        self._condition_builder.reset()\n        generated_names = {}\n        generated_values = {}\n\n        # Create and apply the Condition Expression transformation.\n        transformation = ConditionExpressionTransformation(\n            self._condition_builder,\n            placeholder_names=generated_names,\n            placeholder_values=generated_values,\n            is_key_condition=False,\n        )\n        self._transformer.transform(\n            params, model.input_shape, transformation, 'ConditionExpression'\n        )\n\n        # Create and apply the Key Condition Expression transformation.\n        transformation = ConditionExpressionTransformation(\n            self._condition_builder,\n            placeholder_names=generated_names,\n            placeholder_values=generated_values,\n            is_key_condition=True,\n        )\n        self._transformer.transform(\n            params, model.input_shape, transformation, 'KeyExpression'\n        )\n\n        expr_attr_names_input = 'ExpressionAttributeNames'\n        expr_attr_values_input = 'ExpressionAttributeValues'\n\n        # Now that all of the condition expression transformation are done,\n        # update the placeholder dictionaries in the request.\n        if expr_attr_names_input in params:\n            params[expr_attr_names_input].update(generated_names)\n        else:\n            if generated_names:\n                params[expr_attr_names_input] = generated_names\n\n        if expr_attr_values_input in params:\n            params[expr_attr_values_input].update(generated_values)\n        else:\n            if generated_values:\n                params[expr_attr_values_input] = generated_values\n\n    def inject_attribute_value_input(self, params, model, **kwargs):\n        \"\"\"Injects DynamoDB serialization into parameter input\"\"\"\n        self._transformer.transform(\n            params,\n            model.input_shape,\n            self._serializer.serialize,\n            'AttributeValue',\n        )\n\n    def inject_attribute_value_output(self, parsed, model, **kwargs):\n        \"\"\"Injects DynamoDB deserialization into responses\"\"\"\n        if model.output_shape is not None:\n            self._transformer.transform(\n                parsed,\n                model.output_shape,\n                self._deserializer.deserialize,\n                'AttributeValue',\n            )\n\n\nclass ConditionExpressionTransformation:\n    \"\"\"Provides a transformation for condition expressions\n\n    The ``ParameterTransformer`` class can call this class directly\n    to transform the condition expressions in the parameters provided.\n    \"\"\"\n\n    def __init__(\n        self,\n        condition_builder,\n        placeholder_names,\n        placeholder_values,\n        is_key_condition=False,\n    ):\n        self._condition_builder = condition_builder\n        self._placeholder_names = placeholder_names\n        self._placeholder_values = placeholder_values\n        self._is_key_condition = is_key_condition\n\n    def __call__(self, value):\n        if isinstance(value, ConditionBase):\n            # Create a conditional expression string with placeholders\n            # for the provided condition.\n            built_expression = self._condition_builder.build_expression(\n                value, is_key_condition=self._is_key_condition\n            )\n\n            self._placeholder_names.update(\n                built_expression.attribute_name_placeholders\n            )\n            self._placeholder_values.update(\n                built_expression.attribute_value_placeholders\n            )\n\n            return built_expression.condition_expression\n        # Use the user provided value if it is not a ConditonBase object.\n        return value\n\n\nclass ParameterTransformer:\n    \"\"\"Transforms the input to and output from botocore based on shape\"\"\"\n\n    def transform(self, params, model, transformation, target_shape):\n        \"\"\"Transforms the dynamodb input to or output from botocore\n\n        It applies a specified transformation whenever a specific shape name\n        is encountered while traversing the parameters in the dictionary.\n\n        :param params: The parameters structure to transform.\n        :param model: The operation model.\n        :param transformation: The function to apply the parameter\n        :param target_shape: The name of the shape to apply the\n            transformation to\n        \"\"\"\n        self._transform_parameters(model, params, transformation, target_shape)\n\n    def _transform_parameters(\n        self, model, params, transformation, target_shape\n    ):\n        type_name = model.type_name\n        if type_name in ('structure', 'map', 'list'):\n            getattr(self, f'_transform_{type_name}')(\n                model, params, transformation, target_shape\n            )\n\n    def _transform_structure(\n        self, model, params, transformation, target_shape\n    ):\n        if not isinstance(params, collections_abc.Mapping):\n            return\n        for param in params:\n            if param in model.members:\n                member_model = model.members[param]\n                member_shape = member_model.name\n                if member_shape == target_shape:\n                    params[param] = transformation(params[param])\n                else:\n                    self._transform_parameters(\n                        member_model,\n                        params[param],\n                        transformation,\n                        target_shape,\n                    )\n\n    def _transform_map(self, model, params, transformation, target_shape):\n        if not isinstance(params, collections_abc.Mapping):\n            return\n        value_model = model.value\n        value_shape = value_model.name\n        for key, value in params.items():\n            if value_shape == target_shape:\n                params[key] = transformation(value)\n            else:\n                self._transform_parameters(\n                    value_model, params[key], transformation, target_shape\n                )\n\n    def _transform_list(self, model, params, transformation, target_shape):\n        if not isinstance(params, collections_abc.MutableSequence):\n            return\n        member_model = model.member\n        member_shape = member_model.name\n        for i, item in enumerate(params):\n            if member_shape == target_shape:\n                params[i] = transformation(item)\n            else:\n                self._transform_parameters(\n                    member_model, params[i], transformation, target_shape\n                )\n", "boto3/ec2/deletetags.py": "# Copyright 2016 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom boto3.resources.action import CustomModeledAction\n\n\ndef inject_delete_tags(event_emitter, **kwargs):\n    action_model = {\n        'request': {\n            'operation': 'DeleteTags',\n            'params': [\n                {\n                    'target': 'Resources[0]',\n                    'source': 'identifier',\n                    'name': 'Id',\n                }\n            ],\n        }\n    }\n    action = CustomModeledAction(\n        'delete_tags', action_model, delete_tags, event_emitter\n    )\n    action.inject(**kwargs)\n\n\ndef delete_tags(self, **kwargs):\n    kwargs['Resources'] = [self.id]\n    return self.meta.client.delete_tags(**kwargs)\n", "boto3/ec2/createtags.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n\n\ndef inject_create_tags(event_name, class_attributes, **kwargs):\n    \"\"\"This injects a custom create_tags method onto the ec2 service resource\n\n    This is needed because the resource model is not able to express\n    creating multiple tag resources based on the fact you can apply a set\n    of tags to multiple ec2 resources.\n    \"\"\"\n    class_attributes['create_tags'] = create_tags\n\n\ndef create_tags(self, **kwargs):\n    # Call the client method\n    self.meta.client.create_tags(**kwargs)\n    resources = kwargs.get('Resources', [])\n    tags = kwargs.get('Tags', [])\n    tag_resources = []\n\n    # Generate all of the tag resources that just were created with the\n    # preceding client call.\n    for resource in resources:\n        for tag in tags:\n            # Add each tag from the tag set for each resource to the list\n            # that is returned by the method.\n            tag_resource = self.Tag(resource, tag['Key'], tag['Value'])\n            tag_resources.append(tag_resource)\n    return tag_resources\n", "boto3/ec2/__init__.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n", "boto3/docs/attr.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom botocore.docs.params import ResponseParamsDocumenter\n\nfrom boto3.docs.utils import get_identifier_description\n\n\nclass ResourceShapeDocumenter(ResponseParamsDocumenter):\n    EVENT_NAME = 'resource-shape'\n\n\ndef document_attribute(\n    section,\n    service_name,\n    resource_name,\n    attr_name,\n    event_emitter,\n    attr_model,\n    include_signature=True,\n):\n    if include_signature:\n        full_attr_name = f\"{section.context.get('qualifier', '')}{attr_name}\"\n        section.style.start_sphinx_py_attr(full_attr_name)\n    # Note that an attribute may have one, may have many, or may have no\n    # operations that back the resource's shape. So we just set the\n    # operation_name to the resource name if we ever to hook in and modify\n    # a particular attribute.\n    ResourceShapeDocumenter(\n        service_name=service_name,\n        operation_name=resource_name,\n        event_emitter=event_emitter,\n    ).document_params(section=section, shape=attr_model)\n\n\ndef document_identifier(\n    section,\n    resource_name,\n    identifier_model,\n    include_signature=True,\n):\n    if include_signature:\n        full_identifier_name = (\n            f\"{section.context.get('qualifier', '')}{identifier_model.name}\"\n        )\n        section.style.start_sphinx_py_attr(full_identifier_name)\n    description = get_identifier_description(\n        resource_name, identifier_model.name\n    )\n    section.write(f'*(string)* {description}')\n\n\ndef document_reference(section, reference_model, include_signature=True):\n    if include_signature:\n        full_reference_name = (\n            f\"{section.context.get('qualifier', '')}{reference_model.name}\"\n        )\n        section.style.start_sphinx_py_attr(full_reference_name)\n    reference_type = f'(:py:class:`{reference_model.resource.type}`) '\n    section.write(reference_type)\n    section.include_doc_string(\n        f'The related {reference_model.name} if set, otherwise ``None``.'\n    )\n", "boto3/docs/action.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport os\n\nfrom botocore import xform_name\nfrom botocore.docs.bcdoc.restdoc import DocumentStructure\nfrom botocore.docs.method import (\n    document_custom_method,\n    document_model_driven_method,\n)\nfrom botocore.model import OperationModel\nfrom botocore.utils import get_service_module_name\n\nfrom boto3.docs.base import NestedDocumenter\nfrom boto3.docs.method import document_model_driven_resource_method\nfrom boto3.docs.utils import (\n    add_resource_type_overview,\n    get_resource_ignore_params,\n    get_resource_public_actions,\n)\n\nPUT_DATA_WARNING_MESSAGE = \"\"\"\n.. warning::\n    It is recommended to use the :py:meth:`put_metric_data`\n    :doc:`client method <../../cloudwatch/client/put_metric_data>`\n    instead. If you would still like to use this resource method,\n    please make sure that ``MetricData[].MetricName`` is equal to\n    the metric resource's ``name`` attribute.\n\"\"\"\n\nWARNING_MESSAGES = {\n    \"Metric\": {\"put_data\": PUT_DATA_WARNING_MESSAGE},\n}\n\nIGNORE_PARAMS = {\"Metric\": {\"put_data\": [\"Namespace\"]}}\n\n\nclass ActionDocumenter(NestedDocumenter):\n    def document_actions(self, section):\n        modeled_actions_list = self._resource_model.actions\n        modeled_actions = {}\n        for modeled_action in modeled_actions_list:\n            modeled_actions[modeled_action.name] = modeled_action\n        resource_actions = get_resource_public_actions(\n            self._resource.__class__\n        )\n        self.member_map['actions'] = sorted(resource_actions)\n        add_resource_type_overview(\n            section=section,\n            resource_type='Actions',\n            description=(\n                'Actions call operations on resources.  They may '\n                'automatically handle the passing in of arguments set '\n                'from identifiers and some attributes.'\n            ),\n            intro_link='actions_intro',\n        )\n        resource_warnings = WARNING_MESSAGES.get(self._resource_name, {})\n        for action_name in sorted(resource_actions):\n            # Create a new DocumentStructure for each action and add contents.\n            action_doc = DocumentStructure(action_name, target='html')\n            breadcrumb_section = action_doc.add_new_section('breadcrumb')\n            breadcrumb_section.style.ref(self._resource_class_name, 'index')\n            breadcrumb_section.write(f' / Action / {action_name}')\n            action_doc.add_title_section(action_name)\n            warning_message = resource_warnings.get(action_name)\n            if warning_message is not None:\n                action_doc.add_new_section(\"warning\").write(warning_message)\n            action_section = action_doc.add_new_section(\n                action_name,\n                context={'qualifier': f'{self.class_name}.'},\n            )\n            if action_name in ['load', 'reload'] and self._resource_model.load:\n                document_load_reload_action(\n                    section=action_section,\n                    action_name=action_name,\n                    resource_name=self._resource_name,\n                    event_emitter=self._resource.meta.client.meta.events,\n                    load_model=self._resource_model.load,\n                    service_model=self._service_model,\n                )\n            elif action_name in modeled_actions:\n                document_action(\n                    section=action_section,\n                    resource_name=self._resource_name,\n                    event_emitter=self._resource.meta.client.meta.events,\n                    action_model=modeled_actions[action_name],\n                    service_model=self._service_model,\n                )\n            else:\n                document_custom_method(\n                    action_section, action_name, resource_actions[action_name]\n                )\n            # Write actions in individual/nested files.\n            # Path: <root>/reference/services/<service>/<resource_name>/<action_name>.rst\n            actions_dir_path = os.path.join(\n                self._root_docs_path,\n                f'{self._service_name}',\n                f'{self._resource_sub_path}',\n            )\n            action_doc.write_to_file(actions_dir_path, action_name)\n\n\ndef document_action(\n    section,\n    resource_name,\n    event_emitter,\n    action_model,\n    service_model,\n    include_signature=True,\n):\n    \"\"\"Documents a resource action\n\n    :param section: The section to write to\n\n    :param resource_name: The name of the resource\n\n    :param event_emitter: The event emitter to use to emit events\n\n    :param action_model: The model of the action\n\n    :param service_model: The model of the service\n\n    :param include_signature: Whether or not to include the signature.\n        It is useful for generating docstrings.\n    \"\"\"\n    operation_model = service_model.operation_model(\n        action_model.request.operation\n    )\n    ignore_params = IGNORE_PARAMS.get(resource_name, {}).get(\n        action_model.name,\n        get_resource_ignore_params(action_model.request.params),\n    )\n    example_return_value = 'response'\n    if action_model.resource:\n        example_return_value = xform_name(action_model.resource.type)\n    example_resource_name = xform_name(resource_name)\n    if service_model.service_name == resource_name:\n        example_resource_name = resource_name\n    example_prefix = (\n        f'{example_return_value} = {example_resource_name}.{action_model.name}'\n    )\n    full_action_name = (\n        f\"{section.context.get('qualifier', '')}{action_model.name}\"\n    )\n    document_model_driven_resource_method(\n        section=section,\n        method_name=full_action_name,\n        operation_model=operation_model,\n        event_emitter=event_emitter,\n        method_description=operation_model.documentation,\n        example_prefix=example_prefix,\n        exclude_input=ignore_params,\n        resource_action_model=action_model,\n        include_signature=include_signature,\n    )\n\n\ndef document_load_reload_action(\n    section,\n    action_name,\n    resource_name,\n    event_emitter,\n    load_model,\n    service_model,\n    include_signature=True,\n):\n    \"\"\"Documents the resource load action\n\n    :param section: The section to write to\n\n    :param action_name: The name of the loading action should be load or reload\n\n    :param resource_name: The name of the resource\n\n    :param event_emitter: The event emitter to use to emit events\n\n    :param load_model: The model of the load action\n\n    :param service_model: The model of the service\n\n    :param include_signature: Whether or not to include the signature.\n        It is useful for generating docstrings.\n    \"\"\"\n    description = (\n        f'Calls :py:meth:`{get_service_module_name(service_model)}.Client.'\n        f'{xform_name(load_model.request.operation)}` to update the attributes of the '\n        f'{resource_name} resource. Note that the load and reload methods are '\n        'the same method and can be used interchangeably.'\n    )\n    example_resource_name = xform_name(resource_name)\n    if service_model.service_name == resource_name:\n        example_resource_name = resource_name\n    example_prefix = f'{example_resource_name}.{action_name}'\n    full_action_name = f\"{section.context.get('qualifier', '')}{action_name}\"\n    document_model_driven_method(\n        section=section,\n        method_name=full_action_name,\n        operation_model=OperationModel({}, service_model),\n        event_emitter=event_emitter,\n        method_description=description,\n        example_prefix=example_prefix,\n        include_signature=include_signature,\n    )\n", "boto3/docs/subresource.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport os\n\nfrom botocore import xform_name\nfrom botocore.docs.bcdoc.restdoc import DocumentStructure\nfrom botocore.utils import get_service_module_name\n\nfrom boto3.docs.base import NestedDocumenter\nfrom boto3.docs.utils import (\n    add_resource_type_overview,\n    get_identifier_args_for_signature,\n    get_identifier_description,\n    get_identifier_values_for_example,\n)\n\n\nclass SubResourceDocumenter(NestedDocumenter):\n    def document_sub_resources(self, section):\n        add_resource_type_overview(\n            section=section,\n            resource_type='Sub-resources',\n            description=(\n                'Sub-resources are methods that create a new instance of a'\n                ' child resource. This resource\\'s identifiers get passed'\n                ' along to the child.'\n            ),\n            intro_link='subresources_intro',\n        )\n        sub_resources = sorted(\n            self._resource.meta.resource_model.subresources,\n            key=lambda sub_resource: sub_resource.name,\n        )\n        sub_resources_list = []\n        self.member_map['sub-resources'] = sub_resources_list\n        for sub_resource in sub_resources:\n            sub_resources_list.append(sub_resource.name)\n            # Create a new DocumentStructure for each sub_resource and add contents.\n            sub_resource_doc = DocumentStructure(\n                sub_resource.name, target='html'\n            )\n            breadcrumb_section = sub_resource_doc.add_new_section('breadcrumb')\n            breadcrumb_section.style.ref(self._resource_class_name, 'index')\n            breadcrumb_section.write(f' / Sub-Resource / {sub_resource.name}')\n            sub_resource_doc.add_title_section(sub_resource.name)\n            sub_resource_section = sub_resource_doc.add_new_section(\n                sub_resource.name,\n                context={'qualifier': f'{self.class_name}.'},\n            )\n            document_sub_resource(\n                section=sub_resource_section,\n                resource_name=self._resource_name,\n                sub_resource_model=sub_resource,\n                service_model=self._service_model,\n            )\n\n            # Write sub_resources in individual/nested files.\n            # Path: <root>/reference/services/<service>/<resource_name>/<sub_resource_name>.rst\n            sub_resources_dir_path = os.path.join(\n                self._root_docs_path,\n                f'{self._service_name}',\n                f'{self._resource_sub_path}',\n            )\n            sub_resource_doc.write_to_file(\n                sub_resources_dir_path, sub_resource.name\n            )\n\n\ndef document_sub_resource(\n    section,\n    resource_name,\n    sub_resource_model,\n    service_model,\n    include_signature=True,\n):\n    \"\"\"Documents a resource action\n\n    :param section: The section to write to\n\n    :param resource_name: The name of the resource\n\n    :param sub_resource_model: The model of the subresource\n\n    :param service_model: The model of the service\n\n    :param include_signature: Whether or not to include the signature.\n        It is useful for generating docstrings.\n    \"\"\"\n    identifiers_needed = []\n    for identifier in sub_resource_model.resource.identifiers:\n        if identifier.source == 'input':\n            identifiers_needed.append(xform_name(identifier.target))\n\n    if include_signature:\n        signature_args = get_identifier_args_for_signature(identifiers_needed)\n        full_sub_resource_name = (\n            f\"{section.context.get('qualifier', '')}{sub_resource_model.name}\"\n        )\n        section.style.start_sphinx_py_method(\n            full_sub_resource_name, signature_args\n        )\n\n    method_intro_section = section.add_new_section('method-intro')\n    description = f'Creates a {sub_resource_model.resource.type} resource.'\n    method_intro_section.include_doc_string(description)\n    example_section = section.add_new_section('example')\n    example_values = get_identifier_values_for_example(identifiers_needed)\n    example_resource_name = xform_name(resource_name)\n    if service_model.service_name == resource_name:\n        example_resource_name = resource_name\n    example = f'{xform_name(sub_resource_model.resource.type)} = {example_resource_name}.{sub_resource_model.name}({example_values})'\n    example_section.style.start_codeblock()\n    example_section.write(example)\n    example_section.style.end_codeblock()\n\n    param_section = section.add_new_section('params')\n    for identifier in identifiers_needed:\n        description = get_identifier_description(\n            sub_resource_model.name, identifier\n        )\n        param_section.write(f':type {identifier}: string')\n        param_section.style.new_line()\n        param_section.write(f':param {identifier}: {description}')\n        param_section.style.new_line()\n\n    return_section = section.add_new_section('return')\n    return_section.style.new_line()\n    return_section.write(\n        f':rtype: :py:class:`{get_service_module_name(service_model)}.{sub_resource_model.resource.type}`'\n    )\n    return_section.style.new_line()\n    return_section.write(\n        f':returns: A {sub_resource_model.resource.type} resource'\n    )\n    return_section.style.new_line()\n", "boto3/docs/utils.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport inspect\n\nimport jmespath\n\n\ndef get_resource_ignore_params(params):\n    \"\"\"Helper method to determine which parameters to ignore for actions\n\n    :returns: A list of the parameter names that does not need to be\n        included in a resource's method call for documentation purposes.\n    \"\"\"\n    ignore_params = []\n    for param in params:\n        result = jmespath.compile(param.target)\n        current = result.parsed\n        # Use JMESPath to find the left most element in the target expression\n        # which will be the parameter to ignore in the action call.\n        while current['children']:\n            current = current['children'][0]\n        # Make sure the parameter we are about to ignore is a field.\n        # If it is not, we should ignore the result to avoid false positives.\n        if current['type'] == 'field':\n            ignore_params.append(current['value'])\n    return ignore_params\n\n\ndef is_resource_action(action_handle):\n    return inspect.isfunction(action_handle)\n\n\ndef get_resource_public_actions(resource_class):\n    resource_class_members = inspect.getmembers(resource_class)\n    resource_methods = {}\n    for name, member in resource_class_members:\n        if not name.startswith('_'):\n            if not name[0].isupper():\n                if not name.startswith('wait_until'):\n                    if is_resource_action(member):\n                        resource_methods[name] = member\n    return resource_methods\n\n\ndef get_identifier_values_for_example(identifier_names):\n    return ','.join([f'\\'{identifier}\\'' for identifier in identifier_names])\n\n\ndef get_identifier_args_for_signature(identifier_names):\n    return ','.join(identifier_names)\n\n\ndef get_identifier_description(resource_name, identifier_name):\n    return (\n        f\"The {resource_name}'s {identifier_name} identifier. \"\n        f\"This **must** be set.\"\n    )\n\n\ndef add_resource_type_overview(\n    section, resource_type, description, intro_link=None\n):\n    section.style.new_line()\n    section.style.h3(resource_type)\n    section.style.new_line()\n    section.style.new_line()\n    section.write(description)\n    section.style.new_line()\n    if intro_link is not None:\n        section.write(\n            f'For more information about {resource_type.lower()} refer to the '\n            f':ref:`Resources Introduction Guide<{intro_link}>`.'\n        )\n        section.style.new_line()\n\n\nclass DocumentModifiedShape:\n    def __init__(\n        self, shape_name, new_type, new_description, new_example_value\n    ):\n        self._shape_name = shape_name\n        self._new_type = new_type\n        self._new_description = new_description\n        self._new_example_value = new_example_value\n\n    def replace_documentation_for_matching_shape(\n        self, event_name, section, **kwargs\n    ):\n        if self._shape_name == section.context.get('shape'):\n            self._replace_documentation(event_name, section)\n        for section_name in section.available_sections:\n            sub_section = section.get_section(section_name)\n            if self._shape_name == sub_section.context.get('shape'):\n                self._replace_documentation(event_name, sub_section)\n            else:\n                self.replace_documentation_for_matching_shape(\n                    event_name, sub_section\n                )\n\n    def _replace_documentation(self, event_name, section):\n        if event_name.startswith(\n            'docs.request-example'\n        ) or event_name.startswith('docs.response-example'):\n            section.remove_all_sections()\n            section.clear_text()\n            section.write(self._new_example_value)\n\n        if event_name.startswith(\n            'docs.request-params'\n        ) or event_name.startswith('docs.response-params'):\n            allowed_sections = (\n                'param-name',\n                'param-documentation',\n                'end-structure',\n                'param-type',\n                'end-param',\n            )\n            for section_name in section.available_sections:\n                # Delete any extra members as a new shape is being\n                # used.\n                if section_name not in allowed_sections:\n                    section.delete_section(section_name)\n\n            # Update the documentation\n            description_section = section.get_section('param-documentation')\n            description_section.clear_text()\n            description_section.write(self._new_description)\n\n            # Update the param type\n            type_section = section.get_section('param-type')\n            if type_section.getvalue().decode('utf-8').startswith(':type'):\n                type_section.clear_text()\n                type_section.write(f':type {section.name}: {self._new_type}')\n            else:\n                type_section.clear_text()\n                type_section.style.italics(f'({self._new_type}) -- ')\n", "boto3/docs/base.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom botocore.compat import OrderedDict\n\n\nclass BaseDocumenter:\n    def __init__(self, resource):\n        self._resource = resource\n        self._client = self._resource.meta.client\n        self._resource_model = self._resource.meta.resource_model\n        self._service_model = self._client.meta.service_model\n        self._resource_name = self._resource.meta.resource_model.name\n        self._service_name = self._service_model.service_name\n        self._service_docs_name = self._client.__class__.__name__\n        self.member_map = OrderedDict()\n        self.represents_service_resource = (\n            self._service_name == self._resource_name\n        )\n        self._resource_class_name = self._resource_name\n        if self._resource_name == self._service_name:\n            self._resource_class_name = 'ServiceResource'\n\n    @property\n    def class_name(self):\n        return f'{self._service_docs_name}.{self._resource_name}'\n\n\nclass NestedDocumenter(BaseDocumenter):\n    def __init__(self, resource, root_docs_path):\n        super().__init__(resource)\n        self._root_docs_path = root_docs_path\n        self._resource_sub_path = self._resource_name.lower()\n        if self._resource_name == self._service_name:\n            self._resource_sub_path = 'service-resource'\n\n    @property\n    def class_name(self):\n        resource_class_name = self._resource_name\n        if self._resource_name == self._service_name:\n            resource_class_name = 'ServiceResource'\n        return f'{self._service_docs_name}.{resource_class_name}'\n", "boto3/docs/waiter.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport os\n\nfrom botocore import xform_name\nfrom botocore.docs.bcdoc.restdoc import DocumentStructure\nfrom botocore.docs.method import document_model_driven_method\nfrom botocore.utils import get_service_module_name\n\nfrom boto3.docs.base import NestedDocumenter\nfrom boto3.docs.utils import (\n    add_resource_type_overview,\n    get_resource_ignore_params,\n)\n\n\nclass WaiterResourceDocumenter(NestedDocumenter):\n    def __init__(self, resource, service_waiter_model, root_docs_path):\n        super().__init__(resource, root_docs_path)\n        self._service_waiter_model = service_waiter_model\n\n    def document_resource_waiters(self, section):\n        waiters = self._resource.meta.resource_model.waiters\n        add_resource_type_overview(\n            section=section,\n            resource_type='Waiters',\n            description=(\n                'Waiters provide an interface to wait for a resource'\n                ' to reach a specific state.'\n            ),\n            intro_link='waiters_intro',\n        )\n        waiter_list = []\n        self.member_map['waiters'] = waiter_list\n        for waiter in waiters:\n            waiter_list.append(waiter.name)\n            # Create a new DocumentStructure for each waiter and add contents.\n            waiter_doc = DocumentStructure(waiter.name, target='html')\n            breadcrumb_section = waiter_doc.add_new_section('breadcrumb')\n            breadcrumb_section.style.ref(self._resource_class_name, 'index')\n            breadcrumb_section.write(f' / Waiter / {waiter.name}')\n            waiter_doc.add_title_section(waiter.name)\n            waiter_section = waiter_doc.add_new_section(\n                waiter.name,\n                context={'qualifier': f'{self.class_name}.'},\n            )\n            document_resource_waiter(\n                section=waiter_section,\n                resource_name=self._resource_name,\n                event_emitter=self._resource.meta.client.meta.events,\n                service_model=self._service_model,\n                resource_waiter_model=waiter,\n                service_waiter_model=self._service_waiter_model,\n            )\n            # Write waiters in individual/nested files.\n            # Path: <root>/reference/services/<service>/<resource_name>/<waiter_name>.rst\n            waiters_dir_path = os.path.join(\n                self._root_docs_path,\n                f'{self._service_name}',\n                f'{self._resource_sub_path}',\n            )\n            waiter_doc.write_to_file(waiters_dir_path, waiter.name)\n\n\ndef document_resource_waiter(\n    section,\n    resource_name,\n    event_emitter,\n    service_model,\n    resource_waiter_model,\n    service_waiter_model,\n    include_signature=True,\n):\n    waiter_model = service_waiter_model.get_waiter(\n        resource_waiter_model.waiter_name\n    )\n    operation_model = service_model.operation_model(waiter_model.operation)\n\n    ignore_params = get_resource_ignore_params(resource_waiter_model.params)\n    service_module_name = get_service_module_name(service_model)\n    description = (\n        'Waits until this {} is {}. This method calls '\n        ':py:meth:`{}.Waiter.{}.wait` which polls '\n        ':py:meth:`{}.Client.{}` every {} seconds until '\n        'a successful state is reached. An error is raised '\n        'after {} failed checks.'.format(\n            resource_name,\n            ' '.join(resource_waiter_model.name.split('_')[2:]),\n            service_module_name,\n            xform_name(resource_waiter_model.waiter_name),\n            service_module_name,\n            xform_name(waiter_model.operation),\n            waiter_model.delay,\n            waiter_model.max_attempts,\n        )\n    )\n    example_prefix = (\n        f'{xform_name(resource_name)}.{resource_waiter_model.name}'\n    )\n    full_waiter_name = (\n        f\"{section.context.get('qualifier', '')}{resource_waiter_model.name}\"\n    )\n    document_model_driven_method(\n        section=section,\n        method_name=full_waiter_name,\n        operation_model=operation_model,\n        event_emitter=event_emitter,\n        example_prefix=example_prefix,\n        method_description=description,\n        exclude_input=ignore_params,\n        include_signature=include_signature,\n    )\n    if 'return' in section.available_sections:\n        # Waiters do not return anything so we should remove\n        # any sections that may document the underlying return\n        # value of the client method.\n        return_section = section.get_section('return')\n        return_section.clear_text()\n        return_section.remove_all_sections()\n        return_section.write(':returns: None')\n", "boto3/docs/method.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom botocore.docs.method import document_model_driven_method\n\n\ndef document_model_driven_resource_method(\n    section,\n    method_name,\n    operation_model,\n    event_emitter,\n    method_description=None,\n    example_prefix=None,\n    include_input=None,\n    include_output=None,\n    exclude_input=None,\n    exclude_output=None,\n    document_output=True,\n    resource_action_model=None,\n    include_signature=True,\n):\n    document_model_driven_method(\n        section=section,\n        method_name=method_name,\n        operation_model=operation_model,\n        event_emitter=event_emitter,\n        method_description=method_description,\n        example_prefix=example_prefix,\n        include_input=include_input,\n        include_output=include_output,\n        exclude_input=exclude_input,\n        exclude_output=exclude_output,\n        document_output=document_output,\n        include_signature=include_signature,\n    )\n\n    # If this action returns a resource modify the return example to\n    # appropriately reflect that.\n    if resource_action_model.resource:\n        if 'return' in section.available_sections:\n            section.delete_section('return')\n        resource_type = resource_action_model.resource.type\n\n        new_return_section = section.add_new_section('return')\n        return_resource_type = (\n            f'{operation_model.service_model.service_name}.{resource_type}'\n        )\n\n        return_type = f':py:class:`{return_resource_type}`'\n        return_description = f'{resource_type} resource'\n\n        if _method_returns_resource_list(resource_action_model.resource):\n            return_type = f'list({return_type})'\n            return_description = f'A list of {resource_type} resources'\n\n        new_return_section.style.new_line()\n        new_return_section.write(f':rtype: {return_type}')\n        new_return_section.style.new_line()\n        new_return_section.write(f':returns: {return_description}')\n        new_return_section.style.new_line()\n\n\ndef _method_returns_resource_list(resource):\n    for identifier in resource.identifiers:\n        if identifier.path and '[]' in identifier.path:\n            return True\n\n    return False\n", "boto3/docs/client.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom botocore.docs.client import ClientDocumenter\n\n\nclass Boto3ClientDocumenter(ClientDocumenter):\n    def _add_client_creation_example(self, section):\n        section.style.start_codeblock()\n        section.style.new_line()\n        section.write('import boto3')\n        section.style.new_line()\n        section.style.new_line()\n        section.write(f'client = boto3.client(\\'{self._service_name}\\')')\n        section.style.end_codeblock()\n", "boto3/docs/collection.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport os\n\nfrom botocore import xform_name\nfrom botocore.docs.bcdoc.restdoc import DocumentStructure\nfrom botocore.docs.method import get_instance_public_methods\nfrom botocore.docs.utils import DocumentedShape\n\nfrom boto3.docs.base import NestedDocumenter\nfrom boto3.docs.method import document_model_driven_resource_method\nfrom boto3.docs.utils import (\n    add_resource_type_overview,\n    get_resource_ignore_params,\n)\n\n\nclass CollectionDocumenter(NestedDocumenter):\n    def document_collections(self, section):\n        collections = self._resource.meta.resource_model.collections\n        collections_list = []\n        add_resource_type_overview(\n            section=section,\n            resource_type='Collections',\n            description=(\n                'Collections provide an interface to iterate over and '\n                'manipulate groups of resources. '\n            ),\n            intro_link='guide_collections',\n        )\n        self.member_map['collections'] = collections_list\n        for collection in collections:\n            collections_list.append(collection.name)\n            # Create a new DocumentStructure for each collection and add contents.\n            collection_doc = DocumentStructure(collection.name, target='html')\n            breadcrumb_section = collection_doc.add_new_section('breadcrumb')\n            breadcrumb_section.style.ref(self._resource_class_name, 'index')\n            breadcrumb_section.write(f' / Collection / {collection.name}')\n            collection_doc.add_title_section(collection.name)\n            collection_section = collection_doc.add_new_section(\n                collection.name,\n                context={'qualifier': f'{self.class_name}.'},\n            )\n            self._document_collection(collection_section, collection)\n\n            # Write collections in individual/nested files.\n            # Path: <root>/reference/services/<service>/<resource_name>/<collection_name>.rst\n            collections_dir_path = os.path.join(\n                self._root_docs_path,\n                f'{self._service_name}',\n                f'{self._resource_sub_path}',\n            )\n            collection_doc.write_to_file(collections_dir_path, collection.name)\n\n    def _document_collection(self, section, collection):\n        methods = get_instance_public_methods(\n            getattr(self._resource, collection.name)\n        )\n        document_collection_object(section, collection)\n        batch_actions = {}\n        for batch_action in collection.batch_actions:\n            batch_actions[batch_action.name] = batch_action\n\n        for method in sorted(methods):\n            method_section = section.add_new_section(method)\n            if method in batch_actions:\n                document_batch_action(\n                    section=method_section,\n                    resource_name=self._resource_name,\n                    event_emitter=self._resource.meta.client.meta.events,\n                    batch_action_model=batch_actions[method],\n                    collection_model=collection,\n                    service_model=self._resource.meta.client.meta.service_model,\n                )\n            else:\n                document_collection_method(\n                    section=method_section,\n                    resource_name=self._resource_name,\n                    action_name=method,\n                    event_emitter=self._resource.meta.client.meta.events,\n                    collection_model=collection,\n                    service_model=self._resource.meta.client.meta.service_model,\n                )\n\n\ndef document_collection_object(\n    section,\n    collection_model,\n    include_signature=True,\n):\n    \"\"\"Documents a collection resource object\n\n    :param section: The section to write to\n\n    :param collection_model: The model of the collection\n\n    :param include_signature: Whether or not to include the signature.\n        It is useful for generating docstrings.\n    \"\"\"\n    if include_signature:\n        full_collection_name = (\n            f\"{section.context.get('qualifier', '')}{collection_model.name}\"\n        )\n        section.style.start_sphinx_py_attr(full_collection_name)\n    section.include_doc_string(\n        f'A collection of {collection_model.resource.type} resources.'\n    )\n    section.include_doc_string(\n        f'A {collection_model.resource.type} Collection will include all '\n        f'resources by default, and extreme caution should be taken when '\n        f'performing actions on all resources.'\n    )\n\n\ndef document_batch_action(\n    section,\n    resource_name,\n    event_emitter,\n    batch_action_model,\n    service_model,\n    collection_model,\n    include_signature=True,\n):\n    \"\"\"Documents a collection's batch action\n\n    :param section: The section to write to\n\n    :param resource_name: The name of the resource\n\n    :param action_name: The name of collection action. Currently only\n        can be all, filter, limit, or page_size\n\n    :param event_emitter: The event emitter to use to emit events\n\n    :param batch_action_model: The model of the batch action\n\n    :param collection_model: The model of the collection\n\n    :param service_model: The model of the service\n\n    :param include_signature: Whether or not to include the signature.\n        It is useful for generating docstrings.\n    \"\"\"\n    operation_model = service_model.operation_model(\n        batch_action_model.request.operation\n    )\n    ignore_params = get_resource_ignore_params(\n        batch_action_model.request.params\n    )\n\n    example_return_value = 'response'\n    if batch_action_model.resource:\n        example_return_value = xform_name(batch_action_model.resource.type)\n\n    example_resource_name = xform_name(resource_name)\n    if service_model.service_name == resource_name:\n        example_resource_name = resource_name\n    example_prefix = f'{example_return_value} = {example_resource_name}.{collection_model.name}.{batch_action_model.name}'\n    document_model_driven_resource_method(\n        section=section,\n        method_name=batch_action_model.name,\n        operation_model=operation_model,\n        event_emitter=event_emitter,\n        method_description=operation_model.documentation,\n        example_prefix=example_prefix,\n        exclude_input=ignore_params,\n        resource_action_model=batch_action_model,\n        include_signature=include_signature,\n    )\n\n\ndef document_collection_method(\n    section,\n    resource_name,\n    action_name,\n    event_emitter,\n    collection_model,\n    service_model,\n    include_signature=True,\n):\n    \"\"\"Documents a collection method\n\n    :param section: The section to write to\n\n    :param resource_name: The name of the resource\n\n    :param action_name: The name of collection action. Currently only\n        can be all, filter, limit, or page_size\n\n    :param event_emitter: The event emitter to use to emit events\n\n    :param collection_model: The model of the collection\n\n    :param service_model: The model of the service\n\n    :param include_signature: Whether or not to include the signature.\n        It is useful for generating docstrings.\n    \"\"\"\n    operation_model = service_model.operation_model(\n        collection_model.request.operation\n    )\n\n    underlying_operation_members = []\n    if operation_model.input_shape:\n        underlying_operation_members = operation_model.input_shape.members\n\n    example_resource_name = xform_name(resource_name)\n    if service_model.service_name == resource_name:\n        example_resource_name = resource_name\n\n    custom_action_info_dict = {\n        'all': {\n            'method_description': (\n                f'Creates an iterable of all {collection_model.resource.type} '\n                f'resources in the collection.'\n            ),\n            'example_prefix': f'{xform_name(collection_model.resource.type)}_iterator = {example_resource_name}.{collection_model.name}.all',\n            'exclude_input': underlying_operation_members,\n        },\n        'filter': {\n            'method_description': (\n                f'Creates an iterable of all {collection_model.resource.type} '\n                f'resources in the collection filtered by kwargs passed to '\n                f'method. A {collection_model.resource.type} collection will '\n                f'include all resources by default if no filters are provided, '\n                f'and extreme caution should be taken when performing actions '\n                f'on all resources.'\n            ),\n            'example_prefix': f'{xform_name(collection_model.resource.type)}_iterator = {example_resource_name}.{collection_model.name}.filter',\n            'exclude_input': get_resource_ignore_params(\n                collection_model.request.params\n            ),\n        },\n        'limit': {\n            'method_description': (\n                f'Creates an iterable up to a specified amount of '\n                f'{collection_model.resource.type} resources in the collection.'\n            ),\n            'example_prefix': f'{xform_name(collection_model.resource.type)}_iterator = {example_resource_name}.{collection_model.name}.limit',\n            'include_input': [\n                DocumentedShape(\n                    name='count',\n                    type_name='integer',\n                    documentation=(\n                        'The limit to the number of resources '\n                        'in the iterable.'\n                    ),\n                )\n            ],\n            'exclude_input': underlying_operation_members,\n        },\n        'page_size': {\n            'method_description': (\n                f'Creates an iterable of all {collection_model.resource.type} '\n                f'resources in the collection, but limits the number of '\n                f'items returned by each service call by the specified amount.'\n            ),\n            'example_prefix': f'{xform_name(collection_model.resource.type)}_iterator = {example_resource_name}.{collection_model.name}.page_size',\n            'include_input': [\n                DocumentedShape(\n                    name='count',\n                    type_name='integer',\n                    documentation=(\n                        'The number of items returned by each ' 'service call'\n                    ),\n                )\n            ],\n            'exclude_input': underlying_operation_members,\n        },\n    }\n    if action_name in custom_action_info_dict:\n        action_info = custom_action_info_dict[action_name]\n        document_model_driven_resource_method(\n            section=section,\n            method_name=action_name,\n            operation_model=operation_model,\n            event_emitter=event_emitter,\n            resource_action_model=collection_model,\n            include_signature=include_signature,\n            **action_info,\n        )\n", "boto3/docs/service.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport os\n\nfrom botocore.docs.bcdoc.restdoc import DocumentStructure\nfrom botocore.docs.service import ServiceDocumenter as BaseServiceDocumenter\nfrom botocore.exceptions import DataNotFoundError\n\nimport boto3\nfrom boto3.docs.client import Boto3ClientDocumenter\nfrom boto3.docs.resource import ResourceDocumenter, ServiceResourceDocumenter\nfrom boto3.utils import ServiceContext\n\n\nclass ServiceDocumenter(BaseServiceDocumenter):\n    # The path used to find examples\n    EXAMPLE_PATH = os.path.join(os.path.dirname(boto3.__file__), 'examples')\n\n    def __init__(self, service_name, session, root_docs_path):\n        super().__init__(\n            service_name=service_name,\n            # I know that this is an internal attribute, but the botocore session\n            # is needed to load the paginator and waiter models.\n            session=session._session,\n            root_docs_path=root_docs_path,\n        )\n        self._boto3_session = session\n        self._client = self._boto3_session.client(service_name)\n        self._service_resource = None\n        if self._service_name in self._boto3_session.get_available_resources():\n            self._service_resource = self._boto3_session.resource(service_name)\n        self.sections = [\n            'title',\n            'client',\n            'paginators',\n            'waiters',\n            'resources',\n            'examples',\n            'context-params',\n        ]\n        self._root_docs_path = root_docs_path\n        self._USER_GUIDE_LINK = (\n            'https://boto3.amazonaws.com/'\n            'v1/documentation/api/latest/guide/resources.html'\n        )\n\n    def document_service(self):\n        \"\"\"Documents an entire service.\n\n        :returns: The reStructured text of the documented service.\n        \"\"\"\n        doc_structure = DocumentStructure(\n            self._service_name, section_names=self.sections, target='html'\n        )\n        self.title(doc_structure.get_section('title'))\n\n        self.client_api(doc_structure.get_section('client'))\n        self.paginator_api(doc_structure.get_section('paginators'))\n        self.waiter_api(doc_structure.get_section('waiters'))\n        if self._service_resource:\n            self.resource_section(doc_structure.get_section('resources'))\n        self._document_examples(doc_structure.get_section('examples'))\n        context_params_section = doc_structure.get_section('context-params')\n        self.client_context_params(context_params_section)\n        return doc_structure.flush_structure()\n\n    def client_api(self, section):\n        examples = None\n        try:\n            examples = self.get_examples(self._service_name)\n        except DataNotFoundError:\n            pass\n\n        Boto3ClientDocumenter(\n            self._client, self._root_docs_path, examples\n        ).document_client(section)\n\n    def resource_section(self, section):\n        section.style.h2('Resources')\n        section.style.new_line()\n        section.write(\n            'Resources are available in boto3 via the '\n            '``resource`` method. For more detailed instructions '\n            'and examples on the usage of resources, see the '\n            'resources '\n        )\n        section.style.external_link(\n            title='user guide',\n            link=self._USER_GUIDE_LINK,\n        )\n        section.write('.')\n        section.style.new_line()\n        section.style.new_line()\n        section.write('The available resources are:')\n        section.style.new_line()\n        section.style.toctree()\n        self._document_service_resource(section)\n        self._document_resources(section)\n\n    def _document_service_resource(self, section):\n        # Create a new DocumentStructure for each Service Resource and add contents.\n        service_resource_doc = DocumentStructure(\n            'service-resource', target='html'\n        )\n        breadcrumb_section = service_resource_doc.add_new_section('breadcrumb')\n        breadcrumb_section.style.ref(\n            self._client.__class__.__name__, f'../../{self._service_name}'\n        )\n        breadcrumb_section.write(' / Resource / ServiceResource')\n        ServiceResourceDocumenter(\n            self._service_resource, self._session, self._root_docs_path\n        ).document_resource(service_resource_doc)\n        # Write collections in individual/nested files.\n        # Path: <root>/reference/services/<service>/<resource_name>/<collection_name>.rst\n        resource_name = self._service_resource.meta.resource_model.name\n        if resource_name == self._service_name:\n            resource_name = 'service-resource'\n        service_resource_dir_path = os.path.join(\n            self._root_docs_path,\n            f'{self._service_name}',\n            f'{resource_name.lower()}',\n        )\n        service_resource_doc.write_to_file(service_resource_dir_path, 'index')\n        section.style.tocitem(f'{self._service_name}/{resource_name}/index')\n\n    def _document_resources(self, section):\n        temp_identifier_value = 'foo'\n        loader = self._session.get_component('data_loader')\n        json_resource_model = loader.load_service_model(\n            self._service_name, 'resources-1'\n        )\n        service_model = self._service_resource.meta.client.meta.service_model\n        for resource_name in json_resource_model['resources']:\n            resource_model = json_resource_model['resources'][resource_name]\n            resource_cls = (\n                self._boto3_session.resource_factory.load_from_definition(\n                    resource_name=resource_name,\n                    single_resource_json_definition=resource_model,\n                    service_context=ServiceContext(\n                        service_name=self._service_name,\n                        resource_json_definitions=json_resource_model[\n                            'resources'\n                        ],\n                        service_model=service_model,\n                        service_waiter_model=None,\n                    ),\n                )\n            )\n            identifiers = resource_cls.meta.resource_model.identifiers\n            args = []\n            for _ in identifiers:\n                args.append(temp_identifier_value)\n            resource = resource_cls(*args, client=self._client)\n            # Create a new DocumentStructure for each Resource and add contents.\n            resource_name = resource.meta.resource_model.name.lower()\n            resource_doc = DocumentStructure(resource_name, target='html')\n            breadcrumb_section = resource_doc.add_new_section('breadcrumb')\n            breadcrumb_section.style.ref(\n                self._client.__class__.__name__, f'../../{self._service_name}'\n            )\n            breadcrumb_section.write(\n                f' / Resource / {resource.meta.resource_model.name}'\n            )\n            ResourceDocumenter(\n                resource, self._session, self._root_docs_path\n            ).document_resource(\n                resource_doc.add_new_section(resource.meta.resource_model.name)\n            )\n            # Write collections in individual/nested files.\n            # Path: <root>/reference/services/<service>/<resource_name>/<index>.rst\n            service_resource_dir_path = os.path.join(\n                self._root_docs_path,\n                f'{self._service_name}',\n                f'{resource_name}',\n            )\n            resource_doc.write_to_file(service_resource_dir_path, 'index')\n            section.style.tocitem(\n                f'{self._service_name}/{resource_name}/index'\n            )\n\n    def _get_example_file(self):\n        return os.path.realpath(\n            os.path.join(self.EXAMPLE_PATH, self._service_name + '.rst')\n        )\n\n    def _document_examples(self, section):\n        examples_file = self._get_example_file()\n        if os.path.isfile(examples_file):\n            section.style.h2('Examples')\n            section.style.new_line()\n            with open(examples_file) as f:\n                section.write(f.read())\n", "boto3/docs/__init__.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport os\n\nfrom botocore.docs import DEPRECATED_SERVICE_NAMES\n\nfrom boto3.docs.service import ServiceDocumenter\n\n\ndef generate_docs(root_dir, session):\n    \"\"\"Generates the reference documentation for botocore\n\n    This will go through every available AWS service and output ReSTructured\n    text files documenting each service.\n\n    :param root_dir: The directory to write the reference files to. Each\n        service's reference documentation is loacated at\n        root_dir/reference/services/service-name.rst\n\n    :param session: The boto3 session\n    \"\"\"\n    services_doc_path = os.path.join(root_dir, 'reference', 'services')\n    if not os.path.exists(services_doc_path):\n        os.makedirs(services_doc_path)\n\n    # Prevents deprecated service names from being generated in docs.\n    available_services = [\n        service\n        for service in session.get_available_services()\n        if service not in DEPRECATED_SERVICE_NAMES\n    ]\n\n    for service_name in available_services:\n        docs = ServiceDocumenter(\n            service_name, session, services_doc_path\n        ).document_service()\n        service_doc_path = os.path.join(\n            services_doc_path, service_name + '.rst'\n        )\n        with open(service_doc_path, 'wb') as f:\n            f.write(docs)\n", "boto3/docs/docstring.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom botocore.docs.docstring import LazyLoadedDocstring\n\nfrom boto3.docs.action import document_action, document_load_reload_action\nfrom boto3.docs.attr import (\n    document_attribute,\n    document_identifier,\n    document_reference,\n)\nfrom boto3.docs.collection import (\n    document_batch_action,\n    document_collection_method,\n    document_collection_object,\n)\nfrom boto3.docs.subresource import document_sub_resource\nfrom boto3.docs.waiter import document_resource_waiter\n\n\nclass ActionDocstring(LazyLoadedDocstring):\n    def _write_docstring(self, *args, **kwargs):\n        document_action(*args, **kwargs)\n\n\nclass LoadReloadDocstring(LazyLoadedDocstring):\n    def _write_docstring(self, *args, **kwargs):\n        document_load_reload_action(*args, **kwargs)\n\n\nclass SubResourceDocstring(LazyLoadedDocstring):\n    def _write_docstring(self, *args, **kwargs):\n        document_sub_resource(*args, **kwargs)\n\n\nclass AttributeDocstring(LazyLoadedDocstring):\n    def _write_docstring(self, *args, **kwargs):\n        document_attribute(*args, **kwargs)\n\n\nclass IdentifierDocstring(LazyLoadedDocstring):\n    def _write_docstring(self, *args, **kwargs):\n        document_identifier(*args, **kwargs)\n\n\nclass ReferenceDocstring(LazyLoadedDocstring):\n    def _write_docstring(self, *args, **kwargs):\n        document_reference(*args, **kwargs)\n\n\nclass CollectionDocstring(LazyLoadedDocstring):\n    def _write_docstring(self, *args, **kwargs):\n        document_collection_object(*args, **kwargs)\n\n\nclass CollectionMethodDocstring(LazyLoadedDocstring):\n    def _write_docstring(self, *args, **kwargs):\n        document_collection_method(*args, **kwargs)\n\n\nclass BatchActionDocstring(LazyLoadedDocstring):\n    def _write_docstring(self, *args, **kwargs):\n        document_batch_action(*args, **kwargs)\n\n\nclass ResourceWaiterDocstring(LazyLoadedDocstring):\n    def _write_docstring(self, *args, **kwargs):\n        document_resource_waiter(*args, **kwargs)\n", "boto3/docs/resource.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport os\n\nfrom botocore import xform_name\nfrom botocore.docs.bcdoc.restdoc import DocumentStructure\nfrom botocore.docs.utils import get_official_service_name\n\nfrom boto3.docs.action import ActionDocumenter\nfrom boto3.docs.attr import (\n    document_attribute,\n    document_identifier,\n    document_reference,\n)\nfrom boto3.docs.base import BaseDocumenter\nfrom boto3.docs.collection import CollectionDocumenter\nfrom boto3.docs.subresource import SubResourceDocumenter\nfrom boto3.docs.utils import (\n    add_resource_type_overview,\n    get_identifier_args_for_signature,\n    get_identifier_description,\n    get_identifier_values_for_example,\n)\nfrom boto3.docs.waiter import WaiterResourceDocumenter\n\n\nclass ResourceDocumenter(BaseDocumenter):\n    def __init__(self, resource, botocore_session, root_docs_path):\n        super().__init__(resource)\n        self._botocore_session = botocore_session\n        self._root_docs_path = root_docs_path\n        self._resource_sub_path = self._resource_name.lower()\n        if self._resource_name == self._service_name:\n            self._resource_sub_path = 'service-resource'\n\n    def document_resource(self, section):\n        self._add_title(section)\n        self._add_resource_note(section)\n        self._add_intro(section)\n        self._add_identifiers(section)\n        self._add_attributes(section)\n        self._add_references(section)\n        self._add_actions(section)\n        self._add_sub_resources(section)\n        self._add_collections(section)\n        self._add_waiters(section)\n\n    def _add_title(self, section):\n        title_section = section.add_new_section('title')\n        title_section.style.h2(self._resource_name)\n\n    def _add_intro(self, section):\n        identifier_names = []\n        if self._resource_model.identifiers:\n            for identifier in self._resource_model.identifiers:\n                identifier_names.append(identifier.name)\n\n        # Write out the class signature.\n        class_args = get_identifier_args_for_signature(identifier_names)\n        start_class = section.add_new_section('start_class')\n        start_class.style.start_sphinx_py_class(\n            class_name=f'{self.class_name}({class_args})'\n        )\n\n        # Add as short description about the resource\n        description_section = start_class.add_new_section('description')\n        self._add_description(description_section)\n\n        # Add an example of how to instantiate the resource\n        example_section = start_class.add_new_section('example')\n        self._add_example(example_section, identifier_names)\n\n        # Add the description for the parameters to instantiate the\n        # resource.\n        param_section = start_class.add_new_section('params')\n        self._add_params_description(param_section, identifier_names)\n\n        end_class = section.add_new_section('end_class')\n        end_class.style.end_sphinx_py_class()\n\n    def _add_description(self, section):\n        official_service_name = get_official_service_name(self._service_model)\n        section.write(\n            f'A resource representing an {official_service_name} {self._resource_name}'\n        )\n\n    def _add_example(self, section, identifier_names):\n        section.style.start_codeblock()\n        section.style.new_line()\n        section.write('import boto3')\n        section.style.new_line()\n        section.style.new_line()\n        section.write(\n            f'{self._service_name} = boto3.resource(\\'{self._service_name}\\')'\n        )\n        section.style.new_line()\n        example_values = get_identifier_values_for_example(identifier_names)\n        section.write(\n            f'{xform_name(self._resource_name)} = {self._service_name}.{self._resource_name}({example_values})'\n        )\n        section.style.end_codeblock()\n\n    def _add_params_description(self, section, identifier_names):\n        for identifier_name in identifier_names:\n            description = get_identifier_description(\n                self._resource_name, identifier_name\n            )\n            section.write(f':type {identifier_name}: string')\n            section.style.new_line()\n            section.write(f':param {identifier_name}: {description}')\n            section.style.new_line()\n\n    def _add_overview_of_member_type(self, section, resource_member_type):\n        section.style.new_line()\n        section.write(\n            f'These are the resource\\'s available {resource_member_type}:'\n        )\n        section.style.new_line()\n        section.style.toctree()\n        for member in self.member_map[resource_member_type]:\n            section.style.tocitem(f'{member}')\n\n    def _add_identifiers(self, section):\n        identifiers = self._resource.meta.resource_model.identifiers\n        section = section.add_new_section('identifiers')\n        member_list = []\n        if identifiers:\n            self.member_map['identifiers'] = member_list\n            add_resource_type_overview(\n                section=section,\n                resource_type='Identifiers',\n                description=(\n                    'Identifiers are properties of a resource that are '\n                    'set upon instantiation of the resource.'\n                ),\n                intro_link='identifiers_attributes_intro',\n            )\n        for identifier in identifiers:\n            member_list.append(identifier.name)\n            # Create a new DocumentStructure for each identifier and add contents.\n            identifier_doc = DocumentStructure(identifier.name, target='html')\n            breadcrumb_section = identifier_doc.add_new_section('breadcrumb')\n            breadcrumb_section.style.ref(self._resource_class_name, 'index')\n            breadcrumb_section.write(f' / Identifier / {identifier.name}')\n            identifier_doc.add_title_section(identifier.name)\n            identifier_section = identifier_doc.add_new_section(\n                identifier.name,\n                context={'qualifier': f'{self.class_name}.'},\n            )\n            document_identifier(\n                section=identifier_section,\n                resource_name=self._resource_name,\n                identifier_model=identifier,\n            )\n            # Write identifiers in individual/nested files.\n            # Path: <root>/reference/services/<service>/<resource_name>/<identifier_name>.rst\n            identifiers_dir_path = os.path.join(\n                self._root_docs_path,\n                f'{self._service_name}',\n                f'{self._resource_sub_path}',\n            )\n            identifier_doc.write_to_file(identifiers_dir_path, identifier.name)\n\n        if identifiers:\n            self._add_overview_of_member_type(section, 'identifiers')\n\n    def _add_attributes(self, section):\n        service_model = self._resource.meta.client.meta.service_model\n        attributes = {}\n        if self._resource.meta.resource_model.shape:\n            shape = service_model.shape_for(\n                self._resource.meta.resource_model.shape\n            )\n            attributes = self._resource.meta.resource_model.get_attributes(\n                shape\n            )\n        section = section.add_new_section('attributes')\n        attribute_list = []\n        if attributes:\n            add_resource_type_overview(\n                section=section,\n                resource_type='Attributes',\n                description=(\n                    'Attributes provide access'\n                    ' to the properties of a resource. Attributes are lazy-'\n                    'loaded the first time one is accessed via the'\n                    ' :py:meth:`load` method.'\n                ),\n                intro_link='identifiers_attributes_intro',\n            )\n            self.member_map['attributes'] = attribute_list\n        for attr_name in sorted(attributes):\n            _, attr_shape = attributes[attr_name]\n            attribute_list.append(attr_name)\n            # Create a new DocumentStructure for each attribute and add contents.\n            attribute_doc = DocumentStructure(attr_name, target='html')\n            breadcrumb_section = attribute_doc.add_new_section('breadcrumb')\n            breadcrumb_section.style.ref(self._resource_class_name, 'index')\n            breadcrumb_section.write(f' / Attribute / {attr_name}')\n            attribute_doc.add_title_section(attr_name)\n            attribute_section = attribute_doc.add_new_section(\n                attr_name,\n                context={'qualifier': f'{self.class_name}.'},\n            )\n            document_attribute(\n                section=attribute_section,\n                service_name=self._service_name,\n                resource_name=self._resource_name,\n                attr_name=attr_name,\n                event_emitter=self._resource.meta.client.meta.events,\n                attr_model=attr_shape,\n            )\n            # Write attributes in individual/nested files.\n            # Path: <root>/reference/services/<service>/<resource_name>/<attribute_name>.rst\n            attributes_dir_path = os.path.join(\n                self._root_docs_path,\n                f'{self._service_name}',\n                f'{self._resource_sub_path}',\n            )\n            attribute_doc.write_to_file(attributes_dir_path, attr_name)\n        if attributes:\n            self._add_overview_of_member_type(section, 'attributes')\n\n    def _add_references(self, section):\n        section = section.add_new_section('references')\n        references = self._resource.meta.resource_model.references\n        reference_list = []\n        if references:\n            add_resource_type_overview(\n                section=section,\n                resource_type='References',\n                description=(\n                    'References are related resource instances that have '\n                    'a belongs-to relationship.'\n                ),\n                intro_link='references_intro',\n            )\n            self.member_map['references'] = reference_list\n        for reference in references:\n            reference_list.append(reference.name)\n            # Create a new DocumentStructure for each reference and add contents.\n            reference_doc = DocumentStructure(reference.name, target='html')\n            breadcrumb_section = reference_doc.add_new_section('breadcrumb')\n            breadcrumb_section.style.ref(self._resource_class_name, 'index')\n            breadcrumb_section.write(f' / Reference / {reference.name}')\n            reference_doc.add_title_section(reference.name)\n            reference_section = reference_doc.add_new_section(\n                reference.name,\n                context={'qualifier': f'{self.class_name}.'},\n            )\n            document_reference(\n                section=reference_section,\n                reference_model=reference,\n            )\n            # Write references in individual/nested files.\n            # Path: <root>/reference/services/<service>/<resource_name>/<reference_name>.rst\n            references_dir_path = os.path.join(\n                self._root_docs_path,\n                f'{self._service_name}',\n                f'{self._resource_sub_path}',\n            )\n            reference_doc.write_to_file(references_dir_path, reference.name)\n        if references:\n            self._add_overview_of_member_type(section, 'references')\n\n    def _add_actions(self, section):\n        section = section.add_new_section('actions')\n        actions = self._resource.meta.resource_model.actions\n        if actions:\n            documenter = ActionDocumenter(self._resource, self._root_docs_path)\n            documenter.member_map = self.member_map\n            documenter.document_actions(section)\n            self._add_overview_of_member_type(section, 'actions')\n\n    def _add_sub_resources(self, section):\n        section = section.add_new_section('sub-resources')\n        sub_resources = self._resource.meta.resource_model.subresources\n        if sub_resources:\n            documenter = SubResourceDocumenter(\n                self._resource, self._root_docs_path\n            )\n            documenter.member_map = self.member_map\n            documenter.document_sub_resources(section)\n            self._add_overview_of_member_type(section, 'sub-resources')\n\n    def _add_collections(self, section):\n        section = section.add_new_section('collections')\n        collections = self._resource.meta.resource_model.collections\n        if collections:\n            documenter = CollectionDocumenter(\n                self._resource, self._root_docs_path\n            )\n            documenter.member_map = self.member_map\n            documenter.document_collections(section)\n            self._add_overview_of_member_type(section, 'collections')\n\n    def _add_waiters(self, section):\n        section = section.add_new_section('waiters')\n        waiters = self._resource.meta.resource_model.waiters\n        if waiters:\n            service_waiter_model = self._botocore_session.get_waiter_model(\n                self._service_name\n            )\n            documenter = WaiterResourceDocumenter(\n                self._resource, service_waiter_model, self._root_docs_path\n            )\n            documenter.member_map = self.member_map\n            documenter.document_resource_waiters(section)\n            self._add_overview_of_member_type(section, 'waiters')\n\n    def _add_resource_note(self, section):\n        section = section.add_new_section('feature-freeze')\n        section.style.start_note()\n        section.write(\n            \"Before using anything on this page, please refer to the resources \"\n            \":doc:`user guide <../../../../guide/resources>` for the most recent \"\n            \"guidance on using resources.\"\n        )\n        section.style.end_note()\n\n\nclass ServiceResourceDocumenter(ResourceDocumenter):\n    @property\n    def class_name(self):\n        return f'{self._service_docs_name}.ServiceResource'\n\n    def _add_title(self, section):\n        title_section = section.add_new_section('title')\n        title_section.style.h2('Service Resource')\n\n    def _add_description(self, section):\n        official_service_name = get_official_service_name(self._service_model)\n        section.write(f'A resource representing {official_service_name}')\n\n    def _add_example(self, section, identifier_names):\n        section.style.start_codeblock()\n        section.style.new_line()\n        section.write('import boto3')\n        section.style.new_line()\n        section.style.new_line()\n        section.write(\n            f'{self._service_name} = boto3.resource(\\'{self._service_name}\\')'\n        )\n        section.style.end_codeblock()\n", "boto3/s3/inject.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport copy as python_copy\n\nfrom botocore.exceptions import ClientError\n\nfrom boto3 import utils\nfrom boto3.s3.transfer import (\n    ProgressCallbackInvoker,\n    S3Transfer,\n    TransferConfig,\n    create_transfer_manager,\n)\n\n\ndef inject_s3_transfer_methods(class_attributes, **kwargs):\n    utils.inject_attribute(class_attributes, 'upload_file', upload_file)\n    utils.inject_attribute(class_attributes, 'download_file', download_file)\n    utils.inject_attribute(class_attributes, 'copy', copy)\n    utils.inject_attribute(class_attributes, 'upload_fileobj', upload_fileobj)\n    utils.inject_attribute(\n        class_attributes, 'download_fileobj', download_fileobj\n    )\n\n\ndef inject_bucket_methods(class_attributes, **kwargs):\n    utils.inject_attribute(class_attributes, 'load', bucket_load)\n    utils.inject_attribute(class_attributes, 'upload_file', bucket_upload_file)\n    utils.inject_attribute(\n        class_attributes, 'download_file', bucket_download_file\n    )\n    utils.inject_attribute(class_attributes, 'copy', bucket_copy)\n    utils.inject_attribute(\n        class_attributes, 'upload_fileobj', bucket_upload_fileobj\n    )\n    utils.inject_attribute(\n        class_attributes, 'download_fileobj', bucket_download_fileobj\n    )\n\n\ndef inject_object_methods(class_attributes, **kwargs):\n    utils.inject_attribute(class_attributes, 'upload_file', object_upload_file)\n    utils.inject_attribute(\n        class_attributes, 'download_file', object_download_file\n    )\n    utils.inject_attribute(class_attributes, 'copy', object_copy)\n    utils.inject_attribute(\n        class_attributes, 'upload_fileobj', object_upload_fileobj\n    )\n    utils.inject_attribute(\n        class_attributes, 'download_fileobj', object_download_fileobj\n    )\n\n\ndef inject_object_summary_methods(class_attributes, **kwargs):\n    utils.inject_attribute(class_attributes, 'load', object_summary_load)\n\n\ndef bucket_load(self, *args, **kwargs):\n    \"\"\"\n    Calls s3.Client.list_buckets() to update the attributes of the Bucket\n    resource.\n    \"\"\"\n    # The docstring above is phrased this way to match what the autogenerated\n    # docs produce.\n\n    # We can't actually get the bucket's attributes from a HeadBucket,\n    # so we need to use a ListBuckets and search for our bucket.\n    # However, we may fail if we lack permissions to ListBuckets\n    # or the bucket is in another account. In which case, creation_date\n    # will be None.\n    self.meta.data = {}\n    try:\n        response = self.meta.client.list_buckets()\n        for bucket_data in response['Buckets']:\n            if bucket_data['Name'] == self.name:\n                self.meta.data = bucket_data\n                break\n    except ClientError as e:\n        if not e.response.get('Error', {}).get('Code') == 'AccessDenied':\n            raise\n\n\ndef object_summary_load(self, *args, **kwargs):\n    \"\"\"\n    Calls s3.Client.head_object to update the attributes of the ObjectSummary\n    resource.\n    \"\"\"\n    response = self.meta.client.head_object(\n        Bucket=self.bucket_name, Key=self.key\n    )\n    if 'ContentLength' in response:\n        response['Size'] = response.pop('ContentLength')\n    self.meta.data = response\n\n\ndef upload_file(\n    self, Filename, Bucket, Key, ExtraArgs=None, Callback=None, Config=None\n):\n    \"\"\"Upload a file to an S3 object.\n\n    Usage::\n\n        import boto3\n        s3 = boto3.client('s3')\n        s3.upload_file('/tmp/hello.txt', 'mybucket', 'hello.txt')\n\n    Similar behavior as S3Transfer's upload_file() method, except that\n    argument names are capitalized. Detailed examples can be found at\n    :ref:`S3Transfer's Usage <ref_s3transfer_usage>`.\n\n    :type Filename: str\n    :param Filename: The path to the file to upload.\n\n    :type Bucket: str\n    :param Bucket: The name of the bucket to upload to.\n\n    :type Key: str\n    :param Key: The name of the key to upload to.\n\n    :type ExtraArgs: dict\n    :param ExtraArgs: Extra arguments that may be passed to the\n        client operation. For allowed upload arguments see\n        boto3.s3.transfer.S3Transfer.ALLOWED_UPLOAD_ARGS.\n\n    :type Callback: function\n    :param Callback: A method which takes a number of bytes transferred to\n        be periodically called during the upload.\n\n    :type Config: boto3.s3.transfer.TransferConfig\n    :param Config: The transfer configuration to be used when performing the\n        transfer.\n    \"\"\"\n    with S3Transfer(self, Config) as transfer:\n        return transfer.upload_file(\n            filename=Filename,\n            bucket=Bucket,\n            key=Key,\n            extra_args=ExtraArgs,\n            callback=Callback,\n        )\n\n\ndef download_file(\n    self, Bucket, Key, Filename, ExtraArgs=None, Callback=None, Config=None\n):\n    \"\"\"Download an S3 object to a file.\n\n    Usage::\n\n        import boto3\n        s3 = boto3.client('s3')\n        s3.download_file('mybucket', 'hello.txt', '/tmp/hello.txt')\n\n    Similar behavior as S3Transfer's download_file() method,\n    except that parameters are capitalized. Detailed examples can be found at\n    :ref:`S3Transfer's Usage <ref_s3transfer_usage>`.\n\n    :type Bucket: str\n    :param Bucket: The name of the bucket to download from.\n\n    :type Key: str\n    :param Key: The name of the key to download from.\n\n    :type Filename: str\n    :param Filename: The path to the file to download to.\n\n    :type ExtraArgs: dict\n    :param ExtraArgs: Extra arguments that may be passed to the\n        client operation. For allowed download arguments see\n        boto3.s3.transfer.S3Transfer.ALLOWED_DOWNLOAD_ARGS.\n\n    :type Callback: function\n    :param Callback: A method which takes a number of bytes transferred to\n        be periodically called during the download.\n\n    :type Config: boto3.s3.transfer.TransferConfig\n    :param Config: The transfer configuration to be used when performing the\n        transfer.\n    \"\"\"\n    with S3Transfer(self, Config) as transfer:\n        return transfer.download_file(\n            bucket=Bucket,\n            key=Key,\n            filename=Filename,\n            extra_args=ExtraArgs,\n            callback=Callback,\n        )\n\n\ndef bucket_upload_file(\n    self, Filename, Key, ExtraArgs=None, Callback=None, Config=None\n):\n    \"\"\"Upload a file to an S3 object.\n\n    Usage::\n\n        import boto3\n        s3 = boto3.resource('s3')\n        s3.Bucket('mybucket').upload_file('/tmp/hello.txt', 'hello.txt')\n\n    Similar behavior as S3Transfer's upload_file() method,\n    except that parameters are capitalized. Detailed examples can be found at\n    :ref:`S3Transfer's Usage <ref_s3transfer_usage>`.\n\n    :type Filename: str\n    :param Filename: The path to the file to upload.\n\n    :type Key: str\n    :param Key: The name of the key to upload to.\n\n    :type ExtraArgs: dict\n    :param ExtraArgs: Extra arguments that may be passed to the\n        client operation. For allowed upload arguments see\n        boto3.s3.transfer.S3Transfer.ALLOWED_UPLOAD_ARGS.\n\n    :type Callback: function\n    :param Callback: A method which takes a number of bytes transferred to\n        be periodically called during the upload.\n\n    :type Config: boto3.s3.transfer.TransferConfig\n    :param Config: The transfer configuration to be used when performing the\n        transfer.\n    \"\"\"\n    return self.meta.client.upload_file(\n        Filename=Filename,\n        Bucket=self.name,\n        Key=Key,\n        ExtraArgs=ExtraArgs,\n        Callback=Callback,\n        Config=Config,\n    )\n\n\ndef bucket_download_file(\n    self, Key, Filename, ExtraArgs=None, Callback=None, Config=None\n):\n    \"\"\"Download an S3 object to a file.\n\n    Usage::\n\n        import boto3\n        s3 = boto3.resource('s3')\n        s3.Bucket('mybucket').download_file('hello.txt', '/tmp/hello.txt')\n\n    Similar behavior as S3Transfer's download_file() method,\n    except that parameters are capitalized. Detailed examples can be found at\n    :ref:`S3Transfer's Usage <ref_s3transfer_usage>`.\n\n    :type Key: str\n    :param Key: The name of the key to download from.\n\n    :type Filename: str\n    :param Filename: The path to the file to download to.\n\n    :type ExtraArgs: dict\n    :param ExtraArgs: Extra arguments that may be passed to the\n        client operation. For allowed download arguments see\n        boto3.s3.transfer.S3Transfer.ALLOWED_DOWNLOAD_ARGS.\n\n    :type Callback: function\n    :param Callback: A method which takes a number of bytes transferred to\n        be periodically called during the download.\n\n    :type Config: boto3.s3.transfer.TransferConfig\n    :param Config: The transfer configuration to be used when performing the\n        transfer.\n    \"\"\"\n    return self.meta.client.download_file(\n        Bucket=self.name,\n        Key=Key,\n        Filename=Filename,\n        ExtraArgs=ExtraArgs,\n        Callback=Callback,\n        Config=Config,\n    )\n\n\ndef object_upload_file(\n    self, Filename, ExtraArgs=None, Callback=None, Config=None\n):\n    \"\"\"Upload a file to an S3 object.\n\n    Usage::\n\n        import boto3\n        s3 = boto3.resource('s3')\n        s3.Object('mybucket', 'hello.txt').upload_file('/tmp/hello.txt')\n\n    Similar behavior as S3Transfer's upload_file() method,\n    except that parameters are capitalized. Detailed examples can be found at\n    :ref:`S3Transfer's Usage <ref_s3transfer_usage>`.\n\n    :type Filename: str\n    :param Filename: The path to the file to upload.\n\n    :type ExtraArgs: dict\n    :param ExtraArgs: Extra arguments that may be passed to the\n        client operation. For allowed upload arguments see\n        boto3.s3.transfer.S3Transfer.ALLOWED_UPLOAD_ARGS.\n\n    :type Callback: function\n    :param Callback: A method which takes a number of bytes transferred to\n        be periodically called during the upload.\n\n    :type Config: boto3.s3.transfer.TransferConfig\n    :param Config: The transfer configuration to be used when performing the\n        transfer.\n    \"\"\"\n    return self.meta.client.upload_file(\n        Filename=Filename,\n        Bucket=self.bucket_name,\n        Key=self.key,\n        ExtraArgs=ExtraArgs,\n        Callback=Callback,\n        Config=Config,\n    )\n\n\ndef object_download_file(\n    self, Filename, ExtraArgs=None, Callback=None, Config=None\n):\n    \"\"\"Download an S3 object to a file.\n\n    Usage::\n\n        import boto3\n        s3 = boto3.resource('s3')\n        s3.Object('mybucket', 'hello.txt').download_file('/tmp/hello.txt')\n\n    Similar behavior as S3Transfer's download_file() method,\n    except that parameters are capitalized. Detailed examples can be found at\n    :ref:`S3Transfer's Usage <ref_s3transfer_usage>`.\n\n    :type Filename: str\n    :param Filename: The path to the file to download to.\n\n    :type ExtraArgs: dict\n    :param ExtraArgs: Extra arguments that may be passed to the\n        client operation. For allowed download arguments see\n        boto3.s3.transfer.S3Transfer.ALLOWED_DOWNLOAD_ARGS.\n\n    :type Callback: function\n    :param Callback: A method which takes a number of bytes transferred to\n        be periodically called during the download.\n\n    :type Config: boto3.s3.transfer.TransferConfig\n    :param Config: The transfer configuration to be used when performing the\n        transfer.\n    \"\"\"\n    return self.meta.client.download_file(\n        Bucket=self.bucket_name,\n        Key=self.key,\n        Filename=Filename,\n        ExtraArgs=ExtraArgs,\n        Callback=Callback,\n        Config=Config,\n    )\n\n\ndef copy(\n    self,\n    CopySource,\n    Bucket,\n    Key,\n    ExtraArgs=None,\n    Callback=None,\n    SourceClient=None,\n    Config=None,\n):\n    \"\"\"Copy an object from one S3 location to another.\n\n    This is a managed transfer which will perform a multipart copy in\n    multiple threads if necessary.\n\n    Usage::\n\n        import boto3\n        s3 = boto3.resource('s3')\n        copy_source = {\n            'Bucket': 'mybucket',\n            'Key': 'mykey'\n        }\n        s3.meta.client.copy(copy_source, 'otherbucket', 'otherkey')\n\n    :type CopySource: dict\n    :param CopySource: The name of the source bucket, key name of the\n        source object, and optional version ID of the source object. The\n        dictionary format is:\n        ``{'Bucket': 'bucket', 'Key': 'key', 'VersionId': 'id'}``. Note\n        that the ``VersionId`` key is optional and may be omitted.\n\n    :type Bucket: str\n    :param Bucket: The name of the bucket to copy to\n\n    :type Key: str\n    :param Key: The name of the key to copy to\n\n    :type ExtraArgs: dict\n    :param ExtraArgs: Extra arguments that may be passed to the\n        client operation. For allowed download arguments see\n        boto3.s3.transfer.S3Transfer.ALLOWED_DOWNLOAD_ARGS.\n\n    :type Callback: function\n    :param Callback: A method which takes a number of bytes transferred to\n        be periodically called during the copy.\n\n    :type SourceClient: botocore or boto3 Client\n    :param SourceClient: The client to be used for operation that\n        may happen at the source object. For example, this client is\n        used for the head_object that determines the size of the copy.\n        If no client is provided, the current client is used as the client\n        for the source object.\n\n    :type Config: boto3.s3.transfer.TransferConfig\n    :param Config: The transfer configuration to be used when performing the\n        copy.\n    \"\"\"\n    subscribers = None\n    if Callback is not None:\n        subscribers = [ProgressCallbackInvoker(Callback)]\n\n    config = Config\n    if config is None:\n        config = TransferConfig()\n\n    # copy is not supported in the CRT\n    new_config = python_copy.copy(config)\n    new_config.preferred_transfer_client = \"classic\"\n\n    with create_transfer_manager(self, new_config) as manager:\n        future = manager.copy(\n            copy_source=CopySource,\n            bucket=Bucket,\n            key=Key,\n            extra_args=ExtraArgs,\n            subscribers=subscribers,\n            source_client=SourceClient,\n        )\n        return future.result()\n\n\ndef bucket_copy(\n    self,\n    CopySource,\n    Key,\n    ExtraArgs=None,\n    Callback=None,\n    SourceClient=None,\n    Config=None,\n):\n    \"\"\"Copy an object from one S3 location to an object in this bucket.\n\n    This is a managed transfer which will perform a multipart copy in\n    multiple threads if necessary.\n\n    Usage::\n\n        import boto3\n        s3 = boto3.resource('s3')\n        copy_source = {\n            'Bucket': 'mybucket',\n            'Key': 'mykey'\n        }\n        bucket = s3.Bucket('otherbucket')\n        bucket.copy(copy_source, 'otherkey')\n\n    :type CopySource: dict\n    :param CopySource: The name of the source bucket, key name of the\n        source object, and optional version ID of the source object. The\n        dictionary format is:\n        ``{'Bucket': 'bucket', 'Key': 'key', 'VersionId': 'id'}``. Note\n        that the ``VersionId`` key is optional and may be omitted.\n\n    :type Key: str\n    :param Key: The name of the key to copy to\n\n    :type ExtraArgs: dict\n    :param ExtraArgs: Extra arguments that may be passed to the\n        client operation. For allowed download arguments see\n        boto3.s3.transfer.S3Transfer.ALLOWED_DOWNLOAD_ARGS.\n\n    :type Callback: function\n    :param Callback: A method which takes a number of bytes transferred to\n        be periodically called during the copy.\n\n    :type SourceClient: botocore or boto3 Client\n    :param SourceClient: The client to be used for operation that\n        may happen at the source object. For example, this client is\n        used for the head_object that determines the size of the copy.\n        If no client is provided, the current client is used as the client\n        for the source object.\n\n    :type Config: boto3.s3.transfer.TransferConfig\n    :param Config: The transfer configuration to be used when performing the\n        copy.\n    \"\"\"\n    return self.meta.client.copy(\n        CopySource=CopySource,\n        Bucket=self.name,\n        Key=Key,\n        ExtraArgs=ExtraArgs,\n        Callback=Callback,\n        SourceClient=SourceClient,\n        Config=Config,\n    )\n\n\ndef object_copy(\n    self,\n    CopySource,\n    ExtraArgs=None,\n    Callback=None,\n    SourceClient=None,\n    Config=None,\n):\n    \"\"\"Copy an object from one S3 location to this object.\n\n    This is a managed transfer which will perform a multipart copy in\n    multiple threads if necessary.\n\n    Usage::\n\n        import boto3\n        s3 = boto3.resource('s3')\n        copy_source = {\n            'Bucket': 'mybucket',\n            'Key': 'mykey'\n        }\n        bucket = s3.Bucket('otherbucket')\n        obj = bucket.Object('otherkey')\n        obj.copy(copy_source)\n\n    :type CopySource: dict\n    :param CopySource: The name of the source bucket, key name of the\n        source object, and optional version ID of the source object. The\n        dictionary format is:\n        ``{'Bucket': 'bucket', 'Key': 'key', 'VersionId': 'id'}``. Note\n        that the ``VersionId`` key is optional and may be omitted.\n\n    :type ExtraArgs: dict\n    :param ExtraArgs: Extra arguments that may be passed to the\n        client operation. For allowed download arguments see\n        boto3.s3.transfer.S3Transfer.ALLOWED_DOWNLOAD_ARGS.\n\n    :type Callback: function\n    :param Callback: A method which takes a number of bytes transferred to\n        be periodically called during the copy.\n\n    :type SourceClient: botocore or boto3 Client\n    :param SourceClient: The client to be used for operation that\n        may happen at the source object. For example, this client is\n        used for the head_object that determines the size of the copy.\n        If no client is provided, the current client is used as the client\n        for the source object.\n\n    :type Config: boto3.s3.transfer.TransferConfig\n    :param Config: The transfer configuration to be used when performing the\n        copy.\n    \"\"\"\n    return self.meta.client.copy(\n        CopySource=CopySource,\n        Bucket=self.bucket_name,\n        Key=self.key,\n        ExtraArgs=ExtraArgs,\n        Callback=Callback,\n        SourceClient=SourceClient,\n        Config=Config,\n    )\n\n\ndef upload_fileobj(\n    self, Fileobj, Bucket, Key, ExtraArgs=None, Callback=None, Config=None\n):\n    \"\"\"Upload a file-like object to S3.\n\n    The file-like object must be in binary mode.\n\n    This is a managed transfer which will perform a multipart upload in\n    multiple threads if necessary.\n\n    Usage::\n\n        import boto3\n        s3 = boto3.client('s3')\n\n        with open('filename', 'rb') as data:\n            s3.upload_fileobj(data, 'mybucket', 'mykey')\n\n    :type Fileobj: a file-like object\n    :param Fileobj: A file-like object to upload. At a minimum, it must\n        implement the `read` method, and must return bytes.\n\n    :type Bucket: str\n    :param Bucket: The name of the bucket to upload to.\n\n    :type Key: str\n    :param Key: The name of the key to upload to.\n\n    :type ExtraArgs: dict\n    :param ExtraArgs: Extra arguments that may be passed to the\n        client operation. For allowed upload arguments see\n        boto3.s3.transfer.S3Transfer.ALLOWED_UPLOAD_ARGS.\n\n    :type Callback: function\n    :param Callback: A method which takes a number of bytes transferred to\n        be periodically called during the upload.\n\n    :type Config: boto3.s3.transfer.TransferConfig\n    :param Config: The transfer configuration to be used when performing the\n        upload.\n    \"\"\"\n    if not hasattr(Fileobj, 'read'):\n        raise ValueError('Fileobj must implement read')\n\n    subscribers = None\n    if Callback is not None:\n        subscribers = [ProgressCallbackInvoker(Callback)]\n\n    config = Config\n    if config is None:\n        config = TransferConfig()\n\n    with create_transfer_manager(self, config) as manager:\n        future = manager.upload(\n            fileobj=Fileobj,\n            bucket=Bucket,\n            key=Key,\n            extra_args=ExtraArgs,\n            subscribers=subscribers,\n        )\n        return future.result()\n\n\ndef bucket_upload_fileobj(\n    self, Fileobj, Key, ExtraArgs=None, Callback=None, Config=None\n):\n    \"\"\"Upload a file-like object to this bucket.\n\n    The file-like object must be in binary mode.\n\n    This is a managed transfer which will perform a multipart upload in\n    multiple threads if necessary.\n\n    Usage::\n\n        import boto3\n        s3 = boto3.resource('s3')\n        bucket = s3.Bucket('mybucket')\n\n        with open('filename', 'rb') as data:\n            bucket.upload_fileobj(data, 'mykey')\n\n    :type Fileobj: a file-like object\n    :param Fileobj: A file-like object to upload. At a minimum, it must\n        implement the `read` method, and must return bytes.\n\n    :type Key: str\n    :param Key: The name of the key to upload to.\n\n    :type ExtraArgs: dict\n    :param ExtraArgs: Extra arguments that may be passed to the\n        client operation. For allowed upload arguments see\n        boto3.s3.transfer.S3Transfer.ALLOWED_UPLOAD_ARGS.\n\n    :type Callback: function\n    :param Callback: A method which takes a number of bytes transferred to\n        be periodically called during the upload.\n\n    :type Config: boto3.s3.transfer.TransferConfig\n    :param Config: The transfer configuration to be used when performing the\n        upload.\n    \"\"\"\n    return self.meta.client.upload_fileobj(\n        Fileobj=Fileobj,\n        Bucket=self.name,\n        Key=Key,\n        ExtraArgs=ExtraArgs,\n        Callback=Callback,\n        Config=Config,\n    )\n\n\ndef object_upload_fileobj(\n    self, Fileobj, ExtraArgs=None, Callback=None, Config=None\n):\n    \"\"\"Upload a file-like object to this object.\n\n    The file-like object must be in binary mode.\n\n    This is a managed transfer which will perform a multipart upload in\n    multiple threads if necessary.\n\n    Usage::\n\n        import boto3\n        s3 = boto3.resource('s3')\n        bucket = s3.Bucket('mybucket')\n        obj = bucket.Object('mykey')\n\n        with open('filename', 'rb') as data:\n            obj.upload_fileobj(data)\n\n    :type Fileobj: a file-like object\n    :param Fileobj: A file-like object to upload. At a minimum, it must\n        implement the `read` method, and must return bytes.\n\n    :type ExtraArgs: dict\n    :param ExtraArgs: Extra arguments that may be passed to the\n        client operation. For allowed upload arguments see\n        boto3.s3.transfer.S3Transfer.ALLOWED_UPLOAD_ARGS.\n\n    :type Callback: function\n    :param Callback: A method which takes a number of bytes transferred to\n        be periodically called during the upload.\n\n    :type Config: boto3.s3.transfer.TransferConfig\n    :param Config: The transfer configuration to be used when performing the\n        upload.\n    \"\"\"\n    return self.meta.client.upload_fileobj(\n        Fileobj=Fileobj,\n        Bucket=self.bucket_name,\n        Key=self.key,\n        ExtraArgs=ExtraArgs,\n        Callback=Callback,\n        Config=Config,\n    )\n\n\ndef download_fileobj(\n    self, Bucket, Key, Fileobj, ExtraArgs=None, Callback=None, Config=None\n):\n    \"\"\"Download an object from S3 to a file-like object.\n\n    The file-like object must be in binary mode.\n\n    This is a managed transfer which will perform a multipart download in\n    multiple threads if necessary.\n\n    Usage::\n\n        import boto3\n        s3 = boto3.client('s3')\n\n        with open('filename', 'wb') as data:\n            s3.download_fileobj('mybucket', 'mykey', data)\n\n    :type Bucket: str\n    :param Bucket: The name of the bucket to download from.\n\n    :type Key: str\n    :param Key: The name of the key to download from.\n\n    :type Fileobj: a file-like object\n    :param Fileobj: A file-like object to download into. At a minimum, it must\n        implement the `write` method and must accept bytes.\n\n    :type ExtraArgs: dict\n    :param ExtraArgs: Extra arguments that may be passed to the\n        client operation. For allowed download arguments see\n        boto3.s3.transfer.S3Transfer.ALLOWED_DOWNLOAD_ARGS.\n\n    :type Callback: function\n    :param Callback: A method which takes a number of bytes transferred to\n        be periodically called during the download.\n\n    :type Config: boto3.s3.transfer.TransferConfig\n    :param Config: The transfer configuration to be used when performing the\n        download.\n    \"\"\"\n    if not hasattr(Fileobj, 'write'):\n        raise ValueError('Fileobj must implement write')\n\n    subscribers = None\n    if Callback is not None:\n        subscribers = [ProgressCallbackInvoker(Callback)]\n\n    config = Config\n    if config is None:\n        config = TransferConfig()\n\n    with create_transfer_manager(self, config) as manager:\n        future = manager.download(\n            bucket=Bucket,\n            key=Key,\n            fileobj=Fileobj,\n            extra_args=ExtraArgs,\n            subscribers=subscribers,\n        )\n        return future.result()\n\n\ndef bucket_download_fileobj(\n    self, Key, Fileobj, ExtraArgs=None, Callback=None, Config=None\n):\n    \"\"\"Download an object from this bucket to a file-like-object.\n\n    The file-like object must be in binary mode.\n\n    This is a managed transfer which will perform a multipart download in\n    multiple threads if necessary.\n\n    Usage::\n\n        import boto3\n        s3 = boto3.resource('s3')\n        bucket = s3.Bucket('mybucket')\n\n        with open('filename', 'wb') as data:\n            bucket.download_fileobj('mykey', data)\n\n    :type Fileobj: a file-like object\n    :param Fileobj: A file-like object to download into. At a minimum, it must\n        implement the `write` method and must accept bytes.\n\n    :type Key: str\n    :param Key: The name of the key to download from.\n\n    :type ExtraArgs: dict\n    :param ExtraArgs: Extra arguments that may be passed to the\n        client operation. For allowed download arguments see\n        boto3.s3.transfer.S3Transfer.ALLOWED_DOWNLOAD_ARGS.\n\n    :type Callback: function\n    :param Callback: A method which takes a number of bytes transferred to\n        be periodically called during the download.\n\n    :type Config: boto3.s3.transfer.TransferConfig\n    :param Config: The transfer configuration to be used when performing the\n        download.\n    \"\"\"\n    return self.meta.client.download_fileobj(\n        Bucket=self.name,\n        Key=Key,\n        Fileobj=Fileobj,\n        ExtraArgs=ExtraArgs,\n        Callback=Callback,\n        Config=Config,\n    )\n\n\ndef object_download_fileobj(\n    self, Fileobj, ExtraArgs=None, Callback=None, Config=None\n):\n    \"\"\"Download this object from S3 to a file-like object.\n\n    The file-like object must be in binary mode.\n\n    This is a managed transfer which will perform a multipart download in\n    multiple threads if necessary.\n\n    Usage::\n\n        import boto3\n        s3 = boto3.resource('s3')\n        bucket = s3.Bucket('mybucket')\n        obj = bucket.Object('mykey')\n\n        with open('filename', 'wb') as data:\n            obj.download_fileobj(data)\n\n    :type Fileobj: a file-like object\n    :param Fileobj: A file-like object to download into. At a minimum, it must\n        implement the `write` method and must accept bytes.\n\n    :type ExtraArgs: dict\n    :param ExtraArgs: Extra arguments that may be passed to the\n        client operation. For allowed download arguments see\n        boto3.s3.transfer.S3Transfer.ALLOWED_DOWNLOAD_ARGS.\n\n    :type Callback: function\n    :param Callback: A method which takes a number of bytes transferred to\n        be periodically called during the download.\n\n    :type Config: boto3.s3.transfer.TransferConfig\n    :param Config: The transfer configuration to be used when performing the\n        download.\n    \"\"\"\n    return self.meta.client.download_fileobj(\n        Bucket=self.bucket_name,\n        Key=self.key,\n        Fileobj=Fileobj,\n        ExtraArgs=ExtraArgs,\n        Callback=Callback,\n        Config=Config,\n    )\n", "boto3/s3/transfer.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n\"\"\"Abstractions over S3's upload/download operations.\n\nThis module provides high level abstractions for efficient\nuploads/downloads.  It handles several things for the user:\n\n* Automatically switching to multipart transfers when\n  a file is over a specific size threshold\n* Uploading/downloading a file in parallel\n* Progress callbacks to monitor transfers\n* Retries.  While botocore handles retries for streaming uploads,\n  it is not possible for it to handle retries for streaming\n  downloads.  This module handles retries for both cases so\n  you don't need to implement any retry logic yourself.\n\nThis module has a reasonable set of defaults.  It also allows you\nto configure many aspects of the transfer process including:\n\n* Multipart threshold size\n* Max parallel downloads\n* Socket timeouts\n* Retry amounts\n\nThere is no support for s3->s3 multipart copies at this\ntime.\n\n\n.. _ref_s3transfer_usage:\n\nUsage\n=====\n\nThe simplest way to use this module is:\n\n.. code-block:: python\n\n    client = boto3.client('s3', 'us-west-2')\n    transfer = S3Transfer(client)\n    # Upload /tmp/myfile to s3://bucket/key\n    transfer.upload_file('/tmp/myfile', 'bucket', 'key')\n\n    # Download s3://bucket/key to /tmp/myfile\n    transfer.download_file('bucket', 'key', '/tmp/myfile')\n\nThe ``upload_file`` and ``download_file`` methods also accept\n``**kwargs``, which will be forwarded through to the corresponding\nclient operation.  Here are a few examples using ``upload_file``::\n\n    # Making the object public\n    transfer.upload_file('/tmp/myfile', 'bucket', 'key',\n                         extra_args={'ACL': 'public-read'})\n\n    # Setting metadata\n    transfer.upload_file('/tmp/myfile', 'bucket', 'key',\n                         extra_args={'Metadata': {'a': 'b', 'c': 'd'}})\n\n    # Setting content type\n    transfer.upload_file('/tmp/myfile.json', 'bucket', 'key',\n                         extra_args={'ContentType': \"application/json\"})\n\n\nThe ``S3Transfer`` class also supports progress callbacks so you can\nprovide transfer progress to users.  Both the ``upload_file`` and\n``download_file`` methods take an optional ``callback`` parameter.\nHere's an example of how to print a simple progress percentage\nto the user:\n\n.. code-block:: python\n\n    class ProgressPercentage(object):\n        def __init__(self, filename):\n            self._filename = filename\n            self._size = float(os.path.getsize(filename))\n            self._seen_so_far = 0\n            self._lock = threading.Lock()\n\n        def __call__(self, bytes_amount):\n            # To simplify we'll assume this is hooked up\n            # to a single filename.\n            with self._lock:\n                self._seen_so_far += bytes_amount\n                percentage = (self._seen_so_far / self._size) * 100\n                sys.stdout.write(\n                    \"\\r%s  %s / %s  (%.2f%%)\" % (\n                        self._filename, self._seen_so_far, self._size,\n                        percentage))\n                sys.stdout.flush()\n\n\n    transfer = S3Transfer(boto3.client('s3', 'us-west-2'))\n    # Upload /tmp/myfile to s3://bucket/key and print upload progress.\n    transfer.upload_file('/tmp/myfile', 'bucket', 'key',\n                         callback=ProgressPercentage('/tmp/myfile'))\n\n\n\nYou can also provide a TransferConfig object to the S3Transfer\nobject that gives you more fine grained control over the\ntransfer.  For example:\n\n.. code-block:: python\n\n    client = boto3.client('s3', 'us-west-2')\n    config = TransferConfig(\n        multipart_threshold=8 * 1024 * 1024,\n        max_concurrency=10,\n        num_download_attempts=10,\n    )\n    transfer = S3Transfer(client, config)\n    transfer.upload_file('/tmp/foo', 'bucket', 'key')\n\n\n\"\"\"\n\nimport logging\nimport threading\nfrom os import PathLike, fspath, getpid\n\nfrom botocore.compat import HAS_CRT\nfrom botocore.exceptions import ClientError\nfrom s3transfer.exceptions import (\n    RetriesExceededError as S3TransferRetriesExceededError,\n)\nfrom s3transfer.futures import NonThreadedExecutor\nfrom s3transfer.manager import TransferConfig as S3TransferConfig\nfrom s3transfer.manager import TransferManager\nfrom s3transfer.subscribers import BaseSubscriber\nfrom s3transfer.utils import OSUtils\n\nimport boto3.s3.constants as constants\nfrom boto3.exceptions import RetriesExceededError, S3UploadFailedError\n\nif HAS_CRT:\n    import awscrt.s3\n\n    from boto3.crt import create_crt_transfer_manager\n\nKB = 1024\nMB = KB * KB\n\nlogger = logging.getLogger(__name__)\n\n\ndef create_transfer_manager(client, config, osutil=None):\n    \"\"\"Creates a transfer manager based on configuration\n\n    :type client: boto3.client\n    :param client: The S3 client to use\n\n    :type config: boto3.s3.transfer.TransferConfig\n    :param config: The transfer config to use\n\n    :type osutil: s3transfer.utils.OSUtils\n    :param osutil: The os utility to use\n\n    :rtype: s3transfer.manager.TransferManager\n    :returns: A transfer manager based on parameters provided\n    \"\"\"\n    if _should_use_crt(config):\n        crt_transfer_manager = create_crt_transfer_manager(client, config)\n        if crt_transfer_manager is not None:\n            logger.debug(\n                f\"Using CRT client. pid: {getpid()}, thread: {threading.get_ident()}\"\n            )\n            return crt_transfer_manager\n\n    # If we don't resolve something above, fallback to the default.\n    logger.debug(\n        f\"Using default client. pid: {getpid()}, thread: {threading.get_ident()}\"\n    )\n    return _create_default_transfer_manager(client, config, osutil)\n\n\ndef _should_use_crt(config):\n    # This feature requires awscrt>=0.19.18\n    if HAS_CRT and has_minimum_crt_version((0, 19, 18)):\n        is_optimized_instance = awscrt.s3.is_optimized_for_system()\n    else:\n        is_optimized_instance = False\n    pref_transfer_client = config.preferred_transfer_client.lower()\n\n    if (\n        is_optimized_instance\n        and pref_transfer_client == constants.AUTO_RESOLVE_TRANSFER_CLIENT\n    ):\n        logger.debug(\n            \"Attempting to use CRTTransferManager. Config settings may be ignored.\"\n        )\n        return True\n\n    logger.debug(\n        \"Opting out of CRT Transfer Manager. Preferred client: \"\n        f\"{pref_transfer_client}, CRT available: {HAS_CRT}, \"\n        f\"Instance Optimized: {is_optimized_instance}.\"\n    )\n    return False\n\n\ndef has_minimum_crt_version(minimum_version):\n    \"\"\"Not intended for use outside boto3.\"\"\"\n    if not HAS_CRT:\n        return False\n\n    crt_version_str = awscrt.__version__\n    try:\n        crt_version_ints = map(int, crt_version_str.split(\".\"))\n        crt_version_tuple = tuple(crt_version_ints)\n    except (TypeError, ValueError):\n        return False\n\n    return crt_version_tuple >= minimum_version\n\n\ndef _create_default_transfer_manager(client, config, osutil):\n    \"\"\"Create the default TransferManager implementation for s3transfer.\"\"\"\n    executor_cls = None\n    if not config.use_threads:\n        executor_cls = NonThreadedExecutor\n    return TransferManager(client, config, osutil, executor_cls)\n\n\nclass TransferConfig(S3TransferConfig):\n    ALIAS = {\n        'max_concurrency': 'max_request_concurrency',\n        'max_io_queue': 'max_io_queue_size',\n    }\n\n    def __init__(\n        self,\n        multipart_threshold=8 * MB,\n        max_concurrency=10,\n        multipart_chunksize=8 * MB,\n        num_download_attempts=5,\n        max_io_queue=100,\n        io_chunksize=256 * KB,\n        use_threads=True,\n        max_bandwidth=None,\n        preferred_transfer_client=constants.AUTO_RESOLVE_TRANSFER_CLIENT,\n    ):\n        \"\"\"Configuration object for managed S3 transfers\n\n        :param multipart_threshold: The transfer size threshold for which\n            multipart uploads, downloads, and copies will automatically be\n            triggered.\n\n        :param max_concurrency: The maximum number of threads that will be\n            making requests to perform a transfer. If ``use_threads`` is\n            set to ``False``, the value provided is ignored as the transfer\n            will only ever use the current thread.\n\n        :param multipart_chunksize: The partition size of each part for a\n            multipart transfer.\n\n        :param num_download_attempts: The number of download attempts that\n            will be retried upon errors with downloading an object in S3.\n            Note that these retries account for errors that occur when\n            streaming  down the data from s3 (i.e. socket errors and read\n            timeouts that occur after receiving an OK response from s3).\n            Other retryable exceptions such as throttling errors and 5xx\n            errors are already retried by botocore (this default is 5). This\n            does not take into account the number of exceptions retried by\n            botocore.\n\n        :param max_io_queue: The maximum amount of read parts that can be\n            queued in memory to be written for a download. The size of each\n            of these read parts is at most the size of ``io_chunksize``.\n\n        :param io_chunksize: The max size of each chunk in the io queue.\n            Currently, this is size used when ``read`` is called on the\n            downloaded stream as well.\n\n        :param use_threads: If True, threads will be used when performing\n            S3 transfers. If False, no threads will be used in\n            performing transfers; all logic will be run in the current thread.\n\n        :param max_bandwidth: The maximum bandwidth that will be consumed\n            in uploading and downloading file content. The value is an integer\n            in terms of bytes per second.\n\n        :param preferred_transfer_client: String specifying preferred transfer\n            client for transfer operations.\n\n            Current supported settings are:\n              * auto (default) - Use the CRTTransferManager when calls\n                  are made with supported environment and settings.\n              * classic - Only use the origin S3TransferManager with\n                  requests. Disables possible CRT upgrade on requests.\n        \"\"\"\n        super().__init__(\n            multipart_threshold=multipart_threshold,\n            max_request_concurrency=max_concurrency,\n            multipart_chunksize=multipart_chunksize,\n            num_download_attempts=num_download_attempts,\n            max_io_queue_size=max_io_queue,\n            io_chunksize=io_chunksize,\n            max_bandwidth=max_bandwidth,\n        )\n        # Some of the argument names are not the same as the inherited\n        # S3TransferConfig so we add aliases so you can still access the\n        # old version of the names.\n        for alias in self.ALIAS:\n            setattr(self, alias, getattr(self, self.ALIAS[alias]))\n        self.use_threads = use_threads\n        self.preferred_transfer_client = preferred_transfer_client\n\n    def __setattr__(self, name, value):\n        # If the alias name is used, make sure we set the name that it points\n        # to as that is what actually is used in governing the TransferManager.\n        if name in self.ALIAS:\n            super().__setattr__(self.ALIAS[name], value)\n        # Always set the value of the actual name provided.\n        super().__setattr__(name, value)\n\n\nclass S3Transfer:\n    ALLOWED_DOWNLOAD_ARGS = TransferManager.ALLOWED_DOWNLOAD_ARGS\n    ALLOWED_UPLOAD_ARGS = TransferManager.ALLOWED_UPLOAD_ARGS\n\n    def __init__(self, client=None, config=None, osutil=None, manager=None):\n        if not client and not manager:\n            raise ValueError(\n                'Either a boto3.Client or s3transfer.manager.TransferManager '\n                'must be provided'\n            )\n        if manager and any([client, config, osutil]):\n            raise ValueError(\n                'Manager cannot be provided with client, config, '\n                'nor osutil. These parameters are mutually exclusive.'\n            )\n        if config is None:\n            config = TransferConfig()\n        if osutil is None:\n            osutil = OSUtils()\n        if manager:\n            self._manager = manager\n        else:\n            self._manager = create_transfer_manager(client, config, osutil)\n\n    def upload_file(\n        self, filename, bucket, key, callback=None, extra_args=None\n    ):\n        \"\"\"Upload a file to an S3 object.\n\n        Variants have also been injected into S3 client, Bucket and Object.\n        You don't have to use S3Transfer.upload_file() directly.\n\n        .. seealso::\n            :py:meth:`S3.Client.upload_file`\n            :py:meth:`S3.Client.upload_fileobj`\n        \"\"\"\n        if isinstance(filename, PathLike):\n            filename = fspath(filename)\n        if not isinstance(filename, str):\n            raise ValueError('Filename must be a string or a path-like object')\n\n        subscribers = self._get_subscribers(callback)\n        future = self._manager.upload(\n            filename, bucket, key, extra_args, subscribers\n        )\n        try:\n            future.result()\n        # If a client error was raised, add the backwards compatibility layer\n        # that raises a S3UploadFailedError. These specific errors were only\n        # ever thrown for upload_parts but now can be thrown for any related\n        # client error.\n        except ClientError as e:\n            raise S3UploadFailedError(\n                \"Failed to upload {} to {}: {}\".format(\n                    filename, '/'.join([bucket, key]), e\n                )\n            )\n\n    def download_file(\n        self, bucket, key, filename, extra_args=None, callback=None\n    ):\n        \"\"\"Download an S3 object to a file.\n\n        Variants have also been injected into S3 client, Bucket and Object.\n        You don't have to use S3Transfer.download_file() directly.\n\n        .. seealso::\n            :py:meth:`S3.Client.download_file`\n            :py:meth:`S3.Client.download_fileobj`\n        \"\"\"\n        if isinstance(filename, PathLike):\n            filename = fspath(filename)\n        if not isinstance(filename, str):\n            raise ValueError('Filename must be a string or a path-like object')\n\n        subscribers = self._get_subscribers(callback)\n        future = self._manager.download(\n            bucket, key, filename, extra_args, subscribers\n        )\n        try:\n            future.result()\n        # This is for backwards compatibility where when retries are\n        # exceeded we need to throw the same error from boto3 instead of\n        # s3transfer's built in RetriesExceededError as current users are\n        # catching the boto3 one instead of the s3transfer exception to do\n        # their own retries.\n        except S3TransferRetriesExceededError as e:\n            raise RetriesExceededError(e.last_exception)\n\n    def _get_subscribers(self, callback):\n        if not callback:\n            return None\n        return [ProgressCallbackInvoker(callback)]\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *args):\n        self._manager.__exit__(*args)\n\n\nclass ProgressCallbackInvoker(BaseSubscriber):\n    \"\"\"A back-compat wrapper to invoke a provided callback via a subscriber\n\n    :param callback: A callable that takes a single positional argument for\n        how many bytes were transferred.\n    \"\"\"\n\n    def __init__(self, callback):\n        self._callback = callback\n\n    def on_progress(self, bytes_transferred, **kwargs):\n        self._callback(bytes_transferred)\n", "boto3/s3/constants.py": "# Copyright 2023 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n\n\n# TransferConfig preferred_transfer_client settings\nCLASSIC_TRANSFER_CLIENT = \"classic\"\nAUTO_RESOLVE_TRANSFER_CLIENT = \"auto\"\n", "boto3/s3/__init__.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n", "docs/source/conf.py": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n#\n# Boto3 documentation build configuration file, created by\n# sphinx-quickstart on Wed Sep  3 11:11:30 2014.\n#\n# This file is execfile()d with the current directory set to its containing dir.\n#\n# Note that not all possible configuration values are present in this\n# autogenerated file.\n#\n# All configuration values have a default; values that are commented out\n# serve to show the default.\n\nimport datetime\nimport os\n\nimport boto3\nimport boto3.session\nfrom boto3.docs import generate_docs\n\ntry:\n    from botocore.docs.translator import BotoHTML5Translator\n    CUSTOM_HTML_TRANSLATOR = BotoHTML5Translator\nexcept ImportError:\n    CUSTOM_HTML_TRANSLATOR = None\n\n\nsession = boto3.session.Session(region_name='us-east-1')\ngenerate_docs(os.path.dirname(os.path.abspath(__file__)), session)\n\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n#sys.path.insert(0, os.path.abspath('.'))\n\n# -- General configuration -----------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n#needs_sphinx = '1.0'\n\n# Add any Sphinx extension module names here, as strings. They can be extensions\n# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.\nextensions = ['sphinx.ext.autodoc', 'sphinx.ext.viewcode', 'sphinx_copybutton', 'sphinx_remove_toctrees']\n\n# Remove service docs from toctree to speed up writing phase.\nremove_from_toctrees = ['reference/services/*/**/*']\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = ['_templates']\n\n# The suffix of source filenames.\nsource_suffix = '.rst'\n\n# The encoding of source files.\n#source_encoding = 'utf-8-sig'\n\n# The master toctree document.\nmaster_doc = 'index'\n\n# General information about the project.\nproject = 'Boto3'\ncurrent_year = datetime.date.today().year\ncopyright = f'{current_year}, Amazon Web Services, Inc'\n\n# The version info for the project you're documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.\n#\n# The short X.Y version.\nversion = boto3.__version__\n# The full version, including alpha/beta/rc tags.\nrelease = boto3.__version__\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#language = None\n\n# There are two options for replacing |today|: either, you set today to some\n# non-false value, then it is used:\n#today = ''\n# Else, today_fmt is used as the format for a strftime call.\n#today_fmt = '%B %d, %Y'\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\nexclude_patterns = []\n\n# The reST default role (used for this markup: `text`) to use for all documents.\n#default_role = None\n\n# If true, '()' will be appended to :func: etc. cross-reference text.\n#add_function_parentheses = True\n\n# If true, the current module name will be prepended to all description\n# unit titles (such as .. function::).\n#add_module_names = True\n\n# If true, sectionauthor and moduleauthor directives will be shown in the\n# output. They are ignored by default.\n#show_authors = False\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = \"default\"\npygments_dark_style = \"monokai\"\n\n# A list of ignored prefixes for module index sorting.\n#modindex_common_prefix = []\n\nhtml_theme = 'furo'\n\n\n\n\n# -- Options for HTML output ---------------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#html_theme = 'default'\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\nhtml_theme_options = {\n    \"footer_icons\": [\n        {\n            \"name\": \"GitHub\",\n            \"url\": \"https://github.com/boto/boto3\",\n            \"html\": \"\"\"\n                <svg stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" viewBox=\"0 0 16 16\">\n                    <path fill-rule=\"evenodd\" d=\"M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0 0 16 8c0-4.42-3.58-8-8-8z\"></path>\n                </svg>\n            \"\"\",\n            \"class\": \"\",\n        },\n    ],\n    \"light_logo\": \"logos/aws_light_theme_logo.svg\",\n    \"dark_logo\": \"logos/aws_dark_theme_logo.svg\",\n}\n\n# Add any paths that contain custom themes here, relative to this directory.\n#html_theme_path = []\n\n# The name for this set of Sphinx documents.  If None, it defaults to\n# \"<project> v<release> documentation\".\n#html_title = None\n\n# A shorter title for the navigation bar.  Default is the same as html_title.\n#html_short_title = None\n\n# The name of an image file (relative to this directory) to place at the top\n# of the sidebar.\n#html_logo = None\n\n# The name of an image file (within the static path) to use as favicon of the\n# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32\n# pixels large.\n#html_favicon = None\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named \"default.css\" will overwrite the builtin \"default.css\".\nhtml_static_path = ['_static']\n\n# List of custom CSS files relative to _static directory.\nhtml_css_files = [\n    'css/custom.css',\n]\n# List of custom JS files relative to _static directory.\nhtml_js_files = [\n    'js/custom.js',\n]\n\n# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,\n# using the given strftime format.\n#html_last_updated_fmt = '%b %d, %Y'\n\n# If true, SmartyPants will be used to convert quotes and dashes to\n# typographically correct entities.\n#html_use_smartypants = True\n\n# Custom sidebar templates, maps document names to template names.\nhtml_show_sourcelink = False\nhtml_sidebars = {\n    \"**\": [\n        \"sidebar/close-icon.html\",\n        \"sidebar/brand.html\",\n        \"sidebar/search.html\",\n        \"sidebar/scroll-start.html\",\n        \"sidebar/feedback.html\",\n        \"sidebar/navigation.html\",\n        \"sidebar/scroll-end.html\",\n    ]\n}\n\n# Additional templates that should be rendered to pages, maps page names to\n# template names.\n#html_additional_pages = {}\n\n# If false, no module index is generated.\n#html_domain_indices = True\n\n# If false, no index is generated.\n#html_use_index = True\n\n# If true, the index is split into individual pages for each letter.\n#html_split_index = False\n\n# If true, links to the reST sources are added to the pages.\n#html_show_sourcelink = True\n\n# If true, \"Created using Sphinx\" is shown in the HTML footer. Default is True.\nhtml_show_sphinx = True\n\n# If true, \"(C) Copyright ...\" is shown in the HTML footer. Default is True.\nhtml_show_copyright = True\n\n# If true, an OpenSearch description file will be output, and all pages will\n# contain a <link> tag referring to it.  The value of this option must be the\n# base URL from which the finished HTML is served.\n#html_use_opensearch = ''\n\n# This is the file name suffix for HTML files (e.g. \".xhtml\").\n#html_file_suffix = None\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = 'Boto3doc'\n\n\n# -- Options for LaTeX output --------------------------------------------------\n\nlatex_elements = {\n# The paper size ('letterpaper' or 'a4paper').\n#'papersize': 'letterpaper',\n\n# The font size ('10pt', '11pt' or '12pt').\n#'pointsize': '10pt',\n\n# Additional stuff for the LaTeX preamble.\n#'preamble': '',\n}\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title, author, documentclass [howto/manual]).\nlatex_documents = [\n  ('index', 'Boto3.tex', 'Boto3 Documentation',\n   'Amazon.com, Inc.', 'manual'),\n]\n\n# The name of an image file (relative to this directory) to place at the top of\n# the title page.\n#latex_logo = None\n\n# For \"manual\" documents, if this is true, then toplevel headings are parts,\n# not chapters.\n#latex_use_parts = False\n\n# If true, show page references after internal links.\n#latex_show_pagerefs = False\n\n# If true, show URL addresses after external links.\n#latex_show_urls = False\n\n# Documents to append as an appendix to all manuals.\n#latex_appendices = []\n\n# If false, no module index is generated.\n#latex_domain_indices = True\n\n\n# -- Options for manual page output --------------------------------------------\n\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [\n    ('index', 'boto3', 'Boto3 Documentation',\n     ['Amazon.com, Inc.'], 1)\n]\n\n# If true, show URL addresses after external links.\n#man_show_urls = False\n\n\n# -- Options for Texinfo output ------------------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n  ('index', 'Boto3', 'Boto3 Documentation',\n   'Amazon.com, Inc.', 'Boto3', 'One line description of project.',\n   'Miscellaneous'),\n]\n\n# Documents to append as an appendix to all manuals.\n#texinfo_appendices = []\n\n# If false, no module index is generated.\n#texinfo_domain_indices = True\n\n# How to display URL addresses: 'footnote', 'no', or 'inline'.\n#texinfo_show_urls = 'footnote'\n\nautoclass_content = 'both'\n\n\ndef setup(app):\n    # Register our custom HTML translator.\n    if CUSTOM_HTML_TRANSLATOR:\n        app.set_translator(\"html\", CUSTOM_HTML_TRANSLATOR)\n", "tests/__init__.py": "# Copyright 2014 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n\nimport random\nimport time\nimport unittest\nfrom unittest import mock\n\nfrom botocore.compat import HAS_CRT\n\n\ndef unique_id(name):\n    \"\"\"\n    Generate a unique ID that includes the given name,\n    a timestamp and a random number. This helps when running\n    integration tests in parallel that must create remote\n    resources.\n    \"\"\"\n    return f'{name}-{int(time.time())}-{random.randint(0, 10000)}'\n\n\nclass BaseTestCase(unittest.TestCase):\n    \"\"\"\n    A base test case which mocks out the low-level session to prevent\n    any actual calls to Botocore.\n    \"\"\"\n\n    def setUp(self):\n        self.bc_session_patch = mock.patch('botocore.session.Session')\n        self.bc_session_cls = self.bc_session_patch.start()\n\n        loader = self.bc_session_cls.return_value.get_component.return_value\n        loader.data_path = ''\n        self.loader = loader\n\n        # We also need to patch the global default session.\n        # Otherwise it could be a cached real session came from previous\n        # \"functional\" or \"integration\" tests.\n        patch_global_session = mock.patch('boto3.DEFAULT_SESSION')\n        patch_global_session.start()\n        self.addCleanup(patch_global_session.stop)\n\n    def tearDown(self):\n        self.bc_session_patch.stop()\n\n\ndef requires_crt(reason=None):\n    if reason is None:\n        reason = \"Test requires awscrt to be installed\"\n\n    def decorator(func):\n        return unittest.skipIf(not HAS_CRT, reason)(func)\n\n    return decorator\n", "tests/integration/test_collections.py": "# Copyright 2014 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n\nimport pytest\n\nimport boto3.session\nfrom boto3.resources.base import ServiceResource\nfrom boto3.resources.collection import CollectionManager\n\n# A map of services to regions that cannot use us-west-2\n# for the integration tests.\nREGION_MAP = {'opsworks': 'us-east-1'}\n\n# A list of collections to ignore. They require parameters\n# or are very slow to run.\nBLOCKLIST = {\n    'ec2': ['images'],\n    'iam': ['signing_certificates'],\n    'sqs': ['dead_letter_source_queues'],\n}\n\n\ndef all_collections():\n    # This generator yields every collection on every available resource,\n    # except those which have been blocklisted.\n    session = boto3.session.Session()\n    for service_name in session.get_available_resources():\n        resource = session.resource(\n            service_name, region_name=REGION_MAP.get(service_name, 'us-west-2')\n        )\n\n        for key in dir(resource):\n            if key in BLOCKLIST.get(service_name, []):\n                continue\n\n            value = getattr(resource, key)\n            if isinstance(value, CollectionManager):\n                yield value\n\n\n@pytest.mark.parametrize(\"collection\", all_collections())\ndef test_all_collections(collection):\n    \"\"\"Test all collections work on every available resource.\"\"\"\n    # Create a list of the first page of items. This tests that\n    # a remote request can be made, the response parsed, and that\n    # resources are successfully created.\n    collection_list = list(collection.limit(1))\n    assert len(collection_list) < 2\n    assert all([isinstance(res, ServiceResource) for res in collection_list])\n", "tests/integration/test_sqs.py": "# Copyright 2014 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n\nimport boto3.session\nfrom tests import unique_id, unittest\n\n\nclass TestSQSResource(unittest.TestCase):\n    def setUp(self):\n        self.session = boto3.session.Session(region_name='us-west-2')\n        self.sqs = self.session.resource('sqs')\n        self.queue_name = unique_id('boto3-test')\n\n    def test_sqs(self):\n        # Create a new resource\n        queue = self.sqs.create_queue(QueueName=self.queue_name)\n        self.addCleanup(queue.delete)\n\n        # Call an action\n        queue.send_message(MessageBody='test')\n\n        # Get pre-populated resources and access attributes\n        messages = queue.receive_messages(WaitTimeSeconds=1)\n\n        self.assertEqual(len(messages), 1)\n        self.addCleanup(messages[0].delete)\n\n        self.assertEqual(queue.url, messages[0].queue_url)\n        self.assertEqual('test', messages[0].body)\n", "tests/integration/test_dynamodb.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom decimal import Decimal\n\nimport boto3.session\nfrom boto3.compat import collections_abc\nfrom boto3.dynamodb.conditions import Attr, Key\nfrom boto3.dynamodb.types import Binary\nfrom tests import unique_id, unittest\n\n\nclass BaseDynamoDBTest(unittest.TestCase):\n    @classmethod\n    def setUpClass(cls):\n        cls.session = boto3.session.Session(region_name='us-west-2')\n        cls.dynamodb = cls.session.resource('dynamodb')\n        cls.table_name = unique_id('boto3db')\n        cls.item_data = {\n            'MyHashKey': 'mykey',\n            'MyNull': None,\n            'MyBool': True,\n            'MyString': 'mystring',\n            'MyNumber': Decimal('1.25'),\n            'MyBinary': Binary(b'\\x01'),\n            'MyStringSet': {'foo'},\n            'MyNumberSet': {Decimal('1.25')},\n            'MyBinarySet': {Binary(b'\\x01')},\n            'MyList': ['foo'],\n            'MyMap': {'foo': 'bar'},\n        }\n        cls.table = cls.dynamodb.create_table(\n            TableName=cls.table_name,\n            ProvisionedThroughput={\n                \"ReadCapacityUnits\": 5,\n                \"WriteCapacityUnits\": 5,\n            },\n            KeySchema=[{\"AttributeName\": \"MyHashKey\", \"KeyType\": \"HASH\"}],\n            AttributeDefinitions=[\n                {\"AttributeName\": \"MyHashKey\", \"AttributeType\": \"S\"}\n            ],\n        )\n        waiter = cls.dynamodb.meta.client.get_waiter('table_exists')\n        waiter.wait(TableName=cls.table_name)\n\n    @classmethod\n    def tearDownClass(cls):\n        cls.table.delete()\n\n\nclass TestDynamoDBTypes(BaseDynamoDBTest):\n    def test_put_get_item(self):\n        self.table.put_item(Item=self.item_data)\n        self.addCleanup(self.table.delete_item, Key={'MyHashKey': 'mykey'})\n        response = self.table.get_item(\n            Key={'MyHashKey': 'mykey'}, ConsistentRead=True\n        )\n        self.assertEqual(response['Item'], self.item_data)\n\n\nclass TestDynamoDBConditions(BaseDynamoDBTest):\n    @classmethod\n    def setUpClass(cls):\n        super().setUpClass()\n        cls.table.put_item(Item=cls.item_data)\n\n    @classmethod\n    def tearDownClass(cls):\n        cls.table.delete_item(Key={'MyHashKey': 'mykey'})\n        super().tearDownClass()\n\n    def scan(self, filter_expression):\n        return self.table.scan(\n            FilterExpression=filter_expression, ConsistentRead=True\n        )\n\n    def query(self, key_condition_expression, filter_expression=None):\n        kwargs = {\n            'KeyConditionExpression': key_condition_expression,\n            'ConsistentRead': True,\n        }\n        if filter_expression is not None:\n            kwargs['FilterExpression'] = filter_expression\n        return self.table.query(**kwargs)\n\n    def test_filter_expression(self):\n        r = self.scan(filter_expression=Attr('MyHashKey').eq('mykey'))\n        self.assertEqual(r['Items'][0]['MyHashKey'], 'mykey')\n\n    def test_key_condition_expression(self):\n        r = self.query(key_condition_expression=Key('MyHashKey').eq('mykey'))\n        self.assertEqual(r['Items'][0]['MyHashKey'], 'mykey')\n\n    def test_key_condition_with_filter_condition_expression(self):\n        r = self.query(\n            key_condition_expression=Key('MyHashKey').eq('mykey'),\n            filter_expression=Attr('MyString').eq('mystring'),\n        )\n        self.assertEqual(r['Items'][0]['MyString'], 'mystring')\n\n    def test_condition_less_than(self):\n        r = self.scan(filter_expression=Attr('MyNumber').lt(Decimal('1.26')))\n        self.assertTrue(r['Items'][0]['MyNumber'] < Decimal('1.26'))\n\n    def test_condition_less_than_equal(self):\n        r = self.scan(filter_expression=Attr('MyNumber').lte(Decimal('1.26')))\n        self.assertTrue(r['Items'][0]['MyNumber'] <= Decimal('1.26'))\n\n    def test_condition_greater_than(self):\n        r = self.scan(filter_expression=Attr('MyNumber').gt(Decimal('1.24')))\n        self.assertTrue(r['Items'][0]['MyNumber'] > Decimal('1.24'))\n\n    def test_condition_greater_than_equal(self):\n        r = self.scan(filter_expression=Attr('MyNumber').gte(Decimal('1.24')))\n        self.assertTrue(r['Items'][0]['MyNumber'] >= Decimal('1.24'))\n\n    def test_condition_begins_with(self):\n        r = self.scan(filter_expression=Attr('MyString').begins_with('my'))\n        self.assertTrue(r['Items'][0]['MyString'].startswith('my'))\n\n    def test_condition_between(self):\n        r = self.scan(\n            filter_expression=Attr('MyNumber').between(\n                Decimal('1.24'), Decimal('1.26')\n            )\n        )\n        self.assertTrue(r['Items'][0]['MyNumber'] > Decimal('1.24'))\n        self.assertTrue(r['Items'][0]['MyNumber'] < Decimal('1.26'))\n\n    def test_condition_not_equal(self):\n        r = self.scan(filter_expression=Attr('MyHashKey').ne('notmykey'))\n        self.assertNotEqual(r['Items'][0]['MyHashKey'], 'notmykey')\n\n    def test_condition_in(self):\n        r = self.scan(\n            filter_expression=Attr('MyHashKey').is_in(['notmykey', 'mykey'])\n        )\n        self.assertIn(r['Items'][0]['MyHashKey'], ['notmykey', 'mykey'])\n\n    def test_condition_exists(self):\n        r = self.scan(filter_expression=Attr('MyString').exists())\n        self.assertIn('MyString', r['Items'][0])\n\n    def test_condition_not_exists(self):\n        r = self.scan(filter_expression=Attr('MyFakeKey').not_exists())\n        self.assertNotIn('MyFakeKey', r['Items'][0])\n\n    def test_condition_contains(self):\n        r = self.scan(filter_expression=Attr('MyString').contains('my'))\n        self.assertIn('my', r['Items'][0]['MyString'])\n\n    def test_condition_size(self):\n        r = self.scan(\n            filter_expression=Attr('MyString').size().eq(len('mystring'))\n        )\n        self.assertEqual(len(r['Items'][0]['MyString']), len('mystring'))\n\n    def test_condition_attribute_type(self):\n        r = self.scan(filter_expression=Attr('MyMap').attribute_type('M'))\n        self.assertIsInstance(r['Items'][0]['MyMap'], collections_abc.Mapping)\n\n    def test_condition_and(self):\n        r = self.scan(\n            filter_expression=(\n                Attr('MyHashKey').eq('mykey') & Attr('MyString').eq('mystring')\n            )\n        )\n        item = r['Items'][0]\n        self.assertTrue(\n            item['MyHashKey'] == 'mykey' and item['MyString'] == 'mystring'\n        )\n\n    def test_condition_or(self):\n        r = self.scan(\n            filter_expression=(\n                Attr('MyHashKey').eq('mykey2')\n                | Attr('MyString').eq('mystring')\n            )\n        )\n        item = r['Items'][0]\n        self.assertTrue(\n            item['MyHashKey'] == 'mykey2' or item['MyString'] == 'mystring'\n        )\n\n    def test_condition_not(self):\n        r = self.scan(filter_expression=(~Attr('MyHashKey').eq('mykey2')))\n        item = r['Items'][0]\n        self.assertTrue(item['MyHashKey'] != 'mykey2')\n\n    def test_condition_in_map(self):\n        r = self.scan(filter_expression=Attr('MyMap.foo').eq('bar'))\n        self.assertEqual(r['Items'][0]['MyMap']['foo'], 'bar')\n\n    def test_condition_in_list(self):\n        r = self.scan(filter_expression=Attr('MyList[0]').eq('foo'))\n        self.assertEqual(r['Items'][0]['MyList'][0], 'foo')\n\n\nclass TestDynamodbBatchWrite(BaseDynamoDBTest):\n    def test_batch_write_items(self):\n        num_elements = 1000\n        items = []\n        for i in range(num_elements):\n            items.append({'MyHashKey': f'foo{i}', 'OtherKey': f'bar{i}'})\n        with self.table.batch_writer() as batch:\n            for item in items:\n                batch.put_item(Item=item)\n\n        # Verify all the items were added to dynamodb.\n        for obj in self.table.scan(ConsistentRead=True)['Items']:\n            self.assertIn(obj, items)\n", "tests/integration/test_s3.py": "# Copyright 2014 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport datetime\nimport hashlib\nimport io\nimport logging\nimport math\nimport os\nimport shutil\nimport string\nimport tempfile\nimport threading\nfrom pathlib import Path\n\nfrom botocore.client import Config\n\nimport boto3.s3.transfer\nimport boto3.session\nfrom tests import unique_id, unittest\n\nLOG = logging.getLogger('boto3.tests.integration')\n\n\ndef assert_files_equal(first, second):\n    if os.path.getsize(first) != os.path.getsize(second):\n        raise AssertionError(f\"Files are not equal: {first}, {second}\")\n    first_md5 = md5_checksum(first)\n    second_md5 = md5_checksum(second)\n    if first_md5 != second_md5:\n        raise AssertionError(\n            f\"Files are not equal: {first}(md5={first_md5}) != {second}(md5={second_md5})\"\n        )\n\n\ndef md5_checksum(filename):\n    checksum = hashlib.md5()\n    with open(filename, 'rb') as f:\n        for chunk in iter(lambda: f.read(8192), b''):\n            checksum.update(chunk)\n    return checksum.hexdigest()\n\n\ndef random_bucket_name(prefix='boto3-transfer', num_chars=10):\n    base = string.ascii_lowercase + string.digits\n    random_bytes = bytearray(os.urandom(num_chars))\n    return prefix + ''.join([base[b % len(base)] for b in random_bytes])\n\n\n_SHARED_BUCKET = random_bucket_name()\n_DEFAULT_REGION = 'us-west-2'\n\n\ndef setup_module():\n    s3 = boto3.client('s3')\n    waiter = s3.get_waiter('bucket_exists')\n    params = {\n        'Bucket': _SHARED_BUCKET,\n        'CreateBucketConfiguration': {\n            'LocationConstraint': _DEFAULT_REGION,\n        },\n        'ObjectOwnership': 'ObjectWriter',\n    }\n    try:\n        s3.create_bucket(**params)\n    except Exception as e:\n        # A create_bucket can fail for a number of reasons.\n        # We're going to defer to the waiter below to make the\n        # final call as to whether or not the bucket exists.\n        LOG.debug(\"create_bucket() raised an exception: %s\", e, exc_info=True)\n    waiter.wait(Bucket=_SHARED_BUCKET)\n    s3.delete_public_access_block(Bucket=_SHARED_BUCKET)\n\n\ndef clear_out_bucket(bucket, region, delete_bucket=False):\n    s3 = boto3.client('s3', region_name=region)\n    page = s3.get_paginator('list_objects')\n    # Use pages paired with batch delete_objects().\n    for page in page.paginate(Bucket=bucket):\n        keys = [{'Key': obj['Key']} for obj in page.get('Contents', [])]\n        if keys:\n            s3.delete_objects(Bucket=bucket, Delete={'Objects': keys})\n    if delete_bucket:\n        try:\n            s3.delete_bucket(Bucket=bucket)\n        except Exception as e:\n            # We can sometimes get exceptions when trying to\n            # delete a bucket.  We'll let the waiter make\n            # the final call as to whether the bucket was able\n            # to be deleted.\n            LOG.debug(\n                \"delete_bucket() raised an exception: %s\", e, exc_info=True\n            )\n            waiter = s3.get_waiter('bucket_not_exists')\n            waiter.wait(Bucket=bucket)\n\n\ndef teardown_module():\n    clear_out_bucket(_SHARED_BUCKET, _DEFAULT_REGION, delete_bucket=True)\n\n\nclass FileCreator:\n    def __init__(self):\n        self.rootdir = tempfile.mkdtemp()\n\n    def remove_all(self):\n        shutil.rmtree(self.rootdir)\n\n    def create_file(self, filename, contents, mode='w'):\n        \"\"\"Creates a file in a tmpdir\n\n        ``filename`` should be a relative path, e.g. \"foo/bar/baz.txt\"\n        It will be translated into a full path in a tmp dir.\n\n        ``mode`` is the mode the file should be opened either as ``w`` or\n        `wb``.\n\n        Returns the full path to the file.\n\n        \"\"\"\n        full_path = os.path.join(self.rootdir, filename)\n        if not os.path.isdir(os.path.dirname(full_path)):\n            os.makedirs(os.path.dirname(full_path))\n        with open(full_path, mode) as f:\n            f.write(contents)\n        return full_path\n\n    def create_file_with_size(self, filename, filesize):\n        filename = self.create_file(filename, contents='')\n        chunksize = 8192\n        with open(filename, 'wb') as f:\n            for i in range(int(math.ceil(filesize / float(chunksize)))):\n                f.write(b'a' * chunksize)\n        return filename\n\n    def append_file(self, filename, contents):\n        \"\"\"Append contents to a file\n\n        ``filename`` should be a relative path, e.g. \"foo/bar/baz.txt\"\n        It will be translated into a full path in a tmp dir.\n\n        Returns the full path to the file.\n        \"\"\"\n        full_path = os.path.join(self.rootdir, filename)\n        if not os.path.isdir(os.path.dirname(full_path)):\n            os.makedirs(os.path.dirname(full_path))\n        with open(full_path, 'a') as f:\n            f.write(contents)\n        return full_path\n\n    def full_path(self, filename):\n        \"\"\"Translate relative path to full path in temp dir.\n\n        f.full_path('foo/bar.txt') -> /tmp/asdfasd/foo/bar.txt\n        \"\"\"\n        return os.path.join(self.rootdir, filename)\n\n\nclass TestS3Resource(unittest.TestCase):\n    def setUp(self):\n        self.region = _DEFAULT_REGION\n        self.bucket_name = _SHARED_BUCKET\n        clear_out_bucket(self.bucket_name, self.region)\n        self.session = boto3.session.Session(region_name=self.region)\n        self.s3 = self.session.resource('s3')\n        self.bucket = self.s3.Bucket(self.bucket_name)\n\n    def create_bucket_resource(self, bucket_name=None, region=None):\n        if bucket_name is None:\n            bucket_name = random_bucket_name()\n\n        if region is None:\n            region = self.region\n\n        kwargs = {'Bucket': bucket_name}\n\n        if region != 'us-east-1':\n            kwargs['CreateBucketConfiguration'] = {\n                'LocationConstraint': region\n            }\n        bucket = self.s3.create_bucket(**kwargs)\n        self.addCleanup(bucket.delete)\n\n        for _ in range(3):\n            bucket.wait_until_exists()\n        return bucket\n\n    def test_s3(self):\n        client = self.s3.meta.client\n\n        # Create an object\n        obj = self.bucket.Object('test.txt')\n        obj.put(Body='hello, world')\n        waiter = client.get_waiter('object_exists')\n        waiter.wait(Bucket=self.bucket_name, Key='test.txt')\n        self.addCleanup(obj.delete)\n\n        # List objects and make sure ours is present\n        self.assertIn('test.txt', [o.key for o in self.bucket.objects.all()])\n\n        # Lazy-loaded attribute\n        self.assertEqual(12, obj.content_length)\n\n        # Load a similar attribute from the collection response\n        self.assertEqual(12, list(self.bucket.objects.all())[0].size)\n\n        # Perform a resource action with a low-level response\n        self.assertEqual(b'hello, world', obj.get()['Body'].read())\n\n    def test_s3_resource_waiter(self):\n        # Create a bucket\n        bucket_name = random_bucket_name()\n        bucket = self.create_bucket_resource(bucket_name)\n        # Wait till the bucket exists\n        bucket.wait_until_exists()\n        # Confirm the bucket exists by finding it in a list of all of our\n        # buckets\n        self.assertIn(bucket_name, [b.name for b in self.s3.buckets.all()])\n\n        # Create an object\n        obj = bucket.Object('test.txt')\n        obj.put(Body='hello, world')\n        self.addCleanup(obj.delete)\n\n        # Wait till the bucket exists\n        obj.wait_until_exists()\n\n        # List objects and make sure ours is present\n        self.assertIn('test.txt', [o.key for o in bucket.objects.all()])\n\n    def test_can_create_object_directly(self):\n        obj = self.s3.Object(self.bucket_name, 'test.txt')\n\n        self.assertEqual(obj.bucket_name, self.bucket_name)\n        self.assertEqual(obj.key, 'test.txt')\n\n    def test_s3_multipart(self):\n        # Create the multipart upload\n        mpu = self.bucket.Object('mp-test.txt').initiate_multipart_upload()\n        self.addCleanup(mpu.abort)\n\n        # Create and upload a part\n        part = mpu.Part(1)\n        response = part.upload(Body='hello, world!')\n\n        # Complete the upload, which requires info on all of the parts\n        part_info = {'Parts': [{'PartNumber': 1, 'ETag': response['ETag']}]}\n\n        mpu.complete(MultipartUpload=part_info)\n        self.addCleanup(self.bucket.Object('mp-test.txt').delete)\n\n        contents = self.bucket.Object('mp-test.txt').get()['Body'].read()\n        self.assertEqual(contents, b'hello, world!')\n\n    def test_s3_batch_delete(self):\n        bucket = self.create_bucket_resource()\n        bucket.Versioning().enable()\n\n        # Create several versions of an object\n        obj = self.bucket.Object('test.txt')\n        for i in range(10):\n            obj.put(Body=f\"Version {i}\")\n\n            # Delete all the versions of the object\n            bucket.object_versions.all().delete()\n\n        versions = list(bucket.object_versions.all())\n        self.assertEqual(len(versions), 0)\n\n\nclass TestS3Transfers(unittest.TestCase):\n    \"\"\"Tests for the high level boto3.s3.transfer module.\"\"\"\n\n    def setUp(self):\n        self.region = _DEFAULT_REGION\n        self.bucket_name = _SHARED_BUCKET\n        clear_out_bucket(self.bucket_name, self.region)\n        self.session = boto3.session.Session(region_name=self.region)\n        self.client = self.session.client('s3', self.region)\n        self.files = FileCreator()\n        self.progress = 0\n\n    def tearDown(self):\n        self.files.remove_all()\n\n    def delete_object(self, key):\n        self.client.delete_object(Bucket=self.bucket_name, Key=key)\n\n    def object_exists(self, key):\n        waiter = self.client.get_waiter('object_exists')\n        waiter.wait(Bucket=self.bucket_name, Key=key)\n        return True\n\n    def wait_until_object_exists(\n        self, key_name, extra_params=None, min_successes=3\n    ):\n        waiter = self.client.get_waiter('object_exists')\n        params = {'Bucket': self.bucket_name, 'Key': key_name}\n        if extra_params is not None:\n            params.update(extra_params)\n        for _ in range(min_successes):\n            waiter.wait(**params)\n\n    def create_s3_transfer(self, config=None):\n        return boto3.s3.transfer.S3Transfer(self.client, config=config)\n\n    def assert_has_public_read_acl(self, response):\n        grants = response['Grants']\n        public_read = [\n            g['Grantee'].get('URI', '')\n            for g in grants\n            if g['Permission'] == 'READ'\n        ]\n        self.assertIn('groups/global/AllUsers', public_read[0])\n\n    def test_copy(self):\n        self.client.put_object(\n            Bucket=self.bucket_name, Key='foo', Body='beach'\n        )\n        self.addCleanup(self.delete_object, 'foo')\n\n        self.client.copy(\n            CopySource={'Bucket': self.bucket_name, 'Key': 'foo'},\n            Bucket=self.bucket_name,\n            Key='bar',\n        )\n        self.addCleanup(self.delete_object, 'bar')\n\n        self.object_exists('bar')\n\n    def test_upload_fileobj(self):\n        fileobj = io.BytesIO(b'foo')\n        self.client.upload_fileobj(\n            Fileobj=fileobj, Bucket=self.bucket_name, Key='foo'\n        )\n        self.addCleanup(self.delete_object, 'foo')\n\n        self.object_exists('foo')\n\n    def test_upload_fileobj_progress(self):\n        # This has to be an integration test because the fileobj will never\n        # actually be read from when using the stubber and therefore the\n        # progress callbacks will not be invoked.\n        chunksize = 5 * (1024**2)\n        config = boto3.s3.transfer.TransferConfig(\n            multipart_chunksize=chunksize,\n            multipart_threshold=chunksize,\n            max_concurrency=1,\n        )\n        fileobj = io.BytesIO(b'0' * (chunksize * 3))\n\n        def progress_callback(amount):\n            self.progress += amount\n\n        self.client.upload_fileobj(\n            Fileobj=fileobj,\n            Bucket=self.bucket_name,\n            Key='foo',\n            Config=config,\n            Callback=progress_callback,\n        )\n        self.addCleanup(self.delete_object, 'foo')\n\n        self.object_exists('foo')\n        self.assertEqual(self.progress, chunksize * 3)\n\n    def test_download_fileobj(self):\n        fileobj = io.BytesIO()\n        self.client.put_object(\n            Bucket=self.bucket_name, Key='foo', Body=b'beach'\n        )\n        self.addCleanup(self.delete_object, 'foo')\n\n        self.wait_until_object_exists('foo')\n        self.client.download_fileobj(\n            Bucket=self.bucket_name, Key='foo', Fileobj=fileobj\n        )\n\n        self.assertEqual(fileobj.getvalue(), b'beach')\n\n    def test_upload_via_path(self):\n        transfer = self.create_s3_transfer()\n        filename = self.files.create_file_with_size('path.txt', filesize=1024)\n        transfer.upload_file(Path(filename), self.bucket_name, 'path.txt')\n        self.addCleanup(self.delete_object, 'path.txt')\n        self.assertTrue(self.object_exists('path.txt'))\n\n    def test_upload_below_threshold(self):\n        config = boto3.s3.transfer.TransferConfig(\n            multipart_threshold=2 * 1024 * 1024\n        )\n        transfer = self.create_s3_transfer(config)\n        filename = self.files.create_file_with_size(\n            'foo.txt', filesize=1024 * 1024\n        )\n        transfer.upload_file(filename, self.bucket_name, 'foo.txt')\n        self.addCleanup(self.delete_object, 'foo.txt')\n        self.assertTrue(self.object_exists('foo.txt'))\n\n    def test_upload_above_threshold(self):\n        config = boto3.s3.transfer.TransferConfig(\n            multipart_threshold=2 * 1024 * 1024\n        )\n        transfer = self.create_s3_transfer(config)\n        filename = self.files.create_file_with_size(\n            '20mb.txt', filesize=20 * 1024 * 1024\n        )\n        transfer.upload_file(filename, self.bucket_name, '20mb.txt')\n        self.addCleanup(self.delete_object, '20mb.txt')\n        self.assertTrue(self.object_exists('20mb.txt'))\n\n    def test_upload_file_above_threshold_with_acl(self):\n        config = boto3.s3.transfer.TransferConfig(\n            multipart_threshold=5 * 1024 * 1024\n        )\n        transfer = self.create_s3_transfer(config)\n        filename = self.files.create_file_with_size(\n            '6mb.txt', filesize=6 * 1024 * 1024\n        )\n        extra_args = {'ACL': 'public-read'}\n        transfer.upload_file(\n            filename, self.bucket_name, '6mb.txt', extra_args=extra_args\n        )\n        self.addCleanup(self.delete_object, '6mb.txt')\n\n        self.assertTrue(self.object_exists('6mb.txt'))\n        response = self.client.get_object_acl(\n            Bucket=self.bucket_name, Key='6mb.txt'\n        )\n        self.assert_has_public_read_acl(response)\n\n    def test_upload_file_above_threshold_with_ssec(self):\n        key_bytes = os.urandom(32)\n        extra_args = {\n            'SSECustomerKey': key_bytes,\n            'SSECustomerAlgorithm': 'AES256',\n        }\n        config = boto3.s3.transfer.TransferConfig(\n            multipart_threshold=5 * 1024 * 1024\n        )\n        transfer = self.create_s3_transfer(config)\n        filename = self.files.create_file_with_size(\n            '6mb.txt', filesize=6 * 1024 * 1024\n        )\n        transfer.upload_file(\n            filename, self.bucket_name, '6mb.txt', extra_args=extra_args\n        )\n        self.addCleanup(self.delete_object, '6mb.txt')\n        # A head object will fail if it has a customer key\n        # associated with it and it's not provided in the HeadObject\n        # request so we can use this to verify our functionality.\n        response = self.client.head_object(\n            Bucket=self.bucket_name, Key='6mb.txt', **extra_args\n        )\n        self.assertEqual(response['SSECustomerAlgorithm'], 'AES256')\n\n    def test_progress_callback_on_upload(self):\n        self.amount_seen = 0\n        lock = threading.Lock()\n\n        def progress_callback(amount):\n            with lock:\n                self.amount_seen += amount\n\n        transfer = self.create_s3_transfer()\n        filename = self.files.create_file_with_size(\n            '20mb.txt', filesize=20 * 1024 * 1024\n        )\n        transfer.upload_file(\n            filename, self.bucket_name, '20mb.txt', callback=progress_callback\n        )\n        self.addCleanup(self.delete_object, '20mb.txt')\n\n        # The callback should have been called enough times such that\n        # the total amount of bytes we've seen (via the \"amount\"\n        # arg to the callback function) should be the size\n        # of the file we uploaded.\n        self.assertEqual(self.amount_seen, 20 * 1024 * 1024)\n\n    def test_callback_called_once_with_sigv4(self):\n        # Verify #98, where the callback was being invoked\n        # twice when using signature version 4.\n        self.amount_seen = 0\n        lock = threading.Lock()\n\n        def progress_callback(amount):\n            with lock:\n                self.amount_seen += amount\n\n        client = self.session.client(\n            's3', self.region, config=Config(signature_version='s3v4')\n        )\n        transfer = boto3.s3.transfer.S3Transfer(client)\n        filename = self.files.create_file_with_size(\n            '10mb.txt', filesize=10 * 1024 * 1024\n        )\n        transfer.upload_file(\n            filename, self.bucket_name, '10mb.txt', callback=progress_callback\n        )\n        self.addCleanup(self.delete_object, '10mb.txt')\n\n        self.assertEqual(self.amount_seen, 10 * 1024 * 1024)\n\n    def test_can_send_extra_params_on_upload(self):\n        transfer = self.create_s3_transfer()\n        filename = self.files.create_file_with_size('foo.txt', filesize=1024)\n        transfer.upload_file(\n            filename,\n            self.bucket_name,\n            'foo.txt',\n            extra_args={'ACL': 'public-read'},\n        )\n        self.addCleanup(self.delete_object, 'foo.txt')\n\n        response = self.client.get_object_acl(\n            Bucket=self.bucket_name, Key='foo.txt'\n        )\n        self.assert_has_public_read_acl(response)\n\n    def test_can_configure_threshold(self):\n        config = boto3.s3.transfer.TransferConfig(\n            multipart_threshold=6 * 1024 * 1024\n        )\n        transfer = self.create_s3_transfer(config)\n        filename = self.files.create_file_with_size(\n            'foo.txt', filesize=8 * 1024 * 1024\n        )\n        transfer.upload_file(filename, self.bucket_name, 'foo.txt')\n        self.addCleanup(self.delete_object, 'foo.txt')\n\n        self.assertTrue(self.object_exists('foo.txt'))\n\n    def test_can_send_extra_params_on_download(self):\n        # We're picking the customer provided sse feature\n        # of S3 to test the extra_args functionality of\n        # S3.\n        key_bytes = os.urandom(32)\n        extra_args = {\n            'SSECustomerKey': key_bytes,\n            'SSECustomerAlgorithm': 'AES256',\n        }\n        self.client.put_object(\n            Bucket=self.bucket_name,\n            Key='foo.txt',\n            Body=b'hello world',\n            **extra_args,\n        )\n        self.addCleanup(self.delete_object, 'foo.txt')\n        transfer = self.create_s3_transfer()\n\n        download_path = os.path.join(self.files.rootdir, 'downloaded.txt')\n        self.wait_until_object_exists('foo.txt', extra_params=extra_args)\n        transfer.download_file(\n            self.bucket_name, 'foo.txt', download_path, extra_args=extra_args\n        )\n        with open(download_path, 'rb') as f:\n            self.assertEqual(f.read(), b'hello world')\n\n    def test_progress_callback_on_download(self):\n        self.amount_seen = 0\n        lock = threading.Lock()\n\n        def progress_callback(amount):\n            with lock:\n                self.amount_seen += amount\n\n        transfer = self.create_s3_transfer()\n        filename = self.files.create_file_with_size(\n            '20mb.txt', filesize=20 * 1024 * 1024\n        )\n        with open(filename, 'rb') as f:\n            self.client.put_object(\n                Bucket=self.bucket_name, Key='20mb.txt', Body=f\n            )\n        self.addCleanup(self.delete_object, '20mb.txt')\n\n        download_path = os.path.join(self.files.rootdir, 'downloaded.txt')\n        transfer.download_file(\n            self.bucket_name,\n            '20mb.txt',\n            download_path,\n            callback=progress_callback,\n        )\n\n        self.assertEqual(self.amount_seen, 20 * 1024 * 1024)\n\n    def test_download_below_threshold(self):\n        transfer = self.create_s3_transfer()\n\n        filename = self.files.create_file_with_size(\n            'foo.txt', filesize=1024 * 1024\n        )\n        with open(filename, 'rb') as f:\n            self.client.put_object(\n                Bucket=self.bucket_name, Key='foo.txt', Body=f\n            )\n            self.addCleanup(self.delete_object, 'foo.txt')\n\n        download_path = os.path.join(self.files.rootdir, 'downloaded.txt')\n        self.wait_until_object_exists('foo.txt')\n        transfer.download_file(self.bucket_name, 'foo.txt', download_path)\n        assert_files_equal(filename, download_path)\n\n    def test_download_above_threshold(self):\n        transfer = self.create_s3_transfer()\n\n        filename = self.files.create_file_with_size(\n            'foo.txt', filesize=20 * 1024 * 1024\n        )\n        with open(filename, 'rb') as f:\n            self.client.put_object(\n                Bucket=self.bucket_name, Key='foo.txt', Body=f\n            )\n            self.addCleanup(self.delete_object, 'foo.txt')\n\n        download_path = os.path.join(self.files.rootdir, 'downloaded.txt')\n        self.wait_until_object_exists('foo.txt')\n        transfer.download_file(self.bucket_name, 'foo.txt', download_path)\n        assert_files_equal(filename, download_path)\n\n    def test_download_file_with_directory_not_exist(self):\n        transfer = self.create_s3_transfer()\n        self.client.put_object(\n            Bucket=self.bucket_name, Key='foo.txt', Body=b'foo'\n        )\n        self.addCleanup(self.delete_object, 'foo.txt')\n        download_path = os.path.join(\n            self.files.rootdir, 'a', 'b', 'c', 'downloaded.txt'\n        )\n        self.wait_until_object_exists('foo.txt')\n        with self.assertRaises(IOError):\n            transfer.download_file(self.bucket_name, 'foo.txt', download_path)\n\n    def test_download_large_file_directory_not_exist(self):\n        transfer = self.create_s3_transfer()\n\n        filename = self.files.create_file_with_size(\n            'foo.txt', filesize=20 * 1024 * 1024\n        )\n        with open(filename, 'rb') as f:\n            self.client.put_object(\n                Bucket=self.bucket_name, Key='foo.txt', Body=f\n            )\n            self.addCleanup(self.delete_object, 'foo.txt')\n        download_path = os.path.join(\n            self.files.rootdir, 'a', 'b', 'c', 'downloaded.txt'\n        )\n        self.wait_until_object_exists('foo.txt')\n        with self.assertRaises(IOError):\n            transfer.download_file(self.bucket_name, 'foo.txt', download_path)\n\n    def test_transfer_methods_through_client(self):\n        # This is really just a sanity check to ensure that the interface\n        # from the clients work.  We're not exhaustively testing through\n        # this client interface.\n        filename = self.files.create_file_with_size(\n            'foo.txt', filesize=1024 * 1024\n        )\n        self.client.upload_file(\n            Filename=filename, Bucket=self.bucket_name, Key='foo.txt'\n        )\n        self.addCleanup(self.delete_object, 'foo.txt')\n\n        download_path = os.path.join(self.files.rootdir, 'downloaded.txt')\n        self.wait_until_object_exists('foo.txt')\n        self.client.download_file(\n            Bucket=self.bucket_name, Key='foo.txt', Filename=download_path\n        )\n        assert_files_equal(filename, download_path)\n\n    def test_transfer_methods_do_not_use_threads(self):\n        # This is just a smoke test to make sure that\n        # setting use_threads to False has no issues transferring files as\n        # the non-threaded implementation is ran under the same integration\n        # and functional tests in s3transfer as the normal threaded\n        # implementation\n        #\n        # The methods used are arbitrary other than one of the methods\n        # use ``boto3.s3.transfer.S3Transfer`` and the other should be\n        # using ``s3transfer.manager.TransferManager`` directly\n        content = b'my content'\n        filename = self.files.create_file('myfile', content.decode('utf-8'))\n        key = 'foo'\n        config = boto3.s3.transfer.TransferConfig(use_threads=False)\n\n        self.client.upload_file(\n            Bucket=self.bucket_name, Key=key, Filename=filename, Config=config\n        )\n        self.addCleanup(self.delete_object, key)\n        self.assertTrue(self.object_exists(key))\n\n        fileobj = io.BytesIO()\n        self.client.download_fileobj(\n            Bucket=self.bucket_name, Key='foo', Fileobj=fileobj, Config=config\n        )\n        self.assertEqual(fileobj.getvalue(), content)\n\n    def test_transfer_methods_through_bucket(self):\n        # This is just a sanity check to ensure that the bucket interface work.\n        key = 'bucket.txt'\n        bucket = self.session.resource('s3').Bucket(self.bucket_name)\n        filename = self.files.create_file_with_size(key, 1024 * 1024)\n        bucket.upload_file(Filename=filename, Key=key)\n        self.addCleanup(self.delete_object, key)\n        download_path = os.path.join(self.files.rootdir, unique_id('foo'))\n        bucket.download_file(Key=key, Filename=download_path)\n        assert_files_equal(filename, download_path)\n\n    def test_transfer_methods_through_object(self):\n        # This is just a sanity check to ensure that the object interface work.\n        key = 'object.txt'\n        obj = self.session.resource('s3').Object(self.bucket_name, key)\n        filename = self.files.create_file_with_size(key, 1024 * 1024)\n        obj.upload_file(Filename=filename)\n        self.addCleanup(self.delete_object, key)\n        download_path = os.path.join(self.files.rootdir, unique_id('foo'))\n        obj.download_file(Filename=download_path)\n        assert_files_equal(filename, download_path)\n\n\nclass TestCustomS3BucketLoad(unittest.TestCase):\n    def setUp(self):\n        self.region = _DEFAULT_REGION\n        self.bucket_name = _SHARED_BUCKET\n        clear_out_bucket(self.bucket_name, self.region)\n        self.session = boto3.session.Session(region_name=self.region)\n        self.s3 = self.session.resource('s3')\n\n    def test_can_access_buckets_creation_date(self):\n        bucket = self.s3.Bucket(self.bucket_name)\n        self.assertIsInstance(bucket.creation_date, datetime.datetime)\n", "tests/integration/__init__.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n", "tests/integration/test_session.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport botocore.session\n\nimport boto3.session\nfrom tests import unittest\n\n\nclass TestUserAgentCustomizations(unittest.TestCase):\n    def setUp(self):\n        self.botocore_session = botocore.session.get_session()\n        self.session = boto3.session.Session(\n            region_name='us-west-2', botocore_session=self.botocore_session\n        )\n        self.actual_user_agent = None\n        self.botocore_session.register(\n            'request-created', self.record_user_agent\n        )\n\n    def record_user_agent(self, request, **kwargs):\n        self.actual_user_agent = request.headers['User-Agent']\n\n    def test_client_user_agent(self):\n        client = self.session.client('s3')\n        client.list_buckets()\n        self.assertIn('Boto3', self.actual_user_agent)\n        self.assertIn('Botocore', self.actual_user_agent)\n        self.assertIn('Python', self.actual_user_agent)\n        # We should *not* have any mention of resource\n        # when using clients directly.\n        self.assertNotIn('Resource', self.actual_user_agent)\n\n    def test_resource_user_agent_has_customization(self):\n        resource = self.session.resource('s3')\n        list(resource.buckets.all())\n        # We should have customized the user agent for\n        # resource calls with \"Resource\".\n        self.assertTrue(self.actual_user_agent.endswith(' Resource'))\n", "tests/functional/test_collection.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom boto3.resources.collection import ResourceCollection\nfrom boto3.session import Session\nfrom tests import unittest\n\n\nclass TestCollection(unittest.TestCase):\n    def setUp(self):\n        self.session = Session(\n            aws_access_key_id='dummy',\n            aws_secret_access_key='dummy',\n            region_name='us-east-1',\n        )\n        # Pick an arbitrary resource.\n        self.ec2_resource = self.session.resource('ec2')\n\n    def test_can_use_collection_methods(self):\n        assert isinstance(\n            self.ec2_resource.instances.all(), ResourceCollection\n        )\n\n    def test_can_chain_methods(self):\n        assert isinstance(\n            self.ec2_resource.instances.all().page_size(5), ResourceCollection\n        )\n", "tests/functional/test_dynamodb.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport json\n\nfrom botocore.awsrequest import AWSResponse\n\nfrom boto3.dynamodb.conditions import Attr\nfrom boto3.session import Session\nfrom tests import mock, unittest\n\n\nclass TestDynamoDB(unittest.TestCase):\n    def setUp(self):\n        self.http_response = AWSResponse(None, 200, {}, None)\n        self.parsed_response = {}\n        self.make_request_patch = mock.patch(\n            'botocore.endpoint.Endpoint.make_request'\n        )\n        self.make_request_mock = self.make_request_patch.start()\n        self.make_request_mock.return_value = (\n            self.http_response,\n            self.parsed_response,\n        )\n        self.session = Session(\n            aws_access_key_id='dummy',\n            aws_secret_access_key='dummy',\n            region_name='us-east-1',\n        )\n\n    def tearDown(self):\n        self.make_request_patch.stop()\n\n    def test_resource(self):\n        dynamodb = self.session.resource('dynamodb')\n        table = dynamodb.Table('MyTable')\n        # Make sure it uses the high level interface\n        table.scan(FilterExpression=Attr('mykey').eq('myvalue'))\n        request = self.make_request_mock.call_args_list[0][0][1]\n        request_params = json.loads(request['body'].decode('utf-8'))\n        assert request_params == {\n            'TableName': 'MyTable',\n            'FilterExpression': '#n0 = :v0',\n            'ExpressionAttributeNames': {'#n0': 'mykey'},\n            'ExpressionAttributeValues': {':v0': {'S': 'myvalue'}},\n        }\n\n    def test_client(self):\n        dynamodb = self.session.client('dynamodb')\n        # Make sure the client still uses the botocore level interface\n        dynamodb.scan(\n            TableName='MyTable',\n            FilterExpression='#n0 = :v0',\n            ExpressionAttributeNames={'#n0': 'mykey'},\n            ExpressionAttributeValues={':v0': {'S': 'myvalue'}},\n        )\n        request = self.make_request_mock.call_args_list[0][0][1]\n        request_params = json.loads(request['body'].decode('utf-8'))\n        assert request_params == {\n            'TableName': 'MyTable',\n            'FilterExpression': '#n0 = :v0',\n            'ExpressionAttributeNames': {'#n0': 'mykey'},\n            'ExpressionAttributeValues': {':v0': {'S': 'myvalue'}},\n        }\n", "tests/functional/test_ec2.py": "# Copyright 2016 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport unittest\n\nfrom botocore.stub import Stubber\n\nimport boto3.session\n\n\nclass TestInstanceDeleteTags(unittest.TestCase):\n    def setUp(self):\n        self.session = boto3.session.Session(region_name='us-west-2')\n        self.service_resource = self.session.resource('ec2')\n        self.instance_resource = self.service_resource.Instance('i-abc123')\n\n    def test_delete_tags_injected(self):\n        assert hasattr(self.instance_resource, 'delete_tags')\n\n    def test_delete_tags(self):\n        stubber = Stubber(self.instance_resource.meta.client)\n        stubber.add_response('delete_tags', {})\n        stubber.activate()\n        response = self.instance_resource.delete_tags(Tags=[{'Key': 'foo'}])\n        stubber.assert_no_pending_responses()\n        assert response == {}\n        stubber.deactivate()\n\n    def test_mutating_filters(self):\n        stubber = Stubber(self.service_resource.meta.client)\n        instance_filters = [\n            {'Name': 'instance-state-name', 'Values': ['running']}\n        ]\n        running_instances = self.service_resource.instances.filter(\n            Filters=instance_filters\n        )\n\n        # This should not impact the already-created filter.\n        instance_filters.append(\n            {'Name': 'instance-type', 'Values': ['c4.large']}\n        )\n\n        stubber.add_response(\n            method='describe_instances',\n            service_response={'Reservations': []},\n            expected_params={\n                'Filters': [\n                    {'Name': 'instance-state-name', 'Values': ['running']}\n                ]\n            },\n        )\n\n        with stubber:\n            list(running_instances)\n\n        stubber.assert_no_pending_responses()\n", "tests/functional/test_s3.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport io\n\nimport botocore\nimport botocore.stub\nimport pytest\nfrom botocore.config import Config\nfrom botocore.stub import Stubber\n\nimport boto3.session\nfrom boto3.s3.transfer import TransferConfig\nfrom tests import unittest\n\n\nclass TestS3MethodInjection(unittest.TestCase):\n    def test_transfer_methods_injected_to_client(self):\n        session = boto3.session.Session(region_name='us-west-2')\n        client = session.client('s3')\n        assert hasattr(client, 'upload_file')\n        assert hasattr(client, 'download_file')\n        assert hasattr(client, 'copy')\n\n    def test_bucket_resource_has_load_method(self):\n        session = boto3.session.Session(region_name='us-west-2')\n        bucket = session.resource('s3').Bucket('fakebucket')\n        assert hasattr(bucket, 'load')\n\n    def test_transfer_methods_injected_to_bucket(self):\n        bucket = boto3.resource('s3').Bucket('my_bucket')\n        assert hasattr(bucket, 'upload_file')\n        assert hasattr(bucket, 'download_file')\n        assert hasattr(bucket, 'copy')\n\n    def test_transfer_methods_injected_to_object(self):\n        obj = boto3.resource('s3').Object('my_bucket', 'my_key')\n        assert hasattr(obj, 'upload_file')\n        assert hasattr(obj, 'download_file')\n        assert hasattr(obj, 'copy')\n\n\nclass BaseTransferTest(unittest.TestCase):\n    def setUp(self):\n        self.session = boto3.session.Session(\n            aws_access_key_id='foo',\n            aws_secret_access_key='bar',\n            region_name='us-west-2',\n        )\n        self.s3 = self.session.resource('s3')\n        self.stubber = Stubber(self.s3.meta.client)\n        self.bucket = 'mybucket'\n        self.key = 'mykey'\n        self.upload_id = 'uploadid'\n        self.etag = '\"example0etag\"'\n        self.progress = 0\n        self.progress_times_called = 0\n\n    def stub_head(self, content_length=4, expected_params=None):\n        head_response = {\n            'AcceptRanges': 'bytes',\n            'ContentLength': content_length,\n            'ContentType': 'binary/octet-stream',\n            'ETag': self.etag,\n            'Metadata': {},\n            'ResponseMetadata': {\n                'HTTPStatusCode': 200,\n            },\n        }\n\n        if expected_params is None:\n            expected_params = {'Bucket': self.bucket, 'Key': self.key}\n\n        self.stubber.add_response(\n            method='head_object',\n            service_response=head_response,\n            expected_params=expected_params,\n        )\n\n    def stub_create_multipart_upload(self):\n        # Add the response and assert params for CreateMultipartUpload\n        create_upload_response = {\n            \"Bucket\": self.bucket,\n            \"Key\": self.key,\n            \"UploadId\": self.upload_id,\n        }\n        expected_params = {\n            \"Bucket\": self.bucket,\n            \"Key\": self.key,\n        }\n        self.stubber.add_response(\n            method='create_multipart_upload',\n            service_response=create_upload_response,\n            expected_params=expected_params,\n        )\n\n    def stub_complete_multipart_upload(self, parts):\n        complete_upload_response = {\n            \"Location\": \"us-west-2\",\n            \"Bucket\": self.bucket,\n            \"Key\": self.key,\n            \"ETag\": self.etag,\n        }\n        expected_params = {\n            \"Bucket\": self.bucket,\n            \"Key\": self.key,\n            \"MultipartUpload\": {\"Parts\": parts},\n            \"UploadId\": self.upload_id,\n        }\n\n        self.stubber.add_response(\n            method='complete_multipart_upload',\n            service_response=complete_upload_response,\n            expected_params=expected_params,\n        )\n\n\nclass TestCopy(BaseTransferTest):\n    def setUp(self):\n        super().setUp()\n        self.copy_source = {'Bucket': 'foo', 'Key': 'bar'}\n\n    def stub_single_part_copy(self):\n        self.stub_head(expected_params=self.copy_source)\n        self.stub_copy_object()\n\n    def stub_multipart_copy(self, part_size, num_parts):\n        # Set the HEAD to return the total size\n        total_size = part_size * num_parts\n        self.stub_head(\n            content_length=total_size, expected_params=self.copy_source\n        )\n\n        self.stub_create_multipart_upload()\n\n        # Add the responses for each UploadPartCopy\n        parts = []\n        for i in range(num_parts):\n            # Fill in the parts\n            part_number = i + 1\n            copy_range = (\n                f\"bytes={i * part_size}-{i * part_size + (part_size - 1)}\"\n            )\n            self.stub_copy_part(part_number=part_number, copy_range=copy_range)\n            parts.append({'ETag': self.etag, 'PartNumber': part_number})\n\n        self.stub_complete_multipart_upload(parts)\n\n    def stub_copy_object(self):\n        copy_response = {\n            'CopyObjectResult': {'ETag': self.etag},\n            'ResponseMetadata': {'HTTPStatusCode': 200},\n        }\n        expected_params = {\n            \"Bucket\": self.bucket,\n            \"Key\": self.key,\n            \"CopySource\": self.copy_source,\n        }\n        self.stubber.add_response(\n            method='copy_object',\n            service_response=copy_response,\n            expected_params=expected_params,\n        )\n\n    def stub_copy_part(self, part_number, copy_range):\n        copy_part_response = {\n            \"CopyPartResult\": {\"ETag\": self.etag},\n            'ResponseMetadata': {'HTTPStatusCode': 200},\n        }\n        expected_params = {\n            \"Bucket\": self.bucket,\n            \"Key\": self.key,\n            \"CopySource\": self.copy_source,\n            \"UploadId\": self.upload_id,\n            \"PartNumber\": part_number,\n            \"CopySourceRange\": copy_range,\n        }\n        self.stubber.add_response(\n            method='upload_part_copy',\n            service_response=copy_part_response,\n            expected_params=expected_params,\n        )\n\n    def test_client_copy(self):\n        self.stub_single_part_copy()\n        with self.stubber:\n            response = self.s3.meta.client.copy(\n                self.copy_source, self.bucket, self.key\n            )\n        # The response will be none on a successful transfer.\n        assert response is None\n\n    def test_bucket_copy(self):\n        self.stub_single_part_copy()\n        bucket = self.s3.Bucket(self.bucket)\n        with self.stubber:\n            response = bucket.copy(self.copy_source, self.key)\n        # The response will be none on a successful transfer.\n        assert response is None\n\n    def test_object_copy(self):\n        self.stub_single_part_copy()\n        obj = self.s3.Object(self.bucket, self.key)\n        with self.stubber:\n            response = obj.copy(self.copy_source)\n        assert response is None\n\n    def test_copy_progress(self):\n        chunksize = 8 * (1024**2)\n        self.stub_multipart_copy(chunksize, 3)\n        transfer_config = TransferConfig(\n            multipart_chunksize=chunksize,\n            multipart_threshold=1,\n            max_concurrency=1,\n        )\n\n        def progress_callback(amount):\n            self.progress += amount\n            self.progress_times_called += 1\n\n        with self.stubber:\n            self.s3.meta.client.copy(\n                Bucket=self.bucket,\n                Key=self.key,\n                CopySource=self.copy_source,\n                Config=transfer_config,\n                Callback=progress_callback,\n            )\n\n        # Assert that the progress callback was called the correct number of\n        # times with the correct amounts.\n        assert self.progress_times_called == 3\n        assert self.progress == chunksize * 3\n\n\nclass TestUploadFileobj(BaseTransferTest):\n    def setUp(self):\n        super().setUp()\n        self.contents = io.BytesIO(b'foo\\n')\n\n    def stub_put_object(self):\n        put_object_response = {\n            \"ETag\": self.etag,\n            \"ResponseMetadata\": {\"HTTPStatusCode\": 200},\n        }\n        expected_params = {\n            \"Bucket\": self.bucket,\n            \"Key\": self.key,\n            \"Body\": botocore.stub.ANY,\n        }\n        self.stubber.add_response(\n            method='put_object',\n            service_response=put_object_response,\n            expected_params=expected_params,\n        )\n\n    def stub_upload_part(self, part_number):\n        upload_part_response = {\n            'ETag': self.etag,\n            'ResponseMetadata': {'HTTPStatusCode': 200},\n        }\n        expected_params = {\n            \"Bucket\": self.bucket,\n            \"Key\": self.key,\n            \"Body\": botocore.stub.ANY,\n            \"PartNumber\": part_number,\n            \"UploadId\": self.upload_id,\n        }\n        self.stubber.add_response(\n            method='upload_part',\n            service_response=upload_part_response,\n            expected_params=expected_params,\n        )\n\n    def stub_multipart_upload(self, num_parts):\n        self.stub_create_multipart_upload()\n\n        # Add the responses for each UploadPartCopy\n        parts = []\n        for i in range(num_parts):\n            # Fill in the parts\n            part_number = i + 1\n            self.stub_upload_part(part_number=part_number)\n            parts.append({'ETag': self.etag, 'PartNumber': part_number})\n\n        self.stub_complete_multipart_upload(parts)\n\n    def test_client_upload(self):\n        self.stub_put_object()\n        with self.stubber:\n            # The stubber will assert that all the right parameters are called.\n            self.s3.meta.client.upload_fileobj(\n                Fileobj=self.contents, Bucket=self.bucket, Key=self.key\n            )\n\n        self.stubber.assert_no_pending_responses()\n\n    def test_raises_value_error_on_invalid_fileobj(self):\n        with self.stubber:\n            with pytest.raises(ValueError):\n                self.s3.meta.client.upload_fileobj(\n                    Fileobj='foo', Bucket=self.bucket, Key=self.key\n                )\n\n    def test_bucket_upload(self):\n        self.stub_put_object()\n        bucket = self.s3.Bucket(self.bucket)\n        with self.stubber:\n            # The stubber will assert that all the right parameters are called.\n            bucket.upload_fileobj(Fileobj=self.contents, Key=self.key)\n\n        self.stubber.assert_no_pending_responses()\n\n    def test_object_upload(self):\n        self.stub_put_object()\n        obj = self.s3.Object(self.bucket, self.key)\n        with self.stubber:\n            # The stubber will assert that all the right parameters are called.\n            obj.upload_fileobj(Fileobj=self.contents)\n\n        self.stubber.assert_no_pending_responses()\n\n    def test_multipart_upload(self):\n        chunksize = 8 * (1024**2)\n        contents = io.BytesIO(b'0' * (chunksize * 3))\n        self.stub_multipart_upload(num_parts=3)\n        transfer_config = TransferConfig(\n            multipart_chunksize=chunksize,\n            multipart_threshold=1,\n            max_concurrency=1,\n        )\n\n        with self.stubber:\n            # The stubber will assert that all the right parameters are called.\n            self.s3.meta.client.upload_fileobj(\n                Fileobj=contents,\n                Bucket=self.bucket,\n                Key=self.key,\n                Config=transfer_config,\n            )\n\n        self.stubber.assert_no_pending_responses()\n\n\nclass TestDownloadFileobj(BaseTransferTest):\n    def setUp(self):\n        super().setUp()\n        self.contents = b'foo'\n        self.fileobj = io.BytesIO()\n\n    def stub_single_part_download(self):\n        self.stub_head(content_length=len(self.contents))\n        self.stub_get_object(self.contents)\n\n    def stub_get_object(self, full_contents, start_byte=0, end_byte=None):\n        \"\"\"\n        Stubs out the get_object operation.\n\n        :param full_contents: The FULL contents of the object\n        :param start_byte: The first byte to grab.\n        :param end_byte: The last byte to grab.\n        \"\"\"\n        get_object_response = {}\n        expected_params = {}\n        contents = full_contents\n        end_byte_range = end_byte\n\n        # If the start byte is set and the end byte is not, the end byte is\n        # the last byte.\n        if start_byte != 0 and end_byte is None:\n            end_byte = len(full_contents) - 1\n\n        # The range on get object where the the end byte is the last byte\n        # should set the input range as e.g. Range='bytes=3-'\n        if end_byte == len(full_contents) - 1:\n            end_byte_range = ''\n\n        # If this is a ranged get, ContentRange needs to be returned,\n        # contents needs to be pruned, and Range needs to be an expected param.\n        if end_byte is not None:\n            contents = full_contents[start_byte : end_byte + 1]\n            part_range = f'bytes={start_byte}-{end_byte_range}'\n            content_range = (\n                f'bytes={start_byte}-{end_byte}/{len(full_contents)}'\n            )\n            get_object_response['ContentRange'] = content_range\n            expected_params['Range'] = part_range\n\n        get_object_response.update(\n            {\n                \"AcceptRanges\": \"bytes\",\n                \"ETag\": self.etag,\n                \"ContentLength\": len(contents),\n                \"ContentType\": \"binary/octet-stream\",\n                \"Body\": io.BytesIO(contents),\n                \"ResponseMetadata\": {\"HTTPStatusCode\": 200},\n            }\n        )\n        expected_params.update({\"Bucket\": self.bucket, \"Key\": self.key})\n\n        self.stubber.add_response(\n            method='get_object',\n            service_response=get_object_response,\n            expected_params=expected_params,\n        )\n\n    def stub_multipart_download(self, contents, part_size, num_parts):\n        self.stub_head(content_length=len(contents))\n\n        for i in range(num_parts):\n            start_byte = i * part_size\n            end_byte = (i + 1) * part_size - 1\n            self.stub_get_object(\n                full_contents=contents,\n                start_byte=start_byte,\n                end_byte=end_byte,\n            )\n\n    def test_client_download(self):\n        self.stub_single_part_download()\n        with self.stubber:\n            self.s3.meta.client.download_fileobj(\n                Bucket=self.bucket, Key=self.key, Fileobj=self.fileobj\n            )\n\n        assert self.fileobj.getvalue() == self.contents\n        self.stubber.assert_no_pending_responses()\n\n    def test_raises_value_error_on_invalid_fileobj(self):\n        with self.stubber:\n            with pytest.raises(ValueError):\n                self.s3.meta.client.download_fileobj(\n                    Bucket=self.bucket, Key=self.key, Fileobj='foo'\n                )\n\n    def test_bucket_download(self):\n        self.stub_single_part_download()\n        bucket = self.s3.Bucket(self.bucket)\n        with self.stubber:\n            bucket.download_fileobj(Key=self.key, Fileobj=self.fileobj)\n\n        assert self.fileobj.getvalue() == self.contents\n        self.stubber.assert_no_pending_responses()\n\n    def test_object_download(self):\n        self.stub_single_part_download()\n        obj = self.s3.Object(self.bucket, self.key)\n        with self.stubber:\n            obj.download_fileobj(Fileobj=self.fileobj)\n\n        assert self.fileobj.getvalue() == self.contents\n        self.stubber.assert_no_pending_responses()\n\n    def test_multipart_download(self):\n        self.contents = b'A' * 55\n        self.stub_multipart_download(\n            contents=self.contents, part_size=5, num_parts=11\n        )\n        transfer_config = TransferConfig(\n            multipart_chunksize=5, multipart_threshold=1, max_concurrency=1\n        )\n\n        with self.stubber:\n            self.s3.meta.client.download_fileobj(\n                Bucket=self.bucket,\n                Key=self.key,\n                Fileobj=self.fileobj,\n                Config=transfer_config,\n            )\n\n        assert self.fileobj.getvalue() == self.contents\n        self.stubber.assert_no_pending_responses()\n\n    def test_download_progress(self):\n        self.contents = b'A' * 55\n        self.stub_multipart_download(\n            contents=self.contents, part_size=5, num_parts=11\n        )\n        transfer_config = TransferConfig(\n            multipart_chunksize=5, multipart_threshold=1, max_concurrency=1\n        )\n\n        def progress_callback(amount):\n            self.progress += amount\n            self.progress_times_called += 1\n\n        with self.stubber:\n            self.s3.meta.client.download_fileobj(\n                Bucket=self.bucket,\n                Key=self.key,\n                Fileobj=self.fileobj,\n                Config=transfer_config,\n                Callback=progress_callback,\n            )\n\n        # Assert that the progress callback was called the correct number of\n        # times with the correct amounts.\n        assert self.progress_times_called == 11\n        assert self.progress == 55\n        self.stubber.assert_no_pending_responses()\n\n\nclass TestS3ObjectSummary(unittest.TestCase):\n    def setUp(self):\n        self.session = boto3.session.Session(\n            aws_access_key_id='foo',\n            aws_secret_access_key='bar',\n            region_name='us-west-2',\n        )\n        self.s3 = self.session.resource('s3')\n        self.obj_summary = self.s3.ObjectSummary('my_bucket', 'my_key')\n        self.obj_summary_size = 12\n        self.stubber = Stubber(self.s3.meta.client)\n        self.stubber.activate()\n        self.stubber.add_response(\n            method='head_object',\n            service_response={\n                'ContentLength': self.obj_summary_size,\n                'ETag': 'my-etag',\n                'ContentType': 'binary',\n            },\n            expected_params={'Bucket': 'my_bucket', 'Key': 'my_key'},\n        )\n\n    def tearDown(self):\n        self.stubber.deactivate()\n\n    def test_has_load(self):\n        # Validate load was injected onto ObjectSummary.\n        assert hasattr(self.obj_summary, 'load')\n\n    def test_autoloads_correctly(self):\n        # In HeadObject the parameter returned is ContentLength, this\n        # should get mapped to Size of ListObject since the resource uses\n        # the shape returned to by ListObjects.\n        assert self.obj_summary.size == self.obj_summary_size\n\n    def test_cannot_access_other_non_related_parameters(self):\n        # Even though an HeadObject was used to load this, it should\n        # only expose the attributes from its shape defined in ListObjects.\n        assert not hasattr(self.obj_summary, 'content_length')\n\n\nclass TestServiceResource(unittest.TestCase):\n    def setUp(self):\n        self.session = boto3.session.Session()\n\n    def test_unsigned_signature_version_is_not_corrupted(self):\n        config = Config(signature_version=botocore.UNSIGNED)\n        resource = self.session.resource('s3', config=config)\n        sig_version = resource.meta.client.meta.config.signature_version\n        assert sig_version is botocore.UNSIGNED\n", "tests/functional/test_smoke.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport botocore.session\nimport pytest\n\nfrom boto3.session import Session\n\nboto3_session = None\n\n\ndef create_session():\n    global boto3_session\n    if boto3_session is None:\n        boto3_session = Session(\n            aws_access_key_id='dummy',\n            aws_secret_access_key='dummy',\n            region_name='us-east-1',\n        )\n\n    return boto3_session\n\n\ndef _all_resources():\n    session = create_session()\n    for service_name in session.get_available_resources():\n        yield session, service_name\n\n\ndef _all_clients():\n    session = create_session()\n    for service_name in session.get_available_services():\n        yield session, service_name\n\n\ndef _all_api_version_args():\n    botocore_session = botocore.session.get_session()\n    boto3_session = create_session()\n    for service_name in boto3_session.get_available_resources():\n        yield (service_name, botocore_session, boto3_session)\n\n\n@pytest.mark.parametrize('resource_args', _all_resources())\ndef test_can_create_all_resources(resource_args):\n    \"\"\"Verify we can create all existing resources.\"\"\"\n    session, service_name = resource_args\n    resource = session.resource(service_name)\n    # Verifying we have a \"meta\" attr is just an arbitrary\n    # sanity check.\n    assert hasattr(resource, 'meta')\n\n\n@pytest.mark.parametrize('client_args', _all_clients())\ndef test_can_create_all_clients(client_args):\n    \"\"\"Verify we can create all existing clients.\"\"\"\n    session, service_name = client_args\n    client = session.client(service_name)\n    assert hasattr(client, 'meta')\n\n\n@pytest.mark.parametrize('api_version_args', _all_api_version_args())\ndef test_api_versions_synced_with_botocore(api_version_args):\n    \"\"\"Verify both boto3 and botocore clients stay in sync.\"\"\"\n    service_name, botocore_session, boto3_session = api_version_args\n    resource = boto3_session.resource(service_name)\n    boto3_api_version = resource.meta.client.meta.service_model.api_version\n    client = botocore_session.create_client(\n        service_name,\n        region_name='us-east-1',\n        aws_access_key_id='foo',\n        aws_secret_access_key='bar',\n    )\n    botocore_api_version = client.meta.service_model.api_version\n    err = (\n        f\"Different latest API versions found for {service_name}: \"\n        f\"{botocore_api_version} (botocore), {boto3_api_version} (boto3)\\n\"\n    )\n    assert botocore_api_version == boto3_api_version, err\n", "tests/functional/__init__.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n", "tests/functional/test_session.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport boto3.session\nfrom tests import unittest\n\n\nclass TestSession(unittest.TestCase):\n    def setUp(self):\n        self.session = boto3.session.Session(region_name='us-west-2')\n\n    def test_events_attribute(self):\n        # Create some function to register.\n        def my_handler(my_list, **kwargs):\n            return my_list.append('my_handler called')\n\n        # Register the handler to the event.\n        self.session.events.register('myevent', my_handler)\n\n        initial_list = []\n        # Emit the event.\n        self.session.events.emit('myevent', my_list=initial_list)\n        # Ensure that the registered handler was called.\n        assert initial_list == ['my_handler called']\n\n    def test_can_access_region_property(self):\n        session = boto3.session.Session(region_name='us-west-1')\n        assert session.region_name == 'us-west-1'\n\n    def test_get_available_partitions(self):\n        partitions = self.session.get_available_partitions()\n        assert isinstance(partitions, list)\n        assert partitions\n\n    def test_get_available_regions(self):\n        regions = self.session.get_available_regions('s3')\n        assert isinstance(regions, list)\n        assert regions\n", "tests/functional/test_crt.py": "# Copyright 2023 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n\nfrom contextlib import ContextDecorator\n\nimport pytest\nfrom botocore.compat import HAS_CRT\nfrom botocore.credentials import Credentials\n\nfrom boto3.s3.transfer import (\n    TransferConfig,\n    create_transfer_manager,\n    has_minimum_crt_version,\n)\nfrom tests import mock, requires_crt\n\nif HAS_CRT:\n    from s3transfer.crt import CRTTransferManager\n\n\nclass MockOptimizedInstance(ContextDecorator):\n    \"\"\"Helper class to simulate a CRT optimized EC2 instance.\"\"\"\n\n    DEFAULT_LOCK_MOCK = mock.Mock()\n\n    def __init__(self, lock=DEFAULT_LOCK_MOCK, optimized=True):\n        self.acquire_process_lock = mock.patch(\n            'boto3.crt.acquire_crt_s3_process_lock'\n        )\n        self.acquire_process_lock.return_value = lock\n        self.is_optimized = mock.patch('awscrt.s3.is_optimized_for_system')\n        self.is_optimized.return_value = optimized\n\n    def __enter__(self, *args, **kwargs):\n        self.acquire_process_lock.start()\n        self.is_optimized.start()\n\n    def __exit__(self, *args, **kwargs):\n        self.acquire_process_lock.stop()\n        self.is_optimized.stop()\n\n\ndef create_mock_client(region_name='us-west-2'):\n    client = mock.Mock()\n    client.meta.region_name = region_name\n    client._get_credentials.return_value = Credentials(\n        'access', 'secret', 'token'\n    )\n    return client\n\n\nclass TestS3TransferWithCRT:\n    @requires_crt()\n    @MockOptimizedInstance()\n    def test_create_transfer_manager_on_optimized_instance(self):\n        client = create_mock_client()\n        config = TransferConfig()\n        transfer_manager = create_transfer_manager(client, config)\n        assert isinstance(transfer_manager, CRTTransferManager)\n\n    @requires_crt()\n    def test_minimum_crt_version(self):\n        assert has_minimum_crt_version((0, 16, 12)) is True\n\n    @pytest.mark.parametrize(\n        \"bad_version\",\n        (\n            None,\n            \"0.1.0-dev\",\n            \"0.20\",\n            object(),\n        ),\n    )\n    @requires_crt()\n    def test_minimum_crt_version_bad_crt_version(self, bad_version):\n        with mock.patch(\"awscrt.__version__\") as vers:\n            vers.return_value = bad_version\n\n            assert has_minimum_crt_version((0, 16, 12)) is False\n", "tests/functional/test_resource.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport botocore.session\nimport pytest\n\nimport boto3\nfrom boto3.exceptions import ResourceNotExistsError\nfrom tests import unittest\n\n\ndef identity(self, x):\n    return x\n\n\nclass TestResourceCustomization(unittest.TestCase):\n    def setUp(self):\n        self.botocore_session = botocore.session.get_session()\n\n    def add_new_method(self, name):\n        def handler(class_attributes, **kwargs):\n            class_attributes[name] = identity\n\n        return handler\n\n    def test_can_inject_method_onto_resource(self):\n        session = boto3.Session(botocore_session=self.botocore_session)\n        self.botocore_session.register(\n            'creating-resource-class.s3', self.add_new_method(name='my_method')\n        )\n        resource = session.resource('s3')\n        assert hasattr(resource, 'my_method')\n        assert resource.my_method('anything') == 'anything'\n\n\nclass TestSessionErrorMessages(unittest.TestCase):\n    def test_has_good_error_message_when_no_resource(self):\n        bad_resource_name = 'doesnotexist'\n        err_regex = f'{bad_resource_name}.*resource does not exist.'\n        with pytest.raises(ResourceNotExistsError, match=err_regex):\n            boto3.resource(bad_resource_name)\n\n\nclass TestGetAvailableSubresources(unittest.TestCase):\n    def test_s3_available_subresources_exists(self):\n        s3 = boto3.resource('s3')\n        assert hasattr(s3, 'get_available_subresources')\n", "tests/functional/test_utils.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport botocore.session\nimport pytest\n\nimport boto3.session\nfrom boto3 import utils\nfrom tests import unittest\n\n\nclass TestUtils(unittest.TestCase):\n    def test_runtime_error_raised_when_shadowing_client_method(self):\n        botocore_session = botocore.session.get_session()\n        session = boto3.session.Session(\n            region_name='us-west-2', botocore_session=botocore_session\n        )\n\n        def shadows_put_object(class_attributes, **kwargs):\n            utils.inject_attribute(class_attributes, 'put_object', 'invalid')\n\n        botocore_session.register('creating-client-class', shadows_put_object)\n\n        with pytest.raises(RuntimeError):\n            # This should raise an exception because we're trying to\n            # shadow the put_object client method in the\n            # shadows_put_object handler above.\n            session.client('s3')\n", "tests/functional/dynamodb/test_stubber_conditions.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom botocore.stub import Stubber\n\nimport boto3\nfrom boto3.dynamodb.conditions import Attr, Key\nfrom tests import unittest\n\n\nclass TestStubberSupportsFilterExpressions(unittest.TestCase):\n    maxDiff = None\n\n    def setUp(self):\n        self.resource = boto3.resource('dynamodb', 'us-east-1')\n\n    def test_table_query_can_be_stubbed_with_expressions(self):\n        table = self.resource.Table('mytable')\n        key_expr = Key('mykey').eq('testkey')\n        filter_expr = Attr('myattr').eq('foo') & (\n            Attr('myattr2').lte('buzz') | Attr('myattr2').gte('fizz')\n        )\n\n        stubber = Stubber(table.meta.client)\n        stubber.add_response(\n            'query',\n            dict(Items=list()),\n            expected_params=dict(\n                TableName='mytable',\n                KeyConditionExpression=key_expr,\n                FilterExpression=filter_expr,\n            ),\n        )\n\n        with stubber:\n            response = table.query(\n                KeyConditionExpression=key_expr, FilterExpression=filter_expr\n            )\n\n        assert response['Items'] == []\n        stubber.assert_no_pending_responses()\n\n    def test_table_scan_can_be_stubbed_with_expressions(self):\n        table = self.resource.Table('mytable')\n        filter_expr = Attr('myattr').eq('foo') & (\n            Attr('myattr2').lte('buzz') | Attr('myattr2').gte('fizz')\n        )\n\n        stubber = Stubber(table.meta.client)\n        stubber.add_response(\n            'scan',\n            dict(Items=list()),\n            expected_params=dict(\n                TableName='mytable', FilterExpression=filter_expr\n            ),\n        )\n\n        with stubber:\n            response = table.scan(FilterExpression=filter_expr)\n\n        assert response['Items'] == []\n        stubber.assert_no_pending_responses()\n", "tests/functional/dynamodb/__init__.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n", "tests/functional/dynamodb/test_table.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport json\n\nfrom botocore.stub import Stubber\n\nimport boto3\nfrom tests import unittest\n\n\nclass TestTableResourceCustomizations(unittest.TestCase):\n    maxDiff = None\n\n    def setUp(self):\n        self.resource = boto3.resource('dynamodb', 'us-east-1')\n        self.table = self.resource.Table('mytable')\n\n    def test_resource_has_batch_writer_added(self):\n        assert hasattr(self.table, 'batch_writer')\n\n    def test_operation_without_output(self):\n        stubber = Stubber(self.table.meta.client)\n        stubber.add_response('tag_resource', {})\n        arn = 'arn:aws:dynamodb:us-west-2:123456789:table/mytable'\n\n        with stubber:\n            self.table.meta.client.tag_resource(\n                ResourceArn=arn, Tags=[{'Key': 'project', 'Value': 'val'}]\n            )\n\n        stubber.assert_no_pending_responses()\n\n    def test_batch_write_does_not_double_serialize(self):\n        # If multiple items reference the same Python object, the\n        # object does not get double-serialized.\n        # https://github.com/boto/boto3/issues/3474\n\n        used_twice = {'pkey': 'foo1', 'otherfield': {'foo': 1, 'bar': 2}}\n        batch_writer = self.table.batch_writer()\n\n        # The default Stubber compares the request payload to the\n        # \"expected_params\" before automatic serialization happens. This custom\n        # event handler uses the same technique as the Stubber to record the\n        # serialized request body, but later in the request lifecycle.\n        class LateStubber:\n            def __init__(self, client):\n                self.intercepted_request_body = None\n                client.meta.events.register_first(\n                    'before-call.*.*',\n                    self.late_request_interceptor,\n                )\n\n            def late_request_interceptor(self, event_name, params, **kwargs):\n                if self.intercepted_request_body is not None:\n                    raise AssertionError(\n                        'LateStubber was called more than once, but only one '\n                        'request is expected'\n                    )\n                body_str = params.get('body', b'').decode('utf-8')\n                try:\n                    self.intercepted_request_body = json.loads(body_str)\n                except Exception:\n                    raise AssertionError(\n                        'Expected JSON request body, but failed to JSON decode'\n                    )\n\n        late_stubber = LateStubber(self.table.meta.client)\n\n        with Stubber(self.table.meta.client) as stubber:\n            stubber.add_response(\n                'batch_write_item',\n                service_response={'UnprocessedItems': {}},\n            )\n            batch_writer.put_item(Item=used_twice)\n            batch_writer.put_item(Item=used_twice)\n            batch_writer._flush()\n\n        expected_request_body = {\n            'RequestItems': {\n                'mytable': [\n                    {\n                        'PutRequest': {\n                            'Item': {\n                                'pkey': {'S': 'foo1'},\n                                'otherfield': {\n                                    'M': {'foo': {'N': '1'}, 'bar': {'N': '2'}}\n                                },\n                            }\n                        }\n                    },\n                    {\n                        'PutRequest': {\n                            'Item': {\n                                'pkey': {'S': 'foo1'},\n                                'otherfield': {\n                                    'M': {'foo': {'N': '1'}, 'bar': {'N': '2'}}\n                                },\n                            }\n                        }\n                    },\n                ]\n            }\n        }\n\n        assert late_stubber.intercepted_request_body == expected_request_body\n", "tests/functional/docs/test_cloudwatch.py": "# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n\nfrom boto3.docs.action import PUT_DATA_WARNING_MESSAGE\nfrom boto3.docs.service import ServiceDocumenter\nfrom boto3.session import Session\nfrom tests.functional.docs import BaseDocsFunctionalTests\n\n\nclass TestCloudWatchMetricPutActionOverrides(BaseDocsFunctionalTests):\n    def setUp(self):\n        super().setUp()\n        self.documenter = ServiceDocumenter(\n            'cloudwatch',\n            session=Session(region_name='us-east-1'),\n            root_docs_path=self.root_services_path,\n        )\n        self.generated_contents = self.documenter.document_service()\n        self.generated_contents = self.generated_contents.decode('utf-8')\n\n    def test_put_action_overrides(self):\n        put_action_contents = self.get_nested_file_contents(\n            \"cloudwatch\", \"metric\", \"put_data\"\n        )\n        # first line is an empty string\n        self.assert_contains_lines_in_order(\n            PUT_DATA_WARNING_MESSAGE.splitlines()[1:],\n            put_action_contents,\n        )\n\n    def test_put_action_override_not_present_in_other_action(self):\n        put_alarm_contents = self.get_nested_file_contents(\n            \"cloudwatch\", \"metric\", \"put_alarm\"\n        )\n        for line in PUT_DATA_WARNING_MESSAGE.splitlines()[1:]:\n            self.assertNotIn(line, put_alarm_contents)\n", "tests/functional/docs/test_dynamodb.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom boto3.docs.service import ServiceDocumenter\nfrom boto3.session import Session\nfrom tests.functional.docs import BaseDocsFunctionalTests\n\n\nclass TestDynamoDBCustomizations(BaseDocsFunctionalTests):\n    def setUp(self):\n        super().setUp()\n        self.documenter = ServiceDocumenter(\n            'dynamodb',\n            session=Session(region_name='us-east-1'),\n            root_docs_path=self.root_services_path,\n        )\n        self.generated_contents = self.documenter.document_service()\n        self.generated_contents = self.generated_contents.decode('utf-8')\n\n    def test_batch_writer_is_documented(self):\n        self.assert_contains_lines_in_order(\n            [\n                '=========',\n                'Resources',\n                '=========',\n                'The available resources are:',\n                '  dynamodb/table/index',\n            ],\n            self.generated_contents,\n        )\n        self.assert_contains_lines_in_order(\n            [\n                '.. py:class:: DynamoDB.Table(name)',\n                '  batch_writer',\n            ],\n            self.get_nested_file_contents('dynamodb', 'table', 'index'),\n        )\n        self.assert_contains_lines_in_order(\n            [\n                '************\\nbatch_writer\\n************',\n                '.. py:method:: DynamoDB.Table.batch_writer(overwrite_by_pkeys=None)',\n            ],\n            self.get_nested_file_contents('dynamodb', 'table', 'batch_writer'),\n        )\n\n    def test_document_interface_is_documented(self):\n        put_item_content = self.get_nested_file_contents(\n            'dynamodb', 'table', 'put_item'\n        )\n        self.assert_contains_lines_in_order(\n            [\n                '********',\n                'put_item',\n                '********',\n                '.. py:method:: DynamoDB.Table.put_item(**kwargs)',\n                # Make sure the request syntax is as expected.\n                'response = table.put_item(',\n                'Item={',\n                (\n                    '\\'string\\': \\'string\\'|123|Binary(b\\'bytes\\')'\n                    '|True|None|set([\\'string\\'])|set([123])|'\n                    'set([Binary(b\\'bytes\\')])|[]|{}'\n                ),\n                '},',\n                'Expected={',\n                '\\'string\\': {',\n                (\n                    '\\'Value\\': \\'string\\'|123'\n                    '|Binary(b\\'bytes\\')|True|None|set([\\'string\\'])'\n                    '|set([123])|set([Binary(b\\'bytes\\')])|[]|{},'\n                ),\n                '\\'AttributeValueList\\': [',\n                (\n                    '\\'string\\'|123|Binary(b\\'bytes\\')'\n                    '|True|None|set([\\'string\\'])|set([123])|'\n                    'set([Binary(b\\'bytes\\')])|[]|{},'\n                ),\n                # Make sure the request parameter is documented correctly.\n                ':type Item: dict',\n                ':param Item: **[REQUIRED]**',\n                '- *(string) --*',\n                (\n                    '- *(valid DynamoDB type) -- *- The value of the '\n                    'attribute. The valid value types are listed in the '\n                    ':ref:`DynamoDB Reference Guide<ref_valid_dynamodb_types>`.'\n                ),\n                # Make sure the response syntax is as expected.\n                '{',\n                '\\'Attributes\\': {',\n                (\n                    '\\'string\\': \\'string\\'|123|'\n                    'Binary(b\\'bytes\\')|True|None|set([\\'string\\'])|'\n                    'set([123])|set([Binary(b\\'bytes\\')])|[]|{}'\n                ),\n                '},',\n                # Make sure the response parameter is documented correctly.\n                '- **Attributes** *(dict) --*',\n                '- *(string) --*',\n                (\n                    '- *(valid DynamoDB type) -- *- The value of '\n                    'the attribute. The valid value types are listed in the '\n                    ':ref:`DynamoDB Reference Guide<ref_valid_dynamodb_types>`.'\n                ),\n            ],\n            put_item_content,\n        )\n\n    def test_conditions_is_documented(self):\n        query_contents = self.get_nested_file_contents(\n            'dynamodb', 'table', 'query'\n        )\n        self.assert_contains_lines_in_order(\n            [\n                # Make sure the request syntax is as expected.\n                'response = table.query(',\n                ('FilterExpression=Attr(\\'myattribute\\').' 'eq(\\'myvalue\\'),'),\n                ('KeyConditionExpression=Key(\\'mykey\\')' '.eq(\\'myvalue\\'),'),\n                # Make sure the request parameter is documented correctly.\n                (\n                    ':type FilterExpression: condition from '\n                    ':py:class:`boto3.dynamodb.conditions.Attr` method'\n                ),\n                (\n                    ':param FilterExpression: The condition(s) an '\n                    'attribute(s) must meet. Valid conditions are listed in '\n                    'the :ref:`DynamoDB Reference Guide<ref_dynamodb_conditions>`.'\n                ),\n                (\n                    ':type KeyConditionExpression: condition from '\n                    ':py:class:`boto3.dynamodb.conditions.Key` method'\n                ),\n                (\n                    ':param KeyConditionExpression: The condition(s) a '\n                    'key(s) must meet. Valid conditions are listed in the '\n                    ':ref:`DynamoDB Reference Guide<ref_dynamodb_conditions>`.'\n                ),\n            ],\n            query_contents,\n        )\n", "tests/functional/docs/test_ec2.py": "# Copyright 2016 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom boto3.docs.service import ServiceDocumenter\nfrom boto3.session import Session\nfrom tests.functional.docs import BaseDocsFunctionalTests\n\n\nclass TestInstanceDeleteTags(BaseDocsFunctionalTests):\n    def setUp(self):\n        super().setUp()\n        self.documenter = ServiceDocumenter(\n            'ec2',\n            session=Session(region_name='us-east-1'),\n            root_docs_path=self.root_services_path,\n        )\n        self.generated_contents = self.documenter.document_service()\n        self.generated_contents = self.generated_contents.decode('utf-8')\n\n    def test_delete_tags_method_is_documented(self):\n        self.assert_contains_lines_in_order(\n            [\n                '=========',\n                'Resources',\n                '=========',\n                'The available resources are:',\n                '  ec2/instance/index',\n            ],\n            self.generated_contents,\n        )\n        self.assert_contains_lines_in_order(\n            [\n                '.. py:class:: EC2.Instance',\n                '  delete_tags',\n            ],\n            self.get_nested_file_contents('ec2', 'instance', 'index'),\n        )\n        self.assert_contains_lines_in_order(\n            [\n                'delete_tags',\n                '.. py:method:: EC2.Instance.delete_tags(**kwargs)',\n                'response = instance.delete_tags(',\n                'DryRun=True|False,',\n                'Tags=[',\n            ],\n            self.get_nested_file_contents('ec2', 'instance', 'delete_tags'),\n        )\n", "tests/functional/docs/test_s3.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom boto3.docs.service import ServiceDocumenter\nfrom boto3.session import Session\nfrom tests.functional.docs import BaseDocsFunctionalTests\n\n\nclass TestS3Customizations(BaseDocsFunctionalTests):\n    def setUp(self):\n        super().setUp()\n        self.documenter = ServiceDocumenter(\n            's3',\n            session=Session(region_name='us-east-1'),\n            root_docs_path=self.root_services_path,\n        )\n        self.generated_contents = self.documenter.document_service()\n        self.generated_contents = self.generated_contents.decode('utf-8')\n\n    def test_file_transfer_methods_are_documented(self):\n        self.assert_contains_lines_in_order(\n            [\n                '=========',\n                'Resources',\n                '=========',\n                'The available resources are:',\n                '  s3/service-resource/index',\n            ],\n            self.generated_contents,\n        )\n        self.assert_contains_lines_in_order(\n            [\n                '.. py:class:: S3.Client',\n                '  s3/client/download_file',\n                '  s3/client/upload_file',\n            ],\n            self.generated_contents,\n        )\n        self.assert_contains_lines_in_order(\n            [\n                'download_file',\n                '.. py:method:: S3.Client.download_file(',\n            ],\n            self.get_nested_file_contents('s3', 'client', 'download_file'),\n        )\n        self.assert_contains_lines_in_order(\n            [\n                'upload_file',\n                '.. py:method:: S3.Client.upload_file(',\n            ],\n            self.get_nested_file_contents('s3', 'client', 'upload_file'),\n        )\n", "tests/functional/docs/test_smoke.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport os\nimport shutil\nimport tempfile\n\nimport botocore.session\nimport pytest\nfrom botocore import xform_name\nfrom botocore.exceptions import DataNotFoundError\n\nimport boto3\nfrom boto3.docs.service import ServiceDocumenter\n\nDOCS_ROOT_DIR = None\nROOT_SERVICES_PATH = None\n\n\n@pytest.fixture\ndef botocore_session():\n    return botocore.session.get_session()\n\n\n@pytest.fixture\ndef boto3_session():\n    return boto3.Session(region_name='us-east-1')\n\n\ndef all_services():\n    # Create temporary directory before testing.\n    global DOCS_ROOT_DIR, ROOT_SERVICES_PATH\n    DOCS_ROOT_DIR = tempfile.mkdtemp()\n    ROOT_SERVICES_PATH = os.path.join(\n        tempfile.mkdtemp(), 'reference', 'services'\n    )\n    session = boto3.Session(region_name='us-east-1')\n    yield from session.get_available_services()\n    # Clean up temporary directory after testing.\n    shutil.rmtree(DOCS_ROOT_DIR)\n\n\n@pytest.fixture\ndef available_resources():\n    session = boto3.Session(region_name='us-east-1')\n    return session.get_available_resources()\n\n\n@pytest.mark.parametrize('service_name', all_services())\ndef test_documentation(\n    boto3_session, botocore_session, available_resources, service_name\n):\n    generated_docs = ServiceDocumenter(\n        service_name, session=boto3_session, root_docs_path=ROOT_SERVICES_PATH\n    ).document_service()\n    generated_docs = generated_docs.decode('utf-8')\n    client = boto3.client(service_name, 'us-east-1')\n\n    # Check that all of the services have the appropriate title\n    _assert_has_title(generated_docs, client)\n\n    # Check that all services have the client documented.\n    _assert_has_client_documentation(generated_docs, service_name, client)\n\n    # If the service has resources, make sure the service resource\n    # is at least documented.\n    if service_name in available_resources:\n        resource = boto3.resource(service_name, 'us-east-1')\n        _assert_has_resource_documentation(\n            generated_docs, service_name, resource\n        )\n\n    # If the client can paginate, make sure the paginators are documented.\n    try:\n        paginator_model = botocore_session.get_paginator_model(service_name)\n        if paginator_model._paginator_config:\n            _assert_has_paginator_documentation(\n                generated_docs,\n                service_name,\n                client,\n                sorted(paginator_model._paginator_config),\n            )\n    except DataNotFoundError:\n        pass\n\n    # If the client has waiters, make sure the waiters are documented.\n    if client.waiter_names:\n        waiter_model = botocore_session.get_waiter_model(service_name)\n        _assert_has_waiter_documentation(\n            generated_docs, service_name, client, waiter_model\n        )\n\n\ndef _assert_contains_lines_in_order(lines, contents):\n    for line in lines:\n        assert line in contents\n        beginning = contents.find(line)\n        contents = contents[(beginning + len(line)) :]\n\n\ndef _assert_has_title(generated_docs, client):\n    title = client.__class__.__name__\n    ref_lines = ['*' * len(title), title, '*' * len(title)]\n    _assert_contains_lines_in_order(ref_lines, generated_docs)\n\n\ndef _assert_has_client_documentation(generated_docs, service_name, client):\n    class_name = client.__class__.__name__\n    ref_lines = [\n        '======',\n        'Client',\n        '======',\n        f'.. py:class:: {class_name}.Client',\n        '  A low-level client representing',\n        '    import boto3',\n        f'    client = boto3.client(\\'{service_name}\\')',\n        'These are the available methods:',\n        f'  {service_name}/client/get_paginator',\n        f'  {service_name}/client/get_waiter',\n    ]\n    _assert_contains_lines_in_order(ref_lines, generated_docs)\n    for method_name in ['get_paginator', 'get_waiter']:\n        _assert_contains_lines_in_order(\n            [\n                f'{method_name}',\n                f'.. py:method:: {client.__class__.__name__}.Client.{method_name}(',\n            ],\n            get_nested_file_contents(service_name, 'client', method_name),\n        )\n\n\ndef _assert_has_paginator_documentation(\n    generated_docs, service_name, client, paginator_names\n):\n    ref_lines = [\n        '==========',\n        'Paginators',\n        '==========',\n        'The available paginators are:',\n    ]\n    for paginator_name in paginator_names:\n        ref_lines.append(f'  {service_name}/paginator/{paginator_name}')\n\n    for paginator_name in paginator_names:\n        _assert_contains_lines_in_order(\n            [\n                f'.. py:class:: {client.__class__.__name__}.Paginator.{paginator_name}',\n                '  .. py:method:: paginate(',\n            ],\n            get_nested_file_contents(\n                service_name, 'paginator', paginator_name\n            ),\n        )\n\n    _assert_contains_lines_in_order(ref_lines, generated_docs)\n\n\ndef _assert_has_waiter_documentation(\n    generated_docs, service_name, client, waiter_model\n):\n    ref_lines = ['=======', 'Waiters', '=======', 'The available waiters are:']\n    for waiter_name in waiter_model.waiter_names:\n        ref_lines.append(f'  {service_name}/waiter/{waiter_name}')\n\n    for waiter_name in waiter_model.waiter_names:\n        _assert_contains_lines_in_order(\n            [\n                f'.. py:class:: {client.__class__.__name__}.Waiter.{waiter_name}',\n                f'    waiter = client.get_waiter(\\'{xform_name(waiter_name)}\\')',\n                '  .. py:method:: wait(',\n            ],\n            get_nested_file_contents(service_name, 'waiter', waiter_name),\n        )\n\n    _assert_contains_lines_in_order(ref_lines, generated_docs)\n\n\ndef _assert_has_resource_documentation(generated_docs, service_name, resource):\n    ref_lines = [\n        '=======',\n        'Resources',\n        '=======',\n        'The available resources are:',\n    ]\n    ref_lines.append(f'  {service_name}/service-resource/index')\n    _assert_contains_lines_in_order(ref_lines, generated_docs)\n\n    service_resource_ref_lines = [\n        '================',\n        'Service Resource',\n        '================',\n        f'.. py:class:: {resource.meta.client.__class__.__name__}.ServiceResource',\n        '  A resource representing',\n        '    import boto3',\n        f'    {service_name} = boto3.resource(\\'{service_name}\\')',\n    ]\n    _assert_contains_lines_in_order(\n        service_resource_ref_lines,\n        get_nested_file_contents(service_name, 'service-resource', 'index'),\n    )\n\n\ndef get_nested_file_contents(service_name, sub_folder, file_name):\n    service_file_path = os.path.join(\n        ROOT_SERVICES_PATH,\n        service_name,\n        sub_folder,\n        f'{file_name}.rst',\n    )\n    with open(service_file_path, 'rb') as f:\n        return f.read().decode('utf-8')\n", "tests/functional/docs/__init__.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport os\nimport shutil\nimport tempfile\n\nfrom tests import unittest\n\n\nclass BaseDocsFunctionalTests(unittest.TestCase):\n    def setUp(self):\n        self.docs_root_dir = tempfile.mkdtemp()\n        self.root_services_path = os.path.join(\n            self.docs_root_dir, 'reference', 'services'\n        )\n\n    def tearDown(self):\n        shutil.rmtree(self.docs_root_dir)\n\n    def assert_contains_lines_in_order(self, lines, contents):\n        for line in lines:\n            assert line in contents\n            beginning = contents.find(line)\n            contents = contents[(beginning + len(line)) :]\n\n    def get_class_document_block(self, class_name, contents):\n        start_class_document = f'.. py:class:: {class_name}'\n        start_index = contents.find(start_class_document)\n        assert start_index != -1, 'Class is not found in contents'\n        contents = contents[start_index:]\n        end_index = contents.find('  .. py:class::', len(start_class_document))\n        return contents[:end_index]\n\n    def get_method_document_block(self, method_name, contents):\n        start_method_document = f'  .. py:method:: {method_name}('\n        start_index = contents.find(start_method_document)\n        assert start_index != -1, 'Method is not found in contents'\n        contents = contents[start_index:]\n        end_index = contents.find(\n            '  .. py:method::', len(start_method_document)\n        )\n        return contents[:end_index]\n\n    def get_request_syntax_document_block(self, contents):\n        start_marker = '**Request Syntax**'\n        start_index = contents.find(start_marker)\n        assert start_index != -1, 'There is no request syntax section'\n        contents = contents[start_index:]\n        end_index = contents.find(':type', len(start_marker))\n        return contents[:end_index]\n\n    def get_response_syntax_document_block(self, contents):\n        start_marker = '**Response Syntax**'\n        start_index = contents.find(start_marker)\n        assert start_index != -1, 'There is no response syntax section'\n        contents = contents[start_index:]\n        end_index = contents.find('**Response Structure**', len(start_marker))\n        return contents[:end_index]\n\n    def get_request_parameter_document_block(self, param_name, contents):\n        start_param_document = f':type {param_name}:'\n        start_index = contents.find(start_param_document)\n        assert start_index != -1, 'Param is not found in contents'\n        contents = contents[start_index:]\n        end_index = contents.find(':type', len(start_param_document))\n        return contents[:end_index]\n\n    def get_response_parameter_document_block(self, param_name, contents):\n        start_param_document = '**Response Structure**'\n        start_index = contents.find(start_param_document)\n        assert start_index != -1, 'There is no response structure'\n\n        start_param_document = f'- **{param_name}**'\n        start_index = contents.find(start_param_document)\n        assert start_index != -1, 'Param is not found in contents'\n        contents = contents[start_index:]\n        end_index = contents.find('- **', len(start_param_document))\n        return contents[:end_index]\n\n    def get_nested_file_contents(self, service_name, sub_folder, file_name):\n        service_file_path = os.path.join(\n            self.root_services_path,\n            service_name,\n            sub_folder,\n            f'{file_name}.rst',\n        )\n        with open(service_file_path, 'rb') as f:\n            return f.read().decode('utf-8')\n", "tests/unit/test_boto3.py": "# Copyright 2014 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n\nimport boto3\nfrom tests import mock, unittest\n\n\nclass TestBoto3(unittest.TestCase):\n    def setUp(self):\n        self.session_patch = mock.patch('boto3.Session', autospec=True)\n        self.Session = self.session_patch.start()\n\n    def tearDown(self):\n        boto3.DEFAULT_SESSION = None\n        self.session_patch.stop()\n\n    def test_create_default_session(self):\n        session = self.Session.return_value\n\n        boto3.setup_default_session()\n\n        assert boto3.DEFAULT_SESSION == session\n\n    def test_create_default_session_with_args(self):\n        boto3.setup_default_session(\n            aws_access_key_id='key', aws_secret_access_key='secret'\n        )\n\n        self.Session.assert_called_with(\n            aws_access_key_id='key', aws_secret_access_key='secret'\n        )\n\n    @mock.patch(\n        'boto3.setup_default_session', wraps=boto3.setup_default_session\n    )\n    def test_client_creates_default_session(self, setup_session):\n        boto3.DEFAULT_SESSION = None\n\n        boto3.client('sqs')\n\n        assert setup_session.called\n        assert boto3.DEFAULT_SESSION.client.called\n\n    @mock.patch(\n        'boto3.setup_default_session', wraps=boto3.setup_default_session\n    )\n    def test_client_uses_existing_session(self, setup_session):\n        boto3.DEFAULT_SESSION = self.Session()\n\n        boto3.client('sqs')\n\n        assert not setup_session.called\n        assert boto3.DEFAULT_SESSION.client.called\n\n    def test_client_passes_through_arguments(self):\n        boto3.DEFAULT_SESSION = self.Session()\n\n        boto3.client('sqs', region_name='us-west-2', verify=False)\n\n        boto3.DEFAULT_SESSION.client.assert_called_with(\n            'sqs', region_name='us-west-2', verify=False\n        )\n\n    @mock.patch(\n        'boto3.setup_default_session', wraps=boto3.setup_default_session\n    )\n    def test_resource_creates_default_session(self, setup_session):\n        boto3.DEFAULT_SESSION = None\n\n        boto3.resource('sqs')\n\n        assert setup_session.called\n        assert boto3.DEFAULT_SESSION.resource.called\n\n    @mock.patch(\n        'boto3.setup_default_session', wraps=boto3.setup_default_session\n    )\n    def test_resource_uses_existing_session(self, setup_session):\n        boto3.DEFAULT_SESSION = self.Session()\n\n        boto3.resource('sqs')\n\n        assert not setup_session.called\n        assert boto3.DEFAULT_SESSION.resource.called\n\n    def test_resource_passes_through_arguments(self):\n        boto3.DEFAULT_SESSION = self.Session()\n\n        boto3.resource('sqs', region_name='us-west-2', verify=False)\n\n        boto3.DEFAULT_SESSION.resource.assert_called_with(\n            'sqs', region_name='us-west-2', verify=False\n        )\n", "tests/unit/__init__.py": "", "tests/unit/test_session.py": "# Copyright 2014 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport pytest\nfrom botocore import loaders\nfrom botocore.client import Config\nfrom botocore.exceptions import UnknownServiceError\n\nfrom boto3 import __version__\nfrom boto3.exceptions import ResourceNotExistsError\nfrom boto3.session import Session\nfrom tests import BaseTestCase, mock\n\n\nclass TestSession(BaseTestCase):\n    def test_repr(self):\n        bc_session = self.bc_session_cls.return_value\n        bc_session.get_credentials.return_value.access_key = 'abc123'\n        bc_session.get_config_variable.return_value = 'us-west-2'\n\n        session = Session('abc123', region_name='us-west-2')\n\n        assert repr(session) == 'Session(region_name=\\'us-west-2\\')'\n\n    def test_repr_on_subclasses(self):\n        bc_session = self.bc_session_cls.return_value\n        bc_session.get_credentials.return_value.access_key = 'abc123'\n        bc_session.get_config_variable.return_value = 'us-west-2'\n\n        class MySession(Session):\n            pass\n\n        session = MySession('abc123', region_name='us-west-2')\n\n        assert repr(session) == 'MySession(region_name=\\'us-west-2\\')'\n\n    def test_can_access_region_name(self):\n        bc_session = self.bc_session_cls.return_value\n        bc_session.get_config_variable.return_value = 'us-west-2'\n        session = Session('abc123', region_name='us-west-2')\n        bc_session.set_config_variable.assert_called_with(\n            'region', 'us-west-2'\n        )\n\n        assert session.region_name == 'us-west-2'\n\n    def test_arguments_not_required(self):\n        Session()\n\n        assert self.bc_session_cls.called\n\n    def test_credentials_can_be_set(self):\n        bc_session = self.bc_session_cls.return_value\n\n        # Set values in constructor\n        Session(\n            aws_access_key_id='key',\n            aws_secret_access_key='secret',\n            aws_session_token='token',\n        )\n\n        assert self.bc_session_cls.called\n        assert bc_session.set_credentials.called\n        bc_session.set_credentials.assert_called_with('key', 'secret', 'token')\n\n    def test_can_get_credentials(self):\n        access_key = 'foo'\n        secret_key = 'bar'\n        token = 'baz'\n\n        creds = mock.Mock()\n        creds.access_key = access_key\n        creds.secret_key = secret_key\n        creds.token = token\n\n        bc_session = self.bc_session_cls.return_value\n        bc_session.get_credentials.return_value = creds\n\n        session = Session(\n            aws_access_key_id=access_key,\n            aws_secret_access_key=secret_key,\n            aws_session_token=token,\n        )\n\n        credentials = session.get_credentials()\n        assert credentials.access_key == access_key\n        assert credentials.secret_key == secret_key\n        assert credentials.token == token\n\n    def test_profile_can_be_set(self):\n        bc_session = self.bc_session_cls.return_value\n\n        session = Session(profile_name='foo')\n\n        bc_session.set_config_variable.assert_called_with('profile', 'foo')\n        bc_session.profile = 'foo'\n\n        # We should also be able to read the value\n        assert session.profile_name == 'foo'\n\n    def test_profile_default(self):\n        self.bc_session_cls.return_value.profile = None\n\n        session = Session()\n\n        assert session.profile_name == 'default'\n\n    def test_available_profiles(self):\n        bc_session = mock.Mock()\n        bc_session.available_profiles.return_value = ['foo', 'bar']\n        session = Session(botocore_session=bc_session)\n        profiles = session.available_profiles\n        assert len(profiles.return_value) == 2\n\n    def test_custom_session(self):\n        bc_session = self.bc_session_cls()\n        self.bc_session_cls.reset_mock()\n\n        Session(botocore_session=bc_session)\n\n        # No new session was created\n        assert not self.bc_session_cls.called\n\n    def test_user_agent(self):\n        # Here we get the underlying Botocore session, create a Boto3\n        # session, and ensure that the user-agent is modified as expected\n        bc_session = self.bc_session_cls.return_value\n        bc_session.user_agent_name = 'Botocore'\n        bc_session.user_agent_version = '0.68.0'\n        bc_session.user_agent_extra = ''\n\n        Session(botocore_session=bc_session)\n\n        assert bc_session.user_agent_name == 'Boto3'\n        assert bc_session.user_agent_version == __version__\n        assert bc_session.user_agent_extra == 'Botocore/0.68.0'\n\n    def test_user_agent_extra(self):\n        # This test is the same as above, but includes custom extra content\n        # which must still be in the final modified user-agent.\n        bc_session = self.bc_session_cls.return_value\n        bc_session.user_agent_name = 'Botocore'\n        bc_session.user_agent_version = '0.68.0'\n        bc_session.user_agent_extra = 'foo'\n\n        Session(botocore_session=bc_session)\n\n        assert bc_session.user_agent_extra == 'foo Botocore/0.68.0'\n\n    def test_custom_user_agent(self):\n        # This test ensures that a customized user-agent is left untouched.\n        bc_session = self.bc_session_cls.return_value\n        bc_session.user_agent_name = 'Custom'\n        bc_session.user_agent_version = '1.0'\n        bc_session.user_agent_extra = ''\n\n        Session(botocore_session=bc_session)\n\n        assert bc_session.user_agent_name == 'Custom'\n        assert bc_session.user_agent_version == '1.0'\n        assert bc_session.user_agent_extra == ''\n\n    def test_get_available_services(self):\n        bc_session = self.bc_session_cls.return_value\n\n        session = Session()\n        session.get_available_services()\n\n        assert bc_session.get_available_services.called\n\n    def test_get_available_resources(self):\n        mock_bc_session = mock.Mock()\n        loader = mock.Mock(spec=loaders.Loader)\n        loader.list_available_services.return_value = ['foo', 'bar']\n        mock_bc_session.get_component.return_value = loader\n        session = Session(botocore_session=mock_bc_session)\n\n        names = session.get_available_resources()\n        assert names == ['foo', 'bar']\n\n    def test_get_available_partitions(self):\n        bc_session = mock.Mock()\n        bc_session.get_available_partitions.return_value = ['foo']\n        session = Session(botocore_session=bc_session)\n\n        partitions = session.get_available_partitions()\n        assert partitions == ['foo']\n\n    def test_get_available_regions(self):\n        bc_session = mock.Mock()\n        bc_session.get_available_regions.return_value = ['foo']\n        session = Session(botocore_session=bc_session)\n\n        partitions = session.get_available_regions('myservice')\n        bc_session.get_available_regions.assert_called_with(\n            service_name='myservice',\n            partition_name='aws',\n            allow_non_regional=False,\n        )\n        assert partitions == ['foo']\n\n    def test_get_partition_for_region(self):\n        bc_session = mock.Mock()\n        bc_session.get_partition_for_region.return_value = 'baz'\n        session = Session(botocore_session=bc_session)\n\n        partition = session.get_partition_for_region('foo-bar-1')\n        bc_session.get_partition_for_region.assert_called_with('foo-bar-1')\n        assert partition == 'baz'\n\n    def test_create_client(self):\n        session = Session(region_name='us-east-1')\n        client = session.client('sqs', region_name='us-west-2')\n\n        assert client, 'No low-level client was returned'\n\n    def test_create_client_with_args(self):\n        bc_session = self.bc_session_cls.return_value\n\n        session = Session(region_name='us-east-1')\n        session.client('sqs', region_name='us-west-2')\n\n        bc_session.create_client.assert_called_with(\n            'sqs',\n            aws_secret_access_key=None,\n            aws_access_key_id=None,\n            endpoint_url=None,\n            use_ssl=True,\n            aws_session_token=None,\n            verify=None,\n            region_name='us-west-2',\n            api_version=None,\n            config=None,\n        )\n\n    def test_create_resource_with_args(self):\n        mock_bc_session = mock.Mock()\n        loader = mock.Mock(spec=loaders.Loader)\n        loader.determine_latest_version.return_value = '2014-11-02'\n        loader.load_service_model.return_value = {\n            'resources': [],\n            'service': [],\n        }\n        mock_bc_session.get_component.return_value = loader\n        session = Session(botocore_session=mock_bc_session)\n        session.resource_factory.load_from_definition = mock.Mock()\n        session.client = mock.Mock()\n\n        session.resource('sqs', verify=False)\n\n        session.client.assert_called_with(\n            'sqs',\n            aws_secret_access_key=None,\n            aws_access_key_id=None,\n            endpoint_url=None,\n            use_ssl=True,\n            aws_session_token=None,\n            verify=False,\n            region_name=None,\n            api_version='2014-11-02',\n            config=mock.ANY,\n        )\n        client_config = session.client.call_args[1]['config']\n        assert client_config.user_agent_extra == 'Resource'\n        assert client_config.signature_version is None\n\n    def test_create_resource_with_config(self):\n        mock_bc_session = mock.Mock()\n        loader = mock.Mock(spec=loaders.Loader)\n        loader.determine_latest_version.return_value = '2014-11-02'\n        loader.load_service_model.return_value = {\n            'resources': [],\n            'service': [],\n        }\n        mock_bc_session.get_component.return_value = loader\n        session = Session(botocore_session=mock_bc_session)\n        session.resource_factory.load_from_definition = mock.Mock()\n        session.client = mock.Mock()\n        config = Config(signature_version='v4')\n\n        session.resource('sqs', config=config)\n\n        session.client.assert_called_with(\n            'sqs',\n            aws_secret_access_key=None,\n            aws_access_key_id=None,\n            endpoint_url=None,\n            use_ssl=True,\n            aws_session_token=None,\n            verify=None,\n            region_name=None,\n            api_version='2014-11-02',\n            config=mock.ANY,\n        )\n        client_config = session.client.call_args[1]['config']\n        assert client_config.user_agent_extra == 'Resource'\n        assert client_config.signature_version == 'v4'\n\n    def test_create_resource_with_config_override_user_agent_extra(self):\n        mock_bc_session = mock.Mock()\n        loader = mock.Mock(spec=loaders.Loader)\n        loader.determine_latest_version.return_value = '2014-11-02'\n        loader.load_service_model.return_value = {\n            'resources': [],\n            'service': [],\n        }\n        mock_bc_session.get_component.return_value = loader\n        session = Session(botocore_session=mock_bc_session)\n        session.resource_factory.load_from_definition = mock.Mock()\n        session.client = mock.Mock()\n        config = Config(signature_version='v4', user_agent_extra='foo')\n\n        session.resource('sqs', config=config)\n\n        session.client.assert_called_with(\n            'sqs',\n            aws_secret_access_key=None,\n            aws_access_key_id=None,\n            endpoint_url=None,\n            use_ssl=True,\n            aws_session_token=None,\n            verify=None,\n            region_name=None,\n            api_version='2014-11-02',\n            config=mock.ANY,\n        )\n        client_config = session.client.call_args[1]['config']\n        assert client_config.user_agent_extra == 'foo'\n        assert client_config.signature_version == 'v4'\n\n    def test_create_resource_latest_version(self):\n        mock_bc_session = mock.Mock()\n        loader = mock.Mock(spec=loaders.Loader)\n        loader.determine_latest_version.return_value = '2014-11-02'\n        loader.load_service_model.return_value = {\n            'resources': [],\n            'service': [],\n        }\n        mock_bc_session.get_component.return_value = loader\n        session = Session(botocore_session=mock_bc_session)\n        session.resource_factory.load_from_definition = mock.Mock()\n\n        session.resource('sqs')\n\n        loader.load_service_model.assert_called_with(\n            'sqs', 'resources-1', None\n        )\n\n    def test_bad_resource_name(self):\n        mock_bc_session = mock.Mock()\n        loader = mock.Mock(spec=loaders.Loader)\n        loader.load_service_model.side_effect = UnknownServiceError(\n            service_name='foo', known_service_names='asdf'\n        )\n        mock_bc_session.get_component.return_value = loader\n        loader.list_available_services.return_value = ['good-resource']\n        mock_bc_session.get_available_services.return_value = ['sqs']\n\n        session = Session(botocore_session=mock_bc_session)\n        with pytest.raises(ResourceNotExistsError) as e:\n            session.resource('sqs')\n\n            err_msg = str(e.exception)\n            # 1. should say the resource doesn't exist.\n            assert 'resource does not exist' in err_msg\n            assert 'sqs' in err_msg\n            # 2. Should list available resources you can choose.\n            assert 'good-resource' in err_msg\n            # 3. Should list client if available.\n            assert 'client' in err_msg\n\n    def test_bad_resource_name_with_no_client_has_simple_err_msg(self):\n        mock_bc_session = mock.Mock()\n        loader = mock.Mock(spec=loaders.Loader)\n        loader.load_service_model.side_effect = UnknownServiceError(\n            service_name='foo', known_service_names='asdf'\n        )\n        mock_bc_session.get_component.return_value = loader\n        loader.list_available_services.return_value = ['good-resource']\n        mock_bc_session.get_available_services.return_value = ['good-client']\n\n        session = Session(botocore_session=mock_bc_session)\n        with pytest.raises(ResourceNotExistsError) as e:\n            session.resource('bad-client')\n\n            err_msg = str(e.exception)\n            # Shouldn't mention anything about clients because\n            # 'bad-client' it not a valid boto3.client(...)\n            assert 'boto3.client' not in err_msg\n\n    def test_can_reach_events(self):\n        mock_bc_session = self.bc_session_cls()\n        session = Session(botocore_session=mock_bc_session)\n        session.events\n        mock_bc_session.get_component.assert_called_with('event_emitter')\n", "tests/unit/test_crt.py": "# Copyright 2023 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport botocore.exceptions\nimport pytest\nimport s3transfer\nfrom botocore.compat import HAS_CRT\nfrom botocore.credentials import Credentials\n\nimport boto3\nfrom boto3.s3.transfer import TransferConfig\nfrom tests import mock, requires_crt\n\nif HAS_CRT:\n    from awscrt.s3 import CrossProcessLock as CrossProcessLockClass\n    from s3transfer.crt import BotocoreCRTCredentialsWrapper\n\n    import boto3.crt\n\n\n@pytest.fixture\ndef mock_crt_process_lock(monkeypatch):\n    # The process lock is cached at the module layer whenever the\n    # cross process lock is successfully acquired. This patch ensures that\n    # test cases will start off with no previously cached process lock and\n    # if a cross process is instantiated/acquired it will be the mock that\n    # can be used for controlling lock behavior.\n    if HAS_CRT:\n        monkeypatch.setattr('s3transfer.crt.CRT_S3_PROCESS_LOCK', None)\n        with mock.patch('awscrt.s3.CrossProcessLock', spec=True) as mock_lock:\n            yield mock_lock\n    else:\n        # We cannot mock or use the lock without CRT support.\n        yield None\n\n\n@pytest.fixture\ndef mock_crt_client_singleton(monkeypatch):\n    # Clear CRT state for each test\n    if HAS_CRT:\n        monkeypatch.setattr('boto3.crt.CRT_S3_CLIENT', None)\n    yield None\n\n\n@pytest.fixture\ndef mock_serializer_singleton(monkeypatch):\n    # Clear CRT state for each test\n    if HAS_CRT:\n        monkeypatch.setattr('boto3.crt.BOTOCORE_CRT_SERIALIZER', None)\n    yield None\n\n\ndef create_test_client(service_name='s3', region_name=\"us-east-1\"):\n    return boto3.client(\n        service_name,\n        region_name=region_name,\n        aws_access_key_id=\"access\",\n        aws_secret_access_key=\"secret\",\n        aws_session_token=\"token\",\n    )\n\n\nUSW2_S3_CLIENT = create_test_client(region_name=\"us-west-2\")\nUSE1_S3_CLIENT = create_test_client(region_name=\"us-east-1\")\n\n\nclass TestCRTTransferManager:\n    @requires_crt()\n    def test_create_crt_transfer_manager_with_lock_in_use(\n        self,\n        mock_crt_process_lock,\n        mock_crt_client_singleton,\n        mock_serializer_singleton,\n    ):\n        mock_crt_process_lock.return_value.acquire.side_effect = RuntimeError\n\n        # Verify we can't create a second CRT client\n        tm = boto3.crt.create_crt_transfer_manager(USW2_S3_CLIENT, None)\n        assert tm is None\n\n    @requires_crt()\n    def test_create_crt_transfer_manager(\n        self,\n        mock_crt_process_lock,\n        mock_crt_client_singleton,\n        mock_serializer_singleton,\n    ):\n        tm = boto3.crt.create_crt_transfer_manager(USW2_S3_CLIENT, None)\n        assert isinstance(tm, s3transfer.crt.CRTTransferManager)\n\n    @requires_crt()\n    def test_crt_singleton_is_returned_every_call(\n        self,\n        mock_crt_process_lock,\n        mock_crt_client_singleton,\n        mock_serializer_singleton,\n    ):\n        first_s3_client = boto3.crt.get_crt_s3_client(USW2_S3_CLIENT, None)\n        second_s3_client = boto3.crt.get_crt_s3_client(USW2_S3_CLIENT, None)\n\n        assert isinstance(first_s3_client, boto3.crt.CRTS3Client)\n        assert first_s3_client is second_s3_client\n        assert first_s3_client.crt_client is second_s3_client.crt_client\n\n    @requires_crt()\n    def test_create_crt_transfer_manager_w_client_in_wrong_region(\n        self,\n        mock_crt_process_lock,\n        mock_crt_client_singleton,\n        mock_serializer_singleton,\n    ):\n        \"\"\"Ensure we don't return the crt transfer manager if client is in\n        different region. The CRT isn't able to handle region redirects and\n        will consistently fail.\n\n        We can remove this test once we have this fixed on the CRT side.\n        \"\"\"\n        usw2_s3_client = boto3.crt.create_crt_transfer_manager(\n            USW2_S3_CLIENT, None\n        )\n        assert isinstance(usw2_s3_client, boto3.crt.CRTTransferManager)\n\n        use1_s3_client = boto3.crt.create_crt_transfer_manager(\n            USE1_S3_CLIENT, None\n        )\n        assert use1_s3_client is None\n\n    @pytest.mark.parametrize(\n        \"boto3_tuple,crt_tuple,matching\",\n        (\n            (\n                (\"access\", \"secret\", \"token\"),\n                (\"access\", \"secret\", \"token\"),\n                True,\n            ),\n            (\n                (\"access\", \"secret\", \"token\"),\n                (\"noaccess\", \"secret\", \"token\"),\n                False,\n            ),\n            (\n                (\"access\", \"secret\", \"token\"),\n                (\"access\", \"nosecret\", \"token\"),\n                False,\n            ),\n            (\n                (\"access\", \"secret\", \"token\"),\n                (\"access\", \"secret\", \"notoken\"),\n                False,\n            ),\n        ),\n    )\n    @requires_crt()\n    def test_compare_identities(self, boto3_tuple, crt_tuple, matching):\n        boto3_creds = Credentials(*boto3_tuple)\n        crt_creds = Credentials(*crt_tuple)\n        crt_creds_wrapper = BotocoreCRTCredentialsWrapper(crt_creds)\n        assert (\n            boto3.crt.compare_identity(boto3_creds, crt_creds_wrapper)\n            is matching\n        )\n\n    @requires_crt()\n    def test_compare_idenities_no_credentials(self):\n        def no_credentials():\n            raise botocore.exceptions.NoCredentialsError()\n\n        boto3_creds = Credentials(\"access\", \"secret\", \"token\")\n        crt_creds_wrapper = no_credentials\n        assert (\n            boto3.crt.compare_identity(boto3_creds, crt_creds_wrapper) is False\n        )\n\n    @requires_crt()\n    def test_get_crt_s3_client(\n        self,\n        mock_crt_process_lock,\n        mock_crt_client_singleton,\n        mock_serializer_singleton,\n    ):\n        config = TransferConfig()\n        crt_s3_client = boto3.crt.get_crt_s3_client(USW2_S3_CLIENT, config)\n        assert isinstance(crt_s3_client, boto3.crt.CRTS3Client)\n        assert isinstance(crt_s3_client.process_lock, CrossProcessLockClass)\n        assert crt_s3_client.region == \"us-west-2\"\n        assert isinstance(\n            crt_s3_client.cred_provider, BotocoreCRTCredentialsWrapper\n        )\n\n    @requires_crt()\n    def test_get_crt_s3_client_w_wrong_region(\n        self,\n        mock_crt_process_lock,\n        mock_crt_client_singleton,\n        mock_serializer_singleton,\n    ):\n        config = TransferConfig()\n        crt_s3_client = boto3.crt.get_crt_s3_client(USW2_S3_CLIENT, config)\n        assert isinstance(crt_s3_client, boto3.crt.CRTS3Client)\n\n        # Ensure we don't create additional CRT clients\n        use1_crt_s3_client = boto3.crt.get_crt_s3_client(\n            USE1_S3_CLIENT, config\n        )\n        assert use1_crt_s3_client is crt_s3_client\n        assert use1_crt_s3_client.region == \"us-west-2\"\n", "tests/unit/test_utils.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport types\n\nimport pytest\n\nfrom boto3 import utils\nfrom tests import mock, unittest\n\n\nclass FakeModule:\n    @staticmethod\n    def entry_point(**kwargs):\n        return kwargs\n\n\nclass TestUtils(unittest.TestCase):\n    def test_lazy_call(self):\n        with mock.patch('boto3.utils.import_module') as importer:\n            importer.return_value = FakeModule\n            lazy_function = utils.lazy_call(\n                'fakemodule.FakeModule.entry_point'\n            )\n            assert lazy_function(a=1, b=2) == {'a': 1, 'b': 2}\n\n    def test_import_module(self):\n        module = utils.import_module('boto3.s3.transfer')\n        assert module.__name__ == 'boto3.s3.transfer'\n        assert isinstance(module, types.ModuleType)\n\n    def test_inject_attributes_with_no_shadowing(self):\n        class_attributes = {}\n        utils.inject_attribute(class_attributes, 'foo', 'bar')\n        assert class_attributes['foo'] == 'bar'\n\n    def test_shadowing_existing_var_raises_exception(self):\n        class_attributes = {'foo': 'preexisting'}\n        with pytest.raises(RuntimeError):\n            utils.inject_attribute(class_attributes, 'foo', 'bar')\n\n\nclass TestLazyLoadedWaiterModel(unittest.TestCase):\n    def test_get_waiter_model_is_lazy(self):\n        session = mock.Mock()\n        waiter_model = utils.LazyLoadedWaiterModel(\n            session, 'myservice', '2014-01-01'\n        )\n        assert not session.get_waiter_model.called\n        waiter_model.get_waiter('Foo')\n        assert session.get_waiter_model.called\n        session.get_waiter_model.return_value.get_waiter.assert_called_with(\n            'Foo'\n        )\n", "tests/unit/resources/test_collection.py": "# Copyright 2014 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the 'License'). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the 'license' file accompanying this file. This file is\n# distributed on an 'AS IS' BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport pytest\nfrom botocore.hooks import HierarchicalEmitter\nfrom botocore.model import ServiceModel\n\nfrom boto3.resources.base import ResourceMeta\nfrom boto3.resources.collection import (\n    CollectionFactory,\n    CollectionManager,\n    ResourceCollection,\n)\nfrom boto3.resources.factory import ResourceFactory\nfrom boto3.resources.model import Collection\nfrom boto3.utils import ServiceContext\nfrom tests import BaseTestCase, mock\n\n\nclass TestCollectionFactory(BaseTestCase):\n    def setUp(self):\n        super().setUp()\n\n        self.client = mock.Mock()\n        self.client.can_paginate.return_value = False\n        self.parent = mock.Mock()\n        self.parent.meta = ResourceMeta('test', client=self.client)\n        self.resource_factory = ResourceFactory(mock.Mock())\n        self.service_model = ServiceModel({})\n        self.event_emitter = HierarchicalEmitter()\n\n        self.factory = CollectionFactory()\n        self.load = self.factory.load_from_definition\n\n    def test_create_subclasses(self):\n        resource_defs = {\n            'Frob': {},\n            'Chain': {\n                'hasMany': {\n                    'Frobs': {\n                        'request': {'operation': 'GetFrobs'},\n                        'resource': {'type': 'Frob'},\n                    }\n                }\n            },\n        }\n        collection_model = Collection(\n            'Frobs', resource_defs['Chain']['hasMany']['Frobs'], resource_defs\n        )\n\n        service_context = ServiceContext(\n            service_name='test',\n            resource_json_definitions=resource_defs,\n            service_model=self.service_model,\n            service_waiter_model=None,\n        )\n        collection_cls = self.load(\n            resource_name='Chain',\n            collection_model=collection_model,\n            service_context=service_context,\n            event_emitter=self.event_emitter,\n        )\n        collection = collection_cls(\n            collection_model=collection_model,\n            parent=self.parent,\n            factory=self.resource_factory,\n            service_context=service_context,\n        )\n\n        assert collection_cls.__name__ == 'test.Chain.FrobsCollectionManager'\n        assert isinstance(collection, CollectionManager)\n\n        # Make sure that collection manager created from the factory\n        # returns a ResourceCollection.\n        assert isinstance(collection.all(), ResourceCollection)\n\n        # Make sure that the collection returned from the collection\n        # manager can be chained and return a ResourceCollection as well.\n        assert isinstance(collection.all().all(), ResourceCollection)\n\n    @mock.patch('boto3.resources.collection.BatchAction')\n    def test_create_batch_actions(self, action_mock):\n        resource_defs = {\n            'Frob': {\n                'batchActions': {\n                    'Delete': {'request': {'operation': 'DeleteFrobs'}}\n                }\n            },\n            'Chain': {\n                'hasMany': {\n                    'Frobs': {\n                        'request': {'operation': 'GetFrobs'},\n                        'resource': {'type': 'Frob'},\n                    }\n                }\n            },\n        }\n\n        collection_model = Collection(\n            'Frobs', resource_defs['Chain']['hasMany']['Frobs'], resource_defs\n        )\n\n        service_context = ServiceContext(\n            service_name='test',\n            resource_json_definitions=resource_defs,\n            service_model=self.service_model,\n            service_waiter_model=None,\n        )\n        collection_cls = self.load(\n            resource_name='Chain',\n            collection_model=collection_model,\n            service_context=service_context,\n            event_emitter=self.event_emitter,\n        )\n        collection = collection_cls(\n            collection_model=collection_model,\n            parent=self.parent,\n            factory=self.resource_factory,\n            service_context=service_context,\n        )\n\n        assert hasattr(collection, 'delete')\n\n        collection.delete()\n\n        action_mock.return_value.assert_called_with(collection)\n\n\nclass TestResourceCollection(BaseTestCase):\n    def setUp(self):\n        super().setUp()\n\n        # Minimal definition so things like repr work\n        self.collection_def = {\n            'request': {'operation': 'TestOperation'},\n            'resource': {'type': 'Frob'},\n        }\n        self.client = mock.Mock()\n        self.client.can_paginate.return_value = False\n        self.parent = mock.Mock()\n        self.parent.meta = ResourceMeta('test', client=self.client)\n        self.factory = ResourceFactory(mock.Mock())\n        self.service_model = ServiceModel({})\n\n    def get_collection(self):\n        resource_defs = {'Frob': {'identifiers': []}}\n\n        # Build up a resource def identifier list based on what\n        # the collection is expecting to be required from its\n        # definition. This saves a bunch of repetitive typing\n        # and lets you just define a collection in the tests\n        # below. Any identifiers you expect to be availabe in\n        # the resource definition will automatically be there.\n        resource_def = self.collection_def.get('resource', {})\n        for identifier in resource_def.get('identifiers', []):\n            resource_defs['Frob']['identifiers'].append(\n                {'name': identifier['target']}\n            )\n\n        collection_model = Collection(\n            'test', self.collection_def, resource_defs\n        )\n\n        collection = CollectionManager(\n            collection_model=collection_model,\n            parent=self.parent,\n            factory=self.factory,\n            service_context=ServiceContext(\n                service_name='test',\n                service_model=self.service_model,\n                resource_json_definitions=resource_defs,\n                service_waiter_model=None,\n            ),\n        )\n        return collection\n\n    def test_repr(self):\n        collection = self.get_collection()\n        assert 'CollectionManager' in repr(collection)\n\n    def test_iteration_manager(self):\n        # A collection manager is not iterable. You must first call\n        # .all or .filter or another method to get an iterable.\n        collection = self.get_collection()\n        with pytest.raises(TypeError):\n            list(collection)\n\n    def test_iteration_non_paginated(self):\n        self.collection_def = {\n            'request': {'operation': 'GetFrobs'},\n            'resource': {\n                'type': 'Frob',\n                'identifiers': [\n                    {\n                        'target': 'Id',\n                        'source': 'response',\n                        'path': 'Frobs[].Id',\n                    }\n                ],\n            },\n        }\n        self.client.get_frobs.return_value = {\n            'Frobs': [\n                {'Id': 'one'},\n                {'Id': 'two'},\n                {'Id': 'three'},\n                {'Id': 'four'},\n            ]\n        }\n        collection = self.get_collection()\n        items = list(collection.all())\n        assert len(items) == 4\n        assert items[0].id == 'one'\n        assert items[1].id == 'two'\n        assert items[2].id == 'three'\n        assert items[3].id == 'four'\n\n    def test_limit_param_non_paginated(self):\n        self.collection_def = {\n            'request': {'operation': 'GetFrobs'},\n            'resource': {\n                'type': 'Frob',\n                'identifiers': [\n                    {\n                        'target': 'Id',\n                        'source': 'response',\n                        'path': 'Frobs[].Id',\n                    }\n                ],\n            },\n        }\n        self.client.get_frobs.return_value = {\n            'Frobs': [\n                {'Id': 'one'},\n                {'Id': 'two'},\n                {'Id': 'three'},\n                {'Id': 'four'},\n            ]\n        }\n        collection = self.get_collection()\n        items = list(collection.all().limit(2))\n        assert len(items) == 2\n\n        # Only the first two should be present\n        assert items[0].id == 'one'\n        assert items[1].id == 'two'\n\n    def test_limit_method_non_paginated(self):\n        self.collection_def = {\n            'request': {'operation': 'GetFrobs'},\n            'resource': {\n                'type': 'Frob',\n                'identifiers': [\n                    {\n                        'target': 'Id',\n                        'source': 'response',\n                        'path': 'Frobs[].Id',\n                    }\n                ],\n            },\n        }\n        self.client.get_frobs.return_value = {\n            'Frobs': [\n                {'Id': 'one'},\n                {'Id': 'two'},\n                {'Id': 'three'},\n                {'Id': 'four'},\n            ]\n        }\n        collection = self.get_collection()\n        items = list(collection.limit(2))\n        assert len(items) == 2\n\n        # Only the first two should be present\n        assert items[0].id == 'one'\n        assert items[1].id == 'two'\n\n    @mock.patch('boto3.resources.collection.ResourceHandler')\n    def test_filters_non_paginated(self, handler):\n        self.collection_def = {\n            'request': {'operation': 'GetFrobs'},\n            'resource': {'type': 'Frob', 'identifiers': []},\n        }\n        self.client.get_frobs.return_value = {}\n        handler.return_value.return_value = []\n        collection = self.get_collection()\n\n        list(collection.filter(Param1='foo', Param2=3).limit(2))\n\n        # Note - limit is not passed through to the low-level call\n        self.client.get_frobs.assert_called_with(Param1='foo', Param2=3)\n\n    def test_page_iterator_returns_pages_of_items(self):\n        self.collection_def = {\n            'request': {'operation': 'GetFrobs'},\n            'resource': {\n                'type': 'Frob',\n                'identifiers': [\n                    {\n                        'target': 'Id',\n                        'source': 'response',\n                        'path': 'Frobs[].Id',\n                    }\n                ],\n            },\n        }\n        self.client.can_paginate.return_value = True\n        self.client.get_paginator.return_value.paginate.return_value = [\n            {'Frobs': [{'Id': 'one'}, {'Id': 'two'}]},\n            {'Frobs': [{'Id': 'three'}, {'Id': 'four'}]},\n        ]\n        collection = self.get_collection()\n        pages = list(collection.limit(3).pages())\n        assert len(pages) == 2\n        assert len(pages[0]) == 2\n        assert len(pages[1]) == 1\n\n    def test_page_iterator_page_size(self):\n        self.collection_def = {\n            'request': {'operation': 'GetFrobs'},\n            'resource': {\n                'type': 'Frob',\n                'identifiers': [\n                    {\n                        'target': 'Id',\n                        'source': 'response',\n                        'path': 'Frobs[].Id',\n                    }\n                ],\n            },\n        }\n        self.client.can_paginate.return_value = True\n        paginator = self.client.get_paginator.return_value\n        paginator.paginate.return_value = []\n\n        collection = self.get_collection()\n        list(collection.page_size(5).pages())\n\n        paginator.paginate.assert_called_with(\n            PaginationConfig={'PageSize': 5, 'MaxItems': None}\n        )\n\n    def test_iteration_paginated(self):\n        self.collection_def = {\n            'request': {'operation': 'GetFrobs'},\n            'resource': {\n                'type': 'Frob',\n                'identifiers': [\n                    {\n                        'target': 'Id',\n                        'source': 'response',\n                        'path': 'Frobs[].Id',\n                    }\n                ],\n            },\n        }\n        self.client.can_paginate.return_value = True\n        self.client.get_paginator.return_value.paginate.return_value = [\n            {'Frobs': [{'Id': 'one'}, {'Id': 'two'}]},\n            {'Frobs': [{'Id': 'three'}, {'Id': 'four'}]},\n        ]\n        collection = self.get_collection()\n        items = list(collection.all())\n        assert len(items) == 4\n        assert items[0].id == 'one'\n        assert items[1].id == 'two'\n        assert items[2].id == 'three'\n        assert items[3].id == 'four'\n\n        # Low-level pagination should have been called\n        self.client.get_paginator.assert_called_with('get_frobs')\n        paginator = self.client.get_paginator.return_value\n        paginator.paginate.assert_called_with(\n            PaginationConfig={'PageSize': None, 'MaxItems': None}\n        )\n\n    def test_limit_param_paginated(self):\n        self.collection_def = {\n            'request': {'operation': 'GetFrobs'},\n            'resource': {\n                'type': 'Frob',\n                'identifiers': [\n                    {\n                        'target': 'Id',\n                        'source': 'response',\n                        'path': 'Frobs[].Id',\n                    }\n                ],\n            },\n        }\n        self.client.can_paginate.return_value = True\n        self.client.get_paginator.return_value.paginate.return_value = [\n            {'Frobs': [{'Id': 'one'}, {'Id': 'two'}]},\n            {'Frobs': [{'Id': 'three'}, {'Id': 'four'}]},\n        ]\n        collection = self.get_collection()\n        items = list(collection.all().limit(2))\n        assert len(items) == 2\n\n        # Only the first two should be present\n        assert items[0].id == 'one'\n        assert items[1].id == 'two'\n\n    def test_limit_method_paginated(self):\n        self.collection_def = {\n            'request': {'operation': 'GetFrobs'},\n            'resource': {\n                'type': 'Frob',\n                'identifiers': [\n                    {\n                        'target': 'Id',\n                        'source': 'response',\n                        'path': 'Frobs[].Id',\n                    }\n                ],\n            },\n        }\n        self.client.can_paginate.return_value = True\n        self.client.get_paginator.return_value.paginate.return_value = [\n            {'Frobs': [{'Id': 'one'}, {'Id': 'two'}]},\n            {'Frobs': [{'Id': 'three'}, {'Id': 'four'}]},\n        ]\n        collection = self.get_collection()\n        items = list(collection.all().limit(2))\n        assert len(items) == 2\n\n        # Only the first two should be present\n        assert items[0].id == 'one'\n        assert items[1].id == 'two'\n\n    @mock.patch('boto3.resources.collection.ResourceHandler')\n    def test_filters_paginated(self, handler):\n        self.client.can_paginate.return_value = True\n        self.client.get_paginator.return_value.paginate.return_value = []\n        handler.return_value.return_value = []\n        collection = self.get_collection()\n\n        list(collection.filter(Param1='foo', Param2=3).limit(2))\n\n        paginator = self.client.get_paginator.return_value\n        paginator.paginate.assert_called_with(\n            PaginationConfig={'PageSize': None, 'MaxItems': 2},\n            Param1='foo',\n            Param2=3,\n        )\n\n    @mock.patch('boto3.resources.collection.ResourceHandler')\n    def test_filter_does_not_clobber_existing_list_values(self, handler):\n        self.collection_def = {\n            'request': {\n                'operation': 'GetFrobs',\n                \"params\": [\n                    {\n                        \"target\": \"Filters[0].Name\",\n                        \"source\": \"string\",\n                        \"value\": \"frob-id\",\n                    },\n                    {\n                        \"target\": \"Filters[0].Values[0]\",\n                        \"source\": \"identifier\",\n                        \"name\": \"Id\",\n                    },\n                ],\n            },\n            'resource': {\n                'type': 'Frob',\n                'identifiers': [\n                    {\n                        'target': 'Id',\n                        'source': 'response',\n                        'path': 'Frobs[].Id',\n                    }\n                ],\n            },\n        }\n        self.client.can_paginate.return_value = True\n        self.client.get_paginator.return_value.paginate.return_value = []\n        handler.return_value.return_value = []\n        collection = self.get_collection()\n\n        self.parent.id = 'my-id'\n        list(\n            collection.filter(\n                Filters=[{'Name': 'another-filter', 'Values': ['foo']}]\n            )\n        )\n        paginator = self.client.get_paginator.return_value\n        paginator.paginate.assert_called_with(\n            PaginationConfig={'PageSize': None, 'MaxItems': None},\n            Filters=[\n                {'Values': ['my-id'], 'Name': 'frob-id'},\n                {'Values': ['foo'], 'Name': 'another-filter'},\n            ],\n        )\n\n    @mock.patch('boto3.resources.collection.ResourceHandler')\n    def test_page_size_param(self, handler):\n        self.client.can_paginate.return_value = True\n        self.client.get_paginator.return_value.paginate.return_value = []\n        handler.return_value.return_value = []\n        collection = self.get_collection()\n\n        list(collection.all().page_size(1))\n\n        paginator = self.client.get_paginator.return_value\n        paginator.paginate.assert_called_with(\n            PaginationConfig={'PageSize': 1, 'MaxItems': None}\n        )\n\n    @mock.patch('boto3.resources.collection.ResourceHandler')\n    def test_page_size_method(self, handler):\n        self.client.can_paginate.return_value = True\n        self.client.get_paginator.return_value.paginate.return_value = []\n        handler.return_value.return_value = []\n        collection = self.get_collection()\n\n        list(collection.page_size(1))\n\n        paginator = self.client.get_paginator.return_value\n        paginator.paginate.assert_called_with(\n            PaginationConfig={'PageSize': 1, 'MaxItems': None}\n        )\n\n    def test_chaining(self):\n        self.collection_def = {\n            'request': {'operation': 'GetFrobs'},\n            'resource': {\n                'type': 'Frob',\n                'identifiers': [\n                    {\n                        'target': 'Id',\n                        'source': 'response',\n                        'path': 'Frobs[].Id',\n                    }\n                ],\n            },\n        }\n        self.client.get_frobs.return_value = {\n            'Frobs': [\n                {'Id': 'one'},\n                {'Id': 'two'},\n                {'Id': 'three'},\n                {'Id': 'four'},\n            ]\n        }\n        collection = self.get_collection()\n\n        items = list(collection.filter().all().all())\n\n        assert len(items) == 4\n        assert items[0].id == 'one'\n        assert items[1].id == 'two'\n        assert items[2].id == 'three'\n        assert items[3].id == 'four'\n\n    @mock.patch('boto3.resources.collection.ResourceHandler')\n    def test_chaining_copies_parameters(self, handler):\n        self.client.can_paginate.return_value = True\n        self.client.get_paginator.return_value.paginate.return_value = []\n        handler.return_value.return_value = []\n        collection = self.get_collection()\n\n        list(collection.all().filter(CustomArg=1).limit(3).page_size(3))\n\n        paginator = self.client.get_paginator.return_value\n        paginator.paginate.assert_called_with(\n            PaginationConfig={'PageSize': 3, 'MaxItems': 3}, CustomArg=1\n        )\n\n    @mock.patch('boto3.resources.collection.ResourceHandler')\n    def test_chaining_filters_does_not_clobber_list_values(self, handler):\n        self.collection_def = {\n            'request': {\n                'operation': 'GetFrobs',\n                \"params\": [\n                    {\n                        \"target\": \"Filters[0].Name\",\n                        \"source\": \"string\",\n                        \"value\": \"frob-id\",\n                    },\n                    {\n                        \"target\": \"Filters[0].Values[0]\",\n                        \"source\": \"identifier\",\n                        \"name\": \"Id\",\n                    },\n                ],\n            },\n            'resource': {\n                'type': 'Frob',\n                'identifiers': [\n                    {\n                        'target': 'Id',\n                        'source': 'response',\n                        'path': 'Frobs[].Id',\n                    }\n                ],\n            },\n        }\n        self.client.can_paginate.return_value = True\n        self.client.get_paginator.return_value.paginate.return_value = []\n        handler.return_value.return_value = []\n        collection = self.get_collection()\n\n        self.parent.id = 'my-id'\n        collection = collection.filter(\n            Filters=[{'Name': 'second-filter', 'Values': ['foo']}]\n        )\n        list(\n            collection.filter(\n                Filters=[{'Name': 'third-filter', 'Values': ['bar']}]\n            )\n        )\n        paginator = self.client.get_paginator.return_value\n        paginator.paginate.assert_called_with(\n            PaginationConfig={'PageSize': None, 'MaxItems': None},\n            Filters=[\n                {'Values': ['my-id'], 'Name': 'frob-id'},\n                {'Values': ['foo'], 'Name': 'second-filter'},\n                {'Values': ['bar'], 'Name': 'third-filter'},\n            ],\n        )\n\n    def test_chained_repr(self):\n        collection = self.get_collection()\n\n        assert 'ResourceCollection' in repr(collection.all())\n", "tests/unit/resources/test_collection_smoke.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport botocore.session\nimport pytest\nfrom botocore import xform_name\n\nfrom boto3.resources.model import ResourceModel\nfrom boto3.session import Session\n\n# A list of names that are common names of a pagination parameter.\n# Note that this list is not comprehensive. It may have to be updated\n# in the future, but this covers a lot of the pagination parameters.\nCOMMON_PAGINATION_PARAM_NAMES = [\n    'nextToken',\n    'NextToken',\n    'marker',\n    'Marker',\n    'NextMarker',\n    'nextPageToken',\n    'NextPageToken',\n]\n\n\ndef operation_looks_paginated(operation_model):\n    \"\"\"Checks whether an operation looks like it can be paginated\n\n    :type operation_model: botocore.model.OperationModel\n    :param operation_model: The model for a particular operation\n\n    :returns: True if determines it can be paginated. False otherwise.\n    \"\"\"\n    has_input_param = _shape_has_pagination_param(operation_model.input_shape)\n    has_output_param = _shape_has_pagination_param(\n        operation_model.output_shape\n    )\n    # If there is a parameter in either the input or output that\n    # is used in pagination, mark the operation as paginateable.\n    return has_input_param and has_output_param\n\n\ndef _shape_has_pagination_param(shape):\n    if shape:\n        members = shape.members\n        # Go through the list of common names that may be a pagination\n        # parameter name\n        for param in COMMON_PAGINATION_PARAM_NAMES:\n            # Go through all of the shapes members.\n            for member in members:\n                # See if the name is the member name. If it is, mark\n                # it as a pagination parameter.\n                if param == member:\n                    return True\n    return False\n\n\ndef _collection_test_args():\n    botocore_session = botocore.session.get_session()\n    session = Session(botocore_session=botocore_session)\n    loader = botocore_session.get_component('data_loader')\n    for service_name in session.get_available_resources():\n        client = session.client(service_name, region_name='us-east-1')\n        json_resource_model = loader.load_service_model(\n            service_name, 'resources-1'\n        )\n        resource_defs = json_resource_model['resources']\n        resource_models = []\n        # Get the service resource model\n        service_resource_model = ResourceModel(\n            service_name, json_resource_model['service'], resource_defs\n        )\n        resource_models.append(service_resource_model)\n        # Generate all of the resource models for a service\n        for resource_name, resource_defintion in resource_defs.items():\n            resource_models.append(\n                ResourceModel(resource_name, resource_defintion, resource_defs)\n            )\n        for resource_model in resource_models:\n            # Iterate over all of the collections for each resource model\n            # and ensure that the collection has a paginator if it needs one.\n            for collection_model in resource_model.collections:\n                yield (client, service_name, resource_name, collection_model)\n\n\n@pytest.mark.parametrize('collection_args', _collection_test_args())\ndef test_all_collections_have_paginators_if_needed(collection_args):\n    # If a collection relies on an operation that is paginated, it\n    # will require a paginator to iterate through all of the resources\n    # with the all() method. If there is no paginator, it will only\n    # make it through the first page of results. So we need to make sure\n    # if a collection looks like it uses a paginated operation then there\n    # should be a paginator applied to it.\n    _assert_collection_has_paginator_if_needed(*collection_args)\n\n\ndef _assert_collection_has_paginator_if_needed(\n    client, service_name, resource_name, collection_model\n):\n    underlying_operation_name = collection_model.request.operation\n    # See if the operation can be paginated from the client.\n    can_paginate_operation = client.can_paginate(\n        xform_name(underlying_operation_name)\n    )\n    # See if the operation looks paginated.\n    looks_paginated = operation_looks_paginated(\n        client.meta.service_model.operation_model(underlying_operation_name)\n    )\n    # Make sure that if the operation looks paginated then there is\n    # a paginator for the client to use for the collection.\n    if not can_paginate_operation:\n        error_msg = (\n            f'Collection {collection_model.name} on resource {resource_name} '\n            f'of service {service_name} uses the operation '\n            f'{underlying_operation_name}, but the operation has no paginator '\n            f'even though it looks paginated.'\n        )\n\n        assert not looks_paginated, error_msg\n", "tests/unit/resources/test_action.py": "# Copyright 2014 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the 'License'). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the 'license' file accompanying this file. This file is\n# distributed on an 'AS IS' BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport pytest\n\nfrom boto3.resources.action import BatchAction, ServiceAction, WaiterAction\nfrom boto3.resources.base import ResourceMeta\nfrom boto3.resources.model import Action, Waiter\nfrom boto3.utils import ServiceContext\nfrom tests import BaseTestCase, mock\n\n\nclass TestServiceActionCall(BaseTestCase):\n    def setUp(self):\n        super().setUp()\n\n        self.action_def = {'request': {'operation': 'GetFrobs', 'params': []}}\n\n    @property\n    def action(self):\n        return Action('test', self.action_def, {})\n\n    @mock.patch(\n        'boto3.resources.action.create_request_parameters', return_value={}\n    )\n    def test_service_action_creates_params(self, params_mock):\n        resource = mock.Mock()\n        resource.meta = ResourceMeta('test', client=mock.Mock())\n\n        action = ServiceAction(self.action)\n\n        action(resource, foo=1)\n\n        assert params_mock.called\n\n    @mock.patch(\n        'boto3.resources.action.create_request_parameters',\n        return_value={'bar': 'baz'},\n    )\n    def test_service_action_calls_operation(self, params_mock):\n        resource = mock.Mock()\n        resource.meta = ResourceMeta('test', client=mock.Mock())\n        operation = resource.meta.client.get_frobs\n        operation.return_value = 'response'\n\n        action = ServiceAction(self.action)\n\n        response = action(resource, foo=1)\n\n        operation.assert_called_with(foo=1, bar='baz')\n        assert response == 'response'\n\n    @mock.patch(\n        'boto3.resources.action.create_request_parameters', return_value={}\n    )\n    @mock.patch('boto3.resources.action.RawHandler')\n    def test_service_action_calls_raw_handler(self, handler_mock, params_mock):\n        resource = mock.Mock()\n        resource.meta = ResourceMeta('test', client=mock.Mock())\n        operation = resource.meta.client.get_frobs\n        operation.return_value = 'response'\n\n        action = ServiceAction(self.action)\n\n        handler_mock.return_value.return_value = 'response'\n\n        action(resource)\n\n        handler_mock.assert_called_with(None)\n        handler_mock.return_value.assert_called_with(resource, {}, 'response')\n\n    @mock.patch(\n        'boto3.resources.action.create_request_parameters', return_value={}\n    )\n    @mock.patch('boto3.resources.action.ResourceHandler')\n    def test_service_action_calls_resource_handler(\n        self, handler_mock, params_mock\n    ):\n        self.action_def['resource'] = {'type': 'Frob', 'path': 'Container'}\n\n        resource = mock.Mock()\n        resource.meta = ResourceMeta('test', client=mock.Mock())\n        operation = resource.meta.client.get_frobs\n        operation.return_value = 'response'\n\n        factory = mock.Mock()\n        resource_defs = {}\n        service_model = mock.Mock()\n\n        action_model = self.action\n\n        service_context = ServiceContext(\n            service_name='test',\n            service_model=service_model,\n            resource_json_definitions=resource_defs,\n            service_waiter_model=None,\n        )\n\n        action = ServiceAction(\n            action_model=action_model,\n            factory=factory,\n            service_context=service_context,\n        )\n\n        handler_mock.return_value.return_value = 'response'\n\n        action(resource)\n\n        handler_mock.assert_called_with(\n            search_path='Container',\n            factory=factory,\n            resource_model=action_model.resource,\n            service_context=service_context,\n            operation_name='GetFrobs',\n        )\n\n    def test_service_action_call_positional_argument(self):\n        def _api_call(*args, **kwargs):\n            if args:\n                raise TypeError(\"get_frobs() only accepts keyword arguments.\")\n\n        resource = mock.Mock()\n        resource.meta = ResourceMeta('test', client=mock.Mock())\n        resource.meta.client.get_frobs = _api_call\n\n        action = ServiceAction(self.action)\n\n        with pytest.raises(TypeError):\n            action(resource, 'item1')\n\n\nclass TestWaiterActionCall(BaseTestCase):\n    def setUp(self):\n        super().setUp()\n        self.waiter_resource_name = 'wait_until_exists'\n        self.waiter_def = {\n            \"waiterName\": \"FrobExists\",\n            \"params\": [\n                {\n                    \"target\": \"Frob\",\n                    \"sourceType\": \"identifier\",\n                    \"source\": \"Name\",\n                }\n            ],\n        }\n\n    @property\n    def waiter(self):\n        return Waiter('test', self.waiter_def)\n\n    @mock.patch(\n        'boto3.resources.action.create_request_parameters', return_value={}\n    )\n    def test_service_waiter_creates_params(self, params_mock):\n        resource = mock.Mock()\n        resource.meta = ResourceMeta('test', client=mock.Mock())\n\n        action = WaiterAction(self.waiter, self.waiter_resource_name)\n\n        action(resource, foo=1)\n\n        assert params_mock.called\n\n    @mock.patch(\n        'boto3.resources.action.create_request_parameters',\n        return_value={'bar': 'baz'},\n    )\n    def test_service_action_calls_operation(self, params_mock):\n        resource = mock.Mock()\n        resource.meta = ResourceMeta('test', client=mock.Mock())\n        get_waiter = resource.meta.client.get_waiter\n        mock_waiter = mock.Mock()\n        get_waiter.return_value = mock_waiter\n\n        action = WaiterAction(self.waiter, self.waiter_resource_name)\n\n        action(resource, foo=1)\n\n        get_waiter.assert_called_with('frob_exists')\n        mock_waiter.wait.assert_called_with(foo=1, bar='baz')\n\n\nclass TestBatchActionCall(BaseTestCase):\n    def setUp(self):\n        super().setUp()\n\n        self.action_def = {'request': {'operation': 'GetFrobs', 'params': []}}\n\n    @property\n    def model(self):\n        return Action('test', self.action_def, {})\n\n    def test_batch_action_gets_pages_from_collection(self):\n        collection = mock.Mock()\n        collection.pages.return_value = []\n        action = BatchAction(self.model)\n\n        action(collection)\n\n        collection.pages.assert_called_with()\n\n    def test_batch_action_creates_parameters_from_items(self):\n        self.action_def['request']['params'] = [\n            {'target': 'Bucket', 'source': 'data', 'path': 'BucketName'},\n            {\n                'target': 'Delete.Objects[].Key',\n                'source': 'data',\n                'path': 'Key',\n            },\n        ]\n\n        client = mock.Mock()\n\n        item1 = mock.Mock()\n        item1.meta = ResourceMeta(\n            'test',\n            client=client,\n            data={'BucketName': 'bucket', 'Key': 'item1'},\n        )\n\n        item2 = mock.Mock()\n        item2.meta = ResourceMeta(\n            'test',\n            client=client,\n            data={'BucketName': 'bucket', 'Key': 'item2'},\n        )\n\n        collection = mock.Mock()\n        collection.pages.return_value = [[item1, item2]]\n\n        action = BatchAction(self.model)\n        action(collection)\n\n        client.get_frobs.assert_called_with(\n            Bucket='bucket',\n            Delete={'Objects': [{'Key': 'item1'}, {'Key': 'item2'}]},\n        )\n\n    @mock.patch(\n        'boto3.resources.action.create_request_parameters', return_value={}\n    )\n    def test_batch_action_skips_operation(self, crp_mock):\n        # In this test we have an item from the collection, but no\n        # parameters are set up. Because of this, we do NOT call\n        # the batch operation.\n        client = mock.Mock()\n\n        item = mock.Mock()\n        item.meta = ResourceMeta('test', client=client)\n\n        collection = mock.Mock()\n        collection.pages.return_value = [[item]]\n\n        model = self.model\n        action = BatchAction(model)\n        action(collection)\n\n        crp_mock.assert_called_with(item, model.request, params={}, index=0)\n        client.get_frobs.assert_not_called()\n\n    @mock.patch('boto3.resources.action.create_request_parameters')\n    def test_batch_action_calls_operation(self, crp_mock):\n        # In this test we have an item and parameters, so the call\n        # to the batch operation should be made.\n        def side_effect(resource, model, params=None, index=None):\n            params['foo'] = 'bar'\n\n        crp_mock.side_effect = side_effect\n\n        client = mock.Mock()\n\n        item = mock.Mock()\n        item.meta = ResourceMeta('test', client=client)\n\n        collection = mock.Mock()\n        collection.pages.return_value = [[item]]\n\n        model = self.model\n        action = BatchAction(model)\n        action(collection)\n\n        # Here the call is made with params={}, but they are edited\n        # in-place so we need to compare to the final edited value.\n        crp_mock.assert_called_with(\n            item, model.request, params={'foo': 'bar'}, index=0\n        )\n        client.get_frobs.assert_called_with(foo='bar')\n\n    @mock.patch('boto3.resources.action.create_request_parameters')\n    def test_batch_action_with_positional_argument(self, crp_mock):\n        def side_effect(resource, model, params=None, index=None):\n            params['foo'] = 'bar'\n\n        def _api_call(*args, **kwargs):\n            if args:\n                raise TypeError(\"get_frobs() only accepts keyword arguments.\")\n\n        crp_mock.side_effect = side_effect\n\n        client = mock.Mock()\n        client.get_frobs = _api_call\n\n        item = mock.Mock()\n        item.meta = ResourceMeta('test', client=client)\n\n        collection = mock.Mock()\n        collection.pages.return_value = [[item]]\n\n        model = self.model\n        action = BatchAction(model)\n\n        with pytest.raises(TypeError):\n            action(collection, 'item1')\n", "tests/unit/resources/test_response.py": "# Copyright 2014 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the 'License'). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the 'license' file accompanying this file. This file is\n# distributed on an 'AS IS' BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport pytest\n\nfrom boto3.resources.base import ResourceMeta, ServiceResource\nfrom boto3.resources.factory import ResourceFactory\nfrom boto3.resources.model import Parameter, ResponseResource\nfrom boto3.resources.response import (\n    RawHandler,\n    ResourceHandler,\n    build_empty_response,\n    build_identifiers,\n)\nfrom boto3.utils import ServiceContext\nfrom tests import BaseTestCase, mock\n\n\nclass TestBuildIdentifiers(BaseTestCase):\n    def test_build_identifier_from_res_path_scalar(self):\n        identifiers = [\n            Parameter(target='Id', source='response', path='Container.Frob.Id')\n        ]\n\n        parent = mock.Mock()\n        params = {}\n        response = {'Container': {'Frob': {'Id': 'response-path'}}}\n\n        values = build_identifiers(identifiers, parent, params, response)\n\n        # Verify identifier loaded from responsePath scalar set\n        assert values[0][1] == 'response-path'\n\n    def test_build_identifier_from_res_path_list(self):\n        identifiers = [\n            Parameter(\n                target='Id', source='response', path='Container.Frobs[].Id'\n            )\n        ]\n\n        parent = mock.Mock()\n        params = {}\n        response = {'Container': {'Frobs': [{'Id': 'response-path'}]}}\n\n        values = build_identifiers(identifiers, parent, params, response)\n\n        # Verify identifier loaded from responsePath scalar set\n        assert values[0][1] == ['response-path']\n\n    def test_build_identifier_from_parent_identifier(self):\n        identifiers = [Parameter(target='Id', source='identifier', name='Id')]\n\n        parent = mock.Mock()\n        parent.id = 'identifier'\n        params = {}\n        response = {'Container': {'Frobs': []}}\n\n        values = build_identifiers(identifiers, parent, params, response)\n\n        # Verify identifier loaded from responsePath scalar set\n        assert values[0][1] == 'identifier'\n\n    def test_build_identifier_from_parent_data_member(self):\n        identifiers = [Parameter(target='Id', source='data', path='Member')]\n\n        parent = mock.Mock()\n        parent.meta = ResourceMeta('test', data={'Member': 'data-member'})\n        params = {}\n        response = {'Container': {'Frobs': []}}\n\n        values = build_identifiers(identifiers, parent, params, response)\n\n        # Verify identifier loaded from responsePath scalar set\n        assert values[0][1] == 'data-member'\n\n    def test_build_identifier_from_req_param(self):\n        identifiers = [\n            Parameter(target='Id', source='requestParameter', path='Param')\n        ]\n\n        parent = mock.Mock()\n        params = {'Param': 'request-param'}\n        response = {'Container': {'Frobs': []}}\n\n        values = build_identifiers(identifiers, parent, params, response)\n\n        # Verify identifier loaded from responsePath scalar set\n        assert values[0][1] == 'request-param'\n\n    def test_build_identifier_from_invalid_source_type(self):\n        identifiers = [Parameter(target='Id', source='invalid')]\n\n        parent = mock.Mock()\n        params = {}\n        response = {'Container': {'Frobs': []}}\n\n        with pytest.raises(NotImplementedError):\n            build_identifiers(identifiers, parent, params, response)\n\n\nclass TestBuildEmptyResponse(BaseTestCase):\n    def setUp(self):\n        super().setUp()\n\n        self.search_path = ''\n        self.operation_name = 'GetFrobs'\n\n        self.output_shape = mock.Mock()\n\n        operation_model = mock.Mock()\n        operation_model.output_shape = self.output_shape\n\n        self.service_model = mock.Mock()\n        self.service_model.operation_model.return_value = operation_model\n\n    def get_response(self):\n        return build_empty_response(\n            self.search_path, self.operation_name, self.service_model\n        )\n\n    def test_empty_structure(self):\n        self.output_shape.type_name = 'structure'\n\n        response = self.get_response()\n\n        # Structure should default to empty dictionary\n        assert isinstance(response, dict)\n        assert response == {}\n\n    def test_empty_list(self):\n        self.output_shape.type_name = 'list'\n\n        response = self.get_response()\n\n        assert isinstance(response, list)\n        assert len(response) == 0\n\n    def test_empty_map(self):\n        self.output_shape.type_name = 'map'\n\n        response = self.get_response()\n\n        assert isinstance(response, dict)\n        assert response == {}\n\n    def test_empty_string(self):\n        self.output_shape.type_name = \"string\"\n\n        response = self.get_response()\n        assert response is None\n\n    def test_empty_integer(self):\n        self.output_shape.type_name = \"integer\"\n\n        response = self.get_response()\n        assert response is None\n\n    def test_empty_unknown_returns_none(self):\n        self.output_shape.type_name = \"invalid\"\n\n        response = self.get_response()\n        assert response is None\n\n    def test_path_structure(self):\n        self.search_path = 'Container.Frob'\n\n        frob = mock.Mock()\n        frob.type_name = 'integer'\n\n        container = mock.Mock()\n        container.type_name = 'structure'\n        container.members = {'Frob': frob}\n\n        self.output_shape.type_name = 'structure'\n        self.output_shape.members = {'Container': container}\n\n        response = self.get_response()\n        assert response is None\n\n    def test_path_list(self):\n        self.search_path = 'Container[1].Frob'\n\n        frob = mock.Mock()\n        frob.type_name = 'integer'\n\n        container = mock.Mock()\n        container.type_name = 'list'\n        container.member = frob\n\n        self.output_shape.type_name = 'structure'\n        self.output_shape.members = {'Container': container}\n\n        response = self.get_response()\n        assert response is None\n\n    def test_path_invalid(self):\n        self.search_path = 'Container.Invalid'\n\n        container = mock.Mock()\n        container.type_name = 'invalid'\n\n        self.output_shape.type_name = 'structure'\n        self.output_shape.members = {'Container': container}\n\n        with pytest.raises(NotImplementedError):\n            self.get_response()\n\n\nclass TestRawHandler(BaseTestCase):\n    def test_raw_handler_response(self):\n        parent = mock.Mock()\n        params = {}\n        response = {'Id': 'foo'}\n\n        handler = RawHandler(search_path=None)\n        parsed_response = handler(parent, params, response)\n\n        # verify response is unmodified\n        assert parsed_response == response\n\n    def test_raw_handler_response_path(self):\n        parent = mock.Mock()\n        params = {}\n        frob = {'Id': 'foo'}\n        response = {'Container': {'Frob': frob}}\n\n        handler = RawHandler(search_path='Container.Frob')\n        parsed_response = handler(parent, params, response)\n\n        assert parsed_response == frob\n\n\nclass TestResourceHandler(BaseTestCase):\n    def setUp(self):\n        super().setUp()\n        self.identifier_path = ''\n        self.factory = ResourceFactory(mock.Mock())\n        self.resource_defs = {\n            'Frob': {'shape': 'Frob', 'identifiers': [{'name': 'Id'}]}\n        }\n        self.service_model = mock.Mock()\n        shape = mock.Mock()\n        shape.members = {}\n        self.service_model.shape_for.return_value = shape\n\n        frobs = mock.Mock()\n        frobs.type_name = 'list'\n        container = mock.Mock()\n        container.type_name = 'structure'\n        container.members = {'Frobs': frobs}\n        self.output_shape = mock.Mock()\n        self.output_shape.type_name = 'structure'\n        self.output_shape.members = {'Container': container}\n        operation_model = mock.Mock()\n        operation_model.output_shape = self.output_shape\n        self.service_model.operation_model.return_value = operation_model\n\n        self.parent = mock.Mock()\n        self.parent.meta = ResourceMeta('test', client=mock.Mock())\n        self.params = {}\n\n    def get_resource(self, search_path, response):\n        request_resource_def = {\n            'type': 'Frob',\n            'identifiers': [\n                {\n                    'target': 'Id',\n                    'source': 'response',\n                    'path': self.identifier_path,\n                },\n            ],\n        }\n        resource_model = ResponseResource(\n            request_resource_def, self.resource_defs\n        )\n\n        handler = ResourceHandler(\n            search_path=search_path,\n            factory=self.factory,\n            resource_model=resource_model,\n            service_context=ServiceContext(\n                service_name='myservice',\n                resource_json_definitions=self.resource_defs,\n                service_model=self.service_model,\n                service_waiter_model=None,\n            ),\n            operation_name='GetFrobs',\n        )\n        return handler(self.parent, self.params, response)\n\n    def test_create_resource_scalar(self):\n        self.identifier_path = 'Container.Id'\n        search_path = 'Container'\n        response = {\n            'Container': {\n                'Id': 'a-frob',\n                'OtherValue': 'other',\n            }\n        }\n        resource = self.get_resource(search_path, response)\n\n        assert isinstance(resource, ServiceResource)\n\n    @mock.patch('boto3.resources.response.build_empty_response')\n    def test_missing_data_scalar_builds_empty_response(self, build_mock):\n        self.identifier_path = 'Container.Id'\n        search_path = 'Container'\n        response = {'something': 'irrelevant'}\n\n        resources = self.get_resource(search_path, response)\n\n        assert build_mock.called\n        assert resources == build_mock.return_value\n\n    def test_create_resource_list(self):\n        self.identifier_path = 'Container.Frobs[].Id'\n        search_path = 'Container.Frobs[]'\n        response = {\n            'Container': {\n                'Frobs': [\n                    {\n                        'Id': 'a-frob',\n                        'OtherValue': 'other',\n                    },\n                    {\n                        'Id': 'another-frob',\n                        'OtherValue': 'foo',\n                    },\n                ]\n            }\n        }\n\n        resources = self.get_resource(search_path, response)\n\n        assert isinstance(resources, list)\n        assert len(resources) == 2\n        assert isinstance(resources[0], ServiceResource)\n\n    def test_create_resource_list_no_search_path(self):\n        self.identifier_path = '[].Id'\n        search_path = ''\n        response = [{'Id': 'a-frob', 'OtherValue': 'other'}]\n\n        resources = self.get_resource(search_path, response)\n\n        assert isinstance(resources, list)\n        assert len(resources) == 1\n        assert isinstance(resources[0], ServiceResource)\n\n    @mock.patch('boto3.resources.response.build_empty_response')\n    def test_missing_data_list_builds_empty_response(self, build_mock):\n        self.identifier_path = 'Container.Frobs[].Id'\n        search_path = 'Container.Frobs[]'\n        response = {'something': 'irrelevant'}\n\n        resources = self.get_resource(search_path, response)\n\n        assert build_mock.called, 'build_empty_response was never called'\n        assert resources == build_mock.return_value\n", "tests/unit/resources/test_model.py": "# Copyright 2014 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the 'License'). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the 'license' file accompanying this file. This file is\n# distributed on an 'AS IS' BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n\nfrom botocore.model import DenormalizedStructureBuilder\n\nfrom boto3.resources.model import Action, Collection, ResourceModel, Waiter\nfrom tests import BaseTestCase\n\n\nclass TestModels(BaseTestCase):\n    def test_resource_name(self):\n        model = ResourceModel('test', {}, {})\n\n        assert model.name == 'test'\n\n    def test_resource_shape(self):\n        model = ResourceModel('test', {'shape': 'Frob'}, {})\n\n        assert model.shape == 'Frob'\n\n    def test_resource_identifiers(self):\n        model = ResourceModel(\n            'test',\n            {\n                'identifiers': [\n                    {'name': 'one'},\n                    {'name': 'two', 'memberName': 'three'},\n                ]\n            },\n            {},\n        )\n\n        assert model.identifiers[0].name == 'one'\n        assert model.identifiers[1].name == 'two'\n        assert model.identifiers[1].member_name == 'three'\n\n    def test_resource_action_raw(self):\n        model = ResourceModel(\n            'test',\n            {\n                'actions': {\n                    'GetFrobs': {\n                        'request': {\n                            'operation': 'GetFrobsOperation',\n                            'params': [\n                                {\n                                    'target': 'FrobId',\n                                    'source': 'identifier',\n                                    'name': 'Id',\n                                }\n                            ],\n                        },\n                        'path': 'Container.Frobs[]',\n                    }\n                }\n            },\n            {},\n        )\n\n        assert isinstance(model.actions, list)\n        assert len(model.actions) == 1\n\n        action = model.actions[0]\n        assert isinstance(action, Action)\n        assert action.request.operation == 'GetFrobsOperation'\n        assert isinstance(action.request.params, list)\n        assert len(action.request.params) == 1\n        assert action.request.params[0].target == 'FrobId'\n        assert action.request.params[0].source == 'identifier'\n        assert action.request.params[0].name == 'Id'\n        assert action.path == 'Container.Frobs[]'\n\n    def test_resource_action_response_resource(self):\n        model = ResourceModel(\n            'test',\n            {\n                'actions': {\n                    'GetFrobs': {\n                        'resource': {\n                            'type': 'Frob',\n                            'path': 'Container.Frobs[]',\n                        }\n                    }\n                }\n            },\n            {'Frob': {}},\n        )\n\n        action = model.actions[0]\n        assert action.resource.type == 'Frob'\n        assert action.resource.path == 'Container.Frobs[]'\n        assert isinstance(action.resource.model, ResourceModel)\n        assert action.resource.model.name == 'Frob'\n\n    def test_resource_load_action(self):\n        model = ResourceModel(\n            'test',\n            {'load': {'request': {'operation': 'GetFrobInfo'}, 'path': '$'}},\n            {},\n        )\n\n        assert isinstance(model.load, Action)\n        assert model.load.request.operation == 'GetFrobInfo'\n        assert model.load.path == '$'\n\n    def test_resource_batch_action(self):\n        model = ResourceModel(\n            'test',\n            {\n                'batchActions': {\n                    'Delete': {\n                        'request': {\n                            'operation': 'DeleteObjects',\n                            'params': [\n                                {\n                                    'target': 'Bucket',\n                                    'sourceType': 'identifier',\n                                    'source': 'BucketName',\n                                }\n                            ],\n                        }\n                    }\n                }\n            },\n            {},\n        )\n\n        assert isinstance(model.batch_actions, list)\n\n        action = model.batch_actions[0]\n        assert isinstance(action, Action)\n        assert action.request.operation == 'DeleteObjects'\n        assert action.request.params[0].target == 'Bucket'\n\n    def test_sub_resources(self):\n        model = ResourceModel(\n            'test',\n            {\n                'has': {\n                    'RedFrob': {\n                        'resource': {\n                            'type': 'Frob',\n                            'identifiers': [\n                                {'target': 'Id', 'source': 'input'}\n                            ],\n                        }\n                    },\n                    'GreenFrob': {\n                        'resource': {\n                            'type': 'Frob',\n                            'identifiers': [\n                                {'target': 'Id', 'source': 'input'}\n                            ],\n                        }\n                    },\n                }\n            },\n            {'Frob': {}},\n        )\n\n        assert isinstance(model.subresources, list)\n        assert len(model.subresources) == 2\n\n        action = model.subresources[0]\n        resource = action.resource\n\n        assert action.name in ['RedFrob', 'GreenFrob']\n        assert resource.identifiers[0].target == 'Id'\n        assert resource.identifiers[0].source == 'input'\n        assert resource.type == 'Frob'\n\n    def test_resource_references(self):\n        model_def = {\n            'has': {\n                'Frob': {\n                    'resource': {\n                        'type': 'Frob',\n                        'identifiers': [\n                            {\n                                'target': 'Id',\n                                'source': 'data',\n                                'path': 'FrobId',\n                            }\n                        ],\n                    }\n                }\n            }\n        }\n        resource_defs = {'Frob': {}}\n        model = ResourceModel('test', model_def, resource_defs)\n\n        assert isinstance(model.references, list)\n        assert len(model.references) == 1\n\n        ref = model.references[0]\n        assert ref.name == 'frob'\n        assert ref.resource.type == 'Frob'\n        assert ref.resource.identifiers[0].target == 'Id'\n        assert ref.resource.identifiers[0].source == 'data'\n        assert ref.resource.identifiers[0].path == 'FrobId'\n\n    def test_resource_collections(self):\n        model = ResourceModel(\n            'test',\n            {\n                'hasMany': {\n                    'Frobs': {\n                        'request': {'operation': 'GetFrobList'},\n                        'resource': {'type': 'Frob', 'path': 'FrobList[]'},\n                    }\n                }\n            },\n            {'Frob': {}},\n        )\n\n        assert isinstance(model.collections, list)\n        assert len(model.collections) == 1\n        assert isinstance(model.collections[0], Collection)\n        assert model.collections[0].request.operation == 'GetFrobList'\n        assert model.collections[0].resource.type == 'Frob'\n        assert model.collections[0].resource.model.name == 'Frob'\n        assert model.collections[0].resource.path == 'FrobList[]'\n\n    def test_waiter(self):\n        model = ResourceModel(\n            'test',\n            {\n                'waiters': {\n                    'Exists': {\n                        'waiterName': 'ObjectExists',\n                        'params': [\n                            {\n                                'target': 'Bucket',\n                                'sourceType': 'identifier',\n                                'source': 'BucketName',\n                            }\n                        ],\n                    }\n                }\n            },\n            {},\n        )\n\n        assert isinstance(model.waiters, list)\n\n        waiter = model.waiters[0]\n        assert isinstance(waiter, Waiter)\n        assert waiter.name == 'wait_until_exists'\n        assert waiter.waiter_name == 'ObjectExists'\n        assert waiter.params[0].target == 'Bucket'\n\n\nclass TestRenaming(BaseTestCase):\n    def test_multiple(self):\n        # This tests a bunch of different renames working together\n        model = ResourceModel(\n            'test',\n            {\n                'identifiers': [{'name': 'Foo'}],\n                'actions': {'Foo': {}},\n                'has': {\n                    'Foo': {\n                        'resource': {\n                            'type': 'Frob',\n                            'identifiers': [\n                                {\n                                    'target': 'Id',\n                                    'source': 'data',\n                                    'path': 'FrobId',\n                                }\n                            ],\n                        }\n                    }\n                },\n                'hasMany': {'Foo': {}},\n                'waiters': {'Foo': {}},\n            },\n            {'Frob': {}},\n        )\n\n        shape = (\n            DenormalizedStructureBuilder()\n            .with_members(\n                {\n                    'Foo': {\n                        'type': 'string',\n                    },\n                    'Bar': {'type': 'string'},\n                }\n            )\n            .build_model()\n        )\n\n        model.load_rename_map(shape)\n\n        assert model.identifiers[0].name == 'foo'\n        assert model.actions[0].name == 'foo_action'\n        assert model.references[0].name == 'foo_reference'\n        assert model.collections[0].name == 'foo_collection'\n        assert model.waiters[0].name == 'wait_until_foo'\n\n        # If an identifier and an attribute share the same name, then\n        # the attribute is essentially hidden.\n        assert 'foo_attribute' not in model.get_attributes(shape)\n\n        # Other attributes need to be there, though\n        assert 'bar' in model.get_attributes(shape)\n\n    # The rest of the tests below ensure the correct order of precedence\n    # for the various categories of attributes/properties/methods on the\n    # resource model.\n    def test_meta_beats_identifier(self):\n        model = ResourceModel('test', {'identifiers': [{'name': 'Meta'}]}, {})\n\n        model.load_rename_map()\n\n        assert model.identifiers[0].name == 'meta_identifier'\n\n    def test_load_beats_identifier(self):\n        model = ResourceModel(\n            'test',\n            {\n                'identifiers': [{'name': 'Load'}],\n                'load': {'request': {'operation': 'GetFrobs'}},\n            },\n            {},\n        )\n\n        model.load_rename_map()\n\n        assert model.load\n        assert model.identifiers[0].name == 'load_identifier'\n\n    def test_identifier_beats_action(self):\n        model = ResourceModel(\n            'test',\n            {\n                'identifiers': [{'name': 'foo'}],\n                'actions': {'Foo': {'request': {'operation': 'GetFoo'}}},\n            },\n            {},\n        )\n\n        model.load_rename_map()\n\n        assert model.identifiers[0].name == 'foo'\n        assert model.actions[0].name == 'foo_action'\n\n    def test_action_beats_reference(self):\n        model = ResourceModel(\n            'test',\n            {\n                'actions': {'Foo': {'request': {'operation': 'GetFoo'}}},\n                'has': {\n                    'Foo': {\n                        'resource': {\n                            'type': 'Frob',\n                            'identifiers': [\n                                {\n                                    'target': 'Id',\n                                    'source': 'data',\n                                    'path': 'FrobId',\n                                }\n                            ],\n                        }\n                    }\n                },\n            },\n            {'Frob': {}},\n        )\n\n        model.load_rename_map()\n\n        assert model.actions[0].name == 'foo'\n        assert model.references[0].name == 'foo_reference'\n\n    def test_reference_beats_collection(self):\n        model = ResourceModel(\n            'test',\n            {\n                'has': {\n                    'Foo': {\n                        'resource': {\n                            'type': 'Frob',\n                            'identifiers': [\n                                {\n                                    'target': 'Id',\n                                    'source': 'data',\n                                    'path': 'FrobId',\n                                }\n                            ],\n                        }\n                    }\n                },\n                'hasMany': {'Foo': {'resource': {'type': 'Frob'}}},\n            },\n            {'Frob': {}},\n        )\n\n        model.load_rename_map()\n\n        assert model.references[0].name == 'foo'\n        assert model.collections[0].name == 'foo_collection'\n\n    def test_collection_beats_waiter(self):\n        model = ResourceModel(\n            'test',\n            {\n                'hasMany': {'WaitUntilFoo': {'resource': {'type': 'Frob'}}},\n                'waiters': {'Foo': {}},\n            },\n            {'Frob': {}},\n        )\n\n        model.load_rename_map()\n\n        assert model.collections[0].name == 'wait_until_foo'\n        assert model.waiters[0].name == 'wait_until_foo_waiter'\n\n    def test_waiter_beats_attribute(self):\n        model = ResourceModel('test', {'waiters': {'Foo': {}}}, {'Frob': {}})\n\n        shape = (\n            DenormalizedStructureBuilder()\n            .with_members(\n                {\n                    'WaitUntilFoo': {\n                        'type': 'string',\n                    }\n                }\n            )\n            .build_model()\n        )\n\n        model.load_rename_map(shape)\n\n        assert model.waiters[0].name == 'wait_until_foo'\n        assert 'wait_until_foo_attribute' in model.get_attributes(shape)\n", "tests/unit/resources/test_params.py": "# Copyright 2014 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the 'License'). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the 'license' file accompanying this file. This file is\n# distributed on an 'AS IS' BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport pytest\n\nfrom boto3.exceptions import ResourceLoadException\nfrom boto3.resources.base import ResourceMeta, ServiceResource\nfrom boto3.resources.model import Request\nfrom boto3.resources.params import (\n    build_param_structure,\n    create_request_parameters,\n)\nfrom tests import BaseTestCase, mock\n\n\nclass TestServiceActionParams(BaseTestCase):\n    def test_service_action_params_identifier(self):\n        request_model = Request(\n            {\n                'operation': 'GetFrobs',\n                'params': [\n                    {\n                        'target': 'WarehouseUrl',\n                        'source': 'identifier',\n                        'name': 'Url',\n                    }\n                ],\n            }\n        )\n\n        parent = mock.Mock()\n        parent.url = 'w-url'\n\n        params = create_request_parameters(parent, request_model)\n\n        assert params['WarehouseUrl'] == 'w-url'\n\n    def test_service_action_params_data_member(self):\n        request_model = Request(\n            {\n                'operation': 'GetFrobs',\n                'params': [\n                    {\n                        'target': 'WarehouseUrl',\n                        'source': 'data',\n                        'path': 'SomeMember',\n                    }\n                ],\n            }\n        )\n\n        parent = mock.Mock()\n        parent.meta = ResourceMeta('test', data={'SomeMember': 'w-url'})\n\n        params = create_request_parameters(parent, request_model)\n\n        assert params['WarehouseUrl'] == 'w-url'\n\n    def test_service_action_params_data_member_missing(self):\n        request_model = Request(\n            {\n                'operation': 'GetFrobs',\n                'params': [\n                    {\n                        'target': 'WarehouseUrl',\n                        'source': 'data',\n                        'path': 'SomeMember',\n                    }\n                ],\n            }\n        )\n\n        parent = mock.Mock()\n\n        def load_data():\n            parent.meta.data = {'SomeMember': 'w-url'}\n\n        parent.load.side_effect = load_data\n        parent.meta = ResourceMeta('test')\n\n        params = create_request_parameters(parent, request_model)\n\n        parent.load.assert_called_with()\n        assert params['WarehouseUrl'] == 'w-url'\n\n    def test_service_action_params_data_member_missing_no_load(self):\n        request_model = Request(\n            {\n                'operation': 'GetFrobs',\n                'params': [\n                    {\n                        'target': 'WarehouseUrl',\n                        'source': 'data',\n                        'path': 'SomeMember',\n                    }\n                ],\n            }\n        )\n\n        # This mock has no ``load`` method.\n        parent = mock.Mock(spec=ServiceResource)\n        parent.meta = ResourceMeta('test', data=None)\n\n        with pytest.raises(ResourceLoadException):\n            create_request_parameters(parent, request_model)\n\n    def test_service_action_params_constants(self):\n        request_model = Request(\n            {\n                'operation': 'GetFrobs',\n                'params': [\n                    {\n                        'target': 'Param1',\n                        'source': 'string',\n                        'value': 'param1',\n                    },\n                    {'target': 'Param2', 'source': 'integer', 'value': 123},\n                    {'target': 'Param3', 'source': 'boolean', 'value': True},\n                ],\n            }\n        )\n\n        params = create_request_parameters(None, request_model)\n\n        assert params['Param1'] == 'param1'\n        assert params['Param2'] == 123\n        assert params['Param3'] is True\n\n    def test_service_action_params_input(self):\n        request_model = Request(\n            {\n                'operation': 'GetFrobs',\n                'params': [{'target': 'Param1', 'source': 'input'}],\n            }\n        )\n\n        params = create_request_parameters(None, request_model)\n        assert params == {}\n\n        params['param1'] = 'myinput'\n        params = create_request_parameters(None, request_model, params=params)\n        assert params == {'param1': 'myinput'}\n\n    def test_service_action_params_invalid(self):\n        request_model = Request(\n            {\n                'operation': 'GetFrobs',\n                'params': [{'target': 'Param1', 'source': 'invalid'}],\n            }\n        )\n\n        with pytest.raises(NotImplementedError):\n            create_request_parameters(None, request_model)\n\n    def test_service_action_params_list(self):\n        request_model = Request(\n            {\n                'operation': 'GetFrobs',\n                'params': [\n                    {\n                        'target': 'WarehouseUrls[0]',\n                        'source': 'string',\n                        'value': 'w-url',\n                    }\n                ],\n            }\n        )\n\n        params = create_request_parameters(None, request_model)\n\n        assert isinstance(params['WarehouseUrls'], list)\n        assert len(params['WarehouseUrls']) == 1\n        assert 'w-url' in params['WarehouseUrls']\n\n    def test_service_action_params_reuse(self):\n        request_model = Request(\n            {\n                'operation': 'GetFrobs',\n                'params': [\n                    {\n                        'target': 'Delete.Objects[].Key',\n                        'source': 'data',\n                        'path': 'Key',\n                    }\n                ],\n            }\n        )\n\n        item1 = mock.Mock()\n        item1.meta = ResourceMeta('test', data={'Key': 'item1'})\n\n        item2 = mock.Mock()\n        item2.meta = ResourceMeta('test', data={'Key': 'item2'})\n\n        # Here we create params and then re-use it to build up a more\n        # complex structure over multiple calls.\n        params = create_request_parameters(item1, request_model)\n        create_request_parameters(item2, request_model, params=params)\n\n        assert params == {\n            'Delete': {'Objects': [{'Key': 'item1'}, {'Key': 'item2'}]}\n        }\n\n\nclass TestStructBuilder(BaseTestCase):\n    def test_simple_value(self):\n        params = {}\n        build_param_structure(params, 'foo', 'bar')\n        assert params['foo'] == 'bar'\n\n    def test_nested_dict(self):\n        params = {}\n        build_param_structure(params, 'foo.bar.baz', 123)\n        assert params['foo']['bar']['baz'] == 123\n\n    def test_nested_list(self):\n        params = {}\n        build_param_structure(params, 'foo.bar[0]', 'test')\n        assert params['foo']['bar'][0] == 'test'\n\n    def test_strange_offset(self):\n        params = {}\n        build_param_structure(params, 'foo[2]', 'test')\n        assert params['foo'] == [{}, {}, 'test']\n\n    def test_nested_list_dict(self):\n        params = {}\n        build_param_structure(params, 'foo.bar[0].baz', 123)\n        assert params['foo']['bar'][0]['baz'] == 123\n\n    def test_modify_existing(self):\n        params = {'foo': [{'key': 'abc'}]}\n        build_param_structure(params, 'foo[0].secret', 123)\n        assert params['foo'][0]['key'] == 'abc'\n        assert params['foo'][0]['secret'] == 123\n\n    def test_append_no_index(self):\n        params = {}\n        build_param_structure(params, 'foo[]', 123)\n        assert params['foo'] == [123]\n\n        build_param_structure(params, 'foo[]', 456)\n        assert params['foo'] == [123, 456]\n\n    def test_provided_index_with_wildcard(self):\n        params = {}\n        index = 0\n        build_param_structure(params, 'foo[*].bar', 123, index)\n        build_param_structure(params, 'foo[*].baz', 456, index)\n        assert params['foo'][index] == {'bar': 123, 'baz': 456}\n\n        index = 1\n        build_param_structure(params, 'foo[*].bar', 789, index)\n        build_param_structure(params, 'foo[*].baz', 123, index)\n        assert params['foo'] == [\n            {'bar': 123, 'baz': 456},\n            {'bar': 789, 'baz': 123},\n        ]\n", "tests/unit/resources/__init__.py": "", "tests/unit/resources/test_factory.py": "# Copyright 2014 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the 'License'). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the 'license' file accompanying this file. This file is\n# distributed on an 'AS IS' BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport pytest\nfrom botocore.model import DenormalizedStructureBuilder, ServiceModel\n\nfrom boto3.exceptions import ResourceLoadException\nfrom boto3.resources.base import ServiceResource\nfrom boto3.resources.collection import CollectionManager\nfrom boto3.resources.factory import ResourceFactory\nfrom boto3.utils import ServiceContext\nfrom tests import BaseTestCase, mock\n\n\nclass BaseTestResourceFactory(BaseTestCase):\n    def setUp(self):\n        super().setUp()\n        self.emitter = mock.Mock()\n        self.factory = ResourceFactory(self.emitter)\n\n    def load(\n        self,\n        resource_name,\n        resource_json_definition=None,\n        resource_json_definitions=None,\n        service_model=None,\n    ):\n        if resource_json_definition is None:\n            resource_json_definition = {}\n        if resource_json_definitions is None:\n            resource_json_definitions = {}\n        service_context = ServiceContext(\n            service_name='test',\n            resource_json_definitions=resource_json_definitions,\n            service_model=service_model,\n            service_waiter_model=None,\n        )\n\n        return self.factory.load_from_definition(\n            resource_name=resource_name,\n            single_resource_json_definition=resource_json_definition,\n            service_context=service_context,\n        )\n\n\nclass TestResourceFactory(BaseTestResourceFactory):\n    def test_get_service_returns_resource_class(self):\n        TestResource = self.load('test')\n        assert ServiceResource in TestResource.__bases__\n\n    def test_get_resource_returns_resource_class(self):\n        QueueResource = self.load('Queue')\n        assert ServiceResource in QueueResource.__bases__\n\n    def test_factory_sets_service_name(self):\n        QueueResource = self.load('Queue')\n        assert QueueResource.meta.service_name == 'test'\n\n    def test_factory_sets_identifiers(self):\n        model = {\n            'identifiers': [\n                {'name': 'QueueUrl'},\n                {'name': 'ReceiptHandle'},\n            ],\n        }\n\n        MessageResource = self.load('Message', model)\n\n        assert 'queue_url' in MessageResource.meta.identifiers\n        assert 'receipt_handle' in MessageResource.meta.identifiers\n\n    def test_identifiers_in_repr(self):\n        model = {\n            'identifiers': [\n                {'name': 'QueueUrl'},\n                {'name': 'ReceiptHandle'},\n            ],\n        }\n        defs = {'Message': model}\n\n        resource = self.load('Message', model, defs)('url', 'handle')\n\n        # Class name\n        assert 'test.Message' in repr(resource)\n\n        # Identifier names and values\n        assert 'queue_url' in repr(resource)\n        assert \"'url'\" in repr(resource)\n        assert 'receipt_handle' in repr(resource)\n        assert \"'handle'\" in repr(resource)\n\n    def test_factory_creates_dangling_resources(self):\n        model = {\n            'has': {\n                'Queue': {\n                    'resource': {\n                        'type': 'Queue',\n                        'identifiers': [{'target': 'Url', 'source': 'input'}],\n                    }\n                },\n                'Message': {\n                    'resource': {\n                        'type': 'Message',\n                        'identifiers': [\n                            {'target': 'QueueUrl', 'source': 'input'},\n                            {'target': 'Handle', 'source': 'input'},\n                        ],\n                    }\n                },\n            }\n        }\n        defs = {'Queue': {}, 'Message': {}}\n\n        TestResource = self.load('test', model, defs)\n\n        assert hasattr(TestResource, 'Queue')\n        assert hasattr(TestResource, 'Message')\n\n    def test_factory_creates_properties(self):\n        model = {\n            'shape': 'TestShape',\n            'load': {\n                'request': {\n                    'operation': 'DescribeTest',\n                }\n            },\n        }\n        shape = (\n            DenormalizedStructureBuilder()\n            .with_members(\n                {\n                    'ETag': {\n                        'type': 'string',\n                    },\n                    'LastModified': {'type': 'string'},\n                }\n            )\n            .build_model()\n        )\n        service_model = mock.Mock()\n        service_model.shape_for.return_value = shape\n\n        TestResource = self.load('test', model, service_model=service_model)\n\n        assert hasattr(TestResource, 'e_tag')\n        assert hasattr(TestResource, 'last_modified')\n\n    def test_factory_renames_on_clobber_identifier(self):\n        model = {'identifiers': [{'name': 'Meta'}]}\n\n        # Each resource has a ``meta`` defined, so this identifier\n        # must be renamed.\n        cls = self.load('test', model)\n\n        assert hasattr(cls, 'meta_identifier')\n\n    def test_factory_fails_on_clobber_action(self):\n        model = {\n            'identifiers': [{'name': 'Test'}, {'name': 'TestAction'}],\n            'actions': {'Test': {'request': {'operation': 'GetTest'}}},\n        }\n\n        # This fails because the resource has an identifier\n        # that would be clobbered by the action name.\n        with pytest.raises(ValueError) as cm:\n            self.load('test', model)\n\n            assert 'test' in str(cm.exception)\n            assert 'action' in str(cm.exception)\n\n    def test_can_instantiate_service_resource(self):\n        TestResource = self.load('test')\n        resource = TestResource()\n\n        assert isinstance(resource, ServiceResource)\n\n    def test_non_service_resource_missing_defs(self):\n        # Only services should get dangling defs\n        defs = {\n            'Queue': {'identifiers': [{'name': 'Url'}]},\n            'Message': {\n                'identifiers': [\n                    {'name': 'QueueUrl'},\n                    {'name': 'ReceiptHandle'},\n                ]\n            },\n        }\n\n        model = defs['Queue']\n\n        queue = self.load('Queue', model, defs)('url')\n\n        assert not hasattr(queue, 'Queue')\n        assert not hasattr(queue, 'Message')\n\n    def test_subresource_requires_only_identifier(self):\n        defs = {\n            'Queue': {\n                'identifiers': [{'name': 'Url'}],\n                'has': {\n                    'Message': {\n                        'resource': {\n                            'type': 'Message',\n                            'identifiers': [\n                                {\n                                    'target': 'QueueUrl',\n                                    'source': 'identifier',\n                                    'name': 'Url',\n                                },\n                                {'target': 'ReceiptHandle', 'source': 'input'},\n                            ],\n                        }\n                    }\n                },\n            },\n            'Message': {\n                'identifiers': [\n                    {'name': 'QueueUrl'},\n                    {'name': 'ReceiptHandle'},\n                ]\n            },\n        }\n\n        model = defs['Queue']\n\n        queue = self.load('Queue', model, defs)('url')\n\n        # Let's create a message and only give it a receipt handle\n        # The required queue_url identifier should be set from the\n        # queue itself.\n        message = queue.Message('receipt')\n\n        assert message.queue_url == 'url'\n        assert message.receipt_handle == 'receipt'\n\n    def test_resource_meta_unique(self):\n        queue_cls = self.load('Queue')\n\n        queue1 = queue_cls()\n        queue2 = queue_cls()\n\n        assert queue1.meta == queue2.meta\n\n        queue1.meta.data = {'id': 'foo'}\n        queue2.meta.data = {'id': 'bar'}\n\n        assert queue_cls.meta != queue1.meta\n        assert queue1.meta != queue2.meta\n        assert queue1.meta != 'bad-value'\n\n    def test_resource_meta_repr(self):\n        queue_cls = self.load('Queue')\n        queue = queue_cls()\n        assert repr(queue.meta) == 'ResourceMeta(\\'test\\', identifiers=[])'\n\n    @mock.patch('boto3.resources.factory.ServiceAction')\n    def test_resource_calls_action(self, action_cls):\n        model = {\n            'actions': {\n                'GetMessageStatus': {\n                    'request': {'operation': 'DescribeMessageStatus'}\n                }\n            }\n        }\n\n        action = action_cls.return_value\n\n        queue = self.load('Queue', model)()\n        queue.get_message_status('arg1', arg2=2)\n\n        action.assert_called_with(queue, 'arg1', arg2=2)\n\n    @mock.patch('boto3.resources.factory.ServiceAction')\n    def test_resource_action_clears_data(self, action_cls):\n        model = {\n            'load': {'request': {'operation': 'DescribeQueue'}},\n            'actions': {\n                'GetMessageStatus': {\n                    'request': {'operation': 'DescribeMessageStatus'}\n                }\n            },\n        }\n\n        queue = self.load('Queue', model)()\n\n        # Simulate loaded data\n        queue.meta.data = {'some': 'data'}\n\n        # Perform a call\n        queue.get_message_status()\n\n        # Cached data should be cleared\n        assert queue.meta.data is None\n\n    @mock.patch('boto3.resources.factory.ServiceAction')\n    def test_resource_action_leaves_data(self, action_cls):\n        # This model has NO load method. Cached data should\n        # never be cleared since it cannot be reloaded!\n        model = {\n            'actions': {\n                'GetMessageStatus': {\n                    'request': {'operation': 'DescribeMessageStatus'}\n                }\n            }\n        }\n\n        queue = self.load('Queue', model)()\n\n        # Simulate loaded data\n        queue.meta.data = {'some': 'data'}\n\n        # Perform a call\n        queue.get_message_status()\n\n        # Cached data should not be cleared\n        assert queue.meta.data == {'some': 'data'}\n\n    @mock.patch('boto3.resources.factory.ServiceAction')\n    def test_resource_lazy_loads_properties(self, action_cls):\n        model = {\n            'shape': 'TestShape',\n            'identifiers': [{'name': 'Url'}],\n            'load': {\n                'request': {\n                    'operation': 'DescribeTest',\n                }\n            },\n        }\n        shape = (\n            DenormalizedStructureBuilder()\n            .with_members(\n                {\n                    'ETag': {'type': 'string', 'shape_name': 'ETag'},\n                    'LastModified': {\n                        'type': 'string',\n                        'shape_name': 'LastModified',\n                    },\n                    'Url': {'type': 'string', 'shape_name': 'Url'},\n                }\n            )\n            .build_model()\n        )\n        service_model = mock.Mock()\n        service_model.shape_for.return_value = shape\n\n        action = action_cls.return_value\n        action.return_value = {'ETag': 'tag', 'LastModified': 'never'}\n\n        resource = self.load('test', model, service_model=service_model)('url')\n\n        # Accessing an identifier should not call load, even if it's in\n        # the shape members.\n        resource.url\n        action.assert_not_called()\n\n        # Accessing a property should call load\n        assert resource.e_tag == 'tag'\n        assert action.call_count == 1\n\n        # Both params should have been loaded into the data bag\n        assert 'ETag' in resource.meta.data\n        assert 'LastModified' in resource.meta.data\n\n        # Accessing another property should use cached value\n        # instead of making a second call.\n        assert resource.last_modified == 'never'\n        assert action.call_count == 1\n\n    @mock.patch('boto3.resources.factory.ServiceAction')\n    def test_resource_lazy_properties_missing_load(self, action_cls):\n        model = {\n            'shape': 'TestShape',\n            'identifiers': [{'name': 'Url'}],\n            # Note the lack of a `load` method. These resources\n            # are usually loaded via a call on a parent resource.\n        }\n        shape = (\n            DenormalizedStructureBuilder()\n            .with_members(\n                {\n                    'ETag': {\n                        'type': 'string',\n                    },\n                    'LastModified': {'type': 'string'},\n                    'Url': {'type': 'string'},\n                }\n            )\n            .build_model()\n        )\n        service_model = mock.Mock()\n        service_model.shape_for.return_value = shape\n\n        action = action_cls.return_value\n        action.return_value = {'ETag': 'tag', 'LastModified': 'never'}\n\n        resource = self.load('test', model, service_model=service_model)('url')\n\n        with pytest.raises(ResourceLoadException):\n            resource.last_modified\n\n    @mock.patch('boto3.resources.factory.ServiceAction')\n    def test_resource_aliases_identifiers(self, action_cls):\n        model = {\n            'shape': 'TestShape',\n            'identifiers': [{'name': 'id', 'memberName': 'foo_id'}],\n        }\n        shape = (\n            DenormalizedStructureBuilder()\n            .with_members(\n                {\n                    'foo_id': {\n                        'type': 'string',\n                    },\n                    'bar': {'type': 'string'},\n                }\n            )\n            .build_model()\n        )\n        service_model = mock.Mock()\n        service_model.shape_for.return_value = shape\n\n        shape_id = 'baz'\n        resource = self.load('test', model, service_model=service_model)(\n            shape_id\n        )\n\n        try:\n            assert resource.id == shape_id\n            assert resource.foo_id == shape_id\n        except ResourceLoadException:\n            self.fail(\"Load attempted on identifier alias.\")\n\n    def test_resource_loads_references(self):\n        model = {\n            'shape': 'InstanceShape',\n            'identifiers': [{'name': 'GroupId'}],\n            'has': {\n                'Subnet': {\n                    'resource': {\n                        'type': 'Subnet',\n                        'identifiers': [\n                            {\n                                'target': 'Id',\n                                'source': 'data',\n                                'path': 'SubnetId',\n                            }\n                        ],\n                    }\n                },\n                'Vpcs': {\n                    'resource': {\n                        'type': 'Vpc',\n                        'identifiers': [\n                            {\n                                'target': 'Id',\n                                'source': 'data',\n                                'path': 'Vpcs[].Id',\n                            }\n                        ],\n                    }\n                },\n            },\n        }\n        defs = {\n            'Subnet': {'identifiers': [{'name': 'Id'}]},\n            'Vpc': {'identifiers': [{'name': 'Id'}]},\n        }\n        service_model = ServiceModel(\n            {\n                'shapes': {\n                    'InstanceShape': {\n                        'type': 'structure',\n                        'members': {'SubnetId': {'shape': 'String'}},\n                    },\n                    'String': {'type': 'string'},\n                }\n            }\n        )\n\n        resource = self.load('Instance', model, defs, service_model)(\n            'group-id'\n        )\n\n        # Load the resource with no data\n        resource.meta.data = {}\n\n        assert hasattr(resource, 'subnet')\n        assert resource.subnet is None\n        assert resource.vpcs is None\n\n        # Load the resource with data to instantiate a reference\n        resource.meta.data = {\n            'SubnetId': 'abc123',\n            'Vpcs': [{'Id': 'vpc1'}, {'Id': 'vpc2'}],\n        }\n\n        assert isinstance(resource.subnet, ServiceResource)\n        assert resource.subnet.id == 'abc123'\n\n        vpcs = resource.vpcs\n        assert isinstance(vpcs, list)\n        assert len(vpcs) == 2\n        assert vpcs[0].id == 'vpc1'\n        assert vpcs[1].id == 'vpc2'\n\n    @mock.patch('boto3.resources.model.Collection')\n    def test_resource_loads_collections(self, mock_model):\n        model = {\n            'hasMany': {\n                'Queues': {\n                    'request': {'operation': 'ListQueues'},\n                    'resource': {'type': 'Queue'},\n                }\n            }\n        }\n        defs = {'Queue': {}}\n        service_model = ServiceModel({})\n        mock_model.return_value.name = 'queues'\n\n        resource = self.load('test', model, defs, service_model)()\n\n        # Resource must expose queues collection\n        assert hasattr(resource, 'queues')\n        assert isinstance(resource.queues, CollectionManager)\n\n    def test_resource_loads_waiters(self):\n        model = {\n            \"waiters\": {\n                \"Exists\": {\n                    \"waiterName\": \"BucketExists\",\n                    \"params\": [\n                        {\n                            \"target\": \"Bucket\",\n                            \"source\": \"identifier\",\n                            \"name\": \"Name\",\n                        }\n                    ],\n                }\n            }\n        }\n\n        defs = {'Bucket': {}}\n        service_model = ServiceModel({})\n\n        resource = self.load('test', model, defs, service_model)()\n\n        assert hasattr(resource, 'wait_until_exists')\n\n    @mock.patch('boto3.resources.factory.WaiterAction')\n    def test_resource_waiter_calls_waiter_method(self, waiter_action_cls):\n        model = {\n            \"waiters\": {\n                \"Exists\": {\n                    \"waiterName\": \"BucketExists\",\n                    \"params\": [\n                        {\n                            \"target\": \"Bucket\",\n                            \"source\": \"identifier\",\n                            \"name\": \"Name\",\n                        }\n                    ],\n                }\n            }\n        }\n\n        defs = {'Bucket': {}}\n        service_model = ServiceModel({})\n\n        waiter_action = waiter_action_cls.return_value\n        resource = self.load('test', model, defs, service_model)()\n\n        resource.wait_until_exists('arg1', arg2=2)\n        waiter_action.assert_called_with(resource, 'arg1', arg2=2)\n\n\nclass TestResourceFactoryDanglingResource(BaseTestResourceFactory):\n    def setUp(self):\n        super().setUp()\n\n        self.model = {\n            'has': {\n                'Queue': {\n                    'resource': {\n                        'type': 'Queue',\n                        'identifiers': [{'target': 'Url', 'source': 'input'}],\n                    }\n                }\n            }\n        }\n\n        self.defs = {'Queue': {'identifiers': [{'name': 'Url'}]}}\n\n    def test_dangling_resources_create_resource_instance(self):\n        resource = self.load('test', self.model, self.defs)()\n        q = resource.Queue('test')\n\n        assert isinstance(q, ServiceResource)\n\n    def test_hash_resource_equal(self):\n        resource = self.load('test', self.model, self.defs)()\n        p = resource.Queue('test')\n        q = resource.Queue('test')\n\n        assert p == q\n        assert hash(p) == hash(q)\n\n    def test_hash_resource_not_equal(self):\n        resource = self.load('test', self.model, self.defs)()\n        p = resource.Queue('test1')\n        q = resource.Queue('test2')\n\n        assert p != q\n        assert hash(p) != hash(q)\n\n    def test_dangling_resource_create_with_kwarg(self):\n        resource = self.load('test', self.model, self.defs)()\n        q = resource.Queue(url='test')\n\n        assert isinstance(q, ServiceResource)\n\n    def test_dangling_resource_shares_client(self):\n        resource = self.load('test', self.model, self.defs)()\n        q = resource.Queue('test')\n\n        assert resource.meta.client == q.meta.client\n\n    def test_dangling_resource_requires_identifier(self):\n        resource = self.load('test', self.model, self.defs)()\n\n        with pytest.raises(ValueError):\n            resource.Queue()\n\n    def test_dangling_resource_raises_for_unknown_arg(self):\n        resource = self.load('test', self.model, self.defs)()\n\n        with pytest.raises(ValueError):\n            resource.Queue(url='foo', bar='baz')\n\n    def test_dangling_resource_identifier_is_immutable(self):\n        resource = self.load('test', self.model, self.defs)()\n        queue = resource.Queue('url')\n        # We should not be able to change the identifier's value\n        with pytest.raises(AttributeError):\n            queue.url = 'foo'\n\n    def test_dangling_resource_equality(self):\n        resource = self.load('test', self.model, self.defs)()\n\n        q1 = resource.Queue('url')\n        q2 = resource.Queue('url')\n\n        assert q1 == q2\n\n    def test_dangling_resource_inequality(self):\n        self.defs = {\n            'Queue': {\n                'identifiers': [{'name': 'Url'}],\n                'has': {\n                    'Message': {\n                        'resource': {\n                            'type': 'Message',\n                            'identifiers': [\n                                {\n                                    'target': 'QueueUrl',\n                                    'source': 'identifier',\n                                    'name': 'Url',\n                                },\n                                {'target': 'Handle', 'source': 'input'},\n                            ],\n                        }\n                    }\n                },\n            },\n            'Message': {\n                'identifiers': [{'name': 'QueueUrl'}, {'name': 'Handle'}]\n            },\n        }\n\n        resource = self.load('test', self.model, self.defs)()\n\n        q1 = resource.Queue('url')\n        q2 = resource.Queue('different')\n        m = q1.Message('handle')\n\n        assert q1 != q2\n        assert q1 != m\n\n    def test_dangling_resource_loads_data(self):\n        # Given a loadable resource instance that contains a reference\n        # to another resource which has a resource data path, the\n        # referenced resource should be loaded with all of the data\n        # contained at that path. This allows loading references\n        # which would otherwise not be loadable (missing load method)\n        # and prevents extra load calls for others when we already\n        # have the data available.\n        self.defs = {\n            'Instance': {\n                'identifiers': [{'name': 'Id'}],\n                'has': {\n                    'NetworkInterface': {\n                        'resource': {\n                            'type': 'NetworkInterface',\n                            'identifiers': [\n                                {\n                                    'target': 'Id',\n                                    'source': 'data',\n                                    'path': 'NetworkInterface.Id',\n                                }\n                            ],\n                            'path': 'NetworkInterface',\n                        }\n                    }\n                },\n            },\n            'NetworkInterface': {\n                'identifiers': [{'name': 'Id'}],\n                'shape': 'NetworkInterfaceShape',\n            },\n        }\n        self.model = self.defs['Instance']\n        shape = (\n            DenormalizedStructureBuilder()\n            .with_members(\n                {\n                    'Id': {\n                        'type': 'string',\n                    },\n                    'PublicIp': {'type': 'string'},\n                }\n            )\n            .build_model()\n        )\n        service_model = mock.Mock()\n        service_model.shape_for.return_value = shape\n\n        cls = self.load('Instance', self.model, self.defs, service_model)\n        instance = cls('instance-id')\n\n        # Set some data as if we had completed a load action.\n        def set_meta_data():\n            instance.meta.data = {\n                'NetworkInterface': {\n                    'Id': 'network-interface-id',\n                    'PublicIp': '127.0.0.1',\n                }\n            }\n\n        instance.load = mock.Mock(side_effect=set_meta_data)\n\n        # Now, get the reference and make sure it has its data\n        # set as expected.\n        interface = instance.network_interface\n        assert interface.meta.data is not None\n        assert interface.public_ip == '127.0.0.1'\n\n\nclass TestServiceResourceSubresources(BaseTestResourceFactory):\n    def setUp(self):\n        super().setUp()\n\n        self.model = {\n            'has': {\n                'QueueObject': {\n                    'resource': {\n                        'type': 'Queue',\n                        'identifiers': [{'target': 'Url', 'source': 'input'}],\n                    }\n                },\n                'PriorityQueue': {\n                    'resource': {\n                        'type': 'Queue',\n                        'identifiers': [{'target': 'Url', 'source': 'input'}],\n                    }\n                },\n            }\n        }\n\n        self.defs = {\n            'Queue': {'identifiers': [{'name': 'Url'}]},\n            'Message': {\n                'identifiers': [\n                    {'name': 'QueueUrl'},\n                    {'name': 'ReceiptHandle'},\n                ]\n            },\n        }\n\n    def test_subresource_custom_name(self):\n        resource = self.load('test', self.model, self.defs)()\n\n        assert hasattr(resource, 'QueueObject')\n\n    def test_contains_all_subresources(self):\n        resource = self.load('test', self.model, self.defs)()\n\n        assert 'QueueObject' in dir(resource)\n        assert 'PriorityQueue' in dir(resource)\n        assert 'Message' in dir(resource)\n\n    def test_get_available_subresources(self):\n        resource = self.load('test', self.model, self.defs)()\n        assert hasattr(resource, 'get_available_subresources')\n        subresources = sorted(resource.get_available_subresources())\n        expected = sorted(['PriorityQueue', 'Message', 'QueueObject'])\n        assert subresources == expected\n\n    def test_subresource_missing_all_subresources(self):\n        resource = self.load('test', self.model, self.defs)()\n        message = resource.Message('url', 'handle')\n\n        assert 'QueueObject' not in dir(message)\n        assert 'PriorityQueue' not in dir(message)\n        assert 'Queue' not in dir(message)\n        assert 'Message' not in dir(message)\n\n    def test_event_emitted_when_class_created(self):\n        self.load('test', self.model, self.defs)\n        assert self.emitter.emit.called\n        call_args = self.emitter.emit.call_args\n        # Verify the correct event name emitted.\n        assert (\n            call_args[0][0] == 'creating-resource-class.test.ServiceResource'\n        )\n\n        # Verify we send out the class attributes dict.\n        actual_class_attrs = sorted(call_args[1]['class_attributes'])\n        assert actual_class_attrs == [\n            'Message',\n            'PriorityQueue',\n            'QueueObject',\n            'get_available_subresources',\n            'meta',\n        ]\n\n        base_classes = sorted(call_args[1]['base_classes'])\n        assert base_classes == [ServiceResource]\n", "tests/unit/dynamodb/test_conditions.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport copy\n\nimport pytest\n\nfrom boto3.dynamodb.conditions import (\n    And,\n    Attr,\n    AttributeExists,\n    AttributeNotExists,\n    AttributeType,\n    BeginsWith,\n    Between,\n    ConditionExpressionBuilder,\n    Contains,\n    Equals,\n    GreaterThan,\n    GreaterThanEquals,\n    In,\n    Key,\n    LessThan,\n    LessThanEquals,\n    Not,\n    NotEquals,\n    Or,\n    Size,\n)\nfrom boto3.exceptions import (\n    DynamoDBNeedsConditionError,\n    DynamoDBNeedsKeyConditionError,\n    DynamoDBOperationNotSupportedError,\n)\nfrom tests import unittest\n\n\nclass TestK(unittest.TestCase):\n    def setUp(self):\n        self.attr = Key('mykey')\n        self.attr2 = Key('myotherkey')\n        self.value = 'foo'\n        self.value2 = 'foo2'\n\n    def test_and(self):\n        with pytest.raises(DynamoDBOperationNotSupportedError, match=r'AND'):\n            self.attr & self.attr2\n\n    def test_or(self):\n        with pytest.raises(DynamoDBOperationNotSupportedError, match=r'OR'):\n            self.attr | self.attr2\n\n    def test_not(self):\n        with pytest.raises(DynamoDBOperationNotSupportedError, match=r'NOT'):\n            ~self.attr\n\n    def test_eq(self):\n        assert self.attr.eq(self.value) == Equals(self.attr, self.value)\n\n    def test_lt(self):\n        assert self.attr.lt(self.value) == LessThan(self.attr, self.value)\n\n    def test_lte(self):\n        assert self.attr.lte(self.value) == LessThanEquals(\n            self.attr, self.value\n        )\n\n    def test_gt(self):\n        assert self.attr.gt(self.value) == GreaterThan(self.attr, self.value)\n\n    def test_gte(self):\n        assert self.attr.gte(self.value) == GreaterThanEquals(\n            self.attr, self.value\n        )\n\n    def test_begins_with(self):\n        assert self.attr.begins_with(self.value) == BeginsWith(\n            self.attr, self.value\n        )\n\n    def test_between(self):\n        assert self.attr.between(self.value, self.value2) == Between(\n            self.attr, self.value, self.value2\n        )\n\n    def test_attribute_equality(self):\n        attr_copy = copy.deepcopy(self.attr)\n        assert self.attr is not attr_copy\n        assert self.attr == attr_copy\n\n    def test_eq_equality(self):\n        attr_copy = copy.deepcopy(self.attr)\n        comp = self.attr.eq(self.value)\n        comp2 = attr_copy.eq(self.value)\n        assert comp == comp2\n\n    def test_eq_inequality(self):\n        attr_copy = copy.deepcopy(self.attr)\n        assert self.attr.eq(self.value) != attr_copy.eq(self.value2)\n\n    def test_lt_equality(self):\n        attr_copy = copy.deepcopy(self.attr)\n        comp = self.attr.lt(self.value)\n        comp2 = attr_copy.lt(self.value)\n        assert comp == comp2\n\n    def test_lte_equality(self):\n        attr_copy = copy.deepcopy(self.attr)\n        comp = self.attr.lte(self.value)\n        comp2 = attr_copy.lte(self.value)\n        assert comp == comp2\n\n    def test_gt_equality(self):\n        attr_copy = copy.deepcopy(self.attr)\n        comp = self.attr.gt(self.value)\n        comp2 = attr_copy.gt(self.value)\n        assert comp == comp2\n\n    def test_gte_equality(self):\n        attr_copy = copy.deepcopy(self.attr)\n        comp = self.attr.gte(self.value)\n        comp2 = attr_copy.gte(self.value)\n        assert comp == comp2\n\n    def test_begins_with_equality(self):\n        attr_copy = copy.deepcopy(self.attr)\n        comp = self.attr.begins_with(self.value)\n        comp2 = attr_copy.begins_with(self.value)\n        assert comp == comp2\n\n    def test_between_equality(self):\n        attr_copy = copy.deepcopy(self.attr)\n        comp = self.attr.between(self.value, self.value2)\n        comp2 = attr_copy.between(self.value, self.value2)\n        assert comp == comp2\n\n\nclass TestA(TestK):\n    def setUp(self):\n        self.attr = Attr('mykey')\n        self.attr2 = Attr('myotherkey')\n        self.value = 'foo'\n        self.value2 = 'foo2'\n\n    def test_ne(self):\n        assert self.attr.ne(self.value) == NotEquals(self.attr, self.value)\n\n    def test_is_in(self):\n        assert self.attr.is_in([self.value]) == In(self.attr, [self.value])\n\n    def test_exists(self):\n        assert self.attr.exists() == AttributeExists(self.attr)\n\n    def test_not_exists(self):\n        assert self.attr.not_exists() == AttributeNotExists(self.attr)\n\n    def test_contains(self):\n        assert self.attr.contains(self.value) == Contains(\n            self.attr, self.value\n        )\n\n    def test_size(self):\n        assert self.attr.size() == Size(self.attr)\n\n    def test_attribute_type(self):\n        assert self.attr.attribute_type(self.value) == AttributeType(\n            self.attr, self.value\n        )\n\n    def test_ne_equality(self):\n        attr_copy = copy.deepcopy(self.attr)\n        comp = self.attr.ne(self.value)\n        comp2 = attr_copy.ne(self.value)\n        assert comp == comp2\n\n    def test_is_in_equality(self):\n        attr_copy = copy.deepcopy(self.attr)\n        comp = self.attr.is_in([self.value])\n        comp2 = attr_copy.is_in([self.value])\n        assert comp == comp2\n\n    def test_exists_equality(self):\n        attr_copy = copy.deepcopy(self.attr)\n        comp = self.attr.exists()\n        comp2 = attr_copy.exists()\n        assert comp == comp2\n\n    def test_not_exists_equality(self):\n        attr_copy = copy.deepcopy(self.attr)\n        comp = self.attr.not_exists()\n        comp2 = attr_copy.not_exists()\n        assert comp == comp2\n\n    def test_contains_equality(self):\n        attr_copy = copy.deepcopy(self.attr)\n        comp = self.attr.contains(self.value)\n        comp2 = attr_copy.contains(self.value)\n        assert comp == comp2\n\n    def test_size_equality(self):\n        attr_copy = copy.deepcopy(self.attr)\n        comp = self.attr.size()\n        comp2 = attr_copy.size()\n        assert comp == comp2\n\n    def test_attribute_type_equality(self):\n        attr_copy = copy.deepcopy(self.attr)\n        comp = self.attr.attribute_type(self.value)\n        comp2 = attr_copy.attribute_type(self.value)\n        assert comp == comp2\n\n\nclass TestConditions(unittest.TestCase):\n    def setUp(self):\n        self.value = Attr('mykey')\n        self.value2 = 'foo'\n\n    def build_and_assert_expression(\n        self, condition, reference_expression_dict\n    ):\n        expression_dict = condition.get_expression()\n        assert expression_dict == reference_expression_dict\n\n    def test_equal_operator(self):\n        cond1 = Equals(self.value, self.value2)\n        cond2 = Equals(self.value, self.value2)\n        assert cond1 == cond2\n\n    def test_equal_operator_type(self):\n        cond1 = Equals(self.value, self.value2)\n        cond2 = NotEquals(self.value, self.value2)\n        assert cond1 != cond2\n\n    def test_equal_operator_value(self):\n        cond1 = Equals(self.value, self.value2)\n        cond2 = Equals(self.value, self.value)\n        assert cond1 != cond2\n\n    def test_not_equal_operator(self):\n        cond1 = Equals(self.value, self.value2)\n        cond2 = NotEquals(self.value, self.value)\n        assert cond1 != cond2\n\n    def test_and_operator(self):\n        cond1 = Equals(self.value, self.value2)\n        cond2 = Equals(self.value, self.value2)\n        assert cond1 & cond2 == And(cond1, cond2)\n\n    def test_and_operator_throws_excepetion(self):\n        cond1 = Equals(self.value, self.value2)\n        with pytest.raises(DynamoDBOperationNotSupportedError, match=r'AND'):\n            cond1 & self.value2\n\n    def test_or_operator(self):\n        cond1 = Equals(self.value, self.value2)\n        cond2 = Equals(self.value, self.value2)\n        assert cond1 | cond2 == Or(cond1, cond2)\n\n    def test_or_operator_throws_excepetion(self):\n        cond1 = Equals(self.value, self.value2)\n        with pytest.raises(DynamoDBOperationNotSupportedError, match=r'OR'):\n            cond1 | self.value2\n\n    def test_not_operator(self):\n        cond1 = Equals(self.value, self.value2)\n        assert ~cond1 == Not(cond1)\n\n    def test_eq(self):\n        self.build_and_assert_expression(\n            Equals(self.value, self.value2),\n            {\n                'format': '{0} {operator} {1}',\n                'operator': '=',\n                'values': (self.value, self.value2),\n            },\n        )\n\n    def test_ne(self):\n        self.build_and_assert_expression(\n            NotEquals(self.value, self.value2),\n            {\n                'format': '{0} {operator} {1}',\n                'operator': '<>',\n                'values': (self.value, self.value2),\n            },\n        )\n\n    def test_lt(self):\n        self.build_and_assert_expression(\n            LessThan(self.value, self.value2),\n            {\n                'format': '{0} {operator} {1}',\n                'operator': '<',\n                'values': (self.value, self.value2),\n            },\n        )\n\n    def test_lte(self):\n        self.build_and_assert_expression(\n            LessThanEquals(self.value, self.value2),\n            {\n                'format': '{0} {operator} {1}',\n                'operator': '<=',\n                'values': (self.value, self.value2),\n            },\n        )\n\n    def test_gt(self):\n        self.build_and_assert_expression(\n            GreaterThan(self.value, self.value2),\n            {\n                'format': '{0} {operator} {1}',\n                'operator': '>',\n                'values': (self.value, self.value2),\n            },\n        )\n\n    def test_gte(self):\n        self.build_and_assert_expression(\n            GreaterThanEquals(self.value, self.value2),\n            {\n                'format': '{0} {operator} {1}',\n                'operator': '>=',\n                'values': (self.value, self.value2),\n            },\n        )\n\n    def test_in(self):\n        cond = In(self.value, (self.value2))\n        self.build_and_assert_expression(\n            cond,\n            {\n                'format': '{0} {operator} {1}',\n                'operator': 'IN',\n                'values': (self.value, (self.value2)),\n            },\n        )\n        assert cond.has_grouped_values\n\n    def test_bet(self):\n        self.build_and_assert_expression(\n            Between(self.value, self.value2, 'foo2'),\n            {\n                'format': '{0} {operator} {1} AND {2}',\n                'operator': 'BETWEEN',\n                'values': (self.value, self.value2, 'foo2'),\n            },\n        )\n\n    def test_beg(self):\n        self.build_and_assert_expression(\n            BeginsWith(self.value, self.value2),\n            {\n                'format': '{operator}({0}, {1})',\n                'operator': 'begins_with',\n                'values': (self.value, self.value2),\n            },\n        )\n\n    def test_cont(self):\n        self.build_and_assert_expression(\n            Contains(self.value, self.value2),\n            {\n                'format': '{operator}({0}, {1})',\n                'operator': 'contains',\n                'values': (self.value, self.value2),\n            },\n        )\n\n    def test_ae(self):\n        self.build_and_assert_expression(\n            AttributeExists(self.value),\n            {\n                'format': '{operator}({0})',\n                'operator': 'attribute_exists',\n                'values': (self.value,),\n            },\n        )\n\n    def test_ane(self):\n        self.build_and_assert_expression(\n            AttributeNotExists(self.value),\n            {\n                'format': '{operator}({0})',\n                'operator': 'attribute_not_exists',\n                'values': (self.value,),\n            },\n        )\n\n    def test_size(self):\n        self.build_and_assert_expression(\n            Size(self.value),\n            {\n                'format': '{operator}({0})',\n                'operator': 'size',\n                'values': (self.value,),\n            },\n        )\n\n    def test_size_can_use_attr_methods(self):\n        size = Size(self.value)\n        self.build_and_assert_expression(\n            size.eq(self.value),\n            {\n                'format': '{0} {operator} {1}',\n                'operator': '=',\n                'values': (size, self.value),\n            },\n        )\n\n    def test_size_can_use_and(self):\n        size = Size(self.value)\n        ae = AttributeExists(self.value)\n        self.build_and_assert_expression(\n            size & ae,\n            {\n                'format': '({0} {operator} {1})',\n                'operator': 'AND',\n                'values': (size, ae),\n            },\n        )\n\n    def test_attribute_type(self):\n        self.build_and_assert_expression(\n            AttributeType(self.value, self.value2),\n            {\n                'format': '{operator}({0}, {1})',\n                'operator': 'attribute_type',\n                'values': (self.value, self.value2),\n            },\n        )\n\n    def test_and(self):\n        cond1 = Equals(self.value, self.value2)\n        cond2 = Equals(self.value, self.value2)\n        and_cond = And(cond1, cond2)\n        self.build_and_assert_expression(\n            and_cond,\n            {\n                'format': '({0} {operator} {1})',\n                'operator': 'AND',\n                'values': (cond1, cond2),\n            },\n        )\n\n    def test_or(self):\n        cond1 = Equals(self.value, self.value2)\n        cond2 = Equals(self.value, self.value2)\n        or_cond = Or(cond1, cond2)\n        self.build_and_assert_expression(\n            or_cond,\n            {\n                'format': '({0} {operator} {1})',\n                'operator': 'OR',\n                'values': (cond1, cond2),\n            },\n        )\n\n    def test_not(self):\n        cond = Equals(self.value, self.value2)\n        not_cond = Not(cond)\n        self.build_and_assert_expression(\n            not_cond,\n            {\n                'format': '({operator} {0})',\n                'operator': 'NOT',\n                'values': (cond,),\n            },\n        )\n\n\nclass TestConditionExpressionBuilder(unittest.TestCase):\n    def setUp(self):\n        self.builder = ConditionExpressionBuilder()\n\n    def assert_condition_expression_build(\n        self,\n        condition,\n        ref_string,\n        ref_names,\n        ref_values,\n        is_key_condition=False,\n    ):\n        exp_string, names, values = self.builder.build_expression(\n            condition, is_key_condition=is_key_condition\n        )\n        assert exp_string == ref_string\n        assert names == ref_names\n        assert values == ref_values\n\n    def test_bad_input(self):\n        a = Attr('myattr')\n        with pytest.raises(DynamoDBNeedsConditionError):\n            self.builder.build_expression(a)\n\n    def test_build_expression_eq(self):\n        a = Attr('myattr')\n        self.assert_condition_expression_build(\n            a.eq('foo'), '#n0 = :v0', {'#n0': 'myattr'}, {':v0': 'foo'}\n        )\n\n    def test_reset(self):\n        a = Attr('myattr')\n        self.assert_condition_expression_build(\n            a.eq('foo'), '#n0 = :v0', {'#n0': 'myattr'}, {':v0': 'foo'}\n        )\n\n        self.assert_condition_expression_build(\n            a.eq('foo'), '#n1 = :v1', {'#n1': 'myattr'}, {':v1': 'foo'}\n        )\n\n        self.builder.reset()\n        self.assert_condition_expression_build(\n            a.eq('foo'), '#n0 = :v0', {'#n0': 'myattr'}, {':v0': 'foo'}\n        )\n\n    def test_build_expression_lt(self):\n        a = Attr('myattr')\n        self.assert_condition_expression_build(\n            a.lt('foo'), '#n0 < :v0', {'#n0': 'myattr'}, {':v0': 'foo'}\n        )\n\n    def test_build_expression_lte(self):\n        a1 = Attr('myattr')\n        self.assert_condition_expression_build(\n            a1.lte('foo'), '#n0 <= :v0', {'#n0': 'myattr'}, {':v0': 'foo'}\n        )\n\n    def test_build_expression_gt(self):\n        a = Attr('myattr')\n        self.assert_condition_expression_build(\n            a.gt('foo'), '#n0 > :v0', {'#n0': 'myattr'}, {':v0': 'foo'}\n        )\n\n    def test_build_expression_gte(self):\n        a = Attr('myattr')\n        self.assert_condition_expression_build(\n            a.gte('foo'), '#n0 >= :v0', {'#n0': 'myattr'}, {':v0': 'foo'}\n        )\n\n    def test_build_expression_begins_with(self):\n        a = Attr('myattr')\n        self.assert_condition_expression_build(\n            a.begins_with('foo'),\n            'begins_with(#n0, :v0)',\n            {'#n0': 'myattr'},\n            {':v0': 'foo'},\n        )\n\n    def test_build_expression_between(self):\n        a = Attr('myattr')\n        self.assert_condition_expression_build(\n            a.between('foo', 'foo2'),\n            '#n0 BETWEEN :v0 AND :v1',\n            {'#n0': 'myattr'},\n            {':v0': 'foo', ':v1': 'foo2'},\n        )\n\n    def test_build_expression_ne(self):\n        a = Attr('myattr')\n        self.assert_condition_expression_build(\n            a.ne('foo'), '#n0 <> :v0', {'#n0': 'myattr'}, {':v0': 'foo'}\n        )\n\n    def test_build_expression_in(self):\n        a = Attr('myattr')\n        self.assert_condition_expression_build(\n            a.is_in([1, 2, 3]),\n            '#n0 IN (:v0, :v1, :v2)',\n            {'#n0': 'myattr'},\n            {':v0': 1, ':v1': 2, ':v2': 3},\n        )\n\n    def test_build_expression_exists(self):\n        a = Attr('myattr')\n        self.assert_condition_expression_build(\n            a.exists(), 'attribute_exists(#n0)', {'#n0': 'myattr'}, {}\n        )\n\n    def test_build_expression_not_exists(self):\n        a = Attr('myattr')\n        self.assert_condition_expression_build(\n            a.not_exists(), 'attribute_not_exists(#n0)', {'#n0': 'myattr'}, {}\n        )\n\n    def test_build_contains(self):\n        a = Attr('myattr')\n        self.assert_condition_expression_build(\n            a.contains('foo'),\n            'contains(#n0, :v0)',\n            {'#n0': 'myattr'},\n            {':v0': 'foo'},\n        )\n\n    def test_build_size(self):\n        a = Attr('myattr')\n        self.assert_condition_expression_build(\n            a.size(), 'size(#n0)', {'#n0': 'myattr'}, {}\n        )\n\n    def test_build_size_with_other_conditons(self):\n        a = Attr('myattr')\n        self.assert_condition_expression_build(\n            a.size().eq(5), 'size(#n0) = :v0', {'#n0': 'myattr'}, {':v0': 5}\n        )\n\n    def test_build_attribute_type(self):\n        a = Attr('myattr')\n        self.assert_condition_expression_build(\n            a.attribute_type('foo'),\n            'attribute_type(#n0, :v0)',\n            {'#n0': 'myattr'},\n            {':v0': 'foo'},\n        )\n\n    def test_build_and(self):\n        a = Attr('myattr')\n        a2 = Attr('myattr2')\n        self.assert_condition_expression_build(\n            a.eq('foo') & a2.eq('bar'),\n            '(#n0 = :v0 AND #n1 = :v1)',\n            {'#n0': 'myattr', '#n1': 'myattr2'},\n            {':v0': 'foo', ':v1': 'bar'},\n        )\n\n    def test_build_or(self):\n        a = Attr('myattr')\n        a2 = Attr('myattr2')\n        self.assert_condition_expression_build(\n            a.eq('foo') | a2.eq('bar'),\n            '(#n0 = :v0 OR #n1 = :v1)',\n            {'#n0': 'myattr', '#n1': 'myattr2'},\n            {':v0': 'foo', ':v1': 'bar'},\n        )\n\n    def test_build_not(self):\n        a = Attr('myattr')\n        self.assert_condition_expression_build(\n            ~a.eq('foo'), '(NOT #n0 = :v0)', {'#n0': 'myattr'}, {':v0': 'foo'}\n        )\n\n    def test_build_attribute_with_attr_value(self):\n        a = Attr('myattr')\n        value = Attr('myreference')\n        self.assert_condition_expression_build(\n            a.eq(value),\n            '#n0 = #n1',\n            {'#n0': 'myattr', '#n1': 'myreference'},\n            {},\n        )\n\n    def test_build_with_is_key_condition(self):\n        k = Key('myattr')\n        self.assert_condition_expression_build(\n            k.eq('foo'),\n            '#n0 = :v0',\n            {'#n0': 'myattr'},\n            {':v0': 'foo'},\n            is_key_condition=True,\n        )\n\n    def test_build_with_is_key_condition_throws_error(self):\n        a = Attr('myattr')\n        with pytest.raises(DynamoDBNeedsKeyConditionError):\n            self.builder.build_expression(a.eq('foo'), is_key_condition=True)\n\n    def test_build_attr_map(self):\n        a = Attr('MyMap.MyKey')\n        self.assert_condition_expression_build(\n            a.eq('foo'),\n            '#n0.#n1 = :v0',\n            {'#n0': 'MyMap', '#n1': 'MyKey'},\n            {':v0': 'foo'},\n        )\n\n    def test_build_attr_list(self):\n        a = Attr('MyList[0]')\n        self.assert_condition_expression_build(\n            a.eq('foo'), '#n0[0] = :v0', {'#n0': 'MyList'}, {':v0': 'foo'}\n        )\n\n    def test_build_nested_attr_map_list(self):\n        a = Attr('MyMap.MyList[2].MyElement')\n        self.assert_condition_expression_build(\n            a.eq('foo'),\n            '#n0.#n1[2].#n2 = :v0',\n            {'#n0': 'MyMap', '#n1': 'MyList', '#n2': 'MyElement'},\n            {':v0': 'foo'},\n        )\n\n    def test_build_double_nested_and_or(self):\n        a = Attr('myattr')\n        a2 = Attr('myattr2')\n        self.assert_condition_expression_build(\n            (a.eq('foo') & a2.eq('foo2')) | (a.eq('bar') & a2.eq('bar2')),\n            '((#n0 = :v0 AND #n1 = :v1) OR (#n2 = :v2 AND #n3 = :v3))',\n            {\n                '#n0': 'myattr',\n                '#n1': 'myattr2',\n                '#n2': 'myattr',\n                '#n3': 'myattr2',\n            },\n            {':v0': 'foo', ':v1': 'foo2', ':v2': 'bar', ':v3': 'bar2'},\n        )\n", "tests/unit/dynamodb/test_transform.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom botocore.model import OperationModel, ServiceModel\n\nfrom boto3.dynamodb.conditions import Attr, Key\nfrom boto3.dynamodb.transform import (\n    DynamoDBHighLevelResource,\n    ParameterTransformer,\n    TransformationInjector,\n    copy_dynamodb_params,\n    register_high_level_interface,\n)\nfrom boto3.resources.base import ResourceMeta, ServiceResource\nfrom tests import mock, unittest\n\n\nclass BaseTransformationTest(unittest.TestCase):\n    def setUp(self):\n        self.target_shape = 'MyShape'\n        self.original_value = 'orginal'\n        self.transformed_value = 'transformed'\n        self.transformer = ParameterTransformer()\n        self.json_model = {}\n        self.nested_json_model = {}\n        self.setup_models()\n        self.build_models()\n\n    def setup_models(self):\n        self.json_model = {\n            'operations': {\n                'SampleOperation': {\n                    'name': 'SampleOperation',\n                    'input': {'shape': 'SampleOperationInputOutput'},\n                    'output': {'shape': 'SampleOperationInputOutput'},\n                }\n            },\n            'shapes': {\n                'SampleOperationInputOutput': {\n                    'type': 'structure',\n                    'members': {},\n                },\n                'String': {'type': 'string'},\n            },\n        }\n\n    def build_models(self):\n        self.service_model = ServiceModel(self.json_model)\n        self.operation_model = OperationModel(\n            self.json_model['operations']['SampleOperation'],\n            self.service_model,\n        )\n\n    def add_input_shape(self, shape):\n        self.add_shape(shape)\n        params_shape = self.json_model['shapes']['SampleOperationInputOutput']\n        shape_name = list(shape.keys())[0]\n        params_shape['members'][shape_name] = {'shape': shape_name}\n\n    def add_shape(self, shape):\n        shape_name = list(shape.keys())[0]\n        self.json_model['shapes'][shape_name] = shape[shape_name]\n\n\nclass TestInputOutputTransformer(BaseTransformationTest):\n    def setUp(self):\n        super().setUp()\n        self.transformation = lambda params: self.transformed_value\n        self.add_shape({self.target_shape: {'type': 'string'}})\n\n    def test_transform_structure(self):\n        input_params = {\n            'Structure': {\n                'TransformMe': self.original_value,\n                'LeaveAlone': self.original_value,\n            }\n        }\n        input_shape = {\n            'Structure': {\n                'type': 'structure',\n                'members': {\n                    'TransformMe': {'shape': self.target_shape},\n                    'LeaveAlone': {'shape': 'String'},\n                },\n            }\n        }\n\n        self.add_input_shape(input_shape)\n        self.transformer.transform(\n            params=input_params,\n            model=self.operation_model.input_shape,\n            transformation=self.transformation,\n            target_shape=self.target_shape,\n        )\n        assert input_params == {\n            'Structure': {\n                'TransformMe': self.transformed_value,\n                'LeaveAlone': self.original_value,\n            }\n        }\n\n    def test_transform_map(self):\n        input_params = {\n            'TransformMe': {'foo': self.original_value},\n            'LeaveAlone': {'foo': self.original_value},\n        }\n\n        targeted_input_shape = {\n            'TransformMe': {\n                'type': 'map',\n                'key': {'shape': 'String'},\n                'value': {'shape': self.target_shape},\n            }\n        }\n\n        untargeted_input_shape = {\n            'LeaveAlone': {\n                'type': 'map',\n                'key': {'shape': 'String'},\n                'value': {'shape': 'String'},\n            }\n        }\n\n        self.add_input_shape(targeted_input_shape)\n        self.add_input_shape(untargeted_input_shape)\n\n        self.transformer.transform(\n            params=input_params,\n            model=self.operation_model.input_shape,\n            transformation=self.transformation,\n            target_shape=self.target_shape,\n        )\n        assert input_params == {\n            'TransformMe': {'foo': self.transformed_value},\n            'LeaveAlone': {'foo': self.original_value},\n        }\n\n    def test_transform_list(self):\n        input_params = {\n            'TransformMe': [self.original_value, self.original_value],\n            'LeaveAlone': [self.original_value, self.original_value],\n        }\n\n        targeted_input_shape = {\n            'TransformMe': {\n                'type': 'list',\n                'member': {'shape': self.target_shape},\n            }\n        }\n\n        untargeted_input_shape = {\n            'LeaveAlone': {'type': 'list', 'member': {'shape': 'String'}}\n        }\n\n        self.add_input_shape(targeted_input_shape)\n        self.add_input_shape(untargeted_input_shape)\n\n        self.transformer.transform(\n            params=input_params,\n            model=self.operation_model.input_shape,\n            transformation=self.transformation,\n            target_shape=self.target_shape,\n        )\n        assert input_params == {\n            'TransformMe': [self.transformed_value, self.transformed_value],\n            'LeaveAlone': [self.original_value, self.original_value],\n        }\n\n    def test_transform_nested_structure(self):\n        input_params = {\n            'WrapperStructure': {\n                'Structure': {\n                    'TransformMe': self.original_value,\n                    'LeaveAlone': self.original_value,\n                }\n            }\n        }\n\n        structure_shape = {\n            'Structure': {\n                'type': 'structure',\n                'members': {\n                    'TransformMe': {'shape': self.target_shape},\n                    'LeaveAlone': {'shape': 'String'},\n                },\n            }\n        }\n\n        input_shape = {\n            'WrapperStructure': {\n                'type': 'structure',\n                'members': {'Structure': {'shape': 'Structure'}},\n            }\n        }\n        self.add_shape(structure_shape)\n        self.add_input_shape(input_shape)\n\n        self.transformer.transform(\n            params=input_params,\n            model=self.operation_model.input_shape,\n            transformation=self.transformation,\n            target_shape=self.target_shape,\n        )\n        assert input_params == {\n            'WrapperStructure': {\n                'Structure': {\n                    'TransformMe': self.transformed_value,\n                    'LeaveAlone': self.original_value,\n                }\n            }\n        }\n\n    def test_transform_nested_map(self):\n        input_params = {\n            'TargetedWrapperMap': {'foo': {'bar': self.original_value}},\n            'UntargetedWrapperMap': {'foo': {'bar': self.original_value}},\n        }\n\n        targeted_map_shape = {\n            'TransformMeMap': {\n                'type': 'map',\n                'key': {'shape': 'String'},\n                'value': {'shape': self.target_shape},\n            }\n        }\n\n        targeted_wrapper_shape = {\n            'TargetedWrapperMap': {\n                'type': 'map',\n                'key': {'shape': 'Name'},\n                'value': {'shape': 'TransformMeMap'},\n            }\n        }\n\n        self.add_shape(targeted_map_shape)\n        self.add_input_shape(targeted_wrapper_shape)\n\n        untargeted_map_shape = {\n            'LeaveAloneMap': {\n                'type': 'map',\n                'key': {'shape': 'String'},\n                'value': {'shape': 'String'},\n            }\n        }\n\n        untargeted_wrapper_shape = {\n            'UntargetedWrapperMap': {\n                'type': 'map',\n                'key': {'shape': 'Name'},\n                'value': {'shape': 'LeaveAloneMap'},\n            }\n        }\n\n        self.add_shape(untargeted_map_shape)\n        self.add_input_shape(untargeted_wrapper_shape)\n\n        self.transformer.transform(\n            params=input_params,\n            model=self.operation_model.input_shape,\n            transformation=self.transformation,\n            target_shape=self.target_shape,\n        )\n        assert input_params == {\n            'TargetedWrapperMap': {'foo': {'bar': self.transformed_value}},\n            'UntargetedWrapperMap': {'foo': {'bar': self.original_value}},\n        }\n\n    def test_transform_nested_list(self):\n        input_params = {\n            'TargetedWrapperList': [\n                [self.original_value, self.original_value]\n            ],\n            'UntargetedWrapperList': [\n                [self.original_value, self.original_value]\n            ],\n        }\n\n        targeted_list_shape = {\n            'TransformMe': {\n                'type': 'list',\n                'member': {'shape': self.target_shape},\n            }\n        }\n\n        targeted_wrapper_shape = {\n            'TargetedWrapperList': {\n                'type': 'list',\n                'member': {'shape': 'TransformMe'},\n            }\n        }\n\n        self.add_shape(targeted_list_shape)\n        self.add_input_shape(targeted_wrapper_shape)\n\n        untargeted_list_shape = {\n            'LeaveAlone': {'type': 'list', 'member': {'shape': 'String'}}\n        }\n\n        untargeted_wrapper_shape = {\n            'UntargetedWrapperList': {\n                'type': 'list',\n                'member': {'shape': 'LeaveAlone'},\n            }\n        }\n\n        self.add_shape(untargeted_list_shape)\n        self.add_input_shape(untargeted_wrapper_shape)\n\n        self.transformer.transform(\n            params=input_params,\n            model=self.operation_model.input_shape,\n            transformation=self.transformation,\n            target_shape=self.target_shape,\n        )\n        assert input_params == {\n            'TargetedWrapperList': [\n                [self.transformed_value, self.transformed_value]\n            ],\n            'UntargetedWrapperList': [\n                [self.original_value, self.original_value]\n            ],\n        }\n\n    def test_transform_incorrect_type_for_structure(self):\n        input_params = {'Structure': 'foo'}\n\n        input_shape = {\n            'Structure': {\n                'type': 'structure',\n                'members': {\n                    'TransformMe': {'shape': self.target_shape},\n                },\n            }\n        }\n\n        self.add_input_shape(input_shape)\n\n        self.transformer.transform(\n            params=input_params,\n            model=self.operation_model.input_shape,\n            transformation=self.transformation,\n            target_shape=self.target_shape,\n        )\n        assert input_params == {'Structure': 'foo'}\n\n    def test_transform_incorrect_type_for_map(self):\n        input_params = {'Map': 'foo'}\n\n        input_shape = {\n            'Map': {\n                'type': 'map',\n                'key': {'shape': 'String'},\n                'value': {'shape': self.target_shape},\n            }\n        }\n\n        self.add_input_shape(input_shape)\n\n        self.transformer.transform(\n            params=input_params,\n            model=self.operation_model.input_shape,\n            transformation=self.transformation,\n            target_shape=self.target_shape,\n        )\n        assert input_params == {'Map': 'foo'}\n\n    def test_transform_incorrect_type_for_list(self):\n        input_params = {'List': 'foo'}\n\n        input_shape = {\n            'List': {'type': 'list', 'member': {'shape': self.target_shape}}\n        }\n\n        self.add_input_shape(input_shape)\n\n        self.transformer.transform(\n            params=input_params,\n            model=self.operation_model.input_shape,\n            transformation=self.transformation,\n            target_shape=self.target_shape,\n        )\n        assert input_params == {'List': 'foo'}\n\n\nclass BaseTransformAttributeValueTest(BaseTransformationTest):\n    def setUp(self):\n        self.target_shape = 'AttributeValue'\n        self.setup_models()\n        self.build_models()\n        self.python_value = 'mystring'\n        self.dynamodb_value = {'S': self.python_value}\n        self.injector = TransformationInjector()\n        self.add_shape({self.target_shape: {'type': 'string'}})\n\n\nclass TestTransformAttributeValueInput(BaseTransformAttributeValueTest):\n    def test_handler(self):\n        input_params = {\n            'Structure': {\n                'TransformMe': self.python_value,\n                'LeaveAlone': 'unchanged',\n            }\n        }\n        input_shape = {\n            'Structure': {\n                'type': 'structure',\n                'members': {\n                    'TransformMe': {'shape': self.target_shape},\n                    'LeaveAlone': {'shape': 'String'},\n                },\n            }\n        }\n\n        self.add_input_shape(input_shape)\n\n        self.injector.inject_attribute_value_input(\n            params=input_params, model=self.operation_model\n        )\n        assert input_params == {\n            'Structure': {\n                'TransformMe': self.dynamodb_value,\n                'LeaveAlone': 'unchanged',\n            }\n        }\n\n\nclass TestTransformAttributeValueOutput(BaseTransformAttributeValueTest):\n    def test_handler(self):\n        parsed = {\n            'Structure': {\n                'TransformMe': self.dynamodb_value,\n                'LeaveAlone': 'unchanged',\n            }\n        }\n        input_shape = {\n            'Structure': {\n                'type': 'structure',\n                'members': {\n                    'TransformMe': {'shape': self.target_shape},\n                    'LeaveAlone': {'shape': 'String'},\n                },\n            }\n        }\n\n        self.add_input_shape(input_shape)\n        self.injector.inject_attribute_value_output(\n            parsed=parsed, model=self.operation_model\n        )\n        assert parsed == {\n            'Structure': {\n                'TransformMe': self.python_value,\n                'LeaveAlone': 'unchanged',\n            }\n        }\n\n    def test_no_output(self):\n        service_model = ServiceModel(\n            {\n                'operations': {\n                    'SampleOperation': {\n                        'name': 'SampleOperation',\n                        'input': {'shape': 'SampleOperationInputOutput'},\n                    }\n                },\n                'shapes': {\n                    'SampleOperationInput': {\n                        'type': 'structure',\n                        'members': {},\n                    },\n                    'String': {'type': 'string'},\n                },\n            }\n        )\n        operation_model = service_model.operation_model('SampleOperation')\n\n        parsed = {}\n        self.injector.inject_attribute_value_output(\n            parsed=parsed, model=operation_model\n        )\n        assert parsed == {}\n\n\nclass TestTransformConditionExpression(BaseTransformationTest):\n    def setUp(self):\n        super().setUp()\n        self.add_shape({'ConditionExpression': {'type': 'string'}})\n        self.add_shape({'KeyExpression': {'type': 'string'}})\n\n        shapes = self.json_model['shapes']\n        input_members = shapes['SampleOperationInputOutput']['members']\n        input_members['KeyCondition'] = {'shape': 'KeyExpression'}\n        input_members['AttrCondition'] = {'shape': 'ConditionExpression'}\n        self.injector = TransformationInjector()\n        self.build_models()\n\n    def test_non_condition_input(self):\n        params = {'KeyCondition': 'foo', 'AttrCondition': 'bar'}\n        self.injector.inject_condition_expressions(\n            params, self.operation_model\n        )\n        assert params == {'KeyCondition': 'foo', 'AttrCondition': 'bar'}\n\n    def test_single_attr_condition_expression(self):\n        params = {'AttrCondition': Attr('foo').eq('bar')}\n        self.injector.inject_condition_expressions(\n            params, self.operation_model\n        )\n        assert params == {\n            'AttrCondition': '#n0 = :v0',\n            'ExpressionAttributeNames': {'#n0': 'foo'},\n            'ExpressionAttributeValues': {':v0': 'bar'},\n        }\n\n    def test_single_key_conditon_expression(self):\n        params = {'KeyCondition': Key('foo').eq('bar')}\n        self.injector.inject_condition_expressions(\n            params, self.operation_model\n        )\n        assert params == {\n            'KeyCondition': '#n0 = :v0',\n            'ExpressionAttributeNames': {'#n0': 'foo'},\n            'ExpressionAttributeValues': {':v0': 'bar'},\n        }\n\n    def test_key_and_attr_conditon_expression(self):\n        params = {\n            'KeyCondition': Key('foo').eq('bar'),\n            'AttrCondition': Attr('biz').eq('baz'),\n        }\n        self.injector.inject_condition_expressions(\n            params, self.operation_model\n        )\n        assert params == {\n            'KeyCondition': '#n1 = :v1',\n            'AttrCondition': '#n0 = :v0',\n            'ExpressionAttributeNames': {'#n0': 'biz', '#n1': 'foo'},\n            'ExpressionAttributeValues': {':v0': 'baz', ':v1': 'bar'},\n        }\n\n    def test_key_and_attr_conditon_expression_with_placeholders(self):\n        params = {\n            'KeyCondition': Key('foo').eq('bar'),\n            'AttrCondition': Attr('biz').eq('baz'),\n            'ExpressionAttributeNames': {'#a': 'b'},\n            'ExpressionAttributeValues': {':c': 'd'},\n        }\n        self.injector.inject_condition_expressions(\n            params, self.operation_model\n        )\n        assert params == {\n            'KeyCondition': '#n1 = :v1',\n            'AttrCondition': '#n0 = :v0',\n            'ExpressionAttributeNames': {\n                '#n0': 'biz',\n                '#n1': 'foo',\n                '#a': 'b',\n            },\n            'ExpressionAttributeValues': {\n                ':v0': 'baz',\n                ':v1': 'bar',\n                ':c': 'd',\n            },\n        }\n\n\nclass TestCopyDynamoDBParams(unittest.TestCase):\n    def test_copy_dynamodb_params(self):\n        params = {'foo': 'bar'}\n        new_params = copy_dynamodb_params(params)\n        assert params == new_params\n        assert new_params is not params\n\n\nclass TestDynamoDBHighLevelResource(unittest.TestCase):\n    def setUp(self):\n        self.events = mock.Mock()\n        self.client = mock.Mock()\n        self.client.meta.events = self.events\n        self.meta = ResourceMeta('dynamodb')\n\n    def test_instantiation(self):\n        # Instantiate the class.\n        dynamodb_class = type(\n            'dynamodb',\n            (DynamoDBHighLevelResource, ServiceResource),\n            {'meta': self.meta},\n        )\n        with mock.patch(\n            'boto3.dynamodb.transform.TransformationInjector'\n        ) as mock_injector:\n            with mock.patch(\n                'boto3.dynamodb.transform.DocumentModifiedShape.'\n                'replace_documentation_for_matching_shape'\n            ) as mock_modify_documentation_method:\n                dynamodb_class(client=self.client)\n\n        # It should have fired the following events upon instantiation.\n        event_call_args = self.events.register.call_args_list\n        assert event_call_args == [\n            mock.call(\n                'provide-client-params.dynamodb',\n                copy_dynamodb_params,\n                unique_id='dynamodb-create-params-copy',\n            ),\n            mock.call(\n                'before-parameter-build.dynamodb',\n                mock_injector.return_value.inject_condition_expressions,\n                unique_id='dynamodb-condition-expression',\n            ),\n            mock.call(\n                'before-parameter-build.dynamodb',\n                mock_injector.return_value.inject_attribute_value_input,\n                unique_id='dynamodb-attr-value-input',\n            ),\n            mock.call(\n                'after-call.dynamodb',\n                mock_injector.return_value.inject_attribute_value_output,\n                unique_id='dynamodb-attr-value-output',\n            ),\n            mock.call(\n                'docs.*.dynamodb.*.complete-section',\n                mock_modify_documentation_method,\n                unique_id='dynamodb-attr-value-docs',\n            ),\n            mock.call(\n                'docs.*.dynamodb.*.complete-section',\n                mock_modify_documentation_method,\n                unique_id='dynamodb-key-expression-docs',\n            ),\n            mock.call(\n                'docs.*.dynamodb.*.complete-section',\n                mock_modify_documentation_method,\n                unique_id='dynamodb-cond-expression-docs',\n            ),\n        ]\n\n\nclass TestRegisterHighLevelInterface(unittest.TestCase):\n    def test_register(self):\n        base_classes = [object]\n        register_high_level_interface(base_classes)\n\n        # Check that the base classes are as expected\n        assert base_classes == [DynamoDBHighLevelResource, object]\n", "tests/unit/dynamodb/__init__.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n", "tests/unit/dynamodb/test_types.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the 'License'). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the 'license' file accompanying this file. This file is\n# distributed on an 'AS IS' BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom decimal import Decimal\n\nimport pytest\n\nfrom boto3.dynamodb.types import Binary, TypeDeserializer, TypeSerializer\nfrom tests import unittest\n\n\nclass TestBinary(unittest.TestCase):\n    def test_bytes_input(self):\n        data = Binary(b'\\x01')\n        assert b'\\x01' == data\n        assert b'\\x01' == data.value\n\n    def test_non_ascii_bytes_input(self):\n        # Binary data that is out of ASCII range\n        data = Binary(b'\\x88')\n        assert b'\\x88' == data\n        assert b'\\x88' == data.value\n\n    def test_bytearray_input(self):\n        data = Binary(bytearray([1]))\n        assert b'\\x01' == data\n        assert b'\\x01' == data.value\n\n    def test_unicode_throws_error(self):\n        with pytest.raises(TypeError):\n            Binary('\\u00e9')\n\n    def test_integer_throws_error(self):\n        with pytest.raises(TypeError):\n            Binary(1)\n\n    def test_not_equal(self):\n        assert Binary(b'\\x01') != b'\\x02'\n\n    def test_str(self):\n        assert Binary(b'\\x01').__str__() == b'\\x01'\n\n    def test_bytes(self):\n        self.assertEqual(bytes(Binary(b'\\x01')), b'\\x01')\n\n    def test_repr(self):\n        assert 'Binary' in repr(Binary(b'1'))\n\n\nclass TestSerializer(unittest.TestCase):\n    def setUp(self):\n        self.serializer = TypeSerializer()\n\n    def test_serialize_unsupported_type(self):\n        with pytest.raises(TypeError, match=r'Unsupported type'):\n            self.serializer.serialize(object())\n\n    def test_serialize_null(self):\n        assert self.serializer.serialize(None) == {'NULL': True}\n\n    def test_serialize_boolean(self):\n        assert self.serializer.serialize(False) == {'BOOL': False}\n\n    def test_serialize_integer(self):\n        assert self.serializer.serialize(1) == {'N': '1'}\n\n    def test_serialize_decimal(self):\n        assert self.serializer.serialize(Decimal('1.25')) == {'N': '1.25'}\n\n    def test_serialize_float_error(self):\n        error_msg = r'Float types are not supported. Use Decimal types instead'\n        with pytest.raises(TypeError, match=error_msg):\n            self.serializer.serialize(1.25)\n\n    def test_serialize_NaN_error(self):\n        with pytest.raises(TypeError, match=r'Infinity and NaN not supported'):\n            self.serializer.serialize(Decimal('NaN'))\n\n    def test_serialize_string(self):\n        assert self.serializer.serialize('foo') == {'S': 'foo'}\n\n    def test_serialize_binary(self):\n        assert self.serializer.serialize(Binary(b'\\x01')) == {'B': b'\\x01'}\n\n    def test_serialize_bytearray(self):\n        assert self.serializer.serialize(bytearray([1])) == {'B': b'\\x01'}\n\n    def test_serialize_bytes(self):\n        assert self.serializer.serialize(b'\\x01') == {'B': b'\\x01'}\n\n    def test_serialize_number_set(self):\n        serialized_value = self.serializer.serialize({1, 2, 3})\n        assert len(serialized_value) == 1\n        assert 'NS' in serialized_value\n        self.assertCountEqual(serialized_value['NS'], ['1', '2', '3'])\n\n    def test_serialize_string_set(self):\n        serialized_value = self.serializer.serialize({'foo', 'bar'})\n        assert len(serialized_value) == 1\n        assert 'SS' in serialized_value\n        self.assertCountEqual(serialized_value['SS'], ['foo', 'bar'])\n\n    def test_serialize_binary_set(self):\n        serialized_value = self.serializer.serialize(\n            {Binary(b'\\x01'), Binary(b'\\x02')}\n        )\n        assert len(serialized_value) == 1\n        assert 'BS' in serialized_value\n        self.assertCountEqual(serialized_value['BS'], [b'\\x01', b'\\x02'])\n\n    def test_serialize_list(self):\n        serialized_value = self.serializer.serialize(['foo', 1, [1]])\n        assert len(serialized_value) == 1\n        assert 'L' in serialized_value\n        self.assertCountEqual(\n            serialized_value['L'],\n            [{'S': 'foo'}, {'N': '1'}, {'L': [{'N': '1'}]}],\n        )\n\n    def test_serialize_tuple(self):\n        serialized_value = self.serializer.serialize(('foo', 1, (1,)))\n        self.assertEqual(len(serialized_value), 1)\n        self.assertIn('L', serialized_value)\n        self.assertCountEqual(\n            serialized_value['L'],\n            [{'S': 'foo'}, {'N': '1'}, {'L': [{'N': '1'}]}],\n        )\n\n    def test_serialize_map(self):\n        serialized_value = self.serializer.serialize(\n            {'foo': 'bar', 'baz': {'biz': 1}}\n        )\n        assert serialized_value == {\n            'M': {'foo': {'S': 'bar'}, 'baz': {'M': {'biz': {'N': '1'}}}}\n        }\n\n\nclass TestDeserializer(unittest.TestCase):\n    def setUp(self):\n        self.deserializer = TypeDeserializer()\n\n    def test_deserialize_invalid_type(self):\n        with pytest.raises(TypeError, match=r'FOO is not supported'):\n            self.deserializer.deserialize({'FOO': 'bar'})\n\n    def test_deserialize_empty_structure(self):\n        with pytest.raises(TypeError, match=r'Value must be a nonempty'):\n            self.assertEqual(self.deserializer.deserialize({}), {})\n\n    def test_deserialize_null(self):\n        assert self.deserializer.deserialize({\"NULL\": True}) is None\n\n    def test_deserialize_boolean(self):\n        assert self.deserializer.deserialize({\"BOOL\": False}) is False\n\n    def test_deserialize_integer(self):\n        assert self.deserializer.deserialize({'N': '1'}) == Decimal('1')\n\n    def test_deserialize_decimal(self):\n        assert self.deserializer.deserialize({'N': '1.25'}) == Decimal('1.25')\n\n    def test_deserialize_string(self):\n        assert self.deserializer.deserialize({'S': 'foo'}) == 'foo'\n\n    def test_deserialize_binary(self):\n        assert self.deserializer.deserialize({'B': b'\\x00'}) == Binary(b'\\x00')\n\n    def test_deserialize_number_set(self):\n        assert self.deserializer.deserialize({'NS': ['1', '1.25']}) == {\n            Decimal('1'),\n            Decimal('1.25'),\n        }\n\n    def test_deserialize_string_set(self):\n        assert self.deserializer.deserialize({'SS': ['foo', 'bar']}) == {\n            'foo',\n            'bar',\n        }\n\n    def test_deserialize_binary_set(self):\n        assert self.deserializer.deserialize({'BS': [b'\\x00', b'\\x01']}) == {\n            Binary(b'\\x00'),\n            Binary(b'\\x01'),\n        }\n\n    def test_deserialize_list(self):\n        assert self.deserializer.deserialize(\n            {'L': [{'N': '1'}, {'S': 'foo'}, {'L': [{'N': '1.25'}]}]}\n        ) == [Decimal('1'), 'foo', [Decimal('1.25')]]\n\n    def test_deserialize_map(self):\n        assert self.deserializer.deserialize(\n            {\n                'M': {\n                    'foo': {'S': 'mystring'},\n                    'bar': {'M': {'baz': {'N': '1'}}},\n                }\n            }\n        ) == {'foo': 'mystring', 'bar': {'baz': Decimal('1')}}\n", "tests/unit/dynamodb/test_table.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom boto3.dynamodb.table import BatchWriter\nfrom tests import mock, unittest\n\n\nclass BaseTransformationTest(unittest.TestCase):\n    maxDiff = None\n\n    def setUp(self):\n        self.client = mock.Mock()\n        self.client.batch_write_item.return_value = {'UnprocessedItems': {}}\n        self.table_name = 'tablename'\n        self.flush_amount = 2\n        self.batch_writer = BatchWriter(\n            self.table_name, self.client, self.flush_amount\n        )\n\n    def assert_batch_write_calls_are(self, expected_batch_writes):\n        assert self.client.batch_write_item.call_count == len(\n            expected_batch_writes\n        )\n        batch_write_calls = [\n            args[1] for args in self.client.batch_write_item.call_args_list\n        ]\n        assert batch_write_calls == expected_batch_writes\n\n    def test_batch_write_does_not_immediately_write(self):\n        self.batch_writer.put_item(Item={'Hash': 'foo'})\n        assert not self.client.batch_write_item.called\n\n    def test_batch_write_flushes_at_flush_amount(self):\n        self.batch_writer.put_item(Item={'Hash': 'foo1'})\n        self.batch_writer.put_item(Item={'Hash': 'foo2'})\n        expected = {\n            'RequestItems': {\n                self.table_name: [\n                    {'PutRequest': {'Item': {'Hash': 'foo1'}}},\n                    {'PutRequest': {'Item': {'Hash': 'foo2'}}},\n                ]\n            }\n        }\n        self.assert_batch_write_calls_are([expected])\n\n    def test_multiple_flushes_reset_items_to_put(self):\n        self.batch_writer.put_item(Item={'Hash': 'foo1'})\n        self.batch_writer.put_item(Item={'Hash': 'foo2'})\n        self.batch_writer.put_item(Item={'Hash': 'foo3'})\n        self.batch_writer.put_item(Item={'Hash': 'foo4'})\n        # We should have two batch calls, one for foo1,foo2 and\n        # one for foo3,foo4.\n        first_batch = {\n            'RequestItems': {\n                self.table_name: [\n                    {'PutRequest': {'Item': {'Hash': 'foo1'}}},\n                    {'PutRequest': {'Item': {'Hash': 'foo2'}}},\n                ]\n            }\n        }\n        second_batch = {\n            'RequestItems': {\n                self.table_name: [\n                    {'PutRequest': {'Item': {'Hash': 'foo3'}}},\n                    {'PutRequest': {'Item': {'Hash': 'foo4'}}},\n                ]\n            }\n        }\n        self.assert_batch_write_calls_are([first_batch, second_batch])\n\n    def test_can_handle_puts_and_deletes(self):\n        self.batch_writer.put_item(Item={'Hash': 'foo1'})\n        self.batch_writer.delete_item(Key={'Hash': 'foo2'})\n        expected = {\n            'RequestItems': {\n                self.table_name: [\n                    {'PutRequest': {'Item': {'Hash': 'foo1'}}},\n                    {'DeleteRequest': {'Key': {'Hash': 'foo2'}}},\n                ]\n            }\n        }\n        self.assert_batch_write_calls_are([expected])\n\n    def test_multiple_batch_calls_with_mixed_deletes(self):\n        self.batch_writer.put_item(Item={'Hash': 'foo1'})\n        self.batch_writer.delete_item(Key={'Hash': 'foo2'})\n        self.batch_writer.delete_item(Key={'Hash': 'foo3'})\n        self.batch_writer.put_item(Item={'Hash': 'foo4'})\n        first_batch = {\n            'RequestItems': {\n                self.table_name: [\n                    {'PutRequest': {'Item': {'Hash': 'foo1'}}},\n                    {'DeleteRequest': {'Key': {'Hash': 'foo2'}}},\n                ]\n            }\n        }\n        second_batch = {\n            'RequestItems': {\n                self.table_name: [\n                    {'DeleteRequest': {'Key': {'Hash': 'foo3'}}},\n                    {'PutRequest': {'Item': {'Hash': 'foo4'}}},\n                ]\n            }\n        }\n        self.assert_batch_write_calls_are([first_batch, second_batch])\n\n    def test_unprocessed_items_added_to_next_batch(self):\n        self.client.batch_write_item.side_effect = [\n            {\n                'UnprocessedItems': {\n                    self.table_name: [\n                        {'PutRequest': {'Item': {'Hash': 'foo2'}}}\n                    ],\n                },\n            },\n            # Then the last response shows that everything went through\n            {'UnprocessedItems': {}},\n        ]\n        self.batch_writer.put_item(Item={'Hash': 'foo1'})\n        self.batch_writer.put_item(Item={'Hash': 'foo2'})\n        self.batch_writer.put_item(Item={'Hash': 'foo3'})\n\n        # We should have sent two batch requests consisting of 2\n        # 2 requests.  foo1,foo2 and foo2,foo3.\n        # foo2 is sent twice because the first response has it listed\n        # as an unprocessed item which means it needs to be part\n        # of the next batch.\n        first_batch = {\n            'RequestItems': {\n                self.table_name: [\n                    {'PutRequest': {'Item': {'Hash': 'foo1'}}},\n                    {'PutRequest': {'Item': {'Hash': 'foo2'}}},\n                ]\n            }\n        }\n        second_batch = {\n            'RequestItems': {\n                self.table_name: [\n                    {'PutRequest': {'Item': {'Hash': 'foo2'}}},\n                    {'PutRequest': {'Item': {'Hash': 'foo3'}}},\n                ]\n            }\n        }\n        self.assert_batch_write_calls_are([first_batch, second_batch])\n\n    def test_all_items_flushed_on_exit(self):\n        with self.batch_writer as b:\n            b.put_item(Item={'Hash': 'foo1'})\n        self.assert_batch_write_calls_are(\n            [\n                {\n                    'RequestItems': {\n                        self.table_name: [\n                            {'PutRequest': {'Item': {'Hash': 'foo1'}}},\n                        ]\n                    },\n                },\n            ]\n        )\n\n    def test_never_send_more_than_max_batch_size(self):\n        # Suppose the server sends backs a response that indicates that\n        # all the items were unprocessed.\n        self.client.batch_write_item.side_effect = [\n            {\n                'UnprocessedItems': {\n                    self.table_name: [\n                        {'PutRequest': {'Item': {'Hash': 'foo1'}}},\n                        {'PutRequest': {'Item': {'Hash': 'foo2'}}},\n                    ],\n                },\n            },\n            {\n                'UnprocessedItems': {\n                    self.table_name: [\n                        {'PutRequest': {'Item': {'Hash': 'foo2'}}},\n                    ],\n                },\n            },\n            {'UnprocessedItems': {}},\n        ]\n        with BatchWriter(self.table_name, self.client, flush_amount=2) as b:\n            b.put_item(Item={'Hash': 'foo1'})\n            b.put_item(Item={'Hash': 'foo2'})\n            b.put_item(Item={'Hash': 'foo3'})\n\n        # Note how we're never sending more than flush_amount=2.\n        first_batch = {\n            'RequestItems': {\n                self.table_name: [\n                    {'PutRequest': {'Item': {'Hash': 'foo1'}}},\n                    {'PutRequest': {'Item': {'Hash': 'foo2'}}},\n                ]\n            }\n        }\n        # Even when the server sends us unprocessed items of 2 elements,\n        # we'll still only send 2 at a time, in order.\n        second_batch = {\n            'RequestItems': {\n                self.table_name: [\n                    {'PutRequest': {'Item': {'Hash': 'foo1'}}},\n                    {'PutRequest': {'Item': {'Hash': 'foo2'}}},\n                ]\n            }\n        }\n        # And then we still see one more unprocessed item so\n        # we need to send another batch.\n        third_batch = {\n            'RequestItems': {\n                self.table_name: [\n                    {'PutRequest': {'Item': {'Hash': 'foo3'}}},\n                    {'PutRequest': {'Item': {'Hash': 'foo2'}}},\n                ]\n            }\n        }\n        self.assert_batch_write_calls_are(\n            [first_batch, second_batch, third_batch]\n        )\n\n    def test_repeated_flushing_on_exit(self):\n        # We're going to simulate unprocessed_items\n        # returning multiple unprocessed items across calls.\n        self.client.batch_write_item.side_effect = [\n            {\n                'UnprocessedItems': {\n                    self.table_name: [\n                        {'PutRequest': {'Item': {'Hash': 'foo2'}}},\n                        {'PutRequest': {'Item': {'Hash': 'foo3'}}},\n                    ],\n                },\n            },\n            {\n                'UnprocessedItems': {\n                    self.table_name: [\n                        {'PutRequest': {'Item': {'Hash': 'foo3'}}},\n                    ],\n                },\n            },\n            {'UnprocessedItems': {}},\n        ]\n        with BatchWriter(self.table_name, self.client, flush_amount=4) as b:\n            b.put_item(Item={'Hash': 'foo1'})\n            b.put_item(Item={'Hash': 'foo2'})\n            b.put_item(Item={'Hash': 'foo3'})\n        # So when we exit, we expect three calls.\n        # First we try the normal batch write with 3 items:\n        first_batch = {\n            'RequestItems': {\n                self.table_name: [\n                    {'PutRequest': {'Item': {'Hash': 'foo1'}}},\n                    {'PutRequest': {'Item': {'Hash': 'foo2'}}},\n                    {'PutRequest': {'Item': {'Hash': 'foo3'}}},\n                ]\n            }\n        }\n        # Then we see two unprocessed items so we send another batch.\n        second_batch = {\n            'RequestItems': {\n                self.table_name: [\n                    {'PutRequest': {'Item': {'Hash': 'foo2'}}},\n                    {'PutRequest': {'Item': {'Hash': 'foo3'}}},\n                ]\n            }\n        }\n        # And then we still see one more unprocessed item so\n        # we need to send another batch.\n        third_batch = {\n            'RequestItems': {\n                self.table_name: [\n                    {'PutRequest': {'Item': {'Hash': 'foo3'}}},\n                ]\n            }\n        }\n        self.assert_batch_write_calls_are(\n            [first_batch, second_batch, third_batch]\n        )\n\n    def test_auto_dedup_for_dup_requests(self):\n        with BatchWriter(\n            self.table_name,\n            self.client,\n            flush_amount=5,\n            overwrite_by_pkeys=[\"pkey\", \"skey\"],\n        ) as b:\n            # dup 1\n            b.put_item(\n                Item={'pkey': 'foo1', 'skey': 'bar1', 'other': 'other1'}\n            )\n            b.put_item(\n                Item={'pkey': 'foo1', 'skey': 'bar1', 'other': 'other2'}\n            )\n            # dup 2\n            b.delete_item(\n                Key={\n                    'pkey': 'foo1',\n                    'skey': 'bar2',\n                }\n            )\n            b.put_item(\n                Item={'pkey': 'foo1', 'skey': 'bar2', 'other': 'other3'}\n            )\n            # dup 3\n            b.put_item(\n                Item={'pkey': 'foo2', 'skey': 'bar2', 'other': 'other3'}\n            )\n            b.delete_item(\n                Key={\n                    'pkey': 'foo2',\n                    'skey': 'bar2',\n                }\n            )\n            # dup 4\n            b.delete_item(\n                Key={\n                    'pkey': 'foo2',\n                    'skey': 'bar3',\n                }\n            )\n            b.delete_item(\n                Key={\n                    'pkey': 'foo2',\n                    'skey': 'bar3',\n                }\n            )\n            # 5\n            b.delete_item(\n                Key={\n                    'pkey': 'foo3',\n                    'skey': 'bar3',\n                }\n            )\n            # 2nd batch\n            b.put_item(\n                Item={'pkey': 'foo1', 'skey': 'bar1', 'other': 'other1'}\n            )\n            b.put_item(\n                Item={'pkey': 'foo1', 'skey': 'bar1', 'other': 'other2'}\n            )\n\n        first_batch = {\n            'RequestItems': {\n                self.table_name: [\n                    {\n                        'PutRequest': {\n                            'Item': {\n                                'pkey': 'foo1',\n                                'skey': 'bar1',\n                                'other': 'other2',\n                            }\n                        }\n                    },\n                    {\n                        'PutRequest': {\n                            'Item': {\n                                'pkey': 'foo1',\n                                'skey': 'bar2',\n                                'other': 'other3',\n                            }\n                        }\n                    },\n                    {\n                        'DeleteRequest': {\n                            'Key': {\n                                'pkey': 'foo2',\n                                'skey': 'bar2',\n                            }\n                        }\n                    },\n                    {\n                        'DeleteRequest': {\n                            'Key': {\n                                'pkey': 'foo2',\n                                'skey': 'bar3',\n                            }\n                        }\n                    },\n                    {\n                        'DeleteRequest': {\n                            'Key': {\n                                'pkey': 'foo3',\n                                'skey': 'bar3',\n                            }\n                        }\n                    },\n                ]\n            }\n        }\n        second_batch = {\n            'RequestItems': {\n                self.table_name: [\n                    {\n                        'PutRequest': {\n                            'Item': {\n                                'pkey': 'foo1',\n                                'skey': 'bar1',\n                                'other': 'other2',\n                            }\n                        }\n                    },\n                ]\n            }\n        }\n        self.assert_batch_write_calls_are([first_batch, second_batch])\n\n    def test_added_unsent_request_not_flushed_put(self):\n        # If n requests that get sent fail to process where n = flush_amount\n        # and at least one more request gets created before the second attempt,\n        # then previously if n requests were successful on the next run and\n        # returned an empty dict, _item_buffer would be emptied before sending\n        # the next batch of n requests\n        self.client.batch_write_item.side_effect = [\n            {\n                'UnprocessedItems': {\n                    self.table_name: [\n                        {'PutRequest': {'Item': {'Hash': 'foo1'}}},\n                        {'PutRequest': {'Item': {'Hash': 'foo2'}}},\n                    ],\n                },\n            },\n            {\n                'UnprocessedItems': {},\n            },\n            {\n                'UnprocessedItems': {},\n            },\n        ]\n        self.batch_writer.put_item({'Hash': 'foo1'})\n        self.batch_writer.put_item({'Hash': 'foo2'})\n        self.batch_writer.put_item({'Hash': 'foo3'})\n        self.assertIn(\n            {'PutRequest': {'Item': {'Hash': 'foo3'}}},\n            self.batch_writer._items_buffer,\n        )\n        batch = {\n            'RequestItems': {\n                self.table_name: [\n                    {'PutRequest': {'Item': {'Hash': 'foo1'}}},\n                    {'PutRequest': {'Item': {'Hash': 'foo2'}}},\n                ]\n            }\n        }\n        final_batch = {\n            'RequestItems': {\n                self.table_name: [\n                    {'PutRequest': {'Item': {'Hash': 'foo3'}}},\n                    {'PutRequest': {'Item': {'Hash': 'foo4'}}},\n                ]\n            }\n        }\n        # same batch sent twice since all failed on first try\n        # and flush_items = 2\n        self.assert_batch_write_calls_are([batch, batch])\n        # test that the next two items get sent\n        self.batch_writer.put_item({'Hash': 'foo4'})\n        self.assert_batch_write_calls_are([batch, batch, final_batch])\n        # the buffer should be empty now\n        self.assertEqual(self.batch_writer._items_buffer, [])\n\n    def test_added_unsent_request_not_flushed_delete(self):\n        # If n requests that get sent fail to process where n = flush_amount\n        # and at least one more request gets created before the second attempt,\n        # then previously if n requests were successful on the next run and\n        # returned an empty dict, _item_buffer would be emptied before sending\n        # the next batch of n requests\n        self.client.batch_write_item.side_effect = [\n            {\n                'UnprocessedItems': {\n                    self.table_name: [\n                        {'DeleteRequest': {'Key': {'Hash': 'foo1'}}},\n                        {'DeleteRequest': {'Key': {'Hash': 'foo2'}}},\n                    ],\n                },\n            },\n            {\n                'UnprocessedItems': {},\n            },\n            {\n                'UnprocessedItems': {},\n            },\n        ]\n        self.batch_writer.delete_item({'Hash': 'foo1'})\n        self.batch_writer.delete_item({'Hash': 'foo2'})\n        self.batch_writer.delete_item({'Hash': 'foo3'})\n        self.assertIn(\n            {'DeleteRequest': {'Key': {'Hash': 'foo3'}}},\n            self.batch_writer._items_buffer,\n        )\n        batch = {\n            'RequestItems': {\n                self.table_name: [\n                    {'DeleteRequest': {'Key': {'Hash': 'foo1'}}},\n                    {'DeleteRequest': {'Key': {'Hash': 'foo2'}}},\n                ]\n            }\n        }\n        final_batch = {\n            'RequestItems': {\n                self.table_name: [\n                    {'DeleteRequest': {'Key': {'Hash': 'foo3'}}},\n                    {'DeleteRequest': {'Key': {'Hash': 'foo4'}}},\n                ]\n            }\n        }\n        # same batch sent twice since all failed on first try\n        # and flush_items = 2\n        self.assert_batch_write_calls_are([batch, batch])\n        # test that the next two items get sent\n        self.batch_writer.delete_item({'Hash': 'foo4'})\n        self.assert_batch_write_calls_are([batch, batch, final_batch])\n        # the buffer should be empty now\n        self.assertEqual(self.batch_writer._items_buffer, [])\n", "tests/unit/ec2/test_createtags.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the 'License'). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the 'license' file accompanying this file. This file is\n# distributed on an 'AS IS' BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport boto3.session\nfrom boto3.ec2 import createtags\nfrom tests import mock, unittest\n\n\nclass TestCreateTags(unittest.TestCase):\n    def setUp(self):\n        self.client = mock.Mock()\n        self.resource = mock.Mock()\n        self.resource.meta.client = self.client\n        self.ref_tags = ['tag1', 'tag2', 'tag3', 'tag4', 'tag5', 'tag6']\n        self.resource.Tag.side_effect = self.ref_tags\n\n    def test_create_tags(self):\n        ref_kwargs = {\n            'Resources': ['foo', 'bar'],\n            'Tags': [\n                {'Key': 'key1', 'Value': 'value1'},\n                {'Key': 'key2', 'Value': 'value2'},\n                {'Key': 'key3', 'Value': 'value3'},\n            ],\n        }\n\n        result_tags = createtags.create_tags(self.resource, **ref_kwargs)\n\n        # Ensure the client method was called properly.\n        self.client.create_tags.assert_called_with(**ref_kwargs)\n\n        # Ensure the calls to the Tag reference were correct.\n        assert self.resource.Tag.call_args_list == [\n            mock.call('foo', 'key1', 'value1'),\n            mock.call('foo', 'key2', 'value2'),\n            mock.call('foo', 'key3', 'value3'),\n            mock.call('bar', 'key1', 'value1'),\n            mock.call('bar', 'key2', 'value2'),\n            mock.call('bar', 'key3', 'value3'),\n        ]\n\n        # Ensure the return values are as expected.\n        assert result_tags == self.ref_tags\n\n\nclass TestCreateTagsInjection(unittest.TestCase):\n    def test_create_tags_injected_to_resource(self):\n        session = boto3.session.Session(region_name='us-west-2')\n        with mock.patch('boto3.ec2.createtags.create_tags') as mock_method:\n            resource = session.resource('ec2')\n            assert hasattr(resource, 'create_tags')\n            assert resource.create_tags is mock_method\n", "tests/unit/ec2/test_deletetags.py": "# Copyright 2016 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the 'License'). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the 'license' file accompanying this file. This file is\n# distributed on an 'AS IS' BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom boto3.ec2.deletetags import delete_tags\nfrom tests import mock, unittest\n\n\nclass TestDeleteTags(unittest.TestCase):\n    def setUp(self):\n        self.client = mock.Mock()\n        self.resource = mock.Mock()\n        self.resource.meta.client = self.client\n        self.instance_id = 'instance_id'\n        self.resource.id = self.instance_id\n\n    def test_delete_tags(self):\n        tags = {\n            'Tags': [\n                {'Key': 'key1', 'Value': 'value1'},\n                {'Key': 'key2', 'Value': 'value2'},\n                {'Key': 'key3', 'Value': 'value3'},\n            ]\n        }\n\n        delete_tags(self.resource, **tags)\n\n        kwargs = tags\n        kwargs['Resources'] = [self.instance_id]\n        self.client.delete_tags.assert_called_with(**kwargs)\n", "tests/unit/ec2/__init__.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the 'License'). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the 'license' file accompanying this file. This file is\n# distributed on an 'AS IS' BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n", "tests/unit/docs/test_waiter.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom boto3.docs.waiter import WaiterResourceDocumenter\nfrom tests.unit.docs import BaseDocsTest\n\n\nclass TestWaiterResourceDocumenter(BaseDocsTest):\n    def test_document_resource_waiters(self):\n        service_waiter_model = self.botocore_session.get_waiter_model(\n            'myservice'\n        )\n        subresource = self.resource.Sample('mysample')\n        waiter_documenter = WaiterResourceDocumenter(\n            subresource, service_waiter_model, self.root_services_path\n        )\n        waiter_documenter.document_resource_waiters(self.doc_structure)\n        self.assert_contains_lines_in_order(\n            [\n                '-------\\nWaiters\\n-------',\n                'Waiters provide an interface to wait for a resource',\n                ' to reach a specific state.',\n                'For more information about waiters refer to the',\n            ]\n        )\n        self.assert_contains_lines_in_order(\n            [\n                'wait_until_complete',\n                '.. py:method:: MyService.Sample.wait_until_complete(**kwargs)',\n                (\n                    '  Waits until this Sample is complete. This method calls '\n                    ':py:meth:`MyService.Waiter.sample_operation_complete.wait` '\n                    'which polls :py:meth:`MyService.Client.sample_operation` '\n                    'every 15 seconds until a successful state is reached. An '\n                    'error is raised after 40 failed checks.'\n                ),\n                '  **Request Syntax**',\n                '  ::',\n                '    sample.wait_until_complete(',\n                \"        Bar='string'\",\n                '    )',\n                '  :type Bar: string',\n                '  :param Bar: Documents Bar',\n                '  :returns: None',\n            ],\n            self.get_nested_service_contents(\n                'myservice', 'sample', 'wait_until_complete'\n            ),\n        )\n", "tests/unit/docs/test_collection.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom boto3.docs.collection import CollectionDocumenter\nfrom tests.unit.docs import BaseDocsTest\n\n\nclass TestCollectionDocumenter(BaseDocsTest):\n    def test_document_collections(self):\n        collection_documenter = CollectionDocumenter(\n            self.resource, self.root_services_path\n        )\n        collection_documenter.document_collections(self.doc_structure)\n        self.assert_contains_lines_in_order(\n            [\n                '-----------\\nCollections\\n-----------',\n                'Collections provide an interface to iterate over and ',\n                'manipulate groups of resources. ',\n                'For more information about collections refer to the ',\n            ]\n        )\n        self.assert_contains_lines_in_order(\n            [\n                'samples',\n                '.. py:attribute:: MyService.ServiceResource.samples',\n                '  A collection of Sample resources.'\n                'A Sample Collection will include all resources by default, '\n                'and extreme caution should be taken when performing actions '\n                'on all resources.',\n                '  .. py:method:: all()',\n                (\n                    '    Creates an iterable of all Sample resources in the '\n                    'collection.'\n                ),\n                '    **Request Syntax**',\n                '    ::',\n                '      sample_iterator = myservice.samples.all()',\n                '    :rtype: list(:py:class:`myservice.Sample`)',\n                '    :returns: A list of Sample resources',\n                '  .. py:method:: filter(**kwargs)',\n                (\n                    '    Creates an iterable of all Sample resources in '\n                    'the collection filtered by kwargs passed to method. '\n                    'A Sample collection will include all resources by default '\n                    'if no filters are provided, and extreme caution should be '\n                    'taken when performing actions on all resources'\n                ),\n                '    **Request Syntax**',\n                '    ::',\n                '      sample_iterator = myservice.samples.filter(',\n                \"          Foo='string',\",\n                \"          Bar='string'\",\n                '      )',\n                '    :type Foo: string',\n                '    :param Foo: Documents Foo',\n                '    :type Bar: string',\n                '    :param Bar: Documents Bar',\n                '    :rtype: list(:py:class:`myservice.Sample`)',\n                '    :returns: A list of Sample resources',\n                '  .. py:method:: limit(**kwargs)',\n                (\n                    '    Creates an iterable up to a specified amount of '\n                    'Sample resources in the collection.'\n                ),\n                '    **Request Syntax**',\n                '    ::',\n                '      sample_iterator = myservice.samples.limit(',\n                '          count=123',\n                '      )',\n                '    :type count: integer',\n                (\n                    '    :param count: The limit to the number of resources '\n                    'in the iterable.'\n                ),\n                '    :rtype: list(:py:class:`myservice.Sample`)',\n                '    :returns: A list of Sample resources',\n                '  .. py:method:: operate(**kwargs)',\n                '    **Request Syntax**',\n                '      response = myservice.samples.operate(',\n                \"          Foo='string',\",\n                \"          Bar='string'\",\n                '      )',\n                '    :type Foo: string',\n                '    :param Foo: Documents Foo',\n                '    :type Bar: string',\n                '    :param Bar: Documents Bar',\n                '    :rtype: dict',\n                '    :returns: ',\n                '      **Response Syntax**',\n                '      ::',\n                '        {',\n                \"            'Foo': 'string',\",\n                \"            'Bar': 'string'\",\n                '        }',\n                '      **Response Structure**',\n                '      - *(dict) --* ',\n                '        - **Foo** *(string) --* Documents Foo',\n                '        - **Bar** *(string) --* Documents Bar',\n                '  .. py:method:: page_size(**kwargs)',\n                (\n                    '    Creates an iterable of all Sample resources in the '\n                    'collection, but limits the number of items returned by '\n                    'each service call by the specified amount.'\n                ),\n                '    **Request Syntax**',\n                '    ::',\n                '',\n                '      sample_iterator = myservice.samples.page_size(',\n                '          count=123',\n                '      )',\n                '    :type count: integer',\n                (\n                    '    :param count: The number of items returned by '\n                    'each service call'\n                ),\n                '    :rtype: list(:py:class:`myservice.Sample`)',\n                '    :returns: A list of Sample resources',\n                '    ',\n            ],\n            self.get_nested_service_contents(\n                'myservice', 'service-resource', 'samples'\n            ),\n        )\n", "tests/unit/docs/test_attr.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom botocore.hooks import HierarchicalEmitter\n\nfrom boto3.docs.attr import document_attribute\nfrom tests.unit.docs import BaseDocsTest\n\n\nclass TestDocumentAttribute(BaseDocsTest):\n    def setUp(self):\n        super().setUp()\n        self.add_shape(\n            {\n                'NestedStruct': {\n                    'type': 'structure',\n                    'members': {\n                        'NestedStrAttr': {\n                            'shape': 'String',\n                            'documentation': 'Documents a nested string attribute',\n                        }\n                    },\n                }\n            }\n        )\n        self.add_shape(\n            {\n                'ResourceShape': {\n                    'type': 'structure',\n                    'members': {\n                        'StringAttr': {\n                            'shape': 'String',\n                            'documentation': 'Documents a string attribute',\n                        },\n                        'NestedAttr': {\n                            'shape': 'NestedStruct',\n                            'documentation': 'Documents a nested attribute',\n                        },\n                    },\n                }\n            }\n        )\n        self.setup_client_and_resource()\n\n        self.event_emitter = HierarchicalEmitter()\n        self.service_name = 'myservice'\n        self.resource_name = 'myresource'\n        self.service_model = self.client.meta.service_model\n\n    def test_document_attr_scalar(self):\n        shape_model = self.service_model.shape_for('ResourceShape')\n        attr_name = 'StringAttr'\n        document_attribute(\n            self.doc_structure,\n            self.service_name,\n            self.resource_name,\n            attr_name,\n            self.event_emitter,\n            shape_model.members[attr_name],\n        )\n        self.assert_contains_lines_in_order(\n            [\n                '.. py:attribute:: StringAttr',\n                '  - *(string) --* Documents a string attribute',\n            ]\n        )\n\n    def test_document_attr_structure(self):\n        shape_model = self.service_model.shape_for('ResourceShape')\n        attr_name = 'NestedAttr'\n        document_attribute(\n            self.doc_structure,\n            self.service_name,\n            self.resource_name,\n            attr_name,\n            self.event_emitter,\n            shape_model.members[attr_name],\n        )\n        self.assert_contains_lines_in_order(\n            [\n                '.. py:attribute:: NestedAttr',\n                '  - *(dict) --* Documents a nested attribute',\n                (\n                    '    - **NestedStrAttr** *(string) --* Documents a nested '\n                    'string attribute'\n                ),\n            ]\n        )\n", "tests/unit/docs/test_action.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom boto3.docs.action import ActionDocumenter\nfrom tests.unit.docs import BaseDocsTest\n\n\nclass TestActionDocumenter(BaseDocsTest):\n    def test_document_service_resource_actions(self):\n        action_documenter = ActionDocumenter(\n            self.resource, self.root_services_path\n        )\n        action_documenter.document_actions(self.doc_structure)\n        self.assert_contains_lines_in_order(\n            [\n                '-------\\nActions\\n-------',\n                'Actions call operations on resources.  They may',\n                'automatically handle the passing in of arguments set',\n                'from identifiers and some attributes.',\n                'For more information about actions refer to the ',\n            ]\n        )\n        self.assert_contains_lines_in_order(\n            [\n                'sample_operation',\n                '.. py:method:: MyService.ServiceResource.sample_operation(**kwargs)',\n                '  **Request Syntax**',\n                '  ::',\n                '    response = myservice.sample_operation(',\n                '        Foo=\\'string\\',',\n                '        Bar=\\'string\\'',\n                '    )',\n                '  :type Foo: string',\n                '  :param Foo: Documents Foo',\n                '  :type Bar: string',\n                '  :param Bar: Documents Bar',\n                '  :rtype: dict',\n                '  :returns:',\n                '    **Response Syntax**',\n                '    ::',\n                '      {',\n                '          \\'Foo\\': \\'string\\',',\n                '          \\'Bar\\': \\'string\\'',\n                '      }',\n                '    **Response Structure**',\n                '    - *(dict) --*',\n                '      - **Foo** *(string) --* Documents Foo',\n                '      - **Bar** *(string) --* Documents Bar',\n            ],\n            self.get_nested_service_contents(\n                'myservice', 'service-resource', 'sample_operation'\n            ),\n        )\n\n    def test_document_nonservice_resource_actions(self):\n        subresource = self.resource.Sample('mysample')\n        action_documenter = ActionDocumenter(\n            subresource, self.root_services_path\n        )\n        action_documenter.document_actions(self.doc_structure)\n        self.assert_contains_lines_in_order(\n            [\n                '-------\\nActions\\n-------',\n                'Actions call operations on resources.  They may',\n                'automatically handle the passing in of arguments set',\n                'from identifiers and some attributes.',\n                'For more information about actions refer to the ',\n            ]\n        )\n        self.assert_contains_lines_in_order(\n            [\n                'load',\n                '.. py:method:: MyService.Sample.load()',\n                (\n                    '  Calls :py:meth:`MyService.Client.sample_operation` to update '\n                    'the attributes of the Sample resource'\n                ),\n                '  **Request Syntax**',\n                '  ::',\n                '    sample.load()',\n                '  :returns: None',\n            ],\n            self.get_nested_service_contents('myservice', 'sample', 'load'),\n        )\n        self.assert_contains_lines_in_order(\n            [\n                'operate',\n                '.. py:method:: MyService.Sample.operate(**kwargs)',\n                '  **Request Syntax**',\n                '  ::',\n                '    response = sample.operate(',\n                \"        Bar='string'\",\n                '    )',\n                '  :type Bar: string',\n                '  :param Bar: Documents Bar',\n                '  :rtype: dict',\n                '  :returns: ',\n                '    ',\n                '    **Response Syntax**',\n                '    ::',\n                '      {',\n                \"          'Foo': 'string',\",\n                \"          'Bar': 'string'\",\n                '      }',\n                '    **Response Structure**',\n                '    - *(dict) --* ',\n                '      - **Foo** *(string) --* Documents Foo',\n                '      - **Bar** *(string) --* Documents Bar',\n            ],\n            self.get_nested_service_contents('myservice', 'sample', 'operate'),\n        )\n        self.assert_contains_lines_in_order(\n            [\n                'reload',\n                '.. py:method:: MyService.Sample.reload()',\n                (\n                    '  Calls :py:meth:`MyService.Client.sample_operation` to update '\n                    'the attributes of the Sample resource'\n                ),\n                '  **Request Syntax**',\n                '  ::',\n                '    sample.reload()',\n                '  :returns: None',\n            ],\n            self.get_nested_service_contents('myservice', 'sample', 'reload'),\n        )\n        self.assert_contains_lines_in_order(\n            [\n                'get_available_subresources',\n                '.. py:method:: MyService.Sample.get_available_subresources()',\n                'Returns a list of all the available sub-resources for this',\n                ':returns: A list containing the name of each sub-resource for this',\n                ':rtype: list of str',\n            ],\n            self.get_nested_service_contents(\n                'myservice', 'sample', 'get_available_subresources'\n            ),\n        )\n", "tests/unit/docs/test_service.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport os\n\nimport boto3\nfrom boto3.docs.service import ServiceDocumenter\nfrom tests import mock\nfrom tests.unit.docs import BaseDocsTest\n\n\nclass TestServiceDocumenter(BaseDocsTest):\n    def test_document_service(self):\n        service_documenter = ServiceDocumenter(\n            'myservice', self.session, self.root_services_path\n        )\n        contents = service_documenter.document_service().decode('utf-8')\n        lines = [\n            '*********',\n            'MyService',\n            '*********',\n            '======',\n            'Client',\n            '======',\n            '.. py:class:: MyService.Client',\n            'These are the available methods:',\n            '  myservice/client/sample_operation',\n            '==========',\n            'Paginators',\n            '==========',\n            'The available paginators are:',\n            '  myservice/paginator/SampleOperation',\n            '=======',\n            'Waiters',\n            '=======',\n            'The available waiters are:',\n            '  myservice/waiter/SampleOperationComplete',\n            '=========',\n            'Resources',\n            '=========',\n            'Resources are available in boto3 via the ',\n            '``resource`` method. For more detailed instructions ',\n            'and examples on the usage of resources, see the ',\n            'resources ',\n            'The available resources are:',\n            '  myservice/service-resource/index',\n            '  myservice/sample/index',\n        ]\n        self.assert_contains_lines_in_order(lines, contents)\n        self.assert_contains_lines_in_order(\n            [\n                '================',\n                'Service Resource',\n                '================',\n                '.. py:class:: MyService.ServiceResource()',\n                '  A resource representing AWS MyService::',\n                '    import boto3',\n                \"    myservice = boto3.resource('myservice')\",\n                'Actions',\n                \"These are the resource's available actions:\",\n                '.. toctree::',\n                '  :maxdepth: 1',\n                '  :titlesonly:',\n                '  sample_operation',\n                'Sub-resources',\n                \"These are the resource's available sub-resources:\",\n                '.. toctree::',\n                '  :maxdepth: 1',\n                '  :titlesonly:',\n                '  Sample',\n                'Collections',\n                \"These are the resource's available collections:\",\n                '.. toctree::',\n                '  :maxdepth: 1',\n                '  :titlesonly:',\n                '  samples',\n            ],\n            self.get_nested_service_contents(\n                'myservice', 'service-resource', 'index'\n            ),\n        )\n        self.assert_contains_lines_in_order(\n            [\n                '======',\n                'Sample',\n                '======',\n                '.. py:class:: MyService.Sample(name)',\n                \"These are the resource's available identifiers:\",\n                '.. toctree::',\n                '  :maxdepth: 1',\n                '  :titlesonly:',\n                '  name',\n                \"These are the resource's available attributes:\",\n                '.. toctree::',\n                '  :maxdepth: 1',\n                '  :titlesonly:',\n                '  bar',\n                '  foo',\n                \"These are the resource's available actions:\",\n                '.. toctree::',\n                '  :maxdepth: 1',\n                '  :titlesonly:',\n                '  load',\n                '  operate',\n                '  reload',\n                \"These are the resource's available waiters:\",\n                '.. toctree::',\n                '  :maxdepth: 1',\n                '  :titlesonly:',\n                '  wait_until_complete',\n            ],\n            self.get_nested_service_contents('myservice', 'sample', 'index'),\n        )\n        self.assert_contains_lines_in_order(\n            [\n                'sample_operation',\n                '.. py:method:: MyService.Client.sample_operation(**kwargs)',\n                '  **Examples**',\n                '  Sample Description.',\n                '  ::',\n                '    response = client.sample_operation(',\n            ],\n            self.get_nested_service_contents(\n                'myservice', 'client', 'sample_operation'\n            ),\n        )\n        self.assert_contains_lines_in_order(\n            [\n                'SampleOperation',\n                '.. py:class:: MyService.Paginator.SampleOperation',\n                '  .. py:method:: paginate(**kwargs)',\n            ],\n            self.get_nested_service_contents(\n                'myservice', 'paginator', 'SampleOperation'\n            ),\n        )\n        self.assert_contains_lines_in_order(\n            [\n                'SampleOperationComplete',\n                '.. py:class:: MyService.Waiter.SampleOperationComplete',\n                '  .. py:method:: wait(**kwargs)',\n            ],\n            self.get_nested_service_contents(\n                'myservice', 'waiter', 'SampleOperationComplete'\n            ),\n        )\n        self.assert_contains_lines_in_order(\n            [\n                'sample_operation',\n                '.. py:method:: MyService.ServiceResource.sample_operation(**kwargs)',\n            ],\n            self.get_nested_service_contents(\n                'myservice', 'service-resource', 'sample_operation'\n            ),\n        )\n        self.assert_contains_lines_in_order(\n            [\n                'Sample',\n                '.. py:method:: MyService.ServiceResource.Sample(name)',\n            ],\n            self.get_nested_service_contents(\n                'myservice', 'service-resource', 'Sample'\n            ),\n        )\n        self.assert_contains_lines_in_order(\n            [\n                'samples',\n                '.. py:attribute:: MyService.ServiceResource.samples',\n                '  .. py:method:: all()',\n                '  .. py:method:: filter(**kwargs)',\n                '  .. py:method:: limit(**kwargs)',\n                '  .. py:method:: page_size(**kwargs)',\n            ],\n            self.get_nested_service_contents(\n                'myservice', 'service-resource', 'samples'\n            ),\n        )\n        self.assert_contains_lines_in_order(\n            [\n                'name',\n                '.. py:attribute:: MyService.Sample.name',\n            ],\n            self.get_nested_service_contents('myservice', 'sample', 'name'),\n        )\n        self.assert_contains_lines_in_order(\n            [\n                'name',\n                '.. py:attribute:: MyService.Sample.name',\n            ],\n            self.get_nested_service_contents('myservice', 'sample', 'name'),\n        )\n        self.assert_contains_lines_in_order(\n            [\n                'bar',\n                '.. py:attribute:: MyService.Sample.bar',\n            ],\n            self.get_nested_service_contents('myservice', 'sample', 'bar'),\n        )\n        self.assert_contains_lines_in_order(\n            [\n                'load',\n                '.. py:method:: MyService.Sample.load()',\n            ],\n            self.get_nested_service_contents('myservice', 'sample', 'load'),\n        )\n        self.assert_contains_lines_in_order(\n            [\n                'wait_until_complete',\n                '.. py:method:: MyService.Sample.wait_until_complete(**kwargs)',\n            ],\n            self.get_nested_service_contents(\n                'myservice', 'sample', 'wait_until_complete'\n            ),\n        )\n\n    def test_document_service_no_resource(self):\n        os.remove(self.resource_model_file)\n        service_documenter = ServiceDocumenter(\n            'myservice', self.session, self.root_services_path\n        )\n        contents = service_documenter.document_service().decode('utf-8')\n        assert 'Service Resource' not in contents\n\n    def test_document_service_no_paginators(self):\n        # Delete the resource model so that the resource is not documented\n        # as it may try to look at the paginator model during documentation.\n        os.remove(self.resource_model_file)\n        os.remove(self.paginator_model_file)\n        service_documenter = ServiceDocumenter(\n            'myservice', self.session, self.root_services_path\n        )\n        contents = service_documenter.document_service().decode('utf-8')\n        assert 'Paginators' not in contents\n\n    def test_document_service_no_waiter(self):\n        # Delete the resource model so that the resource is not documented\n        # as it may try to look at the waiter model during documentation.\n        os.remove(self.resource_model_file)\n        os.remove(self.waiter_model_file)\n        service_documenter = ServiceDocumenter(\n            'myservice', self.session, self.root_services_path\n        )\n        contents = service_documenter.document_service().decode('utf-8')\n        assert 'Waiters' not in contents\n\n    def test_creates_correct_path_to_examples_based_on_service_name(self):\n        path = os.sep.join(\n            [os.path.dirname(boto3.__file__), 'examples', 'myservice.rst']\n        )\n        path = os.path.realpath(path)\n        with mock.patch('os.path.isfile') as isfile:\n            isfile.return_value = False\n            s = ServiceDocumenter(\n                'myservice', self.session, self.root_services_path\n            )\n            s.document_service()\n            assert isfile.call_args_list[-1] == mock.call(path)\n\n    def test_injects_examples_when_found(self):\n        examples_path = os.sep.join(\n            [os.path.dirname(__file__), '..', 'data', 'examples']\n        )\n        service_documenter = ServiceDocumenter(\n            'myservice', self.session, self.root_services_path\n        )\n        service_documenter.EXAMPLE_PATH = examples_path\n        contents = service_documenter.document_service().decode('utf-8')\n        assert 'This is an example' in contents\n        assert 'This is for another service' not in contents\n\n    def test_service_with_context_params(self):\n        self.json_model['clientContextParams'] = {\n            'MyContextParam': {\n                'documentation': 'This is my context param',\n                'type': 'boolean',\n            }\n        }\n        self.setup_client_and_resource()\n        service_documenter = ServiceDocumenter(\n            'myservice', self.session, self.root_services_path\n        )\n        contents = service_documenter.document_service().decode('utf-8')\n        lines = [\n            \"=========================\",\n            \"Client Context Parameters\",\n            \"=========================\",\n            \"* ``my_context_param`` (boolean) - This is my context param\",\n        ]\n        self.assert_contains_lines_in_order(lines, contents)\n", "tests/unit/docs/test_client.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom boto3.docs.client import Boto3ClientDocumenter\nfrom tests.unit.docs import BaseDocsTest\n\n\nclass TestBoto3ClientDocumenter(BaseDocsTest):\n    def setUp(self):\n        super().setUp()\n        self.client_documenter = Boto3ClientDocumenter(\n            self.client, self.root_services_path\n        )\n\n    def test_document_client(self):\n        self.client_documenter.document_client(self.doc_structure)\n        self.assert_contains_lines_in_order(\n            [\n                '======',\n                'Client',\n                '======',\n                '.. py:class:: MyService.Client',\n                '  A low-level client representing AWS MyService',\n                '  ::',\n                '    import boto3',\n                '    client = boto3.client(\\'myservice\\')',\n                'These are the available methods:',\n                '.. toctree::',\n                '  :maxdepth: 1',\n                '  :titlesonly:',\n                '  myservice/client/can_paginate',\n                '  myservice/client/get_paginator',\n                '  myservice/client/get_waiter',\n                '  myservice/client/sample_operation',\n            ]\n        )\n        self.assert_contains_lines_in_order(\n            [\n                'can_paginate',\n                '.. py:method:: MyService.Client.can_paginate(operation_name)',\n            ],\n            self.get_nested_service_contents(\n                'myservice', 'client', 'can_paginate'\n            ),\n        )\n        self.assert_contains_lines_in_order(\n            [\n                'get_paginator',\n                '.. py:method:: MyService.Client.get_paginator(operation_name)',\n            ],\n            self.get_nested_service_contents(\n                'myservice', 'client', 'get_paginator'\n            ),\n        )\n        self.assert_contains_lines_in_order(\n            [\n                'get_waiter',\n                '.. py:method:: MyService.Client.get_waiter(waiter_name)',\n            ],\n            self.get_nested_service_contents(\n                'myservice', 'client', 'get_waiter'\n            ),\n        )\n        self.assert_contains_lines_in_order(\n            [\n                'sample_operation',\n                '.. py:method:: MyService.Client.sample_operation(**kwargs)',\n                '  **Request Syntax**',\n                '  ::',\n                '    response = client.sample_operation(',\n                '        Foo=\\'string\\'',\n                '        Bar=\\'string\\'',\n                '    )',\n                '  :type Foo: string',\n                '  :param Foo: Documents Foo',\n                '  :type Bar: string',\n                '  :param Bar: Documents Bar',\n                '  :rtype: dict',\n                '  :returns:',\n                '    **Response Syntax**',\n                '    ::',\n                '      {',\n                '          \\'Foo\\': \\'string\\'',\n                '          \\'Bar\\': \\'string\\'',\n                '      }',\n                '    **Response Structure**',\n                '    - *(dict) --*',\n                '      - **Foo** *(string) --*',\n                '      - **Bar** *(string) --*',\n            ],\n            self.get_nested_service_contents(\n                'myservice', 'client', 'sample_operation'\n            ),\n        )\n", "tests/unit/docs/test_docstring.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport io\n\nfrom tests import mock\nfrom tests.unit.docs import BaseDocsTest\n\n\nclass TestResourceDocstrings(BaseDocsTest):\n    def test_action_help(self):\n        with mock.patch('sys.stdout', io.StringIO()) as mock_stdout:\n            help(self.resource.sample_operation)\n        action_docstring = mock_stdout.getvalue()\n        self.assert_contains_lines_in_order(\n            [\n                '  **Request Syntax**',\n                '  ::',\n                '    response = myservice.sample_operation(',\n                '        Foo=\\'string\\',',\n                '        Bar=\\'string\\'',\n                '    )',\n                '  :type Foo: string',\n                '  :param Foo: Documents Foo',\n                '  :type Bar: string',\n                '  :param Bar: Documents Bar',\n                '  :rtype: dict',\n                '  :returns:',\n                '    **Response Syntax**',\n                '    ::',\n                '      {',\n                '          \\'Foo\\': \\'string\\',',\n                '          \\'Bar\\': \\'string\\'',\n                '      }',\n                '    **Response Structure**',\n                '    - *(dict) --*',\n                '      - **Foo** *(string) --* Documents Foo',\n                '      - **Bar** *(string) --* Documents Bar',\n            ],\n            action_docstring,\n        )\n\n    def test_load_help(self):\n        sub_resource = self.resource.Sample('Id')\n        with mock.patch('sys.stdout', io.StringIO()) as mock_stdout:\n            help(sub_resource.load)\n        load_docstring = mock_stdout.getvalue()\n        self.assert_contains_lines_in_order(\n            [\n                (\n                    '  Calls :py:meth:`MyService.Client.sample_operation` to update '\n                    'the attributes of the Sample resource'\n                ),\n                '  **Request Syntax**',\n                '  ::',\n                '    sample.load()',\n                '  :returns: None',\n            ],\n            load_docstring,\n        )\n\n    def test_sub_resource_help(self):\n        with mock.patch('sys.stdout', io.StringIO()) as mock_stdout:\n            help(self.resource.Sample)\n        sub_resource_docstring = mock_stdout.getvalue()\n        self.assert_contains_lines_in_order(\n            [\n                '  Creates a Sample resource.::',\n                \"    sample = myservice.Sample('name')\",\n                '  :type name: string',\n                \"  :param name: The Sample's name identifier.\",\n                '  :rtype: :py:class:`MyService.Sample`',\n                '  :returns: A Sample resource',\n            ],\n            sub_resource_docstring,\n        )\n\n    def test_attribute_help(self):\n        with mock.patch('sys.stdout', io.StringIO()) as mock_stdout:\n            help(self.resource.Sample('id').__class__.foo)\n        attribute_docstring = mock_stdout.getvalue()\n        self.assert_contains_lines_in_order(\n            ['    - *(string) --* Documents Foo'], attribute_docstring\n        )\n\n    def test_identifier_help(self):\n        with mock.patch('sys.stdout', io.StringIO()) as mock_stdout:\n            help(self.resource.Sample('id').__class__.name)\n        identifier_docstring = mock_stdout.getvalue()\n        self.assert_contains_lines_in_order(\n            [\n                \"    *(string)* The Sample's name identifier. This \"\n                \"**must** be set.\"\n            ],\n            identifier_docstring,\n        )\n\n    def test_reference_help(self):\n        sample_resource = self.resource.Sample('id')\n        with mock.patch('sys.stdout', io.StringIO()) as mock_stdout:\n            help(sample_resource.__class__.related_sample)\n        reference_docstring = mock_stdout.getvalue()\n        self.assert_contains_lines_in_order(\n            [\n                \"    (:py:class:`Sample`) The related related_sample \"\n                \"if set, otherwise ``None``.\"\n            ],\n            reference_docstring,\n        )\n\n    def test_collection_help(self):\n        with mock.patch('sys.stdout', io.StringIO()) as mock_stdout:\n            help(self.resource.__class__.samples)\n        collection_method_docstring = mock_stdout.getvalue()\n        self.assert_contains_lines_in_order(\n            ['    A collection of Sample resources'],\n            collection_method_docstring,\n        )\n\n    def test_collection_all_method_help(self):\n        with mock.patch('sys.stdout', io.StringIO()) as mock_stdout:\n            help(self.resource.samples.all)\n        collection_method_docstring = mock_stdout.getvalue()\n        self.assert_contains_lines_in_order(\n            [\n                (\n                    '    Creates an iterable of all Sample resources in the '\n                    'collection.'\n                ),\n                '    **Request Syntax**',\n                '    ::',\n                '      sample_iterator = myservice.samples.all()',\n                '    :rtype: list(:py:class:`myservice.Sample`)',\n                '    :returns: A list of Sample resources',\n            ],\n            collection_method_docstring,\n        )\n\n    def test_collection_filter_method_help(self):\n        with mock.patch('sys.stdout', io.StringIO()) as mock_stdout:\n            help(self.resource.samples.filter)\n        collection_method_docstring = mock_stdout.getvalue()\n        self.assert_contains_lines_in_order(\n            [\n                '    **Request Syntax**',\n                '    ::',\n                '      sample_iterator = myservice.samples.filter(',\n                \"          Foo='string',\",\n                \"          Bar='string'\",\n                '      )',\n                '    :type Foo: string',\n                '    :param Foo: Documents Foo',\n                '    :type Bar: string',\n                '    :param Bar: Documents Bar',\n                '    :rtype: list(:py:class:`myservice.Sample`)',\n                '    :returns: A list of Sample resources',\n            ],\n            collection_method_docstring,\n        )\n\n    def test_collection_limit_method_help(self):\n        with mock.patch('sys.stdout', io.StringIO()) as mock_stdout:\n            help(self.resource.samples.limit)\n        collection_method_docstring = mock_stdout.getvalue()\n        self.assert_contains_lines_in_order(\n            [\n                '    **Request Syntax**',\n                '    ::',\n                '      sample_iterator = myservice.samples.limit(',\n                '          count=123',\n                '      )',\n                '    :type count: integer',\n                (\n                    '    :param count: The limit to the number of resources '\n                    'in the iterable.'\n                ),\n                '    :rtype: list(:py:class:`myservice.Sample`)',\n                '    :returns: A list of Sample resources',\n            ],\n            collection_method_docstring,\n        )\n\n    def test_collection_page_size_method_help(self):\n        with mock.patch('sys.stdout', io.StringIO()) as mock_stdout:\n            help(self.resource.samples.page_size)\n        collection_method_docstring = mock_stdout.getvalue()\n        self.assert_contains_lines_in_order(\n            [\n                '    **Request Syntax**',\n                '    ::',\n                '      sample_iterator = myservice.samples.page_size(',\n                '          count=123',\n                '      )',\n                '    :type count: integer',\n                (\n                    '    :param count: The number of items returned by '\n                    'each service call'\n                ),\n                '    :rtype: list(:py:class:`myservice.Sample`)',\n                '    :returns: A list of Sample resources',\n            ],\n            collection_method_docstring,\n        )\n\n    def test_collection_chaining_help(self):\n        collection = self.resource.samples.all()\n        with mock.patch('sys.stdout', io.StringIO()) as mock_stdout:\n            help(collection.all)\n        collection_method_docstring = mock_stdout.getvalue()\n        self.assert_contains_lines_in_order(\n            [\n                (\n                    '    Creates an iterable of all Sample resources in the '\n                    'collection.'\n                ),\n                '    **Request Syntax**',\n                '    ::',\n                '      sample_iterator = myservice.samples.all()',\n                '    :rtype: list(:py:class:`myservice.Sample`)',\n                '    :returns: A list of Sample resources',\n            ],\n            collection_method_docstring,\n        )\n\n    def test_batch_action_help(self):\n        with mock.patch('sys.stdout', io.StringIO()) as mock_stdout:\n            help(self.resource.samples.operate)\n        batch_action_docstring = mock_stdout.getvalue()\n        self.assert_contains_lines_in_order(\n            [\n                '    **Request Syntax**',\n                '    ::',\n                '      response = myservice.samples.operate(',\n                \"          Foo='string',\",\n                \"          Bar='string'\",\n                '      )',\n                '    :type Foo: string',\n                '    :param Foo: Documents Foo',\n                '    :type Bar: string',\n                '    :param Bar: Documents Bar',\n                '    :rtype: dict',\n                '    :returns:',\n                '      **Response Syntax**',\n                '      ::',\n                '        {',\n                \"            'Foo': 'string',\",\n                \"            'Bar': 'string'\",\n                '        }',\n                '      **Response Structure**',\n                '      - *(dict) --*',\n                '        - **Foo** *(string) --* Documents Foo',\n                '        - **Bar** *(string) --* Documents Bar',\n            ],\n            batch_action_docstring,\n        )\n\n    def test_resource_waiter_help(self):\n        with mock.patch('sys.stdout', io.StringIO()) as mock_stdout:\n            help(self.resource.Sample('id').wait_until_complete)\n        resource_waiter_docstring = mock_stdout.getvalue()\n        self.assert_contains_lines_in_order(\n            [\n                (\n                    '    Waits until this Sample is complete. This method calls '\n                    ':py:meth:`MyService.Waiter.sample_operation_complete.wait` '\n                    'which polls :py:meth:`MyService.Client.sample_operation` every '\n                    '15 seconds until a successful state is reached. An error '\n                    'is raised after 40 failed checks.'\n                ),\n                '    **Request Syntax**',\n                '    ::',\n                '      sample.wait_until_complete(',\n                \"          Bar='string'\",\n                '      )',\n                '    :type Bar: string',\n                '    :param Bar: Documents Bar',\n                '    :returns: None',\n            ],\n            resource_waiter_docstring,\n        )\n", "tests/unit/docs/__init__.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport json\nimport os\nimport shutil\nimport tempfile\n\nimport botocore.session\nfrom botocore.compat import OrderedDict\nfrom botocore.docs.bcdoc.restdoc import DocumentStructure\nfrom botocore.loaders import Loader\n\nfrom boto3.session import Session\nfrom tests import unittest\n\n\nclass BaseDocsTest(unittest.TestCase):\n    def setUp(self):\n        self.root_dir = tempfile.mkdtemp()\n        self.version_dirs = os.path.join(\n            self.root_dir, 'myservice', '2014-01-01'\n        )\n        os.makedirs(self.version_dirs)\n\n        self.model_file = os.path.join(self.version_dirs, 'service-2.json')\n        self.waiter_model_file = os.path.join(\n            self.version_dirs, 'waiters-2.json'\n        )\n        self.paginator_model_file = os.path.join(\n            self.version_dirs, 'paginators-1.json'\n        )\n        self.resource_model_file = os.path.join(\n            self.version_dirs, 'resources-1.json'\n        )\n        self.example_model_file = os.path.join(\n            self.version_dirs, 'examples-1.json'\n        )\n        self.docs_root_dir = tempfile.mkdtemp()\n        self.root_services_path = os.path.join(\n            self.docs_root_dir, 'reference', 'services'\n        )\n\n        self.json_model = {}\n        self.waiter_json_model = {}\n        self.paginator_json_model = {}\n        self.resource_json_model = {}\n        self._setup_models()\n\n        self.doc_name = 'MyDoc'\n        self.doc_structure = DocumentStructure(self.doc_name, target='html')\n\n        self.setup_client_and_resource()\n\n    def tearDown(self):\n        shutil.rmtree(self.root_dir)\n        shutil.rmtree(self.docs_root_dir)\n\n    def setup_client_and_resource(self):\n        self._write_models()\n        self.loader = Loader(extra_search_paths=[self.root_dir])\n        self.botocore_session = botocore.session.get_session()\n        self.botocore_session.register_component('data_loader', self.loader)\n        self.session = Session(\n            botocore_session=self.botocore_session, region_name='us-east-1'\n        )\n        self.client = self.session.client('myservice', 'us-east-1')\n        self.resource = self.session.resource('myservice', 'us-east-1')\n\n    def get_nested_service_contents(self, service, type, name):\n        service_file_path = os.path.join(\n            self.root_services_path, service, type, f'{name}.rst'\n        )\n        with open(service_file_path, 'rb') as f:\n            return f.read().decode('utf-8')\n\n    def _setup_models(self):\n        self.json_model = {\n            'metadata': {\n                'apiVersion': '2014-01-01',\n                'endpointPrefix': 'myservice',\n                'signatureVersion': 'v4',\n                'serviceFullName': 'AWS MyService',\n                'protocol': 'query',\n                'serviceId': 'MyService',\n            },\n            'operations': {\n                'SampleOperation': {\n                    'name': 'SampleOperation',\n                    'input': {'shape': 'SampleOperationInputOutput'},\n                    'output': {'shape': 'SampleOperationInputOutput'},\n                }\n            },\n            'shapes': {\n                'SampleOperationInputOutput': {\n                    'type': 'structure',\n                    'members': OrderedDict(\n                        [\n                            (\n                                'Foo',\n                                {\n                                    'shape': 'String',\n                                    'documentation': 'Documents Foo',\n                                },\n                            ),\n                            (\n                                'Bar',\n                                {\n                                    'shape': 'String',\n                                    'documentation': 'Documents Bar',\n                                },\n                            ),\n                        ]\n                    ),\n                },\n                'String': {'type': 'string'},\n            },\n        }\n\n        self.example_json_model = {\n            \"version\": 1,\n            \"examples\": {\n                \"SampleOperation\": [\n                    {\n                        \"id\": \"sample-id\",\n                        \"title\": \"sample-title\",\n                        \"description\": \"Sample Description.\",\n                        \"input\": OrderedDict(\n                            [\n                                (\"Foo\", \"bar\"),\n                            ]\n                        ),\n                        \"comments\": {\n                            \"input\": {\"Foo\": \"biz\"},\n                        },\n                    }\n                ]\n            },\n        }\n\n        self.waiter_json_model = {\n            \"version\": 2,\n            \"waiters\": {\n                \"SampleOperationComplete\": {\n                    \"delay\": 15,\n                    \"operation\": \"SampleOperation\",\n                    \"maxAttempts\": 40,\n                    \"acceptors\": [\n                        {\n                            \"expected\": \"complete\",\n                            \"matcher\": \"pathAll\",\n                            \"state\": \"success\",\n                            \"argument\": \"Biz\",\n                        },\n                        {\n                            \"expected\": \"failed\",\n                            \"matcher\": \"pathAny\",\n                            \"state\": \"failure\",\n                            \"argument\": \"Biz\",\n                        },\n                    ],\n                }\n            },\n        }\n\n        self.paginator_json_model = {\n            \"pagination\": {\n                \"SampleOperation\": {\n                    \"input_token\": \"NextResult\",\n                    \"output_token\": \"NextResult\",\n                    \"limit_key\": \"MaxResults\",\n                    \"result_key\": \"Biz\",\n                }\n            }\n        }\n\n        self.resource_json_model = {\n            \"service\": {\n                \"actions\": OrderedDict(\n                    [\n                        (\n                            \"SampleOperation\",\n                            {\"request\": {\"operation\": \"SampleOperation\"}},\n                        ),\n                        (\n                            \"SampleListReturnOperation\",\n                            {\n                                \"request\": {\"operation\": \"SampleOperation\"},\n                                \"resource\": {\n                                    \"type\": \"Sample\",\n                                    \"identifiers\": [\n                                        {\n                                            \"target\": \"Name\",\n                                            \"source\": \"response\",\n                                            \"path\": \"Samples[].Name\",\n                                        }\n                                    ],\n                                    \"path\": \"Samples[]\",\n                                },\n                            },\n                        ),\n                    ]\n                ),\n                \"has\": {\n                    \"Sample\": {\n                        \"resource\": {\n                            \"type\": \"Sample\",\n                            \"identifiers\": [\n                                {\"target\": \"Name\", \"source\": \"input\"}\n                            ],\n                        }\n                    }\n                },\n                \"hasMany\": {\n                    \"Samples\": {\n                        \"request\": {\"operation\": \"SampleOperation\"},\n                        \"resource\": {\n                            \"type\": \"Sample\",\n                            \"identifiers\": [\n                                {\n                                    \"target\": \"Name\",\n                                    \"source\": \"response\",\n                                    \"path\": \"Samples[].Foo\",\n                                }\n                            ],\n                        },\n                    }\n                },\n            },\n            \"resources\": {\n                \"Sample\": {\n                    \"identifiers\": [{\"name\": \"Name\", \"memberName\": \"Foo\"}],\n                    \"shape\": \"SampleOperationInputOutput\",\n                    \"load\": {\n                        \"request\": {\n                            \"operation\": \"SampleOperation\",\n                            \"params\": [\n                                {\n                                    \"target\": \"Foo\",\n                                    \"source\": \"identifier\",\n                                    \"name\": \"Name\",\n                                }\n                            ],\n                        }\n                    },\n                    \"actions\": {\n                        \"Operate\": {\n                            \"request\": {\n                                \"operation\": \"SampleOperation\",\n                                \"params\": [\n                                    {\n                                        \"target\": \"Foo\",\n                                        \"source\": \"identifier\",\n                                        \"name\": \"Name\",\n                                    }\n                                ],\n                            }\n                        }\n                    },\n                    \"batchActions\": {\n                        \"Operate\": {\n                            \"request\": {\n                                \"operation\": \"SampleOperation\",\n                                \"params\": [\n                                    {\n                                        \"target\": \"Samples[].Foo\",\n                                        \"source\": \"identifier\",\n                                        \"name\": \"Name\",\n                                    }\n                                ],\n                            }\n                        }\n                    },\n                    \"has\": {\n                        \"RelatedSample\": {\n                            \"resource\": {\n                                \"type\": \"Sample\",\n                                \"identifiers\": [\n                                    {\n                                        \"target\": \"Name\",\n                                        \"source\": \"data\",\n                                        \"path\": \"Foo\",\n                                    }\n                                ],\n                            }\n                        }\n                    },\n                    \"waiters\": {\n                        \"Complete\": {\n                            \"waiterName\": \"SampleOperationComplete\",\n                            \"params\": [\n                                {\n                                    \"target\": \"Foo\",\n                                    \"source\": \"identifier\",\n                                    \"name\": \"Name\",\n                                }\n                            ],\n                        }\n                    },\n                }\n            },\n        }\n\n    def _write_models(self):\n        with open(self.resource_model_file, 'w') as f:\n            json.dump(self.resource_json_model, f)\n\n        with open(self.waiter_model_file, 'w') as f:\n            json.dump(self.waiter_json_model, f)\n\n        with open(self.paginator_model_file, 'w') as f:\n            json.dump(self.paginator_json_model, f)\n\n        with open(self.model_file, 'w') as f:\n            json.dump(self.json_model, f)\n\n        with open(self.example_model_file, 'w') as f:\n            json.dump(self.example_json_model, f)\n\n    def add_shape(self, shape):\n        shape_name = list(shape.keys())[0]\n        self.json_model['shapes'][shape_name] = shape[shape_name]\n\n    def add_shape_to_params(\n        self, param_name, shape_name, documentation=None, is_required=False\n    ):\n        params_shape = self.json_model['shapes']['SampleOperationInputOutput']\n        member = {'shape': shape_name}\n        if documentation is not None:\n            member['documentation'] = documentation\n        params_shape['members'][param_name] = member\n\n        if is_required:\n            required_list = params_shape.get('required', [])\n            required_list.append(param_name)\n            params_shape['required'] = required_list\n\n    def assert_contains_lines_in_order(self, lines, contents=None):\n        if contents is None:\n            contents = self.doc_structure.flush_structure().decode('utf-8')\n        for line in lines:\n            assert line in contents\n            beginning = contents.find(line)\n            contents = contents[(beginning + len(line)) :]\n\n    def assert_not_contains_lines(self, lines):\n        contents = self.doc_structure.flush_structure().decode('utf-8')\n        for line in lines:\n            assert line not in contents\n", "tests/unit/docs/test_method.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom botocore.docs.utils import DocumentedShape\nfrom botocore.hooks import HierarchicalEmitter\n\nfrom boto3.docs.method import document_model_driven_resource_method\nfrom boto3.resources.model import ResponseResource\nfrom tests.unit.docs import BaseDocsTest\n\n\nclass TestDocumentModelDrivenResourceMethod(BaseDocsTest):\n    def setUp(self):\n        super().setUp()\n        self.event_emitter = HierarchicalEmitter()\n        self.service_model = self.client.meta.service_model\n        self.operation_model = self.service_model.operation_model(\n            'SampleOperation'\n        )\n        self.service_resource_model = self.resource.meta.resource_model\n\n    def test_default(self):\n        document_model_driven_resource_method(\n            self.doc_structure,\n            'foo',\n            self.operation_model,\n            event_emitter=self.event_emitter,\n            method_description='This describes the foo method.',\n            example_prefix='response = myservice.foo',\n            resource_action_model=self.service_resource_model.actions[0],\n        )\n        self.assert_contains_lines_in_order(\n            [\n                '.. py:method:: foo(**kwargs)',\n                '  This describes the foo method.',\n                '  **Request Syntax**',\n                '  ::',\n                '    response = myservice.foo(',\n                \"        Foo='string',\",\n                \"        Bar='string'\",\n                '    )',\n                '  :type Foo: string',\n                '  :param Foo: Documents Foo',\n                '  :type Bar: string',\n                '  :param Bar: Documents Bar',\n                '  :rtype: dict',\n                '  :returns: ',\n                '    **Response Syntax**',\n                '    ::',\n                '      {',\n                \"          'Foo': 'string',\",\n                \"          'Bar': 'string'\",\n                '      }',\n                '    **Response Structure**',\n                '    - *(dict) --* ',\n                '      - **Foo** *(string) --* Documents Foo',\n                '      - **Bar** *(string) --* Documents Bar',\n            ]\n        )\n\n    def test_returns_resource(self):\n        resource_action = self.service_resource_model.actions[0]\n        # Override the return type of the action to be a resource\n        # instead of the regular dictionary.\n        resource_action.resource = ResponseResource(\n            {\n                'type': 'Sample',\n                'identifiers': [\n                    {\n                        'target': 'Name',\n                        'source': 'requestParameter',\n                        'path': 'Foo',\n                    }\n                ],\n            },\n            self.resource_json_model,\n        )\n        document_model_driven_resource_method(\n            self.doc_structure,\n            'foo',\n            self.operation_model,\n            event_emitter=self.event_emitter,\n            method_description='This describes the foo method.',\n            example_prefix='sample = myservice.foo',\n            resource_action_model=resource_action,\n        )\n        self.assert_contains_lines_in_order(\n            [\n                '.. py:method:: foo(**kwargs)',\n                '  This describes the foo method.',\n                '  **Request Syntax**',\n                '  ::',\n                '    sample = myservice.foo(',\n                \"        Foo='string',\",\n                \"        Bar='string'\",\n                '    )',\n                '  :type Foo: string',\n                '  :param Foo: Documents Foo',\n                '  :type Bar: string',\n                '  :param Bar: Documents Bar',\n                '  :rtype: :py:class:`myservice.Sample`',\n                '  :returns: Sample resource',\n            ]\n        )\n\n    def test_returns_list_of_resource(self):\n        resource_action = self.service_resource_model.actions[1]\n        document_model_driven_resource_method(\n            self.doc_structure,\n            'foo',\n            self.operation_model,\n            event_emitter=self.event_emitter,\n            method_description='This describes the foo method.',\n            example_prefix='samples = myservice.foo',\n            resource_action_model=resource_action,\n        )\n        self.assert_contains_lines_in_order(\n            [\n                '.. py:method:: foo(**kwargs)',\n                '  This describes the foo method.',\n                '  **Request Syntax**',\n                '  ::',\n                '    samples = myservice.foo(',\n                \"        Foo='string',\",\n                \"        Bar='string'\",\n                '    )',\n                '  :type Foo: string',\n                '  :param Foo: Documents Foo',\n                '  :type Bar: string',\n                '  :param Bar: Documents Bar',\n                '  :rtype: list(:py:class:`myservice.Sample`)',\n                '  :returns: A list of Sample resource',\n            ]\n        )\n\n    def test_include_input(self):\n        include_params = [\n            DocumentedShape(\n                name='Biz', type_name='string', documentation='biz docs'\n            )\n        ]\n        document_model_driven_resource_method(\n            self.doc_structure,\n            'foo',\n            self.operation_model,\n            event_emitter=self.event_emitter,\n            method_description='This describes the foo method.',\n            example_prefix='response = myservice.foo',\n            include_input=include_params,\n            resource_action_model=self.service_resource_model.actions[0],\n        )\n        self.assert_contains_lines_in_order(\n            [\n                '.. py:method:: foo(**kwargs)',\n                '  This describes the foo method.',\n                '  **Request Syntax**',\n                '  ::',\n                '    response = myservice.foo(',\n                \"        Foo='string',\",\n                \"        Bar='string',\",\n                \"        Biz='string'\",\n                '    )',\n                '  :type Foo: string',\n                '  :param Foo: Documents Foo',\n                '  :type Bar: string',\n                '  :param Bar: Documents Bar',\n                '  :type Biz: string',\n                '  :param Biz: biz docs',\n                '  :rtype: dict',\n                '  :returns: ',\n                '    **Response Syntax**',\n                '    ::',\n                '      {',\n                \"          'Foo': 'string',\",\n                \"          'Bar': 'string'\",\n                '      }',\n                '    **Response Structure**',\n                '    - *(dict) --* ',\n                '      - **Foo** *(string) --* Documents Foo',\n                '      - **Bar** *(string) --* Documents Bar',\n            ]\n        )\n\n    def test_include_output(self):\n        include_params = [\n            DocumentedShape(\n                name='Biz', type_name='string', documentation='biz docs'\n            )\n        ]\n        document_model_driven_resource_method(\n            self.doc_structure,\n            'foo',\n            self.operation_model,\n            event_emitter=self.event_emitter,\n            method_description='This describes the foo method.',\n            example_prefix='response = myservice.foo',\n            include_output=include_params,\n            resource_action_model=self.service_resource_model.actions[0],\n        )\n        self.assert_contains_lines_in_order(\n            [\n                '.. py:method:: foo(**kwargs)',\n                '  This describes the foo method.',\n                '  **Request Syntax**',\n                '  ::',\n                '    response = myservice.foo(',\n                \"        Foo='string',\",\n                \"        Bar='string'\",\n                '    )',\n                '  :type Foo: string',\n                '  :param Foo: Documents Foo',\n                '  :type Bar: string',\n                '  :param Bar: Documents Bar',\n                '  :rtype: dict',\n                '  :returns: ',\n                '    **Response Syntax**',\n                '    ::',\n                '      {',\n                \"          'Foo': 'string',\",\n                \"          'Bar': 'string',\",\n                \"          'Biz': 'string'\",\n                '      }',\n                '    **Response Structure**',\n                '    - *(dict) --* ',\n                '      - **Foo** *(string) --* Documents Foo',\n                '      - **Bar** *(string) --* Documents Bar',\n                '      - **Biz** *(string) --* biz docs',\n            ]\n        )\n\n    def test_exclude_input(self):\n        document_model_driven_resource_method(\n            self.doc_structure,\n            'foo',\n            self.operation_model,\n            event_emitter=self.event_emitter,\n            method_description='This describes the foo method.',\n            example_prefix='response = myservice.foo',\n            exclude_input=['Bar'],\n            resource_action_model=self.service_resource_model.actions[0],\n        )\n        self.assert_contains_lines_in_order(\n            [\n                '.. py:method:: foo(**kwargs)',\n                '  This describes the foo method.',\n                '  **Request Syntax**',\n                '  ::',\n                '    response = myservice.foo(',\n                \"        Foo='string',\",\n                '    )',\n                '  :type Foo: string',\n                '  :param Foo: Documents Foo',\n                '  :rtype: dict',\n                '  :returns: ',\n                '    **Response Syntax**',\n                '    ::',\n                '      {',\n                \"          'Foo': 'string',\",\n                \"          'Bar': 'string'\",\n                '      }',\n                '    **Response Structure**',\n                '    - *(dict) --* ',\n                '      - **Foo** *(string) --* Documents Foo',\n                '      - **Bar** *(string) --* Documents Bar',\n            ]\n        )\n        self.assert_not_contains_lines(\n            [':param Bar: string', 'Bar=\\'string\\'']\n        )\n\n    def test_exclude_output(self):\n        document_model_driven_resource_method(\n            self.doc_structure,\n            'foo',\n            self.operation_model,\n            event_emitter=self.event_emitter,\n            method_description='This describes the foo method.',\n            example_prefix='response = myservice.foo',\n            exclude_output=['Bar'],\n            resource_action_model=self.service_resource_model.actions[0],\n        )\n        self.assert_contains_lines_in_order(\n            [\n                '.. py:method:: foo(**kwargs)',\n                '  This describes the foo method.',\n                '  **Request Syntax**',\n                '  ::',\n                '    response = myservice.foo(',\n                \"        Foo='string',\",\n                \"        Bar='string'\",\n                '    )',\n                '  :type Foo: string',\n                '  :param Foo: Documents Foo',\n                '  :type Bar: string',\n                '  :param Bar: Documents Bar',\n                '  :rtype: dict',\n                '  :returns: ',\n                '    **Response Syntax**',\n                '    ::',\n                '      {',\n                \"          'Foo': 'string'\",\n                '      }',\n                '    **Response Structure**',\n                '    - *(dict) --* ',\n                '      - **Foo** *(string) --* Documents Foo',\n            ]\n        )\n        self.assert_not_contains_lines(\n            [\n                '\\'Bar\\': \\'string\\'',\n                '- **Bar** *(string) --*',\n            ]\n        )\n", "tests/unit/docs/test_subresource.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom boto3.docs.subresource import SubResourceDocumenter\nfrom tests.unit.docs import BaseDocsTest\n\n\nclass TestSubResourceDocumenter(BaseDocsTest):\n    def test_document_sub_resources(self):\n        sub_resource_documentor = SubResourceDocumenter(\n            self.resource, self.root_services_path\n        )\n        sub_resource_documentor.document_sub_resources(self.doc_structure)\n        self.assert_contains_lines_in_order(\n            [\n                '-------------\\nSub-resources\\n-------------',\n                'Sub-resources are methods that create a new instance of a',\n                ' child resource. This resource\\'s identifiers get passed',\n                ' along to the child.',\n                'For more information about sub-resources refer to the ',\n            ]\n        )\n        self.assert_contains_lines_in_order(\n            [\n                'Sample',\n                '.. py:method:: MyService.ServiceResource.Sample(name)',\n                '  Creates a Sample resource.::',\n                \"    sample = myservice.Sample('name')\",\n                '  :type name: string',\n                \"  :param name: The Sample's name identifier.\",\n                '  :rtype: :py:class:`MyService.Sample`',\n                '  :returns: A Sample resource',\n            ],\n            self.get_nested_service_contents(\n                'myservice', 'service-resource', 'Sample'\n            ),\n        )\n", "tests/unit/docs/test_resource.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom boto3.docs.resource import ResourceDocumenter, ServiceResourceDocumenter\nfrom tests.unit.docs import BaseDocsTest\n\n\nclass TestResourceDocumenter(BaseDocsTest):\n    def test_document_resource(self):\n        resource = self.resource.Sample('mysample')\n        resource_documenter = ResourceDocumenter(\n            resource, self.botocore_session, self.root_services_path\n        )\n        resource_documenter.document_resource(self.doc_structure)\n        self.assert_contains_lines_in_order(\n            [\n                '======',\n                'Sample',\n                '======',\n                'Before using anything on this page, please refer to the resources ',\n                ':doc:`user guide <../../../../guide/resources>` for the most recent ',\n                'guidance on using resources.',\n                '.. py:class:: MyService.Sample(name)',\n                '  A resource representing an AWS MyService Sample::',\n                '    import boto3',\n                \"    myservice = boto3.resource('myservice')\",\n                \"    sample = myservice.Sample('name')\",\n                'Identifiers',\n                \"These are the resource's available identifiers:\",\n                '.. toctree::',\n                '  :maxdepth: 1',\n                '  :titlesonly:',\n                '  name',\n                'Attributes',\n                \"These are the resource's available attributes:\",\n                '.. toctree::',\n                '  :maxdepth: 1',\n                '  :titlesonly:',\n                '  bar',\n                '  foo',\n                'Actions',\n                \"These are the resource's available actions:\",\n                '.. toctree::',\n                '  :maxdepth: 1',\n                '  :titlesonly:',\n                '  load',\n                '  operate',\n                '  reload',\n                'Waiters',\n                \"These are the resource's available waiters:\",\n                '.. toctree::',\n                '  :maxdepth: 1',\n                '  :titlesonly:',\n                '  wait_until_complete',\n            ]\n        )\n        self.assert_contains_lines_in_order(\n            [\n                'name',\n                '.. py:attribute:: MyService.Sample.name',\n            ],\n            self.get_nested_service_contents('myservice', 'sample', 'name'),\n        )\n        self.assert_contains_lines_in_order(\n            [\n                'bar',\n                '.. py:attribute:: MyService.Sample.bar',\n                '  - *(string) --* Documents Bar',\n            ],\n            self.get_nested_service_contents('myservice', 'sample', 'bar'),\n        )\n        self.assert_contains_lines_in_order(\n            [\n                'load',\n                '.. py:method:: MyService.Sample.load()',\n            ],\n            self.get_nested_service_contents('myservice', 'sample', 'load'),\n        )\n        self.assert_contains_lines_in_order(\n            [\n                'wait_until_complete',\n                '.. py:method:: MyService.Sample.wait_until_complete(**kwargs)',\n            ],\n            self.get_nested_service_contents(\n                'myservice', 'sample', 'wait_until_complete'\n            ),\n        )\n\n\nclass TestServiceResourceDocumenter(BaseDocsTest):\n    def test_document_resource(self):\n        resource_documenter = ServiceResourceDocumenter(\n            self.resource, self.botocore_session, self.root_services_path\n        )\n        resource_documenter.document_resource(self.doc_structure)\n        self.assert_contains_lines_in_order(\n            [\n                '================',\n                'Service Resource',\n                '================',\n                'Before using anything on this page, please refer to the resources ',\n                ':doc:`user guide <../../../../guide/resources>` for the most recent ',\n                'guidance on using resources.',\n                '.. py:class:: MyService.ServiceResource()',\n                '  A resource representing AWS MyService::',\n                '    import boto3',\n                \"    myservice = boto3.resource('myservice')\",\n                'Actions',\n                \"These are the resource's available actions:\",\n                '.. toctree::',\n                '  :maxdepth: 1',\n                '  :titlesonly:',\n                '  sample_operation',\n                'Sub-resources',\n                \"These are the resource's available sub-resources:\",\n                '.. toctree::',\n                '  :maxdepth: 1',\n                '  :titlesonly:',\n                '  Sample',\n                'Collections',\n                \"These are the resource's available collections:\",\n                '.. toctree::',\n                '  :maxdepth: 1',\n                '  :titlesonly:',\n                '  samples',\n            ]\n        )\n        self.assert_contains_lines_in_order(\n            [\n                'sample_operation',\n                '.. py:method:: MyService.ServiceResource.sample_operation(**kwargs)',\n            ],\n            self.get_nested_service_contents(\n                'myservice', 'service-resource', 'sample_operation'\n            ),\n        )\n        self.assert_contains_lines_in_order(\n            [\n                'Sample',\n                '.. py:method:: MyService.ServiceResource.Sample(name)',\n            ],\n            self.get_nested_service_contents(\n                'myservice', 'service-resource', 'Sample'\n            ),\n        )\n        self.assert_contains_lines_in_order(\n            [\n                'samples',\n                '.. py:attribute:: MyService.ServiceResource.samples',\n                '  .. py:method:: all()',\n                '  .. py:method:: filter(**kwargs)',\n                '  .. py:method:: limit(**kwargs)',\n                '  .. py:method:: page_size(**kwargs)',\n            ],\n            self.get_nested_service_contents(\n                'myservice', 'service-resource', 'samples'\n            ),\n        )\n", "tests/unit/docs/test_utils.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom boto3.docs.utils import get_resource_ignore_params\nfrom boto3.resources.model import Parameter\nfrom tests import unittest\n\n\nclass TestGetResourceIgnoreParams(unittest.TestCase):\n    def test_target_is_single_resource(self):\n        param = Parameter('InstanceId', 'response')\n        ignore_params = get_resource_ignore_params([param])\n        assert ignore_params == ['InstanceId']\n\n    def test_target_is_multiple_resources(self):\n        param = Parameter('InstanceIds[]', 'response')\n        ignore_params = get_resource_ignore_params([param])\n        assert ignore_params == ['InstanceIds']\n\n    def test_target_is_element_of_multiple_resources(self):\n        param = Parameter('InstanceIds[0]', 'response')\n        ignore_params = get_resource_ignore_params([param])\n        assert ignore_params == ['InstanceIds']\n\n    def test_target_is_nested_param(self):\n        param = Parameter('Filters[0].Name', 'response')\n        ignore_params = get_resource_ignore_params([param])\n        assert ignore_params == ['Filters']\n\n        param = Parameter('Filters[0].Values[0]', 'response')\n        ignore_params = get_resource_ignore_params([param])\n        assert ignore_params == ['Filters']\n", "tests/unit/s3/test_inject.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the 'License'). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the 'license' file accompanying this file. This file is\n# distributed on an 'AS IS' BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport io\n\nimport pytest\nfrom botocore.exceptions import ClientError\n\nfrom boto3.s3 import inject\nfrom tests import mock, unittest\n\n\nclass TestInjectTransferMethods(unittest.TestCase):\n    def test_inject_upload_download_file_to_client(self):\n        class_attributes = {}\n        inject.inject_s3_transfer_methods(class_attributes=class_attributes)\n        assert 'upload_file' in class_attributes\n        assert 'download_file' in class_attributes\n\n    def test_upload_file_proxies_to_transfer_object(self):\n        with mock.patch('boto3.s3.inject.S3Transfer') as transfer:\n            inject.upload_file(\n                mock.sentinel.CLIENT,\n                Filename='filename',\n                Bucket='bucket',\n                Key='key',\n            )\n            transfer_in_context_manager = (\n                transfer.return_value.__enter__.return_value\n            )\n            transfer_in_context_manager.upload_file.assert_called_with(\n                filename='filename',\n                bucket='bucket',\n                key='key',\n                extra_args=None,\n                callback=None,\n            )\n\n    def test_download_file_proxies_to_transfer_object(self):\n        with mock.patch('boto3.s3.inject.S3Transfer') as transfer:\n            inject.download_file(\n                mock.sentinel.CLIENT,\n                Bucket='bucket',\n                Key='key',\n                Filename='filename',\n            )\n            transfer_in_context_manager = (\n                transfer.return_value.__enter__.return_value\n            )\n            transfer_in_context_manager.download_file.assert_called_with(\n                bucket='bucket',\n                key='key',\n                filename='filename',\n                extra_args=None,\n                callback=None,\n            )\n\n\nclass TestBucketLoad(unittest.TestCase):\n    def setUp(self):\n        self.client = mock.Mock()\n        self.resource = mock.Mock()\n        self.resource.meta.client = self.client\n\n    def test_bucket_load_finds_bucket(self):\n        self.resource.name = 'MyBucket'\n        self.client.list_buckets.return_value = {\n            'Buckets': [\n                {'Name': 'NotMyBucket', 'CreationDate': 1},\n                {'Name': self.resource.name, 'CreationDate': 2},\n            ],\n        }\n\n        inject.bucket_load(self.resource)\n        assert self.resource.meta.data == {\n            'Name': self.resource.name,\n            'CreationDate': 2,\n        }\n\n    def test_bucket_load_doesnt_find_bucket(self):\n        self.resource.name = 'MyBucket'\n        self.client.list_buckets.return_value = {\n            'Buckets': [\n                {'Name': 'NotMyBucket', 'CreationDate': 1},\n                {'Name': 'NotMine2', 'CreationDate': 2},\n            ],\n        }\n        inject.bucket_load(self.resource)\n        assert self.resource.meta.data == {}\n\n    def test_bucket_load_encounters_access_exception(self):\n        self.client.list_buckets.side_effect = ClientError(\n            {'Error': {'Code': 'AccessDenied', 'Message': 'Access Denied'}},\n            'ListBuckets',\n        )\n        inject.bucket_load(self.resource)\n        assert self.resource.meta.data == {}\n\n    def test_bucket_load_encounters_other_exception(self):\n        self.client.list_buckets.side_effect = ClientError(\n            {\n                'Error': {\n                    'Code': 'ExpiredToken',\n                    'Message': 'The provided token has expired.',\n                }\n            },\n            'ListBuckets',\n        )\n        with pytest.raises(ClientError):\n            inject.bucket_load(self.resource)\n\n\nclass TestBucketTransferMethods(unittest.TestCase):\n    def setUp(self):\n        self.bucket = mock.Mock(name='my_bucket')\n        self.copy_source = {'Bucket': 'foo', 'Key': 'bar'}\n\n    def test_upload_file_proxies_to_meta_client(self):\n        inject.bucket_upload_file(self.bucket, Filename='foo', Key='key')\n        self.bucket.meta.client.upload_file.assert_called_with(\n            Filename='foo',\n            Bucket=self.bucket.name,\n            Key='key',\n            ExtraArgs=None,\n            Callback=None,\n            Config=None,\n        )\n\n    def test_download_file_proxies_to_meta_client(self):\n        inject.bucket_download_file(self.bucket, Key='key', Filename='foo')\n        self.bucket.meta.client.download_file.assert_called_with(\n            Bucket=self.bucket.name,\n            Key='key',\n            Filename='foo',\n            ExtraArgs=None,\n            Callback=None,\n            Config=None,\n        )\n\n    def test_copy(self):\n        inject.bucket_copy(self.bucket, self.copy_source, Key='key')\n        self.bucket.meta.client.copy.assert_called_with(\n            CopySource=self.copy_source,\n            Bucket=self.bucket.name,\n            Key='key',\n            ExtraArgs=None,\n            Callback=None,\n            SourceClient=None,\n            Config=None,\n        )\n\n    def test_upload_fileobj(self):\n        fileobj = io.BytesIO(b'foo')\n        inject.bucket_upload_fileobj(self.bucket, Key='key', Fileobj=fileobj)\n        self.bucket.meta.client.upload_fileobj.assert_called_with(\n            Bucket=self.bucket.name,\n            Fileobj=fileobj,\n            Key='key',\n            ExtraArgs=None,\n            Callback=None,\n            Config=None,\n        )\n\n    def test_download_fileobj(self):\n        obj = io.BytesIO()\n        inject.bucket_download_fileobj(self.bucket, Key='key', Fileobj=obj)\n        self.bucket.meta.client.download_fileobj.assert_called_with(\n            Bucket=self.bucket.name,\n            Key='key',\n            Fileobj=obj,\n            ExtraArgs=None,\n            Callback=None,\n            Config=None,\n        )\n\n\nclass TestObjectTransferMethods(unittest.TestCase):\n    def setUp(self):\n        self.obj = mock.Mock(bucket_name='my_bucket', key='my_key')\n        self.copy_source = {'Bucket': 'foo', 'Key': 'bar'}\n\n    def test_upload_file_proxies_to_meta_client(self):\n        inject.object_upload_file(self.obj, Filename='foo')\n        self.obj.meta.client.upload_file.assert_called_with(\n            Filename='foo',\n            Bucket=self.obj.bucket_name,\n            Key=self.obj.key,\n            ExtraArgs=None,\n            Callback=None,\n            Config=None,\n        )\n\n    def test_download_file_proxies_to_meta_client(self):\n        inject.object_download_file(self.obj, Filename='foo')\n        self.obj.meta.client.download_file.assert_called_with(\n            Bucket=self.obj.bucket_name,\n            Key=self.obj.key,\n            Filename='foo',\n            ExtraArgs=None,\n            Callback=None,\n            Config=None,\n        )\n\n    def test_copy(self):\n        inject.object_copy(self.obj, self.copy_source)\n        self.obj.meta.client.copy.assert_called_with(\n            CopySource=self.copy_source,\n            Bucket=self.obj.bucket_name,\n            Key=self.obj.key,\n            ExtraArgs=None,\n            Callback=None,\n            SourceClient=None,\n            Config=None,\n        )\n\n    def test_upload_fileobj(self):\n        fileobj = io.BytesIO(b'foo')\n        inject.object_upload_fileobj(self.obj, Fileobj=fileobj)\n        self.obj.meta.client.upload_fileobj.assert_called_with(\n            Bucket=self.obj.bucket_name,\n            Fileobj=fileobj,\n            Key=self.obj.key,\n            ExtraArgs=None,\n            Callback=None,\n            Config=None,\n        )\n\n    def test_download_fileobj(self):\n        fileobj = io.BytesIO()\n        inject.object_download_fileobj(self.obj, Fileobj=fileobj)\n        self.obj.meta.client.download_fileobj.assert_called_with(\n            Bucket=self.obj.bucket_name,\n            Key=self.obj.key,\n            Fileobj=fileobj,\n            ExtraArgs=None,\n            Callback=None,\n            Config=None,\n        )\n\n\nclass TestObejctSummaryLoad(unittest.TestCase):\n    def setUp(self):\n        self.client = mock.Mock()\n        self.resource = mock.Mock()\n        self.resource.meta.client = self.client\n        self.head_object_response = {'ContentLength': 5, 'ETag': 'my-etag'}\n        self.client.head_object.return_value = self.head_object_response\n\n    def test_object_summary_load(self):\n        inject.object_summary_load(self.resource)\n        assert self.resource.meta.data == {'Size': 5, 'ETag': 'my-etag'}\n\n    def test_can_handle_missing_content_length(self):\n        self.head_object_response.pop('ContentLength')\n        inject.object_summary_load(self.resource)\n        assert self.resource.meta.data == {'ETag': 'my-etag'}\n", "tests/unit/s3/test_transfer.py": "# Copyright 2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the 'License'). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n# https://aws.amazon.com/apache2.0/\n#\n# or in the 'license' file accompanying this file. This file is\n# distributed on an 'AS IS' BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport copy\nimport pathlib\nfrom tempfile import NamedTemporaryFile\n\nimport pytest\nfrom botocore.credentials import Credentials\nfrom s3transfer.futures import NonThreadedExecutor\nfrom s3transfer.manager import TransferManager\n\nfrom boto3.exceptions import RetriesExceededError, S3UploadFailedError\nfrom boto3.s3.transfer import (\n    KB,\n    MB,\n    ClientError,\n    OSUtils,\n    ProgressCallbackInvoker,\n    S3Transfer,\n    S3TransferRetriesExceededError,\n    TransferConfig,\n    create_transfer_manager,\n)\nfrom tests import mock, unittest\n\n\ndef create_mock_client(region_name='us-west-2'):\n    client = mock.Mock()\n    client.meta.region_name = region_name\n    client._get_credentials.return_value = Credentials(\n        'access', 'secret', 'token'\n    )\n    return client\n\n\nclass TestCreateTransferManager(unittest.TestCase):\n    def test_create_transfer_manager(self):\n        client = create_mock_client()\n        config = TransferConfig(preferred_transfer_client=\"classic\")\n        osutil = OSUtils()\n        with mock.patch('boto3.s3.transfer.TransferManager') as manager:\n            create_transfer_manager(client, config, osutil)\n            assert manager.call_args == mock.call(client, config, osutil, None)\n\n    def test_create_transfer_manager_with_no_threads(self):\n        client = create_mock_client()\n        config = TransferConfig(preferred_transfer_client=\"classic\")\n        config.use_threads = False\n        with mock.patch('boto3.s3.transfer.TransferManager') as manager:\n            create_transfer_manager(client, config)\n            assert manager.call_args == mock.call(\n                client, config, None, NonThreadedExecutor\n            )\n\n    def test_create_transfer_manager_with_default_config(self):\n        \"\"\"Ensure we still default to classic transfer manager when CRT\n        is disabled.\n        \"\"\"\n        with mock.patch('boto3.s3.transfer.HAS_CRT', False):\n            client = create_mock_client()\n            config = TransferConfig()\n            assert config.preferred_transfer_client == \"auto\"\n            with mock.patch('boto3.s3.transfer.TransferManager') as manager:\n                create_transfer_manager(client, config)\n                assert manager.call_args == mock.call(\n                    client, config, None, None\n                )\n\n\nclass TestTransferConfig(unittest.TestCase):\n    def assert_value_of_actual_and_alias(\n        self, config, actual, alias, ref_value\n    ):\n        # Ensure that the name set in the underlying TransferConfig (i.e.\n        # the actual) is the correct value.\n        assert getattr(config, actual) == ref_value\n        # Ensure that backcompat name (i.e. the alias) is the correct value.\n        assert getattr(config, alias) == ref_value\n\n    def test_alias_max_concurreny(self):\n        ref_value = 10\n        config = TransferConfig(max_concurrency=ref_value)\n        self.assert_value_of_actual_and_alias(\n            config, 'max_request_concurrency', 'max_concurrency', ref_value\n        )\n\n        # Set a new value using the alias\n        new_value = 15\n        config.max_concurrency = new_value\n        # Make sure it sets the value for both the alias and the actual\n        # value that will be used in the TransferManager\n        self.assert_value_of_actual_and_alias(\n            config, 'max_request_concurrency', 'max_concurrency', new_value\n        )\n\n    def test_alias_max_io_queue(self):\n        ref_value = 10\n        config = TransferConfig(max_io_queue=ref_value)\n        self.assert_value_of_actual_and_alias(\n            config, 'max_io_queue_size', 'max_io_queue', ref_value\n        )\n\n        # Set a new value using the alias\n        new_value = 15\n        config.max_io_queue = new_value\n        # Make sure it sets the value for both the alias and the actual\n        # value that will be used in the TransferManager\n        self.assert_value_of_actual_and_alias(\n            config, 'max_io_queue_size', 'max_io_queue', new_value\n        )\n\n    def test_transferconfig_parameters(self):\n        config = TransferConfig(\n            multipart_threshold=8 * MB,\n            max_concurrency=10,\n            multipart_chunksize=8 * MB,\n            num_download_attempts=5,\n            max_io_queue=100,\n            io_chunksize=256 * KB,\n            use_threads=True,\n            max_bandwidth=1024 * KB,\n            preferred_transfer_client=\"classic\",\n        )\n        assert config.multipart_threshold == 8 * MB\n        assert config.multipart_chunksize == 8 * MB\n        assert config.max_request_concurrency == 10\n        assert config.num_download_attempts == 5\n        assert config.max_io_queue_size == 100\n        assert config.io_chunksize == 256 * KB\n        assert config.use_threads is True\n        assert config.max_bandwidth == 1024 * KB\n        assert config.preferred_transfer_client == \"classic\"\n\n    def test_transferconfig_copy(self):\n        config = TransferConfig(\n            multipart_threshold=8 * MB,\n            max_concurrency=10,\n            multipart_chunksize=8 * MB,\n            num_download_attempts=5,\n            max_io_queue=100,\n            io_chunksize=256 * KB,\n            use_threads=True,\n            max_bandwidth=1024 * KB,\n            preferred_transfer_client=\"classic\",\n        )\n        copied_config = copy.copy(config)\n\n        assert config is not copied_config\n        assert config.multipart_threshold == copied_config.multipart_threshold\n        assert config.multipart_chunksize == copied_config.multipart_chunksize\n        assert (\n            config.max_request_concurrency\n            == copied_config.max_request_concurrency\n        )\n        assert (\n            config.num_download_attempts == copied_config.num_download_attempts\n        )\n        assert config.max_io_queue_size == copied_config.max_io_queue_size\n        assert config.io_chunksize == copied_config.io_chunksize\n        assert config.use_threads == copied_config.use_threads\n        assert config.max_bandwidth == copied_config.max_bandwidth\n        assert (\n            config.preferred_transfer_client\n            == copied_config.preferred_transfer_client\n        )\n\n\nclass TestProgressCallbackInvoker(unittest.TestCase):\n    def test_on_progress(self):\n        callback = mock.Mock()\n        subscriber = ProgressCallbackInvoker(callback)\n        subscriber.on_progress(bytes_transferred=1)\n        callback.assert_called_with(1)\n\n\nclass TestS3Transfer(unittest.TestCase):\n    def setUp(self):\n        self.client = create_mock_client()\n        self.manager = mock.Mock(TransferManager(self.client))\n        self.transfer = S3Transfer(manager=self.manager)\n        self.callback = mock.Mock()\n        # Use NamedTempFile as source of a path string that is valid and\n        # realistic for the system the tests are run on. The file gets deleted\n        # immediately and will not actually exist while the tests are run.\n        with NamedTemporaryFile(\"w\") as tmp_file:\n            self.file_path_str = tmp_file.name\n\n    def assert_callback_wrapped_in_subscriber(self, call_args):\n        subscribers = call_args[0][4]\n        # Make sure only one subscriber was passed in.\n        assert len(subscribers) == 1\n        subscriber = subscribers[0]\n        # Make sure that the subscriber is of the correct type\n        assert isinstance(subscriber, ProgressCallbackInvoker)\n        # Make sure that the on_progress method() calls out to the wrapped\n        # callback by actually invoking it.\n        subscriber.on_progress(bytes_transferred=1)\n        self.callback.assert_called_with(1)\n\n    def test_upload_file(self):\n        extra_args = {'ACL': 'public-read'}\n        self.transfer.upload_file(\n            'smallfile', 'bucket', 'key', extra_args=extra_args\n        )\n        self.manager.upload.assert_called_with(\n            'smallfile', 'bucket', 'key', extra_args, None\n        )\n\n    def test_upload_file_via_path(self):\n        extra_args = {'ACL': 'public-read'}\n        self.transfer.upload_file(\n            pathlib.Path(self.file_path_str),\n            'bucket',\n            'key',\n            extra_args=extra_args,\n        )\n        self.manager.upload.assert_called_with(\n            self.file_path_str, 'bucket', 'key', extra_args, None\n        )\n\n    def test_upload_file_via_purepath(self):\n        extra_args = {'ACL': 'public-read'}\n        self.transfer.upload_file(\n            pathlib.PurePath(self.file_path_str),\n            'bucket',\n            'key',\n            extra_args=extra_args,\n        )\n        self.manager.upload.assert_called_with(\n            self.file_path_str, 'bucket', 'key', extra_args, None\n        )\n\n    def test_download_file(self):\n        extra_args = {\n            'SSECustomerKey': 'foo',\n            'SSECustomerAlgorithm': 'AES256',\n        }\n        self.transfer.download_file(\n            'bucket', 'key', self.file_path_str, extra_args=extra_args\n        )\n        self.manager.download.assert_called_with(\n            'bucket', 'key', self.file_path_str, extra_args, None\n        )\n\n    def test_download_file_via_path(self):\n        extra_args = {\n            'SSECustomerKey': 'foo',\n            'SSECustomerAlgorithm': 'AES256',\n        }\n        self.transfer.download_file(\n            'bucket',\n            'key',\n            pathlib.Path(self.file_path_str),\n            extra_args=extra_args,\n        )\n        self.manager.download.assert_called_with(\n            'bucket',\n            'key',\n            self.file_path_str,\n            extra_args,\n            None,\n        )\n\n    def test_upload_wraps_callback(self):\n        self.transfer.upload_file(\n            'smallfile', 'bucket', 'key', callback=self.callback\n        )\n        self.assert_callback_wrapped_in_subscriber(\n            self.manager.upload.call_args\n        )\n\n    def test_download_wraps_callback(self):\n        self.transfer.download_file(\n            'bucket', 'key', '/tmp/smallfile', callback=self.callback\n        )\n        self.assert_callback_wrapped_in_subscriber(\n            self.manager.download.call_args\n        )\n\n    def test_propogation_of_retry_error(self):\n        future = mock.Mock()\n        future.result.side_effect = S3TransferRetriesExceededError(Exception())\n        self.manager.download.return_value = future\n        with pytest.raises(RetriesExceededError):\n            self.transfer.download_file('bucket', 'key', '/tmp/smallfile')\n\n    def test_propogation_s3_upload_failed_error(self):\n        future = mock.Mock()\n        future.result.side_effect = ClientError({'Error': {}}, 'op_name')\n        self.manager.upload.return_value = future\n        with pytest.raises(S3UploadFailedError):\n            self.transfer.upload_file('smallfile', 'bucket', 'key')\n\n    def test_can_create_with_just_client(self):\n        transfer = S3Transfer(client=create_mock_client())\n        assert isinstance(transfer, S3Transfer)\n\n    def test_can_create_with_extra_configurations(self):\n        transfer = S3Transfer(\n            client=create_mock_client(),\n            config=TransferConfig(),\n            osutil=OSUtils(),\n        )\n        assert isinstance(transfer, S3Transfer)\n\n    def test_client_or_manager_is_required(self):\n        with pytest.raises(ValueError):\n            S3Transfer()\n\n    def test_client_and_manager_are_mutually_exclusive(self):\n        with pytest.raises(ValueError):\n            S3Transfer(self.client, manager=self.manager)\n\n    def test_config_and_manager_are_mutually_exclusive(self):\n        with pytest.raises(ValueError):\n            S3Transfer(config=mock.Mock(), manager=self.manager)\n\n    def test_osutil_and_manager_are_mutually_exclusive(self):\n        with pytest.raises(ValueError):\n            S3Transfer(osutil=mock.Mock(), manager=self.manager)\n\n    def test_upload_requires_string_filename(self):\n        transfer = S3Transfer(client=create_mock_client())\n        with pytest.raises(ValueError):\n            transfer.upload_file(filename=object(), bucket='foo', key='bar')\n\n    def test_download_requires_string_filename(self):\n        transfer = S3Transfer(client=create_mock_client())\n        with pytest.raises(ValueError):\n            transfer.download_file(bucket='foo', key='bar', filename=object())\n\n    def test_context_manager(self):\n        manager = mock.Mock()\n        manager.__exit__ = mock.Mock()\n        with S3Transfer(manager=manager):\n            pass\n        # The underlying transfer manager should have had its __exit__\n        # called as well.\n        assert manager.__exit__.call_args == mock.call(None, None, None)\n\n    def test_context_manager_with_errors(self):\n        manager = mock.Mock()\n        manager.__exit__ = mock.Mock()\n        raised_exception = ValueError()\n        with pytest.raises(type(raised_exception)):\n            with S3Transfer(manager=manager):\n                raise raised_exception\n        # The underlying transfer manager should have had its __exit__\n        # called as well and pass on the error as well.\n        assert manager.__exit__.call_args == mock.call(\n            type(raised_exception), raised_exception, mock.ANY\n        )\n", "tests/unit/s3/__init__.py": ""}