{"conftest.py": "import builtins\nimport sys\n\n\ndef pytest_configure():\n    add_future_flags()\n\n\ndef add_future_flags():  # pragma: no cover\n    if sys.version_info > (3, 10):\n        return\n\n    builtins.EncodingWarning = type('EncodingWarning', (Warning,), {})\n", "zipp/glob.py": "import os\nimport re\n\n\n_default_seps = os.sep + str(os.altsep) * bool(os.altsep)\n\n\nclass Translator:\n    \"\"\"\n    >>> Translator('xyz')\n    Traceback (most recent call last):\n    ...\n    AssertionError: Invalid separators\n\n    >>> Translator('')\n    Traceback (most recent call last):\n    ...\n    AssertionError: Invalid separators\n    \"\"\"\n\n    seps: str\n\n    def __init__(self, seps: str = _default_seps):\n        assert seps and set(seps) <= set(_default_seps), \"Invalid separators\"\n        self.seps = seps\n\n    def translate(self, pattern):\n        \"\"\"\n        Given a glob pattern, produce a regex that matches it.\n        \"\"\"\n        return self.extend(self.translate_core(pattern))\n\n    def extend(self, pattern):\n        r\"\"\"\n        Extend regex for pattern-wide concerns.\n\n        Apply '(?s:)' to create a non-matching group that\n        matches newlines (valid on Unix).\n\n        Append '\\Z' to imply fullmatch even when match is used.\n        \"\"\"\n        return rf'(?s:{pattern})\\Z'\n\n    def translate_core(self, pattern):\n        r\"\"\"\n        Given a glob pattern, produce a regex that matches it.\n\n        >>> t = Translator()\n        >>> t.translate_core('*.txt').replace('\\\\\\\\', '')\n        '[^/]*\\\\.txt'\n        >>> t.translate_core('a?txt')\n        'a[^/]txt'\n        >>> t.translate_core('**/*').replace('\\\\\\\\', '')\n        '.*/[^/][^/]*'\n        \"\"\"\n        self.restrict_rglob(pattern)\n        return ''.join(map(self.replace, separate(self.star_not_empty(pattern))))\n\n    def replace(self, match):\n        \"\"\"\n        Perform the replacements for a match from :func:`separate`.\n        \"\"\"\n        return match.group('set') or (\n            re.escape(match.group(0))\n            .replace('\\\\*\\\\*', r'.*')\n            .replace('\\\\*', rf'[^{re.escape(self.seps)}]*')\n            .replace('\\\\?', r'[^/]')\n        )\n\n    def restrict_rglob(self, pattern):\n        \"\"\"\n        Raise ValueError if ** appears in anything but a full path segment.\n\n        >>> Translator().translate('**foo')\n        Traceback (most recent call last):\n        ...\n        ValueError: ** must appear alone in a path segment\n        \"\"\"\n        seps_pattern = rf'[{re.escape(self.seps)}]+'\n        segments = re.split(seps_pattern, pattern)\n        if any('**' in segment and segment != '**' for segment in segments):\n            raise ValueError(\"** must appear alone in a path segment\")\n\n    def star_not_empty(self, pattern):\n        \"\"\"\n        Ensure that * will not match an empty segment.\n        \"\"\"\n\n        def handle_segment(match):\n            segment = match.group(0)\n            return '?*' if segment == '*' else segment\n\n        not_seps_pattern = rf'[^{re.escape(self.seps)}]+'\n        return re.sub(not_seps_pattern, handle_segment, pattern)\n\n\ndef separate(pattern):\n    \"\"\"\n    Separate out character sets to avoid translating their contents.\n\n    >>> [m.group(0) for m in separate('*.txt')]\n    ['*.txt']\n    >>> [m.group(0) for m in separate('a[?]txt')]\n    ['a', '[?]', 'txt']\n    \"\"\"\n    return re.finditer(r'([^\\[]+)|(?P<set>[\\[].*?[\\]])|([\\[][^\\]]*$)', pattern)\n", "zipp/__init__.py": "import io\nimport posixpath\nimport zipfile\nimport itertools\nimport contextlib\nimport pathlib\nimport re\nimport stat\nimport sys\n\nfrom .compat.py310 import text_encoding\nfrom .glob import Translator\n\n\n__all__ = ['Path']\n\n\ndef _parents(path):\n    \"\"\"\n    Given a path with elements separated by\n    posixpath.sep, generate all parents of that path.\n\n    >>> list(_parents('b/d'))\n    ['b']\n    >>> list(_parents('/b/d/'))\n    ['/b']\n    >>> list(_parents('b/d/f/'))\n    ['b/d', 'b']\n    >>> list(_parents('b'))\n    []\n    >>> list(_parents(''))\n    []\n    \"\"\"\n    return itertools.islice(_ancestry(path), 1, None)\n\n\ndef _ancestry(path):\n    \"\"\"\n    Given a path with elements separated by\n    posixpath.sep, generate all elements of that path\n\n    >>> list(_ancestry('b/d'))\n    ['b/d', 'b']\n    >>> list(_ancestry('/b/d/'))\n    ['/b/d', '/b']\n    >>> list(_ancestry('b/d/f/'))\n    ['b/d/f', 'b/d', 'b']\n    >>> list(_ancestry('b'))\n    ['b']\n    >>> list(_ancestry(''))\n    []\n    \"\"\"\n    path = path.rstrip(posixpath.sep)\n    while path and path != posixpath.sep:\n        yield path\n        path, tail = posixpath.split(path)\n\n\n_dedupe = dict.fromkeys\n\"\"\"Deduplicate an iterable in original order\"\"\"\n\n\ndef _difference(minuend, subtrahend):\n    \"\"\"\n    Return items in minuend not in subtrahend, retaining order\n    with O(1) lookup.\n    \"\"\"\n    return itertools.filterfalse(set(subtrahend).__contains__, minuend)\n\n\nclass InitializedState:\n    \"\"\"\n    Mix-in to save the initialization state for pickling.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        self.__args = args\n        self.__kwargs = kwargs\n        super().__init__(*args, **kwargs)\n\n    def __getstate__(self):\n        return self.__args, self.__kwargs\n\n    def __setstate__(self, state):\n        args, kwargs = state\n        super().__init__(*args, **kwargs)\n\n\nclass SanitizedNames:\n    \"\"\"\n    ZipFile mix-in to ensure names are sanitized.\n    \"\"\"\n\n    def namelist(self):\n        return list(map(self._sanitize, super().namelist()))\n\n    @staticmethod\n    def _sanitize(name):\n        r\"\"\"\n        Ensure a relative path with posix separators and no dot names.\n\n        Modeled after\n        https://github.com/python/cpython/blob/bcc1be39cb1d04ad9fc0bd1b9193d3972835a57c/Lib/zipfile/__init__.py#L1799-L1813\n        but provides consistent cross-platform behavior.\n\n        >>> san = SanitizedNames._sanitize\n        >>> san('/foo/bar')\n        'foo/bar'\n        >>> san('//foo.txt')\n        'foo.txt'\n        >>> san('foo/.././bar.txt')\n        'foo/bar.txt'\n        >>> san('foo../.bar.txt')\n        'foo../.bar.txt'\n        >>> san('\\\\foo\\\\bar.txt')\n        'foo/bar.txt'\n        >>> san('D:\\\\foo.txt')\n        'D/foo.txt'\n        >>> san('\\\\\\\\server\\\\share\\\\file.txt')\n        'server/share/file.txt'\n        >>> san('\\\\\\\\?\\\\GLOBALROOT\\\\Volume3')\n        '?/GLOBALROOT/Volume3'\n        >>> san('\\\\\\\\.\\\\PhysicalDrive1\\\\root')\n        'PhysicalDrive1/root'\n\n        Retain any trailing slash.\n        >>> san('abc/')\n        'abc/'\n\n        Raises a ValueError if the result is empty.\n        >>> san('../..')\n        Traceback (most recent call last):\n        ...\n        ValueError: Empty filename\n        \"\"\"\n\n        def allowed(part):\n            return part and part not in {'..', '.'}\n\n        # Remove the drive letter.\n        # Don't use ntpath.splitdrive, because that also strips UNC paths\n        bare = re.sub('^([A-Z]):', r'\\1', name, flags=re.IGNORECASE)\n        clean = bare.replace('\\\\', '/')\n        parts = clean.split('/')\n        joined = '/'.join(filter(allowed, parts))\n        if not joined:\n            raise ValueError(\"Empty filename\")\n        return joined + '/' * name.endswith('/')\n\n\nclass CompleteDirs(InitializedState, SanitizedNames, zipfile.ZipFile):\n    \"\"\"\n    A ZipFile subclass that ensures that implied directories\n    are always included in the namelist.\n\n    >>> list(CompleteDirs._implied_dirs(['foo/bar.txt', 'foo/bar/baz.txt']))\n    ['foo/', 'foo/bar/']\n    >>> list(CompleteDirs._implied_dirs(['foo/bar.txt', 'foo/bar/baz.txt', 'foo/bar/']))\n    ['foo/']\n    \"\"\"\n\n    @staticmethod\n    def _implied_dirs(names):\n        parents = itertools.chain.from_iterable(map(_parents, names))\n        as_dirs = (p + posixpath.sep for p in parents)\n        return _dedupe(_difference(as_dirs, names))\n\n    def namelist(self):\n        names = super().namelist()\n        return names + list(self._implied_dirs(names))\n\n    def _name_set(self):\n        return set(self.namelist())\n\n    def resolve_dir(self, name):\n        \"\"\"\n        If the name represents a directory, return that name\n        as a directory (with the trailing slash).\n        \"\"\"\n        names = self._name_set()\n        dirname = name + '/'\n        dir_match = name not in names and dirname in names\n        return dirname if dir_match else name\n\n    def getinfo(self, name):\n        \"\"\"\n        Supplement getinfo for implied dirs.\n        \"\"\"\n        try:\n            return super().getinfo(name)\n        except KeyError:\n            if not name.endswith('/') or name not in self._name_set():\n                raise\n            return zipfile.ZipInfo(filename=name)\n\n    @classmethod\n    def make(cls, source):\n        \"\"\"\n        Given a source (filename or zipfile), return an\n        appropriate CompleteDirs subclass.\n        \"\"\"\n        if isinstance(source, CompleteDirs):\n            return source\n\n        if not isinstance(source, zipfile.ZipFile):\n            return cls(source)\n\n        # Only allow for FastLookup when supplied zipfile is read-only\n        if 'r' not in source.mode:\n            cls = CompleteDirs\n\n        source.__class__ = cls\n        return source\n\n    @classmethod\n    def inject(cls, zf: zipfile.ZipFile) -> zipfile.ZipFile:\n        \"\"\"\n        Given a writable zip file zf, inject directory entries for\n        any directories implied by the presence of children.\n        \"\"\"\n        for name in cls._implied_dirs(zf.namelist()):\n            zf.writestr(name, b\"\")\n        return zf\n\n\nclass FastLookup(CompleteDirs):\n    \"\"\"\n    ZipFile subclass to ensure implicit\n    dirs exist and are resolved rapidly.\n    \"\"\"\n\n    def namelist(self):\n        with contextlib.suppress(AttributeError):\n            return self.__names\n        self.__names = super().namelist()\n        return self.__names\n\n    def _name_set(self):\n        with contextlib.suppress(AttributeError):\n            return self.__lookup\n        self.__lookup = super()._name_set()\n        return self.__lookup\n\n\ndef _extract_text_encoding(encoding=None, *args, **kwargs):\n    # compute stack level so that the caller of the caller sees any warning.\n    is_pypy = sys.implementation.name == 'pypy'\n    stack_level = 3 + is_pypy\n    return text_encoding(encoding, stack_level), args, kwargs\n\n\nclass Path:\n    \"\"\"\n    A :class:`importlib.resources.abc.Traversable` interface for zip files.\n\n    Implements many of the features users enjoy from\n    :class:`pathlib.Path`.\n\n    Consider a zip file with this structure::\n\n        .\n        \u251c\u2500\u2500 a.txt\n        \u2514\u2500\u2500 b\n            \u251c\u2500\u2500 c.txt\n            \u2514\u2500\u2500 d\n                \u2514\u2500\u2500 e.txt\n\n    >>> data = io.BytesIO()\n    >>> zf = zipfile.ZipFile(data, 'w')\n    >>> zf.writestr('a.txt', 'content of a')\n    >>> zf.writestr('b/c.txt', 'content of c')\n    >>> zf.writestr('b/d/e.txt', 'content of e')\n    >>> zf.filename = 'mem/abcde.zip'\n\n    Path accepts the zipfile object itself or a filename\n\n    >>> path = Path(zf)\n\n    From there, several path operations are available.\n\n    Directory iteration (including the zip file itself):\n\n    >>> a, b = path.iterdir()\n    >>> a\n    Path('mem/abcde.zip', 'a.txt')\n    >>> b\n    Path('mem/abcde.zip', 'b/')\n\n    name property:\n\n    >>> b.name\n    'b'\n\n    join with divide operator:\n\n    >>> c = b / 'c.txt'\n    >>> c\n    Path('mem/abcde.zip', 'b/c.txt')\n    >>> c.name\n    'c.txt'\n\n    Read text:\n\n    >>> c.read_text(encoding='utf-8')\n    'content of c'\n\n    existence:\n\n    >>> c.exists()\n    True\n    >>> (b / 'missing.txt').exists()\n    False\n\n    Coercion to string:\n\n    >>> import os\n    >>> str(c).replace(os.sep, posixpath.sep)\n    'mem/abcde.zip/b/c.txt'\n\n    At the root, ``name``, ``filename``, and ``parent``\n    resolve to the zipfile.\n\n    >>> str(path)\n    'mem/abcde.zip/'\n    >>> path.name\n    'abcde.zip'\n    >>> path.filename == pathlib.Path('mem/abcde.zip')\n    True\n    >>> str(path.parent)\n    'mem'\n\n    If the zipfile has no filename, such \ufeffattributes are not\n    valid and accessing them will raise an Exception.\n\n    >>> zf.filename = None\n    >>> path.name\n    Traceback (most recent call last):\n    ...\n    TypeError: ...\n\n    >>> path.filename\n    Traceback (most recent call last):\n    ...\n    TypeError: ...\n\n    >>> path.parent\n    Traceback (most recent call last):\n    ...\n    TypeError: ...\n\n    # workaround python/cpython#106763\n    >>> pass\n    \"\"\"\n\n    __repr = \"{self.__class__.__name__}({self.root.filename!r}, {self.at!r})\"\n\n    def __init__(self, root, at=\"\"):\n        \"\"\"\n        Construct a Path from a ZipFile or filename.\n\n        Note: When the source is an existing ZipFile object,\n        its type (__class__) will be mutated to a\n        specialized type. If the caller wishes to retain the\n        original type, the caller should either create a\n        separate ZipFile object or pass a filename.\n        \"\"\"\n        self.root = FastLookup.make(root)\n        self.at = at\n\n    def __eq__(self, other):\n        \"\"\"\n        >>> Path(zipfile.ZipFile(io.BytesIO(), 'w')) == 'foo'\n        False\n        \"\"\"\n        if self.__class__ is not other.__class__:\n            return NotImplemented\n        return (self.root, self.at) == (other.root, other.at)\n\n    def __hash__(self):\n        return hash((self.root, self.at))\n\n    def open(self, mode='r', *args, pwd=None, **kwargs):\n        \"\"\"\n        Open this entry as text or binary following the semantics\n        of ``pathlib.Path.open()`` by passing arguments through\n        to io.TextIOWrapper().\n        \"\"\"\n        if self.is_dir():\n            raise IsADirectoryError(self)\n        zip_mode = mode[0]\n        if not self.exists() and zip_mode == 'r':\n            raise FileNotFoundError(self)\n        stream = self.root.open(self.at, zip_mode, pwd=pwd)\n        if 'b' in mode:\n            if args or kwargs:\n                raise ValueError(\"encoding args invalid for binary operation\")\n            return stream\n        # Text mode:\n        encoding, args, kwargs = _extract_text_encoding(*args, **kwargs)\n        return io.TextIOWrapper(stream, encoding, *args, **kwargs)\n\n    def _base(self):\n        return pathlib.PurePosixPath(self.at or self.root.filename)\n\n    @property\n    def name(self):\n        return self._base().name\n\n    @property\n    def suffix(self):\n        return self._base().suffix\n\n    @property\n    def suffixes(self):\n        return self._base().suffixes\n\n    @property\n    def stem(self):\n        return self._base().stem\n\n    @property\n    def filename(self):\n        return pathlib.Path(self.root.filename).joinpath(self.at)\n\n    def read_text(self, *args, **kwargs):\n        encoding, args, kwargs = _extract_text_encoding(*args, **kwargs)\n        with self.open('r', encoding, *args, **kwargs) as strm:\n            return strm.read()\n\n    def read_bytes(self):\n        with self.open('rb') as strm:\n            return strm.read()\n\n    def _is_child(self, path):\n        return posixpath.dirname(path.at.rstrip(\"/\")) == self.at.rstrip(\"/\")\n\n    def _next(self, at):\n        return self.__class__(self.root, at)\n\n    def is_dir(self):\n        return not self.at or self.at.endswith(\"/\")\n\n    def is_file(self):\n        return self.exists() and not self.is_dir()\n\n    def exists(self):\n        return self.at in self.root._name_set()\n\n    def iterdir(self):\n        if not self.is_dir():\n            raise ValueError(\"Can't listdir a file\")\n        subs = map(self._next, self.root.namelist())\n        return filter(self._is_child, subs)\n\n    def match(self, path_pattern):\n        return pathlib.PurePosixPath(self.at).match(path_pattern)\n\n    def is_symlink(self):\n        \"\"\"\n        Return whether this path is a symlink.\n        \"\"\"\n        info = self.root.getinfo(self.at)\n        mode = info.external_attr >> 16\n        return stat.S_ISLNK(mode)\n\n    def glob(self, pattern):\n        if not pattern:\n            raise ValueError(f\"Unacceptable pattern: {pattern!r}\")\n\n        prefix = re.escape(self.at)\n        tr = Translator(seps='/')\n        matches = re.compile(prefix + tr.translate(pattern)).fullmatch\n        names = (data.filename for data in self.root.filelist)\n        return map(self._next, filter(matches, names))\n\n    def rglob(self, pattern):\n        return self.glob(f'**/{pattern}')\n\n    def relative_to(self, other, *extra):\n        return posixpath.relpath(str(self), str(other.joinpath(*extra)))\n\n    def __str__(self):\n        return posixpath.join(self.root.filename, self.at)\n\n    def __repr__(self):\n        return self.__repr.format(self=self)\n\n    def joinpath(self, *other):\n        next = posixpath.join(self.at, *other)\n        return self._next(self.root.resolve_dir(next))\n\n    __truediv__ = joinpath\n\n    @property\n    def parent(self):\n        if not self.at:\n            return self.filename.parent\n        parent_at = posixpath.dirname(self.at.rstrip('/'))\n        if parent_at:\n            parent_at += '/'\n        return self._next(parent_at)\n", "zipp/compat/py310.py": "import sys\nimport io\n\n\ndef _text_encoding(encoding, stacklevel=2, /):  # pragma: no cover\n    return encoding\n\n\ntext_encoding = (\n    io.text_encoding if sys.version_info > (3, 10) else _text_encoding  # type: ignore\n)\n", "zipp/compat/__init__.py": "", "docs/conf.py": "extensions = [\n    'sphinx.ext.autodoc',\n    'jaraco.packaging.sphinx',\n]\n\nmaster_doc = \"index\"\nhtml_theme = \"furo\"\n\n# Link dates and other references in the changelog\nextensions += ['rst.linker']\nlink_files = {\n    '../NEWS.rst': dict(\n        using=dict(GH='https://github.com'),\n        replace=[\n            dict(\n                pattern=r'(Issue #|\\B#)(?P<issue>\\d+)',\n                url='{package_url}/issues/{issue}',\n            ),\n            dict(\n                pattern=r'(?m:^((?P<scm_version>v?\\d+(\\.\\d+){1,2}))\\n[-=]+\\n)',\n                with_scm='{text}\\n{rev[timestamp]:%d %b %Y}\\n',\n            ),\n            dict(\n                pattern=r'PEP[- ](?P<pep_number>\\d+)',\n                url='https://peps.python.org/pep-{pep_number:0>4}/',\n            ),\n            dict(\n                pattern=r'(bpo-)(?P<bpo>\\d+)',\n                url='http://bugs.python.org/issue{bpo}',\n            ),\n            dict(\n                pattern=r'(gh-)(?P<python_gh>\\d+)',\n                url='http://bugs.python.org/issue{python_gh}',\n            ),\n        ],\n    )\n}\n\n# Be strict about any broken references\nnitpicky = True\n\n# Include Python intersphinx mapping to prevent failures\n# jaraco/skeleton#51\nextensions += ['sphinx.ext.intersphinx']\nintersphinx_mapping = {\n    'python': ('https://docs.python.org/3', None),\n}\n\n# Preserve authored syntax for defaults\nautodoc_preserve_defaults = True\n\nextensions += ['jaraco.tidelift']\n", "tests/test_path.py": "import io\nimport itertools\nimport contextlib\nimport pathlib\nimport pickle\nimport stat\nimport sys\nimport unittest\nfrom .compat.overlay import zipfile\n\nfrom .compat.py39.os_helper import temp_dir, FakePath\n\nimport jaraco.itertools\nfrom jaraco.functools import compose\n\nfrom ._test_params import parameterize, Invoked\n\n\ndef _make_link(info: zipfile.ZipInfo):  # type: ignore[name-defined]\n    info.external_attr |= stat.S_IFLNK << 16\n\n\ndef build_alpharep_fixture():\n    \"\"\"\n    Create a zip file with this structure:\n\n    .\n    \u251c\u2500\u2500 a.txt\n    \u251c\u2500\u2500 n.txt (-> a.txt)\n    \u251c\u2500\u2500 b\n    \u2502   \u251c\u2500\u2500 c.txt\n    \u2502   \u251c\u2500\u2500 d\n    \u2502   \u2502   \u2514\u2500\u2500 e.txt\n    \u2502   \u2514\u2500\u2500 f.txt\n    \u251c\u2500\u2500 g\n    \u2502   \u2514\u2500\u2500 h\n    \u2502       \u2514\u2500\u2500 i.txt\n    \u2514\u2500\u2500 j\n        \u251c\u2500\u2500 k.bin\n        \u251c\u2500\u2500 l.baz\n        \u2514\u2500\u2500 m.bar\n\n    This fixture has the following key characteristics:\n\n    - a file at the root (a)\n    - a file two levels deep (b/d/e)\n    - multiple files in a directory (b/c, b/f)\n    - a directory containing only a directory (g/h)\n    - a directory with files of different extensions (j/klm)\n    - a symlink (n) pointing to (a)\n\n    \"alpha\" because it uses alphabet\n    \"rep\" because it's a representative example\n    \"\"\"\n    data = io.BytesIO()\n    zf = zipfile.ZipFile(data, \"w\")\n    zf.writestr(\"a.txt\", b\"content of a\")\n    zf.writestr(\"b/c.txt\", b\"content of c\")\n    zf.writestr(\"b/d/e.txt\", b\"content of e\")\n    zf.writestr(\"b/f.txt\", b\"content of f\")\n    zf.writestr(\"g/h/i.txt\", b\"content of i\")\n    zf.writestr(\"j/k.bin\", b\"content of k\")\n    zf.writestr(\"j/l.baz\", b\"content of l\")\n    zf.writestr(\"j/m.bar\", b\"content of m\")\n    zf.writestr(\"n.txt\", b\"a.txt\")\n    _make_link(zf.infolist()[-1])\n\n    zf.filename = \"alpharep.zip\"\n    return zf\n\n\nalpharep_generators = [\n    Invoked.wrap(build_alpharep_fixture),\n    Invoked.wrap(compose(zipfile._path.CompleteDirs.inject, build_alpharep_fixture)),\n]\n\npass_alpharep = parameterize(['alpharep'], alpharep_generators)\n\n\nclass TestPath(unittest.TestCase):\n    def setUp(self):\n        self.fixtures = contextlib.ExitStack()\n        self.addCleanup(self.fixtures.close)\n\n    def zipfile_ondisk(self, alpharep):\n        tmpdir = pathlib.Path(self.fixtures.enter_context(temp_dir()))\n        buffer = alpharep.fp\n        alpharep.close()\n        path = tmpdir / alpharep.filename\n        with path.open(\"wb\") as strm:\n            strm.write(buffer.getvalue())\n        return path\n\n    @pass_alpharep\n    def test_iterdir_and_types(self, alpharep):\n        root = zipfile.Path(alpharep)\n        assert root.is_dir()\n        a, n, b, g, j = root.iterdir()\n        assert a.is_file()\n        assert b.is_dir()\n        assert g.is_dir()\n        c, f, d = b.iterdir()\n        assert c.is_file() and f.is_file()\n        (e,) = d.iterdir()\n        assert e.is_file()\n        (h,) = g.iterdir()\n        (i,) = h.iterdir()\n        assert i.is_file()\n\n    @pass_alpharep\n    def test_is_file_missing(self, alpharep):\n        root = zipfile.Path(alpharep)\n        assert not root.joinpath('missing.txt').is_file()\n\n    @pass_alpharep\n    def test_iterdir_on_file(self, alpharep):\n        root = zipfile.Path(alpharep)\n        a, n, b, g, j = root.iterdir()\n        with self.assertRaises(ValueError):\n            a.iterdir()\n\n    @pass_alpharep\n    def test_subdir_is_dir(self, alpharep):\n        root = zipfile.Path(alpharep)\n        assert (root / 'b').is_dir()\n        assert (root / 'b/').is_dir()\n        assert (root / 'g').is_dir()\n        assert (root / 'g/').is_dir()\n\n    @pass_alpharep\n    def test_open(self, alpharep):\n        root = zipfile.Path(alpharep)\n        a, n, b, g, j = root.iterdir()\n        with a.open(encoding=\"utf-8\") as strm:\n            data = strm.read()\n        self.assertEqual(data, \"content of a\")\n        with a.open('r', \"utf-8\") as strm:  # not a kw, no gh-101144 TypeError\n            data = strm.read()\n        self.assertEqual(data, \"content of a\")\n\n    def test_open_encoding_utf16(self):\n        in_memory_file = io.BytesIO()\n        zf = zipfile.ZipFile(in_memory_file, \"w\")\n        zf.writestr(\"path/16.txt\", \"This was utf-16\".encode(\"utf-16\"))\n        zf.filename = \"test_open_utf16.zip\"\n        root = zipfile.Path(zf)\n        (path,) = root.iterdir()\n        u16 = path.joinpath(\"16.txt\")\n        with u16.open('r', \"utf-16\") as strm:\n            data = strm.read()\n        assert data == \"This was utf-16\"\n        with u16.open(encoding=\"utf-16\") as strm:\n            data = strm.read()\n        assert data == \"This was utf-16\"\n\n    def test_open_encoding_errors(self):\n        in_memory_file = io.BytesIO()\n        zf = zipfile.ZipFile(in_memory_file, \"w\")\n        zf.writestr(\"path/bad-utf8.bin\", b\"invalid utf-8: \\xff\\xff.\")\n        zf.filename = \"test_read_text_encoding_errors.zip\"\n        root = zipfile.Path(zf)\n        (path,) = root.iterdir()\n        u16 = path.joinpath(\"bad-utf8.bin\")\n\n        # encoding= as a positional argument for gh-101144.\n        data = u16.read_text(\"utf-8\", errors=\"ignore\")\n        assert data == \"invalid utf-8: .\"\n        with u16.open(\"r\", \"utf-8\", errors=\"surrogateescape\") as f:\n            assert f.read() == \"invalid utf-8: \\udcff\\udcff.\"\n\n        # encoding= both positional and keyword is an error; gh-101144.\n        with self.assertRaisesRegex(TypeError, \"encoding\"):\n            data = u16.read_text(\"utf-8\", encoding=\"utf-8\")\n\n        # both keyword arguments work.\n        with u16.open(\"r\", encoding=\"utf-8\", errors=\"strict\") as f:\n            # error during decoding with wrong codec.\n            with self.assertRaises(UnicodeDecodeError):\n                f.read()\n\n    @unittest.skipIf(\n        not getattr(sys.flags, 'warn_default_encoding', 0),\n        \"Requires warn_default_encoding\",\n    )\n    @pass_alpharep\n    def test_encoding_warnings(self, alpharep):\n        \"\"\"EncodingWarning must blame the read_text and open calls.\"\"\"\n        assert sys.flags.warn_default_encoding\n        root = zipfile.Path(alpharep)\n        with self.assertWarns(EncodingWarning) as wc:\n            root.joinpath(\"a.txt\").read_text()\n        assert __file__ == wc.filename\n        with self.assertWarns(EncodingWarning) as wc:\n            root.joinpath(\"a.txt\").open(\"r\").close()\n        assert __file__ == wc.filename\n\n    def test_open_write(self):\n        \"\"\"\n        If the zipfile is open for write, it should be possible to\n        write bytes or text to it.\n        \"\"\"\n        zf = zipfile.Path(zipfile.ZipFile(io.BytesIO(), mode='w'))\n        with zf.joinpath('file.bin').open('wb') as strm:\n            strm.write(b'binary contents')\n        with zf.joinpath('file.txt').open('w', encoding=\"utf-8\") as strm:\n            strm.write('text file')\n\n    @pass_alpharep\n    def test_open_extant_directory(self, alpharep):\n        \"\"\"\n        Attempting to open a directory raises IsADirectoryError.\n        \"\"\"\n        zf = zipfile.Path(alpharep)\n        with self.assertRaises(IsADirectoryError):\n            zf.joinpath('b').open()\n\n    @pass_alpharep\n    def test_open_binary_invalid_args(self, alpharep):\n        root = zipfile.Path(alpharep)\n        with self.assertRaises(ValueError):\n            root.joinpath('a.txt').open('rb', encoding='utf-8')\n        with self.assertRaises(ValueError):\n            root.joinpath('a.txt').open('rb', 'utf-8')\n\n    @pass_alpharep\n    def test_open_missing_directory(self, alpharep):\n        \"\"\"\n        Attempting to open a missing directory raises FileNotFoundError.\n        \"\"\"\n        zf = zipfile.Path(alpharep)\n        with self.assertRaises(FileNotFoundError):\n            zf.joinpath('z').open()\n\n    @pass_alpharep\n    def test_read(self, alpharep):\n        root = zipfile.Path(alpharep)\n        a, n, b, g, j = root.iterdir()\n        assert a.read_text(encoding=\"utf-8\") == \"content of a\"\n        # Also check positional encoding arg (gh-101144).\n        assert a.read_text(\"utf-8\") == \"content of a\"\n        assert a.read_bytes() == b\"content of a\"\n\n    @pass_alpharep\n    def test_joinpath(self, alpharep):\n        root = zipfile.Path(alpharep)\n        a = root.joinpath(\"a.txt\")\n        assert a.is_file()\n        e = root.joinpath(\"b\").joinpath(\"d\").joinpath(\"e.txt\")\n        assert e.read_text(encoding=\"utf-8\") == \"content of e\"\n\n    @pass_alpharep\n    def test_joinpath_multiple(self, alpharep):\n        root = zipfile.Path(alpharep)\n        e = root.joinpath(\"b\", \"d\", \"e.txt\")\n        assert e.read_text(encoding=\"utf-8\") == \"content of e\"\n\n    @pass_alpharep\n    def test_traverse_truediv(self, alpharep):\n        root = zipfile.Path(alpharep)\n        a = root / \"a.txt\"\n        assert a.is_file()\n        e = root / \"b\" / \"d\" / \"e.txt\"\n        assert e.read_text(encoding=\"utf-8\") == \"content of e\"\n\n    @pass_alpharep\n    def test_pathlike_construction(self, alpharep):\n        \"\"\"\n        zipfile.Path should be constructable from a path-like object\n        \"\"\"\n        zipfile_ondisk = self.zipfile_ondisk(alpharep)\n        pathlike = FakePath(str(zipfile_ondisk))\n        zipfile.Path(pathlike)\n\n    @pass_alpharep\n    def test_traverse_pathlike(self, alpharep):\n        root = zipfile.Path(alpharep)\n        root / FakePath(\"a\")\n\n    @pass_alpharep\n    def test_parent(self, alpharep):\n        root = zipfile.Path(alpharep)\n        assert (root / 'a').parent.at == ''\n        assert (root / 'a' / 'b').parent.at == 'a/'\n\n    @pass_alpharep\n    def test_dir_parent(self, alpharep):\n        root = zipfile.Path(alpharep)\n        assert (root / 'b').parent.at == ''\n        assert (root / 'b/').parent.at == ''\n\n    @pass_alpharep\n    def test_missing_dir_parent(self, alpharep):\n        root = zipfile.Path(alpharep)\n        assert (root / 'missing dir/').parent.at == ''\n\n    @pass_alpharep\n    def test_mutability(self, alpharep):\n        \"\"\"\n        If the underlying zipfile is changed, the Path object should\n        reflect that change.\n        \"\"\"\n        root = zipfile.Path(alpharep)\n        a, n, b, g, j = root.iterdir()\n        alpharep.writestr('foo.txt', 'foo')\n        alpharep.writestr('bar/baz.txt', 'baz')\n        assert any(child.name == 'foo.txt' for child in root.iterdir())\n        assert (root / 'foo.txt').read_text(encoding=\"utf-8\") == 'foo'\n        (baz,) = (root / 'bar').iterdir()\n        assert baz.read_text(encoding=\"utf-8\") == 'baz'\n\n    HUGE_ZIPFILE_NUM_ENTRIES = 2**13\n\n    def huge_zipfile(self):\n        \"\"\"Create a read-only zipfile with a huge number of entries entries.\"\"\"\n        strm = io.BytesIO()\n        zf = zipfile.ZipFile(strm, \"w\")\n        for entry in map(str, range(self.HUGE_ZIPFILE_NUM_ENTRIES)):\n            zf.writestr(entry, entry)\n        zf.mode = 'r'\n        return zf\n\n    def test_joinpath_constant_time(self):\n        \"\"\"\n        Ensure joinpath on items in zipfile is linear time.\n        \"\"\"\n        root = zipfile.Path(self.huge_zipfile())\n        entries = jaraco.itertools.Counter(root.iterdir())\n        for entry in entries:\n            entry.joinpath('suffix')\n        # Check the file iterated all items\n        assert entries.count == self.HUGE_ZIPFILE_NUM_ENTRIES\n\n    @pass_alpharep\n    def test_read_does_not_close(self, alpharep):\n        alpharep = self.zipfile_ondisk(alpharep)\n        with zipfile.ZipFile(alpharep) as file:\n            for rep in range(2):\n                zipfile.Path(file, 'a.txt').read_text(encoding=\"utf-8\")\n\n    @pass_alpharep\n    def test_subclass(self, alpharep):\n        class Subclass(zipfile.Path):\n            pass\n\n        root = Subclass(alpharep)\n        assert isinstance(root / 'b', Subclass)\n\n    @pass_alpharep\n    def test_filename(self, alpharep):\n        root = zipfile.Path(alpharep)\n        assert root.filename == pathlib.Path('alpharep.zip')\n\n    @pass_alpharep\n    def test_root_name(self, alpharep):\n        \"\"\"\n        The name of the root should be the name of the zipfile\n        \"\"\"\n        root = zipfile.Path(alpharep)\n        assert root.name == 'alpharep.zip' == root.filename.name\n\n    @pass_alpharep\n    def test_suffix(self, alpharep):\n        \"\"\"\n        The suffix of the root should be the suffix of the zipfile.\n        The suffix of each nested file is the final component's last suffix, if any.\n        Includes the leading period, just like pathlib.Path.\n        \"\"\"\n        root = zipfile.Path(alpharep)\n        assert root.suffix == '.zip' == root.filename.suffix\n\n        b = root / \"b.txt\"\n        assert b.suffix == \".txt\"\n\n        c = root / \"c\" / \"filename.tar.gz\"\n        assert c.suffix == \".gz\"\n\n        d = root / \"d\"\n        assert d.suffix == \"\"\n\n    @pass_alpharep\n    def test_suffixes(self, alpharep):\n        \"\"\"\n        The suffix of the root should be the suffix of the zipfile.\n        The suffix of each nested file is the final component's last suffix, if any.\n        Includes the leading period, just like pathlib.Path.\n        \"\"\"\n        root = zipfile.Path(alpharep)\n        assert root.suffixes == ['.zip'] == root.filename.suffixes\n\n        b = root / 'b.txt'\n        assert b.suffixes == ['.txt']\n\n        c = root / 'c' / 'filename.tar.gz'\n        assert c.suffixes == ['.tar', '.gz']\n\n        d = root / 'd'\n        assert d.suffixes == []\n\n        e = root / '.hgrc'\n        assert e.suffixes == []\n\n    @pass_alpharep\n    def test_suffix_no_filename(self, alpharep):\n        alpharep.filename = None\n        root = zipfile.Path(alpharep)\n        assert root.joinpath('example').suffix == \"\"\n        assert root.joinpath('example').suffixes == []\n\n    @pass_alpharep\n    def test_stem(self, alpharep):\n        \"\"\"\n        The final path component, without its suffix\n        \"\"\"\n        root = zipfile.Path(alpharep)\n        assert root.stem == 'alpharep' == root.filename.stem\n\n        b = root / \"b.txt\"\n        assert b.stem == \"b\"\n\n        c = root / \"c\" / \"filename.tar.gz\"\n        assert c.stem == \"filename.tar\"\n\n        d = root / \"d\"\n        assert d.stem == \"d\"\n\n        assert (root / \".gitignore\").stem == \".gitignore\"\n\n    @pass_alpharep\n    def test_root_parent(self, alpharep):\n        root = zipfile.Path(alpharep)\n        assert root.parent == pathlib.Path('.')\n        root.root.filename = 'foo/bar.zip'\n        assert root.parent == pathlib.Path('foo')\n\n    @pass_alpharep\n    def test_root_unnamed(self, alpharep):\n        \"\"\"\n        It is an error to attempt to get the name\n        or parent of an unnamed zipfile.\n        \"\"\"\n        alpharep.filename = None\n        root = zipfile.Path(alpharep)\n        with self.assertRaises(TypeError):\n            root.name\n        with self.assertRaises(TypeError):\n            root.parent\n\n        # .name and .parent should still work on subs\n        sub = root / \"b\"\n        assert sub.name == \"b\"\n        assert sub.parent\n\n    @pass_alpharep\n    def test_match_and_glob(self, alpharep):\n        root = zipfile.Path(alpharep)\n        assert not root.match(\"*.txt\")\n\n        assert list(root.glob(\"b/c.*\")) == [zipfile.Path(alpharep, \"b/c.txt\")]\n        assert list(root.glob(\"b/*.txt\")) == [\n            zipfile.Path(alpharep, \"b/c.txt\"),\n            zipfile.Path(alpharep, \"b/f.txt\"),\n        ]\n\n    @pass_alpharep\n    def test_glob_recursive(self, alpharep):\n        root = zipfile.Path(alpharep)\n        files = root.glob(\"**/*.txt\")\n        assert all(each.match(\"*.txt\") for each in files)\n\n        assert list(root.glob(\"**/*.txt\")) == list(root.rglob(\"*.txt\"))\n\n    @pass_alpharep\n    def test_glob_subdirs(self, alpharep):\n        root = zipfile.Path(alpharep)\n\n        assert list(root.glob(\"*/i.txt\")) == []\n        assert list(root.rglob(\"*/i.txt\")) == [zipfile.Path(alpharep, \"g/h/i.txt\")]\n\n    @pass_alpharep\n    def test_glob_does_not_overmatch_dot(self, alpharep):\n        root = zipfile.Path(alpharep)\n\n        assert list(root.glob(\"*.xt\")) == []\n\n    @pass_alpharep\n    def test_glob_single_char(self, alpharep):\n        root = zipfile.Path(alpharep)\n\n        assert list(root.glob(\"a?txt\")) == [zipfile.Path(alpharep, \"a.txt\")]\n        assert list(root.glob(\"a[.]txt\")) == [zipfile.Path(alpharep, \"a.txt\")]\n        assert list(root.glob(\"a[?]txt\")) == []\n\n    @pass_alpharep\n    def test_glob_chars(self, alpharep):\n        root = zipfile.Path(alpharep)\n\n        assert list(root.glob(\"j/?.b[ai][nz]\")) == [\n            zipfile.Path(alpharep, \"j/k.bin\"),\n            zipfile.Path(alpharep, \"j/l.baz\"),\n        ]\n\n    def test_glob_empty(self):\n        root = zipfile.Path(zipfile.ZipFile(io.BytesIO(), 'w'))\n        with self.assertRaises(ValueError):\n            root.glob('')\n\n    @pass_alpharep\n    def test_eq_hash(self, alpharep):\n        root = zipfile.Path(alpharep)\n        assert root == zipfile.Path(alpharep)\n\n        assert root != (root / \"a.txt\")\n        assert (root / \"a.txt\") == (root / \"a.txt\")\n\n        root = zipfile.Path(alpharep)\n        assert root in {root}\n\n    @pass_alpharep\n    def test_is_symlink(self, alpharep):\n        root = zipfile.Path(alpharep)\n        assert not root.joinpath('a.txt').is_symlink()\n        assert root.joinpath('n.txt').is_symlink()\n\n    @pass_alpharep\n    def test_relative_to(self, alpharep):\n        root = zipfile.Path(alpharep)\n        relative = root.joinpath(\"b\", \"c.txt\").relative_to(root / \"b\")\n        assert str(relative) == \"c.txt\"\n\n        relative = root.joinpath(\"b\", \"d\", \"e.txt\").relative_to(root / \"b\")\n        assert str(relative) == \"d/e.txt\"\n\n    @pass_alpharep\n    def test_inheritance(self, alpharep):\n        cls = type('PathChild', (zipfile.Path,), {})\n        file = cls(alpharep).joinpath('some dir').parent\n        assert isinstance(file, cls)\n\n    @parameterize(\n        ['alpharep', 'path_type', 'subpath'],\n        itertools.product(\n            alpharep_generators,\n            [str, FakePath],\n            ['', 'b/'],\n        ),\n    )\n    def test_pickle(self, alpharep, path_type, subpath):\n        zipfile_ondisk = path_type(str(self.zipfile_ondisk(alpharep)))\n\n        saved_1 = pickle.dumps(zipfile.Path(zipfile_ondisk, at=subpath))\n        restored_1 = pickle.loads(saved_1)\n        first, *rest = restored_1.iterdir()\n        assert first.read_text(encoding='utf-8').startswith('content of ')\n\n    @pass_alpharep\n    def test_extract_orig_with_implied_dirs(self, alpharep):\n        \"\"\"\n        A zip file wrapped in a Path should extract even with implied dirs.\n        \"\"\"\n        source_path = self.zipfile_ondisk(alpharep)\n        zf = zipfile.ZipFile(source_path)\n        # wrap the zipfile for its side effect\n        zipfile.Path(zf)\n        zf.extractall(source_path.parent)\n\n    @pass_alpharep\n    def test_getinfo_missing(self, alpharep):\n        \"\"\"\n        Validate behavior of getinfo on original zipfile after wrapping.\n        \"\"\"\n        zipfile.Path(alpharep)\n        with self.assertRaises(KeyError):\n            alpharep.getinfo('does-not-exist')\n\n    def test_malformed_paths(self):\n        \"\"\"\n        Path should handle malformed paths.\n        \"\"\"\n        data = io.BytesIO()\n        zf = zipfile.ZipFile(data, \"w\")\n        zf.writestr(\"/one-slash.txt\", b\"content\")\n        zf.writestr(\"//two-slash.txt\", b\"content\")\n        zf.writestr(\"../parent.txt\", b\"content\")\n        zf.filename = ''\n        root = zipfile.Path(zf)\n        assert list(map(str, root.iterdir())) == [\n            'one-slash.txt',\n            'two-slash.txt',\n            'parent.txt',\n        ]\n\n    @pass_alpharep\n    def test_interface(self, alpharep):\n        from .compat.py310 import Traversable\n\n        zf = zipfile.Path(alpharep)\n        assert isinstance(zf, Traversable)\n", "tests/write-alpharep.py": "from . import test_path\n\n\n__name__ == '__main__' and test_path.build_alpharep_fixture().extractall('alpharep')\n", "tests/test_complexity.py": "import io\nimport itertools\nimport math\nimport re\nimport string\nimport unittest\nfrom .compat.overlay import zipfile\n\nfrom jaraco.functools import compose\nfrom more_itertools import consume\n\nfrom ._support import import_or_skip\n\n\nbig_o = import_or_skip('big_o')\npytest = import_or_skip('pytest')\n\n\nclass TestComplexity(unittest.TestCase):\n    @pytest.mark.flaky\n    def test_implied_dirs_performance(self):\n        best, others = big_o.big_o(\n            compose(consume, zipfile._path.CompleteDirs._implied_dirs),\n            lambda size: [\n                '/'.join(string.ascii_lowercase + str(n)) for n in range(size)\n            ],\n            max_n=1000,\n            min_n=1,\n        )\n        assert best <= big_o.complexities.Linear\n\n    def make_zip_path(self, depth=1, width=1):\n        \"\"\"\n        Construct a Path with width files at every level of depth.\n        \"\"\"\n        zf = zipfile.ZipFile(io.BytesIO(), mode='w')\n        pairs = itertools.product(self.make_deep_paths(depth), self.make_names(width))\n        for path, name in pairs:\n            zf.writestr(f\"{path}{name}.txt\", b'')\n        zf.filename = \"big un.zip\"\n        return zipfile.Path(zf)\n\n    @classmethod\n    def make_names(cls, width, letters=string.ascii_lowercase):\n        \"\"\"\n        >>> list(TestComplexity.make_names(1))\n        ['a']\n        >>> list(TestComplexity.make_names(2))\n        ['a', 'b']\n        >>> list(TestComplexity.make_names(30))\n        ['aa', 'ab', ..., 'bd']\n        >>> list(TestComplexity.make_names(17124))\n        ['aaa', 'aab', ..., 'zip']\n        \"\"\"\n        # determine how many products are needed to produce width\n        n_products = max(1, math.ceil(math.log(width, len(letters))))\n        inputs = (letters,) * n_products\n        combinations = itertools.product(*inputs)\n        names = map(''.join, combinations)\n        return itertools.islice(names, width)\n\n    @classmethod\n    def make_deep_paths(cls, depth):\n        return map(cls.make_deep_path, range(depth))\n\n    @classmethod\n    def make_deep_path(cls, depth):\n        return ''.join(('d/',) * depth)\n\n    def test_baseline_regex_complexity(self):\n        best, others = big_o.big_o(\n            lambda path: re.fullmatch(r'[^/]*\\\\.txt', path),\n            self.make_deep_path,\n            max_n=100,\n            min_n=1,\n        )\n        assert best <= big_o.complexities.Constant\n\n    @pytest.mark.flaky\n    def test_glob_depth(self):\n        best, others = big_o.big_o(\n            lambda path: consume(path.glob('*.txt')),\n            self.make_zip_path,\n            max_n=100,\n            min_n=1,\n        )\n        assert best <= big_o.complexities.Linear\n\n    @pytest.mark.flaky\n    def test_glob_width(self):\n        best, others = big_o.big_o(\n            lambda path: consume(path.glob('*.txt')),\n            lambda size: self.make_zip_path(width=size),\n            max_n=100,\n            min_n=1,\n        )\n        assert best <= big_o.complexities.Linear\n\n    @pytest.mark.flaky\n    def test_glob_width_and_depth(self):\n        best, others = big_o.big_o(\n            lambda path: consume(path.glob('*.txt')),\n            lambda size: self.make_zip_path(depth=size, width=size),\n            max_n=10,\n            min_n=1,\n        )\n        assert best <= big_o.complexities.Linear\n", "tests/__init__.py": "", "tests/_support.py": "import importlib\nimport unittest\n\n\ndef import_or_skip(name):\n    try:\n        return importlib.import_module(name)\n    except ImportError:  # pragma: no cover\n        raise unittest.SkipTest(f'Unable to import {name}')\n", "tests/_test_params.py": "import types\nimport functools\n\nfrom more_itertools import always_iterable\n\n\ndef parameterize(names, value_groups):\n    \"\"\"\n    Decorate a test method to run it as a set of subtests.\n\n    Modeled after pytest.parametrize.\n    \"\"\"\n\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapped(self):\n            for values in value_groups:\n                resolved = map(Invoked.eval, always_iterable(values))\n                params = dict(zip(always_iterable(names), resolved))\n                with self.subTest(**params):\n                    func(self, **params)\n\n        return wrapped\n\n    return decorator\n\n\nclass Invoked(types.SimpleNamespace):\n    \"\"\"\n    Wrap a function to be invoked for each usage.\n    \"\"\"\n\n    @classmethod\n    def wrap(cls, func):\n        return cls(func=func)\n\n    @classmethod\n    def eval(cls, cand):\n        return cand.func() if isinstance(cand, cls) else cand\n", "tests/compat/py310.py": "import sys\n\n\nif sys.version_info >= (3, 11):\n    from importlib.resources.abc import Traversable\nelse:  # pragma: no cover\n    from .py38 import Traversable\n\n\n__all__ = ['Traversable']\n", "tests/compat/py38.py": "import sys\n\n\nif sys.version_info >= (3, 9):\n    from importlib.abc import Traversable\nelse:  # pragma: no cover\n    from importlib_resources.abc import Traversable\n\n\n__all__ = ['Traversable']\n", "tests/compat/py39.py": "import sys\n\nfrom jaraco.test.cpython import from_test_support, try_import\n\n\nos_helper = try_import('os_helper') or from_test_support(\n    'FakePath',\n    'temp_dir',\n)\n\nsys.modules[__name__ + '.os_helper'] = os_helper\n", "tests/compat/__init__.py": "", "tests/compat/overlay.py": "\"\"\"\nExpose zipp.Path as .zipfile.Path\n\"\"\"\n\nimport importlib\nimport sys\nimport types\n\nimport zipp\n\n\nzipfile = types.SimpleNamespace(**vars(importlib.import_module('zipfile')))\nzipfile.Path = zipp.Path\nzipfile._path = zipp\n\nsys.modules[__name__ + '.zipfile'] = zipfile  # type: ignore\n"}