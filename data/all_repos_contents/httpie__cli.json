{"setup.py": "from setuptools import setup\n\nsetup()\n", "extras/profiling/run.py": "\"\"\"\nRun the HTTPie benchmark suite with multiple environments.\n\nThis script is configured in a way that, it will create\ntwo (or more) isolated environments and compare the *last\ncommit* of this repository with it's master.\n\n> If you didn't commit yet, it won't be showing results.\n\nYou can also pass --fresh, which would test the *last\ncommit* of this repository with a fresh copy of HTTPie\nitself. This way even if you don't have an up-to-date\nmaster branch, you can still compare it with the upstream's\nmaster.\n\nYou can also pass --complex to add 2 additional environments,\nwhich would include additional dependencies like pyOpenSSL.\n\nExamples:\n\n    # Run everything as usual, and compare last commit with master\n    $ python extras/profiling/run.py\n\n    # Include complex environments\n    $ python extras/profiling/run.py --complex\n\n    # Compare against a fresh copy\n    $ python extras/profiling/run.py --fresh\n\n    # Compare against a custom branch of a custom repo\n    $ python extras/profiling/run.py --target-repo my_repo --target-branch my_branch\n\n    # Debug changes made on this script (only run benchmarks once)\n    $ python extras/profiling/run.py --debug\n\"\"\"\n\nimport dataclasses\nimport shlex\nimport subprocess\nimport sys\nimport tempfile\nimport venv\nfrom argparse import ArgumentParser, FileType\nfrom contextlib import contextmanager\nfrom dataclasses import dataclass\nfrom pathlib import Path\nfrom typing import (IO, Dict, Generator, Iterable, List, Optional,\n                    Tuple)\n\nBENCHMARK_SCRIPT = Path(__file__).parent / 'benchmarks.py'\nCURRENT_REPO = Path(__file__).parent.parent.parent\n\nGITHUB_URL = 'https://github.com/httpie/cli.git'\nTARGET_BRANCH = 'master'\n\n# Additional dependencies for --complex\nADDITIONAL_DEPS = ('pyOpenSSL',)\n\n\ndef call(*args, **kwargs):\n    kwargs.setdefault('stdout', subprocess.DEVNULL)\n    return subprocess.check_call(*args, **kwargs)\n\n\nclass Environment:\n    \"\"\"\n    Each environment defines how to create an isolated instance\n    where we could install HTTPie and run benchmarks without any\n    environmental factors.\n    \"\"\"\n\n    @contextmanager\n    def on_repo(self) -> Generator[Tuple[Path, Dict[str, str]], None, None]:\n        \"\"\"\n        Return the path to the python interpreter and the\n        environment variables (e.g HTTPIE_COMMAND) to be\n        used on the benchmarks.\n        \"\"\"\n        raise NotImplementedError\n\n\n@dataclass\nclass HTTPieEnvironment(Environment):\n    repo_url: str\n    branch: Optional[str] = None\n    dependencies: Iterable[str] = ()\n\n    @contextmanager\n    def on_repo(self) -> Generator[Path, None, None]:\n        with tempfile.TemporaryDirectory() as directory_path:\n            directory = Path(directory_path)\n\n            # Clone the repo\n            repo_path = directory / 'httpie'\n            call(\n                ['git', 'clone', self.repo_url, repo_path],\n                stderr=subprocess.DEVNULL,\n            )\n\n            if self.branch is not None:\n                call(\n                    ['git', 'checkout', self.branch],\n                    cwd=repo_path,\n                    stderr=subprocess.DEVNULL,\n                )\n\n            # Prepare the environment\n            venv_path = directory / '.venv'\n            venv.create(venv_path, with_pip=True)\n\n            # Install basic dependencies\n            python = venv_path / 'bin' / 'python'\n            call(\n                [\n                    python,\n                    '-m',\n                    'pip',\n                    'install',\n                    'wheel',\n                    'pyperf==2.3.0',\n                    *self.dependencies,\n                ]\n            )\n\n            # Create a wheel distribution of HTTPie\n            call([python, 'setup.py', 'bdist_wheel'], cwd=repo_path)\n\n            # Install httpie\n            distribution_path = next((repo_path / 'dist').iterdir())\n            call(\n                [python, '-m', 'pip', 'install', distribution_path],\n                cwd=repo_path,\n            )\n\n            http = venv_path / 'bin' / 'http'\n            yield python, {'HTTPIE_COMMAND': shlex.join([str(python), str(http)])}\n\n\n@dataclass\nclass LocalCommandEnvironment(Environment):\n    local_command: str\n\n    @contextmanager\n    def on_repo(self) -> Generator[Path, None, None]:\n        yield sys.executable, {'HTTPIE_COMMAND': self.local_command}\n\n\ndef dump_results(\n    results: List[str],\n    file: IO[str],\n    min_speed: Optional[str] = None\n) -> None:\n    for result in results:\n        lines = result.strip().splitlines()\n        if min_speed is not None and \"hidden\" in lines[-1]:\n            lines[-1] = (\n                'Some benchmarks were hidden from this list '\n                'because their timings did not change in a '\n                'significant way (change was within the error '\n                'margin \u00b1{margin}%).'\n            ).format(margin=min_speed)\n            result = '\\n'.join(lines)\n\n        print(result, file=file)\n        print(\"\\n---\\n\", file=file)\n\n\ndef compare(*args, directory: Path, min_speed: Optional[str] = None):\n    compare_args = ['pyperf', 'compare_to', '--table', '--table-format=md', *args]\n    if min_speed:\n        compare_args.extend(['--min-speed', min_speed])\n    return subprocess.check_output(\n        compare_args,\n        cwd=directory,\n        text=True,\n    )\n\n\ndef run(\n    configs: List[Dict[str, Environment]],\n    file: IO[str],\n    debug: bool = False,\n    min_speed: Optional[str] = None,\n) -> None:\n    result_directory = Path(tempfile.mkdtemp())\n    results = []\n\n    current = 1\n    total = sum(1 for config in configs for _ in config.items())\n\n    def iterate(env_name, status):\n        print(\n            f'Iteration: {env_name} ({current}/{total}) ({status})' + ' ' * 10,\n            end='\\r',\n            flush=True,\n        )\n\n    for config in configs:\n        for env_name, env in config.items():\n            iterate(env_name, 'setting up')\n            with env.on_repo() as (python, env_vars):\n                iterate(env_name, 'running benchmarks')\n                args = [python, BENCHMARK_SCRIPT, '-o', env_name]\n                if debug:\n                    args.append('--debug-single-value')\n                call(\n                    args,\n                    cwd=result_directory,\n                    env=env_vars,\n                )\n            current += 1\n\n        results.append(compare(\n            *config.keys(),\n            directory=result_directory,\n            min_speed=min_speed\n        ))\n\n    dump_results(results, file=file, min_speed=min_speed)\n    print('Results are available at:', result_directory)\n\n\ndef main() -> None:\n    parser = ArgumentParser()\n    parser.add_argument('--local-repo', default=CURRENT_REPO)\n    parser.add_argument('--local-branch', default=None)\n    parser.add_argument('--target-repo', default=CURRENT_REPO)\n    parser.add_argument('--target-branch', default=TARGET_BRANCH)\n    parser.add_argument(\n        '--fresh',\n        action='store_const',\n        const=GITHUB_URL,\n        dest='target_repo',\n        help='Clone the target repo from upstream GitHub URL',\n    )\n    parser.add_argument(\n        '--complex',\n        action='store_true',\n        help='Add a second run, with a complex python environment.',\n    )\n    parser.add_argument(\n        '--local-bin',\n        help='Run the suite with the given local binary in addition to'\n        ' existing runners. (E.g --local-bin $(command -v xh))',\n    )\n    parser.add_argument(\n        '--file',\n        type=FileType('w'),\n        default=sys.stdout,\n        help='File to print the actual results',\n    )\n    parser.add_argument(\n        '--min-speed',\n        help='Minimum of speed in percent to consider that a '\n             'benchmark is significant'\n    )\n    parser.add_argument(\n        '--debug',\n        action='store_true',\n    )\n\n    options = parser.parse_args()\n\n    configs = []\n\n    base_config = {\n        options.target_branch: HTTPieEnvironment(options.target_repo, options.target_branch),\n        'this_branch': HTTPieEnvironment(options.local_repo, options.local_branch),\n    }\n    configs.append(base_config)\n\n    if options.complex:\n        complex_config = {\n            env_name\n            + '-complex': dataclasses.replace(env, dependencies=ADDITIONAL_DEPS)\n            for env_name, env in base_config.items()\n        }\n        configs.append(complex_config)\n\n    if options.local_bin:\n        base_config['binary'] = LocalCommandEnvironment(options.local_bin)\n\n    run(configs, file=options.file, debug=options.debug, min_speed=options.min_speed)\n\n\nif __name__ == '__main__':\n    main()\n", "extras/profiling/benchmarks.py": "\"\"\"\nThis file is the declaration of benchmarks for HTTPie. It\nis also used to run them with the current environment.\n\nEach instance of BaseRunner class will be an individual\nbenchmark. And if run without any arguments, this file\nwill execute every benchmark instance and report the\ntimings.\n\nThe benchmarks are run through 'pyperf', which allows to\ndo get very precise results. For micro-benchmarks like startup,\nplease run `pyperf system tune` to get even more accurate results.\n\nExamples:\n\n    # Run everything as usual, the default is that we do 3 warm-up runs\n    # and 5 actual runs.\n    $ python extras/profiling/benchmarks.py\n\n    # For retrieving results faster, pass --fast\n    $ python extras/profiling/benchmarks.py --fast\n\n    # For verify everything works as expected, pass --debug-single-value.\n    # It will only run everything once, so the resuls are not reliable. But\n    # very useful when iterating on a benchmark\n    $ python extras/profiling/benchmarks.py --debug-single-value\n\n    # If you want to run with a custom HTTPie command (for example with\n    # and HTTPie instance installed in another virtual environment),\n    # pass HTTPIE_COMMAND variable.\n    $ HTTPIE_COMMAND=\"/my/python /my/httpie\" python extras/profiling/benchmarks.py\n\"\"\"\n\nfrom __future__ import annotations\n\nimport os\nimport shlex\nimport subprocess\nimport sys\nimport threading\nfrom contextlib import ExitStack, contextmanager\nfrom dataclasses import dataclass, field\nfrom functools import cached_property, partial\nfrom http.server import HTTPServer, SimpleHTTPRequestHandler\nfrom tempfile import TemporaryDirectory\nfrom typing import ClassVar, Final, List\n\nimport pyperf\n\n# For download benchmarks, define a set of files.\n# file: (block_size, count) => total_size = block_size * count\nPREDEFINED_FILES: Final = {'3G': (3 * 1024 ** 2, 1024)}\n\n\nclass QuietSimpleHTTPServer(SimpleHTTPRequestHandler):\n    def log_message(self, *args, **kwargs):\n        pass\n\n\n@contextmanager\ndef start_server():\n    \"\"\"Create a server to serve local files. It will create the\n    PREDEFINED_FILES through dd.\"\"\"\n    with TemporaryDirectory() as directory:\n        for file_name, (block_size, count) in PREDEFINED_FILES.items():\n            subprocess.check_call(\n                [\n                    'dd',\n                    'if=/dev/zero',\n                    f'of={file_name}',\n                    f'bs={block_size}',\n                    f'count={count}',\n                ],\n                cwd=directory,\n                stdout=subprocess.DEVNULL,\n                stderr=subprocess.DEVNULL,\n            )\n\n        handler = partial(QuietSimpleHTTPServer, directory=directory)\n        server = HTTPServer(('localhost', 0), handler)\n\n        thread = threading.Thread(target=server.serve_forever)\n        thread.start()\n        yield '{}:{}'.format(*server.socket.getsockname())\n        server.shutdown()\n        thread.join(timeout=0.5)\n\n\n@dataclass\nclass Context:\n    benchmarks: ClassVar[List[BaseRunner]] = []\n    stack: ExitStack = field(default_factory=ExitStack)\n    runner: pyperf.Runner = field(default_factory=pyperf.Runner)\n\n    def run(self) -> pyperf.BenchmarkSuite:\n        results = [benchmark.run(self) for benchmark in self.benchmarks]\n        return pyperf.BenchmarkSuite(results)\n\n    @property\n    def cmd(self) -> List[str]:\n        if cmd := os.getenv('HTTPIE_COMMAND'):\n            return shlex.split(cmd)\n\n        http = os.path.join(os.path.dirname(sys.executable), 'http')\n        assert os.path.exists(http)\n        return [sys.executable, http]\n\n    @cached_property\n    def server(self) -> str:\n        return self.stack.enter_context(start_server())\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *exc_info):\n        self.stack.close()\n\n\n@dataclass\nclass BaseRunner:\n    \"\"\"\n    An individual benchmark case. By default it has the category\n    (e.g like startup or download) and a name.\n    \"\"\"\n\n    category: str\n    title: str\n\n    def __post_init__(self):\n        Context.benchmarks.append(self)\n\n    def run(self, context: Context) -> pyperf.Benchmark:\n        raise NotImplementedError\n\n    @property\n    def name(self) -> str:\n        return f'{self.title} ({self.category})'\n\n\n@dataclass\nclass CommandRunner(BaseRunner):\n    \"\"\"\n    Run a single command, and benchmark it.\n    \"\"\"\n\n    args: List[str]\n\n    def run(self, context: Context) -> pyperf.Benchmark:\n        return context.runner.bench_command(self.name, [*context.cmd, *self.args])\n\n\n@dataclass\nclass DownloadRunner(BaseRunner):\n    \"\"\"\n    Benchmark downloading a single file from the\n    remote server.\n    \"\"\"\n\n    file_name: str\n\n    def run(self, context: Context) -> pyperf.Benchmark:\n        return context.runner.bench_command(\n            self.name,\n            [\n                *context.cmd,\n                '--download',\n                'GET',\n                f'{context.server}/{self.file_name}',\n            ],\n        )\n\n\nCommandRunner('startup', '`http --version`', ['--version'])\nCommandRunner('startup', '`http --offline pie.dev/get`', ['--offline', 'pie.dev/get'])\nfor pretty in ['all', 'none']:\n    CommandRunner(\n        'startup',\n        f'`http --pretty={pretty} pie.dev/stream/1000`',\n        [\n            '--print=HBhb',\n            f'--pretty={pretty}',\n            'httpbin.org/stream/1000'\n        ]\n    )\nDownloadRunner('download', '`http --download :/big_file.txt` (3GB)', '3G')\n\n\ndef main() -> None:\n    # PyPerf will bring it's own argument parser, so configure the script.\n    # The somewhat fast and also precise enough configuration is this. We run\n    # benchmarks 3 times to warm up (e.g especially for download benchmark, this\n    # is important). And then 5 actual runs where we record.\n    sys.argv.extend(\n        ['--worker', '--loops=1', '--warmup=3', '--values=5', '--processes=2']\n    )\n\n    with Context() as context:\n        context.run()\n\n\nif __name__ == '__main__':\n    main()\n", "extras/scripts/generate_man_pages.py": "import os\nimport re\nfrom contextlib import contextmanager\nfrom pathlib import Path\nfrom typing import Optional, Iterator, Iterable\n\n\n# So that httpie.cli.definition can provide man-page-specific output. Must be set before importing httpie.\nos.environ['HTTPIE_BUILDING_MAN_PAGES'] = '1'\n\nimport httpie\nfrom httpie.cli.definition import options as core_options, IS_MAN_PAGE\nfrom httpie.cli.options import ParserSpec\nfrom httpie.manager.cli import options as manager_options\nfrom httpie.output.ui.rich_help import OptionsHighlighter, to_usage\nfrom httpie.output.ui.rich_utils import render_as_string\n\n\nassert IS_MAN_PAGE, 'CLI definition does not understand we\u2019re building man pages'\n\n# Escape certain characters, so they are rendered properly on all terminals.\n# <https://man7.org/linux/man-pages/man7/groff_char.7.html>\nESCAPE_MAP = {\n    '\"': '\\[dq]',\n    \"'\": '\\[aq]',\n    '~': '\\(ti',\n    '\u2019': \"\\(ga\",\n    '\\\\': '\\e',\n}\nESCAPE_MAP = {ord(key): value for key, value in ESCAPE_MAP.items()}\n\nEXTRAS_DIR = Path(__file__).parent.parent\nMAN_PAGE_PATH = EXTRAS_DIR / 'man'\nPROJECT_ROOT = EXTRAS_DIR.parent\n\nOPTION_HIGHLIGHT_RE = re.compile(\n    OptionsHighlighter.highlights[0]\n)\n\n\nclass ManPageBuilder:\n    def __init__(self):\n        self.source = []\n\n    def title_line(\n        self,\n        full_name: str,\n        program_name: str,\n        program_version: str,\n        last_edit_date: str,\n    ) -> None:\n        self.source.append(\n            f'.TH {program_name} 1 \"{last_edit_date}\" '\n            f'\"{full_name} {program_version}\" \"{full_name} Manual\"'\n        )\n\n    def set_name(self, program_name: str) -> None:\n        with self.section('NAME'):\n            self.write(program_name)\n\n    def write(self, text: str, *, bold: bool = False) -> None:\n        if bold:\n            text = '.B ' + text\n        self.source.append(text)\n\n    def separate(self) -> None:\n        self.source.append('.PP')\n\n    def format_desc(self, desc: str) -> str:\n        description = _escape_and_dedent(desc)\n        description = OPTION_HIGHLIGHT_RE.sub(\n            # Boldify the option part, but don't remove the prefix (start of the match).\n            lambda match: match[1] + self.boldify(match['option']),\n            description\n        )\n        return description\n\n    def add_comment(self, comment: str) -> None:\n        self.source.append(f'.\\\\\" {comment}')\n\n    def add_options(self, options: Iterable[str], *, metavar: Optional[str] = None) -> None:\n        text = \", \".join(map(self.boldify, options))\n        if metavar:\n            text += f' {self.underline(metavar)}'\n        self.write(f'.IP \"{text}\"')\n\n    def build(self) -> str:\n        return '\\n'.join(self.source)\n\n    @contextmanager\n    def section(self, section_name: str) -> Iterator[None]:\n        self.write(f'.SH {section_name}')\n        self.in_section = True\n        yield\n        self.in_section = False\n\n    def underline(self, text: str) -> str:\n        return r'\\fI\\,{}\\/\\fR'.format(text)\n\n    def boldify(self, text: str) -> str:\n        return r'\\fB\\,{}\\/\\fR'.format(text)\n\n\ndef _escape_and_dedent(text: str) -> str:\n    lines = []\n    for should_act, line in enumerate(text.splitlines()):\n        # Only dedent after the first line.\n        if should_act:\n            if line.startswith('    '):\n                line = line[4:]\n\n        lines.append(line)\n    return '\\n'.join(lines).translate(ESCAPE_MAP)\n\n\ndef to_man_page(program_name: str, spec: ParserSpec, *, is_top_level_cmd: bool = False) -> str:\n    builder = ManPageBuilder()\n    builder.add_comment(\n        f\"This file is auto-generated from the parser declaration \"\n        + (f\"in {Path(spec.source_file).relative_to(PROJECT_ROOT)} \" if spec.source_file else \"\")\n        + f\"by {Path(__file__).relative_to(PROJECT_ROOT)}.\"\n    )\n\n    builder.title_line(\n        full_name='HTTPie',\n        program_name=program_name,\n        program_version=httpie.__version__,\n        last_edit_date=httpie.__date__,\n    )\n    builder.set_name(program_name)\n\n    with builder.section('SYNOPSIS'):\n        # `http` and `https` are commands that can be directly used, so they can have\n        # a valid usage. But `httpie` is a top-level command with multiple sub commands,\n        # so for the synopsis we'll only reference the `httpie` name.\n        if is_top_level_cmd:\n            synopsis = program_name\n        else:\n            synopsis = render_as_string(to_usage(spec, program_name=program_name))\n        builder.write(synopsis)\n\n    with builder.section('DESCRIPTION'):\n        builder.write(spec.description)\n        if spec.man_page_hint:\n            builder.write(spec.man_page_hint)\n\n    for index, group in enumerate(spec.groups, 1):\n        with builder.section(group.name):\n            if group.description:\n                builder.write(group.description)\n\n            for argument in group.arguments:\n                if argument.is_hidden:\n                    continue\n\n                raw_arg = argument.serialize(isolation_mode=True)\n\n                metavar = raw_arg.get('metavar')\n                if raw_arg.get('is_positional'):\n                    # In case of positional arguments, metavar is always equal\n                    # to the list of options (e.g `METHOD`).\n                    metavar = None\n                builder.add_options(raw_arg['options'], metavar=metavar)\n\n                desc = builder.format_desc(raw_arg.get('description', ''))\n                builder.write('\\n' + desc + '\\n')\n\n            builder.separate()\n\n    if spec.epilog:\n        with builder.section('SEE ALSO'):\n            builder.write(builder.format_desc(spec.epilog))\n\n    return builder.build()\n\n\ndef main() -> None:\n    for program_name, spec, config in [\n        ('http', core_options, {}),\n        ('https', core_options, {}),\n        ('httpie', manager_options, {'is_top_level_cmd': True}),\n    ]:\n        with open((MAN_PAGE_PATH / program_name).with_suffix('.1'), 'w') as stream:\n            stream.write(to_man_page(program_name, spec, **config))\n\n\nif __name__ == '__main__':\n    main()\n", "extras/packaging/linux/build.py": "import stat\nimport subprocess\nfrom pathlib import Path\nfrom typing import Iterator, Tuple\n\nBUILD_DIR = Path(__file__).parent\nHTTPIE_DIR = BUILD_DIR.parent.parent.parent\n\nEXTRAS_DIR = HTTPIE_DIR / 'extras'\nMAN_PAGES_DIR = EXTRAS_DIR /  'man'\n\nSCRIPT_DIR = BUILD_DIR / Path('scripts')\nHOOKS_DIR = SCRIPT_DIR / 'hooks'\n\nDIST_DIR = BUILD_DIR / 'dist'\n\nTARGET_SCRIPTS = {\n    SCRIPT_DIR / 'http_cli.py': [],\n    SCRIPT_DIR / 'httpie_cli.py': ['--hidden-import=pip'],\n}\n\n\ndef build_binaries() -> Iterator[Tuple[str, Path]]:\n    for target_script, extra_args in TARGET_SCRIPTS.items():\n        subprocess.check_call(\n            [\n                'pyinstaller',\n                '--onefile',\n                '--noupx',\n                '-p',\n                HTTPIE_DIR,\n                '--additional-hooks-dir',\n                HOOKS_DIR,\n                *extra_args,\n                target_script,\n            ]\n        )\n\n    for executable_path in DIST_DIR.iterdir():\n        if executable_path.suffix:\n            continue\n        stat_r = executable_path.stat()\n        executable_path.chmod(stat_r.st_mode | stat.S_IEXEC)\n        yield executable_path.stem, executable_path\n\n\ndef build_packages(http_binary: Path, httpie_binary: Path) -> None:\n    import httpie\n\n    # Mapping of src_file -> dst_file\n    files = [\n        (http_binary, '/usr/bin/http'),\n        (http_binary, '/usr/bin/https'),\n        (httpie_binary, '/usr/bin/httpie'),\n    ]\n    files.extend(\n        (man_page, f'/usr/share/man/man1/{man_page.name}')\n        for man_page in MAN_PAGES_DIR.glob('*.1')\n    )\n\n    # A list of additional dependencies\n    deps = [\n        'python3 >= 3.7',\n        'python3-pip'\n    ]\n\n    processed_deps = [\n        f'--depends={dep}'\n        for dep in deps\n    ]\n    processed_files = [\n        '='.join([str(src.resolve()), dst]) for src, dst in files\n    ]\n    for target in ['deb', 'rpm']:\n        subprocess.check_call(\n            [\n                'fpm',\n                '--force',\n                '-s',\n                'dir',\n                '-t',\n                target,\n                '--name',\n                'httpie',\n                '--version',\n                httpie.__version__,\n                '--description',\n                httpie.__doc__.strip(),\n                '--license',\n                httpie.__licence__,\n                *processed_deps,\n                *processed_files,\n            ],\n            cwd=DIST_DIR,\n        )\n\n\ndef main():\n    binaries = dict(build_binaries())\n    build_packages(binaries['http_cli'], binaries['httpie_cli'])\n\n    # Rename http_cli/httpie_cli to http/httpie\n    binaries['http_cli'].rename(DIST_DIR / 'http')\n    binaries['httpie_cli'].rename(DIST_DIR / 'httpie')\n\n\n\nif __name__ == '__main__':\n    main()\n", "extras/packaging/linux/scripts/http_cli.py": "from httpie.__main__ import main\n\nif __name__ == '__main__':\n    import sys\n    sys.exit(main())\n", "extras/packaging/linux/scripts/httpie_cli.py": "from httpie.manager.__main__ import main\n\nif __name__ == '__main__':\n    import sys\n    sys.exit(main())\n", "extras/packaging/linux/scripts/hooks/hook-pip.py": "from pathlib import Path\nfrom PyInstaller.utils.hooks import collect_all\n\ndef hook(hook_api):\n    for pkg in [\n        'pip',\n        'setuptools',\n        'distutils',\n        'pkg_resources'\n    ]:\n        datas, binaries, hiddenimports = collect_all(pkg)\n        hook_api.add_datas(datas)\n        hook_api.add_binaries(binaries)\n        hook_api.add_imports(*hiddenimports)\n", "httpie/uploads.py": "import sys\nimport os\nimport zlib\nimport functools\nimport threading\nfrom typing import Any, Callable, IO, Iterable, Optional, Tuple, Union, TYPE_CHECKING\nfrom urllib.parse import urlencode\n\nimport requests\nfrom requests.utils import super_len\n\nif TYPE_CHECKING:\n    from requests_toolbelt import MultipartEncoder\n\nfrom .context import Environment\nfrom .cli.dicts import MultipartRequestDataDict, RequestDataDict\nfrom .compat import is_windows\n\n\nclass ChunkedStream:\n    def __iter__(self) -> Iterable[Union[str, bytes]]:\n        raise NotImplementedError\n\n\nclass ChunkedUploadStream(ChunkedStream):\n    def __init__(\n        self,\n        stream: Iterable,\n        callback: Callable,\n        event: Optional[threading.Event] = None\n    ) -> None:\n        self.callback = callback\n        self.stream = stream\n        self.event = event\n\n    def __iter__(self) -> Iterable[Union[str, bytes]]:\n        for chunk in self.stream:\n            if self.event:\n                self.event.set()\n            self.callback(chunk)\n            yield chunk\n\n\nclass ChunkedMultipartUploadStream(ChunkedStream):\n    chunk_size = 100 * 1024\n\n    def __init__(\n        self,\n        encoder: 'MultipartEncoder',\n        event: Optional[threading.Event] = None\n    ) -> None:\n        self.encoder = encoder\n        self.event = event\n\n    def __iter__(self) -> Iterable[Union[str, bytes]]:\n        while True:\n            chunk = self.encoder.read(self.chunk_size)\n            if self.event:\n                self.event.set()\n            if not chunk:\n                break\n            yield chunk\n\n\ndef as_bytes(data: Union[str, bytes]) -> bytes:\n    if isinstance(data, str):\n        return data.encode()\n    else:\n        return data\n\n\nCallbackT = Callable[[bytes], bytes]\n\n\ndef _wrap_function_with_callback(\n    func: Callable[..., Any],\n    callback: CallbackT\n) -> Callable[..., Any]:\n    @functools.wraps(func)\n    def wrapped(*args, **kwargs):\n        chunk = func(*args, **kwargs)\n        callback(chunk)\n        return chunk\n    return wrapped\n\n\ndef is_stdin(file: IO) -> bool:\n    try:\n        file_no = file.fileno()\n    except Exception:\n        return False\n    else:\n        return file_no == sys.stdin.fileno()\n\n\nREAD_THRESHOLD = float(os.getenv('HTTPIE_STDIN_READ_WARN_THRESHOLD', 10.0))\n\n\ndef observe_stdin_for_data_thread(env: Environment, file: IO, read_event: threading.Event) -> None:\n    # Windows unfortunately does not support select() operation\n    # on regular files, like stdin in our use case.\n    # https://docs.python.org/3/library/select.html#select.select\n    if is_windows:\n        return None\n\n    # If the user configures READ_THRESHOLD to be 0, then\n    # disable this warning.\n    if READ_THRESHOLD == 0:\n        return None\n\n    def worker(event: threading.Event) -> None:\n        if not event.wait(timeout=READ_THRESHOLD):\n            env.stderr.write(\n                f'> warning: no stdin data read in {READ_THRESHOLD}s '\n                f'(perhaps you want to --ignore-stdin)\\n'\n                f'> See: https://httpie.io/docs/cli/best-practices\\n'\n            )\n\n    # Making it a daemon ensures that if the user exits from the main program\n    # (e.g. either regularly or with Ctrl-C), the thread will not\n    # block them.\n    thread = threading.Thread(\n        target=worker,\n        args=(read_event,),\n        daemon=True\n    )\n    thread.start()\n\n\ndef _read_file_with_selectors(file: IO, read_event: threading.Event) -> bytes:\n    if is_windows or not is_stdin(file):\n        return as_bytes(file.read())\n\n    import select\n\n    # Try checking whether there is any incoming data for READ_THRESHOLD\n    # seconds. If there isn't anything in the given period, issue\n    # a warning about a misusage.\n    read_selectors, _, _ = select.select([file], [], [], READ_THRESHOLD)\n    if read_selectors:\n        read_event.set()\n\n    return as_bytes(file.read())\n\n\ndef _prepare_file_for_upload(\n    env: Environment,\n    file: Union[IO, 'MultipartEncoder'],\n    callback: CallbackT,\n    chunked: bool = False,\n    content_length_header_value: Optional[int] = None,\n) -> Union[bytes, IO, ChunkedStream]:\n    read_event = threading.Event()\n    if not super_len(file):\n        if is_stdin(file):\n            observe_stdin_for_data_thread(env, file, read_event)\n\n        # Zero-length -> assume stdin.\n        if content_length_header_value is None and not chunked:\n            # Read the whole stdin to determine `Content-Length`.\n            #\n            # TODO: Instead of opt-in --chunked, consider making\n            #   `Transfer-Encoding: chunked` for STDIN opt-out via\n            #   something like --no-chunked.\n            #   This would be backwards-incompatible so wait until v3.0.0.\n            #\n            file = _read_file_with_selectors(file, read_event)\n    else:\n        file.read = _wrap_function_with_callback(\n            file.read,\n            callback\n        )\n\n    if chunked:\n        from requests_toolbelt import MultipartEncoder\n        if isinstance(file, MultipartEncoder):\n            return ChunkedMultipartUploadStream(\n                encoder=file,\n                event=read_event,\n            )\n        else:\n            return ChunkedUploadStream(\n                stream=file,\n                callback=callback,\n                event=read_event\n            )\n    else:\n        return file\n\n\ndef prepare_request_body(\n    env: Environment,\n    raw_body: Union[str, bytes, IO, 'MultipartEncoder', RequestDataDict],\n    body_read_callback: CallbackT,\n    offline: bool = False,\n    chunked: bool = False,\n    content_length_header_value: Optional[int] = None,\n) -> Union[bytes, IO, 'MultipartEncoder', ChunkedStream]:\n    is_file_like = hasattr(raw_body, 'read')\n    if isinstance(raw_body, (bytes, str)):\n        body = as_bytes(raw_body)\n    elif isinstance(raw_body, RequestDataDict):\n        body = as_bytes(urlencode(raw_body, doseq=True))\n    else:\n        body = raw_body\n\n    if offline:\n        if is_file_like:\n            return as_bytes(raw_body.read())\n        else:\n            return body\n\n    if is_file_like:\n        return _prepare_file_for_upload(\n            env,\n            body,\n            chunked=chunked,\n            callback=body_read_callback,\n            content_length_header_value=content_length_header_value\n        )\n    elif chunked:\n        return ChunkedUploadStream(\n            stream=iter([body]),\n            callback=body_read_callback\n        )\n    else:\n        return body\n\n\ndef get_multipart_data_and_content_type(\n    data: MultipartRequestDataDict,\n    boundary: str = None,\n    content_type: str = None,\n) -> Tuple['MultipartEncoder', str]:\n    from requests_toolbelt import MultipartEncoder\n\n    encoder = MultipartEncoder(\n        fields=data.items(),\n        boundary=boundary,\n    )\n    if content_type:\n        content_type = content_type.strip()\n        if 'boundary=' not in content_type:\n            content_type = f'{content_type}; boundary={encoder.boundary_value}'\n    else:\n        content_type = encoder.content_type\n\n    data = encoder\n    return data, content_type\n\n\ndef compress_request(\n    request: requests.PreparedRequest,\n    always: bool,\n):\n    deflater = zlib.compressobj()\n    if isinstance(request.body, str):\n        body_bytes = request.body.encode()\n    elif hasattr(request.body, 'read'):\n        body_bytes = request.body.read()\n    else:\n        body_bytes = request.body\n    deflated_data = deflater.compress(body_bytes)\n    deflated_data += deflater.flush()\n    is_economical = len(deflated_data) < len(body_bytes)\n    if is_economical or always:\n        request.body = deflated_data\n        request.headers['Content-Encoding'] = 'deflate'\n        request.headers['Content-Length'] = str(len(deflated_data))\n", "httpie/config.py": "import json\nimport os\nfrom pathlib import Path\nfrom typing import Any, Dict, Union\n\nfrom . import __version__\nfrom .compat import is_windows\nfrom .encoding import UTF8\n\n\nENV_XDG_CONFIG_HOME = 'XDG_CONFIG_HOME'\nENV_HTTPIE_CONFIG_DIR = 'HTTPIE_CONFIG_DIR'\nDEFAULT_CONFIG_DIRNAME = 'httpie'\nDEFAULT_RELATIVE_XDG_CONFIG_HOME = Path('.config')\nDEFAULT_RELATIVE_LEGACY_CONFIG_DIR = Path('.httpie')\nDEFAULT_WINDOWS_CONFIG_DIR = Path(\n    os.path.expandvars('%APPDATA%')) / DEFAULT_CONFIG_DIRNAME\n\n\ndef get_default_config_dir() -> Path:\n    \"\"\"\n    Return the path to the httpie configuration directory.\n\n    This directory isn't guaranteed to exist, and nor are any of its\n    ancestors (only the legacy ~/.httpie, if returned, is guaranteed to exist).\n\n    XDG Base Directory Specification support:\n\n        <https://wiki.archlinux.org/index.php/XDG_Base_Directory>\n\n        $XDG_CONFIG_HOME is supported; $XDG_CONFIG_DIRS is not\n\n    \"\"\"\n    # 1. explicitly set through env\n    env_config_dir = os.environ.get(ENV_HTTPIE_CONFIG_DIR)\n    if env_config_dir:\n        return Path(env_config_dir)\n\n    # 2. Windows\n    if is_windows:\n        return DEFAULT_WINDOWS_CONFIG_DIR\n\n    home_dir = Path.home()\n\n    # 3. legacy ~/.httpie\n    legacy_config_dir = home_dir / DEFAULT_RELATIVE_LEGACY_CONFIG_DIR\n    if legacy_config_dir.exists():\n        return legacy_config_dir\n\n    # 4. XDG\n    xdg_config_home_dir = os.environ.get(\n        ENV_XDG_CONFIG_HOME,  # 4.1. explicit\n        home_dir / DEFAULT_RELATIVE_XDG_CONFIG_HOME  # 4.2. default\n    )\n    return Path(xdg_config_home_dir) / DEFAULT_CONFIG_DIRNAME\n\n\nDEFAULT_CONFIG_DIR = get_default_config_dir()\n\n\nclass ConfigFileError(Exception):\n    pass\n\n\ndef read_raw_config(config_type: str, path: Path) -> Dict[str, Any]:\n    try:\n        with path.open(encoding=UTF8) as f:\n            try:\n                return json.load(f)\n            except ValueError as e:\n                raise ConfigFileError(\n                    f'invalid {config_type} file: {e} [{path}]'\n                )\n    except FileNotFoundError:\n        pass\n    except OSError as e:\n        raise ConfigFileError(f'cannot read {config_type} file: {e}')\n\n\nclass BaseConfigDict(dict):\n    name = None\n    helpurl = None\n    about = None\n\n    def __init__(self, path: Path):\n        super().__init__()\n        self.path = path\n\n    def ensure_directory(self):\n        self.path.parent.mkdir(mode=0o700, parents=True, exist_ok=True)\n\n    def is_new(self) -> bool:\n        return not self.path.exists()\n\n    def pre_process_data(self, data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Hook for processing the incoming config data.\"\"\"\n        return data\n\n    def post_process_data(self, data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Hook for processing the outgoing config data.\"\"\"\n        return data\n\n    def load(self):\n        config_type = type(self).__name__.lower()\n        data = read_raw_config(config_type, self.path)\n        if data is not None:\n            data = self.pre_process_data(data)\n            self.update(data)\n\n    def save(self, *, bump_version: bool = False):\n        self.setdefault('__meta__', {})\n        if bump_version or 'httpie' not in self['__meta__']:\n            self['__meta__']['httpie'] = __version__\n        if self.helpurl:\n            self['__meta__']['help'] = self.helpurl\n\n        if self.about:\n            self['__meta__']['about'] = self.about\n\n        self.ensure_directory()\n\n        json_string = json.dumps(\n            obj=self.post_process_data(self),\n            indent=4,\n            sort_keys=True,\n            ensure_ascii=True,\n        )\n        self.path.write_text(json_string + '\\n', encoding=UTF8)\n\n    @property\n    def version(self):\n        return self.get(\n            '__meta__', {}\n        ).get('httpie', __version__)\n\n\nclass Config(BaseConfigDict):\n    FILENAME = 'config.json'\n    DEFAULTS = {\n        'default_options': []\n    }\n\n    def __init__(self, directory: Union[str, Path] = DEFAULT_CONFIG_DIR):\n        self.directory = Path(directory)\n        super().__init__(path=self.directory / self.FILENAME)\n        self.update(self.DEFAULTS)\n\n    @property\n    def default_options(self) -> list:\n        return self['default_options']\n\n    def _configured_path(self, config_option: str, default: str) -> None:\n        return Path(\n            self.get(config_option, self.directory / default)\n        ).expanduser().resolve()\n\n    @property\n    def plugins_dir(self) -> Path:\n        return self._configured_path('plugins_dir', 'plugins')\n\n    @property\n    def version_info_file(self) -> Path:\n        return self._configured_path('version_info_file', 'version_info.json')\n\n    @property\n    def developer_mode(self) -> bool:\n        \"\"\"This is a special setting for the development environment. It is\n        different from the --debug mode in the terms that it might change\n        the behavior for certain parameters (e.g updater system) that\n        we usually ignore.\"\"\"\n\n        return self.get('developer_mode')\n", "httpie/core.py": "import argparse\nimport os\nimport platform\nimport sys\nimport socket\nfrom typing import List, Optional, Union, Callable\n\nimport requests\nfrom pygments import __version__ as pygments_version\nfrom requests import __version__ as requests_version\n\nfrom . import __version__ as httpie_version\nfrom .cli.constants import OUT_REQ_BODY\nfrom .cli.nested_json import NestedJSONSyntaxError\nfrom .client import collect_messages\nfrom .context import Environment, LogLevel\nfrom .downloads import Downloader\nfrom .models import (\n    RequestsMessageKind,\n    OutputOptions\n)\nfrom .output.models import ProcessingOptions\nfrom .output.writer import write_message, write_stream, write_raw_data, MESSAGE_SEPARATOR_BYTES\nfrom .plugins.registry import plugin_manager\nfrom .status import ExitStatus, http_status_to_exit_status\nfrom .utils import unwrap_context\nfrom .internal.update_warnings import check_updates\nfrom .internal.daemon_runner import is_daemon_mode, run_daemon_task\n\n\n# noinspection PyDefaultArgument\ndef raw_main(\n    parser: argparse.ArgumentParser,\n    main_program: Callable[[argparse.Namespace, Environment], ExitStatus],\n    args: List[Union[str, bytes]] = sys.argv,\n    env: Environment = Environment(),\n    use_default_options: bool = True,\n) -> ExitStatus:\n    program_name, *args = args\n    env.program_name = os.path.basename(program_name)\n    args = decode_raw_args(args, env.stdin_encoding)\n\n    if is_daemon_mode(args):\n        return run_daemon_task(env, args)\n\n    plugin_manager.load_installed_plugins(env.config.plugins_dir)\n\n    if use_default_options and env.config.default_options:\n        args = env.config.default_options + args\n\n    include_debug_info = '--debug' in args\n    include_traceback = include_debug_info or '--traceback' in args\n\n    def handle_generic_error(e, annotation=None):\n        msg = str(e)\n        if hasattr(e, 'request'):\n            request = e.request\n            if hasattr(request, 'url'):\n                msg = (\n                    f'{msg} while doing a {request.method}'\n                    f' request to URL: {request.url}'\n                )\n        if annotation:\n            msg += annotation\n        env.log_error(f'{type(e).__name__}: {msg}')\n        if include_traceback:\n            raise\n\n    if include_debug_info:\n        print_debug_info(env)\n        if args == ['--debug']:\n            return ExitStatus.SUCCESS\n\n    exit_status = ExitStatus.SUCCESS\n\n    try:\n        parsed_args = parser.parse_args(\n            args=args,\n            env=env,\n        )\n    except NestedJSONSyntaxError as exc:\n        env.stderr.write(str(exc) + \"\\n\")\n        if include_traceback:\n            raise\n        exit_status = ExitStatus.ERROR\n    except KeyboardInterrupt:\n        env.stderr.write('\\n')\n        if include_traceback:\n            raise\n        exit_status = ExitStatus.ERROR_CTRL_C\n    except SystemExit as e:\n        if e.code != ExitStatus.SUCCESS:\n            env.stderr.write('\\n')\n            if include_traceback:\n                raise\n            exit_status = ExitStatus.ERROR\n    else:\n        check_updates(env)\n        try:\n            exit_status = main_program(\n                args=parsed_args,\n                env=env,\n            )\n        except KeyboardInterrupt:\n            env.stderr.write('\\n')\n            if include_traceback:\n                raise\n            exit_status = ExitStatus.ERROR_CTRL_C\n        except SystemExit as e:\n            if e.code != ExitStatus.SUCCESS:\n                env.stderr.write('\\n')\n                if include_traceback:\n                    raise\n                exit_status = ExitStatus.ERROR\n        except requests.Timeout:\n            exit_status = ExitStatus.ERROR_TIMEOUT\n            env.log_error(f'Request timed out ({parsed_args.timeout}s).')\n        except requests.TooManyRedirects:\n            exit_status = ExitStatus.ERROR_TOO_MANY_REDIRECTS\n            env.log_error(\n                f'Too many redirects'\n                f' (--max-redirects={parsed_args.max_redirects}).'\n            )\n        except requests.exceptions.ConnectionError as exc:\n            annotation = None\n            original_exc = unwrap_context(exc)\n            if isinstance(original_exc, socket.gaierror):\n                if original_exc.errno == socket.EAI_AGAIN:\n                    annotation = '\\nCouldn\u2019t connect to a DNS server. Please check your connection and try again.'\n                elif original_exc.errno == socket.EAI_NONAME:\n                    annotation = '\\nCouldn\u2019t resolve the given hostname. Please check the URL and try again.'\n                propagated_exc = original_exc\n            else:\n                propagated_exc = exc\n\n            handle_generic_error(propagated_exc, annotation=annotation)\n            exit_status = ExitStatus.ERROR\n        except Exception as e:\n            # TODO: Further distinction between expected and unexpected errors.\n            handle_generic_error(e)\n            exit_status = ExitStatus.ERROR\n\n    return exit_status\n\n\ndef main(\n    args: List[Union[str, bytes]] = sys.argv,\n    env: Environment = Environment()\n) -> ExitStatus:\n    \"\"\"\n    The main function.\n\n    Pre-process args, handle some special types of invocations,\n    and run the main program with error handling.\n\n    Return exit status code.\n\n    \"\"\"\n\n    from .cli.definition import parser\n\n    return raw_main(\n        parser=parser,\n        main_program=program,\n        args=args,\n        env=env\n    )\n\n\ndef program(args: argparse.Namespace, env: Environment) -> ExitStatus:\n    \"\"\"\n    The main program without error handling.\n\n    \"\"\"\n    # TODO: Refactor and drastically simplify, especially so that the separator logic is elsewhere.\n    exit_status = ExitStatus.SUCCESS\n    downloader = None\n    initial_request: Optional[requests.PreparedRequest] = None\n    final_response: Optional[requests.Response] = None\n    processing_options = ProcessingOptions.from_raw_args(args)\n\n    def separate():\n        getattr(env.stdout, 'buffer', env.stdout).write(MESSAGE_SEPARATOR_BYTES)\n\n    def request_body_read_callback(chunk: bytes):\n        should_pipe_to_stdout = bool(\n            # Request body output desired\n            OUT_REQ_BODY in args.output_options\n            # & not `.read()` already pre-request (e.g., for  compression)\n            and initial_request\n            # & non-EOF chunk\n            and chunk\n        )\n        if should_pipe_to_stdout:\n            return write_raw_data(\n                env,\n                chunk,\n                processing_options=processing_options,\n                headers=initial_request.headers\n            )\n\n    try:\n        if args.download:\n            args.follow = True  # --download implies --follow.\n            downloader = Downloader(env, output_file=args.output_file, resume=args.download_resume)\n            downloader.pre_request(args.headers)\n        messages = collect_messages(env, args=args,\n                                    request_body_read_callback=request_body_read_callback)\n        force_separator = False\n        prev_with_body = False\n\n        # Process messages as they\u2019re generated\n        for message in messages:\n            output_options = OutputOptions.from_message(message, args.output_options)\n\n            do_write_body = output_options.body\n            if prev_with_body and output_options.any() and (force_separator or not env.stdout_isatty):\n                # Separate after a previous message with body, if needed. See test_tokens.py.\n                separate()\n            force_separator = False\n            if output_options.kind is RequestsMessageKind.REQUEST:\n                if not initial_request:\n                    initial_request = message\n                if output_options.body:\n                    is_streamed_upload = not isinstance(message.body, (str, bytes))\n                    do_write_body = not is_streamed_upload\n                    force_separator = is_streamed_upload and env.stdout_isatty\n            else:\n                final_response = message\n                if args.check_status or downloader:\n                    exit_status = http_status_to_exit_status(http_status=message.status_code, follow=args.follow)\n                    if exit_status != ExitStatus.SUCCESS and (not env.stdout_isatty or args.quiet == 1):\n                        env.log_error(f'HTTP {message.raw.status} {message.raw.reason}', level=LogLevel.WARNING)\n            write_message(\n                requests_message=message,\n                env=env,\n                output_options=output_options._replace(\n                    body=do_write_body\n                ),\n                processing_options=processing_options\n            )\n            prev_with_body = output_options.body\n\n        # Cleanup\n        if force_separator:\n            separate()\n        if downloader and exit_status == ExitStatus.SUCCESS:\n            # Last response body download.\n            download_stream, download_to = downloader.start(\n                initial_url=initial_request.url,\n                final_response=final_response,\n            )\n            write_stream(stream=download_stream, outfile=download_to, flush=False)\n            downloader.finish()\n            if downloader.interrupted:\n                exit_status = ExitStatus.ERROR\n                env.log_error(\n                    f'Incomplete download: size={downloader.status.total_size};'\n                    f' downloaded={downloader.status.downloaded}'\n                )\n        return exit_status\n\n    finally:\n        if downloader and not downloader.finished:\n            downloader.failed()\n        if args.output_file and args.output_file_specified:\n            args.output_file.close()\n\n\ndef print_debug_info(env: Environment):\n    env.stderr.writelines([\n        f'HTTPie {httpie_version}\\n',\n        f'Requests {requests_version}\\n',\n        f'Pygments {pygments_version}\\n',\n        f'Python {sys.version}\\n{sys.executable}\\n',\n        f'{platform.system()} {platform.release()}',\n    ])\n    env.stderr.write('\\n\\n')\n    env.stderr.write(repr(env))\n    env.stderr.write('\\n\\n')\n    env.stderr.write(repr(plugin_manager))\n    env.stderr.write('\\n')\n\n\ndef decode_raw_args(\n    args: List[Union[str, bytes]],\n    stdin_encoding: str\n) -> List[str]:\n    \"\"\"\n    Convert all bytes args to str\n    by decoding them using stdin encoding.\n\n    \"\"\"\n    return [\n        arg.decode(stdin_encoding)\n        if type(arg) is bytes else arg\n        for arg in args\n    ]\n", "httpie/utils.py": "import os\nimport base64\nimport json\nimport mimetypes\nimport re\nimport sys\nimport time\nimport tempfile\nimport sysconfig\n\nfrom collections import OrderedDict\nfrom contextlib import contextmanager\nfrom http.cookiejar import parse_ns_headers\nfrom pathlib import Path\nfrom pprint import pformat\nfrom urllib.parse import urlsplit\nfrom typing import Any, List, Optional, Tuple, Generator, Callable, Iterable, IO, TypeVar\n\nimport requests.auth\n\nRE_COOKIE_SPLIT = re.compile(r', (?=[^ ;]+=)')\nItem = Tuple[str, Any]\nItems = List[Item]\nT = TypeVar(\"T\")\n\n\nclass JsonDictPreservingDuplicateKeys(OrderedDict):\n    \"\"\"A specialized JSON dict preserving duplicate keys.\"\"\"\n\n    # Python versions prior to 3.8 suffer from an issue with multiple keys with the same name.\n    # `json.dumps(obj, indent=N, sort_keys=True)` will output sorted keys when they are unique, and\n    # duplicate keys will be outputted as they were defined in the original data.\n    # See <https://bugs.python.org/issue23493#msg400929> for the behavior change between Python versions.\n    SUPPORTS_SORTING = sys.version_info >= (3, 8)\n\n    def __init__(self, items: Items):\n        self._items = items\n        self._ensure_items_used()\n\n    def _ensure_items_used(self) -> None:\n        \"\"\"HACK: Force `json.dumps()` to use `self.items()` instead of an empty dict.\n\n        Two JSON encoders are available on CPython: pure-Python (1) and C (2) implementations.\n\n        (1) The pure-python implementation will do a simple `if not dict: return '{}'`,\n        and we could fake that check by implementing the `__bool__()` method.\n        Source:\n            - <https://github.com/python/cpython/blob/9d318ad/Lib/json/encoder.py#L334-L336>\n\n        (2) On the other hand, the C implementation will do a check on the number of\n        items contained inside the dict, using a verification on `dict->ma_used`, which\n        is updated only when an item is added/removed from the dict. For that case,\n        there is no workaround but to add an item into the dict.\n        Sources:\n            - <https://github.com/python/cpython/blob/9d318ad/Modules/_json.c#L1581-L1582>\n            - <https://github.com/python/cpython/blob/9d318ad/Include/cpython/dictobject.h#L53>\n            - <https://github.com/python/cpython/blob/9d318ad/Include/cpython/dictobject.h#L17-L18>\n\n        To please both implementations, we simply add one item to the dict.\n\n        \"\"\"\n        if self._items:\n            self['__hack__'] = '__hack__'\n\n    def items(self) -> Items:\n        \"\"\"Return all items, duplicate ones included.\n\n        \"\"\"\n        return self._items\n\n\ndef load_json_preserve_order_and_dupe_keys(s):\n    return json.loads(s, object_pairs_hook=JsonDictPreservingDuplicateKeys)\n\n\ndef repr_dict(d: dict) -> str:\n    return pformat(d)\n\n\ndef humanize_bytes(n, precision=2):\n    # Author: Doug Latornell\n    # Licence: MIT\n    # URL: https://code.activestate.com/recipes/577081/\n    \"\"\"Return a humanized string representation of a number of bytes.\n\n    >>> humanize_bytes(1)\n    '1 B'\n    >>> humanize_bytes(1024, precision=1)\n    '1.0 kB'\n    >>> humanize_bytes(1024 * 123, precision=1)\n    '123.0 kB'\n    >>> humanize_bytes(1024 * 12342, precision=1)\n    '12.1 MB'\n    >>> humanize_bytes(1024 * 12342, precision=2)\n    '12.05 MB'\n    >>> humanize_bytes(1024 * 1234, precision=2)\n    '1.21 MB'\n    >>> humanize_bytes(1024 * 1234 * 1111, precision=2)\n    '1.31 GB'\n    >>> humanize_bytes(1024 * 1234 * 1111, precision=1)\n    '1.3 GB'\n\n    \"\"\"\n    abbrevs = [\n        (1 << 50, 'PB'),\n        (1 << 40, 'TB'),\n        (1 << 30, 'GB'),\n        (1 << 20, 'MB'),\n        (1 << 10, 'kB'),\n        (1, 'B')\n    ]\n\n    if n == 1:\n        return '1 B'\n\n    for factor, suffix in abbrevs:\n        if n >= factor:\n            break\n\n    # noinspection PyUnboundLocalVariable\n    return f'{n / factor:.{precision}f} {suffix}'\n\n\nclass ExplicitNullAuth(requests.auth.AuthBase):\n    \"\"\"Forces requests to ignore the ``.netrc``.\n    <https://github.com/psf/requests/issues/2773#issuecomment-174312831>\n    \"\"\"\n\n    def __call__(self, r):\n        return r\n\n\ndef get_content_type(filename):\n    \"\"\"\n    Return the content type for ``filename`` in format appropriate\n    for Content-Type headers, or ``None`` if the file type is unknown\n    to ``mimetypes``.\n\n    \"\"\"\n    return mimetypes.guess_type(filename, strict=False)[0]\n\n\ndef split_cookies(cookies):\n    \"\"\"\n    When ``requests`` stores cookies in ``response.headers['Set-Cookie']``\n    it concatenates all of them through ``, ``.\n\n    This function splits cookies apart being careful to not to\n    split on ``, `` which may be part of cookie value.\n    \"\"\"\n    if not cookies:\n        return []\n    return RE_COOKIE_SPLIT.split(cookies)\n\n\ndef get_expired_cookies(\n    cookies: str,\n    now: float = None\n) -> List[dict]:\n\n    now = now or time.time()\n\n    def is_expired(expires: Optional[float]) -> bool:\n        return expires is not None and expires <= now\n\n    attr_sets: List[Tuple[str, str]] = parse_ns_headers(\n        split_cookies(cookies)\n    )\n\n    cookies = [\n        # The first attr name is the cookie name.\n        dict(attrs[1:], name=attrs[0][0])\n        for attrs in attr_sets\n    ]\n\n    _max_age_to_expires(cookies=cookies, now=now)\n\n    return [\n        {\n            'name': cookie['name'],\n            'path': cookie.get('path', '/')\n        }\n        for cookie in cookies\n        if is_expired(expires=cookie.get('expires'))\n    ]\n\n\ndef _max_age_to_expires(cookies, now):\n    \"\"\"\n    Translate `max-age` into `expires` for Requests to take it into account.\n\n    HACK/FIXME: <https://github.com/psf/requests/issues/5743>\n\n    \"\"\"\n    for cookie in cookies:\n        if 'expires' in cookie:\n            continue\n        max_age = cookie.get('max-age')\n        if max_age and max_age.isdigit():\n            cookie['expires'] = now + float(max_age)\n\n\ndef parse_content_type_header(header):\n    \"\"\"Borrowed from requests.\"\"\"\n    tokens = header.split(';')\n    content_type, params = tokens[0].strip(), tokens[1:]\n    params_dict = {}\n    items_to_strip = \"\\\"' \"\n    for param in params:\n        param = param.strip()\n        if param:\n            key, value = param, True\n            index_of_equals = param.find(\"=\")\n            if index_of_equals != -1:\n                key = param[:index_of_equals].strip(items_to_strip)\n                value = param[index_of_equals + 1:].strip(items_to_strip)\n            params_dict[key.lower()] = value\n    return content_type, params_dict\n\n\ndef as_site(path: Path, **extra_vars) -> Path:\n    site_packages_path = sysconfig.get_path(\n        'purelib',\n        vars={'base': str(path), **extra_vars}\n    )\n    return Path(site_packages_path)\n\n\ndef get_site_paths(path: Path) -> Iterable[Path]:\n    from httpie.compat import (\n        MIN_SUPPORTED_PY_VERSION,\n        MAX_SUPPORTED_PY_VERSION,\n        is_frozen\n    )\n\n    if is_frozen:\n        [major, min_minor] = MIN_SUPPORTED_PY_VERSION\n        [major, max_minor] = MAX_SUPPORTED_PY_VERSION\n        for minor in range(min_minor, max_minor + 1):\n            yield as_site(\n                path,\n                py_version_short=f'{major}.{minor}'\n            )\n    else:\n        yield as_site(path)\n\n\ndef split_iterable(iterable: Iterable[T], key: Callable[[T], bool]) -> Tuple[List[T], List[T]]:\n    left, right = [], []\n    for item in iterable:\n        if key(item):\n            left.append(item)\n        else:\n            right.append(item)\n    return left, right\n\n\ndef unwrap_context(exc: Exception) -> Optional[Exception]:\n    context = exc.__context__\n    if isinstance(context, Exception):\n        return unwrap_context(context)\n    else:\n        return exc\n\n\ndef url_as_host(url: str) -> str:\n    return urlsplit(url).netloc.split('@')[-1]\n\n\nclass LockFileError(ValueError):\n    pass\n\n\n@contextmanager\ndef open_with_lockfile(file: Path, *args, **kwargs) -> Generator[IO[Any], None, None]:\n    file_id = base64.b64encode(os.fsencode(file)).decode()\n    target_file = Path(tempfile.gettempdir()) / file_id\n\n    # Have an atomic-like touch here, so we'll tighten the possibility of\n    # a race occurring between multiple processes accessing the same file.\n    try:\n        target_file.touch(exist_ok=False)\n    except FileExistsError as exc:\n        raise LockFileError(\"Can't modify a locked file.\") from exc\n\n    try:\n        with open(file, *args, **kwargs) as stream:\n            yield stream\n    finally:\n        target_file.unlink()\n\n\ndef is_version_greater(version_1: str, version_2: str) -> bool:\n    # In an ideal scenario, we would depend on `packaging` in order\n    # to offer PEP 440 compatible parsing. But since it might not be\n    # commonly available for outside packages, and since we are only\n    # going to parse HTTPie's own version it should be fine to compare\n    # this in a SemVer subset fashion.\n\n    def split_version(version: str) -> Tuple[int, ...]:\n        parts = []\n        for part in version.split('.')[:3]:\n            try:\n                parts.append(int(part))\n            except ValueError:\n                break\n        return tuple(parts)\n\n    return split_version(version_1) > split_version(version_2)\n", "httpie/adapters.py": "from httpie.cli.dicts import HTTPHeadersDict\nfrom requests.adapters import HTTPAdapter\n\n\nclass HTTPieHTTPAdapter(HTTPAdapter):\n\n    def build_response(self, req, resp):\n        \"\"\"Wrap the original headers with the `HTTPHeadersDict`\n        to preserve multiple headers that have the same name\"\"\"\n\n        response = super().build_response(req, resp)\n        response.headers = HTTPHeadersDict(getattr(resp, 'headers', {}))\n        return response\n", "httpie/models.py": "from time import monotonic\n\nimport requests\nfrom urllib3.util import SKIP_HEADER, SKIPPABLE_HEADERS\n\nfrom enum import Enum, auto\nfrom typing import Iterable, Union, NamedTuple\nfrom urllib.parse import urlsplit\n\nfrom .cli.constants import (\n    OUT_REQ_BODY,\n    OUT_REQ_HEAD,\n    OUT_RESP_BODY,\n    OUT_RESP_HEAD,\n    OUT_RESP_META\n)\nfrom .compat import cached_property\nfrom .utils import split_cookies, parse_content_type_header\n\nELAPSED_TIME_LABEL = 'Elapsed time'\n\n\nclass HTTPMessage:\n    \"\"\"Abstract class for HTTP messages.\"\"\"\n\n    def __init__(self, orig):\n        self._orig = orig\n\n    def iter_body(self, chunk_size: int) -> Iterable[bytes]:\n        \"\"\"Return an iterator over the body.\"\"\"\n        raise NotImplementedError\n\n    def iter_lines(self, chunk_size: int) -> Iterable[bytes]:\n        \"\"\"Return an iterator over the body yielding (`line`, `line_feed`).\"\"\"\n        raise NotImplementedError\n\n    @property\n    def headers(self) -> str:\n        \"\"\"Return a `str` with the message's headers.\"\"\"\n        raise NotImplementedError\n\n    @property\n    def metadata(self) -> str:\n        \"\"\"Return metadata about the current message.\"\"\"\n        raise NotImplementedError\n\n    @cached_property\n    def encoding(self) -> str:\n        ct, params = parse_content_type_header(self.content_type)\n        return params.get('charset', '')\n\n    @property\n    def content_type(self) -> str:\n        \"\"\"Return the message content type.\"\"\"\n        ct = self._orig.headers.get('Content-Type', '')\n        if not isinstance(ct, str):\n            ct = ct.decode()\n        return ct\n\n\nclass HTTPResponse(HTTPMessage):\n    \"\"\"A :class:`requests.models.Response` wrapper.\"\"\"\n\n    def iter_body(self, chunk_size=1):\n        return self._orig.iter_content(chunk_size=chunk_size)\n\n    def iter_lines(self, chunk_size):\n        return ((line, b'\\n') for line in self._orig.iter_lines(chunk_size))\n\n    @property\n    def headers(self):\n        original = self._orig\n        status_line = f'HTTP/{self.version} {original.status_code} {original.reason}'\n        headers = [status_line]\n        headers.extend(\n            ': '.join(header)\n            for header in original.headers.items()\n            if header[0] != 'Set-Cookie'\n        )\n        headers.extend(\n            f'Set-Cookie: {cookie}'\n            for header, value in original.headers.items()\n            for cookie in split_cookies(value)\n            if header == 'Set-Cookie'\n        )\n        return '\\r\\n'.join(headers)\n\n    @property\n    def metadata(self) -> str:\n        data = {}\n        time_to_parse_headers = self._orig.elapsed.total_seconds()\n        # noinspection PyProtectedMember\n        time_since_headers_parsed = monotonic() - self._orig._httpie_headers_parsed_at\n        time_elapsed = time_to_parse_headers + time_since_headers_parsed\n        # data['Headers time'] = str(round(time_to_parse_headers, 5)) + 's'\n        # data['Body time'] = str(round(time_since_headers_parsed, 5)) + 's'\n        data[ELAPSED_TIME_LABEL] = str(round(time_elapsed, 10)) + 's'\n        return '\\n'.join(\n            f'{key}: {value}'\n            for key, value in data.items()\n        )\n\n    @property\n    def version(self) -> str:\n        \"\"\"\n        Return the HTTP version used by the server, e.g. '1.1'.\n\n        Assume HTTP/1.1 if version is not available.\n\n        \"\"\"\n        mapping = {\n            9: '0.9',\n            10: '1.0',\n            11: '1.1',\n            20: '2.0',\n        }\n        fallback = 11\n        version = None\n        try:\n            raw = self._orig.raw\n            if getattr(raw, '_original_response', None):\n                version = raw._original_response.version\n            else:\n                version = raw.version\n        except AttributeError:\n            pass\n        return mapping[version or fallback]\n\n\nclass HTTPRequest(HTTPMessage):\n    \"\"\"A :class:`requests.models.Request` wrapper.\"\"\"\n\n    def iter_body(self, chunk_size):\n        yield self.body\n\n    def iter_lines(self, chunk_size):\n        yield self.body, b''\n\n    @property\n    def headers(self):\n        url = urlsplit(self._orig.url)\n\n        request_line = '{method} {path}{query} HTTP/1.1'.format(\n            method=self._orig.method,\n            path=url.path or '/',\n            query=f'?{url.query}' if url.query else ''\n        )\n\n        headers = self._orig.headers.copy()\n        if 'Host' not in self._orig.headers:\n            headers['Host'] = url.netloc.split('@')[-1]\n\n        headers = [\n            f'{name}: {value if isinstance(value, str) else value.decode()}'\n            for name, value in headers.items()\n            if not (name.lower() in SKIPPABLE_HEADERS and value == SKIP_HEADER)\n        ]\n\n        headers.insert(0, request_line)\n        headers = '\\r\\n'.join(headers).strip()\n        return headers\n\n    @property\n    def body(self):\n        body = self._orig.body\n        if isinstance(body, str):\n            # Happens with JSON/form request data parsed from the command line.\n            body = body.encode()\n        return body or b''\n\n\nRequestsMessage = Union[requests.PreparedRequest, requests.Response]\n\n\nclass RequestsMessageKind(Enum):\n    REQUEST = auto()\n    RESPONSE = auto()\n\n\ndef infer_requests_message_kind(message: RequestsMessage) -> RequestsMessageKind:\n    if isinstance(message, requests.PreparedRequest):\n        return RequestsMessageKind.REQUEST\n    elif isinstance(message, requests.Response):\n        return RequestsMessageKind.RESPONSE\n    else:\n        raise TypeError(f\"Unexpected message type: {type(message).__name__}\")\n\n\nOPTION_TO_PARAM = {\n    RequestsMessageKind.REQUEST: {\n        'headers': OUT_REQ_HEAD,\n        'body': OUT_REQ_BODY,\n    },\n    RequestsMessageKind.RESPONSE: {\n        'headers': OUT_RESP_HEAD,\n        'body': OUT_RESP_BODY,\n        'meta': OUT_RESP_META\n    }\n}\n\n\nclass OutputOptions(NamedTuple):\n    kind: RequestsMessageKind\n    headers: bool\n    body: bool\n    meta: bool = False\n\n    def any(self):\n        return (\n            self.headers\n            or self.body\n            or self.meta\n        )\n\n    @classmethod\n    def from_message(\n        cls,\n        message: RequestsMessage,\n        raw_args: str = '',\n        **kwargs\n    ):\n        kind = infer_requests_message_kind(message)\n\n        options = {\n            option: param in raw_args\n            for option, param in OPTION_TO_PARAM[kind].items()\n        }\n        options.update(kwargs)\n\n        return cls(\n            kind=kind,\n            **options\n        )\n", "httpie/downloads.py": "\"\"\"\nDownload mode implementation.\n\n\"\"\"\nimport mimetypes\nimport os\nimport re\nfrom mailbox import Message\nfrom time import monotonic\nfrom typing import IO, Optional, Tuple\nfrom urllib.parse import urlsplit\n\nimport requests\n\nfrom .models import HTTPResponse, OutputOptions\nfrom .output.streams import RawStream\nfrom .context import Environment\n\n\nPARTIAL_CONTENT = 206\n\n\nclass ContentRangeError(ValueError):\n    pass\n\n\ndef parse_content_range(content_range: str, resumed_from: int) -> int:\n    \"\"\"\n    Parse and validate Content-Range header.\n\n    <https://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html>\n\n    :param content_range: the value of a Content-Range response header\n                          eg. \"bytes 21010-47021/47022\"\n    :param resumed_from: first byte pos. from the Range request header\n    :return: total size of the response body when fully downloaded.\n\n    \"\"\"\n    if content_range is None:\n        raise ContentRangeError('Missing Content-Range')\n\n    pattern = (\n        r'^bytes (?P<first_byte_pos>\\d+)-(?P<last_byte_pos>\\d+)'\n        r'/(\\*|(?P<instance_length>\\d+))$'\n    )\n    match = re.match(pattern, content_range)\n\n    if not match:\n        raise ContentRangeError(\n            f'Invalid Content-Range format {content_range!r}')\n\n    content_range_dict = match.groupdict()\n    first_byte_pos = int(content_range_dict['first_byte_pos'])\n    last_byte_pos = int(content_range_dict['last_byte_pos'])\n    instance_length = (\n        int(content_range_dict['instance_length'])\n        if content_range_dict['instance_length']\n        else None\n    )\n\n    # \"A byte-content-range-spec with a byte-range-resp-spec whose\n    # last- byte-pos value is less than its first-byte-pos value,\n    # or whose instance-length value is less than or equal to its\n    # last-byte-pos value, is invalid. The recipient of an invalid\n    # byte-content-range- spec MUST ignore it and any content\n    # transferred along with it.\"\n    if (first_byte_pos > last_byte_pos\n        or (instance_length is not None\n            and instance_length <= last_byte_pos)):\n        raise ContentRangeError(\n            f'Invalid Content-Range returned: {content_range!r}')\n\n    if (first_byte_pos != resumed_from\n        or (instance_length is not None\n            and last_byte_pos + 1 != instance_length)):\n        # Not what we asked for.\n        raise ContentRangeError(\n            f'Unexpected Content-Range returned ({content_range!r})'\n            f' for the requested Range (\"bytes={resumed_from}-\")'\n        )\n\n    return last_byte_pos + 1\n\n\ndef filename_from_content_disposition(\n    content_disposition: str\n) -> Optional[str]:\n    \"\"\"\n    Extract and validate filename from a Content-Disposition header.\n\n    :param content_disposition: Content-Disposition value\n    :return: the filename if present and valid, otherwise `None`\n\n    \"\"\"\n    # attachment; filename=jakubroztocil-httpie-0.4.1-20-g40bd8f6.tar.gz\n\n    msg = Message(f'Content-Disposition: {content_disposition}')\n    filename = msg.get_filename()\n    if filename:\n        # Basic sanitation.\n        filename = os.path.basename(filename).lstrip('.').strip()\n        if filename:\n            return filename\n\n\ndef filename_from_url(url: str, content_type: Optional[str]) -> str:\n    fn = urlsplit(url).path.rstrip('/')\n    fn = os.path.basename(fn) if fn else 'index'\n    if '.' not in fn and content_type:\n        content_type = content_type.split(';')[0]\n        if content_type == 'text/plain':\n            # mimetypes returns '.ksh'\n            ext = '.txt'\n        else:\n            ext = mimetypes.guess_extension(content_type)\n\n        if ext == '.htm':\n            ext = '.html'\n\n        if ext:\n            fn += ext\n\n    return fn\n\n\ndef trim_filename(filename: str, max_len: int) -> str:\n    if len(filename) > max_len:\n        trim_by = len(filename) - max_len\n        name, ext = os.path.splitext(filename)\n        if trim_by >= len(name):\n            filename = filename[:-trim_by]\n        else:\n            filename = name[:-trim_by] + ext\n    return filename\n\n\ndef get_filename_max_length(directory: str) -> int:\n    max_len = 255\n    if hasattr(os, 'pathconf') and 'PC_NAME_MAX' in os.pathconf_names:\n        max_len = os.pathconf(directory, 'PC_NAME_MAX')\n    return max_len\n\n\ndef trim_filename_if_needed(filename: str, directory='.', extra=0) -> str:\n    max_len = get_filename_max_length(directory) - extra\n    if len(filename) > max_len:\n        filename = trim_filename(filename, max_len)\n    return filename\n\n\ndef get_unique_filename(filename: str, exists=os.path.exists) -> str:\n    attempt = 0\n    while True:\n        suffix = f'-{attempt}' if attempt > 0 else ''\n        try_filename = trim_filename_if_needed(filename, extra=len(suffix))\n        try_filename += suffix\n        if not exists(try_filename):\n            return try_filename\n        attempt += 1\n\n\nclass Downloader:\n\n    def __init__(\n        self,\n        env: Environment,\n        output_file: IO = None,\n        resume: bool = False\n    ):\n        \"\"\"\n        :param resume: Should the download resume if partial download\n                       already exists.\n\n        :param output_file: The file to store response body in. If not\n                            provided, it will be guessed from the response.\n\n        :param progress_file: Where to report download progress.\n\n        \"\"\"\n        self.finished = False\n        self.status = DownloadStatus(env=env)\n        self._output_file = output_file\n        self._resume = resume\n        self._resumed_from = 0\n\n    def pre_request(self, request_headers: dict):\n        \"\"\"Called just before the HTTP request is sent.\n\n        Might alter `request_headers`.\n\n        \"\"\"\n        # Ask the server not to encode the content so that we can resume, etc.\n        request_headers['Accept-Encoding'] = 'identity'\n        if self._resume:\n            bytes_have = os.path.getsize(self._output_file.name)\n            if bytes_have:\n                # Set ``Range`` header to resume the download\n                # TODO: Use \"If-Range: mtime\" to make sure it's fresh?\n                request_headers['Range'] = f'bytes={bytes_have}-'\n                self._resumed_from = bytes_have\n\n    def start(\n        self,\n        initial_url: str,\n        final_response: requests.Response\n    ) -> Tuple[RawStream, IO]:\n        \"\"\"\n        Initiate and return a stream for `response` body  with progress\n        callback attached. Can be called only once.\n\n        :param initial_url: The original requested URL\n        :param final_response: Initiated response object with headers already fetched\n\n        :return: RawStream, output_file\n\n        \"\"\"\n        assert not self.status.time_started\n\n        # FIXME: some servers still might sent Content-Encoding: gzip\n        # <https://github.com/httpie/cli/issues/423>\n        try:\n            total_size = int(final_response.headers['Content-Length'])\n        except (KeyError, ValueError, TypeError):\n            total_size = None\n\n        if not self._output_file:\n            self._output_file = self._get_output_file_from_response(\n                initial_url=initial_url,\n                final_response=final_response,\n            )\n        else:\n            # `--output, -o` provided\n            if self._resume and final_response.status_code == PARTIAL_CONTENT:\n                total_size = parse_content_range(\n                    final_response.headers.get('Content-Range'),\n                    self._resumed_from\n                )\n\n            else:\n                self._resumed_from = 0\n                try:\n                    self._output_file.seek(0)\n                    self._output_file.truncate()\n                except OSError:\n                    pass  # stdout\n\n        output_options = OutputOptions.from_message(final_response, headers=False, body=True)\n        stream = RawStream(\n            msg=HTTPResponse(final_response),\n            output_options=output_options,\n            on_body_chunk_downloaded=self.chunk_downloaded,\n        )\n\n        self.status.started(\n            output_file=self._output_file,\n            resumed_from=self._resumed_from,\n            total_size=total_size\n        )\n\n        return stream, self._output_file\n\n    def finish(self):\n        assert not self.finished\n        self.finished = True\n        self.status.finished()\n\n    def failed(self):\n        self.status.terminate()\n\n    @property\n    def interrupted(self) -> bool:\n        return (\n            self.finished\n            and self.status.total_size\n            and self.status.total_size != self.status.downloaded\n        )\n\n    def chunk_downloaded(self, chunk: bytes):\n        \"\"\"\n        A download progress callback.\n\n        :param chunk: A chunk of response body data that has just\n                      been downloaded and written to the output.\n\n        \"\"\"\n        self.status.chunk_downloaded(len(chunk))\n\n    @staticmethod\n    def _get_output_file_from_response(\n        initial_url: str,\n        final_response: requests.Response,\n    ) -> IO:\n        # Output file not specified. Pick a name that doesn't exist yet.\n        filename = None\n        if 'Content-Disposition' in final_response.headers:\n            filename = filename_from_content_disposition(\n                final_response.headers['Content-Disposition'])\n        if not filename:\n            filename = filename_from_url(\n                url=initial_url,\n                content_type=final_response.headers.get('Content-Type'),\n            )\n        unique_filename = get_unique_filename(filename)\n        return open(unique_filename, buffering=0, mode='a+b')\n\n\nclass DownloadStatus:\n    \"\"\"Holds details about the download status.\"\"\"\n\n    def __init__(self, env):\n        self.env = env\n        self.downloaded = 0\n        self.total_size = None\n        self.resumed_from = 0\n        self.time_started = None\n        self.time_finished = None\n\n    def started(self, output_file, resumed_from=0, total_size=None):\n        assert self.time_started is None\n        self.total_size = total_size\n        self.downloaded = self.resumed_from = resumed_from\n        self.time_started = monotonic()\n        self.start_display(output_file=output_file)\n\n    def start_display(self, output_file):\n        from httpie.output.ui.rich_progress import (\n            DummyDisplay,\n            StatusDisplay,\n            ProgressDisplay\n        )\n\n        message = f'Downloading to {output_file.name}'\n        if self.env.show_displays:\n            if self.total_size is None:\n                # Rich does not support progress bars without a total\n                # size given. Instead we use status objects.\n                self.display = StatusDisplay(self.env)\n            else:\n                self.display = ProgressDisplay(self.env)\n        else:\n            self.display = DummyDisplay(self.env)\n\n        self.display.start(\n            total=self.total_size,\n            at=self.downloaded,\n            description=message\n        )\n\n    def chunk_downloaded(self, size):\n        assert self.time_finished is None\n        self.downloaded += size\n        self.display.update(size)\n\n    @property\n    def has_finished(self):\n        return self.time_finished is not None\n\n    @property\n    def time_spent(self):\n        if (\n            self.time_started is not None\n            and self.time_finished is not None\n        ):\n            return self.time_finished - self.time_started\n        else:\n            return None\n\n    def finished(self):\n        assert self.time_started is not None\n        assert self.time_finished is None\n        self.time_finished = monotonic()\n        if hasattr(self, 'display'):\n            self.display.stop(self.time_spent)\n\n    def terminate(self):\n        if hasattr(self, 'display'):\n            self.display.stop(self.time_spent)\n", "httpie/client.py": "import argparse\nimport http.client\nimport json\nimport sys\nfrom contextlib import contextmanager\nfrom time import monotonic\nfrom typing import Any, Dict, Callable, Iterable\nfrom urllib.parse import urlparse, urlunparse\n\nimport requests\n# noinspection PyPackageRequirements\nimport urllib3\nfrom urllib3.util import SKIP_HEADER, SKIPPABLE_HEADERS\n\nfrom . import __version__\nfrom .adapters import HTTPieHTTPAdapter\nfrom .cli.constants import HTTP_OPTIONS\nfrom .cli.dicts import HTTPHeadersDict\nfrom .cli.nested_json import unwrap_top_level_list_if_needed\nfrom .context import Environment\nfrom .encoding import UTF8\nfrom .models import RequestsMessage\nfrom .plugins.registry import plugin_manager\nfrom .sessions import get_httpie_session\nfrom .ssl_ import AVAILABLE_SSL_VERSION_ARG_MAPPING, HTTPieCertificate, HTTPieHTTPSAdapter\nfrom .uploads import (\n    compress_request, prepare_request_body,\n    get_multipart_data_and_content_type,\n)\nfrom .utils import get_expired_cookies, repr_dict\n\n\nurllib3.disable_warnings()\n\nFORM_CONTENT_TYPE = f'application/x-www-form-urlencoded; charset={UTF8}'\nJSON_CONTENT_TYPE = 'application/json'\nJSON_ACCEPT = f'{JSON_CONTENT_TYPE}, */*;q=0.5'\nDEFAULT_UA = f'HTTPie/{__version__}'\n\nIGNORE_CONTENT_LENGTH_METHODS = frozenset([HTTP_OPTIONS])\n\n\ndef collect_messages(\n    env: Environment,\n    args: argparse.Namespace,\n    request_body_read_callback: Callable[[bytes], None] = None,\n) -> Iterable[RequestsMessage]:\n    httpie_session = None\n    httpie_session_headers = None\n    if args.session or args.session_read_only:\n        httpie_session = get_httpie_session(\n            env=env,\n            config_dir=env.config.directory,\n            session_name=args.session or args.session_read_only,\n            host=args.headers.get('Host'),\n            url=args.url,\n        )\n        httpie_session_headers = httpie_session.headers\n\n    request_kwargs = make_request_kwargs(\n        env,\n        args=args,\n        base_headers=httpie_session_headers,\n        request_body_read_callback=request_body_read_callback\n    )\n    send_kwargs = make_send_kwargs(args)\n    send_kwargs_mergeable_from_env = make_send_kwargs_mergeable_from_env(args)\n    requests_session = build_requests_session(\n        ssl_version=args.ssl_version,\n        ciphers=args.ciphers,\n        verify=bool(send_kwargs_mergeable_from_env['verify'])\n    )\n\n    if httpie_session:\n        httpie_session.update_headers(request_kwargs['headers'])\n        requests_session.cookies = httpie_session.cookies\n        if args.auth_plugin:\n            # Save auth from CLI to HTTPie session.\n            httpie_session.auth = {\n                'type': args.auth_plugin.auth_type,\n                'raw_auth': args.auth_plugin.raw_auth,\n            }\n        elif httpie_session.auth:\n            # Apply auth from HTTPie session\n            request_kwargs['auth'] = httpie_session.auth\n\n    if args.debug:\n        # TODO: reflect the split between request and send kwargs.\n        dump_request(request_kwargs)\n\n    request = requests.Request(**request_kwargs)\n    prepared_request = requests_session.prepare_request(request)\n    transform_headers(request, prepared_request)\n    if args.path_as_is:\n        prepared_request.url = ensure_path_as_is(\n            orig_url=args.url,\n            prepped_url=prepared_request.url,\n        )\n    if args.compress and prepared_request.body:\n        compress_request(\n            request=prepared_request,\n            always=args.compress > 1,\n        )\n    response_count = 0\n    expired_cookies = []\n    while prepared_request:\n        yield prepared_request\n        if not args.offline:\n            send_kwargs_merged = requests_session.merge_environment_settings(\n                url=prepared_request.url,\n                **send_kwargs_mergeable_from_env,\n            )\n            with max_headers(args.max_headers):\n                response = requests_session.send(\n                    request=prepared_request,\n                    **send_kwargs_merged,\n                    **send_kwargs,\n                )\n            response._httpie_headers_parsed_at = monotonic()\n            expired_cookies += get_expired_cookies(\n                response.headers.get('Set-Cookie', '')\n            )\n\n            response_count += 1\n            if response.next:\n                if args.max_redirects and response_count == args.max_redirects:\n                    raise requests.TooManyRedirects\n                if args.follow:\n                    prepared_request = response.next\n                    if args.all:\n                        yield response\n                    continue\n            yield response\n        break\n\n    if httpie_session:\n        if httpie_session.is_new() or not args.session_read_only:\n            httpie_session.cookies = requests_session.cookies\n            httpie_session.remove_cookies(expired_cookies)\n            httpie_session.save()\n\n\n# noinspection PyProtectedMember\n@contextmanager\ndef max_headers(limit):\n    # <https://github.com/httpie/cli/issues/802>\n    # noinspection PyUnresolvedReferences\n    orig = http.client._MAXHEADERS\n    http.client._MAXHEADERS = limit or float('Inf')\n    try:\n        yield\n    finally:\n        http.client._MAXHEADERS = orig\n\n\ndef build_requests_session(\n    verify: bool,\n    ssl_version: str = None,\n    ciphers: str = None,\n) -> requests.Session:\n    requests_session = requests.Session()\n\n    # Install our adapter.\n    http_adapter = HTTPieHTTPAdapter()\n    https_adapter = HTTPieHTTPSAdapter(\n        ciphers=ciphers,\n        verify=verify,\n        ssl_version=(\n            AVAILABLE_SSL_VERSION_ARG_MAPPING[ssl_version]\n            if ssl_version else None\n        ),\n    )\n    requests_session.mount('http://', http_adapter)\n    requests_session.mount('https://', https_adapter)\n\n    # Install adapters from plugins.\n    for plugin_cls in plugin_manager.get_transport_plugins():\n        transport_plugin = plugin_cls()\n        requests_session.mount(\n            prefix=transport_plugin.prefix,\n            adapter=transport_plugin.get_adapter(),\n        )\n\n    return requests_session\n\n\ndef dump_request(kwargs: dict):\n    sys.stderr.write(\n        f'\\n>>> requests.request(**{repr_dict(kwargs)})\\n\\n')\n\n\ndef finalize_headers(headers: HTTPHeadersDict) -> HTTPHeadersDict:\n    final_headers = HTTPHeadersDict()\n    for name, value in headers.items():\n        if value is not None:\n            # \u201cleading or trailing LWS MAY be removed without\n            # changing the semantics of the field value\u201d\n            # <https://www.w3.org/Protocols/rfc2616/rfc2616-sec4.html>\n            # Also, requests raises `InvalidHeader` for leading spaces.\n            value = value.strip()\n            if isinstance(value, str):\n                # See <https://github.com/httpie/cli/issues/212>\n                value = value.encode()\n        elif name.lower() in SKIPPABLE_HEADERS:\n            # Some headers get overwritten by urllib3 when set to `None`\n            # and should be replaced with the `SKIP_HEADER` constant.\n            value = SKIP_HEADER\n        final_headers.add(name, value)\n    return final_headers\n\n\ndef transform_headers(\n    request: requests.Request,\n    prepared_request: requests.PreparedRequest\n) -> None:\n    \"\"\"Apply various transformations on top of the `prepared_requests`'s\n    headers to change the request prepreation behavior.\"\"\"\n\n    # Remove 'Content-Length' when it is misplaced by requests.\n    if (\n        prepared_request.method in IGNORE_CONTENT_LENGTH_METHODS\n        and prepared_request.headers.get('Content-Length') == '0'\n        and request.headers.get('Content-Length') != '0'\n    ):\n        prepared_request.headers.pop('Content-Length')\n\n    apply_missing_repeated_headers(\n        request.headers,\n        prepared_request\n    )\n\n\ndef apply_missing_repeated_headers(\n    original_headers: HTTPHeadersDict,\n    prepared_request: requests.PreparedRequest\n) -> None:\n    \"\"\"Update the given `prepared_request`'s headers with the original\n    ones. This allows the requests to be prepared as usual, and then later\n    merged with headers that are specified multiple times.\"\"\"\n\n    new_headers = HTTPHeadersDict(prepared_request.headers)\n    for prepared_name, prepared_value in prepared_request.headers.items():\n        if prepared_name not in original_headers:\n            continue\n\n        original_keys, original_values = zip(*filter(\n            lambda item: item[0].casefold() == prepared_name.casefold(),\n            original_headers.items()\n        ))\n\n        if prepared_value not in original_values:\n            # If the current value is not among the initial values\n            # set for this field, then it means that this field got\n            # overridden on the way, and we should preserve it.\n            continue\n\n        new_headers.popone(prepared_name)\n        new_headers.update(zip(original_keys, original_values))\n\n    prepared_request.headers = new_headers\n\n\ndef make_default_headers(args: argparse.Namespace) -> HTTPHeadersDict:\n    default_headers = HTTPHeadersDict({\n        'User-Agent': DEFAULT_UA\n    })\n\n    auto_json = args.data and not args.form\n    if args.json or auto_json:\n        default_headers['Accept'] = JSON_ACCEPT\n        if args.json or (auto_json and args.data):\n            default_headers['Content-Type'] = JSON_CONTENT_TYPE\n\n    elif args.form and not args.files:\n        # If sending files, `requests` will set\n        # the `Content-Type` for us.\n        default_headers['Content-Type'] = FORM_CONTENT_TYPE\n    return default_headers\n\n\ndef make_send_kwargs(args: argparse.Namespace) -> dict:\n    return {\n        'timeout': args.timeout or None,\n        'allow_redirects': False,\n    }\n\n\ndef make_send_kwargs_mergeable_from_env(args: argparse.Namespace) -> dict:\n    cert = None\n    if args.cert:\n        cert = args.cert\n        if args.cert_key:\n            # Having a client certificate key passphrase is not supported\n            # by requests. So we are using our own transportation structure\n            # which is compatible with their format (a tuple of minimum two\n            # items).\n            #\n            # See: https://github.com/psf/requests/issues/2519\n            cert = HTTPieCertificate(cert, args.cert_key, args.cert_key_pass.value)\n\n    return {\n        'proxies': {p.key: p.value for p in args.proxy},\n        'stream': True,\n        'verify': {\n            'yes': True,\n            'true': True,\n            'no': False,\n            'false': False,\n        }.get(args.verify.lower(), args.verify),\n        'cert': cert,\n    }\n\n\ndef json_dict_to_request_body(data: Dict[str, Any]) -> str:\n    data = unwrap_top_level_list_if_needed(data)\n    if data:\n        data = json.dumps(data)\n    else:\n        # We need to set data to an empty string to prevent requests\n        # from assigning an empty list to `response.request.data`.\n        data = ''\n    return data\n\n\ndef make_request_kwargs(\n    env: Environment,\n    args: argparse.Namespace,\n    base_headers: HTTPHeadersDict = None,\n    request_body_read_callback=lambda chunk: chunk\n) -> dict:\n    \"\"\"\n    Translate our `args` into `requests.Request` keyword arguments.\n\n    \"\"\"\n    files = args.files\n    # Serialize JSON data, if needed.\n    data = args.data\n    auto_json = data and not args.form\n    if (args.json or auto_json) and isinstance(data, dict):\n        data = json_dict_to_request_body(data)\n\n    # Finalize headers.\n    headers = make_default_headers(args)\n    if base_headers:\n        headers.update(base_headers)\n    headers.update(args.headers)\n    if args.offline and args.chunked and 'Transfer-Encoding' not in headers:\n        # When online, we let requests set the header instead to be able more\n        # easily verify chunking is taking place.\n        headers['Transfer-Encoding'] = 'chunked'\n    headers = finalize_headers(headers)\n\n    if (args.form and files) or args.multipart:\n        data, headers['Content-Type'] = get_multipart_data_and_content_type(\n            data=args.multipart_data,\n            boundary=args.boundary,\n            content_type=args.headers.get('Content-Type'),\n        )\n\n    return {\n        'method': args.method.lower(),\n        'url': args.url,\n        'headers': headers,\n        'data': prepare_request_body(\n            env,\n            data,\n            body_read_callback=request_body_read_callback,\n            chunked=args.chunked,\n            offline=args.offline,\n            content_length_header_value=headers.get('Content-Length'),\n        ),\n        'auth': args.auth,\n        'params': args.params.items(),\n    }\n\n\ndef ensure_path_as_is(orig_url: str, prepped_url: str) -> str:\n    \"\"\"\n    Handle `--path-as-is` by replacing the path component of the prepared\n    URL with the path component from the original URL. Other parts stay\n    untouched because other (welcome) processing on the URL might have\n    taken place.\n\n    <https://github.com/httpie/cli/issues/895>\n\n\n    <https://ec.haxx.se/http/http-basics#path-as-is>\n    <https://curl.haxx.se/libcurl/c/CURLOPT_PATH_AS_IS.html>\n\n    >>> ensure_path_as_is('http://foo/../', 'http://foo/?foo=bar')\n    'http://foo/../?foo=bar'\n\n    \"\"\"\n    parsed_orig, parsed_prepped = urlparse(orig_url), urlparse(prepped_url)\n    final_dict = {\n        # noinspection PyProtectedMember\n        **parsed_prepped._asdict(),\n        'path': parsed_orig.path,\n    }\n    return urlunparse(tuple(final_dict.values()))\n", "httpie/__main__.py": "\"\"\"The main entry point. Invoke as `http' or `python -m httpie'.\n\n\"\"\"\n\n\ndef main():\n    try:\n        from httpie.core import main\n        exit_status = main()\n    except KeyboardInterrupt:\n        from httpie.status import ExitStatus\n        exit_status = ExitStatus.ERROR_CTRL_C\n\n    return exit_status.value\n\n\nif __name__ == '__main__':  # pragma: nocover\n    import sys\n    sys.exit(main())\n", "httpie/__init__.py": "\"\"\"\nHTTPie: modern, user-friendly command-line HTTP client for the API era.\n\n\"\"\"\n\n__version__ = '3.2.2'\n__date__ = '2022-05-06'\n__author__ = 'Jakub Roztocil'\n__licence__ = 'BSD'\n", "httpie/context.py": "import argparse\nimport sys\nimport os\nimport warnings\nfrom contextlib import contextmanager\nfrom pathlib import Path\nfrom typing import Iterator, IO, Optional, TYPE_CHECKING\nfrom enum import Enum\n\n\ntry:\n    import curses\nexcept ImportError:\n    curses = None  # Compiled w/o curses\n\nfrom .compat import is_windows, cached_property\nfrom .config import DEFAULT_CONFIG_DIR, Config, ConfigFileError\nfrom .encoding import UTF8\n\nfrom .utils import repr_dict\nfrom .output.ui.palette import GenericColor\n\nif TYPE_CHECKING:\n    from rich.console import Console\n\n\nclass LogLevel(str, Enum):\n    INFO = 'info'\n    WARNING = 'warning'\n    ERROR = 'error'\n\n\nLOG_LEVEL_COLORS = {\n    LogLevel.INFO: GenericColor.PINK,\n    LogLevel.WARNING: GenericColor.ORANGE,\n    LogLevel.ERROR: GenericColor.RED,\n}\n\nLOG_LEVEL_DISPLAY_THRESHOLDS = {\n    LogLevel.INFO: 1,\n    LogLevel.WARNING: 2,\n    LogLevel.ERROR: float('inf'),  # Never hide errors.\n}\n\n\nclass Environment:\n    \"\"\"\n    Information about the execution context\n    (standard streams, config directory, etc).\n\n    By default, it represents the actual environment.\n    All of the attributes can be overwritten though, which\n    is used by the test suite to simulate various scenarios.\n\n    \"\"\"\n    args = argparse.Namespace()\n    is_windows: bool = is_windows\n    config_dir: Path = DEFAULT_CONFIG_DIR\n    stdin: Optional[IO] = sys.stdin  # `None` when closed fd (#791)\n    stdin_isatty: bool = stdin.isatty() if stdin else False\n    stdin_encoding: str = None\n    stdout: IO = sys.stdout\n    stdout_isatty: bool = stdout.isatty()\n    stdout_encoding: str = None\n    stderr: IO = sys.stderr\n    stderr_isatty: bool = stderr.isatty()\n    colors = 256\n    program_name: str = 'http'\n\n    # Whether to show progress bars / status spinners etc.\n    show_displays: bool = True\n\n    if not is_windows:\n        if curses:\n            try:\n                curses.setupterm()\n                colors = curses.tigetnum('colors')\n            except curses.error:\n                pass\n    else:\n        # noinspection PyUnresolvedReferences\n        import colorama.initialise\n        stdout = colorama.initialise.wrap_stream(\n            stdout, convert=None, strip=None,\n            autoreset=True, wrap=True\n        )\n        stderr = colorama.initialise.wrap_stream(\n            stderr, convert=None, strip=None,\n            autoreset=True, wrap=True\n        )\n        del colorama\n\n    def __init__(self, devnull=None, **kwargs):\n        \"\"\"\n        Use keyword arguments to overwrite\n        any of the class attributes for this instance.\n\n        \"\"\"\n        assert all(hasattr(type(self), attr) for attr in kwargs.keys())\n        self.__dict__.update(**kwargs)\n\n        # The original STDERR unaffected by --quiet\u2019ing.\n        self._orig_stderr = self.stderr\n        self._devnull = devnull\n\n        # Keyword arguments > stream.encoding > default UTF-8\n        if self.stdin and self.stdin_encoding is None:\n            self.stdin_encoding = getattr(\n                self.stdin, 'encoding', None) or UTF8\n        if self.stdout_encoding is None:\n            actual_stdout = self.stdout\n            if is_windows:\n                # noinspection PyUnresolvedReferences\n                from colorama import AnsiToWin32\n                if isinstance(self.stdout, AnsiToWin32):\n                    # noinspection PyUnresolvedReferences\n                    actual_stdout = self.stdout.wrapped\n            self.stdout_encoding = getattr(\n                actual_stdout, 'encoding', None) or UTF8\n\n        self.quiet = kwargs.pop('quiet', 0)\n\n    def __str__(self):\n        defaults = dict(type(self).__dict__)\n        actual = dict(defaults)\n        actual.update(self.__dict__)\n        actual['config'] = self.config\n        return repr_dict({\n            key: value\n            for key, value in actual.items()\n            if not key.startswith('_')\n        })\n\n    def __repr__(self):\n        return f'<{type(self).__name__} {self}>'\n\n    _config: Config = None\n\n    @property\n    def config(self) -> Config:\n        config = self._config\n        if not config:\n            self._config = config = Config(directory=self.config_dir)\n            if not config.is_new():\n                try:\n                    config.load()\n                except ConfigFileError as e:\n                    self.log_error(e, level=LogLevel.WARNING)\n        return config\n\n    @property\n    def devnull(self) -> IO:\n        if self._devnull is None:\n            self._devnull = open(os.devnull, 'w+')\n        return self._devnull\n\n    @contextmanager\n    def as_silent(self) -> Iterator[None]:\n        original_stdout = self.stdout\n        original_stderr = self.stderr\n\n        try:\n            self.stdout = self.devnull\n            self.stderr = self.devnull\n            yield\n        finally:\n            self.stdout = original_stdout\n            self.stderr = original_stderr\n\n    def log_error(self, msg: str, level: LogLevel = LogLevel.ERROR) -> None:\n        if self.stdout_isatty and self.quiet >= LOG_LEVEL_DISPLAY_THRESHOLDS[level]:\n            stderr = self.stderr  # Not directly /dev/null, since stderr might be mocked\n        else:\n            stderr = self._orig_stderr\n        rich_console = self._make_rich_console(file=stderr, force_terminal=stderr.isatty())\n        rich_console.print(\n            f'\\n{self.program_name}: {level.value}: {msg}\\n\\n',\n            style=LOG_LEVEL_COLORS[level],\n            markup=False,\n            highlight=False,\n            soft_wrap=True\n        )\n\n    def apply_warnings_filter(self) -> None:\n        if self.quiet >= LOG_LEVEL_DISPLAY_THRESHOLDS[LogLevel.WARNING]:\n            warnings.simplefilter(\"ignore\")\n\n    def _make_rich_console(\n        self,\n        file: IO[str],\n        force_terminal: bool\n    ) -> 'Console':\n        from rich.console import Console\n        from httpie.output.ui.rich_palette import _make_rich_color_theme\n\n        style = getattr(self.args, 'style', None)\n        theme = _make_rich_color_theme(style)\n        # Rich infers the rest of the knowledge (e.g encoding)\n        # dynamically by looking at the file/stderr.\n        return Console(\n            file=file,\n            force_terminal=force_terminal,\n            no_color=(self.colors == 0),\n            theme=theme\n        )\n\n    # Rich recommends separating the actual console (stdout) from\n    # the error (stderr) console for better isolation between parts.\n    # https://rich.readthedocs.io/en/stable/console.html#error-console\n\n    @cached_property\n    def rich_console(self):\n        return self._make_rich_console(self.stdout, self.stdout_isatty)\n\n    @cached_property\n    def rich_error_console(self):\n        return self._make_rich_console(self.stderr, self.stderr_isatty)\n", "httpie/compat.py": "import sys\nfrom typing import Any, Optional, Iterable\n\nfrom httpie.cookies import HTTPieCookiePolicy\nfrom http import cookiejar # noqa\n\n\n# Request does not carry the original policy attached to the\n# cookie jar, so until it is resolved we change the global cookie\n# policy. <https://github.com/psf/requests/issues/5449>\ncookiejar.DefaultCookiePolicy = HTTPieCookiePolicy\n\n\nis_windows = 'win32' in str(sys.platform).lower()\nis_frozen = getattr(sys, 'frozen', False)\n\nMIN_SUPPORTED_PY_VERSION = (3, 7)\nMAX_SUPPORTED_PY_VERSION = (3, 11)\n\ntry:\n    from functools import cached_property\nexcept ImportError:\n    # Can be removed once we drop Python <3.8 support.\n    # Taken from `django.utils.functional.cached_property`.\n    class cached_property:\n        \"\"\"\n        Decorator that converts a method with a single self argument into a\n        property cached on the instance.\n\n        A cached property can be made out of an existing method:\n        (e.g. ``url = cached_property(get_absolute_url)``).\n        The optional ``name`` argument is obsolete as of Python 3.6 and will be\n        deprecated in Django 4.0 (#30127).\n        \"\"\"\n        name = None\n\n        @staticmethod\n        def func(instance):\n            raise TypeError(\n                'Cannot use cached_property instance without calling '\n                '__set_name__() on it.'\n            )\n\n        def __init__(self, func, name=None):\n            self.real_func = func\n            self.__doc__ = getattr(func, '__doc__')\n\n        def __set_name__(self, owner, name):\n            if self.name is None:\n                self.name = name\n                self.func = self.real_func\n            elif name != self.name:\n                raise TypeError(\n                    \"Cannot assign the same cached_property to two different names \"\n                    \"(%r and %r).\" % (self.name, name)\n                )\n\n        def __get__(self, instance, cls=None):\n            \"\"\"\n            Call the function and put the return value in instance.__dict__ so that\n            subsequent attribute access on the instance returns the cached value\n            instead of calling cached_property.__get__().\n            \"\"\"\n            if instance is None:\n                return self\n            res = instance.__dict__[self.name] = self.func(instance)\n            return res\n\n\n# importlib_metadata was a provisional module, so the APIs changed quite a few times\n# between 3.8-3.10. It was also not included in the standard library until 3.8, so\n# we install the backport for <3.8.\n\nif sys.version_info >= (3, 8):\n    import importlib.metadata as importlib_metadata\nelse:\n    import importlib_metadata\n\n\ndef find_entry_points(entry_points: Any, group: str) -> Iterable[importlib_metadata.EntryPoint]:\n    if hasattr(entry_points, \"select\"):  # Python 3.10+ / importlib_metadata >= 3.9.0\n        return entry_points.select(group=group)\n    else:\n        return set(entry_points.get(group, ()))\n\n\ndef get_dist_name(entry_point: importlib_metadata.EntryPoint) -> Optional[str]:\n    dist = getattr(entry_point, \"dist\", None)\n    if dist is not None:  # Python 3.10+\n        return dist.name\n\n    match = entry_point.pattern.match(entry_point.value)\n    if not (match and match.group('module')):\n        return None\n\n    package = match.group('module').split('.')[0]\n    try:\n        metadata = importlib_metadata.metadata(package)\n    except importlib_metadata.PackageNotFoundError:\n        return None\n    else:\n        return metadata.get('name')\n", "httpie/cookies.py": "from http import cookiejar\n\n\n_LOCALHOST = 'localhost'\n_LOCALHOST_SUFFIX = '.localhost'\n\n\nclass HTTPieCookiePolicy(cookiejar.DefaultCookiePolicy):\n    def return_ok_secure(self, cookie, request):\n        \"\"\"Check whether the given cookie is sent to a secure host.\"\"\"\n\n        is_secure_protocol = super().return_ok_secure(cookie, request)\n        if is_secure_protocol:\n            return True\n\n        # The original implementation of this method only takes secure protocols\n        # (e.g., https) into account, but the latest developments in modern browsers\n        # (chrome, firefox) assume 'localhost' is also a secure location. So we\n        # override it with our own strategy.\n        return self._is_local_host(cookiejar.request_host(request))\n\n    def _is_local_host(self, hostname):\n        # Implements the static localhost detection algorithm in firefox.\n        # <https://searchfox.org/mozilla-central/rev/d4d7611ee4dd0003b492b865bc5988a4e6afc985/netwerk/dns/DNS.cpp#205-218>\n        return hostname == _LOCALHOST or hostname.endswith(_LOCALHOST_SUFFIX)\n", "httpie/encoding.py": "from typing import Union, Tuple\n\nfrom charset_normalizer import from_bytes\nfrom charset_normalizer.constant import TOO_SMALL_SEQUENCE\n\nUTF8 = 'utf-8'\n\nContentBytes = Union[bytearray, bytes]\n\n\ndef detect_encoding(content: ContentBytes) -> str:\n    \"\"\"\n    We default to UTF-8 if text too short, because the detection\n    can return a random encoding leading to confusing results\n    given the `charset_normalizer` version (< 2.0.5).\n\n    >>> too_short = ']\"foo\"'\n    >>> detected = from_bytes(too_short.encode()).best().encoding\n    >>> detected\n    'ascii'\n    >>> too_short.encode().decode(detected)\n    ']\"foo\"'\n    \"\"\"\n    encoding = UTF8\n    if len(content) > TOO_SMALL_SEQUENCE:\n        match = from_bytes(bytes(content)).best()\n        if match:\n            encoding = match.encoding\n    return encoding\n\n\ndef smart_decode(content: ContentBytes, encoding: str) -> Tuple[str, str]:\n    \"\"\"Decode `content` using the given `encoding`.\n    If no `encoding` is provided, the best effort is to guess it from `content`.\n\n    Unicode errors are replaced.\n\n    \"\"\"\n    if not encoding:\n        encoding = detect_encoding(content)\n    return content.decode(encoding, 'replace'), encoding\n\n\ndef smart_encode(content: str, encoding: str) -> bytes:\n    \"\"\"Encode `content` using the given `encoding`.\n\n    Unicode errors are replaced.\n\n    \"\"\"\n    return content.encode(encoding, 'replace')\n", "httpie/status.py": "from enum import IntEnum, unique\n\n\n@unique\nclass ExitStatus(IntEnum):\n    \"\"\"Program exit status code constants.\"\"\"\n    SUCCESS = 0\n    ERROR = 1\n    ERROR_TIMEOUT = 2\n\n    # See --check-status\n    ERROR_HTTP_3XX = 3\n    ERROR_HTTP_4XX = 4\n    ERROR_HTTP_5XX = 5\n\n    ERROR_TOO_MANY_REDIRECTS = 6\n    PLUGIN_ERROR = 7\n    # 128+2 SIGINT\n    # <http://www.tldp.org/LDP/abs/html/exitcodes.html>\n    ERROR_CTRL_C = 130\n\n\ndef http_status_to_exit_status(http_status: int, follow=False) -> ExitStatus:\n    \"\"\"\n    Translate HTTP status code to exit status code.\n\n    (Relevant only when invoked with --check-status or --download.)\n\n    \"\"\"\n    if 300 <= http_status <= 399 and not follow:\n        # Redirect\n        return ExitStatus.ERROR_HTTP_3XX\n    elif 400 <= http_status <= 499:\n        # Client Error\n        return ExitStatus.ERROR_HTTP_4XX\n    elif 500 <= http_status <= 599:\n        # Server Error\n        return ExitStatus.ERROR_HTTP_5XX\n    else:\n        return ExitStatus.SUCCESS\n", "httpie/sessions.py": "\"\"\"\nPersistent, JSON-serialized sessions.\n\n\"\"\"\nimport os\nimport re\n\nfrom http.cookies import SimpleCookie\nfrom http.cookiejar import Cookie\nfrom pathlib import Path\nfrom typing import Any, Dict, List, Optional, Union\n\nfrom requests.auth import AuthBase\nfrom requests.cookies import RequestsCookieJar, remove_cookie_by_name\n\nfrom .context import Environment, LogLevel\nfrom .cookies import HTTPieCookiePolicy\nfrom .cli.dicts import HTTPHeadersDict\nfrom .config import BaseConfigDict, DEFAULT_CONFIG_DIR\nfrom .utils import url_as_host\nfrom .plugins.registry import plugin_manager\n\nfrom .legacy import (\n    v3_1_0_session_cookie_format as legacy_cookies,\n    v3_2_0_session_header_format as legacy_headers\n)\n\n\nSESSIONS_DIR_NAME = 'sessions'\nDEFAULT_SESSIONS_DIR = DEFAULT_CONFIG_DIR / SESSIONS_DIR_NAME\nVALID_SESSION_NAME_PATTERN = re.compile('^[a-zA-Z0-9_.-]+$')\n# Request headers starting with these prefixes won't be stored in sessions.\n# They are specific to each request.\n# <https://en.wikipedia.org/wiki/List_of_HTTP_header_fields#Requests>\nSESSION_IGNORED_HEADER_PREFIXES = ['Content-', 'If-']\n\n# Cookie related options\nKEPT_COOKIE_OPTIONS = ['name', 'expires', 'path', 'value', 'domain', 'secure']\nDEFAULT_COOKIE_PATH = '/'\n\n\ndef is_anonymous_session(session_name: str) -> bool:\n    return os.path.sep in session_name\n\n\ndef session_hostname_to_dirname(hostname: str, session_name: str) -> str:\n    # host:port => host_port\n    hostname = hostname.replace(':', '_')\n    return os.path.join(\n        SESSIONS_DIR_NAME,\n        hostname,\n        f'{session_name}.json'\n    )\n\n\ndef strip_port(hostname: str) -> str:\n    return hostname.split(':')[0]\n\n\ndef materialize_cookie(cookie: Cookie) -> Dict[str, Any]:\n    materialized_cookie = {\n        option: getattr(cookie, option)\n        for option in KEPT_COOKIE_OPTIONS\n    }\n\n    if (\n        cookie._rest.get('is_explicit_none')\n        and materialized_cookie['domain'] == ''\n    ):\n        materialized_cookie['domain'] = None\n\n    return materialized_cookie\n\n\ndef materialize_cookies(jar: RequestsCookieJar) -> List[Dict[str, Any]]:\n    return [\n        materialize_cookie(cookie)\n        for cookie in jar\n    ]\n\n\ndef materialize_headers(headers: Dict[str, str]) -> List[Dict[str, Any]]:\n    return [\n        {\n            'name': name,\n            'value': value\n        }\n        for name, value in headers.copy().items()\n    ]\n\n\ndef get_httpie_session(\n    env: Environment,\n    config_dir: Path,\n    session_name: str,\n    host: Optional[str],\n    url: str,\n    *,\n    suppress_legacy_warnings: bool = False\n) -> 'Session':\n    bound_hostname = host or url_as_host(url)\n    if not bound_hostname:\n        # HACK/FIXME: httpie-unixsocket's URLs have no hostname.\n        bound_hostname = 'localhost'\n\n    if is_anonymous_session(session_name):\n        path = os.path.expanduser(session_name)\n        session_id = path\n    else:\n        path = config_dir / session_hostname_to_dirname(bound_hostname, session_name)\n        session_id = session_name\n\n    session = Session(\n        path,\n        env=env,\n        session_id=session_id,\n        bound_host=strip_port(bound_hostname),\n        suppress_legacy_warnings=suppress_legacy_warnings\n    )\n    session.load()\n    return session\n\n\nclass Session(BaseConfigDict):\n    helpurl = 'https://httpie.io/docs#sessions'\n    about = 'HTTPie session file'\n\n    def __init__(\n        self,\n        path: Union[str, Path],\n        env: Environment,\n        bound_host: str,\n        session_id: str,\n        suppress_legacy_warnings: bool = False,\n    ):\n        super().__init__(path=Path(path))\n\n        # Default values for the session files\n        self['headers'] = []\n        self['cookies'] = []\n        self['auth'] = {\n            'type': None,\n            'username': None,\n            'password': None\n        }\n\n        # Runtime state of the Session objects.\n        self.env = env\n        self._headers = HTTPHeadersDict()\n        self.cookie_jar = RequestsCookieJar(\n            # See also a temporary workaround for a Requests bug in `compat.py`.\n            policy=HTTPieCookiePolicy(),\n        )\n        self.session_id = session_id\n        self.bound_host = bound_host\n        self.suppress_legacy_warnings = suppress_legacy_warnings\n\n    def _add_cookies(self, cookies: List[Dict[str, Any]]) -> None:\n        for cookie in cookies:\n            domain = cookie.get('domain', '')\n            if domain is None:\n                # domain = None means explicitly lack of cookie, though\n                # requests requires domain to be a string so we'll cast it\n                # manually.\n                cookie['domain'] = ''\n                cookie['rest'] = {'is_explicit_none': True}\n\n            self.cookie_jar.set(**cookie)\n\n    def pre_process_data(self, data: Dict[str, Any]) -> Dict[str, Any]:\n        for key, deserializer, importer in [\n            ('cookies', legacy_cookies.pre_process, self._add_cookies),\n            ('headers', legacy_headers.pre_process, self._headers.update),\n        ]:\n            values = data.get(key)\n            if values:\n                normalized_values = deserializer(self, values)\n            else:\n                normalized_values = []\n\n            importer(normalized_values)\n\n        return data\n\n    def post_process_data(self, data: Dict[str, Any]) -> Dict[str, Any]:\n        for key, store, serializer, exporter in [\n            ('cookies', self.cookie_jar, materialize_cookies, legacy_cookies.post_process),\n            ('headers', self._headers, materialize_headers, legacy_headers.post_process),\n        ]:\n            original_type = type(data.get(key))\n            values = serializer(store)\n\n            data[key] = exporter(\n                values,\n                original_type=original_type\n            )\n\n        return data\n\n    def _compute_new_headers(self, request_headers: HTTPHeadersDict) -> HTTPHeadersDict:\n        new_headers = HTTPHeadersDict()\n        for name, value in request_headers.copy().items():\n            if value is None:\n                continue  # Ignore explicitly unset headers\n\n            original_value = value\n            if type(value) is not str:\n                value = value.decode()\n\n            if name.lower() == 'user-agent' and value.startswith('HTTPie/'):\n                continue\n\n            if name.lower() == 'cookie':\n                for cookie_name, morsel in SimpleCookie(value).items():\n                    if not morsel['path']:\n                        morsel['path'] = DEFAULT_COOKIE_PATH\n                    self.cookie_jar.set(cookie_name, morsel)\n\n                request_headers.remove_item(name, original_value)\n                continue\n\n            for prefix in SESSION_IGNORED_HEADER_PREFIXES:\n                if name.lower().startswith(prefix.lower()):\n                    break\n            else:\n                new_headers.add(name, value)\n\n        return new_headers\n\n    def update_headers(self, request_headers: HTTPHeadersDict):\n        \"\"\"\n        Update the session headers with the request ones while ignoring\n        certain name prefixes.\n\n        \"\"\"\n\n        new_headers = self._compute_new_headers(request_headers)\n        new_keys = new_headers.copy().keys()\n\n        # New headers will take priority over the existing ones, and override\n        # them directly instead of extending them.\n        for key, value in self._headers.copy().items():\n            if key in new_keys:\n                continue\n\n            new_headers.add(key, value)\n\n        self._headers = new_headers\n\n    @property\n    def headers(self) -> HTTPHeadersDict:\n        return self._headers.copy()\n\n    @property\n    def cookies(self) -> RequestsCookieJar:\n        self.cookie_jar.clear_expired_cookies()\n        return self.cookie_jar\n\n    @cookies.setter\n    def cookies(self, jar: RequestsCookieJar):\n        self.cookie_jar = jar\n\n    def remove_cookies(self, cookies: List[Dict[str, str]]):\n        for cookie in cookies:\n            remove_cookie_by_name(\n                self.cookie_jar,\n                cookie['name'],\n                domain=cookie.get('domain', None),\n                path=cookie.get('path', None)\n            )\n\n    @property\n    def auth(self) -> Optional[AuthBase]:\n        auth = self.get('auth', None)\n        if not auth or not auth['type']:\n            return\n\n        plugin = plugin_manager.get_auth_plugin(auth['type'])()\n\n        credentials = {'username': None, 'password': None}\n        try:\n            # New style\n            plugin.raw_auth = auth['raw_auth']\n        except KeyError:\n            # Old style\n            credentials = {\n                'username': auth['username'],\n                'password': auth['password'],\n            }\n        else:\n            if plugin.auth_parse:\n                from .cli.argtypes import parse_auth\n                parsed = parse_auth(plugin.raw_auth)\n                credentials = {\n                    'username': parsed.key,\n                    'password': parsed.value,\n                }\n\n        return plugin.get_auth(**credentials)\n\n    @auth.setter\n    def auth(self, auth: dict):\n        assert {'type', 'raw_auth'} == auth.keys()\n        self['auth'] = auth\n\n    @property\n    def is_anonymous(self):\n        return is_anonymous_session(self.session_id)\n\n    def warn_legacy_usage(self, warning: str) -> None:\n        if self.suppress_legacy_warnings:\n            return None\n\n        self.env.log_error(\n            warning,\n            level=LogLevel.WARNING\n        )\n\n        # We don't want to spam multiple warnings on each usage,\n        # so if there is already a warning for the legacy usage\n        # we'll skip the next ones.\n        self.suppress_legacy_warnings = True\n", "httpie/ssl_.py": "import ssl\nfrom typing import NamedTuple, Optional\n\nfrom httpie.adapters import HTTPAdapter\n# noinspection PyPackageRequirements\nfrom urllib3.util.ssl_ import (\n    create_urllib3_context,\n    resolve_ssl_version,\n)\n\n\nSSL_VERSION_ARG_MAPPING = {\n    'ssl2.3': 'PROTOCOL_SSLv23',\n    'ssl3': 'PROTOCOL_SSLv3',\n    'tls1': 'PROTOCOL_TLSv1',\n    'tls1.1': 'PROTOCOL_TLSv1_1',\n    'tls1.2': 'PROTOCOL_TLSv1_2',\n    'tls1.3': 'PROTOCOL_TLSv1_3',\n}\nAVAILABLE_SSL_VERSION_ARG_MAPPING = {\n    arg: getattr(ssl, constant_name)\n    for arg, constant_name in SSL_VERSION_ARG_MAPPING.items()\n    if hasattr(ssl, constant_name)\n}\n\n\nclass HTTPieCertificate(NamedTuple):\n    cert_file: Optional[str] = None\n    key_file: Optional[str] = None\n    key_password: Optional[str] = None\n\n    def to_raw_cert(self):\n        \"\"\"Synthesize a requests-compatible (2-item tuple of cert and key file)\n        object from HTTPie's internal representation of a certificate.\"\"\"\n        return (self.cert_file, self.key_file)\n\n\nclass HTTPieHTTPSAdapter(HTTPAdapter):\n    def __init__(\n        self,\n        verify: bool,\n        ssl_version: str = None,\n        ciphers: str = None,\n        **kwargs\n    ):\n        self._ssl_context = self._create_ssl_context(\n            verify=verify,\n            ssl_version=ssl_version,\n            ciphers=ciphers,\n        )\n        super().__init__(**kwargs)\n\n    def init_poolmanager(self, *args, **kwargs):\n        kwargs['ssl_context'] = self._ssl_context\n        return super().init_poolmanager(*args, **kwargs)\n\n    def proxy_manager_for(self, *args, **kwargs):\n        kwargs['ssl_context'] = self._ssl_context\n        return super().proxy_manager_for(*args, **kwargs)\n\n    def cert_verify(self, conn, url, verify, cert):\n        if isinstance(cert, HTTPieCertificate):\n            conn.key_password = cert.key_password\n            cert = cert.to_raw_cert()\n\n        return super().cert_verify(conn, url, verify, cert)\n\n    @staticmethod\n    def _create_ssl_context(\n        verify: bool,\n        ssl_version: str = None,\n        ciphers: str = None,\n    ) -> 'ssl.SSLContext':\n        return create_urllib3_context(\n            ciphers=ciphers,\n            ssl_version=resolve_ssl_version(ssl_version),\n            # Since we are using a custom SSL context, we need to pass this\n            # here manually, even though it\u2019s also passed to the connection\n            # in `super().cert_verify()`.\n            cert_reqs=ssl.CERT_REQUIRED if verify else ssl.CERT_NONE\n        )\n\n    @classmethod\n    def get_default_ciphers_names(cls):\n        return [cipher['name'] for cipher in cls._create_ssl_context(verify=False).get_ciphers()]\n\n\ndef _is_key_file_encrypted(key_file):\n    \"\"\"Detects if a key file is encrypted or not.\n\n    Copy of the internal urllib function (urllib3.util.ssl_)\"\"\"\n\n    with open(key_file, \"r\") as f:\n        for line in f:\n            # Look for Proc-Type: 4,ENCRYPTED\n            if \"ENCRYPTED\" in line:\n                return True\n\n    return False\n\n\n# We used to import the default set of TLS ciphers from urllib3, but they removed it.\n# Instead, now urllib3 uses the list of ciphers configured by the system.\n# <https://github.com/httpie/cli/pull/1501>\nDEFAULT_SSL_CIPHERS_STRING = ':'.join(HTTPieHTTPSAdapter.get_default_ciphers_names())\n", "httpie/plugins/builtin.py": "from base64 import b64encode\n\nimport requests.auth\n\nfrom .base import AuthPlugin\n\n\n# noinspection PyAbstractClass\nclass BuiltinAuthPlugin(AuthPlugin):\n    package_name = '(builtin)'\n\n\nclass HTTPBasicAuth(requests.auth.HTTPBasicAuth):\n\n    def __call__(\n        self,\n        request: requests.PreparedRequest\n    ) -> requests.PreparedRequest:\n        \"\"\"\n        Override username/password serialization to allow unicode.\n\n        See https://github.com/httpie/cli/issues/212\n\n        \"\"\"\n        # noinspection PyTypeChecker\n        request.headers['Authorization'] = type(self).make_header(\n            self.username, self.password).encode('latin1')\n        return request\n\n    @staticmethod\n    def make_header(username: str, password: str) -> str:\n        credentials = f'{username}:{password}'\n        token = b64encode(credentials.encode()).strip().decode('latin1')\n        return f'Basic {token}'\n\n\nclass HTTPBearerAuth(requests.auth.AuthBase):\n\n    def __init__(self, token: str) -> None:\n        self.token = token\n\n    def __call__(self, request: requests.PreparedRequest) -> requests.PreparedRequest:\n        request.headers['Authorization'] = f'Bearer {self.token}'\n        return request\n\n\nclass BasicAuthPlugin(BuiltinAuthPlugin):\n    name = 'Basic HTTP auth'\n    auth_type = 'basic'\n    netrc_parse = True\n\n    # noinspection PyMethodOverriding\n    def get_auth(self, username: str, password: str) -> HTTPBasicAuth:\n        return HTTPBasicAuth(username, password)\n\n\nclass DigestAuthPlugin(BuiltinAuthPlugin):\n    name = 'Digest HTTP auth'\n    auth_type = 'digest'\n    netrc_parse = True\n\n    # noinspection PyMethodOverriding\n    def get_auth(\n        self,\n        username: str,\n        password: str\n    ) -> requests.auth.HTTPDigestAuth:\n        return requests.auth.HTTPDigestAuth(username, password)\n\n\nclass BearerAuthPlugin(BuiltinAuthPlugin):\n    name = 'Bearer HTTP Auth'\n    auth_type = 'bearer'\n    netrc_parse = False\n    auth_parse = False\n\n    # noinspection PyMethodOverriding\n    def get_auth(self, **kwargs) -> requests.auth.HTTPDigestAuth:\n        return HTTPBearerAuth(self.raw_auth)\n", "httpie/plugins/manager.py": "import sys\nimport os\nimport warnings\n\nfrom itertools import groupby\nfrom operator import attrgetter\nfrom typing import Dict, List, Type, Iterator, Iterable, Optional, ContextManager\nfrom pathlib import Path\nfrom contextlib import contextmanager, nullcontext\n\nfrom ..compat import importlib_metadata, find_entry_points, get_dist_name\n\nfrom ..utils import repr_dict, get_site_paths\nfrom . import AuthPlugin, ConverterPlugin, FormatterPlugin, TransportPlugin\nfrom .base import BasePlugin\n\n\nENTRY_POINT_CLASSES = {\n    'httpie.plugins.auth.v1': AuthPlugin,\n    'httpie.plugins.converter.v1': ConverterPlugin,\n    'httpie.plugins.formatter.v1': FormatterPlugin,\n    'httpie.plugins.transport.v1': TransportPlugin\n}\nENTRY_POINT_NAMES = list(ENTRY_POINT_CLASSES.keys())\n\n\n@contextmanager\ndef _load_directories(site_dirs: Iterable[Path]) -> Iterator[None]:\n    plugin_dirs = [\n        os.fspath(site_dir)\n        for site_dir in site_dirs\n    ]\n    sys.path.extend(plugin_dirs)\n    try:\n        yield\n    finally:\n        for plugin_dir in plugin_dirs:\n            sys.path.remove(plugin_dir)\n\n\ndef enable_plugins(plugins_dir: Optional[Path]) -> ContextManager[None]:\n    if plugins_dir is None:\n        return nullcontext()\n    else:\n        return _load_directories(get_site_paths(plugins_dir))\n\n\nclass PluginManager(list):\n    def register(self, *plugins: Type[BasePlugin]):\n        for plugin in plugins:\n            self.append(plugin)\n\n    def unregister(self, plugin: Type[BasePlugin]):\n        self.remove(plugin)\n\n    def filter(self, by_type=Type[BasePlugin]):\n        return [plugin for plugin in self if issubclass(plugin, by_type)]\n\n    def iter_entry_points(self, directory: Optional[Path] = None):\n        with enable_plugins(directory):\n            eps = importlib_metadata.entry_points()\n\n            for entry_point_name in ENTRY_POINT_NAMES:\n                yield from find_entry_points(eps, group=entry_point_name)\n\n    def load_installed_plugins(self, directory: Optional[Path] = None):\n        for entry_point in self.iter_entry_points(directory):\n            plugin_name = get_dist_name(entry_point)\n            try:\n                plugin = entry_point.load()\n            except BaseException as exc:\n                warnings.warn(\n                    f'While loading \"{plugin_name}\", an error occurred: {exc}\\n'\n                    f'For uninstallations, please use either \"httpie plugins uninstall {plugin_name}\" '\n                    f'or \"pip uninstall {plugin_name}\" (depending on how you installed it in the first '\n                    'place).'\n                )\n                continue\n            plugin.package_name = plugin_name\n            self.register(plugin)\n\n    # Auth\n    def get_auth_plugins(self) -> List[Type[AuthPlugin]]:\n        return self.filter(AuthPlugin)\n\n    def get_auth_plugin_mapping(self) -> Dict[str, Type[AuthPlugin]]:\n        return {\n            plugin.auth_type: plugin for plugin in self.get_auth_plugins()\n        }\n\n    def get_auth_plugin(self, auth_type: str) -> Type[AuthPlugin]:\n        return self.get_auth_plugin_mapping()[auth_type]\n\n    # Output processing\n    def get_formatters(self) -> List[Type[FormatterPlugin]]:\n        return self.filter(FormatterPlugin)\n\n    def get_formatters_grouped(self) -> Dict[str, List[Type[FormatterPlugin]]]:\n        return {\n            group_name: list(group)\n            for group_name, group\n            in groupby(self.get_formatters(), key=attrgetter('group_name'))\n        }\n\n    def get_converters(self) -> List[Type[ConverterPlugin]]:\n        return self.filter(ConverterPlugin)\n\n    # Adapters\n    def get_transport_plugins(self) -> List[Type[TransportPlugin]]:\n        return self.filter(TransportPlugin)\n\n    def __str__(self):\n        return repr_dict({\n            'adapters': self.get_transport_plugins(),\n            'auth': self.get_auth_plugins(),\n            'converters': self.get_converters(),\n            'formatters': self.get_formatters(),\n        })\n\n    def __repr__(self):\n        return f'<{type(self).__name__} {self}>'\n", "httpie/plugins/base.py": "from typing import Tuple\n\n\nclass BasePlugin:\n    # The name of the plugin, eg. \"My auth\".\n    name = None\n\n    # Optional short description. It will be shown in the help\n    # under --auth-type.\n    description = None\n\n    # This be set automatically once the plugin has been loaded.\n    package_name = None\n\n\nclass AuthPlugin(BasePlugin):\n    \"\"\"\n    Base auth plugin class.\n\n    See httpie-ntlm for an example auth plugin:\n\n        <https://github.com/httpie/httpie-ntlm>\n\n    See also `test_auth_plugins.py`\n\n    \"\"\"\n    # The value that should be passed to --auth-type\n    # to use this auth plugin. Eg. \"my-auth\"\n    auth_type = None\n\n    # Set to `False` to make it possible to invoke this auth\n    # plugin without requiring the user to specify credentials\n    # through `--auth, -a`.\n    auth_require = True\n\n    # By default the `-a` argument is parsed for `username:password`.\n    # Set this to `False` to disable the parsing and error handling.\n    auth_parse = True\n\n    # Set to `True` to make it possible for this auth\n    # plugin to acquire credentials from the user\u2019s netrc file(s).\n    # It is used as a fallback when the credentials are not provided explicitly\n    # through `--auth, -a`. Enabling this will allow skipping `--auth, -a`\n    # even when `auth_require` is set `True` (provided that netrc provides\n    # credential for a given host).\n    netrc_parse = False\n\n    # If both `auth_parse` and `prompt_password` are set to `True`,\n    # and the value of `-a` lacks the password part,\n    # then the user will be prompted to type the password in.\n    prompt_password = True\n\n    # Will be set to the raw value of `-a` (if provided) before\n    # `get_auth()` gets called. If the credentials came from a netrc file,\n    # then this is `None`.\n    raw_auth = None\n\n    def get_auth(self, username: str = None, password: str = None):\n        \"\"\"\n        If `auth_parse` is set to `True`, then `username`\n        and `password` contain the parsed credentials.\n\n        Use `self.raw_auth` to access the raw value passed through\n        `--auth, -a`.\n\n        Return a ``requests.auth.AuthBase`` subclass instance.\n\n        \"\"\"\n        raise NotImplementedError()\n\n\nclass TransportPlugin(BasePlugin):\n    \"\"\"\n    Requests transport adapter docs:\n\n        <https://requests.readthedocs.io/en/latest/user/advanced/#transport-adapters>\n\n    See httpie-unixsocket for an example transport plugin:\n\n        <https://github.com/httpie/httpie-unixsocket>\n\n    \"\"\"\n\n    # The URL prefix the adapter should be mount to.\n    prefix = None\n\n    def get_adapter(self):\n        \"\"\"\n        Return a ``requests.adapters.BaseAdapter`` subclass instance to be\n        mounted to ``self.prefix``.\n\n        \"\"\"\n        raise NotImplementedError()\n\n\nclass ConverterPlugin(BasePlugin):\n    \"\"\"\n    Possibly converts binary response data for prettified terminal display.\n\n    See httpie-msgpack for an example converter plugin:\n\n        <https://github.com/rasky/httpie-msgpack>.\n\n    \"\"\"\n\n    def __init__(self, mime: str):\n        self.mime = mime\n\n    def convert(self, body: bytes) -> Tuple[str, str]:\n        \"\"\"\n        Convert a binary body to a textual representation for the terminal\n        and return a tuple containing the new Content-Type and content, e.g.:\n\n        ('application/json', '{}')\n\n        \"\"\"\n        raise NotImplementedError\n\n    @classmethod\n    def supports(cls, mime: str) -> bool:\n        raise NotImplementedError\n\n\nclass FormatterPlugin(BasePlugin):\n    \"\"\"\n    Possibly formats response body & headers for prettified terminal display.\n\n    \"\"\"\n    group_name = 'format'\n\n    def __init__(self, **kwargs):\n        \"\"\"\n        :param env: an class:`Environment` instance\n        :param kwargs: additional keyword argument that some\n                       formatters might require.\n\n        \"\"\"\n        self.enabled = True\n        self.kwargs = kwargs\n        self.format_options = kwargs['format_options']\n\n    def format_headers(self, headers: str) -> str:\n        \"\"\"Return processed `headers`\n\n        :param headers: The headers as text.\n\n        \"\"\"\n        return headers\n\n    def format_body(self, content: str, mime: str) -> str:\n        \"\"\"Return processed `content`.\n\n        :param mime: E.g., 'application/atom+xml'.\n        :param content: The body content as text\n\n        \"\"\"\n        return content\n\n    def format_metadata(self, metadata: str) -> str:\n        \"\"\"Return processed `metadata`.\n\n        :param metadata: The metadata as text.\n\n        \"\"\"\n        return metadata\n", "httpie/plugins/registry.py": "from .manager import PluginManager\nfrom .builtin import BasicAuthPlugin, DigestAuthPlugin, BearerAuthPlugin\nfrom ..output.formatters.headers import HeadersFormatter\nfrom ..output.formatters.json import JSONFormatter\nfrom ..output.formatters.xml import XMLFormatter\nfrom ..output.formatters.colors import ColorFormatter\n\n\nplugin_manager = PluginManager()\n\n\n# Register all built-in plugins.\nplugin_manager.register(\n    BasicAuthPlugin,\n    DigestAuthPlugin,\n    BearerAuthPlugin,\n    HeadersFormatter,\n    JSONFormatter,\n    XMLFormatter,\n    ColorFormatter,\n)\n", "httpie/plugins/__init__.py": "\"\"\"\nWARNING: The plugin API is still work in progress and will\n         probably be completely reworked in the future.\n\n\"\"\"\nfrom .base import (\n    AuthPlugin, FormatterPlugin,\n    ConverterPlugin, TransportPlugin\n)\n\n__all__ = ('AuthPlugin', 'ConverterPlugin', 'FormatterPlugin', 'TransportPlugin')\n", "httpie/internal/daemons.py": "\"\"\"\nThis module provides an interface to spawn a detached task to be\nrun with httpie.internal.daemon_runner on a separate process. It is\nbased on DVC's daemon system.\nhttps://github.com/iterative/dvc/blob/main/dvc/daemon.py\n\"\"\"\n\nimport inspect\nimport os\nimport platform\nimport sys\nimport httpie.__main__\nfrom contextlib import suppress\nfrom subprocess import Popen, DEVNULL\nfrom typing import Dict, List\nfrom httpie.compat import is_frozen, is_windows\n\n\nProcessContext = Dict[str, str]\n\n\ndef _start_process(cmd: List[str], **kwargs) -> Popen:\n    prefix = [sys.executable]\n    # If it is frozen, sys.executable points to the binary (http).\n    # Otherwise it points to the python interpreter.\n    if not is_frozen:\n        main_entrypoint = httpie.__main__.__file__\n        prefix += [main_entrypoint]\n    return Popen(prefix + cmd, close_fds=True, shell=False, stdout=DEVNULL, stderr=DEVNULL, **kwargs)\n\n\ndef _spawn_windows(cmd: List[str], process_context: ProcessContext) -> None:\n    from subprocess import (\n        CREATE_NEW_PROCESS_GROUP,\n        CREATE_NO_WINDOW,\n        STARTF_USESHOWWINDOW,\n        STARTUPINFO,\n    )\n\n    # https://stackoverflow.com/a/7006424\n    # https://bugs.python.org/issue41619\n    creationflags = CREATE_NEW_PROCESS_GROUP | CREATE_NO_WINDOW\n\n    startupinfo = STARTUPINFO()\n    startupinfo.dwFlags |= STARTF_USESHOWWINDOW\n\n    _start_process(\n        cmd,\n        env=process_context,\n        creationflags=creationflags,\n        startupinfo=startupinfo,\n    )\n\n\ndef _spawn_posix(args: List[str], process_context: ProcessContext) -> None:\n    \"\"\"\n    Perform a double fork procedure* to detach from the parent\n    process so that we don't block the user even if their original\n    command's execution is done but the release fetcher is not.\n\n    [1]: https://pubs.opengroup.org/onlinepubs/9699919799/basedefs/V1_chap11.html#tag_11_01_03\n    \"\"\"\n\n    from httpie.core import main\n\n    try:\n        pid = os.fork()\n        if pid > 0:\n            return\n    except OSError:\n        os._exit(1)\n\n    os.setsid()\n\n    try:\n        pid = os.fork()\n        if pid > 0:\n            os._exit(0)\n    except OSError:\n        os._exit(1)\n\n    # Close all standard inputs/outputs\n    sys.stdin.close()\n    sys.stdout.close()\n    sys.stderr.close()\n\n    if platform.system() == 'Darwin':\n        # Double-fork is not reliable on MacOS, so we'll use a subprocess\n        # to ensure the task is isolated properly.\n        process = _start_process(args, env=process_context)\n        # Unlike windows, since we already completed the fork procedure\n        # we can simply join the process and wait for it.\n        process.communicate()\n    else:\n        os.environ.update(process_context)\n        with suppress(BaseException):\n            main(['http'] + args)\n\n    os._exit(0)\n\n\ndef _spawn(args: List[str], process_context: ProcessContext) -> None:\n    \"\"\"\n    Spawn a new process to run the given command.\n    \"\"\"\n    if is_windows:\n        _spawn_windows(args, process_context)\n    else:\n        _spawn_posix(args, process_context)\n\n\ndef spawn_daemon(task: str) -> None:\n    args = [task, '--daemon']\n    process_context = os.environ.copy()\n    if not is_frozen:\n        file_path = os.path.abspath(inspect.stack()[0][1])\n        process_context['PYTHONPATH'] = os.path.dirname(\n            os.path.dirname(os.path.dirname(file_path))\n        )\n\n    _spawn(args, process_context)\n", "httpie/internal/update_warnings.py": "import json\nfrom contextlib import nullcontext, suppress\nfrom datetime import datetime, timedelta\nfrom pathlib import Path\nfrom typing import Any, Optional, Callable\n\nimport requests\n\nimport httpie\nfrom httpie.context import Environment, LogLevel\nfrom httpie.internal.__build_channel__ import BUILD_CHANNEL\nfrom httpie.internal.daemons import spawn_daemon\nfrom httpie.utils import is_version_greater, open_with_lockfile\n\n# Automatically updated package version index.\nPACKAGE_INDEX_LINK = 'https://packages.httpie.io/latest.json'\n\nFETCH_INTERVAL = timedelta(weeks=2)\nWARN_INTERVAL = timedelta(weeks=1)\n\nUPDATE_MESSAGE_FORMAT = \"\"\"\\\nA new HTTPie release ({last_released_version}) is available.\nTo see how you can update, please visit https://httpie.io/docs/cli/{installation_method}\n\"\"\"\n\nALREADY_UP_TO_DATE_MESSAGE = \"\"\"\\\nYou are already up-to-date.\n\"\"\"\n\n\ndef _read_data_error_free(file: Path) -> Any:\n    # If the file is broken / non-existent, ignore it.\n    try:\n        with open(file) as stream:\n            return json.load(stream)\n    except (ValueError, OSError):\n        return {}\n\n\ndef _fetch_updates(env: Environment) -> str:\n    file = env.config.version_info_file\n    data = _read_data_error_free(file)\n\n    response = requests.get(PACKAGE_INDEX_LINK, verify=False)\n    response.raise_for_status()\n\n    data.setdefault('last_warned_date', None)\n    data['last_fetched_date'] = datetime.now().isoformat()\n    data['last_released_versions'] = response.json()\n\n    with open_with_lockfile(file, 'w') as stream:\n        json.dump(data, stream)\n\n\ndef fetch_updates(env: Environment, lazy: bool = True):\n    if lazy:\n        spawn_daemon('fetch_updates')\n    else:\n        _fetch_updates(env)\n\n\ndef maybe_fetch_updates(env: Environment) -> None:\n    if env.config.get('disable_update_warnings'):\n        return None\n\n    data = _read_data_error_free(env.config.version_info_file)\n\n    if data:\n        current_date = datetime.now()\n        last_fetched_date = datetime.fromisoformat(data['last_fetched_date'])\n        earliest_fetch_date = last_fetched_date + FETCH_INTERVAL\n        if current_date < earliest_fetch_date:\n            return None\n\n    fetch_updates(env)\n\n\ndef _get_suppress_context(env: Environment) -> Any:\n    \"\"\"Return a context manager that suppress\n    all possible errors.\n\n    Note: if you have set the developer_mode=True in\n    your config, then it will show all errors for easier\n    debugging.\"\"\"\n    if env.config.developer_mode:\n        return nullcontext()\n    else:\n        return suppress(BaseException)\n\n\ndef _update_checker(\n    func: Callable[[Environment], None]\n) -> Callable[[Environment], None]:\n    \"\"\"Control the execution of the update checker (suppress errors, trigger\n    auto updates etc.)\"\"\"\n\n    def wrapper(env: Environment) -> None:\n        with _get_suppress_context(env):\n            func(env)\n\n        with _get_suppress_context(env):\n            maybe_fetch_updates(env)\n\n    return wrapper\n\n\ndef _get_update_status(env: Environment) -> Optional[str]:\n    \"\"\"If there is a new update available, return the warning text.\n    Otherwise just return None.\"\"\"\n    file = env.config.version_info_file\n    if not file.exists():\n        return None\n\n    with _get_suppress_context(env):\n        # If the user quickly spawns multiple httpie processes\n        # we don't want to end in a race.\n        with open_with_lockfile(file) as stream:\n            version_info = json.load(stream)\n\n        available_channels = version_info['last_released_versions']\n        if BUILD_CHANNEL not in available_channels:\n            return None\n\n        current_version = httpie.__version__\n        last_released_version = available_channels[BUILD_CHANNEL]\n        if not is_version_greater(last_released_version, current_version):\n            return None\n\n        text = UPDATE_MESSAGE_FORMAT.format(\n            last_released_version=last_released_version,\n            installation_method=BUILD_CHANNEL,\n        )\n        return text\n\n\ndef get_update_status(env: Environment) -> str:\n    return _get_update_status(env) or ALREADY_UP_TO_DATE_MESSAGE\n\n\n@_update_checker\ndef check_updates(env: Environment) -> None:\n    if env.config.get('disable_update_warnings'):\n        return None\n\n    file = env.config.version_info_file\n    update_status = _get_update_status(env)\n\n    if not update_status:\n        return None\n\n    # If the user quickly spawns multiple httpie processes\n    # we don't want to end in a race.\n    with open_with_lockfile(file) as stream:\n        version_info = json.load(stream)\n\n    # We don't want to spam the user with too many warnings,\n    # so we'll only warn every once a while (WARN_INTERNAL).\n    current_date = datetime.now()\n    last_warned_date = version_info['last_warned_date']\n    if last_warned_date is not None:\n        earliest_warn_date = (\n            datetime.fromisoformat(last_warned_date) + WARN_INTERVAL\n        )\n        if current_date < earliest_warn_date:\n            return None\n\n    env.log_error(update_status, level=LogLevel.INFO)\n    version_info['last_warned_date'] = current_date.isoformat()\n\n    with open_with_lockfile(file, 'w') as stream:\n        json.dump(version_info, stream)\n", "httpie/internal/daemon_runner.py": "import argparse\nfrom contextlib import redirect_stderr, redirect_stdout\nfrom typing import List\n\nfrom httpie.context import Environment\nfrom httpie.internal.update_warnings import _fetch_updates, _get_suppress_context\nfrom httpie.status import ExitStatus\n\nSTATUS_FILE = '.httpie-test-daemon-status'\n\n\ndef _check_status(env):\n    # This function is used only for the testing (test_update_warnings).\n    # Since we don't want to trigger the fetch_updates (which would interact\n    # with real world resources), we'll only trigger this pseudo task\n    # and check whether the STATUS_FILE is created or not.\n    import tempfile\n    from pathlib import Path\n\n    status_file = Path(tempfile.gettempdir()) / STATUS_FILE\n    status_file.touch()\n\n\nDAEMONIZED_TASKS = {\n    'check_status': _check_status,\n    'fetch_updates': _fetch_updates,\n}\n\n\ndef _parse_options(args: List[str]) -> argparse.Namespace:\n    parser = argparse.ArgumentParser()\n    parser.add_argument('task_id')\n    parser.add_argument('--daemon', action='store_true')\n    return parser.parse_known_args(args)[0]\n\n\ndef is_daemon_mode(args: List[str]) -> bool:\n    return '--daemon' in args\n\n\ndef run_daemon_task(env: Environment, args: List[str]) -> ExitStatus:\n    options = _parse_options(args)\n\n    assert options.daemon\n    assert options.task_id in DAEMONIZED_TASKS\n    with redirect_stdout(env.devnull), redirect_stderr(env.devnull):\n        with _get_suppress_context(env):\n            DAEMONIZED_TASKS[options.task_id](env)\n\n    return ExitStatus.SUCCESS\n", "httpie/internal/__build_channel__.py": "# Represents the packaging method. This file should\n# be overridden by every build system we support on\n# the packaging step.\n\nBUILD_CHANNEL = 'unknown'\n", "httpie/internal/__init__.py": "", "httpie/legacy/v3_1_0_session_cookie_format.py": "import argparse\nfrom typing import Any, Type, List, Dict, TYPE_CHECKING\n\nif TYPE_CHECKING:\n    from httpie.sessions import Session\n\n\nINSECURE_COOKIE_JAR_WARNING = '''\\\nOutdated layout detected for the current session. Please consider updating it,\nin order to not get affected by potential security problems.\n\nFor fixing the current session:\n\n    With binding all cookies to the current host (secure):\n        $ httpie cli sessions upgrade --bind-cookies {hostname} {session_id}\n\n    Without binding cookies (leaving them as is) (insecure):\n        $ httpie cli sessions upgrade {hostname} {session_id}\n'''\n\n\nINSECURE_COOKIE_JAR_WARNING_FOR_NAMED_SESSIONS = '''\\\n\nFor fixing all named sessions:\n\n    With binding all cookies to the current host (secure):\n        $ httpie cli sessions upgrade-all --bind-cookies\n\n    Without binding cookies (leaving them as is) (insecure):\n        $ httpie cli sessions upgrade-all\n'''\n\nINSECURE_COOKIE_SECURITY_LINK = '\\nSee https://pie.co/docs/security for more information.'\n\n\ndef pre_process(session: 'Session', cookies: Any) -> List[Dict[str, Any]]:\n    \"\"\"Load the given cookies to the cookie jar while maintaining\n    support for the old cookie layout.\"\"\"\n\n    is_old_style = isinstance(cookies, dict)\n    if is_old_style:\n        normalized_cookies = [\n            {\n                'name': key,\n                **value\n            }\n            for key, value in cookies.items()\n        ]\n    else:\n        normalized_cookies = cookies\n\n    should_issue_warning = is_old_style and any(\n        cookie.get('domain', '') == ''\n        for cookie in normalized_cookies\n    )\n\n    if should_issue_warning:\n        warning = INSECURE_COOKIE_JAR_WARNING.format(hostname=session.bound_host, session_id=session.session_id)\n        if not session.is_anonymous:\n            warning += INSECURE_COOKIE_JAR_WARNING_FOR_NAMED_SESSIONS\n        warning += INSECURE_COOKIE_SECURITY_LINK\n        session.warn_legacy_usage(warning)\n\n    return normalized_cookies\n\n\ndef post_process(\n    normalized_cookies: List[Dict[str, Any]],\n    *,\n    original_type: Type[Any]\n) -> Any:\n    \"\"\"Convert the cookies to their original format for\n    maximum compatibility.\"\"\"\n\n    if issubclass(original_type, dict):\n        return {\n            cookie.pop('name'): cookie\n            for cookie in normalized_cookies\n        }\n    else:\n        return normalized_cookies\n\n\ndef fix_layout(session: 'Session', hostname: str, args: argparse.Namespace) -> None:\n    if not isinstance(session['cookies'], dict):\n        return None\n\n    session['cookies'] = [\n        {\n            'name': key,\n            **value\n        }\n        for key, value in session['cookies'].items()\n    ]\n    for cookie in session.cookies:\n        if cookie.domain == '':\n            if args.bind_cookies:\n                cookie.domain = hostname\n            else:\n                cookie._rest['is_explicit_none'] = True\n", "httpie/legacy/v3_2_0_session_header_format.py": "from typing import Any, Type, List, Dict, TYPE_CHECKING\n\nif TYPE_CHECKING:\n    from httpie.sessions import Session\n\n\nOLD_HEADER_STORE_WARNING = '''\\\nOutdated layout detected for the current session. Please consider updating it,\nin order to use the latest features regarding the header layout.\n\nFor fixing the current session:\n\n    $ httpie cli sessions upgrade {hostname} {session_id}\n'''\n\nOLD_HEADER_STORE_WARNING_FOR_NAMED_SESSIONS = '''\\\n\nFor fixing all named sessions:\n\n    $ httpie cli sessions upgrade-all\n'''\n\nOLD_HEADER_STORE_LINK = '\\nSee $INSERT_LINK for more information.'\n\n\ndef pre_process(session: 'Session', headers: Any) -> List[Dict[str, Any]]:\n    \"\"\"Serialize the headers into a unified form and issue a warning if\n    the session file is using the old layout.\"\"\"\n\n    is_old_style = isinstance(headers, dict)\n    if is_old_style:\n        normalized_headers = list(headers.items())\n    else:\n        normalized_headers = [\n            (item['name'], item['value'])\n            for item in headers\n        ]\n\n    if is_old_style:\n        warning = OLD_HEADER_STORE_WARNING.format(hostname=session.bound_host, session_id=session.session_id)\n        if not session.is_anonymous:\n            warning += OLD_HEADER_STORE_WARNING_FOR_NAMED_SESSIONS\n        warning += OLD_HEADER_STORE_LINK\n        session.warn_legacy_usage(warning)\n\n    return normalized_headers\n\n\ndef post_process(\n    normalized_headers: List[Dict[str, Any]],\n    *,\n    original_type: Type[Any]\n) -> Any:\n    \"\"\"Deserialize given header store into the original form it was\n    used in.\"\"\"\n\n    if issubclass(original_type, dict):\n        # For the legacy behavior, preserve the last value.\n        return {\n            item['name']: item['value']\n            for item in normalized_headers\n        }\n    else:\n        return normalized_headers\n\n\ndef fix_layout(session: 'Session', *args, **kwargs) -> None:\n    from httpie.sessions import materialize_headers\n\n    if not isinstance(session['headers'], dict):\n        return None\n\n    session['headers'] = materialize_headers(session['headers'])\n", "httpie/legacy/__init__.py": "", "httpie/cli/options.py": "import argparse\nimport textwrap\nimport typing\nfrom dataclasses import dataclass, field\nfrom enum import Enum, auto\nfrom typing import Any, Optional, Dict, List, Tuple, Type, TypeVar\n\nfrom httpie.cli.argparser import HTTPieArgumentParser\nfrom httpie.cli.utils import Manual, LazyChoices\n\n\nclass Qualifiers(Enum):\n    OPTIONAL = auto()\n    ZERO_OR_MORE = auto()\n    ONE_OR_MORE = auto()\n    SUPPRESS = auto()\n\n\ndef map_qualifiers(\n    configuration: Dict[str, Any], qualifier_map: Dict[Qualifiers, Any]\n) -> Dict[str, Any]:\n    return {\n        key: qualifier_map[value] if isinstance(value, Qualifiers) else value\n        for key, value in configuration.items()\n    }\n\n\ndef drop_keys(\n    configuration: Dict[str, Any], key_blacklist: Tuple[str, ...]\n):\n    return {\n        key: value\n        for key, value in configuration.items()\n        if key not in key_blacklist\n    }\n\n\nPARSER_SPEC_VERSION = '0.0.1a0'\n\n\n@dataclass\nclass ParserSpec:\n    program: str\n    description: Optional[str] = None\n    epilog: Optional[str] = None\n    groups: List['Group'] = field(default_factory=list)\n    man_page_hint: Optional[str] = None\n    source_file: Optional[str] = None\n\n    def finalize(self) -> 'ParserSpec':\n        if self.description:\n            self.description = textwrap.dedent(self.description)\n        if self.epilog:\n            self.epilog = textwrap.dedent(self.epilog)\n        for group in self.groups:\n            group.finalize()\n        return self\n\n    def add_group(self, name: str, **kwargs) -> 'Group':\n        group = Group(name, **kwargs)\n        self.groups.append(group)\n        return group\n\n    def serialize(self) -> Dict[str, Any]:\n        return {\n            'name': self.program,\n            'description': self.description,\n            'groups': [group.serialize() for group in self.groups],\n        }\n\n\n@dataclass\nclass Group:\n    name: str\n    description: str = ''\n    is_mutually_exclusive: bool = False\n    arguments: List['Argument'] = field(default_factory=list)\n\n    def finalize(self) -> None:\n        if self.description:\n            self.description = textwrap.dedent(self.description)\n\n    def add_argument(self, *args, **kwargs):\n        argument = Argument(list(args), kwargs.copy())\n        argument.post_init()\n        self.arguments.append(argument)\n        return argument\n\n    def serialize(self) -> Dict[str, Any]:\n        return {\n            'name': self.name,\n            'description': self.description or None,\n            'is_mutually_exclusive': self.is_mutually_exclusive,\n            'args': [argument.serialize() for argument in self.arguments],\n        }\n\n\nclass Argument(typing.NamedTuple):\n    aliases: List[str]\n    configuration: Dict[str, Any]\n\n    def post_init(self):\n        \"\"\"Run a bunch of post-init hooks.\"\"\"\n        # If there is a short help, then create the longer version from it.\n        short_help = self.configuration.get('short_help')\n        if (\n            short_help\n            and 'help' not in self.configuration\n            and self.configuration.get('action') != 'lazy_choices'\n        ):\n            self.configuration['help'] = f'\\n{short_help}\\n\\n'\n\n    def serialize(self, *, isolation_mode: bool = False) -> Dict[str, Any]:\n        configuration = self.configuration.copy()\n\n        # Unpack the dynamically computed choices, since we\n        # will need to store the actual values somewhere.\n        action = configuration.pop('action', None)\n        short_help = configuration.pop('short_help', None)\n        nested_options = configuration.pop('nested_options', None)\n\n        if action == 'lazy_choices':\n            choices = LazyChoices(\n                self.aliases,\n                **{'dest': None, **configuration},\n                isolation_mode=isolation_mode\n            )\n            configuration['choices'] = list(choices.load())\n            configuration['help'] = choices.help\n\n        result = {}\n        if self.aliases:\n            result['options'] = self.aliases.copy()\n        else:\n            result['options'] = [configuration['metavar']]\n            result['is_positional'] = True\n\n        qualifiers = JSON_QUALIFIER_TO_OPTIONS[configuration.get('nargs', Qualifiers.SUPPRESS)]\n        result.update(qualifiers)\n\n        description = configuration.get('help')\n        if description and description is not Qualifiers.SUPPRESS:\n            result['short_description'] = short_help\n            result['description'] = description\n\n        if nested_options:\n            result['nested_options'] = nested_options\n\n        python_type = configuration.get('type')\n        if python_type is not None:\n            if hasattr(python_type, '__name__'):\n                type_name = python_type.__name__\n            else:\n                type_name = type(python_type).__name__\n\n            result['python_type_name'] = type_name\n\n        result.update({\n            key: value\n            for key, value in configuration.items()\n            if key in JSON_DIRECT_MIRROR_OPTIONS\n            if value is not Qualifiers.SUPPRESS\n        })\n\n        return result\n\n    @property\n    def is_positional(self):\n        return len(self.aliases) == 0\n\n    @property\n    def is_hidden(self):\n        return self.configuration.get('help') is Qualifiers.SUPPRESS\n\n    def __getattr__(self, attribute_name):\n        if attribute_name in self.configuration:\n            return self.configuration[attribute_name]\n        else:\n            raise AttributeError(attribute_name)\n\n\nParserType = TypeVar('ParserType', bound=Type[argparse.ArgumentParser])\n\nARGPARSE_QUALIFIER_MAP = {\n    Qualifiers.OPTIONAL: argparse.OPTIONAL,\n    Qualifiers.SUPPRESS: argparse.SUPPRESS,\n    Qualifiers.ZERO_OR_MORE: argparse.ZERO_OR_MORE,\n    Qualifiers.ONE_OR_MORE: argparse.ONE_OR_MORE\n}\nARGPARSE_IGNORE_KEYS = ('short_help', 'nested_options')\n\n\ndef to_argparse(\n    abstract_options: ParserSpec,\n    parser_type: ParserType = HTTPieArgumentParser,\n) -> ParserType:\n    concrete_parser = parser_type(\n        prog=abstract_options.program,\n        description=abstract_options.description,\n        epilog=abstract_options.epilog,\n    )\n    concrete_parser.spec = abstract_options\n    concrete_parser.register('action', 'lazy_choices', LazyChoices)\n    concrete_parser.register('action', 'manual', Manual)\n\n    for abstract_group in abstract_options.groups:\n        concrete_group = concrete_parser.add_argument_group(\n            title=abstract_group.name, description=abstract_group.description\n        )\n        if abstract_group.is_mutually_exclusive:\n            concrete_group = concrete_group.add_mutually_exclusive_group(required=False)\n\n        for abstract_argument in abstract_group.arguments:\n            concrete_group.add_argument(\n                *abstract_argument.aliases,\n                **drop_keys(map_qualifiers(\n                    abstract_argument.configuration, ARGPARSE_QUALIFIER_MAP\n                ), ARGPARSE_IGNORE_KEYS)\n            )\n\n    return concrete_parser\n\n\nJSON_DIRECT_MIRROR_OPTIONS = (\n    'choices',\n    'metavar'\n)\n\n\nJSON_QUALIFIER_TO_OPTIONS = {\n    Qualifiers.OPTIONAL: {'is_optional': True},\n    Qualifiers.ZERO_OR_MORE: {'is_optional': True, 'is_variadic': True},\n    Qualifiers.ONE_OR_MORE: {'is_optional': False, 'is_variadic': True},\n    Qualifiers.SUPPRESS: {}\n}\n\n\ndef to_data(abstract_options: ParserSpec) -> Dict[str, Any]:\n    return {'version': PARSER_SPEC_VERSION, 'spec': abstract_options.serialize()}\n\n\ndef parser_to_parser_spec(parser: argparse.ArgumentParser, **kwargs) -> ParserSpec:\n    \"\"\"Take an existing argparse parser, and create a spec from it.\"\"\"\n    return ParserSpec(\n        program=parser.prog,\n        description=parser.description,\n        epilog=parser.epilog,\n        **kwargs\n    )\n", "httpie/cli/dicts.py": "from collections import OrderedDict\n\nfrom multidict import MultiDict, CIMultiDict\n\n\nclass BaseMultiDict(MultiDict):\n    \"\"\"\n    Base class for all MultiDicts.\n    \"\"\"\n\n\nclass HTTPHeadersDict(CIMultiDict, BaseMultiDict):\n    \"\"\"\n    Headers are case-insensitive and multiple values are supported\n    through the `add()` API.\n    \"\"\"\n\n    def add(self, key, value):\n        \"\"\"\n        Add or update a new header.\n\n        If the given `value` is `None`, then all the previous\n        values will be overwritten and the value will be set\n        to `None`.\n        \"\"\"\n        if value is None:\n            self[key] = value\n            return None\n\n        # If the previous value for the given header is `None`\n        # then discard it since we are explicitly giving a new\n        # value for it.\n        if key in self and self.getone(key) is None:\n            self.popone(key)\n\n        super().add(key, value)\n\n    def remove_item(self, key, value):\n        \"\"\"\n        Remove a (key, value) pair from the dict.\n        \"\"\"\n        existing_values = self.popall(key)\n        existing_values.remove(value)\n\n        for value in existing_values:\n            self.add(key, value)\n\n\nclass RequestJSONDataDict(OrderedDict):\n    pass\n\n\nclass MultiValueOrderedDict(OrderedDict):\n    \"\"\"Multi-value dict for URL parameters and form data.\"\"\"\n\n    def __setitem__(self, key, value):\n        \"\"\"\n        If `key` is assigned more than once, `self[key]` holds a\n        `list` of all the values.\n\n        This allows having multiple fields with the same name in form\n        data and URL params.\n\n        \"\"\"\n        assert not isinstance(value, list)\n        if key not in self:\n            super().__setitem__(key, value)\n        else:\n            if not isinstance(self[key], list):\n                super().__setitem__(key, [self[key]])\n            self[key].append(value)\n\n    def items(self):\n        for key, values in super().items():\n            if not isinstance(values, list):\n                values = [values]\n            for value in values:\n                yield key, value\n\n\nclass RequestQueryParamsDict(MultiValueOrderedDict):\n    pass\n\n\nclass RequestDataDict(MultiValueOrderedDict):\n    pass\n\n\nclass MultipartRequestDataDict(MultiValueOrderedDict):\n    pass\n\n\nclass RequestFilesDict(RequestDataDict):\n    pass\n", "httpie/cli/exceptions.py": "class ParseError(Exception):\n    pass\n", "httpie/cli/definition.py": "from __future__ import annotations\n\nimport os\nimport textwrap\nfrom argparse import FileType\n\nfrom httpie import __doc__, __version__\nfrom httpie.cli.argtypes import (KeyValueArgType, SessionNameValidator,\n                                 SSLCredentials, readable_file_arg,\n                                 response_charset_type, response_mime_type)\nfrom httpie.cli.constants import (BASE_OUTPUT_OPTIONS, DEFAULT_FORMAT_OPTIONS,\n                                  OUT_REQ_BODY, OUT_REQ_HEAD, OUT_RESP_BODY,\n                                  OUT_RESP_HEAD, OUT_RESP_META, OUTPUT_OPTIONS,\n                                  OUTPUT_OPTIONS_DEFAULT, PRETTY_MAP,\n                                  PRETTY_STDOUT_TTY_ONLY,\n                                  SEPARATOR_GROUP_ALL_ITEMS, SEPARATOR_PROXY,\n                                  SORTED_FORMAT_OPTIONS_STRING,\n                                  UNSORTED_FORMAT_OPTIONS_STRING, RequestType)\nfrom httpie.cli.options import ParserSpec, Qualifiers, to_argparse\nfrom httpie.output.formatters.colors import (AUTO_STYLE, DEFAULT_STYLE, BUNDLED_STYLES,\n                                             get_available_styles)\nfrom httpie.plugins.builtin import BuiltinAuthPlugin\nfrom httpie.plugins.registry import plugin_manager\nfrom httpie.ssl_ import AVAILABLE_SSL_VERSION_ARG_MAPPING, DEFAULT_SSL_CIPHERS_STRING\n\n\n# Man pages are static (built when making a release).\n# We use this check to not include generated, system-specific information there (e.g., default --ciphers).\nIS_MAN_PAGE = bool(os.environ.get('HTTPIE_BUILDING_MAN_PAGES'))\n\n\noptions = ParserSpec(\n    'http',\n    description=f'{__doc__.strip()} <https://httpie.io>',\n    epilog=\"\"\"\n    For every --OPTION there is also a --no-OPTION that reverts OPTION\n    to its default value.\n\n    Suggestions and bug reports are greatly appreciated:\n        https://github.com/httpie/cli/issues\n    \"\"\",\n    source_file=__file__\n)\n\n#######################################################################\n# Positional arguments.\n#######################################################################\n\npositional_arguments = options.add_group(\n    'Positional arguments',\n    description=\"\"\"\n    These arguments come after any flags and in the order they are listed here.\n    Only URL is required.\n    \"\"\",\n)\n\npositional_arguments.add_argument(\n    dest='method',\n    metavar='METHOD',\n    nargs=Qualifiers.OPTIONAL,\n    default=None,\n    short_help='The HTTP method to be used for the request (GET, POST, PUT, DELETE, ...).',\n    help=\"\"\"\n    The HTTP method to be used for the request (GET, POST, PUT, DELETE, ...).\n\n    This argument can be omitted in which case HTTPie will use POST if there\n    is some data to be sent, otherwise GET:\n\n        $ http example.org               # => GET\n        $ http example.org hello=world   # => POST\n\n    \"\"\",\n)\npositional_arguments.add_argument(\n    dest='url',\n    metavar='URL',\n    short_help='The request URL.',\n    help=\"\"\"\n    The request URL. Scheme defaults to 'http://' if the URL\n    does not include one. (You can override this with: --default-scheme=http/https)\n\n    You can also use a shorthand for localhost\n\n        $ http :3000                    # => http://localhost:3000\n        $ http :/foo                    # => http://localhost/foo\n\n    \"\"\",\n)\npositional_arguments.add_argument(\n    dest='request_items',\n    metavar='REQUEST_ITEM',\n    nargs=Qualifiers.ZERO_OR_MORE,\n    default=None,\n    type=KeyValueArgType(*SEPARATOR_GROUP_ALL_ITEMS),\n    short_help=(\n        'HTTPie\u2019s request items syntax for specifying HTTP headers, JSON/Form'\n        'data, files, and URL parameters.'\n    ),\n    nested_options=[\n        ('HTTP Headers', 'Name:Value', 'Arbitrary HTTP header, e.g X-API-Token:123'),\n        ('URL Parameters', 'name==value', 'Querystring parameter to the URL, e.g limit==50'),\n        ('Data Fields', 'field=value', 'Data fields to be serialized as JSON (default) or Form Data (with --form)'),\n        ('Raw JSON Fields', 'field:=json', 'Data field for real JSON types.'),\n        ('File upload Fields', 'field@/dir/file', 'Path field for uploading a file.'),\n    ],\n    help=r\"\"\"\n    Optional key-value pairs to be included in the request. The separator used\n    determines the type:\n\n    ':' HTTP headers:\n\n        Referer:https://httpie.io  Cookie:foo=bar  User-Agent:bacon/1.0\n\n    '==' URL parameters to be appended to the request URI:\n\n        search==httpie\n\n    '=' Data fields to be serialized into a JSON object (with --json, -j)\n        or form data (with --form, -f):\n\n        name=HTTPie  language=Python  description='CLI HTTP client'\n\n    ':=' Non-string JSON data fields (only with --json, -j):\n\n        awesome:=true  amount:=42  colors:='[\"red\", \"green\", \"blue\"]'\n\n    '@' Form file fields (only with --form or --multipart):\n\n        cv@~/Documents/CV.pdf\n        cv@'~/Documents/CV.pdf;type=application/pdf'\n\n    '=@' A data field like '=', but takes a file path and embeds its content:\n\n        essay=@Documents/essay.txt\n\n    ':=@' A raw JSON field like ':=', but takes a file path and embeds its content:\n\n        package:=@./package.json\n\n    You can use a backslash to escape a colliding separator in the field name:\n\n        field-name-with\\:colon=value\n\n    \"\"\",\n)\n\n#######################################################################\n# Content type.\n#######################################################################\n\ncontent_types = options.add_group('Predefined content types')\n\ncontent_types.add_argument(\n    '--json',\n    '-j',\n    action='store_const',\n    const=RequestType.JSON,\n    dest='request_type',\n    short_help='(default) Serialize data items from the command line as a JSON object.',\n    help=\"\"\"\n    (default) Data items from the command line are serialized as a JSON object.\n    The Content-Type and Accept headers are set to application/json\n    (if not specified).\n\n    \"\"\",\n)\ncontent_types.add_argument(\n    '--form',\n    '-f',\n    action='store_const',\n    const=RequestType.FORM,\n    dest='request_type',\n    short_help='Serialize data items from the command line as form field data.',\n    help=\"\"\"\n    Data items from the command line are serialized as form fields.\n\n    The Content-Type is set to application/x-www-form-urlencoded (if not\n    specified). The presence of any file fields results in a\n    multipart/form-data request.\n\n    \"\"\",\n)\ncontent_types.add_argument(\n    '--multipart',\n    action='store_const',\n    const=RequestType.MULTIPART,\n    dest='request_type',\n    short_help=(\n        'Similar to --form, but always sends a multipart/form-data '\n        'request (i.e., even without files).'\n    )\n)\ncontent_types.add_argument(\n    '--boundary',\n    short_help=(\n        'Specify a custom boundary string for multipart/form-data requests. '\n        'Only has effect only together with --form.'\n    )\n)\ncontent_types.add_argument(\n    '--raw',\n    short_help='Pass raw request data without extra processing.',\n    help=\"\"\"\n    This option allows you to pass raw request data without extra processing\n    (as opposed to the structured request items syntax):\n\n        $ http --raw='data' pie.dev/post\n\n    You can achieve the same by piping the data via stdin:\n\n        $ echo data | http pie.dev/post\n\n    Or have HTTPie load the raw data from a file:\n\n        $ http pie.dev/post @data.txt\n\n\n    \"\"\",\n)\n\n#######################################################################\n# Content processing.\n#######################################################################\n\nprocessing_options = options.add_group('Content processing options')\n\nprocessing_options.add_argument(\n    '--compress',\n    '-x',\n    action='count',\n    default=0,\n    short_help='Compress the content with Deflate algorithm.',\n    help=\"\"\"\n    Content compressed (encoded) with Deflate algorithm.\n    The Content-Encoding header is set to deflate.\n\n    Compression is skipped if it appears that compression ratio is\n    negative. Compression can be forced by repeating the argument.\n\n    \"\"\",\n)\n\n\n#######################################################################\n# Output processing\n#######################################################################\n\n\ndef format_style_help(available_styles, *, isolation_mode: bool = False):\n    text = \"\"\"\n    Output coloring style (default is \"{default}\"). It can be one of:\n\n        {available_styles}\n    \"\"\"\n    if isolation_mode:\n        text += '\\n\\n'\n        text += 'For finding out all available styles in your system, try:\\n\\n'\n        text += '    $ http --style\\n'\n    text += textwrap.dedent(\"\"\"\n        The \"{auto_style}\" style follows your terminal's ANSI color styles.\n        For non-{auto_style} styles to work properly, please make sure that the\n        $TERM environment variable is set to \"xterm-256color\" or similar\n        (e.g., via `export TERM=xterm-256color' in your ~/.bashrc).\n    \"\"\")\n\n    if isolation_mode:\n        available_styles = sorted(BUNDLED_STYLES)\n\n    available_styles_text = '\\n'.join(\n        f'    {line.strip()}'\n        for line in textwrap.wrap(', '.join(available_styles), 60)\n    ).strip()\n    return text.format(\n        default=DEFAULT_STYLE,\n        available_styles=available_styles_text,\n        auto_style=AUTO_STYLE,\n    )\n\n\n_sorted_kwargs = {\n    'action': 'append_const',\n    'const': SORTED_FORMAT_OPTIONS_STRING,\n    'dest': 'format_options',\n}\n_unsorted_kwargs = {\n    'action': 'append_const',\n    'const': UNSORTED_FORMAT_OPTIONS_STRING,\n    'dest': 'format_options',\n}\n\noutput_processing = options.add_group('Output processing')\n\noutput_processing.add_argument(\n    '--pretty',\n    dest='prettify',\n    default=PRETTY_STDOUT_TTY_ONLY,\n    choices=sorted(PRETTY_MAP.keys()),\n    short_help='Control the processing of console outputs.',\n    help=\"\"\"\n    Controls output processing. The value can be \"none\" to not prettify\n    the output (default for redirected output), \"all\" to apply both colors\n    and formatting (default for terminal output), \"colors\", or \"format\".\n\n    \"\"\",\n)\noutput_processing.add_argument(\n    '--style',\n    '-s',\n    dest='style',\n    metavar='STYLE',\n    default=DEFAULT_STYLE,\n    action='lazy_choices',\n    getter=get_available_styles,\n    short_help=f'Output coloring style (default is \"{DEFAULT_STYLE}\").',\n    help_formatter=format_style_help,\n)\n\n# The closest approx. of the documented resetting to default via --no-<option>.\n# We hide them from the doc because they act only as low-level aliases here.\noutput_processing.add_argument(\n    '--no-unsorted', **_sorted_kwargs, help=Qualifiers.SUPPRESS\n)\noutput_processing.add_argument(\n    '--no-sorted', **_unsorted_kwargs, help=Qualifiers.SUPPRESS\n)\n\noutput_processing.add_argument(\n    '--unsorted',\n    **_unsorted_kwargs,\n    short_help='Disables all sorting while formatting output.',\n    help=f\"\"\"\n    Disables all sorting while formatting output. It is a shortcut for:\n\n        --format-options={UNSORTED_FORMAT_OPTIONS_STRING}\n\n    \"\"\",\n)\noutput_processing.add_argument(\n    '--sorted',\n    **_sorted_kwargs,\n    short_help='Re-enables all sorting options while formatting output.',\n    help=f\"\"\"\n    Re-enables all sorting options while formatting output. It is a shortcut for:\n\n        --format-options={SORTED_FORMAT_OPTIONS_STRING}\n\n    \"\"\",\n)\noutput_processing.add_argument(\n    '--response-charset',\n    metavar='ENCODING',\n    type=response_charset_type,\n    short_help='Override the response encoding for terminal display purposes.',\n    help=\"\"\"\n    Override the response encoding for terminal display purposes, e.g.:\n\n        --response-charset=utf8\n        --response-charset=big5\n\n    \"\"\",\n)\noutput_processing.add_argument(\n    '--response-mime',\n    metavar='MIME_TYPE',\n    type=response_mime_type,\n    short_help='Override the response mime type for coloring and formatting for the terminal.',\n    help=\"\"\"\n    Override the response mime type for coloring and formatting for the terminal, e.g.:\n\n        --response-mime=application/json\n        --response-mime=text/xml\n\n    \"\"\",\n)\noutput_processing.add_argument(\n    '--format-options',\n    action='append',\n    short_help='Controls output formatting.',\n    help=\"\"\"\n    Controls output formatting. Only relevant when formatting is enabled\n    through (explicit or implied) --pretty=all or --pretty=format.\n    The following are the default options:\n\n        {option_list}\n\n    You may use this option multiple times, as well as specify multiple\n    comma-separated options at the same time. For example, this modifies the\n    settings to disable the sorting of JSON keys, and sets the indent size to 2:\n\n        --format-options json.sort_keys:false,json.indent:2\n\n    This is something you will typically put into your config file.\n\n    \"\"\".format(\n        option_list='\\n'.join(\n            f'        {option}' for option in DEFAULT_FORMAT_OPTIONS\n        ).strip()\n    ),\n)\n\n#######################################################################\n# Output options\n#######################################################################\n\noutput_options = options.add_group('Output options')\n\noutput_options.add_argument(\n    '--print',\n    '-p',\n    dest='output_options',\n    metavar='WHAT',\n    short_help='Options to specify what the console output should contain.',\n    help=f\"\"\"\n    String specifying what the output should contain:\n\n        '{OUT_REQ_HEAD}' request headers\n        '{OUT_REQ_BODY}' request body\n        '{OUT_RESP_HEAD}' response headers\n        '{OUT_RESP_BODY}' response body\n        '{OUT_RESP_META}' response metadata\n\n    The default behaviour is '{OUTPUT_OPTIONS_DEFAULT}' (i.e., the response\n    headers and body is printed), if standard output is not redirected.\n    If the output is piped to another program or to a file, then only the\n    response body is printed by default.\n\n    \"\"\",\n)\noutput_options.add_argument(\n    '--headers',\n    '-h',\n    dest='output_options',\n    action='store_const',\n    const=OUT_RESP_HEAD,\n    short_help='Print only the response headers.',\n    help=f\"\"\"\n    Print only the response headers. Shortcut for --print={OUT_RESP_HEAD}.\n\n    \"\"\",\n)\noutput_options.add_argument(\n    '--meta',\n    '-m',\n    dest='output_options',\n    action='store_const',\n    const=OUT_RESP_META,\n    short_help='Print only the response metadata.',\n    help=f\"\"\"\n    Print only the response metadata. Shortcut for --print={OUT_RESP_META}.\n\n    \"\"\",\n)\noutput_options.add_argument(\n    '--body',\n    '-b',\n    dest='output_options',\n    action='store_const',\n    const=OUT_RESP_BODY,\n    short_help='Print only the response body.',\n    help=f\"\"\"\n    Print only the response body. Shortcut for --print={OUT_RESP_BODY}.\n\n    \"\"\",\n)\n\noutput_options.add_argument(\n    '--verbose',\n    '-v',\n    dest='verbose',\n    action='count',\n    default=0,\n    short_help='Make output more verbose.',\n    help=f\"\"\"\n    Verbose output. For the level one (with single `-v`/`--verbose`), print\n    the whole request as well as the response. Also print any intermediary\n    requests/responses (such as redirects). For the second level and higher,\n    print these as well as the response metadata.\n\n    Level one is a shortcut for: --all --print={''.join(sorted(BASE_OUTPUT_OPTIONS))}\n    Level two is a shortcut for: --all --print={''.join(sorted(OUTPUT_OPTIONS))}\n    \"\"\",\n)\noutput_options.add_argument(\n    '--all',\n    default=False,\n    action='store_true',\n    short_help='Show any intermediary requests/responses.',\n    help=\"\"\"\n    By default, only the final request/response is shown. Use this flag to show\n    any intermediary requests/responses as well. Intermediary requests include\n    followed redirects (with --follow), the first unauthorized request when\n    Digest auth is used (--auth=digest), etc.\n\n    \"\"\",\n)\noutput_options.add_argument(\n    '--history-print',\n    '-P',\n    dest='output_options_history',\n    metavar='WHAT',\n    help=Qualifiers.SUPPRESS,\n)\noutput_options.add_argument(\n    '--stream',\n    '-S',\n    action='store_true',\n    default=False,\n    short_help='Always stream the response body by line, i.e., behave like `tail -f`.',\n    help=\"\"\"\n    Always stream the response body by line, i.e., behave like `tail -f'.\n\n    Without --stream and with --pretty (either set or implied),\n    HTTPie fetches the whole response before it outputs the processed data.\n\n    Set this option when you want to continuously display a prettified\n    long-lived response, such as one from the Twitter streaming API.\n\n    It is useful also without --pretty: It ensures that the output is flushed\n    more often and in smaller chunks.\n\n    \"\"\",\n)\noutput_options.add_argument(\n    '--output',\n    '-o',\n    type=FileType('a+b'),\n    dest='output_file',\n    metavar='FILE',\n    short_help='Save output to FILE instead of stdout.',\n    help=\"\"\"\n    Save output to FILE instead of stdout. If --download is also set, then only\n    the response body is saved to FILE. Other parts of the HTTP exchange are\n    printed to stderr.\n\n    \"\"\",\n)\n\noutput_options.add_argument(\n    '--download',\n    '-d',\n    action='store_true',\n    default=False,\n    short_help='Download the body to a file instead of printing it to stdout.',\n    help=\"\"\"\n    Do not print the response body to stdout. Rather, download it and store it\n    in a file. The filename is guessed unless specified with --output\n    [filename]. This action is similar to the default behaviour of wget.\n\n    \"\"\",\n)\noutput_options.add_argument(\n    '--continue',\n    '-c',\n    dest='download_resume',\n    action='store_true',\n    default=False,\n    short_help='Resume an interrupted download (--output needs to be specified).',\n    help=\"\"\"\n    Resume an interrupted download. Note that the --output option needs to be\n    specified as well.\n\n    \"\"\",\n)\noutput_options.add_argument(\n    '--quiet',\n    '-q',\n    action='count',\n    default=0,\n    short_help='Do not print to stdout or stderr, except for errors and warnings when provided once.',\n    help=\"\"\"\n    Do not print to stdout or stderr, except for errors and warnings when provided once.\n    Provide twice to suppress warnings as well.\n    stdout is still redirected if --output is specified.\n    Flag doesn't affect behaviour of download beyond not printing to terminal.\n\n    \"\"\",\n)\n\n#######################################################################\n# Sessions\n#######################################################################\n\nsession_name_validator = SessionNameValidator(\n    'Session name contains invalid characters.'\n)\n\nsessions = options.add_group('Sessions', is_mutually_exclusive=True)\n\nsessions.add_argument(\n    '--session',\n    metavar='SESSION_NAME_OR_PATH',\n    type=session_name_validator,\n    short_help='Create, or reuse and update a session.',\n    help=\"\"\"\n    Create, or reuse and update a session. Within a session, custom headers,\n    auth credential, as well as any cookies sent by the server persist between\n    requests.\n\n    Session files are stored in:\n\n        [HTTPIE_CONFIG_DIR]/<HOST>/<SESSION_NAME>.json.\n\n    See the following page to find out your default HTTPIE_CONFIG_DIR:\n\n        https://httpie.io/docs/cli/config-file-directory\n    \"\"\",\n)\nsessions.add_argument(\n    '--session-read-only',\n    metavar='SESSION_NAME_OR_PATH',\n    type=session_name_validator,\n    short_help='Create or read a session without updating it',\n    help=\"\"\"\n    Create or read a session without updating it form the request/response\n    exchange.\n\n    \"\"\",\n)\n\n\n#######################################################################\n# Authentication\n#######################################################################\n\n\ndef format_auth_help(auth_plugins_mapping, *, isolation_mode: bool = False):\n    text = \"\"\"\n    The authentication mechanism to be used. Defaults to \"{default}\".\n\n    {auth_types}\n    \"\"\"\n\n    auth_plugins = list(auth_plugins_mapping.values())\n    if isolation_mode:\n        auth_plugins = [\n            auth_plugin\n            for auth_plugin in auth_plugins\n            if issubclass(auth_plugin, BuiltinAuthPlugin)\n        ]\n        text += '\\n'\n        text += 'To see all available auth types on your system, including ones installed via plugins, run:\\n\\n'\n        text += '    $ http --auth-type'\n\n    auth_types = '\\n\\n    '.join(\n        '\"{type}\": {name}{package}{description}'.format(\n            type=plugin.auth_type,\n            name=plugin.name,\n            package=(\n                ''\n                if issubclass(plugin, BuiltinAuthPlugin)\n                else f' (provided by {plugin.package_name})'\n            ),\n            description=(\n                ''\n                if not plugin.description\n                else '\\n      '\n                     + ('\\n      '.join(textwrap.wrap(plugin.description)))\n            ),\n        )\n        for plugin in auth_plugins\n    )\n\n    return text.format(\n        default=auth_plugins[0].auth_type,\n        auth_types=auth_types,\n    )\n\n\nauthentication = options.add_group('Authentication')\n\nauthentication.add_argument(\n    '--auth',\n    '-a',\n    default=None,\n    metavar='USER[:PASS] | TOKEN',\n    short_help='Credentials for the selected (-A) authentication method.',\n    help=\"\"\"\n    For username/password based authentication mechanisms (e.g\n    basic auth or digest auth) if only the username is provided\n    (-a username), HTTPie will prompt for the password.\n\n    \"\"\",\n)\nauthentication.add_argument(\n    '--auth-type',\n    '-A',\n    action='lazy_choices',\n    default=None,\n    getter=plugin_manager.get_auth_plugin_mapping,\n    sort=True,\n    cache=False,\n    short_help='The authentication mechanism to be used.',\n    help_formatter=format_auth_help,\n)\nauthentication.add_argument(\n    '--ignore-netrc',\n    default=False,\n    action='store_true',\n    short_help='Ignore credentials from .netrc.'\n)\n\n#######################################################################\n# Network\n#######################################################################\n\nnetwork = options.add_group('Network')\n\nnetwork.add_argument(\n    '--offline',\n    default=False,\n    action='store_true',\n    short_help='Build the request and print it but don\u2019t actually send it.'\n)\nnetwork.add_argument(\n    '--proxy',\n    default=[],\n    action='append',\n    metavar='PROTOCOL:PROXY_URL',\n    type=KeyValueArgType(SEPARATOR_PROXY),\n    short_help='String mapping of protocol to the URL of the proxy.',\n    help=\"\"\"\n    String mapping protocol to the URL of the proxy\n    (e.g. http:http://foo.bar:3128). You can specify multiple proxies with\n    different protocols. The environment variables $ALL_PROXY, $HTTP_PROXY,\n    and $HTTPS_proxy are supported as well.\n\n    \"\"\",\n)\nnetwork.add_argument(\n    '--follow',\n    '-F',\n    default=False,\n    action='store_true',\n    short_help='Follow 30x Location redirects.'\n)\n\nnetwork.add_argument(\n    '--max-redirects',\n    type=int,\n    default=30,\n    short_help='The maximum number of redirects that should be followed (with --follow).',\n    help=\"\"\"\n    By default, requests have a limit of 30 redirects (works with --follow).\n\n    \"\"\",\n)\nnetwork.add_argument(\n    '--max-headers',\n    type=int,\n    default=0,\n    short_help=(\n        'The maximum number of response headers to be read before '\n        'giving up (default 0, i.e., no limit).'\n    )\n)\n\nnetwork.add_argument(\n    '--timeout',\n    type=float,\n    default=0,\n    metavar='SECONDS',\n    short_help='The connection timeout of the request in seconds.',\n    help=\"\"\"\n    The connection timeout of the request in seconds.\n    The default value is 0, i.e., there is no timeout limit.\n    This is not a time limit on the entire response download;\n    rather, an error is reported if the server has not issued a response for\n    timeout seconds (more precisely, if no bytes have been received on\n    the underlying socket for timeout seconds).\n\n    \"\"\",\n)\nnetwork.add_argument(\n    '--check-status',\n    default=False,\n    action='store_true',\n    short_help='Exit with an error status code if the server replies with an error.',\n    help=\"\"\"\n    By default, HTTPie exits with 0 when no network or other fatal errors\n    occur. This flag instructs HTTPie to also check the HTTP status code and\n    exit with an error if the status indicates one.\n\n    When the server replies with a 4xx (Client Error) or 5xx (Server Error)\n    status code, HTTPie exits with 4 or 5 respectively. If the response is a\n    3xx (Redirect) and --follow hasn't been set, then the exit status is 3.\n    Also an error message is written to stderr if stdout is redirected.\n\n    \"\"\",\n)\nnetwork.add_argument(\n    '--path-as-is',\n    default=False,\n    action='store_true',\n    short_help='Bypass dot segment (/../ or /./) URL squashing.'\n)\nnetwork.add_argument(\n    '--chunked',\n    default=False,\n    action='store_true',\n    short_help=(\n        'Enable streaming via chunked transfer encoding. '\n        'The Transfer-Encoding header is set to chunked.'\n    )\n)\n\n#######################################################################\n# SSL\n#######################################################################\n\nssl = options.add_group('SSL')\n\nssl.add_argument(\n    '--verify',\n    default='yes',\n    short_help='If \"no\", skip SSL verification. If a file path, use it as a CA bundle.',\n    help=\"\"\"\n    Set to \"no\" (or \"false\") to skip checking the host's SSL certificate.\n    Defaults to \"yes\" (\"true\"). You can also pass the path to a CA_BUNDLE file\n    for private certs. (Or you can set the REQUESTS_CA_BUNDLE environment\n    variable instead.)\n    \"\"\",\n)\nssl.add_argument(\n    '--ssl',\n    dest='ssl_version',\n    choices=sorted(AVAILABLE_SSL_VERSION_ARG_MAPPING.keys()),\n    short_help='The desired protocol version to used.',\n    help=\"\"\"\n    The desired protocol version to use. This will default to\n    SSL v2.3 which will negotiate the highest protocol that both\n    the server and your installation of OpenSSL support. Available protocols\n    may vary depending on OpenSSL installation (only the supported ones\n    are shown here).\n\n    \"\"\",\n)\n\nCIPHERS_CURRENT_DEFAULTS = (\n    \"\"\"\n    See `http --help` for the default ciphers list on you system.\n\n    \"\"\"\n    if IS_MAN_PAGE else\n    f\"\"\"\n    By default, the following ciphers are used on your system:\n\n    {DEFAULT_SSL_CIPHERS_STRING}\n\n    \"\"\"\n)\nssl.add_argument(\n    '--ciphers',\n    short_help='A string in the OpenSSL cipher list format.',\n    help=f\"\"\"\n\n    A string in the OpenSSL cipher list format.\n\n    {CIPHERS_CURRENT_DEFAULTS}\n\n    \"\"\"\n)\nssl.add_argument(\n    '--cert',\n    default=None,\n    type=readable_file_arg,\n    short_help='Specifies a local cert to use as the client-side SSL certificate.',\n    help=\"\"\"\n    You can specify a local cert to use as client side SSL certificate.\n    This file may either contain both private key and certificate or you may\n    specify --cert-key separately.\n\n    \"\"\",\n)\nssl.add_argument(\n    '--cert-key',\n    default=None,\n    type=readable_file_arg,\n    short_help='The private key to use with SSL. Only needed if --cert is given.',\n    help=\"\"\"\n    The private key to use with SSL. Only needed if --cert is given and the\n    certificate file does not contain the private key.\n\n    \"\"\",\n)\n\nssl.add_argument(\n    '--cert-key-pass',\n    default=None,\n    type=SSLCredentials,\n    short_help='The passphrase to be used to with the given private key.',\n    help=\"\"\"\n    The passphrase to be used to with the given private key. Only needed if --cert-key\n    is given and the key file requires a passphrase.\n    If not provided, you\u2019ll be prompted interactively.\n    \"\"\"\n)\n\n#######################################################################\n# Troubleshooting\n#######################################################################\n\ntroubleshooting = options.add_group('Troubleshooting')\ntroubleshooting.add_argument(\n    '--ignore-stdin',\n    '-I',\n    action='store_true',\n    default=False,\n    short_help='Do not attempt to read stdin'\n)\ntroubleshooting.add_argument(\n    '--help',\n    action='help',\n    default=Qualifiers.SUPPRESS,\n    short_help='Show this help message and exit.',\n)\ntroubleshooting.add_argument(\n    '--manual',\n    action='manual',\n    default=Qualifiers.SUPPRESS,\n    short_help='Show the full manual.',\n)\ntroubleshooting.add_argument(\n    '--version',\n    action='version',\n    version=__version__,\n    short_help='Show version and exit.',\n)\ntroubleshooting.add_argument(\n    '--traceback',\n    action='store_true',\n    default=False,\n    short_help='Prints the exception traceback should one occur.',\n)\ntroubleshooting.add_argument(\n    '--default-scheme',\n    default='http',\n    short_help='The default scheme to use if not specified in the URL.'\n)\ntroubleshooting.add_argument(\n    '--debug',\n    action='store_true',\n    default=False,\n    short_help='Print useful diagnostic information for bug reports.',\n    help=\"\"\"\n    Prints the exception traceback should one occur, as well as other\n    information useful for debugging HTTPie itself and for reporting bugs.\n\n    \"\"\",\n)\n\n#######################################################################\n# Finalization\n#######################################################################\n\noptions.finalize()\nparser = to_argparse(options)\n", "httpie/cli/utils.py": "import argparse\nfrom typing import Any, Callable, Generic, Iterator, Iterable, Optional, TypeVar\n\nT = TypeVar('T')\n\n\nclass Manual(argparse.Action):\n    def __init__(\n        self,\n        option_strings,\n        dest=argparse.SUPPRESS,\n        default=argparse.SUPPRESS,\n        help=None\n    ):\n        super().__init__(\n            option_strings=option_strings,\n            dest=dest,\n            default=default,\n            nargs=0,\n            help=help\n        )\n\n    def __call__(self, parser, namespace, values, option_string=None):\n        parser.print_manual()\n        parser.exit()\n\n\nclass LazyChoices(argparse.Action, Generic[T]):\n    def __init__(\n        self,\n        *args,\n        getter: Callable[[], Iterable[T]],\n        help_formatter: Optional[Callable[[T, bool], str]] = None,\n        sort: bool = False,\n        cache: bool = True,\n        isolation_mode: bool = False,\n        **kwargs\n    ) -> None:\n        self.getter = getter\n        self.help_formatter = help_formatter\n        self.sort = sort\n        self.cache = cache\n        self.isolation_mode = isolation_mode\n        self._help: Optional[str] = None\n        self._obj: Optional[Iterable[T]] = None\n        super().__init__(*args, **kwargs)\n        self.choices = self\n\n    def load(self) -> T:\n        if self._obj is None or not self.cache:\n            self._obj = self.getter()\n\n        assert self._obj is not None\n        return self._obj\n\n    @property\n    def help(self) -> str:\n        if self._help is None and self.help_formatter is not None:\n            self._help = self.help_formatter(\n                self.load(),\n                isolation_mode=self.isolation_mode\n            )\n        return self._help\n\n    @help.setter\n    def help(self, value: Any) -> None:\n        self._help = value\n\n    def __contains__(self, item: Any) -> bool:\n        return item in self.load()\n\n    def __iter__(self) -> Iterator[T]:\n        if self.sort:\n            return iter(sorted(self.load()))\n        else:\n            return iter(self.load())\n\n    def __call__(self, parser, namespace, values, option_string=None):\n        setattr(namespace, self.dest, values)\n", "httpie/cli/constants.py": "\"\"\"Parsing and processing of CLI input (args, auth credentials, files, stdin).\n\n\"\"\"\nimport enum\nimport re\n\n\nURL_SCHEME_RE = re.compile(r'^[a-z][a-z0-9.+-]*://', re.IGNORECASE)\n\nHTTP_POST = 'POST'\nHTTP_GET = 'GET'\nHTTP_OPTIONS = 'OPTIONS'\n\n# Various separators used in args\nSEPARATOR_HEADER = ':'\nSEPARATOR_HEADER_EMPTY = ';'\nSEPARATOR_CREDENTIALS = ':'\nSEPARATOR_PROXY = ':'\nSEPARATOR_HEADER_EMBED = ':@'\nSEPARATOR_DATA_STRING = '='\nSEPARATOR_DATA_RAW_JSON = ':='\nSEPARATOR_FILE_UPLOAD = '@'\nSEPARATOR_FILE_UPLOAD_TYPE = ';type='  # in already parsed file upload path only\nSEPARATOR_DATA_EMBED_FILE_CONTENTS = '=@'\nSEPARATOR_DATA_EMBED_RAW_JSON_FILE = ':=@'\nSEPARATOR_QUERY_PARAM = '=='\nSEPARATOR_QUERY_EMBED_FILE = '==@'\n\n# Separators that become request data\nSEPARATOR_GROUP_DATA_ITEMS = frozenset({\n    SEPARATOR_DATA_STRING,\n    SEPARATOR_DATA_RAW_JSON,\n    SEPARATOR_FILE_UPLOAD,\n    SEPARATOR_DATA_EMBED_FILE_CONTENTS,\n    SEPARATOR_DATA_EMBED_RAW_JSON_FILE\n})\n\nSEPARATORS_GROUP_MULTIPART = frozenset({\n    SEPARATOR_DATA_STRING,\n    SEPARATOR_DATA_EMBED_FILE_CONTENTS,\n    SEPARATOR_FILE_UPLOAD,\n})\n\n# Separators for items whose value is a filename to be embedded\nSEPARATOR_GROUP_DATA_EMBED_ITEMS = frozenset({\n    SEPARATOR_HEADER_EMBED,\n    SEPARATOR_QUERY_EMBED_FILE,\n    SEPARATOR_DATA_EMBED_FILE_CONTENTS,\n    SEPARATOR_DATA_EMBED_RAW_JSON_FILE,\n})\n\n# Separators for nested JSON items\nSEPARATOR_GROUP_NESTED_JSON_ITEMS = frozenset([\n    SEPARATOR_DATA_STRING,\n    SEPARATOR_DATA_RAW_JSON,\n    SEPARATOR_DATA_EMBED_FILE_CONTENTS,\n    SEPARATOR_DATA_EMBED_RAW_JSON_FILE,\n])\n\n# Separators allowed in ITEM arguments\nSEPARATOR_GROUP_ALL_ITEMS = frozenset({\n    SEPARATOR_HEADER,\n    SEPARATOR_HEADER_EMPTY,\n    SEPARATOR_HEADER_EMBED,\n    SEPARATOR_QUERY_PARAM,\n    SEPARATOR_QUERY_EMBED_FILE,\n    SEPARATOR_DATA_STRING,\n    SEPARATOR_DATA_RAW_JSON,\n    SEPARATOR_FILE_UPLOAD,\n    SEPARATOR_DATA_EMBED_FILE_CONTENTS,\n    SEPARATOR_DATA_EMBED_RAW_JSON_FILE,\n})\n\n# Output options\nOUT_REQ_HEAD = 'H'\nOUT_REQ_BODY = 'B'\nOUT_RESP_HEAD = 'h'\nOUT_RESP_BODY = 'b'\nOUT_RESP_META = 'm'\n\nBASE_OUTPUT_OPTIONS = frozenset({\n    OUT_REQ_HEAD,\n    OUT_REQ_BODY,\n    OUT_RESP_HEAD,\n    OUT_RESP_BODY,\n})\n\nOUTPUT_OPTIONS = frozenset({\n    *BASE_OUTPUT_OPTIONS,\n    OUT_RESP_META,\n})\n\n# Pretty\n\n\nclass PrettyOptions(enum.Enum):\n    STDOUT_TTY_ONLY = enum.auto()\n\n\nPRETTY_MAP = {\n    'all': ['format', 'colors'],\n    'colors': ['colors'],\n    'format': ['format'],\n    'none': []\n}\nPRETTY_STDOUT_TTY_ONLY = PrettyOptions.STDOUT_TTY_ONLY\n\n\nDEFAULT_FORMAT_OPTIONS = [\n    'headers.sort:true',\n    'json.format:true',\n    'json.indent:4',\n    'json.sort_keys:true',\n    'xml.format:true',\n    'xml.indent:2',\n]\nSORTED_FORMAT_OPTIONS = [\n    'headers.sort:true',\n    'json.sort_keys:true',\n]\nSORTED_FORMAT_OPTIONS_STRING = ','.join(SORTED_FORMAT_OPTIONS)\nUNSORTED_FORMAT_OPTIONS_STRING = ','.join(\n    option.replace('true', 'false') for option in SORTED_FORMAT_OPTIONS)\n\n# Defaults\nOUTPUT_OPTIONS_DEFAULT = OUT_RESP_HEAD + OUT_RESP_BODY\nOUTPUT_OPTIONS_DEFAULT_STDOUT_REDIRECTED = OUT_RESP_BODY\nOUTPUT_OPTIONS_DEFAULT_OFFLINE = OUT_REQ_HEAD + OUT_REQ_BODY\n\n\nclass RequestType(enum.Enum):\n    FORM = enum.auto()\n    MULTIPART = enum.auto()\n    JSON = enum.auto()\n", "httpie/cli/argtypes.py": "import argparse\nimport getpass\nimport os\nimport sys\nfrom copy import deepcopy\nfrom typing import List, Optional, Union\n\nfrom .constants import DEFAULT_FORMAT_OPTIONS, SEPARATOR_CREDENTIALS\nfrom ..sessions import VALID_SESSION_NAME_PATTERN\n\n\nclass KeyValueArg:\n    \"\"\"Base key-value pair parsed from CLI.\"\"\"\n\n    def __init__(self, key: str, value: Optional[str], sep: str, orig: str):\n        self.key = key\n        self.value = value\n        self.sep = sep\n        self.orig = orig\n\n    def __eq__(self, other: 'KeyValueArg'):\n        return self.__dict__ == other.__dict__\n\n    def __repr__(self):\n        return repr(self.__dict__)\n\n\nclass SessionNameValidator:\n\n    def __init__(self, error_message: str):\n        self.error_message = error_message\n\n    def __call__(self, value: str) -> str:\n        # Session name can be a path or just a name.\n        if (os.path.sep not in value\n                and not VALID_SESSION_NAME_PATTERN.search(value)):\n            raise argparse.ArgumentError(None, self.error_message)\n        return value\n\n\nclass Escaped(str):\n    \"\"\"Represents an escaped character.\"\"\"\n\n    def __repr__(self):\n        return f\"Escaped({repr(str(self))})\"\n\n\nclass KeyValueArgType:\n    \"\"\"A key-value pair argument type used with `argparse`.\n\n    Parses a key-value arg and constructs a `KeyValueArg` instance.\n    Used for headers, form data, and other key-value pair types.\n\n    \"\"\"\n\n    key_value_class = KeyValueArg\n\n    def __init__(self, *separators: str):\n        self.separators = separators\n        self.special_characters = set()\n        for separator in separators:\n            self.special_characters.update(separator)\n\n    def __call__(self, s: str) -> KeyValueArg:\n        \"\"\"Parse raw string arg and return `self.key_value_class` instance.\n\n        The best of `self.separators` is determined (first found, longest).\n        Back slash escaped characters aren't considered as separators\n        (or parts thereof). Literal back slash characters have to be escaped\n        as well (r'\\\\').\n\n        \"\"\"\n        tokens = self.tokenize(s)\n\n        # Sorting by length ensures that the longest one will be\n        # chosen as it will overwrite any shorter ones starting\n        # at the same position in the `found` dictionary.\n        separators = sorted(self.separators, key=len)\n\n        for i, token in enumerate(tokens):\n\n            if isinstance(token, Escaped):\n                continue\n\n            found = {}\n            for sep in separators:\n                pos = token.find(sep)\n                if pos != -1:\n                    found[pos] = sep\n\n            if found:\n                # Starting first, longest separator found.\n                sep = found[min(found.keys())]\n\n                key, value = token.split(sep, 1)\n\n                # Any preceding tokens are part of the key.\n                key = ''.join(tokens[:i]) + key\n\n                # Any following tokens are part of the value.\n                value += ''.join(tokens[i + 1:])\n\n                break\n\n        else:\n            raise argparse.ArgumentTypeError(f'{s!r} is not a valid value')\n\n        return self.key_value_class(key=key, value=value, sep=sep, orig=s)\n\n    def tokenize(self, s: str) -> List[Union[str, Escaped]]:\n        r\"\"\"Tokenize the raw arg string\n\n        There are only two token types - strings and escaped characters:\n\n        >>> KeyValueArgType('=').tokenize(r'foo\\=bar\\\\baz')\n        ['foo', Escaped('='), 'bar\\\\\\\\baz']\n\n        \"\"\"\n        tokens = ['']\n        characters = iter(s)\n        for char in characters:\n            if char == '\\\\':\n                char = next(characters, '')\n                if char not in self.special_characters:\n                    tokens[-1] += '\\\\' + char\n                else:\n                    tokens.extend([Escaped(char), ''])\n            else:\n                tokens[-1] += char\n        return tokens\n\n\nclass PromptMixin:\n    def _prompt_password(self, prompt: str) -> str:\n        prompt_text = f'http: {prompt}: '\n        try:\n            return self._getpass(prompt_text)\n        except (EOFError, KeyboardInterrupt):\n            sys.stderr.write('\\n')\n            sys.exit(0)\n\n    @staticmethod\n    def _getpass(prompt):\n        # To allow easy mocking.\n        return getpass.getpass(str(prompt))\n\n\nclass SSLCredentials(PromptMixin):\n    \"\"\"Represents the passphrase for the certificate's key.\"\"\"\n\n    def __init__(self, value: Optional[str]) -> None:\n        self.value = value\n\n    def prompt_password(self, key_file: str) -> None:\n        self.value = self._prompt_password(f'passphrase for {key_file}')\n\n\nclass AuthCredentials(KeyValueArg, PromptMixin):\n    \"\"\"Represents parsed credentials.\"\"\"\n\n    def has_password(self) -> bool:\n        return self.value is not None\n\n    def prompt_password(self, host: str) -> None:\n        self.value = self._prompt_password(f'password for {self.key}@{host}:')\n\n\nclass AuthCredentialsArgType(KeyValueArgType):\n    \"\"\"A key-value arg type that parses credentials.\"\"\"\n\n    key_value_class = AuthCredentials\n\n    def __call__(self, s):\n        \"\"\"Parse credentials from `s`.\n\n        (\"username\" or \"username:password\").\n\n        \"\"\"\n        try:\n            return super().__call__(s)\n        except argparse.ArgumentTypeError:\n            # No password provided, will prompt for it later.\n            return self.key_value_class(\n                key=s,\n                value=None,\n                sep=SEPARATOR_CREDENTIALS,\n                orig=s\n            )\n\n\nparse_auth = AuthCredentialsArgType(SEPARATOR_CREDENTIALS)\n\n\ndef readable_file_arg(filename):\n    try:\n        with open(filename, 'rb'):\n            return filename\n    except OSError as ex:\n        raise argparse.ArgumentTypeError(f'{ex.filename}: {ex.strerror}')\n\n\ndef parse_format_options(s: str, defaults: Optional[dict]) -> dict:\n    \"\"\"\n    Parse `s` and update `defaults` with the parsed values.\n\n    >>> parse_format_options(\n    ... defaults={'json': {'indent': 4, 'sort_keys': True}},\n    ... s='json.indent:2,json.sort_keys:False',\n    ... )\n    {'json': {'indent': 2, 'sort_keys': False}}\n\n    \"\"\"\n    value_map = {\n        'true': True,\n        'false': False,\n    }\n    options = deepcopy(defaults or {})\n    for option in s.split(','):\n        try:\n            path, value = option.lower().split(':')\n            section, key = path.split('.')\n        except ValueError:\n            raise argparse.ArgumentTypeError(f'invalid option {option!r}')\n\n        if value in value_map:\n            parsed_value = value_map[value]\n        else:\n            if value.isnumeric():\n                parsed_value = int(value)\n            else:\n                parsed_value = value\n\n        if defaults is None:\n            options.setdefault(section, {})\n        else:\n            try:\n                default_value = defaults[section][key]\n            except KeyError:\n                raise argparse.ArgumentTypeError(\n                    f'invalid key {path!r}')\n\n            default_type, parsed_type = type(default_value), type(parsed_value)\n            if parsed_type is not default_type:\n                raise argparse.ArgumentTypeError(\n                    'invalid value'\n                    f' {value!r} in {option!r}'\n                    f' (expected {default_type.__name__}'\n                    f' got {parsed_type.__name__})'\n                )\n\n        options[section][key] = parsed_value\n\n    return options\n\n\nPARSED_DEFAULT_FORMAT_OPTIONS = parse_format_options(\n    s=','.join(DEFAULT_FORMAT_OPTIONS),\n    defaults=None,\n)\n\n\ndef response_charset_type(encoding: str) -> str:\n    try:\n        ''.encode(encoding)\n    except LookupError:\n        raise argparse.ArgumentTypeError(\n            f'{encoding!r} is not a supported encoding')\n    return encoding\n\n\ndef response_mime_type(mime_type: str) -> str:\n    if mime_type.count('/') != 1:\n        raise argparse.ArgumentTypeError(\n            f'{mime_type!r} doesn\u2019t look like a mime type; use type/subtype')\n    return mime_type\n", "httpie/cli/__init__.py": "", "httpie/cli/requestitems.py": "import os\nimport functools\nfrom typing import Callable, Dict, IO, List, Optional, Tuple, Union\n\nfrom .argtypes import KeyValueArg\nfrom .constants import (\n    SEPARATORS_GROUP_MULTIPART, SEPARATOR_DATA_EMBED_FILE_CONTENTS,\n    SEPARATOR_DATA_EMBED_RAW_JSON_FILE, SEPARATOR_GROUP_NESTED_JSON_ITEMS,\n    SEPARATOR_DATA_RAW_JSON, SEPARATOR_DATA_STRING, SEPARATOR_FILE_UPLOAD,\n    SEPARATOR_FILE_UPLOAD_TYPE, SEPARATOR_HEADER, SEPARATOR_HEADER_EMPTY,\n    SEPARATOR_HEADER_EMBED, SEPARATOR_QUERY_PARAM,\n    SEPARATOR_QUERY_EMBED_FILE, RequestType\n)\nfrom .dicts import (\n    BaseMultiDict, MultipartRequestDataDict, RequestDataDict,\n    RequestFilesDict, HTTPHeadersDict, RequestJSONDataDict,\n    RequestQueryParamsDict,\n)\nfrom .exceptions import ParseError\nfrom .nested_json import interpret_nested_json\nfrom ..utils import get_content_type, load_json_preserve_order_and_dupe_keys, split_iterable\n\n\nclass RequestItems:\n\n    def __init__(self, request_type: Optional[RequestType] = None):\n        self.headers = HTTPHeadersDict()\n        self.request_type = request_type\n        self.is_json = request_type is None or request_type is RequestType.JSON\n        self.data = RequestJSONDataDict() if self.is_json else RequestDataDict()\n        self.files = RequestFilesDict()\n        self.params = RequestQueryParamsDict()\n        # To preserve the order of fields in file upload multipart requests.\n        self.multipart_data = MultipartRequestDataDict()\n\n    @classmethod\n    def from_args(\n        cls,\n        request_item_args: List[KeyValueArg],\n        request_type: Optional[RequestType] = None,\n    ) -> 'RequestItems':\n        instance = cls(request_type=request_type)\n        rules: Dict[str, Tuple[Callable, dict]] = {\n            SEPARATOR_HEADER: (\n                process_header_arg,\n                instance.headers,\n            ),\n            SEPARATOR_HEADER_EMPTY: (\n                process_empty_header_arg,\n                instance.headers,\n            ),\n            SEPARATOR_HEADER_EMBED: (\n                process_embed_header_arg,\n                instance.headers,\n            ),\n            SEPARATOR_QUERY_PARAM: (\n                process_query_param_arg,\n                instance.params,\n            ),\n            SEPARATOR_QUERY_EMBED_FILE: (\n                process_embed_query_param_arg,\n                instance.params,\n            ),\n            SEPARATOR_FILE_UPLOAD: (\n                process_file_upload_arg,\n                instance.files,\n            ),\n            SEPARATOR_DATA_STRING: (\n                process_data_item_arg,\n                instance.data,\n            ),\n            SEPARATOR_DATA_EMBED_FILE_CONTENTS: (\n                process_data_embed_file_contents_arg,\n                instance.data,\n            ),\n            SEPARATOR_GROUP_NESTED_JSON_ITEMS: (\n                process_data_nested_json_embed_args,\n                instance.data,\n            ),\n            SEPARATOR_DATA_RAW_JSON: (\n                convert_json_value_to_form_if_needed(\n                    in_json_mode=instance.is_json,\n                    processor=process_data_raw_json_embed_arg\n                ),\n                instance.data,\n            ),\n            SEPARATOR_DATA_EMBED_RAW_JSON_FILE: (\n                convert_json_value_to_form_if_needed(\n                    in_json_mode=instance.is_json,\n                    processor=process_data_embed_raw_json_file_arg,\n                ),\n                instance.data,\n            ),\n        }\n\n        if instance.is_json:\n            json_item_args, request_item_args = split_iterable(\n                iterable=request_item_args,\n                key=lambda arg: arg.sep in SEPARATOR_GROUP_NESTED_JSON_ITEMS\n            )\n            if json_item_args:\n                pairs = [(arg.key, rules[arg.sep][0](arg)) for arg in json_item_args]\n                processor_func, target_dict = rules[SEPARATOR_GROUP_NESTED_JSON_ITEMS]\n                value = processor_func(pairs)\n                target_dict.update(value)\n\n        # Then handle all other items.\n        for arg in request_item_args:\n            processor_func, target_dict = rules[arg.sep]\n            value = processor_func(arg)\n\n            if arg.sep in SEPARATORS_GROUP_MULTIPART:\n                instance.multipart_data[arg.key] = value\n\n            if isinstance(target_dict, BaseMultiDict):\n                target_dict.add(arg.key, value)\n            else:\n                target_dict[arg.key] = value\n\n        return instance\n\n\nJSONType = Union[str, bool, int, list, dict]\n\n\ndef process_header_arg(arg: KeyValueArg) -> Optional[str]:\n    return arg.value or None\n\n\ndef process_embed_header_arg(arg: KeyValueArg) -> str:\n    return load_text_file(arg).rstrip('\\n')\n\n\ndef process_empty_header_arg(arg: KeyValueArg) -> str:\n    if not arg.value:\n        return arg.value\n    raise ParseError(\n        f'Invalid item {arg.orig!r} (to specify an empty header use `Header;`)'\n    )\n\n\ndef process_query_param_arg(arg: KeyValueArg) -> str:\n    return arg.value\n\n\ndef process_embed_query_param_arg(arg: KeyValueArg) -> str:\n    return load_text_file(arg).rstrip('\\n')\n\n\ndef process_file_upload_arg(arg: KeyValueArg) -> Tuple[str, IO, str]:\n    parts = arg.value.split(SEPARATOR_FILE_UPLOAD_TYPE)\n    filename = parts[0]\n    mime_type = parts[1] if len(parts) > 1 else None\n    try:\n        f = open(os.path.expanduser(filename), 'rb')\n    except OSError as e:\n        raise ParseError(f'{arg.orig!r}: {e}')\n    return (\n        os.path.basename(filename),\n        f,\n        mime_type or get_content_type(filename),\n    )\n\n\ndef convert_json_value_to_form_if_needed(in_json_mode: bool, processor: Callable[[KeyValueArg], JSONType]) -> Callable[[], str]:\n    \"\"\"\n    We allow primitive values to be passed to forms via JSON key/value syntax.\n\n    But complex values lead to an error because there\u2019s no clear way to serialize them.\n\n    \"\"\"\n    if in_json_mode:\n        return processor\n\n    @functools.wraps(processor)\n    def wrapper(*args, **kwargs) -> str:\n        try:\n            output = processor(*args, **kwargs)\n        except ParseError:\n            output = None\n        if isinstance(output, (str, int, float)):\n            return str(output)\n        else:\n            raise ParseError('Cannot use complex JSON value types with --form/--multipart.')\n\n    return wrapper\n\n\ndef process_data_item_arg(arg: KeyValueArg) -> str:\n    return arg.value\n\n\ndef process_data_embed_file_contents_arg(arg: KeyValueArg) -> str:\n    return load_text_file(arg)\n\n\ndef process_data_embed_raw_json_file_arg(arg: KeyValueArg) -> JSONType:\n    contents = load_text_file(arg)\n    value = load_json(arg, contents)\n    return value\n\n\ndef process_data_raw_json_embed_arg(arg: KeyValueArg) -> JSONType:\n    value = load_json(arg, arg.value)\n    return value\n\n\ndef process_data_nested_json_embed_args(pairs) -> Dict[str, JSONType]:\n    return interpret_nested_json(pairs)\n\n\ndef load_text_file(item: KeyValueArg) -> str:\n    path = item.value\n    try:\n        with open(os.path.expanduser(path), 'rb') as f:\n            return f.read().decode()\n    except OSError as e:\n        raise ParseError(f'{item.orig!r}: {e}')\n    except UnicodeDecodeError:\n        raise ParseError(\n            f'{item.orig!r}: cannot embed the content of {item.value!r},'\n            ' not a UTF-8 or ASCII-encoded text file'\n        )\n\n\ndef load_json(arg: KeyValueArg, contents: str) -> JSONType:\n    try:\n        return load_json_preserve_order_and_dupe_keys(contents)\n    except ValueError as e:\n        raise ParseError(f'{arg.orig!r}: {e}')\n", "httpie/cli/argparser.py": "import argparse\nimport errno\nimport os\nimport re\nimport sys\nfrom argparse import RawDescriptionHelpFormatter\nfrom textwrap import dedent\nfrom urllib.parse import urlsplit\n\nfrom requests.utils import get_netrc_auth\n\nfrom .argtypes import (\n    AuthCredentials, SSLCredentials, KeyValueArgType,\n    PARSED_DEFAULT_FORMAT_OPTIONS,\n    parse_auth,\n    parse_format_options,\n)\nfrom .constants import (\n    HTTP_GET, HTTP_POST, BASE_OUTPUT_OPTIONS, OUTPUT_OPTIONS, OUTPUT_OPTIONS_DEFAULT,\n    OUTPUT_OPTIONS_DEFAULT_OFFLINE, OUTPUT_OPTIONS_DEFAULT_STDOUT_REDIRECTED,\n    OUT_RESP_BODY, PRETTY_MAP, PRETTY_STDOUT_TTY_ONLY, RequestType,\n    SEPARATOR_CREDENTIALS,\n    SEPARATOR_GROUP_ALL_ITEMS, SEPARATOR_GROUP_DATA_ITEMS, URL_SCHEME_RE,\n)\nfrom .exceptions import ParseError\nfrom .requestitems import RequestItems\nfrom ..context import Environment\nfrom ..plugins.registry import plugin_manager\nfrom ..utils import ExplicitNullAuth, get_content_type\n\n\nclass HTTPieHelpFormatter(RawDescriptionHelpFormatter):\n    \"\"\"A nicer help formatter.\n\n    Help for arguments can be indented and contain new lines.\n    It will be de-dented and arguments in the help\n    will be separated by a blank line for better readability.\n\n\n    \"\"\"\n\n    def __init__(self, max_help_position=6, *args, **kwargs):\n        # A smaller indent for args help.\n        kwargs['max_help_position'] = max_help_position\n        super().__init__(*args, **kwargs)\n\n    def _split_lines(self, text, width):\n        text = dedent(text).strip() + '\\n\\n'\n        return text.splitlines()\n\n    def add_usage(self, usage, actions, groups, prefix=None):\n        # Only display the positional arguments\n        displayed_actions = [\n            action\n            for action in actions\n            if not action.option_strings\n        ]\n\n        _, exception, _ = sys.exc_info()\n        if (\n            isinstance(exception, argparse.ArgumentError)\n            and len(exception.args) >= 1\n            and isinstance(exception.args[0], argparse.Action)\n        ):\n            # add_usage path is also taken when you pass an invalid option,\n            # e.g --style=invalid. If something like that happens, we want\n            # to include to action that caused to the invalid usage into\n            # the list of actions we are displaying.\n            displayed_actions.insert(0, exception.args[0])\n\n        super().add_usage(\n            usage,\n            displayed_actions,\n            groups,\n            prefix=\"usage:\\n    \"\n        )\n\n\n# TODO: refactor and design type-annotated data structures\n#       for raw args + parsed args and keep things immutable.\nclass BaseHTTPieArgumentParser(argparse.ArgumentParser):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.env = None\n        self.args = None\n        self.has_stdin_data = False\n        self.has_input_data = False\n\n    # noinspection PyMethodOverriding\n    def parse_args(\n        self,\n        env: Environment,\n        args=None,\n        namespace=None\n    ) -> argparse.Namespace:\n        self.env = env\n        self.args, no_options = self.parse_known_args(args, namespace)\n        if self.args.debug:\n            self.args.traceback = True\n        self.has_stdin_data = (\n            self.env.stdin\n            and not getattr(self.args, 'ignore_stdin', False)\n            and not self.env.stdin_isatty\n        )\n        self.has_input_data = self.has_stdin_data or getattr(self.args, 'raw', None) is not None\n        return self.args\n\n    # noinspection PyShadowingBuiltins\n    def _print_message(self, message, file=None):\n        # Sneak in our stderr/stdout.\n        if hasattr(self, 'root'):\n            env = self.root.env\n        else:\n            env = self.env\n\n        if env is not None:\n            file = {\n                sys.stdout: env.stdout,\n                sys.stderr: env.stderr,\n                None: env.stderr\n            }.get(file, file)\n\n        if not hasattr(file, 'buffer') and isinstance(message, str):\n            message = message.encode(env.stdout_encoding)\n        super()._print_message(message, file)\n\n\nclass HTTPieManagerArgumentParser(BaseHTTPieArgumentParser):\n    def parse_known_args(self, args=None, namespace=None):\n        try:\n            return super().parse_known_args(args, namespace)\n        except SystemExit as exc:\n            if not hasattr(self, 'root') and exc.code == 2:  # Argument Parser Error\n                raise argparse.ArgumentError(None, None)\n            raise\n\n\nclass HTTPieArgumentParser(BaseHTTPieArgumentParser):\n    \"\"\"Adds additional logic to `argparse.ArgumentParser`.\n\n    Handles all input (CLI args, file args, stdin), applies defaults,\n    and performs extra validation.\n\n    \"\"\"\n\n    def __init__(self, *args, formatter_class=HTTPieHelpFormatter, **kwargs):\n        kwargs.setdefault('add_help', False)\n        super().__init__(*args, formatter_class=formatter_class, **kwargs)\n\n    # noinspection PyMethodOverriding\n    def parse_args(\n        self,\n        env: Environment,\n        args=None,\n        namespace=None\n    ) -> argparse.Namespace:\n        self.env = env\n        self.env.args = namespace = namespace or argparse.Namespace()\n        self.args, no_options = super().parse_known_args(args, namespace)\n        if self.args.debug:\n            self.args.traceback = True\n        self.has_stdin_data = (\n            self.env.stdin\n            and not self.args.ignore_stdin\n            and not self.env.stdin_isatty\n        )\n        self.has_input_data = self.has_stdin_data or self.args.raw is not None\n        # Arguments processing and environment setup.\n        self._apply_no_options(no_options)\n        self._process_request_type()\n        self._process_download_options()\n        self._setup_standard_streams()\n        self._process_output_options()\n        self._process_pretty_options()\n        self._process_format_options()\n        self._guess_method()\n        self._parse_items()\n        self._process_url()\n        self._process_auth()\n        self._process_ssl_cert()\n\n        if self.args.raw is not None:\n            self._body_from_input(self.args.raw)\n        elif self.has_stdin_data:\n            self._body_from_file(self.env.stdin)\n\n        if self.args.compress:\n            # TODO: allow --compress with --chunked / --multipart\n            if self.args.chunked:\n                self.error('cannot combine --compress and --chunked')\n            if self.args.multipart:\n                self.error('cannot combine --compress and --multipart')\n\n        return self.args\n\n    def _process_request_type(self):\n        request_type = self.args.request_type\n        self.args.json = request_type is RequestType.JSON\n        self.args.multipart = request_type is RequestType.MULTIPART\n        self.args.form = request_type in {\n            RequestType.FORM,\n            RequestType.MULTIPART,\n        }\n\n    def _process_url(self):\n        if self.args.url.startswith('://'):\n            # Paste URL & add space shortcut: `http ://pie.dev` \u2192 `http://pie.dev`\n            self.args.url = self.args.url[3:]\n        if not URL_SCHEME_RE.match(self.args.url):\n            if os.path.basename(self.env.program_name) == 'https':\n                scheme = 'https://'\n            else:\n                scheme = self.args.default_scheme + '://'\n\n            # See if we're using curl style shorthand for localhost (:3000/foo)\n            shorthand = re.match(r'^:(?!:)(\\d*)(/?.*)$', self.args.url)\n            if shorthand:\n                port = shorthand.group(1)\n                rest = shorthand.group(2)\n                self.args.url = scheme + 'localhost'\n                if port:\n                    self.args.url += ':' + port\n                self.args.url += rest\n            else:\n                self.args.url = scheme + self.args.url\n\n    def _setup_standard_streams(self):\n        \"\"\"\n        Modify `env.stdout` and `env.stdout_isatty` based on args, if needed.\n\n        \"\"\"\n\n        self.args.output_file_specified = bool(self.args.output_file)\n        if self.args.download:\n            # FIXME: Come up with a cleaner solution.\n            if not self.args.output_file and not self.env.stdout_isatty:\n                # Use stdout as the download output file.\n                self.args.output_file = self.env.stdout\n            # With `--download`, we write everything that would normally go to\n            # `stdout` to `stderr` instead. Let's replace the stream so that\n            # we don't have to use many `if`s throughout the codebase.\n            # The response body will be treated separately.\n            self.env.stdout = self.env.stderr\n            self.env.stdout_isatty = self.env.stderr_isatty\n\n        elif self.args.output_file:\n            # When not `--download`ing, then `--output` simply replaces\n            # `stdout`. The file is opened for appending, which isn't what\n            # we want in this case.\n            self.args.output_file.seek(0)\n            try:\n                self.args.output_file.truncate()\n            except OSError as e:\n                if e.errno == errno.EINVAL:\n                    # E.g. /dev/null on Linux.\n                    pass\n                else:\n                    raise\n            self.env.stdout = self.args.output_file\n            self.env.stdout_isatty = False\n\n        if self.args.quiet:\n            self.env.quiet = self.args.quiet\n            self.env.stderr = self.env.devnull\n            if not (self.args.output_file_specified and not self.args.download):\n                self.env.stdout = self.env.devnull\n            self.env.apply_warnings_filter()\n\n    def _process_ssl_cert(self):\n        from httpie.ssl_ import _is_key_file_encrypted\n\n        if self.args.cert_key_pass is None:\n            self.args.cert_key_pass = SSLCredentials(None)\n\n        if (\n            self.args.cert_key is not None\n            and self.args.cert_key_pass.value is None\n            and _is_key_file_encrypted(self.args.cert_key)\n        ):\n            self.args.cert_key_pass.prompt_password(self.args.cert_key)\n\n    def _process_auth(self):\n        # TODO: refactor & simplify this method.\n        self.args.auth_plugin = None\n        default_auth_plugin = plugin_manager.get_auth_plugins()[0]\n        auth_type_set = self.args.auth_type is not None\n        url = urlsplit(self.args.url)\n\n        if self.args.auth is None and not auth_type_set:\n            if url.username is not None:\n                # Handle http://username:password@hostname/\n                username = url.username\n                password = url.password or ''\n                self.args.auth = AuthCredentials(\n                    key=username,\n                    value=password,\n                    sep=SEPARATOR_CREDENTIALS,\n                    orig=SEPARATOR_CREDENTIALS.join([username, password])\n                )\n\n        if self.args.auth is not None or auth_type_set:\n            if not self.args.auth_type:\n                self.args.auth_type = default_auth_plugin.auth_type\n            plugin = plugin_manager.get_auth_plugin(self.args.auth_type)()\n\n            if (not self.args.ignore_netrc\n                    and self.args.auth is None\n                    and plugin.netrc_parse):\n                # Only host needed, so it\u2019s OK URL not finalized.\n                netrc_credentials = get_netrc_auth(self.args.url)\n                if netrc_credentials:\n                    self.args.auth = AuthCredentials(\n                        key=netrc_credentials[0],\n                        value=netrc_credentials[1],\n                        sep=SEPARATOR_CREDENTIALS,\n                        orig=SEPARATOR_CREDENTIALS.join(netrc_credentials)\n                    )\n\n            if plugin.auth_require and self.args.auth is None:\n                self.error('--auth required')\n\n            plugin.raw_auth = self.args.auth\n            self.args.auth_plugin = plugin\n            already_parsed = isinstance(self.args.auth, AuthCredentials)\n\n            if self.args.auth is None or not plugin.auth_parse:\n                self.args.auth = plugin.get_auth()\n            else:\n                if already_parsed:\n                    # from the URL\n                    credentials = self.args.auth\n                else:\n                    credentials = parse_auth(self.args.auth)\n\n                if (not credentials.has_password()\n                        and plugin.prompt_password):\n                    if self.args.ignore_stdin:\n                        # Non-tty stdin read by now\n                        self.error(\n                            'Unable to prompt for passwords because'\n                            ' --ignore-stdin is set.'\n                        )\n                    credentials.prompt_password(url.netloc)\n\n                if (credentials.key and credentials.value):\n                    plugin.raw_auth = credentials.key + \":\" + credentials.value\n\n                self.args.auth = plugin.get_auth(\n                    username=credentials.key,\n                    password=credentials.value,\n                )\n        if not self.args.auth and self.args.ignore_netrc:\n            # Set a no-op auth to force requests to ignore .netrc\n            # <https://github.com/psf/requests/issues/2773#issuecomment-174312831>\n            self.args.auth = ExplicitNullAuth()\n\n    def _apply_no_options(self, no_options):\n        \"\"\"For every `--no-OPTION` in `no_options`, set `args.OPTION` to\n        its default value. This allows for un-setting of options, e.g.,\n        specified in config.\n\n        \"\"\"\n        invalid = []\n\n        for option in no_options:\n            if not option.startswith('--no-'):\n                invalid.append(option)\n                continue\n\n            # --no-option => --option\n            inverted = '--' + option[5:]\n            for action in self._actions:\n                if inverted in action.option_strings:\n                    setattr(self.args, action.dest, action.default)\n                    break\n            else:\n                invalid.append(option)\n\n        if invalid:\n            self.error(f'unrecognized arguments: {\" \".join(invalid)}')\n\n    def _body_from_file(self, fd):\n        \"\"\"Read the data from a file-like object.\n\n        Bytes are always read.\n\n        \"\"\"\n        self._ensure_one_data_source(self.args.data, self.args.files)\n        self.args.data = getattr(fd, 'buffer', fd)\n\n    def _body_from_input(self, data):\n        \"\"\"Read the data from the CLI.\n\n        \"\"\"\n        self._ensure_one_data_source(self.has_stdin_data, self.args.data,\n                                     self.args.files)\n        self.args.data = data.encode()\n\n    def _ensure_one_data_source(self, *other_sources):\n        \"\"\"There can only be one source of input request data.\n\n        \"\"\"\n        if any(other_sources):\n            self.error('Request body (from stdin, --raw or a file) and request '\n                       'data (key=value) cannot be mixed. Pass '\n                       '--ignore-stdin to let key/value take priority. '\n                       'See https://httpie.io/docs#scripting for details.')\n\n    def _guess_method(self):\n        \"\"\"Set `args.method` if not specified to either POST or GET\n        based on whether the request has data or not.\n\n        \"\"\"\n        if self.args.method is None:\n            # Invoked as `http URL'.\n            assert not self.args.request_items\n            if self.has_input_data:\n                self.args.method = HTTP_POST\n            else:\n                self.args.method = HTTP_GET\n\n        # FIXME: False positive, e.g., \"localhost\" matches but is a valid URL.\n        elif not re.match('^[a-zA-Z]+$', self.args.method):\n            # Invoked as `http URL item+'. The URL is now in `args.method`\n            # and the first ITEM is now incorrectly in `args.url`.\n            try:\n                # Parse the URL as an ITEM and store it as the first ITEM arg.\n                self.args.request_items.insert(0, KeyValueArgType(\n                    *SEPARATOR_GROUP_ALL_ITEMS).__call__(self.args.url))\n\n            except argparse.ArgumentTypeError as e:\n                if self.args.traceback:\n                    raise\n                self.error(e.args[0])\n\n            else:\n                # Set the URL correctly\n                self.args.url = self.args.method\n                # Infer the method\n                has_data = (\n                    self.has_input_data\n                    or any(\n                        item.sep in SEPARATOR_GROUP_DATA_ITEMS\n                        for item in self.args.request_items)\n                )\n                self.args.method = HTTP_POST if has_data else HTTP_GET\n\n    def _parse_items(self):\n        \"\"\"\n        Parse `args.request_items` into `args.headers`, `args.data`,\n        `args.params`, and `args.files`.\n\n        \"\"\"\n        try:\n            request_items = RequestItems.from_args(\n                request_item_args=self.args.request_items,\n                request_type=self.args.request_type,\n            )\n        except ParseError as e:\n            if self.args.traceback:\n                raise\n            self.error(e.args[0])\n        else:\n            self.args.headers = request_items.headers\n            self.args.data = request_items.data\n            self.args.files = request_items.files\n            self.args.params = request_items.params\n            self.args.multipart_data = request_items.multipart_data\n\n        if self.args.files and not self.args.form:\n            # `http url @/path/to/file`\n            request_file = None\n            for key, file in self.args.files.items():\n                if key != '':\n                    self.error(\n                        'Invalid file fields (perhaps you meant --form?):'\n                        f' {\",\".join(self.args.files.keys())}')\n                if request_file is not None:\n                    self.error(\"Can't read request from multiple files\")\n                request_file = file\n\n            fn, fd, ct = request_file\n            self.args.files = {}\n\n            self._body_from_file(fd)\n\n            if 'Content-Type' not in self.args.headers:\n                content_type = get_content_type(fn)\n                if content_type:\n                    self.args.headers['Content-Type'] = content_type\n\n    def _process_output_options(self):\n        \"\"\"Apply defaults to output options, or validate the provided ones.\n\n        The default output options are stdout-type-sensitive.\n\n        \"\"\"\n\n        def check_options(value, option):\n            unknown = set(value) - OUTPUT_OPTIONS\n            if unknown:\n                self.error(f'Unknown output options: {option}={\",\".join(unknown)}')\n\n        if self.args.verbose:\n            self.args.all = True\n\n        if self.args.output_options is None:\n            if self.args.verbose >= 2:\n                self.args.output_options = ''.join(OUTPUT_OPTIONS)\n            elif self.args.verbose == 1:\n                self.args.output_options = ''.join(BASE_OUTPUT_OPTIONS)\n            elif self.args.offline:\n                self.args.output_options = OUTPUT_OPTIONS_DEFAULT_OFFLINE\n            elif not self.env.stdout_isatty:\n                self.args.output_options = OUTPUT_OPTIONS_DEFAULT_STDOUT_REDIRECTED\n            else:\n                self.args.output_options = OUTPUT_OPTIONS_DEFAULT\n\n        if self.args.output_options_history is None:\n            self.args.output_options_history = self.args.output_options\n\n        check_options(self.args.output_options, '--print')\n        check_options(self.args.output_options_history, '--history-print')\n\n        if self.args.download and OUT_RESP_BODY in self.args.output_options:\n            # Response body is always downloaded with --download and it goes\n            # through a different routine, so we remove it.\n            self.args.output_options = str(\n                set(self.args.output_options) - set(OUT_RESP_BODY))\n\n    def _process_pretty_options(self):\n        if self.args.prettify == PRETTY_STDOUT_TTY_ONLY:\n            self.args.prettify = PRETTY_MAP[\n                'all' if self.env.stdout_isatty else 'none']\n        elif (self.args.prettify and self.env.is_windows\n              and self.args.output_file):\n            self.error('Only terminal output can be colorized on Windows.')\n        else:\n            # noinspection PyTypeChecker\n            self.args.prettify = PRETTY_MAP[self.args.prettify]\n\n    def _process_download_options(self):\n        if self.args.offline:\n            self.args.download = False\n            self.args.download_resume = False\n            return\n        if not self.args.download:\n            if self.args.download_resume:\n                self.error('--continue only works with --download')\n        if self.args.download_resume and not (\n                self.args.download and self.args.output_file):\n            self.error('--continue requires --output to be specified')\n\n    def _process_format_options(self):\n        format_options = self.args.format_options or []\n        parsed_options = PARSED_DEFAULT_FORMAT_OPTIONS\n        for options_group in format_options:\n            parsed_options = parse_format_options(options_group, defaults=parsed_options)\n        self.args.format_options = parsed_options\n\n    def print_manual(self):\n        from httpie.output.ui import man_pages\n\n        if man_pages.is_available(self.env.program_name):\n            man_pages.display_for(self.env, self.env.program_name)\n            return None\n\n        text = self.format_help()\n        with self.env.rich_console.pager():\n            self.env.rich_console.print(\n                text,\n                highlight=False\n            )\n\n    def print_usage(self, file):\n        from rich.text import Text\n        from httpie.output.ui import rich_help\n\n        whitelist = set()\n        _, exception, _ = sys.exc_info()\n        if (\n            isinstance(exception, argparse.ArgumentError)\n            and len(exception.args) >= 1\n            and isinstance(exception.args[0], argparse.Action)\n            and exception.args[0].option_strings\n        ):\n            # add_usage path is also taken when you pass an invalid option,\n            # e.g --style=invalid. If something like that happens, we want\n            # to include to action that caused to the invalid usage into\n            # the list of actions we are displaying.\n            whitelist.add(exception.args[0].option_strings[0])\n\n        usage_text = Text('usage', style='bold')\n        usage_text.append(':\\n    ')\n        usage_text.append(rich_help.to_usage(self.spec, whitelist=whitelist))\n        self.env.rich_error_console.print(usage_text)\n\n    def error(self, message):\n        \"\"\"Prints a usage message incorporating the message to stderr and\n        exits.\"\"\"\n        self.print_usage(sys.stderr)\n        self.env.rich_error_console.print(\n            dedent(\n                f'''\n                [bold]error[/bold]:\n                    {message}\n\n                [bold]for more information[/bold]:\n                    run '{self.prog} --help' or visit https://httpie.io/docs/cli\n                '''.rstrip()\n            )\n        )\n        self.exit(2)\n", "httpie/cli/nested_json/tokens.py": "from enum import Enum, auto\nfrom typing import NamedTuple, Union, Optional, List\n\nEMPTY_STRING = ''\nHIGHLIGHTER = '^'\nOPEN_BRACKET = '['\nCLOSE_BRACKET = ']'\nBACKSLASH = '\\\\'\n\n\nclass TokenKind(Enum):\n    TEXT = auto()\n    NUMBER = auto()\n    LEFT_BRACKET = auto()\n    RIGHT_BRACKET = auto()\n    PSEUDO = auto()  # Not a real token, use when representing location only.\n\n    def to_name(self) -> str:\n        for key, value in OPERATORS.items():\n            if value is self:\n                return repr(key)\n        else:\n            return 'a ' + self.name.lower()\n\n\nOPERATORS = {\n    OPEN_BRACKET: TokenKind.LEFT_BRACKET,\n    CLOSE_BRACKET: TokenKind.RIGHT_BRACKET,\n}\nSPECIAL_CHARS = OPERATORS.keys() | {BACKSLASH}\nLITERAL_TOKENS = [\n    TokenKind.TEXT,\n    TokenKind.NUMBER,\n]\n\n\nclass Token(NamedTuple):\n    kind: TokenKind\n    value: Union[str, int]\n    start: int\n    end: int\n\n\nclass PathAction(Enum):\n    KEY = auto()\n    INDEX = auto()\n    APPEND = auto()\n    # Pseudo action, used by the interpreter\n    SET = auto()\n\n    def to_string(self) -> str:\n        return self.name.lower()\n\n\nclass Path:\n    def __init__(\n        self,\n        kind: PathAction,\n        accessor: Optional[Union[str, int]] = None,\n        tokens: Optional[List[Token]] = None,\n        is_root: bool = False,\n    ):\n        self.kind = kind\n        self.accessor = accessor\n        self.tokens = tokens or []\n        self.is_root = is_root\n\n    def reconstruct(self) -> str:\n        if self.kind is PathAction.KEY:\n            if self.is_root:\n                return str(self.accessor)\n            return OPEN_BRACKET + self.accessor + CLOSE_BRACKET\n        elif self.kind is PathAction.INDEX:\n            return OPEN_BRACKET + str(self.accessor) + CLOSE_BRACKET\n        elif self.kind is PathAction.APPEND:\n            return OPEN_BRACKET + CLOSE_BRACKET\n\n\nclass NestedJSONArray(list):\n    \"\"\"Denotes a top-level JSON array.\"\"\"\n", "httpie/cli/nested_json/parse.py": "from typing import Iterator\n\nfrom .errors import NestedJSONSyntaxError\nfrom .tokens import (\n    EMPTY_STRING,\n    BACKSLASH,\n    TokenKind,\n    OPERATORS,\n    SPECIAL_CHARS,\n    LITERAL_TOKENS,\n    Token,\n    PathAction,\n    Path,\n)\n\n\n__all__ = [\n    'parse',\n    'assert_cant_happen',\n]\n\n\ndef parse(source: str) -> Iterator[Path]:\n    \"\"\"\n    start: root_path path*\n    root_path: (literal | index_path | append_path)\n    literal: TEXT | NUMBER\n\n    path:\n        key_path\n        | index_path\n        | append_path\n    key_path: LEFT_BRACKET TEXT RIGHT_BRACKET\n    index_path: LEFT_BRACKET NUMBER RIGHT_BRACKET\n    append_path: LEFT_BRACKET RIGHT_BRACKET\n\n    \"\"\"\n\n    tokens = list(tokenize(source))\n    cursor = 0\n\n    def can_advance():\n        return cursor < len(tokens)\n\n    # noinspection PyShadowingNames\n    def expect(*kinds):\n        nonlocal cursor\n        assert kinds\n        if can_advance():\n            token = tokens[cursor]\n            cursor += 1\n            if token.kind in kinds:\n                return token\n        elif tokens:\n            token = tokens[-1]._replace(\n                start=tokens[-1].end + 0,\n                end=tokens[-1].end + 1,\n            )\n        else:\n            token = None\n        if len(kinds) == 1:\n            suffix = kinds[0].to_name()\n        else:\n            suffix = ', '.join(kind.to_name() for kind in kinds[:-1])\n            suffix += ' or ' + kinds[-1].to_name()\n        message = f'Expecting {suffix}'\n        raise NestedJSONSyntaxError(source, token, message)\n\n    # noinspection PyShadowingNames\n    def parse_root():\n        tokens = []\n        if not can_advance():\n            return Path(\n                kind=PathAction.KEY,\n                accessor=EMPTY_STRING,\n                is_root=True\n            )\n        # (literal | index_path | append_path)?\n        token = expect(*LITERAL_TOKENS, TokenKind.LEFT_BRACKET)\n        tokens.append(token)\n        if token.kind in LITERAL_TOKENS:\n            action = PathAction.KEY\n            value = str(token.value)\n        elif token.kind is TokenKind.LEFT_BRACKET:\n            token = expect(TokenKind.NUMBER, TokenKind.RIGHT_BRACKET)\n            tokens.append(token)\n            if token.kind is TokenKind.NUMBER:\n                action = PathAction.INDEX\n                value = token.value\n                tokens.append(expect(TokenKind.RIGHT_BRACKET))\n            elif token.kind is TokenKind.RIGHT_BRACKET:\n                action = PathAction.APPEND\n                value = None\n            else:\n                assert_cant_happen()\n        else:\n            assert_cant_happen()\n        # noinspection PyUnboundLocalVariable\n        return Path(\n            kind=action,\n            accessor=value,\n            tokens=tokens,\n            is_root=True\n        )\n\n    yield parse_root()\n\n    # path*\n    while can_advance():\n        path_tokens = [expect(TokenKind.LEFT_BRACKET)]\n        token = expect(TokenKind.TEXT, TokenKind.NUMBER, TokenKind.RIGHT_BRACKET)\n        path_tokens.append(token)\n        if token.kind is TokenKind.RIGHT_BRACKET:\n            path = Path(PathAction.APPEND, tokens=path_tokens)\n        elif token.kind is TokenKind.TEXT:\n            path = Path(PathAction.KEY, token.value, tokens=path_tokens)\n            path_tokens.append(expect(TokenKind.RIGHT_BRACKET))\n        elif token.kind is TokenKind.NUMBER:\n            path = Path(PathAction.INDEX, token.value, tokens=path_tokens)\n            path_tokens.append(expect(TokenKind.RIGHT_BRACKET))\n        else:\n            assert_cant_happen()\n        # noinspection PyUnboundLocalVariable\n        yield path\n\n\ndef tokenize(source: str) -> Iterator[Token]:\n    cursor = 0\n    backslashes = 0\n    buffer = []\n\n    def send_buffer() -> Iterator[Token]:\n        nonlocal backslashes\n        if not buffer:\n            return None\n\n        value = ''.join(buffer)\n        kind = TokenKind.TEXT\n        if not backslashes:\n            for variation, kind in [\n                (int, TokenKind.NUMBER),\n                (check_escaped_int, TokenKind.TEXT),\n            ]:\n                try:\n                    value = variation(value)\n                except ValueError:\n                    continue\n                else:\n                    break\n        yield Token(\n            kind=kind,\n            value=value,\n            start=cursor - (len(buffer) + backslashes),\n            end=cursor,\n        )\n        buffer.clear()\n        backslashes = 0\n\n    def can_advance() -> bool:\n        return cursor < len(source)\n\n    while can_advance():\n        index = source[cursor]\n        if index in OPERATORS:\n            yield from send_buffer()\n            yield Token(OPERATORS[index], index, cursor, cursor + 1)\n        elif index == BACKSLASH and can_advance():\n            if source[cursor + 1] in SPECIAL_CHARS:\n                backslashes += 1\n            else:\n                buffer.append(index)\n            buffer.append(source[cursor + 1])\n            cursor += 1\n        else:\n            buffer.append(index)\n        cursor += 1\n\n    yield from send_buffer()\n\n\ndef check_escaped_int(value: str) -> str:\n    if not value.startswith(BACKSLASH):\n        raise ValueError('Not an escaped int')\n    try:\n        int(value[1:])\n    except ValueError as exc:\n        raise ValueError('Not an escaped int') from exc\n    else:\n        return value[1:]\n\n\ndef assert_cant_happen():\n    raise ValueError('Unexpected value')\n", "httpie/cli/nested_json/errors.py": "from typing import Optional\n\nfrom .tokens import Token, HIGHLIGHTER\n\n\nclass NestedJSONSyntaxError(ValueError):\n    def __init__(\n        self,\n        source: str,\n        token: Optional[Token],\n        message: str,\n        message_kind: str = 'Syntax',\n    ) -> None:\n        self.source = source\n        self.token = token\n        self.message = message\n        self.message_kind = message_kind\n\n    def __str__(self):\n        lines = [f'HTTPie {self.message_kind} Error: {self.message}']\n        if self.token is not None:\n            lines.append(self.source)\n            lines.append(\n                ' ' * self.token.start\n                + HIGHLIGHTER * (self.token.end - self.token.start)\n            )\n        return '\\n'.join(lines)\n", "httpie/cli/nested_json/__init__.py": "\"\"\"\nA library for parsing the HTTPie nested JSON key syntax and constructing the resulting objects.\n\n<https://httpie.io/docs/cli/nested-json>\n\nIt has no dependencies.\n\n\"\"\"\nfrom .interpret import interpret_nested_json, unwrap_top_level_list_if_needed\nfrom .errors import NestedJSONSyntaxError\nfrom .tokens import EMPTY_STRING, NestedJSONArray\n\n\n__all__ = [\n    'interpret_nested_json',\n    'unwrap_top_level_list_if_needed',\n    'EMPTY_STRING',\n    'NestedJSONArray',\n    'NestedJSONSyntaxError'\n]\n", "httpie/cli/nested_json/interpret.py": "from typing import Type, Union, Any, Iterable, Tuple\n\nfrom .parse import parse, assert_cant_happen\nfrom .errors import NestedJSONSyntaxError\nfrom .tokens import EMPTY_STRING, TokenKind, Token, PathAction, Path, NestedJSONArray\n\n\n__all__ = [\n    'interpret_nested_json',\n    'unwrap_top_level_list_if_needed',\n]\n\nJSONType = Type[Union[dict, list, int, float, str]]\nJSON_TYPE_MAPPING = {\n    dict: 'object',\n    list: 'array',\n    int: 'number',\n    float: 'number',\n    str: 'string',\n}\n\n\ndef interpret_nested_json(pairs: Iterable[Tuple[str, str]]) -> dict:\n    context = None\n    for key, value in pairs:\n        context = interpret(context, key, value)\n    return wrap_with_dict(context)\n\n\ndef interpret(context: Any, key: str, value: Any) -> Any:\n    cursor = context\n    paths = list(parse(key))\n    paths.append(Path(PathAction.SET, value))\n\n    # noinspection PyShadowingNames\n    def type_check(index: int, path: Path, expected_type: JSONType):\n        if not isinstance(cursor, expected_type):\n            if path.tokens:\n                pseudo_token = Token(\n                    kind=TokenKind.PSEUDO,\n                    value='',\n                    start=path.tokens[0].start,\n                    end=path.tokens[-1].end,\n                )\n            else:\n                pseudo_token = None\n            cursor_type = JSON_TYPE_MAPPING.get(type(cursor), type(cursor).__name__)\n            required_type = JSON_TYPE_MAPPING[expected_type]\n            message = f'Cannot perform {path.kind.to_string()!r} based access on '\n            message += repr(''.join(path.reconstruct() for path in paths[:index]))\n            message += f' which has a type of {cursor_type!r} but this operation'\n            message += f' requires a type of {required_type!r}.'\n            raise NestedJSONSyntaxError(\n                source=key,\n                token=pseudo_token,\n                message=message,\n                message_kind='Type',\n            )\n\n    def object_for(kind: PathAction) -> Any:\n        if kind is PathAction.KEY:\n            return {}\n        elif kind in {PathAction.INDEX, PathAction.APPEND}:\n            return []\n        else:\n            assert_cant_happen()\n\n    for index, (path, next_path) in enumerate(zip(paths, paths[1:])):\n        # If there is no context yet, set it.\n        if cursor is None:\n            context = cursor = object_for(path.kind)\n        if path.kind is PathAction.KEY:\n            type_check(index, path, dict)\n            if next_path.kind is PathAction.SET:\n                cursor[path.accessor] = next_path.accessor\n                break\n            cursor = cursor.setdefault(path.accessor, object_for(next_path.kind))\n        elif path.kind is PathAction.INDEX:\n            type_check(index, path, list)\n            if path.accessor < 0:\n                raise NestedJSONSyntaxError(\n                    source=key,\n                    token=path.tokens[1],\n                    message='Negative indexes are not supported.',\n                    message_kind='Value',\n                )\n            cursor.extend([None] * (path.accessor - len(cursor) + 1))\n            if next_path.kind is PathAction.SET:\n                cursor[path.accessor] = next_path.accessor\n                break\n            if cursor[path.accessor] is None:\n                cursor[path.accessor] = object_for(next_path.kind)\n            cursor = cursor[path.accessor]\n        elif path.kind is PathAction.APPEND:\n            type_check(index, path, list)\n            if next_path.kind is PathAction.SET:\n                cursor.append(next_path.accessor)\n                break\n            cursor.append(object_for(next_path.kind))\n            cursor = cursor[-1]\n        else:\n            assert_cant_happen()\n\n    return context\n\n\ndef wrap_with_dict(context):\n    if context is None:\n        return {}\n    elif isinstance(context, list):\n        return {\n            EMPTY_STRING: NestedJSONArray(context),\n        }\n    else:\n        assert isinstance(context, dict)\n        return context\n\n\ndef unwrap_top_level_list_if_needed(data: dict):\n    \"\"\"\n    Propagate the top-level list, if that\u2019s what we got.\n\n    \"\"\"\n    if len(data) == 1:\n        key, value = list(data.items())[0]\n        if isinstance(value, NestedJSONArray):\n            assert key == EMPTY_STRING\n            return value\n    return data\n", "httpie/output/processing.py": "import re\nfrom typing import Optional, List\n\nfrom ..plugins import ConverterPlugin\nfrom ..plugins.registry import plugin_manager\nfrom ..context import Environment\n\n\nMIME_RE = re.compile(r'^[^/]+/[^/]+$')\n\n\ndef is_valid_mime(mime):\n    return mime and MIME_RE.match(mime)\n\n\nclass Conversion:\n\n    @staticmethod\n    def get_converter(mime: str) -> Optional[ConverterPlugin]:\n        if is_valid_mime(mime):\n            for converter_class in plugin_manager.get_converters():\n                if converter_class.supports(mime):\n                    return converter_class(mime)\n\n\nclass Formatting:\n    \"\"\"A delegate class that invokes the actual processors.\"\"\"\n\n    def __init__(self, groups: List[str], env=Environment(), **kwargs):\n        \"\"\"\n        :param groups: names of processor groups to be applied\n        :param env: Environment\n        :param kwargs: additional keyword arguments for processors\n\n        \"\"\"\n        available_plugins = plugin_manager.get_formatters_grouped()\n        self.enabled_plugins = []\n        for group in groups:\n            for cls in available_plugins[group]:\n                p = cls(env=env, **kwargs)\n                if p.enabled:\n                    self.enabled_plugins.append(p)\n\n    def format_headers(self, headers: str) -> str:\n        for p in self.enabled_plugins:\n            headers = p.format_headers(headers)\n        return headers\n\n    def format_body(self, content: str, mime: str) -> str:\n        if is_valid_mime(mime):\n            for p in self.enabled_plugins:\n                content = p.format_body(content, mime)\n        return content\n\n    def format_metadata(self, metadata: str) -> str:\n        for p in self.enabled_plugins:\n            metadata = p.format_metadata(metadata)\n        return metadata\n", "httpie/output/utils.py": "import json\nimport re\nfrom typing import Tuple\n\nfrom ..utils import load_json_preserve_order_and_dupe_keys\nfrom .lexers.json import PREFIX_REGEX\n\n\ndef load_prefixed_json(data: str) -> Tuple[str, json.JSONDecoder]:\n    \"\"\"Simple JSON loading from `data`.\n\n    \"\"\"\n    # First, the full data.\n    try:\n        return '', load_json_preserve_order_and_dupe_keys(data)\n    except ValueError:\n        pass\n\n    # Then, try to find the start of the actual body.\n    data_prefix, body = parse_prefixed_json(data)\n    try:\n        return data_prefix, load_json_preserve_order_and_dupe_keys(body)\n    except ValueError:\n        raise ValueError('Invalid JSON')\n\n\ndef parse_prefixed_json(data: str) -> Tuple[str, str]:\n    \"\"\"Find the potential JSON body from `data`.\n\n    Sometimes the JSON body is prefixed with a XSSI magic string, specific to the server.\n    Return a tuple (data prefix, actual JSON body).\n\n    \"\"\"\n    matches = re.findall(PREFIX_REGEX, data)\n    data_prefix = matches[0] if matches else ''\n    body = data[len(data_prefix):]\n    return data_prefix, body\n", "httpie/output/writer.py": "import errno\nimport requests\nfrom typing import Any, Dict, IO, Optional, TextIO, Tuple, Type, Union\n\nfrom ..cli.dicts import HTTPHeadersDict\nfrom ..context import Environment\nfrom ..models import (\n    HTTPRequest,\n    HTTPResponse,\n    HTTPMessage,\n    RequestsMessage,\n    RequestsMessageKind,\n    OutputOptions,\n)\nfrom .models import ProcessingOptions\nfrom .processing import Conversion, Formatting\nfrom .streams import (\n    BaseStream, BufferedPrettyStream, EncodedStream, PrettyStream, RawStream,\n)\nfrom ..utils import parse_content_type_header\n\n\nMESSAGE_SEPARATOR = '\\n\\n'\nMESSAGE_SEPARATOR_BYTES = MESSAGE_SEPARATOR.encode()\n\n\ndef write_message(\n    requests_message: RequestsMessage,\n    env: Environment,\n    output_options: OutputOptions,\n    processing_options: ProcessingOptions,\n    extra_stream_kwargs: Optional[Dict[str, Any]] = None\n):\n    if not output_options.any():\n        return\n    write_stream_kwargs = {\n        'stream': build_output_stream_for_message(\n            env=env,\n            requests_message=requests_message,\n            output_options=output_options,\n            processing_options=processing_options,\n            extra_stream_kwargs=extra_stream_kwargs\n        ),\n        # NOTE: `env.stdout` will in fact be `stderr` with `--download`\n        'outfile': env.stdout,\n        'flush': env.stdout_isatty or processing_options.stream\n    }\n    try:\n        if env.is_windows and 'colors' in processing_options.get_prettify(env):\n            write_stream_with_colors_win(**write_stream_kwargs)\n        else:\n            write_stream(**write_stream_kwargs)\n    except OSError as e:\n        if processing_options.show_traceback and e.errno == errno.EPIPE:\n            # Ignore broken pipes unless --traceback.\n            env.stderr.write('\\n')\n        else:\n            raise\n\n\ndef write_stream(\n    stream: BaseStream,\n    outfile: Union[IO, TextIO],\n    flush: bool\n):\n    \"\"\"Write the output stream.\"\"\"\n    try:\n        # Writing bytes so we use the buffer interface.\n        buf = outfile.buffer\n    except AttributeError:\n        buf = outfile\n\n    for chunk in stream:\n        buf.write(chunk)\n        if flush:\n            outfile.flush()\n\n\ndef write_stream_with_colors_win(\n    stream: 'BaseStream',\n    outfile: TextIO,\n    flush: bool\n):\n    \"\"\"Like `write`, but colorized chunks are written as text\n    directly to `outfile` to ensure it gets processed by colorama.\n    Applies only to Windows and colorized terminal output.\n\n    \"\"\"\n    color = b'\\x1b['\n    encoding = outfile.encoding\n    for chunk in stream:\n        if color in chunk:\n            outfile.write(chunk.decode(encoding))\n        else:\n            outfile.buffer.write(chunk)\n        if flush:\n            outfile.flush()\n\n\ndef write_raw_data(\n    env: Environment,\n    data: Any,\n    *,\n    processing_options: Optional[ProcessingOptions] = None,\n    headers: Optional[HTTPHeadersDict] = None,\n    stream_kwargs: Optional[Dict[str, Any]] = None\n):\n    msg = requests.PreparedRequest()\n    msg.is_body_upload_chunk = True\n    msg.body = data\n    msg.headers = headers or HTTPHeadersDict()\n    msg_output_options = OutputOptions.from_message(msg, body=True, headers=False)\n    return write_message(\n        requests_message=msg,\n        env=env,\n        output_options=msg_output_options,\n        processing_options=processing_options or ProcessingOptions(),\n        extra_stream_kwargs=stream_kwargs\n    )\n\n\ndef build_output_stream_for_message(\n    env: Environment,\n    requests_message: RequestsMessage,\n    output_options: OutputOptions,\n    processing_options: ProcessingOptions,\n    extra_stream_kwargs: Optional[Dict[str, Any]] = None\n):\n    message_type = {\n        RequestsMessageKind.REQUEST: HTTPRequest,\n        RequestsMessageKind.RESPONSE: HTTPResponse,\n    }[output_options.kind]\n    stream_class, stream_kwargs = get_stream_type_and_kwargs(\n        env=env,\n        processing_options=processing_options,\n        message_type=message_type,\n        headers=requests_message.headers\n    )\n    if extra_stream_kwargs:\n        stream_kwargs.update(extra_stream_kwargs)\n    yield from stream_class(\n        msg=message_type(requests_message),\n        output_options=output_options,\n        **stream_kwargs,\n    )\n    if (env.stdout_isatty and output_options.body and not output_options.meta\n            and not getattr(requests_message, 'is_body_upload_chunk', False)):\n        # Ensure a blank line after the response body.\n        # For terminal output only.\n        yield MESSAGE_SEPARATOR_BYTES\n\n\ndef get_stream_type_and_kwargs(\n    env: Environment,\n    processing_options: ProcessingOptions,\n    message_type: Type[HTTPMessage],\n    headers: HTTPHeadersDict,\n) -> Tuple[Type['BaseStream'], dict]:\n    \"\"\"Pick the right stream type and kwargs for it based on `env` and `args`.\n\n    \"\"\"\n    is_stream = processing_options.stream\n    prettify_groups = processing_options.get_prettify(env)\n    if not is_stream and message_type is HTTPResponse:\n        # If this is a response, then check the headers for determining\n        # auto-streaming.\n        raw_content_type_header = headers.get('Content-Type', None)\n        if raw_content_type_header:\n            content_type_header, _ = parse_content_type_header(raw_content_type_header)\n            is_stream = (content_type_header == 'text/event-stream')\n\n    if not env.stdout_isatty and not prettify_groups:\n        stream_class = RawStream\n        stream_kwargs = {\n            'chunk_size': (\n                RawStream.CHUNK_SIZE_BY_LINE\n                if is_stream\n                else RawStream.CHUNK_SIZE\n            )\n        }\n    else:\n        stream_class = EncodedStream\n        stream_kwargs = {\n            'env': env,\n        }\n        if message_type is HTTPResponse:\n            stream_kwargs.update({\n                'mime_overwrite': processing_options.response_mime,\n                'encoding_overwrite': processing_options.response_charset,\n            })\n        if prettify_groups:\n            stream_class = PrettyStream if is_stream else BufferedPrettyStream\n            stream_kwargs.update({\n                'conversion': Conversion(),\n                'formatting': Formatting(\n                    env=env,\n                    groups=prettify_groups,\n                    color_scheme=processing_options.style,\n                    explicit_json=processing_options.json,\n                    format_options=processing_options.format_options,\n                )\n            })\n\n    return stream_class, stream_kwargs\n", "httpie/output/streams.py": "from abc import ABCMeta, abstractmethod\nfrom itertools import chain\nfrom typing import Callable, Iterable, Optional, Union\n\nfrom .processing import Conversion, Formatting\nfrom ..context import Environment\nfrom ..encoding import smart_decode, smart_encode, UTF8\nfrom ..models import HTTPMessage, OutputOptions\nfrom ..utils import parse_content_type_header\n\n\nBINARY_SUPPRESSED_NOTICE = (\n    b'\\n'\n    b'+-----------------------------------------+\\n'\n    b'| NOTE: binary data not shown in terminal |\\n'\n    b'+-----------------------------------------+'\n)\n\n\nclass DataSuppressedError(Exception):\n    message = None\n\n\nclass BinarySuppressedError(DataSuppressedError):\n    \"\"\"An error indicating that the body is binary and won't be written,\n     e.g., for terminal output).\"\"\"\n    message = BINARY_SUPPRESSED_NOTICE\n\n\nclass BaseStream(metaclass=ABCMeta):\n    \"\"\"Base HTTP message output stream class.\"\"\"\n\n    def __init__(\n        self,\n        msg: HTTPMessage,\n        output_options: OutputOptions,\n        on_body_chunk_downloaded: Callable[[bytes], None] = None,\n        **kwargs\n    ):\n        \"\"\"\n        :param msg: a :class:`models.HTTPMessage` subclass\n        :param output_options: a :class:`OutputOptions` instance to represent\n                               which parts of the message is printed.\n        \"\"\"\n        assert output_options.any()\n        self.msg = msg\n        self.output_options = output_options\n        self.on_body_chunk_downloaded = on_body_chunk_downloaded\n        self.extra_options = kwargs\n\n    def get_headers(self) -> bytes:\n        \"\"\"Return the headers' bytes.\"\"\"\n        return self.msg.headers.encode()\n\n    def get_metadata(self) -> bytes:\n        \"\"\"Return the message metadata.\"\"\"\n        return self.msg.metadata.encode()\n\n    @abstractmethod\n    def iter_body(self) -> Iterable[bytes]:\n        \"\"\"Return an iterator over the message body.\"\"\"\n\n    def __iter__(self) -> Iterable[bytes]:\n        \"\"\"Return an iterator over `self.msg`.\"\"\"\n        if self.output_options.headers:\n            yield self.get_headers()\n            yield b'\\r\\n\\r\\n'\n\n        if self.output_options.body:\n            try:\n                for chunk in self.iter_body():\n                    yield chunk\n                    if self.on_body_chunk_downloaded:\n                        self.on_body_chunk_downloaded(chunk)\n            except DataSuppressedError as e:\n                if self.output_options.headers:\n                    yield b'\\n'\n                yield e.message\n\n        if self.output_options.meta:\n            if self.output_options.body:\n                yield b'\\n\\n'\n\n            yield self.get_metadata()\n            yield b'\\n\\n'\n\n\nclass RawStream(BaseStream):\n    \"\"\"The message is streamed in chunks with no processing.\"\"\"\n\n    CHUNK_SIZE = 1024 * 100\n    CHUNK_SIZE_BY_LINE = 1\n\n    def __init__(self, chunk_size=CHUNK_SIZE, **kwargs):\n        super().__init__(**kwargs)\n        self.chunk_size = chunk_size\n\n    def iter_body(self) -> Iterable[bytes]:\n        return self.msg.iter_body(self.chunk_size)\n\n\nENCODING_GUESS_THRESHOLD = 3\n\n\nclass EncodedStream(BaseStream):\n    \"\"\"Encoded HTTP message stream.\n\n    The message bytes are converted to an encoding suitable for\n    `self.env.stdout`. Unicode errors are replaced and binary data\n    is suppressed. The body is always streamed by line.\n\n    \"\"\"\n    CHUNK_SIZE = 1\n\n    def __init__(\n        self,\n        env=Environment(),\n        mime_overwrite: str = None,\n        encoding_overwrite: str = None,\n        **kwargs\n    ):\n        super().__init__(**kwargs)\n        if mime_overwrite:\n            self.mime = mime_overwrite\n        else:\n            self.mime, _ = parse_content_type_header(self.msg.content_type)\n        self._encoding = encoding_overwrite or self.msg.encoding\n        self._encoding_guesses = []\n        if env.stdout_isatty:\n            # Use the encoding supported by the terminal.\n            output_encoding = env.stdout_encoding\n        else:\n            # Preserve the message encoding.\n            output_encoding = self.msg.encoding\n        # Default to UTF-8 when unsure.\n        self.output_encoding = output_encoding or UTF8\n\n    def iter_body(self) -> Iterable[bytes]:\n        for line, lf in self.msg.iter_lines(self.CHUNK_SIZE):\n            if b'\\0' in line:\n                raise BinarySuppressedError()\n            line = self.decode_chunk(line)\n            yield smart_encode(line, self.output_encoding) + lf\n\n    def decode_chunk(self, raw_chunk: str) -> str:\n        chunk, guessed_encoding = smart_decode(raw_chunk, self.encoding)\n        self._encoding_guesses.append(guessed_encoding)\n        return chunk\n\n    @property\n    def encoding(self) -> Optional[str]:\n        if self._encoding:\n            return self._encoding\n\n        # If we find a reliable (used consecutively) encoding, than\n        # use it for the next iterations.\n        if len(self._encoding_guesses) < ENCODING_GUESS_THRESHOLD:\n            return None\n\n        guess_1, guess_2 = self._encoding_guesses[-2:]\n        if guess_1 == guess_2:\n            self._encoding = guess_1\n            return guess_1\n\n    @encoding.setter\n    def encoding(self, value) -> None:\n        self._encoding = value\n\n\nclass PrettyStream(EncodedStream):\n    \"\"\"In addition to :class:`EncodedStream` behaviour, this stream applies\n    content processing.\n\n    Useful for long-lived HTTP responses that stream by lines\n    such as the Twitter streaming API.\n\n    \"\"\"\n\n    CHUNK_SIZE = 1\n\n    def __init__(\n        self, conversion: Conversion,\n        formatting: Formatting,\n        **kwargs,\n    ):\n        super().__init__(**kwargs)\n        self.formatting = formatting\n        self.conversion = conversion\n\n    def get_headers(self) -> bytes:\n        return self.formatting.format_headers(\n            self.msg.headers).encode(self.output_encoding)\n\n    def get_metadata(self) -> bytes:\n        return self.formatting.format_metadata(\n            self.msg.metadata).encode(self.output_encoding)\n\n    def iter_body(self) -> Iterable[bytes]:\n        first_chunk = True\n        iter_lines = self.msg.iter_lines(self.CHUNK_SIZE)\n        for line, lf in iter_lines:\n            if b'\\0' in line:\n                if first_chunk:\n                    converter = self.conversion.get_converter(self.mime)\n                    if converter:\n                        body = bytearray()\n                        # noinspection PyAssignmentToLoopOrWithParameter\n                        for line, lf in chain([(line, lf)], iter_lines):\n                            body.extend(line)\n                            body.extend(lf)\n                        self.mime, body = converter.convert(body)\n                        assert isinstance(body, str)\n                        yield self.process_body(body)\n                        return\n                raise BinarySuppressedError()\n            yield self.process_body(line) + lf\n            first_chunk = False\n\n    def process_body(self, chunk: Union[str, bytes]) -> bytes:\n        if not isinstance(chunk, str):\n            # Text when a converter has been used,\n            # otherwise it will always be bytes.\n            chunk = self.decode_chunk(chunk)\n        chunk = self.formatting.format_body(content=chunk, mime=self.mime)\n        return smart_encode(chunk, self.output_encoding)\n\n\nclass BufferedPrettyStream(PrettyStream):\n    \"\"\"The same as :class:`PrettyStream` except that the body is fully\n    fetched before it's processed.\n\n    Suitable regular HTTP responses.\n\n    \"\"\"\n\n    CHUNK_SIZE = 1024 * 10\n\n    def iter_body(self) -> Iterable[bytes]:\n        # Read the whole body before prettifying it,\n        # but bail out immediately if the body is binary.\n        converter = None\n        body = bytearray()\n\n        for chunk in self.msg.iter_body(self.CHUNK_SIZE):\n            if not converter and b'\\0' in chunk:\n                converter = self.conversion.get_converter(self.mime)\n                if not converter:\n                    raise BinarySuppressedError()\n            body.extend(chunk)\n\n        if converter:\n            self.mime, body = converter.convert(body)\n\n        yield self.process_body(body)\n", "httpie/output/models.py": "import argparse\nfrom typing import Any, Dict, Union, List, NamedTuple, Optional\n\nfrom httpie.context import Environment\nfrom httpie.cli.constants import PrettyOptions, PRETTY_MAP, PRETTY_STDOUT_TTY_ONLY\nfrom httpie.cli.argtypes import PARSED_DEFAULT_FORMAT_OPTIONS\nfrom httpie.output.formatters.colors import AUTO_STYLE\n\n\nclass ProcessingOptions(NamedTuple):\n    \"\"\"Represents a set of stylistic options\n    that are used when deciding which stream\n    should be used.\"\"\"\n\n    debug: bool = False\n    traceback: bool = False\n\n    stream: bool = False\n    style: str = AUTO_STYLE\n    prettify: Union[List[str], PrettyOptions] = PRETTY_STDOUT_TTY_ONLY\n\n    response_mime: Optional[str] = None\n    response_charset: Optional[str] = None\n\n    json: bool = False\n    format_options: Dict[str, Any] = PARSED_DEFAULT_FORMAT_OPTIONS\n\n    def get_prettify(self, env: Environment) -> List[str]:\n        if self.prettify is PRETTY_STDOUT_TTY_ONLY:\n            return PRETTY_MAP['all' if env.stdout_isatty else 'none']\n        else:\n            return self.prettify\n\n    @classmethod\n    def from_raw_args(cls, options: argparse.Namespace) -> 'ProcessingOptions':\n        fetched_options = {\n            option: getattr(options, option)\n            for option in cls._fields\n        }\n        return cls(**fetched_options)\n\n    @property\n    def show_traceback(self):\n        return self.debug or self.traceback\n", "httpie/output/__init__.py": "", "httpie/output/lexers/common.py": "def precise(lexer, precise_token, parent_token):\n    # Due to a pygments bug*, custom tokens will look bad\n    # on outside styles. Until it is fixed on upstream, we'll\n    # convey whether the client is using pie style or not\n    # through precise option and return more precise tokens\n    # depending on it's value.\n    #\n    # [0]: https://github.com/pygments/pygments/issues/1986\n    if precise_token is None or not lexer.options.get(\"precise\"):\n        return parent_token\n    else:\n        return precise_token\n", "httpie/output/lexers/http.py": "import re\nimport pygments\nfrom httpie.output.lexers.common import precise\n\nRE_STATUS_LINE = re.compile(r'(\\d{3})( +)?(.+)?')\n\nSTATUS_TYPES = {\n    '1': pygments.token.Number.HTTP.INFO,\n    '2': pygments.token.Number.HTTP.OK,\n    '3': pygments.token.Number.HTTP.REDIRECT,\n    '4': pygments.token.Number.HTTP.CLIENT_ERR,\n    '5': pygments.token.Number.HTTP.SERVER_ERR,\n}\n\nRESPONSE_TYPES = {\n    'GET': pygments.token.Name.Function.HTTP.GET,\n    'HEAD': pygments.token.Name.Function.HTTP.HEAD,\n    'POST': pygments.token.Name.Function.HTTP.POST,\n    'PUT': pygments.token.Name.Function.HTTP.PUT,\n    'PATCH': pygments.token.Name.Function.HTTP.PATCH,\n    'DELETE': pygments.token.Name.Function.HTTP.DELETE,\n}\n\n\ndef http_response_type(lexer, match, ctx):\n    status_match = RE_STATUS_LINE.match(match.group())\n    if status_match is None:\n        return None\n\n    status_code, text, reason = status_match.groups()\n    status_type = precise(\n        lexer,\n        STATUS_TYPES.get(status_code[0]),\n        pygments.token.Number\n    )\n\n    groups = pygments.lexer.bygroups(\n        status_type,\n        pygments.token.Text,\n        status_type\n    )\n    yield from groups(lexer, status_match, ctx)\n\n\ndef request_method(lexer, match, ctx):\n    response_type = precise(\n        lexer,\n        RESPONSE_TYPES.get(match.group()),\n        pygments.token.Name.Function\n    )\n    yield match.start(), response_type, match.group()\n\n\nclass SimplifiedHTTPLexer(pygments.lexer.RegexLexer):\n    \"\"\"Simplified HTTP lexer for Pygments.\n\n    It only operates on headers and provides a stronger contrast between\n    their names and values than the original one bundled with Pygments\n    (:class:`pygments.lexers.text import HttpLexer`), especially when\n    Solarized color scheme is used.\n\n    \"\"\"\n    name = 'HTTP'\n    aliases = ['http']\n    filenames = ['*.http']\n    tokens = {\n        'root': [\n            # Request-Line\n            (r'([A-Z]+)( +)([^ ]+)( +)(HTTP)(/)(\\d+\\.\\d+)',\n             pygments.lexer.bygroups(\n                 request_method,\n                 pygments.token.Text,\n                 pygments.token.Name.Namespace,\n                 pygments.token.Text,\n                 pygments.token.Keyword.Reserved,\n                 pygments.token.Operator,\n                 pygments.token.Number\n             )),\n            # Response Status-Line\n            (r'(HTTP)(/)(\\d+\\.\\d+)( +)(.+)',\n             pygments.lexer.bygroups(\n                 pygments.token.Keyword.Reserved,  # 'HTTP'\n                 pygments.token.Operator,  # '/'\n                 pygments.token.Number,  # Version\n                 pygments.token.Text,\n                 http_response_type,  # Status code and Reason\n             )),\n            # Header\n            (r'(.*?)( *)(:)( *)(.+)', pygments.lexer.bygroups(\n                pygments.token.Name.Attribute,  # Name\n                pygments.token.Text,\n                pygments.token.Operator,  # Colon\n                pygments.token.Text,\n                pygments.token.String  # Value\n            ))\n        ]\n    }\n", "httpie/output/lexers/json.py": "import re\n\nfrom pygments.lexer import bygroups, using, RegexLexer\nfrom pygments.lexers.data import JsonLexer\nfrom pygments.token import Token\n\nPREFIX_TOKEN = Token.Error\nPREFIX_REGEX = r'[^{\\[\"]+'\n\n\nclass EnhancedJsonLexer(RegexLexer):\n    \"\"\"\n    Enhanced JSON lexer for Pygments.\n\n    It adds support for eventual data prefixing the actual JSON body.\n\n    \"\"\"\n    name = 'JSON'\n    flags = re.IGNORECASE | re.DOTALL\n    tokens = {\n        'root': [\n            # Eventual non-JSON data prefix followed by actual JSON body.\n            # FIX: data prefix + number (integer or float) is not correctly handled.\n            (\n                fr'({PREFIX_REGEX})' + r'((?:[{\\[\"]|true|false|null).+)',\n                bygroups(PREFIX_TOKEN, using(JsonLexer))\n            ),\n            # JSON body.\n            (r'.+', using(JsonLexer)),\n        ],\n    }\n", "httpie/output/lexers/__init__.py": "", "httpie/output/ui/rich_progress.py": "from dataclasses import dataclass\nfrom typing import TYPE_CHECKING, Optional\n\nfrom httpie.context import Environment\n\nif TYPE_CHECKING:\n    from rich.console import Console\n\n\n@dataclass\nclass BaseDisplay:\n    env: Environment\n\n    def start(\n        self, *, total: Optional[float], at: float, description: str\n    ) -> None:\n        ...\n\n    def update(self, steps: float) -> None:\n        ...\n\n    def stop(self, time_spent: float) -> None:\n        ...\n\n    @property\n    def console(self) -> 'Console':\n        \"\"\"Returns the default console to be used with displays (stderr).\"\"\"\n        return self.env.rich_error_console\n\n    def _print_summary(\n        self, is_finished: bool, observed_steps: int, time_spent: float\n    ):\n        from rich import filesize\n\n        if is_finished:\n            verb = 'Done'\n        else:\n            verb = 'Interrupted'\n\n        total_size = filesize.decimal(observed_steps)\n        avg_speed = filesize.decimal(observed_steps / time_spent)\n\n        minutes, seconds = divmod(time_spent, 60)\n        hours, minutes = divmod(int(minutes), 60)\n        if hours:\n            total_time = f'{hours:d}:{minutes:02d}:{seconds:0.5f}'\n        else:\n            total_time = f'{minutes:02d}:{seconds:0.5f}'\n\n        self.console.print(\n            f'[progress.description]{verb}. {total_size} in {total_time} ({avg_speed}/s)'\n        )\n\n\nclass DummyDisplay(BaseDisplay):\n    \"\"\"\n    A dummy display object to be used when the progress bars,\n    spinners etc. are disabled globally (or during tests).\n    \"\"\"\n\n\nclass StatusDisplay(BaseDisplay):\n    def start(\n        self, *, total: Optional[float], at: float, description: str\n    ) -> None:\n        self.observed = at\n        self.description = (\n            f'[progress.description]{description}[/progress.description]'\n        )\n\n        self.status = self.console.status(self.description, spinner='line')\n        self.status.start()\n\n    def update(self, steps: float) -> None:\n        from rich import filesize\n\n        self.observed += steps\n\n        observed_amount, observed_unit = filesize.decimal(\n            self.observed\n        ).split()\n        self.status.update(\n            status=f'{self.description} [progress.download]{observed_amount}/? {observed_unit}[/progress.download]'\n        )\n\n    def stop(self, time_spent: float) -> None:\n        self.status.stop()\n        self.console.print(self.description)\n        if time_spent:\n            self._print_summary(\n                is_finished=True,\n                observed_steps=self.observed,\n                time_spent=time_spent,\n            )\n\n\nclass ProgressDisplay(BaseDisplay):\n    def start(\n        self, *, total: Optional[float], at: float, description: str\n    ) -> None:\n        from rich.progress import (\n            Progress,\n            BarColumn,\n            DownloadColumn,\n            TimeRemainingColumn,\n            TransferSpeedColumn,\n        )\n\n        assert total is not None\n        self.console.print(f'[progress.description]{description}')\n        self.progress_bar = Progress(\n            '[',\n            BarColumn(),\n            ']',\n            '[progress.percentage]{task.percentage:>3.0f}%',\n            '(',\n            DownloadColumn(),\n            ')',\n            TimeRemainingColumn(),\n            TransferSpeedColumn(),\n            console=self.console,\n            transient=True,\n        )\n        self.progress_bar.start()\n        self.transfer_task = self.progress_bar.add_task(\n            description, completed=at, total=total\n        )\n\n    def update(self, steps: float) -> None:\n        self.progress_bar.advance(self.transfer_task, steps)\n\n    def stop(self, time_spent: Optional[float]) -> None:\n        self.progress_bar.stop()\n\n        if time_spent:\n            [task] = self.progress_bar.tasks\n            self._print_summary(\n                is_finished=task.finished,\n                observed_steps=task.completed,\n                time_spent=time_spent,\n            )\n", "httpie/output/ui/man_pages.py": "\"\"\"Logic for checking and displaying man pages.\"\"\"\n\nimport subprocess\nimport os\nfrom httpie.context import Environment\n\n\nMAN_COMMAND = 'man'\nNO_MAN_PAGES = os.getenv('HTTPIE_NO_MAN_PAGES', False)\n\n# On some systems, HTTP(n) might exist, but we are only interested in HTTP(1).\n# For more information on man page sections: <https://unix.stackexchange.com/a/138643>\nMAN_PAGE_SECTION = '1'\n\n\ndef is_available(program: str) -> bool:\n    \"\"\"\n    Check whether `program`'s man pages are available on this system.\n\n    \"\"\"\n    if NO_MAN_PAGES or os.system == 'nt':\n        return False\n    try:\n        process = subprocess.run(\n            [MAN_COMMAND, MAN_PAGE_SECTION, program],\n            shell=False,\n            stdout=subprocess.DEVNULL,\n            stderr=subprocess.DEVNULL\n        )\n    except Exception:\n        # There might be some errors outside the process, e.g\n        # a permission error to execute something that is not an\n        # executable.\n        return False\n    else:\n        return process.returncode == 0\n\n\ndef display_for(env: Environment, program: str) -> None:\n    \"\"\"\n    Open the system man page for the given command (http/https/httpie).\n\n    \"\"\"\n    subprocess.run(\n        [MAN_COMMAND, MAN_PAGE_SECTION, program],\n        stdout=env.stdout,\n        stderr=env.stderr\n    )\n", "httpie/output/ui/rich_utils.py": "import os\n\nfrom typing import Iterator\nfrom contextlib import contextmanager\n\nfrom rich.console import Console, RenderableType\nfrom rich.highlighter import Highlighter\n\nfrom httpie.output.ui.rich_palette import _make_rich_color_theme\n\n\ndef render_as_string(renderable: RenderableType) -> str:\n    \"\"\"Render any `rich` object in a fake console and\n    return a *style-less* version of it as a string.\"\"\"\n\n    with open(os.devnull, 'w') as null_stream:\n        fake_console = Console(file=null_stream, record=True, theme=_make_rich_color_theme())\n        fake_console.print(renderable)\n        return fake_console.export_text()\n\n\n@contextmanager\ndef enable_highlighter(\n    console: Console,\n    highlighter: Highlighter,\n) -> Iterator[Console]:\n    \"\"\"Enable a highlighter temporarily.\"\"\"\n\n    original_highlighter = console.highlighter\n    try:\n        console.highlighter = highlighter\n        yield console\n    finally:\n        console.highlighter = original_highlighter\n", "httpie/output/ui/__init__.py": "", "httpie/output/ui/rich_palette.py": "from collections import ChainMap\nfrom typing import TYPE_CHECKING, Any, Optional\n\nif TYPE_CHECKING:\n    from rich.theme import Theme\n\nfrom httpie.output.ui.palette import GenericColor, PieStyle, Styles, ColorString, _StyledGenericColor  # noqa\n\nRICH_BOLD = ColorString('bold')\n\n# Rich-specific color code declarations\n# <https://github.com/Textualize/rich/blob/fcd684dd3a482977cab620e71ccaebb94bf13ac9/rich/default_styles.py>\nCUSTOM_STYLES = {\n    'progress.description': RICH_BOLD | GenericColor.WHITE,\n    'progress.data.speed': RICH_BOLD | GenericColor.GREEN,\n    'progress.percentage': RICH_BOLD | GenericColor.AQUA,\n    'progress.download': RICH_BOLD | GenericColor.AQUA,\n    'progress.remaining': RICH_BOLD | GenericColor.ORANGE,\n    'bar.complete': RICH_BOLD | GenericColor.PURPLE,\n    'bar.finished': RICH_BOLD | GenericColor.GREEN,\n    'bar.pulse': RICH_BOLD | GenericColor.PURPLE,\n    'option': RICH_BOLD | GenericColor.PINK,\n}\n\n\nclass _GenericColorCaster(dict):\n    \"\"\"\n    Translate GenericColor to a regular string on the attribute access\n    phase.\n    \"\"\"\n\n    def _translate(self, key: Any) -> Any:\n        if isinstance(key, GenericColor):\n            return key.name.lower()\n        else:\n            return key\n\n    def __getitem__(self, key: Any) -> Any:\n        return super().__getitem__(self._translate(key))\n\n    def get(self, key: Any) -> Any:\n        return super().get(self._translate(key))\n\n\ndef _make_rich_color_theme(style_name: Optional[str] = None) -> 'Theme':\n    from rich.style import Style\n    from rich.theme import Theme\n\n    try:\n        PieStyle(style_name)\n    except ValueError:\n        style = Styles.ANSI\n    else:\n        style = Styles.PIE\n\n    theme = Theme()\n    for color, color_set in ChainMap(\n        GenericColor.__members__, CUSTOM_STYLES\n    ).items():\n        if isinstance(color_set, _StyledGenericColor):\n            properties = dict.fromkeys(color_set.styles, True)\n            color_set = color_set.color\n        else:\n            properties = {}\n\n        theme.styles[color.lower()] = Style(\n            color=color_set.apply_style(style, style_name=style_name),\n            **properties,\n        )\n\n    # E.g translate GenericColor.BLUE into blue on key access\n    theme.styles = _GenericColorCaster(theme.styles)\n    return theme\n", "httpie/output/ui/palette.py": "from dataclasses import dataclass, field\nfrom enum import Enum, auto\nfrom typing import Optional, List\n\n\nPYGMENTS_BRIGHT_BLACK = 'ansibrightblack'\n\nAUTO_STYLE = 'auto'  # Follows terminal ANSI color styles\n\n\nclass Styles(Enum):\n    PIE = auto()\n    ANSI = auto()\n\n\nclass PieStyle(str, Enum):\n    UNIVERSAL = 'pie'\n    DARK = 'pie-dark'\n    LIGHT = 'pie-light'\n\n\nPIE_STYLE_TO_SHADE = {\n    PieStyle.DARK: '500',\n    PieStyle.UNIVERSAL: '600',\n    PieStyle.LIGHT: '700',\n}\nSHADE_TO_PIE_STYLE = {\n    shade: style for style, shade in PIE_STYLE_TO_SHADE.items()\n}\n\n\nclass ColorString(str):\n    def __or__(self, other: str) -> 'ColorString':\n        \"\"\"Combine a style with a property.\n\n        E.g: PieColor.BLUE | BOLD | ITALIC\n        \"\"\"\n        if isinstance(other, str):\n            # In case of PieColor.BLUE | SOMETHING\n            # we just create a new string.\n            return ColorString(self + ' ' + other)\n        elif isinstance(other, GenericColor):\n            # If we see a GenericColor, then we'll wrap it\n            # in with the desired property in a different class.\n            return _StyledGenericColor(other, styles=self.split())\n        elif isinstance(other, _StyledGenericColor):\n            # And if it is already wrapped, we'll just extend the\n            # list of properties.\n            other.styles.extend(self.split())\n            return other\n        else:\n            return NotImplemented\n\n\nclass PieColor(ColorString, Enum):\n    \"\"\"Styles that are available only in Pie themes.\"\"\"\n\n    PRIMARY = 'primary'\n    SECONDARY = 'secondary'\n\n    WHITE = 'white'\n    BLACK = 'black'\n    GREY = 'grey'\n    AQUA = 'aqua'\n    PURPLE = 'purple'\n    ORANGE = 'orange'\n    RED = 'red'\n    BLUE = 'blue'\n    PINK = 'pink'\n    GREEN = 'green'\n    YELLOW = 'yellow'\n\n\nclass GenericColor(Enum):\n    \"\"\"Generic colors that are safe to use everywhere.\"\"\"\n\n    # <https://rich.readthedocs.io/en/stable/appendix/colors.html>\n\n    WHITE = {Styles.PIE: PieColor.WHITE, Styles.ANSI: 'white'}\n    BLACK = {Styles.PIE: PieColor.BLACK, Styles.ANSI: 'black'}\n    GREEN = {Styles.PIE: PieColor.GREEN, Styles.ANSI: 'green'}\n    ORANGE = {Styles.PIE: PieColor.ORANGE, Styles.ANSI: 'yellow'}\n    YELLOW = {Styles.PIE: PieColor.YELLOW, Styles.ANSI: 'bright_yellow'}\n    BLUE = {Styles.PIE: PieColor.BLUE, Styles.ANSI: 'blue'}\n    PINK = {Styles.PIE: PieColor.PINK, Styles.ANSI: 'bright_magenta'}\n    PURPLE = {Styles.PIE: PieColor.PURPLE, Styles.ANSI: 'magenta'}\n    RED = {Styles.PIE: PieColor.RED, Styles.ANSI: 'red'}\n    AQUA = {Styles.PIE: PieColor.AQUA, Styles.ANSI: 'cyan'}\n    GREY = {Styles.PIE: PieColor.GREY, Styles.ANSI: 'bright_black'}\n\n    def apply_style(\n        self, style: Styles, *, style_name: Optional[str] = None\n    ) -> str:\n        \"\"\"Apply the given style to a particular value.\"\"\"\n        exposed_color = self.value[style]\n        if style is Styles.PIE:\n            assert style_name is not None\n            shade = PIE_STYLE_TO_SHADE[PieStyle(style_name)]\n            return get_color(exposed_color, shade)\n        else:\n            return exposed_color\n\n\n@dataclass\nclass _StyledGenericColor:\n    color: 'GenericColor'\n    styles: List[str] = field(default_factory=list)\n\n\n# noinspection PyDictCreation\nCOLOR_PALETTE = {\n    # Copy the brand palette\n    PieColor.WHITE: '#F5F5F0',\n    PieColor.BLACK: '#1C1818',\n    PieColor.GREY: {\n        '50': '#F5F5F0',\n        '100': '#EDEDEB',\n        '200': '#D1D1CF',\n        '300': '#B5B5B2',\n        '400': '#999999',\n        '500': '#7D7D7D',\n        '600': '#666663',\n        '700': '#4F4D4D',\n        '800': '#363636',\n        '900': '#1C1818',\n        'DEFAULT': '#7D7D7D',\n    },\n    PieColor.AQUA: {\n        '50': '#E8F0F5',\n        '100': '#D6E3ED',\n        '200': '#C4D9E5',\n        '300': '#B0CCDE',\n        '400': '#9EBFD6',\n        '500': '#8CB4CD',\n        '600': '#7A9EB5',\n        '700': '#698799',\n        '800': '#597082',\n        '900': '#455966',\n        'DEFAULT': '#8CB4CD',\n    },\n    PieColor.PURPLE: {\n        '50': '#F0E0FC',\n        '100': '#E3C7FA',\n        '200': '#D9ADF7',\n        '300': '#CC96F5',\n        '400': '#BF7DF2',\n        '500': '#B464F0',\n        '600': '#9E54D6',\n        '700': '#8745BA',\n        '800': '#70389E',\n        '900': '#5C2982',\n        'DEFAULT': '#B464F0',\n    },\n    PieColor.ORANGE: {\n        '50': '#FFEDDB',\n        '100': '#FFDEBF',\n        '200': '#FFCFA3',\n        '300': '#FFBF87',\n        '400': '#FFB06B',\n        '500': '#FFA24E',\n        '600': '#F2913D',\n        '700': '#E3822B',\n        '800': '#D6701C',\n        '900': '#C75E0A',\n        'DEFAULT': '#FFA24E',\n    },\n    PieColor.RED: {\n        '50': '#FFE0DE',\n        '100': '#FFC7C4',\n        '200': '#FFB0AB',\n        '300': '#FF968F',\n        '400': '#FF8075',\n        '500': '#FF665B',\n        '600': '#E34F45',\n        '700': '#C7382E',\n        '800': '#AD2117',\n        '900': '#910A00',\n        'DEFAULT': '#FF665B',\n    },\n    PieColor.BLUE: {\n        '50': '#DBE3FA',\n        '100': '#BFCFF5',\n        '200': '#A1B8F2',\n        '300': '#85A3ED',\n        '400': '#698FEB',\n        '500': '#4B78E6',\n        '600': '#426BD1',\n        '700': '#3B5EBA',\n        '800': '#3354A6',\n        '900': '#2B478F',\n        'DEFAULT': '#4B78E6',\n    },\n    PieColor.PINK: {\n        '50': '#FFEBFF',\n        '100': '#FCDBFC',\n        '200': '#FCCCFC',\n        '300': '#FCBAFC',\n        '400': '#FAABFA',\n        '500': '#FA9BFA',\n        '600': '#DE85DE',\n        '700': '#C26EC2',\n        '800': '#A854A6',\n        '900': '#8C3D8A',\n        'DEFAULT': '#FA9BFA',\n    },\n    PieColor.GREEN: {\n        '50': '#E3F7E8',\n        '100': '#CCF2D6',\n        '200': '#B5EDC4',\n        '300': '#A1E8B0',\n        '400': '#8AE09E',\n        '500': '#73DC8C',\n        '600': '#63C27A',\n        '700': '#52AB66',\n        '800': '#429154',\n        '900': '#307842',\n        'DEFAULT': '#73DC8C',\n    },\n    PieColor.YELLOW: {\n        '50': '#F7F7DB',\n        '100': '#F2F2BF',\n        '200': '#EDEDA6',\n        '300': '#E5E88A',\n        '400': '#E0E36E',\n        '500': '#DBDE52',\n        '600': '#CCCC3D',\n        '700': '#BABA29',\n        '800': '#ABA614',\n        '900': '#999400',\n        'DEFAULT': '#DBDE52',\n    },\n}\nCOLOR_PALETTE.update(\n    {\n        # Terminal-specific palette customizations.\n        PieColor.GREY: {\n            # Grey is the same no matter shade for the colors\n            shade: COLOR_PALETTE[PieColor.GREY]['500']\n            for shade in COLOR_PALETTE[PieColor.GREY].keys()\n        },\n        PieColor.PRIMARY: {\n            '700': COLOR_PALETTE[PieColor.BLACK],\n            '600': PYGMENTS_BRIGHT_BLACK,\n            '500': COLOR_PALETTE[PieColor.WHITE],\n        },\n        PieColor.SECONDARY: {\n            '700': '#37523C',\n            '600': '#6c6969',\n            '500': '#6c6969',\n        },\n    }\n)\n\n\ndef boldify(color: PieColor) -> str:\n    return f'bold {color}'\n\n\n# noinspection PyDefaultArgument\ndef get_color(\n    color: PieColor, shade: str, *, palette=COLOR_PALETTE\n) -> Optional[str]:\n    if color not in palette:\n        return None\n    color_code = palette[color]\n    if isinstance(color_code, dict) and shade in color_code:\n        return color_code[shade]\n    else:\n        return color_code\n", "httpie/output/ui/rich_help.py": "import re\nimport textwrap\nfrom typing import AbstractSet, Iterable, Optional, Tuple\n\nfrom rich.console import RenderableType\nfrom rich.highlighter import RegexHighlighter\nfrom rich.padding import Padding\nfrom rich.table import Table\nfrom rich.text import Text\n\nfrom httpie.cli.constants import SEPARATOR_GROUP_ALL_ITEMS\nfrom httpie.cli.options import Argument, ParserSpec, Qualifiers\nfrom httpie.output.ui.palette import GenericColor\n\nSEPARATORS = '|'.join(map(re.escape, SEPARATOR_GROUP_ALL_ITEMS))\n\nSTYLE_METAVAR = GenericColor.YELLOW\nSTYLE_SWITCH = GenericColor.GREEN\nSTYLE_PROGRAM_NAME = GenericColor.GREEN  # .boldify()\nSTYLE_USAGE_OPTIONAL = GenericColor.GREY\nSTYLE_USAGE_REGULAR = GenericColor.WHITE\nSTYLE_USAGE_ERROR = GenericColor.RED\nSTYLE_USAGE_MISSING = GenericColor.YELLOW\nSTYLE_BOLD = 'bold'\n\nMAX_CHOICE_CHARS = 80\n\nLEFT_PADDING_2 = (0, 0, 0, 2)\nLEFT_PADDING_3 = (0, 0, 0, 3)\nLEFT_PADDING_4 = (0, 0, 0, 4)\nLEFT_PADDING_5 = (0, 0, 0, 4)\n\nLEFT_INDENT_2 = (1, 0, 0, 2)\nLEFT_INDENT_3 = (1, 0, 0, 3)\nLEFT_INDENT_BOTTOM_3 = (0, 0, 1, 3)\n\nMORE_INFO_COMMANDS = \"\"\"\nTo learn more, you can try:\n    -> running 'http --manual'\n    -> visiting our full documentation at https://httpie.io/docs/cli\n\"\"\"\n\n\nclass OptionsHighlighter(RegexHighlighter):\n    highlights = [\n        r'(^|\\W)(?P<option>\\-{1,2}[\\w|-]+)(?![a-zA-Z0-9])',\n        r'(?P<bold>HTTPie)',\n    ]\n\n\noptions_highlighter = OptionsHighlighter()\n\n\ndef unpack_argument(\n    argument: Argument,\n) -> Tuple[Text, Text]:\n    opt1 = opt2 = ''\n\n    style = None\n    if argument.aliases:\n        if len(argument.aliases) >= 2:\n            opt2, opt1 = argument.aliases\n        else:\n            (opt1,) = argument.aliases\n    else:\n        opt1 = argument.metavar\n        style = STYLE_USAGE_REGULAR\n\n    return Text(opt1, style=style), Text(opt2)\n\n\ndef to_usage(\n    spec: ParserSpec,\n    *,\n    program_name: Optional[str] = None,\n    whitelist: AbstractSet[str] = frozenset()\n) -> RenderableType:\n    shown_arguments = [\n        argument\n        for group in spec.groups\n        for argument in group.arguments\n        if (not argument.aliases or whitelist.intersection(argument.aliases))\n    ]\n\n    # Sort the shown_arguments so that --dash options are\n    # shown first\n    shown_arguments.sort(key=lambda argument: argument.aliases, reverse=True)\n\n    text = Text(program_name or spec.program, style=STYLE_BOLD)\n    for argument in shown_arguments:\n        text.append(' ')\n\n        is_whitelisted = whitelist.intersection(argument.aliases)\n        if argument.aliases:\n            name = '/'.join(sorted(argument.aliases, key=len))\n        else:\n            name = argument.metavar\n\n        nargs = argument.configuration.get('nargs')\n        if nargs is Qualifiers.OPTIONAL:\n            text.append('[' + name + ']', style=STYLE_USAGE_OPTIONAL)\n        elif nargs is Qualifiers.ZERO_OR_MORE:\n            text.append(\n                '[' + name + ' ...]',\n                style=STYLE_USAGE_OPTIONAL,\n            )\n        else:\n            text.append(\n                name,\n                style=STYLE_USAGE_ERROR\n                if is_whitelisted\n                else STYLE_USAGE_REGULAR,\n            )\n\n        raw_form = argument.serialize()\n        if raw_form.get('choices'):\n            text.append(' ')\n            text.append(\n                '{' + ', '.join(raw_form['choices']) + '}',\n                style=STYLE_USAGE_MISSING,\n            )\n\n    return text\n\n\n# This part is loosely based on the rich-click's help message\n# generation.\ndef to_help_message(\n    spec: ParserSpec,\n) -> Iterable[RenderableType]:\n    yield Padding(\n        options_highlighter(spec.description),\n        LEFT_INDENT_2,\n    )\n\n    yield Padding(\n        Text('Usage', style=STYLE_SWITCH),\n        LEFT_INDENT_2,\n    )\n    yield Padding(to_usage(spec), LEFT_INDENT_3)\n\n    group_rows = {}\n    for group in spec.groups:\n        options_rows = []\n\n        for argument in group.arguments:\n            if argument.is_hidden:\n                continue\n\n            opt1, opt2 = unpack_argument(argument)\n            if opt2:\n                opt1.append('/')\n                opt1.append(opt2)\n\n            # Column for a metavar, if we have one\n            metavar = Text(style=STYLE_METAVAR)\n            metavar.append(argument.configuration.get('metavar', ''))\n\n            if opt1 == metavar:\n                metavar = Text('')\n\n            raw_form = argument.serialize()\n            desc = raw_form.get('short_description', '')\n            if raw_form.get('choices'):\n                desc += ' (choices: '\n                desc += textwrap.shorten(\n                    ', '.join(raw_form.get('choices')),\n                    MAX_CHOICE_CHARS,\n                )\n                desc += ')'\n\n            rows = [\n                Padding(\n                    options_highlighter(opt1),\n                    LEFT_PADDING_2,\n                ),\n                metavar,\n                options_highlighter(desc),\n            ]\n\n            options_rows.append(rows)\n            if argument.configuration.get('nested_options'):\n                options_rows.extend(\n                    [\n                        (\n                            Padding(\n                                Text(\n                                    key,\n                                    style=STYLE_USAGE_OPTIONAL,\n                                ),\n                                LEFT_PADDING_4,\n                            ),\n                            value,\n                            dec,\n                        )\n                        for key, value, dec in argument.nested_options\n                    ]\n                )\n\n        group_rows[group.name] = options_rows\n\n    options_table = Table(highlight=False, box=None, show_header=False)\n    for group_name, options_rows in group_rows.items():\n        options_table.add_row(Text(), Text(), Text())\n        options_table.add_row(\n            Text(group_name, style=STYLE_SWITCH),\n            Text(),\n            Text(),\n        )\n        options_table.add_row(Text(), Text(), Text())\n        for row in options_rows:\n            options_table.add_row(*row)\n\n    yield Padding(\n        Text('Options', style=STYLE_SWITCH),\n        LEFT_INDENT_2,\n    )\n    yield Padding(options_table, LEFT_PADDING_2)\n    yield Padding(\n        Text('More Information', style=STYLE_SWITCH),\n        LEFT_INDENT_2,\n    )\n    yield Padding(\n        MORE_INFO_COMMANDS.rstrip('\\n'),\n        LEFT_PADDING_3\n    )\n    yield Padding(\n        spec.epilog.rstrip('\\n'),\n        LEFT_INDENT_BOTTOM_3,\n    )\n", "httpie/output/formatters/xml.py": "from typing import TYPE_CHECKING, Optional\n\nfrom ...encoding import UTF8\nfrom ...plugins import FormatterPlugin\n\nif TYPE_CHECKING:\n    from xml.dom.minidom import Document\n\n\nXML_DECLARATION_OPEN = '<?xml'\nXML_DECLARATION_CLOSE = '?>'\n\n\ndef parse_xml(data: str) -> 'Document':\n    \"\"\"Parse given XML `data` string into an appropriate :class:`~xml.dom.minidom.Document` object.\"\"\"\n    from defusedxml.minidom import parseString\n    return parseString(data)\n\n\ndef parse_declaration(raw_body: str) -> Optional[str]:\n    body = raw_body.strip()\n    # XMLDecl ::= '<?xml' DECL_CONTENT '?>'\n    if body.startswith(XML_DECLARATION_OPEN):\n        end = body.find(XML_DECLARATION_CLOSE)\n        if end != -1:\n            return body[:end + len(XML_DECLARATION_CLOSE)]\n\n\ndef pretty_xml(document: 'Document',\n               declaration: Optional[str] = None,\n               encoding: Optional[str] = UTF8,\n               indent: int = 2) -> str:\n    \"\"\"Render the given :class:`~xml.dom.minidom.Document` `document` into a prettified string.\"\"\"\n    kwargs = {\n        'encoding': encoding or UTF8,\n        'indent': ' ' * indent,\n    }\n    body = document.toprettyxml(**kwargs).decode(kwargs['encoding'])\n\n    # Remove blank lines automatically added by `toprettyxml()`.\n    lines = [line for line in body.splitlines() if line.strip()]\n\n    # xml.dom automatically adds the declaration, even if\n    # it is not present in the actual body. Remove it.\n    if len(lines) >= 1 and parse_declaration(lines[0]):\n        lines.pop(0)\n        if declaration:\n            lines.insert(0, declaration)\n\n    return '\\n'.join(lines)\n\n\nclass XMLFormatter(FormatterPlugin):\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.enabled = self.format_options['xml']['format']\n\n    def format_body(self, body: str, mime: str):\n        if 'xml' not in mime:\n            return body\n\n        from xml.parsers.expat import ExpatError\n        from defusedxml.common import DefusedXmlException\n\n        declaration = parse_declaration(body)\n        try:\n            parsed_body = parse_xml(body)\n        except ExpatError:\n            pass  # Invalid XML, ignore.\n        except DefusedXmlException:\n            pass  # Unsafe XML, ignore.\n        else:\n            body = pretty_xml(parsed_body,\n                              encoding=parsed_body.encoding,\n                              indent=self.format_options['xml']['indent'],\n                              declaration=declaration)\n\n        return body\n", "httpie/output/formatters/json.py": "import json\n\nfrom ...plugins import FormatterPlugin\n\n\nclass JSONFormatter(FormatterPlugin):\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.enabled = self.format_options['json']['format']\n\n    def format_body(self, body: str, mime: str) -> str:\n        maybe_json = [\n            'json',\n            'javascript',\n            'text',\n        ]\n        if (self.kwargs['explicit_json']\n                or any(token in mime for token in maybe_json)):\n            from ..utils import load_prefixed_json\n            try:\n                data_prefix, json_obj = load_prefixed_json(body)\n            except ValueError:\n                pass  # Invalid JSON, ignore.\n            else:\n                # Indent, sort keys by name, and avoid\n                # unicode escapes to improve readability.\n                body = data_prefix + json.dumps(\n                    obj=json_obj,\n                    sort_keys=self.format_options['json']['sort_keys'],\n                    ensure_ascii=False,\n                    indent=self.format_options['json']['indent']\n                )\n        return body\n", "httpie/output/formatters/headers.py": "from ...plugins import FormatterPlugin\n\n\nclass HeadersFormatter(FormatterPlugin):\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.enabled = self.format_options['headers']['sort']\n\n    def format_headers(self, headers: str) -> str:\n        \"\"\"\n        Sorts headers by name while retaining relative\n        order of multiple headers with the same name.\n\n        \"\"\"\n        lines = headers.splitlines()\n        headers = sorted(lines[1:], key=lambda h: h.split(':')[0])\n        return '\\r\\n'.join(lines[:1] + headers)\n", "httpie/output/formatters/__init__.py": "", "httpie/output/formatters/colors.py": "import json\nfrom typing import Optional, Type, Tuple\n\nimport pygments.formatters\nimport pygments.lexer\nimport pygments.lexers\nimport pygments.style\nimport pygments.styles\nimport pygments.token\nfrom pygments.formatters.terminal import TerminalFormatter\nfrom pygments.formatters.terminal256 import Terminal256Formatter\nfrom pygments.lexer import Lexer\nfrom pygments.lexers.data import JsonLexer\nfrom pygments.lexers.special import TextLexer\nfrom pygments.lexers.text import HttpLexer as PygmentsHttpLexer\nfrom pygments.util import ClassNotFound\n\nfrom ..lexers.json import EnhancedJsonLexer\nfrom ..lexers.metadata import MetadataLexer\nfrom ..ui.palette import AUTO_STYLE, SHADE_TO_PIE_STYLE, PieColor, ColorString, get_color\nfrom ...context import Environment\nfrom ...plugins import FormatterPlugin\n\n\nDEFAULT_STYLE = AUTO_STYLE\nSOLARIZED_STYLE = 'solarized'  # Bundled here\nPYGMENTS_BOLD = ColorString('bold')\nPYGMENTS_ITALIC = ColorString('italic')\n\nBUNDLED_STYLES = {\n    SOLARIZED_STYLE,\n    AUTO_STYLE\n}\n\n\ndef get_available_styles():\n    return sorted(BUNDLED_STYLES | set(pygments.styles.get_all_styles()))\n\n\nclass ColorFormatter(FormatterPlugin):\n    \"\"\"\n    Colorize using Pygments\n\n    This processor that applies syntax highlighting to the headers,\n    and also to the body if its content type is recognized.\n\n    \"\"\"\n    group_name = 'colors'\n    metadata_lexer = MetadataLexer()\n\n    def __init__(\n        self,\n        env: Environment,\n        explicit_json=False,\n        color_scheme=DEFAULT_STYLE,\n        **kwargs\n    ):\n        super().__init__(**kwargs)\n\n        if not env.colors:\n            self.enabled = False\n            return\n\n        use_auto_style = color_scheme == AUTO_STYLE\n        has_256_colors = env.colors == 256\n        if use_auto_style or not has_256_colors:\n            http_lexer = PygmentsHttpLexer()\n            body_formatter = header_formatter = TerminalFormatter()\n            precise = False\n        else:\n            from ..lexers.http import SimplifiedHTTPLexer\n            header_formatter, body_formatter, precise = self.get_formatters(color_scheme)\n            http_lexer = SimplifiedHTTPLexer(precise=precise)\n\n        self.explicit_json = explicit_json  # --json\n        self.header_formatter = header_formatter\n        self.body_formatter = body_formatter\n        self.http_lexer = http_lexer\n        self.metadata_lexer = MetadataLexer(precise=precise)\n\n    def format_headers(self, headers: str) -> str:\n        return pygments.highlight(\n            code=headers,\n            lexer=self.http_lexer,\n            formatter=self.header_formatter,\n        ).strip()\n\n    def format_body(self, body: str, mime: str) -> str:\n        lexer = self.get_lexer_for_body(mime, body)\n        if lexer:\n            body = pygments.highlight(\n                code=body,\n                lexer=lexer,\n                formatter=self.body_formatter,\n            )\n        return body\n\n    def format_metadata(self, metadata: str) -> str:\n        return pygments.highlight(\n            code=metadata,\n            lexer=self.metadata_lexer,\n            formatter=self.header_formatter,\n        ).strip()\n\n    def get_lexer_for_body(\n        self, mime: str,\n        body: str\n    ) -> Optional[Type[Lexer]]:\n        return get_lexer(\n            mime=mime,\n            explicit_json=self.explicit_json,\n            body=body,\n        )\n\n    def get_formatters(self, color_scheme: str) -> Tuple[\n        pygments.formatter.Formatter,\n        pygments.formatter.Formatter,\n        bool\n    ]:\n        if color_scheme in PIE_STYLES:\n            header_style, body_style = PIE_STYLES[color_scheme]\n            precise = True\n        else:\n            header_style = self.get_style_class(color_scheme)\n            body_style = header_style\n            precise = False\n\n        return (\n            Terminal256Formatter(style=header_style),\n            Terminal256Formatter(style=body_style),\n            precise\n        )\n\n    @staticmethod\n    def get_style_class(color_scheme: str) -> Type[pygments.style.Style]:\n        try:\n            return pygments.styles.get_style_by_name(color_scheme)\n        except ClassNotFound:\n            return Solarized256Style\n\n\ndef get_lexer(\n    mime: str,\n    explicit_json=False,\n    body=''\n) -> Optional[Type[Lexer]]:\n    # Build candidate mime type and lexer names.\n    mime_types, lexer_names = [mime], []\n    type_, subtype = mime.split('/', 1)\n    if '+' not in subtype:\n        lexer_names.append(subtype)\n    else:\n        subtype_name, subtype_suffix = subtype.split('+', 1)\n        lexer_names.extend([subtype_name, subtype_suffix])\n        mime_types.extend([\n            f'{type_}/{subtype_name}',\n            f'{type_}/{subtype_suffix}',\n        ])\n\n    # As a last resort, if no lexer feels responsible, and\n    # the subtype contains 'json', take the JSON lexer\n    if 'json' in subtype:\n        lexer_names.append('json')\n\n    # Try to resolve the right lexer.\n    lexer = None\n    for mime_type in mime_types:\n        try:\n            lexer = pygments.lexers.get_lexer_for_mimetype(mime_type)\n            break\n        except ClassNotFound:\n            pass\n    else:\n        for name in lexer_names:\n            try:\n                lexer = pygments.lexers.get_lexer_by_name(name)\n            except ClassNotFound:\n                pass\n\n    if explicit_json and body and (not lexer or isinstance(lexer, TextLexer)):\n        # JSON response with an incorrect Content-Type?\n        try:\n            json.loads(body)  # FIXME: the body also gets parsed in json.py\n        except ValueError:\n            pass  # Nope\n        else:\n            lexer = pygments.lexers.get_lexer_by_name('json')\n\n    # Use our own JSON lexer: it supports JSON bodies preceded by non-JSON data\n    # as well as legit JSON bodies.\n    if isinstance(lexer, JsonLexer):\n        lexer = EnhancedJsonLexer()\n\n    return lexer\n\n\nclass Solarized256Style(pygments.style.Style):\n    \"\"\"\n    solarized256\n    ------------\n\n    A Pygments style inspired by Solarized's 256 color mode.\n\n    :copyright: (c) 2011 by Hank Gay, (c) 2012 by John Mastro.\n    :license: BSD, see LICENSE for more details.\n\n    \"\"\"\n    BASE03 = \"#1c1c1c\"\n    BASE02 = \"#262626\"\n    BASE01 = \"#4e4e4e\"\n    BASE00 = \"#585858\"\n    BASE0 = \"#808080\"\n    BASE1 = \"#8a8a8a\"\n    BASE2 = \"#d7d7af\"\n    BASE3 = \"#ffffd7\"\n    YELLOW = \"#af8700\"\n    ORANGE = \"#d75f00\"\n    RED = \"#af0000\"\n    MAGENTA = \"#af005f\"\n    VIOLET = \"#5f5faf\"\n    BLUE = \"#0087ff\"\n    CYAN = \"#00afaf\"\n    GREEN = \"#5f8700\"\n\n    background_color = BASE03\n    styles = {\n        pygments.token.Keyword: GREEN,\n        pygments.token.Keyword.Constant: ORANGE,\n        pygments.token.Keyword.Declaration: BLUE,\n        pygments.token.Keyword.Namespace: ORANGE,\n        pygments.token.Keyword.Reserved: BLUE,\n        pygments.token.Keyword.Type: RED,\n        pygments.token.Name.Attribute: BASE1,\n        pygments.token.Name.Builtin: BLUE,\n        pygments.token.Name.Builtin.Pseudo: BLUE,\n        pygments.token.Name.Class: BLUE,\n        pygments.token.Name.Constant: ORANGE,\n        pygments.token.Name.Decorator: BLUE,\n        pygments.token.Name.Entity: ORANGE,\n        pygments.token.Name.Exception: YELLOW,\n        pygments.token.Name.Function: BLUE,\n        pygments.token.Name.Tag: BLUE,\n        pygments.token.Name.Variable: BLUE,\n        pygments.token.String: CYAN,\n        pygments.token.String.Backtick: BASE01,\n        pygments.token.String.Char: CYAN,\n        pygments.token.String.Doc: CYAN,\n        pygments.token.String.Escape: RED,\n        pygments.token.String.Heredoc: CYAN,\n        pygments.token.String.Regex: RED,\n        pygments.token.Number: CYAN,\n        pygments.token.Operator: BASE1,\n        pygments.token.Operator.Word: GREEN,\n        pygments.token.Comment: BASE01,\n        pygments.token.Comment.Preproc: GREEN,\n        pygments.token.Comment.Special: GREEN,\n        pygments.token.Generic.Deleted: CYAN,\n        pygments.token.Generic.Emph: PYGMENTS_ITALIC,\n        pygments.token.Generic.Error: RED,\n        pygments.token.Generic.Heading: ORANGE,\n        pygments.token.Generic.Inserted: GREEN,\n        pygments.token.Generic.Strong: PYGMENTS_BOLD,\n        pygments.token.Generic.Subheading: ORANGE,\n        pygments.token.Token: BASE1,\n        pygments.token.Token.Other: ORANGE,\n    }\n\n\nPIE_HEADER_STYLE = {\n    # HTTP line / Headers / Etc.\n    pygments.token.Name.Namespace: PYGMENTS_BOLD | PieColor.PRIMARY,\n    pygments.token.Keyword.Reserved: PYGMENTS_BOLD | PieColor.GREY,\n    pygments.token.Operator: PYGMENTS_BOLD | PieColor.GREY,\n    pygments.token.Number: PYGMENTS_BOLD | PieColor.GREY,\n    pygments.token.Name.Function.Magic: PYGMENTS_BOLD | PieColor.GREEN,\n    pygments.token.Name.Exception: PYGMENTS_BOLD | PieColor.GREEN,\n    pygments.token.Name.Attribute: PieColor.BLUE,\n    pygments.token.String: PieColor.PRIMARY,\n\n    # HTTP Methods\n    pygments.token.Name.Function: PYGMENTS_BOLD | PieColor.GREY,\n    pygments.token.Name.Function.HTTP.GET: PYGMENTS_BOLD | PieColor.GREEN,\n    pygments.token.Name.Function.HTTP.HEAD: PYGMENTS_BOLD | PieColor.GREEN,\n    pygments.token.Name.Function.HTTP.POST: PYGMENTS_BOLD | PieColor.YELLOW,\n    pygments.token.Name.Function.HTTP.PUT: PYGMENTS_BOLD | PieColor.ORANGE,\n    pygments.token.Name.Function.HTTP.PATCH: PYGMENTS_BOLD | PieColor.ORANGE,\n    pygments.token.Name.Function.HTTP.DELETE: PYGMENTS_BOLD | PieColor.RED,\n\n    # HTTP status codes\n    pygments.token.Number.HTTP.INFO: PYGMENTS_BOLD | PieColor.AQUA,\n    pygments.token.Number.HTTP.OK: PYGMENTS_BOLD | PieColor.GREEN,\n    pygments.token.Number.HTTP.REDIRECT: PYGMENTS_BOLD | PieColor.YELLOW,\n    pygments.token.Number.HTTP.CLIENT_ERR: PYGMENTS_BOLD | PieColor.ORANGE,\n    pygments.token.Number.HTTP.SERVER_ERR: PYGMENTS_BOLD | PieColor.RED,\n\n    # Metadata\n    pygments.token.Name.Decorator: PieColor.GREY,\n    pygments.token.Number.SPEED.FAST: PYGMENTS_BOLD | PieColor.GREEN,\n    pygments.token.Number.SPEED.AVG: PYGMENTS_BOLD | PieColor.YELLOW,\n    pygments.token.Number.SPEED.SLOW: PYGMENTS_BOLD | PieColor.ORANGE,\n    pygments.token.Number.SPEED.VERY_SLOW: PYGMENTS_BOLD | PieColor.RED,\n}\n\nPIE_BODY_STYLE = {\n    # {}[]:\n    pygments.token.Punctuation: PieColor.GREY,\n\n    # Keys\n    pygments.token.Name.Tag: PieColor.PINK,\n\n    # Values\n    pygments.token.Literal.String: PieColor.GREEN,\n    pygments.token.Literal.String.Double: PieColor.GREEN,\n    pygments.token.Literal.Number: PieColor.AQUA,\n    pygments.token.Keyword: PieColor.ORANGE,\n\n    # Other stuff\n    pygments.token.Text: PieColor.PRIMARY,\n    pygments.token.Name.Attribute: PieColor.PRIMARY,\n    pygments.token.Name.Builtin: PieColor.BLUE,\n    pygments.token.Name.Builtin.Pseudo: PieColor.BLUE,\n    pygments.token.Name.Class: PieColor.BLUE,\n    pygments.token.Name.Constant: PieColor.ORANGE,\n    pygments.token.Name.Decorator: PieColor.BLUE,\n    pygments.token.Name.Entity: PieColor.ORANGE,\n    pygments.token.Name.Exception: PieColor.YELLOW,\n    pygments.token.Name.Function: PieColor.BLUE,\n    pygments.token.Name.Variable: PieColor.BLUE,\n    pygments.token.String: PieColor.AQUA,\n    pygments.token.String.Backtick: PieColor.SECONDARY,\n    pygments.token.String.Char: PieColor.AQUA,\n    pygments.token.String.Doc: PieColor.AQUA,\n    pygments.token.String.Escape: PieColor.RED,\n    pygments.token.String.Heredoc: PieColor.AQUA,\n    pygments.token.String.Regex: PieColor.RED,\n    pygments.token.Number: PieColor.AQUA,\n    pygments.token.Operator: PieColor.PRIMARY,\n    pygments.token.Operator.Word: PieColor.GREEN,\n    pygments.token.Comment: PieColor.SECONDARY,\n    pygments.token.Comment.Preproc: PieColor.GREEN,\n    pygments.token.Comment.Special: PieColor.GREEN,\n    pygments.token.Generic.Deleted: PieColor.AQUA,\n    pygments.token.Generic.Emph: PYGMENTS_ITALIC,\n    pygments.token.Generic.Error: PieColor.RED,\n    pygments.token.Generic.Heading: PieColor.ORANGE,\n    pygments.token.Generic.Inserted: PieColor.GREEN,\n    pygments.token.Generic.Strong: PYGMENTS_BOLD,\n    pygments.token.Generic.Subheading: PieColor.ORANGE,\n    pygments.token.Token: PieColor.PRIMARY,\n    pygments.token.Token.Other: PieColor.ORANGE,\n}\n\n\ndef make_style(name, raw_styles, shade):\n    def format_value(value):\n        return ' '.join(\n            get_color(part, shade) or part\n            for part in value.split()\n        )\n\n    bases = (pygments.style.Style,)\n    data = {\n        'styles': {\n            key: format_value(value)\n            for key, value in raw_styles.items()\n        }\n    }\n    return type(name, bases, data)\n\n\ndef make_styles():\n    styles = {}\n\n    for shade, name in SHADE_TO_PIE_STYLE.items():\n        styles[name] = [\n            make_style(name, style_map, shade)\n            for style_name, style_map in [\n                (f'Pie{name}HeaderStyle', PIE_HEADER_STYLE),\n                (f'Pie{name}BodyStyle', PIE_BODY_STYLE),\n            ]\n        ]\n\n    return styles\n\n\nPIE_STYLES = make_styles()\nPIE_STYLE_NAMES = list(PIE_STYLES.keys())\nBUNDLED_STYLES |= PIE_STYLES.keys()\n", "httpie/manager/cli.py": "from textwrap import dedent\nfrom httpie.cli.argparser import HTTPieManagerArgumentParser\nfrom httpie.cli.options import Qualifiers, ARGPARSE_QUALIFIER_MAP, map_qualifiers, parser_to_parser_spec\nfrom httpie import __version__\n\nCLI_SESSION_UPGRADE_FLAGS = [\n    {\n        'flags': ['--bind-cookies'],\n        'action': 'store_true',\n        'default': False,\n        'help': 'Bind domainless cookies to the host that session belongs.'\n    }\n]\n\nCOMMANDS = {\n    'cli': {\n        'help': 'Manage HTTPie for Terminal',\n        'export-args': [\n            'Export available options for the CLI',\n            {\n                'flags': ['-f', '--format'],\n                'choices': ['json'],\n                'help': 'Format to export in.',\n                'default': 'json'\n            }\n        ],\n        'check-updates': [\n            'Check for updates'\n        ],\n        'sessions': {\n            'help': 'Manage HTTPie sessions',\n            'upgrade': [\n                'Upgrade the given HTTPie session with the latest '\n                'layout. A list of changes between different session versions '\n                'can be found in the official documentation.',\n                {\n                    'dest': 'hostname',\n                    'metavar': 'HOSTNAME',\n                    'help': 'The host this session belongs.'\n                },\n                {\n                    'dest': 'session',\n                    'metavar': 'SESSION_NAME_OR_PATH',\n                    'help': 'The name or the path for the session that will be upgraded.'\n                },\n                *CLI_SESSION_UPGRADE_FLAGS\n            ],\n            'upgrade-all': [\n                'Upgrade all named sessions with the latest layout. A list of '\n                'changes between different session versions can be found in the official '\n                'documentation.',\n                *CLI_SESSION_UPGRADE_FLAGS\n            ],\n        }\n    }\n}\n\n\nCOMMANDS['plugins'] = COMMANDS['cli']['plugins'] = {\n    'help': 'Manage HTTPie plugins.',\n    'install': [\n        'Install the given targets from PyPI '\n        'or from a local paths.',\n        {\n            'dest': 'targets',\n            'metavar': 'TARGET',\n            'nargs': Qualifiers.ONE_OR_MORE,\n            'help': 'targets to install'\n        }\n    ],\n    'upgrade': [\n        'Upgrade the given plugins',\n        {\n            'dest': 'targets',\n            'metavar': 'TARGET',\n            'nargs': Qualifiers.ONE_OR_MORE,\n            'help': 'targets to upgrade'\n        }\n    ],\n    'uninstall': [\n        'Uninstall the given HTTPie plugins.',\n        {\n            'dest': 'targets',\n            'metavar': 'TARGET',\n            'nargs': Qualifiers.ONE_OR_MORE,\n            'help': 'targets to install'\n        }\n    ],\n    'list': [\n        'List all installed HTTPie plugins.'\n    ],\n}\n\n\ndef missing_subcommand(*args) -> str:\n    base = COMMANDS\n    for arg in args:\n        base = base[arg]\n\n    assert isinstance(base, dict)\n    subcommands = ', '.join(map(repr, base.keys()))\n    return f'Please specify one of these: {subcommands}'\n\n\ndef generate_subparsers(root, parent_parser, definitions, spec):\n    action_dest = '_'.join(parent_parser.prog.split()[1:] + ['action'])\n    actions = parent_parser.add_subparsers(\n        dest=action_dest\n    )\n    for command, properties in definitions.items():\n        is_subparser = isinstance(properties, dict)\n        properties = properties.copy()\n\n        descr = properties.pop('help', None) if is_subparser else properties.pop(0)\n        command_parser = actions.add_parser(command, description=descr)\n        command_parser.root = root\n        if is_subparser:\n            generate_subparsers(root, command_parser, properties, spec)\n            continue\n\n        group = spec.add_group(parent_parser.prog + ' ' + command, description=descr)\n        for argument in properties:\n            argument = argument.copy()\n            flags = argument.pop('flags', [])\n            command_parser.add_argument(*flags, **map_qualifiers(argument, ARGPARSE_QUALIFIER_MAP))\n            group.add_argument(*flags, **argument)\n\n\nparser = HTTPieManagerArgumentParser(\n    prog='httpie',\n    description=dedent(\n        '''\n        Managing interface for the HTTPie itself. <https://httpie.io/docs#manager>\n\n        Be aware that you might be looking for http/https commands for sending\n        HTTP requests. This command is only available for managing the HTTTPie\n        plugins and the configuration around it.\n        '''\n    ),\n)\n\nparser.add_argument(\n    '--debug',\n    action='store_true',\n    default=False,\n    help='''\n    Prints the exception traceback should one occur, as well as other\n    information useful for debugging HTTPie itself and for reporting bugs.\n\n    '''\n)\n\nparser.add_argument(\n    '--traceback',\n    action='store_true',\n    default=False,\n    help='''\n    Prints the exception traceback should one occur.\n\n    '''\n)\n\nparser.add_argument(\n    '--version',\n    action='version',\n    version=__version__,\n    help='''\n    Show version and exit.\n\n    '''\n)\n\nman_page_hint = '''\nIf you are looking for the man pages of http/https commands, try one of the following:\n    $ man http\n    $ man https\n\n'''\n\noptions = parser_to_parser_spec(parser, man_page_hint=man_page_hint, source_file=__file__)\ngenerate_subparsers(parser, parser, COMMANDS, options)\n", "httpie/manager/core.py": "import argparse\nfrom typing import Optional\n\nfrom httpie.context import Environment\nfrom httpie.status import ExitStatus\nfrom httpie.manager.cli import missing_subcommand, parser\nfrom httpie.manager.tasks import CLI_TASKS\n\nMSG_COMMAND_CONFUSION = '''\\\nThis command is only for managing HTTPie plugins.\nTo send a request, please use the http/https commands:\n\n  $ http {args}\n\n  $ https {args}\n'''\n\n# noinspection PyStringFormat\nMSG_NAKED_INVOCATION = f'''\\\n{missing_subcommand()}\n\n{MSG_COMMAND_CONFUSION}\n'''.rstrip(\"\\n\").format(args='POST pie.dev/post hello=world')\n\n\ndef dispatch_cli_task(env: Environment, action: Optional[str], args: argparse.Namespace) -> ExitStatus:\n    if action is None:\n        parser.error(missing_subcommand('cli'))\n\n    return CLI_TASKS[action](env, args)\n\n\ndef program(args: argparse.Namespace, env: Environment) -> ExitStatus:\n    if args.action is None:\n        parser.error(MSG_NAKED_INVOCATION)\n\n    if args.action == 'plugins':\n        return dispatch_cli_task(env, args.action, args)\n    elif args.action == 'cli':\n        return dispatch_cli_task(env, args.cli_action, args)\n\n    return ExitStatus.SUCCESS\n", "httpie/manager/__main__.py": "import argparse\nimport sys\n\nfrom typing import List, Union\n\nfrom httpie.context import Environment\nfrom httpie.status import ExitStatus\nfrom httpie.manager.cli import parser\nfrom httpie.manager.core import MSG_COMMAND_CONFUSION, program as main_program\n\n\ndef is_http_command(args: List[Union[str, bytes]], env: Environment) -> bool:\n    \"\"\"Check whether http/https parser can parse the arguments.\"\"\"\n\n    from httpie.cli.definition import parser as http_parser\n    from httpie.manager.cli import COMMANDS\n\n    # If the user already selected a top-level sub-command, never\n    # show the http/https version. E.g httpie plugins pie.dev/post\n    if len(args) >= 1 and args[0] in COMMANDS:\n        return False\n\n    with env.as_silent():\n        try:\n            http_parser.parse_args(env=env, args=args)\n        except (Exception, SystemExit):\n            return False\n        else:\n            return True\n\n\ndef main(args: List[Union[str, bytes]] = sys.argv, env: Environment = Environment()) -> ExitStatus:\n    from httpie.core import raw_main\n\n    try:\n        return raw_main(\n            parser=parser,\n            main_program=main_program,\n            args=args,\n            env=env,\n            use_default_options=False,\n        )\n    except argparse.ArgumentError:\n        program_args = args[1:]\n        if is_http_command(program_args, env):\n            env.stderr.write(MSG_COMMAND_CONFUSION.format(args=' '.join(program_args)) + \"\\n\")\n\n        return ExitStatus.ERROR\n\n\ndef program():\n    try:\n        exit_status = main()\n    except KeyboardInterrupt:\n        exit_status = ExitStatus.ERROR_CTRL_C\n\n    return exit_status\n\n\nif __name__ == '__main__':  # pragma: nocover\n    sys.exit(program())\n", "httpie/manager/__init__.py": "", "httpie/manager/compat.py": "import sys\nimport shutil\nimport subprocess\n\nfrom contextlib import suppress\nfrom typing import List, Optional\nfrom httpie.compat import is_frozen\n\n\nclass PipError(Exception):\n    \"\"\"An exception that occurs when pip exits with an error status code.\"\"\"\n\n    def __init__(self, stdout, stderr):\n        self.stdout = stdout\n        self.stderr = stderr\n\n\ndef _discover_system_pip() -> List[str]:\n    # When we are running inside of a frozen binary, we need the system\n    # pip to install plugins since there is no way for us to execute any\n    # code outside of the HTTPie.\n    #\n    # We explicitly depend on system pip, so the SystemError should not\n    # be executed (except for broken installations).\n    def _check_pip_version(pip_location: Optional[str]) -> bool:\n        if not pip_location:\n            return False\n\n        with suppress(subprocess.CalledProcessError):\n            stdout = subprocess.check_output([pip_location, \"--version\"], text=True)\n            return \"python 3\" in stdout\n\n    targets = [\n        \"pip\",\n        \"pip3\"\n    ]\n    for target in targets:\n        pip_location = shutil.which(target)\n        if _check_pip_version(pip_location):\n            return pip_location\n\n    raise SystemError(\"Couldn't find 'pip' executable. Please ensure that pip in your system is available.\")\n\n\ndef _run_pip_subprocess(pip_executable: List[str], args: List[str]) -> bytes:\n\n    cmd = [*pip_executable, *args]\n    try:\n        process = subprocess.run(\n            cmd,\n            check=True,\n            shell=False,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE\n        )\n    except subprocess.CalledProcessError as error:\n        raise PipError(error.stdout, error.stderr) from error\n    else:\n        return process.stdout\n\n\ndef run_pip(args: List[str]) -> bytes:\n    if is_frozen:\n        pip_executable = [_discover_system_pip()]\n    else:\n        pip_executable = [sys.executable, '-m', 'pip']\n\n    return _run_pip_subprocess(pip_executable, args)\n", "httpie/manager/tasks/check_updates.py": "import argparse\nfrom httpie.context import Environment\nfrom httpie.status import ExitStatus\nfrom httpie.internal.update_warnings import fetch_updates, get_update_status\n\n\ndef cli_check_updates(env: Environment, args: argparse.Namespace) -> ExitStatus:\n    fetch_updates(env, lazy=False)\n    env.stdout.write(get_update_status(env))\n    return ExitStatus.SUCCESS\n", "httpie/manager/tasks/export_args.py": "import argparse\nimport json\n\nfrom httpie.cli.definition import options\nfrom httpie.cli.options import to_data\nfrom httpie.output.writer import write_raw_data\nfrom httpie.status import ExitStatus\nfrom httpie.context import Environment\n\n\nFORMAT_TO_CONTENT_TYPE = {\n    'json': 'application/json'\n}\n\n\ndef cli_export_args(env: Environment, args: argparse.Namespace) -> ExitStatus:\n    if args.format == 'json':\n        data = json.dumps(to_data(options))\n    else:\n        raise NotImplementedError(f'Unexpected format value: {args.format}')\n\n    write_raw_data(\n        env,\n        data,\n        stream_kwargs={'mime_overwrite': FORMAT_TO_CONTENT_TYPE[args.format]},\n    )\n    return ExitStatus.SUCCESS\n", "httpie/manager/tasks/plugins.py": "import argparse\nimport os\nimport textwrap\nimport re\nimport shutil\nfrom collections import defaultdict\nfrom contextlib import suppress\nfrom pathlib import Path\nfrom typing import List, Optional, Tuple\n\nfrom httpie.manager.compat import PipError, run_pip\nfrom httpie.manager.cli import parser, missing_subcommand\nfrom httpie.compat import get_dist_name, importlib_metadata\nfrom httpie.context import Environment\nfrom httpie.status import ExitStatus\nfrom httpie.utils import get_site_paths\n\nPEP_503 = re.compile(r\"[-_.]+\")\n\n\nclass PluginInstaller:\n\n    def __init__(self, env: Environment, debug: bool = False) -> None:\n        self.env = env\n        self.dir = env.config.plugins_dir\n        self.debug = debug\n\n        self.setup_plugins_dir()\n\n    def setup_plugins_dir(self) -> None:\n        try:\n            self.dir.mkdir(\n                exist_ok=True,\n                parents=True\n            )\n        except OSError:\n            self.env.stderr.write(\n                f'Couldn\\'t create \"{self.dir!s}\"'\n                ' directory for plugin installation.'\n                ' Please re-check the permissions for that directory,'\n                ' and if needed, allow write-access.'\n            )\n            raise\n\n    def fail(\n        self,\n        command: str,\n        target: Optional[str] = None,\n        reason: Optional[str] = None\n    ) -> ExitStatus:\n        message = f'Can\\'t {command}'\n        if target:\n            message += f' {target!r}'\n        if reason:\n            message += f': {reason}'\n\n        self.env.stderr.write(message + '\\n')\n        return ExitStatus.ERROR\n\n    def _install(self, targets: List[str], mode='install') -> Tuple[\n        bytes, ExitStatus\n    ]:\n        pip_args = [\n            'install',\n            '--prefer-binary',\n            f'--prefix={self.dir}',\n            '--no-warn-script-location',\n        ]\n        if mode == 'upgrade':\n            pip_args.append('--upgrade')\n        pip_args.extend(targets)\n\n        try:\n            stdout = run_pip(pip_args)\n        except PipError as pip_error:\n            error = pip_error\n            stdout = pip_error.stdout\n        else:\n            error = None\n\n        self.env.stdout.write(stdout.decode())\n\n        if error:\n            reason = None\n            if error.stderr:\n                stderr = error.stderr.decode()\n\n                if self.debug:\n                    self.env.stderr.write('Command failed: ')\n                    self.env.stderr.write('pip ' + ' '.join(pip_args) + '\\n')\n                    self.env.stderr.write(textwrap.indent('  ', stderr))\n\n                last_line = stderr.strip().splitlines()[-1]\n                severity, _, message = last_line.partition(': ')\n                if severity == 'ERROR':\n                    reason = message\n\n            stdout = error.stdout\n            exit_status = self.fail(mode, ', '.join(targets), reason)\n        else:\n            exit_status = ExitStatus.SUCCESS\n\n        return stdout, exit_status\n\n    def install(self, targets: List[str]) -> ExitStatus:\n        self.env.stdout.write(f\"Installing {', '.join(targets)}...\\n\")\n        self.env.stdout.flush()\n        _, exit_status = self._install(targets)\n        return exit_status\n\n    def _clear_metadata(self, targets: List[str]) -> None:\n        # Due to an outstanding pip problem[0], we have to get rid of\n        # existing metadata for old versions manually.\n        # [0]: https://github.com/pypa/pip/issues/10727\n        result_deps = defaultdict(list)\n        for site_dir in get_site_paths(self.dir):\n            for child in site_dir.iterdir():\n                if child.suffix in {'.dist-info', '.egg-info'}:\n                    name, _, version = child.stem.rpartition('-')\n                    result_deps[name].append((version, child))\n\n        for target in targets:\n            name, _, version = target.rpartition('-')\n            name = PEP_503.sub(\"-\", name).lower().replace('-', '_')\n            if name not in result_deps:\n                continue\n\n            for result_version, meta_path in result_deps[name]:\n                if version != result_version:\n                    shutil.rmtree(meta_path)\n\n    def upgrade(self, targets: List[str]) -> ExitStatus:\n        self.env.stdout.write(f\"Upgrading {', '.join(targets)}...\\n\")\n        self.env.stdout.flush()\n\n        raw_stdout, exit_status = self._install(\n            targets,\n            mode='upgrade'\n        )\n        if not raw_stdout:\n            return exit_status\n\n        stdout = raw_stdout.decode()\n        installation_line = stdout.splitlines()[-1]\n        if installation_line.startswith('Successfully installed'):\n            self._clear_metadata(installation_line.split()[2:])\n\n    def _uninstall(self, target: str) -> Optional[ExitStatus]:\n        try:\n            distribution = importlib_metadata.distribution(target)\n        except importlib_metadata.PackageNotFoundError:\n            return self.fail('uninstall', target, 'package is not installed')\n\n        base_dir = Path(distribution.locate_file('.')).resolve()\n        if self.dir not in base_dir.parents:\n            # If the package is installed somewhere else (e.g on the site packages\n            # of the real python interpreter), than that means this package is not\n            # installed through us.\n            return self.fail('uninstall', target,\n                             'package is not installed through httpie plugins'\n                             ' interface')\n\n        files = distribution.files\n        if files is None:\n            return self.fail('uninstall', target, 'couldn\\'t locate the package')\n\n        # TODO: Consider handling failures here (e.g if it fails,\n        # just revert the operation and leave the site-packages\n        # in a proper shape).\n        for file in files:\n            with suppress(FileNotFoundError):\n                os.unlink(distribution.locate_file(file))\n\n        metadata_path = getattr(distribution, '_path', None)\n        if (\n            metadata_path\n            and metadata_path.exists()\n            and not any(metadata_path.iterdir())\n        ):\n            metadata_path.rmdir()\n\n        self.env.stdout.write(f'Successfully uninstalled {target}\\n')\n\n    def uninstall(self, targets: List[str]) -> ExitStatus:\n        # Unfortunately uninstall doesn't work with custom pip schemes. See:\n        # - https://github.com/pypa/pip/issues/5595\n        # - https://github.com/pypa/pip/issues/4575\n        # so we have to implement our own uninstalling logic. Which works\n        # on top of the importlib_metadata.\n\n        exit_code = ExitStatus.SUCCESS\n        for target in targets:\n            exit_code |= self._uninstall(target) or ExitStatus.SUCCESS\n        return ExitStatus(exit_code)\n\n    def list(self) -> None:\n        from httpie.plugins.registry import plugin_manager\n\n        known_plugins = defaultdict(list)\n\n        for entry_point in plugin_manager.iter_entry_points(self.dir):\n            ep_info = (entry_point.group, entry_point.name)\n            ep_name = get_dist_name(entry_point) or entry_point.module\n            known_plugins[ep_name].append(ep_info)\n\n        for plugin, entry_points in known_plugins.items():\n            self.env.stdout.write(plugin)\n\n            version = importlib_metadata.version(plugin)\n            if version is not None:\n                self.env.stdout.write(f' ({version})')\n            self.env.stdout.write('\\n')\n\n            for group, entry_point in sorted(entry_points):\n                self.env.stdout.write(f'  {entry_point} ({group})\\n')\n\n    def run(\n        self,\n        action: Optional[str],\n        args: argparse.Namespace,\n    ) -> ExitStatus:\n        from httpie.plugins.manager import enable_plugins\n\n        if action is None:\n            parser.error(missing_subcommand('plugins'))\n\n        with enable_plugins(self.dir):\n            if action == 'install':\n                status = self.install(args.targets)\n            elif action == 'upgrade':\n                status = self.upgrade(args.targets)\n            elif action == 'uninstall':\n                status = self.uninstall(args.targets)\n            elif action == 'list':\n                status = self.list()\n\n        return status or ExitStatus.SUCCESS\n\n\ndef cli_plugins(env: Environment, args: argparse.Namespace) -> ExitStatus:\n    plugins = PluginInstaller(env, debug=args.debug)\n\n    try:\n        action = args.cli_plugins_action\n    except AttributeError:\n        action = args.plugins_action\n\n    return plugins.run(action, args)\n", "httpie/manager/tasks/__init__.py": "from httpie.manager.tasks.sessions import cli_sessions\nfrom httpie.manager.tasks.export_args import cli_export_args\nfrom httpie.manager.tasks.plugins import cli_plugins\nfrom httpie.manager.tasks.check_updates import cli_check_updates\n\nCLI_TASKS = {\n    'sessions': cli_sessions,\n    'export-args': cli_export_args,\n    'plugins': cli_plugins,\n    'check-updates': cli_check_updates\n}\n", "httpie/manager/tasks/sessions.py": "import argparse\n\nfrom httpie.sessions import SESSIONS_DIR_NAME, get_httpie_session\nfrom httpie.status import ExitStatus\nfrom httpie.context import Environment\nfrom httpie.legacy import v3_1_0_session_cookie_format, v3_2_0_session_header_format\nfrom httpie.manager.cli import missing_subcommand, parser\nfrom httpie.utils import is_version_greater\n\n\nFIXERS_TO_VERSIONS = {\n    '3.1.0': v3_1_0_session_cookie_format.fix_layout,\n    '3.2.0': v3_2_0_session_header_format.fix_layout,\n}\n\n\ndef cli_sessions(env: Environment, args: argparse.Namespace) -> ExitStatus:\n    action = args.cli_sessions_action\n    if action is None:\n        parser.error(missing_subcommand('cli', 'sessions'))\n\n    if action == 'upgrade':\n        return cli_upgrade_session(env, args)\n    elif action == 'upgrade-all':\n        return cli_upgrade_all_sessions(env, args)\n    else:\n        raise ValueError(f'Unexpected action: {action}')\n\n\ndef upgrade_session(env: Environment, args: argparse.Namespace, hostname: str, session_name: str):\n    session = get_httpie_session(\n        env=env,\n        config_dir=env.config.directory,\n        session_name=session_name,\n        host=hostname,\n        url=hostname,\n        suppress_legacy_warnings=True\n    )\n\n    session_name = session.path.stem\n    if session.is_new():\n        env.log_error(f'{session_name!r} @ {hostname!r} does not exist.')\n        return ExitStatus.ERROR\n\n    fixers = [\n        fixer\n        for version, fixer in FIXERS_TO_VERSIONS.items()\n        if is_version_greater(version, session.version)\n    ]\n\n    if len(fixers) == 0:\n        env.stdout.write(f'{session_name!r} @ {hostname!r} is already up to date.\\n')\n        return ExitStatus.SUCCESS\n\n    for fixer in fixers:\n        fixer(session, hostname, args)\n\n    session.save(bump_version=True)\n    env.stdout.write(f'Upgraded {session_name!r} @ {hostname!r} to v{session.version}\\n')\n    return ExitStatus.SUCCESS\n\n\ndef cli_upgrade_session(env: Environment, args: argparse.Namespace) -> ExitStatus:\n    return upgrade_session(\n        env,\n        args=args,\n        hostname=args.hostname,\n        session_name=args.session\n    )\n\n\ndef cli_upgrade_all_sessions(env: Environment, args: argparse.Namespace) -> ExitStatus:\n    session_dir_path = env.config_dir / SESSIONS_DIR_NAME\n\n    status = ExitStatus.SUCCESS\n    for host_path in session_dir_path.iterdir():\n        hostname = host_path.name\n        for session_path in host_path.glob(\"*.json\"):\n            session_name = session_path.stem\n            status |= upgrade_session(\n                env,\n                args=args,\n                hostname=hostname,\n                session_name=session_name\n            )\n    return status\n"}