{"run.py": "#!/usr/bin/env python\n# coding: utf-8\nfrom __future__ import unicode_literals, division, absolute_import, print_function\n\nfrom dev._task import run_task\n\n\nrun_task()\n", "setup.py": "import codecs\nimport os\nimport shutil\nimport sys\nimport warnings\n\nimport setuptools\nfrom setuptools import setup, Command\nfrom setuptools.command.egg_info import egg_info\n\n\nPACKAGE_NAME = 'asn1crypto'\nPACKAGE_VERSION = '1.5.1'\nPACKAGE_ROOT = os.path.dirname(os.path.abspath(__file__))\n\n\n# setuptools 38.6.0 and newer know about long_description_content_type, but\n# distutils still complains about it, so silence the warning\nsv = setuptools.__version__\nsvi = tuple(int(o) if o.isdigit() else o for o in sv.split('.'))\nif svi >= (38, 6):\n    warnings.filterwarnings(\n        'ignore',\n        \"Unknown distribution option: 'long_description_content_type'\",\n        module='distutils.dist'\n    )\n\n\n# Try to load the tests first from the source repository layout. If that\n# doesn't work, we assume this file is in the release package, and the tests\n# are part of the package {PACKAGE_NAME}_tests.\nif os.path.exists(os.path.join(PACKAGE_ROOT, 'tests')):\n    tests_require = []\n    test_suite = 'tests.make_suite'\nelse:\n    tests_require = ['%s_tests' % PACKAGE_NAME]\n    test_suite = '%s_tests.make_suite' % PACKAGE_NAME\n\n\n# This allows us to send the LICENSE and docs when creating a sdist. Wheels\n# automatically include the LICENSE, and don't need the docs. For these\n# to be included, the command must be \"python setup.py sdist\".\npackage_data = {}\nif sys.argv[1:] == ['sdist'] or sorted(sys.argv[1:]) == ['-q', 'sdist']:\n    package_data[PACKAGE_NAME] = [\n        '../LICENSE',\n        '../*.md',\n        '../docs/*.md',\n    ]\n\n\n# Ensures a copy of the LICENSE is included with the egg-info for\n# install and bdist_egg commands\nclass EggInfoCommand(egg_info):\n    def run(self):\n        egg_info_path = os.path.join(\n            PACKAGE_ROOT,\n            '%s.egg-info' % PACKAGE_NAME\n        )\n        if not os.path.exists(egg_info_path):\n            os.mkdir(egg_info_path)\n        shutil.copy2(\n            os.path.join(PACKAGE_ROOT, 'LICENSE'),\n            os.path.join(egg_info_path, 'LICENSE')\n        )\n        egg_info.run(self)\n\n\nclass CleanCommand(Command):\n    user_options = [\n        ('all', 'a', '(Compatibility with original clean command)'),\n    ]\n\n    def initialize_options(self):\n        self.all = False\n\n    def finalize_options(self):\n        pass\n\n    def run(self):\n        sub_folders = ['build', 'temp', '%s.egg-info' % PACKAGE_NAME]\n        if self.all:\n            sub_folders.append('dist')\n        for sub_folder in sub_folders:\n            full_path = os.path.join(PACKAGE_ROOT, sub_folder)\n            if os.path.exists(full_path):\n                shutil.rmtree(full_path)\n        for root, dirs, files in os.walk(os.path.join(PACKAGE_ROOT, PACKAGE_NAME)):\n            for filename in files:\n                if filename[-4:] == '.pyc':\n                    os.unlink(os.path.join(root, filename))\n            for dirname in list(dirs):\n                if dirname == '__pycache__':\n                    shutil.rmtree(os.path.join(root, dirname))\n\n\nreadme = ''\nwith codecs.open(os.path.join(PACKAGE_ROOT, 'readme.md'), 'r', 'utf-8') as f:\n    readme = f.read()\n\n\nsetup(\n    name=PACKAGE_NAME,\n    version=PACKAGE_VERSION,\n\n    description=(\n        'Fast ASN.1 parser and serializer with definitions for private keys, '\n        'public keys, certificates, CRL, OCSP, CMS, PKCS#3, PKCS#7, PKCS#8, '\n        'PKCS#12, PKCS#5, X.509 and TSP'\n    ),\n    long_description=readme,\n    long_description_content_type='text/markdown',\n\n    url='https://github.com/wbond/asn1crypto',\n\n    author='wbond',\n    author_email='will@wbond.net',\n\n    license='MIT',\n\n    classifiers=[\n        'Development Status :: 5 - Production/Stable',\n\n        'Intended Audience :: Developers',\n\n        'License :: OSI Approved :: MIT License',\n\n        'Programming Language :: Python',\n        'Programming Language :: Python :: 2',\n        'Programming Language :: Python :: 2.6',\n        'Programming Language :: Python :: 2.7',\n        'Programming Language :: Python :: 3',\n        'Programming Language :: Python :: 3.2',\n        'Programming Language :: Python :: 3.3',\n        'Programming Language :: Python :: 3.4',\n        'Programming Language :: Python :: 3.5',\n        'Programming Language :: Python :: 3.6',\n        'Programming Language :: Python :: 3.7',\n        'Programming Language :: Python :: 3.8',\n        'Programming Language :: Python :: 3.9',\n        'Programming Language :: Python :: 3.10',\n        'Programming Language :: Python :: 3.11',\n        'Programming Language :: Python :: 3.12',\n        'Programming Language :: Python :: Implementation :: CPython',\n        'Programming Language :: Python :: Implementation :: PyPy',\n\n        'Topic :: Security :: Cryptography',\n    ],\n\n    keywords='asn1 crypto pki x509 certificate rsa dsa ec dh',\n\n    packages=[PACKAGE_NAME],\n    package_data=package_data,\n\n    tests_require=tests_require,\n    test_suite=test_suite,\n\n    cmdclass={\n        'clean': CleanCommand,\n        'egg_info': EggInfoCommand,\n    }\n)\n", "dev/release.py": "# coding: utf-8\nfrom __future__ import unicode_literals, division, absolute_import, print_function\n\nimport subprocess\nimport sys\n\nimport twine.cli\n\nfrom . import package_name, package_root, has_tests_package\nfrom .build import run as build\n\n\ndef run():\n    \"\"\"\n    Creates a sdist .tar.gz and a bdist_wheel --univeral .whl and uploads\n    them to pypi\n\n    :return:\n        A bool - if the packaging and upload process was successful\n    \"\"\"\n\n    git_wc_proc = subprocess.Popen(\n        ['git', 'status', '--porcelain', '-uno'],\n        stdout=subprocess.PIPE,\n        stderr=subprocess.STDOUT,\n        cwd=package_root\n    )\n    git_wc_status, _ = git_wc_proc.communicate()\n\n    if len(git_wc_status) > 0:\n        print(git_wc_status.decode('utf-8').rstrip(), file=sys.stderr)\n        print('Unable to perform release since working copy is not clean', file=sys.stderr)\n        return False\n\n    git_tag_proc = subprocess.Popen(\n        ['git', 'tag', '-l', '--contains', 'HEAD'],\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n        cwd=package_root\n    )\n    tag, tag_error = git_tag_proc.communicate()\n\n    if len(tag_error) > 0:\n        print(tag_error.decode('utf-8').rstrip(), file=sys.stderr)\n        print('Error looking for current git tag', file=sys.stderr)\n        return False\n\n    if len(tag) == 0:\n        print('No git tag found on HEAD', file=sys.stderr)\n        return False\n\n    tag = tag.decode('ascii').strip()\n\n    build()\n\n    twine.cli.dispatch(['upload', 'dist/%s-%s*' % (package_name, tag)])\n    if has_tests_package:\n        twine.cli.dispatch(['upload', 'dist/%s_tests-%s*' % (package_name, tag)])\n\n    return True\n", "dev/deps.py": "# coding: utf-8\nfrom __future__ import unicode_literals, division, absolute_import, print_function\n\nimport os\nimport subprocess\nimport sys\nimport shutil\nimport re\nimport json\nimport tarfile\nimport zipfile\n\nfrom . import package_root, build_root, other_packages\nfrom ._pep425 import _pep425tags, _pep425_implementation\n\nif sys.version_info < (3,):\n    str_cls = unicode  # noqa\nelse:\n    str_cls = str\n\n\ndef run():\n    \"\"\"\n    Installs required development dependencies. Uses git to checkout other\n    modularcrypto repos for more accurate coverage data.\n    \"\"\"\n\n    deps_dir = os.path.join(build_root, 'modularcrypto-deps')\n    if os.path.exists(deps_dir):\n        shutil.rmtree(deps_dir, ignore_errors=True)\n    os.mkdir(deps_dir)\n\n    try:\n        print(\"Staging ci dependencies\")\n        _stage_requirements(deps_dir, os.path.join(package_root, 'requires', 'ci'))\n\n        print(\"Checking out modularcrypto packages for coverage\")\n        for other_package in other_packages:\n            pkg_url = 'https://github.com/wbond/%s.git' % other_package\n            pkg_dir = os.path.join(build_root, other_package)\n            if os.path.exists(pkg_dir):\n                print(\"%s is already present\" % other_package)\n                continue\n            print(\"Cloning %s\" % pkg_url)\n            _execute(['git', 'clone', pkg_url], build_root)\n        print()\n\n    except (Exception):\n        if os.path.exists(deps_dir):\n            shutil.rmtree(deps_dir, ignore_errors=True)\n        raise\n\n    return True\n\n\ndef _download(url, dest):\n    \"\"\"\n    Downloads a URL to a directory\n\n    :param url:\n        The URL to download\n\n    :param dest:\n        The path to the directory to save the file in\n\n    :return:\n        The filesystem path to the saved file\n    \"\"\"\n\n    print('Downloading %s' % url)\n    filename = os.path.basename(url)\n    dest_path = os.path.join(dest, filename)\n\n    if sys.platform == 'win32':\n        powershell_exe = os.path.join('system32\\\\WindowsPowerShell\\\\v1.0\\\\powershell.exe')\n        code = \"[System.Net.ServicePointManager]::SecurityProtocol = [System.Net.SecurityProtocolType]::Tls12;\"\n        code += \"(New-Object Net.WebClient).DownloadFile('%s', '%s');\" % (url, dest_path)\n        _execute([powershell_exe, '-Command', code], dest, 'Unable to connect to')\n\n    else:\n        _execute(\n            ['curl', '-L', '--silent', '--show-error', '-O', url],\n            dest,\n            'Failed to connect to'\n        )\n\n    return dest_path\n\n\ndef _tuple_from_ver(version_string):\n    \"\"\"\n    :param version_string:\n        A unicode dotted version string\n\n    :return:\n        A tuple of integers\n    \"\"\"\n\n    match = re.search(\n        r'(\\d+(?:\\.\\d+)*)'\n        r'([-._]?(?:alpha|a|beta|b|preview|pre|c|rc)\\.?\\d*)?'\n        r'(-\\d+|(?:[-._]?(?:rev|r|post)\\.?\\d*))?'\n        r'([-._]?dev\\.?\\d*)?',\n        version_string\n    )\n    if not match:\n        return tuple()\n\n    nums = tuple(map(int, match.group(1).split('.')))\n\n    pre = match.group(2)\n    if pre:\n        pre = pre.replace('alpha', 'a')\n        pre = pre.replace('beta', 'b')\n        pre = pre.replace('preview', 'rc')\n        pre = pre.replace('pre', 'rc')\n        pre = re.sub(r'(?<!r)c', 'rc', pre)\n        pre = pre.lstrip('._-')\n        pre_dig_match = re.search(r'\\d+', pre)\n        if pre_dig_match:\n            pre_dig = int(pre_dig_match.group(0))\n        else:\n            pre_dig = 0\n        pre = pre.rstrip('0123456789')\n\n        pre_num = {\n            'a': -3,\n            'b': -2,\n            'rc': -1,\n        }[pre]\n\n        pre_tup = (pre_num, pre_dig)\n    else:\n        pre_tup = tuple()\n\n    post = match.group(3)\n    if post:\n        post_dig_match = re.search(r'\\d+', post)\n        if post_dig_match:\n            post_dig = int(post_dig_match.group(0))\n        else:\n            post_dig = 0\n        post_tup = (1, post_dig)\n    else:\n        post_tup = tuple()\n\n    dev = match.group(4)\n    if dev:\n        dev_dig_match = re.search(r'\\d+', dev)\n        if dev_dig_match:\n            dev_dig = int(dev_dig_match.group(0))\n        else:\n            dev_dig = 0\n        dev_tup = (-4, dev_dig)\n    else:\n        dev_tup = tuple()\n\n    normalized = [nums]\n    if pre_tup:\n        normalized.append(pre_tup)\n    if post_tup:\n        normalized.append(post_tup)\n    if dev_tup:\n        normalized.append(dev_tup)\n    # This ensures regular releases happen after dev and prerelease, but\n    # before post releases\n    if not pre_tup and not post_tup and not dev_tup:\n        normalized.append((0, 0))\n\n    return tuple(normalized)\n\n\ndef _open_archive(path):\n    \"\"\"\n    :param path:\n        A unicode string of the filesystem path to the archive\n\n    :return:\n        An archive object\n    \"\"\"\n\n    if path.endswith('.zip'):\n        return zipfile.ZipFile(path, 'r')\n    return tarfile.open(path, 'r')\n\n\ndef _list_archive_members(archive):\n    \"\"\"\n    :param archive:\n        An archive from _open_archive()\n\n    :return:\n        A list of info objects to be used with _info_name() and _extract_info()\n    \"\"\"\n\n    if isinstance(archive, zipfile.ZipFile):\n        return archive.infolist()\n    return archive.getmembers()\n\n\ndef _archive_single_dir(archive):\n    \"\"\"\n    Check if all members of the archive are in a single top-level directory\n\n    :param archive:\n        An archive from _open_archive()\n\n    :return:\n        None if not a single top level directory in archive, otherwise a\n        unicode string of the top level directory name\n    \"\"\"\n\n    common_root = None\n    for info in _list_archive_members(archive):\n        fn = _info_name(info)\n        if fn in set(['.', '/']):\n            continue\n        sep = None\n        if '/' in fn:\n            sep = '/'\n        elif '\\\\' in fn:\n            sep = '\\\\'\n        if sep is None:\n            root_dir = fn\n        else:\n            root_dir, _ = fn.split(sep, 1)\n        if common_root is None:\n            common_root = root_dir\n        else:\n            if common_root != root_dir:\n                return None\n    return common_root\n\n\ndef _info_name(info):\n    \"\"\"\n    Returns a normalized file path for an archive info object\n\n    :param info:\n        An info object from _list_archive_members()\n\n    :return:\n        A unicode string with all directory separators normalized to \"/\"\n    \"\"\"\n\n    if isinstance(info, zipfile.ZipInfo):\n        return info.filename.replace('\\\\', '/')\n    return info.name.replace('\\\\', '/')\n\n\ndef _extract_info(archive, info):\n    \"\"\"\n    Extracts the contents of an archive info object\n\n    ;param archive:\n        An archive from _open_archive()\n\n    :param info:\n        An info object from _list_archive_members()\n\n    :return:\n        None, or a byte string of the file contents\n    \"\"\"\n\n    if isinstance(archive, zipfile.ZipFile):\n        fn = info.filename\n        is_dir = fn.endswith('/') or fn.endswith('\\\\')\n        out = archive.read(info)\n        if is_dir and out == b'':\n            return None\n        return out\n\n    info_file = archive.extractfile(info)\n    if info_file:\n        return info_file.read()\n    return None\n\n\ndef _extract_package(deps_dir, pkg_path, pkg_dir):\n    \"\"\"\n    Extract a .whl, .zip, .tar.gz or .tar.bz2 into a package path to\n    use when running CI tasks\n\n    :param deps_dir:\n        A unicode string of the directory the package should be extracted to\n\n    :param pkg_path:\n        A unicode string of the path to the archive\n\n    :param pkg_dir:\n        If running setup.py, change to this dir first - a unicode string\n    \"\"\"\n\n    if pkg_path.endswith('.exe'):\n        try:\n            zf = None\n            zf = zipfile.ZipFile(pkg_path, 'r')\n            # Exes have a PLATLIB folder containing everything we want\n            for zi in zf.infolist():\n                if not zi.filename.startswith('PLATLIB'):\n                    continue\n                data = _extract_info(zf, zi)\n                if data is not None:\n                    dst_path = os.path.join(deps_dir, zi.filename[8:])\n                    dst_dir = os.path.dirname(dst_path)\n                    if not os.path.exists(dst_dir):\n                        os.makedirs(dst_dir)\n                    with open(dst_path, 'wb') as f:\n                        f.write(data)\n        finally:\n            if zf:\n                zf.close()\n        return\n\n    if pkg_path.endswith('.whl'):\n        try:\n            zf = None\n            zf = zipfile.ZipFile(pkg_path, 'r')\n            # Wheels contain exactly what we need and nothing else\n            zf.extractall(deps_dir)\n        finally:\n            if zf:\n                zf.close()\n        return\n\n    # Source archives may contain a bunch of other things, including multiple\n    # packages, so we must use setup.py/setuptool to install/extract it\n\n    ar = None\n    staging_dir = os.path.join(deps_dir, '_staging')\n    try:\n        ar = _open_archive(pkg_path)\n\n        common_root = _archive_single_dir(ar)\n\n        members = []\n        for info in _list_archive_members(ar):\n            dst_rel_path = _info_name(info)\n            if common_root is not None:\n                dst_rel_path = dst_rel_path[len(common_root) + 1:]\n            members.append((info, dst_rel_path))\n\n        if not os.path.exists(staging_dir):\n            os.makedirs(staging_dir)\n\n        for info, rel_path in members:\n            info_data = _extract_info(ar, info)\n            # Dirs won't return a file\n            if info_data is not None:\n                dst_path = os.path.join(staging_dir, rel_path)\n                dst_dir = os.path.dirname(dst_path)\n                if not os.path.exists(dst_dir):\n                    os.makedirs(dst_dir)\n                with open(dst_path, 'wb') as f:\n                    f.write(info_data)\n\n        setup_dir = staging_dir\n        if pkg_dir:\n            setup_dir = os.path.join(staging_dir, pkg_dir)\n\n        root = os.path.abspath(os.path.join(deps_dir, '..'))\n        install_lib = os.path.basename(deps_dir)\n\n        # Ensure we pick up previously installed packages when running\n        # setup.py. This is important for things like setuptools.\n        env = os.environ.copy()\n        if sys.version_info >= (3,):\n            env['PYTHONPATH'] = deps_dir\n        else:\n            env[b'PYTHONPATH'] = deps_dir.encode('utf-8')\n\n        _execute(\n            [\n                sys.executable,\n                'setup.py',\n                'install',\n                '--root=%s' % root,\n                '--install-lib=%s' % install_lib,\n                '--no-compile'\n            ],\n            setup_dir,\n            env=env\n        )\n\n    finally:\n        if ar:\n            ar.close()\n        if staging_dir:\n            shutil.rmtree(staging_dir)\n\n\ndef _sort_pep440_versions(releases, include_prerelease):\n    \"\"\"\n    :param releases:\n        A list of unicode string PEP 440 version numbers\n\n    :param include_prerelease:\n        A boolean indicating if prerelease versions should be included\n\n    :return:\n        A sorted generator of 2-element tuples:\n         0: A unicode string containing a PEP 440 version number\n         1: A tuple of tuples containing integers - this is the output of\n            _tuple_from_ver() for the PEP 440 version number and is intended\n            for comparing versions\n    \"\"\"\n\n    parsed_versions = []\n    for v in releases:\n        t = _tuple_from_ver(v)\n        if not include_prerelease and t[1][0] < 0:\n            continue\n        parsed_versions.append((v, t))\n\n    return sorted(parsed_versions, key=lambda v: v[1])\n\n\ndef _is_valid_python_version(python_version, requires_python):\n    \"\"\"\n    Verifies the \"python_version\" and \"requires_python\" keys from a PyPi\n    download record are applicable to the current version of Python\n\n    :param python_version:\n        The \"python_version\" value from a PyPi download JSON structure. This\n        should be one of: \"py2\", \"py3\", \"py2.py3\" or \"source\".\n\n    :param requires_python:\n        The \"requires_python\" value from a PyPi download JSON structure. This\n        will be None, or a comma-separated list of conditions that must be\n        true. Ex: \">=3.5\", \"!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*,>=2.7\"\n    \"\"\"\n\n    if python_version == \"py2\" and sys.version_info >= (3,):\n        return False\n    if python_version == \"py3\" and sys.version_info < (3,):\n        return False\n\n    if requires_python is not None:\n\n        def _ver_tuples(ver_str):\n            ver_str = ver_str.strip()\n            if ver_str.endswith('.*'):\n                ver_str = ver_str[:-2]\n            cond_tup = tuple(map(int, ver_str.split('.')))\n            return (sys.version_info[:len(cond_tup)], cond_tup)\n\n        for part in map(str_cls.strip, requires_python.split(',')):\n            if part.startswith('!='):\n                sys_tup, cond_tup = _ver_tuples(part[2:])\n                if sys_tup == cond_tup:\n                    return False\n            elif part.startswith('>='):\n                sys_tup, cond_tup = _ver_tuples(part[2:])\n                if sys_tup < cond_tup:\n                    return False\n            elif part.startswith('>'):\n                sys_tup, cond_tup = _ver_tuples(part[1:])\n                if sys_tup <= cond_tup:\n                    return False\n            elif part.startswith('<='):\n                sys_tup, cond_tup = _ver_tuples(part[2:])\n                if sys_tup > cond_tup:\n                    return False\n            elif part.startswith('<'):\n                sys_tup, cond_tup = _ver_tuples(part[1:])\n                if sys_tup >= cond_tup:\n                    return False\n            elif part.startswith('=='):\n                sys_tup, cond_tup = _ver_tuples(part[2:])\n                if sys_tup != cond_tup:\n                    return False\n\n    return True\n\n\ndef _locate_suitable_download(downloads):\n    \"\"\"\n    :param downloads:\n        A list of dicts containing a key \"url\", \"python_version\" and\n        \"requires_python\"\n\n    :return:\n        A unicode string URL, or None if not a valid release for the current\n        version of Python\n    \"\"\"\n\n    valid_tags = _pep425tags()\n\n    exe_suffix = None\n    if sys.platform == 'win32' and _pep425_implementation() == 'cp':\n        win_arch = 'win32' if sys.maxsize == 2147483647 else 'win-amd64'\n        version_info = sys.version_info\n        exe_suffix = '.%s-py%d.%d.exe' % (win_arch, version_info[0], version_info[1])\n\n    wheels = {}\n    whl = None\n    tar_bz2 = None\n    tar_gz = None\n    exe = None\n    for download in downloads:\n        if not _is_valid_python_version(download.get('python_version'), download.get('requires_python')):\n            continue\n\n        if exe_suffix and download['url'].endswith(exe_suffix):\n            exe = download['url']\n        if download['url'].endswith('.whl'):\n            parts = os.path.basename(download['url']).split('-')\n            tag_impl = parts[-3]\n            tag_abi = parts[-2]\n            tag_arch = parts[-1].split('.')[0]\n            wheels[(tag_impl, tag_abi, tag_arch)] = download['url']\n        if download['url'].endswith('.tar.bz2'):\n            tar_bz2 = download['url']\n        if download['url'].endswith('.tar.gz'):\n            tar_gz = download['url']\n\n    # Find the most-specific wheel possible\n    for tag in valid_tags:\n        if tag in wheels:\n            whl = wheels[tag]\n            break\n\n    if exe_suffix and exe:\n        url = exe\n    elif whl:\n        url = whl\n    elif tar_bz2:\n        url = tar_bz2\n    elif tar_gz:\n        url = tar_gz\n    else:\n        return None\n\n    return url\n\n\ndef _stage_requirements(deps_dir, path):\n    \"\"\"\n    Installs requirements without using Python to download, since\n    different services are limiting to TLS 1.2, and older version of\n    Python do not support that\n\n    :param deps_dir:\n        A unicode path to a temporary directory to use for downloads\n\n    :param path:\n        A unicode filesystem path to a requirements file\n    \"\"\"\n\n    packages = _parse_requires(path)\n    for p in packages:\n        url = None\n        pkg = p['pkg']\n        pkg_sub_dir = None\n        if p['type'] == 'url':\n            anchor = None\n            if '#' in pkg:\n                pkg, anchor = pkg.split('#', 1)\n                if '&' in anchor:\n                    parts = anchor.split('&')\n                else:\n                    parts = [anchor]\n                for part in parts:\n                    param, value = part.split('=')\n                    if param == 'subdirectory':\n                        pkg_sub_dir = value\n\n            if pkg.endswith('.zip') or pkg.endswith('.tar.gz') or pkg.endswith('.tar.bz2') or pkg.endswith('.whl'):\n                url = pkg\n            else:\n                raise Exception('Unable to install package from URL that is not an archive')\n        else:\n            pypi_json_url = 'https://pypi.org/pypi/%s/json' % pkg\n            json_dest = _download(pypi_json_url, deps_dir)\n            with open(json_dest, 'rb') as f:\n                pkg_info = json.loads(f.read().decode('utf-8'))\n            if os.path.exists(json_dest):\n                os.remove(json_dest)\n\n            if p['type'] == '==':\n                if p['ver'] not in pkg_info['releases']:\n                    raise Exception('Unable to find version %s of %s' % (p['ver'], pkg))\n                url = _locate_suitable_download(pkg_info['releases'][p['ver']])\n                if not url:\n                    raise Exception('Unable to find a compatible download of %s == %s' % (pkg, p['ver']))\n            else:\n                p_ver_tup = _tuple_from_ver(p['ver'])\n                for ver_str, ver_tup in reversed(_sort_pep440_versions(pkg_info['releases'], False)):\n                    if p['type'] == '>=' and ver_tup < p_ver_tup:\n                        break\n                    url = _locate_suitable_download(pkg_info['releases'][ver_str])\n                    if url:\n                        break\n                if not url:\n                    if p['type'] == '>=':\n                        raise Exception('Unable to find a compatible download of %s >= %s' % (pkg, p['ver']))\n                    else:\n                        raise Exception('Unable to find a compatible download of %s' % pkg)\n\n        local_path = _download(url, deps_dir)\n\n        _extract_package(deps_dir, local_path, pkg_sub_dir)\n\n        os.remove(local_path)\n\n\ndef _parse_requires(path):\n    \"\"\"\n    Does basic parsing of pip requirements files, to allow for\n    using something other than Python to do actual TLS requests\n\n    :param path:\n        A path to a requirements file\n\n    :return:\n        A list of dict objects containing the keys:\n         - 'type' ('any', 'url', '==', '>=')\n         - 'pkg'\n         - 'ver' (if 'type' == '==' or 'type' == '>=')\n    \"\"\"\n\n    python_version = '.'.join(map(str_cls, sys.version_info[0:2]))\n    sys_platform = sys.platform\n\n    packages = []\n\n    with open(path, 'rb') as f:\n        contents = f.read().decode('utf-8')\n\n    for line in re.split(r'\\r?\\n', contents):\n        line = line.strip()\n        if not len(line):\n            continue\n        if re.match(r'^\\s*#', line):\n            continue\n        if ';' in line:\n            package, cond = line.split(';', 1)\n            package = package.strip()\n            cond = cond.strip()\n            cond = cond.replace('sys_platform', repr(sys_platform))\n            cond = re.sub(\n                r'[\\'\"]'\n                r'(\\d+(?:\\.\\d+)*)'\n                r'([-._]?(?:alpha|a|beta|b|preview|pre|c|rc)\\.?\\d*)?'\n                r'(-\\d+|(?:[-._]?(?:rev|r|post)\\.?\\d*))?'\n                r'([-._]?dev\\.?\\d*)?'\n                r'[\\'\"]',\n                r'_tuple_from_ver(\\g<0>)',\n                cond\n            )\n            cond = cond.replace('python_version', '_tuple_from_ver(%r)' % python_version)\n            if not eval(cond):\n                continue\n        else:\n            package = line.strip()\n\n        if re.match(r'^\\s*-r\\s*', package):\n            sub_req_file = re.sub(r'^\\s*-r\\s*', '', package)\n            sub_req_file = os.path.abspath(os.path.join(os.path.dirname(path), sub_req_file))\n            packages.extend(_parse_requires(sub_req_file))\n            continue\n\n        if re.match(r'https?://', package):\n            packages.append({'type': 'url', 'pkg': package})\n            continue\n\n        if '>=' in package:\n            parts = package.split('>=')\n            package = parts[0].strip()\n            ver = parts[1].strip()\n            packages.append({'type': '>=', 'pkg': package, 'ver': ver})\n            continue\n\n        if '==' in package:\n            parts = package.split('==')\n            package = parts[0].strip()\n            ver = parts[1].strip()\n            packages.append({'type': '==', 'pkg': package, 'ver': ver})\n            continue\n\n        if re.search(r'[^ a-zA-Z0-9\\-]', package):\n            raise Exception('Unsupported requirements format version constraint: %s' % package)\n\n        packages.append({'type': 'any', 'pkg': package})\n\n    return packages\n\n\ndef _execute(params, cwd, retry=None, env=None):\n    \"\"\"\n    Executes a subprocess\n\n    :param params:\n        A list of the executable and arguments to pass to it\n\n    :param cwd:\n        The working directory to execute the command in\n\n    :param retry:\n        If this string is present in stderr, retry the operation\n\n    :return:\n        A 2-element tuple of (stdout, stderr)\n    \"\"\"\n\n    proc = subprocess.Popen(\n        params,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n        cwd=cwd,\n        env=env\n    )\n    stdout, stderr = proc.communicate()\n    code = proc.wait()\n    if code != 0:\n        if retry and retry in stderr.decode('utf-8'):\n            return _execute(params, cwd)\n        e = OSError('subprocess exit code for \"%s\" was %d: %s' % (' '.join(params), code, stderr))\n        e.stdout = stdout\n        e.stderr = stderr\n        raise e\n    return (stdout, stderr)\n", "dev/ci-driver.py": "# coding: utf-8\nfrom __future__ import unicode_literals, division, absolute_import, print_function\n\nimport os\nimport platform\nimport sys\nimport subprocess\n\n\nrun_args = [\n    {\n        'name': 'cffi',\n        'kwarg': 'cffi',\n    },\n    {\n        'name': 'openssl',\n        'kwarg': 'openssl',\n    },\n    {\n        'name': 'winlegacy',\n        'kwarg': 'winlegacy',\n    },\n]\n\n\ndef _write_env(env, key, value):\n    sys.stdout.write(\"%s: %s\\n\" % (key, value))\n    sys.stdout.flush()\n    if sys.version_info < (3,):\n        env[key.encode('utf-8')] = value.encode('utf-8')\n    else:\n        env[key] = value\n\n\ndef run(**_):\n    \"\"\"\n    Runs CI, setting various env vars\n\n    :return:\n        A bool - if the CI ran successfully\n    \"\"\"\n\n    env = os.environ.copy()\n    options = set(sys.argv[2:])\n\n    newline = False\n    if 'cffi' not in options:\n        _write_env(env, 'OSCRYPTO_USE_CTYPES', 'true')\n        newline = True\n    if 'openssl' in options and sys.platform == 'darwin':\n        mac_version_info = tuple(map(int, platform.mac_ver()[0].split('.')[:2]))\n        if mac_version_info < (10, 15):\n            _write_env(env, 'OSCRYPTO_USE_OPENSSL', '/usr/lib/libcrypto.dylib,/usr/lib/libssl.dylib')\n        else:\n            _write_env(env, 'OSCRYPTO_USE_OPENSSL', '/usr/lib/libcrypto.35.dylib,/usr/lib/libssl.35.dylib')\n        newline = True\n    if 'openssl3' in options and sys.platform == 'darwin':\n        _write_env(\n            env,\n            'OSCRYPTO_USE_OPENSSL',\n            '/usr/local/opt/openssl@3/lib/libcrypto.dylib,/usr/local/opt/openssl@3/lib/libssl.dylib'\n        )\n    if 'winlegacy' in options:\n        _write_env(env, 'OSCRYPTO_USE_WINLEGACY', 'true')\n        newline = True\n\n    if newline:\n        sys.stdout.write(\"\\n\")\n\n    proc = subprocess.Popen(\n        [\n            sys.executable,\n            'run.py',\n            'ci',\n        ],\n        env=env\n    )\n    proc.communicate()\n    return proc.returncode == 0\n", "dev/_task.py": "# coding: utf-8\nfrom __future__ import unicode_literals, division, absolute_import, print_function\n\nimport ast\nimport _ast\nimport os\nimport sys\n\nfrom . import package_root, task_keyword_args\nfrom ._import import _import_from\n\n\nif sys.version_info < (3,):\n    byte_cls = str\nelse:\n    byte_cls = bytes\n\n\ndef _list_tasks():\n    \"\"\"\n    Fetches a list of all valid tasks that may be run, and the args they\n    accept. Does not actually import the task module to prevent errors if a\n    user does not have the dependencies installed for every task.\n\n    :return:\n        A list of 2-element tuples:\n         0: a unicode string of the task name\n         1: a list of dicts containing the parameter definitions\n    \"\"\"\n\n    out = []\n    dev_path = os.path.join(package_root, 'dev')\n    for fname in sorted(os.listdir(dev_path)):\n        if fname.startswith('.') or fname.startswith('_'):\n            continue\n        if not fname.endswith('.py'):\n            continue\n        name = fname[:-3]\n        args = ()\n\n        full_path = os.path.join(package_root, 'dev', fname)\n        with open(full_path, 'rb') as f:\n            full_code = f.read()\n            if sys.version_info >= (3,):\n                full_code = full_code.decode('utf-8')\n\n        task_node = ast.parse(full_code, filename=full_path)\n        for node in ast.iter_child_nodes(task_node):\n            if isinstance(node, _ast.Assign):\n                if len(node.targets) == 1 \\\n                        and isinstance(node.targets[0], _ast.Name) \\\n                        and node.targets[0].id == 'run_args':\n                    args = ast.literal_eval(node.value)\n                    break\n\n        out.append((name, args))\n    return out\n\n\ndef show_usage():\n    \"\"\"\n    Prints to stderr the valid options for invoking tasks\n    \"\"\"\n\n    valid_tasks = []\n    for task in _list_tasks():\n        usage = task[0]\n        for run_arg in task[1]:\n            usage += ' '\n            name = run_arg.get('name', '')\n            if run_arg.get('required', False):\n                usage += '{%s}' % name\n            else:\n                usage += '[%s]' % name\n        valid_tasks.append(usage)\n\n    out = 'Usage: run.py'\n    for karg in task_keyword_args:\n        out += ' [%s=%s]' % (karg['name'], karg['placeholder'])\n    out += ' (%s)' % ' | '.join(valid_tasks)\n\n    print(out, file=sys.stderr)\n    sys.exit(1)\n\n\ndef _get_arg(num):\n    \"\"\"\n    :return:\n        A unicode string of the requested command line arg\n    \"\"\"\n\n    if len(sys.argv) < num + 1:\n        return None\n    arg = sys.argv[num]\n    if isinstance(arg, byte_cls):\n        arg = arg.decode('utf-8')\n    return arg\n\n\ndef run_task():\n    \"\"\"\n    Parses the command line args, invoking the requested task\n    \"\"\"\n\n    arg_num = 1\n    task = None\n    args = []\n    kwargs = {}\n\n    # We look for the task name, processing any global task keyword args\n    # by setting the appropriate env var\n    while True:\n        val = _get_arg(arg_num)\n        if val is None:\n            break\n\n        next_arg = False\n        for karg in task_keyword_args:\n            if val.startswith(karg['name'] + '='):\n                os.environ[karg['env_var']] = val[len(karg['name']) + 1:]\n                next_arg = True\n                break\n\n        if next_arg:\n            arg_num += 1\n            continue\n\n        task = val\n        break\n\n    if task is None:\n        show_usage()\n\n    task_mod = _import_from('dev.%s' % task, package_root, allow_error=True)\n    if task_mod is None:\n        show_usage()\n\n    run_args = task_mod.__dict__.get('run_args', [])\n    max_args = arg_num + 1 + len(run_args)\n\n    if len(sys.argv) > max_args:\n        show_usage()\n\n    for i, run_arg in enumerate(run_args):\n        val = _get_arg(arg_num + 1 + i)\n        if val is None:\n            if run_arg.get('required', False):\n                show_usage()\n            break\n\n        if run_arg.get('cast') == 'int' and val.isdigit():\n            val = int(val)\n\n        kwarg = run_arg.get('kwarg')\n        if kwarg:\n            kwargs[kwarg] = val\n        else:\n            args.append(val)\n\n    run = task_mod.__dict__.get('run')\n\n    result = run(*args, **kwargs)\n    sys.exit(int(not result))\n", "dev/coverage.py": "# coding: utf-8\nfrom __future__ import unicode_literals, division, absolute_import, print_function\n\nimport cgi\nimport codecs\nimport coverage\nimport json\nimport os\nimport unittest\nimport re\nimport sys\nimport tempfile\nimport time\nimport platform as _plat\nimport subprocess\nfrom fnmatch import fnmatch\n\nfrom . import package_name, package_root, other_packages\nfrom ._import import _import_from\n\nif sys.version_info < (3,):\n    str_cls = unicode  # noqa\n    from urllib2 import URLError\n    from urllib import urlencode\n    from io import open\nelse:\n    str_cls = str\n    from urllib.error import URLError\n    from urllib.parse import urlencode\n\nif sys.version_info < (3, 7):\n    Pattern = re._pattern_type\nelse:\n    Pattern = re.Pattern\n\n\ndef run(ci=False):\n    \"\"\"\n    Runs the tests while measuring coverage\n\n    :param ci:\n        If coverage is being run in a CI environment - this triggers trying to\n        run the tests for the rest of modularcrypto and uploading coverage data\n\n    :return:\n        A bool - if the tests ran successfully\n    \"\"\"\n\n    xml_report_path = os.path.join(package_root, 'coverage.xml')\n    if os.path.exists(xml_report_path):\n        os.unlink(xml_report_path)\n\n    cov = coverage.Coverage(include='%s/*.py' % package_name)\n    cov.start()\n\n    from .tests import run as run_tests\n    result = run_tests(ci=ci)\n    print()\n\n    if ci:\n        suite = unittest.TestSuite()\n        loader = unittest.TestLoader()\n        for other_package in other_packages:\n            for test_class in _load_package_tests(other_package):\n                suite.addTest(loader.loadTestsFromTestCase(test_class))\n\n        if suite.countTestCases() > 0:\n            print('Running tests from other modularcrypto packages')\n            sys.stdout.flush()\n            runner_result = unittest.TextTestRunner(stream=sys.stdout, verbosity=1).run(suite)\n            result = runner_result.wasSuccessful() and result\n            print()\n            sys.stdout.flush()\n\n    cov.stop()\n    cov.save()\n\n    cov.report(show_missing=False)\n    print()\n    sys.stdout.flush()\n    if ci:\n        cov.xml_report()\n\n    if ci and result and os.path.exists(xml_report_path):\n        _codecov_submit()\n        print()\n\n    return result\n\n\ndef _load_package_tests(name):\n    \"\"\"\n    Load the test classes from another modularcrypto package\n\n    :param name:\n        A unicode string of the other package name\n\n    :return:\n        A list of unittest.TestCase classes of the tests for the package\n    \"\"\"\n\n    package_dir = os.path.join('..', name)\n    if not os.path.exists(package_dir):\n        return []\n\n    return _import_from('%s_tests' % name, package_dir, 'tests').test_classes()\n\n\ndef _env_info():\n    \"\"\"\n    :return:\n        A two-element tuple of unicode strings. The first is the name of the\n        environment, the second the root of the repo. The environment name\n        will be one of: \"ci-travis\", \"ci-circle\", \"ci-appveyor\",\n        \"ci-github-actions\", \"local\"\n    \"\"\"\n\n    if os.getenv('CI') == 'true' and os.getenv('TRAVIS') == 'true':\n        return ('ci-travis', os.getenv('TRAVIS_BUILD_DIR'))\n\n    if os.getenv('CI') == 'True' and os.getenv('APPVEYOR') == 'True':\n        return ('ci-appveyor', os.getenv('APPVEYOR_BUILD_FOLDER'))\n\n    if os.getenv('CI') == 'true' and os.getenv('CIRCLECI') == 'true':\n        return ('ci-circle', os.getcwdu() if sys.version_info < (3,) else os.getcwd())\n\n    if os.getenv('GITHUB_ACTIONS') == 'true':\n        return ('ci-github-actions', os.getenv('GITHUB_WORKSPACE'))\n\n    return ('local', package_root)\n\n\ndef _codecov_submit():\n    env_name, root = _env_info()\n\n    try:\n        with open(os.path.join(root, 'dev/codecov.json'), 'rb') as f:\n            json_data = json.loads(f.read().decode('utf-8'))\n    except (OSError, ValueError, UnicodeDecodeError, KeyError):\n        print('error reading codecov.json')\n        return\n\n    if json_data.get('disabled'):\n        return\n\n    if env_name == 'ci-travis':\n        # http://docs.travis-ci.com/user/environment-variables/#Default-Environment-Variables\n        build_url = 'https://travis-ci.org/%s/jobs/%s' % (os.getenv('TRAVIS_REPO_SLUG'), os.getenv('TRAVIS_JOB_ID'))\n        query = {\n            'service': 'travis',\n            'branch': os.getenv('TRAVIS_BRANCH'),\n            'build': os.getenv('TRAVIS_JOB_NUMBER'),\n            'pr': os.getenv('TRAVIS_PULL_REQUEST'),\n            'job': os.getenv('TRAVIS_JOB_ID'),\n            'tag': os.getenv('TRAVIS_TAG'),\n            'slug': os.getenv('TRAVIS_REPO_SLUG'),\n            'commit': os.getenv('TRAVIS_COMMIT'),\n            'build_url': build_url,\n        }\n\n    elif env_name == 'ci-appveyor':\n        # http://www.appveyor.com/docs/environment-variables\n        build_url = 'https://ci.appveyor.com/project/%s/build/%s' % (\n            os.getenv('APPVEYOR_REPO_NAME'),\n            os.getenv('APPVEYOR_BUILD_VERSION')\n        )\n        query = {\n            'service': \"appveyor\",\n            'branch': os.getenv('APPVEYOR_REPO_BRANCH'),\n            'build': os.getenv('APPVEYOR_JOB_ID'),\n            'pr': os.getenv('APPVEYOR_PULL_REQUEST_NUMBER'),\n            'job': '/'.join((\n                os.getenv('APPVEYOR_ACCOUNT_NAME'),\n                os.getenv('APPVEYOR_PROJECT_SLUG'),\n                os.getenv('APPVEYOR_BUILD_VERSION')\n            )),\n            'tag': os.getenv('APPVEYOR_REPO_TAG_NAME'),\n            'slug': os.getenv('APPVEYOR_REPO_NAME'),\n            'commit': os.getenv('APPVEYOR_REPO_COMMIT'),\n            'build_url': build_url,\n        }\n\n    elif env_name == 'ci-circle':\n        # https://circleci.com/docs/environment-variables\n        query = {\n            'service': 'circleci',\n            'branch': os.getenv('CIRCLE_BRANCH'),\n            'build': os.getenv('CIRCLE_BUILD_NUM'),\n            'pr': os.getenv('CIRCLE_PR_NUMBER'),\n            'job': os.getenv('CIRCLE_BUILD_NUM') + \".\" + os.getenv('CIRCLE_NODE_INDEX'),\n            'tag': os.getenv('CIRCLE_TAG'),\n            'slug': os.getenv('CIRCLE_PROJECT_USERNAME') + \"/\" + os.getenv('CIRCLE_PROJECT_REPONAME'),\n            'commit': os.getenv('CIRCLE_SHA1'),\n            'build_url': os.getenv('CIRCLE_BUILD_URL'),\n        }\n\n    elif env_name == 'ci-github-actions':\n        branch = ''\n        tag = ''\n        ref = os.getenv('GITHUB_REF', '')\n        if ref.startswith('refs/tags/'):\n            tag = ref[10:]\n        elif ref.startswith('refs/heads/'):\n            branch = ref[11:]\n\n        impl = _plat.python_implementation()\n        major, minor = _plat.python_version_tuple()[0:2]\n        build_name = '%s %s %s.%s' % (_platform_name(), impl, major, minor)\n\n        query = {\n            'service': 'custom',\n            'token': json_data['token'],\n            'branch': branch,\n            'tag': tag,\n            'slug': os.getenv('GITHUB_REPOSITORY'),\n            'commit': os.getenv('GITHUB_SHA'),\n            'build_url': 'https://github.com/wbond/oscrypto/commit/%s/checks' % os.getenv('GITHUB_SHA'),\n            'name': 'GitHub Actions %s on %s' % (build_name, os.getenv('RUNNER_OS'))\n        }\n\n    else:\n        if not os.path.exists(os.path.join(root, '.git')):\n            print('git repository not found, not submitting coverage data')\n            return\n        git_status = _git_command(['status', '--porcelain'], root)\n        if git_status != '':\n            print('git repository has uncommitted changes, not submitting coverage data')\n            return\n\n        branch = _git_command(['rev-parse', '--abbrev-ref', 'HEAD'], root)\n        commit = _git_command(['rev-parse', '--verify', 'HEAD'], root)\n        tag = _git_command(['name-rev', '--tags', '--name-only', commit], root)\n        impl = _plat.python_implementation()\n        major, minor = _plat.python_version_tuple()[0:2]\n        build_name = '%s %s %s.%s' % (_platform_name(), impl, major, minor)\n        query = {\n            'branch': branch,\n            'commit': commit,\n            'slug': json_data['slug'],\n            'token': json_data['token'],\n            'build': build_name,\n        }\n        if tag != 'undefined':\n            query['tag'] = tag\n\n    payload = 'PLATFORM=%s\\n' % _platform_name()\n    payload += 'PYTHON_VERSION=%s %s\\n' % (_plat.python_version(), _plat.python_implementation())\n    if 'oscrypto' in sys.modules:\n        payload += 'OSCRYPTO_BACKEND=%s\\n' % sys.modules['oscrypto'].backend()\n    payload += '<<<<<< ENV\\n'\n\n    for path in _list_files(root):\n        payload += path + '\\n'\n    payload += '<<<<<< network\\n'\n\n    payload += '# path=coverage.xml\\n'\n    with open(os.path.join(root, 'coverage.xml'), 'r', encoding='utf-8') as f:\n        payload += f.read() + '\\n'\n    payload += '<<<<<< EOF\\n'\n\n    url = 'https://codecov.io/upload/v4'\n    headers = {\n        'Accept': 'text/plain'\n    }\n    filtered_query = {}\n    for key in query:\n        value = query[key]\n        if value == '' or value is None:\n            continue\n        filtered_query[key] = value\n\n    print('Submitting coverage info to codecov.io')\n    info = _do_request(\n        'POST',\n        url,\n        headers,\n        query_params=filtered_query\n    )\n\n    encoding = info[1] or 'utf-8'\n    text = info[2].decode(encoding).strip()\n    parts = text.split()\n    upload_url = parts[1]\n\n    headers = {\n        'Content-Type': 'text/plain',\n        'x-amz-acl': 'public-read',\n        'x-amz-storage-class': 'REDUCED_REDUNDANCY'\n    }\n\n    print('Uploading coverage data to codecov.io S3 bucket')\n    _do_request(\n        'PUT',\n        upload_url,\n        headers,\n        data=payload.encode('utf-8')\n    )\n\n\ndef _git_command(params, cwd):\n    \"\"\"\n    Executes a git command, returning the output\n\n    :param params:\n        A list of the parameters to pass to git\n\n    :param cwd:\n        The working directory to execute git in\n\n    :return:\n        A 2-element tuple of (stdout, stderr)\n    \"\"\"\n\n    proc = subprocess.Popen(\n        ['git'] + params,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.STDOUT,\n        cwd=cwd\n    )\n    stdout, stderr = proc.communicate()\n    code = proc.wait()\n    if code != 0:\n        e = OSError('git exit code was non-zero')\n        e.stdout = stdout\n        raise e\n    return stdout.decode('utf-8').strip()\n\n\ndef _parse_env_var_file(data):\n    \"\"\"\n    Parses a basic VAR=\"value data\" file contents into a dict\n\n    :param data:\n        A unicode string of the file data\n\n    :return:\n        A dict of parsed name/value data\n    \"\"\"\n\n    output = {}\n    for line in data.splitlines():\n        line = line.strip()\n        if not line or '=' not in line:\n            continue\n        parts = line.split('=')\n        if len(parts) != 2:\n            continue\n        name = parts[0]\n        value = parts[1]\n        if len(value) > 1:\n            if value[0] == '\"' and value[-1] == '\"':\n                value = value[1:-1]\n        output[name] = value\n    return output\n\n\ndef _platform_name():\n    \"\"\"\n    Returns information about the current operating system and version\n\n    :return:\n        A unicode string containing the OS name and version\n    \"\"\"\n\n    if sys.platform == 'darwin':\n        version = _plat.mac_ver()[0]\n        _plat_ver_info = tuple(map(int, version.split('.')))\n        if _plat_ver_info < (10, 12):\n            name = 'OS X'\n        else:\n            name = 'macOS'\n        return '%s %s' % (name, version)\n\n    elif sys.platform == 'win32':\n        _win_ver = sys.getwindowsversion()\n        _plat_ver_info = (_win_ver[0], _win_ver[1])\n        return 'Windows %s' % _plat.win32_ver()[0]\n\n    elif sys.platform in ['linux', 'linux2']:\n        if os.path.exists('/etc/os-release'):\n            with open('/etc/os-release', 'r', encoding='utf-8') as f:\n                pairs = _parse_env_var_file(f.read())\n                if 'NAME' in pairs and 'VERSION_ID' in pairs:\n                    return '%s %s' % (pairs['NAME'], pairs['VERSION_ID'])\n                    version = pairs['VERSION_ID']\n                elif 'PRETTY_NAME' in pairs:\n                    return pairs['PRETTY_NAME']\n                elif 'NAME' in pairs:\n                    return pairs['NAME']\n                else:\n                    raise ValueError('No suitable version info found in /etc/os-release')\n        elif os.path.exists('/etc/lsb-release'):\n            with open('/etc/lsb-release', 'r', encoding='utf-8') as f:\n                pairs = _parse_env_var_file(f.read())\n                if 'DISTRIB_DESCRIPTION' in pairs:\n                    return pairs['DISTRIB_DESCRIPTION']\n                else:\n                    raise ValueError('No suitable version info found in /etc/lsb-release')\n        else:\n            return 'Linux'\n\n    else:\n        return '%s %s' % (_plat.system(), _plat.release())\n\n\ndef _list_files(root):\n    \"\"\"\n    Lists all of the files in a directory, taking into account any .gitignore\n    file that is present\n\n    :param root:\n        A unicode filesystem path\n\n    :return:\n        A list of unicode strings, containing paths of all files not ignored\n        by .gitignore with root, using relative paths\n    \"\"\"\n\n    dir_patterns, file_patterns = _gitignore(root)\n    paths = []\n    prefix = os.path.abspath(root) + os.sep\n    for base, dirs, files in os.walk(root):\n        for d in dirs:\n            for dir_pattern in dir_patterns:\n                if fnmatch(d, dir_pattern):\n                    dirs.remove(d)\n                    break\n        for f in files:\n            skip = False\n            for file_pattern in file_patterns:\n                if fnmatch(f, file_pattern):\n                    skip = True\n                    break\n            if skip:\n                continue\n            full_path = os.path.join(base, f)\n            if full_path[:len(prefix)] == prefix:\n                full_path = full_path[len(prefix):]\n            paths.append(full_path)\n    return sorted(paths)\n\n\ndef _gitignore(root):\n    \"\"\"\n    Parses a .gitignore file and returns patterns to match dirs and files.\n    Only basic gitignore patterns are supported. Pattern negation, ** wildcards\n    and anchored patterns are not currently implemented.\n\n    :param root:\n        A unicode string of the path to the git repository\n\n    :return:\n        A 2-element tuple:\n         - 0: a list of unicode strings to match against dirs\n         - 1: a list of unicode strings to match against dirs and files\n    \"\"\"\n\n    gitignore_path = os.path.join(root, '.gitignore')\n\n    dir_patterns = ['.git']\n    file_patterns = []\n\n    if not os.path.exists(gitignore_path):\n        return (dir_patterns, file_patterns)\n\n    with open(gitignore_path, 'r', encoding='utf-8') as f:\n        for line in f.readlines():\n            line = line.strip()\n            if not line:\n                continue\n            if line.startswith('#'):\n                continue\n            if '**' in line:\n                raise NotImplementedError('gitignore ** wildcards are not implemented')\n            if line.startswith('!'):\n                raise NotImplementedError('gitignore pattern negation is not implemented')\n            if line.startswith('/'):\n                raise NotImplementedError('gitignore anchored patterns are not implemented')\n            if line.startswith('\\\\#'):\n                line = '#' + line[2:]\n            if line.startswith('\\\\!'):\n                line = '!' + line[2:]\n            if line.endswith('/'):\n                dir_patterns.append(line[:-1])\n            else:\n                file_patterns.append(line)\n\n    return (dir_patterns, file_patterns)\n\n\ndef _do_request(method, url, headers, data=None, query_params=None, timeout=20):\n    \"\"\"\n    Performs an HTTP request\n\n    :param method:\n        A unicode string of 'POST' or 'PUT'\n\n    :param url;\n        A unicode string of the URL to request\n\n    :param headers:\n        A dict of unicode strings, where keys are header names and values are\n        the header values.\n\n    :param data:\n        A dict of unicode strings (to be encoded as\n        application/x-www-form-urlencoded), or a byte string of data.\n\n    :param query_params:\n        A dict of unicode keys and values to pass as query params\n\n    :param timeout:\n        An integer number of seconds to use as the timeout\n\n    :return:\n        A 3-element tuple:\n         - 0: A unicode string of the response content-type\n         - 1: A unicode string of the response encoding, or None\n         - 2: A byte string of the response body\n    \"\"\"\n\n    if query_params:\n        url += '?' + urlencode(query_params).replace('+', '%20')\n\n    if isinstance(data, dict):\n        data_bytes = {}\n        for key in data:\n            data_bytes[key.encode('utf-8')] = data[key].encode('utf-8')\n        data = urlencode(data_bytes)\n        headers['Content-Type'] = 'application/x-www-form-urlencoded'\n    if isinstance(data, str_cls):\n        raise TypeError('data must be a byte string')\n\n    try:\n        tempfd, tempf_path = tempfile.mkstemp('-coverage')\n        os.write(tempfd, data or b'')\n        os.close(tempfd)\n\n        if sys.platform == 'win32':\n            powershell_exe = os.path.join('system32\\\\WindowsPowerShell\\\\v1.0\\\\powershell.exe')\n            code = \"[System.Net.ServicePointManager]::SecurityProtocol = [System.Net.SecurityProtocolType]::Tls12;\"\n            code += \"$wc = New-Object Net.WebClient;\"\n            for key in headers:\n                code += \"$wc.Headers.add('%s','%s');\" % (key, headers[key])\n            code += \"$out = $wc.UploadFile('%s', '%s', '%s');\" % (url, method, tempf_path)\n            code += \"[System.Text.Encoding]::GetEncoding('ISO-8859-1').GetString($wc.ResponseHeaders.ToByteArray())\"\n\n            # To properly obtain bytes, we use BitConverter to get hex dash\n            # encoding (e.g. AE-09-3F) and they decode in python\n            code += \" + [System.BitConverter]::ToString($out);\"\n            stdout, stderr = _execute(\n                [powershell_exe, '-Command', code],\n                os.getcwd(),\n                re.compile(r'Unable to connect to|TLS|Internal Server Error'),\n                6\n            )\n            if stdout[-2:] == b'\\r\\n' and b'\\r\\n\\r\\n' in stdout:\n                # An extra trailing crlf is added at the end by powershell\n                stdout = stdout[0:-2]\n                parts = stdout.split(b'\\r\\n\\r\\n', 1)\n                if len(parts) == 2:\n                    stdout = parts[0] + b'\\r\\n\\r\\n' + codecs.decode(parts[1].replace(b'-', b''), 'hex_codec')\n\n        else:\n            args = [\n                'curl',\n                '--http1.1',\n                '--connect-timeout', '5',\n                '--request',\n                method,\n                '--location',\n                '--silent',\n                '--show-error',\n                '--include',\n                # Prevent curl from asking for an HTTP \"100 Continue\" response\n                '--header', 'Expect:'\n            ]\n            for key in headers:\n                args.append('--header')\n                args.append(\"%s: %s\" % (key, headers[key]))\n            args.append('--data-binary')\n            args.append('@%s' % tempf_path)\n            args.append(url)\n            stdout, stderr = _execute(\n                args,\n                os.getcwd(),\n                re.compile(r'Failed to connect to|TLS|SSLRead|outstanding|cleanly|timed out'),\n                6\n            )\n    finally:\n        if tempf_path and os.path.exists(tempf_path):\n            os.remove(tempf_path)\n\n    if len(stderr) > 0:\n        raise URLError(\"Error %sing %s:\\n%s\" % (method, url, stderr))\n\n    parts = stdout.split(b'\\r\\n\\r\\n', 1)\n    if len(parts) != 2:\n        raise URLError(\"Error %sing %s, response data malformed:\\n%s\" % (method, url, stdout))\n    header_block, body = parts\n\n    content_type_header = None\n    content_len_header = None\n    for hline in header_block.decode('iso-8859-1').splitlines():\n        hline_parts = hline.split(':', 1)\n        if len(hline_parts) != 2:\n            continue\n        name, val = hline_parts\n        name = name.strip().lower()\n        val = val.strip()\n        if name == 'content-type':\n            content_type_header = val\n        if name == 'content-length':\n            content_len_header = val\n\n    if content_type_header is None and content_len_header != '0':\n        raise URLError(\"Error %sing %s, no content-type header:\\n%s\" % (method, url, stdout))\n\n    if content_type_header is None:\n        content_type = 'text/plain'\n        encoding = 'utf-8'\n    else:\n        content_type, params = cgi.parse_header(content_type_header)\n        encoding = params.get('charset')\n\n    return (content_type, encoding, body)\n\n\ndef _execute(params, cwd, retry=None, retries=0, backoff=2):\n    \"\"\"\n    Executes a subprocess\n\n    :param params:\n        A list of the executable and arguments to pass to it\n\n    :param cwd:\n        The working directory to execute the command in\n\n    :param retry:\n        If this string is present in stderr, or regex pattern matches stderr, retry the operation\n\n    :param retries:\n        An integer number of times to retry\n\n    :return:\n        A 2-element tuple of (stdout, stderr)\n    \"\"\"\n\n    proc = subprocess.Popen(\n        params,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n        cwd=cwd\n    )\n    stdout, stderr = proc.communicate()\n    code = proc.wait()\n    if code != 0:\n        if retry and retries > 0:\n            stderr_str = stderr.decode('utf-8')\n            if isinstance(retry, Pattern):\n                if retry.search(stderr_str) is not None:\n                    time.sleep(backoff)\n                    return _execute(params, cwd, retry, retries - 1, backoff * 2)\n            elif retry in stderr_str:\n                time.sleep(backoff)\n                return _execute(params, cwd, retry, retries - 1, backoff * 2)\n        e = OSError('subprocess exit code for \"%s\" was %d: %s' % (' '.join(params), code, stderr))\n        e.stdout = stdout\n        e.stderr = stderr\n        raise e\n    return (stdout, stderr)\n\n\nif __name__ == '__main__':\n    _codecov_submit()\n", "dev/python-install.py": "# coding: utf-8\nfrom __future__ import unicode_literals, division, absolute_import, print_function\n\nimport os\nimport shutil\nimport subprocess\nimport sys\nfrom urllib.parse import urlparse\nfrom urllib.request import urlopen\n\n\nrun_args = [\n    {\n        'name': 'version',\n        'kwarg': 'version',\n    },\n    {\n        'name': 'arch',\n        'kwarg': 'arch',\n    },\n]\n\n\ndef run(version=None, arch=None):\n    \"\"\"\n    Installs a version of Python on Windows\n\n    :return:\n        A bool - if Python was installed successfully\n    \"\"\"\n\n    if sys.platform != 'win32':\n        raise ValueError('python-install is only designed for Windows')\n\n    if version not in set(['2.6', '2.7', '3.3']):\n        raise ValueError('Invalid version: %r' % version)\n\n    if arch not in set(['x86', 'x64']):\n        raise ValueError('Invalid arch: %r' % arch)\n\n    if version == '2.6':\n        if arch == 'x64':\n            url = 'https://www.python.org/ftp/python/2.6.6/python-2.6.6.amd64.msi'\n        else:\n            url = 'https://www.python.org/ftp/python/2.6.6/python-2.6.6.msi'\n    elif version == '2.7':\n        if arch == 'x64':\n            url = 'https://www.python.org/ftp/python/2.7.18/python-2.7.18.amd64.msi'\n        else:\n            url = 'https://www.python.org/ftp/python/2.7.18/python-2.7.18.msi'\n    else:\n        if arch == 'x64':\n            url = 'https://www.python.org/ftp/python/3.3.5/python-3.3.5.amd64.msi'\n        else:\n            url = 'https://www.python.org/ftp/python/3.3.5/python-3.3.5.msi'\n\n    home = os.environ.get('USERPROFILE')\n    msi_filename = os.path.basename(urlparse(url).path)\n    msi_path = os.path.join(home, msi_filename)\n    install_path = os.path.join(os.environ.get('LOCALAPPDATA'), 'Python%s-%s' % (version, arch))\n\n    if os.path.exists(os.path.join(install_path, 'python.exe')):\n        print(install_path)\n        return True\n\n    try:\n        with urlopen(url) as r, open(msi_path, 'wb') as f:\n            shutil.copyfileobj(r, f)\n\n        proc = subprocess.Popen(\n            'msiexec /passive /a %s TARGETDIR=%s' % (msi_filename, install_path),\n            shell=True,\n            cwd=home\n        )\n        proc.communicate()\n\n    finally:\n        if os.path.exists(msi_path):\n            os.unlink(msi_path)\n\n    print(install_path)\n    return True\n", "dev/version.py": "# coding: utf-8\nfrom __future__ import unicode_literals, division, absolute_import, print_function\n\nimport codecs\nimport os\nimport re\n\nfrom . import package_root, package_name, has_tests_package\n\n\nrun_args = [\n    {\n        'name': 'pep440_version',\n        'required': True\n    },\n]\n\n\ndef run(new_version):\n    \"\"\"\n    Updates the package version in the various locations\n\n    :param new_version:\n        A unicode string of the new library version as a PEP 440 version\n\n    :return:\n        A bool - if the version number was successfully bumped\n    \"\"\"\n\n    # We use a restricted form of PEP 440 versions\n    version_match = re.match(\n        r'(\\d+)\\.(\\d+)\\.(\\d)+(?:\\.((?:dev|a|b|rc)\\d+))?$',\n        new_version\n    )\n    if not version_match:\n        raise ValueError('Invalid PEP 440 version: %s' % new_version)\n\n    new_version_info = (\n        int(version_match.group(1)),\n        int(version_match.group(2)),\n        int(version_match.group(3)),\n    )\n    if version_match.group(4):\n        new_version_info += (version_match.group(4),)\n\n    version_path = os.path.join(package_root, package_name, 'version.py')\n    setup_path = os.path.join(package_root, 'setup.py')\n    setup_tests_path = os.path.join(package_root, 'tests', 'setup.py')\n    tests_path = os.path.join(package_root, 'tests', '__init__.py')\n\n    file_paths = [version_path, setup_path]\n    if has_tests_package:\n        file_paths.extend([setup_tests_path, tests_path])\n\n    for file_path in file_paths:\n        orig_source = ''\n        with codecs.open(file_path, 'r', encoding='utf-8') as f:\n            orig_source = f.read()\n\n        found = 0\n        new_source = ''\n        for line in orig_source.splitlines(True):\n            if line.startswith('__version__ = '):\n                found += 1\n                new_source += '__version__ = %r\\n' % new_version\n            elif line.startswith('__version_info__ = '):\n                found += 1\n                new_source += '__version_info__ = %r\\n' % (new_version_info,)\n            elif line.startswith('PACKAGE_VERSION = '):\n                found += 1\n                new_source += 'PACKAGE_VERSION = %r\\n' % new_version\n            else:\n                new_source += line\n\n        if found == 0:\n            raise ValueError('Did not find any versions in %s' % file_path)\n\n        s = 's' if found > 1 else ''\n        rel_path = file_path[len(package_root) + 1:]\n        was_were = 'was' if found == 1 else 'were'\n        if new_source != orig_source:\n            print('Updated %d version%s in %s' % (found, s, rel_path))\n            with codecs.open(file_path, 'w', encoding='utf-8') as f:\n                f.write(new_source)\n        else:\n            print('%d version%s in %s %s up-to-date' % (found, s, rel_path, was_were))\n\n    return True\n", "dev/_pep425.py": "# coding: utf-8\n\n\"\"\"\nThis file was originally derived from\nhttps://github.com/pypa/pip/blob/3e713708088aedb1cde32f3c94333d6e29aaf86e/src/pip/_internal/pep425tags.py\n\nThe following license covers that code:\n\nCopyright (c) 2008-2018 The pip developers (see AUTHORS.txt file)\n\nPermission is hereby granted, free of charge, to any person obtaining\na copy of this software and associated documentation files (the\n\"Software\"), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\nLIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\nOF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\nWITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\"\"\"\n\nfrom __future__ import unicode_literals, division, absolute_import, print_function\n\nimport sys\nimport os\nimport ctypes\nimport re\nimport platform\n\nif sys.version_info >= (2, 7):\n    import sysconfig\n\nif sys.version_info < (3,):\n    str_cls = unicode  # noqa\nelse:\n    str_cls = str\n\n\ndef _pep425_implementation():\n    \"\"\"\n    :return:\n        A 2 character unicode string of the implementation - 'cp' for cpython\n        or 'pp' for PyPy\n    \"\"\"\n\n    return 'pp' if hasattr(sys, 'pypy_version_info') else 'cp'\n\n\ndef _pep425_version():\n    \"\"\"\n    :return:\n        A tuple of integers representing the Python version number\n    \"\"\"\n\n    if hasattr(sys, 'pypy_version_info'):\n        return (sys.version_info[0], sys.pypy_version_info.major,\n                sys.pypy_version_info.minor)\n    else:\n        return (sys.version_info[0], sys.version_info[1])\n\n\ndef _pep425_supports_manylinux():\n    \"\"\"\n    :return:\n        A boolean indicating if the machine can use manylinux1 packages\n    \"\"\"\n\n    try:\n        import _manylinux\n        return bool(_manylinux.manylinux1_compatible)\n    except (ImportError, AttributeError):\n        pass\n\n    # Check for glibc 2.5\n    try:\n        proc = ctypes.CDLL(None)\n        gnu_get_libc_version = proc.gnu_get_libc_version\n        gnu_get_libc_version.restype = ctypes.c_char_p\n\n        ver = gnu_get_libc_version()\n        if not isinstance(ver, str_cls):\n            ver = ver.decode('ascii')\n        match = re.match(r'(\\d+)\\.(\\d+)', ver)\n        return match and match.group(1) == '2' and int(match.group(2)) >= 5\n\n    except (AttributeError):\n        return False\n\n\ndef _pep425_get_abi():\n    \"\"\"\n    :return:\n        A unicode string of the system abi. Will be something like: \"cp27m\",\n        \"cp33m\", etc.\n    \"\"\"\n\n    try:\n        soabi = sysconfig.get_config_var('SOABI')\n        if soabi:\n            if soabi.startswith('cpython-'):\n                return 'cp%s' % soabi.split('-')[1]\n            return soabi.replace('.', '_').replace('-', '_')\n    except (IOError, NameError):\n        pass\n\n    impl = _pep425_implementation()\n    suffix = ''\n    if impl == 'cp':\n        suffix += 'm'\n    if sys.maxunicode == 0x10ffff and sys.version_info < (3, 3):\n        suffix += 'u'\n    return '%s%s%s' % (impl, ''.join(map(str_cls, _pep425_version())), suffix)\n\n\ndef _pep425tags():\n    \"\"\"\n    :return:\n        A list of 3-element tuples with unicode strings or None:\n         [0] implementation tag - cp33, pp27, cp26, py2, py2.py3\n         [1] abi tag - cp26m, None\n         [2] arch tag - linux_x86_64, macosx_10_10_x85_64, etc\n    \"\"\"\n\n    tags = []\n\n    versions = []\n    version_info = _pep425_version()\n    major = version_info[:-1]\n    for minor in range(version_info[-1], -1, -1):\n        versions.append(''.join(map(str, major + (minor,))))\n\n    impl = _pep425_implementation()\n\n    abis = []\n    abi = _pep425_get_abi()\n    if abi:\n        abis.append(abi)\n    abi3 = _pep425_implementation() == 'cp' and sys.version_info >= (3,)\n    if abi3:\n        abis.append('abi3')\n    abis.append('none')\n\n    if sys.platform == 'darwin':\n        plat_ver = platform.mac_ver()\n        ver_parts = plat_ver[0].split('.')\n        minor = int(ver_parts[1])\n        arch = plat_ver[2]\n        if sys.maxsize == 2147483647:\n            arch = 'i386'\n        arches = []\n        while minor > 5:\n            arches.append('macosx_10_%s_%s' % (minor, arch))\n            arches.append('macosx_10_%s_intel' % (minor,))\n            arches.append('macosx_10_%s_universal' % (minor,))\n            minor -= 1\n    else:\n        if sys.platform == 'win32':\n            if 'amd64' in sys.version.lower():\n                arches = ['win_amd64']\n            else:\n                arches = [sys.platform]\n        elif hasattr(os, 'uname'):\n            (plat, _, _, _, machine) = os.uname()\n            plat = plat.lower().replace('/', '')\n            machine.replace(' ', '_').replace('/', '_')\n            if plat == 'linux' and sys.maxsize == 2147483647 and 'arm' not in machine:\n                machine = 'i686'\n            arch = '%s_%s' % (plat, machine)\n            if _pep425_supports_manylinux():\n                arches = [arch.replace('linux', 'manylinux1'), arch]\n            else:\n                arches = [arch]\n\n    for abi in abis:\n        for arch in arches:\n            tags.append(('%s%s' % (impl, versions[0]), abi, arch))\n\n    if abi3:\n        for version in versions[1:]:\n            for arch in arches:\n                tags.append(('%s%s' % (impl, version), 'abi3', arch))\n\n    for arch in arches:\n        tags.append(('py%s' % (versions[0][0]), 'none', arch))\n\n    tags.append(('%s%s' % (impl, versions[0]), 'none', 'any'))\n    tags.append(('%s%s' % (impl, versions[0][0]), 'none', 'any'))\n\n    for i, version in enumerate(versions):\n        tags.append(('py%s' % (version,), 'none', 'any'))\n        if i == 0:\n            tags.append(('py%s' % (version[0]), 'none', 'any'))\n\n    tags.append(('py2.py3', 'none', 'any'))\n\n    return tags\n", "dev/build.py": "# coding: utf-8\nfrom __future__ import unicode_literals, division, absolute_import, print_function\n\nimport os\nimport tarfile\nimport zipfile\n\nimport setuptools.sandbox\n\nfrom . import package_root, package_name, has_tests_package\nfrom ._import import _import_from\n\n\ndef _list_zip(filename):\n    \"\"\"\n    Prints all of the files in a .zip file\n    \"\"\"\n\n    zf = zipfile.ZipFile(filename, 'r')\n    for name in zf.namelist():\n        print('     %s' % name)\n\n\ndef _list_tgz(filename):\n    \"\"\"\n    Prints all of the files in a .tar.gz file\n    \"\"\"\n\n    tf = tarfile.open(filename, 'r:gz')\n    for name in tf.getnames():\n        print('     %s' % name)\n\n\ndef run():\n    \"\"\"\n    Creates a sdist .tar.gz and a bdist_wheel --univeral .whl\n\n    :return:\n        A bool - if the packaging process was successful\n    \"\"\"\n\n    setup = os.path.join(package_root, 'setup.py')\n    tests_root = os.path.join(package_root, 'tests')\n    tests_setup = os.path.join(tests_root, 'setup.py')\n\n    # Trying to call setuptools.sandbox.run_setup(setup, ['--version'])\n    # resulted in a segfault, so we do this instead\n    package_dir = os.path.join(package_root, package_name)\n    version_mod = _import_from('%s.version' % package_name, package_dir, 'version')\n\n    pkg_name_info = (package_name, version_mod.__version__)\n    print('Building %s-%s' % pkg_name_info)\n\n    sdist = '%s-%s.tar.gz' % pkg_name_info\n    whl = '%s-%s-py2.py3-none-any.whl' % pkg_name_info\n    setuptools.sandbox.run_setup(setup, ['-q', 'sdist'])\n    print(' - created %s' % sdist)\n    _list_tgz(os.path.join(package_root, 'dist', sdist))\n    setuptools.sandbox.run_setup(setup, ['-q', 'bdist_wheel', '--universal'])\n    print(' - created %s' % whl)\n    _list_zip(os.path.join(package_root, 'dist', whl))\n    setuptools.sandbox.run_setup(setup, ['-q', 'clean'])\n\n    if has_tests_package:\n        print('Building %s_tests-%s' % (package_name, version_mod.__version__))\n\n        tests_sdist = '%s_tests-%s.tar.gz' % pkg_name_info\n        tests_whl = '%s_tests-%s-py2.py3-none-any.whl' % pkg_name_info\n        setuptools.sandbox.run_setup(tests_setup, ['-q', 'sdist'])\n        print(' - created %s' % tests_sdist)\n        _list_tgz(os.path.join(tests_root, 'dist', tests_sdist))\n        setuptools.sandbox.run_setup(tests_setup, ['-q', 'bdist_wheel', '--universal'])\n        print(' - created %s' % tests_whl)\n        _list_zip(os.path.join(tests_root, 'dist', tests_whl))\n        setuptools.sandbox.run_setup(tests_setup, ['-q', 'clean'])\n\n        dist_dir = os.path.join(package_root, 'dist')\n        tests_dist_dir = os.path.join(tests_root, 'dist')\n        os.rename(\n            os.path.join(tests_dist_dir, tests_sdist),\n            os.path.join(dist_dir, tests_sdist)\n        )\n        os.rename(\n            os.path.join(tests_dist_dir, tests_whl),\n            os.path.join(dist_dir, tests_whl)\n        )\n        os.rmdir(tests_dist_dir)\n\n    return True\n", "dev/ci-cleanup.py": "# coding: utf-8\nfrom __future__ import unicode_literals, division, absolute_import, print_function\n\nimport os\nimport shutil\n\nfrom . import build_root, other_packages\n\n\ndef run():\n    \"\"\"\n    Cleans up CI dependencies - used for persistent GitHub Actions\n    Runners since they don't clean themselves up.\n    \"\"\"\n\n    print(\"Removing ci dependencies\")\n    deps_dir = os.path.join(build_root, 'modularcrypto-deps')\n    if os.path.exists(deps_dir):\n        shutil.rmtree(deps_dir, ignore_errors=True)\n\n    print(\"Removing modularcrypto packages\")\n    for other_package in other_packages:\n        pkg_dir = os.path.join(build_root, other_package)\n        if os.path.exists(pkg_dir):\n            shutil.rmtree(pkg_dir, ignore_errors=True)\n    print()\n\n    return True\n", "dev/ci.py": "# coding: utf-8\nfrom __future__ import unicode_literals, division, absolute_import, print_function\n\nimport os\nimport site\nimport sys\n\nfrom . import build_root, requires_oscrypto\nfrom ._import import _preload\n\n\ndeps_dir = os.path.join(build_root, 'modularcrypto-deps')\nif os.path.exists(deps_dir):\n    site.addsitedir(deps_dir)\n    # In case any of the deps are installed system-wide\n    sys.path.insert(0, deps_dir)\n\nif sys.version_info[0:2] not in [(2, 6), (3, 2)]:\n    from .lint import run as run_lint\nelse:\n    run_lint = None\n\nif sys.version_info[0:2] != (3, 2):\n    from .coverage import run as run_coverage\n    from .coverage import coverage\n    run_tests = None\n\nelse:\n    from .tests import run as run_tests\n    run_coverage = None\n\n\ndef run():\n    \"\"\"\n    Runs the linter and tests\n\n    :return:\n        A bool - if the linter and tests ran successfully\n    \"\"\"\n\n    _preload(requires_oscrypto, True)\n\n    if run_lint:\n        print('')\n        lint_result = run_lint()\n    else:\n        lint_result = True\n\n    if run_coverage:\n        print('\\nRunning tests (via coverage.py %s)' % coverage.__version__)\n        sys.stdout.flush()\n        tests_result = run_coverage(ci=True)\n    else:\n        print('\\nRunning tests')\n        sys.stdout.flush()\n        tests_result = run_tests(ci=True)\n    sys.stdout.flush()\n\n    return lint_result and tests_result\n", "dev/__init__.py": "# coding: utf-8\nfrom __future__ import unicode_literals, division, absolute_import, print_function\n\nimport os\n\n\npackage_name = \"asn1crypto\"\n\nother_packages = [\n    \"oscrypto\",\n    \"certbuilder\",\n    \"certvalidator\",\n    \"crlbuilder\",\n    \"csrbuilder\",\n    \"ocspbuilder\"\n]\n\ntask_keyword_args = []\n\nrequires_oscrypto = False\nhas_tests_package = True\n\npackage_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))\nbuild_root = os.path.abspath(os.path.join(package_root, '..'))\n\nmd_source_map = {}\n\ndefinition_replacements = {}\n", "dev/_import.py": "# coding: utf-8\nfrom __future__ import unicode_literals, division, absolute_import, print_function\n\nimport sys\nimport os\n\nfrom . import build_root, package_name, package_root\n\nif sys.version_info < (3, 5):\n    import imp\nelse:\n    import importlib\n    import importlib.abc\n    import importlib.util\n\n\nif sys.version_info < (3,):\n    getcwd = os.getcwdu\nelse:\n    getcwd = os.getcwd\n\n\nif sys.version_info >= (3, 5):\n    class ModCryptoMetaFinder(importlib.abc.MetaPathFinder):\n        def setup(self):\n            self.modules = {}\n            sys.meta_path.insert(0, self)\n\n        def add_module(self, package_name, package_path):\n            if package_name not in self.modules:\n                self.modules[package_name] = package_path\n\n        def find_spec(self, fullname, path, target=None):\n            name_parts = fullname.split('.')\n            if name_parts[0] not in self.modules:\n                return None\n\n            package = name_parts[0]\n            package_path = self.modules[package]\n\n            fullpath = os.path.join(package_path, *name_parts[1:])\n\n            if os.path.isdir(fullpath):\n                filename = os.path.join(fullpath, \"__init__.py\")\n                submodule_locations = [fullpath]\n            else:\n                filename = fullpath + \".py\"\n                submodule_locations = None\n\n            if not os.path.exists(filename):\n                return None\n\n            return importlib.util.spec_from_file_location(\n                fullname,\n                filename,\n                loader=None,\n                submodule_search_locations=submodule_locations\n            )\n\n    CUSTOM_FINDER = ModCryptoMetaFinder()\n    CUSTOM_FINDER.setup()\n\n\ndef _import_from(mod, path, mod_dir=None, allow_error=False):\n    \"\"\"\n    Imports a module from a specific path\n\n    :param mod:\n        A unicode string of the module name\n\n    :param path:\n        A unicode string to the directory containing the module\n\n    :param mod_dir:\n        If the sub directory of \"path\" is different than the \"mod\" name,\n        pass the sub directory as a unicode string\n\n    :param allow_error:\n        If an ImportError should be raised when the module can't be imported\n\n    :return:\n        None if not loaded, otherwise the module\n    \"\"\"\n\n    if mod in sys.modules:\n        return sys.modules[mod]\n\n    if mod_dir is None:\n        full_mod = mod\n    else:\n        full_mod = mod_dir.replace(os.sep, '.')\n\n    if mod_dir is None:\n        mod_dir = mod.replace('.', os.sep)\n\n    if not os.path.exists(path):\n        return None\n\n    source_path = os.path.join(path, mod_dir, '__init__.py')\n    if not os.path.exists(source_path):\n        source_path = os.path.join(path, mod_dir + '.py')\n\n    if not os.path.exists(source_path):\n        return None\n\n    if os.sep in mod_dir:\n        append, mod_dir = mod_dir.rsplit(os.sep, 1)\n        path = os.path.join(path, append)\n\n    try:\n        if sys.version_info < (3, 5):\n            mod_info = imp.find_module(mod_dir, [path])\n            return imp.load_module(mod, *mod_info)\n\n        else:\n            package = mod.split('.', 1)[0]\n            package_dir = full_mod.split('.', 1)[0]\n            package_path = os.path.join(path, package_dir)\n            CUSTOM_FINDER.add_module(package, package_path)\n\n            return importlib.import_module(mod)\n\n    except ImportError:\n        if allow_error:\n            raise\n        return None\n\n\ndef _preload(require_oscrypto, print_info):\n    \"\"\"\n    Preloads asn1crypto and optionally oscrypto from a local source checkout,\n    or from a normal install\n\n    :param require_oscrypto:\n        A bool if oscrypto needs to be preloaded\n\n    :param print_info:\n        A bool if info about asn1crypto and oscrypto should be printed\n    \"\"\"\n\n    if print_info:\n        print('Working dir: ' + getcwd())\n        print('Python ' + sys.version.replace('\\n', ''))\n\n    asn1crypto = None\n    oscrypto = None\n\n    if require_oscrypto:\n        # Some CI services don't use the package name for the dir\n        if package_name == 'oscrypto':\n            oscrypto_dir = package_root\n        else:\n            oscrypto_dir = os.path.join(build_root, 'oscrypto')\n        oscrypto_tests = None\n        if os.path.exists(oscrypto_dir):\n            oscrypto_tests = _import_from('oscrypto_tests', oscrypto_dir, 'tests')\n        if oscrypto_tests is None:\n            import oscrypto_tests\n        asn1crypto, oscrypto = oscrypto_tests.local_oscrypto()\n\n    else:\n        if package_name == 'asn1crypto':\n            asn1crypto_dir = package_root\n        else:\n            asn1crypto_dir = os.path.join(build_root, 'asn1crypto')\n        if os.path.exists(asn1crypto_dir):\n            asn1crypto = _import_from('asn1crypto', asn1crypto_dir)\n        if asn1crypto is None:\n            import asn1crypto\n\n    if print_info:\n        print(\n            '\\nasn1crypto: %s, %s' % (\n                asn1crypto.__version__,\n                os.path.dirname(asn1crypto.__file__)\n            )\n        )\n        if require_oscrypto:\n            backend = oscrypto.backend()\n            if backend == 'openssl':\n                from oscrypto._openssl._libcrypto import libcrypto_version\n                backend = '%s (%s)' % (backend, libcrypto_version)\n\n            print(\n                'oscrypto: %s, %s backend, %s' % (\n                    oscrypto.__version__,\n                    backend,\n                    os.path.dirname(oscrypto.__file__)\n                )\n            )\n", "dev/pyenv-install.py": "# coding: utf-8\nfrom __future__ import unicode_literals, division, absolute_import, print_function\n\nimport os\nimport subprocess\nimport sys\n\n\nrun_args = [\n    {\n        'name': 'version',\n        'kwarg': 'version',\n    },\n]\n\n\ndef _write_env(env, key, value):\n    sys.stdout.write(\"%s: %s\\n\" % (key, value))\n    sys.stdout.flush()\n    if sys.version_info < (3,):\n        env[key.encode('utf-8')] = value.encode('utf-8')\n    else:\n        env[key] = value\n\n\ndef _shell_subproc(args):\n    proc = subprocess.Popen(\n        args,\n        shell=True,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE\n    )\n    so, se = proc.communicate()\n    stdout = so.decode('utf-8')\n    stderr = se.decode('utf-8')\n    return proc.returncode == 0, stdout, stderr\n\n\ndef run(version=None):\n    \"\"\"\n    Installs a version of Python on Mac using pyenv\n\n    :return:\n        A bool - if Python was installed successfully\n    \"\"\"\n\n    if sys.platform == 'win32':\n        raise ValueError('pyenv-install is not designed for Windows')\n\n    if version not in set(['2.6', '2.7', '3.3']):\n        raise ValueError('Invalid version: %r' % version)\n\n    python_path = os.path.expanduser('~/.pyenv/versions/%s/bin' % version)\n    if os.path.exists(os.path.join(python_path, 'python')):\n        print(python_path)\n        return True\n\n    stdout = \"\"\n    stderr = \"\"\n\n    has_pyenv, _, _ = _shell_subproc('command -v pyenv')\n    if not has_pyenv:\n        success, stdout, stderr = _shell_subproc('brew install pyenv')\n        if not success:\n            print(stdout)\n            print(stderr, file=sys.stderr)\n            return False\n\n    has_zlib, _, _ = _shell_subproc('brew list zlib')\n    if not has_zlib:\n        success, stdout, stderr = _shell_subproc('brew install zlib')\n        if not success:\n            print(stdout)\n            print(stderr, file=sys.stderr)\n            return False\n\n    success, stdout, stderr = _shell_subproc('brew --prefix zlib')\n    if not success:\n        print(stdout)\n        print(stderr, file=sys.stderr)\n        return False\n    zlib_prefix = stdout.strip()\n\n    pyenv_script = './%s' % version\n    try:\n        with open(pyenv_script, 'wb') as f:\n            if version == '2.6':\n                contents = '#require_gcc\\n' \\\n                    'install_package \"openssl-1.0.2k\" \"https://www.openssl.org/source/old/1.0.2/openssl-1.0.2k.tar.gz' \\\n                    '#6b3977c61f2aedf0f96367dcfb5c6e578cf37e7b8d913b4ecb6643c3cb88d8c0\" mac_openssl\\n' \\\n                    'install_package \"readline-8.0\" \"https://ftpmirror.gnu.org/readline/readline-8.0.tar.gz' \\\n                    '#e339f51971478d369f8a053a330a190781acb9864cf4c541060f12078948e461\" mac_readline' \\\n                    ' --if has_broken_mac_readline\\n' \\\n                    'install_package \"Python-2.6.9\" \"https://www.python.org/ftp/python/2.6.9/Python-2.6.9.tgz' \\\n                    '#7277b1285d8a82f374ef6ebaac85b003266f7939b3f2a24a3af52f9523ac94db\" standard verify_py26'\n            elif version == '2.7':\n                contents = '#require_gcc\\n' \\\n                    'export PYTHON_BUILD_HOMEBREW_OPENSSL_FORMULA=\"openssl@1.1 openssl@1.0 openssl\"\\n' \\\n                    'install_package \"openssl-1.0.2q\" \"https://www.openssl.org/source/old/1.0.2/openssl-1.0.2q.tar.gz' \\\n                    '#5744cfcbcec2b1b48629f7354203bc1e5e9b5466998bbccc5b5fcde3b18eb684\" mac_openssl ' \\\n                    '--if has_broken_mac_openssl\\n' \\\n                    'install_package \"readline-8.0\" \"https://ftpmirror.gnu.org/readline/readline-8.0.tar.gz' \\\n                    '#e339f51971478d369f8a053a330a190781acb9864cf4c541060f12078948e461\" mac_readline ' \\\n                    '--if has_broken_mac_readline\\n' \\\n                    'install_package \"Python-2.7.18\" \"https://www.python.org/ftp/python/2.7.18/Python-2.7.18.tgz' \\\n                    '#da3080e3b488f648a3d7a4560ddee895284c3380b11d6de75edb986526b9a814\" standard verify_py27 ' \\\n                    'copy_python_gdb ensurepip\\n'\n            elif version == '3.3':\n                contents = '#require_gcc\\n' \\\n                    'install_package \"openssl-1.0.2k\" \"https://www.openssl.org/source/old/1.0.2/openssl-1.0.2k.tar.gz' \\\n                    '#6b3977c61f2aedf0f96367dcfb5c6e578cf37e7b8d913b4ecb6643c3cb88d8c0\" mac_openssl\\n' \\\n                    'install_package \"readline-8.0\" \"https://ftpmirror.gnu.org/readline/readline-8.0.tar.gz' \\\n                    '#e339f51971478d369f8a053a330a190781acb9864cf4c541060f12078948e461\" mac_readline' \\\n                    ' --if has_broken_mac_readline\\n' \\\n                    'install_package \"Python-3.3.7\" \"https://www.python.org/ftp/python/3.3.7/Python-3.3.7.tar.xz' \\\n                    '#85f60c327501c36bc18c33370c14d472801e6af2f901dafbba056f61685429fe\" standard verify_py33'\n            f.write(contents.encode('utf-8'))\n\n        args = ['pyenv', 'install', pyenv_script]\n        stdin = None\n        stdin_contents = None\n        env = os.environ.copy()\n\n        _write_env(env, 'CFLAGS', '-I' + zlib_prefix + '/include')\n        _write_env(env, 'LDFLAGS', '-L' + zlib_prefix + '/lib')\n\n        if version == '2.6':\n            _write_env(env, 'PYTHON_CONFIGURE_OPTS', '--enable-ipv6')\n            stdin = subprocess.PIPE\n            stdin_contents = '--- configure  2021-08-05 20:17:26.000000000 -0400\\n' \\\n                '+++ configure   2021-08-05 20:21:30.000000000 -0400\\n' \\\n                '@@ -10300,17 +10300,8 @@\\n' \\\n                ' rm -f core conftest.err conftest.$ac_objext \\\\\\n' \\\n                '     conftest$ac_exeext conftest.$ac_ext\\n' \\\n                ' \\n' \\\n                '-if test \"$buggygetaddrinfo\" = \"yes\"; then\\n' \\\n                '-\\tif test \"$ipv6\" = \"yes\"; then\\n' \\\n                '-\\t\\techo \\'Fatal: You must get working getaddrinfo() function.\\'\\n' \\\n                '-\\t\\techo \\'       or you can specify \"--disable-ipv6\"\\'.\\n' \\\n                '-\\t\\texit 1\\n' \\\n                '-\\tfi\\n' \\\n                '-else\\n' \\\n                '-\\n' \\\n                ' $as_echo \"#define HAVE_GETADDRINFO 1\" >>confdefs.h\\n' \\\n                ' \\n' \\\n                '-fi\\n' \\\n                ' for ac_func in getnameinfo\\n' \\\n                ' do :\\n' \\\n                '   ac_fn_c_check_func \"$LINENO\" \"getnameinfo\" \"ac_cv_func_getnameinfo\"'\n            stdin_contents = stdin_contents.encode('ascii')\n            args.append('--patch')\n        elif version == '3.3':\n            stdin = subprocess.PIPE\n            stdin_contents = '--- configure\\n' \\\n                '+++ configure\\n' \\\n                '@@ -3391,7 +3391,7 @@ $as_echo \"#define _BSD_SOURCE 1\" >>confdefs.h\\n' \\\n                '   # has no effect, don\\'t bother defining them\\n' \\\n                '   Darwin/[6789].*)\\n' \\\n                '     define_xopen_source=no;;\\n' \\\n                '-  Darwin/1[0-9].*)\\n' \\\n                '+  Darwin/[12][0-9].*)\\n' \\\n                '     define_xopen_source=no;;\\n' \\\n                '   # On AIX 4 and 5.1, mbstate_t is defined only when _XOPEN_SOURCE == 500 but\\n' \\\n                '   # used in wcsnrtombs() and mbsnrtowcs() even if _XOPEN_SOURCE is not defined\\n' \\\n                '--- configure.ac\\n' \\\n                '+++ configure.ac\\n' \\\n                '@@ 480,7 +480,7 @@ case $ac_sys_system/$ac_sys_release in\\n' \\\n                '   # has no effect, don\\'t bother defining them\\n' \\\n                '   Darwin/@<:@6789@:>@.*)\\n' \\\n                '     define_xopen_source=no;;\\n' \\\n                '-  Darwin/1@<:@0-9@:>@.*)\\n' \\\n                '+  Darwin/@<:@[12]@:>@@<:@0-9@:>@.*)\\n' \\\n                '     define_xopen_source=no;;\\n' \\\n                '   # On AIX 4 and 5.1, mbstate_t is defined only when _XOPEN_SOURCE == 500 but\\n' \\\n                '   # used in wcsnrtombs() and mbsnrtowcs() even if _XOPEN_SOURCE is not defined\\n'\n            stdin_contents = stdin_contents.encode('ascii')\n            args.append('--patch')\n\n        proc = subprocess.Popen(\n            args,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            stdin=stdin,\n            env=env\n        )\n        so, se = proc.communicate(stdin_contents)\n        stdout += so.decode('utf-8')\n        stderr += se.decode('utf-8')\n\n        if proc.returncode != 0:\n            print(stdout)\n            print(stderr, file=sys.stderr)\n            return False\n\n    finally:\n        if os.path.exists(pyenv_script):\n            os.unlink(pyenv_script)\n\n    print(python_path)\n    return True\n", "dev/lint.py": "# coding: utf-8\nfrom __future__ import unicode_literals, division, absolute_import, print_function\n\nimport os\n\nfrom . import package_name, package_root\n\nimport flake8\nif not hasattr(flake8, '__version_info__') or flake8.__version_info__ < (3,):\n    from flake8.engine import get_style_guide\nelse:\n    from flake8.api.legacy import get_style_guide\n\n\ndef run():\n    \"\"\"\n    Runs flake8 lint\n\n    :return:\n        A bool - if flake8 did not find any errors\n    \"\"\"\n\n    print('Running flake8 %s' % flake8.__version__)\n\n    flake8_style = get_style_guide(config_file=os.path.join(package_root, 'tox.ini'))\n\n    paths = []\n    for _dir in [package_name, 'dev', 'tests']:\n        for root, _, filenames in os.walk(_dir):\n            for filename in filenames:\n                if not filename.endswith('.py'):\n                    continue\n                paths.append(os.path.join(root, filename))\n    report = flake8_style.check_files(paths)\n    success = report.total_errors == 0\n    if success:\n        print('OK')\n    return success\n", "asn1crypto/crl.py": "# coding: utf-8\n\n\"\"\"\nASN.1 type classes for certificate revocation lists (CRL). Exports the\nfollowing items:\n\n - CertificateList()\n\nOther type classes are defined that help compose the types listed above.\n\"\"\"\n\nfrom __future__ import unicode_literals, division, absolute_import, print_function\n\nimport hashlib\n\nfrom .algos import SignedDigestAlgorithm\nfrom .core import (\n    Boolean,\n    Enumerated,\n    GeneralizedTime,\n    Integer,\n    ObjectIdentifier,\n    OctetBitString,\n    ParsableOctetString,\n    Sequence,\n    SequenceOf,\n)\nfrom .x509 import (\n    AuthorityInfoAccessSyntax,\n    AuthorityKeyIdentifier,\n    CRLDistributionPoints,\n    DistributionPointName,\n    GeneralNames,\n    Name,\n    ReasonFlags,\n    Time,\n)\n\n\n# The structures in this file are taken from https://tools.ietf.org/html/rfc5280\n\n\nclass Version(Integer):\n    _map = {\n        0: 'v1',\n        1: 'v2',\n    }\n\n\nclass IssuingDistributionPoint(Sequence):\n    _fields = [\n        ('distribution_point', DistributionPointName, {'explicit': 0, 'optional': True}),\n        ('only_contains_user_certs', Boolean, {'implicit': 1, 'default': False}),\n        ('only_contains_ca_certs', Boolean, {'implicit': 2, 'default': False}),\n        ('only_some_reasons', ReasonFlags, {'implicit': 3, 'optional': True}),\n        ('indirect_crl', Boolean, {'implicit': 4, 'default': False}),\n        ('only_contains_attribute_certs', Boolean, {'implicit': 5, 'default': False}),\n    ]\n\n\nclass TBSCertListExtensionId(ObjectIdentifier):\n    _map = {\n        '2.5.29.18': 'issuer_alt_name',\n        '2.5.29.20': 'crl_number',\n        '2.5.29.27': 'delta_crl_indicator',\n        '2.5.29.28': 'issuing_distribution_point',\n        '2.5.29.35': 'authority_key_identifier',\n        '2.5.29.46': 'freshest_crl',\n        '1.3.6.1.5.5.7.1.1': 'authority_information_access',\n    }\n\n\nclass TBSCertListExtension(Sequence):\n    _fields = [\n        ('extn_id', TBSCertListExtensionId),\n        ('critical', Boolean, {'default': False}),\n        ('extn_value', ParsableOctetString),\n    ]\n\n    _oid_pair = ('extn_id', 'extn_value')\n    _oid_specs = {\n        'issuer_alt_name': GeneralNames,\n        'crl_number': Integer,\n        'delta_crl_indicator': Integer,\n        'issuing_distribution_point': IssuingDistributionPoint,\n        'authority_key_identifier': AuthorityKeyIdentifier,\n        'freshest_crl': CRLDistributionPoints,\n        'authority_information_access': AuthorityInfoAccessSyntax,\n    }\n\n\nclass TBSCertListExtensions(SequenceOf):\n    _child_spec = TBSCertListExtension\n\n\nclass CRLReason(Enumerated):\n    _map = {\n        0: 'unspecified',\n        1: 'key_compromise',\n        2: 'ca_compromise',\n        3: 'affiliation_changed',\n        4: 'superseded',\n        5: 'cessation_of_operation',\n        6: 'certificate_hold',\n        8: 'remove_from_crl',\n        9: 'privilege_withdrawn',\n        10: 'aa_compromise',\n    }\n\n    @property\n    def human_friendly(self):\n        \"\"\"\n        :return:\n            A unicode string with revocation description that is suitable to\n            show to end-users. Starts with a lower case letter and phrased in\n            such a way that it makes sense after the phrase \"because of\" or\n            \"due to\".\n        \"\"\"\n\n        return {\n            'unspecified': 'an unspecified reason',\n            'key_compromise': 'a compromised key',\n            'ca_compromise': 'the CA being compromised',\n            'affiliation_changed': 'an affiliation change',\n            'superseded': 'certificate supersession',\n            'cessation_of_operation': 'a cessation of operation',\n            'certificate_hold': 'a certificate hold',\n            'remove_from_crl': 'removal from the CRL',\n            'privilege_withdrawn': 'privilege withdrawl',\n            'aa_compromise': 'the AA being compromised',\n        }[self.native]\n\n\nclass CRLEntryExtensionId(ObjectIdentifier):\n    _map = {\n        '2.5.29.21': 'crl_reason',\n        '2.5.29.23': 'hold_instruction_code',\n        '2.5.29.24': 'invalidity_date',\n        '2.5.29.29': 'certificate_issuer',\n    }\n\n\nclass CRLEntryExtension(Sequence):\n    _fields = [\n        ('extn_id', CRLEntryExtensionId),\n        ('critical', Boolean, {'default': False}),\n        ('extn_value', ParsableOctetString),\n    ]\n\n    _oid_pair = ('extn_id', 'extn_value')\n    _oid_specs = {\n        'crl_reason': CRLReason,\n        'hold_instruction_code': ObjectIdentifier,\n        'invalidity_date': GeneralizedTime,\n        'certificate_issuer': GeneralNames,\n    }\n\n\nclass CRLEntryExtensions(SequenceOf):\n    _child_spec = CRLEntryExtension\n\n\nclass RevokedCertificate(Sequence):\n    _fields = [\n        ('user_certificate', Integer),\n        ('revocation_date', Time),\n        ('crl_entry_extensions', CRLEntryExtensions, {'optional': True}),\n    ]\n\n    _processed_extensions = False\n    _critical_extensions = None\n    _crl_reason_value = None\n    _invalidity_date_value = None\n    _certificate_issuer_value = None\n    _issuer_name = False\n\n    def _set_extensions(self):\n        \"\"\"\n        Sets common named extensions to private attributes and creates a list\n        of critical extensions\n        \"\"\"\n\n        self._critical_extensions = set()\n\n        for extension in self['crl_entry_extensions']:\n            name = extension['extn_id'].native\n            attribute_name = '_%s_value' % name\n            if hasattr(self, attribute_name):\n                setattr(self, attribute_name, extension['extn_value'].parsed)\n            if extension['critical'].native:\n                self._critical_extensions.add(name)\n\n        self._processed_extensions = True\n\n    @property\n    def critical_extensions(self):\n        \"\"\"\n        Returns a set of the names (or OID if not a known extension) of the\n        extensions marked as critical\n\n        :return:\n            A set of unicode strings\n        \"\"\"\n\n        if not self._processed_extensions:\n            self._set_extensions()\n        return self._critical_extensions\n\n    @property\n    def crl_reason_value(self):\n        \"\"\"\n        This extension indicates the reason that a certificate was revoked.\n\n        :return:\n            None or a CRLReason object\n        \"\"\"\n\n        if self._processed_extensions is False:\n            self._set_extensions()\n        return self._crl_reason_value\n\n    @property\n    def invalidity_date_value(self):\n        \"\"\"\n        This extension indicates the suspected date/time the private key was\n        compromised or the certificate became invalid. This would usually be\n        before the revocation date, which is when the CA processed the\n        revocation.\n\n        :return:\n            None or a GeneralizedTime object\n        \"\"\"\n\n        if self._processed_extensions is False:\n            self._set_extensions()\n        return self._invalidity_date_value\n\n    @property\n    def certificate_issuer_value(self):\n        \"\"\"\n        This extension indicates the issuer of the certificate in question,\n        and is used in indirect CRLs. CRL entries without this extension are\n        for certificates issued from the last seen issuer.\n\n        :return:\n            None or an x509.GeneralNames object\n        \"\"\"\n\n        if self._processed_extensions is False:\n            self._set_extensions()\n        return self._certificate_issuer_value\n\n    @property\n    def issuer_name(self):\n        \"\"\"\n        :return:\n            None, or an asn1crypto.x509.Name object for the issuer of the cert\n        \"\"\"\n\n        if self._issuer_name is False:\n            self._issuer_name = None\n            if self.certificate_issuer_value:\n                for general_name in self.certificate_issuer_value:\n                    if general_name.name == 'directory_name':\n                        self._issuer_name = general_name.chosen\n                        break\n        return self._issuer_name\n\n\nclass RevokedCertificates(SequenceOf):\n    _child_spec = RevokedCertificate\n\n\nclass TbsCertList(Sequence):\n    _fields = [\n        ('version', Version, {'optional': True}),\n        ('signature', SignedDigestAlgorithm),\n        ('issuer', Name),\n        ('this_update', Time),\n        ('next_update', Time, {'optional': True}),\n        ('revoked_certificates', RevokedCertificates, {'optional': True}),\n        ('crl_extensions', TBSCertListExtensions, {'explicit': 0, 'optional': True}),\n    ]\n\n\nclass CertificateList(Sequence):\n    _fields = [\n        ('tbs_cert_list', TbsCertList),\n        ('signature_algorithm', SignedDigestAlgorithm),\n        ('signature', OctetBitString),\n    ]\n\n    _processed_extensions = False\n    _critical_extensions = None\n    _issuer_alt_name_value = None\n    _crl_number_value = None\n    _delta_crl_indicator_value = None\n    _issuing_distribution_point_value = None\n    _authority_key_identifier_value = None\n    _freshest_crl_value = None\n    _authority_information_access_value = None\n    _issuer_cert_urls = None\n    _delta_crl_distribution_points = None\n    _sha1 = None\n    _sha256 = None\n\n    def _set_extensions(self):\n        \"\"\"\n        Sets common named extensions to private attributes and creates a list\n        of critical extensions\n        \"\"\"\n\n        self._critical_extensions = set()\n\n        for extension in self['tbs_cert_list']['crl_extensions']:\n            name = extension['extn_id'].native\n            attribute_name = '_%s_value' % name\n            if hasattr(self, attribute_name):\n                setattr(self, attribute_name, extension['extn_value'].parsed)\n            if extension['critical'].native:\n                self._critical_extensions.add(name)\n\n        self._processed_extensions = True\n\n    @property\n    def critical_extensions(self):\n        \"\"\"\n        Returns a set of the names (or OID if not a known extension) of the\n        extensions marked as critical\n\n        :return:\n            A set of unicode strings\n        \"\"\"\n\n        if not self._processed_extensions:\n            self._set_extensions()\n        return self._critical_extensions\n\n    @property\n    def issuer_alt_name_value(self):\n        \"\"\"\n        This extension allows associating one or more alternative names with\n        the issuer of the CRL.\n\n        :return:\n            None or an x509.GeneralNames object\n        \"\"\"\n\n        if self._processed_extensions is False:\n            self._set_extensions()\n        return self._issuer_alt_name_value\n\n    @property\n    def crl_number_value(self):\n        \"\"\"\n        This extension adds a monotonically increasing number to the CRL and is\n        used to distinguish different versions of the CRL.\n\n        :return:\n            None or an Integer object\n        \"\"\"\n\n        if self._processed_extensions is False:\n            self._set_extensions()\n        return self._crl_number_value\n\n    @property\n    def delta_crl_indicator_value(self):\n        \"\"\"\n        This extension indicates a CRL is a delta CRL, and contains the CRL\n        number of the base CRL that it is a delta from.\n\n        :return:\n            None or an Integer object\n        \"\"\"\n\n        if self._processed_extensions is False:\n            self._set_extensions()\n        return self._delta_crl_indicator_value\n\n    @property\n    def issuing_distribution_point_value(self):\n        \"\"\"\n        This extension includes information about what types of revocations\n        and certificates are part of the CRL.\n\n        :return:\n            None or an IssuingDistributionPoint object\n        \"\"\"\n\n        if self._processed_extensions is False:\n            self._set_extensions()\n        return self._issuing_distribution_point_value\n\n    @property\n    def authority_key_identifier_value(self):\n        \"\"\"\n        This extension helps in identifying the public key with which to\n        validate the authenticity of the CRL.\n\n        :return:\n            None or an AuthorityKeyIdentifier object\n        \"\"\"\n\n        if self._processed_extensions is False:\n            self._set_extensions()\n        return self._authority_key_identifier_value\n\n    @property\n    def freshest_crl_value(self):\n        \"\"\"\n        This extension is used in complete CRLs to indicate where a delta CRL\n        may be located.\n\n        :return:\n            None or a CRLDistributionPoints object\n        \"\"\"\n\n        if self._processed_extensions is False:\n            self._set_extensions()\n        return self._freshest_crl_value\n\n    @property\n    def authority_information_access_value(self):\n        \"\"\"\n        This extension is used to provide a URL with which to download the\n        certificate used to sign this CRL.\n\n        :return:\n            None or an AuthorityInfoAccessSyntax object\n        \"\"\"\n\n        if self._processed_extensions is False:\n            self._set_extensions()\n        return self._authority_information_access_value\n\n    @property\n    def issuer(self):\n        \"\"\"\n        :return:\n            An asn1crypto.x509.Name object for the issuer of the CRL\n        \"\"\"\n\n        return self['tbs_cert_list']['issuer']\n\n    @property\n    def authority_key_identifier(self):\n        \"\"\"\n        :return:\n            None or a byte string of the key_identifier from the authority key\n            identifier extension\n        \"\"\"\n\n        if not self.authority_key_identifier_value:\n            return None\n\n        return self.authority_key_identifier_value['key_identifier'].native\n\n    @property\n    def issuer_cert_urls(self):\n        \"\"\"\n        :return:\n            A list of unicode strings that are URLs that should contain either\n            an individual DER-encoded X.509 certificate, or a DER-encoded CMS\n            message containing multiple certificates\n        \"\"\"\n\n        if self._issuer_cert_urls is None:\n            self._issuer_cert_urls = []\n            if self.authority_information_access_value:\n                for entry in self.authority_information_access_value:\n                    if entry['access_method'].native == 'ca_issuers':\n                        location = entry['access_location']\n                        if location.name != 'uniform_resource_identifier':\n                            continue\n                        url = location.native\n                        if url.lower()[0:7] == 'http://':\n                            self._issuer_cert_urls.append(url)\n        return self._issuer_cert_urls\n\n    @property\n    def delta_crl_distribution_points(self):\n        \"\"\"\n        Returns delta CRL URLs - only applies to complete CRLs\n\n        :return:\n            A list of zero or more DistributionPoint objects\n        \"\"\"\n\n        if self._delta_crl_distribution_points is None:\n            self._delta_crl_distribution_points = []\n\n            if self.freshest_crl_value is not None:\n                for distribution_point in self.freshest_crl_value:\n                    distribution_point_name = distribution_point['distribution_point']\n                    # RFC 5280 indicates conforming CA should not use the relative form\n                    if distribution_point_name.name == 'name_relative_to_crl_issuer':\n                        continue\n                    # This library is currently only concerned with HTTP-based CRLs\n                    for general_name in distribution_point_name.chosen:\n                        if general_name.name == 'uniform_resource_identifier':\n                            self._delta_crl_distribution_points.append(distribution_point)\n\n        return self._delta_crl_distribution_points\n\n    @property\n    def signature(self):\n        \"\"\"\n        :return:\n            A byte string of the signature\n        \"\"\"\n\n        return self['signature'].native\n\n    @property\n    def sha1(self):\n        \"\"\"\n        :return:\n            The SHA1 hash of the DER-encoded bytes of this certificate list\n        \"\"\"\n\n        if self._sha1 is None:\n            self._sha1 = hashlib.sha1(self.dump()).digest()\n        return self._sha1\n\n    @property\n    def sha256(self):\n        \"\"\"\n        :return:\n            The SHA-256 hash of the DER-encoded bytes of this certificate list\n        \"\"\"\n\n        if self._sha256 is None:\n            self._sha256 = hashlib.sha256(self.dump()).digest()\n        return self._sha256\n", "asn1crypto/_errors.py": "# coding: utf-8\n\n\"\"\"\nExports the following items:\n\n - unwrap()\n - APIException()\n\"\"\"\n\nfrom __future__ import unicode_literals, division, absolute_import, print_function\n\nimport re\nimport textwrap\n\n\nclass APIException(Exception):\n    \"\"\"\n    An exception indicating an API has been removed from asn1crypto\n    \"\"\"\n\n    pass\n\n\ndef unwrap(string, *params):\n    \"\"\"\n    Takes a multi-line string and does the following:\n\n     - dedents\n     - converts newlines with text before and after into a single line\n     - strips leading and trailing whitespace\n\n    :param string:\n        The string to format\n\n    :param *params:\n        Params to interpolate into the string\n\n    :return:\n        The formatted string\n    \"\"\"\n\n    output = textwrap.dedent(string)\n\n    # Unwrap lines, taking into account bulleted lists, ordered lists and\n    # underlines consisting of = signs\n    if output.find('\\n') != -1:\n        output = re.sub('(?<=\\\\S)\\n(?=[^ \\n\\t\\\\d\\\\*\\\\-=])', ' ', output)\n\n    if params:\n        output = output % params\n\n    output = output.strip()\n\n    return output\n", "asn1crypto/_ordereddict.py": "# Copyright (c) 2009 Raymond Hettinger\n#\n# Permission is hereby granted, free of charge, to any person\n# obtaining a copy of this software and associated documentation files\n# (the \"Software\"), to deal in the Software without restriction,\n# including without limitation the rights to use, copy, modify, merge,\n# publish, distribute, sublicense, and/or sell copies of the Software,\n# and to permit persons to whom the Software is furnished to do so,\n# subject to the following conditions:\n#\n#     The above copyright notice and this permission notice shall be\n#     included in all copies or substantial portions of the Software.\n#\n#     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n#     EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES\n#     OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n#     NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT\n#     HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,\n#     WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n#     FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\n#     OTHER DEALINGS IN THE SOFTWARE.\n\nimport sys\n\nif not sys.version_info < (2, 7):\n\n    from collections import OrderedDict\n\nelse:\n\n    from UserDict import DictMixin\n\n    class OrderedDict(dict, DictMixin):\n\n        def __init__(self, *args, **kwds):\n            if len(args) > 1:\n                raise TypeError('expected at most 1 arguments, got %d' % len(args))\n            try:\n                self.__end\n            except AttributeError:\n                self.clear()\n            self.update(*args, **kwds)\n\n        def clear(self):\n            self.__end = end = []\n            end += [None, end, end]  # sentinel node for doubly linked list\n            self.__map = {}          # key --> [key, prev, next]\n            dict.clear(self)\n\n        def __setitem__(self, key, value):\n            if key not in self:\n                end = self.__end\n                curr = end[1]\n                curr[2] = end[1] = self.__map[key] = [key, curr, end]\n            dict.__setitem__(self, key, value)\n\n        def __delitem__(self, key):\n            dict.__delitem__(self, key)\n            key, prev, next_ = self.__map.pop(key)\n            prev[2] = next_\n            next_[1] = prev\n\n        def __iter__(self):\n            end = self.__end\n            curr = end[2]\n            while curr is not end:\n                yield curr[0]\n                curr = curr[2]\n\n        def __reversed__(self):\n            end = self.__end\n            curr = end[1]\n            while curr is not end:\n                yield curr[0]\n                curr = curr[1]\n\n        def popitem(self, last=True):\n            if not self:\n                raise KeyError('dictionary is empty')\n            if last:\n                key = reversed(self).next()\n            else:\n                key = iter(self).next()\n            value = self.pop(key)\n            return key, value\n\n        def __reduce__(self):\n            items = [[k, self[k]] for k in self]\n            tmp = self.__map, self.__end\n            del self.__map, self.__end\n            inst_dict = vars(self).copy()\n            self.__map, self.__end = tmp\n            if inst_dict:\n                return (self.__class__, (items,), inst_dict)\n            return self.__class__, (items,)\n\n        def keys(self):\n            return list(self)\n\n        setdefault = DictMixin.setdefault\n        update = DictMixin.update\n        pop = DictMixin.pop\n        values = DictMixin.values\n        items = DictMixin.items\n        iterkeys = DictMixin.iterkeys\n        itervalues = DictMixin.itervalues\n        iteritems = DictMixin.iteritems\n\n        def __repr__(self):\n            if not self:\n                return '%s()' % (self.__class__.__name__,)\n            return '%s(%r)' % (self.__class__.__name__, self.items())\n\n        def copy(self):\n            return self.__class__(self)\n\n        @classmethod\n        def fromkeys(cls, iterable, value=None):\n            d = cls()\n            for key in iterable:\n                d[key] = value\n            return d\n\n        def __eq__(self, other):\n            if isinstance(other, OrderedDict):\n                if len(self) != len(other):\n                    return False\n                for p, q in zip(self.items(), other.items()):\n                    if p != q:\n                        return False\n                return True\n            return dict.__eq__(self, other)\n\n        def __ne__(self, other):\n            return not self == other\n", "asn1crypto/x509.py": "# coding: utf-8\n\n\"\"\"\nASN.1 type classes for X.509 certificates. Exports the following items:\n\n - Attributes()\n - Certificate()\n - Extensions()\n - GeneralName()\n - GeneralNames()\n - Name()\n\nOther type classes are defined that help compose the types listed above.\n\"\"\"\n\nfrom __future__ import unicode_literals, division, absolute_import, print_function\n\nfrom contextlib import contextmanager\nfrom encodings import idna  # noqa\nimport hashlib\nimport re\nimport socket\nimport stringprep\nimport sys\nimport unicodedata\n\nfrom ._errors import unwrap\nfrom ._iri import iri_to_uri, uri_to_iri\nfrom ._ordereddict import OrderedDict\nfrom ._types import type_name, str_cls, byte_cls, bytes_to_list\nfrom .algos import AlgorithmIdentifier, AnyAlgorithmIdentifier, DigestAlgorithm, SignedDigestAlgorithm\nfrom .core import (\n    Any,\n    BitString,\n    BMPString,\n    Boolean,\n    Choice,\n    Concat,\n    Enumerated,\n    GeneralizedTime,\n    GeneralString,\n    IA5String,\n    Integer,\n    Null,\n    NumericString,\n    ObjectIdentifier,\n    OctetBitString,\n    OctetString,\n    ParsableOctetString,\n    PrintableString,\n    Sequence,\n    SequenceOf,\n    Set,\n    SetOf,\n    TeletexString,\n    UniversalString,\n    UTCTime,\n    UTF8String,\n    VisibleString,\n    VOID,\n)\nfrom .keys import PublicKeyInfo\nfrom .util import int_to_bytes, int_from_bytes, inet_ntop, inet_pton\n\n\n# The structures in this file are taken from https://tools.ietf.org/html/rfc5280\n# and a few other supplementary sources, mostly due to extra supported\n# extension and name OIDs\n\n\nclass DNSName(IA5String):\n\n    _encoding = 'idna'\n    _bad_tag = (12, 19)\n\n    def __ne__(self, other):\n        return not self == other\n\n    def __eq__(self, other):\n        \"\"\"\n        Equality as defined by https://tools.ietf.org/html/rfc5280#section-7.2\n\n        :param other:\n            Another DNSName object\n\n        :return:\n            A boolean\n        \"\"\"\n\n        if not isinstance(other, DNSName):\n            return False\n\n        return self.__unicode__().lower() == other.__unicode__().lower()\n\n    def set(self, value):\n        \"\"\"\n        Sets the value of the DNS name\n\n        :param value:\n            A unicode string\n        \"\"\"\n\n        if not isinstance(value, str_cls):\n            raise TypeError(unwrap(\n                '''\n                %s value must be a unicode string, not %s\n                ''',\n                type_name(self),\n                type_name(value)\n            ))\n\n        if value.startswith('.'):\n            encoded_value = b'.' + value[1:].encode(self._encoding)\n        else:\n            encoded_value = value.encode(self._encoding)\n\n        self._unicode = value\n        self.contents = encoded_value\n        self._header = None\n        if self._trailer != b'':\n            self._trailer = b''\n\n\nclass URI(IA5String):\n\n    def set(self, value):\n        \"\"\"\n        Sets the value of the string\n\n        :param value:\n            A unicode string\n        \"\"\"\n\n        if not isinstance(value, str_cls):\n            raise TypeError(unwrap(\n                '''\n                %s value must be a unicode string, not %s\n                ''',\n                type_name(self),\n                type_name(value)\n            ))\n\n        self._unicode = value\n        self.contents = iri_to_uri(value)\n        self._header = None\n        if self._trailer != b'':\n            self._trailer = b''\n\n    def __ne__(self, other):\n        return not self == other\n\n    def __eq__(self, other):\n        \"\"\"\n        Equality as defined by https://tools.ietf.org/html/rfc5280#section-7.4\n\n        :param other:\n            Another URI object\n\n        :return:\n            A boolean\n        \"\"\"\n\n        if not isinstance(other, URI):\n            return False\n\n        return iri_to_uri(self.native, True) == iri_to_uri(other.native, True)\n\n    def __unicode__(self):\n        \"\"\"\n        :return:\n            A unicode string\n        \"\"\"\n\n        if self.contents is None:\n            return ''\n        if self._unicode is None:\n            self._unicode = uri_to_iri(self._merge_chunks())\n        return self._unicode\n\n\nclass EmailAddress(IA5String):\n\n    _contents = None\n\n    # If the value has gone through the .set() method, thus normalizing it\n    _normalized = False\n\n    # In the wild we've seen this encoded as a UTF8String and PrintableString\n    _bad_tag = (12, 19)\n\n    @property\n    def contents(self):\n        \"\"\"\n        :return:\n            A byte string of the DER-encoded contents of the sequence\n        \"\"\"\n\n        return self._contents\n\n    @contents.setter\n    def contents(self, value):\n        \"\"\"\n        :param value:\n            A byte string of the DER-encoded contents of the sequence\n        \"\"\"\n\n        self._normalized = False\n        self._contents = value\n\n    def set(self, value):\n        \"\"\"\n        Sets the value of the string\n\n        :param value:\n            A unicode string\n        \"\"\"\n\n        if not isinstance(value, str_cls):\n            raise TypeError(unwrap(\n                '''\n                %s value must be a unicode string, not %s\n                ''',\n                type_name(self),\n                type_name(value)\n            ))\n\n        if value.find('@') != -1:\n            mailbox, hostname = value.rsplit('@', 1)\n            encoded_value = mailbox.encode('ascii') + b'@' + hostname.encode('idna')\n        else:\n            encoded_value = value.encode('ascii')\n\n        self._normalized = True\n        self._unicode = value\n        self.contents = encoded_value\n        self._header = None\n        if self._trailer != b'':\n            self._trailer = b''\n\n    def __unicode__(self):\n        \"\"\"\n        :return:\n            A unicode string\n        \"\"\"\n\n        # We've seen this in the wild as a PrintableString, and since ascii is a\n        # subset of cp1252, we use the later for decoding to be more user friendly\n        if self._unicode is None:\n            contents = self._merge_chunks()\n            if contents.find(b'@') == -1:\n                self._unicode = contents.decode('cp1252')\n            else:\n                mailbox, hostname = contents.rsplit(b'@', 1)\n                self._unicode = mailbox.decode('cp1252') + '@' + hostname.decode('idna')\n        return self._unicode\n\n    def __ne__(self, other):\n        return not self == other\n\n    def __eq__(self, other):\n        \"\"\"\n        Equality as defined by https://tools.ietf.org/html/rfc5280#section-7.5\n\n        :param other:\n            Another EmailAddress object\n\n        :return:\n            A boolean\n        \"\"\"\n\n        if not isinstance(other, EmailAddress):\n            return False\n\n        if not self._normalized:\n            self.set(self.native)\n        if not other._normalized:\n            other.set(other.native)\n\n        if self._contents.find(b'@') == -1 or other._contents.find(b'@') == -1:\n            return self._contents == other._contents\n\n        other_mailbox, other_hostname = other._contents.rsplit(b'@', 1)\n        mailbox, hostname = self._contents.rsplit(b'@', 1)\n\n        if mailbox != other_mailbox:\n            return False\n\n        if hostname.lower() != other_hostname.lower():\n            return False\n\n        return True\n\n\nclass IPAddress(OctetString):\n    def parse(self, spec=None, spec_params=None):\n        \"\"\"\n        This method is not applicable to IP addresses\n        \"\"\"\n\n        raise ValueError(unwrap(\n            '''\n            IP address values can not be parsed\n            '''\n        ))\n\n    def set(self, value):\n        \"\"\"\n        Sets the value of the object\n\n        :param value:\n            A unicode string containing an IPv4 address, IPv4 address with CIDR,\n            an IPv6 address or IPv6 address with CIDR\n        \"\"\"\n\n        if not isinstance(value, str_cls):\n            raise TypeError(unwrap(\n                '''\n                %s value must be a unicode string, not %s\n                ''',\n                type_name(self),\n                type_name(value)\n            ))\n\n        original_value = value\n\n        has_cidr = value.find('/') != -1\n        cidr = 0\n        if has_cidr:\n            parts = value.split('/', 1)\n            value = parts[0]\n            cidr = int(parts[1])\n            if cidr < 0:\n                raise ValueError(unwrap(\n                    '''\n                    %s value contains a CIDR range less than 0\n                    ''',\n                    type_name(self)\n                ))\n\n        if value.find(':') != -1:\n            family = socket.AF_INET6\n            if cidr > 128:\n                raise ValueError(unwrap(\n                    '''\n                    %s value contains a CIDR range bigger than 128, the maximum\n                    value for an IPv6 address\n                    ''',\n                    type_name(self)\n                ))\n            cidr_size = 128\n        else:\n            family = socket.AF_INET\n            if cidr > 32:\n                raise ValueError(unwrap(\n                    '''\n                    %s value contains a CIDR range bigger than 32, the maximum\n                    value for an IPv4 address\n                    ''',\n                    type_name(self)\n                ))\n            cidr_size = 32\n\n        cidr_bytes = b''\n        if has_cidr:\n            cidr_mask = '1' * cidr\n            cidr_mask += '0' * (cidr_size - len(cidr_mask))\n            cidr_bytes = int_to_bytes(int(cidr_mask, 2))\n            cidr_bytes = (b'\\x00' * ((cidr_size // 8) - len(cidr_bytes))) + cidr_bytes\n\n        self._native = original_value\n        self.contents = inet_pton(family, value) + cidr_bytes\n        self._bytes = self.contents\n        self._header = None\n        if self._trailer != b'':\n            self._trailer = b''\n\n    @property\n    def native(self):\n        \"\"\"\n        The native Python datatype representation of this value\n\n        :return:\n            A unicode string or None\n        \"\"\"\n\n        if self.contents is None:\n            return None\n\n        if self._native is None:\n            byte_string = self.__bytes__()\n            byte_len = len(byte_string)\n            value = None\n            cidr_int = None\n            if byte_len in set([32, 16]):\n                value = inet_ntop(socket.AF_INET6, byte_string[0:16])\n                if byte_len > 16:\n                    cidr_int = int_from_bytes(byte_string[16:])\n            elif byte_len in set([8, 4]):\n                value = inet_ntop(socket.AF_INET, byte_string[0:4])\n                if byte_len > 4:\n                    cidr_int = int_from_bytes(byte_string[4:])\n            if cidr_int is not None:\n                cidr_bits = '{0:b}'.format(cidr_int)\n                cidr = len(cidr_bits.rstrip('0'))\n                value = value + '/' + str_cls(cidr)\n            self._native = value\n        return self._native\n\n    def __ne__(self, other):\n        return not self == other\n\n    def __eq__(self, other):\n        \"\"\"\n        :param other:\n            Another IPAddress object\n\n        :return:\n            A boolean\n        \"\"\"\n\n        if not isinstance(other, IPAddress):\n            return False\n\n        return self.__bytes__() == other.__bytes__()\n\n\nclass Attribute(Sequence):\n    _fields = [\n        ('type', ObjectIdentifier),\n        ('values', SetOf, {'spec': Any}),\n    ]\n\n\nclass Attributes(SequenceOf):\n    _child_spec = Attribute\n\n\nclass KeyUsage(BitString):\n    _map = {\n        0: 'digital_signature',\n        1: 'non_repudiation',\n        2: 'key_encipherment',\n        3: 'data_encipherment',\n        4: 'key_agreement',\n        5: 'key_cert_sign',\n        6: 'crl_sign',\n        7: 'encipher_only',\n        8: 'decipher_only',\n    }\n\n\nclass PrivateKeyUsagePeriod(Sequence):\n    _fields = [\n        ('not_before', GeneralizedTime, {'implicit': 0, 'optional': True}),\n        ('not_after', GeneralizedTime, {'implicit': 1, 'optional': True}),\n    ]\n\n\nclass NotReallyTeletexString(TeletexString):\n    \"\"\"\n    OpenSSL (and probably some other libraries) puts ISO-8859-1\n    into TeletexString instead of ITU T.61. We use Windows-1252 when\n    decoding since it is a superset of ISO-8859-1, and less likely to\n    cause encoding issues, but we stay strict with encoding to prevent\n    us from creating bad data.\n    \"\"\"\n\n    _decoding_encoding = 'cp1252'\n\n    def __unicode__(self):\n        \"\"\"\n        :return:\n            A unicode string\n        \"\"\"\n\n        if self.contents is None:\n            return ''\n        if self._unicode is None:\n            self._unicode = self._merge_chunks().decode(self._decoding_encoding)\n        return self._unicode\n\n\n@contextmanager\ndef strict_teletex():\n    try:\n        NotReallyTeletexString._decoding_encoding = 'teletex'\n        yield\n    finally:\n        NotReallyTeletexString._decoding_encoding = 'cp1252'\n\n\nclass DirectoryString(Choice):\n    _alternatives = [\n        ('teletex_string', NotReallyTeletexString),\n        ('printable_string', PrintableString),\n        ('universal_string', UniversalString),\n        ('utf8_string', UTF8String),\n        ('bmp_string', BMPString),\n        # This is an invalid/bad alternative, but some broken certs use it\n        ('ia5_string', IA5String),\n    ]\n\n\nclass NameType(ObjectIdentifier):\n    _map = {\n        '2.5.4.3': 'common_name',\n        '2.5.4.4': 'surname',\n        '2.5.4.5': 'serial_number',\n        '2.5.4.6': 'country_name',\n        '2.5.4.7': 'locality_name',\n        '2.5.4.8': 'state_or_province_name',\n        '2.5.4.9': 'street_address',\n        '2.5.4.10': 'organization_name',\n        '2.5.4.11': 'organizational_unit_name',\n        '2.5.4.12': 'title',\n        '2.5.4.15': 'business_category',\n        '2.5.4.17': 'postal_code',\n        '2.5.4.20': 'telephone_number',\n        '2.5.4.41': 'name',\n        '2.5.4.42': 'given_name',\n        '2.5.4.43': 'initials',\n        '2.5.4.44': 'generation_qualifier',\n        '2.5.4.45': 'unique_identifier',\n        '2.5.4.46': 'dn_qualifier',\n        '2.5.4.65': 'pseudonym',\n        '2.5.4.97': 'organization_identifier',\n        # https://www.trustedcomputinggroup.org/wp-content/uploads/Credential_Profile_EK_V2.0_R14_published.pdf\n        '2.23.133.2.1': 'tpm_manufacturer',\n        '2.23.133.2.2': 'tpm_model',\n        '2.23.133.2.3': 'tpm_version',\n        '2.23.133.2.4': 'platform_manufacturer',\n        '2.23.133.2.5': 'platform_model',\n        '2.23.133.2.6': 'platform_version',\n        # https://tools.ietf.org/html/rfc2985#page-26\n        '1.2.840.113549.1.9.1': 'email_address',\n        # Page 10 of https://cabforum.org/wp-content/uploads/EV-V1_5_5.pdf\n        '1.3.6.1.4.1.311.60.2.1.1': 'incorporation_locality',\n        '1.3.6.1.4.1.311.60.2.1.2': 'incorporation_state_or_province',\n        '1.3.6.1.4.1.311.60.2.1.3': 'incorporation_country',\n        # https://tools.ietf.org/html/rfc4519#section-2.39\n        '0.9.2342.19200300.100.1.1': 'user_id',\n        # https://tools.ietf.org/html/rfc2247#section-4\n        '0.9.2342.19200300.100.1.25': 'domain_component',\n        # http://www.alvestrand.no/objectid/0.2.262.1.10.7.20.html\n        '0.2.262.1.10.7.20': 'name_distinguisher',\n    }\n\n    # This order is largely based on observed order seen in EV certs from\n    # Symantec and DigiCert. Some of the uncommon name-related fields are\n    # just placed in what seems like a reasonable order.\n    preferred_order = [\n        'incorporation_country',\n        'incorporation_state_or_province',\n        'incorporation_locality',\n        'business_category',\n        'serial_number',\n        'country_name',\n        'postal_code',\n        'state_or_province_name',\n        'locality_name',\n        'street_address',\n        'organization_name',\n        'organizational_unit_name',\n        'title',\n        'common_name',\n        'user_id',\n        'initials',\n        'generation_qualifier',\n        'surname',\n        'given_name',\n        'name',\n        'pseudonym',\n        'dn_qualifier',\n        'telephone_number',\n        'email_address',\n        'domain_component',\n        'name_distinguisher',\n        'organization_identifier',\n        'tpm_manufacturer',\n        'tpm_model',\n        'tpm_version',\n        'platform_manufacturer',\n        'platform_model',\n        'platform_version',\n    ]\n\n    @classmethod\n    def preferred_ordinal(cls, attr_name):\n        \"\"\"\n        Returns an ordering value for a particular attribute key.\n\n        Unrecognized attributes and OIDs will be sorted lexically at the end.\n\n        :return:\n            An orderable value.\n\n        \"\"\"\n\n        attr_name = cls.map(attr_name)\n        if attr_name in cls.preferred_order:\n            ordinal = cls.preferred_order.index(attr_name)\n        else:\n            ordinal = len(cls.preferred_order)\n\n        return (ordinal, attr_name)\n\n    @property\n    def human_friendly(self):\n        \"\"\"\n        :return:\n            A human-friendly unicode string to display to users\n        \"\"\"\n\n        return {\n            'common_name': 'Common Name',\n            'surname': 'Surname',\n            'serial_number': 'Serial Number',\n            'country_name': 'Country',\n            'locality_name': 'Locality',\n            'state_or_province_name': 'State/Province',\n            'street_address': 'Street Address',\n            'organization_name': 'Organization',\n            'organizational_unit_name': 'Organizational Unit',\n            'title': 'Title',\n            'business_category': 'Business Category',\n            'postal_code': 'Postal Code',\n            'telephone_number': 'Telephone Number',\n            'name': 'Name',\n            'given_name': 'Given Name',\n            'initials': 'Initials',\n            'generation_qualifier': 'Generation Qualifier',\n            'unique_identifier': 'Unique Identifier',\n            'dn_qualifier': 'DN Qualifier',\n            'pseudonym': 'Pseudonym',\n            'email_address': 'Email Address',\n            'incorporation_locality': 'Incorporation Locality',\n            'incorporation_state_or_province': 'Incorporation State/Province',\n            'incorporation_country': 'Incorporation Country',\n            'domain_component': 'Domain Component',\n            'name_distinguisher': 'Name Distinguisher',\n            'organization_identifier': 'Organization Identifier',\n            'tpm_manufacturer': 'TPM Manufacturer',\n            'tpm_model': 'TPM Model',\n            'tpm_version': 'TPM Version',\n            'platform_manufacturer': 'Platform Manufacturer',\n            'platform_model': 'Platform Model',\n            'platform_version': 'Platform Version',\n            'user_id': 'User ID',\n        }.get(self.native, self.native)\n\n\nclass NameTypeAndValue(Sequence):\n    _fields = [\n        ('type', NameType),\n        ('value', Any),\n    ]\n\n    _oid_pair = ('type', 'value')\n    _oid_specs = {\n        'common_name': DirectoryString,\n        'surname': DirectoryString,\n        'serial_number': DirectoryString,\n        'country_name': DirectoryString,\n        'locality_name': DirectoryString,\n        'state_or_province_name': DirectoryString,\n        'street_address': DirectoryString,\n        'organization_name': DirectoryString,\n        'organizational_unit_name': DirectoryString,\n        'title': DirectoryString,\n        'business_category': DirectoryString,\n        'postal_code': DirectoryString,\n        'telephone_number': PrintableString,\n        'name': DirectoryString,\n        'given_name': DirectoryString,\n        'initials': DirectoryString,\n        'generation_qualifier': DirectoryString,\n        'unique_identifier': OctetBitString,\n        'dn_qualifier': DirectoryString,\n        'pseudonym': DirectoryString,\n        # https://tools.ietf.org/html/rfc2985#page-26\n        'email_address': EmailAddress,\n        # Page 10 of https://cabforum.org/wp-content/uploads/EV-V1_5_5.pdf\n        'incorporation_locality': DirectoryString,\n        'incorporation_state_or_province': DirectoryString,\n        'incorporation_country': DirectoryString,\n        'domain_component': DNSName,\n        'name_distinguisher': DirectoryString,\n        'organization_identifier': DirectoryString,\n        'tpm_manufacturer': UTF8String,\n        'tpm_model': UTF8String,\n        'tpm_version': UTF8String,\n        'platform_manufacturer': UTF8String,\n        'platform_model': UTF8String,\n        'platform_version': UTF8String,\n        'user_id': DirectoryString,\n    }\n\n    _prepped = None\n\n    @property\n    def prepped_value(self):\n        \"\"\"\n        Returns the value after being processed by the internationalized string\n        preparation as specified by RFC 5280\n\n        :return:\n            A unicode string\n        \"\"\"\n\n        if self._prepped is None:\n            native = self['value'].native\n            if isinstance(native, str_cls):\n                self._prepped = self._ldap_string_prep(native)\n            else:\n                if isinstance(native, byte_cls):\n                    native = ' ' + native.decode('cp1252') + ' '\n                self._prepped = native\n        return self._prepped\n\n    def __ne__(self, other):\n        return not self == other\n\n    def __eq__(self, other):\n        \"\"\"\n        Equality as defined by https://tools.ietf.org/html/rfc5280#section-7.1\n\n        :param other:\n            Another NameTypeAndValue object\n\n        :return:\n            A boolean\n        \"\"\"\n\n        if not isinstance(other, NameTypeAndValue):\n            return False\n\n        if other['type'].native != self['type'].native:\n            return False\n\n        return other.prepped_value == self.prepped_value\n\n    def _ldap_string_prep(self, string):\n        \"\"\"\n        Implements the internationalized string preparation algorithm from\n        RFC 4518. https://tools.ietf.org/html/rfc4518#section-2\n\n        :param string:\n            A unicode string to prepare\n\n        :return:\n            A prepared unicode string, ready for comparison\n        \"\"\"\n\n        # Map step\n        string = re.sub('[\\u00ad\\u1806\\u034f\\u180b-\\u180d\\ufe0f-\\uff00\\ufffc]+', '', string)\n        string = re.sub('[\\u0009\\u000a\\u000b\\u000c\\u000d\\u0085]', ' ', string)\n        if sys.maxunicode == 0xffff:\n            # Some installs of Python 2.7 don't support 8-digit unicode escape\n            # ranges, so we have to break them into pieces\n            # Original was: \\U0001D173-\\U0001D17A and \\U000E0020-\\U000E007F\n            string = re.sub('\\ud834[\\udd73-\\udd7a]|\\udb40[\\udc20-\\udc7f]|\\U000e0001', '', string)\n        else:\n            string = re.sub('[\\U0001D173-\\U0001D17A\\U000E0020-\\U000E007F\\U000e0001]', '', string)\n        string = re.sub(\n            '[\\u0000-\\u0008\\u000e-\\u001f\\u007f-\\u0084\\u0086-\\u009f\\u06dd\\u070f\\u180e\\u200c-\\u200f'\n            '\\u202a-\\u202e\\u2060-\\u2063\\u206a-\\u206f\\ufeff\\ufff9-\\ufffb]+',\n            '',\n            string\n        )\n        string = string.replace('\\u200b', '')\n        string = re.sub('[\\u00a0\\u1680\\u2000-\\u200a\\u2028-\\u2029\\u202f\\u205f\\u3000]', ' ', string)\n\n        string = ''.join(map(stringprep.map_table_b2, string))\n\n        # Normalize step\n        string = unicodedata.normalize('NFKC', string)\n\n        # Prohibit step\n        for char in string:\n            if stringprep.in_table_a1(char):\n                raise ValueError(unwrap(\n                    '''\n                    X.509 Name objects may not contain unassigned code points\n                    '''\n                ))\n\n            if stringprep.in_table_c8(char):\n                raise ValueError(unwrap(\n                    '''\n                    X.509 Name objects may not contain change display or\n                    zzzzdeprecated characters\n                    '''\n                ))\n\n            if stringprep.in_table_c3(char):\n                raise ValueError(unwrap(\n                    '''\n                    X.509 Name objects may not contain private use characters\n                    '''\n                ))\n\n            if stringprep.in_table_c4(char):\n                raise ValueError(unwrap(\n                    '''\n                    X.509 Name objects may not contain non-character code points\n                    '''\n                ))\n\n            if stringprep.in_table_c5(char):\n                raise ValueError(unwrap(\n                    '''\n                    X.509 Name objects may not contain surrogate code points\n                    '''\n                ))\n\n            if char == '\\ufffd':\n                raise ValueError(unwrap(\n                    '''\n                    X.509 Name objects may not contain the replacement character\n                    '''\n                ))\n\n        # Check bidirectional step - here we ensure that we are not mixing\n        # left-to-right and right-to-left text in the string\n        has_r_and_al_cat = False\n        has_l_cat = False\n        for char in string:\n            if stringprep.in_table_d1(char):\n                has_r_and_al_cat = True\n            elif stringprep.in_table_d2(char):\n                has_l_cat = True\n\n        if has_r_and_al_cat:\n            first_is_r_and_al = stringprep.in_table_d1(string[0])\n            last_is_r_and_al = stringprep.in_table_d1(string[-1])\n\n            if has_l_cat or not first_is_r_and_al or not last_is_r_and_al:\n                raise ValueError(unwrap(\n                    '''\n                    X.509 Name object contains a malformed bidirectional\n                    sequence\n                    '''\n                ))\n\n        # Insignificant space handling step\n        string = ' ' + re.sub(' +', '  ', string).strip() + ' '\n\n        return string\n\n\nclass RelativeDistinguishedName(SetOf):\n    _child_spec = NameTypeAndValue\n\n    @property\n    def hashable(self):\n        \"\"\"\n        :return:\n            A unicode string that can be used as a dict key or in a set\n        \"\"\"\n\n        output = []\n        values = self._get_values(self)\n        for key in sorted(values.keys()):\n            output.append('%s: %s' % (key, values[key]))\n        # Unit separator is used here since the normalization process for\n        # values moves any such character, and the keys are all dotted integers\n        # or under_score_words\n        return '\\x1F'.join(output)\n\n    def __ne__(self, other):\n        return not self == other\n\n    def __eq__(self, other):\n        \"\"\"\n        Equality as defined by https://tools.ietf.org/html/rfc5280#section-7.1\n\n        :param other:\n            Another RelativeDistinguishedName object\n\n        :return:\n            A boolean\n        \"\"\"\n\n        if not isinstance(other, RelativeDistinguishedName):\n            return False\n\n        if len(self) != len(other):\n            return False\n\n        self_types = self._get_types(self)\n        other_types = self._get_types(other)\n\n        if self_types != other_types:\n            return False\n\n        self_values = self._get_values(self)\n        other_values = self._get_values(other)\n\n        for type_name_ in self_types:\n            if self_values[type_name_] != other_values[type_name_]:\n                return False\n\n        return True\n\n    def _get_types(self, rdn):\n        \"\"\"\n        Returns a set of types contained in an RDN\n\n        :param rdn:\n            A RelativeDistinguishedName object\n\n        :return:\n            A set object with unicode strings of NameTypeAndValue type field\n            values\n        \"\"\"\n\n        return set([ntv['type'].native for ntv in rdn])\n\n    def _get_values(self, rdn):\n        \"\"\"\n        Returns a dict of prepped values contained in an RDN\n\n        :param rdn:\n            A RelativeDistinguishedName object\n\n        :return:\n            A dict object with unicode strings of NameTypeAndValue value field\n            values that have been prepped for comparison\n        \"\"\"\n\n        output = {}\n        [output.update([(ntv['type'].native, ntv.prepped_value)]) for ntv in rdn]\n        return output\n\n\nclass RDNSequence(SequenceOf):\n    _child_spec = RelativeDistinguishedName\n\n    @property\n    def hashable(self):\n        \"\"\"\n        :return:\n            A unicode string that can be used as a dict key or in a set\n        \"\"\"\n\n        # Record separator is used here since the normalization process for\n        # values moves any such character, and the keys are all dotted integers\n        # or under_score_words\n        return '\\x1E'.join(rdn.hashable for rdn in self)\n\n    def __ne__(self, other):\n        return not self == other\n\n    def __eq__(self, other):\n        \"\"\"\n        Equality as defined by https://tools.ietf.org/html/rfc5280#section-7.1\n\n        :param other:\n            Another RDNSequence object\n\n        :return:\n            A boolean\n        \"\"\"\n\n        if not isinstance(other, RDNSequence):\n            return False\n\n        if len(self) != len(other):\n            return False\n\n        for index, self_rdn in enumerate(self):\n            if other[index] != self_rdn:\n                return False\n\n        return True\n\n\nclass Name(Choice):\n    _alternatives = [\n        ('', RDNSequence),\n    ]\n\n    _human_friendly = None\n    _sha1 = None\n    _sha256 = None\n\n    @classmethod\n    def build(cls, name_dict, use_printable=False):\n        \"\"\"\n        Creates a Name object from a dict of unicode string keys and values.\n        The keys should be from NameType._map, or a dotted-integer OID unicode\n        string.\n\n        :param name_dict:\n            A dict of name information, e.g. {\"common_name\": \"Will Bond\",\n            \"country_name\": \"US\", \"organization_name\": \"Codex Non Sufficit LC\"}\n\n        :param use_printable:\n            A bool - if PrintableString should be used for encoding instead of\n            UTF8String. This is for backwards compatibility with old software.\n\n        :return:\n            An x509.Name object\n        \"\"\"\n\n        rdns = []\n        if not use_printable:\n            encoding_name = 'utf8_string'\n            encoding_class = UTF8String\n        else:\n            encoding_name = 'printable_string'\n            encoding_class = PrintableString\n\n        # Sort the attributes according to NameType.preferred_order\n        name_dict = OrderedDict(\n            sorted(\n                name_dict.items(),\n                key=lambda item: NameType.preferred_ordinal(item[0])\n            )\n        )\n\n        for attribute_name, attribute_value in name_dict.items():\n            attribute_name = NameType.map(attribute_name)\n            attribute_class = NameTypeAndValue._oid_specs.get(attribute_name)\n            if not attribute_class:\n                raise ValueError(unwrap(\n                    '''\n                    No encoding specification found for %s\n                    ''',\n                    attribute_name\n                ))\n\n            if isinstance(attribute_value, attribute_class):\n                value = attribute_value\n\n            elif attribute_class is not DirectoryString:\n                value = attribute_class(attribute_value)\n\n            elif attribute_name in set(['dn_qualifier', 'country_name', 'serial_number']):\n                value = DirectoryString(\n                    name='printable_string',\n                    value=PrintableString(attribute_value)\n                )\n\n            else:\n                value = DirectoryString(\n                    name=encoding_name,\n                    value=encoding_class(attribute_value)\n                )\n\n            rdns.append(RelativeDistinguishedName([\n                NameTypeAndValue({\n                    'type': attribute_name,\n                    'value': value\n                })\n            ]))\n\n        return cls(name='', value=RDNSequence(rdns))\n\n    @property\n    def hashable(self):\n        \"\"\"\n        :return:\n            A unicode string that can be used as a dict key or in a set\n        \"\"\"\n\n        return self.chosen.hashable\n\n    def __len__(self):\n        return len(self.chosen)\n\n    def __ne__(self, other):\n        return not self == other\n\n    def __eq__(self, other):\n        \"\"\"\n        Equality as defined by https://tools.ietf.org/html/rfc5280#section-7.1\n\n        :param other:\n            Another Name object\n\n        :return:\n            A boolean\n        \"\"\"\n\n        if not isinstance(other, Name):\n            return False\n        return self.chosen == other.chosen\n\n    @property\n    def native(self):\n        if self._native is None:\n            self._native = OrderedDict()\n            for rdn in self.chosen.native:\n                for type_val in rdn:\n                    field_name = type_val['type']\n                    if field_name in self._native:\n                        existing = self._native[field_name]\n                        if not isinstance(existing, list):\n                            existing = self._native[field_name] = [existing]\n                        existing.append(type_val['value'])\n                    else:\n                        self._native[field_name] = type_val['value']\n        return self._native\n\n    @property\n    def human_friendly(self):\n        \"\"\"\n        :return:\n            A human-friendly unicode string containing the parts of the name\n        \"\"\"\n\n        if self._human_friendly is None:\n            data = OrderedDict()\n            last_field = None\n            for rdn in self.chosen:\n                for type_val in rdn:\n                    field_name = type_val['type'].human_friendly\n                    last_field = field_name\n                    if field_name in data:\n                        data[field_name] = [data[field_name]]\n                        data[field_name].append(type_val['value'])\n                    else:\n                        data[field_name] = type_val['value']\n            to_join = []\n            keys = data.keys()\n            if last_field == 'Country':\n                keys = reversed(list(keys))\n            for key in keys:\n                value = data[key]\n                native_value = self._recursive_humanize(value)\n                to_join.append('%s: %s' % (key, native_value))\n\n            has_comma = False\n            for element in to_join:\n                if element.find(',') != -1:\n                    has_comma = True\n                    break\n\n            separator = ', ' if not has_comma else '; '\n            self._human_friendly = separator.join(to_join[::-1])\n\n        return self._human_friendly\n\n    def _recursive_humanize(self, value):\n        \"\"\"\n        Recursively serializes data compiled from the RDNSequence\n\n        :param value:\n            An Asn1Value object, or a list of Asn1Value objects\n\n        :return:\n            A unicode string\n        \"\"\"\n\n        if isinstance(value, list):\n            return ', '.join(\n                reversed([self._recursive_humanize(sub_value) for sub_value in value])\n            )\n        return value.native\n\n    @property\n    def sha1(self):\n        \"\"\"\n        :return:\n            The SHA1 hash of the DER-encoded bytes of this name\n        \"\"\"\n\n        if self._sha1 is None:\n            self._sha1 = hashlib.sha1(self.dump()).digest()\n        return self._sha1\n\n    @property\n    def sha256(self):\n        \"\"\"\n        :return:\n            The SHA-256 hash of the DER-encoded bytes of this name\n        \"\"\"\n\n        if self._sha256 is None:\n            self._sha256 = hashlib.sha256(self.dump()).digest()\n        return self._sha256\n\n\nclass AnotherName(Sequence):\n    _fields = [\n        ('type_id', ObjectIdentifier),\n        ('value', Any, {'explicit': 0}),\n    ]\n\n\nclass CountryName(Choice):\n    class_ = 1\n    tag = 1\n\n    _alternatives = [\n        ('x121_dcc_code', NumericString),\n        ('iso_3166_alpha2_code', PrintableString),\n    ]\n\n\nclass AdministrationDomainName(Choice):\n    class_ = 1\n    tag = 2\n\n    _alternatives = [\n        ('numeric', NumericString),\n        ('printable', PrintableString),\n    ]\n\n\nclass PrivateDomainName(Choice):\n    _alternatives = [\n        ('numeric', NumericString),\n        ('printable', PrintableString),\n    ]\n\n\nclass PersonalName(Set):\n    _fields = [\n        ('surname', PrintableString, {'implicit': 0}),\n        ('given_name', PrintableString, {'implicit': 1, 'optional': True}),\n        ('initials', PrintableString, {'implicit': 2, 'optional': True}),\n        ('generation_qualifier', PrintableString, {'implicit': 3, 'optional': True}),\n    ]\n\n\nclass TeletexPersonalName(Set):\n    _fields = [\n        ('surname', TeletexString, {'implicit': 0}),\n        ('given_name', TeletexString, {'implicit': 1, 'optional': True}),\n        ('initials', TeletexString, {'implicit': 2, 'optional': True}),\n        ('generation_qualifier', TeletexString, {'implicit': 3, 'optional': True}),\n    ]\n\n\nclass OrganizationalUnitNames(SequenceOf):\n    _child_spec = PrintableString\n\n\nclass TeletexOrganizationalUnitNames(SequenceOf):\n    _child_spec = TeletexString\n\n\nclass BuiltInStandardAttributes(Sequence):\n    _fields = [\n        ('country_name', CountryName, {'optional': True}),\n        ('administration_domain_name', AdministrationDomainName, {'optional': True}),\n        ('network_address', NumericString, {'implicit': 0, 'optional': True}),\n        ('terminal_identifier', PrintableString, {'implicit': 1, 'optional': True}),\n        ('private_domain_name', PrivateDomainName, {'explicit': 2, 'optional': True}),\n        ('organization_name', PrintableString, {'implicit': 3, 'optional': True}),\n        ('numeric_user_identifier', NumericString, {'implicit': 4, 'optional': True}),\n        ('personal_name', PersonalName, {'implicit': 5, 'optional': True}),\n        ('organizational_unit_names', OrganizationalUnitNames, {'implicit': 6, 'optional': True}),\n    ]\n\n\nclass BuiltInDomainDefinedAttribute(Sequence):\n    _fields = [\n        ('type', PrintableString),\n        ('value', PrintableString),\n    ]\n\n\nclass BuiltInDomainDefinedAttributes(SequenceOf):\n    _child_spec = BuiltInDomainDefinedAttribute\n\n\nclass TeletexDomainDefinedAttribute(Sequence):\n    _fields = [\n        ('type', TeletexString),\n        ('value', TeletexString),\n    ]\n\n\nclass TeletexDomainDefinedAttributes(SequenceOf):\n    _child_spec = TeletexDomainDefinedAttribute\n\n\nclass PhysicalDeliveryCountryName(Choice):\n    _alternatives = [\n        ('x121_dcc_code', NumericString),\n        ('iso_3166_alpha2_code', PrintableString),\n    ]\n\n\nclass PostalCode(Choice):\n    _alternatives = [\n        ('numeric_code', NumericString),\n        ('printable_code', PrintableString),\n    ]\n\n\nclass PDSParameter(Set):\n    _fields = [\n        ('printable_string', PrintableString, {'optional': True}),\n        ('teletex_string', TeletexString, {'optional': True}),\n    ]\n\n\nclass PrintableAddress(SequenceOf):\n    _child_spec = PrintableString\n\n\nclass UnformattedPostalAddress(Set):\n    _fields = [\n        ('printable_address', PrintableAddress, {'optional': True}),\n        ('teletex_string', TeletexString, {'optional': True}),\n    ]\n\n\nclass E1634Address(Sequence):\n    _fields = [\n        ('number', NumericString, {'implicit': 0}),\n        ('sub_address', NumericString, {'implicit': 1, 'optional': True}),\n    ]\n\n\nclass NAddresses(SetOf):\n    _child_spec = OctetString\n\n\nclass PresentationAddress(Sequence):\n    _fields = [\n        ('p_selector', OctetString, {'explicit': 0, 'optional': True}),\n        ('s_selector', OctetString, {'explicit': 1, 'optional': True}),\n        ('t_selector', OctetString, {'explicit': 2, 'optional': True}),\n        ('n_addresses', NAddresses, {'explicit': 3}),\n    ]\n\n\nclass ExtendedNetworkAddress(Choice):\n    _alternatives = [\n        ('e163_4_address', E1634Address),\n        ('psap_address', PresentationAddress, {'implicit': 0})\n    ]\n\n\nclass TerminalType(Integer):\n    _map = {\n        3: 'telex',\n        4: 'teletex',\n        5: 'g3_facsimile',\n        6: 'g4_facsimile',\n        7: 'ia5_terminal',\n        8: 'videotex',\n    }\n\n\nclass ExtensionAttributeType(Integer):\n    _map = {\n        1: 'common_name',\n        2: 'teletex_common_name',\n        3: 'teletex_organization_name',\n        4: 'teletex_personal_name',\n        5: 'teletex_organization_unit_names',\n        6: 'teletex_domain_defined_attributes',\n        7: 'pds_name',\n        8: 'physical_delivery_country_name',\n        9: 'postal_code',\n        10: 'physical_delivery_office_name',\n        11: 'physical_delivery_office_number',\n        12: 'extension_of_address_components',\n        13: 'physical_delivery_personal_name',\n        14: 'physical_delivery_organization_name',\n        15: 'extension_physical_delivery_address_components',\n        16: 'unformatted_postal_address',\n        17: 'street_address',\n        18: 'post_office_box_address',\n        19: 'poste_restante_address',\n        20: 'unique_postal_name',\n        21: 'local_postal_attributes',\n        22: 'extended_network_address',\n        23: 'terminal_type',\n    }\n\n\nclass ExtensionAttribute(Sequence):\n    _fields = [\n        ('extension_attribute_type', ExtensionAttributeType, {'implicit': 0}),\n        ('extension_attribute_value', Any, {'explicit': 1}),\n    ]\n\n    _oid_pair = ('extension_attribute_type', 'extension_attribute_value')\n    _oid_specs = {\n        'common_name': PrintableString,\n        'teletex_common_name': TeletexString,\n        'teletex_organization_name': TeletexString,\n        'teletex_personal_name': TeletexPersonalName,\n        'teletex_organization_unit_names': TeletexOrganizationalUnitNames,\n        'teletex_domain_defined_attributes': TeletexDomainDefinedAttributes,\n        'pds_name': PrintableString,\n        'physical_delivery_country_name': PhysicalDeliveryCountryName,\n        'postal_code': PostalCode,\n        'physical_delivery_office_name': PDSParameter,\n        'physical_delivery_office_number': PDSParameter,\n        'extension_of_address_components': PDSParameter,\n        'physical_delivery_personal_name': PDSParameter,\n        'physical_delivery_organization_name': PDSParameter,\n        'extension_physical_delivery_address_components': PDSParameter,\n        'unformatted_postal_address': UnformattedPostalAddress,\n        'street_address': PDSParameter,\n        'post_office_box_address': PDSParameter,\n        'poste_restante_address': PDSParameter,\n        'unique_postal_name': PDSParameter,\n        'local_postal_attributes': PDSParameter,\n        'extended_network_address': ExtendedNetworkAddress,\n        'terminal_type': TerminalType,\n    }\n\n\nclass ExtensionAttributes(SequenceOf):\n    _child_spec = ExtensionAttribute\n\n\nclass ORAddress(Sequence):\n    _fields = [\n        ('built_in_standard_attributes', BuiltInStandardAttributes),\n        ('built_in_domain_defined_attributes', BuiltInDomainDefinedAttributes, {'optional': True}),\n        ('extension_attributes', ExtensionAttributes, {'optional': True}),\n    ]\n\n\nclass EDIPartyName(Sequence):\n    _fields = [\n        ('name_assigner', DirectoryString, {'implicit': 0, 'optional': True}),\n        ('party_name', DirectoryString, {'implicit': 1}),\n    ]\n\n\nclass GeneralName(Choice):\n    _alternatives = [\n        ('other_name', AnotherName, {'implicit': 0}),\n        ('rfc822_name', EmailAddress, {'implicit': 1}),\n        ('dns_name', DNSName, {'implicit': 2}),\n        ('x400_address', ORAddress, {'implicit': 3}),\n        ('directory_name', Name, {'explicit': 4}),\n        ('edi_party_name', EDIPartyName, {'implicit': 5}),\n        ('uniform_resource_identifier', URI, {'implicit': 6}),\n        ('ip_address', IPAddress, {'implicit': 7}),\n        ('registered_id', ObjectIdentifier, {'implicit': 8}),\n    ]\n\n    def __ne__(self, other):\n        return not self == other\n\n    def __eq__(self, other):\n        \"\"\"\n        Does not support other_name, x400_address or edi_party_name\n\n        :param other:\n            The other GeneralName to compare to\n\n        :return:\n            A boolean\n        \"\"\"\n\n        if self.name in ('other_name', 'x400_address', 'edi_party_name'):\n            raise ValueError(unwrap(\n                '''\n                Comparison is not supported for GeneralName objects of\n                choice %s\n                ''',\n                self.name\n            ))\n\n        if other.name in ('other_name', 'x400_address', 'edi_party_name'):\n            raise ValueError(unwrap(\n                '''\n                Comparison is not supported for GeneralName objects of choice\n                %s''',\n                other.name\n            ))\n\n        if self.name != other.name:\n            return False\n\n        return self.chosen == other.chosen\n\n\nclass GeneralNames(SequenceOf):\n    _child_spec = GeneralName\n\n\nclass Time(Choice):\n    _alternatives = [\n        ('utc_time', UTCTime),\n        ('general_time', GeneralizedTime),\n    ]\n\n\nclass Validity(Sequence):\n    _fields = [\n        ('not_before', Time),\n        ('not_after', Time),\n    ]\n\n\nclass BasicConstraints(Sequence):\n    _fields = [\n        ('ca', Boolean, {'default': False}),\n        ('path_len_constraint', Integer, {'optional': True}),\n    ]\n\n\nclass AuthorityKeyIdentifier(Sequence):\n    _fields = [\n        ('key_identifier', OctetString, {'implicit': 0, 'optional': True}),\n        ('authority_cert_issuer', GeneralNames, {'implicit': 1, 'optional': True}),\n        ('authority_cert_serial_number', Integer, {'implicit': 2, 'optional': True}),\n    ]\n\n\nclass DistributionPointName(Choice):\n    _alternatives = [\n        ('full_name', GeneralNames, {'implicit': 0}),\n        ('name_relative_to_crl_issuer', RelativeDistinguishedName, {'implicit': 1}),\n    ]\n\n\nclass ReasonFlags(BitString):\n    _map = {\n        0: 'unused',\n        1: 'key_compromise',\n        2: 'ca_compromise',\n        3: 'affiliation_changed',\n        4: 'superseded',\n        5: 'cessation_of_operation',\n        6: 'certificate_hold',\n        7: 'privilege_withdrawn',\n        8: 'aa_compromise',\n    }\n\n\nclass GeneralSubtree(Sequence):\n    _fields = [\n        ('base', GeneralName),\n        ('minimum', Integer, {'implicit': 0, 'default': 0}),\n        ('maximum', Integer, {'implicit': 1, 'optional': True}),\n    ]\n\n\nclass GeneralSubtrees(SequenceOf):\n    _child_spec = GeneralSubtree\n\n\nclass NameConstraints(Sequence):\n    _fields = [\n        ('permitted_subtrees', GeneralSubtrees, {'implicit': 0, 'optional': True}),\n        ('excluded_subtrees', GeneralSubtrees, {'implicit': 1, 'optional': True}),\n    ]\n\n\nclass DistributionPoint(Sequence):\n    _fields = [\n        ('distribution_point', DistributionPointName, {'explicit': 0, 'optional': True}),\n        ('reasons', ReasonFlags, {'implicit': 1, 'optional': True}),\n        ('crl_issuer', GeneralNames, {'implicit': 2, 'optional': True}),\n    ]\n\n    _url = False\n\n    @property\n    def url(self):\n        \"\"\"\n        :return:\n            None or a unicode string of the distribution point's URL\n        \"\"\"\n\n        if self._url is False:\n            self._url = None\n            name = self['distribution_point']\n            if name.name != 'full_name':\n                raise ValueError(unwrap(\n                    '''\n                    CRL distribution points that are relative to the issuer are\n                    not supported\n                    '''\n                ))\n\n            for general_name in name.chosen:\n                if general_name.name == 'uniform_resource_identifier':\n                    url = general_name.native\n                    if url.lower().startswith(('http://', 'https://', 'ldap://', 'ldaps://')):\n                        self._url = url\n                        break\n\n        return self._url\n\n\nclass CRLDistributionPoints(SequenceOf):\n    _child_spec = DistributionPoint\n\n\nclass DisplayText(Choice):\n    _alternatives = [\n        ('ia5_string', IA5String),\n        ('visible_string', VisibleString),\n        ('bmp_string', BMPString),\n        ('utf8_string', UTF8String),\n    ]\n\n\nclass NoticeNumbers(SequenceOf):\n    _child_spec = Integer\n\n\nclass NoticeReference(Sequence):\n    _fields = [\n        ('organization', DisplayText),\n        ('notice_numbers', NoticeNumbers),\n    ]\n\n\nclass UserNotice(Sequence):\n    _fields = [\n        ('notice_ref', NoticeReference, {'optional': True}),\n        ('explicit_text', DisplayText, {'optional': True}),\n    ]\n\n\nclass PolicyQualifierId(ObjectIdentifier):\n    _map = {\n        '1.3.6.1.5.5.7.2.1': 'certification_practice_statement',\n        '1.3.6.1.5.5.7.2.2': 'user_notice',\n    }\n\n\nclass PolicyQualifierInfo(Sequence):\n    _fields = [\n        ('policy_qualifier_id', PolicyQualifierId),\n        ('qualifier', Any),\n    ]\n\n    _oid_pair = ('policy_qualifier_id', 'qualifier')\n    _oid_specs = {\n        'certification_practice_statement': IA5String,\n        'user_notice': UserNotice,\n    }\n\n\nclass PolicyQualifierInfos(SequenceOf):\n    _child_spec = PolicyQualifierInfo\n\n\nclass PolicyIdentifier(ObjectIdentifier):\n    _map = {\n        '2.5.29.32.0': 'any_policy',\n    }\n\n\nclass PolicyInformation(Sequence):\n    _fields = [\n        ('policy_identifier', PolicyIdentifier),\n        ('policy_qualifiers', PolicyQualifierInfos, {'optional': True})\n    ]\n\n\nclass CertificatePolicies(SequenceOf):\n    _child_spec = PolicyInformation\n\n\nclass PolicyMapping(Sequence):\n    _fields = [\n        ('issuer_domain_policy', PolicyIdentifier),\n        ('subject_domain_policy', PolicyIdentifier),\n    ]\n\n\nclass PolicyMappings(SequenceOf):\n    _child_spec = PolicyMapping\n\n\nclass PolicyConstraints(Sequence):\n    _fields = [\n        ('require_explicit_policy', Integer, {'implicit': 0, 'optional': True}),\n        ('inhibit_policy_mapping', Integer, {'implicit': 1, 'optional': True}),\n    ]\n\n\nclass KeyPurposeId(ObjectIdentifier):\n    _map = {\n        # https://tools.ietf.org/html/rfc5280#page-45\n        '2.5.29.37.0': 'any_extended_key_usage',\n        '1.3.6.1.5.5.7.3.1': 'server_auth',\n        '1.3.6.1.5.5.7.3.2': 'client_auth',\n        '1.3.6.1.5.5.7.3.3': 'code_signing',\n        '1.3.6.1.5.5.7.3.4': 'email_protection',\n        '1.3.6.1.5.5.7.3.5': 'ipsec_end_system',\n        '1.3.6.1.5.5.7.3.6': 'ipsec_tunnel',\n        '1.3.6.1.5.5.7.3.7': 'ipsec_user',\n        '1.3.6.1.5.5.7.3.8': 'time_stamping',\n        '1.3.6.1.5.5.7.3.9': 'ocsp_signing',\n        # http://tools.ietf.org/html/rfc3029.html#page-9\n        '1.3.6.1.5.5.7.3.10': 'dvcs',\n        # http://tools.ietf.org/html/rfc6268.html#page-16\n        '1.3.6.1.5.5.7.3.13': 'eap_over_ppp',\n        '1.3.6.1.5.5.7.3.14': 'eap_over_lan',\n        # https://tools.ietf.org/html/rfc5055#page-76\n        '1.3.6.1.5.5.7.3.15': 'scvp_server',\n        '1.3.6.1.5.5.7.3.16': 'scvp_client',\n        # https://tools.ietf.org/html/rfc4945#page-31\n        '1.3.6.1.5.5.7.3.17': 'ipsec_ike',\n        # https://tools.ietf.org/html/rfc5415#page-38\n        '1.3.6.1.5.5.7.3.18': 'capwap_ac',\n        '1.3.6.1.5.5.7.3.19': 'capwap_wtp',\n        # https://tools.ietf.org/html/rfc5924#page-8\n        '1.3.6.1.5.5.7.3.20': 'sip_domain',\n        # https://tools.ietf.org/html/rfc6187#page-7\n        '1.3.6.1.5.5.7.3.21': 'secure_shell_client',\n        '1.3.6.1.5.5.7.3.22': 'secure_shell_server',\n        # https://tools.ietf.org/html/rfc6494#page-7\n        '1.3.6.1.5.5.7.3.23': 'send_router',\n        '1.3.6.1.5.5.7.3.24': 'send_proxied_router',\n        '1.3.6.1.5.5.7.3.25': 'send_owner',\n        '1.3.6.1.5.5.7.3.26': 'send_proxied_owner',\n        # https://tools.ietf.org/html/rfc6402#page-10\n        '1.3.6.1.5.5.7.3.27': 'cmc_ca',\n        '1.3.6.1.5.5.7.3.28': 'cmc_ra',\n        '1.3.6.1.5.5.7.3.29': 'cmc_archive',\n        # https://tools.ietf.org/html/draft-ietf-sidr-bgpsec-pki-profiles-15#page-6\n        '1.3.6.1.5.5.7.3.30': 'bgpspec_router',\n        # https://www.ietf.org/proceedings/44/I-D/draft-ietf-ipsec-pki-req-01.txt\n        '1.3.6.1.5.5.8.2.2': 'ike_intermediate',\n        # https://msdn.microsoft.com/en-us/library/windows/desktop/aa378132(v=vs.85).aspx\n        # and https://support.microsoft.com/en-us/kb/287547\n        '1.3.6.1.4.1.311.10.3.1': 'microsoft_trust_list_signing',\n        '1.3.6.1.4.1.311.10.3.2': 'microsoft_time_stamp_signing',\n        '1.3.6.1.4.1.311.10.3.3': 'microsoft_server_gated',\n        '1.3.6.1.4.1.311.10.3.3.1': 'microsoft_serialized',\n        '1.3.6.1.4.1.311.10.3.4': 'microsoft_efs',\n        '1.3.6.1.4.1.311.10.3.4.1': 'microsoft_efs_recovery',\n        '1.3.6.1.4.1.311.10.3.5': 'microsoft_whql',\n        '1.3.6.1.4.1.311.10.3.6': 'microsoft_nt5',\n        '1.3.6.1.4.1.311.10.3.7': 'microsoft_oem_whql',\n        '1.3.6.1.4.1.311.10.3.8': 'microsoft_embedded_nt',\n        '1.3.6.1.4.1.311.10.3.9': 'microsoft_root_list_signer',\n        '1.3.6.1.4.1.311.10.3.10': 'microsoft_qualified_subordination',\n        '1.3.6.1.4.1.311.10.3.11': 'microsoft_key_recovery',\n        '1.3.6.1.4.1.311.10.3.12': 'microsoft_document_signing',\n        '1.3.6.1.4.1.311.10.3.13': 'microsoft_lifetime_signing',\n        '1.3.6.1.4.1.311.10.3.14': 'microsoft_mobile_device_software',\n        # https://support.microsoft.com/en-us/help/287547/object-ids-associated-with-microsoft-cryptography\n        '1.3.6.1.4.1.311.20.2.2': 'microsoft_smart_card_logon',\n        # https://opensource.apple.com/source\n        #  - /Security/Security-57031.40.6/Security/libsecurity_keychain/lib/SecPolicy.cpp\n        #  - /libsecurity_cssm/libsecurity_cssm-36064/lib/oidsalg.c\n        '1.2.840.113635.100.1.2': 'apple_x509_basic',\n        '1.2.840.113635.100.1.3': 'apple_ssl',\n        '1.2.840.113635.100.1.4': 'apple_local_cert_gen',\n        '1.2.840.113635.100.1.5': 'apple_csr_gen',\n        '1.2.840.113635.100.1.6': 'apple_revocation_crl',\n        '1.2.840.113635.100.1.7': 'apple_revocation_ocsp',\n        '1.2.840.113635.100.1.8': 'apple_smime',\n        '1.2.840.113635.100.1.9': 'apple_eap',\n        '1.2.840.113635.100.1.10': 'apple_software_update_signing',\n        '1.2.840.113635.100.1.11': 'apple_ipsec',\n        '1.2.840.113635.100.1.12': 'apple_ichat',\n        '1.2.840.113635.100.1.13': 'apple_resource_signing',\n        '1.2.840.113635.100.1.14': 'apple_pkinit_client',\n        '1.2.840.113635.100.1.15': 'apple_pkinit_server',\n        '1.2.840.113635.100.1.16': 'apple_code_signing',\n        '1.2.840.113635.100.1.17': 'apple_package_signing',\n        '1.2.840.113635.100.1.18': 'apple_id_validation',\n        '1.2.840.113635.100.1.20': 'apple_time_stamping',\n        '1.2.840.113635.100.1.21': 'apple_revocation',\n        '1.2.840.113635.100.1.22': 'apple_passbook_signing',\n        '1.2.840.113635.100.1.23': 'apple_mobile_store',\n        '1.2.840.113635.100.1.24': 'apple_escrow_service',\n        '1.2.840.113635.100.1.25': 'apple_profile_signer',\n        '1.2.840.113635.100.1.26': 'apple_qa_profile_signer',\n        '1.2.840.113635.100.1.27': 'apple_test_mobile_store',\n        '1.2.840.113635.100.1.28': 'apple_otapki_signer',\n        '1.2.840.113635.100.1.29': 'apple_test_otapki_signer',\n        '1.2.840.113625.100.1.30': 'apple_id_validation_record_signing_policy',\n        '1.2.840.113625.100.1.31': 'apple_smp_encryption',\n        '1.2.840.113625.100.1.32': 'apple_test_smp_encryption',\n        '1.2.840.113635.100.1.33': 'apple_server_authentication',\n        '1.2.840.113635.100.1.34': 'apple_pcs_escrow_service',\n        # http://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.201-2.pdf\n        '2.16.840.1.101.3.6.8': 'piv_card_authentication',\n        '2.16.840.1.101.3.6.7': 'piv_content_signing',\n        # https://tools.ietf.org/html/rfc4556.html\n        '1.3.6.1.5.2.3.4': 'pkinit_kpclientauth',\n        '1.3.6.1.5.2.3.5': 'pkinit_kpkdc',\n        # https://www.adobe.com/devnet-docs/acrobatetk/tools/DigSig/changes.html\n        '1.2.840.113583.1.1.5': 'adobe_authentic_documents_trust',\n        # https://www.idmanagement.gov/wp-content/uploads/sites/1171/uploads/fpki-pivi-cert-profiles.pdf\n        '2.16.840.1.101.3.8.7': 'fpki_pivi_content_signing'\n    }\n\n\nclass ExtKeyUsageSyntax(SequenceOf):\n    _child_spec = KeyPurposeId\n\n\nclass AccessMethod(ObjectIdentifier):\n    _map = {\n        '1.3.6.1.5.5.7.48.1': 'ocsp',\n        '1.3.6.1.5.5.7.48.2': 'ca_issuers',\n        '1.3.6.1.5.5.7.48.3': 'time_stamping',\n        '1.3.6.1.5.5.7.48.5': 'ca_repository',\n    }\n\n\nclass AccessDescription(Sequence):\n    _fields = [\n        ('access_method', AccessMethod),\n        ('access_location', GeneralName),\n    ]\n\n\nclass AuthorityInfoAccessSyntax(SequenceOf):\n    _child_spec = AccessDescription\n\n\nclass SubjectInfoAccessSyntax(SequenceOf):\n    _child_spec = AccessDescription\n\n\n# https://tools.ietf.org/html/rfc7633\nclass Features(SequenceOf):\n    _child_spec = Integer\n\n\nclass EntrustVersionInfo(Sequence):\n    _fields = [\n        ('entrust_vers', GeneralString),\n        ('entrust_info_flags', BitString)\n    ]\n\n\nclass NetscapeCertificateType(BitString):\n    _map = {\n        0: 'ssl_client',\n        1: 'ssl_server',\n        2: 'email',\n        3: 'object_signing',\n        4: 'reserved',\n        5: 'ssl_ca',\n        6: 'email_ca',\n        7: 'object_signing_ca',\n    }\n\n\nclass Version(Integer):\n    _map = {\n        0: 'v1',\n        1: 'v2',\n        2: 'v3',\n    }\n\n\nclass TPMSpecification(Sequence):\n    _fields = [\n        ('family', UTF8String),\n        ('level', Integer),\n        ('revision', Integer),\n    ]\n\n\nclass SetOfTPMSpecification(SetOf):\n    _child_spec = TPMSpecification\n\n\nclass TCGSpecificationVersion(Sequence):\n    _fields = [\n        ('major_version', Integer),\n        ('minor_version', Integer),\n        ('revision', Integer),\n    ]\n\n\nclass TCGPlatformSpecification(Sequence):\n    _fields = [\n        ('version', TCGSpecificationVersion),\n        ('platform_class', OctetString),\n    ]\n\n\nclass SetOfTCGPlatformSpecification(SetOf):\n    _child_spec = TCGPlatformSpecification\n\n\nclass EKGenerationType(Enumerated):\n    _map = {\n        0: 'internal',\n        1: 'injected',\n        2: 'internal_revocable',\n        3: 'injected_revocable',\n    }\n\n\nclass EKGenerationLocation(Enumerated):\n    _map = {\n        0: 'tpm_manufacturer',\n        1: 'platform_manufacturer',\n        2: 'ek_cert_signer',\n    }\n\n\nclass EKCertificateGenerationLocation(Enumerated):\n    _map = {\n        0: 'tpm_manufacturer',\n        1: 'platform_manufacturer',\n        2: 'ek_cert_signer',\n    }\n\n\nclass EvaluationAssuranceLevel(Enumerated):\n    _map = {\n        1: 'level1',\n        2: 'level2',\n        3: 'level3',\n        4: 'level4',\n        5: 'level5',\n        6: 'level6',\n        7: 'level7',\n    }\n\n\nclass EvaluationStatus(Enumerated):\n    _map = {\n        0: 'designed_to_meet',\n        1: 'evaluation_in_progress',\n        2: 'evaluation_completed',\n    }\n\n\nclass StrengthOfFunction(Enumerated):\n    _map = {\n        0: 'basic',\n        1: 'medium',\n        2: 'high',\n    }\n\n\nclass URIReference(Sequence):\n    _fields = [\n        ('uniform_resource_identifier', IA5String),\n        ('hash_algorithm', DigestAlgorithm, {'optional': True}),\n        ('hash_value', BitString, {'optional': True}),\n    ]\n\n\nclass CommonCriteriaMeasures(Sequence):\n    _fields = [\n        ('version', IA5String),\n        ('assurance_level', EvaluationAssuranceLevel),\n        ('evaluation_status', EvaluationStatus),\n        ('plus', Boolean, {'default': False}),\n        ('strengh_of_function', StrengthOfFunction, {'implicit': 0, 'optional': True}),\n        ('profile_oid', ObjectIdentifier, {'implicit': 1, 'optional': True}),\n        ('profile_url', URIReference, {'implicit': 2, 'optional': True}),\n        ('target_oid', ObjectIdentifier, {'implicit': 3, 'optional': True}),\n        ('target_uri', URIReference, {'implicit': 4, 'optional': True}),\n    ]\n\n\nclass SecurityLevel(Enumerated):\n    _map = {\n        1: 'level1',\n        2: 'level2',\n        3: 'level3',\n        4: 'level4',\n    }\n\n\nclass FIPSLevel(Sequence):\n    _fields = [\n        ('version', IA5String),\n        ('level', SecurityLevel),\n        ('plus', Boolean, {'default': False}),\n    ]\n\n\nclass TPMSecurityAssertions(Sequence):\n    _fields = [\n        ('version', Version, {'default': 'v1'}),\n        ('field_upgradable', Boolean, {'default': False}),\n        ('ek_generation_type', EKGenerationType, {'implicit': 0, 'optional': True}),\n        ('ek_generation_location', EKGenerationLocation, {'implicit': 1, 'optional': True}),\n        ('ek_certificate_generation_location', EKCertificateGenerationLocation, {'implicit': 2, 'optional': True}),\n        ('cc_info', CommonCriteriaMeasures, {'implicit': 3, 'optional': True}),\n        ('fips_level', FIPSLevel, {'implicit': 4, 'optional': True}),\n        ('iso_9000_certified', Boolean, {'implicit': 5, 'default': False}),\n        ('iso_9000_uri', IA5String, {'optional': True}),\n    ]\n\n\nclass SetOfTPMSecurityAssertions(SetOf):\n    _child_spec = TPMSecurityAssertions\n\n\nclass SubjectDirectoryAttributeId(ObjectIdentifier):\n    _map = {\n        # https://tools.ietf.org/html/rfc2256#page-11\n        '2.5.4.52': 'supported_algorithms',\n        # https://www.trustedcomputinggroup.org/wp-content/uploads/Credential_Profile_EK_V2.0_R14_published.pdf\n        '2.23.133.2.16': 'tpm_specification',\n        '2.23.133.2.17': 'tcg_platform_specification',\n        '2.23.133.2.18': 'tpm_security_assertions',\n        # https://tools.ietf.org/html/rfc3739#page-18\n        '1.3.6.1.5.5.7.9.1': 'pda_date_of_birth',\n        '1.3.6.1.5.5.7.9.2': 'pda_place_of_birth',\n        '1.3.6.1.5.5.7.9.3': 'pda_gender',\n        '1.3.6.1.5.5.7.9.4': 'pda_country_of_citizenship',\n        '1.3.6.1.5.5.7.9.5': 'pda_country_of_residence',\n        # https://holtstrom.com/michael/tools/asn1decoder.php\n        '1.2.840.113533.7.68.29': 'entrust_user_role',\n    }\n\n\nclass SetOfGeneralizedTime(SetOf):\n    _child_spec = GeneralizedTime\n\n\nclass SetOfDirectoryString(SetOf):\n    _child_spec = DirectoryString\n\n\nclass SetOfPrintableString(SetOf):\n    _child_spec = PrintableString\n\n\nclass SupportedAlgorithm(Sequence):\n    _fields = [\n        ('algorithm_identifier', AnyAlgorithmIdentifier),\n        ('intended_usage', KeyUsage, {'explicit': 0, 'optional': True}),\n        ('intended_certificate_policies', CertificatePolicies, {'explicit': 1, 'optional': True}),\n    ]\n\n\nclass SetOfSupportedAlgorithm(SetOf):\n    _child_spec = SupportedAlgorithm\n\n\nclass SubjectDirectoryAttribute(Sequence):\n    _fields = [\n        ('type', SubjectDirectoryAttributeId),\n        ('values', Any),\n    ]\n\n    _oid_pair = ('type', 'values')\n    _oid_specs = {\n        'supported_algorithms': SetOfSupportedAlgorithm,\n        'tpm_specification': SetOfTPMSpecification,\n        'tcg_platform_specification': SetOfTCGPlatformSpecification,\n        'tpm_security_assertions': SetOfTPMSecurityAssertions,\n        'pda_date_of_birth': SetOfGeneralizedTime,\n        'pda_place_of_birth': SetOfDirectoryString,\n        'pda_gender': SetOfPrintableString,\n        'pda_country_of_citizenship': SetOfPrintableString,\n        'pda_country_of_residence': SetOfPrintableString,\n    }\n\n    def _values_spec(self):\n        type_ = self['type'].native\n        if type_ in self._oid_specs:\n            return self._oid_specs[type_]\n        return SetOf\n\n    _spec_callbacks = {\n        'values': _values_spec\n    }\n\n\nclass SubjectDirectoryAttributes(SequenceOf):\n    _child_spec = SubjectDirectoryAttribute\n\n\nclass ExtensionId(ObjectIdentifier):\n    _map = {\n        '2.5.29.9': 'subject_directory_attributes',\n        '2.5.29.14': 'key_identifier',\n        '2.5.29.15': 'key_usage',\n        '2.5.29.16': 'private_key_usage_period',\n        '2.5.29.17': 'subject_alt_name',\n        '2.5.29.18': 'issuer_alt_name',\n        '2.5.29.19': 'basic_constraints',\n        '2.5.29.30': 'name_constraints',\n        '2.5.29.31': 'crl_distribution_points',\n        '2.5.29.32': 'certificate_policies',\n        '2.5.29.33': 'policy_mappings',\n        '2.5.29.35': 'authority_key_identifier',\n        '2.5.29.36': 'policy_constraints',\n        '2.5.29.37': 'extended_key_usage',\n        '2.5.29.46': 'freshest_crl',\n        '2.5.29.54': 'inhibit_any_policy',\n        '1.3.6.1.5.5.7.1.1': 'authority_information_access',\n        '1.3.6.1.5.5.7.1.11': 'subject_information_access',\n        # https://tools.ietf.org/html/rfc7633\n        '1.3.6.1.5.5.7.1.24': 'tls_feature',\n        '1.3.6.1.5.5.7.48.1.5': 'ocsp_no_check',\n        '1.2.840.113533.7.65.0': 'entrust_version_extension',\n        '2.16.840.1.113730.1.1': 'netscape_certificate_type',\n        # https://tools.ietf.org/html/rfc6962.html#page-14\n        '1.3.6.1.4.1.11129.2.4.2': 'signed_certificate_timestamp_list',\n        # https://docs.microsoft.com/en-us/openspecs/windows_protocols/ms-wcce/3aec3e50-511a-42f9-a5d5-240af503e470\n        '1.3.6.1.4.1.311.20.2': 'microsoft_enroll_certtype',\n    }\n\n\nclass Extension(Sequence):\n    _fields = [\n        ('extn_id', ExtensionId),\n        ('critical', Boolean, {'default': False}),\n        ('extn_value', ParsableOctetString),\n    ]\n\n    _oid_pair = ('extn_id', 'extn_value')\n    _oid_specs = {\n        'subject_directory_attributes': SubjectDirectoryAttributes,\n        'key_identifier': OctetString,\n        'key_usage': KeyUsage,\n        'private_key_usage_period': PrivateKeyUsagePeriod,\n        'subject_alt_name': GeneralNames,\n        'issuer_alt_name': GeneralNames,\n        'basic_constraints': BasicConstraints,\n        'name_constraints': NameConstraints,\n        'crl_distribution_points': CRLDistributionPoints,\n        'certificate_policies': CertificatePolicies,\n        'policy_mappings': PolicyMappings,\n        'authority_key_identifier': AuthorityKeyIdentifier,\n        'policy_constraints': PolicyConstraints,\n        'extended_key_usage': ExtKeyUsageSyntax,\n        'freshest_crl': CRLDistributionPoints,\n        'inhibit_any_policy': Integer,\n        'authority_information_access': AuthorityInfoAccessSyntax,\n        'subject_information_access': SubjectInfoAccessSyntax,\n        'tls_feature': Features,\n        'ocsp_no_check': Null,\n        'entrust_version_extension': EntrustVersionInfo,\n        'netscape_certificate_type': NetscapeCertificateType,\n        'signed_certificate_timestamp_list': OctetString,\n        # Not UTF8String as Microsofts docs claim, see:\n        # https://www.alvestrand.no/objectid/1.3.6.1.4.1.311.20.2.html\n        'microsoft_enroll_certtype': BMPString,\n    }\n\n\nclass Extensions(SequenceOf):\n    _child_spec = Extension\n\n\nclass TbsCertificate(Sequence):\n    _fields = [\n        ('version', Version, {'explicit': 0, 'default': 'v1'}),\n        ('serial_number', Integer),\n        ('signature', SignedDigestAlgorithm),\n        ('issuer', Name),\n        ('validity', Validity),\n        ('subject', Name),\n        ('subject_public_key_info', PublicKeyInfo),\n        ('issuer_unique_id', OctetBitString, {'implicit': 1, 'optional': True}),\n        ('subject_unique_id', OctetBitString, {'implicit': 2, 'optional': True}),\n        ('extensions', Extensions, {'explicit': 3, 'optional': True}),\n    ]\n\n\nclass Certificate(Sequence):\n    _fields = [\n        ('tbs_certificate', TbsCertificate),\n        ('signature_algorithm', SignedDigestAlgorithm),\n        ('signature_value', OctetBitString),\n    ]\n\n    _processed_extensions = False\n    _critical_extensions = None\n    _subject_directory_attributes_value = None\n    _key_identifier_value = None\n    _key_usage_value = None\n    _subject_alt_name_value = None\n    _issuer_alt_name_value = None\n    _basic_constraints_value = None\n    _name_constraints_value = None\n    _crl_distribution_points_value = None\n    _certificate_policies_value = None\n    _policy_mappings_value = None\n    _authority_key_identifier_value = None\n    _policy_constraints_value = None\n    _freshest_crl_value = None\n    _inhibit_any_policy_value = None\n    _extended_key_usage_value = None\n    _authority_information_access_value = None\n    _subject_information_access_value = None\n    _private_key_usage_period_value = None\n    _tls_feature_value = None\n    _ocsp_no_check_value = None\n    _issuer_serial = None\n    _authority_issuer_serial = False\n    _crl_distribution_points = None\n    _delta_crl_distribution_points = None\n    _valid_domains = None\n    _valid_ips = None\n    _self_issued = None\n    _self_signed = None\n    _sha1 = None\n    _sha256 = None\n\n    def _set_extensions(self):\n        \"\"\"\n        Sets common named extensions to private attributes and creates a list\n        of critical extensions\n        \"\"\"\n\n        self._critical_extensions = set()\n\n        for extension in self['tbs_certificate']['extensions']:\n            name = extension['extn_id'].native\n            attribute_name = '_%s_value' % name\n            if hasattr(self, attribute_name):\n                setattr(self, attribute_name, extension['extn_value'].parsed)\n            if extension['critical'].native:\n                self._critical_extensions.add(name)\n\n        self._processed_extensions = True\n\n    @property\n    def critical_extensions(self):\n        \"\"\"\n        Returns a set of the names (or OID if not a known extension) of the\n        extensions marked as critical\n\n        :return:\n            A set of unicode strings\n        \"\"\"\n\n        if not self._processed_extensions:\n            self._set_extensions()\n        return self._critical_extensions\n\n    @property\n    def private_key_usage_period_value(self):\n        \"\"\"\n        This extension is used to constrain the period over which the subject\n        private key may be used\n\n        :return:\n            None or a PrivateKeyUsagePeriod object\n        \"\"\"\n\n        if not self._processed_extensions:\n            self._set_extensions()\n        return self._private_key_usage_period_value\n\n    @property\n    def subject_directory_attributes_value(self):\n        \"\"\"\n        This extension is used to contain additional identification attributes\n        about the subject.\n\n        :return:\n            None or a SubjectDirectoryAttributes object\n        \"\"\"\n\n        if not self._processed_extensions:\n            self._set_extensions()\n        return self._subject_directory_attributes_value\n\n    @property\n    def key_identifier_value(self):\n        \"\"\"\n        This extension is used to help in creating certificate validation paths.\n        It contains an identifier that should generally, but is not guaranteed\n        to, be unique.\n\n        :return:\n            None or an OctetString object\n        \"\"\"\n\n        if not self._processed_extensions:\n            self._set_extensions()\n        return self._key_identifier_value\n\n    @property\n    def key_usage_value(self):\n        \"\"\"\n        This extension is used to define the purpose of the public key\n        contained within the certificate.\n\n        :return:\n            None or a KeyUsage\n        \"\"\"\n\n        if not self._processed_extensions:\n            self._set_extensions()\n        return self._key_usage_value\n\n    @property\n    def subject_alt_name_value(self):\n        \"\"\"\n        This extension allows for additional names to be associate with the\n        subject of the certificate. While it may contain a whole host of\n        possible names, it is usually used to allow certificates to be used\n        with multiple different domain names.\n\n        :return:\n            None or a GeneralNames object\n        \"\"\"\n\n        if not self._processed_extensions:\n            self._set_extensions()\n        return self._subject_alt_name_value\n\n    @property\n    def issuer_alt_name_value(self):\n        \"\"\"\n        This extension allows associating one or more alternative names with\n        the issuer of the certificate.\n\n        :return:\n            None or an x509.GeneralNames object\n        \"\"\"\n\n        if not self._processed_extensions:\n            self._set_extensions()\n        return self._issuer_alt_name_value\n\n    @property\n    def basic_constraints_value(self):\n        \"\"\"\n        This extension is used to determine if the subject of the certificate\n        is a CA, and if so, what the maximum number of intermediate CA certs\n        after this are, before an end-entity certificate is found.\n\n        :return:\n            None or a BasicConstraints object\n        \"\"\"\n\n        if not self._processed_extensions:\n            self._set_extensions()\n        return self._basic_constraints_value\n\n    @property\n    def name_constraints_value(self):\n        \"\"\"\n        This extension is used in CA certificates, and is used to limit the\n        possible names of certificates issued.\n\n        :return:\n            None or a NameConstraints object\n        \"\"\"\n\n        if not self._processed_extensions:\n            self._set_extensions()\n        return self._name_constraints_value\n\n    @property\n    def crl_distribution_points_value(self):\n        \"\"\"\n        This extension is used to help in locating the CRL for this certificate.\n\n        :return:\n            None or a CRLDistributionPoints object\n            extension\n        \"\"\"\n\n        if not self._processed_extensions:\n            self._set_extensions()\n        return self._crl_distribution_points_value\n\n    @property\n    def certificate_policies_value(self):\n        \"\"\"\n        This extension defines policies in CA certificates under which\n        certificates may be issued. In end-entity certificates, the inclusion\n        of a policy indicates the issuance of the certificate follows the\n        policy.\n\n        :return:\n            None or a CertificatePolicies object\n        \"\"\"\n\n        if not self._processed_extensions:\n            self._set_extensions()\n        return self._certificate_policies_value\n\n    @property\n    def policy_mappings_value(self):\n        \"\"\"\n        This extension allows mapping policy OIDs to other OIDs. This is used\n        to allow different policies to be treated as equivalent in the process\n        of validation.\n\n        :return:\n            None or a PolicyMappings object\n        \"\"\"\n\n        if not self._processed_extensions:\n            self._set_extensions()\n        return self._policy_mappings_value\n\n    @property\n    def authority_key_identifier_value(self):\n        \"\"\"\n        This extension helps in identifying the public key with which to\n        validate the authenticity of the certificate.\n\n        :return:\n            None or an AuthorityKeyIdentifier object\n        \"\"\"\n\n        if not self._processed_extensions:\n            self._set_extensions()\n        return self._authority_key_identifier_value\n\n    @property\n    def policy_constraints_value(self):\n        \"\"\"\n        This extension is used to control if policy mapping is allowed and\n        when policies are required.\n\n        :return:\n            None or a PolicyConstraints object\n        \"\"\"\n\n        if not self._processed_extensions:\n            self._set_extensions()\n        return self._policy_constraints_value\n\n    @property\n    def freshest_crl_value(self):\n        \"\"\"\n        This extension is used to help locate any available delta CRLs\n\n        :return:\n            None or an CRLDistributionPoints object\n        \"\"\"\n\n        if not self._processed_extensions:\n            self._set_extensions()\n        return self._freshest_crl_value\n\n    @property\n    def inhibit_any_policy_value(self):\n        \"\"\"\n        This extension is used to prevent mapping of the any policy to\n        specific requirements\n\n        :return:\n            None or a Integer object\n        \"\"\"\n\n        if not self._processed_extensions:\n            self._set_extensions()\n        return self._inhibit_any_policy_value\n\n    @property\n    def extended_key_usage_value(self):\n        \"\"\"\n        This extension is used to define additional purposes for the public key\n        beyond what is contained in the basic constraints.\n\n        :return:\n            None or an ExtKeyUsageSyntax object\n        \"\"\"\n\n        if not self._processed_extensions:\n            self._set_extensions()\n        return self._extended_key_usage_value\n\n    @property\n    def authority_information_access_value(self):\n        \"\"\"\n        This extension is used to locate the CA certificate used to sign this\n        certificate, or the OCSP responder for this certificate.\n\n        :return:\n            None or an AuthorityInfoAccessSyntax object\n        \"\"\"\n\n        if not self._processed_extensions:\n            self._set_extensions()\n        return self._authority_information_access_value\n\n    @property\n    def subject_information_access_value(self):\n        \"\"\"\n        This extension is used to access information about the subject of this\n        certificate.\n\n        :return:\n            None or a SubjectInfoAccessSyntax object\n        \"\"\"\n\n        if not self._processed_extensions:\n            self._set_extensions()\n        return self._subject_information_access_value\n\n    @property\n    def tls_feature_value(self):\n        \"\"\"\n        This extension is used to list the TLS features a server must respond\n        with if a client initiates a request supporting them.\n\n        :return:\n            None or a Features object\n        \"\"\"\n\n        if not self._processed_extensions:\n            self._set_extensions()\n        return self._tls_feature_value\n\n    @property\n    def ocsp_no_check_value(self):\n        \"\"\"\n        This extension is used on certificates of OCSP responders, indicating\n        that revocation information for the certificate should never need to\n        be verified, thus preventing possible loops in path validation.\n\n        :return:\n            None or a Null object (if present)\n        \"\"\"\n\n        if not self._processed_extensions:\n            self._set_extensions()\n        return self._ocsp_no_check_value\n\n    @property\n    def signature(self):\n        \"\"\"\n        :return:\n            A byte string of the signature\n        \"\"\"\n\n        return self['signature_value'].native\n\n    @property\n    def signature_algo(self):\n        \"\"\"\n        :return:\n            A unicode string of \"rsassa_pkcs1v15\", \"rsassa_pss\", \"dsa\", \"ecdsa\"\n        \"\"\"\n\n        return self['signature_algorithm'].signature_algo\n\n    @property\n    def hash_algo(self):\n        \"\"\"\n        :return:\n            A unicode string of \"md2\", \"md5\", \"sha1\", \"sha224\", \"sha256\",\n            \"sha384\", \"sha512\", \"sha512_224\", \"sha512_256\"\n        \"\"\"\n\n        return self['signature_algorithm'].hash_algo\n\n    @property\n    def public_key(self):\n        \"\"\"\n        :return:\n            The PublicKeyInfo object for this certificate\n        \"\"\"\n\n        return self['tbs_certificate']['subject_public_key_info']\n\n    @property\n    def subject(self):\n        \"\"\"\n        :return:\n            The Name object for the subject of this certificate\n        \"\"\"\n\n        return self['tbs_certificate']['subject']\n\n    @property\n    def issuer(self):\n        \"\"\"\n        :return:\n            The Name object for the issuer of this certificate\n        \"\"\"\n\n        return self['tbs_certificate']['issuer']\n\n    @property\n    def serial_number(self):\n        \"\"\"\n        :return:\n            An integer of the certificate's serial number\n        \"\"\"\n\n        return self['tbs_certificate']['serial_number'].native\n\n    @property\n    def key_identifier(self):\n        \"\"\"\n        :return:\n            None or a byte string of the certificate's key identifier from the\n            key identifier extension\n        \"\"\"\n\n        if not self.key_identifier_value:\n            return None\n\n        return self.key_identifier_value.native\n\n    @property\n    def issuer_serial(self):\n        \"\"\"\n        :return:\n            A byte string of the SHA-256 hash of the issuer concatenated with\n            the ascii character \":\", concatenated with the serial number as\n            an ascii string\n        \"\"\"\n\n        if self._issuer_serial is None:\n            self._issuer_serial = self.issuer.sha256 + b':' + str_cls(self.serial_number).encode('ascii')\n        return self._issuer_serial\n\n    @property\n    def not_valid_after(self):\n        \"\"\"\n        :return:\n            A datetime of latest time when the certificate is still valid\n        \"\"\"\n        return self['tbs_certificate']['validity']['not_after'].native\n\n    @property\n    def not_valid_before(self):\n        \"\"\"\n        :return:\n            A datetime of the earliest time when the certificate is valid\n        \"\"\"\n        return self['tbs_certificate']['validity']['not_before'].native\n\n    @property\n    def authority_key_identifier(self):\n        \"\"\"\n        :return:\n            None or a byte string of the key_identifier from the authority key\n            identifier extension\n        \"\"\"\n\n        if not self.authority_key_identifier_value:\n            return None\n\n        return self.authority_key_identifier_value['key_identifier'].native\n\n    @property\n    def authority_issuer_serial(self):\n        \"\"\"\n        :return:\n            None or a byte string of the SHA-256 hash of the isser from the\n            authority key identifier extension concatenated with the ascii\n            character \":\", concatenated with the serial number from the\n            authority key identifier extension as an ascii string\n        \"\"\"\n\n        if self._authority_issuer_serial is False:\n            akiv = self.authority_key_identifier_value\n            if akiv and akiv['authority_cert_issuer'].native:\n                issuer = self.authority_key_identifier_value['authority_cert_issuer'][0].chosen\n                # We untag the element since it is tagged via being a choice from GeneralName\n                issuer = issuer.untag()\n                authority_serial = self.authority_key_identifier_value['authority_cert_serial_number'].native\n                self._authority_issuer_serial = issuer.sha256 + b':' + str_cls(authority_serial).encode('ascii')\n            else:\n                self._authority_issuer_serial = None\n        return self._authority_issuer_serial\n\n    @property\n    def crl_distribution_points(self):\n        \"\"\"\n        Returns complete CRL URLs - does not include delta CRLs\n\n        :return:\n            A list of zero or more DistributionPoint objects\n        \"\"\"\n\n        if self._crl_distribution_points is None:\n            self._crl_distribution_points = self._get_http_crl_distribution_points(self.crl_distribution_points_value)\n        return self._crl_distribution_points\n\n    @property\n    def delta_crl_distribution_points(self):\n        \"\"\"\n        Returns delta CRL URLs - does not include complete CRLs\n\n        :return:\n            A list of zero or more DistributionPoint objects\n        \"\"\"\n\n        if self._delta_crl_distribution_points is None:\n            self._delta_crl_distribution_points = self._get_http_crl_distribution_points(self.freshest_crl_value)\n        return self._delta_crl_distribution_points\n\n    def _get_http_crl_distribution_points(self, crl_distribution_points):\n        \"\"\"\n        Fetches the DistributionPoint object for non-relative, HTTP CRLs\n        referenced by the certificate\n\n        :param crl_distribution_points:\n            A CRLDistributionPoints object to grab the DistributionPoints from\n\n        :return:\n            A list of zero or more DistributionPoint objects\n        \"\"\"\n\n        output = []\n\n        if crl_distribution_points is None:\n            return []\n\n        for distribution_point in crl_distribution_points:\n            distribution_point_name = distribution_point['distribution_point']\n            if distribution_point_name is VOID:\n                continue\n            # RFC 5280 indicates conforming CA should not use the relative form\n            if distribution_point_name.name == 'name_relative_to_crl_issuer':\n                continue\n            # This library is currently only concerned with HTTP-based CRLs\n            for general_name in distribution_point_name.chosen:\n                if general_name.name == 'uniform_resource_identifier':\n                    output.append(distribution_point)\n\n        return output\n\n    @property\n    def ocsp_urls(self):\n        \"\"\"\n        :return:\n            A list of zero or more unicode strings of the OCSP URLs for this\n            cert\n        \"\"\"\n\n        if not self.authority_information_access_value:\n            return []\n\n        output = []\n        for entry in self.authority_information_access_value:\n            if entry['access_method'].native == 'ocsp':\n                location = entry['access_location']\n                if location.name != 'uniform_resource_identifier':\n                    continue\n                url = location.native\n                if url.lower().startswith(('http://', 'https://', 'ldap://', 'ldaps://')):\n                    output.append(url)\n        return output\n\n    @property\n    def valid_domains(self):\n        \"\"\"\n        :return:\n            A list of unicode strings of valid domain names for the certificate.\n            Wildcard certificates will have a domain in the form: *.example.com\n        \"\"\"\n\n        if self._valid_domains is None:\n            self._valid_domains = []\n\n            # For the subject alt name extension, we can look at the name of\n            # the choice selected since it distinguishes between domain names,\n            # email addresses, IPs, etc\n            if self.subject_alt_name_value:\n                for general_name in self.subject_alt_name_value:\n                    if general_name.name == 'dns_name' and general_name.native not in self._valid_domains:\n                        self._valid_domains.append(general_name.native)\n\n            # If there was no subject alt name extension, and the common name\n            # in the subject looks like a domain, that is considered the valid\n            # list. This is done because according to\n            # https://tools.ietf.org/html/rfc6125#section-6.4.4, the common\n            # name should not be used if the subject alt name is present.\n            else:\n                pattern = re.compile('^(\\\\*\\\\.)?(?:[a-zA-Z0-9](?:[a-zA-Z0-9\\\\-]*[a-zA-Z0-9])?\\\\.)+[a-zA-Z]{2,}$')\n                for rdn in self.subject.chosen:\n                    for name_type_value in rdn:\n                        if name_type_value['type'].native == 'common_name':\n                            value = name_type_value['value'].native\n                            if pattern.match(value):\n                                self._valid_domains.append(value)\n\n        return self._valid_domains\n\n    @property\n    def valid_ips(self):\n        \"\"\"\n        :return:\n            A list of unicode strings of valid IP addresses for the certificate\n        \"\"\"\n\n        if self._valid_ips is None:\n            self._valid_ips = []\n\n            if self.subject_alt_name_value:\n                for general_name in self.subject_alt_name_value:\n                    if general_name.name == 'ip_address':\n                        self._valid_ips.append(general_name.native)\n\n        return self._valid_ips\n\n    @property\n    def ca(self):\n        \"\"\"\n        :return;\n            A boolean - if the certificate is marked as a CA\n        \"\"\"\n\n        return self.basic_constraints_value and self.basic_constraints_value['ca'].native\n\n    @property\n    def max_path_length(self):\n        \"\"\"\n        :return;\n            None or an integer of the maximum path length\n        \"\"\"\n\n        if not self.ca:\n            return None\n        return self.basic_constraints_value['path_len_constraint'].native\n\n    @property\n    def self_issued(self):\n        \"\"\"\n        :return:\n            A boolean - if the certificate is self-issued, as defined by RFC\n            5280\n        \"\"\"\n\n        if self._self_issued is None:\n            self._self_issued = self.subject == self.issuer\n        return self._self_issued\n\n    @property\n    def self_signed(self):\n        \"\"\"\n        :return:\n            A unicode string of \"no\" or \"maybe\". The \"maybe\" result will\n            be returned if the certificate issuer and subject are the same.\n            If a key identifier and authority key identifier are present,\n            they will need to match otherwise \"no\" will be returned.\n\n            To verify is a certificate is truly self-signed, the signature\n            will need to be verified. See the certvalidator package for\n            one possible solution.\n        \"\"\"\n\n        if self._self_signed is None:\n            self._self_signed = 'no'\n            if self.self_issued:\n                if self.key_identifier:\n                    if not self.authority_key_identifier:\n                        self._self_signed = 'maybe'\n                    elif self.authority_key_identifier == self.key_identifier:\n                        self._self_signed = 'maybe'\n                else:\n                    self._self_signed = 'maybe'\n        return self._self_signed\n\n    @property\n    def sha1(self):\n        \"\"\"\n        :return:\n            The SHA-1 hash of the DER-encoded bytes of this complete certificate\n        \"\"\"\n\n        if self._sha1 is None:\n            self._sha1 = hashlib.sha1(self.dump()).digest()\n        return self._sha1\n\n    @property\n    def sha1_fingerprint(self):\n        \"\"\"\n        :return:\n            A unicode string of the SHA-1 hash, formatted using hex encoding\n            with a space between each pair of characters, all uppercase\n        \"\"\"\n\n        return ' '.join('%02X' % c for c in bytes_to_list(self.sha1))\n\n    @property\n    def sha256(self):\n        \"\"\"\n        :return:\n            The SHA-256 hash of the DER-encoded bytes of this complete\n            certificate\n        \"\"\"\n\n        if self._sha256 is None:\n            self._sha256 = hashlib.sha256(self.dump()).digest()\n        return self._sha256\n\n    @property\n    def sha256_fingerprint(self):\n        \"\"\"\n        :return:\n            A unicode string of the SHA-256 hash, formatted using hex encoding\n            with a space between each pair of characters, all uppercase\n        \"\"\"\n\n        return ' '.join('%02X' % c for c in bytes_to_list(self.sha256))\n\n    def is_valid_domain_ip(self, domain_ip):\n        \"\"\"\n        Check if a domain name or IP address is valid according to the\n        certificate\n\n        :param domain_ip:\n            A unicode string of a domain name or IP address\n\n        :return:\n            A boolean - if the domain or IP is valid for the certificate\n        \"\"\"\n\n        if not isinstance(domain_ip, str_cls):\n            raise TypeError(unwrap(\n                '''\n                domain_ip must be a unicode string, not %s\n                ''',\n                type_name(domain_ip)\n            ))\n\n        encoded_domain_ip = domain_ip.encode('idna').decode('ascii').lower()\n\n        is_ipv6 = encoded_domain_ip.find(':') != -1\n        is_ipv4 = not is_ipv6 and re.match('^\\\\d+\\\\.\\\\d+\\\\.\\\\d+\\\\.\\\\d+$', encoded_domain_ip)\n        is_domain = not is_ipv6 and not is_ipv4\n\n        # Handle domain name checks\n        if is_domain:\n            if not self.valid_domains:\n                return False\n\n            domain_labels = encoded_domain_ip.split('.')\n\n            for valid_domain in self.valid_domains:\n                encoded_valid_domain = valid_domain.encode('idna').decode('ascii').lower()\n                valid_domain_labels = encoded_valid_domain.split('.')\n\n                # The domain must be equal in label length to match\n                if len(valid_domain_labels) != len(domain_labels):\n                    continue\n\n                if valid_domain_labels == domain_labels:\n                    return True\n\n                is_wildcard = self._is_wildcard_domain(encoded_valid_domain)\n                if is_wildcard and self._is_wildcard_match(domain_labels, valid_domain_labels):\n                    return True\n\n            return False\n\n        # Handle IP address checks\n        if not self.valid_ips:\n            return False\n\n        family = socket.AF_INET if is_ipv4 else socket.AF_INET6\n        normalized_ip = inet_pton(family, encoded_domain_ip)\n\n        for valid_ip in self.valid_ips:\n            valid_family = socket.AF_INET if valid_ip.find('.') != -1 else socket.AF_INET6\n            normalized_valid_ip = inet_pton(valid_family, valid_ip)\n\n            if normalized_valid_ip == normalized_ip:\n                return True\n\n        return False\n\n    def _is_wildcard_domain(self, domain):\n        \"\"\"\n        Checks if a domain is a valid wildcard according to\n        https://tools.ietf.org/html/rfc6125#section-6.4.3\n\n        :param domain:\n            A unicode string of the domain name, where any U-labels from an IDN\n            have been converted to A-labels\n\n        :return:\n            A boolean - if the domain is a valid wildcard domain\n        \"\"\"\n\n        # The * character must be present for a wildcard match, and if there is\n        # most than one, it is an invalid wildcard specification\n        if domain.count('*') != 1:\n            return False\n\n        labels = domain.lower().split('.')\n\n        if not labels:\n            return False\n\n        # Wildcards may only appear in the left-most label\n        if labels[0].find('*') == -1:\n            return False\n\n        # Wildcards may not be embedded in an A-label from an IDN\n        if labels[0][0:4] == 'xn--':\n            return False\n\n        return True\n\n    def _is_wildcard_match(self, domain_labels, valid_domain_labels):\n        \"\"\"\n        Determines if the labels in a domain are a match for labels from a\n        wildcard valid domain name\n\n        :param domain_labels:\n            A list of unicode strings, with A-label form for IDNs, of the labels\n            in the domain name to check\n\n        :param valid_domain_labels:\n            A list of unicode strings, with A-label form for IDNs, of the labels\n            in a wildcard domain pattern\n\n        :return:\n            A boolean - if the domain matches the valid domain\n        \"\"\"\n\n        first_domain_label = domain_labels[0]\n        other_domain_labels = domain_labels[1:]\n\n        wildcard_label = valid_domain_labels[0]\n        other_valid_domain_labels = valid_domain_labels[1:]\n\n        # The wildcard is only allowed in the first label, so if\n        # The subsequent labels are not equal, there is no match\n        if other_domain_labels != other_valid_domain_labels:\n            return False\n\n        if wildcard_label == '*':\n            return True\n\n        wildcard_regex = re.compile('^' + wildcard_label.replace('*', '.*') + '$')\n        if wildcard_regex.match(first_domain_label):\n            return True\n\n        return False\n\n\n# The structures are taken from the OpenSSL source file x_x509a.c, and specify\n# extra information that is added to X.509 certificates to store trust\n# information about the certificate.\n\nclass KeyPurposeIdentifiers(SequenceOf):\n    _child_spec = KeyPurposeId\n\n\nclass SequenceOfAlgorithmIdentifiers(SequenceOf):\n    _child_spec = AlgorithmIdentifier\n\n\nclass CertificateAux(Sequence):\n    _fields = [\n        ('trust', KeyPurposeIdentifiers, {'optional': True}),\n        ('reject', KeyPurposeIdentifiers, {'implicit': 0, 'optional': True}),\n        ('alias', UTF8String, {'optional': True}),\n        ('keyid', OctetString, {'optional': True}),\n        ('other', SequenceOfAlgorithmIdentifiers, {'implicit': 1, 'optional': True}),\n    ]\n\n\nclass TrustedCertificate(Concat):\n    _child_specs = [Certificate, CertificateAux]\n", "asn1crypto/core.py": "# coding: utf-8\n\n\"\"\"\nASN.1 type classes for universal types. Exports the following items:\n\n - load()\n - Any()\n - Asn1Value()\n - BitString()\n - BMPString()\n - Boolean()\n - CharacterString()\n - Choice()\n - EmbeddedPdv()\n - Enumerated()\n - GeneralizedTime()\n - GeneralString()\n - GraphicString()\n - IA5String()\n - InstanceOf()\n - Integer()\n - IntegerBitString()\n - IntegerOctetString()\n - Null()\n - NumericString()\n - ObjectDescriptor()\n - ObjectIdentifier()\n - OctetBitString()\n - OctetString()\n - PrintableString()\n - Real()\n - RelativeOid()\n - Sequence()\n - SequenceOf()\n - Set()\n - SetOf()\n - TeletexString()\n - UniversalString()\n - UTCTime()\n - UTF8String()\n - VideotexString()\n - VisibleString()\n - VOID\n - Void()\n\nOther type classes are defined that help compose the types listed above.\n\"\"\"\n\nfrom __future__ import unicode_literals, division, absolute_import, print_function\n\nfrom datetime import datetime, timedelta\nfrom fractions import Fraction\nimport binascii\nimport copy\nimport math\nimport re\nimport sys\n\nfrom . import _teletex_codec\nfrom ._errors import unwrap\nfrom ._ordereddict import OrderedDict\nfrom ._types import type_name, str_cls, byte_cls, int_types, chr_cls\nfrom .parser import _parse, _dump_header\nfrom .util import int_to_bytes, int_from_bytes, timezone, extended_datetime, create_timezone, utc_with_dst\n\nif sys.version_info <= (3,):\n    from cStringIO import StringIO as BytesIO\n\n    range = xrange  # noqa\n    _PY2 = True\n\nelse:\n    from io import BytesIO\n\n    _PY2 = False\n\n\n_teletex_codec.register()\n\n\nCLASS_NUM_TO_NAME_MAP = {\n    0: 'universal',\n    1: 'application',\n    2: 'context',\n    3: 'private',\n}\n\nCLASS_NAME_TO_NUM_MAP = {\n    'universal': 0,\n    'application': 1,\n    'context': 2,\n    'private': 3,\n    0: 0,\n    1: 1,\n    2: 2,\n    3: 3,\n}\n\nMETHOD_NUM_TO_NAME_MAP = {\n    0: 'primitive',\n    1: 'constructed',\n}\n\n\n_OID_RE = re.compile(r'^\\d+(\\.\\d+)*$')\n\n\n# A global tracker to ensure that _setup() is called for every class, even\n# if is has been called for a parent class. This allows different _fields\n# definitions for child classes. Without such a construct, the child classes\n# would just see the parent class attributes and would use them.\n_SETUP_CLASSES = {}\n\n\ndef load(encoded_data, strict=False):\n    \"\"\"\n    Loads a BER/DER-encoded byte string and construct a universal object based\n    on the tag value:\n\n     - 1: Boolean\n     - 2: Integer\n     - 3: BitString\n     - 4: OctetString\n     - 5: Null\n     - 6: ObjectIdentifier\n     - 7: ObjectDescriptor\n     - 8: InstanceOf\n     - 9: Real\n     - 10: Enumerated\n     - 11: EmbeddedPdv\n     - 12: UTF8String\n     - 13: RelativeOid\n     - 16: Sequence,\n     - 17: Set\n     - 18: NumericString\n     - 19: PrintableString\n     - 20: TeletexString\n     - 21: VideotexString\n     - 22: IA5String\n     - 23: UTCTime\n     - 24: GeneralizedTime\n     - 25: GraphicString\n     - 26: VisibleString\n     - 27: GeneralString\n     - 28: UniversalString\n     - 29: CharacterString\n     - 30: BMPString\n\n    :param encoded_data:\n        A byte string of BER or DER-encoded data\n\n    :param strict:\n        A boolean indicating if trailing data should be forbidden - if so, a\n        ValueError will be raised when trailing data exists\n\n    :raises:\n        ValueError - when strict is True and trailing data is present\n        ValueError - when the encoded value tag a tag other than listed above\n        ValueError - when the ASN.1 header length is longer than the data\n        TypeError - when encoded_data is not a byte string\n\n    :return:\n        An instance of the one of the universal classes\n    \"\"\"\n\n    return Asn1Value.load(encoded_data, strict=strict)\n\n\ndef unpickle_helper(asn1crypto_cls, der_bytes):\n    \"\"\"\n    Helper function to integrate with pickle.\n\n    Note that this must be an importable top-level function.\n    \"\"\"\n    return asn1crypto_cls.load(der_bytes)\n\n\nclass Asn1Value(object):\n    \"\"\"\n    The basis of all ASN.1 values\n    \"\"\"\n\n    # The integer 0 for primitive, 1 for constructed\n    method = None\n\n    # An integer 0 through 3 - see CLASS_NUM_TO_NAME_MAP for value\n    class_ = None\n\n    # An integer 1 or greater indicating the tag number\n    tag = None\n\n    # An alternate tag allowed for this type - used for handling broken\n    # structures where a string value is encoded using an incorrect tag\n    _bad_tag = None\n\n    # If the value has been implicitly tagged\n    implicit = False\n\n    # If explicitly tagged, a tuple of 2-element tuples containing the\n    # class int and tag int, from innermost to outermost\n    explicit = None\n\n    # The BER/DER header bytes\n    _header = None\n\n    # Raw encoded value bytes not including class, method, tag, length header\n    contents = None\n\n    # The BER/DER trailer bytes\n    _trailer = b''\n\n    # The native python representation of the value - this is not used by\n    # some classes since they utilize _bytes or _unicode\n    _native = None\n\n    @classmethod\n    def load(cls, encoded_data, strict=False, **kwargs):\n        \"\"\"\n        Loads a BER/DER-encoded byte string using the current class as the spec\n\n        :param encoded_data:\n            A byte string of BER or DER-encoded data\n\n        :param strict:\n            A boolean indicating if trailing data should be forbidden - if so, a\n            ValueError will be raised when trailing data exists\n\n        :return:\n            An instance of the current class\n        \"\"\"\n\n        if not isinstance(encoded_data, byte_cls):\n            raise TypeError('encoded_data must be a byte string, not %s' % type_name(encoded_data))\n\n        spec = None\n        if cls.tag is not None:\n            spec = cls\n\n        value, _ = _parse_build(encoded_data, spec=spec, spec_params=kwargs, strict=strict)\n        return value\n\n    def __init__(self, explicit=None, implicit=None, no_explicit=False, tag_type=None, class_=None, tag=None,\n                 optional=None, default=None, contents=None, method=None):\n        \"\"\"\n        The optional parameter is not used, but rather included so we don't\n        have to delete it from the parameter dictionary when passing as keyword\n        args\n\n        :param explicit:\n            An int tag number for explicit tagging, or a 2-element tuple of\n            class and tag.\n\n        :param implicit:\n            An int tag number for implicit tagging, or a 2-element tuple of\n            class and tag.\n\n        :param no_explicit:\n            If explicit tagging info should be removed from this instance.\n            Used internally to allow contructing the underlying value that\n            has been wrapped in an explicit tag.\n\n        :param tag_type:\n            None for normal values, or one of \"implicit\", \"explicit\" for tagged\n            values. Deprecated in favor of explicit and implicit params.\n\n        :param class_:\n            The class for the value - defaults to \"universal\" if tag_type is\n            None, otherwise defaults to \"context\". Valid values include:\n             - \"universal\"\n             - \"application\"\n             - \"context\"\n             - \"private\"\n            Deprecated in favor of explicit and implicit params.\n\n        :param tag:\n            The integer tag to override - usually this is used with tag_type or\n            class_. Deprecated in favor of explicit and implicit params.\n\n        :param optional:\n            Dummy parameter that allows \"optional\" key in spec param dicts\n\n        :param default:\n            The default value to use if the value is currently None\n\n        :param contents:\n            A byte string of the encoded contents of the value\n\n        :param method:\n            The method for the value - no default value since this is\n            normally set on a class. Valid values include:\n             - \"primitive\" or 0\n             - \"constructed\" or 1\n\n        :raises:\n            ValueError - when implicit, explicit, tag_type, class_ or tag are invalid values\n        \"\"\"\n\n        try:\n            if self.__class__ not in _SETUP_CLASSES:\n                cls = self.__class__\n                # Allow explicit to be specified as a simple 2-element tuple\n                # instead of requiring the user make a nested tuple\n                if cls.explicit is not None and isinstance(cls.explicit[0], int_types):\n                    cls.explicit = (cls.explicit, )\n                if hasattr(cls, '_setup'):\n                    self._setup()\n                _SETUP_CLASSES[cls] = True\n\n            # Normalize tagging values\n            if explicit is not None:\n                if isinstance(explicit, int_types):\n                    if class_ is None:\n                        class_ = 'context'\n                    explicit = (class_, explicit)\n                # Prevent both explicit and tag_type == 'explicit'\n                if tag_type == 'explicit':\n                    tag_type = None\n                    tag = None\n\n            if implicit is not None:\n                if isinstance(implicit, int_types):\n                    if class_ is None:\n                        class_ = 'context'\n                    implicit = (class_, implicit)\n                # Prevent both implicit and tag_type == 'implicit'\n                if tag_type == 'implicit':\n                    tag_type = None\n                    tag = None\n\n            # Convert old tag_type API to explicit/implicit params\n            if tag_type is not None:\n                if class_ is None:\n                    class_ = 'context'\n                if tag_type == 'explicit':\n                    explicit = (class_, tag)\n                elif tag_type == 'implicit':\n                    implicit = (class_, tag)\n                else:\n                    raise ValueError(unwrap(\n                        '''\n                        tag_type must be one of \"implicit\", \"explicit\", not %s\n                        ''',\n                        repr(tag_type)\n                    ))\n\n            if explicit is not None:\n                # Ensure we have a tuple of 2-element tuples\n                if len(explicit) == 2 and isinstance(explicit[1], int_types):\n                    explicit = (explicit, )\n                for class_, tag in explicit:\n                    invalid_class = None\n                    if isinstance(class_, int_types):\n                        if class_ not in CLASS_NUM_TO_NAME_MAP:\n                            invalid_class = class_\n                    else:\n                        if class_ not in CLASS_NAME_TO_NUM_MAP:\n                            invalid_class = class_\n                        class_ = CLASS_NAME_TO_NUM_MAP[class_]\n                    if invalid_class is not None:\n                        raise ValueError(unwrap(\n                            '''\n                            explicit class must be one of \"universal\", \"application\",\n                            \"context\", \"private\", not %s\n                            ''',\n                            repr(invalid_class)\n                        ))\n                    if tag is not None:\n                        if not isinstance(tag, int_types):\n                            raise TypeError(unwrap(\n                                '''\n                                explicit tag must be an integer, not %s\n                                ''',\n                                type_name(tag)\n                            ))\n                    if self.explicit is None:\n                        self.explicit = ((class_, tag), )\n                    else:\n                        self.explicit = self.explicit + ((class_, tag), )\n\n            elif implicit is not None:\n                class_, tag = implicit\n                if class_ not in CLASS_NAME_TO_NUM_MAP:\n                    raise ValueError(unwrap(\n                        '''\n                        implicit class must be one of \"universal\", \"application\",\n                        \"context\", \"private\", not %s\n                        ''',\n                        repr(class_)\n                    ))\n                if tag is not None:\n                    if not isinstance(tag, int_types):\n                        raise TypeError(unwrap(\n                            '''\n                            implicit tag must be an integer, not %s\n                            ''',\n                            type_name(tag)\n                        ))\n                self.class_ = CLASS_NAME_TO_NUM_MAP[class_]\n                self.tag = tag\n                self.implicit = True\n            else:\n                if class_ is not None:\n                    if class_ not in CLASS_NAME_TO_NUM_MAP:\n                        raise ValueError(unwrap(\n                            '''\n                            class_ must be one of \"universal\", \"application\",\n                            \"context\", \"private\", not %s\n                            ''',\n                            repr(class_)\n                        ))\n                    self.class_ = CLASS_NAME_TO_NUM_MAP[class_]\n\n                if self.class_ is None:\n                    self.class_ = 0\n\n                if tag is not None:\n                    self.tag = tag\n\n            if method is not None:\n                if method not in set([\"primitive\", 0, \"constructed\", 1]):\n                    raise ValueError(unwrap(\n                        '''\n                        method must be one of \"primitive\" or \"constructed\",\n                        not %s\n                        ''',\n                        repr(method)\n                    ))\n                if method == \"primitive\":\n                    method = 0\n                elif method == \"constructed\":\n                    method = 1\n                self.method = method\n\n            if no_explicit:\n                self.explicit = None\n\n            if contents is not None:\n                self.contents = contents\n\n            elif default is not None:\n                self.set(default)\n\n        except (ValueError, TypeError) as e:\n            args = e.args[1:]\n            e.args = (e.args[0] + '\\n    while constructing %s' % type_name(self),) + args\n            raise e\n\n    def __str__(self):\n        \"\"\"\n        Since str is different in Python 2 and 3, this calls the appropriate\n        method, __unicode__() or __bytes__()\n\n        :return:\n            A unicode string\n        \"\"\"\n\n        if _PY2:\n            return self.__bytes__()\n        else:\n            return self.__unicode__()\n\n    def __repr__(self):\n        \"\"\"\n        :return:\n            A unicode string\n        \"\"\"\n\n        if _PY2:\n            return '<%s %s b%s>' % (type_name(self), id(self), repr(self.dump()))\n        else:\n            return '<%s %s %s>' % (type_name(self), id(self), repr(self.dump()))\n\n    def __bytes__(self):\n        \"\"\"\n        A fall-back method for print() in Python 2\n\n        :return:\n            A byte string of the output of repr()\n        \"\"\"\n\n        return self.__repr__().encode('utf-8')\n\n    def __unicode__(self):\n        \"\"\"\n        A fall-back method for print() in Python 3\n\n        :return:\n            A unicode string of the output of repr()\n        \"\"\"\n\n        return self.__repr__()\n\n    def __reduce__(self):\n        \"\"\"\n        Permits pickling Asn1Value objects using their DER representation.\n        \"\"\"\n        return unpickle_helper, (self.__class__, self.dump())\n\n    def _new_instance(self):\n        \"\"\"\n        Constructs a new copy of the current object, preserving any tagging\n\n        :return:\n            An Asn1Value object\n        \"\"\"\n\n        new_obj = self.__class__()\n        new_obj.class_ = self.class_\n        new_obj.tag = self.tag\n        new_obj.implicit = self.implicit\n        new_obj.explicit = self.explicit\n        return new_obj\n\n    def __copy__(self):\n        \"\"\"\n        Implements the copy.copy() interface\n\n        :return:\n            A new shallow copy of the current Asn1Value object\n        \"\"\"\n\n        new_obj = self._new_instance()\n        new_obj._copy(self, copy.copy)\n        return new_obj\n\n    def __deepcopy__(self, memo):\n        \"\"\"\n        Implements the copy.deepcopy() interface\n\n        :param memo:\n            A dict for memoization\n\n        :return:\n            A new deep copy of the current Asn1Value object\n        \"\"\"\n\n        new_obj = self._new_instance()\n        memo[id(self)] = new_obj\n        new_obj._copy(self, copy.deepcopy)\n        return new_obj\n\n    def copy(self):\n        \"\"\"\n        Copies the object, preserving any special tagging from it\n\n        :return:\n            An Asn1Value object\n        \"\"\"\n\n        return copy.deepcopy(self)\n\n    def retag(self, tagging, tag=None):\n        \"\"\"\n        Copies the object, applying a new tagging to it\n\n        :param tagging:\n            A dict containing the keys \"explicit\" and \"implicit\". Legacy\n            API allows a unicode string of \"implicit\" or \"explicit\".\n\n        :param tag:\n            A integer tag number. Only used when tagging is a unicode string.\n\n        :return:\n            An Asn1Value object\n        \"\"\"\n\n        # This is required to preserve the old API\n        if not isinstance(tagging, dict):\n            tagging = {tagging: tag}\n        new_obj = self.__class__(explicit=tagging.get('explicit'), implicit=tagging.get('implicit'))\n        new_obj._copy(self, copy.deepcopy)\n        return new_obj\n\n    def untag(self):\n        \"\"\"\n        Copies the object, removing any special tagging from it\n\n        :return:\n            An Asn1Value object\n        \"\"\"\n\n        new_obj = self.__class__()\n        new_obj._copy(self, copy.deepcopy)\n        return new_obj\n\n    def _copy(self, other, copy_func):\n        \"\"\"\n        Copies the contents of another Asn1Value object to itself\n\n        :param object:\n            Another instance of the same class\n\n        :param copy_func:\n            An reference of copy.copy() or copy.deepcopy() to use when copying\n            lists, dicts and objects\n        \"\"\"\n\n        if self.__class__ != other.__class__:\n            raise TypeError(unwrap(\n                '''\n                Can not copy values from %s object to %s object\n                ''',\n                type_name(other),\n                type_name(self)\n            ))\n\n        self.contents = other.contents\n        self._native = copy_func(other._native)\n\n    def debug(self, nest_level=1):\n        \"\"\"\n        Show the binary data and parsed data in a tree structure\n        \"\"\"\n\n        prefix = '  ' * nest_level\n\n        # This interacts with Any and moves the tag, implicit, explicit, _header,\n        # contents, _footer to the parsed value so duplicate data isn't present\n        has_parsed = hasattr(self, 'parsed')\n\n        _basic_debug(prefix, self)\n        if has_parsed:\n            self.parsed.debug(nest_level + 2)\n        elif hasattr(self, 'chosen'):\n            self.chosen.debug(nest_level + 2)\n        else:\n            if _PY2 and isinstance(self.native, byte_cls):\n                print('%s    Native: b%s' % (prefix, repr(self.native)))\n            else:\n                print('%s    Native: %s' % (prefix, self.native))\n\n    def dump(self, force=False):\n        \"\"\"\n        Encodes the value using DER\n\n        :param force:\n            If the encoded contents already exist, clear them and regenerate\n            to ensure they are in DER format instead of BER format\n\n        :return:\n            A byte string of the DER-encoded value\n        \"\"\"\n\n        contents = self.contents\n\n        # If the length is indefinite, force the re-encoding\n        if self._header is not None and self._header[-1:] == b'\\x80':\n            force = True\n\n        if self._header is None or force:\n            if isinstance(self, Constructable) and self._indefinite:\n                self.method = 0\n\n            header = _dump_header(self.class_, self.method, self.tag, self.contents)\n\n            if self.explicit is not None:\n                for class_, tag in self.explicit:\n                    header = _dump_header(class_, 1, tag, header + self.contents) + header\n\n            self._header = header\n            self._trailer = b''\n\n        return self._header + contents + self._trailer\n\n\nclass ValueMap():\n    \"\"\"\n    Basic functionality that allows for mapping values from ints or OIDs to\n    python unicode strings\n    \"\"\"\n\n    # A dict from primitive value (int or OID) to unicode string. This needs\n    # to be defined in the source code\n    _map = None\n\n    # A dict from unicode string to int/OID. This is automatically generated\n    # from _map the first time it is needed\n    _reverse_map = None\n\n    def _setup(self):\n        \"\"\"\n        Generates _reverse_map from _map\n        \"\"\"\n\n        cls = self.__class__\n        if cls._map is None or cls._reverse_map is not None:\n            return\n        cls._reverse_map = {}\n        for key, value in cls._map.items():\n            cls._reverse_map[value] = key\n\n\nclass Castable(object):\n    \"\"\"\n    A mixin to handle converting an object between different classes that\n    represent the same encoded value, but with different rules for converting\n    to and from native Python values\n    \"\"\"\n\n    def cast(self, other_class):\n        \"\"\"\n        Converts the current object into an object of a different class. The\n        new class must use the ASN.1 encoding for the value.\n\n        :param other_class:\n            The class to instantiate the new object from\n\n        :return:\n            An instance of the type other_class\n        \"\"\"\n\n        if other_class.tag != self.__class__.tag:\n            raise TypeError(unwrap(\n                '''\n                Can not covert a value from %s object to %s object since they\n                use different tags: %d versus %d\n                ''',\n                type_name(other_class),\n                type_name(self),\n                other_class.tag,\n                self.__class__.tag\n            ))\n\n        new_obj = other_class()\n        new_obj.class_ = self.class_\n        new_obj.implicit = self.implicit\n        new_obj.explicit = self.explicit\n        new_obj._header = self._header\n        new_obj.contents = self.contents\n        new_obj._trailer = self._trailer\n        if isinstance(self, Constructable):\n            new_obj.method = self.method\n            new_obj._indefinite = self._indefinite\n        return new_obj\n\n\nclass Constructable(object):\n    \"\"\"\n    A mixin to handle string types that may be constructed from chunks\n    contained within an indefinite length BER-encoded container\n    \"\"\"\n\n    # Instance attribute indicating if an object was indefinite\n    # length when parsed - affects parsing and dumping\n    _indefinite = False\n\n    def _merge_chunks(self):\n        \"\"\"\n        :return:\n            A concatenation of the native values of the contained chunks\n        \"\"\"\n\n        if not self._indefinite:\n            return self._as_chunk()\n\n        pointer = 0\n        contents_len = len(self.contents)\n        output = None\n\n        while pointer < contents_len:\n            # We pass the current class as the spec so content semantics are preserved\n            sub_value, pointer = _parse_build(self.contents, pointer, spec=self.__class__)\n            if output is None:\n                output = sub_value._merge_chunks()\n            else:\n                output += sub_value._merge_chunks()\n\n        if output is None:\n            return self._as_chunk()\n\n        return output\n\n    def _as_chunk(self):\n        \"\"\"\n        A method to return a chunk of data that can be combined for\n        constructed method values\n\n        :return:\n            A native Python value that can be added together. Examples include\n            byte strings, unicode strings or tuples.\n        \"\"\"\n\n        return self.contents\n\n    def _setable_native(self):\n        \"\"\"\n        Returns a native value that can be round-tripped into .set(), to\n        result in a DER encoding. This differs from .native in that .native\n        is designed for the end use, and may account for the fact that the\n        merged value is further parsed as ASN.1, such as in the case of\n        ParsableOctetString() and ParsableOctetBitString().\n\n        :return:\n            A python value that is valid to pass to .set()\n        \"\"\"\n\n        return self.native\n\n    def _copy(self, other, copy_func):\n        \"\"\"\n        Copies the contents of another Constructable object to itself\n\n        :param object:\n            Another instance of the same class\n\n        :param copy_func:\n            An reference of copy.copy() or copy.deepcopy() to use when copying\n            lists, dicts and objects\n        \"\"\"\n\n        super(Constructable, self)._copy(other, copy_func)\n        # We really don't want to dump BER encodings, so if we see an\n        # indefinite encoding, let's re-encode it\n        if other._indefinite:\n            self.set(other._setable_native())\n\n\nclass Void(Asn1Value):\n    \"\"\"\n    A representation of an optional value that is not present. Has .native\n    property and .dump() method to be compatible with other value classes.\n    \"\"\"\n\n    contents = b''\n\n    def __eq__(self, other):\n        \"\"\"\n        :param other:\n            The other Primitive to compare to\n\n        :return:\n            A boolean\n        \"\"\"\n\n        return other.__class__ == self.__class__\n\n    def __nonzero__(self):\n        return False\n\n    def __len__(self):\n        return 0\n\n    def __iter__(self):\n        return iter(())\n\n    @property\n    def native(self):\n        \"\"\"\n        The native Python datatype representation of this value\n\n        :return:\n            None\n        \"\"\"\n\n        return None\n\n    def dump(self, force=False):\n        \"\"\"\n        Encodes the value using DER\n\n        :param force:\n            If the encoded contents already exist, clear them and regenerate\n            to ensure they are in DER format instead of BER format\n\n        :return:\n            A byte string of the DER-encoded value\n        \"\"\"\n\n        return b''\n\n\nVOID = Void()\n\n\nclass Any(Asn1Value):\n    \"\"\"\n    A value class that can contain any value, and allows for easy parsing of\n    the underlying encoded value using a spec. This is normally contained in\n    a Structure that has an ObjectIdentifier field and _oid_pair and _oid_specs\n    defined.\n    \"\"\"\n\n    # The parsed value object\n    _parsed = None\n\n    def __init__(self, value=None, **kwargs):\n        \"\"\"\n        Sets the value of the object before passing to Asn1Value.__init__()\n\n        :param value:\n            An Asn1Value object that will be set as the parsed value\n        \"\"\"\n\n        Asn1Value.__init__(self, **kwargs)\n\n        try:\n            if value is not None:\n                if not isinstance(value, Asn1Value):\n                    raise TypeError(unwrap(\n                        '''\n                        value must be an instance of Asn1Value, not %s\n                        ''',\n                        type_name(value)\n                    ))\n\n                self._parsed = (value, value.__class__, None)\n                self.contents = value.dump()\n\n        except (ValueError, TypeError) as e:\n            args = e.args[1:]\n            e.args = (e.args[0] + '\\n    while constructing %s' % type_name(self),) + args\n            raise e\n\n    @property\n    def native(self):\n        \"\"\"\n        The native Python datatype representation of this value\n\n        :return:\n            The .native value from the parsed value object\n        \"\"\"\n\n        if self._parsed is None:\n            self.parse()\n\n        return self._parsed[0].native\n\n    @property\n    def parsed(self):\n        \"\"\"\n        Returns the parsed object from .parse()\n\n        :return:\n            The object returned by .parse()\n        \"\"\"\n\n        if self._parsed is None:\n            self.parse()\n\n        return self._parsed[0]\n\n    def parse(self, spec=None, spec_params=None):\n        \"\"\"\n        Parses the contents generically, or using a spec with optional params\n\n        :param spec:\n            A class derived from Asn1Value that defines what class_ and tag the\n            value should have, and the semantics of the encoded value. The\n            return value will be of this type. If omitted, the encoded value\n            will be decoded using the standard universal tag based on the\n            encoded tag number.\n\n        :param spec_params:\n            A dict of params to pass to the spec object\n\n        :return:\n            An object of the type spec, or if not present, a child of Asn1Value\n        \"\"\"\n\n        if self._parsed is None or self._parsed[1:3] != (spec, spec_params):\n            try:\n                passed_params = spec_params or {}\n                _tag_type_to_explicit_implicit(passed_params)\n                if self.explicit is not None:\n                    if 'explicit' in passed_params:\n                        passed_params['explicit'] = self.explicit + passed_params['explicit']\n                    else:\n                        passed_params['explicit'] = self.explicit\n                contents = self._header + self.contents + self._trailer\n                parsed_value, _ = _parse_build(\n                    contents,\n                    spec=spec,\n                    spec_params=passed_params\n                )\n                self._parsed = (parsed_value, spec, spec_params)\n\n                # Once we've parsed the Any value, clear any attributes from this object\n                # since they are now duplicate\n                self.tag = None\n                self.explicit = None\n                self.implicit = False\n                self._header = b''\n                self.contents = contents\n                self._trailer = b''\n\n            except (ValueError, TypeError) as e:\n                args = e.args[1:]\n                e.args = (e.args[0] + '\\n    while parsing %s' % type_name(self),) + args\n                raise e\n        return self._parsed[0]\n\n    def _copy(self, other, copy_func):\n        \"\"\"\n        Copies the contents of another Any object to itself\n\n        :param object:\n            Another instance of the same class\n\n        :param copy_func:\n            An reference of copy.copy() or copy.deepcopy() to use when copying\n            lists, dicts and objects\n        \"\"\"\n\n        super(Any, self)._copy(other, copy_func)\n        self._parsed = copy_func(other._parsed)\n\n    def dump(self, force=False):\n        \"\"\"\n        Encodes the value using DER\n\n        :param force:\n            If the encoded contents already exist, clear them and regenerate\n            to ensure they are in DER format instead of BER format\n\n        :return:\n            A byte string of the DER-encoded value\n        \"\"\"\n\n        if self._parsed is None:\n            self.parse()\n\n        return self._parsed[0].dump(force=force)\n\n\nclass Choice(Asn1Value):\n    \"\"\"\n    A class to handle when a value may be one of several options\n    \"\"\"\n\n    # The index in _alternatives of the validated alternative\n    _choice = None\n\n    # The name of the chosen alternative\n    _name = None\n\n    # The Asn1Value object for the chosen alternative\n    _parsed = None\n\n    # Choice overrides .contents to be a property so that the code expecting\n    # the .contents attribute will get the .contents of the chosen alternative\n    _contents = None\n\n    # A list of tuples in one of the following forms.\n    #\n    # Option 1, a unicode string field name and a value class\n    #\n    # (\"name\", Asn1ValueClass)\n    #\n    # Option 2, same as Option 1, but with a dict of class params\n    #\n    # (\"name\", Asn1ValueClass, {'explicit': 5})\n    _alternatives = None\n\n    # A dict that maps tuples of (class_, tag) to an index in _alternatives\n    _id_map = None\n\n    # A dict that maps alternative names to an index in _alternatives\n    _name_map = None\n\n    @classmethod\n    def load(cls, encoded_data, strict=False, **kwargs):\n        \"\"\"\n        Loads a BER/DER-encoded byte string using the current class as the spec\n\n        :param encoded_data:\n            A byte string of BER or DER encoded data\n\n        :param strict:\n            A boolean indicating if trailing data should be forbidden - if so, a\n            ValueError will be raised when trailing data exists\n\n        :return:\n            A instance of the current class\n        \"\"\"\n\n        if not isinstance(encoded_data, byte_cls):\n            raise TypeError('encoded_data must be a byte string, not %s' % type_name(encoded_data))\n\n        value, _ = _parse_build(encoded_data, spec=cls, spec_params=kwargs, strict=strict)\n        return value\n\n    def _setup(self):\n        \"\"\"\n        Generates _id_map from _alternatives to allow validating contents\n        \"\"\"\n\n        cls = self.__class__\n        cls._id_map = {}\n        cls._name_map = {}\n        for index, info in enumerate(cls._alternatives):\n            if len(info) < 3:\n                info = info + ({},)\n                cls._alternatives[index] = info\n            id_ = _build_id_tuple(info[2], info[1])\n            cls._id_map[id_] = index\n            cls._name_map[info[0]] = index\n\n    def __init__(self, name=None, value=None, **kwargs):\n        \"\"\"\n        Checks to ensure implicit tagging is not being used since it is\n        incompatible with Choice, then forwards on to Asn1Value.__init__()\n\n        :param name:\n            The name of the alternative to be set - used with value.\n            Alternatively this may be a dict with a single key being the name\n            and the value being the value, or a two-element tuple of the name\n            and the value.\n\n        :param value:\n            The alternative value to set - used with name\n\n        :raises:\n            ValueError - when implicit param is passed (or legacy tag_type param is \"implicit\")\n        \"\"\"\n\n        _tag_type_to_explicit_implicit(kwargs)\n\n        Asn1Value.__init__(self, **kwargs)\n\n        try:\n            if kwargs.get('implicit') is not None:\n                raise ValueError(unwrap(\n                    '''\n                    The Choice type can not be implicitly tagged even if in an\n                    implicit module - due to its nature any tagging must be\n                    explicit\n                    '''\n                ))\n\n            if name is not None:\n                if isinstance(name, dict):\n                    if len(name) != 1:\n                        raise ValueError(unwrap(\n                            '''\n                            When passing a dict as the \"name\" argument to %s,\n                            it must have a single key/value - however %d were\n                            present\n                            ''',\n                            type_name(self),\n                            len(name)\n                        ))\n                    name, value = list(name.items())[0]\n\n                if isinstance(name, tuple):\n                    if len(name) != 2:\n                        raise ValueError(unwrap(\n                            '''\n                            When passing a tuple as the \"name\" argument to %s,\n                            it must have two elements, the name and value -\n                            however %d were present\n                            ''',\n                            type_name(self),\n                            len(name)\n                        ))\n                    value = name[1]\n                    name = name[0]\n\n                if name not in self._name_map:\n                    raise ValueError(unwrap(\n                        '''\n                        The name specified, \"%s\", is not a valid alternative\n                        for %s\n                        ''',\n                        name,\n                        type_name(self)\n                    ))\n\n                self._choice = self._name_map[name]\n                _, spec, params = self._alternatives[self._choice]\n\n                if not isinstance(value, spec):\n                    value = spec(value, **params)\n                else:\n                    value = _fix_tagging(value, params)\n                self._parsed = value\n\n        except (ValueError, TypeError) as e:\n            args = e.args[1:]\n            e.args = (e.args[0] + '\\n    while constructing %s' % type_name(self),) + args\n            raise e\n\n    @property\n    def contents(self):\n        \"\"\"\n        :return:\n            A byte string of the DER-encoded contents of the chosen alternative\n        \"\"\"\n\n        if self._parsed is not None:\n            return self._parsed.contents\n\n        return self._contents\n\n    @contents.setter\n    def contents(self, value):\n        \"\"\"\n        :param value:\n            A byte string of the DER-encoded contents of the chosen alternative\n        \"\"\"\n\n        self._contents = value\n\n    @property\n    def name(self):\n        \"\"\"\n        :return:\n            A unicode string of the field name of the chosen alternative\n        \"\"\"\n        if not self._name:\n            self._name = self._alternatives[self._choice][0]\n        return self._name\n\n    def parse(self):\n        \"\"\"\n        Parses the detected alternative\n\n        :return:\n            An Asn1Value object of the chosen alternative\n        \"\"\"\n\n        if self._parsed is None:\n            try:\n                _, spec, params = self._alternatives[self._choice]\n                self._parsed, _ = _parse_build(self._contents, spec=spec, spec_params=params)\n            except (ValueError, TypeError) as e:\n                args = e.args[1:]\n                e.args = (e.args[0] + '\\n    while parsing %s' % type_name(self),) + args\n                raise e\n        return self._parsed\n\n    @property\n    def chosen(self):\n        \"\"\"\n        :return:\n            An Asn1Value object of the chosen alternative\n        \"\"\"\n\n        return self.parse()\n\n    @property\n    def native(self):\n        \"\"\"\n        The native Python datatype representation of this value\n\n        :return:\n            The .native value from the contained value object\n        \"\"\"\n\n        return self.chosen.native\n\n    def validate(self, class_, tag, contents):\n        \"\"\"\n        Ensures that the class and tag specified exist as an alternative\n\n        :param class_:\n            The integer class_ from the encoded value header\n\n        :param tag:\n            The integer tag from the encoded value header\n\n        :param contents:\n            A byte string of the contents of the value - used when the object\n            is explicitly tagged\n\n        :raises:\n            ValueError - when value is not a valid alternative\n        \"\"\"\n\n        id_ = (class_, tag)\n\n        if self.explicit is not None:\n            if self.explicit[-1] != id_:\n                raise ValueError(unwrap(\n                    '''\n                    %s was explicitly tagged, but the value provided does not\n                    match the class and tag\n                    ''',\n                    type_name(self)\n                ))\n\n            ((class_, _, tag, _, _, _), _) = _parse(contents, len(contents))\n            id_ = (class_, tag)\n\n        if id_ in self._id_map:\n            self._choice = self._id_map[id_]\n            return\n\n        # This means the Choice was implicitly tagged\n        if self.class_ is not None and self.tag is not None:\n            if len(self._alternatives) > 1:\n                raise ValueError(unwrap(\n                    '''\n                    %s was implicitly tagged, but more than one alternative\n                    exists\n                    ''',\n                    type_name(self)\n                ))\n            if id_ == (self.class_, self.tag):\n                self._choice = 0\n                return\n\n        asn1 = self._format_class_tag(class_, tag)\n        asn1s = [self._format_class_tag(pair[0], pair[1]) for pair in self._id_map]\n\n        raise ValueError(unwrap(\n            '''\n            Value %s did not match the class and tag of any of the alternatives\n            in %s: %s\n            ''',\n            asn1,\n            type_name(self),\n            ', '.join(asn1s)\n        ))\n\n    def _format_class_tag(self, class_, tag):\n        \"\"\"\n        :return:\n            A unicode string of a human-friendly representation of the class and tag\n        \"\"\"\n\n        return '[%s %s]' % (CLASS_NUM_TO_NAME_MAP[class_].upper(), tag)\n\n    def _copy(self, other, copy_func):\n        \"\"\"\n        Copies the contents of another Choice object to itself\n\n        :param object:\n            Another instance of the same class\n\n        :param copy_func:\n            An reference of copy.copy() or copy.deepcopy() to use when copying\n            lists, dicts and objects\n        \"\"\"\n\n        super(Choice, self)._copy(other, copy_func)\n        self._choice = other._choice\n        self._name = other._name\n        self._parsed = copy_func(other._parsed)\n\n    def dump(self, force=False):\n        \"\"\"\n        Encodes the value using DER\n\n        :param force:\n            If the encoded contents already exist, clear them and regenerate\n            to ensure they are in DER format instead of BER format\n\n        :return:\n            A byte string of the DER-encoded value\n        \"\"\"\n\n        # If the length is indefinite, force the re-encoding\n        if self._header is not None and self._header[-1:] == b'\\x80':\n            force = True\n\n        self._contents = self.chosen.dump(force=force)\n        if self._header is None or force:\n            self._header = b''\n            if self.explicit is not None:\n                for class_, tag in self.explicit:\n                    self._header = _dump_header(class_, 1, tag, self._header + self._contents) + self._header\n        return self._header + self._contents\n\n\nclass Concat(object):\n    \"\"\"\n    A class that contains two or more encoded child values concatentated\n    together. THIS IS NOT PART OF THE ASN.1 SPECIFICATION! This exists to handle\n    the x509.TrustedCertificate() class for OpenSSL certificates containing\n    extra information.\n    \"\"\"\n\n    # A list of the specs of the concatenated values\n    _child_specs = None\n\n    _children = None\n\n    @classmethod\n    def load(cls, encoded_data, strict=False):\n        \"\"\"\n        Loads a BER/DER-encoded byte string using the current class as the spec\n\n        :param encoded_data:\n            A byte string of BER or DER encoded data\n\n        :param strict:\n            A boolean indicating if trailing data should be forbidden - if so, a\n            ValueError will be raised when trailing data exists\n\n        :return:\n            A Concat object\n        \"\"\"\n\n        return cls(contents=encoded_data, strict=strict)\n\n    def __init__(self, value=None, contents=None, strict=False):\n        \"\"\"\n        :param value:\n            A native Python datatype to initialize the object value with\n\n        :param contents:\n            A byte string of the encoded contents of the value\n\n        :param strict:\n            A boolean indicating if trailing data should be forbidden - if so, a\n            ValueError will be raised when trailing data exists in contents\n\n        :raises:\n            ValueError - when an error occurs with one of the children\n            TypeError - when an error occurs with one of the children\n        \"\"\"\n\n        if contents is not None:\n            try:\n                contents_len = len(contents)\n                self._children = []\n\n                offset = 0\n                for spec in self._child_specs:\n                    if offset < contents_len:\n                        child_value, offset = _parse_build(contents, pointer=offset, spec=spec)\n                    else:\n                        child_value = spec()\n                    self._children.append(child_value)\n\n                if strict and offset != contents_len:\n                    extra_bytes = contents_len - offset\n                    raise ValueError('Extra data - %d bytes of trailing data were provided' % extra_bytes)\n\n            except (ValueError, TypeError) as e:\n                args = e.args[1:]\n                e.args = (e.args[0] + '\\n    while constructing %s' % type_name(self),) + args\n                raise e\n\n        if value is not None:\n            if self._children is None:\n                self._children = [None] * len(self._child_specs)\n            for index, data in enumerate(value):\n                self.__setitem__(index, data)\n\n    def __str__(self):\n        \"\"\"\n        Since str is different in Python 2 and 3, this calls the appropriate\n        method, __unicode__() or __bytes__()\n\n        :return:\n            A unicode string\n        \"\"\"\n\n        if _PY2:\n            return self.__bytes__()\n        else:\n            return self.__unicode__()\n\n    def __bytes__(self):\n        \"\"\"\n        A byte string of the DER-encoded contents\n        \"\"\"\n\n        return self.dump()\n\n    def __unicode__(self):\n        \"\"\"\n        :return:\n            A unicode string\n        \"\"\"\n\n        return repr(self)\n\n    def __repr__(self):\n        \"\"\"\n        :return:\n            A unicode string\n        \"\"\"\n\n        return '<%s %s %s>' % (type_name(self), id(self), repr(self.dump()))\n\n    def __copy__(self):\n        \"\"\"\n        Implements the copy.copy() interface\n\n        :return:\n            A new shallow copy of the Concat object\n        \"\"\"\n\n        new_obj = self.__class__()\n        new_obj._copy(self, copy.copy)\n        return new_obj\n\n    def __deepcopy__(self, memo):\n        \"\"\"\n        Implements the copy.deepcopy() interface\n\n        :param memo:\n            A dict for memoization\n\n        :return:\n            A new deep copy of the Concat object and all child objects\n        \"\"\"\n\n        new_obj = self.__class__()\n        memo[id(self)] = new_obj\n        new_obj._copy(self, copy.deepcopy)\n        return new_obj\n\n    def copy(self):\n        \"\"\"\n        Copies the object\n\n        :return:\n            A Concat object\n        \"\"\"\n\n        return copy.deepcopy(self)\n\n    def _copy(self, other, copy_func):\n        \"\"\"\n        Copies the contents of another Concat object to itself\n\n        :param object:\n            Another instance of the same class\n\n        :param copy_func:\n            An reference of copy.copy() or copy.deepcopy() to use when copying\n            lists, dicts and objects\n        \"\"\"\n\n        if self.__class__ != other.__class__:\n            raise TypeError(unwrap(\n                '''\n                Can not copy values from %s object to %s object\n                ''',\n                type_name(other),\n                type_name(self)\n            ))\n\n        self._children = copy_func(other._children)\n\n    def debug(self, nest_level=1):\n        \"\"\"\n        Show the binary data and parsed data in a tree structure\n        \"\"\"\n\n        prefix = '  ' * nest_level\n        print('%s%s Object #%s' % (prefix, type_name(self), id(self)))\n        print('%s  Children:' % (prefix,))\n        for child in self._children:\n            child.debug(nest_level + 2)\n\n    def dump(self, force=False):\n        \"\"\"\n        Encodes the value using DER\n\n        :param force:\n            If the encoded contents already exist, clear them and regenerate\n            to ensure they are in DER format instead of BER format\n\n        :return:\n            A byte string of the DER-encoded value\n        \"\"\"\n\n        contents = b''\n        for child in self._children:\n            contents += child.dump(force=force)\n        return contents\n\n    @property\n    def contents(self):\n        \"\"\"\n        :return:\n            A byte string of the DER-encoded contents of the children\n        \"\"\"\n\n        return self.dump()\n\n    def __len__(self):\n        \"\"\"\n        :return:\n            Integer\n        \"\"\"\n\n        return len(self._children)\n\n    def __getitem__(self, key):\n        \"\"\"\n        Allows accessing children by index\n\n        :param key:\n            An integer of the child index\n\n        :raises:\n            KeyError - when an index is invalid\n\n        :return:\n            The Asn1Value object of the child specified\n        \"\"\"\n\n        if key > len(self._child_specs) - 1 or key < 0:\n            raise KeyError(unwrap(\n                '''\n                No child is definition for position %d of %s\n                ''',\n                key,\n                type_name(self)\n            ))\n\n        return self._children[key]\n\n    def __setitem__(self, key, value):\n        \"\"\"\n        Allows settings children by index\n\n        :param key:\n            An integer of the child index\n\n        :param value:\n            An Asn1Value object to set the child to\n\n        :raises:\n            KeyError - when an index is invalid\n            ValueError - when the value is not an instance of Asn1Value\n        \"\"\"\n\n        if key > len(self._child_specs) - 1 or key < 0:\n            raise KeyError(unwrap(\n                '''\n                No child is defined for position %d of %s\n                ''',\n                key,\n                type_name(self)\n            ))\n\n        if not isinstance(value, Asn1Value):\n            raise ValueError(unwrap(\n                '''\n                Value for child %s of %s is not an instance of\n                asn1crypto.core.Asn1Value\n                ''',\n                key,\n                type_name(self)\n            ))\n\n        self._children[key] = value\n\n    def __iter__(self):\n        \"\"\"\n        :return:\n            An iterator of child values\n        \"\"\"\n\n        return iter(self._children)\n\n\nclass Primitive(Asn1Value):\n    \"\"\"\n    Sets the class_ and method attributes for primitive, universal values\n    \"\"\"\n\n    class_ = 0\n\n    method = 0\n\n    def __init__(self, value=None, default=None, contents=None, **kwargs):\n        \"\"\"\n        Sets the value of the object before passing to Asn1Value.__init__()\n\n        :param value:\n            A native Python datatype to initialize the object value with\n\n        :param default:\n            The default value if no value is specified\n\n        :param contents:\n            A byte string of the encoded contents of the value\n        \"\"\"\n\n        Asn1Value.__init__(self, **kwargs)\n\n        try:\n            if contents is not None:\n                self.contents = contents\n\n            elif value is not None:\n                self.set(value)\n\n            elif default is not None:\n                self.set(default)\n\n        except (ValueError, TypeError) as e:\n            args = e.args[1:]\n            e.args = (e.args[0] + '\\n    while constructing %s' % type_name(self),) + args\n            raise e\n\n    def set(self, value):\n        \"\"\"\n        Sets the value of the object\n\n        :param value:\n            A byte string\n        \"\"\"\n\n        if not isinstance(value, byte_cls):\n            raise TypeError(unwrap(\n                '''\n                %s value must be a byte string, not %s\n                ''',\n                type_name(self),\n                type_name(value)\n            ))\n\n        self._native = value\n        self.contents = value\n        self._header = None\n        if self._trailer != b'':\n            self._trailer = b''\n\n    def dump(self, force=False):\n        \"\"\"\n        Encodes the value using DER\n\n        :param force:\n            If the encoded contents already exist, clear them and regenerate\n            to ensure they are in DER format instead of BER format\n\n        :return:\n            A byte string of the DER-encoded value\n        \"\"\"\n\n        # If the length is indefinite, force the re-encoding\n        if self._header is not None and self._header[-1:] == b'\\x80':\n            force = True\n\n        if force:\n            native = self.native\n            self.contents = None\n            self.set(native)\n\n        return Asn1Value.dump(self)\n\n    def __ne__(self, other):\n        return not self == other\n\n    def __eq__(self, other):\n        \"\"\"\n        :param other:\n            The other Primitive to compare to\n\n        :return:\n            A boolean\n        \"\"\"\n\n        if not isinstance(other, Primitive):\n            return False\n\n        if self.contents != other.contents:\n            return False\n\n        # We compare class tag numbers since object tag numbers could be\n        # different due to implicit or explicit tagging\n        if self.__class__.tag != other.__class__.tag:\n            return False\n\n        if self.__class__ == other.__class__ and self.contents == other.contents:\n            return True\n\n        # If the objects share a common base class that is not too low-level\n        # then we can compare the contents\n        self_bases = (set(self.__class__.__bases__) | set([self.__class__])) - set([Asn1Value, Primitive, ValueMap])\n        other_bases = (set(other.__class__.__bases__) | set([other.__class__])) - set([Asn1Value, Primitive, ValueMap])\n        if self_bases | other_bases:\n            return self.contents == other.contents\n\n        # When tagging is going on, do the extra work of constructing new\n        # objects to see if the dumped representation are the same\n        if self.implicit or self.explicit or other.implicit or other.explicit:\n            return self.untag().dump() == other.untag().dump()\n\n        return self.dump() == other.dump()\n\n\nclass AbstractString(Constructable, Primitive):\n    \"\"\"\n    A base class for all strings that have a known encoding. In general, we do\n    not worry ourselves with confirming that the decoded values match a specific\n    set of characters, only that they are decoded into a Python unicode string\n    \"\"\"\n\n    # The Python encoding name to use when decoding or encoded the contents\n    _encoding = 'latin1'\n\n    # Instance attribute of (possibly-merged) unicode string\n    _unicode = None\n\n    def set(self, value):\n        \"\"\"\n        Sets the value of the string\n\n        :param value:\n            A unicode string\n        \"\"\"\n\n        if not isinstance(value, str_cls):\n            raise TypeError(unwrap(\n                '''\n                %s value must be a unicode string, not %s\n                ''',\n                type_name(self),\n                type_name(value)\n            ))\n\n        self._unicode = value\n        self.contents = value.encode(self._encoding)\n        self._header = None\n        if self._indefinite:\n            self._indefinite = False\n            self.method = 0\n        if self._trailer != b'':\n            self._trailer = b''\n\n    def __unicode__(self):\n        \"\"\"\n        :return:\n            A unicode string\n        \"\"\"\n\n        if self.contents is None:\n            return ''\n        if self._unicode is None:\n            self._unicode = self._merge_chunks().decode(self._encoding)\n        return self._unicode\n\n    def _copy(self, other, copy_func):\n        \"\"\"\n        Copies the contents of another AbstractString object to itself\n\n        :param object:\n            Another instance of the same class\n\n        :param copy_func:\n            An reference of copy.copy() or copy.deepcopy() to use when copying\n            lists, dicts and objects\n        \"\"\"\n\n        super(AbstractString, self)._copy(other, copy_func)\n        self._unicode = other._unicode\n\n    @property\n    def native(self):\n        \"\"\"\n        The native Python datatype representation of this value\n\n        :return:\n            A unicode string or None\n        \"\"\"\n\n        if self.contents is None:\n            return None\n\n        return self.__unicode__()\n\n\nclass Boolean(Primitive):\n    \"\"\"\n    Represents a boolean in both ASN.1 and Python\n    \"\"\"\n\n    tag = 1\n\n    def set(self, value):\n        \"\"\"\n        Sets the value of the object\n\n        :param value:\n            True, False or another value that works with bool()\n        \"\"\"\n\n        self._native = bool(value)\n        self.contents = b'\\x00' if not value else b'\\xff'\n        self._header = None\n        if self._trailer != b'':\n            self._trailer = b''\n\n    # Python 2\n    def __nonzero__(self):\n        \"\"\"\n        :return:\n            True or False\n        \"\"\"\n        return self.__bool__()\n\n    def __bool__(self):\n        \"\"\"\n        :return:\n            True or False\n        \"\"\"\n        return self.contents != b'\\x00'\n\n    @property\n    def native(self):\n        \"\"\"\n        The native Python datatype representation of this value\n\n        :return:\n            True, False or None\n        \"\"\"\n\n        if self.contents is None:\n            return None\n\n        if self._native is None:\n            self._native = self.__bool__()\n        return self._native\n\n\nclass Integer(Primitive, ValueMap):\n    \"\"\"\n    Represents an integer in both ASN.1 and Python\n    \"\"\"\n\n    tag = 2\n\n    def set(self, value):\n        \"\"\"\n        Sets the value of the object\n\n        :param value:\n            An integer, or a unicode string if _map is set\n\n        :raises:\n            ValueError - when an invalid value is passed\n        \"\"\"\n\n        if isinstance(value, str_cls):\n            if self._map is None:\n                raise ValueError(unwrap(\n                    '''\n                    %s value is a unicode string, but no _map provided\n                    ''',\n                    type_name(self)\n                ))\n\n            if value not in self._reverse_map:\n                raise ValueError(unwrap(\n                    '''\n                    %s value, %s, is not present in the _map\n                    ''',\n                    type_name(self),\n                    value\n                ))\n\n            value = self._reverse_map[value]\n\n        elif not isinstance(value, int_types):\n            raise TypeError(unwrap(\n                '''\n                %s value must be an integer or unicode string when a name_map\n                is provided, not %s\n                ''',\n                type_name(self),\n                type_name(value)\n            ))\n\n        self._native = self._map[value] if self._map and value in self._map else value\n\n        self.contents = int_to_bytes(value, signed=True)\n        self._header = None\n        if self._trailer != b'':\n            self._trailer = b''\n\n    def __int__(self):\n        \"\"\"\n        :return:\n            An integer\n        \"\"\"\n        return int_from_bytes(self.contents, signed=True)\n\n    @property\n    def native(self):\n        \"\"\"\n        The native Python datatype representation of this value\n\n        :return:\n            An integer or None\n        \"\"\"\n\n        if self.contents is None:\n            return None\n\n        if self._native is None:\n            self._native = self.__int__()\n            if self._map is not None and self._native in self._map:\n                self._native = self._map[self._native]\n        return self._native\n\n\nclass _IntegerBitString(object):\n    \"\"\"\n    A mixin for IntegerBitString and BitString to parse the contents as an integer.\n    \"\"\"\n\n    # Tuple of 1s and 0s; set through native\n    _unused_bits = ()\n\n    def _as_chunk(self):\n        \"\"\"\n        Parse the contents of a primitive BitString encoding as an integer value.\n        Allows reconstructing indefinite length values.\n\n        :raises:\n            ValueError - when an invalid value is passed\n\n        :return:\n            A list with one tuple (value, bits, unused_bits) where value is an integer\n            with the value of the BitString, bits is the bit count of value and\n            unused_bits is a tuple of 1s and 0s.\n        \"\"\"\n\n        if self._indefinite:\n            # return an empty chunk, for cases like \\x23\\x80\\x00\\x00\n            return []\n\n        unused_bits_len = ord(self.contents[0]) if _PY2 else self.contents[0]\n        value = int_from_bytes(self.contents[1:])\n        bits = (len(self.contents) - 1) * 8\n\n        if not unused_bits_len:\n            return [(value, bits, ())]\n\n        if len(self.contents) == 1:\n            # Disallowed by X.690 \u00a78.6.2.3\n            raise ValueError('Empty bit string has {0} unused bits'.format(unused_bits_len))\n\n        if unused_bits_len > 7:\n            # Disallowed by X.690 \u00a78.6.2.2\n            raise ValueError('Bit string has {0} unused bits'.format(unused_bits_len))\n\n        unused_bits = _int_to_bit_tuple(value & ((1 << unused_bits_len) - 1), unused_bits_len)\n        value >>= unused_bits_len\n        bits -= unused_bits_len\n\n        return [(value, bits, unused_bits)]\n\n    def _chunks_to_int(self):\n        \"\"\"\n        Combines the chunks into a single value.\n\n        :raises:\n            ValueError - when an invalid value is passed\n\n        :return:\n            A tuple (value, bits, unused_bits) where value is an integer with the\n            value of the BitString, bits is the bit count of value and unused_bits\n            is a tuple of 1s and 0s.\n        \"\"\"\n\n        if not self._indefinite:\n            # Fast path\n            return self._as_chunk()[0]\n\n        value = 0\n        total_bits = 0\n        unused_bits = ()\n\n        # X.690 \u00a78.6.3 allows empty indefinite encodings\n        for chunk, bits, unused_bits in self._merge_chunks():\n            if total_bits & 7:\n                # Disallowed by X.690 \u00a78.6.4\n                raise ValueError('Only last chunk in a bit string may have unused bits')\n            total_bits += bits\n            value = (value << bits) | chunk\n\n        return value, total_bits, unused_bits\n\n    def _copy(self, other, copy_func):\n        \"\"\"\n        Copies the contents of another _IntegerBitString object to itself\n\n        :param object:\n            Another instance of the same class\n\n        :param copy_func:\n            An reference of copy.copy() or copy.deepcopy() to use when copying\n            lists, dicts and objects\n        \"\"\"\n\n        super(_IntegerBitString, self)._copy(other, copy_func)\n        self._unused_bits = other._unused_bits\n\n    @property\n    def unused_bits(self):\n        \"\"\"\n        The unused bits of the bit string encoding.\n\n        :return:\n            A tuple of 1s and 0s\n        \"\"\"\n\n        # call native to set _unused_bits\n        self.native\n\n        return self._unused_bits\n\n\nclass BitString(_IntegerBitString, Constructable, Castable, Primitive, ValueMap):\n    \"\"\"\n    Represents a bit string from ASN.1 as a Python tuple of 1s and 0s\n    \"\"\"\n\n    tag = 3\n\n    _size = None\n\n    def _setup(self):\n        \"\"\"\n        Generates _reverse_map from _map\n        \"\"\"\n\n        ValueMap._setup(self)\n\n        cls = self.__class__\n        if cls._map is not None:\n            cls._size = max(self._map.keys()) + 1\n\n    def set(self, value):\n        \"\"\"\n        Sets the value of the object\n\n        :param value:\n            An integer or a tuple of integers 0 and 1\n\n        :raises:\n            ValueError - when an invalid value is passed\n        \"\"\"\n\n        if isinstance(value, set):\n            if self._map is None:\n                raise ValueError(unwrap(\n                    '''\n                    %s._map has not been defined\n                    ''',\n                    type_name(self)\n                ))\n\n            bits = [0] * self._size\n            self._native = value\n            for index in range(0, self._size):\n                key = self._map.get(index)\n                if key is None:\n                    continue\n                if key in value:\n                    bits[index] = 1\n\n            value = ''.join(map(str_cls, bits))\n\n        elif value.__class__ == tuple:\n            if self._map is None:\n                self._native = value\n            else:\n                self._native = set()\n                for index, bit in enumerate(value):\n                    if bit:\n                        name = self._map.get(index, index)\n                        self._native.add(name)\n            value = ''.join(map(str_cls, value))\n\n        else:\n            raise TypeError(unwrap(\n                '''\n                %s value must be a tuple of ones and zeros or a set of unicode\n                strings, not %s\n                ''',\n                type_name(self),\n                type_name(value)\n            ))\n\n        if self._map is not None:\n            if len(value) > self._size:\n                raise ValueError(unwrap(\n                    '''\n                    %s value must be at most %s bits long, specified was %s long\n                    ''',\n                    type_name(self),\n                    self._size,\n                    len(value)\n                ))\n            # A NamedBitList must have trailing zero bit truncated. See\n            # https://www.itu.int/ITU-T/studygroups/com17/languages/X.690-0207.pdf\n            # section 11.2,\n            # https://tools.ietf.org/html/rfc5280#page-134 and\n            # https://www.ietf.org/mail-archive/web/pkix/current/msg10443.html\n            value = value.rstrip('0')\n        size = len(value)\n\n        size_mod = size % 8\n        extra_bits = 0\n        if size_mod != 0:\n            extra_bits = 8 - size_mod\n            value += '0' * extra_bits\n\n        size_in_bytes = int(math.ceil(size / 8))\n\n        if extra_bits:\n            extra_bits_byte = int_to_bytes(extra_bits)\n        else:\n            extra_bits_byte = b'\\x00'\n\n        if value == '':\n            value_bytes = b''\n        else:\n            value_bytes = int_to_bytes(int(value, 2))\n        if len(value_bytes) != size_in_bytes:\n            value_bytes = (b'\\x00' * (size_in_bytes - len(value_bytes))) + value_bytes\n\n        self.contents = extra_bits_byte + value_bytes\n        self._unused_bits = (0,) * extra_bits\n        self._header = None\n        if self._indefinite:\n            self._indefinite = False\n            self.method = 0\n        if self._trailer != b'':\n            self._trailer = b''\n\n    def __getitem__(self, key):\n        \"\"\"\n        Retrieves a boolean version of one of the bits based on a name from the\n        _map\n\n        :param key:\n            The unicode string of one of the bit names\n\n        :raises:\n            ValueError - when _map is not set or the key name is invalid\n\n        :return:\n            A boolean if the bit is set\n        \"\"\"\n\n        is_int = isinstance(key, int_types)\n        if not is_int:\n            if not isinstance(self._map, dict):\n                raise ValueError(unwrap(\n                    '''\n                    %s._map has not been defined\n                    ''',\n                    type_name(self)\n                ))\n\n            if key not in self._reverse_map:\n                raise ValueError(unwrap(\n                    '''\n                    %s._map does not contain an entry for \"%s\"\n                    ''',\n                    type_name(self),\n                    key\n                ))\n\n        if self._native is None:\n            self.native\n\n        if self._map is None:\n            if len(self._native) >= key + 1:\n                return bool(self._native[key])\n            return False\n\n        if is_int:\n            key = self._map.get(key, key)\n\n        return key in self._native\n\n    def __setitem__(self, key, value):\n        \"\"\"\n        Sets one of the bits based on a name from the _map\n\n        :param key:\n            The unicode string of one of the bit names\n\n        :param value:\n            A boolean value\n\n        :raises:\n            ValueError - when _map is not set or the key name is invalid\n        \"\"\"\n\n        is_int = isinstance(key, int_types)\n        if not is_int:\n            if self._map is None:\n                raise ValueError(unwrap(\n                    '''\n                    %s._map has not been defined\n                    ''',\n                    type_name(self)\n                ))\n\n            if key not in self._reverse_map:\n                raise ValueError(unwrap(\n                    '''\n                    %s._map does not contain an entry for \"%s\"\n                    ''',\n                    type_name(self),\n                    key\n                ))\n\n        if self._native is None:\n            self.native\n\n        if self._map is None:\n            new_native = list(self._native)\n            max_key = len(new_native) - 1\n            if key > max_key:\n                new_native.extend([0] * (key - max_key))\n            new_native[key] = 1 if value else 0\n            self._native = tuple(new_native)\n\n        else:\n            if is_int:\n                key = self._map.get(key, key)\n\n            if value:\n                if key not in self._native:\n                    self._native.add(key)\n            else:\n                if key in self._native:\n                    self._native.remove(key)\n\n        self.set(self._native)\n\n    @property\n    def native(self):\n        \"\"\"\n        The native Python datatype representation of this value\n\n        :return:\n            If a _map is set, a set of names, or if no _map is set, a tuple of\n            integers 1 and 0. None if no value.\n        \"\"\"\n\n        # For BitString we default the value to be all zeros\n        if self.contents is None:\n            if self._map is None:\n                self.set(())\n            else:\n                self.set(set())\n\n        if self._native is None:\n            int_value, bit_count, self._unused_bits = self._chunks_to_int()\n            bits = _int_to_bit_tuple(int_value, bit_count)\n\n            if self._map:\n                self._native = set()\n                for index, bit in enumerate(bits):\n                    if bit:\n                        name = self._map.get(index, index)\n                        self._native.add(name)\n            else:\n                self._native = bits\n        return self._native\n\n\nclass OctetBitString(Constructable, Castable, Primitive):\n    \"\"\"\n    Represents a bit string in ASN.1 as a Python byte string\n    \"\"\"\n\n    tag = 3\n\n    # Instance attribute of (possibly-merged) byte string\n    _bytes = None\n\n    # Tuple of 1s and 0s; set through native\n    _unused_bits = ()\n\n    def set(self, value):\n        \"\"\"\n        Sets the value of the object\n\n        :param value:\n            A byte string\n\n        :raises:\n            ValueError - when an invalid value is passed\n        \"\"\"\n\n        if not isinstance(value, byte_cls):\n            raise TypeError(unwrap(\n                '''\n                %s value must be a byte string, not %s\n                ''',\n                type_name(self),\n                type_name(value)\n            ))\n\n        self._bytes = value\n        # Set the unused bits to 0\n        self.contents = b'\\x00' + value\n        self._unused_bits = ()\n        self._header = None\n        if self._indefinite:\n            self._indefinite = False\n            self.method = 0\n        if self._trailer != b'':\n            self._trailer = b''\n\n    def __bytes__(self):\n        \"\"\"\n        :return:\n            A byte string\n        \"\"\"\n\n        if self.contents is None:\n            return b''\n        if self._bytes is None:\n            if not self._indefinite:\n                self._bytes, self._unused_bits = self._as_chunk()[0]\n            else:\n                chunks = self._merge_chunks()\n                self._unused_bits = ()\n                for chunk in chunks:\n                    if self._unused_bits:\n                        # Disallowed by X.690 \u00a78.6.4\n                        raise ValueError('Only last chunk in a bit string may have unused bits')\n                    self._unused_bits = chunk[1]\n                self._bytes = b''.join(chunk[0] for chunk in chunks)\n\n        return self._bytes\n\n    def _copy(self, other, copy_func):\n        \"\"\"\n        Copies the contents of another OctetBitString object to itself\n\n        :param object:\n            Another instance of the same class\n\n        :param copy_func:\n            An reference of copy.copy() or copy.deepcopy() to use when copying\n            lists, dicts and objects\n        \"\"\"\n\n        super(OctetBitString, self)._copy(other, copy_func)\n        self._bytes = other._bytes\n        self._unused_bits = other._unused_bits\n\n    def _as_chunk(self):\n        \"\"\"\n        Allows reconstructing indefinite length values\n\n        :raises:\n            ValueError - when an invalid value is passed\n\n        :return:\n            List with one tuple, consisting of a byte string and an integer (unused bits)\n        \"\"\"\n\n        unused_bits_len = ord(self.contents[0]) if _PY2 else self.contents[0]\n        if not unused_bits_len:\n            return [(self.contents[1:], ())]\n\n        if len(self.contents) == 1:\n            # Disallowed by X.690 \u00a78.6.2.3\n            raise ValueError('Empty bit string has {0} unused bits'.format(unused_bits_len))\n\n        if unused_bits_len > 7:\n            # Disallowed by X.690 \u00a78.6.2.2\n            raise ValueError('Bit string has {0} unused bits'.format(unused_bits_len))\n\n        mask = (1 << unused_bits_len) - 1\n        last_byte = ord(self.contents[-1]) if _PY2 else self.contents[-1]\n\n        # zero out the unused bits in the last byte.\n        zeroed_byte = last_byte & ~mask\n        value = self.contents[1:-1] + (chr(zeroed_byte) if _PY2 else bytes((zeroed_byte,)))\n\n        unused_bits = _int_to_bit_tuple(last_byte & mask, unused_bits_len)\n\n        return [(value, unused_bits)]\n\n    @property\n    def native(self):\n        \"\"\"\n        The native Python datatype representation of this value\n\n        :return:\n            A byte string or None\n        \"\"\"\n\n        if self.contents is None:\n            return None\n\n        return self.__bytes__()\n\n    @property\n    def unused_bits(self):\n        \"\"\"\n        The unused bits of the bit string encoding.\n\n        :return:\n            A tuple of 1s and 0s\n        \"\"\"\n\n        # call native to set _unused_bits\n        self.native\n\n        return self._unused_bits\n\n\nclass IntegerBitString(_IntegerBitString, Constructable, Castable, Primitive):\n    \"\"\"\n    Represents a bit string in ASN.1 as a Python integer\n    \"\"\"\n\n    tag = 3\n\n    def set(self, value):\n        \"\"\"\n        Sets the value of the object\n\n        :param value:\n            An integer\n\n        :raises:\n            ValueError - when an invalid value is passed\n        \"\"\"\n\n        if not isinstance(value, int_types):\n            raise TypeError(unwrap(\n                '''\n                %s value must be a positive integer, not %s\n                ''',\n                type_name(self),\n                type_name(value)\n            ))\n\n        if value < 0:\n            raise ValueError(unwrap(\n                '''\n                %s value must be a positive integer, not %d\n                ''',\n                type_name(self),\n                value\n            ))\n\n        self._native = value\n        # Set the unused bits to 0\n        self.contents = b'\\x00' + int_to_bytes(value, signed=True)\n        self._unused_bits = ()\n        self._header = None\n        if self._indefinite:\n            self._indefinite = False\n            self.method = 0\n        if self._trailer != b'':\n            self._trailer = b''\n\n    @property\n    def native(self):\n        \"\"\"\n        The native Python datatype representation of this value\n\n        :return:\n            An integer or None\n        \"\"\"\n\n        if self.contents is None:\n            return None\n\n        if self._native is None:\n            self._native, __, self._unused_bits = self._chunks_to_int()\n\n        return self._native\n\n\nclass OctetString(Constructable, Castable, Primitive):\n    \"\"\"\n    Represents a byte string in both ASN.1 and Python\n    \"\"\"\n\n    tag = 4\n\n    # Instance attribute of (possibly-merged) byte string\n    _bytes = None\n\n    def set(self, value):\n        \"\"\"\n        Sets the value of the object\n\n        :param value:\n            A byte string\n        \"\"\"\n\n        if not isinstance(value, byte_cls):\n            raise TypeError(unwrap(\n                '''\n                %s value must be a byte string, not %s\n                ''',\n                type_name(self),\n                type_name(value)\n            ))\n\n        self._bytes = value\n        self.contents = value\n        self._header = None\n        if self._indefinite:\n            self._indefinite = False\n            self.method = 0\n        if self._trailer != b'':\n            self._trailer = b''\n\n    def __bytes__(self):\n        \"\"\"\n        :return:\n            A byte string\n        \"\"\"\n\n        if self.contents is None:\n            return b''\n        if self._bytes is None:\n            self._bytes = self._merge_chunks()\n        return self._bytes\n\n    def _copy(self, other, copy_func):\n        \"\"\"\n        Copies the contents of another OctetString object to itself\n\n        :param object:\n            Another instance of the same class\n\n        :param copy_func:\n            An reference of copy.copy() or copy.deepcopy() to use when copying\n            lists, dicts and objects\n        \"\"\"\n\n        super(OctetString, self)._copy(other, copy_func)\n        self._bytes = other._bytes\n\n    @property\n    def native(self):\n        \"\"\"\n        The native Python datatype representation of this value\n\n        :return:\n            A byte string or None\n        \"\"\"\n\n        if self.contents is None:\n            return None\n\n        return self.__bytes__()\n\n\nclass IntegerOctetString(Constructable, Castable, Primitive):\n    \"\"\"\n    Represents a byte string in ASN.1 as a Python integer\n    \"\"\"\n\n    tag = 4\n\n    # An explicit length in bytes the integer should be encoded to. This should\n    # generally not be used since DER defines a canonical encoding, however some\n    # use of this, such as when storing elliptic curve private keys, requires an\n    # exact number of bytes, even if the leading bytes are null.\n    _encoded_width = None\n\n    def set(self, value):\n        \"\"\"\n        Sets the value of the object\n\n        :param value:\n            An integer\n\n        :raises:\n            ValueError - when an invalid value is passed\n        \"\"\"\n\n        if not isinstance(value, int_types):\n            raise TypeError(unwrap(\n                '''\n                %s value must be a positive integer, not %s\n                ''',\n                type_name(self),\n                type_name(value)\n            ))\n\n        if value < 0:\n            raise ValueError(unwrap(\n                '''\n                %s value must be a positive integer, not %d\n                ''',\n                type_name(self),\n                value\n            ))\n\n        self._native = value\n        self.contents = int_to_bytes(value, signed=False, width=self._encoded_width)\n        self._header = None\n        if self._indefinite:\n            self._indefinite = False\n            self.method = 0\n        if self._trailer != b'':\n            self._trailer = b''\n\n    @property\n    def native(self):\n        \"\"\"\n        The native Python datatype representation of this value\n\n        :return:\n            An integer or None\n        \"\"\"\n\n        if self.contents is None:\n            return None\n\n        if self._native is None:\n            self._native = int_from_bytes(self._merge_chunks())\n        return self._native\n\n    def set_encoded_width(self, width):\n        \"\"\"\n        Set the explicit enoding width for the integer\n\n        :param width:\n            An integer byte width to encode the integer to\n        \"\"\"\n\n        self._encoded_width = width\n        # Make sure the encoded value is up-to-date with the proper width\n        if self.contents is not None and len(self.contents) != width:\n            self.set(self.native)\n\n\nclass ParsableOctetString(Constructable, Castable, Primitive):\n\n    tag = 4\n\n    _parsed = None\n\n    # Instance attribute of (possibly-merged) byte string\n    _bytes = None\n\n    def __init__(self, value=None, parsed=None, **kwargs):\n        \"\"\"\n        Allows providing a parsed object that will be serialized to get the\n        byte string value\n\n        :param value:\n            A native Python datatype to initialize the object value with\n\n        :param parsed:\n            If value is None and this is an Asn1Value object, this will be\n            set as the parsed value, and the value will be obtained by calling\n            .dump() on this object.\n        \"\"\"\n\n        set_parsed = False\n        if value is None and parsed is not None and isinstance(parsed, Asn1Value):\n            value = parsed.dump()\n            set_parsed = True\n\n        Primitive.__init__(self, value=value, **kwargs)\n\n        if set_parsed:\n            self._parsed = (parsed, parsed.__class__, None)\n\n    def set(self, value):\n        \"\"\"\n        Sets the value of the object\n\n        :param value:\n            A byte string\n        \"\"\"\n\n        if not isinstance(value, byte_cls):\n            raise TypeError(unwrap(\n                '''\n                %s value must be a byte string, not %s\n                ''',\n                type_name(self),\n                type_name(value)\n            ))\n\n        self._bytes = value\n        self.contents = value\n        self._header = None\n        if self._indefinite:\n            self._indefinite = False\n            self.method = 0\n        if self._trailer != b'':\n            self._trailer = b''\n\n    def parse(self, spec=None, spec_params=None):\n        \"\"\"\n        Parses the contents generically, or using a spec with optional params\n\n        :param spec:\n            A class derived from Asn1Value that defines what class_ and tag the\n            value should have, and the semantics of the encoded value. The\n            return value will be of this type. If omitted, the encoded value\n            will be decoded using the standard universal tag based on the\n            encoded tag number.\n\n        :param spec_params:\n            A dict of params to pass to the spec object\n\n        :return:\n            An object of the type spec, or if not present, a child of Asn1Value\n        \"\"\"\n\n        if self._parsed is None or self._parsed[1:3] != (spec, spec_params):\n            parsed_value, _ = _parse_build(self.__bytes__(), spec=spec, spec_params=spec_params)\n            self._parsed = (parsed_value, spec, spec_params)\n        return self._parsed[0]\n\n    def __bytes__(self):\n        \"\"\"\n        :return:\n            A byte string\n        \"\"\"\n\n        if self.contents is None:\n            return b''\n        if self._bytes is None:\n            self._bytes = self._merge_chunks()\n        return self._bytes\n\n    def _setable_native(self):\n        \"\"\"\n        Returns a byte string that can be passed into .set()\n\n        :return:\n            A python value that is valid to pass to .set()\n        \"\"\"\n\n        return self.__bytes__()\n\n    def _copy(self, other, copy_func):\n        \"\"\"\n        Copies the contents of another ParsableOctetString object to itself\n\n        :param object:\n            Another instance of the same class\n\n        :param copy_func:\n            An reference of copy.copy() or copy.deepcopy() to use when copying\n            lists, dicts and objects\n        \"\"\"\n\n        super(ParsableOctetString, self)._copy(other, copy_func)\n        self._bytes = other._bytes\n        self._parsed = copy_func(other._parsed)\n\n    @property\n    def native(self):\n        \"\"\"\n        The native Python datatype representation of this value\n\n        :return:\n            A byte string or None\n        \"\"\"\n\n        if self.contents is None:\n            return None\n\n        if self._parsed is not None:\n            return self._parsed[0].native\n        else:\n            return self.__bytes__()\n\n    @property\n    def parsed(self):\n        \"\"\"\n        Returns the parsed object from .parse()\n\n        :return:\n            The object returned by .parse()\n        \"\"\"\n\n        if self._parsed is None:\n            self.parse()\n\n        return self._parsed[0]\n\n    def dump(self, force=False):\n        \"\"\"\n        Encodes the value using DER\n\n        :param force:\n            If the encoded contents already exist, clear them and regenerate\n            to ensure they are in DER format instead of BER format\n\n        :return:\n            A byte string of the DER-encoded value\n        \"\"\"\n\n        # If the length is indefinite, force the re-encoding\n        if self._indefinite:\n            force = True\n\n        if force:\n            if self._parsed is not None:\n                native = self.parsed.dump(force=force)\n            else:\n                native = self.native\n            self.contents = None\n            self.set(native)\n\n        return Asn1Value.dump(self)\n\n\nclass ParsableOctetBitString(ParsableOctetString):\n\n    tag = 3\n\n    def set(self, value):\n        \"\"\"\n        Sets the value of the object\n\n        :param value:\n            A byte string\n\n        :raises:\n            ValueError - when an invalid value is passed\n        \"\"\"\n\n        if not isinstance(value, byte_cls):\n            raise TypeError(unwrap(\n                '''\n                %s value must be a byte string, not %s\n                ''',\n                type_name(self),\n                type_name(value)\n            ))\n\n        self._bytes = value\n        # Set the unused bits to 0\n        self.contents = b'\\x00' + value\n        self._header = None\n        if self._indefinite:\n            self._indefinite = False\n            self.method = 0\n        if self._trailer != b'':\n            self._trailer = b''\n\n    def _as_chunk(self):\n        \"\"\"\n        Allows reconstructing indefinite length values\n\n        :raises:\n            ValueError - when an invalid value is passed\n\n        :return:\n            A byte string\n        \"\"\"\n\n        unused_bits_len = ord(self.contents[0]) if _PY2 else self.contents[0]\n        if unused_bits_len:\n            raise ValueError('ParsableOctetBitString should have no unused bits')\n\n        return self.contents[1:]\n\n\nclass Null(Primitive):\n    \"\"\"\n    Represents a null value in ASN.1 as None in Python\n    \"\"\"\n\n    tag = 5\n\n    contents = b''\n\n    def set(self, value):\n        \"\"\"\n        Sets the value of the object\n\n        :param value:\n            None\n        \"\"\"\n\n        self.contents = b''\n\n    @property\n    def native(self):\n        \"\"\"\n        The native Python datatype representation of this value\n\n        :return:\n            None\n        \"\"\"\n\n        return None\n\n\nclass ObjectIdentifier(Primitive, ValueMap):\n    \"\"\"\n    Represents an object identifier in ASN.1 as a Python unicode dotted\n    integer string\n    \"\"\"\n\n    tag = 6\n\n    # A unicode string of the dotted form of the object identifier\n    _dotted = None\n\n    @classmethod\n    def map(cls, value):\n        \"\"\"\n        Converts a dotted unicode string OID into a mapped unicode string\n\n        :param value:\n            A dotted unicode string OID\n\n        :raises:\n            ValueError - when no _map dict has been defined on the class\n            TypeError - when value is not a unicode string\n\n        :return:\n            A mapped unicode string\n        \"\"\"\n\n        if cls._map is None:\n            raise ValueError(unwrap(\n                '''\n                %s._map has not been defined\n                ''',\n                type_name(cls)\n            ))\n\n        if not isinstance(value, str_cls):\n            raise TypeError(unwrap(\n                '''\n                value must be a unicode string, not %s\n                ''',\n                type_name(value)\n            ))\n\n        return cls._map.get(value, value)\n\n    @classmethod\n    def unmap(cls, value):\n        \"\"\"\n        Converts a mapped unicode string value into a dotted unicode string OID\n\n        :param value:\n            A mapped unicode string OR dotted unicode string OID\n\n        :raises:\n            ValueError - when no _map dict has been defined on the class or the value can't be unmapped\n            TypeError - when value is not a unicode string\n\n        :return:\n            A dotted unicode string OID\n        \"\"\"\n\n        if cls not in _SETUP_CLASSES:\n            cls()._setup()\n            _SETUP_CLASSES[cls] = True\n\n        if cls._map is None:\n            raise ValueError(unwrap(\n                '''\n                %s._map has not been defined\n                ''',\n                type_name(cls)\n            ))\n\n        if not isinstance(value, str_cls):\n            raise TypeError(unwrap(\n                '''\n                value must be a unicode string, not %s\n                ''',\n                type_name(value)\n            ))\n\n        if value in cls._reverse_map:\n            return cls._reverse_map[value]\n\n        if not _OID_RE.match(value):\n            raise ValueError(unwrap(\n                '''\n                %s._map does not contain an entry for \"%s\"\n                ''',\n                type_name(cls),\n                value\n            ))\n\n        return value\n\n    def set(self, value):\n        \"\"\"\n        Sets the value of the object\n\n        :param value:\n            A unicode string. May be a dotted integer string, or if _map is\n            provided, one of the mapped values.\n\n        :raises:\n            ValueError - when an invalid value is passed\n        \"\"\"\n\n        if not isinstance(value, str_cls):\n            raise TypeError(unwrap(\n                '''\n                %s value must be a unicode string, not %s\n                ''',\n                type_name(self),\n                type_name(value)\n            ))\n\n        self._native = value\n\n        if self._map is not None:\n            if value in self._reverse_map:\n                value = self._reverse_map[value]\n\n        self.contents = b''\n        first = None\n        for index, part in enumerate(value.split('.')):\n            part = int(part)\n\n            # The first two parts are merged into a single byte\n            if index == 0:\n                first = part\n                continue\n            elif index == 1:\n                if first > 2:\n                    raise ValueError(unwrap(\n                        '''\n                        First arc must be one of 0, 1 or 2, not %s\n                        ''',\n                        repr(first)\n                    ))\n                elif first < 2 and part >= 40:\n                    raise ValueError(unwrap(\n                        '''\n                        Second arc must be less than 40 if first arc is 0 or\n                        1, not %s\n                        ''',\n                        repr(part)\n                    ))\n                part = (first * 40) + part\n\n            encoded_part = chr_cls(0x7F & part)\n            part = part >> 7\n            while part > 0:\n                encoded_part = chr_cls(0x80 | (0x7F & part)) + encoded_part\n                part = part >> 7\n            self.contents += encoded_part\n\n        self._header = None\n        if self._trailer != b'':\n            self._trailer = b''\n\n    def __unicode__(self):\n        \"\"\"\n        :return:\n            A unicode string\n        \"\"\"\n\n        return self.dotted\n\n    @property\n    def dotted(self):\n        \"\"\"\n        :return:\n            A unicode string of the object identifier in dotted notation, thus\n            ignoring any mapped value\n        \"\"\"\n\n        if self._dotted is None:\n            output = []\n\n            part = 0\n            for byte in self.contents:\n                if _PY2:\n                    byte = ord(byte)\n                part = part * 128\n                part += byte & 127\n                # Last byte in subidentifier has the eighth bit set to 0\n                if byte & 0x80 == 0:\n                    if len(output) == 0:\n                        if part >= 80:\n                            output.append(str_cls(2))\n                            output.append(str_cls(part - 80))\n                        elif part >= 40:\n                            output.append(str_cls(1))\n                            output.append(str_cls(part - 40))\n                        else:\n                            output.append(str_cls(0))\n                            output.append(str_cls(part))\n                    else:\n                        output.append(str_cls(part))\n                    part = 0\n\n            self._dotted = '.'.join(output)\n        return self._dotted\n\n    @property\n    def native(self):\n        \"\"\"\n        The native Python datatype representation of this value\n\n        :return:\n            A unicode string or None. If _map is not defined, the unicode string\n            is a string of dotted integers. If _map is defined and the dotted\n            string is present in the _map, the mapped value is returned.\n        \"\"\"\n\n        if self.contents is None:\n            return None\n\n        if self._native is None:\n            self._native = self.dotted\n        if self._map is not None and self._native in self._map:\n            self._native = self._map[self._native]\n        return self._native\n\n\nclass ObjectDescriptor(Primitive):\n    \"\"\"\n    Represents an object descriptor from ASN.1 - no Python implementation\n    \"\"\"\n\n    tag = 7\n\n\nclass InstanceOf(Primitive):\n    \"\"\"\n    Represents an instance from ASN.1 - no Python implementation\n    \"\"\"\n\n    tag = 8\n\n\nclass Real(Primitive):\n    \"\"\"\n    Represents a real number from ASN.1 - no Python implementation\n    \"\"\"\n\n    tag = 9\n\n\nclass Enumerated(Integer):\n    \"\"\"\n    Represents a enumerated list of integers from ASN.1 as a Python\n    unicode string\n    \"\"\"\n\n    tag = 10\n\n    def set(self, value):\n        \"\"\"\n        Sets the value of the object\n\n        :param value:\n            An integer or a unicode string from _map\n\n        :raises:\n            ValueError - when an invalid value is passed\n        \"\"\"\n\n        if not isinstance(value, int_types) and not isinstance(value, str_cls):\n            raise TypeError(unwrap(\n                '''\n                %s value must be an integer or a unicode string, not %s\n                ''',\n                type_name(self),\n                type_name(value)\n            ))\n\n        if isinstance(value, str_cls):\n            if value not in self._reverse_map:\n                raise ValueError(unwrap(\n                    '''\n                    %s value \"%s\" is not a valid value\n                    ''',\n                    type_name(self),\n                    value\n                ))\n\n            value = self._reverse_map[value]\n\n        elif value not in self._map:\n            raise ValueError(unwrap(\n                '''\n                %s value %s is not a valid value\n                ''',\n                type_name(self),\n                value\n            ))\n\n        Integer.set(self, value)\n\n    @property\n    def native(self):\n        \"\"\"\n        The native Python datatype representation of this value\n\n        :return:\n            A unicode string or None\n        \"\"\"\n\n        if self.contents is None:\n            return None\n\n        if self._native is None:\n            self._native = self._map[self.__int__()]\n        return self._native\n\n\nclass UTF8String(AbstractString):\n    \"\"\"\n    Represents a UTF-8 string from ASN.1 as a Python unicode string\n    \"\"\"\n\n    tag = 12\n    _encoding = 'utf-8'\n\n\nclass RelativeOid(ObjectIdentifier):\n    \"\"\"\n    Represents an object identifier in ASN.1 as a Python unicode dotted\n    integer string\n    \"\"\"\n\n    tag = 13\n\n\nclass Sequence(Asn1Value):\n    \"\"\"\n    Represents a sequence of fields from ASN.1 as a Python object with a\n    dict-like interface\n    \"\"\"\n\n    tag = 16\n\n    class_ = 0\n    method = 1\n\n    # A list of child objects, in order of _fields\n    children = None\n\n    # Sequence overrides .contents to be a property so that the mutated state\n    # of child objects can be checked to ensure everything is up-to-date\n    _contents = None\n\n    # Variable to track if the object has been mutated\n    _mutated = False\n\n    # A list of tuples in one of the following forms.\n    #\n    # Option 1, a unicode string field name and a value class\n    #\n    # (\"name\", Asn1ValueClass)\n    #\n    # Option 2, same as Option 1, but with a dict of class params\n    #\n    # (\"name\", Asn1ValueClass, {'explicit': 5})\n    _fields = []\n\n    # A dict with keys being the name of a field and the value being a unicode\n    # string of the method name on self to call to get the spec for that field\n    _spec_callbacks = None\n\n    # A dict that maps unicode string field names to an index in _fields\n    _field_map = None\n\n    # A list in the same order as _fields that has tuples in the form (class_, tag)\n    _field_ids = None\n\n    # An optional 2-element tuple that defines the field names of an OID field\n    # and the field that the OID should be used to help decode. Works with the\n    # _oid_specs attribute.\n    _oid_pair = None\n\n    # A dict with keys that are unicode string OID values and values that are\n    # Asn1Value classes to use for decoding a variable-type field.\n    _oid_specs = None\n\n    # A 2-element tuple of the indexes in _fields of the OID and value fields\n    _oid_nums = None\n\n    # Predetermined field specs to optimize away calls to _determine_spec()\n    _precomputed_specs = None\n\n    def __init__(self, value=None, default=None, **kwargs):\n        \"\"\"\n        Allows setting field values before passing everything else along to\n        Asn1Value.__init__()\n\n        :param value:\n            A native Python datatype to initialize the object value with\n\n        :param default:\n            The default value if no value is specified\n        \"\"\"\n\n        Asn1Value.__init__(self, **kwargs)\n\n        check_existing = False\n        if value is None and default is not None:\n            check_existing = True\n            if self.children is None:\n                if self.contents is None:\n                    check_existing = False\n                else:\n                    self._parse_children()\n            value = default\n\n        if value is not None:\n            try:\n                # Fields are iterated in definition order to allow things like\n                # OID-based specs. Otherwise sometimes the value would be processed\n                # before the OID field, resulting in invalid value object creation.\n                if self._fields:\n                    keys = [info[0] for info in self._fields]\n                    unused_keys = set(value.keys())\n                else:\n                    keys = value.keys()\n                    unused_keys = set(keys)\n\n                for key in keys:\n                    # If we are setting defaults, but a real value has already\n                    # been set for the field, then skip it\n                    if check_existing:\n                        index = self._field_map[key]\n                        if index < len(self.children) and self.children[index] is not VOID:\n                            if key in unused_keys:\n                                unused_keys.remove(key)\n                            continue\n\n                    if key in value:\n                        self.__setitem__(key, value[key])\n                        unused_keys.remove(key)\n\n                # This handles the situation where there is field name\n                # mapping going on due to a field be renamed. Normally\n                # the keys are checked against the primary field list.\n                # If there are still keys left over, check to see if they\n                # are mapped via checking the _field_map.\n                if len(unused_keys):\n                    for key in list(unused_keys):\n                        if key in self._field_map:\n                            self.__setitem__(key, value[key])\n                            unused_keys.remove(key)\n\n                if len(unused_keys):\n                    raise ValueError(unwrap(\n                        '''\n                        One or more unknown fields was passed to the constructor\n                        of %s: %s\n                        ''',\n                        type_name(self),\n                        ', '.join(sorted(list(unused_keys)))\n                    ))\n\n            except (ValueError, TypeError) as e:\n                args = e.args[1:]\n                e.args = (e.args[0] + '\\n    while constructing %s' % type_name(self),) + args\n                raise e\n\n    @property\n    def contents(self):\n        \"\"\"\n        :return:\n            A byte string of the DER-encoded contents of the sequence\n        \"\"\"\n\n        if self.children is None:\n            return self._contents\n\n        if self._is_mutated():\n            self._set_contents()\n\n        return self._contents\n\n    @contents.setter\n    def contents(self, value):\n        \"\"\"\n        :param value:\n            A byte string of the DER-encoded contents of the sequence\n        \"\"\"\n\n        self._contents = value\n\n    def _is_mutated(self):\n        \"\"\"\n        :return:\n            A boolean - if the sequence or any children (recursively) have been\n            mutated\n        \"\"\"\n\n        mutated = self._mutated\n        if self.children is not None:\n            for child in self.children:\n                if isinstance(child, Sequence) or isinstance(child, SequenceOf):\n                    mutated = mutated or child._is_mutated()\n\n        return mutated\n\n    def _lazy_child(self, index):\n        \"\"\"\n        Builds a child object if the child has only been parsed into a tuple so far\n        \"\"\"\n\n        child = self.children[index]\n        if child.__class__ == tuple:\n            child = self.children[index] = _build(*child)\n        return child\n\n    def __len__(self):\n        \"\"\"\n        :return:\n            Integer\n        \"\"\"\n        # We inline this check to prevent method invocation each time\n        if self.children is None:\n            self._parse_children()\n\n        return len(self.children)\n\n    def __getitem__(self, key):\n        \"\"\"\n        Allows accessing fields by name or index\n\n        :param key:\n            A unicode string of the field name, or an integer of the field index\n\n        :raises:\n            KeyError - when a field name or index is invalid\n\n        :return:\n            The Asn1Value object of the field specified\n        \"\"\"\n\n        # We inline this check to prevent method invocation each time\n        if self.children is None:\n            self._parse_children()\n\n        if not isinstance(key, int_types):\n            if key not in self._field_map:\n                raise KeyError(unwrap(\n                    '''\n                    No field named \"%s\" defined for %s\n                    ''',\n                    key,\n                    type_name(self)\n                ))\n            key = self._field_map[key]\n\n        if key >= len(self.children):\n            raise KeyError(unwrap(\n                '''\n                No field numbered %s is present in this %s\n                ''',\n                key,\n                type_name(self)\n            ))\n\n        try:\n            return self._lazy_child(key)\n\n        except (ValueError, TypeError) as e:\n            args = e.args[1:]\n            e.args = (e.args[0] + '\\n    while parsing %s' % type_name(self),) + args\n            raise e\n\n    def __setitem__(self, key, value):\n        \"\"\"\n        Allows settings fields by name or index\n\n        :param key:\n            A unicode string of the field name, or an integer of the field index\n\n        :param value:\n            A native Python datatype to set the field value to. This method will\n            construct the appropriate Asn1Value object from _fields.\n\n        :raises:\n            ValueError - when a field name or index is invalid\n        \"\"\"\n\n        # We inline this check to prevent method invocation each time\n        if self.children is None:\n            self._parse_children()\n\n        if not isinstance(key, int_types):\n            if key not in self._field_map:\n                raise KeyError(unwrap(\n                    '''\n                    No field named \"%s\" defined for %s\n                    ''',\n                    key,\n                    type_name(self)\n                ))\n            key = self._field_map[key]\n\n        field_name, field_spec, value_spec, field_params, _ = self._determine_spec(key)\n\n        new_value = self._make_value(field_name, field_spec, value_spec, field_params, value)\n\n        invalid_value = False\n        if isinstance(new_value, Any):\n            invalid_value = new_value.parsed is None\n        else:\n            invalid_value = new_value.contents is None\n\n        if invalid_value:\n            raise ValueError(unwrap(\n                '''\n                Value for field \"%s\" of %s is not set\n                ''',\n                field_name,\n                type_name(self)\n            ))\n\n        self.children[key] = new_value\n\n        if self._native is not None:\n            self._native[self._fields[key][0]] = self.children[key].native\n        self._mutated = True\n\n    def __delitem__(self, key):\n        \"\"\"\n        Allows deleting optional or default fields by name or index\n\n        :param key:\n            A unicode string of the field name, or an integer of the field index\n\n        :raises:\n            ValueError - when a field name or index is invalid, or the field is not optional or defaulted\n        \"\"\"\n\n        # We inline this check to prevent method invocation each time\n        if self.children is None:\n            self._parse_children()\n\n        if not isinstance(key, int_types):\n            if key not in self._field_map:\n                raise KeyError(unwrap(\n                    '''\n                    No field named \"%s\" defined for %s\n                    ''',\n                    key,\n                    type_name(self)\n                ))\n            key = self._field_map[key]\n\n        name, _, params = self._fields[key]\n        if not params or ('default' not in params and 'optional' not in params):\n            raise ValueError(unwrap(\n                '''\n                Can not delete the value for the field \"%s\" of %s since it is\n                not optional or defaulted\n                ''',\n                name,\n                type_name(self)\n            ))\n\n        if 'optional' in params:\n            self.children[key] = VOID\n            if self._native is not None:\n                self._native[name] = None\n        else:\n            self.__setitem__(key, None)\n        self._mutated = True\n\n    def __iter__(self):\n        \"\"\"\n        :return:\n            An iterator of field key names\n        \"\"\"\n\n        for info in self._fields:\n            yield info[0]\n\n    def _set_contents(self, force=False):\n        \"\"\"\n        Updates the .contents attribute of the value with the encoded value of\n        all of the child objects\n\n        :param force:\n            Ensure all contents are in DER format instead of possibly using\n            cached BER-encoded data\n        \"\"\"\n\n        if self.children is None:\n            self._parse_children()\n\n        contents = BytesIO()\n        for index, info in enumerate(self._fields):\n            child = self.children[index]\n            if child is None:\n                child_dump = b''\n            elif child.__class__ == tuple:\n                if force:\n                    child_dump = self._lazy_child(index).dump(force=force)\n                else:\n                    child_dump = child[3] + child[4] + child[5]\n            else:\n                child_dump = child.dump(force=force)\n            # Skip values that are the same as the default\n            if info[2] and 'default' in info[2]:\n                default_value = info[1](**info[2])\n                if default_value.dump() == child_dump:\n                    continue\n            contents.write(child_dump)\n        self._contents = contents.getvalue()\n\n        self._header = None\n        if self._trailer != b'':\n            self._trailer = b''\n\n    def _setup(self):\n        \"\"\"\n        Generates _field_map, _field_ids and _oid_nums for use in parsing\n        \"\"\"\n\n        cls = self.__class__\n        cls._field_map = {}\n        cls._field_ids = []\n        cls._precomputed_specs = []\n        for index, field in enumerate(cls._fields):\n            if len(field) < 3:\n                field = field + ({},)\n                cls._fields[index] = field\n            cls._field_map[field[0]] = index\n            cls._field_ids.append(_build_id_tuple(field[2], field[1]))\n\n        if cls._oid_pair is not None:\n            cls._oid_nums = (cls._field_map[cls._oid_pair[0]], cls._field_map[cls._oid_pair[1]])\n\n        for index, field in enumerate(cls._fields):\n            has_callback = cls._spec_callbacks is not None and field[0] in cls._spec_callbacks\n            is_mapped_oid = cls._oid_nums is not None and cls._oid_nums[1] == index\n            if has_callback or is_mapped_oid:\n                cls._precomputed_specs.append(None)\n            else:\n                cls._precomputed_specs.append((field[0], field[1], field[1], field[2], None))\n\n    def _determine_spec(self, index):\n        \"\"\"\n        Determine how a value for a field should be constructed\n\n        :param index:\n            The field number\n\n        :return:\n            A tuple containing the following elements:\n             - unicode string of the field name\n             - Asn1Value class of the field spec\n             - Asn1Value class of the value spec\n             - None or dict of params to pass to the field spec\n             - None or Asn1Value class indicating the value spec was derived from an OID or a spec callback\n        \"\"\"\n\n        name, field_spec, field_params = self._fields[index]\n        value_spec = field_spec\n        spec_override = None\n\n        if self._spec_callbacks is not None and name in self._spec_callbacks:\n            callback = self._spec_callbacks[name]\n            spec_override = callback(self)\n            if spec_override:\n                # Allow a spec callback to specify both the base spec and\n                # the override, for situations such as OctetString and parse_as\n                if spec_override.__class__ == tuple and len(spec_override) == 2:\n                    field_spec, value_spec = spec_override\n                    if value_spec is None:\n                        value_spec = field_spec\n                        spec_override = None\n                # When no field spec is specified, use a single return value as that\n                elif field_spec is None:\n                    field_spec = spec_override\n                    value_spec = field_spec\n                    spec_override = None\n                else:\n                    value_spec = spec_override\n\n        elif self._oid_nums is not None and self._oid_nums[1] == index:\n            oid = self._lazy_child(self._oid_nums[0]).native\n            if oid in self._oid_specs:\n                spec_override = self._oid_specs[oid]\n                value_spec = spec_override\n\n        return (name, field_spec, value_spec, field_params, spec_override)\n\n    def _make_value(self, field_name, field_spec, value_spec, field_params, value):\n        \"\"\"\n        Contructs an appropriate Asn1Value object for a field\n\n        :param field_name:\n            A unicode string of the field name\n\n        :param field_spec:\n            An Asn1Value class that is the field spec\n\n        :param value_spec:\n            An Asn1Value class that is the vaue spec\n\n        :param field_params:\n            None or a dict of params for the field spec\n\n        :param value:\n            The value to construct an Asn1Value object from\n\n        :return:\n            An instance of a child class of Asn1Value\n        \"\"\"\n\n        if value is None and 'optional' in field_params:\n            return VOID\n\n        specs_different = field_spec != value_spec\n        is_any = issubclass(field_spec, Any)\n\n        if issubclass(value_spec, Choice):\n            is_asn1value = isinstance(value, Asn1Value)\n            is_tuple = isinstance(value, tuple) and len(value) == 2\n            is_dict = isinstance(value, dict) and len(value) == 1\n            if not is_asn1value and not is_tuple and not is_dict:\n                raise ValueError(unwrap(\n                    '''\n                    Can not set a native python value to %s, which has the\n                    choice type of %s - value must be an instance of Asn1Value\n                    ''',\n                    field_name,\n                    type_name(value_spec)\n                ))\n            if is_tuple or is_dict:\n                value = value_spec(value)\n            if not isinstance(value, value_spec):\n                wrapper = value_spec()\n                wrapper.validate(value.class_, value.tag, value.contents)\n                wrapper._parsed = value\n                new_value = wrapper\n            else:\n                new_value = value\n\n        elif isinstance(value, field_spec):\n            new_value = value\n            if specs_different:\n                new_value.parse(value_spec)\n\n        elif (not specs_different or is_any) and not isinstance(value, value_spec):\n            if (not is_any or specs_different) and isinstance(value, Asn1Value):\n                raise TypeError(unwrap(\n                    '''\n                    %s value must be %s, not %s\n                    ''',\n                    field_name,\n                    type_name(value_spec),\n                    type_name(value)\n                ))\n            new_value = value_spec(value, **field_params)\n\n        else:\n            if isinstance(value, value_spec):\n                new_value = value\n            else:\n                if isinstance(value, Asn1Value):\n                    raise TypeError(unwrap(\n                        '''\n                        %s value must be %s, not %s\n                        ''',\n                        field_name,\n                        type_name(value_spec),\n                        type_name(value)\n                    ))\n                new_value = value_spec(value)\n\n            # For when the field is OctetString or OctetBitString with embedded\n            # values we need to wrap the value in the field spec to get the\n            # appropriate encoded value.\n            if specs_different and not is_any:\n                wrapper = field_spec(value=new_value.dump(), **field_params)\n                wrapper._parsed = (new_value, new_value.__class__, None)\n                new_value = wrapper\n\n        new_value = _fix_tagging(new_value, field_params)\n\n        return new_value\n\n    def _parse_children(self, recurse=False):\n        \"\"\"\n        Parses the contents and generates Asn1Value objects based on the\n        definitions from _fields.\n\n        :param recurse:\n            If child objects that are Sequence or SequenceOf objects should\n            be recursively parsed\n\n        :raises:\n            ValueError - when an error occurs parsing child objects\n        \"\"\"\n\n        cls = self.__class__\n        if self._contents is None:\n            if self._fields:\n                self.children = [VOID] * len(self._fields)\n                for index, (_, _, params) in enumerate(self._fields):\n                    if 'default' in params:\n                        if cls._precomputed_specs[index]:\n                            field_name, field_spec, value_spec, field_params, _ = cls._precomputed_specs[index]\n                        else:\n                            field_name, field_spec, value_spec, field_params, _ = self._determine_spec(index)\n                        self.children[index] = self._make_value(field_name, field_spec, value_spec, field_params, None)\n            return\n\n        try:\n            self.children = []\n            contents_length = len(self._contents)\n            child_pointer = 0\n            field = 0\n            field_len = len(self._fields)\n            parts = None\n            again = child_pointer < contents_length\n            while again:\n                if parts is None:\n                    parts, child_pointer = _parse(self._contents, contents_length, pointer=child_pointer)\n                again = child_pointer < contents_length\n\n                if field < field_len:\n                    _, field_spec, value_spec, field_params, spec_override = (\n                        cls._precomputed_specs[field] or self._determine_spec(field))\n\n                    # If the next value is optional or default, allow it to be absent\n                    if field_params and ('optional' in field_params or 'default' in field_params):\n                        if self._field_ids[field] != (parts[0], parts[2]) and field_spec != Any:\n\n                            # See if the value is a valid choice before assuming\n                            # that we have a missing optional or default value\n                            choice_match = False\n                            if issubclass(field_spec, Choice):\n                                try:\n                                    tester = field_spec(**field_params)\n                                    tester.validate(parts[0], parts[2], parts[4])\n                                    choice_match = True\n                                except (ValueError):\n                                    pass\n\n                            if not choice_match:\n                                if 'optional' in field_params:\n                                    self.children.append(VOID)\n                                else:\n                                    self.children.append(field_spec(**field_params))\n                                field += 1\n                                again = True\n                                continue\n\n                    if field_spec is None or (spec_override and issubclass(field_spec, Any)):\n                        field_spec = value_spec\n                        spec_override = None\n\n                    if spec_override:\n                        child = parts + (field_spec, field_params, value_spec)\n                    else:\n                        child = parts + (field_spec, field_params)\n\n                # Handle situations where an optional or defaulted field definition is incorrect\n                elif field_len > 0 and field + 1 <= field_len:\n                    missed_fields = []\n                    prev_field = field - 1\n                    while prev_field >= 0:\n                        prev_field_info = self._fields[prev_field]\n                        if len(prev_field_info) < 3:\n                            break\n                        if 'optional' in prev_field_info[2] or 'default' in prev_field_info[2]:\n                            missed_fields.append(prev_field_info[0])\n                        prev_field -= 1\n                    plural = 's' if len(missed_fields) > 1 else ''\n                    missed_field_names = ', '.join(missed_fields)\n                    raise ValueError(unwrap(\n                        '''\n                        Data for field %s (%s class, %s method, tag %s) does\n                        not match the field definition%s of %s\n                        ''',\n                        field + 1,\n                        CLASS_NUM_TO_NAME_MAP.get(parts[0]),\n                        METHOD_NUM_TO_NAME_MAP.get(parts[1]),\n                        parts[2],\n                        plural,\n                        missed_field_names\n                    ))\n\n                else:\n                    child = parts\n\n                if recurse:\n                    child = _build(*child)\n                    if isinstance(child, (Sequence, SequenceOf)):\n                        child._parse_children(recurse=True)\n\n                self.children.append(child)\n                field += 1\n                parts = None\n\n            index = len(self.children)\n            while index < field_len:\n                name, field_spec, field_params = self._fields[index]\n                if 'default' in field_params:\n                    self.children.append(field_spec(**field_params))\n                elif 'optional' in field_params:\n                    self.children.append(VOID)\n                else:\n                    raise ValueError(unwrap(\n                        '''\n                        Field \"%s\" is missing from structure\n                        ''',\n                        name\n                    ))\n                index += 1\n\n        except (ValueError, TypeError) as e:\n            self.children = None\n            args = e.args[1:]\n            e.args = (e.args[0] + '\\n    while parsing %s' % type_name(self),) + args\n            raise e\n\n    def spec(self, field_name):\n        \"\"\"\n        Determines the spec to use for the field specified. Depending on how\n        the spec is determined (_oid_pair or _spec_callbacks), it may be\n        necessary to set preceding field values before calling this. Usually\n        specs, if dynamic, are controlled by a preceding ObjectIdentifier\n        field.\n\n        :param field_name:\n            A unicode string of the field name to get the spec for\n\n        :return:\n            A child class of asn1crypto.core.Asn1Value that the field must be\n            encoded using\n        \"\"\"\n\n        if not isinstance(field_name, str_cls):\n            raise TypeError(unwrap(\n                '''\n                field_name must be a unicode string, not %s\n                ''',\n                type_name(field_name)\n            ))\n\n        if self._fields is None:\n            raise ValueError(unwrap(\n                '''\n                Unable to retrieve spec for field %s in the class %s because\n                _fields has not been set\n                ''',\n                repr(field_name),\n                type_name(self)\n            ))\n\n        index = self._field_map[field_name]\n        info = self._determine_spec(index)\n\n        return info[2]\n\n    @property\n    def native(self):\n        \"\"\"\n        The native Python datatype representation of this value\n\n        :return:\n            An OrderedDict or None. If an OrderedDict, all child values are\n            recursively converted to native representation also.\n        \"\"\"\n\n        if self.contents is None:\n            return None\n\n        if self._native is None:\n            if self.children is None:\n                self._parse_children(recurse=True)\n            try:\n                self._native = OrderedDict()\n                for index, child in enumerate(self.children):\n                    if child.__class__ == tuple:\n                        child = _build(*child)\n                        self.children[index] = child\n                    try:\n                        name = self._fields[index][0]\n                    except (IndexError):\n                        name = str_cls(index)\n                    self._native[name] = child.native\n            except (ValueError, TypeError) as e:\n                self._native = None\n                args = e.args[1:]\n                e.args = (e.args[0] + '\\n    while parsing %s' % type_name(self),) + args\n                raise e\n        return self._native\n\n    def _copy(self, other, copy_func):\n        \"\"\"\n        Copies the contents of another Sequence object to itself\n\n        :param object:\n            Another instance of the same class\n\n        :param copy_func:\n            An reference of copy.copy() or copy.deepcopy() to use when copying\n            lists, dicts and objects\n        \"\"\"\n\n        super(Sequence, self)._copy(other, copy_func)\n        if self.children is not None:\n            self.children = []\n            for child in other.children:\n                if child.__class__ == tuple:\n                    self.children.append(child)\n                else:\n                    self.children.append(child.copy())\n\n    def debug(self, nest_level=1):\n        \"\"\"\n        Show the binary data and parsed data in a tree structure\n        \"\"\"\n\n        if self.children is None:\n            self._parse_children()\n\n        prefix = '  ' * nest_level\n        _basic_debug(prefix, self)\n        for field_name in self:\n            child = self._lazy_child(self._field_map[field_name])\n            if child is not VOID:\n                print('%s    Field \"%s\"' % (prefix, field_name))\n                child.debug(nest_level + 3)\n\n    def dump(self, force=False):\n        \"\"\"\n        Encodes the value using DER\n\n        :param force:\n            If the encoded contents already exist, clear them and regenerate\n            to ensure they are in DER format instead of BER format\n\n        :return:\n            A byte string of the DER-encoded value\n        \"\"\"\n\n        # If the length is indefinite, force the re-encoding\n        if self._header is not None and self._header[-1:] == b'\\x80':\n            force = True\n\n        # We can't force encoding if we don't have a spec\n        if force and self._fields == [] and self.__class__ is Sequence:\n            force = False\n\n        if force:\n            self._set_contents(force=force)\n\n        if self._fields and self.children is not None:\n            for index, (field_name, _, params) in enumerate(self._fields):\n                if self.children[index] is not VOID:\n                    continue\n                if 'default' in params or 'optional' in params:\n                    continue\n                raise ValueError(unwrap(\n                    '''\n                    Field \"%s\" is missing from structure\n                    ''',\n                    field_name\n                ))\n\n        return Asn1Value.dump(self)\n\n\nclass SequenceOf(Asn1Value):\n    \"\"\"\n    Represents a sequence (ordered) of a single type of values from ASN.1 as a\n    Python object with a list-like interface\n    \"\"\"\n\n    tag = 16\n\n    class_ = 0\n    method = 1\n\n    # A list of child objects\n    children = None\n\n    # SequenceOf overrides .contents to be a property so that the mutated state\n    # of child objects can be checked to ensure everything is up-to-date\n    _contents = None\n\n    # Variable to track if the object has been mutated\n    _mutated = False\n\n    # An Asn1Value class to use when parsing children\n    _child_spec = None\n\n    def __init__(self, value=None, default=None, contents=None, spec=None, **kwargs):\n        \"\"\"\n        Allows setting child objects and the _child_spec via the spec parameter\n        before passing everything else along to Asn1Value.__init__()\n\n        :param value:\n            A native Python datatype to initialize the object value with\n\n        :param default:\n            The default value if no value is specified\n\n        :param contents:\n            A byte string of the encoded contents of the value\n\n        :param spec:\n            A class derived from Asn1Value to use to parse children\n        \"\"\"\n\n        if spec:\n            self._child_spec = spec\n\n        Asn1Value.__init__(self, **kwargs)\n\n        try:\n            if contents is not None:\n                self.contents = contents\n            else:\n                if value is None and default is not None:\n                    value = default\n\n                if value is not None:\n                    for index, child in enumerate(value):\n                        self.__setitem__(index, child)\n\n                    # Make sure a blank list is serialized\n                    if self.contents is None:\n                        self._set_contents()\n\n        except (ValueError, TypeError) as e:\n            args = e.args[1:]\n            e.args = (e.args[0] + '\\n    while constructing %s' % type_name(self),) + args\n            raise e\n\n    @property\n    def contents(self):\n        \"\"\"\n        :return:\n            A byte string of the DER-encoded contents of the sequence\n        \"\"\"\n\n        if self.children is None:\n            return self._contents\n\n        if self._is_mutated():\n            self._set_contents()\n\n        return self._contents\n\n    @contents.setter\n    def contents(self, value):\n        \"\"\"\n        :param value:\n            A byte string of the DER-encoded contents of the sequence\n        \"\"\"\n\n        self._contents = value\n\n    def _is_mutated(self):\n        \"\"\"\n        :return:\n            A boolean - if the sequence or any children (recursively) have been\n            mutated\n        \"\"\"\n\n        mutated = self._mutated\n        if self.children is not None:\n            for child in self.children:\n                if isinstance(child, Sequence) or isinstance(child, SequenceOf):\n                    mutated = mutated or child._is_mutated()\n\n        return mutated\n\n    def _lazy_child(self, index):\n        \"\"\"\n        Builds a child object if the child has only been parsed into a tuple so far\n        \"\"\"\n\n        child = self.children[index]\n        if child.__class__ == tuple:\n            child = _build(*child)\n            self.children[index] = child\n        return child\n\n    def _make_value(self, value):\n        \"\"\"\n        Constructs a _child_spec value from a native Python data type, or\n        an appropriate Asn1Value object\n\n        :param value:\n            A native Python value, or some child of Asn1Value\n\n        :return:\n            An object of type _child_spec\n        \"\"\"\n\n        if isinstance(value, self._child_spec):\n            new_value = value\n\n        elif issubclass(self._child_spec, Any):\n            if isinstance(value, Asn1Value):\n                new_value = value\n            else:\n                raise ValueError(unwrap(\n                    '''\n                    Can not set a native python value to %s where the\n                    _child_spec is Any - value must be an instance of Asn1Value\n                    ''',\n                    type_name(self)\n                ))\n\n        elif issubclass(self._child_spec, Choice):\n            if not isinstance(value, Asn1Value):\n                raise ValueError(unwrap(\n                    '''\n                    Can not set a native python value to %s where the\n                    _child_spec is the choice type %s - value must be an\n                    instance of Asn1Value\n                    ''',\n                    type_name(self),\n                    self._child_spec.__name__\n                ))\n            if not isinstance(value, self._child_spec):\n                wrapper = self._child_spec()\n                wrapper.validate(value.class_, value.tag, value.contents)\n                wrapper._parsed = value\n                value = wrapper\n            new_value = value\n\n        else:\n            return self._child_spec(value=value)\n\n        params = {}\n        if self._child_spec.explicit:\n            params['explicit'] = self._child_spec.explicit\n        if self._child_spec.implicit:\n            params['implicit'] = (self._child_spec.class_, self._child_spec.tag)\n        return _fix_tagging(new_value, params)\n\n    def __len__(self):\n        \"\"\"\n        :return:\n            An integer\n        \"\"\"\n        # We inline this checks to prevent method invocation each time\n        if self.children is None:\n            self._parse_children()\n\n        return len(self.children)\n\n    def __getitem__(self, key):\n        \"\"\"\n        Allows accessing children via index\n\n        :param key:\n            Integer index of child\n        \"\"\"\n\n        # We inline this checks to prevent method invocation each time\n        if self.children is None:\n            self._parse_children()\n\n        return self._lazy_child(key)\n\n    def __setitem__(self, key, value):\n        \"\"\"\n        Allows overriding a child via index\n\n        :param key:\n            Integer index of child\n\n        :param value:\n            Native python datatype that will be passed to _child_spec to create\n            new child object\n        \"\"\"\n\n        # We inline this checks to prevent method invocation each time\n        if self.children is None:\n            self._parse_children()\n\n        new_value = self._make_value(value)\n\n        # If adding at the end, create a space for the new value\n        if key == len(self.children):\n            self.children.append(None)\n            if self._native is not None:\n                self._native.append(None)\n\n        self.children[key] = new_value\n\n        if self._native is not None:\n            self._native[key] = self.children[key].native\n\n        self._mutated = True\n\n    def __delitem__(self, key):\n        \"\"\"\n        Allows removing a child via index\n\n        :param key:\n            Integer index of child\n        \"\"\"\n\n        # We inline this checks to prevent method invocation each time\n        if self.children is None:\n            self._parse_children()\n\n        self.children.pop(key)\n        if self._native is not None:\n            self._native.pop(key)\n\n        self._mutated = True\n\n    def __iter__(self):\n        \"\"\"\n        :return:\n            An iter() of child objects\n        \"\"\"\n\n        # We inline this checks to prevent method invocation each time\n        if self.children is None:\n            self._parse_children()\n\n        for index in range(0, len(self.children)):\n            yield self._lazy_child(index)\n\n    def __contains__(self, item):\n        \"\"\"\n        :param item:\n            An object of the type cls._child_spec\n\n        :return:\n            A boolean if the item is contained in this SequenceOf\n        \"\"\"\n\n        if item is None or item is VOID:\n            return False\n\n        if not isinstance(item, self._child_spec):\n            raise TypeError(unwrap(\n                '''\n                Checking membership in %s is only available for instances of\n                %s, not %s\n                ''',\n                type_name(self),\n                type_name(self._child_spec),\n                type_name(item)\n            ))\n\n        for child in self:\n            if child == item:\n                return True\n\n        return False\n\n    def append(self, value):\n        \"\"\"\n        Allows adding a child to the end of the sequence\n\n        :param value:\n            Native python datatype that will be passed to _child_spec to create\n            new child object\n        \"\"\"\n\n        # We inline this checks to prevent method invocation each time\n        if self.children is None:\n            self._parse_children()\n\n        self.children.append(self._make_value(value))\n\n        if self._native is not None:\n            self._native.append(self.children[-1].native)\n\n        self._mutated = True\n\n    def _set_contents(self, force=False):\n        \"\"\"\n        Encodes all child objects into the contents for this object\n\n        :param force:\n            Ensure all contents are in DER format instead of possibly using\n            cached BER-encoded data\n        \"\"\"\n\n        if self.children is None:\n            self._parse_children()\n\n        contents = BytesIO()\n        for child in self:\n            contents.write(child.dump(force=force))\n        self._contents = contents.getvalue()\n        self._header = None\n        if self._trailer != b'':\n            self._trailer = b''\n\n    def _parse_children(self, recurse=False):\n        \"\"\"\n        Parses the contents and generates Asn1Value objects based on the\n        definitions from _child_spec.\n\n        :param recurse:\n            If child objects that are Sequence or SequenceOf objects should\n            be recursively parsed\n\n        :raises:\n            ValueError - when an error occurs parsing child objects\n        \"\"\"\n\n        try:\n            self.children = []\n            if self._contents is None:\n                return\n            contents_length = len(self._contents)\n            child_pointer = 0\n            while child_pointer < contents_length:\n                parts, child_pointer = _parse(self._contents, contents_length, pointer=child_pointer)\n                if self._child_spec:\n                    child = parts + (self._child_spec,)\n                else:\n                    child = parts\n                if recurse:\n                    child = _build(*child)\n                    if isinstance(child, (Sequence, SequenceOf)):\n                        child._parse_children(recurse=True)\n                self.children.append(child)\n        except (ValueError, TypeError) as e:\n            self.children = None\n            args = e.args[1:]\n            e.args = (e.args[0] + '\\n    while parsing %s' % type_name(self),) + args\n            raise e\n\n    def spec(self):\n        \"\"\"\n        Determines the spec to use for child values.\n\n        :return:\n            A child class of asn1crypto.core.Asn1Value that child values must be\n            encoded using\n        \"\"\"\n\n        return self._child_spec\n\n    @property\n    def native(self):\n        \"\"\"\n        The native Python datatype representation of this value\n\n        :return:\n            A list or None. If a list, all child values are recursively\n            converted to native representation also.\n        \"\"\"\n\n        if self.contents is None:\n            return None\n\n        if self._native is None:\n            if self.children is None:\n                self._parse_children(recurse=True)\n            try:\n                self._native = [child.native for child in self]\n            except (ValueError, TypeError) as e:\n                args = e.args[1:]\n                e.args = (e.args[0] + '\\n    while parsing %s' % type_name(self),) + args\n                raise e\n        return self._native\n\n    def _copy(self, other, copy_func):\n        \"\"\"\n        Copies the contents of another SequenceOf object to itself\n\n        :param object:\n            Another instance of the same class\n\n        :param copy_func:\n            An reference of copy.copy() or copy.deepcopy() to use when copying\n            lists, dicts and objects\n        \"\"\"\n\n        super(SequenceOf, self)._copy(other, copy_func)\n        if self.children is not None:\n            self.children = []\n            for child in other.children:\n                if child.__class__ == tuple:\n                    self.children.append(child)\n                else:\n                    self.children.append(child.copy())\n\n    def debug(self, nest_level=1):\n        \"\"\"\n        Show the binary data and parsed data in a tree structure\n        \"\"\"\n\n        if self.children is None:\n            self._parse_children()\n\n        prefix = '  ' * nest_level\n        _basic_debug(prefix, self)\n        for child in self:\n            child.debug(nest_level + 1)\n\n    def dump(self, force=False):\n        \"\"\"\n        Encodes the value using DER\n\n        :param force:\n            If the encoded contents already exist, clear them and regenerate\n            to ensure they are in DER format instead of BER format\n\n        :return:\n            A byte string of the DER-encoded value\n        \"\"\"\n\n        # If the length is indefinite, force the re-encoding\n        if self._header is not None and self._header[-1:] == b'\\x80':\n            force = True\n\n        if force:\n            self._set_contents(force=force)\n\n        return Asn1Value.dump(self)\n\n\nclass Set(Sequence):\n    \"\"\"\n    Represents a set of fields (unordered) from ASN.1 as a Python object with a\n    dict-like interface\n    \"\"\"\n\n    method = 1\n    class_ = 0\n    tag = 17\n\n    # A dict of 2-element tuples in the form (class_, tag) as keys and integers\n    # as values that are the index of the field in _fields\n    _field_ids = None\n\n    def _setup(self):\n        \"\"\"\n        Generates _field_map, _field_ids and _oid_nums for use in parsing\n        \"\"\"\n\n        cls = self.__class__\n        cls._field_map = {}\n        cls._field_ids = {}\n        cls._precomputed_specs = []\n        for index, field in enumerate(cls._fields):\n            if len(field) < 3:\n                field = field + ({},)\n                cls._fields[index] = field\n            cls._field_map[field[0]] = index\n            cls._field_ids[_build_id_tuple(field[2], field[1])] = index\n\n        if cls._oid_pair is not None:\n            cls._oid_nums = (cls._field_map[cls._oid_pair[0]], cls._field_map[cls._oid_pair[1]])\n\n        for index, field in enumerate(cls._fields):\n            has_callback = cls._spec_callbacks is not None and field[0] in cls._spec_callbacks\n            is_mapped_oid = cls._oid_nums is not None and cls._oid_nums[1] == index\n            if has_callback or is_mapped_oid:\n                cls._precomputed_specs.append(None)\n            else:\n                cls._precomputed_specs.append((field[0], field[1], field[1], field[2], None))\n\n    def _parse_children(self, recurse=False):\n        \"\"\"\n        Parses the contents and generates Asn1Value objects based on the\n        definitions from _fields.\n\n        :param recurse:\n            If child objects that are Sequence or SequenceOf objects should\n            be recursively parsed\n\n        :raises:\n            ValueError - when an error occurs parsing child objects\n        \"\"\"\n\n        cls = self.__class__\n        if self._contents is None:\n            if self._fields:\n                self.children = [VOID] * len(self._fields)\n                for index, (_, _, params) in enumerate(self._fields):\n                    if 'default' in params:\n                        if cls._precomputed_specs[index]:\n                            field_name, field_spec, value_spec, field_params, _ = cls._precomputed_specs[index]\n                        else:\n                            field_name, field_spec, value_spec, field_params, _ = self._determine_spec(index)\n                        self.children[index] = self._make_value(field_name, field_spec, value_spec, field_params, None)\n            return\n\n        try:\n            child_map = {}\n            contents_length = len(self.contents)\n            child_pointer = 0\n            seen_field = 0\n            while child_pointer < contents_length:\n                parts, child_pointer = _parse(self.contents, contents_length, pointer=child_pointer)\n\n                id_ = (parts[0], parts[2])\n\n                field = self._field_ids.get(id_)\n                if field is None:\n                    raise ValueError(unwrap(\n                        '''\n                        Data for field %s (%s class, %s method, tag %s) does\n                        not match any of the field definitions\n                        ''',\n                        seen_field,\n                        CLASS_NUM_TO_NAME_MAP.get(parts[0]),\n                        METHOD_NUM_TO_NAME_MAP.get(parts[1]),\n                        parts[2],\n                    ))\n\n                _, field_spec, value_spec, field_params, spec_override = (\n                    cls._precomputed_specs[field] or self._determine_spec(field))\n\n                if field_spec is None or (spec_override and issubclass(field_spec, Any)):\n                    field_spec = value_spec\n                    spec_override = None\n\n                if spec_override:\n                    child = parts + (field_spec, field_params, value_spec)\n                else:\n                    child = parts + (field_spec, field_params)\n\n                if recurse:\n                    child = _build(*child)\n                    if isinstance(child, (Sequence, SequenceOf)):\n                        child._parse_children(recurse=True)\n\n                child_map[field] = child\n                seen_field += 1\n\n            total_fields = len(self._fields)\n\n            for index in range(0, total_fields):\n                if index in child_map:\n                    continue\n\n                name, field_spec, value_spec, field_params, spec_override = (\n                    cls._precomputed_specs[index] or self._determine_spec(index))\n\n                if field_spec is None or (spec_override and issubclass(field_spec, Any)):\n                    field_spec = value_spec\n                    spec_override = None\n\n                missing = False\n\n                if not field_params:\n                    missing = True\n                elif 'optional' not in field_params and 'default' not in field_params:\n                    missing = True\n                elif 'optional' in field_params:\n                    child_map[index] = VOID\n                elif 'default' in field_params:\n                    child_map[index] = field_spec(**field_params)\n\n                if missing:\n                    raise ValueError(unwrap(\n                        '''\n                        Missing required field \"%s\" from %s\n                        ''',\n                        name,\n                        type_name(self)\n                    ))\n\n            self.children = []\n            for index in range(0, total_fields):\n                self.children.append(child_map[index])\n\n        except (ValueError, TypeError) as e:\n            args = e.args[1:]\n            e.args = (e.args[0] + '\\n    while parsing %s' % type_name(self),) + args\n            raise e\n\n    def _set_contents(self, force=False):\n        \"\"\"\n        Encodes all child objects into the contents for this object.\n\n        This method is overridden because a Set needs to be encoded by\n        removing defaulted fields and then sorting the fields by tag.\n\n        :param force:\n            Ensure all contents are in DER format instead of possibly using\n            cached BER-encoded data\n        \"\"\"\n\n        if self.children is None:\n            self._parse_children()\n\n        child_tag_encodings = []\n        for index, child in enumerate(self.children):\n            child_encoding = child.dump(force=force)\n\n            # Skip encoding defaulted children\n            name, spec, field_params = self._fields[index]\n            if 'default' in field_params:\n                if spec(**field_params).dump() == child_encoding:\n                    continue\n\n            child_tag_encodings.append((child.tag, child_encoding))\n        child_tag_encodings.sort(key=lambda ct: ct[0])\n\n        self._contents = b''.join([ct[1] for ct in child_tag_encodings])\n        self._header = None\n        if self._trailer != b'':\n            self._trailer = b''\n\n\nclass SetOf(SequenceOf):\n    \"\"\"\n    Represents a set (unordered) of a single type of values from ASN.1 as a\n    Python object with a list-like interface\n    \"\"\"\n\n    tag = 17\n\n    def _set_contents(self, force=False):\n        \"\"\"\n        Encodes all child objects into the contents for this object.\n\n        This method is overridden because a SetOf needs to be encoded by\n        sorting the child encodings.\n\n        :param force:\n            Ensure all contents are in DER format instead of possibly using\n            cached BER-encoded data\n        \"\"\"\n\n        if self.children is None:\n            self._parse_children()\n\n        child_encodings = []\n        for child in self:\n            child_encodings.append(child.dump(force=force))\n\n        self._contents = b''.join(sorted(child_encodings))\n        self._header = None\n        if self._trailer != b'':\n            self._trailer = b''\n\n\nclass EmbeddedPdv(Sequence):\n    \"\"\"\n    A sequence structure\n    \"\"\"\n\n    tag = 11\n\n\nclass NumericString(AbstractString):\n    \"\"\"\n    Represents a numeric string from ASN.1 as a Python unicode string\n    \"\"\"\n\n    tag = 18\n    _encoding = 'latin1'\n\n\nclass PrintableString(AbstractString):\n    \"\"\"\n    Represents a printable string from ASN.1 as a Python unicode string\n    \"\"\"\n\n    tag = 19\n    _encoding = 'latin1'\n\n\nclass TeletexString(AbstractString):\n    \"\"\"\n    Represents a teletex string from ASN.1 as a Python unicode string\n    \"\"\"\n\n    tag = 20\n    _encoding = 'teletex'\n\n\nclass VideotexString(OctetString):\n    \"\"\"\n    Represents a videotex string from ASN.1 as a Python byte string\n    \"\"\"\n\n    tag = 21\n\n\nclass IA5String(AbstractString):\n    \"\"\"\n    Represents an IA5 string from ASN.1 as a Python unicode string\n    \"\"\"\n\n    tag = 22\n    _encoding = 'ascii'\n\n\nclass AbstractTime(AbstractString):\n    \"\"\"\n    Represents a time from ASN.1 as a Python datetime.datetime object\n    \"\"\"\n\n    @property\n    def _parsed_time(self):\n        \"\"\"\n        The parsed datetime string.\n\n        :raises:\n            ValueError - when an invalid value is passed\n\n        :return:\n            A dict with the parsed values\n        \"\"\"\n\n        string = str_cls(self)\n\n        m = self._TIMESTRING_RE.match(string)\n        if not m:\n            raise ValueError(unwrap(\n                '''\n                Error parsing %s to a %s\n                ''',\n                string,\n                type_name(self),\n            ))\n\n        groups = m.groupdict()\n\n        tz = None\n        if groups['zulu']:\n            tz = timezone.utc\n        elif groups['dsign']:\n            sign = 1 if groups['dsign'] == '+' else -1\n            tz = create_timezone(sign * timedelta(\n                hours=int(groups['dhour']),\n                minutes=int(groups['dminute'] or 0)\n            ))\n\n        if groups['fraction']:\n            # Compute fraction in microseconds\n            fract = Fraction(\n                int(groups['fraction']),\n                10 ** len(groups['fraction'])\n            ) * 1000000\n\n            if groups['minute'] is None:\n                fract *= 3600\n            elif groups['second'] is None:\n                fract *= 60\n\n            fract_usec = int(fract.limit_denominator(1))\n\n        else:\n            fract_usec = 0\n\n        return {\n            'year': int(groups['year']),\n            'month': int(groups['month']),\n            'day': int(groups['day']),\n            'hour': int(groups['hour']),\n            'minute': int(groups['minute'] or 0),\n            'second': int(groups['second'] or 0),\n            'tzinfo': tz,\n            'fraction': fract_usec,\n        }\n\n    @property\n    def native(self):\n        \"\"\"\n        The native Python datatype representation of this value\n\n        :return:\n            A datetime.datetime object, asn1crypto.util.extended_datetime object or\n            None. The datetime object is usually timezone aware. If it's naive, then\n            it's in the sender's local time; see X.680 sect. 42.3\n        \"\"\"\n\n        if self.contents is None:\n            return None\n\n        if self._native is None:\n            parsed = self._parsed_time\n\n            fraction = parsed.pop('fraction', 0)\n\n            value = self._get_datetime(parsed)\n\n            if fraction:\n                value += timedelta(microseconds=fraction)\n\n            self._native = value\n\n        return self._native\n\n\nclass UTCTime(AbstractTime):\n    \"\"\"\n    Represents a UTC time from ASN.1 as a timezone aware Python datetime.datetime object\n    \"\"\"\n\n    tag = 23\n\n    # Regular expression for UTCTime as described in X.680 sect. 43 and ISO 8601\n    _TIMESTRING_RE = re.compile(r'''\n        ^\n        # YYMMDD\n        (?P<year>\\d{2})\n        (?P<month>\\d{2})\n        (?P<day>\\d{2})\n\n        # hhmm or hhmmss\n        (?P<hour>\\d{2})\n        (?P<minute>\\d{2})\n        (?P<second>\\d{2})?\n\n        # Matches nothing, needed because GeneralizedTime uses this.\n        (?P<fraction>)\n\n        # Z or [-+]hhmm\n        (?:\n            (?P<zulu>Z)\n            |\n            (?:\n                (?P<dsign>[-+])\n                (?P<dhour>\\d{2})\n                (?P<dminute>\\d{2})\n            )\n        )\n        $\n    ''', re.X)\n\n    def set(self, value):\n        \"\"\"\n        Sets the value of the object\n\n        :param value:\n            A unicode string or a datetime.datetime object\n\n        :raises:\n            ValueError - when an invalid value is passed\n        \"\"\"\n\n        if isinstance(value, datetime):\n            if not value.tzinfo:\n                raise ValueError('Must be timezone aware')\n\n            # Convert value to UTC.\n            value = value.astimezone(utc_with_dst)\n\n            if not 1950 <= value.year <= 2049:\n                raise ValueError('Year of the UTCTime is not in range [1950, 2049], use GeneralizedTime instead')\n\n            value = value.strftime('%y%m%d%H%M%SZ')\n            if _PY2:\n                value = value.decode('ascii')\n\n        AbstractString.set(self, value)\n        # Set it to None and let the class take care of converting the next\n        # time that .native is called\n        self._native = None\n\n    def _get_datetime(self, parsed):\n        \"\"\"\n        Create a datetime object from the parsed time.\n\n        :return:\n            An aware datetime.datetime object\n        \"\"\"\n\n        # X.680 only specifies that UTCTime is not using a century.\n        # So \"18\" could as well mean 2118 or 1318.\n        # X.509 and CMS specify to use UTCTime for years earlier than 2050.\n        # Assume that UTCTime is only used for years [1950, 2049].\n        if parsed['year'] < 50:\n            parsed['year'] += 2000\n        else:\n            parsed['year'] += 1900\n\n        return datetime(**parsed)\n\n\nclass GeneralizedTime(AbstractTime):\n    \"\"\"\n    Represents a generalized time from ASN.1 as a Python datetime.datetime\n    object or asn1crypto.util.extended_datetime object in UTC\n    \"\"\"\n\n    tag = 24\n\n    # Regular expression for GeneralizedTime as described in X.680 sect. 42 and ISO 8601\n    _TIMESTRING_RE = re.compile(r'''\n        ^\n        # YYYYMMDD\n        (?P<year>\\d{4})\n        (?P<month>\\d{2})\n        (?P<day>\\d{2})\n\n        # hh or hhmm or hhmmss\n        (?P<hour>\\d{2})\n        (?:\n            (?P<minute>\\d{2})\n            (?P<second>\\d{2})?\n        )?\n\n        # Optional fraction; [.,]dddd (one or more decimals)\n        # If Seconds are given, it's fractions of Seconds.\n        # Else if Minutes are given, it's fractions of Minutes.\n        # Else it's fractions of Hours.\n        (?:\n            [,.]\n            (?P<fraction>\\d+)\n        )?\n\n        # Optional timezone. If left out, the time is in local time.\n        # Z or [-+]hh or [-+]hhmm\n        (?:\n            (?P<zulu>Z)\n            |\n            (?:\n                (?P<dsign>[-+])\n                (?P<dhour>\\d{2})\n                (?P<dminute>\\d{2})?\n            )\n        )?\n        $\n    ''', re.X)\n\n    def set(self, value):\n        \"\"\"\n        Sets the value of the object\n\n        :param value:\n            A unicode string, a datetime.datetime object or an\n            asn1crypto.util.extended_datetime object\n\n        :raises:\n            ValueError - when an invalid value is passed\n        \"\"\"\n\n        if isinstance(value, (datetime, extended_datetime)):\n            if not value.tzinfo:\n                raise ValueError('Must be timezone aware')\n\n            # Convert value to UTC.\n            value = value.astimezone(utc_with_dst)\n\n            if value.microsecond:\n                fraction = '.' + str(value.microsecond).zfill(6).rstrip('0')\n            else:\n                fraction = ''\n\n            value = value.strftime('%Y%m%d%H%M%S') + fraction + 'Z'\n            if _PY2:\n                value = value.decode('ascii')\n\n        AbstractString.set(self, value)\n        # Set it to None and let the class take care of converting the next\n        # time that .native is called\n        self._native = None\n\n    def _get_datetime(self, parsed):\n        \"\"\"\n        Create a datetime object from the parsed time.\n\n        :return:\n            A datetime.datetime object or asn1crypto.util.extended_datetime object.\n            It may or may not be aware.\n        \"\"\"\n\n        if parsed['year'] == 0:\n            # datetime does not support year 0. Use extended_datetime instead.\n            return extended_datetime(**parsed)\n        else:\n            return datetime(**parsed)\n\n\nclass GraphicString(AbstractString):\n    \"\"\"\n    Represents a graphic string from ASN.1 as a Python unicode string\n    \"\"\"\n\n    tag = 25\n    # This is technically not correct since this type can contain any charset\n    _encoding = 'latin1'\n\n\nclass VisibleString(AbstractString):\n    \"\"\"\n    Represents a visible string from ASN.1 as a Python unicode string\n    \"\"\"\n\n    tag = 26\n    _encoding = 'latin1'\n\n\nclass GeneralString(AbstractString):\n    \"\"\"\n    Represents a general string from ASN.1 as a Python unicode string\n    \"\"\"\n\n    tag = 27\n    # This is technically not correct since this type can contain any charset\n    _encoding = 'latin1'\n\n\nclass UniversalString(AbstractString):\n    \"\"\"\n    Represents a universal string from ASN.1 as a Python unicode string\n    \"\"\"\n\n    tag = 28\n    _encoding = 'utf-32-be'\n\n\nclass CharacterString(AbstractString):\n    \"\"\"\n    Represents a character string from ASN.1 as a Python unicode string\n    \"\"\"\n\n    tag = 29\n    # This is technically not correct since this type can contain any charset\n    _encoding = 'latin1'\n\n\nclass BMPString(AbstractString):\n    \"\"\"\n    Represents a BMP string from ASN.1 as a Python unicode string\n    \"\"\"\n\n    tag = 30\n    _encoding = 'utf-16-be'\n\n\ndef _basic_debug(prefix, self):\n    \"\"\"\n    Prints out basic information about an Asn1Value object. Extracted for reuse\n    among different classes that customize the debug information.\n\n    :param prefix:\n        A unicode string of spaces to prefix output line with\n\n    :param self:\n        The object to print the debugging information about\n    \"\"\"\n\n    print('%s%s Object #%s' % (prefix, type_name(self), id(self)))\n    if self._header:\n        print('%s  Header: 0x%s' % (prefix, binascii.hexlify(self._header or b'').decode('utf-8')))\n\n    has_header = self.method is not None and self.class_ is not None and self.tag is not None\n    if has_header:\n        method_name = METHOD_NUM_TO_NAME_MAP.get(self.method)\n        class_name = CLASS_NUM_TO_NAME_MAP.get(self.class_)\n\n    if self.explicit is not None:\n        for class_, tag in self.explicit:\n            print(\n                '%s    %s tag %s (explicitly tagged)' %\n                (\n                    prefix,\n                    CLASS_NUM_TO_NAME_MAP.get(class_),\n                    tag\n                )\n            )\n        if has_header:\n            print('%s      %s %s %s' % (prefix, method_name, class_name, self.tag))\n\n    elif self.implicit:\n        if has_header:\n            print('%s    %s %s tag %s (implicitly tagged)' % (prefix, method_name, class_name, self.tag))\n\n    elif has_header:\n        print('%s    %s %s tag %s' % (prefix, method_name, class_name, self.tag))\n\n    if self._trailer:\n        print('%s  Trailer: 0x%s' % (prefix, binascii.hexlify(self._trailer or b'').decode('utf-8')))\n\n    print('%s  Data: 0x%s' % (prefix, binascii.hexlify(self.contents or b'').decode('utf-8')))\n\n\ndef _tag_type_to_explicit_implicit(params):\n    \"\"\"\n    Converts old-style \"tag_type\" and \"tag\" params to \"explicit\" and \"implicit\"\n\n    :param params:\n        A dict of parameters to convert from tag_type/tag to explicit/implicit\n    \"\"\"\n\n    if 'tag_type' in params:\n        if params['tag_type'] == 'explicit':\n            params['explicit'] = (params.get('class', 2), params['tag'])\n        elif params['tag_type'] == 'implicit':\n            params['implicit'] = (params.get('class', 2), params['tag'])\n        del params['tag_type']\n        del params['tag']\n        if 'class' in params:\n            del params['class']\n\n\ndef _fix_tagging(value, params):\n    \"\"\"\n    Checks if a value is properly tagged based on the spec, and re/untags as\n    necessary\n\n    :param value:\n        An Asn1Value object\n\n    :param params:\n        A dict of spec params\n\n    :return:\n        An Asn1Value that is properly tagged\n    \"\"\"\n\n    _tag_type_to_explicit_implicit(params)\n\n    retag = False\n    if 'implicit' not in params:\n        if value.implicit is not False:\n            retag = True\n    else:\n        if isinstance(params['implicit'], tuple):\n            class_, tag = params['implicit']\n        else:\n            tag = params['implicit']\n            class_ = 'context'\n        if value.implicit is False:\n            retag = True\n        elif value.class_ != CLASS_NAME_TO_NUM_MAP[class_] or value.tag != tag:\n            retag = True\n\n    if params.get('explicit') != value.explicit:\n        retag = True\n\n    if retag:\n        return value.retag(params)\n    return value\n\n\ndef _build_id_tuple(params, spec):\n    \"\"\"\n    Builds a 2-element tuple used to identify fields by grabbing the class_\n    and tag from an Asn1Value class and the params dict being passed to it\n\n    :param params:\n        A dict of params to pass to spec\n\n    :param spec:\n        An Asn1Value class\n\n    :return:\n        A 2-element integer tuple in the form (class_, tag)\n    \"\"\"\n\n    # Handle situations where the spec is not known at setup time\n    if spec is None:\n        return (None, None)\n\n    required_class = spec.class_\n    required_tag = spec.tag\n\n    _tag_type_to_explicit_implicit(params)\n\n    if 'explicit' in params:\n        if isinstance(params['explicit'], tuple):\n            required_class, required_tag = params['explicit']\n        else:\n            required_class = 2\n            required_tag = params['explicit']\n    elif 'implicit' in params:\n        if isinstance(params['implicit'], tuple):\n            required_class, required_tag = params['implicit']\n        else:\n            required_class = 2\n            required_tag = params['implicit']\n    if required_class is not None and not isinstance(required_class, int_types):\n        required_class = CLASS_NAME_TO_NUM_MAP[required_class]\n\n    required_class = params.get('class_', required_class)\n    required_tag = params.get('tag', required_tag)\n\n    return (required_class, required_tag)\n\n\ndef _int_to_bit_tuple(value, bits):\n    \"\"\"\n    Format value as a tuple of 1s and 0s.\n\n    :param value:\n        A non-negative integer to format\n\n    :param bits:\n        Number of bits in the output\n\n    :return:\n        A tuple of 1s and 0s with bits members.\n    \"\"\"\n\n    if not value and not bits:\n        return ()\n\n    result = tuple(map(int, format(value, '0{0}b'.format(bits))))\n    if len(result) != bits:\n        raise ValueError('Result too large: {0} > {1}'.format(len(result), bits))\n\n    return result\n\n\n_UNIVERSAL_SPECS = {\n    1: Boolean,\n    2: Integer,\n    3: BitString,\n    4: OctetString,\n    5: Null,\n    6: ObjectIdentifier,\n    7: ObjectDescriptor,\n    8: InstanceOf,\n    9: Real,\n    10: Enumerated,\n    11: EmbeddedPdv,\n    12: UTF8String,\n    13: RelativeOid,\n    16: Sequence,\n    17: Set,\n    18: NumericString,\n    19: PrintableString,\n    20: TeletexString,\n    21: VideotexString,\n    22: IA5String,\n    23: UTCTime,\n    24: GeneralizedTime,\n    25: GraphicString,\n    26: VisibleString,\n    27: GeneralString,\n    28: UniversalString,\n    29: CharacterString,\n    30: BMPString\n}\n\n\ndef _build(class_, method, tag, header, contents, trailer, spec=None, spec_params=None, nested_spec=None):\n    \"\"\"\n    Builds an Asn1Value object generically, or using a spec with optional params\n\n    :param class_:\n        An integer representing the ASN.1 class\n\n    :param method:\n        An integer representing the ASN.1 method\n\n    :param tag:\n        An integer representing the ASN.1 tag\n\n    :param header:\n        A byte string of the ASN.1 header (class, method, tag, length)\n\n    :param contents:\n        A byte string of the ASN.1 value\n\n    :param trailer:\n        A byte string of any ASN.1 trailer (only used by indefinite length encodings)\n\n    :param spec:\n        A class derived from Asn1Value that defines what class_ and tag the\n        value should have, and the semantics of the encoded value. The\n        return value will be of this type. If omitted, the encoded value\n        will be decoded using the standard universal tag based on the\n        encoded tag number.\n\n    :param spec_params:\n        A dict of params to pass to the spec object\n\n    :param nested_spec:\n        For certain Asn1Value classes (such as OctetString and BitString), the\n        contents can be further parsed and interpreted as another Asn1Value.\n        This parameter controls the spec for that sub-parsing.\n\n    :return:\n        An object of the type spec, or if not specified, a child of Asn1Value\n    \"\"\"\n\n    if spec_params is not None:\n        _tag_type_to_explicit_implicit(spec_params)\n\n    if header is None:\n        return VOID\n\n    header_set = False\n\n    # If an explicit specification was passed in, make sure it matches\n    if spec is not None:\n        # If there is explicit tagging and contents, we have to split\n        # the header and trailer off before we do the parsing\n        no_explicit = spec_params and 'no_explicit' in spec_params\n        if not no_explicit and (spec.explicit or (spec_params and 'explicit' in spec_params)):\n            if spec_params:\n                value = spec(**spec_params)\n            else:\n                value = spec()\n            original_explicit = value.explicit\n            explicit_info = reversed(original_explicit)\n            parsed_class = class_\n            parsed_method = method\n            parsed_tag = tag\n            to_parse = contents\n            explicit_header = header\n            explicit_trailer = trailer or b''\n            for expected_class, expected_tag in explicit_info:\n                if parsed_class != expected_class:\n                    raise ValueError(unwrap(\n                        '''\n                        Error parsing %s - explicitly-tagged class should have been\n                        %s, but %s was found\n                        ''',\n                        type_name(value),\n                        CLASS_NUM_TO_NAME_MAP.get(expected_class),\n                        CLASS_NUM_TO_NAME_MAP.get(parsed_class, parsed_class)\n                    ))\n                if parsed_method != 1:\n                    raise ValueError(unwrap(\n                        '''\n                        Error parsing %s - explicitly-tagged method should have\n                        been %s, but %s was found\n                        ''',\n                        type_name(value),\n                        METHOD_NUM_TO_NAME_MAP.get(1),\n                        METHOD_NUM_TO_NAME_MAP.get(parsed_method, parsed_method)\n                    ))\n                if parsed_tag != expected_tag:\n                    raise ValueError(unwrap(\n                        '''\n                        Error parsing %s - explicitly-tagged tag should have been\n                        %s, but %s was found\n                        ''',\n                        type_name(value),\n                        expected_tag,\n                        parsed_tag\n                    ))\n                info, _ = _parse(to_parse, len(to_parse))\n                parsed_class, parsed_method, parsed_tag, parsed_header, to_parse, parsed_trailer = info\n\n                if not isinstance(value, Choice):\n                    explicit_header += parsed_header\n                    explicit_trailer = parsed_trailer + explicit_trailer\n\n            value = _build(*info, spec=spec, spec_params={'no_explicit': True})\n            value._header = explicit_header\n            value._trailer = explicit_trailer\n            value.explicit = original_explicit\n            header_set = True\n        else:\n            if spec_params:\n                value = spec(contents=contents, **spec_params)\n            else:\n                value = spec(contents=contents)\n\n            if spec is Any:\n                pass\n\n            elif isinstance(value, Choice):\n                value.validate(class_, tag, contents)\n                try:\n                    # Force parsing the Choice now\n                    value.contents = header + value.contents\n                    header = b''\n                    value.parse()\n                except (ValueError, TypeError) as e:\n                    args = e.args[1:]\n                    e.args = (e.args[0] + '\\n    while parsing %s' % type_name(value),) + args\n                    raise e\n\n            else:\n                if class_ != value.class_:\n                    raise ValueError(unwrap(\n                        '''\n                        Error parsing %s - class should have been %s, but %s was\n                        found\n                        ''',\n                        type_name(value),\n                        CLASS_NUM_TO_NAME_MAP.get(value.class_),\n                        CLASS_NUM_TO_NAME_MAP.get(class_, class_)\n                    ))\n                if method != value.method:\n                    # Allow parsing a primitive method as constructed if the value\n                    # is indefinite length. This is to allow parsing BER.\n                    ber_indef = method == 1 and value.method == 0 and trailer == b'\\x00\\x00'\n                    if not ber_indef or not isinstance(value, Constructable):\n                        raise ValueError(unwrap(\n                            '''\n                            Error parsing %s - method should have been %s, but %s was found\n                            ''',\n                            type_name(value),\n                            METHOD_NUM_TO_NAME_MAP.get(value.method),\n                            METHOD_NUM_TO_NAME_MAP.get(method, method)\n                        ))\n                    else:\n                        value.method = method\n                        value._indefinite = True\n                if tag != value.tag:\n                    if isinstance(value._bad_tag, tuple):\n                        is_bad_tag = tag in value._bad_tag\n                    else:\n                        is_bad_tag = tag == value._bad_tag\n                    if not is_bad_tag:\n                        raise ValueError(unwrap(\n                            '''\n                            Error parsing %s - tag should have been %s, but %s was found\n                            ''',\n                            type_name(value),\n                            value.tag,\n                            tag\n                        ))\n\n    # For explicitly tagged, un-speced parsings, we use a generic container\n    # since we will be parsing the contents and discarding the outer object\n    # anyway a little further on\n    elif spec_params and 'explicit' in spec_params:\n        original_value = Asn1Value(contents=contents, **spec_params)\n        original_explicit = original_value.explicit\n\n        to_parse = contents\n        explicit_header = header\n        explicit_trailer = trailer or b''\n        for expected_class, expected_tag in reversed(original_explicit):\n            info, _ = _parse(to_parse, len(to_parse))\n            _, _, _, parsed_header, to_parse, parsed_trailer = info\n            explicit_header += parsed_header\n            explicit_trailer = parsed_trailer + explicit_trailer\n        value = _build(*info, spec=spec, spec_params={'no_explicit': True})\n        value._header = header + value._header\n        value._trailer += trailer or b''\n        value.explicit = original_explicit\n        header_set = True\n\n    # If no spec was specified, allow anything and just process what\n    # is in the input data\n    else:\n        if tag not in _UNIVERSAL_SPECS:\n            raise ValueError(unwrap(\n                '''\n                Unknown element - %s class, %s method, tag %s\n                ''',\n                CLASS_NUM_TO_NAME_MAP.get(class_),\n                METHOD_NUM_TO_NAME_MAP.get(method),\n                tag\n            ))\n\n        spec = _UNIVERSAL_SPECS[tag]\n\n        value = spec(contents=contents, class_=class_)\n        ber_indef = method == 1 and value.method == 0 and trailer == b'\\x00\\x00'\n        if ber_indef and isinstance(value, Constructable):\n            value._indefinite = True\n        value.method = method\n\n    if not header_set:\n        value._header = header\n        value._trailer = trailer or b''\n\n    # Destroy any default value that our contents have overwritten\n    value._native = None\n\n    if nested_spec:\n        try:\n            value.parse(nested_spec)\n        except (ValueError, TypeError) as e:\n            args = e.args[1:]\n            e.args = (e.args[0] + '\\n    while parsing %s' % type_name(value),) + args\n            raise e\n\n    return value\n\n\ndef _parse_build(encoded_data, pointer=0, spec=None, spec_params=None, strict=False):\n    \"\"\"\n    Parses a byte string generically, or using a spec with optional params\n\n    :param encoded_data:\n        A byte string that contains BER-encoded data\n\n    :param pointer:\n        The index in the byte string to parse from\n\n    :param spec:\n        A class derived from Asn1Value that defines what class_ and tag the\n        value should have, and the semantics of the encoded value. The\n        return value will be of this type. If omitted, the encoded value\n        will be decoded using the standard universal tag based on the\n        encoded tag number.\n\n    :param spec_params:\n        A dict of params to pass to the spec object\n\n    :param strict:\n        A boolean indicating if trailing data should be forbidden - if so, a\n        ValueError will be raised when trailing data exists\n\n    :return:\n        A 2-element tuple:\n         - 0: An object of the type spec, or if not specified, a child of Asn1Value\n         - 1: An integer indicating how many bytes were consumed\n    \"\"\"\n\n    encoded_len = len(encoded_data)\n    info, new_pointer = _parse(encoded_data, encoded_len, pointer)\n    if strict and new_pointer != pointer + encoded_len:\n        extra_bytes = pointer + encoded_len - new_pointer\n        raise ValueError('Extra data - %d bytes of trailing data were provided' % extra_bytes)\n    return (_build(*info, spec=spec, spec_params=spec_params), new_pointer)\n", "asn1crypto/pdf.py": "# coding: utf-8\n\n\"\"\"\nASN.1 type classes for PDF signature structures. Adds extra oid mapping and\nvalue parsing to asn1crypto.x509.Extension() and asn1crypto.xms.CMSAttribute().\n\"\"\"\n\nfrom __future__ import unicode_literals, division, absolute_import, print_function\n\nfrom .cms import CMSAttributeType, CMSAttribute\nfrom .core import (\n    Boolean,\n    Integer,\n    Null,\n    ObjectIdentifier,\n    OctetString,\n    Sequence,\n    SequenceOf,\n    SetOf,\n)\nfrom .crl import CertificateList\nfrom .ocsp import OCSPResponse\nfrom .x509 import (\n    Extension,\n    ExtensionId,\n    GeneralName,\n    KeyPurposeId,\n)\n\n\nclass AdobeArchiveRevInfo(Sequence):\n    _fields = [\n        ('version', Integer)\n    ]\n\n\nclass AdobeTimestamp(Sequence):\n    _fields = [\n        ('version', Integer),\n        ('location', GeneralName),\n        ('requires_auth', Boolean, {'optional': True, 'default': False}),\n    ]\n\n\nclass OtherRevInfo(Sequence):\n    _fields = [\n        ('type', ObjectIdentifier),\n        ('value', OctetString),\n    ]\n\n\nclass SequenceOfCertificateList(SequenceOf):\n    _child_spec = CertificateList\n\n\nclass SequenceOfOCSPResponse(SequenceOf):\n    _child_spec = OCSPResponse\n\n\nclass SequenceOfOtherRevInfo(SequenceOf):\n    _child_spec = OtherRevInfo\n\n\nclass RevocationInfoArchival(Sequence):\n    _fields = [\n        ('crl', SequenceOfCertificateList, {'explicit': 0, 'optional': True}),\n        ('ocsp', SequenceOfOCSPResponse, {'explicit': 1, 'optional': True}),\n        ('other_rev_info', SequenceOfOtherRevInfo, {'explicit': 2, 'optional': True}),\n    ]\n\n\nclass SetOfRevocationInfoArchival(SetOf):\n    _child_spec = RevocationInfoArchival\n\n\nExtensionId._map['1.2.840.113583.1.1.9.2'] = 'adobe_archive_rev_info'\nExtensionId._map['1.2.840.113583.1.1.9.1'] = 'adobe_timestamp'\nExtensionId._map['1.2.840.113583.1.1.10'] = 'adobe_ppklite_credential'\nExtension._oid_specs['adobe_archive_rev_info'] = AdobeArchiveRevInfo\nExtension._oid_specs['adobe_timestamp'] = AdobeTimestamp\nExtension._oid_specs['adobe_ppklite_credential'] = Null\nKeyPurposeId._map['1.2.840.113583.1.1.5'] = 'pdf_signing'\nCMSAttributeType._map['1.2.840.113583.1.1.8'] = 'adobe_revocation_info_archival'\nCMSAttribute._oid_specs['adobe_revocation_info_archival'] = SetOfRevocationInfoArchival\n", "asn1crypto/_inet.py": "# coding: utf-8\nfrom __future__ import unicode_literals, division, absolute_import, print_function\n\nimport socket\nimport struct\n\nfrom ._errors import unwrap\nfrom ._types import byte_cls, bytes_to_list, str_cls, type_name\n\n\ndef inet_ntop(address_family, packed_ip):\n    \"\"\"\n    Windows compatibility shim for socket.inet_ntop().\n\n    :param address_family:\n        socket.AF_INET for IPv4 or socket.AF_INET6 for IPv6\n\n    :param packed_ip:\n        A byte string of the network form of an IP address\n\n    :return:\n        A unicode string of the IP address\n    \"\"\"\n\n    if address_family not in set([socket.AF_INET, socket.AF_INET6]):\n        raise ValueError(unwrap(\n            '''\n            address_family must be socket.AF_INET (%s) or socket.AF_INET6 (%s),\n            not %s\n            ''',\n            repr(socket.AF_INET),\n            repr(socket.AF_INET6),\n            repr(address_family)\n        ))\n\n    if not isinstance(packed_ip, byte_cls):\n        raise TypeError(unwrap(\n            '''\n            packed_ip must be a byte string, not %s\n            ''',\n            type_name(packed_ip)\n        ))\n\n    required_len = 4 if address_family == socket.AF_INET else 16\n    if len(packed_ip) != required_len:\n        raise ValueError(unwrap(\n            '''\n            packed_ip must be %d bytes long - is %d\n            ''',\n            required_len,\n            len(packed_ip)\n        ))\n\n    if address_family == socket.AF_INET:\n        return '%d.%d.%d.%d' % tuple(bytes_to_list(packed_ip))\n\n    octets = struct.unpack(b'!HHHHHHHH', packed_ip)\n\n    runs_of_zero = {}\n    longest_run = 0\n    zero_index = None\n    for i, octet in enumerate(octets + (-1,)):\n        if octet != 0:\n            if zero_index is not None:\n                length = i - zero_index\n                if length not in runs_of_zero:\n                    runs_of_zero[length] = zero_index\n                longest_run = max(longest_run, length)\n                zero_index = None\n        elif zero_index is None:\n            zero_index = i\n\n    hexed = [hex(o)[2:] for o in octets]\n\n    if longest_run < 2:\n        return ':'.join(hexed)\n\n    zero_start = runs_of_zero[longest_run]\n    zero_end = zero_start + longest_run\n\n    return ':'.join(hexed[:zero_start]) + '::' + ':'.join(hexed[zero_end:])\n\n\ndef inet_pton(address_family, ip_string):\n    \"\"\"\n    Windows compatibility shim for socket.inet_ntop().\n\n    :param address_family:\n        socket.AF_INET for IPv4 or socket.AF_INET6 for IPv6\n\n    :param ip_string:\n        A unicode string of an IP address\n\n    :return:\n        A byte string of the network form of the IP address\n    \"\"\"\n\n    if address_family not in set([socket.AF_INET, socket.AF_INET6]):\n        raise ValueError(unwrap(\n            '''\n            address_family must be socket.AF_INET (%s) or socket.AF_INET6 (%s),\n            not %s\n            ''',\n            repr(socket.AF_INET),\n            repr(socket.AF_INET6),\n            repr(address_family)\n        ))\n\n    if not isinstance(ip_string, str_cls):\n        raise TypeError(unwrap(\n            '''\n            ip_string must be a unicode string, not %s\n            ''',\n            type_name(ip_string)\n        ))\n\n    if address_family == socket.AF_INET:\n        octets = ip_string.split('.')\n        error = len(octets) != 4\n        if not error:\n            ints = []\n            for o in octets:\n                o = int(o)\n                if o > 255 or o < 0:\n                    error = True\n                    break\n                ints.append(o)\n\n        if error:\n            raise ValueError(unwrap(\n                '''\n                ip_string must be a dotted string with four integers in the\n                range of 0 to 255, got %s\n                ''',\n                repr(ip_string)\n            ))\n\n        return struct.pack(b'!BBBB', *ints)\n\n    error = False\n    omitted = ip_string.count('::')\n    if omitted > 1:\n        error = True\n    elif omitted == 0:\n        octets = ip_string.split(':')\n        error = len(octets) != 8\n    else:\n        begin, end = ip_string.split('::')\n        begin_octets = begin.split(':')\n        end_octets = end.split(':')\n        missing = 8 - len(begin_octets) - len(end_octets)\n        octets = begin_octets + (['0'] * missing) + end_octets\n\n    if not error:\n        ints = []\n        for o in octets:\n            o = int(o, 16)\n            if o > 65535 or o < 0:\n                error = True\n                break\n            ints.append(o)\n\n        return struct.pack(b'!HHHHHHHH', *ints)\n\n    raise ValueError(unwrap(\n        '''\n        ip_string must be a valid ipv6 string, got %s\n        ''',\n        repr(ip_string)\n    ))\n", "asn1crypto/version.py": "# coding: utf-8\nfrom __future__ import unicode_literals, division, absolute_import, print_function\n\n\n__version__ = '1.5.1'\n__version_info__ = (1, 5, 1)\n", "asn1crypto/cms.py": "# coding: utf-8\n\n\"\"\"\nASN.1 type classes for cryptographic message syntax (CMS). Structures are also\ncompatible with PKCS#7. Exports the following items:\n\n - AuthenticatedData()\n - AuthEnvelopedData()\n - CompressedData()\n - ContentInfo()\n - DigestedData()\n - EncryptedData()\n - EnvelopedData()\n - SignedAndEnvelopedData()\n - SignedData()\n\nOther type classes are defined that help compose the types listed above.\n\nMost CMS structures in the wild are formatted as ContentInfo encapsulating one of the other types.\n\"\"\"\n\nfrom __future__ import unicode_literals, division, absolute_import, print_function\n\ntry:\n    import zlib\nexcept (ImportError):\n    zlib = None\n\nfrom .algos import (\n    _ForceNullParameters,\n    DigestAlgorithm,\n    EncryptionAlgorithm,\n    EncryptionAlgorithmId,\n    HmacAlgorithm,\n    KdfAlgorithm,\n    RSAESOAEPParams,\n    SignedDigestAlgorithm,\n)\nfrom .core import (\n    Any,\n    BitString,\n    Choice,\n    Enumerated,\n    GeneralizedTime,\n    Integer,\n    ObjectIdentifier,\n    OctetBitString,\n    OctetString,\n    ParsableOctetString,\n    Sequence,\n    SequenceOf,\n    SetOf,\n    UTCTime,\n    UTF8String,\n)\nfrom .crl import CertificateList\nfrom .keys import PublicKeyInfo\nfrom .ocsp import OCSPResponse\nfrom .x509 import Attributes, Certificate, Extensions, GeneralName, GeneralNames, Name\n\n\n# These structures are taken from\n# ftp://ftp.rsasecurity.com/pub/pkcs/ascii/pkcs-6.asc\n\nclass ExtendedCertificateInfo(Sequence):\n    _fields = [\n        ('version', Integer),\n        ('certificate', Certificate),\n        ('attributes', Attributes),\n    ]\n\n\nclass ExtendedCertificate(Sequence):\n    _fields = [\n        ('extended_certificate_info', ExtendedCertificateInfo),\n        ('signature_algorithm', SignedDigestAlgorithm),\n        ('signature', OctetBitString),\n    ]\n\n\n# These structures are taken from https://tools.ietf.org/html/rfc5652,\n# https://tools.ietf.org/html/rfc5083, http://tools.ietf.org/html/rfc2315,\n# https://tools.ietf.org/html/rfc5940, https://tools.ietf.org/html/rfc3274,\n# https://tools.ietf.org/html/rfc3281\n\n\nclass CMSVersion(Integer):\n    _map = {\n        0: 'v0',\n        1: 'v1',\n        2: 'v2',\n        3: 'v3',\n        4: 'v4',\n        5: 'v5',\n    }\n\n\nclass CMSAttributeType(ObjectIdentifier):\n    _map = {\n        '1.2.840.113549.1.9.3': 'content_type',\n        '1.2.840.113549.1.9.4': 'message_digest',\n        '1.2.840.113549.1.9.5': 'signing_time',\n        '1.2.840.113549.1.9.6': 'counter_signature',\n        # https://datatracker.ietf.org/doc/html/rfc2633#section-2.5.2\n        '1.2.840.113549.1.9.15': 'smime_capabilities',\n        # https://tools.ietf.org/html/rfc2633#page-26\n        '1.2.840.113549.1.9.16.2.11': 'encrypt_key_pref',\n        # https://tools.ietf.org/html/rfc3161#page-20\n        '1.2.840.113549.1.9.16.2.14': 'signature_time_stamp_token',\n        # https://tools.ietf.org/html/rfc6211#page-5\n        '1.2.840.113549.1.9.52': 'cms_algorithm_protection',\n        # https://docs.microsoft.com/en-us/previous-versions/hh968145(v%3Dvs.85)\n        '1.3.6.1.4.1.311.2.4.1': 'microsoft_nested_signature',\n        # Some places refer to this as SPC_RFC3161_OBJID, others szOID_RFC3161_counterSign.\n        # https://docs.microsoft.com/en-us/windows/win32/api/wincrypt/ns-wincrypt-crypt_algorithm_identifier\n        # refers to szOID_RFC3161_counterSign as \"1.2.840.113549.1.9.16.1.4\",\n        # but that OID is also called szOID_TIMESTAMP_TOKEN. Because of there being\n        # no canonical source for this OID, we give it our own name\n        '1.3.6.1.4.1.311.3.3.1': 'microsoft_time_stamp_token',\n    }\n\n\nclass Time(Choice):\n    _alternatives = [\n        ('utc_time', UTCTime),\n        ('generalized_time', GeneralizedTime),\n    ]\n\n\nclass ContentType(ObjectIdentifier):\n    _map = {\n        '1.2.840.113549.1.7.1': 'data',\n        '1.2.840.113549.1.7.2': 'signed_data',\n        '1.2.840.113549.1.7.3': 'enveloped_data',\n        '1.2.840.113549.1.7.4': 'signed_and_enveloped_data',\n        '1.2.840.113549.1.7.5': 'digested_data',\n        '1.2.840.113549.1.7.6': 'encrypted_data',\n        '1.2.840.113549.1.9.16.1.2': 'authenticated_data',\n        '1.2.840.113549.1.9.16.1.9': 'compressed_data',\n        '1.2.840.113549.1.9.16.1.23': 'authenticated_enveloped_data',\n    }\n\n\nclass CMSAlgorithmProtection(Sequence):\n    _fields = [\n        ('digest_algorithm', DigestAlgorithm),\n        ('signature_algorithm', SignedDigestAlgorithm, {'implicit': 1, 'optional': True}),\n        ('mac_algorithm', HmacAlgorithm, {'implicit': 2, 'optional': True}),\n    ]\n\n\nclass SetOfContentType(SetOf):\n    _child_spec = ContentType\n\n\nclass SetOfOctetString(SetOf):\n    _child_spec = OctetString\n\n\nclass SetOfTime(SetOf):\n    _child_spec = Time\n\n\nclass SetOfAny(SetOf):\n    _child_spec = Any\n\n\nclass SetOfCMSAlgorithmProtection(SetOf):\n    _child_spec = CMSAlgorithmProtection\n\n\nclass CMSAttribute(Sequence):\n    _fields = [\n        ('type', CMSAttributeType),\n        ('values', None),\n    ]\n\n    _oid_specs = {}\n\n    def _values_spec(self):\n        return self._oid_specs.get(self['type'].native, SetOfAny)\n\n    _spec_callbacks = {\n        'values': _values_spec\n    }\n\n\nclass CMSAttributes(SetOf):\n    _child_spec = CMSAttribute\n\n\nclass IssuerSerial(Sequence):\n    _fields = [\n        ('issuer', GeneralNames),\n        ('serial', Integer),\n        ('issuer_uid', OctetBitString, {'optional': True}),\n    ]\n\n\nclass AttCertVersion(Integer):\n    _map = {\n        0: 'v1',\n        1: 'v2',\n    }\n\n\nclass AttCertSubject(Choice):\n    _alternatives = [\n        ('base_certificate_id', IssuerSerial, {'explicit': 0}),\n        ('subject_name', GeneralNames, {'explicit': 1}),\n    ]\n\n\nclass AttCertValidityPeriod(Sequence):\n    _fields = [\n        ('not_before_time', GeneralizedTime),\n        ('not_after_time', GeneralizedTime),\n    ]\n\n\nclass AttributeCertificateInfoV1(Sequence):\n    _fields = [\n        ('version', AttCertVersion, {'default': 'v1'}),\n        ('subject', AttCertSubject),\n        ('issuer', GeneralNames),\n        ('signature', SignedDigestAlgorithm),\n        ('serial_number', Integer),\n        ('att_cert_validity_period', AttCertValidityPeriod),\n        ('attributes', Attributes),\n        ('issuer_unique_id', OctetBitString, {'optional': True}),\n        ('extensions', Extensions, {'optional': True}),\n    ]\n\n\nclass AttributeCertificateV1(Sequence):\n    _fields = [\n        ('ac_info', AttributeCertificateInfoV1),\n        ('signature_algorithm', SignedDigestAlgorithm),\n        ('signature', OctetBitString),\n    ]\n\n\nclass DigestedObjectType(Enumerated):\n    _map = {\n        0: 'public_key',\n        1: 'public_key_cert',\n        2: 'other_objy_types',\n    }\n\n\nclass ObjectDigestInfo(Sequence):\n    _fields = [\n        ('digested_object_type', DigestedObjectType),\n        ('other_object_type_id', ObjectIdentifier, {'optional': True}),\n        ('digest_algorithm', DigestAlgorithm),\n        ('object_digest', OctetBitString),\n    ]\n\n\nclass Holder(Sequence):\n    _fields = [\n        ('base_certificate_id', IssuerSerial, {'implicit': 0, 'optional': True}),\n        ('entity_name', GeneralNames, {'implicit': 1, 'optional': True}),\n        ('object_digest_info', ObjectDigestInfo, {'implicit': 2, 'optional': True}),\n    ]\n\n\nclass V2Form(Sequence):\n    _fields = [\n        ('issuer_name', GeneralNames, {'optional': True}),\n        ('base_certificate_id', IssuerSerial, {'explicit': 0, 'optional': True}),\n        ('object_digest_info', ObjectDigestInfo, {'explicit': 1, 'optional': True}),\n    ]\n\n\nclass AttCertIssuer(Choice):\n    _alternatives = [\n        ('v1_form', GeneralNames),\n        ('v2_form', V2Form, {'implicit': 0}),\n    ]\n\n\nclass IetfAttrValue(Choice):\n    _alternatives = [\n        ('octets', OctetString),\n        ('oid', ObjectIdentifier),\n        ('string', UTF8String),\n    ]\n\n\nclass IetfAttrValues(SequenceOf):\n    _child_spec = IetfAttrValue\n\n\nclass IetfAttrSyntax(Sequence):\n    _fields = [\n        ('policy_authority', GeneralNames, {'implicit': 0, 'optional': True}),\n        ('values', IetfAttrValues),\n    ]\n\n\nclass SetOfIetfAttrSyntax(SetOf):\n    _child_spec = IetfAttrSyntax\n\n\nclass SvceAuthInfo(Sequence):\n    _fields = [\n        ('service', GeneralName),\n        ('ident', GeneralName),\n        ('auth_info', OctetString, {'optional': True}),\n    ]\n\n\nclass SetOfSvceAuthInfo(SetOf):\n    _child_spec = SvceAuthInfo\n\n\nclass RoleSyntax(Sequence):\n    _fields = [\n        ('role_authority', GeneralNames, {'implicit': 0, 'optional': True}),\n        ('role_name', GeneralName, {'explicit': 1}),\n    ]\n\n\nclass SetOfRoleSyntax(SetOf):\n    _child_spec = RoleSyntax\n\n\nclass ClassList(BitString):\n    _map = {\n        0: 'unmarked',\n        1: 'unclassified',\n        2: 'restricted',\n        3: 'confidential',\n        4: 'secret',\n        5: 'top_secret',\n    }\n\n\nclass SecurityCategory(Sequence):\n    _fields = [\n        ('type', ObjectIdentifier, {'implicit': 0}),\n        ('value', Any, {'explicit': 1}),\n    ]\n\n\nclass SetOfSecurityCategory(SetOf):\n    _child_spec = SecurityCategory\n\n\nclass Clearance(Sequence):\n    _fields = [\n        ('policy_id', ObjectIdentifier),\n        ('class_list', ClassList, {'default': set(['unclassified'])}),\n        ('security_categories', SetOfSecurityCategory, {'optional': True}),\n    ]\n\n\nclass SetOfClearance(SetOf):\n    _child_spec = Clearance\n\n\nclass BigTime(Sequence):\n    _fields = [\n        ('major', Integer),\n        ('fractional_seconds', Integer),\n        ('sign', Integer, {'optional': True}),\n    ]\n\n\nclass LeapData(Sequence):\n    _fields = [\n        ('leap_time', BigTime),\n        ('action', Integer),\n    ]\n\n\nclass SetOfLeapData(SetOf):\n    _child_spec = LeapData\n\n\nclass TimingMetrics(Sequence):\n    _fields = [\n        ('ntp_time', BigTime),\n        ('offset', BigTime),\n        ('delay', BigTime),\n        ('expiration', BigTime),\n        ('leap_event', SetOfLeapData, {'optional': True}),\n    ]\n\n\nclass SetOfTimingMetrics(SetOf):\n    _child_spec = TimingMetrics\n\n\nclass TimingPolicy(Sequence):\n    _fields = [\n        ('policy_id', SequenceOf, {'spec': ObjectIdentifier}),\n        ('max_offset', BigTime, {'explicit': 0, 'optional': True}),\n        ('max_delay', BigTime, {'explicit': 1, 'optional': True}),\n    ]\n\n\nclass SetOfTimingPolicy(SetOf):\n    _child_spec = TimingPolicy\n\n\nclass AttCertAttributeType(ObjectIdentifier):\n    _map = {\n        '1.3.6.1.5.5.7.10.1': 'authentication_info',\n        '1.3.6.1.5.5.7.10.2': 'access_identity',\n        '1.3.6.1.5.5.7.10.3': 'charging_identity',\n        '1.3.6.1.5.5.7.10.4': 'group',\n        '2.5.4.72': 'role',\n        '2.5.4.55': 'clearance',\n        '1.3.6.1.4.1.601.10.4.1': 'timing_metrics',\n        '1.3.6.1.4.1.601.10.4.2': 'timing_policy',\n    }\n\n\nclass AttCertAttribute(Sequence):\n    _fields = [\n        ('type', AttCertAttributeType),\n        ('values', None),\n    ]\n\n    _oid_specs = {\n        'authentication_info': SetOfSvceAuthInfo,\n        'access_identity': SetOfSvceAuthInfo,\n        'charging_identity': SetOfIetfAttrSyntax,\n        'group': SetOfIetfAttrSyntax,\n        'role': SetOfRoleSyntax,\n        'clearance': SetOfClearance,\n        'timing_metrics': SetOfTimingMetrics,\n        'timing_policy': SetOfTimingPolicy,\n    }\n\n    def _values_spec(self):\n        return self._oid_specs.get(self['type'].native, SetOfAny)\n\n    _spec_callbacks = {\n        'values': _values_spec\n    }\n\n\nclass AttCertAttributes(SequenceOf):\n    _child_spec = AttCertAttribute\n\n\nclass AttributeCertificateInfoV2(Sequence):\n    _fields = [\n        ('version', AttCertVersion),\n        ('holder', Holder),\n        ('issuer', AttCertIssuer),\n        ('signature', SignedDigestAlgorithm),\n        ('serial_number', Integer),\n        ('att_cert_validity_period', AttCertValidityPeriod),\n        ('attributes', AttCertAttributes),\n        ('issuer_unique_id', OctetBitString, {'optional': True}),\n        ('extensions', Extensions, {'optional': True}),\n    ]\n\n\nclass AttributeCertificateV2(Sequence):\n    # Handle the situation where a V2 cert is encoded as V1\n    _bad_tag = 1\n\n    _fields = [\n        ('ac_info', AttributeCertificateInfoV2),\n        ('signature_algorithm', SignedDigestAlgorithm),\n        ('signature', OctetBitString),\n    ]\n\n\nclass OtherCertificateFormat(Sequence):\n    _fields = [\n        ('other_cert_format', ObjectIdentifier),\n        ('other_cert', Any),\n    ]\n\n\nclass CertificateChoices(Choice):\n    _alternatives = [\n        ('certificate', Certificate),\n        ('extended_certificate', ExtendedCertificate, {'implicit': 0}),\n        ('v1_attr_cert', AttributeCertificateV1, {'implicit': 1}),\n        ('v2_attr_cert', AttributeCertificateV2, {'implicit': 2}),\n        ('other', OtherCertificateFormat, {'implicit': 3}),\n    ]\n\n    def validate(self, class_, tag, contents):\n        \"\"\"\n        Ensures that the class and tag specified exist as an alternative. This\n        custom version fixes parsing broken encodings there a V2 attribute\n        # certificate is encoded as a V1\n\n        :param class_:\n            The integer class_ from the encoded value header\n\n        :param tag:\n            The integer tag from the encoded value header\n\n        :param contents:\n            A byte string of the contents of the value - used when the object\n            is explicitly tagged\n\n        :raises:\n            ValueError - when value is not a valid alternative\n        \"\"\"\n\n        super(CertificateChoices, self).validate(class_, tag, contents)\n        if self._choice == 2:\n            if AttCertVersion.load(Sequence.load(contents)[0].dump()).native == 'v2':\n                self._choice = 3\n\n\nclass CertificateSet(SetOf):\n    _child_spec = CertificateChoices\n\n\nclass ContentInfo(Sequence):\n    _fields = [\n        ('content_type', ContentType),\n        ('content', Any, {'explicit': 0, 'optional': True}),\n    ]\n\n    _oid_pair = ('content_type', 'content')\n    _oid_specs = {}\n\n\nclass SetOfContentInfo(SetOf):\n    _child_spec = ContentInfo\n\n\nclass EncapsulatedContentInfo(Sequence):\n    _fields = [\n        ('content_type', ContentType),\n        ('content', ParsableOctetString, {'explicit': 0, 'optional': True}),\n    ]\n\n    _oid_pair = ('content_type', 'content')\n    _oid_specs = {}\n\n\nclass IssuerAndSerialNumber(Sequence):\n    _fields = [\n        ('issuer', Name),\n        ('serial_number', Integer),\n    ]\n\n\nclass SignerIdentifier(Choice):\n    _alternatives = [\n        ('issuer_and_serial_number', IssuerAndSerialNumber),\n        ('subject_key_identifier', OctetString, {'implicit': 0}),\n    ]\n\n\nclass DigestAlgorithms(SetOf):\n    _child_spec = DigestAlgorithm\n\n\nclass CertificateRevocationLists(SetOf):\n    _child_spec = CertificateList\n\n\nclass SCVPReqRes(Sequence):\n    _fields = [\n        ('request', ContentInfo, {'explicit': 0, 'optional': True}),\n        ('response', ContentInfo),\n    ]\n\n\nclass OtherRevInfoFormatId(ObjectIdentifier):\n    _map = {\n        '1.3.6.1.5.5.7.16.2': 'ocsp_response',\n        '1.3.6.1.5.5.7.16.4': 'scvp',\n    }\n\n\nclass OtherRevocationInfoFormat(Sequence):\n    _fields = [\n        ('other_rev_info_format', OtherRevInfoFormatId),\n        ('other_rev_info', Any),\n    ]\n\n    _oid_pair = ('other_rev_info_format', 'other_rev_info')\n    _oid_specs = {\n        'ocsp_response': OCSPResponse,\n        'scvp': SCVPReqRes,\n    }\n\n\nclass RevocationInfoChoice(Choice):\n    _alternatives = [\n        ('crl', CertificateList),\n        ('other', OtherRevocationInfoFormat, {'implicit': 1}),\n    ]\n\n\nclass RevocationInfoChoices(SetOf):\n    _child_spec = RevocationInfoChoice\n\n\nclass SignerInfo(Sequence):\n    _fields = [\n        ('version', CMSVersion),\n        ('sid', SignerIdentifier),\n        ('digest_algorithm', DigestAlgorithm),\n        ('signed_attrs', CMSAttributes, {'implicit': 0, 'optional': True}),\n        ('signature_algorithm', SignedDigestAlgorithm),\n        ('signature', OctetString),\n        ('unsigned_attrs', CMSAttributes, {'implicit': 1, 'optional': True}),\n    ]\n\n\nclass SignerInfos(SetOf):\n    _child_spec = SignerInfo\n\n\nclass SignedData(Sequence):\n    _fields = [\n        ('version', CMSVersion),\n        ('digest_algorithms', DigestAlgorithms),\n        ('encap_content_info', None),\n        ('certificates', CertificateSet, {'implicit': 0, 'optional': True}),\n        ('crls', RevocationInfoChoices, {'implicit': 1, 'optional': True}),\n        ('signer_infos', SignerInfos),\n    ]\n\n    def _encap_content_info_spec(self):\n        # If the encap_content_info is version v1, then this could be a PKCS#7\n        # structure, or a CMS structure. CMS wraps the encoded value in an\n        # Octet String tag.\n\n        # If the version is greater than 1, it is definite CMS\n        if self['version'].native != 'v1':\n            return EncapsulatedContentInfo\n\n        # Otherwise, the ContentInfo spec from PKCS#7 will be compatible with\n        # CMS v1 (which only allows Data, an Octet String) and PKCS#7, which\n        # allows Any\n        return ContentInfo\n\n    _spec_callbacks = {\n        'encap_content_info': _encap_content_info_spec\n    }\n\n\nclass OriginatorInfo(Sequence):\n    _fields = [\n        ('certs', CertificateSet, {'implicit': 0, 'optional': True}),\n        ('crls', RevocationInfoChoices, {'implicit': 1, 'optional': True}),\n    ]\n\n\nclass RecipientIdentifier(Choice):\n    _alternatives = [\n        ('issuer_and_serial_number', IssuerAndSerialNumber),\n        ('subject_key_identifier', OctetString, {'implicit': 0}),\n    ]\n\n\nclass KeyEncryptionAlgorithmId(ObjectIdentifier):\n    _map = {\n        '1.2.840.113549.1.1.1': 'rsaes_pkcs1v15',\n        '1.2.840.113549.1.1.7': 'rsaes_oaep',\n        '2.16.840.1.101.3.4.1.5': 'aes128_wrap',\n        '2.16.840.1.101.3.4.1.8': 'aes128_wrap_pad',\n        '2.16.840.1.101.3.4.1.25': 'aes192_wrap',\n        '2.16.840.1.101.3.4.1.28': 'aes192_wrap_pad',\n        '2.16.840.1.101.3.4.1.45': 'aes256_wrap',\n        '2.16.840.1.101.3.4.1.48': 'aes256_wrap_pad',\n    }\n\n    _reverse_map = {\n        'rsa': '1.2.840.113549.1.1.1',\n        'rsaes_pkcs1v15': '1.2.840.113549.1.1.1',\n        'rsaes_oaep': '1.2.840.113549.1.1.7',\n        'aes128_wrap': '2.16.840.1.101.3.4.1.5',\n        'aes128_wrap_pad': '2.16.840.1.101.3.4.1.8',\n        'aes192_wrap': '2.16.840.1.101.3.4.1.25',\n        'aes192_wrap_pad': '2.16.840.1.101.3.4.1.28',\n        'aes256_wrap': '2.16.840.1.101.3.4.1.45',\n        'aes256_wrap_pad': '2.16.840.1.101.3.4.1.48',\n    }\n\n\nclass KeyEncryptionAlgorithm(_ForceNullParameters, Sequence):\n    _fields = [\n        ('algorithm', KeyEncryptionAlgorithmId),\n        ('parameters', Any, {'optional': True}),\n    ]\n\n    _oid_pair = ('algorithm', 'parameters')\n    _oid_specs = {\n        'rsaes_oaep': RSAESOAEPParams,\n    }\n\n\nclass KeyTransRecipientInfo(Sequence):\n    _fields = [\n        ('version', CMSVersion),\n        ('rid', RecipientIdentifier),\n        ('key_encryption_algorithm', KeyEncryptionAlgorithm),\n        ('encrypted_key', OctetString),\n    ]\n\n\nclass OriginatorIdentifierOrKey(Choice):\n    _alternatives = [\n        ('issuer_and_serial_number', IssuerAndSerialNumber),\n        ('subject_key_identifier', OctetString, {'implicit': 0}),\n        ('originator_key', PublicKeyInfo, {'implicit': 1}),\n    ]\n\n\nclass OtherKeyAttribute(Sequence):\n    _fields = [\n        ('key_attr_id', ObjectIdentifier),\n        ('key_attr', Any),\n    ]\n\n\nclass RecipientKeyIdentifier(Sequence):\n    _fields = [\n        ('subject_key_identifier', OctetString),\n        ('date', GeneralizedTime, {'optional': True}),\n        ('other', OtherKeyAttribute, {'optional': True}),\n    ]\n\n    def _setup(self):\n        super(RecipientKeyIdentifier, self)._setup()\n        # This creates a backwards compatible shim for an\n        # incorrect format field name that was in old versions\n        self._field_map['subjectKeyIdentifier'] = self._field_map['subject_key_identifier']\n\n\nclass KeyAgreementRecipientIdentifier(Choice):\n    _alternatives = [\n        ('issuer_and_serial_number', IssuerAndSerialNumber),\n        ('r_key_id', RecipientKeyIdentifier, {'implicit': 0}),\n    ]\n\n\nclass RecipientEncryptedKey(Sequence):\n    _fields = [\n        ('rid', KeyAgreementRecipientIdentifier),\n        ('encrypted_key', OctetString),\n    ]\n\n\nclass RecipientEncryptedKeys(SequenceOf):\n    _child_spec = RecipientEncryptedKey\n\n\nclass KeyAgreeRecipientInfo(Sequence):\n    _fields = [\n        ('version', CMSVersion),\n        ('originator', OriginatorIdentifierOrKey, {'explicit': 0}),\n        ('ukm', OctetString, {'explicit': 1, 'optional': True}),\n        ('key_encryption_algorithm', KeyEncryptionAlgorithm),\n        ('recipient_encrypted_keys', RecipientEncryptedKeys),\n    ]\n\n\nclass KEKIdentifier(Sequence):\n    _fields = [\n        ('key_identifier', OctetString),\n        ('date', GeneralizedTime, {'optional': True}),\n        ('other', OtherKeyAttribute, {'optional': True}),\n    ]\n\n\nclass KEKRecipientInfo(Sequence):\n    _fields = [\n        ('version', CMSVersion),\n        ('kekid', KEKIdentifier),\n        ('key_encryption_algorithm', KeyEncryptionAlgorithm),\n        ('encrypted_key', OctetString),\n    ]\n\n\nclass PasswordRecipientInfo(Sequence):\n    _fields = [\n        ('version', CMSVersion),\n        ('key_derivation_algorithm', KdfAlgorithm, {'implicit': 0, 'optional': True}),\n        ('key_encryption_algorithm', KeyEncryptionAlgorithm),\n        ('encrypted_key', OctetString),\n    ]\n\n\nclass OtherRecipientInfo(Sequence):\n    _fields = [\n        ('ori_type', ObjectIdentifier),\n        ('ori_value', Any),\n    ]\n\n\nclass RecipientInfo(Choice):\n    _alternatives = [\n        ('ktri', KeyTransRecipientInfo),\n        ('kari', KeyAgreeRecipientInfo, {'implicit': 1}),\n        ('kekri', KEKRecipientInfo, {'implicit': 2}),\n        ('pwri', PasswordRecipientInfo, {'implicit': 3}),\n        ('ori', OtherRecipientInfo, {'implicit': 4}),\n    ]\n\n\nclass RecipientInfos(SetOf):\n    _child_spec = RecipientInfo\n\n\nclass EncryptedContentInfo(Sequence):\n    _fields = [\n        ('content_type', ContentType),\n        ('content_encryption_algorithm', EncryptionAlgorithm),\n        ('encrypted_content', OctetString, {'implicit': 0, 'optional': True}),\n    ]\n\n\nclass EnvelopedData(Sequence):\n    _fields = [\n        ('version', CMSVersion),\n        ('originator_info', OriginatorInfo, {'implicit': 0, 'optional': True}),\n        ('recipient_infos', RecipientInfos),\n        ('encrypted_content_info', EncryptedContentInfo),\n        ('unprotected_attrs', CMSAttributes, {'implicit': 1, 'optional': True}),\n    ]\n\n\nclass SignedAndEnvelopedData(Sequence):\n    _fields = [\n        ('version', CMSVersion),\n        ('recipient_infos', RecipientInfos),\n        ('digest_algorithms', DigestAlgorithms),\n        ('encrypted_content_info', EncryptedContentInfo),\n        ('certificates', CertificateSet, {'implicit': 0, 'optional': True}),\n        ('crls', CertificateRevocationLists, {'implicit': 1, 'optional': True}),\n        ('signer_infos', SignerInfos),\n    ]\n\n\nclass DigestedData(Sequence):\n    _fields = [\n        ('version', CMSVersion),\n        ('digest_algorithm', DigestAlgorithm),\n        ('encap_content_info', None),\n        ('digest', OctetString),\n    ]\n\n    def _encap_content_info_spec(self):\n        # If the encap_content_info is version v1, then this could be a PKCS#7\n        # structure, or a CMS structure. CMS wraps the encoded value in an\n        # Octet String tag.\n\n        # If the version is greater than 1, it is definite CMS\n        if self['version'].native != 'v1':\n            return EncapsulatedContentInfo\n\n        # Otherwise, the ContentInfo spec from PKCS#7 will be compatible with\n        # CMS v1 (which only allows Data, an Octet String) and PKCS#7, which\n        # allows Any\n        return ContentInfo\n\n    _spec_callbacks = {\n        'encap_content_info': _encap_content_info_spec\n    }\n\n\nclass EncryptedData(Sequence):\n    _fields = [\n        ('version', CMSVersion),\n        ('encrypted_content_info', EncryptedContentInfo),\n        ('unprotected_attrs', CMSAttributes, {'implicit': 1, 'optional': True}),\n    ]\n\n\nclass AuthenticatedData(Sequence):\n    _fields = [\n        ('version', CMSVersion),\n        ('originator_info', OriginatorInfo, {'implicit': 0, 'optional': True}),\n        ('recipient_infos', RecipientInfos),\n        ('mac_algorithm', HmacAlgorithm),\n        ('digest_algorithm', DigestAlgorithm, {'implicit': 1, 'optional': True}),\n        # This does not require the _spec_callbacks approach of SignedData and\n        # DigestedData since AuthenticatedData was not part of PKCS#7\n        ('encap_content_info', EncapsulatedContentInfo),\n        ('auth_attrs', CMSAttributes, {'implicit': 2, 'optional': True}),\n        ('mac', OctetString),\n        ('unauth_attrs', CMSAttributes, {'implicit': 3, 'optional': True}),\n    ]\n\n\nclass AuthEnvelopedData(Sequence):\n    _fields = [\n        ('version', CMSVersion),\n        ('originator_info', OriginatorInfo, {'implicit': 0, 'optional': True}),\n        ('recipient_infos', RecipientInfos),\n        ('auth_encrypted_content_info', EncryptedContentInfo),\n        ('auth_attrs', CMSAttributes, {'implicit': 1, 'optional': True}),\n        ('mac', OctetString),\n        ('unauth_attrs', CMSAttributes, {'implicit': 2, 'optional': True}),\n    ]\n\n\nclass CompressionAlgorithmId(ObjectIdentifier):\n    _map = {\n        '1.2.840.113549.1.9.16.3.8': 'zlib',\n    }\n\n\nclass CompressionAlgorithm(Sequence):\n    _fields = [\n        ('algorithm', CompressionAlgorithmId),\n        ('parameters', Any, {'optional': True}),\n    ]\n\n\nclass CompressedData(Sequence):\n    _fields = [\n        ('version', CMSVersion),\n        ('compression_algorithm', CompressionAlgorithm),\n        ('encap_content_info', EncapsulatedContentInfo),\n    ]\n\n    _decompressed = None\n\n    @property\n    def decompressed(self):\n        if self._decompressed is None:\n            if zlib is None:\n                raise SystemError('The zlib module is not available')\n            self._decompressed = zlib.decompress(self['encap_content_info']['content'].native)\n        return self._decompressed\n\n\nclass SMIMEEncryptionKeyPreference(Choice):\n    _alternatives = [\n        ('issuer_and_serial_number', IssuerAndSerialNumber, {'implicit': 0}),\n        ('recipient_key_id', RecipientKeyIdentifier, {'implicit': 1}),\n        ('subject_alt_key_identifier', PublicKeyInfo, {'implicit': 2}),\n    ]\n\n    def _setup(self):\n        super(SMIMEEncryptionKeyPreference, self)._setup()\n        # This creates backwards compatible shims for two\n        # incorrect format alternative names that were in old versions\n        self._name_map['recipientKeyId'] = self._name_map['recipient_key_id']\n        self._name_map['subjectAltKeyIdentifier'] = self._name_map['subject_alt_key_identifier']\n\n\nclass SMIMEEncryptionKeyPreferences(SetOf):\n    _child_spec = SMIMEEncryptionKeyPreference\n\n\nclass SMIMECapabilityIdentifier(Sequence):\n    _fields = [\n        ('capability_id', EncryptionAlgorithmId),\n        ('parameters', Any, {'optional': True}),\n    ]\n\n\nclass SMIMECapabilites(SequenceOf):\n    _child_spec = SMIMECapabilityIdentifier\n\n\nclass SetOfSMIMECapabilites(SetOf):\n    _child_spec = SMIMECapabilites\n\n\nContentInfo._oid_specs = {\n    'data': OctetString,\n    'signed_data': SignedData,\n    'enveloped_data': EnvelopedData,\n    'signed_and_enveloped_data': SignedAndEnvelopedData,\n    'digested_data': DigestedData,\n    'encrypted_data': EncryptedData,\n    'authenticated_data': AuthenticatedData,\n    'compressed_data': CompressedData,\n    'authenticated_enveloped_data': AuthEnvelopedData,\n}\n\n\nEncapsulatedContentInfo._oid_specs = {\n    'signed_data': SignedData,\n    'enveloped_data': EnvelopedData,\n    'signed_and_enveloped_data': SignedAndEnvelopedData,\n    'digested_data': DigestedData,\n    'encrypted_data': EncryptedData,\n    'authenticated_data': AuthenticatedData,\n    'compressed_data': CompressedData,\n    'authenticated_enveloped_data': AuthEnvelopedData,\n}\n\n\nCMSAttribute._oid_specs = {\n    'content_type': SetOfContentType,\n    'message_digest': SetOfOctetString,\n    'signing_time': SetOfTime,\n    'counter_signature': SignerInfos,\n    'signature_time_stamp_token': SetOfContentInfo,\n    'cms_algorithm_protection': SetOfCMSAlgorithmProtection,\n    'microsoft_nested_signature': SetOfContentInfo,\n    'microsoft_time_stamp_token': SetOfContentInfo,\n    'encrypt_key_pref': SMIMEEncryptionKeyPreferences,\n    'smime_capabilities': SetOfSMIMECapabilites,\n}\n", "asn1crypto/util.py": "# coding: utf-8\n\n\"\"\"\nMiscellaneous data helpers, including functions for converting integers to and\nfrom bytes and UTC timezone. Exports the following items:\n\n - OrderedDict()\n - int_from_bytes()\n - int_to_bytes()\n - timezone.utc\n - utc_with_dst\n - create_timezone()\n - inet_ntop()\n - inet_pton()\n - uri_to_iri()\n - iri_to_uri()\n\"\"\"\n\nfrom __future__ import unicode_literals, division, absolute_import, print_function\n\nimport math\nimport sys\nfrom datetime import datetime, date, timedelta, tzinfo\n\nfrom ._errors import unwrap\nfrom ._iri import iri_to_uri, uri_to_iri  # noqa\nfrom ._ordereddict import OrderedDict  # noqa\nfrom ._types import type_name\n\nif sys.platform == 'win32':\n    from ._inet import inet_ntop, inet_pton\nelse:\n    from socket import inet_ntop, inet_pton  # noqa\n\n\n# Python 2\nif sys.version_info <= (3,):\n\n    def int_to_bytes(value, signed=False, width=None):\n        \"\"\"\n        Converts an integer to a byte string\n\n        :param value:\n            The integer to convert\n\n        :param signed:\n            If the byte string should be encoded using two's complement\n\n        :param width:\n            If None, the minimal possible size (but at least 1),\n            otherwise an integer of the byte width for the return value\n\n        :return:\n            A byte string\n        \"\"\"\n\n        if value == 0 and width == 0:\n            return b''\n\n        # Handle negatives in two's complement\n        is_neg = False\n        if signed and value < 0:\n            is_neg = True\n            bits = int(math.ceil(len('%x' % abs(value)) / 2.0) * 8)\n            value = (value + (1 << bits)) % (1 << bits)\n\n        hex_str = '%x' % value\n        if len(hex_str) & 1:\n            hex_str = '0' + hex_str\n\n        output = hex_str.decode('hex')\n\n        if signed and not is_neg and ord(output[0:1]) & 0x80:\n            output = b'\\x00' + output\n\n        if width is not None:\n            if len(output) > width:\n                raise OverflowError('int too big to convert')\n            if is_neg:\n                pad_char = b'\\xFF'\n            else:\n                pad_char = b'\\x00'\n            output = (pad_char * (width - len(output))) + output\n        elif is_neg and ord(output[0:1]) & 0x80 == 0:\n            output = b'\\xFF' + output\n\n        return output\n\n    def int_from_bytes(value, signed=False):\n        \"\"\"\n        Converts a byte string to an integer\n\n        :param value:\n            The byte string to convert\n\n        :param signed:\n            If the byte string should be interpreted using two's complement\n\n        :return:\n            An integer\n        \"\"\"\n\n        if value == b'':\n            return 0\n\n        num = long(value.encode(\"hex\"), 16)  # noqa\n\n        if not signed:\n            return num\n\n        # Check for sign bit and handle two's complement\n        if ord(value[0:1]) & 0x80:\n            bit_len = len(value) * 8\n            return num - (1 << bit_len)\n\n        return num\n\n    class timezone(tzinfo):  # noqa\n        \"\"\"\n        Implements datetime.timezone for py2.\n        Only full minute offsets are supported.\n        DST is not supported.\n        \"\"\"\n\n        def __init__(self, offset, name=None):\n            \"\"\"\n            :param offset:\n                A timedelta with this timezone's offset from UTC\n\n            :param name:\n                Name of the timezone; if None, generate one.\n            \"\"\"\n\n            if not timedelta(hours=-24) < offset < timedelta(hours=24):\n                raise ValueError('Offset must be in [-23:59, 23:59]')\n\n            if offset.seconds % 60 or offset.microseconds:\n                raise ValueError('Offset must be full minutes')\n\n            self._offset = offset\n\n            if name is not None:\n                self._name = name\n            elif not offset:\n                self._name = 'UTC'\n            else:\n                self._name = 'UTC' + _format_offset(offset)\n\n        def __eq__(self, other):\n            \"\"\"\n            Compare two timezones\n\n            :param other:\n                The other timezone to compare to\n\n            :return:\n                A boolean\n            \"\"\"\n\n            if type(other) != timezone:\n                return False\n            return self._offset == other._offset\n\n        def __getinitargs__(self):\n            \"\"\"\n            Called by tzinfo.__reduce__ to support pickle and copy.\n\n            :return:\n                offset and name, to be used for __init__\n            \"\"\"\n\n            return self._offset, self._name\n\n        def tzname(self, dt):\n            \"\"\"\n            :param dt:\n                A datetime object; ignored.\n\n            :return:\n                Name of this timezone\n            \"\"\"\n\n            return self._name\n\n        def utcoffset(self, dt):\n            \"\"\"\n            :param dt:\n                A datetime object; ignored.\n\n            :return:\n                A timedelta object with the offset from UTC\n            \"\"\"\n\n            return self._offset\n\n        def dst(self, dt):\n            \"\"\"\n            :param dt:\n                A datetime object; ignored.\n\n            :return:\n                Zero timedelta\n            \"\"\"\n\n            return timedelta(0)\n\n    timezone.utc = timezone(timedelta(0))\n\n# Python 3\nelse:\n\n    from datetime import timezone  # noqa\n\n    def int_to_bytes(value, signed=False, width=None):\n        \"\"\"\n        Converts an integer to a byte string\n\n        :param value:\n            The integer to convert\n\n        :param signed:\n            If the byte string should be encoded using two's complement\n\n        :param width:\n            If None, the minimal possible size (but at least 1),\n            otherwise an integer of the byte width for the return value\n\n        :return:\n            A byte string\n        \"\"\"\n\n        if width is None:\n            if signed:\n                if value < 0:\n                    bits_required = abs(value + 1).bit_length()\n                else:\n                    bits_required = value.bit_length()\n                if bits_required % 8 == 0:\n                    bits_required += 1\n            else:\n                bits_required = value.bit_length()\n            width = math.ceil(bits_required / 8) or 1\n        return value.to_bytes(width, byteorder='big', signed=signed)\n\n    def int_from_bytes(value, signed=False):\n        \"\"\"\n        Converts a byte string to an integer\n\n        :param value:\n            The byte string to convert\n\n        :param signed:\n            If the byte string should be interpreted using two's complement\n\n        :return:\n            An integer\n        \"\"\"\n\n        return int.from_bytes(value, 'big', signed=signed)\n\n\ndef _format_offset(off):\n    \"\"\"\n    Format a timedelta into \"[+-]HH:MM\" format or \"\" for None\n    \"\"\"\n\n    if off is None:\n        return ''\n    mins = off.days * 24 * 60 + off.seconds // 60\n    sign = '-' if mins < 0 else '+'\n    return sign + '%02d:%02d' % divmod(abs(mins), 60)\n\n\nclass _UtcWithDst(tzinfo):\n    \"\"\"\n    Utc class where dst does not return None; required for astimezone\n    \"\"\"\n\n    def tzname(self, dt):\n        return 'UTC'\n\n    def utcoffset(self, dt):\n        return timedelta(0)\n\n    def dst(self, dt):\n        return timedelta(0)\n\n\nutc_with_dst = _UtcWithDst()\n\n_timezone_cache = {}\n\n\ndef create_timezone(offset):\n    \"\"\"\n    Returns a new datetime.timezone object with the given offset.\n    Uses cached objects if possible.\n\n    :param offset:\n        A datetime.timedelta object; It needs to be in full minutes and between -23:59 and +23:59.\n\n    :return:\n        A datetime.timezone object\n    \"\"\"\n\n    try:\n        tz = _timezone_cache[offset]\n    except KeyError:\n        tz = _timezone_cache[offset] = timezone(offset)\n    return tz\n\n\nclass extended_date(object):\n    \"\"\"\n    A datetime.datetime-like object that represents the year 0. This is just\n    to handle 0000-01-01 found in some certificates. Python's datetime does\n    not support year 0.\n\n    The proleptic gregorian calendar repeats itself every 400 years. Therefore,\n    the simplest way to format is to substitute year 2000.\n    \"\"\"\n\n    def __init__(self, year, month, day):\n        \"\"\"\n        :param year:\n            The integer 0\n\n        :param month:\n            An integer from 1 to 12\n\n        :param day:\n            An integer from 1 to 31\n        \"\"\"\n\n        if year != 0:\n            raise ValueError('year must be 0')\n\n        self._y2k = date(2000, month, day)\n\n    @property\n    def year(self):\n        \"\"\"\n        :return:\n            The integer 0\n        \"\"\"\n\n        return 0\n\n    @property\n    def month(self):\n        \"\"\"\n        :return:\n            An integer from 1 to 12\n        \"\"\"\n\n        return self._y2k.month\n\n    @property\n    def day(self):\n        \"\"\"\n        :return:\n            An integer from 1 to 31\n        \"\"\"\n\n        return self._y2k.day\n\n    def strftime(self, format):\n        \"\"\"\n        Formats the date using strftime()\n\n        :param format:\n            A strftime() format string\n\n        :return:\n            A str, the formatted date as a unicode string\n            in Python 3 and a byte string in Python 2\n        \"\"\"\n\n        # Format the date twice, once with year 2000, once with year 4000.\n        # The only differences in the result will be in the millennium. Find them and replace by zeros.\n        y2k = self._y2k.strftime(format)\n        y4k = self._y2k.replace(year=4000).strftime(format)\n        return ''.join('0' if (c2, c4) == ('2', '4') else c2 for c2, c4 in zip(y2k, y4k))\n\n    def isoformat(self):\n        \"\"\"\n        Formats the date as %Y-%m-%d\n\n        :return:\n            The date formatted to %Y-%m-%d as a unicode string in Python 3\n            and a byte string in Python 2\n        \"\"\"\n\n        return self.strftime('0000-%m-%d')\n\n    def replace(self, year=None, month=None, day=None):\n        \"\"\"\n        Returns a new datetime.date or asn1crypto.util.extended_date\n        object with the specified components replaced\n\n        :return:\n            A datetime.date or asn1crypto.util.extended_date object\n        \"\"\"\n\n        if year is None:\n            year = self.year\n        if month is None:\n            month = self.month\n        if day is None:\n            day = self.day\n\n        if year > 0:\n            cls = date\n        else:\n            cls = extended_date\n\n        return cls(\n            year,\n            month,\n            day\n        )\n\n    def __str__(self):\n        \"\"\"\n        :return:\n            A str representing this extended_date, e.g. \"0000-01-01\"\n        \"\"\"\n\n        return self.strftime('%Y-%m-%d')\n\n    def __eq__(self, other):\n        \"\"\"\n        Compare two extended_date objects\n\n        :param other:\n            The other extended_date to compare to\n\n        :return:\n            A boolean\n        \"\"\"\n\n        # datetime.date object wouldn't compare equal because it can't be year 0\n        if not isinstance(other, self.__class__):\n            return False\n        return self.__cmp__(other) == 0\n\n    def __ne__(self, other):\n        \"\"\"\n        Compare two extended_date objects\n\n        :param other:\n            The other extended_date to compare to\n\n        :return:\n            A boolean\n        \"\"\"\n\n        return not self.__eq__(other)\n\n    def _comparison_error(self, other):\n        raise TypeError(unwrap(\n            '''\n            An asn1crypto.util.extended_date object can only be compared to\n            an asn1crypto.util.extended_date or datetime.date object, not %s\n            ''',\n            type_name(other)\n        ))\n\n    def __cmp__(self, other):\n        \"\"\"\n        Compare two extended_date or datetime.date objects\n\n        :param other:\n            The other extended_date object to compare to\n\n        :return:\n            An integer smaller than, equal to, or larger than 0\n        \"\"\"\n\n        # self is year 0, other is >= year 1\n        if isinstance(other, date):\n            return -1\n\n        if not isinstance(other, self.__class__):\n            self._comparison_error(other)\n\n        if self._y2k < other._y2k:\n            return -1\n        if self._y2k > other._y2k:\n            return 1\n        return 0\n\n    def __lt__(self, other):\n        return self.__cmp__(other) < 0\n\n    def __le__(self, other):\n        return self.__cmp__(other) <= 0\n\n    def __gt__(self, other):\n        return self.__cmp__(other) > 0\n\n    def __ge__(self, other):\n        return self.__cmp__(other) >= 0\n\n\nclass extended_datetime(object):\n    \"\"\"\n    A datetime.datetime-like object that represents the year 0. This is just\n    to handle 0000-01-01 found in some certificates. Python's datetime does\n    not support year 0.\n\n    The proleptic gregorian calendar repeats itself every 400 years. Therefore,\n    the simplest way to format is to substitute year 2000.\n    \"\"\"\n\n    # There are 97 leap days during 400 years.\n    DAYS_IN_400_YEARS = 400 * 365 + 97\n    DAYS_IN_2000_YEARS = 5 * DAYS_IN_400_YEARS\n\n    def __init__(self, year, *args, **kwargs):\n        \"\"\"\n        :param year:\n            The integer 0\n\n        :param args:\n            Other positional arguments; see datetime.datetime.\n\n        :param kwargs:\n            Other keyword arguments; see datetime.datetime.\n        \"\"\"\n\n        if year != 0:\n            raise ValueError('year must be 0')\n\n        self._y2k = datetime(2000, *args, **kwargs)\n\n    @property\n    def year(self):\n        \"\"\"\n        :return:\n            The integer 0\n        \"\"\"\n\n        return 0\n\n    @property\n    def month(self):\n        \"\"\"\n        :return:\n            An integer from 1 to 12\n        \"\"\"\n\n        return self._y2k.month\n\n    @property\n    def day(self):\n        \"\"\"\n        :return:\n            An integer from 1 to 31\n        \"\"\"\n\n        return self._y2k.day\n\n    @property\n    def hour(self):\n        \"\"\"\n        :return:\n            An integer from 1 to 24\n        \"\"\"\n\n        return self._y2k.hour\n\n    @property\n    def minute(self):\n        \"\"\"\n        :return:\n            An integer from 1 to 60\n        \"\"\"\n\n        return self._y2k.minute\n\n    @property\n    def second(self):\n        \"\"\"\n        :return:\n            An integer from 1 to 60\n        \"\"\"\n\n        return self._y2k.second\n\n    @property\n    def microsecond(self):\n        \"\"\"\n        :return:\n            An integer from 0 to 999999\n        \"\"\"\n\n        return self._y2k.microsecond\n\n    @property\n    def tzinfo(self):\n        \"\"\"\n        :return:\n            If object is timezone aware, a datetime.tzinfo object, else None.\n        \"\"\"\n\n        return self._y2k.tzinfo\n\n    def utcoffset(self):\n        \"\"\"\n        :return:\n            If object is timezone aware, a datetime.timedelta object, else None.\n        \"\"\"\n\n        return self._y2k.utcoffset()\n\n    def time(self):\n        \"\"\"\n        :return:\n            A datetime.time object\n        \"\"\"\n\n        return self._y2k.time()\n\n    def date(self):\n        \"\"\"\n        :return:\n            An asn1crypto.util.extended_date of the date\n        \"\"\"\n\n        return extended_date(0, self.month, self.day)\n\n    def strftime(self, format):\n        \"\"\"\n        Performs strftime(), always returning a str\n\n        :param format:\n            A strftime() format string\n\n        :return:\n            A str of the formatted datetime\n        \"\"\"\n\n        # Format the datetime twice, once with year 2000, once with year 4000.\n        # The only differences in the result will be in the millennium. Find them and replace by zeros.\n        y2k = self._y2k.strftime(format)\n        y4k = self._y2k.replace(year=4000).strftime(format)\n        return ''.join('0' if (c2, c4) == ('2', '4') else c2 for c2, c4 in zip(y2k, y4k))\n\n    def isoformat(self, sep='T'):\n        \"\"\"\n        Formats the date as \"%Y-%m-%d %H:%M:%S\" with the sep param between the\n        date and time portions\n\n        :param set:\n            A single character of the separator to place between the date and\n            time\n\n        :return:\n            The formatted datetime as a unicode string in Python 3 and a byte\n            string in Python 2\n        \"\"\"\n\n        s = '0000-%02d-%02d%c%02d:%02d:%02d' % (self.month, self.day, sep, self.hour, self.minute, self.second)\n        if self.microsecond:\n            s += '.%06d' % self.microsecond\n        return s + _format_offset(self.utcoffset())\n\n    def replace(self, year=None, *args, **kwargs):\n        \"\"\"\n        Returns a new datetime.datetime or asn1crypto.util.extended_datetime\n        object with the specified components replaced\n\n        :param year:\n            The new year to substitute. None to keep it.\n\n        :param args:\n            Other positional arguments; see datetime.datetime.replace.\n\n        :param kwargs:\n            Other keyword arguments; see datetime.datetime.replace.\n\n        :return:\n            A datetime.datetime or asn1crypto.util.extended_datetime object\n        \"\"\"\n\n        if year:\n            return self._y2k.replace(year, *args, **kwargs)\n\n        return extended_datetime.from_y2k(self._y2k.replace(2000, *args, **kwargs))\n\n    def astimezone(self, tz):\n        \"\"\"\n        Convert this extended_datetime to another timezone.\n\n        :param tz:\n            A datetime.tzinfo object.\n\n        :return:\n            A new extended_datetime or datetime.datetime object\n        \"\"\"\n\n        return extended_datetime.from_y2k(self._y2k.astimezone(tz))\n\n    def timestamp(self):\n        \"\"\"\n        Return POSIX timestamp. Only supported in python >= 3.3\n\n        :return:\n            A float representing the seconds since 1970-01-01 UTC. This will be a negative value.\n        \"\"\"\n\n        return self._y2k.timestamp() - self.DAYS_IN_2000_YEARS * 86400\n\n    def __str__(self):\n        \"\"\"\n        :return:\n            A str representing this extended_datetime, e.g. \"0000-01-01 00:00:00.000001-10:00\"\n        \"\"\"\n\n        return self.isoformat(sep=' ')\n\n    def __eq__(self, other):\n        \"\"\"\n        Compare two extended_datetime objects\n\n        :param other:\n            The other extended_datetime to compare to\n\n        :return:\n            A boolean\n        \"\"\"\n\n        # Only compare against other datetime or extended_datetime objects\n        if not isinstance(other, (self.__class__, datetime)):\n            return False\n\n        # Offset-naive and offset-aware datetimes are never the same\n        if (self.tzinfo is None) != (other.tzinfo is None):\n            return False\n\n        return self.__cmp__(other) == 0\n\n    def __ne__(self, other):\n        \"\"\"\n        Compare two extended_datetime objects\n\n        :param other:\n            The other extended_datetime to compare to\n\n        :return:\n            A boolean\n        \"\"\"\n\n        return not self.__eq__(other)\n\n    def _comparison_error(self, other):\n        \"\"\"\n        Raises a TypeError about the other object not being suitable for\n        comparison\n\n        :param other:\n            The object being compared to\n        \"\"\"\n\n        raise TypeError(unwrap(\n            '''\n            An asn1crypto.util.extended_datetime object can only be compared to\n            an asn1crypto.util.extended_datetime or datetime.datetime object,\n            not %s\n            ''',\n            type_name(other)\n        ))\n\n    def __cmp__(self, other):\n        \"\"\"\n        Compare two extended_datetime or datetime.datetime objects\n\n        :param other:\n            The other extended_datetime or datetime.datetime object to compare to\n\n        :return:\n            An integer smaller than, equal to, or larger than 0\n        \"\"\"\n\n        if not isinstance(other, (self.__class__, datetime)):\n            self._comparison_error(other)\n\n        if (self.tzinfo is None) != (other.tzinfo is None):\n            raise TypeError(\"can't compare offset-naive and offset-aware datetimes\")\n\n        diff = self - other\n        zero = timedelta(0)\n        if diff < zero:\n            return -1\n        if diff > zero:\n            return 1\n        return 0\n\n    def __lt__(self, other):\n        return self.__cmp__(other) < 0\n\n    def __le__(self, other):\n        return self.__cmp__(other) <= 0\n\n    def __gt__(self, other):\n        return self.__cmp__(other) > 0\n\n    def __ge__(self, other):\n        return self.__cmp__(other) >= 0\n\n    def __add__(self, other):\n        \"\"\"\n        Adds a timedelta\n\n        :param other:\n            A datetime.timedelta object to add.\n\n        :return:\n            A new extended_datetime or datetime.datetime object.\n        \"\"\"\n\n        return extended_datetime.from_y2k(self._y2k + other)\n\n    def __sub__(self, other):\n        \"\"\"\n        Subtracts a timedelta or another datetime.\n\n        :param other:\n            A datetime.timedelta or datetime.datetime or extended_datetime object to subtract.\n\n        :return:\n            If a timedelta is passed, a new extended_datetime or datetime.datetime object.\n            Else a datetime.timedelta object.\n        \"\"\"\n\n        if isinstance(other, timedelta):\n            return extended_datetime.from_y2k(self._y2k - other)\n\n        if isinstance(other, extended_datetime):\n            return self._y2k - other._y2k\n\n        if isinstance(other, datetime):\n            return self._y2k - other - timedelta(days=self.DAYS_IN_2000_YEARS)\n\n        return NotImplemented\n\n    def __rsub__(self, other):\n        return -(self - other)\n\n    @classmethod\n    def from_y2k(cls, value):\n        \"\"\"\n        Revert substitution of year 2000.\n\n        :param value:\n            A datetime.datetime object which is 2000 years in the future.\n        :return:\n            A new extended_datetime or datetime.datetime object.\n        \"\"\"\n\n        year = value.year - 2000\n\n        if year > 0:\n            new_cls = datetime\n        else:\n            new_cls = cls\n\n        return new_cls(\n            year,\n            value.month,\n            value.day,\n            value.hour,\n            value.minute,\n            value.second,\n            value.microsecond,\n            value.tzinfo\n        )\n", "asn1crypto/pkcs12.py": "# coding: utf-8\n\n\"\"\"\nASN.1 type classes for PKCS#12 files. Exports the following items:\n\n - CertBag()\n - CrlBag()\n - Pfx()\n - SafeBag()\n - SecretBag()\n\nOther type classes are defined that help compose the types listed above.\n\"\"\"\n\nfrom __future__ import unicode_literals, division, absolute_import, print_function\n\nfrom .algos import DigestInfo\nfrom .cms import ContentInfo, SignedData\nfrom .core import (\n    Any,\n    BMPString,\n    Integer,\n    ObjectIdentifier,\n    OctetString,\n    ParsableOctetString,\n    Sequence,\n    SequenceOf,\n    SetOf,\n)\nfrom .keys import PrivateKeyInfo, EncryptedPrivateKeyInfo\nfrom .x509 import Certificate, KeyPurposeId\n\n\n# The structures in this file are taken from https://tools.ietf.org/html/rfc7292\n\nclass MacData(Sequence):\n    _fields = [\n        ('mac', DigestInfo),\n        ('mac_salt', OctetString),\n        ('iterations', Integer, {'default': 1}),\n    ]\n\n\nclass Version(Integer):\n    _map = {\n        3: 'v3'\n    }\n\n\nclass AttributeType(ObjectIdentifier):\n    _map = {\n        # https://tools.ietf.org/html/rfc2985#page-18\n        '1.2.840.113549.1.9.20': 'friendly_name',\n        '1.2.840.113549.1.9.21': 'local_key_id',\n        # https://support.microsoft.com/en-us/kb/287547\n        '1.3.6.1.4.1.311.17.1': 'microsoft_local_machine_keyset',\n        # https://github.com/frohoff/jdk8u-dev-jdk/blob/master/src/share/classes/sun/security/pkcs12/PKCS12KeyStore.java\n        # this is a set of OIDs, representing key usage, the usual value is a SET of one element OID 2.5.29.37.0\n        '2.16.840.1.113894.746875.1.1': 'trusted_key_usage',\n    }\n\n\nclass SetOfAny(SetOf):\n    _child_spec = Any\n\n\nclass SetOfBMPString(SetOf):\n    _child_spec = BMPString\n\n\nclass SetOfOctetString(SetOf):\n    _child_spec = OctetString\n\n\nclass SetOfKeyPurposeId(SetOf):\n    _child_spec = KeyPurposeId\n\n\nclass Attribute(Sequence):\n    _fields = [\n        ('type', AttributeType),\n        ('values', None),\n    ]\n\n    _oid_specs = {\n        'friendly_name': SetOfBMPString,\n        'local_key_id': SetOfOctetString,\n        'microsoft_csp_name': SetOfBMPString,\n        'trusted_key_usage': SetOfKeyPurposeId,\n    }\n\n    def _values_spec(self):\n        return self._oid_specs.get(self['type'].native, SetOfAny)\n\n    _spec_callbacks = {\n        'values': _values_spec\n    }\n\n\nclass Attributes(SetOf):\n    _child_spec = Attribute\n\n\nclass Pfx(Sequence):\n    _fields = [\n        ('version', Version),\n        ('auth_safe', ContentInfo),\n        ('mac_data', MacData, {'optional': True})\n    ]\n\n    _authenticated_safe = None\n\n    @property\n    def authenticated_safe(self):\n        if self._authenticated_safe is None:\n            content = self['auth_safe']['content']\n            if isinstance(content, SignedData):\n                content = content['content_info']['content']\n            self._authenticated_safe = AuthenticatedSafe.load(content.native)\n        return self._authenticated_safe\n\n\nclass AuthenticatedSafe(SequenceOf):\n    _child_spec = ContentInfo\n\n\nclass BagId(ObjectIdentifier):\n    _map = {\n        '1.2.840.113549.1.12.10.1.1': 'key_bag',\n        '1.2.840.113549.1.12.10.1.2': 'pkcs8_shrouded_key_bag',\n        '1.2.840.113549.1.12.10.1.3': 'cert_bag',\n        '1.2.840.113549.1.12.10.1.4': 'crl_bag',\n        '1.2.840.113549.1.12.10.1.5': 'secret_bag',\n        '1.2.840.113549.1.12.10.1.6': 'safe_contents',\n    }\n\n\nclass CertId(ObjectIdentifier):\n    _map = {\n        '1.2.840.113549.1.9.22.1': 'x509',\n        '1.2.840.113549.1.9.22.2': 'sdsi',\n    }\n\n\nclass CertBag(Sequence):\n    _fields = [\n        ('cert_id', CertId),\n        ('cert_value', ParsableOctetString, {'explicit': 0}),\n    ]\n\n    _oid_pair = ('cert_id', 'cert_value')\n    _oid_specs = {\n        'x509': Certificate,\n    }\n\n\nclass CrlBag(Sequence):\n    _fields = [\n        ('crl_id', ObjectIdentifier),\n        ('crl_value', OctetString, {'explicit': 0}),\n    ]\n\n\nclass SecretBag(Sequence):\n    _fields = [\n        ('secret_type_id', ObjectIdentifier),\n        ('secret_value', OctetString, {'explicit': 0}),\n    ]\n\n\nclass SafeContents(SequenceOf):\n    pass\n\n\nclass SafeBag(Sequence):\n    _fields = [\n        ('bag_id', BagId),\n        ('bag_value', Any, {'explicit': 0}),\n        ('bag_attributes', Attributes, {'optional': True}),\n    ]\n\n    _oid_pair = ('bag_id', 'bag_value')\n    _oid_specs = {\n        'key_bag': PrivateKeyInfo,\n        'pkcs8_shrouded_key_bag': EncryptedPrivateKeyInfo,\n        'cert_bag': CertBag,\n        'crl_bag': CrlBag,\n        'secret_bag': SecretBag,\n        'safe_contents': SafeContents\n    }\n\n\nSafeContents._child_spec = SafeBag\n", "asn1crypto/_teletex_codec.py": "# coding: utf-8\n\n\"\"\"\nImplementation of the teletex T.61 codec. Exports the following items:\n\n - register()\n\"\"\"\n\nfrom __future__ import unicode_literals, division, absolute_import, print_function\n\nimport codecs\n\n\nclass TeletexCodec(codecs.Codec):\n\n    def encode(self, input_, errors='strict'):\n        return codecs.charmap_encode(input_, errors, ENCODING_TABLE)\n\n    def decode(self, input_, errors='strict'):\n        return codecs.charmap_decode(input_, errors, DECODING_TABLE)\n\n\nclass TeletexIncrementalEncoder(codecs.IncrementalEncoder):\n\n    def encode(self, input_, final=False):\n        return codecs.charmap_encode(input_, self.errors, ENCODING_TABLE)[0]\n\n\nclass TeletexIncrementalDecoder(codecs.IncrementalDecoder):\n\n    def decode(self, input_, final=False):\n        return codecs.charmap_decode(input_, self.errors, DECODING_TABLE)[0]\n\n\nclass TeletexStreamWriter(TeletexCodec, codecs.StreamWriter):\n\n    pass\n\n\nclass TeletexStreamReader(TeletexCodec, codecs.StreamReader):\n\n    pass\n\n\ndef teletex_search_function(name):\n    \"\"\"\n    Search function for teletex codec that is passed to codecs.register()\n    \"\"\"\n\n    if name != 'teletex':\n        return None\n\n    return codecs.CodecInfo(\n        name='teletex',\n        encode=TeletexCodec().encode,\n        decode=TeletexCodec().decode,\n        incrementalencoder=TeletexIncrementalEncoder,\n        incrementaldecoder=TeletexIncrementalDecoder,\n        streamreader=TeletexStreamReader,\n        streamwriter=TeletexStreamWriter,\n    )\n\n\ndef register():\n    \"\"\"\n    Registers the teletex codec\n    \"\"\"\n\n    codecs.register(teletex_search_function)\n\n\n# http://en.wikipedia.org/wiki/ITU_T.61\nDECODING_TABLE = (\n    '\\u0000'\n    '\\u0001'\n    '\\u0002'\n    '\\u0003'\n    '\\u0004'\n    '\\u0005'\n    '\\u0006'\n    '\\u0007'\n    '\\u0008'\n    '\\u0009'\n    '\\u000A'\n    '\\u000B'\n    '\\u000C'\n    '\\u000D'\n    '\\u000E'\n    '\\u000F'\n    '\\u0010'\n    '\\u0011'\n    '\\u0012'\n    '\\u0013'\n    '\\u0014'\n    '\\u0015'\n    '\\u0016'\n    '\\u0017'\n    '\\u0018'\n    '\\u0019'\n    '\\u001A'\n    '\\u001B'\n    '\\u001C'\n    '\\u001D'\n    '\\u001E'\n    '\\u001F'\n    '\\u0020'\n    '\\u0021'\n    '\\u0022'\n    '\\ufffe'\n    '\\ufffe'\n    '\\u0025'\n    '\\u0026'\n    '\\u0027'\n    '\\u0028'\n    '\\u0029'\n    '\\u002A'\n    '\\u002B'\n    '\\u002C'\n    '\\u002D'\n    '\\u002E'\n    '\\u002F'\n    '\\u0030'\n    '\\u0031'\n    '\\u0032'\n    '\\u0033'\n    '\\u0034'\n    '\\u0035'\n    '\\u0036'\n    '\\u0037'\n    '\\u0038'\n    '\\u0039'\n    '\\u003A'\n    '\\u003B'\n    '\\u003C'\n    '\\u003D'\n    '\\u003E'\n    '\\u003F'\n    '\\u0040'\n    '\\u0041'\n    '\\u0042'\n    '\\u0043'\n    '\\u0044'\n    '\\u0045'\n    '\\u0046'\n    '\\u0047'\n    '\\u0048'\n    '\\u0049'\n    '\\u004A'\n    '\\u004B'\n    '\\u004C'\n    '\\u004D'\n    '\\u004E'\n    '\\u004F'\n    '\\u0050'\n    '\\u0051'\n    '\\u0052'\n    '\\u0053'\n    '\\u0054'\n    '\\u0055'\n    '\\u0056'\n    '\\u0057'\n    '\\u0058'\n    '\\u0059'\n    '\\u005A'\n    '\\u005B'\n    '\\ufffe'\n    '\\u005D'\n    '\\ufffe'\n    '\\u005F'\n    '\\ufffe'\n    '\\u0061'\n    '\\u0062'\n    '\\u0063'\n    '\\u0064'\n    '\\u0065'\n    '\\u0066'\n    '\\u0067'\n    '\\u0068'\n    '\\u0069'\n    '\\u006A'\n    '\\u006B'\n    '\\u006C'\n    '\\u006D'\n    '\\u006E'\n    '\\u006F'\n    '\\u0070'\n    '\\u0071'\n    '\\u0072'\n    '\\u0073'\n    '\\u0074'\n    '\\u0075'\n    '\\u0076'\n    '\\u0077'\n    '\\u0078'\n    '\\u0079'\n    '\\u007A'\n    '\\ufffe'\n    '\\u007C'\n    '\\ufffe'\n    '\\ufffe'\n    '\\u007F'\n    '\\u0080'\n    '\\u0081'\n    '\\u0082'\n    '\\u0083'\n    '\\u0084'\n    '\\u0085'\n    '\\u0086'\n    '\\u0087'\n    '\\u0088'\n    '\\u0089'\n    '\\u008A'\n    '\\u008B'\n    '\\u008C'\n    '\\u008D'\n    '\\u008E'\n    '\\u008F'\n    '\\u0090'\n    '\\u0091'\n    '\\u0092'\n    '\\u0093'\n    '\\u0094'\n    '\\u0095'\n    '\\u0096'\n    '\\u0097'\n    '\\u0098'\n    '\\u0099'\n    '\\u009A'\n    '\\u009B'\n    '\\u009C'\n    '\\u009D'\n    '\\u009E'\n    '\\u009F'\n    '\\u00A0'\n    '\\u00A1'\n    '\\u00A2'\n    '\\u00A3'\n    '\\u0024'\n    '\\u00A5'\n    '\\u0023'\n    '\\u00A7'\n    '\\u00A4'\n    '\\ufffe'\n    '\\ufffe'\n    '\\u00AB'\n    '\\ufffe'\n    '\\ufffe'\n    '\\ufffe'\n    '\\ufffe'\n    '\\u00B0'\n    '\\u00B1'\n    '\\u00B2'\n    '\\u00B3'\n    '\\u00D7'\n    '\\u00B5'\n    '\\u00B6'\n    '\\u00B7'\n    '\\u00F7'\n    '\\ufffe'\n    '\\ufffe'\n    '\\u00BB'\n    '\\u00BC'\n    '\\u00BD'\n    '\\u00BE'\n    '\\u00BF'\n    '\\ufffe'\n    '\\u0300'\n    '\\u0301'\n    '\\u0302'\n    '\\u0303'\n    '\\u0304'\n    '\\u0306'\n    '\\u0307'\n    '\\u0308'\n    '\\ufffe'\n    '\\u030A'\n    '\\u0327'\n    '\\u0332'\n    '\\u030B'\n    '\\u0328'\n    '\\u030C'\n    '\\ufffe'\n    '\\ufffe'\n    '\\ufffe'\n    '\\ufffe'\n    '\\ufffe'\n    '\\ufffe'\n    '\\ufffe'\n    '\\ufffe'\n    '\\ufffe'\n    '\\ufffe'\n    '\\ufffe'\n    '\\ufffe'\n    '\\ufffe'\n    '\\ufffe'\n    '\\ufffe'\n    '\\ufffe'\n    '\\u2126'\n    '\\u00C6'\n    '\\u00D0'\n    '\\u00AA'\n    '\\u0126'\n    '\\ufffe'\n    '\\u0132'\n    '\\u013F'\n    '\\u0141'\n    '\\u00D8'\n    '\\u0152'\n    '\\u00BA'\n    '\\u00DE'\n    '\\u0166'\n    '\\u014A'\n    '\\u0149'\n    '\\u0138'\n    '\\u00E6'\n    '\\u0111'\n    '\\u00F0'\n    '\\u0127'\n    '\\u0131'\n    '\\u0133'\n    '\\u0140'\n    '\\u0142'\n    '\\u00F8'\n    '\\u0153'\n    '\\u00DF'\n    '\\u00FE'\n    '\\u0167'\n    '\\u014B'\n    '\\ufffe'\n)\nENCODING_TABLE = codecs.charmap_build(DECODING_TABLE)\n", "asn1crypto/_int.py": "# coding: utf-8\nfrom __future__ import unicode_literals, division, absolute_import, print_function\n\n\ndef fill_width(bytes_, width):\n    \"\"\"\n    Ensure a byte string representing a positive integer is a specific width\n    (in bytes)\n\n    :param bytes_:\n        The integer byte string\n\n    :param width:\n        The desired width as an integer\n\n    :return:\n        A byte string of the width specified\n    \"\"\"\n\n    while len(bytes_) < width:\n        bytes_ = b'\\x00' + bytes_\n    return bytes_\n", "asn1crypto/csr.py": "# coding: utf-8\n\n\"\"\"\nASN.1 type classes for certificate signing requests (CSR). Exports the\nfollowing items:\n\n - CertificationRequest()\n\nOther type classes are defined that help compose the types listed above.\n\"\"\"\n\nfrom __future__ import unicode_literals, division, absolute_import, print_function\n\nfrom .algos import SignedDigestAlgorithm\nfrom .core import (\n    Any,\n    BitString,\n    BMPString,\n    Integer,\n    ObjectIdentifier,\n    OctetBitString,\n    Sequence,\n    SetOf,\n    UTF8String\n)\nfrom .keys import PublicKeyInfo\nfrom .x509 import DirectoryString, Extensions, Name\n\n\n# The structures in this file are taken from https://tools.ietf.org/html/rfc2986\n# and https://tools.ietf.org/html/rfc2985\n\n\nclass Version(Integer):\n    _map = {\n        0: 'v1',\n    }\n\n\nclass CSRAttributeType(ObjectIdentifier):\n    _map = {\n        '1.2.840.113549.1.9.7': 'challenge_password',\n        '1.2.840.113549.1.9.9': 'extended_certificate_attributes',\n        '1.2.840.113549.1.9.14': 'extension_request',\n        # https://docs.microsoft.com/en-us/openspecs/windows_protocols/ms-wcce/a5eaae36-e9f3-4dc5-a687-bfa7115954f1\n        '1.3.6.1.4.1.311.13.2.2': 'microsoft_enrollment_csp_provider',\n        # https://docs.microsoft.com/en-us/openspecs/windows_protocols/ms-wcce/7c677cba-030d-48be-ba2b-01e407705f34\n        '1.3.6.1.4.1.311.13.2.3': 'microsoft_os_version',\n        # https://docs.microsoft.com/en-us/openspecs/windows_protocols/ms-wcce/64e5ff6d-c6dd-4578-92f7-b3d895f9b9c7\n        '1.3.6.1.4.1.311.21.20': 'microsoft_request_client_info',\n    }\n\n\nclass SetOfDirectoryString(SetOf):\n    _child_spec = DirectoryString\n\n\nclass Attribute(Sequence):\n    _fields = [\n        ('type', ObjectIdentifier),\n        ('values', SetOf, {'spec': Any}),\n    ]\n\n\nclass SetOfAttributes(SetOf):\n    _child_spec = Attribute\n\n\nclass SetOfExtensions(SetOf):\n    _child_spec = Extensions\n\n\nclass MicrosoftEnrollmentCSProvider(Sequence):\n    _fields = [\n        ('keyspec', Integer),\n        ('cspname', BMPString),  # cryptographic service provider name\n        ('signature', BitString),\n    ]\n\n\nclass SetOfMicrosoftEnrollmentCSProvider(SetOf):\n    _child_spec = MicrosoftEnrollmentCSProvider\n\n\nclass MicrosoftRequestClientInfo(Sequence):\n    _fields = [\n        ('clientid', Integer),\n        ('machinename', UTF8String),\n        ('username', UTF8String),\n        ('processname', UTF8String),\n    ]\n\n\nclass SetOfMicrosoftRequestClientInfo(SetOf):\n    _child_spec = MicrosoftRequestClientInfo\n\n\nclass CRIAttribute(Sequence):\n    _fields = [\n        ('type', CSRAttributeType),\n        ('values', Any),\n    ]\n\n    _oid_pair = ('type', 'values')\n    _oid_specs = {\n        'challenge_password': SetOfDirectoryString,\n        'extended_certificate_attributes': SetOfAttributes,\n        'extension_request': SetOfExtensions,\n        'microsoft_enrollment_csp_provider': SetOfMicrosoftEnrollmentCSProvider,\n        'microsoft_os_version': SetOfDirectoryString,\n        'microsoft_request_client_info': SetOfMicrosoftRequestClientInfo,\n    }\n\n\nclass CRIAttributes(SetOf):\n    _child_spec = CRIAttribute\n\n\nclass CertificationRequestInfo(Sequence):\n    _fields = [\n        ('version', Version),\n        ('subject', Name),\n        ('subject_pk_info', PublicKeyInfo),\n        ('attributes', CRIAttributes, {'implicit': 0, 'optional': True}),\n    ]\n\n\nclass CertificationRequest(Sequence):\n    _fields = [\n        ('certification_request_info', CertificationRequestInfo),\n        ('signature_algorithm', SignedDigestAlgorithm),\n        ('signature', OctetBitString),\n    ]\n", "asn1crypto/tsp.py": "# coding: utf-8\n\n\"\"\"\nASN.1 type classes for the time stamp protocol (TSP). Exports the following\nitems:\n\n - TimeStampReq()\n - TimeStampResp()\n\nAlso adds TimeStampedData() support to asn1crypto.cms.ContentInfo(),\nTimeStampedData() and TSTInfo() support to\nasn1crypto.cms.EncapsulatedContentInfo() and some oids and value parsers to\nasn1crypto.cms.CMSAttribute().\n\nOther type classes are defined that help compose the types listed above.\n\"\"\"\n\nfrom __future__ import unicode_literals, division, absolute_import, print_function\n\nfrom .algos import DigestAlgorithm\nfrom .cms import (\n    CMSAttribute,\n    CMSAttributeType,\n    ContentInfo,\n    ContentType,\n    EncapsulatedContentInfo,\n)\nfrom .core import (\n    Any,\n    BitString,\n    Boolean,\n    Choice,\n    GeneralizedTime,\n    IA5String,\n    Integer,\n    ObjectIdentifier,\n    OctetString,\n    Sequence,\n    SequenceOf,\n    SetOf,\n    UTF8String,\n)\nfrom .crl import CertificateList\nfrom .x509 import (\n    Attributes,\n    CertificatePolicies,\n    GeneralName,\n    GeneralNames,\n)\n\n\n# The structures in this file are based on https://tools.ietf.org/html/rfc3161,\n# https://tools.ietf.org/html/rfc4998, https://tools.ietf.org/html/rfc5544,\n# https://tools.ietf.org/html/rfc5035, https://tools.ietf.org/html/rfc2634\n\nclass Version(Integer):\n    _map = {\n        0: 'v0',\n        1: 'v1',\n        2: 'v2',\n        3: 'v3',\n        4: 'v4',\n        5: 'v5',\n    }\n\n\nclass MessageImprint(Sequence):\n    _fields = [\n        ('hash_algorithm', DigestAlgorithm),\n        ('hashed_message', OctetString),\n    ]\n\n\nclass Accuracy(Sequence):\n    _fields = [\n        ('seconds', Integer, {'optional': True}),\n        ('millis', Integer, {'implicit': 0, 'optional': True}),\n        ('micros', Integer, {'implicit': 1, 'optional': True}),\n    ]\n\n\nclass Extension(Sequence):\n    _fields = [\n        ('extn_id', ObjectIdentifier),\n        ('critical', Boolean, {'default': False}),\n        ('extn_value', OctetString),\n    ]\n\n\nclass Extensions(SequenceOf):\n    _child_spec = Extension\n\n\nclass TSTInfo(Sequence):\n    _fields = [\n        ('version', Version),\n        ('policy', ObjectIdentifier),\n        ('message_imprint', MessageImprint),\n        ('serial_number', Integer),\n        ('gen_time', GeneralizedTime),\n        ('accuracy', Accuracy, {'optional': True}),\n        ('ordering', Boolean, {'default': False}),\n        ('nonce', Integer, {'optional': True}),\n        ('tsa', GeneralName, {'explicit': 0, 'optional': True}),\n        ('extensions', Extensions, {'implicit': 1, 'optional': True}),\n    ]\n\n\nclass TimeStampReq(Sequence):\n    _fields = [\n        ('version', Version),\n        ('message_imprint', MessageImprint),\n        ('req_policy', ObjectIdentifier, {'optional': True}),\n        ('nonce', Integer, {'optional': True}),\n        ('cert_req', Boolean, {'default': False}),\n        ('extensions', Extensions, {'implicit': 0, 'optional': True}),\n    ]\n\n\nclass PKIStatus(Integer):\n    _map = {\n        0: 'granted',\n        1: 'granted_with_mods',\n        2: 'rejection',\n        3: 'waiting',\n        4: 'revocation_warning',\n        5: 'revocation_notification',\n    }\n\n\nclass PKIFreeText(SequenceOf):\n    _child_spec = UTF8String\n\n\nclass PKIFailureInfo(BitString):\n    _map = {\n        0: 'bad_alg',\n        2: 'bad_request',\n        5: 'bad_data_format',\n        14: 'time_not_available',\n        15: 'unaccepted_policy',\n        16: 'unaccepted_extensions',\n        17: 'add_info_not_available',\n        25: 'system_failure',\n    }\n\n\nclass PKIStatusInfo(Sequence):\n    _fields = [\n        ('status', PKIStatus),\n        ('status_string', PKIFreeText, {'optional': True}),\n        ('fail_info', PKIFailureInfo, {'optional': True}),\n    ]\n\n\nclass TimeStampResp(Sequence):\n    _fields = [\n        ('status', PKIStatusInfo),\n        ('time_stamp_token', ContentInfo),\n    ]\n\n\nclass MetaData(Sequence):\n    _fields = [\n        ('hash_protected', Boolean),\n        ('file_name', UTF8String, {'optional': True}),\n        ('media_type', IA5String, {'optional': True}),\n        ('other_meta_data', Attributes, {'optional': True}),\n    ]\n\n\nclass TimeStampAndCRL(Sequence):\n    _fields = [\n        ('time_stamp', EncapsulatedContentInfo),\n        ('crl', CertificateList, {'optional': True}),\n    ]\n\n\nclass TimeStampTokenEvidence(SequenceOf):\n    _child_spec = TimeStampAndCRL\n\n\nclass DigestAlgorithms(SequenceOf):\n    _child_spec = DigestAlgorithm\n\n\nclass EncryptionInfo(Sequence):\n    _fields = [\n        ('encryption_info_type', ObjectIdentifier),\n        ('encryption_info_value', Any),\n    ]\n\n\nclass PartialHashtree(SequenceOf):\n    _child_spec = OctetString\n\n\nclass PartialHashtrees(SequenceOf):\n    _child_spec = PartialHashtree\n\n\nclass ArchiveTimeStamp(Sequence):\n    _fields = [\n        ('digest_algorithm', DigestAlgorithm, {'implicit': 0, 'optional': True}),\n        ('attributes', Attributes, {'implicit': 1, 'optional': True}),\n        ('reduced_hashtree', PartialHashtrees, {'implicit': 2, 'optional': True}),\n        ('time_stamp', ContentInfo),\n    ]\n\n\nclass ArchiveTimeStampSequence(SequenceOf):\n    _child_spec = ArchiveTimeStamp\n\n\nclass EvidenceRecord(Sequence):\n    _fields = [\n        ('version', Version),\n        ('digest_algorithms', DigestAlgorithms),\n        ('crypto_infos', Attributes, {'implicit': 0, 'optional': True}),\n        ('encryption_info', EncryptionInfo, {'implicit': 1, 'optional': True}),\n        ('archive_time_stamp_sequence', ArchiveTimeStampSequence),\n    ]\n\n\nclass OtherEvidence(Sequence):\n    _fields = [\n        ('oe_type', ObjectIdentifier),\n        ('oe_value', Any),\n    ]\n\n\nclass Evidence(Choice):\n    _alternatives = [\n        ('tst_evidence', TimeStampTokenEvidence, {'implicit': 0}),\n        ('ers_evidence', EvidenceRecord, {'implicit': 1}),\n        ('other_evidence', OtherEvidence, {'implicit': 2}),\n    ]\n\n\nclass TimeStampedData(Sequence):\n    _fields = [\n        ('version', Version),\n        ('data_uri', IA5String, {'optional': True}),\n        ('meta_data', MetaData, {'optional': True}),\n        ('content', OctetString, {'optional': True}),\n        ('temporal_evidence', Evidence),\n    ]\n\n\nclass IssuerSerial(Sequence):\n    _fields = [\n        ('issuer', GeneralNames),\n        ('serial_number', Integer),\n    ]\n\n\nclass ESSCertID(Sequence):\n    _fields = [\n        ('cert_hash', OctetString),\n        ('issuer_serial', IssuerSerial, {'optional': True}),\n    ]\n\n\nclass ESSCertIDs(SequenceOf):\n    _child_spec = ESSCertID\n\n\nclass SigningCertificate(Sequence):\n    _fields = [\n        ('certs', ESSCertIDs),\n        ('policies', CertificatePolicies, {'optional': True}),\n    ]\n\n\nclass SetOfSigningCertificates(SetOf):\n    _child_spec = SigningCertificate\n\n\nclass ESSCertIDv2(Sequence):\n    _fields = [\n        ('hash_algorithm', DigestAlgorithm, {'default': {'algorithm': 'sha256'}}),\n        ('cert_hash', OctetString),\n        ('issuer_serial', IssuerSerial, {'optional': True}),\n    ]\n\n\nclass ESSCertIDv2s(SequenceOf):\n    _child_spec = ESSCertIDv2\n\n\nclass SigningCertificateV2(Sequence):\n    _fields = [\n        ('certs', ESSCertIDv2s),\n        ('policies', CertificatePolicies, {'optional': True}),\n    ]\n\n\nclass SetOfSigningCertificatesV2(SetOf):\n    _child_spec = SigningCertificateV2\n\n\nEncapsulatedContentInfo._oid_specs['tst_info'] = TSTInfo\nEncapsulatedContentInfo._oid_specs['timestamped_data'] = TimeStampedData\nContentInfo._oid_specs['timestamped_data'] = TimeStampedData\nContentType._map['1.2.840.113549.1.9.16.1.4'] = 'tst_info'\nContentType._map['1.2.840.113549.1.9.16.1.31'] = 'timestamped_data'\nCMSAttributeType._map['1.2.840.113549.1.9.16.2.12'] = 'signing_certificate'\nCMSAttribute._oid_specs['signing_certificate'] = SetOfSigningCertificates\nCMSAttributeType._map['1.2.840.113549.1.9.16.2.47'] = 'signing_certificate_v2'\nCMSAttribute._oid_specs['signing_certificate_v2'] = SetOfSigningCertificatesV2\n", "asn1crypto/ocsp.py": "# coding: utf-8\n\n\"\"\"\nASN.1 type classes for the online certificate status protocol (OCSP). Exports\nthe following items:\n\n - OCSPRequest()\n - OCSPResponse()\n\nOther type classes are defined that help compose the types listed above.\n\"\"\"\n\nfrom __future__ import unicode_literals, division, absolute_import, print_function\n\nfrom ._errors import unwrap\nfrom .algos import DigestAlgorithm, SignedDigestAlgorithm\nfrom .core import (\n    Boolean,\n    Choice,\n    Enumerated,\n    GeneralizedTime,\n    IA5String,\n    Integer,\n    Null,\n    ObjectIdentifier,\n    OctetBitString,\n    OctetString,\n    ParsableOctetString,\n    Sequence,\n    SequenceOf,\n)\nfrom .crl import AuthorityInfoAccessSyntax, CRLReason\nfrom .keys import PublicKeyAlgorithm\nfrom .x509 import Certificate, GeneralName, GeneralNames, Name\n\n\n# The structures in this file are taken from https://tools.ietf.org/html/rfc6960\n\n\nclass Version(Integer):\n    _map = {\n        0: 'v1'\n    }\n\n\nclass CertId(Sequence):\n    _fields = [\n        ('hash_algorithm', DigestAlgorithm),\n        ('issuer_name_hash', OctetString),\n        ('issuer_key_hash', OctetString),\n        ('serial_number', Integer),\n    ]\n\n\nclass ServiceLocator(Sequence):\n    _fields = [\n        ('issuer', Name),\n        ('locator', AuthorityInfoAccessSyntax),\n    ]\n\n\nclass RequestExtensionId(ObjectIdentifier):\n    _map = {\n        '1.3.6.1.5.5.7.48.1.7': 'service_locator',\n    }\n\n\nclass RequestExtension(Sequence):\n    _fields = [\n        ('extn_id', RequestExtensionId),\n        ('critical', Boolean, {'default': False}),\n        ('extn_value', ParsableOctetString),\n    ]\n\n    _oid_pair = ('extn_id', 'extn_value')\n    _oid_specs = {\n        'service_locator': ServiceLocator,\n    }\n\n\nclass RequestExtensions(SequenceOf):\n    _child_spec = RequestExtension\n\n\nclass Request(Sequence):\n    _fields = [\n        ('req_cert', CertId),\n        ('single_request_extensions', RequestExtensions, {'explicit': 0, 'optional': True}),\n    ]\n\n    _processed_extensions = False\n    _critical_extensions = None\n    _service_locator_value = None\n\n    def _set_extensions(self):\n        \"\"\"\n        Sets common named extensions to private attributes and creates a list\n        of critical extensions\n        \"\"\"\n\n        self._critical_extensions = set()\n\n        for extension in self['single_request_extensions']:\n            name = extension['extn_id'].native\n            attribute_name = '_%s_value' % name\n            if hasattr(self, attribute_name):\n                setattr(self, attribute_name, extension['extn_value'].parsed)\n            if extension['critical'].native:\n                self._critical_extensions.add(name)\n\n        self._processed_extensions = True\n\n    @property\n    def critical_extensions(self):\n        \"\"\"\n        Returns a set of the names (or OID if not a known extension) of the\n        extensions marked as critical\n\n        :return:\n            A set of unicode strings\n        \"\"\"\n\n        if not self._processed_extensions:\n            self._set_extensions()\n        return self._critical_extensions\n\n    @property\n    def service_locator_value(self):\n        \"\"\"\n        This extension is used when communicating with an OCSP responder that\n        acts as a proxy for OCSP requests\n\n        :return:\n            None or a ServiceLocator object\n        \"\"\"\n\n        if self._processed_extensions is False:\n            self._set_extensions()\n        return self._service_locator_value\n\n\nclass Requests(SequenceOf):\n    _child_spec = Request\n\n\nclass ResponseType(ObjectIdentifier):\n    _map = {\n        '1.3.6.1.5.5.7.48.1.1': 'basic_ocsp_response',\n    }\n\n\nclass AcceptableResponses(SequenceOf):\n    _child_spec = ResponseType\n\n\nclass PreferredSignatureAlgorithm(Sequence):\n    _fields = [\n        ('sig_identifier', SignedDigestAlgorithm),\n        ('cert_identifier', PublicKeyAlgorithm, {'optional': True}),\n    ]\n\n\nclass PreferredSignatureAlgorithms(SequenceOf):\n    _child_spec = PreferredSignatureAlgorithm\n\n\nclass TBSRequestExtensionId(ObjectIdentifier):\n    _map = {\n        '1.3.6.1.5.5.7.48.1.2': 'nonce',\n        '1.3.6.1.5.5.7.48.1.4': 'acceptable_responses',\n        '1.3.6.1.5.5.7.48.1.8': 'preferred_signature_algorithms',\n    }\n\n\nclass TBSRequestExtension(Sequence):\n    _fields = [\n        ('extn_id', TBSRequestExtensionId),\n        ('critical', Boolean, {'default': False}),\n        ('extn_value', ParsableOctetString),\n    ]\n\n    _oid_pair = ('extn_id', 'extn_value')\n    _oid_specs = {\n        'nonce': OctetString,\n        'acceptable_responses': AcceptableResponses,\n        'preferred_signature_algorithms': PreferredSignatureAlgorithms,\n    }\n\n\nclass TBSRequestExtensions(SequenceOf):\n    _child_spec = TBSRequestExtension\n\n\nclass TBSRequest(Sequence):\n    _fields = [\n        ('version', Version, {'explicit': 0, 'default': 'v1'}),\n        ('requestor_name', GeneralName, {'explicit': 1, 'optional': True}),\n        ('request_list', Requests),\n        ('request_extensions', TBSRequestExtensions, {'explicit': 2, 'optional': True}),\n    ]\n\n\nclass Certificates(SequenceOf):\n    _child_spec = Certificate\n\n\nclass Signature(Sequence):\n    _fields = [\n        ('signature_algorithm', SignedDigestAlgorithm),\n        ('signature', OctetBitString),\n        ('certs', Certificates, {'explicit': 0, 'optional': True}),\n    ]\n\n\nclass OCSPRequest(Sequence):\n    _fields = [\n        ('tbs_request', TBSRequest),\n        ('optional_signature', Signature, {'explicit': 0, 'optional': True}),\n    ]\n\n    _processed_extensions = False\n    _critical_extensions = None\n    _nonce_value = None\n    _acceptable_responses_value = None\n    _preferred_signature_algorithms_value = None\n\n    def _set_extensions(self):\n        \"\"\"\n        Sets common named extensions to private attributes and creates a list\n        of critical extensions\n        \"\"\"\n\n        self._critical_extensions = set()\n\n        for extension in self['tbs_request']['request_extensions']:\n            name = extension['extn_id'].native\n            attribute_name = '_%s_value' % name\n            if hasattr(self, attribute_name):\n                setattr(self, attribute_name, extension['extn_value'].parsed)\n            if extension['critical'].native:\n                self._critical_extensions.add(name)\n\n        self._processed_extensions = True\n\n    @property\n    def critical_extensions(self):\n        \"\"\"\n        Returns a set of the names (or OID if not a known extension) of the\n        extensions marked as critical\n\n        :return:\n            A set of unicode strings\n        \"\"\"\n\n        if not self._processed_extensions:\n            self._set_extensions()\n        return self._critical_extensions\n\n    @property\n    def nonce_value(self):\n        \"\"\"\n        This extension is used to prevent replay attacks by including a unique,\n        random value with each request/response pair\n\n        :return:\n            None or an OctetString object\n        \"\"\"\n\n        if self._processed_extensions is False:\n            self._set_extensions()\n        return self._nonce_value\n\n    @property\n    def acceptable_responses_value(self):\n        \"\"\"\n        This extension is used to allow the client and server to communicate\n        with alternative response formats other than just basic_ocsp_response,\n        although no other formats are defined in the standard.\n\n        :return:\n            None or an AcceptableResponses object\n        \"\"\"\n\n        if self._processed_extensions is False:\n            self._set_extensions()\n        return self._acceptable_responses_value\n\n    @property\n    def preferred_signature_algorithms_value(self):\n        \"\"\"\n        This extension is used by the client to define what signature algorithms\n        are preferred, including both the hash algorithm and the public key\n        algorithm, with a level of detail down to even the public key algorithm\n        parameters, such as curve name.\n\n        :return:\n            None or a PreferredSignatureAlgorithms object\n        \"\"\"\n\n        if self._processed_extensions is False:\n            self._set_extensions()\n        return self._preferred_signature_algorithms_value\n\n\nclass OCSPResponseStatus(Enumerated):\n    _map = {\n        0: 'successful',\n        1: 'malformed_request',\n        2: 'internal_error',\n        3: 'try_later',\n        5: 'sign_required',\n        6: 'unauthorized',\n    }\n\n\nclass ResponderId(Choice):\n    _alternatives = [\n        ('by_name', Name, {'explicit': 1}),\n        ('by_key', OctetString, {'explicit': 2}),\n    ]\n\n\n# Custom class to return a meaningful .native attribute from CertStatus()\nclass StatusGood(Null):\n    def set(self, value):\n        \"\"\"\n        Sets the value of the object\n\n        :param value:\n            None or 'good'\n        \"\"\"\n\n        if value is not None and value != 'good' and not isinstance(value, Null):\n            raise ValueError(unwrap(\n                '''\n                value must be one of None, \"good\", not %s\n                ''',\n                repr(value)\n            ))\n\n        self.contents = b''\n\n    @property\n    def native(self):\n        return 'good'\n\n\n# Custom class to return a meaningful .native attribute from CertStatus()\nclass StatusUnknown(Null):\n    def set(self, value):\n        \"\"\"\n        Sets the value of the object\n\n        :param value:\n            None or 'unknown'\n        \"\"\"\n\n        if value is not None and value != 'unknown' and not isinstance(value, Null):\n            raise ValueError(unwrap(\n                '''\n                value must be one of None, \"unknown\", not %s\n                ''',\n                repr(value)\n            ))\n\n        self.contents = b''\n\n    @property\n    def native(self):\n        return 'unknown'\n\n\nclass RevokedInfo(Sequence):\n    _fields = [\n        ('revocation_time', GeneralizedTime),\n        ('revocation_reason', CRLReason, {'explicit': 0, 'optional': True}),\n    ]\n\n\nclass CertStatus(Choice):\n    _alternatives = [\n        ('good', StatusGood, {'implicit': 0}),\n        ('revoked', RevokedInfo, {'implicit': 1}),\n        ('unknown', StatusUnknown, {'implicit': 2}),\n    ]\n\n\nclass CrlId(Sequence):\n    _fields = [\n        ('crl_url', IA5String, {'explicit': 0, 'optional': True}),\n        ('crl_num', Integer, {'explicit': 1, 'optional': True}),\n        ('crl_time', GeneralizedTime, {'explicit': 2, 'optional': True}),\n    ]\n\n\nclass SingleResponseExtensionId(ObjectIdentifier):\n    _map = {\n        '1.3.6.1.5.5.7.48.1.3': 'crl',\n        '1.3.6.1.5.5.7.48.1.6': 'archive_cutoff',\n        # These are CRLEntryExtension values from\n        # https://tools.ietf.org/html/rfc5280\n        '2.5.29.21': 'crl_reason',\n        '2.5.29.24': 'invalidity_date',\n        '2.5.29.29': 'certificate_issuer',\n        # https://tools.ietf.org/html/rfc6962.html#page-13\n        '1.3.6.1.4.1.11129.2.4.5': 'signed_certificate_timestamp_list',\n    }\n\n\nclass SingleResponseExtension(Sequence):\n    _fields = [\n        ('extn_id', SingleResponseExtensionId),\n        ('critical', Boolean, {'default': False}),\n        ('extn_value', ParsableOctetString),\n    ]\n\n    _oid_pair = ('extn_id', 'extn_value')\n    _oid_specs = {\n        'crl': CrlId,\n        'archive_cutoff': GeneralizedTime,\n        'crl_reason': CRLReason,\n        'invalidity_date': GeneralizedTime,\n        'certificate_issuer': GeneralNames,\n        'signed_certificate_timestamp_list': OctetString,\n    }\n\n\nclass SingleResponseExtensions(SequenceOf):\n    _child_spec = SingleResponseExtension\n\n\nclass SingleResponse(Sequence):\n    _fields = [\n        ('cert_id', CertId),\n        ('cert_status', CertStatus),\n        ('this_update', GeneralizedTime),\n        ('next_update', GeneralizedTime, {'explicit': 0, 'optional': True}),\n        ('single_extensions', SingleResponseExtensions, {'explicit': 1, 'optional': True}),\n    ]\n\n    _processed_extensions = False\n    _critical_extensions = None\n    _crl_value = None\n    _archive_cutoff_value = None\n    _crl_reason_value = None\n    _invalidity_date_value = None\n    _certificate_issuer_value = None\n\n    def _set_extensions(self):\n        \"\"\"\n        Sets common named extensions to private attributes and creates a list\n        of critical extensions\n        \"\"\"\n\n        self._critical_extensions = set()\n\n        for extension in self['single_extensions']:\n            name = extension['extn_id'].native\n            attribute_name = '_%s_value' % name\n            if hasattr(self, attribute_name):\n                setattr(self, attribute_name, extension['extn_value'].parsed)\n            if extension['critical'].native:\n                self._critical_extensions.add(name)\n\n        self._processed_extensions = True\n\n    @property\n    def critical_extensions(self):\n        \"\"\"\n        Returns a set of the names (or OID if not a known extension) of the\n        extensions marked as critical\n\n        :return:\n            A set of unicode strings\n        \"\"\"\n\n        if not self._processed_extensions:\n            self._set_extensions()\n        return self._critical_extensions\n\n    @property\n    def crl_value(self):\n        \"\"\"\n        This extension is used to locate the CRL that a certificate's revocation\n        is contained within.\n\n        :return:\n            None or a CrlId object\n        \"\"\"\n\n        if self._processed_extensions is False:\n            self._set_extensions()\n        return self._crl_value\n\n    @property\n    def archive_cutoff_value(self):\n        \"\"\"\n        This extension is used to indicate the date at which an archived\n        (historical) certificate status entry will no longer be available.\n\n        :return:\n            None or a GeneralizedTime object\n        \"\"\"\n\n        if self._processed_extensions is False:\n            self._set_extensions()\n        return self._archive_cutoff_value\n\n    @property\n    def crl_reason_value(self):\n        \"\"\"\n        This extension indicates the reason that a certificate was revoked.\n\n        :return:\n            None or a CRLReason object\n        \"\"\"\n\n        if self._processed_extensions is False:\n            self._set_extensions()\n        return self._crl_reason_value\n\n    @property\n    def invalidity_date_value(self):\n        \"\"\"\n        This extension indicates the suspected date/time the private key was\n        compromised or the certificate became invalid. This would usually be\n        before the revocation date, which is when the CA processed the\n        revocation.\n\n        :return:\n            None or a GeneralizedTime object\n        \"\"\"\n\n        if self._processed_extensions is False:\n            self._set_extensions()\n        return self._invalidity_date_value\n\n    @property\n    def certificate_issuer_value(self):\n        \"\"\"\n        This extension indicates the issuer of the certificate in question.\n\n        :return:\n            None or an x509.GeneralNames object\n        \"\"\"\n\n        if self._processed_extensions is False:\n            self._set_extensions()\n        return self._certificate_issuer_value\n\n\nclass Responses(SequenceOf):\n    _child_spec = SingleResponse\n\n\nclass ResponseDataExtensionId(ObjectIdentifier):\n    _map = {\n        '1.3.6.1.5.5.7.48.1.2': 'nonce',\n        '1.3.6.1.5.5.7.48.1.9': 'extended_revoke',\n    }\n\n\nclass ResponseDataExtension(Sequence):\n    _fields = [\n        ('extn_id', ResponseDataExtensionId),\n        ('critical', Boolean, {'default': False}),\n        ('extn_value', ParsableOctetString),\n    ]\n\n    _oid_pair = ('extn_id', 'extn_value')\n    _oid_specs = {\n        'nonce': OctetString,\n        'extended_revoke': Null,\n    }\n\n\nclass ResponseDataExtensions(SequenceOf):\n    _child_spec = ResponseDataExtension\n\n\nclass ResponseData(Sequence):\n    _fields = [\n        ('version', Version, {'explicit': 0, 'default': 'v1'}),\n        ('responder_id', ResponderId),\n        ('produced_at', GeneralizedTime),\n        ('responses', Responses),\n        ('response_extensions', ResponseDataExtensions, {'explicit': 1, 'optional': True}),\n    ]\n\n\nclass BasicOCSPResponse(Sequence):\n    _fields = [\n        ('tbs_response_data', ResponseData),\n        ('signature_algorithm', SignedDigestAlgorithm),\n        ('signature', OctetBitString),\n        ('certs', Certificates, {'explicit': 0, 'optional': True}),\n    ]\n\n\nclass ResponseBytes(Sequence):\n    _fields = [\n        ('response_type', ResponseType),\n        ('response', ParsableOctetString),\n    ]\n\n    _oid_pair = ('response_type', 'response')\n    _oid_specs = {\n        'basic_ocsp_response': BasicOCSPResponse,\n    }\n\n\nclass OCSPResponse(Sequence):\n    _fields = [\n        ('response_status', OCSPResponseStatus),\n        ('response_bytes', ResponseBytes, {'explicit': 0, 'optional': True}),\n    ]\n\n    _processed_extensions = False\n    _critical_extensions = None\n    _nonce_value = None\n    _extended_revoke_value = None\n\n    def _set_extensions(self):\n        \"\"\"\n        Sets common named extensions to private attributes and creates a list\n        of critical extensions\n        \"\"\"\n\n        self._critical_extensions = set()\n\n        for extension in self['response_bytes']['response'].parsed['tbs_response_data']['response_extensions']:\n            name = extension['extn_id'].native\n            attribute_name = '_%s_value' % name\n            if hasattr(self, attribute_name):\n                setattr(self, attribute_name, extension['extn_value'].parsed)\n            if extension['critical'].native:\n                self._critical_extensions.add(name)\n\n        self._processed_extensions = True\n\n    @property\n    def critical_extensions(self):\n        \"\"\"\n        Returns a set of the names (or OID if not a known extension) of the\n        extensions marked as critical\n\n        :return:\n            A set of unicode strings\n        \"\"\"\n\n        if not self._processed_extensions:\n            self._set_extensions()\n        return self._critical_extensions\n\n    @property\n    def nonce_value(self):\n        \"\"\"\n        This extension is used to prevent replay attacks on the request/response\n        exchange\n\n        :return:\n            None or an OctetString object\n        \"\"\"\n\n        if self._processed_extensions is False:\n            self._set_extensions()\n        return self._nonce_value\n\n    @property\n    def extended_revoke_value(self):\n        \"\"\"\n        This extension is used to signal that the responder will return a\n        \"revoked\" status for non-issued certificates.\n\n        :return:\n            None or a Null object (if present)\n        \"\"\"\n\n        if self._processed_extensions is False:\n            self._set_extensions()\n        return self._extended_revoke_value\n\n    @property\n    def basic_ocsp_response(self):\n        \"\"\"\n        A shortcut into the BasicOCSPResponse sequence\n\n        :return:\n            None or an asn1crypto.ocsp.BasicOCSPResponse object\n        \"\"\"\n\n        return self['response_bytes']['response'].parsed\n\n    @property\n    def response_data(self):\n        \"\"\"\n        A shortcut into the parsed, ResponseData sequence\n\n        :return:\n            None or an asn1crypto.ocsp.ResponseData object\n        \"\"\"\n\n        return self['response_bytes']['response'].parsed['tbs_response_data']\n", "asn1crypto/_types.py": "# coding: utf-8\nfrom __future__ import unicode_literals, division, absolute_import, print_function\n\nimport inspect\nimport sys\n\n\nif sys.version_info < (3,):\n    str_cls = unicode  # noqa\n    byte_cls = str\n    int_types = (int, long)  # noqa\n\n    def bytes_to_list(byte_string):\n        return [ord(b) for b in byte_string]\n\n    chr_cls = chr\n\nelse:\n    str_cls = str\n    byte_cls = bytes\n    int_types = int\n\n    bytes_to_list = list\n\n    def chr_cls(num):\n        return bytes([num])\n\n\ndef type_name(value):\n    \"\"\"\n    Returns a user-readable name for the type of an object\n\n    :param value:\n        A value to get the type name of\n\n    :return:\n        A unicode string of the object's type name\n    \"\"\"\n\n    if inspect.isclass(value):\n        cls = value\n    else:\n        cls = value.__class__\n    if cls.__module__ in set(['builtins', '__builtin__']):\n        return cls.__name__\n    return '%s.%s' % (cls.__module__, cls.__name__)\n", "asn1crypto/algos.py": "# coding: utf-8\n\n\"\"\"\nASN.1 type classes for various algorithms using in various aspects of public\nkey cryptography. Exports the following items:\n\n - AlgorithmIdentifier()\n - AnyAlgorithmIdentifier()\n - DigestAlgorithm()\n - DigestInfo()\n - DSASignature()\n - EncryptionAlgorithm()\n - HmacAlgorithm()\n - KdfAlgorithm()\n - Pkcs5MacAlgorithm()\n - SignedDigestAlgorithm()\n\nOther type classes are defined that help compose the types listed above.\n\"\"\"\n\nfrom __future__ import unicode_literals, division, absolute_import, print_function\n\nfrom ._errors import unwrap\nfrom ._int import fill_width\nfrom .util import int_from_bytes, int_to_bytes\nfrom .core import (\n    Any,\n    Choice,\n    Integer,\n    Null,\n    ObjectIdentifier,\n    OctetString,\n    Sequence,\n    Void,\n)\n\n\n# Structures and OIDs in this file are pulled from\n# https://tools.ietf.org/html/rfc3279, https://tools.ietf.org/html/rfc4055,\n# https://tools.ietf.org/html/rfc5758, https://tools.ietf.org/html/rfc7292,\n# http://www.emc.com/collateral/white-papers/h11302-pkcs5v2-1-password-based-cryptography-standard-wp.pdf\n\nclass AlgorithmIdentifier(Sequence):\n    _fields = [\n        ('algorithm', ObjectIdentifier),\n        ('parameters', Any, {'optional': True}),\n    ]\n\n\nclass _ForceNullParameters(object):\n    \"\"\"\n    Various structures based on AlgorithmIdentifier require that the parameters\n    field be core.Null() for certain OIDs. This mixin ensures that happens.\n    \"\"\"\n\n    # The following attribute, plus the parameters spec callback and custom\n    # __setitem__ are all to handle a situation where parameters should not be\n    # optional and must be Null for certain OIDs. More info at\n    # https://tools.ietf.org/html/rfc4055#page-15 and\n    # https://tools.ietf.org/html/rfc4055#section-2.1\n    _null_algos = set([\n        '1.2.840.113549.1.1.1',    # rsassa_pkcs1v15 / rsaes_pkcs1v15 / rsa\n        '1.2.840.113549.1.1.11',   # sha256_rsa\n        '1.2.840.113549.1.1.12',   # sha384_rsa\n        '1.2.840.113549.1.1.13',   # sha512_rsa\n        '1.2.840.113549.1.1.14',   # sha224_rsa\n        '1.3.14.3.2.26',           # sha1\n        '2.16.840.1.101.3.4.2.4',  # sha224\n        '2.16.840.1.101.3.4.2.1',  # sha256\n        '2.16.840.1.101.3.4.2.2',  # sha384\n        '2.16.840.1.101.3.4.2.3',  # sha512\n    ])\n\n    def _parameters_spec(self):\n        if self._oid_pair == ('algorithm', 'parameters'):\n            algo = self['algorithm'].native\n            if algo in self._oid_specs:\n                return self._oid_specs[algo]\n\n        if self['algorithm'].dotted in self._null_algos:\n            return Null\n\n        return None\n\n    _spec_callbacks = {\n        'parameters': _parameters_spec\n    }\n\n    # We have to override this since the spec callback uses the value of\n    # algorithm to determine the parameter spec, however default values are\n    # assigned before setting a field, so a default value can't be based on\n    # another field value (unless it is a default also). Thus we have to\n    # manually check to see if the algorithm was set and parameters is unset,\n    # and then fix the value as appropriate.\n    def __setitem__(self, key, value):\n        res = super(_ForceNullParameters, self).__setitem__(key, value)\n        if key != 'algorithm':\n            return res\n        if self['algorithm'].dotted not in self._null_algos:\n            return res\n        if self['parameters'].__class__ != Void:\n            return res\n        self['parameters'] = Null()\n        return res\n\n\nclass HmacAlgorithmId(ObjectIdentifier):\n    _map = {\n        '1.3.14.3.2.10': 'des_mac',\n        '1.2.840.113549.2.7': 'sha1',\n        '1.2.840.113549.2.8': 'sha224',\n        '1.2.840.113549.2.9': 'sha256',\n        '1.2.840.113549.2.10': 'sha384',\n        '1.2.840.113549.2.11': 'sha512',\n        '1.2.840.113549.2.12': 'sha512_224',\n        '1.2.840.113549.2.13': 'sha512_256',\n        '2.16.840.1.101.3.4.2.13': 'sha3_224',\n        '2.16.840.1.101.3.4.2.14': 'sha3_256',\n        '2.16.840.1.101.3.4.2.15': 'sha3_384',\n        '2.16.840.1.101.3.4.2.16': 'sha3_512',\n    }\n\n\nclass HmacAlgorithm(Sequence):\n    _fields = [\n        ('algorithm', HmacAlgorithmId),\n        ('parameters', Any, {'optional': True}),\n    ]\n\n\nclass DigestAlgorithmId(ObjectIdentifier):\n    _map = {\n        '1.2.840.113549.2.2': 'md2',\n        '1.2.840.113549.2.5': 'md5',\n        '1.3.14.3.2.26': 'sha1',\n        '2.16.840.1.101.3.4.2.4': 'sha224',\n        '2.16.840.1.101.3.4.2.1': 'sha256',\n        '2.16.840.1.101.3.4.2.2': 'sha384',\n        '2.16.840.1.101.3.4.2.3': 'sha512',\n        '2.16.840.1.101.3.4.2.5': 'sha512_224',\n        '2.16.840.1.101.3.4.2.6': 'sha512_256',\n        '2.16.840.1.101.3.4.2.7': 'sha3_224',\n        '2.16.840.1.101.3.4.2.8': 'sha3_256',\n        '2.16.840.1.101.3.4.2.9': 'sha3_384',\n        '2.16.840.1.101.3.4.2.10': 'sha3_512',\n        '2.16.840.1.101.3.4.2.11': 'shake128',\n        '2.16.840.1.101.3.4.2.12': 'shake256',\n        '2.16.840.1.101.3.4.2.17': 'shake128_len',\n        '2.16.840.1.101.3.4.2.18': 'shake256_len',\n    }\n\n\nclass DigestAlgorithm(_ForceNullParameters, Sequence):\n    _fields = [\n        ('algorithm', DigestAlgorithmId),\n        ('parameters', Any, {'optional': True}),\n    ]\n\n\n# This structure is what is signed with a SignedDigestAlgorithm\nclass DigestInfo(Sequence):\n    _fields = [\n        ('digest_algorithm', DigestAlgorithm),\n        ('digest', OctetString),\n    ]\n\n\nclass MaskGenAlgorithmId(ObjectIdentifier):\n    _map = {\n        '1.2.840.113549.1.1.8': 'mgf1',\n    }\n\n\nclass MaskGenAlgorithm(Sequence):\n    _fields = [\n        ('algorithm', MaskGenAlgorithmId),\n        ('parameters', Any, {'optional': True}),\n    ]\n\n    _oid_pair = ('algorithm', 'parameters')\n    _oid_specs = {\n        'mgf1': DigestAlgorithm\n    }\n\n\nclass TrailerField(Integer):\n    _map = {\n        1: 'trailer_field_bc',\n    }\n\n\nclass RSASSAPSSParams(Sequence):\n    _fields = [\n        (\n            'hash_algorithm',\n            DigestAlgorithm,\n            {\n                'explicit': 0,\n                'default': {'algorithm': 'sha1'},\n            }\n        ),\n        (\n            'mask_gen_algorithm',\n            MaskGenAlgorithm,\n            {\n                'explicit': 1,\n                'default': {\n                    'algorithm': 'mgf1',\n                    'parameters': {'algorithm': 'sha1'},\n                },\n            }\n        ),\n        (\n            'salt_length',\n            Integer,\n            {\n                'explicit': 2,\n                'default': 20,\n            }\n        ),\n        (\n            'trailer_field',\n            TrailerField,\n            {\n                'explicit': 3,\n                'default': 'trailer_field_bc',\n            }\n        ),\n    ]\n\n\nclass SignedDigestAlgorithmId(ObjectIdentifier):\n    _map = {\n        '1.3.14.3.2.3': 'md5_rsa',\n        '1.3.14.3.2.29': 'sha1_rsa',\n        '1.3.14.7.2.3.1': 'md2_rsa',\n        '1.2.840.113549.1.1.2': 'md2_rsa',\n        '1.2.840.113549.1.1.4': 'md5_rsa',\n        '1.2.840.113549.1.1.5': 'sha1_rsa',\n        '1.2.840.113549.1.1.14': 'sha224_rsa',\n        '1.2.840.113549.1.1.11': 'sha256_rsa',\n        '1.2.840.113549.1.1.12': 'sha384_rsa',\n        '1.2.840.113549.1.1.13': 'sha512_rsa',\n        '1.2.840.113549.1.1.10': 'rsassa_pss',\n        '1.2.840.10040.4.3': 'sha1_dsa',\n        '1.3.14.3.2.13': 'sha1_dsa',\n        '1.3.14.3.2.27': 'sha1_dsa',\n        # Source: NIST CSOR Algorithm Registrations\n        '2.16.840.1.101.3.4.3.1': 'sha224_dsa',\n        '2.16.840.1.101.3.4.3.2': 'sha256_dsa',\n        '2.16.840.1.101.3.4.3.3': 'sha384_dsa',\n        '2.16.840.1.101.3.4.3.4': 'sha512_dsa',\n        '1.2.840.10045.4.1': 'sha1_ecdsa',\n        '1.2.840.10045.4.3.1': 'sha224_ecdsa',\n        '1.2.840.10045.4.3.2': 'sha256_ecdsa',\n        '1.2.840.10045.4.3.3': 'sha384_ecdsa',\n        '1.2.840.10045.4.3.4': 'sha512_ecdsa',\n        # Source: NIST CSOR Algorithm Registrations\n        '2.16.840.1.101.3.4.3.5': 'sha3_224_dsa',\n        '2.16.840.1.101.3.4.3.6': 'sha3_256_dsa',\n        '2.16.840.1.101.3.4.3.7': 'sha3_384_dsa',\n        '2.16.840.1.101.3.4.3.8': 'sha3_512_dsa',\n        '2.16.840.1.101.3.4.3.9': 'sha3_224_ecdsa',\n        '2.16.840.1.101.3.4.3.10': 'sha3_256_ecdsa',\n        '2.16.840.1.101.3.4.3.11': 'sha3_384_ecdsa',\n        '2.16.840.1.101.3.4.3.12': 'sha3_512_ecdsa',\n        '2.16.840.1.101.3.4.3.13': 'sha3_224_rsa',\n        '2.16.840.1.101.3.4.3.14': 'sha3_256_rsa',\n        '2.16.840.1.101.3.4.3.15': 'sha3_384_rsa',\n        '2.16.840.1.101.3.4.3.16': 'sha3_512_rsa',\n        # For when the digest is specified elsewhere in a Sequence\n        '1.2.840.113549.1.1.1': 'rsassa_pkcs1v15',\n        '1.2.840.10040.4.1': 'dsa',\n        '1.2.840.10045.4': 'ecdsa',\n        # RFC 8410 -- https://tools.ietf.org/html/rfc8410\n        '1.3.101.112': 'ed25519',\n        '1.3.101.113': 'ed448',\n        # Source: BSI TR-03111 V-2\n        '0.4.0.127.0.7.1.1.4.1.1': 'sha1_ecdsa_plain',\n        '0.4.0.127.0.7.1.1.4.1.2': 'sha224_ecdsa_plain',\n        '0.4.0.127.0.7.1.1.4.1.3': 'sha256_ecdsa_plain',\n        '0.4.0.127.0.7.1.1.4.1.4': 'sha384_ecdsa_plain',\n        '0.4.0.127.0.7.1.1.4.1.5': 'sha512_ecdsa_plain',\n        '0.4.0.127.0.7.1.1.4.1.8': 'sha3_224_ecdsa_plain',\n        '0.4.0.127.0.7.1.1.4.1.9': 'sha3_256_ecdsa_plain',\n        '0.4.0.127.0.7.1.1.4.1.10': 'sha3_384_ecdsa_plain',\n        '0.4.0.127.0.7.1.1.4.1.11': 'sha3_512_ecdsa_plain',\n    }\n\n    _reverse_map = {\n        'dsa': '1.2.840.10040.4.1',\n        'ecdsa': '1.2.840.10045.4',\n        'md2_rsa': '1.2.840.113549.1.1.2',\n        'md5_rsa': '1.2.840.113549.1.1.4',\n        'rsassa_pkcs1v15': '1.2.840.113549.1.1.1',\n        'rsassa_pss': '1.2.840.113549.1.1.10',\n        'sha1_dsa': '1.2.840.10040.4.3',\n        'sha1_ecdsa': '1.2.840.10045.4.1',\n        'sha1_rsa': '1.2.840.113549.1.1.5',\n        'sha224_dsa': '2.16.840.1.101.3.4.3.1',\n        'sha224_ecdsa': '1.2.840.10045.4.3.1',\n        'sha224_rsa': '1.2.840.113549.1.1.14',\n        'sha256_dsa': '2.16.840.1.101.3.4.3.2',\n        'sha256_ecdsa': '1.2.840.10045.4.3.2',\n        'sha256_rsa': '1.2.840.113549.1.1.11',\n        'sha384_dsa': '2.16.840.1.101.3.4.3.3',\n        'sha384_ecdsa': '1.2.840.10045.4.3.3',\n        'sha384_rsa': '1.2.840.113549.1.1.12',\n        'sha512_dsa': '2.16.840.1.101.3.4.3.4',\n        'sha512_ecdsa': '1.2.840.10045.4.3.4',\n        'sha512_rsa': '1.2.840.113549.1.1.13',\n        # Source: NIST CSOR Algorithm Registrations\n        'sha3_224_dsa': '2.16.840.1.101.3.4.3.5',\n        'sha3_256_dsa': '2.16.840.1.101.3.4.3.6',\n        'sha3_384_dsa': '2.16.840.1.101.3.4.3.7',\n        'sha3_512_dsa': '2.16.840.1.101.3.4.3.8',\n        'sha3_224_ecdsa': '2.16.840.1.101.3.4.3.9',\n        'sha3_256_ecdsa': '2.16.840.1.101.3.4.3.10',\n        'sha3_384_ecdsa': '2.16.840.1.101.3.4.3.11',\n        'sha3_512_ecdsa': '2.16.840.1.101.3.4.3.12',\n        'sha3_224_rsa': '2.16.840.1.101.3.4.3.13',\n        'sha3_256_rsa': '2.16.840.1.101.3.4.3.14',\n        'sha3_384_rsa': '2.16.840.1.101.3.4.3.15',\n        'sha3_512_rsa': '2.16.840.1.101.3.4.3.16',\n        'ed25519': '1.3.101.112',\n        'ed448': '1.3.101.113',\n        'sha1_ecdsa_plain': '0.4.0.127.0.7.1.1.4.1.1',\n        'sha224_ecdsa_plain': '0.4.0.127.0.7.1.1.4.1.2',\n        'sha256_ecdsa_plain': '0.4.0.127.0.7.1.1.4.1.3',\n        'sha384_ecdsa_plain': '0.4.0.127.0.7.1.1.4.1.4',\n        'sha512_ecdsa_plain': '0.4.0.127.0.7.1.1.4.1.5',\n        'sha3_224_ecdsa_plain': '0.4.0.127.0.7.1.1.4.1.8',\n        'sha3_256_ecdsa_plain': '0.4.0.127.0.7.1.1.4.1.9',\n        'sha3_384_ecdsa_plain': '0.4.0.127.0.7.1.1.4.1.10',\n        'sha3_512_ecdsa_plain': '0.4.0.127.0.7.1.1.4.1.11',\n    }\n\n\nclass SignedDigestAlgorithm(_ForceNullParameters, Sequence):\n    _fields = [\n        ('algorithm', SignedDigestAlgorithmId),\n        ('parameters', Any, {'optional': True}),\n    ]\n\n    _oid_pair = ('algorithm', 'parameters')\n    _oid_specs = {\n        'rsassa_pss': RSASSAPSSParams,\n    }\n\n    _algo_map = {\n        'md2_rsa': 'md2',\n        'md5_rsa': 'md5',\n        'sha1_rsa': 'sha1',\n        'sha224_rsa': 'sha224',\n        'sha256_rsa': 'sha256',\n        'sha384_rsa': 'sha384',\n        'sha512_rsa': 'sha512',\n        'sha1_dsa': 'sha1',\n        'sha224_dsa': 'sha224',\n        'sha256_dsa': 'sha256',\n        'sha384_dsa': 'sha384',\n        'sha512_dsa': 'sha512',\n        'sha1_ecdsa': 'sha1',\n        'sha1_ecdsa_plain': 'sha1',\n        'sha224_ecdsa': 'sha224',\n        'sha256_ecdsa': 'sha256',\n        'sha384_ecdsa': 'sha384',\n        'sha512_ecdsa': 'sha512',\n        'sha224_ecdsa_plain': 'sha224',\n        'sha256_ecdsa_plain': 'sha256',\n        'sha384_ecdsa_plain': 'sha384',\n        'sha512_ecdsa_plain': 'sha512',\n        'sha3_224_dsa': 'sha3_224',\n        'sha3_256_dsa': 'sha3_256',\n        'sha3_384_dsa': 'sha3_384',\n        'sha3_512_dsa': 'sha3_512',\n        'sha3_224_ecdsa': 'sha3_224',\n        'sha3_256_ecdsa': 'sha3_256',\n        'sha3_384_ecdsa': 'sha3_384',\n        'sha3_512_ecdsa': 'sha3_512',\n        'sha3_224_ecdsa_plain': 'sha3_224',\n        'sha3_256_ecdsa_plain': 'sha3_256',\n        'sha3_384_ecdsa_plain': 'sha3_384',\n        'sha3_512_ecdsa_plain': 'sha3_512',\n        'sha3_224_rsa': 'sha3_224',\n        'sha3_256_rsa': 'sha3_256',\n        'sha3_384_rsa': 'sha3_384',\n        'sha3_512_rsa': 'sha3_512',\n    }\n\n    @property\n    def signature_algo(self):\n        \"\"\"\n        :return:\n            A unicode string of \"rsassa_pkcs1v15\", \"rsassa_pss\", \"dsa\",\n            \"ecdsa\", \"ed25519\" or \"ed448\"\n        \"\"\"\n\n        algorithm = self['algorithm'].native\n\n        algo_map = {\n            'md2_rsa': 'rsassa_pkcs1v15',\n            'md5_rsa': 'rsassa_pkcs1v15',\n            'sha1_rsa': 'rsassa_pkcs1v15',\n            'sha224_rsa': 'rsassa_pkcs1v15',\n            'sha256_rsa': 'rsassa_pkcs1v15',\n            'sha384_rsa': 'rsassa_pkcs1v15',\n            'sha512_rsa': 'rsassa_pkcs1v15',\n            'sha3_224_rsa': 'rsassa_pkcs1v15',\n            'sha3_256_rsa': 'rsassa_pkcs1v15',\n            'sha3_384_rsa': 'rsassa_pkcs1v15',\n            'sha3_512_rsa': 'rsassa_pkcs1v15',\n            'rsassa_pkcs1v15': 'rsassa_pkcs1v15',\n            'rsassa_pss': 'rsassa_pss',\n            'sha1_dsa': 'dsa',\n            'sha224_dsa': 'dsa',\n            'sha256_dsa': 'dsa',\n            'sha384_dsa': 'dsa',\n            'sha512_dsa': 'dsa',\n            'sha3_224_dsa': 'dsa',\n            'sha3_256_dsa': 'dsa',\n            'sha3_384_dsa': 'dsa',\n            'sha3_512_dsa': 'dsa',\n            'dsa': 'dsa',\n            'sha1_ecdsa': 'ecdsa',\n            'sha224_ecdsa': 'ecdsa',\n            'sha256_ecdsa': 'ecdsa',\n            'sha384_ecdsa': 'ecdsa',\n            'sha512_ecdsa': 'ecdsa',\n            'sha3_224_ecdsa': 'ecdsa',\n            'sha3_256_ecdsa': 'ecdsa',\n            'sha3_384_ecdsa': 'ecdsa',\n            'sha3_512_ecdsa': 'ecdsa',\n            'sha1_ecdsa_plain': 'ecdsa',\n            'sha224_ecdsa_plain': 'ecdsa',\n            'sha256_ecdsa_plain': 'ecdsa',\n            'sha384_ecdsa_plain': 'ecdsa',\n            'sha512_ecdsa_plain': 'ecdsa',\n            'sha3_224_ecdsa_plain': 'ecdsa',\n            'sha3_256_ecdsa_plain': 'ecdsa',\n            'sha3_384_ecdsa_plain': 'ecdsa',\n            'sha3_512_ecdsa_plain': 'ecdsa',\n            'ecdsa': 'ecdsa',\n            'ed25519': 'ed25519',\n            'ed448': 'ed448',\n        }\n        if algorithm in algo_map:\n            return algo_map[algorithm]\n\n        raise ValueError(unwrap(\n            '''\n            Signature algorithm not known for %s\n            ''',\n            algorithm\n        ))\n\n    @property\n    def hash_algo(self):\n        \"\"\"\n        :return:\n            A unicode string of \"md2\", \"md5\", \"sha1\", \"sha224\", \"sha256\",\n            \"sha384\", \"sha512\", \"sha512_224\", \"sha512_256\" or \"shake256\"\n        \"\"\"\n\n        algorithm = self['algorithm'].native\n        if algorithm in self._algo_map:\n            return self._algo_map[algorithm]\n\n        if algorithm == 'rsassa_pss':\n            return self['parameters']['hash_algorithm']['algorithm'].native\n\n        if algorithm == 'ed25519' or algorithm == 'ed448':\n            raise ValueError(unwrap(\n                '''\n                Hash algorithm not known for %s - use .cms_hash_algorithm for CMS purposes.\n                More info at https://github.com/wbond/asn1crypto/pull/230.\n                ''',\n                algorithm\n            ))\n\n        raise ValueError(unwrap(\n            '''\n            Hash algorithm not known for %s\n            ''',\n            algorithm\n        ))\n\n    @property\n    def cms_hash_algo(self):\n        \"\"\"\n        The hash algorithm for CMS hashing\n\n        :return:\n            A unicode string of \"md2\", \"md5\", \"sha1\", \"sha224\", \"sha256\",\n            \"sha384\", \"sha512\", \"sha512_224\", \"sha512_256\" or \"shake256\"\n        \"\"\"\n\n        algorithm = self['algorithm'].native\n\n        if algorithm in self._algo_map:\n            return self._algo_map[algorithm]\n\n        if algorithm == 'rsassa_pss':\n            return self['parameters']['hash_algorithm']['algorithm'].native\n\n        cms_algo_map = {\n            'ed25519': 'sha512',\n            'ed448': 'shake256',\n        }\n        if algorithm in cms_algo_map:\n            return cms_algo_map[algorithm]\n\n        raise ValueError(unwrap(\n            '''\n            Hash algorithm not known for %s\n            ''',\n            algorithm\n        ))\n\n\nclass Pbkdf2Salt(Choice):\n    _alternatives = [\n        ('specified', OctetString),\n        ('other_source', AlgorithmIdentifier),\n    ]\n\n\nclass Pbkdf2Params(Sequence):\n    _fields = [\n        ('salt', Pbkdf2Salt),\n        ('iteration_count', Integer),\n        ('key_length', Integer, {'optional': True}),\n        ('prf', HmacAlgorithm, {'default': {'algorithm': 'sha1'}}),\n    ]\n\n\nclass ScryptParams(Sequence):\n    # https://tools.ietf.org/html/rfc7914#section-7\n    _fields = [\n        ('salt', OctetString),\n        ('cost_parameter', Integer),\n        ('block_size', Integer),\n        ('parallelization_parameter', Integer),\n        ('key_length', Integer, {'optional': True}),\n    ]\n\n\nclass KdfAlgorithmId(ObjectIdentifier):\n    _map = {\n        '1.2.840.113549.1.5.12': 'pbkdf2',\n        '1.3.6.1.4.1.11591.4.11': 'scrypt',\n    }\n\n\nclass KdfAlgorithm(Sequence):\n    _fields = [\n        ('algorithm', KdfAlgorithmId),\n        ('parameters', Any, {'optional': True}),\n    ]\n    _oid_pair = ('algorithm', 'parameters')\n    _oid_specs = {\n        'pbkdf2': Pbkdf2Params,\n        'scrypt': ScryptParams,\n    }\n\n\nclass DHParameters(Sequence):\n    \"\"\"\n    Original Name: DHParameter\n    Source: ftp://ftp.rsasecurity.com/pub/pkcs/ascii/pkcs-3.asc section 9\n    \"\"\"\n\n    _fields = [\n        ('p', Integer),\n        ('g', Integer),\n        ('private_value_length', Integer, {'optional': True}),\n    ]\n\n\nclass KeyExchangeAlgorithmId(ObjectIdentifier):\n    _map = {\n        '1.2.840.113549.1.3.1': 'dh',\n    }\n\n\nclass KeyExchangeAlgorithm(Sequence):\n    _fields = [\n        ('algorithm', KeyExchangeAlgorithmId),\n        ('parameters', Any, {'optional': True}),\n    ]\n    _oid_pair = ('algorithm', 'parameters')\n    _oid_specs = {\n        'dh': DHParameters,\n    }\n\n\nclass Rc2Params(Sequence):\n    _fields = [\n        ('rc2_parameter_version', Integer, {'optional': True}),\n        ('iv', OctetString),\n    ]\n\n\nclass Rc5ParamVersion(Integer):\n    _map = {\n        16: 'v1-0'\n    }\n\n\nclass Rc5Params(Sequence):\n    _fields = [\n        ('version', Rc5ParamVersion),\n        ('rounds', Integer),\n        ('block_size_in_bits', Integer),\n        ('iv', OctetString, {'optional': True}),\n    ]\n\n\nclass Pbes1Params(Sequence):\n    _fields = [\n        ('salt', OctetString),\n        ('iterations', Integer),\n    ]\n\n\nclass CcmParams(Sequence):\n    # https://tools.ietf.org/html/rfc5084\n    # aes_ICVlen: 4 | 6 | 8 | 10 | 12 | 14 | 16\n    _fields = [\n        ('aes_nonce', OctetString),\n        ('aes_icvlen', Integer),\n    ]\n\n\nclass PSourceAlgorithmId(ObjectIdentifier):\n    _map = {\n        '1.2.840.113549.1.1.9': 'p_specified',\n    }\n\n\nclass PSourceAlgorithm(Sequence):\n    _fields = [\n        ('algorithm', PSourceAlgorithmId),\n        ('parameters', Any, {'optional': True}),\n    ]\n\n    _oid_pair = ('algorithm', 'parameters')\n    _oid_specs = {\n        'p_specified': OctetString\n    }\n\n\nclass RSAESOAEPParams(Sequence):\n    _fields = [\n        (\n            'hash_algorithm',\n            DigestAlgorithm,\n            {\n                'explicit': 0,\n                'default': {'algorithm': 'sha1'}\n            }\n        ),\n        (\n            'mask_gen_algorithm',\n            MaskGenAlgorithm,\n            {\n                'explicit': 1,\n                'default': {\n                    'algorithm': 'mgf1',\n                    'parameters': {'algorithm': 'sha1'}\n                }\n            }\n        ),\n        (\n            'p_source_algorithm',\n            PSourceAlgorithm,\n            {\n                'explicit': 2,\n                'default': {\n                    'algorithm': 'p_specified',\n                    'parameters': b''\n                }\n            }\n        ),\n    ]\n\n\nclass DSASignature(Sequence):\n    \"\"\"\n    An ASN.1 class for translating between the OS crypto library's\n    representation of an (EC)DSA signature and the ASN.1 structure that is part\n    of various RFCs.\n\n    Original Name: DSS-Sig-Value\n    Source: https://tools.ietf.org/html/rfc3279#section-2.2.2\n    \"\"\"\n\n    _fields = [\n        ('r', Integer),\n        ('s', Integer),\n    ]\n\n    @classmethod\n    def from_p1363(cls, data):\n        \"\"\"\n        Reads a signature from a byte string encoding accordint to IEEE P1363,\n        which is used by Microsoft's BCryptSignHash() function.\n\n        :param data:\n            A byte string from BCryptSignHash()\n\n        :return:\n            A DSASignature object\n        \"\"\"\n\n        r = int_from_bytes(data[0:len(data) // 2])\n        s = int_from_bytes(data[len(data) // 2:])\n        return cls({'r': r, 's': s})\n\n    def to_p1363(self):\n        \"\"\"\n        Dumps a signature to a byte string compatible with Microsoft's\n        BCryptVerifySignature() function.\n\n        :return:\n            A byte string compatible with BCryptVerifySignature()\n        \"\"\"\n\n        r_bytes = int_to_bytes(self['r'].native)\n        s_bytes = int_to_bytes(self['s'].native)\n\n        int_byte_length = max(len(r_bytes), len(s_bytes))\n        r_bytes = fill_width(r_bytes, int_byte_length)\n        s_bytes = fill_width(s_bytes, int_byte_length)\n\n        return r_bytes + s_bytes\n\n\nclass EncryptionAlgorithmId(ObjectIdentifier):\n    _map = {\n        '1.3.14.3.2.7': 'des',\n        '1.2.840.113549.3.7': 'tripledes_3key',\n        '1.2.840.113549.3.2': 'rc2',\n        '1.2.840.113549.3.4': 'rc4',\n        '1.2.840.113549.3.9': 'rc5',\n        # From http://csrc.nist.gov/groups/ST/crypto_apps_infra/csor/algorithms.html#AES\n        '2.16.840.1.101.3.4.1.1': 'aes128_ecb',\n        '2.16.840.1.101.3.4.1.2': 'aes128_cbc',\n        '2.16.840.1.101.3.4.1.3': 'aes128_ofb',\n        '2.16.840.1.101.3.4.1.4': 'aes128_cfb',\n        '2.16.840.1.101.3.4.1.5': 'aes128_wrap',\n        '2.16.840.1.101.3.4.1.6': 'aes128_gcm',\n        '2.16.840.1.101.3.4.1.7': 'aes128_ccm',\n        '2.16.840.1.101.3.4.1.8': 'aes128_wrap_pad',\n        '2.16.840.1.101.3.4.1.21': 'aes192_ecb',\n        '2.16.840.1.101.3.4.1.22': 'aes192_cbc',\n        '2.16.840.1.101.3.4.1.23': 'aes192_ofb',\n        '2.16.840.1.101.3.4.1.24': 'aes192_cfb',\n        '2.16.840.1.101.3.4.1.25': 'aes192_wrap',\n        '2.16.840.1.101.3.4.1.26': 'aes192_gcm',\n        '2.16.840.1.101.3.4.1.27': 'aes192_ccm',\n        '2.16.840.1.101.3.4.1.28': 'aes192_wrap_pad',\n        '2.16.840.1.101.3.4.1.41': 'aes256_ecb',\n        '2.16.840.1.101.3.4.1.42': 'aes256_cbc',\n        '2.16.840.1.101.3.4.1.43': 'aes256_ofb',\n        '2.16.840.1.101.3.4.1.44': 'aes256_cfb',\n        '2.16.840.1.101.3.4.1.45': 'aes256_wrap',\n        '2.16.840.1.101.3.4.1.46': 'aes256_gcm',\n        '2.16.840.1.101.3.4.1.47': 'aes256_ccm',\n        '2.16.840.1.101.3.4.1.48': 'aes256_wrap_pad',\n        # From PKCS#5\n        '1.2.840.113549.1.5.13': 'pbes2',\n        '1.2.840.113549.1.5.1': 'pbes1_md2_des',\n        '1.2.840.113549.1.5.3': 'pbes1_md5_des',\n        '1.2.840.113549.1.5.4': 'pbes1_md2_rc2',\n        '1.2.840.113549.1.5.6': 'pbes1_md5_rc2',\n        '1.2.840.113549.1.5.10': 'pbes1_sha1_des',\n        '1.2.840.113549.1.5.11': 'pbes1_sha1_rc2',\n        # From PKCS#12\n        '1.2.840.113549.1.12.1.1': 'pkcs12_sha1_rc4_128',\n        '1.2.840.113549.1.12.1.2': 'pkcs12_sha1_rc4_40',\n        '1.2.840.113549.1.12.1.3': 'pkcs12_sha1_tripledes_3key',\n        '1.2.840.113549.1.12.1.4': 'pkcs12_sha1_tripledes_2key',\n        '1.2.840.113549.1.12.1.5': 'pkcs12_sha1_rc2_128',\n        '1.2.840.113549.1.12.1.6': 'pkcs12_sha1_rc2_40',\n        # PKCS#1 v2.2\n        '1.2.840.113549.1.1.1': 'rsaes_pkcs1v15',\n        '1.2.840.113549.1.1.7': 'rsaes_oaep',\n    }\n\n\nclass EncryptionAlgorithm(_ForceNullParameters, Sequence):\n    _fields = [\n        ('algorithm', EncryptionAlgorithmId),\n        ('parameters', Any, {'optional': True}),\n    ]\n\n    _oid_pair = ('algorithm', 'parameters')\n    _oid_specs = {\n        'des': OctetString,\n        'tripledes_3key': OctetString,\n        'rc2': Rc2Params,\n        'rc5': Rc5Params,\n        'aes128_cbc': OctetString,\n        'aes192_cbc': OctetString,\n        'aes256_cbc': OctetString,\n        'aes128_ofb': OctetString,\n        'aes192_ofb': OctetString,\n        'aes256_ofb': OctetString,\n        # From RFC5084\n        'aes128_ccm': CcmParams,\n        'aes192_ccm': CcmParams,\n        'aes256_ccm': CcmParams,\n        # From PKCS#5\n        'pbes1_md2_des': Pbes1Params,\n        'pbes1_md5_des': Pbes1Params,\n        'pbes1_md2_rc2': Pbes1Params,\n        'pbes1_md5_rc2': Pbes1Params,\n        'pbes1_sha1_des': Pbes1Params,\n        'pbes1_sha1_rc2': Pbes1Params,\n        # From PKCS#12\n        'pkcs12_sha1_rc4_128': Pbes1Params,\n        'pkcs12_sha1_rc4_40': Pbes1Params,\n        'pkcs12_sha1_tripledes_3key': Pbes1Params,\n        'pkcs12_sha1_tripledes_2key': Pbes1Params,\n        'pkcs12_sha1_rc2_128': Pbes1Params,\n        'pkcs12_sha1_rc2_40': Pbes1Params,\n        # PKCS#1 v2.2\n        'rsaes_oaep': RSAESOAEPParams,\n    }\n\n    @property\n    def kdf(self):\n        \"\"\"\n        Returns the name of the key derivation function to use.\n\n        :return:\n            A unicode from of one of the following: \"pbkdf1\", \"pbkdf2\",\n            \"pkcs12_kdf\"\n        \"\"\"\n\n        encryption_algo = self['algorithm'].native\n\n        if encryption_algo == 'pbes2':\n            return self['parameters']['key_derivation_func']['algorithm'].native\n\n        if encryption_algo.find('.') == -1:\n            if encryption_algo.find('_') != -1:\n                encryption_algo, _ = encryption_algo.split('_', 1)\n\n                if encryption_algo == 'pbes1':\n                    return 'pbkdf1'\n\n                if encryption_algo == 'pkcs12':\n                    return 'pkcs12_kdf'\n\n            raise ValueError(unwrap(\n                '''\n                Encryption algorithm \"%s\" does not have a registered key\n                derivation function\n                ''',\n                encryption_algo\n            ))\n\n        raise ValueError(unwrap(\n            '''\n            Unrecognized encryption algorithm \"%s\", can not determine key\n            derivation function\n            ''',\n            encryption_algo\n        ))\n\n    @property\n    def kdf_hmac(self):\n        \"\"\"\n        Returns the HMAC algorithm to use with the KDF.\n\n        :return:\n            A unicode string of one of the following: \"md2\", \"md5\", \"sha1\",\n            \"sha224\", \"sha256\", \"sha384\", \"sha512\"\n        \"\"\"\n\n        encryption_algo = self['algorithm'].native\n\n        if encryption_algo == 'pbes2':\n            if self.kdf == 'scrypt':\n                return None\n            return self['parameters']['key_derivation_func']['parameters']['prf']['algorithm'].native\n\n        if encryption_algo.find('.') == -1:\n            if encryption_algo.find('_') != -1:\n                _, hmac_algo, _ = encryption_algo.split('_', 2)\n                return hmac_algo\n\n            raise ValueError(unwrap(\n                '''\n                Encryption algorithm \"%s\" does not have a registered key\n                derivation function\n                ''',\n                encryption_algo\n            ))\n\n        raise ValueError(unwrap(\n            '''\n            Unrecognized encryption algorithm \"%s\", can not determine key\n            derivation hmac algorithm\n            ''',\n            encryption_algo\n        ))\n\n    @property\n    def kdf_salt(self):\n        \"\"\"\n        Returns the byte string to use as the salt for the KDF.\n\n        :return:\n            A byte string\n        \"\"\"\n\n        encryption_algo = self['algorithm'].native\n\n        if encryption_algo == 'pbes2':\n            salt = self['parameters']['key_derivation_func']['parameters']['salt']\n\n            if salt.name == 'other_source':\n                raise ValueError(unwrap(\n                    '''\n                    Can not determine key derivation salt - the\n                    reserved-for-future-use other source salt choice was\n                    specified in the PBKDF2 params structure\n                    '''\n                ))\n\n            return salt.native\n\n        if encryption_algo.find('.') == -1:\n            if encryption_algo.find('_') != -1:\n                return self['parameters']['salt'].native\n\n            raise ValueError(unwrap(\n                '''\n                Encryption algorithm \"%s\" does not have a registered key\n                derivation function\n                ''',\n                encryption_algo\n            ))\n\n        raise ValueError(unwrap(\n            '''\n            Unrecognized encryption algorithm \"%s\", can not determine key\n            derivation salt\n            ''',\n            encryption_algo\n        ))\n\n    @property\n    def kdf_iterations(self):\n        \"\"\"\n        Returns the number of iterations that should be run via the KDF.\n\n        :return:\n            An integer\n        \"\"\"\n\n        encryption_algo = self['algorithm'].native\n\n        if encryption_algo == 'pbes2':\n            if self.kdf == 'scrypt':\n                return None\n            return self['parameters']['key_derivation_func']['parameters']['iteration_count'].native\n\n        if encryption_algo.find('.') == -1:\n            if encryption_algo.find('_') != -1:\n                return self['parameters']['iterations'].native\n\n            raise ValueError(unwrap(\n                '''\n                Encryption algorithm \"%s\" does not have a registered key\n                derivation function\n                ''',\n                encryption_algo\n            ))\n\n        raise ValueError(unwrap(\n            '''\n            Unrecognized encryption algorithm \"%s\", can not determine key\n            derivation iterations\n            ''',\n            encryption_algo\n        ))\n\n    @property\n    def key_length(self):\n        \"\"\"\n        Returns the key length to pass to the cipher/kdf. The PKCS#5 spec does\n        not specify a way to store the RC5 key length, however this tends not\n        to be a problem since OpenSSL does not support RC5 in PKCS#8 and OS X\n        does not provide an RC5 cipher for use in the Security Transforms\n        library.\n\n        :raises:\n            ValueError - when the key length can not be determined\n\n        :return:\n            An integer representing the length in bytes\n        \"\"\"\n\n        encryption_algo = self['algorithm'].native\n\n        if encryption_algo[0:3] == 'aes':\n            return {\n                'aes128_': 16,\n                'aes192_': 24,\n                'aes256_': 32,\n            }[encryption_algo[0:7]]\n\n        cipher_lengths = {\n            'des': 8,\n            'tripledes_3key': 24,\n        }\n\n        if encryption_algo in cipher_lengths:\n            return cipher_lengths[encryption_algo]\n\n        if encryption_algo == 'rc2':\n            rc2_parameter_version = self['parameters']['rc2_parameter_version'].native\n\n            # See page 24 of\n            # http://www.emc.com/collateral/white-papers/h11302-pkcs5v2-1-password-based-cryptography-standard-wp.pdf\n            encoded_key_bits_map = {\n                160: 5,   # 40-bit\n                120: 8,   # 64-bit\n                58: 16,   # 128-bit\n            }\n\n            if rc2_parameter_version in encoded_key_bits_map:\n                return encoded_key_bits_map[rc2_parameter_version]\n\n            if rc2_parameter_version >= 256:\n                return rc2_parameter_version\n\n            if rc2_parameter_version is None:\n                return 4  # 32-bit default\n\n            raise ValueError(unwrap(\n                '''\n                Invalid RC2 parameter version found in EncryptionAlgorithm\n                parameters\n                '''\n            ))\n\n        if encryption_algo == 'pbes2':\n            key_length = self['parameters']['key_derivation_func']['parameters']['key_length'].native\n            if key_length is not None:\n                return key_length\n\n            # If the KDF params don't specify the key size, we can infer it from\n            # the encryption scheme for all schemes except for RC5. However, in\n            # practical terms, neither OpenSSL or OS X support RC5 for PKCS#8\n            # so it is unlikely to be an issue that is run into.\n\n            return self['parameters']['encryption_scheme'].key_length\n\n        if encryption_algo.find('.') == -1:\n            return {\n                'pbes1_md2_des': 8,\n                'pbes1_md5_des': 8,\n                'pbes1_md2_rc2': 8,\n                'pbes1_md5_rc2': 8,\n                'pbes1_sha1_des': 8,\n                'pbes1_sha1_rc2': 8,\n                'pkcs12_sha1_rc4_128': 16,\n                'pkcs12_sha1_rc4_40': 5,\n                'pkcs12_sha1_tripledes_3key': 24,\n                'pkcs12_sha1_tripledes_2key': 16,\n                'pkcs12_sha1_rc2_128': 16,\n                'pkcs12_sha1_rc2_40': 5,\n            }[encryption_algo]\n\n        raise ValueError(unwrap(\n            '''\n            Unrecognized encryption algorithm \"%s\"\n            ''',\n            encryption_algo\n        ))\n\n    @property\n    def encryption_mode(self):\n        \"\"\"\n        Returns the name of the encryption mode to use.\n\n        :return:\n            A unicode string from one of the following: \"cbc\", \"ecb\", \"ofb\",\n            \"cfb\", \"wrap\", \"gcm\", \"ccm\", \"wrap_pad\"\n        \"\"\"\n\n        encryption_algo = self['algorithm'].native\n\n        if encryption_algo[0:7] in set(['aes128_', 'aes192_', 'aes256_']):\n            return encryption_algo[7:]\n\n        if encryption_algo[0:6] == 'pbes1_':\n            return 'cbc'\n\n        if encryption_algo[0:7] == 'pkcs12_':\n            return 'cbc'\n\n        if encryption_algo in set(['des', 'tripledes_3key', 'rc2', 'rc5']):\n            return 'cbc'\n\n        if encryption_algo == 'pbes2':\n            return self['parameters']['encryption_scheme'].encryption_mode\n\n        raise ValueError(unwrap(\n            '''\n            Unrecognized encryption algorithm \"%s\"\n            ''',\n            encryption_algo\n        ))\n\n    @property\n    def encryption_cipher(self):\n        \"\"\"\n        Returns the name of the symmetric encryption cipher to use. The key\n        length can be retrieved via the .key_length property to disabiguate\n        between different variations of TripleDES, AES, and the RC* ciphers.\n\n        :return:\n            A unicode string from one of the following: \"rc2\", \"rc5\", \"des\",\n            \"tripledes\", \"aes\"\n        \"\"\"\n\n        encryption_algo = self['algorithm'].native\n\n        if encryption_algo[0:7] in set(['aes128_', 'aes192_', 'aes256_']):\n            return 'aes'\n\n        if encryption_algo in set(['des', 'rc2', 'rc5']):\n            return encryption_algo\n\n        if encryption_algo == 'tripledes_3key':\n            return 'tripledes'\n\n        if encryption_algo == 'pbes2':\n            return self['parameters']['encryption_scheme'].encryption_cipher\n\n        if encryption_algo.find('.') == -1:\n            return {\n                'pbes1_md2_des': 'des',\n                'pbes1_md5_des': 'des',\n                'pbes1_md2_rc2': 'rc2',\n                'pbes1_md5_rc2': 'rc2',\n                'pbes1_sha1_des': 'des',\n                'pbes1_sha1_rc2': 'rc2',\n                'pkcs12_sha1_rc4_128': 'rc4',\n                'pkcs12_sha1_rc4_40': 'rc4',\n                'pkcs12_sha1_tripledes_3key': 'tripledes',\n                'pkcs12_sha1_tripledes_2key': 'tripledes',\n                'pkcs12_sha1_rc2_128': 'rc2',\n                'pkcs12_sha1_rc2_40': 'rc2',\n            }[encryption_algo]\n\n        raise ValueError(unwrap(\n            '''\n            Unrecognized encryption algorithm \"%s\"\n            ''',\n            encryption_algo\n        ))\n\n    @property\n    def encryption_block_size(self):\n        \"\"\"\n        Returns the block size of the encryption cipher, in bytes.\n\n        :return:\n            An integer that is the block size in bytes\n        \"\"\"\n\n        encryption_algo = self['algorithm'].native\n\n        if encryption_algo[0:7] in set(['aes128_', 'aes192_', 'aes256_']):\n            return 16\n\n        cipher_map = {\n            'des': 8,\n            'tripledes_3key': 8,\n            'rc2': 8,\n        }\n        if encryption_algo in cipher_map:\n            return cipher_map[encryption_algo]\n\n        if encryption_algo == 'rc5':\n            return self['parameters']['block_size_in_bits'].native // 8\n\n        if encryption_algo == 'pbes2':\n            return self['parameters']['encryption_scheme'].encryption_block_size\n\n        if encryption_algo.find('.') == -1:\n            return {\n                'pbes1_md2_des': 8,\n                'pbes1_md5_des': 8,\n                'pbes1_md2_rc2': 8,\n                'pbes1_md5_rc2': 8,\n                'pbes1_sha1_des': 8,\n                'pbes1_sha1_rc2': 8,\n                'pkcs12_sha1_rc4_128': 0,\n                'pkcs12_sha1_rc4_40': 0,\n                'pkcs12_sha1_tripledes_3key': 8,\n                'pkcs12_sha1_tripledes_2key': 8,\n                'pkcs12_sha1_rc2_128': 8,\n                'pkcs12_sha1_rc2_40': 8,\n            }[encryption_algo]\n\n        raise ValueError(unwrap(\n            '''\n            Unrecognized encryption algorithm \"%s\"\n            ''',\n            encryption_algo\n        ))\n\n    @property\n    def encryption_iv(self):\n        \"\"\"\n        Returns the byte string of the initialization vector for the encryption\n        scheme. Only the PBES2 stores the IV in the params. For PBES1, the IV\n        is derived from the KDF and this property will return None.\n\n        :return:\n            A byte string or None\n        \"\"\"\n\n        encryption_algo = self['algorithm'].native\n\n        if encryption_algo in set(['rc2', 'rc5']):\n            return self['parameters']['iv'].native\n\n        # For DES/Triple DES and AES the IV is the entirety of the parameters\n        octet_string_iv_oids = set([\n            'des',\n            'tripledes_3key',\n            'aes128_cbc',\n            'aes192_cbc',\n            'aes256_cbc',\n            'aes128_ofb',\n            'aes192_ofb',\n            'aes256_ofb',\n        ])\n        if encryption_algo in octet_string_iv_oids:\n            return self['parameters'].native\n\n        if encryption_algo == 'pbes2':\n            return self['parameters']['encryption_scheme'].encryption_iv\n\n        # All of the PBES1 algos use their KDF to create the IV. For the pbkdf1,\n        # the KDF is told to generate a key that is an extra 8 bytes long, and\n        # that is used for the IV. For the PKCS#12 KDF, it is called with an id\n        # of 2 to generate the IV. In either case, we can't return the IV\n        # without knowing the user's password.\n        if encryption_algo.find('.') == -1:\n            return None\n\n        raise ValueError(unwrap(\n            '''\n            Unrecognized encryption algorithm \"%s\"\n            ''',\n            encryption_algo\n        ))\n\n\nclass Pbes2Params(Sequence):\n    _fields = [\n        ('key_derivation_func', KdfAlgorithm),\n        ('encryption_scheme', EncryptionAlgorithm),\n    ]\n\n\nclass Pbmac1Params(Sequence):\n    _fields = [\n        ('key_derivation_func', KdfAlgorithm),\n        ('message_auth_scheme', HmacAlgorithm),\n    ]\n\n\nclass Pkcs5MacId(ObjectIdentifier):\n    _map = {\n        '1.2.840.113549.1.5.14': 'pbmac1',\n    }\n\n\nclass Pkcs5MacAlgorithm(Sequence):\n    _fields = [\n        ('algorithm', Pkcs5MacId),\n        ('parameters', Any),\n    ]\n\n    _oid_pair = ('algorithm', 'parameters')\n    _oid_specs = {\n        'pbmac1': Pbmac1Params,\n    }\n\n\nEncryptionAlgorithm._oid_specs['pbes2'] = Pbes2Params\n\n\nclass AnyAlgorithmId(ObjectIdentifier):\n    _map = {}\n\n    def _setup(self):\n        _map = self.__class__._map\n        for other_cls in (EncryptionAlgorithmId, SignedDigestAlgorithmId, DigestAlgorithmId):\n            for oid, name in other_cls._map.items():\n                _map[oid] = name\n\n\nclass AnyAlgorithmIdentifier(_ForceNullParameters, Sequence):\n    _fields = [\n        ('algorithm', AnyAlgorithmId),\n        ('parameters', Any, {'optional': True}),\n    ]\n\n    _oid_pair = ('algorithm', 'parameters')\n    _oid_specs = {}\n\n    def _setup(self):\n        Sequence._setup(self)\n        specs = self.__class__._oid_specs\n        for other_cls in (EncryptionAlgorithm, SignedDigestAlgorithm):\n            for oid, spec in other_cls._oid_specs.items():\n                specs[oid] = spec\n", "asn1crypto/pem.py": "# coding: utf-8\n\n\"\"\"\nEncoding DER to PEM and decoding PEM to DER. Exports the following items:\n\n - armor()\n - detect()\n - unarmor()\n\n\"\"\"\n\nfrom __future__ import unicode_literals, division, absolute_import, print_function\n\nimport base64\nimport re\nimport sys\n\nfrom ._errors import unwrap\nfrom ._types import type_name as _type_name, str_cls, byte_cls\n\nif sys.version_info < (3,):\n    from cStringIO import StringIO as BytesIO\nelse:\n    from io import BytesIO\n\n\ndef detect(byte_string):\n    \"\"\"\n    Detect if a byte string seems to contain a PEM-encoded block\n\n    :param byte_string:\n        A byte string to look through\n\n    :return:\n        A boolean, indicating if a PEM-encoded block is contained in the byte\n        string\n    \"\"\"\n\n    if not isinstance(byte_string, byte_cls):\n        raise TypeError(unwrap(\n            '''\n            byte_string must be a byte string, not %s\n            ''',\n            _type_name(byte_string)\n        ))\n\n    return byte_string.find(b'-----BEGIN') != -1 or byte_string.find(b'---- BEGIN') != -1\n\n\ndef armor(type_name, der_bytes, headers=None):\n    \"\"\"\n    Armors a DER-encoded byte string in PEM\n\n    :param type_name:\n        A unicode string that will be capitalized and placed in the header\n        and footer of the block. E.g. \"CERTIFICATE\", \"PRIVATE KEY\", etc. This\n        will appear as \"-----BEGIN CERTIFICATE-----\" and\n        \"-----END CERTIFICATE-----\".\n\n    :param der_bytes:\n        A byte string to be armored\n\n    :param headers:\n        An OrderedDict of the header lines to write after the BEGIN line\n\n    :return:\n        A byte string of the PEM block\n    \"\"\"\n\n    if not isinstance(der_bytes, byte_cls):\n        raise TypeError(unwrap(\n            '''\n            der_bytes must be a byte string, not %s\n            ''' % _type_name(der_bytes)\n        ))\n\n    if not isinstance(type_name, str_cls):\n        raise TypeError(unwrap(\n            '''\n            type_name must be a unicode string, not %s\n            ''',\n            _type_name(type_name)\n        ))\n\n    type_name = type_name.upper().encode('ascii')\n\n    output = BytesIO()\n    output.write(b'-----BEGIN ')\n    output.write(type_name)\n    output.write(b'-----\\n')\n    if headers:\n        for key in headers:\n            output.write(key.encode('ascii'))\n            output.write(b': ')\n            output.write(headers[key].encode('ascii'))\n            output.write(b'\\n')\n        output.write(b'\\n')\n    b64_bytes = base64.b64encode(der_bytes)\n    b64_len = len(b64_bytes)\n    i = 0\n    while i < b64_len:\n        output.write(b64_bytes[i:i + 64])\n        output.write(b'\\n')\n        i += 64\n    output.write(b'-----END ')\n    output.write(type_name)\n    output.write(b'-----\\n')\n\n    return output.getvalue()\n\n\ndef _unarmor(pem_bytes):\n    \"\"\"\n    Convert a PEM-encoded byte string into one or more DER-encoded byte strings\n\n    :param pem_bytes:\n        A byte string of the PEM-encoded data\n\n    :raises:\n        ValueError - when the pem_bytes do not appear to be PEM-encoded bytes\n\n    :return:\n        A generator of 3-element tuples in the format: (object_type, headers,\n        der_bytes). The object_type is a unicode string of what is between\n        \"-----BEGIN \" and \"-----\". Examples include: \"CERTIFICATE\",\n        \"PUBLIC KEY\", \"PRIVATE KEY\". The headers is a dict containing any lines\n        in the form \"Name: Value\" that are right after the begin line.\n    \"\"\"\n\n    if not isinstance(pem_bytes, byte_cls):\n        raise TypeError(unwrap(\n            '''\n            pem_bytes must be a byte string, not %s\n            ''',\n            _type_name(pem_bytes)\n        ))\n\n    # Valid states include: \"trash\", \"headers\", \"body\"\n    state = 'trash'\n    headers = {}\n    base64_data = b''\n    object_type = None\n\n    found_start = False\n    found_end = False\n\n    for line in pem_bytes.splitlines(False):\n        if line == b'':\n            continue\n\n        if state == \"trash\":\n            # Look for a starting line since some CA cert bundle show the cert\n            # into in a parsed format above each PEM block\n            type_name_match = re.match(b'^(?:---- |-----)BEGIN ([A-Z0-9 ]+)(?: ----|-----)', line)\n            if not type_name_match:\n                continue\n            object_type = type_name_match.group(1).decode('ascii')\n\n            found_start = True\n            state = 'headers'\n            continue\n\n        if state == 'headers':\n            if line.find(b':') == -1:\n                state = 'body'\n            else:\n                decoded_line = line.decode('ascii')\n                name, value = decoded_line.split(':', 1)\n                headers[name] = value.strip()\n                continue\n\n        if state == 'body':\n            if line[0:5] in (b'-----', b'---- '):\n                der_bytes = base64.b64decode(base64_data)\n\n                yield (object_type, headers, der_bytes)\n\n                state = 'trash'\n                headers = {}\n                base64_data = b''\n                object_type = None\n                found_end = True\n                continue\n\n            base64_data += line\n\n    if not found_start or not found_end:\n        raise ValueError(unwrap(\n            '''\n            pem_bytes does not appear to contain PEM-encoded data - no\n            BEGIN/END combination found\n            '''\n        ))\n\n\ndef unarmor(pem_bytes, multiple=False):\n    \"\"\"\n    Convert a PEM-encoded byte string into a DER-encoded byte string\n\n    :param pem_bytes:\n        A byte string of the PEM-encoded data\n\n    :param multiple:\n        If True, function will return a generator\n\n    :raises:\n        ValueError - when the pem_bytes do not appear to be PEM-encoded bytes\n\n    :return:\n        A 3-element tuple (object_name, headers, der_bytes). The object_name is\n        a unicode string of what is between \"-----BEGIN \" and \"-----\". Examples\n        include: \"CERTIFICATE\", \"PUBLIC KEY\", \"PRIVATE KEY\". The headers is a\n        dict containing any lines in the form \"Name: Value\" that are right\n        after the begin line.\n    \"\"\"\n\n    generator = _unarmor(pem_bytes)\n\n    if not multiple:\n        return next(generator)\n\n    return generator\n", "asn1crypto/keys.py": "# coding: utf-8\n\n\"\"\"\nASN.1 type classes for public and private keys. Exports the following items:\n\n - DSAPrivateKey()\n - ECPrivateKey()\n - EncryptedPrivateKeyInfo()\n - PrivateKeyInfo()\n - PublicKeyInfo()\n - RSAPrivateKey()\n - RSAPublicKey()\n\nOther type classes are defined that help compose the types listed above.\n\"\"\"\n\nfrom __future__ import unicode_literals, division, absolute_import, print_function\n\nimport hashlib\nimport math\n\nfrom ._errors import unwrap, APIException\nfrom ._types import type_name, byte_cls\nfrom .algos import _ForceNullParameters, DigestAlgorithm, EncryptionAlgorithm, RSAESOAEPParams, RSASSAPSSParams\nfrom .core import (\n    Any,\n    Asn1Value,\n    BitString,\n    Choice,\n    Integer,\n    IntegerOctetString,\n    Null,\n    ObjectIdentifier,\n    OctetBitString,\n    OctetString,\n    ParsableOctetString,\n    ParsableOctetBitString,\n    Sequence,\n    SequenceOf,\n    SetOf,\n)\nfrom .util import int_from_bytes, int_to_bytes\n\n\nclass OtherPrimeInfo(Sequence):\n    \"\"\"\n    Source: https://tools.ietf.org/html/rfc3447#page-46\n    \"\"\"\n\n    _fields = [\n        ('prime', Integer),\n        ('exponent', Integer),\n        ('coefficient', Integer),\n    ]\n\n\nclass OtherPrimeInfos(SequenceOf):\n    \"\"\"\n    Source: https://tools.ietf.org/html/rfc3447#page-46\n    \"\"\"\n\n    _child_spec = OtherPrimeInfo\n\n\nclass RSAPrivateKeyVersion(Integer):\n    \"\"\"\n    Original Name: Version\n    Source: https://tools.ietf.org/html/rfc3447#page-45\n    \"\"\"\n\n    _map = {\n        0: 'two-prime',\n        1: 'multi',\n    }\n\n\nclass RSAPrivateKey(Sequence):\n    \"\"\"\n    Source: https://tools.ietf.org/html/rfc3447#page-45\n    \"\"\"\n\n    _fields = [\n        ('version', RSAPrivateKeyVersion),\n        ('modulus', Integer),\n        ('public_exponent', Integer),\n        ('private_exponent', Integer),\n        ('prime1', Integer),\n        ('prime2', Integer),\n        ('exponent1', Integer),\n        ('exponent2', Integer),\n        ('coefficient', Integer),\n        ('other_prime_infos', OtherPrimeInfos, {'optional': True})\n    ]\n\n\nclass RSAPublicKey(Sequence):\n    \"\"\"\n    Source: https://tools.ietf.org/html/rfc3447#page-44\n    \"\"\"\n\n    _fields = [\n        ('modulus', Integer),\n        ('public_exponent', Integer)\n    ]\n\n\nclass DSAPrivateKey(Sequence):\n    \"\"\"\n    The ASN.1 structure that OpenSSL uses to store a DSA private key that is\n    not part of a PKCS#8 structure. Reversed engineered from english-language\n    description on linked OpenSSL documentation page.\n\n    Original Name: None\n    Source: https://www.openssl.org/docs/apps/dsa.html\n    \"\"\"\n\n    _fields = [\n        ('version', Integer),\n        ('p', Integer),\n        ('q', Integer),\n        ('g', Integer),\n        ('public_key', Integer),\n        ('private_key', Integer),\n    ]\n\n\nclass _ECPoint():\n    \"\"\"\n    In both PublicKeyInfo and PrivateKeyInfo, the EC public key is a byte\n    string that is encoded as a bit string. This class adds convenience\n    methods for converting to and from the byte string to a pair of integers\n    that are the X and Y coordinates.\n    \"\"\"\n\n    @classmethod\n    def from_coords(cls, x, y):\n        \"\"\"\n        Creates an ECPoint object from the X and Y integer coordinates of the\n        point\n\n        :param x:\n            The X coordinate, as an integer\n\n        :param y:\n            The Y coordinate, as an integer\n\n        :return:\n            An ECPoint object\n        \"\"\"\n\n        x_bytes = int(math.ceil(math.log(x, 2) / 8.0))\n        y_bytes = int(math.ceil(math.log(y, 2) / 8.0))\n\n        num_bytes = max(x_bytes, y_bytes)\n\n        byte_string = b'\\x04'\n        byte_string += int_to_bytes(x, width=num_bytes)\n        byte_string += int_to_bytes(y, width=num_bytes)\n\n        return cls(byte_string)\n\n    def to_coords(self):\n        \"\"\"\n        Returns the X and Y coordinates for this EC point, as native Python\n        integers\n\n        :return:\n            A 2-element tuple containing integers (X, Y)\n        \"\"\"\n\n        data = self.native\n        first_byte = data[0:1]\n\n        # Uncompressed\n        if first_byte == b'\\x04':\n            remaining = data[1:]\n            field_len = len(remaining) // 2\n            x = int_from_bytes(remaining[0:field_len])\n            y = int_from_bytes(remaining[field_len:])\n            return (x, y)\n\n        if first_byte not in set([b'\\x02', b'\\x03']):\n            raise ValueError(unwrap(\n                '''\n                Invalid EC public key - first byte is incorrect\n                '''\n            ))\n\n        raise ValueError(unwrap(\n            '''\n            Compressed representations of EC public keys are not supported due\n            to patent US6252960\n            '''\n        ))\n\n\nclass ECPoint(OctetString, _ECPoint):\n\n    pass\n\n\nclass ECPointBitString(OctetBitString, _ECPoint):\n\n    pass\n\n\nclass SpecifiedECDomainVersion(Integer):\n    \"\"\"\n    Source: http://www.secg.org/sec1-v2.pdf page 104\n    \"\"\"\n    _map = {\n        1: 'ecdpVer1',\n        2: 'ecdpVer2',\n        3: 'ecdpVer3',\n    }\n\n\nclass FieldType(ObjectIdentifier):\n    \"\"\"\n    Original Name: None\n    Source: http://www.secg.org/sec1-v2.pdf page 101\n    \"\"\"\n\n    _map = {\n        '1.2.840.10045.1.1': 'prime_field',\n        '1.2.840.10045.1.2': 'characteristic_two_field',\n    }\n\n\nclass CharacteristicTwoBasis(ObjectIdentifier):\n    \"\"\"\n    Original Name: None\n    Source: http://www.secg.org/sec1-v2.pdf page 102\n    \"\"\"\n\n    _map = {\n        '1.2.840.10045.1.2.1.1': 'gn_basis',\n        '1.2.840.10045.1.2.1.2': 'tp_basis',\n        '1.2.840.10045.1.2.1.3': 'pp_basis',\n    }\n\n\nclass Pentanomial(Sequence):\n    \"\"\"\n    Source: http://www.secg.org/sec1-v2.pdf page 102\n    \"\"\"\n\n    _fields = [\n        ('k1', Integer),\n        ('k2', Integer),\n        ('k3', Integer),\n    ]\n\n\nclass CharacteristicTwo(Sequence):\n    \"\"\"\n    Original Name: Characteristic-two\n    Source: http://www.secg.org/sec1-v2.pdf page 101\n    \"\"\"\n\n    _fields = [\n        ('m', Integer),\n        ('basis', CharacteristicTwoBasis),\n        ('parameters', Any),\n    ]\n\n    _oid_pair = ('basis', 'parameters')\n    _oid_specs = {\n        'gn_basis': Null,\n        'tp_basis': Integer,\n        'pp_basis': Pentanomial,\n    }\n\n\nclass FieldID(Sequence):\n    \"\"\"\n    Source: http://www.secg.org/sec1-v2.pdf page 100\n    \"\"\"\n\n    _fields = [\n        ('field_type', FieldType),\n        ('parameters', Any),\n    ]\n\n    _oid_pair = ('field_type', 'parameters')\n    _oid_specs = {\n        'prime_field': Integer,\n        'characteristic_two_field': CharacteristicTwo,\n    }\n\n\nclass Curve(Sequence):\n    \"\"\"\n    Source: http://www.secg.org/sec1-v2.pdf page 104\n    \"\"\"\n\n    _fields = [\n        ('a', OctetString),\n        ('b', OctetString),\n        ('seed', OctetBitString, {'optional': True}),\n    ]\n\n\nclass SpecifiedECDomain(Sequence):\n    \"\"\"\n    Source: http://www.secg.org/sec1-v2.pdf page 103\n    \"\"\"\n\n    _fields = [\n        ('version', SpecifiedECDomainVersion),\n        ('field_id', FieldID),\n        ('curve', Curve),\n        ('base', ECPoint),\n        ('order', Integer),\n        ('cofactor', Integer, {'optional': True}),\n        ('hash', DigestAlgorithm, {'optional': True}),\n    ]\n\n\nclass NamedCurve(ObjectIdentifier):\n    \"\"\"\n    Various named curves\n\n    Original Name: None\n    Source: https://tools.ietf.org/html/rfc3279#page-23,\n            https://tools.ietf.org/html/rfc5480#page-5\n    \"\"\"\n\n    _map = {\n        # https://tools.ietf.org/html/rfc3279#page-23\n        '1.2.840.10045.3.0.1': 'c2pnb163v1',\n        '1.2.840.10045.3.0.2': 'c2pnb163v2',\n        '1.2.840.10045.3.0.3': 'c2pnb163v3',\n        '1.2.840.10045.3.0.4': 'c2pnb176w1',\n        '1.2.840.10045.3.0.5': 'c2tnb191v1',\n        '1.2.840.10045.3.0.6': 'c2tnb191v2',\n        '1.2.840.10045.3.0.7': 'c2tnb191v3',\n        '1.2.840.10045.3.0.8': 'c2onb191v4',\n        '1.2.840.10045.3.0.9': 'c2onb191v5',\n        '1.2.840.10045.3.0.10': 'c2pnb208w1',\n        '1.2.840.10045.3.0.11': 'c2tnb239v1',\n        '1.2.840.10045.3.0.12': 'c2tnb239v2',\n        '1.2.840.10045.3.0.13': 'c2tnb239v3',\n        '1.2.840.10045.3.0.14': 'c2onb239v4',\n        '1.2.840.10045.3.0.15': 'c2onb239v5',\n        '1.2.840.10045.3.0.16': 'c2pnb272w1',\n        '1.2.840.10045.3.0.17': 'c2pnb304w1',\n        '1.2.840.10045.3.0.18': 'c2tnb359v1',\n        '1.2.840.10045.3.0.19': 'c2pnb368w1',\n        '1.2.840.10045.3.0.20': 'c2tnb431r1',\n        '1.2.840.10045.3.1.2': 'prime192v2',\n        '1.2.840.10045.3.1.3': 'prime192v3',\n        '1.2.840.10045.3.1.4': 'prime239v1',\n        '1.2.840.10045.3.1.5': 'prime239v2',\n        '1.2.840.10045.3.1.6': 'prime239v3',\n        # https://tools.ietf.org/html/rfc5480#page-5\n        # http://www.secg.org/SEC2-Ver-1.0.pdf\n        '1.2.840.10045.3.1.1': 'secp192r1',\n        '1.2.840.10045.3.1.7': 'secp256r1',\n        '1.3.132.0.1': 'sect163k1',\n        '1.3.132.0.2': 'sect163r1',\n        '1.3.132.0.3': 'sect239k1',\n        '1.3.132.0.4': 'sect113r1',\n        '1.3.132.0.5': 'sect113r2',\n        '1.3.132.0.6': 'secp112r1',\n        '1.3.132.0.7': 'secp112r2',\n        '1.3.132.0.8': 'secp160r1',\n        '1.3.132.0.9': 'secp160k1',\n        '1.3.132.0.10': 'secp256k1',\n        '1.3.132.0.15': 'sect163r2',\n        '1.3.132.0.16': 'sect283k1',\n        '1.3.132.0.17': 'sect283r1',\n        '1.3.132.0.22': 'sect131r1',\n        '1.3.132.0.23': 'sect131r2',\n        '1.3.132.0.24': 'sect193r1',\n        '1.3.132.0.25': 'sect193r2',\n        '1.3.132.0.26': 'sect233k1',\n        '1.3.132.0.27': 'sect233r1',\n        '1.3.132.0.28': 'secp128r1',\n        '1.3.132.0.29': 'secp128r2',\n        '1.3.132.0.30': 'secp160r2',\n        '1.3.132.0.31': 'secp192k1',\n        '1.3.132.0.32': 'secp224k1',\n        '1.3.132.0.33': 'secp224r1',\n        '1.3.132.0.34': 'secp384r1',\n        '1.3.132.0.35': 'secp521r1',\n        '1.3.132.0.36': 'sect409k1',\n        '1.3.132.0.37': 'sect409r1',\n        '1.3.132.0.38': 'sect571k1',\n        '1.3.132.0.39': 'sect571r1',\n        # https://tools.ietf.org/html/rfc5639#section-4.1\n        '1.3.36.3.3.2.8.1.1.1': 'brainpoolp160r1',\n        '1.3.36.3.3.2.8.1.1.2': 'brainpoolp160t1',\n        '1.3.36.3.3.2.8.1.1.3': 'brainpoolp192r1',\n        '1.3.36.3.3.2.8.1.1.4': 'brainpoolp192t1',\n        '1.3.36.3.3.2.8.1.1.5': 'brainpoolp224r1',\n        '1.3.36.3.3.2.8.1.1.6': 'brainpoolp224t1',\n        '1.3.36.3.3.2.8.1.1.7': 'brainpoolp256r1',\n        '1.3.36.3.3.2.8.1.1.8': 'brainpoolp256t1',\n        '1.3.36.3.3.2.8.1.1.9': 'brainpoolp320r1',\n        '1.3.36.3.3.2.8.1.1.10': 'brainpoolp320t1',\n        '1.3.36.3.3.2.8.1.1.11': 'brainpoolp384r1',\n        '1.3.36.3.3.2.8.1.1.12': 'brainpoolp384t1',\n        '1.3.36.3.3.2.8.1.1.13': 'brainpoolp512r1',\n        '1.3.36.3.3.2.8.1.1.14': 'brainpoolp512t1',\n    }\n\n    _key_sizes = {\n        # Order values used to compute these sourced from\n        # http://cr.openjdk.java.net/~vinnie/7194075/webrev-3/src/share/classes/sun/security/ec/CurveDB.java.html\n        '1.2.840.10045.3.0.1': 21,\n        '1.2.840.10045.3.0.2': 21,\n        '1.2.840.10045.3.0.3': 21,\n        '1.2.840.10045.3.0.4': 21,\n        '1.2.840.10045.3.0.5': 24,\n        '1.2.840.10045.3.0.6': 24,\n        '1.2.840.10045.3.0.7': 24,\n        '1.2.840.10045.3.0.8': 24,\n        '1.2.840.10045.3.0.9': 24,\n        '1.2.840.10045.3.0.10': 25,\n        '1.2.840.10045.3.0.11': 30,\n        '1.2.840.10045.3.0.12': 30,\n        '1.2.840.10045.3.0.13': 30,\n        '1.2.840.10045.3.0.14': 30,\n        '1.2.840.10045.3.0.15': 30,\n        '1.2.840.10045.3.0.16': 33,\n        '1.2.840.10045.3.0.17': 37,\n        '1.2.840.10045.3.0.18': 45,\n        '1.2.840.10045.3.0.19': 45,\n        '1.2.840.10045.3.0.20': 53,\n        '1.2.840.10045.3.1.2': 24,\n        '1.2.840.10045.3.1.3': 24,\n        '1.2.840.10045.3.1.4': 30,\n        '1.2.840.10045.3.1.5': 30,\n        '1.2.840.10045.3.1.6': 30,\n        # Order values used to compute these sourced from\n        # http://www.secg.org/SEC2-Ver-1.0.pdf\n        # ceil(n.bit_length() / 8)\n        '1.2.840.10045.3.1.1': 24,\n        '1.2.840.10045.3.1.7': 32,\n        '1.3.132.0.1': 21,\n        '1.3.132.0.2': 21,\n        '1.3.132.0.3': 30,\n        '1.3.132.0.4': 15,\n        '1.3.132.0.5': 15,\n        '1.3.132.0.6': 14,\n        '1.3.132.0.7': 14,\n        '1.3.132.0.8': 21,\n        '1.3.132.0.9': 21,\n        '1.3.132.0.10': 32,\n        '1.3.132.0.15': 21,\n        '1.3.132.0.16': 36,\n        '1.3.132.0.17': 36,\n        '1.3.132.0.22': 17,\n        '1.3.132.0.23': 17,\n        '1.3.132.0.24': 25,\n        '1.3.132.0.25': 25,\n        '1.3.132.0.26': 29,\n        '1.3.132.0.27': 30,\n        '1.3.132.0.28': 16,\n        '1.3.132.0.29': 16,\n        '1.3.132.0.30': 21,\n        '1.3.132.0.31': 24,\n        '1.3.132.0.32': 29,\n        '1.3.132.0.33': 28,\n        '1.3.132.0.34': 48,\n        '1.3.132.0.35': 66,\n        '1.3.132.0.36': 51,\n        '1.3.132.0.37': 52,\n        '1.3.132.0.38': 72,\n        '1.3.132.0.39': 72,\n        # Order values used to compute these sourced from\n        # https://tools.ietf.org/html/rfc5639#section-3\n        # ceil(q.bit_length() / 8)\n        '1.3.36.3.3.2.8.1.1.1': 20,\n        '1.3.36.3.3.2.8.1.1.2': 20,\n        '1.3.36.3.3.2.8.1.1.3': 24,\n        '1.3.36.3.3.2.8.1.1.4': 24,\n        '1.3.36.3.3.2.8.1.1.5': 28,\n        '1.3.36.3.3.2.8.1.1.6': 28,\n        '1.3.36.3.3.2.8.1.1.7': 32,\n        '1.3.36.3.3.2.8.1.1.8': 32,\n        '1.3.36.3.3.2.8.1.1.9': 40,\n        '1.3.36.3.3.2.8.1.1.10': 40,\n        '1.3.36.3.3.2.8.1.1.11': 48,\n        '1.3.36.3.3.2.8.1.1.12': 48,\n        '1.3.36.3.3.2.8.1.1.13': 64,\n        '1.3.36.3.3.2.8.1.1.14': 64,\n    }\n\n    @classmethod\n    def register(cls, name, oid, key_size):\n        \"\"\"\n        Registers a new named elliptic curve that is not included in the\n        default list of named curves\n\n        :param name:\n            A unicode string of the curve name\n\n        :param oid:\n            A unicode string of the dotted format OID\n\n        :param key_size:\n            An integer of the number of bytes the private key should be\n            encoded to\n        \"\"\"\n\n        cls._map[oid] = name\n        if cls._reverse_map is not None:\n            cls._reverse_map[name] = oid\n        cls._key_sizes[oid] = key_size\n\n\nclass ECDomainParameters(Choice):\n    \"\"\"\n    Source: http://www.secg.org/sec1-v2.pdf page 102\n    \"\"\"\n\n    _alternatives = [\n        ('specified', SpecifiedECDomain),\n        ('named', NamedCurve),\n        ('implicit_ca', Null),\n    ]\n\n    @property\n    def key_size(self):\n        if self.name == 'implicit_ca':\n            raise ValueError(unwrap(\n                '''\n                Unable to calculate key_size from ECDomainParameters\n                that are implicitly defined by the CA key\n                '''\n            ))\n\n        if self.name == 'specified':\n            order = self.chosen['order'].native\n            return math.ceil(math.log(order, 2.0) / 8.0)\n\n        oid = self.chosen.dotted\n        if oid not in NamedCurve._key_sizes:\n            raise ValueError(unwrap(\n                '''\n                The asn1crypto.keys.NamedCurve %s does not have a registered key length,\n                please call asn1crypto.keys.NamedCurve.register()\n                ''',\n                repr(oid)\n            ))\n        return NamedCurve._key_sizes[oid]\n\n\nclass ECPrivateKeyVersion(Integer):\n    \"\"\"\n    Original Name: None\n    Source: http://www.secg.org/sec1-v2.pdf page 108\n    \"\"\"\n\n    _map = {\n        1: 'ecPrivkeyVer1',\n    }\n\n\nclass ECPrivateKey(Sequence):\n    \"\"\"\n    Source: http://www.secg.org/sec1-v2.pdf page 108\n    \"\"\"\n\n    _fields = [\n        ('version', ECPrivateKeyVersion),\n        ('private_key', IntegerOctetString),\n        ('parameters', ECDomainParameters, {'explicit': 0, 'optional': True}),\n        ('public_key', ECPointBitString, {'explicit': 1, 'optional': True}),\n    ]\n\n    # Ensures the key is set to the correct length when encoding\n    _key_size = None\n\n    # This is necessary to ensure the private_key IntegerOctetString is encoded properly\n    def __setitem__(self, key, value):\n        res = super(ECPrivateKey, self).__setitem__(key, value)\n\n        if key == 'private_key':\n            if self._key_size is None:\n                # Infer the key_size from the existing private key if possible\n                pkey_contents = self['private_key'].contents\n                if isinstance(pkey_contents, byte_cls) and len(pkey_contents) > 1:\n                    self.set_key_size(len(self['private_key'].contents))\n\n            elif self._key_size is not None:\n                self._update_key_size()\n\n        elif key == 'parameters' and isinstance(self['parameters'], ECDomainParameters) and \\\n                self['parameters'].name != 'implicit_ca':\n            self.set_key_size(self['parameters'].key_size)\n\n        return res\n\n    def set_key_size(self, key_size):\n        \"\"\"\n        Sets the key_size to ensure the private key is encoded to the proper length\n\n        :param key_size:\n            An integer byte length to encode the private_key to\n        \"\"\"\n\n        self._key_size = key_size\n        self._update_key_size()\n\n    def _update_key_size(self):\n        \"\"\"\n        Ensure the private_key explicit encoding width is set\n        \"\"\"\n\n        if self._key_size is not None and isinstance(self['private_key'], IntegerOctetString):\n            self['private_key'].set_encoded_width(self._key_size)\n\n\nclass DSAParams(Sequence):\n    \"\"\"\n    Parameters for a DSA public or private key\n\n    Original Name: Dss-Parms\n    Source: https://tools.ietf.org/html/rfc3279#page-9\n    \"\"\"\n\n    _fields = [\n        ('p', Integer),\n        ('q', Integer),\n        ('g', Integer),\n    ]\n\n\nclass Attribute(Sequence):\n    \"\"\"\n    Source: https://www.itu.int/rec/dologin_pub.asp?lang=e&id=T-REC-X.501-198811-S!!PDF-E&type=items page 8\n    \"\"\"\n\n    _fields = [\n        ('type', ObjectIdentifier),\n        ('values', SetOf, {'spec': Any}),\n    ]\n\n\nclass Attributes(SetOf):\n    \"\"\"\n    Source: https://tools.ietf.org/html/rfc5208#page-3\n    \"\"\"\n\n    _child_spec = Attribute\n\n\nclass PrivateKeyAlgorithmId(ObjectIdentifier):\n    \"\"\"\n    These OIDs for various public keys are reused when storing private keys\n    inside of a PKCS#8 structure\n\n    Original Name: None\n    Source: https://tools.ietf.org/html/rfc3279\n    \"\"\"\n\n    _map = {\n        # https://tools.ietf.org/html/rfc3279#page-19\n        '1.2.840.113549.1.1.1': 'rsa',\n        # https://tools.ietf.org/html/rfc4055#page-8\n        '1.2.840.113549.1.1.10': 'rsassa_pss',\n        # https://tools.ietf.org/html/rfc3279#page-18\n        '1.2.840.10040.4.1': 'dsa',\n        # https://tools.ietf.org/html/rfc3279#page-13\n        '1.2.840.10045.2.1': 'ec',\n        # https://tools.ietf.org/html/rfc8410#section-9\n        '1.3.101.110': 'x25519',\n        '1.3.101.111': 'x448',\n        '1.3.101.112': 'ed25519',\n        '1.3.101.113': 'ed448',\n    }\n\n\nclass PrivateKeyAlgorithm(_ForceNullParameters, Sequence):\n    \"\"\"\n    Original Name: PrivateKeyAlgorithmIdentifier\n    Source: https://tools.ietf.org/html/rfc5208#page-3\n    \"\"\"\n\n    _fields = [\n        ('algorithm', PrivateKeyAlgorithmId),\n        ('parameters', Any, {'optional': True}),\n    ]\n\n    _oid_pair = ('algorithm', 'parameters')\n    _oid_specs = {\n        'dsa': DSAParams,\n        'ec': ECDomainParameters,\n        'rsassa_pss': RSASSAPSSParams,\n    }\n\n\nclass PrivateKeyInfo(Sequence):\n    \"\"\"\n    Source: https://tools.ietf.org/html/rfc5208#page-3\n    \"\"\"\n\n    _fields = [\n        ('version', Integer),\n        ('private_key_algorithm', PrivateKeyAlgorithm),\n        ('private_key', ParsableOctetString),\n        ('attributes', Attributes, {'implicit': 0, 'optional': True}),\n    ]\n\n    def _private_key_spec(self):\n        algorithm = self['private_key_algorithm']['algorithm'].native\n        return {\n            'rsa': RSAPrivateKey,\n            'rsassa_pss': RSAPrivateKey,\n            'dsa': Integer,\n            'ec': ECPrivateKey,\n            # These should be treated as opaque octet strings according\n            # to RFC 8410\n            'x25519': OctetString,\n            'x448': OctetString,\n            'ed25519': OctetString,\n            'ed448': OctetString,\n        }[algorithm]\n\n    _spec_callbacks = {\n        'private_key': _private_key_spec\n    }\n\n    _algorithm = None\n    _bit_size = None\n    _public_key = None\n    _fingerprint = None\n\n    @classmethod\n    def wrap(cls, private_key, algorithm):\n        \"\"\"\n        Wraps a private key in a PrivateKeyInfo structure\n\n        :param private_key:\n            A byte string or Asn1Value object of the private key\n\n        :param algorithm:\n            A unicode string of \"rsa\", \"dsa\" or \"ec\"\n\n        :return:\n            A PrivateKeyInfo object\n        \"\"\"\n\n        if not isinstance(private_key, byte_cls) and not isinstance(private_key, Asn1Value):\n            raise TypeError(unwrap(\n                '''\n                private_key must be a byte string or Asn1Value, not %s\n                ''',\n                type_name(private_key)\n            ))\n\n        if algorithm == 'rsa' or algorithm == 'rsassa_pss':\n            if not isinstance(private_key, RSAPrivateKey):\n                private_key = RSAPrivateKey.load(private_key)\n            params = Null()\n        elif algorithm == 'dsa':\n            if not isinstance(private_key, DSAPrivateKey):\n                private_key = DSAPrivateKey.load(private_key)\n            params = DSAParams()\n            params['p'] = private_key['p']\n            params['q'] = private_key['q']\n            params['g'] = private_key['g']\n            public_key = private_key['public_key']\n            private_key = private_key['private_key']\n        elif algorithm == 'ec':\n            if not isinstance(private_key, ECPrivateKey):\n                private_key = ECPrivateKey.load(private_key)\n            else:\n                private_key = private_key.copy()\n            params = private_key['parameters']\n            del private_key['parameters']\n        else:\n            raise ValueError(unwrap(\n                '''\n                algorithm must be one of \"rsa\", \"dsa\", \"ec\", not %s\n                ''',\n                repr(algorithm)\n            ))\n\n        private_key_algo = PrivateKeyAlgorithm()\n        private_key_algo['algorithm'] = PrivateKeyAlgorithmId(algorithm)\n        private_key_algo['parameters'] = params\n\n        container = cls()\n        container._algorithm = algorithm\n        container['version'] = Integer(0)\n        container['private_key_algorithm'] = private_key_algo\n        container['private_key'] = private_key\n\n        # Here we save the DSA public key if possible since it is not contained\n        # within the PKCS#8 structure for a DSA key\n        if algorithm == 'dsa':\n            container._public_key = public_key\n\n        return container\n\n    # This is necessary to ensure any contained ECPrivateKey is the\n    # correct size\n    def __setitem__(self, key, value):\n        res = super(PrivateKeyInfo, self).__setitem__(key, value)\n\n        algorithm = self['private_key_algorithm']\n\n        # When possible, use the parameter info to make sure the private key encoding\n        # retains any necessary leading bytes, instead of them being dropped\n        if (key == 'private_key_algorithm' or key == 'private_key') and \\\n                algorithm['algorithm'].native == 'ec' and \\\n                isinstance(algorithm['parameters'], ECDomainParameters) and \\\n                algorithm['parameters'].name != 'implicit_ca' and \\\n                isinstance(self['private_key'], ParsableOctetString) and \\\n                isinstance(self['private_key'].parsed, ECPrivateKey):\n            self['private_key'].parsed.set_key_size(algorithm['parameters'].key_size)\n\n        return res\n\n    def unwrap(self):\n        \"\"\"\n        Unwraps the private key into an RSAPrivateKey, DSAPrivateKey or\n        ECPrivateKey object\n\n        :return:\n            An RSAPrivateKey, DSAPrivateKey or ECPrivateKey object\n        \"\"\"\n\n        raise APIException(\n            'asn1crypto.keys.PrivateKeyInfo().unwrap() has been removed, '\n            'please use oscrypto.asymmetric.PrivateKey().unwrap() instead')\n\n    @property\n    def curve(self):\n        \"\"\"\n        Returns information about the curve used for an EC key\n\n        :raises:\n            ValueError - when the key is not an EC key\n\n        :return:\n            A two-element tuple, with the first element being a unicode string\n            of \"implicit_ca\", \"specified\" or \"named\". If the first element is\n            \"implicit_ca\", the second is None. If \"specified\", the second is\n            an OrderedDict that is the native version of SpecifiedECDomain. If\n            \"named\", the second is a unicode string of the curve name.\n        \"\"\"\n\n        if self.algorithm != 'ec':\n            raise ValueError(unwrap(\n                '''\n                Only EC keys have a curve, this key is %s\n                ''',\n                self.algorithm.upper()\n            ))\n\n        params = self['private_key_algorithm']['parameters']\n        chosen = params.chosen\n\n        if params.name == 'implicit_ca':\n            value = None\n        else:\n            value = chosen.native\n\n        return (params.name, value)\n\n    @property\n    def hash_algo(self):\n        \"\"\"\n        Returns the name of the family of hash algorithms used to generate a\n        DSA key\n\n        :raises:\n            ValueError - when the key is not a DSA key\n\n        :return:\n            A unicode string of \"sha1\" or \"sha2\"\n        \"\"\"\n\n        if self.algorithm != 'dsa':\n            raise ValueError(unwrap(\n                '''\n                Only DSA keys are generated using a hash algorithm, this key is\n                %s\n                ''',\n                self.algorithm.upper()\n            ))\n\n        byte_len = math.log(self['private_key_algorithm']['parameters']['q'].native, 2) / 8\n\n        return 'sha1' if byte_len <= 20 else 'sha2'\n\n    @property\n    def algorithm(self):\n        \"\"\"\n        :return:\n            A unicode string of \"rsa\", \"rsassa_pss\", \"dsa\" or \"ec\"\n        \"\"\"\n\n        if self._algorithm is None:\n            self._algorithm = self['private_key_algorithm']['algorithm'].native\n        return self._algorithm\n\n    @property\n    def bit_size(self):\n        \"\"\"\n        :return:\n            The bit size of the private key, as an integer\n        \"\"\"\n\n        if self._bit_size is None:\n            if self.algorithm == 'rsa' or self.algorithm == 'rsassa_pss':\n                prime = self['private_key'].parsed['modulus'].native\n            elif self.algorithm == 'dsa':\n                prime = self['private_key_algorithm']['parameters']['p'].native\n            elif self.algorithm == 'ec':\n                prime = self['private_key'].parsed['private_key'].native\n            self._bit_size = int(math.ceil(math.log(prime, 2)))\n            modulus = self._bit_size % 8\n            if modulus != 0:\n                self._bit_size += 8 - modulus\n        return self._bit_size\n\n    @property\n    def byte_size(self):\n        \"\"\"\n        :return:\n            The byte size of the private key, as an integer\n        \"\"\"\n\n        return int(math.ceil(self.bit_size / 8))\n\n    @property\n    def public_key(self):\n        \"\"\"\n        :return:\n            If an RSA key, an RSAPublicKey object. If a DSA key, an Integer\n            object. If an EC key, an ECPointBitString object.\n        \"\"\"\n\n        raise APIException(\n            'asn1crypto.keys.PrivateKeyInfo().public_key has been removed, '\n            'please use oscrypto.asymmetric.PrivateKey().public_key.unwrap() instead')\n\n    @property\n    def public_key_info(self):\n        \"\"\"\n        :return:\n            A PublicKeyInfo object derived from this private key.\n        \"\"\"\n\n        raise APIException(\n            'asn1crypto.keys.PrivateKeyInfo().public_key_info has been removed, '\n            'please use oscrypto.asymmetric.PrivateKey().public_key.asn1 instead')\n\n    @property\n    def fingerprint(self):\n        \"\"\"\n        Creates a fingerprint that can be compared with a public key to see if\n        the two form a pair.\n\n        This fingerprint is not compatible with fingerprints generated by any\n        other software.\n\n        :return:\n            A byte string that is a sha256 hash of selected components (based\n            on the key type)\n        \"\"\"\n\n        raise APIException(\n            'asn1crypto.keys.PrivateKeyInfo().fingerprint has been removed, '\n            'please use oscrypto.asymmetric.PrivateKey().fingerprint instead')\n\n\nclass EncryptedPrivateKeyInfo(Sequence):\n    \"\"\"\n    Source: https://tools.ietf.org/html/rfc5208#page-4\n    \"\"\"\n\n    _fields = [\n        ('encryption_algorithm', EncryptionAlgorithm),\n        ('encrypted_data', OctetString),\n    ]\n\n\n# These structures are from https://tools.ietf.org/html/rfc3279\n\nclass ValidationParms(Sequence):\n    \"\"\"\n    Source: https://tools.ietf.org/html/rfc3279#page-10\n    \"\"\"\n\n    _fields = [\n        ('seed', BitString),\n        ('pgen_counter', Integer),\n    ]\n\n\nclass DomainParameters(Sequence):\n    \"\"\"\n    Source: https://tools.ietf.org/html/rfc3279#page-10\n    \"\"\"\n\n    _fields = [\n        ('p', Integer),\n        ('g', Integer),\n        ('q', Integer),\n        ('j', Integer, {'optional': True}),\n        ('validation_params', ValidationParms, {'optional': True}),\n    ]\n\n\nclass PublicKeyAlgorithmId(ObjectIdentifier):\n    \"\"\"\n    Original Name: None\n    Source: https://tools.ietf.org/html/rfc3279\n    \"\"\"\n\n    _map = {\n        # https://tools.ietf.org/html/rfc3279#page-19\n        '1.2.840.113549.1.1.1': 'rsa',\n        # https://tools.ietf.org/html/rfc3447#page-47\n        '1.2.840.113549.1.1.7': 'rsaes_oaep',\n        # https://tools.ietf.org/html/rfc4055#page-8\n        '1.2.840.113549.1.1.10': 'rsassa_pss',\n        # https://tools.ietf.org/html/rfc3279#page-18\n        '1.2.840.10040.4.1': 'dsa',\n        # https://tools.ietf.org/html/rfc3279#page-13\n        '1.2.840.10045.2.1': 'ec',\n        # https://tools.ietf.org/html/rfc3279#page-10\n        '1.2.840.10046.2.1': 'dh',\n        # https://tools.ietf.org/html/rfc8410#section-9\n        '1.3.101.110': 'x25519',\n        '1.3.101.111': 'x448',\n        '1.3.101.112': 'ed25519',\n        '1.3.101.113': 'ed448',\n    }\n\n\nclass PublicKeyAlgorithm(_ForceNullParameters, Sequence):\n    \"\"\"\n    Original Name: AlgorithmIdentifier\n    Source: https://tools.ietf.org/html/rfc5280#page-18\n    \"\"\"\n\n    _fields = [\n        ('algorithm', PublicKeyAlgorithmId),\n        ('parameters', Any, {'optional': True}),\n    ]\n\n    _oid_pair = ('algorithm', 'parameters')\n    _oid_specs = {\n        'dsa': DSAParams,\n        'ec': ECDomainParameters,\n        'dh': DomainParameters,\n        'rsaes_oaep': RSAESOAEPParams,\n        'rsassa_pss': RSASSAPSSParams,\n    }\n\n\nclass PublicKeyInfo(Sequence):\n    \"\"\"\n    Original Name: SubjectPublicKeyInfo\n    Source: https://tools.ietf.org/html/rfc5280#page-17\n    \"\"\"\n\n    _fields = [\n        ('algorithm', PublicKeyAlgorithm),\n        ('public_key', ParsableOctetBitString),\n    ]\n\n    def _public_key_spec(self):\n        algorithm = self['algorithm']['algorithm'].native\n        return {\n            'rsa': RSAPublicKey,\n            'rsaes_oaep': RSAPublicKey,\n            'rsassa_pss': RSAPublicKey,\n            'dsa': Integer,\n            # We override the field spec with ECPoint so that users can easily\n            # decompose the byte string into the constituent X and Y coords\n            'ec': (ECPointBitString, None),\n            'dh': Integer,\n            # These should be treated as opaque bit strings according\n            # to RFC 8410, and need not even be valid ASN.1\n            'x25519': (OctetBitString, None),\n            'x448': (OctetBitString, None),\n            'ed25519': (OctetBitString, None),\n            'ed448': (OctetBitString, None),\n        }[algorithm]\n\n    _spec_callbacks = {\n        'public_key': _public_key_spec\n    }\n\n    _algorithm = None\n    _bit_size = None\n    _fingerprint = None\n    _sha1 = None\n    _sha256 = None\n\n    @classmethod\n    def wrap(cls, public_key, algorithm):\n        \"\"\"\n        Wraps a public key in a PublicKeyInfo structure\n\n        :param public_key:\n            A byte string or Asn1Value object of the public key\n\n        :param algorithm:\n            A unicode string of \"rsa\"\n\n        :return:\n            A PublicKeyInfo object\n        \"\"\"\n\n        if not isinstance(public_key, byte_cls) and not isinstance(public_key, Asn1Value):\n            raise TypeError(unwrap(\n                '''\n                public_key must be a byte string or Asn1Value, not %s\n                ''',\n                type_name(public_key)\n            ))\n\n        if algorithm != 'rsa' and algorithm != 'rsassa_pss':\n            raise ValueError(unwrap(\n                '''\n                algorithm must \"rsa\", not %s\n                ''',\n                repr(algorithm)\n            ))\n\n        algo = PublicKeyAlgorithm()\n        algo['algorithm'] = PublicKeyAlgorithmId(algorithm)\n        algo['parameters'] = Null()\n\n        container = cls()\n        container['algorithm'] = algo\n        if isinstance(public_key, Asn1Value):\n            public_key = public_key.untag().dump()\n        container['public_key'] = ParsableOctetBitString(public_key)\n\n        return container\n\n    def unwrap(self):\n        \"\"\"\n        Unwraps an RSA public key into an RSAPublicKey object. Does not support\n        DSA or EC public keys since they do not have an unwrapped form.\n\n        :return:\n            An RSAPublicKey object\n        \"\"\"\n\n        raise APIException(\n            'asn1crypto.keys.PublicKeyInfo().unwrap() has been removed, '\n            'please use oscrypto.asymmetric.PublicKey().unwrap() instead')\n\n    @property\n    def curve(self):\n        \"\"\"\n        Returns information about the curve used for an EC key\n\n        :raises:\n            ValueError - when the key is not an EC key\n\n        :return:\n            A two-element tuple, with the first element being a unicode string\n            of \"implicit_ca\", \"specified\" or \"named\". If the first element is\n            \"implicit_ca\", the second is None. If \"specified\", the second is\n            an OrderedDict that is the native version of SpecifiedECDomain. If\n            \"named\", the second is a unicode string of the curve name.\n        \"\"\"\n\n        if self.algorithm != 'ec':\n            raise ValueError(unwrap(\n                '''\n                Only EC keys have a curve, this key is %s\n                ''',\n                self.algorithm.upper()\n            ))\n\n        params = self['algorithm']['parameters']\n        chosen = params.chosen\n\n        if params.name == 'implicit_ca':\n            value = None\n        else:\n            value = chosen.native\n\n        return (params.name, value)\n\n    @property\n    def hash_algo(self):\n        \"\"\"\n        Returns the name of the family of hash algorithms used to generate a\n        DSA key\n\n        :raises:\n            ValueError - when the key is not a DSA key\n\n        :return:\n            A unicode string of \"sha1\" or \"sha2\" or None if no parameters are\n            present\n        \"\"\"\n\n        if self.algorithm != 'dsa':\n            raise ValueError(unwrap(\n                '''\n                Only DSA keys are generated using a hash algorithm, this key is\n                %s\n                ''',\n                self.algorithm.upper()\n            ))\n\n        parameters = self['algorithm']['parameters']\n        if parameters.native is None:\n            return None\n\n        byte_len = math.log(parameters['q'].native, 2) / 8\n\n        return 'sha1' if byte_len <= 20 else 'sha2'\n\n    @property\n    def algorithm(self):\n        \"\"\"\n        :return:\n            A unicode string of \"rsa\", \"rsassa_pss\", \"dsa\" or \"ec\"\n        \"\"\"\n\n        if self._algorithm is None:\n            self._algorithm = self['algorithm']['algorithm'].native\n        return self._algorithm\n\n    @property\n    def bit_size(self):\n        \"\"\"\n        :return:\n            The bit size of the public key, as an integer\n        \"\"\"\n\n        if self._bit_size is None:\n            if self.algorithm == 'ec':\n                self._bit_size = int(((len(self['public_key'].native) - 1) / 2) * 8)\n            else:\n                if self.algorithm == 'rsa' or self.algorithm == 'rsassa_pss':\n                    prime = self['public_key'].parsed['modulus'].native\n                elif self.algorithm == 'dsa':\n                    prime = self['algorithm']['parameters']['p'].native\n                self._bit_size = int(math.ceil(math.log(prime, 2)))\n                modulus = self._bit_size % 8\n                if modulus != 0:\n                    self._bit_size += 8 - modulus\n\n        return self._bit_size\n\n    @property\n    def byte_size(self):\n        \"\"\"\n        :return:\n            The byte size of the public key, as an integer\n        \"\"\"\n\n        return int(math.ceil(self.bit_size / 8))\n\n    @property\n    def sha1(self):\n        \"\"\"\n        :return:\n            The SHA1 hash of the DER-encoded bytes of this public key info\n        \"\"\"\n\n        if self._sha1 is None:\n            self._sha1 = hashlib.sha1(byte_cls(self['public_key'])).digest()\n        return self._sha1\n\n    @property\n    def sha256(self):\n        \"\"\"\n        :return:\n            The SHA-256 hash of the DER-encoded bytes of this public key info\n        \"\"\"\n\n        if self._sha256 is None:\n            self._sha256 = hashlib.sha256(byte_cls(self['public_key'])).digest()\n        return self._sha256\n\n    @property\n    def fingerprint(self):\n        \"\"\"\n        Creates a fingerprint that can be compared with a private key to see if\n        the two form a pair.\n\n        This fingerprint is not compatible with fingerprints generated by any\n        other software.\n\n        :return:\n            A byte string that is a sha256 hash of selected components (based\n            on the key type)\n        \"\"\"\n\n        raise APIException(\n            'asn1crypto.keys.PublicKeyInfo().fingerprint has been removed, '\n            'please use oscrypto.asymmetric.PublicKey().fingerprint instead')\n", "asn1crypto/__init__.py": "# coding: utf-8\nfrom __future__ import unicode_literals, division, absolute_import, print_function\n\nfrom .version import __version__, __version_info__\n\n__all__ = [\n    '__version__',\n    '__version_info__',\n    'load_order',\n]\n\n\ndef load_order():\n    \"\"\"\n    Returns a list of the module and sub-module names for asn1crypto in\n    dependency load order, for the sake of live reloading code\n\n    :return:\n        A list of unicode strings of module names, as they would appear in\n        sys.modules, ordered by which module should be reloaded first\n    \"\"\"\n\n    return [\n        'asn1crypto._errors',\n        'asn1crypto._int',\n        'asn1crypto._ordereddict',\n        'asn1crypto._teletex_codec',\n        'asn1crypto._types',\n        'asn1crypto._inet',\n        'asn1crypto._iri',\n        'asn1crypto.version',\n        'asn1crypto.pem',\n        'asn1crypto.util',\n        'asn1crypto.parser',\n        'asn1crypto.core',\n        'asn1crypto.algos',\n        'asn1crypto.keys',\n        'asn1crypto.x509',\n        'asn1crypto.crl',\n        'asn1crypto.csr',\n        'asn1crypto.ocsp',\n        'asn1crypto.cms',\n        'asn1crypto.pdf',\n        'asn1crypto.pkcs12',\n        'asn1crypto.tsp',\n        'asn1crypto',\n    ]\n", "asn1crypto/_iri.py": "# coding: utf-8\n\n\"\"\"\nFunctions to convert unicode IRIs into ASCII byte string URIs and back. Exports\nthe following items:\n\n - iri_to_uri()\n - uri_to_iri()\n\"\"\"\n\nfrom __future__ import unicode_literals, division, absolute_import, print_function\n\nfrom encodings import idna  # noqa\nimport codecs\nimport re\nimport sys\n\nfrom ._errors import unwrap\nfrom ._types import byte_cls, str_cls, type_name, bytes_to_list, int_types\n\nif sys.version_info < (3,):\n    from urlparse import urlsplit, urlunsplit\n    from urllib import (\n        quote as urlquote,\n        unquote as unquote_to_bytes,\n    )\n\nelse:\n    from urllib.parse import (\n        quote as urlquote,\n        unquote_to_bytes,\n        urlsplit,\n        urlunsplit,\n    )\n\n\ndef iri_to_uri(value, normalize=False):\n    \"\"\"\n    Encodes a unicode IRI into an ASCII byte string URI\n\n    :param value:\n        A unicode string of an IRI\n\n    :param normalize:\n        A bool that controls URI normalization\n\n    :return:\n        A byte string of the ASCII-encoded URI\n    \"\"\"\n\n    if not isinstance(value, str_cls):\n        raise TypeError(unwrap(\n            '''\n            value must be a unicode string, not %s\n            ''',\n            type_name(value)\n        ))\n\n    scheme = None\n    # Python 2.6 doesn't split properly is the URL doesn't start with http:// or https://\n    if sys.version_info < (2, 7) and not value.startswith('http://') and not value.startswith('https://'):\n        real_prefix = None\n        prefix_match = re.match('^[^:]*://', value)\n        if prefix_match:\n            real_prefix = prefix_match.group(0)\n            value = 'http://' + value[len(real_prefix):]\n        parsed = urlsplit(value)\n        if real_prefix:\n            value = real_prefix + value[7:]\n            scheme = _urlquote(real_prefix[:-3])\n    else:\n        parsed = urlsplit(value)\n\n    if scheme is None:\n        scheme = _urlquote(parsed.scheme)\n    hostname = parsed.hostname\n    if hostname is not None:\n        hostname = hostname.encode('idna')\n    # RFC 3986 allows userinfo to contain sub-delims\n    username = _urlquote(parsed.username, safe='!$&\\'()*+,;=')\n    password = _urlquote(parsed.password, safe='!$&\\'()*+,;=')\n    port = parsed.port\n    if port is not None:\n        port = str_cls(port).encode('ascii')\n\n    netloc = b''\n    if username is not None:\n        netloc += username\n        if password:\n            netloc += b':' + password\n        netloc += b'@'\n    if hostname is not None:\n        netloc += hostname\n    if port is not None:\n        default_http = scheme == b'http' and port == b'80'\n        default_https = scheme == b'https' and port == b'443'\n        if not normalize or (not default_http and not default_https):\n            netloc += b':' + port\n\n    # RFC 3986 allows a path to contain sub-delims, plus \"@\" and \":\"\n    path = _urlquote(parsed.path, safe='/!$&\\'()*+,;=@:')\n    # RFC 3986 allows the query to contain sub-delims, plus \"@\", \":\" , \"/\" and \"?\"\n    query = _urlquote(parsed.query, safe='/?!$&\\'()*+,;=@:')\n    # RFC 3986 allows the fragment to contain sub-delims, plus \"@\", \":\" , \"/\" and \"?\"\n    fragment = _urlquote(parsed.fragment, safe='/?!$&\\'()*+,;=@:')\n\n    if normalize and query is None and fragment is None and path == b'/':\n        path = None\n\n    # Python 2.7 compat\n    if path is None:\n        path = ''\n\n    output = urlunsplit((scheme, netloc, path, query, fragment))\n    if isinstance(output, str_cls):\n        output = output.encode('latin1')\n    return output\n\n\ndef uri_to_iri(value):\n    \"\"\"\n    Converts an ASCII URI byte string into a unicode IRI\n\n    :param value:\n        An ASCII-encoded byte string of the URI\n\n    :return:\n        A unicode string of the IRI\n    \"\"\"\n\n    if not isinstance(value, byte_cls):\n        raise TypeError(unwrap(\n            '''\n            value must be a byte string, not %s\n            ''',\n            type_name(value)\n        ))\n\n    parsed = urlsplit(value)\n\n    scheme = parsed.scheme\n    if scheme is not None:\n        scheme = scheme.decode('ascii')\n\n    username = _urlunquote(parsed.username, remap=[':', '@'])\n    password = _urlunquote(parsed.password, remap=[':', '@'])\n    hostname = parsed.hostname\n    if hostname:\n        hostname = hostname.decode('idna')\n    port = parsed.port\n    if port and not isinstance(port, int_types):\n        port = port.decode('ascii')\n\n    netloc = ''\n    if username is not None:\n        netloc += username\n        if password:\n            netloc += ':' + password\n        netloc += '@'\n    if hostname is not None:\n        netloc += hostname\n    if port is not None:\n        netloc += ':' + str_cls(port)\n\n    path = _urlunquote(parsed.path, remap=['/'], preserve=True)\n    query = _urlunquote(parsed.query, remap=['&', '='], preserve=True)\n    fragment = _urlunquote(parsed.fragment)\n\n    return urlunsplit((scheme, netloc, path, query, fragment))\n\n\ndef _iri_utf8_errors_handler(exc):\n    \"\"\"\n    Error handler for decoding UTF-8 parts of a URI into an IRI. Leaves byte\n    sequences encoded in %XX format, but as part of a unicode string.\n\n    :param exc:\n        The UnicodeDecodeError exception\n\n    :return:\n        A 2-element tuple of (replacement unicode string, integer index to\n        resume at)\n    \"\"\"\n\n    bytes_as_ints = bytes_to_list(exc.object[exc.start:exc.end])\n    replacements = ['%%%02x' % num for num in bytes_as_ints]\n    return (''.join(replacements), exc.end)\n\n\ncodecs.register_error('iriutf8', _iri_utf8_errors_handler)\n\n\ndef _urlquote(string, safe=''):\n    \"\"\"\n    Quotes a unicode string for use in a URL\n\n    :param string:\n        A unicode string\n\n    :param safe:\n        A unicode string of character to not encode\n\n    :return:\n        None (if string is None) or an ASCII byte string of the quoted string\n    \"\"\"\n\n    if string is None or string == '':\n        return None\n\n    # Anything already hex quoted is pulled out of the URL and unquoted if\n    # possible\n    escapes = []\n    if re.search('%[0-9a-fA-F]{2}', string):\n        # Try to unquote any percent values, restoring them if they are not\n        # valid UTF-8. Also, requote any safe chars since encoded versions of\n        # those are functionally different than the unquoted ones.\n        def _try_unescape(match):\n            byte_string = unquote_to_bytes(match.group(0))\n            unicode_string = byte_string.decode('utf-8', 'iriutf8')\n            for safe_char in list(safe):\n                unicode_string = unicode_string.replace(safe_char, '%%%02x' % ord(safe_char))\n            return unicode_string\n        string = re.sub('(?:%[0-9a-fA-F]{2})+', _try_unescape, string)\n\n        # Once we have the minimal set of hex quoted values, removed them from\n        # the string so that they are not double quoted\n        def _extract_escape(match):\n            escapes.append(match.group(0).encode('ascii'))\n            return '\\x00'\n        string = re.sub('%[0-9a-fA-F]{2}', _extract_escape, string)\n\n    output = urlquote(string.encode('utf-8'), safe=safe.encode('utf-8'))\n    if not isinstance(output, byte_cls):\n        output = output.encode('ascii')\n\n    # Restore the existing quoted values that we extracted\n    if len(escapes) > 0:\n        def _return_escape(_):\n            return escapes.pop(0)\n        output = re.sub(b'%00', _return_escape, output)\n\n    return output\n\n\ndef _urlunquote(byte_string, remap=None, preserve=None):\n    \"\"\"\n    Unquotes a URI portion from a byte string into unicode using UTF-8\n\n    :param byte_string:\n        A byte string of the data to unquote\n\n    :param remap:\n        A list of characters (as unicode) that should be re-mapped to a\n        %XX encoding. This is used when characters are not valid in part of a\n        URL.\n\n    :param preserve:\n        A bool - indicates that the chars to be remapped if they occur in\n        non-hex form, should be preserved. E.g. / for URL path.\n\n    :return:\n        A unicode string\n    \"\"\"\n\n    if byte_string is None:\n        return byte_string\n\n    if byte_string == b'':\n        return ''\n\n    if preserve:\n        replacements = ['\\x1A', '\\x1C', '\\x1D', '\\x1E', '\\x1F']\n        preserve_unmap = {}\n        for char in remap:\n            replacement = replacements.pop(0)\n            preserve_unmap[replacement] = char\n            byte_string = byte_string.replace(char.encode('ascii'), replacement.encode('ascii'))\n\n    byte_string = unquote_to_bytes(byte_string)\n\n    if remap:\n        for char in remap:\n            byte_string = byte_string.replace(char.encode('ascii'), ('%%%02x' % ord(char)).encode('ascii'))\n\n    output = byte_string.decode('utf-8', 'iriutf8')\n\n    if preserve:\n        for replacement, original in preserve_unmap.items():\n            output = output.replace(replacement, original)\n\n    return output\n", "asn1crypto/parser.py": "# coding: utf-8\n\n\"\"\"\nFunctions for parsing and dumping using the ASN.1 DER encoding. Exports the\nfollowing items:\n\n - emit()\n - parse()\n - peek()\n\nOther type classes are defined that help compose the types listed above.\n\"\"\"\n\nfrom __future__ import unicode_literals, division, absolute_import, print_function\n\nimport sys\n\nfrom ._types import byte_cls, chr_cls, type_name\nfrom .util import int_from_bytes, int_to_bytes\n\n_PY2 = sys.version_info <= (3,)\n_INSUFFICIENT_DATA_MESSAGE = 'Insufficient data - %s bytes requested but only %s available'\n_MAX_DEPTH = 10\n\n\ndef emit(class_, method, tag, contents):\n    \"\"\"\n    Constructs a byte string of an ASN.1 DER-encoded value\n\n    This is typically not useful. Instead, use one of the standard classes from\n    asn1crypto.core, or construct a new class with specific fields, and call the\n    .dump() method.\n\n    :param class_:\n        An integer ASN.1 class value: 0 (universal), 1 (application),\n        2 (context), 3 (private)\n\n    :param method:\n        An integer ASN.1 method value: 0 (primitive), 1 (constructed)\n\n    :param tag:\n        An integer ASN.1 tag value\n\n    :param contents:\n        A byte string of the encoded byte contents\n\n    :return:\n        A byte string of the ASN.1 DER value (header and contents)\n    \"\"\"\n\n    if not isinstance(class_, int):\n        raise TypeError('class_ must be an integer, not %s' % type_name(class_))\n\n    if class_ < 0 or class_ > 3:\n        raise ValueError('class_ must be one of 0, 1, 2 or 3, not %s' % class_)\n\n    if not isinstance(method, int):\n        raise TypeError('method must be an integer, not %s' % type_name(method))\n\n    if method < 0 or method > 1:\n        raise ValueError('method must be 0 or 1, not %s' % method)\n\n    if not isinstance(tag, int):\n        raise TypeError('tag must be an integer, not %s' % type_name(tag))\n\n    if tag < 0:\n        raise ValueError('tag must be greater than zero, not %s' % tag)\n\n    if not isinstance(contents, byte_cls):\n        raise TypeError('contents must be a byte string, not %s' % type_name(contents))\n\n    return _dump_header(class_, method, tag, contents) + contents\n\n\ndef parse(contents, strict=False):\n    \"\"\"\n    Parses a byte string of ASN.1 BER/DER-encoded data.\n\n    This is typically not useful. Instead, use one of the standard classes from\n    asn1crypto.core, or construct a new class with specific fields, and call the\n    .load() class method.\n\n    :param contents:\n        A byte string of BER/DER-encoded data\n\n    :param strict:\n        A boolean indicating if trailing data should be forbidden - if so, a\n        ValueError will be raised when trailing data exists\n\n    :raises:\n        ValueError - when the contents do not contain an ASN.1 header or are truncated in some way\n        TypeError - when contents is not a byte string\n\n    :return:\n        A 6-element tuple:\n         - 0: integer class (0 to 3)\n         - 1: integer method\n         - 2: integer tag\n         - 3: byte string header\n         - 4: byte string content\n         - 5: byte string trailer\n    \"\"\"\n\n    if not isinstance(contents, byte_cls):\n        raise TypeError('contents must be a byte string, not %s' % type_name(contents))\n\n    contents_len = len(contents)\n    info, consumed = _parse(contents, contents_len)\n    if strict and consumed != contents_len:\n        raise ValueError('Extra data - %d bytes of trailing data were provided' % (contents_len - consumed))\n    return info\n\n\ndef peek(contents):\n    \"\"\"\n    Parses a byte string of ASN.1 BER/DER-encoded data to find the length\n\n    This is typically used to look into an encoded value to see how long the\n    next chunk of ASN.1-encoded data is. Primarily it is useful when a\n    value is a concatenation of multiple values.\n\n    :param contents:\n        A byte string of BER/DER-encoded data\n\n    :raises:\n        ValueError - when the contents do not contain an ASN.1 header or are truncated in some way\n        TypeError - when contents is not a byte string\n\n    :return:\n        An integer with the number of bytes occupied by the ASN.1 value\n    \"\"\"\n\n    if not isinstance(contents, byte_cls):\n        raise TypeError('contents must be a byte string, not %s' % type_name(contents))\n\n    info, consumed = _parse(contents, len(contents))\n    return consumed\n\n\ndef _parse(encoded_data, data_len, pointer=0, lengths_only=False, depth=0):\n    \"\"\"\n    Parses a byte string into component parts\n\n    :param encoded_data:\n        A byte string that contains BER-encoded data\n\n    :param data_len:\n        The integer length of the encoded data\n\n    :param pointer:\n        The index in the byte string to parse from\n\n    :param lengths_only:\n        A boolean to cause the call to return a 2-element tuple of the integer\n        number of bytes in the header and the integer number of bytes in the\n        contents. Internal use only.\n\n    :param depth:\n        The recursion depth when evaluating indefinite-length encoding.\n\n    :return:\n        A 2-element tuple:\n         - 0: A tuple of (class_, method, tag, header, content, trailer)\n         - 1: An integer indicating how many bytes were consumed\n    \"\"\"\n\n    if depth > _MAX_DEPTH:\n        raise ValueError('Indefinite-length recursion limit exceeded')\n\n    start = pointer\n\n    if data_len < pointer + 1:\n        raise ValueError(_INSUFFICIENT_DATA_MESSAGE % (1, data_len - pointer))\n    first_octet = ord(encoded_data[pointer]) if _PY2 else encoded_data[pointer]\n\n    pointer += 1\n\n    tag = first_octet & 31\n    constructed = (first_octet >> 5) & 1\n    # Base 128 length using 8th bit as continuation indicator\n    if tag == 31:\n        tag = 0\n        while True:\n            if data_len < pointer + 1:\n                raise ValueError(_INSUFFICIENT_DATA_MESSAGE % (1, data_len - pointer))\n            num = ord(encoded_data[pointer]) if _PY2 else encoded_data[pointer]\n            pointer += 1\n            if num == 0x80 and tag == 0:\n                raise ValueError('Non-minimal tag encoding')\n            tag *= 128\n            tag += num & 127\n            if num >> 7 == 0:\n                break\n        if tag < 31:\n            raise ValueError('Non-minimal tag encoding')\n\n    if data_len < pointer + 1:\n        raise ValueError(_INSUFFICIENT_DATA_MESSAGE % (1, data_len - pointer))\n    length_octet = ord(encoded_data[pointer]) if _PY2 else encoded_data[pointer]\n    pointer += 1\n    trailer = b''\n\n    if length_octet >> 7 == 0:\n        contents_end = pointer + (length_octet & 127)\n\n    else:\n        length_octets = length_octet & 127\n        if length_octets:\n            if data_len < pointer + length_octets:\n                raise ValueError(_INSUFFICIENT_DATA_MESSAGE % (length_octets, data_len - pointer))\n            pointer += length_octets\n            contents_end = pointer + int_from_bytes(encoded_data[pointer - length_octets:pointer], signed=False)\n\n        else:\n            # To properly parse indefinite length values, we need to scan forward\n            # parsing headers until we find a value with a length of zero. If we\n            # just scanned looking for \\x00\\x00, nested indefinite length values\n            # would not work.\n            if not constructed:\n                raise ValueError('Indefinite-length element must be constructed')\n            contents_end = pointer\n            while data_len < contents_end + 2 or encoded_data[contents_end:contents_end+2] != b'\\x00\\x00':\n                _, contents_end = _parse(encoded_data, data_len, contents_end, lengths_only=True, depth=depth+1)\n            contents_end += 2\n            trailer = b'\\x00\\x00'\n\n    if contents_end > data_len:\n        raise ValueError(_INSUFFICIENT_DATA_MESSAGE % (contents_end - pointer, data_len - pointer))\n\n    if lengths_only:\n        return (pointer, contents_end)\n\n    return (\n        (\n            first_octet >> 6,\n            constructed,\n            tag,\n            encoded_data[start:pointer],\n            encoded_data[pointer:contents_end-len(trailer)],\n            trailer\n        ),\n        contents_end\n    )\n\n\ndef _dump_header(class_, method, tag, contents):\n    \"\"\"\n    Constructs the header bytes for an ASN.1 object\n\n    :param class_:\n        An integer ASN.1 class value: 0 (universal), 1 (application),\n        2 (context), 3 (private)\n\n    :param method:\n        An integer ASN.1 method value: 0 (primitive), 1 (constructed)\n\n    :param tag:\n        An integer ASN.1 tag value\n\n    :param contents:\n        A byte string of the encoded byte contents\n\n    :return:\n        A byte string of the ASN.1 DER header\n    \"\"\"\n\n    header = b''\n\n    id_num = 0\n    id_num |= class_ << 6\n    id_num |= method << 5\n\n    if tag >= 31:\n        cont_bit = 0\n        while tag > 0:\n            header = chr_cls(cont_bit | (tag & 0x7f)) + header\n            if not cont_bit:\n                cont_bit = 0x80\n            tag = tag >> 7\n        header = chr_cls(id_num | 31) + header\n    else:\n        header += chr_cls(id_num | tag)\n\n    length = len(contents)\n    if length <= 127:\n        header += chr_cls(length)\n    else:\n        length_bytes = int_to_bytes(length)\n        header += chr_cls(0x80 | len(length_bytes))\n        header += length_bytes\n\n    return header\n"}