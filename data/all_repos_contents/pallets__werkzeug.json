{"docs/conf.py": "from pallets_sphinx_themes import get_version\nfrom pallets_sphinx_themes import ProjectLink\n\n# Project --------------------------------------------------------------\n\nproject = \"Werkzeug\"\ncopyright = \"2007 Pallets\"\nauthor = \"Pallets\"\nrelease, version = get_version(\"Werkzeug\")\n\n# General --------------------------------------------------------------\n\ndefault_role = \"code\"\nextensions = [\n    \"sphinx.ext.autodoc\",\n    \"sphinx.ext.extlinks\",\n    \"sphinx.ext.intersphinx\",\n    \"sphinxcontrib.log_cabinet\",\n    \"pallets_sphinx_themes\",\n]\nautoclass_content = \"both\"\nautodoc_member_order = \"bysource\"\nautodoc_typehints = \"description\"\nautodoc_preserve_defaults = True\nextlinks = {\n    \"issue\": (\"https://github.com/pallets/werkzeug/issues/%s\", \"#%s\"),\n    \"pr\": (\"https://github.com/pallets/werkzeug/pull/%s\", \"#%s\"),\n    \"ghsa\": (\"https://github.com/advisories/%s\", \"GHSA-%s\"),\n}\nintersphinx_mapping = {\n    \"python\": (\"https://docs.python.org/3/\", None),\n}\n\n# HTML -----------------------------------------------------------------\n\nhtml_theme = \"werkzeug\"\nhtml_theme_options = {\"index_sidebar_logo\": False}\nhtml_context = {\n    \"project_links\": [\n        ProjectLink(\"Donate\", \"https://palletsprojects.com/donate\"),\n        ProjectLink(\"PyPI Releases\", \"https://pypi.org/project/Werkzeug/\"),\n        ProjectLink(\"Source Code\", \"https://github.com/pallets/werkzeug/\"),\n        ProjectLink(\"Issue Tracker\", \"https://github.com/pallets/werkzeug/issues/\"),\n        ProjectLink(\"Chat\", \"https://discord.gg/pallets\"),\n    ]\n}\nhtml_sidebars = {\n    \"index\": [\"project.html\", \"localtoc.html\", \"searchbox.html\", \"ethicalads.html\"],\n    \"**\": [\"localtoc.html\", \"relations.html\", \"searchbox.html\", \"ethicalads.html\"],\n}\nsinglehtml_sidebars = {\"index\": [\"project.html\", \"localtoc.html\", \"ethicalads.html\"]}\nhtml_static_path = [\"_static\"]\nhtml_favicon = \"_static/shortcut-icon.png\"\nhtml_logo = \"_static/werkzeug-vertical.png\"\nhtml_title = f\"Werkzeug Documentation ({version})\"\nhtml_show_sourcelink = False\n", "tests/test_send_file.py": "import datetime\nimport io\nimport pathlib\n\nimport pytest\n\nfrom werkzeug.exceptions import NotFound\nfrom werkzeug.http import http_date\nfrom werkzeug.test import EnvironBuilder\nfrom werkzeug.utils import send_file\nfrom werkzeug.utils import send_from_directory\n\nres_path = pathlib.Path(__file__).parent / \"res\"\nhtml_path = res_path / \"index.html\"\ntxt_path = res_path / \"test.txt\"\n\nenviron = EnvironBuilder().get_environ()\n\n\n@pytest.mark.parametrize(\"path\", [html_path, str(html_path)])\ndef test_path(path):\n    rv = send_file(path, environ)\n    assert rv.mimetype == \"text/html\"\n    assert rv.direct_passthrough\n    rv.direct_passthrough = False\n    assert rv.data == html_path.read_bytes()\n    rv.close()\n\n\ndef test_x_sendfile():\n    rv = send_file(html_path, environ, use_x_sendfile=True)\n    assert rv.headers[\"x-sendfile\"] == str(html_path)\n    assert rv.data == b\"\"\n    rv.close()\n\n\ndef test_last_modified():\n    last_modified = datetime.datetime(1999, 1, 1, tzinfo=datetime.timezone.utc)\n    rv = send_file(txt_path, environ, last_modified=last_modified)\n    assert rv.last_modified == last_modified\n    rv.close()\n\n\n@pytest.mark.parametrize(\n    \"file_factory\", [lambda: txt_path.open(\"rb\"), lambda: io.BytesIO(b\"test\")]\n)\ndef test_object(file_factory):\n    rv = send_file(file_factory(), environ, mimetype=\"text/plain\", use_x_sendfile=True)\n    rv.direct_passthrough = False\n    assert rv.data\n    assert rv.mimetype == \"text/plain\"\n    assert \"x-sendfile\" not in rv.headers\n    rv.close()\n\n\ndef test_object_without_mimetype():\n    with pytest.raises(TypeError, match=\"detect the MIME type\"):\n        send_file(io.BytesIO(b\"test\"), environ)\n\n\ndef test_object_mimetype_from_name():\n    rv = send_file(io.BytesIO(b\"test\"), environ, download_name=\"test.txt\")\n    assert rv.mimetype == \"text/plain\"\n    rv.close()\n\n\n@pytest.mark.parametrize(\n    \"file_factory\", [lambda: txt_path.open(), lambda: io.StringIO(\"test\")]\n)\ndef test_text_mode_fails(file_factory):\n    with file_factory() as f, pytest.raises(ValueError, match=\"binary mode\"):\n        send_file(f, environ, mimetype=\"text/plain\")\n\n\n@pytest.mark.parametrize(\n    (\"as_attachment\", \"value\"), [(False, \"inline\"), (True, \"attachment\")]\n)\ndef test_disposition_name(as_attachment, value):\n    rv = send_file(txt_path, environ, as_attachment=as_attachment)\n    assert rv.headers[\"Content-Disposition\"] == f\"{value}; filename=test.txt\"\n    rv.close()\n\n\ndef test_object_attachment_requires_name():\n    with pytest.raises(TypeError, match=\"attachment\"):\n        send_file(\n            io.BytesIO(b\"test\"), environ, mimetype=\"text/plain\", as_attachment=True\n        )\n\n    rv = send_file(\n        io.BytesIO(b\"test\"), environ, as_attachment=True, download_name=\"test.txt\"\n    )\n    assert rv.headers[\"Content-Disposition\"] == \"attachment; filename=test.txt\"\n    rv.close()\n\n\n@pytest.mark.parametrize(\n    (\"name\", \"ascii\", \"utf8\"),\n    (\n        (\"index.html\", \"index.html\", None),\n        (\n            \"\u00d1and\u00fa\uff0fping\u00fcino.txt\",\n            '\"Nandu/pinguino.txt\"',\n            \"%C3%91and%C3%BA%EF%BC%8Fping%C3%BCino.txt\",\n        ),\n        # latin-1 isn't ascii, should be quoted\n        (\"V\u00f6gel.txt\", \"Vogel.txt\", \"V%C3%B6gel.txt\"),\n        # \":/\" are not safe in filename* value\n        (\"\u0442\u0435:/\u0441\u0442\", '\":/\"', \"%D1%82%D0%B5%3A%2F%D1%81%D1%82\"),\n        # general test of extended parameter (non-quoted)\n        (\"(\u0442\u0435\u0441\u0442.txt\", '\"(.txt\"', \"%28%D1%82%D0%B5%D1%81%D1%82.txt\"),\n        (\"(test.txt\", '\"(test.txt\"', None),\n    ),\n)\ndef test_non_ascii_name(name, ascii, utf8):\n    rv = send_file(html_path, environ, as_attachment=True, download_name=name)\n    rv.close()\n    content_disposition = rv.headers[\"Content-Disposition\"]\n    assert f\"filename={ascii}\" in content_disposition\n\n    if utf8:\n        assert f\"filename*=UTF-8''{utf8}\" in content_disposition\n    else:\n        assert \"filename*=UTF-8''\" not in content_disposition\n\n\ndef test_no_cache_conditional_default():\n    rv = send_file(\n        txt_path,\n        EnvironBuilder(\n            headers={\"If-Modified-Since\": http_date(datetime.datetime(2020, 7, 12))}\n        ).get_environ(),\n        last_modified=datetime.datetime(2020, 7, 11),\n    )\n    rv.close()\n    assert \"no-cache\" in rv.headers[\"Cache-Control\"]\n    assert not rv.cache_control.public\n    assert not rv.cache_control.max_age\n    assert not rv.expires\n    assert rv.status_code == 304\n\n\n@pytest.mark.parametrize((\"value\", \"public\"), [(0, False), (60, True)])\ndef test_max_age(value, public):\n    rv = send_file(txt_path, environ, max_age=value)\n    rv.close()\n    assert (\"no-cache\" in rv.headers[\"Cache-Control\"]) != public\n    assert rv.cache_control.public == public\n    assert rv.cache_control.max_age == value\n    assert rv.expires\n    assert rv.status_code == 200\n\n\ndef test_etag():\n    rv = send_file(txt_path, environ)\n    rv.close()\n    assert rv.headers[\"ETag\"].count(\"-\") == 2\n    rv = send_file(txt_path, environ, etag=False)\n    rv.close()\n    assert \"ETag\" not in rv.headers\n    rv = send_file(txt_path, environ, etag=\"unique\")\n    rv.close()\n    assert rv.headers[\"ETag\"] == '\"unique\"'\n\n\n@pytest.mark.parametrize(\"as_attachment\", (True, False))\ndef test_content_encoding(as_attachment):\n    rv = send_file(\n        txt_path, environ, download_name=\"logo.svgz\", as_attachment=as_attachment\n    )\n    rv.close()\n    assert rv.mimetype == \"image/svg+xml\"\n    assert rv.content_encoding == (\"gzip\" if not as_attachment else None)\n\n\n@pytest.mark.parametrize(\n    (\"directory\", \"path\"),\n    [(str(res_path), \"test.txt\"), (res_path, pathlib.Path(\"test.txt\"))],\n)\ndef test_from_directory(directory, path):\n    rv = send_from_directory(directory, path, environ)\n    rv.direct_passthrough = False\n    assert rv.data.strip() == b\"FOUND\"\n    rv.close()\n\n\n@pytest.mark.parametrize(\"path\", [\"../res/test.txt\", \"nothing.txt\", \"null\\x00.txt\"])\ndef test_from_directory_not_found(path):\n    with pytest.raises(NotFound):\n        send_from_directory(res_path, path, environ)\n\n\ndef test_root_path(tmp_path):\n    # This is a private API, it should only be used by Flask.\n    d = tmp_path / \"d\"\n    d.mkdir()\n    (d / \"test.txt\").write_bytes(b\"test\")\n    rv = send_file(\"d/test.txt\", environ, _root_path=tmp_path)\n    rv.direct_passthrough = False\n    assert rv.data == b\"test\"\n    rv.close()\n    rv = send_from_directory(\"d\", \"test.txt\", environ, _root_path=tmp_path)\n    rv.direct_passthrough = False\n    assert rv.data == b\"test\"\n    rv.close()\n\n\ndef test_max_age_callable():\n    # This is a private API, it should only be used by Flask.\n    rv = send_file(txt_path, environ, max_age=lambda p: 10)\n    rv.close()\n    assert rv.cache_control.max_age == 10\n", "tests/test_datastructures.py": "import io\nimport pickle\nimport tempfile\nimport typing as t\nfrom contextlib import contextmanager\nfrom copy import copy\nfrom copy import deepcopy\n\nimport pytest\n\nfrom werkzeug import datastructures as ds\nfrom werkzeug import http\nfrom werkzeug.exceptions import BadRequestKeyError\n\n\nclass TestNativeItermethods:\n    def test_basic(self):\n        class StupidDict:\n            def keys(self, multi=1):\n                return iter([\"a\", \"b\", \"c\"] * multi)\n\n            def values(self, multi=1):\n                return iter([1, 2, 3] * multi)\n\n            def items(self, multi=1):\n                return iter(\n                    zip(iter(self.keys(multi=multi)), iter(self.values(multi=multi)))\n                )\n\n        d = StupidDict()\n        expected_keys = [\"a\", \"b\", \"c\"]\n        expected_values = [1, 2, 3]\n        expected_items = list(zip(expected_keys, expected_values))\n\n        assert list(d.keys()) == expected_keys\n        assert list(d.values()) == expected_values\n        assert list(d.items()) == expected_items\n\n        assert list(d.keys(2)) == expected_keys * 2\n        assert list(d.values(2)) == expected_values * 2\n        assert list(d.items(2)) == expected_items * 2\n\n\nclass _MutableMultiDictTests:\n    storage_class: t.Type[\"ds.MultiDict\"]\n\n    def test_pickle(self):\n        cls = self.storage_class\n\n        def create_instance(module=None):\n            if module is None:\n                d = cls()\n            else:\n                old = cls.__module__\n                cls.__module__ = module\n                d = cls()\n                cls.__module__ = old\n            d.setlist(b\"foo\", [1, 2, 3, 4])\n            d.setlist(b\"bar\", b\"foo bar baz\".split())\n            return d\n\n        for protocol in range(pickle.HIGHEST_PROTOCOL + 1):\n            d = create_instance()\n            s = pickle.dumps(d, protocol)\n            ud = pickle.loads(s)\n            assert type(ud) == type(d)  # noqa: E721\n            assert ud == d\n            alternative = pickle.dumps(create_instance(\"werkzeug\"), protocol)\n            assert pickle.loads(alternative) == d\n            ud[b\"newkey\"] = b\"bla\"\n            assert ud != d\n\n    def test_multidict_dict_interop(self):\n        # https://github.com/pallets/werkzeug/pull/2043\n        md = self.storage_class([(\"a\", 1), (\"a\", 2)])\n        assert dict(md)[\"a\"] != [1, 2]\n        assert dict(md)[\"a\"] == 1\n        assert dict(md) == {**md} == {\"a\": 1}\n\n    def test_basic_interface(self):\n        md = self.storage_class()\n        assert isinstance(md, dict)\n\n        mapping = [\n            (\"a\", 1),\n            (\"b\", 2),\n            (\"a\", 2),\n            (\"d\", 3),\n            (\"a\", 1),\n            (\"a\", 3),\n            (\"d\", 4),\n            (\"c\", 3),\n        ]\n        md = self.storage_class(mapping)\n\n        # simple getitem gives the first value\n        assert md[\"a\"] == 1\n        assert md[\"c\"] == 3\n        with pytest.raises(KeyError):\n            md[\"e\"]\n        assert md.get(\"a\") == 1\n\n        # list getitem\n        assert md.getlist(\"a\") == [1, 2, 1, 3]\n        assert md.getlist(\"d\") == [3, 4]\n        # do not raise if key not found\n        assert md.getlist(\"x\") == []\n\n        # simple setitem overwrites all values\n        md[\"a\"] = 42\n        assert md.getlist(\"a\") == [42]\n\n        # list setitem\n        md.setlist(\"a\", [1, 2, 3])\n        assert md[\"a\"] == 1\n        assert md.getlist(\"a\") == [1, 2, 3]\n\n        # verify that it does not change original lists\n        l1 = [1, 2, 3]\n        md.setlist(\"a\", l1)\n        del l1[:]\n        assert md[\"a\"] == 1\n\n        # setdefault, setlistdefault\n        assert md.setdefault(\"u\", 23) == 23\n        assert md.getlist(\"u\") == [23]\n        del md[\"u\"]\n\n        md.setlist(\"u\", [-1, -2])\n\n        # delitem\n        del md[\"u\"]\n        with pytest.raises(KeyError):\n            md[\"u\"]\n        del md[\"d\"]\n        assert md.getlist(\"d\") == []\n\n        # keys, values, items, lists\n        assert list(sorted(md.keys())) == [\"a\", \"b\", \"c\"]\n        assert list(sorted(md.keys())) == [\"a\", \"b\", \"c\"]\n\n        assert list(sorted(md.values())) == [1, 2, 3]\n        assert list(sorted(md.values())) == [1, 2, 3]\n\n        assert list(sorted(md.items())) == [(\"a\", 1), (\"b\", 2), (\"c\", 3)]\n        assert list(sorted(md.items(multi=True))) == [\n            (\"a\", 1),\n            (\"a\", 2),\n            (\"a\", 3),\n            (\"b\", 2),\n            (\"c\", 3),\n        ]\n        assert list(sorted(md.items())) == [(\"a\", 1), (\"b\", 2), (\"c\", 3)]\n        assert list(sorted(md.items(multi=True))) == [\n            (\"a\", 1),\n            (\"a\", 2),\n            (\"a\", 3),\n            (\"b\", 2),\n            (\"c\", 3),\n        ]\n\n        assert list(sorted(md.lists())) == [(\"a\", [1, 2, 3]), (\"b\", [2]), (\"c\", [3])]\n        assert list(sorted(md.lists())) == [(\"a\", [1, 2, 3]), (\"b\", [2]), (\"c\", [3])]\n\n        # copy method\n        c = md.copy()\n        assert c[\"a\"] == 1\n        assert c.getlist(\"a\") == [1, 2, 3]\n\n        # copy method 2\n        c = copy(md)\n        assert c[\"a\"] == 1\n        assert c.getlist(\"a\") == [1, 2, 3]\n\n        # deepcopy method\n        c = md.deepcopy()\n        assert c[\"a\"] == 1\n        assert c.getlist(\"a\") == [1, 2, 3]\n\n        # deepcopy method 2\n        c = deepcopy(md)\n        assert c[\"a\"] == 1\n        assert c.getlist(\"a\") == [1, 2, 3]\n\n        # update with a multidict\n        od = self.storage_class([(\"a\", 4), (\"a\", 5), (\"y\", 0)])\n        md.update(od)\n        assert md.getlist(\"a\") == [1, 2, 3, 4, 5]\n        assert md.getlist(\"y\") == [0]\n\n        # update with a regular dict\n        md = c\n        od = {\"a\": 4, \"y\": 0}\n        md.update(od)\n        assert md.getlist(\"a\") == [1, 2, 3, 4]\n        assert md.getlist(\"y\") == [0]\n\n        # pop, poplist, popitem, popitemlist\n        assert md.pop(\"y\") == 0\n        assert \"y\" not in md\n        assert md.poplist(\"a\") == [1, 2, 3, 4]\n        assert \"a\" not in md\n        assert md.poplist(\"missing\") == []\n\n        # remaining: b=2, c=3\n        popped = md.popitem()\n        assert popped in [(\"b\", 2), (\"c\", 3)]\n        popped = md.popitemlist()\n        assert popped in [(\"b\", [2]), (\"c\", [3])]\n\n        # type conversion\n        md = self.storage_class({\"a\": \"4\", \"b\": [\"2\", \"3\"]})\n        assert md.get(\"a\", type=int) == 4\n        assert md.getlist(\"b\", type=int) == [2, 3]\n\n        # repr\n        md = self.storage_class([(\"a\", 1), (\"a\", 2), (\"b\", 3)])\n        assert \"('a', 1)\" in repr(md)\n        assert \"('a', 2)\" in repr(md)\n        assert \"('b', 3)\" in repr(md)\n\n        # add and getlist\n        md.add(\"c\", \"42\")\n        md.add(\"c\", \"23\")\n        assert md.getlist(\"c\") == [\"42\", \"23\"]\n        md.add(\"c\", \"blah\")\n        assert md.getlist(\"c\", type=int) == [42, 23]\n\n        # setdefault\n        md = self.storage_class()\n        md.setdefault(\"x\", []).append(42)\n        md.setdefault(\"x\", []).append(23)\n        assert md[\"x\"] == [42, 23]\n\n        # to dict\n        md = self.storage_class()\n        md[\"foo\"] = 42\n        md.add(\"bar\", 1)\n        md.add(\"bar\", 2)\n        assert md.to_dict() == {\"foo\": 42, \"bar\": 1}\n        assert md.to_dict(flat=False) == {\"foo\": [42], \"bar\": [1, 2]}\n\n        # popitem from empty dict\n        with pytest.raises(KeyError):\n            self.storage_class().popitem()\n\n        with pytest.raises(KeyError):\n            self.storage_class().popitemlist()\n\n        # key errors are of a special type\n        with pytest.raises(BadRequestKeyError):\n            self.storage_class()[42]\n\n        # setlist works\n        md = self.storage_class()\n        md[\"foo\"] = 42\n        md.setlist(\"foo\", [1, 2])\n        assert md.getlist(\"foo\") == [1, 2]\n\n\nclass _ImmutableDictTests:\n    storage_class: t.Type[dict]\n\n    def test_follows_dict_interface(self):\n        cls = self.storage_class\n\n        data = {\"foo\": 1, \"bar\": 2, \"baz\": 3}\n        d = cls(data)\n\n        assert d[\"foo\"] == 1\n        assert d[\"bar\"] == 2\n        assert d[\"baz\"] == 3\n        assert sorted(d.keys()) == [\"bar\", \"baz\", \"foo\"]\n        assert \"foo\" in d\n        assert \"foox\" not in d\n        assert len(d) == 3\n\n    def test_copies_are_mutable(self):\n        cls = self.storage_class\n        immutable = cls({\"a\": 1})\n        with pytest.raises(TypeError):\n            immutable.pop(\"a\")\n\n        mutable = immutable.copy()\n        mutable.pop(\"a\")\n        assert \"a\" in immutable\n        assert mutable is not immutable\n        assert copy(immutable) is immutable\n\n    def test_dict_is_hashable(self):\n        cls = self.storage_class\n        immutable = cls({\"a\": 1, \"b\": 2})\n        immutable2 = cls({\"a\": 2, \"b\": 2})\n        x = {immutable}\n        assert immutable in x\n        assert immutable2 not in x\n        x.discard(immutable)\n        assert immutable not in x\n        assert immutable2 not in x\n        x.add(immutable2)\n        assert immutable not in x\n        assert immutable2 in x\n        x.add(immutable)\n        assert immutable in x\n        assert immutable2 in x\n\n\nclass TestImmutableTypeConversionDict(_ImmutableDictTests):\n    storage_class = ds.ImmutableTypeConversionDict\n\n\nclass TestImmutableMultiDict(_ImmutableDictTests):\n    storage_class = ds.ImmutableMultiDict\n\n    def test_multidict_is_hashable(self):\n        cls = self.storage_class\n        immutable = cls({\"a\": [1, 2], \"b\": 2})\n        immutable2 = cls({\"a\": [1], \"b\": 2})\n        x = {immutable}\n        assert immutable in x\n        assert immutable2 not in x\n        x.discard(immutable)\n        assert immutable not in x\n        assert immutable2 not in x\n        x.add(immutable2)\n        assert immutable not in x\n        assert immutable2 in x\n        x.add(immutable)\n        assert immutable in x\n        assert immutable2 in x\n\n\nclass TestImmutableDict(_ImmutableDictTests):\n    storage_class = ds.ImmutableDict\n\n\nclass TestImmutableOrderedMultiDict(_ImmutableDictTests):\n    storage_class = ds.ImmutableOrderedMultiDict\n\n    def test_ordered_multidict_is_hashable(self):\n        a = self.storage_class([(\"a\", 1), (\"b\", 1), (\"a\", 2)])\n        b = self.storage_class([(\"a\", 1), (\"a\", 2), (\"b\", 1)])\n        assert hash(a) != hash(b)\n\n\nclass TestMultiDict(_MutableMultiDictTests):\n    storage_class = ds.MultiDict\n\n    def test_multidict_pop(self):\n        def make_d():\n            return self.storage_class({\"foo\": [1, 2, 3, 4]})\n\n        d = make_d()\n        assert d.pop(\"foo\") == 1\n        assert not d\n        d = make_d()\n        assert d.pop(\"foo\", 32) == 1\n        assert not d\n        d = make_d()\n        assert d.pop(\"foos\", 32) == 32\n        assert d\n\n        with pytest.raises(KeyError):\n            d.pop(\"foos\")\n\n    def test_multidict_pop_raise_badrequestkeyerror_for_empty_list_value(self):\n        mapping = [(\"a\", \"b\"), (\"a\", \"c\")]\n        md = self.storage_class(mapping)\n\n        md.setlistdefault(\"empty\", [])\n\n        with pytest.raises(KeyError):\n            md.pop(\"empty\")\n\n    def test_multidict_popitem_raise_badrequestkeyerror_for_empty_list_value(self):\n        mapping = []\n        md = self.storage_class(mapping)\n\n        md.setlistdefault(\"empty\", [])\n\n        with pytest.raises(BadRequestKeyError):\n            md.popitem()\n\n    def test_setlistdefault(self):\n        md = self.storage_class()\n        assert md.setlistdefault(\"u\", [-1, -2]) == [-1, -2]\n        assert md.getlist(\"u\") == [-1, -2]\n        assert md[\"u\"] == -1\n\n    def test_iter_interfaces(self):\n        mapping = [\n            (\"a\", 1),\n            (\"b\", 2),\n            (\"a\", 2),\n            (\"d\", 3),\n            (\"a\", 1),\n            (\"a\", 3),\n            (\"d\", 4),\n            (\"c\", 3),\n        ]\n        md = self.storage_class(mapping)\n        assert list(zip(md.keys(), md.listvalues())) == list(md.lists())\n        assert list(zip(md, md.listvalues())) == list(md.lists())\n        assert list(zip(md.keys(), md.listvalues())) == list(md.lists())\n\n    def test_getitem_raise_badrequestkeyerror_for_empty_list_value(self):\n        mapping = [(\"a\", \"b\"), (\"a\", \"c\")]\n        md = self.storage_class(mapping)\n\n        md.setlistdefault(\"empty\", [])\n\n        with pytest.raises(KeyError):\n            md[\"empty\"]\n\n\nclass TestOrderedMultiDict(_MutableMultiDictTests):\n    storage_class = ds.OrderedMultiDict\n\n    def test_ordered_interface(self):\n        cls = self.storage_class\n\n        d = cls()\n        assert not d\n        d.add(\"foo\", \"bar\")\n        assert len(d) == 1\n        d.add(\"foo\", \"baz\")\n        assert len(d) == 1\n        assert list(d.items()) == [(\"foo\", \"bar\")]\n        assert list(d) == [\"foo\"]\n        assert list(d.items(multi=True)) == [(\"foo\", \"bar\"), (\"foo\", \"baz\")]\n        del d[\"foo\"]\n        assert not d\n        assert len(d) == 0\n        assert list(d) == []\n\n        d.update([(\"foo\", 1), (\"foo\", 2), (\"bar\", 42)])\n        d.add(\"foo\", 3)\n        assert d.getlist(\"foo\") == [1, 2, 3]\n        assert d.getlist(\"bar\") == [42]\n        assert list(d.items()) == [(\"foo\", 1), (\"bar\", 42)]\n\n        expected = [\"foo\", \"bar\"]\n\n        assert list(d.keys()) == expected\n        assert list(d) == expected\n        assert list(d.keys()) == expected\n\n        assert list(d.items(multi=True)) == [\n            (\"foo\", 1),\n            (\"foo\", 2),\n            (\"bar\", 42),\n            (\"foo\", 3),\n        ]\n        assert len(d) == 2\n\n        assert d.pop(\"foo\") == 1\n        assert d.pop(\"blafasel\", None) is None\n        assert d.pop(\"blafasel\", 42) == 42\n        assert len(d) == 1\n        assert d.poplist(\"bar\") == [42]\n        assert not d\n\n        assert d.get(\"missingkey\") is None\n\n        d.add(\"foo\", 42)\n        d.add(\"foo\", 23)\n        d.add(\"bar\", 2)\n        d.add(\"foo\", 42)\n        assert d == ds.MultiDict(d)\n        id = self.storage_class(d)\n        assert d == id\n        d.add(\"foo\", 2)\n        assert d != id\n\n        d.update({\"blah\": [1, 2, 3]})\n        assert d[\"blah\"] == 1\n        assert d.getlist(\"blah\") == [1, 2, 3]\n\n        # setlist works\n        d = self.storage_class()\n        d[\"foo\"] = 42\n        d.setlist(\"foo\", [1, 2])\n        assert d.getlist(\"foo\") == [1, 2]\n        with pytest.raises(BadRequestKeyError):\n            d.pop(\"missing\")\n\n        with pytest.raises(BadRequestKeyError):\n            d[\"missing\"]\n\n        # popping\n        d = self.storage_class()\n        d.add(\"foo\", 23)\n        d.add(\"foo\", 42)\n        d.add(\"foo\", 1)\n        assert d.popitem() == (\"foo\", 23)\n        with pytest.raises(BadRequestKeyError):\n            d.popitem()\n        assert not d\n\n        d.add(\"foo\", 23)\n        d.add(\"foo\", 42)\n        d.add(\"foo\", 1)\n        assert d.popitemlist() == (\"foo\", [23, 42, 1])\n\n        with pytest.raises(BadRequestKeyError):\n            d.popitemlist()\n\n        # Unhashable\n        d = self.storage_class()\n        d.add(\"foo\", 23)\n        pytest.raises(TypeError, hash, d)\n\n    def test_iterables(self):\n        a = ds.MultiDict(((\"key_a\", \"value_a\"),))\n        b = ds.MultiDict(((\"key_b\", \"value_b\"),))\n        ab = ds.CombinedMultiDict((a, b))\n\n        assert sorted(ab.lists()) == [(\"key_a\", [\"value_a\"]), (\"key_b\", [\"value_b\"])]\n        assert sorted(ab.listvalues()) == [[\"value_a\"], [\"value_b\"]]\n        assert sorted(ab.keys()) == [\"key_a\", \"key_b\"]\n\n        assert sorted(ab.lists()) == [(\"key_a\", [\"value_a\"]), (\"key_b\", [\"value_b\"])]\n        assert sorted(ab.listvalues()) == [[\"value_a\"], [\"value_b\"]]\n        assert sorted(ab.keys()) == [\"key_a\", \"key_b\"]\n\n    def test_get_description(self):\n        data = ds.OrderedMultiDict()\n\n        with pytest.raises(BadRequestKeyError) as exc_info:\n            data[\"baz\"]\n\n        assert \"baz\" not in exc_info.value.get_description()\n        exc_info.value.show_exception = True\n        assert \"baz\" in exc_info.value.get_description()\n\n        with pytest.raises(BadRequestKeyError) as exc_info:\n            data.pop(\"baz\")\n\n        exc_info.value.show_exception = True\n        assert \"baz\" in exc_info.value.get_description()\n        exc_info.value.args = ()\n        assert \"baz\" not in exc_info.value.get_description()\n\n\nclass TestTypeConversionDict:\n    storage_class = ds.TypeConversionDict\n\n    def test_value_conversion(self):\n        d = self.storage_class(foo=\"1\")\n        assert d.get(\"foo\", type=int) == 1\n\n    def test_return_default_when_conversion_is_not_possible(self):\n        d = self.storage_class(foo=\"bar\", baz=None)\n        assert d.get(\"foo\", default=-1, type=int) == -1\n        assert d.get(\"baz\", default=-1, type=int) == -1\n\n    def test_propagate_exceptions_in_conversion(self):\n        d = self.storage_class(foo=\"bar\")\n        switch = {\"a\": 1}\n        with pytest.raises(KeyError):\n            d.get(\"foo\", type=lambda x: switch[x])\n\n\nclass TestCombinedMultiDict:\n    storage_class = ds.CombinedMultiDict\n\n    def test_basic_interface(self):\n        d1 = ds.MultiDict([(\"foo\", \"1\")])\n        d2 = ds.MultiDict([(\"bar\", \"2\"), (\"bar\", \"3\")])\n        d = self.storage_class([d1, d2])\n\n        # lookup\n        assert d[\"foo\"] == \"1\"\n        assert d[\"bar\"] == \"2\"\n        assert d.getlist(\"bar\") == [\"2\", \"3\"]\n\n        assert sorted(d.items()) == [(\"bar\", \"2\"), (\"foo\", \"1\")]\n        assert sorted(d.items(multi=True)) == [(\"bar\", \"2\"), (\"bar\", \"3\"), (\"foo\", \"1\")]\n        assert \"missingkey\" not in d\n        assert \"foo\" in d\n\n        # type lookup\n        assert d.get(\"foo\", type=int) == 1\n        assert d.getlist(\"bar\", type=int) == [2, 3]\n\n        # get key errors for missing stuff\n        with pytest.raises(KeyError):\n            d[\"missing\"]\n\n        # make sure that they are immutable\n        with pytest.raises(TypeError):\n            d[\"foo\"] = \"blub\"\n\n        # copies are mutable\n        d = d.copy()\n        d[\"foo\"] = \"blub\"\n\n        # make sure lists merges\n        md1 = ds.MultiDict(((\"foo\", \"bar\"), (\"foo\", \"baz\")))\n        md2 = ds.MultiDict(((\"foo\", \"blafasel\"),))\n        x = self.storage_class((md1, md2))\n        assert list(x.lists()) == [(\"foo\", [\"bar\", \"baz\", \"blafasel\"])]\n\n        # make sure dicts are created properly\n        assert x.to_dict() == {\"foo\": \"bar\"}\n        assert x.to_dict(flat=False) == {\"foo\": [\"bar\", \"baz\", \"blafasel\"]}\n\n    def test_length(self):\n        d1 = ds.MultiDict([(\"foo\", \"1\")])\n        d2 = ds.MultiDict([(\"bar\", \"2\")])\n        assert len(d1) == len(d2) == 1\n        d = self.storage_class([d1, d2])\n        assert len(d) == 2\n        d1.clear()\n        assert len(d1) == 0\n        assert len(d) == 1\n\n\nclass TestHeaders:\n    storage_class = ds.Headers\n\n    def test_basic_interface(self):\n        headers = self.storage_class()\n        headers.add(\"Content-Type\", \"text/plain\")\n        headers.add(\"X-Foo\", \"bar\")\n        assert \"x-Foo\" in headers\n        assert \"Content-type\" in headers\n\n        with pytest.raises(ValueError):\n            headers.add(\"X-Example\", \"foo\\r\\n bar\")\n\n        headers[\"Content-Type\"] = \"foo/bar\"\n        assert headers[\"Content-Type\"] == \"foo/bar\"\n        assert len(headers.getlist(\"Content-Type\")) == 1\n\n        # list conversion\n        assert headers.to_wsgi_list() == [(\"Content-Type\", \"foo/bar\"), (\"X-Foo\", \"bar\")]\n        assert str(headers) == \"Content-Type: foo/bar\\r\\nX-Foo: bar\\r\\n\\r\\n\"\n        assert str(self.storage_class()) == \"\\r\\n\"\n\n        # extended add\n        headers.add(\"Content-Disposition\", \"attachment\", filename=\"foo\")\n        assert headers[\"Content-Disposition\"] == \"attachment; filename=foo\"\n\n        headers.add(\"x\", \"y\", z='\"')\n        assert headers[\"x\"] == r'y; z=\"\\\"\"'\n\n        # string conversion\n        headers.add(\"a\", 1)\n        assert headers[\"a\"] == \"1\"\n\n    def test_defaults_and_conversion(self):\n        # defaults\n        headers = self.storage_class(\n            [\n                (\"Content-Type\", \"text/plain\"),\n                (\"X-Foo\", \"bar\"),\n                (\"X-Bar\", \"1\"),\n                (\"X-Bar\", \"2\"),\n            ]\n        )\n        assert headers.getlist(\"x-bar\") == [\"1\", \"2\"]\n        assert headers.get(\"x-Bar\") == \"1\"\n        assert headers.get(\"Content-Type\") == \"text/plain\"\n\n        assert headers.setdefault(\"X-Foo\", \"nope\") == \"bar\"\n        assert headers.setdefault(\"X-Bar\", \"nope\") == \"1\"\n        assert headers.setdefault(\"X-Baz\", \"quux\") == \"quux\"\n        assert headers.setdefault(\"X-Baz\", \"nope\") == \"quux\"\n        headers.pop(\"X-Baz\")\n\n        # newlines are not allowed in values\n        with pytest.raises(ValueError):\n            self.storage_class([(\"X-Example\", \"foo\\r\\n bar\")])\n\n        # type conversion\n        assert headers.get(\"x-bar\", type=int) == 1\n        assert headers.getlist(\"x-bar\", type=int) == [1, 2]\n\n        # list like operations\n        assert headers[0] == (\"Content-Type\", \"text/plain\")\n        assert headers[:1] == self.storage_class([(\"Content-Type\", \"text/plain\")])\n        del headers[:2]\n        del headers[-1]\n        assert headers == self.storage_class([(\"X-Bar\", \"1\")])\n\n    def test_copying(self):\n        a = self.storage_class([(\"foo\", \"bar\")])\n        b = a.copy()\n        a.add(\"foo\", \"baz\")\n        assert a.getlist(\"foo\") == [\"bar\", \"baz\"]\n        assert b.getlist(\"foo\") == [\"bar\"]\n\n    def test_popping(self):\n        headers = self.storage_class([(\"a\", 1)])\n        # headers object expect string values. If a non string value\n        # is passed, it tries converting it to a string\n        assert headers.pop(\"a\") == \"1\"\n        assert headers.pop(\"b\", \"2\") == \"2\"\n\n        with pytest.raises(KeyError):\n            headers.pop(\"c\")\n\n    def test_set_arguments(self):\n        a = self.storage_class()\n        a.set(\"Content-Disposition\", \"useless\")\n        a.set(\"Content-Disposition\", \"attachment\", filename=\"foo\")\n        assert a[\"Content-Disposition\"] == \"attachment; filename=foo\"\n\n    def test_reject_newlines(self):\n        h = self.storage_class()\n\n        for variation in \"foo\\nbar\", \"foo\\r\\nbar\", \"foo\\rbar\":\n            with pytest.raises(ValueError):\n                h[\"foo\"] = variation\n            with pytest.raises(ValueError):\n                h.add(\"foo\", variation)\n            with pytest.raises(ValueError):\n                h.add(\"foo\", \"test\", option=variation)\n            with pytest.raises(ValueError):\n                h.set(\"foo\", variation)\n            with pytest.raises(ValueError):\n                h.set(\"foo\", \"test\", option=variation)\n\n    def test_slicing(self):\n        # there's nothing wrong with these being native strings\n        # Headers doesn't care about the data types\n        h = self.storage_class()\n        h.set(\"X-Foo-Poo\", \"bleh\")\n        h.set(\"Content-Type\", \"application/whocares\")\n        h.set(\"X-Forwarded-For\", \"192.168.0.123\")\n        h[:] = [(k, v) for k, v in h if k.startswith(\"X-\")]\n        assert list(h) == [(\"X-Foo-Poo\", \"bleh\"), (\"X-Forwarded-For\", \"192.168.0.123\")]\n\n    def test_extend(self):\n        h = self.storage_class([(\"a\", \"0\"), (\"b\", \"1\"), (\"c\", \"2\")])\n        h.extend(ds.Headers([(\"a\", \"3\"), (\"a\", \"4\")]))\n        assert h.getlist(\"a\") == [\"0\", \"3\", \"4\"]\n        h.extend(b=[\"5\", \"6\"])\n        assert h.getlist(\"b\") == [\"1\", \"5\", \"6\"]\n        h.extend({\"c\": \"7\", \"d\": [\"8\", \"9\"]}, c=\"10\")\n        assert h.getlist(\"c\") == [\"2\", \"7\", \"10\"]\n        assert h.getlist(\"d\") == [\"8\", \"9\"]\n\n        with pytest.raises(TypeError):\n            h.extend({\"x\": \"x\"}, {\"x\": \"x\"})\n\n    def test_update(self):\n        h = self.storage_class([(\"a\", \"0\"), (\"b\", \"1\"), (\"c\", \"2\")])\n        h.update(ds.Headers([(\"a\", \"3\"), (\"a\", \"4\")]))\n        assert h.getlist(\"a\") == [\"3\", \"4\"]\n        h.update(b=[\"5\", \"6\"])\n        assert h.getlist(\"b\") == [\"5\", \"6\"]\n        h.update({\"c\": \"7\", \"d\": [\"8\", \"9\"]})\n        assert h.getlist(\"c\") == [\"7\"]\n        assert h.getlist(\"d\") == [\"8\", \"9\"]\n        h.update({\"c\": \"10\"}, c=\"11\")\n        assert h.getlist(\"c\") == [\"11\"]\n\n        with pytest.raises(TypeError):\n            h.extend({\"x\": \"x\"}, {\"x\": \"x\"})\n\n    def test_setlist(self):\n        h = self.storage_class([(\"a\", \"0\"), (\"b\", \"1\"), (\"c\", \"2\")])\n        h.setlist(\"b\", [\"3\", \"4\"])\n        assert h[1] == (\"b\", \"3\")\n        assert h[-1] == (\"b\", \"4\")\n        h.setlist(\"b\", [])\n        assert \"b\" not in h\n        h.setlist(\"d\", [\"5\"])\n        assert h[\"d\"] == \"5\"\n\n    def test_setlistdefault(self):\n        h = self.storage_class([(\"a\", \"0\"), (\"b\", \"1\"), (\"c\", \"2\")])\n        assert h.setlistdefault(\"a\", [\"3\"]) == [\"0\"]\n        assert h.setlistdefault(\"d\", [\"4\", \"5\"]) == [\"4\", \"5\"]\n\n    def test_to_wsgi_list(self):\n        h = self.storage_class()\n        h.set(\"Key\", \"Value\")\n        for key, value in h.to_wsgi_list():\n            assert key == \"Key\"\n            assert value == \"Value\"\n\n    def test_equality(self):\n        # test equality, given keys are case insensitive\n        h1 = self.storage_class()\n        h1.add(\"X-Foo\", \"foo\")\n        h1.add(\"X-Bar\", \"bah\")\n        h1.add(\"X-Bar\", \"humbug\")\n\n        h2 = self.storage_class()\n        h2.add(\"x-foo\", \"foo\")\n        h2.add(\"x-bar\", \"bah\")\n        h2.add(\"x-bar\", \"humbug\")\n\n        assert h1 == h2\n\n\nclass TestEnvironHeaders:\n    storage_class = ds.EnvironHeaders\n\n    def test_basic_interface(self):\n        # this happens in multiple WSGI servers because they\n        # use a vary naive way to convert the headers;\n        broken_env = {\n            \"HTTP_CONTENT_TYPE\": \"text/html\",\n            \"CONTENT_TYPE\": \"text/html\",\n            \"HTTP_CONTENT_LENGTH\": \"0\",\n            \"CONTENT_LENGTH\": \"0\",\n            \"HTTP_ACCEPT\": \"*\",\n            \"wsgi.version\": (1, 0),\n        }\n        headers = self.storage_class(broken_env)\n        assert headers\n        assert len(headers) == 3\n        assert sorted(headers) == [\n            (\"Accept\", \"*\"),\n            (\"Content-Length\", \"0\"),\n            (\"Content-Type\", \"text/html\"),\n        ]\n        assert not self.storage_class({\"wsgi.version\": (1, 0)})\n        assert len(self.storage_class({\"wsgi.version\": (1, 0)})) == 0\n        assert 42 not in headers\n\n    def test_skip_empty_special_vars(self):\n        env = {\"HTTP_X_FOO\": \"42\", \"CONTENT_TYPE\": \"\", \"CONTENT_LENGTH\": \"\"}\n        headers = self.storage_class(env)\n        assert dict(headers) == {\"X-Foo\": \"42\"}\n\n        env = {\"HTTP_X_FOO\": \"42\", \"CONTENT_TYPE\": \"\", \"CONTENT_LENGTH\": \"0\"}\n        headers = self.storage_class(env)\n        assert dict(headers) == {\"X-Foo\": \"42\", \"Content-Length\": \"0\"}\n\n    def test_return_type_is_str(self):\n        headers = self.storage_class({\"HTTP_FOO\": \"\\xe2\\x9c\\x93\"})\n        assert headers[\"Foo\"] == \"\\xe2\\x9c\\x93\"\n        assert next(iter(headers)) == (\"Foo\", \"\\xe2\\x9c\\x93\")\n\n\nclass TestHeaderSet:\n    storage_class = ds.HeaderSet\n\n    def test_basic_interface(self):\n        hs = self.storage_class()\n        hs.add(\"foo\")\n        hs.add(\"bar\")\n        assert \"Bar\" in hs\n        assert hs.find(\"foo\") == 0\n        assert hs.find(\"BAR\") == 1\n        assert hs.find(\"baz\") < 0\n        hs.discard(\"missing\")\n        hs.discard(\"foo\")\n        assert hs.find(\"foo\") < 0\n        assert hs.find(\"bar\") == 0\n\n        with pytest.raises(IndexError):\n            hs.index(\"missing\")\n\n        assert hs.index(\"bar\") == 0\n        assert hs\n        hs.clear()\n        assert not hs\n\n\nclass TestImmutableList:\n    storage_class = ds.ImmutableList\n\n    def test_list_hashable(self):\n        data = (1, 2, 3, 4)\n        store = self.storage_class(data)\n        assert hash(data) == hash(store)\n        assert data != store\n\n\ndef make_call_asserter(func=None):\n    \"\"\"Utility to assert a certain number of function calls.\n\n    :param func: Additional callback for each function call.\n\n    .. code-block:: python\n        assert_calls, func = make_call_asserter()\n        with assert_calls(2):\n            func()\n            func()\n    \"\"\"\n    calls = [0]\n\n    @contextmanager\n    def asserter(count, msg=None):\n        calls[0] = 0\n        yield\n        assert calls[0] == count\n\n    def wrapped(*args, **kwargs):\n        calls[0] += 1\n        if func is not None:\n            return func(*args, **kwargs)\n\n    return asserter, wrapped\n\n\nclass TestCallbackDict:\n    storage_class = ds.CallbackDict\n\n    def test_callback_dict_reads(self):\n        assert_calls, func = make_call_asserter()\n        initial = {\"a\": \"foo\", \"b\": \"bar\"}\n        dct = self.storage_class(initial=initial, on_update=func)\n        with assert_calls(0, \"callback triggered by read-only method\"):\n            # read-only methods\n            dct[\"a\"]\n            dct.get(\"a\")\n            pytest.raises(KeyError, lambda: dct[\"x\"])\n            assert \"a\" in dct\n            list(iter(dct))\n            dct.copy()\n        with assert_calls(0, \"callback triggered without modification\"):\n            # methods that may write but don't\n            dct.pop(\"z\", None)\n            dct.setdefault(\"a\")\n\n    def test_callback_dict_writes(self):\n        assert_calls, func = make_call_asserter()\n        initial = {\"a\": \"foo\", \"b\": \"bar\"}\n        dct = self.storage_class(initial=initial, on_update=func)\n        with assert_calls(8, \"callback not triggered by write method\"):\n            # always-write methods\n            dct[\"z\"] = 123\n            dct[\"z\"] = 123  # must trigger again\n            del dct[\"z\"]\n            dct.pop(\"b\", None)\n            dct.setdefault(\"x\")\n            dct.popitem()\n            dct.update([])\n            dct.clear()\n        with assert_calls(0, \"callback triggered by failed del\"):\n            pytest.raises(KeyError, lambda: dct.__delitem__(\"x\"))\n        with assert_calls(0, \"callback triggered by failed pop\"):\n            pytest.raises(KeyError, lambda: dct.pop(\"x\"))\n\n\nclass TestCacheControl:\n    def test_repr(self):\n        cc = ds.RequestCacheControl([(\"max-age\", \"0\"), (\"private\", \"True\")])\n        assert repr(cc) == \"<RequestCacheControl max-age='0' private='True'>\"\n\n    def test_set_none(self):\n        cc = ds.ResponseCacheControl([(\"max-age\", \"0\")])\n        assert cc.no_cache is None\n        cc.no_cache = None\n        assert cc.no_cache is None\n        cc.no_cache = False\n        assert cc.no_cache is False\n\n\nclass TestContentSecurityPolicy:\n    def test_construct(self):\n        csp = ds.ContentSecurityPolicy([(\"font-src\", \"'self'\"), (\"media-src\", \"*\")])\n        assert csp.font_src == \"'self'\"\n        assert csp.media_src == \"*\"\n        policies = [policy.strip() for policy in csp.to_header().split(\";\")]\n        assert \"font-src 'self'\" in policies\n        assert \"media-src *\" in policies\n\n    def test_properties(self):\n        csp = ds.ContentSecurityPolicy()\n        csp.default_src = \"* 'self' quart.com\"\n        csp.img_src = \"'none'\"\n        policies = [policy.strip() for policy in csp.to_header().split(\";\")]\n        assert \"default-src * 'self' quart.com\" in policies\n        assert \"img-src 'none'\" in policies\n\n\nclass TestAccept:\n    storage_class = ds.Accept\n\n    def test_accept_basic(self):\n        accept = self.storage_class(\n            [(\"tinker\", 0), (\"tailor\", 0.333), (\"soldier\", 0.667), (\"sailor\", 1)]\n        )\n        # check __getitem__ on indices\n        assert accept[3] == (\"tinker\", 0)\n        assert accept[2] == (\"tailor\", 0.333)\n        assert accept[1] == (\"soldier\", 0.667)\n        assert accept[0], (\"sailor\", 1)\n        # check __getitem__ on string\n        assert accept[\"tinker\"] == 0\n        assert accept[\"tailor\"] == 0.333\n        assert accept[\"soldier\"] == 0.667\n        assert accept[\"sailor\"] == 1\n        assert accept[\"spy\"] == 0\n        # check quality method\n        assert accept.quality(\"tinker\") == 0\n        assert accept.quality(\"tailor\") == 0.333\n        assert accept.quality(\"soldier\") == 0.667\n        assert accept.quality(\"sailor\") == 1\n        assert accept.quality(\"spy\") == 0\n        # check __contains__\n        assert \"sailor\" in accept\n        assert \"spy\" not in accept\n        # check index method\n        assert accept.index(\"tinker\") == 3\n        assert accept.index(\"tailor\") == 2\n        assert accept.index(\"soldier\") == 1\n        assert accept.index(\"sailor\") == 0\n        with pytest.raises(ValueError):\n            accept.index(\"spy\")\n        # check find method\n        assert accept.find(\"tinker\") == 3\n        assert accept.find(\"tailor\") == 2\n        assert accept.find(\"soldier\") == 1\n        assert accept.find(\"sailor\") == 0\n        assert accept.find(\"spy\") == -1\n        # check to_header method\n        assert accept.to_header() == \"sailor,soldier;q=0.667,tailor;q=0.333,tinker;q=0\"\n        # check best_match method\n        assert (\n            accept.best_match([\"tinker\", \"tailor\", \"soldier\", \"sailor\"], default=None)\n            == \"sailor\"\n        )\n        assert (\n            accept.best_match([\"tinker\", \"tailor\", \"soldier\"], default=None)\n            == \"soldier\"\n        )\n        assert accept.best_match([\"tinker\", \"tailor\"], default=None) == \"tailor\"\n        assert accept.best_match([\"tinker\"], default=None) is None\n        assert accept.best_match([\"tinker\"], default=\"x\") == \"x\"\n\n    def test_accept_wildcard(self):\n        accept = self.storage_class([(\"*\", 0), (\"asterisk\", 1)])\n        assert \"*\" in accept\n        assert accept.best_match([\"asterisk\", \"star\"], default=None) == \"asterisk\"\n        assert accept.best_match([\"star\"], default=None) is None\n\n    def test_accept_keep_order(self):\n        accept = self.storage_class([(\"*\", 1)])\n        assert accept.best_match([\"alice\", \"bob\"]) == \"alice\"\n        assert accept.best_match([\"bob\", \"alice\"]) == \"bob\"\n        accept = self.storage_class([(\"alice\", 1), (\"bob\", 1)])\n        assert accept.best_match([\"alice\", \"bob\"]) == \"alice\"\n        assert accept.best_match([\"bob\", \"alice\"]) == \"bob\"\n\n    def test_accept_wildcard_specificity(self):\n        accept = self.storage_class([(\"asterisk\", 0), (\"star\", 0.5), (\"*\", 1)])\n        assert accept.best_match([\"star\", \"asterisk\"], default=None) == \"star\"\n        assert accept.best_match([\"asterisk\", \"star\"], default=None) == \"star\"\n        assert accept.best_match([\"asterisk\", \"times\"], default=None) == \"times\"\n        assert accept.best_match([\"asterisk\"], default=None) is None\n\n    def test_accept_equal_quality(self):\n        accept = self.storage_class([(\"a\", 1), (\"b\", 1)])\n        assert accept.best == \"a\"\n\n\nclass TestMIMEAccept:\n    @pytest.mark.parametrize(\n        (\"values\", \"matches\", \"default\", \"expect\"),\n        [\n            ([(\"text/*\", 1)], [\"text/html\"], None, \"text/html\"),\n            ([(\"text/*\", 1)], [\"image/png\"], \"text/plain\", \"text/plain\"),\n            ([(\"text/*\", 1)], [\"image/png\"], None, None),\n            (\n                [(\"*/*\", 1), (\"text/html\", 1)],\n                [\"image/png\", \"text/html\"],\n                None,\n                \"text/html\",\n            ),\n            (\n                [(\"*/*\", 1), (\"text/html\", 1)],\n                [\"image/png\", \"text/plain\"],\n                None,\n                \"image/png\",\n            ),\n            (\n                [(\"*/*\", 1), (\"text/html\", 1), (\"image/*\", 1)],\n                [\"image/png\", \"text/html\"],\n                None,\n                \"text/html\",\n            ),\n            (\n                [(\"*/*\", 1), (\"text/html\", 1), (\"image/*\", 1)],\n                [\"text/plain\", \"image/png\"],\n                None,\n                \"image/png\",\n            ),\n            (\n                [(\"text/html\", 1), (\"text/html; level=1\", 1)],\n                [\"text/html;level=1\"],\n                None,\n                \"text/html;level=1\",\n            ),\n        ],\n    )\n    def test_mime_accept(self, values, matches, default, expect):\n        accept = ds.MIMEAccept(values)\n        match = accept.best_match(matches, default=default)\n        assert match == expect\n\n\nclass TestLanguageAccept:\n    @pytest.mark.parametrize(\n        (\"values\", \"matches\", \"default\", \"expect\"),\n        (\n            ([(\"en-us\", 1)], [\"en\"], None, \"en\"),\n            ([(\"en\", 1)], [\"en_US\"], None, \"en_US\"),\n            ([(\"en-GB\", 1)], [\"en-US\"], None, None),\n            ([(\"de_AT\", 1), (\"de\", 0.9)], [\"en\"], None, None),\n            ([(\"de_AT\", 1), (\"de\", 0.9), (\"en-US\", 0.8)], [\"de\", \"en\"], None, \"de\"),\n            ([(\"de_AT\", 0.9), (\"en-US\", 1)], [\"en\"], None, \"en\"),\n            ([(\"en-us\", 1)], [\"en-us\"], None, \"en-us\"),\n            ([(\"en-us\", 1)], [\"en-us\", \"en\"], None, \"en-us\"),\n            ([(\"en-GB\", 1)], [\"en-US\", \"en\"], \"en-US\", \"en\"),\n            ([(\"de_AT\", 1)], [\"en-US\", \"en\"], \"en-US\", \"en-US\"),\n            ([(\"aus-EN\", 1)], [\"aus\"], None, \"aus\"),\n            ([(\"aus\", 1)], [\"aus-EN\"], None, \"aus-EN\"),\n        ),\n    )\n    def test_best_match_fallback(self, values, matches, default, expect):\n        accept = ds.LanguageAccept(values)\n        best = accept.best_match(matches, default=default)\n        assert best == expect\n\n\nclass TestFileStorage:\n    storage_class = ds.FileStorage\n\n    def test_mimetype_always_lowercase(self):\n        file_storage = self.storage_class(content_type=\"APPLICATION/JSON\")\n        assert file_storage.mimetype == \"application/json\"\n\n    @pytest.mark.parametrize(\"data\", [io.StringIO(\"one\\ntwo\"), io.BytesIO(b\"one\\ntwo\")])\n    def test_bytes_proper_sentinel(self, data):\n        # iterate over new lines and don't enter an infinite loop\n        storage = self.storage_class(data)\n        idx = -1\n\n        for idx, _line in enumerate(storage):\n            assert idx < 2\n\n        assert idx == 1\n\n    @pytest.mark.parametrize(\"stream\", (tempfile.SpooledTemporaryFile, io.BytesIO))\n    def test_proxy_can_access_stream_attrs(self, stream):\n        \"\"\"``SpooledTemporaryFile`` doesn't implement some of\n        ``IOBase``. Ensure that ``FileStorage`` can still access the\n        attributes from the backing file object.\n\n        https://github.com/pallets/werkzeug/issues/1344\n        https://github.com/python/cpython/pull/3249\n        \"\"\"\n        file_storage = self.storage_class(stream=stream())\n\n        for name in (\"fileno\", \"writable\", \"readable\", \"seekable\"):\n            assert hasattr(file_storage, name)\n\n        file_storage.close()\n\n    def test_save_to_pathlib_dst(self, tmp_path):\n        src = tmp_path / \"src.txt\"\n        src.write_text(\"test\")\n        dst = tmp_path / \"dst.txt\"\n\n        with src.open(\"rb\") as f:\n            storage = self.storage_class(f)\n            storage.save(dst)\n\n        assert dst.read_text() == \"test\"\n\n    def test_save_to_bytes_io(self):\n        storage = self.storage_class(io.BytesIO(b\"one\\ntwo\"))\n        dst = io.BytesIO()\n        storage.save(dst)\n        assert dst.getvalue() == b\"one\\ntwo\"\n\n    def test_save_to_file(self, tmp_path):\n        path = tmp_path / \"file.data\"\n        storage = self.storage_class(io.BytesIO(b\"one\\ntwo\"))\n        with path.open(\"wb\") as dst:\n            storage.save(dst)\n        with path.open(\"rb\") as src:\n            assert src.read() == b\"one\\ntwo\"\n\n\n@pytest.mark.parametrize(\"ranges\", ([(0, 1), (-5, None)], [(5, None)]))\ndef test_range_to_header(ranges):\n    header = ds.Range(\"byes\", ranges).to_header()\n    r = http.parse_range_header(header)\n    assert r.ranges == ranges\n\n\n@pytest.mark.parametrize(\n    \"ranges\", ([(0, 0)], [(None, 1)], [(1, 0)], [(0, 1), (-5, 10)])\n)\ndef test_range_validates_ranges(ranges):\n    with pytest.raises(ValueError):\n        ds.Range(\"bytes\", ranges)\n", "tests/test_urls.py": "import pytest\n\nfrom werkzeug import urls\n\n\ndef test_iri_support():\n    assert urls.uri_to_iri(\"http://xn--n3h.net/\") == \"http://\\u2603.net/\"\n    assert urls.iri_to_uri(\"http://\u2603.net/\") == \"http://xn--n3h.net/\"\n    assert (\n        urls.iri_to_uri(\"http://\u00fcser:p\u00e4ssword@\u2603.net/p\u00e5th\")\n        == \"http://%C3%BCser:p%C3%A4ssword@xn--n3h.net/p%C3%A5th\"\n    )\n    assert (\n        urls.uri_to_iri(\"http://test.com/%3Fmeh?foo=%26%2F\")\n        == \"http://test.com/%3Fmeh?foo=%26/\"\n    )\n    assert urls.iri_to_uri(\"/foo\") == \"/foo\"\n    assert (\n        urls.iri_to_uri(\"http://f\u00f6\u00f6.com:8080/bam/baz\")\n        == \"http://xn--f-1gaa.com:8080/bam/baz\"\n    )\n\n\ndef test_iri_safe_quoting():\n    uri = \"http://xn--f-1gaa.com/%2F%25?q=%C3%B6&x=%3D%25#%25\"\n    iri = \"http://f\u00f6\u00f6.com/%2F%25?q=\u00f6&x=%3D%25#%25\"\n    assert urls.uri_to_iri(uri) == iri\n    assert urls.iri_to_uri(urls.uri_to_iri(uri)) == uri\n\n\ndef test_quoting_of_local_urls():\n    rv = urls.iri_to_uri(\"/foo\\x8f\")\n    assert rv == \"/foo%C2%8F\"\n\n\ndef test_iri_to_uri_idempotence_ascii_only():\n    uri = \"http://www.idempoten.ce\"\n    uri = urls.iri_to_uri(uri)\n    assert urls.iri_to_uri(uri) == uri\n\n\ndef test_iri_to_uri_idempotence_non_ascii():\n    uri = \"http://\\N{SNOWMAN}/\\N{SNOWMAN}\"\n    uri = urls.iri_to_uri(uri)\n    assert urls.iri_to_uri(uri) == uri\n\n\ndef test_uri_to_iri_idempotence_ascii_only():\n    uri = \"http://www.idempoten.ce\"\n    uri = urls.uri_to_iri(uri)\n    assert urls.uri_to_iri(uri) == uri\n\n\ndef test_uri_to_iri_idempotence_non_ascii():\n    uri = \"http://xn--n3h/%E2%98%83\"\n    uri = urls.uri_to_iri(uri)\n    assert urls.uri_to_iri(uri) == uri\n\n\ndef test_iri_to_uri_to_iri():\n    iri = \"http://f\u00f6\u00f6.com/\"\n    uri = urls.iri_to_uri(iri)\n    assert urls.uri_to_iri(uri) == iri\n\n\ndef test_uri_to_iri_to_uri():\n    uri = \"http://xn--f-rgao.com/%C3%9E\"\n    iri = urls.uri_to_iri(uri)\n    assert urls.iri_to_uri(iri) == uri\n\n\n@pytest.mark.parametrize(\n    \"value\",\n    [\n        \"http://f\u00f6\u00f1.com/\\N{BALLOT BOX}/fred?utf8=\\u2713\",\n        \"http://xn--f-rgao.com/\\u2610/fred?utf8=\\N{CHECK MARK}\",\n        \"http://xn--f-rgao.com/%E2%98%90/fred?utf8=%E2%9C%93\",\n        \"http://xn--f-rgao.com/%E2%98%90/fred?utf8=%E2%9C%93\",\n        \"http://f\u00f6\u00f1.com/\\u2610/fred?utf8=%E2%9C%93\",\n    ],\n)\ndef test_uri_iri_normalization(value):\n    uri = \"http://xn--f-rgao.com/%E2%98%90/fred?utf8=%E2%9C%93\"\n    iri = \"http://f\u00f6\u00f1.com/\\N{BALLOT BOX}/fred?utf8=\\u2713\"\n    assert urls.uri_to_iri(value) == iri\n    assert urls.iri_to_uri(value) == uri\n    assert urls.uri_to_iri(urls.iri_to_uri(value)) == iri\n    assert urls.iri_to_uri(urls.uri_to_iri(value)) == uri\n    assert urls.uri_to_iri(urls.uri_to_iri(value)) == iri\n    assert urls.iri_to_uri(urls.iri_to_uri(value)) == uri\n\n\ndef test_uri_to_iri_dont_unquote_space():\n    assert urls.uri_to_iri(\"abc%20def\") == \"abc%20def\"\n\n\ndef test_iri_to_uri_dont_quote_valid_code_points():\n    # [] are not valid URL code points according to WhatWG URL Standard\n    # https://url.spec.whatwg.org/#url-code-points\n    assert urls.iri_to_uri(\"/path[bracket]?(paren)\") == \"/path%5Bbracket%5D?(paren)\"\n\n\n# Python < 3.12\ndef test_itms_services() -> None:\n    url = \"itms-services://?action=download-manifest&url=https://test.example/path\"\n    assert urls.iri_to_uri(url) == url\n", "tests/test_formparser.py": "import csv\nimport io\nfrom os.path import dirname\nfrom os.path import join\n\nimport pytest\n\nfrom werkzeug import formparser\nfrom werkzeug.datastructures import MultiDict\nfrom werkzeug.exceptions import RequestEntityTooLarge\nfrom werkzeug.formparser import FormDataParser\nfrom werkzeug.formparser import parse_form_data\nfrom werkzeug.test import Client\nfrom werkzeug.test import create_environ\nfrom werkzeug.wrappers import Request\nfrom werkzeug.wrappers import Response\n\n\n@Request.application\ndef form_data_consumer(request):\n    result_object = request.args[\"object\"]\n    if result_object == \"text\":\n        return Response(repr(request.form[\"text\"]))\n    f = request.files[result_object]\n    return Response(\n        b\"\\n\".join(\n            (\n                repr(f.filename).encode(\"ascii\"),\n                repr(f.name).encode(\"ascii\"),\n                repr(f.content_type).encode(\"ascii\"),\n                f.stream.read(),\n            )\n        )\n    )\n\n\ndef get_contents(filename):\n    with open(filename, \"rb\") as f:\n        return f.read()\n\n\nclass TestFormParser:\n    def test_limiting(self):\n        data = b\"foo=Hello+World&bar=baz\"\n        req = Request.from_values(\n            input_stream=io.BytesIO(data),\n            content_length=len(data),\n            content_type=\"application/x-www-form-urlencoded\",\n            method=\"POST\",\n        )\n        req.max_content_length = 400\n        assert req.form[\"foo\"] == \"Hello World\"\n\n        req = Request.from_values(\n            input_stream=io.BytesIO(data),\n            content_length=len(data),\n            content_type=\"application/x-www-form-urlencoded\",\n            method=\"POST\",\n        )\n        req.max_form_memory_size = 7\n        pytest.raises(RequestEntityTooLarge, lambda: req.form[\"foo\"])\n\n        req = Request.from_values(\n            input_stream=io.BytesIO(data),\n            content_length=len(data),\n            content_type=\"application/x-www-form-urlencoded\",\n            method=\"POST\",\n        )\n        req.max_form_memory_size = 400\n        assert req.form[\"foo\"] == \"Hello World\"\n\n        input_stream = io.BytesIO(b\"foo=123456\")\n        req = Request.from_values(\n            input_stream=input_stream,\n            content_type=\"application/x-www-form-urlencoded\",\n            method=\"POST\",\n        )\n        req.max_content_length = 4\n        pytest.raises(RequestEntityTooLarge, lambda: req.form[\"foo\"])\n        # content-length was set, so request could exit early without reading anything\n        assert input_stream.read() == b\"foo=123456\"\n\n        data = (\n            b\"--foo\\r\\nContent-Disposition: form-field; name=foo\\r\\n\\r\\n\"\n            b\"Hello World\\r\\n\"\n            b\"--foo\\r\\nContent-Disposition: form-field; name=bar\\r\\n\\r\\n\"\n            b\"bar=baz\\r\\n--foo--\"\n        )\n        req = Request.from_values(\n            input_stream=io.BytesIO(data),\n            content_length=len(data),\n            content_type=\"multipart/form-data; boundary=foo\",\n            method=\"POST\",\n        )\n        req.max_content_length = 400\n        assert req.form[\"foo\"] == \"Hello World\"\n\n        req = Request.from_values(\n            input_stream=io.BytesIO(data),\n            content_length=len(data),\n            content_type=\"multipart/form-data; boundary=foo\",\n            method=\"POST\",\n        )\n        req.max_form_memory_size = 7\n        pytest.raises(RequestEntityTooLarge, lambda: req.form[\"foo\"])\n\n        req = Request.from_values(\n            input_stream=io.BytesIO(data),\n            content_length=len(data),\n            content_type=\"multipart/form-data; boundary=foo\",\n            method=\"POST\",\n        )\n        req.max_form_memory_size = 400\n        assert req.form[\"foo\"] == \"Hello World\"\n\n        req = Request.from_values(\n            input_stream=io.BytesIO(data),\n            content_length=len(data),\n            content_type=\"multipart/form-data; boundary=foo\",\n            method=\"POST\",\n        )\n        req.max_form_parts = 1\n        pytest.raises(RequestEntityTooLarge, lambda: req.form[\"foo\"])\n\n    def test_x_www_urlencoded_max_form_parts(self):\n        r = Request.from_values(method=\"POST\", data={\"a\": 1, \"b\": 2})\n        r.max_form_parts = 1\n\n        assert r.form[\"a\"] == \"1\"\n        assert r.form[\"b\"] == \"2\"\n\n    def test_missing_multipart_boundary(self):\n        data = (\n            b\"--foo\\r\\nContent-Disposition: form-field; name=foo\\r\\n\\r\\n\"\n            b\"Hello World\\r\\n\"\n            b\"--foo\\r\\nContent-Disposition: form-field; name=bar\\r\\n\\r\\n\"\n            b\"bar=baz\\r\\n--foo--\"\n        )\n        req = Request.from_values(\n            input_stream=io.BytesIO(data),\n            content_length=len(data),\n            content_type=\"multipart/form-data\",\n            method=\"POST\",\n        )\n        assert req.form == {}\n\n    def test_parse_form_data_put_without_content(self):\n        # A PUT without a Content-Type header returns empty data\n\n        # Both rfc1945 and rfc2616 (1.0 and 1.1) say \"Any HTTP/[1.0/1.1] message\n        # containing an entity-body SHOULD include a Content-Type header field\n        # defining the media type of that body.\"  In the case where either\n        # headers are omitted, parse_form_data should still work.\n        env = create_environ(\"/foo\", \"http://example.org/\", method=\"PUT\")\n\n        stream, form, files = formparser.parse_form_data(env)\n        assert stream.read() == b\"\"\n        assert len(form) == 0\n        assert len(files) == 0\n\n    def test_parse_form_data_get_without_content(self):\n        env = create_environ(\"/foo\", \"http://example.org/\", method=\"GET\")\n\n        stream, form, files = formparser.parse_form_data(env)\n        assert stream.read() == b\"\"\n        assert len(form) == 0\n        assert len(files) == 0\n\n    @pytest.mark.parametrize(\n        (\"no_spooled\", \"size\"), ((False, 100), (False, 3000), (True, 100), (True, 3000))\n    )\n    def test_default_stream_factory(self, no_spooled, size, monkeypatch):\n        if no_spooled:\n            monkeypatch.setattr(\"werkzeug.formparser.SpooledTemporaryFile\", None)\n\n        data = b\"a,b,c\\n\" * size\n        with Request.from_values(\n            data={\"foo\": (io.BytesIO(data), \"test.txt\")}, method=\"POST\"\n        ) as req:\n            reader = csv.reader(io.TextIOWrapper(req.files[\"foo\"]))\n            # This fails if file_storage doesn't implement IOBase.\n            # https://github.com/pallets/werkzeug/issues/1344\n            # https://github.com/python/cpython/pull/3249\n            assert sum(1 for _ in reader) == size\n\n    def test_parse_bad_content_type(self):\n        parser = FormDataParser()\n        assert parser.parse(\"\", \"bad-mime-type\", 0) == (\n            \"\",\n            MultiDict([]),\n            MultiDict([]),\n        )\n\n    def test_parse_from_environ(self):\n        parser = FormDataParser()\n        stream, _, _ = parser.parse_from_environ({\"wsgi.input\": \"\"})\n        assert stream is not None\n\n\n@pytest.mark.filterwarnings(\"ignore::pytest.PytestUnraisableExceptionWarning\")\nclass TestMultiPart:\n    def test_basic(self):\n        resources = join(dirname(__file__), \"multipart\")\n        client = Client(form_data_consumer)\n\n        repository = [\n            (\n                \"firefox3-2png1txt\",\n                \"---------------------------186454651713519341951581030105\",\n                [\n                    (\"anchor.png\", \"file1\", \"image/png\", \"file1.png\"),\n                    (\"application_edit.png\", \"file2\", \"image/png\", \"file2.png\"),\n                ],\n                \"example text\",\n            ),\n            (\n                \"firefox3-2pnglongtext\",\n                \"---------------------------14904044739787191031754711748\",\n                [\n                    (\"accept.png\", \"file1\", \"image/png\", \"file1.png\"),\n                    (\"add.png\", \"file2\", \"image/png\", \"file2.png\"),\n                ],\n                \"--long text\\r\\n--with boundary\\r\\n--lookalikes--\",\n            ),\n            (\n                \"opera8-2png1txt\",\n                \"----------zEO9jQKmLc2Cq88c23Dx19\",\n                [\n                    (\"arrow_branch.png\", \"file1\", \"image/png\", \"file1.png\"),\n                    (\"award_star_bronze_1.png\", \"file2\", \"image/png\", \"file2.png\"),\n                ],\n                \"blafasel \u00f6\u00e4\u00fc\",\n            ),\n            (\n                \"webkit3-2png1txt\",\n                \"----WebKitFormBoundaryjdSFhcARk8fyGNy6\",\n                [\n                    (\"gtk-apply.png\", \"file1\", \"image/png\", \"file1.png\"),\n                    (\"gtk-no.png\", \"file2\", \"image/png\", \"file2.png\"),\n                ],\n                \"this is another text with \u00fcml\u00e4\u00fcts\",\n            ),\n            (\n                \"ie6-2png1txt\",\n                \"---------------------------7d91b03a20128\",\n                [\n                    (\"file1.png\", \"file1\", \"image/x-png\", \"file1.png\"),\n                    (\"file2.png\", \"file2\", \"image/x-png\", \"file2.png\"),\n                ],\n                \"ie6 sucks :-/\",\n            ),\n        ]\n\n        for name, boundary, files, text in repository:\n            folder = join(resources, name)\n            data = get_contents(join(folder, \"request.http\"))\n            for filename, field, content_type, fsname in files:\n                with client.post(\n                    f\"/?object={field}\",\n                    data=data,\n                    content_type=f'multipart/form-data; boundary=\"{boundary}\"',\n                    content_length=len(data),\n                ) as response:\n                    lines = response.get_data().split(b\"\\n\", 3)\n                    assert lines[0] == repr(filename).encode(\"ascii\")\n                    assert lines[1] == repr(field).encode(\"ascii\")\n                    assert lines[2] == repr(content_type).encode(\"ascii\")\n                    assert lines[3] == get_contents(join(folder, fsname))\n\n            with client.post(\n                \"/?object=text\",\n                data=data,\n                content_type=f'multipart/form-data; boundary=\"{boundary}\"',\n                content_length=len(data),\n            ) as response:\n                assert response.get_data() == repr(text).encode()\n\n    @pytest.mark.filterwarnings(\"ignore::pytest.PytestUnraisableExceptionWarning\")\n    def test_ie7_unc_path(self):\n        client = Client(form_data_consumer)\n        data_file = join(dirname(__file__), \"multipart\", \"ie7_full_path_request.http\")\n        data = get_contents(data_file)\n        boundary = \"---------------------------7da36d1b4a0164\"\n        with client.post(\n            \"/?object=cb_file_upload_multiple\",\n            data=data,\n            content_type=f'multipart/form-data; boundary=\"{boundary}\"',\n            content_length=len(data),\n        ) as response:\n            lines = response.get_data().split(b\"\\n\", 3)\n            assert lines[0] == b\"'Sellersburg Town Council Meeting 02-22-2010doc.doc'\"\n\n    def test_end_of_file(self):\n        # This test looks innocent but it was actually timing out in\n        # the Werkzeug 0.5 release version (#394)\n        data = (\n            b\"--foo\\r\\n\"\n            b'Content-Disposition: form-data; name=\"test\"; filename=\"test.txt\"\\r\\n'\n            b\"Content-Type: text/plain\\r\\n\\r\\n\"\n            b\"file contents and no end\"\n        )\n        with Request.from_values(\n            input_stream=io.BytesIO(data),\n            content_length=len(data),\n            content_type=\"multipart/form-data; boundary=foo\",\n            method=\"POST\",\n        ) as data:\n            assert not data.files\n            assert not data.form\n\n    def test_file_no_content_type(self):\n        data = (\n            b\"--foo\\r\\n\"\n            b'Content-Disposition: form-data; name=\"test\"; filename=\"test.txt\"\\r\\n\\r\\n'\n            b\"file contents\\r\\n--foo--\"\n        )\n        with Request.from_values(\n            input_stream=io.BytesIO(data),\n            content_length=len(data),\n            content_type=\"multipart/form-data; boundary=foo\",\n            method=\"POST\",\n        ) as data:\n            assert data.files[\"test\"].filename == \"test.txt\"\n            assert data.files[\"test\"].read() == b\"file contents\"\n\n    def test_extra_newline(self):\n        # this test looks innocent but it was actually timing out in\n        # the Werkzeug 0.5 release version (#394)\n        data = (\n            b\"\\r\\n\\r\\n--foo\\r\\n\"\n            b'Content-Disposition: form-data; name=\"foo\"\\r\\n\\r\\n'\n            b\"a string\\r\\n\"\n            b\"--foo--\"\n        )\n        data = Request.from_values(\n            input_stream=io.BytesIO(data),\n            content_length=len(data),\n            content_type=\"multipart/form-data; boundary=foo\",\n            method=\"POST\",\n        )\n        assert not data.files\n        assert data.form[\"foo\"] == \"a string\"\n\n    def test_headers(self):\n        data = (\n            b\"--foo\\r\\n\"\n            b'Content-Disposition: form-data; name=\"foo\"; filename=\"foo.txt\"\\r\\n'\n            b\"X-Custom-Header: blah\\r\\n\"\n            b\"Content-Type: text/plain; charset=utf-8\\r\\n\\r\\n\"\n            b\"file contents, just the contents\\r\\n\"\n            b\"--foo--\"\n        )\n        with Request.from_values(\n            input_stream=io.BytesIO(data),\n            content_length=len(data),\n            content_type=\"multipart/form-data; boundary=foo\",\n            method=\"POST\",\n        ) as req:\n            foo = req.files[\"foo\"]\n            assert foo.mimetype == \"text/plain\"\n            assert foo.mimetype_params == {\"charset\": \"utf-8\"}\n            assert foo.headers[\"content-type\"] == foo.content_type\n            assert foo.content_type == \"text/plain; charset=utf-8\"\n            assert foo.headers[\"x-custom-header\"] == \"blah\"\n\n    @pytest.mark.parametrize(\"ending\", [b\"\\n\", b\"\\r\", b\"\\r\\n\"])\n    def test_nonstandard_line_endings(self, ending: bytes):\n        data = ending.join(\n            (\n                b\"--foo\",\n                b\"Content-Disposition: form-data; name=foo\",\n                b\"\",\n                b\"this is just bar\",\n                b\"--foo\",\n                b\"Content-Disposition: form-data; name=bar\",\n                b\"\",\n                b\"blafasel\",\n                b\"--foo--\",\n            )\n        )\n        req = Request.from_values(\n            input_stream=io.BytesIO(data),\n            content_length=len(data),\n            content_type=\"multipart/form-data; boundary=foo\",\n            method=\"POST\",\n        )\n        assert req.form[\"foo\"] == \"this is just bar\"\n        assert req.form[\"bar\"] == \"blafasel\"\n\n    def test_failures(self):\n        def parse_multipart(stream, boundary, content_length):\n            parser = formparser.MultiPartParser(content_length)\n            return parser.parse(stream, boundary, content_length)\n\n        data = b\"--foo\\r\\n\\r\\nHello World\\r\\n--foo--\"\n        pytest.raises(ValueError, parse_multipart, io.BytesIO(data), b\"foo\", len(data))\n\n        data = (\n            b\"--foo\\r\\nContent-Disposition: form-field; name=foo\\r\\n\\r\\nHello World\\r\\n\"\n        )\n        pytest.raises(ValueError, parse_multipart, io.BytesIO(data), b\"foo\", len(data))\n\n    def test_empty_multipart(self):\n        environ = {}\n        data = b\"--boundary--\"\n        environ[\"REQUEST_METHOD\"] = \"POST\"\n        environ[\"CONTENT_TYPE\"] = \"multipart/form-data; boundary=boundary\"\n        environ[\"CONTENT_LENGTH\"] = str(len(data))\n        environ[\"wsgi.input\"] = io.BytesIO(data)\n        stream, form, files = parse_form_data(environ, silent=False)\n        rv = stream.read()\n        assert rv == b\"\"\n        assert form == MultiDict()\n        assert files == MultiDict()\n\n\nclass TestMultiPartParser:\n    def test_constructor_not_pass_stream_factory_and_cls(self):\n        parser = formparser.MultiPartParser()\n\n        assert parser.stream_factory is formparser.default_stream_factory\n        assert parser.cls is MultiDict\n\n    def test_constructor_pass_stream_factory_and_cls(self):\n        def stream_factory():\n            pass\n\n        parser = formparser.MultiPartParser(stream_factory=stream_factory, cls=dict)\n\n        assert parser.stream_factory is stream_factory\n        assert parser.cls is dict\n\n    def test_file_rfc2231_filename_continuations(self):\n        data = (\n            b\"--foo\\r\\n\"\n            b\"Content-Type: text/plain; charset=utf-8\\r\\n\"\n            b\"Content-Disposition: form-data; name=rfc2231;\\r\\n\"\n            b\"\tfilename*0*=ascii''a%20b%20;\\r\\n\"\n            b\"\tfilename*1*=c%20d%20;\\r\\n\"\n            b'\tfilename*2=\"e f.txt\"\\r\\n\\r\\n'\n            b\"file contents\\r\\n--foo--\"\n        )\n        with Request.from_values(\n            input_stream=io.BytesIO(data),\n            content_length=len(data),\n            content_type=\"multipart/form-data; boundary=foo\",\n            method=\"POST\",\n        ) as request:\n            assert request.files[\"rfc2231\"].filename == \"a b c d e f.txt\"\n            assert request.files[\"rfc2231\"].read() == b\"file contents\"\n", "tests/test_wrappers.py": "import contextlib\nimport json\nimport os\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom datetime import timezone\nfrom io import BytesIO\n\nimport pytest\n\nfrom werkzeug import Response\nfrom werkzeug import wrappers\nfrom werkzeug.datastructures import Accept\nfrom werkzeug.datastructures import CharsetAccept\nfrom werkzeug.datastructures import CombinedMultiDict\nfrom werkzeug.datastructures import Headers\nfrom werkzeug.datastructures import ImmutableList\nfrom werkzeug.datastructures import ImmutableMultiDict\nfrom werkzeug.datastructures import ImmutableOrderedMultiDict\nfrom werkzeug.datastructures import LanguageAccept\nfrom werkzeug.datastructures import MIMEAccept\nfrom werkzeug.datastructures import MultiDict\nfrom werkzeug.datastructures import WWWAuthenticate\nfrom werkzeug.exceptions import BadRequest\nfrom werkzeug.exceptions import RequestedRangeNotSatisfiable\nfrom werkzeug.exceptions import SecurityError\nfrom werkzeug.exceptions import UnsupportedMediaType\nfrom werkzeug.http import COEP\nfrom werkzeug.http import COOP\nfrom werkzeug.http import generate_etag\nfrom werkzeug.test import Client\nfrom werkzeug.test import create_environ\nfrom werkzeug.test import run_wsgi_app\nfrom werkzeug.wsgi import LimitedStream\nfrom werkzeug.wsgi import wrap_file\n\n\n@wrappers.Request.application\ndef request_demo_app(request):\n    assert \"werkzeug.request\" in request.environ\n    return Response()\n\n\ndef assert_environ(environ, method):\n    assert environ[\"REQUEST_METHOD\"] == method\n    assert environ[\"PATH_INFO\"] == \"/\"\n    assert environ[\"SCRIPT_NAME\"] == \"\"\n    assert environ[\"SERVER_NAME\"] == \"localhost\"\n    assert environ[\"wsgi.version\"] == (1, 0)\n    assert environ[\"wsgi.url_scheme\"] == \"http\"\n\n\ndef test_base_request():\n    client = Client(request_demo_app)\n\n    # get requests\n    response = client.get(\"/?foo=bar&foo=hehe\")\n    request = response.request\n    assert request.args == MultiDict([(\"foo\", \"bar\"), (\"foo\", \"hehe\")])\n    assert request.form == MultiDict()\n    assert request.data == b\"\"\n    assert_environ(request.environ, \"GET\")\n\n    # post requests with form data\n    response = client.post(\n        \"/?blub=blah\",\n        data=\"foo=blub+hehe&blah=42\",\n        content_type=\"application/x-www-form-urlencoded\",\n    )\n    request = response.request\n    assert request.args == MultiDict([(\"blub\", \"blah\")])\n    assert request.form == MultiDict([(\"foo\", \"blub hehe\"), (\"blah\", \"42\")])\n    assert request.data == b\"\"\n    # currently we do not guarantee that the values are ordered correctly\n    # for post data.\n    # assert response['form_as_list'] == [('foo', ['blub hehe']), ('blah', ['42'])]\n    assert_environ(request.environ, \"POST\")\n\n    # patch requests with form data\n    response = client.patch(\n        \"/?blub=blah\",\n        data=\"foo=blub+hehe&blah=42\",\n        content_type=\"application/x-www-form-urlencoded\",\n    )\n    request = response.request\n    assert request.args == MultiDict([(\"blub\", \"blah\")])\n    assert request.form == MultiDict([(\"foo\", \"blub hehe\"), (\"blah\", \"42\")])\n    assert request.data == b\"\"\n    assert_environ(request.environ, \"PATCH\")\n\n    # post requests with json data\n    json = b'{\"foo\": \"bar\", \"blub\": \"blah\"}'\n    response = client.post(\"/?a=b\", data=json, content_type=\"application/json\")\n    request = response.request\n    assert request.data == json\n    assert request.args == MultiDict([(\"a\", \"b\")])\n    assert request.form == MultiDict()\n\n\ndef test_query_string_is_bytes():\n    req = wrappers.Request.from_values(\"/?foo=%2f\")\n    assert req.query_string == b\"foo=%2f\"\n\n\ndef test_request_repr():\n    req = wrappers.Request.from_values(\"/foobar\")\n    assert \"<Request 'http://localhost/foobar' [GET]>\" == repr(req)\n    req = wrappers.Request.from_values(\"/\u043f\u0440\u0438\u0432\u0435\u0442\")\n    assert \"<Request 'http://localhost/\u043f\u0440\u0438\u0432\u0435\u0442' [GET]>\" == repr(req)\n\n\ndef test_access_route():\n    req = wrappers.Request.from_values(\n        headers={\"X-Forwarded-For\": \"192.168.1.2, 192.168.1.1\"},\n        environ_base={\"REMOTE_ADDR\": \"192.168.1.3\"},\n    )\n    assert req.access_route == [\"192.168.1.2\", \"192.168.1.1\"]\n    assert req.remote_addr == \"192.168.1.3\"\n\n    req = wrappers.Request.from_values(environ_base={\"REMOTE_ADDR\": \"192.168.1.3\"})\n    assert list(req.access_route) == [\"192.168.1.3\"]\n\n\ndef test_url_request_descriptors():\n    req = wrappers.Request.from_values(\"/bar?foo=baz\", \"http://example.com/test\")\n    assert req.path == \"/bar\"\n    assert req.full_path == \"/bar?foo=baz\"\n    assert req.script_root == \"/test\"\n    assert req.url == \"http://example.com/test/bar?foo=baz\"\n    assert req.base_url == \"http://example.com/test/bar\"\n    assert req.url_root == \"http://example.com/test/\"\n    assert req.host_url == \"http://example.com/\"\n    assert req.host == \"example.com\"\n    assert req.scheme == \"http\"\n\n    req = wrappers.Request.from_values(\"/bar?foo=baz\", \"https://example.com/test\")\n    assert req.scheme == \"https\"\n\n\ndef test_url_request_descriptors_query_quoting():\n    quoted = \"http%3A%2F%2Fwww.example.com%2F%3Fnext%3D%2Fbaz%23my%3Dhash\"\n    unquoted = \"http://www.example.com/?next%3D/baz%23my%3Dhash\"\n    req = wrappers.Request.from_values(f\"/bar?next={quoted}\", \"http://example.com/\")\n    assert req.path == \"/bar\"\n    assert req.full_path == f\"/bar?next={quoted}\"\n    assert req.url == f\"http://example.com/bar?next={unquoted}\"\n\n\ndef test_url_request_descriptors_hosts():\n    req = wrappers.Request.from_values(\"/bar?foo=baz\", \"http://example.com/test\")\n    req.trusted_hosts = [\"example.com\"]\n    assert req.path == \"/bar\"\n    assert req.full_path == \"/bar?foo=baz\"\n    assert req.script_root == \"/test\"\n    assert req.url == \"http://example.com/test/bar?foo=baz\"\n    assert req.base_url == \"http://example.com/test/bar\"\n    assert req.url_root == \"http://example.com/test/\"\n    assert req.host_url == \"http://example.com/\"\n    assert req.host == \"example.com\"\n    assert req.scheme == \"http\"\n\n    req = wrappers.Request.from_values(\"/bar?foo=baz\", \"https://example.com/test\")\n    assert req.scheme == \"https\"\n\n    req = wrappers.Request.from_values(\"/bar?foo=baz\", \"http://example.com/test\")\n    req.trusted_hosts = [\"example.org\"]\n    pytest.raises(SecurityError, lambda: req.url)\n    pytest.raises(SecurityError, lambda: req.base_url)\n    pytest.raises(SecurityError, lambda: req.url_root)\n    pytest.raises(SecurityError, lambda: req.host_url)\n    pytest.raises(SecurityError, lambda: req.host)\n\n\ndef test_authorization():\n    request = wrappers.Request.from_values(\n        headers={\"Authorization\": \"Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ==\"}\n    )\n    a = request.authorization\n    assert a.type == \"basic\"\n    assert a.username == \"Aladdin\"\n    assert a.password == \"open sesame\"\n\n\ndef test_authorization_with_unicode():\n    request = wrappers.Request.from_values(\n        headers={\"Authorization\": \"Basic 0YDRg9GB0YHQutC40IE60JHRg9C60LLRiw==\"}\n    )\n    a = request.authorization\n    assert a.type == \"basic\"\n    assert a.username == \"\u0440\u0443\u0441\u0441\u043a\u0438\u0401\"\n    assert a.password == \"\u0411\u0443\u043a\u0432\u044b\"\n\n\ndef test_request_application():\n    @wrappers.Request.application\n    def application(request):\n        return wrappers.Response(\"Hello World!\")\n\n    @wrappers.Request.application\n    def failing_application(request):\n        raise BadRequest()\n\n    resp = wrappers.Response.from_app(application, create_environ())\n    assert resp.data == b\"Hello World!\"\n    assert resp.status_code == 200\n\n    resp = wrappers.Response.from_app(failing_application, create_environ())\n    assert b\"Bad Request\" in resp.data\n    assert resp.status_code == 400\n\n\ndef test_request_access_control():\n    request = wrappers.Request.from_values(\n        headers={\n            \"Origin\": \"https://palletsprojects.com\",\n            \"Access-Control-Request-Headers\": \"X-A, X-B\",\n            \"Access-Control-Request-Method\": \"PUT\",\n        }\n    )\n    assert request.origin == \"https://palletsprojects.com\"\n    assert request.access_control_request_headers == {\"X-A\", \"X-B\"}\n    assert request.access_control_request_method == \"PUT\"\n\n\ndef test_response_access_control():\n    response = wrappers.Response(\"Hello World\")\n    assert response.access_control_allow_credentials is False\n    response.access_control_allow_credentials = True\n    response.access_control_allow_headers = [\"X-A\", \"X-B\"]\n    assert response.headers[\"Access-Control-Allow-Credentials\"] == \"true\"\n    assert set(response.headers[\"Access-Control-Allow-Headers\"].split(\", \")) == {\n        \"X-A\",\n        \"X-B\",\n    }\n\n\ndef test_base_response():\n    response = wrappers.Response(\"\u00f6\u00e4\u00fc\")\n    assert response.get_data() == \"\u00f6\u00e4\u00fc\".encode()\n\n    # writing\n    response = wrappers.Response(\"foo\")\n    response.stream.write(\"bar\")\n    assert response.get_data() == b\"foobar\"\n\n    # set cookie\n    response = wrappers.Response()\n    response.set_cookie(\n        \"foo\",\n        value=\"bar\",\n        max_age=60,\n        expires=0,\n        path=\"/blub\",\n        domain=\"example.org\",\n        samesite=\"Strict\",\n    )\n    assert response.headers.to_wsgi_list() == [\n        (\"Content-Type\", \"text/plain; charset=utf-8\"),\n        (\n            \"Set-Cookie\",\n            \"foo=bar; Domain=example.org;\"\n            \" Expires=Thu, 01 Jan 1970 00:00:00 GMT; Max-Age=60;\"\n            \" Path=/blub; SameSite=Strict\",\n        ),\n    ]\n\n    # delete cookie\n    response = wrappers.Response()\n    response.delete_cookie(\"foo\")\n    assert response.headers.to_wsgi_list() == [\n        (\"Content-Type\", \"text/plain; charset=utf-8\"),\n        (\n            \"Set-Cookie\",\n            \"foo=; Expires=Thu, 01 Jan 1970 00:00:00 GMT; Max-Age=0; Path=/\",\n        ),\n    ]\n\n    # close call forwarding\n    closed = []\n\n    class Iterable:\n        def __next__(self):\n            raise StopIteration()\n\n        def __iter__(self):\n            return self\n\n        def close(self):\n            closed.append(True)\n\n    response = wrappers.Response(Iterable())\n    response.call_on_close(lambda: closed.append(True))\n    app_iter, status, headers = run_wsgi_app(response, create_environ(), buffered=True)\n    assert status == \"200 OK\"\n    assert \"\".join(app_iter) == \"\"\n    assert len(closed) == 2\n\n    # with statement\n    del closed[:]\n    response = wrappers.Response(Iterable())\n    with response:\n        pass\n    assert len(closed) == 1\n\n\n@pytest.mark.parametrize(\n    (\"status_code\", \"expected_status\"),\n    [\n        (200, \"200 OK\"),\n        (404, \"404 NOT FOUND\"),\n        (588, \"588 UNKNOWN\"),\n        (999, \"999 UNKNOWN\"),\n    ],\n)\ndef test_response_set_status_code(status_code, expected_status):\n    response = wrappers.Response()\n    response.status_code = status_code\n    assert response.status_code == status_code\n    assert response.status == expected_status\n\n\n@pytest.mark.parametrize(\n    (\"status\", \"expected_status_code\", \"expected_status\"),\n    [\n        (\"404\", 404, \"404 NOT FOUND\"),\n        (\"588\", 588, \"588 UNKNOWN\"),\n        (\"999\", 999, \"999 UNKNOWN\"),\n        (\"200 OK\", 200, \"200 OK\"),\n        (\"999 WTF\", 999, \"999 WTF\"),\n        (\"wtf\", 0, \"0 wtf\"),\n        (\"200 TEA POT\", 200, \"200 TEA POT\"),\n        (200, 200, \"200 OK\"),\n        (400, 400, \"400 BAD REQUEST\"),\n    ],\n)\ndef test_response_set_status(status, expected_status_code, expected_status):\n    response = wrappers.Response()\n    response.status = status\n    assert response.status_code == expected_status_code\n    assert response.status == expected_status\n\n    response = wrappers.Response(status=status)\n    assert response.status_code == expected_status_code\n    assert response.status == expected_status\n\n\ndef test_response_init_status_empty_string():\n    # invalid status codes\n    with pytest.raises(ValueError) as info:\n        wrappers.Response(None, \"\")\n\n    assert \"Empty status argument\" in str(info.value)\n\n\ndef test_type_forcing():\n    def wsgi_application(environ, start_response):\n        start_response(\"200 OK\", [(\"Content-Type\", \"text/html\")])\n        return [\"Hello World!\"]\n\n    base_response = wrappers.Response(\"Hello World!\", content_type=\"text/html\")\n\n    class SpecialResponse(wrappers.Response):\n        def foo(self):\n            return 42\n\n    # good enough for this simple application, but don't ever use that in\n    # real world examples!\n    fake_env = {}\n\n    for orig_resp in wsgi_application, base_response:\n        response = SpecialResponse.force_type(orig_resp, fake_env)\n        assert response.__class__ is SpecialResponse\n        assert response.foo() == 42\n        assert response.get_data() == b\"Hello World!\"\n        assert response.content_type == \"text/html\"\n\n    # without env, no arbitrary conversion\n    pytest.raises(TypeError, SpecialResponse.force_type, wsgi_application)\n\n\ndef test_accept():\n    request = wrappers.Request(\n        {\n            \"HTTP_ACCEPT\": \"text/xml,application/xml,application/xhtml+xml,\"\n            \"text/html;q=0.9,text/plain;q=0.8,image/png,*/*;q=0.5\",\n            \"HTTP_ACCEPT_CHARSET\": \"ISO-8859-1,utf-8;q=0.7,*;q=0.7\",\n            \"HTTP_ACCEPT_ENCODING\": \"gzip,deflate\",\n            \"HTTP_ACCEPT_LANGUAGE\": \"en-us,en;q=0.5\",\n            \"SERVER_NAME\": \"eggs\",\n            \"SERVER_PORT\": \"80\",\n        }\n    )\n    assert request.accept_mimetypes == MIMEAccept(\n        [\n            (\"text/xml\", 1),\n            (\"application/xml\", 1),\n            (\"application/xhtml+xml\", 1),\n            (\"image/png\", 1),\n            (\"text/html\", 0.9),\n            (\"text/plain\", 0.8),\n            (\"*/*\", 0.5),\n        ]\n    )\n    assert request.accept_charsets == CharsetAccept(\n        [(\"ISO-8859-1\", 1), (\"utf-8\", 0.7), (\"*\", 0.7)]\n    )\n    assert request.accept_encodings == Accept([(\"gzip\", 1), (\"deflate\", 1)])\n    assert request.accept_languages == LanguageAccept([(\"en-us\", 1), (\"en\", 0.5)])\n\n    request = wrappers.Request(\n        {\"HTTP_ACCEPT\": \"\", \"SERVER_NAME\": \"example.org\", \"SERVER_PORT\": \"80\"}\n    )\n    assert request.accept_mimetypes == MIMEAccept()\n\n\ndef test_etag_request():\n    request = wrappers.Request(\n        {\n            \"HTTP_CACHE_CONTROL\": \"no-store, no-cache\",\n            \"HTTP_IF_MATCH\": 'W/\"foo\", bar, \"baz\"',\n            \"HTTP_IF_NONE_MATCH\": 'W/\"foo\", bar, \"baz\"',\n            \"HTTP_IF_MODIFIED_SINCE\": \"Tue, 22 Jan 2008 11:18:44 GMT\",\n            \"HTTP_IF_UNMODIFIED_SINCE\": \"Tue, 22 Jan 2008 11:18:44 GMT\",\n            \"SERVER_NAME\": \"eggs\",\n            \"SERVER_PORT\": \"80\",\n        }\n    )\n    assert request.cache_control.no_store\n    assert request.cache_control.no_cache\n\n    for etags in request.if_match, request.if_none_match:\n        assert etags(\"bar\")\n        assert etags.contains_raw('W/\"foo\"')\n        assert etags.contains_weak(\"foo\")\n        assert not etags.contains(\"foo\")\n\n    dt = datetime(2008, 1, 22, 11, 18, 44, tzinfo=timezone.utc)\n    assert request.if_modified_since == dt\n    assert request.if_unmodified_since == dt\n\n\ndef test_user_agent():\n    user_agent = \"Mozilla/5.0 (X11; Linux x86_64; rv:94.0) Gecko/20100101 Firefox/94.0\"\n    request = wrappers.Request({\"HTTP_USER_AGENT\": user_agent})\n    assert request.user_agent.to_header() == user_agent\n    assert str(request.user_agent) == user_agent\n    assert request.user_agent.string == user_agent\n\n\ndef test_stream_wrapping():\n    class LowercasingStream:\n        def __init__(self, stream):\n            self._stream = stream\n\n        def read(self, size=-1):\n            return self._stream.read(size).lower()\n\n        def readline(self, size=-1):\n            return self._stream.readline(size).lower()\n\n    data = b\"foo=Hello+World\"\n    req = wrappers.Request.from_values(\n        \"/\", method=\"POST\", data=data, content_type=\"application/x-www-form-urlencoded\"\n    )\n    req.stream = LowercasingStream(req.stream)\n    assert req.form[\"foo\"] == \"hello world\"\n\n\ndef test_data_descriptor_triggers_parsing():\n    data = b\"foo=Hello+World\"\n    req = wrappers.Request.from_values(\n        \"/\", method=\"POST\", data=data, content_type=\"application/x-www-form-urlencoded\"\n    )\n\n    assert req.data == b\"\"\n    assert req.form[\"foo\"] == \"Hello World\"\n\n\ndef test_get_data_method_parsing_caching_behavior():\n    data = b\"foo=Hello+World\"\n    req = wrappers.Request.from_values(\n        \"/\", method=\"POST\", data=data, content_type=\"application/x-www-form-urlencoded\"\n    )\n\n    # get_data() caches, so form stays available\n    assert req.get_data() == data\n    assert req.form[\"foo\"] == \"Hello World\"\n    assert req.get_data() == data\n\n    # here we access the form data first, caching is bypassed\n    req = wrappers.Request.from_values(\n        \"/\", method=\"POST\", data=data, content_type=\"application/x-www-form-urlencoded\"\n    )\n    assert req.form[\"foo\"] == \"Hello World\"\n    assert req.get_data() == b\"\"\n\n    # Another case is uncached get data which trashes everything\n    req = wrappers.Request.from_values(\n        \"/\", method=\"POST\", data=data, content_type=\"application/x-www-form-urlencoded\"\n    )\n    assert req.get_data(cache=False) == data\n    assert req.get_data(cache=False) == b\"\"\n    assert req.form == {}\n\n    # Or we can implicitly start the form parser which is similar to\n    # the old .data behavior\n    req = wrappers.Request.from_values(\n        \"/\", method=\"POST\", data=data, content_type=\"application/x-www-form-urlencoded\"\n    )\n    assert req.get_data(parse_form_data=True) == b\"\"\n    assert req.form[\"foo\"] == \"Hello World\"\n\n\ndef test_etag_response():\n    response = wrappers.Response(\"Hello World\")\n    assert response.get_etag() == (None, None)\n    response.add_etag()\n    assert response.get_etag() == (\"0a4d55a8d778e5022fab701977c5d840bbc486d0\", False)\n    assert not response.cache_control\n    response.cache_control.must_revalidate = True\n    response.cache_control.max_age = 60\n    response.headers[\"Content-Length\"] = len(response.get_data())\n    assert response.headers[\"Cache-Control\"] in (\n        \"must-revalidate, max-age=60\",\n        \"max-age=60, must-revalidate\",\n    )\n\n    assert \"date\" not in response.headers\n    env = create_environ()\n    env.update({\"REQUEST_METHOD\": \"GET\", \"HTTP_IF_NONE_MATCH\": response.get_etag()[0]})\n    response.make_conditional(env)\n    assert \"date\" in response.headers\n\n    # after the thing is invoked by the server as wsgi application\n    # (we're emulating this here), there must not be any entity\n    # headers left and the status code would have to be 304\n    resp = wrappers.Response.from_app(response, env)\n    assert resp.status_code == 304\n    assert \"content-length\" not in resp.headers\n\n    # make sure date is not overriden\n    response = wrappers.Response(\"Hello World\")\n    response.date = 1337\n    d = response.date\n    response.make_conditional(env)\n    assert response.date == d\n\n    # make sure content length is only set if missing\n    response = wrappers.Response(\"Hello World\")\n    response.content_length = 999\n    response.make_conditional(env)\n    assert response.content_length == 999\n\n\ndef test_etag_response_412():\n    response = wrappers.Response(\"Hello World\")\n    assert response.get_etag() == (None, None)\n    response.add_etag()\n    assert response.get_etag() == (\"0a4d55a8d778e5022fab701977c5d840bbc486d0\", False)\n    assert not response.cache_control\n    response.cache_control.must_revalidate = True\n    response.cache_control.max_age = 60\n    response.headers[\"Content-Length\"] = len(response.get_data())\n    assert response.headers[\"Cache-Control\"] in (\n        \"must-revalidate, max-age=60\",\n        \"max-age=60, must-revalidate\",\n    )\n\n    assert \"date\" not in response.headers\n    env = create_environ()\n    env.update(\n        {\"REQUEST_METHOD\": \"GET\", \"HTTP_IF_MATCH\": f\"{response.get_etag()[0]}xyz\"}\n    )\n    response.make_conditional(env)\n    assert \"date\" in response.headers\n\n    # after the thing is invoked by the server as wsgi application\n    # (we're emulating this here), there must not be any entity\n    # headers left and the status code would have to be 412\n    resp = wrappers.Response.from_app(response, env)\n    assert resp.status_code == 412\n    # Make sure there is a body still\n    assert resp.data != b\"\"\n\n    # make sure date is not overriden\n    response = wrappers.Response(\"Hello World\")\n    response.date = 1337\n    d = response.date\n    response.make_conditional(env)\n    assert response.date == d\n\n    # make sure content length is only set if missing\n    response = wrappers.Response(\"Hello World\")\n    response.content_length = 999\n    response.make_conditional(env)\n    assert response.content_length == 999\n\n\ndef test_range_request_basic():\n    env = create_environ()\n    response = wrappers.Response(\"Hello World\")\n    env[\"HTTP_RANGE\"] = \"bytes=0-4\"\n    response.make_conditional(env, accept_ranges=True, complete_length=11)\n    assert response.status_code == 206\n    assert response.headers[\"Accept-Ranges\"] == \"bytes\"\n    assert response.headers[\"Content-Range\"] == \"bytes 0-4/11\"\n    assert response.headers[\"Content-Length\"] == \"5\"\n    assert response.data == b\"Hello\"\n\n\ndef test_range_request_out_of_bound():\n    env = create_environ()\n    response = wrappers.Response(\"Hello World\")\n    env[\"HTTP_RANGE\"] = \"bytes=6-666\"\n    response.make_conditional(env, accept_ranges=True, complete_length=11)\n    assert response.status_code == 206\n    assert response.headers[\"Accept-Ranges\"] == \"bytes\"\n    assert response.headers[\"Content-Range\"] == \"bytes 6-10/11\"\n    assert response.headers[\"Content-Length\"] == \"5\"\n    assert response.data == b\"World\"\n\n\ndef test_range_request_with_file():\n    env = create_environ()\n    resources = os.path.join(os.path.dirname(__file__), \"res\")\n    fname = os.path.join(resources, \"test.txt\")\n    with open(fname, \"rb\") as f:\n        fcontent = f.read()\n    with open(fname, \"rb\") as f:\n        response = wrappers.Response(wrap_file(env, f))\n        env[\"HTTP_RANGE\"] = \"bytes=0-0\"\n        response.make_conditional(\n            env, accept_ranges=True, complete_length=len(fcontent)\n        )\n        assert response.status_code == 206\n        assert response.headers[\"Accept-Ranges\"] == \"bytes\"\n        assert response.headers[\"Content-Range\"] == f\"bytes 0-0/{len(fcontent)}\"\n        assert response.headers[\"Content-Length\"] == \"1\"\n        assert response.data == fcontent[:1]\n\n\ndef test_range_request_with_complete_file():\n    env = create_environ()\n    resources = os.path.join(os.path.dirname(__file__), \"res\")\n    fname = os.path.join(resources, \"test.txt\")\n    with open(fname, \"rb\") as f:\n        fcontent = f.read()\n    with open(fname, \"rb\") as f:\n        fsize = os.path.getsize(fname)\n        response = wrappers.Response(wrap_file(env, f))\n        env[\"HTTP_RANGE\"] = f\"bytes=0-{fsize - 1}\"\n        response.make_conditional(env, accept_ranges=True, complete_length=fsize)\n        assert response.status_code == 206\n        assert response.headers[\"Accept-Ranges\"] == \"bytes\"\n        assert response.headers[\"Content-Range\"] == f\"bytes 0-{fsize - 1}/{fsize}\"\n        assert response.headers[\"Content-Length\"] == str(fsize)\n        assert response.data == fcontent\n\n\n@pytest.mark.parametrize(\"value\", [None, 0])\ndef test_range_request_without_complete_length(value):\n    env = create_environ(headers={\"Range\": \"bytes=0-10\"})\n    response = wrappers.Response(\"Hello World\")\n    response.make_conditional(env, accept_ranges=True, complete_length=value)\n    assert response.status_code == 200\n    assert response.data == b\"Hello World\"\n\n\ndef test_invalid_range_request():\n    env = create_environ()\n    response = wrappers.Response(\"Hello World\")\n    env[\"HTTP_RANGE\"] = \"bytes=-\"\n    with pytest.raises(RequestedRangeNotSatisfiable):\n        response.make_conditional(env, accept_ranges=True, complete_length=11)\n\n\ndef test_etag_response_freezing():\n    response = Response(\"Hello World\")\n    response.freeze()\n    assert response.get_etag() == (str(generate_etag(b\"Hello World\")), False)\n\n\ndef test_authenticate():\n    resp = wrappers.Response()\n    resp.www_authenticate.realm = \"Testing\"\n    assert resp.headers[\"WWW-Authenticate\"] == \"Basic realm=Testing\"\n    del resp.www_authenticate\n    assert \"WWW-Authenticate\" not in resp.headers\n\n\ndef test_authenticate_quoted_qop():\n    # Example taken from https://github.com/pallets/werkzeug/issues/633\n    resp = wrappers.Response()\n    resp.www_authenticate = WWWAuthenticate(\n        \"digest\", {\"realm\": \"REALM\", \"nonce\": \"NONCE\", \"qop\": \"auth, auth-int\"}\n    )\n\n    actual = resp.headers[\"WWW-Authenticate\"]\n    expected = 'Digest realm=\"REALM\", nonce=\"NONCE\", qop=\"auth, auth-int\"'\n    assert actual == expected\n\n    resp.www_authenticate.parameters[\"qop\"] = \"auth\"\n    actual = resp.headers[\"WWW-Authenticate\"]\n    expected = 'Digest realm=\"REALM\", nonce=\"NONCE\", qop=\"auth\"'\n    assert actual == expected\n\n\ndef test_response_stream():\n    response = wrappers.Response()\n    response.stream.write(\"Hello \")\n    response.stream.write(\"World!\")\n    assert response.response == [\"Hello \", \"World!\"]\n    assert response.get_data() == b\"Hello World!\"\n\n\ndef test_common_response_descriptors():\n    response = wrappers.Response()\n    response.mimetype = \"text/html\"\n    assert response.mimetype == \"text/html\"\n    assert response.content_type == \"text/html; charset=utf-8\"\n    assert response.mimetype_params == {\"charset\": \"utf-8\"}\n    response.mimetype_params[\"x-foo\"] = \"yep\"\n    del response.mimetype_params[\"charset\"]\n    assert response.content_type == \"text/html; x-foo=yep\"\n\n    now = datetime.now(timezone.utc).replace(microsecond=0)\n\n    assert response.content_length is None\n    response.content_length = \"42\"\n    assert response.content_length == 42\n\n    for attr in \"date\", \"expires\":\n        assert getattr(response, attr) is None\n        setattr(response, attr, now)\n        assert getattr(response, attr) == now\n\n    assert response.age is None\n    age_td = timedelta(days=1, minutes=3, seconds=5)\n    response.age = age_td\n    assert response.age == age_td\n    response.age = 42\n    assert response.age == timedelta(seconds=42)\n\n    assert response.retry_after is None\n    response.retry_after = now\n    assert response.retry_after == now\n\n    assert not response.vary\n    response.vary.add(\"Cookie\")\n    response.vary.add(\"Content-Language\")\n    assert \"cookie\" in response.vary\n    assert response.vary.to_header() == \"Cookie, Content-Language\"\n    response.headers[\"Vary\"] = \"Content-Encoding\"\n    assert response.vary.as_set() == {\"content-encoding\"}\n\n    response.allow.update([\"GET\", \"POST\"])\n    assert response.headers[\"Allow\"] == \"GET, POST\"\n\n    response.content_language.add(\"en-US\")\n    response.content_language.add(\"fr\")\n    assert response.headers[\"Content-Language\"] == \"en-US, fr\"\n\n\ndef test_common_request_descriptors():\n    request = wrappers.Request.from_values(\n        content_type=\"text/html; charset=utf-8\",\n        content_length=\"23\",\n        headers={\n            \"Referer\": \"http://www.example.com/\",\n            \"Date\": \"Sat, 28 Feb 2009 19:04:35 GMT\",\n            \"Max-Forwards\": \"10\",\n            \"Pragma\": \"no-cache\",\n            \"Content-Encoding\": \"gzip\",\n            \"Content-MD5\": \"9a3bc6dbc47a70db25b84c6e5867a072\",\n        },\n    )\n\n    assert request.content_type == \"text/html; charset=utf-8\"\n    assert request.mimetype == \"text/html\"\n    assert request.mimetype_params == {\"charset\": \"utf-8\"}\n    assert request.content_length == 23\n    assert request.referrer == \"http://www.example.com/\"\n    assert request.date == datetime(2009, 2, 28, 19, 4, 35, tzinfo=timezone.utc)\n    assert request.max_forwards == 10\n    assert \"no-cache\" in request.pragma\n    assert request.content_encoding == \"gzip\"\n    assert request.content_md5 == \"9a3bc6dbc47a70db25b84c6e5867a072\"\n\n\ndef test_request_mimetype_always_lowercase():\n    request = wrappers.Request.from_values(content_type=\"APPLICATION/JSON\")\n    assert request.mimetype == \"application/json\"\n\n\ndef test_shallow_mode():\n    request = wrappers.Request(\n        {\"QUERY_STRING\": \"foo=bar\", \"SERVER_NAME\": \"eggs\", \"SERVER_PORT\": \"80\"},\n        shallow=True,\n    )\n    assert request.args[\"foo\"] == \"bar\"\n    pytest.raises(RuntimeError, lambda: request.stream)\n    pytest.raises(RuntimeError, lambda: request.data)\n    pytest.raises(RuntimeError, lambda: request.form)\n\n\ndef test_form_parsing_failed():\n    data = b\"--blah\\r\\n\"\n    request = wrappers.Request.from_values(\n        input_stream=BytesIO(data),\n        content_length=len(data),\n        content_type=\"multipart/form-data; boundary=foo\",\n        method=\"POST\",\n    )\n    assert not request.files\n    assert not request.form\n\n    # Bad Content-Type\n    data = b\"test\"\n    request = wrappers.Request.from_values(\n        input_stream=BytesIO(data),\n        content_length=len(data),\n        content_type=\", \",\n        method=\"POST\",\n    )\n    assert not request.form\n\n\ndef test_file_closing():\n    data = (\n        b\"--foo\\r\\n\"\n        b'Content-Disposition: form-data; name=\"foo\"; filename=\"foo.txt\"\\r\\n'\n        b\"Content-Type: text/plain; charset=utf-8\\r\\n\\r\\n\"\n        b\"file contents, just the contents\\r\\n\"\n        b\"--foo--\"\n    )\n    req = wrappers.Request.from_values(\n        input_stream=BytesIO(data),\n        content_length=len(data),\n        content_type=\"multipart/form-data; boundary=foo\",\n        method=\"POST\",\n    )\n    foo = req.files[\"foo\"]\n    assert foo.mimetype == \"text/plain\"\n    assert foo.filename == \"foo.txt\"\n\n    assert foo.closed is False\n    req.close()\n    assert foo.closed is True\n\n\ndef test_file_closing_with():\n    data = (\n        b\"--foo\\r\\n\"\n        b'Content-Disposition: form-data; name=\"foo\"; filename=\"foo.txt\"\\r\\n'\n        b\"Content-Type: text/plain; charset=utf-8\\r\\n\\r\\n\"\n        b\"file contents, just the contents\\r\\n\"\n        b\"--foo--\"\n    )\n    req = wrappers.Request.from_values(\n        input_stream=BytesIO(data),\n        content_length=len(data),\n        content_type=\"multipart/form-data; boundary=foo\",\n        method=\"POST\",\n    )\n    with req:\n        foo = req.files[\"foo\"]\n        assert foo.mimetype == \"text/plain\"\n        assert foo.filename == \"foo.txt\"\n\n    assert foo.closed is True\n\n\ndef test_response_streamed():\n    r = wrappers.Response()\n    assert not r.is_streamed\n    r = wrappers.Response(\"Hello World\")\n    assert not r.is_streamed\n    r = wrappers.Response([\"foo\", \"bar\"])\n    assert not r.is_streamed\n\n    def gen():\n        if 0:\n            yield None\n\n    r = wrappers.Response(gen())\n    assert r.is_streamed\n\n\ndef test_response_iter_wrapping():\n    def uppercasing(iterator):\n        for item in iterator:\n            yield item.upper()\n\n    def generator():\n        yield \"foo\"\n        yield \"bar\"\n\n    req = wrappers.Request.from_values()\n    resp = wrappers.Response(generator())\n    del resp.headers[\"Content-Length\"]\n    resp.response = uppercasing(resp.iter_encoded())\n    actual_resp = wrappers.Response.from_app(resp, req.environ, buffered=True)\n    assert actual_resp.get_data() == b\"FOOBAR\"\n\n\ndef test_response_freeze():\n    def generate():\n        yield \"foo\"\n        yield \"bar\"\n\n    resp = wrappers.Response(generate())\n    resp.freeze()\n    assert resp.response == [b\"foo\", b\"bar\"]\n    assert resp.headers[\"content-length\"] == \"6\"\n\n\ndef test_response_content_length_uses_encode():\n    r = wrappers.Response(\"\u4f60\u597d\")\n    assert r.calculate_content_length() == 6\n\n\ndef test_other_method_payload():\n    data = b\"Hello World\"\n    req = wrappers.Request.from_values(\n        input_stream=BytesIO(data),\n        content_length=len(data),\n        content_type=\"text/plain\",\n        method=\"WHAT_THE_FUCK\",\n    )\n    assert req.get_data() == data\n    assert isinstance(req.stream, LimitedStream)\n\n\ndef test_urlfication():\n    resp = wrappers.Response()\n    resp.headers[\"Location\"] = \"http://\u00fcser:p\u00e4ssword@\u2603.net/p\u00e5th\"\n    resp.headers[\"Content-Location\"] = \"http://\u2603.net/\"\n    headers = resp.get_wsgi_headers(create_environ())\n    assert headers[\"location\"] == \"http://%C3%BCser:p%C3%A4ssword@xn--n3h.net/p%C3%A5th\"\n    assert headers[\"content-location\"] == \"http://xn--n3h.net/\"\n\n\ndef test_new_response_iterator_behavior():\n    req = wrappers.Request.from_values()\n    resp = wrappers.Response(\"Hello W\u00f6rld!\")\n\n    def get_content_length(resp):\n        headers = resp.get_wsgi_headers(req.environ)\n        return headers.get(\"content-length\", type=int)\n\n    def generate_items():\n        yield \"Hello \"\n        yield \"W\u00f6rld!\"\n\n    # werkzeug encodes when set to `data` now, which happens\n    # if a string is passed to the response object.\n    assert resp.response == [\"Hello W\u00f6rld!\".encode()]\n    assert resp.get_data() == \"Hello W\u00f6rld!\".encode()\n    assert get_content_length(resp) == 13\n    assert not resp.is_streamed\n    assert resp.is_sequence\n\n    # try the same for manual assignment\n    resp.set_data(\"W\u00f6rd\")\n    assert resp.response == [\"W\u00f6rd\".encode()]\n    assert resp.get_data() == \"W\u00f6rd\".encode()\n    assert get_content_length(resp) == 5\n    assert not resp.is_streamed\n    assert resp.is_sequence\n\n    # automatic generator sequence conversion\n    resp.response = generate_items()\n    assert resp.is_streamed\n    assert not resp.is_sequence\n    assert resp.get_data() == \"Hello W\u00f6rld!\".encode()\n    assert resp.response == [b\"Hello \", \"W\u00f6rld!\".encode()]\n    assert not resp.is_streamed\n    assert resp.is_sequence\n\n    # automatic generator sequence conversion\n    resp.response = generate_items()\n    resp.implicit_sequence_conversion = False\n    assert resp.is_streamed\n    assert not resp.is_sequence\n    pytest.raises(RuntimeError, lambda: resp.get_data())\n    resp.make_sequence()\n    assert resp.get_data() == \"Hello W\u00f6rld!\".encode()\n    assert resp.response == [b\"Hello \", \"W\u00f6rld!\".encode()]\n    assert not resp.is_streamed\n    assert resp.is_sequence\n\n    # stream makes it a list no matter how the conversion is set\n    for val in True, False:\n        resp.implicit_sequence_conversion = val\n        resp.response = (\"foo\", \"bar\")\n        assert resp.is_sequence\n        resp.stream.write(\"baz\")\n        assert resp.response == [\"foo\", \"bar\", \"baz\"]\n\n\ndef test_form_data_ordering():\n    class MyRequest(wrappers.Request):\n        parameter_storage_class = ImmutableOrderedMultiDict\n\n    req = MyRequest.from_values(\"/?foo=1&bar=0&foo=3\")\n    assert list(req.args) == [\"foo\", \"bar\"]\n    assert list(req.args.items(multi=True)) == [\n        (\"foo\", \"1\"),\n        (\"bar\", \"0\"),\n        (\"foo\", \"3\"),\n    ]\n    assert isinstance(req.args, ImmutableOrderedMultiDict)\n    assert isinstance(req.values, CombinedMultiDict)\n    assert req.values[\"foo\"] == \"1\"\n    assert req.values.getlist(\"foo\") == [\"1\", \"3\"]\n\n\ndef test_values():\n    r = wrappers.Request.from_values(\n        method=\"POST\", query_string={\"a\": \"1\"}, data={\"a\": \"2\", \"b\": \"2\"}\n    )\n    assert r.values[\"a\"] == \"1\"\n    assert r.values[\"b\"] == \"2\"\n\n    # form should not be combined for GET method\n    r = wrappers.Request.from_values(\n        method=\"GET\", query_string={\"a\": \"1\"}, data={\"a\": \"2\", \"b\": \"2\"}\n    )\n    assert r.values[\"a\"] == \"1\"\n    assert \"b\" not in r.values\n\n\ndef test_storage_classes():\n    class MyRequest(wrappers.Request):\n        dict_storage_class = dict\n        list_storage_class = list\n        parameter_storage_class = dict\n\n    req = MyRequest.from_values(\"/?foo=baz\", headers={\"Cookie\": \"foo=bar\"})\n    assert type(req.cookies) is dict  # noqa: E721\n    assert req.cookies == {\"foo\": \"bar\"}\n    assert type(req.access_route) is list  # noqa: E721\n\n    assert type(req.args) is dict  # noqa: E721\n    assert type(req.values) is CombinedMultiDict  # noqa: E721\n    assert req.values[\"foo\"] == \"baz\"\n\n    req = wrappers.Request.from_values(headers={\"Cookie\": \"foo=bar;foo=baz\"})\n    assert type(req.cookies) is ImmutableMultiDict  # noqa: E721\n    assert req.cookies.to_dict() == {\"foo\": \"bar\"}\n\n    # it is possible to have multiple cookies with the same name\n    assert req.cookies.getlist(\"foo\") == [\"bar\", \"baz\"]\n    assert type(req.access_route) is ImmutableList  # noqa: E721\n\n    MyRequest.list_storage_class = tuple\n    req = MyRequest.from_values()\n    assert type(req.access_route) is tuple  # noqa: E721\n\n\ndef test_response_headers_passthrough():\n    headers = Headers()\n    resp = wrappers.Response(headers=headers)\n    assert resp.headers is headers\n\n\ndef test_response_304_no_content_length():\n    resp = wrappers.Response(\"Test\", status=304)\n    env = create_environ()\n    assert \"content-length\" not in resp.get_wsgi_headers(env)\n\n\ndef test_ranges():\n    # basic range stuff\n    req = wrappers.Request.from_values()\n    assert req.range is None\n    req = wrappers.Request.from_values(headers={\"Range\": \"bytes=0-499\"})\n    assert req.range.ranges == [(0, 500)]\n\n    resp = wrappers.Response()\n    resp.content_range = req.range.make_content_range(1000)\n    assert resp.content_range.units == \"bytes\"\n    assert resp.content_range.start == 0\n    assert resp.content_range.stop == 500\n    assert resp.content_range.length == 1000\n    assert resp.headers[\"Content-Range\"] == \"bytes 0-499/1000\"\n\n    resp.content_range.unset()\n    assert \"Content-Range\" not in resp.headers\n\n    resp.headers[\"Content-Range\"] = \"bytes 0-499/1000\"\n    assert resp.content_range.units == \"bytes\"\n    assert resp.content_range.start == 0\n    assert resp.content_range.stop == 500\n    assert resp.content_range.length == 1000\n\n\ndef test_csp():\n    resp = wrappers.Response()\n    resp.content_security_policy.default_src = \"'self'\"\n    assert resp.headers[\"Content-Security-Policy\"] == \"default-src 'self'\"\n    resp.content_security_policy.script_src = \"'self' palletsprojects.com\"\n    assert (\n        resp.headers[\"Content-Security-Policy\"]\n        == \"default-src 'self'; script-src 'self' palletsprojects.com\"\n    )\n\n    resp.content_security_policy = None\n    assert \"Content-Security-Policy\" not in resp.headers\n\n\ndef test_auto_content_length():\n    resp = wrappers.Response(\"Hello World!\")\n    assert resp.content_length == 12\n\n    resp = wrappers.Response([\"Hello World!\"])\n    assert resp.content_length is None\n    assert resp.get_wsgi_headers({})[\"Content-Length\"] == \"12\"\n\n\ndef test_stream_content_length():\n    resp = wrappers.Response()\n    resp.stream.writelines([\"foo\", \"bar\", \"baz\"])\n    assert resp.get_wsgi_headers({})[\"Content-Length\"] == \"9\"\n\n    resp = wrappers.Response()\n    resp.make_conditional({\"REQUEST_METHOD\": \"GET\"})\n    resp.stream.writelines([\"foo\", \"bar\", \"baz\"])\n    assert resp.get_wsgi_headers({})[\"Content-Length\"] == \"9\"\n\n    resp = wrappers.Response(\"foo\")\n    resp.stream.writelines([\"bar\", \"baz\"])\n    assert resp.get_wsgi_headers({})[\"Content-Length\"] == \"9\"\n\n\ndef test_disabled_auto_content_length():\n    class MyResponse(wrappers.Response):\n        automatically_set_content_length = False\n\n    resp = MyResponse(\"Hello World!\")\n    assert resp.content_length is None\n\n    resp = MyResponse([\"Hello World!\"])\n    assert resp.content_length is None\n    assert \"Content-Length\" not in resp.get_wsgi_headers({})\n\n    resp = MyResponse()\n    resp.make_conditional({\"REQUEST_METHOD\": \"GET\"})\n    assert resp.content_length is None\n    assert \"Content-Length\" not in resp.get_wsgi_headers({})\n\n\n@pytest.mark.parametrize(\n    (\"auto\", \"location\", \"expect\"),\n    (\n        (False, \"/test\", \"/test\"),\n        (False, \"/\\\\\\\\test.example?q\", \"/%5C%5Ctest.example?q\"),\n        (True, \"/test\", \"http://localhost/test\"),\n        (True, \"test\", \"http://localhost/a/b/test\"),\n        (True, \"./test\", \"http://localhost/a/b/test\"),\n        (True, \"../test\", \"http://localhost/a/test\"),\n    ),\n)\ndef test_location_header_autocorrect(monkeypatch, auto, location, expect):\n    monkeypatch.setattr(wrappers.Response, \"autocorrect_location_header\", auto)\n    env = create_environ(\"/a/b/c\")\n    resp = wrappers.Response(\"Hello World!\")\n    resp.headers[\"Location\"] = location\n    assert resp.get_wsgi_headers(env)[\"Location\"] == expect\n\n\ndef test_204_and_1XX_response_has_no_content_length():\n    response = wrappers.Response(status=204)\n    assert response.content_length is None\n\n    headers = response.get_wsgi_headers(create_environ())\n    assert \"Content-Length\" not in headers\n\n    response = wrappers.Response(status=100)\n    assert response.content_length is None\n\n    headers = response.get_wsgi_headers(create_environ())\n    assert \"Content-Length\" not in headers\n\n\ndef test_malformed_204_response_has_no_content_length():\n    # flask-restful can generate a malformed response when doing `return '', 204`\n    response = wrappers.Response(status=204)\n    response.set_data(b\"test\")\n    assert response.content_length == 4\n\n    env = create_environ()\n    app_iter, status, headers = response.get_wsgi_response(env)\n    assert status == \"204 NO CONTENT\"\n    assert \"Content-Length\" not in headers\n    assert b\"\".join(app_iter) == b\"\"  # ensure data will not be sent\n\n\ndef test_request_method_case_sensitivity():\n    req = wrappers.Request(\n        {\"REQUEST_METHOD\": \"get\", \"SERVER_NAME\": \"eggs\", \"SERVER_PORT\": \"80\"}\n    )\n    assert req.method == \"GET\"\n\n\ndef test_write_length():\n    response = wrappers.Response()\n    length = response.stream.write(b\"bar\")\n    assert length == 3\n\n\ndef test_stream_zip():\n    import zipfile\n\n    response = wrappers.Response()\n    with contextlib.closing(zipfile.ZipFile(response.stream, mode=\"w\")) as z:\n        z.writestr(\"foo\", b\"bar\")\n\n    buffer = BytesIO(response.get_data())\n    with contextlib.closing(zipfile.ZipFile(buffer, mode=\"r\")) as z:\n        assert z.namelist() == [\"foo\"]\n        assert z.read(\"foo\") == b\"bar\"\n\n\nclass TestSetCookie:\n    def test_secure(self):\n        response = wrappers.Response()\n        response.set_cookie(\n            \"foo\",\n            value=\"bar\",\n            max_age=60,\n            expires=0,\n            path=\"/blub\",\n            domain=\"example.org\",\n            secure=True,\n            samesite=None,\n        )\n        assert response.headers.to_wsgi_list() == [\n            (\"Content-Type\", \"text/plain; charset=utf-8\"),\n            (\n                \"Set-Cookie\",\n                \"foo=bar; Domain=example.org;\"\n                \" Expires=Thu, 01 Jan 1970 00:00:00 GMT; Max-Age=60;\"\n                \" Secure; Path=/blub\",\n            ),\n        ]\n\n    def test_httponly(self):\n        response = wrappers.Response()\n        response.set_cookie(\n            \"foo\",\n            value=\"bar\",\n            max_age=60,\n            expires=0,\n            path=\"/blub\",\n            domain=\"example.org\",\n            secure=False,\n            httponly=True,\n            samesite=None,\n        )\n        assert response.headers.to_wsgi_list() == [\n            (\"Content-Type\", \"text/plain; charset=utf-8\"),\n            (\n                \"Set-Cookie\",\n                \"foo=bar; Domain=example.org;\"\n                \" Expires=Thu, 01 Jan 1970 00:00:00 GMT; Max-Age=60;\"\n                \" HttpOnly; Path=/blub\",\n            ),\n        ]\n\n    def test_secure_and_httponly(self):\n        response = wrappers.Response()\n        response.set_cookie(\n            \"foo\",\n            value=\"bar\",\n            max_age=60,\n            expires=0,\n            path=\"/blub\",\n            domain=\"example.org\",\n            secure=True,\n            httponly=True,\n            samesite=None,\n        )\n        assert response.headers.to_wsgi_list() == [\n            (\"Content-Type\", \"text/plain; charset=utf-8\"),\n            (\n                \"Set-Cookie\",\n                \"foo=bar; Domain=example.org;\"\n                \" Expires=Thu, 01 Jan 1970 00:00:00 GMT; Max-Age=60;\"\n                \" Secure; HttpOnly; Path=/blub\",\n            ),\n        ]\n\n    def test_samesite(self):\n        response = wrappers.Response()\n        response.set_cookie(\n            \"foo\",\n            value=\"bar\",\n            max_age=60,\n            expires=0,\n            path=\"/blub\",\n            domain=\"example.org\",\n            secure=False,\n            samesite=\"strict\",\n        )\n        assert response.headers.to_wsgi_list() == [\n            (\"Content-Type\", \"text/plain; charset=utf-8\"),\n            (\n                \"Set-Cookie\",\n                \"foo=bar; Domain=example.org;\"\n                \" Expires=Thu, 01 Jan 1970 00:00:00 GMT; Max-Age=60;\"\n                \" Path=/blub; SameSite=Strict\",\n            ),\n        ]\n\n\nclass TestJSON:\n    def test_request(self):\n        value = {\"\u00e4\": \"b\"}\n        request = wrappers.Request.from_values(json=value)\n        assert request.json == value\n        assert request.get_data()\n\n    def test_response(self):\n        value = {\"\u00e4\": \"b\"}\n        response = wrappers.Response(\n            response=json.dumps(value), content_type=\"application/json\"\n        )\n        assert response.json == value\n\n    def test_bad_content_type(self):\n        value = [1, 2, 3]\n        request = wrappers.Request.from_values(json=value, content_type=\"text/plain\")\n\n        with pytest.raises(UnsupportedMediaType):\n            request.get_json()\n\n        assert request.get_json(silent=True) is None\n        assert request.get_json(force=True) == value\n\n    def test_bad_data(self):\n        request = wrappers.Request.from_values(\n            data=b'{\"a\":}', content_type=\"application/json\"\n        )\n        assert request.get_json(silent=True) is None\n\n        with pytest.raises(BadRequest):\n            request.get_json()\n\n    def test_cache_disabled(self):\n        value = [1, 2, 3]\n        request = wrappers.Request.from_values(json=value)\n        assert request.get_json(cache=False) == [1, 2, 3]\n        assert not request.get_data()\n\n        with pytest.raises(BadRequest):\n            request.get_json()\n\n\ndef test_response_coop():\n    response = wrappers.Response(\"Hello World\")\n    assert response.cross_origin_opener_policy is COOP.UNSAFE_NONE\n    response.cross_origin_opener_policy = COOP.SAME_ORIGIN\n    assert response.headers[\"Cross-Origin-Opener-Policy\"] == \"same-origin\"\n\n\ndef test_response_coep():\n    response = wrappers.Response(\"Hello World\")\n    assert response.cross_origin_embedder_policy is COEP.UNSAFE_NONE\n    response.cross_origin_embedder_policy = COEP.REQUIRE_CORP\n    assert response.headers[\"Cross-Origin-Embedder-Policy\"] == \"require-corp\"\n", "tests/test_serving.py": "import http.client\nimport json\nimport os\nimport shutil\nimport socket\nimport ssl\nimport sys\nfrom io import BytesIO\nfrom pathlib import Path\nfrom unittest.mock import patch\n\nimport pytest\nfrom watchdog.events import EVENT_TYPE_MODIFIED\nfrom watchdog.events import EVENT_TYPE_OPENED\nfrom watchdog.events import FileModifiedEvent\n\nfrom werkzeug import run_simple\nfrom werkzeug._reloader import _find_stat_paths\nfrom werkzeug._reloader import _find_watchdog_paths\nfrom werkzeug._reloader import _get_args_for_reloading\nfrom werkzeug._reloader import WatchdogReloaderLoop\nfrom werkzeug.datastructures import FileStorage\nfrom werkzeug.serving import make_ssl_devcert\nfrom werkzeug.test import stream_encode_multipart\n\n\n@pytest.mark.filterwarnings(\"ignore::pytest.PytestUnraisableExceptionWarning\")\n@pytest.mark.parametrize(\n    \"kwargs\",\n    [\n        pytest.param({}, id=\"http\"),\n        pytest.param({\"ssl_context\": \"adhoc\"}, id=\"https\"),\n        pytest.param({\"use_reloader\": True}, id=\"reloader\"),\n        pytest.param(\n            {\"hostname\": \"unix\"},\n            id=\"unix socket\",\n            marks=pytest.mark.skipif(\n                not hasattr(socket, \"AF_UNIX\"), reason=\"requires unix socket support\"\n            ),\n        ),\n    ],\n)\n@pytest.mark.dev_server\ndef test_server(tmp_path, dev_server, kwargs: dict):\n    if kwargs.get(\"hostname\") == \"unix\":\n        kwargs[\"hostname\"] = f\"unix://{tmp_path / 'test.sock'}\"\n\n    client = dev_server(**kwargs)\n    r = client.request()\n    assert r.status == 200\n    assert r.json[\"PATH_INFO\"] == \"/\"\n\n\n@pytest.mark.filterwarnings(\"ignore::pytest.PytestUnraisableExceptionWarning\")\n@pytest.mark.dev_server\ndef test_untrusted_host(standard_app):\n    r = standard_app.request(\n        \"http://missing.test:1337/index.html#ignore\",\n        headers={\"x-base-url\": standard_app.url},\n    )\n    assert r.json[\"HTTP_HOST\"] == \"missing.test:1337\"\n    assert r.json[\"PATH_INFO\"] == \"/index.html\"\n    host, _, port = r.json[\"HTTP_X_BASE_URL\"].rpartition(\":\")\n    assert r.json[\"SERVER_NAME\"] == host.partition(\"http://\")[2]\n    assert r.json[\"SERVER_PORT\"] == port\n\n\n@pytest.mark.filterwarnings(\"ignore::pytest.PytestUnraisableExceptionWarning\")\n@pytest.mark.dev_server\ndef test_double_slash_path(standard_app):\n    r = standard_app.request(\"//double-slash\")\n    assert \"double-slash\" not in r.json[\"HTTP_HOST\"]\n    assert r.json[\"PATH_INFO\"] == \"/double-slash\"\n\n\n@pytest.mark.filterwarnings(\"ignore::pytest.PytestUnraisableExceptionWarning\")\n@pytest.mark.dev_server\ndef test_500_error(standard_app):\n    r = standard_app.request(\"/crash\")\n    assert r.status == 500\n    assert b\"Internal Server Error\" in r.data\n\n\n@pytest.mark.filterwarnings(\"ignore::pytest.PytestUnraisableExceptionWarning\")\n@pytest.mark.dev_server\ndef test_ssl_dev_cert(tmp_path, dev_server):\n    client = dev_server(ssl_context=make_ssl_devcert(tmp_path))\n    r = client.request()\n    assert r.json[\"wsgi.url_scheme\"] == \"https\"\n\n\n@pytest.mark.filterwarnings(\"ignore::pytest.PytestUnraisableExceptionWarning\")\n@pytest.mark.dev_server\ndef test_ssl_object(dev_server):\n    client = dev_server(ssl_context=\"custom\")\n    r = client.request()\n    assert r.json[\"wsgi.url_scheme\"] == \"https\"\n\n\n@pytest.mark.filterwarnings(\"ignore::pytest.PytestUnraisableExceptionWarning\")\n@pytest.mark.parametrize(\"reloader_type\", [\"stat\", \"watchdog\"])\n@pytest.mark.skipif(\n    os.name == \"nt\" and \"CI\" in os.environ, reason=\"unreliable on Windows during CI\"\n)\n@pytest.mark.dev_server\ndef test_reloader_sys_path(tmp_path, dev_server, reloader_type):\n    \"\"\"This tests the general behavior of the reloader. It also tests\n    that fixing an import error triggers a reload, not just Python\n    retrying the failed import.\n    \"\"\"\n    real_path = tmp_path / \"real_app.py\"\n    real_path.write_text(\"syntax error causes import error\")\n\n    client = dev_server(\"reloader\", reloader_type=reloader_type)\n    assert client.request().status == 500\n\n    shutil.copyfile(Path(__file__).parent / \"live_apps\" / \"standard_app.py\", real_path)\n    client.wait_for_log(f\" * Detected change in {str(real_path)!r}, reloading\")\n    client.wait_for_reload()\n    assert client.request().status == 200\n\n\n@patch.object(WatchdogReloaderLoop, \"trigger_reload\")\ndef test_watchdog_reloader_ignores_opened(mock_trigger_reload):\n    reloader = WatchdogReloaderLoop()\n    modified_event = FileModifiedEvent(\"\")\n    modified_event.event_type = EVENT_TYPE_MODIFIED\n    reloader.event_handler.on_any_event(modified_event)\n    mock_trigger_reload.assert_called_once()\n\n    reloader.trigger_reload.reset_mock()\n\n    opened_event = FileModifiedEvent(\"\")\n    opened_event.event_type = EVENT_TYPE_OPENED\n    reloader.event_handler.on_any_event(opened_event)\n    reloader.trigger_reload.assert_not_called()\n\n\n@pytest.mark.skipif(sys.version_info >= (3, 10), reason=\"not needed on >= 3.10\")\ndef test_windows_get_args_for_reloading(monkeypatch, tmp_path):\n    argv = [str(tmp_path / \"test.exe\"), \"run\"]\n    monkeypatch.setattr(\"sys.executable\", str(tmp_path / \"python.exe\"))\n    monkeypatch.setattr(\"sys.argv\", argv)\n    monkeypatch.setattr(\"__main__.__package__\", None)\n    monkeypatch.setattr(\"os.name\", \"nt\")\n    rv = _get_args_for_reloading()\n    assert rv == argv\n\n\n@pytest.mark.filterwarnings(\"ignore::pytest.PytestUnraisableExceptionWarning\")\n@pytest.mark.parametrize(\"find\", [_find_stat_paths, _find_watchdog_paths])\ndef test_exclude_patterns(find):\n    # Select a path to exclude from the unfiltered list, assert that it is present and\n    # then gets excluded.\n    paths = find(set(), set())\n    path_to_exclude = next(iter(paths))\n    assert any(p.startswith(path_to_exclude) for p in paths)\n\n    # Those paths should be excluded due to the pattern.\n    paths = find(set(), {f\"{path_to_exclude}*\"})\n    assert not any(p.startswith(path_to_exclude) for p in paths)\n\n\n@pytest.mark.filterwarnings(\"ignore::pytest.PytestUnraisableExceptionWarning\")\n@pytest.mark.dev_server\ndef test_wrong_protocol(standard_app):\n    \"\"\"An HTTPS request to an HTTP server doesn't show a traceback.\n    https://github.com/pallets/werkzeug/pull/838\n    \"\"\"\n    conn = http.client.HTTPSConnection(standard_app.addr)\n\n    with pytest.raises(ssl.SSLError):\n        conn.request(\"GET\", f\"https://{standard_app.addr}\")\n\n    assert \"Traceback\" not in standard_app.log.read()\n\n\n@pytest.mark.filterwarnings(\"ignore::pytest.PytestUnraisableExceptionWarning\")\n@pytest.mark.dev_server\ndef test_content_type_and_length(standard_app):\n    r = standard_app.request()\n    assert \"CONTENT_TYPE\" not in r.json\n    assert \"CONTENT_LENGTH\" not in r.json\n\n    r = standard_app.request(body=b\"{}\", headers={\"content-type\": \"application/json\"})\n    assert r.json[\"CONTENT_TYPE\"] == \"application/json\"\n    assert r.json[\"CONTENT_LENGTH\"] == \"2\"\n\n\ndef test_port_is_int():\n    with pytest.raises(TypeError, match=\"port must be an integer\"):\n        run_simple(\"127.0.0.1\", \"5000\", None)\n\n\n@pytest.mark.filterwarnings(\"ignore::pytest.PytestUnraisableExceptionWarning\")\n@pytest.mark.parametrize(\"send_length\", [False, True])\n@pytest.mark.dev_server\ndef test_chunked_request(monkeypatch, dev_server, send_length):\n    stream, length, boundary = stream_encode_multipart(\n        {\n            \"value\": \"this is text\",\n            \"file\": FileStorage(\n                BytesIO(b\"this is a file\"),\n                filename=\"test.txt\",\n                content_type=\"text/plain\",\n            ),\n        }\n    )\n    client = dev_server(\"data\")\n    # Small block size to produce multiple chunks.\n    conn = client.connect(blocksize=128)\n    conn.putrequest(\"POST\", \"/\")\n    conn.putheader(\"Transfer-Encoding\", \"chunked\")\n    conn.putheader(\"Content-Type\", f\"multipart/form-data; boundary={boundary}\")\n\n    # Sending the content-length header with chunked is invalid, but if\n    # a client does send it the server should ignore it. Previously the\n    # multipart parser would crash. Python's higher-level functions\n    # won't send the header, which is why we use conn.put in this test.\n    if send_length:\n        conn.putheader(\"Content-Length\", \"invalid\")\n        expect_content_len = \"invalid\"\n    else:\n        expect_content_len = None\n\n    conn.endheaders(stream, encode_chunked=True)\n    r = conn.getresponse()\n    data = json.load(r)\n    r.close()\n    assert data[\"form\"][\"value\"] == \"this is text\"\n    assert data[\"files\"][\"file\"] == \"this is a file\"\n    environ = data[\"environ\"]\n    assert environ[\"HTTP_TRANSFER_ENCODING\"] == \"chunked\"\n    assert environ.get(\"CONTENT_LENGTH\") == expect_content_len\n    assert environ[\"wsgi.input_terminated\"]\n\n\n@pytest.mark.filterwarnings(\"ignore::pytest.PytestUnraisableExceptionWarning\")\n@pytest.mark.dev_server\ndef test_multiple_headers_concatenated(standard_app):\n    \"\"\"A header key can be sent multiple times. The server will join all\n    the values with commas.\n\n    https://tools.ietf.org/html/rfc3875#section-4.1.18\n    \"\"\"\n    # conn.request doesn't support multiple values.\n    conn = standard_app.connect()\n    conn.putrequest(\"GET\", \"/\")\n    conn.putheader(\"XYZ\", \"a \")  # trailing space is preserved\n    conn.putheader(\"X-Ignore-1\", \"ignore value\")\n    conn.putheader(\"XYZ\", \" b\")  # leading space is collapsed\n    conn.putheader(\"X-Ignore-2\", \"ignore value\")\n    conn.putheader(\"XYZ\", \"c \")\n    conn.putheader(\"X-Ignore-3\", \"ignore value\")\n    conn.putheader(\"XYZ\", \"d\")\n    conn.endheaders()\n    r = conn.getresponse()\n    data = json.load(r)\n    r.close()\n    assert data[\"HTTP_XYZ\"] == \"a ,b,c ,d\"\n\n\n@pytest.mark.filterwarnings(\"ignore::pytest.PytestUnraisableExceptionWarning\")\n@pytest.mark.dev_server\ndef test_multiline_header_folding(standard_app):\n    \"\"\"A header value can be split over multiple lines with a leading\n    tab. The server will remove the newlines and preserve the tabs.\n\n    https://tools.ietf.org/html/rfc2616#section-2.2\n    \"\"\"\n    # conn.request doesn't support multiline values.\n    conn = standard_app.connect()\n    conn.putrequest(\"GET\", \"/\")\n    conn.putheader(\"XYZ\", \"first\", \"second\", \"third\")\n    conn.endheaders()\n    r = conn.getresponse()\n    data = json.load(r)\n    r.close()\n    assert data[\"HTTP_XYZ\"] == \"first\\tsecond\\tthird\"\n\n\n@pytest.mark.parametrize(\"endpoint\", [\"\", \"crash\"])\n@pytest.mark.filterwarnings(\"ignore::pytest.PytestUnraisableExceptionWarning\")\n@pytest.mark.dev_server\ndef test_streaming_close_response(dev_server, endpoint):\n    \"\"\"When using HTTP/1.0, chunked encoding is not supported. Fall\n    back to Connection: close, but this allows no reliable way to\n    distinguish between complete and truncated responses.\n    \"\"\"\n    r = dev_server(\"streaming\").request(\"/\" + endpoint)\n    assert r.getheader(\"connection\") == \"close\"\n    assert r.data == \"\".join(str(x) + \"\\n\" for x in range(5)).encode()\n\n\n@pytest.mark.filterwarnings(\"ignore::pytest.PytestUnraisableExceptionWarning\")\n@pytest.mark.dev_server\ndef test_streaming_chunked_response(dev_server):\n    \"\"\"When using HTTP/1.1, use Transfer-Encoding: chunked for streamed\n    responses, since it can distinguish the end of the response without\n    closing the connection.\n\n    https://tools.ietf.org/html/rfc2616#section-3.6.1\n    \"\"\"\n    r = dev_server(\"streaming\", threaded=True).request(\"/\")\n    assert r.getheader(\"transfer-encoding\") == \"chunked\"\n    assert r.data == \"\".join(str(x) + \"\\n\" for x in range(5)).encode()\n\n\n@pytest.mark.filterwarnings(\"ignore::pytest.PytestUnraisableExceptionWarning\")\n@pytest.mark.dev_server\ndef test_streaming_chunked_truncation(dev_server):\n    \"\"\"When using HTTP/1.1, chunked encoding allows the client to detect\n    content truncated by a prematurely closed connection.\n    \"\"\"\n    with pytest.raises(http.client.IncompleteRead):\n        dev_server(\"streaming\", threaded=True).request(\"/crash\")\n", "tests/test_debug.py": "import re\nimport sys\n\nimport pytest\n\nfrom werkzeug.debug import console\nfrom werkzeug.debug import DebuggedApplication\nfrom werkzeug.debug import DebugTraceback\nfrom werkzeug.debug import get_machine_id\nfrom werkzeug.debug.console import HTMLStringO\nfrom werkzeug.debug.repr import debug_repr\nfrom werkzeug.debug.repr import DebugReprGenerator\nfrom werkzeug.debug.repr import dump\nfrom werkzeug.debug.repr import helper\nfrom werkzeug.test import Client\nfrom werkzeug.wrappers import Request\n\n\nclass TestDebugRepr:\n    def test_basic_repr(self):\n        assert debug_repr([]) == \"[]\"\n        assert debug_repr([1, 2]) == (\n            '[<span class=\"number\">1</span>, <span class=\"number\">2</span>]'\n        )\n        assert debug_repr([1, \"test\"]) == (\n            '[<span class=\"number\">1</span>,'\n            ' <span class=\"string\">&#39;test&#39;</span>]'\n        )\n        assert debug_repr([None]) == '[<span class=\"object\">None</span>]'\n\n    def test_string_repr(self):\n        assert debug_repr(\"\") == '<span class=\"string\">&#39;&#39;</span>'\n        assert debug_repr(\"foo\") == '<span class=\"string\">&#39;foo&#39;</span>'\n        assert debug_repr(\"s\" * 80) == (\n            f'<span class=\"string\">&#39;{\"s\" * 69}'\n            f'<span class=\"extended\">{\"s\" * 11}&#39;</span></span>'\n        )\n        assert debug_repr(\"<\" * 80) == (\n            f'<span class=\"string\">&#39;{\"&lt;\" * 69}'\n            f'<span class=\"extended\">{\"&lt;\" * 11}&#39;</span></span>'\n        )\n\n    def test_string_subclass_repr(self):\n        class Test(str):\n            pass\n\n        assert debug_repr(Test(\"foo\")) == (\n            '<span class=\"module\">test_debug.</span>'\n            'Test(<span class=\"string\">&#39;foo&#39;</span>)'\n        )\n\n    def test_sequence_repr(self):\n        assert debug_repr(list(range(20))) == (\n            '[<span class=\"number\">0</span>, <span class=\"number\">1</span>, '\n            '<span class=\"number\">2</span>, <span class=\"number\">3</span>, '\n            '<span class=\"number\">4</span>, <span class=\"number\">5</span>, '\n            '<span class=\"number\">6</span>, <span class=\"number\">7</span>, '\n            '<span class=\"extended\"><span class=\"number\">8</span>, '\n            '<span class=\"number\">9</span>, <span class=\"number\">10</span>, '\n            '<span class=\"number\">11</span>, <span class=\"number\">12</span>, '\n            '<span class=\"number\">13</span>, <span class=\"number\">14</span>, '\n            '<span class=\"number\">15</span>, <span class=\"number\">16</span>, '\n            '<span class=\"number\">17</span>, <span class=\"number\">18</span>, '\n            '<span class=\"number\">19</span></span>]'\n        )\n\n    def test_mapping_repr(self):\n        assert debug_repr({}) == \"{}\"\n        assert debug_repr({\"foo\": 42}) == (\n            '{<span class=\"pair\"><span class=\"key\"><span class=\"string\">&#39;foo&#39;'\n            '</span></span>: <span class=\"value\"><span class=\"number\">42'\n            \"</span></span></span>}\"\n        )\n        assert debug_repr(dict(zip(range(10), [None] * 10))) == (\n            '{<span class=\"pair\"><span class=\"key\"><span class=\"number\">0'\n            '</span></span>: <span class=\"value\"><span class=\"object\">None'\n            \"</span></span></span>, \"\n            '<span class=\"pair\"><span class=\"key\"><span class=\"number\">1'\n            '</span></span>: <span class=\"value\"><span class=\"object\">None'\n            \"</span></span></span>, \"\n            '<span class=\"pair\"><span class=\"key\"><span class=\"number\">2'\n            '</span></span>: <span class=\"value\"><span class=\"object\">None'\n            \"</span></span></span>, \"\n            '<span class=\"pair\"><span class=\"key\"><span class=\"number\">3'\n            '</span></span>: <span class=\"value\"><span class=\"object\">None'\n            \"</span></span></span>, \"\n            '<span class=\"extended\">'\n            '<span class=\"pair\"><span class=\"key\"><span class=\"number\">4'\n            '</span></span>: <span class=\"value\"><span class=\"object\">None'\n            \"</span></span></span>, \"\n            '<span class=\"pair\"><span class=\"key\"><span class=\"number\">5'\n            '</span></span>: <span class=\"value\"><span class=\"object\">None'\n            \"</span></span></span>, \"\n            '<span class=\"pair\"><span class=\"key\"><span class=\"number\">6'\n            '</span></span>: <span class=\"value\"><span class=\"object\">None'\n            \"</span></span></span>, \"\n            '<span class=\"pair\"><span class=\"key\"><span class=\"number\">7'\n            '</span></span>: <span class=\"value\"><span class=\"object\">None'\n            \"</span></span></span>, \"\n            '<span class=\"pair\"><span class=\"key\"><span class=\"number\">8'\n            '</span></span>: <span class=\"value\"><span class=\"object\">None'\n            \"</span></span></span>, \"\n            '<span class=\"pair\"><span class=\"key\"><span class=\"number\">9'\n            '</span></span>: <span class=\"value\"><span class=\"object\">None'\n            \"</span></span></span></span>}\"\n        )\n        assert debug_repr((1, \"zwei\", \"drei\")) == (\n            '(<span class=\"number\">1</span>, <span class=\"string\">&#39;'\n            'zwei&#39;</span>, <span class=\"string\">&#39;drei&#39;</span>)'\n        )\n\n    def test_custom_repr(self):\n        class Foo:\n            def __repr__(self):\n                return \"<Foo 42>\"\n\n        assert debug_repr(Foo()) == '<span class=\"object\">&lt;Foo 42&gt;</span>'\n\n    def test_list_subclass_repr(self):\n        class MyList(list):\n            pass\n\n        assert debug_repr(MyList([1, 2])) == (\n            '<span class=\"module\">test_debug.</span>MyList(['\n            '<span class=\"number\">1</span>, <span class=\"number\">2</span>])'\n        )\n\n    def test_regex_repr(self):\n        assert (\n            debug_repr(re.compile(r\"foo\\d\"))\n            == \"re.compile(<span class=\\\"string regex\\\">r'foo\\\\d'</span>)\"\n        )\n        # No ur'' in Py3\n        # https://bugs.python.org/issue15096\n        assert debug_repr(re.compile(\"foo\\\\d\")) == (\n            \"re.compile(<span class=\\\"string regex\\\">r'foo\\\\d'</span>)\"\n        )\n\n    def test_set_repr(self):\n        assert (\n            debug_repr(frozenset(\"x\"))\n            == 'frozenset([<span class=\"string\">&#39;x&#39;</span>])'\n        )\n        assert debug_repr(set(\"x\")) == (\n            'set([<span class=\"string\">&#39;x&#39;</span>])'\n        )\n\n    def test_recursive_repr(self):\n        a = [1]\n        a.append(a)\n        assert debug_repr(a) == '[<span class=\"number\">1</span>, [...]]'\n\n    def test_broken_repr(self):\n        class Foo:\n            def __repr__(self):\n                raise Exception(\"broken!\")\n\n        assert debug_repr(Foo()) == (\n            '<span class=\"brokenrepr\">&lt;broken repr (Exception: '\n            \"broken!)&gt;</span>\"\n        )\n\n\nclass Foo:\n    x = 42\n    y = 23\n\n    def __init__(self):\n        self.z = 15\n\n\nclass TestDebugHelpers:\n    def test_object_dumping(self):\n        drg = DebugReprGenerator()\n        out = drg.dump_object(Foo())\n        assert re.search(\"Details for test_debug.Foo object at\", out)\n        assert re.search('<th>x.*<span class=\"number\">42</span>', out, flags=re.DOTALL)\n        assert re.search('<th>y.*<span class=\"number\">23</span>', out, flags=re.DOTALL)\n        assert re.search('<th>z.*<span class=\"number\">15</span>', out, flags=re.DOTALL)\n\n        out = drg.dump_object({\"x\": 42, \"y\": 23})\n        assert re.search(\"Contents of\", out)\n        assert re.search('<th>x.*<span class=\"number\">42</span>', out, flags=re.DOTALL)\n        assert re.search('<th>y.*<span class=\"number\">23</span>', out, flags=re.DOTALL)\n\n        out = drg.dump_object({\"x\": 42, \"y\": 23, 23: 11})\n        assert not re.search(\"Contents of\", out)\n\n        out = drg.dump_locals({\"x\": 42, \"y\": 23})\n        assert re.search(\"Local variables in frame\", out)\n        assert re.search('<th>x.*<span class=\"number\">42</span>', out, flags=re.DOTALL)\n        assert re.search('<th>y.*<span class=\"number\">23</span>', out, flags=re.DOTALL)\n\n    def test_debug_dump(self):\n        old = sys.stdout\n        sys.stdout = HTMLStringO()\n        try:\n            dump([1, 2, 3])\n            x = sys.stdout.reset()\n            dump()\n            y = sys.stdout.reset()\n        finally:\n            sys.stdout = old\n\n        assert \"Details for list object at\" in x\n        assert '<span class=\"number\">1</span>' in x\n        assert \"Local variables in frame\" in y\n        assert \"<th>x\" in y\n        assert \"<th>old\" in y\n\n    def test_debug_help(self):\n        old = sys.stdout\n        sys.stdout = HTMLStringO()\n        try:\n            helper([1, 2, 3])\n            x = sys.stdout.reset()\n        finally:\n            sys.stdout = old\n\n        assert \"Help on list object\" in x\n        assert \"__delitem__\" in x\n\n    def test_exc_divider_found_on_chained_exception(self):\n        @Request.application\n        def app(request):\n            def do_something():\n                raise ValueError(\"inner\")\n\n            try:\n                do_something()\n            except ValueError:\n                raise KeyError(\"outer\")  # noqa: B904\n\n        debugged = DebuggedApplication(app)\n        client = Client(debugged)\n        response = client.get(\"/\")\n        data = response.get_data(as_text=True)\n        assert 'raise ValueError(\"inner\")' in data\n        assert '<div class=\"exc-divider\">' in data\n        assert 'raise KeyError(\"outer\")' in data\n\n\ndef test_get_machine_id():\n    rv = get_machine_id()\n    assert isinstance(rv, bytes)\n\n\n@pytest.mark.filterwarnings(\"ignore::pytest.PytestUnraisableExceptionWarning\")\n@pytest.mark.parametrize(\"crash\", (True, False))\n@pytest.mark.dev_server\ndef test_basic(dev_server, crash):\n    c = dev_server(use_debugger=True)\n    r = c.request(\"/crash\" if crash else \"\")\n    assert r.status == (500 if crash else 200)\n\n    if crash:\n        assert b\"The debugger caught an exception in your WSGI application\" in r.data\n    else:\n        assert r.json[\"PATH_INFO\"] == \"/\"\n\n\ndef test_console_closure_variables(monkeypatch):\n    # restore the original display hook\n    monkeypatch.setattr(sys, \"displayhook\", console._displayhook)\n    c = console.Console()\n    c.eval(\"y = 5\")\n    c.eval(\"x = lambda: y\")\n    ret = c.eval(\"x()\")\n    assert ret == \">>> x()\\n5\\n\"\n\n\n@pytest.mark.timeout(2)\ndef test_chained_exception_cycle():\n    try:\n        try:\n            raise ValueError()\n        except ValueError:\n            raise TypeError()  # noqa: B904\n    except TypeError as e:\n        # create a cycle and make it available outside the except block\n        e.__context__.__context__ = error = e\n\n    # if cycles aren't broken, this will time out\n    tb = DebugTraceback(error)\n    assert len(tb.all_tracebacks) == 2\n\n\ndef test_exception_without_traceback():\n    try:\n        raise Exception(\"msg1\")\n    except Exception as e:\n        # filter_hidden_frames should skip this since it has no traceback\n        e.__context__ = Exception(\"msg2\")\n        DebugTraceback(e)\n", "tests/test_internal.py": "from werkzeug.test import create_environ\nfrom werkzeug.wrappers import Request\nfrom werkzeug.wrappers import Response\n\n\ndef test_wrapper_internals():\n    req = Request.from_values(data={\"foo\": \"bar\"}, method=\"POST\")\n    req._load_form_data()\n    assert req.form.to_dict() == {\"foo\": \"bar\"}\n\n    # second call does not break\n    req._load_form_data()\n    assert req.form.to_dict() == {\"foo\": \"bar\"}\n\n    # check reprs\n    assert repr(req) == \"<Request 'http://localhost/' [POST]>\"\n    resp = Response()\n    assert repr(resp) == \"<Response 0 bytes [200 OK]>\"\n    resp.set_data(\"Hello World!\")\n    assert repr(resp) == \"<Response 12 bytes [200 OK]>\"\n    resp.response = iter([\"Test\"])\n    assert repr(resp) == \"<Response streamed [200 OK]>\"\n\n    response = Response([\"H\u00e4llo W\u00f6rld\"])\n    headers = response.get_wsgi_headers(create_environ())\n    assert \"Content-Length\" in headers\n\n    response = Response([\"H\u00e4llo W\u00f6rld\".encode()])\n    headers = response.get_wsgi_headers(create_environ())\n    assert \"Content-Length\" in headers\n", "tests/test_wsgi.py": "from __future__ import annotations\n\nimport io\nimport json\nimport os\nimport typing as t\n\nimport pytest\n\nfrom werkzeug import wsgi\nfrom werkzeug.exceptions import BadRequest\nfrom werkzeug.exceptions import ClientDisconnected\nfrom werkzeug.test import Client\nfrom werkzeug.test import create_environ\nfrom werkzeug.test import run_wsgi_app\nfrom werkzeug.wrappers import Response\nfrom werkzeug.wsgi import _RangeWrapper\nfrom werkzeug.wsgi import ClosingIterator\nfrom werkzeug.wsgi import wrap_file\n\n\n@pytest.mark.parametrize(\n    (\"environ\", \"expect\"),\n    (\n        pytest.param({\"HTTP_HOST\": \"spam\"}, \"spam\", id=\"host\"),\n        pytest.param({\"HTTP_HOST\": \"spam:80\"}, \"spam\", id=\"host, strip http port\"),\n        pytest.param(\n            {\"wsgi.url_scheme\": \"https\", \"HTTP_HOST\": \"spam:443\"},\n            \"spam\",\n            id=\"host, strip https port\",\n        ),\n        pytest.param({\"HTTP_HOST\": \"spam:8080\"}, \"spam:8080\", id=\"host, custom port\"),\n        pytest.param(\n            {\"HTTP_HOST\": \"spam\", \"SERVER_NAME\": \"eggs\", \"SERVER_PORT\": \"80\"},\n            \"spam\",\n            id=\"prefer host\",\n        ),\n        pytest.param(\n            {\"SERVER_NAME\": \"eggs\", \"SERVER_PORT\": \"80\"},\n            \"eggs\",\n            id=\"name, ignore http port\",\n        ),\n        pytest.param(\n            {\"wsgi.url_scheme\": \"https\", \"SERVER_NAME\": \"eggs\", \"SERVER_PORT\": \"443\"},\n            \"eggs\",\n            id=\"name, ignore https port\",\n        ),\n        pytest.param(\n            {\"SERVER_NAME\": \"eggs\", \"SERVER_PORT\": \"8080\"},\n            \"eggs:8080\",\n            id=\"name, custom port\",\n        ),\n        pytest.param(\n            {\"HTTP_HOST\": \"ham\", \"HTTP_X_FORWARDED_HOST\": \"eggs\"},\n            \"ham\",\n            id=\"ignore x-forwarded-host\",\n        ),\n    ),\n)\ndef test_get_host(environ, expect):\n    environ.setdefault(\"wsgi.url_scheme\", \"http\")\n    assert wsgi.get_host(environ) == expect\n\n\ndef test_get_host_validate_trusted_hosts():\n    env = {\"SERVER_NAME\": \"example.org\", \"SERVER_PORT\": \"80\", \"wsgi.url_scheme\": \"http\"}\n    assert wsgi.get_host(env, trusted_hosts=[\".example.org\"]) == \"example.org\"\n    pytest.raises(BadRequest, wsgi.get_host, env, trusted_hosts=[\"example.com\"])\n    env[\"SERVER_PORT\"] = \"8080\"\n    assert wsgi.get_host(env, trusted_hosts=[\".example.org:8080\"]) == \"example.org:8080\"\n    pytest.raises(BadRequest, wsgi.get_host, env, trusted_hosts=[\".example.com\"])\n    env = {\"HTTP_HOST\": \"example.org\", \"wsgi.url_scheme\": \"http\"}\n    assert wsgi.get_host(env, trusted_hosts=[\".example.org\"]) == \"example.org\"\n    pytest.raises(BadRequest, wsgi.get_host, env, trusted_hosts=[\"example.com\"])\n\n\ndef test_responder():\n    def foo(environ, start_response):\n        return Response(b\"Test\")\n\n    client = Client(wsgi.responder(foo))\n    response = client.get(\"/\")\n    assert response.status_code == 200\n    assert response.data == b\"Test\"\n\n\ndef test_path_info_and_script_name_fetching():\n    env = create_environ(\"/\\N{SNOWMAN}\", \"http://example.com/\\N{COMET}/\")\n    assert wsgi.get_path_info(env) == \"/\\N{SNOWMAN}\"\n\n\ndef test_limited_stream():\n    class RaisingLimitedStream(wsgi.LimitedStream):\n        def on_exhausted(self):\n            raise BadRequest(\"input stream exhausted\")\n\n    io_ = io.BytesIO(b\"123456\")\n    stream = RaisingLimitedStream(io_, 3)\n    assert stream.read() == b\"123\"\n    pytest.raises(BadRequest, stream.read)\n\n    io_ = io.BytesIO(b\"123456\")\n    stream = RaisingLimitedStream(io_, 3)\n    assert stream.tell() == 0\n    assert stream.read(1) == b\"1\"\n    assert stream.tell() == 1\n    assert stream.read(1) == b\"2\"\n    assert stream.tell() == 2\n    assert stream.read(1) == b\"3\"\n    assert stream.tell() == 3\n    pytest.raises(BadRequest, stream.read)\n\n    io_ = io.BytesIO(b\"123456\\nabcdefg\")\n    stream = wsgi.LimitedStream(io_, 9)\n    assert stream.readline() == b\"123456\\n\"\n    assert stream.readline() == b\"ab\"\n\n    io_ = io.BytesIO(b\"123456\\nabcdefg\")\n    stream = wsgi.LimitedStream(io_, 9)\n    assert stream.readlines() == [b\"123456\\n\", b\"ab\"]\n\n    io_ = io.BytesIO(b\"123\\n456\\nabcdefg\")\n    stream = wsgi.LimitedStream(io_, 9)\n    assert stream.readlines(2) == [b\"123\\n\"]\n    assert stream.readlines() == [b\"456\\n\", b\"a\"]\n\n    io_ = io.BytesIO(b\"123456\\nabcdefg\")\n    stream = wsgi.LimitedStream(io_, 9)\n    assert stream.readline(100) == b\"123456\\n\"\n\n    io_ = io.BytesIO(b\"123456\\nabcdefg\")\n    stream = wsgi.LimitedStream(io_, 9)\n    assert stream.readlines(100) == [b\"123456\\n\", b\"ab\"]\n\n    io_ = io.BytesIO(b\"123456\")\n    stream = wsgi.LimitedStream(io_, 3)\n    assert stream.read(1) == b\"1\"\n    assert stream.read(1) == b\"2\"\n    assert stream.read() == b\"3\"\n    assert stream.read() == b\"\"\n\n    io_ = io.BytesIO(b\"123456\")\n    stream = wsgi.LimitedStream(io_, 3)\n    assert stream.read(-1) == b\"123\"\n\n    io_ = io.BytesIO(b\"123456\")\n    stream = wsgi.LimitedStream(io_, 0)\n    assert stream.read(-1) == b\"\"\n\n    stream = wsgi.LimitedStream(io.BytesIO(b\"123\\n456\\n\"), 8)\n    assert list(stream) == [b\"123\\n\", b\"456\\n\"]\n\n\ndef test_limited_stream_json_load():\n    stream = wsgi.LimitedStream(io.BytesIO(b'{\"hello\": \"test\"}'), 17)\n    # flask.json adapts bytes to text with TextIOWrapper\n    # this expects stream.readable() to exist and return true\n    stream = io.TextIOWrapper(io.BufferedReader(stream), \"UTF-8\")\n    data = json.load(stream)\n    assert data == {\"hello\": \"test\"}\n\n\ndef test_limited_stream_disconnection():\n    # disconnect because stream returns zero bytes\n    stream = wsgi.LimitedStream(io.BytesIO(), 255)\n    with pytest.raises(ClientDisconnected):\n        stream.read()\n\n    # disconnect because stream is closed\n    data = io.BytesIO(b\"x\" * 255)\n    data.close()\n    stream = wsgi.LimitedStream(data, 255)\n\n    with pytest.raises(ClientDisconnected):\n        stream.read()\n\n\ndef test_limited_stream_read_with_raw_io():\n    class OneByteStream(t.BinaryIO):\n        def __init__(self, buf: bytes) -> None:\n            self.buf = buf\n            self.pos = 0\n\n        def read(self, size: int | None = None) -> bytes:\n            \"\"\"Return one byte at a time regardless of requested size.\"\"\"\n\n            if size is None or size == -1:\n                raise ValueError(\"expected read to be called with specific limit\")\n\n            if size == 0 or len(self.buf) < self.pos:\n                return b\"\"\n\n            b = self.buf[self.pos : self.pos + 1]\n            self.pos += 1\n            return b\n\n    stream = wsgi.LimitedStream(OneByteStream(b\"foo\"), 4)\n    assert stream.read(5) == b\"f\"\n    assert stream.read(5) == b\"o\"\n    assert stream.read(5) == b\"o\"\n\n    # The stream has fewer bytes (3) than the limit (4), therefore the read returns 0\n    # bytes before the limit is reached.\n    with pytest.raises(ClientDisconnected):\n        stream.read(5)\n\n    stream = wsgi.LimitedStream(OneByteStream(b\"foo123\"), 3)\n    assert stream.read(5) == b\"f\"\n    assert stream.read(5) == b\"o\"\n    assert stream.read(5) == b\"o\"\n    # The limit was reached, therefore the wrapper is exhausted, not disconnected.\n    assert stream.read(5) == b\"\"\n\n    stream = wsgi.LimitedStream(OneByteStream(b\"foo\"), 3)\n    assert stream.read() == b\"foo\"\n\n    stream = wsgi.LimitedStream(OneByteStream(b\"foo\"), 2)\n    assert stream.read() == b\"fo\"\n\n\ndef test_get_host_fallback():\n    assert (\n        wsgi.get_host(\n            {\n                \"SERVER_NAME\": \"foobar.example.com\",\n                \"wsgi.url_scheme\": \"http\",\n                \"SERVER_PORT\": \"80\",\n            }\n        )\n        == \"foobar.example.com\"\n    )\n    assert (\n        wsgi.get_host(\n            {\n                \"SERVER_NAME\": \"foobar.example.com\",\n                \"wsgi.url_scheme\": \"http\",\n                \"SERVER_PORT\": \"81\",\n            }\n        )\n        == \"foobar.example.com:81\"\n    )\n\n\ndef test_get_current_url_unicode():\n    env = create_environ(query_string=\"foo=bar&baz=blah&meh=\\xcf\")\n    rv = wsgi.get_current_url(env)\n    assert rv == \"http://localhost/?foo=bar&baz=blah&meh=\\xcf\"\n\n\ndef test_get_current_url_invalid_utf8():\n    env = create_environ()\n    # set the query string *after* wsgi dance, so \\xcf is invalid\n    env[\"QUERY_STRING\"] = \"foo=bar&baz=blah&meh=\\xcf\"\n    rv = wsgi.get_current_url(env)\n    # it remains percent-encoded\n    assert rv == \"http://localhost/?foo=bar&baz=blah&meh=%CF\"\n\n\ndef test_range_wrapper():\n    response = Response(b\"Hello World\")\n    range_wrapper = _RangeWrapper(response.response, 6, 4)\n    assert next(range_wrapper) == b\"Worl\"\n\n    response = Response(b\"Hello World\")\n    range_wrapper = _RangeWrapper(response.response, 1, 0)\n    with pytest.raises(StopIteration):\n        next(range_wrapper)\n\n    response = Response(b\"Hello World\")\n    range_wrapper = _RangeWrapper(response.response, 6, 100)\n    assert next(range_wrapper) == b\"World\"\n\n    response = Response(x for x in (b\"He\", b\"ll\", b\"o \", b\"Wo\", b\"rl\", b\"d\"))\n    range_wrapper = _RangeWrapper(response.response, 6, 4)\n    assert not range_wrapper.seekable\n    assert next(range_wrapper) == b\"Wo\"\n    assert next(range_wrapper) == b\"rl\"\n\n    response = Response(x for x in (b\"He\", b\"ll\", b\"o W\", b\"o\", b\"rld\"))\n    range_wrapper = _RangeWrapper(response.response, 6, 4)\n    assert next(range_wrapper) == b\"W\"\n    assert next(range_wrapper) == b\"o\"\n    assert next(range_wrapper) == b\"rl\"\n    with pytest.raises(StopIteration):\n        next(range_wrapper)\n\n    response = Response(x for x in (b\"Hello\", b\" World\"))\n    range_wrapper = _RangeWrapper(response.response, 1, 1)\n    assert next(range_wrapper) == b\"e\"\n    with pytest.raises(StopIteration):\n        next(range_wrapper)\n\n    resources = os.path.join(os.path.dirname(__file__), \"res\")\n    env = create_environ()\n    with open(os.path.join(resources, \"test.txt\"), \"rb\") as f:\n        response = Response(wrap_file(env, f))\n        range_wrapper = _RangeWrapper(response.response, 1, 2)\n        assert range_wrapper.seekable\n        assert next(range_wrapper) == b\"OU\"\n        with pytest.raises(StopIteration):\n            next(range_wrapper)\n\n    with open(os.path.join(resources, \"test.txt\"), \"rb\") as f:\n        response = Response(wrap_file(env, f))\n        range_wrapper = _RangeWrapper(response.response, 2)\n        assert next(range_wrapper) == b\"UND\\n\"\n        with pytest.raises(StopIteration):\n            next(range_wrapper)\n\n\ndef test_closing_iterator():\n    class Namespace:\n        got_close = False\n        got_additional = False\n\n    class Response:\n        def __init__(self, environ, start_response):\n            self.start = start_response\n\n        # Return a generator instead of making the object its own\n        # iterator. This ensures that ClosingIterator calls close on\n        # the iterable (the object), not the iterator.\n        def __iter__(self):\n            self.start(\"200 OK\", [(\"Content-Type\", \"text/plain\")])\n            yield \"some content\"\n\n        def close(self):\n            Namespace.got_close = True\n\n    def additional():\n        Namespace.got_additional = True\n\n    def app(environ, start_response):\n        return ClosingIterator(Response(environ, start_response), additional)\n\n    app_iter, status, headers = run_wsgi_app(app, create_environ(), buffered=True)\n\n    assert \"\".join(app_iter) == \"some content\"\n    assert Namespace.got_close\n    assert Namespace.got_additional\n", "tests/test_exceptions.py": "from datetime import datetime\n\nimport pytest\nfrom markupsafe import escape\nfrom markupsafe import Markup\n\nfrom werkzeug import exceptions\nfrom werkzeug.datastructures import Headers\nfrom werkzeug.datastructures import WWWAuthenticate\nfrom werkzeug.exceptions import default_exceptions\nfrom werkzeug.exceptions import HTTPException\nfrom werkzeug.wrappers import Response\n\n\ndef test_proxy_exception():\n    orig_resp = Response(\"Hello World\")\n    with pytest.raises(exceptions.HTTPException) as excinfo:\n        exceptions.abort(orig_resp)\n    resp = excinfo.value.get_response({})\n    assert resp is orig_resp\n    assert resp.get_data() == b\"Hello World\"\n\n\n@pytest.mark.parametrize(\n    \"test\",\n    [\n        (exceptions.BadRequest, 400),\n        (exceptions.Unauthorized, 401, 'Basic \"test realm\"'),\n        (exceptions.Forbidden, 403),\n        (exceptions.NotFound, 404),\n        (exceptions.MethodNotAllowed, 405, [\"GET\", \"HEAD\"]),\n        (exceptions.NotAcceptable, 406),\n        (exceptions.RequestTimeout, 408),\n        (exceptions.Gone, 410),\n        (exceptions.LengthRequired, 411),\n        (exceptions.PreconditionFailed, 412),\n        (exceptions.RequestEntityTooLarge, 413),\n        (exceptions.RequestURITooLarge, 414),\n        (exceptions.UnsupportedMediaType, 415),\n        (exceptions.UnprocessableEntity, 422),\n        (exceptions.Locked, 423),\n        (exceptions.InternalServerError, 500),\n        (exceptions.NotImplemented, 501),\n        (exceptions.BadGateway, 502),\n        (exceptions.ServiceUnavailable, 503),\n    ],\n)\ndef test_aborter_general(test):\n    exc_type = test[0]\n    args = test[1:]\n\n    with pytest.raises(exc_type) as exc_info:\n        exceptions.abort(*args)\n    assert type(exc_info.value) is exc_type\n\n\ndef test_abort_description_markup():\n    with pytest.raises(HTTPException) as exc_info:\n        exceptions.abort(400, Markup(\"<b>&lt;</b>\"))\n\n    assert \"<b>&lt;</b>\" in str(exc_info.value)\n\n\ndef test_aborter_custom():\n    myabort = exceptions.Aborter({1: exceptions.NotFound})\n    pytest.raises(LookupError, myabort, 404)\n    pytest.raises(exceptions.NotFound, myabort, 1)\n\n    myabort = exceptions.Aborter(extra={1: exceptions.NotFound})\n    pytest.raises(exceptions.NotFound, myabort, 404)\n    pytest.raises(exceptions.NotFound, myabort, 1)\n\n\ndef test_exception_repr():\n    exc = exceptions.NotFound()\n    assert str(exc) == (\n        \"404 Not Found: The requested URL was not found on the server.\"\n        \" If you entered the URL manually please check your spelling\"\n        \" and try again.\"\n    )\n    assert repr(exc) == \"<NotFound '404: Not Found'>\"\n\n    exc = exceptions.NotFound(\"Not There\")\n    assert str(exc) == \"404 Not Found: Not There\"\n    assert repr(exc) == \"<NotFound '404: Not Found'>\"\n\n    exc = exceptions.HTTPException(\"An error message\")\n    assert str(exc) == \"??? Unknown Error: An error message\"\n    assert repr(exc) == \"<HTTPException '???: Unknown Error'>\"\n\n\ndef test_method_not_allowed_methods():\n    exc = exceptions.MethodNotAllowed([\"GET\", \"HEAD\", \"POST\"])\n    h = dict(exc.get_headers({}))\n    assert h[\"Allow\"] == \"GET, HEAD, POST\"\n    assert \"The method is not allowed\" in exc.get_description()\n\n\ndef test_unauthorized_www_authenticate():\n    basic = WWWAuthenticate(\"basic\", {\"realm\": \"test\"})\n    digest = WWWAuthenticate(\"digest\", {\"realm\": \"test\", \"nonce\": \"test\"})\n\n    exc = exceptions.Unauthorized(www_authenticate=basic)\n    h = Headers(exc.get_headers({}))\n    assert h[\"WWW-Authenticate\"] == str(basic)\n\n    exc = exceptions.Unauthorized(www_authenticate=[digest, basic])\n    h = Headers(exc.get_headers({}))\n    assert h.get_all(\"WWW-Authenticate\") == [str(digest), str(basic)]\n\n    exc = exceptions.Unauthorized()\n    h = Headers(exc.get_headers({}))\n    assert \"WWW-Authenticate\" not in h\n\n\ndef test_response_header_content_type_should_contain_charset():\n    exc = exceptions.HTTPException(\"An error message\")\n    h = exc.get_response({})\n    assert h.headers[\"Content-Type\"] == \"text/html; charset=utf-8\"\n\n\n@pytest.mark.parametrize(\n    (\"cls\", \"value\", \"expect\"),\n    [\n        (exceptions.TooManyRequests, 20, \"20\"),\n        (\n            exceptions.ServiceUnavailable,\n            datetime(2020, 1, 4, 18, 52, 16),\n            \"Sat, 04 Jan 2020 18:52:16 GMT\",\n        ),\n    ],\n)\ndef test_retry_after_mixin(cls, value, expect):\n    e = cls(retry_after=value)\n    h = dict(e.get_headers({}))\n    assert h[\"Retry-After\"] == expect\n\n\n@pytest.mark.parametrize(\n    \"cls\",\n    sorted(\n        (e for e in default_exceptions.values() if e.code and e.code >= 400),\n        key=lambda e: e.code,  # type: ignore\n    ),\n)\ndef test_passing_response(cls):\n    class TestResponse(Response):\n        pass\n\n    exc = cls(response=TestResponse())\n    rp = exc.get_response({})\n    assert isinstance(rp, TestResponse)\n\n\ndef test_description_none():\n    HTTPException().get_response()\n\n\n@pytest.mark.parametrize(\n    \"cls\",\n    sorted(\n        (e for e in default_exceptions.values() if e.code),\n        key=lambda e: e.code,  # type: ignore\n    ),\n)\ndef test_response_body(cls):\n    exc = cls()\n    response_body = exc.get_body()\n    assert response_body.startswith(\"<!doctype html>\\n<html lang=en>\\n\")\n    assert f\"{exc.code} {escape(exc.name)}\" in response_body\n    assert exc.get_description() in response_body\n", "tests/conftest.py": "import http.client\nimport json\nimport os\nimport socket\nimport ssl\nimport sys\nfrom pathlib import Path\n\nimport ephemeral_port_reserve\nimport pytest\nfrom xprocess import ProcessStarter\n\nfrom werkzeug.utils import cached_property\n\nrun_path = str(Path(__file__).parent / \"live_apps\" / \"run.py\")\n\n\nclass UnixSocketHTTPConnection(http.client.HTTPConnection):\n    def connect(self):\n        self.sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n        self.sock.connect(self.host)\n\n\nclass DevServerClient:\n    def __init__(self, kwargs):\n        host = kwargs.get(\"hostname\", \"127.0.0.1\")\n\n        if not host.startswith(\"unix\"):\n            port = kwargs.get(\"port\")\n\n            if port is None:\n                kwargs[\"port\"] = port = ephemeral_port_reserve.reserve(host)\n\n            scheme = \"https\" if \"ssl_context\" in kwargs else \"http\"\n            self.addr = f\"{host}:{port}\"\n            self.url = f\"{scheme}://{self.addr}\"\n        else:\n            self.addr = host[7:]  # strip \"unix://\"\n            self.url = host\n\n        self.log = None\n\n    def tail_log(self, path):\n        # surrogateescape allows for handling of file streams\n        # containing junk binary values as normal text streams\n        self.log = open(path, errors=\"surrogateescape\")\n        self.log.read()\n\n    def connect(self, **kwargs):\n        protocol = self.url.partition(\":\")[0]\n\n        if protocol == \"https\":\n            if \"context\" not in kwargs:\n                context = ssl.SSLContext(ssl.PROTOCOL_TLS_CLIENT)\n                context.check_hostname = False\n                context.verify_mode = ssl.CERT_NONE\n                kwargs[\"context\"] = context\n\n            return http.client.HTTPSConnection(self.addr, **kwargs)\n\n        if protocol == \"unix\":\n            return UnixSocketHTTPConnection(self.addr, **kwargs)\n\n        return http.client.HTTPConnection(self.addr, **kwargs)\n\n    def request(self, path=\"\", **kwargs):\n        kwargs.setdefault(\"method\", \"GET\")\n        kwargs.setdefault(\"url\", path)\n        conn = self.connect()\n        conn.request(**kwargs)\n\n        with conn.getresponse() as response:\n            response.data = response.read()\n\n        conn.close()\n\n        if response.headers.get(\"Content-Type\", \"\").startswith(\"application/json\"):\n            response.json = json.loads(response.data)\n        else:\n            response.json = None\n\n        return response\n\n    def wait_for_log(self, start):\n        while True:\n            for line in self.log:\n                if line.startswith(start):\n                    return\n\n    def wait_for_reload(self):\n        self.wait_for_log(\" * Restarting with \")\n\n\n@pytest.fixture()\ndef dev_server(xprocess, request, tmp_path):\n    \"\"\"A function that will start a dev server in an external process\n    and return a client for interacting with the server.\n    \"\"\"\n\n    def start_dev_server(name=\"standard\", **kwargs):\n        client = DevServerClient(kwargs)\n\n        class Starter(ProcessStarter):\n            args = [sys.executable, run_path, name, json.dumps(kwargs)]\n            # Extend the existing env, otherwise Windows and CI fails.\n            # Modules will be imported from tmp_path for the reloader.\n            # Unbuffered output so the logs update immediately.\n            env = {**os.environ, \"PYTHONPATH\": str(tmp_path), \"PYTHONUNBUFFERED\": \"1\"}\n\n            @cached_property\n            def pattern(self):\n                client.request(\"/ensure\")\n                return \"GET /ensure\"\n\n        # Each test that uses the fixture will have a different log.\n        xp_name = f\"dev_server-{request.node.name}\"\n        _, log_path = xprocess.ensure(xp_name, Starter, restart=True)\n        client.tail_log(log_path)\n\n        @request.addfinalizer\n        def close():\n            xprocess.getinfo(xp_name).terminate()\n            client.log.close()\n\n        return client\n\n    return start_dev_server\n\n\n@pytest.fixture()\ndef standard_app(dev_server):\n    \"\"\"Equivalent to ``dev_server(\"standard\")``.\"\"\"\n    return dev_server()\n", "tests/test_routing.py": "import gc\nimport typing as t\nimport uuid\n\nimport pytest\n\nfrom werkzeug import routing as r\nfrom werkzeug.datastructures import ImmutableDict\nfrom werkzeug.datastructures import MultiDict\nfrom werkzeug.exceptions import MethodNotAllowed\nfrom werkzeug.exceptions import NotFound\nfrom werkzeug.test import create_environ\nfrom werkzeug.wrappers import Response\n\n\ndef test_basic_routing():\n    map = r.Map(\n        [\n            r.Rule(\"/\", endpoint=\"index\"),\n            r.Rule(\"/foo\", endpoint=\"foo\"),\n            r.Rule(\"/bar/\", endpoint=\"bar\"),\n            r.Rule(\"/ws\", endpoint=\"ws\", websocket=True),\n            r.Rule(\"/\", endpoint=\"indexws\", websocket=True),\n        ]\n    )\n    adapter = map.bind(\"example.org\", \"/\")\n    assert adapter.match(\"/\") == (\"index\", {})\n    assert adapter.match(\"/foo\") == (\"foo\", {})\n    assert adapter.match(\"/bar/\") == (\"bar\", {})\n    pytest.raises(r.RequestRedirect, lambda: adapter.match(\"/bar\"))\n    pytest.raises(NotFound, lambda: adapter.match(\"/blub\"))\n\n    adapter = map.bind(\"example.org\", \"/\", url_scheme=\"ws\")\n    assert adapter.match(\"/\") == (\"indexws\", {})\n\n    adapter = map.bind(\"example.org\", \"/test\")\n    with pytest.raises(r.RequestRedirect) as excinfo:\n        adapter.match(\"/bar\")\n    assert excinfo.value.new_url == \"http://example.org/test/bar/\"\n\n    adapter = map.bind(\"example.org\", \"/\")\n    with pytest.raises(r.RequestRedirect) as excinfo:\n        adapter.match(\"/bar\")\n    assert excinfo.value.new_url == \"http://example.org/bar/\"\n\n    adapter = map.bind(\"example.org\", \"/\")\n    with pytest.raises(r.RequestRedirect) as excinfo:\n        adapter.match(\"/bar\", query_args={\"aha\": \"muhaha\"})\n    assert excinfo.value.new_url == \"http://example.org/bar/?aha=muhaha\"\n\n    adapter = map.bind(\"example.org\", \"/\")\n    with pytest.raises(r.RequestRedirect) as excinfo:\n        adapter.match(\"/bar\", query_args=\"aha=muhaha\")\n    assert excinfo.value.new_url == \"http://example.org/bar/?aha=muhaha\"\n\n    adapter = map.bind_to_environ(create_environ(\"/bar?foo=bar\", \"http://example.org/\"))\n    with pytest.raises(r.RequestRedirect) as excinfo:\n        adapter.match()\n    assert excinfo.value.new_url == \"http://example.org/bar/?foo=bar\"\n\n    adapter = map.bind(\"example.org\", \"/ws\", url_scheme=\"wss\")\n    assert adapter.match(\"/ws\", websocket=True) == (\"ws\", {})\n    with pytest.raises(r.WebsocketMismatch):\n        adapter.match(\"/ws\", websocket=False)\n    with pytest.raises(r.WebsocketMismatch):\n        adapter.match(\"/foo\", websocket=True)\n\n    adapter = map.bind_to_environ(\n        create_environ(\n            \"/ws?foo=bar\",\n            \"http://example.org/\",\n            headers=[(\"Connection\", \"Upgrade\"), (\"upgrade\", \"WebSocket\")],\n        )\n    )\n    assert adapter.match(\"/ws\") == (\"ws\", {})\n    with pytest.raises(r.WebsocketMismatch):\n        adapter.match(\"/ws\", websocket=False)\n\n    adapter = map.bind_to_environ(\n        create_environ(\n            \"/ws?foo=bar\",\n            \"http://example.org/\",\n            headers=[(\"Connection\", \"keep-alive, Upgrade\"), (\"upgrade\", \"websocket\")],\n        )\n    )\n    assert adapter.match(\"/ws\") == (\"ws\", {})\n    with pytest.raises(r.WebsocketMismatch):\n        adapter.match(\"/ws\", websocket=False)\n\n\ndef test_merge_slashes_match():\n    url_map = r.Map(\n        [\n            r.Rule(\"/no/tail\", endpoint=\"no_tail\"),\n            r.Rule(\"/yes/tail/\", endpoint=\"yes_tail\"),\n            r.Rule(\"/with/<path:path>\", endpoint=\"with_path\"),\n            r.Rule(\"/no//merge\", endpoint=\"no_merge\", merge_slashes=False),\n            r.Rule(\"/no/merging\", endpoint=\"no_merging\", merge_slashes=False),\n        ]\n    )\n    adapter = url_map.bind(\"localhost\", \"/\")\n\n    with pytest.raises(r.RequestRedirect) as excinfo:\n        adapter.match(\"/no//tail\")\n\n    assert excinfo.value.new_url.endswith(\"/no/tail\")\n\n    with pytest.raises(r.RequestRedirect) as excinfo:\n        adapter.match(\"/yes//tail\")\n\n    assert excinfo.value.new_url.endswith(\"/yes/tail/\")\n\n    with pytest.raises(r.RequestRedirect) as excinfo:\n        adapter.match(\"/yes/tail//\")\n\n    assert excinfo.value.new_url.endswith(\"/yes/tail/\")\n\n    assert adapter.match(\"/no/tail\")[0] == \"no_tail\"\n    assert adapter.match(\"/yes/tail/\")[0] == \"yes_tail\"\n\n    _, rv = adapter.match(\"/with/http://example.com/\")\n    assert rv[\"path\"] == \"http://example.com/\"\n    _, rv = adapter.match(\"/with/x//y\")\n    assert rv[\"path\"] == \"x//y\"\n\n    assert adapter.match(\"/no//merge\")[0] == \"no_merge\"\n\n    assert adapter.match(\"/no/merging\")[0] == \"no_merging\"\n    pytest.raises(NotFound, lambda: adapter.match(\"/no//merging\"))\n\n\n@pytest.mark.parametrize(\n    (\"path\", \"expected\"),\n    [(\"/merge/%//path\", \"/merge/%25/path\"), (\"/merge//st/path\", \"/merge/st/path\")],\n)\ndef test_merge_slash_encoding(path, expected):\n    \"\"\"This test is to make sure URLs are not double-encoded\n    when a redirect is thrown with `merge_slash = True`\"\"\"\n    url_map = r.Map(\n        [\n            r.Rule(\"/merge/<some>/path\"),\n        ]\n    )\n    adapter = url_map.bind(\"localhost\", \"/\")\n\n    with pytest.raises(r.RequestRedirect) as excinfo:\n        adapter.match(path)\n\n    assert excinfo.value.new_url.endswith(expected)\n\n\ndef test_merge_slashes_build():\n    url_map = r.Map(\n        [\n            r.Rule(\"/yes//merge\", endpoint=\"yes_merge\"),\n            r.Rule(\"/no//merge\", endpoint=\"no_merge\", merge_slashes=False),\n        ]\n    )\n    adapter = url_map.bind(\"localhost\", \"/\")\n    assert adapter.build(\"yes_merge\") == \"/yes/merge\"\n    assert adapter.build(\"no_merge\") == \"/no//merge\"\n\n\ndef test_strict_slashes_redirect():\n    map = r.Map(\n        [\n            r.Rule(\"/bar/\", endpoint=\"get\", methods=[\"GET\"]),\n            r.Rule(\"/bar\", endpoint=\"post\", methods=[\"POST\"]),\n            r.Rule(\"/foo/\", endpoint=\"foo\", methods=[\"POST\"]),\n            r.Rule(\"/<path:var>/\", endpoint=\"path\", methods=[\"GET\"]),\n        ]\n    )\n    adapter = map.bind(\"example.org\", \"/\")\n\n    # Check if the actual routes works\n    assert adapter.match(\"/bar/\", method=\"GET\") == (\"get\", {})\n    assert adapter.match(\"/bar\", method=\"POST\") == (\"post\", {})\n    assert adapter.match(\"/abc/\", method=\"GET\") == (\"path\", {\"var\": \"abc\"})\n\n    # Check if exceptions are correct\n    pytest.raises(r.RequestRedirect, adapter.match, \"/bar\", method=\"GET\")\n    pytest.raises(MethodNotAllowed, adapter.match, \"/bar/\", method=\"POST\")\n    with pytest.raises(r.RequestRedirect) as error_info:\n        adapter.match(\"/foo\", method=\"POST\")\n    assert error_info.value.code == 308\n    with pytest.raises(r.RequestRedirect) as error_info:\n        adapter.match(\"/abc\", method=\"GET\")\n    assert error_info.value.new_url == \"http://example.org/abc/\"\n\n    # Check differently defined order\n    map = r.Map(\n        [\n            r.Rule(\"/bar\", endpoint=\"post\", methods=[\"POST\"]),\n            r.Rule(\"/bar/\", endpoint=\"get\", methods=[\"GET\"]),\n        ]\n    )\n    adapter = map.bind(\"example.org\", \"/\")\n\n    # Check if the actual routes works\n    assert adapter.match(\"/bar/\", method=\"GET\") == (\"get\", {})\n    assert adapter.match(\"/bar\", method=\"POST\") == (\"post\", {})\n\n    # Check if exceptions are correct\n    pytest.raises(r.RequestRedirect, adapter.match, \"/bar\", method=\"GET\")\n    pytest.raises(MethodNotAllowed, adapter.match, \"/bar/\", method=\"POST\")\n\n    # Check what happens when only slash route is defined\n    map = r.Map([r.Rule(\"/bar/\", endpoint=\"get\", methods=[\"GET\"])])\n    adapter = map.bind(\"example.org\", \"/\")\n\n    # Check if the actual routes works\n    assert adapter.match(\"/bar/\", method=\"GET\") == (\"get\", {})\n\n    # Check if exceptions are correct\n    pytest.raises(r.RequestRedirect, adapter.match, \"/bar\", method=\"GET\")\n    pytest.raises(MethodNotAllowed, adapter.match, \"/bar/\", method=\"POST\")\n\n\ndef test_strict_slashes_leaves_dont_consume():\n    # See issue #1074\n    map = r.Map(\n        [\n            r.Rule(\"/path1\", endpoint=\"leaf\"),\n            r.Rule(\"/path1/\", endpoint=\"branch\"),\n            r.Rule(\"/path2\", endpoint=\"leaf\", strict_slashes=False),\n            r.Rule(\"/path2/\", endpoint=\"branch\"),\n            r.Rule(\"/path3\", endpoint=\"leaf\"),\n            r.Rule(\"/path3/\", endpoint=\"branch\", strict_slashes=False),\n            r.Rule(\"/path4\", endpoint=\"leaf\", strict_slashes=False),\n            r.Rule(\"/path4/\", endpoint=\"branch\", strict_slashes=False),\n            r.Rule(\"/path5\", endpoint=\"leaf\"),\n        ],\n        strict_slashes=False,\n    )\n\n    adapter = map.bind(\"example.org\", \"/\")\n\n    assert adapter.match(\"/path1\", method=\"GET\") == (\"leaf\", {})\n    assert adapter.match(\"/path1/\", method=\"GET\") == (\"branch\", {})\n    assert adapter.match(\"/path2\", method=\"GET\") == (\"leaf\", {})\n    assert adapter.match(\"/path2/\", method=\"GET\") == (\"branch\", {})\n    assert adapter.match(\"/path3\", method=\"GET\") == (\"leaf\", {})\n    assert adapter.match(\"/path3/\", method=\"GET\") == (\"branch\", {})\n    assert adapter.match(\"/path4\", method=\"GET\") == (\"leaf\", {})\n    assert adapter.match(\"/path4/\", method=\"GET\") == (\"branch\", {})\n    assert adapter.match(\"/path5/\", method=\"GET\") == (\"leaf\", {})\n\n\ndef test_environ_defaults():\n    environ = create_environ(\"/foo\")\n    assert environ[\"PATH_INFO\"] == \"/foo\"\n    m = r.Map([r.Rule(\"/foo\", endpoint=\"foo\"), r.Rule(\"/bar\", endpoint=\"bar\")])\n    a = m.bind_to_environ(environ)\n    assert a.match(\"/foo\") == (\"foo\", {})\n    assert a.match() == (\"foo\", {})\n    assert a.match(\"/bar\") == (\"bar\", {})\n    pytest.raises(NotFound, a.match, \"/bars\")\n\n\ndef test_environ_nonascii_pathinfo():\n    environ = create_environ(\"/\u043b\u043e\u0448\u0430\u0434\u044c\")\n    m = r.Map([r.Rule(\"/\", endpoint=\"index\"), r.Rule(\"/\u043b\u043e\u0448\u0430\u0434\u044c\", endpoint=\"horse\")])\n    a = m.bind_to_environ(environ)\n    assert a.match(\"/\") == (\"index\", {})\n    assert a.match(\"/\u043b\u043e\u0448\u0430\u0434\u044c\") == (\"horse\", {})\n    pytest.raises(NotFound, a.match, \"/\u0431\u0430\u0440\u0441\u0443\u043a\")\n\n\ndef test_basic_building():\n    map = r.Map(\n        [\n            r.Rule(\"/\", endpoint=\"index\"),\n            r.Rule(\"/foo\", endpoint=\"foo\"),\n            r.Rule(\"/bar/<baz>\", endpoint=\"bar\"),\n            r.Rule(\"/bar/<int:bazi>\", endpoint=\"bari\"),\n            r.Rule(\"/bar/<float:bazf>\", endpoint=\"barf\"),\n            r.Rule(\"/bar/<path:bazp>\", endpoint=\"barp\"),\n            r.Rule(\"/hehe\", endpoint=\"blah\", subdomain=\"blah\"),\n            r.Rule(\"/ws\", endpoint=\"ws\", websocket=True),\n        ]\n    )\n    adapter = map.bind(\"example.org\", \"/\", subdomain=\"blah\")\n\n    assert adapter.build(\"index\", {}) == \"http://example.org/\"\n    assert adapter.build(\"foo\", {}) == \"http://example.org/foo\"\n    assert adapter.build(\"bar\", {\"baz\": \"blub\"}) == \"http://example.org/bar/blub\"\n    assert adapter.build(\"bari\", {\"bazi\": 50}) == \"http://example.org/bar/50\"\n    assert adapter.build(\"barf\", {\"bazf\": 0.815}) == \"http://example.org/bar/0.815\"\n    assert adapter.build(\"barp\", {\"bazp\": \"la/di\"}) == \"http://example.org/bar/la/di\"\n    assert adapter.build(\"blah\", {}) == \"/hehe\"\n    pytest.raises(r.BuildError, lambda: adapter.build(\"urks\"))\n\n    adapter = map.bind(\"example.org\", \"/test\", subdomain=\"blah\")\n    assert adapter.build(\"index\", {}) == \"http://example.org/test/\"\n    assert adapter.build(\"foo\", {}) == \"http://example.org/test/foo\"\n    assert adapter.build(\"bar\", {\"baz\": \"blub\"}) == \"http://example.org/test/bar/blub\"\n    assert adapter.build(\"bari\", {\"bazi\": 50}) == \"http://example.org/test/bar/50\"\n    assert adapter.build(\"barf\", {\"bazf\": 0.815}) == \"http://example.org/test/bar/0.815\"\n    assert (\n        adapter.build(\"barp\", {\"bazp\": \"la/di\"}) == \"http://example.org/test/bar/la/di\"\n    )\n    assert adapter.build(\"blah\", {}) == \"/test/hehe\"\n\n    adapter = map.bind(\"example.org\")\n    assert adapter.build(\"foo\", {}) == \"/foo\"\n    assert adapter.build(\"foo\", {}, force_external=True) == \"http://example.org/foo\"\n    adapter = map.bind(\"example.org\", url_scheme=\"\")\n    assert adapter.build(\"foo\", {}) == \"/foo\"\n    assert adapter.build(\"foo\", {}, force_external=True) == \"//example.org/foo\"\n    assert (\n        adapter.build(\"foo\", {}, url_scheme=\"https\", force_external=True)\n        == \"https://example.org/foo\"\n    )\n\n    adapter = map.bind(\"example.org\", url_scheme=\"ws\")\n    assert adapter.build(\"ws\", {}) == \"ws://example.org/ws\"\n    assert adapter.build(\"foo\", {}, force_external=True) == \"http://example.org/foo\"\n    assert adapter.build(\"foo\", {}) == \"/foo\"\n    assert adapter.build(\"ws\", {}, url_scheme=\"https\") == \"wss://example.org/ws\"\n\n\ndef test_long_build():\n    long_args = {f\"v{x}\": x for x in range(10000)}\n    map = r.Map(\n        [\n            r.Rule(\n                \"\".join(f\"/<{k}>\" for k in long_args.keys()),\n                endpoint=\"bleep\",\n                build_only=True,\n            )\n        ]\n    )\n    adapter = map.bind(\"localhost\", \"/\")\n    url = f\"{adapter.build('bleep', long_args)}/\"\n    for v in long_args.values():\n        assert f\"/{v}\" in url\n\n\ndef test_defaults():\n    map = r.Map(\n        [\n            r.Rule(\"/foo/\", defaults={\"page\": 1}, endpoint=\"foo\"),\n            r.Rule(\"/foo/<int:page>\", endpoint=\"foo\"),\n        ]\n    )\n    adapter = map.bind(\"example.org\", \"/\")\n\n    assert adapter.match(\"/foo/\") == (\"foo\", {\"page\": 1})\n    pytest.raises(r.RequestRedirect, lambda: adapter.match(\"/foo/1\"))\n    assert adapter.match(\"/foo/2\") == (\"foo\", {\"page\": 2})\n    assert adapter.build(\"foo\", {}) == \"/foo/\"\n    assert adapter.build(\"foo\", {\"page\": 1}) == \"/foo/\"\n    assert adapter.build(\"foo\", {\"page\": 2}) == \"/foo/2\"\n\n\ndef test_negative():\n    map = r.Map(\n        [\n            r.Rule(\"/foos/<int(signed=True):page>\", endpoint=\"foos\"),\n            r.Rule(\"/bars/<float(signed=True):page>\", endpoint=\"bars\"),\n            r.Rule(\"/foo/<int:page>\", endpoint=\"foo\"),\n            r.Rule(\"/bar/<float:page>\", endpoint=\"bar\"),\n        ]\n    )\n    adapter = map.bind(\"example.org\", \"/\")\n\n    assert adapter.match(\"/foos/-2\") == (\"foos\", {\"page\": -2})\n    assert adapter.match(\"/foos/-50\") == (\"foos\", {\"page\": -50})\n    assert adapter.match(\"/bars/-2.0\") == (\"bars\", {\"page\": -2.0})\n    assert adapter.match(\"/bars/-0.185\") == (\"bars\", {\"page\": -0.185})\n\n    # Make sure signed values are rejected in unsigned mode\n    pytest.raises(NotFound, lambda: adapter.match(\"/foo/-2\"))\n    pytest.raises(NotFound, lambda: adapter.match(\"/foo/-50\"))\n    pytest.raises(NotFound, lambda: adapter.match(\"/bar/-0.185\"))\n    pytest.raises(NotFound, lambda: adapter.match(\"/bar/-2.0\"))\n\n\ndef test_greedy():\n    map = r.Map(\n        [\n            r.Rule(\"/foo\", endpoint=\"foo\"),\n            r.Rule(\"/<path:bar>\", endpoint=\"bar\"),\n            r.Rule(\"/<path:bar>/<path:blub>\", endpoint=\"bar\"),\n        ]\n    )\n    adapter = map.bind(\"example.org\", \"/\")\n\n    assert adapter.match(\"/foo\") == (\"foo\", {})\n    assert adapter.match(\"/blub\") == (\"bar\", {\"bar\": \"blub\"})\n    assert adapter.match(\"/he/he\") == (\"bar\", {\"bar\": \"he\", \"blub\": \"he\"})\n\n    assert adapter.build(\"foo\", {}) == \"/foo\"\n    assert adapter.build(\"bar\", {\"bar\": \"blub\"}) == \"/blub\"\n    assert adapter.build(\"bar\", {\"bar\": \"blub\", \"blub\": \"bar\"}) == \"/blub/bar\"\n\n\ndef test_path():\n    map = r.Map(\n        [\n            r.Rule(\"/\", defaults={\"name\": \"FrontPage\"}, endpoint=\"page\"),\n            r.Rule(\"/Special\", endpoint=\"special\"),\n            r.Rule(\"/<int:year>\", endpoint=\"year\"),\n            r.Rule(\"/<path:name>:foo\", endpoint=\"foopage\"),\n            r.Rule(\"/<path:name>:<path:name2>\", endpoint=\"twopage\"),\n            r.Rule(\"/<path:name>\", endpoint=\"page\"),\n            r.Rule(\"/<path:name>/edit\", endpoint=\"editpage\"),\n            r.Rule(\"/<path:name>/silly/<path:name2>\", endpoint=\"sillypage\"),\n            r.Rule(\"/<path:name>/silly/<path:name2>/edit\", endpoint=\"editsillypage\"),\n            r.Rule(\"/Talk:<path:name>\", endpoint=\"talk\"),\n            r.Rule(\"/User:<username>\", endpoint=\"user\"),\n            r.Rule(\"/User:<username>/<path:name>\", endpoint=\"userpage\"),\n            r.Rule(\n                \"/User:<username>/comment/<int:id>-<int:replyId>\",\n                endpoint=\"usercomment\",\n            ),\n            r.Rule(\"/Files/<path:file>\", endpoint=\"files\"),\n            r.Rule(\"/<admin>/<manage>/<things>\", endpoint=\"admin\"),\n        ]\n    )\n    adapter = map.bind(\"example.org\", \"/\")\n\n    assert adapter.match(\"/\") == (\"page\", {\"name\": \"FrontPage\"})\n    pytest.raises(r.RequestRedirect, lambda: adapter.match(\"/FrontPage\"))\n    assert adapter.match(\"/Special\") == (\"special\", {})\n    assert adapter.match(\"/2007\") == (\"year\", {\"year\": 2007})\n    assert adapter.match(\"/Some:foo\") == (\"foopage\", {\"name\": \"Some\"})\n    assert adapter.match(\"/Some:bar\") == (\"twopage\", {\"name\": \"Some\", \"name2\": \"bar\"})\n    assert adapter.match(\"/Some/Page\") == (\"page\", {\"name\": \"Some/Page\"})\n    assert adapter.match(\"/Some/Page/edit\") == (\"editpage\", {\"name\": \"Some/Page\"})\n    assert adapter.match(\"/Foo/silly/bar\") == (\n        \"sillypage\",\n        {\"name\": \"Foo\", \"name2\": \"bar\"},\n    )\n    assert adapter.match(\"/Foo/silly/bar/edit\") == (\n        \"editsillypage\",\n        {\"name\": \"Foo\", \"name2\": \"bar\"},\n    )\n    assert adapter.match(\"/Talk:Foo/Bar\") == (\"talk\", {\"name\": \"Foo/Bar\"})\n    assert adapter.match(\"/User:thomas\") == (\"user\", {\"username\": \"thomas\"})\n    assert adapter.match(\"/User:thomas/projects/werkzeug\") == (\n        \"userpage\",\n        {\"username\": \"thomas\", \"name\": \"projects/werkzeug\"},\n    )\n    assert adapter.match(\"/User:thomas/comment/123-456\") == (\n        \"usercomment\",\n        {\"username\": \"thomas\", \"id\": 123, \"replyId\": 456},\n    )\n    assert adapter.match(\"/Files/downloads/werkzeug/0.2.zip\") == (\n        \"files\",\n        {\"file\": \"downloads/werkzeug/0.2.zip\"},\n    )\n    assert adapter.match(\"/Jerry/eats/cheese\") == (\n        \"admin\",\n        {\"admin\": \"Jerry\", \"manage\": \"eats\", \"things\": \"cheese\"},\n    )\n\n\ndef test_dispatch():\n    env = create_environ(\"/\")\n    map = r.Map([r.Rule(\"/\", endpoint=\"root\"), r.Rule(\"/foo/\", endpoint=\"foo\")])\n    adapter = map.bind_to_environ(env)\n\n    raise_this = None\n\n    def view_func(endpoint, values):\n        if raise_this is not None:\n            raise raise_this\n        return Response(repr((endpoint, values)))\n\n    def dispatch(path, quiet=False):\n        return Response.force_type(\n            adapter.dispatch(view_func, path, catch_http_exceptions=quiet), env\n        )\n\n    assert dispatch(\"/\").data == b\"('root', {})\"\n    assert dispatch(\"/foo\").status_code == 308\n    raise_this = NotFound()\n    pytest.raises(NotFound, lambda: dispatch(\"/bar\"))\n    assert dispatch(\"/bar\", True).status_code == 404\n\n\ndef test_http_host_before_server_name():\n    env = {\n        \"HTTP_HOST\": \"wiki.example.com\",\n        \"SERVER_NAME\": \"web0.example.com\",\n        \"SERVER_PORT\": \"80\",\n        \"SCRIPT_NAME\": \"\",\n        \"PATH_INFO\": \"\",\n        \"REQUEST_METHOD\": \"GET\",\n        \"wsgi.url_scheme\": \"http\",\n    }\n    map = r.Map([r.Rule(\"/\", endpoint=\"index\", subdomain=\"wiki\")])\n    adapter = map.bind_to_environ(env, server_name=\"example.com\")\n    assert adapter.match(\"/\") == (\"index\", {})\n    assert adapter.build(\"index\", force_external=True) == \"http://wiki.example.com/\"\n    assert adapter.build(\"index\") == \"/\"\n\n    env[\"HTTP_HOST\"] = \"admin.example.com\"\n    adapter = map.bind_to_environ(env, server_name=\"example.com\")\n    assert adapter.build(\"index\") == \"http://wiki.example.com/\"\n\n\ndef test_invalid_subdomain_warning():\n    env = create_environ(\"/foo\")\n    env[\"SERVER_NAME\"] = env[\"HTTP_HOST\"] = \"foo.example.com\"\n    m = r.Map([r.Rule(\"/foo\", endpoint=\"foo\")])\n    with pytest.warns(UserWarning) as record:\n        a = m.bind_to_environ(env, server_name=\"bar.example.com\")\n    assert a.subdomain == \"<invalid>\"\n    assert len(record) == 1\n\n\n@pytest.mark.parametrize(\n    (\"base\", \"name\"),\n    ((\"http://localhost\", \"localhost:80\"), (\"https://localhost\", \"localhost:443\")),\n)\ndef test_server_name_match_default_port(base, name):\n    environ = create_environ(\"/foo\", base_url=base)\n    map = r.Map([r.Rule(\"/foo\", endpoint=\"foo\")])\n    adapter = map.bind_to_environ(environ, server_name=name)\n    assert adapter.match() == (\"foo\", {})\n\n\ndef test_adapter_url_parameter_sorting():\n    map = r.Map(\n        [r.Rule(\"/\", endpoint=\"index\")], sort_parameters=True, sort_key=lambda x: x[1]\n    )\n    adapter = map.bind(\"localhost\", \"/\")\n    assert (\n        adapter.build(\"index\", {\"x\": 20, \"y\": 10, \"z\": 30}, force_external=True)\n        == \"http://localhost/?y=10&x=20&z=30\"\n    )\n\n\ndef test_request_direct_charset_bug():\n    map = r.Map([r.Rule(\"/\u00f6\u00e4\u00fc/\")])\n    adapter = map.bind(\"localhost\", \"/\")\n\n    with pytest.raises(r.RequestRedirect) as excinfo:\n        adapter.match(\"/\u00f6\u00e4\u00fc\")\n    assert excinfo.value.new_url == \"http://localhost/%C3%B6%C3%A4%C3%BC/\"\n\n\ndef test_request_redirect_default():\n    map = r.Map([r.Rule(\"/foo\", defaults={\"bar\": 42}), r.Rule(\"/foo/<int:bar>\")])\n    adapter = map.bind(\"localhost\", \"/\")\n\n    with pytest.raises(r.RequestRedirect) as excinfo:\n        adapter.match(\"/foo/42\")\n    assert excinfo.value.new_url == \"http://localhost/foo\"\n\n\ndef test_request_redirect_default_subdomain():\n    map = r.Map(\n        [\n            r.Rule(\"/foo\", defaults={\"bar\": 42}, subdomain=\"test\"),\n            r.Rule(\"/foo/<int:bar>\", subdomain=\"other\"),\n        ]\n    )\n    adapter = map.bind(\"localhost\", \"/\", subdomain=\"other\")\n\n    with pytest.raises(r.RequestRedirect) as excinfo:\n        adapter.match(\"/foo/42\")\n    assert excinfo.value.new_url == \"http://test.localhost/foo\"\n\n\ndef test_adapter_match_return_rule():\n    rule = r.Rule(\"/foo/\", endpoint=\"foo\")\n    map = r.Map([rule])\n    adapter = map.bind(\"localhost\", \"/\")\n    assert adapter.match(\"/foo/\", return_rule=True) == (rule, {})\n\n\ndef test_server_name_interpolation():\n    server_name = \"example.invalid\"\n    map = r.Map(\n        [r.Rule(\"/\", endpoint=\"index\"), r.Rule(\"/\", endpoint=\"alt\", subdomain=\"alt\")]\n    )\n\n    env = create_environ(\"/\", f\"http://{server_name}/\")\n    adapter = map.bind_to_environ(env, server_name=server_name)\n    assert adapter.match() == (\"index\", {})\n\n    env = create_environ(\"/\", f\"http://alt.{server_name}/\")\n    adapter = map.bind_to_environ(env, server_name=server_name)\n    assert adapter.match() == (\"alt\", {})\n\n    env = create_environ(\"/\", f\"http://{server_name}/\")\n\n    with pytest.warns(UserWarning):\n        adapter = map.bind_to_environ(env, server_name=\"foo\")\n\n    assert adapter.subdomain == \"<invalid>\"\n\n\ndef test_rule_emptying():\n    rule = r.Rule(\"/foo\", {\"meh\": \"muh\"}, \"x\", [\"POST\"], False, \"x\", True, None)\n    rule2 = rule.empty()\n    assert rule.__dict__ == rule2.__dict__\n    rule.methods.add(\"GET\")\n    assert rule.__dict__ != rule2.__dict__\n    rule.methods.discard(\"GET\")\n    rule.defaults[\"meh\"] = \"aha\"\n    assert rule.__dict__ != rule2.__dict__\n\n\ndef test_rule_unhashable():\n    rule = r.Rule(\"/foo\", {\"meh\": \"muh\"}, \"x\", [\"POST\"], False, \"x\", True, None)\n    pytest.raises(TypeError, hash, rule)\n\n\ndef test_rule_templates():\n    testcase = r.RuleTemplate(\n        [\n            r.Submount(\n                \"/test/$app\",\n                [\n                    r.Rule(\"/foo/\", endpoint=\"handle_foo\"),\n                    r.Rule(\"/bar/\", endpoint=\"handle_bar\"),\n                    r.Rule(\"/baz/\", endpoint=\"handle_baz\"),\n                ],\n            ),\n            r.EndpointPrefix(\n                \"${app}\",\n                [\n                    r.Rule(\"/${app}-blah\", endpoint=\"bar\"),\n                    r.Rule(\"/${app}-meh\", endpoint=\"baz\"),\n                ],\n            ),\n            r.Subdomain(\n                \"$app\",\n                [r.Rule(\"/blah\", endpoint=\"x_bar\"), r.Rule(\"/meh\", endpoint=\"x_baz\")],\n            ),\n        ]\n    )\n\n    url_map = r.Map(\n        [\n            testcase(app=\"test1\"),\n            testcase(app=\"test2\"),\n            testcase(app=\"test3\"),\n            testcase(app=\"test4\"),\n        ]\n    )\n\n    out = sorted((x.rule, x.subdomain, x.endpoint) for x in url_map.iter_rules())\n\n    assert out == [\n        (\"/blah\", \"test1\", \"x_bar\"),\n        (\"/blah\", \"test2\", \"x_bar\"),\n        (\"/blah\", \"test3\", \"x_bar\"),\n        (\"/blah\", \"test4\", \"x_bar\"),\n        (\"/meh\", \"test1\", \"x_baz\"),\n        (\"/meh\", \"test2\", \"x_baz\"),\n        (\"/meh\", \"test3\", \"x_baz\"),\n        (\"/meh\", \"test4\", \"x_baz\"),\n        (\"/test/test1/bar/\", \"\", \"handle_bar\"),\n        (\"/test/test1/baz/\", \"\", \"handle_baz\"),\n        (\"/test/test1/foo/\", \"\", \"handle_foo\"),\n        (\"/test/test2/bar/\", \"\", \"handle_bar\"),\n        (\"/test/test2/baz/\", \"\", \"handle_baz\"),\n        (\"/test/test2/foo/\", \"\", \"handle_foo\"),\n        (\"/test/test3/bar/\", \"\", \"handle_bar\"),\n        (\"/test/test3/baz/\", \"\", \"handle_baz\"),\n        (\"/test/test3/foo/\", \"\", \"handle_foo\"),\n        (\"/test/test4/bar/\", \"\", \"handle_bar\"),\n        (\"/test/test4/baz/\", \"\", \"handle_baz\"),\n        (\"/test/test4/foo/\", \"\", \"handle_foo\"),\n        (\"/test1-blah\", \"\", \"test1bar\"),\n        (\"/test1-meh\", \"\", \"test1baz\"),\n        (\"/test2-blah\", \"\", \"test2bar\"),\n        (\"/test2-meh\", \"\", \"test2baz\"),\n        (\"/test3-blah\", \"\", \"test3bar\"),\n        (\"/test3-meh\", \"\", \"test3baz\"),\n        (\"/test4-blah\", \"\", \"test4bar\"),\n        (\"/test4-meh\", \"\", \"test4baz\"),\n    ]\n\n\ndef test_non_string_parts():\n    m = r.Map([r.Rule(\"/<foo>\", endpoint=\"foo\")])\n    a = m.bind(\"example.com\")\n    assert a.build(\"foo\", {\"foo\": 42}) == \"/42\"\n\n\ndef test_complex_routing_rules():\n    m = r.Map(\n        [\n            r.Rule(\"/\", endpoint=\"index\"),\n            r.Rule(\"/<int:blub>\", endpoint=\"an_int\"),\n            r.Rule(\"/<blub>\", endpoint=\"a_string\"),\n            r.Rule(\"/foo/\", endpoint=\"nested\"),\n            r.Rule(\"/foobar/\", endpoint=\"nestedbar\"),\n            r.Rule(\"/foo/<path:testing>/\", endpoint=\"nested_show\"),\n            r.Rule(\"/foo/<path:testing>/edit\", endpoint=\"nested_edit\"),\n            r.Rule(\"/users/\", endpoint=\"users\", defaults={\"page\": 1}),\n            r.Rule(\"/users/page/<int:page>\", endpoint=\"users\"),\n            r.Rule(\"/foox\", endpoint=\"foox\"),\n            r.Rule(\"/<path:bar>/<path:blub>\", endpoint=\"barx_path_path\"),\n        ]\n    )\n    a = m.bind(\"example.com\")\n\n    assert a.match(\"/\") == (\"index\", {})\n    assert a.match(\"/42\") == (\"an_int\", {\"blub\": 42})\n    assert a.match(\"/blub\") == (\"a_string\", {\"blub\": \"blub\"})\n    assert a.match(\"/foo/\") == (\"nested\", {})\n    assert a.match(\"/foobar/\") == (\"nestedbar\", {})\n    assert a.match(\"/foo/1/2/3/\") == (\"nested_show\", {\"testing\": \"1/2/3\"})\n    assert a.match(\"/foo/1/2/3/edit\") == (\"nested_edit\", {\"testing\": \"1/2/3\"})\n    assert a.match(\"/users/\") == (\"users\", {\"page\": 1})\n    assert a.match(\"/users/page/2\") == (\"users\", {\"page\": 2})\n    assert a.match(\"/foox\") == (\"foox\", {})\n    assert a.match(\"/1/2/3\") == (\"barx_path_path\", {\"bar\": \"1\", \"blub\": \"2/3\"})\n\n    assert a.build(\"index\") == \"/\"\n    assert a.build(\"an_int\", {\"blub\": 42}) == \"/42\"\n    assert a.build(\"a_string\", {\"blub\": \"test\"}) == \"/test\"\n    assert a.build(\"nested\") == \"/foo/\"\n    assert a.build(\"nestedbar\") == \"/foobar/\"\n    assert a.build(\"nested_show\", {\"testing\": \"1/2/3\"}) == \"/foo/1/2/3/\"\n    assert a.build(\"nested_edit\", {\"testing\": \"1/2/3\"}) == \"/foo/1/2/3/edit\"\n    assert a.build(\"users\", {\"page\": 1}) == \"/users/\"\n    assert a.build(\"users\", {\"page\": 2}) == \"/users/page/2\"\n    assert a.build(\"foox\") == \"/foox\"\n    assert a.build(\"barx_path_path\", {\"bar\": \"1\", \"blub\": \"2/3\"}) == \"/1/2/3\"\n\n\ndef test_default_converters():\n    class MyMap(r.Map):\n        default_converters = r.Map.default_converters.copy()\n        default_converters[\"foo\"] = r.UnicodeConverter\n\n    assert isinstance(r.Map.default_converters, ImmutableDict)\n    m = MyMap(\n        [\n            r.Rule(\"/a/<foo:a>\", endpoint=\"a\"),\n            r.Rule(\"/b/<foo:b>\", endpoint=\"b\"),\n            r.Rule(\"/c/<c>\", endpoint=\"c\"),\n        ],\n        converters={\"bar\": r.UnicodeConverter},\n    )\n    a = m.bind(\"example.org\", \"/\")\n    assert a.match(\"/a/1\") == (\"a\", {\"a\": \"1\"})\n    assert a.match(\"/b/2\") == (\"b\", {\"b\": \"2\"})\n    assert a.match(\"/c/3\") == (\"c\", {\"c\": \"3\"})\n    assert \"foo\" not in r.Map.default_converters\n\n\ndef test_uuid_converter():\n    m = r.Map([r.Rule(\"/a/<uuid:a_uuid>\", endpoint=\"a\")])\n    a = m.bind(\"example.org\", \"/\")\n    route, kwargs = a.match(\"/a/a8098c1a-f86e-11da-bd1a-00112444be1e\")\n    assert type(kwargs[\"a_uuid\"]) == uuid.UUID  # noqa: E721\n\n\ndef test_converter_with_tuples():\n    \"\"\"\n    Regression test for https://github.com/pallets/werkzeug/issues/709\n    \"\"\"\n\n    class TwoValueConverter(r.BaseConverter):\n        part_isolating = False\n\n        def __init__(self, *args, **kwargs):\n            super().__init__(*args, **kwargs)\n            self.regex = r\"(\\w\\w+)/(\\w\\w+)\"\n\n        def to_python(self, two_values):\n            one, two = two_values.split(\"/\")\n            return one, two\n\n        def to_url(self, values):\n            return f\"{values[0]}/{values[1]}\"\n\n    map = r.Map(\n        [r.Rule(\"/<two:foo>/\", endpoint=\"handler\")],\n        converters={\"two\": TwoValueConverter},\n    )\n    a = map.bind(\"example.org\", \"/\")\n    route, kwargs = a.match(\"/qwert/yuiop/\")\n    assert kwargs[\"foo\"] == (\"qwert\", \"yuiop\")\n\n\ndef test_nested_regex_groups():\n    \"\"\"\n    Regression test for https://github.com/pallets/werkzeug/issues/2590\n    \"\"\"\n\n    class RegexConverter(r.BaseConverter):\n        def __init__(self, url_map, *items):\n            super().__init__(url_map)\n            self.part_isolating = False\n            self.regex = items[0]\n\n    # This is a regex pattern with nested groups\n    DATE_PATTERN = r\"((\\d{8}T\\d{6}([.,]\\d{1,3})?)|(\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}([.,]\\d{1,3})?))Z\"  # noqa: E501\n\n    map = r.Map(\n        [\n            r.Rule(\n                f\"/<regex('{DATE_PATTERN}'):start>/<regex('{DATE_PATTERN}'):end>/\",\n                endpoint=\"handler\",\n            )\n        ],\n        converters={\"regex\": RegexConverter},\n    )\n    a = map.bind(\"example.org\", \"/\")\n    route, kwargs = a.match(\"/2023-02-16T23:36:36.266Z/2023-02-16T23:46:36.266Z/\")\n    assert kwargs[\"start\"] == \"2023-02-16T23:36:36.266Z\"\n    assert kwargs[\"end\"] == \"2023-02-16T23:46:36.266Z\"\n\n\ndef test_anyconverter():\n    m = r.Map(\n        [\n            r.Rule(\"/<any(a1, a2):a>\", endpoint=\"no_dot\"),\n            r.Rule(\"/<any(a.1, a.2):a>\", endpoint=\"yes_dot\"),\n        ]\n    )\n    a = m.bind(\"example.org\", \"/\")\n    assert a.match(\"/a1\") == (\"no_dot\", {\"a\": \"a1\"})\n    assert a.match(\"/a2\") == (\"no_dot\", {\"a\": \"a2\"})\n    assert a.match(\"/a.1\") == (\"yes_dot\", {\"a\": \"a.1\"})\n    assert a.match(\"/a.2\") == (\"yes_dot\", {\"a\": \"a.2\"})\n\n\ndef test_any_converter_build_validates_value() -> None:\n    m = r.Map([r.Rule(\"/<any(patient, provider):value>\", endpoint=\"actor\")])\n    a = m.bind(\"localhost\")\n\n    assert a.build(\"actor\", {\"value\": \"patient\"}) == \"/patient\"\n    assert a.build(\"actor\", {\"value\": \"provider\"}) == \"/provider\"\n\n    with pytest.raises(ValueError) as exc:\n        a.build(\"actor\", {\"value\": \"invalid\"})\n\n    assert str(exc.value) == \"'invalid' is not one of 'patient', 'provider'\"\n\n\ndef test_part_isolating_default() -> None:\n    class TwoConverter(r.BaseConverter):\n        regex = r\"\\w+/\\w+\"\n\n        def to_python(self, value: str) -> t.Any:\n            return value.split(\"/\")\n\n    m = r.Map(\n        [r.Rule(\"/<two:values>/\", endpoint=\"two\")], converters={\"two\": TwoConverter}\n    )\n    a = m.bind(\"localhost\")\n    assert a.match(\"/a/b/\") == (\"two\", {\"values\": [\"a\", \"b\"]})\n\n\n@pytest.mark.parametrize(\n    (\"endpoint\", \"value\", \"expect\"),\n    [\n        (\"int\", 1, \"/1\"),\n        (\"int\", None, r.BuildError),\n        (\"int\", [1], TypeError),\n        (\"list\", [1], \"/1\"),\n        (\"list\", [1, None, 2], \"/1.None.2\"),\n        (\"list\", 1, TypeError),\n    ],\n)\ndef test_build_values_dict(endpoint, value, expect):\n    class ListConverter(r.BaseConverter):\n        def to_url(self, value: t.Any) -> str:\n            return super().to_url(\".\".join(map(str, value)))\n\n    url_map = r.Map(\n        [r.Rule(\"/<int:v>\", endpoint=\"int\"), r.Rule(\"/<list:v>\", endpoint=\"list\")],\n        converters={\"list\": ListConverter},\n    )\n    adapter = url_map.bind(\"localhost\")\n\n    if isinstance(expect, str):\n        assert adapter.build(endpoint, {\"v\": value}) == expect\n    else:\n        with pytest.raises(expect):\n            adapter.build(endpoint, {\"v\": value})\n\n\n@pytest.mark.parametrize(\n    (\"endpoint\", \"value\", \"expect\"),\n    [\n        (\"int\", 1, \"/1\"),\n        (\"int\", [1], \"/1\"),\n        (\"int\", [], r.BuildError),\n        (\"int\", None, TypeError),\n        (\"int\", [None], TypeError),\n        (\"list\", 1, TypeError),\n        (\"list\", [1], TypeError),\n        (\"list\", [[1]], \"/1\"),\n        (\"list\", [1, None, 2], \"/1.None.2\"),\n    ],\n)\ndef test_build_values_multidict(endpoint, value, expect):\n    class ListConverter(r.BaseConverter):\n        def to_url(self, value: t.Any) -> str:\n            return super().to_url(\".\".join(map(str, value)))\n\n    url_map = r.Map(\n        [r.Rule(\"/<int:v>\", endpoint=\"int\"), r.Rule(\"/<list:v>\", endpoint=\"list\")],\n        converters={\"list\": ListConverter},\n    )\n    adapter = url_map.bind(\"localhost\")\n\n    if isinstance(expect, str):\n        assert adapter.build(endpoint, MultiDict({\"v\": value})) == expect\n    else:\n        with pytest.raises(expect):\n            adapter.build(endpoint, MultiDict({\"v\": value}))\n\n\n@pytest.mark.parametrize(\n    (\"value\", \"expect\"),\n    [\n        (None, \"\"),\n        ([None], \"\"),\n        ([None, None], \"\"),\n        (\"\", \"?v=\"),\n        ([\"\"], \"?v=\"),\n        (0, \"?v=0\"),\n        (1.0, \"?v=1.0\"),\n        ([1, 2], \"?v=1&v=2\"),\n        ([1, None, 2], \"?v=1&v=2\"),\n        ([1, \"\", 2], \"?v=1&v=&v=2\"),\n        (\"1+2\", \"?v=1%2B2\"),\n    ],\n)\ndef test_build_append_unknown_dict(value, expect):\n    map = r.Map([r.Rule(\"/\", endpoint=\"a\")])\n    adapter = map.bind(\"localhost\")\n    assert adapter.build(\"a\", {\"v\": value}) == f\"/{expect}\"\n    assert adapter.build(\"a\", {\"v\": value}, append_unknown=False) == \"/\"\n\n\n@pytest.mark.parametrize(\n    (\"value\", \"expect\"),\n    [\n        (None, \"\"),\n        ([None], \"\"),\n        ([None, None], \"\"),\n        (\"\", \"?v=\"),\n        ([\"\"], \"?v=\"),\n        (0, \"?v=0\"),\n        (1.0, \"?v=1.0\"),\n        ([1, 2], \"?v=1&v=2\"),\n        ([1, None, 2], \"?v=1&v=2\"),\n        ([1, \"\", 2], \"?v=1&v=&v=2\"),\n    ],\n)\ndef test_build_append_unknown_multidict(value, expect):\n    map = r.Map([r.Rule(\"/\", endpoint=\"a\")])\n    adapter = map.bind(\"localhost\")\n    assert adapter.build(\"a\", MultiDict({\"v\": value})) == f\"/{expect}\"\n    assert adapter.build(\"a\", MultiDict({\"v\": value}), append_unknown=False) == \"/\"\n\n\ndef test_build_drop_none():\n    map = r.Map([r.Rule(\"/flob/<flub>\", endpoint=\"endp\")])\n    adapter = map.bind(\"\", \"/\")\n    params = {\"flub\": None, \"flop\": None}\n    with pytest.raises(r.BuildError):\n        adapter.build(\"endp\", params)\n    params = {\"flub\": \"x\", \"flop\": None}\n    url = adapter.build(\"endp\", params)\n    assert \"flop\" not in url\n\n\ndef test_method_fallback():\n    map = r.Map(\n        [\n            r.Rule(\"/\", endpoint=\"index\", methods=[\"GET\"]),\n            r.Rule(\"/<name>\", endpoint=\"hello_name\", methods=[\"GET\"]),\n            r.Rule(\"/select\", endpoint=\"hello_select\", methods=[\"POST\"]),\n            r.Rule(\"/search_get\", endpoint=\"search\", methods=[\"GET\"]),\n            r.Rule(\"/search_post\", endpoint=\"search\", methods=[\"POST\"]),\n        ]\n    )\n    adapter = map.bind(\"example.com\")\n    assert adapter.build(\"index\") == \"/\"\n    assert adapter.build(\"index\", method=\"GET\") == \"/\"\n    assert adapter.build(\"hello_name\", {\"name\": \"foo\"}) == \"/foo\"\n    assert adapter.build(\"hello_select\") == \"/select\"\n    assert adapter.build(\"hello_select\", method=\"POST\") == \"/select\"\n    assert adapter.build(\"search\") == \"/search_get\"\n    assert adapter.build(\"search\", method=\"GET\") == \"/search_get\"\n    assert adapter.build(\"search\", method=\"POST\") == \"/search_post\"\n\n\ndef test_implicit_head():\n    url_map = r.Map(\n        [\n            r.Rule(\"/get\", methods=[\"GET\"], endpoint=\"a\"),\n            r.Rule(\"/post\", methods=[\"POST\"], endpoint=\"b\"),\n        ]\n    )\n    adapter = url_map.bind(\"example.org\")\n    assert adapter.match(\"/get\", method=\"HEAD\") == (\"a\", {})\n    pytest.raises(MethodNotAllowed, adapter.match, \"/post\", method=\"HEAD\")\n\n\ndef test_pass_str_as_router_methods():\n    with pytest.raises(TypeError):\n        r.Rule(\"/get\", methods=\"GET\")\n\n\ndef test_protocol_joining_bug():\n    m = r.Map([r.Rule(\"/<foo>\", endpoint=\"x\")])\n    a = m.bind(\"example.org\")\n    assert a.build(\"x\", {\"foo\": \"x:y\"}) == \"/x:y\"\n    assert a.build(\"x\", {\"foo\": \"x:y\"}, force_external=True) == \"http://example.org/x:y\"\n\n\ndef test_allowed_methods_querying():\n    m = r.Map(\n        [r.Rule(\"/<foo>\", methods=[\"GET\", \"HEAD\"]), r.Rule(\"/foo\", methods=[\"POST\"])]\n    )\n    a = m.bind(\"example.org\")\n    assert sorted(a.allowed_methods(\"/foo\")) == [\"GET\", \"HEAD\", \"POST\"]\n\n\ndef test_external_building_with_port():\n    map = r.Map([r.Rule(\"/\", endpoint=\"index\")])\n    adapter = map.bind(\"example.org:5000\", \"/\")\n    built_url = adapter.build(\"index\", {}, force_external=True)\n    assert built_url == \"http://example.org:5000/\", built_url\n\n\ndef test_external_building_with_port_bind_to_environ():\n    map = r.Map([r.Rule(\"/\", endpoint=\"index\")])\n    adapter = map.bind_to_environ(\n        create_environ(\"/\", \"http://example.org:5000/\"), server_name=\"example.org:5000\"\n    )\n    built_url = adapter.build(\"index\", {}, force_external=True)\n    assert built_url == \"http://example.org:5000/\", built_url\n\n\ndef test_external_building_with_port_bind_to_environ_wrong_servername():\n    map = r.Map([r.Rule(\"/\", endpoint=\"index\")])\n    environ = create_environ(\"/\", \"http://example.org:5000/\")\n\n    with pytest.warns(UserWarning):\n        adapter = map.bind_to_environ(environ, server_name=\"example.org\")\n\n    assert adapter.subdomain == \"<invalid>\"\n\n\ndef test_bind_long_idna_name_with_port():\n    map = r.Map([r.Rule(\"/\", endpoint=\"index\")])\n    adapter = map.bind(\"\ud83d\udc0d\" + \"a\" * 52 + \":8443\")\n    name, _, port = adapter.server_name.partition(\":\")\n    assert len(name) == 63\n    assert port == \"8443\"\n\n\ndef test_converter_parser():\n    args, kwargs = r.parse_converter_args(\"test, a=1, b=3.0\")\n\n    assert args == (\"test\",)\n    assert kwargs == {\"a\": 1, \"b\": 3.0}\n\n    args, kwargs = r.parse_converter_args(\"\")\n    assert not args and not kwargs\n\n    args, kwargs = r.parse_converter_args(\"a, b, c,\")\n    assert args == (\"a\", \"b\", \"c\")\n    assert not kwargs\n\n    args, kwargs = r.parse_converter_args(\"True, False, None\")\n    assert args == (True, False, None)\n\n    args, kwargs = r.parse_converter_args('\"foo\", \"bar\"')\n    assert args == (\"foo\", \"bar\")\n\n    with pytest.raises(ValueError):\n        r.parse_converter_args(\"min=0;max=500\")\n\n\ndef test_alias_redirects():\n    m = r.Map(\n        [\n            r.Rule(\"/\", endpoint=\"index\"),\n            r.Rule(\"/index.html\", endpoint=\"index\", alias=True),\n            r.Rule(\"/users/\", defaults={\"page\": 1}, endpoint=\"users\"),\n            r.Rule(\n                \"/users/index.html\", defaults={\"page\": 1}, alias=True, endpoint=\"users\"\n            ),\n            r.Rule(\"/users/page/<int:page>\", endpoint=\"users\"),\n            r.Rule(\"/users/page-<int:page>.html\", alias=True, endpoint=\"users\"),\n        ]\n    )\n    a = m.bind(\"example.com\")\n\n    def ensure_redirect(path, new_url, args=None):\n        with pytest.raises(r.RequestRedirect) as excinfo:\n            a.match(path, query_args=args)\n        assert excinfo.value.new_url == f\"http://example.com{new_url}\"\n\n    ensure_redirect(\"/index.html\", \"/\")\n    ensure_redirect(\"/users/index.html\", \"/users/\")\n    ensure_redirect(\"/users/page-2.html\", \"/users/page/2\")\n    ensure_redirect(\"/users/page-1.html\", \"/users/\")\n    ensure_redirect(\"/users/page-1.html\", \"/users/?foo=bar\", {\"foo\": \"bar\"})\n\n    assert a.build(\"index\") == \"/\"\n    assert a.build(\"users\", {\"page\": 1}) == \"/users/\"\n    assert a.build(\"users\", {\"page\": 2}) == \"/users/page/2\"\n\n\n@pytest.mark.parametrize(\"prefix\", (\"\", \"/aaa\"))\ndef test_double_defaults(prefix):\n    m = r.Map(\n        [\n            r.Rule(f\"{prefix}/\", defaults={\"foo\": 1, \"bar\": False}, endpoint=\"x\"),\n            r.Rule(f\"{prefix}/<int:foo>\", defaults={\"bar\": False}, endpoint=\"x\"),\n            r.Rule(f\"{prefix}/bar/\", defaults={\"foo\": 1, \"bar\": True}, endpoint=\"x\"),\n            r.Rule(f\"{prefix}/bar/<int:foo>\", defaults={\"bar\": True}, endpoint=\"x\"),\n        ]\n    )\n    a = m.bind(\"example.com\")\n\n    assert a.match(f\"{prefix}/\") == (\"x\", {\"foo\": 1, \"bar\": False})\n    assert a.match(f\"{prefix}/2\") == (\"x\", {\"foo\": 2, \"bar\": False})\n    assert a.match(f\"{prefix}/bar/\") == (\"x\", {\"foo\": 1, \"bar\": True})\n    assert a.match(f\"{prefix}/bar/2\") == (\"x\", {\"foo\": 2, \"bar\": True})\n\n    assert a.build(\"x\", {\"foo\": 1, \"bar\": False}) == f\"{prefix}/\"\n    assert a.build(\"x\", {\"foo\": 2, \"bar\": False}) == f\"{prefix}/2\"\n    assert a.build(\"x\", {\"bar\": False}) == f\"{prefix}/\"\n    assert a.build(\"x\", {\"foo\": 1, \"bar\": True}) == f\"{prefix}/bar/\"\n    assert a.build(\"x\", {\"foo\": 2, \"bar\": True}) == f\"{prefix}/bar/2\"\n    assert a.build(\"x\", {\"bar\": True}) == f\"{prefix}/bar/\"\n\n\ndef test_host_matching():\n    m = r.Map(\n        [\n            r.Rule(\"/\", endpoint=\"index\", host=\"www.<domain>\"),\n            r.Rule(\"/\", endpoint=\"files\", host=\"files.<domain>\"),\n            r.Rule(\"/foo/\", defaults={\"page\": 1}, host=\"www.<domain>\", endpoint=\"x\"),\n            r.Rule(\"/<int:page>\", host=\"files.<domain>\", endpoint=\"x\"),\n        ],\n        host_matching=True,\n    )\n\n    a = m.bind(\"www.example.com\")\n    assert a.match(\"/\") == (\"index\", {\"domain\": \"example.com\"})\n    assert a.match(\"/foo/\") == (\"x\", {\"domain\": \"example.com\", \"page\": 1})\n\n    with pytest.raises(r.RequestRedirect) as excinfo:\n        a.match(\"/foo\")\n    assert excinfo.value.new_url == \"http://www.example.com/foo/\"\n\n    a = m.bind(\"files.example.com\")\n    assert a.match(\"/\") == (\"files\", {\"domain\": \"example.com\"})\n    assert a.match(\"/2\") == (\"x\", {\"domain\": \"example.com\", \"page\": 2})\n\n    with pytest.raises(r.RequestRedirect) as excinfo:\n        a.match(\"/1\")\n    assert excinfo.value.new_url == \"http://www.example.com/foo/\"\n\n\ndef test_host_matching_building():\n    m = r.Map(\n        [\n            r.Rule(\"/\", endpoint=\"index\", host=\"www.domain.com\"),\n            r.Rule(\"/\", endpoint=\"foo\", host=\"my.domain.com\"),\n        ],\n        host_matching=True,\n    )\n\n    www = m.bind(\"www.domain.com\")\n    assert www.match(\"/\") == (\"index\", {})\n    assert www.build(\"index\") == \"/\"\n    assert www.build(\"foo\") == \"http://my.domain.com/\"\n\n    my = m.bind(\"my.domain.com\")\n    assert my.match(\"/\") == (\"foo\", {})\n    assert my.build(\"foo\") == \"/\"\n    assert my.build(\"index\") == \"http://www.domain.com/\"\n\n\ndef test_server_name_casing():\n    m = r.Map([r.Rule(\"/\", endpoint=\"index\", subdomain=\"foo\")])\n\n    env = create_environ()\n    env[\"SERVER_NAME\"] = env[\"HTTP_HOST\"] = \"FOO.EXAMPLE.COM\"\n    a = m.bind_to_environ(env, server_name=\"example.com\")\n    assert a.match(\"/\") == (\"index\", {})\n\n    env = create_environ()\n    env[\"SERVER_NAME\"] = \"127.0.0.1\"\n    env[\"SERVER_PORT\"] = \"5000\"\n    del env[\"HTTP_HOST\"]\n\n    with pytest.warns(UserWarning):\n        a = m.bind_to_environ(env, server_name=\"example.com\")\n\n    with pytest.raises(NotFound):\n        a.match()\n\n\ndef test_redirect_request_exception_code():\n    exc = r.RequestRedirect(\"http://www.google.com/\")\n    exc.code = 307\n    env = create_environ()\n    assert exc.get_response(env).status_code == exc.code\n\n\ndef test_redirect_path_quoting():\n    url_map = r.Map(\n        [\n            r.Rule(\"/<category>\", defaults={\"page\": 1}, endpoint=\"category\"),\n            r.Rule(\"/<category>/page/<int:page>\", endpoint=\"category\"),\n        ]\n    )\n    adapter = url_map.bind(\"example.com\")\n\n    with pytest.raises(r.RequestRedirect) as excinfo:\n        adapter.match(\"/foo bar/page/1\")\n    response = excinfo.value.get_response({})\n    assert response.headers[\"location\"] == \"http://example.com/foo%20bar\"\n\n\ndef test_unicode_rules():\n    m = r.Map(\n        [r.Rule(\"/\u0432\u043e\u0439\u0442\u0438/\", endpoint=\"enter\"), r.Rule(\"/foo+bar/\", endpoint=\"foobar\")]\n    )\n    a = m.bind(\"\u2603.example.com\")\n    with pytest.raises(r.RequestRedirect) as excinfo:\n        a.match(\"/\u0432\u043e\u0439\u0442\u0438\")\n    assert (\n        excinfo.value.new_url\n        == \"http://xn--n3h.example.com/%D0%B2%D0%BE%D0%B9%D1%82%D0%B8/\"\n    )\n\n    endpoint, values = a.match(\"/\u0432\u043e\u0439\u0442\u0438/\")\n    assert endpoint == \"enter\"\n    assert values == {}\n\n    with pytest.raises(r.RequestRedirect) as excinfo:\n        a.match(\"/foo+bar\")\n    assert excinfo.value.new_url == \"http://xn--n3h.example.com/foo+bar/\"\n\n    endpoint, values = a.match(\"/foo+bar/\")\n    assert endpoint == \"foobar\"\n    assert values == {}\n\n    url = a.build(\"enter\", {}, force_external=True)\n    assert url == \"http://xn--n3h.example.com/%D0%B2%D0%BE%D0%B9%D1%82%D0%B8/\"\n\n    url = a.build(\"foobar\", {}, force_external=True)\n    assert url == \"http://xn--n3h.example.com/foo+bar/\"\n\n\ndef test_empty_path_info():\n    m = r.Map([r.Rule(\"/\", endpoint=\"index\")])\n\n    b = m.bind(\"example.com\", script_name=\"/approot\")\n    with pytest.raises(r.RequestRedirect) as excinfo:\n        b.match(\"\")\n    assert excinfo.value.new_url == \"http://example.com/approot/\"\n\n    a = m.bind(\"example.com\")\n    with pytest.raises(r.RequestRedirect) as excinfo:\n        a.match(\"\")\n    assert excinfo.value.new_url == \"http://example.com/\"\n\n\ndef test_both_bind_and_match_path_info_are_none():\n    m = r.Map([r.Rule(\"/\", endpoint=\"index\")])\n    ma = m.bind(\"example.org\")\n    assert ma.match() == (\"index\", {})\n\n\ndef test_map_repr():\n    m = r.Map([r.Rule(\"/wat\", endpoint=\"enter\"), r.Rule(\"/woop\", endpoint=\"foobar\")])\n    rv = repr(m)\n    assert rv == \"Map([<Rule '/wat' -> enter>, <Rule '/woop' -> foobar>])\"\n\n\ndef test_empty_subclass_rules_with_custom_kwargs():\n    class CustomRule(r.Rule):\n        def __init__(self, string=None, custom=None, *args, **kwargs):\n            self.custom = custom\n            super().__init__(string, *args, **kwargs)\n\n    rule1 = CustomRule(\"/foo\", endpoint=\"bar\")\n    try:\n        rule2 = rule1.empty()\n        assert rule1.rule == rule2.rule\n    except TypeError as e:  # raised without fix in PR #675\n        raise e\n\n\ndef test_finding_closest_match_by_endpoint():\n    m = r.Map(\n        [\n            r.Rule(\"/foo/\", endpoint=\"users.here\"),\n            r.Rule(\"/wat/\", endpoint=\"admin.users\"),\n            r.Rule(\"/woop\", endpoint=\"foo.users\"),\n        ]\n    )\n    adapter = m.bind(\"example.com\")\n    assert (\n        r.BuildError(\"admin.user\", None, None, adapter).suggested.endpoint\n        == \"admin.users\"\n    )\n\n\ndef test_finding_closest_match_by_values():\n    rule_id = r.Rule(\"/user/id/<id>/\", endpoint=\"users\")\n    rule_slug = r.Rule(\"/user/<slug>/\", endpoint=\"users\")\n    rule_random = r.Rule(\"/user/emails/<email>/\", endpoint=\"users\")\n    m = r.Map([rule_id, rule_slug, rule_random])\n    adapter = m.bind(\"example.com\")\n    assert r.BuildError(\"x\", {\"slug\": \"\"}, None, adapter).suggested == rule_slug\n\n\ndef test_finding_closest_match_by_method():\n    post = r.Rule(\"/post/\", endpoint=\"foobar\", methods=[\"POST\"])\n    get = r.Rule(\"/get/\", endpoint=\"foobar\", methods=[\"GET\"])\n    put = r.Rule(\"/put/\", endpoint=\"foobar\", methods=[\"PUT\"])\n    m = r.Map([post, get, put])\n    adapter = m.bind(\"example.com\")\n    assert r.BuildError(\"invalid\", {}, \"POST\", adapter).suggested == post\n    assert r.BuildError(\"invalid\", {}, \"GET\", adapter).suggested == get\n    assert r.BuildError(\"invalid\", {}, \"PUT\", adapter).suggested == put\n\n\ndef test_finding_closest_match_when_none_exist():\n    m = r.Map([])\n    assert not r.BuildError(\"invalid\", {}, None, m.bind(\"test.com\")).suggested\n\n\ndef test_error_message_without_suggested_rule():\n    m = r.Map([r.Rule(\"/foo/\", endpoint=\"world\", methods=[\"GET\"])])\n    adapter = m.bind(\"example.com\")\n\n    with pytest.raises(r.BuildError) as excinfo:\n        adapter.build(\"urks\")\n    assert str(excinfo.value).startswith(\"Could not build url for endpoint 'urks'.\")\n\n    with pytest.raises(r.BuildError) as excinfo:\n        adapter.build(\"world\", method=\"POST\")\n    assert str(excinfo.value).startswith(\n        \"Could not build url for endpoint 'world' ('POST').\"\n    )\n\n    with pytest.raises(r.BuildError) as excinfo:\n        adapter.build(\"urks\", values={\"user_id\": 5})\n    assert str(excinfo.value).startswith(\n        \"Could not build url for endpoint 'urks' with values ['user_id'].\"\n    )\n\n\ndef test_error_message_suggestion():\n    m = r.Map([r.Rule(\"/foo/<id>/\", endpoint=\"world\", methods=[\"GET\"])])\n    adapter = m.bind(\"example.com\")\n\n    with pytest.raises(r.BuildError) as excinfo:\n        adapter.build(\"helloworld\")\n    assert \"Did you mean 'world' instead?\" in str(excinfo.value)\n\n    with pytest.raises(r.BuildError) as excinfo:\n        adapter.build(\"world\")\n    assert \"Did you forget to specify values ['id']?\" in str(excinfo.value)\n    assert \"Did you mean to use methods\" not in str(excinfo.value)\n\n    with pytest.raises(r.BuildError) as excinfo:\n        adapter.build(\"world\", {\"id\": 2}, method=\"POST\")\n    assert \"Did you mean to use methods ['GET', 'HEAD']?\" in str(excinfo.value)\n\n\ndef test_no_memory_leak_from_Rule_builder():\n    \"\"\"See #1520\"\"\"\n\n    # generate a bunch of objects that *should* get collected\n    for _ in range(100):\n        r.Map([r.Rule(\"/a/<string:b>\")])\n\n    # ensure that the garbage collection has had a chance to collect cyclic\n    # objects\n    for _ in range(5):\n        gc.collect()\n\n    # assert they got collected!\n    count = sum(1 for obj in gc.get_objects() if isinstance(obj, r.Rule))\n    assert count == 0\n\n\ndef test_build_url_with_arg_self():\n    map = r.Map([r.Rule(\"/foo/<string:self>\", endpoint=\"foo\")])\n    adapter = map.bind(\"example.org\", \"/\", subdomain=\"blah\")\n\n    ret = adapter.build(\"foo\", {\"self\": \"bar\"})\n    assert ret == \"http://example.org/foo/bar\"\n\n\ndef test_build_url_with_arg_keyword():\n    map = r.Map([r.Rule(\"/foo/<string:class>\", endpoint=\"foo\")])\n    adapter = map.bind(\"example.org\", \"/\", subdomain=\"blah\")\n\n    ret = adapter.build(\"foo\", {\"class\": \"bar\"})\n    assert ret == \"http://example.org/foo/bar\"\n\n\ndef test_build_url_same_endpoint_multiple_hosts():\n    m = r.Map(\n        [\n            r.Rule(\"/\", endpoint=\"index\", host=\"alpha.example.com\"),\n            r.Rule(\"/\", endpoint=\"index\", host=\"beta.example.com\"),\n            r.Rule(\"/\", endpoint=\"gamma\", host=\"gamma.example.com\"),\n        ],\n        host_matching=True,\n    )\n\n    alpha = m.bind(\"alpha.example.com\")\n    assert alpha.build(\"index\") == \"/\"\n    assert alpha.build(\"gamma\") == \"http://gamma.example.com/\"\n\n    alpha_case = m.bind(\"AlPhA.ExAmPlE.CoM\")\n    assert alpha_case.build(\"index\") == \"/\"\n    assert alpha_case.build(\"gamma\") == \"http://gamma.example.com/\"\n\n    beta = m.bind(\"beta.example.com\")\n    assert beta.build(\"index\") == \"/\"\n\n    beta_case = m.bind(\"BeTa.ExAmPlE.CoM\")\n    assert beta_case.build(\"index\") == \"/\"\n\n\ndef test_rule_websocket_methods():\n    with pytest.raises(ValueError):\n        r.Rule(\"/ws\", endpoint=\"ws\", websocket=True, methods=[\"post\"])\n    with pytest.raises(ValueError):\n        r.Rule(\n            \"/ws\",\n            endpoint=\"ws\",\n            websocket=True,\n            methods=[\"get\", \"head\", \"options\", \"post\"],\n        )\n    r.Rule(\"/ws\", endpoint=\"ws\", websocket=True, methods=[\"get\", \"head\", \"options\"])\n\n\ndef test_path_weighting():\n    m = r.Map(\n        [\n            r.Rule(\"/<path:path>/c\", endpoint=\"simple\"),\n            r.Rule(\"/<path:path>/<a>/<b>\", endpoint=\"complex\"),\n        ]\n    )\n    a = m.bind(\"localhost\", path_info=\"/a/b/c\")\n\n    assert a.match() == (\"simple\", {\"path\": \"a/b\"})\n\n\ndef test_newline_match():\n    m = r.Map([r.Rule(\"/hello\", endpoint=\"hello\")])\n    a = m.bind(\"localhost\")\n\n    with pytest.raises(NotFound):\n        a.match(\"/hello\\n\")\n\n\ndef test_weighting():\n    m = r.Map(\n        [\n            r.Rule(\"/<int:value>\", endpoint=\"int\"),\n            r.Rule(\"/<uuid:value>\", endpoint=\"uuid\"),\n        ]\n    )\n    a = m.bind(\"localhost\")\n\n    assert a.match(\"/2b5b0911-fdcf-4dd2-921b-28ace88db8a0\") == (\n        \"uuid\",\n        {\"value\": uuid.UUID(\"2b5b0911-fdcf-4dd2-921b-28ace88db8a0\")},\n    )\n\n\ndef test_strict_slashes_false():\n    map = r.Map(\n        [\n            r.Rule(\"/path1\", endpoint=\"leaf_path\", strict_slashes=False),\n            r.Rule(\"/path2/\", endpoint=\"branch_path\", strict_slashes=False),\n            r.Rule(\n                \"/<path:path>\", endpoint=\"leaf_path_converter\", strict_slashes=False\n            ),\n        ],\n    )\n\n    adapter = map.bind(\"example.org\", \"/\")\n\n    assert adapter.match(\"/path1\", method=\"GET\") == (\"leaf_path\", {})\n    assert adapter.match(\"/path1/\", method=\"GET\") == (\"leaf_path\", {})\n    assert adapter.match(\"/path2\", method=\"GET\") == (\"branch_path\", {})\n    assert adapter.match(\"/path2/\", method=\"GET\") == (\"branch_path\", {})\n    assert adapter.match(\"/any\", method=\"GET\") == (\n        \"leaf_path_converter\",\n        {\"path\": \"any\"},\n    )\n    assert adapter.match(\"/any/\", method=\"GET\") == (\n        \"leaf_path_converter\",\n        {\"path\": \"any/\"},\n    )\n\n\ndef test_invalid_rule():\n    with pytest.raises(ValueError):\n        r.Map([r.Rule(\"/<int()>\", endpoint=\"test\")])\n\n\ndef test_multiple_converters_per_part():\n    map_ = r.Map(\n        [\n            r.Rule(\"/v<int:major>.<int:minor>\", endpoint=\"version\"),\n        ],\n    )\n    adapter = map_.bind(\"localhost\")\n    assert adapter.match(\"/v1.2\") == (\"version\", {\"major\": 1, \"minor\": 2})\n\n\ndef test_static_regex_escape():\n    map_ = r.Map(\n        [\n            r.Rule(\"/.<int:value>\", endpoint=\"dotted\"),\n        ],\n    )\n    adapter = map_.bind(\"localhost\")\n    assert adapter.match(\"/.2\") == (\"dotted\", {\"value\": 2})\n    with pytest.raises(NotFound):\n        adapter.match(\"/a2\")\n\n\nclass RegexConverter(r.BaseConverter):\n    def __init__(self, url_map, *items):\n        super().__init__(url_map)\n        self.regex = items[0]\n\n\ndef test_regex():\n    map_ = r.Map(\n        [\n            r.Rule(r\"/<regex('[^/:]+\\.[^/:]+'):value>\", endpoint=\"regex\"),\n        ],\n        converters={\"regex\": RegexConverter},\n    )\n    adapter = map_.bind(\"localhost\")\n    assert adapter.match(\"/asdfsa.asdfs\") == (\"regex\", {\"value\": \"asdfsa.asdfs\"})\n", "tests/test_security.py": "import os\nimport posixpath\nimport sys\n\nimport pytest\n\nfrom werkzeug.security import check_password_hash\nfrom werkzeug.security import generate_password_hash\nfrom werkzeug.security import safe_join\n\n\ndef test_default_password_method():\n    value = generate_password_hash(\"secret\")\n    assert value.startswith(\"scrypt:\")\n\n\n@pytest.mark.xfail(\n    sys.implementation.name == \"pypy\", reason=\"scrypt unavailable on pypy\"\n)\ndef test_scrypt():\n    value = generate_password_hash(\"secret\", method=\"scrypt\")\n    assert check_password_hash(value, \"secret\")\n    assert value.startswith(\"scrypt:32768:8:1$\")\n\n\ndef test_pbkdf2():\n    value = generate_password_hash(\"secret\", method=\"pbkdf2\")\n    assert check_password_hash(value, \"secret\")\n    assert value.startswith(\"pbkdf2:sha256:600000$\")\n\n\ndef test_salted_hashes():\n    hash1 = generate_password_hash(\"secret\")\n    hash2 = generate_password_hash(\"secret\")\n    assert hash1 != hash2\n    assert check_password_hash(hash1, \"secret\")\n    assert check_password_hash(hash2, \"secret\")\n\n\ndef test_require_salt():\n    with pytest.raises(ValueError):\n        generate_password_hash(\"secret\", salt_length=0)\n\n\ndef test_invalid_method():\n    with pytest.raises(ValueError, match=\"Invalid hash method\"):\n        generate_password_hash(\"secret\", \"sha256\")\n\n\ndef test_safe_join():\n    assert safe_join(\"foo\", \"bar/baz\") == posixpath.join(\"foo\", \"bar/baz\")\n    assert safe_join(\"foo\", \"../bar/baz\") is None\n    if os.name == \"nt\":\n        assert safe_join(\"foo\", \"foo\\\\bar\") is None\n\n\ndef test_safe_join_os_sep():\n    import werkzeug.security as sec\n\n    prev_value = sec._os_alt_seps\n    sec._os_alt_seps = \"*\"\n    assert safe_join(\"foo\", \"bar/baz*\") is None\n    sec._os_alt_steps = prev_value\n\n\ndef test_safe_join_empty_trusted():\n    assert safe_join(\"\", \"c:test.txt\") == \"./c:test.txt\"\n", "tests/test_test.py": "import json\nimport sys\nfrom functools import partial\nfrom io import BytesIO\n\nimport pytest\n\nfrom werkzeug.datastructures import Authorization\nfrom werkzeug.datastructures import FileStorage\nfrom werkzeug.datastructures import Headers\nfrom werkzeug.datastructures import MultiDict\nfrom werkzeug.formparser import parse_form_data\nfrom werkzeug.test import Client\nfrom werkzeug.test import ClientRedirectError\nfrom werkzeug.test import create_environ\nfrom werkzeug.test import EnvironBuilder\nfrom werkzeug.test import run_wsgi_app\nfrom werkzeug.test import stream_encode_multipart\nfrom werkzeug.test import TestResponse\nfrom werkzeug.utils import redirect\nfrom werkzeug.wrappers import Request\nfrom werkzeug.wrappers import Response\n\n\ndef cookie_app(environ, start_response):\n    \"\"\"A WSGI application which sets a cookie, and returns as a response any\n    cookie which exists.\n    \"\"\"\n    response = Response(environ.get(\"HTTP_COOKIE\", \"No Cookie\"), mimetype=\"text/plain\")\n    response.set_cookie(\"test\", \"test\")\n    return response(environ, start_response)\n\n\ndef redirect_loop_app(environ, start_response):\n    response = redirect(\"http://localhost/some/redirect/\")\n    return response(environ, start_response)\n\n\ndef redirect_with_get_app(environ, start_response):\n    req = Request(environ)\n    if req.url not in (\n        \"http://localhost/\",\n        \"http://localhost/first/request\",\n        \"http://localhost/some/redirect/\",\n    ):\n        raise AssertionError(f'redirect_demo_app() did not expect URL \"{req.url}\"')\n    if \"/some/redirect\" not in req.url:\n        response = redirect(\"http://localhost/some/redirect/\")\n    else:\n        response = Response(f\"current url: {req.url}\")\n    return response(environ, start_response)\n\n\ndef external_redirect_demo_app(environ, start_response):\n    response = redirect(\"http://example.com/\")\n    return response(environ, start_response)\n\n\ndef external_subdomain_redirect_demo_app(environ, start_response):\n    if \"test.example.com\" in environ[\"HTTP_HOST\"]:\n        response = Response(\"redirected successfully to subdomain\")\n    else:\n        response = redirect(\"http://test.example.com/login\")\n    return response(environ, start_response)\n\n\ndef multi_value_post_app(environ, start_response):\n    req = Request(environ)\n    assert req.form[\"field\"] == \"val1\", req.form[\"field\"]\n    assert req.form.getlist(\"field\") == [\"val1\", \"val2\"], req.form.getlist(\"field\")\n    response = Response(\"ok\")\n    return response(environ, start_response)\n\n\ndef test_cookie_forging():\n    c = Client(cookie_app)\n    c.set_cookie(\"foo\", \"bar\")\n    response = c.open()\n    assert response.text == \"foo=bar\"\n\n\ndef test_set_cookie_app():\n    c = Client(cookie_app)\n    response = c.open()\n    assert \"Set-Cookie\" in response.headers\n\n\ndef test_cookiejar_stores_cookie():\n    c = Client(cookie_app)\n    c.open()\n    assert c.get_cookie(\"test\") is not None\n\n\ndef test_no_initial_cookie():\n    c = Client(cookie_app)\n    response = c.open()\n    assert response.text == \"No Cookie\"\n\n\ndef test_resent_cookie():\n    c = Client(cookie_app)\n    c.open()\n    response = c.open()\n    assert response.text == \"test=test\"\n\n\ndef test_disable_cookies():\n    c = Client(cookie_app, use_cookies=False)\n    c.open()\n    response = c.open()\n    assert response.text == \"No Cookie\"\n\n\ndef test_cookie_for_different_path():\n    c = Client(cookie_app)\n    c.open(\"/path1\")\n    response = c.open(\"/path2\")\n    assert response.text == \"test=test\"\n\n\ndef test_cookie_default_path() -> None:\n    \"\"\"When no path is set for a cookie, the default uses everything up to but not\n    including the first slash.\n    \"\"\"\n\n    @Request.application\n    def app(request: Request) -> Response:\n        r = Response()\n        r.set_cookie(\"k\", \"v\", path=None)\n        return r\n\n    c = Client(app)\n    c.get(\"/nested/leaf\")\n    assert c.get_cookie(\"k\") is None\n    assert c.get_cookie(\"k\", path=\"/nested\") is not None\n    c.get(\"/nested/dir/\")\n    assert c.get_cookie(\"k\", path=\"/nested/dir\") is not None\n\n\ndef test_environ_builder_basics():\n    b = EnvironBuilder()\n    assert b.content_type is None\n    b.method = \"POST\"\n    assert b.content_type is None\n    b.form[\"test\"] = \"normal value\"\n    assert b.content_type == \"application/x-www-form-urlencoded\"\n    b.files.add_file(\"test\", BytesIO(b\"test contents\"), \"test.txt\")\n    assert b.files[\"test\"].content_type == \"text/plain\"\n    b.form[\"test_int\"] = 1\n    assert b.content_type == \"multipart/form-data\"\n\n    req = b.get_request()\n    b.close()\n\n    assert req.url == \"http://localhost/\"\n    assert req.method == \"POST\"\n    assert req.form[\"test\"] == \"normal value\"\n    assert req.files[\"test\"].content_type == \"text/plain\"\n    assert req.files[\"test\"].filename == \"test.txt\"\n    assert req.files[\"test\"].read() == b\"test contents\"\n    req.close()\n\n\ndef test_environ_builder_data():\n    b = EnvironBuilder(data=\"foo\")\n    assert b.input_stream.getvalue() == b\"foo\"\n    b = EnvironBuilder(data=b\"foo\")\n    assert b.input_stream.getvalue() == b\"foo\"\n\n    b = EnvironBuilder(data={\"foo\": \"bar\"})\n    assert b.form[\"foo\"] == \"bar\"\n    b = EnvironBuilder(data={\"foo\": [\"bar1\", \"bar2\"]})\n    assert b.form.getlist(\"foo\") == [\"bar1\", \"bar2\"]\n\n    def check_list_content(b, length):\n        foo = b.files.getlist(\"foo\")\n        assert len(foo) == length\n        for obj in foo:\n            assert isinstance(obj, FileStorage)\n\n    b = EnvironBuilder(data={\"foo\": BytesIO()})\n    check_list_content(b, 1)\n    b = EnvironBuilder(data={\"foo\": [BytesIO(), BytesIO()]})\n    check_list_content(b, 2)\n\n    b = EnvironBuilder(data={\"foo\": (BytesIO(),)})\n    check_list_content(b, 1)\n    b = EnvironBuilder(data={\"foo\": [(BytesIO(),), (BytesIO(),)]})\n    check_list_content(b, 2)\n\n\ndef test_environ_builder_json():\n    @Request.application\n    def app(request):\n        assert request.content_type == \"application/json\"\n        return Response(json.loads(request.get_data(as_text=True))[\"foo\"])\n\n    c = Client(app)\n    response = c.post(\"/\", json={\"foo\": \"bar\"})\n    assert response.text == \"bar\"\n\n    with pytest.raises(TypeError):\n        c.post(\"/\", json={\"foo\": \"bar\"}, data={\"baz\": \"qux\"})\n\n\ndef test_environ_builder_headers():\n    b = EnvironBuilder(\n        environ_base={\"HTTP_USER_AGENT\": \"Foo/0.1\"},\n        environ_overrides={\"wsgi.version\": (1, 1)},\n    )\n    b.headers[\"X-Beat-My-Horse\"] = \"very well sir\"\n    env = b.get_environ()\n    assert env[\"HTTP_USER_AGENT\"] == \"Foo/0.1\"\n    assert env[\"HTTP_X_BEAT_MY_HORSE\"] == \"very well sir\"\n    assert env[\"wsgi.version\"] == (1, 1)\n\n    b.headers[\"User-Agent\"] = \"Bar/1.0\"\n    env = b.get_environ()\n    assert env[\"HTTP_USER_AGENT\"] == \"Bar/1.0\"\n\n\ndef test_environ_builder_headers_content_type():\n    b = EnvironBuilder(headers={\"Content-Type\": \"text/plain\"})\n    env = b.get_environ()\n    assert env[\"CONTENT_TYPE\"] == \"text/plain\"\n    assert \"HTTP_CONTENT_TYPE\" not in env\n    b = EnvironBuilder(content_type=\"text/html\", headers={\"Content-Type\": \"text/plain\"})\n    env = b.get_environ()\n    assert env[\"CONTENT_TYPE\"] == \"text/html\"\n    assert \"HTTP_CONTENT_TYPE\" not in env\n    b = EnvironBuilder()\n    env = b.get_environ()\n    assert \"CONTENT_TYPE\" not in env\n    assert \"HTTP_CONTENT_TYPE\" not in env\n\n\ndef test_envrion_builder_multiple_headers():\n    h = Headers()\n    h.add(\"FOO\", \"bar\")\n    h.add(\"FOO\", \"baz\")\n    b = EnvironBuilder(headers=h)\n    env = b.get_environ()\n    assert env[\"HTTP_FOO\"] == \"bar, baz\"\n\n\ndef test_environ_builder_paths():\n    b = EnvironBuilder(path=\"/foo\", base_url=\"http://example.com/\")\n    assert b.base_url == \"http://example.com/\"\n    assert b.path == \"/foo\"\n    assert b.script_root == \"\"\n    assert b.host == \"example.com\"\n\n    b = EnvironBuilder(path=\"/foo\", base_url=\"http://example.com/bar\")\n    assert b.base_url == \"http://example.com/bar/\"\n    assert b.path == \"/foo\"\n    assert b.script_root == \"/bar\"\n    assert b.host == \"example.com\"\n\n    b.host = \"localhost\"\n    assert b.base_url == \"http://localhost/bar/\"\n    b.base_url = \"http://localhost:8080/\"\n    assert b.host == \"localhost:8080\"\n    assert b.server_name == \"localhost\"\n    assert b.server_port == 8080\n\n    b.host = \"foo.invalid\"\n    b.url_scheme = \"https\"\n    b.script_root = \"/test\"\n    env = b.get_environ()\n    assert env[\"SERVER_NAME\"] == \"foo.invalid\"\n    assert env[\"SERVER_PORT\"] == \"443\"\n    assert env[\"SCRIPT_NAME\"] == \"/test\"\n    assert env[\"PATH_INFO\"] == \"/foo\"\n    assert env[\"HTTP_HOST\"] == \"foo.invalid\"\n    assert env[\"wsgi.url_scheme\"] == \"https\"\n    assert b.base_url == \"https://foo.invalid/test/\"\n\n\ndef test_environ_builder_content_type():\n    builder = EnvironBuilder()\n    assert builder.content_type is None\n    builder.method = \"POST\"\n    assert builder.content_type is None\n    builder.method = \"PUT\"\n    assert builder.content_type is None\n    builder.method = \"PATCH\"\n    assert builder.content_type is None\n    builder.method = \"DELETE\"\n    assert builder.content_type is None\n    builder.method = \"GET\"\n    assert builder.content_type is None\n    builder.form[\"foo\"] = \"bar\"\n    assert builder.content_type == \"application/x-www-form-urlencoded\"\n    builder.files.add_file(\"data\", BytesIO(b\"foo\"), \"test.txt\")\n    assert builder.content_type == \"multipart/form-data\"\n    req = builder.get_request()\n    builder.close()\n    assert req.form[\"foo\"] == \"bar\"\n    assert req.files[\"data\"].read() == b\"foo\"\n    req.close()\n\n\ndef test_basic_auth():\n    builder = EnvironBuilder(auth=(\"username\", \"password\"))\n    request = builder.get_request()\n    assert request.authorization.username == \"username\"\n    assert request.authorization.password == \"password\"\n\n\ndef test_auth_object():\n    builder = EnvironBuilder(\n        auth=Authorization(\"digest\", {\"username\": \"u\", \"password\": \"p\"})\n    )\n    request = builder.get_request()\n    assert request.headers[\"Authorization\"].startswith(\"Digest \")\n\n\ndef test_environ_builder_stream_switch():\n    d = MultiDict(dict(foo=\"bar\", blub=\"blah\", hu=\"hum\"))\n    for use_tempfile in False, True:\n        stream, length, boundary = stream_encode_multipart(\n            d, use_tempfile, threshold=150\n        )\n        assert isinstance(stream, BytesIO) != use_tempfile\n\n        form = parse_form_data(\n            {\n                \"wsgi.input\": stream,\n                \"CONTENT_LENGTH\": str(length),\n                \"CONTENT_TYPE\": f'multipart/form-data; boundary=\"{boundary}\"',\n            }\n        )[1]\n        assert form == d\n        stream.close()\n\n\ndef test_environ_builder_unicode_file_mix():\n    for use_tempfile in False, True:\n        f = FileStorage(BytesIO(rb\"\\N{SNOWMAN}\"), \"snowman.txt\")\n        d = MultiDict(dict(f=f, s=\"\\N{SNOWMAN}\"))\n        stream, length, boundary = stream_encode_multipart(\n            d, use_tempfile, threshold=150\n        )\n        assert isinstance(stream, BytesIO) != use_tempfile\n\n        _, form, files = parse_form_data(\n            {\n                \"wsgi.input\": stream,\n                \"CONTENT_LENGTH\": str(length),\n                \"CONTENT_TYPE\": f'multipart/form-data; boundary=\"{boundary}\"',\n            }\n        )\n        assert form[\"s\"] == \"\\N{SNOWMAN}\"\n        assert files[\"f\"].name == \"f\"\n        assert files[\"f\"].filename == \"snowman.txt\"\n        assert files[\"f\"].read() == rb\"\\N{SNOWMAN}\"\n        stream.close()\n        files[\"f\"].close()\n\n\ndef test_environ_builder_empty_file():\n    f = FileStorage(BytesIO(rb\"\"), \"empty.txt\")\n    d = MultiDict(dict(f=f, s=\"\"))\n    stream, length, boundary = stream_encode_multipart(d)\n    _, form, files = parse_form_data(\n        {\n            \"wsgi.input\": stream,\n            \"CONTENT_LENGTH\": str(length),\n            \"CONTENT_TYPE\": f'multipart/form-data; boundary=\"{boundary}\"',\n        }\n    )\n    assert form[\"s\"] == \"\"\n    assert files[\"f\"].read() == rb\"\"\n    stream.close()\n    files[\"f\"].close()\n\n\ndef test_create_environ():\n    env = create_environ(\"/foo?bar=baz\", \"http://example.org/\")\n    expected = {\n        \"wsgi.multiprocess\": False,\n        \"wsgi.version\": (1, 0),\n        \"wsgi.run_once\": False,\n        \"wsgi.errors\": sys.stderr,\n        \"wsgi.multithread\": False,\n        \"wsgi.url_scheme\": \"http\",\n        \"SCRIPT_NAME\": \"\",\n        \"SERVER_NAME\": \"example.org\",\n        \"REQUEST_METHOD\": \"GET\",\n        \"HTTP_HOST\": \"example.org\",\n        \"PATH_INFO\": \"/foo\",\n        \"SERVER_PORT\": \"80\",\n        \"SERVER_PROTOCOL\": \"HTTP/1.1\",\n        \"QUERY_STRING\": \"bar=baz\",\n    }\n    for key, value in iter(expected.items()):\n        assert env[key] == value\n    assert env[\"wsgi.input\"].read(0) == b\"\"\n    assert create_environ(\"/foo\", \"http://example.com/\")[\"SCRIPT_NAME\"] == \"\"\n\n\ndef test_create_environ_query_string_error():\n    with pytest.raises(ValueError):\n        create_environ(\"/foo?bar=baz\", query_string={\"a\": \"b\"})\n\n\ndef test_builder_from_environ():\n    environ = create_environ(\n        \"/\u3131\",\n        base_url=\"https://example.com/base\",\n        query_string={\"name\": \"Werkzeug\"},\n        data={\"foo\": \"\u3134\"},\n        headers={\"X-Foo\": \"\u3137\"},\n    )\n    builder = EnvironBuilder.from_environ(environ)\n\n    try:\n        new_environ = builder.get_environ()\n    finally:\n        builder.close()\n\n    assert new_environ == environ\n\n\ndef test_file_closing():\n    closed = []\n\n    class SpecialInput:\n        def read(self, size):\n            return b\"\"\n\n        def close(self):\n            closed.append(self)\n\n    create_environ(data={\"foo\": SpecialInput()})\n    assert len(closed) == 1\n    builder = EnvironBuilder()\n    builder.files.add_file(\"blah\", SpecialInput())\n    builder.close()\n    assert len(closed) == 2\n\n\ndef test_follow_redirect():\n    env = create_environ(\"/\", base_url=\"http://localhost\")\n    c = Client(redirect_with_get_app)\n    response = c.open(environ_overrides=env, follow_redirects=True)\n    assert response.status == \"200 OK\"\n    assert response.text == \"current url: http://localhost/some/redirect/\"\n\n    # Test that the :cls:`Client` is aware of user defined response wrappers\n    c = Client(redirect_with_get_app)\n    resp = c.get(\"/\", follow_redirects=True)\n    assert resp.status_code == 200\n    assert resp.text == \"current url: http://localhost/some/redirect/\"\n\n    # test with URL other than '/' to make sure redirected URL's are correct\n    c = Client(redirect_with_get_app)\n    resp = c.get(\"/first/request\", follow_redirects=True)\n    assert resp.status_code == 200\n    assert resp.text == \"current url: http://localhost/some/redirect/\"\n\n\ndef test_follow_local_redirect():\n    class LocalResponse(Response):\n        autocorrect_location_header = False\n\n    def local_redirect_app(environ, start_response):\n        req = Request(environ)\n        if \"/from/location\" in req.url:\n            response = redirect(\"/to/location\", Response=LocalResponse)\n        else:\n            response = Response(f\"current path: {req.path}\")\n        return response(environ, start_response)\n\n    c = Client(local_redirect_app)\n    resp = c.get(\"/from/location\", follow_redirects=True)\n    assert resp.status_code == 200\n    assert resp.text == \"current path: /to/location\"\n\n\n@pytest.mark.parametrize(\n    (\"code\", \"keep\"), ((302, False), (301, False), (307, True), (308, True))\n)\ndef test_follow_redirect_body(code, keep):\n    @Request.application\n    def app(request):\n        if request.url == \"http://localhost/some/redirect/\":\n            assert request.method == \"POST\" if keep else \"GET\"\n            assert request.headers[\"X-Foo\"] == \"bar\"\n\n            if keep:\n                assert request.form[\"foo\"] == \"bar\"\n            else:\n                assert not request.form\n\n            return Response(f\"current url: {request.url}\")\n\n        return redirect(\"http://localhost/some/redirect/\", code=code)\n\n    c = Client(app)\n    response = c.post(\n        \"/\", follow_redirects=True, data={\"foo\": \"bar\"}, headers={\"X-Foo\": \"bar\"}\n    )\n    assert response.status_code == 200\n    assert response.text == \"current url: http://localhost/some/redirect/\"\n\n\ndef test_follow_external_redirect():\n    env = create_environ(\"/\", base_url=\"http://localhost\")\n    c = Client(external_redirect_demo_app)\n    pytest.raises(\n        RuntimeError, lambda: c.get(environ_overrides=env, follow_redirects=True)\n    )\n\n\ndef test_follow_external_redirect_on_same_subdomain():\n    env = create_environ(\"/\", base_url=\"http://example.com\")\n    c = Client(external_subdomain_redirect_demo_app, allow_subdomain_redirects=True)\n    c.get(environ_overrides=env, follow_redirects=True)\n\n    # check that this does not work for real external domains\n    env = create_environ(\"/\", base_url=\"http://localhost\")\n    pytest.raises(\n        RuntimeError, lambda: c.get(environ_overrides=env, follow_redirects=True)\n    )\n\n    # check that subdomain redirects fail if no `allow_subdomain_redirects` is applied\n    c = Client(external_subdomain_redirect_demo_app)\n    pytest.raises(\n        RuntimeError, lambda: c.get(environ_overrides=env, follow_redirects=True)\n    )\n\n\ndef test_follow_redirect_loop():\n    c = Client(redirect_loop_app)\n    with pytest.raises(ClientRedirectError):\n        c.get(\"/\", follow_redirects=True)\n\n\ndef test_follow_redirect_non_root_base_url():\n    @Request.application\n    def app(request):\n        if request.path == \"/redirect\":\n            return redirect(\"done\")\n\n        return Response(request.path)\n\n    c = Client(app)\n    response = c.get(\n        \"/redirect\", base_url=\"http://localhost/other\", follow_redirects=True\n    )\n    assert response.text == \"/done\"\n\n\ndef test_follow_redirect_exhaust_intermediate():\n    class Middleware:\n        def __init__(self, app):\n            self.app = app\n            self.active = 0\n\n        def __call__(self, environ, start_response):\n            # Test client must exhaust response stream, otherwise the\n            # cleanup code that decrements this won't have run by the\n            # time the next request is started.\n            assert not self.active\n            self.active += 1\n            try:\n                yield from self.app(environ, start_response)\n            finally:\n                self.active -= 1\n\n    app = Middleware(redirect_with_get_app)\n    client = Client(Middleware(redirect_with_get_app))\n    response = client.get(\"/\", follow_redirects=True, buffered=False)\n    assert response.text == \"current url: http://localhost/some/redirect/\"\n    assert not app.active\n\n\ndef test_redirects_are_tracked():\n    @Request.application\n    def app(request):\n        if request.path == \"/first\":\n            return redirect(\"/second\")\n\n        if request.path == \"/second\":\n            return redirect(\"/third\")\n\n        return Response(\"done\")\n\n    c = Client(app)\n    response = c.get(\"/first\", follow_redirects=True)\n    assert response.text == \"done\"\n    assert len(response.history) == 2\n\n    assert response.history[-1].request.path == \"/second\"\n    assert response.history[-1].status_code == 302\n    assert response.history[-1].location == \"/third\"\n    assert len(response.history[-1].history) == 1\n    assert response.history[-1].history[-1] is response.history[-2]\n\n    assert response.history[-2].request.path == \"/first\"\n    assert response.history[-2].status_code == 302\n    assert response.history[-2].location == \"/second\"\n    assert len(response.history[-2].history) == 0\n\n\ndef test_cookie_across_redirect():\n    @Request.application\n    def app(request):\n        if request.path == \"/\":\n            return Response(request.cookies.get(\"auth\", \"out\"))\n\n        if request.path == \"/in\":\n            rv = redirect(\"/\")\n            rv.set_cookie(\"auth\", \"in\")\n            return rv\n\n        if request.path == \"/out\":\n            rv = redirect(\"/\")\n            rv.delete_cookie(\"auth\")\n            return rv\n\n    c = Client(app)\n    assert c.get(\"/\").text == \"out\"\n    assert c.get(\"/in\", follow_redirects=True).text == \"in\"\n    assert c.get(\"/\").text == \"in\"\n    assert c.get(\"/out\", follow_redirects=True).text == \"out\"\n    assert c.get(\"/\").text == \"out\"\n\n\ndef test_path_info_script_name_unquoting():\n    def test_app(environ, start_response):\n        start_response(\"200 OK\", [(\"Content-Type\", \"text/plain\")])\n        return [f\"{environ['PATH_INFO']}\\n{environ['SCRIPT_NAME']}\"]\n\n    c = Client(test_app)\n    resp = c.get(\"/foo%40bar\")\n    assert resp.text == \"/foo@bar\\n\"\n    c = Client(test_app)\n    resp = c.get(\"/foo%40bar\", \"http://localhost/bar%40baz\")\n    assert resp.text == \"/foo@bar\\n/bar@baz\"\n\n\ndef test_multi_value_submit():\n    c = Client(multi_value_post_app)\n    data = {\"field\": [\"val1\", \"val2\"]}\n    resp = c.post(\"/\", data=data)\n    assert resp.status_code == 200\n    c = Client(multi_value_post_app)\n    data = MultiDict({\"field\": [\"val1\", \"val2\"]})\n    resp = c.post(\"/\", data=data)\n    assert resp.status_code == 200\n\n\ndef test_iri_support():\n    b = EnvironBuilder(\"/f\u00f6\u00f6-bar\", base_url=\"http://\u2603.net/\")\n    assert b.path == \"/f%C3%B6%C3%B6-bar\"\n    assert b.base_url == \"http://xn--n3h.net/\"\n\n\n@pytest.mark.parametrize(\"buffered\", (True, False))\n@pytest.mark.parametrize(\"iterable\", (True, False))\ndef test_run_wsgi_apps(buffered, iterable):\n    leaked_data = []\n\n    def simple_app(environ, start_response):\n        start_response(\"200 OK\", [(\"Content-Type\", \"text/html\")])\n        return [\"Hello World!\"]\n\n    def yielding_app(environ, start_response):\n        start_response(\"200 OK\", [(\"Content-Type\", \"text/html\")])\n        yield \"Hello \"\n        yield \"World!\"\n\n    def late_start_response(environ, start_response):\n        yield \"Hello \"\n        yield \"World\"\n        start_response(\"200 OK\", [(\"Content-Type\", \"text/html\")])\n        yield \"!\"\n\n    def depends_on_close(environ, start_response):\n        leaked_data.append(\"harhar\")\n        start_response(\"200 OK\", [(\"Content-Type\", \"text/html\")])\n\n        class Rv:\n            def __iter__(self):\n                yield \"Hello \"\n                yield \"World\"\n                yield \"!\"\n\n            def close(self):\n                assert leaked_data.pop() == \"harhar\"\n\n        return Rv()\n\n    for app in (simple_app, yielding_app, late_start_response, depends_on_close):\n        if iterable:\n            app = iterable_middleware(app)\n        app_iter, status, headers = run_wsgi_app(app, {}, buffered=buffered)\n        assert status == \"200 OK\"\n        assert list(headers) == [(\"Content-Type\", \"text/html\")]\n        assert \"\".join(app_iter) == \"Hello World!\"\n\n        if hasattr(app_iter, \"close\"):\n            app_iter.close()\n        assert not leaked_data\n\n\n@pytest.mark.parametrize(\"buffered\", (True, False))\n@pytest.mark.parametrize(\"iterable\", (True, False))\ndef test_lazy_start_response_empty_response_app(buffered, iterable):\n    class app:\n        def __init__(self, environ, start_response):\n            self.start_response = start_response\n\n        def __iter__(self):\n            return self\n\n        def __next__(self):\n            self.start_response(\"200 OK\", [(\"Content-Type\", \"text/html\")])\n            raise StopIteration\n\n    if iterable:\n        app = iterable_middleware(app)\n    app_iter, status, headers = run_wsgi_app(app, {}, buffered=buffered)\n    assert status == \"200 OK\"\n    assert list(headers) == [(\"Content-Type\", \"text/html\")]\n    assert \"\".join(app_iter) == \"\"\n\n\ndef test_run_wsgi_app_closing_iterator():\n    got_close = []\n\n    class CloseIter:\n        def __init__(self):\n            self.iterated = False\n\n        def __iter__(self):\n            return self\n\n        def close(self):\n            got_close.append(None)\n\n        def __next__(self):\n            if self.iterated:\n                raise StopIteration()\n            self.iterated = True\n            return \"bar\"\n\n    def bar(environ, start_response):\n        start_response(\"200 OK\", [(\"Content-Type\", \"text/plain\")])\n        return CloseIter()\n\n    app_iter, status, headers = run_wsgi_app(bar, {})\n    assert status == \"200 OK\"\n    assert list(headers) == [(\"Content-Type\", \"text/plain\")]\n    assert next(app_iter) == \"bar\"\n    pytest.raises(StopIteration, partial(next, app_iter))\n    app_iter.close()\n\n    assert run_wsgi_app(bar, {}, True)[0] == [\"bar\"]\n\n    assert len(got_close) == 2\n\n\ndef iterable_middleware(app):\n    \"\"\"Guarantee that the app returns an iterable\"\"\"\n\n    def inner(environ, start_response):\n        rv = app(environ, start_response)\n\n        class Iterable:\n            def __iter__(self):\n                return iter(rv)\n\n            if hasattr(rv, \"close\"):\n\n                def close(self):\n                    rv.close()\n\n        return Iterable()\n\n    return inner\n\n\ndef test_multiple_cookies():\n    @Request.application\n    def test_app(request):\n        response = Response(repr(sorted(request.cookies.items())))\n        response.set_cookie(\"test1\", \"foo\")\n        response.set_cookie(\"test2\", \"bar\")\n        return response\n\n    client = Client(test_app)\n    resp = client.get(\"/\")\n    assert resp.text == \"[]\"\n    resp = client.get(\"/\")\n    assert resp.text == repr([(\"test1\", \"foo\"), (\"test2\", \"bar\")])\n\n\ndef test_correct_open_invocation_on_redirect():\n    class MyClient(Client):\n        counter = 0\n\n        def open(self, *args, **kwargs):\n            self.counter += 1\n            env = kwargs.setdefault(\"environ_overrides\", {})\n            env[\"werkzeug._foo\"] = self.counter\n            return Client.open(self, *args, **kwargs)\n\n    @Request.application\n    def test_app(request):\n        return Response(str(request.environ[\"werkzeug._foo\"]))\n\n    c = MyClient(test_app, response_wrapper=Response)\n    assert c.get(\"/\").text == \"1\"\n    assert c.get(\"/\").text == \"2\"\n    assert c.get(\"/\").text == \"3\"\n\n\ndef test_correct_encoding():\n    req = Request.from_values(\"/\\N{SNOWMAN}\", \"http://example.com/foo\")\n    assert req.script_root == \"/foo\"\n    assert req.path == \"/\\N{SNOWMAN}\"\n\n\ndef test_full_url_requests_with_args():\n    base = \"http://example.com/\"\n\n    @Request.application\n    def test_app(request):\n        return Response(request.args[\"x\"])\n\n    client = Client(test_app)\n    resp = client.get(\"/?x=42\", base)\n    assert resp.text == \"42\"\n    resp = client.get(\"http://www.example.com/?x=23\", base)\n    assert resp.text == \"23\"\n\n\ndef test_delete_requests_with_form():\n    @Request.application\n    def test_app(request):\n        return Response(request.form.get(\"x\", None))\n\n    client = Client(test_app)\n    resp = client.delete(\"/\", data={\"x\": 42})\n    assert resp.text == \"42\"\n\n\ndef test_post_with_file_descriptor(tmpdir):\n    c = Client(Response())\n    f = tmpdir.join(\"some-file.txt\")\n    f.write(\"foo\")\n    with open(f.strpath) as data:\n        resp = c.post(\"/\", data=data)\n    assert resp.status_code == 200\n    with open(f.strpath, mode=\"rb\") as data:\n        resp = c.post(\"/\", data=data)\n    assert resp.status_code == 200\n\n\ndef test_content_type():\n    @Request.application\n    def test_app(request):\n        return Response(request.content_type)\n\n    client = Client(test_app)\n\n    resp = client.get(\"/\", data=b\"testing\", mimetype=\"text/css\")\n    assert resp.text == \"text/css; charset=utf-8\"\n\n    resp = client.get(\"/\", data=b\"testing\", mimetype=\"application/octet-stream\")\n    assert resp.text == \"application/octet-stream\"\n\n\ndef test_raw_request_uri():\n    @Request.application\n    def app(request):\n        path_info = request.path\n        request_uri = request.environ[\"REQUEST_URI\"]\n        return Response(\"\\n\".join((path_info, request_uri)))\n\n    client = Client(app)\n    response = client.get(\"/hello%2fworld\")\n    data = response.text\n    assert data == \"/hello/world\\n/hello%2fworld\"\n\n    response = client.get(\"/?a=b\")\n    assert response.text == \"/\\n/?a=b\"\n\n    response = client.get(\"/%3f?\")  # escaped ? in path, and empty query string\n    assert response.text == \"/?\\n/%3f?\"\n\n\ndef no_response_headers_app(environ, start_response):\n    \"\"\"A WSGI application which returns a resposne with no headers.\"\"\"\n    response = Response(\"Response\")\n    response.headers.clear()\n    return response(environ, start_response)\n\n\ndef test_no_content_type_header_addition():\n    c = Client(no_response_headers_app)\n    response = c.open()\n    assert response.headers == Headers([(\"Content-Length\", \"8\")])\n\n\ndef test_client_response_wrapper():\n    class CustomResponse(Response):\n        pass\n\n    class CustomTestResponse(TestResponse, Response):\n        pass\n\n    c1 = Client(Response(), CustomResponse)\n    r1 = c1.open()\n\n    assert isinstance(r1, CustomResponse)\n    assert type(r1) is not CustomResponse  # Got subclassed\n    assert issubclass(type(r1), CustomResponse)\n\n    c2 = Client(Response(), CustomTestResponse)\n    r2 = c2.open()\n\n    assert isinstance(r2, CustomTestResponse)\n    assert type(r2) is CustomTestResponse  # Did not get subclassed\n", "tests/test_http.py": "import base64\nimport urllib.parse\nfrom datetime import date\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom datetime import timezone\n\nimport pytest\n\nfrom werkzeug import datastructures\nfrom werkzeug import http\nfrom werkzeug._internal import _wsgi_encoding_dance\nfrom werkzeug.datastructures import Authorization\nfrom werkzeug.datastructures import WWWAuthenticate\nfrom werkzeug.test import create_environ\n\n\nclass TestHTTPUtility:\n    def test_accept(self):\n        a = http.parse_accept_header(\"en-us,ru;q=0.5\")\n        assert list(a.values()) == [\"en-us\", \"ru\"]\n        assert a.best == \"en-us\"\n        assert a.find(\"ru\") == 1\n        pytest.raises(ValueError, a.index, \"de\")\n        assert a.to_header() == \"en-us,ru;q=0.5\"\n\n    def test_accept_parameter_with_space(self):\n        a = http.parse_accept_header('application/x-special; z=\"a b\";q=0.5')\n        assert a['application/x-special; z=\"a b\"'] == 0.5\n\n    def test_mime_accept(self):\n        a = http.parse_accept_header(\n            \"text/xml,application/xml,\"\n            \"application/xhtml+xml,\"\n            \"application/foo;quiet=no; bar=baz;q=0.6,\"\n            \"text/html;q=0.9,text/plain;q=0.8,\"\n            \"image/png,*/*;q=0.5\",\n            datastructures.MIMEAccept,\n        )\n        pytest.raises(ValueError, lambda: a[\"missing\"])\n        assert a[\"image/png\"] == 1\n        assert a[\"text/plain\"] == 0.8\n        assert a[\"foo/bar\"] == 0.5\n        assert a[\"application/foo;quiet=no; bar=baz\"] == 0.6\n        assert a[a.find(\"foo/bar\")] == (\"*/*\", 0.5)\n\n    def test_accept_matches(self):\n        a = http.parse_accept_header(\n            \"text/xml,application/xml,application/xhtml+xml,\"\n            \"text/html;q=0.9,text/plain;q=0.8,\"\n            \"image/png\",\n            datastructures.MIMEAccept,\n        )\n        assert (\n            a.best_match([\"text/html\", \"application/xhtml+xml\"])\n            == \"application/xhtml+xml\"\n        )\n        assert a.best_match([\"text/html\"]) == \"text/html\"\n        assert a.best_match([\"foo/bar\"]) is None\n        assert a.best_match([\"foo/bar\", \"bar/foo\"], default=\"foo/bar\") == \"foo/bar\"\n        assert a.best_match([\"application/xml\", \"text/xml\"]) == \"application/xml\"\n\n    def test_accept_mime_specificity(self):\n        a = http.parse_accept_header(\n            \"text/*, text/html, text/html;level=1, */*\", datastructures.MIMEAccept\n        )\n        assert a.best_match([\"text/html; version=1\", \"text/html\"]) == \"text/html\"\n        assert a.best_match([\"text/html\", \"text/html; level=1\"]) == \"text/html; level=1\"\n\n    def test_charset_accept(self):\n        a = http.parse_accept_header(\n            \"ISO-8859-1,utf-8;q=0.7,*;q=0.7\", datastructures.CharsetAccept\n        )\n        assert a[\"iso-8859-1\"] == a[\"iso8859-1\"]\n        assert a[\"iso-8859-1\"] == 1\n        assert a[\"UTF8\"] == 0.7\n        assert a[\"ebcdic\"] == 0.7\n\n    def test_language_accept(self):\n        a = http.parse_accept_header(\n            \"de-AT,de;q=0.8,en;q=0.5\", datastructures.LanguageAccept\n        )\n        assert a.best == \"de-AT\"\n        assert \"de_AT\" in a\n        assert \"en\" in a\n        assert a[\"de-at\"] == 1\n        assert a[\"en\"] == 0.5\n\n    def test_set_header(self):\n        hs = http.parse_set_header('foo, Bar, \"Blah baz\", Hehe')\n        assert \"blah baz\" in hs\n        assert \"foobar\" not in hs\n        assert \"foo\" in hs\n        assert list(hs) == [\"foo\", \"Bar\", \"Blah baz\", \"Hehe\"]\n        hs.add(\"Foo\")\n        assert hs.to_header() == 'foo, Bar, \"Blah baz\", Hehe'\n\n    @pytest.mark.parametrize(\n        (\"value\", \"expect\"),\n        [\n            (\"a b\", [\"a b\"]),\n            (\"a b, c\", [\"a b\", \"c\"]),\n            ('a b, \"c, d\"', [\"a b\", \"c, d\"]),\n            ('\"a\\\\\"b\", c', ['a\"b', \"c\"]),\n        ],\n    )\n    def test_list_header(self, value, expect):\n        assert http.parse_list_header(value) == expect\n\n    def test_dict_header(self):\n        d = http.parse_dict_header('foo=\"bar baz\", blah=42')\n        assert d == {\"foo\": \"bar baz\", \"blah\": \"42\"}\n\n    def test_cache_control_header(self):\n        cc = http.parse_cache_control_header(\"max-age=0, no-cache\")\n        assert cc.max_age == 0\n        assert cc.no_cache\n        cc = http.parse_cache_control_header(\n            'private, community=\"UCI\"', None, datastructures.ResponseCacheControl\n        )\n        assert cc.private\n        assert cc[\"community\"] == \"UCI\"\n\n        c = datastructures.ResponseCacheControl()\n        assert c.no_cache is None\n        assert c.private is None\n        c.no_cache = True\n        assert c.no_cache == \"*\"\n        c.private = True\n        assert c.private == \"*\"\n        del c.private\n        assert c.private is None\n        # max_age is an int, other types are converted\n        c.max_age = 3.1\n        assert c.max_age == 3\n        del c.max_age\n        c.s_maxage = 3.1\n        assert c.s_maxage == 3\n        del c.s_maxage\n        assert c.to_header() == \"no-cache\"\n\n    def test_csp_header(self):\n        csp = http.parse_csp_header(\n            \"default-src 'self'; script-src 'unsafe-inline' *; img-src\"\n        )\n        assert csp.default_src == \"'self'\"\n        assert csp.script_src == \"'unsafe-inline' *\"\n        assert csp.img_src is None\n\n    def test_authorization_header(self):\n        a = Authorization.from_header(\"Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ==\")\n        assert a.type == \"basic\"\n        assert a.username == \"Aladdin\"\n        assert a.password == \"open sesame\"\n\n        a = Authorization.from_header(\"Basic 0YDRg9GB0YHQutC40IE60JHRg9C60LLRiw==\")\n        assert a.type == \"basic\"\n        assert a.username == \"\u0440\u0443\u0441\u0441\u043a\u0438\u0401\"\n        assert a.password == \"\u0411\u0443\u043a\u0432\u044b\"\n\n        a = Authorization.from_header(\"Basic 5pmu6YCa6K+dOuS4reaWhw==\")\n        assert a.type == \"basic\"\n        assert a.username == \"\u666e\u901a\u8bdd\"\n        assert a.password == \"\u4e2d\u6587\"\n\n        a = Authorization.from_header(\n            'Digest username=\"Mufasa\",'\n            ' realm=\"testrealm@host.invalid\",'\n            ' nonce=\"dcd98b7102dd2f0e8b11d0f600bfb0c093\",'\n            ' uri=\"/dir/index.html\",'\n            \" qop=auth, nc=00000001,\"\n            ' cnonce=\"0a4f113b\",'\n            ' response=\"6629fae49393a05397450978507c4ef1\",'\n            ' opaque=\"5ccc069c403ebaf9f0171e9517f40e41\"'\n        )\n        assert a.type == \"digest\"\n        assert a.username == \"Mufasa\"\n        assert a.realm == \"testrealm@host.invalid\"\n        assert a.nonce == \"dcd98b7102dd2f0e8b11d0f600bfb0c093\"\n        assert a.uri == \"/dir/index.html\"\n        assert a.qop == \"auth\"\n        assert a.nc == \"00000001\"\n        assert a.cnonce == \"0a4f113b\"\n        assert a.response == \"6629fae49393a05397450978507c4ef1\"\n        assert a.opaque == \"5ccc069c403ebaf9f0171e9517f40e41\"\n\n        a = Authorization.from_header(\n            'Digest username=\"Mufasa\",'\n            ' realm=\"testrealm@host.invalid\",'\n            ' nonce=\"dcd98b7102dd2f0e8b11d0f600bfb0c093\",'\n            ' uri=\"/dir/index.html\",'\n            ' response=\"e257afa1414a3340d93d30955171dd0e\",'\n            ' opaque=\"5ccc069c403ebaf9f0171e9517f40e41\"'\n        )\n        assert a.type == \"digest\"\n        assert a.username == \"Mufasa\"\n        assert a.realm == \"testrealm@host.invalid\"\n        assert a.nonce == \"dcd98b7102dd2f0e8b11d0f600bfb0c093\"\n        assert a.uri == \"/dir/index.html\"\n        assert a.response == \"e257afa1414a3340d93d30955171dd0e\"\n        assert a.opaque == \"5ccc069c403ebaf9f0171e9517f40e41\"\n\n        assert Authorization.from_header(\"\") is None\n        assert Authorization.from_header(None) is None\n        assert Authorization.from_header(\"foo\").type == \"foo\"\n\n    def test_authorization_token_padding(self):\n        # padded with =\n        token = base64.b64encode(b\"This has base64 padding\").decode()\n        a = Authorization.from_header(f\"Token {token}\")\n        assert a.type == \"token\"\n        assert a.token == token\n\n        # padded with ==\n        token = base64.b64encode(b\"This has base64 padding..\").decode()\n        a = Authorization.from_header(f\"Token {token}\")\n        assert a.type == \"token\"\n        assert a.token == token\n\n    def test_authorization_basic_incorrect_padding(self):\n        assert Authorization.from_header(\"Basic foo\") is None\n\n    def test_bad_authorization_header_encoding(self):\n        \"\"\"If the base64 encoded bytes can't be decoded as UTF-8\"\"\"\n        content = base64.b64encode(b\"\\xffser:pass\").decode()\n        assert Authorization.from_header(f\"Basic {content}\") is None\n\n    def test_authorization_eq(self):\n        basic1 = Authorization.from_header(\"Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ==\")\n        basic2 = Authorization(\n            \"basic\", {\"username\": \"Aladdin\", \"password\": \"open sesame\"}\n        )\n        assert basic1 == basic2\n        bearer1 = Authorization.from_header(\"Bearer abc\")\n        bearer2 = Authorization(\"bearer\", token=\"abc\")\n        assert bearer1 == bearer2\n        assert basic1 != bearer1\n        assert basic1 != object()\n\n    def test_www_authenticate_header(self):\n        wa = WWWAuthenticate.from_header('Basic realm=\"WallyWorld\"')\n        assert wa.type == \"basic\"\n        assert wa.realm == \"WallyWorld\"\n        wa.realm = \"Foo Bar\"\n        assert wa.to_header() == 'Basic realm=\"Foo Bar\"'\n\n        wa = WWWAuthenticate.from_header(\n            'Digest realm=\"testrealm@host.com\",'\n            ' qop=\"auth,auth-int\",'\n            ' nonce=\"dcd98b7102dd2f0e8b11d0f600bfb0c093\",'\n            ' opaque=\"5ccc069c403ebaf9f0171e9517f40e41\"'\n        )\n        assert wa.type == \"digest\"\n        assert wa.realm == \"testrealm@host.com\"\n        assert wa.parameters[\"qop\"] == \"auth,auth-int\"\n        assert wa.nonce == \"dcd98b7102dd2f0e8b11d0f600bfb0c093\"\n        assert wa.opaque == \"5ccc069c403ebaf9f0171e9517f40e41\"\n\n        assert WWWAuthenticate.from_header(\"broken\").type == \"broken\"\n        assert WWWAuthenticate.from_header(\"\") is None\n\n    def test_www_authenticate_token_padding(self):\n        # padded with =\n        token = base64.b64encode(b\"This has base64 padding\").decode()\n        a = WWWAuthenticate.from_header(f\"Token {token}\")\n        assert a.type == \"token\"\n        assert a.token == token\n\n        # padded with ==\n        token = base64.b64encode(b\"This has base64 padding..\").decode()\n        a = WWWAuthenticate.from_header(f\"Token {token}\")\n        assert a.type == \"token\"\n        assert a.token == token\n\n    def test_www_authenticate_eq(self):\n        basic1 = WWWAuthenticate.from_header(\"Basic realm=abc\")\n        basic2 = WWWAuthenticate(\"basic\", {\"realm\": \"abc\"})\n        assert basic1 == basic2\n        token1 = WWWAuthenticate.from_header(\"Token abc\")\n        token2 = WWWAuthenticate(\"token\", token=\"abc\")\n        assert token1 == token2\n        assert basic1 != token1\n        assert basic1 != object()\n\n    def test_etags(self):\n        assert http.quote_etag(\"foo\") == '\"foo\"'\n        assert http.quote_etag(\"foo\", True) == 'W/\"foo\"'\n        assert http.unquote_etag('\"foo\"') == (\"foo\", False)\n        assert http.unquote_etag('W/\"foo\"') == (\"foo\", True)\n        es = http.parse_etags('\"foo\", \"bar\", W/\"baz\", blar')\n        assert sorted(es) == [\"bar\", \"blar\", \"foo\"]\n        assert \"foo\" in es\n        assert \"baz\" not in es\n        assert es.contains_weak(\"baz\")\n        assert \"blar\" in es\n        assert es.contains_raw('W/\"baz\"')\n        assert es.contains_raw('\"foo\"')\n        assert sorted(es.to_header().split(\", \")) == [\n            '\"bar\"',\n            '\"blar\"',\n            '\"foo\"',\n            'W/\"baz\"',\n        ]\n\n    def test_etags_nonzero(self):\n        etags = http.parse_etags('W/\"foo\"')\n        assert bool(etags)\n        assert etags.contains_raw('W/\"foo\"')\n\n    def test_remove_entity_headers(self):\n        now = http.http_date()\n        headers1 = [\n            (\"Date\", now),\n            (\"Content-Type\", \"text/html\"),\n            (\"Content-Length\", \"0\"),\n        ]\n        headers2 = datastructures.Headers(headers1)\n\n        http.remove_entity_headers(headers1)\n        assert headers1 == [(\"Date\", now)]\n\n        http.remove_entity_headers(headers2)\n        assert headers2 == datastructures.Headers([(\"Date\", now)])\n\n    def test_remove_hop_by_hop_headers(self):\n        headers1 = [(\"Connection\", \"closed\"), (\"Foo\", \"bar\"), (\"Keep-Alive\", \"wtf\")]\n        headers2 = datastructures.Headers(headers1)\n\n        http.remove_hop_by_hop_headers(headers1)\n        assert headers1 == [(\"Foo\", \"bar\")]\n\n        http.remove_hop_by_hop_headers(headers2)\n        assert headers2 == datastructures.Headers([(\"Foo\", \"bar\")])\n\n    @pytest.mark.parametrize(\n        (\"value\", \"expect\"),\n        [\n            (None, \"\"),\n            (\"\", \"\"),\n            (\";a=b\", \"\"),\n            (\"v\", \"v\"),\n            (\"v;\", \"v\"),\n        ],\n    )\n    def test_parse_options_header_empty(self, value, expect):\n        assert http.parse_options_header(value) == (expect, {})\n\n    @pytest.mark.parametrize(\n        (\"value\", \"expect\"),\n        [\n            (\"v;a=b;c=d;\", {\"a\": \"b\", \"c\": \"d\"}),\n            (\"v;  ; a=b ; \", {\"a\": \"b\"}),\n            (\"v;a\", {}),\n            (\"v;a=\", {}),\n            (\"v;=b\", {}),\n            ('v;a=\"b\"', {\"a\": \"b\"}),\n            (\"v;a=\u00b5\", {}),\n            ('v;a=\"\\';\\'\";b=\"\u00b5\";', {\"a\": \"';'\", \"b\": \"\u00b5\"}),\n            ('v;a=\"b c\"', {\"a\": \"b c\"}),\n            # HTTP headers use \\\" for internal \"\n            ('v;a=\"b\\\\\"c\";d=e', {\"a\": 'b\"c', \"d\": \"e\"}),\n            # HTTP headers use \\\\ for internal \\\n            ('v;a=\"c:\\\\\\\\\"', {\"a\": \"c:\\\\\"}),\n            # Invalid trailing slash in quoted part is left as-is.\n            ('v;a=\"c:\\\\\"', {\"a\": \"c:\\\\\"}),\n            ('v;a=\"b\\\\\\\\\\\\\"c\"', {\"a\": 'b\\\\\"c'}),\n            # multipart form data uses %22 for internal \"\n            ('v;a=\"b%22c\"', {\"a\": 'b\"c'}),\n            (\"v;a*=b\", {\"a\": \"b\"}),\n            (\"v;a*=ASCII'en'b\", {\"a\": \"b\"}),\n            (\"v;a*=US-ASCII''%62\", {\"a\": \"b\"}),\n            (\"v;a*=UTF-8''%C2%B5\", {\"a\": \"\u00b5\"}),\n            (\"v;a*=US-ASCII''%C2%B5\", {\"a\": \"\ufffd\ufffd\"}),\n            (\"v;a*=BAD''%62\", {\"a\": \"%62\"}),\n            (\"v;a*=UTF-8'''%F0%9F%90%8D'.txt\", {\"a\": \"'\ud83d\udc0d'.txt\"}),\n            ('v;a=\"\ud83d\udc0d.txt\"', {\"a\": \"\ud83d\udc0d.txt\"}),\n            (\"v;a*0=b;a*1=c;d=e\", {\"a\": \"bc\", \"d\": \"e\"}),\n            (\"v;a*0*=b\", {\"a\": \"b\"}),\n            (\"v;a*0*=UTF-8''b;a*1=c;a*2*=%C2%B5\", {\"a\": \"bc\u00b5\"}),\n        ],\n    )\n    def test_parse_options_header(self, value, expect) -> None:\n        assert http.parse_options_header(value) == (\"v\", expect)\n\n    def test_parse_options_header_broken_values(self):\n        # Issue #995\n        assert http.parse_options_header(\" \") == (\"\", {})\n        assert http.parse_options_header(\" , \") == (\",\", {})\n        assert http.parse_options_header(\" ; \") == (\"\", {})\n        assert http.parse_options_header(\" ,; \") == (\",\", {})\n        assert http.parse_options_header(\" , a \") == (\", a\", {})\n        assert http.parse_options_header(\" ; a \") == (\"\", {})\n\n    def test_parse_options_header_case_insensitive(self):\n        _, options = http.parse_options_header(r'something; fileName=\"File.ext\"')\n        assert options[\"filename\"] == \"File.ext\"\n\n    def test_dump_options_header(self):\n        assert http.dump_options_header(\"foo\", {\"bar\": 42}) == \"foo; bar=42\"\n        assert \"fizz\" not in http.dump_options_header(\"foo\", {\"bar\": 42, \"fizz\": None})\n\n    def test_dump_header(self):\n        assert http.dump_header([1, 2, 3]) == \"1, 2, 3\"\n        assert http.dump_header({\"foo\": \"bar\"}) == \"foo=bar\"\n        assert http.dump_header({\"foo*\": \"UTF-8''bar\"}) == \"foo*=UTF-8''bar\"\n\n    def test_is_resource_modified(self):\n        env = create_environ()\n\n        # any method is allowed\n        env[\"REQUEST_METHOD\"] = \"POST\"\n        assert http.is_resource_modified(env, etag=\"testing\")\n        env[\"REQUEST_METHOD\"] = \"GET\"\n\n        # etagify from data\n        pytest.raises(TypeError, http.is_resource_modified, env, data=\"42\", etag=\"23\")\n        env[\"HTTP_IF_NONE_MATCH\"] = http.generate_etag(b\"awesome\")\n        assert not http.is_resource_modified(env, data=b\"awesome\")\n\n        env[\"HTTP_IF_MODIFIED_SINCE\"] = http.http_date(datetime(2008, 1, 1, 12, 30))\n        assert not http.is_resource_modified(\n            env, last_modified=datetime(2008, 1, 1, 12, 00)\n        )\n        assert http.is_resource_modified(\n            env, last_modified=datetime(2008, 1, 1, 13, 00)\n        )\n\n    def test_is_resource_modified_for_range_requests(self):\n        env = create_environ()\n\n        env[\"HTTP_IF_MODIFIED_SINCE\"] = http.http_date(datetime(2008, 1, 1, 12, 30))\n        env[\"HTTP_IF_RANGE\"] = http.generate_etag(b\"awesome_if_range\")\n        # Range header not present, so If-Range should be ignored\n        assert not http.is_resource_modified(\n            env,\n            data=b\"not_the_same\",\n            ignore_if_range=False,\n            last_modified=datetime(2008, 1, 1, 12, 30),\n        )\n\n        env[\"HTTP_RANGE\"] = \"\"\n        assert not http.is_resource_modified(\n            env, data=b\"awesome_if_range\", ignore_if_range=False\n        )\n        assert http.is_resource_modified(\n            env, data=b\"not_the_same\", ignore_if_range=False\n        )\n\n        env[\"HTTP_IF_RANGE\"] = http.http_date(datetime(2008, 1, 1, 13, 30))\n        assert http.is_resource_modified(\n            env, last_modified=datetime(2008, 1, 1, 14, 00), ignore_if_range=False\n        )\n        assert not http.is_resource_modified(\n            env, last_modified=datetime(2008, 1, 1, 13, 30), ignore_if_range=False\n        )\n        assert http.is_resource_modified(\n            env, last_modified=datetime(2008, 1, 1, 13, 30), ignore_if_range=True\n        )\n\n    def test_parse_cookie(self):\n        cookies = http.parse_cookie(\n            \"dismiss-top=6; CP=null*; PHPSESSID=0a539d42abc001cdc762809248d4beed;\"\n            'a=42; b=\"\\\\\";\"; ; fo234{=bar;blub=Blah; \"__Secure-c\"=d;'\n            \"==__Host-eq=bad;__Host-eq=good;\"\n        )\n        assert cookies.to_dict() == {\n            \"CP\": \"null*\",\n            \"PHPSESSID\": \"0a539d42abc001cdc762809248d4beed\",\n            \"a\": \"42\",\n            \"dismiss-top\": \"6\",\n            \"b\": '\";',\n            \"fo234{\": \"bar\",\n            \"blub\": \"Blah\",\n            '\"__Secure-c\"': \"d\",\n            \"__Host-eq\": \"good\",\n        }\n\n    def test_dump_cookie(self):\n        rv = http.dump_cookie(\n            \"foo\", \"bar baz blub\", 360, httponly=True, sync_expires=False\n        )\n        assert set(rv.split(\"; \")) == {\n            \"HttpOnly\",\n            \"Max-Age=360\",\n            \"Path=/\",\n            'foo=\"bar baz blub\"',\n        }\n        assert http.dump_cookie(\"key\", \"xxx/\") == \"key=xxx/; Path=/\"\n        assert http.dump_cookie(\"key\", \"xxx=\", path=None) == \"key=xxx=\"\n\n    def test_bad_cookies(self):\n        cookies = http.parse_cookie(\n            \"first=IamTheFirst ; a=1; oops ; a=2 ;second = andMeTwo;\"\n        )\n        expect = {\n            \"first\": [\"IamTheFirst\"],\n            \"a\": [\"1\", \"2\"],\n            \"oops\": [\"\"],\n            \"second\": [\"andMeTwo\"],\n        }\n        assert cookies.to_dict(flat=False) == expect\n        assert cookies[\"a\"] == \"1\"\n        assert cookies.getlist(\"a\") == [\"1\", \"2\"]\n\n    def test_empty_keys_are_ignored(self):\n        cookies = http.parse_cookie(\"spam=ham; duck=mallard; ; \")\n        expect = {\"spam\": \"ham\", \"duck\": \"mallard\"}\n        assert cookies.to_dict() == expect\n\n    def test_cookie_quoting(self):\n        val = http.dump_cookie(\"foo\", \"?foo\")\n        assert val == \"foo=?foo; Path=/\"\n        assert http.parse_cookie(val)[\"foo\"] == \"?foo\"\n        assert http.parse_cookie(r'foo=\"foo\\054bar\"')[\"foo\"] == \"foo,bar\"\n\n    def test_parse_set_cookie_directive(self):\n        val = 'foo=\"?foo\"; version=\"0.1\";'\n        assert http.parse_cookie(val).to_dict() == {\"foo\": \"?foo\", \"version\": \"0.1\"}\n\n    def test_cookie_domain_resolving(self):\n        val = http.dump_cookie(\"foo\", \"bar\", domain=\"\\N{SNOWMAN}.com\")\n        assert val == \"foo=bar; Domain=xn--n3h.com; Path=/\"\n\n    def test_cookie_unicode_dumping(self):\n        val = http.dump_cookie(\"foo\", \"\\N{SNOWMAN}\")\n        h = datastructures.Headers()\n        h.add(\"Set-Cookie\", val)\n        assert h[\"Set-Cookie\"] == 'foo=\"\\\\342\\\\230\\\\203\"; Path=/'\n\n        cookies = http.parse_cookie(h[\"Set-Cookie\"])\n        assert cookies[\"foo\"] == \"\\N{SNOWMAN}\"\n\n    def test_cookie_unicode_keys(self):\n        # Yes, this is technically against the spec but happens\n        val = http.dump_cookie(\"f\u00f6\", \"f\u00f6\")\n        assert val == _wsgi_encoding_dance('f\u00f6=\"f\\\\303\\\\266\"; Path=/')\n        cookies = http.parse_cookie(val)\n        assert cookies[\"f\u00f6\"] == \"f\u00f6\"\n\n    def test_cookie_unicode_parsing(self):\n        # This is submitted by Firefox if you set a Unicode cookie.\n        cookies = http.parse_cookie(\"f\u00c3\u00b6=f\u00c3\u00b6\")\n        assert cookies[\"f\u00f6\"] == \"f\u00f6\"\n\n    def test_cookie_domain_encoding(self):\n        val = http.dump_cookie(\"foo\", \"bar\", domain=\"\\N{SNOWMAN}.com\")\n        assert val == \"foo=bar; Domain=xn--n3h.com; Path=/\"\n\n        val = http.dump_cookie(\"foo\", \"bar\", domain=\"foo.com\")\n        assert val == \"foo=bar; Domain=foo.com; Path=/\"\n\n    def test_cookie_maxsize(self):\n        val = http.dump_cookie(\"foo\", \"bar\" * 1360 + \"b\")\n        assert len(val) == 4093\n\n        with pytest.warns(UserWarning, match=\"cookie is too large\"):\n            http.dump_cookie(\"foo\", \"bar\" * 1360 + \"ba\")\n\n        with pytest.warns(UserWarning, match=\"the limit is 512 bytes\"):\n            http.dump_cookie(\"foo\", \"w\" * 501, max_size=512)\n\n    @pytest.mark.parametrize(\n        (\"samesite\", \"expected\"),\n        (\n            (\"strict\", \"foo=bar; SameSite=Strict\"),\n            (\"lax\", \"foo=bar; SameSite=Lax\"),\n            (\"none\", \"foo=bar; SameSite=None\"),\n            (None, \"foo=bar\"),\n        ),\n    )\n    def test_cookie_samesite_attribute(self, samesite, expected):\n        value = http.dump_cookie(\"foo\", \"bar\", samesite=samesite, path=None)\n        assert value == expected\n\n    def test_cookie_samesite_invalid(self):\n        with pytest.raises(ValueError):\n            http.dump_cookie(\"foo\", \"bar\", samesite=\"invalid\")\n\n    def test_cookie_partitioned(self):\n        value = http.dump_cookie(\"foo\", \"bar\", partitioned=True, secure=True)\n        assert value == \"foo=bar; Secure; Path=/; Partitioned\"\n\n    def test_cookie_partitioned_sets_secure(self):\n        value = http.dump_cookie(\"foo\", \"bar\", partitioned=True, secure=False)\n        assert value == \"foo=bar; Secure; Path=/; Partitioned\"\n\n\nclass TestRange:\n    def test_if_range_parsing(self):\n        rv = http.parse_if_range_header('\"Test\"')\n        assert rv.etag == \"Test\"\n        assert rv.date is None\n        assert rv.to_header() == '\"Test\"'\n\n        # weak information is dropped\n        rv = http.parse_if_range_header('W/\"Test\"')\n        assert rv.etag == \"Test\"\n        assert rv.date is None\n        assert rv.to_header() == '\"Test\"'\n\n        # broken etags are supported too\n        rv = http.parse_if_range_header(\"bullshit\")\n        assert rv.etag == \"bullshit\"\n        assert rv.date is None\n        assert rv.to_header() == '\"bullshit\"'\n\n        rv = http.parse_if_range_header(\"Thu, 01 Jan 1970 00:00:00 GMT\")\n        assert rv.etag is None\n        assert rv.date == datetime(1970, 1, 1, tzinfo=timezone.utc)\n        assert rv.to_header() == \"Thu, 01 Jan 1970 00:00:00 GMT\"\n\n        for x in \"\", None:\n            rv = http.parse_if_range_header(x)\n            assert rv.etag is None\n            assert rv.date is None\n            assert rv.to_header() == \"\"\n\n    def test_range_parsing(self):\n        rv = http.parse_range_header(\"bytes=52\")\n        assert rv is None\n\n        rv = http.parse_range_header(\"bytes=52-\")\n        assert rv.units == \"bytes\"\n        assert rv.ranges == [(52, None)]\n        assert rv.to_header() == \"bytes=52-\"\n\n        rv = http.parse_range_header(\"bytes=52-99\")\n        assert rv.units == \"bytes\"\n        assert rv.ranges == [(52, 100)]\n        assert rv.to_header() == \"bytes=52-99\"\n\n        rv = http.parse_range_header(\"bytes=52-99,-1000\")\n        assert rv.units == \"bytes\"\n        assert rv.ranges == [(52, 100), (-1000, None)]\n        assert rv.to_header() == \"bytes=52-99,-1000\"\n\n        rv = http.parse_range_header(\"bytes = 1 - 100\")\n        assert rv.units == \"bytes\"\n        assert rv.ranges == [(1, 101)]\n        assert rv.to_header() == \"bytes=1-100\"\n\n        rv = http.parse_range_header(\"AWesomes=0-999\")\n        assert rv.units == \"awesomes\"\n        assert rv.ranges == [(0, 1000)]\n        assert rv.to_header() == \"awesomes=0-999\"\n\n        rv = http.parse_range_header(\"bytes=-\")\n        assert rv is None\n\n        rv = http.parse_range_header(\"bytes=bad\")\n        assert rv is None\n\n        rv = http.parse_range_header(\"bytes=bad-1\")\n        assert rv is None\n\n        rv = http.parse_range_header(\"bytes=-bad\")\n        assert rv is None\n\n        rv = http.parse_range_header(\"bytes=52-99, bad\")\n        assert rv is None\n\n    def test_content_range_parsing(self):\n        rv = http.parse_content_range_header(\"bytes 0-98/*\")\n        assert rv.units == \"bytes\"\n        assert rv.start == 0\n        assert rv.stop == 99\n        assert rv.length is None\n        assert rv.to_header() == \"bytes 0-98/*\"\n\n        rv = http.parse_content_range_header(\"bytes 0-98/*asdfsa\")\n        assert rv is None\n\n        rv = http.parse_content_range_header(\"bytes */-1\")\n        assert rv is None\n\n        rv = http.parse_content_range_header(\"bytes 0-99/100\")\n        assert rv.to_header() == \"bytes 0-99/100\"\n        rv.start = None\n        rv.stop = None\n        assert rv.units == \"bytes\"\n        assert rv.to_header() == \"bytes */100\"\n\n        rv = http.parse_content_range_header(\"bytes */100\")\n        assert rv.start is None\n        assert rv.stop is None\n        assert rv.length == 100\n        assert rv.units == \"bytes\"\n\n\nclass TestRegression:\n    def test_best_match_works(self):\n        # was a bug in 0.6\n        rv = http.parse_accept_header(\n            \"foo=,application/xml,application/xhtml+xml,\"\n            \"text/html;q=0.9,text/plain;q=0.8,\"\n            \"image/png,*/*;q=0.5\",\n            datastructures.MIMEAccept,\n        ).best_match([\"foo/bar\"])\n        assert rv == \"foo/bar\"\n\n\n@pytest.mark.parametrize(\n    \"value\",\n    [\n        \"Basic V2Vya3pldWc6V2VrcnpldWc=\",\n        'Digest username=Mufasa, realm=\"testrealm@host.invalid\",'\n        ' nonce=dcd98b7102dd2f0e8b11d0f600bfb0c093, uri=\"/dir/index.html\", qop=auth,'\n        \" nc=00000001, cnonce=0a4f113b, response=6629fae49393a05397450978507c4ef1,\"\n        \" opaque=5ccc069c403ebaf9f0171e9517f40e41\",\n    ],\n)\ndef test_authorization_to_header(value: str) -> None:\n    parsed = Authorization.from_header(value)\n    assert parsed is not None\n    assert parsed.to_header() == value\n\n\n@pytest.mark.parametrize(\n    (\"value\", \"expect\"),\n    [\n        (\n            \"Sun, 06 Nov 1994 08:49:37 GMT    \",\n            datetime(1994, 11, 6, 8, 49, 37, tzinfo=timezone.utc),\n        ),\n        (\n            \"Sunday, 06-Nov-94 08:49:37 GMT\",\n            datetime(1994, 11, 6, 8, 49, 37, tzinfo=timezone.utc),\n        ),\n        (\n            \" Sun Nov  6 08:49:37 1994\",\n            datetime(1994, 11, 6, 8, 49, 37, tzinfo=timezone.utc),\n        ),\n        (\"foo\", None),\n        (\n            \" Sun 02 Feb 1343 08:49:37 GMT\",\n            datetime(1343, 2, 2, 8, 49, 37, tzinfo=timezone.utc),\n        ),\n        (\n            \"Thu, 01 Jan 1970 00:00:00 GMT\",\n            datetime(1970, 1, 1, tzinfo=timezone.utc),\n        ),\n        (\"Thu, 33 Jan 1970 00:00:00 GMT\", None),\n    ],\n)\ndef test_parse_date(value, expect):\n    assert http.parse_date(value) == expect\n\n\n@pytest.mark.parametrize(\n    (\"value\", \"expect\"),\n    [\n        (\n            datetime(1994, 11, 6, 8, 49, 37, tzinfo=timezone.utc),\n            \"Sun, 06 Nov 1994 08:49:37 GMT\",\n        ),\n        (\n            datetime(1994, 11, 6, 8, 49, 37, tzinfo=timezone(timedelta(hours=-8))),\n            \"Sun, 06 Nov 1994 16:49:37 GMT\",\n        ),\n        (datetime(1994, 11, 6, 8, 49, 37), \"Sun, 06 Nov 1994 08:49:37 GMT\"),\n        (0, \"Thu, 01 Jan 1970 00:00:00 GMT\"),\n        (datetime(1970, 1, 1), \"Thu, 01 Jan 1970 00:00:00 GMT\"),\n        (datetime(1, 1, 1), \"Mon, 01 Jan 0001 00:00:00 GMT\"),\n        (datetime(999, 1, 1), \"Tue, 01 Jan 0999 00:00:00 GMT\"),\n        (datetime(1000, 1, 1), \"Wed, 01 Jan 1000 00:00:00 GMT\"),\n        (datetime(2020, 1, 1), \"Wed, 01 Jan 2020 00:00:00 GMT\"),\n        (date(2020, 1, 1), \"Wed, 01 Jan 2020 00:00:00 GMT\"),\n    ],\n)\ndef test_http_date(value, expect):\n    assert http.http_date(value) == expect\n\n\n@pytest.mark.parametrize(\"value\", [\".5\", \"+0.5\", \"0.5_1\", \"\ud83e\udff0.\ud83e\udff5\"])\ndef test_accept_invalid_float(value):\n    quoted = urllib.parse.quote(value)\n\n    if quoted == value:\n        q = f\"q={value}\"\n    else:\n        q = f\"q*=UTF-8''{value}\"\n\n    a = http.parse_accept_header(f\"en,jp;{q}\")\n    assert list(a.values()) == [\"en\"]\n\n\ndef test_accept_valid_int_one_zero():\n    assert http.parse_accept_header(\"en;q=1\") == http.parse_accept_header(\"en;q=1.0\")\n    assert http.parse_accept_header(\"en;q=0\") == http.parse_accept_header(\"en;q=0.0\")\n    assert http.parse_accept_header(\"en;q=5\") == http.parse_accept_header(\"en;q=5.0\")\n\n\n@pytest.mark.parametrize(\"value\", [\"\ud83e\udff1\ud83e\udff2\ud83e\udff3\", \"+1-\", \"1-1_23\"])\ndef test_range_invalid_int(value):\n    assert http.parse_range_header(value) is None\n\n\n@pytest.mark.parametrize(\"value\", [\"*/\ud83e\udff1\ud83e\udff2\ud83e\udff3\", \"1-+2/3\", \"1_23-125/*\"])\ndef test_content_range_invalid_int(value):\n    assert http.parse_content_range_header(f\"bytes {value}\") is None\n", "tests/test_local.py": "import asyncio\nimport copy\nimport math\nimport operator\nimport time\nfrom contextvars import ContextVar\nfrom threading import Thread\n\nimport pytest\n\nfrom werkzeug import local\n\n# Since the tests are creating local instances, use global context vars\n# to avoid accumulating anonymous context vars that can't be collected.\n_cv_ns = ContextVar(\"werkzeug.tests.ns\")\n_cv_stack = ContextVar(\"werkzeug.tests.stack\")\n_cv_val = ContextVar(\"werkzeug.tests.val\")\n\n\n@pytest.fixture(autouse=True)\ndef reset_context_vars():\n    ns_token = _cv_ns.set({})\n    stack_token = _cv_stack.set([])\n    yield\n    _cv_ns.reset(ns_token)\n    _cv_stack.reset(stack_token)\n\n\ndef test_basic_local():\n    ns = local.Local(_cv_ns)\n    ns.foo = 0\n    values = []\n\n    def value_setter(idx):\n        time.sleep(0.01 * idx)\n        ns.foo = idx\n        time.sleep(0.02)\n        values.append(ns.foo)\n\n    threads = [Thread(target=value_setter, args=(x,)) for x in [1, 2, 3]]\n    for thread in threads:\n        thread.start()\n    for thread in threads:\n        thread.join()\n    assert sorted(values) == [1, 2, 3]\n\n    def delfoo():\n        del ns.foo\n\n    delfoo()\n    pytest.raises(AttributeError, lambda: ns.foo)\n    pytest.raises(AttributeError, delfoo)\n\n    local.release_local(ns)\n\n\ndef test_basic_local_asyncio():\n    ns = local.Local(_cv_ns)\n    ns.foo = 0\n    values = []\n\n    async def value_setter(idx):\n        await asyncio.sleep(0.01 * idx)\n        ns.foo = idx\n        await asyncio.sleep(0.02)\n        values.append(ns.foo)\n\n    async def main():\n        futures = [asyncio.ensure_future(value_setter(i)) for i in [1, 2, 3]]\n        await asyncio.gather(*futures)\n\n    asyncio.run(main())\n    assert sorted(values) == [1, 2, 3]\n\n    def delfoo():\n        del ns.foo\n\n    delfoo()\n    pytest.raises(AttributeError, lambda: ns.foo)\n    pytest.raises(AttributeError, delfoo)\n\n    local.release_local(ns)\n\n\ndef test_local_release():\n    ns = local.Local(_cv_ns)\n    ns.foo = 42\n    local.release_local(ns)\n    assert not hasattr(ns, \"foo\")\n\n    ls = local.LocalStack(_cv_stack)\n    ls.push(42)\n    local.release_local(ls)\n    assert ls.top is None\n\n\ndef test_local_stack():\n    ls = local.LocalStack(_cv_stack)\n    assert ls.top is None\n    ls.push(42)\n    assert ls.top == 42\n    ls.push(23)\n    assert ls.top == 23\n    ls.pop()\n    assert ls.top == 42\n    ls.pop()\n    assert ls.top is None\n    assert ls.pop() is None\n    assert ls.pop() is None\n\n    proxy = ls()\n    ls.push([1, 2])\n    assert proxy == [1, 2]\n    ls.push((1, 2))\n    assert proxy == (1, 2)\n    ls.pop()\n    ls.pop()\n    assert repr(proxy) == \"<LocalProxy unbound>\"\n\n\ndef test_local_stack_asyncio():\n    ls = local.LocalStack(_cv_stack)\n    ls.push(1)\n\n    async def task():\n        ls.push(1)\n        assert len(ls._storage.get()) == 2\n\n    async def main():\n        futures = [asyncio.ensure_future(task()) for _ in range(3)]\n        await asyncio.gather(*futures)\n\n    asyncio.run(main())\n\n\ndef test_proxy_local():\n    ns = local.Local(_cv_ns)\n    ns.foo = []\n    p = local.LocalProxy(ns, \"foo\")\n    p.append(42)\n    p.append(23)\n    p[1:] = [1, 2, 3]\n    assert p == [42, 1, 2, 3]\n    assert p == ns.foo\n    ns.foo += [1]\n    assert list(p) == [42, 1, 2, 3, 1]\n    p_from_local = ns(\"foo\")\n    p_from_local.append(2)\n    assert p == p_from_local\n    assert p._get_current_object() is ns.foo\n\n\ndef test_proxy_callable():\n    value = 42\n    p = local.LocalProxy(lambda: value)\n    assert p == 42\n    value = [23]\n    p.append(42)\n    assert p == [23, 42]\n    assert value == [23, 42]\n    assert p._get_current_object() is value\n\n\ndef test_proxy_wrapped():\n    class SomeClassWithWrapped:\n        __wrapped__ = \"wrapped\"\n\n    proxy = local.LocalProxy(_cv_val)\n    assert proxy.__wrapped__ is _cv_val\n    _cv_val.set(42)\n\n    with pytest.raises(AttributeError):\n        proxy.__wrapped__  # noqa: B018\n\n    ns = local.Local(_cv_ns)\n    ns.foo = SomeClassWithWrapped()\n    ns.bar = 42\n\n    assert ns(\"foo\").__wrapped__ == \"wrapped\"\n\n    with pytest.raises(AttributeError):\n        ns(\"bar\").__wrapped__  # noqa: B018\n\n\ndef test_proxy_doc():\n    def example():\n        \"\"\"example doc\"\"\"\n\n    assert local.LocalProxy(lambda: example).__doc__ == \"example doc\"\n    # The __doc__ descriptor shouldn't block the LocalProxy's class doc.\n    assert local.LocalProxy.__doc__.startswith(\"A proxy\")\n\n\ndef test_proxy_fallback():\n    local_stack = local.LocalStack(_cv_stack)\n    local_proxy = local_stack()\n\n    assert repr(local_proxy) == \"<LocalProxy unbound>\"\n    assert isinstance(local_proxy, local.LocalProxy)\n    assert local_proxy.__class__ is local.LocalProxy\n    assert \"LocalProxy\" in local_proxy.__doc__\n\n    local_stack.push(42)\n\n    assert repr(local_proxy) == \"42\"\n    assert isinstance(local_proxy, int)\n    assert local_proxy.__class__ is int\n    assert \"int(\" in local_proxy.__doc__\n\n\ndef test_proxy_unbound():\n    ns = local.Local(_cv_ns)\n    p = ns(\"value\")\n    assert repr(p) == \"<LocalProxy unbound>\"\n    assert not p\n    assert dir(p) == []\n\n\ndef _make_proxy(value):\n    ns = local.Local(_cv_ns)\n    ns.value = value\n    p = ns(\"value\")\n    return ns, p\n\n\ndef test_proxy_type():\n    _, p = _make_proxy([])\n    assert isinstance(p, list)\n    assert p.__class__ is list\n    assert issubclass(type(p), local.LocalProxy)\n    assert type(p) is local.LocalProxy\n\n\ndef test_proxy_string_representations():\n    class Example:\n        def __repr__(self):\n            return \"a\"\n\n        def __bytes__(self):\n            return b\"b\"\n\n        def __index__(self):\n            return 23\n\n    _, p = _make_proxy(Example())\n    assert str(p) == \"a\"\n    assert repr(p) == \"a\"\n    assert bytes(p) == b\"b\"\n    # __index__\n    assert bin(p) == \"0b10111\"\n    assert oct(p) == \"0o27\"\n    assert hex(p) == \"0x17\"\n\n\ndef test_proxy_hash():\n    ns, p = _make_proxy(\"abc\")\n    assert hash(ns.value) == hash(p)\n\n\n@pytest.mark.parametrize(\n    \"op\",\n    [\n        operator.lt,\n        operator.le,\n        operator.eq,\n        operator.ne,\n        operator.gt,\n        operator.ge,\n        operator.add,\n        operator.sub,\n        operator.mul,\n        operator.truediv,\n        operator.floordiv,\n        operator.mod,\n        divmod,\n        pow,\n        operator.lshift,\n        operator.rshift,\n        operator.and_,\n        operator.or_,\n        operator.xor,\n    ],\n)\ndef test_proxy_binop_int(op):\n    _, p = _make_proxy(2)\n    assert op(p, 3) == op(2, 3)\n    # r-op\n    assert op(3, p) == op(3, 2)\n\n\n@pytest.mark.parametrize(\"op\", [operator.neg, operator.pos, abs, operator.invert])\ndef test_proxy_uop_int(op):\n    _, p = _make_proxy(-2)\n    assert op(p) == op(-2)\n\n\ndef test_proxy_numeric():\n    class Example:\n        def __complex__(self):\n            return 1 + 2j\n\n        def __int__(self):\n            return 1\n\n        def __float__(self):\n            return 2.1\n\n        def __round__(self, n=None):\n            if n is not None:\n                return 3.3\n\n            return 3\n\n        def __trunc__(self):\n            return 4\n\n        def __floor__(self):\n            return 5\n\n        def __ceil__(self):\n            return 6\n\n        def __index__(self):\n            return 2\n\n    _, p = _make_proxy(Example())\n    assert complex(p) == 1 + 2j\n    assert int(p) == 1\n    assert float(p) == 2.1\n    assert round(p) == 3\n    assert round(p, 2) == 3.3\n    assert math.trunc(p) == 4\n    assert math.floor(p) == 5\n    assert math.ceil(p) == 6\n    assert [1, 2, 3][p] == 3  # __index__\n\n\n@pytest.mark.parametrize(\n    \"op\",\n    [\n        operator.iadd,\n        operator.isub,\n        operator.imul,\n        operator.imatmul,\n        operator.itruediv,\n        operator.ifloordiv,\n        operator.imod,\n        operator.ipow,\n        operator.ilshift,\n        operator.irshift,\n        operator.iand,\n        operator.ior,\n        operator.ixor,\n    ],\n)\ndef test_proxy_iop(op):\n    class Example:\n        value = 1\n\n        def fake_op(self, other):\n            self.value = other\n            return self\n\n        __iadd__ = fake_op\n        __isub__ = fake_op\n        __imul__ = fake_op\n        __imatmul__ = fake_op\n        __itruediv__ = fake_op\n        __ifloordiv__ = fake_op\n        __imod__ = fake_op\n        __ipow__ = fake_op\n        __ilshift__ = fake_op\n        __irshift__ = fake_op\n        __iand__ = fake_op\n        __ior__ = fake_op\n        __ixor__ = fake_op\n\n    ns, p = _make_proxy(Example())\n    p_out = op(p, 2)\n    assert type(p_out) is local.LocalProxy\n    assert p.value == 2\n    assert ns.value.value == 2\n\n\ndef test_proxy_matmul():\n    class Example:\n        def __matmul__(self, other):\n            return 2 * other\n\n        def __rmatmul__(self, other):\n            return 2 * other\n\n    _, p = _make_proxy(Example())\n    assert p @ 3 == 6\n    assert 4 @ p == 8\n\n\ndef test_proxy_str():\n    _, p = _make_proxy(\"{act} %s\")\n    assert p + \" world\" == \"{act} %s world\"\n    assert \"say \" + p == \"say {act} %s\"\n    assert p * 2 == \"{act} %s{act} %s\"\n    assert 2 * p == p * 2\n    assert p % (\"world\",) == \"{act} world\"\n    assert p.format(act=\"test\") == \"test %s\"\n\n\ndef test_proxy_list():\n    _, p = _make_proxy([1, 2, 3])\n    assert len(p) == 3\n    assert p[0] == 1\n    assert 3 in p\n    assert 4 not in p\n    assert tuple(p) == (1, 2, 3)\n    assert list(reversed(p)) == [3, 2, 1]\n    p[0] = 4\n    assert p == [4, 2, 3]\n    del p[-1]\n    assert p == [4, 2]\n    p += [5]\n    assert p[-1] == 5\n    p *= 2\n    assert len(p) == 6\n    p[:] = []\n    assert not p\n    p.append(1)\n    assert p\n    assert p + [2] == [1, 2]\n    assert [2] + p == [2, 1]\n\n\ndef test_proxy_copy():\n    class Foo:\n        def __copy__(self):\n            return self\n\n        def __deepcopy__(self, memo):\n            return self\n\n    ns, p = _make_proxy(Foo())\n    assert copy.copy(p) is ns.value\n    assert copy.deepcopy(p) is ns.value\n\n    a = []\n    _, p = _make_proxy([a])\n    assert copy.copy(p) == [a]\n    assert copy.copy(p)[0] is a\n    assert copy.deepcopy(p) == [a]\n    assert copy.deepcopy(p)[0] is not a\n\n\ndef test_proxy_iterator():\n    a = [1, 2, 3]\n    _, p = _make_proxy(iter(a))\n    assert next(p) == 1\n\n\ndef test_proxy_length_hint():\n    class Example:\n        def __length_hint__(self):\n            return 2\n\n    _, p = _make_proxy(Example())\n    assert operator.length_hint(p) == 2\n\n\ndef test_proxy_context_manager():\n    class Example:\n        value = 2\n\n        def __enter__(self):\n            self.value += 1\n            return self\n\n        def __exit__(self, exc_type, exc_val, exc_tb):\n            self.value -= 1\n\n    _, p = _make_proxy(Example())\n    assert p.value == 2\n\n    with p:\n        assert p.value == 3\n\n    assert p.value == 2\n\n\ndef test_proxy_class():\n    class Meta(type):\n        def __instancecheck__(cls, instance):\n            return True\n\n        def __subclasscheck__(cls, subclass):\n            return True\n\n    class Parent:\n        pass\n\n    class Example(Parent, metaclass=Meta):\n        pass\n\n    class Child(Example):\n        pass\n\n    _, p = _make_proxy(Example)\n    assert type(p()) is Example\n    assert isinstance(1, p)\n    assert issubclass(int, p)\n    assert p.__mro__ == (Example, Parent, object)\n    assert p.__bases__ == (Parent,)\n    assert p.__subclasses__() == [Child]\n\n\ndef test_proxy_attributes():\n    class Example:\n        def __init__(self):\n            object.__setattr__(self, \"values\", {})\n\n        def __getattribute__(self, name):\n            if name == \"ham\":\n                return \"eggs\"\n\n            return super().__getattribute__(name)\n\n        def __getattr__(self, name):\n            return self.values.get(name)\n\n        def __setattr__(self, name, value):\n            self.values[name] = value\n\n        def __delattr__(self, name):\n            del self.values[name]\n\n        def __dir__(self):\n            return sorted(self.values.keys())\n\n    _, p = _make_proxy(Example())\n    assert p.nothing is None\n    assert p.__dict__ == {\"values\": {}}\n    assert dir(p) == []\n\n    p.x = 1\n    assert p.x == 1\n    assert dir(p) == [\"x\"]\n\n    del p.x\n    assert dir(p) == []\n\n    assert p.ham == \"eggs\"\n    p.ham = \"spam\"\n    assert p.ham == \"eggs\"\n    assert p.values[\"ham\"] == \"spam\"\n\n\ndef test_proxy_await():\n    async def get():\n        return 1\n\n    _, p = _make_proxy(get())\n\n    async def main():\n        return await p\n\n    out = asyncio.run(main())\n    assert out == 1\n\n\ndef test_proxy_aiter():\n    class Example:\n        value = 3\n\n        def __aiter__(self):\n            return self\n\n        async def __anext__(self):\n            if self.value:\n                self.value -= 1\n                return self.value\n\n            raise StopAsyncIteration\n\n    _, p = _make_proxy(Example())\n\n    async def main():\n        out = []\n\n        async for v in p:\n            out.append(v)\n\n        return out\n\n    out = asyncio.run(main())\n    assert out == [2, 1, 0]\n\n\ndef test_proxy_async_context_manager():\n    class Example:\n        value = 2\n\n        async def __aenter__(self):\n            self.value += 1\n            return self\n\n        async def __aexit__(self, exc_type, exc_val, exc_tb):\n            self.value -= 1\n\n    _, p = _make_proxy(Example())\n\n    async def main():\n        async with p:\n            assert p.value == 3\n\n        assert p.value == 2\n        return True\n\n    assert asyncio.run(main())\n", "tests/test_utils.py": "from __future__ import annotations\n\nimport inspect\nfrom datetime import datetime\n\nimport pytest\n\nfrom werkzeug import Request\nfrom werkzeug import utils\nfrom werkzeug.datastructures import Headers\nfrom werkzeug.http import http_date\nfrom werkzeug.http import parse_date\nfrom werkzeug.test import Client\nfrom werkzeug.test import EnvironBuilder\nfrom werkzeug.wrappers import Response\n\n\n@pytest.mark.parametrize(\n    (\"url\", \"code\", \"expect\"),\n    [\n        (\"http://example.com\", None, \"http://example.com\"),\n        (\"/f\u00fc\u00fcb\u00e4r\", 305, \"/f%C3%BC%C3%BCb%C3%A4r\"),\n        (\"http://\u2603.example.com/\", 307, \"http://xn--n3h.example.com/\"),\n        (\"itms-services://?url=abc\", None, \"itms-services://?url=abc\"),\n    ],\n)\ndef test_redirect(url: str, code: int | None, expect: str) -> None:\n    environ = EnvironBuilder().get_environ()\n\n    if code is None:\n        resp = utils.redirect(url)\n        assert resp.status_code == 302\n    else:\n        resp = utils.redirect(url, code)\n        assert resp.status_code == code\n\n    assert resp.headers[\"Location\"] == url\n    assert resp.get_wsgi_headers(environ)[\"Location\"] == expect\n    assert resp.get_data(as_text=True).count(url) == 2\n\n\ndef test_redirect_xss():\n    location = 'http://example.com/?xss=\"><script>alert(1)</script>'\n    resp = utils.redirect(location)\n    assert b\"<script>alert(1)</script>\" not in resp.get_data()\n\n    location = 'http://example.com/?xss=\"onmouseover=\"alert(1)'\n    resp = utils.redirect(location)\n    assert (\n        b'href=\"http://example.com/?xss=\"onmouseover=\"alert(1)\"' not in resp.get_data()\n    )\n\n\ndef test_redirect_with_custom_response_class():\n    class MyResponse(Response):\n        pass\n\n    location = \"http://example.com/redirect\"\n    resp = utils.redirect(location, Response=MyResponse)\n\n    assert isinstance(resp, MyResponse)\n    assert resp.headers[\"Location\"] == location\n\n\ndef test_cached_property():\n    foo = []\n\n    class A:\n        def prop(self):\n            foo.append(42)\n            return 42\n\n        prop = utils.cached_property(prop)\n\n    a = A()\n    p = a.prop\n    q = a.prop\n    assert p == q == 42\n    assert foo == [42]\n\n    foo = []\n\n    class A:\n        def _prop(self):\n            foo.append(42)\n            return 42\n\n        prop = utils.cached_property(_prop, name=\"prop\")\n        del _prop\n\n    a = A()\n    p = a.prop\n    q = a.prop\n    assert p == q == 42\n    assert foo == [42]\n\n\ndef test_can_set_cached_property():\n    class A:\n        @utils.cached_property\n        def _prop(self):\n            return \"cached_property return value\"\n\n    a = A()\n    a._prop = \"value\"\n    assert a._prop == \"value\"\n\n\ndef test_invalidate_cached_property():\n    accessed = 0\n\n    class A:\n        @utils.cached_property\n        def prop(self):\n            nonlocal accessed\n            accessed += 1\n            return 42\n\n    a = A()\n    p = a.prop\n    q = a.prop\n    assert p == q == 42\n    assert accessed == 1\n\n    a.prop = 16\n    assert a.prop == 16\n    assert accessed == 1\n\n    del a.prop\n    r = a.prop\n    assert r == 42\n    assert accessed == 2\n\n\ndef test_inspect_treats_cached_property_as_property():\n    class A:\n        @utils.cached_property\n        def _prop(self):\n            return \"cached_property return value\"\n\n    attrs = inspect.classify_class_attrs(A)\n    for attr in attrs:\n        if attr.name == \"_prop\":\n            break\n    assert attr.kind == \"property\"\n\n\ndef test_environ_property():\n    class A:\n        environ = {\"string\": \"abc\", \"number\": \"42\"}\n\n        string = utils.environ_property(\"string\")\n        missing = utils.environ_property(\"missing\", \"spam\")\n        read_only = utils.environ_property(\"number\")\n        number = utils.environ_property(\"number\", load_func=int)\n        broken_number = utils.environ_property(\"broken_number\", load_func=int)\n        date = utils.environ_property(\n            \"date\", None, parse_date, http_date, read_only=False\n        )\n        foo = utils.environ_property(\"foo\")\n\n    a = A()\n    assert a.string == \"abc\"\n    assert a.missing == \"spam\"\n\n    def test_assign():\n        a.read_only = \"something\"\n\n    pytest.raises(AttributeError, test_assign)\n    assert a.number == 42\n    assert a.broken_number is None\n    assert a.date is None\n    a.date = datetime(2008, 1, 22, 10, 0, 0, 0)\n    assert a.environ[\"date\"] == \"Tue, 22 Jan 2008 10:00:00 GMT\"\n\n\ndef test_import_string():\n    from datetime import date\n\n    from werkzeug.debug import DebuggedApplication\n\n    assert utils.import_string(\"datetime.date\") is date\n    assert utils.import_string(\"datetime.date\") is date\n    assert utils.import_string(\"datetime:date\") is date\n    assert utils.import_string(\"XXXXXXXXXXXX\", True) is None\n    assert utils.import_string(\"datetime.XXXXXXXXXXXX\", True) is None\n    assert (\n        utils.import_string(\"werkzeug.debug.DebuggedApplication\") is DebuggedApplication\n    )\n    pytest.raises(ImportError, utils.import_string, \"XXXXXXXXXXXXXXXX\")\n    pytest.raises(ImportError, utils.import_string, \"datetime.XXXXXXXXXX\")\n\n\ndef test_import_string_provides_traceback(tmpdir, monkeypatch):\n    monkeypatch.syspath_prepend(str(tmpdir))\n    # Couple of packages\n    dir_a = tmpdir.mkdir(\"a\")\n    dir_b = tmpdir.mkdir(\"b\")\n    # Totally packages, I promise\n    dir_a.join(\"__init__.py\").write(\"\")\n    dir_b.join(\"__init__.py\").write(\"\")\n    # 'aa.a' that depends on 'bb.b', which in turn has a broken import\n    dir_a.join(\"aa.py\").write(\"from b import bb\")\n    dir_b.join(\"bb.py\").write(\"from os import a_typo\")\n\n    # Do we get all the useful information in the traceback?\n    with pytest.raises(ImportError) as baz_exc:\n        utils.import_string(\"a.aa\")\n    traceback = \"\".join(str(line) for line in baz_exc.traceback)\n    assert \"bb.py':1\" in traceback  # a bit different than typical python tb\n    assert \"from os import a_typo\" in traceback\n\n\ndef test_import_string_attribute_error(tmpdir, monkeypatch):\n    monkeypatch.syspath_prepend(str(tmpdir))\n    tmpdir.join(\"foo_test.py\").write(\"from bar_test import value\")\n    tmpdir.join(\"bar_test.py\").write(\"raise AttributeError('bad')\")\n\n    with pytest.raises(AttributeError) as info:\n        utils.import_string(\"foo_test\")\n\n    assert \"bad\" in str(info.value)\n\n    with pytest.raises(AttributeError) as info:\n        utils.import_string(\"bar_test\")\n\n    assert \"bad\" in str(info.value)\n\n\ndef test_find_modules():\n    assert list(utils.find_modules(\"werkzeug.debug\")) == [\n        \"werkzeug.debug.console\",\n        \"werkzeug.debug.repr\",\n        \"werkzeug.debug.tbtools\",\n    ]\n\n\ndef test_header_set_duplication_bug():\n    headers = Headers([(\"Content-Type\", \"text/html\"), (\"Foo\", \"bar\"), (\"Blub\", \"blah\")])\n    headers[\"blub\"] = \"hehe\"\n    headers[\"blafasel\"] = \"humm\"\n    assert headers == Headers(\n        [\n            (\"Content-Type\", \"text/html\"),\n            (\"Foo\", \"bar\"),\n            (\"blub\", \"hehe\"),\n            (\"blafasel\", \"humm\"),\n        ]\n    )\n\n\n@pytest.mark.parametrize(\n    (\"path\", \"base_url\", \"absolute_location\"),\n    [\n        (\"foo\", \"http://example.org/app\", \"http://example.org/app/foo/\"),\n        (\"/foo\", \"http://example.org/app\", \"http://example.org/app/foo/\"),\n        (\"/foo/bar\", \"http://example.org/\", \"http://example.org/foo/bar/\"),\n        (\"/foo/bar\", \"http://example.org/app\", \"http://example.org/app/foo/bar/\"),\n        (\"/foo?baz\", \"http://example.org/\", \"http://example.org/foo/?baz\"),\n        (\"/foo/\", \"http://example.org/\", \"http://example.org/foo/\"),\n        (\"/foo/\", \"http://example.org/app\", \"http://example.org/app/foo/\"),\n        (\"/\", \"http://example.org/\", \"http://example.org/\"),\n        (\"/\", \"http://example.org/app\", \"http://example.org/app/\"),\n    ],\n)\n@pytest.mark.parametrize(\"autocorrect\", [False, True])\ndef test_append_slash_redirect(autocorrect, path, base_url, absolute_location):\n    @Request.application\n    def app(request):\n        rv = utils.append_slash_redirect(request.environ)\n        rv.autocorrect_location_header = autocorrect\n        return rv\n\n    client = Client(app)\n    response = client.get(path, base_url=base_url)\n    assert response.status_code == 308\n\n    if not autocorrect:\n        assert response.headers[\"Location\"].count(\"/\") == 1\n    else:\n        assert response.headers[\"Location\"] == absolute_location\n\n\ndef test_cached_property_doc():\n    @utils.cached_property\n    def foo():\n        \"\"\"testing\"\"\"\n        return 42\n\n    assert foo.__doc__ == \"testing\"\n    assert foo.__name__ == \"foo\"\n    assert foo.__module__ == __name__\n\n\ndef test_secure_filename():\n    assert utils.secure_filename(\"My cool movie.mov\") == \"My_cool_movie.mov\"\n    assert utils.secure_filename(\"../../../etc/passwd\") == \"etc_passwd\"\n    assert (\n        utils.secure_filename(\"i contain cool \\xfcml\\xe4uts.txt\")\n        == \"i_contain_cool_umlauts.txt\"\n    )\n    assert utils.secure_filename(\"__filename__\") == \"filename\"\n    assert utils.secure_filename(\"foo$&^*)bar\") == \"foobar\"\n", "tests/live_apps/run.py": "import json\nimport sys\nfrom importlib import import_module\n\nfrom werkzeug.serving import generate_adhoc_ssl_context\nfrom werkzeug.serving import run_simple\nfrom werkzeug.wrappers import Request\nfrom werkzeug.wrappers import Response\n\nname = sys.argv[1]\nmod = import_module(f\"{name}_app\")\n\n\n@Request.application\ndef app(request):\n    if request.path == \"/ensure\":\n        return Response()\n\n    return Response.from_app(mod.app, request.environ)\n\n\nkwargs = getattr(mod, \"kwargs\", {})\nkwargs.update(hostname=\"127.0.0.1\", port=5000, application=app)\nkwargs.update(json.loads(sys.argv[2]))\nssl_context = kwargs.get(\"ssl_context\")\n\nif ssl_context == \"custom\":\n    kwargs[\"ssl_context\"] = generate_adhoc_ssl_context()\nelif isinstance(ssl_context, list):\n    kwargs[\"ssl_context\"] = tuple(ssl_context)\n\nrun_simple(**kwargs)\n", "tests/live_apps/data_app.py": "import json\n\nfrom werkzeug.wrappers import Request\nfrom werkzeug.wrappers import Response\n\n\n@Request.application\ndef app(request: Request) -> Response:\n    return Response(\n        json.dumps(\n            {\n                \"environ\": request.environ,\n                \"form\": request.form.to_dict(),\n                \"files\": {k: v.read().decode() for k, v in request.files.items()},\n            },\n            default=lambda x: str(x),\n        ),\n        content_type=\"application/json\",\n    )\n", "tests/live_apps/standard_app.py": "import json\n\nfrom werkzeug.wrappers import Request\nfrom werkzeug.wrappers import Response\n\n\n@Request.application\ndef app(request):\n    if request.path == \"/crash\":\n        raise Exception(\"crash requested\")\n\n    return Response(\n        json.dumps(request.environ, default=lambda x: str(x)),\n        content_type=\"application/json\",\n    )\n", "tests/live_apps/streaming_app.py": "from werkzeug.wrappers import Request\nfrom werkzeug.wrappers import Response\n\n\n@Request.application\ndef app(request):\n    def gen():\n        for x in range(5):\n            yield f\"{x}\\n\"\n\n        if request.path == \"/crash\":\n            raise Exception(\"crash requested\")\n\n    return Response(gen())\n", "tests/live_apps/reloader_app.py": "import os\nimport sys\n\nfrom werkzeug import _reloader\nfrom werkzeug.wrappers import Request\nfrom werkzeug.wrappers import Response\n\n# Tox puts the tmp dir in the venv sys.prefix, patch the reloader so\n# it doesn't skip real_app.\nif \"TOX_ENV_DIR\" in os.environ:\n    _reloader._stat_ignore_scan = tuple(\n        set(_reloader._stat_ignore_scan) - {sys.prefix, sys.exec_prefix}\n    )\n\n\n@Request.application\ndef app(request):\n    import real_app  # type: ignore\n\n    return Response.from_app(real_app.app, request.environ)\n\n\nkwargs = {\"use_reloader\": True, \"reloader_interval\": 0.1}\n", "tests/middleware/test_shared_data.py": "import os\nfrom contextlib import closing\n\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.test import create_environ\nfrom werkzeug.test import run_wsgi_app\n\n\ndef test_get_file_loader():\n    app = SharedDataMiddleware(None, {})\n    assert callable(app.get_file_loader(\"foo\"))\n\n\ndef test_shared_data_middleware(tmpdir):\n    def null_application(environ, start_response):\n        start_response(\"404 NOT FOUND\", [(\"Content-Type\", \"text/plain\")])\n        yield b\"NOT FOUND\"\n\n    test_dir = str(tmpdir)\n\n    with open(os.path.join(test_dir, \"\u00e4\u00f6\u00fc\"), \"w\") as test_file:\n        test_file.write(\"FOUND\")\n\n    for t in [list, dict]:\n        app = SharedDataMiddleware(\n            null_application,\n            t(\n                [\n                    (\"/\", os.path.join(os.path.dirname(__file__), \"..\", \"res\")),\n                    (\"/sources\", os.path.join(os.path.dirname(__file__), \"..\", \"res\")),\n                    (\"/pkg\", (\"werkzeug.debug\", \"shared\")),\n                    (\"/foo\", test_dir),\n                ]\n            ),\n        )\n\n        for p in \"/test.txt\", \"/sources/test.txt\", \"/foo/\u00e4\u00f6\u00fc\":\n            app_iter, status, headers = run_wsgi_app(app, create_environ(p))\n            assert status == \"200 OK\"\n\n            if p.endswith(\".txt\"):\n                content_type = next(v for k, v in headers if k == \"Content-Type\")\n                assert content_type == \"text/plain; charset=utf-8\"\n\n            with closing(app_iter) as app_iter:\n                data = b\"\".join(app_iter).strip()\n\n            assert data == b\"FOUND\"\n\n        app_iter, status, headers = run_wsgi_app(\n            app, create_environ(\"/pkg/debugger.js\")\n        )\n\n        with closing(app_iter) as app_iter:\n            contents = b\"\".join(app_iter)\n\n        assert b\"docReady(() =>\" in contents\n\n        for path in (\"/missing\", \"/pkg\", \"/pkg/\", \"/pkg/missing.txt\"):\n            app_iter, status, headers = run_wsgi_app(app, create_environ(path))\n            assert status == \"404 NOT FOUND\"\n            assert b\"\".join(app_iter).strip() == b\"NOT FOUND\"\n", "tests/middleware/test_dispatcher.py": "from werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.test import create_environ\nfrom werkzeug.test import run_wsgi_app\n\n\ndef test_dispatcher():\n    def null_application(environ, start_response):\n        start_response(\"404 NOT FOUND\", [(\"Content-Type\", \"text/plain\")])\n        yield b\"NOT FOUND\"\n\n    def dummy_application(environ, start_response):\n        start_response(\"200 OK\", [(\"Content-Type\", \"text/plain\")])\n        yield environ[\"SCRIPT_NAME\"].encode()\n\n    app = DispatcherMiddleware(\n        null_application,\n        {\"/test1\": dummy_application, \"/test2/very\": dummy_application},\n    )\n    tests = {\n        \"/test1\": (\"/test1\", \"/test1/asfd\", \"/test1/very\"),\n        \"/test2/very\": (\"/test2/very\", \"/test2/very/long/path/after/script/name\"),\n    }\n\n    for name, urls in tests.items():\n        for p in urls:\n            environ = create_environ(p)\n            app_iter, status, headers = run_wsgi_app(app, environ)\n            assert status == \"200 OK\"\n            assert b\"\".join(app_iter).strip() == name.encode()\n\n    app_iter, status, headers = run_wsgi_app(app, create_environ(\"/missing\"))\n    assert status == \"404 NOT FOUND\"\n    assert b\"\".join(app_iter).strip() == b\"NOT FOUND\"\n", "tests/middleware/test_profiler.py": "import datetime\nimport os\nfrom unittest.mock import ANY\nfrom unittest.mock import MagicMock\nfrom unittest.mock import patch\n\nfrom werkzeug.middleware.profiler import Profile\nfrom werkzeug.middleware.profiler import ProfilerMiddleware\nfrom werkzeug.test import Client\n\n\ndef dummy_application(environ, start_response):\n    start_response(\"200 OK\", [(\"Content-Type\", \"text/plain\")])\n    return [b\"Foo\"]\n\n\ndef test_filename_format_function():\n    # This should be called once with the generated file name\n    mock_capture_name = MagicMock()\n\n    def filename_format(env):\n        now = datetime.datetime.fromtimestamp(env[\"werkzeug.profiler\"][\"time\"])\n        timestamp = now.strftime(\"%Y-%m-%d:%H:%M:%S\")\n        path = (\n            \"_\".join(token for token in env[\"PATH_INFO\"].split(\"/\") if token) or \"ROOT\"\n        )\n        elapsed = env[\"werkzeug.profiler\"][\"elapsed\"]\n        name = f\"{timestamp}.{env['REQUEST_METHOD']}.{path}.{elapsed:.0f}ms.prof\"\n        mock_capture_name(name=name)\n        return name\n\n    client = Client(\n        ProfilerMiddleware(\n            dummy_application,\n            stream=None,\n            profile_dir=\"profiles\",\n            filename_format=filename_format,\n        )\n    )\n\n    # Replace the Profile class with a function that simulates an __init__()\n    # call and returns our mock instance.\n    mock_profile = MagicMock(wraps=Profile())\n    mock_profile.dump_stats = MagicMock()\n    with patch(\"werkzeug.middleware.profiler.Profile\", lambda: mock_profile):\n        client.get(\"/foo/bar\")\n\n        mock_capture_name.assert_called_once_with(name=ANY)\n        name = mock_capture_name.mock_calls[0].kwargs[\"name\"]\n        mock_profile.dump_stats.assert_called_once_with(os.path.join(\"profiles\", name))\n", "tests/middleware/test_proxy_fix.py": "import pytest\n\nfrom werkzeug.middleware.proxy_fix import ProxyFix\nfrom werkzeug.routing import Map\nfrom werkzeug.routing import Rule\nfrom werkzeug.test import Client\nfrom werkzeug.test import create_environ\nfrom werkzeug.utils import redirect\nfrom werkzeug.wrappers import Request\nfrom werkzeug.wrappers import Response\n\n\n@pytest.mark.parametrize(\n    (\"kwargs\", \"base\", \"url_root\"),\n    (\n        pytest.param(\n            {},\n            {\n                \"REMOTE_ADDR\": \"192.168.0.2\",\n                \"HTTP_HOST\": \"spam\",\n                \"HTTP_X_FORWARDED_FOR\": \"192.168.0.1\",\n                \"HTTP_X_FORWARDED_PROTO\": \"https\",\n            },\n            \"https://spam/\",\n            id=\"for\",\n        ),\n        pytest.param(\n            {\"x_proto\": 1},\n            {\"HTTP_HOST\": \"spam\", \"HTTP_X_FORWARDED_PROTO\": \"https\"},\n            \"https://spam/\",\n            id=\"proto\",\n        ),\n        pytest.param(\n            {\"x_host\": 1},\n            {\"HTTP_HOST\": \"spam\", \"HTTP_X_FORWARDED_HOST\": \"eggs\"},\n            \"http://eggs/\",\n            id=\"host\",\n        ),\n        pytest.param(\n            {\"x_port\": 1},\n            {\"HTTP_HOST\": \"spam\", \"HTTP_X_FORWARDED_PORT\": \"8080\"},\n            \"http://spam:8080/\",\n            id=\"port, host without port\",\n        ),\n        pytest.param(\n            {\"x_port\": 1},\n            {\"HTTP_HOST\": \"spam:9000\", \"HTTP_X_FORWARDED_PORT\": \"8080\"},\n            \"http://spam:8080/\",\n            id=\"port, host with port\",\n        ),\n        pytest.param(\n            {\"x_port\": 1},\n            {\n                \"SERVER_NAME\": \"spam\",\n                \"SERVER_PORT\": \"9000\",\n                \"HTTP_X_FORWARDED_PORT\": \"8080\",\n            },\n            \"http://spam:8080/\",\n            id=\"port, name\",\n        ),\n        pytest.param(\n            {\"x_prefix\": 1},\n            {\"HTTP_HOST\": \"spam\", \"HTTP_X_FORWARDED_PREFIX\": \"/eggs\"},\n            \"http://spam/eggs/\",\n            id=\"prefix\",\n        ),\n        pytest.param(\n            {\"x_for\": 1, \"x_proto\": 1, \"x_host\": 1, \"x_port\": 1, \"x_prefix\": 1},\n            {\n                \"REMOTE_ADDR\": \"192.168.0.2\",\n                \"HTTP_HOST\": \"spam:9000\",\n                \"HTTP_X_FORWARDED_FOR\": \"192.168.0.1\",\n                \"HTTP_X_FORWARDED_PROTO\": \"https\",\n                \"HTTP_X_FORWARDED_HOST\": \"eggs\",\n                \"HTTP_X_FORWARDED_PORT\": \"443\",\n                \"HTTP_X_FORWARDED_PREFIX\": \"/ham\",\n            },\n            \"https://eggs/ham/\",\n            id=\"all\",\n        ),\n        pytest.param(\n            {\"x_for\": 2},\n            {\n                \"REMOTE_ADDR\": \"192.168.0.3\",\n                \"HTTP_HOST\": \"spam\",\n                \"HTTP_X_FORWARDED_FOR\": \"192.168.0.1, 192.168.0.2\",\n            },\n            \"http://spam/\",\n            id=\"multiple for\",\n        ),\n        pytest.param(\n            {\"x_for\": 0},\n            {\n                \"REMOTE_ADDR\": \"192.168.0.1\",\n                \"HTTP_HOST\": \"spam\",\n                \"HTTP_X_FORWARDED_FOR\": \"192.168.0.2\",\n            },\n            \"http://spam/\",\n            id=\"ignore 0\",\n        ),\n        pytest.param(\n            {\"x_for\": 3},\n            {\n                \"REMOTE_ADDR\": \"192.168.0.1\",\n                \"HTTP_HOST\": \"spam\",\n                \"HTTP_X_FORWARDED_FOR\": \"192.168.0.3, 192.168.0.2\",\n            },\n            \"http://spam/\",\n            id=\"ignore len < trusted\",\n        ),\n        pytest.param(\n            {},\n            {\n                \"REMOTE_ADDR\": \"192.168.0.2\",\n                \"HTTP_HOST\": \"spam\",\n                \"HTTP_X_FORWARDED_FOR\": \"192.168.0.3, 192.168.0.1\",\n            },\n            \"http://spam/\",\n            id=\"ignore untrusted\",\n        ),\n        pytest.param(\n            {\"x_for\": 2},\n            {\n                \"REMOTE_ADDR\": \"192.168.0.1\",\n                \"HTTP_HOST\": \"spam\",\n                \"HTTP_X_FORWARDED_FOR\": \", 192.168.0.3\",\n            },\n            \"http://spam/\",\n            id=\"ignore empty\",\n        ),\n        pytest.param(\n            {\"x_for\": 2, \"x_prefix\": 1},\n            {\n                \"REMOTE_ADDR\": \"192.168.0.2\",\n                \"HTTP_HOST\": \"spam\",\n                \"HTTP_X_FORWARDED_FOR\": \"192.168.0.1, 192.168.0.3\",\n                \"HTTP_X_FORWARDED_PREFIX\": \"/ham, /eggs\",\n            },\n            \"http://spam/eggs/\",\n            id=\"prefix < for\",\n        ),\n        pytest.param(\n            {\"x_host\": 1},\n            {\"HTTP_HOST\": \"spam\", \"HTTP_X_FORWARDED_HOST\": \"[2001:db8::a]\"},\n            \"http://[2001:db8::a]/\",\n            id=\"ipv6 host\",\n        ),\n        pytest.param(\n            {\"x_port\": 1},\n            {\"HTTP_HOST\": \"[2001:db8::a]\", \"HTTP_X_FORWARDED_PORT\": \"8080\"},\n            \"http://[2001:db8::a]:8080/\",\n            id=\"ipv6 port, host without port\",\n        ),\n        pytest.param(\n            {\"x_port\": 1},\n            {\"HTTP_HOST\": \"[2001:db8::a]:9000\", \"HTTP_X_FORWARDED_PORT\": \"8080\"},\n            \"http://[2001:db8::a]:8080/\",\n            id=\"ipv6 - port, host with port\",\n        ),\n    ),\n)\ndef test_proxy_fix(monkeypatch, kwargs, base, url_root):\n    monkeypatch.setattr(Response, \"autocorrect_location_header\", True)\n\n    @Request.application\n    def app(request):\n        # for header\n        assert request.remote_addr == \"192.168.0.1\"\n        # proto, host, port, prefix headers\n        assert request.url_root == url_root\n\n        urls = url_map.bind_to_environ(request.environ)\n        parrot_url = urls.build(\"parrot\")\n        # build includes prefix\n        assert urls.build(\"parrot\") == \"/\".join((request.script_root, \"parrot\"))\n        # match doesn't include prefix\n        assert urls.match(\"/parrot\")[0] == \"parrot\"\n\n        # With autocorrect_location_header enabled, location header will\n        # start with url_root\n        return redirect(parrot_url)\n\n    url_map = Map([Rule(\"/parrot\", endpoint=\"parrot\")])\n    app = ProxyFix(app, **kwargs)\n\n    base.setdefault(\"REMOTE_ADDR\", \"192.168.0.1\")\n    environ = create_environ(environ_overrides=base)\n\n    # host is always added, remove it if the test doesn't set it\n    if \"HTTP_HOST\" not in base:\n        del environ[\"HTTP_HOST\"]\n\n    response = Client(app).open(Request(environ))\n    assert response.location == f\"{url_root}parrot\"\n", "tests/middleware/test_lint.py": "import pytest\n\nfrom werkzeug.middleware.lint import HTTPWarning\nfrom werkzeug.middleware.lint import LintMiddleware\nfrom werkzeug.middleware.lint import WSGIWarning\nfrom werkzeug.test import create_environ\nfrom werkzeug.test import run_wsgi_app\n\n\ndef dummy_application(environ, start_response):\n    start_response(\"200 OK\", [(\"Content-Type\", \"text/plain\")])\n    return [b\"Foo\"]\n\n\ndef test_lint_middleware():\n    \"\"\"Test lint middleware runs for a dummy applications without warnings\"\"\"\n    app = LintMiddleware(dummy_application)\n\n    environ = create_environ(\"/test\")\n    app_iter, status, headers = run_wsgi_app(app, environ, buffered=True)\n    assert status == \"200 OK\"\n\n\n@pytest.mark.parametrize(\n    \"key, value, message\",\n    [\n        (\"wsgi.version\", (0, 7), \"Environ is not a WSGI 1.0 environ.\"),\n        (\"SCRIPT_NAME\", \"test\", \"'SCRIPT_NAME' does not start with a slash:\"),\n        (\"PATH_INFO\", \"test\", \"'PATH_INFO' does not start with a slash:\"),\n    ],\n)\ndef test_lint_middleware_check_environ(key, value, message):\n    app = LintMiddleware(dummy_application)\n\n    environ = create_environ(\"/test\")\n    environ[key] = value\n    with pytest.warns(WSGIWarning, match=message):\n        app_iter, status, headers = run_wsgi_app(app, environ, buffered=True)\n    assert status == \"200 OK\"\n\n\ndef test_lint_middleware_invalid_status():\n    def my_dummy_application(environ, start_response):\n        start_response(\"20 OK\", [(\"Content-Type\", \"text/plain\")])\n        return [b\"Foo\"]\n\n    app = LintMiddleware(my_dummy_application)\n\n    environ = create_environ(\"/test\")\n    with pytest.warns(WSGIWarning) as record:\n        run_wsgi_app(app, environ, buffered=True)\n\n    # Returning status 20 should raise three different warnings\n    assert len(record) == 3\n\n\n@pytest.mark.parametrize(\n    \"headers, message\",\n    [\n        (tuple([(\"Content-Type\", \"text/plain\")]), \"Header list is not a list.\"),\n        ([\"fo\"], \"Header items must be 2-item tuples.\"),\n        ([(\"status\", \"foo\")], \"The status header is not supported.\"),\n    ],\n)\ndef test_lint_middleware_http_headers(headers, message):\n    def my_dummy_application(environ, start_response):\n        start_response(\"200 OK\", headers)\n        return [b\"Foo\"]\n\n    app = LintMiddleware(my_dummy_application)\n\n    environ = create_environ(\"/test\")\n    with pytest.warns(WSGIWarning, match=message):\n        run_wsgi_app(app, environ, buffered=True)\n\n\ndef test_lint_middleware_invalid_location():\n    def my_dummy_application(environ, start_response):\n        start_response(\"200 OK\", [(\"location\", \"foo\")])\n        return [b\"Foo\"]\n\n    app = LintMiddleware(my_dummy_application)\n\n    environ = create_environ(\"/test\")\n    with pytest.warns(HTTPWarning, match=\"Absolute URLs required for location header.\"):\n        run_wsgi_app(app, environ, buffered=True)\n", "tests/middleware/test_http_proxy.py": "import pytest\n\nfrom werkzeug.middleware.http_proxy import ProxyMiddleware\nfrom werkzeug.test import Client\nfrom werkzeug.wrappers import Response\n\n\n@pytest.mark.filterwarnings(\"ignore::pytest.PytestUnraisableExceptionWarning\")\n@pytest.mark.dev_server\ndef test_http_proxy(standard_app):\n    app = ProxyMiddleware(\n        Response(\"ROOT\"),\n        {\n            \"/foo\": {\n                \"target\": standard_app.url,\n                \"host\": \"faked.invalid\",\n                \"headers\": {\"X-Special\": \"foo\"},\n            },\n            \"/bar\": {\n                \"target\": standard_app.url,\n                \"host\": None,\n                \"remove_prefix\": True,\n                \"headers\": {\"X-Special\": \"bar\"},\n            },\n            \"/autohost\": {\"target\": standard_app.url},\n        },\n    )\n\n    client = Client(app)\n\n    r = client.get(\"/\")\n    assert r.data == b\"ROOT\"\n\n    r = client.get(\"/foo/bar\")\n    assert r.json[\"HTTP_X_SPECIAL\"] == \"foo\"\n    assert r.json[\"HTTP_HOST\"] == \"faked.invalid\"\n    assert r.json[\"PATH_INFO\"] == \"/foo/bar\"\n\n    r = client.get(\"/bar/baz?a=a&b=b\")\n    assert r.json[\"HTTP_X_SPECIAL\"] == \"bar\"\n    assert r.json[\"HTTP_HOST\"] == \"localhost\"\n    assert r.json[\"PATH_INFO\"] == \"/baz\"\n    assert r.json[\"QUERY_STRING\"] == \"a=a&b=b\"\n\n    r = client.get(\"/autohost/aha\")\n    assert \"HTTP_X_SPECIAL\" not in r.json\n    assert r.json[\"HTTP_HOST\"] == \"127.0.0.1\"\n    assert r.json[\"PATH_INFO\"] == \"/autohost/aha\"\n\n    # test if characters allowed in URL are not encoded by proxy\n    r = client.get(\"/autohost/$\")\n    assert r.json[\"REQUEST_URI\"] == \"/autohost/$\"\n", "tests/sansio/test_request.py": "import typing as t\n\nimport pytest\n\nfrom werkzeug.datastructures import Headers\nfrom werkzeug.sansio.request import Request\n\n\n@pytest.mark.parametrize(\n    \"headers, expected\",\n    [\n        (Headers({\"Transfer-Encoding\": \"chunked\", \"Content-Length\": \"6\"}), None),\n        (Headers({\"Transfer-Encoding\": \"something\", \"Content-Length\": \"6\"}), 6),\n        (Headers({\"Content-Length\": \"6\"}), 6),\n        (Headers({\"Content-Length\": \"-6\"}), 0),\n        (Headers({\"Content-Length\": \"+123\"}), 0),\n        (Headers({\"Content-Length\": \"1_23\"}), 0),\n        (Headers({\"Content-Length\": \"\ud83e\udff1\ud83e\udff2\ud83e\udff3\"}), 0),\n        (Headers(), None),\n    ],\n)\ndef test_content_length(headers: Headers, expected: t.Optional[int]) -> None:\n    req = Request(\"POST\", \"http\", None, \"\", \"\", b\"\", headers, None)\n    assert req.content_length == expected\n\n\ndef test_cookies() -> None:\n    headers = Headers([(\"Cookie\", \"a=b\"), (\"Content-Type\", \"text\"), (\"Cookie\", \"a=c\")])\n    req = Request(\"GET\", \"http\", None, \"\", \"\", b\"\", headers, None)\n    assert req.cookies.get(\"a\") == \"b\"\n    assert req.cookies.getlist(\"a\") == [\"b\", \"c\"]\n", "tests/sansio/__init__.py": "", "tests/sansio/test_multipart.py": "import pytest\n\nfrom werkzeug.datastructures import Headers\nfrom werkzeug.sansio.multipart import Data\nfrom werkzeug.sansio.multipart import Epilogue\nfrom werkzeug.sansio.multipart import Field\nfrom werkzeug.sansio.multipart import File\nfrom werkzeug.sansio.multipart import MultipartDecoder\nfrom werkzeug.sansio.multipart import MultipartEncoder\nfrom werkzeug.sansio.multipart import NeedData\nfrom werkzeug.sansio.multipart import Preamble\n\n\ndef test_decoder_simple() -> None:\n    boundary = b\"---------------------------9704338192090380615194531385$\"\n    decoder = MultipartDecoder(boundary)\n    data = \"\"\"\n-----------------------------9704338192090380615194531385$\nContent-Disposition: form-data; name=\"fname\"\n\n\u00df\u2211\u0153\u00df\u2202\u0192\u00e5\u2202\n-----------------------------9704338192090380615194531385$\nContent-Disposition: form-data; name=\"lname\"; filename=\"bob\"\n\nasdasd\n-----------------------------9704338192090380615194531385$--\n    \"\"\".replace(\"\\n\", \"\\r\\n\").encode()\n    decoder.receive_data(data)\n    decoder.receive_data(None)\n    events = [decoder.next_event()]\n    while not isinstance(events[-1], Epilogue):\n        events.append(decoder.next_event())\n    assert events == [\n        Preamble(data=b\"\"),\n        Field(\n            name=\"fname\",\n            headers=Headers([(\"Content-Disposition\", 'form-data; name=\"fname\"')]),\n        ),\n        Data(data=\"\u00df\u2211\u0153\u00df\u2202\u0192\u00e5\u2202\".encode(), more_data=False),\n        File(\n            name=\"lname\",\n            filename=\"bob\",\n            headers=Headers(\n                [(\"Content-Disposition\", 'form-data; name=\"lname\"; filename=\"bob\"')]\n            ),\n        ),\n        Data(data=b\"asdasd\", more_data=False),\n        Epilogue(data=b\"    \"),\n    ]\n    encoder = MultipartEncoder(boundary)\n    result = b\"\"\n    for event in events:\n        result += encoder.send_event(event)\n    assert data == result\n\n\n@pytest.mark.parametrize(\n    \"data_start\",\n    [\n        b\"A\",\n        b\"\\n\",\n        b\"\\r\",\n        b\"\\r\\n\",\n        b\"\\n\\r\",\n        b\"A\\n\",\n        b\"A\\r\",\n        b\"A\\r\\n\",\n        b\"A\\n\\r\",\n    ],\n)\n@pytest.mark.parametrize(\"data_end\", [b\"\", b\"\\r\\n--foo\"])\ndef test_decoder_data_start_with_different_newline_positions(\n    data_start: bytes, data_end: bytes\n) -> None:\n    boundary = b\"foo\"\n    data = (\n        b\"\\r\\n--foo\\r\\n\"\n        b'Content-Disposition: form-data; name=\"test\"; filename=\"testfile\"\\r\\n'\n        b\"Content-Type: application/octet-stream\\r\\n\\r\\n\"\n        b\"\" + data_start + b\"\\r\\nBCDE\" + data_end\n    )\n    decoder = MultipartDecoder(boundary)\n    decoder.receive_data(data)\n    events = [decoder.next_event()]\n    # We want to check up to data start event\n    while not isinstance(events[-1], Data):\n        events.append(decoder.next_event())\n    expected = data_start if data_end == b\"\" else data_start + b\"\\r\\nBCDE\"\n    assert events == [\n        Preamble(data=b\"\"),\n        File(\n            name=\"test\",\n            filename=\"testfile\",\n            headers=Headers(\n                [\n                    (\n                        \"Content-Disposition\",\n                        'form-data; name=\"test\"; filename=\"testfile\"',\n                    ),\n                    (\"Content-Type\", \"application/octet-stream\"),\n                ]\n            ),\n        ),\n        Data(data=expected, more_data=True),\n    ]\n\n\ndef test_chunked_boundaries() -> None:\n    boundary = b\"--boundary\"\n    decoder = MultipartDecoder(boundary)\n    decoder.receive_data(b\"--\")\n    assert isinstance(decoder.next_event(), NeedData)\n    decoder.receive_data(b\"--boundary\\r\\n\")\n    assert isinstance(decoder.next_event(), Preamble)\n    decoder.receive_data(b\"Content-Disposition: form-data;\")\n    assert isinstance(decoder.next_event(), NeedData)\n    decoder.receive_data(b'name=\"fname\"\\r\\n\\r\\n')\n    assert isinstance(decoder.next_event(), Field)\n    decoder.receive_data(b\"longer than the boundary\")\n    assert isinstance(decoder.next_event(), Data)\n    decoder.receive_data(b\"also longer, but includes a linebreak\\r\\n--\")\n    assert isinstance(decoder.next_event(), Data)\n    assert isinstance(decoder.next_event(), NeedData)\n    decoder.receive_data(b\"--boundary--\\r\\n\")\n    event = decoder.next_event()\n    assert isinstance(event, Data)\n    assert not event.more_data\n    decoder.receive_data(None)\n    assert isinstance(decoder.next_event(), Epilogue)\n\n\ndef test_empty_field() -> None:\n    boundary = b\"foo\"\n    decoder = MultipartDecoder(boundary)\n    data = \"\"\"\n--foo\nContent-Disposition: form-data; name=\"text\"\nContent-Type: text/plain; charset=\"UTF-8\"\n\nSome Text\n--foo\nContent-Disposition: form-data; name=\"empty\"\nContent-Type: text/plain; charset=\"UTF-8\"\n\n--foo--\n    \"\"\".replace(\"\\n\", \"\\r\\n\").encode()\n    decoder.receive_data(data)\n    decoder.receive_data(None)\n    events = [decoder.next_event()]\n    while not isinstance(events[-1], Epilogue):\n        events.append(decoder.next_event())\n    assert events == [\n        Preamble(data=b\"\"),\n        Field(\n            name=\"text\",\n            headers=Headers(\n                [\n                    (\"Content-Disposition\", 'form-data; name=\"text\"'),\n                    (\"Content-Type\", 'text/plain; charset=\"UTF-8\"'),\n                ]\n            ),\n        ),\n        Data(data=b\"Some Text\", more_data=False),\n        Field(\n            name=\"empty\",\n            headers=Headers(\n                [\n                    (\"Content-Disposition\", 'form-data; name=\"empty\"'),\n                    (\"Content-Type\", 'text/plain; charset=\"UTF-8\"'),\n                ]\n            ),\n        ),\n        Data(data=b\"\", more_data=False),\n        Epilogue(data=b\"    \"),\n    ]\n    encoder = MultipartEncoder(boundary)\n    result = b\"\"\n    for event in events:\n        result += encoder.send_event(event)\n    assert data == result\n", "tests/sansio/test_utils.py": "from __future__ import annotations\n\nimport pytest\n\nfrom werkzeug.sansio.utils import get_content_length\nfrom werkzeug.sansio.utils import get_host\n\n\n@pytest.mark.parametrize(\n    (\"scheme\", \"host_header\", \"server\", \"expected\"),\n    [\n        (\"http\", \"spam\", None, \"spam\"),\n        (\"http\", \"spam:80\", None, \"spam\"),\n        (\"https\", \"spam\", None, \"spam\"),\n        (\"https\", \"spam:443\", None, \"spam\"),\n        (\"http\", \"spam:8080\", None, \"spam:8080\"),\n        (\"ws\", \"spam\", None, \"spam\"),\n        (\"ws\", \"spam:80\", None, \"spam\"),\n        (\"wss\", \"spam\", None, \"spam\"),\n        (\"wss\", \"spam:443\", None, \"spam\"),\n        (\"http\", None, (\"spam\", 80), \"spam\"),\n        (\"http\", None, (\"spam\", 8080), \"spam:8080\"),\n        (\"http\", None, (\"unix/socket\", None), \"unix/socket\"),\n        (\"http\", \"spam\", (\"eggs\", 80), \"spam\"),\n    ],\n)\ndef test_get_host(\n    scheme: str,\n    host_header: str | None,\n    server: tuple[str, int | None] | None,\n    expected: str,\n) -> None:\n    assert get_host(scheme, host_header, server) == expected\n\n\n@pytest.mark.parametrize(\n    (\"http_content_length\", \"http_transfer_encoding\", \"expected\"),\n    [\n        (\"2\", None, 2),\n        (\" 2\", None, 2),\n        (\"2 \", None, 2),\n        (None, None, None),\n        (None, \"chunked\", None),\n        (\"a\", None, 0),\n        (\"-2\", None, 0),\n    ],\n)\ndef test_get_content_length(\n    http_content_length: str | None,\n    http_transfer_encoding: str | None,\n    expected: int | None,\n) -> None:\n    assert get_content_length(http_content_length, http_transfer_encoding) == expected\n", "src/werkzeug/serving.py": "\"\"\"A WSGI and HTTP server for use **during development only**. This\nserver is convenient to use, but is not designed to be particularly\nstable, secure, or efficient. Use a dedicate WSGI server and HTTP\nserver when deploying to production.\n\nIt provides features like interactive debugging and code reloading. Use\n``run_simple`` to start the server. Put this in a ``run.py`` script:\n\n.. code-block:: python\n\n    from myapp import create_app\n    from werkzeug import run_simple\n\"\"\"\n\nfrom __future__ import annotations\n\nimport errno\nimport io\nimport os\nimport selectors\nimport socket\nimport socketserver\nimport sys\nimport typing as t\nfrom datetime import datetime as dt\nfrom datetime import timedelta\nfrom datetime import timezone\nfrom http.server import BaseHTTPRequestHandler\nfrom http.server import HTTPServer\nfrom urllib.parse import unquote\nfrom urllib.parse import urlsplit\n\nfrom ._internal import _log\nfrom ._internal import _wsgi_encoding_dance\nfrom .exceptions import InternalServerError\nfrom .urls import uri_to_iri\n\ntry:\n    import ssl\nexcept ImportError:\n\n    class _SslDummy:\n        def __getattr__(self, name: str) -> t.Any:\n            raise RuntimeError(  # noqa: B904\n                \"SSL is unavailable because this Python runtime was not\"\n                \" compiled with SSL/TLS support.\"\n            )\n\n    ssl = _SslDummy()  # type: ignore\n\n_log_add_style = True\n\nif os.name == \"nt\":\n    try:\n        __import__(\"colorama\")\n    except ImportError:\n        _log_add_style = False\n\ncan_fork = hasattr(os, \"fork\")\n\nif can_fork:\n    ForkingMixIn = socketserver.ForkingMixIn\nelse:\n\n    class ForkingMixIn:  # type: ignore\n        pass\n\n\ntry:\n    af_unix = socket.AF_UNIX\nexcept AttributeError:\n    af_unix = None  # type: ignore\n\nLISTEN_QUEUE = 128\n\n_TSSLContextArg = t.Optional[\n    t.Union[\"ssl.SSLContext\", t.Tuple[str, t.Optional[str]], t.Literal[\"adhoc\"]]\n]\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n    from cryptography.hazmat.primitives.asymmetric.rsa import (\n        RSAPrivateKeyWithSerialization,\n    )\n    from cryptography.x509 import Certificate\n\n\nclass DechunkedInput(io.RawIOBase):\n    \"\"\"An input stream that handles Transfer-Encoding 'chunked'\"\"\"\n\n    def __init__(self, rfile: t.IO[bytes]) -> None:\n        self._rfile = rfile\n        self._done = False\n        self._len = 0\n\n    def readable(self) -> bool:\n        return True\n\n    def read_chunk_len(self) -> int:\n        try:\n            line = self._rfile.readline().decode(\"latin1\")\n            _len = int(line.strip(), 16)\n        except ValueError as e:\n            raise OSError(\"Invalid chunk header\") from e\n        if _len < 0:\n            raise OSError(\"Negative chunk length not allowed\")\n        return _len\n\n    def readinto(self, buf: bytearray) -> int:  # type: ignore\n        read = 0\n        while not self._done and read < len(buf):\n            if self._len == 0:\n                # This is the first chunk or we fully consumed the previous\n                # one. Read the next length of the next chunk\n                self._len = self.read_chunk_len()\n\n            if self._len == 0:\n                # Found the final chunk of size 0. The stream is now exhausted,\n                # but there is still a final newline that should be consumed\n                self._done = True\n\n            if self._len > 0:\n                # There is data (left) in this chunk, so append it to the\n                # buffer. If this operation fully consumes the chunk, this will\n                # reset self._len to 0.\n                n = min(len(buf), self._len)\n\n                # If (read + chunk size) becomes more than len(buf), buf will\n                # grow beyond the original size and read more data than\n                # required. So only read as much data as can fit in buf.\n                if read + n > len(buf):\n                    buf[read:] = self._rfile.read(len(buf) - read)\n                    self._len -= len(buf) - read\n                    read = len(buf)\n                else:\n                    buf[read : read + n] = self._rfile.read(n)\n                    self._len -= n\n                    read += n\n\n            if self._len == 0:\n                # Skip the terminating newline of a chunk that has been fully\n                # consumed. This also applies to the 0-sized final chunk\n                terminator = self._rfile.readline()\n                if terminator not in (b\"\\n\", b\"\\r\\n\", b\"\\r\"):\n                    raise OSError(\"Missing chunk terminating newline\")\n\n        return read\n\n\nclass WSGIRequestHandler(BaseHTTPRequestHandler):\n    \"\"\"A request handler that implements WSGI dispatching.\"\"\"\n\n    server: BaseWSGIServer\n\n    @property\n    def server_version(self) -> str:  # type: ignore\n        return self.server._server_version\n\n    def make_environ(self) -> WSGIEnvironment:\n        request_url = urlsplit(self.path)\n        url_scheme = \"http\" if self.server.ssl_context is None else \"https\"\n\n        if not self.client_address:\n            self.client_address = (\"<local>\", 0)\n        elif isinstance(self.client_address, str):\n            self.client_address = (self.client_address, 0)\n\n        # If there was no scheme but the path started with two slashes,\n        # the first segment may have been incorrectly parsed as the\n        # netloc, prepend it to the path again.\n        if not request_url.scheme and request_url.netloc:\n            path_info = f\"/{request_url.netloc}{request_url.path}\"\n        else:\n            path_info = request_url.path\n\n        path_info = unquote(path_info)\n\n        environ: WSGIEnvironment = {\n            \"wsgi.version\": (1, 0),\n            \"wsgi.url_scheme\": url_scheme,\n            \"wsgi.input\": self.rfile,\n            \"wsgi.errors\": sys.stderr,\n            \"wsgi.multithread\": self.server.multithread,\n            \"wsgi.multiprocess\": self.server.multiprocess,\n            \"wsgi.run_once\": False,\n            \"werkzeug.socket\": self.connection,\n            \"SERVER_SOFTWARE\": self.server_version,\n            \"REQUEST_METHOD\": self.command,\n            \"SCRIPT_NAME\": \"\",\n            \"PATH_INFO\": _wsgi_encoding_dance(path_info),\n            \"QUERY_STRING\": _wsgi_encoding_dance(request_url.query),\n            # Non-standard, added by mod_wsgi, uWSGI\n            \"REQUEST_URI\": _wsgi_encoding_dance(self.path),\n            # Non-standard, added by gunicorn\n            \"RAW_URI\": _wsgi_encoding_dance(self.path),\n            \"REMOTE_ADDR\": self.address_string(),\n            \"REMOTE_PORT\": self.port_integer(),\n            \"SERVER_NAME\": self.server.server_address[0],\n            \"SERVER_PORT\": str(self.server.server_address[1]),\n            \"SERVER_PROTOCOL\": self.request_version,\n        }\n\n        for key, value in self.headers.items():\n            if \"_\" in key:\n                continue\n\n            key = key.upper().replace(\"-\", \"_\")\n            value = value.replace(\"\\r\\n\", \"\")\n            if key not in (\"CONTENT_TYPE\", \"CONTENT_LENGTH\"):\n                key = f\"HTTP_{key}\"\n                if key in environ:\n                    value = f\"{environ[key]},{value}\"\n            environ[key] = value\n\n        if environ.get(\"HTTP_TRANSFER_ENCODING\", \"\").strip().lower() == \"chunked\":\n            environ[\"wsgi.input_terminated\"] = True\n            environ[\"wsgi.input\"] = DechunkedInput(environ[\"wsgi.input\"])\n\n        # Per RFC 2616, if the URL is absolute, use that as the host.\n        # We're using \"has a scheme\" to indicate an absolute URL.\n        if request_url.scheme and request_url.netloc:\n            environ[\"HTTP_HOST\"] = request_url.netloc\n\n        try:\n            # binary_form=False gives nicer information, but wouldn't be compatible with\n            # what Nginx or Apache could return.\n            peer_cert = self.connection.getpeercert(binary_form=True)\n            if peer_cert is not None:\n                # Nginx and Apache use PEM format.\n                environ[\"SSL_CLIENT_CERT\"] = ssl.DER_cert_to_PEM_cert(peer_cert)\n        except ValueError:\n            # SSL handshake hasn't finished.\n            self.server.log(\"error\", \"Cannot fetch SSL peer certificate info\")\n        except AttributeError:\n            # Not using TLS, the socket will not have getpeercert().\n            pass\n\n        return environ\n\n    def run_wsgi(self) -> None:\n        if self.headers.get(\"Expect\", \"\").lower().strip() == \"100-continue\":\n            self.wfile.write(b\"HTTP/1.1 100 Continue\\r\\n\\r\\n\")\n\n        self.environ = environ = self.make_environ()\n        status_set: str | None = None\n        headers_set: list[tuple[str, str]] | None = None\n        status_sent: str | None = None\n        headers_sent: list[tuple[str, str]] | None = None\n        chunk_response: bool = False\n\n        def write(data: bytes) -> None:\n            nonlocal status_sent, headers_sent, chunk_response\n            assert status_set is not None, \"write() before start_response\"\n            assert headers_set is not None, \"write() before start_response\"\n            if status_sent is None:\n                status_sent = status_set\n                headers_sent = headers_set\n                try:\n                    code_str, msg = status_sent.split(None, 1)\n                except ValueError:\n                    code_str, msg = status_sent, \"\"\n                code = int(code_str)\n                self.send_response(code, msg)\n                header_keys = set()\n                for key, value in headers_sent:\n                    self.send_header(key, value)\n                    header_keys.add(key.lower())\n\n                # Use chunked transfer encoding if there is no content\n                # length. Do not use for 1xx and 204 responses. 304\n                # responses and HEAD requests are also excluded, which\n                # is the more conservative behavior and matches other\n                # parts of the code.\n                # https://httpwg.org/specs/rfc7230.html#rfc.section.3.3.1\n                if (\n                    not (\n                        \"content-length\" in header_keys\n                        or environ[\"REQUEST_METHOD\"] == \"HEAD\"\n                        or (100 <= code < 200)\n                        or code in {204, 304}\n                    )\n                    and self.protocol_version >= \"HTTP/1.1\"\n                ):\n                    chunk_response = True\n                    self.send_header(\"Transfer-Encoding\", \"chunked\")\n\n                # Always close the connection. This disables HTTP/1.1\n                # keep-alive connections. They aren't handled well by\n                # Python's http.server because it doesn't know how to\n                # drain the stream before the next request line.\n                self.send_header(\"Connection\", \"close\")\n                self.end_headers()\n\n            assert isinstance(data, bytes), \"applications must write bytes\"\n\n            if data:\n                if chunk_response:\n                    self.wfile.write(hex(len(data))[2:].encode())\n                    self.wfile.write(b\"\\r\\n\")\n\n                self.wfile.write(data)\n\n                if chunk_response:\n                    self.wfile.write(b\"\\r\\n\")\n\n            self.wfile.flush()\n\n        def start_response(status, headers, exc_info=None):  # type: ignore\n            nonlocal status_set, headers_set\n            if exc_info:\n                try:\n                    if headers_sent:\n                        raise exc_info[1].with_traceback(exc_info[2])\n                finally:\n                    exc_info = None\n            elif headers_set:\n                raise AssertionError(\"Headers already set\")\n            status_set = status\n            headers_set = headers\n            return write\n\n        def execute(app: WSGIApplication) -> None:\n            application_iter = app(environ, start_response)\n            try:\n                for data in application_iter:\n                    write(data)\n                if not headers_sent:\n                    write(b\"\")\n                if chunk_response:\n                    self.wfile.write(b\"0\\r\\n\\r\\n\")\n            finally:\n                # Check for any remaining data in the read socket, and discard it. This\n                # will read past request.max_content_length, but lets the client see a\n                # 413 response instead of a connection reset failure. If we supported\n                # keep-alive connections, this naive approach would break by reading the\n                # next request line. Since we know that write (above) closes every\n                # connection we can read everything.\n                selector = selectors.DefaultSelector()\n                selector.register(self.connection, selectors.EVENT_READ)\n                total_size = 0\n                total_reads = 0\n\n                # A timeout of 0 tends to fail because a client needs a small amount of\n                # time to continue sending its data.\n                while selector.select(timeout=0.01):\n                    # Only read 10MB into memory at a time.\n                    data = self.rfile.read(10_000_000)\n                    total_size += len(data)\n                    total_reads += 1\n\n                    # Stop reading on no data, >=10GB, or 1000 reads. If a client sends\n                    # more than that, they'll get a connection reset failure.\n                    if not data or total_size >= 10_000_000_000 or total_reads > 1000:\n                        break\n\n                selector.close()\n\n                if hasattr(application_iter, \"close\"):\n                    application_iter.close()\n\n        try:\n            execute(self.server.app)\n        except (ConnectionError, socket.timeout) as e:\n            self.connection_dropped(e, environ)\n        except Exception as e:\n            if self.server.passthrough_errors:\n                raise\n\n            if status_sent is not None and chunk_response:\n                self.close_connection = True\n\n            try:\n                # if we haven't yet sent the headers but they are set\n                # we roll back to be able to set them again.\n                if status_sent is None:\n                    status_set = None\n                    headers_set = None\n                execute(InternalServerError())\n            except Exception:\n                pass\n\n            from .debug.tbtools import DebugTraceback\n\n            msg = DebugTraceback(e).render_traceback_text()\n            self.server.log(\"error\", f\"Error on request:\\n{msg}\")\n\n    def handle(self) -> None:\n        \"\"\"Handles a request ignoring dropped connections.\"\"\"\n        try:\n            super().handle()\n        except (ConnectionError, socket.timeout) as e:\n            self.connection_dropped(e)\n        except Exception as e:\n            if self.server.ssl_context is not None and is_ssl_error(e):\n                self.log_error(\"SSL error occurred: %s\", e)\n            else:\n                raise\n\n    def connection_dropped(\n        self, error: BaseException, environ: WSGIEnvironment | None = None\n    ) -> None:\n        \"\"\"Called if the connection was closed by the client.  By default\n        nothing happens.\n        \"\"\"\n\n    def __getattr__(self, name: str) -> t.Any:\n        # All HTTP methods are handled by run_wsgi.\n        if name.startswith(\"do_\"):\n            return self.run_wsgi\n\n        # All other attributes are forwarded to the base class.\n        return getattr(super(), name)\n\n    def address_string(self) -> str:\n        if getattr(self, \"environ\", None):\n            return self.environ[\"REMOTE_ADDR\"]  # type: ignore\n\n        if not self.client_address:\n            return \"<local>\"\n\n        return self.client_address[0]\n\n    def port_integer(self) -> int:\n        return self.client_address[1]\n\n    # Escape control characters. This is defined (but private) in Python 3.12.\n    _control_char_table = str.maketrans(\n        {c: rf\"\\x{c:02x}\" for c in [*range(0x20), *range(0x7F, 0xA0)]}\n    )\n    _control_char_table[ord(\"\\\\\")] = r\"\\\\\"\n\n    def log_request(self, code: int | str = \"-\", size: int | str = \"-\") -> None:\n        try:\n            path = uri_to_iri(self.path)\n            msg = f\"{self.command} {path} {self.request_version}\"\n        except AttributeError:\n            # path isn't set if the requestline was bad\n            msg = self.requestline\n\n        # Escape control characters that may be in the decoded path.\n        msg = msg.translate(self._control_char_table)\n        code = str(code)\n\n        if code[0] == \"1\":  # 1xx - Informational\n            msg = _ansi_style(msg, \"bold\")\n        elif code == \"200\":  # 2xx - Success\n            pass\n        elif code == \"304\":  # 304 - Resource Not Modified\n            msg = _ansi_style(msg, \"cyan\")\n        elif code[0] == \"3\":  # 3xx - Redirection\n            msg = _ansi_style(msg, \"green\")\n        elif code == \"404\":  # 404 - Resource Not Found\n            msg = _ansi_style(msg, \"yellow\")\n        elif code[0] == \"4\":  # 4xx - Client Error\n            msg = _ansi_style(msg, \"bold\", \"red\")\n        else:  # 5xx, or any other response\n            msg = _ansi_style(msg, \"bold\", \"magenta\")\n\n        self.log(\"info\", '\"%s\" %s %s', msg, code, size)\n\n    def log_error(self, format: str, *args: t.Any) -> None:\n        self.log(\"error\", format, *args)\n\n    def log_message(self, format: str, *args: t.Any) -> None:\n        self.log(\"info\", format, *args)\n\n    def log(self, type: str, message: str, *args: t.Any) -> None:\n        _log(\n            type,\n            f\"{self.address_string()} - - [{self.log_date_time_string()}] {message}\\n\",\n            *args,\n        )\n\n\ndef _ansi_style(value: str, *styles: str) -> str:\n    if not _log_add_style:\n        return value\n\n    codes = {\n        \"bold\": 1,\n        \"red\": 31,\n        \"green\": 32,\n        \"yellow\": 33,\n        \"magenta\": 35,\n        \"cyan\": 36,\n    }\n\n    for style in styles:\n        value = f\"\\x1b[{codes[style]}m{value}\"\n\n    return f\"{value}\\x1b[0m\"\n\n\ndef generate_adhoc_ssl_pair(\n    cn: str | None = None,\n) -> tuple[Certificate, RSAPrivateKeyWithSerialization]:\n    try:\n        from cryptography import x509\n        from cryptography.hazmat.backends import default_backend\n        from cryptography.hazmat.primitives import hashes\n        from cryptography.hazmat.primitives.asymmetric import rsa\n        from cryptography.x509.oid import NameOID\n    except ImportError:\n        raise TypeError(\n            \"Using ad-hoc certificates requires the cryptography library.\"\n        ) from None\n\n    backend = default_backend()\n    pkey = rsa.generate_private_key(\n        public_exponent=65537, key_size=2048, backend=backend\n    )\n\n    # pretty damn sure that this is not actually accepted by anyone\n    if cn is None:\n        cn = \"*\"\n\n    subject = x509.Name(\n        [\n            x509.NameAttribute(NameOID.ORGANIZATION_NAME, \"Dummy Certificate\"),\n            x509.NameAttribute(NameOID.COMMON_NAME, cn),\n        ]\n    )\n\n    backend = default_backend()\n    cert = (\n        x509.CertificateBuilder()\n        .subject_name(subject)\n        .issuer_name(subject)\n        .public_key(pkey.public_key())\n        .serial_number(x509.random_serial_number())\n        .not_valid_before(dt.now(timezone.utc))\n        .not_valid_after(dt.now(timezone.utc) + timedelta(days=365))\n        .add_extension(x509.ExtendedKeyUsage([x509.OID_SERVER_AUTH]), critical=False)\n        .add_extension(\n            x509.SubjectAlternativeName([x509.DNSName(cn), x509.DNSName(f\"*.{cn}\")]),\n            critical=False,\n        )\n        .sign(pkey, hashes.SHA256(), backend)\n    )\n    return cert, pkey\n\n\ndef make_ssl_devcert(\n    base_path: str, host: str | None = None, cn: str | None = None\n) -> tuple[str, str]:\n    \"\"\"Creates an SSL key for development.  This should be used instead of\n    the ``'adhoc'`` key which generates a new cert on each server start.\n    It accepts a path for where it should store the key and cert and\n    either a host or CN.  If a host is given it will use the CN\n    ``*.host/CN=host``.\n\n    For more information see :func:`run_simple`.\n\n    .. versionadded:: 0.9\n\n    :param base_path: the path to the certificate and key.  The extension\n                      ``.crt`` is added for the certificate, ``.key`` is\n                      added for the key.\n    :param host: the name of the host.  This can be used as an alternative\n                 for the `cn`.\n    :param cn: the `CN` to use.\n    \"\"\"\n\n    if host is not None:\n        cn = host\n    cert, pkey = generate_adhoc_ssl_pair(cn=cn)\n\n    from cryptography.hazmat.primitives import serialization\n\n    cert_file = f\"{base_path}.crt\"\n    pkey_file = f\"{base_path}.key\"\n\n    with open(cert_file, \"wb\") as f:\n        f.write(cert.public_bytes(serialization.Encoding.PEM))\n    with open(pkey_file, \"wb\") as f:\n        f.write(\n            pkey.private_bytes(\n                encoding=serialization.Encoding.PEM,\n                format=serialization.PrivateFormat.TraditionalOpenSSL,\n                encryption_algorithm=serialization.NoEncryption(),\n            )\n        )\n\n    return cert_file, pkey_file\n\n\ndef generate_adhoc_ssl_context() -> ssl.SSLContext:\n    \"\"\"Generates an adhoc SSL context for the development server.\"\"\"\n    import atexit\n    import tempfile\n\n    cert, pkey = generate_adhoc_ssl_pair()\n\n    from cryptography.hazmat.primitives import serialization\n\n    cert_handle, cert_file = tempfile.mkstemp()\n    pkey_handle, pkey_file = tempfile.mkstemp()\n    atexit.register(os.remove, pkey_file)\n    atexit.register(os.remove, cert_file)\n\n    os.write(cert_handle, cert.public_bytes(serialization.Encoding.PEM))\n    os.write(\n        pkey_handle,\n        pkey.private_bytes(\n            encoding=serialization.Encoding.PEM,\n            format=serialization.PrivateFormat.TraditionalOpenSSL,\n            encryption_algorithm=serialization.NoEncryption(),\n        ),\n    )\n\n    os.close(cert_handle)\n    os.close(pkey_handle)\n    ctx = load_ssl_context(cert_file, pkey_file)\n    return ctx\n\n\ndef load_ssl_context(\n    cert_file: str, pkey_file: str | None = None, protocol: int | None = None\n) -> ssl.SSLContext:\n    \"\"\"Loads SSL context from cert/private key files and optional protocol.\n    Many parameters are directly taken from the API of\n    :py:class:`ssl.SSLContext`.\n\n    :param cert_file: Path of the certificate to use.\n    :param pkey_file: Path of the private key to use. If not given, the key\n                      will be obtained from the certificate file.\n    :param protocol: A ``PROTOCOL`` constant from the :mod:`ssl` module.\n        Defaults to :data:`ssl.PROTOCOL_TLS_SERVER`.\n    \"\"\"\n    if protocol is None:\n        protocol = ssl.PROTOCOL_TLS_SERVER\n\n    ctx = ssl.SSLContext(protocol)\n    ctx.load_cert_chain(cert_file, pkey_file)\n    return ctx\n\n\ndef is_ssl_error(error: Exception | None = None) -> bool:\n    \"\"\"Checks if the given error (or the current one) is an SSL error.\"\"\"\n    if error is None:\n        error = t.cast(Exception, sys.exc_info()[1])\n    return isinstance(error, ssl.SSLError)\n\n\ndef select_address_family(host: str, port: int) -> socket.AddressFamily:\n    \"\"\"Return ``AF_INET4``, ``AF_INET6``, or ``AF_UNIX`` depending on\n    the host and port.\"\"\"\n    if host.startswith(\"unix://\"):\n        return socket.AF_UNIX\n    elif \":\" in host and hasattr(socket, \"AF_INET6\"):\n        return socket.AF_INET6\n    return socket.AF_INET\n\n\ndef get_sockaddr(\n    host: str, port: int, family: socket.AddressFamily\n) -> tuple[str, int] | str:\n    \"\"\"Return a fully qualified socket address that can be passed to\n    :func:`socket.bind`.\"\"\"\n    if family == af_unix:\n        # Absolute path avoids IDNA encoding error when path starts with dot.\n        return os.path.abspath(host.partition(\"://\")[2])\n    try:\n        res = socket.getaddrinfo(\n            host, port, family, socket.SOCK_STREAM, socket.IPPROTO_TCP\n        )\n    except socket.gaierror:\n        return host, port\n    return res[0][4]  # type: ignore\n\n\ndef get_interface_ip(family: socket.AddressFamily) -> str:\n    \"\"\"Get the IP address of an external interface. Used when binding to\n    0.0.0.0 or ::1 to show a more useful URL.\n\n    :meta private:\n    \"\"\"\n    # arbitrary private address\n    host = \"fd31:f903:5ab5:1::1\" if family == socket.AF_INET6 else \"10.253.155.219\"\n\n    with socket.socket(family, socket.SOCK_DGRAM) as s:\n        try:\n            s.connect((host, 58162))\n        except OSError:\n            return \"::1\" if family == socket.AF_INET6 else \"127.0.0.1\"\n\n        return s.getsockname()[0]  # type: ignore\n\n\nclass BaseWSGIServer(HTTPServer):\n    \"\"\"A WSGI server that that handles one request at a time.\n\n    Use :func:`make_server` to create a server instance.\n    \"\"\"\n\n    multithread = False\n    multiprocess = False\n    request_queue_size = LISTEN_QUEUE\n    allow_reuse_address = True\n\n    def __init__(\n        self,\n        host: str,\n        port: int,\n        app: WSGIApplication,\n        handler: type[WSGIRequestHandler] | None = None,\n        passthrough_errors: bool = False,\n        ssl_context: _TSSLContextArg | None = None,\n        fd: int | None = None,\n    ) -> None:\n        if handler is None:\n            handler = WSGIRequestHandler\n\n        # If the handler doesn't directly set a protocol version and\n        # thread or process workers are used, then allow chunked\n        # responses and keep-alive connections by enabling HTTP/1.1.\n        if \"protocol_version\" not in vars(handler) and (\n            self.multithread or self.multiprocess\n        ):\n            handler.protocol_version = \"HTTP/1.1\"\n\n        self.host = host\n        self.port = port\n        self.app = app\n        self.passthrough_errors = passthrough_errors\n\n        self.address_family = address_family = select_address_family(host, port)\n        server_address = get_sockaddr(host, int(port), address_family)\n\n        # Remove a leftover Unix socket file from a previous run. Don't\n        # remove a file that was set up by run_simple.\n        if address_family == af_unix and fd is None:\n            server_address = t.cast(str, server_address)\n\n            if os.path.exists(server_address):\n                os.unlink(server_address)\n\n        # Bind and activate will be handled manually, it should only\n        # happen if we're not using a socket that was already set up.\n        super().__init__(\n            server_address,  # type: ignore[arg-type]\n            handler,\n            bind_and_activate=False,\n        )\n\n        if fd is None:\n            # No existing socket descriptor, do bind_and_activate=True.\n            try:\n                self.server_bind()\n                self.server_activate()\n            except OSError as e:\n                # Catch connection issues and show them without the traceback. Show\n                # extra instructions for address not found, and for macOS.\n                self.server_close()\n                print(e.strerror, file=sys.stderr)\n\n                if e.errno == errno.EADDRINUSE:\n                    print(\n                        f\"Port {port} is in use by another program. Either identify and\"\n                        \" stop that program, or start the server with a different\"\n                        \" port.\",\n                        file=sys.stderr,\n                    )\n\n                    if sys.platform == \"darwin\" and port == 5000:\n                        print(\n                            \"On macOS, try disabling the 'AirPlay Receiver' service\"\n                            \" from System Preferences -> General -> AirDrop & Handoff.\",\n                            file=sys.stderr,\n                        )\n\n                sys.exit(1)\n            except BaseException:\n                self.server_close()\n                raise\n        else:\n            # TCPServer automatically opens a socket even if bind_and_activate is False.\n            # Close it to silence a ResourceWarning.\n            self.server_close()\n\n            # Use the passed in socket directly.\n            self.socket = socket.fromfd(fd, address_family, socket.SOCK_STREAM)\n            self.server_address = self.socket.getsockname()\n\n        if address_family != af_unix:\n            # If port was 0, this will record the bound port.\n            self.port = self.server_address[1]\n\n        if ssl_context is not None:\n            if isinstance(ssl_context, tuple):\n                ssl_context = load_ssl_context(*ssl_context)\n            elif ssl_context == \"adhoc\":\n                ssl_context = generate_adhoc_ssl_context()\n\n            self.socket = ssl_context.wrap_socket(self.socket, server_side=True)\n            self.ssl_context: ssl.SSLContext | None = ssl_context\n        else:\n            self.ssl_context = None\n\n        import importlib.metadata\n\n        self._server_version = f\"Werkzeug/{importlib.metadata.version('werkzeug')}\"\n\n    def log(self, type: str, message: str, *args: t.Any) -> None:\n        _log(type, message, *args)\n\n    def serve_forever(self, poll_interval: float = 0.5) -> None:\n        try:\n            super().serve_forever(poll_interval=poll_interval)\n        except KeyboardInterrupt:\n            pass\n        finally:\n            self.server_close()\n\n    def handle_error(\n        self, request: t.Any, client_address: tuple[str, int] | str\n    ) -> None:\n        if self.passthrough_errors:\n            raise\n\n        return super().handle_error(request, client_address)\n\n    def log_startup(self) -> None:\n        \"\"\"Show information about the address when starting the server.\"\"\"\n        dev_warning = (\n            \"WARNING: This is a development server. Do not use it in a production\"\n            \" deployment. Use a production WSGI server instead.\"\n        )\n        dev_warning = _ansi_style(dev_warning, \"bold\", \"red\")\n        messages = [dev_warning]\n\n        if self.address_family == af_unix:\n            messages.append(f\" * Running on {self.host}\")\n        else:\n            scheme = \"http\" if self.ssl_context is None else \"https\"\n            display_hostname = self.host\n\n            if self.host in {\"0.0.0.0\", \"::\"}:\n                messages.append(f\" * Running on all addresses ({self.host})\")\n\n                if self.host == \"0.0.0.0\":\n                    localhost = \"127.0.0.1\"\n                    display_hostname = get_interface_ip(socket.AF_INET)\n                else:\n                    localhost = \"[::1]\"\n                    display_hostname = get_interface_ip(socket.AF_INET6)\n\n                messages.append(f\" * Running on {scheme}://{localhost}:{self.port}\")\n\n            if \":\" in display_hostname:\n                display_hostname = f\"[{display_hostname}]\"\n\n            messages.append(f\" * Running on {scheme}://{display_hostname}:{self.port}\")\n\n        _log(\"info\", \"\\n\".join(messages))\n\n\nclass ThreadedWSGIServer(socketserver.ThreadingMixIn, BaseWSGIServer):\n    \"\"\"A WSGI server that handles concurrent requests in separate\n    threads.\n\n    Use :func:`make_server` to create a server instance.\n    \"\"\"\n\n    multithread = True\n    daemon_threads = True\n\n\nclass ForkingWSGIServer(ForkingMixIn, BaseWSGIServer):\n    \"\"\"A WSGI server that handles concurrent requests in separate forked\n    processes.\n\n    Use :func:`make_server` to create a server instance.\n    \"\"\"\n\n    multiprocess = True\n\n    def __init__(\n        self,\n        host: str,\n        port: int,\n        app: WSGIApplication,\n        processes: int = 40,\n        handler: type[WSGIRequestHandler] | None = None,\n        passthrough_errors: bool = False,\n        ssl_context: _TSSLContextArg | None = None,\n        fd: int | None = None,\n    ) -> None:\n        if not can_fork:\n            raise ValueError(\"Your platform does not support forking.\")\n\n        super().__init__(host, port, app, handler, passthrough_errors, ssl_context, fd)\n        self.max_children = processes\n\n\ndef make_server(\n    host: str,\n    port: int,\n    app: WSGIApplication,\n    threaded: bool = False,\n    processes: int = 1,\n    request_handler: type[WSGIRequestHandler] | None = None,\n    passthrough_errors: bool = False,\n    ssl_context: _TSSLContextArg | None = None,\n    fd: int | None = None,\n) -> BaseWSGIServer:\n    \"\"\"Create an appropriate WSGI server instance based on the value of\n    ``threaded`` and ``processes``.\n\n    This is called from :func:`run_simple`, but can be used separately\n    to have access to the server object, such as to run it in a separate\n    thread.\n\n    See :func:`run_simple` for parameter docs.\n    \"\"\"\n    if threaded and processes > 1:\n        raise ValueError(\"Cannot have a multi-thread and multi-process server.\")\n\n    if threaded:\n        return ThreadedWSGIServer(\n            host, port, app, request_handler, passthrough_errors, ssl_context, fd=fd\n        )\n\n    if processes > 1:\n        return ForkingWSGIServer(\n            host,\n            port,\n            app,\n            processes,\n            request_handler,\n            passthrough_errors,\n            ssl_context,\n            fd=fd,\n        )\n\n    return BaseWSGIServer(\n        host, port, app, request_handler, passthrough_errors, ssl_context, fd=fd\n    )\n\n\ndef is_running_from_reloader() -> bool:\n    \"\"\"Check if the server is running as a subprocess within the\n    Werkzeug reloader.\n\n    .. versionadded:: 0.10\n    \"\"\"\n    return os.environ.get(\"WERKZEUG_RUN_MAIN\") == \"true\"\n\n\ndef run_simple(\n    hostname: str,\n    port: int,\n    application: WSGIApplication,\n    use_reloader: bool = False,\n    use_debugger: bool = False,\n    use_evalex: bool = True,\n    extra_files: t.Iterable[str] | None = None,\n    exclude_patterns: t.Iterable[str] | None = None,\n    reloader_interval: int = 1,\n    reloader_type: str = \"auto\",\n    threaded: bool = False,\n    processes: int = 1,\n    request_handler: type[WSGIRequestHandler] | None = None,\n    static_files: dict[str, str | tuple[str, str]] | None = None,\n    passthrough_errors: bool = False,\n    ssl_context: _TSSLContextArg | None = None,\n) -> None:\n    \"\"\"Start a development server for a WSGI application. Various\n    optional features can be enabled.\n\n    .. warning::\n\n        Do not use the development server when deploying to production.\n        It is intended for use only during local development. It is not\n        designed to be particularly efficient, stable, or secure.\n\n    :param hostname: The host to bind to, for example ``'localhost'``.\n        Can be a domain, IPv4 or IPv6 address, or file path starting\n        with ``unix://`` for a Unix socket.\n    :param port: The port to bind to, for example ``8080``. Using ``0``\n        tells the OS to pick a random free port.\n    :param application: The WSGI application to run.\n    :param use_reloader: Use a reloader process to restart the server\n        process when files are changed.\n    :param use_debugger: Use Werkzeug's debugger, which will show\n        formatted tracebacks on unhandled exceptions.\n    :param use_evalex: Make the debugger interactive. A Python terminal\n        can be opened for any frame in the traceback. Some protection is\n        provided by requiring a PIN, but this should never be enabled\n        on a publicly visible server.\n    :param extra_files: The reloader will watch these files for changes\n        in addition to Python modules. For example, watch a\n        configuration file.\n    :param exclude_patterns: The reloader will ignore changes to any\n        files matching these :mod:`fnmatch` patterns. For example,\n        ignore cache files.\n    :param reloader_interval: How often the reloader tries to check for\n        changes.\n    :param reloader_type: The reloader to use. The ``'stat'`` reloader\n        is built in, but may require significant CPU to watch files. The\n        ``'watchdog'`` reloader is much more efficient but requires\n        installing the ``watchdog`` package first.\n    :param threaded: Handle concurrent requests using threads. Cannot be\n        used with ``processes``.\n    :param processes: Handle concurrent requests using up to this number\n        of processes. Cannot be used with ``threaded``.\n    :param request_handler: Use a different\n        :class:`~BaseHTTPServer.BaseHTTPRequestHandler` subclass to\n        handle requests.\n    :param static_files: A dict mapping URL prefixes to directories to\n        serve static files from using\n        :class:`~werkzeug.middleware.SharedDataMiddleware`.\n    :param passthrough_errors: Don't catch unhandled exceptions at the\n        server level, let the server crash instead. If ``use_debugger``\n        is enabled, the debugger will still catch such errors.\n    :param ssl_context: Configure TLS to serve over HTTPS. Can be an\n        :class:`ssl.SSLContext` object, a ``(cert_file, key_file)``\n        tuple to create a typical context, or the string ``'adhoc'`` to\n        generate a temporary self-signed certificate.\n\n    .. versionchanged:: 2.1\n        Instructions are shown for dealing with an \"address already in\n        use\" error.\n\n    .. versionchanged:: 2.1\n        Running on ``0.0.0.0`` or ``::`` shows the loopback IP in\n        addition to a real IP.\n\n    .. versionchanged:: 2.1\n        The command-line interface was removed.\n\n    .. versionchanged:: 2.0\n        Running on ``0.0.0.0`` or ``::`` shows a real IP address that\n        was bound as well as a warning not to run the development server\n        in production.\n\n    .. versionchanged:: 2.0\n        The ``exclude_patterns`` parameter was added.\n\n    .. versionchanged:: 0.15\n        Bind to a Unix socket by passing a ``hostname`` that starts with\n        ``unix://``.\n\n    .. versionchanged:: 0.10\n        Improved the reloader and added support for changing the backend\n        through the ``reloader_type`` parameter.\n\n    .. versionchanged:: 0.9\n        A command-line interface was added.\n\n    .. versionchanged:: 0.8\n        ``ssl_context`` can be a tuple of paths to the certificate and\n        private key files.\n\n    .. versionchanged:: 0.6\n        The ``ssl_context`` parameter was added.\n\n    .. versionchanged:: 0.5\n       The ``static_files`` and ``passthrough_errors`` parameters were\n       added.\n    \"\"\"\n    if not isinstance(port, int):\n        raise TypeError(\"port must be an integer\")\n\n    if static_files:\n        from .middleware.shared_data import SharedDataMiddleware\n\n        application = SharedDataMiddleware(application, static_files)\n\n    if use_debugger:\n        from .debug import DebuggedApplication\n\n        application = DebuggedApplication(application, evalex=use_evalex)\n        # Allow the specified hostname to use the debugger, in addition to\n        # localhost domains.\n        application.trusted_hosts.append(hostname)\n\n    if not is_running_from_reloader():\n        fd = None\n    else:\n        fd = int(os.environ[\"WERKZEUG_SERVER_FD\"])\n\n    srv = make_server(\n        hostname,\n        port,\n        application,\n        threaded,\n        processes,\n        request_handler,\n        passthrough_errors,\n        ssl_context,\n        fd=fd,\n    )\n    srv.socket.set_inheritable(True)\n    os.environ[\"WERKZEUG_SERVER_FD\"] = str(srv.fileno())\n\n    if not is_running_from_reloader():\n        srv.log_startup()\n        _log(\"info\", _ansi_style(\"Press CTRL+C to quit\", \"yellow\"))\n\n    if use_reloader:\n        from ._reloader import run_with_reloader\n\n        try:\n            run_with_reloader(\n                srv.serve_forever,\n                extra_files=extra_files,\n                exclude_patterns=exclude_patterns,\n                interval=reloader_interval,\n                reloader_type=reloader_type,\n            )\n        finally:\n            srv.server_close()\n    else:\n        srv.serve_forever()\n", "src/werkzeug/_reloader.py": "from __future__ import annotations\n\nimport fnmatch\nimport os\nimport subprocess\nimport sys\nimport threading\nimport time\nimport typing as t\nfrom itertools import chain\nfrom pathlib import PurePath\n\nfrom ._internal import _log\n\n# The various system prefixes where imports are found. Base values are\n# different when running in a virtualenv. All reloaders will ignore the\n# base paths (usually the system installation). The stat reloader won't\n# scan the virtualenv paths, it will only include modules that are\n# already imported.\n_ignore_always = tuple({sys.base_prefix, sys.base_exec_prefix})\nprefix = {*_ignore_always, sys.prefix, sys.exec_prefix}\n\nif hasattr(sys, \"real_prefix\"):\n    # virtualenv < 20\n    prefix.add(sys.real_prefix)\n\n_stat_ignore_scan = tuple(prefix)\ndel prefix\n_ignore_common_dirs = {\n    \"__pycache__\",\n    \".git\",\n    \".hg\",\n    \".tox\",\n    \".nox\",\n    \".pytest_cache\",\n    \".mypy_cache\",\n}\n\n\ndef _iter_module_paths() -> t.Iterator[str]:\n    \"\"\"Find the filesystem paths associated with imported modules.\"\"\"\n    # List is in case the value is modified by the app while updating.\n    for module in list(sys.modules.values()):\n        name = getattr(module, \"__file__\", None)\n\n        if name is None or name.startswith(_ignore_always):\n            continue\n\n        while not os.path.isfile(name):\n            # Zip file, find the base file without the module path.\n            old = name\n            name = os.path.dirname(name)\n\n            if name == old:  # skip if it was all directories somehow\n                break\n        else:\n            yield name\n\n\ndef _remove_by_pattern(paths: set[str], exclude_patterns: set[str]) -> None:\n    for pattern in exclude_patterns:\n        paths.difference_update(fnmatch.filter(paths, pattern))\n\n\ndef _find_stat_paths(\n    extra_files: set[str], exclude_patterns: set[str]\n) -> t.Iterable[str]:\n    \"\"\"Find paths for the stat reloader to watch. Returns imported\n    module files, Python files under non-system paths. Extra files and\n    Python files under extra directories can also be scanned.\n\n    System paths have to be excluded for efficiency. Non-system paths,\n    such as a project root or ``sys.path.insert``, should be the paths\n    of interest to the user anyway.\n    \"\"\"\n    paths = set()\n\n    for path in chain(list(sys.path), extra_files):\n        path = os.path.abspath(path)\n\n        if os.path.isfile(path):\n            # zip file on sys.path, or extra file\n            paths.add(path)\n            continue\n\n        parent_has_py = {os.path.dirname(path): True}\n\n        for root, dirs, files in os.walk(path):\n            # Optimizations: ignore system prefixes, __pycache__ will\n            # have a py or pyc module at the import path, ignore some\n            # common known dirs such as version control and tool caches.\n            if (\n                root.startswith(_stat_ignore_scan)\n                or os.path.basename(root) in _ignore_common_dirs\n            ):\n                dirs.clear()\n                continue\n\n            has_py = False\n\n            for name in files:\n                if name.endswith((\".py\", \".pyc\")):\n                    has_py = True\n                    paths.add(os.path.join(root, name))\n\n            # Optimization: stop scanning a directory if neither it nor\n            # its parent contained Python files.\n            if not (has_py or parent_has_py[os.path.dirname(root)]):\n                dirs.clear()\n                continue\n\n            parent_has_py[root] = has_py\n\n    paths.update(_iter_module_paths())\n    _remove_by_pattern(paths, exclude_patterns)\n    return paths\n\n\ndef _find_watchdog_paths(\n    extra_files: set[str], exclude_patterns: set[str]\n) -> t.Iterable[str]:\n    \"\"\"Find paths for the stat reloader to watch. Looks at the same\n    sources as the stat reloader, but watches everything under\n    directories instead of individual files.\n    \"\"\"\n    dirs = set()\n\n    for name in chain(list(sys.path), extra_files):\n        name = os.path.abspath(name)\n\n        if os.path.isfile(name):\n            name = os.path.dirname(name)\n\n        dirs.add(name)\n\n    for name in _iter_module_paths():\n        dirs.add(os.path.dirname(name))\n\n    _remove_by_pattern(dirs, exclude_patterns)\n    return _find_common_roots(dirs)\n\n\ndef _find_common_roots(paths: t.Iterable[str]) -> t.Iterable[str]:\n    root: dict[str, dict[str, t.Any]] = {}\n\n    for chunks in sorted((PurePath(x).parts for x in paths), key=len, reverse=True):\n        node = root\n\n        for chunk in chunks:\n            node = node.setdefault(chunk, {})\n\n        node.clear()\n\n    rv = set()\n\n    def _walk(node: t.Mapping[str, dict[str, t.Any]], path: tuple[str, ...]) -> None:\n        for prefix, child in node.items():\n            _walk(child, path + (prefix,))\n\n        # If there are no more nodes, and a path has been accumulated, add it.\n        # Path may be empty if the \"\" entry is in sys.path.\n        if not node and path:\n            rv.add(os.path.join(*path))\n\n    _walk(root, ())\n    return rv\n\n\ndef _get_args_for_reloading() -> list[str]:\n    \"\"\"Determine how the script was executed, and return the args needed\n    to execute it again in a new process.\n    \"\"\"\n    if sys.version_info >= (3, 10):\n        # sys.orig_argv, added in Python 3.10, contains the exact args used to invoke\n        # Python. Still replace argv[0] with sys.executable for accuracy.\n        return [sys.executable, *sys.orig_argv[1:]]\n\n    rv = [sys.executable]\n    py_script = sys.argv[0]\n    args = sys.argv[1:]\n    # Need to look at main module to determine how it was executed.\n    __main__ = sys.modules[\"__main__\"]\n\n    # The value of __package__ indicates how Python was called. It may\n    # not exist if a setuptools script is installed as an egg. It may be\n    # set incorrectly for entry points created with pip on Windows.\n    if getattr(__main__, \"__package__\", None) is None or (\n        os.name == \"nt\"\n        and __main__.__package__ == \"\"\n        and not os.path.exists(py_script)\n        and os.path.exists(f\"{py_script}.exe\")\n    ):\n        # Executed a file, like \"python app.py\".\n        py_script = os.path.abspath(py_script)\n\n        if os.name == \"nt\":\n            # Windows entry points have \".exe\" extension and should be\n            # called directly.\n            if not os.path.exists(py_script) and os.path.exists(f\"{py_script}.exe\"):\n                py_script += \".exe\"\n\n            if (\n                os.path.splitext(sys.executable)[1] == \".exe\"\n                and os.path.splitext(py_script)[1] == \".exe\"\n            ):\n                rv.pop(0)\n\n        rv.append(py_script)\n    else:\n        # Executed a module, like \"python -m werkzeug.serving\".\n        if os.path.isfile(py_script):\n            # Rewritten by Python from \"-m script\" to \"/path/to/script.py\".\n            py_module = t.cast(str, __main__.__package__)\n            name = os.path.splitext(os.path.basename(py_script))[0]\n\n            if name != \"__main__\":\n                py_module += f\".{name}\"\n        else:\n            # Incorrectly rewritten by pydevd debugger from \"-m script\" to \"script\".\n            py_module = py_script\n\n        rv.extend((\"-m\", py_module.lstrip(\".\")))\n\n    rv.extend(args)\n    return rv\n\n\nclass ReloaderLoop:\n    name = \"\"\n\n    def __init__(\n        self,\n        extra_files: t.Iterable[str] | None = None,\n        exclude_patterns: t.Iterable[str] | None = None,\n        interval: int | float = 1,\n    ) -> None:\n        self.extra_files: set[str] = {os.path.abspath(x) for x in extra_files or ()}\n        self.exclude_patterns: set[str] = set(exclude_patterns or ())\n        self.interval = interval\n\n    def __enter__(self) -> ReloaderLoop:\n        \"\"\"Do any setup, then run one step of the watch to populate the\n        initial filesystem state.\n        \"\"\"\n        self.run_step()\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):  # type: ignore\n        \"\"\"Clean up any resources associated with the reloader.\"\"\"\n        pass\n\n    def run(self) -> None:\n        \"\"\"Continually run the watch step, sleeping for the configured\n        interval after each step.\n        \"\"\"\n        while True:\n            self.run_step()\n            time.sleep(self.interval)\n\n    def run_step(self) -> None:\n        \"\"\"Run one step for watching the filesystem. Called once to set\n        up initial state, then repeatedly to update it.\n        \"\"\"\n        pass\n\n    def restart_with_reloader(self) -> int:\n        \"\"\"Spawn a new Python interpreter with the same arguments as the\n        current one, but running the reloader thread.\n        \"\"\"\n        while True:\n            _log(\"info\", f\" * Restarting with {self.name}\")\n            args = _get_args_for_reloading()\n            new_environ = os.environ.copy()\n            new_environ[\"WERKZEUG_RUN_MAIN\"] = \"true\"\n            exit_code = subprocess.call(args, env=new_environ, close_fds=False)\n\n            if exit_code != 3:\n                return exit_code\n\n    def trigger_reload(self, filename: str) -> None:\n        self.log_reload(filename)\n        sys.exit(3)\n\n    def log_reload(self, filename: str) -> None:\n        filename = os.path.abspath(filename)\n        _log(\"info\", f\" * Detected change in {filename!r}, reloading\")\n\n\nclass StatReloaderLoop(ReloaderLoop):\n    name = \"stat\"\n\n    def __enter__(self) -> ReloaderLoop:\n        self.mtimes: dict[str, float] = {}\n        return super().__enter__()\n\n    def run_step(self) -> None:\n        for name in _find_stat_paths(self.extra_files, self.exclude_patterns):\n            try:\n                mtime = os.stat(name).st_mtime\n            except OSError:\n                continue\n\n            old_time = self.mtimes.get(name)\n\n            if old_time is None:\n                self.mtimes[name] = mtime\n                continue\n\n            if mtime > old_time:\n                self.trigger_reload(name)\n\n\nclass WatchdogReloaderLoop(ReloaderLoop):\n    def __init__(self, *args: t.Any, **kwargs: t.Any) -> None:\n        from watchdog.events import EVENT_TYPE_OPENED\n        from watchdog.events import FileModifiedEvent\n        from watchdog.events import PatternMatchingEventHandler\n        from watchdog.observers import Observer\n\n        super().__init__(*args, **kwargs)\n        trigger_reload = self.trigger_reload\n\n        class EventHandler(PatternMatchingEventHandler):\n            def on_any_event(self, event: FileModifiedEvent):  # type: ignore\n                if event.event_type == EVENT_TYPE_OPENED:\n                    return\n\n                trigger_reload(event.src_path)\n\n        reloader_name = Observer.__name__.lower()  # type: ignore[attr-defined]\n\n        if reloader_name.endswith(\"observer\"):\n            reloader_name = reloader_name[:-8]\n\n        self.name = f\"watchdog ({reloader_name})\"\n        self.observer = Observer()\n        # Extra patterns can be non-Python files, match them in addition\n        # to all Python files in default and extra directories. Ignore\n        # __pycache__ since a change there will always have a change to\n        # the source file (or initial pyc file) as well. Ignore Git and\n        # Mercurial internal changes.\n        extra_patterns = [p for p in self.extra_files if not os.path.isdir(p)]\n        self.event_handler = EventHandler(  # type: ignore[no-untyped-call]\n            patterns=[\"*.py\", \"*.pyc\", \"*.zip\", *extra_patterns],\n            ignore_patterns=[\n                *[f\"*/{d}/*\" for d in _ignore_common_dirs],\n                *self.exclude_patterns,\n            ],\n        )\n        self.should_reload = False\n\n    def trigger_reload(self, filename: str) -> None:\n        # This is called inside an event handler, which means throwing\n        # SystemExit has no effect.\n        # https://github.com/gorakhargosh/watchdog/issues/294\n        self.should_reload = True\n        self.log_reload(filename)\n\n    def __enter__(self) -> ReloaderLoop:\n        self.watches: dict[str, t.Any] = {}\n        self.observer.start()  # type: ignore[no-untyped-call]\n        return super().__enter__()\n\n    def __exit__(self, exc_type, exc_val, exc_tb):  # type: ignore\n        self.observer.stop()  # type: ignore[no-untyped-call]\n        self.observer.join()\n\n    def run(self) -> None:\n        while not self.should_reload:\n            self.run_step()\n            time.sleep(self.interval)\n\n        sys.exit(3)\n\n    def run_step(self) -> None:\n        to_delete = set(self.watches)\n\n        for path in _find_watchdog_paths(self.extra_files, self.exclude_patterns):\n            if path not in self.watches:\n                try:\n                    self.watches[path] = self.observer.schedule(  # type: ignore[no-untyped-call]\n                        self.event_handler, path, recursive=True\n                    )\n                except OSError:\n                    # Clear this path from list of watches We don't want\n                    # the same error message showing again in the next\n                    # iteration.\n                    self.watches[path] = None\n\n            to_delete.discard(path)\n\n        for path in to_delete:\n            watch = self.watches.pop(path, None)\n\n            if watch is not None:\n                self.observer.unschedule(watch)  # type: ignore[no-untyped-call]\n\n\nreloader_loops: dict[str, type[ReloaderLoop]] = {\n    \"stat\": StatReloaderLoop,\n    \"watchdog\": WatchdogReloaderLoop,\n}\n\ntry:\n    __import__(\"watchdog.observers\")\nexcept ImportError:\n    reloader_loops[\"auto\"] = reloader_loops[\"stat\"]\nelse:\n    reloader_loops[\"auto\"] = reloader_loops[\"watchdog\"]\n\n\ndef ensure_echo_on() -> None:\n    \"\"\"Ensure that echo mode is enabled. Some tools such as PDB disable\n    it which causes usability issues after a reload.\"\"\"\n    # tcgetattr will fail if stdin isn't a tty\n    if sys.stdin is None or not sys.stdin.isatty():\n        return\n\n    try:\n        import termios\n    except ImportError:\n        return\n\n    attributes = termios.tcgetattr(sys.stdin)\n\n    if not attributes[3] & termios.ECHO:\n        attributes[3] |= termios.ECHO\n        termios.tcsetattr(sys.stdin, termios.TCSANOW, attributes)\n\n\ndef run_with_reloader(\n    main_func: t.Callable[[], None],\n    extra_files: t.Iterable[str] | None = None,\n    exclude_patterns: t.Iterable[str] | None = None,\n    interval: int | float = 1,\n    reloader_type: str = \"auto\",\n) -> None:\n    \"\"\"Run the given function in an independent Python interpreter.\"\"\"\n    import signal\n\n    signal.signal(signal.SIGTERM, lambda *args: sys.exit(0))\n    reloader = reloader_loops[reloader_type](\n        extra_files=extra_files, exclude_patterns=exclude_patterns, interval=interval\n    )\n\n    try:\n        if os.environ.get(\"WERKZEUG_RUN_MAIN\") == \"true\":\n            ensure_echo_on()\n            t = threading.Thread(target=main_func, args=())\n            t.daemon = True\n\n            # Enter the reloader to set up initial state, then start\n            # the app thread and reloader update loop.\n            with reloader:\n                t.start()\n                reloader.run()\n        else:\n            sys.exit(reloader.restart_with_reloader())\n    except KeyboardInterrupt:\n        pass\n", "src/werkzeug/local.py": "from __future__ import annotations\n\nimport copy\nimport math\nimport operator\nimport typing as t\nfrom contextvars import ContextVar\nfrom functools import partial\nfrom functools import update_wrapper\nfrom operator import attrgetter\n\nfrom .wsgi import ClosingIterator\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import StartResponse\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n\nT = t.TypeVar(\"T\")\nF = t.TypeVar(\"F\", bound=t.Callable[..., t.Any])\n\n\ndef release_local(local: Local | LocalStack[t.Any]) -> None:\n    \"\"\"Release the data for the current context in a :class:`Local` or\n    :class:`LocalStack` without using a :class:`LocalManager`.\n\n    This should not be needed for modern use cases, and may be removed\n    in the future.\n\n    .. versionadded:: 0.6.1\n    \"\"\"\n    local.__release_local__()\n\n\nclass Local:\n    \"\"\"Create a namespace of context-local data. This wraps a\n    :class:`ContextVar` containing a :class:`dict` value.\n\n    This may incur a performance penalty compared to using individual\n    context vars, as it has to copy data to avoid mutating the dict\n    between nested contexts.\n\n    :param context_var: The :class:`~contextvars.ContextVar` to use as\n        storage for this local. If not given, one will be created.\n        Context vars not created at the global scope may interfere with\n        garbage collection.\n\n    .. versionchanged:: 2.0\n        Uses ``ContextVar`` instead of a custom storage implementation.\n    \"\"\"\n\n    __slots__ = (\"__storage\",)\n\n    def __init__(self, context_var: ContextVar[dict[str, t.Any]] | None = None) -> None:\n        if context_var is None:\n            # A ContextVar not created at global scope interferes with\n            # Python's garbage collection. However, a local only makes\n            # sense defined at the global scope as well, in which case\n            # the GC issue doesn't seem relevant.\n            context_var = ContextVar(f\"werkzeug.Local<{id(self)}>.storage\")\n\n        object.__setattr__(self, \"_Local__storage\", context_var)\n\n    def __iter__(self) -> t.Iterator[tuple[str, t.Any]]:\n        return iter(self.__storage.get({}).items())\n\n    def __call__(\n        self, name: str, *, unbound_message: str | None = None\n    ) -> LocalProxy[t.Any]:\n        \"\"\"Create a :class:`LocalProxy` that access an attribute on this\n        local namespace.\n\n        :param name: Proxy this attribute.\n        :param unbound_message: The error message that the proxy will\n            show if the attribute isn't set.\n        \"\"\"\n        return LocalProxy(self, name, unbound_message=unbound_message)\n\n    def __release_local__(self) -> None:\n        self.__storage.set({})\n\n    def __getattr__(self, name: str) -> t.Any:\n        values = self.__storage.get({})\n\n        if name in values:\n            return values[name]\n\n        raise AttributeError(name)\n\n    def __setattr__(self, name: str, value: t.Any) -> None:\n        values = self.__storage.get({}).copy()\n        values[name] = value\n        self.__storage.set(values)\n\n    def __delattr__(self, name: str) -> None:\n        values = self.__storage.get({})\n\n        if name in values:\n            values = values.copy()\n            del values[name]\n            self.__storage.set(values)\n        else:\n            raise AttributeError(name)\n\n\nclass LocalStack(t.Generic[T]):\n    \"\"\"Create a stack of context-local data. This wraps a\n    :class:`ContextVar` containing a :class:`list` value.\n\n    This may incur a performance penalty compared to using individual\n    context vars, as it has to copy data to avoid mutating the list\n    between nested contexts.\n\n    :param context_var: The :class:`~contextvars.ContextVar` to use as\n        storage for this local. If not given, one will be created.\n        Context vars not created at the global scope may interfere with\n        garbage collection.\n\n    .. versionchanged:: 2.0\n        Uses ``ContextVar`` instead of a custom storage implementation.\n\n    .. versionadded:: 0.6.1\n    \"\"\"\n\n    __slots__ = (\"_storage\",)\n\n    def __init__(self, context_var: ContextVar[list[T]] | None = None) -> None:\n        if context_var is None:\n            # A ContextVar not created at global scope interferes with\n            # Python's garbage collection. However, a local only makes\n            # sense defined at the global scope as well, in which case\n            # the GC issue doesn't seem relevant.\n            context_var = ContextVar(f\"werkzeug.LocalStack<{id(self)}>.storage\")\n\n        self._storage = context_var\n\n    def __release_local__(self) -> None:\n        self._storage.set([])\n\n    def push(self, obj: T) -> list[T]:\n        \"\"\"Add a new item to the top of the stack.\"\"\"\n        stack = self._storage.get([]).copy()\n        stack.append(obj)\n        self._storage.set(stack)\n        return stack\n\n    def pop(self) -> T | None:\n        \"\"\"Remove the top item from the stack and return it. If the\n        stack is empty, return ``None``.\n        \"\"\"\n        stack = self._storage.get([])\n\n        if len(stack) == 0:\n            return None\n\n        rv = stack[-1]\n        self._storage.set(stack[:-1])\n        return rv\n\n    @property\n    def top(self) -> T | None:\n        \"\"\"The topmost item on the stack.  If the stack is empty,\n        `None` is returned.\n        \"\"\"\n        stack = self._storage.get([])\n\n        if len(stack) == 0:\n            return None\n\n        return stack[-1]\n\n    def __call__(\n        self, name: str | None = None, *, unbound_message: str | None = None\n    ) -> LocalProxy[t.Any]:\n        \"\"\"Create a :class:`LocalProxy` that accesses the top of this\n        local stack.\n\n        :param name: If given, the proxy access this attribute of the\n            top item, rather than the item itself.\n        :param unbound_message: The error message that the proxy will\n            show if the stack is empty.\n        \"\"\"\n        return LocalProxy(self, name, unbound_message=unbound_message)\n\n\nclass LocalManager:\n    \"\"\"Manage releasing the data for the current context in one or more\n    :class:`Local` and :class:`LocalStack` objects.\n\n    This should not be needed for modern use cases, and may be removed\n    in the future.\n\n    :param locals: A local or list of locals to manage.\n\n    .. versionchanged:: 2.1\n        The ``ident_func`` was removed.\n\n    .. versionchanged:: 0.7\n        The ``ident_func`` parameter was added.\n\n    .. versionchanged:: 0.6.1\n        The :func:`release_local` function can be used instead of a\n        manager.\n    \"\"\"\n\n    __slots__ = (\"locals\",)\n\n    def __init__(\n        self,\n        locals: None\n        | (Local | LocalStack[t.Any] | t.Iterable[Local | LocalStack[t.Any]]) = None,\n    ) -> None:\n        if locals is None:\n            self.locals = []\n        elif isinstance(locals, Local):\n            self.locals = [locals]\n        else:\n            self.locals = list(locals)  # type: ignore[arg-type]\n\n    def cleanup(self) -> None:\n        \"\"\"Release the data in the locals for this context. Call this at\n        the end of each request or use :meth:`make_middleware`.\n        \"\"\"\n        for local in self.locals:\n            release_local(local)\n\n    def make_middleware(self, app: WSGIApplication) -> WSGIApplication:\n        \"\"\"Wrap a WSGI application so that local data is released\n        automatically after the response has been sent for a request.\n        \"\"\"\n\n        def application(\n            environ: WSGIEnvironment, start_response: StartResponse\n        ) -> t.Iterable[bytes]:\n            return ClosingIterator(app(environ, start_response), self.cleanup)\n\n        return application\n\n    def middleware(self, func: WSGIApplication) -> WSGIApplication:\n        \"\"\"Like :meth:`make_middleware` but used as a decorator on the\n        WSGI application function.\n\n        .. code-block:: python\n\n            @manager.middleware\n            def application(environ, start_response):\n                ...\n        \"\"\"\n        return update_wrapper(self.make_middleware(func), func)\n\n    def __repr__(self) -> str:\n        return f\"<{type(self).__name__} storages: {len(self.locals)}>\"\n\n\nclass _ProxyLookup:\n    \"\"\"Descriptor that handles proxied attribute lookup for\n    :class:`LocalProxy`.\n\n    :param f: The built-in function this attribute is accessed through.\n        Instead of looking up the special method, the function call\n        is redone on the object.\n    :param fallback: Return this function if the proxy is unbound\n        instead of raising a :exc:`RuntimeError`.\n    :param is_attr: This proxied name is an attribute, not a function.\n        Call the fallback immediately to get the value.\n    :param class_value: Value to return when accessed from the\n        ``LocalProxy`` class directly. Used for ``__doc__`` so building\n        docs still works.\n    \"\"\"\n\n    __slots__ = (\"bind_f\", \"fallback\", \"is_attr\", \"class_value\", \"name\")\n\n    def __init__(\n        self,\n        f: t.Callable[..., t.Any] | None = None,\n        fallback: t.Callable[[LocalProxy[t.Any]], t.Any] | None = None,\n        class_value: t.Any | None = None,\n        is_attr: bool = False,\n    ) -> None:\n        bind_f: t.Callable[[LocalProxy[t.Any], t.Any], t.Callable[..., t.Any]] | None\n\n        if hasattr(f, \"__get__\"):\n            # A Python function, can be turned into a bound method.\n\n            def bind_f(\n                instance: LocalProxy[t.Any], obj: t.Any\n            ) -> t.Callable[..., t.Any]:\n                return f.__get__(obj, type(obj))  # type: ignore\n\n        elif f is not None:\n            # A C function, use partial to bind the first argument.\n\n            def bind_f(\n                instance: LocalProxy[t.Any], obj: t.Any\n            ) -> t.Callable[..., t.Any]:\n                return partial(f, obj)\n\n        else:\n            # Use getattr, which will produce a bound method.\n            bind_f = None\n\n        self.bind_f = bind_f\n        self.fallback = fallback\n        self.class_value = class_value\n        self.is_attr = is_attr\n\n    def __set_name__(self, owner: LocalProxy[t.Any], name: str) -> None:\n        self.name = name\n\n    def __get__(self, instance: LocalProxy[t.Any], owner: type | None = None) -> t.Any:\n        if instance is None:\n            if self.class_value is not None:\n                return self.class_value\n\n            return self\n\n        try:\n            obj = instance._get_current_object()\n        except RuntimeError:\n            if self.fallback is None:\n                raise\n\n            fallback = self.fallback.__get__(instance, owner)\n\n            if self.is_attr:\n                # __class__ and __doc__ are attributes, not methods.\n                # Call the fallback to get the value.\n                return fallback()\n\n            return fallback\n\n        if self.bind_f is not None:\n            return self.bind_f(instance, obj)\n\n        return getattr(obj, self.name)\n\n    def __repr__(self) -> str:\n        return f\"proxy {self.name}\"\n\n    def __call__(\n        self, instance: LocalProxy[t.Any], *args: t.Any, **kwargs: t.Any\n    ) -> t.Any:\n        \"\"\"Support calling unbound methods from the class. For example,\n        this happens with ``copy.copy``, which does\n        ``type(x).__copy__(x)``. ``type(x)`` can't be proxied, so it\n        returns the proxy type and descriptor.\n        \"\"\"\n        return self.__get__(instance, type(instance))(*args, **kwargs)\n\n\nclass _ProxyIOp(_ProxyLookup):\n    \"\"\"Look up an augmented assignment method on a proxied object. The\n    method is wrapped to return the proxy instead of the object.\n    \"\"\"\n\n    __slots__ = ()\n\n    def __init__(\n        self,\n        f: t.Callable[..., t.Any] | None = None,\n        fallback: t.Callable[[LocalProxy[t.Any]], t.Any] | None = None,\n    ) -> None:\n        super().__init__(f, fallback)\n\n        def bind_f(instance: LocalProxy[t.Any], obj: t.Any) -> t.Callable[..., t.Any]:\n            def i_op(self: t.Any, other: t.Any) -> LocalProxy[t.Any]:\n                f(self, other)  # type: ignore\n                return instance\n\n            return i_op.__get__(obj, type(obj))  # type: ignore\n\n        self.bind_f = bind_f\n\n\ndef _l_to_r_op(op: F) -> F:\n    \"\"\"Swap the argument order to turn an l-op into an r-op.\"\"\"\n\n    def r_op(obj: t.Any, other: t.Any) -> t.Any:\n        return op(other, obj)\n\n    return t.cast(F, r_op)\n\n\ndef _identity(o: T) -> T:\n    return o\n\n\nclass LocalProxy(t.Generic[T]):\n    \"\"\"A proxy to the object bound to a context-local object. All\n    operations on the proxy are forwarded to the bound object. If no\n    object is bound, a ``RuntimeError`` is raised.\n\n    :param local: The context-local object that provides the proxied\n        object.\n    :param name: Proxy this attribute from the proxied object.\n    :param unbound_message: The error message to show if the\n        context-local object is unbound.\n\n    Proxy a :class:`~contextvars.ContextVar` to make it easier to\n    access. Pass a name to proxy that attribute.\n\n    .. code-block:: python\n\n        _request_var = ContextVar(\"request\")\n        request = LocalProxy(_request_var)\n        session = LocalProxy(_request_var, \"session\")\n\n    Proxy an attribute on a :class:`Local` namespace by calling the\n    local with the attribute name:\n\n    .. code-block:: python\n\n        data = Local()\n        user = data(\"user\")\n\n    Proxy the top item on a :class:`LocalStack` by calling the local.\n    Pass a name to proxy that attribute.\n\n    .. code-block::\n\n        app_stack = LocalStack()\n        current_app = app_stack()\n        g = app_stack(\"g\")\n\n    Pass a function to proxy the return value from that function. This\n    was previously used to access attributes of local objects before\n    that was supported directly.\n\n    .. code-block:: python\n\n        session = LocalProxy(lambda: request.session)\n\n    ``__repr__`` and ``__class__`` are proxied, so ``repr(x)`` and\n    ``isinstance(x, cls)`` will look like the proxied object. Use\n    ``issubclass(type(x), LocalProxy)`` to check if an object is a\n    proxy.\n\n    .. code-block:: python\n\n        repr(user)  # <User admin>\n        isinstance(user, User)  # True\n        issubclass(type(user), LocalProxy)  # True\n\n    .. versionchanged:: 2.2.2\n        ``__wrapped__`` is set when wrapping an object, not only when\n        wrapping a function, to prevent doctest from failing.\n\n    .. versionchanged:: 2.2\n        Can proxy a ``ContextVar`` or ``LocalStack`` directly.\n\n    .. versionchanged:: 2.2\n        The ``name`` parameter can be used with any proxied object, not\n        only ``Local``.\n\n    .. versionchanged:: 2.2\n        Added the ``unbound_message`` parameter.\n\n    .. versionchanged:: 2.0\n        Updated proxied attributes and methods to reflect the current\n        data model.\n\n    .. versionchanged:: 0.6.1\n        The class can be instantiated with a callable.\n    \"\"\"\n\n    __slots__ = (\"__wrapped\", \"_get_current_object\")\n\n    _get_current_object: t.Callable[[], T]\n    \"\"\"Return the current object this proxy is bound to. If the proxy is\n    unbound, this raises a ``RuntimeError``.\n\n    This should be used if you need to pass the object to something that\n    doesn't understand the proxy. It can also be useful for performance\n    if you are accessing the object multiple times in a function, rather\n    than going through the proxy multiple times.\n    \"\"\"\n\n    def __init__(\n        self,\n        local: ContextVar[T] | Local | LocalStack[T] | t.Callable[[], T],\n        name: str | None = None,\n        *,\n        unbound_message: str | None = None,\n    ) -> None:\n        if name is None:\n            get_name = _identity\n        else:\n            get_name = attrgetter(name)  # type: ignore[assignment]\n\n        if unbound_message is None:\n            unbound_message = \"object is not bound\"\n\n        if isinstance(local, Local):\n            if name is None:\n                raise TypeError(\"'name' is required when proxying a 'Local' object.\")\n\n            def _get_current_object() -> T:\n                try:\n                    return get_name(local)  # type: ignore[return-value]\n                except AttributeError:\n                    raise RuntimeError(unbound_message) from None\n\n        elif isinstance(local, LocalStack):\n\n            def _get_current_object() -> T:\n                obj = local.top\n\n                if obj is None:\n                    raise RuntimeError(unbound_message)\n\n                return get_name(obj)\n\n        elif isinstance(local, ContextVar):\n\n            def _get_current_object() -> T:\n                try:\n                    obj = local.get()\n                except LookupError:\n                    raise RuntimeError(unbound_message) from None\n\n                return get_name(obj)\n\n        elif callable(local):\n\n            def _get_current_object() -> T:\n                return get_name(local())\n\n        else:\n            raise TypeError(f\"Don't know how to proxy '{type(local)}'.\")\n\n        object.__setattr__(self, \"_LocalProxy__wrapped\", local)\n        object.__setattr__(self, \"_get_current_object\", _get_current_object)\n\n    __doc__ = _ProxyLookup(  # type: ignore[assignment]\n        class_value=__doc__, fallback=lambda self: type(self).__doc__, is_attr=True\n    )\n    __wrapped__ = _ProxyLookup(\n        fallback=lambda self: self._LocalProxy__wrapped,  # type: ignore[attr-defined]\n        is_attr=True,\n    )\n    # __del__ should only delete the proxy\n    __repr__ = _ProxyLookup(  # type: ignore[assignment]\n        repr, fallback=lambda self: f\"<{type(self).__name__} unbound>\"\n    )\n    __str__ = _ProxyLookup(str)  # type: ignore[assignment]\n    __bytes__ = _ProxyLookup(bytes)\n    __format__ = _ProxyLookup()  # type: ignore[assignment]\n    __lt__ = _ProxyLookup(operator.lt)\n    __le__ = _ProxyLookup(operator.le)\n    __eq__ = _ProxyLookup(operator.eq)  # type: ignore[assignment]\n    __ne__ = _ProxyLookup(operator.ne)  # type: ignore[assignment]\n    __gt__ = _ProxyLookup(operator.gt)\n    __ge__ = _ProxyLookup(operator.ge)\n    __hash__ = _ProxyLookup(hash)  # type: ignore[assignment]\n    __bool__ = _ProxyLookup(bool, fallback=lambda self: False)\n    __getattr__ = _ProxyLookup(getattr)\n    # __getattribute__ triggered through __getattr__\n    __setattr__ = _ProxyLookup(setattr)  # type: ignore[assignment]\n    __delattr__ = _ProxyLookup(delattr)  # type: ignore[assignment]\n    __dir__ = _ProxyLookup(dir, fallback=lambda self: [])  # type: ignore[assignment]\n    # __get__ (proxying descriptor not supported)\n    # __set__ (descriptor)\n    # __delete__ (descriptor)\n    # __set_name__ (descriptor)\n    # __objclass__ (descriptor)\n    # __slots__ used by proxy itself\n    # __dict__ (__getattr__)\n    # __weakref__ (__getattr__)\n    # __init_subclass__ (proxying metaclass not supported)\n    # __prepare__ (metaclass)\n    __class__ = _ProxyLookup(fallback=lambda self: type(self), is_attr=True)  # type: ignore[assignment]\n    __instancecheck__ = _ProxyLookup(lambda self, other: isinstance(other, self))\n    __subclasscheck__ = _ProxyLookup(lambda self, other: issubclass(other, self))\n    # __class_getitem__ triggered through __getitem__\n    __call__ = _ProxyLookup(lambda self, *args, **kwargs: self(*args, **kwargs))\n    __len__ = _ProxyLookup(len)\n    __length_hint__ = _ProxyLookup(operator.length_hint)\n    __getitem__ = _ProxyLookup(operator.getitem)\n    __setitem__ = _ProxyLookup(operator.setitem)\n    __delitem__ = _ProxyLookup(operator.delitem)\n    # __missing__ triggered through __getitem__\n    __iter__ = _ProxyLookup(iter)\n    __next__ = _ProxyLookup(next)\n    __reversed__ = _ProxyLookup(reversed)\n    __contains__ = _ProxyLookup(operator.contains)\n    __add__ = _ProxyLookup(operator.add)\n    __sub__ = _ProxyLookup(operator.sub)\n    __mul__ = _ProxyLookup(operator.mul)\n    __matmul__ = _ProxyLookup(operator.matmul)\n    __truediv__ = _ProxyLookup(operator.truediv)\n    __floordiv__ = _ProxyLookup(operator.floordiv)\n    __mod__ = _ProxyLookup(operator.mod)\n    __divmod__ = _ProxyLookup(divmod)\n    __pow__ = _ProxyLookup(pow)\n    __lshift__ = _ProxyLookup(operator.lshift)\n    __rshift__ = _ProxyLookup(operator.rshift)\n    __and__ = _ProxyLookup(operator.and_)\n    __xor__ = _ProxyLookup(operator.xor)\n    __or__ = _ProxyLookup(operator.or_)\n    __radd__ = _ProxyLookup(_l_to_r_op(operator.add))\n    __rsub__ = _ProxyLookup(_l_to_r_op(operator.sub))\n    __rmul__ = _ProxyLookup(_l_to_r_op(operator.mul))\n    __rmatmul__ = _ProxyLookup(_l_to_r_op(operator.matmul))\n    __rtruediv__ = _ProxyLookup(_l_to_r_op(operator.truediv))\n    __rfloordiv__ = _ProxyLookup(_l_to_r_op(operator.floordiv))\n    __rmod__ = _ProxyLookup(_l_to_r_op(operator.mod))\n    __rdivmod__ = _ProxyLookup(_l_to_r_op(divmod))\n    __rpow__ = _ProxyLookup(_l_to_r_op(pow))\n    __rlshift__ = _ProxyLookup(_l_to_r_op(operator.lshift))\n    __rrshift__ = _ProxyLookup(_l_to_r_op(operator.rshift))\n    __rand__ = _ProxyLookup(_l_to_r_op(operator.and_))\n    __rxor__ = _ProxyLookup(_l_to_r_op(operator.xor))\n    __ror__ = _ProxyLookup(_l_to_r_op(operator.or_))\n    __iadd__ = _ProxyIOp(operator.iadd)\n    __isub__ = _ProxyIOp(operator.isub)\n    __imul__ = _ProxyIOp(operator.imul)\n    __imatmul__ = _ProxyIOp(operator.imatmul)\n    __itruediv__ = _ProxyIOp(operator.itruediv)\n    __ifloordiv__ = _ProxyIOp(operator.ifloordiv)\n    __imod__ = _ProxyIOp(operator.imod)\n    __ipow__ = _ProxyIOp(operator.ipow)\n    __ilshift__ = _ProxyIOp(operator.ilshift)\n    __irshift__ = _ProxyIOp(operator.irshift)\n    __iand__ = _ProxyIOp(operator.iand)\n    __ixor__ = _ProxyIOp(operator.ixor)\n    __ior__ = _ProxyIOp(operator.ior)\n    __neg__ = _ProxyLookup(operator.neg)\n    __pos__ = _ProxyLookup(operator.pos)\n    __abs__ = _ProxyLookup(abs)\n    __invert__ = _ProxyLookup(operator.invert)\n    __complex__ = _ProxyLookup(complex)\n    __int__ = _ProxyLookup(int)\n    __float__ = _ProxyLookup(float)\n    __index__ = _ProxyLookup(operator.index)\n    __round__ = _ProxyLookup(round)\n    __trunc__ = _ProxyLookup(math.trunc)\n    __floor__ = _ProxyLookup(math.floor)\n    __ceil__ = _ProxyLookup(math.ceil)\n    __enter__ = _ProxyLookup()\n    __exit__ = _ProxyLookup()\n    __await__ = _ProxyLookup()\n    __aiter__ = _ProxyLookup()\n    __anext__ = _ProxyLookup()\n    __aenter__ = _ProxyLookup()\n    __aexit__ = _ProxyLookup()\n    __copy__ = _ProxyLookup(copy.copy)\n    __deepcopy__ = _ProxyLookup(copy.deepcopy)\n    # __getnewargs_ex__ (pickle through proxy not supported)\n    # __getnewargs__ (pickle)\n    # __getstate__ (pickle)\n    # __setstate__ (pickle)\n    # __reduce__ (pickle)\n    # __reduce_ex__ (pickle)\n", "src/werkzeug/http.py": "from __future__ import annotations\n\nimport email.utils\nimport re\nimport typing as t\nimport warnings\nfrom datetime import date\nfrom datetime import datetime\nfrom datetime import time\nfrom datetime import timedelta\nfrom datetime import timezone\nfrom enum import Enum\nfrom hashlib import sha1\nfrom time import mktime\nfrom time import struct_time\nfrom urllib.parse import quote\nfrom urllib.parse import unquote\nfrom urllib.request import parse_http_list as _parse_list_header\n\nfrom ._internal import _dt_as_utc\nfrom ._internal import _plain_int\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import WSGIEnvironment\n\n_token_chars = frozenset(\n    \"!#$%&'*+-.0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ^_`abcdefghijklmnopqrstuvwxyz|~\"\n)\n_etag_re = re.compile(r'([Ww]/)?(?:\"(.*?)\"|(.*?))(?:\\s*,\\s*|$)')\n_entity_headers = frozenset(\n    [\n        \"allow\",\n        \"content-encoding\",\n        \"content-language\",\n        \"content-length\",\n        \"content-location\",\n        \"content-md5\",\n        \"content-range\",\n        \"content-type\",\n        \"expires\",\n        \"last-modified\",\n    ]\n)\n_hop_by_hop_headers = frozenset(\n    [\n        \"connection\",\n        \"keep-alive\",\n        \"proxy-authenticate\",\n        \"proxy-authorization\",\n        \"te\",\n        \"trailer\",\n        \"transfer-encoding\",\n        \"upgrade\",\n    ]\n)\nHTTP_STATUS_CODES = {\n    100: \"Continue\",\n    101: \"Switching Protocols\",\n    102: \"Processing\",\n    103: \"Early Hints\",  # see RFC 8297\n    200: \"OK\",\n    201: \"Created\",\n    202: \"Accepted\",\n    203: \"Non Authoritative Information\",\n    204: \"No Content\",\n    205: \"Reset Content\",\n    206: \"Partial Content\",\n    207: \"Multi Status\",\n    208: \"Already Reported\",  # see RFC 5842\n    226: \"IM Used\",  # see RFC 3229\n    300: \"Multiple Choices\",\n    301: \"Moved Permanently\",\n    302: \"Found\",\n    303: \"See Other\",\n    304: \"Not Modified\",\n    305: \"Use Proxy\",\n    306: \"Switch Proxy\",  # unused\n    307: \"Temporary Redirect\",\n    308: \"Permanent Redirect\",\n    400: \"Bad Request\",\n    401: \"Unauthorized\",\n    402: \"Payment Required\",  # unused\n    403: \"Forbidden\",\n    404: \"Not Found\",\n    405: \"Method Not Allowed\",\n    406: \"Not Acceptable\",\n    407: \"Proxy Authentication Required\",\n    408: \"Request Timeout\",\n    409: \"Conflict\",\n    410: \"Gone\",\n    411: \"Length Required\",\n    412: \"Precondition Failed\",\n    413: \"Request Entity Too Large\",\n    414: \"Request URI Too Long\",\n    415: \"Unsupported Media Type\",\n    416: \"Requested Range Not Satisfiable\",\n    417: \"Expectation Failed\",\n    418: \"I'm a teapot\",  # see RFC 2324\n    421: \"Misdirected Request\",  # see RFC 7540\n    422: \"Unprocessable Entity\",\n    423: \"Locked\",\n    424: \"Failed Dependency\",\n    425: \"Too Early\",  # see RFC 8470\n    426: \"Upgrade Required\",\n    428: \"Precondition Required\",  # see RFC 6585\n    429: \"Too Many Requests\",\n    431: \"Request Header Fields Too Large\",\n    449: \"Retry With\",  # proprietary MS extension\n    451: \"Unavailable For Legal Reasons\",\n    500: \"Internal Server Error\",\n    501: \"Not Implemented\",\n    502: \"Bad Gateway\",\n    503: \"Service Unavailable\",\n    504: \"Gateway Timeout\",\n    505: \"HTTP Version Not Supported\",\n    506: \"Variant Also Negotiates\",  # see RFC 2295\n    507: \"Insufficient Storage\",\n    508: \"Loop Detected\",  # see RFC 5842\n    510: \"Not Extended\",\n    511: \"Network Authentication Failed\",\n}\n\n\nclass COEP(Enum):\n    \"\"\"Cross Origin Embedder Policies\"\"\"\n\n    UNSAFE_NONE = \"unsafe-none\"\n    REQUIRE_CORP = \"require-corp\"\n\n\nclass COOP(Enum):\n    \"\"\"Cross Origin Opener Policies\"\"\"\n\n    UNSAFE_NONE = \"unsafe-none\"\n    SAME_ORIGIN_ALLOW_POPUPS = \"same-origin-allow-popups\"\n    SAME_ORIGIN = \"same-origin\"\n\n\ndef quote_header_value(value: t.Any, allow_token: bool = True) -> str:\n    \"\"\"Add double quotes around a header value. If the header contains only ASCII token\n    characters, it will be returned unchanged. If the header contains ``\"`` or ``\\\\``\n    characters, they will be escaped with an additional ``\\\\`` character.\n\n    This is the reverse of :func:`unquote_header_value`.\n\n    :param value: The value to quote. Will be converted to a string.\n    :param allow_token: Disable to quote the value even if it only has token characters.\n\n    .. versionchanged:: 3.0\n        Passing bytes is not supported.\n\n    .. versionchanged:: 3.0\n        The ``extra_chars`` parameter is removed.\n\n    .. versionchanged:: 2.3\n        The value is quoted if it is the empty string.\n\n    .. versionadded:: 0.5\n    \"\"\"\n    value_str = str(value)\n\n    if not value_str:\n        return '\"\"'\n\n    if allow_token:\n        token_chars = _token_chars\n\n        if token_chars.issuperset(value_str):\n            return value_str\n\n    value_str = value_str.replace(\"\\\\\", \"\\\\\\\\\").replace('\"', '\\\\\"')\n    return f'\"{value_str}\"'\n\n\ndef unquote_header_value(value: str) -> str:\n    \"\"\"Remove double quotes and decode slash-escaped ``\"`` and ``\\\\`` characters in a\n    header value.\n\n    This is the reverse of :func:`quote_header_value`.\n\n    :param value: The header value to unquote.\n\n    .. versionchanged:: 3.0\n        The ``is_filename`` parameter is removed.\n    \"\"\"\n    if len(value) >= 2 and value[0] == value[-1] == '\"':\n        value = value[1:-1]\n        return value.replace(\"\\\\\\\\\", \"\\\\\").replace('\\\\\"', '\"')\n\n    return value\n\n\ndef dump_options_header(header: str | None, options: t.Mapping[str, t.Any]) -> str:\n    \"\"\"Produce a header value and ``key=value`` parameters separated by semicolons\n    ``;``. For example, the ``Content-Type`` header.\n\n    .. code-block:: python\n\n        dump_options_header(\"text/html\", {\"charset\": \"UTF-8\"})\n        'text/html; charset=UTF-8'\n\n    This is the reverse of :func:`parse_options_header`.\n\n    If a value contains non-token characters, it will be quoted.\n\n    If a value is ``None``, the parameter is skipped.\n\n    In some keys for some headers, a UTF-8 value can be encoded using a special\n    ``key*=UTF-8''value`` form, where ``value`` is percent encoded. This function will\n    not produce that format automatically, but if a given key ends with an asterisk\n    ``*``, the value is assumed to have that form and will not be quoted further.\n\n    :param header: The primary header value.\n    :param options: Parameters to encode as ``key=value`` pairs.\n\n    .. versionchanged:: 2.3\n        Keys with ``None`` values are skipped rather than treated as a bare key.\n\n    .. versionchanged:: 2.2.3\n        If a key ends with ``*``, its value will not be quoted.\n    \"\"\"\n    segments = []\n\n    if header is not None:\n        segments.append(header)\n\n    for key, value in options.items():\n        if value is None:\n            continue\n\n        if key[-1] == \"*\":\n            segments.append(f\"{key}={value}\")\n        else:\n            segments.append(f\"{key}={quote_header_value(value)}\")\n\n    return \"; \".join(segments)\n\n\ndef dump_header(iterable: dict[str, t.Any] | t.Iterable[t.Any]) -> str:\n    \"\"\"Produce a header value from a list of items or ``key=value`` pairs, separated by\n    commas ``,``.\n\n    This is the reverse of :func:`parse_list_header`, :func:`parse_dict_header`, and\n    :func:`parse_set_header`.\n\n    If a value contains non-token characters, it will be quoted.\n\n    If a value is ``None``, the key is output alone.\n\n    In some keys for some headers, a UTF-8 value can be encoded using a special\n    ``key*=UTF-8''value`` form, where ``value`` is percent encoded. This function will\n    not produce that format automatically, but if a given key ends with an asterisk\n    ``*``, the value is assumed to have that form and will not be quoted further.\n\n    .. code-block:: python\n\n        dump_header([\"foo\", \"bar baz\"])\n        'foo, \"bar baz\"'\n\n        dump_header({\"foo\": \"bar baz\"})\n        'foo=\"bar baz\"'\n\n    :param iterable: The items to create a header from.\n\n    .. versionchanged:: 3.0\n        The ``allow_token`` parameter is removed.\n\n    .. versionchanged:: 2.2.3\n        If a key ends with ``*``, its value will not be quoted.\n    \"\"\"\n    if isinstance(iterable, dict):\n        items = []\n\n        for key, value in iterable.items():\n            if value is None:\n                items.append(key)\n            elif key[-1] == \"*\":\n                items.append(f\"{key}={value}\")\n            else:\n                items.append(f\"{key}={quote_header_value(value)}\")\n    else:\n        items = [quote_header_value(x) for x in iterable]\n\n    return \", \".join(items)\n\n\ndef dump_csp_header(header: ds.ContentSecurityPolicy) -> str:\n    \"\"\"Dump a Content Security Policy header.\n\n    These are structured into policies such as \"default-src 'self';\n    script-src 'self'\".\n\n    .. versionadded:: 1.0.0\n       Support for Content Security Policy headers was added.\n\n    \"\"\"\n    return \"; \".join(f\"{key} {value}\" for key, value in header.items())\n\n\ndef parse_list_header(value: str) -> list[str]:\n    \"\"\"Parse a header value that consists of a list of comma separated items according\n    to `RFC 9110 <https://httpwg.org/specs/rfc9110.html#abnf.extension>`__.\n\n    This extends :func:`urllib.request.parse_http_list` to remove surrounding quotes\n    from values.\n\n    .. code-block:: python\n\n        parse_list_header('token, \"quoted value\"')\n        ['token', 'quoted value']\n\n    This is the reverse of :func:`dump_header`.\n\n    :param value: The header value to parse.\n    \"\"\"\n    result = []\n\n    for item in _parse_list_header(value):\n        if len(item) >= 2 and item[0] == item[-1] == '\"':\n            item = item[1:-1]\n\n        result.append(item)\n\n    return result\n\n\ndef parse_dict_header(value: str) -> dict[str, str | None]:\n    \"\"\"Parse a list header using :func:`parse_list_header`, then parse each item as a\n    ``key=value`` pair.\n\n    .. code-block:: python\n\n        parse_dict_header('a=b, c=\"d, e\", f')\n        {\"a\": \"b\", \"c\": \"d, e\", \"f\": None}\n\n    This is the reverse of :func:`dump_header`.\n\n    If a key does not have a value, it is ``None``.\n\n    This handles charsets for values as described in\n    `RFC 2231 <https://www.rfc-editor.org/rfc/rfc2231#section-3>`__. Only ASCII, UTF-8,\n    and ISO-8859-1 charsets are accepted, otherwise the value remains quoted.\n\n    :param value: The header value to parse.\n\n    .. versionchanged:: 3.0\n        Passing bytes is not supported.\n\n    .. versionchanged:: 3.0\n        The ``cls`` argument is removed.\n\n    .. versionchanged:: 2.3\n        Added support for ``key*=charset''value`` encoded items.\n\n    .. versionchanged:: 0.9\n       The ``cls`` argument was added.\n    \"\"\"\n    result: dict[str, str | None] = {}\n\n    for item in parse_list_header(value):\n        key, has_value, value = item.partition(\"=\")\n        key = key.strip()\n\n        if not has_value:\n            result[key] = None\n            continue\n\n        value = value.strip()\n        encoding: str | None = None\n\n        if key[-1] == \"*\":\n            # key*=charset''value becomes key=value, where value is percent encoded\n            # adapted from parse_options_header, without the continuation handling\n            key = key[:-1]\n            match = _charset_value_re.match(value)\n\n            if match:\n                # If there is a charset marker in the value, split it off.\n                encoding, value = match.groups()\n                encoding = encoding.lower()\n\n            # A safe list of encodings. Modern clients should only send ASCII or UTF-8.\n            # This list will not be extended further. An invalid encoding will leave the\n            # value quoted.\n            if encoding in {\"ascii\", \"us-ascii\", \"utf-8\", \"iso-8859-1\"}:\n                # invalid bytes are replaced during unquoting\n                value = unquote(value, encoding=encoding)\n\n        if len(value) >= 2 and value[0] == value[-1] == '\"':\n            value = value[1:-1]\n\n        result[key] = value\n\n    return result\n\n\n# https://httpwg.org/specs/rfc9110.html#parameter\n_parameter_re = re.compile(\n    r\"\"\"\n    # don't match multiple empty parts, that causes backtracking\n    \\s*;\\s*  # find the part delimiter\n    (?:\n        ([\\w!#$%&'*+\\-.^`|~]+)  # key, one or more token chars\n        =  # equals, with no space on either side\n        (  # value, token or quoted string\n            [\\w!#$%&'*+\\-.^`|~]+  # one or more token chars\n        |\n            \"(?:\\\\\\\\|\\\\\"|.)*?\"  # quoted string, consuming slash escapes\n        )\n    )?  # optionally match key=value, to account for empty parts\n    \"\"\",\n    re.ASCII | re.VERBOSE,\n)\n# https://www.rfc-editor.org/rfc/rfc2231#section-4\n_charset_value_re = re.compile(\n    r\"\"\"\n    ([\\w!#$%&*+\\-.^`|~]*)'  # charset part, could be empty\n    [\\w!#$%&*+\\-.^`|~]*'  # don't care about language part, usually empty\n    ([\\w!#$%&'*+\\-.^`|~]+)  # one or more token chars with percent encoding\n    \"\"\",\n    re.ASCII | re.VERBOSE,\n)\n# https://www.rfc-editor.org/rfc/rfc2231#section-3\n_continuation_re = re.compile(r\"\\*(\\d+)$\", re.ASCII)\n\n\ndef parse_options_header(value: str | None) -> tuple[str, dict[str, str]]:\n    \"\"\"Parse a header that consists of a value with ``key=value`` parameters separated\n    by semicolons ``;``. For example, the ``Content-Type`` header.\n\n    .. code-block:: python\n\n        parse_options_header(\"text/html; charset=UTF-8\")\n        ('text/html', {'charset': 'UTF-8'})\n\n        parse_options_header(\"\")\n        (\"\", {})\n\n    This is the reverse of :func:`dump_options_header`.\n\n    This parses valid parameter parts as described in\n    `RFC 9110 <https://httpwg.org/specs/rfc9110.html#parameter>`__. Invalid parts are\n    skipped.\n\n    This handles continuations and charsets as described in\n    `RFC 2231 <https://www.rfc-editor.org/rfc/rfc2231#section-3>`__, although not as\n    strictly as the RFC. Only ASCII, UTF-8, and ISO-8859-1 charsets are accepted,\n    otherwise the value remains quoted.\n\n    Clients may not be consistent in how they handle a quote character within a quoted\n    value. The `HTML Standard <https://html.spec.whatwg.org/#multipart-form-data>`__\n    replaces it with ``%22`` in multipart form data.\n    `RFC 9110 <https://httpwg.org/specs/rfc9110.html#quoted.strings>`__ uses backslash\n    escapes in HTTP headers. Both are decoded to the ``\"`` character.\n\n    Clients may not be consistent in how they handle non-ASCII characters. HTML\n    documents must declare ``<meta charset=UTF-8>``, otherwise browsers may replace with\n    HTML character references, which can be decoded using :func:`html.unescape`.\n\n    :param value: The header value to parse.\n    :return: ``(value, options)``, where ``options`` is a dict\n\n    .. versionchanged:: 2.3\n        Invalid parts, such as keys with no value, quoted keys, and incorrectly quoted\n        values, are discarded instead of treating as ``None``.\n\n    .. versionchanged:: 2.3\n        Only ASCII, UTF-8, and ISO-8859-1 are accepted for charset values.\n\n    .. versionchanged:: 2.3\n        Escaped quotes in quoted values, like ``%22`` and ``\\\\\"``, are handled.\n\n    .. versionchanged:: 2.2\n        Option names are always converted to lowercase.\n\n    .. versionchanged:: 2.2\n        The ``multiple`` parameter was removed.\n\n    .. versionchanged:: 0.15\n        :rfc:`2231` parameter continuations are handled.\n\n    .. versionadded:: 0.5\n    \"\"\"\n    if value is None:\n        return \"\", {}\n\n    value, _, rest = value.partition(\";\")\n    value = value.strip()\n    rest = rest.strip()\n\n    if not value or not rest:\n        # empty (invalid) value, or value without options\n        return value, {}\n\n    rest = f\";{rest}\"\n    options: dict[str, str] = {}\n    encoding: str | None = None\n    continued_encoding: str | None = None\n\n    for pk, pv in _parameter_re.findall(rest):\n        if not pk:\n            # empty or invalid part\n            continue\n\n        pk = pk.lower()\n\n        if pk[-1] == \"*\":\n            # key*=charset''value becomes key=value, where value is percent encoded\n            pk = pk[:-1]\n            match = _charset_value_re.match(pv)\n\n            if match:\n                # If there is a valid charset marker in the value, split it off.\n                encoding, pv = match.groups()\n                # This might be the empty string, handled next.\n                encoding = encoding.lower()\n\n            # No charset marker, or marker with empty charset value.\n            if not encoding:\n                encoding = continued_encoding\n\n            # A safe list of encodings. Modern clients should only send ASCII or UTF-8.\n            # This list will not be extended further. An invalid encoding will leave the\n            # value quoted.\n            if encoding in {\"ascii\", \"us-ascii\", \"utf-8\", \"iso-8859-1\"}:\n                # Continuation parts don't require their own charset marker. This is\n                # looser than the RFC, it will persist across different keys and allows\n                # changing the charset during a continuation. But this implementation is\n                # much simpler than tracking the full state.\n                continued_encoding = encoding\n                # invalid bytes are replaced during unquoting\n                pv = unquote(pv, encoding=encoding)\n\n        # Remove quotes. At this point the value cannot be empty or a single quote.\n        if pv[0] == pv[-1] == '\"':\n            # HTTP headers use slash, multipart form data uses percent\n            pv = pv[1:-1].replace(\"\\\\\\\\\", \"\\\\\").replace('\\\\\"', '\"').replace(\"%22\", '\"')\n\n        match = _continuation_re.search(pk)\n\n        if match:\n            # key*0=a; key*1=b becomes key=ab\n            pk = pk[: match.start()]\n            options[pk] = options.get(pk, \"\") + pv\n        else:\n            options[pk] = pv\n\n    return value, options\n\n\n_q_value_re = re.compile(r\"-?\\d+(\\.\\d+)?\", re.ASCII)\n_TAnyAccept = t.TypeVar(\"_TAnyAccept\", bound=\"ds.Accept\")\n\n\n@t.overload\ndef parse_accept_header(value: str | None) -> ds.Accept: ...\n\n\n@t.overload\ndef parse_accept_header(value: str | None, cls: type[_TAnyAccept]) -> _TAnyAccept: ...\n\n\ndef parse_accept_header(\n    value: str | None, cls: type[_TAnyAccept] | None = None\n) -> _TAnyAccept:\n    \"\"\"Parse an ``Accept`` header according to\n    `RFC 9110 <https://httpwg.org/specs/rfc9110.html#field.accept>`__.\n\n    Returns an :class:`.Accept` instance, which can sort and inspect items based on\n    their quality parameter. When parsing ``Accept-Charset``, ``Accept-Encoding``, or\n    ``Accept-Language``, pass the appropriate :class:`.Accept` subclass.\n\n    :param value: The header value to parse.\n    :param cls: The :class:`.Accept` class to wrap the result in.\n    :return: An instance of ``cls``.\n\n    .. versionchanged:: 2.3\n        Parse according to RFC 9110. Items with invalid ``q`` values are skipped.\n    \"\"\"\n    if cls is None:\n        cls = t.cast(t.Type[_TAnyAccept], ds.Accept)\n\n    if not value:\n        return cls(None)\n\n    result = []\n\n    for item in parse_list_header(value):\n        item, options = parse_options_header(item)\n\n        if \"q\" in options:\n            # pop q, remaining options are reconstructed\n            q_str = options.pop(\"q\").strip()\n\n            if _q_value_re.fullmatch(q_str) is None:\n                # ignore an invalid q\n                continue\n\n            q = float(q_str)\n\n            if q < 0 or q > 1:\n                # ignore an invalid q\n                continue\n        else:\n            q = 1\n\n        if options:\n            # reconstruct the media type with any options\n            item = dump_options_header(item, options)\n\n        result.append((item, q))\n\n    return cls(result)\n\n\n_TAnyCC = t.TypeVar(\"_TAnyCC\", bound=\"ds.cache_control._CacheControl\")\n\n\n@t.overload\ndef parse_cache_control_header(\n    value: str | None,\n    on_update: t.Callable[[ds.cache_control._CacheControl], None] | None = None,\n) -> ds.RequestCacheControl: ...\n\n\n@t.overload\ndef parse_cache_control_header(\n    value: str | None,\n    on_update: t.Callable[[ds.cache_control._CacheControl], None] | None = None,\n    cls: type[_TAnyCC] = ...,\n) -> _TAnyCC: ...\n\n\ndef parse_cache_control_header(\n    value: str | None,\n    on_update: t.Callable[[ds.cache_control._CacheControl], None] | None = None,\n    cls: type[_TAnyCC] | None = None,\n) -> _TAnyCC:\n    \"\"\"Parse a cache control header.  The RFC differs between response and\n    request cache control, this method does not.  It's your responsibility\n    to not use the wrong control statements.\n\n    .. versionadded:: 0.5\n       The `cls` was added.  If not specified an immutable\n       :class:`~werkzeug.datastructures.RequestCacheControl` is returned.\n\n    :param value: a cache control header to be parsed.\n    :param on_update: an optional callable that is called every time a value\n                      on the :class:`~werkzeug.datastructures.CacheControl`\n                      object is changed.\n    :param cls: the class for the returned object.  By default\n                :class:`~werkzeug.datastructures.RequestCacheControl` is used.\n    :return: a `cls` object.\n    \"\"\"\n    if cls is None:\n        cls = t.cast(\"type[_TAnyCC]\", ds.RequestCacheControl)\n\n    if not value:\n        return cls((), on_update)\n\n    return cls(parse_dict_header(value), on_update)\n\n\n_TAnyCSP = t.TypeVar(\"_TAnyCSP\", bound=\"ds.ContentSecurityPolicy\")\n\n\n@t.overload\ndef parse_csp_header(\n    value: str | None,\n    on_update: t.Callable[[ds.ContentSecurityPolicy], None] | None = None,\n) -> ds.ContentSecurityPolicy: ...\n\n\n@t.overload\ndef parse_csp_header(\n    value: str | None,\n    on_update: t.Callable[[ds.ContentSecurityPolicy], None] | None = None,\n    cls: type[_TAnyCSP] = ...,\n) -> _TAnyCSP: ...\n\n\ndef parse_csp_header(\n    value: str | None,\n    on_update: t.Callable[[ds.ContentSecurityPolicy], None] | None = None,\n    cls: type[_TAnyCSP] | None = None,\n) -> _TAnyCSP:\n    \"\"\"Parse a Content Security Policy header.\n\n    .. versionadded:: 1.0.0\n       Support for Content Security Policy headers was added.\n\n    :param value: a csp header to be parsed.\n    :param on_update: an optional callable that is called every time a value\n                      on the object is changed.\n    :param cls: the class for the returned object.  By default\n                :class:`~werkzeug.datastructures.ContentSecurityPolicy` is used.\n    :return: a `cls` object.\n    \"\"\"\n    if cls is None:\n        cls = t.cast(\"type[_TAnyCSP]\", ds.ContentSecurityPolicy)\n\n    if value is None:\n        return cls((), on_update)\n\n    items = []\n\n    for policy in value.split(\";\"):\n        policy = policy.strip()\n\n        # Ignore badly formatted policies (no space)\n        if \" \" in policy:\n            directive, value = policy.strip().split(\" \", 1)\n            items.append((directive.strip(), value.strip()))\n\n    return cls(items, on_update)\n\n\ndef parse_set_header(\n    value: str | None,\n    on_update: t.Callable[[ds.HeaderSet], None] | None = None,\n) -> ds.HeaderSet:\n    \"\"\"Parse a set-like header and return a\n    :class:`~werkzeug.datastructures.HeaderSet` object:\n\n    >>> hs = parse_set_header('token, \"quoted value\"')\n\n    The return value is an object that treats the items case-insensitively\n    and keeps the order of the items:\n\n    >>> 'TOKEN' in hs\n    True\n    >>> hs.index('quoted value')\n    1\n    >>> hs\n    HeaderSet(['token', 'quoted value'])\n\n    To create a header from the :class:`HeaderSet` again, use the\n    :func:`dump_header` function.\n\n    :param value: a set header to be parsed.\n    :param on_update: an optional callable that is called every time a\n                      value on the :class:`~werkzeug.datastructures.HeaderSet`\n                      object is changed.\n    :return: a :class:`~werkzeug.datastructures.HeaderSet`\n    \"\"\"\n    if not value:\n        return ds.HeaderSet(None, on_update)\n    return ds.HeaderSet(parse_list_header(value), on_update)\n\n\ndef parse_if_range_header(value: str | None) -> ds.IfRange:\n    \"\"\"Parses an if-range header which can be an etag or a date.  Returns\n    a :class:`~werkzeug.datastructures.IfRange` object.\n\n    .. versionchanged:: 2.0\n        If the value represents a datetime, it is timezone-aware.\n\n    .. versionadded:: 0.7\n    \"\"\"\n    if not value:\n        return ds.IfRange()\n    date = parse_date(value)\n    if date is not None:\n        return ds.IfRange(date=date)\n    # drop weakness information\n    return ds.IfRange(unquote_etag(value)[0])\n\n\ndef parse_range_header(\n    value: str | None, make_inclusive: bool = True\n) -> ds.Range | None:\n    \"\"\"Parses a range header into a :class:`~werkzeug.datastructures.Range`\n    object.  If the header is missing or malformed `None` is returned.\n    `ranges` is a list of ``(start, stop)`` tuples where the ranges are\n    non-inclusive.\n\n    .. versionadded:: 0.7\n    \"\"\"\n    if not value or \"=\" not in value:\n        return None\n\n    ranges = []\n    last_end = 0\n    units, rng = value.split(\"=\", 1)\n    units = units.strip().lower()\n\n    for item in rng.split(\",\"):\n        item = item.strip()\n        if \"-\" not in item:\n            return None\n        if item.startswith(\"-\"):\n            if last_end < 0:\n                return None\n            try:\n                begin = _plain_int(item)\n            except ValueError:\n                return None\n            end = None\n            last_end = -1\n        elif \"-\" in item:\n            begin_str, end_str = item.split(\"-\", 1)\n            begin_str = begin_str.strip()\n            end_str = end_str.strip()\n\n            try:\n                begin = _plain_int(begin_str)\n            except ValueError:\n                return None\n\n            if begin < last_end or last_end < 0:\n                return None\n            if end_str:\n                try:\n                    end = _plain_int(end_str) + 1\n                except ValueError:\n                    return None\n\n                if begin >= end:\n                    return None\n            else:\n                end = None\n            last_end = end if end is not None else -1\n        ranges.append((begin, end))\n\n    return ds.Range(units, ranges)\n\n\ndef parse_content_range_header(\n    value: str | None,\n    on_update: t.Callable[[ds.ContentRange], None] | None = None,\n) -> ds.ContentRange | None:\n    \"\"\"Parses a range header into a\n    :class:`~werkzeug.datastructures.ContentRange` object or `None` if\n    parsing is not possible.\n\n    .. versionadded:: 0.7\n\n    :param value: a content range header to be parsed.\n    :param on_update: an optional callable that is called every time a value\n                      on the :class:`~werkzeug.datastructures.ContentRange`\n                      object is changed.\n    \"\"\"\n    if value is None:\n        return None\n    try:\n        units, rangedef = (value or \"\").strip().split(None, 1)\n    except ValueError:\n        return None\n\n    if \"/\" not in rangedef:\n        return None\n    rng, length_str = rangedef.split(\"/\", 1)\n    if length_str == \"*\":\n        length = None\n    else:\n        try:\n            length = _plain_int(length_str)\n        except ValueError:\n            return None\n\n    if rng == \"*\":\n        if not is_byte_range_valid(None, None, length):\n            return None\n\n        return ds.ContentRange(units, None, None, length, on_update=on_update)\n    elif \"-\" not in rng:\n        return None\n\n    start_str, stop_str = rng.split(\"-\", 1)\n    try:\n        start = _plain_int(start_str)\n        stop = _plain_int(stop_str) + 1\n    except ValueError:\n        return None\n\n    if is_byte_range_valid(start, stop, length):\n        return ds.ContentRange(units, start, stop, length, on_update=on_update)\n\n    return None\n\n\ndef quote_etag(etag: str, weak: bool = False) -> str:\n    \"\"\"Quote an etag.\n\n    :param etag: the etag to quote.\n    :param weak: set to `True` to tag it \"weak\".\n    \"\"\"\n    if '\"' in etag:\n        raise ValueError(\"invalid etag\")\n    etag = f'\"{etag}\"'\n    if weak:\n        etag = f\"W/{etag}\"\n    return etag\n\n\ndef unquote_etag(\n    etag: str | None,\n) -> tuple[str, bool] | tuple[None, None]:\n    \"\"\"Unquote a single etag:\n\n    >>> unquote_etag('W/\"bar\"')\n    ('bar', True)\n    >>> unquote_etag('\"bar\"')\n    ('bar', False)\n\n    :param etag: the etag identifier to unquote.\n    :return: a ``(etag, weak)`` tuple.\n    \"\"\"\n    if not etag:\n        return None, None\n    etag = etag.strip()\n    weak = False\n    if etag.startswith((\"W/\", \"w/\")):\n        weak = True\n        etag = etag[2:]\n    if etag[:1] == etag[-1:] == '\"':\n        etag = etag[1:-1]\n    return etag, weak\n\n\ndef parse_etags(value: str | None) -> ds.ETags:\n    \"\"\"Parse an etag header.\n\n    :param value: the tag header to parse\n    :return: an :class:`~werkzeug.datastructures.ETags` object.\n    \"\"\"\n    if not value:\n        return ds.ETags()\n    strong = []\n    weak = []\n    end = len(value)\n    pos = 0\n    while pos < end:\n        match = _etag_re.match(value, pos)\n        if match is None:\n            break\n        is_weak, quoted, raw = match.groups()\n        if raw == \"*\":\n            return ds.ETags(star_tag=True)\n        elif quoted:\n            raw = quoted\n        if is_weak:\n            weak.append(raw)\n        else:\n            strong.append(raw)\n        pos = match.end()\n    return ds.ETags(strong, weak)\n\n\ndef generate_etag(data: bytes) -> str:\n    \"\"\"Generate an etag for some data.\n\n    .. versionchanged:: 2.0\n        Use SHA-1. MD5 may not be available in some environments.\n    \"\"\"\n    return sha1(data).hexdigest()\n\n\ndef parse_date(value: str | None) -> datetime | None:\n    \"\"\"Parse an :rfc:`2822` date into a timezone-aware\n    :class:`datetime.datetime` object, or ``None`` if parsing fails.\n\n    This is a wrapper for :func:`email.utils.parsedate_to_datetime`. It\n    returns ``None`` if parsing fails instead of raising an exception,\n    and always returns a timezone-aware datetime object. If the string\n    doesn't have timezone information, it is assumed to be UTC.\n\n    :param value: A string with a supported date format.\n\n    .. versionchanged:: 2.0\n        Return a timezone-aware datetime object. Use\n        ``email.utils.parsedate_to_datetime``.\n    \"\"\"\n    if value is None:\n        return None\n\n    try:\n        dt = email.utils.parsedate_to_datetime(value)\n    except (TypeError, ValueError):\n        return None\n\n    if dt.tzinfo is None:\n        return dt.replace(tzinfo=timezone.utc)\n\n    return dt\n\n\ndef http_date(\n    timestamp: datetime | date | int | float | struct_time | None = None,\n) -> str:\n    \"\"\"Format a datetime object or timestamp into an :rfc:`2822` date\n    string.\n\n    This is a wrapper for :func:`email.utils.format_datetime`. It\n    assumes naive datetime objects are in UTC instead of raising an\n    exception.\n\n    :param timestamp: The datetime or timestamp to format. Defaults to\n        the current time.\n\n    .. versionchanged:: 2.0\n        Use ``email.utils.format_datetime``. Accept ``date`` objects.\n    \"\"\"\n    if isinstance(timestamp, date):\n        if not isinstance(timestamp, datetime):\n            # Assume plain date is midnight UTC.\n            timestamp = datetime.combine(timestamp, time(), tzinfo=timezone.utc)\n        else:\n            # Ensure datetime is timezone-aware.\n            timestamp = _dt_as_utc(timestamp)\n\n        return email.utils.format_datetime(timestamp, usegmt=True)\n\n    if isinstance(timestamp, struct_time):\n        timestamp = mktime(timestamp)\n\n    return email.utils.formatdate(timestamp, usegmt=True)\n\n\ndef parse_age(value: str | None = None) -> timedelta | None:\n    \"\"\"Parses a base-10 integer count of seconds into a timedelta.\n\n    If parsing fails, the return value is `None`.\n\n    :param value: a string consisting of an integer represented in base-10\n    :return: a :class:`datetime.timedelta` object or `None`.\n    \"\"\"\n    if not value:\n        return None\n    try:\n        seconds = int(value)\n    except ValueError:\n        return None\n    if seconds < 0:\n        return None\n    try:\n        return timedelta(seconds=seconds)\n    except OverflowError:\n        return None\n\n\ndef dump_age(age: timedelta | int | None = None) -> str | None:\n    \"\"\"Formats the duration as a base-10 integer.\n\n    :param age: should be an integer number of seconds,\n                a :class:`datetime.timedelta` object, or,\n                if the age is unknown, `None` (default).\n    \"\"\"\n    if age is None:\n        return None\n    if isinstance(age, timedelta):\n        age = int(age.total_seconds())\n    else:\n        age = int(age)\n\n    if age < 0:\n        raise ValueError(\"age cannot be negative\")\n\n    return str(age)\n\n\ndef is_resource_modified(\n    environ: WSGIEnvironment,\n    etag: str | None = None,\n    data: bytes | None = None,\n    last_modified: datetime | str | None = None,\n    ignore_if_range: bool = True,\n) -> bool:\n    \"\"\"Convenience method for conditional requests.\n\n    :param environ: the WSGI environment of the request to be checked.\n    :param etag: the etag for the response for comparison.\n    :param data: or alternatively the data of the response to automatically\n                 generate an etag using :func:`generate_etag`.\n    :param last_modified: an optional date of the last modification.\n    :param ignore_if_range: If `False`, `If-Range` header will be taken into\n                            account.\n    :return: `True` if the resource was modified, otherwise `False`.\n\n    .. versionchanged:: 2.0\n        SHA-1 is used to generate an etag value for the data. MD5 may\n        not be available in some environments.\n\n    .. versionchanged:: 1.0.0\n        The check is run for methods other than ``GET`` and ``HEAD``.\n    \"\"\"\n    return _sansio_http.is_resource_modified(\n        http_range=environ.get(\"HTTP_RANGE\"),\n        http_if_range=environ.get(\"HTTP_IF_RANGE\"),\n        http_if_modified_since=environ.get(\"HTTP_IF_MODIFIED_SINCE\"),\n        http_if_none_match=environ.get(\"HTTP_IF_NONE_MATCH\"),\n        http_if_match=environ.get(\"HTTP_IF_MATCH\"),\n        etag=etag,\n        data=data,\n        last_modified=last_modified,\n        ignore_if_range=ignore_if_range,\n    )\n\n\ndef remove_entity_headers(\n    headers: ds.Headers | list[tuple[str, str]],\n    allowed: t.Iterable[str] = (\"expires\", \"content-location\"),\n) -> None:\n    \"\"\"Remove all entity headers from a list or :class:`Headers` object.  This\n    operation works in-place.  `Expires` and `Content-Location` headers are\n    by default not removed.  The reason for this is :rfc:`2616` section\n    10.3.5 which specifies some entity headers that should be sent.\n\n    .. versionchanged:: 0.5\n       added `allowed` parameter.\n\n    :param headers: a list or :class:`Headers` object.\n    :param allowed: a list of headers that should still be allowed even though\n                    they are entity headers.\n    \"\"\"\n    allowed = {x.lower() for x in allowed}\n    headers[:] = [\n        (key, value)\n        for key, value in headers\n        if not is_entity_header(key) or key.lower() in allowed\n    ]\n\n\ndef remove_hop_by_hop_headers(headers: ds.Headers | list[tuple[str, str]]) -> None:\n    \"\"\"Remove all HTTP/1.1 \"Hop-by-Hop\" headers from a list or\n    :class:`Headers` object.  This operation works in-place.\n\n    .. versionadded:: 0.5\n\n    :param headers: a list or :class:`Headers` object.\n    \"\"\"\n    headers[:] = [\n        (key, value) for key, value in headers if not is_hop_by_hop_header(key)\n    ]\n\n\ndef is_entity_header(header: str) -> bool:\n    \"\"\"Check if a header is an entity header.\n\n    .. versionadded:: 0.5\n\n    :param header: the header to test.\n    :return: `True` if it's an entity header, `False` otherwise.\n    \"\"\"\n    return header.lower() in _entity_headers\n\n\ndef is_hop_by_hop_header(header: str) -> bool:\n    \"\"\"Check if a header is an HTTP/1.1 \"Hop-by-Hop\" header.\n\n    .. versionadded:: 0.5\n\n    :param header: the header to test.\n    :return: `True` if it's an HTTP/1.1 \"Hop-by-Hop\" header, `False` otherwise.\n    \"\"\"\n    return header.lower() in _hop_by_hop_headers\n\n\ndef parse_cookie(\n    header: WSGIEnvironment | str | None,\n    cls: type[ds.MultiDict[str, str]] | None = None,\n) -> ds.MultiDict[str, str]:\n    \"\"\"Parse a cookie from a string or WSGI environ.\n\n    The same key can be provided multiple times, the values are stored\n    in-order. The default :class:`MultiDict` will have the first value\n    first, and all values can be retrieved with\n    :meth:`MultiDict.getlist`.\n\n    :param header: The cookie header as a string, or a WSGI environ dict\n        with a ``HTTP_COOKIE`` key.\n    :param cls: A dict-like class to store the parsed cookies in.\n        Defaults to :class:`MultiDict`.\n\n    .. versionchanged:: 3.0\n        Passing bytes, and the ``charset`` and ``errors`` parameters, were removed.\n\n    .. versionchanged:: 1.0\n        Returns a :class:`MultiDict` instead of a ``TypeConversionDict``.\n\n    .. versionchanged:: 0.5\n        Returns a :class:`TypeConversionDict` instead of a regular dict. The ``cls``\n        parameter was added.\n    \"\"\"\n    if isinstance(header, dict):\n        cookie = header.get(\"HTTP_COOKIE\")\n    else:\n        cookie = header\n\n    if cookie:\n        cookie = cookie.encode(\"latin1\").decode()\n\n    return _sansio_http.parse_cookie(cookie=cookie, cls=cls)\n\n\n_cookie_no_quote_re = re.compile(r\"[\\w!#$%&'()*+\\-./:<=>?@\\[\\]^`{|}~]*\", re.A)\n_cookie_slash_re = re.compile(rb\"[\\x00-\\x19\\\",;\\\\\\x7f-\\xff]\", re.A)\n_cookie_slash_map = {b'\"': b'\\\\\"', b\"\\\\\": b\"\\\\\\\\\"}\n_cookie_slash_map.update(\n    (v.to_bytes(1, \"big\"), b\"\\\\%03o\" % v)\n    for v in [*range(0x20), *b\",;\", *range(0x7F, 256)]\n)\n\n\ndef dump_cookie(\n    key: str,\n    value: str = \"\",\n    max_age: timedelta | int | None = None,\n    expires: str | datetime | int | float | None = None,\n    path: str | None = \"/\",\n    domain: str | None = None,\n    secure: bool = False,\n    httponly: bool = False,\n    sync_expires: bool = True,\n    max_size: int = 4093,\n    samesite: str | None = None,\n    partitioned: bool = False,\n) -> str:\n    \"\"\"Create a Set-Cookie header without the ``Set-Cookie`` prefix.\n\n    The return value is usually restricted to ascii as the vast majority\n    of values are properly escaped, but that is no guarantee. It's\n    tunneled through latin1 as required by :pep:`3333`.\n\n    The return value is not ASCII safe if the key contains unicode\n    characters.  This is technically against the specification but\n    happens in the wild.  It's strongly recommended to not use\n    non-ASCII values for the keys.\n\n    :param max_age: should be a number of seconds, or `None` (default) if\n                    the cookie should last only as long as the client's\n                    browser session.  Additionally `timedelta` objects\n                    are accepted, too.\n    :param expires: should be a `datetime` object or unix timestamp.\n    :param path: limits the cookie to a given path, per default it will\n                 span the whole domain.\n    :param domain: Use this if you want to set a cross-domain cookie. For\n                   example, ``domain=\"example.com\"`` will set a cookie\n                   that is readable by the domain ``www.example.com``,\n                   ``foo.example.com`` etc. Otherwise, a cookie will only\n                   be readable by the domain that set it.\n    :param secure: The cookie will only be available via HTTPS\n    :param httponly: disallow JavaScript to access the cookie.  This is an\n                     extension to the cookie standard and probably not\n                     supported by all browsers.\n    :param charset: the encoding for string values.\n    :param sync_expires: automatically set expires if max_age is defined\n                         but expires not.\n    :param max_size: Warn if the final header value exceeds this size. The\n        default, 4093, should be safely `supported by most browsers\n        <cookie_>`_. Set to 0 to disable this check.\n    :param samesite: Limits the scope of the cookie such that it will\n        only be attached to requests if those requests are same-site.\n    :param partitioned: Opts the cookie into partitioned storage. This\n        will also set secure to True\n\n    .. _`cookie`: http://browsercookielimits.squawky.net/\n\n    .. versionchanged:: 3.1\n        The ``partitioned`` parameter was added.\n\n    .. versionchanged:: 3.0\n        Passing bytes, and the ``charset`` parameter, were removed.\n\n    .. versionchanged:: 2.3.3\n        The ``path`` parameter is ``/`` by default.\n\n    .. versionchanged:: 2.3.1\n        The value allows more characters without quoting.\n\n    .. versionchanged:: 2.3\n        ``localhost`` and other names without a dot are allowed for the domain. A\n        leading dot is ignored.\n\n    .. versionchanged:: 2.3\n        The ``path`` parameter is ``None`` by default.\n\n    .. versionchanged:: 1.0.0\n        The string ``'None'`` is accepted for ``samesite``.\n    \"\"\"\n    if path is not None:\n        # safe = https://url.spec.whatwg.org/#url-path-segment-string\n        # as well as percent for things that are already quoted\n        # excluding semicolon since it's part of the header syntax\n        path = quote(path, safe=\"%!$&'()*+,/:=@\")\n\n    if domain:\n        domain = domain.partition(\":\")[0].lstrip(\".\").encode(\"idna\").decode(\"ascii\")\n\n    if isinstance(max_age, timedelta):\n        max_age = int(max_age.total_seconds())\n\n    if expires is not None:\n        if not isinstance(expires, str):\n            expires = http_date(expires)\n    elif max_age is not None and sync_expires:\n        expires = http_date(datetime.now(tz=timezone.utc).timestamp() + max_age)\n\n    if samesite is not None:\n        samesite = samesite.title()\n\n        if samesite not in {\"Strict\", \"Lax\", \"None\"}:\n            raise ValueError(\"SameSite must be 'Strict', 'Lax', or 'None'.\")\n\n    if partitioned:\n        secure = True\n\n    # Quote value if it contains characters not allowed by RFC 6265. Slash-escape with\n    # three octal digits, which matches http.cookies, although the RFC suggests base64.\n    if not _cookie_no_quote_re.fullmatch(value):\n        # Work with bytes here, since a UTF-8 character could be multiple bytes.\n        value = _cookie_slash_re.sub(\n            lambda m: _cookie_slash_map[m.group()], value.encode()\n        ).decode(\"ascii\")\n        value = f'\"{value}\"'\n\n    # Send a non-ASCII key as mojibake. Everything else should already be ASCII.\n    # TODO Remove encoding dance, it seems like clients accept UTF-8 keys\n    buf = [f\"{key.encode().decode('latin1')}={value}\"]\n\n    for k, v in (\n        (\"Domain\", domain),\n        (\"Expires\", expires),\n        (\"Max-Age\", max_age),\n        (\"Secure\", secure),\n        (\"HttpOnly\", httponly),\n        (\"Path\", path),\n        (\"SameSite\", samesite),\n        (\"Partitioned\", partitioned),\n    ):\n        if v is None or v is False:\n            continue\n\n        if v is True:\n            buf.append(k)\n            continue\n\n        buf.append(f\"{k}={v}\")\n\n    rv = \"; \".join(buf)\n\n    # Warn if the final value of the cookie is larger than the limit. If the cookie is\n    # too large, then it may be silently ignored by the browser, which can be quite hard\n    # to debug.\n    cookie_size = len(rv)\n\n    if max_size and cookie_size > max_size:\n        value_size = len(value)\n        warnings.warn(\n            f\"The '{key}' cookie is too large: the value was {value_size} bytes but the\"\n            f\" header required {cookie_size - value_size} extra bytes. The final size\"\n            f\" was {cookie_size} bytes but the limit is {max_size} bytes. Browsers may\"\n            \" silently ignore cookies larger than this.\",\n            stacklevel=2,\n        )\n\n    return rv\n\n\ndef is_byte_range_valid(\n    start: int | None, stop: int | None, length: int | None\n) -> bool:\n    \"\"\"Checks if a given byte content range is valid for the given length.\n\n    .. versionadded:: 0.7\n    \"\"\"\n    if (start is None) != (stop is None):\n        return False\n    elif start is None:\n        return length is None or length >= 0\n    elif length is None:\n        return 0 <= start < stop  # type: ignore\n    elif start >= stop:  # type: ignore\n        return False\n    return 0 <= start < length\n\n\n# circular dependencies\nfrom . import datastructures as ds\nfrom .sansio import http as _sansio_http\n", "src/werkzeug/exceptions.py": "\"\"\"Implements a number of Python exceptions which can be raised from within\na view to trigger a standard HTTP non-200 response.\n\nUsage Example\n-------------\n\n.. code-block:: python\n\n    from werkzeug.wrappers.request import Request\n    from werkzeug.exceptions import HTTPException, NotFound\n\n    def view(request):\n        raise NotFound()\n\n    @Request.application\n    def application(request):\n        try:\n            return view(request)\n        except HTTPException as e:\n            return e\n\nAs you can see from this example those exceptions are callable WSGI\napplications. However, they are not Werkzeug response objects. You\ncan get a response object by calling ``get_response()`` on a HTTP\nexception.\n\nKeep in mind that you may have to pass an environ (WSGI) or scope\n(ASGI) to ``get_response()`` because some errors fetch additional\ninformation relating to the request.\n\nIf you want to hook in a different exception page to say, a 404 status\ncode, you can add a second except for a specific subclass of an error:\n\n.. code-block:: python\n\n    @Request.application\n    def application(request):\n        try:\n            return view(request)\n        except NotFound as e:\n            return not_found(request)\n        except HTTPException as e:\n            return e\n\n\"\"\"\n\nfrom __future__ import annotations\n\nimport typing as t\nfrom datetime import datetime\n\nfrom markupsafe import escape\nfrom markupsafe import Markup\n\nfrom ._internal import _get_environ\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import StartResponse\n    from _typeshed.wsgi import WSGIEnvironment\n\n    from .datastructures import WWWAuthenticate\n    from .sansio.response import Response\n    from .wrappers.request import Request as WSGIRequest\n    from .wrappers.response import Response as WSGIResponse\n\n\nclass HTTPException(Exception):\n    \"\"\"The base class for all HTTP exceptions. This exception can be called as a WSGI\n    application to render a default error page or you can catch the subclasses\n    of it independently and render nicer error messages.\n\n    .. versionchanged:: 2.1\n        Removed the ``wrap`` class method.\n    \"\"\"\n\n    code: int | None = None\n    description: str | None = None\n\n    def __init__(\n        self,\n        description: str | None = None,\n        response: Response | None = None,\n    ) -> None:\n        super().__init__()\n        if description is not None:\n            self.description = description\n        self.response = response\n\n    @property\n    def name(self) -> str:\n        \"\"\"The status name.\"\"\"\n        from .http import HTTP_STATUS_CODES\n\n        return HTTP_STATUS_CODES.get(self.code, \"Unknown Error\")  # type: ignore\n\n    def get_description(\n        self,\n        environ: WSGIEnvironment | None = None,\n        scope: dict[str, t.Any] | None = None,\n    ) -> str:\n        \"\"\"Get the description.\"\"\"\n        if self.description is None:\n            description = \"\"\n        else:\n            description = self.description\n\n        description = escape(description).replace(\"\\n\", Markup(\"<br>\"))\n        return f\"<p>{description}</p>\"\n\n    def get_body(\n        self,\n        environ: WSGIEnvironment | None = None,\n        scope: dict[str, t.Any] | None = None,\n    ) -> str:\n        \"\"\"Get the HTML body.\"\"\"\n        return (\n            \"<!doctype html>\\n\"\n            \"<html lang=en>\\n\"\n            f\"<title>{self.code} {escape(self.name)}</title>\\n\"\n            f\"<h1>{escape(self.name)}</h1>\\n\"\n            f\"{self.get_description(environ)}\\n\"\n        )\n\n    def get_headers(\n        self,\n        environ: WSGIEnvironment | None = None,\n        scope: dict[str, t.Any] | None = None,\n    ) -> list[tuple[str, str]]:\n        \"\"\"Get a list of headers.\"\"\"\n        return [(\"Content-Type\", \"text/html; charset=utf-8\")]\n\n    def get_response(\n        self,\n        environ: WSGIEnvironment | WSGIRequest | None = None,\n        scope: dict[str, t.Any] | None = None,\n    ) -> Response:\n        \"\"\"Get a response object.  If one was passed to the exception\n        it's returned directly.\n\n        :param environ: the optional environ for the request.  This\n                        can be used to modify the response depending\n                        on how the request looked like.\n        :return: a :class:`Response` object or a subclass thereof.\n        \"\"\"\n        from .wrappers.response import Response as WSGIResponse  # noqa: F811\n\n        if self.response is not None:\n            return self.response\n        if environ is not None:\n            environ = _get_environ(environ)\n        headers = self.get_headers(environ, scope)\n        return WSGIResponse(self.get_body(environ, scope), self.code, headers)\n\n    def __call__(\n        self, environ: WSGIEnvironment, start_response: StartResponse\n    ) -> t.Iterable[bytes]:\n        \"\"\"Call the exception as WSGI application.\n\n        :param environ: the WSGI environment.\n        :param start_response: the response callable provided by the WSGI\n                               server.\n        \"\"\"\n        response = t.cast(\"WSGIResponse\", self.get_response(environ))\n        return response(environ, start_response)\n\n    def __str__(self) -> str:\n        code = self.code if self.code is not None else \"???\"\n        return f\"{code} {self.name}: {self.description}\"\n\n    def __repr__(self) -> str:\n        code = self.code if self.code is not None else \"???\"\n        return f\"<{type(self).__name__} '{code}: {self.name}'>\"\n\n\nclass BadRequest(HTTPException):\n    \"\"\"*400* `Bad Request`\n\n    Raise if the browser sends something to the application the application\n    or server cannot handle.\n    \"\"\"\n\n    code = 400\n    description = (\n        \"The browser (or proxy) sent a request that this server could \"\n        \"not understand.\"\n    )\n\n\nclass BadRequestKeyError(BadRequest, KeyError):\n    \"\"\"An exception that is used to signal both a :exc:`KeyError` and a\n    :exc:`BadRequest`. Used by many of the datastructures.\n    \"\"\"\n\n    _description = BadRequest.description\n    #: Show the KeyError along with the HTTP error message in the\n    #: response. This should be disabled in production, but can be\n    #: useful in a debug mode.\n    show_exception = False\n\n    def __init__(self, arg: str | None = None, *args: t.Any, **kwargs: t.Any):\n        super().__init__(*args, **kwargs)\n\n        if arg is None:\n            KeyError.__init__(self)\n        else:\n            KeyError.__init__(self, arg)\n\n    @property  # type: ignore\n    def description(self) -> str:\n        if self.show_exception:\n            return (\n                f\"{self._description}\\n\"\n                f\"{KeyError.__name__}: {KeyError.__str__(self)}\"\n            )\n\n        return self._description\n\n    @description.setter\n    def description(self, value: str) -> None:\n        self._description = value\n\n\nclass ClientDisconnected(BadRequest):\n    \"\"\"Internal exception that is raised if Werkzeug detects a disconnected\n    client.  Since the client is already gone at that point attempting to\n    send the error message to the client might not work and might ultimately\n    result in another exception in the server.  Mainly this is here so that\n    it is silenced by default as far as Werkzeug is concerned.\n\n    Since disconnections cannot be reliably detected and are unspecified\n    by WSGI to a large extent this might or might not be raised if a client\n    is gone.\n\n    .. versionadded:: 0.8\n    \"\"\"\n\n\nclass SecurityError(BadRequest):\n    \"\"\"Raised if something triggers a security error.  This is otherwise\n    exactly like a bad request error.\n\n    .. versionadded:: 0.9\n    \"\"\"\n\n\nclass BadHost(BadRequest):\n    \"\"\"Raised if the submitted host is badly formatted.\n\n    .. versionadded:: 0.11.2\n    \"\"\"\n\n\nclass Unauthorized(HTTPException):\n    \"\"\"*401* ``Unauthorized``\n\n    Raise if the user is not authorized to access a resource.\n\n    The ``www_authenticate`` argument should be used to set the\n    ``WWW-Authenticate`` header. This is used for HTTP basic auth and\n    other schemes. Use :class:`~werkzeug.datastructures.WWWAuthenticate`\n    to create correctly formatted values. Strictly speaking a 401\n    response is invalid if it doesn't provide at least one value for\n    this header, although real clients typically don't care.\n\n    :param description: Override the default message used for the body\n        of the response.\n    :param www-authenticate: A single value, or list of values, for the\n        WWW-Authenticate header(s).\n\n    .. versionchanged:: 2.0\n        Serialize multiple ``www_authenticate`` items into multiple\n        ``WWW-Authenticate`` headers, rather than joining them\n        into a single value, for better interoperability.\n\n    .. versionchanged:: 0.15.3\n        If the ``www_authenticate`` argument is not set, the\n        ``WWW-Authenticate`` header is not set.\n\n    .. versionchanged:: 0.15.3\n        The ``response`` argument was restored.\n\n    .. versionchanged:: 0.15.1\n        ``description`` was moved back as the first argument, restoring\n         its previous position.\n\n    .. versionchanged:: 0.15.0\n        ``www_authenticate`` was added as the first argument, ahead of\n        ``description``.\n    \"\"\"\n\n    code = 401\n    description = (\n        \"The server could not verify that you are authorized to access\"\n        \" the URL requested. You either supplied the wrong credentials\"\n        \" (e.g. a bad password), or your browser doesn't understand\"\n        \" how to supply the credentials required.\"\n    )\n\n    def __init__(\n        self,\n        description: str | None = None,\n        response: Response | None = None,\n        www_authenticate: None | (WWWAuthenticate | t.Iterable[WWWAuthenticate]) = None,\n    ) -> None:\n        super().__init__(description, response)\n\n        from .datastructures import WWWAuthenticate\n\n        if isinstance(www_authenticate, WWWAuthenticate):\n            www_authenticate = (www_authenticate,)\n\n        self.www_authenticate = www_authenticate\n\n    def get_headers(\n        self,\n        environ: WSGIEnvironment | None = None,\n        scope: dict[str, t.Any] | None = None,\n    ) -> list[tuple[str, str]]:\n        headers = super().get_headers(environ, scope)\n        if self.www_authenticate:\n            headers.extend((\"WWW-Authenticate\", str(x)) for x in self.www_authenticate)\n        return headers\n\n\nclass Forbidden(HTTPException):\n    \"\"\"*403* `Forbidden`\n\n    Raise if the user doesn't have the permission for the requested resource\n    but was authenticated.\n    \"\"\"\n\n    code = 403\n    description = (\n        \"You don't have the permission to access the requested\"\n        \" resource. It is either read-protected or not readable by the\"\n        \" server.\"\n    )\n\n\nclass NotFound(HTTPException):\n    \"\"\"*404* `Not Found`\n\n    Raise if a resource does not exist and never existed.\n    \"\"\"\n\n    code = 404\n    description = (\n        \"The requested URL was not found on the server. If you entered\"\n        \" the URL manually please check your spelling and try again.\"\n    )\n\n\nclass MethodNotAllowed(HTTPException):\n    \"\"\"*405* `Method Not Allowed`\n\n    Raise if the server used a method the resource does not handle.  For\n    example `POST` if the resource is view only.  Especially useful for REST.\n\n    The first argument for this exception should be a list of allowed methods.\n    Strictly speaking the response would be invalid if you don't provide valid\n    methods in the header which you can do with that list.\n    \"\"\"\n\n    code = 405\n    description = \"The method is not allowed for the requested URL.\"\n\n    def __init__(\n        self,\n        valid_methods: t.Iterable[str] | None = None,\n        description: str | None = None,\n        response: Response | None = None,\n    ) -> None:\n        \"\"\"Takes an optional list of valid http methods\n        starting with werkzeug 0.3 the list will be mandatory.\"\"\"\n        super().__init__(description=description, response=response)\n        self.valid_methods = valid_methods\n\n    def get_headers(\n        self,\n        environ: WSGIEnvironment | None = None,\n        scope: dict[str, t.Any] | None = None,\n    ) -> list[tuple[str, str]]:\n        headers = super().get_headers(environ, scope)\n        if self.valid_methods:\n            headers.append((\"Allow\", \", \".join(self.valid_methods)))\n        return headers\n\n\nclass NotAcceptable(HTTPException):\n    \"\"\"*406* `Not Acceptable`\n\n    Raise if the server can't return any content conforming to the\n    `Accept` headers of the client.\n    \"\"\"\n\n    code = 406\n    description = (\n        \"The resource identified by the request is only capable of\"\n        \" generating response entities which have content\"\n        \" characteristics not acceptable according to the accept\"\n        \" headers sent in the request.\"\n    )\n\n\nclass RequestTimeout(HTTPException):\n    \"\"\"*408* `Request Timeout`\n\n    Raise to signalize a timeout.\n    \"\"\"\n\n    code = 408\n    description = (\n        \"The server closed the network connection because the browser\"\n        \" didn't finish the request within the specified time.\"\n    )\n\n\nclass Conflict(HTTPException):\n    \"\"\"*409* `Conflict`\n\n    Raise to signal that a request cannot be completed because it conflicts\n    with the current state on the server.\n\n    .. versionadded:: 0.7\n    \"\"\"\n\n    code = 409\n    description = (\n        \"A conflict happened while processing the request. The\"\n        \" resource might have been modified while the request was being\"\n        \" processed.\"\n    )\n\n\nclass Gone(HTTPException):\n    \"\"\"*410* `Gone`\n\n    Raise if a resource existed previously and went away without new location.\n    \"\"\"\n\n    code = 410\n    description = (\n        \"The requested URL is no longer available on this server and\"\n        \" there is no forwarding address. If you followed a link from a\"\n        \" foreign page, please contact the author of this page.\"\n    )\n\n\nclass LengthRequired(HTTPException):\n    \"\"\"*411* `Length Required`\n\n    Raise if the browser submitted data but no ``Content-Length`` header which\n    is required for the kind of processing the server does.\n    \"\"\"\n\n    code = 411\n    description = (\n        \"A request with this method requires a valid <code>Content-\"\n        \"Length</code> header.\"\n    )\n\n\nclass PreconditionFailed(HTTPException):\n    \"\"\"*412* `Precondition Failed`\n\n    Status code used in combination with ``If-Match``, ``If-None-Match``, or\n    ``If-Unmodified-Since``.\n    \"\"\"\n\n    code = 412\n    description = (\n        \"The precondition on the request for the URL failed positive evaluation.\"\n    )\n\n\nclass RequestEntityTooLarge(HTTPException):\n    \"\"\"*413* `Request Entity Too Large`\n\n    The status code one should return if the data submitted exceeded a given\n    limit.\n    \"\"\"\n\n    code = 413\n    description = \"The data value transmitted exceeds the capacity limit.\"\n\n\nclass RequestURITooLarge(HTTPException):\n    \"\"\"*414* `Request URI Too Large`\n\n    Like *413* but for too long URLs.\n    \"\"\"\n\n    code = 414\n    description = (\n        \"The length of the requested URL exceeds the capacity limit for\"\n        \" this server. The request cannot be processed.\"\n    )\n\n\nclass UnsupportedMediaType(HTTPException):\n    \"\"\"*415* `Unsupported Media Type`\n\n    The status code returned if the server is unable to handle the media type\n    the client transmitted.\n    \"\"\"\n\n    code = 415\n    description = (\n        \"The server does not support the media type transmitted in the request.\"\n    )\n\n\nclass RequestedRangeNotSatisfiable(HTTPException):\n    \"\"\"*416* `Requested Range Not Satisfiable`\n\n    The client asked for an invalid part of the file.\n\n    .. versionadded:: 0.7\n    \"\"\"\n\n    code = 416\n    description = \"The server cannot provide the requested range.\"\n\n    def __init__(\n        self,\n        length: int | None = None,\n        units: str = \"bytes\",\n        description: str | None = None,\n        response: Response | None = None,\n    ) -> None:\n        \"\"\"Takes an optional `Content-Range` header value based on ``length``\n        parameter.\n        \"\"\"\n        super().__init__(description=description, response=response)\n        self.length = length\n        self.units = units\n\n    def get_headers(\n        self,\n        environ: WSGIEnvironment | None = None,\n        scope: dict[str, t.Any] | None = None,\n    ) -> list[tuple[str, str]]:\n        headers = super().get_headers(environ, scope)\n        if self.length is not None:\n            headers.append((\"Content-Range\", f\"{self.units} */{self.length}\"))\n        return headers\n\n\nclass ExpectationFailed(HTTPException):\n    \"\"\"*417* `Expectation Failed`\n\n    The server cannot meet the requirements of the Expect request-header.\n\n    .. versionadded:: 0.7\n    \"\"\"\n\n    code = 417\n    description = \"The server could not meet the requirements of the Expect header\"\n\n\nclass ImATeapot(HTTPException):\n    \"\"\"*418* `I'm a teapot`\n\n    The server should return this if it is a teapot and someone attempted\n    to brew coffee with it.\n\n    .. versionadded:: 0.7\n    \"\"\"\n\n    code = 418\n    description = \"This server is a teapot, not a coffee machine\"\n\n\nclass UnprocessableEntity(HTTPException):\n    \"\"\"*422* `Unprocessable Entity`\n\n    Used if the request is well formed, but the instructions are otherwise\n    incorrect.\n    \"\"\"\n\n    code = 422\n    description = (\n        \"The request was well-formed but was unable to be followed due\"\n        \" to semantic errors.\"\n    )\n\n\nclass Locked(HTTPException):\n    \"\"\"*423* `Locked`\n\n    Used if the resource that is being accessed is locked.\n    \"\"\"\n\n    code = 423\n    description = \"The resource that is being accessed is locked.\"\n\n\nclass FailedDependency(HTTPException):\n    \"\"\"*424* `Failed Dependency`\n\n    Used if the method could not be performed on the resource\n    because the requested action depended on another action and that action failed.\n    \"\"\"\n\n    code = 424\n    description = (\n        \"The method could not be performed on the resource because the\"\n        \" requested action depended on another action and that action\"\n        \" failed.\"\n    )\n\n\nclass PreconditionRequired(HTTPException):\n    \"\"\"*428* `Precondition Required`\n\n    The server requires this request to be conditional, typically to prevent\n    the lost update problem, which is a race condition between two or more\n    clients attempting to update a resource through PUT or DELETE. By requiring\n    each client to include a conditional header (\"If-Match\" or \"If-Unmodified-\n    Since\") with the proper value retained from a recent GET request, the\n    server ensures that each client has at least seen the previous revision of\n    the resource.\n    \"\"\"\n\n    code = 428\n    description = (\n        \"This request is required to be conditional; try using\"\n        ' \"If-Match\" or \"If-Unmodified-Since\".'\n    )\n\n\nclass _RetryAfter(HTTPException):\n    \"\"\"Adds an optional ``retry_after`` parameter which will set the\n    ``Retry-After`` header. May be an :class:`int` number of seconds or\n    a :class:`~datetime.datetime`.\n    \"\"\"\n\n    def __init__(\n        self,\n        description: str | None = None,\n        response: Response | None = None,\n        retry_after: datetime | int | None = None,\n    ) -> None:\n        super().__init__(description, response)\n        self.retry_after = retry_after\n\n    def get_headers(\n        self,\n        environ: WSGIEnvironment | None = None,\n        scope: dict[str, t.Any] | None = None,\n    ) -> list[tuple[str, str]]:\n        headers = super().get_headers(environ, scope)\n\n        if self.retry_after:\n            if isinstance(self.retry_after, datetime):\n                from .http import http_date\n\n                value = http_date(self.retry_after)\n            else:\n                value = str(self.retry_after)\n\n            headers.append((\"Retry-After\", value))\n\n        return headers\n\n\nclass TooManyRequests(_RetryAfter):\n    \"\"\"*429* `Too Many Requests`\n\n    The server is limiting the rate at which this user receives\n    responses, and this request exceeds that rate. (The server may use\n    any convenient method to identify users and their request rates).\n    The server may include a \"Retry-After\" header to indicate how long\n    the user should wait before retrying.\n\n    :param retry_after: If given, set the ``Retry-After`` header to this\n        value. May be an :class:`int` number of seconds or a\n        :class:`~datetime.datetime`.\n\n    .. versionchanged:: 1.0\n        Added ``retry_after`` parameter.\n    \"\"\"\n\n    code = 429\n    description = \"This user has exceeded an allotted request count. Try again later.\"\n\n\nclass RequestHeaderFieldsTooLarge(HTTPException):\n    \"\"\"*431* `Request Header Fields Too Large`\n\n    The server refuses to process the request because the header fields are too\n    large. One or more individual fields may be too large, or the set of all\n    headers is too large.\n    \"\"\"\n\n    code = 431\n    description = \"One or more header fields exceeds the maximum size.\"\n\n\nclass UnavailableForLegalReasons(HTTPException):\n    \"\"\"*451* `Unavailable For Legal Reasons`\n\n    This status code indicates that the server is denying access to the\n    resource as a consequence of a legal demand.\n    \"\"\"\n\n    code = 451\n    description = \"Unavailable for legal reasons.\"\n\n\nclass InternalServerError(HTTPException):\n    \"\"\"*500* `Internal Server Error`\n\n    Raise if an internal server error occurred.  This is a good fallback if an\n    unknown error occurred in the dispatcher.\n\n    .. versionchanged:: 1.0.0\n        Added the :attr:`original_exception` attribute.\n    \"\"\"\n\n    code = 500\n    description = (\n        \"The server encountered an internal error and was unable to\"\n        \" complete your request. Either the server is overloaded or\"\n        \" there is an error in the application.\"\n    )\n\n    def __init__(\n        self,\n        description: str | None = None,\n        response: Response | None = None,\n        original_exception: BaseException | None = None,\n    ) -> None:\n        #: The original exception that caused this 500 error. Can be\n        #: used by frameworks to provide context when handling\n        #: unexpected errors.\n        self.original_exception = original_exception\n        super().__init__(description=description, response=response)\n\n\nclass NotImplemented(HTTPException):\n    \"\"\"*501* `Not Implemented`\n\n    Raise if the application does not support the action requested by the\n    browser.\n    \"\"\"\n\n    code = 501\n    description = \"The server does not support the action requested by the browser.\"\n\n\nclass BadGateway(HTTPException):\n    \"\"\"*502* `Bad Gateway`\n\n    If you do proxying in your application you should return this status code\n    if you received an invalid response from the upstream server it accessed\n    in attempting to fulfill the request.\n    \"\"\"\n\n    code = 502\n    description = (\n        \"The proxy server received an invalid response from an upstream server.\"\n    )\n\n\nclass ServiceUnavailable(_RetryAfter):\n    \"\"\"*503* `Service Unavailable`\n\n    Status code you should return if a service is temporarily\n    unavailable.\n\n    :param retry_after: If given, set the ``Retry-After`` header to this\n        value. May be an :class:`int` number of seconds or a\n        :class:`~datetime.datetime`.\n\n    .. versionchanged:: 1.0\n        Added ``retry_after`` parameter.\n    \"\"\"\n\n    code = 503\n    description = (\n        \"The server is temporarily unable to service your request due\"\n        \" to maintenance downtime or capacity problems. Please try\"\n        \" again later.\"\n    )\n\n\nclass GatewayTimeout(HTTPException):\n    \"\"\"*504* `Gateway Timeout`\n\n    Status code you should return if a connection to an upstream server\n    times out.\n    \"\"\"\n\n    code = 504\n    description = \"The connection to an upstream server timed out.\"\n\n\nclass HTTPVersionNotSupported(HTTPException):\n    \"\"\"*505* `HTTP Version Not Supported`\n\n    The server does not support the HTTP protocol version used in the request.\n    \"\"\"\n\n    code = 505\n    description = (\n        \"The server does not support the HTTP protocol version used in the request.\"\n    )\n\n\ndefault_exceptions: dict[int, type[HTTPException]] = {}\n\n\ndef _find_exceptions() -> None:\n    for obj in globals().values():\n        try:\n            is_http_exception = issubclass(obj, HTTPException)\n        except TypeError:\n            is_http_exception = False\n        if not is_http_exception or obj.code is None:\n            continue\n        old_obj = default_exceptions.get(obj.code, None)\n        if old_obj is not None and issubclass(obj, old_obj):\n            continue\n        default_exceptions[obj.code] = obj\n\n\n_find_exceptions()\ndel _find_exceptions\n\n\nclass Aborter:\n    \"\"\"When passed a dict of code -> exception items it can be used as\n    callable that raises exceptions.  If the first argument to the\n    callable is an integer it will be looked up in the mapping, if it's\n    a WSGI application it will be raised in a proxy exception.\n\n    The rest of the arguments are forwarded to the exception constructor.\n    \"\"\"\n\n    def __init__(\n        self,\n        mapping: dict[int, type[HTTPException]] | None = None,\n        extra: dict[int, type[HTTPException]] | None = None,\n    ) -> None:\n        if mapping is None:\n            mapping = default_exceptions\n        self.mapping = dict(mapping)\n        if extra is not None:\n            self.mapping.update(extra)\n\n    def __call__(\n        self, code: int | Response, *args: t.Any, **kwargs: t.Any\n    ) -> t.NoReturn:\n        from .sansio.response import Response\n\n        if isinstance(code, Response):\n            raise HTTPException(response=code)\n\n        if code not in self.mapping:\n            raise LookupError(f\"no exception for {code!r}\")\n\n        raise self.mapping[code](*args, **kwargs)\n\n\ndef abort(status: int | Response, *args: t.Any, **kwargs: t.Any) -> t.NoReturn:\n    \"\"\"Raises an :py:exc:`HTTPException` for the given status code or WSGI\n    application.\n\n    If a status code is given, it will be looked up in the list of\n    exceptions and will raise that exception.  If passed a WSGI application,\n    it will wrap it in a proxy WSGI exception and raise that::\n\n       abort(404)  # 404 Not Found\n       abort(Response('Hello World'))\n\n    \"\"\"\n    _aborter(status, *args, **kwargs)\n\n\n_aborter: Aborter = Aborter()\n", "src/werkzeug/security.py": "from __future__ import annotations\n\nimport hashlib\nimport hmac\nimport os\nimport posixpath\nimport secrets\n\nSALT_CHARS = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\"\nDEFAULT_PBKDF2_ITERATIONS = 600000\n\n_os_alt_seps: list[str] = list(\n    sep for sep in [os.sep, os.path.altsep] if sep is not None and sep != \"/\"\n)\n\n\ndef gen_salt(length: int) -> str:\n    \"\"\"Generate a random string of SALT_CHARS with specified ``length``.\"\"\"\n    if length <= 0:\n        raise ValueError(\"Salt length must be at least 1.\")\n\n    return \"\".join(secrets.choice(SALT_CHARS) for _ in range(length))\n\n\ndef _hash_internal(method: str, salt: str, password: str) -> tuple[str, str]:\n    method, *args = method.split(\":\")\n    salt_bytes = salt.encode()\n    password_bytes = password.encode()\n\n    if method == \"scrypt\":\n        if not args:\n            n = 2**15\n            r = 8\n            p = 1\n        else:\n            try:\n                n, r, p = map(int, args)\n            except ValueError:\n                raise ValueError(\"'scrypt' takes 3 arguments.\") from None\n\n        maxmem = 132 * n * r * p  # ideally 128, but some extra seems needed\n        return (\n            hashlib.scrypt(\n                password_bytes, salt=salt_bytes, n=n, r=r, p=p, maxmem=maxmem\n            ).hex(),\n            f\"scrypt:{n}:{r}:{p}\",\n        )\n    elif method == \"pbkdf2\":\n        len_args = len(args)\n\n        if len_args == 0:\n            hash_name = \"sha256\"\n            iterations = DEFAULT_PBKDF2_ITERATIONS\n        elif len_args == 1:\n            hash_name = args[0]\n            iterations = DEFAULT_PBKDF2_ITERATIONS\n        elif len_args == 2:\n            hash_name = args[0]\n            iterations = int(args[1])\n        else:\n            raise ValueError(\"'pbkdf2' takes 2 arguments.\")\n\n        return (\n            hashlib.pbkdf2_hmac(\n                hash_name, password_bytes, salt_bytes, iterations\n            ).hex(),\n            f\"pbkdf2:{hash_name}:{iterations}\",\n        )\n    else:\n        raise ValueError(f\"Invalid hash method '{method}'.\")\n\n\ndef generate_password_hash(\n    password: str, method: str = \"scrypt\", salt_length: int = 16\n) -> str:\n    \"\"\"Securely hash a password for storage. A password can be compared to a stored hash\n    using :func:`check_password_hash`.\n\n    The following methods are supported:\n\n    -   ``scrypt``, the default. The parameters are ``n``, ``r``, and ``p``, the default\n        is ``scrypt:32768:8:1``. See :func:`hashlib.scrypt`.\n    -   ``pbkdf2``, less secure. The parameters are ``hash_method`` and ``iterations``,\n        the default is ``pbkdf2:sha256:600000``. See :func:`hashlib.pbkdf2_hmac`.\n\n    Default parameters may be updated to reflect current guidelines, and methods may be\n    deprecated and removed if they are no longer considered secure. To migrate old\n    hashes, you may generate a new hash when checking an old hash, or you may contact\n    users with a link to reset their password.\n\n    :param password: The plaintext password.\n    :param method: The key derivation function and parameters.\n    :param salt_length: The number of characters to generate for the salt.\n\n    .. versionchanged:: 2.3\n        Scrypt support was added.\n\n    .. versionchanged:: 2.3\n        The default iterations for pbkdf2 was increased to 600,000.\n\n    .. versionchanged:: 2.3\n        All plain hashes are deprecated and will not be supported in Werkzeug 3.0.\n    \"\"\"\n    salt = gen_salt(salt_length)\n    h, actual_method = _hash_internal(method, salt, password)\n    return f\"{actual_method}${salt}${h}\"\n\n\ndef check_password_hash(pwhash: str, password: str) -> bool:\n    \"\"\"Securely check that the given stored password hash, previously generated using\n    :func:`generate_password_hash`, matches the given password.\n\n    Methods may be deprecated and removed if they are no longer considered secure. To\n    migrate old hashes, you may generate a new hash when checking an old hash, or you\n    may contact users with a link to reset their password.\n\n    :param pwhash: The hashed password.\n    :param password: The plaintext password.\n\n    .. versionchanged:: 2.3\n        All plain hashes are deprecated and will not be supported in Werkzeug 3.0.\n    \"\"\"\n    try:\n        method, salt, hashval = pwhash.split(\"$\", 2)\n    except ValueError:\n        return False\n\n    return hmac.compare_digest(_hash_internal(method, salt, password)[0], hashval)\n\n\ndef safe_join(directory: str, *pathnames: str) -> str | None:\n    \"\"\"Safely join zero or more untrusted path components to a base\n    directory to avoid escaping the base directory.\n\n    :param directory: The trusted base directory.\n    :param pathnames: The untrusted path components relative to the\n        base directory.\n    :return: A safe path, otherwise ``None``.\n    \"\"\"\n    if not directory:\n        # Ensure we end up with ./path if directory=\"\" is given,\n        # otherwise the first untrusted part could become trusted.\n        directory = \".\"\n\n    parts = [directory]\n\n    for filename in pathnames:\n        if filename != \"\":\n            filename = posixpath.normpath(filename)\n\n        if (\n            any(sep in filename for sep in _os_alt_seps)\n            or os.path.isabs(filename)\n            or filename == \"..\"\n            or filename.startswith(\"../\")\n        ):\n            return None\n\n        parts.append(filename)\n\n    return posixpath.join(*parts)\n", "src/werkzeug/_internal.py": "from __future__ import annotations\n\nimport logging\nimport re\nimport sys\nimport typing as t\nfrom datetime import datetime\nfrom datetime import timezone\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import WSGIEnvironment\n\n    from .wrappers.request import Request\n\n_logger: logging.Logger | None = None\n\n\nclass _Missing:\n    def __repr__(self) -> str:\n        return \"no value\"\n\n    def __reduce__(self) -> str:\n        return \"_missing\"\n\n\n_missing = _Missing()\n\n\ndef _wsgi_decoding_dance(s: str) -> str:\n    return s.encode(\"latin1\").decode(errors=\"replace\")\n\n\ndef _wsgi_encoding_dance(s: str) -> str:\n    return s.encode().decode(\"latin1\")\n\n\ndef _get_environ(obj: WSGIEnvironment | Request) -> WSGIEnvironment:\n    env = getattr(obj, \"environ\", obj)\n    assert isinstance(\n        env, dict\n    ), f\"{type(obj).__name__!r} is not a WSGI environment (has to be a dict)\"\n    return env\n\n\ndef _has_level_handler(logger: logging.Logger) -> bool:\n    \"\"\"Check if there is a handler in the logging chain that will handle\n    the given logger's effective level.\n    \"\"\"\n    level = logger.getEffectiveLevel()\n    current = logger\n\n    while current:\n        if any(handler.level <= level for handler in current.handlers):\n            return True\n\n        if not current.propagate:\n            break\n\n        current = current.parent  # type: ignore\n\n    return False\n\n\nclass _ColorStreamHandler(logging.StreamHandler):  # type: ignore[type-arg]\n    \"\"\"On Windows, wrap stream with Colorama for ANSI style support.\"\"\"\n\n    def __init__(self) -> None:\n        try:\n            import colorama\n        except ImportError:\n            stream = None\n        else:\n            stream = colorama.AnsiToWin32(sys.stderr)\n\n        super().__init__(stream)\n\n\ndef _log(type: str, message: str, *args: t.Any, **kwargs: t.Any) -> None:\n    \"\"\"Log a message to the 'werkzeug' logger.\n\n    The logger is created the first time it is needed. If there is no\n    level set, it is set to :data:`logging.INFO`. If there is no handler\n    for the logger's effective level, a :class:`logging.StreamHandler`\n    is added.\n    \"\"\"\n    global _logger\n\n    if _logger is None:\n        _logger = logging.getLogger(\"werkzeug\")\n\n        if _logger.level == logging.NOTSET:\n            _logger.setLevel(logging.INFO)\n\n        if not _has_level_handler(_logger):\n            _logger.addHandler(_ColorStreamHandler())\n\n    getattr(_logger, type)(message.rstrip(), *args, **kwargs)\n\n\n@t.overload\ndef _dt_as_utc(dt: None) -> None: ...\n\n\n@t.overload\ndef _dt_as_utc(dt: datetime) -> datetime: ...\n\n\ndef _dt_as_utc(dt: datetime | None) -> datetime | None:\n    if dt is None:\n        return dt\n\n    if dt.tzinfo is None:\n        return dt.replace(tzinfo=timezone.utc)\n    elif dt.tzinfo != timezone.utc:\n        return dt.astimezone(timezone.utc)\n\n    return dt\n\n\n_TAccessorValue = t.TypeVar(\"_TAccessorValue\")\n\n\nclass _DictAccessorProperty(t.Generic[_TAccessorValue]):\n    \"\"\"Baseclass for `environ_property` and `header_property`.\"\"\"\n\n    read_only = False\n\n    def __init__(\n        self,\n        name: str,\n        default: _TAccessorValue | None = None,\n        load_func: t.Callable[[str], _TAccessorValue] | None = None,\n        dump_func: t.Callable[[_TAccessorValue], str] | None = None,\n        read_only: bool | None = None,\n        doc: str | None = None,\n    ) -> None:\n        self.name = name\n        self.default = default\n        self.load_func = load_func\n        self.dump_func = dump_func\n        if read_only is not None:\n            self.read_only = read_only\n        self.__doc__ = doc\n\n    def lookup(self, instance: t.Any) -> t.MutableMapping[str, t.Any]:\n        raise NotImplementedError\n\n    @t.overload\n    def __get__(\n        self, instance: None, owner: type\n    ) -> _DictAccessorProperty[_TAccessorValue]: ...\n\n    @t.overload\n    def __get__(self, instance: t.Any, owner: type) -> _TAccessorValue: ...\n\n    def __get__(\n        self, instance: t.Any | None, owner: type\n    ) -> _TAccessorValue | _DictAccessorProperty[_TAccessorValue]:\n        if instance is None:\n            return self\n\n        storage = self.lookup(instance)\n\n        if self.name not in storage:\n            return self.default  # type: ignore\n\n        value = storage[self.name]\n\n        if self.load_func is not None:\n            try:\n                return self.load_func(value)\n            except (ValueError, TypeError):\n                return self.default  # type: ignore\n\n        return value  # type: ignore\n\n    def __set__(self, instance: t.Any, value: _TAccessorValue) -> None:\n        if self.read_only:\n            raise AttributeError(\"read only property\")\n\n        if self.dump_func is not None:\n            self.lookup(instance)[self.name] = self.dump_func(value)\n        else:\n            self.lookup(instance)[self.name] = value\n\n    def __delete__(self, instance: t.Any) -> None:\n        if self.read_only:\n            raise AttributeError(\"read only property\")\n\n        self.lookup(instance).pop(self.name, None)\n\n    def __repr__(self) -> str:\n        return f\"<{type(self).__name__} {self.name}>\"\n\n\n_plain_int_re = re.compile(r\"-?\\d+\", re.ASCII)\n\n\ndef _plain_int(value: str) -> int:\n    \"\"\"Parse an int only if it is only ASCII digits and ``-``.\n\n    This disallows ``+``, ``_``, and non-ASCII digits, which are accepted by ``int`` but\n    are not allowed in HTTP header values.\n\n    Any leading or trailing whitespace is stripped\n    \"\"\"\n    value = value.strip()\n    if _plain_int_re.fullmatch(value) is None:\n        raise ValueError\n\n    return int(value)\n", "src/werkzeug/utils.py": "from __future__ import annotations\n\nimport io\nimport mimetypes\nimport os\nimport pkgutil\nimport re\nimport sys\nimport typing as t\nimport unicodedata\nfrom datetime import datetime\nfrom time import time\nfrom urllib.parse import quote\nfrom zlib import adler32\n\nfrom markupsafe import escape\n\nfrom ._internal import _DictAccessorProperty\nfrom ._internal import _missing\nfrom ._internal import _TAccessorValue\nfrom .datastructures import Headers\nfrom .exceptions import NotFound\nfrom .exceptions import RequestedRangeNotSatisfiable\nfrom .security import safe_join\nfrom .wsgi import wrap_file\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import WSGIEnvironment\n\n    from .wrappers.request import Request\n    from .wrappers.response import Response\n\n_T = t.TypeVar(\"_T\")\n\n_entity_re = re.compile(r\"&([^;]+);\")\n_filename_ascii_strip_re = re.compile(r\"[^A-Za-z0-9_.-]\")\n_windows_device_files = {\n    \"CON\",\n    \"PRN\",\n    \"AUX\",\n    \"NUL\",\n    *(f\"COM{i}\" for i in range(10)),\n    *(f\"LPT{i}\" for i in range(10)),\n}\n\n\nclass cached_property(property, t.Generic[_T]):\n    \"\"\"A :func:`property` that is only evaluated once. Subsequent access\n    returns the cached value. Setting the property sets the cached\n    value. Deleting the property clears the cached value, accessing it\n    again will evaluate it again.\n\n    .. code-block:: python\n\n        class Example:\n            @cached_property\n            def value(self):\n                # calculate something important here\n                return 42\n\n        e = Example()\n        e.value  # evaluates\n        e.value  # uses cache\n        e.value = 16  # sets cache\n        del e.value  # clears cache\n\n    If the class defines ``__slots__``, it must add ``_cache_{name}`` as\n    a slot. Alternatively, it can add ``__dict__``, but that's usually\n    not desirable.\n\n    .. versionchanged:: 2.1\n        Works with ``__slots__``.\n\n    .. versionchanged:: 2.0\n        ``del obj.name`` clears the cached value.\n    \"\"\"\n\n    def __init__(\n        self,\n        fget: t.Callable[[t.Any], _T],\n        name: str | None = None,\n        doc: str | None = None,\n    ) -> None:\n        super().__init__(fget, doc=doc)\n        self.__name__ = name or fget.__name__\n        self.slot_name = f\"_cache_{self.__name__}\"\n        self.__module__ = fget.__module__\n\n    def __set__(self, obj: object, value: _T) -> None:\n        if hasattr(obj, \"__dict__\"):\n            obj.__dict__[self.__name__] = value\n        else:\n            setattr(obj, self.slot_name, value)\n\n    def __get__(self, obj: object, type: type = None) -> _T:  # type: ignore\n        if obj is None:\n            return self  # type: ignore\n\n        obj_dict = getattr(obj, \"__dict__\", None)\n\n        if obj_dict is not None:\n            value: _T = obj_dict.get(self.__name__, _missing)\n        else:\n            value = getattr(obj, self.slot_name, _missing)  # type: ignore[arg-type]\n\n        if value is _missing:\n            value = self.fget(obj)  # type: ignore\n\n            if obj_dict is not None:\n                obj.__dict__[self.__name__] = value\n            else:\n                setattr(obj, self.slot_name, value)\n\n        return value\n\n    def __delete__(self, obj: object) -> None:\n        if hasattr(obj, \"__dict__\"):\n            del obj.__dict__[self.__name__]\n        else:\n            setattr(obj, self.slot_name, _missing)\n\n\nclass environ_property(_DictAccessorProperty[_TAccessorValue]):\n    \"\"\"Maps request attributes to environment variables. This works not only\n    for the Werkzeug request object, but also any other class with an\n    environ attribute:\n\n    >>> class Test(object):\n    ...     environ = {'key': 'value'}\n    ...     test = environ_property('key')\n    >>> var = Test()\n    >>> var.test\n    'value'\n\n    If you pass it a second value it's used as default if the key does not\n    exist, the third one can be a converter that takes a value and converts\n    it.  If it raises :exc:`ValueError` or :exc:`TypeError` the default value\n    is used. If no default value is provided `None` is used.\n\n    Per default the property is read only.  You have to explicitly enable it\n    by passing ``read_only=False`` to the constructor.\n    \"\"\"\n\n    read_only = True\n\n    def lookup(self, obj: Request) -> WSGIEnvironment:\n        return obj.environ\n\n\nclass header_property(_DictAccessorProperty[_TAccessorValue]):\n    \"\"\"Like `environ_property` but for headers.\"\"\"\n\n    def lookup(self, obj: Request | Response) -> Headers:\n        return obj.headers\n\n\n# https://cgit.freedesktop.org/xdg/shared-mime-info/tree/freedesktop.org.xml.in\n# https://www.iana.org/assignments/media-types/media-types.xhtml\n# Types listed in the XDG mime info that have a charset in the IANA registration.\n_charset_mimetypes = {\n    \"application/ecmascript\",\n    \"application/javascript\",\n    \"application/sql\",\n    \"application/xml\",\n    \"application/xml-dtd\",\n    \"application/xml-external-parsed-entity\",\n}\n\n\ndef get_content_type(mimetype: str, charset: str) -> str:\n    \"\"\"Returns the full content type string with charset for a mimetype.\n\n    If the mimetype represents text, the charset parameter will be\n    appended, otherwise the mimetype is returned unchanged.\n\n    :param mimetype: The mimetype to be used as content type.\n    :param charset: The charset to be appended for text mimetypes.\n    :return: The content type.\n\n    .. versionchanged:: 0.15\n        Any type that ends with ``+xml`` gets a charset, not just those\n        that start with ``application/``. Known text types such as\n        ``application/javascript`` are also given charsets.\n    \"\"\"\n    if (\n        mimetype.startswith(\"text/\")\n        or mimetype in _charset_mimetypes\n        or mimetype.endswith(\"+xml\")\n    ):\n        mimetype += f\"; charset={charset}\"\n\n    return mimetype\n\n\ndef secure_filename(filename: str) -> str:\n    r\"\"\"Pass it a filename and it will return a secure version of it.  This\n    filename can then safely be stored on a regular file system and passed\n    to :func:`os.path.join`.  The filename returned is an ASCII only string\n    for maximum portability.\n\n    On windows systems the function also makes sure that the file is not\n    named after one of the special device files.\n\n    >>> secure_filename(\"My cool movie.mov\")\n    'My_cool_movie.mov'\n    >>> secure_filename(\"../../../etc/passwd\")\n    'etc_passwd'\n    >>> secure_filename('i contain cool \\xfcml\\xe4uts.txt')\n    'i_contain_cool_umlauts.txt'\n\n    The function might return an empty filename.  It's your responsibility\n    to ensure that the filename is unique and that you abort or\n    generate a random filename if the function returned an empty one.\n\n    .. versionadded:: 0.5\n\n    :param filename: the filename to secure\n    \"\"\"\n    filename = unicodedata.normalize(\"NFKD\", filename)\n    filename = filename.encode(\"ascii\", \"ignore\").decode(\"ascii\")\n\n    for sep in os.sep, os.path.altsep:\n        if sep:\n            filename = filename.replace(sep, \" \")\n    filename = str(_filename_ascii_strip_re.sub(\"\", \"_\".join(filename.split()))).strip(\n        \"._\"\n    )\n\n    # on nt a couple of special files are present in each folder.  We\n    # have to ensure that the target file is not such a filename.  In\n    # this case we prepend an underline\n    if (\n        os.name == \"nt\"\n        and filename\n        and filename.split(\".\")[0].upper() in _windows_device_files\n    ):\n        filename = f\"_{filename}\"\n\n    return filename\n\n\ndef redirect(\n    location: str, code: int = 302, Response: type[Response] | None = None\n) -> Response:\n    \"\"\"Returns a response object (a WSGI application) that, if called,\n    redirects the client to the target location. Supported codes are\n    301, 302, 303, 305, 307, and 308. 300 is not supported because\n    it's not a real redirect and 304 because it's the answer for a\n    request with a request with defined If-Modified-Since headers.\n\n    .. versionadded:: 0.6\n       The location can now be a unicode string that is encoded using\n       the :func:`iri_to_uri` function.\n\n    .. versionadded:: 0.10\n        The class used for the Response object can now be passed in.\n\n    :param location: the location the response should redirect to.\n    :param code: the redirect status code. defaults to 302.\n    :param class Response: a Response class to use when instantiating a\n        response. The default is :class:`werkzeug.wrappers.Response` if\n        unspecified.\n    \"\"\"\n    if Response is None:\n        from .wrappers import Response\n\n    html_location = escape(location)\n    response = Response(  # type: ignore[misc]\n        \"<!doctype html>\\n\"\n        \"<html lang=en>\\n\"\n        \"<title>Redirecting...</title>\\n\"\n        \"<h1>Redirecting...</h1>\\n\"\n        \"<p>You should be redirected automatically to the target URL: \"\n        f'<a href=\"{html_location}\">{html_location}</a>. If not, click the link.\\n',\n        code,\n        mimetype=\"text/html\",\n    )\n    response.headers[\"Location\"] = location\n    return response\n\n\ndef append_slash_redirect(environ: WSGIEnvironment, code: int = 308) -> Response:\n    \"\"\"Redirect to the current URL with a slash appended.\n\n    If the current URL is ``/user/42``, the redirect URL will be\n    ``42/``. When joined to the current URL during response\n    processing or by the browser, this will produce ``/user/42/``.\n\n    The behavior is undefined if the path ends with a slash already. If\n    called unconditionally on a URL, it may produce a redirect loop.\n\n    :param environ: Use the path and query from this WSGI environment\n        to produce the redirect URL.\n    :param code: the status code for the redirect.\n\n    .. versionchanged:: 2.1\n        Produce a relative URL that only modifies the last segment.\n        Relevant when the current path has multiple segments.\n\n    .. versionchanged:: 2.1\n        The default status code is 308 instead of 301. This preserves\n        the request method and body.\n    \"\"\"\n    tail = environ[\"PATH_INFO\"].rpartition(\"/\")[2]\n\n    if not tail:\n        new_path = \"./\"\n    else:\n        new_path = f\"{tail}/\"\n\n    query_string = environ.get(\"QUERY_STRING\")\n\n    if query_string:\n        new_path = f\"{new_path}?{query_string}\"\n\n    return redirect(new_path, code)\n\n\ndef send_file(\n    path_or_file: os.PathLike[str] | str | t.IO[bytes],\n    environ: WSGIEnvironment,\n    mimetype: str | None = None,\n    as_attachment: bool = False,\n    download_name: str | None = None,\n    conditional: bool = True,\n    etag: bool | str = True,\n    last_modified: datetime | int | float | None = None,\n    max_age: None | (int | t.Callable[[str | None], int | None]) = None,\n    use_x_sendfile: bool = False,\n    response_class: type[Response] | None = None,\n    _root_path: os.PathLike[str] | str | None = None,\n) -> Response:\n    \"\"\"Send the contents of a file to the client.\n\n    The first argument can be a file path or a file-like object. Paths\n    are preferred in most cases because Werkzeug can manage the file and\n    get extra information from the path. Passing a file-like object\n    requires that the file is opened in binary mode, and is mostly\n    useful when building a file in memory with :class:`io.BytesIO`.\n\n    Never pass file paths provided by a user. The path is assumed to be\n    trusted, so a user could craft a path to access a file you didn't\n    intend. Use :func:`send_from_directory` to safely serve user-provided paths.\n\n    If the WSGI server sets a ``file_wrapper`` in ``environ``, it is\n    used, otherwise Werkzeug's built-in wrapper is used. Alternatively,\n    if the HTTP server supports ``X-Sendfile``, ``use_x_sendfile=True``\n    will tell the server to send the given path, which is much more\n    efficient than reading it in Python.\n\n    :param path_or_file: The path to the file to send, relative to the\n        current working directory if a relative path is given.\n        Alternatively, a file-like object opened in binary mode. Make\n        sure the file pointer is seeked to the start of the data.\n    :param environ: The WSGI environ for the current request.\n    :param mimetype: The MIME type to send for the file. If not\n        provided, it will try to detect it from the file name.\n    :param as_attachment: Indicate to a browser that it should offer to\n        save the file instead of displaying it.\n    :param download_name: The default name browsers will use when saving\n        the file. Defaults to the passed file name.\n    :param conditional: Enable conditional and range responses based on\n        request headers. Requires passing a file path and ``environ``.\n    :param etag: Calculate an ETag for the file, which requires passing\n        a file path. Can also be a string to use instead.\n    :param last_modified: The last modified time to send for the file,\n        in seconds. If not provided, it will try to detect it from the\n        file path.\n    :param max_age: How long the client should cache the file, in\n        seconds. If set, ``Cache-Control`` will be ``public``, otherwise\n        it will be ``no-cache`` to prefer conditional caching.\n    :param use_x_sendfile: Set the ``X-Sendfile`` header to let the\n        server to efficiently send the file. Requires support from the\n        HTTP server. Requires passing a file path.\n    :param response_class: Build the response using this class. Defaults\n        to :class:`~werkzeug.wrappers.Response`.\n    :param _root_path: Do not use. For internal use only. Use\n        :func:`send_from_directory` to safely send files under a path.\n\n    .. versionchanged:: 2.0.2\n        ``send_file`` only sets a detected ``Content-Encoding`` if\n        ``as_attachment`` is disabled.\n\n    .. versionadded:: 2.0\n        Adapted from Flask's implementation.\n\n    .. versionchanged:: 2.0\n        ``download_name`` replaces Flask's ``attachment_filename``\n         parameter. If ``as_attachment=False``, it is passed with\n         ``Content-Disposition: inline`` instead.\n\n    .. versionchanged:: 2.0\n        ``max_age`` replaces Flask's ``cache_timeout`` parameter.\n        ``conditional`` is enabled and ``max_age`` is not set by\n        default.\n\n    .. versionchanged:: 2.0\n        ``etag`` replaces Flask's ``add_etags`` parameter. It can be a\n        string to use instead of generating one.\n\n    .. versionchanged:: 2.0\n        If an encoding is returned when guessing ``mimetype`` from\n        ``download_name``, set the ``Content-Encoding`` header.\n    \"\"\"\n    if response_class is None:\n        from .wrappers import Response\n\n        response_class = Response\n\n    path: str | None = None\n    file: t.IO[bytes] | None = None\n    size: int | None = None\n    mtime: float | None = None\n    headers = Headers()\n\n    if isinstance(path_or_file, (os.PathLike, str)) or hasattr(\n        path_or_file, \"__fspath__\"\n    ):\n        path_or_file = t.cast(\"t.Union[os.PathLike[str], str]\", path_or_file)\n\n        # Flask will pass app.root_path, allowing its send_file wrapper\n        # to not have to deal with paths.\n        if _root_path is not None:\n            path = os.path.join(_root_path, path_or_file)\n        else:\n            path = os.path.abspath(path_or_file)\n\n        stat = os.stat(path)\n        size = stat.st_size\n        mtime = stat.st_mtime\n    else:\n        file = path_or_file\n\n    if download_name is None and path is not None:\n        download_name = os.path.basename(path)\n\n    if mimetype is None:\n        if download_name is None:\n            raise TypeError(\n                \"Unable to detect the MIME type because a file name is\"\n                \" not available. Either set 'download_name', pass a\"\n                \" path instead of a file, or set 'mimetype'.\"\n            )\n\n        mimetype, encoding = mimetypes.guess_type(download_name)\n\n        if mimetype is None:\n            mimetype = \"application/octet-stream\"\n\n        # Don't send encoding for attachments, it causes browsers to\n        # save decompress tar.gz files.\n        if encoding is not None and not as_attachment:\n            headers.set(\"Content-Encoding\", encoding)\n\n    if download_name is not None:\n        try:\n            download_name.encode(\"ascii\")\n        except UnicodeEncodeError:\n            simple = unicodedata.normalize(\"NFKD\", download_name)\n            simple = simple.encode(\"ascii\", \"ignore\").decode(\"ascii\")\n            # safe = RFC 5987 attr-char\n            quoted = quote(download_name, safe=\"!#$&+-.^_`|~\")\n            names = {\"filename\": simple, \"filename*\": f\"UTF-8''{quoted}\"}\n        else:\n            names = {\"filename\": download_name}\n\n        value = \"attachment\" if as_attachment else \"inline\"\n        headers.set(\"Content-Disposition\", value, **names)\n    elif as_attachment:\n        raise TypeError(\n            \"No name provided for attachment. Either set\"\n            \" 'download_name' or pass a path instead of a file.\"\n        )\n\n    if use_x_sendfile and path is not None:\n        headers[\"X-Sendfile\"] = path\n        data = None\n    else:\n        if file is None:\n            file = open(path, \"rb\")  # type: ignore\n        elif isinstance(file, io.BytesIO):\n            size = file.getbuffer().nbytes\n        elif isinstance(file, io.TextIOBase):\n            raise ValueError(\"Files must be opened in binary mode or use BytesIO.\")\n\n        data = wrap_file(environ, file)\n\n    rv = response_class(\n        data, mimetype=mimetype, headers=headers, direct_passthrough=True\n    )\n\n    if size is not None:\n        rv.content_length = size\n\n    if last_modified is not None:\n        rv.last_modified = last_modified  # type: ignore\n    elif mtime is not None:\n        rv.last_modified = mtime  # type: ignore\n\n    rv.cache_control.no_cache = True\n\n    # Flask will pass app.get_send_file_max_age, allowing its send_file\n    # wrapper to not have to deal with paths.\n    if callable(max_age):\n        max_age = max_age(path)\n\n    if max_age is not None:\n        if max_age > 0:\n            rv.cache_control.no_cache = None\n            rv.cache_control.public = True\n\n        rv.cache_control.max_age = max_age\n        rv.expires = int(time() + max_age)  # type: ignore\n\n    if isinstance(etag, str):\n        rv.set_etag(etag)\n    elif etag and path is not None:\n        check = adler32(path.encode()) & 0xFFFFFFFF\n        rv.set_etag(f\"{mtime}-{size}-{check}\")\n\n    if conditional:\n        try:\n            rv = rv.make_conditional(environ, accept_ranges=True, complete_length=size)\n        except RequestedRangeNotSatisfiable:\n            if file is not None:\n                file.close()\n\n            raise\n\n        # Some x-sendfile implementations incorrectly ignore the 304\n        # status code and send the file anyway.\n        if rv.status_code == 304:\n            rv.headers.pop(\"x-sendfile\", None)\n\n    return rv\n\n\ndef send_from_directory(\n    directory: os.PathLike[str] | str,\n    path: os.PathLike[str] | str,\n    environ: WSGIEnvironment,\n    **kwargs: t.Any,\n) -> Response:\n    \"\"\"Send a file from within a directory using :func:`send_file`.\n\n    This is a secure way to serve files from a folder, such as static\n    files or uploads. Uses :func:`~werkzeug.security.safe_join` to\n    ensure the path coming from the client is not maliciously crafted to\n    point outside the specified directory.\n\n    If the final path does not point to an existing regular file,\n    returns a 404 :exc:`~werkzeug.exceptions.NotFound` error.\n\n    :param directory: The directory that ``path`` must be located under. This *must not*\n        be a value provided by the client, otherwise it becomes insecure.\n    :param path: The path to the file to send, relative to ``directory``. This is the\n        part of the path provided by the client, which is checked for security.\n    :param environ: The WSGI environ for the current request.\n    :param kwargs: Arguments to pass to :func:`send_file`.\n\n    .. versionadded:: 2.0\n        Adapted from Flask's implementation.\n    \"\"\"\n    path_str = safe_join(os.fspath(directory), os.fspath(path))\n\n    if path_str is None:\n        raise NotFound()\n\n    # Flask will pass app.root_path, allowing its send_from_directory\n    # wrapper to not have to deal with paths.\n    if \"_root_path\" in kwargs:\n        path_str = os.path.join(kwargs[\"_root_path\"], path_str)\n\n    if not os.path.isfile(path_str):\n        raise NotFound()\n\n    return send_file(path_str, environ, **kwargs)\n\n\ndef import_string(import_name: str, silent: bool = False) -> t.Any:\n    \"\"\"Imports an object based on a string.  This is useful if you want to\n    use import paths as endpoints or something similar.  An import path can\n    be specified either in dotted notation (``xml.sax.saxutils.escape``)\n    or with a colon as object delimiter (``xml.sax.saxutils:escape``).\n\n    If `silent` is True the return value will be `None` if the import fails.\n\n    :param import_name: the dotted name for the object to import.\n    :param silent: if set to `True` import errors are ignored and\n                   `None` is returned instead.\n    :return: imported object\n    \"\"\"\n    import_name = import_name.replace(\":\", \".\")\n    try:\n        try:\n            __import__(import_name)\n        except ImportError:\n            if \".\" not in import_name:\n                raise\n        else:\n            return sys.modules[import_name]\n\n        module_name, obj_name = import_name.rsplit(\".\", 1)\n        module = __import__(module_name, globals(), locals(), [obj_name])\n        try:\n            return getattr(module, obj_name)\n        except AttributeError as e:\n            raise ImportError(e) from None\n\n    except ImportError as e:\n        if not silent:\n            raise ImportStringError(import_name, e).with_traceback(\n                sys.exc_info()[2]\n            ) from None\n\n    return None\n\n\ndef find_modules(\n    import_path: str, include_packages: bool = False, recursive: bool = False\n) -> t.Iterator[str]:\n    \"\"\"Finds all the modules below a package.  This can be useful to\n    automatically import all views / controllers so that their metaclasses /\n    function decorators have a chance to register themselves on the\n    application.\n\n    Packages are not returned unless `include_packages` is `True`.  This can\n    also recursively list modules but in that case it will import all the\n    packages to get the correct load path of that module.\n\n    :param import_path: the dotted name for the package to find child modules.\n    :param include_packages: set to `True` if packages should be returned, too.\n    :param recursive: set to `True` if recursion should happen.\n    :return: generator\n    \"\"\"\n    module = import_string(import_path)\n    path = getattr(module, \"__path__\", None)\n    if path is None:\n        raise ValueError(f\"{import_path!r} is not a package\")\n    basename = f\"{module.__name__}.\"\n    for _importer, modname, ispkg in pkgutil.iter_modules(path):\n        modname = basename + modname\n        if ispkg:\n            if include_packages:\n                yield modname\n            if recursive:\n                yield from find_modules(modname, include_packages, True)\n        else:\n            yield modname\n\n\nclass ImportStringError(ImportError):\n    \"\"\"Provides information about a failed :func:`import_string` attempt.\"\"\"\n\n    #: String in dotted notation that failed to be imported.\n    import_name: str\n    #: Wrapped exception.\n    exception: BaseException\n\n    def __init__(self, import_name: str, exception: BaseException) -> None:\n        self.import_name = import_name\n        self.exception = exception\n        msg = import_name\n        name = \"\"\n        tracked = []\n        for part in import_name.replace(\":\", \".\").split(\".\"):\n            name = f\"{name}.{part}\" if name else part\n            imported = import_string(name, silent=True)\n            if imported:\n                tracked.append((name, getattr(imported, \"__file__\", None)))\n            else:\n                track = [f\"- {n!r} found in {i!r}.\" for n, i in tracked]\n                track.append(f\"- {name!r} not found.\")\n                track_str = \"\\n\".join(track)\n                msg = (\n                    f\"import_string() failed for {import_name!r}. Possible reasons\"\n                    f\" are:\\n\\n\"\n                    \"- missing __init__.py in a package;\\n\"\n                    \"- package or module path not included in sys.path;\\n\"\n                    \"- duplicated package or module name taking precedence in\"\n                    \" sys.path;\\n\"\n                    \"- missing module, class, function or variable;\\n\\n\"\n                    f\"Debugged import:\\n\\n{track_str}\\n\\n\"\n                    f\"Original exception:\\n\\n{type(exception).__name__}: {exception}\"\n                )\n                break\n\n        super().__init__(msg)\n\n    def __repr__(self) -> str:\n        return f\"<{type(self).__name__}({self.import_name!r}, {self.exception!r})>\"\n", "src/werkzeug/urls.py": "from __future__ import annotations\n\nimport codecs\nimport re\nimport typing as t\nimport urllib.parse\nfrom urllib.parse import quote\nfrom urllib.parse import unquote\nfrom urllib.parse import urlencode\nfrom urllib.parse import urlsplit\nfrom urllib.parse import urlunsplit\n\nfrom .datastructures import iter_multi_items\n\n\ndef _codec_error_url_quote(e: UnicodeError) -> tuple[str, int]:\n    \"\"\"Used in :func:`uri_to_iri` after unquoting to re-quote any\n    invalid bytes.\n    \"\"\"\n    # the docs state that UnicodeError does have these attributes,\n    # but mypy isn't picking them up\n    out = quote(e.object[e.start : e.end], safe=\"\")  # type: ignore\n    return out, e.end  # type: ignore\n\n\ncodecs.register_error(\"werkzeug.url_quote\", _codec_error_url_quote)\n\n\ndef _make_unquote_part(name: str, chars: str) -> t.Callable[[str], str]:\n    \"\"\"Create a function that unquotes all percent encoded characters except those\n    given. This allows working with unquoted characters if possible while not changing\n    the meaning of a given part of a URL.\n    \"\"\"\n    choices = \"|\".join(f\"{ord(c):02X}\" for c in sorted(chars))\n    pattern = re.compile(f\"((?:%(?:{choices}))+)\", re.I)\n\n    def _unquote_partial(value: str) -> str:\n        parts = iter(pattern.split(value))\n        out = []\n\n        for part in parts:\n            out.append(unquote(part, \"utf-8\", \"werkzeug.url_quote\"))\n            out.append(next(parts, \"\"))\n\n        return \"\".join(out)\n\n    _unquote_partial.__name__ = f\"_unquote_{name}\"\n    return _unquote_partial\n\n\n# characters that should remain quoted in URL parts\n# based on https://url.spec.whatwg.org/#percent-encoded-bytes\n# always keep all controls, space, and % quoted\n_always_unsafe = bytes((*range(0x21), 0x25, 0x7F)).decode()\n_unquote_fragment = _make_unquote_part(\"fragment\", _always_unsafe)\n_unquote_query = _make_unquote_part(\"query\", _always_unsafe + \"&=+#\")\n_unquote_path = _make_unquote_part(\"path\", _always_unsafe + \"/?#\")\n_unquote_user = _make_unquote_part(\"user\", _always_unsafe + \":@/?#\")\n\n\ndef uri_to_iri(uri: str) -> str:\n    \"\"\"Convert a URI to an IRI. All valid UTF-8 characters are unquoted,\n    leaving all reserved and invalid characters quoted. If the URL has\n    a domain, it is decoded from Punycode.\n\n    >>> uri_to_iri(\"http://xn--n3h.net/p%C3%A5th?q=%C3%A8ry%DF\")\n    'http://\\\\u2603.net/p\\\\xe5th?q=\\\\xe8ry%DF'\n\n    :param uri: The URI to convert.\n\n    .. versionchanged:: 3.0\n        Passing a tuple or bytes, and the ``charset`` and ``errors`` parameters,\n        are removed.\n\n    .. versionchanged:: 2.3\n        Which characters remain quoted is specific to each part of the URL.\n\n    .. versionchanged:: 0.15\n        All reserved and invalid characters remain quoted. Previously,\n        only some reserved characters were preserved, and invalid bytes\n        were replaced instead of left quoted.\n\n    .. versionadded:: 0.6\n    \"\"\"\n    parts = urlsplit(uri)\n    path = _unquote_path(parts.path)\n    query = _unquote_query(parts.query)\n    fragment = _unquote_fragment(parts.fragment)\n\n    if parts.hostname:\n        netloc = _decode_idna(parts.hostname)\n    else:\n        netloc = \"\"\n\n    if \":\" in netloc:\n        netloc = f\"[{netloc}]\"\n\n    if parts.port:\n        netloc = f\"{netloc}:{parts.port}\"\n\n    if parts.username:\n        auth = _unquote_user(parts.username)\n\n        if parts.password:\n            password = _unquote_user(parts.password)\n            auth = f\"{auth}:{password}\"\n\n        netloc = f\"{auth}@{netloc}\"\n\n    return urlunsplit((parts.scheme, netloc, path, query, fragment))\n\n\ndef iri_to_uri(iri: str) -> str:\n    \"\"\"Convert an IRI to a URI. All non-ASCII and unsafe characters are\n    quoted. If the URL has a domain, it is encoded to Punycode.\n\n    >>> iri_to_uri('http://\\\\u2603.net/p\\\\xe5th?q=\\\\xe8ry%DF')\n    'http://xn--n3h.net/p%C3%A5th?q=%C3%A8ry%DF'\n\n    :param iri: The IRI to convert.\n\n    .. versionchanged:: 3.0\n        Passing a tuple or bytes, the ``charset`` and ``errors`` parameters,\n        and the ``safe_conversion`` parameter, are removed.\n\n    .. versionchanged:: 2.3\n        Which characters remain unquoted is specific to each part of the URL.\n\n    .. versionchanged:: 0.15\n        All reserved characters remain unquoted. Previously, only some reserved\n        characters were left unquoted.\n\n    .. versionchanged:: 0.9.6\n       The ``safe_conversion`` parameter was added.\n\n    .. versionadded:: 0.6\n    \"\"\"\n    parts = urlsplit(iri)\n    # safe = https://url.spec.whatwg.org/#url-path-segment-string\n    # as well as percent for things that are already quoted\n    path = quote(parts.path, safe=\"%!$&'()*+,/:;=@\")\n    query = quote(parts.query, safe=\"%!$&'()*+,/:;=?@\")\n    fragment = quote(parts.fragment, safe=\"%!#$&'()*+,/:;=?@\")\n\n    if parts.hostname:\n        netloc = parts.hostname.encode(\"idna\").decode(\"ascii\")\n    else:\n        netloc = \"\"\n\n    if \":\" in netloc:\n        netloc = f\"[{netloc}]\"\n\n    if parts.port:\n        netloc = f\"{netloc}:{parts.port}\"\n\n    if parts.username:\n        auth = quote(parts.username, safe=\"%!$&'()*+,;=\")\n\n        if parts.password:\n            password = quote(parts.password, safe=\"%!$&'()*+,;=\")\n            auth = f\"{auth}:{password}\"\n\n        netloc = f\"{auth}@{netloc}\"\n\n    return urlunsplit((parts.scheme, netloc, path, query, fragment))\n\n\n# Python < 3.12\n# itms-services was worked around in previous iri_to_uri implementations, but\n# we can tell Python directly that it needs to preserve the //.\nif \"itms-services\" not in urllib.parse.uses_netloc:\n    urllib.parse.uses_netloc.append(\"itms-services\")\n\n\ndef _decode_idna(domain: str) -> str:\n    try:\n        data = domain.encode(\"ascii\")\n    except UnicodeEncodeError:\n        # If the domain is not ASCII, it's decoded already.\n        return domain\n\n    try:\n        # Try decoding in one shot.\n        return data.decode(\"idna\")\n    except UnicodeDecodeError:\n        pass\n\n    # Decode each part separately, leaving invalid parts as punycode.\n    parts = []\n\n    for part in data.split(b\".\"):\n        try:\n            parts.append(part.decode(\"idna\"))\n        except UnicodeDecodeError:\n            parts.append(part.decode(\"ascii\"))\n\n    return \".\".join(parts)\n\n\ndef _urlencode(query: t.Mapping[str, str] | t.Iterable[tuple[str, str]]) -> str:\n    items = [x for x in iter_multi_items(query) if x[1] is not None]\n    # safe = https://url.spec.whatwg.org/#percent-encoded-bytes\n    return urlencode(items, safe=\"!$'()*,/:;?@\")\n", "src/werkzeug/formparser.py": "from __future__ import annotations\n\nimport typing as t\nfrom io import BytesIO\nfrom urllib.parse import parse_qsl\n\nfrom ._internal import _plain_int\nfrom .datastructures import FileStorage\nfrom .datastructures import Headers\nfrom .datastructures import MultiDict\nfrom .exceptions import RequestEntityTooLarge\nfrom .http import parse_options_header\nfrom .sansio.multipart import Data\nfrom .sansio.multipart import Epilogue\nfrom .sansio.multipart import Field\nfrom .sansio.multipart import File\nfrom .sansio.multipart import MultipartDecoder\nfrom .sansio.multipart import NeedData\nfrom .wsgi import get_content_length\nfrom .wsgi import get_input_stream\n\n# there are some platforms where SpooledTemporaryFile is not available.\n# In that case we need to provide a fallback.\ntry:\n    from tempfile import SpooledTemporaryFile\nexcept ImportError:\n    from tempfile import TemporaryFile\n\n    SpooledTemporaryFile = None  # type: ignore\n\nif t.TYPE_CHECKING:\n    import typing as te\n\n    from _typeshed.wsgi import WSGIEnvironment\n\n    t_parse_result = t.Tuple[\n        t.IO[bytes], MultiDict[str, str], MultiDict[str, FileStorage]\n    ]\n\n    class TStreamFactory(te.Protocol):\n        def __call__(\n            self,\n            total_content_length: int | None,\n            content_type: str | None,\n            filename: str | None,\n            content_length: int | None = None,\n        ) -> t.IO[bytes]: ...\n\n\nF = t.TypeVar(\"F\", bound=t.Callable[..., t.Any])\n\n\ndef default_stream_factory(\n    total_content_length: int | None,\n    content_type: str | None,\n    filename: str | None,\n    content_length: int | None = None,\n) -> t.IO[bytes]:\n    max_size = 1024 * 500\n\n    if SpooledTemporaryFile is not None:\n        return t.cast(t.IO[bytes], SpooledTemporaryFile(max_size=max_size, mode=\"rb+\"))\n    elif total_content_length is None or total_content_length > max_size:\n        return t.cast(t.IO[bytes], TemporaryFile(\"rb+\"))\n\n    return BytesIO()\n\n\ndef parse_form_data(\n    environ: WSGIEnvironment,\n    stream_factory: TStreamFactory | None = None,\n    max_form_memory_size: int | None = None,\n    max_content_length: int | None = None,\n    cls: type[MultiDict[str, t.Any]] | None = None,\n    silent: bool = True,\n    *,\n    max_form_parts: int | None = None,\n) -> t_parse_result:\n    \"\"\"Parse the form data in the environ and return it as tuple in the form\n    ``(stream, form, files)``.  You should only call this method if the\n    transport method is `POST`, `PUT`, or `PATCH`.\n\n    If the mimetype of the data transmitted is `multipart/form-data` the\n    files multidict will be filled with `FileStorage` objects.  If the\n    mimetype is unknown the input stream is wrapped and returned as first\n    argument, else the stream is empty.\n\n    This is a shortcut for the common usage of :class:`FormDataParser`.\n\n    :param environ: the WSGI environment to be used for parsing.\n    :param stream_factory: An optional callable that returns a new read and\n                           writeable file descriptor.  This callable works\n                           the same as :meth:`Response._get_file_stream`.\n    :param max_form_memory_size: the maximum number of bytes to be accepted for\n                           in-memory stored form data.  If the data\n                           exceeds the value specified an\n                           :exc:`~exceptions.RequestEntityTooLarge`\n                           exception is raised.\n    :param max_content_length: If this is provided and the transmitted data\n                               is longer than this value an\n                               :exc:`~exceptions.RequestEntityTooLarge`\n                               exception is raised.\n    :param cls: an optional dict class to use.  If this is not specified\n                       or `None` the default :class:`MultiDict` is used.\n    :param silent: If set to False parsing errors will not be caught.\n    :param max_form_parts: The maximum number of multipart parts to be parsed. If this\n        is exceeded, a :exc:`~exceptions.RequestEntityTooLarge` exception is raised.\n    :return: A tuple in the form ``(stream, form, files)``.\n\n    .. versionchanged:: 3.0\n        The ``charset`` and ``errors`` parameters were removed.\n\n    .. versionchanged:: 2.3\n        Added the ``max_form_parts`` parameter.\n\n    .. versionadded:: 0.5.1\n       Added the ``silent`` parameter.\n\n    .. versionadded:: 0.5\n       Added the ``max_form_memory_size``, ``max_content_length``, and ``cls``\n       parameters.\n    \"\"\"\n    return FormDataParser(\n        stream_factory=stream_factory,\n        max_form_memory_size=max_form_memory_size,\n        max_content_length=max_content_length,\n        max_form_parts=max_form_parts,\n        silent=silent,\n        cls=cls,\n    ).parse_from_environ(environ)\n\n\nclass FormDataParser:\n    \"\"\"This class implements parsing of form data for Werkzeug.  By itself\n    it can parse multipart and url encoded form data.  It can be subclassed\n    and extended but for most mimetypes it is a better idea to use the\n    untouched stream and expose it as separate attributes on a request\n    object.\n\n    :param stream_factory: An optional callable that returns a new read and\n                           writeable file descriptor.  This callable works\n                           the same as :meth:`Response._get_file_stream`.\n    :param max_form_memory_size: the maximum number of bytes to be accepted for\n                           in-memory stored form data.  If the data\n                           exceeds the value specified an\n                           :exc:`~exceptions.RequestEntityTooLarge`\n                           exception is raised.\n    :param max_content_length: If this is provided and the transmitted data\n                               is longer than this value an\n                               :exc:`~exceptions.RequestEntityTooLarge`\n                               exception is raised.\n    :param cls: an optional dict class to use.  If this is not specified\n                       or `None` the default :class:`MultiDict` is used.\n    :param silent: If set to False parsing errors will not be caught.\n    :param max_form_parts: The maximum number of multipart parts to be parsed. If this\n        is exceeded, a :exc:`~exceptions.RequestEntityTooLarge` exception is raised.\n\n    .. versionchanged:: 3.0\n        The ``charset`` and ``errors`` parameters were removed.\n\n    .. versionchanged:: 3.0\n        The ``parse_functions`` attribute and ``get_parse_func`` methods were removed.\n\n    .. versionchanged:: 2.2.3\n        Added the ``max_form_parts`` parameter.\n\n    .. versionadded:: 0.8\n    \"\"\"\n\n    def __init__(\n        self,\n        stream_factory: TStreamFactory | None = None,\n        max_form_memory_size: int | None = None,\n        max_content_length: int | None = None,\n        cls: type[MultiDict[str, t.Any]] | None = None,\n        silent: bool = True,\n        *,\n        max_form_parts: int | None = None,\n    ) -> None:\n        if stream_factory is None:\n            stream_factory = default_stream_factory\n\n        self.stream_factory = stream_factory\n        self.max_form_memory_size = max_form_memory_size\n        self.max_content_length = max_content_length\n        self.max_form_parts = max_form_parts\n\n        if cls is None:\n            cls = t.cast(\"type[MultiDict[str, t.Any]]\", MultiDict)\n\n        self.cls = cls\n        self.silent = silent\n\n    def parse_from_environ(self, environ: WSGIEnvironment) -> t_parse_result:\n        \"\"\"Parses the information from the environment as form data.\n\n        :param environ: the WSGI environment to be used for parsing.\n        :return: A tuple in the form ``(stream, form, files)``.\n        \"\"\"\n        stream = get_input_stream(environ, max_content_length=self.max_content_length)\n        content_length = get_content_length(environ)\n        mimetype, options = parse_options_header(environ.get(\"CONTENT_TYPE\"))\n        return self.parse(\n            stream,\n            content_length=content_length,\n            mimetype=mimetype,\n            options=options,\n        )\n\n    def parse(\n        self,\n        stream: t.IO[bytes],\n        mimetype: str,\n        content_length: int | None,\n        options: dict[str, str] | None = None,\n    ) -> t_parse_result:\n        \"\"\"Parses the information from the given stream, mimetype,\n        content length and mimetype parameters.\n\n        :param stream: an input stream\n        :param mimetype: the mimetype of the data\n        :param content_length: the content length of the incoming data\n        :param options: optional mimetype parameters (used for\n                        the multipart boundary for instance)\n        :return: A tuple in the form ``(stream, form, files)``.\n\n        .. versionchanged:: 3.0\n            The invalid ``application/x-url-encoded`` content type is not\n            treated as ``application/x-www-form-urlencoded``.\n        \"\"\"\n        if mimetype == \"multipart/form-data\":\n            parse_func = self._parse_multipart\n        elif mimetype == \"application/x-www-form-urlencoded\":\n            parse_func = self._parse_urlencoded\n        else:\n            return stream, self.cls(), self.cls()\n\n        if options is None:\n            options = {}\n\n        try:\n            return parse_func(stream, mimetype, content_length, options)\n        except ValueError:\n            if not self.silent:\n                raise\n\n        return stream, self.cls(), self.cls()\n\n    def _parse_multipart(\n        self,\n        stream: t.IO[bytes],\n        mimetype: str,\n        content_length: int | None,\n        options: dict[str, str],\n    ) -> t_parse_result:\n        parser = MultiPartParser(\n            stream_factory=self.stream_factory,\n            max_form_memory_size=self.max_form_memory_size,\n            max_form_parts=self.max_form_parts,\n            cls=self.cls,\n        )\n        boundary = options.get(\"boundary\", \"\").encode(\"ascii\")\n\n        if not boundary:\n            raise ValueError(\"Missing boundary\")\n\n        form, files = parser.parse(stream, boundary, content_length)\n        return stream, form, files\n\n    def _parse_urlencoded(\n        self,\n        stream: t.IO[bytes],\n        mimetype: str,\n        content_length: int | None,\n        options: dict[str, str],\n    ) -> t_parse_result:\n        if (\n            self.max_form_memory_size is not None\n            and content_length is not None\n            and content_length > self.max_form_memory_size\n        ):\n            raise RequestEntityTooLarge()\n\n        try:\n            items = parse_qsl(\n                stream.read().decode(),\n                keep_blank_values=True,\n                errors=\"werkzeug.url_quote\",\n            )\n        except ValueError as e:\n            raise RequestEntityTooLarge() from e\n\n        return stream, self.cls(items), self.cls()\n\n\nclass MultiPartParser:\n    def __init__(\n        self,\n        stream_factory: TStreamFactory | None = None,\n        max_form_memory_size: int | None = None,\n        cls: type[MultiDict[str, t.Any]] | None = None,\n        buffer_size: int = 64 * 1024,\n        max_form_parts: int | None = None,\n    ) -> None:\n        self.max_form_memory_size = max_form_memory_size\n        self.max_form_parts = max_form_parts\n\n        if stream_factory is None:\n            stream_factory = default_stream_factory\n\n        self.stream_factory = stream_factory\n\n        if cls is None:\n            cls = t.cast(\"type[MultiDict[str, t.Any]]\", MultiDict)\n\n        self.cls = cls\n        self.buffer_size = buffer_size\n\n    def fail(self, message: str) -> te.NoReturn:\n        raise ValueError(message)\n\n    def get_part_charset(self, headers: Headers) -> str:\n        # Figure out input charset for current part\n        content_type = headers.get(\"content-type\")\n\n        if content_type:\n            parameters = parse_options_header(content_type)[1]\n            ct_charset = parameters.get(\"charset\", \"\").lower()\n\n            # A safe list of encodings. Modern clients should only send ASCII or UTF-8.\n            # This list will not be extended further.\n            if ct_charset in {\"ascii\", \"us-ascii\", \"utf-8\", \"iso-8859-1\"}:\n                return ct_charset\n\n        return \"utf-8\"\n\n    def start_file_streaming(\n        self, event: File, total_content_length: int | None\n    ) -> t.IO[bytes]:\n        content_type = event.headers.get(\"content-type\")\n\n        try:\n            content_length = _plain_int(event.headers[\"content-length\"])\n        except (KeyError, ValueError):\n            content_length = 0\n\n        container = self.stream_factory(\n            total_content_length=total_content_length,\n            filename=event.filename,\n            content_type=content_type,\n            content_length=content_length,\n        )\n        return container\n\n    def parse(\n        self, stream: t.IO[bytes], boundary: bytes, content_length: int | None\n    ) -> tuple[MultiDict[str, str], MultiDict[str, FileStorage]]:\n        current_part: Field | File\n        container: t.IO[bytes] | list[bytes]\n        _write: t.Callable[[bytes], t.Any]\n\n        parser = MultipartDecoder(\n            boundary,\n            max_form_memory_size=self.max_form_memory_size,\n            max_parts=self.max_form_parts,\n        )\n\n        fields = []\n        files = []\n\n        for data in _chunk_iter(stream.read, self.buffer_size):\n            parser.receive_data(data)\n            event = parser.next_event()\n            while not isinstance(event, (Epilogue, NeedData)):\n                if isinstance(event, Field):\n                    current_part = event\n                    container = []\n                    _write = container.append\n                elif isinstance(event, File):\n                    current_part = event\n                    container = self.start_file_streaming(event, content_length)\n                    _write = container.write\n                elif isinstance(event, Data):\n                    _write(event.data)\n                    if not event.more_data:\n                        if isinstance(current_part, Field):\n                            value = b\"\".join(container).decode(\n                                self.get_part_charset(current_part.headers), \"replace\"\n                            )\n                            fields.append((current_part.name, value))\n                        else:\n                            container = t.cast(t.IO[bytes], container)\n                            container.seek(0)\n                            files.append(\n                                (\n                                    current_part.name,\n                                    FileStorage(\n                                        container,\n                                        current_part.filename,\n                                        current_part.name,\n                                        headers=current_part.headers,\n                                    ),\n                                )\n                            )\n\n                event = parser.next_event()\n\n        return self.cls(fields), self.cls(files)\n\n\ndef _chunk_iter(read: t.Callable[[int], bytes], size: int) -> t.Iterator[bytes | None]:\n    \"\"\"Read data in chunks for multipart/form-data parsing. Stop if no data is read.\n    Yield ``None`` at the end to signal end of parsing.\n    \"\"\"\n    while True:\n        data = read(size)\n\n        if not data:\n            break\n\n        yield data\n\n    yield None\n", "src/werkzeug/__init__.py": "from __future__ import annotations\n\nimport typing as t\n\nfrom .serving import run_simple as run_simple\nfrom .test import Client as Client\nfrom .wrappers import Request as Request\nfrom .wrappers import Response as Response\n\n\ndef __getattr__(name: str) -> t.Any:\n    if name == \"__version__\":\n        import importlib.metadata\n        import warnings\n\n        warnings.warn(\n            \"The '__version__' attribute is deprecated and will be removed in\"\n            \" Werkzeug 3.1. Use feature detection or\"\n            \" 'importlib.metadata.version(\\\"werkzeug\\\")' instead.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        return importlib.metadata.version(\"werkzeug\")\n\n    raise AttributeError(name)\n", "src/werkzeug/wsgi.py": "from __future__ import annotations\n\nimport io\nimport typing as t\nfrom functools import partial\nfrom functools import update_wrapper\n\nfrom .exceptions import ClientDisconnected\nfrom .exceptions import RequestEntityTooLarge\nfrom .sansio import utils as _sansio_utils\nfrom .sansio.utils import host_is_trusted  # noqa: F401 # Imported as part of API\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n\n\ndef responder(f: t.Callable[..., WSGIApplication]) -> WSGIApplication:\n    \"\"\"Marks a function as responder.  Decorate a function with it and it\n    will automatically call the return value as WSGI application.\n\n    Example::\n\n        @responder\n        def application(environ, start_response):\n            return Response('Hello World!')\n    \"\"\"\n    return update_wrapper(lambda *a: f(*a)(*a[-2:]), f)\n\n\ndef get_current_url(\n    environ: WSGIEnvironment,\n    root_only: bool = False,\n    strip_querystring: bool = False,\n    host_only: bool = False,\n    trusted_hosts: t.Iterable[str] | None = None,\n) -> str:\n    \"\"\"Recreate the URL for a request from the parts in a WSGI\n    environment.\n\n    The URL is an IRI, not a URI, so it may contain Unicode characters.\n    Use :func:`~werkzeug.urls.iri_to_uri` to convert it to ASCII.\n\n    :param environ: The WSGI environment to get the URL parts from.\n    :param root_only: Only build the root path, don't include the\n        remaining path or query string.\n    :param strip_querystring: Don't include the query string.\n    :param host_only: Only build the scheme and host.\n    :param trusted_hosts: A list of trusted host names to validate the\n        host against.\n    \"\"\"\n    parts = {\n        \"scheme\": environ[\"wsgi.url_scheme\"],\n        \"host\": get_host(environ, trusted_hosts),\n    }\n\n    if not host_only:\n        parts[\"root_path\"] = environ.get(\"SCRIPT_NAME\", \"\")\n\n        if not root_only:\n            parts[\"path\"] = environ.get(\"PATH_INFO\", \"\")\n\n            if not strip_querystring:\n                parts[\"query_string\"] = environ.get(\"QUERY_STRING\", \"\").encode(\"latin1\")\n\n    return _sansio_utils.get_current_url(**parts)\n\n\ndef _get_server(\n    environ: WSGIEnvironment,\n) -> tuple[str, int | None] | None:\n    name = environ.get(\"SERVER_NAME\")\n\n    if name is None:\n        return None\n\n    try:\n        port: int | None = int(environ.get(\"SERVER_PORT\", None))\n    except (TypeError, ValueError):\n        # unix socket\n        port = None\n\n    return name, port\n\n\ndef get_host(\n    environ: WSGIEnvironment, trusted_hosts: t.Iterable[str] | None = None\n) -> str:\n    \"\"\"Return the host for the given WSGI environment.\n\n    The ``Host`` header is preferred, then ``SERVER_NAME`` if it's not\n    set. The returned host will only contain the port if it is different\n    than the standard port for the protocol.\n\n    Optionally, verify that the host is trusted using\n    :func:`host_is_trusted` and raise a\n    :exc:`~werkzeug.exceptions.SecurityError` if it is not.\n\n    :param environ: A WSGI environment dict.\n    :param trusted_hosts: A list of trusted host names.\n\n    :return: Host, with port if necessary.\n    :raise ~werkzeug.exceptions.SecurityError: If the host is not\n        trusted.\n    \"\"\"\n    return _sansio_utils.get_host(\n        environ[\"wsgi.url_scheme\"],\n        environ.get(\"HTTP_HOST\"),\n        _get_server(environ),\n        trusted_hosts,\n    )\n\n\ndef get_content_length(environ: WSGIEnvironment) -> int | None:\n    \"\"\"Return the ``Content-Length`` header value as an int. If the header is not given\n    or the ``Transfer-Encoding`` header is ``chunked``, ``None`` is returned to indicate\n    a streaming request. If the value is not an integer, or negative, 0 is returned.\n\n    :param environ: The WSGI environ to get the content length from.\n\n    .. versionadded:: 0.9\n    \"\"\"\n    return _sansio_utils.get_content_length(\n        http_content_length=environ.get(\"CONTENT_LENGTH\"),\n        http_transfer_encoding=environ.get(\"HTTP_TRANSFER_ENCODING\"),\n    )\n\n\ndef get_input_stream(\n    environ: WSGIEnvironment,\n    safe_fallback: bool = True,\n    max_content_length: int | None = None,\n) -> t.IO[bytes]:\n    \"\"\"Return the WSGI input stream, wrapped so that it may be read safely without going\n    past the ``Content-Length`` header value or ``max_content_length``.\n\n    If ``Content-Length`` exceeds ``max_content_length``, a\n    :exc:`RequestEntityTooLarge`` ``413 Content Too Large`` error is raised.\n\n    If the WSGI server sets ``environ[\"wsgi.input_terminated\"]``, it indicates that the\n    server handles terminating the stream, so it is safe to read directly. For example,\n    a server that knows how to handle chunked requests safely would set this.\n\n    If ``max_content_length`` is set, it can be enforced on streams if\n    ``wsgi.input_terminated`` is set. Otherwise, an empty stream is returned unless the\n    user explicitly disables this safe fallback.\n\n    If the limit is reached before the underlying stream is exhausted (such as a file\n    that is too large, or an infinite stream), the remaining contents of the stream\n    cannot be read safely. Depending on how the server handles this, clients may show a\n    \"connection reset\" failure instead of seeing the 413 response.\n\n    :param environ: The WSGI environ containing the stream.\n    :param safe_fallback: Return an empty stream when ``Content-Length`` is not set.\n        Disabling this allows infinite streams, which can be a denial-of-service risk.\n    :param max_content_length: The maximum length that content-length or streaming\n        requests may not exceed.\n\n    .. versionchanged:: 2.3.2\n        ``max_content_length`` is only applied to streaming requests if the server sets\n        ``wsgi.input_terminated``.\n\n    .. versionchanged:: 2.3\n        Check ``max_content_length`` and raise an error if it is exceeded.\n\n    .. versionadded:: 0.9\n    \"\"\"\n    stream = t.cast(t.IO[bytes], environ[\"wsgi.input\"])\n    content_length = get_content_length(environ)\n\n    if content_length is not None and max_content_length is not None:\n        if content_length > max_content_length:\n            raise RequestEntityTooLarge()\n\n    # A WSGI server can set this to indicate that it terminates the input stream. In\n    # that case the stream is safe without wrapping, or can enforce a max length.\n    if \"wsgi.input_terminated\" in environ:\n        if max_content_length is not None:\n            # If this is moved above, it can cause the stream to hang if a read attempt\n            # is made when the client sends no data. For example, the development server\n            # does not handle buffering except for chunked encoding.\n            return t.cast(\n                t.IO[bytes], LimitedStream(stream, max_content_length, is_max=True)\n            )\n\n        return stream\n\n    # No limit given, return an empty stream unless the user explicitly allows the\n    # potentially infinite stream. An infinite stream is dangerous if it's not expected,\n    # as it can tie up a worker indefinitely.\n    if content_length is None:\n        return io.BytesIO() if safe_fallback else stream\n\n    return t.cast(t.IO[bytes], LimitedStream(stream, content_length))\n\n\ndef get_path_info(environ: WSGIEnvironment) -> str:\n    \"\"\"Return ``PATH_INFO`` from  the WSGI environment.\n\n    :param environ: WSGI environment to get the path from.\n\n    .. versionchanged:: 3.0\n        The ``charset`` and ``errors`` parameters were removed.\n\n    .. versionadded:: 0.9\n    \"\"\"\n    path: bytes = environ.get(\"PATH_INFO\", \"\").encode(\"latin1\")\n    return path.decode(errors=\"replace\")\n\n\nclass ClosingIterator:\n    \"\"\"The WSGI specification requires that all middlewares and gateways\n    respect the `close` callback of the iterable returned by the application.\n    Because it is useful to add another close action to a returned iterable\n    and adding a custom iterable is a boring task this class can be used for\n    that::\n\n        return ClosingIterator(app(environ, start_response), [cleanup_session,\n                                                              cleanup_locals])\n\n    If there is just one close function it can be passed instead of the list.\n\n    A closing iterator is not needed if the application uses response objects\n    and finishes the processing if the response is started::\n\n        try:\n            return response(environ, start_response)\n        finally:\n            cleanup_session()\n            cleanup_locals()\n    \"\"\"\n\n    def __init__(\n        self,\n        iterable: t.Iterable[bytes],\n        callbacks: None\n        | (t.Callable[[], None] | t.Iterable[t.Callable[[], None]]) = None,\n    ) -> None:\n        iterator = iter(iterable)\n        self._next = t.cast(t.Callable[[], bytes], partial(next, iterator))\n        if callbacks is None:\n            callbacks = []\n        elif callable(callbacks):\n            callbacks = [callbacks]\n        else:\n            callbacks = list(callbacks)\n        iterable_close = getattr(iterable, \"close\", None)\n        if iterable_close:\n            callbacks.insert(0, iterable_close)\n        self._callbacks = callbacks\n\n    def __iter__(self) -> ClosingIterator:\n        return self\n\n    def __next__(self) -> bytes:\n        return self._next()\n\n    def close(self) -> None:\n        for callback in self._callbacks:\n            callback()\n\n\ndef wrap_file(\n    environ: WSGIEnvironment, file: t.IO[bytes], buffer_size: int = 8192\n) -> t.Iterable[bytes]:\n    \"\"\"Wraps a file.  This uses the WSGI server's file wrapper if available\n    or otherwise the generic :class:`FileWrapper`.\n\n    .. versionadded:: 0.5\n\n    If the file wrapper from the WSGI server is used it's important to not\n    iterate over it from inside the application but to pass it through\n    unchanged.  If you want to pass out a file wrapper inside a response\n    object you have to set :attr:`Response.direct_passthrough` to `True`.\n\n    More information about file wrappers are available in :pep:`333`.\n\n    :param file: a :class:`file`-like object with a :meth:`~file.read` method.\n    :param buffer_size: number of bytes for one iteration.\n    \"\"\"\n    return environ.get(\"wsgi.file_wrapper\", FileWrapper)(  # type: ignore\n        file, buffer_size\n    )\n\n\nclass FileWrapper:\n    \"\"\"This class can be used to convert a :class:`file`-like object into\n    an iterable.  It yields `buffer_size` blocks until the file is fully\n    read.\n\n    You should not use this class directly but rather use the\n    :func:`wrap_file` function that uses the WSGI server's file wrapper\n    support if it's available.\n\n    .. versionadded:: 0.5\n\n    If you're using this object together with a :class:`Response` you have\n    to use the `direct_passthrough` mode.\n\n    :param file: a :class:`file`-like object with a :meth:`~file.read` method.\n    :param buffer_size: number of bytes for one iteration.\n    \"\"\"\n\n    def __init__(self, file: t.IO[bytes], buffer_size: int = 8192) -> None:\n        self.file = file\n        self.buffer_size = buffer_size\n\n    def close(self) -> None:\n        if hasattr(self.file, \"close\"):\n            self.file.close()\n\n    def seekable(self) -> bool:\n        if hasattr(self.file, \"seekable\"):\n            return self.file.seekable()\n        if hasattr(self.file, \"seek\"):\n            return True\n        return False\n\n    def seek(self, *args: t.Any) -> None:\n        if hasattr(self.file, \"seek\"):\n            self.file.seek(*args)\n\n    def tell(self) -> int | None:\n        if hasattr(self.file, \"tell\"):\n            return self.file.tell()\n        return None\n\n    def __iter__(self) -> FileWrapper:\n        return self\n\n    def __next__(self) -> bytes:\n        data = self.file.read(self.buffer_size)\n        if data:\n            return data\n        raise StopIteration()\n\n\nclass _RangeWrapper:\n    # private for now, but should we make it public in the future ?\n\n    \"\"\"This class can be used to convert an iterable object into\n    an iterable that will only yield a piece of the underlying content.\n    It yields blocks until the underlying stream range is fully read.\n    The yielded blocks will have a size that can't exceed the original\n    iterator defined block size, but that can be smaller.\n\n    If you're using this object together with a :class:`Response` you have\n    to use the `direct_passthrough` mode.\n\n    :param iterable: an iterable object with a :meth:`__next__` method.\n    :param start_byte: byte from which read will start.\n    :param byte_range: how many bytes to read.\n    \"\"\"\n\n    def __init__(\n        self,\n        iterable: t.Iterable[bytes] | t.IO[bytes],\n        start_byte: int = 0,\n        byte_range: int | None = None,\n    ):\n        self.iterable = iter(iterable)\n        self.byte_range = byte_range\n        self.start_byte = start_byte\n        self.end_byte = None\n\n        if byte_range is not None:\n            self.end_byte = start_byte + byte_range\n\n        self.read_length = 0\n        self.seekable = hasattr(iterable, \"seekable\") and iterable.seekable()\n        self.end_reached = False\n\n    def __iter__(self) -> _RangeWrapper:\n        return self\n\n    def _next_chunk(self) -> bytes:\n        try:\n            chunk = next(self.iterable)\n            self.read_length += len(chunk)\n            return chunk\n        except StopIteration:\n            self.end_reached = True\n            raise\n\n    def _first_iteration(self) -> tuple[bytes | None, int]:\n        chunk = None\n        if self.seekable:\n            self.iterable.seek(self.start_byte)  # type: ignore\n            self.read_length = self.iterable.tell()  # type: ignore\n            contextual_read_length = self.read_length\n        else:\n            while self.read_length <= self.start_byte:\n                chunk = self._next_chunk()\n            if chunk is not None:\n                chunk = chunk[self.start_byte - self.read_length :]\n            contextual_read_length = self.start_byte\n        return chunk, contextual_read_length\n\n    def _next(self) -> bytes:\n        if self.end_reached:\n            raise StopIteration()\n        chunk = None\n        contextual_read_length = self.read_length\n        if self.read_length == 0:\n            chunk, contextual_read_length = self._first_iteration()\n        if chunk is None:\n            chunk = self._next_chunk()\n        if self.end_byte is not None and self.read_length >= self.end_byte:\n            self.end_reached = True\n            return chunk[: self.end_byte - contextual_read_length]\n        return chunk\n\n    def __next__(self) -> bytes:\n        chunk = self._next()\n        if chunk:\n            return chunk\n        self.end_reached = True\n        raise StopIteration()\n\n    def close(self) -> None:\n        if hasattr(self.iterable, \"close\"):\n            self.iterable.close()\n\n\nclass LimitedStream(io.RawIOBase):\n    \"\"\"Wrap a stream so that it doesn't read more than a given limit. This is used to\n    limit ``wsgi.input`` to the ``Content-Length`` header value or\n    :attr:`.Request.max_content_length`.\n\n    When attempting to read after the limit has been reached, :meth:`on_exhausted` is\n    called. When the limit is a maximum, this raises :exc:`.RequestEntityTooLarge`.\n\n    If reading from the stream returns zero bytes or raises an error,\n    :meth:`on_disconnect` is called, which raises :exc:`.ClientDisconnected`. When the\n    limit is a maximum and zero bytes were read, no error is raised, since it may be the\n    end of the stream.\n\n    If the limit is reached before the underlying stream is exhausted (such as a file\n    that is too large, or an infinite stream), the remaining contents of the stream\n    cannot be read safely. Depending on how the server handles this, clients may show a\n    \"connection reset\" failure instead of seeing the 413 response.\n\n    :param stream: The stream to read from. Must be a readable binary IO object.\n    :param limit: The limit in bytes to not read past. Should be either the\n        ``Content-Length`` header value or ``request.max_content_length``.\n    :param is_max: Whether the given ``limit`` is ``request.max_content_length`` instead\n        of the ``Content-Length`` header value. This changes how exhausted and\n        disconnect events are handled.\n\n    .. versionchanged:: 2.3\n        Handle ``max_content_length`` differently than ``Content-Length``.\n\n    .. versionchanged:: 2.3\n        Implements ``io.RawIOBase`` rather than ``io.IOBase``.\n    \"\"\"\n\n    def __init__(self, stream: t.IO[bytes], limit: int, is_max: bool = False) -> None:\n        self._stream = stream\n        self._pos = 0\n        self.limit = limit\n        self._limit_is_max = is_max\n\n    @property\n    def is_exhausted(self) -> bool:\n        \"\"\"Whether the current stream position has reached the limit.\"\"\"\n        return self._pos >= self.limit\n\n    def on_exhausted(self) -> None:\n        \"\"\"Called when attempting to read after the limit has been reached.\n\n        The default behavior is to do nothing, unless the limit is a maximum, in which\n        case it raises :exc:`.RequestEntityTooLarge`.\n\n        .. versionchanged:: 2.3\n            Raises ``RequestEntityTooLarge`` if the limit is a maximum.\n\n        .. versionchanged:: 2.3\n            Any return value is ignored.\n        \"\"\"\n        if self._limit_is_max:\n            raise RequestEntityTooLarge()\n\n    def on_disconnect(self, error: Exception | None = None) -> None:\n        \"\"\"Called when an attempted read receives zero bytes before the limit was\n        reached. This indicates that the client disconnected before sending the full\n        request body.\n\n        The default behavior is to raise :exc:`.ClientDisconnected`, unless the limit is\n        a maximum and no error was raised.\n\n        .. versionchanged:: 2.3\n            Added the ``error`` parameter. Do nothing if the limit is a maximum and no\n            error was raised.\n\n        .. versionchanged:: 2.3\n            Any return value is ignored.\n        \"\"\"\n        if not self._limit_is_max or error is not None:\n            raise ClientDisconnected()\n\n        # If the limit is a maximum, then we may have read zero bytes because the\n        # streaming body is complete. There's no way to distinguish that from the\n        # client disconnecting early.\n\n    def exhaust(self) -> bytes:\n        \"\"\"Exhaust the stream by reading until the limit is reached or the client\n        disconnects, returning the remaining data.\n\n        .. versionchanged:: 2.3\n            Return the remaining data.\n\n        .. versionchanged:: 2.2.3\n            Handle case where wrapped stream returns fewer bytes than requested.\n        \"\"\"\n        if not self.is_exhausted:\n            return self.readall()\n\n        return b\"\"\n\n    def readinto(self, b: bytearray) -> int | None:  # type: ignore[override]\n        size = len(b)\n        remaining = self.limit - self._pos\n\n        if remaining <= 0:\n            self.on_exhausted()\n            return 0\n\n        if hasattr(self._stream, \"readinto\"):\n            # Use stream.readinto if it's available.\n            if size <= remaining:\n                # The size fits in the remaining limit, use the buffer directly.\n                try:\n                    out_size: int | None = self._stream.readinto(b)\n                except (OSError, ValueError) as e:\n                    self.on_disconnect(error=e)\n                    return 0\n            else:\n                # Use a temp buffer with the remaining limit as the size.\n                temp_b = bytearray(remaining)\n\n                try:\n                    out_size = self._stream.readinto(temp_b)\n                except (OSError, ValueError) as e:\n                    self.on_disconnect(error=e)\n                    return 0\n\n                if out_size:\n                    b[:out_size] = temp_b\n        else:\n            # WSGI requires that stream.read is available.\n            try:\n                data = self._stream.read(min(size, remaining))\n            except (OSError, ValueError) as e:\n                self.on_disconnect(error=e)\n                return 0\n\n            out_size = len(data)\n            b[:out_size] = data\n\n        if not out_size:\n            # Read zero bytes from the stream.\n            self.on_disconnect()\n            return 0\n\n        self._pos += out_size\n        return out_size\n\n    def readall(self) -> bytes:\n        if self.is_exhausted:\n            self.on_exhausted()\n            return b\"\"\n\n        out = bytearray()\n\n        # The parent implementation uses \"while True\", which results in an extra read.\n        while not self.is_exhausted:\n            data = self.read(1024 * 64)\n\n            # Stream may return empty before a max limit is reached.\n            if not data:\n                break\n\n            out.extend(data)\n\n        return bytes(out)\n\n    def tell(self) -> int:\n        \"\"\"Return the current stream position.\n\n        .. versionadded:: 0.9\n        \"\"\"\n        return self._pos\n\n    def readable(self) -> bool:\n        return True\n", "src/werkzeug/testapp.py": "\"\"\"A small application that can be used to test a WSGI server and check\nit for WSGI compliance.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport importlib.metadata\nimport os\nimport sys\nimport typing as t\nfrom textwrap import wrap\n\nfrom markupsafe import escape\n\nfrom .wrappers.request import Request\nfrom .wrappers.response import Response\n\nTEMPLATE = \"\"\"\\\n<!doctype html>\n<html lang=en>\n<title>WSGI Information</title>\n<style type=\"text/css\">\n  @import url(https://fonts.googleapis.com/css?family=Ubuntu);\n\n  body       { font-family: 'Lucida Grande', 'Lucida Sans Unicode', 'Geneva',\n               'Verdana', sans-serif; background-color: white; color: #000;\n               font-size: 15px; text-align: center; }\n  div.box    { text-align: left; width: 45em; margin: auto; padding: 50px 0;\n               background-color: white; }\n  h1, h2     { font-family: 'Ubuntu', 'Lucida Grande', 'Lucida Sans Unicode',\n               'Geneva', 'Verdana', sans-serif; font-weight: normal; }\n  h1         { margin: 0 0 30px 0; }\n  h2         { font-size: 1.4em; margin: 1em 0 0.5em 0; }\n  table      { width: 100%%; border-collapse: collapse; border: 1px solid #AFC5C9 }\n  table th   { background-color: #AFC1C4; color: white; font-size: 0.72em;\n               font-weight: normal; width: 18em; vertical-align: top;\n               padding: 0.5em 0 0.1em 0.5em; }\n  table td   { border: 1px solid #AFC5C9; padding: 0.1em 0 0.1em 0.5em; }\n  code       { font-family: 'Consolas', 'Monaco', 'Bitstream Vera Sans Mono',\n               monospace; font-size: 0.7em; }\n  ul li      { line-height: 1.5em; }\n  ul.path    { font-size: 0.7em; margin: 0 -30px; padding: 8px 30px;\n               list-style: none; background: #E8EFF0; }\n  ul.path li { line-height: 1.6em; }\n  li.virtual { color: #999; text-decoration: underline; }\n  li.exp     { background: white; }\n</style>\n<div class=\"box\">\n  <h1>WSGI Information</h1>\n  <p>\n    This page displays all available information about the WSGI server and\n    the underlying Python interpreter.\n  <h2 id=\"python-interpreter\">Python Interpreter</h2>\n  <table>\n    <tr>\n      <th>Python Version\n      <td>%(python_version)s\n    <tr>\n      <th>Platform\n      <td>%(platform)s [%(os)s]\n    <tr>\n      <th>API Version\n      <td>%(api_version)s\n    <tr>\n      <th>Byteorder\n      <td>%(byteorder)s\n    <tr>\n      <th>Werkzeug Version\n      <td>%(werkzeug_version)s\n  </table>\n  <h2 id=\"wsgi-environment\">WSGI Environment</h2>\n  <table>%(wsgi_env)s</table>\n  <h2 id=\"installed-eggs\">Installed Eggs</h2>\n  <p>\n    The following python packages were installed on the system as\n    Python eggs:\n  <ul>%(python_eggs)s</ul>\n  <h2 id=\"sys-path\">System Path</h2>\n  <p>\n    The following paths are the current contents of the load path.  The\n    following entries are looked up for Python packages.  Note that not\n    all items in this path are folders.  Gray and underlined items are\n    entries pointing to invalid resources or used by custom import hooks\n    such as the zip importer.\n  <p>\n    Items with a bright background were expanded for display from a relative\n    path.  If you encounter such paths in the output you might want to check\n    your setup as relative paths are usually problematic in multithreaded\n    environments.\n  <ul class=\"path\">%(sys_path)s</ul>\n</div>\n\"\"\"\n\n\ndef iter_sys_path() -> t.Iterator[tuple[str, bool, bool]]:\n    if os.name == \"posix\":\n\n        def strip(x: str) -> str:\n            prefix = os.path.expanduser(\"~\")\n            if x.startswith(prefix):\n                x = f\"~{x[len(prefix) :]}\"\n            return x\n\n    else:\n\n        def strip(x: str) -> str:\n            return x\n\n    cwd = os.path.abspath(os.getcwd())\n    for item in sys.path:\n        path = os.path.join(cwd, item or os.path.curdir)\n        yield strip(os.path.normpath(path)), not os.path.isdir(path), path != item\n\n\n@Request.application\ndef test_app(req: Request) -> Response:\n    \"\"\"Simple test application that dumps the environment.  You can use\n    it to check if Werkzeug is working properly:\n\n    .. sourcecode:: pycon\n\n        >>> from werkzeug.serving import run_simple\n        >>> from werkzeug.testapp import test_app\n        >>> run_simple('localhost', 3000, test_app)\n         * Running on http://localhost:3000/\n\n    The application displays important information from the WSGI environment,\n    the Python interpreter and the installed libraries.\n    \"\"\"\n    try:\n        import pkg_resources\n    except ImportError:\n        eggs: t.Iterable[t.Any] = ()\n    else:\n        eggs = sorted(\n            pkg_resources.working_set,\n            key=lambda x: x.project_name.lower(),\n        )\n    python_eggs = []\n    for egg in eggs:\n        try:\n            version = egg.version\n        except (ValueError, AttributeError):\n            version = \"unknown\"\n        python_eggs.append(\n            f\"<li>{escape(egg.project_name)} <small>[{escape(version)}]</small>\"\n        )\n\n    wsgi_env = []\n    sorted_environ = sorted(req.environ.items(), key=lambda x: repr(x[0]).lower())\n    for key, value in sorted_environ:\n        value = \"\".join(wrap(str(escape(repr(value)))))\n        wsgi_env.append(f\"<tr><th>{escape(key)}<td><code>{value}</code>\")\n\n    sys_path = []\n    for item, virtual, expanded in iter_sys_path():\n        css = []\n        if virtual:\n            css.append(\"virtual\")\n        if expanded:\n            css.append(\"exp\")\n        class_str = f' class=\"{\" \".join(css)}\"' if css else \"\"\n        sys_path.append(f\"<li{class_str}>{escape(item)}\")\n\n    context = {\n        \"python_version\": \"<br>\".join(escape(sys.version).splitlines()),\n        \"platform\": escape(sys.platform),\n        \"os\": escape(os.name),\n        \"api_version\": sys.api_version,\n        \"byteorder\": sys.byteorder,\n        \"werkzeug_version\": _get_werkzeug_version(),\n        \"python_eggs\": \"\\n\".join(python_eggs),\n        \"wsgi_env\": \"\\n\".join(wsgi_env),\n        \"sys_path\": \"\\n\".join(sys_path),\n    }\n    return Response(TEMPLATE % context, mimetype=\"text/html\")\n\n\n_werkzeug_version = \"\"\n\n\ndef _get_werkzeug_version() -> str:\n    global _werkzeug_version\n\n    if not _werkzeug_version:\n        _werkzeug_version = importlib.metadata.version(\"werkzeug\")\n\n    return _werkzeug_version\n\n\nif __name__ == \"__main__\":\n    from .serving import run_simple\n\n    run_simple(\"localhost\", 5000, test_app, use_reloader=True)\n", "src/werkzeug/test.py": "from __future__ import annotations\n\nimport dataclasses\nimport mimetypes\nimport sys\nimport typing as t\nfrom collections import defaultdict\nfrom datetime import datetime\nfrom io import BytesIO\nfrom itertools import chain\nfrom random import random\nfrom tempfile import TemporaryFile\nfrom time import time\nfrom urllib.parse import unquote\nfrom urllib.parse import urlsplit\nfrom urllib.parse import urlunsplit\n\nfrom ._internal import _get_environ\nfrom ._internal import _wsgi_decoding_dance\nfrom ._internal import _wsgi_encoding_dance\nfrom .datastructures import Authorization\nfrom .datastructures import CallbackDict\nfrom .datastructures import CombinedMultiDict\nfrom .datastructures import EnvironHeaders\nfrom .datastructures import FileMultiDict\nfrom .datastructures import Headers\nfrom .datastructures import MultiDict\nfrom .http import dump_cookie\nfrom .http import dump_options_header\nfrom .http import parse_cookie\nfrom .http import parse_date\nfrom .http import parse_options_header\nfrom .sansio.multipart import Data\nfrom .sansio.multipart import Epilogue\nfrom .sansio.multipart import Field\nfrom .sansio.multipart import File\nfrom .sansio.multipart import MultipartEncoder\nfrom .sansio.multipart import Preamble\nfrom .urls import _urlencode\nfrom .urls import iri_to_uri\nfrom .utils import cached_property\nfrom .utils import get_content_type\nfrom .wrappers.request import Request\nfrom .wrappers.response import Response\nfrom .wsgi import ClosingIterator\nfrom .wsgi import get_current_url\n\nif t.TYPE_CHECKING:\n    import typing_extensions as te\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n\n\ndef stream_encode_multipart(\n    data: t.Mapping[str, t.Any],\n    use_tempfile: bool = True,\n    threshold: int = 1024 * 500,\n    boundary: str | None = None,\n) -> tuple[t.IO[bytes], int, str]:\n    \"\"\"Encode a dict of values (either strings or file descriptors or\n    :class:`FileStorage` objects.) into a multipart encoded string stored\n    in a file descriptor.\n\n    .. versionchanged:: 3.0\n        The ``charset`` parameter was removed.\n    \"\"\"\n    if boundary is None:\n        boundary = f\"---------------WerkzeugFormPart_{time()}{random()}\"\n\n    stream: t.IO[bytes] = BytesIO()\n    total_length = 0\n    on_disk = False\n    write_binary: t.Callable[[bytes], int]\n\n    if use_tempfile:\n\n        def write_binary(s: bytes) -> int:\n            nonlocal stream, total_length, on_disk\n\n            if on_disk:\n                return stream.write(s)\n            else:\n                length = len(s)\n\n                if length + total_length <= threshold:\n                    stream.write(s)\n                else:\n                    new_stream = t.cast(t.IO[bytes], TemporaryFile(\"wb+\"))\n                    new_stream.write(stream.getvalue())  # type: ignore\n                    new_stream.write(s)\n                    stream = new_stream\n                    on_disk = True\n\n                total_length += length\n                return length\n\n    else:\n        write_binary = stream.write\n\n    encoder = MultipartEncoder(boundary.encode())\n    write_binary(encoder.send_event(Preamble(data=b\"\")))\n    for key, value in _iter_data(data):\n        reader = getattr(value, \"read\", None)\n        if reader is not None:\n            filename = getattr(value, \"filename\", getattr(value, \"name\", None))\n            content_type = getattr(value, \"content_type\", None)\n            if content_type is None:\n                content_type = (\n                    filename\n                    and mimetypes.guess_type(filename)[0]\n                    or \"application/octet-stream\"\n                )\n            headers = value.headers\n            headers.update([(\"Content-Type\", content_type)])\n            if filename is None:\n                write_binary(encoder.send_event(Field(name=key, headers=headers)))\n            else:\n                write_binary(\n                    encoder.send_event(\n                        File(name=key, filename=filename, headers=headers)\n                    )\n                )\n            while True:\n                chunk = reader(16384)\n\n                if not chunk:\n                    write_binary(encoder.send_event(Data(data=chunk, more_data=False)))\n                    break\n\n                write_binary(encoder.send_event(Data(data=chunk, more_data=True)))\n        else:\n            if not isinstance(value, str):\n                value = str(value)\n            write_binary(encoder.send_event(Field(name=key, headers=Headers())))\n            write_binary(encoder.send_event(Data(data=value.encode(), more_data=False)))\n\n    write_binary(encoder.send_event(Epilogue(data=b\"\")))\n\n    length = stream.tell()\n    stream.seek(0)\n    return stream, length, boundary\n\n\ndef encode_multipart(\n    values: t.Mapping[str, t.Any], boundary: str | None = None\n) -> tuple[str, bytes]:\n    \"\"\"Like `stream_encode_multipart` but returns a tuple in the form\n    (``boundary``, ``data``) where data is bytes.\n\n    .. versionchanged:: 3.0\n        The ``charset`` parameter was removed.\n    \"\"\"\n    stream, length, boundary = stream_encode_multipart(\n        values, use_tempfile=False, boundary=boundary\n    )\n    return boundary, stream.read()\n\n\ndef _iter_data(data: t.Mapping[str, t.Any]) -> t.Iterator[tuple[str, t.Any]]:\n    \"\"\"Iterate over a mapping that might have a list of values, yielding\n    all key, value pairs. Almost like iter_multi_items but only allows\n    lists, not tuples, of values so tuples can be used for files.\n    \"\"\"\n    if isinstance(data, MultiDict):\n        yield from data.items(multi=True)\n    else:\n        for key, value in data.items():\n            if isinstance(value, list):\n                for v in value:\n                    yield key, v\n            else:\n                yield key, value\n\n\n_TAnyMultiDict = t.TypeVar(\"_TAnyMultiDict\", bound=\"MultiDict[t.Any, t.Any]\")\n\n\nclass EnvironBuilder:\n    \"\"\"This class can be used to conveniently create a WSGI environment\n    for testing purposes.  It can be used to quickly create WSGI environments\n    or request objects from arbitrary data.\n\n    The signature of this class is also used in some other places as of\n    Werkzeug 0.5 (:func:`create_environ`, :meth:`Response.from_values`,\n    :meth:`Client.open`).  Because of this most of the functionality is\n    available through the constructor alone.\n\n    Files and regular form data can be manipulated independently of each\n    other with the :attr:`form` and :attr:`files` attributes, but are\n    passed with the same argument to the constructor: `data`.\n\n    `data` can be any of these values:\n\n    -   a `str` or `bytes` object: The object is converted into an\n        :attr:`input_stream`, the :attr:`content_length` is set and you have to\n        provide a :attr:`content_type`.\n    -   a `dict` or :class:`MultiDict`: The keys have to be strings. The values\n        have to be either any of the following objects, or a list of any of the\n        following objects:\n\n        -   a :class:`file`-like object:  These are converted into\n            :class:`FileStorage` objects automatically.\n        -   a `tuple`:  The :meth:`~FileMultiDict.add_file` method is called\n            with the key and the unpacked `tuple` items as positional\n            arguments.\n        -   a `str`:  The string is set as form data for the associated key.\n    -   a file-like object: The object content is loaded in memory and then\n        handled like a regular `str` or a `bytes`.\n\n    :param path: the path of the request.  In the WSGI environment this will\n                 end up as `PATH_INFO`.  If the `query_string` is not defined\n                 and there is a question mark in the `path` everything after\n                 it is used as query string.\n    :param base_url: the base URL is a URL that is used to extract the WSGI\n                     URL scheme, host (server name + server port) and the\n                     script root (`SCRIPT_NAME`).\n    :param query_string: an optional string or dict with URL parameters.\n    :param method: the HTTP method to use, defaults to `GET`.\n    :param input_stream: an optional input stream.  Do not specify this and\n                         `data`.  As soon as an input stream is set you can't\n                         modify :attr:`args` and :attr:`files` unless you\n                         set the :attr:`input_stream` to `None` again.\n    :param content_type: The content type for the request.  As of 0.5 you\n                         don't have to provide this when specifying files\n                         and form data via `data`.\n    :param content_length: The content length for the request.  You don't\n                           have to specify this when providing data via\n                           `data`.\n    :param errors_stream: an optional error stream that is used for\n                          `wsgi.errors`.  Defaults to :data:`stderr`.\n    :param multithread: controls `wsgi.multithread`.  Defaults to `False`.\n    :param multiprocess: controls `wsgi.multiprocess`.  Defaults to `False`.\n    :param run_once: controls `wsgi.run_once`.  Defaults to `False`.\n    :param headers: an optional list or :class:`Headers` object of headers.\n    :param data: a string or dict of form data or a file-object.\n                 See explanation above.\n    :param json: An object to be serialized and assigned to ``data``.\n        Defaults the content type to ``\"application/json\"``.\n        Serialized with the function assigned to :attr:`json_dumps`.\n    :param environ_base: an optional dict of environment defaults.\n    :param environ_overrides: an optional dict of environment overrides.\n    :param auth: An authorization object to use for the\n        ``Authorization`` header value. A ``(username, password)`` tuple\n        is a shortcut for ``Basic`` authorization.\n\n    .. versionchanged:: 3.0\n        The ``charset`` parameter was removed.\n\n    .. versionchanged:: 2.1\n        ``CONTENT_TYPE`` and ``CONTENT_LENGTH`` are not duplicated as\n        header keys in the environ.\n\n    .. versionchanged:: 2.0\n        ``REQUEST_URI`` and ``RAW_URI`` is the full raw URI including\n        the query string, not only the path.\n\n    .. versionchanged:: 2.0\n        The default :attr:`request_class` is ``Request`` instead of\n        ``BaseRequest``.\n\n    .. versionadded:: 2.0\n       Added the ``auth`` parameter.\n\n    .. versionadded:: 0.15\n        The ``json`` param and :meth:`json_dumps` method.\n\n    .. versionadded:: 0.15\n        The environ has keys ``REQUEST_URI`` and ``RAW_URI`` containing\n        the path before percent-decoding. This is not part of the WSGI\n        PEP, but many WSGI servers include it.\n\n    .. versionchanged:: 0.6\n       ``path`` and ``base_url`` can now be unicode strings that are\n       encoded with :func:`iri_to_uri`.\n    \"\"\"\n\n    #: the server protocol to use.  defaults to HTTP/1.1\n    server_protocol = \"HTTP/1.1\"\n\n    #: the wsgi version to use.  defaults to (1, 0)\n    wsgi_version = (1, 0)\n\n    #: The default request class used by :meth:`get_request`.\n    request_class = Request\n\n    import json\n\n    #: The serialization function used when ``json`` is passed.\n    json_dumps = staticmethod(json.dumps)\n    del json\n\n    _args: MultiDict[str, str] | None\n    _query_string: str | None\n    _input_stream: t.IO[bytes] | None\n    _form: MultiDict[str, str] | None\n    _files: FileMultiDict | None\n\n    def __init__(\n        self,\n        path: str = \"/\",\n        base_url: str | None = None,\n        query_string: t.Mapping[str, str] | str | None = None,\n        method: str = \"GET\",\n        input_stream: t.IO[bytes] | None = None,\n        content_type: str | None = None,\n        content_length: int | None = None,\n        errors_stream: t.IO[str] | None = None,\n        multithread: bool = False,\n        multiprocess: bool = False,\n        run_once: bool = False,\n        headers: Headers | t.Iterable[tuple[str, str]] | None = None,\n        data: None | (t.IO[bytes] | str | bytes | t.Mapping[str, t.Any]) = None,\n        environ_base: t.Mapping[str, t.Any] | None = None,\n        environ_overrides: t.Mapping[str, t.Any] | None = None,\n        mimetype: str | None = None,\n        json: t.Mapping[str, t.Any] | None = None,\n        auth: Authorization | tuple[str, str] | None = None,\n    ) -> None:\n        if query_string is not None and \"?\" in path:\n            raise ValueError(\"Query string is defined in the path and as an argument\")\n        request_uri = urlsplit(path)\n        if query_string is None and \"?\" in path:\n            query_string = request_uri.query\n\n        self.path = iri_to_uri(request_uri.path)\n        self.request_uri = path\n        if base_url is not None:\n            base_url = iri_to_uri(base_url)\n        self.base_url = base_url  # type: ignore\n        if isinstance(query_string, str):\n            self.query_string = query_string\n        else:\n            if query_string is None:\n                query_string = MultiDict()\n            elif not isinstance(query_string, MultiDict):\n                query_string = MultiDict(query_string)\n            self.args = query_string\n        self.method = method\n        if headers is None:\n            headers = Headers()\n        elif not isinstance(headers, Headers):\n            headers = Headers(headers)\n        self.headers = headers\n        if content_type is not None:\n            self.content_type = content_type\n        if errors_stream is None:\n            errors_stream = sys.stderr\n        self.errors_stream = errors_stream\n        self.multithread = multithread\n        self.multiprocess = multiprocess\n        self.run_once = run_once\n        self.environ_base = environ_base\n        self.environ_overrides = environ_overrides\n        self.input_stream = input_stream\n        self.content_length = content_length\n        self.closed = False\n\n        if auth is not None:\n            if isinstance(auth, tuple):\n                auth = Authorization(\n                    \"basic\", {\"username\": auth[0], \"password\": auth[1]}\n                )\n\n            self.headers.set(\"Authorization\", auth.to_header())\n\n        if json is not None:\n            if data is not None:\n                raise TypeError(\"can't provide both json and data\")\n\n            data = self.json_dumps(json)\n\n            if self.content_type is None:\n                self.content_type = \"application/json\"\n\n        if data:\n            if input_stream is not None:\n                raise TypeError(\"can't provide input stream and data\")\n            if hasattr(data, \"read\"):\n                data = data.read()\n            if isinstance(data, str):\n                data = data.encode()\n            if isinstance(data, bytes):\n                self.input_stream = BytesIO(data)\n                if self.content_length is None:\n                    self.content_length = len(data)\n            else:\n                for key, value in _iter_data(data):\n                    if isinstance(value, (tuple, dict)) or hasattr(value, \"read\"):\n                        self._add_file_from_data(key, value)\n                    else:\n                        self.form.setlistdefault(key).append(value)\n\n        if mimetype is not None:\n            self.mimetype = mimetype\n\n    @classmethod\n    def from_environ(cls, environ: WSGIEnvironment, **kwargs: t.Any) -> EnvironBuilder:\n        \"\"\"Turn an environ dict back into a builder. Any extra kwargs\n        override the args extracted from the environ.\n\n        .. versionchanged:: 2.0\n            Path and query values are passed through the WSGI decoding\n            dance to avoid double encoding.\n\n        .. versionadded:: 0.15\n        \"\"\"\n        headers = Headers(EnvironHeaders(environ))\n        out = {\n            \"path\": _wsgi_decoding_dance(environ[\"PATH_INFO\"]),\n            \"base_url\": cls._make_base_url(\n                environ[\"wsgi.url_scheme\"],\n                headers.pop(\"Host\"),\n                _wsgi_decoding_dance(environ[\"SCRIPT_NAME\"]),\n            ),\n            \"query_string\": _wsgi_decoding_dance(environ[\"QUERY_STRING\"]),\n            \"method\": environ[\"REQUEST_METHOD\"],\n            \"input_stream\": environ[\"wsgi.input\"],\n            \"content_type\": headers.pop(\"Content-Type\", None),\n            \"content_length\": headers.pop(\"Content-Length\", None),\n            \"errors_stream\": environ[\"wsgi.errors\"],\n            \"multithread\": environ[\"wsgi.multithread\"],\n            \"multiprocess\": environ[\"wsgi.multiprocess\"],\n            \"run_once\": environ[\"wsgi.run_once\"],\n            \"headers\": headers,\n        }\n        out.update(kwargs)\n        return cls(**out)\n\n    def _add_file_from_data(\n        self,\n        key: str,\n        value: (t.IO[bytes] | tuple[t.IO[bytes], str] | tuple[t.IO[bytes], str, str]),\n    ) -> None:\n        \"\"\"Called in the EnvironBuilder to add files from the data dict.\"\"\"\n        if isinstance(value, tuple):\n            self.files.add_file(key, *value)\n        else:\n            self.files.add_file(key, value)\n\n    @staticmethod\n    def _make_base_url(scheme: str, host: str, script_root: str) -> str:\n        return urlunsplit((scheme, host, script_root, \"\", \"\")).rstrip(\"/\") + \"/\"\n\n    @property\n    def base_url(self) -> str:\n        \"\"\"The base URL is used to extract the URL scheme, host name,\n        port, and root path.\n        \"\"\"\n        return self._make_base_url(self.url_scheme, self.host, self.script_root)\n\n    @base_url.setter\n    def base_url(self, value: str | None) -> None:\n        if value is None:\n            scheme = \"http\"\n            netloc = \"localhost\"\n            script_root = \"\"\n        else:\n            scheme, netloc, script_root, qs, anchor = urlsplit(value)\n            if qs or anchor:\n                raise ValueError(\"base url must not contain a query string or fragment\")\n        self.script_root = script_root.rstrip(\"/\")\n        self.host = netloc\n        self.url_scheme = scheme\n\n    @property\n    def content_type(self) -> str | None:\n        \"\"\"The content type for the request.  Reflected from and to\n        the :attr:`headers`.  Do not set if you set :attr:`files` or\n        :attr:`form` for auto detection.\n        \"\"\"\n        ct = self.headers.get(\"Content-Type\")\n        if ct is None and not self._input_stream:\n            if self._files:\n                return \"multipart/form-data\"\n            if self._form:\n                return \"application/x-www-form-urlencoded\"\n            return None\n        return ct\n\n    @content_type.setter\n    def content_type(self, value: str | None) -> None:\n        if value is None:\n            self.headers.pop(\"Content-Type\", None)\n        else:\n            self.headers[\"Content-Type\"] = value\n\n    @property\n    def mimetype(self) -> str | None:\n        \"\"\"The mimetype (content type without charset etc.)\n\n        .. versionadded:: 0.14\n        \"\"\"\n        ct = self.content_type\n        return ct.split(\";\")[0].strip() if ct else None\n\n    @mimetype.setter\n    def mimetype(self, value: str) -> None:\n        self.content_type = get_content_type(value, \"utf-8\")\n\n    @property\n    def mimetype_params(self) -> t.Mapping[str, str]:\n        \"\"\"The mimetype parameters as dict.  For example if the\n        content type is ``text/html; charset=utf-8`` the params would be\n        ``{'charset': 'utf-8'}``.\n\n        .. versionadded:: 0.14\n        \"\"\"\n\n        def on_update(d: CallbackDict[str, str]) -> None:\n            self.headers[\"Content-Type\"] = dump_options_header(self.mimetype, d)\n\n        d = parse_options_header(self.headers.get(\"content-type\", \"\"))[1]\n        return CallbackDict(d, on_update)\n\n    @property\n    def content_length(self) -> int | None:\n        \"\"\"The content length as integer.  Reflected from and to the\n        :attr:`headers`.  Do not set if you set :attr:`files` or\n        :attr:`form` for auto detection.\n        \"\"\"\n        return self.headers.get(\"Content-Length\", type=int)\n\n    @content_length.setter\n    def content_length(self, value: int | None) -> None:\n        if value is None:\n            self.headers.pop(\"Content-Length\", None)\n        else:\n            self.headers[\"Content-Length\"] = str(value)\n\n    def _get_form(self, name: str, storage: type[_TAnyMultiDict]) -> _TAnyMultiDict:\n        \"\"\"Common behavior for getting the :attr:`form` and\n        :attr:`files` properties.\n\n        :param name: Name of the internal cached attribute.\n        :param storage: Storage class used for the data.\n        \"\"\"\n        if self.input_stream is not None:\n            raise AttributeError(\"an input stream is defined\")\n\n        rv = getattr(self, name)\n\n        if rv is None:\n            rv = storage()\n            setattr(self, name, rv)\n\n        return rv  # type: ignore\n\n    def _set_form(self, name: str, value: MultiDict[str, t.Any]) -> None:\n        \"\"\"Common behavior for setting the :attr:`form` and\n        :attr:`files` properties.\n\n        :param name: Name of the internal cached attribute.\n        :param value: Value to assign to the attribute.\n        \"\"\"\n        self._input_stream = None\n        setattr(self, name, value)\n\n    @property\n    def form(self) -> MultiDict[str, str]:\n        \"\"\"A :class:`MultiDict` of form values.\"\"\"\n        return self._get_form(\"_form\", MultiDict)\n\n    @form.setter\n    def form(self, value: MultiDict[str, str]) -> None:\n        self._set_form(\"_form\", value)\n\n    @property\n    def files(self) -> FileMultiDict:\n        \"\"\"A :class:`FileMultiDict` of uploaded files. Use\n        :meth:`~FileMultiDict.add_file` to add new files.\n        \"\"\"\n        return self._get_form(\"_files\", FileMultiDict)\n\n    @files.setter\n    def files(self, value: FileMultiDict) -> None:\n        self._set_form(\"_files\", value)\n\n    @property\n    def input_stream(self) -> t.IO[bytes] | None:\n        \"\"\"An optional input stream. This is mutually exclusive with\n        setting :attr:`form` and :attr:`files`, setting it will clear\n        those. Do not provide this if the method is not ``POST`` or\n        another method that has a body.\n        \"\"\"\n        return self._input_stream\n\n    @input_stream.setter\n    def input_stream(self, value: t.IO[bytes] | None) -> None:\n        self._input_stream = value\n        self._form = None\n        self._files = None\n\n    @property\n    def query_string(self) -> str:\n        \"\"\"The query string.  If you set this to a string\n        :attr:`args` will no longer be available.\n        \"\"\"\n        if self._query_string is None:\n            if self._args is not None:\n                return _urlencode(self._args)\n            return \"\"\n        return self._query_string\n\n    @query_string.setter\n    def query_string(self, value: str | None) -> None:\n        self._query_string = value\n        self._args = None\n\n    @property\n    def args(self) -> MultiDict[str, str]:\n        \"\"\"The URL arguments as :class:`MultiDict`.\"\"\"\n        if self._query_string is not None:\n            raise AttributeError(\"a query string is defined\")\n        if self._args is None:\n            self._args = MultiDict()\n        return self._args\n\n    @args.setter\n    def args(self, value: MultiDict[str, str] | None) -> None:\n        self._query_string = None\n        self._args = value\n\n    @property\n    def server_name(self) -> str:\n        \"\"\"The server name (read-only, use :attr:`host` to set)\"\"\"\n        return self.host.split(\":\", 1)[0]\n\n    @property\n    def server_port(self) -> int:\n        \"\"\"The server port as integer (read-only, use :attr:`host` to set)\"\"\"\n        pieces = self.host.split(\":\", 1)\n\n        if len(pieces) == 2:\n            try:\n                return int(pieces[1])\n            except ValueError:\n                pass\n\n        if self.url_scheme == \"https\":\n            return 443\n        return 80\n\n    def __del__(self) -> None:\n        try:\n            self.close()\n        except Exception:\n            pass\n\n    def close(self) -> None:\n        \"\"\"Closes all files.  If you put real :class:`file` objects into the\n        :attr:`files` dict you can call this method to automatically close\n        them all in one go.\n        \"\"\"\n        if self.closed:\n            return\n        try:\n            files = self.files.values()\n        except AttributeError:\n            files = ()  # type: ignore\n        for f in files:\n            try:\n                f.close()\n            except Exception:\n                pass\n        self.closed = True\n\n    def get_environ(self) -> WSGIEnvironment:\n        \"\"\"Return the built environ.\n\n        .. versionchanged:: 0.15\n            The content type and length headers are set based on\n            input stream detection. Previously this only set the WSGI\n            keys.\n        \"\"\"\n        input_stream = self.input_stream\n        content_length = self.content_length\n\n        mimetype = self.mimetype\n        content_type = self.content_type\n\n        if input_stream is not None:\n            start_pos = input_stream.tell()\n            input_stream.seek(0, 2)\n            end_pos = input_stream.tell()\n            input_stream.seek(start_pos)\n            content_length = end_pos - start_pos\n        elif mimetype == \"multipart/form-data\":\n            input_stream, content_length, boundary = stream_encode_multipart(\n                CombinedMultiDict([self.form, self.files])\n            )\n            content_type = f'{mimetype}; boundary=\"{boundary}\"'\n        elif mimetype == \"application/x-www-form-urlencoded\":\n            form_encoded = _urlencode(self.form).encode(\"ascii\")\n            content_length = len(form_encoded)\n            input_stream = BytesIO(form_encoded)\n        else:\n            input_stream = BytesIO()\n\n        result: WSGIEnvironment = {}\n        if self.environ_base:\n            result.update(self.environ_base)\n\n        def _path_encode(x: str) -> str:\n            return _wsgi_encoding_dance(unquote(x))\n\n        raw_uri = _wsgi_encoding_dance(self.request_uri)\n        result.update(\n            {\n                \"REQUEST_METHOD\": self.method,\n                \"SCRIPT_NAME\": _path_encode(self.script_root),\n                \"PATH_INFO\": _path_encode(self.path),\n                \"QUERY_STRING\": _wsgi_encoding_dance(self.query_string),\n                # Non-standard, added by mod_wsgi, uWSGI\n                \"REQUEST_URI\": raw_uri,\n                # Non-standard, added by gunicorn\n                \"RAW_URI\": raw_uri,\n                \"SERVER_NAME\": self.server_name,\n                \"SERVER_PORT\": str(self.server_port),\n                \"HTTP_HOST\": self.host,\n                \"SERVER_PROTOCOL\": self.server_protocol,\n                \"wsgi.version\": self.wsgi_version,\n                \"wsgi.url_scheme\": self.url_scheme,\n                \"wsgi.input\": input_stream,\n                \"wsgi.errors\": self.errors_stream,\n                \"wsgi.multithread\": self.multithread,\n                \"wsgi.multiprocess\": self.multiprocess,\n                \"wsgi.run_once\": self.run_once,\n            }\n        )\n\n        headers = self.headers.copy()\n        # Don't send these as headers, they're part of the environ.\n        headers.remove(\"Content-Type\")\n        headers.remove(\"Content-Length\")\n\n        if content_type is not None:\n            result[\"CONTENT_TYPE\"] = content_type\n\n        if content_length is not None:\n            result[\"CONTENT_LENGTH\"] = str(content_length)\n\n        combined_headers = defaultdict(list)\n\n        for key, value in headers.to_wsgi_list():\n            combined_headers[f\"HTTP_{key.upper().replace('-', '_')}\"].append(value)\n\n        for key, values in combined_headers.items():\n            result[key] = \", \".join(values)\n\n        if self.environ_overrides:\n            result.update(self.environ_overrides)\n\n        return result\n\n    def get_request(self, cls: type[Request] | None = None) -> Request:\n        \"\"\"Returns a request with the data.  If the request class is not\n        specified :attr:`request_class` is used.\n\n        :param cls: The request wrapper to use.\n        \"\"\"\n        if cls is None:\n            cls = self.request_class\n\n        return cls(self.get_environ())\n\n\nclass ClientRedirectError(Exception):\n    \"\"\"If a redirect loop is detected when using follow_redirects=True with\n    the :cls:`Client`, then this exception is raised.\n    \"\"\"\n\n\nclass Client:\n    \"\"\"Simulate sending requests to a WSGI application without running a WSGI or HTTP\n    server.\n\n    :param application: The WSGI application to make requests to.\n    :param response_wrapper: A :class:`.Response` class to wrap response data with.\n        Defaults to :class:`.TestResponse`. If it's not a subclass of ``TestResponse``,\n        one will be created.\n    :param use_cookies: Persist cookies from ``Set-Cookie`` response headers to the\n        ``Cookie`` header in subsequent requests. Domain and path matching is supported,\n        but other cookie parameters are ignored.\n    :param allow_subdomain_redirects: Allow requests to follow redirects to subdomains.\n        Enable this if the application handles subdomains and redirects between them.\n\n    .. versionchanged:: 2.3\n        Simplify cookie implementation, support domain and path matching.\n\n    .. versionchanged:: 2.1\n        All data is available as properties on the returned response object. The\n        response cannot be returned as a tuple.\n\n    .. versionchanged:: 2.0\n        ``response_wrapper`` is always a subclass of :class:``TestResponse``.\n\n    .. versionchanged:: 0.5\n        Added the ``use_cookies`` parameter.\n    \"\"\"\n\n    def __init__(\n        self,\n        application: WSGIApplication,\n        response_wrapper: type[Response] | None = None,\n        use_cookies: bool = True,\n        allow_subdomain_redirects: bool = False,\n    ) -> None:\n        self.application = application\n\n        if response_wrapper in {None, Response}:\n            response_wrapper = TestResponse\n        elif response_wrapper is not None and not issubclass(\n            response_wrapper, TestResponse\n        ):\n            response_wrapper = type(\n                \"WrapperTestResponse\",\n                (TestResponse, response_wrapper),\n                {},\n            )\n\n        self.response_wrapper = t.cast(t.Type[\"TestResponse\"], response_wrapper)\n\n        if use_cookies:\n            self._cookies: dict[tuple[str, str, str], Cookie] | None = {}\n        else:\n            self._cookies = None\n\n        self.allow_subdomain_redirects = allow_subdomain_redirects\n\n    def get_cookie(\n        self, key: str, domain: str = \"localhost\", path: str = \"/\"\n    ) -> Cookie | None:\n        \"\"\"Return a :class:`.Cookie` if it exists. Cookies are uniquely identified by\n        ``(domain, path, key)``.\n\n        :param key: The decoded form of the key for the cookie.\n        :param domain: The domain the cookie was set for.\n        :param path: The path the cookie was set for.\n\n        .. versionadded:: 2.3\n        \"\"\"\n        if self._cookies is None:\n            raise TypeError(\n                \"Cookies are disabled. Create a client with 'use_cookies=True'.\"\n            )\n\n        return self._cookies.get((domain, path, key))\n\n    def set_cookie(\n        self,\n        key: str,\n        value: str = \"\",\n        *,\n        domain: str = \"localhost\",\n        origin_only: bool = True,\n        path: str = \"/\",\n        **kwargs: t.Any,\n    ) -> None:\n        \"\"\"Set a cookie to be sent in subsequent requests.\n\n        This is a convenience to skip making a test request to a route that would set\n        the cookie. To test the cookie, make a test request to a route that uses the\n        cookie value.\n\n        The client uses ``domain``, ``origin_only``, and ``path`` to determine which\n        cookies to send with a request. It does not use other cookie parameters that\n        browsers use, since they're not applicable in tests.\n\n        :param key: The key part of the cookie.\n        :param value: The value part of the cookie.\n        :param domain: Send this cookie with requests that match this domain. If\n            ``origin_only`` is true, it must be an exact match, otherwise it may be a\n            suffix match.\n        :param origin_only: Whether the domain must be an exact match to the request.\n        :param path: Send this cookie with requests that match this path either exactly\n            or as a prefix.\n        :param kwargs: Passed to :func:`.dump_cookie`.\n\n        .. versionchanged:: 3.0\n            The parameter ``server_name`` is removed. The first parameter is\n            ``key``. Use the ``domain`` and ``origin_only`` parameters instead.\n\n        .. versionchanged:: 2.3\n            The ``origin_only`` parameter was added.\n\n        .. versionchanged:: 2.3\n            The ``domain`` parameter defaults to ``localhost``.\n        \"\"\"\n        if self._cookies is None:\n            raise TypeError(\n                \"Cookies are disabled. Create a client with 'use_cookies=True'.\"\n            )\n\n        cookie = Cookie._from_response_header(\n            domain, \"/\", dump_cookie(key, value, domain=domain, path=path, **kwargs)\n        )\n        cookie.origin_only = origin_only\n\n        if cookie._should_delete:\n            self._cookies.pop(cookie._storage_key, None)\n        else:\n            self._cookies[cookie._storage_key] = cookie\n\n    def delete_cookie(\n        self,\n        key: str,\n        *,\n        domain: str = \"localhost\",\n        path: str = \"/\",\n    ) -> None:\n        \"\"\"Delete a cookie if it exists. Cookies are uniquely identified by\n        ``(domain, path, key)``.\n\n        :param key: The decoded form of the key for the cookie.\n        :param domain: The domain the cookie was set for.\n        :param path: The path the cookie was set for.\n\n        .. versionchanged:: 3.0\n            The ``server_name`` parameter is removed. The first parameter is\n            ``key``. Use the ``domain`` parameter instead.\n\n        .. versionchanged:: 3.0\n            The ``secure``, ``httponly`` and ``samesite`` parameters are removed.\n\n        .. versionchanged:: 2.3\n            The ``domain`` parameter defaults to ``localhost``.\n        \"\"\"\n        if self._cookies is None:\n            raise TypeError(\n                \"Cookies are disabled. Create a client with 'use_cookies=True'.\"\n            )\n\n        self._cookies.pop((domain, path, key), None)\n\n    def _add_cookies_to_wsgi(self, environ: WSGIEnvironment) -> None:\n        \"\"\"If cookies are enabled, set the ``Cookie`` header in the environ to the\n        cookies that are applicable to the request host and path.\n\n        :meta private:\n\n        .. versionadded:: 2.3\n        \"\"\"\n        if self._cookies is None:\n            return\n\n        url = urlsplit(get_current_url(environ))\n        server_name = url.hostname or \"localhost\"\n        value = \"; \".join(\n            c._to_request_header()\n            for c in self._cookies.values()\n            if c._matches_request(server_name, url.path)\n        )\n\n        if value:\n            environ[\"HTTP_COOKIE\"] = value\n        else:\n            environ.pop(\"HTTP_COOKIE\", None)\n\n    def _update_cookies_from_response(\n        self, server_name: str, path: str, headers: list[str]\n    ) -> None:\n        \"\"\"If cookies are enabled, update the stored cookies from any ``Set-Cookie``\n        headers in the response.\n\n        :meta private:\n\n        .. versionadded:: 2.3\n        \"\"\"\n        if self._cookies is None:\n            return\n\n        for header in headers:\n            cookie = Cookie._from_response_header(server_name, path, header)\n\n            if cookie._should_delete:\n                self._cookies.pop(cookie._storage_key, None)\n            else:\n                self._cookies[cookie._storage_key] = cookie\n\n    def run_wsgi_app(\n        self, environ: WSGIEnvironment, buffered: bool = False\n    ) -> tuple[t.Iterable[bytes], str, Headers]:\n        \"\"\"Runs the wrapped WSGI app with the given environment.\n\n        :meta private:\n        \"\"\"\n        self._add_cookies_to_wsgi(environ)\n        rv = run_wsgi_app(self.application, environ, buffered=buffered)\n        url = urlsplit(get_current_url(environ))\n        self._update_cookies_from_response(\n            url.hostname or \"localhost\", url.path, rv[2].getlist(\"Set-Cookie\")\n        )\n        return rv\n\n    def resolve_redirect(\n        self, response: TestResponse, buffered: bool = False\n    ) -> TestResponse:\n        \"\"\"Perform a new request to the location given by the redirect\n        response to the previous request.\n\n        :meta private:\n        \"\"\"\n        scheme, netloc, path, qs, anchor = urlsplit(response.location)\n        builder = EnvironBuilder.from_environ(\n            response.request.environ, path=path, query_string=qs\n        )\n\n        to_name_parts = netloc.split(\":\", 1)[0].split(\".\")\n        from_name_parts = builder.server_name.split(\".\")\n\n        if to_name_parts != [\"\"]:\n            # The new location has a host, use it for the base URL.\n            builder.url_scheme = scheme\n            builder.host = netloc\n        else:\n            # A local redirect with autocorrect_location_header=False\n            # doesn't have a host, so use the request's host.\n            to_name_parts = from_name_parts\n\n        # Explain why a redirect to a different server name won't be followed.\n        if to_name_parts != from_name_parts:\n            if to_name_parts[-len(from_name_parts) :] == from_name_parts:\n                if not self.allow_subdomain_redirects:\n                    raise RuntimeError(\"Following subdomain redirects is not enabled.\")\n            else:\n                raise RuntimeError(\"Following external redirects is not supported.\")\n\n        path_parts = path.split(\"/\")\n        root_parts = builder.script_root.split(\"/\")\n\n        if path_parts[: len(root_parts)] == root_parts:\n            # Strip the script root from the path.\n            builder.path = path[len(builder.script_root) :]\n        else:\n            # The new location is not under the script root, so use the\n            # whole path and clear the previous root.\n            builder.path = path\n            builder.script_root = \"\"\n\n        # Only 307 and 308 preserve all of the original request.\n        if response.status_code not in {307, 308}:\n            # HEAD is preserved, everything else becomes GET.\n            if builder.method != \"HEAD\":\n                builder.method = \"GET\"\n\n            # Clear the body and the headers that describe it.\n\n            if builder.input_stream is not None:\n                builder.input_stream.close()\n                builder.input_stream = None\n\n            builder.content_type = None\n            builder.content_length = None\n            builder.headers.pop(\"Transfer-Encoding\", None)\n\n        return self.open(builder, buffered=buffered)\n\n    def open(\n        self,\n        *args: t.Any,\n        buffered: bool = False,\n        follow_redirects: bool = False,\n        **kwargs: t.Any,\n    ) -> TestResponse:\n        \"\"\"Generate an environ dict from the given arguments, make a\n        request to the application using it, and return the response.\n\n        :param args: Passed to :class:`EnvironBuilder` to create the\n            environ for the request. If a single arg is passed, it can\n            be an existing :class:`EnvironBuilder` or an environ dict.\n        :param buffered: Convert the iterator returned by the app into\n            a list. If the iterator has a ``close()`` method, it is\n            called automatically.\n        :param follow_redirects: Make additional requests to follow HTTP\n            redirects until a non-redirect status is returned.\n            :attr:`TestResponse.history` lists the intermediate\n            responses.\n\n        .. versionchanged:: 2.1\n            Removed the ``as_tuple`` parameter.\n\n        .. versionchanged:: 2.0\n            The request input stream is closed when calling\n            ``response.close()``. Input streams for redirects are\n            automatically closed.\n\n        .. versionchanged:: 0.5\n            If a dict is provided as file in the dict for the ``data``\n            parameter the content type has to be called ``content_type``\n            instead of ``mimetype``. This change was made for\n            consistency with :class:`werkzeug.FileWrapper`.\n\n        .. versionchanged:: 0.5\n            Added the ``follow_redirects`` parameter.\n        \"\"\"\n        request: Request | None = None\n\n        if not kwargs and len(args) == 1:\n            arg = args[0]\n\n            if isinstance(arg, EnvironBuilder):\n                request = arg.get_request()\n            elif isinstance(arg, dict):\n                request = EnvironBuilder.from_environ(arg).get_request()\n            elif isinstance(arg, Request):\n                request = arg\n\n        if request is None:\n            builder = EnvironBuilder(*args, **kwargs)\n\n            try:\n                request = builder.get_request()\n            finally:\n                builder.close()\n\n        response_parts = self.run_wsgi_app(request.environ, buffered=buffered)\n        response = self.response_wrapper(*response_parts, request=request)\n\n        redirects = set()\n        history: list[TestResponse] = []\n\n        if not follow_redirects:\n            return response\n\n        while response.status_code in {\n            301,\n            302,\n            303,\n            305,\n            307,\n            308,\n        }:\n            # Exhaust intermediate response bodies to ensure middleware\n            # that returns an iterator runs any cleanup code.\n            if not buffered:\n                response.make_sequence()\n                response.close()\n\n            new_redirect_entry = (response.location, response.status_code)\n\n            if new_redirect_entry in redirects:\n                raise ClientRedirectError(\n                    f\"Loop detected: A {response.status_code} redirect\"\n                    f\" to {response.location} was already made.\"\n                )\n\n            redirects.add(new_redirect_entry)\n            response.history = tuple(history)\n            history.append(response)\n            response = self.resolve_redirect(response, buffered=buffered)\n        else:\n            # This is the final request after redirects.\n            response.history = tuple(history)\n            # Close the input stream when closing the response, in case\n            # the input is an open temporary file.\n            response.call_on_close(request.input_stream.close)\n            return response\n\n    def get(self, *args: t.Any, **kw: t.Any) -> TestResponse:\n        \"\"\"Call :meth:`open` with ``method`` set to ``GET``.\"\"\"\n        kw[\"method\"] = \"GET\"\n        return self.open(*args, **kw)\n\n    def post(self, *args: t.Any, **kw: t.Any) -> TestResponse:\n        \"\"\"Call :meth:`open` with ``method`` set to ``POST``.\"\"\"\n        kw[\"method\"] = \"POST\"\n        return self.open(*args, **kw)\n\n    def put(self, *args: t.Any, **kw: t.Any) -> TestResponse:\n        \"\"\"Call :meth:`open` with ``method`` set to ``PUT``.\"\"\"\n        kw[\"method\"] = \"PUT\"\n        return self.open(*args, **kw)\n\n    def delete(self, *args: t.Any, **kw: t.Any) -> TestResponse:\n        \"\"\"Call :meth:`open` with ``method`` set to ``DELETE``.\"\"\"\n        kw[\"method\"] = \"DELETE\"\n        return self.open(*args, **kw)\n\n    def patch(self, *args: t.Any, **kw: t.Any) -> TestResponse:\n        \"\"\"Call :meth:`open` with ``method`` set to ``PATCH``.\"\"\"\n        kw[\"method\"] = \"PATCH\"\n        return self.open(*args, **kw)\n\n    def options(self, *args: t.Any, **kw: t.Any) -> TestResponse:\n        \"\"\"Call :meth:`open` with ``method`` set to ``OPTIONS``.\"\"\"\n        kw[\"method\"] = \"OPTIONS\"\n        return self.open(*args, **kw)\n\n    def head(self, *args: t.Any, **kw: t.Any) -> TestResponse:\n        \"\"\"Call :meth:`open` with ``method`` set to ``HEAD``.\"\"\"\n        kw[\"method\"] = \"HEAD\"\n        return self.open(*args, **kw)\n\n    def trace(self, *args: t.Any, **kw: t.Any) -> TestResponse:\n        \"\"\"Call :meth:`open` with ``method`` set to ``TRACE``.\"\"\"\n        kw[\"method\"] = \"TRACE\"\n        return self.open(*args, **kw)\n\n    def __repr__(self) -> str:\n        return f\"<{type(self).__name__} {self.application!r}>\"\n\n\ndef create_environ(*args: t.Any, **kwargs: t.Any) -> WSGIEnvironment:\n    \"\"\"Create a new WSGI environ dict based on the values passed.  The first\n    parameter should be the path of the request which defaults to '/'.  The\n    second one can either be an absolute path (in that case the host is\n    localhost:80) or a full path to the request with scheme, netloc port and\n    the path to the script.\n\n    This accepts the same arguments as the :class:`EnvironBuilder`\n    constructor.\n\n    .. versionchanged:: 0.5\n       This function is now a thin wrapper over :class:`EnvironBuilder` which\n       was added in 0.5.  The `headers`, `environ_base`, `environ_overrides`\n       and `charset` parameters were added.\n    \"\"\"\n    builder = EnvironBuilder(*args, **kwargs)\n\n    try:\n        return builder.get_environ()\n    finally:\n        builder.close()\n\n\ndef run_wsgi_app(\n    app: WSGIApplication, environ: WSGIEnvironment, buffered: bool = False\n) -> tuple[t.Iterable[bytes], str, Headers]:\n    \"\"\"Return a tuple in the form (app_iter, status, headers) of the\n    application output.  This works best if you pass it an application that\n    returns an iterator all the time.\n\n    Sometimes applications may use the `write()` callable returned\n    by the `start_response` function.  This tries to resolve such edge\n    cases automatically.  But if you don't get the expected output you\n    should set `buffered` to `True` which enforces buffering.\n\n    If passed an invalid WSGI application the behavior of this function is\n    undefined.  Never pass non-conforming WSGI applications to this function.\n\n    :param app: the application to execute.\n    :param buffered: set to `True` to enforce buffering.\n    :return: tuple in the form ``(app_iter, status, headers)``\n    \"\"\"\n    # Copy environ to ensure any mutations by the app (ProxyFix, for\n    # example) don't affect subsequent requests (such as redirects).\n    environ = _get_environ(environ).copy()\n    status: str\n    response: tuple[str, list[tuple[str, str]]] | None = None\n    buffer: list[bytes] = []\n\n    def start_response(status, headers, exc_info=None):  # type: ignore\n        nonlocal response\n\n        if exc_info:\n            try:\n                raise exc_info[1].with_traceback(exc_info[2])\n            finally:\n                exc_info = None\n\n        response = (status, headers)\n        return buffer.append\n\n    app_rv = app(environ, start_response)\n    close_func = getattr(app_rv, \"close\", None)\n    app_iter: t.Iterable[bytes] = iter(app_rv)\n\n    # when buffering we emit the close call early and convert the\n    # application iterator into a regular list\n    if buffered:\n        try:\n            app_iter = list(app_iter)\n        finally:\n            if close_func is not None:\n                close_func()\n\n    # otherwise we iterate the application iter until we have a response, chain\n    # the already received data with the already collected data and wrap it in\n    # a new `ClosingIterator` if we need to restore a `close` callable from the\n    # original return value.\n    else:\n        for item in app_iter:\n            buffer.append(item)\n\n            if response is not None:\n                break\n\n        if buffer:\n            app_iter = chain(buffer, app_iter)\n\n        if close_func is not None and app_iter is not app_rv:\n            app_iter = ClosingIterator(app_iter, close_func)\n\n    status, headers = response  # type: ignore\n    return app_iter, status, Headers(headers)\n\n\nclass TestResponse(Response):\n    \"\"\":class:`~werkzeug.wrappers.Response` subclass that provides extra\n    information about requests made with the test :class:`Client`.\n\n    Test client requests will always return an instance of this class.\n    If a custom response class is passed to the client, it is\n    subclassed along with this to support test information.\n\n    If the test request included large files, or if the application is\n    serving a file, call :meth:`close` to close any open files and\n    prevent Python showing a ``ResourceWarning``.\n\n    .. versionchanged:: 2.2\n        Set the ``default_mimetype`` to None to prevent a mimetype being\n        assumed if missing.\n\n    .. versionchanged:: 2.1\n        Response instances cannot be treated as tuples.\n\n    .. versionadded:: 2.0\n        Test client methods always return instances of this class.\n    \"\"\"\n\n    default_mimetype = None\n    # Don't assume a mimetype, instead use whatever the response provides\n\n    request: Request\n    \"\"\"A request object with the environ used to make the request that\n    resulted in this response.\n    \"\"\"\n\n    history: tuple[TestResponse, ...]\n    \"\"\"A list of intermediate responses. Populated when the test request\n    is made with ``follow_redirects`` enabled.\n    \"\"\"\n\n    # Tell Pytest to ignore this, it's not a test class.\n    __test__ = False\n\n    def __init__(\n        self,\n        response: t.Iterable[bytes],\n        status: str,\n        headers: Headers,\n        request: Request,\n        history: tuple[TestResponse] = (),  # type: ignore\n        **kwargs: t.Any,\n    ) -> None:\n        super().__init__(response, status, headers, **kwargs)\n        self.request = request\n        self.history = history\n        self._compat_tuple = response, status, headers\n\n    @cached_property\n    def text(self) -> str:\n        \"\"\"The response data as text. A shortcut for\n        ``response.get_data(as_text=True)``.\n\n        .. versionadded:: 2.1\n        \"\"\"\n        return self.get_data(as_text=True)\n\n\n@dataclasses.dataclass\nclass Cookie:\n    \"\"\"A cookie key, value, and parameters.\n\n    The class itself is not a public API. Its attributes are documented for inspection\n    with :meth:`.Client.get_cookie` only.\n\n    .. versionadded:: 2.3\n    \"\"\"\n\n    key: str\n    \"\"\"The cookie key, encoded as a client would see it.\"\"\"\n\n    value: str\n    \"\"\"The cookie key, encoded as a client would see it.\"\"\"\n\n    decoded_key: str\n    \"\"\"The cookie key, decoded as the application would set and see it.\"\"\"\n\n    decoded_value: str\n    \"\"\"The cookie value, decoded as the application would set and see it.\"\"\"\n\n    expires: datetime | None\n    \"\"\"The time at which the cookie is no longer valid.\"\"\"\n\n    max_age: int | None\n    \"\"\"The number of seconds from when the cookie was set at which it is\n    no longer valid.\n    \"\"\"\n\n    domain: str\n    \"\"\"The domain that the cookie was set for, or the request domain if not set.\"\"\"\n\n    origin_only: bool\n    \"\"\"Whether the cookie will be sent for exact domain matches only. This is ``True``\n    if the ``Domain`` parameter was not present.\n    \"\"\"\n\n    path: str\n    \"\"\"The path that the cookie was set for.\"\"\"\n\n    secure: bool | None\n    \"\"\"The ``Secure`` parameter.\"\"\"\n\n    http_only: bool | None\n    \"\"\"The ``HttpOnly`` parameter.\"\"\"\n\n    same_site: str | None\n    \"\"\"The ``SameSite`` parameter.\"\"\"\n\n    def _matches_request(self, server_name: str, path: str) -> bool:\n        return (\n            server_name == self.domain\n            or (\n                not self.origin_only\n                and server_name.endswith(self.domain)\n                and server_name[: -len(self.domain)].endswith(\".\")\n            )\n        ) and (\n            path == self.path\n            or (\n                path.startswith(self.path)\n                and path[len(self.path) - self.path.endswith(\"/\") :].startswith(\"/\")\n            )\n        )\n\n    def _to_request_header(self) -> str:\n        return f\"{self.key}={self.value}\"\n\n    @classmethod\n    def _from_response_header(cls, server_name: str, path: str, header: str) -> te.Self:\n        header, _, parameters_str = header.partition(\";\")\n        key, _, value = header.partition(\"=\")\n        decoded_key, decoded_value = next(parse_cookie(header).items())\n        params = {}\n\n        for item in parameters_str.split(\";\"):\n            k, sep, v = item.partition(\"=\")\n            params[k.strip().lower()] = v.strip() if sep else None\n\n        return cls(\n            key=key.strip(),\n            value=value.strip(),\n            decoded_key=decoded_key,\n            decoded_value=decoded_value,\n            expires=parse_date(params.get(\"expires\")),\n            max_age=int(params[\"max-age\"] or 0) if \"max-age\" in params else None,\n            domain=params.get(\"domain\") or server_name,\n            origin_only=\"domain\" not in params,\n            path=params.get(\"path\") or path.rpartition(\"/\")[0] or \"/\",\n            secure=\"secure\" in params,\n            http_only=\"httponly\" in params,\n            same_site=params.get(\"samesite\"),\n        )\n\n    @property\n    def _storage_key(self) -> tuple[str, str, str]:\n        return self.domain, self.path, self.decoded_key\n\n    @property\n    def _should_delete(self) -> bool:\n        return self.max_age == 0 or (\n            self.expires is not None and self.expires.timestamp() == 0\n        )\n", "src/werkzeug/user_agent.py": "from __future__ import annotations\n\n\nclass UserAgent:\n    \"\"\"Represents a parsed user agent header value.\n\n    The default implementation does no parsing, only the :attr:`string`\n    attribute is set. A subclass may parse the string to set the\n    common attributes or expose other information. Set\n    :attr:`werkzeug.wrappers.Request.user_agent_class` to use a\n    subclass.\n\n    :param string: The header value to parse.\n\n    .. versionadded:: 2.0\n        This replaces the previous ``useragents`` module, but does not\n        provide a built-in parser.\n    \"\"\"\n\n    platform: str | None = None\n    \"\"\"The OS name, if it could be parsed from the string.\"\"\"\n\n    browser: str | None = None\n    \"\"\"The browser name, if it could be parsed from the string.\"\"\"\n\n    version: str | None = None\n    \"\"\"The browser version, if it could be parsed from the string.\"\"\"\n\n    language: str | None = None\n    \"\"\"The browser language, if it could be parsed from the string.\"\"\"\n\n    def __init__(self, string: str) -> None:\n        self.string: str = string\n        \"\"\"The original header value.\"\"\"\n\n    def __repr__(self) -> str:\n        return f\"<{type(self).__name__} {self.browser}/{self.version}>\"\n\n    def __str__(self) -> str:\n        return self.string\n\n    def __bool__(self) -> bool:\n        return bool(self.browser)\n\n    def to_header(self) -> str:\n        \"\"\"Convert to a header value.\"\"\"\n        return self.string\n", "src/werkzeug/debug/tbtools.py": "from __future__ import annotations\n\nimport itertools\nimport linecache\nimport os\nimport re\nimport sys\nimport sysconfig\nimport traceback\nimport typing as t\n\nfrom markupsafe import escape\n\nfrom ..utils import cached_property\nfrom .console import Console\n\nHEADER = \"\"\"\\\n<!doctype html>\n<html lang=en>\n  <head>\n    <title>%(title)s // Werkzeug Debugger</title>\n    <link rel=\"stylesheet\" href=\"?__debugger__=yes&amp;cmd=resource&amp;f=style.css\">\n    <link rel=\"shortcut icon\"\n        href=\"?__debugger__=yes&amp;cmd=resource&amp;f=console.png\">\n    <script src=\"?__debugger__=yes&amp;cmd=resource&amp;f=debugger.js\"></script>\n    <script>\n      var CONSOLE_MODE = %(console)s,\n          EVALEX = %(evalex)s,\n          EVALEX_TRUSTED = %(evalex_trusted)s,\n          SECRET = \"%(secret)s\";\n    </script>\n  </head>\n  <body style=\"background-color: #fff\">\n    <div class=\"debugger\">\n\"\"\"\n\nFOOTER = \"\"\"\\\n      <div class=\"footer\">\n        Brought to you by <strong class=\"arthur\">DON'T PANIC</strong>, your\n        friendly Werkzeug powered traceback interpreter.\n      </div>\n    </div>\n\n    <div class=\"pin-prompt\">\n      <div class=\"inner\">\n        <h3>Console Locked</h3>\n        <p>\n          The console is locked and needs to be unlocked by entering the PIN.\n          You can find the PIN printed out on the standard output of your\n          shell that runs the server.\n        <form>\n          <p>PIN:\n            <input type=text name=pin size=14>\n            <input type=submit name=btn value=\"Confirm Pin\">\n        </form>\n      </div>\n    </div>\n  </body>\n</html>\n\"\"\"\n\nPAGE_HTML = (\n    HEADER\n    + \"\"\"\\\n<h1>%(exception_type)s</h1>\n<div class=\"detail\">\n  <p class=\"errormsg\">%(exception)s</p>\n</div>\n<h2 class=\"traceback\">Traceback <em>(most recent call last)</em></h2>\n%(summary)s\n<div class=\"plain\">\n    <p>\n      This is the Copy/Paste friendly version of the traceback.\n    </p>\n    <textarea cols=\"50\" rows=\"10\" name=\"code\" readonly>%(plaintext)s</textarea>\n</div>\n<div class=\"explanation\">\n  The debugger caught an exception in your WSGI application.  You can now\n  look at the traceback which led to the error.  <span class=\"nojavascript\">\n  If you enable JavaScript you can also use additional features such as code\n  execution (if the evalex feature is enabled), automatic pasting of the\n  exceptions and much more.</span>\n</div>\n\"\"\"\n    + FOOTER\n    + \"\"\"\n<!--\n\n%(plaintext_cs)s\n\n-->\n\"\"\"\n)\n\nCONSOLE_HTML = (\n    HEADER\n    + \"\"\"\\\n<h1>Interactive Console</h1>\n<div class=\"explanation\">\nIn this console you can execute Python expressions in the context of the\napplication.  The initial namespace was created by the debugger automatically.\n</div>\n<div class=\"console\"><div class=\"inner\">The Console requires JavaScript.</div></div>\n\"\"\"\n    + FOOTER\n)\n\nSUMMARY_HTML = \"\"\"\\\n<div class=\"%(classes)s\">\n  %(title)s\n  <ul>%(frames)s</ul>\n  %(description)s\n</div>\n\"\"\"\n\nFRAME_HTML = \"\"\"\\\n<div class=\"frame\" id=\"frame-%(id)d\">\n  <h4>File <cite class=\"filename\">\"%(filename)s\"</cite>,\n      line <em class=\"line\">%(lineno)s</em>,\n      in <code class=\"function\">%(function_name)s</code></h4>\n  <div class=\"source %(library)s\">%(lines)s</div>\n</div>\n\"\"\"\n\n\ndef _process_traceback(\n    exc: BaseException,\n    te: traceback.TracebackException | None = None,\n    *,\n    skip: int = 0,\n    hide: bool = True,\n) -> traceback.TracebackException:\n    if te is None:\n        te = traceback.TracebackException.from_exception(exc, lookup_lines=False)\n\n    # Get the frames the same way StackSummary.extract did, in order\n    # to match each frame with the FrameSummary to augment.\n    frame_gen = traceback.walk_tb(exc.__traceback__)\n    limit = getattr(sys, \"tracebacklimit\", None)\n\n    if limit is not None:\n        if limit < 0:\n            limit = 0\n\n        frame_gen = itertools.islice(frame_gen, limit)\n\n    if skip:\n        frame_gen = itertools.islice(frame_gen, skip, None)\n        del te.stack[:skip]\n\n    new_stack: list[DebugFrameSummary] = []\n    hidden = False\n\n    # Match each frame with the FrameSummary that was generated.\n    # Hide frames using Paste's __traceback_hide__ rules. Replace\n    # all visible FrameSummary with DebugFrameSummary.\n    for (f, _), fs in zip(frame_gen, te.stack):\n        if hide:\n            hide_value = f.f_locals.get(\"__traceback_hide__\", False)\n\n            if hide_value in {\"before\", \"before_and_this\"}:\n                new_stack = []\n                hidden = False\n\n                if hide_value == \"before_and_this\":\n                    continue\n            elif hide_value in {\"reset\", \"reset_and_this\"}:\n                hidden = False\n\n                if hide_value == \"reset_and_this\":\n                    continue\n            elif hide_value in {\"after\", \"after_and_this\"}:\n                hidden = True\n\n                if hide_value == \"after_and_this\":\n                    continue\n            elif hide_value or hidden:\n                continue\n\n        frame_args: dict[str, t.Any] = {\n            \"filename\": fs.filename,\n            \"lineno\": fs.lineno,\n            \"name\": fs.name,\n            \"locals\": f.f_locals,\n            \"globals\": f.f_globals,\n        }\n\n        if hasattr(fs, \"colno\"):\n            frame_args[\"colno\"] = fs.colno\n            frame_args[\"end_colno\"] = fs.end_colno\n\n        new_stack.append(DebugFrameSummary(**frame_args))\n\n    # The codeop module is used to compile code from the interactive\n    # debugger. Hide any codeop frames from the bottom of the traceback.\n    while new_stack:\n        module = new_stack[0].global_ns.get(\"__name__\")\n\n        if module is None:\n            module = new_stack[0].local_ns.get(\"__name__\")\n\n        if module == \"codeop\":\n            del new_stack[0]\n        else:\n            break\n\n    te.stack[:] = new_stack\n\n    if te.__context__:\n        context_exc = t.cast(BaseException, exc.__context__)\n        te.__context__ = _process_traceback(context_exc, te.__context__, hide=hide)\n\n    if te.__cause__:\n        cause_exc = t.cast(BaseException, exc.__cause__)\n        te.__cause__ = _process_traceback(cause_exc, te.__cause__, hide=hide)\n\n    return te\n\n\nclass DebugTraceback:\n    __slots__ = (\"_te\", \"_cache_all_tracebacks\", \"_cache_all_frames\")\n\n    def __init__(\n        self,\n        exc: BaseException,\n        te: traceback.TracebackException | None = None,\n        *,\n        skip: int = 0,\n        hide: bool = True,\n    ) -> None:\n        self._te = _process_traceback(exc, te, skip=skip, hide=hide)\n\n    def __str__(self) -> str:\n        return f\"<{type(self).__name__} {self._te}>\"\n\n    @cached_property\n    def all_tracebacks(\n        self,\n    ) -> list[tuple[str | None, traceback.TracebackException]]:\n        out = []\n        current = self._te\n\n        while current is not None:\n            if current.__cause__ is not None:\n                chained_msg = (\n                    \"The above exception was the direct cause of the\"\n                    \" following exception\"\n                )\n                chained_exc = current.__cause__\n            elif current.__context__ is not None and not current.__suppress_context__:\n                chained_msg = (\n                    \"During handling of the above exception, another\"\n                    \" exception occurred\"\n                )\n                chained_exc = current.__context__\n            else:\n                chained_msg = None\n                chained_exc = None\n\n            out.append((chained_msg, current))\n            current = chained_exc\n\n        return out\n\n    @cached_property\n    def all_frames(self) -> list[DebugFrameSummary]:\n        return [\n            f  # type: ignore[misc]\n            for _, te in self.all_tracebacks\n            for f in te.stack\n        ]\n\n    def render_traceback_text(self) -> str:\n        return \"\".join(self._te.format())\n\n    def render_traceback_html(self, include_title: bool = True) -> str:\n        library_frames = [f.is_library for f in self.all_frames]\n        mark_library = 0 < sum(library_frames) < len(library_frames)\n        rows = []\n\n        if not library_frames:\n            classes = \"traceback noframe-traceback\"\n        else:\n            classes = \"traceback\"\n\n            for msg, current in reversed(self.all_tracebacks):\n                row_parts = []\n\n                if msg is not None:\n                    row_parts.append(f'<li><div class=\"exc-divider\">{msg}:</div>')\n\n                for frame in current.stack:\n                    frame = t.cast(DebugFrameSummary, frame)\n                    info = f' title=\"{escape(frame.info)}\"' if frame.info else \"\"\n                    row_parts.append(f\"<li{info}>{frame.render_html(mark_library)}\")\n\n                rows.append(\"\\n\".join(row_parts))\n\n        if sys.version_info < (3, 13):\n            exc_type_str = self._te.exc_type.__name__\n        else:\n            exc_type_str = self._te.exc_type_str\n\n        is_syntax_error = exc_type_str == \"SyntaxError\"\n\n        if include_title:\n            if is_syntax_error:\n                title = \"Syntax Error\"\n            else:\n                title = \"Traceback <em>(most recent call last)</em>:\"\n        else:\n            title = \"\"\n\n        exc_full = escape(\"\".join(self._te.format_exception_only()))\n\n        if is_syntax_error:\n            description = f\"<pre class=syntaxerror>{exc_full}</pre>\"\n        else:\n            description = f\"<blockquote>{exc_full}</blockquote>\"\n\n        return SUMMARY_HTML % {\n            \"classes\": classes,\n            \"title\": f\"<h3>{title}</h3>\",\n            \"frames\": \"\\n\".join(rows),\n            \"description\": description,\n        }\n\n    def render_debugger_html(\n        self, evalex: bool, secret: str, evalex_trusted: bool\n    ) -> str:\n        exc_lines = list(self._te.format_exception_only())\n        plaintext = \"\".join(self._te.format())\n\n        if sys.version_info < (3, 13):\n            exc_type_str = self._te.exc_type.__name__\n        else:\n            exc_type_str = self._te.exc_type_str\n\n        return PAGE_HTML % {\n            \"evalex\": \"true\" if evalex else \"false\",\n            \"evalex_trusted\": \"true\" if evalex_trusted else \"false\",\n            \"console\": \"false\",\n            \"title\": escape(exc_lines[0]),\n            \"exception\": escape(\"\".join(exc_lines)),\n            \"exception_type\": escape(exc_type_str),\n            \"summary\": self.render_traceback_html(include_title=False),\n            \"plaintext\": escape(plaintext),\n            \"plaintext_cs\": re.sub(\"-{2,}\", \"-\", plaintext),\n            \"secret\": secret,\n        }\n\n\nclass DebugFrameSummary(traceback.FrameSummary):\n    \"\"\"A :class:`traceback.FrameSummary` that can evaluate code in the\n    frame's namespace.\n    \"\"\"\n\n    __slots__ = (\n        \"local_ns\",\n        \"global_ns\",\n        \"_cache_info\",\n        \"_cache_is_library\",\n        \"_cache_console\",\n    )\n\n    def __init__(\n        self,\n        *,\n        locals: dict[str, t.Any],\n        globals: dict[str, t.Any],\n        **kwargs: t.Any,\n    ) -> None:\n        super().__init__(locals=None, **kwargs)\n        self.local_ns = locals\n        self.global_ns = globals\n\n    @cached_property\n    def info(self) -> str | None:\n        return self.local_ns.get(\"__traceback_info__\")\n\n    @cached_property\n    def is_library(self) -> bool:\n        return any(\n            self.filename.startswith((path, os.path.realpath(path)))\n            for path in sysconfig.get_paths().values()\n        )\n\n    @cached_property\n    def console(self) -> Console:\n        return Console(self.global_ns, self.local_ns)\n\n    def eval(self, code: str) -> t.Any:\n        return self.console.eval(code)\n\n    def render_html(self, mark_library: bool) -> str:\n        context = 5\n        lines = linecache.getlines(self.filename)\n        line_idx = self.lineno - 1  # type: ignore[operator]\n        start_idx = max(0, line_idx - context)\n        stop_idx = min(len(lines), line_idx + context + 1)\n        rendered_lines = []\n\n        def render_line(line: str, cls: str) -> None:\n            line = line.expandtabs().rstrip()\n            stripped_line = line.strip()\n            prefix = len(line) - len(stripped_line)\n            colno = getattr(self, \"colno\", 0)\n            end_colno = getattr(self, \"end_colno\", 0)\n\n            if cls == \"current\" and colno and end_colno:\n                arrow = (\n                    f'\\n<span class=\"ws\">{\" \" * prefix}</span>'\n                    f'{\" \" * (colno - prefix)}{\"^\" * (end_colno - colno)}'\n                )\n            else:\n                arrow = \"\"\n\n            rendered_lines.append(\n                f'<pre class=\"line {cls}\"><span class=\"ws\">{\" \" * prefix}</span>'\n                f\"{escape(stripped_line) if stripped_line else ' '}\"\n                f\"{arrow if arrow else ''}</pre>\"\n            )\n\n        if lines:\n            for line in lines[start_idx:line_idx]:\n                render_line(line, \"before\")\n\n            render_line(lines[line_idx], \"current\")\n\n            for line in lines[line_idx + 1 : stop_idx]:\n                render_line(line, \"after\")\n\n        return FRAME_HTML % {\n            \"id\": id(self),\n            \"filename\": escape(self.filename),\n            \"lineno\": self.lineno,\n            \"function_name\": escape(self.name),\n            \"lines\": \"\\n\".join(rendered_lines),\n            \"library\": \"library\" if mark_library and self.is_library else \"\",\n        }\n\n\ndef render_console_html(secret: str, evalex_trusted: bool) -> str:\n    return CONSOLE_HTML % {\n        \"evalex\": \"true\",\n        \"evalex_trusted\": \"true\" if evalex_trusted else \"false\",\n        \"console\": \"true\",\n        \"title\": \"Console\",\n        \"secret\": secret,\n    }\n", "src/werkzeug/debug/repr.py": "\"\"\"Object representations for debugging purposes. Unlike the default\nrepr, these expose more information and produce HTML instead of ASCII.\n\nTogether with the CSS and JavaScript of the debugger this gives a\ncolorful and more compact output.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport codecs\nimport re\nimport sys\nimport typing as t\nfrom collections import deque\nfrom traceback import format_exception_only\n\nfrom markupsafe import escape\n\nmissing = object()\n_paragraph_re = re.compile(r\"(?:\\r\\n|\\r|\\n){2,}\")\nRegexType = type(_paragraph_re)\n\nHELP_HTML = \"\"\"\\\n<div class=box>\n  <h3>%(title)s</h3>\n  <pre class=help>%(text)s</pre>\n</div>\\\n\"\"\"\nOBJECT_DUMP_HTML = \"\"\"\\\n<div class=box>\n  <h3>%(title)s</h3>\n  %(repr)s\n  <table>%(items)s</table>\n</div>\\\n\"\"\"\n\n\ndef debug_repr(obj: object) -> str:\n    \"\"\"Creates a debug repr of an object as HTML string.\"\"\"\n    return DebugReprGenerator().repr(obj)\n\n\ndef dump(obj: object = missing) -> None:\n    \"\"\"Print the object details to stdout._write (for the interactive\n    console of the web debugger.\n    \"\"\"\n    gen = DebugReprGenerator()\n    if obj is missing:\n        rv = gen.dump_locals(sys._getframe(1).f_locals)\n    else:\n        rv = gen.dump_object(obj)\n    sys.stdout._write(rv)  # type: ignore\n\n\nclass _Helper:\n    \"\"\"Displays an HTML version of the normal help, for the interactive\n    debugger only because it requires a patched sys.stdout.\n    \"\"\"\n\n    def __repr__(self) -> str:\n        return \"Type help(object) for help about object.\"\n\n    def __call__(self, topic: t.Any | None = None) -> None:\n        if topic is None:\n            sys.stdout._write(f\"<span class=help>{self!r}</span>\")  # type: ignore\n            return\n        import pydoc\n\n        pydoc.help(topic)\n        rv = sys.stdout.reset()  # type: ignore\n        paragraphs = _paragraph_re.split(rv)\n        if len(paragraphs) > 1:\n            title = paragraphs[0]\n            text = \"\\n\\n\".join(paragraphs[1:])\n        else:\n            title = \"Help\"\n            text = paragraphs[0]\n        sys.stdout._write(HELP_HTML % {\"title\": title, \"text\": text})  # type: ignore\n\n\nhelper = _Helper()\n\n\ndef _add_subclass_info(inner: str, obj: object, base: type | tuple[type, ...]) -> str:\n    if isinstance(base, tuple):\n        for cls in base:\n            if type(obj) is cls:\n                return inner\n    elif type(obj) is base:\n        return inner\n    module = \"\"\n    if obj.__class__.__module__ not in (\"__builtin__\", \"exceptions\"):\n        module = f'<span class=\"module\">{obj.__class__.__module__}.</span>'\n    return f\"{module}{type(obj).__name__}({inner})\"\n\n\ndef _sequence_repr_maker(\n    left: str, right: str, base: type, limit: int = 8\n) -> t.Callable[[DebugReprGenerator, t.Iterable[t.Any], bool], str]:\n    def proxy(self: DebugReprGenerator, obj: t.Iterable[t.Any], recursive: bool) -> str:\n        if recursive:\n            return _add_subclass_info(f\"{left}...{right}\", obj, base)\n        buf = [left]\n        have_extended_section = False\n        for idx, item in enumerate(obj):\n            if idx:\n                buf.append(\", \")\n            if idx == limit:\n                buf.append('<span class=\"extended\">')\n                have_extended_section = True\n            buf.append(self.repr(item))\n        if have_extended_section:\n            buf.append(\"</span>\")\n        buf.append(right)\n        return _add_subclass_info(\"\".join(buf), obj, base)\n\n    return proxy\n\n\nclass DebugReprGenerator:\n    def __init__(self) -> None:\n        self._stack: list[t.Any] = []\n\n    list_repr = _sequence_repr_maker(\"[\", \"]\", list)\n    tuple_repr = _sequence_repr_maker(\"(\", \")\", tuple)\n    set_repr = _sequence_repr_maker(\"set([\", \"])\", set)\n    frozenset_repr = _sequence_repr_maker(\"frozenset([\", \"])\", frozenset)\n    deque_repr = _sequence_repr_maker(\n        '<span class=\"module\">collections.</span>deque([', \"])\", deque\n    )\n\n    def regex_repr(self, obj: t.Pattern[t.AnyStr]) -> str:\n        pattern = repr(obj.pattern)\n        pattern = codecs.decode(pattern, \"unicode-escape\", \"ignore\")\n        pattern = f\"r{pattern}\"\n        return f're.compile(<span class=\"string regex\">{pattern}</span>)'\n\n    def string_repr(self, obj: str | bytes, limit: int = 70) -> str:\n        buf = ['<span class=\"string\">']\n        r = repr(obj)\n\n        # shorten the repr when the hidden part would be at least 3 chars\n        if len(r) - limit > 2:\n            buf.extend(\n                (\n                    escape(r[:limit]),\n                    '<span class=\"extended\">',\n                    escape(r[limit:]),\n                    \"</span>\",\n                )\n            )\n        else:\n            buf.append(escape(r))\n\n        buf.append(\"</span>\")\n        out = \"\".join(buf)\n\n        # if the repr looks like a standard string, add subclass info if needed\n        if r[0] in \"'\\\"\" or (r[0] == \"b\" and r[1] in \"'\\\"\"):\n            return _add_subclass_info(out, obj, (bytes, str))\n\n        # otherwise, assume the repr distinguishes the subclass already\n        return out\n\n    def dict_repr(\n        self,\n        d: dict[int, None] | dict[str, int] | dict[str | int, int],\n        recursive: bool,\n        limit: int = 5,\n    ) -> str:\n        if recursive:\n            return _add_subclass_info(\"{...}\", d, dict)\n        buf = [\"{\"]\n        have_extended_section = False\n        for idx, (key, value) in enumerate(d.items()):\n            if idx:\n                buf.append(\", \")\n            if idx == limit - 1:\n                buf.append('<span class=\"extended\">')\n                have_extended_section = True\n            buf.append(\n                f'<span class=\"pair\"><span class=\"key\">{self.repr(key)}</span>:'\n                f' <span class=\"value\">{self.repr(value)}</span></span>'\n            )\n        if have_extended_section:\n            buf.append(\"</span>\")\n        buf.append(\"}\")\n        return _add_subclass_info(\"\".join(buf), d, dict)\n\n    def object_repr(self, obj: t.Any) -> str:\n        r = repr(obj)\n        return f'<span class=\"object\">{escape(r)}</span>'\n\n    def dispatch_repr(self, obj: t.Any, recursive: bool) -> str:\n        if obj is helper:\n            return f'<span class=\"help\">{helper!r}</span>'\n        if isinstance(obj, (int, float, complex)):\n            return f'<span class=\"number\">{obj!r}</span>'\n        if isinstance(obj, str) or isinstance(obj, bytes):\n            return self.string_repr(obj)\n        if isinstance(obj, RegexType):\n            return self.regex_repr(obj)\n        if isinstance(obj, list):\n            return self.list_repr(obj, recursive)\n        if isinstance(obj, tuple):\n            return self.tuple_repr(obj, recursive)\n        if isinstance(obj, set):\n            return self.set_repr(obj, recursive)\n        if isinstance(obj, frozenset):\n            return self.frozenset_repr(obj, recursive)\n        if isinstance(obj, dict):\n            return self.dict_repr(obj, recursive)\n        if isinstance(obj, deque):\n            return self.deque_repr(obj, recursive)\n        return self.object_repr(obj)\n\n    def fallback_repr(self) -> str:\n        try:\n            info = \"\".join(format_exception_only(*sys.exc_info()[:2]))\n        except Exception:\n            info = \"?\"\n        return (\n            '<span class=\"brokenrepr\">'\n            f\"&lt;broken repr ({escape(info.strip())})&gt;</span>\"\n        )\n\n    def repr(self, obj: object) -> str:\n        recursive = False\n        for item in self._stack:\n            if item is obj:\n                recursive = True\n                break\n        self._stack.append(obj)\n        try:\n            try:\n                return self.dispatch_repr(obj, recursive)\n            except Exception:\n                return self.fallback_repr()\n        finally:\n            self._stack.pop()\n\n    def dump_object(self, obj: object) -> str:\n        repr = None\n        items: list[tuple[str, str]] | None = None\n\n        if isinstance(obj, dict):\n            title = \"Contents of\"\n            items = []\n            for key, value in obj.items():\n                if not isinstance(key, str):\n                    items = None\n                    break\n                items.append((key, self.repr(value)))\n        if items is None:\n            items = []\n            repr = self.repr(obj)\n            for key in dir(obj):\n                try:\n                    items.append((key, self.repr(getattr(obj, key))))\n                except Exception:\n                    pass\n            title = \"Details for\"\n        title += f\" {object.__repr__(obj)[1:-1]}\"\n        return self.render_object_dump(items, title, repr)\n\n    def dump_locals(self, d: dict[str, t.Any]) -> str:\n        items = [(key, self.repr(value)) for key, value in d.items()]\n        return self.render_object_dump(items, \"Local variables in frame\")\n\n    def render_object_dump(\n        self, items: list[tuple[str, str]], title: str, repr: str | None = None\n    ) -> str:\n        html_items = []\n        for key, value in items:\n            html_items.append(f\"<tr><th>{escape(key)}<td><pre class=repr>{value}</pre>\")\n        if not html_items:\n            html_items.append(\"<tr><td><em>Nothing</em>\")\n        return OBJECT_DUMP_HTML % {\n            \"title\": escape(title),\n            \"repr\": f\"<pre class=repr>{repr if repr else ''}</pre>\",\n            \"items\": \"\\n\".join(html_items),\n        }\n", "src/werkzeug/debug/console.py": "from __future__ import annotations\n\nimport code\nimport sys\nimport typing as t\nfrom contextvars import ContextVar\nfrom types import CodeType\n\nfrom markupsafe import escape\n\nfrom .repr import debug_repr\nfrom .repr import dump\nfrom .repr import helper\n\n_stream: ContextVar[HTMLStringO] = ContextVar(\"werkzeug.debug.console.stream\")\n_ipy: ContextVar[_InteractiveConsole] = ContextVar(\"werkzeug.debug.console.ipy\")\n\n\nclass HTMLStringO:\n    \"\"\"A StringO version that HTML escapes on write.\"\"\"\n\n    def __init__(self) -> None:\n        self._buffer: list[str] = []\n\n    def isatty(self) -> bool:\n        return False\n\n    def close(self) -> None:\n        pass\n\n    def flush(self) -> None:\n        pass\n\n    def seek(self, n: int, mode: int = 0) -> None:\n        pass\n\n    def readline(self) -> str:\n        if len(self._buffer) == 0:\n            return \"\"\n        ret = self._buffer[0]\n        del self._buffer[0]\n        return ret\n\n    def reset(self) -> str:\n        val = \"\".join(self._buffer)\n        del self._buffer[:]\n        return val\n\n    def _write(self, x: str) -> None:\n        self._buffer.append(x)\n\n    def write(self, x: str) -> None:\n        self._write(escape(x))\n\n    def writelines(self, x: t.Iterable[str]) -> None:\n        self._write(escape(\"\".join(x)))\n\n\nclass ThreadedStream:\n    \"\"\"Thread-local wrapper for sys.stdout for the interactive console.\"\"\"\n\n    @staticmethod\n    def push() -> None:\n        if not isinstance(sys.stdout, ThreadedStream):\n            sys.stdout = t.cast(t.TextIO, ThreadedStream())\n\n        _stream.set(HTMLStringO())\n\n    @staticmethod\n    def fetch() -> str:\n        try:\n            stream = _stream.get()\n        except LookupError:\n            return \"\"\n\n        return stream.reset()\n\n    @staticmethod\n    def displayhook(obj: object) -> None:\n        try:\n            stream = _stream.get()\n        except LookupError:\n            return _displayhook(obj)  # type: ignore\n\n        # stream._write bypasses escaping as debug_repr is\n        # already generating HTML for us.\n        if obj is not None:\n            _ipy.get().locals[\"_\"] = obj\n            stream._write(debug_repr(obj))\n\n    def __setattr__(self, name: str, value: t.Any) -> None:\n        raise AttributeError(f\"read only attribute {name}\")\n\n    def __dir__(self) -> list[str]:\n        return dir(sys.__stdout__)\n\n    def __getattribute__(self, name: str) -> t.Any:\n        try:\n            stream = _stream.get()\n        except LookupError:\n            stream = sys.__stdout__  # type: ignore[assignment]\n\n        return getattr(stream, name)\n\n    def __repr__(self) -> str:\n        return repr(sys.__stdout__)\n\n\n# add the threaded stream as display hook\n_displayhook = sys.displayhook\nsys.displayhook = ThreadedStream.displayhook\n\n\nclass _ConsoleLoader:\n    def __init__(self) -> None:\n        self._storage: dict[int, str] = {}\n\n    def register(self, code: CodeType, source: str) -> None:\n        self._storage[id(code)] = source\n        # register code objects of wrapped functions too.\n        for var in code.co_consts:\n            if isinstance(var, CodeType):\n                self._storage[id(var)] = source\n\n    def get_source_by_code(self, code: CodeType) -> str | None:\n        try:\n            return self._storage[id(code)]\n        except KeyError:\n            return None\n\n\nclass _InteractiveConsole(code.InteractiveInterpreter):\n    locals: dict[str, t.Any]\n\n    def __init__(self, globals: dict[str, t.Any], locals: dict[str, t.Any]) -> None:\n        self.loader = _ConsoleLoader()\n        locals = {\n            **globals,\n            **locals,\n            \"dump\": dump,\n            \"help\": helper,\n            \"__loader__\": self.loader,\n        }\n        super().__init__(locals)\n        original_compile = self.compile\n\n        def compile(source: str, filename: str, symbol: str) -> CodeType | None:\n            code = original_compile(source, filename, symbol)\n\n            if code is not None:\n                self.loader.register(code, source)\n\n            return code\n\n        self.compile = compile  # type: ignore[assignment]\n        self.more = False\n        self.buffer: list[str] = []\n\n    def runsource(self, source: str, **kwargs: t.Any) -> str:  # type: ignore\n        source = f\"{source.rstrip()}\\n\"\n        ThreadedStream.push()\n        prompt = \"... \" if self.more else \">>> \"\n        try:\n            source_to_eval = \"\".join(self.buffer + [source])\n            if super().runsource(source_to_eval, \"<debugger>\", \"single\"):\n                self.more = True\n                self.buffer.append(source)\n            else:\n                self.more = False\n                del self.buffer[:]\n        finally:\n            output = ThreadedStream.fetch()\n        return f\"{prompt}{escape(source)}{output}\"\n\n    def runcode(self, code: CodeType) -> None:\n        try:\n            exec(code, self.locals)\n        except Exception:\n            self.showtraceback()\n\n    def showtraceback(self) -> None:\n        from .tbtools import DebugTraceback\n\n        exc = t.cast(BaseException, sys.exc_info()[1])\n        te = DebugTraceback(exc, skip=1)\n        sys.stdout._write(te.render_traceback_html())  # type: ignore\n\n    def showsyntaxerror(self, filename: str | None = None) -> None:\n        from .tbtools import DebugTraceback\n\n        exc = t.cast(BaseException, sys.exc_info()[1])\n        te = DebugTraceback(exc, skip=4)\n        sys.stdout._write(te.render_traceback_html())  # type: ignore\n\n    def write(self, data: str) -> None:\n        sys.stdout.write(data)\n\n\nclass Console:\n    \"\"\"An interactive console.\"\"\"\n\n    def __init__(\n        self,\n        globals: dict[str, t.Any] | None = None,\n        locals: dict[str, t.Any] | None = None,\n    ) -> None:\n        if locals is None:\n            locals = {}\n        if globals is None:\n            globals = {}\n        self._ipy = _InteractiveConsole(globals, locals)\n\n    def eval(self, code: str) -> str:\n        _ipy.set(self._ipy)\n        old_sys_stdout = sys.stdout\n        try:\n            return self._ipy.runsource(code)\n        finally:\n            sys.stdout = old_sys_stdout\n", "src/werkzeug/debug/__init__.py": "from __future__ import annotations\n\nimport getpass\nimport hashlib\nimport json\nimport os\nimport pkgutil\nimport re\nimport sys\nimport time\nimport typing as t\nimport uuid\nfrom contextlib import ExitStack\nfrom io import BytesIO\nfrom itertools import chain\nfrom os.path import basename\nfrom os.path import join\nfrom zlib import adler32\n\nfrom .._internal import _log\nfrom ..exceptions import NotFound\nfrom ..exceptions import SecurityError\nfrom ..http import parse_cookie\nfrom ..sansio.utils import host_is_trusted\nfrom ..security import gen_salt\nfrom ..utils import send_file\nfrom ..wrappers.request import Request\nfrom ..wrappers.response import Response\nfrom .console import Console\nfrom .tbtools import DebugFrameSummary\nfrom .tbtools import DebugTraceback\nfrom .tbtools import render_console_html\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import StartResponse\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n\n# A week\nPIN_TIME = 60 * 60 * 24 * 7\n\n\ndef hash_pin(pin: str) -> str:\n    return hashlib.sha1(f\"{pin} added salt\".encode(\"utf-8\", \"replace\")).hexdigest()[:12]\n\n\n_machine_id: str | bytes | None = None\n\n\ndef get_machine_id() -> str | bytes | None:\n    global _machine_id\n\n    if _machine_id is not None:\n        return _machine_id\n\n    def _generate() -> str | bytes | None:\n        linux = b\"\"\n\n        # machine-id is stable across boots, boot_id is not.\n        for filename in \"/etc/machine-id\", \"/proc/sys/kernel/random/boot_id\":\n            try:\n                with open(filename, \"rb\") as f:\n                    value = f.readline().strip()\n            except OSError:\n                continue\n\n            if value:\n                linux += value\n                break\n\n        # Containers share the same machine id, add some cgroup\n        # information. This is used outside containers too but should be\n        # relatively stable across boots.\n        try:\n            with open(\"/proc/self/cgroup\", \"rb\") as f:\n                linux += f.readline().strip().rpartition(b\"/\")[2]\n        except OSError:\n            pass\n\n        if linux:\n            return linux\n\n        # On OS X, use ioreg to get the computer's serial number.\n        try:\n            # subprocess may not be available, e.g. Google App Engine\n            # https://github.com/pallets/werkzeug/issues/925\n            from subprocess import PIPE\n            from subprocess import Popen\n\n            dump = Popen(\n                [\"ioreg\", \"-c\", \"IOPlatformExpertDevice\", \"-d\", \"2\"], stdout=PIPE\n            ).communicate()[0]\n            match = re.search(b'\"serial-number\" = <([^>]+)', dump)\n\n            if match is not None:\n                return match.group(1)\n        except (OSError, ImportError):\n            pass\n\n        # On Windows, use winreg to get the machine guid.\n        if sys.platform == \"win32\":\n            import winreg\n\n            try:\n                with winreg.OpenKey(\n                    winreg.HKEY_LOCAL_MACHINE,\n                    \"SOFTWARE\\\\Microsoft\\\\Cryptography\",\n                    0,\n                    winreg.KEY_READ | winreg.KEY_WOW64_64KEY,\n                ) as rk:\n                    guid: str | bytes\n                    guid_type: int\n                    guid, guid_type = winreg.QueryValueEx(rk, \"MachineGuid\")\n\n                    if guid_type == winreg.REG_SZ:\n                        return guid.encode()\n\n                    return guid\n            except OSError:\n                pass\n\n        return None\n\n    _machine_id = _generate()\n    return _machine_id\n\n\nclass _ConsoleFrame:\n    \"\"\"Helper class so that we can reuse the frame console code for the\n    standalone console.\n    \"\"\"\n\n    def __init__(self, namespace: dict[str, t.Any]):\n        self.console = Console(namespace)\n        self.id = 0\n\n    def eval(self, code: str) -> t.Any:\n        return self.console.eval(code)\n\n\ndef get_pin_and_cookie_name(\n    app: WSGIApplication,\n) -> tuple[str, str] | tuple[None, None]:\n    \"\"\"Given an application object this returns a semi-stable 9 digit pin\n    code and a random key.  The hope is that this is stable between\n    restarts to not make debugging particularly frustrating.  If the pin\n    was forcefully disabled this returns `None`.\n\n    Second item in the resulting tuple is the cookie name for remembering.\n    \"\"\"\n    pin = os.environ.get(\"WERKZEUG_DEBUG_PIN\")\n    rv = None\n    num = None\n\n    # Pin was explicitly disabled\n    if pin == \"off\":\n        return None, None\n\n    # Pin was provided explicitly\n    if pin is not None and pin.replace(\"-\", \"\").isdecimal():\n        # If there are separators in the pin, return it directly\n        if \"-\" in pin:\n            rv = pin\n        else:\n            num = pin\n\n    modname = getattr(app, \"__module__\", t.cast(object, app).__class__.__module__)\n    username: str | None\n\n    try:\n        # getuser imports the pwd module, which does not exist in Google\n        # App Engine. It may also raise a KeyError if the UID does not\n        # have a username, such as in Docker.\n        username = getpass.getuser()\n    except (ImportError, KeyError):\n        username = None\n\n    mod = sys.modules.get(modname)\n\n    # This information only exists to make the cookie unique on the\n    # computer, not as a security feature.\n    probably_public_bits = [\n        username,\n        modname,\n        getattr(app, \"__name__\", type(app).__name__),\n        getattr(mod, \"__file__\", None),\n    ]\n\n    # This information is here to make it harder for an attacker to\n    # guess the cookie name.  They are unlikely to be contained anywhere\n    # within the unauthenticated debug page.\n    private_bits = [str(uuid.getnode()), get_machine_id()]\n\n    h = hashlib.sha1()\n    for bit in chain(probably_public_bits, private_bits):\n        if not bit:\n            continue\n        if isinstance(bit, str):\n            bit = bit.encode()\n        h.update(bit)\n    h.update(b\"cookiesalt\")\n\n    cookie_name = f\"__wzd{h.hexdigest()[:20]}\"\n\n    # If we need to generate a pin we salt it a bit more so that we don't\n    # end up with the same value and generate out 9 digits\n    if num is None:\n        h.update(b\"pinsalt\")\n        num = f\"{int(h.hexdigest(), 16):09d}\"[:9]\n\n    # Format the pincode in groups of digits for easier remembering if\n    # we don't have a result yet.\n    if rv is None:\n        for group_size in 5, 4, 3:\n            if len(num) % group_size == 0:\n                rv = \"-\".join(\n                    num[x : x + group_size].rjust(group_size, \"0\")\n                    for x in range(0, len(num), group_size)\n                )\n                break\n        else:\n            rv = num\n\n    return rv, cookie_name\n\n\nclass DebuggedApplication:\n    \"\"\"Enables debugging support for a given application::\n\n        from werkzeug.debug import DebuggedApplication\n        from myapp import app\n        app = DebuggedApplication(app, evalex=True)\n\n    The ``evalex`` argument allows evaluating expressions in any frame\n    of a traceback. This works by preserving each frame with its local\n    state. Some state, such as context globals, cannot be restored with\n    the frame by default. When ``evalex`` is enabled,\n    ``environ[\"werkzeug.debug.preserve_context\"]`` will be a callable\n    that takes a context manager, and can be called multiple times.\n    Each context manager will be entered before evaluating code in the\n    frame, then exited again, so they can perform setup and cleanup for\n    each call.\n\n    :param app: the WSGI application to run debugged.\n    :param evalex: enable exception evaluation feature (interactive\n                   debugging).  This requires a non-forking server.\n    :param request_key: The key that points to the request object in this\n                        environment.  This parameter is ignored in current\n                        versions.\n    :param console_path: the URL for a general purpose console.\n    :param console_init_func: the function that is executed before starting\n                              the general purpose console.  The return value\n                              is used as initial namespace.\n    :param show_hidden_frames: by default hidden traceback frames are skipped.\n                               You can show them by setting this parameter\n                               to `True`.\n    :param pin_security: can be used to disable the pin based security system.\n    :param pin_logging: enables the logging of the pin system.\n\n    .. versionchanged:: 2.2\n        Added the ``werkzeug.debug.preserve_context`` environ key.\n    \"\"\"\n\n    _pin: str\n    _pin_cookie: str\n\n    def __init__(\n        self,\n        app: WSGIApplication,\n        evalex: bool = False,\n        request_key: str = \"werkzeug.request\",\n        console_path: str = \"/console\",\n        console_init_func: t.Callable[[], dict[str, t.Any]] | None = None,\n        show_hidden_frames: bool = False,\n        pin_security: bool = True,\n        pin_logging: bool = True,\n    ) -> None:\n        if not console_init_func:\n            console_init_func = None\n        self.app = app\n        self.evalex = evalex\n        self.frames: dict[int, DebugFrameSummary | _ConsoleFrame] = {}\n        self.frame_contexts: dict[int, list[t.ContextManager[None]]] = {}\n        self.request_key = request_key\n        self.console_path = console_path\n        self.console_init_func = console_init_func\n        self.show_hidden_frames = show_hidden_frames\n        self.secret = gen_salt(20)\n        self._failed_pin_auth = 0\n\n        self.pin_logging = pin_logging\n        if pin_security:\n            # Print out the pin for the debugger on standard out.\n            if os.environ.get(\"WERKZEUG_RUN_MAIN\") == \"true\" and pin_logging:\n                _log(\"warning\", \" * Debugger is active!\")\n                if self.pin is None:\n                    _log(\"warning\", \" * Debugger PIN disabled. DEBUGGER UNSECURED!\")\n                else:\n                    _log(\"info\", \" * Debugger PIN: %s\", self.pin)\n        else:\n            self.pin = None\n\n        self.trusted_hosts: list[str] = [\".localhost\", \"127.0.0.1\"]\n        \"\"\"List of domains to allow requests to the debugger from. A leading dot\n        allows all subdomains. This only allows ``\".localhost\"`` domains by\n        default.\n\n        .. versionadded:: 3.0.3\n        \"\"\"\n\n    @property\n    def pin(self) -> str | None:\n        if not hasattr(self, \"_pin\"):\n            pin_cookie = get_pin_and_cookie_name(self.app)\n            self._pin, self._pin_cookie = pin_cookie  # type: ignore\n        return self._pin\n\n    @pin.setter\n    def pin(self, value: str) -> None:\n        self._pin = value\n\n    @property\n    def pin_cookie_name(self) -> str:\n        \"\"\"The name of the pin cookie.\"\"\"\n        if not hasattr(self, \"_pin_cookie\"):\n            pin_cookie = get_pin_and_cookie_name(self.app)\n            self._pin, self._pin_cookie = pin_cookie  # type: ignore\n        return self._pin_cookie\n\n    def debug_application(\n        self, environ: WSGIEnvironment, start_response: StartResponse\n    ) -> t.Iterator[bytes]:\n        \"\"\"Run the application and conserve the traceback frames.\"\"\"\n        contexts: list[t.ContextManager[t.Any]] = []\n\n        if self.evalex:\n            environ[\"werkzeug.debug.preserve_context\"] = contexts.append\n\n        app_iter = None\n        try:\n            app_iter = self.app(environ, start_response)\n            yield from app_iter\n            if hasattr(app_iter, \"close\"):\n                app_iter.close()\n        except Exception as e:\n            if hasattr(app_iter, \"close\"):\n                app_iter.close()  # type: ignore\n\n            tb = DebugTraceback(e, skip=1, hide=not self.show_hidden_frames)\n\n            for frame in tb.all_frames:\n                self.frames[id(frame)] = frame\n                self.frame_contexts[id(frame)] = contexts\n\n            is_trusted = bool(self.check_pin_trust(environ))\n            html = tb.render_debugger_html(\n                evalex=self.evalex and self.check_host_trust(environ),\n                secret=self.secret,\n                evalex_trusted=is_trusted,\n            )\n            response = Response(html, status=500, mimetype=\"text/html\")\n\n            try:\n                yield from response(environ, start_response)\n            except Exception:\n                # if we end up here there has been output but an error\n                # occurred.  in that situation we can do nothing fancy any\n                # more, better log something into the error log and fall\n                # back gracefully.\n                environ[\"wsgi.errors\"].write(\n                    \"Debugging middleware caught exception in streamed \"\n                    \"response at a point where response headers were already \"\n                    \"sent.\\n\"\n                )\n\n            environ[\"wsgi.errors\"].write(\"\".join(tb.render_traceback_text()))\n\n    def execute_command(  # type: ignore[return]\n        self,\n        request: Request,\n        command: str,\n        frame: DebugFrameSummary | _ConsoleFrame,\n    ) -> Response:\n        \"\"\"Execute a command in a console.\"\"\"\n        if not self.check_host_trust(request.environ):\n            return SecurityError()  # type: ignore[return-value]\n\n        contexts = self.frame_contexts.get(id(frame), [])\n\n        with ExitStack() as exit_stack:\n            for cm in contexts:\n                exit_stack.enter_context(cm)\n\n            return Response(frame.eval(command), mimetype=\"text/html\")\n\n    def display_console(self, request: Request) -> Response:\n        \"\"\"Display a standalone shell.\"\"\"\n        if not self.check_host_trust(request.environ):\n            return SecurityError()  # type: ignore[return-value]\n\n        if 0 not in self.frames:\n            if self.console_init_func is None:\n                ns = {}\n            else:\n                ns = dict(self.console_init_func())\n            ns.setdefault(\"app\", self.app)\n            self.frames[0] = _ConsoleFrame(ns)\n        is_trusted = bool(self.check_pin_trust(request.environ))\n        return Response(\n            render_console_html(secret=self.secret, evalex_trusted=is_trusted),\n            mimetype=\"text/html\",\n        )\n\n    def get_resource(self, request: Request, filename: str) -> Response:\n        \"\"\"Return a static resource from the shared folder.\"\"\"\n        path = join(\"shared\", basename(filename))\n\n        try:\n            data = pkgutil.get_data(__package__, path)\n        except OSError:\n            return NotFound()  # type: ignore[return-value]\n        else:\n            if data is None:\n                return NotFound()  # type: ignore[return-value]\n\n            etag = str(adler32(data) & 0xFFFFFFFF)\n            return send_file(\n                BytesIO(data), request.environ, download_name=filename, etag=etag\n            )\n\n    def check_pin_trust(self, environ: WSGIEnvironment) -> bool | None:\n        \"\"\"Checks if the request passed the pin test.  This returns `True` if the\n        request is trusted on a pin/cookie basis and returns `False` if not.\n        Additionally if the cookie's stored pin hash is wrong it will return\n        `None` so that appropriate action can be taken.\n        \"\"\"\n        if self.pin is None:\n            return True\n        val = parse_cookie(environ).get(self.pin_cookie_name)\n        if not val or \"|\" not in val:\n            return False\n        ts_str, pin_hash = val.split(\"|\", 1)\n\n        try:\n            ts = int(ts_str)\n        except ValueError:\n            return False\n\n        if pin_hash != hash_pin(self.pin):\n            return None\n        return (time.time() - PIN_TIME) < ts\n\n    def check_host_trust(self, environ: WSGIEnvironment) -> bool:\n        return host_is_trusted(environ.get(\"HTTP_HOST\"), self.trusted_hosts)\n\n    def _fail_pin_auth(self) -> None:\n        time.sleep(5.0 if self._failed_pin_auth > 5 else 0.5)\n        self._failed_pin_auth += 1\n\n    def pin_auth(self, request: Request) -> Response:\n        \"\"\"Authenticates with the pin.\"\"\"\n        if not self.check_host_trust(request.environ):\n            return SecurityError()  # type: ignore[return-value]\n\n        exhausted = False\n        auth = False\n        trust = self.check_pin_trust(request.environ)\n        pin = t.cast(str, self.pin)\n\n        # If the trust return value is `None` it means that the cookie is\n        # set but the stored pin hash value is bad.  This means that the\n        # pin was changed.  In this case we count a bad auth and unset the\n        # cookie.  This way it becomes harder to guess the cookie name\n        # instead of the pin as we still count up failures.\n        bad_cookie = False\n        if trust is None:\n            self._fail_pin_auth()\n            bad_cookie = True\n\n        # If we're trusted, we're authenticated.\n        elif trust:\n            auth = True\n\n        # If we failed too many times, then we're locked out.\n        elif self._failed_pin_auth > 10:\n            exhausted = True\n\n        # Otherwise go through pin based authentication\n        else:\n            entered_pin = request.args[\"pin\"]\n\n            if entered_pin.strip().replace(\"-\", \"\") == pin.replace(\"-\", \"\"):\n                self._failed_pin_auth = 0\n                auth = True\n            else:\n                self._fail_pin_auth()\n\n        rv = Response(\n            json.dumps({\"auth\": auth, \"exhausted\": exhausted}),\n            mimetype=\"application/json\",\n        )\n        if auth:\n            rv.set_cookie(\n                self.pin_cookie_name,\n                f\"{int(time.time())}|{hash_pin(pin)}\",\n                httponly=True,\n                samesite=\"Strict\",\n                secure=request.is_secure,\n            )\n        elif bad_cookie:\n            rv.delete_cookie(self.pin_cookie_name)\n        return rv\n\n    def log_pin_request(self, request: Request) -> Response:\n        \"\"\"Log the pin if needed.\"\"\"\n        if not self.check_host_trust(request.environ):\n            return SecurityError()  # type: ignore[return-value]\n\n        if self.pin_logging and self.pin is not None:\n            _log(\n                \"info\", \" * To enable the debugger you need to enter the security pin:\"\n            )\n            _log(\"info\", \" * Debugger pin code: %s\", self.pin)\n        return Response(\"\")\n\n    def __call__(\n        self, environ: WSGIEnvironment, start_response: StartResponse\n    ) -> t.Iterable[bytes]:\n        \"\"\"Dispatch the requests.\"\"\"\n        # important: don't ever access a function here that reads the incoming\n        # form data!  Otherwise the application won't have access to that data\n        # any more!\n        request = Request(environ)\n        response = self.debug_application\n        if request.args.get(\"__debugger__\") == \"yes\":\n            cmd = request.args.get(\"cmd\")\n            arg = request.args.get(\"f\")\n            secret = request.args.get(\"s\")\n            frame = self.frames.get(request.args.get(\"frm\", type=int))  # type: ignore\n            if cmd == \"resource\" and arg:\n                response = self.get_resource(request, arg)  # type: ignore\n            elif cmd == \"pinauth\" and secret == self.secret:\n                response = self.pin_auth(request)  # type: ignore\n            elif cmd == \"printpin\" and secret == self.secret:\n                response = self.log_pin_request(request)  # type: ignore\n            elif (\n                self.evalex\n                and cmd is not None\n                and frame is not None\n                and self.secret == secret\n                and self.check_pin_trust(environ)\n            ):\n                response = self.execute_command(request, cmd, frame)  # type: ignore\n        elif (\n            self.evalex\n            and self.console_path is not None\n            and request.path == self.console_path\n        ):\n            response = self.display_console(request)  # type: ignore\n        return response(environ, start_response)\n", "src/werkzeug/middleware/shared_data.py": "\"\"\"\nServe Shared Static Files\n=========================\n\n.. autoclass:: SharedDataMiddleware\n    :members: is_allowed\n\n:copyright: 2007 Pallets\n:license: BSD-3-Clause\n\"\"\"\n\nfrom __future__ import annotations\n\nimport importlib.util\nimport mimetypes\nimport os\nimport posixpath\nimport typing as t\nfrom datetime import datetime\nfrom datetime import timezone\nfrom io import BytesIO\nfrom time import time\nfrom zlib import adler32\n\nfrom ..http import http_date\nfrom ..http import is_resource_modified\nfrom ..security import safe_join\nfrom ..utils import get_content_type\nfrom ..wsgi import get_path_info\nfrom ..wsgi import wrap_file\n\n_TOpener = t.Callable[[], t.Tuple[t.IO[bytes], datetime, int]]\n_TLoader = t.Callable[[t.Optional[str]], t.Tuple[t.Optional[str], t.Optional[_TOpener]]]\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import StartResponse\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n\n\nclass SharedDataMiddleware:\n    \"\"\"A WSGI middleware which provides static content for development\n    environments or simple server setups. Its usage is quite simple::\n\n        import os\n        from werkzeug.middleware.shared_data import SharedDataMiddleware\n\n        app = SharedDataMiddleware(app, {\n            '/shared': os.path.join(os.path.dirname(__file__), 'shared')\n        })\n\n    The contents of the folder ``./shared`` will now be available on\n    ``http://example.com/shared/``.  This is pretty useful during development\n    because a standalone media server is not required. Files can also be\n    mounted on the root folder and still continue to use the application because\n    the shared data middleware forwards all unhandled requests to the\n    application, even if the requests are below one of the shared folders.\n\n    If `pkg_resources` is available you can also tell the middleware to serve\n    files from package data::\n\n        app = SharedDataMiddleware(app, {\n            '/static': ('myapplication', 'static')\n        })\n\n    This will then serve the ``static`` folder in the `myapplication`\n    Python package.\n\n    The optional `disallow` parameter can be a list of :func:`~fnmatch.fnmatch`\n    rules for files that are not accessible from the web.  If `cache` is set to\n    `False` no caching headers are sent.\n\n    Currently the middleware does not support non-ASCII filenames. If the\n    encoding on the file system happens to match the encoding of the URI it may\n    work but this could also be by accident. We strongly suggest using ASCII\n    only file names for static files.\n\n    The middleware will guess the mimetype using the Python `mimetype`\n    module.  If it's unable to figure out the charset it will fall back\n    to `fallback_mimetype`.\n\n    :param app: the application to wrap.  If you don't want to wrap an\n                application you can pass it :exc:`NotFound`.\n    :param exports: a list or dict of exported files and folders.\n    :param disallow: a list of :func:`~fnmatch.fnmatch` rules.\n    :param cache: enable or disable caching headers.\n    :param cache_timeout: the cache timeout in seconds for the headers.\n    :param fallback_mimetype: The fallback mimetype for unknown files.\n\n    .. versionchanged:: 1.0\n        The default ``fallback_mimetype`` is\n        ``application/octet-stream``. If a filename looks like a text\n        mimetype, the ``utf-8`` charset is added to it.\n\n    .. versionadded:: 0.6\n        Added ``fallback_mimetype``.\n\n    .. versionchanged:: 0.5\n        Added ``cache_timeout``.\n    \"\"\"\n\n    def __init__(\n        self,\n        app: WSGIApplication,\n        exports: (\n            dict[str, str | tuple[str, str]]\n            | t.Iterable[tuple[str, str | tuple[str, str]]]\n        ),\n        disallow: None = None,\n        cache: bool = True,\n        cache_timeout: int = 60 * 60 * 12,\n        fallback_mimetype: str = \"application/octet-stream\",\n    ) -> None:\n        self.app = app\n        self.exports: list[tuple[str, _TLoader]] = []\n        self.cache = cache\n        self.cache_timeout = cache_timeout\n\n        if isinstance(exports, dict):\n            exports = exports.items()\n\n        for key, value in exports:\n            if isinstance(value, tuple):\n                loader = self.get_package_loader(*value)\n            elif isinstance(value, str):\n                if os.path.isfile(value):\n                    loader = self.get_file_loader(value)\n                else:\n                    loader = self.get_directory_loader(value)\n            else:\n                raise TypeError(f\"unknown def {value!r}\")\n\n            self.exports.append((key, loader))\n\n        if disallow is not None:\n            from fnmatch import fnmatch\n\n            self.is_allowed = lambda x: not fnmatch(x, disallow)\n\n        self.fallback_mimetype = fallback_mimetype\n\n    def is_allowed(self, filename: str) -> bool:\n        \"\"\"Subclasses can override this method to disallow the access to\n        certain files.  However by providing `disallow` in the constructor\n        this method is overwritten.\n        \"\"\"\n        return True\n\n    def _opener(self, filename: str) -> _TOpener:\n        return lambda: (\n            open(filename, \"rb\"),\n            datetime.fromtimestamp(os.path.getmtime(filename), tz=timezone.utc),\n            int(os.path.getsize(filename)),\n        )\n\n    def get_file_loader(self, filename: str) -> _TLoader:\n        return lambda x: (os.path.basename(filename), self._opener(filename))\n\n    def get_package_loader(self, package: str, package_path: str) -> _TLoader:\n        load_time = datetime.now(timezone.utc)\n        spec = importlib.util.find_spec(package)\n        reader = spec.loader.get_resource_reader(package)  # type: ignore[union-attr]\n\n        def loader(\n            path: str | None,\n        ) -> tuple[str | None, _TOpener | None]:\n            if path is None:\n                return None, None\n\n            path = safe_join(package_path, path)\n\n            if path is None:\n                return None, None\n\n            basename = posixpath.basename(path)\n\n            try:\n                resource = reader.open_resource(path)\n            except OSError:\n                return None, None\n\n            if isinstance(resource, BytesIO):\n                return (\n                    basename,\n                    lambda: (resource, load_time, len(resource.getvalue())),\n                )\n\n            return (\n                basename,\n                lambda: (\n                    resource,\n                    datetime.fromtimestamp(\n                        os.path.getmtime(resource.name), tz=timezone.utc\n                    ),\n                    os.path.getsize(resource.name),\n                ),\n            )\n\n        return loader\n\n    def get_directory_loader(self, directory: str) -> _TLoader:\n        def loader(\n            path: str | None,\n        ) -> tuple[str | None, _TOpener | None]:\n            if path is not None:\n                path = safe_join(directory, path)\n\n                if path is None:\n                    return None, None\n            else:\n                path = directory\n\n            if os.path.isfile(path):\n                return os.path.basename(path), self._opener(path)\n\n            return None, None\n\n        return loader\n\n    def generate_etag(self, mtime: datetime, file_size: int, real_filename: str) -> str:\n        fn_str = os.fsencode(real_filename)\n        timestamp = mtime.timestamp()\n        checksum = adler32(fn_str) & 0xFFFFFFFF\n        return f\"wzsdm-{timestamp}-{file_size}-{checksum}\"\n\n    def __call__(\n        self, environ: WSGIEnvironment, start_response: StartResponse\n    ) -> t.Iterable[bytes]:\n        path = get_path_info(environ)\n        file_loader = None\n\n        for search_path, loader in self.exports:\n            if search_path == path:\n                real_filename, file_loader = loader(None)\n\n                if file_loader is not None:\n                    break\n\n            if not search_path.endswith(\"/\"):\n                search_path += \"/\"\n\n            if path.startswith(search_path):\n                real_filename, file_loader = loader(path[len(search_path) :])\n\n                if file_loader is not None:\n                    break\n\n        if file_loader is None or not self.is_allowed(real_filename):  # type: ignore\n            return self.app(environ, start_response)\n\n        guessed_type = mimetypes.guess_type(real_filename)  # type: ignore\n        mime_type = get_content_type(guessed_type[0] or self.fallback_mimetype, \"utf-8\")\n        f, mtime, file_size = file_loader()\n\n        headers = [(\"Date\", http_date())]\n\n        if self.cache:\n            timeout = self.cache_timeout\n            etag = self.generate_etag(mtime, file_size, real_filename)  # type: ignore\n            headers += [\n                (\"Etag\", f'\"{etag}\"'),\n                (\"Cache-Control\", f\"max-age={timeout}, public\"),\n            ]\n\n            if not is_resource_modified(environ, etag, last_modified=mtime):\n                f.close()\n                start_response(\"304 Not Modified\", headers)\n                return []\n\n            headers.append((\"Expires\", http_date(time() + timeout)))\n        else:\n            headers.append((\"Cache-Control\", \"public\"))\n\n        headers.extend(\n            (\n                (\"Content-Type\", mime_type),\n                (\"Content-Length\", str(file_size)),\n                (\"Last-Modified\", http_date(mtime)),\n            )\n        )\n        start_response(\"200 OK\", headers)\n        return wrap_file(environ, f)\n", "src/werkzeug/middleware/profiler.py": "\"\"\"\nApplication Profiler\n====================\n\nThis module provides a middleware that profiles each request with the\n:mod:`cProfile` module. This can help identify bottlenecks in your code\nthat may be slowing down your application.\n\n.. autoclass:: ProfilerMiddleware\n\n:copyright: 2007 Pallets\n:license: BSD-3-Clause\n\"\"\"\n\nfrom __future__ import annotations\n\nimport os.path\nimport sys\nimport time\nimport typing as t\nfrom pstats import Stats\n\ntry:\n    from cProfile import Profile\nexcept ImportError:\n    from profile import Profile  # type: ignore\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import StartResponse\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n\n\nclass ProfilerMiddleware:\n    \"\"\"Wrap a WSGI application and profile the execution of each\n    request. Responses are buffered so that timings are more exact.\n\n    If ``stream`` is given, :class:`pstats.Stats` are written to it\n    after each request. If ``profile_dir`` is given, :mod:`cProfile`\n    data files are saved to that directory, one file per request.\n\n    The filename can be customized by passing ``filename_format``. If\n    it is a string, it will be formatted using :meth:`str.format` with\n    the following fields available:\n\n    -   ``{method}`` - The request method; GET, POST, etc.\n    -   ``{path}`` - The request path or 'root' should one not exist.\n    -   ``{elapsed}`` - The elapsed time of the request in milliseconds.\n    -   ``{time}`` - The time of the request.\n\n    If it is a callable, it will be called with the WSGI ``environ`` and\n    be expected to return a filename string. The ``environ`` dictionary\n    will also have the ``\"werkzeug.profiler\"`` key populated with a\n    dictionary containing the following fields (more may be added in the\n    future):\n    -   ``{elapsed}`` - The elapsed time of the request in milliseconds.\n    -   ``{time}`` - The time of the request.\n\n    :param app: The WSGI application to wrap.\n    :param stream: Write stats to this stream. Disable with ``None``.\n    :param sort_by: A tuple of columns to sort stats by. See\n        :meth:`pstats.Stats.sort_stats`.\n    :param restrictions: A tuple of restrictions to filter stats by. See\n        :meth:`pstats.Stats.print_stats`.\n    :param profile_dir: Save profile data files to this directory.\n    :param filename_format: Format string for profile data file names,\n        or a callable returning a name. See explanation above.\n\n    .. code-block:: python\n\n        from werkzeug.middleware.profiler import ProfilerMiddleware\n        app = ProfilerMiddleware(app)\n\n    .. versionchanged:: 3.0\n        Added the ``\"werkzeug.profiler\"`` key to the ``filename_format(environ)``\n        parameter with the  ``elapsed`` and ``time`` fields.\n\n    .. versionchanged:: 0.15\n        Stats are written even if ``profile_dir`` is given, and can be\n        disable by passing ``stream=None``.\n\n    .. versionadded:: 0.15\n        Added ``filename_format``.\n\n    .. versionadded:: 0.9\n        Added ``restrictions`` and ``profile_dir``.\n    \"\"\"\n\n    def __init__(\n        self,\n        app: WSGIApplication,\n        stream: t.IO[str] | None = sys.stdout,\n        sort_by: t.Iterable[str] = (\"time\", \"calls\"),\n        restrictions: t.Iterable[str | int | float] = (),\n        profile_dir: str | None = None,\n        filename_format: str = \"{method}.{path}.{elapsed:.0f}ms.{time:.0f}.prof\",\n    ) -> None:\n        self._app = app\n        self._stream = stream\n        self._sort_by = sort_by\n        self._restrictions = restrictions\n        self._profile_dir = profile_dir\n        self._filename_format = filename_format\n\n    def __call__(\n        self, environ: WSGIEnvironment, start_response: StartResponse\n    ) -> t.Iterable[bytes]:\n        response_body: list[bytes] = []\n\n        def catching_start_response(status, headers, exc_info=None):  # type: ignore\n            start_response(status, headers, exc_info)\n            return response_body.append\n\n        def runapp() -> None:\n            app_iter = self._app(\n                environ, t.cast(\"StartResponse\", catching_start_response)\n            )\n            response_body.extend(app_iter)\n\n            if hasattr(app_iter, \"close\"):\n                app_iter.close()\n\n        profile = Profile()\n        start = time.time()\n        profile.runcall(runapp)\n        body = b\"\".join(response_body)\n        elapsed = time.time() - start\n\n        if self._profile_dir is not None:\n            if callable(self._filename_format):\n                environ[\"werkzeug.profiler\"] = {\n                    \"elapsed\": elapsed * 1000.0,\n                    \"time\": time.time(),\n                }\n                filename = self._filename_format(environ)\n            else:\n                filename = self._filename_format.format(\n                    method=environ[\"REQUEST_METHOD\"],\n                    path=environ[\"PATH_INFO\"].strip(\"/\").replace(\"/\", \".\") or \"root\",\n                    elapsed=elapsed * 1000.0,\n                    time=time.time(),\n                )\n            filename = os.path.join(self._profile_dir, filename)\n            profile.dump_stats(filename)\n\n        if self._stream is not None:\n            stats = Stats(profile, stream=self._stream)\n            stats.sort_stats(*self._sort_by)\n            print(\"-\" * 80, file=self._stream)\n            path_info = environ.get(\"PATH_INFO\", \"\")\n            print(f\"PATH: {path_info!r}\", file=self._stream)\n            stats.print_stats(*self._restrictions)\n            print(f\"{'-' * 80}\\n\", file=self._stream)\n\n        return [body]\n", "src/werkzeug/middleware/dispatcher.py": "\"\"\"\nApplication Dispatcher\n======================\n\nThis middleware creates a single WSGI application that dispatches to\nmultiple other WSGI applications mounted at different URL paths.\n\nA common example is writing a Single Page Application, where you have a\nbackend API and a frontend written in JavaScript that does the routing\nin the browser rather than requesting different pages from the server.\nThe frontend is a single HTML and JS file that should be served for any\npath besides \"/api\".\n\nThis example dispatches to an API app under \"/api\", an admin app\nunder \"/admin\", and an app that serves frontend files for all other\nrequests::\n\n    app = DispatcherMiddleware(serve_frontend, {\n        '/api': api_app,\n        '/admin': admin_app,\n    })\n\nIn production, you might instead handle this at the HTTP server level,\nserving files or proxying to application servers based on location. The\nAPI and admin apps would each be deployed with a separate WSGI server,\nand the static files would be served directly by the HTTP server.\n\n.. autoclass:: DispatcherMiddleware\n\n:copyright: 2007 Pallets\n:license: BSD-3-Clause\n\"\"\"\n\nfrom __future__ import annotations\n\nimport typing as t\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import StartResponse\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n\n\nclass DispatcherMiddleware:\n    \"\"\"Combine multiple applications as a single WSGI application.\n    Requests are dispatched to an application based on the path it is\n    mounted under.\n\n    :param app: The WSGI application to dispatch to if the request\n        doesn't match a mounted path.\n    :param mounts: Maps path prefixes to applications for dispatching.\n    \"\"\"\n\n    def __init__(\n        self,\n        app: WSGIApplication,\n        mounts: dict[str, WSGIApplication] | None = None,\n    ) -> None:\n        self.app = app\n        self.mounts = mounts or {}\n\n    def __call__(\n        self, environ: WSGIEnvironment, start_response: StartResponse\n    ) -> t.Iterable[bytes]:\n        script = environ.get(\"PATH_INFO\", \"\")\n        path_info = \"\"\n\n        while \"/\" in script:\n            if script in self.mounts:\n                app = self.mounts[script]\n                break\n\n            script, last_item = script.rsplit(\"/\", 1)\n            path_info = f\"/{last_item}{path_info}\"\n        else:\n            app = self.mounts.get(script, self.app)\n\n        original_script_name = environ.get(\"SCRIPT_NAME\", \"\")\n        environ[\"SCRIPT_NAME\"] = original_script_name + script\n        environ[\"PATH_INFO\"] = path_info\n        return app(environ, start_response)\n", "src/werkzeug/middleware/__init__.py": "", "src/werkzeug/middleware/http_proxy.py": "\"\"\"\nBasic HTTP Proxy\n================\n\n.. autoclass:: ProxyMiddleware\n\n:copyright: 2007 Pallets\n:license: BSD-3-Clause\n\"\"\"\n\nfrom __future__ import annotations\n\nimport typing as t\nfrom http import client\nfrom urllib.parse import quote\nfrom urllib.parse import urlsplit\n\nfrom ..datastructures import EnvironHeaders\nfrom ..http import is_hop_by_hop_header\nfrom ..wsgi import get_input_stream\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import StartResponse\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n\n\nclass ProxyMiddleware:\n    \"\"\"Proxy requests under a path to an external server, routing other\n    requests to the app.\n\n    This middleware can only proxy HTTP requests, as HTTP is the only\n    protocol handled by the WSGI server. Other protocols, such as\n    WebSocket requests, cannot be proxied at this layer. This should\n    only be used for development, in production a real proxy server\n    should be used.\n\n    The middleware takes a dict mapping a path prefix to a dict\n    describing the host to be proxied to::\n\n        app = ProxyMiddleware(app, {\n            \"/static/\": {\n                \"target\": \"http://127.0.0.1:5001/\",\n            }\n        })\n\n    Each host has the following options:\n\n    ``target``:\n        The target URL to dispatch to. This is required.\n    ``remove_prefix``:\n        Whether to remove the prefix from the URL before dispatching it\n        to the target. The default is ``False``.\n    ``host``:\n        ``\"<auto>\"`` (default):\n            The host header is automatically rewritten to the URL of the\n            target.\n        ``None``:\n            The host header is unmodified from the client request.\n        Any other value:\n            The host header is overwritten with the value.\n    ``headers``:\n        A dictionary of headers to be sent with the request to the\n        target. The default is ``{}``.\n    ``ssl_context``:\n        A :class:`ssl.SSLContext` defining how to verify requests if the\n        target is HTTPS. The default is ``None``.\n\n    In the example above, everything under ``\"/static/\"`` is proxied to\n    the server on port 5001. The host header is rewritten to the target,\n    and the ``\"/static/\"`` prefix is removed from the URLs.\n\n    :param app: The WSGI application to wrap.\n    :param targets: Proxy target configurations. See description above.\n    :param chunk_size: Size of chunks to read from input stream and\n        write to target.\n    :param timeout: Seconds before an operation to a target fails.\n\n    .. versionadded:: 0.14\n    \"\"\"\n\n    def __init__(\n        self,\n        app: WSGIApplication,\n        targets: t.Mapping[str, dict[str, t.Any]],\n        chunk_size: int = 2 << 13,\n        timeout: int = 10,\n    ) -> None:\n        def _set_defaults(opts: dict[str, t.Any]) -> dict[str, t.Any]:\n            opts.setdefault(\"remove_prefix\", False)\n            opts.setdefault(\"host\", \"<auto>\")\n            opts.setdefault(\"headers\", {})\n            opts.setdefault(\"ssl_context\", None)\n            return opts\n\n        self.app = app\n        self.targets = {\n            f\"/{k.strip('/')}/\": _set_defaults(v) for k, v in targets.items()\n        }\n        self.chunk_size = chunk_size\n        self.timeout = timeout\n\n    def proxy_to(\n        self, opts: dict[str, t.Any], path: str, prefix: str\n    ) -> WSGIApplication:\n        target = urlsplit(opts[\"target\"])\n        # socket can handle unicode host, but header must be ascii\n        host = target.hostname.encode(\"idna\").decode(\"ascii\")\n\n        def application(\n            environ: WSGIEnvironment, start_response: StartResponse\n        ) -> t.Iterable[bytes]:\n            headers = list(EnvironHeaders(environ).items())\n            headers[:] = [\n                (k, v)\n                for k, v in headers\n                if not is_hop_by_hop_header(k)\n                and k.lower() not in (\"content-length\", \"host\")\n            ]\n            headers.append((\"Connection\", \"close\"))\n\n            if opts[\"host\"] == \"<auto>\":\n                headers.append((\"Host\", host))\n            elif opts[\"host\"] is None:\n                headers.append((\"Host\", environ[\"HTTP_HOST\"]))\n            else:\n                headers.append((\"Host\", opts[\"host\"]))\n\n            headers.extend(opts[\"headers\"].items())\n            remote_path = path\n\n            if opts[\"remove_prefix\"]:\n                remote_path = remote_path[len(prefix) :].lstrip(\"/\")\n                remote_path = f\"{target.path.rstrip('/')}/{remote_path}\"\n\n            content_length = environ.get(\"CONTENT_LENGTH\")\n            chunked = False\n\n            if content_length not in (\"\", None):\n                headers.append((\"Content-Length\", content_length))  # type: ignore\n            elif content_length is not None:\n                headers.append((\"Transfer-Encoding\", \"chunked\"))\n                chunked = True\n\n            try:\n                if target.scheme == \"http\":\n                    con = client.HTTPConnection(\n                        host, target.port or 80, timeout=self.timeout\n                    )\n                elif target.scheme == \"https\":\n                    con = client.HTTPSConnection(\n                        host,\n                        target.port or 443,\n                        timeout=self.timeout,\n                        context=opts[\"ssl_context\"],\n                    )\n                else:\n                    raise RuntimeError(\n                        \"Target scheme must be 'http' or 'https', got\"\n                        f\" {target.scheme!r}.\"\n                    )\n\n                con.connect()\n                # safe = https://url.spec.whatwg.org/#url-path-segment-string\n                # as well as percent for things that are already quoted\n                remote_url = quote(remote_path, safe=\"!$&'()*+,/:;=@%\")\n                querystring = environ[\"QUERY_STRING\"]\n\n                if querystring:\n                    remote_url = f\"{remote_url}?{querystring}\"\n\n                con.putrequest(environ[\"REQUEST_METHOD\"], remote_url, skip_host=True)\n\n                for k, v in headers:\n                    if k.lower() == \"connection\":\n                        v = \"close\"\n\n                    con.putheader(k, v)\n\n                con.endheaders()\n                stream = get_input_stream(environ)\n\n                while True:\n                    data = stream.read(self.chunk_size)\n\n                    if not data:\n                        break\n\n                    if chunked:\n                        con.send(b\"%x\\r\\n%s\\r\\n\" % (len(data), data))\n                    else:\n                        con.send(data)\n\n                resp = con.getresponse()\n            except OSError:\n                from ..exceptions import BadGateway\n\n                return BadGateway()(environ, start_response)\n\n            start_response(\n                f\"{resp.status} {resp.reason}\",\n                [\n                    (k.title(), v)\n                    for k, v in resp.getheaders()\n                    if not is_hop_by_hop_header(k)\n                ],\n            )\n\n            def read() -> t.Iterator[bytes]:\n                while True:\n                    try:\n                        data = resp.read(self.chunk_size)\n                    except OSError:\n                        break\n\n                    if not data:\n                        break\n\n                    yield data\n\n            return read()\n\n        return application\n\n    def __call__(\n        self, environ: WSGIEnvironment, start_response: StartResponse\n    ) -> t.Iterable[bytes]:\n        path = environ[\"PATH_INFO\"]\n        app = self.app\n\n        for prefix, opts in self.targets.items():\n            if path.startswith(prefix):\n                app = self.proxy_to(opts, path, prefix)\n                break\n\n        return app(environ, start_response)\n", "src/werkzeug/middleware/proxy_fix.py": "\"\"\"\nX-Forwarded-For Proxy Fix\n=========================\n\nThis module provides a middleware that adjusts the WSGI environ based on\n``X-Forwarded-`` headers that proxies in front of an application may\nset.\n\nWhen an application is running behind a proxy server, WSGI may see the\nrequest as coming from that server rather than the real client. Proxies\nset various headers to track where the request actually came from.\n\nThis middleware should only be used if the application is actually\nbehind such a proxy, and should be configured with the number of proxies\nthat are chained in front of it. Not all proxies set all the headers.\nSince incoming headers can be faked, you must set how many proxies are\nsetting each header so the middleware knows what to trust.\n\n.. autoclass:: ProxyFix\n\n:copyright: 2007 Pallets\n:license: BSD-3-Clause\n\"\"\"\n\nfrom __future__ import annotations\n\nimport typing as t\n\nfrom ..http import parse_list_header\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import StartResponse\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n\n\nclass ProxyFix:\n    \"\"\"Adjust the WSGI environ based on ``X-Forwarded-`` that proxies in\n    front of the application may set.\n\n    -   ``X-Forwarded-For`` sets ``REMOTE_ADDR``.\n    -   ``X-Forwarded-Proto`` sets ``wsgi.url_scheme``.\n    -   ``X-Forwarded-Host`` sets ``HTTP_HOST``, ``SERVER_NAME``, and\n        ``SERVER_PORT``.\n    -   ``X-Forwarded-Port`` sets ``HTTP_HOST`` and ``SERVER_PORT``.\n    -   ``X-Forwarded-Prefix`` sets ``SCRIPT_NAME``.\n\n    You must tell the middleware how many proxies set each header so it\n    knows what values to trust. It is a security issue to trust values\n    that came from the client rather than a proxy.\n\n    The original values of the headers are stored in the WSGI\n    environ as ``werkzeug.proxy_fix.orig``, a dict.\n\n    :param app: The WSGI application to wrap.\n    :param x_for: Number of values to trust for ``X-Forwarded-For``.\n    :param x_proto: Number of values to trust for ``X-Forwarded-Proto``.\n    :param x_host: Number of values to trust for ``X-Forwarded-Host``.\n    :param x_port: Number of values to trust for ``X-Forwarded-Port``.\n    :param x_prefix: Number of values to trust for\n        ``X-Forwarded-Prefix``.\n\n    .. code-block:: python\n\n        from werkzeug.middleware.proxy_fix import ProxyFix\n        # App is behind one proxy that sets the -For and -Host headers.\n        app = ProxyFix(app, x_for=1, x_host=1)\n\n    .. versionchanged:: 1.0\n        The ``num_proxies`` argument and attribute; the ``get_remote_addr`` method; and\n        the environ keys ``orig_remote_addr``, ``orig_wsgi_url_scheme``, and\n        ``orig_http_host`` were removed.\n\n    .. versionchanged:: 0.15\n        All headers support multiple values. Each header is configured with a separate\n        number of trusted proxies.\n\n    .. versionchanged:: 0.15\n        Original WSGI environ values are stored in the ``werkzeug.proxy_fix.orig`` dict.\n\n    .. versionchanged:: 0.15\n        Support ``X-Forwarded-Port`` and ``X-Forwarded-Prefix``.\n\n    .. versionchanged:: 0.15\n        ``X-Forwarded-Host`` and ``X-Forwarded-Port`` modify\n        ``SERVER_NAME`` and ``SERVER_PORT``.\n    \"\"\"\n\n    def __init__(\n        self,\n        app: WSGIApplication,\n        x_for: int = 1,\n        x_proto: int = 1,\n        x_host: int = 0,\n        x_port: int = 0,\n        x_prefix: int = 0,\n    ) -> None:\n        self.app = app\n        self.x_for = x_for\n        self.x_proto = x_proto\n        self.x_host = x_host\n        self.x_port = x_port\n        self.x_prefix = x_prefix\n\n    def _get_real_value(self, trusted: int, value: str | None) -> str | None:\n        \"\"\"Get the real value from a list header based on the configured\n        number of trusted proxies.\n\n        :param trusted: Number of values to trust in the header.\n        :param value: Comma separated list header value to parse.\n        :return: The real value, or ``None`` if there are fewer values\n            than the number of trusted proxies.\n\n        .. versionchanged:: 1.0\n            Renamed from ``_get_trusted_comma``.\n\n        .. versionadded:: 0.15\n        \"\"\"\n        if not (trusted and value):\n            return None\n        values = parse_list_header(value)\n        if len(values) >= trusted:\n            return values[-trusted]\n        return None\n\n    def __call__(\n        self, environ: WSGIEnvironment, start_response: StartResponse\n    ) -> t.Iterable[bytes]:\n        \"\"\"Modify the WSGI environ based on the various ``Forwarded``\n        headers before calling the wrapped application. Store the\n        original environ values in ``werkzeug.proxy_fix.orig_{key}``.\n        \"\"\"\n        environ_get = environ.get\n        orig_remote_addr = environ_get(\"REMOTE_ADDR\")\n        orig_wsgi_url_scheme = environ_get(\"wsgi.url_scheme\")\n        orig_http_host = environ_get(\"HTTP_HOST\")\n        environ.update(\n            {\n                \"werkzeug.proxy_fix.orig\": {\n                    \"REMOTE_ADDR\": orig_remote_addr,\n                    \"wsgi.url_scheme\": orig_wsgi_url_scheme,\n                    \"HTTP_HOST\": orig_http_host,\n                    \"SERVER_NAME\": environ_get(\"SERVER_NAME\"),\n                    \"SERVER_PORT\": environ_get(\"SERVER_PORT\"),\n                    \"SCRIPT_NAME\": environ_get(\"SCRIPT_NAME\"),\n                }\n            }\n        )\n\n        x_for = self._get_real_value(self.x_for, environ_get(\"HTTP_X_FORWARDED_FOR\"))\n        if x_for:\n            environ[\"REMOTE_ADDR\"] = x_for\n\n        x_proto = self._get_real_value(\n            self.x_proto, environ_get(\"HTTP_X_FORWARDED_PROTO\")\n        )\n        if x_proto:\n            environ[\"wsgi.url_scheme\"] = x_proto\n\n        x_host = self._get_real_value(self.x_host, environ_get(\"HTTP_X_FORWARDED_HOST\"))\n        if x_host:\n            environ[\"HTTP_HOST\"] = environ[\"SERVER_NAME\"] = x_host\n            # \"]\" to check for IPv6 address without port\n            if \":\" in x_host and not x_host.endswith(\"]\"):\n                environ[\"SERVER_NAME\"], environ[\"SERVER_PORT\"] = x_host.rsplit(\":\", 1)\n\n        x_port = self._get_real_value(self.x_port, environ_get(\"HTTP_X_FORWARDED_PORT\"))\n        if x_port:\n            host = environ.get(\"HTTP_HOST\")\n            if host:\n                # \"]\" to check for IPv6 address without port\n                if \":\" in host and not host.endswith(\"]\"):\n                    host = host.rsplit(\":\", 1)[0]\n                environ[\"HTTP_HOST\"] = f\"{host}:{x_port}\"\n            environ[\"SERVER_PORT\"] = x_port\n\n        x_prefix = self._get_real_value(\n            self.x_prefix, environ_get(\"HTTP_X_FORWARDED_PREFIX\")\n        )\n        if x_prefix:\n            environ[\"SCRIPT_NAME\"] = x_prefix\n\n        return self.app(environ, start_response)\n", "src/werkzeug/middleware/lint.py": "\"\"\"\nWSGI Protocol Linter\n====================\n\nThis module provides a middleware that performs sanity checks on the\nbehavior of the WSGI server and application. It checks that the\n:pep:`3333` WSGI spec is properly implemented. It also warns on some\ncommon HTTP errors such as non-empty responses for 304 status codes.\n\n.. autoclass:: LintMiddleware\n\n:copyright: 2007 Pallets\n:license: BSD-3-Clause\n\"\"\"\n\nfrom __future__ import annotations\n\nimport typing as t\nfrom types import TracebackType\nfrom urllib.parse import urlparse\nfrom warnings import warn\n\nfrom ..datastructures import Headers\nfrom ..http import is_entity_header\nfrom ..wsgi import FileWrapper\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import StartResponse\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n\n\nclass WSGIWarning(Warning):\n    \"\"\"Warning class for WSGI warnings.\"\"\"\n\n\nclass HTTPWarning(Warning):\n    \"\"\"Warning class for HTTP warnings.\"\"\"\n\n\ndef check_type(context: str, obj: object, need: type = str) -> None:\n    if type(obj) is not need:\n        warn(\n            f\"{context!r} requires {need.__name__!r}, got {type(obj).__name__!r}.\",\n            WSGIWarning,\n            stacklevel=3,\n        )\n\n\nclass InputStream:\n    def __init__(self, stream: t.IO[bytes]) -> None:\n        self._stream = stream\n\n    def read(self, *args: t.Any) -> bytes:\n        if len(args) == 0:\n            warn(\n                \"WSGI does not guarantee an EOF marker on the input stream, thus making\"\n                \" calls to 'wsgi.input.read()' unsafe. Conforming servers may never\"\n                \" return from this call.\",\n                WSGIWarning,\n                stacklevel=2,\n            )\n        elif len(args) != 1:\n            warn(\n                \"Too many parameters passed to 'wsgi.input.read()'.\",\n                WSGIWarning,\n                stacklevel=2,\n            )\n        return self._stream.read(*args)\n\n    def readline(self, *args: t.Any) -> bytes:\n        if len(args) == 0:\n            warn(\n                \"Calls to 'wsgi.input.readline()' without arguments are unsafe. Use\"\n                \" 'wsgi.input.read()' instead.\",\n                WSGIWarning,\n                stacklevel=2,\n            )\n        elif len(args) == 1:\n            warn(\n                \"'wsgi.input.readline()' was called with a size hint. WSGI does not\"\n                \" support this, although it's available on all major servers.\",\n                WSGIWarning,\n                stacklevel=2,\n            )\n        else:\n            raise TypeError(\"Too many arguments passed to 'wsgi.input.readline()'.\")\n        return self._stream.readline(*args)\n\n    def __iter__(self) -> t.Iterator[bytes]:\n        try:\n            return iter(self._stream)\n        except TypeError:\n            warn(\"'wsgi.input' is not iterable.\", WSGIWarning, stacklevel=2)\n            return iter(())\n\n    def close(self) -> None:\n        warn(\"The application closed the input stream!\", WSGIWarning, stacklevel=2)\n        self._stream.close()\n\n\nclass ErrorStream:\n    def __init__(self, stream: t.IO[str]) -> None:\n        self._stream = stream\n\n    def write(self, s: str) -> None:\n        check_type(\"wsgi.error.write()\", s, str)\n        self._stream.write(s)\n\n    def flush(self) -> None:\n        self._stream.flush()\n\n    def writelines(self, seq: t.Iterable[str]) -> None:\n        for line in seq:\n            self.write(line)\n\n    def close(self) -> None:\n        warn(\"The application closed the error stream!\", WSGIWarning, stacklevel=2)\n        self._stream.close()\n\n\nclass GuardedWrite:\n    def __init__(self, write: t.Callable[[bytes], object], chunks: list[int]) -> None:\n        self._write = write\n        self._chunks = chunks\n\n    def __call__(self, s: bytes) -> None:\n        check_type(\"write()\", s, bytes)\n        self._write(s)\n        self._chunks.append(len(s))\n\n\nclass GuardedIterator:\n    def __init__(\n        self,\n        iterator: t.Iterable[bytes],\n        headers_set: tuple[int, Headers],\n        chunks: list[int],\n    ) -> None:\n        self._iterator = iterator\n        self._next = iter(iterator).__next__\n        self.closed = False\n        self.headers_set = headers_set\n        self.chunks = chunks\n\n    def __iter__(self) -> GuardedIterator:\n        return self\n\n    def __next__(self) -> bytes:\n        if self.closed:\n            warn(\"Iterated over closed 'app_iter'.\", WSGIWarning, stacklevel=2)\n\n        rv = self._next()\n\n        if not self.headers_set:\n            warn(\n                \"The application returned before it started the response.\",\n                WSGIWarning,\n                stacklevel=2,\n            )\n\n        check_type(\"application iterator items\", rv, bytes)\n        self.chunks.append(len(rv))\n        return rv\n\n    def close(self) -> None:\n        self.closed = True\n\n        if hasattr(self._iterator, \"close\"):\n            self._iterator.close()\n\n        if self.headers_set:\n            status_code, headers = self.headers_set\n            bytes_sent = sum(self.chunks)\n            content_length = headers.get(\"content-length\", type=int)\n\n            if status_code == 304:\n                for key, _value in headers:\n                    key = key.lower()\n                    if key not in (\"expires\", \"content-location\") and is_entity_header(\n                        key\n                    ):\n                        warn(\n                            f\"Entity header {key!r} found in 304 response.\",\n                            HTTPWarning,\n                            stacklevel=2,\n                        )\n                if bytes_sent:\n                    warn(\n                        \"304 responses must not have a body.\",\n                        HTTPWarning,\n                        stacklevel=2,\n                    )\n            elif 100 <= status_code < 200 or status_code == 204:\n                if content_length != 0:\n                    warn(\n                        f\"{status_code} responses must have an empty content length.\",\n                        HTTPWarning,\n                        stacklevel=2,\n                    )\n                if bytes_sent:\n                    warn(\n                        f\"{status_code} responses must not have a body.\",\n                        HTTPWarning,\n                        stacklevel=2,\n                    )\n            elif content_length is not None and content_length != bytes_sent:\n                warn(\n                    \"Content-Length and the number of bytes sent to the\"\n                    \" client do not match.\",\n                    WSGIWarning,\n                    stacklevel=2,\n                )\n\n    def __del__(self) -> None:\n        if not self.closed:\n            try:\n                warn(\n                    \"Iterator was garbage collected before it was closed.\",\n                    WSGIWarning,\n                    stacklevel=2,\n                )\n            except Exception:\n                pass\n\n\nclass LintMiddleware:\n    \"\"\"Warns about common errors in the WSGI and HTTP behavior of the\n    server and wrapped application. Some of the issues it checks are:\n\n    -   invalid status codes\n    -   non-bytes sent to the WSGI server\n    -   strings returned from the WSGI application\n    -   non-empty conditional responses\n    -   unquoted etags\n    -   relative URLs in the Location header\n    -   unsafe calls to wsgi.input\n    -   unclosed iterators\n\n    Error information is emitted using the :mod:`warnings` module.\n\n    :param app: The WSGI application to wrap.\n\n    .. code-block:: python\n\n        from werkzeug.middleware.lint import LintMiddleware\n        app = LintMiddleware(app)\n    \"\"\"\n\n    def __init__(self, app: WSGIApplication) -> None:\n        self.app = app\n\n    def check_environ(self, environ: WSGIEnvironment) -> None:\n        if type(environ) is not dict:  # noqa: E721\n            warn(\n                \"WSGI environment is not a standard Python dict.\",\n                WSGIWarning,\n                stacklevel=4,\n            )\n        for key in (\n            \"REQUEST_METHOD\",\n            \"SERVER_NAME\",\n            \"SERVER_PORT\",\n            \"wsgi.version\",\n            \"wsgi.input\",\n            \"wsgi.errors\",\n            \"wsgi.multithread\",\n            \"wsgi.multiprocess\",\n            \"wsgi.run_once\",\n        ):\n            if key not in environ:\n                warn(\n                    f\"Required environment key {key!r} not found\",\n                    WSGIWarning,\n                    stacklevel=3,\n                )\n        if environ[\"wsgi.version\"] != (1, 0):\n            warn(\"Environ is not a WSGI 1.0 environ.\", WSGIWarning, stacklevel=3)\n\n        script_name = environ.get(\"SCRIPT_NAME\", \"\")\n        path_info = environ.get(\"PATH_INFO\", \"\")\n\n        if script_name and script_name[0] != \"/\":\n            warn(\n                f\"'SCRIPT_NAME' does not start with a slash: {script_name!r}\",\n                WSGIWarning,\n                stacklevel=3,\n            )\n\n        if path_info and path_info[0] != \"/\":\n            warn(\n                f\"'PATH_INFO' does not start with a slash: {path_info!r}\",\n                WSGIWarning,\n                stacklevel=3,\n            )\n\n    def check_start_response(\n        self,\n        status: str,\n        headers: list[tuple[str, str]],\n        exc_info: None | (tuple[type[BaseException], BaseException, TracebackType]),\n    ) -> tuple[int, Headers]:\n        check_type(\"status\", status, str)\n        status_code_str = status.split(None, 1)[0]\n\n        if len(status_code_str) != 3 or not status_code_str.isdecimal():\n            warn(\"Status code must be three digits.\", WSGIWarning, stacklevel=3)\n\n        if len(status) < 4 or status[3] != \" \":\n            warn(\n                f\"Invalid value for status {status!r}. Valid status strings are three\"\n                \" digits, a space and a status explanation.\",\n                WSGIWarning,\n                stacklevel=3,\n            )\n\n        status_code = int(status_code_str)\n\n        if status_code < 100:\n            warn(\"Status code < 100 detected.\", WSGIWarning, stacklevel=3)\n\n        if type(headers) is not list:  # noqa: E721\n            warn(\"Header list is not a list.\", WSGIWarning, stacklevel=3)\n\n        for item in headers:\n            if type(item) is not tuple or len(item) != 2:\n                warn(\"Header items must be 2-item tuples.\", WSGIWarning, stacklevel=3)\n            name, value = item\n            if type(name) is not str or type(value) is not str:  # noqa: E721\n                warn(\n                    \"Header keys and values must be strings.\", WSGIWarning, stacklevel=3\n                )\n            if name.lower() == \"status\":\n                warn(\n                    \"The status header is not supported due to\"\n                    \" conflicts with the CGI spec.\",\n                    WSGIWarning,\n                    stacklevel=3,\n                )\n\n        if exc_info is not None and not isinstance(exc_info, tuple):\n            warn(\"Invalid value for exc_info.\", WSGIWarning, stacklevel=3)\n\n        headers_obj = Headers(headers)\n        self.check_headers(headers_obj)\n\n        return status_code, headers_obj\n\n    def check_headers(self, headers: Headers) -> None:\n        etag = headers.get(\"etag\")\n\n        if etag is not None:\n            if etag.startswith((\"W/\", \"w/\")):\n                if etag.startswith(\"w/\"):\n                    warn(\n                        \"Weak etag indicator should be upper case.\",\n                        HTTPWarning,\n                        stacklevel=4,\n                    )\n\n                etag = etag[2:]\n\n            if not (etag[:1] == etag[-1:] == '\"'):\n                warn(\"Unquoted etag emitted.\", HTTPWarning, stacklevel=4)\n\n        location = headers.get(\"location\")\n\n        if location is not None:\n            if not urlparse(location).netloc:\n                warn(\n                    \"Absolute URLs required for location header.\",\n                    HTTPWarning,\n                    stacklevel=4,\n                )\n\n    def check_iterator(self, app_iter: t.Iterable[bytes]) -> None:\n        if isinstance(app_iter, str):\n            warn(\n                \"The application returned a string. The response will send one\"\n                \" character at a time to the client, which will kill performance.\"\n                \" Return a list or iterable instead.\",\n                WSGIWarning,\n                stacklevel=3,\n            )\n\n    def __call__(self, *args: t.Any, **kwargs: t.Any) -> t.Iterable[bytes]:\n        if len(args) != 2:\n            warn(\"A WSGI app takes two arguments.\", WSGIWarning, stacklevel=2)\n\n        if kwargs:\n            warn(\n                \"A WSGI app does not take keyword arguments.\", WSGIWarning, stacklevel=2\n            )\n\n        environ: WSGIEnvironment = args[0]\n        start_response: StartResponse = args[1]\n\n        self.check_environ(environ)\n        environ[\"wsgi.input\"] = InputStream(environ[\"wsgi.input\"])\n        environ[\"wsgi.errors\"] = ErrorStream(environ[\"wsgi.errors\"])\n\n        # Hook our own file wrapper in so that applications will always\n        # iterate to the end and we can check the content length.\n        environ[\"wsgi.file_wrapper\"] = FileWrapper\n\n        headers_set: list[t.Any] = []\n        chunks: list[int] = []\n\n        def checking_start_response(\n            *args: t.Any, **kwargs: t.Any\n        ) -> t.Callable[[bytes], None]:\n            if len(args) not in {2, 3}:\n                warn(\n                    f\"Invalid number of arguments: {len(args)}, expected 2 or 3.\",\n                    WSGIWarning,\n                    stacklevel=2,\n                )\n\n            if kwargs:\n                warn(\n                    \"'start_response' does not take keyword arguments.\",\n                    WSGIWarning,\n                    stacklevel=2,\n                )\n\n            status: str = args[0]\n            headers: list[tuple[str, str]] = args[1]\n            exc_info: (\n                None | (tuple[type[BaseException], BaseException, TracebackType])\n            ) = args[2] if len(args) == 3 else None\n\n            headers_set[:] = self.check_start_response(status, headers, exc_info)\n            return GuardedWrite(start_response(status, headers, exc_info), chunks)\n\n        app_iter = self.app(environ, t.cast(\"StartResponse\", checking_start_response))\n        self.check_iterator(app_iter)\n        return GuardedIterator(\n            app_iter, t.cast(t.Tuple[int, Headers], headers_set), chunks\n        )\n", "src/werkzeug/datastructures/mixins.py": "from __future__ import annotations\n\nfrom itertools import repeat\n\nfrom .._internal import _missing\n\n\ndef is_immutable(self):\n    raise TypeError(f\"{type(self).__name__!r} objects are immutable\")\n\n\nclass ImmutableListMixin:\n    \"\"\"Makes a :class:`list` immutable.\n\n    .. versionadded:: 0.5\n\n    :private:\n    \"\"\"\n\n    _hash_cache = None\n\n    def __hash__(self):\n        if self._hash_cache is not None:\n            return self._hash_cache\n        rv = self._hash_cache = hash(tuple(self))\n        return rv\n\n    def __reduce_ex__(self, protocol):\n        return type(self), (list(self),)\n\n    def __delitem__(self, key):\n        is_immutable(self)\n\n    def __iadd__(self, other):\n        is_immutable(self)\n\n    def __imul__(self, other):\n        is_immutable(self)\n\n    def __setitem__(self, key, value):\n        is_immutable(self)\n\n    def append(self, item):\n        is_immutable(self)\n\n    def remove(self, item):\n        is_immutable(self)\n\n    def extend(self, iterable):\n        is_immutable(self)\n\n    def insert(self, pos, value):\n        is_immutable(self)\n\n    def pop(self, index=-1):\n        is_immutable(self)\n\n    def reverse(self):\n        is_immutable(self)\n\n    def sort(self, key=None, reverse=False):\n        is_immutable(self)\n\n\nclass ImmutableDictMixin:\n    \"\"\"Makes a :class:`dict` immutable.\n\n    .. versionadded:: 0.5\n\n    :private:\n    \"\"\"\n\n    _hash_cache = None\n\n    @classmethod\n    def fromkeys(cls, keys, value=None):\n        instance = super().__new__(cls)\n        instance.__init__(zip(keys, repeat(value)))\n        return instance\n\n    def __reduce_ex__(self, protocol):\n        return type(self), (dict(self),)\n\n    def _iter_hashitems(self):\n        return self.items()\n\n    def __hash__(self):\n        if self._hash_cache is not None:\n            return self._hash_cache\n        rv = self._hash_cache = hash(frozenset(self._iter_hashitems()))\n        return rv\n\n    def setdefault(self, key, default=None):\n        is_immutable(self)\n\n    def update(self, *args, **kwargs):\n        is_immutable(self)\n\n    def pop(self, key, default=None):\n        is_immutable(self)\n\n    def popitem(self):\n        is_immutable(self)\n\n    def __setitem__(self, key, value):\n        is_immutable(self)\n\n    def __delitem__(self, key):\n        is_immutable(self)\n\n    def clear(self):\n        is_immutable(self)\n\n\nclass ImmutableMultiDictMixin(ImmutableDictMixin):\n    \"\"\"Makes a :class:`MultiDict` immutable.\n\n    .. versionadded:: 0.5\n\n    :private:\n    \"\"\"\n\n    def __reduce_ex__(self, protocol):\n        return type(self), (list(self.items(multi=True)),)\n\n    def _iter_hashitems(self):\n        return self.items(multi=True)\n\n    def add(self, key, value):\n        is_immutable(self)\n\n    def popitemlist(self):\n        is_immutable(self)\n\n    def poplist(self, key):\n        is_immutable(self)\n\n    def setlist(self, key, new_list):\n        is_immutable(self)\n\n    def setlistdefault(self, key, default_list=None):\n        is_immutable(self)\n\n\nclass ImmutableHeadersMixin:\n    \"\"\"Makes a :class:`Headers` immutable.  We do not mark them as\n    hashable though since the only usecase for this datastructure\n    in Werkzeug is a view on a mutable structure.\n\n    .. versionadded:: 0.5\n\n    :private:\n    \"\"\"\n\n    def __delitem__(self, key, **kwargs):\n        is_immutable(self)\n\n    def __setitem__(self, key, value):\n        is_immutable(self)\n\n    def set(self, _key, _value, **kwargs):\n        is_immutable(self)\n\n    def setlist(self, key, values):\n        is_immutable(self)\n\n    def add(self, _key, _value, **kwargs):\n        is_immutable(self)\n\n    def add_header(self, _key, _value, **_kwargs):\n        is_immutable(self)\n\n    def remove(self, key):\n        is_immutable(self)\n\n    def extend(self, *args, **kwargs):\n        is_immutable(self)\n\n    def update(self, *args, **kwargs):\n        is_immutable(self)\n\n    def insert(self, pos, value):\n        is_immutable(self)\n\n    def pop(self, key=None, default=_missing):\n        is_immutable(self)\n\n    def popitem(self):\n        is_immutable(self)\n\n    def setdefault(self, key, default):\n        is_immutable(self)\n\n    def setlistdefault(self, key, default):\n        is_immutable(self)\n\n\ndef _calls_update(name):\n    def oncall(self, *args, **kw):\n        rv = getattr(super(UpdateDictMixin, self), name)(*args, **kw)\n\n        if self.on_update is not None:\n            self.on_update(self)\n\n        return rv\n\n    oncall.__name__ = name\n    return oncall\n\n\nclass UpdateDictMixin(dict):\n    \"\"\"Makes dicts call `self.on_update` on modifications.\n\n    .. versionadded:: 0.5\n\n    :private:\n    \"\"\"\n\n    on_update = None\n\n    def setdefault(self, key, default=None):\n        modified = key not in self\n        rv = super().setdefault(key, default)\n        if modified and self.on_update is not None:\n            self.on_update(self)\n        return rv\n\n    def pop(self, key, default=_missing):\n        modified = key in self\n        if default is _missing:\n            rv = super().pop(key)\n        else:\n            rv = super().pop(key, default)\n        if modified and self.on_update is not None:\n            self.on_update(self)\n        return rv\n\n    __setitem__ = _calls_update(\"__setitem__\")\n    __delitem__ = _calls_update(\"__delitem__\")\n    clear = _calls_update(\"clear\")\n    popitem = _calls_update(\"popitem\")\n    update = _calls_update(\"update\")\n", "src/werkzeug/datastructures/auth.py": "from __future__ import annotations\n\nimport base64\nimport binascii\nimport typing as t\n\nfrom ..http import dump_header\nfrom ..http import parse_dict_header\nfrom ..http import quote_header_value\nfrom .structures import CallbackDict\n\nif t.TYPE_CHECKING:\n    import typing_extensions as te\n\n\nclass Authorization:\n    \"\"\"Represents the parts of an ``Authorization`` request header.\n\n    :attr:`.Request.authorization` returns an instance if the header is set.\n\n    An instance can be used with the test :class:`.Client` request methods' ``auth``\n    parameter to send the header in test requests.\n\n    Depending on the auth scheme, either :attr:`parameters` or :attr:`token` will be\n    set. The ``Basic`` scheme's token is decoded into the ``username`` and ``password``\n    parameters.\n\n    For convenience, ``auth[\"key\"]`` and ``auth.key`` both access the key in the\n    :attr:`parameters` dict, along with ``auth.get(\"key\")`` and ``\"key\" in auth``.\n\n    .. versionchanged:: 2.3\n        The ``token`` parameter and attribute was added to support auth schemes that use\n        a token instead of parameters, such as ``Bearer``.\n\n    .. versionchanged:: 2.3\n        The object is no longer a ``dict``.\n\n    .. versionchanged:: 0.5\n        The object is an immutable dict.\n    \"\"\"\n\n    def __init__(\n        self,\n        auth_type: str,\n        data: dict[str, str | None] | None = None,\n        token: str | None = None,\n    ) -> None:\n        self.type = auth_type\n        \"\"\"The authorization scheme, like ``basic``, ``digest``, or ``bearer``.\"\"\"\n\n        if data is None:\n            data = {}\n\n        self.parameters = data\n        \"\"\"A dict of parameters parsed from the header. Either this or :attr:`token`\n        will have a value for a given scheme.\n        \"\"\"\n\n        self.token = token\n        \"\"\"A token parsed from the header. Either this or :attr:`parameters` will have a\n        value for a given scheme.\n\n        .. versionadded:: 2.3\n        \"\"\"\n\n    def __getattr__(self, name: str) -> str | None:\n        return self.parameters.get(name)\n\n    def __getitem__(self, name: str) -> str | None:\n        return self.parameters.get(name)\n\n    def get(self, key: str, default: str | None = None) -> str | None:\n        return self.parameters.get(key, default)\n\n    def __contains__(self, key: str) -> bool:\n        return key in self.parameters\n\n    def __eq__(self, other: object) -> bool:\n        if not isinstance(other, Authorization):\n            return NotImplemented\n\n        return (\n            other.type == self.type\n            and other.token == self.token\n            and other.parameters == self.parameters\n        )\n\n    @classmethod\n    def from_header(cls, value: str | None) -> te.Self | None:\n        \"\"\"Parse an ``Authorization`` header value and return an instance, or ``None``\n        if the value is empty.\n\n        :param value: The header value to parse.\n\n        .. versionadded:: 2.3\n        \"\"\"\n        if not value:\n            return None\n\n        scheme, _, rest = value.partition(\" \")\n        scheme = scheme.lower()\n        rest = rest.strip()\n\n        if scheme == \"basic\":\n            try:\n                username, _, password = base64.b64decode(rest).decode().partition(\":\")\n            except (binascii.Error, UnicodeError):\n                return None\n\n            return cls(scheme, {\"username\": username, \"password\": password})\n\n        if \"=\" in rest.rstrip(\"=\"):\n            # = that is not trailing, this is parameters.\n            return cls(scheme, parse_dict_header(rest), None)\n\n        # No = or only trailing =, this is a token.\n        return cls(scheme, None, rest)\n\n    def to_header(self) -> str:\n        \"\"\"Produce an ``Authorization`` header value representing this data.\n\n        .. versionadded:: 2.0\n        \"\"\"\n        if self.type == \"basic\":\n            value = base64.b64encode(\n                f\"{self.username}:{self.password}\".encode()\n            ).decode(\"ascii\")\n            return f\"Basic {value}\"\n\n        if self.token is not None:\n            return f\"{self.type.title()} {self.token}\"\n\n        return f\"{self.type.title()} {dump_header(self.parameters)}\"\n\n    def __str__(self) -> str:\n        return self.to_header()\n\n    def __repr__(self) -> str:\n        return f\"<{type(self).__name__} {self.to_header()}>\"\n\n\nclass WWWAuthenticate:\n    \"\"\"Represents the parts of a ``WWW-Authenticate`` response header.\n\n    Set :attr:`.Response.www_authenticate` to an instance of list of instances to set\n    values for this header in the response. Modifying this instance will modify the\n    header value.\n\n    Depending on the auth scheme, either :attr:`parameters` or :attr:`token` should be\n    set. The ``Basic`` scheme will encode ``username`` and ``password`` parameters to a\n    token.\n\n    For convenience, ``auth[\"key\"]`` and ``auth.key`` both act on the :attr:`parameters`\n    dict, and can be used to get, set, or delete parameters. ``auth.get(\"key\")`` and\n    ``\"key\" in auth`` are also provided.\n\n    .. versionchanged:: 2.3\n        The ``token`` parameter and attribute was added to support auth schemes that use\n        a token instead of parameters, such as ``Bearer``.\n\n    .. versionchanged:: 2.3\n        The object is no longer a ``dict``.\n\n    .. versionchanged:: 2.3\n        The ``on_update`` parameter was removed.\n    \"\"\"\n\n    def __init__(\n        self,\n        auth_type: str,\n        values: dict[str, str | None] | None = None,\n        token: str | None = None,\n    ):\n        self._type = auth_type.lower()\n        self._parameters: dict[str, str | None] = CallbackDict(\n            values, lambda _: self._trigger_on_update()\n        )\n        self._token = token\n        self._on_update: t.Callable[[WWWAuthenticate], None] | None = None\n\n    def _trigger_on_update(self) -> None:\n        if self._on_update is not None:\n            self._on_update(self)\n\n    @property\n    def type(self) -> str:\n        \"\"\"The authorization scheme, like ``basic``, ``digest``, or ``bearer``.\"\"\"\n        return self._type\n\n    @type.setter\n    def type(self, value: str) -> None:\n        self._type = value\n        self._trigger_on_update()\n\n    @property\n    def parameters(self) -> dict[str, str | None]:\n        \"\"\"A dict of parameters for the header. Only one of this or :attr:`token` should\n        have a value for a given scheme.\n        \"\"\"\n        return self._parameters\n\n    @parameters.setter\n    def parameters(self, value: dict[str, str]) -> None:\n        self._parameters = CallbackDict(value, lambda _: self._trigger_on_update())\n        self._trigger_on_update()\n\n    @property\n    def token(self) -> str | None:\n        \"\"\"A dict of parameters for the header. Only one of this or :attr:`token` should\n        have a value for a given scheme.\n        \"\"\"\n        return self._token\n\n    @token.setter\n    def token(self, value: str | None) -> None:\n        \"\"\"A token for the header. Only one of this or :attr:`parameters` should have a\n        value for a given scheme.\n\n        .. versionadded:: 2.3\n        \"\"\"\n        self._token = value\n        self._trigger_on_update()\n\n    def __getitem__(self, key: str) -> str | None:\n        return self.parameters.get(key)\n\n    def __setitem__(self, key: str, value: str | None) -> None:\n        if value is None:\n            if key in self.parameters:\n                del self.parameters[key]\n        else:\n            self.parameters[key] = value\n\n        self._trigger_on_update()\n\n    def __delitem__(self, key: str) -> None:\n        if key in self.parameters:\n            del self.parameters[key]\n            self._trigger_on_update()\n\n    def __getattr__(self, name: str) -> str | None:\n        return self[name]\n\n    def __setattr__(self, name: str, value: str | None) -> None:\n        if name in {\"_type\", \"_parameters\", \"_token\", \"_on_update\"}:\n            super().__setattr__(name, value)\n        else:\n            self[name] = value\n\n    def __delattr__(self, name: str) -> None:\n        del self[name]\n\n    def __contains__(self, key: str) -> bool:\n        return key in self.parameters\n\n    def __eq__(self, other: object) -> bool:\n        if not isinstance(other, WWWAuthenticate):\n            return NotImplemented\n\n        return (\n            other.type == self.type\n            and other.token == self.token\n            and other.parameters == self.parameters\n        )\n\n    def get(self, key: str, default: str | None = None) -> str | None:\n        return self.parameters.get(key, default)\n\n    @classmethod\n    def from_header(cls, value: str | None) -> te.Self | None:\n        \"\"\"Parse a ``WWW-Authenticate`` header value and return an instance, or ``None``\n        if the value is empty.\n\n        :param value: The header value to parse.\n\n        .. versionadded:: 2.3\n        \"\"\"\n        if not value:\n            return None\n\n        scheme, _, rest = value.partition(\" \")\n        scheme = scheme.lower()\n        rest = rest.strip()\n\n        if \"=\" in rest.rstrip(\"=\"):\n            # = that is not trailing, this is parameters.\n            return cls(scheme, parse_dict_header(rest), None)\n\n        # No = or only trailing =, this is a token.\n        return cls(scheme, None, rest)\n\n    def to_header(self) -> str:\n        \"\"\"Produce a ``WWW-Authenticate`` header value representing this data.\"\"\"\n        if self.token is not None:\n            return f\"{self.type.title()} {self.token}\"\n\n        if self.type == \"digest\":\n            items = []\n\n            for key, value in self.parameters.items():\n                if key in {\"realm\", \"domain\", \"nonce\", \"opaque\", \"qop\"}:\n                    value = quote_header_value(value, allow_token=False)\n                else:\n                    value = quote_header_value(value)\n\n                items.append(f\"{key}={value}\")\n\n            return f\"Digest {', '.join(items)}\"\n\n        return f\"{self.type.title()} {dump_header(self.parameters)}\"\n\n    def __str__(self) -> str:\n        return self.to_header()\n\n    def __repr__(self) -> str:\n        return f\"<{type(self).__name__} {self.to_header()}>\"\n", "src/werkzeug/datastructures/accept.py": "from __future__ import annotations\n\nimport codecs\nimport re\n\nfrom .structures import ImmutableList\n\n\nclass Accept(ImmutableList):\n    \"\"\"An :class:`Accept` object is just a list subclass for lists of\n    ``(value, quality)`` tuples.  It is automatically sorted by specificity\n    and quality.\n\n    All :class:`Accept` objects work similar to a list but provide extra\n    functionality for working with the data.  Containment checks are\n    normalized to the rules of that header:\n\n    >>> a = CharsetAccept([('ISO-8859-1', 1), ('utf-8', 0.7)])\n    >>> a.best\n    'ISO-8859-1'\n    >>> 'iso-8859-1' in a\n    True\n    >>> 'UTF8' in a\n    True\n    >>> 'utf7' in a\n    False\n\n    To get the quality for an item you can use normal item lookup:\n\n    >>> print a['utf-8']\n    0.7\n    >>> a['utf7']\n    0\n\n    .. versionchanged:: 0.5\n       :class:`Accept` objects are forced immutable now.\n\n    .. versionchanged:: 1.0.0\n       :class:`Accept` internal values are no longer ordered\n       alphabetically for equal quality tags. Instead the initial\n       order is preserved.\n\n    \"\"\"\n\n    def __init__(self, values=()):\n        if values is None:\n            list.__init__(self)\n            self.provided = False\n        elif isinstance(values, Accept):\n            self.provided = values.provided\n            list.__init__(self, values)\n        else:\n            self.provided = True\n            values = sorted(\n                values, key=lambda x: (self._specificity(x[0]), x[1]), reverse=True\n            )\n            list.__init__(self, values)\n\n    def _specificity(self, value):\n        \"\"\"Returns a tuple describing the value's specificity.\"\"\"\n        return (value != \"*\",)\n\n    def _value_matches(self, value, item):\n        \"\"\"Check if a value matches a given accept item.\"\"\"\n        return item == \"*\" or item.lower() == value.lower()\n\n    def __getitem__(self, key):\n        \"\"\"Besides index lookup (getting item n) you can also pass it a string\n        to get the quality for the item.  If the item is not in the list, the\n        returned quality is ``0``.\n        \"\"\"\n        if isinstance(key, str):\n            return self.quality(key)\n        return list.__getitem__(self, key)\n\n    def quality(self, key):\n        \"\"\"Returns the quality of the key.\n\n        .. versionadded:: 0.6\n           In previous versions you had to use the item-lookup syntax\n           (eg: ``obj[key]`` instead of ``obj.quality(key)``)\n        \"\"\"\n        for item, quality in self:\n            if self._value_matches(key, item):\n                return quality\n        return 0\n\n    def __contains__(self, value):\n        for item, _quality in self:\n            if self._value_matches(value, item):\n                return True\n        return False\n\n    def __repr__(self):\n        pairs_str = \", \".join(f\"({x!r}, {y})\" for x, y in self)\n        return f\"{type(self).__name__}([{pairs_str}])\"\n\n    def index(self, key):\n        \"\"\"Get the position of an entry or raise :exc:`ValueError`.\n\n        :param key: The key to be looked up.\n\n        .. versionchanged:: 0.5\n           This used to raise :exc:`IndexError`, which was inconsistent\n           with the list API.\n        \"\"\"\n        if isinstance(key, str):\n            for idx, (item, _quality) in enumerate(self):\n                if self._value_matches(key, item):\n                    return idx\n            raise ValueError(key)\n        return list.index(self, key)\n\n    def find(self, key):\n        \"\"\"Get the position of an entry or return -1.\n\n        :param key: The key to be looked up.\n        \"\"\"\n        try:\n            return self.index(key)\n        except ValueError:\n            return -1\n\n    def values(self):\n        \"\"\"Iterate over all values.\"\"\"\n        for item in self:\n            yield item[0]\n\n    def to_header(self):\n        \"\"\"Convert the header set into an HTTP header string.\"\"\"\n        result = []\n        for value, quality in self:\n            if quality != 1:\n                value = f\"{value};q={quality}\"\n            result.append(value)\n        return \",\".join(result)\n\n    def __str__(self):\n        return self.to_header()\n\n    def _best_single_match(self, match):\n        for client_item, quality in self:\n            if self._value_matches(match, client_item):\n                # self is sorted by specificity descending, we can exit\n                return client_item, quality\n        return None\n\n    def best_match(self, matches, default=None):\n        \"\"\"Returns the best match from a list of possible matches based\n        on the specificity and quality of the client. If two items have the\n        same quality and specificity, the one is returned that comes first.\n\n        :param matches: a list of matches to check for\n        :param default: the value that is returned if none match\n        \"\"\"\n        result = default\n        best_quality = -1\n        best_specificity = (-1,)\n        for server_item in matches:\n            match = self._best_single_match(server_item)\n            if not match:\n                continue\n            client_item, quality = match\n            specificity = self._specificity(client_item)\n            if quality <= 0 or quality < best_quality:\n                continue\n            # better quality or same quality but more specific => better match\n            if quality > best_quality or specificity > best_specificity:\n                result = server_item\n                best_quality = quality\n                best_specificity = specificity\n        return result\n\n    @property\n    def best(self):\n        \"\"\"The best match as value.\"\"\"\n        if self:\n            return self[0][0]\n\n\n_mime_split_re = re.compile(r\"/|(?:\\s*;\\s*)\")\n\n\ndef _normalize_mime(value):\n    return _mime_split_re.split(value.lower())\n\n\nclass MIMEAccept(Accept):\n    \"\"\"Like :class:`Accept` but with special methods and behavior for\n    mimetypes.\n    \"\"\"\n\n    def _specificity(self, value):\n        return tuple(x != \"*\" for x in _mime_split_re.split(value))\n\n    def _value_matches(self, value, item):\n        # item comes from the client, can't match if it's invalid.\n        if \"/\" not in item:\n            return False\n\n        # value comes from the application, tell the developer when it\n        # doesn't look valid.\n        if \"/\" not in value:\n            raise ValueError(f\"invalid mimetype {value!r}\")\n\n        # Split the match value into type, subtype, and a sorted list of parameters.\n        normalized_value = _normalize_mime(value)\n        value_type, value_subtype = normalized_value[:2]\n        value_params = sorted(normalized_value[2:])\n\n        # \"*/*\" is the only valid value that can start with \"*\".\n        if value_type == \"*\" and value_subtype != \"*\":\n            raise ValueError(f\"invalid mimetype {value!r}\")\n\n        # Split the accept item into type, subtype, and parameters.\n        normalized_item = _normalize_mime(item)\n        item_type, item_subtype = normalized_item[:2]\n        item_params = sorted(normalized_item[2:])\n\n        # \"*/not-*\" from the client is invalid, can't match.\n        if item_type == \"*\" and item_subtype != \"*\":\n            return False\n\n        return (\n            (item_type == \"*\" and item_subtype == \"*\")\n            or (value_type == \"*\" and value_subtype == \"*\")\n        ) or (\n            item_type == value_type\n            and (\n                item_subtype == \"*\"\n                or value_subtype == \"*\"\n                or (item_subtype == value_subtype and item_params == value_params)\n            )\n        )\n\n    @property\n    def accept_html(self):\n        \"\"\"True if this object accepts HTML.\"\"\"\n        return (\n            \"text/html\" in self or \"application/xhtml+xml\" in self or self.accept_xhtml\n        )\n\n    @property\n    def accept_xhtml(self):\n        \"\"\"True if this object accepts XHTML.\"\"\"\n        return \"application/xhtml+xml\" in self or \"application/xml\" in self\n\n    @property\n    def accept_json(self):\n        \"\"\"True if this object accepts JSON.\"\"\"\n        return \"application/json\" in self\n\n\n_locale_delim_re = re.compile(r\"[_-]\")\n\n\ndef _normalize_lang(value):\n    \"\"\"Process a language tag for matching.\"\"\"\n    return _locale_delim_re.split(value.lower())\n\n\nclass LanguageAccept(Accept):\n    \"\"\"Like :class:`Accept` but with normalization for language tags.\"\"\"\n\n    def _value_matches(self, value, item):\n        return item == \"*\" or _normalize_lang(value) == _normalize_lang(item)\n\n    def best_match(self, matches, default=None):\n        \"\"\"Given a list of supported values, finds the best match from\n        the list of accepted values.\n\n        Language tags are normalized for the purpose of matching, but\n        are returned unchanged.\n\n        If no exact match is found, this will fall back to matching\n        the first subtag (primary language only), first with the\n        accepted values then with the match values. This partial is not\n        applied to any other language subtags.\n\n        The default is returned if no exact or fallback match is found.\n\n        :param matches: A list of supported languages to find a match.\n        :param default: The value that is returned if none match.\n        \"\"\"\n        # Look for an exact match first. If a client accepts \"en-US\",\n        # \"en-US\" is a valid match at this point.\n        result = super().best_match(matches)\n\n        if result is not None:\n            return result\n\n        # Fall back to accepting primary tags. If a client accepts\n        # \"en-US\", \"en\" is a valid match at this point. Need to use\n        # re.split to account for 2 or 3 letter codes.\n        fallback = Accept(\n            [(_locale_delim_re.split(item[0], 1)[0], item[1]) for item in self]\n        )\n        result = fallback.best_match(matches)\n\n        if result is not None:\n            return result\n\n        # Fall back to matching primary tags. If the client accepts\n        # \"en\", \"en-US\" is a valid match at this point.\n        fallback_matches = [_locale_delim_re.split(item, 1)[0] for item in matches]\n        result = super().best_match(fallback_matches)\n\n        # Return a value from the original match list. Find the first\n        # original value that starts with the matched primary tag.\n        if result is not None:\n            return next(item for item in matches if item.startswith(result))\n\n        return default\n\n\nclass CharsetAccept(Accept):\n    \"\"\"Like :class:`Accept` but with normalization for charsets.\"\"\"\n\n    def _value_matches(self, value, item):\n        def _normalize(name):\n            try:\n                return codecs.lookup(name).name\n            except LookupError:\n                return name.lower()\n\n        return item == \"*\" or _normalize(value) == _normalize(item)\n", "src/werkzeug/datastructures/etag.py": "from __future__ import annotations\n\nfrom collections.abc import Collection\n\n\nclass ETags(Collection):\n    \"\"\"A set that can be used to check if one etag is present in a collection\n    of etags.\n    \"\"\"\n\n    def __init__(self, strong_etags=None, weak_etags=None, star_tag=False):\n        if not star_tag and strong_etags:\n            self._strong = frozenset(strong_etags)\n        else:\n            self._strong = frozenset()\n\n        self._weak = frozenset(weak_etags or ())\n        self.star_tag = star_tag\n\n    def as_set(self, include_weak=False):\n        \"\"\"Convert the `ETags` object into a python set.  Per default all the\n        weak etags are not part of this set.\"\"\"\n        rv = set(self._strong)\n        if include_weak:\n            rv.update(self._weak)\n        return rv\n\n    def is_weak(self, etag):\n        \"\"\"Check if an etag is weak.\"\"\"\n        return etag in self._weak\n\n    def is_strong(self, etag):\n        \"\"\"Check if an etag is strong.\"\"\"\n        return etag in self._strong\n\n    def contains_weak(self, etag):\n        \"\"\"Check if an etag is part of the set including weak and strong tags.\"\"\"\n        return self.is_weak(etag) or self.contains(etag)\n\n    def contains(self, etag):\n        \"\"\"Check if an etag is part of the set ignoring weak tags.\n        It is also possible to use the ``in`` operator.\n        \"\"\"\n        if self.star_tag:\n            return True\n        return self.is_strong(etag)\n\n    def contains_raw(self, etag):\n        \"\"\"When passed a quoted tag it will check if this tag is part of the\n        set.  If the tag is weak it is checked against weak and strong tags,\n        otherwise strong only.\"\"\"\n        from ..http import unquote_etag\n\n        etag, weak = unquote_etag(etag)\n        if weak:\n            return self.contains_weak(etag)\n        return self.contains(etag)\n\n    def to_header(self):\n        \"\"\"Convert the etags set into a HTTP header string.\"\"\"\n        if self.star_tag:\n            return \"*\"\n        return \", \".join(\n            [f'\"{x}\"' for x in self._strong] + [f'W/\"{x}\"' for x in self._weak]\n        )\n\n    def __call__(self, etag=None, data=None, include_weak=False):\n        if [etag, data].count(None) != 1:\n            raise TypeError(\"either tag or data required, but at least one\")\n        if etag is None:\n            from ..http import generate_etag\n\n            etag = generate_etag(data)\n        if include_weak:\n            if etag in self._weak:\n                return True\n        return etag in self._strong\n\n    def __bool__(self):\n        return bool(self.star_tag or self._strong or self._weak)\n\n    def __str__(self):\n        return self.to_header()\n\n    def __len__(self):\n        return len(self._strong)\n\n    def __iter__(self):\n        return iter(self._strong)\n\n    def __contains__(self, etag):\n        return self.contains(etag)\n\n    def __repr__(self):\n        return f\"<{type(self).__name__} {str(self)!r}>\"\n", "src/werkzeug/datastructures/structures.py": "from __future__ import annotations\n\nfrom collections.abc import MutableSet\nfrom copy import deepcopy\n\nfrom .. import exceptions\nfrom .._internal import _missing\nfrom .mixins import ImmutableDictMixin\nfrom .mixins import ImmutableListMixin\nfrom .mixins import ImmutableMultiDictMixin\nfrom .mixins import UpdateDictMixin\n\n\ndef is_immutable(self):\n    raise TypeError(f\"{type(self).__name__!r} objects are immutable\")\n\n\ndef iter_multi_items(mapping):\n    \"\"\"Iterates over the items of a mapping yielding keys and values\n    without dropping any from more complex structures.\n    \"\"\"\n    if isinstance(mapping, MultiDict):\n        yield from mapping.items(multi=True)\n    elif isinstance(mapping, dict):\n        for key, value in mapping.items():\n            if isinstance(value, (tuple, list)):\n                for v in value:\n                    yield key, v\n            else:\n                yield key, value\n    else:\n        yield from mapping\n\n\nclass ImmutableList(ImmutableListMixin, list):\n    \"\"\"An immutable :class:`list`.\n\n    .. versionadded:: 0.5\n\n    :private:\n    \"\"\"\n\n    def __repr__(self):\n        return f\"{type(self).__name__}({list.__repr__(self)})\"\n\n\nclass TypeConversionDict(dict):\n    \"\"\"Works like a regular dict but the :meth:`get` method can perform\n    type conversions.  :class:`MultiDict` and :class:`CombinedMultiDict`\n    are subclasses of this class and provide the same feature.\n\n    .. versionadded:: 0.5\n    \"\"\"\n\n    def get(self, key, default=None, type=None):\n        \"\"\"Return the default value if the requested data doesn't exist.\n        If `type` is provided and is a callable it should convert the value,\n        return it or raise a :exc:`ValueError` if that is not possible.  In\n        this case the function will return the default as if the value was not\n        found:\n\n        >>> d = TypeConversionDict(foo='42', bar='blub')\n        >>> d.get('foo', type=int)\n        42\n        >>> d.get('bar', -1, type=int)\n        -1\n\n        :param key: The key to be looked up.\n        :param default: The default value to be returned if the key can't\n                        be looked up.  If not further specified `None` is\n                        returned.\n        :param type: A callable that is used to cast the value in the\n                     :class:`MultiDict`.  If a :exc:`ValueError` or a\n                     :exc:`TypeError` is raised by this callable the default\n                     value is returned.\n\n        .. versionchanged:: 3.0.2\n           Returns the default value on :exc:`TypeError`, too.\n        \"\"\"\n        try:\n            rv = self[key]\n        except KeyError:\n            return default\n        if type is not None:\n            try:\n                rv = type(rv)\n            except (ValueError, TypeError):\n                rv = default\n        return rv\n\n\nclass ImmutableTypeConversionDict(ImmutableDictMixin, TypeConversionDict):\n    \"\"\"Works like a :class:`TypeConversionDict` but does not support\n    modifications.\n\n    .. versionadded:: 0.5\n    \"\"\"\n\n    def copy(self):\n        \"\"\"Return a shallow mutable copy of this object.  Keep in mind that\n        the standard library's :func:`copy` function is a no-op for this class\n        like for any other python immutable type (eg: :class:`tuple`).\n        \"\"\"\n        return TypeConversionDict(self)\n\n    def __copy__(self):\n        return self\n\n\nclass MultiDict(TypeConversionDict):\n    \"\"\"A :class:`MultiDict` is a dictionary subclass customized to deal with\n    multiple values for the same key which is for example used by the parsing\n    functions in the wrappers.  This is necessary because some HTML form\n    elements pass multiple values for the same key.\n\n    :class:`MultiDict` implements all standard dictionary methods.\n    Internally, it saves all values for a key as a list, but the standard dict\n    access methods will only return the first value for a key. If you want to\n    gain access to the other values, too, you have to use the `list` methods as\n    explained below.\n\n    Basic Usage:\n\n    >>> d = MultiDict([('a', 'b'), ('a', 'c')])\n    >>> d\n    MultiDict([('a', 'b'), ('a', 'c')])\n    >>> d['a']\n    'b'\n    >>> d.getlist('a')\n    ['b', 'c']\n    >>> 'a' in d\n    True\n\n    It behaves like a normal dict thus all dict functions will only return the\n    first value when multiple values for one key are found.\n\n    From Werkzeug 0.3 onwards, the `KeyError` raised by this class is also a\n    subclass of the :exc:`~exceptions.BadRequest` HTTP exception and will\n    render a page for a ``400 BAD REQUEST`` if caught in a catch-all for HTTP\n    exceptions.\n\n    A :class:`MultiDict` can be constructed from an iterable of\n    ``(key, value)`` tuples, a dict, a :class:`MultiDict` or from Werkzeug 0.2\n    onwards some keyword parameters.\n\n    :param mapping: the initial value for the :class:`MultiDict`.  Either a\n                    regular dict, an iterable of ``(key, value)`` tuples\n                    or `None`.\n    \"\"\"\n\n    def __init__(self, mapping=None):\n        if isinstance(mapping, MultiDict):\n            dict.__init__(self, ((k, vs[:]) for k, vs in mapping.lists()))\n        elif isinstance(mapping, dict):\n            tmp = {}\n            for key, value in mapping.items():\n                if isinstance(value, (tuple, list)):\n                    if len(value) == 0:\n                        continue\n                    value = list(value)\n                else:\n                    value = [value]\n                tmp[key] = value\n            dict.__init__(self, tmp)\n        else:\n            tmp = {}\n            for key, value in mapping or ():\n                tmp.setdefault(key, []).append(value)\n            dict.__init__(self, tmp)\n\n    def __getstate__(self):\n        return dict(self.lists())\n\n    def __setstate__(self, value):\n        dict.clear(self)\n        dict.update(self, value)\n\n    def __iter__(self):\n        # Work around https://bugs.python.org/issue43246.\n        # (`return super().__iter__()` also works here, which makes this look\n        # even more like it should be a no-op, yet it isn't.)\n        return dict.__iter__(self)\n\n    def __getitem__(self, key):\n        \"\"\"Return the first data value for this key;\n        raises KeyError if not found.\n\n        :param key: The key to be looked up.\n        :raise KeyError: if the key does not exist.\n        \"\"\"\n\n        if key in self:\n            lst = dict.__getitem__(self, key)\n            if len(lst) > 0:\n                return lst[0]\n        raise exceptions.BadRequestKeyError(key)\n\n    def __setitem__(self, key, value):\n        \"\"\"Like :meth:`add` but removes an existing key first.\n\n        :param key: the key for the value.\n        :param value: the value to set.\n        \"\"\"\n        dict.__setitem__(self, key, [value])\n\n    def add(self, key, value):\n        \"\"\"Adds a new value for the key.\n\n        .. versionadded:: 0.6\n\n        :param key: the key for the value.\n        :param value: the value to add.\n        \"\"\"\n        dict.setdefault(self, key, []).append(value)\n\n    def getlist(self, key, type=None):\n        \"\"\"Return the list of items for a given key. If that key is not in the\n        `MultiDict`, the return value will be an empty list.  Just like `get`,\n        `getlist` accepts a `type` parameter.  All items will be converted\n        with the callable defined there.\n\n        :param key: The key to be looked up.\n        :param type: A callable that is used to cast the value in the\n                     :class:`MultiDict`.  If a :exc:`ValueError` is raised\n                     by this callable the value will be removed from the list.\n        :return: a :class:`list` of all the values for the key.\n        \"\"\"\n        try:\n            rv = dict.__getitem__(self, key)\n        except KeyError:\n            return []\n        if type is None:\n            return list(rv)\n        result = []\n        for item in rv:\n            try:\n                result.append(type(item))\n            except ValueError:\n                pass\n        return result\n\n    def setlist(self, key, new_list):\n        \"\"\"Remove the old values for a key and add new ones.  Note that the list\n        you pass the values in will be shallow-copied before it is inserted in\n        the dictionary.\n\n        >>> d = MultiDict()\n        >>> d.setlist('foo', ['1', '2'])\n        >>> d['foo']\n        '1'\n        >>> d.getlist('foo')\n        ['1', '2']\n\n        :param key: The key for which the values are set.\n        :param new_list: An iterable with the new values for the key.  Old values\n                         are removed first.\n        \"\"\"\n        dict.__setitem__(self, key, list(new_list))\n\n    def setdefault(self, key, default=None):\n        \"\"\"Returns the value for the key if it is in the dict, otherwise it\n        returns `default` and sets that value for `key`.\n\n        :param key: The key to be looked up.\n        :param default: The default value to be returned if the key is not\n                        in the dict.  If not further specified it's `None`.\n        \"\"\"\n        if key not in self:\n            self[key] = default\n        else:\n            default = self[key]\n        return default\n\n    def setlistdefault(self, key, default_list=None):\n        \"\"\"Like `setdefault` but sets multiple values.  The list returned\n        is not a copy, but the list that is actually used internally.  This\n        means that you can put new values into the dict by appending items\n        to the list:\n\n        >>> d = MultiDict({\"foo\": 1})\n        >>> d.setlistdefault(\"foo\").extend([2, 3])\n        >>> d.getlist(\"foo\")\n        [1, 2, 3]\n\n        :param key: The key to be looked up.\n        :param default_list: An iterable of default values.  It is either copied\n                             (in case it was a list) or converted into a list\n                             before returned.\n        :return: a :class:`list`\n        \"\"\"\n        if key not in self:\n            default_list = list(default_list or ())\n            dict.__setitem__(self, key, default_list)\n        else:\n            default_list = dict.__getitem__(self, key)\n        return default_list\n\n    def items(self, multi=False):\n        \"\"\"Return an iterator of ``(key, value)`` pairs.\n\n        :param multi: If set to `True` the iterator returned will have a pair\n                      for each value of each key.  Otherwise it will only\n                      contain pairs for the first value of each key.\n        \"\"\"\n        for key, values in dict.items(self):\n            if multi:\n                for value in values:\n                    yield key, value\n            else:\n                yield key, values[0]\n\n    def lists(self):\n        \"\"\"Return a iterator of ``(key, values)`` pairs, where values is the list\n        of all values associated with the key.\"\"\"\n        for key, values in dict.items(self):\n            yield key, list(values)\n\n    def values(self):\n        \"\"\"Returns an iterator of the first value on every key's value list.\"\"\"\n        for values in dict.values(self):\n            yield values[0]\n\n    def listvalues(self):\n        \"\"\"Return an iterator of all values associated with a key.  Zipping\n        :meth:`keys` and this is the same as calling :meth:`lists`:\n\n        >>> d = MultiDict({\"foo\": [1, 2, 3]})\n        >>> zip(d.keys(), d.listvalues()) == d.lists()\n        True\n        \"\"\"\n        return dict.values(self)\n\n    def copy(self):\n        \"\"\"Return a shallow copy of this object.\"\"\"\n        return self.__class__(self)\n\n    def deepcopy(self, memo=None):\n        \"\"\"Return a deep copy of this object.\"\"\"\n        return self.__class__(deepcopy(self.to_dict(flat=False), memo))\n\n    def to_dict(self, flat=True):\n        \"\"\"Return the contents as regular dict.  If `flat` is `True` the\n        returned dict will only have the first item present, if `flat` is\n        `False` all values will be returned as lists.\n\n        :param flat: If set to `False` the dict returned will have lists\n                     with all the values in it.  Otherwise it will only\n                     contain the first value for each key.\n        :return: a :class:`dict`\n        \"\"\"\n        if flat:\n            return dict(self.items())\n        return dict(self.lists())\n\n    def update(self, mapping):\n        \"\"\"update() extends rather than replaces existing key lists:\n\n        >>> a = MultiDict({'x': 1})\n        >>> b = MultiDict({'x': 2, 'y': 3})\n        >>> a.update(b)\n        >>> a\n        MultiDict([('y', 3), ('x', 1), ('x', 2)])\n\n        If the value list for a key in ``other_dict`` is empty, no new values\n        will be added to the dict and the key will not be created:\n\n        >>> x = {'empty_list': []}\n        >>> y = MultiDict()\n        >>> y.update(x)\n        >>> y\n        MultiDict([])\n        \"\"\"\n        for key, value in iter_multi_items(mapping):\n            MultiDict.add(self, key, value)\n\n    def pop(self, key, default=_missing):\n        \"\"\"Pop the first item for a list on the dict.  Afterwards the\n        key is removed from the dict, so additional values are discarded:\n\n        >>> d = MultiDict({\"foo\": [1, 2, 3]})\n        >>> d.pop(\"foo\")\n        1\n        >>> \"foo\" in d\n        False\n\n        :param key: the key to pop.\n        :param default: if provided the value to return if the key was\n                        not in the dictionary.\n        \"\"\"\n        try:\n            lst = dict.pop(self, key)\n\n            if len(lst) == 0:\n                raise exceptions.BadRequestKeyError(key)\n\n            return lst[0]\n        except KeyError:\n            if default is not _missing:\n                return default\n\n            raise exceptions.BadRequestKeyError(key) from None\n\n    def popitem(self):\n        \"\"\"Pop an item from the dict.\"\"\"\n        try:\n            item = dict.popitem(self)\n\n            if len(item[1]) == 0:\n                raise exceptions.BadRequestKeyError(item[0])\n\n            return (item[0], item[1][0])\n        except KeyError as e:\n            raise exceptions.BadRequestKeyError(e.args[0]) from None\n\n    def poplist(self, key):\n        \"\"\"Pop the list for a key from the dict.  If the key is not in the dict\n        an empty list is returned.\n\n        .. versionchanged:: 0.5\n           If the key does no longer exist a list is returned instead of\n           raising an error.\n        \"\"\"\n        return dict.pop(self, key, [])\n\n    def popitemlist(self):\n        \"\"\"Pop a ``(key, list)`` tuple from the dict.\"\"\"\n        try:\n            return dict.popitem(self)\n        except KeyError as e:\n            raise exceptions.BadRequestKeyError(e.args[0]) from None\n\n    def __copy__(self):\n        return self.copy()\n\n    def __deepcopy__(self, memo):\n        return self.deepcopy(memo=memo)\n\n    def __repr__(self):\n        return f\"{type(self).__name__}({list(self.items(multi=True))!r})\"\n\n\nclass _omd_bucket:\n    \"\"\"Wraps values in the :class:`OrderedMultiDict`.  This makes it\n    possible to keep an order over multiple different keys.  It requires\n    a lot of extra memory and slows down access a lot, but makes it\n    possible to access elements in O(1) and iterate in O(n).\n    \"\"\"\n\n    __slots__ = (\"prev\", \"key\", \"value\", \"next\")\n\n    def __init__(self, omd, key, value):\n        self.prev = omd._last_bucket\n        self.key = key\n        self.value = value\n        self.next = None\n\n        if omd._first_bucket is None:\n            omd._first_bucket = self\n        if omd._last_bucket is not None:\n            omd._last_bucket.next = self\n        omd._last_bucket = self\n\n    def unlink(self, omd):\n        if self.prev:\n            self.prev.next = self.next\n        if self.next:\n            self.next.prev = self.prev\n        if omd._first_bucket is self:\n            omd._first_bucket = self.next\n        if omd._last_bucket is self:\n            omd._last_bucket = self.prev\n\n\nclass OrderedMultiDict(MultiDict):\n    \"\"\"Works like a regular :class:`MultiDict` but preserves the\n    order of the fields.  To convert the ordered multi dict into a\n    list you can use the :meth:`items` method and pass it ``multi=True``.\n\n    In general an :class:`OrderedMultiDict` is an order of magnitude\n    slower than a :class:`MultiDict`.\n\n    .. admonition:: note\n\n       Due to a limitation in Python you cannot convert an ordered\n       multi dict into a regular dict by using ``dict(multidict)``.\n       Instead you have to use the :meth:`to_dict` method, otherwise\n       the internal bucket objects are exposed.\n    \"\"\"\n\n    def __init__(self, mapping=None):\n        dict.__init__(self)\n        self._first_bucket = self._last_bucket = None\n        if mapping is not None:\n            OrderedMultiDict.update(self, mapping)\n\n    def __eq__(self, other):\n        if not isinstance(other, MultiDict):\n            return NotImplemented\n        if isinstance(other, OrderedMultiDict):\n            iter1 = iter(self.items(multi=True))\n            iter2 = iter(other.items(multi=True))\n            try:\n                for k1, v1 in iter1:\n                    k2, v2 = next(iter2)\n                    if k1 != k2 or v1 != v2:\n                        return False\n            except StopIteration:\n                return False\n            try:\n                next(iter2)\n            except StopIteration:\n                return True\n            return False\n        if len(self) != len(other):\n            return False\n        for key, values in self.lists():\n            if other.getlist(key) != values:\n                return False\n        return True\n\n    __hash__ = None\n\n    def __reduce_ex__(self, protocol):\n        return type(self), (list(self.items(multi=True)),)\n\n    def __getstate__(self):\n        return list(self.items(multi=True))\n\n    def __setstate__(self, values):\n        dict.clear(self)\n        for key, value in values:\n            self.add(key, value)\n\n    def __getitem__(self, key):\n        if key in self:\n            return dict.__getitem__(self, key)[0].value\n        raise exceptions.BadRequestKeyError(key)\n\n    def __setitem__(self, key, value):\n        self.poplist(key)\n        self.add(key, value)\n\n    def __delitem__(self, key):\n        self.pop(key)\n\n    def keys(self):\n        return (key for key, value in self.items())\n\n    def __iter__(self):\n        return iter(self.keys())\n\n    def values(self):\n        return (value for key, value in self.items())\n\n    def items(self, multi=False):\n        ptr = self._first_bucket\n        if multi:\n            while ptr is not None:\n                yield ptr.key, ptr.value\n                ptr = ptr.next\n        else:\n            returned_keys = set()\n            while ptr is not None:\n                if ptr.key not in returned_keys:\n                    returned_keys.add(ptr.key)\n                    yield ptr.key, ptr.value\n                ptr = ptr.next\n\n    def lists(self):\n        returned_keys = set()\n        ptr = self._first_bucket\n        while ptr is not None:\n            if ptr.key not in returned_keys:\n                yield ptr.key, self.getlist(ptr.key)\n                returned_keys.add(ptr.key)\n            ptr = ptr.next\n\n    def listvalues(self):\n        for _key, values in self.lists():\n            yield values\n\n    def add(self, key, value):\n        dict.setdefault(self, key, []).append(_omd_bucket(self, key, value))\n\n    def getlist(self, key, type=None):\n        try:\n            rv = dict.__getitem__(self, key)\n        except KeyError:\n            return []\n        if type is None:\n            return [x.value for x in rv]\n        result = []\n        for item in rv:\n            try:\n                result.append(type(item.value))\n            except ValueError:\n                pass\n        return result\n\n    def setlist(self, key, new_list):\n        self.poplist(key)\n        for value in new_list:\n            self.add(key, value)\n\n    def setlistdefault(self, key, default_list=None):\n        raise TypeError(\"setlistdefault is unsupported for ordered multi dicts\")\n\n    def update(self, mapping):\n        for key, value in iter_multi_items(mapping):\n            OrderedMultiDict.add(self, key, value)\n\n    def poplist(self, key):\n        buckets = dict.pop(self, key, ())\n        for bucket in buckets:\n            bucket.unlink(self)\n        return [x.value for x in buckets]\n\n    def pop(self, key, default=_missing):\n        try:\n            buckets = dict.pop(self, key)\n        except KeyError:\n            if default is not _missing:\n                return default\n\n            raise exceptions.BadRequestKeyError(key) from None\n\n        for bucket in buckets:\n            bucket.unlink(self)\n\n        return buckets[0].value\n\n    def popitem(self):\n        try:\n            key, buckets = dict.popitem(self)\n        except KeyError as e:\n            raise exceptions.BadRequestKeyError(e.args[0]) from None\n\n        for bucket in buckets:\n            bucket.unlink(self)\n\n        return key, buckets[0].value\n\n    def popitemlist(self):\n        try:\n            key, buckets = dict.popitem(self)\n        except KeyError as e:\n            raise exceptions.BadRequestKeyError(e.args[0]) from None\n\n        for bucket in buckets:\n            bucket.unlink(self)\n\n        return key, [x.value for x in buckets]\n\n\nclass CombinedMultiDict(ImmutableMultiDictMixin, MultiDict):\n    \"\"\"A read only :class:`MultiDict` that you can pass multiple :class:`MultiDict`\n    instances as sequence and it will combine the return values of all wrapped\n    dicts:\n\n    >>> from werkzeug.datastructures import CombinedMultiDict, MultiDict\n    >>> post = MultiDict([('foo', 'bar')])\n    >>> get = MultiDict([('blub', 'blah')])\n    >>> combined = CombinedMultiDict([get, post])\n    >>> combined['foo']\n    'bar'\n    >>> combined['blub']\n    'blah'\n\n    This works for all read operations and will raise a `TypeError` for\n    methods that usually change data which isn't possible.\n\n    From Werkzeug 0.3 onwards, the `KeyError` raised by this class is also a\n    subclass of the :exc:`~exceptions.BadRequest` HTTP exception and will\n    render a page for a ``400 BAD REQUEST`` if caught in a catch-all for HTTP\n    exceptions.\n    \"\"\"\n\n    def __reduce_ex__(self, protocol):\n        return type(self), (self.dicts,)\n\n    def __init__(self, dicts=None):\n        self.dicts = list(dicts) or []\n\n    @classmethod\n    def fromkeys(cls, keys, value=None):\n        raise TypeError(f\"cannot create {cls.__name__!r} instances by fromkeys\")\n\n    def __getitem__(self, key):\n        for d in self.dicts:\n            if key in d:\n                return d[key]\n        raise exceptions.BadRequestKeyError(key)\n\n    def get(self, key, default=None, type=None):\n        for d in self.dicts:\n            if key in d:\n                if type is not None:\n                    try:\n                        return type(d[key])\n                    except ValueError:\n                        continue\n                return d[key]\n        return default\n\n    def getlist(self, key, type=None):\n        rv = []\n        for d in self.dicts:\n            rv.extend(d.getlist(key, type))\n        return rv\n\n    def _keys_impl(self):\n        \"\"\"This function exists so __len__ can be implemented more efficiently,\n        saving one list creation from an iterator.\n        \"\"\"\n        rv = set()\n        rv.update(*self.dicts)\n        return rv\n\n    def keys(self):\n        return self._keys_impl()\n\n    def __iter__(self):\n        return iter(self.keys())\n\n    def items(self, multi=False):\n        found = set()\n        for d in self.dicts:\n            for key, value in d.items(multi):\n                if multi:\n                    yield key, value\n                elif key not in found:\n                    found.add(key)\n                    yield key, value\n\n    def values(self):\n        for _key, value in self.items():\n            yield value\n\n    def lists(self):\n        rv = {}\n        for d in self.dicts:\n            for key, values in d.lists():\n                rv.setdefault(key, []).extend(values)\n        return list(rv.items())\n\n    def listvalues(self):\n        return (x[1] for x in self.lists())\n\n    def copy(self):\n        \"\"\"Return a shallow mutable copy of this object.\n\n        This returns a :class:`MultiDict` representing the data at the\n        time of copying. The copy will no longer reflect changes to the\n        wrapped dicts.\n\n        .. versionchanged:: 0.15\n            Return a mutable :class:`MultiDict`.\n        \"\"\"\n        return MultiDict(self)\n\n    def to_dict(self, flat=True):\n        \"\"\"Return the contents as regular dict.  If `flat` is `True` the\n        returned dict will only have the first item present, if `flat` is\n        `False` all values will be returned as lists.\n\n        :param flat: If set to `False` the dict returned will have lists\n                     with all the values in it.  Otherwise it will only\n                     contain the first item for each key.\n        :return: a :class:`dict`\n        \"\"\"\n        if flat:\n            return dict(self.items())\n\n        return dict(self.lists())\n\n    def __len__(self):\n        return len(self._keys_impl())\n\n    def __contains__(self, key):\n        for d in self.dicts:\n            if key in d:\n                return True\n        return False\n\n    def __repr__(self):\n        return f\"{type(self).__name__}({self.dicts!r})\"\n\n\nclass ImmutableDict(ImmutableDictMixin, dict):\n    \"\"\"An immutable :class:`dict`.\n\n    .. versionadded:: 0.5\n    \"\"\"\n\n    def __repr__(self):\n        return f\"{type(self).__name__}({dict.__repr__(self)})\"\n\n    def copy(self):\n        \"\"\"Return a shallow mutable copy of this object.  Keep in mind that\n        the standard library's :func:`copy` function is a no-op for this class\n        like for any other python immutable type (eg: :class:`tuple`).\n        \"\"\"\n        return dict(self)\n\n    def __copy__(self):\n        return self\n\n\nclass ImmutableMultiDict(ImmutableMultiDictMixin, MultiDict):\n    \"\"\"An immutable :class:`MultiDict`.\n\n    .. versionadded:: 0.5\n    \"\"\"\n\n    def copy(self):\n        \"\"\"Return a shallow mutable copy of this object.  Keep in mind that\n        the standard library's :func:`copy` function is a no-op for this class\n        like for any other python immutable type (eg: :class:`tuple`).\n        \"\"\"\n        return MultiDict(self)\n\n    def __copy__(self):\n        return self\n\n\nclass ImmutableOrderedMultiDict(ImmutableMultiDictMixin, OrderedMultiDict):\n    \"\"\"An immutable :class:`OrderedMultiDict`.\n\n    .. versionadded:: 0.6\n    \"\"\"\n\n    def _iter_hashitems(self):\n        return enumerate(self.items(multi=True))\n\n    def copy(self):\n        \"\"\"Return a shallow mutable copy of this object.  Keep in mind that\n        the standard library's :func:`copy` function is a no-op for this class\n        like for any other python immutable type (eg: :class:`tuple`).\n        \"\"\"\n        return OrderedMultiDict(self)\n\n    def __copy__(self):\n        return self\n\n\nclass CallbackDict(UpdateDictMixin, dict):\n    \"\"\"A dict that calls a function passed every time something is changed.\n    The function is passed the dict instance.\n    \"\"\"\n\n    def __init__(self, initial=None, on_update=None):\n        dict.__init__(self, initial or ())\n        self.on_update = on_update\n\n    def __repr__(self):\n        return f\"<{type(self).__name__} {dict.__repr__(self)}>\"\n\n\nclass HeaderSet(MutableSet):\n    \"\"\"Similar to the :class:`ETags` class this implements a set-like structure.\n    Unlike :class:`ETags` this is case insensitive and used for vary, allow, and\n    content-language headers.\n\n    If not constructed using the :func:`parse_set_header` function the\n    instantiation works like this:\n\n    >>> hs = HeaderSet(['foo', 'bar', 'baz'])\n    >>> hs\n    HeaderSet(['foo', 'bar', 'baz'])\n    \"\"\"\n\n    def __init__(self, headers=None, on_update=None):\n        self._headers = list(headers or ())\n        self._set = {x.lower() for x in self._headers}\n        self.on_update = on_update\n\n    def add(self, header):\n        \"\"\"Add a new header to the set.\"\"\"\n        self.update((header,))\n\n    def remove(self, header):\n        \"\"\"Remove a header from the set.  This raises an :exc:`KeyError` if the\n        header is not in the set.\n\n        .. versionchanged:: 0.5\n            In older versions a :exc:`IndexError` was raised instead of a\n            :exc:`KeyError` if the object was missing.\n\n        :param header: the header to be removed.\n        \"\"\"\n        key = header.lower()\n        if key not in self._set:\n            raise KeyError(header)\n        self._set.remove(key)\n        for idx, key in enumerate(self._headers):\n            if key.lower() == header:\n                del self._headers[idx]\n                break\n        if self.on_update is not None:\n            self.on_update(self)\n\n    def update(self, iterable):\n        \"\"\"Add all the headers from the iterable to the set.\n\n        :param iterable: updates the set with the items from the iterable.\n        \"\"\"\n        inserted_any = False\n        for header in iterable:\n            key = header.lower()\n            if key not in self._set:\n                self._headers.append(header)\n                self._set.add(key)\n                inserted_any = True\n        if inserted_any and self.on_update is not None:\n            self.on_update(self)\n\n    def discard(self, header):\n        \"\"\"Like :meth:`remove` but ignores errors.\n\n        :param header: the header to be discarded.\n        \"\"\"\n        try:\n            self.remove(header)\n        except KeyError:\n            pass\n\n    def find(self, header):\n        \"\"\"Return the index of the header in the set or return -1 if not found.\n\n        :param header: the header to be looked up.\n        \"\"\"\n        header = header.lower()\n        for idx, item in enumerate(self._headers):\n            if item.lower() == header:\n                return idx\n        return -1\n\n    def index(self, header):\n        \"\"\"Return the index of the header in the set or raise an\n        :exc:`IndexError`.\n\n        :param header: the header to be looked up.\n        \"\"\"\n        rv = self.find(header)\n        if rv < 0:\n            raise IndexError(header)\n        return rv\n\n    def clear(self):\n        \"\"\"Clear the set.\"\"\"\n        self._set.clear()\n        del self._headers[:]\n        if self.on_update is not None:\n            self.on_update(self)\n\n    def as_set(self, preserve_casing=False):\n        \"\"\"Return the set as real python set type.  When calling this, all\n        the items are converted to lowercase and the ordering is lost.\n\n        :param preserve_casing: if set to `True` the items in the set returned\n                                will have the original case like in the\n                                :class:`HeaderSet`, otherwise they will\n                                be lowercase.\n        \"\"\"\n        if preserve_casing:\n            return set(self._headers)\n        return set(self._set)\n\n    def to_header(self):\n        \"\"\"Convert the header set into an HTTP header string.\"\"\"\n        return \", \".join(map(http.quote_header_value, self._headers))\n\n    def __getitem__(self, idx):\n        return self._headers[idx]\n\n    def __delitem__(self, idx):\n        rv = self._headers.pop(idx)\n        self._set.remove(rv.lower())\n        if self.on_update is not None:\n            self.on_update(self)\n\n    def __setitem__(self, idx, value):\n        old = self._headers[idx]\n        self._set.remove(old.lower())\n        self._headers[idx] = value\n        self._set.add(value.lower())\n        if self.on_update is not None:\n            self.on_update(self)\n\n    def __contains__(self, header):\n        return header.lower() in self._set\n\n    def __len__(self):\n        return len(self._set)\n\n    def __iter__(self):\n        return iter(self._headers)\n\n    def __bool__(self):\n        return bool(self._set)\n\n    def __str__(self):\n        return self.to_header()\n\n    def __repr__(self):\n        return f\"{type(self).__name__}({self._headers!r})\"\n\n\n# circular dependencies\nfrom .. import http\n", "src/werkzeug/datastructures/file_storage.py": "from __future__ import annotations\n\nimport mimetypes\nfrom io import BytesIO\nfrom os import fsdecode\nfrom os import fspath\n\nfrom .._internal import _plain_int\nfrom .structures import MultiDict\n\n\nclass FileStorage:\n    \"\"\"The :class:`FileStorage` class is a thin wrapper over incoming files.\n    It is used by the request object to represent uploaded files.  All the\n    attributes of the wrapper stream are proxied by the file storage so\n    it's possible to do ``storage.read()`` instead of the long form\n    ``storage.stream.read()``.\n    \"\"\"\n\n    def __init__(\n        self,\n        stream=None,\n        filename=None,\n        name=None,\n        content_type=None,\n        content_length=None,\n        headers=None,\n    ):\n        self.name = name\n        self.stream = stream or BytesIO()\n\n        # If no filename is provided, attempt to get the filename from\n        # the stream object. Python names special streams like\n        # ``<stderr>`` with angular brackets, skip these streams.\n        if filename is None:\n            filename = getattr(stream, \"name\", None)\n\n            if filename is not None:\n                filename = fsdecode(filename)\n\n            if filename and filename[0] == \"<\" and filename[-1] == \">\":\n                filename = None\n        else:\n            filename = fsdecode(filename)\n\n        self.filename = filename\n\n        if headers is None:\n            from .headers import Headers\n\n            headers = Headers()\n        self.headers = headers\n        if content_type is not None:\n            headers[\"Content-Type\"] = content_type\n        if content_length is not None:\n            headers[\"Content-Length\"] = str(content_length)\n\n    def _parse_content_type(self):\n        if not hasattr(self, \"_parsed_content_type\"):\n            self._parsed_content_type = http.parse_options_header(self.content_type)\n\n    @property\n    def content_type(self):\n        \"\"\"The content-type sent in the header.  Usually not available\"\"\"\n        return self.headers.get(\"content-type\")\n\n    @property\n    def content_length(self):\n        \"\"\"The content-length sent in the header.  Usually not available\"\"\"\n        if \"content-length\" in self.headers:\n            try:\n                return _plain_int(self.headers[\"content-length\"])\n            except ValueError:\n                pass\n\n        return 0\n\n    @property\n    def mimetype(self):\n        \"\"\"Like :attr:`content_type`, but without parameters (eg, without\n        charset, type etc.) and always lowercase.  For example if the content\n        type is ``text/HTML; charset=utf-8`` the mimetype would be\n        ``'text/html'``.\n\n        .. versionadded:: 0.7\n        \"\"\"\n        self._parse_content_type()\n        return self._parsed_content_type[0].lower()\n\n    @property\n    def mimetype_params(self):\n        \"\"\"The mimetype parameters as dict.  For example if the content\n        type is ``text/html; charset=utf-8`` the params would be\n        ``{'charset': 'utf-8'}``.\n\n        .. versionadded:: 0.7\n        \"\"\"\n        self._parse_content_type()\n        return self._parsed_content_type[1]\n\n    def save(self, dst, buffer_size=16384):\n        \"\"\"Save the file to a destination path or file object.  If the\n        destination is a file object you have to close it yourself after the\n        call.  The buffer size is the number of bytes held in memory during\n        the copy process.  It defaults to 16KB.\n\n        For secure file saving also have a look at :func:`secure_filename`.\n\n        :param dst: a filename, :class:`os.PathLike`, or open file\n            object to write to.\n        :param buffer_size: Passed as the ``length`` parameter of\n            :func:`shutil.copyfileobj`.\n\n        .. versionchanged:: 1.0\n            Supports :mod:`pathlib`.\n        \"\"\"\n        from shutil import copyfileobj\n\n        close_dst = False\n\n        if hasattr(dst, \"__fspath__\"):\n            dst = fspath(dst)\n\n        if isinstance(dst, str):\n            dst = open(dst, \"wb\")\n            close_dst = True\n\n        try:\n            copyfileobj(self.stream, dst, buffer_size)\n        finally:\n            if close_dst:\n                dst.close()\n\n    def close(self):\n        \"\"\"Close the underlying file if possible.\"\"\"\n        try:\n            self.stream.close()\n        except Exception:\n            pass\n\n    def __bool__(self):\n        return bool(self.filename)\n\n    def __getattr__(self, name):\n        try:\n            return getattr(self.stream, name)\n        except AttributeError:\n            # SpooledTemporaryFile doesn't implement IOBase, get the\n            # attribute from its backing file instead.\n            # https://github.com/python/cpython/pull/3249\n            if hasattr(self.stream, \"_file\"):\n                return getattr(self.stream._file, name)\n            raise\n\n    def __iter__(self):\n        return iter(self.stream)\n\n    def __repr__(self):\n        return f\"<{type(self).__name__}: {self.filename!r} ({self.content_type!r})>\"\n\n\nclass FileMultiDict(MultiDict):\n    \"\"\"A special :class:`MultiDict` that has convenience methods to add\n    files to it.  This is used for :class:`EnvironBuilder` and generally\n    useful for unittesting.\n\n    .. versionadded:: 0.5\n    \"\"\"\n\n    def add_file(self, name, file, filename=None, content_type=None):\n        \"\"\"Adds a new file to the dict.  `file` can be a file name or\n        a :class:`file`-like or a :class:`FileStorage` object.\n\n        :param name: the name of the field.\n        :param file: a filename or :class:`file`-like object\n        :param filename: an optional filename\n        :param content_type: an optional content type\n        \"\"\"\n        if isinstance(file, FileStorage):\n            value = file\n        else:\n            if isinstance(file, str):\n                if filename is None:\n                    filename = file\n                file = open(file, \"rb\")\n            if filename and content_type is None:\n                content_type = (\n                    mimetypes.guess_type(filename)[0] or \"application/octet-stream\"\n                )\n            value = FileStorage(file, filename, name, content_type)\n\n        self.add(name, value)\n\n\n# circular dependencies\nfrom .. import http\n", "src/werkzeug/datastructures/headers.py": "from __future__ import annotations\n\nimport re\nimport typing as t\n\nfrom .._internal import _missing\nfrom ..exceptions import BadRequestKeyError\nfrom .mixins import ImmutableHeadersMixin\nfrom .structures import iter_multi_items\nfrom .structures import MultiDict\n\n\nclass Headers:\n    \"\"\"An object that stores some headers. It has a dict-like interface,\n    but is ordered, can store the same key multiple times, and iterating\n    yields ``(key, value)`` pairs instead of only keys.\n\n    This data structure is useful if you want a nicer way to handle WSGI\n    headers which are stored as tuples in a list.\n\n    From Werkzeug 0.3 onwards, the :exc:`KeyError` raised by this class is\n    also a subclass of the :class:`~exceptions.BadRequest` HTTP exception\n    and will render a page for a ``400 BAD REQUEST`` if caught in a\n    catch-all for HTTP exceptions.\n\n    Headers is mostly compatible with the Python :class:`wsgiref.headers.Headers`\n    class, with the exception of `__getitem__`.  :mod:`wsgiref` will return\n    `None` for ``headers['missing']``, whereas :class:`Headers` will raise\n    a :class:`KeyError`.\n\n    To create a new ``Headers`` object, pass it a list, dict, or\n    other ``Headers`` object with default values. These values are\n    validated the same way values added later are.\n\n    :param defaults: The list of default values for the :class:`Headers`.\n\n    .. versionchanged:: 2.1.0\n        Default values are validated the same as values added later.\n\n    .. versionchanged:: 0.9\n       This data structure now stores unicode values similar to how the\n       multi dicts do it.  The main difference is that bytes can be set as\n       well which will automatically be latin1 decoded.\n\n    .. versionchanged:: 0.9\n       The :meth:`linked` function was removed without replacement as it\n       was an API that does not support the changes to the encoding model.\n    \"\"\"\n\n    def __init__(self, defaults=None):\n        self._list = []\n        if defaults is not None:\n            self.extend(defaults)\n\n    def __getitem__(self, key, _get_mode=False):\n        if not _get_mode:\n            if isinstance(key, int):\n                return self._list[key]\n            elif isinstance(key, slice):\n                return self.__class__(self._list[key])\n        if not isinstance(key, str):\n            raise BadRequestKeyError(key)\n        ikey = key.lower()\n        for k, v in self._list:\n            if k.lower() == ikey:\n                return v\n        # micro optimization: if we are in get mode we will catch that\n        # exception one stack level down so we can raise a standard\n        # key error instead of our special one.\n        if _get_mode:\n            raise KeyError()\n        raise BadRequestKeyError(key)\n\n    def __eq__(self, other):\n        def lowered(item):\n            return (item[0].lower(),) + item[1:]\n\n        return other.__class__ is self.__class__ and set(\n            map(lowered, other._list)\n        ) == set(map(lowered, self._list))\n\n    __hash__ = None\n\n    def get(self, key, default=None, type=None):\n        \"\"\"Return the default value if the requested data doesn't exist.\n        If `type` is provided and is a callable it should convert the value,\n        return it or raise a :exc:`ValueError` if that is not possible.  In\n        this case the function will return the default as if the value was not\n        found:\n\n        >>> d = Headers([('Content-Length', '42')])\n        >>> d.get('Content-Length', type=int)\n        42\n\n        :param key: The key to be looked up.\n        :param default: The default value to be returned if the key can't\n                        be looked up.  If not further specified `None` is\n                        returned.\n        :param type: A callable that is used to cast the value in the\n                     :class:`Headers`.  If a :exc:`ValueError` is raised\n                     by this callable the default value is returned.\n\n        .. versionchanged:: 3.0\n            The ``as_bytes`` parameter was removed.\n\n        .. versionchanged:: 0.9\n            The ``as_bytes`` parameter was added.\n        \"\"\"\n        try:\n            rv = self.__getitem__(key, _get_mode=True)\n        except KeyError:\n            return default\n        if type is None:\n            return rv\n        try:\n            return type(rv)\n        except ValueError:\n            return default\n\n    def getlist(self, key, type=None):\n        \"\"\"Return the list of items for a given key. If that key is not in the\n        :class:`Headers`, the return value will be an empty list.  Just like\n        :meth:`get`, :meth:`getlist` accepts a `type` parameter.  All items will\n        be converted with the callable defined there.\n\n        :param key: The key to be looked up.\n        :param type: A callable that is used to cast the value in the\n                     :class:`Headers`.  If a :exc:`ValueError` is raised\n                     by this callable the value will be removed from the list.\n        :return: a :class:`list` of all the values for the key.\n\n        .. versionchanged:: 3.0\n            The ``as_bytes`` parameter was removed.\n\n        .. versionchanged:: 0.9\n            The ``as_bytes`` parameter was added.\n        \"\"\"\n        ikey = key.lower()\n        result = []\n        for k, v in self:\n            if k.lower() == ikey:\n                if type is not None:\n                    try:\n                        v = type(v)\n                    except ValueError:\n                        continue\n                result.append(v)\n        return result\n\n    def get_all(self, name):\n        \"\"\"Return a list of all the values for the named field.\n\n        This method is compatible with the :mod:`wsgiref`\n        :meth:`~wsgiref.headers.Headers.get_all` method.\n        \"\"\"\n        return self.getlist(name)\n\n    def items(self, lower=False):\n        for key, value in self:\n            if lower:\n                key = key.lower()\n            yield key, value\n\n    def keys(self, lower=False):\n        for key, _ in self.items(lower):\n            yield key\n\n    def values(self):\n        for _, value in self.items():\n            yield value\n\n    def extend(self, *args, **kwargs):\n        \"\"\"Extend headers in this object with items from another object\n        containing header items as well as keyword arguments.\n\n        To replace existing keys instead of extending, use\n        :meth:`update` instead.\n\n        If provided, the first argument can be another :class:`Headers`\n        object, a :class:`MultiDict`, :class:`dict`, or iterable of\n        pairs.\n\n        .. versionchanged:: 1.0\n            Support :class:`MultiDict`. Allow passing ``kwargs``.\n        \"\"\"\n        if len(args) > 1:\n            raise TypeError(f\"update expected at most 1 arguments, got {len(args)}\")\n\n        if args:\n            for key, value in iter_multi_items(args[0]):\n                self.add(key, value)\n\n        for key, value in iter_multi_items(kwargs):\n            self.add(key, value)\n\n    def __delitem__(self, key, _index_operation=True):\n        if _index_operation and isinstance(key, (int, slice)):\n            del self._list[key]\n            return\n        key = key.lower()\n        new = []\n        for k, v in self._list:\n            if k.lower() != key:\n                new.append((k, v))\n        self._list[:] = new\n\n    def remove(self, key):\n        \"\"\"Remove a key.\n\n        :param key: The key to be removed.\n        \"\"\"\n        return self.__delitem__(key, _index_operation=False)\n\n    def pop(self, key=None, default=_missing):\n        \"\"\"Removes and returns a key or index.\n\n        :param key: The key to be popped.  If this is an integer the item at\n                    that position is removed, if it's a string the value for\n                    that key is.  If the key is omitted or `None` the last\n                    item is removed.\n        :return: an item.\n        \"\"\"\n        if key is None:\n            return self._list.pop()\n        if isinstance(key, int):\n            return self._list.pop(key)\n        try:\n            rv = self[key]\n            self.remove(key)\n        except KeyError:\n            if default is not _missing:\n                return default\n            raise\n        return rv\n\n    def popitem(self):\n        \"\"\"Removes a key or index and returns a (key, value) item.\"\"\"\n        return self.pop()\n\n    def __contains__(self, key):\n        \"\"\"Check if a key is present.\"\"\"\n        try:\n            self.__getitem__(key, _get_mode=True)\n        except KeyError:\n            return False\n        return True\n\n    def __iter__(self):\n        \"\"\"Yield ``(key, value)`` tuples.\"\"\"\n        return iter(self._list)\n\n    def __len__(self):\n        return len(self._list)\n\n    def add(self, _key, _value, **kw):\n        \"\"\"Add a new header tuple to the list.\n\n        Keyword arguments can specify additional parameters for the header\n        value, with underscores converted to dashes::\n\n        >>> d = Headers()\n        >>> d.add('Content-Type', 'text/plain')\n        >>> d.add('Content-Disposition', 'attachment', filename='foo.png')\n\n        The keyword argument dumping uses :func:`dump_options_header`\n        behind the scenes.\n\n        .. versionadded:: 0.4.1\n            keyword arguments were added for :mod:`wsgiref` compatibility.\n        \"\"\"\n        if kw:\n            _value = _options_header_vkw(_value, kw)\n        _value = _str_header_value(_value)\n        self._list.append((_key, _value))\n\n    def add_header(self, _key, _value, **_kw):\n        \"\"\"Add a new header tuple to the list.\n\n        An alias for :meth:`add` for compatibility with the :mod:`wsgiref`\n        :meth:`~wsgiref.headers.Headers.add_header` method.\n        \"\"\"\n        self.add(_key, _value, **_kw)\n\n    def clear(self):\n        \"\"\"Clears all headers.\"\"\"\n        del self._list[:]\n\n    def set(self, _key, _value, **kw):\n        \"\"\"Remove all header tuples for `key` and add a new one.  The newly\n        added key either appears at the end of the list if there was no\n        entry or replaces the first one.\n\n        Keyword arguments can specify additional parameters for the header\n        value, with underscores converted to dashes.  See :meth:`add` for\n        more information.\n\n        .. versionchanged:: 0.6.1\n           :meth:`set` now accepts the same arguments as :meth:`add`.\n\n        :param key: The key to be inserted.\n        :param value: The value to be inserted.\n        \"\"\"\n        if kw:\n            _value = _options_header_vkw(_value, kw)\n        _value = _str_header_value(_value)\n        if not self._list:\n            self._list.append((_key, _value))\n            return\n        listiter = iter(self._list)\n        ikey = _key.lower()\n        for idx, (old_key, _old_value) in enumerate(listiter):\n            if old_key.lower() == ikey:\n                # replace first occurrence\n                self._list[idx] = (_key, _value)\n                break\n        else:\n            self._list.append((_key, _value))\n            return\n        self._list[idx + 1 :] = [t for t in listiter if t[0].lower() != ikey]\n\n    def setlist(self, key, values):\n        \"\"\"Remove any existing values for a header and add new ones.\n\n        :param key: The header key to set.\n        :param values: An iterable of values to set for the key.\n\n        .. versionadded:: 1.0\n        \"\"\"\n        if values:\n            values_iter = iter(values)\n            self.set(key, next(values_iter))\n\n            for value in values_iter:\n                self.add(key, value)\n        else:\n            self.remove(key)\n\n    def setdefault(self, key, default):\n        \"\"\"Return the first value for the key if it is in the headers,\n        otherwise set the header to the value given by ``default`` and\n        return that.\n\n        :param key: The header key to get.\n        :param default: The value to set for the key if it is not in the\n            headers.\n        \"\"\"\n        if key in self:\n            return self[key]\n\n        self.set(key, default)\n        return default\n\n    def setlistdefault(self, key, default):\n        \"\"\"Return the list of values for the key if it is in the\n        headers, otherwise set the header to the list of values given\n        by ``default`` and return that.\n\n        Unlike :meth:`MultiDict.setlistdefault`, modifying the returned\n        list will not affect the headers.\n\n        :param key: The header key to get.\n        :param default: An iterable of values to set for the key if it\n            is not in the headers.\n\n        .. versionadded:: 1.0\n        \"\"\"\n        if key not in self:\n            self.setlist(key, default)\n\n        return self.getlist(key)\n\n    def __setitem__(self, key, value):\n        \"\"\"Like :meth:`set` but also supports index/slice based setting.\"\"\"\n        if isinstance(key, (slice, int)):\n            if isinstance(key, int):\n                value = [value]\n            value = [(k, _str_header_value(v)) for (k, v) in value]\n            if isinstance(key, int):\n                self._list[key] = value[0]\n            else:\n                self._list[key] = value\n        else:\n            self.set(key, value)\n\n    def update(self, *args, **kwargs):\n        \"\"\"Replace headers in this object with items from another\n        headers object and keyword arguments.\n\n        To extend existing keys instead of replacing, use :meth:`extend`\n        instead.\n\n        If provided, the first argument can be another :class:`Headers`\n        object, a :class:`MultiDict`, :class:`dict`, or iterable of\n        pairs.\n\n        .. versionadded:: 1.0\n        \"\"\"\n        if len(args) > 1:\n            raise TypeError(f\"update expected at most 1 arguments, got {len(args)}\")\n\n        if args:\n            mapping = args[0]\n\n            if isinstance(mapping, (Headers, MultiDict)):\n                for key in mapping.keys():\n                    self.setlist(key, mapping.getlist(key))\n            elif isinstance(mapping, dict):\n                for key, value in mapping.items():\n                    if isinstance(value, (list, tuple)):\n                        self.setlist(key, value)\n                    else:\n                        self.set(key, value)\n            else:\n                for key, value in mapping:\n                    self.set(key, value)\n\n        for key, value in kwargs.items():\n            if isinstance(value, (list, tuple)):\n                self.setlist(key, value)\n            else:\n                self.set(key, value)\n\n    def to_wsgi_list(self):\n        \"\"\"Convert the headers into a list suitable for WSGI.\n\n        :return: list\n        \"\"\"\n        return list(self)\n\n    def copy(self):\n        return self.__class__(self._list)\n\n    def __copy__(self):\n        return self.copy()\n\n    def __str__(self):\n        \"\"\"Returns formatted headers suitable for HTTP transmission.\"\"\"\n        strs = []\n        for key, value in self.to_wsgi_list():\n            strs.append(f\"{key}: {value}\")\n        strs.append(\"\\r\\n\")\n        return \"\\r\\n\".join(strs)\n\n    def __repr__(self):\n        return f\"{type(self).__name__}({list(self)!r})\"\n\n\ndef _options_header_vkw(value: str, kw: dict[str, t.Any]):\n    return http.dump_options_header(\n        value, {k.replace(\"_\", \"-\"): v for k, v in kw.items()}\n    )\n\n\n_newline_re = re.compile(r\"[\\r\\n]\")\n\n\ndef _str_header_value(value: t.Any) -> str:\n    if not isinstance(value, str):\n        value = str(value)\n\n    if _newline_re.search(value) is not None:\n        raise ValueError(\"Header values must not contain newline characters.\")\n\n    return value\n\n\nclass EnvironHeaders(ImmutableHeadersMixin, Headers):\n    \"\"\"Read only version of the headers from a WSGI environment.  This\n    provides the same interface as `Headers` and is constructed from\n    a WSGI environment.\n    From Werkzeug 0.3 onwards, the `KeyError` raised by this class is also a\n    subclass of the :exc:`~exceptions.BadRequest` HTTP exception and will\n    render a page for a ``400 BAD REQUEST`` if caught in a catch-all for\n    HTTP exceptions.\n    \"\"\"\n\n    def __init__(self, environ):\n        self.environ = environ\n\n    def __eq__(self, other):\n        return self.environ is other.environ\n\n    __hash__ = None\n\n    def __getitem__(self, key, _get_mode=False):\n        # _get_mode is a no-op for this class as there is no index but\n        # used because get() calls it.\n        if not isinstance(key, str):\n            raise KeyError(key)\n        key = key.upper().replace(\"-\", \"_\")\n        if key in {\"CONTENT_TYPE\", \"CONTENT_LENGTH\"}:\n            return self.environ[key]\n        return self.environ[f\"HTTP_{key}\"]\n\n    def __len__(self):\n        # the iter is necessary because otherwise list calls our\n        # len which would call list again and so forth.\n        return len(list(iter(self)))\n\n    def __iter__(self):\n        for key, value in self.environ.items():\n            if key.startswith(\"HTTP_\") and key not in {\n                \"HTTP_CONTENT_TYPE\",\n                \"HTTP_CONTENT_LENGTH\",\n            }:\n                yield key[5:].replace(\"_\", \"-\").title(), value\n            elif key in {\"CONTENT_TYPE\", \"CONTENT_LENGTH\"} and value:\n                yield key.replace(\"_\", \"-\").title(), value\n\n    def copy(self):\n        raise TypeError(f\"cannot create {type(self).__name__!r} copies\")\n\n\n# circular dependencies\nfrom .. import http\n", "src/werkzeug/datastructures/cache_control.py": "from __future__ import annotations\n\nfrom .mixins import ImmutableDictMixin\nfrom .mixins import UpdateDictMixin\n\n\ndef cache_control_property(key, empty, type):\n    \"\"\"Return a new property object for a cache header. Useful if you\n    want to add support for a cache extension in a subclass.\n\n    .. versionchanged:: 2.0\n        Renamed from ``cache_property``.\n    \"\"\"\n    return property(\n        lambda x: x._get_cache_value(key, empty, type),\n        lambda x, v: x._set_cache_value(key, v, type),\n        lambda x: x._del_cache_value(key),\n        f\"accessor for {key!r}\",\n    )\n\n\nclass _CacheControl(UpdateDictMixin, dict):\n    \"\"\"Subclass of a dict that stores values for a Cache-Control header.  It\n    has accessors for all the cache-control directives specified in RFC 2616.\n    The class does not differentiate between request and response directives.\n\n    Because the cache-control directives in the HTTP header use dashes the\n    python descriptors use underscores for that.\n\n    To get a header of the :class:`CacheControl` object again you can convert\n    the object into a string or call the :meth:`to_header` method.  If you plan\n    to subclass it and add your own items have a look at the sourcecode for\n    that class.\n\n    .. versionchanged:: 2.1.0\n        Setting int properties such as ``max_age`` will convert the\n        value to an int.\n\n    .. versionchanged:: 0.4\n\n       Setting `no_cache` or `private` to boolean `True` will set the implicit\n       none-value which is ``*``:\n\n       >>> cc = ResponseCacheControl()\n       >>> cc.no_cache = True\n       >>> cc\n       <ResponseCacheControl 'no-cache'>\n       >>> cc.no_cache\n       '*'\n       >>> cc.no_cache = None\n       >>> cc\n       <ResponseCacheControl ''>\n\n       In versions before 0.5 the behavior documented here affected the now\n       no longer existing `CacheControl` class.\n    \"\"\"\n\n    no_cache = cache_control_property(\"no-cache\", \"*\", None)\n    no_store = cache_control_property(\"no-store\", None, bool)\n    max_age = cache_control_property(\"max-age\", -1, int)\n    no_transform = cache_control_property(\"no-transform\", None, None)\n\n    def __init__(self, values=(), on_update=None):\n        dict.__init__(self, values or ())\n        self.on_update = on_update\n        self.provided = values is not None\n\n    def _get_cache_value(self, key, empty, type):\n        \"\"\"Used internally by the accessor properties.\"\"\"\n        if type is bool:\n            return key in self\n        if key in self:\n            value = self[key]\n            if value is None:\n                return empty\n            elif type is not None:\n                try:\n                    value = type(value)\n                except ValueError:\n                    pass\n            return value\n        return None\n\n    def _set_cache_value(self, key, value, type):\n        \"\"\"Used internally by the accessor properties.\"\"\"\n        if type is bool:\n            if value:\n                self[key] = None\n            else:\n                self.pop(key, None)\n        else:\n            if value is None:\n                self.pop(key, None)\n            elif value is True:\n                self[key] = None\n            else:\n                if type is not None:\n                    self[key] = type(value)\n                else:\n                    self[key] = value\n\n    def _del_cache_value(self, key):\n        \"\"\"Used internally by the accessor properties.\"\"\"\n        if key in self:\n            del self[key]\n\n    def to_header(self):\n        \"\"\"Convert the stored values into a cache control header.\"\"\"\n        return http.dump_header(self)\n\n    def __str__(self):\n        return self.to_header()\n\n    def __repr__(self):\n        kv_str = \" \".join(f\"{k}={v!r}\" for k, v in sorted(self.items()))\n        return f\"<{type(self).__name__} {kv_str}>\"\n\n    cache_property = staticmethod(cache_control_property)\n\n\nclass RequestCacheControl(ImmutableDictMixin, _CacheControl):\n    \"\"\"A cache control for requests.  This is immutable and gives access\n    to all the request-relevant cache control headers.\n\n    To get a header of the :class:`RequestCacheControl` object again you can\n    convert the object into a string or call the :meth:`to_header` method.  If\n    you plan to subclass it and add your own items have a look at the sourcecode\n    for that class.\n\n    .. versionchanged:: 2.1.0\n        Setting int properties such as ``max_age`` will convert the\n        value to an int.\n\n    .. versionadded:: 0.5\n       In previous versions a `CacheControl` class existed that was used\n       both for request and response.\n    \"\"\"\n\n    max_stale = cache_control_property(\"max-stale\", \"*\", int)\n    min_fresh = cache_control_property(\"min-fresh\", \"*\", int)\n    only_if_cached = cache_control_property(\"only-if-cached\", None, bool)\n\n\nclass ResponseCacheControl(_CacheControl):\n    \"\"\"A cache control for responses.  Unlike :class:`RequestCacheControl`\n    this is mutable and gives access to response-relevant cache control\n    headers.\n\n    To get a header of the :class:`ResponseCacheControl` object again you can\n    convert the object into a string or call the :meth:`to_header` method.  If\n    you plan to subclass it and add your own items have a look at the sourcecode\n    for that class.\n\n    .. versionchanged:: 2.1.1\n        ``s_maxage`` converts the value to an int.\n\n    .. versionchanged:: 2.1.0\n        Setting int properties such as ``max_age`` will convert the\n        value to an int.\n\n    .. versionadded:: 0.5\n       In previous versions a `CacheControl` class existed that was used\n       both for request and response.\n    \"\"\"\n\n    public = cache_control_property(\"public\", None, bool)\n    private = cache_control_property(\"private\", \"*\", None)\n    must_revalidate = cache_control_property(\"must-revalidate\", None, bool)\n    proxy_revalidate = cache_control_property(\"proxy-revalidate\", None, bool)\n    s_maxage = cache_control_property(\"s-maxage\", None, int)\n    immutable = cache_control_property(\"immutable\", None, bool)\n\n\n# circular dependencies\nfrom .. import http\n", "src/werkzeug/datastructures/__init__.py": "from .accept import Accept as Accept\nfrom .accept import CharsetAccept as CharsetAccept\nfrom .accept import LanguageAccept as LanguageAccept\nfrom .accept import MIMEAccept as MIMEAccept\nfrom .auth import Authorization as Authorization\nfrom .auth import WWWAuthenticate as WWWAuthenticate\nfrom .cache_control import RequestCacheControl as RequestCacheControl\nfrom .cache_control import ResponseCacheControl as ResponseCacheControl\nfrom .csp import ContentSecurityPolicy as ContentSecurityPolicy\nfrom .etag import ETags as ETags\nfrom .file_storage import FileMultiDict as FileMultiDict\nfrom .file_storage import FileStorage as FileStorage\nfrom .headers import EnvironHeaders as EnvironHeaders\nfrom .headers import Headers as Headers\nfrom .mixins import ImmutableDictMixin as ImmutableDictMixin\nfrom .mixins import ImmutableHeadersMixin as ImmutableHeadersMixin\nfrom .mixins import ImmutableListMixin as ImmutableListMixin\nfrom .mixins import ImmutableMultiDictMixin as ImmutableMultiDictMixin\nfrom .mixins import UpdateDictMixin as UpdateDictMixin\nfrom .range import ContentRange as ContentRange\nfrom .range import IfRange as IfRange\nfrom .range import Range as Range\nfrom .structures import CallbackDict as CallbackDict\nfrom .structures import CombinedMultiDict as CombinedMultiDict\nfrom .structures import HeaderSet as HeaderSet\nfrom .structures import ImmutableDict as ImmutableDict\nfrom .structures import ImmutableList as ImmutableList\nfrom .structures import ImmutableMultiDict as ImmutableMultiDict\nfrom .structures import ImmutableOrderedMultiDict as ImmutableOrderedMultiDict\nfrom .structures import ImmutableTypeConversionDict as ImmutableTypeConversionDict\nfrom .structures import iter_multi_items as iter_multi_items\nfrom .structures import MultiDict as MultiDict\nfrom .structures import OrderedMultiDict as OrderedMultiDict\nfrom .structures import TypeConversionDict as TypeConversionDict\n", "src/werkzeug/datastructures/range.py": "from __future__ import annotations\n\n\nclass IfRange:\n    \"\"\"Very simple object that represents the `If-Range` header in parsed\n    form.  It will either have neither a etag or date or one of either but\n    never both.\n\n    .. versionadded:: 0.7\n    \"\"\"\n\n    def __init__(self, etag=None, date=None):\n        #: The etag parsed and unquoted.  Ranges always operate on strong\n        #: etags so the weakness information is not necessary.\n        self.etag = etag\n        #: The date in parsed format or `None`.\n        self.date = date\n\n    def to_header(self):\n        \"\"\"Converts the object back into an HTTP header.\"\"\"\n        if self.date is not None:\n            return http.http_date(self.date)\n        if self.etag is not None:\n            return http.quote_etag(self.etag)\n        return \"\"\n\n    def __str__(self):\n        return self.to_header()\n\n    def __repr__(self):\n        return f\"<{type(self).__name__} {str(self)!r}>\"\n\n\nclass Range:\n    \"\"\"Represents a ``Range`` header. All methods only support only\n    bytes as the unit. Stores a list of ranges if given, but the methods\n    only work if only one range is provided.\n\n    :raise ValueError: If the ranges provided are invalid.\n\n    .. versionchanged:: 0.15\n        The ranges passed in are validated.\n\n    .. versionadded:: 0.7\n    \"\"\"\n\n    def __init__(self, units, ranges):\n        #: The units of this range.  Usually \"bytes\".\n        self.units = units\n        #: A list of ``(begin, end)`` tuples for the range header provided.\n        #: The ranges are non-inclusive.\n        self.ranges = ranges\n\n        for start, end in ranges:\n            if start is None or (end is not None and (start < 0 or start >= end)):\n                raise ValueError(f\"{(start, end)} is not a valid range.\")\n\n    def range_for_length(self, length):\n        \"\"\"If the range is for bytes, the length is not None and there is\n        exactly one range and it is satisfiable it returns a ``(start, stop)``\n        tuple, otherwise `None`.\n        \"\"\"\n        if self.units != \"bytes\" or length is None or len(self.ranges) != 1:\n            return None\n        start, end = self.ranges[0]\n        if end is None:\n            end = length\n            if start < 0:\n                start += length\n        if http.is_byte_range_valid(start, end, length):\n            return start, min(end, length)\n        return None\n\n    def make_content_range(self, length):\n        \"\"\"Creates a :class:`~werkzeug.datastructures.ContentRange` object\n        from the current range and given content length.\n        \"\"\"\n        rng = self.range_for_length(length)\n        if rng is not None:\n            return ContentRange(self.units, rng[0], rng[1], length)\n        return None\n\n    def to_header(self):\n        \"\"\"Converts the object back into an HTTP header.\"\"\"\n        ranges = []\n        for begin, end in self.ranges:\n            if end is None:\n                ranges.append(f\"{begin}-\" if begin >= 0 else str(begin))\n            else:\n                ranges.append(f\"{begin}-{end - 1}\")\n        return f\"{self.units}={','.join(ranges)}\"\n\n    def to_content_range_header(self, length):\n        \"\"\"Converts the object into `Content-Range` HTTP header,\n        based on given length\n        \"\"\"\n        range = self.range_for_length(length)\n        if range is not None:\n            return f\"{self.units} {range[0]}-{range[1] - 1}/{length}\"\n        return None\n\n    def __str__(self):\n        return self.to_header()\n\n    def __repr__(self):\n        return f\"<{type(self).__name__} {str(self)!r}>\"\n\n\ndef _callback_property(name):\n    def fget(self):\n        return getattr(self, name)\n\n    def fset(self, value):\n        setattr(self, name, value)\n        if self.on_update is not None:\n            self.on_update(self)\n\n    return property(fget, fset)\n\n\nclass ContentRange:\n    \"\"\"Represents the content range header.\n\n    .. versionadded:: 0.7\n    \"\"\"\n\n    def __init__(self, units, start, stop, length=None, on_update=None):\n        assert http.is_byte_range_valid(start, stop, length), \"Bad range provided\"\n        self.on_update = on_update\n        self.set(start, stop, length, units)\n\n    #: The units to use, usually \"bytes\"\n    units = _callback_property(\"_units\")\n    #: The start point of the range or `None`.\n    start = _callback_property(\"_start\")\n    #: The stop point of the range (non-inclusive) or `None`.  Can only be\n    #: `None` if also start is `None`.\n    stop = _callback_property(\"_stop\")\n    #: The length of the range or `None`.\n    length = _callback_property(\"_length\")\n\n    def set(self, start, stop, length=None, units=\"bytes\"):\n        \"\"\"Simple method to update the ranges.\"\"\"\n        assert http.is_byte_range_valid(start, stop, length), \"Bad range provided\"\n        self._units = units\n        self._start = start\n        self._stop = stop\n        self._length = length\n        if self.on_update is not None:\n            self.on_update(self)\n\n    def unset(self):\n        \"\"\"Sets the units to `None` which indicates that the header should\n        no longer be used.\n        \"\"\"\n        self.set(None, None, units=None)\n\n    def to_header(self):\n        if self.units is None:\n            return \"\"\n        if self.length is None:\n            length = \"*\"\n        else:\n            length = self.length\n        if self.start is None:\n            return f\"{self.units} */{length}\"\n        return f\"{self.units} {self.start}-{self.stop - 1}/{length}\"\n\n    def __bool__(self):\n        return self.units is not None\n\n    def __str__(self):\n        return self.to_header()\n\n    def __repr__(self):\n        return f\"<{type(self).__name__} {str(self)!r}>\"\n\n\n# circular dependencies\nfrom .. import http\n", "src/werkzeug/datastructures/csp.py": "from __future__ import annotations\n\nfrom .mixins import UpdateDictMixin\n\n\ndef csp_property(key):\n    \"\"\"Return a new property object for a content security policy header.\n    Useful if you want to add support for a csp extension in a\n    subclass.\n    \"\"\"\n    return property(\n        lambda x: x._get_value(key),\n        lambda x, v: x._set_value(key, v),\n        lambda x: x._del_value(key),\n        f\"accessor for {key!r}\",\n    )\n\n\nclass ContentSecurityPolicy(UpdateDictMixin, dict):\n    \"\"\"Subclass of a dict that stores values for a Content Security Policy\n    header. It has accessors for all the level 3 policies.\n\n    Because the csp directives in the HTTP header use dashes the\n    python descriptors use underscores for that.\n\n    To get a header of the :class:`ContentSecuirtyPolicy` object again\n    you can convert the object into a string or call the\n    :meth:`to_header` method.  If you plan to subclass it and add your\n    own items have a look at the sourcecode for that class.\n\n    .. versionadded:: 1.0.0\n       Support for Content Security Policy headers was added.\n\n    \"\"\"\n\n    base_uri = csp_property(\"base-uri\")\n    child_src = csp_property(\"child-src\")\n    connect_src = csp_property(\"connect-src\")\n    default_src = csp_property(\"default-src\")\n    font_src = csp_property(\"font-src\")\n    form_action = csp_property(\"form-action\")\n    frame_ancestors = csp_property(\"frame-ancestors\")\n    frame_src = csp_property(\"frame-src\")\n    img_src = csp_property(\"img-src\")\n    manifest_src = csp_property(\"manifest-src\")\n    media_src = csp_property(\"media-src\")\n    navigate_to = csp_property(\"navigate-to\")\n    object_src = csp_property(\"object-src\")\n    prefetch_src = csp_property(\"prefetch-src\")\n    plugin_types = csp_property(\"plugin-types\")\n    report_to = csp_property(\"report-to\")\n    report_uri = csp_property(\"report-uri\")\n    sandbox = csp_property(\"sandbox\")\n    script_src = csp_property(\"script-src\")\n    script_src_attr = csp_property(\"script-src-attr\")\n    script_src_elem = csp_property(\"script-src-elem\")\n    style_src = csp_property(\"style-src\")\n    style_src_attr = csp_property(\"style-src-attr\")\n    style_src_elem = csp_property(\"style-src-elem\")\n    worker_src = csp_property(\"worker-src\")\n\n    def __init__(self, values=(), on_update=None):\n        dict.__init__(self, values or ())\n        self.on_update = on_update\n        self.provided = values is not None\n\n    def _get_value(self, key):\n        \"\"\"Used internally by the accessor properties.\"\"\"\n        return self.get(key)\n\n    def _set_value(self, key, value):\n        \"\"\"Used internally by the accessor properties.\"\"\"\n        if value is None:\n            self.pop(key, None)\n        else:\n            self[key] = value\n\n    def _del_value(self, key):\n        \"\"\"Used internally by the accessor properties.\"\"\"\n        if key in self:\n            del self[key]\n\n    def to_header(self):\n        \"\"\"Convert the stored values into a cache control header.\"\"\"\n        from ..http import dump_csp_header\n\n        return dump_csp_header(self)\n\n    def __str__(self):\n        return self.to_header()\n\n    def __repr__(self):\n        kv_str = \" \".join(f\"{k}={v!r}\" for k, v in sorted(self.items()))\n        return f\"<{type(self).__name__} {kv_str}>\"\n", "src/werkzeug/wrappers/response.py": "from __future__ import annotations\n\nimport json\nimport typing as t\nfrom http import HTTPStatus\nfrom urllib.parse import urljoin\n\nfrom .._internal import _get_environ\nfrom ..datastructures import Headers\nfrom ..http import generate_etag\nfrom ..http import http_date\nfrom ..http import is_resource_modified\nfrom ..http import parse_etags\nfrom ..http import parse_range_header\nfrom ..http import remove_entity_headers\nfrom ..sansio.response import Response as _SansIOResponse\nfrom ..urls import iri_to_uri\nfrom ..utils import cached_property\nfrom ..wsgi import _RangeWrapper\nfrom ..wsgi import ClosingIterator\nfrom ..wsgi import get_current_url\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import StartResponse\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n\n    from .request import Request\n\n\ndef _iter_encoded(iterable: t.Iterable[str | bytes]) -> t.Iterator[bytes]:\n    for item in iterable:\n        if isinstance(item, str):\n            yield item.encode()\n        else:\n            yield item\n\n\nclass Response(_SansIOResponse):\n    \"\"\"Represents an outgoing WSGI HTTP response with body, status, and\n    headers. Has properties and methods for using the functionality\n    defined by various HTTP specs.\n\n    The response body is flexible to support different use cases. The\n    simple form is passing bytes, or a string which will be encoded as\n    UTF-8. Passing an iterable of bytes or strings makes this a\n    streaming response. A generator is particularly useful for building\n    a CSV file in memory or using SSE (Server Sent Events). A file-like\n    object is also iterable, although the\n    :func:`~werkzeug.utils.send_file` helper should be used in that\n    case.\n\n    The response object is itself a WSGI application callable. When\n    called (:meth:`__call__`) with ``environ`` and ``start_response``,\n    it will pass its status and headers to ``start_response`` then\n    return its body as an iterable.\n\n    .. code-block:: python\n\n        from werkzeug.wrappers.response import Response\n\n        def index():\n            return Response(\"Hello, World!\")\n\n        def application(environ, start_response):\n            path = environ.get(\"PATH_INFO\") or \"/\"\n\n            if path == \"/\":\n                response = index()\n            else:\n                response = Response(\"Not Found\", status=404)\n\n            return response(environ, start_response)\n\n    :param response: The data for the body of the response. A string or\n        bytes, or tuple or list of strings or bytes, for a fixed-length\n        response, or any other iterable of strings or bytes for a\n        streaming response. Defaults to an empty body.\n    :param status: The status code for the response. Either an int, in\n        which case the default status message is added, or a string in\n        the form ``{code} {message}``, like ``404 Not Found``. Defaults\n        to 200.\n    :param headers: A :class:`~werkzeug.datastructures.Headers` object,\n        or a list of ``(key, value)`` tuples that will be converted to a\n        ``Headers`` object.\n    :param mimetype: The mime type (content type without charset or\n        other parameters) of the response. If the value starts with\n        ``text/`` (or matches some other special cases), the charset\n        will be added to create the ``content_type``.\n    :param content_type: The full content type of the response.\n        Overrides building the value from ``mimetype``.\n    :param direct_passthrough: Pass the response body directly through\n        as the WSGI iterable. This can be used when the body is a binary\n        file or other iterator of bytes, to skip some unnecessary\n        checks. Use :func:`~werkzeug.utils.send_file` instead of setting\n        this manually.\n\n    .. versionchanged:: 2.1\n        Old ``BaseResponse`` and mixin classes were removed.\n\n    .. versionchanged:: 2.0\n        Combine ``BaseResponse`` and mixins into a single ``Response``\n        class.\n\n    .. versionchanged:: 0.5\n        The ``direct_passthrough`` parameter was added.\n    \"\"\"\n\n    #: if set to `False` accessing properties on the response object will\n    #: not try to consume the response iterator and convert it into a list.\n    #:\n    #: .. versionadded:: 0.6.2\n    #:\n    #:    That attribute was previously called `implicit_seqence_conversion`.\n    #:    (Notice the typo).  If you did use this feature, you have to adapt\n    #:    your code to the name change.\n    implicit_sequence_conversion = True\n\n    #: If a redirect ``Location`` header is a relative URL, make it an\n    #: absolute URL, including scheme and domain.\n    #:\n    #: .. versionchanged:: 2.1\n    #:     This is disabled by default, so responses will send relative\n    #:     redirects.\n    #:\n    #: .. versionadded:: 0.8\n    autocorrect_location_header = False\n\n    #: Should this response object automatically set the content-length\n    #: header if possible?  This is true by default.\n    #:\n    #: .. versionadded:: 0.8\n    automatically_set_content_length = True\n\n    #: The response body to send as the WSGI iterable. A list of strings\n    #: or bytes represents a fixed-length response, any other iterable\n    #: is a streaming response. Strings are encoded to bytes as UTF-8.\n    #:\n    #: Do not set to a plain string or bytes, that will cause sending\n    #: the response to be very inefficient as it will iterate one byte\n    #: at a time.\n    response: t.Iterable[str] | t.Iterable[bytes]\n\n    def __init__(\n        self,\n        response: t.Iterable[bytes] | bytes | t.Iterable[str] | str | None = None,\n        status: int | str | HTTPStatus | None = None,\n        headers: t.Mapping[str, str | t.Iterable[str]]\n        | t.Iterable[tuple[str, str]]\n        | None = None,\n        mimetype: str | None = None,\n        content_type: str | None = None,\n        direct_passthrough: bool = False,\n    ) -> None:\n        super().__init__(\n            status=status,\n            headers=headers,\n            mimetype=mimetype,\n            content_type=content_type,\n        )\n\n        #: Pass the response body directly through as the WSGI iterable.\n        #: This can be used when the body is a binary file or other\n        #: iterator of bytes, to skip some unnecessary checks. Use\n        #: :func:`~werkzeug.utils.send_file` instead of setting this\n        #: manually.\n        self.direct_passthrough = direct_passthrough\n        self._on_close: list[t.Callable[[], t.Any]] = []\n\n        # we set the response after the headers so that if a class changes\n        # the charset attribute, the data is set in the correct charset.\n        if response is None:\n            self.response = []\n        elif isinstance(response, (str, bytes, bytearray)):\n            self.set_data(response)\n        else:\n            self.response = response\n\n    def call_on_close(self, func: t.Callable[[], t.Any]) -> t.Callable[[], t.Any]:\n        \"\"\"Adds a function to the internal list of functions that should\n        be called as part of closing down the response.  Since 0.7 this\n        function also returns the function that was passed so that this\n        can be used as a decorator.\n\n        .. versionadded:: 0.6\n        \"\"\"\n        self._on_close.append(func)\n        return func\n\n    def __repr__(self) -> str:\n        if self.is_sequence:\n            body_info = f\"{sum(map(len, self.iter_encoded()))} bytes\"\n        else:\n            body_info = \"streamed\" if self.is_streamed else \"likely-streamed\"\n        return f\"<{type(self).__name__} {body_info} [{self.status}]>\"\n\n    @classmethod\n    def force_type(\n        cls, response: Response, environ: WSGIEnvironment | None = None\n    ) -> Response:\n        \"\"\"Enforce that the WSGI response is a response object of the current\n        type.  Werkzeug will use the :class:`Response` internally in many\n        situations like the exceptions.  If you call :meth:`get_response` on an\n        exception you will get back a regular :class:`Response` object, even\n        if you are using a custom subclass.\n\n        This method can enforce a given response type, and it will also\n        convert arbitrary WSGI callables into response objects if an environ\n        is provided::\n\n            # convert a Werkzeug response object into an instance of the\n            # MyResponseClass subclass.\n            response = MyResponseClass.force_type(response)\n\n            # convert any WSGI application into a response object\n            response = MyResponseClass.force_type(response, environ)\n\n        This is especially useful if you want to post-process responses in\n        the main dispatcher and use functionality provided by your subclass.\n\n        Keep in mind that this will modify response objects in place if\n        possible!\n\n        :param response: a response object or wsgi application.\n        :param environ: a WSGI environment object.\n        :return: a response object.\n        \"\"\"\n        if not isinstance(response, Response):\n            if environ is None:\n                raise TypeError(\n                    \"cannot convert WSGI application into response\"\n                    \" objects without an environ\"\n                )\n\n            from ..test import run_wsgi_app\n\n            response = Response(*run_wsgi_app(response, environ))\n\n        response.__class__ = cls\n        return response\n\n    @classmethod\n    def from_app(\n        cls, app: WSGIApplication, environ: WSGIEnvironment, buffered: bool = False\n    ) -> Response:\n        \"\"\"Create a new response object from an application output.  This\n        works best if you pass it an application that returns a generator all\n        the time.  Sometimes applications may use the `write()` callable\n        returned by the `start_response` function.  This tries to resolve such\n        edge cases automatically.  But if you don't get the expected output\n        you should set `buffered` to `True` which enforces buffering.\n\n        :param app: the WSGI application to execute.\n        :param environ: the WSGI environment to execute against.\n        :param buffered: set to `True` to enforce buffering.\n        :return: a response object.\n        \"\"\"\n        from ..test import run_wsgi_app\n\n        return cls(*run_wsgi_app(app, environ, buffered))\n\n    @t.overload\n    def get_data(self, as_text: t.Literal[False] = False) -> bytes: ...\n\n    @t.overload\n    def get_data(self, as_text: t.Literal[True]) -> str: ...\n\n    def get_data(self, as_text: bool = False) -> bytes | str:\n        \"\"\"The string representation of the response body.  Whenever you call\n        this property the response iterable is encoded and flattened.  This\n        can lead to unwanted behavior if you stream big data.\n\n        This behavior can be disabled by setting\n        :attr:`implicit_sequence_conversion` to `False`.\n\n        If `as_text` is set to `True` the return value will be a decoded\n        string.\n\n        .. versionadded:: 0.9\n        \"\"\"\n        self._ensure_sequence()\n        rv = b\"\".join(self.iter_encoded())\n\n        if as_text:\n            return rv.decode()\n\n        return rv\n\n    def set_data(self, value: bytes | str) -> None:\n        \"\"\"Sets a new string as response.  The value must be a string or\n        bytes. If a string is set it's encoded to the charset of the\n        response (utf-8 by default).\n\n        .. versionadded:: 0.9\n        \"\"\"\n        if isinstance(value, str):\n            value = value.encode()\n        self.response = [value]\n        if self.automatically_set_content_length:\n            self.headers[\"Content-Length\"] = str(len(value))\n\n    data = property(\n        get_data,\n        set_data,\n        doc=\"A descriptor that calls :meth:`get_data` and :meth:`set_data`.\",\n    )\n\n    def calculate_content_length(self) -> int | None:\n        \"\"\"Returns the content length if available or `None` otherwise.\"\"\"\n        try:\n            self._ensure_sequence()\n        except RuntimeError:\n            return None\n        return sum(len(x) for x in self.iter_encoded())\n\n    def _ensure_sequence(self, mutable: bool = False) -> None:\n        \"\"\"This method can be called by methods that need a sequence.  If\n        `mutable` is true, it will also ensure that the response sequence\n        is a standard Python list.\n\n        .. versionadded:: 0.6\n        \"\"\"\n        if self.is_sequence:\n            # if we need a mutable object, we ensure it's a list.\n            if mutable and not isinstance(self.response, list):\n                self.response = list(self.response)  # type: ignore\n            return\n        if self.direct_passthrough:\n            raise RuntimeError(\n                \"Attempted implicit sequence conversion but the\"\n                \" response object is in direct passthrough mode.\"\n            )\n        if not self.implicit_sequence_conversion:\n            raise RuntimeError(\n                \"The response object required the iterable to be a\"\n                \" sequence, but the implicit conversion was disabled.\"\n                \" Call make_sequence() yourself.\"\n            )\n        self.make_sequence()\n\n    def make_sequence(self) -> None:\n        \"\"\"Converts the response iterator in a list.  By default this happens\n        automatically if required.  If `implicit_sequence_conversion` is\n        disabled, this method is not automatically called and some properties\n        might raise exceptions.  This also encodes all the items.\n\n        .. versionadded:: 0.6\n        \"\"\"\n        if not self.is_sequence:\n            # if we consume an iterable we have to ensure that the close\n            # method of the iterable is called if available when we tear\n            # down the response\n            close = getattr(self.response, \"close\", None)\n            self.response = list(self.iter_encoded())\n            if close is not None:\n                self.call_on_close(close)\n\n    def iter_encoded(self) -> t.Iterator[bytes]:\n        \"\"\"Iter the response encoded with the encoding of the response.\n        If the response object is invoked as WSGI application the return\n        value of this method is used as application iterator unless\n        :attr:`direct_passthrough` was activated.\n        \"\"\"\n        # Encode in a separate function so that self.response is fetched\n        # early.  This allows us to wrap the response with the return\n        # value from get_app_iter or iter_encoded.\n        return _iter_encoded(self.response)\n\n    @property\n    def is_streamed(self) -> bool:\n        \"\"\"If the response is streamed (the response is not an iterable with\n        a length information) this property is `True`.  In this case streamed\n        means that there is no information about the number of iterations.\n        This is usually `True` if a generator is passed to the response object.\n\n        This is useful for checking before applying some sort of post\n        filtering that should not take place for streamed responses.\n        \"\"\"\n        try:\n            len(self.response)  # type: ignore\n        except (TypeError, AttributeError):\n            return True\n        return False\n\n    @property\n    def is_sequence(self) -> bool:\n        \"\"\"If the iterator is buffered, this property will be `True`.  A\n        response object will consider an iterator to be buffered if the\n        response attribute is a list or tuple.\n\n        .. versionadded:: 0.6\n        \"\"\"\n        return isinstance(self.response, (tuple, list))\n\n    def close(self) -> None:\n        \"\"\"Close the wrapped response if possible.  You can also use the object\n        in a with statement which will automatically close it.\n\n        .. versionadded:: 0.9\n           Can now be used in a with statement.\n        \"\"\"\n        if hasattr(self.response, \"close\"):\n            self.response.close()\n        for func in self._on_close:\n            func()\n\n    def __enter__(self) -> Response:\n        return self\n\n    def __exit__(self, exc_type, exc_value, tb):  # type: ignore\n        self.close()\n\n    def freeze(self) -> None:\n        \"\"\"Make the response object ready to be pickled. Does the\n        following:\n\n        *   Buffer the response into a list, ignoring\n            :attr:`implicity_sequence_conversion` and\n            :attr:`direct_passthrough`.\n        *   Set the ``Content-Length`` header.\n        *   Generate an ``ETag`` header if one is not already set.\n\n        .. versionchanged:: 2.1\n            Removed the ``no_etag`` parameter.\n\n        .. versionchanged:: 2.0\n            An ``ETag`` header is always added.\n\n        .. versionchanged:: 0.6\n            The ``Content-Length`` header is set.\n        \"\"\"\n        # Always freeze the encoded response body, ignore\n        # implicit_sequence_conversion and direct_passthrough.\n        self.response = list(self.iter_encoded())\n        self.headers[\"Content-Length\"] = str(sum(map(len, self.response)))\n        self.add_etag()\n\n    def get_wsgi_headers(self, environ: WSGIEnvironment) -> Headers:\n        \"\"\"This is automatically called right before the response is started\n        and returns headers modified for the given environment.  It returns a\n        copy of the headers from the response with some modifications applied\n        if necessary.\n\n        For example the location header (if present) is joined with the root\n        URL of the environment.  Also the content length is automatically set\n        to zero here for certain status codes.\n\n        .. versionchanged:: 0.6\n           Previously that function was called `fix_headers` and modified\n           the response object in place.  Also since 0.6, IRIs in location\n           and content-location headers are handled properly.\n\n           Also starting with 0.6, Werkzeug will attempt to set the content\n           length if it is able to figure it out on its own.  This is the\n           case if all the strings in the response iterable are already\n           encoded and the iterable is buffered.\n\n        :param environ: the WSGI environment of the request.\n        :return: returns a new :class:`~werkzeug.datastructures.Headers`\n                 object.\n        \"\"\"\n        headers = Headers(self.headers)\n        location: str | None = None\n        content_location: str | None = None\n        content_length: str | int | None = None\n        status = self.status_code\n\n        # iterate over the headers to find all values in one go.  Because\n        # get_wsgi_headers is used each response that gives us a tiny\n        # speedup.\n        for key, value in headers:\n            ikey = key.lower()\n            if ikey == \"location\":\n                location = value\n            elif ikey == \"content-location\":\n                content_location = value\n            elif ikey == \"content-length\":\n                content_length = value\n\n        if location is not None:\n            location = iri_to_uri(location)\n\n            if self.autocorrect_location_header:\n                # Make the location header an absolute URL.\n                current_url = get_current_url(environ, strip_querystring=True)\n                current_url = iri_to_uri(current_url)\n                location = urljoin(current_url, location)\n\n            headers[\"Location\"] = location\n\n        # make sure the content location is a URL\n        if content_location is not None:\n            headers[\"Content-Location\"] = iri_to_uri(content_location)\n\n        if 100 <= status < 200 or status == 204:\n            # Per section 3.3.2 of RFC 7230, \"a server MUST NOT send a\n            # Content-Length header field in any response with a status\n            # code of 1xx (Informational) or 204 (No Content).\"\n            headers.remove(\"Content-Length\")\n        elif status == 304:\n            remove_entity_headers(headers)\n\n        # if we can determine the content length automatically, we\n        # should try to do that.  But only if this does not involve\n        # flattening the iterator or encoding of strings in the\n        # response. We however should not do that if we have a 304\n        # response.\n        if (\n            self.automatically_set_content_length\n            and self.is_sequence\n            and content_length is None\n            and status not in (204, 304)\n            and not (100 <= status < 200)\n        ):\n            content_length = sum(len(x) for x in self.iter_encoded())\n            headers[\"Content-Length\"] = str(content_length)\n\n        return headers\n\n    def get_app_iter(self, environ: WSGIEnvironment) -> t.Iterable[bytes]:\n        \"\"\"Returns the application iterator for the given environ.  Depending\n        on the request method and the current status code the return value\n        might be an empty response rather than the one from the response.\n\n        If the request method is `HEAD` or the status code is in a range\n        where the HTTP specification requires an empty response, an empty\n        iterable is returned.\n\n        .. versionadded:: 0.6\n\n        :param environ: the WSGI environment of the request.\n        :return: a response iterable.\n        \"\"\"\n        status = self.status_code\n        if (\n            environ[\"REQUEST_METHOD\"] == \"HEAD\"\n            or 100 <= status < 200\n            or status in (204, 304)\n        ):\n            iterable: t.Iterable[bytes] = ()\n        elif self.direct_passthrough:\n            return self.response  # type: ignore\n        else:\n            iterable = self.iter_encoded()\n        return ClosingIterator(iterable, self.close)\n\n    def get_wsgi_response(\n        self, environ: WSGIEnvironment\n    ) -> tuple[t.Iterable[bytes], str, list[tuple[str, str]]]:\n        \"\"\"Returns the final WSGI response as tuple.  The first item in\n        the tuple is the application iterator, the second the status and\n        the third the list of headers.  The response returned is created\n        specially for the given environment.  For example if the request\n        method in the WSGI environment is ``'HEAD'`` the response will\n        be empty and only the headers and status code will be present.\n\n        .. versionadded:: 0.6\n\n        :param environ: the WSGI environment of the request.\n        :return: an ``(app_iter, status, headers)`` tuple.\n        \"\"\"\n        headers = self.get_wsgi_headers(environ)\n        app_iter = self.get_app_iter(environ)\n        return app_iter, self.status, headers.to_wsgi_list()\n\n    def __call__(\n        self, environ: WSGIEnvironment, start_response: StartResponse\n    ) -> t.Iterable[bytes]:\n        \"\"\"Process this response as WSGI application.\n\n        :param environ: the WSGI environment.\n        :param start_response: the response callable provided by the WSGI\n                               server.\n        :return: an application iterator\n        \"\"\"\n        app_iter, status, headers = self.get_wsgi_response(environ)\n        start_response(status, headers)\n        return app_iter\n\n    # JSON\n\n    #: A module or other object that has ``dumps`` and ``loads``\n    #: functions that match the API of the built-in :mod:`json` module.\n    json_module = json\n\n    @property\n    def json(self) -> t.Any | None:\n        \"\"\"The parsed JSON data if :attr:`mimetype` indicates JSON\n        (:mimetype:`application/json`, see :attr:`is_json`).\n\n        Calls :meth:`get_json` with default arguments.\n        \"\"\"\n        return self.get_json()\n\n    @t.overload\n    def get_json(self, force: bool = ..., silent: t.Literal[False] = ...) -> t.Any: ...\n\n    @t.overload\n    def get_json(self, force: bool = ..., silent: bool = ...) -> t.Any | None: ...\n\n    def get_json(self, force: bool = False, silent: bool = False) -> t.Any | None:\n        \"\"\"Parse :attr:`data` as JSON. Useful during testing.\n\n        If the mimetype does not indicate JSON\n        (:mimetype:`application/json`, see :attr:`is_json`), this\n        returns ``None``.\n\n        Unlike :meth:`Request.get_json`, the result is not cached.\n\n        :param force: Ignore the mimetype and always try to parse JSON.\n        :param silent: Silence parsing errors and return ``None``\n            instead.\n        \"\"\"\n        if not (force or self.is_json):\n            return None\n\n        data = self.get_data()\n\n        try:\n            return self.json_module.loads(data)\n        except ValueError:\n            if not silent:\n                raise\n\n            return None\n\n    # Stream\n\n    @cached_property\n    def stream(self) -> ResponseStream:\n        \"\"\"The response iterable as write-only stream.\"\"\"\n        return ResponseStream(self)\n\n    def _wrap_range_response(self, start: int, length: int) -> None:\n        \"\"\"Wrap existing Response in case of Range Request context.\"\"\"\n        if self.status_code == 206:\n            self.response = _RangeWrapper(self.response, start, length)  # type: ignore\n\n    def _is_range_request_processable(self, environ: WSGIEnvironment) -> bool:\n        \"\"\"Return ``True`` if `Range` header is present and if underlying\n        resource is considered unchanged when compared with `If-Range` header.\n        \"\"\"\n        return (\n            \"HTTP_IF_RANGE\" not in environ\n            or not is_resource_modified(\n                environ,\n                self.headers.get(\"etag\"),\n                None,\n                self.headers.get(\"last-modified\"),\n                ignore_if_range=False,\n            )\n        ) and \"HTTP_RANGE\" in environ\n\n    def _process_range_request(\n        self,\n        environ: WSGIEnvironment,\n        complete_length: int | None,\n        accept_ranges: bool | str,\n    ) -> bool:\n        \"\"\"Handle Range Request related headers (RFC7233).  If `Accept-Ranges`\n        header is valid, and Range Request is processable, we set the headers\n        as described by the RFC, and wrap the underlying response in a\n        RangeWrapper.\n\n        Returns ``True`` if Range Request can be fulfilled, ``False`` otherwise.\n\n        :raises: :class:`~werkzeug.exceptions.RequestedRangeNotSatisfiable`\n                 if `Range` header could not be parsed or satisfied.\n\n        .. versionchanged:: 2.0\n            Returns ``False`` if the length is 0.\n        \"\"\"\n        from ..exceptions import RequestedRangeNotSatisfiable\n\n        if (\n            not accept_ranges\n            or complete_length is None\n            or complete_length == 0\n            or not self._is_range_request_processable(environ)\n        ):\n            return False\n\n        if accept_ranges is True:\n            accept_ranges = \"bytes\"\n\n        parsed_range = parse_range_header(environ.get(\"HTTP_RANGE\"))\n\n        if parsed_range is None:\n            raise RequestedRangeNotSatisfiable(complete_length)\n\n        range_tuple = parsed_range.range_for_length(complete_length)\n        content_range_header = parsed_range.to_content_range_header(complete_length)\n\n        if range_tuple is None or content_range_header is None:\n            raise RequestedRangeNotSatisfiable(complete_length)\n\n        content_length = range_tuple[1] - range_tuple[0]\n        self.headers[\"Content-Length\"] = str(content_length)\n        self.headers[\"Accept-Ranges\"] = accept_ranges\n        self.content_range = content_range_header  # type: ignore\n        self.status_code = 206\n        self._wrap_range_response(range_tuple[0], content_length)\n        return True\n\n    def make_conditional(\n        self,\n        request_or_environ: WSGIEnvironment | Request,\n        accept_ranges: bool | str = False,\n        complete_length: int | None = None,\n    ) -> Response:\n        \"\"\"Make the response conditional to the request.  This method works\n        best if an etag was defined for the response already.  The `add_etag`\n        method can be used to do that.  If called without etag just the date\n        header is set.\n\n        This does nothing if the request method in the request or environ is\n        anything but GET or HEAD.\n\n        For optimal performance when handling range requests, it's recommended\n        that your response data object implements `seekable`, `seek` and `tell`\n        methods as described by :py:class:`io.IOBase`.  Objects returned by\n        :meth:`~werkzeug.wsgi.wrap_file` automatically implement those methods.\n\n        It does not remove the body of the response because that's something\n        the :meth:`__call__` function does for us automatically.\n\n        Returns self so that you can do ``return resp.make_conditional(req)``\n        but modifies the object in-place.\n\n        :param request_or_environ: a request object or WSGI environment to be\n                                   used to make the response conditional\n                                   against.\n        :param accept_ranges: This parameter dictates the value of\n                              `Accept-Ranges` header. If ``False`` (default),\n                              the header is not set. If ``True``, it will be set\n                              to ``\"bytes\"``. If it's a string, it will use this\n                              value.\n        :param complete_length: Will be used only in valid Range Requests.\n                                It will set `Content-Range` complete length\n                                value and compute `Content-Length` real value.\n                                This parameter is mandatory for successful\n                                Range Requests completion.\n        :raises: :class:`~werkzeug.exceptions.RequestedRangeNotSatisfiable`\n                 if `Range` header could not be parsed or satisfied.\n\n        .. versionchanged:: 2.0\n            Range processing is skipped if length is 0 instead of\n            raising a 416 Range Not Satisfiable error.\n        \"\"\"\n        environ = _get_environ(request_or_environ)\n        if environ[\"REQUEST_METHOD\"] in (\"GET\", \"HEAD\"):\n            # if the date is not in the headers, add it now.  We however\n            # will not override an already existing header.  Unfortunately\n            # this header will be overridden by many WSGI servers including\n            # wsgiref.\n            if \"date\" not in self.headers:\n                self.headers[\"Date\"] = http_date()\n            is206 = self._process_range_request(environ, complete_length, accept_ranges)\n            if not is206 and not is_resource_modified(\n                environ,\n                self.headers.get(\"etag\"),\n                None,\n                self.headers.get(\"last-modified\"),\n            ):\n                if parse_etags(environ.get(\"HTTP_IF_MATCH\")):\n                    self.status_code = 412\n                else:\n                    self.status_code = 304\n            if (\n                self.automatically_set_content_length\n                and \"content-length\" not in self.headers\n            ):\n                length = self.calculate_content_length()\n                if length is not None:\n                    self.headers[\"Content-Length\"] = str(length)\n        return self\n\n    def add_etag(self, overwrite: bool = False, weak: bool = False) -> None:\n        \"\"\"Add an etag for the current response if there is none yet.\n\n        .. versionchanged:: 2.0\n            SHA-1 is used to generate the value. MD5 may not be\n            available in some environments.\n        \"\"\"\n        if overwrite or \"etag\" not in self.headers:\n            self.set_etag(generate_etag(self.get_data()), weak)\n\n\nclass ResponseStream:\n    \"\"\"A file descriptor like object used by :meth:`Response.stream` to\n    represent the body of the stream. It directly pushes into the\n    response iterable of the response object.\n    \"\"\"\n\n    mode = \"wb+\"\n\n    def __init__(self, response: Response):\n        self.response = response\n        self.closed = False\n\n    def write(self, value: bytes) -> int:\n        if self.closed:\n            raise ValueError(\"I/O operation on closed file\")\n        self.response._ensure_sequence(mutable=True)\n        self.response.response.append(value)  # type: ignore\n        self.response.headers.pop(\"Content-Length\", None)\n        return len(value)\n\n    def writelines(self, seq: t.Iterable[bytes]) -> None:\n        for item in seq:\n            self.write(item)\n\n    def close(self) -> None:\n        self.closed = True\n\n    def flush(self) -> None:\n        if self.closed:\n            raise ValueError(\"I/O operation on closed file\")\n\n    def isatty(self) -> bool:\n        if self.closed:\n            raise ValueError(\"I/O operation on closed file\")\n        return False\n\n    def tell(self) -> int:\n        self.response._ensure_sequence()\n        return sum(map(len, self.response.response))\n\n    @property\n    def encoding(self) -> str:\n        return \"utf-8\"\n", "src/werkzeug/wrappers/request.py": "from __future__ import annotations\n\nimport collections.abc as cabc\nimport functools\nimport json\nimport typing as t\nfrom io import BytesIO\n\nfrom .._internal import _wsgi_decoding_dance\nfrom ..datastructures import CombinedMultiDict\nfrom ..datastructures import EnvironHeaders\nfrom ..datastructures import FileStorage\nfrom ..datastructures import ImmutableMultiDict\nfrom ..datastructures import iter_multi_items\nfrom ..datastructures import MultiDict\nfrom ..exceptions import BadRequest\nfrom ..exceptions import UnsupportedMediaType\nfrom ..formparser import default_stream_factory\nfrom ..formparser import FormDataParser\nfrom ..sansio.request import Request as _SansIORequest\nfrom ..utils import cached_property\nfrom ..utils import environ_property\nfrom ..wsgi import _get_server\nfrom ..wsgi import get_input_stream\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n\n\nclass Request(_SansIORequest):\n    \"\"\"Represents an incoming WSGI HTTP request, with headers and body\n    taken from the WSGI environment. Has properties and methods for\n    using the functionality defined by various HTTP specs. The data in\n    requests object is read-only.\n\n    Text data is assumed to use UTF-8 encoding, which should be true for\n    the vast majority of modern clients. Using an encoding set by the\n    client is unsafe in Python due to extra encodings it provides, such\n    as ``zip``. To change the assumed encoding, subclass and replace\n    :attr:`charset`.\n\n    :param environ: The WSGI environ is generated by the WSGI server and\n        contains information about the server configuration and client\n        request.\n    :param populate_request: Add this request object to the WSGI environ\n        as ``environ['werkzeug.request']``. Can be useful when\n        debugging.\n    :param shallow: Makes reading from :attr:`stream` (and any method\n        that would read from it) raise a :exc:`RuntimeError`. Useful to\n        prevent consuming the form data in middleware, which would make\n        it unavailable to the final application.\n\n    .. versionchanged:: 3.0\n        The ``charset``, ``url_charset``, and ``encoding_errors`` parameters\n        were removed.\n\n    .. versionchanged:: 2.1\n        Old ``BaseRequest`` and mixin classes were removed.\n\n    .. versionchanged:: 2.1\n        Remove the ``disable_data_descriptor`` attribute.\n\n    .. versionchanged:: 2.0\n        Combine ``BaseRequest`` and mixins into a single ``Request``\n        class.\n\n    .. versionchanged:: 0.5\n        Read-only mode is enforced with immutable classes for all data.\n    \"\"\"\n\n    #: the maximum content length.  This is forwarded to the form data\n    #: parsing function (:func:`parse_form_data`).  When set and the\n    #: :attr:`form` or :attr:`files` attribute is accessed and the\n    #: parsing fails because more than the specified value is transmitted\n    #: a :exc:`~werkzeug.exceptions.RequestEntityTooLarge` exception is raised.\n    #:\n    #: .. versionadded:: 0.5\n    max_content_length: int | None = None\n\n    #: the maximum form field size.  This is forwarded to the form data\n    #: parsing function (:func:`parse_form_data`).  When set and the\n    #: :attr:`form` or :attr:`files` attribute is accessed and the\n    #: data in memory for post data is longer than the specified value a\n    #: :exc:`~werkzeug.exceptions.RequestEntityTooLarge` exception is raised.\n    #:\n    #: .. versionadded:: 0.5\n    max_form_memory_size: int | None = None\n\n    #: The maximum number of multipart parts to parse, passed to\n    #: :attr:`form_data_parser_class`. Parsing form data with more than this\n    #: many parts will raise :exc:`~.RequestEntityTooLarge`.\n    #:\n    #: .. versionadded:: 2.2.3\n    max_form_parts = 1000\n\n    #: The form data parser that should be used.  Can be replaced to customize\n    #: the form date parsing.\n    form_data_parser_class: type[FormDataParser] = FormDataParser\n\n    #: The WSGI environment containing HTTP headers and information from\n    #: the WSGI server.\n    environ: WSGIEnvironment\n\n    #: Set when creating the request object. If ``True``, reading from\n    #: the request body will cause a ``RuntimeException``. Useful to\n    #: prevent modifying the stream from middleware.\n    shallow: bool\n\n    def __init__(\n        self,\n        environ: WSGIEnvironment,\n        populate_request: bool = True,\n        shallow: bool = False,\n    ) -> None:\n        super().__init__(\n            method=environ.get(\"REQUEST_METHOD\", \"GET\"),\n            scheme=environ.get(\"wsgi.url_scheme\", \"http\"),\n            server=_get_server(environ),\n            root_path=_wsgi_decoding_dance(environ.get(\"SCRIPT_NAME\") or \"\"),\n            path=_wsgi_decoding_dance(environ.get(\"PATH_INFO\") or \"\"),\n            query_string=environ.get(\"QUERY_STRING\", \"\").encode(\"latin1\"),\n            headers=EnvironHeaders(environ),\n            remote_addr=environ.get(\"REMOTE_ADDR\"),\n        )\n        self.environ = environ\n        self.shallow = shallow\n\n        if populate_request and not shallow:\n            self.environ[\"werkzeug.request\"] = self\n\n    @classmethod\n    def from_values(cls, *args: t.Any, **kwargs: t.Any) -> Request:\n        \"\"\"Create a new request object based on the values provided.  If\n        environ is given missing values are filled from there.  This method is\n        useful for small scripts when you need to simulate a request from an URL.\n        Do not use this method for unittesting, there is a full featured client\n        object (:class:`Client`) that allows to create multipart requests,\n        support for cookies etc.\n\n        This accepts the same options as the\n        :class:`~werkzeug.test.EnvironBuilder`.\n\n        .. versionchanged:: 0.5\n           This method now accepts the same arguments as\n           :class:`~werkzeug.test.EnvironBuilder`.  Because of this the\n           `environ` parameter is now called `environ_overrides`.\n\n        :return: request object\n        \"\"\"\n        from ..test import EnvironBuilder\n\n        builder = EnvironBuilder(*args, **kwargs)\n        try:\n            return builder.get_request(cls)\n        finally:\n            builder.close()\n\n    @classmethod\n    def application(cls, f: t.Callable[[Request], WSGIApplication]) -> WSGIApplication:\n        \"\"\"Decorate a function as responder that accepts the request as\n        the last argument.  This works like the :func:`responder`\n        decorator but the function is passed the request object as the\n        last argument and the request object will be closed\n        automatically::\n\n            @Request.application\n            def my_wsgi_app(request):\n                return Response('Hello World!')\n\n        As of Werkzeug 0.14 HTTP exceptions are automatically caught and\n        converted to responses instead of failing.\n\n        :param f: the WSGI callable to decorate\n        :return: a new WSGI callable\n        \"\"\"\n        #: return a callable that wraps the -2nd argument with the request\n        #: and calls the function with all the arguments up to that one and\n        #: the request.  The return value is then called with the latest\n        #: two arguments.  This makes it possible to use this decorator for\n        #: both standalone WSGI functions as well as bound methods and\n        #: partially applied functions.\n        from ..exceptions import HTTPException\n\n        @functools.wraps(f)\n        def application(*args: t.Any) -> cabc.Iterable[bytes]:\n            request = cls(args[-2])\n            with request:\n                try:\n                    resp = f(*args[:-2] + (request,))\n                except HTTPException as e:\n                    resp = t.cast(\"WSGIApplication\", e.get_response(args[-2]))\n                return resp(*args[-2:])\n\n        return t.cast(\"WSGIApplication\", application)\n\n    def _get_file_stream(\n        self,\n        total_content_length: int | None,\n        content_type: str | None,\n        filename: str | None = None,\n        content_length: int | None = None,\n    ) -> t.IO[bytes]:\n        \"\"\"Called to get a stream for the file upload.\n\n        This must provide a file-like class with `read()`, `readline()`\n        and `seek()` methods that is both writeable and readable.\n\n        The default implementation returns a temporary file if the total\n        content length is higher than 500KB.  Because many browsers do not\n        provide a content length for the files only the total content\n        length matters.\n\n        :param total_content_length: the total content length of all the\n                                     data in the request combined.  This value\n                                     is guaranteed to be there.\n        :param content_type: the mimetype of the uploaded file.\n        :param filename: the filename of the uploaded file.  May be `None`.\n        :param content_length: the length of this file.  This value is usually\n                               not provided because webbrowsers do not provide\n                               this value.\n        \"\"\"\n        return default_stream_factory(\n            total_content_length=total_content_length,\n            filename=filename,\n            content_type=content_type,\n            content_length=content_length,\n        )\n\n    @property\n    def want_form_data_parsed(self) -> bool:\n        \"\"\"``True`` if the request method carries content. By default\n        this is true if a ``Content-Type`` is sent.\n\n        .. versionadded:: 0.8\n        \"\"\"\n        return bool(self.environ.get(\"CONTENT_TYPE\"))\n\n    def make_form_data_parser(self) -> FormDataParser:\n        \"\"\"Creates the form data parser. Instantiates the\n        :attr:`form_data_parser_class` with some parameters.\n\n        .. versionadded:: 0.8\n        \"\"\"\n        return self.form_data_parser_class(\n            stream_factory=self._get_file_stream,\n            max_form_memory_size=self.max_form_memory_size,\n            max_content_length=self.max_content_length,\n            max_form_parts=self.max_form_parts,\n            cls=self.parameter_storage_class,\n        )\n\n    def _load_form_data(self) -> None:\n        \"\"\"Method used internally to retrieve submitted data.  After calling\n        this sets `form` and `files` on the request object to multi dicts\n        filled with the incoming form data.  As a matter of fact the input\n        stream will be empty afterwards.  You can also call this method to\n        force the parsing of the form data.\n\n        .. versionadded:: 0.8\n        \"\"\"\n        # abort early if we have already consumed the stream\n        if \"form\" in self.__dict__:\n            return\n\n        if self.want_form_data_parsed:\n            parser = self.make_form_data_parser()\n            data = parser.parse(\n                self._get_stream_for_parsing(),\n                self.mimetype,\n                self.content_length,\n                self.mimetype_params,\n            )\n        else:\n            data = (\n                self.stream,\n                self.parameter_storage_class(),\n                self.parameter_storage_class(),\n            )\n\n        # inject the values into the instance dict so that we bypass\n        # our cached_property non-data descriptor.\n        d = self.__dict__\n        d[\"stream\"], d[\"form\"], d[\"files\"] = data\n\n    def _get_stream_for_parsing(self) -> t.IO[bytes]:\n        \"\"\"This is the same as accessing :attr:`stream` with the difference\n        that if it finds cached data from calling :meth:`get_data` first it\n        will create a new stream out of the cached data.\n\n        .. versionadded:: 0.9.3\n        \"\"\"\n        cached_data = getattr(self, \"_cached_data\", None)\n        if cached_data is not None:\n            return BytesIO(cached_data)\n        return self.stream\n\n    def close(self) -> None:\n        \"\"\"Closes associated resources of this request object.  This\n        closes all file handles explicitly.  You can also use the request\n        object in a with statement which will automatically close it.\n\n        .. versionadded:: 0.9\n        \"\"\"\n        files = self.__dict__.get(\"files\")\n        for _key, value in iter_multi_items(files or ()):\n            value.close()\n\n    def __enter__(self) -> Request:\n        return self\n\n    def __exit__(self, exc_type, exc_value, tb) -> None:  # type: ignore\n        self.close()\n\n    @cached_property\n    def stream(self) -> t.IO[bytes]:\n        \"\"\"The WSGI input stream, with safety checks. This stream can only be consumed\n        once.\n\n        Use :meth:`get_data` to get the full data as bytes or text. The :attr:`data`\n        attribute will contain the full bytes only if they do not represent form data.\n        The :attr:`form` attribute will contain the parsed form data in that case.\n\n        Unlike :attr:`input_stream`, this stream guards against infinite streams or\n        reading past :attr:`content_length` or :attr:`max_content_length`.\n\n        If ``max_content_length`` is set, it can be enforced on streams if\n        ``wsgi.input_terminated`` is set. Otherwise, an empty stream is returned.\n\n        If the limit is reached before the underlying stream is exhausted (such as a\n        file that is too large, or an infinite stream), the remaining contents of the\n        stream cannot be read safely. Depending on how the server handles this, clients\n        may show a \"connection reset\" failure instead of seeing the 413 response.\n\n        .. versionchanged:: 2.3\n            Check ``max_content_length`` preemptively and while reading.\n\n        .. versionchanged:: 0.9\n            The stream is always set (but may be consumed) even if form parsing was\n            accessed first.\n        \"\"\"\n        if self.shallow:\n            raise RuntimeError(\n                \"This request was created with 'shallow=True', reading\"\n                \" from the input stream is disabled.\"\n            )\n\n        return get_input_stream(\n            self.environ, max_content_length=self.max_content_length\n        )\n\n    input_stream = environ_property[t.IO[bytes]](\n        \"wsgi.input\",\n        doc=\"\"\"The raw WSGI input stream, without any safety checks.\n\n        This is dangerous to use. It does not guard against infinite streams or reading\n        past :attr:`content_length` or :attr:`max_content_length`.\n\n        Use :attr:`stream` instead.\n        \"\"\",\n    )\n\n    @cached_property\n    def data(self) -> bytes:\n        \"\"\"The raw data read from :attr:`stream`. Will be empty if the request\n        represents form data.\n\n        To get the raw data even if it represents form data, use :meth:`get_data`.\n        \"\"\"\n        return self.get_data(parse_form_data=True)\n\n    @t.overload\n    def get_data(  # type: ignore\n        self,\n        cache: bool = True,\n        as_text: t.Literal[False] = False,\n        parse_form_data: bool = False,\n    ) -> bytes: ...\n\n    @t.overload\n    def get_data(\n        self,\n        cache: bool = True,\n        as_text: t.Literal[True] = ...,\n        parse_form_data: bool = False,\n    ) -> str: ...\n\n    def get_data(\n        self, cache: bool = True, as_text: bool = False, parse_form_data: bool = False\n    ) -> bytes | str:\n        \"\"\"This reads the buffered incoming data from the client into one\n        bytes object.  By default this is cached but that behavior can be\n        changed by setting `cache` to `False`.\n\n        Usually it's a bad idea to call this method without checking the\n        content length first as a client could send dozens of megabytes or more\n        to cause memory problems on the server.\n\n        Note that if the form data was already parsed this method will not\n        return anything as form data parsing does not cache the data like\n        this method does.  To implicitly invoke form data parsing function\n        set `parse_form_data` to `True`.  When this is done the return value\n        of this method will be an empty string if the form parser handles\n        the data.  This generally is not necessary as if the whole data is\n        cached (which is the default) the form parser will used the cached\n        data to parse the form data.  Please be generally aware of checking\n        the content length first in any case before calling this method\n        to avoid exhausting server memory.\n\n        If `as_text` is set to `True` the return value will be a decoded\n        string.\n\n        .. versionadded:: 0.9\n        \"\"\"\n        rv = getattr(self, \"_cached_data\", None)\n        if rv is None:\n            if parse_form_data:\n                self._load_form_data()\n            rv = self.stream.read()\n            if cache:\n                self._cached_data = rv\n        if as_text:\n            rv = rv.decode(errors=\"replace\")\n        return rv\n\n    @cached_property\n    def form(self) -> ImmutableMultiDict[str, str]:\n        \"\"\"The form parameters.  By default an\n        :class:`~werkzeug.datastructures.ImmutableMultiDict`\n        is returned from this function.  This can be changed by setting\n        :attr:`parameter_storage_class` to a different type.  This might\n        be necessary if the order of the form data is important.\n\n        Please keep in mind that file uploads will not end up here, but instead\n        in the :attr:`files` attribute.\n\n        .. versionchanged:: 0.9\n\n            Previous to Werkzeug 0.9 this would only contain form data for POST\n            and PUT requests.\n        \"\"\"\n        self._load_form_data()\n        return self.form\n\n    @cached_property\n    def values(self) -> CombinedMultiDict[str, str]:\n        \"\"\"A :class:`werkzeug.datastructures.CombinedMultiDict` that\n        combines :attr:`args` and :attr:`form`.\n\n        For GET requests, only ``args`` are present, not ``form``.\n\n        .. versionchanged:: 2.0\n            For GET requests, only ``args`` are present, not ``form``.\n        \"\"\"\n        sources = [self.args]\n\n        if self.method != \"GET\":\n            # GET requests can have a body, and some caching proxies\n            # might not treat that differently than a normal GET\n            # request, allowing form data to \"invisibly\" affect the\n            # cache without indication in the query string / URL.\n            sources.append(self.form)\n\n        args = []\n\n        for d in sources:\n            if not isinstance(d, MultiDict):\n                d = MultiDict(d)\n\n            args.append(d)\n\n        return CombinedMultiDict(args)\n\n    @cached_property\n    def files(self) -> ImmutableMultiDict[str, FileStorage]:\n        \"\"\":class:`~werkzeug.datastructures.MultiDict` object containing\n        all uploaded files.  Each key in :attr:`files` is the name from the\n        ``<input type=\"file\" name=\"\">``.  Each value in :attr:`files` is a\n        Werkzeug :class:`~werkzeug.datastructures.FileStorage` object.\n\n        It basically behaves like a standard file object you know from Python,\n        with the difference that it also has a\n        :meth:`~werkzeug.datastructures.FileStorage.save` function that can\n        store the file on the filesystem.\n\n        Note that :attr:`files` will only contain data if the request method was\n        POST, PUT or PATCH and the ``<form>`` that posted to the request had\n        ``enctype=\"multipart/form-data\"``.  It will be empty otherwise.\n\n        See the :class:`~werkzeug.datastructures.MultiDict` /\n        :class:`~werkzeug.datastructures.FileStorage` documentation for\n        more details about the used data structure.\n        \"\"\"\n        self._load_form_data()\n        return self.files\n\n    @property\n    def script_root(self) -> str:\n        \"\"\"Alias for :attr:`self.root_path`. ``environ[\"SCRIPT_ROOT\"]``\n        without a trailing slash.\n        \"\"\"\n        return self.root_path\n\n    @cached_property\n    def url_root(self) -> str:\n        \"\"\"Alias for :attr:`root_url`. The URL with scheme, host, and\n        root path. For example, ``https://example.com/app/``.\n        \"\"\"\n        return self.root_url\n\n    remote_user = environ_property[str](\n        \"REMOTE_USER\",\n        doc=\"\"\"If the server supports user authentication, and the\n        script is protected, this attribute contains the username the\n        user has authenticated as.\"\"\",\n    )\n    is_multithread = environ_property[bool](\n        \"wsgi.multithread\",\n        doc=\"\"\"boolean that is `True` if the application is served by a\n        multithreaded WSGI server.\"\"\",\n    )\n    is_multiprocess = environ_property[bool](\n        \"wsgi.multiprocess\",\n        doc=\"\"\"boolean that is `True` if the application is served by a\n        WSGI server that spawns multiple processes.\"\"\",\n    )\n    is_run_once = environ_property[bool](\n        \"wsgi.run_once\",\n        doc=\"\"\"boolean that is `True` if the application will be\n        executed only once in a process lifetime.  This is the case for\n        CGI for example, but it's not guaranteed that the execution only\n        happens one time.\"\"\",\n    )\n\n    # JSON\n\n    #: A module or other object that has ``dumps`` and ``loads``\n    #: functions that match the API of the built-in :mod:`json` module.\n    json_module = json\n\n    @property\n    def json(self) -> t.Any | None:\n        \"\"\"The parsed JSON data if :attr:`mimetype` indicates JSON\n        (:mimetype:`application/json`, see :attr:`is_json`).\n\n        Calls :meth:`get_json` with default arguments.\n\n        If the request content type is not ``application/json``, this\n        will raise a 415 Unsupported Media Type error.\n\n        .. versionchanged:: 2.3\n            Raise a 415 error instead of 400.\n\n        .. versionchanged:: 2.1\n            Raise a 400 error if the content type is incorrect.\n        \"\"\"\n        return self.get_json()\n\n    # Cached values for ``(silent=False, silent=True)``. Initialized\n    # with sentinel values.\n    _cached_json: tuple[t.Any, t.Any] = (Ellipsis, Ellipsis)\n\n    @t.overload\n    def get_json(\n        self, force: bool = ..., silent: t.Literal[False] = ..., cache: bool = ...\n    ) -> t.Any: ...\n\n    @t.overload\n    def get_json(\n        self, force: bool = ..., silent: bool = ..., cache: bool = ...\n    ) -> t.Any | None: ...\n\n    def get_json(\n        self, force: bool = False, silent: bool = False, cache: bool = True\n    ) -> t.Any | None:\n        \"\"\"Parse :attr:`data` as JSON.\n\n        If the mimetype does not indicate JSON\n        (:mimetype:`application/json`, see :attr:`is_json`), or parsing\n        fails, :meth:`on_json_loading_failed` is called and\n        its return value is used as the return value. By default this\n        raises a 415 Unsupported Media Type resp.\n\n        :param force: Ignore the mimetype and always try to parse JSON.\n        :param silent: Silence mimetype and parsing errors, and\n            return ``None`` instead.\n        :param cache: Store the parsed JSON to return for subsequent\n            calls.\n\n        .. versionchanged:: 2.3\n            Raise a 415 error instead of 400.\n\n        .. versionchanged:: 2.1\n            Raise a 400 error if the content type is incorrect.\n        \"\"\"\n        if cache and self._cached_json[silent] is not Ellipsis:\n            return self._cached_json[silent]\n\n        if not (force or self.is_json):\n            if not silent:\n                return self.on_json_loading_failed(None)\n            else:\n                return None\n\n        data = self.get_data(cache=cache)\n\n        try:\n            rv = self.json_module.loads(data)\n        except ValueError as e:\n            if silent:\n                rv = None\n\n                if cache:\n                    normal_rv, _ = self._cached_json\n                    self._cached_json = (normal_rv, rv)\n            else:\n                rv = self.on_json_loading_failed(e)\n\n                if cache:\n                    _, silent_rv = self._cached_json\n                    self._cached_json = (rv, silent_rv)\n        else:\n            if cache:\n                self._cached_json = (rv, rv)\n\n        return rv\n\n    def on_json_loading_failed(self, e: ValueError | None) -> t.Any:\n        \"\"\"Called if :meth:`get_json` fails and isn't silenced.\n\n        If this method returns a value, it is used as the return value\n        for :meth:`get_json`. The default implementation raises\n        :exc:`~werkzeug.exceptions.BadRequest`.\n\n        :param e: If parsing failed, this is the exception. It will be\n            ``None`` if the content type wasn't ``application/json``.\n\n        .. versionchanged:: 2.3\n            Raise a 415 error instead of 400.\n        \"\"\"\n        if e is not None:\n            raise BadRequest(f\"Failed to decode JSON object: {e}\")\n\n        raise UnsupportedMediaType(\n            \"Did not attempt to load JSON data because the request\"\n            \" Content-Type was not 'application/json'.\"\n        )\n", "src/werkzeug/wrappers/__init__.py": "from .request import Request as Request\nfrom .response import Response as Response\nfrom .response import ResponseStream as ResponseStream\n", "src/werkzeug/sansio/response.py": "from __future__ import annotations\n\nimport typing as t\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom datetime import timezone\nfrom http import HTTPStatus\n\nfrom ..datastructures import CallbackDict\nfrom ..datastructures import ContentRange\nfrom ..datastructures import ContentSecurityPolicy\nfrom ..datastructures import Headers\nfrom ..datastructures import HeaderSet\nfrom ..datastructures import ResponseCacheControl\nfrom ..datastructures import WWWAuthenticate\nfrom ..http import COEP\nfrom ..http import COOP\nfrom ..http import dump_age\nfrom ..http import dump_cookie\nfrom ..http import dump_header\nfrom ..http import dump_options_header\nfrom ..http import http_date\nfrom ..http import HTTP_STATUS_CODES\nfrom ..http import parse_age\nfrom ..http import parse_cache_control_header\nfrom ..http import parse_content_range_header\nfrom ..http import parse_csp_header\nfrom ..http import parse_date\nfrom ..http import parse_options_header\nfrom ..http import parse_set_header\nfrom ..http import quote_etag\nfrom ..http import unquote_etag\nfrom ..utils import get_content_type\nfrom ..utils import header_property\n\nif t.TYPE_CHECKING:\n    from ..datastructures.cache_control import _CacheControl\n\n\ndef _set_property(name: str, doc: str | None = None) -> property:\n    def fget(self: Response) -> HeaderSet:\n        def on_update(header_set: HeaderSet) -> None:\n            if not header_set and name in self.headers:\n                del self.headers[name]\n            elif header_set:\n                self.headers[name] = header_set.to_header()\n\n        return parse_set_header(self.headers.get(name), on_update)\n\n    def fset(\n        self: Response,\n        value: None | (str | dict[str, str | int] | t.Iterable[str]),\n    ) -> None:\n        if not value:\n            del self.headers[name]\n        elif isinstance(value, str):\n            self.headers[name] = value\n        else:\n            self.headers[name] = dump_header(value)\n\n    return property(fget, fset, doc=doc)\n\n\nclass Response:\n    \"\"\"Represents the non-IO parts of an HTTP response, specifically the\n    status and headers but not the body.\n\n    This class is not meant for general use. It should only be used when\n    implementing WSGI, ASGI, or another HTTP application spec. Werkzeug\n    provides a WSGI implementation at :cls:`werkzeug.wrappers.Response`.\n\n    :param status: The status code for the response. Either an int, in\n        which case the default status message is added, or a string in\n        the form ``{code} {message}``, like ``404 Not Found``. Defaults\n        to 200.\n    :param headers: A :class:`~werkzeug.datastructures.Headers` object,\n        or a list of ``(key, value)`` tuples that will be converted to a\n        ``Headers`` object.\n    :param mimetype: The mime type (content type without charset or\n        other parameters) of the response. If the value starts with\n        ``text/`` (or matches some other special cases), the charset\n        will be added to create the ``content_type``.\n    :param content_type: The full content type of the response.\n        Overrides building the value from ``mimetype``.\n\n    .. versionchanged:: 3.0\n        The ``charset`` attribute was removed.\n\n    .. versionadded:: 2.0\n    \"\"\"\n\n    #: the default status if none is provided.\n    default_status = 200\n\n    #: the default mimetype if none is provided.\n    default_mimetype: str | None = \"text/plain\"\n\n    #: Warn if a cookie header exceeds this size. The default, 4093, should be\n    #: safely `supported by most browsers <cookie_>`_. A cookie larger than\n    #: this size will still be sent, but it may be ignored or handled\n    #: incorrectly by some browsers. Set to 0 to disable this check.\n    #:\n    #: .. versionadded:: 0.13\n    #:\n    #: .. _`cookie`: http://browsercookielimits.squawky.net/\n    max_cookie_size = 4093\n\n    # A :class:`Headers` object representing the response headers.\n    headers: Headers\n\n    def __init__(\n        self,\n        status: int | str | HTTPStatus | None = None,\n        headers: t.Mapping[str, str | t.Iterable[str]]\n        | t.Iterable[tuple[str, str]]\n        | None = None,\n        mimetype: str | None = None,\n        content_type: str | None = None,\n    ) -> None:\n        if isinstance(headers, Headers):\n            self.headers = headers\n        elif not headers:\n            self.headers = Headers()\n        else:\n            self.headers = Headers(headers)\n\n        if content_type is None:\n            if mimetype is None and \"content-type\" not in self.headers:\n                mimetype = self.default_mimetype\n            if mimetype is not None:\n                mimetype = get_content_type(mimetype, \"utf-8\")\n            content_type = mimetype\n        if content_type is not None:\n            self.headers[\"Content-Type\"] = content_type\n        if status is None:\n            status = self.default_status\n        self.status = status  # type: ignore\n\n    def __repr__(self) -> str:\n        return f\"<{type(self).__name__} [{self.status}]>\"\n\n    @property\n    def status_code(self) -> int:\n        \"\"\"The HTTP status code as a number.\"\"\"\n        return self._status_code\n\n    @status_code.setter\n    def status_code(self, code: int) -> None:\n        self.status = code  # type: ignore\n\n    @property\n    def status(self) -> str:\n        \"\"\"The HTTP status code as a string.\"\"\"\n        return self._status\n\n    @status.setter\n    def status(self, value: str | int | HTTPStatus) -> None:\n        self._status, self._status_code = self._clean_status(value)\n\n    def _clean_status(self, value: str | int | HTTPStatus) -> tuple[str, int]:\n        if isinstance(value, (int, HTTPStatus)):\n            status_code = int(value)\n        else:\n            value = value.strip()\n\n            if not value:\n                raise ValueError(\"Empty status argument\")\n\n            code_str, sep, _ = value.partition(\" \")\n\n            try:\n                status_code = int(code_str)\n            except ValueError:\n                # only message\n                return f\"0 {value}\", 0\n\n            if sep:\n                # code and message\n                return value, status_code\n\n        # only code, look up message\n        try:\n            status = f\"{status_code} {HTTP_STATUS_CODES[status_code].upper()}\"\n        except KeyError:\n            status = f\"{status_code} UNKNOWN\"\n\n        return status, status_code\n\n    def set_cookie(\n        self,\n        key: str,\n        value: str = \"\",\n        max_age: timedelta | int | None = None,\n        expires: str | datetime | int | float | None = None,\n        path: str | None = \"/\",\n        domain: str | None = None,\n        secure: bool = False,\n        httponly: bool = False,\n        samesite: str | None = None,\n        partitioned: bool = False,\n    ) -> None:\n        \"\"\"Sets a cookie.\n\n        A warning is raised if the size of the cookie header exceeds\n        :attr:`max_cookie_size`, but the header will still be set.\n\n        :param key: the key (name) of the cookie to be set.\n        :param value: the value of the cookie.\n        :param max_age: should be a number of seconds, or `None` (default) if\n                        the cookie should last only as long as the client's\n                        browser session.\n        :param expires: should be a `datetime` object or UNIX timestamp.\n        :param path: limits the cookie to a given path, per default it will\n                     span the whole domain.\n        :param domain: if you want to set a cross-domain cookie.  For example,\n                       ``domain=\"example.com\"`` will set a cookie that is\n                       readable by the domain ``www.example.com``,\n                       ``foo.example.com`` etc.  Otherwise, a cookie will only\n                       be readable by the domain that set it.\n        :param secure: If ``True``, the cookie will only be available\n            via HTTPS.\n        :param httponly: Disallow JavaScript access to the cookie.\n        :param samesite: Limit the scope of the cookie to only be\n            attached to requests that are \"same-site\".\n        :param partitioned: If ``True``, the cookie will be partitioned.\n        \"\"\"\n        self.headers.add(\n            \"Set-Cookie\",\n            dump_cookie(\n                key,\n                value=value,\n                max_age=max_age,\n                expires=expires,\n                path=path,\n                domain=domain,\n                secure=secure,\n                httponly=httponly,\n                max_size=self.max_cookie_size,\n                samesite=samesite,\n                partitioned=partitioned,\n            ),\n        )\n\n    def delete_cookie(\n        self,\n        key: str,\n        path: str | None = \"/\",\n        domain: str | None = None,\n        secure: bool = False,\n        httponly: bool = False,\n        samesite: str | None = None,\n        partitioned: bool = False,\n    ) -> None:\n        \"\"\"Delete a cookie.  Fails silently if key doesn't exist.\n\n        :param key: the key (name) of the cookie to be deleted.\n        :param path: if the cookie that should be deleted was limited to a\n                     path, the path has to be defined here.\n        :param domain: if the cookie that should be deleted was limited to a\n                       domain, that domain has to be defined here.\n        :param secure: If ``True``, the cookie will only be available\n            via HTTPS.\n        :param httponly: Disallow JavaScript access to the cookie.\n        :param samesite: Limit the scope of the cookie to only be\n            attached to requests that are \"same-site\".\n        :param partitioned: If ``True``, the cookie will be partitioned.\n        \"\"\"\n        self.set_cookie(\n            key,\n            expires=0,\n            max_age=0,\n            path=path,\n            domain=domain,\n            secure=secure,\n            httponly=httponly,\n            samesite=samesite,\n            partitioned=partitioned,\n        )\n\n    @property\n    def is_json(self) -> bool:\n        \"\"\"Check if the mimetype indicates JSON data, either\n        :mimetype:`application/json` or :mimetype:`application/*+json`.\n        \"\"\"\n        mt = self.mimetype\n        return mt is not None and (\n            mt == \"application/json\"\n            or mt.startswith(\"application/\")\n            and mt.endswith(\"+json\")\n        )\n\n    # Common Descriptors\n\n    @property\n    def mimetype(self) -> str | None:\n        \"\"\"The mimetype (content type without charset etc.)\"\"\"\n        ct = self.headers.get(\"content-type\")\n\n        if ct:\n            return ct.split(\";\")[0].strip()\n        else:\n            return None\n\n    @mimetype.setter\n    def mimetype(self, value: str) -> None:\n        self.headers[\"Content-Type\"] = get_content_type(value, \"utf-8\")\n\n    @property\n    def mimetype_params(self) -> dict[str, str]:\n        \"\"\"The mimetype parameters as dict. For example if the\n        content type is ``text/html; charset=utf-8`` the params would be\n        ``{'charset': 'utf-8'}``.\n\n        .. versionadded:: 0.5\n        \"\"\"\n\n        def on_update(d: CallbackDict[str, str]) -> None:\n            self.headers[\"Content-Type\"] = dump_options_header(self.mimetype, d)\n\n        d = parse_options_header(self.headers.get(\"content-type\", \"\"))[1]\n        return CallbackDict(d, on_update)\n\n    location = header_property[str](\n        \"Location\",\n        doc=\"\"\"The Location response-header field is used to redirect\n        the recipient to a location other than the Request-URI for\n        completion of the request or identification of a new\n        resource.\"\"\",\n    )\n    age = header_property(\n        \"Age\",\n        None,\n        parse_age,\n        dump_age,  # type: ignore\n        doc=\"\"\"The Age response-header field conveys the sender's\n        estimate of the amount of time since the response (or its\n        revalidation) was generated at the origin server.\n\n        Age values are non-negative decimal integers, representing time\n        in seconds.\"\"\",\n    )\n    content_type = header_property[str](\n        \"Content-Type\",\n        doc=\"\"\"The Content-Type entity-header field indicates the media\n        type of the entity-body sent to the recipient or, in the case of\n        the HEAD method, the media type that would have been sent had\n        the request been a GET.\"\"\",\n    )\n    content_length = header_property(\n        \"Content-Length\",\n        None,\n        int,\n        str,\n        doc=\"\"\"The Content-Length entity-header field indicates the size\n        of the entity-body, in decimal number of OCTETs, sent to the\n        recipient or, in the case of the HEAD method, the size of the\n        entity-body that would have been sent had the request been a\n        GET.\"\"\",\n    )\n    content_location = header_property[str](\n        \"Content-Location\",\n        doc=\"\"\"The Content-Location entity-header field MAY be used to\n        supply the resource location for the entity enclosed in the\n        message when that entity is accessible from a location separate\n        from the requested resource's URI.\"\"\",\n    )\n    content_encoding = header_property[str](\n        \"Content-Encoding\",\n        doc=\"\"\"The Content-Encoding entity-header field is used as a\n        modifier to the media-type. When present, its value indicates\n        what additional content codings have been applied to the\n        entity-body, and thus what decoding mechanisms must be applied\n        in order to obtain the media-type referenced by the Content-Type\n        header field.\"\"\",\n    )\n    content_md5 = header_property[str](\n        \"Content-MD5\",\n        doc=\"\"\"The Content-MD5 entity-header field, as defined in\n        RFC 1864, is an MD5 digest of the entity-body for the purpose of\n        providing an end-to-end message integrity check (MIC) of the\n        entity-body. (Note: a MIC is good for detecting accidental\n        modification of the entity-body in transit, but is not proof\n        against malicious attacks.)\"\"\",\n    )\n    date = header_property(\n        \"Date\",\n        None,\n        parse_date,\n        http_date,\n        doc=\"\"\"The Date general-header field represents the date and\n        time at which the message was originated, having the same\n        semantics as orig-date in RFC 822.\n\n        .. versionchanged:: 2.0\n            The datetime object is timezone-aware.\n        \"\"\",\n    )\n    expires = header_property(\n        \"Expires\",\n        None,\n        parse_date,\n        http_date,\n        doc=\"\"\"The Expires entity-header field gives the date/time after\n        which the response is considered stale. A stale cache entry may\n        not normally be returned by a cache.\n\n        .. versionchanged:: 2.0\n            The datetime object is timezone-aware.\n        \"\"\",\n    )\n    last_modified = header_property(\n        \"Last-Modified\",\n        None,\n        parse_date,\n        http_date,\n        doc=\"\"\"The Last-Modified entity-header field indicates the date\n        and time at which the origin server believes the variant was\n        last modified.\n\n        .. versionchanged:: 2.0\n            The datetime object is timezone-aware.\n        \"\"\",\n    )\n\n    @property\n    def retry_after(self) -> datetime | None:\n        \"\"\"The Retry-After response-header field can be used with a\n        503 (Service Unavailable) response to indicate how long the\n        service is expected to be unavailable to the requesting client.\n\n        Time in seconds until expiration or date.\n\n        .. versionchanged:: 2.0\n            The datetime object is timezone-aware.\n        \"\"\"\n        value = self.headers.get(\"retry-after\")\n        if value is None:\n            return None\n\n        try:\n            seconds = int(value)\n        except ValueError:\n            return parse_date(value)\n\n        return datetime.now(timezone.utc) + timedelta(seconds=seconds)\n\n    @retry_after.setter\n    def retry_after(self, value: datetime | int | str | None) -> None:\n        if value is None:\n            if \"retry-after\" in self.headers:\n                del self.headers[\"retry-after\"]\n            return\n        elif isinstance(value, datetime):\n            value = http_date(value)\n        else:\n            value = str(value)\n        self.headers[\"Retry-After\"] = value\n\n    vary = _set_property(\n        \"Vary\",\n        doc=\"\"\"The Vary field value indicates the set of request-header\n        fields that fully determines, while the response is fresh,\n        whether a cache is permitted to use the response to reply to a\n        subsequent request without revalidation.\"\"\",\n    )\n    content_language = _set_property(\n        \"Content-Language\",\n        doc=\"\"\"The Content-Language entity-header field describes the\n        natural language(s) of the intended audience for the enclosed\n        entity. Note that this might not be equivalent to all the\n        languages used within the entity-body.\"\"\",\n    )\n    allow = _set_property(\n        \"Allow\",\n        doc=\"\"\"The Allow entity-header field lists the set of methods\n        supported by the resource identified by the Request-URI. The\n        purpose of this field is strictly to inform the recipient of\n        valid methods associated with the resource. An Allow header\n        field MUST be present in a 405 (Method Not Allowed)\n        response.\"\"\",\n    )\n\n    # ETag\n\n    @property\n    def cache_control(self) -> ResponseCacheControl:\n        \"\"\"The Cache-Control general-header field is used to specify\n        directives that MUST be obeyed by all caching mechanisms along the\n        request/response chain.\n        \"\"\"\n\n        def on_update(cache_control: _CacheControl) -> None:\n            if not cache_control and \"cache-control\" in self.headers:\n                del self.headers[\"cache-control\"]\n            elif cache_control:\n                self.headers[\"Cache-Control\"] = cache_control.to_header()\n\n        return parse_cache_control_header(\n            self.headers.get(\"cache-control\"), on_update, ResponseCacheControl\n        )\n\n    def set_etag(self, etag: str, weak: bool = False) -> None:\n        \"\"\"Set the etag, and override the old one if there was one.\"\"\"\n        self.headers[\"ETag\"] = quote_etag(etag, weak)\n\n    def get_etag(self) -> tuple[str, bool] | tuple[None, None]:\n        \"\"\"Return a tuple in the form ``(etag, is_weak)``.  If there is no\n        ETag the return value is ``(None, None)``.\n        \"\"\"\n        return unquote_etag(self.headers.get(\"ETag\"))\n\n    accept_ranges = header_property[str](\n        \"Accept-Ranges\",\n        doc=\"\"\"The `Accept-Ranges` header. Even though the name would\n        indicate that multiple values are supported, it must be one\n        string token only.\n\n        The values ``'bytes'`` and ``'none'`` are common.\n\n        .. versionadded:: 0.7\"\"\",\n    )\n\n    @property\n    def content_range(self) -> ContentRange:\n        \"\"\"The ``Content-Range`` header as a\n        :class:`~werkzeug.datastructures.ContentRange` object. Available\n        even if the header is not set.\n\n        .. versionadded:: 0.7\n        \"\"\"\n\n        def on_update(rng: ContentRange) -> None:\n            if not rng:\n                del self.headers[\"content-range\"]\n            else:\n                self.headers[\"Content-Range\"] = rng.to_header()\n\n        rv = parse_content_range_header(self.headers.get(\"content-range\"), on_update)\n        # always provide a content range object to make the descriptor\n        # more user friendly.  It provides an unset() method that can be\n        # used to remove the header quickly.\n        if rv is None:\n            rv = ContentRange(None, None, None, on_update=on_update)\n        return rv\n\n    @content_range.setter\n    def content_range(self, value: ContentRange | str | None) -> None:\n        if not value:\n            del self.headers[\"content-range\"]\n        elif isinstance(value, str):\n            self.headers[\"Content-Range\"] = value\n        else:\n            self.headers[\"Content-Range\"] = value.to_header()\n\n    # Authorization\n\n    @property\n    def www_authenticate(self) -> WWWAuthenticate:\n        \"\"\"The ``WWW-Authenticate`` header parsed into a :class:`.WWWAuthenticate`\n        object. Modifying the object will modify the header value.\n\n        This header is not set by default. To set this header, assign an instance of\n        :class:`.WWWAuthenticate` to this attribute.\n\n        .. code-block:: python\n\n            response.www_authenticate = WWWAuthenticate(\n                \"basic\", {\"realm\": \"Authentication Required\"}\n            )\n\n        Multiple values for this header can be sent to give the client multiple options.\n        Assign a list to set multiple headers. However, modifying the items in the list\n        will not automatically update the header values, and accessing this attribute\n        will only ever return the first value.\n\n        To unset this header, assign ``None`` or use ``del``.\n\n        .. versionchanged:: 2.3\n            This attribute can be assigned to to set the header. A list can be assigned\n            to set multiple header values. Use ``del`` to unset the header.\n\n        .. versionchanged:: 2.3\n            :class:`WWWAuthenticate` is no longer a ``dict``. The ``token`` attribute\n            was added for auth challenges that use a token instead of parameters.\n        \"\"\"\n        value = WWWAuthenticate.from_header(self.headers.get(\"WWW-Authenticate\"))\n\n        if value is None:\n            value = WWWAuthenticate(\"basic\")\n\n        def on_update(value: WWWAuthenticate) -> None:\n            self.www_authenticate = value\n\n        value._on_update = on_update\n        return value\n\n    @www_authenticate.setter\n    def www_authenticate(\n        self, value: WWWAuthenticate | list[WWWAuthenticate] | None\n    ) -> None:\n        if not value:  # None or empty list\n            del self.www_authenticate\n        elif isinstance(value, list):\n            # Clear any existing header by setting the first item.\n            self.headers.set(\"WWW-Authenticate\", value[0].to_header())\n\n            for item in value[1:]:\n                # Add additional header lines for additional items.\n                self.headers.add(\"WWW-Authenticate\", item.to_header())\n        else:\n            self.headers.set(\"WWW-Authenticate\", value.to_header())\n\n            def on_update(value: WWWAuthenticate) -> None:\n                self.www_authenticate = value\n\n            # When setting a single value, allow updating it directly.\n            value._on_update = on_update\n\n    @www_authenticate.deleter\n    def www_authenticate(self) -> None:\n        if \"WWW-Authenticate\" in self.headers:\n            del self.headers[\"WWW-Authenticate\"]\n\n    # CSP\n\n    @property\n    def content_security_policy(self) -> ContentSecurityPolicy:\n        \"\"\"The ``Content-Security-Policy`` header as a\n        :class:`~werkzeug.datastructures.ContentSecurityPolicy` object. Available\n        even if the header is not set.\n\n        The Content-Security-Policy header adds an additional layer of\n        security to help detect and mitigate certain types of attacks.\n        \"\"\"\n\n        def on_update(csp: ContentSecurityPolicy) -> None:\n            if not csp:\n                del self.headers[\"content-security-policy\"]\n            else:\n                self.headers[\"Content-Security-Policy\"] = csp.to_header()\n\n        rv = parse_csp_header(self.headers.get(\"content-security-policy\"), on_update)\n        if rv is None:\n            rv = ContentSecurityPolicy(None, on_update=on_update)\n        return rv\n\n    @content_security_policy.setter\n    def content_security_policy(\n        self, value: ContentSecurityPolicy | str | None\n    ) -> None:\n        if not value:\n            del self.headers[\"content-security-policy\"]\n        elif isinstance(value, str):\n            self.headers[\"Content-Security-Policy\"] = value\n        else:\n            self.headers[\"Content-Security-Policy\"] = value.to_header()\n\n    @property\n    def content_security_policy_report_only(self) -> ContentSecurityPolicy:\n        \"\"\"The ``Content-Security-policy-report-only`` header as a\n        :class:`~werkzeug.datastructures.ContentSecurityPolicy` object. Available\n        even if the header is not set.\n\n        The Content-Security-Policy-Report-Only header adds a csp policy\n        that is not enforced but is reported thereby helping detect\n        certain types of attacks.\n        \"\"\"\n\n        def on_update(csp: ContentSecurityPolicy) -> None:\n            if not csp:\n                del self.headers[\"content-security-policy-report-only\"]\n            else:\n                self.headers[\"Content-Security-policy-report-only\"] = csp.to_header()\n\n        rv = parse_csp_header(\n            self.headers.get(\"content-security-policy-report-only\"), on_update\n        )\n        if rv is None:\n            rv = ContentSecurityPolicy(None, on_update=on_update)\n        return rv\n\n    @content_security_policy_report_only.setter\n    def content_security_policy_report_only(\n        self, value: ContentSecurityPolicy | str | None\n    ) -> None:\n        if not value:\n            del self.headers[\"content-security-policy-report-only\"]\n        elif isinstance(value, str):\n            self.headers[\"Content-Security-policy-report-only\"] = value\n        else:\n            self.headers[\"Content-Security-policy-report-only\"] = value.to_header()\n\n    # CORS\n\n    @property\n    def access_control_allow_credentials(self) -> bool:\n        \"\"\"Whether credentials can be shared by the browser to\n        JavaScript code. As part of the preflight request it indicates\n        whether credentials can be used on the cross origin request.\n        \"\"\"\n        return \"Access-Control-Allow-Credentials\" in self.headers\n\n    @access_control_allow_credentials.setter\n    def access_control_allow_credentials(self, value: bool | None) -> None:\n        if value is True:\n            self.headers[\"Access-Control-Allow-Credentials\"] = \"true\"\n        else:\n            self.headers.pop(\"Access-Control-Allow-Credentials\", None)\n\n    access_control_allow_headers = header_property(\n        \"Access-Control-Allow-Headers\",\n        load_func=parse_set_header,\n        dump_func=dump_header,\n        doc=\"Which headers can be sent with the cross origin request.\",\n    )\n\n    access_control_allow_methods = header_property(\n        \"Access-Control-Allow-Methods\",\n        load_func=parse_set_header,\n        dump_func=dump_header,\n        doc=\"Which methods can be used for the cross origin request.\",\n    )\n\n    access_control_allow_origin = header_property[str](\n        \"Access-Control-Allow-Origin\",\n        doc=\"The origin or '*' for any origin that may make cross origin requests.\",\n    )\n\n    access_control_expose_headers = header_property(\n        \"Access-Control-Expose-Headers\",\n        load_func=parse_set_header,\n        dump_func=dump_header,\n        doc=\"Which headers can be shared by the browser to JavaScript code.\",\n    )\n\n    access_control_max_age = header_property(\n        \"Access-Control-Max-Age\",\n        load_func=int,\n        dump_func=str,\n        doc=\"The maximum age in seconds the access control settings can be cached for.\",\n    )\n\n    cross_origin_opener_policy = header_property[COOP](\n        \"Cross-Origin-Opener-Policy\",\n        load_func=lambda value: COOP(value),\n        dump_func=lambda value: value.value,\n        default=COOP.UNSAFE_NONE,\n        doc=\"\"\"Allows control over sharing of browsing context group with cross-origin\n        documents. Values must be a member of the :class:`werkzeug.http.COOP` enum.\"\"\",\n    )\n\n    cross_origin_embedder_policy = header_property[COEP](\n        \"Cross-Origin-Embedder-Policy\",\n        load_func=lambda value: COEP(value),\n        dump_func=lambda value: value.value,\n        default=COEP.UNSAFE_NONE,\n        doc=\"\"\"Prevents a document from loading any cross-origin resources that do not\n        explicitly grant the document permission. Values must be a member of the\n        :class:`werkzeug.http.COEP` enum.\"\"\",\n    )\n", "src/werkzeug/sansio/multipart.py": "from __future__ import annotations\n\nimport re\nimport typing as t\nfrom dataclasses import dataclass\nfrom enum import auto\nfrom enum import Enum\n\nfrom ..datastructures import Headers\nfrom ..exceptions import RequestEntityTooLarge\nfrom ..http import parse_options_header\n\n\nclass Event:\n    pass\n\n\n@dataclass(frozen=True)\nclass Preamble(Event):\n    data: bytes\n\n\n@dataclass(frozen=True)\nclass Field(Event):\n    name: str\n    headers: Headers\n\n\n@dataclass(frozen=True)\nclass File(Event):\n    name: str\n    filename: str\n    headers: Headers\n\n\n@dataclass(frozen=True)\nclass Data(Event):\n    data: bytes\n    more_data: bool\n\n\n@dataclass(frozen=True)\nclass Epilogue(Event):\n    data: bytes\n\n\nclass NeedData(Event):\n    pass\n\n\nNEED_DATA = NeedData()\n\n\nclass State(Enum):\n    PREAMBLE = auto()\n    PART = auto()\n    DATA = auto()\n    DATA_START = auto()\n    EPILOGUE = auto()\n    COMPLETE = auto()\n\n\n# Multipart line breaks MUST be CRLF (\\r\\n) by RFC-7578, except that\n# many implementations break this and either use CR or LF alone.\nLINE_BREAK = b\"(?:\\r\\n|\\n|\\r)\"\nBLANK_LINE_RE = re.compile(b\"(?:\\r\\n\\r\\n|\\r\\r|\\n\\n)\", re.MULTILINE)\nLINE_BREAK_RE = re.compile(LINE_BREAK, re.MULTILINE)\n# Header values can be continued via a space or tab after the linebreak, as\n# per RFC2231\nHEADER_CONTINUATION_RE = re.compile(b\"%s[ \\t]\" % LINE_BREAK, re.MULTILINE)\n# This must be long enough to contain any line breaks plus any\n# additional boundary markers (--) such that they will be found in a\n# subsequent search\nSEARCH_EXTRA_LENGTH = 8\n\n\nclass MultipartDecoder:\n    \"\"\"Decodes a multipart message as bytes into Python events.\n\n    The part data is returned as available to allow the caller to save\n    the data from memory to disk, if desired.\n    \"\"\"\n\n    def __init__(\n        self,\n        boundary: bytes,\n        max_form_memory_size: int | None = None,\n        *,\n        max_parts: int | None = None,\n    ) -> None:\n        self.buffer = bytearray()\n        self.complete = False\n        self.max_form_memory_size = max_form_memory_size\n        self.max_parts = max_parts\n        self.state = State.PREAMBLE\n        self.boundary = boundary\n\n        # Note in the below \\h i.e. horizontal whitespace is used\n        # as [^\\S\\n\\r] as \\h isn't supported in python.\n\n        # The preamble must end with a boundary where the boundary is\n        # prefixed by a line break, RFC2046. Except that many\n        # implementations including Werkzeug's tests omit the line\n        # break prefix. In addition the first boundary could be the\n        # epilogue boundary (for empty form-data) hence the matching\n        # group to understand if it is an epilogue boundary.\n        self.preamble_re = re.compile(\n            rb\"%s?--%s(--[^\\S\\n\\r]*%s?|[^\\S\\n\\r]*%s)\"\n            % (LINE_BREAK, re.escape(boundary), LINE_BREAK, LINE_BREAK),\n            re.MULTILINE,\n        )\n        # A boundary must include a line break prefix and suffix, and\n        # may include trailing whitespace. In addition the boundary\n        # could be the epilogue boundary hence the matching group to\n        # understand if it is an epilogue boundary.\n        self.boundary_re = re.compile(\n            rb\"%s--%s(--[^\\S\\n\\r]*%s?|[^\\S\\n\\r]*%s)\"\n            % (LINE_BREAK, re.escape(boundary), LINE_BREAK, LINE_BREAK),\n            re.MULTILINE,\n        )\n        self._search_position = 0\n        self._parts_decoded = 0\n\n    def last_newline(self, data: bytes) -> int:\n        try:\n            last_nl = data.rindex(b\"\\n\")\n        except ValueError:\n            last_nl = len(data)\n        try:\n            last_cr = data.rindex(b\"\\r\")\n        except ValueError:\n            last_cr = len(data)\n\n        return min(last_nl, last_cr)\n\n    def receive_data(self, data: bytes | None) -> None:\n        if data is None:\n            self.complete = True\n        elif (\n            self.max_form_memory_size is not None\n            and len(self.buffer) + len(data) > self.max_form_memory_size\n        ):\n            raise RequestEntityTooLarge()\n        else:\n            self.buffer.extend(data)\n\n    def next_event(self) -> Event:\n        event: Event = NEED_DATA\n\n        if self.state == State.PREAMBLE:\n            match = self.preamble_re.search(self.buffer, self._search_position)\n            if match is not None:\n                if match.group(1).startswith(b\"--\"):\n                    self.state = State.EPILOGUE\n                else:\n                    self.state = State.PART\n                data = bytes(self.buffer[: match.start()])\n                del self.buffer[: match.end()]\n                event = Preamble(data=data)\n                self._search_position = 0\n            else:\n                # Update the search start position to be equal to the\n                # current buffer length (already searched) minus a\n                # safe buffer for part of the search target.\n                self._search_position = max(\n                    0, len(self.buffer) - len(self.boundary) - SEARCH_EXTRA_LENGTH\n                )\n\n        elif self.state == State.PART:\n            match = BLANK_LINE_RE.search(self.buffer, self._search_position)\n            if match is not None:\n                headers = self._parse_headers(self.buffer[: match.start()])\n                # The final header ends with a single CRLF, however a\n                # blank line indicates the start of the\n                # body. Therefore the end is after the first CRLF.\n                headers_end = (match.start() + match.end()) // 2\n                del self.buffer[:headers_end]\n\n                if \"content-disposition\" not in headers:\n                    raise ValueError(\"Missing Content-Disposition header\")\n\n                disposition, extra = parse_options_header(\n                    headers[\"content-disposition\"]\n                )\n                name = t.cast(str, extra.get(\"name\"))\n                filename = extra.get(\"filename\")\n                if filename is not None:\n                    event = File(\n                        filename=filename,\n                        headers=headers,\n                        name=name,\n                    )\n                else:\n                    event = Field(\n                        headers=headers,\n                        name=name,\n                    )\n                self.state = State.DATA_START\n                self._search_position = 0\n                self._parts_decoded += 1\n\n                if self.max_parts is not None and self._parts_decoded > self.max_parts:\n                    raise RequestEntityTooLarge()\n            else:\n                # Update the search start position to be equal to the\n                # current buffer length (already searched) minus a\n                # safe buffer for part of the search target.\n                self._search_position = max(0, len(self.buffer) - SEARCH_EXTRA_LENGTH)\n\n        elif self.state == State.DATA_START:\n            data, del_index, more_data = self._parse_data(self.buffer, start=True)\n            del self.buffer[:del_index]\n            event = Data(data=data, more_data=more_data)\n            if more_data:\n                self.state = State.DATA\n\n        elif self.state == State.DATA:\n            data, del_index, more_data = self._parse_data(self.buffer, start=False)\n            del self.buffer[:del_index]\n            if data or not more_data:\n                event = Data(data=data, more_data=more_data)\n\n        elif self.state == State.EPILOGUE and self.complete:\n            event = Epilogue(data=bytes(self.buffer))\n            del self.buffer[:]\n            self.state = State.COMPLETE\n\n        if self.complete and isinstance(event, NeedData):\n            raise ValueError(f\"Invalid form-data cannot parse beyond {self.state}\")\n\n        return event\n\n    def _parse_headers(self, data: bytes) -> Headers:\n        headers: list[tuple[str, str]] = []\n        # Merge the continued headers into one line\n        data = HEADER_CONTINUATION_RE.sub(b\" \", data)\n        # Now there is one header per line\n        for line in data.splitlines():\n            line = line.strip()\n\n            if line != b\"\":\n                name, _, value = line.decode().partition(\":\")\n                headers.append((name.strip(), value.strip()))\n        return Headers(headers)\n\n    def _parse_data(self, data: bytes, *, start: bool) -> tuple[bytes, int, bool]:\n        # Body parts must start with CRLF (or CR or LF)\n        if start:\n            match = LINE_BREAK_RE.match(data)\n            data_start = t.cast(t.Match[bytes], match).end()\n        else:\n            data_start = 0\n\n        boundary = b\"--\" + self.boundary\n\n        if self.buffer.find(boundary) == -1:\n            # No complete boundary in the buffer, but there may be\n            # a partial boundary at the end. As the boundary\n            # starts with either a nl or cr find the earliest and\n            # return up to that as data.\n            data_end = del_index = self.last_newline(data[data_start:]) + data_start\n            # If amount of data after last newline is far from\n            # possible length of partial boundary, we should\n            # assume that there is no partial boundary in the buffer\n            # and return all pending data.\n            if (len(data) - data_end) > len(b\"\\n\" + boundary):\n                data_end = del_index = len(data)\n            more_data = True\n        else:\n            match = self.boundary_re.search(data)\n            if match is not None:\n                if match.group(1).startswith(b\"--\"):\n                    self.state = State.EPILOGUE\n                else:\n                    self.state = State.PART\n                data_end = match.start()\n                del_index = match.end()\n            else:\n                data_end = del_index = self.last_newline(data[data_start:]) + data_start\n            more_data = match is None\n\n        return bytes(data[data_start:data_end]), del_index, more_data\n\n\nclass MultipartEncoder:\n    def __init__(self, boundary: bytes) -> None:\n        self.boundary = boundary\n        self.state = State.PREAMBLE\n\n    def send_event(self, event: Event) -> bytes:\n        if isinstance(event, Preamble) and self.state == State.PREAMBLE:\n            self.state = State.PART\n            return event.data\n        elif isinstance(event, (Field, File)) and self.state in {\n            State.PREAMBLE,\n            State.PART,\n            State.DATA,\n        }:\n            data = b\"\\r\\n--\" + self.boundary + b\"\\r\\n\"\n            data += b'Content-Disposition: form-data; name=\"%s\"' % event.name.encode()\n            if isinstance(event, File):\n                data += b'; filename=\"%s\"' % event.filename.encode()\n            data += b\"\\r\\n\"\n            for name, value in t.cast(Field, event).headers:\n                if name.lower() != \"content-disposition\":\n                    data += f\"{name}: {value}\\r\\n\".encode()\n            self.state = State.DATA_START\n            return data\n        elif isinstance(event, Data) and self.state == State.DATA_START:\n            self.state = State.DATA\n            if len(event.data) > 0:\n                return b\"\\r\\n\" + event.data\n            else:\n                return event.data\n        elif isinstance(event, Data) and self.state == State.DATA:\n            return event.data\n        elif isinstance(event, Epilogue):\n            self.state = State.COMPLETE\n            return b\"\\r\\n--\" + self.boundary + b\"--\\r\\n\" + event.data\n        else:\n            raise ValueError(f\"Cannot generate {event} in state: {self.state}\")\n", "src/werkzeug/sansio/http.py": "from __future__ import annotations\n\nimport re\nimport typing as t\nfrom datetime import datetime\n\nfrom .._internal import _dt_as_utc\nfrom ..http import generate_etag\nfrom ..http import parse_date\nfrom ..http import parse_etags\nfrom ..http import parse_if_range_header\nfrom ..http import unquote_etag\n\n_etag_re = re.compile(r'([Ww]/)?(?:\"(.*?)\"|(.*?))(?:\\s*,\\s*|$)')\n\n\ndef is_resource_modified(\n    http_range: str | None = None,\n    http_if_range: str | None = None,\n    http_if_modified_since: str | None = None,\n    http_if_none_match: str | None = None,\n    http_if_match: str | None = None,\n    etag: str | None = None,\n    data: bytes | None = None,\n    last_modified: datetime | str | None = None,\n    ignore_if_range: bool = True,\n) -> bool:\n    \"\"\"Convenience method for conditional requests.\n    :param http_range: Range HTTP header\n    :param http_if_range: If-Range HTTP header\n    :param http_if_modified_since: If-Modified-Since HTTP header\n    :param http_if_none_match: If-None-Match HTTP header\n    :param http_if_match: If-Match HTTP header\n    :param etag: the etag for the response for comparison.\n    :param data: or alternatively the data of the response to automatically\n                 generate an etag using :func:`generate_etag`.\n    :param last_modified: an optional date of the last modification.\n    :param ignore_if_range: If `False`, `If-Range` header will be taken into\n                            account.\n    :return: `True` if the resource was modified, otherwise `False`.\n\n    .. versionadded:: 2.2\n    \"\"\"\n    if etag is None and data is not None:\n        etag = generate_etag(data)\n    elif data is not None:\n        raise TypeError(\"both data and etag given\")\n\n    unmodified = False\n    if isinstance(last_modified, str):\n        last_modified = parse_date(last_modified)\n\n    # HTTP doesn't use microsecond, remove it to avoid false positive\n    # comparisons. Mark naive datetimes as UTC.\n    if last_modified is not None:\n        last_modified = _dt_as_utc(last_modified.replace(microsecond=0))\n\n    if_range = None\n    if not ignore_if_range and http_range is not None:\n        # https://tools.ietf.org/html/rfc7233#section-3.2\n        # A server MUST ignore an If-Range header field received in a request\n        # that does not contain a Range header field.\n        if_range = parse_if_range_header(http_if_range)\n\n    if if_range is not None and if_range.date is not None:\n        modified_since: datetime | None = if_range.date\n    else:\n        modified_since = parse_date(http_if_modified_since)\n\n    if modified_since and last_modified and last_modified <= modified_since:\n        unmodified = True\n\n    if etag:\n        etag, _ = unquote_etag(etag)\n        etag = t.cast(str, etag)\n\n        if if_range is not None and if_range.etag is not None:\n            unmodified = parse_etags(if_range.etag).contains(etag)\n        else:\n            if_none_match = parse_etags(http_if_none_match)\n            if if_none_match:\n                # https://tools.ietf.org/html/rfc7232#section-3.2\n                # \"A recipient MUST use the weak comparison function when comparing\n                # entity-tags for If-None-Match\"\n                unmodified = if_none_match.contains_weak(etag)\n\n            # https://tools.ietf.org/html/rfc7232#section-3.1\n            # \"Origin server MUST use the strong comparison function when\n            # comparing entity-tags for If-Match\"\n            if_match = parse_etags(http_if_match)\n            if if_match:\n                unmodified = not if_match.is_strong(etag)\n\n    return not unmodified\n\n\n_cookie_re = re.compile(\n    r\"\"\"\n    ([^=;]*)\n    (?:\\s*=\\s*\n      (\n        \"(?:[^\\\\\"]|\\\\.)*\"\n      |\n        .*?\n      )\n    )?\n    \\s*;\\s*\n    \"\"\",\n    flags=re.ASCII | re.VERBOSE,\n)\n_cookie_unslash_re = re.compile(rb\"\\\\([0-3][0-7]{2}|.)\")\n\n\ndef _cookie_unslash_replace(m: t.Match[bytes]) -> bytes:\n    v = m.group(1)\n\n    if len(v) == 1:\n        return v\n\n    return int(v, 8).to_bytes(1, \"big\")\n\n\ndef parse_cookie(\n    cookie: str | None = None,\n    cls: type[ds.MultiDict[str, str]] | None = None,\n) -> ds.MultiDict[str, str]:\n    \"\"\"Parse a cookie from a string.\n\n    The same key can be provided multiple times, the values are stored\n    in-order. The default :class:`MultiDict` will have the first value\n    first, and all values can be retrieved with\n    :meth:`MultiDict.getlist`.\n\n    :param cookie: The cookie header as a string.\n    :param cls: A dict-like class to store the parsed cookies in.\n        Defaults to :class:`MultiDict`.\n\n    .. versionchanged:: 3.0\n        Passing bytes, and the ``charset`` and ``errors`` parameters, were removed.\n\n    .. versionadded:: 2.2\n    \"\"\"\n    if cls is None:\n        cls = t.cast(\"type[ds.MultiDict[str, str]]\", ds.MultiDict)\n\n    if not cookie:\n        return cls()\n\n    cookie = f\"{cookie};\"\n    out = []\n\n    for ck, cv in _cookie_re.findall(cookie):\n        ck = ck.strip()\n        cv = cv.strip()\n\n        if not ck:\n            continue\n\n        if len(cv) >= 2 and cv[0] == cv[-1] == '\"':\n            # Work with bytes here, since a UTF-8 character could be multiple bytes.\n            cv = _cookie_unslash_re.sub(\n                _cookie_unslash_replace, cv[1:-1].encode()\n            ).decode(errors=\"replace\")\n\n        out.append((ck, cv))\n\n    return cls(out)\n\n\n# circular dependencies\nfrom .. import datastructures as ds\n", "src/werkzeug/sansio/request.py": "from __future__ import annotations\n\nimport typing as t\nfrom datetime import datetime\nfrom urllib.parse import parse_qsl\n\nfrom ..datastructures import Accept\nfrom ..datastructures import Authorization\nfrom ..datastructures import CharsetAccept\nfrom ..datastructures import ETags\nfrom ..datastructures import Headers\nfrom ..datastructures import HeaderSet\nfrom ..datastructures import IfRange\nfrom ..datastructures import ImmutableList\nfrom ..datastructures import ImmutableMultiDict\nfrom ..datastructures import LanguageAccept\nfrom ..datastructures import MIMEAccept\nfrom ..datastructures import MultiDict\nfrom ..datastructures import Range\nfrom ..datastructures import RequestCacheControl\nfrom ..http import parse_accept_header\nfrom ..http import parse_cache_control_header\nfrom ..http import parse_date\nfrom ..http import parse_etags\nfrom ..http import parse_if_range_header\nfrom ..http import parse_list_header\nfrom ..http import parse_options_header\nfrom ..http import parse_range_header\nfrom ..http import parse_set_header\nfrom ..user_agent import UserAgent\nfrom ..utils import cached_property\nfrom ..utils import header_property\nfrom .http import parse_cookie\nfrom .utils import get_content_length\nfrom .utils import get_current_url\nfrom .utils import get_host\n\n\nclass Request:\n    \"\"\"Represents the non-IO parts of a HTTP request, including the\n    method, URL info, and headers.\n\n    This class is not meant for general use. It should only be used when\n    implementing WSGI, ASGI, or another HTTP application spec. Werkzeug\n    provides a WSGI implementation at :cls:`werkzeug.wrappers.Request`.\n\n    :param method: The method the request was made with, such as\n        ``GET``.\n    :param scheme: The URL scheme of the protocol the request used, such\n        as ``https`` or ``wss``.\n    :param server: The address of the server. ``(host, port)``,\n        ``(path, None)`` for unix sockets, or ``None`` if not known.\n    :param root_path: The prefix that the application is mounted under.\n        This is prepended to generated URLs, but is not part of route\n        matching.\n    :param path: The path part of the URL after ``root_path``.\n    :param query_string: The part of the URL after the \"?\".\n    :param headers: The headers received with the request.\n    :param remote_addr: The address of the client sending the request.\n\n    .. versionchanged:: 3.0\n        The ``charset``, ``url_charset``, and ``encoding_errors`` attributes\n        were removed.\n\n    .. versionadded:: 2.0\n    \"\"\"\n\n    #: the class to use for `args` and `form`.  The default is an\n    #: :class:`~werkzeug.datastructures.ImmutableMultiDict` which supports\n    #: multiple values per key.  alternatively it makes sense to use an\n    #: :class:`~werkzeug.datastructures.ImmutableOrderedMultiDict` which\n    #: preserves order or a :class:`~werkzeug.datastructures.ImmutableDict`\n    #: which is the fastest but only remembers the last key.  It is also\n    #: possible to use mutable structures, but this is not recommended.\n    #:\n    #: .. versionadded:: 0.6\n    parameter_storage_class: type[MultiDict[str, t.Any]] = ImmutableMultiDict\n\n    #: The type to be used for dict values from the incoming WSGI\n    #: environment. (For example for :attr:`cookies`.) By default an\n    #: :class:`~werkzeug.datastructures.ImmutableMultiDict` is used.\n    #:\n    #: .. versionchanged:: 1.0.0\n    #:     Changed to ``ImmutableMultiDict`` to support multiple values.\n    #:\n    #: .. versionadded:: 0.6\n    dict_storage_class: type[MultiDict[str, t.Any]] = ImmutableMultiDict\n\n    #: the type to be used for list values from the incoming WSGI environment.\n    #: By default an :class:`~werkzeug.datastructures.ImmutableList` is used\n    #: (for example for :attr:`access_list`).\n    #:\n    #: .. versionadded:: 0.6\n    list_storage_class: type[list[t.Any]] = ImmutableList\n\n    user_agent_class: type[UserAgent] = UserAgent\n    \"\"\"The class used and returned by the :attr:`user_agent` property to\n    parse the header. Defaults to\n    :class:`~werkzeug.user_agent.UserAgent`, which does no parsing. An\n    extension can provide a subclass that uses a parser to provide other\n    data.\n\n    .. versionadded:: 2.0\n    \"\"\"\n\n    #: Valid host names when handling requests. By default all hosts are\n    #: trusted, which means that whatever the client says the host is\n    #: will be accepted.\n    #:\n    #: Because ``Host`` and ``X-Forwarded-Host`` headers can be set to\n    #: any value by a malicious client, it is recommended to either set\n    #: this property or implement similar validation in the proxy (if\n    #: the application is being run behind one).\n    #:\n    #: .. versionadded:: 0.9\n    trusted_hosts: list[str] | None = None\n\n    def __init__(\n        self,\n        method: str,\n        scheme: str,\n        server: tuple[str, int | None] | None,\n        root_path: str,\n        path: str,\n        query_string: bytes,\n        headers: Headers,\n        remote_addr: str | None,\n    ) -> None:\n        #: The method the request was made with, such as ``GET``.\n        self.method = method.upper()\n        #: The URL scheme of the protocol the request used, such as\n        #: ``https`` or ``wss``.\n        self.scheme = scheme\n        #: The address of the server. ``(host, port)``, ``(path, None)``\n        #: for unix sockets, or ``None`` if not known.\n        self.server = server\n        #: The prefix that the application is mounted under, without a\n        #: trailing slash. :attr:`path` comes after this.\n        self.root_path = root_path.rstrip(\"/\")\n        #: The path part of the URL after :attr:`root_path`. This is the\n        #: path used for routing within the application.\n        self.path = \"/\" + path.lstrip(\"/\")\n        #: The part of the URL after the \"?\". This is the raw value, use\n        #: :attr:`args` for the parsed values.\n        self.query_string = query_string\n        #: The headers received with the request.\n        self.headers = headers\n        #: The address of the client sending the request.\n        self.remote_addr = remote_addr\n\n    def __repr__(self) -> str:\n        try:\n            url = self.url\n        except Exception as e:\n            url = f\"(invalid URL: {e})\"\n\n        return f\"<{type(self).__name__} {url!r} [{self.method}]>\"\n\n    @cached_property\n    def args(self) -> MultiDict[str, str]:\n        \"\"\"The parsed URL parameters (the part in the URL after the question\n        mark).\n\n        By default an\n        :class:`~werkzeug.datastructures.ImmutableMultiDict`\n        is returned from this function.  This can be changed by setting\n        :attr:`parameter_storage_class` to a different type.  This might\n        be necessary if the order of the form data is important.\n\n        .. versionchanged:: 2.3\n            Invalid bytes remain percent encoded.\n        \"\"\"\n        return self.parameter_storage_class(\n            parse_qsl(\n                self.query_string.decode(),\n                keep_blank_values=True,\n                errors=\"werkzeug.url_quote\",\n            )\n        )\n\n    @cached_property\n    def access_route(self) -> list[str]:\n        \"\"\"If a forwarded header exists this is a list of all ip addresses\n        from the client ip to the last proxy server.\n        \"\"\"\n        if \"X-Forwarded-For\" in self.headers:\n            return self.list_storage_class(\n                parse_list_header(self.headers[\"X-Forwarded-For\"])\n            )\n        elif self.remote_addr is not None:\n            return self.list_storage_class([self.remote_addr])\n        return self.list_storage_class()\n\n    @cached_property\n    def full_path(self) -> str:\n        \"\"\"Requested path, including the query string.\"\"\"\n        return f\"{self.path}?{self.query_string.decode()}\"\n\n    @property\n    def is_secure(self) -> bool:\n        \"\"\"``True`` if the request was made with a secure protocol\n        (HTTPS or WSS).\n        \"\"\"\n        return self.scheme in {\"https\", \"wss\"}\n\n    @cached_property\n    def url(self) -> str:\n        \"\"\"The full request URL with the scheme, host, root path, path,\n        and query string.\"\"\"\n        return get_current_url(\n            self.scheme, self.host, self.root_path, self.path, self.query_string\n        )\n\n    @cached_property\n    def base_url(self) -> str:\n        \"\"\"Like :attr:`url` but without the query string.\"\"\"\n        return get_current_url(self.scheme, self.host, self.root_path, self.path)\n\n    @cached_property\n    def root_url(self) -> str:\n        \"\"\"The request URL scheme, host, and root path. This is the root\n        that the application is accessed from.\n        \"\"\"\n        return get_current_url(self.scheme, self.host, self.root_path)\n\n    @cached_property\n    def host_url(self) -> str:\n        \"\"\"The request URL scheme and host only.\"\"\"\n        return get_current_url(self.scheme, self.host)\n\n    @cached_property\n    def host(self) -> str:\n        \"\"\"The host name the request was made to, including the port if\n        it's non-standard. Validated with :attr:`trusted_hosts`.\n        \"\"\"\n        return get_host(\n            self.scheme, self.headers.get(\"host\"), self.server, self.trusted_hosts\n        )\n\n    @cached_property\n    def cookies(self) -> ImmutableMultiDict[str, str]:\n        \"\"\"A :class:`dict` with the contents of all cookies transmitted with\n        the request.\"\"\"\n        wsgi_combined_cookie = \";\".join(self.headers.getlist(\"Cookie\"))\n        return parse_cookie(  # type: ignore\n            wsgi_combined_cookie, cls=self.dict_storage_class\n        )\n\n    # Common Descriptors\n\n    content_type = header_property[str](\n        \"Content-Type\",\n        doc=\"\"\"The Content-Type entity-header field indicates the media\n        type of the entity-body sent to the recipient or, in the case of\n        the HEAD method, the media type that would have been sent had\n        the request been a GET.\"\"\",\n        read_only=True,\n    )\n\n    @cached_property\n    def content_length(self) -> int | None:\n        \"\"\"The Content-Length entity-header field indicates the size of the\n        entity-body in bytes or, in the case of the HEAD method, the size of\n        the entity-body that would have been sent had the request been a\n        GET.\n        \"\"\"\n        return get_content_length(\n            http_content_length=self.headers.get(\"Content-Length\"),\n            http_transfer_encoding=self.headers.get(\"Transfer-Encoding\"),\n        )\n\n    content_encoding = header_property[str](\n        \"Content-Encoding\",\n        doc=\"\"\"The Content-Encoding entity-header field is used as a\n        modifier to the media-type. When present, its value indicates\n        what additional content codings have been applied to the\n        entity-body, and thus what decoding mechanisms must be applied\n        in order to obtain the media-type referenced by the Content-Type\n        header field.\n\n        .. versionadded:: 0.9\"\"\",\n        read_only=True,\n    )\n    content_md5 = header_property[str](\n        \"Content-MD5\",\n        doc=\"\"\"The Content-MD5 entity-header field, as defined in\n        RFC 1864, is an MD5 digest of the entity-body for the purpose of\n        providing an end-to-end message integrity check (MIC) of the\n        entity-body. (Note: a MIC is good for detecting accidental\n        modification of the entity-body in transit, but is not proof\n        against malicious attacks.)\n\n        .. versionadded:: 0.9\"\"\",\n        read_only=True,\n    )\n    referrer = header_property[str](\n        \"Referer\",\n        doc=\"\"\"The Referer[sic] request-header field allows the client\n        to specify, for the server's benefit, the address (URI) of the\n        resource from which the Request-URI was obtained (the\n        \"referrer\", although the header field is misspelled).\"\"\",\n        read_only=True,\n    )\n    date = header_property(\n        \"Date\",\n        None,\n        parse_date,\n        doc=\"\"\"The Date general-header field represents the date and\n        time at which the message was originated, having the same\n        semantics as orig-date in RFC 822.\n\n        .. versionchanged:: 2.0\n            The datetime object is timezone-aware.\n        \"\"\",\n        read_only=True,\n    )\n    max_forwards = header_property(\n        \"Max-Forwards\",\n        None,\n        int,\n        doc=\"\"\"The Max-Forwards request-header field provides a\n        mechanism with the TRACE and OPTIONS methods to limit the number\n        of proxies or gateways that can forward the request to the next\n        inbound server.\"\"\",\n        read_only=True,\n    )\n\n    def _parse_content_type(self) -> None:\n        if not hasattr(self, \"_parsed_content_type\"):\n            self._parsed_content_type = parse_options_header(\n                self.headers.get(\"Content-Type\", \"\")\n            )\n\n    @property\n    def mimetype(self) -> str:\n        \"\"\"Like :attr:`content_type`, but without parameters (eg, without\n        charset, type etc.) and always lowercase.  For example if the content\n        type is ``text/HTML; charset=utf-8`` the mimetype would be\n        ``'text/html'``.\n        \"\"\"\n        self._parse_content_type()\n        return self._parsed_content_type[0].lower()\n\n    @property\n    def mimetype_params(self) -> dict[str, str]:\n        \"\"\"The mimetype parameters as dict.  For example if the content\n        type is ``text/html; charset=utf-8`` the params would be\n        ``{'charset': 'utf-8'}``.\n        \"\"\"\n        self._parse_content_type()\n        return self._parsed_content_type[1]\n\n    @cached_property\n    def pragma(self) -> HeaderSet:\n        \"\"\"The Pragma general-header field is used to include\n        implementation-specific directives that might apply to any recipient\n        along the request/response chain.  All pragma directives specify\n        optional behavior from the viewpoint of the protocol; however, some\n        systems MAY require that behavior be consistent with the directives.\n        \"\"\"\n        return parse_set_header(self.headers.get(\"Pragma\", \"\"))\n\n    # Accept\n\n    @cached_property\n    def accept_mimetypes(self) -> MIMEAccept:\n        \"\"\"List of mimetypes this client supports as\n        :class:`~werkzeug.datastructures.MIMEAccept` object.\n        \"\"\"\n        return parse_accept_header(self.headers.get(\"Accept\"), MIMEAccept)\n\n    @cached_property\n    def accept_charsets(self) -> CharsetAccept:\n        \"\"\"List of charsets this client supports as\n        :class:`~werkzeug.datastructures.CharsetAccept` object.\n        \"\"\"\n        return parse_accept_header(self.headers.get(\"Accept-Charset\"), CharsetAccept)\n\n    @cached_property\n    def accept_encodings(self) -> Accept:\n        \"\"\"List of encodings this client accepts.  Encodings in a HTTP term\n        are compression encodings such as gzip.  For charsets have a look at\n        :attr:`accept_charset`.\n        \"\"\"\n        return parse_accept_header(self.headers.get(\"Accept-Encoding\"))\n\n    @cached_property\n    def accept_languages(self) -> LanguageAccept:\n        \"\"\"List of languages this client accepts as\n        :class:`~werkzeug.datastructures.LanguageAccept` object.\n\n        .. versionchanged 0.5\n           In previous versions this was a regular\n           :class:`~werkzeug.datastructures.Accept` object.\n        \"\"\"\n        return parse_accept_header(self.headers.get(\"Accept-Language\"), LanguageAccept)\n\n    # ETag\n\n    @cached_property\n    def cache_control(self) -> RequestCacheControl:\n        \"\"\"A :class:`~werkzeug.datastructures.RequestCacheControl` object\n        for the incoming cache control headers.\n        \"\"\"\n        cache_control = self.headers.get(\"Cache-Control\")\n        return parse_cache_control_header(cache_control, None, RequestCacheControl)\n\n    @cached_property\n    def if_match(self) -> ETags:\n        \"\"\"An object containing all the etags in the `If-Match` header.\n\n        :rtype: :class:`~werkzeug.datastructures.ETags`\n        \"\"\"\n        return parse_etags(self.headers.get(\"If-Match\"))\n\n    @cached_property\n    def if_none_match(self) -> ETags:\n        \"\"\"An object containing all the etags in the `If-None-Match` header.\n\n        :rtype: :class:`~werkzeug.datastructures.ETags`\n        \"\"\"\n        return parse_etags(self.headers.get(\"If-None-Match\"))\n\n    @cached_property\n    def if_modified_since(self) -> datetime | None:\n        \"\"\"The parsed `If-Modified-Since` header as a datetime object.\n\n        .. versionchanged:: 2.0\n            The datetime object is timezone-aware.\n        \"\"\"\n        return parse_date(self.headers.get(\"If-Modified-Since\"))\n\n    @cached_property\n    def if_unmodified_since(self) -> datetime | None:\n        \"\"\"The parsed `If-Unmodified-Since` header as a datetime object.\n\n        .. versionchanged:: 2.0\n            The datetime object is timezone-aware.\n        \"\"\"\n        return parse_date(self.headers.get(\"If-Unmodified-Since\"))\n\n    @cached_property\n    def if_range(self) -> IfRange:\n        \"\"\"The parsed ``If-Range`` header.\n\n        .. versionchanged:: 2.0\n            ``IfRange.date`` is timezone-aware.\n\n        .. versionadded:: 0.7\n        \"\"\"\n        return parse_if_range_header(self.headers.get(\"If-Range\"))\n\n    @cached_property\n    def range(self) -> Range | None:\n        \"\"\"The parsed `Range` header.\n\n        .. versionadded:: 0.7\n\n        :rtype: :class:`~werkzeug.datastructures.Range`\n        \"\"\"\n        return parse_range_header(self.headers.get(\"Range\"))\n\n    # User Agent\n\n    @cached_property\n    def user_agent(self) -> UserAgent:\n        \"\"\"The user agent. Use ``user_agent.string`` to get the header\n        value. Set :attr:`user_agent_class` to a subclass of\n        :class:`~werkzeug.user_agent.UserAgent` to provide parsing for\n        the other properties or other extended data.\n\n        .. versionchanged:: 2.1\n            The built-in parser was removed. Set ``user_agent_class`` to a ``UserAgent``\n            subclass to parse data from the string.\n        \"\"\"\n        return self.user_agent_class(self.headers.get(\"User-Agent\", \"\"))\n\n    # Authorization\n\n    @cached_property\n    def authorization(self) -> Authorization | None:\n        \"\"\"The ``Authorization`` header parsed into an :class:`.Authorization` object.\n        ``None`` if the header is not present.\n\n        .. versionchanged:: 2.3\n            :class:`Authorization` is no longer a ``dict``. The ``token`` attribute\n            was added for auth schemes that use a token instead of parameters.\n        \"\"\"\n        return Authorization.from_header(self.headers.get(\"Authorization\"))\n\n    # CORS\n\n    origin = header_property[str](\n        \"Origin\",\n        doc=(\n            \"The host that the request originated from. Set\"\n            \" :attr:`~CORSResponseMixin.access_control_allow_origin` on\"\n            \" the response to indicate which origins are allowed.\"\n        ),\n        read_only=True,\n    )\n\n    access_control_request_headers = header_property(\n        \"Access-Control-Request-Headers\",\n        load_func=parse_set_header,\n        doc=(\n            \"Sent with a preflight request to indicate which headers\"\n            \" will be sent with the cross origin request. Set\"\n            \" :attr:`~CORSResponseMixin.access_control_allow_headers`\"\n            \" on the response to indicate which headers are allowed.\"\n        ),\n        read_only=True,\n    )\n\n    access_control_request_method = header_property[str](\n        \"Access-Control-Request-Method\",\n        doc=(\n            \"Sent with a preflight request to indicate which method\"\n            \" will be used for the cross origin request. Set\"\n            \" :attr:`~CORSResponseMixin.access_control_allow_methods`\"\n            \" on the response to indicate which methods are allowed.\"\n        ),\n        read_only=True,\n    )\n\n    @property\n    def is_json(self) -> bool:\n        \"\"\"Check if the mimetype indicates JSON data, either\n        :mimetype:`application/json` or :mimetype:`application/*+json`.\n        \"\"\"\n        mt = self.mimetype\n        return (\n            mt == \"application/json\"\n            or mt.startswith(\"application/\")\n            and mt.endswith(\"+json\")\n        )\n", "src/werkzeug/sansio/utils.py": "from __future__ import annotations\n\nimport typing as t\nfrom urllib.parse import quote\n\nfrom .._internal import _plain_int\nfrom ..exceptions import SecurityError\nfrom ..urls import uri_to_iri\n\n\ndef host_is_trusted(hostname: str | None, trusted_list: t.Iterable[str]) -> bool:\n    \"\"\"Check if a host matches a list of trusted names.\n\n    :param hostname: The name to check.\n    :param trusted_list: A list of valid names to match. If a name\n        starts with a dot it will match all subdomains.\n\n    .. versionadded:: 0.9\n    \"\"\"\n    if not hostname:\n        return False\n\n    try:\n        hostname = hostname.partition(\":\")[0].encode(\"idna\").decode(\"ascii\")\n    except UnicodeEncodeError:\n        return False\n\n    if isinstance(trusted_list, str):\n        trusted_list = [trusted_list]\n\n    for ref in trusted_list:\n        if ref.startswith(\".\"):\n            ref = ref[1:]\n            suffix_match = True\n        else:\n            suffix_match = False\n\n        try:\n            ref = ref.partition(\":\")[0].encode(\"idna\").decode(\"ascii\")\n        except UnicodeEncodeError:\n            return False\n\n        if ref == hostname or (suffix_match and hostname.endswith(f\".{ref}\")):\n            return True\n\n    return False\n\n\ndef get_host(\n    scheme: str,\n    host_header: str | None,\n    server: tuple[str, int | None] | None = None,\n    trusted_hosts: t.Iterable[str] | None = None,\n) -> str:\n    \"\"\"Return the host for the given parameters.\n\n    This first checks the ``host_header``. If it's not present, then\n    ``server`` is used. The host will only contain the port if it is\n    different than the standard port for the protocol.\n\n    Optionally, verify that the host is trusted using\n    :func:`host_is_trusted` and raise a\n    :exc:`~werkzeug.exceptions.SecurityError` if it is not.\n\n    :param scheme: The protocol the request used, like ``\"https\"``.\n    :param host_header: The ``Host`` header value.\n    :param server: Address of the server. ``(host, port)``, or\n        ``(path, None)`` for unix sockets.\n    :param trusted_hosts: A list of trusted host names.\n\n    :return: Host, with port if necessary.\n    :raise ~werkzeug.exceptions.SecurityError: If the host is not\n        trusted.\n    \"\"\"\n    host = \"\"\n\n    if host_header is not None:\n        host = host_header\n    elif server is not None:\n        host = server[0]\n\n        if server[1] is not None:\n            host = f\"{host}:{server[1]}\"\n\n    if scheme in {\"http\", \"ws\"} and host.endswith(\":80\"):\n        host = host[:-3]\n    elif scheme in {\"https\", \"wss\"} and host.endswith(\":443\"):\n        host = host[:-4]\n\n    if trusted_hosts is not None:\n        if not host_is_trusted(host, trusted_hosts):\n            raise SecurityError(f\"Host {host!r} is not trusted.\")\n\n    return host\n\n\ndef get_current_url(\n    scheme: str,\n    host: str,\n    root_path: str | None = None,\n    path: str | None = None,\n    query_string: bytes | None = None,\n) -> str:\n    \"\"\"Recreate the URL for a request. If an optional part isn't\n    provided, it and subsequent parts are not included in the URL.\n\n    The URL is an IRI, not a URI, so it may contain Unicode characters.\n    Use :func:`~werkzeug.urls.iri_to_uri` to convert it to ASCII.\n\n    :param scheme: The protocol the request used, like ``\"https\"``.\n    :param host: The host the request was made to. See :func:`get_host`.\n    :param root_path: Prefix that the application is mounted under. This\n        is prepended to ``path``.\n    :param path: The path part of the URL after ``root_path``.\n    :param query_string: The portion of the URL after the \"?\".\n    \"\"\"\n    url = [scheme, \"://\", host]\n\n    if root_path is None:\n        url.append(\"/\")\n        return uri_to_iri(\"\".join(url))\n\n    # safe = https://url.spec.whatwg.org/#url-path-segment-string\n    # as well as percent for things that are already quoted\n    url.append(quote(root_path.rstrip(\"/\"), safe=\"!$&'()*+,/:;=@%\"))\n    url.append(\"/\")\n\n    if path is None:\n        return uri_to_iri(\"\".join(url))\n\n    url.append(quote(path.lstrip(\"/\"), safe=\"!$&'()*+,/:;=@%\"))\n\n    if query_string:\n        url.append(\"?\")\n        url.append(quote(query_string, safe=\"!$&'()*+,/:;=?@%\"))\n\n    return uri_to_iri(\"\".join(url))\n\n\ndef get_content_length(\n    http_content_length: str | None = None,\n    http_transfer_encoding: str | None = None,\n) -> int | None:\n    \"\"\"Return the ``Content-Length`` header value as an int. If the header is not given\n    or the ``Transfer-Encoding`` header is ``chunked``, ``None`` is returned to indicate\n    a streaming request. If the value is not an integer, or negative, 0 is returned.\n\n    :param http_content_length: The Content-Length HTTP header.\n    :param http_transfer_encoding: The Transfer-Encoding HTTP header.\n\n    .. versionadded:: 2.2\n    \"\"\"\n    if http_transfer_encoding == \"chunked\" or http_content_length is None:\n        return None\n\n    try:\n        return max(0, _plain_int(http_content_length))\n    except ValueError:\n        return 0\n", "src/werkzeug/sansio/__init__.py": "", "src/werkzeug/routing/map.py": "from __future__ import annotations\n\nimport typing as t\nimport warnings\nfrom pprint import pformat\nfrom threading import Lock\nfrom urllib.parse import quote\nfrom urllib.parse import urljoin\nfrom urllib.parse import urlunsplit\n\nfrom .._internal import _get_environ\nfrom .._internal import _wsgi_decoding_dance\nfrom ..datastructures import ImmutableDict\nfrom ..datastructures import MultiDict\nfrom ..exceptions import BadHost\nfrom ..exceptions import HTTPException\nfrom ..exceptions import MethodNotAllowed\nfrom ..exceptions import NotFound\nfrom ..urls import _urlencode\nfrom ..wsgi import get_host\nfrom .converters import DEFAULT_CONVERTERS\nfrom .exceptions import BuildError\nfrom .exceptions import NoMatch\nfrom .exceptions import RequestAliasRedirect\nfrom .exceptions import RequestPath\nfrom .exceptions import RequestRedirect\nfrom .exceptions import WebsocketMismatch\nfrom .matcher import StateMachineMatcher\nfrom .rules import _simple_rule_re\nfrom .rules import Rule\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n\n    from ..wrappers.request import Request\n    from .converters import BaseConverter\n    from .rules import RuleFactory\n\n\nclass Map:\n    \"\"\"The map class stores all the URL rules and some configuration\n    parameters.  Some of the configuration values are only stored on the\n    `Map` instance since those affect all rules, others are just defaults\n    and can be overridden for each rule.  Note that you have to specify all\n    arguments besides the `rules` as keyword arguments!\n\n    :param rules: sequence of url rules for this map.\n    :param default_subdomain: The default subdomain for rules without a\n                              subdomain defined.\n    :param strict_slashes: If a rule ends with a slash but the matched\n        URL does not, redirect to the URL with a trailing slash.\n    :param merge_slashes: Merge consecutive slashes when matching or\n        building URLs. Matches will redirect to the normalized URL.\n        Slashes in variable parts are not merged.\n    :param redirect_defaults: This will redirect to the default rule if it\n                              wasn't visited that way. This helps creating\n                              unique URLs.\n    :param converters: A dict of converters that adds additional converters\n                       to the list of converters. If you redefine one\n                       converter this will override the original one.\n    :param sort_parameters: If set to `True` the url parameters are sorted.\n                            See `url_encode` for more details.\n    :param sort_key: The sort key function for `url_encode`.\n    :param host_matching: if set to `True` it enables the host matching\n                          feature and disables the subdomain one.  If\n                          enabled the `host` parameter to rules is used\n                          instead of the `subdomain` one.\n\n    .. versionchanged:: 3.0\n        The ``charset`` and ``encoding_errors`` parameters were removed.\n\n    .. versionchanged:: 1.0\n        If ``url_scheme`` is ``ws`` or ``wss``, only WebSocket rules will match.\n\n    .. versionchanged:: 1.0\n        The ``merge_slashes`` parameter was added.\n\n    .. versionchanged:: 0.7\n        The ``encoding_errors`` and ``host_matching`` parameters were added.\n\n    .. versionchanged:: 0.5\n        The ``sort_parameters`` and ``sort_key``  paramters were added.\n    \"\"\"\n\n    #: A dict of default converters to be used.\n    default_converters = ImmutableDict(DEFAULT_CONVERTERS)\n\n    #: The type of lock to use when updating.\n    #:\n    #: .. versionadded:: 1.0\n    lock_class = Lock\n\n    def __init__(\n        self,\n        rules: t.Iterable[RuleFactory] | None = None,\n        default_subdomain: str = \"\",\n        strict_slashes: bool = True,\n        merge_slashes: bool = True,\n        redirect_defaults: bool = True,\n        converters: t.Mapping[str, type[BaseConverter]] | None = None,\n        sort_parameters: bool = False,\n        sort_key: t.Callable[[t.Any], t.Any] | None = None,\n        host_matching: bool = False,\n    ) -> None:\n        self._matcher = StateMachineMatcher(merge_slashes)\n        self._rules_by_endpoint: dict[t.Any, list[Rule]] = {}\n        self._remap = True\n        self._remap_lock = self.lock_class()\n\n        self.default_subdomain = default_subdomain\n        self.strict_slashes = strict_slashes\n        self.redirect_defaults = redirect_defaults\n        self.host_matching = host_matching\n\n        self.converters = self.default_converters.copy()\n        if converters:\n            self.converters.update(converters)\n\n        self.sort_parameters = sort_parameters\n        self.sort_key = sort_key\n\n        for rulefactory in rules or ():\n            self.add(rulefactory)\n\n    @property\n    def merge_slashes(self) -> bool:\n        return self._matcher.merge_slashes\n\n    @merge_slashes.setter\n    def merge_slashes(self, value: bool) -> None:\n        self._matcher.merge_slashes = value\n\n    def is_endpoint_expecting(self, endpoint: t.Any, *arguments: str) -> bool:\n        \"\"\"Iterate over all rules and check if the endpoint expects\n        the arguments provided.  This is for example useful if you have\n        some URLs that expect a language code and others that do not and\n        you want to wrap the builder a bit so that the current language\n        code is automatically added if not provided but endpoints expect\n        it.\n\n        :param endpoint: the endpoint to check.\n        :param arguments: this function accepts one or more arguments\n                          as positional arguments.  Each one of them is\n                          checked.\n        \"\"\"\n        self.update()\n        arguments_set = set(arguments)\n        for rule in self._rules_by_endpoint[endpoint]:\n            if arguments_set.issubset(rule.arguments):\n                return True\n        return False\n\n    @property\n    def _rules(self) -> list[Rule]:\n        return [rule for rules in self._rules_by_endpoint.values() for rule in rules]\n\n    def iter_rules(self, endpoint: t.Any | None = None) -> t.Iterator[Rule]:\n        \"\"\"Iterate over all rules or the rules of an endpoint.\n\n        :param endpoint: if provided only the rules for that endpoint\n                         are returned.\n        :return: an iterator\n        \"\"\"\n        self.update()\n        if endpoint is not None:\n            return iter(self._rules_by_endpoint[endpoint])\n        return iter(self._rules)\n\n    def add(self, rulefactory: RuleFactory) -> None:\n        \"\"\"Add a new rule or factory to the map and bind it.  Requires that the\n        rule is not bound to another map.\n\n        :param rulefactory: a :class:`Rule` or :class:`RuleFactory`\n        \"\"\"\n        for rule in rulefactory.get_rules(self):\n            rule.bind(self)\n            if not rule.build_only:\n                self._matcher.add(rule)\n            self._rules_by_endpoint.setdefault(rule.endpoint, []).append(rule)\n        self._remap = True\n\n    def bind(\n        self,\n        server_name: str,\n        script_name: str | None = None,\n        subdomain: str | None = None,\n        url_scheme: str = \"http\",\n        default_method: str = \"GET\",\n        path_info: str | None = None,\n        query_args: t.Mapping[str, t.Any] | str | None = None,\n    ) -> MapAdapter:\n        \"\"\"Return a new :class:`MapAdapter` with the details specified to the\n        call.  Note that `script_name` will default to ``'/'`` if not further\n        specified or `None`.  The `server_name` at least is a requirement\n        because the HTTP RFC requires absolute URLs for redirects and so all\n        redirect exceptions raised by Werkzeug will contain the full canonical\n        URL.\n\n        If no path_info is passed to :meth:`match` it will use the default path\n        info passed to bind.  While this doesn't really make sense for\n        manual bind calls, it's useful if you bind a map to a WSGI\n        environment which already contains the path info.\n\n        `subdomain` will default to the `default_subdomain` for this map if\n        no defined. If there is no `default_subdomain` you cannot use the\n        subdomain feature.\n\n        .. versionchanged:: 1.0\n            If ``url_scheme`` is ``ws`` or ``wss``, only WebSocket rules\n            will match.\n\n        .. versionchanged:: 0.15\n            ``path_info`` defaults to ``'/'`` if ``None``.\n\n        .. versionchanged:: 0.8\n            ``query_args`` can be a string.\n\n        .. versionchanged:: 0.7\n            Added ``query_args``.\n        \"\"\"\n        server_name = server_name.lower()\n        if self.host_matching:\n            if subdomain is not None:\n                raise RuntimeError(\"host matching enabled and a subdomain was provided\")\n        elif subdomain is None:\n            subdomain = self.default_subdomain\n        if script_name is None:\n            script_name = \"/\"\n        if path_info is None:\n            path_info = \"/\"\n\n        # Port isn't part of IDNA, and might push a name over the 63 octet limit.\n        server_name, port_sep, port = server_name.partition(\":\")\n\n        try:\n            server_name = server_name.encode(\"idna\").decode(\"ascii\")\n        except UnicodeError as e:\n            raise BadHost() from e\n\n        return MapAdapter(\n            self,\n            f\"{server_name}{port_sep}{port}\",\n            script_name,\n            subdomain,\n            url_scheme,\n            path_info,\n            default_method,\n            query_args,\n        )\n\n    def bind_to_environ(\n        self,\n        environ: WSGIEnvironment | Request,\n        server_name: str | None = None,\n        subdomain: str | None = None,\n    ) -> MapAdapter:\n        \"\"\"Like :meth:`bind` but you can pass it an WSGI environment and it\n        will fetch the information from that dictionary.  Note that because of\n        limitations in the protocol there is no way to get the current\n        subdomain and real `server_name` from the environment.  If you don't\n        provide it, Werkzeug will use `SERVER_NAME` and `SERVER_PORT` (or\n        `HTTP_HOST` if provided) as used `server_name` with disabled subdomain\n        feature.\n\n        If `subdomain` is `None` but an environment and a server name is\n        provided it will calculate the current subdomain automatically.\n        Example: `server_name` is ``'example.com'`` and the `SERVER_NAME`\n        in the wsgi `environ` is ``'staging.dev.example.com'`` the calculated\n        subdomain will be ``'staging.dev'``.\n\n        If the object passed as environ has an environ attribute, the value of\n        this attribute is used instead.  This allows you to pass request\n        objects.  Additionally `PATH_INFO` added as a default of the\n        :class:`MapAdapter` so that you don't have to pass the path info to\n        the match method.\n\n        .. versionchanged:: 1.0.0\n            If the passed server name specifies port 443, it will match\n            if the incoming scheme is ``https`` without a port.\n\n        .. versionchanged:: 1.0.0\n            A warning is shown when the passed server name does not\n            match the incoming WSGI server name.\n\n        .. versionchanged:: 0.8\n           This will no longer raise a ValueError when an unexpected server\n           name was passed.\n\n        .. versionchanged:: 0.5\n            previously this method accepted a bogus `calculate_subdomain`\n            parameter that did not have any effect.  It was removed because\n            of that.\n\n        :param environ: a WSGI environment.\n        :param server_name: an optional server name hint (see above).\n        :param subdomain: optionally the current subdomain (see above).\n        \"\"\"\n        env = _get_environ(environ)\n        wsgi_server_name = get_host(env).lower()\n        scheme = env[\"wsgi.url_scheme\"]\n        upgrade = any(\n            v.strip() == \"upgrade\"\n            for v in env.get(\"HTTP_CONNECTION\", \"\").lower().split(\",\")\n        )\n\n        if upgrade and env.get(\"HTTP_UPGRADE\", \"\").lower() == \"websocket\":\n            scheme = \"wss\" if scheme == \"https\" else \"ws\"\n\n        if server_name is None:\n            server_name = wsgi_server_name\n        else:\n            server_name = server_name.lower()\n\n            # strip standard port to match get_host()\n            if scheme in {\"http\", \"ws\"} and server_name.endswith(\":80\"):\n                server_name = server_name[:-3]\n            elif scheme in {\"https\", \"wss\"} and server_name.endswith(\":443\"):\n                server_name = server_name[:-4]\n\n        if subdomain is None and not self.host_matching:\n            cur_server_name = wsgi_server_name.split(\".\")\n            real_server_name = server_name.split(\".\")\n            offset = -len(real_server_name)\n\n            if cur_server_name[offset:] != real_server_name:\n                # This can happen even with valid configs if the server was\n                # accessed directly by IP address under some situations.\n                # Instead of raising an exception like in Werkzeug 0.7 or\n                # earlier we go by an invalid subdomain which will result\n                # in a 404 error on matching.\n                warnings.warn(\n                    f\"Current server name {wsgi_server_name!r} doesn't match configured\"\n                    f\" server name {server_name!r}\",\n                    stacklevel=2,\n                )\n                subdomain = \"<invalid>\"\n            else:\n                subdomain = \".\".join(filter(None, cur_server_name[:offset]))\n\n        def _get_wsgi_string(name: str) -> str | None:\n            val = env.get(name)\n            if val is not None:\n                return _wsgi_decoding_dance(val)\n            return None\n\n        script_name = _get_wsgi_string(\"SCRIPT_NAME\")\n        path_info = _get_wsgi_string(\"PATH_INFO\")\n        query_args = _get_wsgi_string(\"QUERY_STRING\")\n        return Map.bind(\n            self,\n            server_name,\n            script_name,\n            subdomain,\n            scheme,\n            env[\"REQUEST_METHOD\"],\n            path_info,\n            query_args=query_args,\n        )\n\n    def update(self) -> None:\n        \"\"\"Called before matching and building to keep the compiled rules\n        in the correct order after things changed.\n        \"\"\"\n        if not self._remap:\n            return\n\n        with self._remap_lock:\n            if not self._remap:\n                return\n\n            self._matcher.update()\n            for rules in self._rules_by_endpoint.values():\n                rules.sort(key=lambda x: x.build_compare_key())\n            self._remap = False\n\n    def __repr__(self) -> str:\n        rules = self.iter_rules()\n        return f\"{type(self).__name__}({pformat(list(rules))})\"\n\n\nclass MapAdapter:\n    \"\"\"Returned by :meth:`Map.bind` or :meth:`Map.bind_to_environ` and does\n    the URL matching and building based on runtime information.\n    \"\"\"\n\n    def __init__(\n        self,\n        map: Map,\n        server_name: str,\n        script_name: str,\n        subdomain: str | None,\n        url_scheme: str,\n        path_info: str,\n        default_method: str,\n        query_args: t.Mapping[str, t.Any] | str | None = None,\n    ):\n        self.map = map\n        self.server_name = server_name\n\n        if not script_name.endswith(\"/\"):\n            script_name += \"/\"\n\n        self.script_name = script_name\n        self.subdomain = subdomain\n        self.url_scheme = url_scheme\n        self.path_info = path_info\n        self.default_method = default_method\n        self.query_args = query_args\n        self.websocket = self.url_scheme in {\"ws\", \"wss\"}\n\n    def dispatch(\n        self,\n        view_func: t.Callable[[str, t.Mapping[str, t.Any]], WSGIApplication],\n        path_info: str | None = None,\n        method: str | None = None,\n        catch_http_exceptions: bool = False,\n    ) -> WSGIApplication:\n        \"\"\"Does the complete dispatching process.  `view_func` is called with\n        the endpoint and a dict with the values for the view.  It should\n        look up the view function, call it, and return a response object\n        or WSGI application.  http exceptions are not caught by default\n        so that applications can display nicer error messages by just\n        catching them by hand.  If you want to stick with the default\n        error messages you can pass it ``catch_http_exceptions=True`` and\n        it will catch the http exceptions.\n\n        Here a small example for the dispatch usage::\n\n            from werkzeug.wrappers import Request, Response\n            from werkzeug.wsgi import responder\n            from werkzeug.routing import Map, Rule\n\n            def on_index(request):\n                return Response('Hello from the index')\n\n            url_map = Map([Rule('/', endpoint='index')])\n            views = {'index': on_index}\n\n            @responder\n            def application(environ, start_response):\n                request = Request(environ)\n                urls = url_map.bind_to_environ(environ)\n                return urls.dispatch(lambda e, v: views[e](request, **v),\n                                     catch_http_exceptions=True)\n\n        Keep in mind that this method might return exception objects, too, so\n        use :class:`Response.force_type` to get a response object.\n\n        :param view_func: a function that is called with the endpoint as\n                          first argument and the value dict as second.  Has\n                          to dispatch to the actual view function with this\n                          information.  (see above)\n        :param path_info: the path info to use for matching.  Overrides the\n                          path info specified on binding.\n        :param method: the HTTP method used for matching.  Overrides the\n                       method specified on binding.\n        :param catch_http_exceptions: set to `True` to catch any of the\n                                      werkzeug :class:`HTTPException`\\\\s.\n        \"\"\"\n        try:\n            try:\n                endpoint, args = self.match(path_info, method)\n            except RequestRedirect as e:\n                return e\n            return view_func(endpoint, args)\n        except HTTPException as e:\n            if catch_http_exceptions:\n                return e\n            raise\n\n    @t.overload\n    def match(\n        self,\n        path_info: str | None = None,\n        method: str | None = None,\n        return_rule: t.Literal[False] = False,\n        query_args: t.Mapping[str, t.Any] | str | None = None,\n        websocket: bool | None = None,\n    ) -> tuple[t.Any, t.Mapping[str, t.Any]]: ...\n\n    @t.overload\n    def match(\n        self,\n        path_info: str | None = None,\n        method: str | None = None,\n        return_rule: t.Literal[True] = True,\n        query_args: t.Mapping[str, t.Any] | str | None = None,\n        websocket: bool | None = None,\n    ) -> tuple[Rule, t.Mapping[str, t.Any]]: ...\n\n    def match(\n        self,\n        path_info: str | None = None,\n        method: str | None = None,\n        return_rule: bool = False,\n        query_args: t.Mapping[str, t.Any] | str | None = None,\n        websocket: bool | None = None,\n    ) -> tuple[t.Any | Rule, t.Mapping[str, t.Any]]:\n        \"\"\"The usage is simple: you just pass the match method the current\n        path info as well as the method (which defaults to `GET`).  The\n        following things can then happen:\n\n        - you receive a `NotFound` exception that indicates that no URL is\n          matching.  A `NotFound` exception is also a WSGI application you\n          can call to get a default page not found page (happens to be the\n          same object as `werkzeug.exceptions.NotFound`)\n\n        - you receive a `MethodNotAllowed` exception that indicates that there\n          is a match for this URL but not for the current request method.\n          This is useful for RESTful applications.\n\n        - you receive a `RequestRedirect` exception with a `new_url`\n          attribute.  This exception is used to notify you about a request\n          Werkzeug requests from your WSGI application.  This is for example the\n          case if you request ``/foo`` although the correct URL is ``/foo/``\n          You can use the `RequestRedirect` instance as response-like object\n          similar to all other subclasses of `HTTPException`.\n\n        - you receive a ``WebsocketMismatch`` exception if the only\n          match is a WebSocket rule but the bind is an HTTP request, or\n          if the match is an HTTP rule but the bind is a WebSocket\n          request.\n\n        - you get a tuple in the form ``(endpoint, arguments)`` if there is\n          a match (unless `return_rule` is True, in which case you get a tuple\n          in the form ``(rule, arguments)``)\n\n        If the path info is not passed to the match method the default path\n        info of the map is used (defaults to the root URL if not defined\n        explicitly).\n\n        All of the exceptions raised are subclasses of `HTTPException` so they\n        can be used as WSGI responses. They will all render generic error or\n        redirect pages.\n\n        Here is a small example for matching:\n\n        >>> m = Map([\n        ...     Rule('/', endpoint='index'),\n        ...     Rule('/downloads/', endpoint='downloads/index'),\n        ...     Rule('/downloads/<int:id>', endpoint='downloads/show')\n        ... ])\n        >>> urls = m.bind(\"example.com\", \"/\")\n        >>> urls.match(\"/\", \"GET\")\n        ('index', {})\n        >>> urls.match(\"/downloads/42\")\n        ('downloads/show', {'id': 42})\n\n        And here is what happens on redirect and missing URLs:\n\n        >>> urls.match(\"/downloads\")\n        Traceback (most recent call last):\n          ...\n        RequestRedirect: http://example.com/downloads/\n        >>> urls.match(\"/missing\")\n        Traceback (most recent call last):\n          ...\n        NotFound: 404 Not Found\n\n        :param path_info: the path info to use for matching.  Overrides the\n                          path info specified on binding.\n        :param method: the HTTP method used for matching.  Overrides the\n                       method specified on binding.\n        :param return_rule: return the rule that matched instead of just the\n                            endpoint (defaults to `False`).\n        :param query_args: optional query arguments that are used for\n                           automatic redirects as string or dictionary.  It's\n                           currently not possible to use the query arguments\n                           for URL matching.\n        :param websocket: Match WebSocket instead of HTTP requests. A\n            websocket request has a ``ws`` or ``wss``\n            :attr:`url_scheme`. This overrides that detection.\n\n        .. versionadded:: 1.0\n            Added ``websocket``.\n\n        .. versionchanged:: 0.8\n            ``query_args`` can be a string.\n\n        .. versionadded:: 0.7\n            Added ``query_args``.\n\n        .. versionadded:: 0.6\n            Added ``return_rule``.\n        \"\"\"\n        self.map.update()\n        if path_info is None:\n            path_info = self.path_info\n        if query_args is None:\n            query_args = self.query_args or {}\n        method = (method or self.default_method).upper()\n\n        if websocket is None:\n            websocket = self.websocket\n\n        domain_part = self.server_name\n\n        if not self.map.host_matching and self.subdomain is not None:\n            domain_part = self.subdomain\n\n        path_part = f\"/{path_info.lstrip('/')}\" if path_info else \"\"\n\n        try:\n            result = self.map._matcher.match(domain_part, path_part, method, websocket)\n        except RequestPath as e:\n            # safe = https://url.spec.whatwg.org/#url-path-segment-string\n            new_path = quote(e.path_info, safe=\"!$&'()*+,/:;=@\")\n            raise RequestRedirect(\n                self.make_redirect_url(new_path, query_args)\n            ) from None\n        except RequestAliasRedirect as e:\n            raise RequestRedirect(\n                self.make_alias_redirect_url(\n                    f\"{domain_part}|{path_part}\",\n                    e.endpoint,\n                    e.matched_values,\n                    method,\n                    query_args,\n                )\n            ) from None\n        except NoMatch as e:\n            if e.have_match_for:\n                raise MethodNotAllowed(valid_methods=list(e.have_match_for)) from None\n\n            if e.websocket_mismatch:\n                raise WebsocketMismatch() from None\n\n            raise NotFound() from None\n        else:\n            rule, rv = result\n\n            if self.map.redirect_defaults:\n                redirect_url = self.get_default_redirect(rule, method, rv, query_args)\n                if redirect_url is not None:\n                    raise RequestRedirect(redirect_url)\n\n            if rule.redirect_to is not None:\n                if isinstance(rule.redirect_to, str):\n\n                    def _handle_match(match: t.Match[str]) -> str:\n                        value = rv[match.group(1)]\n                        return rule._converters[match.group(1)].to_url(value)\n\n                    redirect_url = _simple_rule_re.sub(_handle_match, rule.redirect_to)\n                else:\n                    redirect_url = rule.redirect_to(self, **rv)\n\n                if self.subdomain:\n                    netloc = f\"{self.subdomain}.{self.server_name}\"\n                else:\n                    netloc = self.server_name\n\n                raise RequestRedirect(\n                    urljoin(\n                        f\"{self.url_scheme or 'http'}://{netloc}{self.script_name}\",\n                        redirect_url,\n                    )\n                )\n\n            if return_rule:\n                return rule, rv\n            else:\n                return rule.endpoint, rv\n\n    def test(self, path_info: str | None = None, method: str | None = None) -> bool:\n        \"\"\"Test if a rule would match.  Works like `match` but returns `True`\n        if the URL matches, or `False` if it does not exist.\n\n        :param path_info: the path info to use for matching.  Overrides the\n                          path info specified on binding.\n        :param method: the HTTP method used for matching.  Overrides the\n                       method specified on binding.\n        \"\"\"\n        try:\n            self.match(path_info, method)\n        except RequestRedirect:\n            pass\n        except HTTPException:\n            return False\n        return True\n\n    def allowed_methods(self, path_info: str | None = None) -> t.Iterable[str]:\n        \"\"\"Returns the valid methods that match for a given path.\n\n        .. versionadded:: 0.7\n        \"\"\"\n        try:\n            self.match(path_info, method=\"--\")\n        except MethodNotAllowed as e:\n            return e.valid_methods  # type: ignore\n        except HTTPException:\n            pass\n        return []\n\n    def get_host(self, domain_part: str | None) -> str:\n        \"\"\"Figures out the full host name for the given domain part.  The\n        domain part is a subdomain in case host matching is disabled or\n        a full host name.\n        \"\"\"\n        if self.map.host_matching:\n            if domain_part is None:\n                return self.server_name\n\n            return domain_part\n\n        if domain_part is None:\n            subdomain = self.subdomain\n        else:\n            subdomain = domain_part\n\n        if subdomain:\n            return f\"{subdomain}.{self.server_name}\"\n        else:\n            return self.server_name\n\n    def get_default_redirect(\n        self,\n        rule: Rule,\n        method: str,\n        values: t.MutableMapping[str, t.Any],\n        query_args: t.Mapping[str, t.Any] | str,\n    ) -> str | None:\n        \"\"\"A helper that returns the URL to redirect to if it finds one.\n        This is used for default redirecting only.\n\n        :internal:\n        \"\"\"\n        assert self.map.redirect_defaults\n        for r in self.map._rules_by_endpoint[rule.endpoint]:\n            # every rule that comes after this one, including ourself\n            # has a lower priority for the defaults.  We order the ones\n            # with the highest priority up for building.\n            if r is rule:\n                break\n            if r.provides_defaults_for(rule) and r.suitable_for(values, method):\n                values.update(r.defaults)  # type: ignore\n                domain_part, path = r.build(values)  # type: ignore\n                return self.make_redirect_url(path, query_args, domain_part=domain_part)\n        return None\n\n    def encode_query_args(self, query_args: t.Mapping[str, t.Any] | str) -> str:\n        if not isinstance(query_args, str):\n            return _urlencode(query_args)\n        return query_args\n\n    def make_redirect_url(\n        self,\n        path_info: str,\n        query_args: t.Mapping[str, t.Any] | str | None = None,\n        domain_part: str | None = None,\n    ) -> str:\n        \"\"\"Creates a redirect URL.\n\n        :internal:\n        \"\"\"\n        if query_args is None:\n            query_args = self.query_args\n\n        if query_args:\n            query_str = self.encode_query_args(query_args)\n        else:\n            query_str = None\n\n        scheme = self.url_scheme or \"http\"\n        host = self.get_host(domain_part)\n        path = \"/\".join((self.script_name.strip(\"/\"), path_info.lstrip(\"/\")))\n        return urlunsplit((scheme, host, path, query_str, None))\n\n    def make_alias_redirect_url(\n        self,\n        path: str,\n        endpoint: t.Any,\n        values: t.Mapping[str, t.Any],\n        method: str,\n        query_args: t.Mapping[str, t.Any] | str,\n    ) -> str:\n        \"\"\"Internally called to make an alias redirect URL.\"\"\"\n        url = self.build(\n            endpoint, values, method, append_unknown=False, force_external=True\n        )\n        if query_args:\n            url += f\"?{self.encode_query_args(query_args)}\"\n        assert url != path, \"detected invalid alias setting. No canonical URL found\"\n        return url\n\n    def _partial_build(\n        self,\n        endpoint: t.Any,\n        values: t.Mapping[str, t.Any],\n        method: str | None,\n        append_unknown: bool,\n    ) -> tuple[str, str, bool] | None:\n        \"\"\"Helper for :meth:`build`.  Returns subdomain and path for the\n        rule that accepts this endpoint, values and method.\n\n        :internal:\n        \"\"\"\n        # in case the method is none, try with the default method first\n        if method is None:\n            rv = self._partial_build(\n                endpoint, values, self.default_method, append_unknown\n            )\n            if rv is not None:\n                return rv\n\n        # Default method did not match or a specific method is passed.\n        # Check all for first match with matching host. If no matching\n        # host is found, go with first result.\n        first_match = None\n\n        for rule in self.map._rules_by_endpoint.get(endpoint, ()):\n            if rule.suitable_for(values, method):\n                build_rv = rule.build(values, append_unknown)\n\n                if build_rv is not None:\n                    rv = (build_rv[0], build_rv[1], rule.websocket)\n                    if self.map.host_matching:\n                        if rv[0] == self.server_name:\n                            return rv\n                        elif first_match is None:\n                            first_match = rv\n                    else:\n                        return rv\n\n        return first_match\n\n    def build(\n        self,\n        endpoint: t.Any,\n        values: t.Mapping[str, t.Any] | None = None,\n        method: str | None = None,\n        force_external: bool = False,\n        append_unknown: bool = True,\n        url_scheme: str | None = None,\n    ) -> str:\n        \"\"\"Building URLs works pretty much the other way round.  Instead of\n        `match` you call `build` and pass it the endpoint and a dict of\n        arguments for the placeholders.\n\n        The `build` function also accepts an argument called `force_external`\n        which, if you set it to `True` will force external URLs. Per default\n        external URLs (include the server name) will only be used if the\n        target URL is on a different subdomain.\n\n        >>> m = Map([\n        ...     Rule('/', endpoint='index'),\n        ...     Rule('/downloads/', endpoint='downloads/index'),\n        ...     Rule('/downloads/<int:id>', endpoint='downloads/show')\n        ... ])\n        >>> urls = m.bind(\"example.com\", \"/\")\n        >>> urls.build(\"index\", {})\n        '/'\n        >>> urls.build(\"downloads/show\", {'id': 42})\n        '/downloads/42'\n        >>> urls.build(\"downloads/show\", {'id': 42}, force_external=True)\n        'http://example.com/downloads/42'\n\n        Because URLs cannot contain non ASCII data you will always get\n        bytes back.  Non ASCII characters are urlencoded with the\n        charset defined on the map instance.\n\n        Additional values are converted to strings and appended to the URL as\n        URL querystring parameters:\n\n        >>> urls.build(\"index\", {'q': 'My Searchstring'})\n        '/?q=My+Searchstring'\n\n        When processing those additional values, lists are furthermore\n        interpreted as multiple values (as per\n        :py:class:`werkzeug.datastructures.MultiDict`):\n\n        >>> urls.build(\"index\", {'q': ['a', 'b', 'c']})\n        '/?q=a&q=b&q=c'\n\n        Passing a ``MultiDict`` will also add multiple values:\n\n        >>> urls.build(\"index\", MultiDict((('p', 'z'), ('q', 'a'), ('q', 'b'))))\n        '/?p=z&q=a&q=b'\n\n        If a rule does not exist when building a `BuildError` exception is\n        raised.\n\n        The build method accepts an argument called `method` which allows you\n        to specify the method you want to have an URL built for if you have\n        different methods for the same endpoint specified.\n\n        :param endpoint: the endpoint of the URL to build.\n        :param values: the values for the URL to build.  Unhandled values are\n                       appended to the URL as query parameters.\n        :param method: the HTTP method for the rule if there are different\n                       URLs for different methods on the same endpoint.\n        :param force_external: enforce full canonical external URLs. If the URL\n                               scheme is not provided, this will generate\n                               a protocol-relative URL.\n        :param append_unknown: unknown parameters are appended to the generated\n                               URL as query string argument.  Disable this\n                               if you want the builder to ignore those.\n        :param url_scheme: Scheme to use in place of the bound\n            :attr:`url_scheme`.\n\n        .. versionchanged:: 2.0\n            Added the ``url_scheme`` parameter.\n\n        .. versionadded:: 0.6\n           Added the ``append_unknown`` parameter.\n        \"\"\"\n        self.map.update()\n\n        if values:\n            if isinstance(values, MultiDict):\n                values = {\n                    k: (v[0] if len(v) == 1 else v)\n                    for k, v in dict.items(values)\n                    if len(v) != 0\n                }\n            else:  # plain dict\n                values = {k: v for k, v in values.items() if v is not None}\n        else:\n            values = {}\n\n        rv = self._partial_build(endpoint, values, method, append_unknown)\n        if rv is None:\n            raise BuildError(endpoint, values, method, self)\n\n        domain_part, path, websocket = rv\n        host = self.get_host(domain_part)\n\n        if url_scheme is None:\n            url_scheme = self.url_scheme\n\n        # Always build WebSocket routes with the scheme (browsers\n        # require full URLs). If bound to a WebSocket, ensure that HTTP\n        # routes are built with an HTTP scheme.\n        secure = url_scheme in {\"https\", \"wss\"}\n\n        if websocket:\n            force_external = True\n            url_scheme = \"wss\" if secure else \"ws\"\n        elif url_scheme:\n            url_scheme = \"https\" if secure else \"http\"\n\n        # shortcut this.\n        if not force_external and (\n            (self.map.host_matching and host == self.server_name)\n            or (not self.map.host_matching and domain_part == self.subdomain)\n        ):\n            return f\"{self.script_name.rstrip('/')}/{path.lstrip('/')}\"\n\n        scheme = f\"{url_scheme}:\" if url_scheme else \"\"\n        return f\"{scheme}//{host}{self.script_name[:-1]}/{path.lstrip('/')}\"\n", "src/werkzeug/routing/exceptions.py": "from __future__ import annotations\n\nimport difflib\nimport typing as t\n\nfrom ..exceptions import BadRequest\nfrom ..exceptions import HTTPException\nfrom ..utils import cached_property\nfrom ..utils import redirect\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import WSGIEnvironment\n\n    from ..wrappers.request import Request\n    from ..wrappers.response import Response\n    from .map import MapAdapter\n    from .rules import Rule\n\n\nclass RoutingException(Exception):\n    \"\"\"Special exceptions that require the application to redirect, notifying\n    about missing urls, etc.\n\n    :internal:\n    \"\"\"\n\n\nclass RequestRedirect(HTTPException, RoutingException):\n    \"\"\"Raise if the map requests a redirect. This is for example the case if\n    `strict_slashes` are activated and an url that requires a trailing slash.\n\n    The attribute `new_url` contains the absolute destination url.\n    \"\"\"\n\n    code = 308\n\n    def __init__(self, new_url: str) -> None:\n        super().__init__(new_url)\n        self.new_url = new_url\n\n    def get_response(\n        self,\n        environ: WSGIEnvironment | Request | None = None,\n        scope: dict[str, t.Any] | None = None,\n    ) -> Response:\n        return redirect(self.new_url, self.code)\n\n\nclass RequestPath(RoutingException):\n    \"\"\"Internal exception.\"\"\"\n\n    __slots__ = (\"path_info\",)\n\n    def __init__(self, path_info: str) -> None:\n        super().__init__()\n        self.path_info = path_info\n\n\nclass RequestAliasRedirect(RoutingException):  # noqa: B903\n    \"\"\"This rule is an alias and wants to redirect to the canonical URL.\"\"\"\n\n    def __init__(self, matched_values: t.Mapping[str, t.Any], endpoint: t.Any) -> None:\n        super().__init__()\n        self.matched_values = matched_values\n        self.endpoint = endpoint\n\n\nclass BuildError(RoutingException, LookupError):\n    \"\"\"Raised if the build system cannot find a URL for an endpoint with the\n    values provided.\n    \"\"\"\n\n    def __init__(\n        self,\n        endpoint: t.Any,\n        values: t.Mapping[str, t.Any],\n        method: str | None,\n        adapter: MapAdapter | None = None,\n    ) -> None:\n        super().__init__(endpoint, values, method)\n        self.endpoint = endpoint\n        self.values = values\n        self.method = method\n        self.adapter = adapter\n\n    @cached_property\n    def suggested(self) -> Rule | None:\n        return self.closest_rule(self.adapter)\n\n    def closest_rule(self, adapter: MapAdapter | None) -> Rule | None:\n        def _score_rule(rule: Rule) -> float:\n            return sum(\n                [\n                    0.98\n                    * difflib.SequenceMatcher(\n                        # endpoints can be any type, compare as strings\n                        None,\n                        str(rule.endpoint),\n                        str(self.endpoint),\n                    ).ratio(),\n                    0.01 * bool(set(self.values or ()).issubset(rule.arguments)),\n                    0.01 * bool(rule.methods and self.method in rule.methods),\n                ]\n            )\n\n        if adapter and adapter.map._rules:\n            return max(adapter.map._rules, key=_score_rule)\n\n        return None\n\n    def __str__(self) -> str:\n        message = [f\"Could not build url for endpoint {self.endpoint!r}\"]\n        if self.method:\n            message.append(f\" ({self.method!r})\")\n        if self.values:\n            message.append(f\" with values {sorted(self.values)!r}\")\n        message.append(\".\")\n        if self.suggested:\n            if self.endpoint == self.suggested.endpoint:\n                if (\n                    self.method\n                    and self.suggested.methods is not None\n                    and self.method not in self.suggested.methods\n                ):\n                    message.append(\n                        \" Did you mean to use methods\"\n                        f\" {sorted(self.suggested.methods)!r}?\"\n                    )\n                missing_values = self.suggested.arguments.union(\n                    set(self.suggested.defaults or ())\n                ) - set(self.values.keys())\n                if missing_values:\n                    message.append(\n                        f\" Did you forget to specify values {sorted(missing_values)!r}?\"\n                    )\n            else:\n                message.append(f\" Did you mean {self.suggested.endpoint!r} instead?\")\n        return \"\".join(message)\n\n\nclass WebsocketMismatch(BadRequest):\n    \"\"\"The only matched rule is either a WebSocket and the request is\n    HTTP, or the rule is HTTP and the request is a WebSocket.\n    \"\"\"\n\n\nclass NoMatch(Exception):\n    __slots__ = (\"have_match_for\", \"websocket_mismatch\")\n\n    def __init__(self, have_match_for: set[str], websocket_mismatch: bool) -> None:\n        self.have_match_for = have_match_for\n        self.websocket_mismatch = websocket_mismatch\n", "src/werkzeug/routing/rules.py": "from __future__ import annotations\n\nimport ast\nimport re\nimport typing as t\nfrom dataclasses import dataclass\nfrom string import Template\nfrom types import CodeType\nfrom urllib.parse import quote\n\nfrom ..datastructures import iter_multi_items\nfrom ..urls import _urlencode\nfrom .converters import ValidationError\n\nif t.TYPE_CHECKING:\n    from .converters import BaseConverter\n    from .map import Map\n\n\nclass Weighting(t.NamedTuple):\n    number_static_weights: int\n    static_weights: list[tuple[int, int]]\n    number_argument_weights: int\n    argument_weights: list[int]\n\n\n@dataclass\nclass RulePart:\n    \"\"\"A part of a rule.\n\n    Rules can be represented by parts as delimited by `/` with\n    instances of this class representing those parts. The *content* is\n    either the raw content if *static* or a regex string to match\n    against. The *weight* can be used to order parts when matching.\n\n    \"\"\"\n\n    content: str\n    final: bool\n    static: bool\n    suffixed: bool\n    weight: Weighting\n\n\n_part_re = re.compile(\n    r\"\"\"\n    (?:\n        (?P<slash>/)                                 # a slash\n      |\n        (?P<static>[^</]+)                           # static rule data\n      |\n        (?:\n          <\n            (?:\n              (?P<converter>[a-zA-Z_][a-zA-Z0-9_]*)   # converter name\n              (?:\\((?P<arguments>.*?)\\))?             # converter arguments\n              :                                       # variable delimiter\n            )?\n            (?P<variable>[a-zA-Z_][a-zA-Z0-9_]*)      # variable name\n           >\n        )\n    )\n    \"\"\",\n    re.VERBOSE,\n)\n\n_simple_rule_re = re.compile(r\"<([^>]+)>\")\n_converter_args_re = re.compile(\n    r\"\"\"\n    \\s*\n    ((?P<name>\\w+)\\s*=\\s*)?\n    (?P<value>\n        True|False|\n        \\d+.\\d+|\n        \\d+.|\n        \\d+|\n        [\\w\\d_.]+|\n        [urUR]?(?P<stringval>\"[^\"]*?\"|'[^']*')\n    )\\s*,\n    \"\"\",\n    re.VERBOSE,\n)\n\n\n_PYTHON_CONSTANTS = {\"None\": None, \"True\": True, \"False\": False}\n\n\ndef _find(value: str, target: str, pos: int) -> int:\n    \"\"\"Find the *target* in *value* after *pos*.\n\n    Returns the *value* length if *target* isn't found.\n    \"\"\"\n    try:\n        return value.index(target, pos)\n    except ValueError:\n        return len(value)\n\n\ndef _pythonize(value: str) -> None | bool | int | float | str:\n    if value in _PYTHON_CONSTANTS:\n        return _PYTHON_CONSTANTS[value]\n    for convert in int, float:\n        try:\n            return convert(value)  # type: ignore\n        except ValueError:\n            pass\n    if value[:1] == value[-1:] and value[0] in \"\\\"'\":\n        value = value[1:-1]\n    return str(value)\n\n\ndef parse_converter_args(argstr: str) -> tuple[tuple[t.Any, ...], dict[str, t.Any]]:\n    argstr += \",\"\n    args = []\n    kwargs = {}\n    position = 0\n\n    for item in _converter_args_re.finditer(argstr):\n        if item.start() != position:\n            raise ValueError(\n                f\"Cannot parse converter argument '{argstr[position:item.start()]}'\"\n            )\n\n        value = item.group(\"stringval\")\n        if value is None:\n            value = item.group(\"value\")\n        value = _pythonize(value)\n        if not item.group(\"name\"):\n            args.append(value)\n        else:\n            name = item.group(\"name\")\n            kwargs[name] = value\n        position = item.end()\n\n    return tuple(args), kwargs\n\n\nclass RuleFactory:\n    \"\"\"As soon as you have more complex URL setups it's a good idea to use rule\n    factories to avoid repetitive tasks.  Some of them are builtin, others can\n    be added by subclassing `RuleFactory` and overriding `get_rules`.\n    \"\"\"\n\n    def get_rules(self, map: Map) -> t.Iterable[Rule]:\n        \"\"\"Subclasses of `RuleFactory` have to override this method and return\n        an iterable of rules.\"\"\"\n        raise NotImplementedError()\n\n\nclass Subdomain(RuleFactory):\n    \"\"\"All URLs provided by this factory have the subdomain set to a\n    specific domain. For example if you want to use the subdomain for\n    the current language this can be a good setup::\n\n        url_map = Map([\n            Rule('/', endpoint='#select_language'),\n            Subdomain('<string(length=2):lang_code>', [\n                Rule('/', endpoint='index'),\n                Rule('/about', endpoint='about'),\n                Rule('/help', endpoint='help')\n            ])\n        ])\n\n    All the rules except for the ``'#select_language'`` endpoint will now\n    listen on a two letter long subdomain that holds the language code\n    for the current request.\n    \"\"\"\n\n    def __init__(self, subdomain: str, rules: t.Iterable[RuleFactory]) -> None:\n        self.subdomain = subdomain\n        self.rules = rules\n\n    def get_rules(self, map: Map) -> t.Iterator[Rule]:\n        for rulefactory in self.rules:\n            for rule in rulefactory.get_rules(map):\n                rule = rule.empty()\n                rule.subdomain = self.subdomain\n                yield rule\n\n\nclass Submount(RuleFactory):\n    \"\"\"Like `Subdomain` but prefixes the URL rule with a given string::\n\n        url_map = Map([\n            Rule('/', endpoint='index'),\n            Submount('/blog', [\n                Rule('/', endpoint='blog/index'),\n                Rule('/entry/<entry_slug>', endpoint='blog/show')\n            ])\n        ])\n\n    Now the rule ``'blog/show'`` matches ``/blog/entry/<entry_slug>``.\n    \"\"\"\n\n    def __init__(self, path: str, rules: t.Iterable[RuleFactory]) -> None:\n        self.path = path.rstrip(\"/\")\n        self.rules = rules\n\n    def get_rules(self, map: Map) -> t.Iterator[Rule]:\n        for rulefactory in self.rules:\n            for rule in rulefactory.get_rules(map):\n                rule = rule.empty()\n                rule.rule = self.path + rule.rule\n                yield rule\n\n\nclass EndpointPrefix(RuleFactory):\n    \"\"\"Prefixes all endpoints (which must be strings for this factory) with\n    another string. This can be useful for sub applications::\n\n        url_map = Map([\n            Rule('/', endpoint='index'),\n            EndpointPrefix('blog/', [Submount('/blog', [\n                Rule('/', endpoint='index'),\n                Rule('/entry/<entry_slug>', endpoint='show')\n            ])])\n        ])\n    \"\"\"\n\n    def __init__(self, prefix: str, rules: t.Iterable[RuleFactory]) -> None:\n        self.prefix = prefix\n        self.rules = rules\n\n    def get_rules(self, map: Map) -> t.Iterator[Rule]:\n        for rulefactory in self.rules:\n            for rule in rulefactory.get_rules(map):\n                rule = rule.empty()\n                rule.endpoint = self.prefix + rule.endpoint\n                yield rule\n\n\nclass RuleTemplate:\n    \"\"\"Returns copies of the rules wrapped and expands string templates in\n    the endpoint, rule, defaults or subdomain sections.\n\n    Here a small example for such a rule template::\n\n        from werkzeug.routing import Map, Rule, RuleTemplate\n\n        resource = RuleTemplate([\n            Rule('/$name/', endpoint='$name.list'),\n            Rule('/$name/<int:id>', endpoint='$name.show')\n        ])\n\n        url_map = Map([resource(name='user'), resource(name='page')])\n\n    When a rule template is called the keyword arguments are used to\n    replace the placeholders in all the string parameters.\n    \"\"\"\n\n    def __init__(self, rules: t.Iterable[Rule]) -> None:\n        self.rules = list(rules)\n\n    def __call__(self, *args: t.Any, **kwargs: t.Any) -> RuleTemplateFactory:\n        return RuleTemplateFactory(self.rules, dict(*args, **kwargs))\n\n\nclass RuleTemplateFactory(RuleFactory):\n    \"\"\"A factory that fills in template variables into rules.  Used by\n    `RuleTemplate` internally.\n\n    :internal:\n    \"\"\"\n\n    def __init__(\n        self, rules: t.Iterable[RuleFactory], context: dict[str, t.Any]\n    ) -> None:\n        self.rules = rules\n        self.context = context\n\n    def get_rules(self, map: Map) -> t.Iterator[Rule]:\n        for rulefactory in self.rules:\n            for rule in rulefactory.get_rules(map):\n                new_defaults = subdomain = None\n                if rule.defaults:\n                    new_defaults = {}\n                    for key, value in rule.defaults.items():\n                        if isinstance(value, str):\n                            value = Template(value).substitute(self.context)\n                        new_defaults[key] = value\n                if rule.subdomain is not None:\n                    subdomain = Template(rule.subdomain).substitute(self.context)\n                new_endpoint = rule.endpoint\n                if isinstance(new_endpoint, str):\n                    new_endpoint = Template(new_endpoint).substitute(self.context)\n                yield Rule(\n                    Template(rule.rule).substitute(self.context),\n                    new_defaults,\n                    subdomain,\n                    rule.methods,\n                    rule.build_only,\n                    new_endpoint,\n                    rule.strict_slashes,\n                )\n\n\ndef _prefix_names(src: str) -> ast.stmt:\n    \"\"\"ast parse and prefix names with `.` to avoid collision with user vars\"\"\"\n    tree = ast.parse(src).body[0]\n    if isinstance(tree, ast.Expr):\n        tree = tree.value  # type: ignore\n    for node in ast.walk(tree):\n        if isinstance(node, ast.Name):\n            node.id = f\".{node.id}\"\n    return tree\n\n\n_CALL_CONVERTER_CODE_FMT = \"self._converters[{elem!r}].to_url()\"\n_IF_KWARGS_URL_ENCODE_CODE = \"\"\"\\\nif kwargs:\n    params = self._encode_query_vars(kwargs)\n    q = \"?\" if params else \"\"\nelse:\n    q = params = \"\"\n\"\"\"\n_IF_KWARGS_URL_ENCODE_AST = _prefix_names(_IF_KWARGS_URL_ENCODE_CODE)\n_URL_ENCODE_AST_NAMES = (_prefix_names(\"q\"), _prefix_names(\"params\"))\n\n\nclass Rule(RuleFactory):\n    \"\"\"A Rule represents one URL pattern.  There are some options for `Rule`\n    that change the way it behaves and are passed to the `Rule` constructor.\n    Note that besides the rule-string all arguments *must* be keyword arguments\n    in order to not break the application on Werkzeug upgrades.\n\n    `string`\n        Rule strings basically are just normal URL paths with placeholders in\n        the format ``<converter(arguments):name>`` where the converter and the\n        arguments are optional.  If no converter is defined the `default`\n        converter is used which means `string` in the normal configuration.\n\n        URL rules that end with a slash are branch URLs, others are leaves.\n        If you have `strict_slashes` enabled (which is the default), all\n        branch URLs that are matched without a trailing slash will trigger a\n        redirect to the same URL with the missing slash appended.\n\n        The converters are defined on the `Map`.\n\n    `endpoint`\n        The endpoint for this rule. This can be anything. A reference to a\n        function, a string, a number etc.  The preferred way is using a string\n        because the endpoint is used for URL generation.\n\n    `defaults`\n        An optional dict with defaults for other rules with the same endpoint.\n        This is a bit tricky but useful if you want to have unique URLs::\n\n            url_map = Map([\n                Rule('/all/', defaults={'page': 1}, endpoint='all_entries'),\n                Rule('/all/page/<int:page>', endpoint='all_entries')\n            ])\n\n        If a user now visits ``http://example.com/all/page/1`` they will be\n        redirected to ``http://example.com/all/``.  If `redirect_defaults` is\n        disabled on the `Map` instance this will only affect the URL\n        generation.\n\n    `subdomain`\n        The subdomain rule string for this rule. If not specified the rule\n        only matches for the `default_subdomain` of the map.  If the map is\n        not bound to a subdomain this feature is disabled.\n\n        Can be useful if you want to have user profiles on different subdomains\n        and all subdomains are forwarded to your application::\n\n            url_map = Map([\n                Rule('/', subdomain='<username>', endpoint='user/homepage'),\n                Rule('/stats', subdomain='<username>', endpoint='user/stats')\n            ])\n\n    `methods`\n        A sequence of http methods this rule applies to.  If not specified, all\n        methods are allowed. For example this can be useful if you want different\n        endpoints for `POST` and `GET`.  If methods are defined and the path\n        matches but the method matched against is not in this list or in the\n        list of another rule for that path the error raised is of the type\n        `MethodNotAllowed` rather than `NotFound`.  If `GET` is present in the\n        list of methods and `HEAD` is not, `HEAD` is added automatically.\n\n    `strict_slashes`\n        Override the `Map` setting for `strict_slashes` only for this rule. If\n        not specified the `Map` setting is used.\n\n    `merge_slashes`\n        Override :attr:`Map.merge_slashes` for this rule.\n\n    `build_only`\n        Set this to True and the rule will never match but will create a URL\n        that can be build. This is useful if you have resources on a subdomain\n        or folder that are not handled by the WSGI application (like static data)\n\n    `redirect_to`\n        If given this must be either a string or callable.  In case of a\n        callable it's called with the url adapter that triggered the match and\n        the values of the URL as keyword arguments and has to return the target\n        for the redirect, otherwise it has to be a string with placeholders in\n        rule syntax::\n\n            def foo_with_slug(adapter, id):\n                # ask the database for the slug for the old id.  this of\n                # course has nothing to do with werkzeug.\n                return f'foo/{Foo.get_slug_for_id(id)}'\n\n            url_map = Map([\n                Rule('/foo/<slug>', endpoint='foo'),\n                Rule('/some/old/url/<slug>', redirect_to='foo/<slug>'),\n                Rule('/other/old/url/<int:id>', redirect_to=foo_with_slug)\n            ])\n\n        When the rule is matched the routing system will raise a\n        `RequestRedirect` exception with the target for the redirect.\n\n        Keep in mind that the URL will be joined against the URL root of the\n        script so don't use a leading slash on the target URL unless you\n        really mean root of that domain.\n\n    `alias`\n        If enabled this rule serves as an alias for another rule with the same\n        endpoint and arguments.\n\n    `host`\n        If provided and the URL map has host matching enabled this can be\n        used to provide a match rule for the whole host.  This also means\n        that the subdomain feature is disabled.\n\n    `websocket`\n        If ``True``, this rule is only matches for WebSocket (``ws://``,\n        ``wss://``) requests. By default, rules will only match for HTTP\n        requests.\n\n    .. versionchanged:: 2.1\n        Percent-encoded newlines (``%0a``), which are decoded by WSGI\n        servers, are considered when routing instead of terminating the\n        match early.\n\n    .. versionadded:: 1.0\n        Added ``websocket``.\n\n    .. versionadded:: 1.0\n        Added ``merge_slashes``.\n\n    .. versionadded:: 0.7\n        Added ``alias`` and ``host``.\n\n    .. versionchanged:: 0.6.1\n       ``HEAD`` is added to ``methods`` if ``GET`` is present.\n    \"\"\"\n\n    def __init__(\n        self,\n        string: str,\n        defaults: t.Mapping[str, t.Any] | None = None,\n        subdomain: str | None = None,\n        methods: t.Iterable[str] | None = None,\n        build_only: bool = False,\n        endpoint: t.Any | None = None,\n        strict_slashes: bool | None = None,\n        merge_slashes: bool | None = None,\n        redirect_to: str | t.Callable[..., str] | None = None,\n        alias: bool = False,\n        host: str | None = None,\n        websocket: bool = False,\n    ) -> None:\n        if not string.startswith(\"/\"):\n            raise ValueError(f\"URL rule '{string}' must start with a slash.\")\n\n        self.rule = string\n        self.is_leaf = not string.endswith(\"/\")\n        self.is_branch = string.endswith(\"/\")\n\n        self.map: Map = None  # type: ignore\n        self.strict_slashes = strict_slashes\n        self.merge_slashes = merge_slashes\n        self.subdomain = subdomain\n        self.host = host\n        self.defaults = defaults\n        self.build_only = build_only\n        self.alias = alias\n        self.websocket = websocket\n\n        if methods is not None:\n            if isinstance(methods, str):\n                raise TypeError(\"'methods' should be a list of strings.\")\n\n            methods = {x.upper() for x in methods}\n\n            if \"HEAD\" not in methods and \"GET\" in methods:\n                methods.add(\"HEAD\")\n\n            if websocket and methods - {\"GET\", \"HEAD\", \"OPTIONS\"}:\n                raise ValueError(\n                    \"WebSocket rules can only use 'GET', 'HEAD', and 'OPTIONS' methods.\"\n                )\n\n        self.methods = methods\n        self.endpoint: t.Any = endpoint\n        self.redirect_to = redirect_to\n\n        if defaults:\n            self.arguments = set(map(str, defaults))\n        else:\n            self.arguments = set()\n\n        self._converters: dict[str, BaseConverter] = {}\n        self._trace: list[tuple[bool, str]] = []\n        self._parts: list[RulePart] = []\n\n    def empty(self) -> Rule:\n        \"\"\"\n        Return an unbound copy of this rule.\n\n        This can be useful if want to reuse an already bound URL for another\n        map.  See ``get_empty_kwargs`` to override what keyword arguments are\n        provided to the new copy.\n        \"\"\"\n        return type(self)(self.rule, **self.get_empty_kwargs())\n\n    def get_empty_kwargs(self) -> t.Mapping[str, t.Any]:\n        \"\"\"\n        Provides kwargs for instantiating empty copy with empty()\n\n        Use this method to provide custom keyword arguments to the subclass of\n        ``Rule`` when calling ``some_rule.empty()``.  Helpful when the subclass\n        has custom keyword arguments that are needed at instantiation.\n\n        Must return a ``dict`` that will be provided as kwargs to the new\n        instance of ``Rule``, following the initial ``self.rule`` value which\n        is always provided as the first, required positional argument.\n        \"\"\"\n        defaults = None\n        if self.defaults:\n            defaults = dict(self.defaults)\n        return dict(\n            defaults=defaults,\n            subdomain=self.subdomain,\n            methods=self.methods,\n            build_only=self.build_only,\n            endpoint=self.endpoint,\n            strict_slashes=self.strict_slashes,\n            redirect_to=self.redirect_to,\n            alias=self.alias,\n            host=self.host,\n        )\n\n    def get_rules(self, map: Map) -> t.Iterator[Rule]:\n        yield self\n\n    def refresh(self) -> None:\n        \"\"\"Rebinds and refreshes the URL.  Call this if you modified the\n        rule in place.\n\n        :internal:\n        \"\"\"\n        self.bind(self.map, rebind=True)\n\n    def bind(self, map: Map, rebind: bool = False) -> None:\n        \"\"\"Bind the url to a map and create a regular expression based on\n        the information from the rule itself and the defaults from the map.\n\n        :internal:\n        \"\"\"\n        if self.map is not None and not rebind:\n            raise RuntimeError(f\"url rule {self!r} already bound to map {self.map!r}\")\n        self.map = map\n        if self.strict_slashes is None:\n            self.strict_slashes = map.strict_slashes\n        if self.merge_slashes is None:\n            self.merge_slashes = map.merge_slashes\n        if self.subdomain is None:\n            self.subdomain = map.default_subdomain\n        self.compile()\n\n    def get_converter(\n        self,\n        variable_name: str,\n        converter_name: str,\n        args: tuple[t.Any, ...],\n        kwargs: t.Mapping[str, t.Any],\n    ) -> BaseConverter:\n        \"\"\"Looks up the converter for the given parameter.\n\n        .. versionadded:: 0.9\n        \"\"\"\n        if converter_name not in self.map.converters:\n            raise LookupError(f\"the converter {converter_name!r} does not exist\")\n        return self.map.converters[converter_name](self.map, *args, **kwargs)\n\n    def _encode_query_vars(self, query_vars: t.Mapping[str, t.Any]) -> str:\n        items: t.Iterable[tuple[str, str]] = iter_multi_items(query_vars)\n\n        if self.map.sort_parameters:\n            items = sorted(items, key=self.map.sort_key)\n\n        return _urlencode(items)\n\n    def _parse_rule(self, rule: str) -> t.Iterable[RulePart]:\n        content = \"\"\n        static = True\n        argument_weights = []\n        static_weights: list[tuple[int, int]] = []\n        final = False\n        convertor_number = 0\n\n        pos = 0\n        while pos < len(rule):\n            match = _part_re.match(rule, pos)\n            if match is None:\n                raise ValueError(f\"malformed url rule: {rule!r}\")\n\n            data = match.groupdict()\n            if data[\"static\"] is not None:\n                static_weights.append((len(static_weights), -len(data[\"static\"])))\n                self._trace.append((False, data[\"static\"]))\n                content += data[\"static\"] if static else re.escape(data[\"static\"])\n\n            if data[\"variable\"] is not None:\n                if static:\n                    # Switching content to represent regex, hence the need to escape\n                    content = re.escape(content)\n                static = False\n                c_args, c_kwargs = parse_converter_args(data[\"arguments\"] or \"\")\n                convobj = self.get_converter(\n                    data[\"variable\"], data[\"converter\"] or \"default\", c_args, c_kwargs\n                )\n                self._converters[data[\"variable\"]] = convobj\n                self.arguments.add(data[\"variable\"])\n                if not convobj.part_isolating:\n                    final = True\n                content += f\"(?P<__werkzeug_{convertor_number}>{convobj.regex})\"\n                convertor_number += 1\n                argument_weights.append(convobj.weight)\n                self._trace.append((True, data[\"variable\"]))\n\n            if data[\"slash\"] is not None:\n                self._trace.append((False, \"/\"))\n                if final:\n                    content += \"/\"\n                else:\n                    if not static:\n                        content += r\"\\Z\"\n                    weight = Weighting(\n                        -len(static_weights),\n                        static_weights,\n                        -len(argument_weights),\n                        argument_weights,\n                    )\n                    yield RulePart(\n                        content=content,\n                        final=final,\n                        static=static,\n                        suffixed=False,\n                        weight=weight,\n                    )\n                    content = \"\"\n                    static = True\n                    argument_weights = []\n                    static_weights = []\n                    final = False\n                    convertor_number = 0\n\n            pos = match.end()\n\n        suffixed = False\n        if final and content[-1] == \"/\":\n            # If a converter is part_isolating=False (matches slashes) and ends with a\n            # slash, augment the regex to support slash redirects.\n            suffixed = True\n            content = content[:-1] + \"(?<!/)(/?)\"\n        if not static:\n            content += r\"\\Z\"\n        weight = Weighting(\n            -len(static_weights),\n            static_weights,\n            -len(argument_weights),\n            argument_weights,\n        )\n        yield RulePart(\n            content=content,\n            final=final,\n            static=static,\n            suffixed=suffixed,\n            weight=weight,\n        )\n        if suffixed:\n            yield RulePart(\n                content=\"\", final=False, static=True, suffixed=False, weight=weight\n            )\n\n    def compile(self) -> None:\n        \"\"\"Compiles the regular expression and stores it.\"\"\"\n        assert self.map is not None, \"rule not bound\"\n\n        if self.map.host_matching:\n            domain_rule = self.host or \"\"\n        else:\n            domain_rule = self.subdomain or \"\"\n        self._parts = []\n        self._trace = []\n        self._converters = {}\n        if domain_rule == \"\":\n            self._parts = [\n                RulePart(\n                    content=\"\",\n                    final=False,\n                    static=True,\n                    suffixed=False,\n                    weight=Weighting(0, [], 0, []),\n                )\n            ]\n        else:\n            self._parts.extend(self._parse_rule(domain_rule))\n        self._trace.append((False, \"|\"))\n        rule = self.rule\n        if self.merge_slashes:\n            rule = re.sub(\"/{2,}?\", \"/\", self.rule)\n        self._parts.extend(self._parse_rule(rule))\n\n        self._build: t.Callable[..., tuple[str, str]]\n        self._build = self._compile_builder(False).__get__(self, None)\n        self._build_unknown: t.Callable[..., tuple[str, str]]\n        self._build_unknown = self._compile_builder(True).__get__(self, None)\n\n    @staticmethod\n    def _get_func_code(code: CodeType, name: str) -> t.Callable[..., tuple[str, str]]:\n        globs: dict[str, t.Any] = {}\n        locs: dict[str, t.Any] = {}\n        exec(code, globs, locs)\n        return locs[name]  # type: ignore\n\n    def _compile_builder(\n        self, append_unknown: bool = True\n    ) -> t.Callable[..., tuple[str, str]]:\n        defaults = self.defaults or {}\n        dom_ops: list[tuple[bool, str]] = []\n        url_ops: list[tuple[bool, str]] = []\n\n        opl = dom_ops\n        for is_dynamic, data in self._trace:\n            if data == \"|\" and opl is dom_ops:\n                opl = url_ops\n                continue\n            # this seems like a silly case to ever come up but:\n            # if a default is given for a value that appears in the rule,\n            # resolve it to a constant ahead of time\n            if is_dynamic and data in defaults:\n                data = self._converters[data].to_url(defaults[data])\n                opl.append((False, data))\n            elif not is_dynamic:\n                # safe = https://url.spec.whatwg.org/#url-path-segment-string\n                opl.append((False, quote(data, safe=\"!$&'()*+,/:;=@\")))\n            else:\n                opl.append((True, data))\n\n        def _convert(elem: str) -> ast.stmt:\n            ret = _prefix_names(_CALL_CONVERTER_CODE_FMT.format(elem=elem))\n            ret.args = [ast.Name(str(elem), ast.Load())]  # type: ignore  # str for py2\n            return ret\n\n        def _parts(ops: list[tuple[bool, str]]) -> list[ast.AST]:\n            parts = [\n                _convert(elem) if is_dynamic else ast.Constant(elem)\n                for is_dynamic, elem in ops\n            ]\n            parts = parts or [ast.Constant(\"\")]\n            # constant fold\n            ret = [parts[0]]\n            for p in parts[1:]:\n                if isinstance(p, ast.Constant) and isinstance(ret[-1], ast.Constant):\n                    ret[-1] = ast.Constant(ret[-1].value + p.value)\n                else:\n                    ret.append(p)\n            return ret\n\n        dom_parts = _parts(dom_ops)\n        url_parts = _parts(url_ops)\n        if not append_unknown:\n            body = []\n        else:\n            body = [_IF_KWARGS_URL_ENCODE_AST]\n            url_parts.extend(_URL_ENCODE_AST_NAMES)\n\n        def _join(parts: list[ast.AST]) -> ast.AST:\n            if len(parts) == 1:  # shortcut\n                return parts[0]\n            return ast.JoinedStr(parts)\n\n        body.append(\n            ast.Return(ast.Tuple([_join(dom_parts), _join(url_parts)], ast.Load()))\n        )\n\n        pargs = [\n            elem\n            for is_dynamic, elem in dom_ops + url_ops\n            if is_dynamic and elem not in defaults\n        ]\n        kargs = [str(k) for k in defaults]\n\n        func_ast: ast.FunctionDef = _prefix_names(\"def _(): pass\")  # type: ignore\n        func_ast.name = f\"<builder:{self.rule!r}>\"\n        func_ast.args.args.append(ast.arg(\".self\", None))\n        for arg in pargs + kargs:\n            func_ast.args.args.append(ast.arg(arg, None))\n        func_ast.args.kwarg = ast.arg(\".kwargs\", None)\n        for _ in kargs:\n            func_ast.args.defaults.append(ast.Constant(\"\"))\n        func_ast.body = body\n\n        # Use `ast.parse` instead of `ast.Module` for better portability, since the\n        # signature of `ast.Module` can change.\n        module = ast.parse(\"\")\n        module.body = [func_ast]\n\n        # mark everything as on line 1, offset 0\n        # less error-prone than `ast.fix_missing_locations`\n        # bad line numbers cause an assert to fail in debug builds\n        for node in ast.walk(module):\n            if \"lineno\" in node._attributes:\n                node.lineno = 1\n            if \"end_lineno\" in node._attributes:\n                node.end_lineno = node.lineno\n            if \"col_offset\" in node._attributes:\n                node.col_offset = 0\n            if \"end_col_offset\" in node._attributes:\n                node.end_col_offset = node.col_offset\n\n        code = compile(module, \"<werkzeug routing>\", \"exec\")\n        return self._get_func_code(code, func_ast.name)\n\n    def build(\n        self, values: t.Mapping[str, t.Any], append_unknown: bool = True\n    ) -> tuple[str, str] | None:\n        \"\"\"Assembles the relative url for that rule and the subdomain.\n        If building doesn't work for some reasons `None` is returned.\n\n        :internal:\n        \"\"\"\n        try:\n            if append_unknown:\n                return self._build_unknown(**values)\n            else:\n                return self._build(**values)\n        except ValidationError:\n            return None\n\n    def provides_defaults_for(self, rule: Rule) -> bool:\n        \"\"\"Check if this rule has defaults for a given rule.\n\n        :internal:\n        \"\"\"\n        return bool(\n            not self.build_only\n            and self.defaults\n            and self.endpoint == rule.endpoint\n            and self != rule\n            and self.arguments == rule.arguments\n        )\n\n    def suitable_for(\n        self, values: t.Mapping[str, t.Any], method: str | None = None\n    ) -> bool:\n        \"\"\"Check if the dict of values has enough data for url generation.\n\n        :internal:\n        \"\"\"\n        # if a method was given explicitly and that method is not supported\n        # by this rule, this rule is not suitable.\n        if (\n            method is not None\n            and self.methods is not None\n            and method not in self.methods\n        ):\n            return False\n\n        defaults = self.defaults or ()\n\n        # all arguments required must be either in the defaults dict or\n        # the value dictionary otherwise it's not suitable\n        for key in self.arguments:\n            if key not in defaults and key not in values:\n                return False\n\n        # in case defaults are given we ensure that either the value was\n        # skipped or the value is the same as the default value.\n        if defaults:\n            for key, value in defaults.items():\n                if key in values and value != values[key]:\n                    return False\n\n        return True\n\n    def build_compare_key(self) -> tuple[int, int, int]:\n        \"\"\"The build compare key for sorting.\n\n        :internal:\n        \"\"\"\n        return (1 if self.alias else 0, -len(self.arguments), -len(self.defaults or ()))\n\n    def __eq__(self, other: object) -> bool:\n        return isinstance(other, type(self)) and self._trace == other._trace\n\n    __hash__ = None  # type: ignore\n\n    def __str__(self) -> str:\n        return self.rule\n\n    def __repr__(self) -> str:\n        if self.map is None:\n            return f\"<{type(self).__name__} (unbound)>\"\n        parts = []\n        for is_dynamic, data in self._trace:\n            if is_dynamic:\n                parts.append(f\"<{data}>\")\n            else:\n                parts.append(data)\n        parts_str = \"\".join(parts).lstrip(\"|\")\n        methods = f\" ({', '.join(self.methods)})\" if self.methods is not None else \"\"\n        return f\"<{type(self).__name__} {parts_str!r}{methods} -> {self.endpoint}>\"\n", "src/werkzeug/routing/converters.py": "from __future__ import annotations\n\nimport re\nimport typing as t\nimport uuid\nfrom urllib.parse import quote\n\nif t.TYPE_CHECKING:\n    from .map import Map\n\n\nclass ValidationError(ValueError):\n    \"\"\"Validation error.  If a rule converter raises this exception the rule\n    does not match the current URL and the next URL is tried.\n    \"\"\"\n\n\nclass BaseConverter:\n    \"\"\"Base class for all converters.\n\n    .. versionchanged:: 2.3\n        ``part_isolating`` defaults to ``False`` if ``regex`` contains a ``/``.\n    \"\"\"\n\n    regex = \"[^/]+\"\n    weight = 100\n    part_isolating = True\n\n    def __init_subclass__(cls, **kwargs: t.Any) -> None:\n        super().__init_subclass__(**kwargs)\n\n        # If the converter isn't inheriting its regex, disable part_isolating by default\n        # if the regex contains a / character.\n        if \"regex\" in cls.__dict__ and \"part_isolating\" not in cls.__dict__:\n            cls.part_isolating = \"/\" not in cls.regex\n\n    def __init__(self, map: Map, *args: t.Any, **kwargs: t.Any) -> None:\n        self.map = map\n\n    def to_python(self, value: str) -> t.Any:\n        return value\n\n    def to_url(self, value: t.Any) -> str:\n        # safe = https://url.spec.whatwg.org/#url-path-segment-string\n        return quote(str(value), safe=\"!$&'()*+,/:;=@\")\n\n\nclass UnicodeConverter(BaseConverter):\n    \"\"\"This converter is the default converter and accepts any string but\n    only one path segment.  Thus the string can not include a slash.\n\n    This is the default validator.\n\n    Example::\n\n        Rule('/pages/<page>'),\n        Rule('/<string(length=2):lang_code>')\n\n    :param map: the :class:`Map`.\n    :param minlength: the minimum length of the string.  Must be greater\n                      or equal 1.\n    :param maxlength: the maximum length of the string.\n    :param length: the exact length of the string.\n    \"\"\"\n\n    def __init__(\n        self,\n        map: Map,\n        minlength: int = 1,\n        maxlength: int | None = None,\n        length: int | None = None,\n    ) -> None:\n        super().__init__(map)\n        if length is not None:\n            length_regex = f\"{{{int(length)}}}\"\n        else:\n            if maxlength is None:\n                maxlength_value = \"\"\n            else:\n                maxlength_value = str(int(maxlength))\n            length_regex = f\"{{{int(minlength)},{maxlength_value}}}\"\n        self.regex = f\"[^/]{length_regex}\"\n\n\nclass AnyConverter(BaseConverter):\n    \"\"\"Matches one of the items provided.  Items can either be Python\n    identifiers or strings::\n\n        Rule('/<any(about, help, imprint, class, \"foo,bar\"):page_name>')\n\n    :param map: the :class:`Map`.\n    :param items: this function accepts the possible items as positional\n                  arguments.\n\n    .. versionchanged:: 2.2\n        Value is validated when building a URL.\n    \"\"\"\n\n    def __init__(self, map: Map, *items: str) -> None:\n        super().__init__(map)\n        self.items = set(items)\n        self.regex = f\"(?:{'|'.join([re.escape(x) for x in items])})\"\n\n    def to_url(self, value: t.Any) -> str:\n        if value in self.items:\n            return str(value)\n\n        valid_values = \", \".join(f\"'{item}'\" for item in sorted(self.items))\n        raise ValueError(f\"'{value}' is not one of {valid_values}\")\n\n\nclass PathConverter(BaseConverter):\n    \"\"\"Like the default :class:`UnicodeConverter`, but it also matches\n    slashes.  This is useful for wikis and similar applications::\n\n        Rule('/<path:wikipage>')\n        Rule('/<path:wikipage>/edit')\n\n    :param map: the :class:`Map`.\n    \"\"\"\n\n    part_isolating = False\n    regex = \"[^/].*?\"\n    weight = 200\n\n\nclass NumberConverter(BaseConverter):\n    \"\"\"Baseclass for `IntegerConverter` and `FloatConverter`.\n\n    :internal:\n    \"\"\"\n\n    weight = 50\n    num_convert: t.Callable[[t.Any], t.Any] = int\n\n    def __init__(\n        self,\n        map: Map,\n        fixed_digits: int = 0,\n        min: int | None = None,\n        max: int | None = None,\n        signed: bool = False,\n    ) -> None:\n        if signed:\n            self.regex = self.signed_regex\n        super().__init__(map)\n        self.fixed_digits = fixed_digits\n        self.min = min\n        self.max = max\n        self.signed = signed\n\n    def to_python(self, value: str) -> t.Any:\n        if self.fixed_digits and len(value) != self.fixed_digits:\n            raise ValidationError()\n        value_num = self.num_convert(value)\n        if (self.min is not None and value_num < self.min) or (\n            self.max is not None and value_num > self.max\n        ):\n            raise ValidationError()\n        return value_num\n\n    def to_url(self, value: t.Any) -> str:\n        value_str = str(self.num_convert(value))\n        if self.fixed_digits:\n            value_str = value_str.zfill(self.fixed_digits)\n        return value_str\n\n    @property\n    def signed_regex(self) -> str:\n        return f\"-?{self.regex}\"\n\n\nclass IntegerConverter(NumberConverter):\n    \"\"\"This converter only accepts integer values::\n\n        Rule(\"/page/<int:page>\")\n\n    By default it only accepts unsigned, positive values. The ``signed``\n    parameter will enable signed, negative values. ::\n\n        Rule(\"/page/<int(signed=True):page>\")\n\n    :param map: The :class:`Map`.\n    :param fixed_digits: The number of fixed digits in the URL. If you\n        set this to ``4`` for example, the rule will only match if the\n        URL looks like ``/0001/``. The default is variable length.\n    :param min: The minimal value.\n    :param max: The maximal value.\n    :param signed: Allow signed (negative) values.\n\n    .. versionadded:: 0.15\n        The ``signed`` parameter.\n    \"\"\"\n\n    regex = r\"\\d+\"\n\n\nclass FloatConverter(NumberConverter):\n    \"\"\"This converter only accepts floating point values::\n\n        Rule(\"/probability/<float:probability>\")\n\n    By default it only accepts unsigned, positive values. The ``signed``\n    parameter will enable signed, negative values. ::\n\n        Rule(\"/offset/<float(signed=True):offset>\")\n\n    :param map: The :class:`Map`.\n    :param min: The minimal value.\n    :param max: The maximal value.\n    :param signed: Allow signed (negative) values.\n\n    .. versionadded:: 0.15\n        The ``signed`` parameter.\n    \"\"\"\n\n    regex = r\"\\d+\\.\\d+\"\n    num_convert = float\n\n    def __init__(\n        self,\n        map: Map,\n        min: float | None = None,\n        max: float | None = None,\n        signed: bool = False,\n    ) -> None:\n        super().__init__(map, min=min, max=max, signed=signed)  # type: ignore\n\n\nclass UUIDConverter(BaseConverter):\n    \"\"\"This converter only accepts UUID strings::\n\n        Rule('/object/<uuid:identifier>')\n\n    .. versionadded:: 0.10\n\n    :param map: the :class:`Map`.\n    \"\"\"\n\n    regex = (\n        r\"[A-Fa-f0-9]{8}-[A-Fa-f0-9]{4}-\"\n        r\"[A-Fa-f0-9]{4}-[A-Fa-f0-9]{4}-[A-Fa-f0-9]{12}\"\n    )\n\n    def to_python(self, value: str) -> uuid.UUID:\n        return uuid.UUID(value)\n\n    def to_url(self, value: uuid.UUID) -> str:\n        return str(value)\n\n\n#: the default converter mapping for the map.\nDEFAULT_CONVERTERS: t.Mapping[str, type[BaseConverter]] = {\n    \"default\": UnicodeConverter,\n    \"string\": UnicodeConverter,\n    \"any\": AnyConverter,\n    \"path\": PathConverter,\n    \"int\": IntegerConverter,\n    \"float\": FloatConverter,\n    \"uuid\": UUIDConverter,\n}\n", "src/werkzeug/routing/matcher.py": "from __future__ import annotations\n\nimport re\nimport typing as t\nfrom dataclasses import dataclass\nfrom dataclasses import field\n\nfrom .converters import ValidationError\nfrom .exceptions import NoMatch\nfrom .exceptions import RequestAliasRedirect\nfrom .exceptions import RequestPath\nfrom .rules import Rule\nfrom .rules import RulePart\n\n\nclass SlashRequired(Exception):\n    pass\n\n\n@dataclass\nclass State:\n    \"\"\"A representation of a rule state.\n\n    This includes the *rules* that correspond to the state and the\n    possible *static* and *dynamic* transitions to the next state.\n    \"\"\"\n\n    dynamic: list[tuple[RulePart, State]] = field(default_factory=list)\n    rules: list[Rule] = field(default_factory=list)\n    static: dict[str, State] = field(default_factory=dict)\n\n\nclass StateMachineMatcher:\n    def __init__(self, merge_slashes: bool) -> None:\n        self._root = State()\n        self.merge_slashes = merge_slashes\n\n    def add(self, rule: Rule) -> None:\n        state = self._root\n        for part in rule._parts:\n            if part.static:\n                state.static.setdefault(part.content, State())\n                state = state.static[part.content]\n            else:\n                for test_part, new_state in state.dynamic:\n                    if test_part == part:\n                        state = new_state\n                        break\n                else:\n                    new_state = State()\n                    state.dynamic.append((part, new_state))\n                    state = new_state\n        state.rules.append(rule)\n\n    def update(self) -> None:\n        # For every state the dynamic transitions should be sorted by\n        # the weight of the transition\n        state = self._root\n\n        def _update_state(state: State) -> None:\n            state.dynamic.sort(key=lambda entry: entry[0].weight)\n            for new_state in state.static.values():\n                _update_state(new_state)\n            for _, new_state in state.dynamic:\n                _update_state(new_state)\n\n        _update_state(state)\n\n    def match(\n        self, domain: str, path: str, method: str, websocket: bool\n    ) -> tuple[Rule, t.MutableMapping[str, t.Any]]:\n        # To match to a rule we need to start at the root state and\n        # try to follow the transitions until we find a match, or find\n        # there is no transition to follow.\n\n        have_match_for = set()\n        websocket_mismatch = False\n\n        def _match(\n            state: State, parts: list[str], values: list[str]\n        ) -> tuple[Rule, list[str]] | None:\n            # This function is meant to be called recursively, and will attempt\n            # to match the head part to the state's transitions.\n            nonlocal have_match_for, websocket_mismatch\n\n            # The base case is when all parts have been matched via\n            # transitions. Hence if there is a rule with methods &\n            # websocket that work return it and the dynamic values\n            # extracted.\n            if parts == []:\n                for rule in state.rules:\n                    if rule.methods is not None and method not in rule.methods:\n                        have_match_for.update(rule.methods)\n                    elif rule.websocket != websocket:\n                        websocket_mismatch = True\n                    else:\n                        return rule, values\n\n                # Test if there is a match with this path with a\n                # trailing slash, if so raise an exception to report\n                # that matching is possible with an additional slash\n                if \"\" in state.static:\n                    for rule in state.static[\"\"].rules:\n                        if websocket == rule.websocket and (\n                            rule.methods is None or method in rule.methods\n                        ):\n                            if rule.strict_slashes:\n                                raise SlashRequired()\n                            else:\n                                return rule, values\n                return None\n\n            part = parts[0]\n            # To match this part try the static transitions first\n            if part in state.static:\n                rv = _match(state.static[part], parts[1:], values)\n                if rv is not None:\n                    return rv\n            # No match via the static transitions, so try the dynamic\n            # ones.\n            for test_part, new_state in state.dynamic:\n                target = part\n                remaining = parts[1:]\n                # A final part indicates a transition that always\n                # consumes the remaining parts i.e. transitions to a\n                # final state.\n                if test_part.final:\n                    target = \"/\".join(parts)\n                    remaining = []\n                match = re.compile(test_part.content).match(target)\n                if match is not None:\n                    if test_part.suffixed:\n                        # If a part_isolating=False part has a slash suffix, remove the\n                        # suffix from the match and check for the slash redirect next.\n                        suffix = match.groups()[-1]\n                        if suffix == \"/\":\n                            remaining = [\"\"]\n\n                    converter_groups = sorted(\n                        match.groupdict().items(), key=lambda entry: entry[0]\n                    )\n                    groups = [\n                        value\n                        for key, value in converter_groups\n                        if key[:11] == \"__werkzeug_\"\n                    ]\n                    rv = _match(new_state, remaining, values + groups)\n                    if rv is not None:\n                        return rv\n\n            # If there is no match and the only part left is a\n            # trailing slash (\"\") consider rules that aren't\n            # strict-slashes as these should match if there is a final\n            # slash part.\n            if parts == [\"\"]:\n                for rule in state.rules:\n                    if rule.strict_slashes:\n                        continue\n                    if rule.methods is not None and method not in rule.methods:\n                        have_match_for.update(rule.methods)\n                    elif rule.websocket != websocket:\n                        websocket_mismatch = True\n                    else:\n                        return rule, values\n\n            return None\n\n        try:\n            rv = _match(self._root, [domain, *path.split(\"/\")], [])\n        except SlashRequired:\n            raise RequestPath(f\"{path}/\") from None\n\n        if self.merge_slashes and rv is None:\n            # Try to match again, but with slashes merged\n            path = re.sub(\"/{2,}?\", \"/\", path)\n            try:\n                rv = _match(self._root, [domain, *path.split(\"/\")], [])\n            except SlashRequired:\n                raise RequestPath(f\"{path}/\") from None\n            if rv is None or rv[0].merge_slashes is False:\n                raise NoMatch(have_match_for, websocket_mismatch)\n            else:\n                raise RequestPath(f\"{path}\")\n        elif rv is not None:\n            rule, values = rv\n\n            result = {}\n            for name, value in zip(rule._converters.keys(), values):\n                try:\n                    value = rule._converters[name].to_python(value)\n                except ValidationError:\n                    raise NoMatch(have_match_for, websocket_mismatch) from None\n                result[str(name)] = value\n            if rule.defaults:\n                result.update(rule.defaults)\n\n            if rule.alias and rule.map.redirect_defaults:\n                raise RequestAliasRedirect(result, rule.endpoint)\n\n            return rule, result\n\n        raise NoMatch(have_match_for, websocket_mismatch)\n", "src/werkzeug/routing/__init__.py": "\"\"\"When it comes to combining multiple controller or view functions\n(however you want to call them) you need a dispatcher. A simple way\nwould be applying regular expression tests on the ``PATH_INFO`` and\ncalling registered callback functions that return the value then.\n\nThis module implements a much more powerful system than simple regular\nexpression matching because it can also convert values in the URLs and\nbuild URLs.\n\nHere a simple example that creates a URL map for an application with\ntwo subdomains (www and kb) and some URL rules:\n\n.. code-block:: python\n\n    m = Map([\n        # Static URLs\n        Rule('/', endpoint='static/index'),\n        Rule('/about', endpoint='static/about'),\n        Rule('/help', endpoint='static/help'),\n        # Knowledge Base\n        Subdomain('kb', [\n            Rule('/', endpoint='kb/index'),\n            Rule('/browse/', endpoint='kb/browse'),\n            Rule('/browse/<int:id>/', endpoint='kb/browse'),\n            Rule('/browse/<int:id>/<int:page>', endpoint='kb/browse')\n        ])\n    ], default_subdomain='www')\n\nIf the application doesn't use subdomains it's perfectly fine to not set\nthe default subdomain and not use the `Subdomain` rule factory. The\nendpoint in the rules can be anything, for example import paths or\nunique identifiers. The WSGI application can use those endpoints to get the\nhandler for that URL.  It doesn't have to be a string at all but it's\nrecommended.\n\nNow it's possible to create a URL adapter for one of the subdomains and\nbuild URLs:\n\n.. code-block:: python\n\n    c = m.bind('example.com')\n\n    c.build(\"kb/browse\", dict(id=42))\n    'http://kb.example.com/browse/42/'\n\n    c.build(\"kb/browse\", dict())\n    'http://kb.example.com/browse/'\n\n    c.build(\"kb/browse\", dict(id=42, page=3))\n    'http://kb.example.com/browse/42/3'\n\n    c.build(\"static/about\")\n    '/about'\n\n    c.build(\"static/index\", force_external=True)\n    'http://www.example.com/'\n\n    c = m.bind('example.com', subdomain='kb')\n\n    c.build(\"static/about\")\n    'http://www.example.com/about'\n\nThe first argument to bind is the server name *without* the subdomain.\nPer default it will assume that the script is mounted on the root, but\noften that's not the case so you can provide the real mount point as\nsecond argument:\n\n.. code-block:: python\n\n    c = m.bind('example.com', '/applications/example')\n\nThe third argument can be the subdomain, if not given the default\nsubdomain is used.  For more details about binding have a look at the\ndocumentation of the `MapAdapter`.\n\nAnd here is how you can match URLs:\n\n.. code-block:: python\n\n    c = m.bind('example.com')\n\n    c.match(\"/\")\n    ('static/index', {})\n\n    c.match(\"/about\")\n    ('static/about', {})\n\n    c = m.bind('example.com', '/', 'kb')\n\n    c.match(\"/\")\n    ('kb/index', {})\n\n    c.match(\"/browse/42/23\")\n    ('kb/browse', {'id': 42, 'page': 23})\n\nIf matching fails you get a ``NotFound`` exception, if the rule thinks\nit's a good idea to redirect (for example because the URL was defined\nto have a slash at the end but the request was missing that slash) it\nwill raise a ``RequestRedirect`` exception. Both are subclasses of\n``HTTPException`` so you can use those errors as responses in the\napplication.\n\nIf matching succeeded but the URL rule was incompatible to the given\nmethod (for example there were only rules for ``GET`` and ``HEAD`` but\nrouting tried to match a ``POST`` request) a ``MethodNotAllowed``\nexception is raised.\n\"\"\"\n\nfrom .converters import AnyConverter as AnyConverter\nfrom .converters import BaseConverter as BaseConverter\nfrom .converters import FloatConverter as FloatConverter\nfrom .converters import IntegerConverter as IntegerConverter\nfrom .converters import PathConverter as PathConverter\nfrom .converters import UnicodeConverter as UnicodeConverter\nfrom .converters import UUIDConverter as UUIDConverter\nfrom .converters import ValidationError as ValidationError\nfrom .exceptions import BuildError as BuildError\nfrom .exceptions import NoMatch as NoMatch\nfrom .exceptions import RequestAliasRedirect as RequestAliasRedirect\nfrom .exceptions import RequestPath as RequestPath\nfrom .exceptions import RequestRedirect as RequestRedirect\nfrom .exceptions import RoutingException as RoutingException\nfrom .exceptions import WebsocketMismatch as WebsocketMismatch\nfrom .map import Map as Map\nfrom .map import MapAdapter as MapAdapter\nfrom .matcher import StateMachineMatcher as StateMachineMatcher\nfrom .rules import EndpointPrefix as EndpointPrefix\nfrom .rules import parse_converter_args as parse_converter_args\nfrom .rules import Rule as Rule\nfrom .rules import RuleFactory as RuleFactory\nfrom .rules import RuleTemplate as RuleTemplate\nfrom .rules import RuleTemplateFactory as RuleTemplateFactory\nfrom .rules import Subdomain as Subdomain\nfrom .rules import Submount as Submount\n", "examples/manage-coolmagic.py": "import click\nfrom werkzeug.serving import run_simple\n\nfrom coolmagic import make_app\n\n\n@click.group()\ndef cli():\n    pass\n\n\n@cli.command()\n@click.option(\"-h\", \"--hostname\", type=str, default=\"localhost\", help=\"localhost\")\n@click.option(\"-p\", \"--port\", type=int, default=5000, help=\"5000\")\n@click.option(\"--no-reloader\", is_flag=True, default=False)\n@click.option(\"--debugger\", is_flag=True)\n@click.option(\"--no-evalex\", is_flag=True, default=False)\n@click.option(\"--threaded\", is_flag=True)\n@click.option(\"--processes\", type=int, default=1, help=\"1\")\ndef runserver(hostname, port, no_reloader, debugger, no_evalex, threaded, processes):\n    \"\"\"Start a new development server.\"\"\"\n    app = make_app()\n    reloader = not no_reloader\n    evalex = not no_evalex\n    run_simple(\n        hostname,\n        port,\n        app,\n        use_reloader=reloader,\n        use_debugger=debugger,\n        use_evalex=evalex,\n        threaded=threaded,\n        processes=processes,\n    )\n\n\n@cli.command()\n@click.option(\"--no-ipython\", is_flag=True, default=False)\ndef shell(no_ipython):\n    \"\"\"Start a new interactive python session.\"\"\"\n    banner = \"Interactive Werkzeug Shell\"\n    namespace = dict()\n    if not no_ipython:\n        try:\n            try:\n                from IPython.frontend.terminal.embed import InteractiveShellEmbed\n\n                sh = InteractiveShellEmbed.instance(banner1=banner)\n            except ImportError:\n                from IPython.Shell import IPShellEmbed\n\n                sh = IPShellEmbed(banner=banner)\n        except ImportError:\n            pass\n        else:\n            sh(local_ns=namespace)\n            return\n    from code import interact\n\n    interact(banner, local=namespace)\n\n\nif __name__ == \"__main__\":\n    cli()\n", "examples/manage-cupoftee.py": "\"\"\"\n    Manage Cup Of Tee\n    ~~~~~~~~~~~~~~~~~\n\n    Manage the cup of tee application.\n\n    :copyright: 2007 Pallets\n    :license: BSD-3-Clause\n\"\"\"\nimport click\nfrom werkzeug.serving import run_simple\n\n\ndef make_app():\n    from cupoftee import make_app\n\n    return make_app(\"/tmp/cupoftee.db\")\n\n\n@click.group()\ndef cli():\n    pass\n\n\n@cli.command()\n@click.option(\"-h\", \"--hostname\", type=str, default=\"localhost\", help=\"localhost\")\n@click.option(\"-p\", \"--port\", type=int, default=5000, help=\"5000\")\n@click.option(\"--reloader\", is_flag=True, default=False)\n@click.option(\"--debugger\", is_flag=True)\n@click.option(\"--evalex\", is_flag=True, default=False)\n@click.option(\"--threaded\", is_flag=True)\n@click.option(\"--processes\", type=int, default=1, help=\"1\")\ndef runserver(hostname, port, reloader, debugger, evalex, threaded, processes):\n    \"\"\"Start a new development server.\"\"\"\n    app = make_app()\n    run_simple(\n        hostname,\n        port,\n        app,\n        use_reloader=reloader,\n        use_debugger=debugger,\n        use_evalex=evalex,\n        threaded=threaded,\n        processes=processes,\n    )\n\n\nif __name__ == \"__main__\":\n    cli()\n", "examples/upload.py": "\"\"\"All uploaded files are directly send back to the client.\"\"\"\nfrom werkzeug.serving import run_simple\nfrom werkzeug.wrappers import Request\nfrom werkzeug.wrappers import Response\nfrom werkzeug.wsgi import wrap_file\n\n\ndef view_file(req):\n    if \"uploaded_file\" not in req.files:\n        return Response(\"no file uploaded\")\n    f = req.files[\"uploaded_file\"]\n    return Response(\n        wrap_file(req.environ, f), mimetype=f.content_type, direct_passthrough=True\n    )\n\n\ndef upload_file(req):\n    return Response(\n        \"\"\"<h1>Upload File</h1>\n        <form action=\"\" method=\"post\" enctype=\"multipart/form-data\">\n            <input type=\"file\" name=\"uploaded_file\">\n            <input type=\"submit\" value=\"Upload\">\n        </form>\"\"\",\n        mimetype=\"text/html\",\n    )\n\n\ndef application(environ, start_response):\n    req = Request(environ)\n    if req.method == \"POST\":\n        resp = view_file(req)\n    else:\n        resp = upload_file(req)\n    return resp(environ, start_response)\n\n\nif __name__ == \"__main__\":\n    run_simple(\"localhost\", 5000, application, use_debugger=True)\n", "examples/httpbasicauth.py": "\"\"\"Shows how you can implement HTTP basic auth support without an\nadditional component.\n\"\"\"\nfrom werkzeug.serving import run_simple\nfrom werkzeug.wrappers import Request\nfrom werkzeug.wrappers import Response\n\n\nclass Application:\n    def __init__(self, users, realm=\"login required\"):\n        self.users = users\n        self.realm = realm\n\n    def check_auth(self, username, password):\n        return username in self.users and self.users[username] == password\n\n    def auth_required(self, request):\n        return Response(\n            \"Could not verify your access level for that URL.\\n\"\n            \"You have to login with proper credentials\",\n            401,\n            {\"WWW-Authenticate\": f'Basic realm=\"{self.realm}\"'},\n        )\n\n    def dispatch_request(self, request):\n        return Response(f\"Logged in as {request.authorization.username}\")\n\n    def __call__(self, environ, start_response):\n        request = Request(environ)\n        auth = request.authorization\n        if not auth or not self.check_auth(auth.username, auth.password):\n            response = self.auth_required(request)\n        else:\n            response = self.dispatch_request(request)\n        return response(environ, start_response)\n\n\nif __name__ == \"__main__\":\n    application = Application({\"user1\": \"password\", \"user2\": \"password\"})\n    run_simple(\"localhost\", 5000, application)\n", "examples/manage-i18nurls.py": "import click\nfrom werkzeug.serving import run_simple\n\nfrom i18nurls import make_app\n\n\n@click.group()\ndef cli():\n    pass\n\n\n@cli.command()\n@click.option(\"-h\", \"--hostname\", type=str, default=\"localhost\", help=\"localhost\")\n@click.option(\"-p\", \"--port\", type=int, default=5000, help=\"5000\")\n@click.option(\"--no-reloader\", is_flag=True, default=False)\n@click.option(\"--debugger\", is_flag=True)\n@click.option(\"--no-evalex\", is_flag=True, default=False)\n@click.option(\"--threaded\", is_flag=True)\n@click.option(\"--processes\", type=int, default=1, help=\"1\")\ndef runserver(hostname, port, no_reloader, debugger, no_evalex, threaded, processes):\n    \"\"\"Start a new development server.\"\"\"\n    app = make_app()\n    reloader = not no_reloader\n    evalex = not no_evalex\n    run_simple(\n        hostname,\n        port,\n        app,\n        use_reloader=reloader,\n        use_debugger=debugger,\n        use_evalex=evalex,\n        threaded=threaded,\n        processes=processes,\n    )\n\n\n@cli.command()\n@click.option(\"--no-ipython\", is_flag=True, default=False)\ndef shell(no_ipython):\n    \"\"\"Start a new interactive python session.\"\"\"\n    banner = \"Interactive Werkzeug Shell\"\n    namespace = dict()\n    if not no_ipython:\n        try:\n            try:\n                from IPython.frontend.terminal.embed import InteractiveShellEmbed\n\n                sh = InteractiveShellEmbed.instance(banner1=banner)\n            except ImportError:\n                from IPython.Shell import IPShellEmbed\n\n                sh = IPShellEmbed(banner=banner)\n        except ImportError:\n            pass\n        else:\n            sh(local_ns=namespace)\n            return\n    from code import interact\n\n    interact(banner, local=namespace)\n\n\nif __name__ == \"__main__\":\n    cli()\n", "examples/wsecho.py": "\"\"\"Shows how you can implement a simple WebSocket echo server using the\nwsproto library.\n\"\"\"\nfrom werkzeug.exceptions import InternalServerError\nfrom werkzeug.serving import run_simple\nfrom werkzeug.wrappers import Request\nfrom werkzeug.wrappers import Response\nfrom wsproto import ConnectionType\nfrom wsproto import WSConnection\nfrom wsproto.events import AcceptConnection\nfrom wsproto.events import CloseConnection\nfrom wsproto.events import Message\nfrom wsproto.events import Ping\nfrom wsproto.events import Request as WSRequest\nfrom wsproto.events import TextMessage\nfrom wsproto.frame_protocol import CloseReason\n\n\n@Request.application\ndef websocket(request):\n    # The underlying socket must be provided by the server. Gunicorn and\n    # Werkzeug's dev server are known to support this.\n    stream = request.environ.get(\"werkzeug.socket\")\n\n    if stream is None:\n        stream = request.environ.get(\"gunicorn.socket\")\n\n    if stream is None:\n        raise InternalServerError()\n\n    # Initialize the wsproto connection. Need to recreate the request\n    # data that was read by the WSGI server already.\n    ws = WSConnection(ConnectionType.SERVER)\n    in_data = b\"GET %s HTTP/1.1\\r\\n\" % request.path.encode(\"utf8\")\n\n    for header, value in request.headers.items():\n        in_data += f\"{header}: {value}\\r\\n\".encode()\n\n    in_data += b\"\\r\\n\"\n    ws.receive_data(in_data)\n    running = True\n\n    while True:\n        out_data = b\"\"\n\n        for event in ws.events():\n            if isinstance(event, WSRequest):\n                out_data += ws.send(AcceptConnection())\n            elif isinstance(event, CloseConnection):\n                out_data += ws.send(event.response())\n                running = False\n            elif isinstance(event, Ping):\n                out_data += ws.send(event.response())\n            elif isinstance(event, TextMessage):\n                # echo the incoming message back to the client\n                if event.data == \"quit\":\n                    out_data += ws.send(\n                        CloseConnection(CloseReason.NORMAL_CLOSURE, \"bye\")\n                    )\n                    running = False\n                else:\n                    out_data += ws.send(Message(data=event.data))\n\n        if out_data:\n            stream.send(out_data)\n\n        if not running:\n            break\n\n        in_data = stream.recv(4096)\n        ws.receive_data(in_data)\n\n    # The connection will be closed at this point, but WSGI still\n    # requires a response.\n    return Response(\"\", status=204)\n\n\nif __name__ == \"__main__\":\n    run_simple(\"localhost\", 5000, websocket)\n", "examples/manage-plnt.py": "import os\n\nimport click\nfrom werkzeug.serving import run_simple\n\n\ndef make_app():\n    \"\"\"Helper function that creates a plnt app.\"\"\"\n    from plnt import Plnt\n\n    database_uri = os.environ.get(\"PLNT_DATABASE_URI\")\n    app = Plnt(database_uri or \"sqlite:////tmp/plnt.db\")\n    app.bind_to_context()\n    return app\n\n\n@click.group()\ndef cli():\n    pass\n\n\n@cli.command()\ndef initdb():\n    \"\"\"Initialize the database\"\"\"\n    from plnt.database import Blog, session\n\n    make_app().init_database()\n    # and now fill in some python blogs everybody should read (shamelessly\n    # added my own blog too)\n    blogs = [\n        Blog(\n            \"Armin Ronacher\",\n            \"https://lucumr.pocoo.org/\",\n            \"https://lucumr.pocoo.org/feed.atom\",\n        ),\n        Blog(\n            \"Georg Brandl\",\n            \"https://pyside.blogspot.com/\",\n            \"https://pyside.blogspot.com/feeds/posts/default\",\n        ),\n        Blog(\n            \"Ian Bicking\",\n            \"https://blog.ianbicking.org/\",\n            \"https://blog.ianbicking.org/feed/\",\n        ),\n        Blog(\n            \"Amir Salihefendic\",\n            \"http://amix.dk/\",\n            \"https://feeds.feedburner.com/amixdk\",\n        ),\n        Blog(\n            \"Christopher Lenz\",\n            \"https://www.cmlenz.net/blog/\",\n            \"https://www.cmlenz.net/blog/atom.xml\",\n        ),\n        Blog(\n            \"Frederick Lundh\",\n            \"https://effbot.org/\",\n            \"https://effbot.org/rss.xml\",\n        ),\n    ]\n    # okay. got tired here.  if someone feels that they are missing, drop me\n    # a line ;-)\n    for blog in blogs:\n        session.add(blog)\n    session.commit()\n    click.echo(\"Initialized database, now run manage-plnt.py sync to get the posts\")\n\n\n@cli.command()\n@click.option(\"-h\", \"--hostname\", type=str, default=\"localhost\", help=\"localhost\")\n@click.option(\"-p\", \"--port\", type=int, default=5000, help=\"5000\")\n@click.option(\"--no-reloader\", is_flag=True, default=False)\n@click.option(\"--debugger\", is_flag=True)\n@click.option(\"--no-evalex\", is_flag=True, default=False)\n@click.option(\"--threaded\", is_flag=True)\n@click.option(\"--processes\", type=int, default=1, help=\"1\")\ndef runserver(hostname, port, no_reloader, debugger, no_evalex, threaded, processes):\n    \"\"\"Start a new development server.\"\"\"\n    app = make_app()\n    reloader = not no_reloader\n    evalex = not no_evalex\n    run_simple(\n        hostname,\n        port,\n        app,\n        use_reloader=reloader,\n        use_debugger=debugger,\n        use_evalex=evalex,\n        threaded=threaded,\n        processes=processes,\n    )\n\n\n@cli.command()\n@click.option(\"--no-ipython\", is_flag=True, default=False)\ndef shell(no_ipython):\n    \"\"\"Start a new interactive python session.\"\"\"\n    banner = \"Interactive Werkzeug Shell\"\n    namespace = {\"app\": make_app()}\n    if not no_ipython:\n        try:\n            try:\n                from IPython.frontend.terminal.embed import InteractiveShellEmbed\n\n                sh = InteractiveShellEmbed.instance(banner1=banner)\n            except ImportError:\n                from IPython.Shell import IPShellEmbed\n\n                sh = IPShellEmbed(banner=banner)\n        except ImportError:\n            pass\n        else:\n            sh(local_ns=namespace)\n            return\n    from code import interact\n\n    interact(banner, local=namespace)\n\n\n@cli.command()\ndef sync():\n    \"\"\"Sync the blogs in the planet.  Call this from a cronjob.\"\"\"\n    from plnt.sync import sync\n\n    make_app().bind_to_context()\n    sync()\n\n\nif __name__ == \"__main__\":\n    cli()\n", "examples/manage-simplewiki.py": "import os\n\nimport click\nfrom werkzeug.serving import run_simple\n\n\ndef make_wiki():\n    \"\"\"Helper function that creates a new wiki instance.\"\"\"\n    from simplewiki import SimpleWiki\n\n    database_uri = os.environ.get(\"SIMPLEWIKI_DATABASE_URI\")\n    return SimpleWiki(database_uri or \"sqlite:////tmp/simplewiki.db\")\n\n\ndef make_shell():\n    from simplewiki import database\n\n    wiki = make_wiki()\n    wiki.bind_to_context()\n    return {\"wiki\": wiki, \"db\": database}\n\n\n@click.group()\ndef cli():\n    pass\n\n\n@cli.command()\ndef initdb():\n    make_wiki().init_database()\n\n\n@cli.command()\n@click.option(\"-h\", \"--hostname\", type=str, default=\"localhost\", help=\"localhost\")\n@click.option(\"-p\", \"--port\", type=int, default=5000, help=\"5000\")\n@click.option(\"--no-reloader\", is_flag=True, default=False)\n@click.option(\"--debugger\", is_flag=True)\n@click.option(\"--no-evalex\", is_flag=True, default=False)\n@click.option(\"--threaded\", is_flag=True)\n@click.option(\"--processes\", type=int, default=1, help=\"1\")\ndef runserver(hostname, port, no_reloader, debugger, no_evalex, threaded, processes):\n    \"\"\"Start a new development server.\"\"\"\n    app = make_wiki()\n    reloader = not no_reloader\n    evalex = not no_evalex\n    run_simple(\n        hostname,\n        port,\n        app,\n        use_reloader=reloader,\n        use_debugger=debugger,\n        use_evalex=evalex,\n        threaded=threaded,\n        processes=processes,\n    )\n\n\n@cli.command()\n@click.option(\"--no-ipython\", is_flag=True, default=False)\ndef shell(no_ipython):\n    \"\"\"Start a new interactive python session.\"\"\"\n    banner = \"Interactive Werkzeug Shell\"\n    namespace = make_shell()\n    if not no_ipython:\n        try:\n            try:\n                from IPython.frontend.terminal.embed import InteractiveShellEmbed\n\n                sh = InteractiveShellEmbed.instance(banner1=banner)\n            except ImportError:\n                from IPython.Shell import IPShellEmbed\n\n                sh = IPShellEmbed(banner=banner)\n        except ImportError:\n            pass\n        else:\n            sh(local_ns=namespace)\n            return\n    from code import interact\n\n    interact(banner, local=namespace)\n\n\nif __name__ == \"__main__\":\n    cli()\n", "examples/manage-webpylike.py": "import os\nimport sys\n\nimport click\nfrom werkzeug.serving import run_simple\n\nfrom webpylike.example import app\n\nsys.path.append(os.path.join(os.path.dirname(__file__), \"webpylike\"))\n\n\n@click.group()\ndef cli():\n    pass\n\n\n@cli.command()\n@click.option(\"-h\", \"--hostname\", type=str, default=\"localhost\", help=\"localhost\")\n@click.option(\"-p\", \"--port\", type=int, default=5000, help=\"5000\")\n@click.option(\"--no-reloader\", is_flag=True, default=False)\n@click.option(\"--debugger\", is_flag=True)\n@click.option(\"--no-evalex\", is_flag=True, default=False)\n@click.option(\"--threaded\", is_flag=True)\n@click.option(\"--processes\", type=int, default=1, help=\"1\")\ndef runserver(hostname, port, no_reloader, debugger, no_evalex, threaded, processes):\n    \"\"\"Start a new development server.\"\"\"\n    reloader = not no_reloader\n    evalex = not no_evalex\n    run_simple(\n        hostname,\n        port,\n        app,\n        use_reloader=reloader,\n        use_debugger=debugger,\n        use_evalex=evalex,\n        threaded=threaded,\n        processes=processes,\n    )\n\n\n@cli.command()\n@click.option(\"--no-ipython\", is_flag=True, default=False)\ndef shell(no_ipython):\n    \"\"\"Start a new interactive python session.\"\"\"\n    banner = \"Interactive Werkzeug Shell\"\n    namespace = dict()\n    if not no_ipython:\n        try:\n            try:\n                from IPython.frontend.terminal.embed import InteractiveShellEmbed\n\n                sh = InteractiveShellEmbed.instance(banner1=banner)\n            except ImportError:\n                from IPython.Shell import IPShellEmbed\n\n                sh = IPShellEmbed(banner=banner)\n        except ImportError:\n            pass\n        else:\n            sh(local_ns=namespace)\n            return\n    from code import interact\n\n    interact(banner, local=namespace)\n\n\nif __name__ == \"__main__\":\n    cli()\n", "examples/manage-couchy.py": "import click\nfrom werkzeug.serving import run_simple\n\n\ndef make_app():\n    from couchy.application import Couchy\n\n    return Couchy(\"http://localhost:5984\")\n\n\ndef make_shell():\n    from couchy import models, utils\n\n    application = make_app()\n    return {\"application\": application, \"models\": models, \"utils\": utils}\n\n\n@click.group()\ndef cli():\n    pass\n\n\n@cli.command()\ndef initdb():\n    from couchy.application import Couchy\n\n    Couchy(\"http://localhost:5984\").init_database()\n\n\n@cli.command()\n@click.option(\"-h\", \"--hostname\", type=str, default=\"localhost\", help=\"localhost\")\n@click.option(\"-p\", \"--port\", type=int, default=5000, help=\"5000\")\n@click.option(\"--no-reloader\", is_flag=True, default=False)\n@click.option(\"--debugger\", is_flag=True)\n@click.option(\"--no-evalex\", is_flag=True, default=False)\n@click.option(\"--threaded\", is_flag=True)\n@click.option(\"--processes\", type=int, default=1, help=\"1\")\ndef runserver(hostname, port, no_reloader, debugger, no_evalex, threaded, processes):\n    \"\"\"Start a new development server.\"\"\"\n    app = make_app()\n    reloader = not no_reloader\n    evalex = not no_evalex\n    run_simple(\n        hostname,\n        port,\n        app,\n        use_reloader=reloader,\n        use_debugger=debugger,\n        use_evalex=evalex,\n        threaded=threaded,\n        processes=processes,\n    )\n\n\n@cli.command()\n@click.option(\"--no-ipython\", is_flag=True, default=False)\ndef shell(no_ipython):\n    \"\"\"Start a new interactive python session.\"\"\"\n    banner = \"Interactive Werkzeug Shell\"\n    namespace = make_shell()\n    if not no_ipython:\n        try:\n            try:\n                from IPython.frontend.terminal.embed import InteractiveShellEmbed\n\n                sh = InteractiveShellEmbed.instance(banner1=banner)\n            except ImportError:\n                from IPython.Shell import IPShellEmbed\n\n                sh = IPShellEmbed(banner=banner)\n        except ImportError:\n            pass\n        else:\n            sh(local_ns=namespace)\n            return\n    from code import interact\n\n    interact(banner, local=namespace)\n\n\nif __name__ == \"__main__\":\n    cli()\n", "examples/manage-shorty.py": "import os\nimport tempfile\n\nimport click\nfrom werkzeug.serving import run_simple\n\n\ndef make_app():\n    from shorty.application import Shorty\n\n    filename = os.path.join(tempfile.gettempdir(), \"shorty.db\")\n    return Shorty(f\"sqlite:///{filename}\")\n\n\ndef make_shell():\n    from shorty import models, utils\n\n    application = make_app()\n    return {\"application\": application, \"models\": models, \"utils\": utils}\n\n\n@click.group()\ndef cli():\n    pass\n\n\n@cli.command()\ndef initdb():\n    make_app().init_database()\n\n\n@cli.command()\n@click.option(\"-h\", \"--hostname\", type=str, default=\"localhost\", help=\"localhost\")\n@click.option(\"-p\", \"--port\", type=int, default=5000, help=\"5000\")\n@click.option(\"--no-reloader\", is_flag=True, default=False)\n@click.option(\"--debugger\", is_flag=True)\n@click.option(\"--no-evalex\", is_flag=True, default=False)\n@click.option(\"--threaded\", is_flag=True)\n@click.option(\"--processes\", type=int, default=1, help=\"1\")\ndef runserver(hostname, port, no_reloader, debugger, no_evalex, threaded, processes):\n    \"\"\"Start a new development server.\"\"\"\n    app = make_app()\n    reloader = not no_reloader\n    evalex = not no_evalex\n    run_simple(\n        hostname,\n        port,\n        app,\n        use_reloader=reloader,\n        use_debugger=debugger,\n        use_evalex=evalex,\n        threaded=threaded,\n        processes=processes,\n    )\n\n\n@cli.command()\n@click.option(\"--no-ipython\", is_flag=True, default=False)\ndef shell(no_ipython):\n    \"\"\"Start a new interactive python session.\"\"\"\n    banner = \"Interactive Werkzeug Shell\"\n    namespace = make_shell()\n    if not no_ipython:\n        try:\n            try:\n                from IPython.frontend.terminal.embed import InteractiveShellEmbed\n\n                sh = InteractiveShellEmbed.instance(banner1=banner)\n            except ImportError:\n                from IPython.Shell import IPShellEmbed\n\n                sh = IPShellEmbed(banner=banner)\n        except ImportError:\n            pass\n        else:\n            sh(local_ns=namespace)\n            return\n    from code import interact\n\n    interact(banner, local=namespace)\n\n\nif __name__ == \"__main__\":\n    cli()\n", "examples/shorty/utils.py": "from os import path\nfrom random import randrange\nfrom random import sample\nfrom urllib.parse import urlsplit\n\nfrom jinja2 import Environment\nfrom jinja2 import FileSystemLoader\nfrom sqlalchemy import MetaData\nfrom sqlalchemy.orm import create_session\nfrom sqlalchemy.orm import scoped_session\nfrom werkzeug.local import Local\nfrom werkzeug.local import LocalManager\nfrom werkzeug.routing import Map\nfrom werkzeug.routing import Rule\nfrom werkzeug.utils import cached_property\nfrom werkzeug.wrappers import Response\n\n\nTEMPLATE_PATH = path.join(path.dirname(__file__), \"templates\")\nSTATIC_PATH = path.join(path.dirname(__file__), \"static\")\nALLOWED_SCHEMES = frozenset([\"http\", \"https\", \"ftp\", \"ftps\"])\nURL_CHARS = \"abcdefghijkmpqrstuvwxyzABCDEFGHIJKLMNPQRST23456789\"\n\nlocal = Local()\nlocal_manager = LocalManager([local])\napplication = local(\"application\")\n\nmetadata = MetaData()\nurl_map = Map([Rule(\"/static/<file>\", endpoint=\"static\", build_only=True)])\n\nsession = scoped_session(\n    lambda: create_session(\n        application.database_engine, autocommit=False, autoflush=False\n    )\n)\njinja_env = Environment(loader=FileSystemLoader(TEMPLATE_PATH))\n\n\ndef expose(rule, **kw):\n    def decorate(f):\n        kw[\"endpoint\"] = f.__name__\n        url_map.add(Rule(rule, **kw))\n        return f\n\n    return decorate\n\n\ndef url_for(endpoint, _external=False, **values):\n    return local.url_adapter.build(endpoint, values, force_external=_external)\n\n\njinja_env.globals[\"url_for\"] = url_for\n\n\ndef render_template(template, **context):\n    return Response(\n        jinja_env.get_template(template).render(**context), mimetype=\"text/html\"\n    )\n\n\ndef validate_url(url):\n    return urlsplit(url)[0] in ALLOWED_SCHEMES\n\n\ndef get_random_uid():\n    return \"\".join(sample(URL_CHARS, randrange(3, 9)))\n\n\nclass Pagination:\n    def __init__(self, query, per_page, page, endpoint):\n        self.query = query\n        self.per_page = per_page\n        self.page = page\n        self.endpoint = endpoint\n\n    @cached_property\n    def count(self):\n        return self.query.count()\n\n    @cached_property\n    def entries(self):\n        return (\n            self.query.offset((self.page - 1) * self.per_page)\n            .limit(self.per_page)\n            .all()\n        )\n\n    @property\n    def has_previous(self):\n        \"\"\"Return True if there are pages before the current one.\"\"\"\n        return self.page > 1\n\n    @property\n    def has_next(self):\n        \"\"\"Return True if there are pages after the current one.\"\"\"\n        return self.page < self.pages\n\n    @property\n    def previous(self):\n        \"\"\"Return the URL for the previous page.\"\"\"\n        return url_for(self.endpoint, page=self.page - 1)\n\n    @property\n    def next(self):\n        \"\"\"Return the URL for the next page.\"\"\"\n        return url_for(self.endpoint, page=self.page + 1)\n\n    @property\n    def pages(self):\n        \"\"\"Return the number of pages.\"\"\"\n        return max(0, self.count - 1) // self.per_page + 1\n", "examples/shorty/models.py": "from datetime import datetime\n\nfrom sqlalchemy import Boolean\nfrom sqlalchemy import Column\nfrom sqlalchemy import DateTime\nfrom sqlalchemy import String\nfrom sqlalchemy import Table\nfrom sqlalchemy.orm import mapper\n\nfrom .utils import get_random_uid\nfrom .utils import metadata\nfrom .utils import session\nfrom .utils import url_for\n\nurl_table = Table(\n    \"urls\",\n    metadata,\n    Column(\"uid\", String(140), primary_key=True),\n    Column(\"target\", String(500)),\n    Column(\"added\", DateTime),\n    Column(\"public\", Boolean),\n)\n\n\nclass URL:\n    query = session.query_property()\n\n    def __init__(self, target, public=True, uid=None, added=None):\n        self.target = target\n        self.public = public\n        self.added = added or datetime.utcnow()\n        if not uid:\n            while 1:\n                uid = get_random_uid()\n                if not URL.query.get(uid):\n                    break\n        self.uid = uid\n        session.add(self)\n\n    @property\n    def short_url(self):\n        return url_for(\"link\", uid=self.uid, _external=True)\n\n    def __repr__(self):\n        return f\"<URL {self.uid!r}>\"\n\n\nmapper(URL, url_table)\n", "examples/shorty/views.py": "from werkzeug.exceptions import NotFound\nfrom werkzeug.utils import redirect\n\nfrom .models import URL\nfrom .utils import expose\nfrom .utils import Pagination\nfrom .utils import render_template\nfrom .utils import session\nfrom .utils import url_for\nfrom .utils import validate_url\n\n\n@expose(\"/\")\ndef new(request):\n    error = url = \"\"\n    if request.method == \"POST\":\n        url = request.form.get(\"url\")\n        alias = request.form.get(\"alias\")\n        if not validate_url(url):\n            error = \"I'm sorry but you cannot shorten this URL.\"\n        elif alias:\n            if len(alias) > 140:\n                error = \"Your alias is too long\"\n            elif \"/\" in alias:\n                error = \"Your alias might not include a slash\"\n            elif URL.query.get(alias):\n                error = \"The alias you have requested exists already\"\n        if not error:\n            uid = URL(url, \"private\" not in request.form, alias).uid\n            session.commit()\n            return redirect(url_for(\"display\", uid=uid))\n    return render_template(\"new.html\", error=error, url=url)\n\n\n@expose(\"/display/<uid>\")\ndef display(request, uid):\n    url = URL.query.get(uid)\n    if not url:\n        raise NotFound()\n    return render_template(\"display.html\", url=url)\n\n\n@expose(\"/u/<uid>\")\ndef link(request, uid):\n    url = URL.query.get(uid)\n    if not url:\n        raise NotFound()\n    return redirect(url.target, 301)\n\n\n@expose(\"/list/\", defaults={\"page\": 1})\n@expose(\"/list/<int:page>\")\ndef list(request, page):\n    query = URL.query.filter_by(public=True)\n    pagination = Pagination(query, 30, page, \"list\")\n    if pagination.page > 1 and not pagination.entries:\n        raise NotFound()\n    return render_template(\"list.html\", pagination=pagination)\n\n\ndef not_found(request):\n    return render_template(\"not_found.html\")\n", "examples/shorty/application.py": "from sqlalchemy import create_engine\nfrom werkzeug.exceptions import HTTPException\nfrom werkzeug.exceptions import NotFound\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.wrappers import Request\nfrom werkzeug.wsgi import ClosingIterator\n\nfrom . import views\nfrom .utils import local\nfrom .utils import local_manager\nfrom .utils import metadata\nfrom .utils import session\nfrom .utils import STATIC_PATH\nfrom .utils import url_map\n\n\nclass Shorty:\n    def __init__(self, db_uri):\n        local.application = self\n        self.database_engine = create_engine(db_uri, convert_unicode=True)\n\n        self.dispatch = SharedDataMiddleware(self.dispatch, {\"/static\": STATIC_PATH})\n\n    def init_database(self):\n        metadata.create_all(self.database_engine)\n\n    def dispatch(self, environ, start_response):\n        local.application = self\n        request = Request(environ)\n        local.url_adapter = adapter = url_map.bind_to_environ(environ)\n        try:\n            endpoint, values = adapter.match()\n            handler = getattr(views, endpoint)\n            response = handler(request, **values)\n        except NotFound:\n            response = views.not_found(request)\n            response.status_code = 404\n        except HTTPException as e:\n            response = e\n        return ClosingIterator(\n            response(environ, start_response), [session.remove, local_manager.cleanup]\n        )\n\n    def __call__(self, environ, start_response):\n        return self.dispatch(environ, start_response)\n", "examples/shorty/__init__.py": "", "examples/simplewiki/actions.py": "\"\"\"The per page actions. The actions are defined in the URL with the\n``action`` parameter and directly dispatched to the functions in this\nmodule. In the module the actions are prefixed with '`on_`', so be\ncareful not to name any other objects in the module with the same prefix\nunless you want to act them as actions.\n\"\"\"\nfrom difflib import unified_diff\n\nfrom werkzeug.utils import redirect\n\nfrom .database import Page\nfrom .database import Revision\nfrom .database import RevisionedPage\nfrom .database import session\nfrom .utils import format_datetime\nfrom .utils import generate_template\nfrom .utils import href\nfrom .utils import Response\n\n\ndef on_show(request, page_name):\n    \"\"\"Displays the page the user requests.\"\"\"\n    revision_id = request.args.get(\"rev\", type=int)\n    query = RevisionedPage.query.filter_by(name=page_name)\n    if revision_id:\n        query = query.filter_by(revision_id=revision_id)\n        revision_requested = True\n    else:\n        query = query.order_by(RevisionedPage.revision_id.desc())\n        revision_requested = False\n    page = query.first()\n    if page is None:\n        return page_missing(request, page_name, revision_requested)\n    return Response(generate_template(\"action_show.html\", page=page))\n\n\ndef on_edit(request, page_name):\n    \"\"\"Edit the current revision of a page.\"\"\"\n    change_note = error = \"\"\n    revision = (\n        Revision.query.filter(\n            (Page.name == page_name) & (Page.page_id == Revision.page_id)\n        )\n        .order_by(Revision.revision_id.desc())\n        .first()\n    )\n    if revision is None:\n        page = None\n    else:\n        page = revision.page\n\n    if request.method == \"POST\":\n        text = request.form.get(\"text\")\n        if request.form.get(\"cancel\") or revision and revision.text == text:\n            return redirect(href(page.name))\n        elif not text:\n            error = \"You cannot save empty revisions.\"\n        else:\n            change_note = request.form.get(\"change_note\", \"\")\n            if page is None:\n                page = Page(page_name)\n                session.add(page)\n            session.add(Revision(page, text, change_note))\n            session.commit()\n            return redirect(href(page.name))\n\n    return Response(\n        generate_template(\n            \"action_edit.html\",\n            revision=revision,\n            page=page,\n            new=page is None,\n            page_name=page_name,\n            change_note=change_note,\n            error=error,\n        )\n    )\n\n\ndef on_log(request, page_name):\n    \"\"\"Show the list of recent changes.\"\"\"\n    page = Page.query.filter_by(name=page_name).first()\n    if page is None:\n        return page_missing(request, page_name, False)\n    return Response(generate_template(\"action_log.html\", page=page))\n\n\ndef on_diff(request, page_name):\n    \"\"\"Show the diff between two revisions.\"\"\"\n    old = request.args.get(\"old\", type=int)\n    new = request.args.get(\"new\", type=int)\n    error = \"\"\n    diff = page = old_rev = new_rev = None\n\n    if not (old and new):\n        error = \"No revisions specified.\"\n    else:\n        revisions = {\n            x.revision_id: x\n            for x in Revision.query.filter(\n                (Revision.revision_id.in_((old, new)))\n                & (Revision.page_id == Page.page_id)\n                & (Page.name == page_name)\n            )\n        }\n        if len(revisions) != 2:\n            error = \"At least one of the revisions requested does not exist.\"\n        else:\n            new_rev = revisions[new]\n            old_rev = revisions[old]\n            page = old_rev.page\n            diff = unified_diff(\n                f\"{old_rev.text}\\n\".splitlines(True),\n                f\"{new_rev.text}\\n\".splitlines(True),\n                page.name,\n                page.name,\n                format_datetime(old_rev.timestamp),\n                format_datetime(new_rev.timestamp),\n                3,\n            )\n\n    return Response(\n        generate_template(\n            \"action_diff.html\",\n            error=error,\n            old_revision=old_rev,\n            new_revision=new_rev,\n            page=page,\n            diff=diff,\n        )\n    )\n\n\ndef on_revert(request, page_name):\n    \"\"\"Revert an old revision.\"\"\"\n    rev_id = request.args.get(\"rev\", type=int)\n\n    old_revision = page = None\n    error = \"No such revision\"\n\n    if request.method == \"POST\" and request.form.get(\"cancel\"):\n        return redirect(href(page_name))\n\n    if rev_id:\n        old_revision = Revision.query.filter(\n            (Revision.revision_id == rev_id)\n            & (Revision.page_id == Page.page_id)\n            & (Page.name == page_name)\n        ).first()\n        if old_revision:\n            new_revision = (\n                Revision.query.filter(\n                    (Revision.page_id == Page.page_id) & (Page.name == page_name)\n                )\n                .order_by(Revision.revision_id.desc())\n                .first()\n            )\n            if old_revision == new_revision:\n                error = \"You tried to revert the current active revision.\"\n            elif old_revision.text == new_revision.text:\n                error = (\n                    \"There are no changes between the current \"\n                    \"revision and the revision you want to \"\n                    \"restore.\"\n                )\n            else:\n                error = \"\"\n                page = old_revision.page\n                if request.method == \"POST\":\n                    change_note = request.form.get(\"change_note\", \"\")\n\n                    if change_note:\n                        change_note = f\"revert: {change_note}\"\n                    else:\n                        change_note = \"revert\"\n\n                    session.add(Revision(page, old_revision.text, change_note))\n                    session.commit()\n                    return redirect(href(page_name))\n\n    return Response(\n        generate_template(\n            \"action_revert.html\", error=error, old_revision=old_revision, page=page\n        )\n    )\n\n\ndef page_missing(request, page_name, revision_requested, protected=False):\n    \"\"\"Displayed if page or revision does not exist.\"\"\"\n    return Response(\n        generate_template(\n            \"page_missing.html\",\n            page_name=page_name,\n            revision_requested=revision_requested,\n            protected=protected,\n        ),\n        status=404,\n    )\n\n\ndef missing_action(request, action):\n    \"\"\"Displayed if a user tried to access a action that does not exist.\"\"\"\n    return Response(generate_template(\"missing_action.html\", action=action), status=404)\n", "examples/simplewiki/utils.py": "from os import path\nfrom urllib.parse import quote\nfrom urllib.parse import urlencode\n\nimport creoleparser\nfrom genshi import Stream\nfrom genshi.template import TemplateLoader\nfrom werkzeug.local import Local\nfrom werkzeug.local import LocalManager\nfrom werkzeug.utils import cached_property\nfrom werkzeug.wrappers import Request as BaseRequest\nfrom werkzeug.wrappers import Response as BaseResponse\n\n\n# calculate the path to the templates an create the template loader\nTEMPLATE_PATH = path.join(path.dirname(__file__), \"templates\")\ntemplate_loader = TemplateLoader(\n    TEMPLATE_PATH, auto_reload=True, variable_lookup=\"lenient\"\n)\n\n\n# context locals.  these two objects are use by the application to\n# bind objects to the current context.  A context is defined as the\n# current thread and the current greenlet if there is greenlet support.\nlocal = Local()\nlocal_manager = LocalManager([local])\nrequest = local(\"request\")\napplication = local(\"application\")\n\n# create a new creole parser\ncreole_parser = creoleparser.Parser(\n    dialect=creoleparser.create_dialect(\n        creoleparser.creole10_base,\n        wiki_links_base_url=\"\",\n        wiki_links_path_func=lambda page_name: href(page_name),\n        wiki_links_space_char=\"_\",\n        no_wiki_monospace=True,\n    ),\n    method=\"html\",\n)\n\n\ndef generate_template(template_name, **context):\n    \"\"\"Load and generate a template.\"\"\"\n    context.update(href=href, format_datetime=format_datetime)\n    return template_loader.load(template_name).generate(**context)\n\n\ndef parse_creole(markup):\n    \"\"\"Parse some creole markup and create a genshi stream.\"\"\"\n    return creole_parser.generate(markup)\n\n\ndef href(*args, **kw):\n    \"\"\"\n    Simple function for URL generation.  Position arguments are used for the\n    URL path and keyword arguments are used for the url parameters.\n    \"\"\"\n    result = [f\"{request.script_root if request else ''}/\"]\n    for idx, arg in enumerate(args):\n        result.append(f\"{'/' if idx else ''}{quote(arg)}\")\n    if kw:\n        result.append(f\"?{urlencode(kw)}\")\n    return \"\".join(result)\n\n\ndef format_datetime(obj):\n    \"\"\"Format a datetime object.\"\"\"\n    return obj.strftime(\"%Y-%m-%d %H:%M\")\n\n\nclass Request(BaseRequest):\n    \"\"\"\n    Simple request subclass that allows to bind the object to the\n    current context.\n    \"\"\"\n\n    def bind_to_context(self):\n        local.request = self\n\n\nclass Response(BaseResponse):\n    \"\"\"\n    Encapsulates a WSGI response.  Unlike the default response object werkzeug\n    provides, this accepts a genshi stream and will automatically render it\n    to html.  This makes it possible to switch to xhtml or html5 easily.\n    \"\"\"\n\n    default_mimetype = \"text/html\"\n\n    def __init__(\n        self, response=None, status=200, headers=None, mimetype=None, content_type=None\n    ):\n        if isinstance(response, Stream):\n            response = response.render(\"html\", encoding=None, doctype=\"html\")\n        super().__init__(response, status, headers, mimetype, content_type)\n\n\nclass Pagination:\n    \"\"\"\n    Paginate a SQLAlchemy query object.\n    \"\"\"\n\n    def __init__(self, query, per_page, page, link):\n        self.query = query\n        self.per_page = per_page\n        self.page = page\n        self.link = link\n        self._count = None\n\n    @cached_property\n    def entries(self):\n        return (\n            self.query.offset((self.page - 1) * self.per_page)\n            .limit(self.per_page)\n            .all()\n        )\n\n    @property\n    def has_previous(self):\n        return self.page > 1\n\n    @property\n    def has_next(self):\n        return self.page < self.pages\n\n    @property\n    def previous(self):\n        return href(self.link, page=self.page - 1)\n\n    @property\n    def next(self):\n        return href(self.link, page=self.page + 1)\n\n    @cached_property\n    def count(self):\n        return self.query.count()\n\n    @property\n    def pages(self):\n        return max(0, self.count - 1) // self.per_page + 1\n", "examples/simplewiki/application.py": "\"\"\"Implements the wiki WSGI application which dispatches requests to\nspecific wiki pages and actions.\n\"\"\"\nfrom os import path\n\nfrom sqlalchemy import create_engine\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.utils import redirect\nfrom werkzeug.wsgi import ClosingIterator\n\nfrom . import actions\nfrom .database import metadata\nfrom .database import session\nfrom .specialpages import page_not_found\nfrom .specialpages import pages\nfrom .utils import href\nfrom .utils import local\nfrom .utils import local_manager\nfrom .utils import Request\n\n#: path to shared data\nSHARED_DATA = path.join(path.dirname(__file__), \"shared\")\n\n\nclass SimpleWiki:\n    \"\"\"\n    Our central WSGI application.\n    \"\"\"\n\n    def __init__(self, database_uri):\n        self.database_engine = create_engine(database_uri)\n\n        # apply our middlewares.   we apply the middlewars *inside* the\n        # application and not outside of it so that we never lose the\n        # reference to the `SimpleWiki` object.\n        self._dispatch = SharedDataMiddleware(\n            self.dispatch_request, {\"/_shared\": SHARED_DATA}\n        )\n\n        # free the context locals at the end of the request\n        self._dispatch = local_manager.make_middleware(self._dispatch)\n\n    def init_database(self):\n        \"\"\"Called from the management script to generate the db.\"\"\"\n        metadata.create_all(bind=self.database_engine)\n\n    def bind_to_context(self):\n        \"\"\"\n        Useful for the shell.  Binds the application to the current active\n        context.  It's automatically called by the shell command.\n        \"\"\"\n        local.application = self\n\n    def dispatch_request(self, environ, start_response):\n        \"\"\"Dispatch an incoming request.\"\"\"\n        # set up all the stuff we want to have for this request.  That is\n        # creating a request object, propagating the application to the\n        # current context and instantiating the database session.\n        self.bind_to_context()\n        request = Request(environ)\n        request.bind_to_context()\n\n        # get the current action from the url and normalize the page name\n        # which is just the request path\n        action_name = request.args.get(\"action\") or \"show\"\n        page_name = \"_\".join([x for x in request.path.strip(\"/\").split() if x])\n\n        # redirect to the Main_Page if the user requested the index\n        if not page_name:\n            response = redirect(href(\"Main_Page\"))\n\n        # check special pages\n        elif page_name.startswith(\"Special:\"):\n            if page_name[8:] not in pages:\n                response = page_not_found(request, page_name)\n            else:\n                response = pages[page_name[8:]](request)\n\n        # get the callback function for the requested action from the\n        # action module.  It's \"on_\" + the action name.  If it doesn't\n        # exists call the missing_action method from the same module.\n        else:\n            action = getattr(actions, f\"on_{action_name}\", None)\n            if action is None:\n                response = actions.missing_action(request, action_name)\n            else:\n                response = action(request, page_name)\n\n        # make sure the session is removed properly\n        return ClosingIterator(response(environ, start_response), session.remove)\n\n    def __call__(self, environ, start_response):\n        \"\"\"Just forward a WSGI call to the first internal middleware.\"\"\"\n        return self._dispatch(environ, start_response)\n", "examples/simplewiki/specialpages.py": "\"\"\"Special pages such as the recent changes page.\"\"\"\nfrom .actions import page_missing\nfrom .database import Page\nfrom .database import RevisionedPage\nfrom .utils import generate_template\nfrom .utils import Pagination\nfrom .utils import Response\n\n\ndef page_index(request):\n    \"\"\"Index of all pages.\"\"\"\n    letters = {}\n    for page in Page.query.order_by(Page.name):\n        letters.setdefault(page.name.capitalize()[0], []).append(page)\n    return Response(\n        generate_template(\"page_index.html\", letters=sorted(letters.items()))\n    )\n\n\ndef recent_changes(request):\n    \"\"\"Display the recent changes.\"\"\"\n    page = max(1, request.args.get(\"page\", type=int))\n    query = RevisionedPage.query.order_by(RevisionedPage.revision_id.desc())\n    return Response(\n        generate_template(\n            \"recent_changes.html\",\n            pagination=Pagination(query, 20, page, \"Special:Recent_Changes\"),\n        )\n    )\n\n\ndef page_not_found(request, page_name):\n    \"\"\"\n    Displays an error message if a user tried to access\n    a not existing special page.\n    \"\"\"\n    return page_missing(request, page_name, True)\n\n\npages = {\"Index\": page_index, \"Recent_Changes\": recent_changes}\n", "examples/simplewiki/database.py": "from datetime import datetime\n\nfrom sqlalchemy import Column\nfrom sqlalchemy import DateTime\nfrom sqlalchemy import ForeignKey\nfrom sqlalchemy import Integer\nfrom sqlalchemy import join\nfrom sqlalchemy import MetaData\nfrom sqlalchemy import String\nfrom sqlalchemy import Table\nfrom sqlalchemy.orm import create_session\nfrom sqlalchemy.orm import mapper\nfrom sqlalchemy.orm import relation\nfrom sqlalchemy.orm import scoped_session\n\nfrom .utils import application\nfrom .utils import parse_creole\n\ntry:\n    from greenlet import getcurrent as get_ident\nexcept ImportError:\n    from threading import get_ident\n\n# create a global metadata\nmetadata = MetaData()\n\n\ndef new_db_session():\n    \"\"\"\n    This function creates a new session if there is no session yet for\n    the current context.  It looks up the application and if it finds\n    one it creates a session bound to the active database engine in that\n    application.  If there is no application bound to the context it\n    raises an exception.\n    \"\"\"\n    return create_session(application.database_engine, autoflush=True, autocommit=False)\n\n\n# and create a new global session factory.  Calling this object gives\n# you the current active session\nsession = scoped_session(new_db_session, get_ident)\n\n\n# our database tables.\npage_table = Table(\n    \"pages\",\n    metadata,\n    Column(\"page_id\", Integer, primary_key=True),\n    Column(\"name\", String(60), unique=True),\n)\n\nrevision_table = Table(\n    \"revisions\",\n    metadata,\n    Column(\"revision_id\", Integer, primary_key=True),\n    Column(\"page_id\", Integer, ForeignKey(\"pages.page_id\")),\n    Column(\"timestamp\", DateTime),\n    Column(\"text\", String),\n    Column(\"change_note\", String(200)),\n)\n\n\nclass Revision:\n    \"\"\"\n    Represents one revision of a page.\n    This is useful for editing particular revision of pages or creating\n    new revisions.  It's also used for the diff system and the revision\n    log.\n    \"\"\"\n\n    query = session.query_property()\n\n    def __init__(self, page, text, change_note=\"\", timestamp=None):\n        if isinstance(page, int):\n            self.page_id = page\n        else:\n            self.page = page\n        self.text = text\n        self.change_note = change_note\n        self.timestamp = timestamp or datetime.utcnow()\n\n    def render(self):\n        \"\"\"Render the page text into a genshi stream.\"\"\"\n        return parse_creole(self.text)\n\n    def __repr__(self):\n        return f\"<{type(self).__name__} {self.page_id!r}:{self.revision_id!r}>\"\n\n\nclass Page:\n    \"\"\"\n    Represents a simple page without any revisions.  This is for example\n    used in the page index where the page contents are not relevant.\n    \"\"\"\n\n    query = session.query_property()\n\n    def __init__(self, name):\n        self.name = name\n\n    @property\n    def title(self):\n        return self.name.replace(\"_\", \" \")\n\n    def __repr__(self):\n        return f\"<{type(self).__name__} {self.name!r}>\"\n\n\nclass RevisionedPage(Page, Revision):\n    \"\"\"\n    Represents a wiki page with a revision.  Thanks to multiple inheritance\n    and the ability of SQLAlchemy to map to joins we can combine `Page` and\n    `Revision` into one class here.\n    \"\"\"\n\n    query = session.query_property()\n\n    def __init__(self):\n        raise TypeError(\n            \"cannot create WikiPage instances, use the Page and \"\n            \"Revision classes for data manipulation.\"\n        )\n\n    def __repr__(self):\n        return f\"<{type(self).__name__} {self.name!r}:{self.revision_id!r}>\"\n\n\n# setup mappers\nmapper(Revision, revision_table)\nmapper(\n    Page,\n    page_table,\n    properties=dict(\n        revisions=relation(\n            Revision, backref=\"page\", order_by=Revision.revision_id.desc()\n        )\n    ),\n)\nmapper(\n    RevisionedPage,\n    join(page_table, revision_table),\n    properties=dict(page_id=[page_table.c.page_id, revision_table.c.page_id]),\n)\n", "examples/simplewiki/__init__.py": "\"\"\"Very simple wiki application based on Genshi, Werkzeug and\nSQLAlchemy. Additionally the creoleparser is used for the wiki markup.\n\"\"\"\nfrom .application import SimpleWiki\n", "examples/partial/complex_routing.py": "from werkzeug.routing import EndpointPrefix\nfrom werkzeug.routing import Map\nfrom werkzeug.routing import Rule\nfrom werkzeug.routing import Subdomain\nfrom werkzeug.routing import Submount\n\nm = Map(\n    [\n        # Static URLs\n        EndpointPrefix(\n            \"static/\",\n            [\n                Rule(\"/\", endpoint=\"index\"),\n                Rule(\"/about\", endpoint=\"about\"),\n                Rule(\"/help\", endpoint=\"help\"),\n            ],\n        ),\n        # Knowledge Base\n        Subdomain(\n            \"kb\",\n            [\n                EndpointPrefix(\n                    \"kb/\",\n                    [\n                        Rule(\"/\", endpoint=\"index\"),\n                        Submount(\n                            \"/browse\",\n                            [\n                                Rule(\"/\", endpoint=\"browse\"),\n                                Rule(\n                                    \"/<int:id>/\",\n                                    defaults={\"page\": 1},\n                                    endpoint=\"browse\",\n                                ),\n                                Rule(\"/<int:id>/<int:page>\", endpoint=\"browse\"),\n                            ],\n                        ),\n                    ],\n                )\n            ],\n        ),\n    ]\n)\n", "examples/plnt/utils.py": "import re\nfrom os import path\n\nfrom jinja2 import Environment\nfrom jinja2 import FileSystemLoader\nfrom werkzeug.local import Local\nfrom werkzeug.local import LocalManager\nfrom werkzeug.routing import Map\nfrom werkzeug.routing import Rule\nfrom werkzeug.utils import cached_property\nfrom werkzeug.wrappers import Response\n\n\n# context locals.  these two objects are use by the application to\n# bind objects to the current context.  A context is defined as the\n# current thread and the current greenlet if there is greenlet support.\n# the `get_request` and `get_application` functions look up the request\n# and application objects from this local manager.\nlocal = Local()\nlocal_manager = LocalManager([local])\n\n\n# proxy objects\nrequest = local(\"request\")\napplication = local(\"application\")\nurl_adapter = local(\"url_adapter\")\n\n\n# let's use jinja for templates this time\ntemplate_path = path.join(path.dirname(__file__), \"templates\")\njinja_env = Environment(loader=FileSystemLoader(template_path))\n\n\n# the collected url patterns\nurl_map = Map([Rule(\"/shared/<path:file>\", endpoint=\"shared\")])\nendpoints = {}\n\n\n_par_re = re.compile(r\"\\n{2,}\")\n_entity_re = re.compile(r\"&([^;]+);\")\n_striptags_re = re.compile(r\"(<!--.*-->|<[^>]*>)\")\n\nfrom html.entities import name2codepoint\n\nhtml_entities = name2codepoint.copy()\nhtml_entities[\"apos\"] = 39\ndel name2codepoint\n\n\ndef expose(url_rule, endpoint=None, **kwargs):\n    \"\"\"Expose this function to the web layer.\"\"\"\n\n    def decorate(f):\n        e = endpoint or f.__name__\n        endpoints[e] = f\n        url_map.add(Rule(url_rule, endpoint=e, **kwargs))\n        return f\n\n    return decorate\n\n\ndef render_template(template_name, **context):\n    \"\"\"Render a template into a response.\"\"\"\n    tmpl = jinja_env.get_template(template_name)\n    context[\"url_for\"] = url_for\n    return Response(tmpl.render(context), mimetype=\"text/html\")\n\n\ndef nl2p(s):\n    \"\"\"Add paragraphs to a text.\"\"\"\n    return \"\\n\".join(f\"<p>{p}</p>\" for p in _par_re.split(s))\n\n\ndef url_for(endpoint, **kw):\n    \"\"\"Simple function for URL generation.\"\"\"\n    return url_adapter.build(endpoint, kw)\n\n\ndef strip_tags(s):\n    \"\"\"Resolve HTML entities and remove tags from a string.\"\"\"\n\n    def handle_match(m):\n        name = m.group(1)\n        if name in html_entities:\n            return chr(html_entities[name])\n        if name[:2] in (\"#x\", \"#X\"):\n            try:\n                return chr(int(name[2:], 16))\n            except ValueError:\n                return \"\"\n        elif name.startswith(\"#\"):\n            try:\n                return chr(int(name[1:]))\n            except ValueError:\n                return \"\"\n        return \"\"\n\n    return _entity_re.sub(handle_match, _striptags_re.sub(\"\", s))\n\n\nclass Pagination:\n    \"\"\"\n    Paginate a SQLAlchemy query object.\n    \"\"\"\n\n    def __init__(self, query, per_page, page, endpoint):\n        self.query = query\n        self.per_page = per_page\n        self.page = page\n        self.endpoint = endpoint\n\n    @cached_property\n    def entries(self):\n        return (\n            self.query.offset((self.page - 1) * self.per_page)\n            .limit(self.per_page)\n            .all()\n        )\n\n    @cached_property\n    def count(self):\n        return self.query.count()\n\n    @property\n    def has_previous(self):\n        \"\"\"Return True if there are pages before the current one.\"\"\"\n        return self.page > 1\n\n    @property\n    def has_next(self):\n        \"\"\"Return True if there are pages after the current one.\"\"\"\n        return self.page < self.pages\n\n    @property\n    def previous(self):\n        \"\"\"Return the URL for the previous page.\"\"\"\n        return url_for(self.endpoint, page=self.page - 1)\n\n    @property\n    def next(self):\n        \"\"\"Return the URL for the next page.\"\"\"\n        return url_for(self.endpoint, page=self.page + 1)\n\n    @property\n    def pages(self):\n        \"\"\"Return the number of pages.\"\"\"\n        return max(0, self.count - 1) // self.per_page + 1\n", "examples/plnt/sync.py": "\"\"\"Does the synchronization. Called by \"manage-plnt.py sync\".\"\"\"\nfrom datetime import datetime\n\nimport feedparser\nfrom markupsafe import escape\n\nfrom .database import Blog\nfrom .database import Entry\nfrom .database import session\nfrom .utils import nl2p\nfrom .utils import strip_tags\n\n\nHTML_MIMETYPES = {\"text/html\", \"application/xhtml+xml\"}\n\n\ndef sync():\n    \"\"\"\n    Performs a synchronization. Articles that are already synchronized aren't\n    touched anymore.\n    \"\"\"\n    for blog in Blog.query.all():\n        # parse the feed. feedparser.parse will never given an exception\n        # but the bozo bit might be defined.\n        feed = feedparser.parse(blog.feed_url)\n\n        for entry in feed.entries:\n            # get the guid. either the id if specified, otherwise the link.\n            # if none is available we skip the entry.\n            guid = entry.get(\"id\") or entry.get(\"link\")\n            if not guid:\n                continue\n\n            # get an old entry for the guid to check if we need to update\n            # or recreate the item\n            old_entry = Entry.query.filter_by(guid=guid).first()\n\n            # get title, url and text. skip if no title or no text is\n            # given. if the link is missing we use the blog link.\n            if \"title_detail\" in entry:\n                title = entry.title_detail.get(\"value\") or \"\"\n                if entry.title_detail.get(\"type\") in HTML_MIMETYPES:\n                    title = strip_tags(title)\n                else:\n                    title = escape(title)\n            else:\n                title = entry.get(\"title\")\n            url = entry.get(\"link\") or blog.blog_url\n            text = (\n                entry.content[0] if \"content\" in entry else entry.get(\"summary_detail\")\n            )\n\n            if not title or not text:\n                continue\n\n            # if we have an html text we use that, otherwise we HTML\n            # escape the text and use that one. We also handle XHTML\n            # with our tag soup parser for the moment.\n            if text.get(\"type\") not in HTML_MIMETYPES:\n                text = escape(nl2p(text.get(\"value\") or \"\"))\n            else:\n                text = text.get(\"value\") or \"\"\n\n            # no text? continue\n            if not text.strip():\n                continue\n\n            # get the pub date and updated date. This is rather complex\n            # because different feeds do different stuff\n            pub_date = (\n                entry.get(\"published_parsed\")\n                or entry.get(\"created_parsed\")\n                or entry.get(\"date_parsed\")\n            )\n            updated = entry.get(\"updated_parsed\") or pub_date\n            pub_date = pub_date or updated\n\n            # if we don't have a pub_date we skip.\n            if not pub_date:\n                continue\n\n            # convert the time tuples to datetime objects.\n            pub_date = datetime(*pub_date[:6])\n            updated = datetime(*updated[:6])\n            if old_entry and updated <= old_entry.last_update:\n                continue\n\n            # create a new entry object based on the data collected or\n            # update the old one.\n            entry = old_entry or Entry()\n            entry.blog = blog\n            entry.guid = guid\n            entry.title = title\n            entry.url = url\n            entry.text = text\n            entry.pub_date = pub_date\n            entry.last_update = updated\n            session.add(entry)\n\n    session.commit()\n", "examples/plnt/views.py": "\"\"\"Display the aggregated feeds.\"\"\"\nfrom datetime import date\n\nfrom .database import Entry\nfrom .utils import expose\nfrom .utils import Pagination\nfrom .utils import render_template\n\n\n#: number of items per page\nPER_PAGE = 30\n\n\n@expose(\"/\", defaults={\"page\": 1})\n@expose(\"/page/<int:page>\")\ndef index(request, page):\n    \"\"\"Show the index page or any an offset of it.\"\"\"\n    days = []\n    days_found = set()\n    query = Entry.query.order_by(Entry.pub_date.desc())\n    pagination = Pagination(query, PER_PAGE, page, \"index\")\n    for entry in pagination.entries:\n        day = date(*entry.pub_date.timetuple()[:3])\n        if day not in days_found:\n            days_found.add(day)\n            days.append({\"date\": day, \"entries\": []})\n        days[-1][\"entries\"].append(entry)\n    return render_template(\"index.html\", days=days, pagination=pagination)\n\n\n@expose(\"/about\")\ndef about(request):\n    \"\"\"Show the about page, so that we have another view func ;-)\"\"\"\n    return render_template(\"about.html\")\n", "examples/plnt/database.py": "from sqlalchemy import Column\nfrom sqlalchemy import DateTime\nfrom sqlalchemy import ForeignKey\nfrom sqlalchemy import Integer\nfrom sqlalchemy import MetaData\nfrom sqlalchemy import String\nfrom sqlalchemy import Table\nfrom sqlalchemy.orm import create_session\nfrom sqlalchemy.orm import dynamic_loader\nfrom sqlalchemy.orm import mapper\nfrom sqlalchemy.orm import scoped_session\n\nfrom .utils import application\n\ntry:\n    from greenlet import getcurrent as get_ident\nexcept ImportError:\n    from threading import get_ident\n\n\ndef new_db_session():\n    return create_session(application.database_engine, autoflush=True, autocommit=False)\n\n\nmetadata = MetaData()\nsession = scoped_session(new_db_session, get_ident)\n\n\nblog_table = Table(\n    \"blogs\",\n    metadata,\n    Column(\"id\", Integer, primary_key=True),\n    Column(\"name\", String(120)),\n    Column(\"description\", String),\n    Column(\"url\", String(200)),\n    Column(\"feed_url\", String(250)),\n)\n\nentry_table = Table(\n    \"entries\",\n    metadata,\n    Column(\"id\", Integer, primary_key=True),\n    Column(\"blog_id\", Integer, ForeignKey(\"blogs.id\")),\n    Column(\"guid\", String(200), unique=True),\n    Column(\"title\", String(140)),\n    Column(\"url\", String(200)),\n    Column(\"text\", String),\n    Column(\"pub_date\", DateTime),\n    Column(\"last_update\", DateTime),\n)\n\n\nclass Blog:\n    query = session.query_property()\n\n    def __init__(self, name, url, feed_url, description=\"\"):\n        self.name = name\n        self.url = url\n        self.feed_url = feed_url\n        self.description = description\n\n    def __repr__(self):\n        return f\"<{type(self).__name__} {self.url!r}>\"\n\n\nclass Entry:\n    query = session.query_property()\n\n    def __repr__(self):\n        return f\"<{type(self).__name__} {self.guid!r}>\"\n\n\nmapper(Entry, entry_table)\nmapper(Blog, blog_table, properties=dict(entries=dynamic_loader(Entry, backref=\"blog\")))\n", "examples/plnt/webapp.py": "from os import path\n\nfrom sqlalchemy import create_engine\nfrom werkzeug.exceptions import HTTPException\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.wrappers import Request\nfrom werkzeug.wsgi import ClosingIterator\n\nfrom . import views  # noqa: F401\nfrom .database import metadata\nfrom .database import session\nfrom .utils import endpoints\nfrom .utils import local\nfrom .utils import local_manager\nfrom .utils import url_map\n\n#: path to shared data\nSHARED_DATA = path.join(path.dirname(__file__), \"shared\")\n\n\nclass Plnt:\n    def __init__(self, database_uri):\n        self.database_engine = create_engine(database_uri)\n\n        self._dispatch = local_manager.middleware(self.dispatch_request)\n        self._dispatch = SharedDataMiddleware(self._dispatch, {\"/shared\": SHARED_DATA})\n\n    def init_database(self):\n        metadata.create_all(self.database_engine)\n\n    def bind_to_context(self):\n        local.application = self\n\n    def dispatch_request(self, environ, start_response):\n        self.bind_to_context()\n        local.request = request = Request(environ, start_response)\n        local.url_adapter = adapter = url_map.bind_to_environ(environ)\n        try:\n            endpoint, values = adapter.match(request.path)\n            response = endpoints[endpoint](request, **values)\n        except HTTPException as e:\n            response = e\n        return ClosingIterator(response(environ, start_response), session.remove)\n\n    def __call__(self, environ, start_response):\n        return self._dispatch(environ, start_response)\n", "examples/plnt/__init__.py": "\"\"\"A planet application, pronounced \"plant\".\"\"\"\nfrom .webapp import Plnt\n", "examples/cupoftee/db.py": "\"\"\"A simple object database. As long as the server is not running in\nmultiprocess mode that's good enough.\n\"\"\"\nimport dbm\nfrom pickle import dumps\nfrom pickle import loads\nfrom threading import Lock\n\n\nclass Database:\n    def __init__(self, filename):\n        self.filename = filename\n        self._fs = dbm.open(filename, \"cf\")\n        self._local = {}\n        self._lock = Lock()\n\n    def __getitem__(self, key):\n        with self._lock:\n            return self._load_key(key)\n\n    def _load_key(self, key):\n        if key in self._local:\n            return self._local[key]\n        rv = loads(self._fs[key])\n        self._local[key] = rv\n        return rv\n\n    def __setitem__(self, key, value):\n        self._local[key] = value\n\n    def __delitem__(self, key):\n        with self._lock:\n            self._local.pop(key, None)\n            if key in self._fs:\n                del self._fs[key]\n\n    def __del__(self):\n        self.close()\n\n    def __contains__(self, key):\n        with self._lock:\n            try:\n                self._load_key(key)\n            except KeyError:\n                pass\n            return key in self._local\n\n    def setdefault(self, key, factory):\n        with self._lock:\n            try:\n                rv = self._load_key(key)\n            except KeyError:\n                self._local[key] = rv = factory()\n            return rv\n\n    def sync(self):\n        with self._lock:\n            for key, value in self._local.items():\n                self._fs[key] = dumps(value, 2)\n            self._fs.sync()\n\n    def close(self):\n        try:\n            self.sync()\n            self._fs.close()\n        except Exception:\n            pass\n", "examples/cupoftee/utils.py": "import re\n\n\n_sort_re = re.compile(r\"\\w+\")\n\n\ndef unicodecmp(a, b):\n    x, y = map(_sort_re.search, [a, b])\n    x = (x.group() if x else a).lower()\n    y = (y.group() if y else b).lower()\n    return (x > y) - (x < y)\n", "examples/cupoftee/application.py": "import time\nfrom os import path\nfrom threading import Thread\n\nfrom jinja2 import Environment\nfrom jinja2 import PackageLoader\nfrom werkzeug.exceptions import HTTPException\nfrom werkzeug.exceptions import NotFound\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.routing import Map\nfrom werkzeug.routing import Rule\nfrom werkzeug.wrappers import Request\nfrom werkzeug.wrappers import Response\n\nfrom .db import Database\nfrom .network import ServerBrowser\n\n\ntemplates = path.join(path.dirname(__file__), \"templates\")\npages = {}\nurl_map = Map([Rule(\"/shared/<file>\", endpoint=\"shared\")])\n\n\ndef make_app(database, interval=120):\n    return SharedDataMiddleware(\n        Cup(database, interval),\n        {\"/shared\": path.join(path.dirname(__file__), \"shared\")},\n    )\n\n\nclass PageMeta(type):\n    def __init__(cls, name, bases, d):\n        type.__init__(cls, name, bases, d)\n        if d.get(\"url_rule\") is not None:\n            pages[cls.identifier] = cls\n            url_map.add(\n                Rule(cls.url_rule, endpoint=cls.identifier, **cls.url_arguments)\n            )\n\n    @property\n    def identifier(cls):\n        return cls.__name__.lower()\n\n\ndef _with_metaclass(meta, *bases):\n    \"\"\"Create a base class with a metaclass.\"\"\"\n\n    class metaclass(type):\n        def __new__(metacls, name, this_bases, d):\n            return meta(name, bases, d)\n\n    return type.__new__(metaclass, \"temporary_class\", (), {})\n\n\nclass Page(_with_metaclass(PageMeta, object)):\n    url_arguments = {}\n\n    def __init__(self, cup, request, url_adapter):\n        self.cup = cup\n        self.request = request\n        self.url_adapter = url_adapter\n\n    def url_for(self, endpoint, **values):\n        return self.url_adapter.build(endpoint, values)\n\n    def process(self):\n        pass\n\n    def render_template(self, template=None):\n        if template is None:\n            template = f\"{type(self).identifier}.html\"\n        context = dict(self.__dict__)\n        context.update(url_for=self.url_for, self=self)\n        return self.cup.render_template(template, context)\n\n    def get_response(self):\n        return Response(self.render_template(), mimetype=\"text/html\")\n\n\nclass Cup:\n    def __init__(self, database, interval=120):\n        self.jinja_env = Environment(loader=PackageLoader(\"cupoftee\"), autoescape=True)\n        self.interval = interval\n        self.db = Database(database)\n        self.server_browser = ServerBrowser(self)\n        self.updater = Thread(None, self.update_server_browser)\n        self.updater.daemon = True\n        self.updater.start()\n\n    def update_server_browser(self):\n        while 1:\n            if self.server_browser.sync():\n                wait = self.interval\n            else:\n                wait = self.interval // 2\n            time.sleep(wait)\n\n    def dispatch_request(self, request):\n        url_adapter = url_map.bind_to_environ(request.environ)\n        try:\n            endpoint, values = url_adapter.match()\n            page = pages[endpoint](self, request, url_adapter)\n            response = page.process(**values)\n        except NotFound:\n            page = MissingPage(self, request, url_adapter)\n            response = page.process()\n        except HTTPException as e:\n            return e\n        return response or page.get_response()\n\n    def __call__(self, environ, start_response):\n        request = Request(environ)\n        return self.dispatch_request(request)(environ, start_response)\n\n    def render_template(self, name, **context):\n        template = self.jinja_env.get_template(name)\n        return template.render(context)\n\n\nfrom cupoftee.pages import MissingPage\n", "examples/cupoftee/__init__.py": "\"\"\"Werkzeug powered Teeworlds Server Browser.\"\"\"\nfrom .application import make_app\n", "examples/cupoftee/pages.py": "from functools import reduce\n\nfrom werkzeug.exceptions import NotFound\nfrom werkzeug.utils import redirect\n\nfrom .application import Page\nfrom .utils import unicodecmp\n\n\nclass ServerList(Page):\n    url_rule = \"/\"\n\n    def order_link(self, name, title):\n        cls = \"\"\n        link = f\"?order_by={name}\"\n        desc = False\n        if name == self.order_by:\n            desc = not self.order_desc\n            cls = f' class=\"{\"down\" if desc else \"up\"}\"'\n        if desc:\n            link += \"&amp;dir=desc\"\n        return f'<a href=\"{link}\"{cls}>{title}</a>'\n\n    def process(self):\n        self.order_by = self.request.args.get(\"order_by\") or \"name\"\n        sort_func = {\n            \"name\": lambda x: x,\n            \"map\": lambda x: x.map,\n            \"gametype\": lambda x: x.gametype,\n            \"players\": lambda x: x.player_count,\n            \"progression\": lambda x: x.progression,\n        }.get(self.order_by)\n        if sort_func is None:\n            return redirect(self.url_for(\"serverlist\"))\n\n        self.servers = self.cup.server_browser.servers.values()\n        self.servers.sort(key=sort_func)\n        if self.request.args.get(\"dir\") == \"desc\":\n            self.servers.reverse()\n            self.order_desc = True\n        else:\n            self.order_desc = False\n\n        self.players = reduce(lambda a, b: a + b.players, self.servers, [])\n        self.players = sorted(self.players, key=lambda a, b: unicodecmp(a.name, b.name))\n\n\nclass Server(Page):\n    url_rule = \"/server/<id>\"\n\n    def process(self, id):\n        try:\n            self.server = self.cup.server_browser.servers[id]\n        except KeyError:\n            raise NotFound() from None\n\n\nclass Search(Page):\n    url_rule = \"/search\"\n\n    def process(self):\n        self.user = self.request.args.get(\"user\")\n        if self.user:\n            self.results = []\n            for server in self.cup.server_browser.servers.values():\n                for player in server.players:\n                    if player.name == self.user:\n                        self.results.append(server)\n\n\nclass MissingPage(Page):\n    def get_response(self):\n        response = super().get_response()\n        response.status_code = 404\n        return response\n", "examples/cupoftee/network.py": "\"\"\"Query the servers for information.\"\"\"\nimport socket\nfrom datetime import datetime\nfrom math import log\n\nfrom .utils import unicodecmp\n\n\nclass ServerError(Exception):\n    pass\n\n\nclass Syncable:\n    last_sync = None\n\n    def sync(self):\n        try:\n            self._sync()\n        except (OSError, socket.timeout):\n            return False\n        self.last_sync = datetime.utcnow()\n        return True\n\n\nclass ServerBrowser(Syncable):\n    def __init__(self, cup):\n        self.cup = cup\n        self.servers = cup.db.setdefault(\"servers\", dict)\n\n    def _sync(self):\n        to_delete = set(self.servers)\n        for x in range(1, 17):\n            addr = (f\"master{x}.teeworlds.com\", 8300)\n            print(addr)\n            try:\n                self._sync_server_browser(addr, to_delete)\n            except (OSError, socket.timeout):\n                continue\n        for server_id in to_delete:\n            self.servers.pop(server_id, None)\n        if not self.servers:\n            raise OSError(\"no servers found\")\n        self.cup.db.sync()\n\n    def _sync_server_browser(self, addr, to_delete):\n        s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n        s.settimeout(5)\n        s.sendto(b\"\\x20\\x00\\x00\\x00\\x00\\x48\\xff\\xff\\xff\\xffreqt\", addr)\n        data = s.recvfrom(1024)[0][14:]\n        s.close()\n\n        for n in range(0, len(data) // 6):\n            addr = (\n                \".\".join(map(str, map(ord, data[n * 6 : n * 6 + 4]))),\n                ord(data[n * 6 + 5]) * 256 + ord(data[n * 6 + 4]),\n            )\n            server_id = f\"{addr[0]}:{addr[1]}\"\n            if server_id in self.servers:\n                if not self.servers[server_id].sync():\n                    continue\n            else:\n                try:\n                    self.servers[server_id] = Server(addr, server_id)\n                except ServerError:\n                    pass\n            to_delete.discard(server_id)\n\n\nclass Server(Syncable):\n    def __init__(self, addr, server_id):\n        self.addr = addr\n        self.id = server_id\n        self.players = []\n        if not self.sync():\n            raise ServerError(\"server not responding in time\")\n\n    def _sync(self):\n        s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n        s.settimeout(1)\n        s.sendto(b\"\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xffgief\", self.addr)\n        bits = s.recvfrom(1024)[0][14:].split(b\"\\x00\")\n        s.close()\n        self.version, server_name, map_name = bits[:3]\n        self.name = server_name.decode(\"latin1\")\n        self.map = map_name.decode(\"latin1\")\n        self.gametype = bits[3]\n        self.flags, self.progression, player_count, self.max_players = map(\n            int, bits[4:8]\n        )\n\n        # sync the player stats\n        players = {p.name: p for p in self.players}\n        for i in range(player_count):\n            name = bits[8 + i * 2].decode(\"latin1\")\n            score = int(bits[9 + i * 2])\n\n            # update existing player\n            if name in players:\n                player = players.pop(name)\n                player.score = score\n            # add new player\n            else:\n                self.players.append(Player(self, name, score))\n        # delete players that left\n        for player in players.values():\n            try:\n                self.players.remove(player)\n            except Exception:\n                pass\n\n        # sort the player list and count them\n        self.players.sort(key=lambda x: -x.score)\n        self.player_count = len(self.players)\n\n    def __cmp__(self, other):\n        return unicodecmp(self.name, other.name)\n\n\nclass Player:\n    def __init__(self, server, name, score):\n        self.server = server\n        self.name = name\n        self.score = score\n        self.size = round(100 + log(max(score, 1)) * 25, 2)\n", "examples/couchy/utils.py": "from os import path\nfrom random import randrange\nfrom random import sample\nfrom urllib.parse import urlsplit\n\nfrom jinja2 import Environment\nfrom jinja2 import FileSystemLoader\nfrom werkzeug.local import Local\nfrom werkzeug.local import LocalManager\nfrom werkzeug.routing import Map\nfrom werkzeug.routing import Rule\nfrom werkzeug.utils import cached_property\nfrom werkzeug.wrappers import Response\n\nTEMPLATE_PATH = path.join(path.dirname(__file__), \"templates\")\nSTATIC_PATH = path.join(path.dirname(__file__), \"static\")\nALLOWED_SCHEMES = frozenset([\"http\", \"https\", \"ftp\", \"ftps\"])\nURL_CHARS = \"abcdefghijkmpqrstuvwxyzABCDEFGHIJKLMNPQRST23456789\"\n\nlocal = Local()\nlocal_manager = LocalManager([local])\napplication = local(\"application\")\n\nurl_map = Map([Rule(\"/static/<file>\", endpoint=\"static\", build_only=True)])\n\njinja_env = Environment(loader=FileSystemLoader(TEMPLATE_PATH))\n\n\ndef expose(rule, **kw):\n    def decorate(f):\n        kw[\"endpoint\"] = f.__name__\n        url_map.add(Rule(rule, **kw))\n        return f\n\n    return decorate\n\n\ndef url_for(endpoint, _external=False, **values):\n    return local.url_adapter.build(endpoint, values, force_external=_external)\n\n\njinja_env.globals[\"url_for\"] = url_for\n\n\ndef render_template(template, **context):\n    return Response(\n        jinja_env.get_template(template).render(**context), mimetype=\"text/html\"\n    )\n\n\ndef validate_url(url):\n    return urlsplit(url)[0] in ALLOWED_SCHEMES\n\n\ndef get_random_uid():\n    return \"\".join(sample(URL_CHARS, randrange(3, 9)))\n\n\nclass Pagination:\n    def __init__(self, results, per_page, page, endpoint):\n        self.results = results\n        self.per_page = per_page\n        self.page = page\n        self.endpoint = endpoint\n\n    @cached_property\n    def count(self):\n        return len(self.results)\n\n    @cached_property\n    def entries(self):\n        return self.results[\n            ((self.page - 1) * self.per_page) : (\n                ((self.page - 1) * self.per_page) + self.per_page\n            )\n        ]\n\n    @property\n    def has_previous(self):\n        \"\"\"Return True if there are pages before the current one.\"\"\"\n        return self.page > 1\n\n    @property\n    def has_next(self):\n        \"\"\"Return True if there are pages after the current one.\"\"\"\n        return self.page < self.pages\n\n    @property\n    def previous(self):\n        \"\"\"Return the URL for the previous page.\"\"\"\n        return url_for(self.endpoint, page=self.page - 1)\n\n    @property\n    def next(self):\n        \"\"\"Return the URL for the next page.\"\"\"\n        return url_for(self.endpoint, page=self.page + 1)\n\n    @property\n    def pages(self):\n        \"\"\"Return the number of pages.\"\"\"\n        return max(0, self.count - 1) // self.per_page + 1\n", "examples/couchy/models.py": "from datetime import datetime\n\nfrom couchdb.mapping import BooleanField\nfrom couchdb.mapping import DateTimeField\nfrom couchdb.mapping import Document\nfrom couchdb.mapping import TextField\n\nfrom .utils import get_random_uid\nfrom .utils import url_for\n\n\nclass URL(Document):\n    target = TextField()\n    public = BooleanField()\n    added = DateTimeField(default=datetime.utcnow())\n    shorty_id = TextField(default=None)\n    db = None\n\n    @classmethod\n    def load(cls, id):\n        return super().load(URL.db, id)\n\n    @classmethod\n    def query(cls, code):\n        return URL.db.query(code)\n\n    def store(self):\n        if getattr(self._data, \"id\", None) is None:\n            new_id = self.shorty_id if self.shorty_id else None\n            while 1:\n                id = new_id if new_id else get_random_uid()\n                try:\n                    docid = URL.db.resource.put(content=self._data, path=f\"/{id}/\")[\n                        \"id\"\n                    ]\n                except Exception:\n                    continue\n                if docid:\n                    break\n            self._data = URL.db.get(docid)\n        else:\n            super().store(URL.db)\n        return self\n\n    @property\n    def short_url(self):\n        return url_for(\"link\", uid=self.id, _external=True)\n\n    def __repr__(self):\n        return f\"<URL {self.id!r}>\"\n", "examples/couchy/views.py": "from werkzeug.exceptions import NotFound\nfrom werkzeug.utils import redirect\n\nfrom .models import URL\nfrom .utils import expose\nfrom .utils import Pagination\nfrom .utils import render_template\nfrom .utils import url_for\nfrom .utils import validate_url\n\n\n@expose(\"/\")\ndef new(request):\n    error = url = \"\"\n    if request.method == \"POST\":\n        url = request.form.get(\"url\")\n        alias = request.form.get(\"alias\")\n        if not validate_url(url):\n            error = \"I'm sorry but you cannot shorten this URL.\"\n        elif alias:\n            if len(alias) > 140:\n                error = \"Your alias is too long\"\n            elif \"/\" in alias:\n                error = \"Your alias might not include a slash\"\n            elif URL.load(alias):\n                error = \"The alias you have requested exists already\"\n        if not error:\n            url = URL(\n                target=url,\n                public=\"private\" not in request.form,\n                shorty_id=alias if alias else None,\n            )\n            url.store()\n            uid = url.id\n            return redirect(url_for(\"display\", uid=uid))\n    return render_template(\"new.html\", error=error, url=url)\n\n\n@expose(\"/display/<uid>\")\ndef display(request, uid):\n    url = URL.load(uid)\n    if not url:\n        raise NotFound()\n    return render_template(\"display.html\", url=url)\n\n\n@expose(\"/u/<uid>\")\ndef link(request, uid):\n    url = URL.load(uid)\n    if not url:\n        raise NotFound()\n    return redirect(url.target, 301)\n\n\n@expose(\"/list/\", defaults={\"page\": 1})\n@expose(\"/list/<int:page>\")\ndef list(request, page):\n    def wrap(doc):\n        data = doc.value\n        data[\"_id\"] = doc.id\n        return URL.wrap(data)\n\n    code = \"\"\"function(doc) { if (doc.public){ map([doc._id], doc); }}\"\"\"\n    docResults = URL.query(code)\n    results = [wrap(doc) for doc in docResults]\n    pagination = Pagination(results, 1, page, \"list\")\n    if pagination.page > 1 and not pagination.entries:\n        raise NotFound()\n    return render_template(\"list.html\", pagination=pagination)\n\n\ndef not_found(request):\n    return render_template(\"not_found.html\")\n", "examples/couchy/application.py": "from couchdb.client import Server\nfrom werkzeug.exceptions import HTTPException\nfrom werkzeug.exceptions import NotFound\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.wrappers import Request\nfrom werkzeug.wsgi import ClosingIterator\n\nfrom . import views\nfrom .models import URL\nfrom .utils import local\nfrom .utils import local_manager\nfrom .utils import STATIC_PATH\nfrom .utils import url_map\n\n\nclass Couchy:\n    def __init__(self, db_uri):\n        local.application = self\n\n        server = Server(db_uri)\n        try:\n            db = server.create(\"urls\")\n        except Exception:\n            db = server[\"urls\"]\n        self.dispatch = SharedDataMiddleware(self.dispatch, {\"/static\": STATIC_PATH})\n\n        URL.db = db\n\n    def dispatch(self, environ, start_response):\n        local.application = self\n        request = Request(environ)\n        local.url_adapter = adapter = url_map.bind_to_environ(environ)\n        try:\n            endpoint, values = adapter.match()\n            handler = getattr(views, endpoint)\n            response = handler(request, **values)\n        except NotFound:\n            response = views.not_found(request)\n            response.status_code = 404\n        except HTTPException as e:\n            response = e\n        return ClosingIterator(\n            response(environ, start_response), [local_manager.cleanup]\n        )\n\n    def __call__(self, environ, start_response):\n        return self.dispatch(environ, start_response)\n", "examples/couchy/__init__.py": "", "examples/webpylike/webpylike.py": "\"\"\"Implements web.py like dispatching. What this module does not\nimplement is a stream system that hooks into sys.stdout like web.py\nprovides.\n\"\"\"\nimport re\n\nfrom werkzeug.exceptions import HTTPException\nfrom werkzeug.exceptions import MethodNotAllowed\nfrom werkzeug.exceptions import NotFound\nfrom werkzeug.exceptions import NotImplemented\nfrom werkzeug.wrappers import Request\nfrom werkzeug.wrappers import Response  # noqa: F401\n\n\nclass View:\n    \"\"\"Baseclass for our views.\"\"\"\n\n    def __init__(self, app, req):\n        self.app = app\n        self.req = req\n\n    def GET(self):\n        raise MethodNotAllowed()\n\n    POST = DELETE = PUT = GET\n\n    def HEAD(self):\n        return self.GET()\n\n\nclass WebPyApp:\n    \"\"\"\n    An interface to a web.py like application.  It works like the web.run\n    function in web.py\n    \"\"\"\n\n    def __init__(self, urls, views):\n        self.urls = [\n            (re.compile(f\"^{urls[i]}$\"), urls[i + 1]) for i in range(0, len(urls), 2)\n        ]\n        self.views = views\n\n    def __call__(self, environ, start_response):\n        try:\n            req = Request(environ)\n            for regex, view in self.urls:\n                match = regex.match(req.path)\n                if match is not None:\n                    view = self.views[view](self, req)\n                    if req.method not in (\"GET\", \"HEAD\", \"POST\", \"DELETE\", \"PUT\"):\n                        raise NotImplemented()  # noqa: F901\n                    resp = getattr(view, req.method)(*match.groups())\n                    break\n            else:\n                raise NotFound()\n        except HTTPException as e:\n            resp = e\n        return resp(environ, start_response)\n", "examples/webpylike/example.py": "from .webpylike import Response\nfrom .webpylike import View\nfrom .webpylike import WebPyApp\n\n\nurls = (\"/\", \"index\", \"/about\", \"about\")\n\n\nclass index(View):\n    def GET(self):\n        return Response(\"Hello World\")\n\n\nclass about(View):\n    def GET(self):\n        return Response(\"This is the about page\")\n\n\napp = WebPyApp(urls, globals())\n", "examples/i18nurls/urls.py": "from werkzeug.routing import Map\nfrom werkzeug.routing import Rule\nfrom werkzeug.routing import Submount\n\nmap = Map(\n    [\n        Rule(\"/\", endpoint=\"#language_select\"),\n        Submount(\n            \"/<string(length=2):lang_code>\",\n            [\n                Rule(\"/\", endpoint=\"index\"),\n                Rule(\"/about\", endpoint=\"about\"),\n                Rule(\"/blog/\", endpoint=\"blog/index\"),\n                Rule(\"/blog/<int:post_id>\", endpoint=\"blog/show\"),\n            ],\n        ),\n    ]\n)\n", "examples/i18nurls/views.py": "from .application import expose\nfrom .application import Response\nfrom .application import TemplateResponse\n\n\n@expose(\"index\")\ndef index(req):\n    return TemplateResponse(\"index.html\", title=\"Index\")\n\n\n@expose(\"about\")\ndef about(req):\n    return TemplateResponse(\"about.html\", title=\"About\")\n\n\n@expose(\"blog/index\")\ndef blog_index(req):\n    return TemplateResponse(\"blog.html\", title=\"Blog Index\", mode=\"index\")\n\n\n@expose(\"blog/show\")\ndef blog_show(req, post_id):\n    return TemplateResponse(\n        \"blog.html\", title=f\"Blog Post #{post_id}\", post_id=post_id, mode=\"show\"\n    )\n\n\ndef page_not_found(req):\n    return Response(\"<h1>Page Not Found</h1>\", mimetype=\"text/html\")\n", "examples/i18nurls/application.py": "from os import path\n\nfrom jinja2 import Environment\nfrom jinja2 import PackageLoader\nfrom werkzeug.exceptions import HTTPException\nfrom werkzeug.exceptions import NotFound\nfrom werkzeug.routing import RequestRedirect\nfrom werkzeug.wrappers import Request as BaseRequest\nfrom werkzeug.wrappers import Response as BaseResponse\n\nfrom .urls import map\n\nTEMPLATES = path.join(path.dirname(__file__), \"templates\")\nviews = {}\n\n\ndef expose(name):\n    \"\"\"Register the function as view.\"\"\"\n\n    def wrapped(f):\n        views[name] = f\n        return f\n\n    return wrapped\n\n\nclass Request(BaseRequest):\n    def __init__(self, environ, urls):\n        super().__init__(environ)\n        self.urls = urls\n        self.matched_url = None\n\n    def url_for(self, endpoint, **args):\n        if \"lang_code\" not in args:\n            args[\"lang_code\"] = self.language\n        if endpoint == \"this\":\n            endpoint = self.matched_url[0]\n            tmp = self.matched_url[1].copy()\n            tmp.update(args)\n            args = tmp\n        return self.urls.build(endpoint, args)\n\n\nclass Response(BaseResponse):\n    pass\n\n\nclass TemplateResponse(Response):\n    jinja_env = Environment(loader=PackageLoader(\"i18nurls\"), autoescape=True)\n\n    def __init__(self, template_name, **values):\n        self.template_name = template_name\n        self.template_values = values\n        Response.__init__(self, mimetype=\"text/html\")\n\n    def __call__(self, environ, start_response):\n        req = environ[\"werkzeug.request\"]\n        values = self.template_values.copy()\n        values[\"req\"] = req\n        self.data = self.render_template(self.template_name, values)\n        return super().__call__(environ, start_response)\n\n    def render_template(self, name, values):\n        template = self.jinja_env.get_template(name)\n        return template.render(values)\n\n\nclass Application:\n    def __init__(self):\n        from i18nurls import views\n\n        self.not_found = views.page_not_found\n\n    def __call__(self, environ, start_response):\n        urls = map.bind_to_environ(environ)\n        req = Request(environ, urls)\n        try:\n            endpoint, args = urls.match(req.path)\n            req.matched_url = (endpoint, args)\n            if endpoint == \"#language_select\":\n                lng = req.accept_languages.best\n                lng = lng.split(\"-\")[0].lower() if lng else \"en\"\n                index_url = urls.build(\"index\", {\"lang_code\": lng})\n                resp = Response(f\"Moved to {index_url}\", status=302)\n                resp.headers[\"Location\"] = index_url\n            else:\n                req.language = args.pop(\"lang_code\", None)\n                resp = views[endpoint](req, **args)\n        except NotFound:\n            resp = self.not_found(req)\n        except (RequestRedirect, HTTPException) as e:\n            resp = e\n        return resp(environ, start_response)\n", "examples/i18nurls/__init__.py": "from .application import Application as make_app\n", "examples/shortly/shortly.py": "\"\"\"A simple URL shortener using Werkzeug and redis.\"\"\"\nimport os\nfrom urllib.parse import urlsplit\n\nimport redis\nfrom jinja2 import Environment\nfrom jinja2 import FileSystemLoader\nfrom werkzeug.exceptions import HTTPException\nfrom werkzeug.exceptions import NotFound\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.routing import Map\nfrom werkzeug.routing import Rule\nfrom werkzeug.utils import redirect\nfrom werkzeug.wrappers import Request\nfrom werkzeug.wrappers import Response\n\n\ndef base36_encode(number):\n    assert number >= 0, \"positive integer required\"\n    if number == 0:\n        return \"0\"\n    base36 = []\n    while number != 0:\n        number, i = divmod(number, 36)\n        base36.append(\"0123456789abcdefghijklmnopqrstuvwxyz\"[i])\n    return \"\".join(reversed(base36))\n\n\ndef is_valid_url(url):\n    parts = urlsplit(url)\n    return parts.scheme in (\"http\", \"https\")\n\n\ndef get_hostname(url):\n    return urlsplit(url).netloc\n\n\nclass Shortly:\n    def __init__(self, config):\n        self.redis = redis.Redis(\n            config[\"redis_host\"], config[\"redis_port\"], decode_responses=True\n        )\n        template_path = os.path.join(os.path.dirname(__file__), \"templates\")\n        self.jinja_env = Environment(\n            loader=FileSystemLoader(template_path), autoescape=True\n        )\n        self.jinja_env.filters[\"hostname\"] = get_hostname\n\n        self.url_map = Map(\n            [\n                Rule(\"/\", endpoint=\"new_url\"),\n                Rule(\"/<short_id>\", endpoint=\"follow_short_link\"),\n                Rule(\"/<short_id>+\", endpoint=\"short_link_details\"),\n            ]\n        )\n\n    def on_new_url(self, request):\n        error = None\n        url = \"\"\n        if request.method == \"POST\":\n            url = request.form[\"url\"]\n            if not is_valid_url(url):\n                error = \"Please enter a valid URL\"\n            else:\n                short_id = self.insert_url(url)\n                return redirect(f\"/{short_id}+\")\n        return self.render_template(\"new_url.html\", error=error, url=url)\n\n    def on_follow_short_link(self, request, short_id):\n        link_target = self.redis.get(f\"url-target:{short_id}\")\n        if link_target is None:\n            raise NotFound()\n        self.redis.incr(f\"click-count:{short_id}\")\n        return redirect(link_target)\n\n    def on_short_link_details(self, request, short_id):\n        link_target = self.redis.get(f\"url-target:{short_id}\")\n        if link_target is None:\n            raise NotFound()\n        click_count = int(self.redis.get(f\"click-count:{short_id}\") or 0)\n        return self.render_template(\n            \"short_link_details.html\",\n            link_target=link_target,\n            short_id=short_id,\n            click_count=click_count,\n        )\n\n    def error_404(self):\n        response = self.render_template(\"404.html\")\n        response.status_code = 404\n        return response\n\n    def insert_url(self, url):\n        short_id = self.redis.get(f\"reverse-url:{url}\")\n        if short_id is not None:\n            return short_id\n        url_num = self.redis.incr(\"last-url-id\")\n        short_id = base36_encode(url_num)\n        self.redis.set(f\"url-target:{short_id}\", url)\n        self.redis.set(f\"reverse-url:{url}\", short_id)\n        return short_id\n\n    def render_template(self, template_name, **context):\n        t = self.jinja_env.get_template(template_name)\n        return Response(t.render(context), mimetype=\"text/html\")\n\n    def dispatch_request(self, request):\n        adapter = self.url_map.bind_to_environ(request.environ)\n        try:\n            endpoint, values = adapter.match()\n            return getattr(self, f\"on_{endpoint}\")(request, **values)\n        except NotFound:\n            return self.error_404()\n        except HTTPException as e:\n            return e\n\n    def wsgi_app(self, environ, start_response):\n        request = Request(environ)\n        response = self.dispatch_request(request)\n        return response(environ, start_response)\n\n    def __call__(self, environ, start_response):\n        return self.wsgi_app(environ, start_response)\n\n\ndef create_app(redis_host=\"localhost\", redis_port=6379, with_static=True):\n    app = Shortly({\"redis_host\": redis_host, \"redis_port\": redis_port})\n    if with_static:\n        app.wsgi_app = SharedDataMiddleware(\n            app.wsgi_app, {\"/static\": os.path.join(os.path.dirname(__file__), \"static\")}\n        )\n    return app\n\n\nif __name__ == \"__main__\":\n    from werkzeug.serving import run_simple\n\n    app = create_app()\n    run_simple(\"127.0.0.1\", 5000, app, use_debugger=True, use_reloader=True)\n", "examples/coolmagic/utils.py": "\"\"\"Subclasses of the base request and response objects provided by\nwerkzeug. The subclasses know about their charset and implement some\nadditional functionality like the ability to link to view functions.\n\"\"\"\nfrom os.path import dirname\nfrom os.path import join\n\nfrom jinja2 import Environment\nfrom jinja2 import FileSystemLoader\nfrom werkzeug.local import Local\nfrom werkzeug.local import LocalManager\nfrom werkzeug.wrappers import Request as BaseRequest\nfrom werkzeug.wrappers import Response as BaseResponse\n\n\nlocal = Local()\nlocal_manager = LocalManager([local])\ntemplate_env = Environment(\n    loader=FileSystemLoader(join(dirname(__file__), \"templates\"))\n)\nexported_views = {}\n\n\ndef export(string, template=None, **extra):\n    \"\"\"\n    Decorator for registering view functions and adding\n    templates to it.\n    \"\"\"\n\n    def wrapped(f):\n        endpoint = f\"{f.__module__}.{f.__name__}\"[16:]\n        if template is not None:\n            old_f = f\n\n            def f(**kwargs):\n                rv = old_f(**kwargs)\n                if not isinstance(rv, Response):\n                    rv = TemplateResponse(template, **(rv or {}))\n                return rv\n\n            f.__name__ = old_f.__name__\n            f.__doc__ = old_f.__doc__\n        exported_views[endpoint] = (f, string, extra)\n        return f\n\n    return wrapped\n\n\ndef url_for(endpoint, **values):\n    \"\"\"\n    Build a URL\n    \"\"\"\n    return local.request.url_adapter.build(endpoint, values)\n\n\nclass Request(BaseRequest):\n    \"\"\"\n    The concrete request object used in the WSGI application.\n    It has some helper functions that can be used to build URLs.\n    \"\"\"\n\n    charset = \"utf-8\"\n\n    def __init__(self, environ, url_adapter):\n        super().__init__(environ)\n        self.url_adapter = url_adapter\n        local.request = self\n\n\nclass ThreadedRequest:\n    \"\"\"\n    A pseudo request object that always points to the current\n    context active request.\n    \"\"\"\n\n    def __getattr__(self, name):\n        if name == \"__members__\":\n            return [x for x in dir(local.request) if not x.startswith(\"_\")]\n        return getattr(local.request, name)\n\n    def __setattr__(self, name, value):\n        return setattr(local.request, name, value)\n\n\nclass Response(BaseResponse):\n    \"\"\"\n    The concrete response object for the WSGI application.\n    \"\"\"\n\n    charset = \"utf-8\"\n    default_mimetype = \"text/html\"\n\n\nclass TemplateResponse(Response):\n    \"\"\"\n    Render a template to a response.\n    \"\"\"\n\n    def __init__(self, template_name, **values):\n        from coolmagic import helpers\n\n        values.update(request=local.request, h=helpers)\n        template = template_env.get_template(template_name)\n        Response.__init__(self, template.render(values))\n", "examples/coolmagic/helpers.py": "from .utils import ThreadedRequest\n\n#: a thread local proxy request object\nrequest = ThreadedRequest()\ndel ThreadedRequest\n", "examples/coolmagic/application.py": "\"\"\"This module provides the WSGI application.\n\nThe WSGI middlewares are applied in the `make_app` factory function that\nautomatically wraps the application within the require middlewares. Per\ndefault only the `SharedDataMiddleware` is applied.\n\"\"\"\nfrom os import listdir\nfrom os import path\n\nfrom werkzeug.exceptions import HTTPException\nfrom werkzeug.exceptions import NotFound\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.routing import Map\nfrom werkzeug.routing import RequestRedirect\nfrom werkzeug.routing import Rule\n\nfrom .utils import local_manager\nfrom .utils import Request\n\n\nclass CoolMagicApplication:\n    \"\"\"\n    The application class. It's passed a directory with configuration values.\n    \"\"\"\n\n    def __init__(self, config):\n        self.config = config\n\n        for fn in listdir(path.join(path.dirname(__file__), \"views\")):\n            if fn.endswith(\".py\") and fn != \"__init__.py\":\n                __import__(f\"coolmagic.views.{fn[:-3]}\")\n\n        from coolmagic.utils import exported_views\n\n        rules = [\n            # url for shared data. this will always be unmatched\n            # because either the middleware or the webserver\n            # handles that request first.\n            Rule(\"/public/<path:file>\", endpoint=\"shared_data\")\n        ]\n        self.views = {}\n        for endpoint, (func, rule, extra) in exported_views.items():\n            if rule is not None:\n                rules.append(Rule(rule, endpoint=endpoint, **extra))\n            self.views[endpoint] = func\n        self.url_map = Map(rules)\n\n    def __call__(self, environ, start_response):\n        urls = self.url_map.bind_to_environ(environ)\n        req = Request(environ, urls)\n        try:\n            endpoint, args = urls.match(req.path)\n            resp = self.views[endpoint](**args)\n        except NotFound:\n            resp = self.views[\"static.not_found\"]()\n        except (HTTPException, RequestRedirect) as e:\n            resp = e\n        return resp(environ, start_response)\n\n\ndef make_app(config=None):\n    \"\"\"\n    Factory function that creates a new `CoolmagicApplication`\n    object. Optional WSGI middlewares should be applied here.\n    \"\"\"\n    config = config or {}\n    app = CoolMagicApplication(config)\n\n    # static stuff\n    app = SharedDataMiddleware(\n        app, {\"/public\": path.join(path.dirname(__file__), \"public\")}\n    )\n\n    # clean up locals\n    app = local_manager.make_middleware(app)\n\n    return app\n", "examples/coolmagic/__init__.py": "from .application import make_app\n", "examples/coolmagic/views/static.py": "from coolmagic.utils import export\n\n\n@export(\"/\", template=\"static/index.html\")\ndef index():\n    pass\n\n\n@export(\"/about\", template=\"static/about.html\")\ndef about():\n    pass\n\n\n@export(\"/broken\")\ndef broken():\n    raise RuntimeError(\"that's really broken\")\n\n\n@export(None, template=\"static/not_found.html\")\ndef not_found():\n    \"\"\"\n    This function is always executed if an url does not\n    match or a `NotFound` exception is raised.\n    \"\"\"\n    pass\n", "examples/coolmagic/views/__init__.py": ""}