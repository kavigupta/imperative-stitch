{"src/werkzeug/serving.py": "\"\"\"A WSGI and HTTP server for use **during development only**. This\nserver is convenient to use, but is not designed to be particularly\nstable, secure, or efficient. Use a dedicate WSGI server and HTTP\nserver when deploying to production.\n\nIt provides features like interactive debugging and code reloading. Use\n``run_simple`` to start the server. Put this in a ``run.py`` script:\n\n.. code-block:: python\n\n    from myapp import create_app\n    from werkzeug import run_simple\n\"\"\"\n\nfrom __future__ import annotations\n\nimport errno\nimport io\nimport os\nimport selectors\nimport socket\nimport socketserver\nimport sys\nimport typing as t\nfrom datetime import datetime as dt\nfrom datetime import timedelta\nfrom datetime import timezone\nfrom http.server import BaseHTTPRequestHandler\nfrom http.server import HTTPServer\nfrom urllib.parse import unquote\nfrom urllib.parse import urlsplit\n\nfrom ._internal import _log\nfrom ._internal import _wsgi_encoding_dance\nfrom .exceptions import InternalServerError\nfrom .urls import uri_to_iri\n\ntry:\n    import ssl\nexcept ImportError:\n\n    class _SslDummy:\n        def __getattr__(self, name: str) -> t.Any:\n            raise RuntimeError(  # noqa: B904\n                \"SSL is unavailable because this Python runtime was not\"\n                \" compiled with SSL/TLS support.\"\n            )\n\n    ssl = _SslDummy()  # type: ignore\n\n_log_add_style = True\n\nif os.name == \"nt\":\n    try:\n        __import__(\"colorama\")\n    except ImportError:\n        _log_add_style = False\n\ncan_fork = hasattr(os, \"fork\")\n\nif can_fork:\n    ForkingMixIn = socketserver.ForkingMixIn\nelse:\n\n    class ForkingMixIn:  # type: ignore\n        pass\n\n\ntry:\n    af_unix = socket.AF_UNIX\nexcept AttributeError:\n    af_unix = None  # type: ignore\n\nLISTEN_QUEUE = 128\n\n_TSSLContextArg = t.Optional[\n    t.Union[\"ssl.SSLContext\", t.Tuple[str, t.Optional[str]], t.Literal[\"adhoc\"]]\n]\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n    from cryptography.hazmat.primitives.asymmetric.rsa import (\n        RSAPrivateKeyWithSerialization,\n    )\n    from cryptography.x509 import Certificate\n\n\nclass DechunkedInput(io.RawIOBase):\n    \"\"\"An input stream that handles Transfer-Encoding 'chunked'\"\"\"\n\n    def __init__(self, rfile: t.IO[bytes]) -> None:\n        self._rfile = rfile\n        self._done = False\n        self._len = 0\n\n    def readable(self) -> bool:\n        return True\n\n    def read_chunk_len(self) -> int:\n        try:\n            line = self._rfile.readline().decode(\"latin1\")\n            _len = int(line.strip(), 16)\n        except ValueError as e:\n            raise OSError(\"Invalid chunk header\") from e\n        if _len < 0:\n            raise OSError(\"Negative chunk length not allowed\")\n        return _len\n\n    def readinto(self, buf: bytearray) -> int:  # type: ignore\n        read = 0\n        while not self._done and read < len(buf):\n            if self._len == 0:\n                # This is the first chunk or we fully consumed the previous\n                # one. Read the next length of the next chunk\n                self._len = self.read_chunk_len()\n\n            if self._len == 0:\n                # Found the final chunk of size 0. The stream is now exhausted,\n                # but there is still a final newline that should be consumed\n                self._done = True\n\n            if self._len > 0:\n                # There is data (left) in this chunk, so append it to the\n                # buffer. If this operation fully consumes the chunk, this will\n                # reset self._len to 0.\n                n = min(len(buf), self._len)\n\n                # If (read + chunk size) becomes more than len(buf), buf will\n                # grow beyond the original size and read more data than\n                # required. So only read as much data as can fit in buf.\n                if read + n > len(buf):\n                    buf[read:] = self._rfile.read(len(buf) - read)\n                    self._len -= len(buf) - read\n                    read = len(buf)\n                else:\n                    buf[read : read + n] = self._rfile.read(n)\n                    self._len -= n\n                    read += n\n\n            if self._len == 0:\n                # Skip the terminating newline of a chunk that has been fully\n                # consumed. This also applies to the 0-sized final chunk\n                terminator = self._rfile.readline()\n                if terminator not in (b\"\\n\", b\"\\r\\n\", b\"\\r\"):\n                    raise OSError(\"Missing chunk terminating newline\")\n\n        return read\n\n\nclass WSGIRequestHandler(BaseHTTPRequestHandler):\n    \"\"\"A request handler that implements WSGI dispatching.\"\"\"\n\n    server: BaseWSGIServer\n\n    @property\n    def server_version(self) -> str:  # type: ignore\n        return self.server._server_version\n\n    def make_environ(self) -> WSGIEnvironment:\n        request_url = urlsplit(self.path)\n        url_scheme = \"http\" if self.server.ssl_context is None else \"https\"\n\n        if not self.client_address:\n            self.client_address = (\"<local>\", 0)\n        elif isinstance(self.client_address, str):\n            self.client_address = (self.client_address, 0)\n\n        # If there was no scheme but the path started with two slashes,\n        # the first segment may have been incorrectly parsed as the\n        # netloc, prepend it to the path again.\n        if not request_url.scheme and request_url.netloc:\n            path_info = f\"/{request_url.netloc}{request_url.path}\"\n        else:\n            path_info = request_url.path\n\n        path_info = unquote(path_info)\n\n        environ: WSGIEnvironment = {\n            \"wsgi.version\": (1, 0),\n            \"wsgi.url_scheme\": url_scheme,\n            \"wsgi.input\": self.rfile,\n            \"wsgi.errors\": sys.stderr,\n            \"wsgi.multithread\": self.server.multithread,\n            \"wsgi.multiprocess\": self.server.multiprocess,\n            \"wsgi.run_once\": False,\n            \"werkzeug.socket\": self.connection,\n            \"SERVER_SOFTWARE\": self.server_version,\n            \"REQUEST_METHOD\": self.command,\n            \"SCRIPT_NAME\": \"\",\n            \"PATH_INFO\": _wsgi_encoding_dance(path_info),\n            \"QUERY_STRING\": _wsgi_encoding_dance(request_url.query),\n            # Non-standard, added by mod_wsgi, uWSGI\n            \"REQUEST_URI\": _wsgi_encoding_dance(self.path),\n            # Non-standard, added by gunicorn\n            \"RAW_URI\": _wsgi_encoding_dance(self.path),\n            \"REMOTE_ADDR\": self.address_string(),\n            \"REMOTE_PORT\": self.port_integer(),\n            \"SERVER_NAME\": self.server.server_address[0],\n            \"SERVER_PORT\": str(self.server.server_address[1]),\n            \"SERVER_PROTOCOL\": self.request_version,\n        }\n\n        for key, value in self.headers.items():\n            if \"_\" in key:\n                continue\n\n            key = key.upper().replace(\"-\", \"_\")\n            value = value.replace(\"\\r\\n\", \"\")\n            if key not in (\"CONTENT_TYPE\", \"CONTENT_LENGTH\"):\n                key = f\"HTTP_{key}\"\n                if key in environ:\n                    value = f\"{environ[key]},{value}\"\n            environ[key] = value\n\n        if environ.get(\"HTTP_TRANSFER_ENCODING\", \"\").strip().lower() == \"chunked\":\n            environ[\"wsgi.input_terminated\"] = True\n            environ[\"wsgi.input\"] = DechunkedInput(environ[\"wsgi.input\"])\n\n        # Per RFC 2616, if the URL is absolute, use that as the host.\n        # We're using \"has a scheme\" to indicate an absolute URL.\n        if request_url.scheme and request_url.netloc:\n            environ[\"HTTP_HOST\"] = request_url.netloc\n\n        try:\n            # binary_form=False gives nicer information, but wouldn't be compatible with\n            # what Nginx or Apache could return.\n            peer_cert = self.connection.getpeercert(binary_form=True)\n            if peer_cert is not None:\n                # Nginx and Apache use PEM format.\n                environ[\"SSL_CLIENT_CERT\"] = ssl.DER_cert_to_PEM_cert(peer_cert)\n        except ValueError:\n            # SSL handshake hasn't finished.\n            self.server.log(\"error\", \"Cannot fetch SSL peer certificate info\")\n        except AttributeError:\n            # Not using TLS, the socket will not have getpeercert().\n            pass\n\n        return environ\n\n    def run_wsgi(self) -> None:\n        if self.headers.get(\"Expect\", \"\").lower().strip() == \"100-continue\":\n            self.wfile.write(b\"HTTP/1.1 100 Continue\\r\\n\\r\\n\")\n\n        self.environ = environ = self.make_environ()\n        status_set: str | None = None\n        headers_set: list[tuple[str, str]] | None = None\n        status_sent: str | None = None\n        headers_sent: list[tuple[str, str]] | None = None\n        chunk_response: bool = False\n\n        def write(data: bytes) -> None:\n            nonlocal status_sent, headers_sent, chunk_response\n            assert status_set is not None, \"write() before start_response\"\n            assert headers_set is not None, \"write() before start_response\"\n            if status_sent is None:\n                status_sent = status_set\n                headers_sent = headers_set\n                try:\n                    code_str, msg = status_sent.split(None, 1)\n                except ValueError:\n                    code_str, msg = status_sent, \"\"\n                code = int(code_str)\n                self.send_response(code, msg)\n                header_keys = set()\n                for key, value in headers_sent:\n                    self.send_header(key, value)\n                    header_keys.add(key.lower())\n\n                # Use chunked transfer encoding if there is no content\n                # length. Do not use for 1xx and 204 responses. 304\n                # responses and HEAD requests are also excluded, which\n                # is the more conservative behavior and matches other\n                # parts of the code.\n                # https://httpwg.org/specs/rfc7230.html#rfc.section.3.3.1\n                if (\n                    not (\n                        \"content-length\" in header_keys\n                        or environ[\"REQUEST_METHOD\"] == \"HEAD\"\n                        or (100 <= code < 200)\n                        or code in {204, 304}\n                    )\n                    and self.protocol_version >= \"HTTP/1.1\"\n                ):\n                    chunk_response = True\n                    self.send_header(\"Transfer-Encoding\", \"chunked\")\n\n                # Always close the connection. This disables HTTP/1.1\n                # keep-alive connections. They aren't handled well by\n                # Python's http.server because it doesn't know how to\n                # drain the stream before the next request line.\n                self.send_header(\"Connection\", \"close\")\n                self.end_headers()\n\n            assert isinstance(data, bytes), \"applications must write bytes\"\n\n            if data:\n                if chunk_response:\n                    self.wfile.write(hex(len(data))[2:].encode())\n                    self.wfile.write(b\"\\r\\n\")\n\n                self.wfile.write(data)\n\n                if chunk_response:\n                    self.wfile.write(b\"\\r\\n\")\n\n            self.wfile.flush()\n\n        def start_response(status, headers, exc_info=None):  # type: ignore\n            nonlocal status_set, headers_set\n            if exc_info:\n                try:\n                    if headers_sent:\n                        raise exc_info[1].with_traceback(exc_info[2])\n                finally:\n                    exc_info = None\n            elif headers_set:\n                raise AssertionError(\"Headers already set\")\n            status_set = status\n            headers_set = headers\n            return write\n\n        def execute(app: WSGIApplication) -> None:\n            application_iter = app(environ, start_response)\n            try:\n                for data in application_iter:\n                    write(data)\n                if not headers_sent:\n                    write(b\"\")\n                if chunk_response:\n                    self.wfile.write(b\"0\\r\\n\\r\\n\")\n            finally:\n                # Check for any remaining data in the read socket, and discard it. This\n                # will read past request.max_content_length, but lets the client see a\n                # 413 response instead of a connection reset failure. If we supported\n                # keep-alive connections, this naive approach would break by reading the\n                # next request line. Since we know that write (above) closes every\n                # connection we can read everything.\n                selector = selectors.DefaultSelector()\n                selector.register(self.connection, selectors.EVENT_READ)\n                total_size = 0\n                total_reads = 0\n\n                # A timeout of 0 tends to fail because a client needs a small amount of\n                # time to continue sending its data.\n                while selector.select(timeout=0.01):\n                    # Only read 10MB into memory at a time.\n                    data = self.rfile.read(10_000_000)\n                    total_size += len(data)\n                    total_reads += 1\n\n                    # Stop reading on no data, >=10GB, or 1000 reads. If a client sends\n                    # more than that, they'll get a connection reset failure.\n                    if not data or total_size >= 10_000_000_000 or total_reads > 1000:\n                        break\n\n                selector.close()\n\n                if hasattr(application_iter, \"close\"):\n                    application_iter.close()\n\n        try:\n            execute(self.server.app)\n        except (ConnectionError, socket.timeout) as e:\n            self.connection_dropped(e, environ)\n        except Exception as e:\n            if self.server.passthrough_errors:\n                raise\n\n            if status_sent is not None and chunk_response:\n                self.close_connection = True\n\n            try:\n                # if we haven't yet sent the headers but they are set\n                # we roll back to be able to set them again.\n                if status_sent is None:\n                    status_set = None\n                    headers_set = None\n                execute(InternalServerError())\n            except Exception:\n                pass\n\n            from .debug.tbtools import DebugTraceback\n\n            msg = DebugTraceback(e).render_traceback_text()\n            self.server.log(\"error\", f\"Error on request:\\n{msg}\")\n\n    def handle(self) -> None:\n        \"\"\"Handles a request ignoring dropped connections.\"\"\"\n        try:\n            super().handle()\n        except (ConnectionError, socket.timeout) as e:\n            self.connection_dropped(e)\n        except Exception as e:\n            if self.server.ssl_context is not None and is_ssl_error(e):\n                self.log_error(\"SSL error occurred: %s\", e)\n            else:\n                raise\n\n    def connection_dropped(\n        self, error: BaseException, environ: WSGIEnvironment | None = None\n    ) -> None:\n        \"\"\"Called if the connection was closed by the client.  By default\n        nothing happens.\n        \"\"\"\n\n    def __getattr__(self, name: str) -> t.Any:\n        # All HTTP methods are handled by run_wsgi.\n        if name.startswith(\"do_\"):\n            return self.run_wsgi\n\n        # All other attributes are forwarded to the base class.\n        return getattr(super(), name)\n\n    def address_string(self) -> str:\n        if getattr(self, \"environ\", None):\n            return self.environ[\"REMOTE_ADDR\"]  # type: ignore\n\n        if not self.client_address:\n            return \"<local>\"\n\n        return self.client_address[0]\n\n    def port_integer(self) -> int:\n        return self.client_address[1]\n\n    # Escape control characters. This is defined (but private) in Python 3.12.\n    _control_char_table = str.maketrans(\n        {c: rf\"\\x{c:02x}\" for c in [*range(0x20), *range(0x7F, 0xA0)]}\n    )\n    _control_char_table[ord(\"\\\\\")] = r\"\\\\\"\n\n    def log_request(self, code: int | str = \"-\", size: int | str = \"-\") -> None:\n        try:\n            path = uri_to_iri(self.path)\n            msg = f\"{self.command} {path} {self.request_version}\"\n        except AttributeError:\n            # path isn't set if the requestline was bad\n            msg = self.requestline\n\n        # Escape control characters that may be in the decoded path.\n        msg = msg.translate(self._control_char_table)\n        code = str(code)\n\n        if code[0] == \"1\":  # 1xx - Informational\n            msg = _ansi_style(msg, \"bold\")\n        elif code == \"200\":  # 2xx - Success\n            pass\n        elif code == \"304\":  # 304 - Resource Not Modified\n            msg = _ansi_style(msg, \"cyan\")\n        elif code[0] == \"3\":  # 3xx - Redirection\n            msg = _ansi_style(msg, \"green\")\n        elif code == \"404\":  # 404 - Resource Not Found\n            msg = _ansi_style(msg, \"yellow\")\n        elif code[0] == \"4\":  # 4xx - Client Error\n            msg = _ansi_style(msg, \"bold\", \"red\")\n        else:  # 5xx, or any other response\n            msg = _ansi_style(msg, \"bold\", \"magenta\")\n\n        self.log(\"info\", '\"%s\" %s %s', msg, code, size)\n\n    def log_error(self, format: str, *args: t.Any) -> None:\n        self.log(\"error\", format, *args)\n\n    def log_message(self, format: str, *args: t.Any) -> None:\n        self.log(\"info\", format, *args)\n\n    def log(self, type: str, message: str, *args: t.Any) -> None:\n        _log(\n            type,\n            f\"{self.address_string()} - - [{self.log_date_time_string()}] {message}\\n\",\n            *args,\n        )\n\n\ndef _ansi_style(value: str, *styles: str) -> str:\n    if not _log_add_style:\n        return value\n\n    codes = {\n        \"bold\": 1,\n        \"red\": 31,\n        \"green\": 32,\n        \"yellow\": 33,\n        \"magenta\": 35,\n        \"cyan\": 36,\n    }\n\n    for style in styles:\n        value = f\"\\x1b[{codes[style]}m{value}\"\n\n    return f\"{value}\\x1b[0m\"\n\n\ndef generate_adhoc_ssl_pair(\n    cn: str | None = None,\n) -> tuple[Certificate, RSAPrivateKeyWithSerialization]:\n    try:\n        from cryptography import x509\n        from cryptography.hazmat.backends import default_backend\n        from cryptography.hazmat.primitives import hashes\n        from cryptography.hazmat.primitives.asymmetric import rsa\n        from cryptography.x509.oid import NameOID\n    except ImportError:\n        raise TypeError(\n            \"Using ad-hoc certificates requires the cryptography library.\"\n        ) from None\n\n    backend = default_backend()\n    pkey = rsa.generate_private_key(\n        public_exponent=65537, key_size=2048, backend=backend\n    )\n\n    # pretty damn sure that this is not actually accepted by anyone\n    if cn is None:\n        cn = \"*\"\n\n    subject = x509.Name(\n        [\n            x509.NameAttribute(NameOID.ORGANIZATION_NAME, \"Dummy Certificate\"),\n            x509.NameAttribute(NameOID.COMMON_NAME, cn),\n        ]\n    )\n\n    backend = default_backend()\n    cert = (\n        x509.CertificateBuilder()\n        .subject_name(subject)\n        .issuer_name(subject)\n        .public_key(pkey.public_key())\n        .serial_number(x509.random_serial_number())\n        .not_valid_before(dt.now(timezone.utc))\n        .not_valid_after(dt.now(timezone.utc) + timedelta(days=365))\n        .add_extension(x509.ExtendedKeyUsage([x509.OID_SERVER_AUTH]), critical=False)\n        .add_extension(\n            x509.SubjectAlternativeName([x509.DNSName(cn), x509.DNSName(f\"*.{cn}\")]),\n            critical=False,\n        )\n        .sign(pkey, hashes.SHA256(), backend)\n    )\n    return cert, pkey\n\n\ndef make_ssl_devcert(\n    base_path: str, host: str | None = None, cn: str | None = None\n) -> tuple[str, str]:\n    \"\"\"Creates an SSL key for development.  This should be used instead of\n    the ``'adhoc'`` key which generates a new cert on each server start.\n    It accepts a path for where it should store the key and cert and\n    either a host or CN.  If a host is given it will use the CN\n    ``*.host/CN=host``.\n\n    For more information see :func:`run_simple`.\n\n    .. versionadded:: 0.9\n\n    :param base_path: the path to the certificate and key.  The extension\n                      ``.crt`` is added for the certificate, ``.key`` is\n                      added for the key.\n    :param host: the name of the host.  This can be used as an alternative\n                 for the `cn`.\n    :param cn: the `CN` to use.\n    \"\"\"\n\n    if host is not None:\n        cn = host\n    cert, pkey = generate_adhoc_ssl_pair(cn=cn)\n\n    from cryptography.hazmat.primitives import serialization\n\n    cert_file = f\"{base_path}.crt\"\n    pkey_file = f\"{base_path}.key\"\n\n    with open(cert_file, \"wb\") as f:\n        f.write(cert.public_bytes(serialization.Encoding.PEM))\n    with open(pkey_file, \"wb\") as f:\n        f.write(\n            pkey.private_bytes(\n                encoding=serialization.Encoding.PEM,\n                format=serialization.PrivateFormat.TraditionalOpenSSL,\n                encryption_algorithm=serialization.NoEncryption(),\n            )\n        )\n\n    return cert_file, pkey_file\n\n\ndef generate_adhoc_ssl_context() -> ssl.SSLContext:\n    \"\"\"Generates an adhoc SSL context for the development server.\"\"\"\n    import atexit\n    import tempfile\n\n    cert, pkey = generate_adhoc_ssl_pair()\n\n    from cryptography.hazmat.primitives import serialization\n\n    cert_handle, cert_file = tempfile.mkstemp()\n    pkey_handle, pkey_file = tempfile.mkstemp()\n    atexit.register(os.remove, pkey_file)\n    atexit.register(os.remove, cert_file)\n\n    os.write(cert_handle, cert.public_bytes(serialization.Encoding.PEM))\n    os.write(\n        pkey_handle,\n        pkey.private_bytes(\n            encoding=serialization.Encoding.PEM,\n            format=serialization.PrivateFormat.TraditionalOpenSSL,\n            encryption_algorithm=serialization.NoEncryption(),\n        ),\n    )\n\n    os.close(cert_handle)\n    os.close(pkey_handle)\n    ctx = load_ssl_context(cert_file, pkey_file)\n    return ctx\n\n\ndef load_ssl_context(\n    cert_file: str, pkey_file: str | None = None, protocol: int | None = None\n) -> ssl.SSLContext:\n    \"\"\"Loads SSL context from cert/private key files and optional protocol.\n    Many parameters are directly taken from the API of\n    :py:class:`ssl.SSLContext`.\n\n    :param cert_file: Path of the certificate to use.\n    :param pkey_file: Path of the private key to use. If not given, the key\n                      will be obtained from the certificate file.\n    :param protocol: A ``PROTOCOL`` constant from the :mod:`ssl` module.\n        Defaults to :data:`ssl.PROTOCOL_TLS_SERVER`.\n    \"\"\"\n    if protocol is None:\n        protocol = ssl.PROTOCOL_TLS_SERVER\n\n    ctx = ssl.SSLContext(protocol)\n    ctx.load_cert_chain(cert_file, pkey_file)\n    return ctx\n\n\ndef is_ssl_error(error: Exception | None = None) -> bool:\n    \"\"\"Checks if the given error (or the current one) is an SSL error.\"\"\"\n    if error is None:\n        error = t.cast(Exception, sys.exc_info()[1])\n    return isinstance(error, ssl.SSLError)\n\n\ndef select_address_family(host: str, port: int) -> socket.AddressFamily:\n    \"\"\"Return ``AF_INET4``, ``AF_INET6``, or ``AF_UNIX`` depending on\n    the host and port.\"\"\"\n    if host.startswith(\"unix://\"):\n        return socket.AF_UNIX\n    elif \":\" in host and hasattr(socket, \"AF_INET6\"):\n        return socket.AF_INET6\n    return socket.AF_INET\n\n\ndef get_sockaddr(\n    host: str, port: int, family: socket.AddressFamily\n) -> tuple[str, int] | str:\n    \"\"\"Return a fully qualified socket address that can be passed to\n    :func:`socket.bind`.\"\"\"\n    if family == af_unix:\n        # Absolute path avoids IDNA encoding error when path starts with dot.\n        return os.path.abspath(host.partition(\"://\")[2])\n    try:\n        res = socket.getaddrinfo(\n            host, port, family, socket.SOCK_STREAM, socket.IPPROTO_TCP\n        )\n    except socket.gaierror:\n        return host, port\n    return res[0][4]  # type: ignore\n\n\ndef get_interface_ip(family: socket.AddressFamily) -> str:\n    \"\"\"Get the IP address of an external interface. Used when binding to\n    0.0.0.0 or ::1 to show a more useful URL.\n\n    :meta private:\n    \"\"\"\n    # arbitrary private address\n    host = \"fd31:f903:5ab5:1::1\" if family == socket.AF_INET6 else \"10.253.155.219\"\n\n    with socket.socket(family, socket.SOCK_DGRAM) as s:\n        try:\n            s.connect((host, 58162))\n        except OSError:\n            return \"::1\" if family == socket.AF_INET6 else \"127.0.0.1\"\n\n        return s.getsockname()[0]  # type: ignore\n\n\nclass BaseWSGIServer(HTTPServer):\n    \"\"\"A WSGI server that that handles one request at a time.\n\n    Use :func:`make_server` to create a server instance.\n    \"\"\"\n\n    multithread = False\n    multiprocess = False\n    request_queue_size = LISTEN_QUEUE\n    allow_reuse_address = True\n\n    def __init__(\n        self,\n        host: str,\n        port: int,\n        app: WSGIApplication,\n        handler: type[WSGIRequestHandler] | None = None,\n        passthrough_errors: bool = False,\n        ssl_context: _TSSLContextArg | None = None,\n        fd: int | None = None,\n    ) -> None:\n        if handler is None:\n            handler = WSGIRequestHandler\n\n        # If the handler doesn't directly set a protocol version and\n        # thread or process workers are used, then allow chunked\n        # responses and keep-alive connections by enabling HTTP/1.1.\n        if \"protocol_version\" not in vars(handler) and (\n            self.multithread or self.multiprocess\n        ):\n            handler.protocol_version = \"HTTP/1.1\"\n\n        self.host = host\n        self.port = port\n        self.app = app\n        self.passthrough_errors = passthrough_errors\n\n        self.address_family = address_family = select_address_family(host, port)\n        server_address = get_sockaddr(host, int(port), address_family)\n\n        # Remove a leftover Unix socket file from a previous run. Don't\n        # remove a file that was set up by run_simple.\n        if address_family == af_unix and fd is None:\n            server_address = t.cast(str, server_address)\n\n            if os.path.exists(server_address):\n                os.unlink(server_address)\n\n        # Bind and activate will be handled manually, it should only\n        # happen if we're not using a socket that was already set up.\n        super().__init__(\n            server_address,  # type: ignore[arg-type]\n            handler,\n            bind_and_activate=False,\n        )\n\n        if fd is None:\n            # No existing socket descriptor, do bind_and_activate=True.\n            try:\n                self.server_bind()\n                self.server_activate()\n            except OSError as e:\n                # Catch connection issues and show them without the traceback. Show\n                # extra instructions for address not found, and for macOS.\n                self.server_close()\n                print(e.strerror, file=sys.stderr)\n\n                if e.errno == errno.EADDRINUSE:\n                    print(\n                        f\"Port {port} is in use by another program. Either identify and\"\n                        \" stop that program, or start the server with a different\"\n                        \" port.\",\n                        file=sys.stderr,\n                    )\n\n                    if sys.platform == \"darwin\" and port == 5000:\n                        print(\n                            \"On macOS, try disabling the 'AirPlay Receiver' service\"\n                            \" from System Preferences -> General -> AirDrop & Handoff.\",\n                            file=sys.stderr,\n                        )\n\n                sys.exit(1)\n            except BaseException:\n                self.server_close()\n                raise\n        else:\n            # TCPServer automatically opens a socket even if bind_and_activate is False.\n            # Close it to silence a ResourceWarning.\n            self.server_close()\n\n            # Use the passed in socket directly.\n            self.socket = socket.fromfd(fd, address_family, socket.SOCK_STREAM)\n            self.server_address = self.socket.getsockname()\n\n        if address_family != af_unix:\n            # If port was 0, this will record the bound port.\n            self.port = self.server_address[1]\n\n        if ssl_context is not None:\n            if isinstance(ssl_context, tuple):\n                ssl_context = load_ssl_context(*ssl_context)\n            elif ssl_context == \"adhoc\":\n                ssl_context = generate_adhoc_ssl_context()\n\n            self.socket = ssl_context.wrap_socket(self.socket, server_side=True)\n            self.ssl_context: ssl.SSLContext | None = ssl_context\n        else:\n            self.ssl_context = None\n\n        import importlib.metadata\n\n        self._server_version = f\"Werkzeug/{importlib.metadata.version('werkzeug')}\"\n\n    def log(self, type: str, message: str, *args: t.Any) -> None:\n        _log(type, message, *args)\n\n    def serve_forever(self, poll_interval: float = 0.5) -> None:\n        try:\n            super().serve_forever(poll_interval=poll_interval)\n        except KeyboardInterrupt:\n            pass\n        finally:\n            self.server_close()\n\n    def handle_error(\n        self, request: t.Any, client_address: tuple[str, int] | str\n    ) -> None:\n        if self.passthrough_errors:\n            raise\n\n        return super().handle_error(request, client_address)\n\n    def log_startup(self) -> None:\n        \"\"\"Show information about the address when starting the server.\"\"\"\n        dev_warning = (\n            \"WARNING: This is a development server. Do not use it in a production\"\n            \" deployment. Use a production WSGI server instead.\"\n        )\n        dev_warning = _ansi_style(dev_warning, \"bold\", \"red\")\n        messages = [dev_warning]\n\n        if self.address_family == af_unix:\n            messages.append(f\" * Running on {self.host}\")\n        else:\n            scheme = \"http\" if self.ssl_context is None else \"https\"\n            display_hostname = self.host\n\n            if self.host in {\"0.0.0.0\", \"::\"}:\n                messages.append(f\" * Running on all addresses ({self.host})\")\n\n                if self.host == \"0.0.0.0\":\n                    localhost = \"127.0.0.1\"\n                    display_hostname = get_interface_ip(socket.AF_INET)\n                else:\n                    localhost = \"[::1]\"\n                    display_hostname = get_interface_ip(socket.AF_INET6)\n\n                messages.append(f\" * Running on {scheme}://{localhost}:{self.port}\")\n\n            if \":\" in display_hostname:\n                display_hostname = f\"[{display_hostname}]\"\n\n            messages.append(f\" * Running on {scheme}://{display_hostname}:{self.port}\")\n\n        _log(\"info\", \"\\n\".join(messages))\n\n\nclass ThreadedWSGIServer(socketserver.ThreadingMixIn, BaseWSGIServer):\n    \"\"\"A WSGI server that handles concurrent requests in separate\n    threads.\n\n    Use :func:`make_server` to create a server instance.\n    \"\"\"\n\n    multithread = True\n    daemon_threads = True\n\n\nclass ForkingWSGIServer(ForkingMixIn, BaseWSGIServer):\n    \"\"\"A WSGI server that handles concurrent requests in separate forked\n    processes.\n\n    Use :func:`make_server` to create a server instance.\n    \"\"\"\n\n    multiprocess = True\n\n    def __init__(\n        self,\n        host: str,\n        port: int,\n        app: WSGIApplication,\n        processes: int = 40,\n        handler: type[WSGIRequestHandler] | None = None,\n        passthrough_errors: bool = False,\n        ssl_context: _TSSLContextArg | None = None,\n        fd: int | None = None,\n    ) -> None:\n        if not can_fork:\n            raise ValueError(\"Your platform does not support forking.\")\n\n        super().__init__(host, port, app, handler, passthrough_errors, ssl_context, fd)\n        self.max_children = processes\n\n\ndef make_server(\n    host: str,\n    port: int,\n    app: WSGIApplication,\n    threaded: bool = False,\n    processes: int = 1,\n    request_handler: type[WSGIRequestHandler] | None = None,\n    passthrough_errors: bool = False,\n    ssl_context: _TSSLContextArg | None = None,\n    fd: int | None = None,\n) -> BaseWSGIServer:\n    \"\"\"Create an appropriate WSGI server instance based on the value of\n    ``threaded`` and ``processes``.\n\n    This is called from :func:`run_simple`, but can be used separately\n    to have access to the server object, such as to run it in a separate\n    thread.\n\n    See :func:`run_simple` for parameter docs.\n    \"\"\"\n    if threaded and processes > 1:\n        raise ValueError(\"Cannot have a multi-thread and multi-process server.\")\n\n    if threaded:\n        return ThreadedWSGIServer(\n            host, port, app, request_handler, passthrough_errors, ssl_context, fd=fd\n        )\n\n    if processes > 1:\n        return ForkingWSGIServer(\n            host,\n            port,\n            app,\n            processes,\n            request_handler,\n            passthrough_errors,\n            ssl_context,\n            fd=fd,\n        )\n\n    return BaseWSGIServer(\n        host, port, app, request_handler, passthrough_errors, ssl_context, fd=fd\n    )\n\n\ndef is_running_from_reloader() -> bool:\n    \"\"\"Check if the server is running as a subprocess within the\n    Werkzeug reloader.\n\n    .. versionadded:: 0.10\n    \"\"\"\n    return os.environ.get(\"WERKZEUG_RUN_MAIN\") == \"true\"\n\n\ndef run_simple(\n    hostname: str,\n    port: int,\n    application: WSGIApplication,\n    use_reloader: bool = False,\n    use_debugger: bool = False,\n    use_evalex: bool = True,\n    extra_files: t.Iterable[str] | None = None,\n    exclude_patterns: t.Iterable[str] | None = None,\n    reloader_interval: int = 1,\n    reloader_type: str = \"auto\",\n    threaded: bool = False,\n    processes: int = 1,\n    request_handler: type[WSGIRequestHandler] | None = None,\n    static_files: dict[str, str | tuple[str, str]] | None = None,\n    passthrough_errors: bool = False,\n    ssl_context: _TSSLContextArg | None = None,\n) -> None:\n    \"\"\"Start a development server for a WSGI application. Various\n    optional features can be enabled.\n\n    .. warning::\n\n        Do not use the development server when deploying to production.\n        It is intended for use only during local development. It is not\n        designed to be particularly efficient, stable, or secure.\n\n    :param hostname: The host to bind to, for example ``'localhost'``.\n        Can be a domain, IPv4 or IPv6 address, or file path starting\n        with ``unix://`` for a Unix socket.\n    :param port: The port to bind to, for example ``8080``. Using ``0``\n        tells the OS to pick a random free port.\n    :param application: The WSGI application to run.\n    :param use_reloader: Use a reloader process to restart the server\n        process when files are changed.\n    :param use_debugger: Use Werkzeug's debugger, which will show\n        formatted tracebacks on unhandled exceptions.\n    :param use_evalex: Make the debugger interactive. A Python terminal\n        can be opened for any frame in the traceback. Some protection is\n        provided by requiring a PIN, but this should never be enabled\n        on a publicly visible server.\n    :param extra_files: The reloader will watch these files for changes\n        in addition to Python modules. For example, watch a\n        configuration file.\n    :param exclude_patterns: The reloader will ignore changes to any\n        files matching these :mod:`fnmatch` patterns. For example,\n        ignore cache files.\n    :param reloader_interval: How often the reloader tries to check for\n        changes.\n    :param reloader_type: The reloader to use. The ``'stat'`` reloader\n        is built in, but may require significant CPU to watch files. The\n        ``'watchdog'`` reloader is much more efficient but requires\n        installing the ``watchdog`` package first.\n    :param threaded: Handle concurrent requests using threads. Cannot be\n        used with ``processes``.\n    :param processes: Handle concurrent requests using up to this number\n        of processes. Cannot be used with ``threaded``.\n    :param request_handler: Use a different\n        :class:`~BaseHTTPServer.BaseHTTPRequestHandler` subclass to\n        handle requests.\n    :param static_files: A dict mapping URL prefixes to directories to\n        serve static files from using\n        :class:`~werkzeug.middleware.SharedDataMiddleware`.\n    :param passthrough_errors: Don't catch unhandled exceptions at the\n        server level, let the server crash instead. If ``use_debugger``\n        is enabled, the debugger will still catch such errors.\n    :param ssl_context: Configure TLS to serve over HTTPS. Can be an\n        :class:`ssl.SSLContext` object, a ``(cert_file, key_file)``\n        tuple to create a typical context, or the string ``'adhoc'`` to\n        generate a temporary self-signed certificate.\n\n    .. versionchanged:: 2.1\n        Instructions are shown for dealing with an \"address already in\n        use\" error.\n\n    .. versionchanged:: 2.1\n        Running on ``0.0.0.0`` or ``::`` shows the loopback IP in\n        addition to a real IP.\n\n    .. versionchanged:: 2.1\n        The command-line interface was removed.\n\n    .. versionchanged:: 2.0\n        Running on ``0.0.0.0`` or ``::`` shows a real IP address that\n        was bound as well as a warning not to run the development server\n        in production.\n\n    .. versionchanged:: 2.0\n        The ``exclude_patterns`` parameter was added.\n\n    .. versionchanged:: 0.15\n        Bind to a Unix socket by passing a ``hostname`` that starts with\n        ``unix://``.\n\n    .. versionchanged:: 0.10\n        Improved the reloader and added support for changing the backend\n        through the ``reloader_type`` parameter.\n\n    .. versionchanged:: 0.9\n        A command-line interface was added.\n\n    .. versionchanged:: 0.8\n        ``ssl_context`` can be a tuple of paths to the certificate and\n        private key files.\n\n    .. versionchanged:: 0.6\n        The ``ssl_context`` parameter was added.\n\n    .. versionchanged:: 0.5\n       The ``static_files`` and ``passthrough_errors`` parameters were\n       added.\n    \"\"\"\n    if not isinstance(port, int):\n        raise TypeError(\"port must be an integer\")\n\n    if static_files:\n        from .middleware.shared_data import SharedDataMiddleware\n\n        application = SharedDataMiddleware(application, static_files)\n\n    if use_debugger:\n        from .debug import DebuggedApplication\n\n        application = DebuggedApplication(application, evalex=use_evalex)\n        # Allow the specified hostname to use the debugger, in addition to\n        # localhost domains.\n        application.trusted_hosts.append(hostname)\n\n    if not is_running_from_reloader():\n        fd = None\n    else:\n        fd = int(os.environ[\"WERKZEUG_SERVER_FD\"])\n\n    srv = make_server(\n        hostname,\n        port,\n        application,\n        threaded,\n        processes,\n        request_handler,\n        passthrough_errors,\n        ssl_context,\n        fd=fd,\n    )\n    srv.socket.set_inheritable(True)\n    os.environ[\"WERKZEUG_SERVER_FD\"] = str(srv.fileno())\n\n    if not is_running_from_reloader():\n        srv.log_startup()\n        _log(\"info\", _ansi_style(\"Press CTRL+C to quit\", \"yellow\"))\n\n    if use_reloader:\n        from ._reloader import run_with_reloader\n\n        try:\n            run_with_reloader(\n                srv.serve_forever,\n                extra_files=extra_files,\n                exclude_patterns=exclude_patterns,\n                interval=reloader_interval,\n                reloader_type=reloader_type,\n            )\n        finally:\n            srv.server_close()\n    else:\n        srv.serve_forever()\n", "src/werkzeug/_reloader.py": "from __future__ import annotations\n\nimport fnmatch\nimport os\nimport subprocess\nimport sys\nimport threading\nimport time\nimport typing as t\nfrom itertools import chain\nfrom pathlib import PurePath\n\nfrom ._internal import _log\n\n# The various system prefixes where imports are found. Base values are\n# different when running in a virtualenv. All reloaders will ignore the\n# base paths (usually the system installation). The stat reloader won't\n# scan the virtualenv paths, it will only include modules that are\n# already imported.\n_ignore_always = tuple({sys.base_prefix, sys.base_exec_prefix})\nprefix = {*_ignore_always, sys.prefix, sys.exec_prefix}\n\nif hasattr(sys, \"real_prefix\"):\n    # virtualenv < 20\n    prefix.add(sys.real_prefix)\n\n_stat_ignore_scan = tuple(prefix)\ndel prefix\n_ignore_common_dirs = {\n    \"__pycache__\",\n    \".git\",\n    \".hg\",\n    \".tox\",\n    \".nox\",\n    \".pytest_cache\",\n    \".mypy_cache\",\n}\n\n\ndef _iter_module_paths() -> t.Iterator[str]:\n    \"\"\"Find the filesystem paths associated with imported modules.\"\"\"\n    # List is in case the value is modified by the app while updating.\n    for module in list(sys.modules.values()):\n        name = getattr(module, \"__file__\", None)\n\n        if name is None or name.startswith(_ignore_always):\n            continue\n\n        while not os.path.isfile(name):\n            # Zip file, find the base file without the module path.\n            old = name\n            name = os.path.dirname(name)\n\n            if name == old:  # skip if it was all directories somehow\n                break\n        else:\n            yield name\n\n\ndef _remove_by_pattern(paths: set[str], exclude_patterns: set[str]) -> None:\n    for pattern in exclude_patterns:\n        paths.difference_update(fnmatch.filter(paths, pattern))\n\n\ndef _find_stat_paths(\n    extra_files: set[str], exclude_patterns: set[str]\n) -> t.Iterable[str]:\n    \"\"\"Find paths for the stat reloader to watch. Returns imported\n    module files, Python files under non-system paths. Extra files and\n    Python files under extra directories can also be scanned.\n\n    System paths have to be excluded for efficiency. Non-system paths,\n    such as a project root or ``sys.path.insert``, should be the paths\n    of interest to the user anyway.\n    \"\"\"\n    paths = set()\n\n    for path in chain(list(sys.path), extra_files):\n        path = os.path.abspath(path)\n\n        if os.path.isfile(path):\n            # zip file on sys.path, or extra file\n            paths.add(path)\n            continue\n\n        parent_has_py = {os.path.dirname(path): True}\n\n        for root, dirs, files in os.walk(path):\n            # Optimizations: ignore system prefixes, __pycache__ will\n            # have a py or pyc module at the import path, ignore some\n            # common known dirs such as version control and tool caches.\n            if (\n                root.startswith(_stat_ignore_scan)\n                or os.path.basename(root) in _ignore_common_dirs\n            ):\n                dirs.clear()\n                continue\n\n            has_py = False\n\n            for name in files:\n                if name.endswith((\".py\", \".pyc\")):\n                    has_py = True\n                    paths.add(os.path.join(root, name))\n\n            # Optimization: stop scanning a directory if neither it nor\n            # its parent contained Python files.\n            if not (has_py or parent_has_py[os.path.dirname(root)]):\n                dirs.clear()\n                continue\n\n            parent_has_py[root] = has_py\n\n    paths.update(_iter_module_paths())\n    _remove_by_pattern(paths, exclude_patterns)\n    return paths\n\n\ndef _find_watchdog_paths(\n    extra_files: set[str], exclude_patterns: set[str]\n) -> t.Iterable[str]:\n    \"\"\"Find paths for the stat reloader to watch. Looks at the same\n    sources as the stat reloader, but watches everything under\n    directories instead of individual files.\n    \"\"\"\n    dirs = set()\n\n    for name in chain(list(sys.path), extra_files):\n        name = os.path.abspath(name)\n\n        if os.path.isfile(name):\n            name = os.path.dirname(name)\n\n        dirs.add(name)\n\n    for name in _iter_module_paths():\n        dirs.add(os.path.dirname(name))\n\n    _remove_by_pattern(dirs, exclude_patterns)\n    return _find_common_roots(dirs)\n\n\ndef _find_common_roots(paths: t.Iterable[str]) -> t.Iterable[str]:\n    root: dict[str, dict[str, t.Any]] = {}\n\n    for chunks in sorted((PurePath(x).parts for x in paths), key=len, reverse=True):\n        node = root\n\n        for chunk in chunks:\n            node = node.setdefault(chunk, {})\n\n        node.clear()\n\n    rv = set()\n\n    def _walk(node: t.Mapping[str, dict[str, t.Any]], path: tuple[str, ...]) -> None:\n        for prefix, child in node.items():\n            _walk(child, path + (prefix,))\n\n        # If there are no more nodes, and a path has been accumulated, add it.\n        # Path may be empty if the \"\" entry is in sys.path.\n        if not node and path:\n            rv.add(os.path.join(*path))\n\n    _walk(root, ())\n    return rv\n\n\ndef _get_args_for_reloading() -> list[str]:\n    \"\"\"Determine how the script was executed, and return the args needed\n    to execute it again in a new process.\n    \"\"\"\n    if sys.version_info >= (3, 10):\n        # sys.orig_argv, added in Python 3.10, contains the exact args used to invoke\n        # Python. Still replace argv[0] with sys.executable for accuracy.\n        return [sys.executable, *sys.orig_argv[1:]]\n\n    rv = [sys.executable]\n    py_script = sys.argv[0]\n    args = sys.argv[1:]\n    # Need to look at main module to determine how it was executed.\n    __main__ = sys.modules[\"__main__\"]\n\n    # The value of __package__ indicates how Python was called. It may\n    # not exist if a setuptools script is installed as an egg. It may be\n    # set incorrectly for entry points created with pip on Windows.\n    if getattr(__main__, \"__package__\", None) is None or (\n        os.name == \"nt\"\n        and __main__.__package__ == \"\"\n        and not os.path.exists(py_script)\n        and os.path.exists(f\"{py_script}.exe\")\n    ):\n        # Executed a file, like \"python app.py\".\n        py_script = os.path.abspath(py_script)\n\n        if os.name == \"nt\":\n            # Windows entry points have \".exe\" extension and should be\n            # called directly.\n            if not os.path.exists(py_script) and os.path.exists(f\"{py_script}.exe\"):\n                py_script += \".exe\"\n\n            if (\n                os.path.splitext(sys.executable)[1] == \".exe\"\n                and os.path.splitext(py_script)[1] == \".exe\"\n            ):\n                rv.pop(0)\n\n        rv.append(py_script)\n    else:\n        # Executed a module, like \"python -m werkzeug.serving\".\n        if os.path.isfile(py_script):\n            # Rewritten by Python from \"-m script\" to \"/path/to/script.py\".\n            py_module = t.cast(str, __main__.__package__)\n            name = os.path.splitext(os.path.basename(py_script))[0]\n\n            if name != \"__main__\":\n                py_module += f\".{name}\"\n        else:\n            # Incorrectly rewritten by pydevd debugger from \"-m script\" to \"script\".\n            py_module = py_script\n\n        rv.extend((\"-m\", py_module.lstrip(\".\")))\n\n    rv.extend(args)\n    return rv\n\n\nclass ReloaderLoop:\n    name = \"\"\n\n    def __init__(\n        self,\n        extra_files: t.Iterable[str] | None = None,\n        exclude_patterns: t.Iterable[str] | None = None,\n        interval: int | float = 1,\n    ) -> None:\n        self.extra_files: set[str] = {os.path.abspath(x) for x in extra_files or ()}\n        self.exclude_patterns: set[str] = set(exclude_patterns or ())\n        self.interval = interval\n\n    def __enter__(self) -> ReloaderLoop:\n        \"\"\"Do any setup, then run one step of the watch to populate the\n        initial filesystem state.\n        \"\"\"\n        self.run_step()\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):  # type: ignore\n        \"\"\"Clean up any resources associated with the reloader.\"\"\"\n        pass\n\n    def run(self) -> None:\n        \"\"\"Continually run the watch step, sleeping for the configured\n        interval after each step.\n        \"\"\"\n        while True:\n            self.run_step()\n            time.sleep(self.interval)\n\n    def run_step(self) -> None:\n        \"\"\"Run one step for watching the filesystem. Called once to set\n        up initial state, then repeatedly to update it.\n        \"\"\"\n        pass\n\n    def restart_with_reloader(self) -> int:\n        \"\"\"Spawn a new Python interpreter with the same arguments as the\n        current one, but running the reloader thread.\n        \"\"\"\n        while True:\n            _log(\"info\", f\" * Restarting with {self.name}\")\n            args = _get_args_for_reloading()\n            new_environ = os.environ.copy()\n            new_environ[\"WERKZEUG_RUN_MAIN\"] = \"true\"\n            exit_code = subprocess.call(args, env=new_environ, close_fds=False)\n\n            if exit_code != 3:\n                return exit_code\n\n    def trigger_reload(self, filename: str) -> None:\n        self.log_reload(filename)\n        sys.exit(3)\n\n    def log_reload(self, filename: str) -> None:\n        filename = os.path.abspath(filename)\n        _log(\"info\", f\" * Detected change in {filename!r}, reloading\")\n\n\nclass StatReloaderLoop(ReloaderLoop):\n    name = \"stat\"\n\n    def __enter__(self) -> ReloaderLoop:\n        self.mtimes: dict[str, float] = {}\n        return super().__enter__()\n\n    def run_step(self) -> None:\n        for name in _find_stat_paths(self.extra_files, self.exclude_patterns):\n            try:\n                mtime = os.stat(name).st_mtime\n            except OSError:\n                continue\n\n            old_time = self.mtimes.get(name)\n\n            if old_time is None:\n                self.mtimes[name] = mtime\n                continue\n\n            if mtime > old_time:\n                self.trigger_reload(name)\n\n\nclass WatchdogReloaderLoop(ReloaderLoop):\n    def __init__(self, *args: t.Any, **kwargs: t.Any) -> None:\n        from watchdog.events import EVENT_TYPE_OPENED\n        from watchdog.events import FileModifiedEvent\n        from watchdog.events import PatternMatchingEventHandler\n        from watchdog.observers import Observer\n\n        super().__init__(*args, **kwargs)\n        trigger_reload = self.trigger_reload\n\n        class EventHandler(PatternMatchingEventHandler):\n            def on_any_event(self, event: FileModifiedEvent):  # type: ignore\n                if event.event_type == EVENT_TYPE_OPENED:\n                    return\n\n                trigger_reload(event.src_path)\n\n        reloader_name = Observer.__name__.lower()  # type: ignore[attr-defined]\n\n        if reloader_name.endswith(\"observer\"):\n            reloader_name = reloader_name[:-8]\n\n        self.name = f\"watchdog ({reloader_name})\"\n        self.observer = Observer()\n        # Extra patterns can be non-Python files, match them in addition\n        # to all Python files in default and extra directories. Ignore\n        # __pycache__ since a change there will always have a change to\n        # the source file (or initial pyc file) as well. Ignore Git and\n        # Mercurial internal changes.\n        extra_patterns = [p for p in self.extra_files if not os.path.isdir(p)]\n        self.event_handler = EventHandler(  # type: ignore[no-untyped-call]\n            patterns=[\"*.py\", \"*.pyc\", \"*.zip\", *extra_patterns],\n            ignore_patterns=[\n                *[f\"*/{d}/*\" for d in _ignore_common_dirs],\n                *self.exclude_patterns,\n            ],\n        )\n        self.should_reload = False\n\n    def trigger_reload(self, filename: str) -> None:\n        # This is called inside an event handler, which means throwing\n        # SystemExit has no effect.\n        # https://github.com/gorakhargosh/watchdog/issues/294\n        self.should_reload = True\n        self.log_reload(filename)\n\n    def __enter__(self) -> ReloaderLoop:\n        self.watches: dict[str, t.Any] = {}\n        self.observer.start()  # type: ignore[no-untyped-call]\n        return super().__enter__()\n\n    def __exit__(self, exc_type, exc_val, exc_tb):  # type: ignore\n        self.observer.stop()  # type: ignore[no-untyped-call]\n        self.observer.join()\n\n    def run(self) -> None:\n        while not self.should_reload:\n            self.run_step()\n            time.sleep(self.interval)\n\n        sys.exit(3)\n\n    def run_step(self) -> None:\n        to_delete = set(self.watches)\n\n        for path in _find_watchdog_paths(self.extra_files, self.exclude_patterns):\n            if path not in self.watches:\n                try:\n                    self.watches[path] = self.observer.schedule(  # type: ignore[no-untyped-call]\n                        self.event_handler, path, recursive=True\n                    )\n                except OSError:\n                    # Clear this path from list of watches We don't want\n                    # the same error message showing again in the next\n                    # iteration.\n                    self.watches[path] = None\n\n            to_delete.discard(path)\n\n        for path in to_delete:\n            watch = self.watches.pop(path, None)\n\n            if watch is not None:\n                self.observer.unschedule(watch)  # type: ignore[no-untyped-call]\n\n\nreloader_loops: dict[str, type[ReloaderLoop]] = {\n    \"stat\": StatReloaderLoop,\n    \"watchdog\": WatchdogReloaderLoop,\n}\n\ntry:\n    __import__(\"watchdog.observers\")\nexcept ImportError:\n    reloader_loops[\"auto\"] = reloader_loops[\"stat\"]\nelse:\n    reloader_loops[\"auto\"] = reloader_loops[\"watchdog\"]\n\n\ndef ensure_echo_on() -> None:\n    \"\"\"Ensure that echo mode is enabled. Some tools such as PDB disable\n    it which causes usability issues after a reload.\"\"\"\n    # tcgetattr will fail if stdin isn't a tty\n    if sys.stdin is None or not sys.stdin.isatty():\n        return\n\n    try:\n        import termios\n    except ImportError:\n        return\n\n    attributes = termios.tcgetattr(sys.stdin)\n\n    if not attributes[3] & termios.ECHO:\n        attributes[3] |= termios.ECHO\n        termios.tcsetattr(sys.stdin, termios.TCSANOW, attributes)\n\n\ndef run_with_reloader(\n    main_func: t.Callable[[], None],\n    extra_files: t.Iterable[str] | None = None,\n    exclude_patterns: t.Iterable[str] | None = None,\n    interval: int | float = 1,\n    reloader_type: str = \"auto\",\n) -> None:\n    \"\"\"Run the given function in an independent Python interpreter.\"\"\"\n    import signal\n\n    signal.signal(signal.SIGTERM, lambda *args: sys.exit(0))\n    reloader = reloader_loops[reloader_type](\n        extra_files=extra_files, exclude_patterns=exclude_patterns, interval=interval\n    )\n\n    try:\n        if os.environ.get(\"WERKZEUG_RUN_MAIN\") == \"true\":\n            ensure_echo_on()\n            t = threading.Thread(target=main_func, args=())\n            t.daemon = True\n\n            # Enter the reloader to set up initial state, then start\n            # the app thread and reloader update loop.\n            with reloader:\n                t.start()\n                reloader.run()\n        else:\n            sys.exit(reloader.restart_with_reloader())\n    except KeyboardInterrupt:\n        pass\n", "src/werkzeug/local.py": "from __future__ import annotations\n\nimport copy\nimport math\nimport operator\nimport typing as t\nfrom contextvars import ContextVar\nfrom functools import partial\nfrom functools import update_wrapper\nfrom operator import attrgetter\n\nfrom .wsgi import ClosingIterator\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import StartResponse\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n\nT = t.TypeVar(\"T\")\nF = t.TypeVar(\"F\", bound=t.Callable[..., t.Any])\n\n\ndef release_local(local: Local | LocalStack[t.Any]) -> None:\n    \"\"\"Release the data for the current context in a :class:`Local` or\n    :class:`LocalStack` without using a :class:`LocalManager`.\n\n    This should not be needed for modern use cases, and may be removed\n    in the future.\n\n    .. versionadded:: 0.6.1\n    \"\"\"\n    local.__release_local__()\n\n\nclass Local:\n    \"\"\"Create a namespace of context-local data. This wraps a\n    :class:`ContextVar` containing a :class:`dict` value.\n\n    This may incur a performance penalty compared to using individual\n    context vars, as it has to copy data to avoid mutating the dict\n    between nested contexts.\n\n    :param context_var: The :class:`~contextvars.ContextVar` to use as\n        storage for this local. If not given, one will be created.\n        Context vars not created at the global scope may interfere with\n        garbage collection.\n\n    .. versionchanged:: 2.0\n        Uses ``ContextVar`` instead of a custom storage implementation.\n    \"\"\"\n\n    __slots__ = (\"__storage\",)\n\n    def __init__(self, context_var: ContextVar[dict[str, t.Any]] | None = None) -> None:\n        if context_var is None:\n            # A ContextVar not created at global scope interferes with\n            # Python's garbage collection. However, a local only makes\n            # sense defined at the global scope as well, in which case\n            # the GC issue doesn't seem relevant.\n            context_var = ContextVar(f\"werkzeug.Local<{id(self)}>.storage\")\n\n        object.__setattr__(self, \"_Local__storage\", context_var)\n\n    def __iter__(self) -> t.Iterator[tuple[str, t.Any]]:\n        return iter(self.__storage.get({}).items())\n\n    def __call__(\n        self, name: str, *, unbound_message: str | None = None\n    ) -> LocalProxy[t.Any]:\n        \"\"\"Create a :class:`LocalProxy` that access an attribute on this\n        local namespace.\n\n        :param name: Proxy this attribute.\n        :param unbound_message: The error message that the proxy will\n            show if the attribute isn't set.\n        \"\"\"\n        return LocalProxy(self, name, unbound_message=unbound_message)\n\n    def __release_local__(self) -> None:\n        self.__storage.set({})\n\n    def __getattr__(self, name: str) -> t.Any:\n        values = self.__storage.get({})\n\n        if name in values:\n            return values[name]\n\n        raise AttributeError(name)\n\n    def __setattr__(self, name: str, value: t.Any) -> None:\n        values = self.__storage.get({}).copy()\n        values[name] = value\n        self.__storage.set(values)\n\n    def __delattr__(self, name: str) -> None:\n        values = self.__storage.get({})\n\n        if name in values:\n            values = values.copy()\n            del values[name]\n            self.__storage.set(values)\n        else:\n            raise AttributeError(name)\n\n\nclass LocalStack(t.Generic[T]):\n    \"\"\"Create a stack of context-local data. This wraps a\n    :class:`ContextVar` containing a :class:`list` value.\n\n    This may incur a performance penalty compared to using individual\n    context vars, as it has to copy data to avoid mutating the list\n    between nested contexts.\n\n    :param context_var: The :class:`~contextvars.ContextVar` to use as\n        storage for this local. If not given, one will be created.\n        Context vars not created at the global scope may interfere with\n        garbage collection.\n\n    .. versionchanged:: 2.0\n        Uses ``ContextVar`` instead of a custom storage implementation.\n\n    .. versionadded:: 0.6.1\n    \"\"\"\n\n    __slots__ = (\"_storage\",)\n\n    def __init__(self, context_var: ContextVar[list[T]] | None = None) -> None:\n        if context_var is None:\n            # A ContextVar not created at global scope interferes with\n            # Python's garbage collection. However, a local only makes\n            # sense defined at the global scope as well, in which case\n            # the GC issue doesn't seem relevant.\n            context_var = ContextVar(f\"werkzeug.LocalStack<{id(self)}>.storage\")\n\n        self._storage = context_var\n\n    def __release_local__(self) -> None:\n        self._storage.set([])\n\n    def push(self, obj: T) -> list[T]:\n        \"\"\"Add a new item to the top of the stack.\"\"\"\n        stack = self._storage.get([]).copy()\n        stack.append(obj)\n        self._storage.set(stack)\n        return stack\n\n    def pop(self) -> T | None:\n        \"\"\"Remove the top item from the stack and return it. If the\n        stack is empty, return ``None``.\n        \"\"\"\n        stack = self._storage.get([])\n\n        if len(stack) == 0:\n            return None\n\n        rv = stack[-1]\n        self._storage.set(stack[:-1])\n        return rv\n\n    @property\n    def top(self) -> T | None:\n        \"\"\"The topmost item on the stack.  If the stack is empty,\n        `None` is returned.\n        \"\"\"\n        stack = self._storage.get([])\n\n        if len(stack) == 0:\n            return None\n\n        return stack[-1]\n\n    def __call__(\n        self, name: str | None = None, *, unbound_message: str | None = None\n    ) -> LocalProxy[t.Any]:\n        \"\"\"Create a :class:`LocalProxy` that accesses the top of this\n        local stack.\n\n        :param name: If given, the proxy access this attribute of the\n            top item, rather than the item itself.\n        :param unbound_message: The error message that the proxy will\n            show if the stack is empty.\n        \"\"\"\n        return LocalProxy(self, name, unbound_message=unbound_message)\n\n\nclass LocalManager:\n    \"\"\"Manage releasing the data for the current context in one or more\n    :class:`Local` and :class:`LocalStack` objects.\n\n    This should not be needed for modern use cases, and may be removed\n    in the future.\n\n    :param locals: A local or list of locals to manage.\n\n    .. versionchanged:: 2.1\n        The ``ident_func`` was removed.\n\n    .. versionchanged:: 0.7\n        The ``ident_func`` parameter was added.\n\n    .. versionchanged:: 0.6.1\n        The :func:`release_local` function can be used instead of a\n        manager.\n    \"\"\"\n\n    __slots__ = (\"locals\",)\n\n    def __init__(\n        self,\n        locals: None\n        | (Local | LocalStack[t.Any] | t.Iterable[Local | LocalStack[t.Any]]) = None,\n    ) -> None:\n        if locals is None:\n            self.locals = []\n        elif isinstance(locals, Local):\n            self.locals = [locals]\n        else:\n            self.locals = list(locals)  # type: ignore[arg-type]\n\n    def cleanup(self) -> None:\n        \"\"\"Release the data in the locals for this context. Call this at\n        the end of each request or use :meth:`make_middleware`.\n        \"\"\"\n        for local in self.locals:\n            release_local(local)\n\n    def make_middleware(self, app: WSGIApplication) -> WSGIApplication:\n        \"\"\"Wrap a WSGI application so that local data is released\n        automatically after the response has been sent for a request.\n        \"\"\"\n\n        def application(\n            environ: WSGIEnvironment, start_response: StartResponse\n        ) -> t.Iterable[bytes]:\n            return ClosingIterator(app(environ, start_response), self.cleanup)\n\n        return application\n\n    def middleware(self, func: WSGIApplication) -> WSGIApplication:\n        \"\"\"Like :meth:`make_middleware` but used as a decorator on the\n        WSGI application function.\n\n        .. code-block:: python\n\n            @manager.middleware\n            def application(environ, start_response):\n                ...\n        \"\"\"\n        return update_wrapper(self.make_middleware(func), func)\n\n    def __repr__(self) -> str:\n        return f\"<{type(self).__name__} storages: {len(self.locals)}>\"\n\n\nclass _ProxyLookup:\n    \"\"\"Descriptor that handles proxied attribute lookup for\n    :class:`LocalProxy`.\n\n    :param f: The built-in function this attribute is accessed through.\n        Instead of looking up the special method, the function call\n        is redone on the object.\n    :param fallback: Return this function if the proxy is unbound\n        instead of raising a :exc:`RuntimeError`.\n    :param is_attr: This proxied name is an attribute, not a function.\n        Call the fallback immediately to get the value.\n    :param class_value: Value to return when accessed from the\n        ``LocalProxy`` class directly. Used for ``__doc__`` so building\n        docs still works.\n    \"\"\"\n\n    __slots__ = (\"bind_f\", \"fallback\", \"is_attr\", \"class_value\", \"name\")\n\n    def __init__(\n        self,\n        f: t.Callable[..., t.Any] | None = None,\n        fallback: t.Callable[[LocalProxy[t.Any]], t.Any] | None = None,\n        class_value: t.Any | None = None,\n        is_attr: bool = False,\n    ) -> None:\n        bind_f: t.Callable[[LocalProxy[t.Any], t.Any], t.Callable[..., t.Any]] | None\n\n        if hasattr(f, \"__get__\"):\n            # A Python function, can be turned into a bound method.\n\n            def bind_f(\n                instance: LocalProxy[t.Any], obj: t.Any\n            ) -> t.Callable[..., t.Any]:\n                return f.__get__(obj, type(obj))  # type: ignore\n\n        elif f is not None:\n            # A C function, use partial to bind the first argument.\n\n            def bind_f(\n                instance: LocalProxy[t.Any], obj: t.Any\n            ) -> t.Callable[..., t.Any]:\n                return partial(f, obj)\n\n        else:\n            # Use getattr, which will produce a bound method.\n            bind_f = None\n\n        self.bind_f = bind_f\n        self.fallback = fallback\n        self.class_value = class_value\n        self.is_attr = is_attr\n\n    def __set_name__(self, owner: LocalProxy[t.Any], name: str) -> None:\n        self.name = name\n\n    def __get__(self, instance: LocalProxy[t.Any], owner: type | None = None) -> t.Any:\n        if instance is None:\n            if self.class_value is not None:\n                return self.class_value\n\n            return self\n\n        try:\n            obj = instance._get_current_object()\n        except RuntimeError:\n            if self.fallback is None:\n                raise\n\n            fallback = self.fallback.__get__(instance, owner)\n\n            if self.is_attr:\n                # __class__ and __doc__ are attributes, not methods.\n                # Call the fallback to get the value.\n                return fallback()\n\n            return fallback\n\n        if self.bind_f is not None:\n            return self.bind_f(instance, obj)\n\n        return getattr(obj, self.name)\n\n    def __repr__(self) -> str:\n        return f\"proxy {self.name}\"\n\n    def __call__(\n        self, instance: LocalProxy[t.Any], *args: t.Any, **kwargs: t.Any\n    ) -> t.Any:\n        \"\"\"Support calling unbound methods from the class. For example,\n        this happens with ``copy.copy``, which does\n        ``type(x).__copy__(x)``. ``type(x)`` can't be proxied, so it\n        returns the proxy type and descriptor.\n        \"\"\"\n        return self.__get__(instance, type(instance))(*args, **kwargs)\n\n\nclass _ProxyIOp(_ProxyLookup):\n    \"\"\"Look up an augmented assignment method on a proxied object. The\n    method is wrapped to return the proxy instead of the object.\n    \"\"\"\n\n    __slots__ = ()\n\n    def __init__(\n        self,\n        f: t.Callable[..., t.Any] | None = None,\n        fallback: t.Callable[[LocalProxy[t.Any]], t.Any] | None = None,\n    ) -> None:\n        super().__init__(f, fallback)\n\n        def bind_f(instance: LocalProxy[t.Any], obj: t.Any) -> t.Callable[..., t.Any]:\n            def i_op(self: t.Any, other: t.Any) -> LocalProxy[t.Any]:\n                f(self, other)  # type: ignore\n                return instance\n\n            return i_op.__get__(obj, type(obj))  # type: ignore\n\n        self.bind_f = bind_f\n\n\ndef _l_to_r_op(op: F) -> F:\n    \"\"\"Swap the argument order to turn an l-op into an r-op.\"\"\"\n\n    def r_op(obj: t.Any, other: t.Any) -> t.Any:\n        return op(other, obj)\n\n    return t.cast(F, r_op)\n\n\ndef _identity(o: T) -> T:\n    return o\n\n\nclass LocalProxy(t.Generic[T]):\n    \"\"\"A proxy to the object bound to a context-local object. All\n    operations on the proxy are forwarded to the bound object. If no\n    object is bound, a ``RuntimeError`` is raised.\n\n    :param local: The context-local object that provides the proxied\n        object.\n    :param name: Proxy this attribute from the proxied object.\n    :param unbound_message: The error message to show if the\n        context-local object is unbound.\n\n    Proxy a :class:`~contextvars.ContextVar` to make it easier to\n    access. Pass a name to proxy that attribute.\n\n    .. code-block:: python\n\n        _request_var = ContextVar(\"request\")\n        request = LocalProxy(_request_var)\n        session = LocalProxy(_request_var, \"session\")\n\n    Proxy an attribute on a :class:`Local` namespace by calling the\n    local with the attribute name:\n\n    .. code-block:: python\n\n        data = Local()\n        user = data(\"user\")\n\n    Proxy the top item on a :class:`LocalStack` by calling the local.\n    Pass a name to proxy that attribute.\n\n    .. code-block::\n\n        app_stack = LocalStack()\n        current_app = app_stack()\n        g = app_stack(\"g\")\n\n    Pass a function to proxy the return value from that function. This\n    was previously used to access attributes of local objects before\n    that was supported directly.\n\n    .. code-block:: python\n\n        session = LocalProxy(lambda: request.session)\n\n    ``__repr__`` and ``__class__`` are proxied, so ``repr(x)`` and\n    ``isinstance(x, cls)`` will look like the proxied object. Use\n    ``issubclass(type(x), LocalProxy)`` to check if an object is a\n    proxy.\n\n    .. code-block:: python\n\n        repr(user)  # <User admin>\n        isinstance(user, User)  # True\n        issubclass(type(user), LocalProxy)  # True\n\n    .. versionchanged:: 2.2.2\n        ``__wrapped__`` is set when wrapping an object, not only when\n        wrapping a function, to prevent doctest from failing.\n\n    .. versionchanged:: 2.2\n        Can proxy a ``ContextVar`` or ``LocalStack`` directly.\n\n    .. versionchanged:: 2.2\n        The ``name`` parameter can be used with any proxied object, not\n        only ``Local``.\n\n    .. versionchanged:: 2.2\n        Added the ``unbound_message`` parameter.\n\n    .. versionchanged:: 2.0\n        Updated proxied attributes and methods to reflect the current\n        data model.\n\n    .. versionchanged:: 0.6.1\n        The class can be instantiated with a callable.\n    \"\"\"\n\n    __slots__ = (\"__wrapped\", \"_get_current_object\")\n\n    _get_current_object: t.Callable[[], T]\n    \"\"\"Return the current object this proxy is bound to. If the proxy is\n    unbound, this raises a ``RuntimeError``.\n\n    This should be used if you need to pass the object to something that\n    doesn't understand the proxy. It can also be useful for performance\n    if you are accessing the object multiple times in a function, rather\n    than going through the proxy multiple times.\n    \"\"\"\n\n    def __init__(\n        self,\n        local: ContextVar[T] | Local | LocalStack[T] | t.Callable[[], T],\n        name: str | None = None,\n        *,\n        unbound_message: str | None = None,\n    ) -> None:\n        if name is None:\n            get_name = _identity\n        else:\n            get_name = attrgetter(name)  # type: ignore[assignment]\n\n        if unbound_message is None:\n            unbound_message = \"object is not bound\"\n\n        if isinstance(local, Local):\n            if name is None:\n                raise TypeError(\"'name' is required when proxying a 'Local' object.\")\n\n            def _get_current_object() -> T:\n                try:\n                    return get_name(local)  # type: ignore[return-value]\n                except AttributeError:\n                    raise RuntimeError(unbound_message) from None\n\n        elif isinstance(local, LocalStack):\n\n            def _get_current_object() -> T:\n                obj = local.top\n\n                if obj is None:\n                    raise RuntimeError(unbound_message)\n\n                return get_name(obj)\n\n        elif isinstance(local, ContextVar):\n\n            def _get_current_object() -> T:\n                try:\n                    obj = local.get()\n                except LookupError:\n                    raise RuntimeError(unbound_message) from None\n\n                return get_name(obj)\n\n        elif callable(local):\n\n            def _get_current_object() -> T:\n                return get_name(local())\n\n        else:\n            raise TypeError(f\"Don't know how to proxy '{type(local)}'.\")\n\n        object.__setattr__(self, \"_LocalProxy__wrapped\", local)\n        object.__setattr__(self, \"_get_current_object\", _get_current_object)\n\n    __doc__ = _ProxyLookup(  # type: ignore[assignment]\n        class_value=__doc__, fallback=lambda self: type(self).__doc__, is_attr=True\n    )\n    __wrapped__ = _ProxyLookup(\n        fallback=lambda self: self._LocalProxy__wrapped,  # type: ignore[attr-defined]\n        is_attr=True,\n    )\n    # __del__ should only delete the proxy\n    __repr__ = _ProxyLookup(  # type: ignore[assignment]\n        repr, fallback=lambda self: f\"<{type(self).__name__} unbound>\"\n    )\n    __str__ = _ProxyLookup(str)  # type: ignore[assignment]\n    __bytes__ = _ProxyLookup(bytes)\n    __format__ = _ProxyLookup()  # type: ignore[assignment]\n    __lt__ = _ProxyLookup(operator.lt)\n    __le__ = _ProxyLookup(operator.le)\n    __eq__ = _ProxyLookup(operator.eq)  # type: ignore[assignment]\n    __ne__ = _ProxyLookup(operator.ne)  # type: ignore[assignment]\n    __gt__ = _ProxyLookup(operator.gt)\n    __ge__ = _ProxyLookup(operator.ge)\n    __hash__ = _ProxyLookup(hash)  # type: ignore[assignment]\n    __bool__ = _ProxyLookup(bool, fallback=lambda self: False)\n    __getattr__ = _ProxyLookup(getattr)\n    # __getattribute__ triggered through __getattr__\n    __setattr__ = _ProxyLookup(setattr)  # type: ignore[assignment]\n    __delattr__ = _ProxyLookup(delattr)  # type: ignore[assignment]\n    __dir__ = _ProxyLookup(dir, fallback=lambda self: [])  # type: ignore[assignment]\n    # __get__ (proxying descriptor not supported)\n    # __set__ (descriptor)\n    # __delete__ (descriptor)\n    # __set_name__ (descriptor)\n    # __objclass__ (descriptor)\n    # __slots__ used by proxy itself\n    # __dict__ (__getattr__)\n    # __weakref__ (__getattr__)\n    # __init_subclass__ (proxying metaclass not supported)\n    # __prepare__ (metaclass)\n    __class__ = _ProxyLookup(fallback=lambda self: type(self), is_attr=True)  # type: ignore[assignment]\n    __instancecheck__ = _ProxyLookup(lambda self, other: isinstance(other, self))\n    __subclasscheck__ = _ProxyLookup(lambda self, other: issubclass(other, self))\n    # __class_getitem__ triggered through __getitem__\n    __call__ = _ProxyLookup(lambda self, *args, **kwargs: self(*args, **kwargs))\n    __len__ = _ProxyLookup(len)\n    __length_hint__ = _ProxyLookup(operator.length_hint)\n    __getitem__ = _ProxyLookup(operator.getitem)\n    __setitem__ = _ProxyLookup(operator.setitem)\n    __delitem__ = _ProxyLookup(operator.delitem)\n    # __missing__ triggered through __getitem__\n    __iter__ = _ProxyLookup(iter)\n    __next__ = _ProxyLookup(next)\n    __reversed__ = _ProxyLookup(reversed)\n    __contains__ = _ProxyLookup(operator.contains)\n    __add__ = _ProxyLookup(operator.add)\n    __sub__ = _ProxyLookup(operator.sub)\n    __mul__ = _ProxyLookup(operator.mul)\n    __matmul__ = _ProxyLookup(operator.matmul)\n    __truediv__ = _ProxyLookup(operator.truediv)\n    __floordiv__ = _ProxyLookup(operator.floordiv)\n    __mod__ = _ProxyLookup(operator.mod)\n    __divmod__ = _ProxyLookup(divmod)\n    __pow__ = _ProxyLookup(pow)\n    __lshift__ = _ProxyLookup(operator.lshift)\n    __rshift__ = _ProxyLookup(operator.rshift)\n    __and__ = _ProxyLookup(operator.and_)\n    __xor__ = _ProxyLookup(operator.xor)\n    __or__ = _ProxyLookup(operator.or_)\n    __radd__ = _ProxyLookup(_l_to_r_op(operator.add))\n    __rsub__ = _ProxyLookup(_l_to_r_op(operator.sub))\n    __rmul__ = _ProxyLookup(_l_to_r_op(operator.mul))\n    __rmatmul__ = _ProxyLookup(_l_to_r_op(operator.matmul))\n    __rtruediv__ = _ProxyLookup(_l_to_r_op(operator.truediv))\n    __rfloordiv__ = _ProxyLookup(_l_to_r_op(operator.floordiv))\n    __rmod__ = _ProxyLookup(_l_to_r_op(operator.mod))\n    __rdivmod__ = _ProxyLookup(_l_to_r_op(divmod))\n    __rpow__ = _ProxyLookup(_l_to_r_op(pow))\n    __rlshift__ = _ProxyLookup(_l_to_r_op(operator.lshift))\n    __rrshift__ = _ProxyLookup(_l_to_r_op(operator.rshift))\n    __rand__ = _ProxyLookup(_l_to_r_op(operator.and_))\n    __rxor__ = _ProxyLookup(_l_to_r_op(operator.xor))\n    __ror__ = _ProxyLookup(_l_to_r_op(operator.or_))\n    __iadd__ = _ProxyIOp(operator.iadd)\n    __isub__ = _ProxyIOp(operator.isub)\n    __imul__ = _ProxyIOp(operator.imul)\n    __imatmul__ = _ProxyIOp(operator.imatmul)\n    __itruediv__ = _ProxyIOp(operator.itruediv)\n    __ifloordiv__ = _ProxyIOp(operator.ifloordiv)\n    __imod__ = _ProxyIOp(operator.imod)\n    __ipow__ = _ProxyIOp(operator.ipow)\n    __ilshift__ = _ProxyIOp(operator.ilshift)\n    __irshift__ = _ProxyIOp(operator.irshift)\n    __iand__ = _ProxyIOp(operator.iand)\n    __ixor__ = _ProxyIOp(operator.ixor)\n    __ior__ = _ProxyIOp(operator.ior)\n    __neg__ = _ProxyLookup(operator.neg)\n    __pos__ = _ProxyLookup(operator.pos)\n    __abs__ = _ProxyLookup(abs)\n    __invert__ = _ProxyLookup(operator.invert)\n    __complex__ = _ProxyLookup(complex)\n    __int__ = _ProxyLookup(int)\n    __float__ = _ProxyLookup(float)\n    __index__ = _ProxyLookup(operator.index)\n    __round__ = _ProxyLookup(round)\n    __trunc__ = _ProxyLookup(math.trunc)\n    __floor__ = _ProxyLookup(math.floor)\n    __ceil__ = _ProxyLookup(math.ceil)\n    __enter__ = _ProxyLookup()\n    __exit__ = _ProxyLookup()\n    __await__ = _ProxyLookup()\n    __aiter__ = _ProxyLookup()\n    __anext__ = _ProxyLookup()\n    __aenter__ = _ProxyLookup()\n    __aexit__ = _ProxyLookup()\n    __copy__ = _ProxyLookup(copy.copy)\n    __deepcopy__ = _ProxyLookup(copy.deepcopy)\n    # __getnewargs_ex__ (pickle through proxy not supported)\n    # __getnewargs__ (pickle)\n    # __getstate__ (pickle)\n    # __setstate__ (pickle)\n    # __reduce__ (pickle)\n    # __reduce_ex__ (pickle)\n", "src/werkzeug/http.py": "from __future__ import annotations\n\nimport email.utils\nimport re\nimport typing as t\nimport warnings\nfrom datetime import date\nfrom datetime import datetime\nfrom datetime import time\nfrom datetime import timedelta\nfrom datetime import timezone\nfrom enum import Enum\nfrom hashlib import sha1\nfrom time import mktime\nfrom time import struct_time\nfrom urllib.parse import quote\nfrom urllib.parse import unquote\nfrom urllib.request import parse_http_list as _parse_list_header\n\nfrom ._internal import _dt_as_utc\nfrom ._internal import _plain_int\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import WSGIEnvironment\n\n_token_chars = frozenset(\n    \"!#$%&'*+-.0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ^_`abcdefghijklmnopqrstuvwxyz|~\"\n)\n_etag_re = re.compile(r'([Ww]/)?(?:\"(.*?)\"|(.*?))(?:\\s*,\\s*|$)')\n_entity_headers = frozenset(\n    [\n        \"allow\",\n        \"content-encoding\",\n        \"content-language\",\n        \"content-length\",\n        \"content-location\",\n        \"content-md5\",\n        \"content-range\",\n        \"content-type\",\n        \"expires\",\n        \"last-modified\",\n    ]\n)\n_hop_by_hop_headers = frozenset(\n    [\n        \"connection\",\n        \"keep-alive\",\n        \"proxy-authenticate\",\n        \"proxy-authorization\",\n        \"te\",\n        \"trailer\",\n        \"transfer-encoding\",\n        \"upgrade\",\n    ]\n)\nHTTP_STATUS_CODES = {\n    100: \"Continue\",\n    101: \"Switching Protocols\",\n    102: \"Processing\",\n    103: \"Early Hints\",  # see RFC 8297\n    200: \"OK\",\n    201: \"Created\",\n    202: \"Accepted\",\n    203: \"Non Authoritative Information\",\n    204: \"No Content\",\n    205: \"Reset Content\",\n    206: \"Partial Content\",\n    207: \"Multi Status\",\n    208: \"Already Reported\",  # see RFC 5842\n    226: \"IM Used\",  # see RFC 3229\n    300: \"Multiple Choices\",\n    301: \"Moved Permanently\",\n    302: \"Found\",\n    303: \"See Other\",\n    304: \"Not Modified\",\n    305: \"Use Proxy\",\n    306: \"Switch Proxy\",  # unused\n    307: \"Temporary Redirect\",\n    308: \"Permanent Redirect\",\n    400: \"Bad Request\",\n    401: \"Unauthorized\",\n    402: \"Payment Required\",  # unused\n    403: \"Forbidden\",\n    404: \"Not Found\",\n    405: \"Method Not Allowed\",\n    406: \"Not Acceptable\",\n    407: \"Proxy Authentication Required\",\n    408: \"Request Timeout\",\n    409: \"Conflict\",\n    410: \"Gone\",\n    411: \"Length Required\",\n    412: \"Precondition Failed\",\n    413: \"Request Entity Too Large\",\n    414: \"Request URI Too Long\",\n    415: \"Unsupported Media Type\",\n    416: \"Requested Range Not Satisfiable\",\n    417: \"Expectation Failed\",\n    418: \"I'm a teapot\",  # see RFC 2324\n    421: \"Misdirected Request\",  # see RFC 7540\n    422: \"Unprocessable Entity\",\n    423: \"Locked\",\n    424: \"Failed Dependency\",\n    425: \"Too Early\",  # see RFC 8470\n    426: \"Upgrade Required\",\n    428: \"Precondition Required\",  # see RFC 6585\n    429: \"Too Many Requests\",\n    431: \"Request Header Fields Too Large\",\n    449: \"Retry With\",  # proprietary MS extension\n    451: \"Unavailable For Legal Reasons\",\n    500: \"Internal Server Error\",\n    501: \"Not Implemented\",\n    502: \"Bad Gateway\",\n    503: \"Service Unavailable\",\n    504: \"Gateway Timeout\",\n    505: \"HTTP Version Not Supported\",\n    506: \"Variant Also Negotiates\",  # see RFC 2295\n    507: \"Insufficient Storage\",\n    508: \"Loop Detected\",  # see RFC 5842\n    510: \"Not Extended\",\n    511: \"Network Authentication Failed\",\n}\n\n\nclass COEP(Enum):\n    \"\"\"Cross Origin Embedder Policies\"\"\"\n\n    UNSAFE_NONE = \"unsafe-none\"\n    REQUIRE_CORP = \"require-corp\"\n\n\nclass COOP(Enum):\n    \"\"\"Cross Origin Opener Policies\"\"\"\n\n    UNSAFE_NONE = \"unsafe-none\"\n    SAME_ORIGIN_ALLOW_POPUPS = \"same-origin-allow-popups\"\n    SAME_ORIGIN = \"same-origin\"\n\n\ndef quote_header_value(value: t.Any, allow_token: bool = True) -> str:\n    \"\"\"Add double quotes around a header value. If the header contains only ASCII token\n    characters, it will be returned unchanged. If the header contains ``\"`` or ``\\\\``\n    characters, they will be escaped with an additional ``\\\\`` character.\n\n    This is the reverse of :func:`unquote_header_value`.\n\n    :param value: The value to quote. Will be converted to a string.\n    :param allow_token: Disable to quote the value even if it only has token characters.\n\n    .. versionchanged:: 3.0\n        Passing bytes is not supported.\n\n    .. versionchanged:: 3.0\n        The ``extra_chars`` parameter is removed.\n\n    .. versionchanged:: 2.3\n        The value is quoted if it is the empty string.\n\n    .. versionadded:: 0.5\n    \"\"\"\n    value_str = str(value)\n\n    if not value_str:\n        return '\"\"'\n\n    if allow_token:\n        token_chars = _token_chars\n\n        if token_chars.issuperset(value_str):\n            return value_str\n\n    value_str = value_str.replace(\"\\\\\", \"\\\\\\\\\").replace('\"', '\\\\\"')\n    return f'\"{value_str}\"'\n\n\ndef unquote_header_value(value: str) -> str:\n    \"\"\"Remove double quotes and decode slash-escaped ``\"`` and ``\\\\`` characters in a\n    header value.\n\n    This is the reverse of :func:`quote_header_value`.\n\n    :param value: The header value to unquote.\n\n    .. versionchanged:: 3.0\n        The ``is_filename`` parameter is removed.\n    \"\"\"\n    if len(value) >= 2 and value[0] == value[-1] == '\"':\n        value = value[1:-1]\n        return value.replace(\"\\\\\\\\\", \"\\\\\").replace('\\\\\"', '\"')\n\n    return value\n\n\ndef dump_options_header(header: str | None, options: t.Mapping[str, t.Any]) -> str:\n    \"\"\"Produce a header value and ``key=value`` parameters separated by semicolons\n    ``;``. For example, the ``Content-Type`` header.\n\n    .. code-block:: python\n\n        dump_options_header(\"text/html\", {\"charset\": \"UTF-8\"})\n        'text/html; charset=UTF-8'\n\n    This is the reverse of :func:`parse_options_header`.\n\n    If a value contains non-token characters, it will be quoted.\n\n    If a value is ``None``, the parameter is skipped.\n\n    In some keys for some headers, a UTF-8 value can be encoded using a special\n    ``key*=UTF-8''value`` form, where ``value`` is percent encoded. This function will\n    not produce that format automatically, but if a given key ends with an asterisk\n    ``*``, the value is assumed to have that form and will not be quoted further.\n\n    :param header: The primary header value.\n    :param options: Parameters to encode as ``key=value`` pairs.\n\n    .. versionchanged:: 2.3\n        Keys with ``None`` values are skipped rather than treated as a bare key.\n\n    .. versionchanged:: 2.2.3\n        If a key ends with ``*``, its value will not be quoted.\n    \"\"\"\n    segments = []\n\n    if header is not None:\n        segments.append(header)\n\n    for key, value in options.items():\n        if value is None:\n            continue\n\n        if key[-1] == \"*\":\n            segments.append(f\"{key}={value}\")\n        else:\n            segments.append(f\"{key}={quote_header_value(value)}\")\n\n    return \"; \".join(segments)\n\n\ndef dump_header(iterable: dict[str, t.Any] | t.Iterable[t.Any]) -> str:\n    \"\"\"Produce a header value from a list of items or ``key=value`` pairs, separated by\n    commas ``,``.\n\n    This is the reverse of :func:`parse_list_header`, :func:`parse_dict_header`, and\n    :func:`parse_set_header`.\n\n    If a value contains non-token characters, it will be quoted.\n\n    If a value is ``None``, the key is output alone.\n\n    In some keys for some headers, a UTF-8 value can be encoded using a special\n    ``key*=UTF-8''value`` form, where ``value`` is percent encoded. This function will\n    not produce that format automatically, but if a given key ends with an asterisk\n    ``*``, the value is assumed to have that form and will not be quoted further.\n\n    .. code-block:: python\n\n        dump_header([\"foo\", \"bar baz\"])\n        'foo, \"bar baz\"'\n\n        dump_header({\"foo\": \"bar baz\"})\n        'foo=\"bar baz\"'\n\n    :param iterable: The items to create a header from.\n\n    .. versionchanged:: 3.0\n        The ``allow_token`` parameter is removed.\n\n    .. versionchanged:: 2.2.3\n        If a key ends with ``*``, its value will not be quoted.\n    \"\"\"\n    if isinstance(iterable, dict):\n        items = []\n\n        for key, value in iterable.items():\n            if value is None:\n                items.append(key)\n            elif key[-1] == \"*\":\n                items.append(f\"{key}={value}\")\n            else:\n                items.append(f\"{key}={quote_header_value(value)}\")\n    else:\n        items = [quote_header_value(x) for x in iterable]\n\n    return \", \".join(items)\n\n\ndef dump_csp_header(header: ds.ContentSecurityPolicy) -> str:\n    \"\"\"Dump a Content Security Policy header.\n\n    These are structured into policies such as \"default-src 'self';\n    script-src 'self'\".\n\n    .. versionadded:: 1.0.0\n       Support for Content Security Policy headers was added.\n\n    \"\"\"\n    return \"; \".join(f\"{key} {value}\" for key, value in header.items())\n\n\ndef parse_list_header(value: str) -> list[str]:\n    \"\"\"Parse a header value that consists of a list of comma separated items according\n    to `RFC 9110 <https://httpwg.org/specs/rfc9110.html#abnf.extension>`__.\n\n    This extends :func:`urllib.request.parse_http_list` to remove surrounding quotes\n    from values.\n\n    .. code-block:: python\n\n        parse_list_header('token, \"quoted value\"')\n        ['token', 'quoted value']\n\n    This is the reverse of :func:`dump_header`.\n\n    :param value: The header value to parse.\n    \"\"\"\n    result = []\n\n    for item in _parse_list_header(value):\n        if len(item) >= 2 and item[0] == item[-1] == '\"':\n            item = item[1:-1]\n\n        result.append(item)\n\n    return result\n\n\ndef parse_dict_header(value: str) -> dict[str, str | None]:\n    \"\"\"Parse a list header using :func:`parse_list_header`, then parse each item as a\n    ``key=value`` pair.\n\n    .. code-block:: python\n\n        parse_dict_header('a=b, c=\"d, e\", f')\n        {\"a\": \"b\", \"c\": \"d, e\", \"f\": None}\n\n    This is the reverse of :func:`dump_header`.\n\n    If a key does not have a value, it is ``None``.\n\n    This handles charsets for values as described in\n    `RFC 2231 <https://www.rfc-editor.org/rfc/rfc2231#section-3>`__. Only ASCII, UTF-8,\n    and ISO-8859-1 charsets are accepted, otherwise the value remains quoted.\n\n    :param value: The header value to parse.\n\n    .. versionchanged:: 3.0\n        Passing bytes is not supported.\n\n    .. versionchanged:: 3.0\n        The ``cls`` argument is removed.\n\n    .. versionchanged:: 2.3\n        Added support for ``key*=charset''value`` encoded items.\n\n    .. versionchanged:: 0.9\n       The ``cls`` argument was added.\n    \"\"\"\n    result: dict[str, str | None] = {}\n\n    for item in parse_list_header(value):\n        key, has_value, value = item.partition(\"=\")\n        key = key.strip()\n\n        if not has_value:\n            result[key] = None\n            continue\n\n        value = value.strip()\n        encoding: str | None = None\n\n        if key[-1] == \"*\":\n            # key*=charset''value becomes key=value, where value is percent encoded\n            # adapted from parse_options_header, without the continuation handling\n            key = key[:-1]\n            match = _charset_value_re.match(value)\n\n            if match:\n                # If there is a charset marker in the value, split it off.\n                encoding, value = match.groups()\n                encoding = encoding.lower()\n\n            # A safe list of encodings. Modern clients should only send ASCII or UTF-8.\n            # This list will not be extended further. An invalid encoding will leave the\n            # value quoted.\n            if encoding in {\"ascii\", \"us-ascii\", \"utf-8\", \"iso-8859-1\"}:\n                # invalid bytes are replaced during unquoting\n                value = unquote(value, encoding=encoding)\n\n        if len(value) >= 2 and value[0] == value[-1] == '\"':\n            value = value[1:-1]\n\n        result[key] = value\n\n    return result\n\n\n# https://httpwg.org/specs/rfc9110.html#parameter\n_parameter_re = re.compile(\n    r\"\"\"\n    # don't match multiple empty parts, that causes backtracking\n    \\s*;\\s*  # find the part delimiter\n    (?:\n        ([\\w!#$%&'*+\\-.^`|~]+)  # key, one or more token chars\n        =  # equals, with no space on either side\n        (  # value, token or quoted string\n            [\\w!#$%&'*+\\-.^`|~]+  # one or more token chars\n        |\n            \"(?:\\\\\\\\|\\\\\"|.)*?\"  # quoted string, consuming slash escapes\n        )\n    )?  # optionally match key=value, to account for empty parts\n    \"\"\",\n    re.ASCII | re.VERBOSE,\n)\n# https://www.rfc-editor.org/rfc/rfc2231#section-4\n_charset_value_re = re.compile(\n    r\"\"\"\n    ([\\w!#$%&*+\\-.^`|~]*)'  # charset part, could be empty\n    [\\w!#$%&*+\\-.^`|~]*'  # don't care about language part, usually empty\n    ([\\w!#$%&'*+\\-.^`|~]+)  # one or more token chars with percent encoding\n    \"\"\",\n    re.ASCII | re.VERBOSE,\n)\n# https://www.rfc-editor.org/rfc/rfc2231#section-3\n_continuation_re = re.compile(r\"\\*(\\d+)$\", re.ASCII)\n\n\ndef parse_options_header(value: str | None) -> tuple[str, dict[str, str]]:\n    \"\"\"Parse a header that consists of a value with ``key=value`` parameters separated\n    by semicolons ``;``. For example, the ``Content-Type`` header.\n\n    .. code-block:: python\n\n        parse_options_header(\"text/html; charset=UTF-8\")\n        ('text/html', {'charset': 'UTF-8'})\n\n        parse_options_header(\"\")\n        (\"\", {})\n\n    This is the reverse of :func:`dump_options_header`.\n\n    This parses valid parameter parts as described in\n    `RFC 9110 <https://httpwg.org/specs/rfc9110.html#parameter>`__. Invalid parts are\n    skipped.\n\n    This handles continuations and charsets as described in\n    `RFC 2231 <https://www.rfc-editor.org/rfc/rfc2231#section-3>`__, although not as\n    strictly as the RFC. Only ASCII, UTF-8, and ISO-8859-1 charsets are accepted,\n    otherwise the value remains quoted.\n\n    Clients may not be consistent in how they handle a quote character within a quoted\n    value. The `HTML Standard <https://html.spec.whatwg.org/#multipart-form-data>`__\n    replaces it with ``%22`` in multipart form data.\n    `RFC 9110 <https://httpwg.org/specs/rfc9110.html#quoted.strings>`__ uses backslash\n    escapes in HTTP headers. Both are decoded to the ``\"`` character.\n\n    Clients may not be consistent in how they handle non-ASCII characters. HTML\n    documents must declare ``<meta charset=UTF-8>``, otherwise browsers may replace with\n    HTML character references, which can be decoded using :func:`html.unescape`.\n\n    :param value: The header value to parse.\n    :return: ``(value, options)``, where ``options`` is a dict\n\n    .. versionchanged:: 2.3\n        Invalid parts, such as keys with no value, quoted keys, and incorrectly quoted\n        values, are discarded instead of treating as ``None``.\n\n    .. versionchanged:: 2.3\n        Only ASCII, UTF-8, and ISO-8859-1 are accepted for charset values.\n\n    .. versionchanged:: 2.3\n        Escaped quotes in quoted values, like ``%22`` and ``\\\\\"``, are handled.\n\n    .. versionchanged:: 2.2\n        Option names are always converted to lowercase.\n\n    .. versionchanged:: 2.2\n        The ``multiple`` parameter was removed.\n\n    .. versionchanged:: 0.15\n        :rfc:`2231` parameter continuations are handled.\n\n    .. versionadded:: 0.5\n    \"\"\"\n    if value is None:\n        return \"\", {}\n\n    value, _, rest = value.partition(\";\")\n    value = value.strip()\n    rest = rest.strip()\n\n    if not value or not rest:\n        # empty (invalid) value, or value without options\n        return value, {}\n\n    rest = f\";{rest}\"\n    options: dict[str, str] = {}\n    encoding: str | None = None\n    continued_encoding: str | None = None\n\n    for pk, pv in _parameter_re.findall(rest):\n        if not pk:\n            # empty or invalid part\n            continue\n\n        pk = pk.lower()\n\n        if pk[-1] == \"*\":\n            # key*=charset''value becomes key=value, where value is percent encoded\n            pk = pk[:-1]\n            match = _charset_value_re.match(pv)\n\n            if match:\n                # If there is a valid charset marker in the value, split it off.\n                encoding, pv = match.groups()\n                # This might be the empty string, handled next.\n                encoding = encoding.lower()\n\n            # No charset marker, or marker with empty charset value.\n            if not encoding:\n                encoding = continued_encoding\n\n            # A safe list of encodings. Modern clients should only send ASCII or UTF-8.\n            # This list will not be extended further. An invalid encoding will leave the\n            # value quoted.\n            if encoding in {\"ascii\", \"us-ascii\", \"utf-8\", \"iso-8859-1\"}:\n                # Continuation parts don't require their own charset marker. This is\n                # looser than the RFC, it will persist across different keys and allows\n                # changing the charset during a continuation. But this implementation is\n                # much simpler than tracking the full state.\n                continued_encoding = encoding\n                # invalid bytes are replaced during unquoting\n                pv = unquote(pv, encoding=encoding)\n\n        # Remove quotes. At this point the value cannot be empty or a single quote.\n        if pv[0] == pv[-1] == '\"':\n            # HTTP headers use slash, multipart form data uses percent\n            pv = pv[1:-1].replace(\"\\\\\\\\\", \"\\\\\").replace('\\\\\"', '\"').replace(\"%22\", '\"')\n\n        match = _continuation_re.search(pk)\n\n        if match:\n            # key*0=a; key*1=b becomes key=ab\n            pk = pk[: match.start()]\n            options[pk] = options.get(pk, \"\") + pv\n        else:\n            options[pk] = pv\n\n    return value, options\n\n\n_q_value_re = re.compile(r\"-?\\d+(\\.\\d+)?\", re.ASCII)\n_TAnyAccept = t.TypeVar(\"_TAnyAccept\", bound=\"ds.Accept\")\n\n\n@t.overload\ndef parse_accept_header(value: str | None) -> ds.Accept: ...\n\n\n@t.overload\ndef parse_accept_header(value: str | None, cls: type[_TAnyAccept]) -> _TAnyAccept: ...\n\n\ndef parse_accept_header(\n    value: str | None, cls: type[_TAnyAccept] | None = None\n) -> _TAnyAccept:\n    \"\"\"Parse an ``Accept`` header according to\n    `RFC 9110 <https://httpwg.org/specs/rfc9110.html#field.accept>`__.\n\n    Returns an :class:`.Accept` instance, which can sort and inspect items based on\n    their quality parameter. When parsing ``Accept-Charset``, ``Accept-Encoding``, or\n    ``Accept-Language``, pass the appropriate :class:`.Accept` subclass.\n\n    :param value: The header value to parse.\n    :param cls: The :class:`.Accept` class to wrap the result in.\n    :return: An instance of ``cls``.\n\n    .. versionchanged:: 2.3\n        Parse according to RFC 9110. Items with invalid ``q`` values are skipped.\n    \"\"\"\n    if cls is None:\n        cls = t.cast(t.Type[_TAnyAccept], ds.Accept)\n\n    if not value:\n        return cls(None)\n\n    result = []\n\n    for item in parse_list_header(value):\n        item, options = parse_options_header(item)\n\n        if \"q\" in options:\n            # pop q, remaining options are reconstructed\n            q_str = options.pop(\"q\").strip()\n\n            if _q_value_re.fullmatch(q_str) is None:\n                # ignore an invalid q\n                continue\n\n            q = float(q_str)\n\n            if q < 0 or q > 1:\n                # ignore an invalid q\n                continue\n        else:\n            q = 1\n\n        if options:\n            # reconstruct the media type with any options\n            item = dump_options_header(item, options)\n\n        result.append((item, q))\n\n    return cls(result)\n\n\n_TAnyCC = t.TypeVar(\"_TAnyCC\", bound=\"ds.cache_control._CacheControl\")\n\n\n@t.overload\ndef parse_cache_control_header(\n    value: str | None,\n    on_update: t.Callable[[ds.cache_control._CacheControl], None] | None = None,\n) -> ds.RequestCacheControl: ...\n\n\n@t.overload\ndef parse_cache_control_header(\n    value: str | None,\n    on_update: t.Callable[[ds.cache_control._CacheControl], None] | None = None,\n    cls: type[_TAnyCC] = ...,\n) -> _TAnyCC: ...\n\n\ndef parse_cache_control_header(\n    value: str | None,\n    on_update: t.Callable[[ds.cache_control._CacheControl], None] | None = None,\n    cls: type[_TAnyCC] | None = None,\n) -> _TAnyCC:\n    \"\"\"Parse a cache control header.  The RFC differs between response and\n    request cache control, this method does not.  It's your responsibility\n    to not use the wrong control statements.\n\n    .. versionadded:: 0.5\n       The `cls` was added.  If not specified an immutable\n       :class:`~werkzeug.datastructures.RequestCacheControl` is returned.\n\n    :param value: a cache control header to be parsed.\n    :param on_update: an optional callable that is called every time a value\n                      on the :class:`~werkzeug.datastructures.CacheControl`\n                      object is changed.\n    :param cls: the class for the returned object.  By default\n                :class:`~werkzeug.datastructures.RequestCacheControl` is used.\n    :return: a `cls` object.\n    \"\"\"\n    if cls is None:\n        cls = t.cast(\"type[_TAnyCC]\", ds.RequestCacheControl)\n\n    if not value:\n        return cls((), on_update)\n\n    return cls(parse_dict_header(value), on_update)\n\n\n_TAnyCSP = t.TypeVar(\"_TAnyCSP\", bound=\"ds.ContentSecurityPolicy\")\n\n\n@t.overload\ndef parse_csp_header(\n    value: str | None,\n    on_update: t.Callable[[ds.ContentSecurityPolicy], None] | None = None,\n) -> ds.ContentSecurityPolicy: ...\n\n\n@t.overload\ndef parse_csp_header(\n    value: str | None,\n    on_update: t.Callable[[ds.ContentSecurityPolicy], None] | None = None,\n    cls: type[_TAnyCSP] = ...,\n) -> _TAnyCSP: ...\n\n\ndef parse_csp_header(\n    value: str | None,\n    on_update: t.Callable[[ds.ContentSecurityPolicy], None] | None = None,\n    cls: type[_TAnyCSP] | None = None,\n) -> _TAnyCSP:\n    \"\"\"Parse a Content Security Policy header.\n\n    .. versionadded:: 1.0.0\n       Support for Content Security Policy headers was added.\n\n    :param value: a csp header to be parsed.\n    :param on_update: an optional callable that is called every time a value\n                      on the object is changed.\n    :param cls: the class for the returned object.  By default\n                :class:`~werkzeug.datastructures.ContentSecurityPolicy` is used.\n    :return: a `cls` object.\n    \"\"\"\n    if cls is None:\n        cls = t.cast(\"type[_TAnyCSP]\", ds.ContentSecurityPolicy)\n\n    if value is None:\n        return cls((), on_update)\n\n    items = []\n\n    for policy in value.split(\";\"):\n        policy = policy.strip()\n\n        # Ignore badly formatted policies (no space)\n        if \" \" in policy:\n            directive, value = policy.strip().split(\" \", 1)\n            items.append((directive.strip(), value.strip()))\n\n    return cls(items, on_update)\n\n\ndef parse_set_header(\n    value: str | None,\n    on_update: t.Callable[[ds.HeaderSet], None] | None = None,\n) -> ds.HeaderSet:\n    \"\"\"Parse a set-like header and return a\n    :class:`~werkzeug.datastructures.HeaderSet` object:\n\n    >>> hs = parse_set_header('token, \"quoted value\"')\n\n    The return value is an object that treats the items case-insensitively\n    and keeps the order of the items:\n\n    >>> 'TOKEN' in hs\n    True\n    >>> hs.index('quoted value')\n    1\n    >>> hs\n    HeaderSet(['token', 'quoted value'])\n\n    To create a header from the :class:`HeaderSet` again, use the\n    :func:`dump_header` function.\n\n    :param value: a set header to be parsed.\n    :param on_update: an optional callable that is called every time a\n                      value on the :class:`~werkzeug.datastructures.HeaderSet`\n                      object is changed.\n    :return: a :class:`~werkzeug.datastructures.HeaderSet`\n    \"\"\"\n    if not value:\n        return ds.HeaderSet(None, on_update)\n    return ds.HeaderSet(parse_list_header(value), on_update)\n\n\ndef parse_if_range_header(value: str | None) -> ds.IfRange:\n    \"\"\"Parses an if-range header which can be an etag or a date.  Returns\n    a :class:`~werkzeug.datastructures.IfRange` object.\n\n    .. versionchanged:: 2.0\n        If the value represents a datetime, it is timezone-aware.\n\n    .. versionadded:: 0.7\n    \"\"\"\n    if not value:\n        return ds.IfRange()\n    date = parse_date(value)\n    if date is not None:\n        return ds.IfRange(date=date)\n    # drop weakness information\n    return ds.IfRange(unquote_etag(value)[0])\n\n\ndef parse_range_header(\n    value: str | None, make_inclusive: bool = True\n) -> ds.Range | None:\n    \"\"\"Parses a range header into a :class:`~werkzeug.datastructures.Range`\n    object.  If the header is missing or malformed `None` is returned.\n    `ranges` is a list of ``(start, stop)`` tuples where the ranges are\n    non-inclusive.\n\n    .. versionadded:: 0.7\n    \"\"\"\n    if not value or \"=\" not in value:\n        return None\n\n    ranges = []\n    last_end = 0\n    units, rng = value.split(\"=\", 1)\n    units = units.strip().lower()\n\n    for item in rng.split(\",\"):\n        item = item.strip()\n        if \"-\" not in item:\n            return None\n        if item.startswith(\"-\"):\n            if last_end < 0:\n                return None\n            try:\n                begin = _plain_int(item)\n            except ValueError:\n                return None\n            end = None\n            last_end = -1\n        elif \"-\" in item:\n            begin_str, end_str = item.split(\"-\", 1)\n            begin_str = begin_str.strip()\n            end_str = end_str.strip()\n\n            try:\n                begin = _plain_int(begin_str)\n            except ValueError:\n                return None\n\n            if begin < last_end or last_end < 0:\n                return None\n            if end_str:\n                try:\n                    end = _plain_int(end_str) + 1\n                except ValueError:\n                    return None\n\n                if begin >= end:\n                    return None\n            else:\n                end = None\n            last_end = end if end is not None else -1\n        ranges.append((begin, end))\n\n    return ds.Range(units, ranges)\n\n\ndef parse_content_range_header(\n    value: str | None,\n    on_update: t.Callable[[ds.ContentRange], None] | None = None,\n) -> ds.ContentRange | None:\n    \"\"\"Parses a range header into a\n    :class:`~werkzeug.datastructures.ContentRange` object or `None` if\n    parsing is not possible.\n\n    .. versionadded:: 0.7\n\n    :param value: a content range header to be parsed.\n    :param on_update: an optional callable that is called every time a value\n                      on the :class:`~werkzeug.datastructures.ContentRange`\n                      object is changed.\n    \"\"\"\n    if value is None:\n        return None\n    try:\n        units, rangedef = (value or \"\").strip().split(None, 1)\n    except ValueError:\n        return None\n\n    if \"/\" not in rangedef:\n        return None\n    rng, length_str = rangedef.split(\"/\", 1)\n    if length_str == \"*\":\n        length = None\n    else:\n        try:\n            length = _plain_int(length_str)\n        except ValueError:\n            return None\n\n    if rng == \"*\":\n        if not is_byte_range_valid(None, None, length):\n            return None\n\n        return ds.ContentRange(units, None, None, length, on_update=on_update)\n    elif \"-\" not in rng:\n        return None\n\n    start_str, stop_str = rng.split(\"-\", 1)\n    try:\n        start = _plain_int(start_str)\n        stop = _plain_int(stop_str) + 1\n    except ValueError:\n        return None\n\n    if is_byte_range_valid(start, stop, length):\n        return ds.ContentRange(units, start, stop, length, on_update=on_update)\n\n    return None\n\n\ndef quote_etag(etag: str, weak: bool = False) -> str:\n    \"\"\"Quote an etag.\n\n    :param etag: the etag to quote.\n    :param weak: set to `True` to tag it \"weak\".\n    \"\"\"\n    if '\"' in etag:\n        raise ValueError(\"invalid etag\")\n    etag = f'\"{etag}\"'\n    if weak:\n        etag = f\"W/{etag}\"\n    return etag\n\n\ndef unquote_etag(\n    etag: str | None,\n) -> tuple[str, bool] | tuple[None, None]:\n    \"\"\"Unquote a single etag:\n\n    >>> unquote_etag('W/\"bar\"')\n    ('bar', True)\n    >>> unquote_etag('\"bar\"')\n    ('bar', False)\n\n    :param etag: the etag identifier to unquote.\n    :return: a ``(etag, weak)`` tuple.\n    \"\"\"\n    if not etag:\n        return None, None\n    etag = etag.strip()\n    weak = False\n    if etag.startswith((\"W/\", \"w/\")):\n        weak = True\n        etag = etag[2:]\n    if etag[:1] == etag[-1:] == '\"':\n        etag = etag[1:-1]\n    return etag, weak\n\n\ndef parse_etags(value: str | None) -> ds.ETags:\n    \"\"\"Parse an etag header.\n\n    :param value: the tag header to parse\n    :return: an :class:`~werkzeug.datastructures.ETags` object.\n    \"\"\"\n    if not value:\n        return ds.ETags()\n    strong = []\n    weak = []\n    end = len(value)\n    pos = 0\n    while pos < end:\n        match = _etag_re.match(value, pos)\n        if match is None:\n            break\n        is_weak, quoted, raw = match.groups()\n        if raw == \"*\":\n            return ds.ETags(star_tag=True)\n        elif quoted:\n            raw = quoted\n        if is_weak:\n            weak.append(raw)\n        else:\n            strong.append(raw)\n        pos = match.end()\n    return ds.ETags(strong, weak)\n\n\ndef generate_etag(data: bytes) -> str:\n    \"\"\"Generate an etag for some data.\n\n    .. versionchanged:: 2.0\n        Use SHA-1. MD5 may not be available in some environments.\n    \"\"\"\n    return sha1(data).hexdigest()\n\n\ndef parse_date(value: str | None) -> datetime | None:\n    \"\"\"Parse an :rfc:`2822` date into a timezone-aware\n    :class:`datetime.datetime` object, or ``None`` if parsing fails.\n\n    This is a wrapper for :func:`email.utils.parsedate_to_datetime`. It\n    returns ``None`` if parsing fails instead of raising an exception,\n    and always returns a timezone-aware datetime object. If the string\n    doesn't have timezone information, it is assumed to be UTC.\n\n    :param value: A string with a supported date format.\n\n    .. versionchanged:: 2.0\n        Return a timezone-aware datetime object. Use\n        ``email.utils.parsedate_to_datetime``.\n    \"\"\"\n    if value is None:\n        return None\n\n    try:\n        dt = email.utils.parsedate_to_datetime(value)\n    except (TypeError, ValueError):\n        return None\n\n    if dt.tzinfo is None:\n        return dt.replace(tzinfo=timezone.utc)\n\n    return dt\n\n\ndef http_date(\n    timestamp: datetime | date | int | float | struct_time | None = None,\n) -> str:\n    \"\"\"Format a datetime object or timestamp into an :rfc:`2822` date\n    string.\n\n    This is a wrapper for :func:`email.utils.format_datetime`. It\n    assumes naive datetime objects are in UTC instead of raising an\n    exception.\n\n    :param timestamp: The datetime or timestamp to format. Defaults to\n        the current time.\n\n    .. versionchanged:: 2.0\n        Use ``email.utils.format_datetime``. Accept ``date`` objects.\n    \"\"\"\n    if isinstance(timestamp, date):\n        if not isinstance(timestamp, datetime):\n            # Assume plain date is midnight UTC.\n            timestamp = datetime.combine(timestamp, time(), tzinfo=timezone.utc)\n        else:\n            # Ensure datetime is timezone-aware.\n            timestamp = _dt_as_utc(timestamp)\n\n        return email.utils.format_datetime(timestamp, usegmt=True)\n\n    if isinstance(timestamp, struct_time):\n        timestamp = mktime(timestamp)\n\n    return email.utils.formatdate(timestamp, usegmt=True)\n\n\ndef parse_age(value: str | None = None) -> timedelta | None:\n    \"\"\"Parses a base-10 integer count of seconds into a timedelta.\n\n    If parsing fails, the return value is `None`.\n\n    :param value: a string consisting of an integer represented in base-10\n    :return: a :class:`datetime.timedelta` object or `None`.\n    \"\"\"\n    if not value:\n        return None\n    try:\n        seconds = int(value)\n    except ValueError:\n        return None\n    if seconds < 0:\n        return None\n    try:\n        return timedelta(seconds=seconds)\n    except OverflowError:\n        return None\n\n\ndef dump_age(age: timedelta | int | None = None) -> str | None:\n    \"\"\"Formats the duration as a base-10 integer.\n\n    :param age: should be an integer number of seconds,\n                a :class:`datetime.timedelta` object, or,\n                if the age is unknown, `None` (default).\n    \"\"\"\n    if age is None:\n        return None\n    if isinstance(age, timedelta):\n        age = int(age.total_seconds())\n    else:\n        age = int(age)\n\n    if age < 0:\n        raise ValueError(\"age cannot be negative\")\n\n    return str(age)\n\n\ndef is_resource_modified(\n    environ: WSGIEnvironment,\n    etag: str | None = None,\n    data: bytes | None = None,\n    last_modified: datetime | str | None = None,\n    ignore_if_range: bool = True,\n) -> bool:\n    \"\"\"Convenience method for conditional requests.\n\n    :param environ: the WSGI environment of the request to be checked.\n    :param etag: the etag for the response for comparison.\n    :param data: or alternatively the data of the response to automatically\n                 generate an etag using :func:`generate_etag`.\n    :param last_modified: an optional date of the last modification.\n    :param ignore_if_range: If `False`, `If-Range` header will be taken into\n                            account.\n    :return: `True` if the resource was modified, otherwise `False`.\n\n    .. versionchanged:: 2.0\n        SHA-1 is used to generate an etag value for the data. MD5 may\n        not be available in some environments.\n\n    .. versionchanged:: 1.0.0\n        The check is run for methods other than ``GET`` and ``HEAD``.\n    \"\"\"\n    return _sansio_http.is_resource_modified(\n        http_range=environ.get(\"HTTP_RANGE\"),\n        http_if_range=environ.get(\"HTTP_IF_RANGE\"),\n        http_if_modified_since=environ.get(\"HTTP_IF_MODIFIED_SINCE\"),\n        http_if_none_match=environ.get(\"HTTP_IF_NONE_MATCH\"),\n        http_if_match=environ.get(\"HTTP_IF_MATCH\"),\n        etag=etag,\n        data=data,\n        last_modified=last_modified,\n        ignore_if_range=ignore_if_range,\n    )\n\n\ndef remove_entity_headers(\n    headers: ds.Headers | list[tuple[str, str]],\n    allowed: t.Iterable[str] = (\"expires\", \"content-location\"),\n) -> None:\n    \"\"\"Remove all entity headers from a list or :class:`Headers` object.  This\n    operation works in-place.  `Expires` and `Content-Location` headers are\n    by default not removed.  The reason for this is :rfc:`2616` section\n    10.3.5 which specifies some entity headers that should be sent.\n\n    .. versionchanged:: 0.5\n       added `allowed` parameter.\n\n    :param headers: a list or :class:`Headers` object.\n    :param allowed: a list of headers that should still be allowed even though\n                    they are entity headers.\n    \"\"\"\n    allowed = {x.lower() for x in allowed}\n    headers[:] = [\n        (key, value)\n        for key, value in headers\n        if not is_entity_header(key) or key.lower() in allowed\n    ]\n\n\ndef remove_hop_by_hop_headers(headers: ds.Headers | list[tuple[str, str]]) -> None:\n    \"\"\"Remove all HTTP/1.1 \"Hop-by-Hop\" headers from a list or\n    :class:`Headers` object.  This operation works in-place.\n\n    .. versionadded:: 0.5\n\n    :param headers: a list or :class:`Headers` object.\n    \"\"\"\n    headers[:] = [\n        (key, value) for key, value in headers if not is_hop_by_hop_header(key)\n    ]\n\n\ndef is_entity_header(header: str) -> bool:\n    \"\"\"Check if a header is an entity header.\n\n    .. versionadded:: 0.5\n\n    :param header: the header to test.\n    :return: `True` if it's an entity header, `False` otherwise.\n    \"\"\"\n    return header.lower() in _entity_headers\n\n\ndef is_hop_by_hop_header(header: str) -> bool:\n    \"\"\"Check if a header is an HTTP/1.1 \"Hop-by-Hop\" header.\n\n    .. versionadded:: 0.5\n\n    :param header: the header to test.\n    :return: `True` if it's an HTTP/1.1 \"Hop-by-Hop\" header, `False` otherwise.\n    \"\"\"\n    return header.lower() in _hop_by_hop_headers\n\n\ndef parse_cookie(\n    header: WSGIEnvironment | str | None,\n    cls: type[ds.MultiDict[str, str]] | None = None,\n) -> ds.MultiDict[str, str]:\n    \"\"\"Parse a cookie from a string or WSGI environ.\n\n    The same key can be provided multiple times, the values are stored\n    in-order. The default :class:`MultiDict` will have the first value\n    first, and all values can be retrieved with\n    :meth:`MultiDict.getlist`.\n\n    :param header: The cookie header as a string, or a WSGI environ dict\n        with a ``HTTP_COOKIE`` key.\n    :param cls: A dict-like class to store the parsed cookies in.\n        Defaults to :class:`MultiDict`.\n\n    .. versionchanged:: 3.0\n        Passing bytes, and the ``charset`` and ``errors`` parameters, were removed.\n\n    .. versionchanged:: 1.0\n        Returns a :class:`MultiDict` instead of a ``TypeConversionDict``.\n\n    .. versionchanged:: 0.5\n        Returns a :class:`TypeConversionDict` instead of a regular dict. The ``cls``\n        parameter was added.\n    \"\"\"\n    if isinstance(header, dict):\n        cookie = header.get(\"HTTP_COOKIE\")\n    else:\n        cookie = header\n\n    if cookie:\n        cookie = cookie.encode(\"latin1\").decode()\n\n    return _sansio_http.parse_cookie(cookie=cookie, cls=cls)\n\n\n_cookie_no_quote_re = re.compile(r\"[\\w!#$%&'()*+\\-./:<=>?@\\[\\]^`{|}~]*\", re.A)\n_cookie_slash_re = re.compile(rb\"[\\x00-\\x19\\\",;\\\\\\x7f-\\xff]\", re.A)\n_cookie_slash_map = {b'\"': b'\\\\\"', b\"\\\\\": b\"\\\\\\\\\"}\n_cookie_slash_map.update(\n    (v.to_bytes(1, \"big\"), b\"\\\\%03o\" % v)\n    for v in [*range(0x20), *b\",;\", *range(0x7F, 256)]\n)\n\n\ndef dump_cookie(\n    key: str,\n    value: str = \"\",\n    max_age: timedelta | int | None = None,\n    expires: str | datetime | int | float | None = None,\n    path: str | None = \"/\",\n    domain: str | None = None,\n    secure: bool = False,\n    httponly: bool = False,\n    sync_expires: bool = True,\n    max_size: int = 4093,\n    samesite: str | None = None,\n    partitioned: bool = False,\n) -> str:\n    \"\"\"Create a Set-Cookie header without the ``Set-Cookie`` prefix.\n\n    The return value is usually restricted to ascii as the vast majority\n    of values are properly escaped, but that is no guarantee. It's\n    tunneled through latin1 as required by :pep:`3333`.\n\n    The return value is not ASCII safe if the key contains unicode\n    characters.  This is technically against the specification but\n    happens in the wild.  It's strongly recommended to not use\n    non-ASCII values for the keys.\n\n    :param max_age: should be a number of seconds, or `None` (default) if\n                    the cookie should last only as long as the client's\n                    browser session.  Additionally `timedelta` objects\n                    are accepted, too.\n    :param expires: should be a `datetime` object or unix timestamp.\n    :param path: limits the cookie to a given path, per default it will\n                 span the whole domain.\n    :param domain: Use this if you want to set a cross-domain cookie. For\n                   example, ``domain=\"example.com\"`` will set a cookie\n                   that is readable by the domain ``www.example.com``,\n                   ``foo.example.com`` etc. Otherwise, a cookie will only\n                   be readable by the domain that set it.\n    :param secure: The cookie will only be available via HTTPS\n    :param httponly: disallow JavaScript to access the cookie.  This is an\n                     extension to the cookie standard and probably not\n                     supported by all browsers.\n    :param charset: the encoding for string values.\n    :param sync_expires: automatically set expires if max_age is defined\n                         but expires not.\n    :param max_size: Warn if the final header value exceeds this size. The\n        default, 4093, should be safely `supported by most browsers\n        <cookie_>`_. Set to 0 to disable this check.\n    :param samesite: Limits the scope of the cookie such that it will\n        only be attached to requests if those requests are same-site.\n    :param partitioned: Opts the cookie into partitioned storage. This\n        will also set secure to True\n\n    .. _`cookie`: http://browsercookielimits.squawky.net/\n\n    .. versionchanged:: 3.1\n        The ``partitioned`` parameter was added.\n\n    .. versionchanged:: 3.0\n        Passing bytes, and the ``charset`` parameter, were removed.\n\n    .. versionchanged:: 2.3.3\n        The ``path`` parameter is ``/`` by default.\n\n    .. versionchanged:: 2.3.1\n        The value allows more characters without quoting.\n\n    .. versionchanged:: 2.3\n        ``localhost`` and other names without a dot are allowed for the domain. A\n        leading dot is ignored.\n\n    .. versionchanged:: 2.3\n        The ``path`` parameter is ``None`` by default.\n\n    .. versionchanged:: 1.0.0\n        The string ``'None'`` is accepted for ``samesite``.\n    \"\"\"\n    if path is not None:\n        # safe = https://url.spec.whatwg.org/#url-path-segment-string\n        # as well as percent for things that are already quoted\n        # excluding semicolon since it's part of the header syntax\n        path = quote(path, safe=\"%!$&'()*+,/:=@\")\n\n    if domain:\n        domain = domain.partition(\":\")[0].lstrip(\".\").encode(\"idna\").decode(\"ascii\")\n\n    if isinstance(max_age, timedelta):\n        max_age = int(max_age.total_seconds())\n\n    if expires is not None:\n        if not isinstance(expires, str):\n            expires = http_date(expires)\n    elif max_age is not None and sync_expires:\n        expires = http_date(datetime.now(tz=timezone.utc).timestamp() + max_age)\n\n    if samesite is not None:\n        samesite = samesite.title()\n\n        if samesite not in {\"Strict\", \"Lax\", \"None\"}:\n            raise ValueError(\"SameSite must be 'Strict', 'Lax', or 'None'.\")\n\n    if partitioned:\n        secure = True\n\n    # Quote value if it contains characters not allowed by RFC 6265. Slash-escape with\n    # three octal digits, which matches http.cookies, although the RFC suggests base64.\n    if not _cookie_no_quote_re.fullmatch(value):\n        # Work with bytes here, since a UTF-8 character could be multiple bytes.\n        value = _cookie_slash_re.sub(\n            lambda m: _cookie_slash_map[m.group()], value.encode()\n        ).decode(\"ascii\")\n        value = f'\"{value}\"'\n\n    # Send a non-ASCII key as mojibake. Everything else should already be ASCII.\n    # TODO Remove encoding dance, it seems like clients accept UTF-8 keys\n    buf = [f\"{key.encode().decode('latin1')}={value}\"]\n\n    for k, v in (\n        (\"Domain\", domain),\n        (\"Expires\", expires),\n        (\"Max-Age\", max_age),\n        (\"Secure\", secure),\n        (\"HttpOnly\", httponly),\n        (\"Path\", path),\n        (\"SameSite\", samesite),\n        (\"Partitioned\", partitioned),\n    ):\n        if v is None or v is False:\n            continue\n\n        if v is True:\n            buf.append(k)\n            continue\n\n        buf.append(f\"{k}={v}\")\n\n    rv = \"; \".join(buf)\n\n    # Warn if the final value of the cookie is larger than the limit. If the cookie is\n    # too large, then it may be silently ignored by the browser, which can be quite hard\n    # to debug.\n    cookie_size = len(rv)\n\n    if max_size and cookie_size > max_size:\n        value_size = len(value)\n        warnings.warn(\n            f\"The '{key}' cookie is too large: the value was {value_size} bytes but the\"\n            f\" header required {cookie_size - value_size} extra bytes. The final size\"\n            f\" was {cookie_size} bytes but the limit is {max_size} bytes. Browsers may\"\n            \" silently ignore cookies larger than this.\",\n            stacklevel=2,\n        )\n\n    return rv\n\n\ndef is_byte_range_valid(\n    start: int | None, stop: int | None, length: int | None\n) -> bool:\n    \"\"\"Checks if a given byte content range is valid for the given length.\n\n    .. versionadded:: 0.7\n    \"\"\"\n    if (start is None) != (stop is None):\n        return False\n    elif start is None:\n        return length is None or length >= 0\n    elif length is None:\n        return 0 <= start < stop  # type: ignore\n    elif start >= stop:  # type: ignore\n        return False\n    return 0 <= start < length\n\n\n# circular dependencies\nfrom . import datastructures as ds\nfrom .sansio import http as _sansio_http\n", "src/werkzeug/exceptions.py": "\"\"\"Implements a number of Python exceptions which can be raised from within\na view to trigger a standard HTTP non-200 response.\n\nUsage Example\n-------------\n\n.. code-block:: python\n\n    from werkzeug.wrappers.request import Request\n    from werkzeug.exceptions import HTTPException, NotFound\n\n    def view(request):\n        raise NotFound()\n\n    @Request.application\n    def application(request):\n        try:\n            return view(request)\n        except HTTPException as e:\n            return e\n\nAs you can see from this example those exceptions are callable WSGI\napplications. However, they are not Werkzeug response objects. You\ncan get a response object by calling ``get_response()`` on a HTTP\nexception.\n\nKeep in mind that you may have to pass an environ (WSGI) or scope\n(ASGI) to ``get_response()`` because some errors fetch additional\ninformation relating to the request.\n\nIf you want to hook in a different exception page to say, a 404 status\ncode, you can add a second except for a specific subclass of an error:\n\n.. code-block:: python\n\n    @Request.application\n    def application(request):\n        try:\n            return view(request)\n        except NotFound as e:\n            return not_found(request)\n        except HTTPException as e:\n            return e\n\n\"\"\"\n\nfrom __future__ import annotations\n\nimport typing as t\nfrom datetime import datetime\n\nfrom markupsafe import escape\nfrom markupsafe import Markup\n\nfrom ._internal import _get_environ\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import StartResponse\n    from _typeshed.wsgi import WSGIEnvironment\n\n    from .datastructures import WWWAuthenticate\n    from .sansio.response import Response\n    from .wrappers.request import Request as WSGIRequest\n    from .wrappers.response import Response as WSGIResponse\n\n\nclass HTTPException(Exception):\n    \"\"\"The base class for all HTTP exceptions. This exception can be called as a WSGI\n    application to render a default error page or you can catch the subclasses\n    of it independently and render nicer error messages.\n\n    .. versionchanged:: 2.1\n        Removed the ``wrap`` class method.\n    \"\"\"\n\n    code: int | None = None\n    description: str | None = None\n\n    def __init__(\n        self,\n        description: str | None = None,\n        response: Response | None = None,\n    ) -> None:\n        super().__init__()\n        if description is not None:\n            self.description = description\n        self.response = response\n\n    @property\n    def name(self) -> str:\n        \"\"\"The status name.\"\"\"\n        from .http import HTTP_STATUS_CODES\n\n        return HTTP_STATUS_CODES.get(self.code, \"Unknown Error\")  # type: ignore\n\n    def get_description(\n        self,\n        environ: WSGIEnvironment | None = None,\n        scope: dict[str, t.Any] | None = None,\n    ) -> str:\n        \"\"\"Get the description.\"\"\"\n        if self.description is None:\n            description = \"\"\n        else:\n            description = self.description\n\n        description = escape(description).replace(\"\\n\", Markup(\"<br>\"))\n        return f\"<p>{description}</p>\"\n\n    def get_body(\n        self,\n        environ: WSGIEnvironment | None = None,\n        scope: dict[str, t.Any] | None = None,\n    ) -> str:\n        \"\"\"Get the HTML body.\"\"\"\n        return (\n            \"<!doctype html>\\n\"\n            \"<html lang=en>\\n\"\n            f\"<title>{self.code} {escape(self.name)}</title>\\n\"\n            f\"<h1>{escape(self.name)}</h1>\\n\"\n            f\"{self.get_description(environ)}\\n\"\n        )\n\n    def get_headers(\n        self,\n        environ: WSGIEnvironment | None = None,\n        scope: dict[str, t.Any] | None = None,\n    ) -> list[tuple[str, str]]:\n        \"\"\"Get a list of headers.\"\"\"\n        return [(\"Content-Type\", \"text/html; charset=utf-8\")]\n\n    def get_response(\n        self,\n        environ: WSGIEnvironment | WSGIRequest | None = None,\n        scope: dict[str, t.Any] | None = None,\n    ) -> Response:\n        \"\"\"Get a response object.  If one was passed to the exception\n        it's returned directly.\n\n        :param environ: the optional environ for the request.  This\n                        can be used to modify the response depending\n                        on how the request looked like.\n        :return: a :class:`Response` object or a subclass thereof.\n        \"\"\"\n        from .wrappers.response import Response as WSGIResponse  # noqa: F811\n\n        if self.response is not None:\n            return self.response\n        if environ is not None:\n            environ = _get_environ(environ)\n        headers = self.get_headers(environ, scope)\n        return WSGIResponse(self.get_body(environ, scope), self.code, headers)\n\n    def __call__(\n        self, environ: WSGIEnvironment, start_response: StartResponse\n    ) -> t.Iterable[bytes]:\n        \"\"\"Call the exception as WSGI application.\n\n        :param environ: the WSGI environment.\n        :param start_response: the response callable provided by the WSGI\n                               server.\n        \"\"\"\n        response = t.cast(\"WSGIResponse\", self.get_response(environ))\n        return response(environ, start_response)\n\n    def __str__(self) -> str:\n        code = self.code if self.code is not None else \"???\"\n        return f\"{code} {self.name}: {self.description}\"\n\n    def __repr__(self) -> str:\n        code = self.code if self.code is not None else \"???\"\n        return f\"<{type(self).__name__} '{code}: {self.name}'>\"\n\n\nclass BadRequest(HTTPException):\n    \"\"\"*400* `Bad Request`\n\n    Raise if the browser sends something to the application the application\n    or server cannot handle.\n    \"\"\"\n\n    code = 400\n    description = (\n        \"The browser (or proxy) sent a request that this server could \"\n        \"not understand.\"\n    )\n\n\nclass BadRequestKeyError(BadRequest, KeyError):\n    \"\"\"An exception that is used to signal both a :exc:`KeyError` and a\n    :exc:`BadRequest`. Used by many of the datastructures.\n    \"\"\"\n\n    _description = BadRequest.description\n    #: Show the KeyError along with the HTTP error message in the\n    #: response. This should be disabled in production, but can be\n    #: useful in a debug mode.\n    show_exception = False\n\n    def __init__(self, arg: str | None = None, *args: t.Any, **kwargs: t.Any):\n        super().__init__(*args, **kwargs)\n\n        if arg is None:\n            KeyError.__init__(self)\n        else:\n            KeyError.__init__(self, arg)\n\n    @property  # type: ignore\n    def description(self) -> str:\n        if self.show_exception:\n            return (\n                f\"{self._description}\\n\"\n                f\"{KeyError.__name__}: {KeyError.__str__(self)}\"\n            )\n\n        return self._description\n\n    @description.setter\n    def description(self, value: str) -> None:\n        self._description = value\n\n\nclass ClientDisconnected(BadRequest):\n    \"\"\"Internal exception that is raised if Werkzeug detects a disconnected\n    client.  Since the client is already gone at that point attempting to\n    send the error message to the client might not work and might ultimately\n    result in another exception in the server.  Mainly this is here so that\n    it is silenced by default as far as Werkzeug is concerned.\n\n    Since disconnections cannot be reliably detected and are unspecified\n    by WSGI to a large extent this might or might not be raised if a client\n    is gone.\n\n    .. versionadded:: 0.8\n    \"\"\"\n\n\nclass SecurityError(BadRequest):\n    \"\"\"Raised if something triggers a security error.  This is otherwise\n    exactly like a bad request error.\n\n    .. versionadded:: 0.9\n    \"\"\"\n\n\nclass BadHost(BadRequest):\n    \"\"\"Raised if the submitted host is badly formatted.\n\n    .. versionadded:: 0.11.2\n    \"\"\"\n\n\nclass Unauthorized(HTTPException):\n    \"\"\"*401* ``Unauthorized``\n\n    Raise if the user is not authorized to access a resource.\n\n    The ``www_authenticate`` argument should be used to set the\n    ``WWW-Authenticate`` header. This is used for HTTP basic auth and\n    other schemes. Use :class:`~werkzeug.datastructures.WWWAuthenticate`\n    to create correctly formatted values. Strictly speaking a 401\n    response is invalid if it doesn't provide at least one value for\n    this header, although real clients typically don't care.\n\n    :param description: Override the default message used for the body\n        of the response.\n    :param www-authenticate: A single value, or list of values, for the\n        WWW-Authenticate header(s).\n\n    .. versionchanged:: 2.0\n        Serialize multiple ``www_authenticate`` items into multiple\n        ``WWW-Authenticate`` headers, rather than joining them\n        into a single value, for better interoperability.\n\n    .. versionchanged:: 0.15.3\n        If the ``www_authenticate`` argument is not set, the\n        ``WWW-Authenticate`` header is not set.\n\n    .. versionchanged:: 0.15.3\n        The ``response`` argument was restored.\n\n    .. versionchanged:: 0.15.1\n        ``description`` was moved back as the first argument, restoring\n         its previous position.\n\n    .. versionchanged:: 0.15.0\n        ``www_authenticate`` was added as the first argument, ahead of\n        ``description``.\n    \"\"\"\n\n    code = 401\n    description = (\n        \"The server could not verify that you are authorized to access\"\n        \" the URL requested. You either supplied the wrong credentials\"\n        \" (e.g. a bad password), or your browser doesn't understand\"\n        \" how to supply the credentials required.\"\n    )\n\n    def __init__(\n        self,\n        description: str | None = None,\n        response: Response | None = None,\n        www_authenticate: None | (WWWAuthenticate | t.Iterable[WWWAuthenticate]) = None,\n    ) -> None:\n        super().__init__(description, response)\n\n        from .datastructures import WWWAuthenticate\n\n        if isinstance(www_authenticate, WWWAuthenticate):\n            www_authenticate = (www_authenticate,)\n\n        self.www_authenticate = www_authenticate\n\n    def get_headers(\n        self,\n        environ: WSGIEnvironment | None = None,\n        scope: dict[str, t.Any] | None = None,\n    ) -> list[tuple[str, str]]:\n        headers = super().get_headers(environ, scope)\n        if self.www_authenticate:\n            headers.extend((\"WWW-Authenticate\", str(x)) for x in self.www_authenticate)\n        return headers\n\n\nclass Forbidden(HTTPException):\n    \"\"\"*403* `Forbidden`\n\n    Raise if the user doesn't have the permission for the requested resource\n    but was authenticated.\n    \"\"\"\n\n    code = 403\n    description = (\n        \"You don't have the permission to access the requested\"\n        \" resource. It is either read-protected or not readable by the\"\n        \" server.\"\n    )\n\n\nclass NotFound(HTTPException):\n    \"\"\"*404* `Not Found`\n\n    Raise if a resource does not exist and never existed.\n    \"\"\"\n\n    code = 404\n    description = (\n        \"The requested URL was not found on the server. If you entered\"\n        \" the URL manually please check your spelling and try again.\"\n    )\n\n\nclass MethodNotAllowed(HTTPException):\n    \"\"\"*405* `Method Not Allowed`\n\n    Raise if the server used a method the resource does not handle.  For\n    example `POST` if the resource is view only.  Especially useful for REST.\n\n    The first argument for this exception should be a list of allowed methods.\n    Strictly speaking the response would be invalid if you don't provide valid\n    methods in the header which you can do with that list.\n    \"\"\"\n\n    code = 405\n    description = \"The method is not allowed for the requested URL.\"\n\n    def __init__(\n        self,\n        valid_methods: t.Iterable[str] | None = None,\n        description: str | None = None,\n        response: Response | None = None,\n    ) -> None:\n        \"\"\"Takes an optional list of valid http methods\n        starting with werkzeug 0.3 the list will be mandatory.\"\"\"\n        super().__init__(description=description, response=response)\n        self.valid_methods = valid_methods\n\n    def get_headers(\n        self,\n        environ: WSGIEnvironment | None = None,\n        scope: dict[str, t.Any] | None = None,\n    ) -> list[tuple[str, str]]:\n        headers = super().get_headers(environ, scope)\n        if self.valid_methods:\n            headers.append((\"Allow\", \", \".join(self.valid_methods)))\n        return headers\n\n\nclass NotAcceptable(HTTPException):\n    \"\"\"*406* `Not Acceptable`\n\n    Raise if the server can't return any content conforming to the\n    `Accept` headers of the client.\n    \"\"\"\n\n    code = 406\n    description = (\n        \"The resource identified by the request is only capable of\"\n        \" generating response entities which have content\"\n        \" characteristics not acceptable according to the accept\"\n        \" headers sent in the request.\"\n    )\n\n\nclass RequestTimeout(HTTPException):\n    \"\"\"*408* `Request Timeout`\n\n    Raise to signalize a timeout.\n    \"\"\"\n\n    code = 408\n    description = (\n        \"The server closed the network connection because the browser\"\n        \" didn't finish the request within the specified time.\"\n    )\n\n\nclass Conflict(HTTPException):\n    \"\"\"*409* `Conflict`\n\n    Raise to signal that a request cannot be completed because it conflicts\n    with the current state on the server.\n\n    .. versionadded:: 0.7\n    \"\"\"\n\n    code = 409\n    description = (\n        \"A conflict happened while processing the request. The\"\n        \" resource might have been modified while the request was being\"\n        \" processed.\"\n    )\n\n\nclass Gone(HTTPException):\n    \"\"\"*410* `Gone`\n\n    Raise if a resource existed previously and went away without new location.\n    \"\"\"\n\n    code = 410\n    description = (\n        \"The requested URL is no longer available on this server and\"\n        \" there is no forwarding address. If you followed a link from a\"\n        \" foreign page, please contact the author of this page.\"\n    )\n\n\nclass LengthRequired(HTTPException):\n    \"\"\"*411* `Length Required`\n\n    Raise if the browser submitted data but no ``Content-Length`` header which\n    is required for the kind of processing the server does.\n    \"\"\"\n\n    code = 411\n    description = (\n        \"A request with this method requires a valid <code>Content-\"\n        \"Length</code> header.\"\n    )\n\n\nclass PreconditionFailed(HTTPException):\n    \"\"\"*412* `Precondition Failed`\n\n    Status code used in combination with ``If-Match``, ``If-None-Match``, or\n    ``If-Unmodified-Since``.\n    \"\"\"\n\n    code = 412\n    description = (\n        \"The precondition on the request for the URL failed positive evaluation.\"\n    )\n\n\nclass RequestEntityTooLarge(HTTPException):\n    \"\"\"*413* `Request Entity Too Large`\n\n    The status code one should return if the data submitted exceeded a given\n    limit.\n    \"\"\"\n\n    code = 413\n    description = \"The data value transmitted exceeds the capacity limit.\"\n\n\nclass RequestURITooLarge(HTTPException):\n    \"\"\"*414* `Request URI Too Large`\n\n    Like *413* but for too long URLs.\n    \"\"\"\n\n    code = 414\n    description = (\n        \"The length of the requested URL exceeds the capacity limit for\"\n        \" this server. The request cannot be processed.\"\n    )\n\n\nclass UnsupportedMediaType(HTTPException):\n    \"\"\"*415* `Unsupported Media Type`\n\n    The status code returned if the server is unable to handle the media type\n    the client transmitted.\n    \"\"\"\n\n    code = 415\n    description = (\n        \"The server does not support the media type transmitted in the request.\"\n    )\n\n\nclass RequestedRangeNotSatisfiable(HTTPException):\n    \"\"\"*416* `Requested Range Not Satisfiable`\n\n    The client asked for an invalid part of the file.\n\n    .. versionadded:: 0.7\n    \"\"\"\n\n    code = 416\n    description = \"The server cannot provide the requested range.\"\n\n    def __init__(\n        self,\n        length: int | None = None,\n        units: str = \"bytes\",\n        description: str | None = None,\n        response: Response | None = None,\n    ) -> None:\n        \"\"\"Takes an optional `Content-Range` header value based on ``length``\n        parameter.\n        \"\"\"\n        super().__init__(description=description, response=response)\n        self.length = length\n        self.units = units\n\n    def get_headers(\n        self,\n        environ: WSGIEnvironment | None = None,\n        scope: dict[str, t.Any] | None = None,\n    ) -> list[tuple[str, str]]:\n        headers = super().get_headers(environ, scope)\n        if self.length is not None:\n            headers.append((\"Content-Range\", f\"{self.units} */{self.length}\"))\n        return headers\n\n\nclass ExpectationFailed(HTTPException):\n    \"\"\"*417* `Expectation Failed`\n\n    The server cannot meet the requirements of the Expect request-header.\n\n    .. versionadded:: 0.7\n    \"\"\"\n\n    code = 417\n    description = \"The server could not meet the requirements of the Expect header\"\n\n\nclass ImATeapot(HTTPException):\n    \"\"\"*418* `I'm a teapot`\n\n    The server should return this if it is a teapot and someone attempted\n    to brew coffee with it.\n\n    .. versionadded:: 0.7\n    \"\"\"\n\n    code = 418\n    description = \"This server is a teapot, not a coffee machine\"\n\n\nclass UnprocessableEntity(HTTPException):\n    \"\"\"*422* `Unprocessable Entity`\n\n    Used if the request is well formed, but the instructions are otherwise\n    incorrect.\n    \"\"\"\n\n    code = 422\n    description = (\n        \"The request was well-formed but was unable to be followed due\"\n        \" to semantic errors.\"\n    )\n\n\nclass Locked(HTTPException):\n    \"\"\"*423* `Locked`\n\n    Used if the resource that is being accessed is locked.\n    \"\"\"\n\n    code = 423\n    description = \"The resource that is being accessed is locked.\"\n\n\nclass FailedDependency(HTTPException):\n    \"\"\"*424* `Failed Dependency`\n\n    Used if the method could not be performed on the resource\n    because the requested action depended on another action and that action failed.\n    \"\"\"\n\n    code = 424\n    description = (\n        \"The method could not be performed on the resource because the\"\n        \" requested action depended on another action and that action\"\n        \" failed.\"\n    )\n\n\nclass PreconditionRequired(HTTPException):\n    \"\"\"*428* `Precondition Required`\n\n    The server requires this request to be conditional, typically to prevent\n    the lost update problem, which is a race condition between two or more\n    clients attempting to update a resource through PUT or DELETE. By requiring\n    each client to include a conditional header (\"If-Match\" or \"If-Unmodified-\n    Since\") with the proper value retained from a recent GET request, the\n    server ensures that each client has at least seen the previous revision of\n    the resource.\n    \"\"\"\n\n    code = 428\n    description = (\n        \"This request is required to be conditional; try using\"\n        ' \"If-Match\" or \"If-Unmodified-Since\".'\n    )\n\n\nclass _RetryAfter(HTTPException):\n    \"\"\"Adds an optional ``retry_after`` parameter which will set the\n    ``Retry-After`` header. May be an :class:`int` number of seconds or\n    a :class:`~datetime.datetime`.\n    \"\"\"\n\n    def __init__(\n        self,\n        description: str | None = None,\n        response: Response | None = None,\n        retry_after: datetime | int | None = None,\n    ) -> None:\n        super().__init__(description, response)\n        self.retry_after = retry_after\n\n    def get_headers(\n        self,\n        environ: WSGIEnvironment | None = None,\n        scope: dict[str, t.Any] | None = None,\n    ) -> list[tuple[str, str]]:\n        headers = super().get_headers(environ, scope)\n\n        if self.retry_after:\n            if isinstance(self.retry_after, datetime):\n                from .http import http_date\n\n                value = http_date(self.retry_after)\n            else:\n                value = str(self.retry_after)\n\n            headers.append((\"Retry-After\", value))\n\n        return headers\n\n\nclass TooManyRequests(_RetryAfter):\n    \"\"\"*429* `Too Many Requests`\n\n    The server is limiting the rate at which this user receives\n    responses, and this request exceeds that rate. (The server may use\n    any convenient method to identify users and their request rates).\n    The server may include a \"Retry-After\" header to indicate how long\n    the user should wait before retrying.\n\n    :param retry_after: If given, set the ``Retry-After`` header to this\n        value. May be an :class:`int` number of seconds or a\n        :class:`~datetime.datetime`.\n\n    .. versionchanged:: 1.0\n        Added ``retry_after`` parameter.\n    \"\"\"\n\n    code = 429\n    description = \"This user has exceeded an allotted request count. Try again later.\"\n\n\nclass RequestHeaderFieldsTooLarge(HTTPException):\n    \"\"\"*431* `Request Header Fields Too Large`\n\n    The server refuses to process the request because the header fields are too\n    large. One or more individual fields may be too large, or the set of all\n    headers is too large.\n    \"\"\"\n\n    code = 431\n    description = \"One or more header fields exceeds the maximum size.\"\n\n\nclass UnavailableForLegalReasons(HTTPException):\n    \"\"\"*451* `Unavailable For Legal Reasons`\n\n    This status code indicates that the server is denying access to the\n    resource as a consequence of a legal demand.\n    \"\"\"\n\n    code = 451\n    description = \"Unavailable for legal reasons.\"\n\n\nclass InternalServerError(HTTPException):\n    \"\"\"*500* `Internal Server Error`\n\n    Raise if an internal server error occurred.  This is a good fallback if an\n    unknown error occurred in the dispatcher.\n\n    .. versionchanged:: 1.0.0\n        Added the :attr:`original_exception` attribute.\n    \"\"\"\n\n    code = 500\n    description = (\n        \"The server encountered an internal error and was unable to\"\n        \" complete your request. Either the server is overloaded or\"\n        \" there is an error in the application.\"\n    )\n\n    def __init__(\n        self,\n        description: str | None = None,\n        response: Response | None = None,\n        original_exception: BaseException | None = None,\n    ) -> None:\n        #: The original exception that caused this 500 error. Can be\n        #: used by frameworks to provide context when handling\n        #: unexpected errors.\n        self.original_exception = original_exception\n        super().__init__(description=description, response=response)\n\n\nclass NotImplemented(HTTPException):\n    \"\"\"*501* `Not Implemented`\n\n    Raise if the application does not support the action requested by the\n    browser.\n    \"\"\"\n\n    code = 501\n    description = \"The server does not support the action requested by the browser.\"\n\n\nclass BadGateway(HTTPException):\n    \"\"\"*502* `Bad Gateway`\n\n    If you do proxying in your application you should return this status code\n    if you received an invalid response from the upstream server it accessed\n    in attempting to fulfill the request.\n    \"\"\"\n\n    code = 502\n    description = (\n        \"The proxy server received an invalid response from an upstream server.\"\n    )\n\n\nclass ServiceUnavailable(_RetryAfter):\n    \"\"\"*503* `Service Unavailable`\n\n    Status code you should return if a service is temporarily\n    unavailable.\n\n    :param retry_after: If given, set the ``Retry-After`` header to this\n        value. May be an :class:`int` number of seconds or a\n        :class:`~datetime.datetime`.\n\n    .. versionchanged:: 1.0\n        Added ``retry_after`` parameter.\n    \"\"\"\n\n    code = 503\n    description = (\n        \"The server is temporarily unable to service your request due\"\n        \" to maintenance downtime or capacity problems. Please try\"\n        \" again later.\"\n    )\n\n\nclass GatewayTimeout(HTTPException):\n    \"\"\"*504* `Gateway Timeout`\n\n    Status code you should return if a connection to an upstream server\n    times out.\n    \"\"\"\n\n    code = 504\n    description = \"The connection to an upstream server timed out.\"\n\n\nclass HTTPVersionNotSupported(HTTPException):\n    \"\"\"*505* `HTTP Version Not Supported`\n\n    The server does not support the HTTP protocol version used in the request.\n    \"\"\"\n\n    code = 505\n    description = (\n        \"The server does not support the HTTP protocol version used in the request.\"\n    )\n\n\ndefault_exceptions: dict[int, type[HTTPException]] = {}\n\n\ndef _find_exceptions() -> None:\n    for obj in globals().values():\n        try:\n            is_http_exception = issubclass(obj, HTTPException)\n        except TypeError:\n            is_http_exception = False\n        if not is_http_exception or obj.code is None:\n            continue\n        old_obj = default_exceptions.get(obj.code, None)\n        if old_obj is not None and issubclass(obj, old_obj):\n            continue\n        default_exceptions[obj.code] = obj\n\n\n_find_exceptions()\ndel _find_exceptions\n\n\nclass Aborter:\n    \"\"\"When passed a dict of code -> exception items it can be used as\n    callable that raises exceptions.  If the first argument to the\n    callable is an integer it will be looked up in the mapping, if it's\n    a WSGI application it will be raised in a proxy exception.\n\n    The rest of the arguments are forwarded to the exception constructor.\n    \"\"\"\n\n    def __init__(\n        self,\n        mapping: dict[int, type[HTTPException]] | None = None,\n        extra: dict[int, type[HTTPException]] | None = None,\n    ) -> None:\n        if mapping is None:\n            mapping = default_exceptions\n        self.mapping = dict(mapping)\n        if extra is not None:\n            self.mapping.update(extra)\n\n    def __call__(\n        self, code: int | Response, *args: t.Any, **kwargs: t.Any\n    ) -> t.NoReturn:\n        from .sansio.response import Response\n\n        if isinstance(code, Response):\n            raise HTTPException(response=code)\n\n        if code not in self.mapping:\n            raise LookupError(f\"no exception for {code!r}\")\n\n        raise self.mapping[code](*args, **kwargs)\n\n\ndef abort(status: int | Response, *args: t.Any, **kwargs: t.Any) -> t.NoReturn:\n    \"\"\"Raises an :py:exc:`HTTPException` for the given status code or WSGI\n    application.\n\n    If a status code is given, it will be looked up in the list of\n    exceptions and will raise that exception.  If passed a WSGI application,\n    it will wrap it in a proxy WSGI exception and raise that::\n\n       abort(404)  # 404 Not Found\n       abort(Response('Hello World'))\n\n    \"\"\"\n    _aborter(status, *args, **kwargs)\n\n\n_aborter: Aborter = Aborter()\n", "src/werkzeug/security.py": "from __future__ import annotations\n\nimport hashlib\nimport hmac\nimport os\nimport posixpath\nimport secrets\n\nSALT_CHARS = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\"\nDEFAULT_PBKDF2_ITERATIONS = 600000\n\n_os_alt_seps: list[str] = list(\n    sep for sep in [os.sep, os.path.altsep] if sep is not None and sep != \"/\"\n)\n\n\ndef gen_salt(length: int) -> str:\n    \"\"\"Generate a random string of SALT_CHARS with specified ``length``.\"\"\"\n    if length <= 0:\n        raise ValueError(\"Salt length must be at least 1.\")\n\n    return \"\".join(secrets.choice(SALT_CHARS) for _ in range(length))\n\n\ndef _hash_internal(method: str, salt: str, password: str) -> tuple[str, str]:\n    method, *args = method.split(\":\")\n    salt_bytes = salt.encode()\n    password_bytes = password.encode()\n\n    if method == \"scrypt\":\n        if not args:\n            n = 2**15\n            r = 8\n            p = 1\n        else:\n            try:\n                n, r, p = map(int, args)\n            except ValueError:\n                raise ValueError(\"'scrypt' takes 3 arguments.\") from None\n\n        maxmem = 132 * n * r * p  # ideally 128, but some extra seems needed\n        return (\n            hashlib.scrypt(\n                password_bytes, salt=salt_bytes, n=n, r=r, p=p, maxmem=maxmem\n            ).hex(),\n            f\"scrypt:{n}:{r}:{p}\",\n        )\n    elif method == \"pbkdf2\":\n        len_args = len(args)\n\n        if len_args == 0:\n            hash_name = \"sha256\"\n            iterations = DEFAULT_PBKDF2_ITERATIONS\n        elif len_args == 1:\n            hash_name = args[0]\n            iterations = DEFAULT_PBKDF2_ITERATIONS\n        elif len_args == 2:\n            hash_name = args[0]\n            iterations = int(args[1])\n        else:\n            raise ValueError(\"'pbkdf2' takes 2 arguments.\")\n\n        return (\n            hashlib.pbkdf2_hmac(\n                hash_name, password_bytes, salt_bytes, iterations\n            ).hex(),\n            f\"pbkdf2:{hash_name}:{iterations}\",\n        )\n    else:\n        raise ValueError(f\"Invalid hash method '{method}'.\")\n\n\ndef generate_password_hash(\n    password: str, method: str = \"scrypt\", salt_length: int = 16\n) -> str:\n    \"\"\"Securely hash a password for storage. A password can be compared to a stored hash\n    using :func:`check_password_hash`.\n\n    The following methods are supported:\n\n    -   ``scrypt``, the default. The parameters are ``n``, ``r``, and ``p``, the default\n        is ``scrypt:32768:8:1``. See :func:`hashlib.scrypt`.\n    -   ``pbkdf2``, less secure. The parameters are ``hash_method`` and ``iterations``,\n        the default is ``pbkdf2:sha256:600000``. See :func:`hashlib.pbkdf2_hmac`.\n\n    Default parameters may be updated to reflect current guidelines, and methods may be\n    deprecated and removed if they are no longer considered secure. To migrate old\n    hashes, you may generate a new hash when checking an old hash, or you may contact\n    users with a link to reset their password.\n\n    :param password: The plaintext password.\n    :param method: The key derivation function and parameters.\n    :param salt_length: The number of characters to generate for the salt.\n\n    .. versionchanged:: 2.3\n        Scrypt support was added.\n\n    .. versionchanged:: 2.3\n        The default iterations for pbkdf2 was increased to 600,000.\n\n    .. versionchanged:: 2.3\n        All plain hashes are deprecated and will not be supported in Werkzeug 3.0.\n    \"\"\"\n    salt = gen_salt(salt_length)\n    h, actual_method = _hash_internal(method, salt, password)\n    return f\"{actual_method}${salt}${h}\"\n\n\ndef check_password_hash(pwhash: str, password: str) -> bool:\n    \"\"\"Securely check that the given stored password hash, previously generated using\n    :func:`generate_password_hash`, matches the given password.\n\n    Methods may be deprecated and removed if they are no longer considered secure. To\n    migrate old hashes, you may generate a new hash when checking an old hash, or you\n    may contact users with a link to reset their password.\n\n    :param pwhash: The hashed password.\n    :param password: The plaintext password.\n\n    .. versionchanged:: 2.3\n        All plain hashes are deprecated and will not be supported in Werkzeug 3.0.\n    \"\"\"\n    try:\n        method, salt, hashval = pwhash.split(\"$\", 2)\n    except ValueError:\n        return False\n\n    return hmac.compare_digest(_hash_internal(method, salt, password)[0], hashval)\n\n\ndef safe_join(directory: str, *pathnames: str) -> str | None:\n    \"\"\"Safely join zero or more untrusted path components to a base\n    directory to avoid escaping the base directory.\n\n    :param directory: The trusted base directory.\n    :param pathnames: The untrusted path components relative to the\n        base directory.\n    :return: A safe path, otherwise ``None``.\n    \"\"\"\n    if not directory:\n        # Ensure we end up with ./path if directory=\"\" is given,\n        # otherwise the first untrusted part could become trusted.\n        directory = \".\"\n\n    parts = [directory]\n\n    for filename in pathnames:\n        if filename != \"\":\n            filename = posixpath.normpath(filename)\n\n        if (\n            any(sep in filename for sep in _os_alt_seps)\n            or os.path.isabs(filename)\n            or filename == \"..\"\n            or filename.startswith(\"../\")\n        ):\n            return None\n\n        parts.append(filename)\n\n    return posixpath.join(*parts)\n", "src/werkzeug/_internal.py": "from __future__ import annotations\n\nimport logging\nimport re\nimport sys\nimport typing as t\nfrom datetime import datetime\nfrom datetime import timezone\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import WSGIEnvironment\n\n    from .wrappers.request import Request\n\n_logger: logging.Logger | None = None\n\n\nclass _Missing:\n    def __repr__(self) -> str:\n        return \"no value\"\n\n    def __reduce__(self) -> str:\n        return \"_missing\"\n\n\n_missing = _Missing()\n\n\ndef _wsgi_decoding_dance(s: str) -> str:\n    return s.encode(\"latin1\").decode(errors=\"replace\")\n\n\ndef _wsgi_encoding_dance(s: str) -> str:\n    return s.encode().decode(\"latin1\")\n\n\ndef _get_environ(obj: WSGIEnvironment | Request) -> WSGIEnvironment:\n    env = getattr(obj, \"environ\", obj)\n    assert isinstance(\n        env, dict\n    ), f\"{type(obj).__name__!r} is not a WSGI environment (has to be a dict)\"\n    return env\n\n\ndef _has_level_handler(logger: logging.Logger) -> bool:\n    \"\"\"Check if there is a handler in the logging chain that will handle\n    the given logger's effective level.\n    \"\"\"\n    level = logger.getEffectiveLevel()\n    current = logger\n\n    while current:\n        if any(handler.level <= level for handler in current.handlers):\n            return True\n\n        if not current.propagate:\n            break\n\n        current = current.parent  # type: ignore\n\n    return False\n\n\nclass _ColorStreamHandler(logging.StreamHandler):  # type: ignore[type-arg]\n    \"\"\"On Windows, wrap stream with Colorama for ANSI style support.\"\"\"\n\n    def __init__(self) -> None:\n        try:\n            import colorama\n        except ImportError:\n            stream = None\n        else:\n            stream = colorama.AnsiToWin32(sys.stderr)\n\n        super().__init__(stream)\n\n\ndef _log(type: str, message: str, *args: t.Any, **kwargs: t.Any) -> None:\n    \"\"\"Log a message to the 'werkzeug' logger.\n\n    The logger is created the first time it is needed. If there is no\n    level set, it is set to :data:`logging.INFO`. If there is no handler\n    for the logger's effective level, a :class:`logging.StreamHandler`\n    is added.\n    \"\"\"\n    global _logger\n\n    if _logger is None:\n        _logger = logging.getLogger(\"werkzeug\")\n\n        if _logger.level == logging.NOTSET:\n            _logger.setLevel(logging.INFO)\n\n        if not _has_level_handler(_logger):\n            _logger.addHandler(_ColorStreamHandler())\n\n    getattr(_logger, type)(message.rstrip(), *args, **kwargs)\n\n\n@t.overload\ndef _dt_as_utc(dt: None) -> None: ...\n\n\n@t.overload\ndef _dt_as_utc(dt: datetime) -> datetime: ...\n\n\ndef _dt_as_utc(dt: datetime | None) -> datetime | None:\n    if dt is None:\n        return dt\n\n    if dt.tzinfo is None:\n        return dt.replace(tzinfo=timezone.utc)\n    elif dt.tzinfo != timezone.utc:\n        return dt.astimezone(timezone.utc)\n\n    return dt\n\n\n_TAccessorValue = t.TypeVar(\"_TAccessorValue\")\n\n\nclass _DictAccessorProperty(t.Generic[_TAccessorValue]):\n    \"\"\"Baseclass for `environ_property` and `header_property`.\"\"\"\n\n    read_only = False\n\n    def __init__(\n        self,\n        name: str,\n        default: _TAccessorValue | None = None,\n        load_func: t.Callable[[str], _TAccessorValue] | None = None,\n        dump_func: t.Callable[[_TAccessorValue], str] | None = None,\n        read_only: bool | None = None,\n        doc: str | None = None,\n    ) -> None:\n        self.name = name\n        self.default = default\n        self.load_func = load_func\n        self.dump_func = dump_func\n        if read_only is not None:\n            self.read_only = read_only\n        self.__doc__ = doc\n\n    def lookup(self, instance: t.Any) -> t.MutableMapping[str, t.Any]:\n        raise NotImplementedError\n\n    @t.overload\n    def __get__(\n        self, instance: None, owner: type\n    ) -> _DictAccessorProperty[_TAccessorValue]: ...\n\n    @t.overload\n    def __get__(self, instance: t.Any, owner: type) -> _TAccessorValue: ...\n\n    def __get__(\n        self, instance: t.Any | None, owner: type\n    ) -> _TAccessorValue | _DictAccessorProperty[_TAccessorValue]:\n        if instance is None:\n            return self\n\n        storage = self.lookup(instance)\n\n        if self.name not in storage:\n            return self.default  # type: ignore\n\n        value = storage[self.name]\n\n        if self.load_func is not None:\n            try:\n                return self.load_func(value)\n            except (ValueError, TypeError):\n                return self.default  # type: ignore\n\n        return value  # type: ignore\n\n    def __set__(self, instance: t.Any, value: _TAccessorValue) -> None:\n        if self.read_only:\n            raise AttributeError(\"read only property\")\n\n        if self.dump_func is not None:\n            self.lookup(instance)[self.name] = self.dump_func(value)\n        else:\n            self.lookup(instance)[self.name] = value\n\n    def __delete__(self, instance: t.Any) -> None:\n        if self.read_only:\n            raise AttributeError(\"read only property\")\n\n        self.lookup(instance).pop(self.name, None)\n\n    def __repr__(self) -> str:\n        return f\"<{type(self).__name__} {self.name}>\"\n\n\n_plain_int_re = re.compile(r\"-?\\d+\", re.ASCII)\n\n\ndef _plain_int(value: str) -> int:\n    \"\"\"Parse an int only if it is only ASCII digits and ``-``.\n\n    This disallows ``+``, ``_``, and non-ASCII digits, which are accepted by ``int`` but\n    are not allowed in HTTP header values.\n\n    Any leading or trailing whitespace is stripped\n    \"\"\"\n    value = value.strip()\n    if _plain_int_re.fullmatch(value) is None:\n        raise ValueError\n\n    return int(value)\n", "src/werkzeug/utils.py": "from __future__ import annotations\n\nimport io\nimport mimetypes\nimport os\nimport pkgutil\nimport re\nimport sys\nimport typing as t\nimport unicodedata\nfrom datetime import datetime\nfrom time import time\nfrom urllib.parse import quote\nfrom zlib import adler32\n\nfrom markupsafe import escape\n\nfrom ._internal import _DictAccessorProperty\nfrom ._internal import _missing\nfrom ._internal import _TAccessorValue\nfrom .datastructures import Headers\nfrom .exceptions import NotFound\nfrom .exceptions import RequestedRangeNotSatisfiable\nfrom .security import safe_join\nfrom .wsgi import wrap_file\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import WSGIEnvironment\n\n    from .wrappers.request import Request\n    from .wrappers.response import Response\n\n_T = t.TypeVar(\"_T\")\n\n_entity_re = re.compile(r\"&([^;]+);\")\n_filename_ascii_strip_re = re.compile(r\"[^A-Za-z0-9_.-]\")\n_windows_device_files = {\n    \"CON\",\n    \"PRN\",\n    \"AUX\",\n    \"NUL\",\n    *(f\"COM{i}\" for i in range(10)),\n    *(f\"LPT{i}\" for i in range(10)),\n}\n\n\nclass cached_property(property, t.Generic[_T]):\n    \"\"\"A :func:`property` that is only evaluated once. Subsequent access\n    returns the cached value. Setting the property sets the cached\n    value. Deleting the property clears the cached value, accessing it\n    again will evaluate it again.\n\n    .. code-block:: python\n\n        class Example:\n            @cached_property\n            def value(self):\n                # calculate something important here\n                return 42\n\n        e = Example()\n        e.value  # evaluates\n        e.value  # uses cache\n        e.value = 16  # sets cache\n        del e.value  # clears cache\n\n    If the class defines ``__slots__``, it must add ``_cache_{name}`` as\n    a slot. Alternatively, it can add ``__dict__``, but that's usually\n    not desirable.\n\n    .. versionchanged:: 2.1\n        Works with ``__slots__``.\n\n    .. versionchanged:: 2.0\n        ``del obj.name`` clears the cached value.\n    \"\"\"\n\n    def __init__(\n        self,\n        fget: t.Callable[[t.Any], _T],\n        name: str | None = None,\n        doc: str | None = None,\n    ) -> None:\n        super().__init__(fget, doc=doc)\n        self.__name__ = name or fget.__name__\n        self.slot_name = f\"_cache_{self.__name__}\"\n        self.__module__ = fget.__module__\n\n    def __set__(self, obj: object, value: _T) -> None:\n        if hasattr(obj, \"__dict__\"):\n            obj.__dict__[self.__name__] = value\n        else:\n            setattr(obj, self.slot_name, value)\n\n    def __get__(self, obj: object, type: type = None) -> _T:  # type: ignore\n        if obj is None:\n            return self  # type: ignore\n\n        obj_dict = getattr(obj, \"__dict__\", None)\n\n        if obj_dict is not None:\n            value: _T = obj_dict.get(self.__name__, _missing)\n        else:\n            value = getattr(obj, self.slot_name, _missing)  # type: ignore[arg-type]\n\n        if value is _missing:\n            value = self.fget(obj)  # type: ignore\n\n            if obj_dict is not None:\n                obj.__dict__[self.__name__] = value\n            else:\n                setattr(obj, self.slot_name, value)\n\n        return value\n\n    def __delete__(self, obj: object) -> None:\n        if hasattr(obj, \"__dict__\"):\n            del obj.__dict__[self.__name__]\n        else:\n            setattr(obj, self.slot_name, _missing)\n\n\nclass environ_property(_DictAccessorProperty[_TAccessorValue]):\n    \"\"\"Maps request attributes to environment variables. This works not only\n    for the Werkzeug request object, but also any other class with an\n    environ attribute:\n\n    >>> class Test(object):\n    ...     environ = {'key': 'value'}\n    ...     test = environ_property('key')\n    >>> var = Test()\n    >>> var.test\n    'value'\n\n    If you pass it a second value it's used as default if the key does not\n    exist, the third one can be a converter that takes a value and converts\n    it.  If it raises :exc:`ValueError` or :exc:`TypeError` the default value\n    is used. If no default value is provided `None` is used.\n\n    Per default the property is read only.  You have to explicitly enable it\n    by passing ``read_only=False`` to the constructor.\n    \"\"\"\n\n    read_only = True\n\n    def lookup(self, obj: Request) -> WSGIEnvironment:\n        return obj.environ\n\n\nclass header_property(_DictAccessorProperty[_TAccessorValue]):\n    \"\"\"Like `environ_property` but for headers.\"\"\"\n\n    def lookup(self, obj: Request | Response) -> Headers:\n        return obj.headers\n\n\n# https://cgit.freedesktop.org/xdg/shared-mime-info/tree/freedesktop.org.xml.in\n# https://www.iana.org/assignments/media-types/media-types.xhtml\n# Types listed in the XDG mime info that have a charset in the IANA registration.\n_charset_mimetypes = {\n    \"application/ecmascript\",\n    \"application/javascript\",\n    \"application/sql\",\n    \"application/xml\",\n    \"application/xml-dtd\",\n    \"application/xml-external-parsed-entity\",\n}\n\n\ndef get_content_type(mimetype: str, charset: str) -> str:\n    \"\"\"Returns the full content type string with charset for a mimetype.\n\n    If the mimetype represents text, the charset parameter will be\n    appended, otherwise the mimetype is returned unchanged.\n\n    :param mimetype: The mimetype to be used as content type.\n    :param charset: The charset to be appended for text mimetypes.\n    :return: The content type.\n\n    .. versionchanged:: 0.15\n        Any type that ends with ``+xml`` gets a charset, not just those\n        that start with ``application/``. Known text types such as\n        ``application/javascript`` are also given charsets.\n    \"\"\"\n    if (\n        mimetype.startswith(\"text/\")\n        or mimetype in _charset_mimetypes\n        or mimetype.endswith(\"+xml\")\n    ):\n        mimetype += f\"; charset={charset}\"\n\n    return mimetype\n\n\ndef secure_filename(filename: str) -> str:\n    r\"\"\"Pass it a filename and it will return a secure version of it.  This\n    filename can then safely be stored on a regular file system and passed\n    to :func:`os.path.join`.  The filename returned is an ASCII only string\n    for maximum portability.\n\n    On windows systems the function also makes sure that the file is not\n    named after one of the special device files.\n\n    >>> secure_filename(\"My cool movie.mov\")\n    'My_cool_movie.mov'\n    >>> secure_filename(\"../../../etc/passwd\")\n    'etc_passwd'\n    >>> secure_filename('i contain cool \\xfcml\\xe4uts.txt')\n    'i_contain_cool_umlauts.txt'\n\n    The function might return an empty filename.  It's your responsibility\n    to ensure that the filename is unique and that you abort or\n    generate a random filename if the function returned an empty one.\n\n    .. versionadded:: 0.5\n\n    :param filename: the filename to secure\n    \"\"\"\n    filename = unicodedata.normalize(\"NFKD\", filename)\n    filename = filename.encode(\"ascii\", \"ignore\").decode(\"ascii\")\n\n    for sep in os.sep, os.path.altsep:\n        if sep:\n            filename = filename.replace(sep, \" \")\n    filename = str(_filename_ascii_strip_re.sub(\"\", \"_\".join(filename.split()))).strip(\n        \"._\"\n    )\n\n    # on nt a couple of special files are present in each folder.  We\n    # have to ensure that the target file is not such a filename.  In\n    # this case we prepend an underline\n    if (\n        os.name == \"nt\"\n        and filename\n        and filename.split(\".\")[0].upper() in _windows_device_files\n    ):\n        filename = f\"_{filename}\"\n\n    return filename\n\n\ndef redirect(\n    location: str, code: int = 302, Response: type[Response] | None = None\n) -> Response:\n    \"\"\"Returns a response object (a WSGI application) that, if called,\n    redirects the client to the target location. Supported codes are\n    301, 302, 303, 305, 307, and 308. 300 is not supported because\n    it's not a real redirect and 304 because it's the answer for a\n    request with a request with defined If-Modified-Since headers.\n\n    .. versionadded:: 0.6\n       The location can now be a unicode string that is encoded using\n       the :func:`iri_to_uri` function.\n\n    .. versionadded:: 0.10\n        The class used for the Response object can now be passed in.\n\n    :param location: the location the response should redirect to.\n    :param code: the redirect status code. defaults to 302.\n    :param class Response: a Response class to use when instantiating a\n        response. The default is :class:`werkzeug.wrappers.Response` if\n        unspecified.\n    \"\"\"\n    if Response is None:\n        from .wrappers import Response\n\n    html_location = escape(location)\n    response = Response(  # type: ignore[misc]\n        \"<!doctype html>\\n\"\n        \"<html lang=en>\\n\"\n        \"<title>Redirecting...</title>\\n\"\n        \"<h1>Redirecting...</h1>\\n\"\n        \"<p>You should be redirected automatically to the target URL: \"\n        f'<a href=\"{html_location}\">{html_location}</a>. If not, click the link.\\n',\n        code,\n        mimetype=\"text/html\",\n    )\n    response.headers[\"Location\"] = location\n    return response\n\n\ndef append_slash_redirect(environ: WSGIEnvironment, code: int = 308) -> Response:\n    \"\"\"Redirect to the current URL with a slash appended.\n\n    If the current URL is ``/user/42``, the redirect URL will be\n    ``42/``. When joined to the current URL during response\n    processing or by the browser, this will produce ``/user/42/``.\n\n    The behavior is undefined if the path ends with a slash already. If\n    called unconditionally on a URL, it may produce a redirect loop.\n\n    :param environ: Use the path and query from this WSGI environment\n        to produce the redirect URL.\n    :param code: the status code for the redirect.\n\n    .. versionchanged:: 2.1\n        Produce a relative URL that only modifies the last segment.\n        Relevant when the current path has multiple segments.\n\n    .. versionchanged:: 2.1\n        The default status code is 308 instead of 301. This preserves\n        the request method and body.\n    \"\"\"\n    tail = environ[\"PATH_INFO\"].rpartition(\"/\")[2]\n\n    if not tail:\n        new_path = \"./\"\n    else:\n        new_path = f\"{tail}/\"\n\n    query_string = environ.get(\"QUERY_STRING\")\n\n    if query_string:\n        new_path = f\"{new_path}?{query_string}\"\n\n    return redirect(new_path, code)\n\n\ndef send_file(\n    path_or_file: os.PathLike[str] | str | t.IO[bytes],\n    environ: WSGIEnvironment,\n    mimetype: str | None = None,\n    as_attachment: bool = False,\n    download_name: str | None = None,\n    conditional: bool = True,\n    etag: bool | str = True,\n    last_modified: datetime | int | float | None = None,\n    max_age: None | (int | t.Callable[[str | None], int | None]) = None,\n    use_x_sendfile: bool = False,\n    response_class: type[Response] | None = None,\n    _root_path: os.PathLike[str] | str | None = None,\n) -> Response:\n    \"\"\"Send the contents of a file to the client.\n\n    The first argument can be a file path or a file-like object. Paths\n    are preferred in most cases because Werkzeug can manage the file and\n    get extra information from the path. Passing a file-like object\n    requires that the file is opened in binary mode, and is mostly\n    useful when building a file in memory with :class:`io.BytesIO`.\n\n    Never pass file paths provided by a user. The path is assumed to be\n    trusted, so a user could craft a path to access a file you didn't\n    intend. Use :func:`send_from_directory` to safely serve user-provided paths.\n\n    If the WSGI server sets a ``file_wrapper`` in ``environ``, it is\n    used, otherwise Werkzeug's built-in wrapper is used. Alternatively,\n    if the HTTP server supports ``X-Sendfile``, ``use_x_sendfile=True``\n    will tell the server to send the given path, which is much more\n    efficient than reading it in Python.\n\n    :param path_or_file: The path to the file to send, relative to the\n        current working directory if a relative path is given.\n        Alternatively, a file-like object opened in binary mode. Make\n        sure the file pointer is seeked to the start of the data.\n    :param environ: The WSGI environ for the current request.\n    :param mimetype: The MIME type to send for the file. If not\n        provided, it will try to detect it from the file name.\n    :param as_attachment: Indicate to a browser that it should offer to\n        save the file instead of displaying it.\n    :param download_name: The default name browsers will use when saving\n        the file. Defaults to the passed file name.\n    :param conditional: Enable conditional and range responses based on\n        request headers. Requires passing a file path and ``environ``.\n    :param etag: Calculate an ETag for the file, which requires passing\n        a file path. Can also be a string to use instead.\n    :param last_modified: The last modified time to send for the file,\n        in seconds. If not provided, it will try to detect it from the\n        file path.\n    :param max_age: How long the client should cache the file, in\n        seconds. If set, ``Cache-Control`` will be ``public``, otherwise\n        it will be ``no-cache`` to prefer conditional caching.\n    :param use_x_sendfile: Set the ``X-Sendfile`` header to let the\n        server to efficiently send the file. Requires support from the\n        HTTP server. Requires passing a file path.\n    :param response_class: Build the response using this class. Defaults\n        to :class:`~werkzeug.wrappers.Response`.\n    :param _root_path: Do not use. For internal use only. Use\n        :func:`send_from_directory` to safely send files under a path.\n\n    .. versionchanged:: 2.0.2\n        ``send_file`` only sets a detected ``Content-Encoding`` if\n        ``as_attachment`` is disabled.\n\n    .. versionadded:: 2.0\n        Adapted from Flask's implementation.\n\n    .. versionchanged:: 2.0\n        ``download_name`` replaces Flask's ``attachment_filename``\n         parameter. If ``as_attachment=False``, it is passed with\n         ``Content-Disposition: inline`` instead.\n\n    .. versionchanged:: 2.0\n        ``max_age`` replaces Flask's ``cache_timeout`` parameter.\n        ``conditional`` is enabled and ``max_age`` is not set by\n        default.\n\n    .. versionchanged:: 2.0\n        ``etag`` replaces Flask's ``add_etags`` parameter. It can be a\n        string to use instead of generating one.\n\n    .. versionchanged:: 2.0\n        If an encoding is returned when guessing ``mimetype`` from\n        ``download_name``, set the ``Content-Encoding`` header.\n    \"\"\"\n    if response_class is None:\n        from .wrappers import Response\n\n        response_class = Response\n\n    path: str | None = None\n    file: t.IO[bytes] | None = None\n    size: int | None = None\n    mtime: float | None = None\n    headers = Headers()\n\n    if isinstance(path_or_file, (os.PathLike, str)) or hasattr(\n        path_or_file, \"__fspath__\"\n    ):\n        path_or_file = t.cast(\"t.Union[os.PathLike[str], str]\", path_or_file)\n\n        # Flask will pass app.root_path, allowing its send_file wrapper\n        # to not have to deal with paths.\n        if _root_path is not None:\n            path = os.path.join(_root_path, path_or_file)\n        else:\n            path = os.path.abspath(path_or_file)\n\n        stat = os.stat(path)\n        size = stat.st_size\n        mtime = stat.st_mtime\n    else:\n        file = path_or_file\n\n    if download_name is None and path is not None:\n        download_name = os.path.basename(path)\n\n    if mimetype is None:\n        if download_name is None:\n            raise TypeError(\n                \"Unable to detect the MIME type because a file name is\"\n                \" not available. Either set 'download_name', pass a\"\n                \" path instead of a file, or set 'mimetype'.\"\n            )\n\n        mimetype, encoding = mimetypes.guess_type(download_name)\n\n        if mimetype is None:\n            mimetype = \"application/octet-stream\"\n\n        # Don't send encoding for attachments, it causes browsers to\n        # save decompress tar.gz files.\n        if encoding is not None and not as_attachment:\n            headers.set(\"Content-Encoding\", encoding)\n\n    if download_name is not None:\n        try:\n            download_name.encode(\"ascii\")\n        except UnicodeEncodeError:\n            simple = unicodedata.normalize(\"NFKD\", download_name)\n            simple = simple.encode(\"ascii\", \"ignore\").decode(\"ascii\")\n            # safe = RFC 5987 attr-char\n            quoted = quote(download_name, safe=\"!#$&+-.^_`|~\")\n            names = {\"filename\": simple, \"filename*\": f\"UTF-8''{quoted}\"}\n        else:\n            names = {\"filename\": download_name}\n\n        value = \"attachment\" if as_attachment else \"inline\"\n        headers.set(\"Content-Disposition\", value, **names)\n    elif as_attachment:\n        raise TypeError(\n            \"No name provided for attachment. Either set\"\n            \" 'download_name' or pass a path instead of a file.\"\n        )\n\n    if use_x_sendfile and path is not None:\n        headers[\"X-Sendfile\"] = path\n        data = None\n    else:\n        if file is None:\n            file = open(path, \"rb\")  # type: ignore\n        elif isinstance(file, io.BytesIO):\n            size = file.getbuffer().nbytes\n        elif isinstance(file, io.TextIOBase):\n            raise ValueError(\"Files must be opened in binary mode or use BytesIO.\")\n\n        data = wrap_file(environ, file)\n\n    rv = response_class(\n        data, mimetype=mimetype, headers=headers, direct_passthrough=True\n    )\n\n    if size is not None:\n        rv.content_length = size\n\n    if last_modified is not None:\n        rv.last_modified = last_modified  # type: ignore\n    elif mtime is not None:\n        rv.last_modified = mtime  # type: ignore\n\n    rv.cache_control.no_cache = True\n\n    # Flask will pass app.get_send_file_max_age, allowing its send_file\n    # wrapper to not have to deal with paths.\n    if callable(max_age):\n        max_age = max_age(path)\n\n    if max_age is not None:\n        if max_age > 0:\n            rv.cache_control.no_cache = None\n            rv.cache_control.public = True\n\n        rv.cache_control.max_age = max_age\n        rv.expires = int(time() + max_age)  # type: ignore\n\n    if isinstance(etag, str):\n        rv.set_etag(etag)\n    elif etag and path is not None:\n        check = adler32(path.encode()) & 0xFFFFFFFF\n        rv.set_etag(f\"{mtime}-{size}-{check}\")\n\n    if conditional:\n        try:\n            rv = rv.make_conditional(environ, accept_ranges=True, complete_length=size)\n        except RequestedRangeNotSatisfiable:\n            if file is not None:\n                file.close()\n\n            raise\n\n        # Some x-sendfile implementations incorrectly ignore the 304\n        # status code and send the file anyway.\n        if rv.status_code == 304:\n            rv.headers.pop(\"x-sendfile\", None)\n\n    return rv\n\n\ndef send_from_directory(\n    directory: os.PathLike[str] | str,\n    path: os.PathLike[str] | str,\n    environ: WSGIEnvironment,\n    **kwargs: t.Any,\n) -> Response:\n    \"\"\"Send a file from within a directory using :func:`send_file`.\n\n    This is a secure way to serve files from a folder, such as static\n    files or uploads. Uses :func:`~werkzeug.security.safe_join` to\n    ensure the path coming from the client is not maliciously crafted to\n    point outside the specified directory.\n\n    If the final path does not point to an existing regular file,\n    returns a 404 :exc:`~werkzeug.exceptions.NotFound` error.\n\n    :param directory: The directory that ``path`` must be located under. This *must not*\n        be a value provided by the client, otherwise it becomes insecure.\n    :param path: The path to the file to send, relative to ``directory``. This is the\n        part of the path provided by the client, which is checked for security.\n    :param environ: The WSGI environ for the current request.\n    :param kwargs: Arguments to pass to :func:`send_file`.\n\n    .. versionadded:: 2.0\n        Adapted from Flask's implementation.\n    \"\"\"\n    path_str = safe_join(os.fspath(directory), os.fspath(path))\n\n    if path_str is None:\n        raise NotFound()\n\n    # Flask will pass app.root_path, allowing its send_from_directory\n    # wrapper to not have to deal with paths.\n    if \"_root_path\" in kwargs:\n        path_str = os.path.join(kwargs[\"_root_path\"], path_str)\n\n    if not os.path.isfile(path_str):\n        raise NotFound()\n\n    return send_file(path_str, environ, **kwargs)\n\n\ndef import_string(import_name: str, silent: bool = False) -> t.Any:\n    \"\"\"Imports an object based on a string.  This is useful if you want to\n    use import paths as endpoints or something similar.  An import path can\n    be specified either in dotted notation (``xml.sax.saxutils.escape``)\n    or with a colon as object delimiter (``xml.sax.saxutils:escape``).\n\n    If `silent` is True the return value will be `None` if the import fails.\n\n    :param import_name: the dotted name for the object to import.\n    :param silent: if set to `True` import errors are ignored and\n                   `None` is returned instead.\n    :return: imported object\n    \"\"\"\n    import_name = import_name.replace(\":\", \".\")\n    try:\n        try:\n            __import__(import_name)\n        except ImportError:\n            if \".\" not in import_name:\n                raise\n        else:\n            return sys.modules[import_name]\n\n        module_name, obj_name = import_name.rsplit(\".\", 1)\n        module = __import__(module_name, globals(), locals(), [obj_name])\n        try:\n            return getattr(module, obj_name)\n        except AttributeError as e:\n            raise ImportError(e) from None\n\n    except ImportError as e:\n        if not silent:\n            raise ImportStringError(import_name, e).with_traceback(\n                sys.exc_info()[2]\n            ) from None\n\n    return None\n\n\ndef find_modules(\n    import_path: str, include_packages: bool = False, recursive: bool = False\n) -> t.Iterator[str]:\n    \"\"\"Finds all the modules below a package.  This can be useful to\n    automatically import all views / controllers so that their metaclasses /\n    function decorators have a chance to register themselves on the\n    application.\n\n    Packages are not returned unless `include_packages` is `True`.  This can\n    also recursively list modules but in that case it will import all the\n    packages to get the correct load path of that module.\n\n    :param import_path: the dotted name for the package to find child modules.\n    :param include_packages: set to `True` if packages should be returned, too.\n    :param recursive: set to `True` if recursion should happen.\n    :return: generator\n    \"\"\"\n    module = import_string(import_path)\n    path = getattr(module, \"__path__\", None)\n    if path is None:\n        raise ValueError(f\"{import_path!r} is not a package\")\n    basename = f\"{module.__name__}.\"\n    for _importer, modname, ispkg in pkgutil.iter_modules(path):\n        modname = basename + modname\n        if ispkg:\n            if include_packages:\n                yield modname\n            if recursive:\n                yield from find_modules(modname, include_packages, True)\n        else:\n            yield modname\n\n\nclass ImportStringError(ImportError):\n    \"\"\"Provides information about a failed :func:`import_string` attempt.\"\"\"\n\n    #: String in dotted notation that failed to be imported.\n    import_name: str\n    #: Wrapped exception.\n    exception: BaseException\n\n    def __init__(self, import_name: str, exception: BaseException) -> None:\n        self.import_name = import_name\n        self.exception = exception\n        msg = import_name\n        name = \"\"\n        tracked = []\n        for part in import_name.replace(\":\", \".\").split(\".\"):\n            name = f\"{name}.{part}\" if name else part\n            imported = import_string(name, silent=True)\n            if imported:\n                tracked.append((name, getattr(imported, \"__file__\", None)))\n            else:\n                track = [f\"- {n!r} found in {i!r}.\" for n, i in tracked]\n                track.append(f\"- {name!r} not found.\")\n                track_str = \"\\n\".join(track)\n                msg = (\n                    f\"import_string() failed for {import_name!r}. Possible reasons\"\n                    f\" are:\\n\\n\"\n                    \"- missing __init__.py in a package;\\n\"\n                    \"- package or module path not included in sys.path;\\n\"\n                    \"- duplicated package or module name taking precedence in\"\n                    \" sys.path;\\n\"\n                    \"- missing module, class, function or variable;\\n\\n\"\n                    f\"Debugged import:\\n\\n{track_str}\\n\\n\"\n                    f\"Original exception:\\n\\n{type(exception).__name__}: {exception}\"\n                )\n                break\n\n        super().__init__(msg)\n\n    def __repr__(self) -> str:\n        return f\"<{type(self).__name__}({self.import_name!r}, {self.exception!r})>\"\n", "src/werkzeug/urls.py": "from __future__ import annotations\n\nimport codecs\nimport re\nimport typing as t\nimport urllib.parse\nfrom urllib.parse import quote\nfrom urllib.parse import unquote\nfrom urllib.parse import urlencode\nfrom urllib.parse import urlsplit\nfrom urllib.parse import urlunsplit\n\nfrom .datastructures import iter_multi_items\n\n\ndef _codec_error_url_quote(e: UnicodeError) -> tuple[str, int]:\n    \"\"\"Used in :func:`uri_to_iri` after unquoting to re-quote any\n    invalid bytes.\n    \"\"\"\n    # the docs state that UnicodeError does have these attributes,\n    # but mypy isn't picking them up\n    out = quote(e.object[e.start : e.end], safe=\"\")  # type: ignore\n    return out, e.end  # type: ignore\n\n\ncodecs.register_error(\"werkzeug.url_quote\", _codec_error_url_quote)\n\n\ndef _make_unquote_part(name: str, chars: str) -> t.Callable[[str], str]:\n    \"\"\"Create a function that unquotes all percent encoded characters except those\n    given. This allows working with unquoted characters if possible while not changing\n    the meaning of a given part of a URL.\n    \"\"\"\n    choices = \"|\".join(f\"{ord(c):02X}\" for c in sorted(chars))\n    pattern = re.compile(f\"((?:%(?:{choices}))+)\", re.I)\n\n    def _unquote_partial(value: str) -> str:\n        parts = iter(pattern.split(value))\n        out = []\n\n        for part in parts:\n            out.append(unquote(part, \"utf-8\", \"werkzeug.url_quote\"))\n            out.append(next(parts, \"\"))\n\n        return \"\".join(out)\n\n    _unquote_partial.__name__ = f\"_unquote_{name}\"\n    return _unquote_partial\n\n\n# characters that should remain quoted in URL parts\n# based on https://url.spec.whatwg.org/#percent-encoded-bytes\n# always keep all controls, space, and % quoted\n_always_unsafe = bytes((*range(0x21), 0x25, 0x7F)).decode()\n_unquote_fragment = _make_unquote_part(\"fragment\", _always_unsafe)\n_unquote_query = _make_unquote_part(\"query\", _always_unsafe + \"&=+#\")\n_unquote_path = _make_unquote_part(\"path\", _always_unsafe + \"/?#\")\n_unquote_user = _make_unquote_part(\"user\", _always_unsafe + \":@/?#\")\n\n\ndef uri_to_iri(uri: str) -> str:\n    \"\"\"Convert a URI to an IRI. All valid UTF-8 characters are unquoted,\n    leaving all reserved and invalid characters quoted. If the URL has\n    a domain, it is decoded from Punycode.\n\n    >>> uri_to_iri(\"http://xn--n3h.net/p%C3%A5th?q=%C3%A8ry%DF\")\n    'http://\\\\u2603.net/p\\\\xe5th?q=\\\\xe8ry%DF'\n\n    :param uri: The URI to convert.\n\n    .. versionchanged:: 3.0\n        Passing a tuple or bytes, and the ``charset`` and ``errors`` parameters,\n        are removed.\n\n    .. versionchanged:: 2.3\n        Which characters remain quoted is specific to each part of the URL.\n\n    .. versionchanged:: 0.15\n        All reserved and invalid characters remain quoted. Previously,\n        only some reserved characters were preserved, and invalid bytes\n        were replaced instead of left quoted.\n\n    .. versionadded:: 0.6\n    \"\"\"\n    parts = urlsplit(uri)\n    path = _unquote_path(parts.path)\n    query = _unquote_query(parts.query)\n    fragment = _unquote_fragment(parts.fragment)\n\n    if parts.hostname:\n        netloc = _decode_idna(parts.hostname)\n    else:\n        netloc = \"\"\n\n    if \":\" in netloc:\n        netloc = f\"[{netloc}]\"\n\n    if parts.port:\n        netloc = f\"{netloc}:{parts.port}\"\n\n    if parts.username:\n        auth = _unquote_user(parts.username)\n\n        if parts.password:\n            password = _unquote_user(parts.password)\n            auth = f\"{auth}:{password}\"\n\n        netloc = f\"{auth}@{netloc}\"\n\n    return urlunsplit((parts.scheme, netloc, path, query, fragment))\n\n\ndef iri_to_uri(iri: str) -> str:\n    \"\"\"Convert an IRI to a URI. All non-ASCII and unsafe characters are\n    quoted. If the URL has a domain, it is encoded to Punycode.\n\n    >>> iri_to_uri('http://\\\\u2603.net/p\\\\xe5th?q=\\\\xe8ry%DF')\n    'http://xn--n3h.net/p%C3%A5th?q=%C3%A8ry%DF'\n\n    :param iri: The IRI to convert.\n\n    .. versionchanged:: 3.0\n        Passing a tuple or bytes, the ``charset`` and ``errors`` parameters,\n        and the ``safe_conversion`` parameter, are removed.\n\n    .. versionchanged:: 2.3\n        Which characters remain unquoted is specific to each part of the URL.\n\n    .. versionchanged:: 0.15\n        All reserved characters remain unquoted. Previously, only some reserved\n        characters were left unquoted.\n\n    .. versionchanged:: 0.9.6\n       The ``safe_conversion`` parameter was added.\n\n    .. versionadded:: 0.6\n    \"\"\"\n    parts = urlsplit(iri)\n    # safe = https://url.spec.whatwg.org/#url-path-segment-string\n    # as well as percent for things that are already quoted\n    path = quote(parts.path, safe=\"%!$&'()*+,/:;=@\")\n    query = quote(parts.query, safe=\"%!$&'()*+,/:;=?@\")\n    fragment = quote(parts.fragment, safe=\"%!#$&'()*+,/:;=?@\")\n\n    if parts.hostname:\n        netloc = parts.hostname.encode(\"idna\").decode(\"ascii\")\n    else:\n        netloc = \"\"\n\n    if \":\" in netloc:\n        netloc = f\"[{netloc}]\"\n\n    if parts.port:\n        netloc = f\"{netloc}:{parts.port}\"\n\n    if parts.username:\n        auth = quote(parts.username, safe=\"%!$&'()*+,;=\")\n\n        if parts.password:\n            password = quote(parts.password, safe=\"%!$&'()*+,;=\")\n            auth = f\"{auth}:{password}\"\n\n        netloc = f\"{auth}@{netloc}\"\n\n    return urlunsplit((parts.scheme, netloc, path, query, fragment))\n\n\n# Python < 3.12\n# itms-services was worked around in previous iri_to_uri implementations, but\n# we can tell Python directly that it needs to preserve the //.\nif \"itms-services\" not in urllib.parse.uses_netloc:\n    urllib.parse.uses_netloc.append(\"itms-services\")\n\n\ndef _decode_idna(domain: str) -> str:\n    try:\n        data = domain.encode(\"ascii\")\n    except UnicodeEncodeError:\n        # If the domain is not ASCII, it's decoded already.\n        return domain\n\n    try:\n        # Try decoding in one shot.\n        return data.decode(\"idna\")\n    except UnicodeDecodeError:\n        pass\n\n    # Decode each part separately, leaving invalid parts as punycode.\n    parts = []\n\n    for part in data.split(b\".\"):\n        try:\n            parts.append(part.decode(\"idna\"))\n        except UnicodeDecodeError:\n            parts.append(part.decode(\"ascii\"))\n\n    return \".\".join(parts)\n\n\ndef _urlencode(query: t.Mapping[str, str] | t.Iterable[tuple[str, str]]) -> str:\n    items = [x for x in iter_multi_items(query) if x[1] is not None]\n    # safe = https://url.spec.whatwg.org/#percent-encoded-bytes\n    return urlencode(items, safe=\"!$'()*,/:;?@\")\n", "src/werkzeug/formparser.py": "from __future__ import annotations\n\nimport typing as t\nfrom io import BytesIO\nfrom urllib.parse import parse_qsl\n\nfrom ._internal import _plain_int\nfrom .datastructures import FileStorage\nfrom .datastructures import Headers\nfrom .datastructures import MultiDict\nfrom .exceptions import RequestEntityTooLarge\nfrom .http import parse_options_header\nfrom .sansio.multipart import Data\nfrom .sansio.multipart import Epilogue\nfrom .sansio.multipart import Field\nfrom .sansio.multipart import File\nfrom .sansio.multipart import MultipartDecoder\nfrom .sansio.multipart import NeedData\nfrom .wsgi import get_content_length\nfrom .wsgi import get_input_stream\n\n# there are some platforms where SpooledTemporaryFile is not available.\n# In that case we need to provide a fallback.\ntry:\n    from tempfile import SpooledTemporaryFile\nexcept ImportError:\n    from tempfile import TemporaryFile\n\n    SpooledTemporaryFile = None  # type: ignore\n\nif t.TYPE_CHECKING:\n    import typing as te\n\n    from _typeshed.wsgi import WSGIEnvironment\n\n    t_parse_result = t.Tuple[\n        t.IO[bytes], MultiDict[str, str], MultiDict[str, FileStorage]\n    ]\n\n    class TStreamFactory(te.Protocol):\n        def __call__(\n            self,\n            total_content_length: int | None,\n            content_type: str | None,\n            filename: str | None,\n            content_length: int | None = None,\n        ) -> t.IO[bytes]: ...\n\n\nF = t.TypeVar(\"F\", bound=t.Callable[..., t.Any])\n\n\ndef default_stream_factory(\n    total_content_length: int | None,\n    content_type: str | None,\n    filename: str | None,\n    content_length: int | None = None,\n) -> t.IO[bytes]:\n    max_size = 1024 * 500\n\n    if SpooledTemporaryFile is not None:\n        return t.cast(t.IO[bytes], SpooledTemporaryFile(max_size=max_size, mode=\"rb+\"))\n    elif total_content_length is None or total_content_length > max_size:\n        return t.cast(t.IO[bytes], TemporaryFile(\"rb+\"))\n\n    return BytesIO()\n\n\ndef parse_form_data(\n    environ: WSGIEnvironment,\n    stream_factory: TStreamFactory | None = None,\n    max_form_memory_size: int | None = None,\n    max_content_length: int | None = None,\n    cls: type[MultiDict[str, t.Any]] | None = None,\n    silent: bool = True,\n    *,\n    max_form_parts: int | None = None,\n) -> t_parse_result:\n    \"\"\"Parse the form data in the environ and return it as tuple in the form\n    ``(stream, form, files)``.  You should only call this method if the\n    transport method is `POST`, `PUT`, or `PATCH`.\n\n    If the mimetype of the data transmitted is `multipart/form-data` the\n    files multidict will be filled with `FileStorage` objects.  If the\n    mimetype is unknown the input stream is wrapped and returned as first\n    argument, else the stream is empty.\n\n    This is a shortcut for the common usage of :class:`FormDataParser`.\n\n    :param environ: the WSGI environment to be used for parsing.\n    :param stream_factory: An optional callable that returns a new read and\n                           writeable file descriptor.  This callable works\n                           the same as :meth:`Response._get_file_stream`.\n    :param max_form_memory_size: the maximum number of bytes to be accepted for\n                           in-memory stored form data.  If the data\n                           exceeds the value specified an\n                           :exc:`~exceptions.RequestEntityTooLarge`\n                           exception is raised.\n    :param max_content_length: If this is provided and the transmitted data\n                               is longer than this value an\n                               :exc:`~exceptions.RequestEntityTooLarge`\n                               exception is raised.\n    :param cls: an optional dict class to use.  If this is not specified\n                       or `None` the default :class:`MultiDict` is used.\n    :param silent: If set to False parsing errors will not be caught.\n    :param max_form_parts: The maximum number of multipart parts to be parsed. If this\n        is exceeded, a :exc:`~exceptions.RequestEntityTooLarge` exception is raised.\n    :return: A tuple in the form ``(stream, form, files)``.\n\n    .. versionchanged:: 3.0\n        The ``charset`` and ``errors`` parameters were removed.\n\n    .. versionchanged:: 2.3\n        Added the ``max_form_parts`` parameter.\n\n    .. versionadded:: 0.5.1\n       Added the ``silent`` parameter.\n\n    .. versionadded:: 0.5\n       Added the ``max_form_memory_size``, ``max_content_length``, and ``cls``\n       parameters.\n    \"\"\"\n    return FormDataParser(\n        stream_factory=stream_factory,\n        max_form_memory_size=max_form_memory_size,\n        max_content_length=max_content_length,\n        max_form_parts=max_form_parts,\n        silent=silent,\n        cls=cls,\n    ).parse_from_environ(environ)\n\n\nclass FormDataParser:\n    \"\"\"This class implements parsing of form data for Werkzeug.  By itself\n    it can parse multipart and url encoded form data.  It can be subclassed\n    and extended but for most mimetypes it is a better idea to use the\n    untouched stream and expose it as separate attributes on a request\n    object.\n\n    :param stream_factory: An optional callable that returns a new read and\n                           writeable file descriptor.  This callable works\n                           the same as :meth:`Response._get_file_stream`.\n    :param max_form_memory_size: the maximum number of bytes to be accepted for\n                           in-memory stored form data.  If the data\n                           exceeds the value specified an\n                           :exc:`~exceptions.RequestEntityTooLarge`\n                           exception is raised.\n    :param max_content_length: If this is provided and the transmitted data\n                               is longer than this value an\n                               :exc:`~exceptions.RequestEntityTooLarge`\n                               exception is raised.\n    :param cls: an optional dict class to use.  If this is not specified\n                       or `None` the default :class:`MultiDict` is used.\n    :param silent: If set to False parsing errors will not be caught.\n    :param max_form_parts: The maximum number of multipart parts to be parsed. If this\n        is exceeded, a :exc:`~exceptions.RequestEntityTooLarge` exception is raised.\n\n    .. versionchanged:: 3.0\n        The ``charset`` and ``errors`` parameters were removed.\n\n    .. versionchanged:: 3.0\n        The ``parse_functions`` attribute and ``get_parse_func`` methods were removed.\n\n    .. versionchanged:: 2.2.3\n        Added the ``max_form_parts`` parameter.\n\n    .. versionadded:: 0.8\n    \"\"\"\n\n    def __init__(\n        self,\n        stream_factory: TStreamFactory | None = None,\n        max_form_memory_size: int | None = None,\n        max_content_length: int | None = None,\n        cls: type[MultiDict[str, t.Any]] | None = None,\n        silent: bool = True,\n        *,\n        max_form_parts: int | None = None,\n    ) -> None:\n        if stream_factory is None:\n            stream_factory = default_stream_factory\n\n        self.stream_factory = stream_factory\n        self.max_form_memory_size = max_form_memory_size\n        self.max_content_length = max_content_length\n        self.max_form_parts = max_form_parts\n\n        if cls is None:\n            cls = t.cast(\"type[MultiDict[str, t.Any]]\", MultiDict)\n\n        self.cls = cls\n        self.silent = silent\n\n    def parse_from_environ(self, environ: WSGIEnvironment) -> t_parse_result:\n        \"\"\"Parses the information from the environment as form data.\n\n        :param environ: the WSGI environment to be used for parsing.\n        :return: A tuple in the form ``(stream, form, files)``.\n        \"\"\"\n        stream = get_input_stream(environ, max_content_length=self.max_content_length)\n        content_length = get_content_length(environ)\n        mimetype, options = parse_options_header(environ.get(\"CONTENT_TYPE\"))\n        return self.parse(\n            stream,\n            content_length=content_length,\n            mimetype=mimetype,\n            options=options,\n        )\n\n    def parse(\n        self,\n        stream: t.IO[bytes],\n        mimetype: str,\n        content_length: int | None,\n        options: dict[str, str] | None = None,\n    ) -> t_parse_result:\n        \"\"\"Parses the information from the given stream, mimetype,\n        content length and mimetype parameters.\n\n        :param stream: an input stream\n        :param mimetype: the mimetype of the data\n        :param content_length: the content length of the incoming data\n        :param options: optional mimetype parameters (used for\n                        the multipart boundary for instance)\n        :return: A tuple in the form ``(stream, form, files)``.\n\n        .. versionchanged:: 3.0\n            The invalid ``application/x-url-encoded`` content type is not\n            treated as ``application/x-www-form-urlencoded``.\n        \"\"\"\n        if mimetype == \"multipart/form-data\":\n            parse_func = self._parse_multipart\n        elif mimetype == \"application/x-www-form-urlencoded\":\n            parse_func = self._parse_urlencoded\n        else:\n            return stream, self.cls(), self.cls()\n\n        if options is None:\n            options = {}\n\n        try:\n            return parse_func(stream, mimetype, content_length, options)\n        except ValueError:\n            if not self.silent:\n                raise\n\n        return stream, self.cls(), self.cls()\n\n    def _parse_multipart(\n        self,\n        stream: t.IO[bytes],\n        mimetype: str,\n        content_length: int | None,\n        options: dict[str, str],\n    ) -> t_parse_result:\n        parser = MultiPartParser(\n            stream_factory=self.stream_factory,\n            max_form_memory_size=self.max_form_memory_size,\n            max_form_parts=self.max_form_parts,\n            cls=self.cls,\n        )\n        boundary = options.get(\"boundary\", \"\").encode(\"ascii\")\n\n        if not boundary:\n            raise ValueError(\"Missing boundary\")\n\n        form, files = parser.parse(stream, boundary, content_length)\n        return stream, form, files\n\n    def _parse_urlencoded(\n        self,\n        stream: t.IO[bytes],\n        mimetype: str,\n        content_length: int | None,\n        options: dict[str, str],\n    ) -> t_parse_result:\n        if (\n            self.max_form_memory_size is not None\n            and content_length is not None\n            and content_length > self.max_form_memory_size\n        ):\n            raise RequestEntityTooLarge()\n\n        try:\n            items = parse_qsl(\n                stream.read().decode(),\n                keep_blank_values=True,\n                errors=\"werkzeug.url_quote\",\n            )\n        except ValueError as e:\n            raise RequestEntityTooLarge() from e\n\n        return stream, self.cls(items), self.cls()\n\n\nclass MultiPartParser:\n    def __init__(\n        self,\n        stream_factory: TStreamFactory | None = None,\n        max_form_memory_size: int | None = None,\n        cls: type[MultiDict[str, t.Any]] | None = None,\n        buffer_size: int = 64 * 1024,\n        max_form_parts: int | None = None,\n    ) -> None:\n        self.max_form_memory_size = max_form_memory_size\n        self.max_form_parts = max_form_parts\n\n        if stream_factory is None:\n            stream_factory = default_stream_factory\n\n        self.stream_factory = stream_factory\n\n        if cls is None:\n            cls = t.cast(\"type[MultiDict[str, t.Any]]\", MultiDict)\n\n        self.cls = cls\n        self.buffer_size = buffer_size\n\n    def fail(self, message: str) -> te.NoReturn:\n        raise ValueError(message)\n\n    def get_part_charset(self, headers: Headers) -> str:\n        # Figure out input charset for current part\n        content_type = headers.get(\"content-type\")\n\n        if content_type:\n            parameters = parse_options_header(content_type)[1]\n            ct_charset = parameters.get(\"charset\", \"\").lower()\n\n            # A safe list of encodings. Modern clients should only send ASCII or UTF-8.\n            # This list will not be extended further.\n            if ct_charset in {\"ascii\", \"us-ascii\", \"utf-8\", \"iso-8859-1\"}:\n                return ct_charset\n\n        return \"utf-8\"\n\n    def start_file_streaming(\n        self, event: File, total_content_length: int | None\n    ) -> t.IO[bytes]:\n        content_type = event.headers.get(\"content-type\")\n\n        try:\n            content_length = _plain_int(event.headers[\"content-length\"])\n        except (KeyError, ValueError):\n            content_length = 0\n\n        container = self.stream_factory(\n            total_content_length=total_content_length,\n            filename=event.filename,\n            content_type=content_type,\n            content_length=content_length,\n        )\n        return container\n\n    def parse(\n        self, stream: t.IO[bytes], boundary: bytes, content_length: int | None\n    ) -> tuple[MultiDict[str, str], MultiDict[str, FileStorage]]:\n        current_part: Field | File\n        container: t.IO[bytes] | list[bytes]\n        _write: t.Callable[[bytes], t.Any]\n\n        parser = MultipartDecoder(\n            boundary,\n            max_form_memory_size=self.max_form_memory_size,\n            max_parts=self.max_form_parts,\n        )\n\n        fields = []\n        files = []\n\n        for data in _chunk_iter(stream.read, self.buffer_size):\n            parser.receive_data(data)\n            event = parser.next_event()\n            while not isinstance(event, (Epilogue, NeedData)):\n                if isinstance(event, Field):\n                    current_part = event\n                    container = []\n                    _write = container.append\n                elif isinstance(event, File):\n                    current_part = event\n                    container = self.start_file_streaming(event, content_length)\n                    _write = container.write\n                elif isinstance(event, Data):\n                    _write(event.data)\n                    if not event.more_data:\n                        if isinstance(current_part, Field):\n                            value = b\"\".join(container).decode(\n                                self.get_part_charset(current_part.headers), \"replace\"\n                            )\n                            fields.append((current_part.name, value))\n                        else:\n                            container = t.cast(t.IO[bytes], container)\n                            container.seek(0)\n                            files.append(\n                                (\n                                    current_part.name,\n                                    FileStorage(\n                                        container,\n                                        current_part.filename,\n                                        current_part.name,\n                                        headers=current_part.headers,\n                                    ),\n                                )\n                            )\n\n                event = parser.next_event()\n\n        return self.cls(fields), self.cls(files)\n\n\ndef _chunk_iter(read: t.Callable[[int], bytes], size: int) -> t.Iterator[bytes | None]:\n    \"\"\"Read data in chunks for multipart/form-data parsing. Stop if no data is read.\n    Yield ``None`` at the end to signal end of parsing.\n    \"\"\"\n    while True:\n        data = read(size)\n\n        if not data:\n            break\n\n        yield data\n\n    yield None\n", "src/werkzeug/__init__.py": "from __future__ import annotations\n\nimport typing as t\n\nfrom .serving import run_simple as run_simple\nfrom .test import Client as Client\nfrom .wrappers import Request as Request\nfrom .wrappers import Response as Response\n\n\ndef __getattr__(name: str) -> t.Any:\n    if name == \"__version__\":\n        import importlib.metadata\n        import warnings\n\n        warnings.warn(\n            \"The '__version__' attribute is deprecated and will be removed in\"\n            \" Werkzeug 3.1. Use feature detection or\"\n            \" 'importlib.metadata.version(\\\"werkzeug\\\")' instead.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        return importlib.metadata.version(\"werkzeug\")\n\n    raise AttributeError(name)\n", "src/werkzeug/wsgi.py": "from __future__ import annotations\n\nimport io\nimport typing as t\nfrom functools import partial\nfrom functools import update_wrapper\n\nfrom .exceptions import ClientDisconnected\nfrom .exceptions import RequestEntityTooLarge\nfrom .sansio import utils as _sansio_utils\nfrom .sansio.utils import host_is_trusted  # noqa: F401 # Imported as part of API\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n\n\ndef responder(f: t.Callable[..., WSGIApplication]) -> WSGIApplication:\n    \"\"\"Marks a function as responder.  Decorate a function with it and it\n    will automatically call the return value as WSGI application.\n\n    Example::\n\n        @responder\n        def application(environ, start_response):\n            return Response('Hello World!')\n    \"\"\"\n    return update_wrapper(lambda *a: f(*a)(*a[-2:]), f)\n\n\ndef get_current_url(\n    environ: WSGIEnvironment,\n    root_only: bool = False,\n    strip_querystring: bool = False,\n    host_only: bool = False,\n    trusted_hosts: t.Iterable[str] | None = None,\n) -> str:\n    \"\"\"Recreate the URL for a request from the parts in a WSGI\n    environment.\n\n    The URL is an IRI, not a URI, so it may contain Unicode characters.\n    Use :func:`~werkzeug.urls.iri_to_uri` to convert it to ASCII.\n\n    :param environ: The WSGI environment to get the URL parts from.\n    :param root_only: Only build the root path, don't include the\n        remaining path or query string.\n    :param strip_querystring: Don't include the query string.\n    :param host_only: Only build the scheme and host.\n    :param trusted_hosts: A list of trusted host names to validate the\n        host against.\n    \"\"\"\n    parts = {\n        \"scheme\": environ[\"wsgi.url_scheme\"],\n        \"host\": get_host(environ, trusted_hosts),\n    }\n\n    if not host_only:\n        parts[\"root_path\"] = environ.get(\"SCRIPT_NAME\", \"\")\n\n        if not root_only:\n            parts[\"path\"] = environ.get(\"PATH_INFO\", \"\")\n\n            if not strip_querystring:\n                parts[\"query_string\"] = environ.get(\"QUERY_STRING\", \"\").encode(\"latin1\")\n\n    return _sansio_utils.get_current_url(**parts)\n\n\ndef _get_server(\n    environ: WSGIEnvironment,\n) -> tuple[str, int | None] | None:\n    name = environ.get(\"SERVER_NAME\")\n\n    if name is None:\n        return None\n\n    try:\n        port: int | None = int(environ.get(\"SERVER_PORT\", None))\n    except (TypeError, ValueError):\n        # unix socket\n        port = None\n\n    return name, port\n\n\ndef get_host(\n    environ: WSGIEnvironment, trusted_hosts: t.Iterable[str] | None = None\n) -> str:\n    \"\"\"Return the host for the given WSGI environment.\n\n    The ``Host`` header is preferred, then ``SERVER_NAME`` if it's not\n    set. The returned host will only contain the port if it is different\n    than the standard port for the protocol.\n\n    Optionally, verify that the host is trusted using\n    :func:`host_is_trusted` and raise a\n    :exc:`~werkzeug.exceptions.SecurityError` if it is not.\n\n    :param environ: A WSGI environment dict.\n    :param trusted_hosts: A list of trusted host names.\n\n    :return: Host, with port if necessary.\n    :raise ~werkzeug.exceptions.SecurityError: If the host is not\n        trusted.\n    \"\"\"\n    return _sansio_utils.get_host(\n        environ[\"wsgi.url_scheme\"],\n        environ.get(\"HTTP_HOST\"),\n        _get_server(environ),\n        trusted_hosts,\n    )\n\n\ndef get_content_length(environ: WSGIEnvironment) -> int | None:\n    \"\"\"Return the ``Content-Length`` header value as an int. If the header is not given\n    or the ``Transfer-Encoding`` header is ``chunked``, ``None`` is returned to indicate\n    a streaming request. If the value is not an integer, or negative, 0 is returned.\n\n    :param environ: The WSGI environ to get the content length from.\n\n    .. versionadded:: 0.9\n    \"\"\"\n    return _sansio_utils.get_content_length(\n        http_content_length=environ.get(\"CONTENT_LENGTH\"),\n        http_transfer_encoding=environ.get(\"HTTP_TRANSFER_ENCODING\"),\n    )\n\n\ndef get_input_stream(\n    environ: WSGIEnvironment,\n    safe_fallback: bool = True,\n    max_content_length: int | None = None,\n) -> t.IO[bytes]:\n    \"\"\"Return the WSGI input stream, wrapped so that it may be read safely without going\n    past the ``Content-Length`` header value or ``max_content_length``.\n\n    If ``Content-Length`` exceeds ``max_content_length``, a\n    :exc:`RequestEntityTooLarge`` ``413 Content Too Large`` error is raised.\n\n    If the WSGI server sets ``environ[\"wsgi.input_terminated\"]``, it indicates that the\n    server handles terminating the stream, so it is safe to read directly. For example,\n    a server that knows how to handle chunked requests safely would set this.\n\n    If ``max_content_length`` is set, it can be enforced on streams if\n    ``wsgi.input_terminated`` is set. Otherwise, an empty stream is returned unless the\n    user explicitly disables this safe fallback.\n\n    If the limit is reached before the underlying stream is exhausted (such as a file\n    that is too large, or an infinite stream), the remaining contents of the stream\n    cannot be read safely. Depending on how the server handles this, clients may show a\n    \"connection reset\" failure instead of seeing the 413 response.\n\n    :param environ: The WSGI environ containing the stream.\n    :param safe_fallback: Return an empty stream when ``Content-Length`` is not set.\n        Disabling this allows infinite streams, which can be a denial-of-service risk.\n    :param max_content_length: The maximum length that content-length or streaming\n        requests may not exceed.\n\n    .. versionchanged:: 2.3.2\n        ``max_content_length`` is only applied to streaming requests if the server sets\n        ``wsgi.input_terminated``.\n\n    .. versionchanged:: 2.3\n        Check ``max_content_length`` and raise an error if it is exceeded.\n\n    .. versionadded:: 0.9\n    \"\"\"\n    stream = t.cast(t.IO[bytes], environ[\"wsgi.input\"])\n    content_length = get_content_length(environ)\n\n    if content_length is not None and max_content_length is not None:\n        if content_length > max_content_length:\n            raise RequestEntityTooLarge()\n\n    # A WSGI server can set this to indicate that it terminates the input stream. In\n    # that case the stream is safe without wrapping, or can enforce a max length.\n    if \"wsgi.input_terminated\" in environ:\n        if max_content_length is not None:\n            # If this is moved above, it can cause the stream to hang if a read attempt\n            # is made when the client sends no data. For example, the development server\n            # does not handle buffering except for chunked encoding.\n            return t.cast(\n                t.IO[bytes], LimitedStream(stream, max_content_length, is_max=True)\n            )\n\n        return stream\n\n    # No limit given, return an empty stream unless the user explicitly allows the\n    # potentially infinite stream. An infinite stream is dangerous if it's not expected,\n    # as it can tie up a worker indefinitely.\n    if content_length is None:\n        return io.BytesIO() if safe_fallback else stream\n\n    return t.cast(t.IO[bytes], LimitedStream(stream, content_length))\n\n\ndef get_path_info(environ: WSGIEnvironment) -> str:\n    \"\"\"Return ``PATH_INFO`` from  the WSGI environment.\n\n    :param environ: WSGI environment to get the path from.\n\n    .. versionchanged:: 3.0\n        The ``charset`` and ``errors`` parameters were removed.\n\n    .. versionadded:: 0.9\n    \"\"\"\n    path: bytes = environ.get(\"PATH_INFO\", \"\").encode(\"latin1\")\n    return path.decode(errors=\"replace\")\n\n\nclass ClosingIterator:\n    \"\"\"The WSGI specification requires that all middlewares and gateways\n    respect the `close` callback of the iterable returned by the application.\n    Because it is useful to add another close action to a returned iterable\n    and adding a custom iterable is a boring task this class can be used for\n    that::\n\n        return ClosingIterator(app(environ, start_response), [cleanup_session,\n                                                              cleanup_locals])\n\n    If there is just one close function it can be passed instead of the list.\n\n    A closing iterator is not needed if the application uses response objects\n    and finishes the processing if the response is started::\n\n        try:\n            return response(environ, start_response)\n        finally:\n            cleanup_session()\n            cleanup_locals()\n    \"\"\"\n\n    def __init__(\n        self,\n        iterable: t.Iterable[bytes],\n        callbacks: None\n        | (t.Callable[[], None] | t.Iterable[t.Callable[[], None]]) = None,\n    ) -> None:\n        iterator = iter(iterable)\n        self._next = t.cast(t.Callable[[], bytes], partial(next, iterator))\n        if callbacks is None:\n            callbacks = []\n        elif callable(callbacks):\n            callbacks = [callbacks]\n        else:\n            callbacks = list(callbacks)\n        iterable_close = getattr(iterable, \"close\", None)\n        if iterable_close:\n            callbacks.insert(0, iterable_close)\n        self._callbacks = callbacks\n\n    def __iter__(self) -> ClosingIterator:\n        return self\n\n    def __next__(self) -> bytes:\n        return self._next()\n\n    def close(self) -> None:\n        for callback in self._callbacks:\n            callback()\n\n\ndef wrap_file(\n    environ: WSGIEnvironment, file: t.IO[bytes], buffer_size: int = 8192\n) -> t.Iterable[bytes]:\n    \"\"\"Wraps a file.  This uses the WSGI server's file wrapper if available\n    or otherwise the generic :class:`FileWrapper`.\n\n    .. versionadded:: 0.5\n\n    If the file wrapper from the WSGI server is used it's important to not\n    iterate over it from inside the application but to pass it through\n    unchanged.  If you want to pass out a file wrapper inside a response\n    object you have to set :attr:`Response.direct_passthrough` to `True`.\n\n    More information about file wrappers are available in :pep:`333`.\n\n    :param file: a :class:`file`-like object with a :meth:`~file.read` method.\n    :param buffer_size: number of bytes for one iteration.\n    \"\"\"\n    return environ.get(\"wsgi.file_wrapper\", FileWrapper)(  # type: ignore\n        file, buffer_size\n    )\n\n\nclass FileWrapper:\n    \"\"\"This class can be used to convert a :class:`file`-like object into\n    an iterable.  It yields `buffer_size` blocks until the file is fully\n    read.\n\n    You should not use this class directly but rather use the\n    :func:`wrap_file` function that uses the WSGI server's file wrapper\n    support if it's available.\n\n    .. versionadded:: 0.5\n\n    If you're using this object together with a :class:`Response` you have\n    to use the `direct_passthrough` mode.\n\n    :param file: a :class:`file`-like object with a :meth:`~file.read` method.\n    :param buffer_size: number of bytes for one iteration.\n    \"\"\"\n\n    def __init__(self, file: t.IO[bytes], buffer_size: int = 8192) -> None:\n        self.file = file\n        self.buffer_size = buffer_size\n\n    def close(self) -> None:\n        if hasattr(self.file, \"close\"):\n            self.file.close()\n\n    def seekable(self) -> bool:\n        if hasattr(self.file, \"seekable\"):\n            return self.file.seekable()\n        if hasattr(self.file, \"seek\"):\n            return True\n        return False\n\n    def seek(self, *args: t.Any) -> None:\n        if hasattr(self.file, \"seek\"):\n            self.file.seek(*args)\n\n    def tell(self) -> int | None:\n        if hasattr(self.file, \"tell\"):\n            return self.file.tell()\n        return None\n\n    def __iter__(self) -> FileWrapper:\n        return self\n\n    def __next__(self) -> bytes:\n        data = self.file.read(self.buffer_size)\n        if data:\n            return data\n        raise StopIteration()\n\n\nclass _RangeWrapper:\n    # private for now, but should we make it public in the future ?\n\n    \"\"\"This class can be used to convert an iterable object into\n    an iterable that will only yield a piece of the underlying content.\n    It yields blocks until the underlying stream range is fully read.\n    The yielded blocks will have a size that can't exceed the original\n    iterator defined block size, but that can be smaller.\n\n    If you're using this object together with a :class:`Response` you have\n    to use the `direct_passthrough` mode.\n\n    :param iterable: an iterable object with a :meth:`__next__` method.\n    :param start_byte: byte from which read will start.\n    :param byte_range: how many bytes to read.\n    \"\"\"\n\n    def __init__(\n        self,\n        iterable: t.Iterable[bytes] | t.IO[bytes],\n        start_byte: int = 0,\n        byte_range: int | None = None,\n    ):\n        self.iterable = iter(iterable)\n        self.byte_range = byte_range\n        self.start_byte = start_byte\n        self.end_byte = None\n\n        if byte_range is not None:\n            self.end_byte = start_byte + byte_range\n\n        self.read_length = 0\n        self.seekable = hasattr(iterable, \"seekable\") and iterable.seekable()\n        self.end_reached = False\n\n    def __iter__(self) -> _RangeWrapper:\n        return self\n\n    def _next_chunk(self) -> bytes:\n        try:\n            chunk = next(self.iterable)\n            self.read_length += len(chunk)\n            return chunk\n        except StopIteration:\n            self.end_reached = True\n            raise\n\n    def _first_iteration(self) -> tuple[bytes | None, int]:\n        chunk = None\n        if self.seekable:\n            self.iterable.seek(self.start_byte)  # type: ignore\n            self.read_length = self.iterable.tell()  # type: ignore\n            contextual_read_length = self.read_length\n        else:\n            while self.read_length <= self.start_byte:\n                chunk = self._next_chunk()\n            if chunk is not None:\n                chunk = chunk[self.start_byte - self.read_length :]\n            contextual_read_length = self.start_byte\n        return chunk, contextual_read_length\n\n    def _next(self) -> bytes:\n        if self.end_reached:\n            raise StopIteration()\n        chunk = None\n        contextual_read_length = self.read_length\n        if self.read_length == 0:\n            chunk, contextual_read_length = self._first_iteration()\n        if chunk is None:\n            chunk = self._next_chunk()\n        if self.end_byte is not None and self.read_length >= self.end_byte:\n            self.end_reached = True\n            return chunk[: self.end_byte - contextual_read_length]\n        return chunk\n\n    def __next__(self) -> bytes:\n        chunk = self._next()\n        if chunk:\n            return chunk\n        self.end_reached = True\n        raise StopIteration()\n\n    def close(self) -> None:\n        if hasattr(self.iterable, \"close\"):\n            self.iterable.close()\n\n\nclass LimitedStream(io.RawIOBase):\n    \"\"\"Wrap a stream so that it doesn't read more than a given limit. This is used to\n    limit ``wsgi.input`` to the ``Content-Length`` header value or\n    :attr:`.Request.max_content_length`.\n\n    When attempting to read after the limit has been reached, :meth:`on_exhausted` is\n    called. When the limit is a maximum, this raises :exc:`.RequestEntityTooLarge`.\n\n    If reading from the stream returns zero bytes or raises an error,\n    :meth:`on_disconnect` is called, which raises :exc:`.ClientDisconnected`. When the\n    limit is a maximum and zero bytes were read, no error is raised, since it may be the\n    end of the stream.\n\n    If the limit is reached before the underlying stream is exhausted (such as a file\n    that is too large, or an infinite stream), the remaining contents of the stream\n    cannot be read safely. Depending on how the server handles this, clients may show a\n    \"connection reset\" failure instead of seeing the 413 response.\n\n    :param stream: The stream to read from. Must be a readable binary IO object.\n    :param limit: The limit in bytes to not read past. Should be either the\n        ``Content-Length`` header value or ``request.max_content_length``.\n    :param is_max: Whether the given ``limit`` is ``request.max_content_length`` instead\n        of the ``Content-Length`` header value. This changes how exhausted and\n        disconnect events are handled.\n\n    .. versionchanged:: 2.3\n        Handle ``max_content_length`` differently than ``Content-Length``.\n\n    .. versionchanged:: 2.3\n        Implements ``io.RawIOBase`` rather than ``io.IOBase``.\n    \"\"\"\n\n    def __init__(self, stream: t.IO[bytes], limit: int, is_max: bool = False) -> None:\n        self._stream = stream\n        self._pos = 0\n        self.limit = limit\n        self._limit_is_max = is_max\n\n    @property\n    def is_exhausted(self) -> bool:\n        \"\"\"Whether the current stream position has reached the limit.\"\"\"\n        return self._pos >= self.limit\n\n    def on_exhausted(self) -> None:\n        \"\"\"Called when attempting to read after the limit has been reached.\n\n        The default behavior is to do nothing, unless the limit is a maximum, in which\n        case it raises :exc:`.RequestEntityTooLarge`.\n\n        .. versionchanged:: 2.3\n            Raises ``RequestEntityTooLarge`` if the limit is a maximum.\n\n        .. versionchanged:: 2.3\n            Any return value is ignored.\n        \"\"\"\n        if self._limit_is_max:\n            raise RequestEntityTooLarge()\n\n    def on_disconnect(self, error: Exception | None = None) -> None:\n        \"\"\"Called when an attempted read receives zero bytes before the limit was\n        reached. This indicates that the client disconnected before sending the full\n        request body.\n\n        The default behavior is to raise :exc:`.ClientDisconnected`, unless the limit is\n        a maximum and no error was raised.\n\n        .. versionchanged:: 2.3\n            Added the ``error`` parameter. Do nothing if the limit is a maximum and no\n            error was raised.\n\n        .. versionchanged:: 2.3\n            Any return value is ignored.\n        \"\"\"\n        if not self._limit_is_max or error is not None:\n            raise ClientDisconnected()\n\n        # If the limit is a maximum, then we may have read zero bytes because the\n        # streaming body is complete. There's no way to distinguish that from the\n        # client disconnecting early.\n\n    def exhaust(self) -> bytes:\n        \"\"\"Exhaust the stream by reading until the limit is reached or the client\n        disconnects, returning the remaining data.\n\n        .. versionchanged:: 2.3\n            Return the remaining data.\n\n        .. versionchanged:: 2.2.3\n            Handle case where wrapped stream returns fewer bytes than requested.\n        \"\"\"\n        if not self.is_exhausted:\n            return self.readall()\n\n        return b\"\"\n\n    def readinto(self, b: bytearray) -> int | None:  # type: ignore[override]\n        size = len(b)\n        remaining = self.limit - self._pos\n\n        if remaining <= 0:\n            self.on_exhausted()\n            return 0\n\n        if hasattr(self._stream, \"readinto\"):\n            # Use stream.readinto if it's available.\n            if size <= remaining:\n                # The size fits in the remaining limit, use the buffer directly.\n                try:\n                    out_size: int | None = self._stream.readinto(b)\n                except (OSError, ValueError) as e:\n                    self.on_disconnect(error=e)\n                    return 0\n            else:\n                # Use a temp buffer with the remaining limit as the size.\n                temp_b = bytearray(remaining)\n\n                try:\n                    out_size = self._stream.readinto(temp_b)\n                except (OSError, ValueError) as e:\n                    self.on_disconnect(error=e)\n                    return 0\n\n                if out_size:\n                    b[:out_size] = temp_b\n        else:\n            # WSGI requires that stream.read is available.\n            try:\n                data = self._stream.read(min(size, remaining))\n            except (OSError, ValueError) as e:\n                self.on_disconnect(error=e)\n                return 0\n\n            out_size = len(data)\n            b[:out_size] = data\n\n        if not out_size:\n            # Read zero bytes from the stream.\n            self.on_disconnect()\n            return 0\n\n        self._pos += out_size\n        return out_size\n\n    def readall(self) -> bytes:\n        if self.is_exhausted:\n            self.on_exhausted()\n            return b\"\"\n\n        out = bytearray()\n\n        # The parent implementation uses \"while True\", which results in an extra read.\n        while not self.is_exhausted:\n            data = self.read(1024 * 64)\n\n            # Stream may return empty before a max limit is reached.\n            if not data:\n                break\n\n            out.extend(data)\n\n        return bytes(out)\n\n    def tell(self) -> int:\n        \"\"\"Return the current stream position.\n\n        .. versionadded:: 0.9\n        \"\"\"\n        return self._pos\n\n    def readable(self) -> bool:\n        return True\n", "src/werkzeug/user_agent.py": "from __future__ import annotations\n\n\nclass UserAgent:\n    \"\"\"Represents a parsed user agent header value.\n\n    The default implementation does no parsing, only the :attr:`string`\n    attribute is set. A subclass may parse the string to set the\n    common attributes or expose other information. Set\n    :attr:`werkzeug.wrappers.Request.user_agent_class` to use a\n    subclass.\n\n    :param string: The header value to parse.\n\n    .. versionadded:: 2.0\n        This replaces the previous ``useragents`` module, but does not\n        provide a built-in parser.\n    \"\"\"\n\n    platform: str | None = None\n    \"\"\"The OS name, if it could be parsed from the string.\"\"\"\n\n    browser: str | None = None\n    \"\"\"The browser name, if it could be parsed from the string.\"\"\"\n\n    version: str | None = None\n    \"\"\"The browser version, if it could be parsed from the string.\"\"\"\n\n    language: str | None = None\n    \"\"\"The browser language, if it could be parsed from the string.\"\"\"\n\n    def __init__(self, string: str) -> None:\n        self.string: str = string\n        \"\"\"The original header value.\"\"\"\n\n    def __repr__(self) -> str:\n        return f\"<{type(self).__name__} {self.browser}/{self.version}>\"\n\n    def __str__(self) -> str:\n        return self.string\n\n    def __bool__(self) -> bool:\n        return bool(self.browser)\n\n    def to_header(self) -> str:\n        \"\"\"Convert to a header value.\"\"\"\n        return self.string\n", "src/werkzeug/debug/tbtools.py": "from __future__ import annotations\n\nimport itertools\nimport linecache\nimport os\nimport re\nimport sys\nimport sysconfig\nimport traceback\nimport typing as t\n\nfrom markupsafe import escape\n\nfrom ..utils import cached_property\nfrom .console import Console\n\nHEADER = \"\"\"\\\n<!doctype html>\n<html lang=en>\n  <head>\n    <title>%(title)s // Werkzeug Debugger</title>\n    <link rel=\"stylesheet\" href=\"?__debugger__=yes&amp;cmd=resource&amp;f=style.css\">\n    <link rel=\"shortcut icon\"\n        href=\"?__debugger__=yes&amp;cmd=resource&amp;f=console.png\">\n    <script src=\"?__debugger__=yes&amp;cmd=resource&amp;f=debugger.js\"></script>\n    <script>\n      var CONSOLE_MODE = %(console)s,\n          EVALEX = %(evalex)s,\n          EVALEX_TRUSTED = %(evalex_trusted)s,\n          SECRET = \"%(secret)s\";\n    </script>\n  </head>\n  <body style=\"background-color: #fff\">\n    <div class=\"debugger\">\n\"\"\"\n\nFOOTER = \"\"\"\\\n      <div class=\"footer\">\n        Brought to you by <strong class=\"arthur\">DON'T PANIC</strong>, your\n        friendly Werkzeug powered traceback interpreter.\n      </div>\n    </div>\n\n    <div class=\"pin-prompt\">\n      <div class=\"inner\">\n        <h3>Console Locked</h3>\n        <p>\n          The console is locked and needs to be unlocked by entering the PIN.\n          You can find the PIN printed out on the standard output of your\n          shell that runs the server.\n        <form>\n          <p>PIN:\n            <input type=text name=pin size=14>\n            <input type=submit name=btn value=\"Confirm Pin\">\n        </form>\n      </div>\n    </div>\n  </body>\n</html>\n\"\"\"\n\nPAGE_HTML = (\n    HEADER\n    + \"\"\"\\\n<h1>%(exception_type)s</h1>\n<div class=\"detail\">\n  <p class=\"errormsg\">%(exception)s</p>\n</div>\n<h2 class=\"traceback\">Traceback <em>(most recent call last)</em></h2>\n%(summary)s\n<div class=\"plain\">\n    <p>\n      This is the Copy/Paste friendly version of the traceback.\n    </p>\n    <textarea cols=\"50\" rows=\"10\" name=\"code\" readonly>%(plaintext)s</textarea>\n</div>\n<div class=\"explanation\">\n  The debugger caught an exception in your WSGI application.  You can now\n  look at the traceback which led to the error.  <span class=\"nojavascript\">\n  If you enable JavaScript you can also use additional features such as code\n  execution (if the evalex feature is enabled), automatic pasting of the\n  exceptions and much more.</span>\n</div>\n\"\"\"\n    + FOOTER\n    + \"\"\"\n<!--\n\n%(plaintext_cs)s\n\n-->\n\"\"\"\n)\n\nCONSOLE_HTML = (\n    HEADER\n    + \"\"\"\\\n<h1>Interactive Console</h1>\n<div class=\"explanation\">\nIn this console you can execute Python expressions in the context of the\napplication.  The initial namespace was created by the debugger automatically.\n</div>\n<div class=\"console\"><div class=\"inner\">The Console requires JavaScript.</div></div>\n\"\"\"\n    + FOOTER\n)\n\nSUMMARY_HTML = \"\"\"\\\n<div class=\"%(classes)s\">\n  %(title)s\n  <ul>%(frames)s</ul>\n  %(description)s\n</div>\n\"\"\"\n\nFRAME_HTML = \"\"\"\\\n<div class=\"frame\" id=\"frame-%(id)d\">\n  <h4>File <cite class=\"filename\">\"%(filename)s\"</cite>,\n      line <em class=\"line\">%(lineno)s</em>,\n      in <code class=\"function\">%(function_name)s</code></h4>\n  <div class=\"source %(library)s\">%(lines)s</div>\n</div>\n\"\"\"\n\n\ndef _process_traceback(\n    exc: BaseException,\n    te: traceback.TracebackException | None = None,\n    *,\n    skip: int = 0,\n    hide: bool = True,\n) -> traceback.TracebackException:\n    if te is None:\n        te = traceback.TracebackException.from_exception(exc, lookup_lines=False)\n\n    # Get the frames the same way StackSummary.extract did, in order\n    # to match each frame with the FrameSummary to augment.\n    frame_gen = traceback.walk_tb(exc.__traceback__)\n    limit = getattr(sys, \"tracebacklimit\", None)\n\n    if limit is not None:\n        if limit < 0:\n            limit = 0\n\n        frame_gen = itertools.islice(frame_gen, limit)\n\n    if skip:\n        frame_gen = itertools.islice(frame_gen, skip, None)\n        del te.stack[:skip]\n\n    new_stack: list[DebugFrameSummary] = []\n    hidden = False\n\n    # Match each frame with the FrameSummary that was generated.\n    # Hide frames using Paste's __traceback_hide__ rules. Replace\n    # all visible FrameSummary with DebugFrameSummary.\n    for (f, _), fs in zip(frame_gen, te.stack):\n        if hide:\n            hide_value = f.f_locals.get(\"__traceback_hide__\", False)\n\n            if hide_value in {\"before\", \"before_and_this\"}:\n                new_stack = []\n                hidden = False\n\n                if hide_value == \"before_and_this\":\n                    continue\n            elif hide_value in {\"reset\", \"reset_and_this\"}:\n                hidden = False\n\n                if hide_value == \"reset_and_this\":\n                    continue\n            elif hide_value in {\"after\", \"after_and_this\"}:\n                hidden = True\n\n                if hide_value == \"after_and_this\":\n                    continue\n            elif hide_value or hidden:\n                continue\n\n        frame_args: dict[str, t.Any] = {\n            \"filename\": fs.filename,\n            \"lineno\": fs.lineno,\n            \"name\": fs.name,\n            \"locals\": f.f_locals,\n            \"globals\": f.f_globals,\n        }\n\n        if hasattr(fs, \"colno\"):\n            frame_args[\"colno\"] = fs.colno\n            frame_args[\"end_colno\"] = fs.end_colno\n\n        new_stack.append(DebugFrameSummary(**frame_args))\n\n    # The codeop module is used to compile code from the interactive\n    # debugger. Hide any codeop frames from the bottom of the traceback.\n    while new_stack:\n        module = new_stack[0].global_ns.get(\"__name__\")\n\n        if module is None:\n            module = new_stack[0].local_ns.get(\"__name__\")\n\n        if module == \"codeop\":\n            del new_stack[0]\n        else:\n            break\n\n    te.stack[:] = new_stack\n\n    if te.__context__:\n        context_exc = t.cast(BaseException, exc.__context__)\n        te.__context__ = _process_traceback(context_exc, te.__context__, hide=hide)\n\n    if te.__cause__:\n        cause_exc = t.cast(BaseException, exc.__cause__)\n        te.__cause__ = _process_traceback(cause_exc, te.__cause__, hide=hide)\n\n    return te\n\n\nclass DebugTraceback:\n    __slots__ = (\"_te\", \"_cache_all_tracebacks\", \"_cache_all_frames\")\n\n    def __init__(\n        self,\n        exc: BaseException,\n        te: traceback.TracebackException | None = None,\n        *,\n        skip: int = 0,\n        hide: bool = True,\n    ) -> None:\n        self._te = _process_traceback(exc, te, skip=skip, hide=hide)\n\n    def __str__(self) -> str:\n        return f\"<{type(self).__name__} {self._te}>\"\n\n    @cached_property\n    def all_tracebacks(\n        self,\n    ) -> list[tuple[str | None, traceback.TracebackException]]:\n        out = []\n        current = self._te\n\n        while current is not None:\n            if current.__cause__ is not None:\n                chained_msg = (\n                    \"The above exception was the direct cause of the\"\n                    \" following exception\"\n                )\n                chained_exc = current.__cause__\n            elif current.__context__ is not None and not current.__suppress_context__:\n                chained_msg = (\n                    \"During handling of the above exception, another\"\n                    \" exception occurred\"\n                )\n                chained_exc = current.__context__\n            else:\n                chained_msg = None\n                chained_exc = None\n\n            out.append((chained_msg, current))\n            current = chained_exc\n\n        return out\n\n    @cached_property\n    def all_frames(self) -> list[DebugFrameSummary]:\n        return [\n            f  # type: ignore[misc]\n            for _, te in self.all_tracebacks\n            for f in te.stack\n        ]\n\n    def render_traceback_text(self) -> str:\n        return \"\".join(self._te.format())\n\n    def render_traceback_html(self, include_title: bool = True) -> str:\n        library_frames = [f.is_library for f in self.all_frames]\n        mark_library = 0 < sum(library_frames) < len(library_frames)\n        rows = []\n\n        if not library_frames:\n            classes = \"traceback noframe-traceback\"\n        else:\n            classes = \"traceback\"\n\n            for msg, current in reversed(self.all_tracebacks):\n                row_parts = []\n\n                if msg is not None:\n                    row_parts.append(f'<li><div class=\"exc-divider\">{msg}:</div>')\n\n                for frame in current.stack:\n                    frame = t.cast(DebugFrameSummary, frame)\n                    info = f' title=\"{escape(frame.info)}\"' if frame.info else \"\"\n                    row_parts.append(f\"<li{info}>{frame.render_html(mark_library)}\")\n\n                rows.append(\"\\n\".join(row_parts))\n\n        if sys.version_info < (3, 13):\n            exc_type_str = self._te.exc_type.__name__\n        else:\n            exc_type_str = self._te.exc_type_str\n\n        is_syntax_error = exc_type_str == \"SyntaxError\"\n\n        if include_title:\n            if is_syntax_error:\n                title = \"Syntax Error\"\n            else:\n                title = \"Traceback <em>(most recent call last)</em>:\"\n        else:\n            title = \"\"\n\n        exc_full = escape(\"\".join(self._te.format_exception_only()))\n\n        if is_syntax_error:\n            description = f\"<pre class=syntaxerror>{exc_full}</pre>\"\n        else:\n            description = f\"<blockquote>{exc_full}</blockquote>\"\n\n        return SUMMARY_HTML % {\n            \"classes\": classes,\n            \"title\": f\"<h3>{title}</h3>\",\n            \"frames\": \"\\n\".join(rows),\n            \"description\": description,\n        }\n\n    def render_debugger_html(\n        self, evalex: bool, secret: str, evalex_trusted: bool\n    ) -> str:\n        exc_lines = list(self._te.format_exception_only())\n        plaintext = \"\".join(self._te.format())\n\n        if sys.version_info < (3, 13):\n            exc_type_str = self._te.exc_type.__name__\n        else:\n            exc_type_str = self._te.exc_type_str\n\n        return PAGE_HTML % {\n            \"evalex\": \"true\" if evalex else \"false\",\n            \"evalex_trusted\": \"true\" if evalex_trusted else \"false\",\n            \"console\": \"false\",\n            \"title\": escape(exc_lines[0]),\n            \"exception\": escape(\"\".join(exc_lines)),\n            \"exception_type\": escape(exc_type_str),\n            \"summary\": self.render_traceback_html(include_title=False),\n            \"plaintext\": escape(plaintext),\n            \"plaintext_cs\": re.sub(\"-{2,}\", \"-\", plaintext),\n            \"secret\": secret,\n        }\n\n\nclass DebugFrameSummary(traceback.FrameSummary):\n    \"\"\"A :class:`traceback.FrameSummary` that can evaluate code in the\n    frame's namespace.\n    \"\"\"\n\n    __slots__ = (\n        \"local_ns\",\n        \"global_ns\",\n        \"_cache_info\",\n        \"_cache_is_library\",\n        \"_cache_console\",\n    )\n\n    def __init__(\n        self,\n        *,\n        locals: dict[str, t.Any],\n        globals: dict[str, t.Any],\n        **kwargs: t.Any,\n    ) -> None:\n        super().__init__(locals=None, **kwargs)\n        self.local_ns = locals\n        self.global_ns = globals\n\n    @cached_property\n    def info(self) -> str | None:\n        return self.local_ns.get(\"__traceback_info__\")\n\n    @cached_property\n    def is_library(self) -> bool:\n        return any(\n            self.filename.startswith((path, os.path.realpath(path)))\n            for path in sysconfig.get_paths().values()\n        )\n\n    @cached_property\n    def console(self) -> Console:\n        return Console(self.global_ns, self.local_ns)\n\n    def eval(self, code: str) -> t.Any:\n        return self.console.eval(code)\n\n    def render_html(self, mark_library: bool) -> str:\n        context = 5\n        lines = linecache.getlines(self.filename)\n        line_idx = self.lineno - 1  # type: ignore[operator]\n        start_idx = max(0, line_idx - context)\n        stop_idx = min(len(lines), line_idx + context + 1)\n        rendered_lines = []\n\n        def render_line(line: str, cls: str) -> None:\n            line = line.expandtabs().rstrip()\n            stripped_line = line.strip()\n            prefix = len(line) - len(stripped_line)\n            colno = getattr(self, \"colno\", 0)\n            end_colno = getattr(self, \"end_colno\", 0)\n\n            if cls == \"current\" and colno and end_colno:\n                arrow = (\n                    f'\\n<span class=\"ws\">{\" \" * prefix}</span>'\n                    f'{\" \" * (colno - prefix)}{\"^\" * (end_colno - colno)}'\n                )\n            else:\n                arrow = \"\"\n\n            rendered_lines.append(\n                f'<pre class=\"line {cls}\"><span class=\"ws\">{\" \" * prefix}</span>'\n                f\"{escape(stripped_line) if stripped_line else ' '}\"\n                f\"{arrow if arrow else ''}</pre>\"\n            )\n\n        if lines:\n            for line in lines[start_idx:line_idx]:\n                render_line(line, \"before\")\n\n            render_line(lines[line_idx], \"current\")\n\n            for line in lines[line_idx + 1 : stop_idx]:\n                render_line(line, \"after\")\n\n        return FRAME_HTML % {\n            \"id\": id(self),\n            \"filename\": escape(self.filename),\n            \"lineno\": self.lineno,\n            \"function_name\": escape(self.name),\n            \"lines\": \"\\n\".join(rendered_lines),\n            \"library\": \"library\" if mark_library and self.is_library else \"\",\n        }\n\n\ndef render_console_html(secret: str, evalex_trusted: bool) -> str:\n    return CONSOLE_HTML % {\n        \"evalex\": \"true\",\n        \"evalex_trusted\": \"true\" if evalex_trusted else \"false\",\n        \"console\": \"true\",\n        \"title\": \"Console\",\n        \"secret\": secret,\n    }\n", "src/werkzeug/debug/repr.py": "\"\"\"Object representations for debugging purposes. Unlike the default\nrepr, these expose more information and produce HTML instead of ASCII.\n\nTogether with the CSS and JavaScript of the debugger this gives a\ncolorful and more compact output.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport codecs\nimport re\nimport sys\nimport typing as t\nfrom collections import deque\nfrom traceback import format_exception_only\n\nfrom markupsafe import escape\n\nmissing = object()\n_paragraph_re = re.compile(r\"(?:\\r\\n|\\r|\\n){2,}\")\nRegexType = type(_paragraph_re)\n\nHELP_HTML = \"\"\"\\\n<div class=box>\n  <h3>%(title)s</h3>\n  <pre class=help>%(text)s</pre>\n</div>\\\n\"\"\"\nOBJECT_DUMP_HTML = \"\"\"\\\n<div class=box>\n  <h3>%(title)s</h3>\n  %(repr)s\n  <table>%(items)s</table>\n</div>\\\n\"\"\"\n\n\ndef debug_repr(obj: object) -> str:\n    \"\"\"Creates a debug repr of an object as HTML string.\"\"\"\n    return DebugReprGenerator().repr(obj)\n\n\ndef dump(obj: object = missing) -> None:\n    \"\"\"Print the object details to stdout._write (for the interactive\n    console of the web debugger.\n    \"\"\"\n    gen = DebugReprGenerator()\n    if obj is missing:\n        rv = gen.dump_locals(sys._getframe(1).f_locals)\n    else:\n        rv = gen.dump_object(obj)\n    sys.stdout._write(rv)  # type: ignore\n\n\nclass _Helper:\n    \"\"\"Displays an HTML version of the normal help, for the interactive\n    debugger only because it requires a patched sys.stdout.\n    \"\"\"\n\n    def __repr__(self) -> str:\n        return \"Type help(object) for help about object.\"\n\n    def __call__(self, topic: t.Any | None = None) -> None:\n        if topic is None:\n            sys.stdout._write(f\"<span class=help>{self!r}</span>\")  # type: ignore\n            return\n        import pydoc\n\n        pydoc.help(topic)\n        rv = sys.stdout.reset()  # type: ignore\n        paragraphs = _paragraph_re.split(rv)\n        if len(paragraphs) > 1:\n            title = paragraphs[0]\n            text = \"\\n\\n\".join(paragraphs[1:])\n        else:\n            title = \"Help\"\n            text = paragraphs[0]\n        sys.stdout._write(HELP_HTML % {\"title\": title, \"text\": text})  # type: ignore\n\n\nhelper = _Helper()\n\n\ndef _add_subclass_info(inner: str, obj: object, base: type | tuple[type, ...]) -> str:\n    if isinstance(base, tuple):\n        for cls in base:\n            if type(obj) is cls:\n                return inner\n    elif type(obj) is base:\n        return inner\n    module = \"\"\n    if obj.__class__.__module__ not in (\"__builtin__\", \"exceptions\"):\n        module = f'<span class=\"module\">{obj.__class__.__module__}.</span>'\n    return f\"{module}{type(obj).__name__}({inner})\"\n\n\ndef _sequence_repr_maker(\n    left: str, right: str, base: type, limit: int = 8\n) -> t.Callable[[DebugReprGenerator, t.Iterable[t.Any], bool], str]:\n    def proxy(self: DebugReprGenerator, obj: t.Iterable[t.Any], recursive: bool) -> str:\n        if recursive:\n            return _add_subclass_info(f\"{left}...{right}\", obj, base)\n        buf = [left]\n        have_extended_section = False\n        for idx, item in enumerate(obj):\n            if idx:\n                buf.append(\", \")\n            if idx == limit:\n                buf.append('<span class=\"extended\">')\n                have_extended_section = True\n            buf.append(self.repr(item))\n        if have_extended_section:\n            buf.append(\"</span>\")\n        buf.append(right)\n        return _add_subclass_info(\"\".join(buf), obj, base)\n\n    return proxy\n\n\nclass DebugReprGenerator:\n    def __init__(self) -> None:\n        self._stack: list[t.Any] = []\n\n    list_repr = _sequence_repr_maker(\"[\", \"]\", list)\n    tuple_repr = _sequence_repr_maker(\"(\", \")\", tuple)\n    set_repr = _sequence_repr_maker(\"set([\", \"])\", set)\n    frozenset_repr = _sequence_repr_maker(\"frozenset([\", \"])\", frozenset)\n    deque_repr = _sequence_repr_maker(\n        '<span class=\"module\">collections.</span>deque([', \"])\", deque\n    )\n\n    def regex_repr(self, obj: t.Pattern[t.AnyStr]) -> str:\n        pattern = repr(obj.pattern)\n        pattern = codecs.decode(pattern, \"unicode-escape\", \"ignore\")\n        pattern = f\"r{pattern}\"\n        return f're.compile(<span class=\"string regex\">{pattern}</span>)'\n\n    def string_repr(self, obj: str | bytes, limit: int = 70) -> str:\n        buf = ['<span class=\"string\">']\n        r = repr(obj)\n\n        # shorten the repr when the hidden part would be at least 3 chars\n        if len(r) - limit > 2:\n            buf.extend(\n                (\n                    escape(r[:limit]),\n                    '<span class=\"extended\">',\n                    escape(r[limit:]),\n                    \"</span>\",\n                )\n            )\n        else:\n            buf.append(escape(r))\n\n        buf.append(\"</span>\")\n        out = \"\".join(buf)\n\n        # if the repr looks like a standard string, add subclass info if needed\n        if r[0] in \"'\\\"\" or (r[0] == \"b\" and r[1] in \"'\\\"\"):\n            return _add_subclass_info(out, obj, (bytes, str))\n\n        # otherwise, assume the repr distinguishes the subclass already\n        return out\n\n    def dict_repr(\n        self,\n        d: dict[int, None] | dict[str, int] | dict[str | int, int],\n        recursive: bool,\n        limit: int = 5,\n    ) -> str:\n        if recursive:\n            return _add_subclass_info(\"{...}\", d, dict)\n        buf = [\"{\"]\n        have_extended_section = False\n        for idx, (key, value) in enumerate(d.items()):\n            if idx:\n                buf.append(\", \")\n            if idx == limit - 1:\n                buf.append('<span class=\"extended\">')\n                have_extended_section = True\n            buf.append(\n                f'<span class=\"pair\"><span class=\"key\">{self.repr(key)}</span>:'\n                f' <span class=\"value\">{self.repr(value)}</span></span>'\n            )\n        if have_extended_section:\n            buf.append(\"</span>\")\n        buf.append(\"}\")\n        return _add_subclass_info(\"\".join(buf), d, dict)\n\n    def object_repr(self, obj: t.Any) -> str:\n        r = repr(obj)\n        return f'<span class=\"object\">{escape(r)}</span>'\n\n    def dispatch_repr(self, obj: t.Any, recursive: bool) -> str:\n        if obj is helper:\n            return f'<span class=\"help\">{helper!r}</span>'\n        if isinstance(obj, (int, float, complex)):\n            return f'<span class=\"number\">{obj!r}</span>'\n        if isinstance(obj, str) or isinstance(obj, bytes):\n            return self.string_repr(obj)\n        if isinstance(obj, RegexType):\n            return self.regex_repr(obj)\n        if isinstance(obj, list):\n            return self.list_repr(obj, recursive)\n        if isinstance(obj, tuple):\n            return self.tuple_repr(obj, recursive)\n        if isinstance(obj, set):\n            return self.set_repr(obj, recursive)\n        if isinstance(obj, frozenset):\n            return self.frozenset_repr(obj, recursive)\n        if isinstance(obj, dict):\n            return self.dict_repr(obj, recursive)\n        if isinstance(obj, deque):\n            return self.deque_repr(obj, recursive)\n        return self.object_repr(obj)\n\n    def fallback_repr(self) -> str:\n        try:\n            info = \"\".join(format_exception_only(*sys.exc_info()[:2]))\n        except Exception:\n            info = \"?\"\n        return (\n            '<span class=\"brokenrepr\">'\n            f\"&lt;broken repr ({escape(info.strip())})&gt;</span>\"\n        )\n\n    def repr(self, obj: object) -> str:\n        recursive = False\n        for item in self._stack:\n            if item is obj:\n                recursive = True\n                break\n        self._stack.append(obj)\n        try:\n            try:\n                return self.dispatch_repr(obj, recursive)\n            except Exception:\n                return self.fallback_repr()\n        finally:\n            self._stack.pop()\n\n    def dump_object(self, obj: object) -> str:\n        repr = None\n        items: list[tuple[str, str]] | None = None\n\n        if isinstance(obj, dict):\n            title = \"Contents of\"\n            items = []\n            for key, value in obj.items():\n                if not isinstance(key, str):\n                    items = None\n                    break\n                items.append((key, self.repr(value)))\n        if items is None:\n            items = []\n            repr = self.repr(obj)\n            for key in dir(obj):\n                try:\n                    items.append((key, self.repr(getattr(obj, key))))\n                except Exception:\n                    pass\n            title = \"Details for\"\n        title += f\" {object.__repr__(obj)[1:-1]}\"\n        return self.render_object_dump(items, title, repr)\n\n    def dump_locals(self, d: dict[str, t.Any]) -> str:\n        items = [(key, self.repr(value)) for key, value in d.items()]\n        return self.render_object_dump(items, \"Local variables in frame\")\n\n    def render_object_dump(\n        self, items: list[tuple[str, str]], title: str, repr: str | None = None\n    ) -> str:\n        html_items = []\n        for key, value in items:\n            html_items.append(f\"<tr><th>{escape(key)}<td><pre class=repr>{value}</pre>\")\n        if not html_items:\n            html_items.append(\"<tr><td><em>Nothing</em>\")\n        return OBJECT_DUMP_HTML % {\n            \"title\": escape(title),\n            \"repr\": f\"<pre class=repr>{repr if repr else ''}</pre>\",\n            \"items\": \"\\n\".join(html_items),\n        }\n", "src/werkzeug/debug/console.py": "from __future__ import annotations\n\nimport code\nimport sys\nimport typing as t\nfrom contextvars import ContextVar\nfrom types import CodeType\n\nfrom markupsafe import escape\n\nfrom .repr import debug_repr\nfrom .repr import dump\nfrom .repr import helper\n\n_stream: ContextVar[HTMLStringO] = ContextVar(\"werkzeug.debug.console.stream\")\n_ipy: ContextVar[_InteractiveConsole] = ContextVar(\"werkzeug.debug.console.ipy\")\n\n\nclass HTMLStringO:\n    \"\"\"A StringO version that HTML escapes on write.\"\"\"\n\n    def __init__(self) -> None:\n        self._buffer: list[str] = []\n\n    def isatty(self) -> bool:\n        return False\n\n    def close(self) -> None:\n        pass\n\n    def flush(self) -> None:\n        pass\n\n    def seek(self, n: int, mode: int = 0) -> None:\n        pass\n\n    def readline(self) -> str:\n        if len(self._buffer) == 0:\n            return \"\"\n        ret = self._buffer[0]\n        del self._buffer[0]\n        return ret\n\n    def reset(self) -> str:\n        val = \"\".join(self._buffer)\n        del self._buffer[:]\n        return val\n\n    def _write(self, x: str) -> None:\n        self._buffer.append(x)\n\n    def write(self, x: str) -> None:\n        self._write(escape(x))\n\n    def writelines(self, x: t.Iterable[str]) -> None:\n        self._write(escape(\"\".join(x)))\n\n\nclass ThreadedStream:\n    \"\"\"Thread-local wrapper for sys.stdout for the interactive console.\"\"\"\n\n    @staticmethod\n    def push() -> None:\n        if not isinstance(sys.stdout, ThreadedStream):\n            sys.stdout = t.cast(t.TextIO, ThreadedStream())\n\n        _stream.set(HTMLStringO())\n\n    @staticmethod\n    def fetch() -> str:\n        try:\n            stream = _stream.get()\n        except LookupError:\n            return \"\"\n\n        return stream.reset()\n\n    @staticmethod\n    def displayhook(obj: object) -> None:\n        try:\n            stream = _stream.get()\n        except LookupError:\n            return _displayhook(obj)  # type: ignore\n\n        # stream._write bypasses escaping as debug_repr is\n        # already generating HTML for us.\n        if obj is not None:\n            _ipy.get().locals[\"_\"] = obj\n            stream._write(debug_repr(obj))\n\n    def __setattr__(self, name: str, value: t.Any) -> None:\n        raise AttributeError(f\"read only attribute {name}\")\n\n    def __dir__(self) -> list[str]:\n        return dir(sys.__stdout__)\n\n    def __getattribute__(self, name: str) -> t.Any:\n        try:\n            stream = _stream.get()\n        except LookupError:\n            stream = sys.__stdout__  # type: ignore[assignment]\n\n        return getattr(stream, name)\n\n    def __repr__(self) -> str:\n        return repr(sys.__stdout__)\n\n\n# add the threaded stream as display hook\n_displayhook = sys.displayhook\nsys.displayhook = ThreadedStream.displayhook\n\n\nclass _ConsoleLoader:\n    def __init__(self) -> None:\n        self._storage: dict[int, str] = {}\n\n    def register(self, code: CodeType, source: str) -> None:\n        self._storage[id(code)] = source\n        # register code objects of wrapped functions too.\n        for var in code.co_consts:\n            if isinstance(var, CodeType):\n                self._storage[id(var)] = source\n\n    def get_source_by_code(self, code: CodeType) -> str | None:\n        try:\n            return self._storage[id(code)]\n        except KeyError:\n            return None\n\n\nclass _InteractiveConsole(code.InteractiveInterpreter):\n    locals: dict[str, t.Any]\n\n    def __init__(self, globals: dict[str, t.Any], locals: dict[str, t.Any]) -> None:\n        self.loader = _ConsoleLoader()\n        locals = {\n            **globals,\n            **locals,\n            \"dump\": dump,\n            \"help\": helper,\n            \"__loader__\": self.loader,\n        }\n        super().__init__(locals)\n        original_compile = self.compile\n\n        def compile(source: str, filename: str, symbol: str) -> CodeType | None:\n            code = original_compile(source, filename, symbol)\n\n            if code is not None:\n                self.loader.register(code, source)\n\n            return code\n\n        self.compile = compile  # type: ignore[assignment]\n        self.more = False\n        self.buffer: list[str] = []\n\n    def runsource(self, source: str, **kwargs: t.Any) -> str:  # type: ignore\n        source = f\"{source.rstrip()}\\n\"\n        ThreadedStream.push()\n        prompt = \"... \" if self.more else \">>> \"\n        try:\n            source_to_eval = \"\".join(self.buffer + [source])\n            if super().runsource(source_to_eval, \"<debugger>\", \"single\"):\n                self.more = True\n                self.buffer.append(source)\n            else:\n                self.more = False\n                del self.buffer[:]\n        finally:\n            output = ThreadedStream.fetch()\n        return f\"{prompt}{escape(source)}{output}\"\n\n    def runcode(self, code: CodeType) -> None:\n        try:\n            exec(code, self.locals)\n        except Exception:\n            self.showtraceback()\n\n    def showtraceback(self) -> None:\n        from .tbtools import DebugTraceback\n\n        exc = t.cast(BaseException, sys.exc_info()[1])\n        te = DebugTraceback(exc, skip=1)\n        sys.stdout._write(te.render_traceback_html())  # type: ignore\n\n    def showsyntaxerror(self, filename: str | None = None) -> None:\n        from .tbtools import DebugTraceback\n\n        exc = t.cast(BaseException, sys.exc_info()[1])\n        te = DebugTraceback(exc, skip=4)\n        sys.stdout._write(te.render_traceback_html())  # type: ignore\n\n    def write(self, data: str) -> None:\n        sys.stdout.write(data)\n\n\nclass Console:\n    \"\"\"An interactive console.\"\"\"\n\n    def __init__(\n        self,\n        globals: dict[str, t.Any] | None = None,\n        locals: dict[str, t.Any] | None = None,\n    ) -> None:\n        if locals is None:\n            locals = {}\n        if globals is None:\n            globals = {}\n        self._ipy = _InteractiveConsole(globals, locals)\n\n    def eval(self, code: str) -> str:\n        _ipy.set(self._ipy)\n        old_sys_stdout = sys.stdout\n        try:\n            return self._ipy.runsource(code)\n        finally:\n            sys.stdout = old_sys_stdout\n", "src/werkzeug/debug/__init__.py": "from __future__ import annotations\n\nimport getpass\nimport hashlib\nimport json\nimport os\nimport pkgutil\nimport re\nimport sys\nimport time\nimport typing as t\nimport uuid\nfrom contextlib import ExitStack\nfrom io import BytesIO\nfrom itertools import chain\nfrom os.path import basename\nfrom os.path import join\nfrom zlib import adler32\n\nfrom .._internal import _log\nfrom ..exceptions import NotFound\nfrom ..exceptions import SecurityError\nfrom ..http import parse_cookie\nfrom ..sansio.utils import host_is_trusted\nfrom ..security import gen_salt\nfrom ..utils import send_file\nfrom ..wrappers.request import Request\nfrom ..wrappers.response import Response\nfrom .console import Console\nfrom .tbtools import DebugFrameSummary\nfrom .tbtools import DebugTraceback\nfrom .tbtools import render_console_html\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import StartResponse\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n\n# A week\nPIN_TIME = 60 * 60 * 24 * 7\n\n\ndef hash_pin(pin: str) -> str:\n    return hashlib.sha1(f\"{pin} added salt\".encode(\"utf-8\", \"replace\")).hexdigest()[:12]\n\n\n_machine_id: str | bytes | None = None\n\n\ndef get_machine_id() -> str | bytes | None:\n    global _machine_id\n\n    if _machine_id is not None:\n        return _machine_id\n\n    def _generate() -> str | bytes | None:\n        linux = b\"\"\n\n        # machine-id is stable across boots, boot_id is not.\n        for filename in \"/etc/machine-id\", \"/proc/sys/kernel/random/boot_id\":\n            try:\n                with open(filename, \"rb\") as f:\n                    value = f.readline().strip()\n            except OSError:\n                continue\n\n            if value:\n                linux += value\n                break\n\n        # Containers share the same machine id, add some cgroup\n        # information. This is used outside containers too but should be\n        # relatively stable across boots.\n        try:\n            with open(\"/proc/self/cgroup\", \"rb\") as f:\n                linux += f.readline().strip().rpartition(b\"/\")[2]\n        except OSError:\n            pass\n\n        if linux:\n            return linux\n\n        # On OS X, use ioreg to get the computer's serial number.\n        try:\n            # subprocess may not be available, e.g. Google App Engine\n            # https://github.com/pallets/werkzeug/issues/925\n            from subprocess import PIPE\n            from subprocess import Popen\n\n            dump = Popen(\n                [\"ioreg\", \"-c\", \"IOPlatformExpertDevice\", \"-d\", \"2\"], stdout=PIPE\n            ).communicate()[0]\n            match = re.search(b'\"serial-number\" = <([^>]+)', dump)\n\n            if match is not None:\n                return match.group(1)\n        except (OSError, ImportError):\n            pass\n\n        # On Windows, use winreg to get the machine guid.\n        if sys.platform == \"win32\":\n            import winreg\n\n            try:\n                with winreg.OpenKey(\n                    winreg.HKEY_LOCAL_MACHINE,\n                    \"SOFTWARE\\\\Microsoft\\\\Cryptography\",\n                    0,\n                    winreg.KEY_READ | winreg.KEY_WOW64_64KEY,\n                ) as rk:\n                    guid: str | bytes\n                    guid_type: int\n                    guid, guid_type = winreg.QueryValueEx(rk, \"MachineGuid\")\n\n                    if guid_type == winreg.REG_SZ:\n                        return guid.encode()\n\n                    return guid\n            except OSError:\n                pass\n\n        return None\n\n    _machine_id = _generate()\n    return _machine_id\n\n\nclass _ConsoleFrame:\n    \"\"\"Helper class so that we can reuse the frame console code for the\n    standalone console.\n    \"\"\"\n\n    def __init__(self, namespace: dict[str, t.Any]):\n        self.console = Console(namespace)\n        self.id = 0\n\n    def eval(self, code: str) -> t.Any:\n        return self.console.eval(code)\n\n\ndef get_pin_and_cookie_name(\n    app: WSGIApplication,\n) -> tuple[str, str] | tuple[None, None]:\n    \"\"\"Given an application object this returns a semi-stable 9 digit pin\n    code and a random key.  The hope is that this is stable between\n    restarts to not make debugging particularly frustrating.  If the pin\n    was forcefully disabled this returns `None`.\n\n    Second item in the resulting tuple is the cookie name for remembering.\n    \"\"\"\n    pin = os.environ.get(\"WERKZEUG_DEBUG_PIN\")\n    rv = None\n    num = None\n\n    # Pin was explicitly disabled\n    if pin == \"off\":\n        return None, None\n\n    # Pin was provided explicitly\n    if pin is not None and pin.replace(\"-\", \"\").isdecimal():\n        # If there are separators in the pin, return it directly\n        if \"-\" in pin:\n            rv = pin\n        else:\n            num = pin\n\n    modname = getattr(app, \"__module__\", t.cast(object, app).__class__.__module__)\n    username: str | None\n\n    try:\n        # getuser imports the pwd module, which does not exist in Google\n        # App Engine. It may also raise a KeyError if the UID does not\n        # have a username, such as in Docker.\n        username = getpass.getuser()\n    except (ImportError, KeyError):\n        username = None\n\n    mod = sys.modules.get(modname)\n\n    # This information only exists to make the cookie unique on the\n    # computer, not as a security feature.\n    probably_public_bits = [\n        username,\n        modname,\n        getattr(app, \"__name__\", type(app).__name__),\n        getattr(mod, \"__file__\", None),\n    ]\n\n    # This information is here to make it harder for an attacker to\n    # guess the cookie name.  They are unlikely to be contained anywhere\n    # within the unauthenticated debug page.\n    private_bits = [str(uuid.getnode()), get_machine_id()]\n\n    h = hashlib.sha1()\n    for bit in chain(probably_public_bits, private_bits):\n        if not bit:\n            continue\n        if isinstance(bit, str):\n            bit = bit.encode()\n        h.update(bit)\n    h.update(b\"cookiesalt\")\n\n    cookie_name = f\"__wzd{h.hexdigest()[:20]}\"\n\n    # If we need to generate a pin we salt it a bit more so that we don't\n    # end up with the same value and generate out 9 digits\n    if num is None:\n        h.update(b\"pinsalt\")\n        num = f\"{int(h.hexdigest(), 16):09d}\"[:9]\n\n    # Format the pincode in groups of digits for easier remembering if\n    # we don't have a result yet.\n    if rv is None:\n        for group_size in 5, 4, 3:\n            if len(num) % group_size == 0:\n                rv = \"-\".join(\n                    num[x : x + group_size].rjust(group_size, \"0\")\n                    for x in range(0, len(num), group_size)\n                )\n                break\n        else:\n            rv = num\n\n    return rv, cookie_name\n\n\nclass DebuggedApplication:\n    \"\"\"Enables debugging support for a given application::\n\n        from werkzeug.debug import DebuggedApplication\n        from myapp import app\n        app = DebuggedApplication(app, evalex=True)\n\n    The ``evalex`` argument allows evaluating expressions in any frame\n    of a traceback. This works by preserving each frame with its local\n    state. Some state, such as context globals, cannot be restored with\n    the frame by default. When ``evalex`` is enabled,\n    ``environ[\"werkzeug.debug.preserve_context\"]`` will be a callable\n    that takes a context manager, and can be called multiple times.\n    Each context manager will be entered before evaluating code in the\n    frame, then exited again, so they can perform setup and cleanup for\n    each call.\n\n    :param app: the WSGI application to run debugged.\n    :param evalex: enable exception evaluation feature (interactive\n                   debugging).  This requires a non-forking server.\n    :param request_key: The key that points to the request object in this\n                        environment.  This parameter is ignored in current\n                        versions.\n    :param console_path: the URL for a general purpose console.\n    :param console_init_func: the function that is executed before starting\n                              the general purpose console.  The return value\n                              is used as initial namespace.\n    :param show_hidden_frames: by default hidden traceback frames are skipped.\n                               You can show them by setting this parameter\n                               to `True`.\n    :param pin_security: can be used to disable the pin based security system.\n    :param pin_logging: enables the logging of the pin system.\n\n    .. versionchanged:: 2.2\n        Added the ``werkzeug.debug.preserve_context`` environ key.\n    \"\"\"\n\n    _pin: str\n    _pin_cookie: str\n\n    def __init__(\n        self,\n        app: WSGIApplication,\n        evalex: bool = False,\n        request_key: str = \"werkzeug.request\",\n        console_path: str = \"/console\",\n        console_init_func: t.Callable[[], dict[str, t.Any]] | None = None,\n        show_hidden_frames: bool = False,\n        pin_security: bool = True,\n        pin_logging: bool = True,\n    ) -> None:\n        if not console_init_func:\n            console_init_func = None\n        self.app = app\n        self.evalex = evalex\n        self.frames: dict[int, DebugFrameSummary | _ConsoleFrame] = {}\n        self.frame_contexts: dict[int, list[t.ContextManager[None]]] = {}\n        self.request_key = request_key\n        self.console_path = console_path\n        self.console_init_func = console_init_func\n        self.show_hidden_frames = show_hidden_frames\n        self.secret = gen_salt(20)\n        self._failed_pin_auth = 0\n\n        self.pin_logging = pin_logging\n        if pin_security:\n            # Print out the pin for the debugger on standard out.\n            if os.environ.get(\"WERKZEUG_RUN_MAIN\") == \"true\" and pin_logging:\n                _log(\"warning\", \" * Debugger is active!\")\n                if self.pin is None:\n                    _log(\"warning\", \" * Debugger PIN disabled. DEBUGGER UNSECURED!\")\n                else:\n                    _log(\"info\", \" * Debugger PIN: %s\", self.pin)\n        else:\n            self.pin = None\n\n        self.trusted_hosts: list[str] = [\".localhost\", \"127.0.0.1\"]\n        \"\"\"List of domains to allow requests to the debugger from. A leading dot\n        allows all subdomains. This only allows ``\".localhost\"`` domains by\n        default.\n\n        .. versionadded:: 3.0.3\n        \"\"\"\n\n    @property\n    def pin(self) -> str | None:\n        if not hasattr(self, \"_pin\"):\n            pin_cookie = get_pin_and_cookie_name(self.app)\n            self._pin, self._pin_cookie = pin_cookie  # type: ignore\n        return self._pin\n\n    @pin.setter\n    def pin(self, value: str) -> None:\n        self._pin = value\n\n    @property\n    def pin_cookie_name(self) -> str:\n        \"\"\"The name of the pin cookie.\"\"\"\n        if not hasattr(self, \"_pin_cookie\"):\n            pin_cookie = get_pin_and_cookie_name(self.app)\n            self._pin, self._pin_cookie = pin_cookie  # type: ignore\n        return self._pin_cookie\n\n    def debug_application(\n        self, environ: WSGIEnvironment, start_response: StartResponse\n    ) -> t.Iterator[bytes]:\n        \"\"\"Run the application and conserve the traceback frames.\"\"\"\n        contexts: list[t.ContextManager[t.Any]] = []\n\n        if self.evalex:\n            environ[\"werkzeug.debug.preserve_context\"] = contexts.append\n\n        app_iter = None\n        try:\n            app_iter = self.app(environ, start_response)\n            yield from app_iter\n            if hasattr(app_iter, \"close\"):\n                app_iter.close()\n        except Exception as e:\n            if hasattr(app_iter, \"close\"):\n                app_iter.close()  # type: ignore\n\n            tb = DebugTraceback(e, skip=1, hide=not self.show_hidden_frames)\n\n            for frame in tb.all_frames:\n                self.frames[id(frame)] = frame\n                self.frame_contexts[id(frame)] = contexts\n\n            is_trusted = bool(self.check_pin_trust(environ))\n            html = tb.render_debugger_html(\n                evalex=self.evalex and self.check_host_trust(environ),\n                secret=self.secret,\n                evalex_trusted=is_trusted,\n            )\n            response = Response(html, status=500, mimetype=\"text/html\")\n\n            try:\n                yield from response(environ, start_response)\n            except Exception:\n                # if we end up here there has been output but an error\n                # occurred.  in that situation we can do nothing fancy any\n                # more, better log something into the error log and fall\n                # back gracefully.\n                environ[\"wsgi.errors\"].write(\n                    \"Debugging middleware caught exception in streamed \"\n                    \"response at a point where response headers were already \"\n                    \"sent.\\n\"\n                )\n\n            environ[\"wsgi.errors\"].write(\"\".join(tb.render_traceback_text()))\n\n    def execute_command(  # type: ignore[return]\n        self,\n        request: Request,\n        command: str,\n        frame: DebugFrameSummary | _ConsoleFrame,\n    ) -> Response:\n        \"\"\"Execute a command in a console.\"\"\"\n        if not self.check_host_trust(request.environ):\n            return SecurityError()  # type: ignore[return-value]\n\n        contexts = self.frame_contexts.get(id(frame), [])\n\n        with ExitStack() as exit_stack:\n            for cm in contexts:\n                exit_stack.enter_context(cm)\n\n            return Response(frame.eval(command), mimetype=\"text/html\")\n\n    def display_console(self, request: Request) -> Response:\n        \"\"\"Display a standalone shell.\"\"\"\n        if not self.check_host_trust(request.environ):\n            return SecurityError()  # type: ignore[return-value]\n\n        if 0 not in self.frames:\n            if self.console_init_func is None:\n                ns = {}\n            else:\n                ns = dict(self.console_init_func())\n            ns.setdefault(\"app\", self.app)\n            self.frames[0] = _ConsoleFrame(ns)\n        is_trusted = bool(self.check_pin_trust(request.environ))\n        return Response(\n            render_console_html(secret=self.secret, evalex_trusted=is_trusted),\n            mimetype=\"text/html\",\n        )\n\n    def get_resource(self, request: Request, filename: str) -> Response:\n        \"\"\"Return a static resource from the shared folder.\"\"\"\n        path = join(\"shared\", basename(filename))\n\n        try:\n            data = pkgutil.get_data(__package__, path)\n        except OSError:\n            return NotFound()  # type: ignore[return-value]\n        else:\n            if data is None:\n                return NotFound()  # type: ignore[return-value]\n\n            etag = str(adler32(data) & 0xFFFFFFFF)\n            return send_file(\n                BytesIO(data), request.environ, download_name=filename, etag=etag\n            )\n\n    def check_pin_trust(self, environ: WSGIEnvironment) -> bool | None:\n        \"\"\"Checks if the request passed the pin test.  This returns `True` if the\n        request is trusted on a pin/cookie basis and returns `False` if not.\n        Additionally if the cookie's stored pin hash is wrong it will return\n        `None` so that appropriate action can be taken.\n        \"\"\"\n        if self.pin is None:\n            return True\n        val = parse_cookie(environ).get(self.pin_cookie_name)\n        if not val or \"|\" not in val:\n            return False\n        ts_str, pin_hash = val.split(\"|\", 1)\n\n        try:\n            ts = int(ts_str)\n        except ValueError:\n            return False\n\n        if pin_hash != hash_pin(self.pin):\n            return None\n        return (time.time() - PIN_TIME) < ts\n\n    def check_host_trust(self, environ: WSGIEnvironment) -> bool:\n        return host_is_trusted(environ.get(\"HTTP_HOST\"), self.trusted_hosts)\n\n    def _fail_pin_auth(self) -> None:\n        time.sleep(5.0 if self._failed_pin_auth > 5 else 0.5)\n        self._failed_pin_auth += 1\n\n    def pin_auth(self, request: Request) -> Response:\n        \"\"\"Authenticates with the pin.\"\"\"\n        if not self.check_host_trust(request.environ):\n            return SecurityError()  # type: ignore[return-value]\n\n        exhausted = False\n        auth = False\n        trust = self.check_pin_trust(request.environ)\n        pin = t.cast(str, self.pin)\n\n        # If the trust return value is `None` it means that the cookie is\n        # set but the stored pin hash value is bad.  This means that the\n        # pin was changed.  In this case we count a bad auth and unset the\n        # cookie.  This way it becomes harder to guess the cookie name\n        # instead of the pin as we still count up failures.\n        bad_cookie = False\n        if trust is None:\n            self._fail_pin_auth()\n            bad_cookie = True\n\n        # If we're trusted, we're authenticated.\n        elif trust:\n            auth = True\n\n        # If we failed too many times, then we're locked out.\n        elif self._failed_pin_auth > 10:\n            exhausted = True\n\n        # Otherwise go through pin based authentication\n        else:\n            entered_pin = request.args[\"pin\"]\n\n            if entered_pin.strip().replace(\"-\", \"\") == pin.replace(\"-\", \"\"):\n                self._failed_pin_auth = 0\n                auth = True\n            else:\n                self._fail_pin_auth()\n\n        rv = Response(\n            json.dumps({\"auth\": auth, \"exhausted\": exhausted}),\n            mimetype=\"application/json\",\n        )\n        if auth:\n            rv.set_cookie(\n                self.pin_cookie_name,\n                f\"{int(time.time())}|{hash_pin(pin)}\",\n                httponly=True,\n                samesite=\"Strict\",\n                secure=request.is_secure,\n            )\n        elif bad_cookie:\n            rv.delete_cookie(self.pin_cookie_name)\n        return rv\n\n    def log_pin_request(self, request: Request) -> Response:\n        \"\"\"Log the pin if needed.\"\"\"\n        if not self.check_host_trust(request.environ):\n            return SecurityError()  # type: ignore[return-value]\n\n        if self.pin_logging and self.pin is not None:\n            _log(\n                \"info\", \" * To enable the debugger you need to enter the security pin:\"\n            )\n            _log(\"info\", \" * Debugger pin code: %s\", self.pin)\n        return Response(\"\")\n\n    def __call__(\n        self, environ: WSGIEnvironment, start_response: StartResponse\n    ) -> t.Iterable[bytes]:\n        \"\"\"Dispatch the requests.\"\"\"\n        # important: don't ever access a function here that reads the incoming\n        # form data!  Otherwise the application won't have access to that data\n        # any more!\n        request = Request(environ)\n        response = self.debug_application\n        if request.args.get(\"__debugger__\") == \"yes\":\n            cmd = request.args.get(\"cmd\")\n            arg = request.args.get(\"f\")\n            secret = request.args.get(\"s\")\n            frame = self.frames.get(request.args.get(\"frm\", type=int))  # type: ignore\n            if cmd == \"resource\" and arg:\n                response = self.get_resource(request, arg)  # type: ignore\n            elif cmd == \"pinauth\" and secret == self.secret:\n                response = self.pin_auth(request)  # type: ignore\n            elif cmd == \"printpin\" and secret == self.secret:\n                response = self.log_pin_request(request)  # type: ignore\n            elif (\n                self.evalex\n                and cmd is not None\n                and frame is not None\n                and self.secret == secret\n                and self.check_pin_trust(environ)\n            ):\n                response = self.execute_command(request, cmd, frame)  # type: ignore\n        elif (\n            self.evalex\n            and self.console_path is not None\n            and request.path == self.console_path\n        ):\n            response = self.display_console(request)  # type: ignore\n        return response(environ, start_response)\n", "src/werkzeug/middleware/profiler.py": "\"\"\"\nApplication Profiler\n====================\n\nThis module provides a middleware that profiles each request with the\n:mod:`cProfile` module. This can help identify bottlenecks in your code\nthat may be slowing down your application.\n\n.. autoclass:: ProfilerMiddleware\n\n:copyright: 2007 Pallets\n:license: BSD-3-Clause\n\"\"\"\n\nfrom __future__ import annotations\n\nimport os.path\nimport sys\nimport time\nimport typing as t\nfrom pstats import Stats\n\ntry:\n    from cProfile import Profile\nexcept ImportError:\n    from profile import Profile  # type: ignore\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import StartResponse\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n\n\nclass ProfilerMiddleware:\n    \"\"\"Wrap a WSGI application and profile the execution of each\n    request. Responses are buffered so that timings are more exact.\n\n    If ``stream`` is given, :class:`pstats.Stats` are written to it\n    after each request. If ``profile_dir`` is given, :mod:`cProfile`\n    data files are saved to that directory, one file per request.\n\n    The filename can be customized by passing ``filename_format``. If\n    it is a string, it will be formatted using :meth:`str.format` with\n    the following fields available:\n\n    -   ``{method}`` - The request method; GET, POST, etc.\n    -   ``{path}`` - The request path or 'root' should one not exist.\n    -   ``{elapsed}`` - The elapsed time of the request in milliseconds.\n    -   ``{time}`` - The time of the request.\n\n    If it is a callable, it will be called with the WSGI ``environ`` and\n    be expected to return a filename string. The ``environ`` dictionary\n    will also have the ``\"werkzeug.profiler\"`` key populated with a\n    dictionary containing the following fields (more may be added in the\n    future):\n    -   ``{elapsed}`` - The elapsed time of the request in milliseconds.\n    -   ``{time}`` - The time of the request.\n\n    :param app: The WSGI application to wrap.\n    :param stream: Write stats to this stream. Disable with ``None``.\n    :param sort_by: A tuple of columns to sort stats by. See\n        :meth:`pstats.Stats.sort_stats`.\n    :param restrictions: A tuple of restrictions to filter stats by. See\n        :meth:`pstats.Stats.print_stats`.\n    :param profile_dir: Save profile data files to this directory.\n    :param filename_format: Format string for profile data file names,\n        or a callable returning a name. See explanation above.\n\n    .. code-block:: python\n\n        from werkzeug.middleware.profiler import ProfilerMiddleware\n        app = ProfilerMiddleware(app)\n\n    .. versionchanged:: 3.0\n        Added the ``\"werkzeug.profiler\"`` key to the ``filename_format(environ)``\n        parameter with the  ``elapsed`` and ``time`` fields.\n\n    .. versionchanged:: 0.15\n        Stats are written even if ``profile_dir`` is given, and can be\n        disable by passing ``stream=None``.\n\n    .. versionadded:: 0.15\n        Added ``filename_format``.\n\n    .. versionadded:: 0.9\n        Added ``restrictions`` and ``profile_dir``.\n    \"\"\"\n\n    def __init__(\n        self,\n        app: WSGIApplication,\n        stream: t.IO[str] | None = sys.stdout,\n        sort_by: t.Iterable[str] = (\"time\", \"calls\"),\n        restrictions: t.Iterable[str | int | float] = (),\n        profile_dir: str | None = None,\n        filename_format: str = \"{method}.{path}.{elapsed:.0f}ms.{time:.0f}.prof\",\n    ) -> None:\n        self._app = app\n        self._stream = stream\n        self._sort_by = sort_by\n        self._restrictions = restrictions\n        self._profile_dir = profile_dir\n        self._filename_format = filename_format\n\n    def __call__(\n        self, environ: WSGIEnvironment, start_response: StartResponse\n    ) -> t.Iterable[bytes]:\n        response_body: list[bytes] = []\n\n        def catching_start_response(status, headers, exc_info=None):  # type: ignore\n            start_response(status, headers, exc_info)\n            return response_body.append\n\n        def runapp() -> None:\n            app_iter = self._app(\n                environ, t.cast(\"StartResponse\", catching_start_response)\n            )\n            response_body.extend(app_iter)\n\n            if hasattr(app_iter, \"close\"):\n                app_iter.close()\n\n        profile = Profile()\n        start = time.time()\n        profile.runcall(runapp)\n        body = b\"\".join(response_body)\n        elapsed = time.time() - start\n\n        if self._profile_dir is not None:\n            if callable(self._filename_format):\n                environ[\"werkzeug.profiler\"] = {\n                    \"elapsed\": elapsed * 1000.0,\n                    \"time\": time.time(),\n                }\n                filename = self._filename_format(environ)\n            else:\n                filename = self._filename_format.format(\n                    method=environ[\"REQUEST_METHOD\"],\n                    path=environ[\"PATH_INFO\"].strip(\"/\").replace(\"/\", \".\") or \"root\",\n                    elapsed=elapsed * 1000.0,\n                    time=time.time(),\n                )\n            filename = os.path.join(self._profile_dir, filename)\n            profile.dump_stats(filename)\n\n        if self._stream is not None:\n            stats = Stats(profile, stream=self._stream)\n            stats.sort_stats(*self._sort_by)\n            print(\"-\" * 80, file=self._stream)\n            path_info = environ.get(\"PATH_INFO\", \"\")\n            print(f\"PATH: {path_info!r}\", file=self._stream)\n            stats.print_stats(*self._restrictions)\n            print(f\"{'-' * 80}\\n\", file=self._stream)\n\n        return [body]\n", "src/werkzeug/middleware/dispatcher.py": "\"\"\"\nApplication Dispatcher\n======================\n\nThis middleware creates a single WSGI application that dispatches to\nmultiple other WSGI applications mounted at different URL paths.\n\nA common example is writing a Single Page Application, where you have a\nbackend API and a frontend written in JavaScript that does the routing\nin the browser rather than requesting different pages from the server.\nThe frontend is a single HTML and JS file that should be served for any\npath besides \"/api\".\n\nThis example dispatches to an API app under \"/api\", an admin app\nunder \"/admin\", and an app that serves frontend files for all other\nrequests::\n\n    app = DispatcherMiddleware(serve_frontend, {\n        '/api': api_app,\n        '/admin': admin_app,\n    })\n\nIn production, you might instead handle this at the HTTP server level,\nserving files or proxying to application servers based on location. The\nAPI and admin apps would each be deployed with a separate WSGI server,\nand the static files would be served directly by the HTTP server.\n\n.. autoclass:: DispatcherMiddleware\n\n:copyright: 2007 Pallets\n:license: BSD-3-Clause\n\"\"\"\n\nfrom __future__ import annotations\n\nimport typing as t\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import StartResponse\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n\n\nclass DispatcherMiddleware:\n    \"\"\"Combine multiple applications as a single WSGI application.\n    Requests are dispatched to an application based on the path it is\n    mounted under.\n\n    :param app: The WSGI application to dispatch to if the request\n        doesn't match a mounted path.\n    :param mounts: Maps path prefixes to applications for dispatching.\n    \"\"\"\n\n    def __init__(\n        self,\n        app: WSGIApplication,\n        mounts: dict[str, WSGIApplication] | None = None,\n    ) -> None:\n        self.app = app\n        self.mounts = mounts or {}\n\n    def __call__(\n        self, environ: WSGIEnvironment, start_response: StartResponse\n    ) -> t.Iterable[bytes]:\n        script = environ.get(\"PATH_INFO\", \"\")\n        path_info = \"\"\n\n        while \"/\" in script:\n            if script in self.mounts:\n                app = self.mounts[script]\n                break\n\n            script, last_item = script.rsplit(\"/\", 1)\n            path_info = f\"/{last_item}{path_info}\"\n        else:\n            app = self.mounts.get(script, self.app)\n\n        original_script_name = environ.get(\"SCRIPT_NAME\", \"\")\n        environ[\"SCRIPT_NAME\"] = original_script_name + script\n        environ[\"PATH_INFO\"] = path_info\n        return app(environ, start_response)\n", "src/werkzeug/middleware/__init__.py": "", "src/werkzeug/middleware/http_proxy.py": "\"\"\"\nBasic HTTP Proxy\n================\n\n.. autoclass:: ProxyMiddleware\n\n:copyright: 2007 Pallets\n:license: BSD-3-Clause\n\"\"\"\n\nfrom __future__ import annotations\n\nimport typing as t\nfrom http import client\nfrom urllib.parse import quote\nfrom urllib.parse import urlsplit\n\nfrom ..datastructures import EnvironHeaders\nfrom ..http import is_hop_by_hop_header\nfrom ..wsgi import get_input_stream\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import StartResponse\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n\n\nclass ProxyMiddleware:\n    \"\"\"Proxy requests under a path to an external server, routing other\n    requests to the app.\n\n    This middleware can only proxy HTTP requests, as HTTP is the only\n    protocol handled by the WSGI server. Other protocols, such as\n    WebSocket requests, cannot be proxied at this layer. This should\n    only be used for development, in production a real proxy server\n    should be used.\n\n    The middleware takes a dict mapping a path prefix to a dict\n    describing the host to be proxied to::\n\n        app = ProxyMiddleware(app, {\n            \"/static/\": {\n                \"target\": \"http://127.0.0.1:5001/\",\n            }\n        })\n\n    Each host has the following options:\n\n    ``target``:\n        The target URL to dispatch to. This is required.\n    ``remove_prefix``:\n        Whether to remove the prefix from the URL before dispatching it\n        to the target. The default is ``False``.\n    ``host``:\n        ``\"<auto>\"`` (default):\n            The host header is automatically rewritten to the URL of the\n            target.\n        ``None``:\n            The host header is unmodified from the client request.\n        Any other value:\n            The host header is overwritten with the value.\n    ``headers``:\n        A dictionary of headers to be sent with the request to the\n        target. The default is ``{}``.\n    ``ssl_context``:\n        A :class:`ssl.SSLContext` defining how to verify requests if the\n        target is HTTPS. The default is ``None``.\n\n    In the example above, everything under ``\"/static/\"`` is proxied to\n    the server on port 5001. The host header is rewritten to the target,\n    and the ``\"/static/\"`` prefix is removed from the URLs.\n\n    :param app: The WSGI application to wrap.\n    :param targets: Proxy target configurations. See description above.\n    :param chunk_size: Size of chunks to read from input stream and\n        write to target.\n    :param timeout: Seconds before an operation to a target fails.\n\n    .. versionadded:: 0.14\n    \"\"\"\n\n    def __init__(\n        self,\n        app: WSGIApplication,\n        targets: t.Mapping[str, dict[str, t.Any]],\n        chunk_size: int = 2 << 13,\n        timeout: int = 10,\n    ) -> None:\n        def _set_defaults(opts: dict[str, t.Any]) -> dict[str, t.Any]:\n            opts.setdefault(\"remove_prefix\", False)\n            opts.setdefault(\"host\", \"<auto>\")\n            opts.setdefault(\"headers\", {})\n            opts.setdefault(\"ssl_context\", None)\n            return opts\n\n        self.app = app\n        self.targets = {\n            f\"/{k.strip('/')}/\": _set_defaults(v) for k, v in targets.items()\n        }\n        self.chunk_size = chunk_size\n        self.timeout = timeout\n\n    def proxy_to(\n        self, opts: dict[str, t.Any], path: str, prefix: str\n    ) -> WSGIApplication:\n        target = urlsplit(opts[\"target\"])\n        # socket can handle unicode host, but header must be ascii\n        host = target.hostname.encode(\"idna\").decode(\"ascii\")\n\n        def application(\n            environ: WSGIEnvironment, start_response: StartResponse\n        ) -> t.Iterable[bytes]:\n            headers = list(EnvironHeaders(environ).items())\n            headers[:] = [\n                (k, v)\n                for k, v in headers\n                if not is_hop_by_hop_header(k)\n                and k.lower() not in (\"content-length\", \"host\")\n            ]\n            headers.append((\"Connection\", \"close\"))\n\n            if opts[\"host\"] == \"<auto>\":\n                headers.append((\"Host\", host))\n            elif opts[\"host\"] is None:\n                headers.append((\"Host\", environ[\"HTTP_HOST\"]))\n            else:\n                headers.append((\"Host\", opts[\"host\"]))\n\n            headers.extend(opts[\"headers\"].items())\n            remote_path = path\n\n            if opts[\"remove_prefix\"]:\n                remote_path = remote_path[len(prefix) :].lstrip(\"/\")\n                remote_path = f\"{target.path.rstrip('/')}/{remote_path}\"\n\n            content_length = environ.get(\"CONTENT_LENGTH\")\n            chunked = False\n\n            if content_length not in (\"\", None):\n                headers.append((\"Content-Length\", content_length))  # type: ignore\n            elif content_length is not None:\n                headers.append((\"Transfer-Encoding\", \"chunked\"))\n                chunked = True\n\n            try:\n                if target.scheme == \"http\":\n                    con = client.HTTPConnection(\n                        host, target.port or 80, timeout=self.timeout\n                    )\n                elif target.scheme == \"https\":\n                    con = client.HTTPSConnection(\n                        host,\n                        target.port or 443,\n                        timeout=self.timeout,\n                        context=opts[\"ssl_context\"],\n                    )\n                else:\n                    raise RuntimeError(\n                        \"Target scheme must be 'http' or 'https', got\"\n                        f\" {target.scheme!r}.\"\n                    )\n\n                con.connect()\n                # safe = https://url.spec.whatwg.org/#url-path-segment-string\n                # as well as percent for things that are already quoted\n                remote_url = quote(remote_path, safe=\"!$&'()*+,/:;=@%\")\n                querystring = environ[\"QUERY_STRING\"]\n\n                if querystring:\n                    remote_url = f\"{remote_url}?{querystring}\"\n\n                con.putrequest(environ[\"REQUEST_METHOD\"], remote_url, skip_host=True)\n\n                for k, v in headers:\n                    if k.lower() == \"connection\":\n                        v = \"close\"\n\n                    con.putheader(k, v)\n\n                con.endheaders()\n                stream = get_input_stream(environ)\n\n                while True:\n                    data = stream.read(self.chunk_size)\n\n                    if not data:\n                        break\n\n                    if chunked:\n                        con.send(b\"%x\\r\\n%s\\r\\n\" % (len(data), data))\n                    else:\n                        con.send(data)\n\n                resp = con.getresponse()\n            except OSError:\n                from ..exceptions import BadGateway\n\n                return BadGateway()(environ, start_response)\n\n            start_response(\n                f\"{resp.status} {resp.reason}\",\n                [\n                    (k.title(), v)\n                    for k, v in resp.getheaders()\n                    if not is_hop_by_hop_header(k)\n                ],\n            )\n\n            def read() -> t.Iterator[bytes]:\n                while True:\n                    try:\n                        data = resp.read(self.chunk_size)\n                    except OSError:\n                        break\n\n                    if not data:\n                        break\n\n                    yield data\n\n            return read()\n\n        return application\n\n    def __call__(\n        self, environ: WSGIEnvironment, start_response: StartResponse\n    ) -> t.Iterable[bytes]:\n        path = environ[\"PATH_INFO\"]\n        app = self.app\n\n        for prefix, opts in self.targets.items():\n            if path.startswith(prefix):\n                app = self.proxy_to(opts, path, prefix)\n                break\n\n        return app(environ, start_response)\n", "src/werkzeug/middleware/proxy_fix.py": "\"\"\"\nX-Forwarded-For Proxy Fix\n=========================\n\nThis module provides a middleware that adjusts the WSGI environ based on\n``X-Forwarded-`` headers that proxies in front of an application may\nset.\n\nWhen an application is running behind a proxy server, WSGI may see the\nrequest as coming from that server rather than the real client. Proxies\nset various headers to track where the request actually came from.\n\nThis middleware should only be used if the application is actually\nbehind such a proxy, and should be configured with the number of proxies\nthat are chained in front of it. Not all proxies set all the headers.\nSince incoming headers can be faked, you must set how many proxies are\nsetting each header so the middleware knows what to trust.\n\n.. autoclass:: ProxyFix\n\n:copyright: 2007 Pallets\n:license: BSD-3-Clause\n\"\"\"\n\nfrom __future__ import annotations\n\nimport typing as t\n\nfrom ..http import parse_list_header\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import StartResponse\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n\n\nclass ProxyFix:\n    \"\"\"Adjust the WSGI environ based on ``X-Forwarded-`` that proxies in\n    front of the application may set.\n\n    -   ``X-Forwarded-For`` sets ``REMOTE_ADDR``.\n    -   ``X-Forwarded-Proto`` sets ``wsgi.url_scheme``.\n    -   ``X-Forwarded-Host`` sets ``HTTP_HOST``, ``SERVER_NAME``, and\n        ``SERVER_PORT``.\n    -   ``X-Forwarded-Port`` sets ``HTTP_HOST`` and ``SERVER_PORT``.\n    -   ``X-Forwarded-Prefix`` sets ``SCRIPT_NAME``.\n\n    You must tell the middleware how many proxies set each header so it\n    knows what values to trust. It is a security issue to trust values\n    that came from the client rather than a proxy.\n\n    The original values of the headers are stored in the WSGI\n    environ as ``werkzeug.proxy_fix.orig``, a dict.\n\n    :param app: The WSGI application to wrap.\n    :param x_for: Number of values to trust for ``X-Forwarded-For``.\n    :param x_proto: Number of values to trust for ``X-Forwarded-Proto``.\n    :param x_host: Number of values to trust for ``X-Forwarded-Host``.\n    :param x_port: Number of values to trust for ``X-Forwarded-Port``.\n    :param x_prefix: Number of values to trust for\n        ``X-Forwarded-Prefix``.\n\n    .. code-block:: python\n\n        from werkzeug.middleware.proxy_fix import ProxyFix\n        # App is behind one proxy that sets the -For and -Host headers.\n        app = ProxyFix(app, x_for=1, x_host=1)\n\n    .. versionchanged:: 1.0\n        The ``num_proxies`` argument and attribute; the ``get_remote_addr`` method; and\n        the environ keys ``orig_remote_addr``, ``orig_wsgi_url_scheme``, and\n        ``orig_http_host`` were removed.\n\n    .. versionchanged:: 0.15\n        All headers support multiple values. Each header is configured with a separate\n        number of trusted proxies.\n\n    .. versionchanged:: 0.15\n        Original WSGI environ values are stored in the ``werkzeug.proxy_fix.orig`` dict.\n\n    .. versionchanged:: 0.15\n        Support ``X-Forwarded-Port`` and ``X-Forwarded-Prefix``.\n\n    .. versionchanged:: 0.15\n        ``X-Forwarded-Host`` and ``X-Forwarded-Port`` modify\n        ``SERVER_NAME`` and ``SERVER_PORT``.\n    \"\"\"\n\n    def __init__(\n        self,\n        app: WSGIApplication,\n        x_for: int = 1,\n        x_proto: int = 1,\n        x_host: int = 0,\n        x_port: int = 0,\n        x_prefix: int = 0,\n    ) -> None:\n        self.app = app\n        self.x_for = x_for\n        self.x_proto = x_proto\n        self.x_host = x_host\n        self.x_port = x_port\n        self.x_prefix = x_prefix\n\n    def _get_real_value(self, trusted: int, value: str | None) -> str | None:\n        \"\"\"Get the real value from a list header based on the configured\n        number of trusted proxies.\n\n        :param trusted: Number of values to trust in the header.\n        :param value: Comma separated list header value to parse.\n        :return: The real value, or ``None`` if there are fewer values\n            than the number of trusted proxies.\n\n        .. versionchanged:: 1.0\n            Renamed from ``_get_trusted_comma``.\n\n        .. versionadded:: 0.15\n        \"\"\"\n        if not (trusted and value):\n            return None\n        values = parse_list_header(value)\n        if len(values) >= trusted:\n            return values[-trusted]\n        return None\n\n    def __call__(\n        self, environ: WSGIEnvironment, start_response: StartResponse\n    ) -> t.Iterable[bytes]:\n        \"\"\"Modify the WSGI environ based on the various ``Forwarded``\n        headers before calling the wrapped application. Store the\n        original environ values in ``werkzeug.proxy_fix.orig_{key}``.\n        \"\"\"\n        environ_get = environ.get\n        orig_remote_addr = environ_get(\"REMOTE_ADDR\")\n        orig_wsgi_url_scheme = environ_get(\"wsgi.url_scheme\")\n        orig_http_host = environ_get(\"HTTP_HOST\")\n        environ.update(\n            {\n                \"werkzeug.proxy_fix.orig\": {\n                    \"REMOTE_ADDR\": orig_remote_addr,\n                    \"wsgi.url_scheme\": orig_wsgi_url_scheme,\n                    \"HTTP_HOST\": orig_http_host,\n                    \"SERVER_NAME\": environ_get(\"SERVER_NAME\"),\n                    \"SERVER_PORT\": environ_get(\"SERVER_PORT\"),\n                    \"SCRIPT_NAME\": environ_get(\"SCRIPT_NAME\"),\n                }\n            }\n        )\n\n        x_for = self._get_real_value(self.x_for, environ_get(\"HTTP_X_FORWARDED_FOR\"))\n        if x_for:\n            environ[\"REMOTE_ADDR\"] = x_for\n\n        x_proto = self._get_real_value(\n            self.x_proto, environ_get(\"HTTP_X_FORWARDED_PROTO\")\n        )\n        if x_proto:\n            environ[\"wsgi.url_scheme\"] = x_proto\n\n        x_host = self._get_real_value(self.x_host, environ_get(\"HTTP_X_FORWARDED_HOST\"))\n        if x_host:\n            environ[\"HTTP_HOST\"] = environ[\"SERVER_NAME\"] = x_host\n            # \"]\" to check for IPv6 address without port\n            if \":\" in x_host and not x_host.endswith(\"]\"):\n                environ[\"SERVER_NAME\"], environ[\"SERVER_PORT\"] = x_host.rsplit(\":\", 1)\n\n        x_port = self._get_real_value(self.x_port, environ_get(\"HTTP_X_FORWARDED_PORT\"))\n        if x_port:\n            host = environ.get(\"HTTP_HOST\")\n            if host:\n                # \"]\" to check for IPv6 address without port\n                if \":\" in host and not host.endswith(\"]\"):\n                    host = host.rsplit(\":\", 1)[0]\n                environ[\"HTTP_HOST\"] = f\"{host}:{x_port}\"\n            environ[\"SERVER_PORT\"] = x_port\n\n        x_prefix = self._get_real_value(\n            self.x_prefix, environ_get(\"HTTP_X_FORWARDED_PREFIX\")\n        )\n        if x_prefix:\n            environ[\"SCRIPT_NAME\"] = x_prefix\n\n        return self.app(environ, start_response)\n", "src/werkzeug/middleware/lint.py": "\"\"\"\nWSGI Protocol Linter\n====================\n\nThis module provides a middleware that performs sanity checks on the\nbehavior of the WSGI server and application. It checks that the\n:pep:`3333` WSGI spec is properly implemented. It also warns on some\ncommon HTTP errors such as non-empty responses for 304 status codes.\n\n.. autoclass:: LintMiddleware\n\n:copyright: 2007 Pallets\n:license: BSD-3-Clause\n\"\"\"\n\nfrom __future__ import annotations\n\nimport typing as t\nfrom types import TracebackType\nfrom urllib.parse import urlparse\nfrom warnings import warn\n\nfrom ..datastructures import Headers\nfrom ..http import is_entity_header\nfrom ..wsgi import FileWrapper\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import StartResponse\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n\n\nclass WSGIWarning(Warning):\n    \"\"\"Warning class for WSGI warnings.\"\"\"\n\n\nclass HTTPWarning(Warning):\n    \"\"\"Warning class for HTTP warnings.\"\"\"\n\n\ndef check_type(context: str, obj: object, need: type = str) -> None:\n    if type(obj) is not need:\n        warn(\n            f\"{context!r} requires {need.__name__!r}, got {type(obj).__name__!r}.\",\n            WSGIWarning,\n            stacklevel=3,\n        )\n\n\nclass InputStream:\n    def __init__(self, stream: t.IO[bytes]) -> None:\n        self._stream = stream\n\n    def read(self, *args: t.Any) -> bytes:\n        if len(args) == 0:\n            warn(\n                \"WSGI does not guarantee an EOF marker on the input stream, thus making\"\n                \" calls to 'wsgi.input.read()' unsafe. Conforming servers may never\"\n                \" return from this call.\",\n                WSGIWarning,\n                stacklevel=2,\n            )\n        elif len(args) != 1:\n            warn(\n                \"Too many parameters passed to 'wsgi.input.read()'.\",\n                WSGIWarning,\n                stacklevel=2,\n            )\n        return self._stream.read(*args)\n\n    def readline(self, *args: t.Any) -> bytes:\n        if len(args) == 0:\n            warn(\n                \"Calls to 'wsgi.input.readline()' without arguments are unsafe. Use\"\n                \" 'wsgi.input.read()' instead.\",\n                WSGIWarning,\n                stacklevel=2,\n            )\n        elif len(args) == 1:\n            warn(\n                \"'wsgi.input.readline()' was called with a size hint. WSGI does not\"\n                \" support this, although it's available on all major servers.\",\n                WSGIWarning,\n                stacklevel=2,\n            )\n        else:\n            raise TypeError(\"Too many arguments passed to 'wsgi.input.readline()'.\")\n        return self._stream.readline(*args)\n\n    def __iter__(self) -> t.Iterator[bytes]:\n        try:\n            return iter(self._stream)\n        except TypeError:\n            warn(\"'wsgi.input' is not iterable.\", WSGIWarning, stacklevel=2)\n            return iter(())\n\n    def close(self) -> None:\n        warn(\"The application closed the input stream!\", WSGIWarning, stacklevel=2)\n        self._stream.close()\n\n\nclass ErrorStream:\n    def __init__(self, stream: t.IO[str]) -> None:\n        self._stream = stream\n\n    def write(self, s: str) -> None:\n        check_type(\"wsgi.error.write()\", s, str)\n        self._stream.write(s)\n\n    def flush(self) -> None:\n        self._stream.flush()\n\n    def writelines(self, seq: t.Iterable[str]) -> None:\n        for line in seq:\n            self.write(line)\n\n    def close(self) -> None:\n        warn(\"The application closed the error stream!\", WSGIWarning, stacklevel=2)\n        self._stream.close()\n\n\nclass GuardedWrite:\n    def __init__(self, write: t.Callable[[bytes], object], chunks: list[int]) -> None:\n        self._write = write\n        self._chunks = chunks\n\n    def __call__(self, s: bytes) -> None:\n        check_type(\"write()\", s, bytes)\n        self._write(s)\n        self._chunks.append(len(s))\n\n\nclass GuardedIterator:\n    def __init__(\n        self,\n        iterator: t.Iterable[bytes],\n        headers_set: tuple[int, Headers],\n        chunks: list[int],\n    ) -> None:\n        self._iterator = iterator\n        self._next = iter(iterator).__next__\n        self.closed = False\n        self.headers_set = headers_set\n        self.chunks = chunks\n\n    def __iter__(self) -> GuardedIterator:\n        return self\n\n    def __next__(self) -> bytes:\n        if self.closed:\n            warn(\"Iterated over closed 'app_iter'.\", WSGIWarning, stacklevel=2)\n\n        rv = self._next()\n\n        if not self.headers_set:\n            warn(\n                \"The application returned before it started the response.\",\n                WSGIWarning,\n                stacklevel=2,\n            )\n\n        check_type(\"application iterator items\", rv, bytes)\n        self.chunks.append(len(rv))\n        return rv\n\n    def close(self) -> None:\n        self.closed = True\n\n        if hasattr(self._iterator, \"close\"):\n            self._iterator.close()\n\n        if self.headers_set:\n            status_code, headers = self.headers_set\n            bytes_sent = sum(self.chunks)\n            content_length = headers.get(\"content-length\", type=int)\n\n            if status_code == 304:\n                for key, _value in headers:\n                    key = key.lower()\n                    if key not in (\"expires\", \"content-location\") and is_entity_header(\n                        key\n                    ):\n                        warn(\n                            f\"Entity header {key!r} found in 304 response.\",\n                            HTTPWarning,\n                            stacklevel=2,\n                        )\n                if bytes_sent:\n                    warn(\n                        \"304 responses must not have a body.\",\n                        HTTPWarning,\n                        stacklevel=2,\n                    )\n            elif 100 <= status_code < 200 or status_code == 204:\n                if content_length != 0:\n                    warn(\n                        f\"{status_code} responses must have an empty content length.\",\n                        HTTPWarning,\n                        stacklevel=2,\n                    )\n                if bytes_sent:\n                    warn(\n                        f\"{status_code} responses must not have a body.\",\n                        HTTPWarning,\n                        stacklevel=2,\n                    )\n            elif content_length is not None and content_length != bytes_sent:\n                warn(\n                    \"Content-Length and the number of bytes sent to the\"\n                    \" client do not match.\",\n                    WSGIWarning,\n                    stacklevel=2,\n                )\n\n    def __del__(self) -> None:\n        if not self.closed:\n            try:\n                warn(\n                    \"Iterator was garbage collected before it was closed.\",\n                    WSGIWarning,\n                    stacklevel=2,\n                )\n            except Exception:\n                pass\n\n\nclass LintMiddleware:\n    \"\"\"Warns about common errors in the WSGI and HTTP behavior of the\n    server and wrapped application. Some of the issues it checks are:\n\n    -   invalid status codes\n    -   non-bytes sent to the WSGI server\n    -   strings returned from the WSGI application\n    -   non-empty conditional responses\n    -   unquoted etags\n    -   relative URLs in the Location header\n    -   unsafe calls to wsgi.input\n    -   unclosed iterators\n\n    Error information is emitted using the :mod:`warnings` module.\n\n    :param app: The WSGI application to wrap.\n\n    .. code-block:: python\n\n        from werkzeug.middleware.lint import LintMiddleware\n        app = LintMiddleware(app)\n    \"\"\"\n\n    def __init__(self, app: WSGIApplication) -> None:\n        self.app = app\n\n    def check_environ(self, environ: WSGIEnvironment) -> None:\n        if type(environ) is not dict:  # noqa: E721\n            warn(\n                \"WSGI environment is not a standard Python dict.\",\n                WSGIWarning,\n                stacklevel=4,\n            )\n        for key in (\n            \"REQUEST_METHOD\",\n            \"SERVER_NAME\",\n            \"SERVER_PORT\",\n            \"wsgi.version\",\n            \"wsgi.input\",\n            \"wsgi.errors\",\n            \"wsgi.multithread\",\n            \"wsgi.multiprocess\",\n            \"wsgi.run_once\",\n        ):\n            if key not in environ:\n                warn(\n                    f\"Required environment key {key!r} not found\",\n                    WSGIWarning,\n                    stacklevel=3,\n                )\n        if environ[\"wsgi.version\"] != (1, 0):\n            warn(\"Environ is not a WSGI 1.0 environ.\", WSGIWarning, stacklevel=3)\n\n        script_name = environ.get(\"SCRIPT_NAME\", \"\")\n        path_info = environ.get(\"PATH_INFO\", \"\")\n\n        if script_name and script_name[0] != \"/\":\n            warn(\n                f\"'SCRIPT_NAME' does not start with a slash: {script_name!r}\",\n                WSGIWarning,\n                stacklevel=3,\n            )\n\n        if path_info and path_info[0] != \"/\":\n            warn(\n                f\"'PATH_INFO' does not start with a slash: {path_info!r}\",\n                WSGIWarning,\n                stacklevel=3,\n            )\n\n    def check_start_response(\n        self,\n        status: str,\n        headers: list[tuple[str, str]],\n        exc_info: None | (tuple[type[BaseException], BaseException, TracebackType]),\n    ) -> tuple[int, Headers]:\n        check_type(\"status\", status, str)\n        status_code_str = status.split(None, 1)[0]\n\n        if len(status_code_str) != 3 or not status_code_str.isdecimal():\n            warn(\"Status code must be three digits.\", WSGIWarning, stacklevel=3)\n\n        if len(status) < 4 or status[3] != \" \":\n            warn(\n                f\"Invalid value for status {status!r}. Valid status strings are three\"\n                \" digits, a space and a status explanation.\",\n                WSGIWarning,\n                stacklevel=3,\n            )\n\n        status_code = int(status_code_str)\n\n        if status_code < 100:\n            warn(\"Status code < 100 detected.\", WSGIWarning, stacklevel=3)\n\n        if type(headers) is not list:  # noqa: E721\n            warn(\"Header list is not a list.\", WSGIWarning, stacklevel=3)\n\n        for item in headers:\n            if type(item) is not tuple or len(item) != 2:\n                warn(\"Header items must be 2-item tuples.\", WSGIWarning, stacklevel=3)\n            name, value = item\n            if type(name) is not str or type(value) is not str:  # noqa: E721\n                warn(\n                    \"Header keys and values must be strings.\", WSGIWarning, stacklevel=3\n                )\n            if name.lower() == \"status\":\n                warn(\n                    \"The status header is not supported due to\"\n                    \" conflicts with the CGI spec.\",\n                    WSGIWarning,\n                    stacklevel=3,\n                )\n\n        if exc_info is not None and not isinstance(exc_info, tuple):\n            warn(\"Invalid value for exc_info.\", WSGIWarning, stacklevel=3)\n\n        headers_obj = Headers(headers)\n        self.check_headers(headers_obj)\n\n        return status_code, headers_obj\n\n    def check_headers(self, headers: Headers) -> None:\n        etag = headers.get(\"etag\")\n\n        if etag is not None:\n            if etag.startswith((\"W/\", \"w/\")):\n                if etag.startswith(\"w/\"):\n                    warn(\n                        \"Weak etag indicator should be upper case.\",\n                        HTTPWarning,\n                        stacklevel=4,\n                    )\n\n                etag = etag[2:]\n\n            if not (etag[:1] == etag[-1:] == '\"'):\n                warn(\"Unquoted etag emitted.\", HTTPWarning, stacklevel=4)\n\n        location = headers.get(\"location\")\n\n        if location is not None:\n            if not urlparse(location).netloc:\n                warn(\n                    \"Absolute URLs required for location header.\",\n                    HTTPWarning,\n                    stacklevel=4,\n                )\n\n    def check_iterator(self, app_iter: t.Iterable[bytes]) -> None:\n        if isinstance(app_iter, str):\n            warn(\n                \"The application returned a string. The response will send one\"\n                \" character at a time to the client, which will kill performance.\"\n                \" Return a list or iterable instead.\",\n                WSGIWarning,\n                stacklevel=3,\n            )\n\n    def __call__(self, *args: t.Any, **kwargs: t.Any) -> t.Iterable[bytes]:\n        if len(args) != 2:\n            warn(\"A WSGI app takes two arguments.\", WSGIWarning, stacklevel=2)\n\n        if kwargs:\n            warn(\n                \"A WSGI app does not take keyword arguments.\", WSGIWarning, stacklevel=2\n            )\n\n        environ: WSGIEnvironment = args[0]\n        start_response: StartResponse = args[1]\n\n        self.check_environ(environ)\n        environ[\"wsgi.input\"] = InputStream(environ[\"wsgi.input\"])\n        environ[\"wsgi.errors\"] = ErrorStream(environ[\"wsgi.errors\"])\n\n        # Hook our own file wrapper in so that applications will always\n        # iterate to the end and we can check the content length.\n        environ[\"wsgi.file_wrapper\"] = FileWrapper\n\n        headers_set: list[t.Any] = []\n        chunks: list[int] = []\n\n        def checking_start_response(\n            *args: t.Any, **kwargs: t.Any\n        ) -> t.Callable[[bytes], None]:\n            if len(args) not in {2, 3}:\n                warn(\n                    f\"Invalid number of arguments: {len(args)}, expected 2 or 3.\",\n                    WSGIWarning,\n                    stacklevel=2,\n                )\n\n            if kwargs:\n                warn(\n                    \"'start_response' does not take keyword arguments.\",\n                    WSGIWarning,\n                    stacklevel=2,\n                )\n\n            status: str = args[0]\n            headers: list[tuple[str, str]] = args[1]\n            exc_info: (\n                None | (tuple[type[BaseException], BaseException, TracebackType])\n            ) = args[2] if len(args) == 3 else None\n\n            headers_set[:] = self.check_start_response(status, headers, exc_info)\n            return GuardedWrite(start_response(status, headers, exc_info), chunks)\n\n        app_iter = self.app(environ, t.cast(\"StartResponse\", checking_start_response))\n        self.check_iterator(app_iter)\n        return GuardedIterator(\n            app_iter, t.cast(t.Tuple[int, Headers], headers_set), chunks\n        )\n", "src/werkzeug/wrappers/response.py": "from __future__ import annotations\n\nimport json\nimport typing as t\nfrom http import HTTPStatus\nfrom urllib.parse import urljoin\n\nfrom .._internal import _get_environ\nfrom ..datastructures import Headers\nfrom ..http import generate_etag\nfrom ..http import http_date\nfrom ..http import is_resource_modified\nfrom ..http import parse_etags\nfrom ..http import parse_range_header\nfrom ..http import remove_entity_headers\nfrom ..sansio.response import Response as _SansIOResponse\nfrom ..urls import iri_to_uri\nfrom ..utils import cached_property\nfrom ..wsgi import _RangeWrapper\nfrom ..wsgi import ClosingIterator\nfrom ..wsgi import get_current_url\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import StartResponse\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n\n    from .request import Request\n\n\ndef _iter_encoded(iterable: t.Iterable[str | bytes]) -> t.Iterator[bytes]:\n    for item in iterable:\n        if isinstance(item, str):\n            yield item.encode()\n        else:\n            yield item\n\n\nclass Response(_SansIOResponse):\n    \"\"\"Represents an outgoing WSGI HTTP response with body, status, and\n    headers. Has properties and methods for using the functionality\n    defined by various HTTP specs.\n\n    The response body is flexible to support different use cases. The\n    simple form is passing bytes, or a string which will be encoded as\n    UTF-8. Passing an iterable of bytes or strings makes this a\n    streaming response. A generator is particularly useful for building\n    a CSV file in memory or using SSE (Server Sent Events). A file-like\n    object is also iterable, although the\n    :func:`~werkzeug.utils.send_file` helper should be used in that\n    case.\n\n    The response object is itself a WSGI application callable. When\n    called (:meth:`__call__`) with ``environ`` and ``start_response``,\n    it will pass its status and headers to ``start_response`` then\n    return its body as an iterable.\n\n    .. code-block:: python\n\n        from werkzeug.wrappers.response import Response\n\n        def index():\n            return Response(\"Hello, World!\")\n\n        def application(environ, start_response):\n            path = environ.get(\"PATH_INFO\") or \"/\"\n\n            if path == \"/\":\n                response = index()\n            else:\n                response = Response(\"Not Found\", status=404)\n\n            return response(environ, start_response)\n\n    :param response: The data for the body of the response. A string or\n        bytes, or tuple or list of strings or bytes, for a fixed-length\n        response, or any other iterable of strings or bytes for a\n        streaming response. Defaults to an empty body.\n    :param status: The status code for the response. Either an int, in\n        which case the default status message is added, or a string in\n        the form ``{code} {message}``, like ``404 Not Found``. Defaults\n        to 200.\n    :param headers: A :class:`~werkzeug.datastructures.Headers` object,\n        or a list of ``(key, value)`` tuples that will be converted to a\n        ``Headers`` object.\n    :param mimetype: The mime type (content type without charset or\n        other parameters) of the response. If the value starts with\n        ``text/`` (or matches some other special cases), the charset\n        will be added to create the ``content_type``.\n    :param content_type: The full content type of the response.\n        Overrides building the value from ``mimetype``.\n    :param direct_passthrough: Pass the response body directly through\n        as the WSGI iterable. This can be used when the body is a binary\n        file or other iterator of bytes, to skip some unnecessary\n        checks. Use :func:`~werkzeug.utils.send_file` instead of setting\n        this manually.\n\n    .. versionchanged:: 2.1\n        Old ``BaseResponse`` and mixin classes were removed.\n\n    .. versionchanged:: 2.0\n        Combine ``BaseResponse`` and mixins into a single ``Response``\n        class.\n\n    .. versionchanged:: 0.5\n        The ``direct_passthrough`` parameter was added.\n    \"\"\"\n\n    #: if set to `False` accessing properties on the response object will\n    #: not try to consume the response iterator and convert it into a list.\n    #:\n    #: .. versionadded:: 0.6.2\n    #:\n    #:    That attribute was previously called `implicit_seqence_conversion`.\n    #:    (Notice the typo).  If you did use this feature, you have to adapt\n    #:    your code to the name change.\n    implicit_sequence_conversion = True\n\n    #: If a redirect ``Location`` header is a relative URL, make it an\n    #: absolute URL, including scheme and domain.\n    #:\n    #: .. versionchanged:: 2.1\n    #:     This is disabled by default, so responses will send relative\n    #:     redirects.\n    #:\n    #: .. versionadded:: 0.8\n    autocorrect_location_header = False\n\n    #: Should this response object automatically set the content-length\n    #: header if possible?  This is true by default.\n    #:\n    #: .. versionadded:: 0.8\n    automatically_set_content_length = True\n\n    #: The response body to send as the WSGI iterable. A list of strings\n    #: or bytes represents a fixed-length response, any other iterable\n    #: is a streaming response. Strings are encoded to bytes as UTF-8.\n    #:\n    #: Do not set to a plain string or bytes, that will cause sending\n    #: the response to be very inefficient as it will iterate one byte\n    #: at a time.\n    response: t.Iterable[str] | t.Iterable[bytes]\n\n    def __init__(\n        self,\n        response: t.Iterable[bytes] | bytes | t.Iterable[str] | str | None = None,\n        status: int | str | HTTPStatus | None = None,\n        headers: t.Mapping[str, str | t.Iterable[str]]\n        | t.Iterable[tuple[str, str]]\n        | None = None,\n        mimetype: str | None = None,\n        content_type: str | None = None,\n        direct_passthrough: bool = False,\n    ) -> None:\n        super().__init__(\n            status=status,\n            headers=headers,\n            mimetype=mimetype,\n            content_type=content_type,\n        )\n\n        #: Pass the response body directly through as the WSGI iterable.\n        #: This can be used when the body is a binary file or other\n        #: iterator of bytes, to skip some unnecessary checks. Use\n        #: :func:`~werkzeug.utils.send_file` instead of setting this\n        #: manually.\n        self.direct_passthrough = direct_passthrough\n        self._on_close: list[t.Callable[[], t.Any]] = []\n\n        # we set the response after the headers so that if a class changes\n        # the charset attribute, the data is set in the correct charset.\n        if response is None:\n            self.response = []\n        elif isinstance(response, (str, bytes, bytearray)):\n            self.set_data(response)\n        else:\n            self.response = response\n\n    def call_on_close(self, func: t.Callable[[], t.Any]) -> t.Callable[[], t.Any]:\n        \"\"\"Adds a function to the internal list of functions that should\n        be called as part of closing down the response.  Since 0.7 this\n        function also returns the function that was passed so that this\n        can be used as a decorator.\n\n        .. versionadded:: 0.6\n        \"\"\"\n        self._on_close.append(func)\n        return func\n\n    def __repr__(self) -> str:\n        if self.is_sequence:\n            body_info = f\"{sum(map(len, self.iter_encoded()))} bytes\"\n        else:\n            body_info = \"streamed\" if self.is_streamed else \"likely-streamed\"\n        return f\"<{type(self).__name__} {body_info} [{self.status}]>\"\n\n    @classmethod\n    def force_type(\n        cls, response: Response, environ: WSGIEnvironment | None = None\n    ) -> Response:\n        \"\"\"Enforce that the WSGI response is a response object of the current\n        type.  Werkzeug will use the :class:`Response` internally in many\n        situations like the exceptions.  If you call :meth:`get_response` on an\n        exception you will get back a regular :class:`Response` object, even\n        if you are using a custom subclass.\n\n        This method can enforce a given response type, and it will also\n        convert arbitrary WSGI callables into response objects if an environ\n        is provided::\n\n            # convert a Werkzeug response object into an instance of the\n            # MyResponseClass subclass.\n            response = MyResponseClass.force_type(response)\n\n            # convert any WSGI application into a response object\n            response = MyResponseClass.force_type(response, environ)\n\n        This is especially useful if you want to post-process responses in\n        the main dispatcher and use functionality provided by your subclass.\n\n        Keep in mind that this will modify response objects in place if\n        possible!\n\n        :param response: a response object or wsgi application.\n        :param environ: a WSGI environment object.\n        :return: a response object.\n        \"\"\"\n        if not isinstance(response, Response):\n            if environ is None:\n                raise TypeError(\n                    \"cannot convert WSGI application into response\"\n                    \" objects without an environ\"\n                )\n\n            from ..test import run_wsgi_app\n\n            response = Response(*run_wsgi_app(response, environ))\n\n        response.__class__ = cls\n        return response\n\n    @classmethod\n    def from_app(\n        cls, app: WSGIApplication, environ: WSGIEnvironment, buffered: bool = False\n    ) -> Response:\n        \"\"\"Create a new response object from an application output.  This\n        works best if you pass it an application that returns a generator all\n        the time.  Sometimes applications may use the `write()` callable\n        returned by the `start_response` function.  This tries to resolve such\n        edge cases automatically.  But if you don't get the expected output\n        you should set `buffered` to `True` which enforces buffering.\n\n        :param app: the WSGI application to execute.\n        :param environ: the WSGI environment to execute against.\n        :param buffered: set to `True` to enforce buffering.\n        :return: a response object.\n        \"\"\"\n        from ..test import run_wsgi_app\n\n        return cls(*run_wsgi_app(app, environ, buffered))\n\n    @t.overload\n    def get_data(self, as_text: t.Literal[False] = False) -> bytes: ...\n\n    @t.overload\n    def get_data(self, as_text: t.Literal[True]) -> str: ...\n\n    def get_data(self, as_text: bool = False) -> bytes | str:\n        \"\"\"The string representation of the response body.  Whenever you call\n        this property the response iterable is encoded and flattened.  This\n        can lead to unwanted behavior if you stream big data.\n\n        This behavior can be disabled by setting\n        :attr:`implicit_sequence_conversion` to `False`.\n\n        If `as_text` is set to `True` the return value will be a decoded\n        string.\n\n        .. versionadded:: 0.9\n        \"\"\"\n        self._ensure_sequence()\n        rv = b\"\".join(self.iter_encoded())\n\n        if as_text:\n            return rv.decode()\n\n        return rv\n\n    def set_data(self, value: bytes | str) -> None:\n        \"\"\"Sets a new string as response.  The value must be a string or\n        bytes. If a string is set it's encoded to the charset of the\n        response (utf-8 by default).\n\n        .. versionadded:: 0.9\n        \"\"\"\n        if isinstance(value, str):\n            value = value.encode()\n        self.response = [value]\n        if self.automatically_set_content_length:\n            self.headers[\"Content-Length\"] = str(len(value))\n\n    data = property(\n        get_data,\n        set_data,\n        doc=\"A descriptor that calls :meth:`get_data` and :meth:`set_data`.\",\n    )\n\n    def calculate_content_length(self) -> int | None:\n        \"\"\"Returns the content length if available or `None` otherwise.\"\"\"\n        try:\n            self._ensure_sequence()\n        except RuntimeError:\n            return None\n        return sum(len(x) for x in self.iter_encoded())\n\n    def _ensure_sequence(self, mutable: bool = False) -> None:\n        \"\"\"This method can be called by methods that need a sequence.  If\n        `mutable` is true, it will also ensure that the response sequence\n        is a standard Python list.\n\n        .. versionadded:: 0.6\n        \"\"\"\n        if self.is_sequence:\n            # if we need a mutable object, we ensure it's a list.\n            if mutable and not isinstance(self.response, list):\n                self.response = list(self.response)  # type: ignore\n            return\n        if self.direct_passthrough:\n            raise RuntimeError(\n                \"Attempted implicit sequence conversion but the\"\n                \" response object is in direct passthrough mode.\"\n            )\n        if not self.implicit_sequence_conversion:\n            raise RuntimeError(\n                \"The response object required the iterable to be a\"\n                \" sequence, but the implicit conversion was disabled.\"\n                \" Call make_sequence() yourself.\"\n            )\n        self.make_sequence()\n\n    def make_sequence(self) -> None:\n        \"\"\"Converts the response iterator in a list.  By default this happens\n        automatically if required.  If `implicit_sequence_conversion` is\n        disabled, this method is not automatically called and some properties\n        might raise exceptions.  This also encodes all the items.\n\n        .. versionadded:: 0.6\n        \"\"\"\n        if not self.is_sequence:\n            # if we consume an iterable we have to ensure that the close\n            # method of the iterable is called if available when we tear\n            # down the response\n            close = getattr(self.response, \"close\", None)\n            self.response = list(self.iter_encoded())\n            if close is not None:\n                self.call_on_close(close)\n\n    def iter_encoded(self) -> t.Iterator[bytes]:\n        \"\"\"Iter the response encoded with the encoding of the response.\n        If the response object is invoked as WSGI application the return\n        value of this method is used as application iterator unless\n        :attr:`direct_passthrough` was activated.\n        \"\"\"\n        # Encode in a separate function so that self.response is fetched\n        # early.  This allows us to wrap the response with the return\n        # value from get_app_iter or iter_encoded.\n        return _iter_encoded(self.response)\n\n    @property\n    def is_streamed(self) -> bool:\n        \"\"\"If the response is streamed (the response is not an iterable with\n        a length information) this property is `True`.  In this case streamed\n        means that there is no information about the number of iterations.\n        This is usually `True` if a generator is passed to the response object.\n\n        This is useful for checking before applying some sort of post\n        filtering that should not take place for streamed responses.\n        \"\"\"\n        try:\n            len(self.response)  # type: ignore\n        except (TypeError, AttributeError):\n            return True\n        return False\n\n    @property\n    def is_sequence(self) -> bool:\n        \"\"\"If the iterator is buffered, this property will be `True`.  A\n        response object will consider an iterator to be buffered if the\n        response attribute is a list or tuple.\n\n        .. versionadded:: 0.6\n        \"\"\"\n        return isinstance(self.response, (tuple, list))\n\n    def close(self) -> None:\n        \"\"\"Close the wrapped response if possible.  You can also use the object\n        in a with statement which will automatically close it.\n\n        .. versionadded:: 0.9\n           Can now be used in a with statement.\n        \"\"\"\n        if hasattr(self.response, \"close\"):\n            self.response.close()\n        for func in self._on_close:\n            func()\n\n    def __enter__(self) -> Response:\n        return self\n\n    def __exit__(self, exc_type, exc_value, tb):  # type: ignore\n        self.close()\n\n    def freeze(self) -> None:\n        \"\"\"Make the response object ready to be pickled. Does the\n        following:\n\n        *   Buffer the response into a list, ignoring\n            :attr:`implicity_sequence_conversion` and\n            :attr:`direct_passthrough`.\n        *   Set the ``Content-Length`` header.\n        *   Generate an ``ETag`` header if one is not already set.\n\n        .. versionchanged:: 2.1\n            Removed the ``no_etag`` parameter.\n\n        .. versionchanged:: 2.0\n            An ``ETag`` header is always added.\n\n        .. versionchanged:: 0.6\n            The ``Content-Length`` header is set.\n        \"\"\"\n        # Always freeze the encoded response body, ignore\n        # implicit_sequence_conversion and direct_passthrough.\n        self.response = list(self.iter_encoded())\n        self.headers[\"Content-Length\"] = str(sum(map(len, self.response)))\n        self.add_etag()\n\n    def get_wsgi_headers(self, environ: WSGIEnvironment) -> Headers:\n        \"\"\"This is automatically called right before the response is started\n        and returns headers modified for the given environment.  It returns a\n        copy of the headers from the response with some modifications applied\n        if necessary.\n\n        For example the location header (if present) is joined with the root\n        URL of the environment.  Also the content length is automatically set\n        to zero here for certain status codes.\n\n        .. versionchanged:: 0.6\n           Previously that function was called `fix_headers` and modified\n           the response object in place.  Also since 0.6, IRIs in location\n           and content-location headers are handled properly.\n\n           Also starting with 0.6, Werkzeug will attempt to set the content\n           length if it is able to figure it out on its own.  This is the\n           case if all the strings in the response iterable are already\n           encoded and the iterable is buffered.\n\n        :param environ: the WSGI environment of the request.\n        :return: returns a new :class:`~werkzeug.datastructures.Headers`\n                 object.\n        \"\"\"\n        headers = Headers(self.headers)\n        location: str | None = None\n        content_location: str | None = None\n        content_length: str | int | None = None\n        status = self.status_code\n\n        # iterate over the headers to find all values in one go.  Because\n        # get_wsgi_headers is used each response that gives us a tiny\n        # speedup.\n        for key, value in headers:\n            ikey = key.lower()\n            if ikey == \"location\":\n                location = value\n            elif ikey == \"content-location\":\n                content_location = value\n            elif ikey == \"content-length\":\n                content_length = value\n\n        if location is not None:\n            location = iri_to_uri(location)\n\n            if self.autocorrect_location_header:\n                # Make the location header an absolute URL.\n                current_url = get_current_url(environ, strip_querystring=True)\n                current_url = iri_to_uri(current_url)\n                location = urljoin(current_url, location)\n\n            headers[\"Location\"] = location\n\n        # make sure the content location is a URL\n        if content_location is not None:\n            headers[\"Content-Location\"] = iri_to_uri(content_location)\n\n        if 100 <= status < 200 or status == 204:\n            # Per section 3.3.2 of RFC 7230, \"a server MUST NOT send a\n            # Content-Length header field in any response with a status\n            # code of 1xx (Informational) or 204 (No Content).\"\n            headers.remove(\"Content-Length\")\n        elif status == 304:\n            remove_entity_headers(headers)\n\n        # if we can determine the content length automatically, we\n        # should try to do that.  But only if this does not involve\n        # flattening the iterator or encoding of strings in the\n        # response. We however should not do that if we have a 304\n        # response.\n        if (\n            self.automatically_set_content_length\n            and self.is_sequence\n            and content_length is None\n            and status not in (204, 304)\n            and not (100 <= status < 200)\n        ):\n            content_length = sum(len(x) for x in self.iter_encoded())\n            headers[\"Content-Length\"] = str(content_length)\n\n        return headers\n\n    def get_app_iter(self, environ: WSGIEnvironment) -> t.Iterable[bytes]:\n        \"\"\"Returns the application iterator for the given environ.  Depending\n        on the request method and the current status code the return value\n        might be an empty response rather than the one from the response.\n\n        If the request method is `HEAD` or the status code is in a range\n        where the HTTP specification requires an empty response, an empty\n        iterable is returned.\n\n        .. versionadded:: 0.6\n\n        :param environ: the WSGI environment of the request.\n        :return: a response iterable.\n        \"\"\"\n        status = self.status_code\n        if (\n            environ[\"REQUEST_METHOD\"] == \"HEAD\"\n            or 100 <= status < 200\n            or status in (204, 304)\n        ):\n            iterable: t.Iterable[bytes] = ()\n        elif self.direct_passthrough:\n            return self.response  # type: ignore\n        else:\n            iterable = self.iter_encoded()\n        return ClosingIterator(iterable, self.close)\n\n    def get_wsgi_response(\n        self, environ: WSGIEnvironment\n    ) -> tuple[t.Iterable[bytes], str, list[tuple[str, str]]]:\n        \"\"\"Returns the final WSGI response as tuple.  The first item in\n        the tuple is the application iterator, the second the status and\n        the third the list of headers.  The response returned is created\n        specially for the given environment.  For example if the request\n        method in the WSGI environment is ``'HEAD'`` the response will\n        be empty and only the headers and status code will be present.\n\n        .. versionadded:: 0.6\n\n        :param environ: the WSGI environment of the request.\n        :return: an ``(app_iter, status, headers)`` tuple.\n        \"\"\"\n        headers = self.get_wsgi_headers(environ)\n        app_iter = self.get_app_iter(environ)\n        return app_iter, self.status, headers.to_wsgi_list()\n\n    def __call__(\n        self, environ: WSGIEnvironment, start_response: StartResponse\n    ) -> t.Iterable[bytes]:\n        \"\"\"Process this response as WSGI application.\n\n        :param environ: the WSGI environment.\n        :param start_response: the response callable provided by the WSGI\n                               server.\n        :return: an application iterator\n        \"\"\"\n        app_iter, status, headers = self.get_wsgi_response(environ)\n        start_response(status, headers)\n        return app_iter\n\n    # JSON\n\n    #: A module or other object that has ``dumps`` and ``loads``\n    #: functions that match the API of the built-in :mod:`json` module.\n    json_module = json\n\n    @property\n    def json(self) -> t.Any | None:\n        \"\"\"The parsed JSON data if :attr:`mimetype` indicates JSON\n        (:mimetype:`application/json`, see :attr:`is_json`).\n\n        Calls :meth:`get_json` with default arguments.\n        \"\"\"\n        return self.get_json()\n\n    @t.overload\n    def get_json(self, force: bool = ..., silent: t.Literal[False] = ...) -> t.Any: ...\n\n    @t.overload\n    def get_json(self, force: bool = ..., silent: bool = ...) -> t.Any | None: ...\n\n    def get_json(self, force: bool = False, silent: bool = False) -> t.Any | None:\n        \"\"\"Parse :attr:`data` as JSON. Useful during testing.\n\n        If the mimetype does not indicate JSON\n        (:mimetype:`application/json`, see :attr:`is_json`), this\n        returns ``None``.\n\n        Unlike :meth:`Request.get_json`, the result is not cached.\n\n        :param force: Ignore the mimetype and always try to parse JSON.\n        :param silent: Silence parsing errors and return ``None``\n            instead.\n        \"\"\"\n        if not (force or self.is_json):\n            return None\n\n        data = self.get_data()\n\n        try:\n            return self.json_module.loads(data)\n        except ValueError:\n            if not silent:\n                raise\n\n            return None\n\n    # Stream\n\n    @cached_property\n    def stream(self) -> ResponseStream:\n        \"\"\"The response iterable as write-only stream.\"\"\"\n        return ResponseStream(self)\n\n    def _wrap_range_response(self, start: int, length: int) -> None:\n        \"\"\"Wrap existing Response in case of Range Request context.\"\"\"\n        if self.status_code == 206:\n            self.response = _RangeWrapper(self.response, start, length)  # type: ignore\n\n    def _is_range_request_processable(self, environ: WSGIEnvironment) -> bool:\n        \"\"\"Return ``True`` if `Range` header is present and if underlying\n        resource is considered unchanged when compared with `If-Range` header.\n        \"\"\"\n        return (\n            \"HTTP_IF_RANGE\" not in environ\n            or not is_resource_modified(\n                environ,\n                self.headers.get(\"etag\"),\n                None,\n                self.headers.get(\"last-modified\"),\n                ignore_if_range=False,\n            )\n        ) and \"HTTP_RANGE\" in environ\n\n    def _process_range_request(\n        self,\n        environ: WSGIEnvironment,\n        complete_length: int | None,\n        accept_ranges: bool | str,\n    ) -> bool:\n        \"\"\"Handle Range Request related headers (RFC7233).  If `Accept-Ranges`\n        header is valid, and Range Request is processable, we set the headers\n        as described by the RFC, and wrap the underlying response in a\n        RangeWrapper.\n\n        Returns ``True`` if Range Request can be fulfilled, ``False`` otherwise.\n\n        :raises: :class:`~werkzeug.exceptions.RequestedRangeNotSatisfiable`\n                 if `Range` header could not be parsed or satisfied.\n\n        .. versionchanged:: 2.0\n            Returns ``False`` if the length is 0.\n        \"\"\"\n        from ..exceptions import RequestedRangeNotSatisfiable\n\n        if (\n            not accept_ranges\n            or complete_length is None\n            or complete_length == 0\n            or not self._is_range_request_processable(environ)\n        ):\n            return False\n\n        if accept_ranges is True:\n            accept_ranges = \"bytes\"\n\n        parsed_range = parse_range_header(environ.get(\"HTTP_RANGE\"))\n\n        if parsed_range is None:\n            raise RequestedRangeNotSatisfiable(complete_length)\n\n        range_tuple = parsed_range.range_for_length(complete_length)\n        content_range_header = parsed_range.to_content_range_header(complete_length)\n\n        if range_tuple is None or content_range_header is None:\n            raise RequestedRangeNotSatisfiable(complete_length)\n\n        content_length = range_tuple[1] - range_tuple[0]\n        self.headers[\"Content-Length\"] = str(content_length)\n        self.headers[\"Accept-Ranges\"] = accept_ranges\n        self.content_range = content_range_header  # type: ignore\n        self.status_code = 206\n        self._wrap_range_response(range_tuple[0], content_length)\n        return True\n\n    def make_conditional(\n        self,\n        request_or_environ: WSGIEnvironment | Request,\n        accept_ranges: bool | str = False,\n        complete_length: int | None = None,\n    ) -> Response:\n        \"\"\"Make the response conditional to the request.  This method works\n        best if an etag was defined for the response already.  The `add_etag`\n        method can be used to do that.  If called without etag just the date\n        header is set.\n\n        This does nothing if the request method in the request or environ is\n        anything but GET or HEAD.\n\n        For optimal performance when handling range requests, it's recommended\n        that your response data object implements `seekable`, `seek` and `tell`\n        methods as described by :py:class:`io.IOBase`.  Objects returned by\n        :meth:`~werkzeug.wsgi.wrap_file` automatically implement those methods.\n\n        It does not remove the body of the response because that's something\n        the :meth:`__call__` function does for us automatically.\n\n        Returns self so that you can do ``return resp.make_conditional(req)``\n        but modifies the object in-place.\n\n        :param request_or_environ: a request object or WSGI environment to be\n                                   used to make the response conditional\n                                   against.\n        :param accept_ranges: This parameter dictates the value of\n                              `Accept-Ranges` header. If ``False`` (default),\n                              the header is not set. If ``True``, it will be set\n                              to ``\"bytes\"``. If it's a string, it will use this\n                              value.\n        :param complete_length: Will be used only in valid Range Requests.\n                                It will set `Content-Range` complete length\n                                value and compute `Content-Length` real value.\n                                This parameter is mandatory for successful\n                                Range Requests completion.\n        :raises: :class:`~werkzeug.exceptions.RequestedRangeNotSatisfiable`\n                 if `Range` header could not be parsed or satisfied.\n\n        .. versionchanged:: 2.0\n            Range processing is skipped if length is 0 instead of\n            raising a 416 Range Not Satisfiable error.\n        \"\"\"\n        environ = _get_environ(request_or_environ)\n        if environ[\"REQUEST_METHOD\"] in (\"GET\", \"HEAD\"):\n            # if the date is not in the headers, add it now.  We however\n            # will not override an already existing header.  Unfortunately\n            # this header will be overridden by many WSGI servers including\n            # wsgiref.\n            if \"date\" not in self.headers:\n                self.headers[\"Date\"] = http_date()\n            is206 = self._process_range_request(environ, complete_length, accept_ranges)\n            if not is206 and not is_resource_modified(\n                environ,\n                self.headers.get(\"etag\"),\n                None,\n                self.headers.get(\"last-modified\"),\n            ):\n                if parse_etags(environ.get(\"HTTP_IF_MATCH\")):\n                    self.status_code = 412\n                else:\n                    self.status_code = 304\n            if (\n                self.automatically_set_content_length\n                and \"content-length\" not in self.headers\n            ):\n                length = self.calculate_content_length()\n                if length is not None:\n                    self.headers[\"Content-Length\"] = str(length)\n        return self\n\n    def add_etag(self, overwrite: bool = False, weak: bool = False) -> None:\n        \"\"\"Add an etag for the current response if there is none yet.\n\n        .. versionchanged:: 2.0\n            SHA-1 is used to generate the value. MD5 may not be\n            available in some environments.\n        \"\"\"\n        if overwrite or \"etag\" not in self.headers:\n            self.set_etag(generate_etag(self.get_data()), weak)\n\n\nclass ResponseStream:\n    \"\"\"A file descriptor like object used by :meth:`Response.stream` to\n    represent the body of the stream. It directly pushes into the\n    response iterable of the response object.\n    \"\"\"\n\n    mode = \"wb+\"\n\n    def __init__(self, response: Response):\n        self.response = response\n        self.closed = False\n\n    def write(self, value: bytes) -> int:\n        if self.closed:\n            raise ValueError(\"I/O operation on closed file\")\n        self.response._ensure_sequence(mutable=True)\n        self.response.response.append(value)  # type: ignore\n        self.response.headers.pop(\"Content-Length\", None)\n        return len(value)\n\n    def writelines(self, seq: t.Iterable[bytes]) -> None:\n        for item in seq:\n            self.write(item)\n\n    def close(self) -> None:\n        self.closed = True\n\n    def flush(self) -> None:\n        if self.closed:\n            raise ValueError(\"I/O operation on closed file\")\n\n    def isatty(self) -> bool:\n        if self.closed:\n            raise ValueError(\"I/O operation on closed file\")\n        return False\n\n    def tell(self) -> int:\n        self.response._ensure_sequence()\n        return sum(map(len, self.response.response))\n\n    @property\n    def encoding(self) -> str:\n        return \"utf-8\"\n", "src/werkzeug/wrappers/request.py": "from __future__ import annotations\n\nimport collections.abc as cabc\nimport functools\nimport json\nimport typing as t\nfrom io import BytesIO\n\nfrom .._internal import _wsgi_decoding_dance\nfrom ..datastructures import CombinedMultiDict\nfrom ..datastructures import EnvironHeaders\nfrom ..datastructures import FileStorage\nfrom ..datastructures import ImmutableMultiDict\nfrom ..datastructures import iter_multi_items\nfrom ..datastructures import MultiDict\nfrom ..exceptions import BadRequest\nfrom ..exceptions import UnsupportedMediaType\nfrom ..formparser import default_stream_factory\nfrom ..formparser import FormDataParser\nfrom ..sansio.request import Request as _SansIORequest\nfrom ..utils import cached_property\nfrom ..utils import environ_property\nfrom ..wsgi import _get_server\nfrom ..wsgi import get_input_stream\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n\n\nclass Request(_SansIORequest):\n    \"\"\"Represents an incoming WSGI HTTP request, with headers and body\n    taken from the WSGI environment. Has properties and methods for\n    using the functionality defined by various HTTP specs. The data in\n    requests object is read-only.\n\n    Text data is assumed to use UTF-8 encoding, which should be true for\n    the vast majority of modern clients. Using an encoding set by the\n    client is unsafe in Python due to extra encodings it provides, such\n    as ``zip``. To change the assumed encoding, subclass and replace\n    :attr:`charset`.\n\n    :param environ: The WSGI environ is generated by the WSGI server and\n        contains information about the server configuration and client\n        request.\n    :param populate_request: Add this request object to the WSGI environ\n        as ``environ['werkzeug.request']``. Can be useful when\n        debugging.\n    :param shallow: Makes reading from :attr:`stream` (and any method\n        that would read from it) raise a :exc:`RuntimeError`. Useful to\n        prevent consuming the form data in middleware, which would make\n        it unavailable to the final application.\n\n    .. versionchanged:: 3.0\n        The ``charset``, ``url_charset``, and ``encoding_errors`` parameters\n        were removed.\n\n    .. versionchanged:: 2.1\n        Old ``BaseRequest`` and mixin classes were removed.\n\n    .. versionchanged:: 2.1\n        Remove the ``disable_data_descriptor`` attribute.\n\n    .. versionchanged:: 2.0\n        Combine ``BaseRequest`` and mixins into a single ``Request``\n        class.\n\n    .. versionchanged:: 0.5\n        Read-only mode is enforced with immutable classes for all data.\n    \"\"\"\n\n    #: the maximum content length.  This is forwarded to the form data\n    #: parsing function (:func:`parse_form_data`).  When set and the\n    #: :attr:`form` or :attr:`files` attribute is accessed and the\n    #: parsing fails because more than the specified value is transmitted\n    #: a :exc:`~werkzeug.exceptions.RequestEntityTooLarge` exception is raised.\n    #:\n    #: .. versionadded:: 0.5\n    max_content_length: int | None = None\n\n    #: the maximum form field size.  This is forwarded to the form data\n    #: parsing function (:func:`parse_form_data`).  When set and the\n    #: :attr:`form` or :attr:`files` attribute is accessed and the\n    #: data in memory for post data is longer than the specified value a\n    #: :exc:`~werkzeug.exceptions.RequestEntityTooLarge` exception is raised.\n    #:\n    #: .. versionadded:: 0.5\n    max_form_memory_size: int | None = None\n\n    #: The maximum number of multipart parts to parse, passed to\n    #: :attr:`form_data_parser_class`. Parsing form data with more than this\n    #: many parts will raise :exc:`~.RequestEntityTooLarge`.\n    #:\n    #: .. versionadded:: 2.2.3\n    max_form_parts = 1000\n\n    #: The form data parser that should be used.  Can be replaced to customize\n    #: the form date parsing.\n    form_data_parser_class: type[FormDataParser] = FormDataParser\n\n    #: The WSGI environment containing HTTP headers and information from\n    #: the WSGI server.\n    environ: WSGIEnvironment\n\n    #: Set when creating the request object. If ``True``, reading from\n    #: the request body will cause a ``RuntimeException``. Useful to\n    #: prevent modifying the stream from middleware.\n    shallow: bool\n\n    def __init__(\n        self,\n        environ: WSGIEnvironment,\n        populate_request: bool = True,\n        shallow: bool = False,\n    ) -> None:\n        super().__init__(\n            method=environ.get(\"REQUEST_METHOD\", \"GET\"),\n            scheme=environ.get(\"wsgi.url_scheme\", \"http\"),\n            server=_get_server(environ),\n            root_path=_wsgi_decoding_dance(environ.get(\"SCRIPT_NAME\") or \"\"),\n            path=_wsgi_decoding_dance(environ.get(\"PATH_INFO\") or \"\"),\n            query_string=environ.get(\"QUERY_STRING\", \"\").encode(\"latin1\"),\n            headers=EnvironHeaders(environ),\n            remote_addr=environ.get(\"REMOTE_ADDR\"),\n        )\n        self.environ = environ\n        self.shallow = shallow\n\n        if populate_request and not shallow:\n            self.environ[\"werkzeug.request\"] = self\n\n    @classmethod\n    def from_values(cls, *args: t.Any, **kwargs: t.Any) -> Request:\n        \"\"\"Create a new request object based on the values provided.  If\n        environ is given missing values are filled from there.  This method is\n        useful for small scripts when you need to simulate a request from an URL.\n        Do not use this method for unittesting, there is a full featured client\n        object (:class:`Client`) that allows to create multipart requests,\n        support for cookies etc.\n\n        This accepts the same options as the\n        :class:`~werkzeug.test.EnvironBuilder`.\n\n        .. versionchanged:: 0.5\n           This method now accepts the same arguments as\n           :class:`~werkzeug.test.EnvironBuilder`.  Because of this the\n           `environ` parameter is now called `environ_overrides`.\n\n        :return: request object\n        \"\"\"\n        from ..test import EnvironBuilder\n\n        builder = EnvironBuilder(*args, **kwargs)\n        try:\n            return builder.get_request(cls)\n        finally:\n            builder.close()\n\n    @classmethod\n    def application(cls, f: t.Callable[[Request], WSGIApplication]) -> WSGIApplication:\n        \"\"\"Decorate a function as responder that accepts the request as\n        the last argument.  This works like the :func:`responder`\n        decorator but the function is passed the request object as the\n        last argument and the request object will be closed\n        automatically::\n\n            @Request.application\n            def my_wsgi_app(request):\n                return Response('Hello World!')\n\n        As of Werkzeug 0.14 HTTP exceptions are automatically caught and\n        converted to responses instead of failing.\n\n        :param f: the WSGI callable to decorate\n        :return: a new WSGI callable\n        \"\"\"\n        #: return a callable that wraps the -2nd argument with the request\n        #: and calls the function with all the arguments up to that one and\n        #: the request.  The return value is then called with the latest\n        #: two arguments.  This makes it possible to use this decorator for\n        #: both standalone WSGI functions as well as bound methods and\n        #: partially applied functions.\n        from ..exceptions import HTTPException\n\n        @functools.wraps(f)\n        def application(*args: t.Any) -> cabc.Iterable[bytes]:\n            request = cls(args[-2])\n            with request:\n                try:\n                    resp = f(*args[:-2] + (request,))\n                except HTTPException as e:\n                    resp = t.cast(\"WSGIApplication\", e.get_response(args[-2]))\n                return resp(*args[-2:])\n\n        return t.cast(\"WSGIApplication\", application)\n\n    def _get_file_stream(\n        self,\n        total_content_length: int | None,\n        content_type: str | None,\n        filename: str | None = None,\n        content_length: int | None = None,\n    ) -> t.IO[bytes]:\n        \"\"\"Called to get a stream for the file upload.\n\n        This must provide a file-like class with `read()`, `readline()`\n        and `seek()` methods that is both writeable and readable.\n\n        The default implementation returns a temporary file if the total\n        content length is higher than 500KB.  Because many browsers do not\n        provide a content length for the files only the total content\n        length matters.\n\n        :param total_content_length: the total content length of all the\n                                     data in the request combined.  This value\n                                     is guaranteed to be there.\n        :param content_type: the mimetype of the uploaded file.\n        :param filename: the filename of the uploaded file.  May be `None`.\n        :param content_length: the length of this file.  This value is usually\n                               not provided because webbrowsers do not provide\n                               this value.\n        \"\"\"\n        return default_stream_factory(\n            total_content_length=total_content_length,\n            filename=filename,\n            content_type=content_type,\n            content_length=content_length,\n        )\n\n    @property\n    def want_form_data_parsed(self) -> bool:\n        \"\"\"``True`` if the request method carries content. By default\n        this is true if a ``Content-Type`` is sent.\n\n        .. versionadded:: 0.8\n        \"\"\"\n        return bool(self.environ.get(\"CONTENT_TYPE\"))\n\n    def make_form_data_parser(self) -> FormDataParser:\n        \"\"\"Creates the form data parser. Instantiates the\n        :attr:`form_data_parser_class` with some parameters.\n\n        .. versionadded:: 0.8\n        \"\"\"\n        return self.form_data_parser_class(\n            stream_factory=self._get_file_stream,\n            max_form_memory_size=self.max_form_memory_size,\n            max_content_length=self.max_content_length,\n            max_form_parts=self.max_form_parts,\n            cls=self.parameter_storage_class,\n        )\n\n    def _load_form_data(self) -> None:\n        \"\"\"Method used internally to retrieve submitted data.  After calling\n        this sets `form` and `files` on the request object to multi dicts\n        filled with the incoming form data.  As a matter of fact the input\n        stream will be empty afterwards.  You can also call this method to\n        force the parsing of the form data.\n\n        .. versionadded:: 0.8\n        \"\"\"\n        # abort early if we have already consumed the stream\n        if \"form\" in self.__dict__:\n            return\n\n        if self.want_form_data_parsed:\n            parser = self.make_form_data_parser()\n            data = parser.parse(\n                self._get_stream_for_parsing(),\n                self.mimetype,\n                self.content_length,\n                self.mimetype_params,\n            )\n        else:\n            data = (\n                self.stream,\n                self.parameter_storage_class(),\n                self.parameter_storage_class(),\n            )\n\n        # inject the values into the instance dict so that we bypass\n        # our cached_property non-data descriptor.\n        d = self.__dict__\n        d[\"stream\"], d[\"form\"], d[\"files\"] = data\n\n    def _get_stream_for_parsing(self) -> t.IO[bytes]:\n        \"\"\"This is the same as accessing :attr:`stream` with the difference\n        that if it finds cached data from calling :meth:`get_data` first it\n        will create a new stream out of the cached data.\n\n        .. versionadded:: 0.9.3\n        \"\"\"\n        cached_data = getattr(self, \"_cached_data\", None)\n        if cached_data is not None:\n            return BytesIO(cached_data)\n        return self.stream\n\n    def close(self) -> None:\n        \"\"\"Closes associated resources of this request object.  This\n        closes all file handles explicitly.  You can also use the request\n        object in a with statement which will automatically close it.\n\n        .. versionadded:: 0.9\n        \"\"\"\n        files = self.__dict__.get(\"files\")\n        for _key, value in iter_multi_items(files or ()):\n            value.close()\n\n    def __enter__(self) -> Request:\n        return self\n\n    def __exit__(self, exc_type, exc_value, tb) -> None:  # type: ignore\n        self.close()\n\n    @cached_property\n    def stream(self) -> t.IO[bytes]:\n        \"\"\"The WSGI input stream, with safety checks. This stream can only be consumed\n        once.\n\n        Use :meth:`get_data` to get the full data as bytes or text. The :attr:`data`\n        attribute will contain the full bytes only if they do not represent form data.\n        The :attr:`form` attribute will contain the parsed form data in that case.\n\n        Unlike :attr:`input_stream`, this stream guards against infinite streams or\n        reading past :attr:`content_length` or :attr:`max_content_length`.\n\n        If ``max_content_length`` is set, it can be enforced on streams if\n        ``wsgi.input_terminated`` is set. Otherwise, an empty stream is returned.\n\n        If the limit is reached before the underlying stream is exhausted (such as a\n        file that is too large, or an infinite stream), the remaining contents of the\n        stream cannot be read safely. Depending on how the server handles this, clients\n        may show a \"connection reset\" failure instead of seeing the 413 response.\n\n        .. versionchanged:: 2.3\n            Check ``max_content_length`` preemptively and while reading.\n\n        .. versionchanged:: 0.9\n            The stream is always set (but may be consumed) even if form parsing was\n            accessed first.\n        \"\"\"\n        if self.shallow:\n            raise RuntimeError(\n                \"This request was created with 'shallow=True', reading\"\n                \" from the input stream is disabled.\"\n            )\n\n        return get_input_stream(\n            self.environ, max_content_length=self.max_content_length\n        )\n\n    input_stream = environ_property[t.IO[bytes]](\n        \"wsgi.input\",\n        doc=\"\"\"The raw WSGI input stream, without any safety checks.\n\n        This is dangerous to use. It does not guard against infinite streams or reading\n        past :attr:`content_length` or :attr:`max_content_length`.\n\n        Use :attr:`stream` instead.\n        \"\"\",\n    )\n\n    @cached_property\n    def data(self) -> bytes:\n        \"\"\"The raw data read from :attr:`stream`. Will be empty if the request\n        represents form data.\n\n        To get the raw data even if it represents form data, use :meth:`get_data`.\n        \"\"\"\n        return self.get_data(parse_form_data=True)\n\n    @t.overload\n    def get_data(  # type: ignore\n        self,\n        cache: bool = True,\n        as_text: t.Literal[False] = False,\n        parse_form_data: bool = False,\n    ) -> bytes: ...\n\n    @t.overload\n    def get_data(\n        self,\n        cache: bool = True,\n        as_text: t.Literal[True] = ...,\n        parse_form_data: bool = False,\n    ) -> str: ...\n\n    def get_data(\n        self, cache: bool = True, as_text: bool = False, parse_form_data: bool = False\n    ) -> bytes | str:\n        \"\"\"This reads the buffered incoming data from the client into one\n        bytes object.  By default this is cached but that behavior can be\n        changed by setting `cache` to `False`.\n\n        Usually it's a bad idea to call this method without checking the\n        content length first as a client could send dozens of megabytes or more\n        to cause memory problems on the server.\n\n        Note that if the form data was already parsed this method will not\n        return anything as form data parsing does not cache the data like\n        this method does.  To implicitly invoke form data parsing function\n        set `parse_form_data` to `True`.  When this is done the return value\n        of this method will be an empty string if the form parser handles\n        the data.  This generally is not necessary as if the whole data is\n        cached (which is the default) the form parser will used the cached\n        data to parse the form data.  Please be generally aware of checking\n        the content length first in any case before calling this method\n        to avoid exhausting server memory.\n\n        If `as_text` is set to `True` the return value will be a decoded\n        string.\n\n        .. versionadded:: 0.9\n        \"\"\"\n        rv = getattr(self, \"_cached_data\", None)\n        if rv is None:\n            if parse_form_data:\n                self._load_form_data()\n            rv = self.stream.read()\n            if cache:\n                self._cached_data = rv\n        if as_text:\n            rv = rv.decode(errors=\"replace\")\n        return rv\n\n    @cached_property\n    def form(self) -> ImmutableMultiDict[str, str]:\n        \"\"\"The form parameters.  By default an\n        :class:`~werkzeug.datastructures.ImmutableMultiDict`\n        is returned from this function.  This can be changed by setting\n        :attr:`parameter_storage_class` to a different type.  This might\n        be necessary if the order of the form data is important.\n\n        Please keep in mind that file uploads will not end up here, but instead\n        in the :attr:`files` attribute.\n\n        .. versionchanged:: 0.9\n\n            Previous to Werkzeug 0.9 this would only contain form data for POST\n            and PUT requests.\n        \"\"\"\n        self._load_form_data()\n        return self.form\n\n    @cached_property\n    def values(self) -> CombinedMultiDict[str, str]:\n        \"\"\"A :class:`werkzeug.datastructures.CombinedMultiDict` that\n        combines :attr:`args` and :attr:`form`.\n\n        For GET requests, only ``args`` are present, not ``form``.\n\n        .. versionchanged:: 2.0\n            For GET requests, only ``args`` are present, not ``form``.\n        \"\"\"\n        sources = [self.args]\n\n        if self.method != \"GET\":\n            # GET requests can have a body, and some caching proxies\n            # might not treat that differently than a normal GET\n            # request, allowing form data to \"invisibly\" affect the\n            # cache without indication in the query string / URL.\n            sources.append(self.form)\n\n        args = []\n\n        for d in sources:\n            if not isinstance(d, MultiDict):\n                d = MultiDict(d)\n\n            args.append(d)\n\n        return CombinedMultiDict(args)\n\n    @cached_property\n    def files(self) -> ImmutableMultiDict[str, FileStorage]:\n        \"\"\":class:`~werkzeug.datastructures.MultiDict` object containing\n        all uploaded files.  Each key in :attr:`files` is the name from the\n        ``<input type=\"file\" name=\"\">``.  Each value in :attr:`files` is a\n        Werkzeug :class:`~werkzeug.datastructures.FileStorage` object.\n\n        It basically behaves like a standard file object you know from Python,\n        with the difference that it also has a\n        :meth:`~werkzeug.datastructures.FileStorage.save` function that can\n        store the file on the filesystem.\n\n        Note that :attr:`files` will only contain data if the request method was\n        POST, PUT or PATCH and the ``<form>`` that posted to the request had\n        ``enctype=\"multipart/form-data\"``.  It will be empty otherwise.\n\n        See the :class:`~werkzeug.datastructures.MultiDict` /\n        :class:`~werkzeug.datastructures.FileStorage` documentation for\n        more details about the used data structure.\n        \"\"\"\n        self._load_form_data()\n        return self.files\n\n    @property\n    def script_root(self) -> str:\n        \"\"\"Alias for :attr:`self.root_path`. ``environ[\"SCRIPT_ROOT\"]``\n        without a trailing slash.\n        \"\"\"\n        return self.root_path\n\n    @cached_property\n    def url_root(self) -> str:\n        \"\"\"Alias for :attr:`root_url`. The URL with scheme, host, and\n        root path. For example, ``https://example.com/app/``.\n        \"\"\"\n        return self.root_url\n\n    remote_user = environ_property[str](\n        \"REMOTE_USER\",\n        doc=\"\"\"If the server supports user authentication, and the\n        script is protected, this attribute contains the username the\n        user has authenticated as.\"\"\",\n    )\n    is_multithread = environ_property[bool](\n        \"wsgi.multithread\",\n        doc=\"\"\"boolean that is `True` if the application is served by a\n        multithreaded WSGI server.\"\"\",\n    )\n    is_multiprocess = environ_property[bool](\n        \"wsgi.multiprocess\",\n        doc=\"\"\"boolean that is `True` if the application is served by a\n        WSGI server that spawns multiple processes.\"\"\",\n    )\n    is_run_once = environ_property[bool](\n        \"wsgi.run_once\",\n        doc=\"\"\"boolean that is `True` if the application will be\n        executed only once in a process lifetime.  This is the case for\n        CGI for example, but it's not guaranteed that the execution only\n        happens one time.\"\"\",\n    )\n\n    # JSON\n\n    #: A module or other object that has ``dumps`` and ``loads``\n    #: functions that match the API of the built-in :mod:`json` module.\n    json_module = json\n\n    @property\n    def json(self) -> t.Any | None:\n        \"\"\"The parsed JSON data if :attr:`mimetype` indicates JSON\n        (:mimetype:`application/json`, see :attr:`is_json`).\n\n        Calls :meth:`get_json` with default arguments.\n\n        If the request content type is not ``application/json``, this\n        will raise a 415 Unsupported Media Type error.\n\n        .. versionchanged:: 2.3\n            Raise a 415 error instead of 400.\n\n        .. versionchanged:: 2.1\n            Raise a 400 error if the content type is incorrect.\n        \"\"\"\n        return self.get_json()\n\n    # Cached values for ``(silent=False, silent=True)``. Initialized\n    # with sentinel values.\n    _cached_json: tuple[t.Any, t.Any] = (Ellipsis, Ellipsis)\n\n    @t.overload\n    def get_json(\n        self, force: bool = ..., silent: t.Literal[False] = ..., cache: bool = ...\n    ) -> t.Any: ...\n\n    @t.overload\n    def get_json(\n        self, force: bool = ..., silent: bool = ..., cache: bool = ...\n    ) -> t.Any | None: ...\n\n    def get_json(\n        self, force: bool = False, silent: bool = False, cache: bool = True\n    ) -> t.Any | None:\n        \"\"\"Parse :attr:`data` as JSON.\n\n        If the mimetype does not indicate JSON\n        (:mimetype:`application/json`, see :attr:`is_json`), or parsing\n        fails, :meth:`on_json_loading_failed` is called and\n        its return value is used as the return value. By default this\n        raises a 415 Unsupported Media Type resp.\n\n        :param force: Ignore the mimetype and always try to parse JSON.\n        :param silent: Silence mimetype and parsing errors, and\n            return ``None`` instead.\n        :param cache: Store the parsed JSON to return for subsequent\n            calls.\n\n        .. versionchanged:: 2.3\n            Raise a 415 error instead of 400.\n\n        .. versionchanged:: 2.1\n            Raise a 400 error if the content type is incorrect.\n        \"\"\"\n        if cache and self._cached_json[silent] is not Ellipsis:\n            return self._cached_json[silent]\n\n        if not (force or self.is_json):\n            if not silent:\n                return self.on_json_loading_failed(None)\n            else:\n                return None\n\n        data = self.get_data(cache=cache)\n\n        try:\n            rv = self.json_module.loads(data)\n        except ValueError as e:\n            if silent:\n                rv = None\n\n                if cache:\n                    normal_rv, _ = self._cached_json\n                    self._cached_json = (normal_rv, rv)\n            else:\n                rv = self.on_json_loading_failed(e)\n\n                if cache:\n                    _, silent_rv = self._cached_json\n                    self._cached_json = (rv, silent_rv)\n        else:\n            if cache:\n                self._cached_json = (rv, rv)\n\n        return rv\n\n    def on_json_loading_failed(self, e: ValueError | None) -> t.Any:\n        \"\"\"Called if :meth:`get_json` fails and isn't silenced.\n\n        If this method returns a value, it is used as the return value\n        for :meth:`get_json`. The default implementation raises\n        :exc:`~werkzeug.exceptions.BadRequest`.\n\n        :param e: If parsing failed, this is the exception. It will be\n            ``None`` if the content type wasn't ``application/json``.\n\n        .. versionchanged:: 2.3\n            Raise a 415 error instead of 400.\n        \"\"\"\n        if e is not None:\n            raise BadRequest(f\"Failed to decode JSON object: {e}\")\n\n        raise UnsupportedMediaType(\n            \"Did not attempt to load JSON data because the request\"\n            \" Content-Type was not 'application/json'.\"\n        )\n", "src/werkzeug/wrappers/__init__.py": "from .request import Request as Request\nfrom .response import Response as Response\nfrom .response import ResponseStream as ResponseStream\n", "src/werkzeug/sansio/response.py": "from __future__ import annotations\n\nimport typing as t\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom datetime import timezone\nfrom http import HTTPStatus\n\nfrom ..datastructures import CallbackDict\nfrom ..datastructures import ContentRange\nfrom ..datastructures import ContentSecurityPolicy\nfrom ..datastructures import Headers\nfrom ..datastructures import HeaderSet\nfrom ..datastructures import ResponseCacheControl\nfrom ..datastructures import WWWAuthenticate\nfrom ..http import COEP\nfrom ..http import COOP\nfrom ..http import dump_age\nfrom ..http import dump_cookie\nfrom ..http import dump_header\nfrom ..http import dump_options_header\nfrom ..http import http_date\nfrom ..http import HTTP_STATUS_CODES\nfrom ..http import parse_age\nfrom ..http import parse_cache_control_header\nfrom ..http import parse_content_range_header\nfrom ..http import parse_csp_header\nfrom ..http import parse_date\nfrom ..http import parse_options_header\nfrom ..http import parse_set_header\nfrom ..http import quote_etag\nfrom ..http import unquote_etag\nfrom ..utils import get_content_type\nfrom ..utils import header_property\n\nif t.TYPE_CHECKING:\n    from ..datastructures.cache_control import _CacheControl\n\n\ndef _set_property(name: str, doc: str | None = None) -> property:\n    def fget(self: Response) -> HeaderSet:\n        def on_update(header_set: HeaderSet) -> None:\n            if not header_set and name in self.headers:\n                del self.headers[name]\n            elif header_set:\n                self.headers[name] = header_set.to_header()\n\n        return parse_set_header(self.headers.get(name), on_update)\n\n    def fset(\n        self: Response,\n        value: None | (str | dict[str, str | int] | t.Iterable[str]),\n    ) -> None:\n        if not value:\n            del self.headers[name]\n        elif isinstance(value, str):\n            self.headers[name] = value\n        else:\n            self.headers[name] = dump_header(value)\n\n    return property(fget, fset, doc=doc)\n\n\nclass Response:\n    \"\"\"Represents the non-IO parts of an HTTP response, specifically the\n    status and headers but not the body.\n\n    This class is not meant for general use. It should only be used when\n    implementing WSGI, ASGI, or another HTTP application spec. Werkzeug\n    provides a WSGI implementation at :cls:`werkzeug.wrappers.Response`.\n\n    :param status: The status code for the response. Either an int, in\n        which case the default status message is added, or a string in\n        the form ``{code} {message}``, like ``404 Not Found``. Defaults\n        to 200.\n    :param headers: A :class:`~werkzeug.datastructures.Headers` object,\n        or a list of ``(key, value)`` tuples that will be converted to a\n        ``Headers`` object.\n    :param mimetype: The mime type (content type without charset or\n        other parameters) of the response. If the value starts with\n        ``text/`` (or matches some other special cases), the charset\n        will be added to create the ``content_type``.\n    :param content_type: The full content type of the response.\n        Overrides building the value from ``mimetype``.\n\n    .. versionchanged:: 3.0\n        The ``charset`` attribute was removed.\n\n    .. versionadded:: 2.0\n    \"\"\"\n\n    #: the default status if none is provided.\n    default_status = 200\n\n    #: the default mimetype if none is provided.\n    default_mimetype: str | None = \"text/plain\"\n\n    #: Warn if a cookie header exceeds this size. The default, 4093, should be\n    #: safely `supported by most browsers <cookie_>`_. A cookie larger than\n    #: this size will still be sent, but it may be ignored or handled\n    #: incorrectly by some browsers. Set to 0 to disable this check.\n    #:\n    #: .. versionadded:: 0.13\n    #:\n    #: .. _`cookie`: http://browsercookielimits.squawky.net/\n    max_cookie_size = 4093\n\n    # A :class:`Headers` object representing the response headers.\n    headers: Headers\n\n    def __init__(\n        self,\n        status: int | str | HTTPStatus | None = None,\n        headers: t.Mapping[str, str | t.Iterable[str]]\n        | t.Iterable[tuple[str, str]]\n        | None = None,\n        mimetype: str | None = None,\n        content_type: str | None = None,\n    ) -> None:\n        if isinstance(headers, Headers):\n            self.headers = headers\n        elif not headers:\n            self.headers = Headers()\n        else:\n            self.headers = Headers(headers)\n\n        if content_type is None:\n            if mimetype is None and \"content-type\" not in self.headers:\n                mimetype = self.default_mimetype\n            if mimetype is not None:\n                mimetype = get_content_type(mimetype, \"utf-8\")\n            content_type = mimetype\n        if content_type is not None:\n            self.headers[\"Content-Type\"] = content_type\n        if status is None:\n            status = self.default_status\n        self.status = status  # type: ignore\n\n    def __repr__(self) -> str:\n        return f\"<{type(self).__name__} [{self.status}]>\"\n\n    @property\n    def status_code(self) -> int:\n        \"\"\"The HTTP status code as a number.\"\"\"\n        return self._status_code\n\n    @status_code.setter\n    def status_code(self, code: int) -> None:\n        self.status = code  # type: ignore\n\n    @property\n    def status(self) -> str:\n        \"\"\"The HTTP status code as a string.\"\"\"\n        return self._status\n\n    @status.setter\n    def status(self, value: str | int | HTTPStatus) -> None:\n        self._status, self._status_code = self._clean_status(value)\n\n    def _clean_status(self, value: str | int | HTTPStatus) -> tuple[str, int]:\n        if isinstance(value, (int, HTTPStatus)):\n            status_code = int(value)\n        else:\n            value = value.strip()\n\n            if not value:\n                raise ValueError(\"Empty status argument\")\n\n            code_str, sep, _ = value.partition(\" \")\n\n            try:\n                status_code = int(code_str)\n            except ValueError:\n                # only message\n                return f\"0 {value}\", 0\n\n            if sep:\n                # code and message\n                return value, status_code\n\n        # only code, look up message\n        try:\n            status = f\"{status_code} {HTTP_STATUS_CODES[status_code].upper()}\"\n        except KeyError:\n            status = f\"{status_code} UNKNOWN\"\n\n        return status, status_code\n\n    def set_cookie(\n        self,\n        key: str,\n        value: str = \"\",\n        max_age: timedelta | int | None = None,\n        expires: str | datetime | int | float | None = None,\n        path: str | None = \"/\",\n        domain: str | None = None,\n        secure: bool = False,\n        httponly: bool = False,\n        samesite: str | None = None,\n        partitioned: bool = False,\n    ) -> None:\n        \"\"\"Sets a cookie.\n\n        A warning is raised if the size of the cookie header exceeds\n        :attr:`max_cookie_size`, but the header will still be set.\n\n        :param key: the key (name) of the cookie to be set.\n        :param value: the value of the cookie.\n        :param max_age: should be a number of seconds, or `None` (default) if\n                        the cookie should last only as long as the client's\n                        browser session.\n        :param expires: should be a `datetime` object or UNIX timestamp.\n        :param path: limits the cookie to a given path, per default it will\n                     span the whole domain.\n        :param domain: if you want to set a cross-domain cookie.  For example,\n                       ``domain=\"example.com\"`` will set a cookie that is\n                       readable by the domain ``www.example.com``,\n                       ``foo.example.com`` etc.  Otherwise, a cookie will only\n                       be readable by the domain that set it.\n        :param secure: If ``True``, the cookie will only be available\n            via HTTPS.\n        :param httponly: Disallow JavaScript access to the cookie.\n        :param samesite: Limit the scope of the cookie to only be\n            attached to requests that are \"same-site\".\n        :param partitioned: If ``True``, the cookie will be partitioned.\n        \"\"\"\n        self.headers.add(\n            \"Set-Cookie\",\n            dump_cookie(\n                key,\n                value=value,\n                max_age=max_age,\n                expires=expires,\n                path=path,\n                domain=domain,\n                secure=secure,\n                httponly=httponly,\n                max_size=self.max_cookie_size,\n                samesite=samesite,\n                partitioned=partitioned,\n            ),\n        )\n\n    def delete_cookie(\n        self,\n        key: str,\n        path: str | None = \"/\",\n        domain: str | None = None,\n        secure: bool = False,\n        httponly: bool = False,\n        samesite: str | None = None,\n        partitioned: bool = False,\n    ) -> None:\n        \"\"\"Delete a cookie.  Fails silently if key doesn't exist.\n\n        :param key: the key (name) of the cookie to be deleted.\n        :param path: if the cookie that should be deleted was limited to a\n                     path, the path has to be defined here.\n        :param domain: if the cookie that should be deleted was limited to a\n                       domain, that domain has to be defined here.\n        :param secure: If ``True``, the cookie will only be available\n            via HTTPS.\n        :param httponly: Disallow JavaScript access to the cookie.\n        :param samesite: Limit the scope of the cookie to only be\n            attached to requests that are \"same-site\".\n        :param partitioned: If ``True``, the cookie will be partitioned.\n        \"\"\"\n        self.set_cookie(\n            key,\n            expires=0,\n            max_age=0,\n            path=path,\n            domain=domain,\n            secure=secure,\n            httponly=httponly,\n            samesite=samesite,\n            partitioned=partitioned,\n        )\n\n    @property\n    def is_json(self) -> bool:\n        \"\"\"Check if the mimetype indicates JSON data, either\n        :mimetype:`application/json` or :mimetype:`application/*+json`.\n        \"\"\"\n        mt = self.mimetype\n        return mt is not None and (\n            mt == \"application/json\"\n            or mt.startswith(\"application/\")\n            and mt.endswith(\"+json\")\n        )\n\n    # Common Descriptors\n\n    @property\n    def mimetype(self) -> str | None:\n        \"\"\"The mimetype (content type without charset etc.)\"\"\"\n        ct = self.headers.get(\"content-type\")\n\n        if ct:\n            return ct.split(\";\")[0].strip()\n        else:\n            return None\n\n    @mimetype.setter\n    def mimetype(self, value: str) -> None:\n        self.headers[\"Content-Type\"] = get_content_type(value, \"utf-8\")\n\n    @property\n    def mimetype_params(self) -> dict[str, str]:\n        \"\"\"The mimetype parameters as dict. For example if the\n        content type is ``text/html; charset=utf-8`` the params would be\n        ``{'charset': 'utf-8'}``.\n\n        .. versionadded:: 0.5\n        \"\"\"\n\n        def on_update(d: CallbackDict[str, str]) -> None:\n            self.headers[\"Content-Type\"] = dump_options_header(self.mimetype, d)\n\n        d = parse_options_header(self.headers.get(\"content-type\", \"\"))[1]\n        return CallbackDict(d, on_update)\n\n    location = header_property[str](\n        \"Location\",\n        doc=\"\"\"The Location response-header field is used to redirect\n        the recipient to a location other than the Request-URI for\n        completion of the request or identification of a new\n        resource.\"\"\",\n    )\n    age = header_property(\n        \"Age\",\n        None,\n        parse_age,\n        dump_age,  # type: ignore\n        doc=\"\"\"The Age response-header field conveys the sender's\n        estimate of the amount of time since the response (or its\n        revalidation) was generated at the origin server.\n\n        Age values are non-negative decimal integers, representing time\n        in seconds.\"\"\",\n    )\n    content_type = header_property[str](\n        \"Content-Type\",\n        doc=\"\"\"The Content-Type entity-header field indicates the media\n        type of the entity-body sent to the recipient or, in the case of\n        the HEAD method, the media type that would have been sent had\n        the request been a GET.\"\"\",\n    )\n    content_length = header_property(\n        \"Content-Length\",\n        None,\n        int,\n        str,\n        doc=\"\"\"The Content-Length entity-header field indicates the size\n        of the entity-body, in decimal number of OCTETs, sent to the\n        recipient or, in the case of the HEAD method, the size of the\n        entity-body that would have been sent had the request been a\n        GET.\"\"\",\n    )\n    content_location = header_property[str](\n        \"Content-Location\",\n        doc=\"\"\"The Content-Location entity-header field MAY be used to\n        supply the resource location for the entity enclosed in the\n        message when that entity is accessible from a location separate\n        from the requested resource's URI.\"\"\",\n    )\n    content_encoding = header_property[str](\n        \"Content-Encoding\",\n        doc=\"\"\"The Content-Encoding entity-header field is used as a\n        modifier to the media-type. When present, its value indicates\n        what additional content codings have been applied to the\n        entity-body, and thus what decoding mechanisms must be applied\n        in order to obtain the media-type referenced by the Content-Type\n        header field.\"\"\",\n    )\n    content_md5 = header_property[str](\n        \"Content-MD5\",\n        doc=\"\"\"The Content-MD5 entity-header field, as defined in\n        RFC 1864, is an MD5 digest of the entity-body for the purpose of\n        providing an end-to-end message integrity check (MIC) of the\n        entity-body. (Note: a MIC is good for detecting accidental\n        modification of the entity-body in transit, but is not proof\n        against malicious attacks.)\"\"\",\n    )\n    date = header_property(\n        \"Date\",\n        None,\n        parse_date,\n        http_date,\n        doc=\"\"\"The Date general-header field represents the date and\n        time at which the message was originated, having the same\n        semantics as orig-date in RFC 822.\n\n        .. versionchanged:: 2.0\n            The datetime object is timezone-aware.\n        \"\"\",\n    )\n    expires = header_property(\n        \"Expires\",\n        None,\n        parse_date,\n        http_date,\n        doc=\"\"\"The Expires entity-header field gives the date/time after\n        which the response is considered stale. A stale cache entry may\n        not normally be returned by a cache.\n\n        .. versionchanged:: 2.0\n            The datetime object is timezone-aware.\n        \"\"\",\n    )\n    last_modified = header_property(\n        \"Last-Modified\",\n        None,\n        parse_date,\n        http_date,\n        doc=\"\"\"The Last-Modified entity-header field indicates the date\n        and time at which the origin server believes the variant was\n        last modified.\n\n        .. versionchanged:: 2.0\n            The datetime object is timezone-aware.\n        \"\"\",\n    )\n\n    @property\n    def retry_after(self) -> datetime | None:\n        \"\"\"The Retry-After response-header field can be used with a\n        503 (Service Unavailable) response to indicate how long the\n        service is expected to be unavailable to the requesting client.\n\n        Time in seconds until expiration or date.\n\n        .. versionchanged:: 2.0\n            The datetime object is timezone-aware.\n        \"\"\"\n        value = self.headers.get(\"retry-after\")\n        if value is None:\n            return None\n\n        try:\n            seconds = int(value)\n        except ValueError:\n            return parse_date(value)\n\n        return datetime.now(timezone.utc) + timedelta(seconds=seconds)\n\n    @retry_after.setter\n    def retry_after(self, value: datetime | int | str | None) -> None:\n        if value is None:\n            if \"retry-after\" in self.headers:\n                del self.headers[\"retry-after\"]\n            return\n        elif isinstance(value, datetime):\n            value = http_date(value)\n        else:\n            value = str(value)\n        self.headers[\"Retry-After\"] = value\n\n    vary = _set_property(\n        \"Vary\",\n        doc=\"\"\"The Vary field value indicates the set of request-header\n        fields that fully determines, while the response is fresh,\n        whether a cache is permitted to use the response to reply to a\n        subsequent request without revalidation.\"\"\",\n    )\n    content_language = _set_property(\n        \"Content-Language\",\n        doc=\"\"\"The Content-Language entity-header field describes the\n        natural language(s) of the intended audience for the enclosed\n        entity. Note that this might not be equivalent to all the\n        languages used within the entity-body.\"\"\",\n    )\n    allow = _set_property(\n        \"Allow\",\n        doc=\"\"\"The Allow entity-header field lists the set of methods\n        supported by the resource identified by the Request-URI. The\n        purpose of this field is strictly to inform the recipient of\n        valid methods associated with the resource. An Allow header\n        field MUST be present in a 405 (Method Not Allowed)\n        response.\"\"\",\n    )\n\n    # ETag\n\n    @property\n    def cache_control(self) -> ResponseCacheControl:\n        \"\"\"The Cache-Control general-header field is used to specify\n        directives that MUST be obeyed by all caching mechanisms along the\n        request/response chain.\n        \"\"\"\n\n        def on_update(cache_control: _CacheControl) -> None:\n            if not cache_control and \"cache-control\" in self.headers:\n                del self.headers[\"cache-control\"]\n            elif cache_control:\n                self.headers[\"Cache-Control\"] = cache_control.to_header()\n\n        return parse_cache_control_header(\n            self.headers.get(\"cache-control\"), on_update, ResponseCacheControl\n        )\n\n    def set_etag(self, etag: str, weak: bool = False) -> None:\n        \"\"\"Set the etag, and override the old one if there was one.\"\"\"\n        self.headers[\"ETag\"] = quote_etag(etag, weak)\n\n    def get_etag(self) -> tuple[str, bool] | tuple[None, None]:\n        \"\"\"Return a tuple in the form ``(etag, is_weak)``.  If there is no\n        ETag the return value is ``(None, None)``.\n        \"\"\"\n        return unquote_etag(self.headers.get(\"ETag\"))\n\n    accept_ranges = header_property[str](\n        \"Accept-Ranges\",\n        doc=\"\"\"The `Accept-Ranges` header. Even though the name would\n        indicate that multiple values are supported, it must be one\n        string token only.\n\n        The values ``'bytes'`` and ``'none'`` are common.\n\n        .. versionadded:: 0.7\"\"\",\n    )\n\n    @property\n    def content_range(self) -> ContentRange:\n        \"\"\"The ``Content-Range`` header as a\n        :class:`~werkzeug.datastructures.ContentRange` object. Available\n        even if the header is not set.\n\n        .. versionadded:: 0.7\n        \"\"\"\n\n        def on_update(rng: ContentRange) -> None:\n            if not rng:\n                del self.headers[\"content-range\"]\n            else:\n                self.headers[\"Content-Range\"] = rng.to_header()\n\n        rv = parse_content_range_header(self.headers.get(\"content-range\"), on_update)\n        # always provide a content range object to make the descriptor\n        # more user friendly.  It provides an unset() method that can be\n        # used to remove the header quickly.\n        if rv is None:\n            rv = ContentRange(None, None, None, on_update=on_update)\n        return rv\n\n    @content_range.setter\n    def content_range(self, value: ContentRange | str | None) -> None:\n        if not value:\n            del self.headers[\"content-range\"]\n        elif isinstance(value, str):\n            self.headers[\"Content-Range\"] = value\n        else:\n            self.headers[\"Content-Range\"] = value.to_header()\n\n    # Authorization\n\n    @property\n    def www_authenticate(self) -> WWWAuthenticate:\n        \"\"\"The ``WWW-Authenticate`` header parsed into a :class:`.WWWAuthenticate`\n        object. Modifying the object will modify the header value.\n\n        This header is not set by default. To set this header, assign an instance of\n        :class:`.WWWAuthenticate` to this attribute.\n\n        .. code-block:: python\n\n            response.www_authenticate = WWWAuthenticate(\n                \"basic\", {\"realm\": \"Authentication Required\"}\n            )\n\n        Multiple values for this header can be sent to give the client multiple options.\n        Assign a list to set multiple headers. However, modifying the items in the list\n        will not automatically update the header values, and accessing this attribute\n        will only ever return the first value.\n\n        To unset this header, assign ``None`` or use ``del``.\n\n        .. versionchanged:: 2.3\n            This attribute can be assigned to to set the header. A list can be assigned\n            to set multiple header values. Use ``del`` to unset the header.\n\n        .. versionchanged:: 2.3\n            :class:`WWWAuthenticate` is no longer a ``dict``. The ``token`` attribute\n            was added for auth challenges that use a token instead of parameters.\n        \"\"\"\n        value = WWWAuthenticate.from_header(self.headers.get(\"WWW-Authenticate\"))\n\n        if value is None:\n            value = WWWAuthenticate(\"basic\")\n\n        def on_update(value: WWWAuthenticate) -> None:\n            self.www_authenticate = value\n\n        value._on_update = on_update\n        return value\n\n    @www_authenticate.setter\n    def www_authenticate(\n        self, value: WWWAuthenticate | list[WWWAuthenticate] | None\n    ) -> None:\n        if not value:  # None or empty list\n            del self.www_authenticate\n        elif isinstance(value, list):\n            # Clear any existing header by setting the first item.\n            self.headers.set(\"WWW-Authenticate\", value[0].to_header())\n\n            for item in value[1:]:\n                # Add additional header lines for additional items.\n                self.headers.add(\"WWW-Authenticate\", item.to_header())\n        else:\n            self.headers.set(\"WWW-Authenticate\", value.to_header())\n\n            def on_update(value: WWWAuthenticate) -> None:\n                self.www_authenticate = value\n\n            # When setting a single value, allow updating it directly.\n            value._on_update = on_update\n\n    @www_authenticate.deleter\n    def www_authenticate(self) -> None:\n        if \"WWW-Authenticate\" in self.headers:\n            del self.headers[\"WWW-Authenticate\"]\n\n    # CSP\n\n    @property\n    def content_security_policy(self) -> ContentSecurityPolicy:\n        \"\"\"The ``Content-Security-Policy`` header as a\n        :class:`~werkzeug.datastructures.ContentSecurityPolicy` object. Available\n        even if the header is not set.\n\n        The Content-Security-Policy header adds an additional layer of\n        security to help detect and mitigate certain types of attacks.\n        \"\"\"\n\n        def on_update(csp: ContentSecurityPolicy) -> None:\n            if not csp:\n                del self.headers[\"content-security-policy\"]\n            else:\n                self.headers[\"Content-Security-Policy\"] = csp.to_header()\n\n        rv = parse_csp_header(self.headers.get(\"content-security-policy\"), on_update)\n        if rv is None:\n            rv = ContentSecurityPolicy(None, on_update=on_update)\n        return rv\n\n    @content_security_policy.setter\n    def content_security_policy(\n        self, value: ContentSecurityPolicy | str | None\n    ) -> None:\n        if not value:\n            del self.headers[\"content-security-policy\"]\n        elif isinstance(value, str):\n            self.headers[\"Content-Security-Policy\"] = value\n        else:\n            self.headers[\"Content-Security-Policy\"] = value.to_header()\n\n    @property\n    def content_security_policy_report_only(self) -> ContentSecurityPolicy:\n        \"\"\"The ``Content-Security-policy-report-only`` header as a\n        :class:`~werkzeug.datastructures.ContentSecurityPolicy` object. Available\n        even if the header is not set.\n\n        The Content-Security-Policy-Report-Only header adds a csp policy\n        that is not enforced but is reported thereby helping detect\n        certain types of attacks.\n        \"\"\"\n\n        def on_update(csp: ContentSecurityPolicy) -> None:\n            if not csp:\n                del self.headers[\"content-security-policy-report-only\"]\n            else:\n                self.headers[\"Content-Security-policy-report-only\"] = csp.to_header()\n\n        rv = parse_csp_header(\n            self.headers.get(\"content-security-policy-report-only\"), on_update\n        )\n        if rv is None:\n            rv = ContentSecurityPolicy(None, on_update=on_update)\n        return rv\n\n    @content_security_policy_report_only.setter\n    def content_security_policy_report_only(\n        self, value: ContentSecurityPolicy | str | None\n    ) -> None:\n        if not value:\n            del self.headers[\"content-security-policy-report-only\"]\n        elif isinstance(value, str):\n            self.headers[\"Content-Security-policy-report-only\"] = value\n        else:\n            self.headers[\"Content-Security-policy-report-only\"] = value.to_header()\n\n    # CORS\n\n    @property\n    def access_control_allow_credentials(self) -> bool:\n        \"\"\"Whether credentials can be shared by the browser to\n        JavaScript code. As part of the preflight request it indicates\n        whether credentials can be used on the cross origin request.\n        \"\"\"\n        return \"Access-Control-Allow-Credentials\" in self.headers\n\n    @access_control_allow_credentials.setter\n    def access_control_allow_credentials(self, value: bool | None) -> None:\n        if value is True:\n            self.headers[\"Access-Control-Allow-Credentials\"] = \"true\"\n        else:\n            self.headers.pop(\"Access-Control-Allow-Credentials\", None)\n\n    access_control_allow_headers = header_property(\n        \"Access-Control-Allow-Headers\",\n        load_func=parse_set_header,\n        dump_func=dump_header,\n        doc=\"Which headers can be sent with the cross origin request.\",\n    )\n\n    access_control_allow_methods = header_property(\n        \"Access-Control-Allow-Methods\",\n        load_func=parse_set_header,\n        dump_func=dump_header,\n        doc=\"Which methods can be used for the cross origin request.\",\n    )\n\n    access_control_allow_origin = header_property[str](\n        \"Access-Control-Allow-Origin\",\n        doc=\"The origin or '*' for any origin that may make cross origin requests.\",\n    )\n\n    access_control_expose_headers = header_property(\n        \"Access-Control-Expose-Headers\",\n        load_func=parse_set_header,\n        dump_func=dump_header,\n        doc=\"Which headers can be shared by the browser to JavaScript code.\",\n    )\n\n    access_control_max_age = header_property(\n        \"Access-Control-Max-Age\",\n        load_func=int,\n        dump_func=str,\n        doc=\"The maximum age in seconds the access control settings can be cached for.\",\n    )\n\n    cross_origin_opener_policy = header_property[COOP](\n        \"Cross-Origin-Opener-Policy\",\n        load_func=lambda value: COOP(value),\n        dump_func=lambda value: value.value,\n        default=COOP.UNSAFE_NONE,\n        doc=\"\"\"Allows control over sharing of browsing context group with cross-origin\n        documents. Values must be a member of the :class:`werkzeug.http.COOP` enum.\"\"\",\n    )\n\n    cross_origin_embedder_policy = header_property[COEP](\n        \"Cross-Origin-Embedder-Policy\",\n        load_func=lambda value: COEP(value),\n        dump_func=lambda value: value.value,\n        default=COEP.UNSAFE_NONE,\n        doc=\"\"\"Prevents a document from loading any cross-origin resources that do not\n        explicitly grant the document permission. Values must be a member of the\n        :class:`werkzeug.http.COEP` enum.\"\"\",\n    )\n", "src/werkzeug/sansio/multipart.py": "from __future__ import annotations\n\nimport re\nimport typing as t\nfrom dataclasses import dataclass\nfrom enum import auto\nfrom enum import Enum\n\nfrom ..datastructures import Headers\nfrom ..exceptions import RequestEntityTooLarge\nfrom ..http import parse_options_header\n\n\nclass Event:\n    pass\n\n\n@dataclass(frozen=True)\nclass Preamble(Event):\n    data: bytes\n\n\n@dataclass(frozen=True)\nclass Field(Event):\n    name: str\n    headers: Headers\n\n\n@dataclass(frozen=True)\nclass File(Event):\n    name: str\n    filename: str\n    headers: Headers\n\n\n@dataclass(frozen=True)\nclass Data(Event):\n    data: bytes\n    more_data: bool\n\n\n@dataclass(frozen=True)\nclass Epilogue(Event):\n    data: bytes\n\n\nclass NeedData(Event):\n    pass\n\n\nNEED_DATA = NeedData()\n\n\nclass State(Enum):\n    PREAMBLE = auto()\n    PART = auto()\n    DATA = auto()\n    DATA_START = auto()\n    EPILOGUE = auto()\n    COMPLETE = auto()\n\n\n# Multipart line breaks MUST be CRLF (\\r\\n) by RFC-7578, except that\n# many implementations break this and either use CR or LF alone.\nLINE_BREAK = b\"(?:\\r\\n|\\n|\\r)\"\nBLANK_LINE_RE = re.compile(b\"(?:\\r\\n\\r\\n|\\r\\r|\\n\\n)\", re.MULTILINE)\nLINE_BREAK_RE = re.compile(LINE_BREAK, re.MULTILINE)\n# Header values can be continued via a space or tab after the linebreak, as\n# per RFC2231\nHEADER_CONTINUATION_RE = re.compile(b\"%s[ \\t]\" % LINE_BREAK, re.MULTILINE)\n# This must be long enough to contain any line breaks plus any\n# additional boundary markers (--) such that they will be found in a\n# subsequent search\nSEARCH_EXTRA_LENGTH = 8\n\n\nclass MultipartDecoder:\n    \"\"\"Decodes a multipart message as bytes into Python events.\n\n    The part data is returned as available to allow the caller to save\n    the data from memory to disk, if desired.\n    \"\"\"\n\n    def __init__(\n        self,\n        boundary: bytes,\n        max_form_memory_size: int | None = None,\n        *,\n        max_parts: int | None = None,\n    ) -> None:\n        self.buffer = bytearray()\n        self.complete = False\n        self.max_form_memory_size = max_form_memory_size\n        self.max_parts = max_parts\n        self.state = State.PREAMBLE\n        self.boundary = boundary\n\n        # Note in the below \\h i.e. horizontal whitespace is used\n        # as [^\\S\\n\\r] as \\h isn't supported in python.\n\n        # The preamble must end with a boundary where the boundary is\n        # prefixed by a line break, RFC2046. Except that many\n        # implementations including Werkzeug's tests omit the line\n        # break prefix. In addition the first boundary could be the\n        # epilogue boundary (for empty form-data) hence the matching\n        # group to understand if it is an epilogue boundary.\n        self.preamble_re = re.compile(\n            rb\"%s?--%s(--[^\\S\\n\\r]*%s?|[^\\S\\n\\r]*%s)\"\n            % (LINE_BREAK, re.escape(boundary), LINE_BREAK, LINE_BREAK),\n            re.MULTILINE,\n        )\n        # A boundary must include a line break prefix and suffix, and\n        # may include trailing whitespace. In addition the boundary\n        # could be the epilogue boundary hence the matching group to\n        # understand if it is an epilogue boundary.\n        self.boundary_re = re.compile(\n            rb\"%s--%s(--[^\\S\\n\\r]*%s?|[^\\S\\n\\r]*%s)\"\n            % (LINE_BREAK, re.escape(boundary), LINE_BREAK, LINE_BREAK),\n            re.MULTILINE,\n        )\n        self._search_position = 0\n        self._parts_decoded = 0\n\n    def last_newline(self, data: bytes) -> int:\n        try:\n            last_nl = data.rindex(b\"\\n\")\n        except ValueError:\n            last_nl = len(data)\n        try:\n            last_cr = data.rindex(b\"\\r\")\n        except ValueError:\n            last_cr = len(data)\n\n        return min(last_nl, last_cr)\n\n    def receive_data(self, data: bytes | None) -> None:\n        if data is None:\n            self.complete = True\n        elif (\n            self.max_form_memory_size is not None\n            and len(self.buffer) + len(data) > self.max_form_memory_size\n        ):\n            raise RequestEntityTooLarge()\n        else:\n            self.buffer.extend(data)\n\n    def next_event(self) -> Event:\n        event: Event = NEED_DATA\n\n        if self.state == State.PREAMBLE:\n            match = self.preamble_re.search(self.buffer, self._search_position)\n            if match is not None:\n                if match.group(1).startswith(b\"--\"):\n                    self.state = State.EPILOGUE\n                else:\n                    self.state = State.PART\n                data = bytes(self.buffer[: match.start()])\n                del self.buffer[: match.end()]\n                event = Preamble(data=data)\n                self._search_position = 0\n            else:\n                # Update the search start position to be equal to the\n                # current buffer length (already searched) minus a\n                # safe buffer for part of the search target.\n                self._search_position = max(\n                    0, len(self.buffer) - len(self.boundary) - SEARCH_EXTRA_LENGTH\n                )\n\n        elif self.state == State.PART:\n            match = BLANK_LINE_RE.search(self.buffer, self._search_position)\n            if match is not None:\n                headers = self._parse_headers(self.buffer[: match.start()])\n                # The final header ends with a single CRLF, however a\n                # blank line indicates the start of the\n                # body. Therefore the end is after the first CRLF.\n                headers_end = (match.start() + match.end()) // 2\n                del self.buffer[:headers_end]\n\n                if \"content-disposition\" not in headers:\n                    raise ValueError(\"Missing Content-Disposition header\")\n\n                disposition, extra = parse_options_header(\n                    headers[\"content-disposition\"]\n                )\n                name = t.cast(str, extra.get(\"name\"))\n                filename = extra.get(\"filename\")\n                if filename is not None:\n                    event = File(\n                        filename=filename,\n                        headers=headers,\n                        name=name,\n                    )\n                else:\n                    event = Field(\n                        headers=headers,\n                        name=name,\n                    )\n                self.state = State.DATA_START\n                self._search_position = 0\n                self._parts_decoded += 1\n\n                if self.max_parts is not None and self._parts_decoded > self.max_parts:\n                    raise RequestEntityTooLarge()\n            else:\n                # Update the search start position to be equal to the\n                # current buffer length (already searched) minus a\n                # safe buffer for part of the search target.\n                self._search_position = max(0, len(self.buffer) - SEARCH_EXTRA_LENGTH)\n\n        elif self.state == State.DATA_START:\n            data, del_index, more_data = self._parse_data(self.buffer, start=True)\n            del self.buffer[:del_index]\n            event = Data(data=data, more_data=more_data)\n            if more_data:\n                self.state = State.DATA\n\n        elif self.state == State.DATA:\n            data, del_index, more_data = self._parse_data(self.buffer, start=False)\n            del self.buffer[:del_index]\n            if data or not more_data:\n                event = Data(data=data, more_data=more_data)\n\n        elif self.state == State.EPILOGUE and self.complete:\n            event = Epilogue(data=bytes(self.buffer))\n            del self.buffer[:]\n            self.state = State.COMPLETE\n\n        if self.complete and isinstance(event, NeedData):\n            raise ValueError(f\"Invalid form-data cannot parse beyond {self.state}\")\n\n        return event\n\n    def _parse_headers(self, data: bytes) -> Headers:\n        headers: list[tuple[str, str]] = []\n        # Merge the continued headers into one line\n        data = HEADER_CONTINUATION_RE.sub(b\" \", data)\n        # Now there is one header per line\n        for line in data.splitlines():\n            line = line.strip()\n\n            if line != b\"\":\n                name, _, value = line.decode().partition(\":\")\n                headers.append((name.strip(), value.strip()))\n        return Headers(headers)\n\n    def _parse_data(self, data: bytes, *, start: bool) -> tuple[bytes, int, bool]:\n        # Body parts must start with CRLF (or CR or LF)\n        if start:\n            match = LINE_BREAK_RE.match(data)\n            data_start = t.cast(t.Match[bytes], match).end()\n        else:\n            data_start = 0\n\n        boundary = b\"--\" + self.boundary\n\n        if self.buffer.find(boundary) == -1:\n            # No complete boundary in the buffer, but there may be\n            # a partial boundary at the end. As the boundary\n            # starts with either a nl or cr find the earliest and\n            # return up to that as data.\n            data_end = del_index = self.last_newline(data[data_start:]) + data_start\n            # If amount of data after last newline is far from\n            # possible length of partial boundary, we should\n            # assume that there is no partial boundary in the buffer\n            # and return all pending data.\n            if (len(data) - data_end) > len(b\"\\n\" + boundary):\n                data_end = del_index = len(data)\n            more_data = True\n        else:\n            match = self.boundary_re.search(data)\n            if match is not None:\n                if match.group(1).startswith(b\"--\"):\n                    self.state = State.EPILOGUE\n                else:\n                    self.state = State.PART\n                data_end = match.start()\n                del_index = match.end()\n            else:\n                data_end = del_index = self.last_newline(data[data_start:]) + data_start\n            more_data = match is None\n\n        return bytes(data[data_start:data_end]), del_index, more_data\n\n\nclass MultipartEncoder:\n    def __init__(self, boundary: bytes) -> None:\n        self.boundary = boundary\n        self.state = State.PREAMBLE\n\n    def send_event(self, event: Event) -> bytes:\n        if isinstance(event, Preamble) and self.state == State.PREAMBLE:\n            self.state = State.PART\n            return event.data\n        elif isinstance(event, (Field, File)) and self.state in {\n            State.PREAMBLE,\n            State.PART,\n            State.DATA,\n        }:\n            data = b\"\\r\\n--\" + self.boundary + b\"\\r\\n\"\n            data += b'Content-Disposition: form-data; name=\"%s\"' % event.name.encode()\n            if isinstance(event, File):\n                data += b'; filename=\"%s\"' % event.filename.encode()\n            data += b\"\\r\\n\"\n            for name, value in t.cast(Field, event).headers:\n                if name.lower() != \"content-disposition\":\n                    data += f\"{name}: {value}\\r\\n\".encode()\n            self.state = State.DATA_START\n            return data\n        elif isinstance(event, Data) and self.state == State.DATA_START:\n            self.state = State.DATA\n            if len(event.data) > 0:\n                return b\"\\r\\n\" + event.data\n            else:\n                return event.data\n        elif isinstance(event, Data) and self.state == State.DATA:\n            return event.data\n        elif isinstance(event, Epilogue):\n            self.state = State.COMPLETE\n            return b\"\\r\\n--\" + self.boundary + b\"--\\r\\n\" + event.data\n        else:\n            raise ValueError(f\"Cannot generate {event} in state: {self.state}\")\n", "src/werkzeug/sansio/http.py": "from __future__ import annotations\n\nimport re\nimport typing as t\nfrom datetime import datetime\n\nfrom .._internal import _dt_as_utc\nfrom ..http import generate_etag\nfrom ..http import parse_date\nfrom ..http import parse_etags\nfrom ..http import parse_if_range_header\nfrom ..http import unquote_etag\n\n_etag_re = re.compile(r'([Ww]/)?(?:\"(.*?)\"|(.*?))(?:\\s*,\\s*|$)')\n\n\ndef is_resource_modified(\n    http_range: str | None = None,\n    http_if_range: str | None = None,\n    http_if_modified_since: str | None = None,\n    http_if_none_match: str | None = None,\n    http_if_match: str | None = None,\n    etag: str | None = None,\n    data: bytes | None = None,\n    last_modified: datetime | str | None = None,\n    ignore_if_range: bool = True,\n) -> bool:\n    \"\"\"Convenience method for conditional requests.\n    :param http_range: Range HTTP header\n    :param http_if_range: If-Range HTTP header\n    :param http_if_modified_since: If-Modified-Since HTTP header\n    :param http_if_none_match: If-None-Match HTTP header\n    :param http_if_match: If-Match HTTP header\n    :param etag: the etag for the response for comparison.\n    :param data: or alternatively the data of the response to automatically\n                 generate an etag using :func:`generate_etag`.\n    :param last_modified: an optional date of the last modification.\n    :param ignore_if_range: If `False`, `If-Range` header will be taken into\n                            account.\n    :return: `True` if the resource was modified, otherwise `False`.\n\n    .. versionadded:: 2.2\n    \"\"\"\n    if etag is None and data is not None:\n        etag = generate_etag(data)\n    elif data is not None:\n        raise TypeError(\"both data and etag given\")\n\n    unmodified = False\n    if isinstance(last_modified, str):\n        last_modified = parse_date(last_modified)\n\n    # HTTP doesn't use microsecond, remove it to avoid false positive\n    # comparisons. Mark naive datetimes as UTC.\n    if last_modified is not None:\n        last_modified = _dt_as_utc(last_modified.replace(microsecond=0))\n\n    if_range = None\n    if not ignore_if_range and http_range is not None:\n        # https://tools.ietf.org/html/rfc7233#section-3.2\n        # A server MUST ignore an If-Range header field received in a request\n        # that does not contain a Range header field.\n        if_range = parse_if_range_header(http_if_range)\n\n    if if_range is not None and if_range.date is not None:\n        modified_since: datetime | None = if_range.date\n    else:\n        modified_since = parse_date(http_if_modified_since)\n\n    if modified_since and last_modified and last_modified <= modified_since:\n        unmodified = True\n\n    if etag:\n        etag, _ = unquote_etag(etag)\n        etag = t.cast(str, etag)\n\n        if if_range is not None and if_range.etag is not None:\n            unmodified = parse_etags(if_range.etag).contains(etag)\n        else:\n            if_none_match = parse_etags(http_if_none_match)\n            if if_none_match:\n                # https://tools.ietf.org/html/rfc7232#section-3.2\n                # \"A recipient MUST use the weak comparison function when comparing\n                # entity-tags for If-None-Match\"\n                unmodified = if_none_match.contains_weak(etag)\n\n            # https://tools.ietf.org/html/rfc7232#section-3.1\n            # \"Origin server MUST use the strong comparison function when\n            # comparing entity-tags for If-Match\"\n            if_match = parse_etags(http_if_match)\n            if if_match:\n                unmodified = not if_match.is_strong(etag)\n\n    return not unmodified\n\n\n_cookie_re = re.compile(\n    r\"\"\"\n    ([^=;]*)\n    (?:\\s*=\\s*\n      (\n        \"(?:[^\\\\\"]|\\\\.)*\"\n      |\n        .*?\n      )\n    )?\n    \\s*;\\s*\n    \"\"\",\n    flags=re.ASCII | re.VERBOSE,\n)\n_cookie_unslash_re = re.compile(rb\"\\\\([0-3][0-7]{2}|.)\")\n\n\ndef _cookie_unslash_replace(m: t.Match[bytes]) -> bytes:\n    v = m.group(1)\n\n    if len(v) == 1:\n        return v\n\n    return int(v, 8).to_bytes(1, \"big\")\n\n\ndef parse_cookie(\n    cookie: str | None = None,\n    cls: type[ds.MultiDict[str, str]] | None = None,\n) -> ds.MultiDict[str, str]:\n    \"\"\"Parse a cookie from a string.\n\n    The same key can be provided multiple times, the values are stored\n    in-order. The default :class:`MultiDict` will have the first value\n    first, and all values can be retrieved with\n    :meth:`MultiDict.getlist`.\n\n    :param cookie: The cookie header as a string.\n    :param cls: A dict-like class to store the parsed cookies in.\n        Defaults to :class:`MultiDict`.\n\n    .. versionchanged:: 3.0\n        Passing bytes, and the ``charset`` and ``errors`` parameters, were removed.\n\n    .. versionadded:: 2.2\n    \"\"\"\n    if cls is None:\n        cls = t.cast(\"type[ds.MultiDict[str, str]]\", ds.MultiDict)\n\n    if not cookie:\n        return cls()\n\n    cookie = f\"{cookie};\"\n    out = []\n\n    for ck, cv in _cookie_re.findall(cookie):\n        ck = ck.strip()\n        cv = cv.strip()\n\n        if not ck:\n            continue\n\n        if len(cv) >= 2 and cv[0] == cv[-1] == '\"':\n            # Work with bytes here, since a UTF-8 character could be multiple bytes.\n            cv = _cookie_unslash_re.sub(\n                _cookie_unslash_replace, cv[1:-1].encode()\n            ).decode(errors=\"replace\")\n\n        out.append((ck, cv))\n\n    return cls(out)\n\n\n# circular dependencies\nfrom .. import datastructures as ds\n", "src/werkzeug/sansio/request.py": "from __future__ import annotations\n\nimport typing as t\nfrom datetime import datetime\nfrom urllib.parse import parse_qsl\n\nfrom ..datastructures import Accept\nfrom ..datastructures import Authorization\nfrom ..datastructures import CharsetAccept\nfrom ..datastructures import ETags\nfrom ..datastructures import Headers\nfrom ..datastructures import HeaderSet\nfrom ..datastructures import IfRange\nfrom ..datastructures import ImmutableList\nfrom ..datastructures import ImmutableMultiDict\nfrom ..datastructures import LanguageAccept\nfrom ..datastructures import MIMEAccept\nfrom ..datastructures import MultiDict\nfrom ..datastructures import Range\nfrom ..datastructures import RequestCacheControl\nfrom ..http import parse_accept_header\nfrom ..http import parse_cache_control_header\nfrom ..http import parse_date\nfrom ..http import parse_etags\nfrom ..http import parse_if_range_header\nfrom ..http import parse_list_header\nfrom ..http import parse_options_header\nfrom ..http import parse_range_header\nfrom ..http import parse_set_header\nfrom ..user_agent import UserAgent\nfrom ..utils import cached_property\nfrom ..utils import header_property\nfrom .http import parse_cookie\nfrom .utils import get_content_length\nfrom .utils import get_current_url\nfrom .utils import get_host\n\n\nclass Request:\n    \"\"\"Represents the non-IO parts of a HTTP request, including the\n    method, URL info, and headers.\n\n    This class is not meant for general use. It should only be used when\n    implementing WSGI, ASGI, or another HTTP application spec. Werkzeug\n    provides a WSGI implementation at :cls:`werkzeug.wrappers.Request`.\n\n    :param method: The method the request was made with, such as\n        ``GET``.\n    :param scheme: The URL scheme of the protocol the request used, such\n        as ``https`` or ``wss``.\n    :param server: The address of the server. ``(host, port)``,\n        ``(path, None)`` for unix sockets, or ``None`` if not known.\n    :param root_path: The prefix that the application is mounted under.\n        This is prepended to generated URLs, but is not part of route\n        matching.\n    :param path: The path part of the URL after ``root_path``.\n    :param query_string: The part of the URL after the \"?\".\n    :param headers: The headers received with the request.\n    :param remote_addr: The address of the client sending the request.\n\n    .. versionchanged:: 3.0\n        The ``charset``, ``url_charset``, and ``encoding_errors`` attributes\n        were removed.\n\n    .. versionadded:: 2.0\n    \"\"\"\n\n    #: the class to use for `args` and `form`.  The default is an\n    #: :class:`~werkzeug.datastructures.ImmutableMultiDict` which supports\n    #: multiple values per key.  alternatively it makes sense to use an\n    #: :class:`~werkzeug.datastructures.ImmutableOrderedMultiDict` which\n    #: preserves order or a :class:`~werkzeug.datastructures.ImmutableDict`\n    #: which is the fastest but only remembers the last key.  It is also\n    #: possible to use mutable structures, but this is not recommended.\n    #:\n    #: .. versionadded:: 0.6\n    parameter_storage_class: type[MultiDict[str, t.Any]] = ImmutableMultiDict\n\n    #: The type to be used for dict values from the incoming WSGI\n    #: environment. (For example for :attr:`cookies`.) By default an\n    #: :class:`~werkzeug.datastructures.ImmutableMultiDict` is used.\n    #:\n    #: .. versionchanged:: 1.0.0\n    #:     Changed to ``ImmutableMultiDict`` to support multiple values.\n    #:\n    #: .. versionadded:: 0.6\n    dict_storage_class: type[MultiDict[str, t.Any]] = ImmutableMultiDict\n\n    #: the type to be used for list values from the incoming WSGI environment.\n    #: By default an :class:`~werkzeug.datastructures.ImmutableList` is used\n    #: (for example for :attr:`access_list`).\n    #:\n    #: .. versionadded:: 0.6\n    list_storage_class: type[list[t.Any]] = ImmutableList\n\n    user_agent_class: type[UserAgent] = UserAgent\n    \"\"\"The class used and returned by the :attr:`user_agent` property to\n    parse the header. Defaults to\n    :class:`~werkzeug.user_agent.UserAgent`, which does no parsing. An\n    extension can provide a subclass that uses a parser to provide other\n    data.\n\n    .. versionadded:: 2.0\n    \"\"\"\n\n    #: Valid host names when handling requests. By default all hosts are\n    #: trusted, which means that whatever the client says the host is\n    #: will be accepted.\n    #:\n    #: Because ``Host`` and ``X-Forwarded-Host`` headers can be set to\n    #: any value by a malicious client, it is recommended to either set\n    #: this property or implement similar validation in the proxy (if\n    #: the application is being run behind one).\n    #:\n    #: .. versionadded:: 0.9\n    trusted_hosts: list[str] | None = None\n\n    def __init__(\n        self,\n        method: str,\n        scheme: str,\n        server: tuple[str, int | None] | None,\n        root_path: str,\n        path: str,\n        query_string: bytes,\n        headers: Headers,\n        remote_addr: str | None,\n    ) -> None:\n        #: The method the request was made with, such as ``GET``.\n        self.method = method.upper()\n        #: The URL scheme of the protocol the request used, such as\n        #: ``https`` or ``wss``.\n        self.scheme = scheme\n        #: The address of the server. ``(host, port)``, ``(path, None)``\n        #: for unix sockets, or ``None`` if not known.\n        self.server = server\n        #: The prefix that the application is mounted under, without a\n        #: trailing slash. :attr:`path` comes after this.\n        self.root_path = root_path.rstrip(\"/\")\n        #: The path part of the URL after :attr:`root_path`. This is the\n        #: path used for routing within the application.\n        self.path = \"/\" + path.lstrip(\"/\")\n        #: The part of the URL after the \"?\". This is the raw value, use\n        #: :attr:`args` for the parsed values.\n        self.query_string = query_string\n        #: The headers received with the request.\n        self.headers = headers\n        #: The address of the client sending the request.\n        self.remote_addr = remote_addr\n\n    def __repr__(self) -> str:\n        try:\n            url = self.url\n        except Exception as e:\n            url = f\"(invalid URL: {e})\"\n\n        return f\"<{type(self).__name__} {url!r} [{self.method}]>\"\n\n    @cached_property\n    def args(self) -> MultiDict[str, str]:\n        \"\"\"The parsed URL parameters (the part in the URL after the question\n        mark).\n\n        By default an\n        :class:`~werkzeug.datastructures.ImmutableMultiDict`\n        is returned from this function.  This can be changed by setting\n        :attr:`parameter_storage_class` to a different type.  This might\n        be necessary if the order of the form data is important.\n\n        .. versionchanged:: 2.3\n            Invalid bytes remain percent encoded.\n        \"\"\"\n        return self.parameter_storage_class(\n            parse_qsl(\n                self.query_string.decode(),\n                keep_blank_values=True,\n                errors=\"werkzeug.url_quote\",\n            )\n        )\n\n    @cached_property\n    def access_route(self) -> list[str]:\n        \"\"\"If a forwarded header exists this is a list of all ip addresses\n        from the client ip to the last proxy server.\n        \"\"\"\n        if \"X-Forwarded-For\" in self.headers:\n            return self.list_storage_class(\n                parse_list_header(self.headers[\"X-Forwarded-For\"])\n            )\n        elif self.remote_addr is not None:\n            return self.list_storage_class([self.remote_addr])\n        return self.list_storage_class()\n\n    @cached_property\n    def full_path(self) -> str:\n        \"\"\"Requested path, including the query string.\"\"\"\n        return f\"{self.path}?{self.query_string.decode()}\"\n\n    @property\n    def is_secure(self) -> bool:\n        \"\"\"``True`` if the request was made with a secure protocol\n        (HTTPS or WSS).\n        \"\"\"\n        return self.scheme in {\"https\", \"wss\"}\n\n    @cached_property\n    def url(self) -> str:\n        \"\"\"The full request URL with the scheme, host, root path, path,\n        and query string.\"\"\"\n        return get_current_url(\n            self.scheme, self.host, self.root_path, self.path, self.query_string\n        )\n\n    @cached_property\n    def base_url(self) -> str:\n        \"\"\"Like :attr:`url` but without the query string.\"\"\"\n        return get_current_url(self.scheme, self.host, self.root_path, self.path)\n\n    @cached_property\n    def root_url(self) -> str:\n        \"\"\"The request URL scheme, host, and root path. This is the root\n        that the application is accessed from.\n        \"\"\"\n        return get_current_url(self.scheme, self.host, self.root_path)\n\n    @cached_property\n    def host_url(self) -> str:\n        \"\"\"The request URL scheme and host only.\"\"\"\n        return get_current_url(self.scheme, self.host)\n\n    @cached_property\n    def host(self) -> str:\n        \"\"\"The host name the request was made to, including the port if\n        it's non-standard. Validated with :attr:`trusted_hosts`.\n        \"\"\"\n        return get_host(\n            self.scheme, self.headers.get(\"host\"), self.server, self.trusted_hosts\n        )\n\n    @cached_property\n    def cookies(self) -> ImmutableMultiDict[str, str]:\n        \"\"\"A :class:`dict` with the contents of all cookies transmitted with\n        the request.\"\"\"\n        wsgi_combined_cookie = \";\".join(self.headers.getlist(\"Cookie\"))\n        return parse_cookie(  # type: ignore\n            wsgi_combined_cookie, cls=self.dict_storage_class\n        )\n\n    # Common Descriptors\n\n    content_type = header_property[str](\n        \"Content-Type\",\n        doc=\"\"\"The Content-Type entity-header field indicates the media\n        type of the entity-body sent to the recipient or, in the case of\n        the HEAD method, the media type that would have been sent had\n        the request been a GET.\"\"\",\n        read_only=True,\n    )\n\n    @cached_property\n    def content_length(self) -> int | None:\n        \"\"\"The Content-Length entity-header field indicates the size of the\n        entity-body in bytes or, in the case of the HEAD method, the size of\n        the entity-body that would have been sent had the request been a\n        GET.\n        \"\"\"\n        return get_content_length(\n            http_content_length=self.headers.get(\"Content-Length\"),\n            http_transfer_encoding=self.headers.get(\"Transfer-Encoding\"),\n        )\n\n    content_encoding = header_property[str](\n        \"Content-Encoding\",\n        doc=\"\"\"The Content-Encoding entity-header field is used as a\n        modifier to the media-type. When present, its value indicates\n        what additional content codings have been applied to the\n        entity-body, and thus what decoding mechanisms must be applied\n        in order to obtain the media-type referenced by the Content-Type\n        header field.\n\n        .. versionadded:: 0.9\"\"\",\n        read_only=True,\n    )\n    content_md5 = header_property[str](\n        \"Content-MD5\",\n        doc=\"\"\"The Content-MD5 entity-header field, as defined in\n        RFC 1864, is an MD5 digest of the entity-body for the purpose of\n        providing an end-to-end message integrity check (MIC) of the\n        entity-body. (Note: a MIC is good for detecting accidental\n        modification of the entity-body in transit, but is not proof\n        against malicious attacks.)\n\n        .. versionadded:: 0.9\"\"\",\n        read_only=True,\n    )\n    referrer = header_property[str](\n        \"Referer\",\n        doc=\"\"\"The Referer[sic] request-header field allows the client\n        to specify, for the server's benefit, the address (URI) of the\n        resource from which the Request-URI was obtained (the\n        \"referrer\", although the header field is misspelled).\"\"\",\n        read_only=True,\n    )\n    date = header_property(\n        \"Date\",\n        None,\n        parse_date,\n        doc=\"\"\"The Date general-header field represents the date and\n        time at which the message was originated, having the same\n        semantics as orig-date in RFC 822.\n\n        .. versionchanged:: 2.0\n            The datetime object is timezone-aware.\n        \"\"\",\n        read_only=True,\n    )\n    max_forwards = header_property(\n        \"Max-Forwards\",\n        None,\n        int,\n        doc=\"\"\"The Max-Forwards request-header field provides a\n        mechanism with the TRACE and OPTIONS methods to limit the number\n        of proxies or gateways that can forward the request to the next\n        inbound server.\"\"\",\n        read_only=True,\n    )\n\n    def _parse_content_type(self) -> None:\n        if not hasattr(self, \"_parsed_content_type\"):\n            self._parsed_content_type = parse_options_header(\n                self.headers.get(\"Content-Type\", \"\")\n            )\n\n    @property\n    def mimetype(self) -> str:\n        \"\"\"Like :attr:`content_type`, but without parameters (eg, without\n        charset, type etc.) and always lowercase.  For example if the content\n        type is ``text/HTML; charset=utf-8`` the mimetype would be\n        ``'text/html'``.\n        \"\"\"\n        self._parse_content_type()\n        return self._parsed_content_type[0].lower()\n\n    @property\n    def mimetype_params(self) -> dict[str, str]:\n        \"\"\"The mimetype parameters as dict.  For example if the content\n        type is ``text/html; charset=utf-8`` the params would be\n        ``{'charset': 'utf-8'}``.\n        \"\"\"\n        self._parse_content_type()\n        return self._parsed_content_type[1]\n\n    @cached_property\n    def pragma(self) -> HeaderSet:\n        \"\"\"The Pragma general-header field is used to include\n        implementation-specific directives that might apply to any recipient\n        along the request/response chain.  All pragma directives specify\n        optional behavior from the viewpoint of the protocol; however, some\n        systems MAY require that behavior be consistent with the directives.\n        \"\"\"\n        return parse_set_header(self.headers.get(\"Pragma\", \"\"))\n\n    # Accept\n\n    @cached_property\n    def accept_mimetypes(self) -> MIMEAccept:\n        \"\"\"List of mimetypes this client supports as\n        :class:`~werkzeug.datastructures.MIMEAccept` object.\n        \"\"\"\n        return parse_accept_header(self.headers.get(\"Accept\"), MIMEAccept)\n\n    @cached_property\n    def accept_charsets(self) -> CharsetAccept:\n        \"\"\"List of charsets this client supports as\n        :class:`~werkzeug.datastructures.CharsetAccept` object.\n        \"\"\"\n        return parse_accept_header(self.headers.get(\"Accept-Charset\"), CharsetAccept)\n\n    @cached_property\n    def accept_encodings(self) -> Accept:\n        \"\"\"List of encodings this client accepts.  Encodings in a HTTP term\n        are compression encodings such as gzip.  For charsets have a look at\n        :attr:`accept_charset`.\n        \"\"\"\n        return parse_accept_header(self.headers.get(\"Accept-Encoding\"))\n\n    @cached_property\n    def accept_languages(self) -> LanguageAccept:\n        \"\"\"List of languages this client accepts as\n        :class:`~werkzeug.datastructures.LanguageAccept` object.\n\n        .. versionchanged 0.5\n           In previous versions this was a regular\n           :class:`~werkzeug.datastructures.Accept` object.\n        \"\"\"\n        return parse_accept_header(self.headers.get(\"Accept-Language\"), LanguageAccept)\n\n    # ETag\n\n    @cached_property\n    def cache_control(self) -> RequestCacheControl:\n        \"\"\"A :class:`~werkzeug.datastructures.RequestCacheControl` object\n        for the incoming cache control headers.\n        \"\"\"\n        cache_control = self.headers.get(\"Cache-Control\")\n        return parse_cache_control_header(cache_control, None, RequestCacheControl)\n\n    @cached_property\n    def if_match(self) -> ETags:\n        \"\"\"An object containing all the etags in the `If-Match` header.\n\n        :rtype: :class:`~werkzeug.datastructures.ETags`\n        \"\"\"\n        return parse_etags(self.headers.get(\"If-Match\"))\n\n    @cached_property\n    def if_none_match(self) -> ETags:\n        \"\"\"An object containing all the etags in the `If-None-Match` header.\n\n        :rtype: :class:`~werkzeug.datastructures.ETags`\n        \"\"\"\n        return parse_etags(self.headers.get(\"If-None-Match\"))\n\n    @cached_property\n    def if_modified_since(self) -> datetime | None:\n        \"\"\"The parsed `If-Modified-Since` header as a datetime object.\n\n        .. versionchanged:: 2.0\n            The datetime object is timezone-aware.\n        \"\"\"\n        return parse_date(self.headers.get(\"If-Modified-Since\"))\n\n    @cached_property\n    def if_unmodified_since(self) -> datetime | None:\n        \"\"\"The parsed `If-Unmodified-Since` header as a datetime object.\n\n        .. versionchanged:: 2.0\n            The datetime object is timezone-aware.\n        \"\"\"\n        return parse_date(self.headers.get(\"If-Unmodified-Since\"))\n\n    @cached_property\n    def if_range(self) -> IfRange:\n        \"\"\"The parsed ``If-Range`` header.\n\n        .. versionchanged:: 2.0\n            ``IfRange.date`` is timezone-aware.\n\n        .. versionadded:: 0.7\n        \"\"\"\n        return parse_if_range_header(self.headers.get(\"If-Range\"))\n\n    @cached_property\n    def range(self) -> Range | None:\n        \"\"\"The parsed `Range` header.\n\n        .. versionadded:: 0.7\n\n        :rtype: :class:`~werkzeug.datastructures.Range`\n        \"\"\"\n        return parse_range_header(self.headers.get(\"Range\"))\n\n    # User Agent\n\n    @cached_property\n    def user_agent(self) -> UserAgent:\n        \"\"\"The user agent. Use ``user_agent.string`` to get the header\n        value. Set :attr:`user_agent_class` to a subclass of\n        :class:`~werkzeug.user_agent.UserAgent` to provide parsing for\n        the other properties or other extended data.\n\n        .. versionchanged:: 2.1\n            The built-in parser was removed. Set ``user_agent_class`` to a ``UserAgent``\n            subclass to parse data from the string.\n        \"\"\"\n        return self.user_agent_class(self.headers.get(\"User-Agent\", \"\"))\n\n    # Authorization\n\n    @cached_property\n    def authorization(self) -> Authorization | None:\n        \"\"\"The ``Authorization`` header parsed into an :class:`.Authorization` object.\n        ``None`` if the header is not present.\n\n        .. versionchanged:: 2.3\n            :class:`Authorization` is no longer a ``dict``. The ``token`` attribute\n            was added for auth schemes that use a token instead of parameters.\n        \"\"\"\n        return Authorization.from_header(self.headers.get(\"Authorization\"))\n\n    # CORS\n\n    origin = header_property[str](\n        \"Origin\",\n        doc=(\n            \"The host that the request originated from. Set\"\n            \" :attr:`~CORSResponseMixin.access_control_allow_origin` on\"\n            \" the response to indicate which origins are allowed.\"\n        ),\n        read_only=True,\n    )\n\n    access_control_request_headers = header_property(\n        \"Access-Control-Request-Headers\",\n        load_func=parse_set_header,\n        doc=(\n            \"Sent with a preflight request to indicate which headers\"\n            \" will be sent with the cross origin request. Set\"\n            \" :attr:`~CORSResponseMixin.access_control_allow_headers`\"\n            \" on the response to indicate which headers are allowed.\"\n        ),\n        read_only=True,\n    )\n\n    access_control_request_method = header_property[str](\n        \"Access-Control-Request-Method\",\n        doc=(\n            \"Sent with a preflight request to indicate which method\"\n            \" will be used for the cross origin request. Set\"\n            \" :attr:`~CORSResponseMixin.access_control_allow_methods`\"\n            \" on the response to indicate which methods are allowed.\"\n        ),\n        read_only=True,\n    )\n\n    @property\n    def is_json(self) -> bool:\n        \"\"\"Check if the mimetype indicates JSON data, either\n        :mimetype:`application/json` or :mimetype:`application/*+json`.\n        \"\"\"\n        mt = self.mimetype\n        return (\n            mt == \"application/json\"\n            or mt.startswith(\"application/\")\n            and mt.endswith(\"+json\")\n        )\n", "src/werkzeug/sansio/utils.py": "from __future__ import annotations\n\nimport typing as t\nfrom urllib.parse import quote\n\nfrom .._internal import _plain_int\nfrom ..exceptions import SecurityError\nfrom ..urls import uri_to_iri\n\n\ndef host_is_trusted(hostname: str | None, trusted_list: t.Iterable[str]) -> bool:\n    \"\"\"Check if a host matches a list of trusted names.\n\n    :param hostname: The name to check.\n    :param trusted_list: A list of valid names to match. If a name\n        starts with a dot it will match all subdomains.\n\n    .. versionadded:: 0.9\n    \"\"\"\n    if not hostname:\n        return False\n\n    try:\n        hostname = hostname.partition(\":\")[0].encode(\"idna\").decode(\"ascii\")\n    except UnicodeEncodeError:\n        return False\n\n    if isinstance(trusted_list, str):\n        trusted_list = [trusted_list]\n\n    for ref in trusted_list:\n        if ref.startswith(\".\"):\n            ref = ref[1:]\n            suffix_match = True\n        else:\n            suffix_match = False\n\n        try:\n            ref = ref.partition(\":\")[0].encode(\"idna\").decode(\"ascii\")\n        except UnicodeEncodeError:\n            return False\n\n        if ref == hostname or (suffix_match and hostname.endswith(f\".{ref}\")):\n            return True\n\n    return False\n\n\ndef get_host(\n    scheme: str,\n    host_header: str | None,\n    server: tuple[str, int | None] | None = None,\n    trusted_hosts: t.Iterable[str] | None = None,\n) -> str:\n    \"\"\"Return the host for the given parameters.\n\n    This first checks the ``host_header``. If it's not present, then\n    ``server`` is used. The host will only contain the port if it is\n    different than the standard port for the protocol.\n\n    Optionally, verify that the host is trusted using\n    :func:`host_is_trusted` and raise a\n    :exc:`~werkzeug.exceptions.SecurityError` if it is not.\n\n    :param scheme: The protocol the request used, like ``\"https\"``.\n    :param host_header: The ``Host`` header value.\n    :param server: Address of the server. ``(host, port)``, or\n        ``(path, None)`` for unix sockets.\n    :param trusted_hosts: A list of trusted host names.\n\n    :return: Host, with port if necessary.\n    :raise ~werkzeug.exceptions.SecurityError: If the host is not\n        trusted.\n    \"\"\"\n    host = \"\"\n\n    if host_header is not None:\n        host = host_header\n    elif server is not None:\n        host = server[0]\n\n        if server[1] is not None:\n            host = f\"{host}:{server[1]}\"\n\n    if scheme in {\"http\", \"ws\"} and host.endswith(\":80\"):\n        host = host[:-3]\n    elif scheme in {\"https\", \"wss\"} and host.endswith(\":443\"):\n        host = host[:-4]\n\n    if trusted_hosts is not None:\n        if not host_is_trusted(host, trusted_hosts):\n            raise SecurityError(f\"Host {host!r} is not trusted.\")\n\n    return host\n\n\ndef get_current_url(\n    scheme: str,\n    host: str,\n    root_path: str | None = None,\n    path: str | None = None,\n    query_string: bytes | None = None,\n) -> str:\n    \"\"\"Recreate the URL for a request. If an optional part isn't\n    provided, it and subsequent parts are not included in the URL.\n\n    The URL is an IRI, not a URI, so it may contain Unicode characters.\n    Use :func:`~werkzeug.urls.iri_to_uri` to convert it to ASCII.\n\n    :param scheme: The protocol the request used, like ``\"https\"``.\n    :param host: The host the request was made to. See :func:`get_host`.\n    :param root_path: Prefix that the application is mounted under. This\n        is prepended to ``path``.\n    :param path: The path part of the URL after ``root_path``.\n    :param query_string: The portion of the URL after the \"?\".\n    \"\"\"\n    url = [scheme, \"://\", host]\n\n    if root_path is None:\n        url.append(\"/\")\n        return uri_to_iri(\"\".join(url))\n\n    # safe = https://url.spec.whatwg.org/#url-path-segment-string\n    # as well as percent for things that are already quoted\n    url.append(quote(root_path.rstrip(\"/\"), safe=\"!$&'()*+,/:;=@%\"))\n    url.append(\"/\")\n\n    if path is None:\n        return uri_to_iri(\"\".join(url))\n\n    url.append(quote(path.lstrip(\"/\"), safe=\"!$&'()*+,/:;=@%\"))\n\n    if query_string:\n        url.append(\"?\")\n        url.append(quote(query_string, safe=\"!$&'()*+,/:;=?@%\"))\n\n    return uri_to_iri(\"\".join(url))\n\n\ndef get_content_length(\n    http_content_length: str | None = None,\n    http_transfer_encoding: str | None = None,\n) -> int | None:\n    \"\"\"Return the ``Content-Length`` header value as an int. If the header is not given\n    or the ``Transfer-Encoding`` header is ``chunked``, ``None`` is returned to indicate\n    a streaming request. If the value is not an integer, or negative, 0 is returned.\n\n    :param http_content_length: The Content-Length HTTP header.\n    :param http_transfer_encoding: The Transfer-Encoding HTTP header.\n\n    .. versionadded:: 2.2\n    \"\"\"\n    if http_transfer_encoding == \"chunked\" or http_content_length is None:\n        return None\n\n    try:\n        return max(0, _plain_int(http_content_length))\n    except ValueError:\n        return 0\n", "src/werkzeug/sansio/__init__.py": "", "src/werkzeug/routing/map.py": "from __future__ import annotations\n\nimport typing as t\nimport warnings\nfrom pprint import pformat\nfrom threading import Lock\nfrom urllib.parse import quote\nfrom urllib.parse import urljoin\nfrom urllib.parse import urlunsplit\n\nfrom .._internal import _get_environ\nfrom .._internal import _wsgi_decoding_dance\nfrom ..datastructures import ImmutableDict\nfrom ..datastructures import MultiDict\nfrom ..exceptions import BadHost\nfrom ..exceptions import HTTPException\nfrom ..exceptions import MethodNotAllowed\nfrom ..exceptions import NotFound\nfrom ..urls import _urlencode\nfrom ..wsgi import get_host\nfrom .converters import DEFAULT_CONVERTERS\nfrom .exceptions import BuildError\nfrom .exceptions import NoMatch\nfrom .exceptions import RequestAliasRedirect\nfrom .exceptions import RequestPath\nfrom .exceptions import RequestRedirect\nfrom .exceptions import WebsocketMismatch\nfrom .matcher import StateMachineMatcher\nfrom .rules import _simple_rule_re\nfrom .rules import Rule\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n\n    from ..wrappers.request import Request\n    from .converters import BaseConverter\n    from .rules import RuleFactory\n\n\nclass Map:\n    \"\"\"The map class stores all the URL rules and some configuration\n    parameters.  Some of the configuration values are only stored on the\n    `Map` instance since those affect all rules, others are just defaults\n    and can be overridden for each rule.  Note that you have to specify all\n    arguments besides the `rules` as keyword arguments!\n\n    :param rules: sequence of url rules for this map.\n    :param default_subdomain: The default subdomain for rules without a\n                              subdomain defined.\n    :param strict_slashes: If a rule ends with a slash but the matched\n        URL does not, redirect to the URL with a trailing slash.\n    :param merge_slashes: Merge consecutive slashes when matching or\n        building URLs. Matches will redirect to the normalized URL.\n        Slashes in variable parts are not merged.\n    :param redirect_defaults: This will redirect to the default rule if it\n                              wasn't visited that way. This helps creating\n                              unique URLs.\n    :param converters: A dict of converters that adds additional converters\n                       to the list of converters. If you redefine one\n                       converter this will override the original one.\n    :param sort_parameters: If set to `True` the url parameters are sorted.\n                            See `url_encode` for more details.\n    :param sort_key: The sort key function for `url_encode`.\n    :param host_matching: if set to `True` it enables the host matching\n                          feature and disables the subdomain one.  If\n                          enabled the `host` parameter to rules is used\n                          instead of the `subdomain` one.\n\n    .. versionchanged:: 3.0\n        The ``charset`` and ``encoding_errors`` parameters were removed.\n\n    .. versionchanged:: 1.0\n        If ``url_scheme`` is ``ws`` or ``wss``, only WebSocket rules will match.\n\n    .. versionchanged:: 1.0\n        The ``merge_slashes`` parameter was added.\n\n    .. versionchanged:: 0.7\n        The ``encoding_errors`` and ``host_matching`` parameters were added.\n\n    .. versionchanged:: 0.5\n        The ``sort_parameters`` and ``sort_key``  paramters were added.\n    \"\"\"\n\n    #: A dict of default converters to be used.\n    default_converters = ImmutableDict(DEFAULT_CONVERTERS)\n\n    #: The type of lock to use when updating.\n    #:\n    #: .. versionadded:: 1.0\n    lock_class = Lock\n\n    def __init__(\n        self,\n        rules: t.Iterable[RuleFactory] | None = None,\n        default_subdomain: str = \"\",\n        strict_slashes: bool = True,\n        merge_slashes: bool = True,\n        redirect_defaults: bool = True,\n        converters: t.Mapping[str, type[BaseConverter]] | None = None,\n        sort_parameters: bool = False,\n        sort_key: t.Callable[[t.Any], t.Any] | None = None,\n        host_matching: bool = False,\n    ) -> None:\n        self._matcher = StateMachineMatcher(merge_slashes)\n        self._rules_by_endpoint: dict[t.Any, list[Rule]] = {}\n        self._remap = True\n        self._remap_lock = self.lock_class()\n\n        self.default_subdomain = default_subdomain\n        self.strict_slashes = strict_slashes\n        self.redirect_defaults = redirect_defaults\n        self.host_matching = host_matching\n\n        self.converters = self.default_converters.copy()\n        if converters:\n            self.converters.update(converters)\n\n        self.sort_parameters = sort_parameters\n        self.sort_key = sort_key\n\n        for rulefactory in rules or ():\n            self.add(rulefactory)\n\n    @property\n    def merge_slashes(self) -> bool:\n        return self._matcher.merge_slashes\n\n    @merge_slashes.setter\n    def merge_slashes(self, value: bool) -> None:\n        self._matcher.merge_slashes = value\n\n    def is_endpoint_expecting(self, endpoint: t.Any, *arguments: str) -> bool:\n        \"\"\"Iterate over all rules and check if the endpoint expects\n        the arguments provided.  This is for example useful if you have\n        some URLs that expect a language code and others that do not and\n        you want to wrap the builder a bit so that the current language\n        code is automatically added if not provided but endpoints expect\n        it.\n\n        :param endpoint: the endpoint to check.\n        :param arguments: this function accepts one or more arguments\n                          as positional arguments.  Each one of them is\n                          checked.\n        \"\"\"\n        self.update()\n        arguments_set = set(arguments)\n        for rule in self._rules_by_endpoint[endpoint]:\n            if arguments_set.issubset(rule.arguments):\n                return True\n        return False\n\n    @property\n    def _rules(self) -> list[Rule]:\n        return [rule for rules in self._rules_by_endpoint.values() for rule in rules]\n\n    def iter_rules(self, endpoint: t.Any | None = None) -> t.Iterator[Rule]:\n        \"\"\"Iterate over all rules or the rules of an endpoint.\n\n        :param endpoint: if provided only the rules for that endpoint\n                         are returned.\n        :return: an iterator\n        \"\"\"\n        self.update()\n        if endpoint is not None:\n            return iter(self._rules_by_endpoint[endpoint])\n        return iter(self._rules)\n\n    def add(self, rulefactory: RuleFactory) -> None:\n        \"\"\"Add a new rule or factory to the map and bind it.  Requires that the\n        rule is not bound to another map.\n\n        :param rulefactory: a :class:`Rule` or :class:`RuleFactory`\n        \"\"\"\n        for rule in rulefactory.get_rules(self):\n            rule.bind(self)\n            if not rule.build_only:\n                self._matcher.add(rule)\n            self._rules_by_endpoint.setdefault(rule.endpoint, []).append(rule)\n        self._remap = True\n\n    def bind(\n        self,\n        server_name: str,\n        script_name: str | None = None,\n        subdomain: str | None = None,\n        url_scheme: str = \"http\",\n        default_method: str = \"GET\",\n        path_info: str | None = None,\n        query_args: t.Mapping[str, t.Any] | str | None = None,\n    ) -> MapAdapter:\n        \"\"\"Return a new :class:`MapAdapter` with the details specified to the\n        call.  Note that `script_name` will default to ``'/'`` if not further\n        specified or `None`.  The `server_name` at least is a requirement\n        because the HTTP RFC requires absolute URLs for redirects and so all\n        redirect exceptions raised by Werkzeug will contain the full canonical\n        URL.\n\n        If no path_info is passed to :meth:`match` it will use the default path\n        info passed to bind.  While this doesn't really make sense for\n        manual bind calls, it's useful if you bind a map to a WSGI\n        environment which already contains the path info.\n\n        `subdomain` will default to the `default_subdomain` for this map if\n        no defined. If there is no `default_subdomain` you cannot use the\n        subdomain feature.\n\n        .. versionchanged:: 1.0\n            If ``url_scheme`` is ``ws`` or ``wss``, only WebSocket rules\n            will match.\n\n        .. versionchanged:: 0.15\n            ``path_info`` defaults to ``'/'`` if ``None``.\n\n        .. versionchanged:: 0.8\n            ``query_args`` can be a string.\n\n        .. versionchanged:: 0.7\n            Added ``query_args``.\n        \"\"\"\n        server_name = server_name.lower()\n        if self.host_matching:\n            if subdomain is not None:\n                raise RuntimeError(\"host matching enabled and a subdomain was provided\")\n        elif subdomain is None:\n            subdomain = self.default_subdomain\n        if script_name is None:\n            script_name = \"/\"\n        if path_info is None:\n            path_info = \"/\"\n\n        # Port isn't part of IDNA, and might push a name over the 63 octet limit.\n        server_name, port_sep, port = server_name.partition(\":\")\n\n        try:\n            server_name = server_name.encode(\"idna\").decode(\"ascii\")\n        except UnicodeError as e:\n            raise BadHost() from e\n\n        return MapAdapter(\n            self,\n            f\"{server_name}{port_sep}{port}\",\n            script_name,\n            subdomain,\n            url_scheme,\n            path_info,\n            default_method,\n            query_args,\n        )\n\n    def bind_to_environ(\n        self,\n        environ: WSGIEnvironment | Request,\n        server_name: str | None = None,\n        subdomain: str | None = None,\n    ) -> MapAdapter:\n        \"\"\"Like :meth:`bind` but you can pass it an WSGI environment and it\n        will fetch the information from that dictionary.  Note that because of\n        limitations in the protocol there is no way to get the current\n        subdomain and real `server_name` from the environment.  If you don't\n        provide it, Werkzeug will use `SERVER_NAME` and `SERVER_PORT` (or\n        `HTTP_HOST` if provided) as used `server_name` with disabled subdomain\n        feature.\n\n        If `subdomain` is `None` but an environment and a server name is\n        provided it will calculate the current subdomain automatically.\n        Example: `server_name` is ``'example.com'`` and the `SERVER_NAME`\n        in the wsgi `environ` is ``'staging.dev.example.com'`` the calculated\n        subdomain will be ``'staging.dev'``.\n\n        If the object passed as environ has an environ attribute, the value of\n        this attribute is used instead.  This allows you to pass request\n        objects.  Additionally `PATH_INFO` added as a default of the\n        :class:`MapAdapter` so that you don't have to pass the path info to\n        the match method.\n\n        .. versionchanged:: 1.0.0\n            If the passed server name specifies port 443, it will match\n            if the incoming scheme is ``https`` without a port.\n\n        .. versionchanged:: 1.0.0\n            A warning is shown when the passed server name does not\n            match the incoming WSGI server name.\n\n        .. versionchanged:: 0.8\n           This will no longer raise a ValueError when an unexpected server\n           name was passed.\n\n        .. versionchanged:: 0.5\n            previously this method accepted a bogus `calculate_subdomain`\n            parameter that did not have any effect.  It was removed because\n            of that.\n\n        :param environ: a WSGI environment.\n        :param server_name: an optional server name hint (see above).\n        :param subdomain: optionally the current subdomain (see above).\n        \"\"\"\n        env = _get_environ(environ)\n        wsgi_server_name = get_host(env).lower()\n        scheme = env[\"wsgi.url_scheme\"]\n        upgrade = any(\n            v.strip() == \"upgrade\"\n            for v in env.get(\"HTTP_CONNECTION\", \"\").lower().split(\",\")\n        )\n\n        if upgrade and env.get(\"HTTP_UPGRADE\", \"\").lower() == \"websocket\":\n            scheme = \"wss\" if scheme == \"https\" else \"ws\"\n\n        if server_name is None:\n            server_name = wsgi_server_name\n        else:\n            server_name = server_name.lower()\n\n            # strip standard port to match get_host()\n            if scheme in {\"http\", \"ws\"} and server_name.endswith(\":80\"):\n                server_name = server_name[:-3]\n            elif scheme in {\"https\", \"wss\"} and server_name.endswith(\":443\"):\n                server_name = server_name[:-4]\n\n        if subdomain is None and not self.host_matching:\n            cur_server_name = wsgi_server_name.split(\".\")\n            real_server_name = server_name.split(\".\")\n            offset = -len(real_server_name)\n\n            if cur_server_name[offset:] != real_server_name:\n                # This can happen even with valid configs if the server was\n                # accessed directly by IP address under some situations.\n                # Instead of raising an exception like in Werkzeug 0.7 or\n                # earlier we go by an invalid subdomain which will result\n                # in a 404 error on matching.\n                warnings.warn(\n                    f\"Current server name {wsgi_server_name!r} doesn't match configured\"\n                    f\" server name {server_name!r}\",\n                    stacklevel=2,\n                )\n                subdomain = \"<invalid>\"\n            else:\n                subdomain = \".\".join(filter(None, cur_server_name[:offset]))\n\n        def _get_wsgi_string(name: str) -> str | None:\n            val = env.get(name)\n            if val is not None:\n                return _wsgi_decoding_dance(val)\n            return None\n\n        script_name = _get_wsgi_string(\"SCRIPT_NAME\")\n        path_info = _get_wsgi_string(\"PATH_INFO\")\n        query_args = _get_wsgi_string(\"QUERY_STRING\")\n        return Map.bind(\n            self,\n            server_name,\n            script_name,\n            subdomain,\n            scheme,\n            env[\"REQUEST_METHOD\"],\n            path_info,\n            query_args=query_args,\n        )\n\n    def update(self) -> None:\n        \"\"\"Called before matching and building to keep the compiled rules\n        in the correct order after things changed.\n        \"\"\"\n        if not self._remap:\n            return\n\n        with self._remap_lock:\n            if not self._remap:\n                return\n\n            self._matcher.update()\n            for rules in self._rules_by_endpoint.values():\n                rules.sort(key=lambda x: x.build_compare_key())\n            self._remap = False\n\n    def __repr__(self) -> str:\n        rules = self.iter_rules()\n        return f\"{type(self).__name__}({pformat(list(rules))})\"\n\n\nclass MapAdapter:\n    \"\"\"Returned by :meth:`Map.bind` or :meth:`Map.bind_to_environ` and does\n    the URL matching and building based on runtime information.\n    \"\"\"\n\n    def __init__(\n        self,\n        map: Map,\n        server_name: str,\n        script_name: str,\n        subdomain: str | None,\n        url_scheme: str,\n        path_info: str,\n        default_method: str,\n        query_args: t.Mapping[str, t.Any] | str | None = None,\n    ):\n        self.map = map\n        self.server_name = server_name\n\n        if not script_name.endswith(\"/\"):\n            script_name += \"/\"\n\n        self.script_name = script_name\n        self.subdomain = subdomain\n        self.url_scheme = url_scheme\n        self.path_info = path_info\n        self.default_method = default_method\n        self.query_args = query_args\n        self.websocket = self.url_scheme in {\"ws\", \"wss\"}\n\n    def dispatch(\n        self,\n        view_func: t.Callable[[str, t.Mapping[str, t.Any]], WSGIApplication],\n        path_info: str | None = None,\n        method: str | None = None,\n        catch_http_exceptions: bool = False,\n    ) -> WSGIApplication:\n        \"\"\"Does the complete dispatching process.  `view_func` is called with\n        the endpoint and a dict with the values for the view.  It should\n        look up the view function, call it, and return a response object\n        or WSGI application.  http exceptions are not caught by default\n        so that applications can display nicer error messages by just\n        catching them by hand.  If you want to stick with the default\n        error messages you can pass it ``catch_http_exceptions=True`` and\n        it will catch the http exceptions.\n\n        Here a small example for the dispatch usage::\n\n            from werkzeug.wrappers import Request, Response\n            from werkzeug.wsgi import responder\n            from werkzeug.routing import Map, Rule\n\n            def on_index(request):\n                return Response('Hello from the index')\n\n            url_map = Map([Rule('/', endpoint='index')])\n            views = {'index': on_index}\n\n            @responder\n            def application(environ, start_response):\n                request = Request(environ)\n                urls = url_map.bind_to_environ(environ)\n                return urls.dispatch(lambda e, v: views[e](request, **v),\n                                     catch_http_exceptions=True)\n\n        Keep in mind that this method might return exception objects, too, so\n        use :class:`Response.force_type` to get a response object.\n\n        :param view_func: a function that is called with the endpoint as\n                          first argument and the value dict as second.  Has\n                          to dispatch to the actual view function with this\n                          information.  (see above)\n        :param path_info: the path info to use for matching.  Overrides the\n                          path info specified on binding.\n        :param method: the HTTP method used for matching.  Overrides the\n                       method specified on binding.\n        :param catch_http_exceptions: set to `True` to catch any of the\n                                      werkzeug :class:`HTTPException`\\\\s.\n        \"\"\"\n        try:\n            try:\n                endpoint, args = self.match(path_info, method)\n            except RequestRedirect as e:\n                return e\n            return view_func(endpoint, args)\n        except HTTPException as e:\n            if catch_http_exceptions:\n                return e\n            raise\n\n    @t.overload\n    def match(\n        self,\n        path_info: str | None = None,\n        method: str | None = None,\n        return_rule: t.Literal[False] = False,\n        query_args: t.Mapping[str, t.Any] | str | None = None,\n        websocket: bool | None = None,\n    ) -> tuple[t.Any, t.Mapping[str, t.Any]]: ...\n\n    @t.overload\n    def match(\n        self,\n        path_info: str | None = None,\n        method: str | None = None,\n        return_rule: t.Literal[True] = True,\n        query_args: t.Mapping[str, t.Any] | str | None = None,\n        websocket: bool | None = None,\n    ) -> tuple[Rule, t.Mapping[str, t.Any]]: ...\n\n    def match(\n        self,\n        path_info: str | None = None,\n        method: str | None = None,\n        return_rule: bool = False,\n        query_args: t.Mapping[str, t.Any] | str | None = None,\n        websocket: bool | None = None,\n    ) -> tuple[t.Any | Rule, t.Mapping[str, t.Any]]:\n        \"\"\"The usage is simple: you just pass the match method the current\n        path info as well as the method (which defaults to `GET`).  The\n        following things can then happen:\n\n        - you receive a `NotFound` exception that indicates that no URL is\n          matching.  A `NotFound` exception is also a WSGI application you\n          can call to get a default page not found page (happens to be the\n          same object as `werkzeug.exceptions.NotFound`)\n\n        - you receive a `MethodNotAllowed` exception that indicates that there\n          is a match for this URL but not for the current request method.\n          This is useful for RESTful applications.\n\n        - you receive a `RequestRedirect` exception with a `new_url`\n          attribute.  This exception is used to notify you about a request\n          Werkzeug requests from your WSGI application.  This is for example the\n          case if you request ``/foo`` although the correct URL is ``/foo/``\n          You can use the `RequestRedirect` instance as response-like object\n          similar to all other subclasses of `HTTPException`.\n\n        - you receive a ``WebsocketMismatch`` exception if the only\n          match is a WebSocket rule but the bind is an HTTP request, or\n          if the match is an HTTP rule but the bind is a WebSocket\n          request.\n\n        - you get a tuple in the form ``(endpoint, arguments)`` if there is\n          a match (unless `return_rule` is True, in which case you get a tuple\n          in the form ``(rule, arguments)``)\n\n        If the path info is not passed to the match method the default path\n        info of the map is used (defaults to the root URL if not defined\n        explicitly).\n\n        All of the exceptions raised are subclasses of `HTTPException` so they\n        can be used as WSGI responses. They will all render generic error or\n        redirect pages.\n\n        Here is a small example for matching:\n\n        >>> m = Map([\n        ...     Rule('/', endpoint='index'),\n        ...     Rule('/downloads/', endpoint='downloads/index'),\n        ...     Rule('/downloads/<int:id>', endpoint='downloads/show')\n        ... ])\n        >>> urls = m.bind(\"example.com\", \"/\")\n        >>> urls.match(\"/\", \"GET\")\n        ('index', {})\n        >>> urls.match(\"/downloads/42\")\n        ('downloads/show', {'id': 42})\n\n        And here is what happens on redirect and missing URLs:\n\n        >>> urls.match(\"/downloads\")\n        Traceback (most recent call last):\n          ...\n        RequestRedirect: http://example.com/downloads/\n        >>> urls.match(\"/missing\")\n        Traceback (most recent call last):\n          ...\n        NotFound: 404 Not Found\n\n        :param path_info: the path info to use for matching.  Overrides the\n                          path info specified on binding.\n        :param method: the HTTP method used for matching.  Overrides the\n                       method specified on binding.\n        :param return_rule: return the rule that matched instead of just the\n                            endpoint (defaults to `False`).\n        :param query_args: optional query arguments that are used for\n                           automatic redirects as string or dictionary.  It's\n                           currently not possible to use the query arguments\n                           for URL matching.\n        :param websocket: Match WebSocket instead of HTTP requests. A\n            websocket request has a ``ws`` or ``wss``\n            :attr:`url_scheme`. This overrides that detection.\n\n        .. versionadded:: 1.0\n            Added ``websocket``.\n\n        .. versionchanged:: 0.8\n            ``query_args`` can be a string.\n\n        .. versionadded:: 0.7\n            Added ``query_args``.\n\n        .. versionadded:: 0.6\n            Added ``return_rule``.\n        \"\"\"\n        self.map.update()\n        if path_info is None:\n            path_info = self.path_info\n        if query_args is None:\n            query_args = self.query_args or {}\n        method = (method or self.default_method).upper()\n\n        if websocket is None:\n            websocket = self.websocket\n\n        domain_part = self.server_name\n\n        if not self.map.host_matching and self.subdomain is not None:\n            domain_part = self.subdomain\n\n        path_part = f\"/{path_info.lstrip('/')}\" if path_info else \"\"\n\n        try:\n            result = self.map._matcher.match(domain_part, path_part, method, websocket)\n        except RequestPath as e:\n            # safe = https://url.spec.whatwg.org/#url-path-segment-string\n            new_path = quote(e.path_info, safe=\"!$&'()*+,/:;=@\")\n            raise RequestRedirect(\n                self.make_redirect_url(new_path, query_args)\n            ) from None\n        except RequestAliasRedirect as e:\n            raise RequestRedirect(\n                self.make_alias_redirect_url(\n                    f\"{domain_part}|{path_part}\",\n                    e.endpoint,\n                    e.matched_values,\n                    method,\n                    query_args,\n                )\n            ) from None\n        except NoMatch as e:\n            if e.have_match_for:\n                raise MethodNotAllowed(valid_methods=list(e.have_match_for)) from None\n\n            if e.websocket_mismatch:\n                raise WebsocketMismatch() from None\n\n            raise NotFound() from None\n        else:\n            rule, rv = result\n\n            if self.map.redirect_defaults:\n                redirect_url = self.get_default_redirect(rule, method, rv, query_args)\n                if redirect_url is not None:\n                    raise RequestRedirect(redirect_url)\n\n            if rule.redirect_to is not None:\n                if isinstance(rule.redirect_to, str):\n\n                    def _handle_match(match: t.Match[str]) -> str:\n                        value = rv[match.group(1)]\n                        return rule._converters[match.group(1)].to_url(value)\n\n                    redirect_url = _simple_rule_re.sub(_handle_match, rule.redirect_to)\n                else:\n                    redirect_url = rule.redirect_to(self, **rv)\n\n                if self.subdomain:\n                    netloc = f\"{self.subdomain}.{self.server_name}\"\n                else:\n                    netloc = self.server_name\n\n                raise RequestRedirect(\n                    urljoin(\n                        f\"{self.url_scheme or 'http'}://{netloc}{self.script_name}\",\n                        redirect_url,\n                    )\n                )\n\n            if return_rule:\n                return rule, rv\n            else:\n                return rule.endpoint, rv\n\n    def test(self, path_info: str | None = None, method: str | None = None) -> bool:\n        \"\"\"Test if a rule would match.  Works like `match` but returns `True`\n        if the URL matches, or `False` if it does not exist.\n\n        :param path_info: the path info to use for matching.  Overrides the\n                          path info specified on binding.\n        :param method: the HTTP method used for matching.  Overrides the\n                       method specified on binding.\n        \"\"\"\n        try:\n            self.match(path_info, method)\n        except RequestRedirect:\n            pass\n        except HTTPException:\n            return False\n        return True\n\n    def allowed_methods(self, path_info: str | None = None) -> t.Iterable[str]:\n        \"\"\"Returns the valid methods that match for a given path.\n\n        .. versionadded:: 0.7\n        \"\"\"\n        try:\n            self.match(path_info, method=\"--\")\n        except MethodNotAllowed as e:\n            return e.valid_methods  # type: ignore\n        except HTTPException:\n            pass\n        return []\n\n    def get_host(self, domain_part: str | None) -> str:\n        \"\"\"Figures out the full host name for the given domain part.  The\n        domain part is a subdomain in case host matching is disabled or\n        a full host name.\n        \"\"\"\n        if self.map.host_matching:\n            if domain_part is None:\n                return self.server_name\n\n            return domain_part\n\n        if domain_part is None:\n            subdomain = self.subdomain\n        else:\n            subdomain = domain_part\n\n        if subdomain:\n            return f\"{subdomain}.{self.server_name}\"\n        else:\n            return self.server_name\n\n    def get_default_redirect(\n        self,\n        rule: Rule,\n        method: str,\n        values: t.MutableMapping[str, t.Any],\n        query_args: t.Mapping[str, t.Any] | str,\n    ) -> str | None:\n        \"\"\"A helper that returns the URL to redirect to if it finds one.\n        This is used for default redirecting only.\n\n        :internal:\n        \"\"\"\n        assert self.map.redirect_defaults\n        for r in self.map._rules_by_endpoint[rule.endpoint]:\n            # every rule that comes after this one, including ourself\n            # has a lower priority for the defaults.  We order the ones\n            # with the highest priority up for building.\n            if r is rule:\n                break\n            if r.provides_defaults_for(rule) and r.suitable_for(values, method):\n                values.update(r.defaults)  # type: ignore\n                domain_part, path = r.build(values)  # type: ignore\n                return self.make_redirect_url(path, query_args, domain_part=domain_part)\n        return None\n\n    def encode_query_args(self, query_args: t.Mapping[str, t.Any] | str) -> str:\n        if not isinstance(query_args, str):\n            return _urlencode(query_args)\n        return query_args\n\n    def make_redirect_url(\n        self,\n        path_info: str,\n        query_args: t.Mapping[str, t.Any] | str | None = None,\n        domain_part: str | None = None,\n    ) -> str:\n        \"\"\"Creates a redirect URL.\n\n        :internal:\n        \"\"\"\n        if query_args is None:\n            query_args = self.query_args\n\n        if query_args:\n            query_str = self.encode_query_args(query_args)\n        else:\n            query_str = None\n\n        scheme = self.url_scheme or \"http\"\n        host = self.get_host(domain_part)\n        path = \"/\".join((self.script_name.strip(\"/\"), path_info.lstrip(\"/\")))\n        return urlunsplit((scheme, host, path, query_str, None))\n\n    def make_alias_redirect_url(\n        self,\n        path: str,\n        endpoint: t.Any,\n        values: t.Mapping[str, t.Any],\n        method: str,\n        query_args: t.Mapping[str, t.Any] | str,\n    ) -> str:\n        \"\"\"Internally called to make an alias redirect URL.\"\"\"\n        url = self.build(\n            endpoint, values, method, append_unknown=False, force_external=True\n        )\n        if query_args:\n            url += f\"?{self.encode_query_args(query_args)}\"\n        assert url != path, \"detected invalid alias setting. No canonical URL found\"\n        return url\n\n    def _partial_build(\n        self,\n        endpoint: t.Any,\n        values: t.Mapping[str, t.Any],\n        method: str | None,\n        append_unknown: bool,\n    ) -> tuple[str, str, bool] | None:\n        \"\"\"Helper for :meth:`build`.  Returns subdomain and path for the\n        rule that accepts this endpoint, values and method.\n\n        :internal:\n        \"\"\"\n        # in case the method is none, try with the default method first\n        if method is None:\n            rv = self._partial_build(\n                endpoint, values, self.default_method, append_unknown\n            )\n            if rv is not None:\n                return rv\n\n        # Default method did not match or a specific method is passed.\n        # Check all for first match with matching host. If no matching\n        # host is found, go with first result.\n        first_match = None\n\n        for rule in self.map._rules_by_endpoint.get(endpoint, ()):\n            if rule.suitable_for(values, method):\n                build_rv = rule.build(values, append_unknown)\n\n                if build_rv is not None:\n                    rv = (build_rv[0], build_rv[1], rule.websocket)\n                    if self.map.host_matching:\n                        if rv[0] == self.server_name:\n                            return rv\n                        elif first_match is None:\n                            first_match = rv\n                    else:\n                        return rv\n\n        return first_match\n\n    def build(\n        self,\n        endpoint: t.Any,\n        values: t.Mapping[str, t.Any] | None = None,\n        method: str | None = None,\n        force_external: bool = False,\n        append_unknown: bool = True,\n        url_scheme: str | None = None,\n    ) -> str:\n        \"\"\"Building URLs works pretty much the other way round.  Instead of\n        `match` you call `build` and pass it the endpoint and a dict of\n        arguments for the placeholders.\n\n        The `build` function also accepts an argument called `force_external`\n        which, if you set it to `True` will force external URLs. Per default\n        external URLs (include the server name) will only be used if the\n        target URL is on a different subdomain.\n\n        >>> m = Map([\n        ...     Rule('/', endpoint='index'),\n        ...     Rule('/downloads/', endpoint='downloads/index'),\n        ...     Rule('/downloads/<int:id>', endpoint='downloads/show')\n        ... ])\n        >>> urls = m.bind(\"example.com\", \"/\")\n        >>> urls.build(\"index\", {})\n        '/'\n        >>> urls.build(\"downloads/show\", {'id': 42})\n        '/downloads/42'\n        >>> urls.build(\"downloads/show\", {'id': 42}, force_external=True)\n        'http://example.com/downloads/42'\n\n        Because URLs cannot contain non ASCII data you will always get\n        bytes back.  Non ASCII characters are urlencoded with the\n        charset defined on the map instance.\n\n        Additional values are converted to strings and appended to the URL as\n        URL querystring parameters:\n\n        >>> urls.build(\"index\", {'q': 'My Searchstring'})\n        '/?q=My+Searchstring'\n\n        When processing those additional values, lists are furthermore\n        interpreted as multiple values (as per\n        :py:class:`werkzeug.datastructures.MultiDict`):\n\n        >>> urls.build(\"index\", {'q': ['a', 'b', 'c']})\n        '/?q=a&q=b&q=c'\n\n        Passing a ``MultiDict`` will also add multiple values:\n\n        >>> urls.build(\"index\", MultiDict((('p', 'z'), ('q', 'a'), ('q', 'b'))))\n        '/?p=z&q=a&q=b'\n\n        If a rule does not exist when building a `BuildError` exception is\n        raised.\n\n        The build method accepts an argument called `method` which allows you\n        to specify the method you want to have an URL built for if you have\n        different methods for the same endpoint specified.\n\n        :param endpoint: the endpoint of the URL to build.\n        :param values: the values for the URL to build.  Unhandled values are\n                       appended to the URL as query parameters.\n        :param method: the HTTP method for the rule if there are different\n                       URLs for different methods on the same endpoint.\n        :param force_external: enforce full canonical external URLs. If the URL\n                               scheme is not provided, this will generate\n                               a protocol-relative URL.\n        :param append_unknown: unknown parameters are appended to the generated\n                               URL as query string argument.  Disable this\n                               if you want the builder to ignore those.\n        :param url_scheme: Scheme to use in place of the bound\n            :attr:`url_scheme`.\n\n        .. versionchanged:: 2.0\n            Added the ``url_scheme`` parameter.\n\n        .. versionadded:: 0.6\n           Added the ``append_unknown`` parameter.\n        \"\"\"\n        self.map.update()\n\n        if values:\n            if isinstance(values, MultiDict):\n                values = {\n                    k: (v[0] if len(v) == 1 else v)\n                    for k, v in dict.items(values)\n                    if len(v) != 0\n                }\n            else:  # plain dict\n                values = {k: v for k, v in values.items() if v is not None}\n        else:\n            values = {}\n\n        rv = self._partial_build(endpoint, values, method, append_unknown)\n        if rv is None:\n            raise BuildError(endpoint, values, method, self)\n\n        domain_part, path, websocket = rv\n        host = self.get_host(domain_part)\n\n        if url_scheme is None:\n            url_scheme = self.url_scheme\n\n        # Always build WebSocket routes with the scheme (browsers\n        # require full URLs). If bound to a WebSocket, ensure that HTTP\n        # routes are built with an HTTP scheme.\n        secure = url_scheme in {\"https\", \"wss\"}\n\n        if websocket:\n            force_external = True\n            url_scheme = \"wss\" if secure else \"ws\"\n        elif url_scheme:\n            url_scheme = \"https\" if secure else \"http\"\n\n        # shortcut this.\n        if not force_external and (\n            (self.map.host_matching and host == self.server_name)\n            or (not self.map.host_matching and domain_part == self.subdomain)\n        ):\n            return f\"{self.script_name.rstrip('/')}/{path.lstrip('/')}\"\n\n        scheme = f\"{url_scheme}:\" if url_scheme else \"\"\n        return f\"{scheme}//{host}{self.script_name[:-1]}/{path.lstrip('/')}\"\n", "src/werkzeug/routing/exceptions.py": "from __future__ import annotations\n\nimport difflib\nimport typing as t\n\nfrom ..exceptions import BadRequest\nfrom ..exceptions import HTTPException\nfrom ..utils import cached_property\nfrom ..utils import redirect\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import WSGIEnvironment\n\n    from ..wrappers.request import Request\n    from ..wrappers.response import Response\n    from .map import MapAdapter\n    from .rules import Rule\n\n\nclass RoutingException(Exception):\n    \"\"\"Special exceptions that require the application to redirect, notifying\n    about missing urls, etc.\n\n    :internal:\n    \"\"\"\n\n\nclass RequestRedirect(HTTPException, RoutingException):\n    \"\"\"Raise if the map requests a redirect. This is for example the case if\n    `strict_slashes` are activated and an url that requires a trailing slash.\n\n    The attribute `new_url` contains the absolute destination url.\n    \"\"\"\n\n    code = 308\n\n    def __init__(self, new_url: str) -> None:\n        super().__init__(new_url)\n        self.new_url = new_url\n\n    def get_response(\n        self,\n        environ: WSGIEnvironment | Request | None = None,\n        scope: dict[str, t.Any] | None = None,\n    ) -> Response:\n        return redirect(self.new_url, self.code)\n\n\nclass RequestPath(RoutingException):\n    \"\"\"Internal exception.\"\"\"\n\n    __slots__ = (\"path_info\",)\n\n    def __init__(self, path_info: str) -> None:\n        super().__init__()\n        self.path_info = path_info\n\n\nclass RequestAliasRedirect(RoutingException):  # noqa: B903\n    \"\"\"This rule is an alias and wants to redirect to the canonical URL.\"\"\"\n\n    def __init__(self, matched_values: t.Mapping[str, t.Any], endpoint: t.Any) -> None:\n        super().__init__()\n        self.matched_values = matched_values\n        self.endpoint = endpoint\n\n\nclass BuildError(RoutingException, LookupError):\n    \"\"\"Raised if the build system cannot find a URL for an endpoint with the\n    values provided.\n    \"\"\"\n\n    def __init__(\n        self,\n        endpoint: t.Any,\n        values: t.Mapping[str, t.Any],\n        method: str | None,\n        adapter: MapAdapter | None = None,\n    ) -> None:\n        super().__init__(endpoint, values, method)\n        self.endpoint = endpoint\n        self.values = values\n        self.method = method\n        self.adapter = adapter\n\n    @cached_property\n    def suggested(self) -> Rule | None:\n        return self.closest_rule(self.adapter)\n\n    def closest_rule(self, adapter: MapAdapter | None) -> Rule | None:\n        def _score_rule(rule: Rule) -> float:\n            return sum(\n                [\n                    0.98\n                    * difflib.SequenceMatcher(\n                        # endpoints can be any type, compare as strings\n                        None,\n                        str(rule.endpoint),\n                        str(self.endpoint),\n                    ).ratio(),\n                    0.01 * bool(set(self.values or ()).issubset(rule.arguments)),\n                    0.01 * bool(rule.methods and self.method in rule.methods),\n                ]\n            )\n\n        if adapter and adapter.map._rules:\n            return max(adapter.map._rules, key=_score_rule)\n\n        return None\n\n    def __str__(self) -> str:\n        message = [f\"Could not build url for endpoint {self.endpoint!r}\"]\n        if self.method:\n            message.append(f\" ({self.method!r})\")\n        if self.values:\n            message.append(f\" with values {sorted(self.values)!r}\")\n        message.append(\".\")\n        if self.suggested:\n            if self.endpoint == self.suggested.endpoint:\n                if (\n                    self.method\n                    and self.suggested.methods is not None\n                    and self.method not in self.suggested.methods\n                ):\n                    message.append(\n                        \" Did you mean to use methods\"\n                        f\" {sorted(self.suggested.methods)!r}?\"\n                    )\n                missing_values = self.suggested.arguments.union(\n                    set(self.suggested.defaults or ())\n                ) - set(self.values.keys())\n                if missing_values:\n                    message.append(\n                        f\" Did you forget to specify values {sorted(missing_values)!r}?\"\n                    )\n            else:\n                message.append(f\" Did you mean {self.suggested.endpoint!r} instead?\")\n        return \"\".join(message)\n\n\nclass WebsocketMismatch(BadRequest):\n    \"\"\"The only matched rule is either a WebSocket and the request is\n    HTTP, or the rule is HTTP and the request is a WebSocket.\n    \"\"\"\n\n\nclass NoMatch(Exception):\n    __slots__ = (\"have_match_for\", \"websocket_mismatch\")\n\n    def __init__(self, have_match_for: set[str], websocket_mismatch: bool) -> None:\n        self.have_match_for = have_match_for\n        self.websocket_mismatch = websocket_mismatch\n", "src/werkzeug/routing/rules.py": "from __future__ import annotations\n\nimport ast\nimport re\nimport typing as t\nfrom dataclasses import dataclass\nfrom string import Template\nfrom types import CodeType\nfrom urllib.parse import quote\n\nfrom ..datastructures import iter_multi_items\nfrom ..urls import _urlencode\nfrom .converters import ValidationError\n\nif t.TYPE_CHECKING:\n    from .converters import BaseConverter\n    from .map import Map\n\n\nclass Weighting(t.NamedTuple):\n    number_static_weights: int\n    static_weights: list[tuple[int, int]]\n    number_argument_weights: int\n    argument_weights: list[int]\n\n\n@dataclass\nclass RulePart:\n    \"\"\"A part of a rule.\n\n    Rules can be represented by parts as delimited by `/` with\n    instances of this class representing those parts. The *content* is\n    either the raw content if *static* or a regex string to match\n    against. The *weight* can be used to order parts when matching.\n\n    \"\"\"\n\n    content: str\n    final: bool\n    static: bool\n    suffixed: bool\n    weight: Weighting\n\n\n_part_re = re.compile(\n    r\"\"\"\n    (?:\n        (?P<slash>/)                                 # a slash\n      |\n        (?P<static>[^</]+)                           # static rule data\n      |\n        (?:\n          <\n            (?:\n              (?P<converter>[a-zA-Z_][a-zA-Z0-9_]*)   # converter name\n              (?:\\((?P<arguments>.*?)\\))?             # converter arguments\n              :                                       # variable delimiter\n            )?\n            (?P<variable>[a-zA-Z_][a-zA-Z0-9_]*)      # variable name\n           >\n        )\n    )\n    \"\"\",\n    re.VERBOSE,\n)\n\n_simple_rule_re = re.compile(r\"<([^>]+)>\")\n_converter_args_re = re.compile(\n    r\"\"\"\n    \\s*\n    ((?P<name>\\w+)\\s*=\\s*)?\n    (?P<value>\n        True|False|\n        \\d+.\\d+|\n        \\d+.|\n        \\d+|\n        [\\w\\d_.]+|\n        [urUR]?(?P<stringval>\"[^\"]*?\"|'[^']*')\n    )\\s*,\n    \"\"\",\n    re.VERBOSE,\n)\n\n\n_PYTHON_CONSTANTS = {\"None\": None, \"True\": True, \"False\": False}\n\n\ndef _find(value: str, target: str, pos: int) -> int:\n    \"\"\"Find the *target* in *value* after *pos*.\n\n    Returns the *value* length if *target* isn't found.\n    \"\"\"\n    try:\n        return value.index(target, pos)\n    except ValueError:\n        return len(value)\n\n\ndef _pythonize(value: str) -> None | bool | int | float | str:\n    if value in _PYTHON_CONSTANTS:\n        return _PYTHON_CONSTANTS[value]\n    for convert in int, float:\n        try:\n            return convert(value)  # type: ignore\n        except ValueError:\n            pass\n    if value[:1] == value[-1:] and value[0] in \"\\\"'\":\n        value = value[1:-1]\n    return str(value)\n\n\ndef parse_converter_args(argstr: str) -> tuple[tuple[t.Any, ...], dict[str, t.Any]]:\n    argstr += \",\"\n    args = []\n    kwargs = {}\n    position = 0\n\n    for item in _converter_args_re.finditer(argstr):\n        if item.start() != position:\n            raise ValueError(\n                f\"Cannot parse converter argument '{argstr[position:item.start()]}'\"\n            )\n\n        value = item.group(\"stringval\")\n        if value is None:\n            value = item.group(\"value\")\n        value = _pythonize(value)\n        if not item.group(\"name\"):\n            args.append(value)\n        else:\n            name = item.group(\"name\")\n            kwargs[name] = value\n        position = item.end()\n\n    return tuple(args), kwargs\n\n\nclass RuleFactory:\n    \"\"\"As soon as you have more complex URL setups it's a good idea to use rule\n    factories to avoid repetitive tasks.  Some of them are builtin, others can\n    be added by subclassing `RuleFactory` and overriding `get_rules`.\n    \"\"\"\n\n    def get_rules(self, map: Map) -> t.Iterable[Rule]:\n        \"\"\"Subclasses of `RuleFactory` have to override this method and return\n        an iterable of rules.\"\"\"\n        raise NotImplementedError()\n\n\nclass Subdomain(RuleFactory):\n    \"\"\"All URLs provided by this factory have the subdomain set to a\n    specific domain. For example if you want to use the subdomain for\n    the current language this can be a good setup::\n\n        url_map = Map([\n            Rule('/', endpoint='#select_language'),\n            Subdomain('<string(length=2):lang_code>', [\n                Rule('/', endpoint='index'),\n                Rule('/about', endpoint='about'),\n                Rule('/help', endpoint='help')\n            ])\n        ])\n\n    All the rules except for the ``'#select_language'`` endpoint will now\n    listen on a two letter long subdomain that holds the language code\n    for the current request.\n    \"\"\"\n\n    def __init__(self, subdomain: str, rules: t.Iterable[RuleFactory]) -> None:\n        self.subdomain = subdomain\n        self.rules = rules\n\n    def get_rules(self, map: Map) -> t.Iterator[Rule]:\n        for rulefactory in self.rules:\n            for rule in rulefactory.get_rules(map):\n                rule = rule.empty()\n                rule.subdomain = self.subdomain\n                yield rule\n\n\nclass Submount(RuleFactory):\n    \"\"\"Like `Subdomain` but prefixes the URL rule with a given string::\n\n        url_map = Map([\n            Rule('/', endpoint='index'),\n            Submount('/blog', [\n                Rule('/', endpoint='blog/index'),\n                Rule('/entry/<entry_slug>', endpoint='blog/show')\n            ])\n        ])\n\n    Now the rule ``'blog/show'`` matches ``/blog/entry/<entry_slug>``.\n    \"\"\"\n\n    def __init__(self, path: str, rules: t.Iterable[RuleFactory]) -> None:\n        self.path = path.rstrip(\"/\")\n        self.rules = rules\n\n    def get_rules(self, map: Map) -> t.Iterator[Rule]:\n        for rulefactory in self.rules:\n            for rule in rulefactory.get_rules(map):\n                rule = rule.empty()\n                rule.rule = self.path + rule.rule\n                yield rule\n\n\nclass EndpointPrefix(RuleFactory):\n    \"\"\"Prefixes all endpoints (which must be strings for this factory) with\n    another string. This can be useful for sub applications::\n\n        url_map = Map([\n            Rule('/', endpoint='index'),\n            EndpointPrefix('blog/', [Submount('/blog', [\n                Rule('/', endpoint='index'),\n                Rule('/entry/<entry_slug>', endpoint='show')\n            ])])\n        ])\n    \"\"\"\n\n    def __init__(self, prefix: str, rules: t.Iterable[RuleFactory]) -> None:\n        self.prefix = prefix\n        self.rules = rules\n\n    def get_rules(self, map: Map) -> t.Iterator[Rule]:\n        for rulefactory in self.rules:\n            for rule in rulefactory.get_rules(map):\n                rule = rule.empty()\n                rule.endpoint = self.prefix + rule.endpoint\n                yield rule\n\n\nclass RuleTemplate:\n    \"\"\"Returns copies of the rules wrapped and expands string templates in\n    the endpoint, rule, defaults or subdomain sections.\n\n    Here a small example for such a rule template::\n\n        from werkzeug.routing import Map, Rule, RuleTemplate\n\n        resource = RuleTemplate([\n            Rule('/$name/', endpoint='$name.list'),\n            Rule('/$name/<int:id>', endpoint='$name.show')\n        ])\n\n        url_map = Map([resource(name='user'), resource(name='page')])\n\n    When a rule template is called the keyword arguments are used to\n    replace the placeholders in all the string parameters.\n    \"\"\"\n\n    def __init__(self, rules: t.Iterable[Rule]) -> None:\n        self.rules = list(rules)\n\n    def __call__(self, *args: t.Any, **kwargs: t.Any) -> RuleTemplateFactory:\n        return RuleTemplateFactory(self.rules, dict(*args, **kwargs))\n\n\nclass RuleTemplateFactory(RuleFactory):\n    \"\"\"A factory that fills in template variables into rules.  Used by\n    `RuleTemplate` internally.\n\n    :internal:\n    \"\"\"\n\n    def __init__(\n        self, rules: t.Iterable[RuleFactory], context: dict[str, t.Any]\n    ) -> None:\n        self.rules = rules\n        self.context = context\n\n    def get_rules(self, map: Map) -> t.Iterator[Rule]:\n        for rulefactory in self.rules:\n            for rule in rulefactory.get_rules(map):\n                new_defaults = subdomain = None\n                if rule.defaults:\n                    new_defaults = {}\n                    for key, value in rule.defaults.items():\n                        if isinstance(value, str):\n                            value = Template(value).substitute(self.context)\n                        new_defaults[key] = value\n                if rule.subdomain is not None:\n                    subdomain = Template(rule.subdomain).substitute(self.context)\n                new_endpoint = rule.endpoint\n                if isinstance(new_endpoint, str):\n                    new_endpoint = Template(new_endpoint).substitute(self.context)\n                yield Rule(\n                    Template(rule.rule).substitute(self.context),\n                    new_defaults,\n                    subdomain,\n                    rule.methods,\n                    rule.build_only,\n                    new_endpoint,\n                    rule.strict_slashes,\n                )\n\n\ndef _prefix_names(src: str) -> ast.stmt:\n    \"\"\"ast parse and prefix names with `.` to avoid collision with user vars\"\"\"\n    tree = ast.parse(src).body[0]\n    if isinstance(tree, ast.Expr):\n        tree = tree.value  # type: ignore\n    for node in ast.walk(tree):\n        if isinstance(node, ast.Name):\n            node.id = f\".{node.id}\"\n    return tree\n\n\n_CALL_CONVERTER_CODE_FMT = \"self._converters[{elem!r}].to_url()\"\n_IF_KWARGS_URL_ENCODE_CODE = \"\"\"\\\nif kwargs:\n    params = self._encode_query_vars(kwargs)\n    q = \"?\" if params else \"\"\nelse:\n    q = params = \"\"\n\"\"\"\n_IF_KWARGS_URL_ENCODE_AST = _prefix_names(_IF_KWARGS_URL_ENCODE_CODE)\n_URL_ENCODE_AST_NAMES = (_prefix_names(\"q\"), _prefix_names(\"params\"))\n\n\nclass Rule(RuleFactory):\n    \"\"\"A Rule represents one URL pattern.  There are some options for `Rule`\n    that change the way it behaves and are passed to the `Rule` constructor.\n    Note that besides the rule-string all arguments *must* be keyword arguments\n    in order to not break the application on Werkzeug upgrades.\n\n    `string`\n        Rule strings basically are just normal URL paths with placeholders in\n        the format ``<converter(arguments):name>`` where the converter and the\n        arguments are optional.  If no converter is defined the `default`\n        converter is used which means `string` in the normal configuration.\n\n        URL rules that end with a slash are branch URLs, others are leaves.\n        If you have `strict_slashes` enabled (which is the default), all\n        branch URLs that are matched without a trailing slash will trigger a\n        redirect to the same URL with the missing slash appended.\n\n        The converters are defined on the `Map`.\n\n    `endpoint`\n        The endpoint for this rule. This can be anything. A reference to a\n        function, a string, a number etc.  The preferred way is using a string\n        because the endpoint is used for URL generation.\n\n    `defaults`\n        An optional dict with defaults for other rules with the same endpoint.\n        This is a bit tricky but useful if you want to have unique URLs::\n\n            url_map = Map([\n                Rule('/all/', defaults={'page': 1}, endpoint='all_entries'),\n                Rule('/all/page/<int:page>', endpoint='all_entries')\n            ])\n\n        If a user now visits ``http://example.com/all/page/1`` they will be\n        redirected to ``http://example.com/all/``.  If `redirect_defaults` is\n        disabled on the `Map` instance this will only affect the URL\n        generation.\n\n    `subdomain`\n        The subdomain rule string for this rule. If not specified the rule\n        only matches for the `default_subdomain` of the map.  If the map is\n        not bound to a subdomain this feature is disabled.\n\n        Can be useful if you want to have user profiles on different subdomains\n        and all subdomains are forwarded to your application::\n\n            url_map = Map([\n                Rule('/', subdomain='<username>', endpoint='user/homepage'),\n                Rule('/stats', subdomain='<username>', endpoint='user/stats')\n            ])\n\n    `methods`\n        A sequence of http methods this rule applies to.  If not specified, all\n        methods are allowed. For example this can be useful if you want different\n        endpoints for `POST` and `GET`.  If methods are defined and the path\n        matches but the method matched against is not in this list or in the\n        list of another rule for that path the error raised is of the type\n        `MethodNotAllowed` rather than `NotFound`.  If `GET` is present in the\n        list of methods and `HEAD` is not, `HEAD` is added automatically.\n\n    `strict_slashes`\n        Override the `Map` setting for `strict_slashes` only for this rule. If\n        not specified the `Map` setting is used.\n\n    `merge_slashes`\n        Override :attr:`Map.merge_slashes` for this rule.\n\n    `build_only`\n        Set this to True and the rule will never match but will create a URL\n        that can be build. This is useful if you have resources on a subdomain\n        or folder that are not handled by the WSGI application (like static data)\n\n    `redirect_to`\n        If given this must be either a string or callable.  In case of a\n        callable it's called with the url adapter that triggered the match and\n        the values of the URL as keyword arguments and has to return the target\n        for the redirect, otherwise it has to be a string with placeholders in\n        rule syntax::\n\n            def foo_with_slug(adapter, id):\n                # ask the database for the slug for the old id.  this of\n                # course has nothing to do with werkzeug.\n                return f'foo/{Foo.get_slug_for_id(id)}'\n\n            url_map = Map([\n                Rule('/foo/<slug>', endpoint='foo'),\n                Rule('/some/old/url/<slug>', redirect_to='foo/<slug>'),\n                Rule('/other/old/url/<int:id>', redirect_to=foo_with_slug)\n            ])\n\n        When the rule is matched the routing system will raise a\n        `RequestRedirect` exception with the target for the redirect.\n\n        Keep in mind that the URL will be joined against the URL root of the\n        script so don't use a leading slash on the target URL unless you\n        really mean root of that domain.\n\n    `alias`\n        If enabled this rule serves as an alias for another rule with the same\n        endpoint and arguments.\n\n    `host`\n        If provided and the URL map has host matching enabled this can be\n        used to provide a match rule for the whole host.  This also means\n        that the subdomain feature is disabled.\n\n    `websocket`\n        If ``True``, this rule is only matches for WebSocket (``ws://``,\n        ``wss://``) requests. By default, rules will only match for HTTP\n        requests.\n\n    .. versionchanged:: 2.1\n        Percent-encoded newlines (``%0a``), which are decoded by WSGI\n        servers, are considered when routing instead of terminating the\n        match early.\n\n    .. versionadded:: 1.0\n        Added ``websocket``.\n\n    .. versionadded:: 1.0\n        Added ``merge_slashes``.\n\n    .. versionadded:: 0.7\n        Added ``alias`` and ``host``.\n\n    .. versionchanged:: 0.6.1\n       ``HEAD`` is added to ``methods`` if ``GET`` is present.\n    \"\"\"\n\n    def __init__(\n        self,\n        string: str,\n        defaults: t.Mapping[str, t.Any] | None = None,\n        subdomain: str | None = None,\n        methods: t.Iterable[str] | None = None,\n        build_only: bool = False,\n        endpoint: t.Any | None = None,\n        strict_slashes: bool | None = None,\n        merge_slashes: bool | None = None,\n        redirect_to: str | t.Callable[..., str] | None = None,\n        alias: bool = False,\n        host: str | None = None,\n        websocket: bool = False,\n    ) -> None:\n        if not string.startswith(\"/\"):\n            raise ValueError(f\"URL rule '{string}' must start with a slash.\")\n\n        self.rule = string\n        self.is_leaf = not string.endswith(\"/\")\n        self.is_branch = string.endswith(\"/\")\n\n        self.map: Map = None  # type: ignore\n        self.strict_slashes = strict_slashes\n        self.merge_slashes = merge_slashes\n        self.subdomain = subdomain\n        self.host = host\n        self.defaults = defaults\n        self.build_only = build_only\n        self.alias = alias\n        self.websocket = websocket\n\n        if methods is not None:\n            if isinstance(methods, str):\n                raise TypeError(\"'methods' should be a list of strings.\")\n\n            methods = {x.upper() for x in methods}\n\n            if \"HEAD\" not in methods and \"GET\" in methods:\n                methods.add(\"HEAD\")\n\n            if websocket and methods - {\"GET\", \"HEAD\", \"OPTIONS\"}:\n                raise ValueError(\n                    \"WebSocket rules can only use 'GET', 'HEAD', and 'OPTIONS' methods.\"\n                )\n\n        self.methods = methods\n        self.endpoint: t.Any = endpoint\n        self.redirect_to = redirect_to\n\n        if defaults:\n            self.arguments = set(map(str, defaults))\n        else:\n            self.arguments = set()\n\n        self._converters: dict[str, BaseConverter] = {}\n        self._trace: list[tuple[bool, str]] = []\n        self._parts: list[RulePart] = []\n\n    def empty(self) -> Rule:\n        \"\"\"\n        Return an unbound copy of this rule.\n\n        This can be useful if want to reuse an already bound URL for another\n        map.  See ``get_empty_kwargs`` to override what keyword arguments are\n        provided to the new copy.\n        \"\"\"\n        return type(self)(self.rule, **self.get_empty_kwargs())\n\n    def get_empty_kwargs(self) -> t.Mapping[str, t.Any]:\n        \"\"\"\n        Provides kwargs for instantiating empty copy with empty()\n\n        Use this method to provide custom keyword arguments to the subclass of\n        ``Rule`` when calling ``some_rule.empty()``.  Helpful when the subclass\n        has custom keyword arguments that are needed at instantiation.\n\n        Must return a ``dict`` that will be provided as kwargs to the new\n        instance of ``Rule``, following the initial ``self.rule`` value which\n        is always provided as the first, required positional argument.\n        \"\"\"\n        defaults = None\n        if self.defaults:\n            defaults = dict(self.defaults)\n        return dict(\n            defaults=defaults,\n            subdomain=self.subdomain,\n            methods=self.methods,\n            build_only=self.build_only,\n            endpoint=self.endpoint,\n            strict_slashes=self.strict_slashes,\n            redirect_to=self.redirect_to,\n            alias=self.alias,\n            host=self.host,\n        )\n\n    def get_rules(self, map: Map) -> t.Iterator[Rule]:\n        yield self\n\n    def refresh(self) -> None:\n        \"\"\"Rebinds and refreshes the URL.  Call this if you modified the\n        rule in place.\n\n        :internal:\n        \"\"\"\n        self.bind(self.map, rebind=True)\n\n    def bind(self, map: Map, rebind: bool = False) -> None:\n        \"\"\"Bind the url to a map and create a regular expression based on\n        the information from the rule itself and the defaults from the map.\n\n        :internal:\n        \"\"\"\n        if self.map is not None and not rebind:\n            raise RuntimeError(f\"url rule {self!r} already bound to map {self.map!r}\")\n        self.map = map\n        if self.strict_slashes is None:\n            self.strict_slashes = map.strict_slashes\n        if self.merge_slashes is None:\n            self.merge_slashes = map.merge_slashes\n        if self.subdomain is None:\n            self.subdomain = map.default_subdomain\n        self.compile()\n\n    def get_converter(\n        self,\n        variable_name: str,\n        converter_name: str,\n        args: tuple[t.Any, ...],\n        kwargs: t.Mapping[str, t.Any],\n    ) -> BaseConverter:\n        \"\"\"Looks up the converter for the given parameter.\n\n        .. versionadded:: 0.9\n        \"\"\"\n        if converter_name not in self.map.converters:\n            raise LookupError(f\"the converter {converter_name!r} does not exist\")\n        return self.map.converters[converter_name](self.map, *args, **kwargs)\n\n    def _encode_query_vars(self, query_vars: t.Mapping[str, t.Any]) -> str:\n        items: t.Iterable[tuple[str, str]] = iter_multi_items(query_vars)\n\n        if self.map.sort_parameters:\n            items = sorted(items, key=self.map.sort_key)\n\n        return _urlencode(items)\n\n    def _parse_rule(self, rule: str) -> t.Iterable[RulePart]:\n        content = \"\"\n        static = True\n        argument_weights = []\n        static_weights: list[tuple[int, int]] = []\n        final = False\n        convertor_number = 0\n\n        pos = 0\n        while pos < len(rule):\n            match = _part_re.match(rule, pos)\n            if match is None:\n                raise ValueError(f\"malformed url rule: {rule!r}\")\n\n            data = match.groupdict()\n            if data[\"static\"] is not None:\n                static_weights.append((len(static_weights), -len(data[\"static\"])))\n                self._trace.append((False, data[\"static\"]))\n                content += data[\"static\"] if static else re.escape(data[\"static\"])\n\n            if data[\"variable\"] is not None:\n                if static:\n                    # Switching content to represent regex, hence the need to escape\n                    content = re.escape(content)\n                static = False\n                c_args, c_kwargs = parse_converter_args(data[\"arguments\"] or \"\")\n                convobj = self.get_converter(\n                    data[\"variable\"], data[\"converter\"] or \"default\", c_args, c_kwargs\n                )\n                self._converters[data[\"variable\"]] = convobj\n                self.arguments.add(data[\"variable\"])\n                if not convobj.part_isolating:\n                    final = True\n                content += f\"(?P<__werkzeug_{convertor_number}>{convobj.regex})\"\n                convertor_number += 1\n                argument_weights.append(convobj.weight)\n                self._trace.append((True, data[\"variable\"]))\n\n            if data[\"slash\"] is not None:\n                self._trace.append((False, \"/\"))\n                if final:\n                    content += \"/\"\n                else:\n                    if not static:\n                        content += r\"\\Z\"\n                    weight = Weighting(\n                        -len(static_weights),\n                        static_weights,\n                        -len(argument_weights),\n                        argument_weights,\n                    )\n                    yield RulePart(\n                        content=content,\n                        final=final,\n                        static=static,\n                        suffixed=False,\n                        weight=weight,\n                    )\n                    content = \"\"\n                    static = True\n                    argument_weights = []\n                    static_weights = []\n                    final = False\n                    convertor_number = 0\n\n            pos = match.end()\n\n        suffixed = False\n        if final and content[-1] == \"/\":\n            # If a converter is part_isolating=False (matches slashes) and ends with a\n            # slash, augment the regex to support slash redirects.\n            suffixed = True\n            content = content[:-1] + \"(?<!/)(/?)\"\n        if not static:\n            content += r\"\\Z\"\n        weight = Weighting(\n            -len(static_weights),\n            static_weights,\n            -len(argument_weights),\n            argument_weights,\n        )\n        yield RulePart(\n            content=content,\n            final=final,\n            static=static,\n            suffixed=suffixed,\n            weight=weight,\n        )\n        if suffixed:\n            yield RulePart(\n                content=\"\", final=False, static=True, suffixed=False, weight=weight\n            )\n\n    def compile(self) -> None:\n        \"\"\"Compiles the regular expression and stores it.\"\"\"\n        assert self.map is not None, \"rule not bound\"\n\n        if self.map.host_matching:\n            domain_rule = self.host or \"\"\n        else:\n            domain_rule = self.subdomain or \"\"\n        self._parts = []\n        self._trace = []\n        self._converters = {}\n        if domain_rule == \"\":\n            self._parts = [\n                RulePart(\n                    content=\"\",\n                    final=False,\n                    static=True,\n                    suffixed=False,\n                    weight=Weighting(0, [], 0, []),\n                )\n            ]\n        else:\n            self._parts.extend(self._parse_rule(domain_rule))\n        self._trace.append((False, \"|\"))\n        rule = self.rule\n        if self.merge_slashes:\n            rule = re.sub(\"/{2,}?\", \"/\", self.rule)\n        self._parts.extend(self._parse_rule(rule))\n\n        self._build: t.Callable[..., tuple[str, str]]\n        self._build = self._compile_builder(False).__get__(self, None)\n        self._build_unknown: t.Callable[..., tuple[str, str]]\n        self._build_unknown = self._compile_builder(True).__get__(self, None)\n\n    @staticmethod\n    def _get_func_code(code: CodeType, name: str) -> t.Callable[..., tuple[str, str]]:\n        globs: dict[str, t.Any] = {}\n        locs: dict[str, t.Any] = {}\n        exec(code, globs, locs)\n        return locs[name]  # type: ignore\n\n    def _compile_builder(\n        self, append_unknown: bool = True\n    ) -> t.Callable[..., tuple[str, str]]:\n        defaults = self.defaults or {}\n        dom_ops: list[tuple[bool, str]] = []\n        url_ops: list[tuple[bool, str]] = []\n\n        opl = dom_ops\n        for is_dynamic, data in self._trace:\n            if data == \"|\" and opl is dom_ops:\n                opl = url_ops\n                continue\n            # this seems like a silly case to ever come up but:\n            # if a default is given for a value that appears in the rule,\n            # resolve it to a constant ahead of time\n            if is_dynamic and data in defaults:\n                data = self._converters[data].to_url(defaults[data])\n                opl.append((False, data))\n            elif not is_dynamic:\n                # safe = https://url.spec.whatwg.org/#url-path-segment-string\n                opl.append((False, quote(data, safe=\"!$&'()*+,/:;=@\")))\n            else:\n                opl.append((True, data))\n\n        def _convert(elem: str) -> ast.stmt:\n            ret = _prefix_names(_CALL_CONVERTER_CODE_FMT.format(elem=elem))\n            ret.args = [ast.Name(str(elem), ast.Load())]  # type: ignore  # str for py2\n            return ret\n\n        def _parts(ops: list[tuple[bool, str]]) -> list[ast.AST]:\n            parts = [\n                _convert(elem) if is_dynamic else ast.Constant(elem)\n                for is_dynamic, elem in ops\n            ]\n            parts = parts or [ast.Constant(\"\")]\n            # constant fold\n            ret = [parts[0]]\n            for p in parts[1:]:\n                if isinstance(p, ast.Constant) and isinstance(ret[-1], ast.Constant):\n                    ret[-1] = ast.Constant(ret[-1].value + p.value)\n                else:\n                    ret.append(p)\n            return ret\n\n        dom_parts = _parts(dom_ops)\n        url_parts = _parts(url_ops)\n        if not append_unknown:\n            body = []\n        else:\n            body = [_IF_KWARGS_URL_ENCODE_AST]\n            url_parts.extend(_URL_ENCODE_AST_NAMES)\n\n        def _join(parts: list[ast.AST]) -> ast.AST:\n            if len(parts) == 1:  # shortcut\n                return parts[0]\n            return ast.JoinedStr(parts)\n\n        body.append(\n            ast.Return(ast.Tuple([_join(dom_parts), _join(url_parts)], ast.Load()))\n        )\n\n        pargs = [\n            elem\n            for is_dynamic, elem in dom_ops + url_ops\n            if is_dynamic and elem not in defaults\n        ]\n        kargs = [str(k) for k in defaults]\n\n        func_ast: ast.FunctionDef = _prefix_names(\"def _(): pass\")  # type: ignore\n        func_ast.name = f\"<builder:{self.rule!r}>\"\n        func_ast.args.args.append(ast.arg(\".self\", None))\n        for arg in pargs + kargs:\n            func_ast.args.args.append(ast.arg(arg, None))\n        func_ast.args.kwarg = ast.arg(\".kwargs\", None)\n        for _ in kargs:\n            func_ast.args.defaults.append(ast.Constant(\"\"))\n        func_ast.body = body\n\n        # Use `ast.parse` instead of `ast.Module` for better portability, since the\n        # signature of `ast.Module` can change.\n        module = ast.parse(\"\")\n        module.body = [func_ast]\n\n        # mark everything as on line 1, offset 0\n        # less error-prone than `ast.fix_missing_locations`\n        # bad line numbers cause an assert to fail in debug builds\n        for node in ast.walk(module):\n            if \"lineno\" in node._attributes:\n                node.lineno = 1\n            if \"end_lineno\" in node._attributes:\n                node.end_lineno = node.lineno\n            if \"col_offset\" in node._attributes:\n                node.col_offset = 0\n            if \"end_col_offset\" in node._attributes:\n                node.end_col_offset = node.col_offset\n\n        code = compile(module, \"<werkzeug routing>\", \"exec\")\n        return self._get_func_code(code, func_ast.name)\n\n    def build(\n        self, values: t.Mapping[str, t.Any], append_unknown: bool = True\n    ) -> tuple[str, str] | None:\n        \"\"\"Assembles the relative url for that rule and the subdomain.\n        If building doesn't work for some reasons `None` is returned.\n\n        :internal:\n        \"\"\"\n        try:\n            if append_unknown:\n                return self._build_unknown(**values)\n            else:\n                return self._build(**values)\n        except ValidationError:\n            return None\n\n    def provides_defaults_for(self, rule: Rule) -> bool:\n        \"\"\"Check if this rule has defaults for a given rule.\n\n        :internal:\n        \"\"\"\n        return bool(\n            not self.build_only\n            and self.defaults\n            and self.endpoint == rule.endpoint\n            and self != rule\n            and self.arguments == rule.arguments\n        )\n\n    def suitable_for(\n        self, values: t.Mapping[str, t.Any], method: str | None = None\n    ) -> bool:\n        \"\"\"Check if the dict of values has enough data for url generation.\n\n        :internal:\n        \"\"\"\n        # if a method was given explicitly and that method is not supported\n        # by this rule, this rule is not suitable.\n        if (\n            method is not None\n            and self.methods is not None\n            and method not in self.methods\n        ):\n            return False\n\n        defaults = self.defaults or ()\n\n        # all arguments required must be either in the defaults dict or\n        # the value dictionary otherwise it's not suitable\n        for key in self.arguments:\n            if key not in defaults and key not in values:\n                return False\n\n        # in case defaults are given we ensure that either the value was\n        # skipped or the value is the same as the default value.\n        if defaults:\n            for key, value in defaults.items():\n                if key in values and value != values[key]:\n                    return False\n\n        return True\n\n    def build_compare_key(self) -> tuple[int, int, int]:\n        \"\"\"The build compare key for sorting.\n\n        :internal:\n        \"\"\"\n        return (1 if self.alias else 0, -len(self.arguments), -len(self.defaults or ()))\n\n    def __eq__(self, other: object) -> bool:\n        return isinstance(other, type(self)) and self._trace == other._trace\n\n    __hash__ = None  # type: ignore\n\n    def __str__(self) -> str:\n        return self.rule\n\n    def __repr__(self) -> str:\n        if self.map is None:\n            return f\"<{type(self).__name__} (unbound)>\"\n        parts = []\n        for is_dynamic, data in self._trace:\n            if is_dynamic:\n                parts.append(f\"<{data}>\")\n            else:\n                parts.append(data)\n        parts_str = \"\".join(parts).lstrip(\"|\")\n        methods = f\" ({', '.join(self.methods)})\" if self.methods is not None else \"\"\n        return f\"<{type(self).__name__} {parts_str!r}{methods} -> {self.endpoint}>\"\n", "src/werkzeug/routing/converters.py": "from __future__ import annotations\n\nimport re\nimport typing as t\nimport uuid\nfrom urllib.parse import quote\n\nif t.TYPE_CHECKING:\n    from .map import Map\n\n\nclass ValidationError(ValueError):\n    \"\"\"Validation error.  If a rule converter raises this exception the rule\n    does not match the current URL and the next URL is tried.\n    \"\"\"\n\n\nclass BaseConverter:\n    \"\"\"Base class for all converters.\n\n    .. versionchanged:: 2.3\n        ``part_isolating`` defaults to ``False`` if ``regex`` contains a ``/``.\n    \"\"\"\n\n    regex = \"[^/]+\"\n    weight = 100\n    part_isolating = True\n\n    def __init_subclass__(cls, **kwargs: t.Any) -> None:\n        super().__init_subclass__(**kwargs)\n\n        # If the converter isn't inheriting its regex, disable part_isolating by default\n        # if the regex contains a / character.\n        if \"regex\" in cls.__dict__ and \"part_isolating\" not in cls.__dict__:\n            cls.part_isolating = \"/\" not in cls.regex\n\n    def __init__(self, map: Map, *args: t.Any, **kwargs: t.Any) -> None:\n        self.map = map\n\n    def to_python(self, value: str) -> t.Any:\n        return value\n\n    def to_url(self, value: t.Any) -> str:\n        # safe = https://url.spec.whatwg.org/#url-path-segment-string\n        return quote(str(value), safe=\"!$&'()*+,/:;=@\")\n\n\nclass UnicodeConverter(BaseConverter):\n    \"\"\"This converter is the default converter and accepts any string but\n    only one path segment.  Thus the string can not include a slash.\n\n    This is the default validator.\n\n    Example::\n\n        Rule('/pages/<page>'),\n        Rule('/<string(length=2):lang_code>')\n\n    :param map: the :class:`Map`.\n    :param minlength: the minimum length of the string.  Must be greater\n                      or equal 1.\n    :param maxlength: the maximum length of the string.\n    :param length: the exact length of the string.\n    \"\"\"\n\n    def __init__(\n        self,\n        map: Map,\n        minlength: int = 1,\n        maxlength: int | None = None,\n        length: int | None = None,\n    ) -> None:\n        super().__init__(map)\n        if length is not None:\n            length_regex = f\"{{{int(length)}}}\"\n        else:\n            if maxlength is None:\n                maxlength_value = \"\"\n            else:\n                maxlength_value = str(int(maxlength))\n            length_regex = f\"{{{int(minlength)},{maxlength_value}}}\"\n        self.regex = f\"[^/]{length_regex}\"\n\n\nclass AnyConverter(BaseConverter):\n    \"\"\"Matches one of the items provided.  Items can either be Python\n    identifiers or strings::\n\n        Rule('/<any(about, help, imprint, class, \"foo,bar\"):page_name>')\n\n    :param map: the :class:`Map`.\n    :param items: this function accepts the possible items as positional\n                  arguments.\n\n    .. versionchanged:: 2.2\n        Value is validated when building a URL.\n    \"\"\"\n\n    def __init__(self, map: Map, *items: str) -> None:\n        super().__init__(map)\n        self.items = set(items)\n        self.regex = f\"(?:{'|'.join([re.escape(x) for x in items])})\"\n\n    def to_url(self, value: t.Any) -> str:\n        if value in self.items:\n            return str(value)\n\n        valid_values = \", \".join(f\"'{item}'\" for item in sorted(self.items))\n        raise ValueError(f\"'{value}' is not one of {valid_values}\")\n\n\nclass PathConverter(BaseConverter):\n    \"\"\"Like the default :class:`UnicodeConverter`, but it also matches\n    slashes.  This is useful for wikis and similar applications::\n\n        Rule('/<path:wikipage>')\n        Rule('/<path:wikipage>/edit')\n\n    :param map: the :class:`Map`.\n    \"\"\"\n\n    part_isolating = False\n    regex = \"[^/].*?\"\n    weight = 200\n\n\nclass NumberConverter(BaseConverter):\n    \"\"\"Baseclass for `IntegerConverter` and `FloatConverter`.\n\n    :internal:\n    \"\"\"\n\n    weight = 50\n    num_convert: t.Callable[[t.Any], t.Any] = int\n\n    def __init__(\n        self,\n        map: Map,\n        fixed_digits: int = 0,\n        min: int | None = None,\n        max: int | None = None,\n        signed: bool = False,\n    ) -> None:\n        if signed:\n            self.regex = self.signed_regex\n        super().__init__(map)\n        self.fixed_digits = fixed_digits\n        self.min = min\n        self.max = max\n        self.signed = signed\n\n    def to_python(self, value: str) -> t.Any:\n        if self.fixed_digits and len(value) != self.fixed_digits:\n            raise ValidationError()\n        value_num = self.num_convert(value)\n        if (self.min is not None and value_num < self.min) or (\n            self.max is not None and value_num > self.max\n        ):\n            raise ValidationError()\n        return value_num\n\n    def to_url(self, value: t.Any) -> str:\n        value_str = str(self.num_convert(value))\n        if self.fixed_digits:\n            value_str = value_str.zfill(self.fixed_digits)\n        return value_str\n\n    @property\n    def signed_regex(self) -> str:\n        return f\"-?{self.regex}\"\n\n\nclass IntegerConverter(NumberConverter):\n    \"\"\"This converter only accepts integer values::\n\n        Rule(\"/page/<int:page>\")\n\n    By default it only accepts unsigned, positive values. The ``signed``\n    parameter will enable signed, negative values. ::\n\n        Rule(\"/page/<int(signed=True):page>\")\n\n    :param map: The :class:`Map`.\n    :param fixed_digits: The number of fixed digits in the URL. If you\n        set this to ``4`` for example, the rule will only match if the\n        URL looks like ``/0001/``. The default is variable length.\n    :param min: The minimal value.\n    :param max: The maximal value.\n    :param signed: Allow signed (negative) values.\n\n    .. versionadded:: 0.15\n        The ``signed`` parameter.\n    \"\"\"\n\n    regex = r\"\\d+\"\n\n\nclass FloatConverter(NumberConverter):\n    \"\"\"This converter only accepts floating point values::\n\n        Rule(\"/probability/<float:probability>\")\n\n    By default it only accepts unsigned, positive values. The ``signed``\n    parameter will enable signed, negative values. ::\n\n        Rule(\"/offset/<float(signed=True):offset>\")\n\n    :param map: The :class:`Map`.\n    :param min: The minimal value.\n    :param max: The maximal value.\n    :param signed: Allow signed (negative) values.\n\n    .. versionadded:: 0.15\n        The ``signed`` parameter.\n    \"\"\"\n\n    regex = r\"\\d+\\.\\d+\"\n    num_convert = float\n\n    def __init__(\n        self,\n        map: Map,\n        min: float | None = None,\n        max: float | None = None,\n        signed: bool = False,\n    ) -> None:\n        super().__init__(map, min=min, max=max, signed=signed)  # type: ignore\n\n\nclass UUIDConverter(BaseConverter):\n    \"\"\"This converter only accepts UUID strings::\n\n        Rule('/object/<uuid:identifier>')\n\n    .. versionadded:: 0.10\n\n    :param map: the :class:`Map`.\n    \"\"\"\n\n    regex = (\n        r\"[A-Fa-f0-9]{8}-[A-Fa-f0-9]{4}-\"\n        r\"[A-Fa-f0-9]{4}-[A-Fa-f0-9]{4}-[A-Fa-f0-9]{12}\"\n    )\n\n    def to_python(self, value: str) -> uuid.UUID:\n        return uuid.UUID(value)\n\n    def to_url(self, value: uuid.UUID) -> str:\n        return str(value)\n\n\n#: the default converter mapping for the map.\nDEFAULT_CONVERTERS: t.Mapping[str, type[BaseConverter]] = {\n    \"default\": UnicodeConverter,\n    \"string\": UnicodeConverter,\n    \"any\": AnyConverter,\n    \"path\": PathConverter,\n    \"int\": IntegerConverter,\n    \"float\": FloatConverter,\n    \"uuid\": UUIDConverter,\n}\n", "src/werkzeug/routing/matcher.py": "from __future__ import annotations\n\nimport re\nimport typing as t\nfrom dataclasses import dataclass\nfrom dataclasses import field\n\nfrom .converters import ValidationError\nfrom .exceptions import NoMatch\nfrom .exceptions import RequestAliasRedirect\nfrom .exceptions import RequestPath\nfrom .rules import Rule\nfrom .rules import RulePart\n\n\nclass SlashRequired(Exception):\n    pass\n\n\n@dataclass\nclass State:\n    \"\"\"A representation of a rule state.\n\n    This includes the *rules* that correspond to the state and the\n    possible *static* and *dynamic* transitions to the next state.\n    \"\"\"\n\n    dynamic: list[tuple[RulePart, State]] = field(default_factory=list)\n    rules: list[Rule] = field(default_factory=list)\n    static: dict[str, State] = field(default_factory=dict)\n\n\nclass StateMachineMatcher:\n    def __init__(self, merge_slashes: bool) -> None:\n        self._root = State()\n        self.merge_slashes = merge_slashes\n\n    def add(self, rule: Rule) -> None:\n        state = self._root\n        for part in rule._parts:\n            if part.static:\n                state.static.setdefault(part.content, State())\n                state = state.static[part.content]\n            else:\n                for test_part, new_state in state.dynamic:\n                    if test_part == part:\n                        state = new_state\n                        break\n                else:\n                    new_state = State()\n                    state.dynamic.append((part, new_state))\n                    state = new_state\n        state.rules.append(rule)\n\n    def update(self) -> None:\n        # For every state the dynamic transitions should be sorted by\n        # the weight of the transition\n        state = self._root\n\n        def _update_state(state: State) -> None:\n            state.dynamic.sort(key=lambda entry: entry[0].weight)\n            for new_state in state.static.values():\n                _update_state(new_state)\n            for _, new_state in state.dynamic:\n                _update_state(new_state)\n\n        _update_state(state)\n\n    def match(\n        self, domain: str, path: str, method: str, websocket: bool\n    ) -> tuple[Rule, t.MutableMapping[str, t.Any]]:\n        # To match to a rule we need to start at the root state and\n        # try to follow the transitions until we find a match, or find\n        # there is no transition to follow.\n\n        have_match_for = set()\n        websocket_mismatch = False\n\n        def _match(\n            state: State, parts: list[str], values: list[str]\n        ) -> tuple[Rule, list[str]] | None:\n            # This function is meant to be called recursively, and will attempt\n            # to match the head part to the state's transitions.\n            nonlocal have_match_for, websocket_mismatch\n\n            # The base case is when all parts have been matched via\n            # transitions. Hence if there is a rule with methods &\n            # websocket that work return it and the dynamic values\n            # extracted.\n            if parts == []:\n                for rule in state.rules:\n                    if rule.methods is not None and method not in rule.methods:\n                        have_match_for.update(rule.methods)\n                    elif rule.websocket != websocket:\n                        websocket_mismatch = True\n                    else:\n                        return rule, values\n\n                # Test if there is a match with this path with a\n                # trailing slash, if so raise an exception to report\n                # that matching is possible with an additional slash\n                if \"\" in state.static:\n                    for rule in state.static[\"\"].rules:\n                        if websocket == rule.websocket and (\n                            rule.methods is None or method in rule.methods\n                        ):\n                            if rule.strict_slashes:\n                                raise SlashRequired()\n                            else:\n                                return rule, values\n                return None\n\n            part = parts[0]\n            # To match this part try the static transitions first\n            if part in state.static:\n                rv = _match(state.static[part], parts[1:], values)\n                if rv is not None:\n                    return rv\n            # No match via the static transitions, so try the dynamic\n            # ones.\n            for test_part, new_state in state.dynamic:\n                target = part\n                remaining = parts[1:]\n                # A final part indicates a transition that always\n                # consumes the remaining parts i.e. transitions to a\n                # final state.\n                if test_part.final:\n                    target = \"/\".join(parts)\n                    remaining = []\n                match = re.compile(test_part.content).match(target)\n                if match is not None:\n                    if test_part.suffixed:\n                        # If a part_isolating=False part has a slash suffix, remove the\n                        # suffix from the match and check for the slash redirect next.\n                        suffix = match.groups()[-1]\n                        if suffix == \"/\":\n                            remaining = [\"\"]\n\n                    converter_groups = sorted(\n                        match.groupdict().items(), key=lambda entry: entry[0]\n                    )\n                    groups = [\n                        value\n                        for key, value in converter_groups\n                        if key[:11] == \"__werkzeug_\"\n                    ]\n                    rv = _match(new_state, remaining, values + groups)\n                    if rv is not None:\n                        return rv\n\n            # If there is no match and the only part left is a\n            # trailing slash (\"\") consider rules that aren't\n            # strict-slashes as these should match if there is a final\n            # slash part.\n            if parts == [\"\"]:\n                for rule in state.rules:\n                    if rule.strict_slashes:\n                        continue\n                    if rule.methods is not None and method not in rule.methods:\n                        have_match_for.update(rule.methods)\n                    elif rule.websocket != websocket:\n                        websocket_mismatch = True\n                    else:\n                        return rule, values\n\n            return None\n\n        try:\n            rv = _match(self._root, [domain, *path.split(\"/\")], [])\n        except SlashRequired:\n            raise RequestPath(f\"{path}/\") from None\n\n        if self.merge_slashes and rv is None:\n            # Try to match again, but with slashes merged\n            path = re.sub(\"/{2,}?\", \"/\", path)\n            try:\n                rv = _match(self._root, [domain, *path.split(\"/\")], [])\n            except SlashRequired:\n                raise RequestPath(f\"{path}/\") from None\n            if rv is None or rv[0].merge_slashes is False:\n                raise NoMatch(have_match_for, websocket_mismatch)\n            else:\n                raise RequestPath(f\"{path}\")\n        elif rv is not None:\n            rule, values = rv\n\n            result = {}\n            for name, value in zip(rule._converters.keys(), values):\n                try:\n                    value = rule._converters[name].to_python(value)\n                except ValidationError:\n                    raise NoMatch(have_match_for, websocket_mismatch) from None\n                result[str(name)] = value\n            if rule.defaults:\n                result.update(rule.defaults)\n\n            if rule.alias and rule.map.redirect_defaults:\n                raise RequestAliasRedirect(result, rule.endpoint)\n\n            return rule, result\n\n        raise NoMatch(have_match_for, websocket_mismatch)\n", "src/werkzeug/routing/__init__.py": "\"\"\"When it comes to combining multiple controller or view functions\n(however you want to call them) you need a dispatcher. A simple way\nwould be applying regular expression tests on the ``PATH_INFO`` and\ncalling registered callback functions that return the value then.\n\nThis module implements a much more powerful system than simple regular\nexpression matching because it can also convert values in the URLs and\nbuild URLs.\n\nHere a simple example that creates a URL map for an application with\ntwo subdomains (www and kb) and some URL rules:\n\n.. code-block:: python\n\n    m = Map([\n        # Static URLs\n        Rule('/', endpoint='static/index'),\n        Rule('/about', endpoint='static/about'),\n        Rule('/help', endpoint='static/help'),\n        # Knowledge Base\n        Subdomain('kb', [\n            Rule('/', endpoint='kb/index'),\n            Rule('/browse/', endpoint='kb/browse'),\n            Rule('/browse/<int:id>/', endpoint='kb/browse'),\n            Rule('/browse/<int:id>/<int:page>', endpoint='kb/browse')\n        ])\n    ], default_subdomain='www')\n\nIf the application doesn't use subdomains it's perfectly fine to not set\nthe default subdomain and not use the `Subdomain` rule factory. The\nendpoint in the rules can be anything, for example import paths or\nunique identifiers. The WSGI application can use those endpoints to get the\nhandler for that URL.  It doesn't have to be a string at all but it's\nrecommended.\n\nNow it's possible to create a URL adapter for one of the subdomains and\nbuild URLs:\n\n.. code-block:: python\n\n    c = m.bind('example.com')\n\n    c.build(\"kb/browse\", dict(id=42))\n    'http://kb.example.com/browse/42/'\n\n    c.build(\"kb/browse\", dict())\n    'http://kb.example.com/browse/'\n\n    c.build(\"kb/browse\", dict(id=42, page=3))\n    'http://kb.example.com/browse/42/3'\n\n    c.build(\"static/about\")\n    '/about'\n\n    c.build(\"static/index\", force_external=True)\n    'http://www.example.com/'\n\n    c = m.bind('example.com', subdomain='kb')\n\n    c.build(\"static/about\")\n    'http://www.example.com/about'\n\nThe first argument to bind is the server name *without* the subdomain.\nPer default it will assume that the script is mounted on the root, but\noften that's not the case so you can provide the real mount point as\nsecond argument:\n\n.. code-block:: python\n\n    c = m.bind('example.com', '/applications/example')\n\nThe third argument can be the subdomain, if not given the default\nsubdomain is used.  For more details about binding have a look at the\ndocumentation of the `MapAdapter`.\n\nAnd here is how you can match URLs:\n\n.. code-block:: python\n\n    c = m.bind('example.com')\n\n    c.match(\"/\")\n    ('static/index', {})\n\n    c.match(\"/about\")\n    ('static/about', {})\n\n    c = m.bind('example.com', '/', 'kb')\n\n    c.match(\"/\")\n    ('kb/index', {})\n\n    c.match(\"/browse/42/23\")\n    ('kb/browse', {'id': 42, 'page': 23})\n\nIf matching fails you get a ``NotFound`` exception, if the rule thinks\nit's a good idea to redirect (for example because the URL was defined\nto have a slash at the end but the request was missing that slash) it\nwill raise a ``RequestRedirect`` exception. Both are subclasses of\n``HTTPException`` so you can use those errors as responses in the\napplication.\n\nIf matching succeeded but the URL rule was incompatible to the given\nmethod (for example there were only rules for ``GET`` and ``HEAD`` but\nrouting tried to match a ``POST`` request) a ``MethodNotAllowed``\nexception is raised.\n\"\"\"\n\nfrom .converters import AnyConverter as AnyConverter\nfrom .converters import BaseConverter as BaseConverter\nfrom .converters import FloatConverter as FloatConverter\nfrom .converters import IntegerConverter as IntegerConverter\nfrom .converters import PathConverter as PathConverter\nfrom .converters import UnicodeConverter as UnicodeConverter\nfrom .converters import UUIDConverter as UUIDConverter\nfrom .converters import ValidationError as ValidationError\nfrom .exceptions import BuildError as BuildError\nfrom .exceptions import NoMatch as NoMatch\nfrom .exceptions import RequestAliasRedirect as RequestAliasRedirect\nfrom .exceptions import RequestPath as RequestPath\nfrom .exceptions import RequestRedirect as RequestRedirect\nfrom .exceptions import RoutingException as RoutingException\nfrom .exceptions import WebsocketMismatch as WebsocketMismatch\nfrom .map import Map as Map\nfrom .map import MapAdapter as MapAdapter\nfrom .matcher import StateMachineMatcher as StateMachineMatcher\nfrom .rules import EndpointPrefix as EndpointPrefix\nfrom .rules import parse_converter_args as parse_converter_args\nfrom .rules import Rule as Rule\nfrom .rules import RuleFactory as RuleFactory\nfrom .rules import RuleTemplate as RuleTemplate\nfrom .rules import RuleTemplateFactory as RuleTemplateFactory\nfrom .rules import Subdomain as Subdomain\nfrom .rules import Submount as Submount\n", "examples/manage-coolmagic.py": "import click\nfrom werkzeug.serving import run_simple\n\nfrom coolmagic import make_app\n\n\n@click.group()\ndef cli():\n    pass\n\n\n@cli.command()\n@click.option(\"-h\", \"--hostname\", type=str, default=\"localhost\", help=\"localhost\")\n@click.option(\"-p\", \"--port\", type=int, default=5000, help=\"5000\")\n@click.option(\"--no-reloader\", is_flag=True, default=False)\n@click.option(\"--debugger\", is_flag=True)\n@click.option(\"--no-evalex\", is_flag=True, default=False)\n@click.option(\"--threaded\", is_flag=True)\n@click.option(\"--processes\", type=int, default=1, help=\"1\")\ndef runserver(hostname, port, no_reloader, debugger, no_evalex, threaded, processes):\n    \"\"\"Start a new development server.\"\"\"\n    app = make_app()\n    reloader = not no_reloader\n    evalex = not no_evalex\n    run_simple(\n        hostname,\n        port,\n        app,\n        use_reloader=reloader,\n        use_debugger=debugger,\n        use_evalex=evalex,\n        threaded=threaded,\n        processes=processes,\n    )\n\n\n@cli.command()\n@click.option(\"--no-ipython\", is_flag=True, default=False)\ndef shell(no_ipython):\n    \"\"\"Start a new interactive python session.\"\"\"\n    banner = \"Interactive Werkzeug Shell\"\n    namespace = dict()\n    if not no_ipython:\n        try:\n            try:\n                from IPython.frontend.terminal.embed import InteractiveShellEmbed\n\n                sh = InteractiveShellEmbed.instance(banner1=banner)\n            except ImportError:\n                from IPython.Shell import IPShellEmbed\n\n                sh = IPShellEmbed(banner=banner)\n        except ImportError:\n            pass\n        else:\n            sh(local_ns=namespace)\n            return\n    from code import interact\n\n    interact(banner, local=namespace)\n\n\nif __name__ == \"__main__\":\n    cli()\n", "examples/manage-cupoftee.py": "\"\"\"\n    Manage Cup Of Tee\n    ~~~~~~~~~~~~~~~~~\n\n    Manage the cup of tee application.\n\n    :copyright: 2007 Pallets\n    :license: BSD-3-Clause\n\"\"\"\nimport click\nfrom werkzeug.serving import run_simple\n\n\ndef make_app():\n    from cupoftee import make_app\n\n    return make_app(\"/tmp/cupoftee.db\")\n\n\n@click.group()\ndef cli():\n    pass\n\n\n@cli.command()\n@click.option(\"-h\", \"--hostname\", type=str, default=\"localhost\", help=\"localhost\")\n@click.option(\"-p\", \"--port\", type=int, default=5000, help=\"5000\")\n@click.option(\"--reloader\", is_flag=True, default=False)\n@click.option(\"--debugger\", is_flag=True)\n@click.option(\"--evalex\", is_flag=True, default=False)\n@click.option(\"--threaded\", is_flag=True)\n@click.option(\"--processes\", type=int, default=1, help=\"1\")\ndef runserver(hostname, port, reloader, debugger, evalex, threaded, processes):\n    \"\"\"Start a new development server.\"\"\"\n    app = make_app()\n    run_simple(\n        hostname,\n        port,\n        app,\n        use_reloader=reloader,\n        use_debugger=debugger,\n        use_evalex=evalex,\n        threaded=threaded,\n        processes=processes,\n    )\n\n\nif __name__ == \"__main__\":\n    cli()\n", "examples/upload.py": "\"\"\"All uploaded files are directly send back to the client.\"\"\"\nfrom werkzeug.serving import run_simple\nfrom werkzeug.wrappers import Request\nfrom werkzeug.wrappers import Response\nfrom werkzeug.wsgi import wrap_file\n\n\ndef view_file(req):\n    if \"uploaded_file\" not in req.files:\n        return Response(\"no file uploaded\")\n    f = req.files[\"uploaded_file\"]\n    return Response(\n        wrap_file(req.environ, f), mimetype=f.content_type, direct_passthrough=True\n    )\n\n\ndef upload_file(req):\n    return Response(\n        \"\"\"<h1>Upload File</h1>\n        <form action=\"\" method=\"post\" enctype=\"multipart/form-data\">\n            <input type=\"file\" name=\"uploaded_file\">\n            <input type=\"submit\" value=\"Upload\">\n        </form>\"\"\",\n        mimetype=\"text/html\",\n    )\n\n\ndef application(environ, start_response):\n    req = Request(environ)\n    if req.method == \"POST\":\n        resp = view_file(req)\n    else:\n        resp = upload_file(req)\n    return resp(environ, start_response)\n\n\nif __name__ == \"__main__\":\n    run_simple(\"localhost\", 5000, application, use_debugger=True)\n", "examples/httpbasicauth.py": "\"\"\"Shows how you can implement HTTP basic auth support without an\nadditional component.\n\"\"\"\nfrom werkzeug.serving import run_simple\nfrom werkzeug.wrappers import Request\nfrom werkzeug.wrappers import Response\n\n\nclass Application:\n    def __init__(self, users, realm=\"login required\"):\n        self.users = users\n        self.realm = realm\n\n    def check_auth(self, username, password):\n        return username in self.users and self.users[username] == password\n\n    def auth_required(self, request):\n        return Response(\n            \"Could not verify your access level for that URL.\\n\"\n            \"You have to login with proper credentials\",\n            401,\n            {\"WWW-Authenticate\": f'Basic realm=\"{self.realm}\"'},\n        )\n\n    def dispatch_request(self, request):\n        return Response(f\"Logged in as {request.authorization.username}\")\n\n    def __call__(self, environ, start_response):\n        request = Request(environ)\n        auth = request.authorization\n        if not auth or not self.check_auth(auth.username, auth.password):\n            response = self.auth_required(request)\n        else:\n            response = self.dispatch_request(request)\n        return response(environ, start_response)\n\n\nif __name__ == \"__main__\":\n    application = Application({\"user1\": \"password\", \"user2\": \"password\"})\n    run_simple(\"localhost\", 5000, application)\n", "examples/manage-i18nurls.py": "import click\nfrom werkzeug.serving import run_simple\n\nfrom i18nurls import make_app\n\n\n@click.group()\ndef cli():\n    pass\n\n\n@cli.command()\n@click.option(\"-h\", \"--hostname\", type=str, default=\"localhost\", help=\"localhost\")\n@click.option(\"-p\", \"--port\", type=int, default=5000, help=\"5000\")\n@click.option(\"--no-reloader\", is_flag=True, default=False)\n@click.option(\"--debugger\", is_flag=True)\n@click.option(\"--no-evalex\", is_flag=True, default=False)\n@click.option(\"--threaded\", is_flag=True)\n@click.option(\"--processes\", type=int, default=1, help=\"1\")\ndef runserver(hostname, port, no_reloader, debugger, no_evalex, threaded, processes):\n    \"\"\"Start a new development server.\"\"\"\n    app = make_app()\n    reloader = not no_reloader\n    evalex = not no_evalex\n    run_simple(\n        hostname,\n        port,\n        app,\n        use_reloader=reloader,\n        use_debugger=debugger,\n        use_evalex=evalex,\n        threaded=threaded,\n        processes=processes,\n    )\n\n\n@cli.command()\n@click.option(\"--no-ipython\", is_flag=True, default=False)\ndef shell(no_ipython):\n    \"\"\"Start a new interactive python session.\"\"\"\n    banner = \"Interactive Werkzeug Shell\"\n    namespace = dict()\n    if not no_ipython:\n        try:\n            try:\n                from IPython.frontend.terminal.embed import InteractiveShellEmbed\n\n                sh = InteractiveShellEmbed.instance(banner1=banner)\n            except ImportError:\n                from IPython.Shell import IPShellEmbed\n\n                sh = IPShellEmbed(banner=banner)\n        except ImportError:\n            pass\n        else:\n            sh(local_ns=namespace)\n            return\n    from code import interact\n\n    interact(banner, local=namespace)\n\n\nif __name__ == \"__main__\":\n    cli()\n", "examples/wsecho.py": "\"\"\"Shows how you can implement a simple WebSocket echo server using the\nwsproto library.\n\"\"\"\nfrom werkzeug.exceptions import InternalServerError\nfrom werkzeug.serving import run_simple\nfrom werkzeug.wrappers import Request\nfrom werkzeug.wrappers import Response\nfrom wsproto import ConnectionType\nfrom wsproto import WSConnection\nfrom wsproto.events import AcceptConnection\nfrom wsproto.events import CloseConnection\nfrom wsproto.events import Message\nfrom wsproto.events import Ping\nfrom wsproto.events import Request as WSRequest\nfrom wsproto.events import TextMessage\nfrom wsproto.frame_protocol import CloseReason\n\n\n@Request.application\ndef websocket(request):\n    # The underlying socket must be provided by the server. Gunicorn and\n    # Werkzeug's dev server are known to support this.\n    stream = request.environ.get(\"werkzeug.socket\")\n\n    if stream is None:\n        stream = request.environ.get(\"gunicorn.socket\")\n\n    if stream is None:\n        raise InternalServerError()\n\n    # Initialize the wsproto connection. Need to recreate the request\n    # data that was read by the WSGI server already.\n    ws = WSConnection(ConnectionType.SERVER)\n    in_data = b\"GET %s HTTP/1.1\\r\\n\" % request.path.encode(\"utf8\")\n\n    for header, value in request.headers.items():\n        in_data += f\"{header}: {value}\\r\\n\".encode()\n\n    in_data += b\"\\r\\n\"\n    ws.receive_data(in_data)\n    running = True\n\n    while True:\n        out_data = b\"\"\n\n        for event in ws.events():\n            if isinstance(event, WSRequest):\n                out_data += ws.send(AcceptConnection())\n            elif isinstance(event, CloseConnection):\n                out_data += ws.send(event.response())\n                running = False\n            elif isinstance(event, Ping):\n                out_data += ws.send(event.response())\n            elif isinstance(event, TextMessage):\n                # echo the incoming message back to the client\n                if event.data == \"quit\":\n                    out_data += ws.send(\n                        CloseConnection(CloseReason.NORMAL_CLOSURE, \"bye\")\n                    )\n                    running = False\n                else:\n                    out_data += ws.send(Message(data=event.data))\n\n        if out_data:\n            stream.send(out_data)\n\n        if not running:\n            break\n\n        in_data = stream.recv(4096)\n        ws.receive_data(in_data)\n\n    # The connection will be closed at this point, but WSGI still\n    # requires a response.\n    return Response(\"\", status=204)\n\n\nif __name__ == \"__main__\":\n    run_simple(\"localhost\", 5000, websocket)\n", "examples/manage-plnt.py": "import os\n\nimport click\nfrom werkzeug.serving import run_simple\n\n\ndef make_app():\n    \"\"\"Helper function that creates a plnt app.\"\"\"\n    from plnt import Plnt\n\n    database_uri = os.environ.get(\"PLNT_DATABASE_URI\")\n    app = Plnt(database_uri or \"sqlite:////tmp/plnt.db\")\n    app.bind_to_context()\n    return app\n\n\n@click.group()\ndef cli():\n    pass\n\n\n@cli.command()\ndef initdb():\n    \"\"\"Initialize the database\"\"\"\n    from plnt.database import Blog, session\n\n    make_app().init_database()\n    # and now fill in some python blogs everybody should read (shamelessly\n    # added my own blog too)\n    blogs = [\n        Blog(\n            \"Armin Ronacher\",\n            \"https://lucumr.pocoo.org/\",\n            \"https://lucumr.pocoo.org/feed.atom\",\n        ),\n        Blog(\n            \"Georg Brandl\",\n            \"https://pyside.blogspot.com/\",\n            \"https://pyside.blogspot.com/feeds/posts/default\",\n        ),\n        Blog(\n            \"Ian Bicking\",\n            \"https://blog.ianbicking.org/\",\n            \"https://blog.ianbicking.org/feed/\",\n        ),\n        Blog(\n            \"Amir Salihefendic\",\n            \"http://amix.dk/\",\n            \"https://feeds.feedburner.com/amixdk\",\n        ),\n        Blog(\n            \"Christopher Lenz\",\n            \"https://www.cmlenz.net/blog/\",\n            \"https://www.cmlenz.net/blog/atom.xml\",\n        ),\n        Blog(\n            \"Frederick Lundh\",\n            \"https://effbot.org/\",\n            \"https://effbot.org/rss.xml\",\n        ),\n    ]\n    # okay. got tired here.  if someone feels that they are missing, drop me\n    # a line ;-)\n    for blog in blogs:\n        session.add(blog)\n    session.commit()\n    click.echo(\"Initialized database, now run manage-plnt.py sync to get the posts\")\n\n\n@cli.command()\n@click.option(\"-h\", \"--hostname\", type=str, default=\"localhost\", help=\"localhost\")\n@click.option(\"-p\", \"--port\", type=int, default=5000, help=\"5000\")\n@click.option(\"--no-reloader\", is_flag=True, default=False)\n@click.option(\"--debugger\", is_flag=True)\n@click.option(\"--no-evalex\", is_flag=True, default=False)\n@click.option(\"--threaded\", is_flag=True)\n@click.option(\"--processes\", type=int, default=1, help=\"1\")\ndef runserver(hostname, port, no_reloader, debugger, no_evalex, threaded, processes):\n    \"\"\"Start a new development server.\"\"\"\n    app = make_app()\n    reloader = not no_reloader\n    evalex = not no_evalex\n    run_simple(\n        hostname,\n        port,\n        app,\n        use_reloader=reloader,\n        use_debugger=debugger,\n        use_evalex=evalex,\n        threaded=threaded,\n        processes=processes,\n    )\n\n\n@cli.command()\n@click.option(\"--no-ipython\", is_flag=True, default=False)\ndef shell(no_ipython):\n    \"\"\"Start a new interactive python session.\"\"\"\n    banner = \"Interactive Werkzeug Shell\"\n    namespace = {\"app\": make_app()}\n    if not no_ipython:\n        try:\n            try:\n                from IPython.frontend.terminal.embed import InteractiveShellEmbed\n\n                sh = InteractiveShellEmbed.instance(banner1=banner)\n            except ImportError:\n                from IPython.Shell import IPShellEmbed\n\n                sh = IPShellEmbed(banner=banner)\n        except ImportError:\n            pass\n        else:\n            sh(local_ns=namespace)\n            return\n    from code import interact\n\n    interact(banner, local=namespace)\n\n\n@cli.command()\ndef sync():\n    \"\"\"Sync the blogs in the planet.  Call this from a cronjob.\"\"\"\n    from plnt.sync import sync\n\n    make_app().bind_to_context()\n    sync()\n\n\nif __name__ == \"__main__\":\n    cli()\n", "examples/manage-simplewiki.py": "import os\n\nimport click\nfrom werkzeug.serving import run_simple\n\n\ndef make_wiki():\n    \"\"\"Helper function that creates a new wiki instance.\"\"\"\n    from simplewiki import SimpleWiki\n\n    database_uri = os.environ.get(\"SIMPLEWIKI_DATABASE_URI\")\n    return SimpleWiki(database_uri or \"sqlite:////tmp/simplewiki.db\")\n\n\ndef make_shell():\n    from simplewiki import database\n\n    wiki = make_wiki()\n    wiki.bind_to_context()\n    return {\"wiki\": wiki, \"db\": database}\n\n\n@click.group()\ndef cli():\n    pass\n\n\n@cli.command()\ndef initdb():\n    make_wiki().init_database()\n\n\n@cli.command()\n@click.option(\"-h\", \"--hostname\", type=str, default=\"localhost\", help=\"localhost\")\n@click.option(\"-p\", \"--port\", type=int, default=5000, help=\"5000\")\n@click.option(\"--no-reloader\", is_flag=True, default=False)\n@click.option(\"--debugger\", is_flag=True)\n@click.option(\"--no-evalex\", is_flag=True, default=False)\n@click.option(\"--threaded\", is_flag=True)\n@click.option(\"--processes\", type=int, default=1, help=\"1\")\ndef runserver(hostname, port, no_reloader, debugger, no_evalex, threaded, processes):\n    \"\"\"Start a new development server.\"\"\"\n    app = make_wiki()\n    reloader = not no_reloader\n    evalex = not no_evalex\n    run_simple(\n        hostname,\n        port,\n        app,\n        use_reloader=reloader,\n        use_debugger=debugger,\n        use_evalex=evalex,\n        threaded=threaded,\n        processes=processes,\n    )\n\n\n@cli.command()\n@click.option(\"--no-ipython\", is_flag=True, default=False)\ndef shell(no_ipython):\n    \"\"\"Start a new interactive python session.\"\"\"\n    banner = \"Interactive Werkzeug Shell\"\n    namespace = make_shell()\n    if not no_ipython:\n        try:\n            try:\n                from IPython.frontend.terminal.embed import InteractiveShellEmbed\n\n                sh = InteractiveShellEmbed.instance(banner1=banner)\n            except ImportError:\n                from IPython.Shell import IPShellEmbed\n\n                sh = IPShellEmbed(banner=banner)\n        except ImportError:\n            pass\n        else:\n            sh(local_ns=namespace)\n            return\n    from code import interact\n\n    interact(banner, local=namespace)\n\n\nif __name__ == \"__main__\":\n    cli()\n", "examples/manage-webpylike.py": "import os\nimport sys\n\nimport click\nfrom werkzeug.serving import run_simple\n\nfrom webpylike.example import app\n\nsys.path.append(os.path.join(os.path.dirname(__file__), \"webpylike\"))\n\n\n@click.group()\ndef cli():\n    pass\n\n\n@cli.command()\n@click.option(\"-h\", \"--hostname\", type=str, default=\"localhost\", help=\"localhost\")\n@click.option(\"-p\", \"--port\", type=int, default=5000, help=\"5000\")\n@click.option(\"--no-reloader\", is_flag=True, default=False)\n@click.option(\"--debugger\", is_flag=True)\n@click.option(\"--no-evalex\", is_flag=True, default=False)\n@click.option(\"--threaded\", is_flag=True)\n@click.option(\"--processes\", type=int, default=1, help=\"1\")\ndef runserver(hostname, port, no_reloader, debugger, no_evalex, threaded, processes):\n    \"\"\"Start a new development server.\"\"\"\n    reloader = not no_reloader\n    evalex = not no_evalex\n    run_simple(\n        hostname,\n        port,\n        app,\n        use_reloader=reloader,\n        use_debugger=debugger,\n        use_evalex=evalex,\n        threaded=threaded,\n        processes=processes,\n    )\n\n\n@cli.command()\n@click.option(\"--no-ipython\", is_flag=True, default=False)\ndef shell(no_ipython):\n    \"\"\"Start a new interactive python session.\"\"\"\n    banner = \"Interactive Werkzeug Shell\"\n    namespace = dict()\n    if not no_ipython:\n        try:\n            try:\n                from IPython.frontend.terminal.embed import InteractiveShellEmbed\n\n                sh = InteractiveShellEmbed.instance(banner1=banner)\n            except ImportError:\n                from IPython.Shell import IPShellEmbed\n\n                sh = IPShellEmbed(banner=banner)\n        except ImportError:\n            pass\n        else:\n            sh(local_ns=namespace)\n            return\n    from code import interact\n\n    interact(banner, local=namespace)\n\n\nif __name__ == \"__main__\":\n    cli()\n", "examples/manage-couchy.py": "import click\nfrom werkzeug.serving import run_simple\n\n\ndef make_app():\n    from couchy.application import Couchy\n\n    return Couchy(\"http://localhost:5984\")\n\n\ndef make_shell():\n    from couchy import models, utils\n\n    application = make_app()\n    return {\"application\": application, \"models\": models, \"utils\": utils}\n\n\n@click.group()\ndef cli():\n    pass\n\n\n@cli.command()\ndef initdb():\n    from couchy.application import Couchy\n\n    Couchy(\"http://localhost:5984\").init_database()\n\n\n@cli.command()\n@click.option(\"-h\", \"--hostname\", type=str, default=\"localhost\", help=\"localhost\")\n@click.option(\"-p\", \"--port\", type=int, default=5000, help=\"5000\")\n@click.option(\"--no-reloader\", is_flag=True, default=False)\n@click.option(\"--debugger\", is_flag=True)\n@click.option(\"--no-evalex\", is_flag=True, default=False)\n@click.option(\"--threaded\", is_flag=True)\n@click.option(\"--processes\", type=int, default=1, help=\"1\")\ndef runserver(hostname, port, no_reloader, debugger, no_evalex, threaded, processes):\n    \"\"\"Start a new development server.\"\"\"\n    app = make_app()\n    reloader = not no_reloader\n    evalex = not no_evalex\n    run_simple(\n        hostname,\n        port,\n        app,\n        use_reloader=reloader,\n        use_debugger=debugger,\n        use_evalex=evalex,\n        threaded=threaded,\n        processes=processes,\n    )\n\n\n@cli.command()\n@click.option(\"--no-ipython\", is_flag=True, default=False)\ndef shell(no_ipython):\n    \"\"\"Start a new interactive python session.\"\"\"\n    banner = \"Interactive Werkzeug Shell\"\n    namespace = make_shell()\n    if not no_ipython:\n        try:\n            try:\n                from IPython.frontend.terminal.embed import InteractiveShellEmbed\n\n                sh = InteractiveShellEmbed.instance(banner1=banner)\n            except ImportError:\n                from IPython.Shell import IPShellEmbed\n\n                sh = IPShellEmbed(banner=banner)\n        except ImportError:\n            pass\n        else:\n            sh(local_ns=namespace)\n            return\n    from code import interact\n\n    interact(banner, local=namespace)\n\n\nif __name__ == \"__main__\":\n    cli()\n", "examples/manage-shorty.py": "import os\nimport tempfile\n\nimport click\nfrom werkzeug.serving import run_simple\n\n\ndef make_app():\n    from shorty.application import Shorty\n\n    filename = os.path.join(tempfile.gettempdir(), \"shorty.db\")\n    return Shorty(f\"sqlite:///{filename}\")\n\n\ndef make_shell():\n    from shorty import models, utils\n\n    application = make_app()\n    return {\"application\": application, \"models\": models, \"utils\": utils}\n\n\n@click.group()\ndef cli():\n    pass\n\n\n@cli.command()\ndef initdb():\n    make_app().init_database()\n\n\n@cli.command()\n@click.option(\"-h\", \"--hostname\", type=str, default=\"localhost\", help=\"localhost\")\n@click.option(\"-p\", \"--port\", type=int, default=5000, help=\"5000\")\n@click.option(\"--no-reloader\", is_flag=True, default=False)\n@click.option(\"--debugger\", is_flag=True)\n@click.option(\"--no-evalex\", is_flag=True, default=False)\n@click.option(\"--threaded\", is_flag=True)\n@click.option(\"--processes\", type=int, default=1, help=\"1\")\ndef runserver(hostname, port, no_reloader, debugger, no_evalex, threaded, processes):\n    \"\"\"Start a new development server.\"\"\"\n    app = make_app()\n    reloader = not no_reloader\n    evalex = not no_evalex\n    run_simple(\n        hostname,\n        port,\n        app,\n        use_reloader=reloader,\n        use_debugger=debugger,\n        use_evalex=evalex,\n        threaded=threaded,\n        processes=processes,\n    )\n\n\n@cli.command()\n@click.option(\"--no-ipython\", is_flag=True, default=False)\ndef shell(no_ipython):\n    \"\"\"Start a new interactive python session.\"\"\"\n    banner = \"Interactive Werkzeug Shell\"\n    namespace = make_shell()\n    if not no_ipython:\n        try:\n            try:\n                from IPython.frontend.terminal.embed import InteractiveShellEmbed\n\n                sh = InteractiveShellEmbed.instance(banner1=banner)\n            except ImportError:\n                from IPython.Shell import IPShellEmbed\n\n                sh = IPShellEmbed(banner=banner)\n        except ImportError:\n            pass\n        else:\n            sh(local_ns=namespace)\n            return\n    from code import interact\n\n    interact(banner, local=namespace)\n\n\nif __name__ == \"__main__\":\n    cli()\n", "examples/shorty/utils.py": "from os import path\nfrom random import randrange\nfrom random import sample\nfrom urllib.parse import urlsplit\n\nfrom jinja2 import Environment\nfrom jinja2 import FileSystemLoader\nfrom sqlalchemy import MetaData\nfrom sqlalchemy.orm import create_session\nfrom sqlalchemy.orm import scoped_session\nfrom werkzeug.local import Local\nfrom werkzeug.local import LocalManager\nfrom werkzeug.routing import Map\nfrom werkzeug.routing import Rule\nfrom werkzeug.utils import cached_property\nfrom werkzeug.wrappers import Response\n\n\nTEMPLATE_PATH = path.join(path.dirname(__file__), \"templates\")\nSTATIC_PATH = path.join(path.dirname(__file__), \"static\")\nALLOWED_SCHEMES = frozenset([\"http\", \"https\", \"ftp\", \"ftps\"])\nURL_CHARS = \"abcdefghijkmpqrstuvwxyzABCDEFGHIJKLMNPQRST23456789\"\n\nlocal = Local()\nlocal_manager = LocalManager([local])\napplication = local(\"application\")\n\nmetadata = MetaData()\nurl_map = Map([Rule(\"/static/<file>\", endpoint=\"static\", build_only=True)])\n\nsession = scoped_session(\n    lambda: create_session(\n        application.database_engine, autocommit=False, autoflush=False\n    )\n)\njinja_env = Environment(loader=FileSystemLoader(TEMPLATE_PATH))\n\n\ndef expose(rule, **kw):\n    def decorate(f):\n        kw[\"endpoint\"] = f.__name__\n        url_map.add(Rule(rule, **kw))\n        return f\n\n    return decorate\n\n\ndef url_for(endpoint, _external=False, **values):\n    return local.url_adapter.build(endpoint, values, force_external=_external)\n\n\njinja_env.globals[\"url_for\"] = url_for\n\n\ndef render_template(template, **context):\n    return Response(\n        jinja_env.get_template(template).render(**context), mimetype=\"text/html\"\n    )\n\n\ndef validate_url(url):\n    return urlsplit(url)[0] in ALLOWED_SCHEMES\n\n\ndef get_random_uid():\n    return \"\".join(sample(URL_CHARS, randrange(3, 9)))\n\n\nclass Pagination:\n    def __init__(self, query, per_page, page, endpoint):\n        self.query = query\n        self.per_page = per_page\n        self.page = page\n        self.endpoint = endpoint\n\n    @cached_property\n    def count(self):\n        return self.query.count()\n\n    @cached_property\n    def entries(self):\n        return (\n            self.query.offset((self.page - 1) * self.per_page)\n            .limit(self.per_page)\n            .all()\n        )\n\n    @property\n    def has_previous(self):\n        \"\"\"Return True if there are pages before the current one.\"\"\"\n        return self.page > 1\n\n    @property\n    def has_next(self):\n        \"\"\"Return True if there are pages after the current one.\"\"\"\n        return self.page < self.pages\n\n    @property\n    def previous(self):\n        \"\"\"Return the URL for the previous page.\"\"\"\n        return url_for(self.endpoint, page=self.page - 1)\n\n    @property\n    def next(self):\n        \"\"\"Return the URL for the next page.\"\"\"\n        return url_for(self.endpoint, page=self.page + 1)\n\n    @property\n    def pages(self):\n        \"\"\"Return the number of pages.\"\"\"\n        return max(0, self.count - 1) // self.per_page + 1\n", "examples/shorty/models.py": "from datetime import datetime\n\nfrom sqlalchemy import Boolean\nfrom sqlalchemy import Column\nfrom sqlalchemy import DateTime\nfrom sqlalchemy import String\nfrom sqlalchemy import Table\nfrom sqlalchemy.orm import mapper\n\nfrom .utils import get_random_uid\nfrom .utils import metadata\nfrom .utils import session\nfrom .utils import url_for\n\nurl_table = Table(\n    \"urls\",\n    metadata,\n    Column(\"uid\", String(140), primary_key=True),\n    Column(\"target\", String(500)),\n    Column(\"added\", DateTime),\n    Column(\"public\", Boolean),\n)\n\n\nclass URL:\n    query = session.query_property()\n\n    def __init__(self, target, public=True, uid=None, added=None):\n        self.target = target\n        self.public = public\n        self.added = added or datetime.utcnow()\n        if not uid:\n            while 1:\n                uid = get_random_uid()\n                if not URL.query.get(uid):\n                    break\n        self.uid = uid\n        session.add(self)\n\n    @property\n    def short_url(self):\n        return url_for(\"link\", uid=self.uid, _external=True)\n\n    def __repr__(self):\n        return f\"<URL {self.uid!r}>\"\n\n\nmapper(URL, url_table)\n", "examples/shorty/views.py": "from werkzeug.exceptions import NotFound\nfrom werkzeug.utils import redirect\n\nfrom .models import URL\nfrom .utils import expose\nfrom .utils import Pagination\nfrom .utils import render_template\nfrom .utils import session\nfrom .utils import url_for\nfrom .utils import validate_url\n\n\n@expose(\"/\")\ndef new(request):\n    error = url = \"\"\n    if request.method == \"POST\":\n        url = request.form.get(\"url\")\n        alias = request.form.get(\"alias\")\n        if not validate_url(url):\n            error = \"I'm sorry but you cannot shorten this URL.\"\n        elif alias:\n            if len(alias) > 140:\n                error = \"Your alias is too long\"\n            elif \"/\" in alias:\n                error = \"Your alias might not include a slash\"\n            elif URL.query.get(alias):\n                error = \"The alias you have requested exists already\"\n        if not error:\n            uid = URL(url, \"private\" not in request.form, alias).uid\n            session.commit()\n            return redirect(url_for(\"display\", uid=uid))\n    return render_template(\"new.html\", error=error, url=url)\n\n\n@expose(\"/display/<uid>\")\ndef display(request, uid):\n    url = URL.query.get(uid)\n    if not url:\n        raise NotFound()\n    return render_template(\"display.html\", url=url)\n\n\n@expose(\"/u/<uid>\")\ndef link(request, uid):\n    url = URL.query.get(uid)\n    if not url:\n        raise NotFound()\n    return redirect(url.target, 301)\n\n\n@expose(\"/list/\", defaults={\"page\": 1})\n@expose(\"/list/<int:page>\")\ndef list(request, page):\n    query = URL.query.filter_by(public=True)\n    pagination = Pagination(query, 30, page, \"list\")\n    if pagination.page > 1 and not pagination.entries:\n        raise NotFound()\n    return render_template(\"list.html\", pagination=pagination)\n\n\ndef not_found(request):\n    return render_template(\"not_found.html\")\n", "examples/shorty/application.py": "from sqlalchemy import create_engine\nfrom werkzeug.exceptions import HTTPException\nfrom werkzeug.exceptions import NotFound\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.wrappers import Request\nfrom werkzeug.wsgi import ClosingIterator\n\nfrom . import views\nfrom .utils import local\nfrom .utils import local_manager\nfrom .utils import metadata\nfrom .utils import session\nfrom .utils import STATIC_PATH\nfrom .utils import url_map\n\n\nclass Shorty:\n    def __init__(self, db_uri):\n        local.application = self\n        self.database_engine = create_engine(db_uri, convert_unicode=True)\n\n        self.dispatch = SharedDataMiddleware(self.dispatch, {\"/static\": STATIC_PATH})\n\n    def init_database(self):\n        metadata.create_all(self.database_engine)\n\n    def dispatch(self, environ, start_response):\n        local.application = self\n        request = Request(environ)\n        local.url_adapter = adapter = url_map.bind_to_environ(environ)\n        try:\n            endpoint, values = adapter.match()\n            handler = getattr(views, endpoint)\n            response = handler(request, **values)\n        except NotFound:\n            response = views.not_found(request)\n            response.status_code = 404\n        except HTTPException as e:\n            response = e\n        return ClosingIterator(\n            response(environ, start_response), [session.remove, local_manager.cleanup]\n        )\n\n    def __call__(self, environ, start_response):\n        return self.dispatch(environ, start_response)\n", "examples/shorty/__init__.py": "", "examples/simplewiki/actions.py": "\"\"\"The per page actions. The actions are defined in the URL with the\n``action`` parameter and directly dispatched to the functions in this\nmodule. In the module the actions are prefixed with '`on_`', so be\ncareful not to name any other objects in the module with the same prefix\nunless you want to act them as actions.\n\"\"\"\nfrom difflib import unified_diff\n\nfrom werkzeug.utils import redirect\n\nfrom .database import Page\nfrom .database import Revision\nfrom .database import RevisionedPage\nfrom .database import session\nfrom .utils import format_datetime\nfrom .utils import generate_template\nfrom .utils import href\nfrom .utils import Response\n\n\ndef on_show(request, page_name):\n    \"\"\"Displays the page the user requests.\"\"\"\n    revision_id = request.args.get(\"rev\", type=int)\n    query = RevisionedPage.query.filter_by(name=page_name)\n    if revision_id:\n        query = query.filter_by(revision_id=revision_id)\n        revision_requested = True\n    else:\n        query = query.order_by(RevisionedPage.revision_id.desc())\n        revision_requested = False\n    page = query.first()\n    if page is None:\n        return page_missing(request, page_name, revision_requested)\n    return Response(generate_template(\"action_show.html\", page=page))\n\n\ndef on_edit(request, page_name):\n    \"\"\"Edit the current revision of a page.\"\"\"\n    change_note = error = \"\"\n    revision = (\n        Revision.query.filter(\n            (Page.name == page_name) & (Page.page_id == Revision.page_id)\n        )\n        .order_by(Revision.revision_id.desc())\n        .first()\n    )\n    if revision is None:\n        page = None\n    else:\n        page = revision.page\n\n    if request.method == \"POST\":\n        text = request.form.get(\"text\")\n        if request.form.get(\"cancel\") or revision and revision.text == text:\n            return redirect(href(page.name))\n        elif not text:\n            error = \"You cannot save empty revisions.\"\n        else:\n            change_note = request.form.get(\"change_note\", \"\")\n            if page is None:\n                page = Page(page_name)\n                session.add(page)\n            session.add(Revision(page, text, change_note))\n            session.commit()\n            return redirect(href(page.name))\n\n    return Response(\n        generate_template(\n            \"action_edit.html\",\n            revision=revision,\n            page=page,\n            new=page is None,\n            page_name=page_name,\n            change_note=change_note,\n            error=error,\n        )\n    )\n\n\ndef on_log(request, page_name):\n    \"\"\"Show the list of recent changes.\"\"\"\n    page = Page.query.filter_by(name=page_name).first()\n    if page is None:\n        return page_missing(request, page_name, False)\n    return Response(generate_template(\"action_log.html\", page=page))\n\n\ndef on_diff(request, page_name):\n    \"\"\"Show the diff between two revisions.\"\"\"\n    old = request.args.get(\"old\", type=int)\n    new = request.args.get(\"new\", type=int)\n    error = \"\"\n    diff = page = old_rev = new_rev = None\n\n    if not (old and new):\n        error = \"No revisions specified.\"\n    else:\n        revisions = {\n            x.revision_id: x\n            for x in Revision.query.filter(\n                (Revision.revision_id.in_((old, new)))\n                & (Revision.page_id == Page.page_id)\n                & (Page.name == page_name)\n            )\n        }\n        if len(revisions) != 2:\n            error = \"At least one of the revisions requested does not exist.\"\n        else:\n            new_rev = revisions[new]\n            old_rev = revisions[old]\n            page = old_rev.page\n            diff = unified_diff(\n                f\"{old_rev.text}\\n\".splitlines(True),\n                f\"{new_rev.text}\\n\".splitlines(True),\n                page.name,\n                page.name,\n                format_datetime(old_rev.timestamp),\n                format_datetime(new_rev.timestamp),\n                3,\n            )\n\n    return Response(\n        generate_template(\n            \"action_diff.html\",\n            error=error,\n            old_revision=old_rev,\n            new_revision=new_rev,\n            page=page,\n            diff=diff,\n        )\n    )\n\n\ndef on_revert(request, page_name):\n    \"\"\"Revert an old revision.\"\"\"\n    rev_id = request.args.get(\"rev\", type=int)\n\n    old_revision = page = None\n    error = \"No such revision\"\n\n    if request.method == \"POST\" and request.form.get(\"cancel\"):\n        return redirect(href(page_name))\n\n    if rev_id:\n        old_revision = Revision.query.filter(\n            (Revision.revision_id == rev_id)\n            & (Revision.page_id == Page.page_id)\n            & (Page.name == page_name)\n        ).first()\n        if old_revision:\n            new_revision = (\n                Revision.query.filter(\n                    (Revision.page_id == Page.page_id) & (Page.name == page_name)\n                )\n                .order_by(Revision.revision_id.desc())\n                .first()\n            )\n            if old_revision == new_revision:\n                error = \"You tried to revert the current active revision.\"\n            elif old_revision.text == new_revision.text:\n                error = (\n                    \"There are no changes between the current \"\n                    \"revision and the revision you want to \"\n                    \"restore.\"\n                )\n            else:\n                error = \"\"\n                page = old_revision.page\n                if request.method == \"POST\":\n                    change_note = request.form.get(\"change_note\", \"\")\n\n                    if change_note:\n                        change_note = f\"revert: {change_note}\"\n                    else:\n                        change_note = \"revert\"\n\n                    session.add(Revision(page, old_revision.text, change_note))\n                    session.commit()\n                    return redirect(href(page_name))\n\n    return Response(\n        generate_template(\n            \"action_revert.html\", error=error, old_revision=old_revision, page=page\n        )\n    )\n\n\ndef page_missing(request, page_name, revision_requested, protected=False):\n    \"\"\"Displayed if page or revision does not exist.\"\"\"\n    return Response(\n        generate_template(\n            \"page_missing.html\",\n            page_name=page_name,\n            revision_requested=revision_requested,\n            protected=protected,\n        ),\n        status=404,\n    )\n\n\ndef missing_action(request, action):\n    \"\"\"Displayed if a user tried to access a action that does not exist.\"\"\"\n    return Response(generate_template(\"missing_action.html\", action=action), status=404)\n", "examples/simplewiki/utils.py": "from os import path\nfrom urllib.parse import quote\nfrom urllib.parse import urlencode\n\nimport creoleparser\nfrom genshi import Stream\nfrom genshi.template import TemplateLoader\nfrom werkzeug.local import Local\nfrom werkzeug.local import LocalManager\nfrom werkzeug.utils import cached_property\nfrom werkzeug.wrappers import Request as BaseRequest\nfrom werkzeug.wrappers import Response as BaseResponse\n\n\n# calculate the path to the templates an create the template loader\nTEMPLATE_PATH = path.join(path.dirname(__file__), \"templates\")\ntemplate_loader = TemplateLoader(\n    TEMPLATE_PATH, auto_reload=True, variable_lookup=\"lenient\"\n)\n\n\n# context locals.  these two objects are use by the application to\n# bind objects to the current context.  A context is defined as the\n# current thread and the current greenlet if there is greenlet support.\nlocal = Local()\nlocal_manager = LocalManager([local])\nrequest = local(\"request\")\napplication = local(\"application\")\n\n# create a new creole parser\ncreole_parser = creoleparser.Parser(\n    dialect=creoleparser.create_dialect(\n        creoleparser.creole10_base,\n        wiki_links_base_url=\"\",\n        wiki_links_path_func=lambda page_name: href(page_name),\n        wiki_links_space_char=\"_\",\n        no_wiki_monospace=True,\n    ),\n    method=\"html\",\n)\n\n\ndef generate_template(template_name, **context):\n    \"\"\"Load and generate a template.\"\"\"\n    context.update(href=href, format_datetime=format_datetime)\n    return template_loader.load(template_name).generate(**context)\n\n\ndef parse_creole(markup):\n    \"\"\"Parse some creole markup and create a genshi stream.\"\"\"\n    return creole_parser.generate(markup)\n\n\ndef href(*args, **kw):\n    \"\"\"\n    Simple function for URL generation.  Position arguments are used for the\n    URL path and keyword arguments are used for the url parameters.\n    \"\"\"\n    result = [f\"{request.script_root if request else ''}/\"]\n    for idx, arg in enumerate(args):\n        result.append(f\"{'/' if idx else ''}{quote(arg)}\")\n    if kw:\n        result.append(f\"?{urlencode(kw)}\")\n    return \"\".join(result)\n\n\ndef format_datetime(obj):\n    \"\"\"Format a datetime object.\"\"\"\n    return obj.strftime(\"%Y-%m-%d %H:%M\")\n\n\nclass Request(BaseRequest):\n    \"\"\"\n    Simple request subclass that allows to bind the object to the\n    current context.\n    \"\"\"\n\n    def bind_to_context(self):\n        local.request = self\n\n\nclass Response(BaseResponse):\n    \"\"\"\n    Encapsulates a WSGI response.  Unlike the default response object werkzeug\n    provides, this accepts a genshi stream and will automatically render it\n    to html.  This makes it possible to switch to xhtml or html5 easily.\n    \"\"\"\n\n    default_mimetype = \"text/html\"\n\n    def __init__(\n        self, response=None, status=200, headers=None, mimetype=None, content_type=None\n    ):\n        if isinstance(response, Stream):\n            response = response.render(\"html\", encoding=None, doctype=\"html\")\n        super().__init__(response, status, headers, mimetype, content_type)\n\n\nclass Pagination:\n    \"\"\"\n    Paginate a SQLAlchemy query object.\n    \"\"\"\n\n    def __init__(self, query, per_page, page, link):\n        self.query = query\n        self.per_page = per_page\n        self.page = page\n        self.link = link\n        self._count = None\n\n    @cached_property\n    def entries(self):\n        return (\n            self.query.offset((self.page - 1) * self.per_page)\n            .limit(self.per_page)\n            .all()\n        )\n\n    @property\n    def has_previous(self):\n        return self.page > 1\n\n    @property\n    def has_next(self):\n        return self.page < self.pages\n\n    @property\n    def previous(self):\n        return href(self.link, page=self.page - 1)\n\n    @property\n    def next(self):\n        return href(self.link, page=self.page + 1)\n\n    @cached_property\n    def count(self):\n        return self.query.count()\n\n    @property\n    def pages(self):\n        return max(0, self.count - 1) // self.per_page + 1\n", "examples/simplewiki/application.py": "\"\"\"Implements the wiki WSGI application which dispatches requests to\nspecific wiki pages and actions.\n\"\"\"\nfrom os import path\n\nfrom sqlalchemy import create_engine\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.utils import redirect\nfrom werkzeug.wsgi import ClosingIterator\n\nfrom . import actions\nfrom .database import metadata\nfrom .database import session\nfrom .specialpages import page_not_found\nfrom .specialpages import pages\nfrom .utils import href\nfrom .utils import local\nfrom .utils import local_manager\nfrom .utils import Request\n\n#: path to shared data\nSHARED_DATA = path.join(path.dirname(__file__), \"shared\")\n\n\nclass SimpleWiki:\n    \"\"\"\n    Our central WSGI application.\n    \"\"\"\n\n    def __init__(self, database_uri):\n        self.database_engine = create_engine(database_uri)\n\n        # apply our middlewares.   we apply the middlewars *inside* the\n        # application and not outside of it so that we never lose the\n        # reference to the `SimpleWiki` object.\n        self._dispatch = SharedDataMiddleware(\n            self.dispatch_request, {\"/_shared\": SHARED_DATA}\n        )\n\n        # free the context locals at the end of the request\n        self._dispatch = local_manager.make_middleware(self._dispatch)\n\n    def init_database(self):\n        \"\"\"Called from the management script to generate the db.\"\"\"\n        metadata.create_all(bind=self.database_engine)\n\n    def bind_to_context(self):\n        \"\"\"\n        Useful for the shell.  Binds the application to the current active\n        context.  It's automatically called by the shell command.\n        \"\"\"\n        local.application = self\n\n    def dispatch_request(self, environ, start_response):\n        \"\"\"Dispatch an incoming request.\"\"\"\n        # set up all the stuff we want to have for this request.  That is\n        # creating a request object, propagating the application to the\n        # current context and instantiating the database session.\n        self.bind_to_context()\n        request = Request(environ)\n        request.bind_to_context()\n\n        # get the current action from the url and normalize the page name\n        # which is just the request path\n        action_name = request.args.get(\"action\") or \"show\"\n        page_name = \"_\".join([x for x in request.path.strip(\"/\").split() if x])\n\n        # redirect to the Main_Page if the user requested the index\n        if not page_name:\n            response = redirect(href(\"Main_Page\"))\n\n        # check special pages\n        elif page_name.startswith(\"Special:\"):\n            if page_name[8:] not in pages:\n                response = page_not_found(request, page_name)\n            else:\n                response = pages[page_name[8:]](request)\n\n        # get the callback function for the requested action from the\n        # action module.  It's \"on_\" + the action name.  If it doesn't\n        # exists call the missing_action method from the same module.\n        else:\n            action = getattr(actions, f\"on_{action_name}\", None)\n            if action is None:\n                response = actions.missing_action(request, action_name)\n            else:\n                response = action(request, page_name)\n\n        # make sure the session is removed properly\n        return ClosingIterator(response(environ, start_response), session.remove)\n\n    def __call__(self, environ, start_response):\n        \"\"\"Just forward a WSGI call to the first internal middleware.\"\"\"\n        return self._dispatch(environ, start_response)\n", "examples/simplewiki/specialpages.py": "\"\"\"Special pages such as the recent changes page.\"\"\"\nfrom .actions import page_missing\nfrom .database import Page\nfrom .database import RevisionedPage\nfrom .utils import generate_template\nfrom .utils import Pagination\nfrom .utils import Response\n\n\ndef page_index(request):\n    \"\"\"Index of all pages.\"\"\"\n    letters = {}\n    for page in Page.query.order_by(Page.name):\n        letters.setdefault(page.name.capitalize()[0], []).append(page)\n    return Response(\n        generate_template(\"page_index.html\", letters=sorted(letters.items()))\n    )\n\n\ndef recent_changes(request):\n    \"\"\"Display the recent changes.\"\"\"\n    page = max(1, request.args.get(\"page\", type=int))\n    query = RevisionedPage.query.order_by(RevisionedPage.revision_id.desc())\n    return Response(\n        generate_template(\n            \"recent_changes.html\",\n            pagination=Pagination(query, 20, page, \"Special:Recent_Changes\"),\n        )\n    )\n\n\ndef page_not_found(request, page_name):\n    \"\"\"\n    Displays an error message if a user tried to access\n    a not existing special page.\n    \"\"\"\n    return page_missing(request, page_name, True)\n\n\npages = {\"Index\": page_index, \"Recent_Changes\": recent_changes}\n", "examples/simplewiki/__init__.py": "\"\"\"Very simple wiki application based on Genshi, Werkzeug and\nSQLAlchemy. Additionally the creoleparser is used for the wiki markup.\n\"\"\"\nfrom .application import SimpleWiki\n", "examples/partial/complex_routing.py": "from werkzeug.routing import EndpointPrefix\nfrom werkzeug.routing import Map\nfrom werkzeug.routing import Rule\nfrom werkzeug.routing import Subdomain\nfrom werkzeug.routing import Submount\n\nm = Map(\n    [\n        # Static URLs\n        EndpointPrefix(\n            \"static/\",\n            [\n                Rule(\"/\", endpoint=\"index\"),\n                Rule(\"/about\", endpoint=\"about\"),\n                Rule(\"/help\", endpoint=\"help\"),\n            ],\n        ),\n        # Knowledge Base\n        Subdomain(\n            \"kb\",\n            [\n                EndpointPrefix(\n                    \"kb/\",\n                    [\n                        Rule(\"/\", endpoint=\"index\"),\n                        Submount(\n                            \"/browse\",\n                            [\n                                Rule(\"/\", endpoint=\"browse\"),\n                                Rule(\n                                    \"/<int:id>/\",\n                                    defaults={\"page\": 1},\n                                    endpoint=\"browse\",\n                                ),\n                                Rule(\"/<int:id>/<int:page>\", endpoint=\"browse\"),\n                            ],\n                        ),\n                    ],\n                )\n            ],\n        ),\n    ]\n)\n", "examples/plnt/utils.py": "import re\nfrom os import path\n\nfrom jinja2 import Environment\nfrom jinja2 import FileSystemLoader\nfrom werkzeug.local import Local\nfrom werkzeug.local import LocalManager\nfrom werkzeug.routing import Map\nfrom werkzeug.routing import Rule\nfrom werkzeug.utils import cached_property\nfrom werkzeug.wrappers import Response\n\n\n# context locals.  these two objects are use by the application to\n# bind objects to the current context.  A context is defined as the\n# current thread and the current greenlet if there is greenlet support.\n# the `get_request` and `get_application` functions look up the request\n# and application objects from this local manager.\nlocal = Local()\nlocal_manager = LocalManager([local])\n\n\n# proxy objects\nrequest = local(\"request\")\napplication = local(\"application\")\nurl_adapter = local(\"url_adapter\")\n\n\n# let's use jinja for templates this time\ntemplate_path = path.join(path.dirname(__file__), \"templates\")\njinja_env = Environment(loader=FileSystemLoader(template_path))\n\n\n# the collected url patterns\nurl_map = Map([Rule(\"/shared/<path:file>\", endpoint=\"shared\")])\nendpoints = {}\n\n\n_par_re = re.compile(r\"\\n{2,}\")\n_entity_re = re.compile(r\"&([^;]+);\")\n_striptags_re = re.compile(r\"(<!--.*-->|<[^>]*>)\")\n\nfrom html.entities import name2codepoint\n\nhtml_entities = name2codepoint.copy()\nhtml_entities[\"apos\"] = 39\ndel name2codepoint\n\n\ndef expose(url_rule, endpoint=None, **kwargs):\n    \"\"\"Expose this function to the web layer.\"\"\"\n\n    def decorate(f):\n        e = endpoint or f.__name__\n        endpoints[e] = f\n        url_map.add(Rule(url_rule, endpoint=e, **kwargs))\n        return f\n\n    return decorate\n\n\ndef render_template(template_name, **context):\n    \"\"\"Render a template into a response.\"\"\"\n    tmpl = jinja_env.get_template(template_name)\n    context[\"url_for\"] = url_for\n    return Response(tmpl.render(context), mimetype=\"text/html\")\n\n\ndef nl2p(s):\n    \"\"\"Add paragraphs to a text.\"\"\"\n    return \"\\n\".join(f\"<p>{p}</p>\" for p in _par_re.split(s))\n\n\ndef url_for(endpoint, **kw):\n    \"\"\"Simple function for URL generation.\"\"\"\n    return url_adapter.build(endpoint, kw)\n\n\ndef strip_tags(s):\n    \"\"\"Resolve HTML entities and remove tags from a string.\"\"\"\n\n    def handle_match(m):\n        name = m.group(1)\n        if name in html_entities:\n            return chr(html_entities[name])\n        if name[:2] in (\"#x\", \"#X\"):\n            try:\n                return chr(int(name[2:], 16))\n            except ValueError:\n                return \"\"\n        elif name.startswith(\"#\"):\n            try:\n                return chr(int(name[1:]))\n            except ValueError:\n                return \"\"\n        return \"\"\n\n    return _entity_re.sub(handle_match, _striptags_re.sub(\"\", s))\n\n\nclass Pagination:\n    \"\"\"\n    Paginate a SQLAlchemy query object.\n    \"\"\"\n\n    def __init__(self, query, per_page, page, endpoint):\n        self.query = query\n        self.per_page = per_page\n        self.page = page\n        self.endpoint = endpoint\n\n    @cached_property\n    def entries(self):\n        return (\n            self.query.offset((self.page - 1) * self.per_page)\n            .limit(self.per_page)\n            .all()\n        )\n\n    @cached_property\n    def count(self):\n        return self.query.count()\n\n    @property\n    def has_previous(self):\n        \"\"\"Return True if there are pages before the current one.\"\"\"\n        return self.page > 1\n\n    @property\n    def has_next(self):\n        \"\"\"Return True if there are pages after the current one.\"\"\"\n        return self.page < self.pages\n\n    @property\n    def previous(self):\n        \"\"\"Return the URL for the previous page.\"\"\"\n        return url_for(self.endpoint, page=self.page - 1)\n\n    @property\n    def next(self):\n        \"\"\"Return the URL for the next page.\"\"\"\n        return url_for(self.endpoint, page=self.page + 1)\n\n    @property\n    def pages(self):\n        \"\"\"Return the number of pages.\"\"\"\n        return max(0, self.count - 1) // self.per_page + 1\n", "examples/plnt/sync.py": "\"\"\"Does the synchronization. Called by \"manage-plnt.py sync\".\"\"\"\nfrom datetime import datetime\n\nimport feedparser\nfrom markupsafe import escape\n\nfrom .database import Blog\nfrom .database import Entry\nfrom .database import session\nfrom .utils import nl2p\nfrom .utils import strip_tags\n\n\nHTML_MIMETYPES = {\"text/html\", \"application/xhtml+xml\"}\n\n\ndef sync():\n    \"\"\"\n    Performs a synchronization. Articles that are already synchronized aren't\n    touched anymore.\n    \"\"\"\n    for blog in Blog.query.all():\n        # parse the feed. feedparser.parse will never given an exception\n        # but the bozo bit might be defined.\n        feed = feedparser.parse(blog.feed_url)\n\n        for entry in feed.entries:\n            # get the guid. either the id if specified, otherwise the link.\n            # if none is available we skip the entry.\n            guid = entry.get(\"id\") or entry.get(\"link\")\n            if not guid:\n                continue\n\n            # get an old entry for the guid to check if we need to update\n            # or recreate the item\n            old_entry = Entry.query.filter_by(guid=guid).first()\n\n            # get title, url and text. skip if no title or no text is\n            # given. if the link is missing we use the blog link.\n            if \"title_detail\" in entry:\n                title = entry.title_detail.get(\"value\") or \"\"\n                if entry.title_detail.get(\"type\") in HTML_MIMETYPES:\n                    title = strip_tags(title)\n                else:\n                    title = escape(title)\n            else:\n                title = entry.get(\"title\")\n            url = entry.get(\"link\") or blog.blog_url\n            text = (\n                entry.content[0] if \"content\" in entry else entry.get(\"summary_detail\")\n            )\n\n            if not title or not text:\n                continue\n\n            # if we have an html text we use that, otherwise we HTML\n            # escape the text and use that one. We also handle XHTML\n            # with our tag soup parser for the moment.\n            if text.get(\"type\") not in HTML_MIMETYPES:\n                text = escape(nl2p(text.get(\"value\") or \"\"))\n            else:\n                text = text.get(\"value\") or \"\"\n\n            # no text? continue\n            if not text.strip():\n                continue\n\n            # get the pub date and updated date. This is rather complex\n            # because different feeds do different stuff\n            pub_date = (\n                entry.get(\"published_parsed\")\n                or entry.get(\"created_parsed\")\n                or entry.get(\"date_parsed\")\n            )\n            updated = entry.get(\"updated_parsed\") or pub_date\n            pub_date = pub_date or updated\n\n            # if we don't have a pub_date we skip.\n            if not pub_date:\n                continue\n\n            # convert the time tuples to datetime objects.\n            pub_date = datetime(*pub_date[:6])\n            updated = datetime(*updated[:6])\n            if old_entry and updated <= old_entry.last_update:\n                continue\n\n            # create a new entry object based on the data collected or\n            # update the old one.\n            entry = old_entry or Entry()\n            entry.blog = blog\n            entry.guid = guid\n            entry.title = title\n            entry.url = url\n            entry.text = text\n            entry.pub_date = pub_date\n            entry.last_update = updated\n            session.add(entry)\n\n    session.commit()\n", "examples/plnt/views.py": "\"\"\"Display the aggregated feeds.\"\"\"\nfrom datetime import date\n\nfrom .database import Entry\nfrom .utils import expose\nfrom .utils import Pagination\nfrom .utils import render_template\n\n\n#: number of items per page\nPER_PAGE = 30\n\n\n@expose(\"/\", defaults={\"page\": 1})\n@expose(\"/page/<int:page>\")\ndef index(request, page):\n    \"\"\"Show the index page or any an offset of it.\"\"\"\n    days = []\n    days_found = set()\n    query = Entry.query.order_by(Entry.pub_date.desc())\n    pagination = Pagination(query, PER_PAGE, page, \"index\")\n    for entry in pagination.entries:\n        day = date(*entry.pub_date.timetuple()[:3])\n        if day not in days_found:\n            days_found.add(day)\n            days.append({\"date\": day, \"entries\": []})\n        days[-1][\"entries\"].append(entry)\n    return render_template(\"index.html\", days=days, pagination=pagination)\n\n\n@expose(\"/about\")\ndef about(request):\n    \"\"\"Show the about page, so that we have another view func ;-)\"\"\"\n    return render_template(\"about.html\")\n", "examples/plnt/webapp.py": "from os import path\n\nfrom sqlalchemy import create_engine\nfrom werkzeug.exceptions import HTTPException\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.wrappers import Request\nfrom werkzeug.wsgi import ClosingIterator\n\nfrom . import views  # noqa: F401\nfrom .database import metadata\nfrom .database import session\nfrom .utils import endpoints\nfrom .utils import local\nfrom .utils import local_manager\nfrom .utils import url_map\n\n#: path to shared data\nSHARED_DATA = path.join(path.dirname(__file__), \"shared\")\n\n\nclass Plnt:\n    def __init__(self, database_uri):\n        self.database_engine = create_engine(database_uri)\n\n        self._dispatch = local_manager.middleware(self.dispatch_request)\n        self._dispatch = SharedDataMiddleware(self._dispatch, {\"/shared\": SHARED_DATA})\n\n    def init_database(self):\n        metadata.create_all(self.database_engine)\n\n    def bind_to_context(self):\n        local.application = self\n\n    def dispatch_request(self, environ, start_response):\n        self.bind_to_context()\n        local.request = request = Request(environ, start_response)\n        local.url_adapter = adapter = url_map.bind_to_environ(environ)\n        try:\n            endpoint, values = adapter.match(request.path)\n            response = endpoints[endpoint](request, **values)\n        except HTTPException as e:\n            response = e\n        return ClosingIterator(response(environ, start_response), session.remove)\n\n    def __call__(self, environ, start_response):\n        return self._dispatch(environ, start_response)\n", "examples/plnt/__init__.py": "\"\"\"A planet application, pronounced \"plant\".\"\"\"\nfrom .webapp import Plnt\n", "examples/cupoftee/db.py": "\"\"\"A simple object database. As long as the server is not running in\nmultiprocess mode that's good enough.\n\"\"\"\nimport dbm\nfrom pickle import dumps\nfrom pickle import loads\nfrom threading import Lock\n\n\nclass Database:\n    def __init__(self, filename):\n        self.filename = filename\n        self._fs = dbm.open(filename, \"cf\")\n        self._local = {}\n        self._lock = Lock()\n\n    def __getitem__(self, key):\n        with self._lock:\n            return self._load_key(key)\n\n    def _load_key(self, key):\n        if key in self._local:\n            return self._local[key]\n        rv = loads(self._fs[key])\n        self._local[key] = rv\n        return rv\n\n    def __setitem__(self, key, value):\n        self._local[key] = value\n\n    def __delitem__(self, key):\n        with self._lock:\n            self._local.pop(key, None)\n            if key in self._fs:\n                del self._fs[key]\n\n    def __del__(self):\n        self.close()\n\n    def __contains__(self, key):\n        with self._lock:\n            try:\n                self._load_key(key)\n            except KeyError:\n                pass\n            return key in self._local\n\n    def setdefault(self, key, factory):\n        with self._lock:\n            try:\n                rv = self._load_key(key)\n            except KeyError:\n                self._local[key] = rv = factory()\n            return rv\n\n    def sync(self):\n        with self._lock:\n            for key, value in self._local.items():\n                self._fs[key] = dumps(value, 2)\n            self._fs.sync()\n\n    def close(self):\n        try:\n            self.sync()\n            self._fs.close()\n        except Exception:\n            pass\n", "examples/cupoftee/utils.py": "import re\n\n\n_sort_re = re.compile(r\"\\w+\")\n\n\ndef unicodecmp(a, b):\n    x, y = map(_sort_re.search, [a, b])\n    x = (x.group() if x else a).lower()\n    y = (y.group() if y else b).lower()\n    return (x > y) - (x < y)\n", "examples/cupoftee/application.py": "import time\nfrom os import path\nfrom threading import Thread\n\nfrom jinja2 import Environment\nfrom jinja2 import PackageLoader\nfrom werkzeug.exceptions import HTTPException\nfrom werkzeug.exceptions import NotFound\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.routing import Map\nfrom werkzeug.routing import Rule\nfrom werkzeug.wrappers import Request\nfrom werkzeug.wrappers import Response\n\nfrom .db import Database\nfrom .network import ServerBrowser\n\n\ntemplates = path.join(path.dirname(__file__), \"templates\")\npages = {}\nurl_map = Map([Rule(\"/shared/<file>\", endpoint=\"shared\")])\n\n\ndef make_app(database, interval=120):\n    return SharedDataMiddleware(\n        Cup(database, interval),\n        {\"/shared\": path.join(path.dirname(__file__), \"shared\")},\n    )\n\n\nclass PageMeta(type):\n    def __init__(cls, name, bases, d):\n        type.__init__(cls, name, bases, d)\n        if d.get(\"url_rule\") is not None:\n            pages[cls.identifier] = cls\n            url_map.add(\n                Rule(cls.url_rule, endpoint=cls.identifier, **cls.url_arguments)\n            )\n\n    @property\n    def identifier(cls):\n        return cls.__name__.lower()\n\n\ndef _with_metaclass(meta, *bases):\n    \"\"\"Create a base class with a metaclass.\"\"\"\n\n    class metaclass(type):\n        def __new__(metacls, name, this_bases, d):\n            return meta(name, bases, d)\n\n    return type.__new__(metaclass, \"temporary_class\", (), {})\n\n\nclass Page(_with_metaclass(PageMeta, object)):\n    url_arguments = {}\n\n    def __init__(self, cup, request, url_adapter):\n        self.cup = cup\n        self.request = request\n        self.url_adapter = url_adapter\n\n    def url_for(self, endpoint, **values):\n        return self.url_adapter.build(endpoint, values)\n\n    def process(self):\n        pass\n\n    def render_template(self, template=None):\n        if template is None:\n            template = f\"{type(self).identifier}.html\"\n        context = dict(self.__dict__)\n        context.update(url_for=self.url_for, self=self)\n        return self.cup.render_template(template, context)\n\n    def get_response(self):\n        return Response(self.render_template(), mimetype=\"text/html\")\n\n\nclass Cup:\n    def __init__(self, database, interval=120):\n        self.jinja_env = Environment(loader=PackageLoader(\"cupoftee\"), autoescape=True)\n        self.interval = interval\n        self.db = Database(database)\n        self.server_browser = ServerBrowser(self)\n        self.updater = Thread(None, self.update_server_browser)\n        self.updater.daemon = True\n        self.updater.start()\n\n    def update_server_browser(self):\n        while 1:\n            if self.server_browser.sync():\n                wait = self.interval\n            else:\n                wait = self.interval // 2\n            time.sleep(wait)\n\n    def dispatch_request(self, request):\n        url_adapter = url_map.bind_to_environ(request.environ)\n        try:\n            endpoint, values = url_adapter.match()\n            page = pages[endpoint](self, request, url_adapter)\n            response = page.process(**values)\n        except NotFound:\n            page = MissingPage(self, request, url_adapter)\n            response = page.process()\n        except HTTPException as e:\n            return e\n        return response or page.get_response()\n\n    def __call__(self, environ, start_response):\n        request = Request(environ)\n        return self.dispatch_request(request)(environ, start_response)\n\n    def render_template(self, name, **context):\n        template = self.jinja_env.get_template(name)\n        return template.render(context)\n\n\nfrom cupoftee.pages import MissingPage\n", "examples/cupoftee/__init__.py": "\"\"\"Werkzeug powered Teeworlds Server Browser.\"\"\"\nfrom .application import make_app\n", "examples/cupoftee/pages.py": "from functools import reduce\n\nfrom werkzeug.exceptions import NotFound\nfrom werkzeug.utils import redirect\n\nfrom .application import Page\nfrom .utils import unicodecmp\n\n\nclass ServerList(Page):\n    url_rule = \"/\"\n\n    def order_link(self, name, title):\n        cls = \"\"\n        link = f\"?order_by={name}\"\n        desc = False\n        if name == self.order_by:\n            desc = not self.order_desc\n            cls = f' class=\"{\"down\" if desc else \"up\"}\"'\n        if desc:\n            link += \"&amp;dir=desc\"\n        return f'<a href=\"{link}\"{cls}>{title}</a>'\n\n    def process(self):\n        self.order_by = self.request.args.get(\"order_by\") or \"name\"\n        sort_func = {\n            \"name\": lambda x: x,\n            \"map\": lambda x: x.map,\n            \"gametype\": lambda x: x.gametype,\n            \"players\": lambda x: x.player_count,\n            \"progression\": lambda x: x.progression,\n        }.get(self.order_by)\n        if sort_func is None:\n            return redirect(self.url_for(\"serverlist\"))\n\n        self.servers = self.cup.server_browser.servers.values()\n        self.servers.sort(key=sort_func)\n        if self.request.args.get(\"dir\") == \"desc\":\n            self.servers.reverse()\n            self.order_desc = True\n        else:\n            self.order_desc = False\n\n        self.players = reduce(lambda a, b: a + b.players, self.servers, [])\n        self.players = sorted(self.players, key=lambda a, b: unicodecmp(a.name, b.name))\n\n\nclass Server(Page):\n    url_rule = \"/server/<id>\"\n\n    def process(self, id):\n        try:\n            self.server = self.cup.server_browser.servers[id]\n        except KeyError:\n            raise NotFound() from None\n\n\nclass Search(Page):\n    url_rule = \"/search\"\n\n    def process(self):\n        self.user = self.request.args.get(\"user\")\n        if self.user:\n            self.results = []\n            for server in self.cup.server_browser.servers.values():\n                for player in server.players:\n                    if player.name == self.user:\n                        self.results.append(server)\n\n\nclass MissingPage(Page):\n    def get_response(self):\n        response = super().get_response()\n        response.status_code = 404\n        return response\n", "examples/cupoftee/network.py": "\"\"\"Query the servers for information.\"\"\"\nimport socket\nfrom datetime import datetime\nfrom math import log\n\nfrom .utils import unicodecmp\n\n\nclass ServerError(Exception):\n    pass\n\n\nclass Syncable:\n    last_sync = None\n\n    def sync(self):\n        try:\n            self._sync()\n        except (OSError, socket.timeout):\n            return False\n        self.last_sync = datetime.utcnow()\n        return True\n\n\nclass ServerBrowser(Syncable):\n    def __init__(self, cup):\n        self.cup = cup\n        self.servers = cup.db.setdefault(\"servers\", dict)\n\n    def _sync(self):\n        to_delete = set(self.servers)\n        for x in range(1, 17):\n            addr = (f\"master{x}.teeworlds.com\", 8300)\n            print(addr)\n            try:\n                self._sync_server_browser(addr, to_delete)\n            except (OSError, socket.timeout):\n                continue\n        for server_id in to_delete:\n            self.servers.pop(server_id, None)\n        if not self.servers:\n            raise OSError(\"no servers found\")\n        self.cup.db.sync()\n\n    def _sync_server_browser(self, addr, to_delete):\n        s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n        s.settimeout(5)\n        s.sendto(b\"\\x20\\x00\\x00\\x00\\x00\\x48\\xff\\xff\\xff\\xffreqt\", addr)\n        data = s.recvfrom(1024)[0][14:]\n        s.close()\n\n        for n in range(0, len(data) // 6):\n            addr = (\n                \".\".join(map(str, map(ord, data[n * 6 : n * 6 + 4]))),\n                ord(data[n * 6 + 5]) * 256 + ord(data[n * 6 + 4]),\n            )\n            server_id = f\"{addr[0]}:{addr[1]}\"\n            if server_id in self.servers:\n                if not self.servers[server_id].sync():\n                    continue\n            else:\n                try:\n                    self.servers[server_id] = Server(addr, server_id)\n                except ServerError:\n                    pass\n            to_delete.discard(server_id)\n\n\nclass Server(Syncable):\n    def __init__(self, addr, server_id):\n        self.addr = addr\n        self.id = server_id\n        self.players = []\n        if not self.sync():\n            raise ServerError(\"server not responding in time\")\n\n    def _sync(self):\n        s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n        s.settimeout(1)\n        s.sendto(b\"\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xffgief\", self.addr)\n        bits = s.recvfrom(1024)[0][14:].split(b\"\\x00\")\n        s.close()\n        self.version, server_name, map_name = bits[:3]\n        self.name = server_name.decode(\"latin1\")\n        self.map = map_name.decode(\"latin1\")\n        self.gametype = bits[3]\n        self.flags, self.progression, player_count, self.max_players = map(\n            int, bits[4:8]\n        )\n\n        # sync the player stats\n        players = {p.name: p for p in self.players}\n        for i in range(player_count):\n            name = bits[8 + i * 2].decode(\"latin1\")\n            score = int(bits[9 + i * 2])\n\n            # update existing player\n            if name in players:\n                player = players.pop(name)\n                player.score = score\n            # add new player\n            else:\n                self.players.append(Player(self, name, score))\n        # delete players that left\n        for player in players.values():\n            try:\n                self.players.remove(player)\n            except Exception:\n                pass\n\n        # sort the player list and count them\n        self.players.sort(key=lambda x: -x.score)\n        self.player_count = len(self.players)\n\n    def __cmp__(self, other):\n        return unicodecmp(self.name, other.name)\n\n\nclass Player:\n    def __init__(self, server, name, score):\n        self.server = server\n        self.name = name\n        self.score = score\n        self.size = round(100 + log(max(score, 1)) * 25, 2)\n", "examples/couchy/utils.py": "from os import path\nfrom random import randrange\nfrom random import sample\nfrom urllib.parse import urlsplit\n\nfrom jinja2 import Environment\nfrom jinja2 import FileSystemLoader\nfrom werkzeug.local import Local\nfrom werkzeug.local import LocalManager\nfrom werkzeug.routing import Map\nfrom werkzeug.routing import Rule\nfrom werkzeug.utils import cached_property\nfrom werkzeug.wrappers import Response\n\nTEMPLATE_PATH = path.join(path.dirname(__file__), \"templates\")\nSTATIC_PATH = path.join(path.dirname(__file__), \"static\")\nALLOWED_SCHEMES = frozenset([\"http\", \"https\", \"ftp\", \"ftps\"])\nURL_CHARS = \"abcdefghijkmpqrstuvwxyzABCDEFGHIJKLMNPQRST23456789\"\n\nlocal = Local()\nlocal_manager = LocalManager([local])\napplication = local(\"application\")\n\nurl_map = Map([Rule(\"/static/<file>\", endpoint=\"static\", build_only=True)])\n\njinja_env = Environment(loader=FileSystemLoader(TEMPLATE_PATH))\n\n\ndef expose(rule, **kw):\n    def decorate(f):\n        kw[\"endpoint\"] = f.__name__\n        url_map.add(Rule(rule, **kw))\n        return f\n\n    return decorate\n\n\ndef url_for(endpoint, _external=False, **values):\n    return local.url_adapter.build(endpoint, values, force_external=_external)\n\n\njinja_env.globals[\"url_for\"] = url_for\n\n\ndef render_template(template, **context):\n    return Response(\n        jinja_env.get_template(template).render(**context), mimetype=\"text/html\"\n    )\n\n\ndef validate_url(url):\n    return urlsplit(url)[0] in ALLOWED_SCHEMES\n\n\ndef get_random_uid():\n    return \"\".join(sample(URL_CHARS, randrange(3, 9)))\n\n\nclass Pagination:\n    def __init__(self, results, per_page, page, endpoint):\n        self.results = results\n        self.per_page = per_page\n        self.page = page\n        self.endpoint = endpoint\n\n    @cached_property\n    def count(self):\n        return len(self.results)\n\n    @cached_property\n    def entries(self):\n        return self.results[\n            ((self.page - 1) * self.per_page) : (\n                ((self.page - 1) * self.per_page) + self.per_page\n            )\n        ]\n\n    @property\n    def has_previous(self):\n        \"\"\"Return True if there are pages before the current one.\"\"\"\n        return self.page > 1\n\n    @property\n    def has_next(self):\n        \"\"\"Return True if there are pages after the current one.\"\"\"\n        return self.page < self.pages\n\n    @property\n    def previous(self):\n        \"\"\"Return the URL for the previous page.\"\"\"\n        return url_for(self.endpoint, page=self.page - 1)\n\n    @property\n    def next(self):\n        \"\"\"Return the URL for the next page.\"\"\"\n        return url_for(self.endpoint, page=self.page + 1)\n\n    @property\n    def pages(self):\n        \"\"\"Return the number of pages.\"\"\"\n        return max(0, self.count - 1) // self.per_page + 1\n", "examples/couchy/models.py": "from datetime import datetime\n\nfrom couchdb.mapping import BooleanField\nfrom couchdb.mapping import DateTimeField\nfrom couchdb.mapping import Document\nfrom couchdb.mapping import TextField\n\nfrom .utils import get_random_uid\nfrom .utils import url_for\n\n\nclass URL(Document):\n    target = TextField()\n    public = BooleanField()\n    added = DateTimeField(default=datetime.utcnow())\n    shorty_id = TextField(default=None)\n    db = None\n\n    @classmethod\n    def load(cls, id):\n        return super().load(URL.db, id)\n\n    @classmethod\n    def query(cls, code):\n        return URL.db.query(code)\n\n    def store(self):\n        if getattr(self._data, \"id\", None) is None:\n            new_id = self.shorty_id if self.shorty_id else None\n            while 1:\n                id = new_id if new_id else get_random_uid()\n                try:\n                    docid = URL.db.resource.put(content=self._data, path=f\"/{id}/\")[\n                        \"id\"\n                    ]\n                except Exception:\n                    continue\n                if docid:\n                    break\n            self._data = URL.db.get(docid)\n        else:\n            super().store(URL.db)\n        return self\n\n    @property\n    def short_url(self):\n        return url_for(\"link\", uid=self.id, _external=True)\n\n    def __repr__(self):\n        return f\"<URL {self.id!r}>\"\n", "examples/couchy/views.py": "from werkzeug.exceptions import NotFound\nfrom werkzeug.utils import redirect\n\nfrom .models import URL\nfrom .utils import expose\nfrom .utils import Pagination\nfrom .utils import render_template\nfrom .utils import url_for\nfrom .utils import validate_url\n\n\n@expose(\"/\")\ndef new(request):\n    error = url = \"\"\n    if request.method == \"POST\":\n        url = request.form.get(\"url\")\n        alias = request.form.get(\"alias\")\n        if not validate_url(url):\n            error = \"I'm sorry but you cannot shorten this URL.\"\n        elif alias:\n            if len(alias) > 140:\n                error = \"Your alias is too long\"\n            elif \"/\" in alias:\n                error = \"Your alias might not include a slash\"\n            elif URL.load(alias):\n                error = \"The alias you have requested exists already\"\n        if not error:\n            url = URL(\n                target=url,\n                public=\"private\" not in request.form,\n                shorty_id=alias if alias else None,\n            )\n            url.store()\n            uid = url.id\n            return redirect(url_for(\"display\", uid=uid))\n    return render_template(\"new.html\", error=error, url=url)\n\n\n@expose(\"/display/<uid>\")\ndef display(request, uid):\n    url = URL.load(uid)\n    if not url:\n        raise NotFound()\n    return render_template(\"display.html\", url=url)\n\n\n@expose(\"/u/<uid>\")\ndef link(request, uid):\n    url = URL.load(uid)\n    if not url:\n        raise NotFound()\n    return redirect(url.target, 301)\n\n\n@expose(\"/list/\", defaults={\"page\": 1})\n@expose(\"/list/<int:page>\")\ndef list(request, page):\n    def wrap(doc):\n        data = doc.value\n        data[\"_id\"] = doc.id\n        return URL.wrap(data)\n\n    code = \"\"\"function(doc) { if (doc.public){ map([doc._id], doc); }}\"\"\"\n    docResults = URL.query(code)\n    results = [wrap(doc) for doc in docResults]\n    pagination = Pagination(results, 1, page, \"list\")\n    if pagination.page > 1 and not pagination.entries:\n        raise NotFound()\n    return render_template(\"list.html\", pagination=pagination)\n\n\ndef not_found(request):\n    return render_template(\"not_found.html\")\n", "examples/couchy/application.py": "from couchdb.client import Server\nfrom werkzeug.exceptions import HTTPException\nfrom werkzeug.exceptions import NotFound\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.wrappers import Request\nfrom werkzeug.wsgi import ClosingIterator\n\nfrom . import views\nfrom .models import URL\nfrom .utils import local\nfrom .utils import local_manager\nfrom .utils import STATIC_PATH\nfrom .utils import url_map\n\n\nclass Couchy:\n    def __init__(self, db_uri):\n        local.application = self\n\n        server = Server(db_uri)\n        try:\n            db = server.create(\"urls\")\n        except Exception:\n            db = server[\"urls\"]\n        self.dispatch = SharedDataMiddleware(self.dispatch, {\"/static\": STATIC_PATH})\n\n        URL.db = db\n\n    def dispatch(self, environ, start_response):\n        local.application = self\n        request = Request(environ)\n        local.url_adapter = adapter = url_map.bind_to_environ(environ)\n        try:\n            endpoint, values = adapter.match()\n            handler = getattr(views, endpoint)\n            response = handler(request, **values)\n        except NotFound:\n            response = views.not_found(request)\n            response.status_code = 404\n        except HTTPException as e:\n            response = e\n        return ClosingIterator(\n            response(environ, start_response), [local_manager.cleanup]\n        )\n\n    def __call__(self, environ, start_response):\n        return self.dispatch(environ, start_response)\n", "examples/couchy/__init__.py": "", "examples/webpylike/webpylike.py": "\"\"\"Implements web.py like dispatching. What this module does not\nimplement is a stream system that hooks into sys.stdout like web.py\nprovides.\n\"\"\"\nimport re\n\nfrom werkzeug.exceptions import HTTPException\nfrom werkzeug.exceptions import MethodNotAllowed\nfrom werkzeug.exceptions import NotFound\nfrom werkzeug.exceptions import NotImplemented\nfrom werkzeug.wrappers import Request\nfrom werkzeug.wrappers import Response  # noqa: F401\n\n\nclass View:\n    \"\"\"Baseclass for our views.\"\"\"\n\n    def __init__(self, app, req):\n        self.app = app\n        self.req = req\n\n    def GET(self):\n        raise MethodNotAllowed()\n\n    POST = DELETE = PUT = GET\n\n    def HEAD(self):\n        return self.GET()\n\n\nclass WebPyApp:\n    \"\"\"\n    An interface to a web.py like application.  It works like the web.run\n    function in web.py\n    \"\"\"\n\n    def __init__(self, urls, views):\n        self.urls = [\n            (re.compile(f\"^{urls[i]}$\"), urls[i + 1]) for i in range(0, len(urls), 2)\n        ]\n        self.views = views\n\n    def __call__(self, environ, start_response):\n        try:\n            req = Request(environ)\n            for regex, view in self.urls:\n                match = regex.match(req.path)\n                if match is not None:\n                    view = self.views[view](self, req)\n                    if req.method not in (\"GET\", \"HEAD\", \"POST\", \"DELETE\", \"PUT\"):\n                        raise NotImplemented()  # noqa: F901\n                    resp = getattr(view, req.method)(*match.groups())\n                    break\n            else:\n                raise NotFound()\n        except HTTPException as e:\n            resp = e\n        return resp(environ, start_response)\n", "examples/webpylike/example.py": "from .webpylike import Response\nfrom .webpylike import View\nfrom .webpylike import WebPyApp\n\n\nurls = (\"/\", \"index\", \"/about\", \"about\")\n\n\nclass index(View):\n    def GET(self):\n        return Response(\"Hello World\")\n\n\nclass about(View):\n    def GET(self):\n        return Response(\"This is the about page\")\n\n\napp = WebPyApp(urls, globals())\n", "examples/i18nurls/urls.py": "from werkzeug.routing import Map\nfrom werkzeug.routing import Rule\nfrom werkzeug.routing import Submount\n\nmap = Map(\n    [\n        Rule(\"/\", endpoint=\"#language_select\"),\n        Submount(\n            \"/<string(length=2):lang_code>\",\n            [\n                Rule(\"/\", endpoint=\"index\"),\n                Rule(\"/about\", endpoint=\"about\"),\n                Rule(\"/blog/\", endpoint=\"blog/index\"),\n                Rule(\"/blog/<int:post_id>\", endpoint=\"blog/show\"),\n            ],\n        ),\n    ]\n)\n", "examples/i18nurls/views.py": "from .application import expose\nfrom .application import Response\nfrom .application import TemplateResponse\n\n\n@expose(\"index\")\ndef index(req):\n    return TemplateResponse(\"index.html\", title=\"Index\")\n\n\n@expose(\"about\")\ndef about(req):\n    return TemplateResponse(\"about.html\", title=\"About\")\n\n\n@expose(\"blog/index\")\ndef blog_index(req):\n    return TemplateResponse(\"blog.html\", title=\"Blog Index\", mode=\"index\")\n\n\n@expose(\"blog/show\")\ndef blog_show(req, post_id):\n    return TemplateResponse(\n        \"blog.html\", title=f\"Blog Post #{post_id}\", post_id=post_id, mode=\"show\"\n    )\n\n\ndef page_not_found(req):\n    return Response(\"<h1>Page Not Found</h1>\", mimetype=\"text/html\")\n", "examples/i18nurls/application.py": "from os import path\n\nfrom jinja2 import Environment\nfrom jinja2 import PackageLoader\nfrom werkzeug.exceptions import HTTPException\nfrom werkzeug.exceptions import NotFound\nfrom werkzeug.routing import RequestRedirect\nfrom werkzeug.wrappers import Request as BaseRequest\nfrom werkzeug.wrappers import Response as BaseResponse\n\nfrom .urls import map\n\nTEMPLATES = path.join(path.dirname(__file__), \"templates\")\nviews = {}\n\n\ndef expose(name):\n    \"\"\"Register the function as view.\"\"\"\n\n    def wrapped(f):\n        views[name] = f\n        return f\n\n    return wrapped\n\n\nclass Request(BaseRequest):\n    def __init__(self, environ, urls):\n        super().__init__(environ)\n        self.urls = urls\n        self.matched_url = None\n\n    def url_for(self, endpoint, **args):\n        if \"lang_code\" not in args:\n            args[\"lang_code\"] = self.language\n        if endpoint == \"this\":\n            endpoint = self.matched_url[0]\n            tmp = self.matched_url[1].copy()\n            tmp.update(args)\n            args = tmp\n        return self.urls.build(endpoint, args)\n\n\nclass Response(BaseResponse):\n    pass\n\n\nclass TemplateResponse(Response):\n    jinja_env = Environment(loader=PackageLoader(\"i18nurls\"), autoescape=True)\n\n    def __init__(self, template_name, **values):\n        self.template_name = template_name\n        self.template_values = values\n        Response.__init__(self, mimetype=\"text/html\")\n\n    def __call__(self, environ, start_response):\n        req = environ[\"werkzeug.request\"]\n        values = self.template_values.copy()\n        values[\"req\"] = req\n        self.data = self.render_template(self.template_name, values)\n        return super().__call__(environ, start_response)\n\n    def render_template(self, name, values):\n        template = self.jinja_env.get_template(name)\n        return template.render(values)\n\n\nclass Application:\n    def __init__(self):\n        from i18nurls import views\n\n        self.not_found = views.page_not_found\n\n    def __call__(self, environ, start_response):\n        urls = map.bind_to_environ(environ)\n        req = Request(environ, urls)\n        try:\n            endpoint, args = urls.match(req.path)\n            req.matched_url = (endpoint, args)\n            if endpoint == \"#language_select\":\n                lng = req.accept_languages.best\n                lng = lng.split(\"-\")[0].lower() if lng else \"en\"\n                index_url = urls.build(\"index\", {\"lang_code\": lng})\n                resp = Response(f\"Moved to {index_url}\", status=302)\n                resp.headers[\"Location\"] = index_url\n            else:\n                req.language = args.pop(\"lang_code\", None)\n                resp = views[endpoint](req, **args)\n        except NotFound:\n            resp = self.not_found(req)\n        except (RequestRedirect, HTTPException) as e:\n            resp = e\n        return resp(environ, start_response)\n", "examples/i18nurls/__init__.py": "from .application import Application as make_app\n", "examples/shortly/shortly.py": "\"\"\"A simple URL shortener using Werkzeug and redis.\"\"\"\nimport os\nfrom urllib.parse import urlsplit\n\nimport redis\nfrom jinja2 import Environment\nfrom jinja2 import FileSystemLoader\nfrom werkzeug.exceptions import HTTPException\nfrom werkzeug.exceptions import NotFound\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.routing import Map\nfrom werkzeug.routing import Rule\nfrom werkzeug.utils import redirect\nfrom werkzeug.wrappers import Request\nfrom werkzeug.wrappers import Response\n\n\ndef base36_encode(number):\n    assert number >= 0, \"positive integer required\"\n    if number == 0:\n        return \"0\"\n    base36 = []\n    while number != 0:\n        number, i = divmod(number, 36)\n        base36.append(\"0123456789abcdefghijklmnopqrstuvwxyz\"[i])\n    return \"\".join(reversed(base36))\n\n\ndef is_valid_url(url):\n    parts = urlsplit(url)\n    return parts.scheme in (\"http\", \"https\")\n\n\ndef get_hostname(url):\n    return urlsplit(url).netloc\n\n\nclass Shortly:\n    def __init__(self, config):\n        self.redis = redis.Redis(\n            config[\"redis_host\"], config[\"redis_port\"], decode_responses=True\n        )\n        template_path = os.path.join(os.path.dirname(__file__), \"templates\")\n        self.jinja_env = Environment(\n            loader=FileSystemLoader(template_path), autoescape=True\n        )\n        self.jinja_env.filters[\"hostname\"] = get_hostname\n\n        self.url_map = Map(\n            [\n                Rule(\"/\", endpoint=\"new_url\"),\n                Rule(\"/<short_id>\", endpoint=\"follow_short_link\"),\n                Rule(\"/<short_id>+\", endpoint=\"short_link_details\"),\n            ]\n        )\n\n    def on_new_url(self, request):\n        error = None\n        url = \"\"\n        if request.method == \"POST\":\n            url = request.form[\"url\"]\n            if not is_valid_url(url):\n                error = \"Please enter a valid URL\"\n            else:\n                short_id = self.insert_url(url)\n                return redirect(f\"/{short_id}+\")\n        return self.render_template(\"new_url.html\", error=error, url=url)\n\n    def on_follow_short_link(self, request, short_id):\n        link_target = self.redis.get(f\"url-target:{short_id}\")\n        if link_target is None:\n            raise NotFound()\n        self.redis.incr(f\"click-count:{short_id}\")\n        return redirect(link_target)\n\n    def on_short_link_details(self, request, short_id):\n        link_target = self.redis.get(f\"url-target:{short_id}\")\n        if link_target is None:\n            raise NotFound()\n        click_count = int(self.redis.get(f\"click-count:{short_id}\") or 0)\n        return self.render_template(\n            \"short_link_details.html\",\n            link_target=link_target,\n            short_id=short_id,\n            click_count=click_count,\n        )\n\n    def error_404(self):\n        response = self.render_template(\"404.html\")\n        response.status_code = 404\n        return response\n\n    def insert_url(self, url):\n        short_id = self.redis.get(f\"reverse-url:{url}\")\n        if short_id is not None:\n            return short_id\n        url_num = self.redis.incr(\"last-url-id\")\n        short_id = base36_encode(url_num)\n        self.redis.set(f\"url-target:{short_id}\", url)\n        self.redis.set(f\"reverse-url:{url}\", short_id)\n        return short_id\n\n    def render_template(self, template_name, **context):\n        t = self.jinja_env.get_template(template_name)\n        return Response(t.render(context), mimetype=\"text/html\")\n\n    def dispatch_request(self, request):\n        adapter = self.url_map.bind_to_environ(request.environ)\n        try:\n            endpoint, values = adapter.match()\n            return getattr(self, f\"on_{endpoint}\")(request, **values)\n        except NotFound:\n            return self.error_404()\n        except HTTPException as e:\n            return e\n\n    def wsgi_app(self, environ, start_response):\n        request = Request(environ)\n        response = self.dispatch_request(request)\n        return response(environ, start_response)\n\n    def __call__(self, environ, start_response):\n        return self.wsgi_app(environ, start_response)\n\n\ndef create_app(redis_host=\"localhost\", redis_port=6379, with_static=True):\n    app = Shortly({\"redis_host\": redis_host, \"redis_port\": redis_port})\n    if with_static:\n        app.wsgi_app = SharedDataMiddleware(\n            app.wsgi_app, {\"/static\": os.path.join(os.path.dirname(__file__), \"static\")}\n        )\n    return app\n\n\nif __name__ == \"__main__\":\n    from werkzeug.serving import run_simple\n\n    app = create_app()\n    run_simple(\"127.0.0.1\", 5000, app, use_debugger=True, use_reloader=True)\n", "examples/coolmagic/utils.py": "\"\"\"Subclasses of the base request and response objects provided by\nwerkzeug. The subclasses know about their charset and implement some\nadditional functionality like the ability to link to view functions.\n\"\"\"\nfrom os.path import dirname\nfrom os.path import join\n\nfrom jinja2 import Environment\nfrom jinja2 import FileSystemLoader\nfrom werkzeug.local import Local\nfrom werkzeug.local import LocalManager\nfrom werkzeug.wrappers import Request as BaseRequest\nfrom werkzeug.wrappers import Response as BaseResponse\n\n\nlocal = Local()\nlocal_manager = LocalManager([local])\ntemplate_env = Environment(\n    loader=FileSystemLoader(join(dirname(__file__), \"templates\"))\n)\nexported_views = {}\n\n\ndef export(string, template=None, **extra):\n    \"\"\"\n    Decorator for registering view functions and adding\n    templates to it.\n    \"\"\"\n\n    def wrapped(f):\n        endpoint = f\"{f.__module__}.{f.__name__}\"[16:]\n        if template is not None:\n            old_f = f\n\n            def f(**kwargs):\n                rv = old_f(**kwargs)\n                if not isinstance(rv, Response):\n                    rv = TemplateResponse(template, **(rv or {}))\n                return rv\n\n            f.__name__ = old_f.__name__\n            f.__doc__ = old_f.__doc__\n        exported_views[endpoint] = (f, string, extra)\n        return f\n\n    return wrapped\n\n\ndef url_for(endpoint, **values):\n    \"\"\"\n    Build a URL\n    \"\"\"\n    return local.request.url_adapter.build(endpoint, values)\n\n\nclass Request(BaseRequest):\n    \"\"\"\n    The concrete request object used in the WSGI application.\n    It has some helper functions that can be used to build URLs.\n    \"\"\"\n\n    charset = \"utf-8\"\n\n    def __init__(self, environ, url_adapter):\n        super().__init__(environ)\n        self.url_adapter = url_adapter\n        local.request = self\n\n\nclass ThreadedRequest:\n    \"\"\"\n    A pseudo request object that always points to the current\n    context active request.\n    \"\"\"\n\n    def __getattr__(self, name):\n        if name == \"__members__\":\n            return [x for x in dir(local.request) if not x.startswith(\"_\")]\n        return getattr(local.request, name)\n\n    def __setattr__(self, name, value):\n        return setattr(local.request, name, value)\n\n\nclass Response(BaseResponse):\n    \"\"\"\n    The concrete response object for the WSGI application.\n    \"\"\"\n\n    charset = \"utf-8\"\n    default_mimetype = \"text/html\"\n\n\nclass TemplateResponse(Response):\n    \"\"\"\n    Render a template to a response.\n    \"\"\"\n\n    def __init__(self, template_name, **values):\n        from coolmagic import helpers\n\n        values.update(request=local.request, h=helpers)\n        template = template_env.get_template(template_name)\n        Response.__init__(self, template.render(values))\n", "examples/coolmagic/helpers.py": "from .utils import ThreadedRequest\n\n#: a thread local proxy request object\nrequest = ThreadedRequest()\ndel ThreadedRequest\n", "examples/coolmagic/application.py": "\"\"\"This module provides the WSGI application.\n\nThe WSGI middlewares are applied in the `make_app` factory function that\nautomatically wraps the application within the require middlewares. Per\ndefault only the `SharedDataMiddleware` is applied.\n\"\"\"\nfrom os import listdir\nfrom os import path\n\nfrom werkzeug.exceptions import HTTPException\nfrom werkzeug.exceptions import NotFound\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.routing import Map\nfrom werkzeug.routing import RequestRedirect\nfrom werkzeug.routing import Rule\n\nfrom .utils import local_manager\nfrom .utils import Request\n\n\nclass CoolMagicApplication:\n    \"\"\"\n    The application class. It's passed a directory with configuration values.\n    \"\"\"\n\n    def __init__(self, config):\n        self.config = config\n\n        for fn in listdir(path.join(path.dirname(__file__), \"views\")):\n            if fn.endswith(\".py\") and fn != \"__init__.py\":\n                __import__(f\"coolmagic.views.{fn[:-3]}\")\n\n        from coolmagic.utils import exported_views\n\n        rules = [\n            # url for shared data. this will always be unmatched\n            # because either the middleware or the webserver\n            # handles that request first.\n            Rule(\"/public/<path:file>\", endpoint=\"shared_data\")\n        ]\n        self.views = {}\n        for endpoint, (func, rule, extra) in exported_views.items():\n            if rule is not None:\n                rules.append(Rule(rule, endpoint=endpoint, **extra))\n            self.views[endpoint] = func\n        self.url_map = Map(rules)\n\n    def __call__(self, environ, start_response):\n        urls = self.url_map.bind_to_environ(environ)\n        req = Request(environ, urls)\n        try:\n            endpoint, args = urls.match(req.path)\n            resp = self.views[endpoint](**args)\n        except NotFound:\n            resp = self.views[\"static.not_found\"]()\n        except (HTTPException, RequestRedirect) as e:\n            resp = e\n        return resp(environ, start_response)\n\n\ndef make_app(config=None):\n    \"\"\"\n    Factory function that creates a new `CoolmagicApplication`\n    object. Optional WSGI middlewares should be applied here.\n    \"\"\"\n    config = config or {}\n    app = CoolMagicApplication(config)\n\n    # static stuff\n    app = SharedDataMiddleware(\n        app, {\"/public\": path.join(path.dirname(__file__), \"public\")}\n    )\n\n    # clean up locals\n    app = local_manager.make_middleware(app)\n\n    return app\n", "examples/coolmagic/__init__.py": "from .application import make_app\n", "examples/coolmagic/views/static.py": "from coolmagic.utils import export\n\n\n@export(\"/\", template=\"static/index.html\")\ndef index():\n    pass\n\n\n@export(\"/about\", template=\"static/about.html\")\ndef about():\n    pass\n\n\n@export(\"/broken\")\ndef broken():\n    raise RuntimeError(\"that's really broken\")\n\n\n@export(None, template=\"static/not_found.html\")\ndef not_found():\n    \"\"\"\n    This function is always executed if an url does not\n    match or a `NotFound` exception is raised.\n    \"\"\"\n    pass\n", "examples/coolmagic/views/__init__.py": ""}