{"e2e/scripts/st_image.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport io\nfrom typing import TYPE_CHECKING, Any\n\nimport numpy as np\nfrom PIL import Image, ImageDraw\n\nimport streamlit as st\n\nif TYPE_CHECKING:\n    import numpy.typing as npt\n\n\ndef create_gif(size, frames=1):\n    # Create grayscale image.\n    im = Image.new(\"L\", (size, size), \"white\")\n\n    images = []\n\n    # Make circle of a constant size with a number of frames, moving across the\n    # principal diagonal of a 64x64 image. The GIF will not loop and stops\n    # animating after frames x 100ms.\n    for i in range(0, frames):\n        frame = im.copy()\n        draw = ImageDraw.Draw(frame)\n        pos = (i, i)\n        circle_size = size / 2\n        draw.ellipse([pos, tuple(p + circle_size for p in pos)], \"black\")\n        images.append(frame.copy())\n\n    # Save the frames as an animated GIF\n    data = io.BytesIO()\n    images[0].save(\n        data,\n        format=\"GIF\",\n        save_all=True,\n        append_images=images[1:],\n        duration=1,\n    )\n\n    return data.getvalue()\n\n\nimg = np.repeat(0, 10000).reshape(100, 100)\nimg800 = np.repeat(0, 640000).reshape(800, 800)\ngif = create_gif(64, frames=32)\n\nst.image(img, caption=\"Black Square as JPEG\", output_format=\"JPEG\", width=100)\n\nst.image(img, caption=\"Black Square as PNG\", output_format=\"PNG\", width=100)\n\nst.image(img, caption=\"Black Square with no output format specified\", width=100)\n\ntransparent_img: \"npt.NDArray[Any]\" = np.zeros((100, 100, 4), dtype=np.uint8)\nst.image(transparent_img, caption=\"Transparent Black Square\", width=100)\n\ncol1, col2, col3 = st.columns(3)\ncol2.image(img)  # 100\ncol2.image(img, use_column_width=\"auto\")  # 100\n\ncol2.image(img, use_column_width=\"never\")  # 100\ncol2.image(img, use_column_width=False)  # 100\n\ncol2.image(img, use_column_width=\"always\")  # column\ncol2.image(img, use_column_width=True)  # column\n\ncol2.image(img800, use_column_width=\"auto\")  # column\n\nst.image(\n    \"\"\"\n<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"500\" height=\"100\">\n<text x=\"0\" y=\"50\">\"I am a quote\" - https://avatars.githubusercontent.com/karriebear</text>\n</svg>\n\"\"\"\n)\n\nst.image(\n    \"\"\"<?xml version=\"1.0\" encoding=\"utf-8\"?>\n    <!-- Generator: Adobe Illustrator 17.1.0, SVG Export Plug-In . SVG Version: 6.00 Build 0)  -->\n    <!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\" \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n    <svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"500\" height=\"100\">\n    <text x=\"0\" y=\"50\">\"I am prefixed with some meta tags</text>\n    </svg>\n\"\"\"\n)\n\nst.image(gif, width=100)\nst.image(create_gif(64), caption=\"Black Circle as GIF\", width=100)\nst.image(gif, caption=\"GIF as PNG\", output_format=\"PNG\", width=100)\n", "e2e/scripts/st_image_svg_sizing.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\nst.image(\n    \"\"\"\n<svg>\n  <circle cx=\"50\" cy=\"50\" r=\"40\" stroke=\"black\" stroke-width=\"3\" fill=\"red\" />\n  Sorry, your browser does not support inline SVG.\n</svg>\n\"\"\"\n)\n\nSVG_RED_CIRCLE = \"\"\"\n<svg width=\"100\" height=\"100\" xmlns=\"http://www.w3.org/2000/svg\">\n  <circle cx=\"50\" cy=\"50\" r=\"40\" stroke=\"black\" stroke-width=\"3\" fill=\"red\" />\n  Sorry, your browser does not support inline SVG.\n</svg>\n\"\"\"\n\nst.image(SVG_RED_CIRCLE)\nst.image(SVG_RED_CIRCLE, width=300)\n\n\nSVG_YELLOW_GREEN_RECTANGLE = \"\"\"\n<svg viewBox=\"{x} 0 100 90\" xmlns=\"http://www.w3.org/2000/svg\">\n    <rect x=\"0\" y=\"0\" width=\"100\" height=\"90\" fill=\"yellow\" />\n    <rect x=\"100\" y=\"0\" width=\"100\" height=\"90\" fill=\"green\" />\n</svg>\n\"\"\"\n\nst.image(SVG_YELLOW_GREEN_RECTANGLE.format(x=50), width=100)\nst.image(SVG_YELLOW_GREEN_RECTANGLE.format(x=50), width=300)\n\nst.image(SVG_YELLOW_GREEN_RECTANGLE.format(x=0), width=100)\nst.image(SVG_YELLOW_GREEN_RECTANGLE.format(x=0), width=300)\n\nst.image(SVG_YELLOW_GREEN_RECTANGLE.format(x=100), width=100)\nst.image(SVG_YELLOW_GREEN_RECTANGLE.format(x=100), width=300)\n", "e2e/scripts/iframe_resizer.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\nx = st.slider(\"Enter a number\", 0, 20, 0)\n\nfor _ in range(x):\n    st.write(\"Hello example\")\n", "e2e/scripts/st_sidebar.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom datetime import date, datetime\n\nimport streamlit as st\n\nw1 = st.sidebar.date_input(\"Label 1\", date(1970, 1, 1))\nst.write(\"Value 1:\", w1)\n\nw2 = st.sidebar.date_input(\"Label 2\", datetime(2019, 7, 6, 21, 15))\nst.write(\"Value 2:\", w2)\n\nx = st.sidebar.text(\"overwrite me\")\nx.text(\"overwritten\")\ny = st.sidebar.text_input(\"type here\")\n\n# TODO: add more tests such as markdown elements and also a test that takes screenshot of complete app to verify alignment of elements\n", "e2e/scripts/st_download_button.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom random import random\n\nimport streamlit as st\n\nst.download_button(\n    \"Download button label\",\n    data=\"Hello world!\",\n    file_name=\"hello.txt\",\n)\n\nst.download_button(\n    \"Download button label\",\n    data=\"Hello world!\",\n    file_name=\"hello.txt\",\n    key=\"disabled_dl_button\",\n    disabled=True,\n)\n\nst.download_button(\n    \"Download RAR archive file\",\n    data=b\"bytes\",\n    file_name=\"archive.rar\",\n    mime=\"application/vnd.rar\",\n)\n\nst.download_button(\n    \"Download button with use_container_width=True\",\n    data=\"Hello world!\",\n    file_name=\"hello.txt\",\n    use_container_width=True,\n)\n\nst.download_button(\n    \"Download button with help text and use_container_width=True\",\n    data=\"Hello world!\",\n    file_name=\"hello.txt\",\n    use_container_width=True,\n    help=\"Example help text\",\n)\n\nst.download_button(\n    \"Primary download button\",\n    data=\"Hello world!\",\n    file_name=\"hello.txt\",\n    type=\"primary\",\n)\n\nrandom_str = str(random())\nclicked = st.download_button(label=\"Download random text\", data=random_str)\n\nst.write(f\"value: {clicked}\")\n", "e2e/scripts/websocket_reconnects.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\nfrom streamlit import runtime\n\n# st.session_state can only be accessed while running with streamlit\nif runtime.exists():\n    if \"counter\" not in st.session_state:\n        st.session_state.counter = 0\n\n    if st.button(\"click me!\"):\n        st.session_state.counter += 1\n\n    st.write(f\"count: {st.session_state.counter}\")\n\n    if f := st.file_uploader(\"Upload a file\"):\n        st.text(f.read())\n\n    if img := st.camera_input(\"Take a picture\"):\n        st.image(img)\n", "e2e/scripts/st_set_page_config.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\nst.set_page_config(\n    page_title=\"Heya, world?\",\n    page_icon=\":shark:\",\n    layout=\"wide\",\n    initial_sidebar_state=\"collapsed\",\n)\nst.sidebar.button(\"Sidebar!\")\nst.markdown(\"Main!\")\n\n\ndef show_balloons():\n    st.balloons()\n\n\nst.button(\"Balloons\", on_click=show_balloons)\n\n\ndef double_set_page_config():\n    st.set_page_config(\n        page_title=\"Change 1\",\n        page_icon=\":shark:\",\n        layout=\"wide\",\n        initial_sidebar_state=\"collapsed\",\n    )\n\n    st.set_page_config(\n        page_title=\"Change 2\",\n        page_icon=\":shark:\",\n        layout=\"wide\",\n        initial_sidebar_state=\"collapsed\",\n    )\n\n\nst.button(\"Double Set Page Config\", on_click=double_set_page_config)\n\n\ndef single_set_page_config():\n    st.set_page_config(\n        page_title=\"Change 3\",\n        page_icon=\":shark:\",\n        layout=\"wide\",\n        initial_sidebar_state=\"collapsed\",\n    )\n\n\nst.button(\"Single Set Page Config\", on_click=single_set_page_config)\n", "e2e/scripts/st_session_state.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\nfrom streamlit import runtime\n\n# st.session_state can only be accessed while running with streamlit\nif runtime.exists():\n    if \"initialized\" not in st.session_state:\n        st.session_state[\"item_counter\"] = 0\n        st.session_state.attr_counter = 0\n\n        st.session_state.initialized = True\n\n    if st.button(\"inc_item_counter\"):\n        st.session_state[\"item_counter\"] += 1\n\n    if st.button(\"inc_attr_counter\"):\n        st.session_state.attr_counter += 1\n\n    if st.button(\"del_item_counter\"):\n        del st.session_state[\"item_counter\"]\n\n    if st.button(\"del_attr_counter\"):\n        del st.session_state.attr_counter\n\n    if \"item_counter\" in st.session_state:\n        st.write(f\"item_counter: {st.session_state['item_counter']}\")\n\n    if \"attr_counter\" in st.session_state:\n        st.write(f\"attr_counter: {st.session_state.attr_counter}\")\n\n    st.write(f\"len(st.session_state): {len(st.session_state)}\")\n    st.write(st.session_state)\n", "e2e/scripts/hostframe/hostframe_app.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport time\n\nimport streamlit as st\n\nst.slider(\"Enter a number\", 0, 20, 0)\nst.checkbox(\"Check me out\", value=True)\nst.radio(\"Radio Widget\", [\"Option 1\", \"Option 2\", \"Option 3\"])\n\nwith st.sidebar:\n    st.write(\"Hello sidebar\")\n\n# Allows for testing of script re-run / stop behavior\ntime.sleep(3)\n", "e2e/scripts/hostframe/pages/02_App_Page_2.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\nst.header(\"Page 2\")\n", "e2e/scripts/hostframe/pages/03_App_Page_3.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\nst.header(\"Page 3\")\n", ".github/scripts/build_info.py": "#!/usr/bin/env python\n# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\"\nGenerates variables that are needed to execute the Github Action build.\n\nThe description of the variables is in the\n`.github/actions/build_info/action.yml` file, but variables are also available\nin other contexts.\n\nVariables are saved in 3 places to handle 3 use cases:\n- The file specified by the GITHUB_OUTPUT environment variable, which\n  means the values will be available in the GitHub expression.\n  This allows us to have values when communicating between jobs.\n  For details, see:\n  https://docs.github.com/en/actions/using-workflows/workflow-commands-for-github-actions#setting-an-output-parameter\n- The file specified by the GITHUB_ENV environment variable, which\n  means the values will be available for other tools run in the following step\n  of the same job as environment variable.\n  For details, see:\n  https://docs.github.com/en/actions/using-workflows/workflow-commands-for-github-actions#setting-an-environment-variable\n- The standard output, which means the values will be available in the GitHub logs,\n  making troubleshooting easier.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport enum\nimport fnmatch\nimport json\nimport os\nimport subprocess\nimport sys\n\nif __name__ not in (\"__main__\", \"__mp_main__\"):\n    raise SystemExit(\n        \"This file is intended to be executed as an executable program. You cannot use \"\n        f\"it as a module. To run this script, run the ./{__file__} command\"\n    )\n\nGITHUB_CONTEXT_ENV_VAR = \"GITHUB_CONTEXT\"\nGITHUB_INPUTS_ENV_VAR = \"GITHUB_INPUTS\"\nGITHUB_OUTPUT_ENV_VAR = \"GITHUB_OUTPUT\"\nGITHUB_ENV_ENV_VAR = \"GITHUB_ENV\"\n\nREQUIRED_ENV_VAR = (\n    [\n        GITHUB_CONTEXT_ENV_VAR,\n        GITHUB_INPUTS_ENV_VAR,\n        GITHUB_OUTPUT_ENV_VAR,\n        GITHUB_ENV_ENV_VAR,\n    ]\n    if \"CI\" in os.environ\n    else [GITHUB_CONTEXT_ENV_VAR]\n)\n# The walrus operator requires Python 3.8 or newer\nif missing_envs := [\n    env_var for env_var in REQUIRED_ENV_VAR if env_var not in os.environ\n]:\n    raise SystemExit(f\"Missing environment variables: {', '.join(missing_envs)}\")\n\n\nFILES_WITH_PYTHON_DEPENDENCIES = [\n    \"lib/dev-requirements.txt\",\n    \"lib/test-requirements*.txt\",\n    \"lib/setup.py\",\n]\n# +1 to make range inclusive.\nALL_PYTHON_VERSIONS = [f\"3.{d}\" for d in range(8, 12 + 1)]\nPYTHON_MIN_VERSION = ALL_PYTHON_VERSIONS[0]\nPYTHON_MAX_VERSION = ALL_PYTHON_VERSIONS[-1]\n\n# To avoid the need to update the protected branch, we replace the boundary\n# values with fixed literal. We map it to real values in the Github workflow.\nALL_PYTHON_VERSIONS[0] = \"min\"\nALL_PYTHON_VERSIONS[-1] = \"max\"\n\nLABEL_FULL_MATRIX = \"dev:full-matrix\"\nLABEL_UPGRADE_DEPENDENCIES = \"dev:upgrade-dependencies\"\n\nGITHUB_CONTEXT = json.loads(os.environ[GITHUB_CONTEXT_ENV_VAR])\nGITHUB_EVENT = GITHUB_CONTEXT[\"event\"]\nGITHUB_EVENT_NAME = GITHUB_CONTEXT[\"event_name\"]\n\n\nclass GithubEvent(enum.Enum):\n    PULL_REQUEST = \"pull_request\"\n    PUSH = \"push\"\n    SCHEDULE = \"schedule\"\n\n\ndef get_changed_files() -> list[str]:\n    \"\"\"\n    Checks the modified files in the last commit.\n\n    Note that GITHUB_SHA for pull_request event is the last merge commit of the pull\n    request merge branch, which means that the last commit for a pull request always\n    lists all files modified by PR.\n\n    This script required the repository to have at least two recent commits checked\n    out, which means that Github Action actions/checkout must set the a parameter\n    fetch-depth to a value equal or greater than 2.\n\n    Example:\n\n      - name: Checkout Streamlit code\n        uses: actions/checkout@v3\n        with:\n          fetch-depth: 2\n    \"\"\"\n    git_output = subprocess.check_output(\n        [\n            \"git\",\n            \"diff-tree\",\n            \"--no-commit-id\",\n            \"--name-only\",\n            \"-r\",\n            \"HEAD^\",\n            \"HEAD\",\n        ]\n    )\n    return [line for line in git_output.decode().splitlines() if line]\n\n\ndef get_current_pr_labels() -> list[str]:\n    \"\"\"\n    Returns a list of all tags associated with the current PR.\n\n    Note that this function works only when the current event is `pull_request`.\n    \"\"\"\n    if GITHUB_EVENT_NAME != GithubEvent.PULL_REQUEST.value:\n        raise Exception(\n            f\"Invalid github event. \"\n            f\"Current value: {GITHUB_EVENT_NAME}. \"\n            f\"Expected state: {GithubEvent.PULL_REQUEST.value}\"\n        )\n    return [label[\"name\"] for label in GITHUB_EVENT[\"pull_request\"].get(\"labels\", [])]\n\n\ndef get_changed_python_dependencies_files() -> list[str]:\n    \"\"\"\n    Gets a list of files that contain Python dependency definitions and have\n    been modified.\n    \"\"\"\n    changed_files = get_changed_files()\n    changed_dependencies_files = sorted(\n        path\n        for pattern in FILES_WITH_PYTHON_DEPENDENCIES\n        for path in fnmatch.filter(changed_files, pattern)\n    )\n    return changed_dependencies_files\n\n\ndef check_if_pr_has_label(label: str, action: str) -> bool:\n    \"\"\"\n    Checks if the PR has the given label.\n\n    The function works for all GitHub events, but returns false\n    for any event that is not a PR.\n    \"\"\"\n    if GITHUB_EVENT_NAME == GithubEvent.PULL_REQUEST.value:\n        pr_labels = get_current_pr_labels()\n        if label in pr_labels:\n            print(f\"PR has the following labels: {pr_labels}\")\n            print(f\"{action}, because PR has {label !r} label.\")\n            return True\n    return False\n\n\ndef get_github_input(input_key: str) -> str | None:\n    \"\"\"\n    Get additional data that the script expects to use during runtime.\n\n    For details, see: https://docs.github.com/en/actions/creating-actions/metadata-syntax-for-github-actions#inputs\n    \"\"\"\n    if GITHUB_INPUTS_ENV_VAR not in os.environ:\n        return None\n    inputs = json.loads(os.environ[GITHUB_INPUTS_ENV_VAR]) or {}\n    input_value = inputs.get(input_key)\n    return input_value\n\n\ndef is_canary_build() -> bool:\n    \"\"\"\n    Checks whether current build is canary.\n\n    Canary builds are tested on all Python versions and do not use constraints.\n    Non-canary builds are tested by default on the oldest and latest Python versions\n    and use constraints files by default.\n\n    The behavior depends on what event triggered the current GitHub Action build to run.\n\n    For pull_request event, we return true when Python dependencies have been modified\n    In other case, we return false.\n\n    For push event, we return true when the default branch is checked. In other case,\n    we return false.\n\n    For scheduled event, we always return true.\n\n    For other events, we return false\n\n    Build canary can be enforced by workflow inputs parameter e.g. all \"Build Release\"\n    workflows trigger canary builds.\n    \"\"\"\n    force_canary_input = get_github_input(\"force-canary\") or \"false\"\n    if force_canary_input.lower() == \"true\":\n        print(\"Current build is canary, because it is enforced by input\")\n        return True\n    if GITHUB_EVENT_NAME == GithubEvent.PULL_REQUEST.value:\n        changed_dependencies_files = get_changed_python_dependencies_files()\n        if changed_dependencies_files:\n            print(f\"{len(changed_dependencies_files)} files changed in this build.\")\n            print(\n                \"Current build is canary, \"\n                \"because the following files have been modified:\"\n            )\n            print(\"- \" + \"- \".join(changed_dependencies_files))\n            return True\n        return False\n    elif GITHUB_EVENT_NAME == GithubEvent.PUSH.value:\n        default_branch = GITHUB_EVENT[\"repository\"][\"default_branch\"]\n        is_default_branch = (\n            GITHUB_CONTEXT[\"ref_type\"] == \"branch\"\n            and default_branch == GITHUB_CONTEXT[\"ref_name\"]\n        )\n        if is_default_branch:\n            print(\n                \"Current build is canary, \"\n                f\"because the default branch ({default_branch!r}) is checked.\"\n            )\n            return True\n        return False\n    elif GITHUB_EVENT_NAME == GithubEvent.SCHEDULE.value:\n        print(\n            \"Current build is canary, \"\n            f\"because current github event name is {GITHUB_EVENT_NAME!r}\"\n        )\n        return True\n\n    print(\n        \"Current build is NOT canary, \"\n        f\"because current github event name is {GITHUB_EVENT_NAME!r}\"\n    )\n    return False\n\n\ndef get_output_variables() -> dict[str, str]:\n    \"\"\"\n    Compute build variables.\n    \"\"\"\n    canary_build = is_canary_build()\n    python_versions = (\n        ALL_PYTHON_VERSIONS\n        if canary_build\n        or check_if_pr_has_label(\n            LABEL_FULL_MATRIX, \"All Python versions will be tested\"\n        )\n        else [ALL_PYTHON_VERSIONS[0], ALL_PYTHON_VERSIONS[-1]]\n    )\n    use_constraints_file = not (\n        canary_build\n        or check_if_pr_has_label(\n            LABEL_UPGRADE_DEPENDENCIES, \"Latest dependencies will be used\"\n        )\n    )\n    variables = {\n        \"PYTHON_MIN_VERSION\": PYTHON_MIN_VERSION,\n        \"PYTHON_MAX_VERSION\": PYTHON_MAX_VERSION,\n        \"PYTHON_VERSIONS\": json.dumps(python_versions),\n        \"USE_CONSTRAINTS_FILE\": str(use_constraints_file).lower(),\n    }\n    # Environment variables can be overridden at job level and we don't want\n    # to change them then.\n    for key, value in variables.copy().items():\n        variables[key] = os.environ.get(key, value)\n    return variables\n\n\ndef save_output_variables(variables: dict[str, str]) -> None:\n    \"\"\"\n    Saves build variables\n    \"\"\"\n    print(\"Saving output variables\")\n    with open(\n        os.environ.get(GITHUB_ENV_ENV_VAR, \"/dev/null\"), \"w+\"\n    ) as github_env_file, open(\n        os.environ.get(GITHUB_OUTPUT_ENV_VAR, \"/dev/null\"), \"w+\"\n    ) as github_output_file:\n        for target_file in [sys.stdout, github_env_file, github_output_file]:\n            for name, value in variables.items():\n                target_file.write(f\"{name}={value}\\n\")\n            target_file.flush()\n\n\ndef main() -> None:\n    print(f\"Current github event name: {GITHUB_EVENT_NAME!r}\")\n    output_variables = get_output_variables()\n    save_output_variables(output_variables)\n\n\nmain()\n", "scripts/update_name.py": "#!/usr/bin/env python\n\n# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Update project name across the entire repo.\n\nThe streamlit-nightly CI job uses this to set the project name to \"streamlit-nightly\".\n\"\"\"\n\nimport fileinput\nimport os\nimport re\nimport sys\nfrom typing import Dict\n\nBASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\"))\n\n# A dict of [filename:regex]. For each filename, we modify all lines\n# matched by the regex.\n#\n# Regexes should start with a \"<pre_match>\" named group and end with a\n# \"<post_match>\" named group. Text between these pre- and post-match\n# groups will be replaced with the specified project_name text.\nFILES_AND_REGEXES = {\n    \"lib/setup.py\": r\"(?P<pre_match>.*name=\\\").*(?P<post_match>\\\")\",\n    \"lib/streamlit/version.py\": r\"(?P<pre_match>.*_version\\(\\\").*(?P<post_match>\\\"\\)$)\",\n}\n\n\ndef update_files(project_name: str, files: Dict[str, str]) -> None:\n    \"\"\"Update files with new project name.\"\"\"\n    for filename, regex in files.items():\n        filename = os.path.join(BASE_DIR, filename)\n        matched = False\n        pattern = re.compile(regex)\n        for line in fileinput.input(filename, inplace=True):\n            line = line.rstrip()\n            if pattern.match(line):\n                line = re.sub(\n                    regex, rf\"\\g<pre_match>{project_name}\\g<post_match>\", line\n                )\n                matched = True\n            print(line)\n        if not matched:\n            raise Exception(f'In file \"{filename}\", did not find regex \"{regex}\"')\n\n\ndef main() -> None:\n    if len(sys.argv) != 2:\n        raise Exception(f'Specify project name, e.g: \"{sys.argv[0]} streamlit-nightly\"')\n    project_name = sys.argv[1]\n    update_files(project_name, FILES_AND_REGEXES)\n\n\nif __name__ == \"__main__\":\n    main()\n", "scripts/get_min_versions.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# This script should be invoked using `make gen-min-dep-constraints`.\n# It has the precondition that you must have installed streamlit locally since\n# you last updated its dependencies, which the make command takes care of.\n\n# based on https://stackoverflow.com/a/59711270\nimport pkg_resources\n\npackage = pkg_resources.working_set.find(pkg_resources.Requirement.parse(\"streamlit\"))\n\noldest_dependencies = []\n\nfor requirement in package.requires():  # type: ignore\n    dependency = requirement.project_name\n    if requirement.extras:\n        dependency += \"[\" + \",\".join(requirement.extras) + \"]\"\n    # We will see both the lower bound and upper bound parts of each requriment\n    # So we ignore the ones that aren't the lower bound.\n    for comparator, version in requirement.specs:\n        if comparator == \"==\":\n            if len(requirement.specs) != 1:\n                raise ValueError(f\"Invalid dependency: {requirement}\")\n            dependency += \"==\" + version\n        elif comparator == \"<=\":\n            if len(requirement.specs) != 2:\n                raise ValueError(f\"Invalid dependency: {requirement}\")\n        elif comparator == \">=\":\n            dependency += \"==\" + version\n\n    oldest_dependencies.append(dependency)\n\nfor dependency in sorted(oldest_dependencies):\n    print(dependency)\n", "scripts/update_emojis.py": "#!/usr/bin/env python\n\n# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Update the list of emojis in `lib/streamlit/emojis.py.\n\nThis script requires the emoji package to be installed: pip install emoji.\n\"\"\"\n\nimport os\nimport re\n\nfrom emoji.unicode_codes.data_dict import EMOJI_DATA\nfrom streamlit.emojis import ALL_EMOJIS\n\nBASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\"))\nEMOJI_SET_REGEX = re.compile(r\"### EMOJIS START ###(.+?)### EMOJIS END ###\", re.DOTALL)\nEMOJIS_SCRIPT_PATH = os.path.join(BASE_DIR, \"lib\", \"streamlit\", \"emojis.py\")\n\nemoji_unicodes = set(EMOJI_DATA.keys())\n\nprint(f\"Existing emoji collection: {len(ALL_EMOJIS)}\")\nprint(f\"New emoji collection:  {len(emoji_unicodes)}\")\n\ngenerated_code = f\"\"\"### EMOJIS START ###\nALL_EMOJIS = {{{\", \".join([f'\"{emoji}\"' for emoji in sorted(emoji_unicodes)])}}}\n### EMOJIS END ###\"\"\"\n\nwith open(EMOJIS_SCRIPT_PATH, \"r\") as file:\n    script_content = file.read()\n\nupdated_script_content = re.sub(EMOJI_SET_REGEX, generated_code, script_content)\n\nwith open(EMOJIS_SCRIPT_PATH, \"w\") as file:\n    file.write(updated_script_content)\n", "scripts/slack_notifications.py": "#!/usr/bin/env python\n# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Send slack notifications\"\"\"\n\nimport os\nimport sys\n\nimport requests\n\n\ndef send_notification():\n    \"\"\"Create a slack message\"\"\"\n\n    webhook = os.getenv(\"SLACK_WEBHOOK\")\n\n    if not webhook:\n        raise Exception(\"Unable to retrieve SLACK_WEBHOOK\")\n\n    nightly_slack_messages = {\n        \"tag\": \"to create a tag\",\n        \"python\": \"on python tests\",\n        \"js\": \"on javascript tests\",\n        \"py_prod\": \"on python prod dependencies test\",\n        \"cypress\": \"on cypress tests\",\n        \"playwright\": \"on playwright tests\",\n        \"build\": \"to release\",\n    }\n\n    run_id = os.getenv(\"RUN_ID\")\n    workflow = sys.argv[1]\n    message_key = sys.argv[2]\n    payload = None\n\n    if workflow == \"nightly\":\n        failure = nightly_slack_messages[message_key]\n        payload = {\n            \"text\": f\":blobonfire: Nightly build failed {failure} - <https://github.com/streamlit/streamlit/actions/runs/{run_id}|Link to run>\"\n        }\n\n    if workflow == \"candidate\":\n        if message_key == \"success\":\n            payload = {\"text\": \":rocket: Release Candidate was successful!\"}\n        else:\n            payload = {\n                \"text\": f\":blobonfire: Release Candidate failed - <https://github.com/streamlit/streamlit/actions/runs/{run_id}|Link to run>\"\n            }\n\n    if workflow == \"release\":\n        if message_key == \"success\":\n            payload = {\"text\": \":rocket: Release was successful!\"}\n        else:\n            payload = {\n                \"text\": f\":blobonfire: Release failed - <https://github.com/streamlit/streamlit/actions/runs/{run_id}|Link to run>\"\n            }\n\n    if payload:\n        response = requests.post(webhook, json=payload)\n\n        if response.status_code != 200:\n            raise Exception(\n                f\"Unable to send slack message, HTTP response: {response.text}\"\n            )\n\n\ndef main():\n    send_notification()\n\n\nif __name__ == \"__main__\":\n    main()\n", "scripts/update_version.py": "#!/usr/bin/env python\n\n# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Update version number across the entire repo.\n\nIf the current version is 0.15.2 and I wanted to create a release for\nlocal development, ie make a wheel file and make either a conda or pex\npackage to test on OSX or linux.  What should I call the next version?\n\nIf its a patch change, then only the third number being edited. If\nits a minor change then its the second number.  In this example, we're\ndoing a patch change.\n\nThe public released dev version would be\n0.15.3-dev0\n\nFor local development it would be\n0.15.3-dev0+USERNAME0\n\nIf you iterate your local dev version it would then be\n0.15.3-dev0+USERNAME1\n\nYou then release it for testing.\n0.15.3-dev0\n\nSomeone finds a bug so you release a new internal version for testing.\n0.15.3-dev1+USERNAME0\n\nThen we can go to alpha, rc1, rc2, etc. but eventually its\n0.15.3\n\"\"\"\n\nimport fileinput\nimport os\nimport re\nimport sys\n\nimport packaging.version\nimport semver\n\nBASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\"))\n\n# Warning: Advanced regex foo.\n# If another file has a version number that needs updating, add it here.\n# These regex's are super greedy in that it actually matches everything\n# but the version number so we can throw any valid PEP440 version in\n# there.\nPYTHON = {\"lib/setup.py\": r\"(?P<pre>.*VERSION = \\\").*(?P<post>\\\"  # PEP-440$)\"}\n\n# This regex captures the \"version\": field in a JSON-like structure\n# allowing for any amount of whitespace before the \"version\": field.\nNODE_ROOT = {\"frontend/package.json\": r'(?P<pre>^ \\s*\"version\": \").*(?P<post>\",$)'}\nNODE_APP = {\"frontend/app/package.json\": r'(?P<pre>^ \\s*\"version\": \").*(?P<post>\",$)'}\nNODE_LIB = {\"frontend/lib/package.json\": r'(?P<pre>^ \\s*\"version\": \").*(?P<post>\",$)'}\n\n# This regex captures the \"@streamlit/lib\": field in a JSON-like structure\n# allowing for any amount of whitespace before the \"version\": field.\nNODE_APP_ST_LIB = {\n    \"frontend/app/package.json\": r'(?P<pre>^ \\s*\"@streamlit/lib\": \").*(?P<post>\",$)'\n}\n\n\ndef verify_pep440(version):\n    \"\"\"Verify if version is PEP440 compliant.\n\n    https://github.com/pypa/packaging/blob/16.7/packaging/version.py#L191\n\n    We might need pre, post, alpha, rc in the future so might as well\n    use an object that does all that.  This verifies its a valid\n    version.\n    \"\"\"\n\n    try:\n        return packaging.version.Version(version)\n    except packaging.version.InvalidVersion as e:\n        raise (e)\n\n\ndef verify_semver(version):\n    \"\"\"Verify if version is compliant with semantic versioning.\n\n    https://semver.org/\n    \"\"\"\n\n    try:\n        return str(semver.VersionInfo.parse(version))\n    except ValueError as e:\n        raise (e)\n\n\ndef update_files(data, version):\n    \"\"\"Update files with new version number.\"\"\"\n\n    for filename, regex in data.items():\n        filename = os.path.join(BASE_DIR, filename)\n        matched = False\n        pattern = re.compile(regex)\n        for line in fileinput.input(filename, inplace=True):\n            if pattern.match(line.rstrip()):\n                matched = True\n            line = re.sub(regex, r\"\\g<pre>%s\\g<post>\" % version, line.rstrip())\n            print(line)\n        if not matched:\n            raise Exception('In file \"%s\", did not find regex \"%s\"' % (filename, regex))\n\n\ndef main():\n    \"\"\"Run main loop.\"\"\"\n\n    if len(sys.argv) != 2:\n        e = Exception(\n            'Specify semvver version as an argument, e.g.: \"%s 1.2.3\"' % sys.argv[0]\n        )\n        raise (e)\n\n    # We need two flavors of the version - one that's semver-compliant for Node, one that's\n    # PEP440-compliant for Python. We allow for the incoming version to be either semver-compliant\n    # PEP440-compliant.\n    # - `verify_pep440` automatically converts semver to PEP440-compliant\n    pep440_version = verify_pep440(sys.argv[1])\n\n    # - Attempt to convert to semver-compliant. If a failure occurs, manually attempt to convert.\n    semver_version = None\n    try:\n        semver_version = verify_semver(sys.argv[1])\n    except ValueError:\n        semver_version = verify_semver(\n            sys.argv[1].replace(\"rc\", \"-rc.\").replace(\".dev\", \"-dev\")\n        )\n\n    update_files(PYTHON, pep440_version)\n    update_files(NODE_ROOT, semver_version)\n    update_files(NODE_APP, semver_version)\n    update_files(NODE_LIB, semver_version)\n    update_files(NODE_APP_ST_LIB, semver_version)\n\n\nif __name__ == \"__main__\":\n    main()\n", "scripts/run_in_subdirectory.py": "#!/usr/bin/env python\n# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport subprocess\nimport sys\nimport textwrap\nfrom pathlib import Path\nfrom typing import List, Tuple\n\nif __name__ not in (\"__main__\", \"__mp_main__\"):\n    raise SystemExit(\n        \"This file is intended to be executed as an executable program. You cannot use \"\n        \"it as a module.To run this script, run the ./{__file__} command\"\n    )\n\n\ndef is_relative_to(path: Path, *other):\n    \"\"\"Return True if the path is relative to another path or False.\n\n    This function is backported from Python 3.9 - Path.relativeto.\n    \"\"\"\n    try:\n        path.relative_to(*other)\n        return True\n    except ValueError:\n        return False\n\n\ndef display_usage():\n    prog = Path(__file__).name\n    print(\n        textwrap.dedent(\n            f\"\"\"\\\n    usage: {prog} [-h] SUBDIRECTORY ARGS [ARGS ...]\n\n    Runs the program in a subdirectory and fix paths in arguments.\n\n    example:\n\n    When this program is executed with the following command:\n       {prog} frontend/ yarn eslint frontend/src/index.ts\n    Then the command will be executed:\n        yarn eslint src/index.ts\n    and the current working directory will be set to frontend/\n\n    positional arguments:\n      SUBDIRECTORY  subdirectory within which the subprocess will be executed\n      ARGS  sequence of program arguments\n\n    optional arguments:\n      -h, --help    show this help message and exit\\\n    \"\"\"\n        )\n    )\n\n\ndef parse_args() -> Tuple[str, List[str]]:\n    if len(sys.argv) == 2 and sys.argv[1] in (\"-h\", \"--help\"):\n        display_usage()\n        sys.exit(0)\n    if len(sys.argv) < 3:\n        print(\"Missing arguments\")\n        display_usage()\n        sys.exit(1)\n    print(sys.argv)\n\n    return sys.argv[1], sys.argv[2:]\n\n\ndef fix_arg(subdirectory: str, arg: str) -> str:\n    arg_path = Path(arg)\n    if not (arg_path.exists() and is_relative_to(arg_path, subdirectory)):\n        return arg\n    return str(arg_path.relative_to(subdirectory))\n\n\ndef try_as_shell(fixed_args: List[str], subdirectory: str):\n    # Windows doesn't know how to run \"yarn\" using the CreateProcess\n    # WINAPI because it's looking for an executable, and yarn is a node script.\n    # Yarn happens to be the only thing currently run with this patching script,\n    # so add a fall-back which tries to run the requested command in a shell\n    # if directly calling the process doesn't work.\n\n    print(\"Direct call failed, trying as shell command:\")\n    shell_cmd = \" \".join(fixed_args)\n    print(shell_cmd)\n    try:\n        subprocess.run(shell_cmd, cwd=subdirectory, check=True, shell=True)\n    except subprocess.CalledProcessError as ex:\n        sys.exit(ex.returncode)\n\n\ndef main():\n    subdirectory, subprocess_args = parse_args()\n\n    fixed_args = [fix_arg(subdirectory, arg) for arg in subprocess_args]\n    try:\n        subprocess.run(fixed_args, cwd=subdirectory, check=True)\n    except subprocess.CalledProcessError as ex:\n        sys.exit(ex.returncode)\n    except FileNotFoundError:\n        if \"win32\" in sys.platform:\n            try_as_shell(fixed_args, subdirectory)\n        else:\n            sys.exit(1)\n\n\nmain()\n", "scripts/pypi_nightly_create_tag.py": "#!/usr/bin/env python\n\n# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Create a tag for the PYPI nightly version\n\nIncrement the version number, add a dev suffix and add todays date\n\"\"\"\n\nfrom datetime import datetime\n\nimport packaging.version\nimport pytz\nfrom packaging.version import Version\n\nPYPI_STREAMLIT_URL = \"https://pypi.org/pypi/streamlit/json\"\n\n\ndef get_latest_streamlit_version() -> Version:\n    \"\"\"Request the latest streamlit version string from PyPI.\n\n    NB: this involves a network call, so it could raise an error\n    or take a long time.\n\n    Parameters\n    ----------\n    timeout : float or None\n        The request timeout.\n\n    Returns\n    -------\n    str\n        The version string for the latest version of streamlit\n        on PyPI.\n\n    \"\"\"\n    import requests\n\n    rsp = requests.get(PYPI_STREAMLIT_URL)\n    try:\n        version_str = rsp.json()[\"info\"][\"version\"]\n    except Exception as e:\n        raise RuntimeError(\"Got unexpected response from PyPI\", e)\n    return Version(version_str)\n\n\ndef create_tag():\n    \"\"\"Create tag with updated version, a suffix and date.\"\"\"\n\n    # Get latest version\n    current_version = get_latest_streamlit_version()\n\n    # Update micro\n    version_with_inc_micro = (\n        current_version.major,\n        current_version.minor,\n        current_version.micro + 1,\n    )\n\n    # Append todays date\n    version_with_date = (\n        \".\".join([str(x) for x in version_with_inc_micro])\n        + \".dev\"\n        + datetime.now(pytz.timezone(\"US/Pacific\")).strftime(\"%Y%m%d\")\n    )\n\n    # Verify if version is PEP440 compliant.\n    packaging.version.Version(version_with_date)\n\n    return version_with_date\n\n\nif __name__ == \"__main__\":\n    tag = create_tag()\n\n    # Print so we can access the tag in the shell\n    print(tag)\n", "scripts/audit_frontend_licenses.py": "#!/usr/bin/env python\n# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Audit the licenses of all our frontend dependencies (as defined by our\n`yarn.lock` file). If any dependency has an unacceptable license, print it\nout and exit with an error code. If all dependencies have acceptable licenses,\nexit normally.\n\"\"\"\n\nimport json\nimport subprocess\nimport sys\nfrom pathlib import Path\nfrom typing import NoReturn, Set, Tuple, cast\n\nfrom typing_extensions import TypeAlias\n\nPackageInfo: TypeAlias = Tuple[str, str, str, str, str, str]\n\nSCRIPT_DIR = Path(__file__).resolve().parent\nFRONTEND_DIR_LIB = SCRIPT_DIR.parent / \"frontend/lib\"\nFRONTEND_DIR_APP = SCRIPT_DIR.parent / \"frontend/app\"\n\n# Set of acceptable licenses. If a library uses one of these licenses,\n# we can include it as a dependency.\nACCEPTABLE_LICENSES = {\n    \"MIT\",  # https://opensource.org/licenses/MIT\n    \"Apache-2.0\",  # https://opensource.org/licenses/Apache-2.0\n    \"Apache-2.0 WITH LLVM-exception\",  # https://spdx.org/licenses/LLVM-exception.html\n    \"0BSD\",  # https://opensource.org/licenses/0BSD\n    \"BlueOak-1.0.0\",  # https://blueoakcouncil.org/license/1.0.0\n    \"BSD-2-Clause\",  # https://opensource.org/licenses/BSD-2-Clause\n    \"BSD-3-Clause\",  # https://opensource.org/licenses/BSD-3-Clause\n    \"ISC\",  # https://opensource.org/licenses/ISC\n    \"CC0-1.0\",  # https://creativecommons.org/publicdomain/zero/1.0/\n    \"CC-BY-3.0\",  # https://creativecommons.org/licenses/by/3.0/\n    \"CC-BY-4.0\",  # https://creativecommons.org/licenses/by/4.0/\n    \"Python-2.0\",  # https://www.python.org/download/releases/2.0/license/\n    \"Zlib\",  # https://opensource.org/licenses/Zlib\n    \"Unlicense\",  # https://unlicense.org/\n    \"WTFPL\",  # http://www.wtfpl.net/about/\n    # Multi-licenses are acceptable if at least one of the licenses is acceptable.\n    \"(MIT OR Apache-2.0)\",\n    \"(MPL-2.0 OR Apache-2.0)\",\n    \"(MIT OR CC0-1.0)\",\n    \"(Apache-2.0 OR MPL-1.1)\",\n    \"(BSD-3-Clause OR GPL-2.0)\",\n    \"(MIT AND BSD-3-Clause)\",\n    \"(MIT AND Zlib)\",\n    \"(WTFPL OR MIT)\",\n    \"(AFL-2.1 OR BSD-3-Clause)\",\n    \"(BSD-2-Clause OR MIT OR Apache-2.0)\",\n}\n\n# Some of our dependencies have licenses that yarn fails to parse, but that\n# are still acceptable. This set contains all those exceptions. Each entry\n# should include a comment about why it's an exception.\nPACKAGE_EXCEPTIONS: Set[PackageInfo] = {\n    (\n        # MIT license: https://github.com/mapbox/jsonlint\n        \"@mapbox/jsonlint-lines-primitives\",\n        \"2.0.2\",\n        \"UNKNOWN\",\n        \"git://github.com/mapbox/jsonlint.git\",\n        \"http://zaa.ch\",\n        \"Zach Carter\",\n    ),\n    (\n        # Apache 2.0 license: https://github.com/google/flatbuffers\n        \"flatbuffers\",\n        \"23.5.26\",\n        \"SEE LICENSE IN LICENSE\",\n        \"git+https://github.com/google/flatbuffers.git\",\n        \"https://google.github.io/flatbuffers/\",\n        \"The FlatBuffers project\",\n    ),\n    (\n        # Mapbox Web SDK license: https://github.com/mapbox/mapbox-gl-js/blob/main/LICENSE.txt\n        \"@plotly/mapbox-gl\",\n        \"1.13.4\",\n        \"SEE LICENSE IN LICENSE.txt\",\n        \"git://github.com/plotly/mapbox-gl-js.git\",\n        \"Unknown\",\n        \"Unknown\",\n    ),\n    (\n        # Mapbox Web SDK license: https://github.com/mapbox/mapbox-gl-js/blob/main/LICENSE.txt\n        \"mapbox-gl\",\n        \"1.13.3\",\n        \"SEE LICENSE IN LICENSE.txt\",\n        \"git://github.com/mapbox/mapbox-gl-js.git\",\n        \"Unknown\",\n        \"Unknown\",\n    ),\n    (\n        # CC-BY-3.0 license: https://github.com/cartodb/cartocolor#licensing\n        \"cartocolor\",\n        \"4.0.2\",\n        \"UNKNOWN\",\n        \"https://github.com/cartodb/cartocolor\",\n        \"http://carto.com/\",\n        \"Unknown\",\n    ),\n    (\n        # Apache-2.0 license: https://github.com/saikocat/colorbrewer/blob/master/LICENSE.txt\n        \"colorbrewer\",\n        \"1.0.0\",\n        \"Apache*\",\n        \"https://github.com/saikocat/colorbrewer\",\n        \"http://colorbrewer2.org/\",\n        \"Cynthia Brewer\",\n    ),\n}\n\n\ndef get_license_type(package: PackageInfo) -> str:\n    \"\"\"Return the license type string for a dependency entry.\"\"\"\n    return package[2]\n\n\ndef check_licenses(licenses) -> NoReturn:\n    # `yarn licenses` outputs a bunch of lines.\n    # The last line contains the JSON object we care about\n    licenses_json = json.loads(licenses[len(licenses) - 1])\n    assert licenses_json[\"type\"] == \"table\"\n\n    # Pull out the list of package infos from the JSON.\n    packages = [\n        cast(PackageInfo, tuple(package)) for package in licenses_json[\"data\"][\"body\"]\n    ]\n\n    # Discover dependency exceptions that are no longer used and can be\n    # jettisoned, and print them out with a warning.\n    unused_exceptions = PACKAGE_EXCEPTIONS.difference(set(packages))\n    if len(unused_exceptions) > 0:\n        for exception in sorted(list(unused_exceptions)):\n            print(f\"Unused package exception, please remove: {exception}\")\n\n    # Discover packages that don't have an acceptable license, and that don't\n    # have an explicit exception. If we have any, we print them out and exit\n    # with an error.\n    bad_packages = [\n        package\n        for package in packages\n        if (get_license_type(package) not in ACCEPTABLE_LICENSES)\n        and (package not in PACKAGE_EXCEPTIONS)\n        # workspace aggregator is yarn workspaces\n        and \"workspace-aggregator\" not in package[0]\n    ]\n\n    if len(bad_packages) > 0:\n        for package in bad_packages:\n            print(f\"Unacceptable license: '{get_license_type(package)}' (in {package})\")\n        print(f\"{len(bad_packages)} unacceptable licenses\")\n        sys.exit(1)\n\n    print(f\"No unacceptable licenses\")\n    sys.exit(0)\n\n\ndef main() -> NoReturn:\n    # Run `yarn licenses` for lib.\n    licenses_output = (\n        subprocess.check_output(\n            [\"yarn\", \"licenses\", \"list\", \"--json\", \"--production\", \"--ignore-platform\"],\n            cwd=str(FRONTEND_DIR_LIB),\n        )\n        .decode()\n        .splitlines()\n    )\n\n    # Run `yarn licenses` for app.\n    licenses_output = licenses_output + (\n        subprocess.check_output(\n            [\"yarn\", \"licenses\", \"list\", \"--json\", \"--production\", \"--ignore-platform\"],\n            cwd=str(FRONTEND_DIR_APP),\n        )\n        .decode()\n        .splitlines()\n    )\n\n    check_licenses(licenses_output)\n\n\nif __name__ == \"__main__\":\n    main()\n", "scripts/check_license_headers.py": "#!/usr/bin/env python\n\n# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport re\nimport subprocess\nimport sys\nfrom pathlib import Path\n\nif __name__ not in (\"__main__\", \"__mp_main__\"):\n    raise SystemExit(\n        \"This file is intended to be executed as an executable program. You cannot use \"\n        f\"it as a module.To run this script, run the ./{__file__} command\"\n    )\n\nSCRIPT_DIR = Path(__file__).resolve().parent\n# We just check if the first line of the license is in the file. This is\n# enough to check that the file is okay.\nLICENSE_TEXT = (SCRIPT_DIR / \"license-template.txt\").read_text().splitlines()[0]\n\nIGNORE_PATTERN = re.compile(\n    # Exclude CI files.\n    r\"^\\.(github)/\"\n    # Exclude images.\n    r\"|\\.(?:png|jpg|jpeg|gif|ttf|woff|otf|eot|woff2|ico|svg)$\"\n    # Exclude videos we use for testing st.video.\n    r\"|e2e_playwright/test_assets/.*\\.(mp4|webm)$\"\n    # Exclude subtitle files we use for testing st.video.\n    r\"|e2e_playwright/test_assets/.*\\.(vtt|srt)$\"\n    # Exclude js file we use for testing st.html.\n    r\"|^lib/tests/streamlit/elements/test_html\\.js\"\n    # Exclude files, because they make it obvious which product they relate to.\n    r\"|(LICENSE|NOTICES|CODE_OF_CONDUCT\\.md|README\\.md|CONTRIBUTING\\.md|SECURITY.md)$\"\n    # Exclude files, because they do not support comments\n    r\"|\\.(json|prettierrc|nvmrc)$\"\n    # Exclude generated files, because they don't have any degree of creativity.\n    r\"|yarn\\.lock$\"\n    # Exclude pytest config files, because they don't have any degree of creativity.\n    r\"|pytest\\.ini$\"\n    # Exclude empty files, because they don't have any degree of creativity.\n    r\"|py\\.typed$\"\n    # Exclude dev-tools configuration files, because they don't have any\n    # degree of creativity.\n    r\"|^(\\.dockerignore|\\.editorconfig|\\.gitignore|\\.gitmodules)$\"\n    r\"|^frontend/(\\.dockerignore|\\.eslintrc.js|\\.prettierignore)$\"\n    r\"|^lib/(\\.coveragerc|\\.dockerignore|MANIFEST\\.in|mypy\\.ini)$\"\n    r\"|^lib/(test|dev)-requirements\\.txt$\"\n    r\"|^lib/min-constraints-gen\\.txt\"\n    r\"|\\.isort\\.cfg$\"\n    r\"|\\.credentials/\\.gitignore$\"\n    # Excluding test files, because adding headers may cause tests to fail.\n    r\"|/(fixtures|__snapshots__|test_data|data)/\"\n    # Exclude vendored files.\n    r\"|/vendor/|^vendor/|^component-lib/declarations/apache-arrow\"\n    r\"|proto/streamlit/proto/openmetrics_data_model\\.proto\",\n    re.IGNORECASE,\n)\n\n\ndef main():\n    git_files = sorted(\n        subprocess.check_output([\"git\", \"ls-files\", \"--no-empty-directory\"])\n        .decode()\n        .strip()\n        .splitlines()\n    )\n\n    invalid_files_count = 0\n    for fileloc in git_files:\n        if IGNORE_PATTERN.search(fileloc):\n            continue\n        filepath = Path(fileloc)\n        # Exclude submodules\n        if not filepath.is_file():\n            continue\n\n        try:\n            file_content = filepath.read_text()\n            if LICENSE_TEXT not in file_content:\n                print(\"Found file without license header\", fileloc)\n                invalid_files_count += 1\n        except:\n            print(\n                f\"Failed to open the file: {fileloc}. Is it binary file?\",\n            )\n            invalid_files_count += 1\n\n    print(\"Invalid files count:\", invalid_files_count)\n    if invalid_files_count > 0:\n        sys.exit(1)\n\n\nmain()\n", "scripts/get_release_branch.py": "#!/usr/bin/env python\n# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Retrieve the branch name from the release PR\"\"\"\n\nimport requests\n\n\n# Assumes there is only one open pull request with a release/ branch\ndef check_for_release_pr(pull):\n    label = pull[\"head\"][\"label\"]\n\n    if label.find(\"release/\") != -1:\n        return pull[\"head\"][\"ref\"]\n\n\ndef get_release_branch():\n    \"\"\"Retrieve the release branch from the release PR\"\"\"\n\n    url = \"https://api.github.com/repos/streamlit/streamlit/pulls\"\n    response = requests.get(url).json()\n\n    # Response is in an array, must map over each pull (dict)\n    for pull in response:\n        ref = check_for_release_pr(pull)\n        if ref != None:\n            return ref\n\n\ndef main():\n    print(get_release_branch())\n\n\nif __name__ == \"__main__\":\n    main()\n", "scripts/create_release.py": "#!/usr/bin/env python\n# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Create a release using Github API\"\"\"\n\nimport os\n\nimport requests\n\n\ndef create_release():\n    \"\"\"Create a release from the Git Tag\"\"\"\n\n    tag = os.getenv(\"GIT_TAG\")\n    access_token = os.getenv(\"GH_TOKEN\")\n\n    if not tag:\n        raise Exception(\"Unable to retrieve GIT_TAG environment variable\")\n\n    url = \"https://api.github.com/repos/streamlit/streamlit/releases\"\n    header = {\"Authorization\": f\"token {access_token}\"}\n\n    # Get the latest release tag to compare against\n    response = requests.get(f\"{url}/latest\", headers=header)\n    previous_tag_name = None\n    if response.status_code == 200:\n        previous_tag_name = response.json()[\"tag_name\"]\n    else:\n        raise Exception(f\"Unable get the latest release: {response.text}\")\n\n    # Generate the automated release notes\n    payload = {\"tag_name\": tag, \"previous_tag_name\": previous_tag_name}\n    response = requests.post(f\"{url}/generate-notes\", json=payload, headers=header)\n    body = None\n    if response.status_code == 200:\n        body = response.json()[\"body\"]\n    else:\n        raise Exception(f\"Unable generate the latest release notes: {response.text}\")\n\n    # Create the release with the generated release notes\n    payload = {\"tag_name\": tag, \"name\": tag, \"body\": body}\n    response = requests.post(url, json=payload, headers=header)\n\n    if response.status_code == 201:\n        print(f\"Successfully created Release {tag}\")\n    else:\n        raise Exception(f\"Unable to create release, HTTP response: {response.text}\")\n\n\ndef main():\n    create_release()\n\n\nif __name__ == \"__main__\":\n    main()\n", "e2e_playwright/st_stop.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\nfrom streamlit import runtime\n\nst.text(\"Text before stop\")\n\n# Since st.stop() throws an intentional exception, we want this to run\n# only in streamlit\nif runtime.exists():\n    st.stop()\n\nst.text(\"Text after stop\")\n", "e2e_playwright/st_selectbox.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport pandas as pd\n\nimport streamlit as st\nfrom streamlit import runtime\n\noptions = (\"male\", \"female\")\nv1 = st.selectbox(\"selectbox 1 (default)\", options)\nst.write(\"value 1:\", v1)\n\nv2 = st.selectbox(\n    \"selectbox 2 (formatted options)\", options, 1, format_func=lambda x: x.capitalize()\n)\nst.write(\"value 2:\", v2)\n\nv3 = st.selectbox(\"selectbox 3 (no options)\", [])\nst.write(\"value 3:\", v3)\n\nmore_options = [\n    \"e2e/scripts/components_iframe.py\",\n    \"e2e/scripts/st_warning.py\",\n    \"This is a very very very long option label that should be truncated when it is showing in the dropdown menu.\",\n    \"e2e/scripts/st_container.py\",\n    \"e2e/scripts/st_dataframe_sort_column.py\",\n    \"e2e/scripts/app_hotkeys.py\",\n    \"e2e/scripts/st_info.py\",\n    \"e2e/scripts/st_echo.py\",\n    \"e2e/scripts/st_json.py\",\n    \"e2e/scripts/st_experimental_get_query_params.py\",\n    \"e2e/scripts/st_markdown.py\",\n    \"e2e/scripts/st_color_picker.py\",\n    \"e2e/scripts/st_expander.py\",\n]\nv4 = st.selectbox(\"selectbox 4 (more options)\", more_options, 0)\nst.write(\"value 4:\", v4)\n\nv5 = st.selectbox(\"selectbox 5 (disabled)\", options, disabled=True)\nst.write(\"value 5:\", v5)\n\nv6 = st.selectbox(\"selectbox 6 (hidden label)\", options, label_visibility=\"hidden\")\nst.write(\"value 6:\", v6)\n\nv7 = st.selectbox(\n    \"selectbox 7 (collapsed label)\", options, label_visibility=\"collapsed\"\n)\nst.write(\"value 7:\", v7)\n\nif runtime.exists():\n\n    def on_change():\n        st.session_state.selectbox_changed = True\n        st.text(\"Selectbox widget callback triggered\")\n\n    st.selectbox(\n        \"selectbox 8 (with callback, help)\",\n        options,\n        1,\n        key=\"selectbox8\",\n        on_change=on_change,\n        help=\"Help text\",\n    )\n    st.write(\"value 8:\", st.session_state.selectbox8)\n    st.write(\"selectbox changed:\", st.session_state.get(\"selectbox_changed\") is True)\n    # Reset to False:\n    st.session_state.selectbox_changed = False\n\nv9 = st.selectbox(\"selectbox 9 (empty selection)\", options, index=None)\nst.write(\"value 9:\", v9)\n\nv10 = st.selectbox(\n    \"selectbox 10 (empty, custom placeholder)\",\n    options,\n    index=None,\n    placeholder=\"Select one of the options...\",\n)\nst.write(\"value 10:\", v10)\n\nv11 = st.selectbox(\n    \"selectbox 11 (options from dataframe)\", pd.DataFrame({\"foo\": list(options)})\n)\nst.write(\"value 11:\", v11)\n\nif \"selectbox_12\" not in st.session_state:\n    st.session_state[\"selectbox_12\"] = \"female\"\n\nv12 = st.selectbox(\n    \"selectbox 12 (empty, value from state)\", options, index=None, key=\"selectbox_12\"\n)\nst.write(\"value 12:\", v12)\n", "e2e_playwright/st_graphviz_chart.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport graphviz as graphviz\n\nimport streamlit as st\n\n# basic graph\nhello = graphviz.Digraph(\"Hello World\")\nhello.edge(\"Hello\", \"World\")\n\n# styled graph\nstyled = graphviz.Graph(\"G\", filename=\"g_c_n.gv\")\nstyled.attr(bgcolor=\"purple:pink\", label=\"agraph\", fontcolor=\"white\")\n\nwith styled.subgraph(name=\"cluster1\") as c:\n    c.attr(\n        fillcolor=\"blue:cyan\",\n        label=\"acluster\",\n        fontcolor=\"white\",\n        style=\"filled\",\n        gradientangle=\"270\",\n    )\n    c.attr(\n        \"node\", shape=\"box\", fillcolor=\"red:yellow\", style=\"filled\", gradientangle=\"90\"\n    )\n    c.node(\"anode\")\n\n# complex graph\nengine = st.sidebar.radio(\n    \"Select engine\",\n    [\"dot\", \"neato\", \"twopi\", \"circo\", \"fdp\", \"osage\", \"patchwork\"],\n)\nst.sidebar.write(engine)\nfinite = graphviz.Digraph(\"finite_state_machine\", filename=\"fsm.gv\", engine=engine)\nfinite.attr(rankdir=\"LR\", size=\"8,5\")\n\nfinite.attr(\"node\", shape=\"doublecircle\")\nfinite.node(\"LR_0\")\nfinite.node(\"LR_3\")\nfinite.node(\"LR_4\")\nfinite.node(\"LR_8\")\n\nfinite.attr(\"node\", shape=\"circle\")\nfinite.edge(\"LR_0\", \"LR_2\", label=\"SS(B)\")\nfinite.edge(\"LR_0\", \"LR_1\", label=\"SS(S)\")\nfinite.edge(\"LR_1\", \"LR_3\", label=\"S($end)\")\nfinite.edge(\"LR_2\", \"LR_6\", label=\"SS(b)\")\nfinite.edge(\"LR_2\", \"LR_5\", label=\"SS(a)\")\nfinite.edge(\"LR_2\", \"LR_4\", label=\"S(A)\")\nfinite.edge(\"LR_5\", \"LR_7\", label=\"S(b)\")\nfinite.edge(\"LR_5\", \"LR_5\", label=\"S(a)\")\nfinite.edge(\"LR_6\", \"LR_6\", label=\"S(b)\")\nfinite.edge(\"LR_6\", \"LR_5\", label=\"S(a)\")\nfinite.edge(\"LR_7\", \"LR_8\", label=\"S(b)\")\nfinite.edge(\"LR_7\", \"LR_5\", label=\"S(a)\")\nfinite.edge(\"LR_8\", \"LR_6\", label=\"S(b)\")\nfinite.edge(\"LR_8\", \"LR_5\", label=\"S(a)\")\n\n# draw graphs\nst.graphviz_chart(hello)\n\nst.graphviz_chart(styled)\n\nst.graphviz_chart(finite)\n\n# draw graphs in columns\n\nleft_graph = graphviz.Digraph(\"Left\")\nleft_graph.edge(\"Left\", \"Graph\")\n\nright_graph = graphviz.Digraph(\"Right\")\nright_graph.edge(\"Right\", \"Graph\")\n\ncol1, col2 = st.columns([1, 1])\n\nwith col1:\n    st.graphviz_chart(left_graph)\n\nwith col2:\n    st.graphviz_chart(right_graph)\n\n\ndot_code = \"\"\"\ndigraph Dot {\n  A -> {B, C, D} -> {F}\n}\n\"\"\"\nst.graphviz_chart(dot_code)\n", "e2e_playwright/fast_rerun_safety.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport time\n\nimport streamlit as st\nfrom streamlit import runtime\n\nif runtime.exists():\n    if \"counter\" not in st.session_state:\n        st.session_state.counter = 0\n    st.button(\"rerun\")\n\n    st.write(st.session_state.counter)\n    time.sleep(3)\n    st.write(st.session_state.counter)\n    live = st.empty()\n    for _ in range(50):\n        st.session_state.counter += 1\n        live.write(f\"live: {st.session_state.counter}\")\n        time.sleep(0.1)\n", "e2e_playwright/st_caption.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\n# keep the sidebar collapsed by default to prevent render flakiness\nst.set_page_config(initial_sidebar_state=\"collapsed\")\nsidebar_markdown = \"\"\"# I am a header\n\n## I am a subheader\n\n### I am a subsubheader\n\nI am some body text\n\n[I am a link](https://google.com)\n\nFoo `bar` baz\"\"\"\n\nwith st.sidebar:\n    st.caption(sidebar_markdown)\n\nst.caption(\"This is a caption!\")\nst.caption(\n    \"This is a caption that contains <div>html</div> inside it!\", unsafe_allow_html=True\n)\nst.caption(\"This is a caption with a help tooltip\", help=\"This is some help tooltip!\")\n\nst.caption(\n    \"\"\"This is a caption that contains a bunch of interesting markdown:\n\n# heading 1\n\n## heading 2\n\n### heading 3\n\n#### heading 4\n\n##### heading 5\n\n###### heading 6\n\n * unordered list item 1\n * unordered list item 2\n * unordered list item 3\n\n 1. ordered list item 1\n 1. ordered list item 2\n 1. ordered list item 3\n\n This is a *caption* that contains **markdown inside it**!\n\n This line contains <div>html</div>!\n\"\"\"\n)\n", "e2e_playwright/st_expander_state.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\nb0 = st.button(\"b0\")\nb1 = st.button(\"b1\")\n\nif b0:\n    with st.expander(\"b0_expander\", expanded=False):\n        st.write(\"b0_write\")\n\nif b1:\n    with st.expander(\"b1_expander\", expanded=False):\n        st.write(\"b1_write\")\n", "e2e_playwright/st_snow.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\nst.snow()\n", "e2e_playwright/st_rerun.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\n\n@st.cache_resource\ndef rerun_record():\n    return [0]\n\n\ncount = rerun_record()\ncount[0] += 1\n\nif count[0] < 4:\n    st.rerun()\n\nif count[0] >= 4:\n    st.text(\"Being able to rerun a session is awesome!\")\n", "e2e_playwright/st_color_picker.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\n\ndef callback():\n    st.write(\"Hello world\")\n\n\nc1 = st.color_picker(\"Default Color\", on_change=callback)\nst.write(\"Color 1\", c1)\n\nc2 = st.color_picker(\"New Color\", \"#EB144C\", help=\"help string\")\nst.write(\"Color 2\", c2)\n\nc3 = st.color_picker(\"Disabled\", disabled=True)\nst.write(\"Color 3\", c3)\n\nc4 = st.color_picker(\"Hidden Label\", label_visibility=\"hidden\")\nst.write(\"Color 4\", c4)\n\nc5 = st.color_picker(\"Collapsed Label\", label_visibility=\"collapsed\")\nst.write(\"Color 5\", c5)\n\nwith st.form(key=\"my_form\", clear_on_submit=True):\n    selection = st.color_picker(\"Form Color Picker\", key=\"color_picker_form\")\n    st.form_submit_button(\"Submit\")\n\nst.write(\"color_picker-in-form selection:\", str(selection))\nif \"color_picker_form\" in st.session_state:\n    st.write(\n        \"color_picker-in-form selection in session state:\",\n        str(st.session_state.color_picker_form),\n    )\n\n\n@st.experimental_fragment()\ndef test_fragment():\n    selection = st.color_picker(\"Fragment Color Picker\")\n    st.write(\"color_picker-in-fragment selection:\", str(selection))\n\n\ntest_fragment()\n\nif \"runs\" not in st.session_state:\n    st.session_state.runs = 0\nst.session_state.runs += 1\nst.write(\"Runs:\", st.session_state.runs)\n", "e2e_playwright/main_menu.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\nfrom streamlit.commands.page_config import MenuItems\n\nmenu_items: MenuItems = {\"about\": \"_*This can be markdown!*_\"}\nst.set_page_config(menu_items=menu_items)\n", "e2e_playwright/st_scatter_chart.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nfrom datetime import date\n\nimport numpy as np\nimport pandas as pd\n\nimport streamlit as st\n\nnp.random.seed(0)\n\n\ndata = np.random.randn(20, 3)\ndf = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\"])\n\n# st.area/bar/line_chart all use Altair/Vega-Lite under the hood.\n# By default, Vega-Lite displays time values in the browser's local\n# time zone, but data is sent down to the browser as UTC. This means\n# Times need to be set correctly to the users timezone.\nutc_df = pd.DataFrame(\n    {\n        \"index\": [\n            date(2019, 8, 9),\n            date(2019, 8, 10),\n            date(2019, 8, 11),\n            date(2019, 8, 12),\n        ],\n        \"numbers\": [10, 50, 30, 40],\n    }\n)\n\nutc_df.set_index(\"index\", inplace=True)\n\n# Dataframe to test the color parameter support:\nN = 100\n\ncolor_df = pd.DataFrame(\n    {\n        # Using a negative range so certain kinds of bugs are more visible.\n        \"a\": -np.arange(N),\n        \"b\": np.random.rand(N) * 10,\n        \"c\": np.random.rand(N) * 10,\n        \"d\": np.random.randn(N) * 30,\n        \"e\": [\"bird\" if x % 2 else \"airplane\" for x in range(N)],\n    }\n)\n\nst.header(\"Scatter Chart\")\n\nst.scatter_chart()\nst.scatter_chart(df)\nst.scatter_chart(df, x=\"a\")\nst.scatter_chart(df, y=\"a\")\nst.scatter_chart(df, y=[\"a\", \"b\"])\nst.scatter_chart(df, x=\"a\", y=\"b\", height=500, width=300, use_container_width=False)\nst.scatter_chart(df, x=\"b\", y=\"a\")\nst.scatter_chart(df, x=\"a\", y=[\"b\", \"c\"])\nst.scatter_chart(utc_df)\nst.scatter_chart(color_df, x=\"a\", y=\"b\", color=\"e\")\n# Additional tests for size parameter (only for scatter_chart)\nst.scatter_chart(color_df, x=\"a\", y=\"b\", size=\"d\", color=\"e\")\nst.scatter_chart(color_df, x=\"a\", y=\"b\", size=\"d\", color=\"c\")\nst.scatter_chart(df, x_label=\"X Axis Label\", y_label=\"Y Axis Label\")\n", "e2e_playwright/hello_app.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport numpy as np\n\nfrom streamlit import runtime\nfrom streamlit.hello import streamlit_app\n\n# Set random seed to always get the same results in the plotting demo\nnp.random.seed(0)\nif runtime.exists():\n    streamlit_app.run()\n", "e2e_playwright/st_video.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport time\nfrom os.path import abspath, dirname, join\n\nimport requests\n\nimport streamlit as st\n\n# Construct test assets path relative to this script file to\n# allow its execution with different working directories.\nTEST_ASSETS_DIR = join(dirname(abspath(__file__)), \"test_assets\")\n\nWEBM_VIDEO_PATH = join(TEST_ASSETS_DIR, \"sintel-short.webm\")\nMP4_VIDEO_PATH = join(TEST_ASSETS_DIR, \"sintel-short.mp4\")\nVTT_EN_PATH = join(TEST_ASSETS_DIR, \"sintel-en.vtt\")\nVTT_DE_PATH = join(TEST_ASSETS_DIR, \"sintel-de.vtt\")\n\nurl = \"https://www.w3schools.com/html/mov_bbb.mp4\"\nfile = requests.get(url).content\nst.video(file)\n\n# Test start time with video\ntimestamp = st.number_input(\"Start Time (in seconds)\", min_value=0, value=6)\nst.video(url, start_time=int(timestamp))\n\n# Test local file with video\nst.video(MP4_VIDEO_PATH, start_time=17)\n\n# Test subtitle with video\nst.video(\n    MP4_VIDEO_PATH,\n    start_time=31,\n    subtitles={\n        \"English\": VTT_EN_PATH,\n        \"Deutsch\": VTT_DE_PATH,\n    },\n)\n\n# Test subtitle with webm video\nst.video(\n    WEBM_VIDEO_PATH,\n    start_time=25,\n    subtitles={\n        \"English\": VTT_EN_PATH,\n        \"Deutsch\": VTT_DE_PATH,\n    },\n)\n\n\n# Test end time webm video\nst.video(\n    WEBM_VIDEO_PATH,\n    start_time=31,\n    end_time=33,\n)\n\n# Test end time mp4 video\nst.video(\n    MP4_VIDEO_PATH,\n    start_time=31,\n    end_time=33,\n)\n\n# Test end time and loop webm video\nst.video(WEBM_VIDEO_PATH, start_time=35, end_time=39, loop=True)\n\n# Test end time and loop mp4 video\nst.video(MP4_VIDEO_PATH, start_time=35, end_time=39, loop=True)\n\n# Test autoplay with video\nautoplay = st.checkbox(\"Autoplay\", value=False)\n\nif st.button(\"Create some elements to unmount component\"):\n    for _ in range(3):\n        # The sleep here is needed, because it won't unmount the\n        # component if this is too fast.\n        time.sleep(1)\n        st.write(\"Another element\")\n\nst.video(\n    WEBM_VIDEO_PATH,\n    autoplay=autoplay,\n)\n\n# Test muted with video\nst.video(\n    WEBM_VIDEO_PATH,\n    autoplay=True,\n    muted=True,\n)\n", "e2e_playwright/st_radio.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport pandas as pd\n\nimport streamlit as st\nfrom streamlit import runtime\n\noptions = (\"female\", \"male\")\nmarkdown_options = (\n    \"**bold text**\",\n    \"*italics text*\",\n    \"~strikethrough text~\",\n    \"shortcode: :blush:\",\n    # link should not work in radio options\n    \"[link text](www.example.com)\",\n    \"`code text`\",\n    \":red[red] :blue[blue] :green[green] :violet[violet] :orange[orange]\",\n)\n\nv1 = st.radio(\"radio 1 (default)\", options)\nst.write(\"value 1:\", v1)\n\nv2 = st.radio(\n    \"radio 2 (Formatted options)\",\n    options,\n    1,\n    format_func=lambda x: x.capitalize(),\n)\nst.write(\"value 2:\", v2)\n\nv3 = st.radio(\"radio 3 (no options)\", [])\nst.write(\"value 3:\", v3)\n\nv4 = st.radio(\"radio 4 (disabled)\", options, disabled=True)\nst.write(\"value 4:\", v4)\n\nv5 = st.radio(\"radio 5 (horizontal)\", options, horizontal=True)\nst.write(\"value 5:\", v5)\n\nv6 = st.radio(\"radio 6 (options from dataframe)\", pd.DataFrame({\"foo\": list(options)}))\nst.write(\"value 6:\", v6)\n\nv7 = st.radio(\"radio 7 (hidden label)\", options, label_visibility=\"hidden\")\nst.write(\"value 7:\", v7)\n\nv8 = st.radio(\"radio 8 (collapsed label)\", options, label_visibility=\"collapsed\")\nst.write(\"value 8:\", v8)\n\nv9 = st.radio(\"radio 9 (markdown options)\", options=markdown_options)\nst.write(\"value 9:\", v9)\n\nv10 = st.radio(\n    \"radio 10 (with captions)\",\n    [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"],\n    captions=markdown_options,\n)\nst.write(\"value 10:\", v10)\n\nv11 = st.radio(\n    \"radio 11 (horizontal, captions)\",\n    [\"yes\", \"maybe\", \"no\"],\n    captions=[\"Opt in\", \"\", \"Opt out\"],\n    horizontal=True,\n)\nst.write(\"value 11:\", v11)\n\nif runtime.exists():\n\n    def on_change():\n        st.session_state.radio_changed = True\n        st.text(\"Radio widget callback triggered\")\n\n    st.radio(\n        \"radio 12 (with callback, help)\",\n        options,\n        1,\n        key=\"radio12\",\n        on_change=on_change,\n        help=\"help text\",\n    )\n    st.write(\"value 12:\", st.session_state.radio12)\n    st.write(\"radio changed:\", st.session_state.get(\"radio_changed\") is True)\n    # Reset to False:\n    st.session_state.radio_changed = False\n\nv13 = st.radio(\"radio 13 (empty selection)\", options, index=None)\nst.write(\"value 13:\", v13)\n", "e2e_playwright/st_experimental_fragment_dynamic_form.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\nimport streamlit as st\n\nst.header(\"Dynamic form - full app only runs on submit\")\n\nstates = {\n    \"USA\": [\"\", \"California\", \"Washington\", \"New Jersey\"],\n    \"Canada\": [\"\", \"Quebec\", \"Ontario\", \"British Columbia\"],\n    \"Germany\": [\"\", \"Brandenberg\", \"Hesse\", \"Bavaria\"],\n}\n\n\n@st.experimental_fragment\ndef get_location():\n    with st.container(border=True):\n        st.subheader(\"Enter your location\")\n\n        city = None\n        state = None\n\n        country = st.selectbox(\"Country\", [\"\", \"USA\", \"Canada\", \"Germany\"])\n\n        if country:\n            state = st.selectbox(\"State\", states[country])\n        if state:\n            city = st.text_input(\"City\")\n\n        submit_enabled = city and state and country\n        if st.button(\"Submit\", type=\"primary\", disabled=not submit_enabled):\n            if len(city) < 8:\n                st.warning(f\"City name {city} must be at least 8 characters\")\n            else:\n                st.session_state.new_location = {\n                    \"country\": country,\n                    \"state\": state,\n                    \"city\": city,\n                }\n                st.rerun()\n\n\nget_location()\n\nif \"new_location\" in st.session_state:\n    result = st.session_state.pop(\"new_location\")\n    st.success(\"We have recorded your location, thank you!\")\n    \"Response:\"\n    st.json(result)\n", "e2e_playwright/st_expander_nested.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\nlevel1 = st.expander(\"See explanation\")\nlevel1.write(\"First level expander\")\nlevel1.image(\"https://static.streamlit.io/examples/dice.jpg\")\n\nlevel2 = level1.expander(\"Nested expander\")\nlevel2.write(\"Second level expander\")\n", "e2e_playwright/st_altair_chart_basic_select.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\nimport time\n\nimport altair as alt\nimport pandas as pd\nfrom vega_datasets import data\n\nimport streamlit as st\n\n# SCATTER CHART\nst.header(\"Altair Chart with point and interval selection\")\n\n# taken from vega_datasets cars example\ncars = data.cars()\ninterval = alt.selection_interval()\n\npoint = alt.selection_point()\n\nst.subheader(\"Scatter chart with selection_point\")\n\nif st.button(\"Create some elements to unmount component\"):\n    for _ in range(3):\n        # The sleep here is needed, because it won't unmount the\n        # component if this is too fast.\n        time.sleep(1)\n        st.write(\"Another element\")\n\nbase = (\n    alt.Chart(cars)\n    .mark_point()\n    .encode(\n        x=\"Horsepower:Q\",\n        y=\"Miles_per_Gallon:Q\",\n        color=alt.condition(point, \"Origin:N\", alt.value(\"lightgray\")),\n        tooltip=alt.value(None),\n    )\n)\nchart_point = base.add_params(point)\nst.altair_chart(\n    chart_point, on_select=\"rerun\", key=\"scatter_point\", use_container_width=True\n)\nif (\n    \"scatter_point\" in st.session_state\n    and len(st.session_state.scatter_point.selection) > 0\n):\n    st.write(\"Scatter chart with selection_point:\", str(st.session_state.scatter_point))\n\nst.subheader(\"Scatter chart with selection_interval\")\nbase = (\n    alt.Chart(cars)\n    .mark_point()\n    .encode(\n        x=\"Horsepower:Q\",\n        y=\"Miles_per_Gallon:Q\",\n        color=alt.condition(interval, \"Origin:N\", alt.value(\"lightgray\")),\n        tooltip=alt.value(None),\n    )\n)\nchart_interval = base.add_params(interval)\n# Set use_container_width=True for all charts so that the width is not dependent on Vega-lib updates.\nst.altair_chart(\n    chart_interval, on_select=\"rerun\", key=\"scatter_interval\", use_container_width=True\n)\nif (\n    \"scatter_interval\" in st.session_state\n    and len(st.session_state.scatter_interval.selection) > 0\n):\n    st.write(\n        \"Scatter chart with selection_interval:\", str(st.session_state.scatter_interval)\n    )\n\n# BAR CHART\nst.subheader(\"Bar chart with selection_point\")\nsource = pd.DataFrame(\n    {\n        \"a\": [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\"],\n        \"b\": [28, 55, 43, 91, 81, 53, 19, 87, 52],\n    }\n)\n\nbar_graph_point = (\n    alt.Chart(source)\n    .mark_bar()\n    .encode(\n        x=\"a\",\n        y=\"b\",\n        fillOpacity=alt.condition(point, alt.value(1), alt.value(0.3)),\n        tooltip=alt.value(None),\n    )\n    .add_params(point)\n)\nst.altair_chart(\n    bar_graph_point, on_select=\"rerun\", key=\"bar_point\", use_container_width=True\n)\nif \"bar_point\" in st.session_state and len(st.session_state.bar_point.selection) > 0:\n    st.write(\"Bar chart with selection_point:\", str(st.session_state.bar_point))\n\n\nbar_graph_interval = (\n    alt.Chart(source)\n    .mark_bar()\n    .encode(\n        x=\"a\",\n        y=\"b\",\n        fillOpacity=alt.condition(interval, alt.value(1), alt.value(0.3)),\n        tooltip=alt.value(None),\n    )\n    .add_params(interval)\n)\n\nst.subheader(\"Bar chart with selection_interval\")\nst.altair_chart(\n    bar_graph_interval, on_select=\"rerun\", key=\"bar_interval\", use_container_width=True\n)\nif (\n    \"bar_interval\" in st.session_state\n    and len(st.session_state.bar_interval.selection) > 0\n):\n    st.write(\"Bar chart with selection_interval:\", str(st.session_state.bar_interval))\n\n# STACKED AREA CHART\nsource = data.iowa_electricity()\n\nbase = (\n    alt.Chart(source)\n    .mark_area()\n    .encode(\n        x=\"year:T\",\n        y=\"net_generation:Q\",\n        color=alt.condition(point, \"source:N\", alt.value(\"lightgray\")),\n        tooltip=alt.value(None),\n    )\n)\narea_chart_point = base.add_params(point)\nst.subheader(\"Area chart with selection_point\")\nselection = st.altair_chart(\n    area_chart_point, on_select=\"rerun\", key=\"area_point\", use_container_width=True\n)\nif len(selection.selection) > 0:\n    st.write(\"Area chart with selection_point:\", str(selection.selection))\n\n\nbase = (\n    alt.Chart(source)\n    .mark_area()\n    .encode(\n        x=\"year:T\",\n        y=\"net_generation:Q\",\n        color=alt.condition(interval, \"source:N\", alt.value(\"lightgray\")),\n        tooltip=alt.value(None),\n    )\n)\narea_chart_interval = base.add_params(interval)\nst.subheader(\"Area chart with selection_interval\")\narea_interval_selection = st.altair_chart(\n    area_chart_interval,\n    on_select=\"rerun\",\n    key=\"area_interval\",\n    use_container_width=True,\n)\nif len(area_interval_selection.selection) > 0:\n    st.write(\n        \"Area chart with selection_interval:\", str(area_interval_selection.selection)\n    )\n\n# HISTOGRAM CHART\nsource = data.movies()\n\nbase = (\n    alt.Chart(source)\n    .mark_bar()\n    .encode(\n        alt.X(\"IMDB_Rating:Q\", bin=True),\n        y=\"count()\",\n        color=alt.condition(point, \"IMDB_Rating:Q\", alt.value(\"lightgray\")),\n        tooltip=alt.value(None),\n    )\n)\nhistogram_point = base.add_params(point)\nst.subheader(\"Histogram chart with selection_point\")\nst.altair_chart(\n    histogram_point, on_select=\"rerun\", key=\"histogram_point\", use_container_width=True\n)\nif (\n    \"histogram_point\" in st.session_state\n    and len(st.session_state.histogram_point.selection) > 0\n):\n    st.write(\n        \"Histogram chart with selection_point:\", str(st.session_state.histogram_point)\n    )\n\nbase = (\n    alt.Chart(source)\n    .mark_bar()\n    .encode(\n        alt.X(\"IMDB_Rating:Q\", bin=True),\n        y=\"count()\",\n        color=alt.condition(interval, \"IMDB_Rating:Q\", alt.value(\"lightgray\")),\n        tooltip=alt.value(None),\n    )\n)\nhistogram_interval = base.add_params(interval)\nst.subheader(\"Histogram chart with selection_interval\")\nst.altair_chart(\n    histogram_interval,\n    on_select=\"rerun\",\n    key=\"histogram_interval\",\n    use_container_width=True,\n)\nif (\n    \"histogram_interval\" in st.session_state\n    and len(st.session_state.histogram_interval.selection) > 0\n):\n    st.write(\n        \"Histogram chart with selection_interval:\",\n        str(st.session_state.histogram_interval),\n    )\n\n# SELECTIONS IN FORM\nst.header(\"Selections in form:\")\n\nwith st.form(key=\"my_form\", clear_on_submit=True):\n    selection = st.altair_chart(\n        histogram_point,\n        on_select=\"rerun\",\n        key=\"histogram_point_in_form\",\n        use_container_width=True,\n    )\n    st.form_submit_button(\"Submit\")\n\nst.write(\"Histogram-in-form selection:\", str(selection))\nif \"histogram_point_in_form\" in st.session_state:\n    st.write(\n        \"Histogram-in-form selection in session state:\",\n        str(st.session_state.histogram_point_in_form),\n    )\n\n# SELECTIONS IN CALLBACK\nst.header(\"Selection callback:\")\n\n\ndef on_selection():\n    st.write(\n        \"Histogram selection callback:\",\n        str(st.session_state.histogram_point_in_callback),\n    )\n\n\nselection = st.altair_chart(\n    histogram_point,\n    on_select=on_selection,\n    key=\"histogram_point_in_callback\",\n    use_container_width=True,\n)\n\n\n# SELECTIONS IN FRAGMENT\nst.header(\"Selections in fragment:\")\n\n\n@st.experimental_fragment\ndef test_fragment():\n    selection = st.altair_chart(\n        histogram_point,\n        on_select=on_selection,\n        key=\"histogram_point_in_fragment\",\n        use_container_width=True,\n    )\n    st.write(\"Histogram-in-fragment selection:\", str(selection))\n\n\ntest_fragment()\n\nif \"runs\" not in st.session_state:\n    st.session_state.runs = 0\nst.session_state.runs += 1\nst.write(\"Runs:\", st.session_state.runs)\n", "e2e_playwright/st_tabs.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\ntab1, tab2, tab3 = st.tabs([\"Tab 1\", \"Tab 2\", \"Tab 3\"])\n\nwith tab1:\n    st.write(\"tab1\")\n    st.text_input(\"Text input\")\n\nwith tab2:\n    st.write(\"tab2\")\n    st.number_input(\"Number input\")\n\nwith tab3:\n    st.write(\"tab3\")\n    st.date_input(\"Date input\")\n\nwith st.expander(\"Expander\", expanded=True):\n    many_tabs = st.tabs([f\"Tab {i}\" for i in range(25)])\n\nsidebar_tab1, sidebar_tab2 = st.sidebar.tabs([\"Foo\", \"Bar\"])\nsidebar_tab1.write(\"I am in the sidebar\")\nsidebar_tab2.write(\"I'm also in the sidebar\")\n", "e2e_playwright/st_time_input.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom datetime import datetime, time\n\nimport streamlit as st\nfrom streamlit import runtime\n\nv1 = st.time_input(\"Time input 1 (8:45)\", time(8, 45))\nst.write(\"Value 1:\", v1)\n\nv2 = st.time_input(\n    \"Time input 2 (21:15, help)\", datetime(2019, 7, 6, 21, 15), help=\"Help text\"\n)\nst.write(\"Value 2:\", v2)\n\nv3 = st.time_input(\"Time input 3 (disabled)\", time(8, 45), disabled=True)\nst.write(\"Value 3:\", v3)\n\nv4 = st.time_input(\n    \"Time input 4 (hidden label)\", time(8, 45), label_visibility=\"hidden\"\n)\nst.write(\"Value 4:\", v4)\n\nv5 = st.time_input(\n    \"Time input 5 (collapsed label)\", time(8, 45), label_visibility=\"collapsed\"\n)\nst.write(\"Value 5:\", v5)\n\nif runtime.exists():\n\n    def on_change():\n        st.session_state.time_input_changed = True\n        st.text(\"Time input callback triggered\")\n\n    st.time_input(\n        \"Time input 6 (with callback)\",\n        time(8, 45),\n        key=\"time_input_6\",\n        on_change=on_change,\n    )\n\n    st.write(\"Value 6:\", st.session_state.time_input_6)\n    st.write(\"time input changed:\", st.session_state.get(\"time_input_changed\") is True)\n    # Reset to False:\n    st.session_state.time_input_changed = False\n\nv7 = st.time_input(\"Time input 7 (step=60)\", time(8, 45), step=60)\nst.write(\"Value 7:\", v7)\n\n\nv8 = st.time_input(\"Time input 8 (empty)\", value=None)\nst.write(\"Value 8:\", v8)\n\nif \"time_input_9\" not in st.session_state:\n    st.session_state[\"time_input_9\"] = time(8, 50)\n\nv9 = st.time_input(\n    \"Time input 9 (empty, from state)\",\n    value=None,\n    key=\"time_input_9\",\n)\nst.write(\"Value 9:\", v9)\n", "e2e_playwright/st_image.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport numpy as np\n\nimport streamlit as st\n\nst.image(np.repeat(0, 100).reshape(10, 10))\n", "e2e_playwright/st_select_slider.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport numpy as np\nimport pandas as pd\n\nimport streamlit as st\nfrom streamlit import runtime\n\n\ndef format_option(option):\n    return f\"Color: {option}\"\n\n\nw1 = st.select_slider(\n    \"Label 1 (format_func with key and help)\",\n    value=(\"orange\", \"blue\"),\n    options=[\"red\", \"orange\", \"yellow\", \"green\", \"blue\", \"indigo\", \"violet\"],\n    format_func=format_option,\n    key=\"first_select_slider\",\n    help=\"Help in a select slider\",\n)\nif \"first_select_slider\" in st.session_state:\n    st.write(\"Value 1:\", st.session_state.first_select_slider)\nst.write(\"Value 1:\", w1)\n\nw2 = st.select_slider(\n    \"Label 2 (no default)\",\n    options=np.array([1, 2, 3, 4, 5]),\n)\nst.write(\"Value 2:\", w2)\n\nw3 = st.select_slider(\n    \"Label 3 (default with ints and series)\",\n    value=[2, 5],\n    options=pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9]),\n)\nst.write(\"Value 3:\", w3)\n\nw4 = st.select_slider(\n    \"Label 4 (default with pandas df)\",\n    value=5,\n    options=pd.DataFrame(\n        {\n            \"first column\": [1, 2, 3, 4, 5],\n            \"second column\": [10, 20, 30, 40, 50],\n        }\n    ),\n)\nst.write(\"Value 4:\", w4)\n\nw5 = st.select_slider(\n    \"Label 5 (disabled)\",\n    value=(\"orange\", \"blue\"),\n    options=[\"red\", \"orange\", \"yellow\", \"green\", \"blue\", \"indigo\", \"violet\"],\n    disabled=True,\n)\nst.write(\"Value 5:\", w5)\n\nw6 = st.select_slider(\n    \"Label 6 (hidden visibility)\",\n    options=[\"red\", \"orange\", \"yellow\", \"green\", \"blue\", \"indigo\", \"violet\"],\n    label_visibility=\"hidden\",\n)\n\nst.write(\"Value 6:\", w6)\n\n\nw7 = st.select_slider(\n    \"Label 7 (collapsed visibility)\",\n    options=[\"red\", \"orange\", \"yellow\", \"green\", \"blue\", \"indigo\", \"violet\"],\n    label_visibility=\"collapsed\",\n)\n\nst.write(\"Value 7:\", w7)\n\nif runtime.exists():\n\n    def on_change():\n        st.session_state.select_slider_changed = True\n        st.write(\"Hello world\")\n\n    st.select_slider(\n        \"Label 8 (on change)\",\n        options=np.array([1, 2, 3, 4, 5]),\n        key=\"select_slider8\",\n        on_change=on_change,\n    )\n    st.write(\"Value 8:\", st.session_state.select_slider8)\n    st.write(\"Select slider changed:\", \"select_slider_changed\" in st.session_state)\n\nwith st.expander(\"Expander\", expanded=True):\n    w9 = st.select_slider(\n        label=\"Label 9 (expander)\",\n        options=[\"foo\", \"bar\", \"baz\", \"This is a very, very long option\"],\n        value=\"This is a very, very long option\",\n    )\n\n    st.write(\"Value 9:\", w9)\n\nwith st.form(key=\"my_form\", clear_on_submit=True):\n    selection = st.select_slider(\n        label=\"Label 10 (form)\",\n        options=np.array([1, 2, 3, 4, 5]),\n    )\n    st.form_submit_button(\"Submit\")\n\nst.write(\"select_slider-in-form selection:\", str(selection))\n\n\n@st.experimental_fragment()\ndef test_fragment():\n    selection = st.select_slider(\n        label=\"Label 11 (fragment)\",\n        options=np.array([1, 2, 3, 4, 5]),\n    )\n    st.write(\"select_slider-in-fragment selection:\", str(selection))\n\n\ntest_fragment()\n\nif \"runs\" not in st.session_state:\n    st.session_state.runs = 0\nst.session_state.runs += 1\nst.write(\"Runs:\", st.session_state.runs)\n", "e2e_playwright/st_both_query_params_error.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\nst.query_params.y = 1.23\n\n# Should throw an error after both apis are used\nparams = st.experimental_get_query_params()\n", "e2e_playwright/st_text_area.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\nfrom streamlit import runtime\n\nv1 = st.text_area(\"text area 1 (default)\")\nst.write(\"value 1:\", v1)\n\nv2 = st.text_area(\"text area 2 (value='some text')\", \"some text\")\nst.write(\"value 2:\", v2)\n\nv3 = st.text_area(\"text area 3 (value=1234)\", 1234)\nst.write(\"value 3:\", v3)\n\nv4 = st.text_area(\"text area 4 (value=None)\", None)\nst.write(\"value 4:\", v4)\n\nv5 = st.text_area(\"text area 5 (placeholder)\", placeholder=\"Placeholder\")\nst.write(\"value 5:\", v5)\n\nv6 = st.text_area(\"text area 6 (disabled)\", \"default text\", disabled=True)\nst.write(\"value 6:\", v6)\n\nv7 = st.text_area(\n    \"text area 7 (hidden label)\", \"default text\", label_visibility=\"hidden\"\n)\nst.write(\"value 7:\", v7)\n\nv8 = st.text_area(\n    \"text area 8 (collapsed label)\", \"default text\", label_visibility=\"collapsed\"\n)\nst.write(\"value 8:\", v8)\n\nif runtime.exists():\n\n    def on_change():\n        st.session_state.text_area_changed = True\n        st.text(\"text area changed callback\")\n\n    st.text_area(\n        \"text area 9 (callback, help)\",\n        key=\"text_area9\",\n        on_change=on_change,\n        help=\"Help text\",\n    )\n    st.write(\"value 9:\", st.session_state.text_area9)\n    st.write(\"text area changed:\", st.session_state.get(\"text_area_changed\") is True)\n    # Reset to False:\n    st.session_state.text_area_changed = False\n\nv10 = st.text_area(\"text area 10 (max_chars=5)\", \"1234\", max_chars=5)\nst.write(\"value 10:\", v10)\n\nv11 = st.text_area(\"text area 11 (height=250)\", \"default text\", height=250)\nst.write(\"value 11:\", v11)\n", "e2e_playwright/deploy_dialog.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Nothing to do here since the deploy button is part of the frontend even\n# without any Streamlit element being rendered.\n", "e2e_playwright/st_query_params.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\nst.markdown(str(st.query_params))\n", "e2e_playwright/st_slider.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom datetime import date, time\n\nimport streamlit as st\nfrom streamlit import runtime\n\ns1 = st.sidebar.slider(\"Label A\", 0, 12345678, 12345678)\nst.sidebar.write(\"Value A:\", s1)\n\nr1 = st.sidebar.slider(\"Range A\", 10000, 25000, [10000, 25000])\nst.sidebar.write(\"Range Value A:\", r1)\n\nwith st.sidebar.expander(\"Expander\", expanded=True):\n    s2 = st.slider(\"Label B\", 10000, 25000, 10000)\n    st.write(\"Value B:\", s2)\n\n    r2 = st.slider(\"Range B\", 10000, 25000, [10000, 25000])\n    st.write(\"Range Value B:\", r2)\n\nw1 = st.slider(\n    \"Label 1\",\n    min_value=date(2019, 8, 1),\n    max_value=date(2021, 6, 4),\n    value=(date(2019, 8, 1), date(2019, 9, 1)),\n    format=\"ddd, hA\",\n    help=\"This is some help tooltip!\",\n)\nst.write(\"Value 1:\", w1)\n\nw2 = st.slider(\"Label 2\", 0.0, 100.0, (25.0, 75.0), 0.5)\nst.write(\"Value 2:\", w2)\n\nw3 = st.slider(\n    \"Label 3 - This is a very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very long label\",\n    0,\n    100,\n    1,\n    1,\n)\nst.write(\"Value 3:\", w3)\n\nw4 = st.slider(\"Label 4\", 10000, 25000, 10000, disabled=True)\nst.write(\"Value 4:\", w4)\n\nw5 = st.slider(\"Label 5\", 0, 100, 25, 1, label_visibility=\"hidden\")\nst.write(\"Value 5:\", w5)\n\nw6 = st.slider(\"Label 6\", 0, 100, 36, label_visibility=\"collapsed\")\nst.write(\"Value 6:\", w6)\n\ndates = st.slider(\n    \"Label 7\",\n    min_value=date(2019, 8, 1),\n    max_value=date(2021, 6, 4),\n    value=(date(2019, 8, 1), date(2019, 9, 1)),\n)\nst.write(\"Value 7:\", dates[0], dates[1])\n\nif runtime.exists():\n\n    def on_change():\n        st.session_state.slider_changed = True\n\n    st.slider(\n        \"Label 8\",\n        min_value=0,\n        max_value=100,\n        value=25,\n        step=1,\n        key=\"slider8\",\n        on_change=on_change,\n    )\n    st.write(\"Value 8:\", st.session_state.slider8)\n    st.write(\"Slider changed:\", \"slider_changed\" in st.session_state)\n\nwith st.form(key=\"my_form\", clear_on_submit=True):\n    selection = st.slider(\n        \"Label 9\",\n        min_value=0,\n        max_value=100,\n        value=25,\n        step=1,\n        key=\"slider9\",\n    )\n    st.form_submit_button(\"Submit\")\n\nst.write(\"slider-in-form selection:\", str(selection))\n\n\n@st.experimental_fragment()\ndef test_fragment():\n    selection = st.slider(\n        \"Label 10\",\n        min_value=0,\n        max_value=100,\n        value=25,\n        step=1,\n        key=\"slider10\",\n        on_change=on_change,\n    )\n    st.write(\"slider-in-fragment selection:\", str(selection))\n\n\ntest_fragment()\n\nif \"runs\" not in st.session_state:\n    st.session_state.runs = 0\nst.session_state.runs += 1\nst.write(\"Runs:\", st.session_state.runs)\n\nslider_11_value = st.slider(\n    \"Slider 11 (formatted float)\", value=0.05, step=0.2, format=\"%f%%\"\n)\nst.write(\"Slider 11:\", slider_11_value)\n\nslider_12_value = st.slider(\"Slider 12 (time-value)\", value=time(12, 0))\nst.write(\"Slider 12:\", slider_12_value)\n", "e2e_playwright/st_form.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom datetime import date, time\n\nimport streamlit as st\n\n# Tests all widgets, sans file_uploader, color picker, camera input and data editor,\n# inside a form. These widgets are a lot more complicated to test, and\n# are tested separately within the e2e tests for those components.\nwith st.form(\"form_1\"):\n    checkbox = st.checkbox(\"Checkbox\", False)\n    date_input = st.date_input(\"Date Input\", date(2019, 7, 6))\n    multiselect = st.multiselect(\"Multiselect\", [\"foo\", \"bar\"], default=[\"foo\"])\n    number_input = st.number_input(\"Number Input\")\n    radio = st.radio(\"Radio\", [\"foo\", \"bar\", \"baz\"])\n    selectbox = st.selectbox(\"Selectbox\", [\"foo\", \"bar\", \"baz\"])\n    select_slider = st.select_slider(\"Select Slider\", [\"foo\", \"bar\", \"baz\"])\n    slider = st.slider(\"Slider\")\n    text_area = st.text_area(\"Text Area\", value=\"foo\")\n    text_input = st.text_input(\"Text Input\", value=\"foo\")\n    time_input = st.time_input(\"Time Input\", time(8, 45))\n    toggle_input = st.toggle(\"Toggle Input\", value=False)\n    st.form_submit_button(\"Submit\")\n\nst.write(\"Checkbox:\", checkbox)\nst.write(\"Date Input:\", date_input)\nst.write(\"Multiselect:\", \", \".join(multiselect))\nst.write(\"Number Input:\", number_input)\nst.write(\"Radio:\", radio)\nst.write(\"Selectbox:\", selectbox)\nst.write(\"Select Slider:\", select_slider)\nst.write(\"Slider:\", slider)\nst.write(\"Text Area:\", text_area)\nst.write(\"Text Input:\", text_input)\nst.write(\"Time Input:\", time_input)\nst.write(\"Toggle Input:\", toggle_input)\n\nwith st.form(\"form_2\"):\n    st.write(\"Inside form 2\")\n    text_input = st.text_input(\"Form 2 - Text Input\")\n    col1, col2 = st.columns(2)\n    col1.form_submit_button(\n        \"Form 2 - Submit (use_container_width, help)\",\n        use_container_width=True,\n        help=\"Submit by clicking\",\n    )\n    col2.form_submit_button(\n        \"Form 2 - Submit 2 (use_container_width)\", use_container_width=True\n    )\n\n\nwith st.form(\"form_3\", border=False):\n    st.write(\"Inside form 3 (border=False)\")\n    text_input = st.text_input(\"Form 3 - Text Input\")\n    st.form_submit_button(\n        \"Form 3 - Submit (use_container_width)\",\n        use_container_width=True,\n    )\n", "e2e_playwright/st_divider.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\nst.divider()\n", "e2e_playwright/st_text.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\nst.text(\"This text is awesome!\")\nst.text(\n    r\"\"\"\n|\\---/|\n| o_o |\n \\_^_/\n\"\"\"\n)\nst.text(\"_This text is **awesome**!_\")\nst.text(\"Text with a help tooltip\", help=\"This is a help tooltip!\")\n", "e2e_playwright/st_chat_input_file_uploader_regression.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport time\n\nimport streamlit as st\n\nif \"messages\" not in st.session_state:\n    st.session_state.messages = []\n\n# A count to record the index of dialog\nif \"count\" not in st.session_state:\n    st.session_state.count = 0\n\nfor message in st.session_state.messages:\n    with st.chat_message(message[\"role\"]):\n        st.markdown(message[\"content\"])\n\nuploaded_files = st.sidebar.file_uploader(label=\"Upload\", accept_multiple_files=True)\n\nfor file in uploaded_files:\n    st.sidebar.write(file.name)\n\nif prompt := st.chat_input(\"What is up?\"):\n    # Display user message in chat message container\n    with st.chat_message(\"user\"):\n        st.markdown(prompt)\n    # Add user message to chat history\n    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n    st.session_state.count += 1\n\n    # Sleep one second here to simulate the process of assistant.\n    time.sleep(1)\n    with st.chat_message(\"assistant\"):\n        assistant = f\"Good at {st.session_state.count}\"\n        st.markdown(assistant)\n    # Add assistant message to chat history\n    st.session_state.messages.append({\"role\": \"assistant\", \"content\": assistant})\n", "e2e_playwright/st_file_uploader.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\nfrom streamlit import runtime\n\nsingle_file = st.file_uploader(\"Drop a file:\", type=[\"txt\"], key=\"single\")\nif single_file is None:\n    st.text(\"No upload\")\nelse:\n    st.text(single_file.read())\n\n# Here and throughout this file, we use `if runtime.is_running():`\n# since we also run e2e python files in \"bare Python mode\" as part of our\n# Python tests, and this doesn't work in that circumstance\n# st.session_state can only be accessed while running with streamlit\nif runtime.exists():\n    st.write(repr(st.session_state.single) == repr(single_file))\n\ndisabled = st.file_uploader(\n    \"Can't drop a file:\", type=[\"txt\"], key=\"disabled\", disabled=True\n)\nif disabled is None:\n    st.text(\"No upload\")\nelse:\n    st.text(disabled.read())\n\nif runtime.exists():\n    st.write(repr(st.session_state.disabled) == repr(disabled))\n\nmultiple_files = st.file_uploader(\n    \"Drop multiple files:\",\n    type=[\"txt\"],\n    accept_multiple_files=True,\n    key=\"multiple\",\n)\nif multiple_files is None:\n    st.text(\"No upload\")\nelse:\n    files = [file.read().decode() for file in multiple_files]\n    st.text(\"\\n\".join(files))\n\nif runtime.exists():\n    st.write(repr(st.session_state.multiple) == repr(multiple_files))\n\nwith st.form(\"foo\"):\n    form_file = st.file_uploader(\"Inside form:\", type=[\"txt\"])\n    st.form_submit_button(\"Submit\")\n    if form_file is None:\n        st.text(\"No upload\")\n    else:\n        st.text(form_file.read())\n\n\nhidden_label = st.file_uploader(\n    \"Hidden label:\",\n    key=\"hidden_label\",\n    label_visibility=\"hidden\",\n)\n\nif hidden_label is None:\n    st.text(\"No upload\")\nelse:\n    st.text(hidden_label.read())\n\nif runtime.exists():\n    st.write(repr(st.session_state.hidden_label) == repr(hidden_label))\n\ncollapsed_label = st.file_uploader(\n    \"Collapsed label:\",\n    key=\"collapsed_label\",\n    label_visibility=\"collapsed\",\n)\n\nif collapsed_label is None:\n    st.text(\"No upload\")\nelse:\n    st.text(collapsed_label.read())\n\nif runtime.exists():\n    st.write(repr(st.session_state.collapsed_label) == repr(collapsed_label))\n\nif runtime.exists():\n    if not st.session_state.get(\"counter\"):\n        st.session_state[\"counter\"] = 0\n\n    def file_uploader_on_change():\n        st.session_state.counter += 1\n\n    st.file_uploader(\n        \"Drop a file:\",\n        type=[\"txt\"],\n        key=\"on_change_file_uploader_key\",\n        on_change=file_uploader_on_change,\n    )\n\n    st.text(st.session_state.counter)\n", "e2e_playwright/st_alert.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\nst.error(\"This is an error\")\nst.warning(\"This is a warning\")\nst.info(\"This is an info message\")\nst.success(\"This is a success message\")\n\n# This is here so we can test the distance between alert messages and\n# elements above/below them.\nst.write(\"Some non-alert text!\")\n\nst.error(\"This is an error\", icon=\"\ud83d\udea8\")\nst.warning(\"This is a warning\", icon=\"\u26a0\ufe0f\")\nst.info(\"This is an info message\", icon=\"\ud83d\udc49\ud83c\udffb\")\nst.success(\"This is a success message\", icon=\"\u2705\")\n\n# Verify that line-wrapping works as expected both with and without break words.\nst.error(\"A\" + 100 * \"H\")\nst.error(\"If I repeat myself enough the line should \" + 20 * \"wrap \")\n\ntext = \"\"\"\n    This is an example error from caching.py\n\n    This error can occur when your virtual environment lives in the same\n    folder as your project, since that makes it hard for Streamlit to\n    understand which files it should check. If you think that's what caused\n    this, please add the following to `~/.streamlit/config.toml`:\n\n    ```toml\n    [server]\n    folderWatchBlacklist = ['foldername']\n    ```\n\n    ...where `foldername` is the relative or absolute path to the folder\n    where you put your virtual environment.\n\n    Otherwise, please [file a bug\n    here](https://github.com/streamlit/streamlit/issues/new/choose).\n\n    To stop this warning from showing in the meantime, try one of the\n    following:\n\n    * **Preferred:** modify your code to avoid using this type of object.\n    * Or add the argument `allow_output_mutation=True` to the `st.cache` decorator.\n    \"\"\"\n\nst.error(text)\nst.warning(text)\nst.info(text)\nst.success(text)\n\n# Check resolution of issue #6394\ntext = \"\"\"\nHere is some code:\n\n```\nimport streamlit as st\nst.write(\"Hello world!\")\n# this is a very long comment just to demonstrate the overflowing behavior it goes on and on and on\n```\n\"\"\"\n\nst.error(text, icon=\"\ud83d\udea8\")\nst.success(text)\n\nst.error(\"This is an error with non emoji icon\", icon=\":material/running_with_errors:\")\n\nst.warning(\"This is a warning with non emoji icon\", icon=\":material/warning:\")\nst.info(\"This is an info message with non emoji icon\", icon=\":material/info:\")\nst.success(\n    \"This is a success message with non emoji icon\",\n    icon=\":material/celebration:\",\n)\n", "e2e_playwright/st_write_stream.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport time\n\nimport numpy as np\nimport pandas as pd\n\nimport streamlit as st\n\nnp.random.seed(0)\n\n\n_LOREM_IPSUM = \"\"\"\nLorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut\nlabore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco\nlaboris nisi ut aliquip ex ea commodo consequat.\n\"\"\"\n\n\ndef stream_example():\n    for word in _LOREM_IPSUM.split():\n        yield word + \" \"\n        time.sleep(0.02)\n\n    yield pd.DataFrame(\n        np.random.randn(5, 10),\n        columns=[\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\"],\n    )\n\n    for word in \"This is the end of the stream.\".split():\n        yield word + \" \"\n        time.sleep(0.02)\n\n\nif st.button(\"Stream data\"):\n    st.session_state[\"written_content\"] = st.write_stream(stream_example)\nelse:\n    if \"written_content\" in st.session_state:\n        st.write(st.session_state[\"written_content\"])\n", "e2e_playwright/st_progress.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\nst.progress(50)\n\nst.progress(30, text=\"This is very long and boring text. \" * 6)\nst.progress(\n    0.5,\n    text=(\n        \"Please be patient :clock1:. **bold text**. $$ x = 1 + 2 $$, :blue[Blue text]\"\n    ),\n)\n", "e2e_playwright/st_bar_chart.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nfrom datetime import date\n\nimport numpy as np\nimport pandas as pd\n\nimport streamlit as st\n\nnp.random.seed(0)\n\n\ndata = np.random.randn(20, 3)\ndf = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\"])\n\n# st.area/bar/line_chart all use Altair/Vega-Lite under the hood.\n# By default, Vega-Lite displays time values in the browser's local\n# time zone, but data is sent down to the browser as UTC. This means\n# Times need to be set correctly to the users timezone.\nutc_df = pd.DataFrame(\n    {\n        \"index\": [\n            date(2019, 8, 9),\n            date(2019, 8, 10),\n            date(2019, 8, 11),\n            date(2019, 8, 12),\n        ],\n        \"numbers\": [10, 50, 30, 40],\n    }\n)\n\nutc_df.set_index(\"index\", inplace=True)\n\n# Dataframe to test the color parameter support:\nN = 100\n\ncolor_df = pd.DataFrame(\n    {\n        # Using a negative range so certain kinds of bugs are more visible.\n        \"a\": -np.arange(N),\n        \"b\": np.random.rand(N) * 10,\n        \"c\": np.random.rand(N) * 10,\n        \"d\": np.random.randn(N) * 30,\n        \"e\": [\"bird\" if x % 2 else \"airplane\" for x in range(N)],\n    }\n)\n\nst.header(\"Bar Chart\")\n\nst.bar_chart()\nst.bar_chart(df)\nst.bar_chart(df, x=\"a\")\nst.bar_chart(df, y=\"a\")\nst.bar_chart(df, y=[\"a\", \"b\"])\nst.bar_chart(df, x=\"a\", y=\"b\", height=500, width=300, use_container_width=False)\nst.bar_chart(df, x=\"b\", y=\"a\")\nst.bar_chart(df, x=\"a\", y=[\"b\", \"c\"])\nst.bar_chart(utc_df)\nst.bar_chart(color_df, x=\"a\", y=\"b\", color=\"e\")\nst.bar_chart(df, x_label=\"X Axis Label\", y_label=\"Y Axis Label\")\nst.bar_chart(df, horizontal=True)\nst.bar_chart(df, horizontal=True, x_label=\"X Label\", y_label=\"Y Label\")\n", "e2e_playwright/st_bokeh_chart.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport numpy as np\nfrom bokeh.layouts import column, row\nfrom bokeh.models import ColumnDataSource, CustomJS, Slider\nfrom bokeh.plotting import figure\n\nimport streamlit as st\n\nx = [1, 2, 3, 4, 5]\ny = [6, 7, 2, 4, 5]\n\np = figure(title=\"simple line example\", x_axis_label=\"x\", y_axis_label=\"y\")\np.line(x, y, legend=\"Trend\", line_width=2)\nst.bokeh_chart(p)\n\n# draw charts in columns\n\nleft_chart = figure(title=\"Left\", x_axis_label=\"x\", y_axis_label=\"y\")\nleft_chart.line(x, y, legend=\"Trend\", line_width=2)\n\nright_chart = figure(title=\"Right\", x_axis_label=\"x\", y_axis_label=\"y\")\nright_chart.line(x, y, legend=\"Trend\", line_width=2)\n\ncol1, col2 = st.columns([1, 1])\n\nwith col1:\n    st.bokeh_chart(left_chart, use_container_width=True)\n\nwith col2:\n    st.bokeh_chart(right_chart, use_container_width=True)\n\nx = np.linspace(0, 10, 500)\ny = np.sin(x)\n\nsource = ColumnDataSource(data={\"x\": x, \"y\": y})\n\nplot = figure(y_range=(-10, 10), width=400, height=400)\n\nplot.line(\"x\", \"y\", source=source, line_width=3, line_alpha=0.6)\n\namp = Slider(start=0.1, end=10, value=1, step=0.1, title=\"Amplitude\")\nfreq = Slider(start=0.1, end=10, value=1, step=0.1, title=\"Frequency\")\nphase = Slider(start=-6.4, end=6.4, value=0, step=0.1, title=\"Phase\")\noffset = Slider(start=-9, end=9, value=0, step=0.1, title=\"Offset\")\n\ncallback = CustomJS(\n    args={\"source\": source, \"amp\": amp, \"freq\": freq, \"phase\": phase, \"offset\": offset},\n    code=\"\"\"\n    const A = amp.value\n    const k = freq.value\n    const phi = phase.value\n    const B = offset.value\n\n    const x = source.data.x\n    const y = Array.from(x, (x) => B + A*Math.sin(k*x+phi))\n    source.data = { x, y }\n\"\"\",\n)\n\namp.js_on_change(\"value\", callback)\nfreq.js_on_change(\"value\", callback)\nphase.js_on_change(\"value\", callback)\noffset.js_on_change(\"value\", callback)\n\nst.bokeh_chart(row(plot, column(amp, freq, phase, offset)))\n", "e2e_playwright/st_status.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\nfrom streamlit.runtime.scriptrunner import get_script_run_ctx\n\nctx = get_script_run_ctx()\nif ctx is None:\n    import sys\n\n    # This script is not compatible with running it in \"bare\" mode (e.g. `python script.py`)\n    # The reason is that the mutable container is not correctly returned if\n    # the runtime doesn't exist.\n    print(\"This test script does not support bare script execution.\")\n    sys.exit(0)\n\n\nrunning_status = st.status(\"Running status\", expanded=True)\nrunning_status.write(\"Doing some work...\")\n\nwith st.status(\"Completed status\", expanded=True, state=\"complete\"):\n    st.write(\"Hello world\")\n\nwith st.status(\"Error status\", expanded=True, state=\"error\"):\n    st.error(\"Oh no, something went wrong!\")\n\nwith st.status(\"Collapsed\", state=\"complete\"):\n    st.write(\"Hello world\")\n\nwith st.status(\"About to change label...\", state=\"complete\") as status:\n    st.write(\"Hello world\")\n    status.update(label=\"Changed label\")\n\nstatus = st.status(\"Without context manager\", state=\"complete\")\nstatus.write(\"Hello world\")\nstatus.update(state=\"error\", expanded=True)\n\nwith st.status(\"Collapse via update...\", state=\"complete\", expanded=True) as status:\n    st.write(\"Hello world\")\n    status.update(label=\"Collapsed\", expanded=False)\n\nst.status(\"Empty state...\", state=\"complete\")\n\ntry:\n    with st.status(\"Uncaught exception\"):\n        st.write(\"Hello world\")\n        raise Exception(\"Error!\")\nexcept Exception:\n    pass\n", "e2e_playwright/st_toggle.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\nfrom streamlit import runtime\n\ni1 = st.toggle(\"toggle 1 (True)\", True)\nst.write(\"toggle 1 - value:\", i1)\n\ni2 = st.toggle(\"toggle 2 (False)\", False)\nst.write(\"toggle 2 - value:\", i2)\n\ni3 = st.toggle(\n    \"toggle 3: This is a really really really really long label that should wrap eventually if we keep addding more text to it \"\n)\nst.write(\"toggle 3 - value:\", i3)\n\nif runtime.exists():\n\n    def on_change():\n        st.session_state.toggle_clicked = True\n\n    st.toggle(\"toggle 4 (with callback)\", key=\"toggle4\", on_change=on_change)\n    st.write(\"toggle 4 - value:\", st.session_state.toggle4)\n    st.write(\"toggle 4 - clicked:\", \"toggle_clicked\" in st.session_state)\n\ni5 = st.toggle(\"toggle 5 (False, disabled)\", disabled=True)\nst.write(\"toggle 5 - value:\", i5)\n\ni6 = st.toggle(\"toggle 6 (True, disabled)\", value=True, disabled=True)\nst.write(\"toggle 6 - value:\", i6)\n\ni7 = st.toggle(\"toggle 7 (label hidden)\", label_visibility=\"hidden\")\nst.write(\"toggle 7 - value:\", i7)\n\ni8 = st.toggle(\"toggle 8 (label collapsed)\", label_visibility=\"collapsed\")\nst.write(\"toggle 8 - value:\", i8)\n\nwith st.expander(\"Grouped toggles\", expanded=True):\n    st.toggle(\"toggle group - 1\")\n    st.toggle(\"toggle group - 2\")\n    st.toggle(\"toggle group - 3\")\n    st.text(\"A non-toggle element\")\n", "e2e_playwright/st_expander.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\nsidebar = st.sidebar.expander(\"Expand me!\")\nsidebar.write(\"I am in the sidebar\")\n\nexpander = st.expander(\"Collapse me!\", expanded=True)\nexpander.write(\"I can collapse\")\nexpander.slider(\"I don't get cut off\")\nexpander.button(\"I'm also not cut off (while focused)\")\n\ncollapsed = st.expander(\"_Expand_ **me**!\")\ncollapsed.write(\"I am already collapsed\")\n\nst.expander(\"Empty expander\")\n\nwith st.expander(\"Expander with number input\", expanded=True):\n    # We deliberately use a list to implement this for the screenshot\n    st.write(\"* Example list item\")\n    value = st.number_input(\"number\", value=1.0, key=\"number\")\n\n\ndef update_value():\n    st.session_state.number = 0\n\n\nupdate_button = st.button(\"Update Num Input\", on_click=update_value)\n\nst.text(st.session_state.get(\"number\"))\n\nif st.button(\"Print State Value\"):\n    st.text(st.session_state.get(\"number\"))\n\nexpander_long = st.expander(\n    \"Expand me! \"\n    \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vestibulum arcu nisl, tincidunt id \"\n    \"orci id, condimentum cursus nunc. Nullam sed sodales ipsum, vel tincidunt dui. Etiam diam \"\n    \"dolor, eleifend sit amet purus id, dictum aliquam quam.\",\n    expanded=True,\n)\nexpander_long.write(\n    \"I can collapse. \"\n    \"Integer et justo orci. In euismod posuere nulla ac maximus. Mauris tristique hendrerit \"\n    \"placerat. Integer eu imperdiet ipsum. Praesent maximus pharetra est, ut ultrices ante \"\n    \"molestie id. Nulla sollicitudin arcu orci, eget lobortis lacus ultricies eu. Ut suscipit est \"\n    \"eget tellus laoreet faucibus. Nullam nec blandit felis. Nulla ullamcorper, justo eget \"\n    \"consequat ultricies, nisi dolor lacinia mauris, eu lacinia ante nisi sit amet tortor.\"\n)\n\ncollapsed_long = st.expander(\n    \"Expand me! \"\n    \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vestibulum arcu nisl, tincidunt id \"\n    \"orci id, condimentum cursus nunc. Nullam sed sodales ipsum, vel tincidunt dui. Etiam diam \"\n    \"dolor, eleifend sit amet purus id, dictum aliquam quam.\"\n)\ncollapsed_long.write(\"I am already collapsed\")\n\nexpander_material_icon = st.expander(\n    \"Expander with material icon!\", icon=\":material/bolt:\"\n).write(\"This is an expander with a material icon.\")\n\nexpander_emoji_icon = st.expander(\"Expander with emoji icon!\", icon=\"\ud83c\udf88\").write(\n    \"This is an expander with an emoji icon.\"\n)\n", "e2e_playwright/st_chat_message.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\n\nimport streamlit as st\n\nnp.random.seed(0)\n\n\n# Generate a random dataframe\ndf = pd.DataFrame(\n    np.random.randn(5, 5),\n    columns=(\"col_%d\" % i for i in range(5)),\n)\n\n\nwith st.chat_message(\"user\"):\n    st.write(\"Hello\u2026\")\n\nwith st.chat_message(\"assistant\"):\n    st.write(\n        \"\"\"\nHello, here is a code snippet:\n\n```python\nimport streamlit as st\nwith st.chat_message(\"assistant\"):\n     st.write(\"Hello, here is a code snippet...\")\n```\n\"\"\"\n    )\n\nwith st.chat_message(\"user\", avatar=\"\ud83e\uddd1\"):\n    st.write(\n        \"\"\"\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Mauris tristique est\nat tincidunt pul vinar. Nam pulvinar neque sapien, eu pellentesque metus pellentesque\nat. Ut et dui molestie, iaculis magna sed.\n\"\"\"\n    )\n\nwith st.chat_message(\"dog\", avatar=\"https://static.streamlit.io/examples/dog.jpg\"):\n    st.write(\"Woof woof! I'm a dog and I like charts:\")\n    st.line_chart(df, use_container_width=True)\n\ncat = st.chat_message(\"cat\", avatar=\"https://static.streamlit.io/examples/cat.jpg\")\ncat.write(\"I'm a cat and I like this dataset:\")\ncat.dataframe(df, use_container_width=True)\ncat.text_input(\"What's your name?\")\n\n\nwith st.chat_message(\"Bot\"):\n    with st.expander(\"See more\", expanded=True):\n        st.write(\"Lorem ipsum dolor sit amet\")\n\nst.chat_message(\"human\")\n\n\nimage1 = Image.new(\"RGB\", (10, 255), \"red\")\nst.chat_message(\"user\", avatar=image1).write(\"Red local image\")\n\nimage2 = Image.new(\"RGB\", (10, 10), \"blue\")\nst.chat_message(\"assistant\", avatar=image2).write(\"Blue local image\")\nst.chat_message(\"assistant\", avatar=image2).write(\n    \"Another message with the same blue avatar.\"\n)\n\nwith st.chat_message(\"user\", avatar=\":material/airline_seat_recline_extra:\"):\n    st.write(\"Hello from USER, non-emoji icon.\")\n\nwith st.chat_message(\"AI\", avatar=\":material/photo_album:\"):\n    st.write(\"Hello from AI, non-emoji icon.\")\n\nquery = \"This is a hardcoded user message\"\nsources = \"example sources\"\nllm_response = \"some response\"\n\npast_messages = st.empty()\n\nif \"messages\" not in st.session_state:\n    st.session_state.messages = []\n\nwith past_messages.container():\n    for message in st.session_state.messages:\n        with st.chat_message(message[\"role\"]):\n            st.markdown(message[\"content\"])\n            if message[\"role\"] != \"user\":\n                with st.expander(\"See sources\"):\n                    st.markdown(message[\"sources\"])\n\nwith st.chat_message(\"user\"):\n    st.markdown(query)\n\nuser_message = {\"role\": \"user\", \"content\": query, \"sources\": \"\"}\nst.session_state.messages.append(user_message)\n\nwith st.chat_message(\"assistant\"):\n    displayed_response = st.empty()\n    with displayed_response.container():\n        st.markdown(llm_response)\n        with st.expander(\"See sources\"):\n            st.markdown(sources)\n\nassistant_message = {\"role\": \"assistant\", \"content\": llm_response, \"sources\": sources}\nst.session_state.messages.append(assistant_message)\n", "e2e_playwright/st_columns.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport os\n\nimport streamlit as st\n\n# Construct test assets path relative to this script file to\n# allow its execution with different working directories.\nTEST_ASSETS_DIR = os.path.join(\n    os.path.dirname(os.path.abspath(__file__)), \"test_assets\"\n)\n\nCAT_IMAGE = os.path.join(TEST_ASSETS_DIR, \"cat.jpg\")\nLOREM_IPSUM = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.\"\n\n# Basic columns:\nc1, c2, c3 = st.columns(3)\n\nc1.write(LOREM_IPSUM)\nc2.write(LOREM_IPSUM)\nc3.write(LOREM_IPSUM)\n\n# Only fill in the last column and keep the others empty\nc1, c2, c3 = st.columns(3)\nc3.write(LOREM_IPSUM)\n\nwith st.expander(\"Variable-width columns (relative numbers)\", expanded=True):\n    for c in st.columns([0.6, 0.3, 0.1]):\n        c.image(CAT_IMAGE)\n\nwith st.expander(\"Variable-width columns (absolute numbers)\", expanded=True):\n    for c in st.columns((1, 2, 3, 4)):\n        c.image(CAT_IMAGE)\n\n# Various column gaps\nwith st.expander(\"Column gap small\", expanded=True):\n    c4, c5, c6 = st.columns(3, gap=\"small\")\n    c4.image(CAT_IMAGE)\n    c5.image(CAT_IMAGE)\n    c6.image(CAT_IMAGE)\n\nwith st.expander(\"Column gap medium\", expanded=True):\n    c7, c8, c9 = st.columns(3, gap=\"medium\")\n    c7.image(CAT_IMAGE)\n    c8.image(CAT_IMAGE)\n    c9.image(CAT_IMAGE)\n\nwith st.expander(\"Column gap large\", expanded=True):\n    c10, c11, c12 = st.columns(3, gap=\"large\")\n    c10.image(CAT_IMAGE)\n    c11.image(CAT_IMAGE)\n    c12.image(CAT_IMAGE)\n\nwith st.expander(\"Nested columns - one level\", expanded=True):\n    col1, col2 = st.columns(2)\n    with col1:\n        subcol1, subcol2 = st.columns(2)\n        subcol1.write(LOREM_IPSUM)\n        subcol2.write(LOREM_IPSUM)\n        st.write(\"\")\n        st.write(LOREM_IPSUM)\n\n    with col2:\n        subcol1, subcol2 = st.columns(2)\n        subcol1.write(LOREM_IPSUM)\n        subcol2.write(LOREM_IPSUM)\n        st.write(\"\")\n        subcol1, subcol2 = st.columns(2)\n        subcol1.write(LOREM_IPSUM)\n        subcol2.write(LOREM_IPSUM)\n\nwith st.expander(\"Vertical alignment - top\", expanded=True):\n    col1, col2, col3 = st.columns(3, vertical_alignment=\"top\")\n    col1.text_input(\"Text input (top)\")\n    col2.button(\"Button (top)\", use_container_width=True)\n    col3.checkbox(\"Checkbox (top)\")\n\nwith st.expander(\"Vertical alignment - center\", expanded=True):\n    col1, col2, col3 = st.columns(3, vertical_alignment=\"center\")\n    col1.text_input(\"Text input (center)\")\n    col2.button(\"Button (center)\", use_container_width=True)\n    col3.checkbox(\"Checkbox (center)\")\n\nwith st.expander(\"Vertical alignment - bottom\", expanded=True):\n    col1, col2, col3 = st.columns(3, vertical_alignment=\"bottom\")\n    col1.text_input(\"Text input (bottom)\")\n    col2.button(\"Button (bottom)\", use_container_width=True)\n    col3.checkbox(\"Checkbox (bottom)\")\n\nif st.button(\"Nested columns - two levels (raises exception)\"):\n    col1, col2 = st.columns(2)\n    with col1:\n        subcol1, subcol2 = st.columns(2)\n        with subcol1:\n            subcol1.write(LOREM_IPSUM)\n            subsubcol1, subsubcol2 = st.columns(2)\n            subsubcol1.write(LOREM_IPSUM)\n            subsubcol2.write(LOREM_IPSUM)\n        subcol2.write(LOREM_IPSUM)\n        st.write(LOREM_IPSUM)\n\nif st.button(\"Nested columns - in sidebar (raises exception)\"):\n    with st.sidebar:\n        col1, col2 = st.columns(2)\n        col1.text_input(\"Text input 1\")\n        col2.text_input(\"Text input 2\")\n        col3, col4 = col1.columns(2)\n        col3.text_input(\"Text input 3\")\n        col4.text_input(\"Text input 4\")\n        st.text_input(\"Text input 5\")\n", "e2e_playwright/config_static_serving.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\nif not st.get_option(\"server.enableStaticServing\"):\n    st.error(\n        \"**ERROR**. This test needs to be run with `--server.enableStaticServing`.\"\n    )\n\nst.markdown(\n    \"\"\"\nImages served via static serving:\n\n![Streamlit](./app/static/streamlit-logo.png)\n\"\"\"\n)\n", "e2e_playwright/st_map.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom typing import Any, cast\n\nimport numpy as np\nimport pandas as pd\n\nimport streamlit as st\n\n\"\"\"\n### Empty map\n\"\"\"\n\nst.map()\n\n\n\"\"\"\n### Simple map\n\"\"\"\n\n# Cast is needed due to mypy not understanding the outcome of dividing\n# an array by a list of numbers.\nnp.random.seed(0)\ncoords: \"np.typing.NDArray[np.float64]\" = cast(\n    Any,\n    np.random.randn(1000, 2) / [50, 50],\n) + [37.76, -122.4]\ndf = pd.DataFrame(coords, columns=[\"lat\", \"lon\"])\n\nst.map(df)\n\n\n\"\"\"\n### Simple map with zoom\n\"\"\"\n\nst.map(df, zoom=8)\n\n\n\"\"\"\n### Map with color and size layers\n\"\"\"\n\ndf = pd.DataFrame(\n    {\n        \"xlat\": [38.8762997, 38.8742997, 38.9025842],\n        \"xlon\": [-77.0037, -77.0057, -77.0556545],\n        \"color\": [\"#f00\", \"#f0f\", \"#00f\"],\n        \"size\": [1000, 500, 300],\n    }\n)\n\nst.map(\n    df,\n    latitude=\"xlat\",\n    longitude=\"xlon\",\n    color=\"color\",\n    size=\"size\",\n    use_container_width=False,\n)\n", "e2e_playwright/widget_state.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport time\n\nimport streamlit as st\n\nst.header(\"Widget State - Heavy Usage Test\")\n# Test for https://github.com/streamlit/streamlit/issues/4836\n\nnumber = st.number_input(\"test\", value=0, step=1)\nst.write(number)\n\nif number:\n    time.sleep(1)\n\nst.header(\"Widget State - Redisplayed Widget Test\")\n# Test for https://github.com/streamlit/streamlit/issues/3512\n\nif st.checkbox(\"Display widgets\"):\n    if st.checkbox(\"Show hello\"):\n        st.write(\"hello\")\n\n    if st.checkbox(\"Show goodbye\", key=\"c3\"):\n        st.write(\"goodbye\")\n", "e2e_playwright/app_hotkeys.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\nst.text_input(\"text_input\")\n", "e2e_playwright/st_experimental_fragment_multiple_fragments.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom uuid import uuid4\n\nimport streamlit as st\n\n\n@st.experimental_fragment\ndef my_fragment(n):\n    with st.container(border=True):\n        st.button(\"rerun this fragment\", key=n)\n        st.write(f\"uuid in fragment {n}: {uuid4()}\")\n\n\nmy_fragment(1)\nmy_fragment(2)\n", "e2e_playwright/st_balloons.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\nst.balloons()\n", "e2e_playwright/st_area_chart.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nfrom datetime import date\n\nimport numpy as np\nimport pandas as pd\n\nimport streamlit as st\n\nnp.random.seed(0)\n\n\ndata = np.random.randn(20, 3)\ndf = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\"])\n\n# st.area/bar/line_chart all use Altair/Vega-Lite under the hood.\n# By default, Vega-Lite displays time values in the browser's local\n# time zone, but data is sent down to the browser as UTC. This means\n# Times need to be set correctly to the users timezone.\nutc_df = pd.DataFrame(\n    {\n        \"index\": [\n            date(2019, 8, 9),\n            date(2019, 8, 10),\n            date(2019, 8, 11),\n            date(2019, 8, 12),\n        ],\n        \"numbers\": [10, 50, 30, 40],\n    }\n)\n\nutc_df.set_index(\"index\", inplace=True)\n\n# Dataframe to test the color parameter support:\nN = 100\n\ncolor_df = pd.DataFrame(\n    {\n        # Using a negative range so certain kinds of bugs are more visible.\n        \"a\": -np.arange(N),\n        \"b\": np.random.rand(N) * 10,\n        \"c\": np.random.rand(N) * 10,\n        \"d\": np.random.randn(N) * 30,\n        \"e\": [\"bird\" if x % 2 else \"airplane\" for x in range(N)],\n    }\n)\n\nst.header(\"Area Chart\")\n\nst.area_chart()\nst.area_chart(df)\nst.area_chart(df, x=\"a\")\nst.area_chart(df, y=\"a\")\nst.area_chart(df, y=[\"a\", \"b\"])\nst.area_chart(df, x=\"a\", y=\"b\", height=500, width=300, use_container_width=False)\nst.area_chart(df, x=\"b\", y=\"a\")\nst.area_chart(df, x=\"a\", y=[\"b\", \"c\"])\nst.area_chart(utc_df)\nst.area_chart(color_df, x=\"a\", y=\"b\", color=\"e\")\nst.area_chart(df, x_label=\"X Axis Label\", y_label=\"Y Axis Label\")\n", "e2e_playwright/st_write.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport io\nfrom dataclasses import dataclass\nfrom datetime import datetime\nfrom typing import NamedTuple\n\nimport altair as alt\nimport graphviz\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport plotly.express as px\nimport pydeck as pdk\nfrom PIL import Image\n\nimport streamlit as st\n\nnp.random.seed(0)\n\nst.subheader(\"st.write(markdown)\")\n\nst.write(\"Hello\", \"World\")\n\nst.write(\"This **markdown** is awesome! :sunglasses:\")\n\nst.write(\"This <b>HTML tag</b> is escaped!\")\n\nst.write(\"This <b>HTML tag</b> is not escaped!\", unsafe_allow_html=True)\n\n\nclass ClassWithReprHtml:\n    def _repr_html_(self):\n        return \"This <b>HTML tag</b> is also not escaped!\"\n\n\nst.write(ClassWithReprHtml())\nst.write(ClassWithReprHtml(), unsafe_allow_html=True)\n\nst.write(100)\n\nst.write(None)\n\nst.write(datetime(2021, 1, 1))\n\nst.write(np.float64(1.0))\n\n\nclass SomeObject1:\n    def __str__(self):\n        return \"1 * 2 - 3 = 4 `ok` !\"\n\n\nst.write(SomeObject1())  # escaped single line string\n\n\nclass SomeObject2:\n    def __str__(self):\n        return \"1 * 2\\n - 3\\n ``` = \\n````\\n4 `ok` !\"\n\n\nst.write(SomeObject2())  # escaped multiline string\n\nstring_io = io.StringIO()\nstring_io.write(\"This is a string IO object!\")\n\nst.write(string_io)\n\n\ndef stream_text():\n    yield \"This is \"\n    yield \"streamed text\"\n\n\nst.subheader(\"st.write(generator)\")\n\nst.write(stream_text)\n\nst.write(stream_text())\n\n\nst.subheader(\"st.write(dataframe-like)\")\n\nst.write(pd.DataFrame(np.random.randn(25, 3), columns=[\"a\", \"b\", \"c\"]))\n\nst.write(pd.Series([1, 2, 3]))\n\nst.write(\n    pd.DataFrame(np.random.randn(25, 3), columns=[\"a\", \"b\", \"c\"]).style.format(\"{:.2%}\")\n)\n\nst.write(np.arange(25).reshape(5, 5))\n\nst.subheader(\"st.write(json-like)\")\n\nst.write([\"foo\", \"bar\"])\n\nst.write({\"foo\": \"bar\"})\n\nst.write(st.session_state)\nst.write(st.experimental_user)\nst.write(st.query_params)\n\n\nclass Point(NamedTuple):\n    x: int\n    y: int\n\n\nst.write(Point(1, 2))\n\nst.subheader(\"st.write(help)\")\n\nst.write(st.dataframe)\n\n\n@dataclass\nclass ExampleClass:\n    name: str\n    age: int\n\n\nst.write(ExampleClass)\n\nst.subheader(\"st.write(exception)\")\n\nst.write(Exception(\"This is an exception!\"))\n\nst.subheader(\"st.write(matplotlib)\")\n\nfig, ax = plt.subplots()\nax.hist(np.random.normal(1, 1, size=100), bins=20)\n\nst.write(fig)\n\nst.subheader(\"st.write(altair)\")\n\ndf = pd.DataFrame(np.random.randn(50, 3), columns=[\"a\", \"b\", \"c\"])\nchart = alt.Chart(df).mark_circle().encode(x=\"a\", y=\"b\", size=\"c\", color=\"c\")\nst.write(chart)\n\nst.subheader(\"st.write(plotly)\")\n\nfig = px.scatter(df, x=\"a\", y=\"b\")\nst.write(fig)\n\nst.subheader(\"st.write(graphviz)\")\n\ngraph = graphviz.Digraph()\ngraph.edge(\"run\", \"intr\")\ngraph.edge(\"intr\", \"runbl\")\ngraph.edge(\"runbl\", \"run\")\n\nst.write(graph)\n\n# Simple pydeck chart:\n\nst.subheader(\"st.write(pydeck)\")\n\nst.write(\n    pdk.Deck(\n        map_style=None,\n        initial_view_state=pdk.ViewState(\n            latitude=37.76,\n            longitude=-122.4,\n            zoom=11,\n            pitch=50,\n        ),\n    )\n)\n\nst.subheader(\"st.write(Image)\")\n\nst.write(Image.new(\"L\", (10, 10), \"black\"))\n", "e2e_playwright/st_experimental_get_query_params.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\nquery_params = st.experimental_get_query_params()\nst.write(str(query_params))\n", "e2e_playwright/st_set_page_config_icon.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport os\n\nimport streamlit as st\n\n# Construct test assets path relative to this script file to\n# allow its execution with different working directories.\nTEST_ASSETS_DIR = os.path.join(\n    os.path.dirname(os.path.abspath(__file__)), \"test_assets\"\n)\nICON_PATH = os.path.join(TEST_ASSETS_DIR, \"favicon.ico\")\n\nst.set_page_config(page_icon=str(ICON_PATH))\n", "e2e_playwright/st_multiselect.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom typing import Any\n\nimport streamlit as st\nfrom streamlit import runtime\n\n\ndef set_multiselect_9_to_have_bad_state():\n    if \"multiselect 9\" in st.session_state:\n        st.session_state[\"multiselect 9\"] = [\"male\", \"female\"]\n\n\noptions = (\"male\", \"female\")\n\ni1 = st.multiselect(\n    \"multiselect 1\", options, placeholder=\"Please select\", help=\"Help text\"\n)\nst.text(f\"value 1: {i1}\")\n\ni2 = st.multiselect(\"multiselect 2\", options, format_func=lambda x: x.capitalize())\nst.text(f\"value 2: {i2}\")\n\ni3: list[Any] = st.multiselect(\"multiselect 3\", [])\nst.text(f\"value 3: {i3}\")\n\ni4 = st.multiselect(\"multiselect 4\", [\"coffee\", \"tea\", \"water\"], [\"tea\", \"water\"])\nst.text(f\"value 4: {i4}\")\n\ni5 = st.multiselect(\n    \"multiselect 5\",\n    [\n        f\"{x} I am a ridiculously long string to have in a multiselect, so perhaps I should just not wrap and go to the next line.\"\n        for x in range(5)\n    ],\n)\nst.text(f\"value 5: {i5}\")\n\ni6 = st.multiselect(\"multiselect 6\", options, disabled=True)\nst.text(f\"value 6: {i6}\")\n\ni7 = st.multiselect(\"Hidden label\", options, label_visibility=\"hidden\")\nst.text(f\"value 7: {i7}\")\n\ni8 = st.multiselect(\"Collapsed label\", options, label_visibility=\"collapsed\")\nst.text(f\"value 8: {i8}\")\n\nset_multiselect_9 = st.checkbox(\n    \"set_multiselect_9\", on_change=set_multiselect_9_to_have_bad_state\n)\n\ni9 = st.multiselect(\"multiselect 9\", options, max_selections=1, key=\"multiselect 9\")\nst.text(f\"value 9: {i9}\")\n\nwith st.form(\"my_max_selections_ms_in_form\"):\n    i10 = st.multiselect(\n        \"multiselect 10\", options, max_selections=1, key=\"multiselect 10\"\n    )\n    st.text(f\"value 10: {i10}\")\n    submitted = st.form_submit_button(\"Submit\")\n\nif runtime.exists():\n\n    def on_change():\n        st.session_state.multiselect_changed = True\n\n    st.multiselect(\"multiselect 11\", options, key=\"multiselect11\", on_change=on_change)\n    st.text(f\"value 11: {st.session_state.multiselect11}\")\n    st.text(f\"multiselect changed: {'multiselect_changed' in st.session_state}\")\n", "e2e_playwright/st_line_chart.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nfrom datetime import date\n\nimport numpy as np\nimport pandas as pd\n\nimport streamlit as st\n\nnp.random.seed(0)\n\n\ndata = np.random.randn(20, 3)\ndf = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\"])\n\n# st.area/bar/line_chart all use Altair/Vega-Lite under the hood.\n# By default, Vega-Lite displays time values in the browser's local\n# time zone, but data is sent down to the browser as UTC. This means\n# Times need to be set correctly to the users timezone.\nutc_df = pd.DataFrame(\n    {\n        \"index\": [\n            date(2019, 8, 9),\n            date(2019, 8, 10),\n            date(2019, 8, 11),\n            date(2019, 8, 12),\n        ],\n        \"numbers\": [10, 50, 30, 40],\n    }\n)\n\nutc_df.set_index(\"index\", inplace=True)\n\n# Dataframe to test the color parameter support:\nN = 100\n\ncolor_df = pd.DataFrame(\n    {\n        # Using a negative range so certain kinds of bugs are more visible.\n        \"a\": -np.arange(N),\n        \"b\": np.random.rand(N) * 10,\n        \"c\": np.random.rand(N) * 10,\n        \"d\": np.random.randn(N) * 30,\n        \"e\": [\"bird\" if x % 2 else \"airplane\" for x in range(N)],\n    }\n)\n\nst.header(\"Line Chart\")\n\nst.line_chart()\nst.line_chart(df)\nst.line_chart(df, x=\"a\")\nst.line_chart(df, y=\"a\")\nst.line_chart(df, y=[\"a\", \"b\"])\nst.line_chart(df, x=\"a\", y=\"b\", height=500, width=300, use_container_width=False)\nst.line_chart(df, x=\"b\", y=\"a\")\nst.line_chart(df, x=\"a\", y=[\"b\", \"c\"])\nst.line_chart(utc_df)\nst.line_chart(color_df, x=\"a\", y=\"b\", color=\"e\")\nst.line_chart(df, x_label=\"X Axis Label\", y_label=\"Y Axis Label\")\n", "e2e_playwright/st_magic.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"File docstring. Should not be printed.\"\"\"\n\nimport asyncio\nimport contextlib\n\nasync_loop = asyncio.new_event_loop()\n\n# Standalone statements should be printed\n\"no block\"\n\na = \"printed\"\n\"This should be\", a\n\n# Standalone statements within blocks should be printed\n\nif True:\n    \"IF\"\n\nif False:\n    pass\nelif True:\n    \"ELIF\"\n\nif False:\n    pass\nelse:\n    \"ELSE\"\n\n\nfor _ in range(1):\n    \"FOR\"\n\nwhile True:\n    \"WHILE\"\n    break\n\n\n@contextlib.contextmanager\ndef context_mgr():\n    try:\n        yield\n    finally:\n        pass\n\n\nwith context_mgr():\n    \"WITH\"\n\ntry:\n    \"TRY\"\nexcept:\n    raise\n\ntry:\n    raise RuntimeError(\"shenanigans!\")\nexcept RuntimeError:\n    \"EXCEPT\"\n\ntry:\n    pass\nfinally:\n    \"FINALLY\"\n\n\ndef func(value):\n    value\n\n\nfunc(\"FUNCTION\")\n\n\nasync def async_func(value):\n    value\n\n\nasync_loop.run_until_complete(async_func(\"ASYNC FUNCTION\"))\n\n\nasync def async_for():\n    async def async_iter():\n        yield\n\n    async for _ in async_iter():\n        \"ASYNC FOR\"\n\n\nasync_loop.run_until_complete(async_for())\n\n\nasync def async_with():\n    @contextlib.asynccontextmanager\n    async def async_context_mgr():\n        try:\n            yield\n        finally:\n            pass\n\n    async with async_context_mgr():\n        \"ASYNC WITH\"\n\n\nasync_loop.run_until_complete(async_with())\n\n# Docstrings should never be printed\n\n\ndef docstrings():\n    \"\"\"Docstring. Should not be printed.\"\"\"\n\n    def nested():\n        \"\"\"Multiline docstring.\n        Should not be printed.\"\"\"\n        pass\n\n    class Foo:\n        \"\"\"Class docstring. Should not be printed.\"\"\"\n\n        pass\n\n    nested()\n\n\ndocstrings()\n\n\ndef my_func():\n    \"\"\"my_func: this help block should be printed.\"\"\"\n    pass\n\n\nmy_func\n\n\nclass MyClass:\n    \"\"\"MyClass: this help block should be printed.\"\"\"\n\n    def __init__(self):\n        \"\"\"This should not be printed.\"\"\"\n\n\nMyClass\n\n\nmy_instance = MyClass()\nmy_instance\n", "e2e_playwright/st_echo.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\nwith st.echo():\n    st.write(\"This code is awesome!\")\n\nwith st.echo(code_location=\"below\"):\n    st.write(\"This code is awesome!\")\n", "e2e_playwright/st_components_v1_import_legacy_file.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n# PLEASE DO NOT ADD MORE IMPORTS HERE OR MOVE THE CODE TO ANOTHER FILE.\n# This file relies on a clean import to make sure the functionality is not made available transiently.\n# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n\nfrom streamlit.components.v1 import components\n\ncomponents.declare_component\ncomponents.CustomComponent\n", "e2e_playwright/st_metric.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\ncol1, col2, col3 = st.columns(3)\n\nwith col1:\n    st.metric(\"User growth\", 123, 123, \"normal\")\nwith col2:\n    st.metric(\"S&P 500\", -4.56, -50)\nwith col3:\n    st.metric(\"Apples I've eaten\", \"23k\", \" -20\", \"off\")\n\nwith col1:\n    st.metric(\"Test 3\", -4.56, 1.23, label_visibility=\"visible\")\nwith col2:\n    st.metric(\"Test 4\", -4.56, 1.23, label_visibility=\"hidden\")\nwith col3:\n    st.metric(\"Test 5\", -4.56, 1.23, label_visibility=\"collapsed\")\n\nst.metric(\n    \"User growth and a relatively long title\", 123, help=\"testing help without a column\"\n)\n\nst.metric(\"label title\", None, None, help=\"testing help without a column\")\n\ncol1, col2, col3, col4, col5, col6, col7, col8 = st.columns(8)\n\nwith col1:\n    st.metric(\n        label=\"Example metric\",\n        help=\"Something should feel right\",\n        value=150.59,\n        delta=\"Very high\",\n    )\n", "e2e_playwright/host_config.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport numpy as np\nimport pandas as pd\n\nimport streamlit as st\n\n# always generate the same data\nnp.random.seed(0)\n\nst.image(np.repeat(0, 100).reshape(10, 10))\nst.dataframe(\n    pd.DataFrame(np.random.randint(0, 100, size=(100, 4)), columns=list(\"ABCD\"))\n)\n", "e2e_playwright/st_tabs_selection.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\nst.subheader(\"Control Panel\", divider=\"blue\")\n\nif \"tabs\" not in st.session_state:\n    st.session_state[\"tabs\"] = [\"Tab 1\", \"Tab 2\"]\nif \"add_tab\" not in st.session_state:\n    st.session_state[\"add_tab\"] = False\nif \"remove_1\" not in st.session_state:\n    st.session_state[\"remove_1\"] = False\nif \"remove_2\" not in st.session_state:\n    st.session_state[\"remove_2\"] = False\nif \"change\" not in st.session_state:\n    st.session_state[\"change\"] = False\n\n\ndef on_click_1():\n    st.session_state.add_tab = True\n\n\ndef on_click_2():\n    st.session_state.remove_1 = True\n\n\ndef on_click_3():\n    st.session_state.remove_2 = True\n\n\ndef on_click_4():\n    st.session_state.change = True\n    on_click_1()\n    on_click_2()\n    on_click_3()\n\n\ndef on_click_5():\n    on_click_4()\n\n\ndef reset():\n    st.session_state.clear()\n\n\ncol1, col2, col3, col4, col5 = st.columns([0.8, 1, 1, 1.2, 1], gap=\"small\")\nwith col1:\n    add_tab = st.button(\n        \"Add Tab 3\",\n        on_click=on_click_1,\n        disabled=st.session_state.add_tab,\n        use_container_width=True,\n    )\nwith col2:\n    remove_1 = st.button(\n        \"Remove Tab 1\",\n        on_click=on_click_2,\n        disabled=st.session_state.remove_1,\n        use_container_width=True,\n    )\nwith col3:\n    remove_2 = st.button(\n        \"Remove Tab 2\",\n        on_click=on_click_3,\n        disabled=st.session_state.remove_2,\n        use_container_width=True,\n    )\nwith col4:\n    change_some = st.button(\n        \"Change Tab 1 & 3\",\n        on_click=on_click_4,\n        disabled=st.session_state.change,\n        use_container_width=True,\n    )\n    change = st.button(\n        \"Change All Tabs\",\n        on_click=on_click_5,\n        disabled=st.session_state.change,\n        use_container_width=True,\n    )\nwith col5:\n    st.button(\"**Reset Tabs**\", on_click=reset)\n\nst.subheader(\"Tabs Example\", divider=\"green\")\n\nif add_tab:\n    st.session_state.tabs.append(\"Tab 3\")\n\nif remove_1:\n    index = st.session_state.tabs.index(\"Tab 1\")\n    st.session_state.tabs.pop(index)\n\nif remove_2:\n    index = st.session_state.tabs.index(\"Tab 2\")\n    st.session_state.tabs.pop(index)\n\nif change:\n    if \"Tab 1\" in st.session_state.tabs:\n        st.session_state.tabs[st.session_state.tabs.index(\"Tab 1\")] = \"Tab A\"\n    if \"Tab 2\" in st.session_state.tabs:\n        st.session_state.tabs[st.session_state.tabs.index(\"Tab 2\")] = \"Tab B\"\n    if \"Tab 3\" in st.session_state.tabs:\n        st.session_state.tabs[st.session_state.tabs.index(\"Tab 3\")] = \"Tab C\"\n\nif change_some:\n    if \"Tab 1\" in st.session_state.tabs:\n        st.session_state.tabs[st.session_state.tabs.index(\"Tab 1\")] = \"Tab A\"\n    if \"Tab 3\" in st.session_state.tabs:\n        st.session_state.tabs[st.session_state.tabs.index(\"Tab 3\")] = \"Tab C\"\n\n\ntabs = st.tabs(st.session_state.tabs)\n\nfor tabs_index, tab in enumerate(tabs):\n    with tab:\n        st.write(f\"You are in Tab {tabs_index + 1}\")\n        st.slider(f\"Slider {tabs_index + 1}\", 0, 10, 5, key=tab)\n", "e2e_playwright/responsive.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport numpy as np\n\nimport streamlit as st\n\nimg = np.repeat(0, 3000 * 800).reshape(800, 3000)\nst.image(img)\n", "e2e_playwright/lazy_loaded_modules.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport importlib.util\nimport sys\n\nimport streamlit as st\n\nlazy_loaded_modules = [\n    \"altair\",\n    \"bokeh\",\n    \"graphviz\",\n    \"matplotlib\",\n    \"numpy\",\n    # There is currently a 10% probability that we check for new\n    # versions on streamlit start-up. This is using the packaging module.\n    # So, we cannot check this without it being flaky.\n    # \"packaging\",\n    \"pandas\",\n    # Pillow is lazy-loaded, but it gets imported by plotly,\n    # which we have to import in case it is installed to correctly\n    # configure the Streamlit theme. So, we cannot test this here.\n    # \"PIL\",\n    \"pyarrow\",\n    \"pydeck\",\n    \"rich\",\n    \"tenacity\",\n    # toml is automatically loaded if there is a secret.toml, config.toml or\n    # a local credentials.toml file.\n    \"toml\",\n    \"unittest\",\n    # Internal modules:\n    \"streamlit.emojis\",\n    \"streamlit.external\",\n    \"streamlit.material_icon_names\",\n    \"streamlit.proto.openmetrics_data_model_pb2\",\n    \"streamlit.vendor.pympler\",\n    # Requires `server.fileWatcherType` to be configured with `none` or `poll`:\n    \"watchdog\",\n    \"streamlit.watcher.event_based_path_watcher\",\n]\n\n\nfor module in lazy_loaded_modules:\n    if module in sys.modules:\n        label = \"imported\"\n    elif importlib.util.find_spec(module) is not None:\n        label = \"not loaded\"\n    else:\n        label = \"not found\"\n\n    st.write(\n        f\"**{module}**:\",\n        label,\n    )\n\n\nif st.button(\"Import lazy loaded modules\"):\n    for module in lazy_loaded_modules:\n        __import__(module)\n    st.rerun()\n", "e2e_playwright/st_plotly_chart.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom datetime import datetime\n\nimport numpy as np\nimport pandas as pd\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nimport streamlit as st\n\n# Explicitly seed the RNG for deterministic results\nnp.random.seed(0)\n\ndf_bubble = px.data.gapminder()\nfig_bubble = px.scatter(\n    df_bubble.query(\"year==2007\"),\n    x=\"gdpPercap\",\n    y=\"lifeExp\",\n    size=\"pop\",\n    color=\"continent\",\n    hover_name=\"country\",\n    log_x=True,\n    size_max=60,\n)\n\n# tests no streamlit theme plot\nst.plotly_chart(fig_bubble, theme=None)\n\n# Bubble Chart\n# Tests Discrete coloring with streamlit theme\n# uses container width when use_container_width flag is True\nfig_bubble.update_layout(height=300, width=300)\nst.plotly_chart(\n    fig_bubble,\n    use_container_width=True,\n    theme=\"streamlit\",\n    # Also test custom toolbar modification:\n    config={\"modeBarButtonsToRemove\": [\"zoom\"]},\n)\n\n# Candlestick Chart\nopen_data_candlestick = [33.0, 33.3, 33.5, 33.0, 34.1]\nhigh_data_candlestick = [33.1, 33.3, 33.6, 33.2, 34.8]\nlow_data_candlestick = [32.7, 32.7, 32.8, 32.6, 32.8]\nclose_data_candlestick = [33.0, 32.9, 33.3, 33.1, 33.1]\ndates_candlestick = [\n    datetime(year=2013, month=10, day=10),\n    datetime(year=2013, month=11, day=10),\n    datetime(year=2013, month=12, day=10),\n    datetime(year=2014, month=1, day=10),\n    datetime(year=2014, month=2, day=10),\n]\nfig_candlestick = go.Figure(\n    data=[\n        go.Candlestick(\n            x=dates_candlestick,\n            open=open_data_candlestick,\n            high=high_data_candlestick,\n            low=low_data_candlestick,\n            close=close_data_candlestick,\n        )\n    ]\n)\nst.plotly_chart(fig_candlestick, theme=\"streamlit\")\n\n# Tests sunburst charts and color parameter using streamlit colors\ndf = px.data.tips()\nfig_sunburst = px.sunburst(\n    df, path=[\"sex\", \"day\", \"time\"], values=\"total_bill\", color=\"day\"\n)\nst.plotly_chart(fig_sunburst, theme=\"streamlit\")\n\n# Contour Plot and Heatmap\nfig = make_subplots(\n    rows=2, cols=2, subplot_titles=(\"connectgaps = False\", \"connectgaps = True\")\n)\nz = [\n    [None, None, None, 12, 13, 14, 15, 16],\n    [None, 1, None, 11, None, None, None, 17],\n    [None, 2, 6, 7, None, None, None, 18],\n    [None, 3, None, 8, None, None, None, 19],\n    [5, 4, 10, 9, None, None, None, 20],\n    [None, None, None, 27, None, None, None, 21],\n    [None, None, None, 26, 25, 24, 23, 22],\n]\n\nfig.add_trace(go.Contour(z=z, showscale=False), 1, 1)\nfig.add_trace(go.Contour(z=z, showscale=False, connectgaps=True), 1, 2)\nfig.add_trace(go.Heatmap(z=z, showscale=False, zsmooth=\"best\"), 2, 1)\nfig.add_trace(go.Heatmap(z=z, showscale=False, connectgaps=True, zsmooth=\"best\"), 2, 2)\n\nfig[\"layout\"][\"yaxis1\"].update(title=\"Contour map\")\nfig[\"layout\"][\"yaxis3\"].update(title=\"Heatmap\")\n\nst.plotly_chart(fig, theme=\"streamlit\")\n\n# Waterfall Chart\nfig_waterfall = go.Figure(\n    go.Waterfall(\n        name=\"20\",\n        orientation=\"v\",\n        measure=[\"relative\", \"relative\", \"total\", \"relative\", \"relative\", \"total\"],\n        x=[\n            \"Sales\",\n            \"Consulting\",\n            \"Net revenue\",\n            \"Purchases\",\n            \"Other expenses\",\n            \"Profit before tax\",\n        ],\n        textposition=\"outside\",\n        text=[\"+60\", \"+80\", \"\", \"-40\", \"-20\", \"Total\"],\n        y=[60, 80, 0, -40, -20, 0],\n        connector={\"line\": {\"color\": \"rgb(63, 63, 63)\"}},\n    )\n)\n\nfig_waterfall.update_layout(\n    title=\"Profit and loss statement 2018\", height=300, width=300, showlegend=True\n)\n# uses figure height and width when use_container_width is False\nst.plotly_chart(fig_waterfall, use_container_width=False, theme=\"streamlit\")\n\n# Ternary Chart\ndf = px.data.election()\nfig_ternary = px.scatter_ternary(df, a=\"Joly\", b=\"Coderre\", c=\"Bergeron\")\n\nst.plotly_chart(fig_ternary, theme=\"streamlit\")\n\n# Table Plot\nfig_table = go.Figure(\n    data=[\n        go.Table(\n            header={\"values\": [\"A Scores\", \"B Scores\"]},\n            cells={\"values\": [[100, 90, 80, 90], [95, 85, 75, 95]]},\n        )\n    ]\n)\nst.plotly_chart(fig_table, theme=\"streamlit\")\n\n# Continuous Customization Chart with plotly.go graph\nfig_contour = go.Figure(\n    data=go.Contour(\n        z=[\n            [10, 10.625, 12.5, 15.625, 20],\n            [5.625, 6.25, 8.125, 11.25, 15.625],\n            [2.5, 3.125, 5.0, 8.125, 12.5],\n            [0.625, 1.25, 3.125, 6.25, 10.625],\n            [0, 0.625, 2.5, 5.625, 10],\n        ],\n        colorscale=\"Electric\",\n    )\n)\nst.plotly_chart(fig_contour, theme=\"streamlit\")\n\n# Discrete Customization Chart\ndf = px.data.wind()\nfig = px.scatter_polar(\n    df,\n    r=\"frequency\",\n    theta=\"direction\",\n    color=\"strength\",\n    symbol=\"strength\",\n    size=\"frequency\",\n    color_discrete_sequence=px.colors.sequential.Plasma_r,\n)\nst.plotly_chart(fig, theme=\"streamlit\")\n\n# Layout Customization Chart\nfig = go.Figure(\n    go.Sunburst(\n        labels=[\n            \"Eve\",\n            \"Cain\",\n            \"Seth\",\n            \"Enos\",\n            \"Noam\",\n            \"Abel\",\n            \"Awan\",\n            \"Enoch\",\n            \"Azura\",\n        ],\n        parents=[\"\", \"Eve\", \"Eve\", \"Seth\", \"Seth\", \"Eve\", \"Eve\", \"Awan\", \"Eve\"],\n        values=[65, 14, 12, 10, 2, 6, 6, 4, 4],\n        branchvalues=\"total\",\n    )\n)\nfig.update_layout(margin={\"t\": 10, \"l\": 100, \"r\": 100, \"b\": 110})\nst.plotly_chart(fig, theme=\"streamlit\")\n\n# Separate template Customization Chart\ndf = px.data.gapminder().query(\"country == 'Canada'\")\nfig = px.bar(\n    df,\n    x=\"year\",\n    y=\"pop\",\n    hover_data=[\"lifeExp\", \"gdpPercap\"],\n    color=\"lifeExp\",\n    template=\"plotly\",\n    labels={\"pop\": \"population of Canada\"},\n    height=400,\n)\n\nst.plotly_chart(fig, theme=\"streamlit\")\n\n# Histogram chart\ndf = px.data.tips()\n\nfig = px.density_heatmap(df, x=\"total_bill\", y=\"tip\")\nst.plotly_chart(fig, theme=\"streamlit\")\n\ndf = pd.read_csv(\n    \"https://raw.githubusercontent.com/plotly/datasets/master/finance-charts-apple.csv\"\n)\n\nfig = px.line(\n    df, x=\"Date\", y=\"AAPL.High\", title=\"Time Series with Range Slider and Selectors\"\n)\n\nfig.update_xaxes(\n    rangeslider_visible=True,\n    rangeselector={\n        \"buttons\": [\n            {\"count\": 1, \"label\": \"1m\", \"step\": \"month\", \"stepmode\": \"backward\"},\n            {\"count\": 6, \"label\": \"6m\", \"step\": \"month\", \"stepmode\": \"backward\"},\n            {\"count\": 1, \"label\": \"YTD\", \"step\": \"year\", \"stepmode\": \"todate\"},\n            {\"count\": 1, \"label\": \"1y\", \"step\": \"year\", \"stepmode\": \"backward\"},\n            {\"step\": \"all\"},\n        ]\n    },\n)\nfig.update_layout(height=300, width=600)\nfig.update_layout(\n    font_family=\"Courier New\",\n    font_color=\"blue\",\n    title_font_family=\"Times New Roman\",\n    title_font_color=\"red\",\n    legend_title_font_color=\"green\",\n    title_font_size=30,\n)\nst.plotly_chart(fig, theme=\"streamlit\")\n\ndata = pd.DataFrame((100, 120, 104, 102, 203, 102), columns=[\"some_col\"])\n\nfig = px.line(data, height=100, width=300)\nfig.update_xaxes(visible=False, fixedrange=True)\nfig.update_yaxes(visible=False, fixedrange=True)\nfig.update_layout(annotations=[], overwrite=True)\nfig.update_layout(showlegend=False, margin={\"t\": 10, \"l\": 10, \"b\": 10, \"r\": 10})\n\n# uses figure height and width when use_container_width is False\nst.plotly_chart(fig, use_container_width=False, theme=None)\n\n# uses container width when use_container_width flag is True\nst.plotly_chart(fig, use_container_width=True, theme=None)\n", "e2e_playwright/st_json.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\nst.subheader(\"Simple dict:\")\nst.json({\"foo\": \"bar\"})\n\nst.subheader(\"Collapsed\")\nst.json({\"foo\": \"bar\"}, expanded=False)\n\nst.subheader(\"Keep whitespaces:\")\nst.json({\"Hello     World\": \"Foo    Bar\"})\n\nst.subheader(\"Complex dict:\")\nst.json(\n    {\n        \"array\": [1, 2],\n        \"boolean\": True,\n        \"null\": None,\n        \"integer\": 123,\n        \"float\": 123.45,\n        \"object\": {\"a\": \"b\", \"c\": \"d\"},\n        \"string\": \"Hello World\",\n    }\n)\n\nst.subheader(\"Simple List:\")\nst.json([\"a\", \"b\"])\n\nst.subheader(\"Empty dict:\")\nst.json({})\n", "e2e_playwright/st_button.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\nfrom streamlit import runtime\n\n# st.session_state can only be used in streamlit\nif runtime.exists():\n\n    def on_click(x, y):\n        if \"click_count\" not in st.session_state:\n            st.session_state.click_count = 0\n\n        st.session_state.click_count += 1\n        st.session_state.x = x\n        st.session_state.y = y\n\n    i1 = st.button(\n        \"button 1\", key=\"button\", on_click=on_click, args=(1,), kwargs={\"y\": 2}\n    )\n    st.write(\"value:\", i1)\n    st.write(\"value from state:\", st.session_state[\"button\"])\n\n    button_was_clicked = \"click_count\" in st.session_state\n    st.write(\"Button was clicked:\", button_was_clicked)\n\n    if button_was_clicked:\n        st.write(\"times clicked:\", st.session_state.click_count)\n        st.write(\"arg value:\", st.session_state.x)\n        st.write(\"kwarg value:\", st.session_state.y)\n\ni2 = st.checkbox(\"reset button return value\")\n\ni3 = st.button(\"button 2 (disabled)\", disabled=True)\nst.write(\"value 2:\", i3)\n\ni4 = st.button(\"button 3 (primary)\", type=\"primary\")\nst.write(\"value 3:\", i4)\n\ni5 = st.button(\"button 4 (primary + disabled)\", type=\"primary\", disabled=True)\nst.write(\"value 4:\", i5)\n\nst.button(\"button 5 (container_width)\", use_container_width=True)\n\nst.button(\n    \"button 6 (container_width + help)\", use_container_width=True, help=\"help text\"\n)\n\nst.button(\"_button 7_ (**styled** :green[label])\")\n\ncols = st.columns(3)\n\n# Order of conn_types matters to preserve the order in st_button.spec.js and the snapshot\nconn_types = [\n    \"snowflake\",\n    \"bigquery\",\n    \"huggingface\",\n    \"aws_s3\",\n    \"http_file\",\n    \"postgresql\",\n    \"gsheets\",\n    \"custom\",\n]\nfor i in range(len(conn_types)):\n    cols[i % 3].button(conn_types[i], use_container_width=True)\n", "e2e_playwright/st_code.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\nst.code(\"# This code is awesome!\")\n\nst.code(\"\")\n\ncode = \"\"\"\ndef hello():\n    print(\"Hello, Streamlit!\")\n\"\"\"\nst.code(code, language=\"python\")\n\nst.code(code, language=\"python\", line_numbers=True)\n\nst.code(\"PLAIN TEXT\", language=None, line_numbers=True)\n\nst.markdown(\"```python\\n\" + code + \"\\n```\")\n\nwith st.expander(\"`st.code` usage\", expanded=True):\n    st.code(code, language=\"python\")\n    st.code(code, language=\"python\")\n\nwith st.expander(\"`st.markdown` code usage\", expanded=True):\n    st.markdown(\"```python\\n\" + code + \"\\n```\")\n    st.markdown(\"```python\\n\" + code + \"\\n```\")\n", "e2e_playwright/st_plotly_chart_select.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\nimport time\n\nimport numpy as np\nimport plotly.express as px\n\nimport streamlit as st\n\n# Explicitly seed the RNG for deterministic results\nnp.random.seed(0)\n\ndf_bubble = px.data.gapminder()\nfig_bubble = px.scatter(\n    df_bubble.query(\"year==2007\"),\n    x=\"gdpPercap\",\n    y=\"lifeExp\",\n    size=\"pop\",\n    color=\"continent\",\n    hover_name=\"country\",\n    log_x=True,\n    size_max=60,\n)\nst.header(\"Bubble Chart with Box Select\")\nst.plotly_chart(fig_bubble, on_select=\"rerun\", key=\"bubble_chart\", selection_mode=\"box\")\nif (\n    st.session_state.get(\"bubble_chart\")\n    and len(st.session_state.bubble_chart.selection[\"points\"]) > 0\n):\n    st.write(\"The original df data selected:\")\n    points = st.session_state.bubble_chart.selection[\"points\"]\n    # Extract x and y values directly into lists\n    x_values = [point[\"x\"] for point in points]\n    y_values = [point[\"y\"] for point in points]\n\n    # Use these lists to filter the DataFrame\n    filtered_df = df_bubble[\n        df_bubble[\"gdpPercap\"].isin(x_values) & df_bubble[\"lifeExp\"].isin(y_values)\n    ]\n    st.dataframe(filtered_df)\nelse:\n    st.write(\"Nothing is selected\")\n\nst.header(\"Line Chart with Lasso select\")\ndf = px.data.gapminder().query(\"continent=='Oceania'\")\nfig_linechart = px.line(df, x=\"year\", y=\"lifeExp\", color=\"country\", markers=True)\nst.plotly_chart(\n    fig_linechart, on_select=\"rerun\", key=\"line_chart\", selection_mode=[\"lasso\"]\n)\nif (\n    st.session_state.get(\"line_chart\")\n    and len(st.session_state.line_chart.selection[\"points\"]) > 0\n):\n    st.write(\"The original df data selected:\")\n    points = st.session_state.line_chart.selection[\"points\"]\n    # Extract x and y values directly into lists\n    x_values = [point[\"x\"] for point in points]\n    y_values = [point[\"y\"] for point in points]\n\n    # Use these lists to filter the DataFrame\n    filtered_df = df[df[\"year\"].isin(x_values) & df[\"lifeExp\"].isin(y_values)]\n    st.dataframe(filtered_df)\nelse:\n    st.write(\"Nothing is selected\")\n\nst.header(\"Bar Chart with Points Selection\")\ndata_canada = px.data.gapminder().query(\"country == 'Canada'\")\nfig_bar = px.bar(data_canada, x=\"year\", y=\"pop\")\nevent_data = st.plotly_chart(\n    fig_bar, on_select=\"rerun\", key=\"bar_chart\", selection_mode=[\"points\"]\n)\nif len(event_data.selection[\"points\"]) > 0:\n    st.write(\"The original df data selected:\")\n    points = st.session_state.bar_chart.selection[\"points\"]\n    # Extract x and y values directly into lists\n    x_values = [point[\"x\"] for point in points]\n    y_values = [point[\"y\"] for point in points]\n\n    # Use these lists to filter the DataFrame\n    filtered_df = data_canada[\n        data_canada[\"year\"].isin(x_values) & data_canada[\"pop\"].isin(y_values)\n    ]\n    st.write(f\"Selected points: {len(filtered_df)}\")\nelse:\n    st.write(\"Nothing is selected\")\n\n\nst.header(\"Box Selections for a Stacked Bar Chart\")\nwide_df = px.data.medals_wide()\nfig = px.bar(\n    wide_df, x=\"nation\", y=[\"gold\", \"silver\", \"bronze\"], title=\"Wide-Form Input\"\n)\nevent_data = st.plotly_chart(\n    fig, on_select=\"rerun\", key=\"StackedBar_chart\", selection_mode=[\"box\", \"lasso\"]\n)\nif len(event_data.selection[\"points\"]) > 0:\n    st.write(\"Countries and their medal data that were selected:\")\n    points = st.session_state.StackedBar_chart.selection[\"points\"]\n    # Extract x and y values directly into lists\n    x_values = [point[\"x\"] for point in points]\n\n    # Use these lists to filter the DataFrame\n    filtered_df = wide_df[wide_df[\"nation\"].isin(x_values)]\n    st.dataframe(filtered_df)\nelse:\n    st.write(\"Nothing is selected\")\n\nst.header(\"Lasso selections on Histograms with a callback\")\ndf = px.data.tips()\nfig = px.histogram(df, x=\"total_bill\")\n\n\ndef histogram_callback():\n    if len(st.session_state.histogram_chart.selection[\"points\"]) > 0:\n        st.write(\"Callback triggered\")\n        points = list(st.session_state.histogram_chart.selection[\"points\"])\n        st.dataframe(points)\n\n\nst.plotly_chart(\n    fig, on_select=histogram_callback, key=\"histogram_chart\", selection_mode=\"lasso\"\n)\n\nif st.button(\"Create some elements to unmount component\"):\n    for _ in range(3):\n        # The sleep here is needed, because it won't unmount the\n        # component if this is too fast.\n        time.sleep(1)\n        st.write(\"Another element\")\n\ndf = px.data.iris()  # iris is a pandas DataFrame\nfig = px.scatter(df, x=\"sepal_width\", y=\"sepal_length\")\nevent_data = st.plotly_chart(\n    fig, on_select=\"rerun\", key=\"bubble_chart_2\", selection_mode=(\"box\", \"lasso\")\n)\n\nif len(event_data.selection[\"points\"]) > 0:\n    st.dataframe(event_data.selection[\"points\"])\n\nst.header(\"Bubble Chart with Points & Box Select\")\nevent_data = st.plotly_chart(\n    fig_bubble, on_select=\"rerun\", selection_mode=(\"points\", \"box\")\n)\nif len(event_data.selection.points) > 0:\n    points = event_data.selection.points\n    # Extract x and y values directly into lists\n    x_values = [point[\"x\"] for point in points]\n    y_values = [point[\"y\"] for point in points]\n\n    # Use these lists to filter the DataFrame\n    filtered_df = df_bubble[\n        df_bubble[\"gdpPercap\"].isin(x_values) & df_bubble[\"lifeExp\"].isin(y_values)\n    ]\n    st.write(f\"Selected points: {len(filtered_df)}\")\nelse:\n    st.write(\"Nothing is selected\")\n", "e2e_playwright/st_empty.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\nst.text(\"The space between this...\")\nst.text(\"..and this should be the same as between this...\")\nst.empty()\nst.text(\"...and this\")\n\nreplace_hello_text_button_clicked = st.button(\n    \"Click here to replace text with a chart!\"\n)\nreplace_chart_button_clicked = st.button(\n    \"Click here to replace chart with st.write with `placeholder.container`!\"\n)\nempty_button_clicked = st.button(\"Empty the placeholder!\")\n\nplaceholder = st.empty()\n\n# Replace the placeholder with some text:\nplaceholder.text(\"Hello\")\nst.text(\"last element\")\n\nif replace_hello_text_button_clicked:\n    # Replace the text with a chart:\n    placeholder.line_chart({\"data\": [1, 5, 2, 6]})\n\nif replace_chart_button_clicked:\n    # # Replace the chart with several elements:\n    with placeholder.container():\n        st.write(\"This is one element\")\n        st.write(\"This is another\")\n\n# # Clear all those elements:\nif empty_button_clicked:\n    placeholder.empty()\n", "e2e_playwright/st_components_v1_import_via_st.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n# PLEASE DO NOT ADD MORE IMPORTS HERE OR MOVE THE CODE TO ANOTHER FILE.\n# This file relies on a clean import to make sure the functionality is not made available transiently.\n# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n\nimport streamlit as st\n\nst.components.v1.html(\"<div>This import and usage worked!</div>\")\nst.write(str(st.components.v1.iframe))\nst.write(str(st.components.v1.declare_component))\n", "e2e_playwright/st_experimental_set_query_params.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\nset_query_params = st.button(\"Set current query params\")\n\nif set_query_params:\n    st.experimental_set_query_params(\n        show_map=True,\n        number_of_countries=2,\n        selected=[\"asia\", \"america\"],\n    )\n", "e2e_playwright/st_chat_input.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\nfrom streamlit import runtime\n\nv1 = st.container().chat_input(\"Chat input 1 (inline)\")\nst.write(\"Chat input 1 (inline) - value:\", v1)\n\ncol1, _ = st.columns(2)\n\nv2 = col1.chat_input(\"Chat input 2 (in column, disabled)\", disabled=True)\nst.write(\"Chat input 2 (in column, disabled) - value:\", v2)\n\nif runtime.exists():\n\n    def on_submit():\n        st.text(\"chat input submitted\")\n\n    st.container().chat_input(\n        \"Chat input 3 (callback)\", key=\"chat_input_3\", on_submit=on_submit\n    )\n    st.write(\"Chat input 3 (callback) - value:\", st.session_state.get(\"chat_input_3\"))\n\nv4 = st.chat_input(\"Chat input 4 (bottom, max_chars)\", max_chars=200)\nst.write(\"Chat input 4 (bottom, max_chars) - value:\", v4)\n", "e2e_playwright/st_text_input.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\nfrom streamlit import runtime\n\nv1 = st.text_input(\"text input 1 (default)\")\nst.write(\"value 1:\", v1)\n\nv2 = st.text_input(\"text input 2 (value='some text')\", \"some text\")\nst.write(\"value 2:\", v2)\n\nv3 = st.text_input(\"text input 3 (value=1234)\", 1234)\nst.write(\"value 3:\", v3)\n\nv4 = st.text_input(\"text input 4 (value=None)\", None)\nst.write(\"value 4:\", v4)\n\nv5 = st.text_input(\"text input 5 (placeholder)\", placeholder=\"Placeholder\")\nst.write(\"value 5:\", v5)\n\nv6 = st.text_input(\"text input 6 (disabled)\", \"default text\", disabled=True)\nst.write(\"value 6:\", v6)\n\nv7 = st.text_input(\n    \"text input 7 (hidden label)\", \"default text\", label_visibility=\"hidden\"\n)\nst.write(\"value 7:\", v7)\n\nv8 = st.text_input(\n    \"text input 8 (collapsed label)\", \"default text\", label_visibility=\"collapsed\"\n)\nst.write(\"value 8:\", v8)\n\nif runtime.exists():\n\n    def on_change():\n        st.session_state.text_input_changed = True\n        st.text(\"Text input changed callback\")\n\n    st.text_input(\n        \"text input 9 (callback, help)\",\n        key=\"text_input9\",\n        on_change=on_change,\n        help=\"Help text\",\n    )\n    st.write(\"value 9:\", st.session_state.text_input9)\n    st.write(\"text input changed:\", st.session_state.get(\"text_input_changed\") is True)\n    st.session_state.text_input_changed = False\n\nv10 = st.text_input(\"text input 10 (max_chars=5)\", \"1234\", max_chars=5)\nst.write(\"value 10:\", v10)\n\nv11 = st.text_input(\"text input 11 (type=password)\", \"my password\", type=\"password\")\nst.write(\"value 11:\", v11)\n", "e2e_playwright/st_experimental_fragment_run_every.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom uuid import uuid4\n\nimport streamlit as st\n\n\n@st.experimental_fragment(run_every=1.0)\ndef my_auto_updating_fragment():\n    st.write(f\"uuid in fragment: {uuid4()}\")\n\n\nmy_auto_updating_fragment()\n", "e2e_playwright/st_exception.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\nfrom streamlit.errors import StreamlitAPIException\n\ne = RuntimeError(\"This exception message is awesome!\")\nst.exception(e)\n\ne = StreamlitAPIException(\n    \"\"\"\nCannot hash object of type `_thread.lock`, found in the return value of\n`get_data()`.\n\nWhile caching the return value of `get_data()`, Streamlit encountered an\nobject of type `_thread.lock`, which it does not know how to hash.\n\nTo address this, please try helping Streamlit understand how to hash that type\nby passing the `hash_funcs` argument into `@st.cache`. For example:\n\n```\n@st.cache(hash_funcs={_thread.lock: my_hash_func_that_is_some_riduculously_long_name})\ndef my_func(...):\n    ...\n```\n\nIf you don't know where the object of type  `_thread.lock` is coming\nfrom, try looking at the hash chain below for an object that you do recognize,\nthen pass that to `hash_funcs` instead:\n\n```\nObject of type _thread.lock: <unlocked _thread.lock object at 0x1392ad690>\nObject of type builtins.tuple: ('I am another ridiculously long string that will take up space', <unlocked _thread.lock object at 0x1392ad690>)\nObject of type builtins.dict: {'I am another ridiculously long string that will take up space': <unlocked _thread.lock object at 0x1392ad690>}\nObject of type builtins.tuple: ('I am a ridiculously long string that will take up space', {'I am another ridiculously long string that will take up space': <unlocked _thread.lock object at 0x1392ad690>})\nObject of type builtins.dict: {'I am a ridiculously long string that will take up space': {'I am another ridiculously long string that will take up space': <unlocked _thread.lock object at 0x1392ad690>}}\n\n```\n\nPlease see the `hash_funcs` [documentation](https://docs.streamlit.io/develop/concepts/architecture/caching#the-hash_funcs-parameter)\nfor more details.\n            \"\"\".strip(\"\\n\")\n)\nst.exception(e)\n", "e2e_playwright/st_altair_chart.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport altair as alt\nimport numpy as np\nimport pandas as pd\n\nimport streamlit as st\n\nnp.random.seed(0)\n\ndata = np.random.randn(200, 3)\ndf = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\"])\nchart = alt.Chart(df).mark_circle().encode(x=\"a\", y=\"b\", size=\"c\", color=\"c\")\n\nst.write(\"Show default vega lite theme:\")\nst.altair_chart(chart, theme=None)\n\nst.write(\"Show streamlit theme:\")\nst.altair_chart(chart, theme=\"streamlit\")\n\nst.write(\"Overwrite theme config:\")\nchart = (\n    alt.Chart(df, usermeta={\"embedOptions\": {\"theme\": None}})\n    .mark_circle()\n    .encode(x=\"a\", y=\"b\", size=\"c\", color=\"c\")\n)\nst.altair_chart(chart, theme=\"streamlit\")\n\ndata = pd.DataFrame(\n    {\n        \"a\": [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\"],\n        \"b\": [28, 55, 43, 91, 81, 53, 19, 87, 52],\n    }\n)\n\nchart = alt.Chart(data).mark_bar().encode(x=\"a\", y=\"b\")\n\nst.write(\"Bar chart with overwritten theme props:\")\nst.altair_chart(chart.configure_mark(color=\"black\"), theme=\"streamlit\")\n\n# mark_arc was added in 4.2, but we have to support altair 4.0-4.1, so we\n# have to skip this part of the test when testing min versions.\nmajor, minor, patch = alt.__version__.split(\".\")\nif not (major == \"4\" and minor < \"2\"):\n    source = pd.DataFrame(\n        {\"category\": [1, 2, 3, 4, 5, 6], \"value\": [4, 6, 10, 3, 7, 8]}\n    )\n\n    chart = (\n        alt.Chart(source)\n        .mark_arc(innerRadius=50)\n        .encode(\n            theta=alt.Theta(field=\"value\", type=\"quantitative\"),\n            color=alt.Color(field=\"category\", type=\"nominal\"),\n        )\n    )\n\n    st.write(\"Pie Chart with more than 4 Legend items\")\n    st.altair_chart(chart, theme=\"streamlit\")\n\n# taken from vega_datasets barley example\nbarley = alt.UrlData(\n    \"https://cdn.jsdelivr.net/npm/vega-datasets@v2.7.0/data/barley.json\"\n)\n\nbarley_chart = (\n    alt.Chart(barley)\n    .mark_bar()\n    .encode(x=\"year:O\", y=\"sum(yield):Q\", color=\"year:N\", column=\"site:N\")\n)\n\nst.write(\"Grouped Bar Chart with default theme:\")\nst.altair_chart(barley_chart, theme=None)\n\nst.write(\"Grouped Bar Chart with streamlit theme:\")\nst.altair_chart(barley_chart, theme=\"streamlit\")\n\nst.write(\"Chart with use_container_width used\")\nst.altair_chart(barley_chart, theme=None, use_container_width=True)\n\nst.write(\"Layered chart\")\n# Taken from vega_datasets\nstocks = alt.UrlData(\n    \"https://cdn.jsdelivr.net/npm/vega-datasets@v1.29.0/data/stocks.csv\"\n)\n\nbase = (\n    alt.Chart(stocks)\n    .encode(x=\"date:T\", y=\"price:Q\", color=\"symbol:N\")\n    .transform_filter(alt.datum.symbol == \"GOOG\")\n)\n\nnew_base_chart = base.mark_line() + base.mark_point()\nst.altair_chart(new_base_chart)\n\nx = np.linspace(10, 100, 10)\ny1 = 5 * x\ny2 = 1 / x\n\ndf1 = pd.DataFrame.from_dict({\"x\": x, \"y1\": y1, \"y2\": y2})\n\nc1 = alt.Chart(df1).mark_line().encode(alt.X(\"x\"), alt.Y(\"y1\"))\n\nc2 = alt.Chart(df1).mark_line().encode(alt.X(\"x\"), alt.Y(\"y2\"))\n\nst.altair_chart(c1 & c2, use_container_width=True)\n", "e2e_playwright/st_heading.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\nst.title(\"This title is awesome!\")\nst.title(\"This title is awesome too!\", help=\"Some help tooltip\", anchor=\"awesome-title\")\nst.title(\"`Code` - Title with hidden Anchor\", anchor=False)\nst.title(\"a [link](#test)\")\n# Foreign language titles and anchors\nst.title(\"\u65e5\u672c\u8a9e\u30bf\u30a4\u30c8\u30eb\")\nst.title(\"\u305d\u306e\u4ed6\u306e\u90a6\u984c\", anchor=\"\u30a2\u30f3\u30ab\u30fc\")\n\nst.header(\"This header is awesome!\")\nst.header(\"This header is awesome too!\", anchor=\"awesome-header\")\nst.header(\"This header with hidden anchor is awesome tooooo!\", anchor=False)\nst.header(\"header with help\", help=\"Some help tooltip\")\nst.header(\"header with help and hidden anchor\", help=\"Some help tooltip\", anchor=False)\n\nst.subheader(\"This subheader is awesome!\")\nst.subheader(\"This subheader is awesome too!\", anchor=\"awesome-subheader\")\nst.subheader(\"`Code` - Subheader without Anchor\")\nst.subheader(\n    \"\"\"`Code` - Subheader with Anchor [test_link](href)\"\"\",\n    anchor=\"subheader\",\n)\nst.subheader(\"Subheader with hidden Anchor\", anchor=False)\nst.subheader(\"Subheader with help\", help=\"Some help tooltip\")\nst.subheader(\n    \"Subheader with help and hidden anchor\", help=\"Some help tooltip\", anchor=False\n)\n\n# Test dividers\ncolors = [\"blue\", \"gray\", \"green\", \"grey\", \"orange\", \"rainbow\", \"red\", \"violet\"]\nlorem_ipsum_text = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit\"\n# Headers with specified color\nfor color in colors:\n    st.header(f\"{color.capitalize()} Header Divider:\", divider=color)\n    st.write(lorem_ipsum_text)\n# Subheaders with specified color\nfor color in colors:\n    st.subheader(f\"{color.capitalize()} Subheader Divider:\", divider=color)\n    st.write(lorem_ipsum_text)\n", "e2e_playwright/st_table.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport random\n\nimport numpy as np\nimport pandas as pd\n\nimport streamlit as st\nfrom shared.data_mocks import (\n    BASE_TYPES_DF,\n    DATETIME_TYPES_DF,\n    INTERVAL_TYPES_DF,\n    LIST_TYPES_DF,\n    NUMBER_TYPES_DF,\n    PERIOD_TYPES_DF,\n    SPECIAL_TYPES_DF,\n    UNSUPPORTED_TYPES_DF,\n)\n\nnp.random.seed(0)\nrandom.seed(0)\n\nst.set_page_config(layout=\"wide\")\n\nst.header(\"Empty tables\")\nst.table()\nst.table([])\nst.table(np.array(0))\nst.table(pd.DataFrame([]))\nst.table(np.array([]))\nst.table(pd.DataFrame({\"lat\": [], \"lon\": []}))\n\nst.header(\"Column types\")\n\nst.subheader(\"Base types\")\nst.table(BASE_TYPES_DF)\n\nst.subheader(\"Number types\")\nst.table(NUMBER_TYPES_DF)\n\nst.subheader(\"Date, time and datetime types\")\nst.table(DATETIME_TYPES_DF)\n\nst.subheader(\"List types\")\nst.table(LIST_TYPES_DF)\n\nst.subheader(\"Interval dtypes in pd.DataFrame\")\nst.table(INTERVAL_TYPES_DF)\n\nst.subheader(\"Period dtypes in pd.DataFrame\")\nst.table(PERIOD_TYPES_DF)\n\nst.subheader(\"Special types\")\nst.table(SPECIAL_TYPES_DF)\n\nst.subheader(\"Unsupported types (by Arrow)\")\nst.table(UNSUPPORTED_TYPES_DF)\n\nst.header(\"Index types\")\n\nst.subheader(\"String Index (pd.Index)\")\nst.table(BASE_TYPES_DF.set_index(\"string\"))\n\nst.subheader(\"Float64 Index (pd.Float64Index)\")\nst.table(NUMBER_TYPES_DF.set_index(\"float64\"))\n\nst.subheader(\"Int64 Index (pd.Int64Index)\")\nst.table(NUMBER_TYPES_DF.set_index(\"int64\"))\n\nst.subheader(\"Uint64 Index (pd.UInt64Index)\")\nst.table(NUMBER_TYPES_DF.set_index(\"uint64\"))\n\nst.subheader(\"Datetime Index (pd.DatetimeIndex)\")\nst.table(DATETIME_TYPES_DF.set_index(\"datetime\"))\n\nst.subheader(\"Date Index (pd.Index)\")\nst.table(DATETIME_TYPES_DF.set_index(\"date\"))\n\nst.subheader(\"Time Index (pd.Index)\")\nst.table(DATETIME_TYPES_DF.set_index(\"time\"))\n\nst.subheader(\"Interval Index (pd.IntervalIndex)\")\nst.table(INTERVAL_TYPES_DF.set_index(\"int64_both\"))\n\nst.subheader(\"List Index (pd.Index)\")\nst.table(LIST_TYPES_DF.set_index(\"string_list\"))\n\nst.subheader(\"Multi Index (pd.MultiIndex)\")\nst.table(BASE_TYPES_DF.set_index([\"string\", \"int64\"]))\n\nst.subheader(\"Categorical Index (pd.CategoricalIndex)\")\nst.table(SPECIAL_TYPES_DF.set_index(\"categorical\"))\n\nst.subheader(\"Period Index (pd.PeriodIndex)\")\nst.table(PERIOD_TYPES_DF.set_index(\"D\"))\n\nst.subheader(\"Timedelta Index (pd.TimedeltaIndex)\")\nst.table(SPECIAL_TYPES_DF.set_index(\"timedelta\"))\n\nst.header(\"Pandas Styler Support\")\n\nst.subheader(\"Pandas Styler: Value formatting\")\ndf = pd.DataFrame({\"test\": [3.1423424, 3.1]})\nst.table(df.style.format({\"test\": \"{:.2f}\"}))\n\nst.subheader(\"Pandas Styler: Background color\")\n\n\ndef highlight_first(value):\n    return \"background-color: yellow\" if value == 0 else \"\"\n\n\ndf = pd.DataFrame(np.arange(0, 100, 1).reshape(10, 10))\nst.table(df.style.map(highlight_first))\n\nst.subheader(\"Pandas Styler: Background and font styling\")\n\ndf = pd.DataFrame(np.random.randn(10, 4), columns=[\"A\", \"B\", \"C\", \"D\"])\n\n\ndef style_negative(v, props=\"\"):\n    return props if v < 0 else None\n\n\ndef highlight_max(s, props=\"\"):\n    return np.where(s == np.nanmax(s.values), props, \"\")\n\n\n# Passing style values w/ all color formats to test css-style-string parsing robustness.\nstyled_df = df.style.map(style_negative, props=\"color:#FF0000;\").map(\n    lambda v: \"opacity: 20%;\" if (v < 0.3) and (v > -0.3) else None\n)\n\nstyled_df.apply(\n    highlight_max, props=\"color:white;background-color:rgb(255, 0, 0)\", axis=0\n)\n\nstyled_df.apply(\n    highlight_max, props=\"color:white;background-color:hsl(273, 98%, 60%);\", axis=1\n).apply(highlight_max, props=\"color:white;background-color:purple\", axis=None)\n\nst.table(styled_df)\n\nst.subheader(\"Pandas Styler: Gradient Styling + Caption\")\n\nweather_df = pd.DataFrame(\n    np.random.rand(10, 2) * 5,\n    index=pd.date_range(start=\"2021-01-01\", periods=10),\n    columns=[\"Tokyo\", \"Beijing\"],\n)\n\n\ndef rain_condition(v):\n    if v < 1.75:\n        return \"Dry\"\n    elif v < 2.75:\n        return \"Rain\"\n    return \"Heavy Rain\"\n\n\ndef make_pretty(styler):\n    styler.set_caption(\"Weather Conditions\")\n    styler.format(rain_condition)\n    styler.background_gradient(axis=None, vmin=1, vmax=5, cmap=\"YlGnBu\")\n    return styler\n\n\nstyled_df = weather_df.style.pipe(make_pretty)\n\nst.table(styled_df)\n", "e2e_playwright/config_arrow_truncation.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport numpy as np\nimport pandas as pd\n\nimport streamlit as st\n\nnp.random.seed(0)\n\ndf = pd.DataFrame(np.random.randn(50000, 20), columns=(\"col %d\" % i for i in range(20)))\n\nst.dataframe(df)\n", "e2e_playwright/st_form_container_association.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\n# Element created in a form located in the sidebar.\nform_0_key = \"form_0\"\nwith st.sidebar.form(form_0_key):\n    value = st.checkbox(f\"in {form_0_key}\")\n    st.form_submit_button(f\"{form_0_key} submit\")\nst.sidebar.write(f\"{form_0_key} value:\", value)\n\n# Element created in the sidebar, outside the form.\nform_1_key = \"form_1\"\nwith st.form(form_1_key):\n    \"Empty Form 1\"\n    value = st.sidebar.checkbox(f\"NOT in {form_1_key}\")\n    st.form_submit_button(f\"{form_1_key} submit\")\nst.write(f\"{form_1_key} value:\", value)\n\n# Parent block created outside a form; element created inside a form.\nform_2_key = \"form_2\"\ncols = st.columns(2)\nwith st.form(form_2_key):\n    \"Empty Form 2\"\n    value = cols[0].checkbox(f\"NOT in {form_2_key}\")\n    st.form_submit_button(f\"{form_2_key} submit\")\nst.write(f\"{form_2_key} value:\", value)\n\n# Parent block and element created inside a form.\nform_3_key = \"form_3\"\nwith st.form(form_3_key):\n    cols = st.columns(2)\n    with cols[0]:\n        value = st.checkbox(f\"in {form_3_key}\")\n    st.form_submit_button(f\"{form_3_key} submit\")\nst.write(f\"{form_3_key} value:\", value)\n\n# Parent block created inside a form; element created outside a form.\nform_4_key = \"form_4\"\nwith st.form(form_4_key):\n    cols = st.columns(2)\n    st.form_submit_button(f\"{form_4_key} submit\")\nvalue = cols[0].checkbox(f\"in {form_4_key}\")\nst.write(f\"{form_4_key} value:\", value)\n\n# DG created outside a form; element created inside a form.\nform_5_key = \"form_5\"\nempty = st.empty()\nwith st.form(form_5_key):\n    \"Empty Form 5\"\n    value = empty.checkbox(f\"NOT in {form_5_key}\")\n    st.form_submit_button(f\"{form_5_key} submit\")\nst.write(f\"{form_5_key} value:\", value)\n\n# DG created inside a form; element created outside a form.\nform_6_key = \"form_6\"\nwith st.form(form_6_key):\n    empty = st.empty()\n    st.form_submit_button(f\"{form_6_key} submit\")\nvalue = empty.checkbox(f\"in {form_6_key}\")\nst.write(f\"{form_6_key} value:\", value)\n\n# Element created directly on a form block.\nform_7_key = \"form_7\"\nform = st.form(form_7_key)\nvalue = form.checkbox(f\"in {form_7_key}\")\nform.form_submit_button(f\"{form_7_key} submit\")\nst.write(f\"{form_7_key} value:\", value)\n\n# Forms inside columns.\ncols = st.columns(2)\nwith cols[0]:\n    form_8_key = \"form_8\"\n    with st.form(form_8_key):\n        value = st.checkbox(f\"in {form_8_key}\")\n        st.form_submit_button(f\"{form_8_key} submit\")\n    st.write(f\"{form_8_key} value:\", value)\nwith cols[1]:\n    form_9_key = \"form_9\"\n    with st.form(form_9_key):\n        value = st.checkbox(f\"in {form_9_key}\")\n        st.form_submit_button(f\"{form_9_key} submit\")\n    st.write(f\"{form_9_key} value:\", value)\n", "e2e_playwright/st_camera_input.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\nx = st.camera_input(\"Label1\", help=\"help1\")\n\nif x is not None:\n    st.image(x)\n\ny = st.camera_input(\"Label2\", help=\"help2\", disabled=True)\n", "e2e_playwright/st_audio.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport time\n\nimport requests\n\nimport streamlit as st\n\nurl1 = \"https://www.w3schools.com/html/horse.ogg\"\nfile = requests.get(url1).content\nst.audio(file)\n\nurl2 = \"https://mdn.github.io/learning-area/html/multimedia-and-embedding/video-and-audio-content/viper.mp3\"\nst.audio(url2, start_time=10, end_time=13)\n\nst.audio(url2, start_time=15, end_time=19, loop=True)\n\nautoplay = st.checkbox(\"Autoplay\", value=False)\n\nif st.button(\"Create some elements to unmount component\"):\n    for _ in range(3):\n        # The sleep here is needed, because it won't unmount the\n        # component if this is too fast.\n        time.sleep(1)\n        st.write(\"Another element\")\n\nst.audio(url2, autoplay=autoplay)\n", "e2e_playwright/st_markdown.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\n# keep the sidebar collapsed by default to prevent render flakiness\nst.set_page_config(initial_sidebar_state=\"collapsed\")\n\nst.markdown(\n    \"This **markdown** is awesome! :sunglasses:\", help=\"This is a help tooltip!\"\n)\n\nst.markdown(\"This <b>HTML tag</b> is escaped!\")\n\nst.markdown(\"This <b>HTML tag</b> is not escaped!\", unsafe_allow_html=True)\n\nst.markdown(\"[text]\")\n\nst.markdown(\"[link](href)\")\n\nst.markdown(\"[][]\")\n\nst.markdown(r\"Inline math with $\\KaTeX$\")\n\nst.markdown(\n    \"\"\"\n$$\nax^2 + bx + c = 0\n$$\n\"\"\"\n)\n\nst.markdown(\n    \"\"\"\n| Col1      | Col2        |\n| --------- | ----------- |\n| Some      | Data        |\n\"\"\"\n)\n\nst.markdown(\":blue-background[**Bold text within blue background**]\")\nst.markdown(\":red-background[*Italic text within red background*]\")\nst.markdown(\":rainbow-background[[Link](http://example.com) within rainbow background]\")\nst.markdown(\n    \":green-background[LaTeX math within green background: $ax^2 + bx + c = 0$]\"\n)\n\nst.markdown(\n    r\"\"\"\nMany different markdown formats in one block:\n\nInline math with $\\KaTeX$\n\n$$\nax^2 + bx + c = 0\n$$\n\n# Some header 1\n\n| Col1      | Col2        |\n| --------- | ----------- |\n| Some      | Data        |\n\nSome text\n- :blue[blue], :green[green], :red[red], :violet[violet], :orange[orange], :gray[gray], :grey[grey], :rainbow[rainbow]\n- :blue-background[blue], :green-background[green], :red-background[red], :violet-background[violet], :orange-background[orange], :gray-background[gray], :grey-background[grey], :rainbow-background[rainbow]\n\n:blue-background[**Bold text within blue background**], :red-background[*Italic text within red background*]\n\n:rainbow-background[[Link](http://example.com) within rainbow background], :green-background[LaTeX math within green background: $ax^2 + bx + c = 0$]\n\n:violet-background[This is a repeating multiline string that wraps within purple background. This is a repeating multiline string that wraps within purple background.]\n\n\"\"\"\n)\n\n\n# Headers in markdown tests (originally from the typography-test suite).\n\nwith st.container():\n    st.markdown(\"# some really long header \" + \" \".join([\"lol\"] * 10))\n    st.markdown(\n        \"\"\"\n| Col1      | Col2        | Col3        | Col4        |\n| --------- | ----------- | ----------- | ----------- |\n| Some      | Data        | Data        | Data        |\n\"\"\"\n    )\n\n\ndef draw_header_test(join_output):\n    strings = [\n        \"# Header header1\",\n        \"## Header header2\",\n        \"### Header header3\",\n        \"#### Header header4\",\n        \"##### Header header5\",\n        \"###### Header header6\",\n        \"Quisque vel blandit mi. Fusce dignissim leo purus, in imperdiet lectus suscipit nec.\",\n    ]\n\n    if join_output:\n        st.markdown(\"\\n\\n\".join(strings))\n    else:\n        for string in strings:\n            st.markdown(string)\n\n\ndraw_header_test(True)\n\nwith st.sidebar:\n    st.text_input(\"This is a label\", key=\"1\")\n    draw_header_test(True)\n\n\"---\"\n\nwith st.container():\n    st.text(\"Headers in single st.markdown command\")\n    draw_header_test(True)\n\n\"---\"\n\nwith st.container():\n    st.text(\"Headers in multiple st.markdown command\")\n    draw_header_test(False)\n\n\"---\"\n\nwith st.container():\n    st.text(\"Headers in columns\")\n\n    a, b = st.columns(2)\n\n    with a:\n        draw_header_test(True)\n\n    with b:\n        draw_header_test(False)\n\n\"---\"\n\nwith st.container():\n    st.text(\"Headers in columns with other elements above\")\n\n    a, b = st.columns(2)\n\n    with a:\n        st.text(\"This is some text\")\n        draw_header_test(True)\n\n    with b:\n        st.text(\"This is some text\")\n        with st.container():\n            draw_header_test(False)\n\n\"---\"\n\nwith st.container():\n    st.text(\"Headers in column beside widget\")\n\n    a, b = st.columns(2)\n\n    with a:\n        st.write(\"# Header header\")\n        st.write(\"## Header header\")\n\n    with b:\n        st.text_input(\"This is a label\", key=\"2\")\n\n\"---\"\n\nst.latex(r\"\\LaTeX\")\n\ntry:\n    import sympy\n\n    a, b = sympy.symbols(\"a b\")\n    out = a + b\nexcept Exception:\n    out = \"a + b\"\n\nst.latex(out)\n\nst.latex(\n    r\"\"\"\n    a + ar + a r^2 + a r^3 + \\cdots + a r^{n-1} =\n    \\sum_{k=0}^{n-1} ar^k =\n    a \\left(\\frac{1-r^{n}}{1-r}\\right)\n    \"\"\",\n    help=\"This is example tooltip displayed on latex.\",\n)\n\nst.markdown(\n    \"Images in markdown should stay inside the container width:\\n\\n![image](./app/static/streamlit-logo.png)\"\n)\n", "e2e_playwright/st_number_input.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\nfrom streamlit import runtime\n\nv1 = st.number_input(\"number input 1 (default)\", help=\"Help text\")\nst.write(\"number input 1 (default) - value: \", v1)\n\nv2 = st.number_input(\"number input 2 (value=1)\", value=1)\nst.write(\"number input 2 (value=1) - value: \", v2)\n\nv3 = st.number_input(\"number input 3 (min & max)\", 1, 10)\nst.write(\"number input 3 (min & max) - value: \", v3)\n\nv4 = st.number_input(\"number input 4 (step=2)\", step=2)\nst.write(\"number input 4 (step=2) - value: \", v4)\n\nv5 = st.number_input(\"number input 5 (max=10)\", max_value=10)\nst.write(\"number input 5 (max=10) - value: \", v5)\n\nv6 = st.number_input(\"number input 6 (disabled=True)\", disabled=True)\nst.write(\"number input 6 (disabled=True) - value: \", v6)\n\nv7 = st.number_input(\"number input 7 (label=hidden)\", label_visibility=\"hidden\")\nst.write(\"number input 7 (label=hidden) - value: \", v7)\n\nv8 = st.number_input(\"number input 8 (label=collapsed)\", label_visibility=\"collapsed\")\nst.write(\"number input 8 (label=collapsed) - value: \", v8)\n\nif runtime.exists():\n\n    def on_change():\n        st.session_state.number_input_changed = True\n\n    st.number_input(\n        \"number input 9 (on_change)\", key=\"number_input_9\", on_change=on_change\n    )\n    st.write(\"number input 9 (on_change) - value: \", st.session_state.number_input_9)\n    st.write(\n        \"number input 9 (on_change) - changed:\",\n        st.session_state.get(\"number_input_changed\") is True,\n    )\n\n[col1, col2, col3, col4, col5, col6] = st.columns(6)\n\nwith col1:\n    v10 = st.number_input(\"number input 10 (small width)\", max_value=10)\n    st.write(\"number input 10 (small width) - value: \", v10)\n\nv11 = st.number_input(\n    \"number input 11 (value=None)\", value=None, placeholder=\"Type a number...\"\n)\nst.write(\"number input 11 (value=None) - value: \", v11)\n\nif \"number_input_12\" not in st.session_state:\n    st.session_state[\"number_input_12\"] = 10\n\nv12 = st.number_input(\n    \"number input 12 (value from state & min=1)\",\n    value=None,\n    min_value=1,\n    key=\"number_input_12\",\n)\nst.write(\"number input 12 (value from state & min=1) - value: \", v12)\n", "e2e_playwright/st_help.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\nfrom streamlit.elements.doc_string import _get_scriptrunner_frame\n\nif _get_scriptrunner_frame() is None:\n    st.warning(\n        \"\"\"\n        You're running this script in an `exec` context, so the `foo` part\n        of `st.help(foo)` will not appear inside the displayed `st.help` element.\n        \"\"\"\n    )\n\n\n# Testing case where there are no docs.\nclass FooWithNoDocs:\n    my_static_var_1 = 123\n\n\nst.help(FooWithNoDocs)\n\n# Testing case where there are no members.\nst.help(globals)\n\n\n# Test case where there the docs need to scroll,\n# and test case where some members doesn't have docs.\nclass FooWithLongDocs:\n    \"\"\"My docstring.\n\n    This is a very long one! You probably need to scroll, scroll, scroll, scroll,\n    scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll,\n    scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll,\n    scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll,\n    scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll,\n    scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll.\n\n    Scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll,\n    scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll,\n    scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll,\n    scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll.\n\n    Scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll,\n    scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll,\n    scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll,\n    scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll.\n\n    Scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll,\n    scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll,\n    scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll,\n    scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll.\n\n    Scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll,\n    scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll,\n    scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll,\n    scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll, scroll.\n    \"\"\"\n\n    def __init__(self):\n        self.my_var_1 = 123\n\n    def my_func_1(self, a, b=False):\n        \"Func with doc.\"\n\n    def my_func_2(self):\n        # Func without doc.\n        pass\n\n\nf = FooWithLongDocs()\n\nf\n", "e2e_playwright/st_components_v1.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\nimport streamlit.components.v1 as components\n\nhtml = r\"<h1>Hello, Streamlit!</h1>\"\ncomponents.html(html, width=200, height=500, scrolling=False)\n\nsrc = \"http://not.a.real.url\"\ncomponents.iframe(src, width=200, height=500, scrolling=True)\n\n# Set a query parameter to ensure that it doesn't affect the path of the custom component,\n# since that would trigger a reload if the query param changes\nst.query_params[\"hello\"] = \"world\"\n\nurl = \"http://not.a.real.url\"\ntest_component = components.declare_component(\"test_component\", url=url)\n\ntest_component()\n", "e2e_playwright/st_vega_lite_chart.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport numpy as np\nimport pandas as pd\n\nimport streamlit as st\n\nnp.random.seed(0)\ndata = np.random.randn(200, 3)\ndf = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\"])\nspec = {\n    \"mark\": \"circle\",\n    \"encoding\": {\n        \"x\": {\"field\": \"a\", \"type\": \"quantitative\"},\n        \"y\": {\"field\": \"b\", \"type\": \"quantitative\"},\n        \"size\": {\"field\": \"c\", \"type\": \"quantitative\"},\n        \"color\": {\"field\": \"c\", \"type\": \"quantitative\"},\n    },\n}\n\nspec_with_width = {\n    \"mark\": \"circle\",\n    \"encoding\": {\n        \"x\": {\"field\": \"a\", \"type\": \"quantitative\"},\n        \"y\": {\"field\": \"b\", \"type\": \"quantitative\"},\n        \"size\": {\"field\": \"c\", \"type\": \"quantitative\"},\n        \"color\": {\"field\": \"c\", \"type\": \"quantitative\"},\n    },\n    \"width\": \"500\",\n}\n\ninteractive_spec = {\n    \"title\": \"Interactive Bar Chart Example\",\n    \"data\": {\n        \"values\": [\n            {\"a\": \"A\", \"b\": 28},\n            {\"a\": \"B\", \"b\": 55},\n            {\"a\": \"C\", \"b\": 43},\n            {\"a\": \"D\", \"b\": 91},\n            {\"a\": \"E\", \"b\": 81},\n            {\"a\": \"F\", \"b\": 53},\n            {\"a\": \"G\", \"b\": 19},\n            {\"a\": \"H\", \"b\": 87},\n            {\"a\": \"I\", \"b\": 52},\n        ]\n    },\n    \"params\": [\n        {\"name\": \"highlight\", \"select\": {\"type\": \"point\", \"on\": \"mouseover\"}},\n        {\"name\": \"select\", \"select\": \"point\"},\n    ],\n    \"mark\": {\"type\": \"bar\", \"fill\": \"#4C78A8\", \"stroke\": \"black\", \"cursor\": \"pointer\"},\n    \"encoding\": {\n        \"x\": {\"field\": \"a\", \"type\": \"ordinal\"},\n        \"y\": {\"field\": \"b\", \"type\": \"quantitative\"},\n        \"fillOpacity\": {\"condition\": {\"param\": \"select\", \"value\": 1}, \"value\": 0.3},\n        \"strokeWidth\": {\n            \"condition\": [\n                {\"param\": \"select\", \"empty\": False, \"value\": 2},\n                {\"param\": \"highlight\", \"empty\": False, \"value\": 1},\n            ],\n            \"value\": 0,\n        },\n    },\n    \"config\": {\"scale\": {\"bandPaddingInner\": 0.2}},\n}\n\nst.vega_lite_chart(df, spec, use_container_width=True)\nst.vega_lite_chart(df, spec, use_container_width=True)\nst.vega_lite_chart(df, spec)\nst.vega_lite_chart(df, spec_with_width)\nst.vega_lite_chart(interactive_spec, None)\n\n# Screenshot comparison\n\nst.header(\"Different ways to get the exact same plot\")\n\ndf = pd.DataFrame([[\"A\", \"B\", \"C\", \"D\"], [28, 55, 43, 91]], index=[\"a\", \"b\"]).T\n\nst.write(\"Using a top-level `df` and a `spec` dict:\")\n\nst.vega_lite_chart(\n    df,\n    {\n        \"mark\": \"bar\",\n        \"encoding\": {\n            \"x\": {\"field\": \"a\", \"type\": \"ordinal\"},\n            \"y\": {\"field\": \"b\", \"type\": \"quantitative\"},\n        },\n    },\n    use_container_width=True,\n)\n\nst.write(\"Using a top-level `df` and keywords as a spec:\")\n\nst.vega_lite_chart(\n    df,\n    mark=\"bar\",\n    x_field=\"a\",\n    x_type=\"ordinal\",\n    y_field=\"b\",\n    y_type=\"quantitative\",\n    use_container_width=True,\n)\n\nst.write(\"Putting the `df` inside the spec, as a `dataset`:\")\n\nst.vega_lite_chart(\n    {\n        \"datasets\": {\"foo\": df},\n        \"data\": {\"name\": \"foo\"},\n        \"mark\": \"bar\",\n        \"encoding\": {\n            \"x\": {\"field\": \"a\", \"type\": \"ordinal\"},\n            \"y\": {\"field\": \"b\", \"type\": \"quantitative\"},\n        },\n    },\n    use_container_width=True,\n)\n\nst.write(\"Putting the `df` inside the spec, as inline `data`:\")\n\nst.vega_lite_chart(\n    {\n        \"data\": df,\n        \"mark\": \"bar\",\n        \"encoding\": {\n            \"x\": {\"field\": \"a\", \"type\": \"ordinal\"},\n            \"y\": {\"field\": \"b\", \"type\": \"quantitative\"},\n        },\n    },\n    use_container_width=True,\n)\n\nst.write(\"Putting the `df` inside the spec, as inline `data` (different notation):\")\n\nst.vega_lite_chart(\n    {\n        \"data\": {\"values\": df},\n        \"mark\": \"bar\",\n        \"encoding\": {\n            \"x\": {\"field\": \"a\", \"type\": \"ordinal\"},\n            \"y\": {\"field\": \"b\", \"type\": \"quantitative\"},\n        },\n    }\n)\n\ndf = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\"])\n\nst.write(\"Show streamlit theme:\")\nst.vega_lite_chart(df, spec, use_container_width=True, theme=\"streamlit\")\n\nst.write(\"Show default theme:\")\nst.vega_lite_chart(df, spec, use_container_width=True, theme=None)\n\nst.write(\"Show custom colors:\")\nst.vega_lite_chart(\n    df,\n    {\n        \"mark\": \"bar\",\n        \"encoding\": {\n            \"x\": {\"field\": \"a\", \"type\": \"ordinal\"},\n            \"y\": {\"field\": \"b\", \"type\": \"quantitative\"},\n        },\n        \"config\": {\"background\": \"purple\", \"axis\": {\"labelColor\": \"blue\"}},\n    },\n    use_container_width=True,\n)\n\nspec = {\n    \"mark\": \"line\",\n    \"encoding\": {\n        \"x\": {\"field\": \"a\", \"type\": \"quantitative\"},\n        \"y\": {\"field\": \"b\", \"type\": \"quantitative\"},\n    },\n}\n\n# empty chart\nst.vega_lite_chart(spec, use_container_width=True)\n", "e2e_playwright/st_spinner.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport time\n\nimport streamlit as st\n\n# A spinner always requires a computation to run for a certain time\n# Therefore, we add a button to allow triggering the spinner during the test execution.\nif st.button(\"Run Spinner\"):\n    with st.spinner(\"Loading...\"):\n        time.sleep(2)\n", "e2e_playwright/__init__.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n", "e2e_playwright/st_container.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\ncontainer = st.container()\n\nst.write(\"Line 1\")\ncontainer.write(\"Line 2\")\nwith container:\n    \"Line 3\"\nst.write(\"Line 4\")\n\n# Ensure widget states persist when React nodes shift\nif st.button(\"Step 2: Press me\"):\n    st.header(\"Pressed!\")\nc = st.container()\nif c.checkbox(\"Step 1: Check me\"):\n    c.title(\"Checked!\")\n\nwith st.container(border=True):\n    st.markdown(\n        \"This is inside a container with a border. And it doesn't overflow \"\n        \"the borders if the text requires multiple lines.\"\n    )\n    st.button(\"Stretch full width\", use_container_width=True)\n\nwith st.container(height=200):\n    st.markdown(\"This is inside a scrolling container.\")\n    st.text_input(\"Widget in scroll container\")\n\n    for i in range(10):\n        st.markdown(f\"Message {i}\")\n\nempty_container = st.container(height=100)\n\nif st.button(\"Add message\"):\n    empty_container.chat_message(\"user\").write(\"Hello world\")\n\nwith st.container(height=200):\n    for i in range(10):\n        st.chat_message(\"user\").write(f\"Message {i}\")\n", "e2e_playwright/st_dialog.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport numpy as np\nimport pandas as pd\n\nimport streamlit as st\n\n\n@st.experimental_dialog(\"Test Dialog with Images\")\ndef dialog_with_images():\n    st.write(\"Hello!\")\n    st.slider(\"Slide me!\", 0, 10)\n\n    # render a dataframe\n    st.dataframe(\n        pd.DataFrame(np.zeros((1000, 6)), columns=[\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"])\n    )\n\n    st.subheader(\"Images\", help=\"Some images are generated\")\n    # render multiple images. This will make the Close button to go out of\n    # screen and allows scrollability of the dialog\n    for _ in range(0, 3):\n        st.image(np.repeat(0, 1000000).reshape(1000, 1000))\n\n    if st.button(\"Submit\", key=\"dialog-btn\"):\n        st.rerun()\n\n\nif st.button(\"Open Dialog with Images\"):\n    dialog_with_images()\n\n\n@st.experimental_dialog(\"Simple Dialog\")\ndef simple_dialog():\n    st.write(\"Hello again!\")\n    st.text_input(\"Enter something!\")\n\n    if st.button(\"Submit\", key=\"dialog2-btn\"):\n        st.rerun()\n\n\nif st.button(\"Open Dialog without Images\"):\n    simple_dialog()\n\n\n@st.experimental_dialog(\"Large-width Dialog\", width=\"large\")\ndef large_width_dialog():\n    st.write(\"This dialog has a large width.\")\n\n    if st.button(\"Submit\", key=\"dialog4-btn\"):\n        st.rerun()\n\n\nif st.button(\"Open large-width Dialog\"):\n    large_width_dialog()\n\n\n@st.experimental_dialog(\"Dialog with headings\")\ndef headings_dialog():\n    st.header(\"Header\", help=\"Some tooltip!\")\n\n\nif st.button(\"Open headings Dialog\"):\n    headings_dialog()\n\n# We use this dialog for a screenshot test as loading images via the browser\n# is non-deterministic\nwith st.sidebar:\n\n    @st.experimental_dialog(\"Simple Dialog in Sidebar\")\n    def dialog_in_sidebar():\n        st.write(\"Hello sidebar dialog!\")\n\n        if st.button(\"Submit\", key=\"dialog5-btn\"):\n            st.rerun()\n\n    if st.button(\"Open Sidebar-Dialog\"):\n        dialog_in_sidebar()\n\n\n@st.experimental_dialog(\"Level2 Dialog\")\ndef level2_dialog():\n    st.write(\"Second level dialog\")\n\n\n@st.experimental_dialog(\"Level1 Dialog\")\ndef level1_dialog():\n    st.write(\"First level dialog\")\n    level2_dialog()\n\n\nif st.button(\"Open Nested Dialogs\"):\n    level1_dialog()\n\n\n@st.experimental_dialog(\"Dialog with error\")\ndef dialog_with_error():\n    with st.form(key=\"forecast_form\"):\n        # key is an invalid argument, so this shows an error\n        st.form_submit_button(\"Submit\", key=\"foo\")\n\n\nif st.button(\"Open Dialog with Key Error\"):\n    dialog_with_error()\n", "e2e_playwright/st_html.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\n# Test that we can render HTML with in-line styles\nst.html(\n    \"\"\"\n    <div style=\"font-family: 'Comic Sans MS'; color: orange\">\n        This is a div with some inline styles.\n    </div>\n    \"\"\"\n)\n\n# Test that script tags are sanitized\nst.html(\n    \"\"\"\n    <i> This is a i tag </i>\n    <script>\n        alert('BEWARE - the script tag is scripting');\n    </script>\n    <strong> This is a strong tag </strong>\n    \"\"\"\n)\n\n# Test that style tags are applied\nst.html(\n    \"\"\"\n    <style>\n        #corgi {\n            color:blue;\n        }\n    </style>\n    <div id=\"corgi\">This text should be blue</div>\n    \"\"\"\n)\n\n# Test that non-rendered HTML doesn't cause extra spacing\nst.write(\"Before tag:\")\nst.html(\n    \"\"\"\n    <style>\n        #random {\n            color:blue;\n        }\n    </style>\n    \"\"\"\n)\nst.write(\"After tag\")\n", "e2e_playwright/st_pydeck_chart.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport math\nfrom typing import Any, cast\n\nimport numpy as np\nimport pandas as pd\nimport pydeck as pdk\n\nimport streamlit as st\n\n# Empty chart.\n\nst.pydeck_chart()\n\n# Basic chart.\n\nnp.random.seed(12345)\n\ndf = pd.DataFrame(\n    cast(Any, np.random.randn(1000, 2) / [50, 50]) + [37.76, -122.4],\n    columns=[\"lat\", \"lon\"],\n)\n\nst.pydeck_chart(\n    pdk.Deck(\n        map_style=\"mapbox://styles/mapbox/light-v9\",\n        initial_view_state=pdk.ViewState(\n            latitude=37.76,\n            longitude=-122.4,\n            zoom=11,\n            pitch=50,\n        ),\n        layers=[\n            pdk.Layer(\n                \"HexagonLayer\",\n                data=df,\n                get_position=\"[lon, lat]\",\n                radius=200,\n                elevation_scale=4,\n                elevation_range=[0, 1000],\n                pickable=True,\n                extruded=True,\n            ),\n            pdk.Layer(\n                \"ScatterplotLayer\",\n                data=df,\n                get_position=\"[lon, lat]\",\n                get_color=\"[200, 30, 0, 160]\",\n                get_radius=200,\n            ),\n        ],\n    )\n)\n\n# Chart w/ invalid JSON - issue #5799.\ndata = pd.DataFrame({\"lng\": [-109.037673], \"lat\": [36.994672], \"weight\": [math.nan]})\nlayer = pdk.Layer(\n    \"ScatterplotLayer\", data=data, get_position=[\"lng\", \"lat\"], radius_min_pixels=4\n)\ndeck = pdk.Deck(\n    layers=[layer],\n    map_style=pdk.map_styles.CARTO_LIGHT,\n    tooltip={\"text\": \"weight: {weight}\"},\n)\nst.pydeck_chart(deck, use_container_width=True)\n\nH3_HEX_DATA = [\n    {\"hex\": \"88283082b9fffff\", \"count\": 10},\n    {\"hex\": \"88283082d7fffff\", \"count\": 50},\n    {\"hex\": \"88283082a9fffff\", \"count\": 100},\n]\ndf = pd.DataFrame(H3_HEX_DATA)\n\nst.pydeck_chart(\n    pdk.Deck(\n        map_style=\"mapbox://styles/mapbox/outdoors-v12\",\n        tooltip={\"text\": \"Count: {count}\"},\n        initial_view_state=pdk.ViewState(\n            latitude=37.7749295, longitude=-122.4194155, zoom=12, bearing=0, pitch=30\n        ),\n        layers=[\n            pdk.Layer(\n                \"H3HexagonLayer\",\n                df,\n                pickable=True,\n                stroked=True,\n                filled=True,\n                get_hexagon=\"hex\",\n                get_fill_color=\"[0, 255, 0]\",\n                get_line_color=[255, 255, 255],\n                line_width_min_pixels=2,\n            ),\n        ],\n    )\n)\n\nst.pydeck_chart(\n    pdk.Deck(\n        initial_view_state=pdk.ViewState(\n            latitude=37.76,\n            longitude=-122.4,\n            zoom=11,\n            pitch=50,\n        ),\n        layers=[\n            pdk.Layer(\n                \"HexagonLayer\",\n                data=df,\n                get_position=\"[lon, lat]\",\n                radius=200,\n                elevation_scale=4,\n                elevation_range=[0, 1000],\n                pickable=True,\n                extruded=True,\n            ),\n            pdk.Layer(\n                \"ScatterplotLayer\",\n                data=df,\n                get_position=\"[lon, lat]\",\n                get_color=\"[200, 30, 0, 160]\",\n                get_radius=200,\n            ),\n        ],\n    )\n)\n", "e2e_playwright/st_popover.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\nimport numpy as np\nimport pandas as pd\n\nimport streamlit as st\n\n# Create random dataframe:\nnp.random.seed(0)\ndf = pd.DataFrame(np.random.randn(50, 5), columns=[\"a\", \"b\", \"c\", \"d\", \"e\"])\n\nst.popover(\"popover 1 (empty)\")\n\nwith st.popover(\"popover 2 (use_container_width)\", use_container_width=True):\n    st.markdown(\"Hello\")\n\nwith st.popover(\n    \"popover 3 (with widgets)\",\n):\n    st.markdown(\"Hello World \ud83d\udc4b\")\n    text = st.text_input(\"Text input\")\n    col1, col2, col3 = st.columns(3)\n    col1.text_input(\"Column 1\")\n    col2.text_input(\"Column 2\")\n    col3.text_input(\"Column 3\")\n    st.selectbox(\"Selectbox\", [\"a\", \"b\", \"c\"])\n\n\nwith st.popover(\"popover 4 (with dataframe)\", help=\"help text\"):\n    st.markdown(\"Popover with dataframe\")\n    st.dataframe(df, use_container_width=False)\n    st.image(np.repeat(0, 100).reshape(10, 10))\n\nwith st.sidebar.popover(\"popover 5 (in sidebar)\"):\n    st.markdown(\"Popover in sidebar with dataframe\")\n    st.dataframe(df, use_container_width=True)\n\nwith st.popover(\"popover 6 (disabled)\", disabled=True):\n    st.markdown(\"Hello World \ud83d\udc4b\")\n\nwith st.expander(\"Output\"):\n    st.markdown(text)\n", "e2e_playwright/st_pyplot.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport textwrap\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nfrom matplotlib import pyplot\n\nimport streamlit as st\n\nnp.random.seed(0)\n\n\nst.write(\"Normal figure:\")\ndata = np.random.normal(1, 1, size=100)\nfig, ax = plt.subplots()\nax.hist(data, bins=20)\nst.pyplot(fig)\n\nst.write(\"Resized figure:\")\n# Resize plot. It is now 4 times smaller than the default value.\nfig.set_size_inches(6.4 / 4, 4.8 / 4)\nst.pyplot(fig)\n\nst.write(\"Resized figure with `use_container_width=True`:\")\nst.pyplot(fig, use_container_width=True)\n\nst.write(\"Resized figure with `use_container_width=False`:\")\nst.pyplot(fig, use_container_width=False)\n\nst.write(\"Advanced Seaborn figure:\")\n# Generate data\ndata_points = 100\nxData: \"np.typing.NDArray[np.float64]\" = (np.random.randn(data_points, 1) * 30) + 30\nyData: \"np.typing.NDArray[np.float64]\" = np.random.randn(data_points, 1) * 30\ndata: \"np.typing.NDArray[np.float64]\" = np.random.randn(data_points, 2)\n\n# Generate plot\nfig, ax = plt.subplots(figsize=(4.5, 4.5))\nsns.set_context(rc={\"font.size\": 10})\np = sns.regplot(x=xData, y=yData, data=data, ci=None, ax=ax, color=\"grey\")\n\np.set_title(\"An Extremely and Really Really Long Long Long Title\", fontweight=\"bold\")\np.set_xlabel(\"Very long long x label\")\np.set_ylabel(\"Very long long y label\")\n\np.set_ylim(-30, 30)\nplot_text = textwrap.dedent(\n    \"\"\"\n    some_var_1 = 'Some label 1'\n    some_var_2 = 'Some label 2'\n\"\"\"\n)\n\ntxt = ax.text(0.90, 0.10, plot_text, transform=ax.transAxes)\nsns.despine()\n\nst.pyplot(fig)\n\nst.write(\"Advanced Seaborn figure using kwargs (low dpi):\")\n\nkwargs = {\n    \"dpi\": 50,  # We use a low dpi to show a stark difference to the figure above.\n    \"bbox_extra_artists\": (txt,),\n    \"bbox_inches\": \"tight\",\n    \"format\": \"png\",  # Required for some Matplotlib backends.\n}\n\n# We need to set clear_figure=True, otherwise the global object\n# test below would not work.\nst.pyplot(fig, clear_figure=True, **kwargs)\n\nst.write(\"Figure using deprecated global object:\")\nplot = pyplot.plot(data)\nst.pyplot()\npyplot.clf()\n\nfig, ax = plt.subplots()\nst.pyplot(fig)\n", "e2e_playwright/st_experimental_fragment_chat_response.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport re\n\nimport streamlit as st\n\nst.header(\"Chat response cell\")\nst.caption('The \"LLM-generated\" code runs independently of the rest of the page')\n\n\nline_chart_response = \"\"\"\nHere, have a line chart,\n```python\nimport streamlit as st\nimport pandas as pd\n\napp_df = pd.DataFrame([[1, 1, 1], [2, 2, 2], [3, 3, 2], [4, 4, 2], [5, 5, 3]], columns=[\"day\", \"apps\", \"external_apps\"])\nexclude = st.checkbox(\"Exclude internal apps\")\ny = \"apps\" if not exclude else \"external_apps\"\nst.line_chart(app_df, x=\"day\", y=y)\n```\n\"\"\"\n\n\n@st.experimental_fragment\ndef parse_and_exec(response):\n    code_match = re.search(r\"```python\\n(.*)\\n```\", response, re.DOTALL)\n    if code_match:\n        code = code_match.group(1)\n        exec(code)\n\n\nmessages = [\n    {\"role\": \"user\", \"content\": \"how2LineChartPlz\"},\n    {\"role\": \"assistant\", \"content\": line_chart_response},\n]\n\nfor msg in messages:\n    st.chat_message(msg[\"role\"]).write(msg[\"content\"])\n    parse_and_exec(msg[\"content\"])\n", "e2e_playwright/st_link_button.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\nst.link_button(\"the label\", url=\"https://streamlit.io\")\n\nst.link_button(\"disabled\", url=\"https://streamlit.io\", disabled=True)\n\nst.link_button(\"primary\", url=\"https://streamlit.io\", type=\"primary\")\n\nst.link_button(\n    \"primary disabled\",\n    url=\"https://streamlit.io\",\n    type=\"primary\",\n    disabled=True,\n)\n\nst.link_button(\n    \"Container **full width** *markdown*\",\n    \"https://streamlit.io\",\n    use_container_width=True,\n    help=\"help text\",\n)\n\nst.link_button(\n    \"Container **full width** *markdown* ~~primary~~\",\n    \"https://streamlit.io\",\n    type=\"primary\",\n    use_container_width=True,\n    help=\"help text here\",\n)\n", "e2e_playwright/st_checkbox.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\nfrom streamlit import runtime\n\nleading_indent_code_tooltip = \"\"\"\nCode:\n\n    This\n    is\n    a\n    code\n    block!\"\"\"\ni1 = st.checkbox(\"checkbox 1 (True)\", True, help=leading_indent_code_tooltip)\nst.write(\"checkbox 1 - value:\", i1)\n\ni2 = st.checkbox(\"checkbox 2 (False)\", False)\nst.write(\"checkbox 2 - value:\", i2)\n\ni3 = st.checkbox(\n    \"checkbox 3: This is a really really really really long label that should wrap eventually if we keep addding more text to it\"\n)\nst.write(\"checkbox 3 - value:\", i3)\n\nif runtime.exists():\n\n    def on_change():\n        st.session_state.checkbox_clicked = True\n\n    st.checkbox(\"checkbox 4 (with callback)\", key=\"checkbox4\", on_change=on_change)\n    st.write(\"checkbox 4 - value:\", st.session_state.checkbox4)\n    st.write(\"checkbox 4 - clicked:\", \"checkbox_clicked\" in st.session_state)\n\ni5 = st.checkbox(\"checkbox 5 (False, disabled)\", disabled=True)\nst.write(\"checkbox 5 - value:\", i5)\n\ni6 = st.checkbox(\"checkbox 6 (True, disabled)\", value=True, disabled=True)\nst.write(\"checkbox 6 - value:\", i6)\n\ni7 = st.checkbox(\"checkbox 7 (label hidden)\", label_visibility=\"hidden\")\nst.write(\"checkbox 7 - value:\", i7)\n\ni8 = st.checkbox(\"checkbox 8 (label collapsed)\", label_visibility=\"collapsed\")\nst.write(\"checkbox 8 - value:\", i8)\n\nwith st.expander(\"Grouped checkboxes\", expanded=True):\n    st.checkbox(\"checkbox group - 1\")\n    st.checkbox(\"checkbox group - 2\")\n    st.checkbox(\"checkbox group - 3\")\n    st.text(\"A non-checkbox element\")\n", "e2e_playwright/forward_msg_cache.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\n# Send a ForwardMsg to the client that's long enough that we cache it.\nst.markdown(\n    \"\\n\\n\".join(\n        50\n        * [\n            \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus quis neque eu orci faucibus pellentesque. Vivamus dapibus pellentesque sem, vitae ultricies sem pharetra at. Curabitur eu congue magna, eu tempor libero. Donec vitae condimentum odio. Sed neque elit, porttitor eget laoreet volutpat, imperdiet et leo. Phasellus vel velit sit amet nulla hendrerit pharetra et non tortor. Lorem ipsum dolor sit amet, consectetur adipiscing elit. In malesuada sem sit amet felis vestibulum, maximus imperdiet nibh mollis. Cras in ipsum at neque mollis facilisis nec et tortor. Duis fringilla tortor id urna laoreet lobortis.\"\n        ]\n    )\n)\n", "e2e_playwright/st_experimental_fragment_basics.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom datetime import date\nfrom uuid import uuid4\n\nimport streamlit as st\n\n\n# Write a bunch of widgets so that we can interact with them and verify that only the\n# uuid within the fragment changes in the script run.\n# NOTE: We intentionally don't verify that values returned by these widgets work as\n# expected as doing so in this type of batch test would drastically increase the\n# boilerplate code required to write this. Instead, we rely on other tests to fully test\n# return values. We also don't test the camera_input, data_editor, and file_uploader\n# widgets as well as custom components here due to the disproportionate amount of work\n# required to do so.\n@st.experimental_fragment\ndef my_big_fragment():\n    st.button(\"a button\")\n    st.download_button(\"a download button\", b\"\")\n    st.chat_input(\"a chat input\")\n    st.checkbox(\"a checkbox\")\n    st.color_picker(\"a color picker\")\n    st.date_input(\"a date input\", date(1970, 1, 1), min_value=date(1970, 1, 1))\n    st.multiselect(\"a multiselect\", [\"a\", \"b\", \"c\"])\n    st.number_input(\"a number input\")\n    st.radio(\"a radio\", [\"a\", \"b\", \"c\"])\n    st.selectbox(\"a selectbox\", [\"a\", \"b\", \"c\"])\n    st.slider(\"a slider\")\n    st.text_area(\"a text area\")\n    st.text_input(\"a text input\")\n    st.time_input(\"a time input\")\n\n    st.write(f\"inside fragment: {uuid4()}\")\n\n\nmy_big_fragment()\n\nst.write(f\"outside: fragment {uuid4()}\")\n", "e2e_playwright/st_cache_resource.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\nst.button(\"click to rerun\")\n\nside_effects = []\n\n\n@st.cache_resource(experimental_allow_widgets=True)\ndef foo():\n    side_effects.append(\"function ran\")\n    r = st.radio(\"radio\", [\"foo\", \"bar\", \"baz\", \"qux\"], index=1)\n    return r\n\n\nfoo()\n\nst.text(side_effects)\n\n\n@st.cache_resource\ndef with_cached_widget_warning():\n    st.write(\"Cached function that should show a widget usage warning.\")\n    st.selectbox(\"selectbox\", [\"foo\", \"bar\", \"baz\", \"qux\"], index=1)\n\n\nif st.button(\"Run cached function with widget warning\"):\n    with_cached_widget_warning()\n\n\n@st.cache_resource(experimental_allow_widgets=True)\ndef inner_cache_function():\n    st.radio(\"radio 2\", [\"foo\", \"bar\", \"baz\", \"qux\"], index=1)\n\n\n@st.cache_resource(experimental_allow_widgets=False)\ndef nested_cached_function():\n    inner_cache_function()\n    st.selectbox(\"selectbox 2\", [\"foo\", \"bar\", \"baz\", \"qux\"], index=1)\n\n\nif st.button(\"Run nested cached function with widget warning\"):\n    # When running nested_cached_function(), we get two warnings, one from nested_cached_function()\n    # and one from inner_cache_function. inner_cache_function() on its own would allow the\n    # widget usage, but since it is nested in the other function that does not allow it, we don't allow it.\n    # The outer experimental_allow_widgets=False will always take priority.\n    # Otherwise, we would need to recompute the outer cached function whenever\n    # the widget in the inner function is used. Which we don't want to do when\n    # experimental_allow_widgets is set to False.\n    nested_cached_function()\n\nif \"run_counter\" not in st.session_state:\n    st.session_state.run_counter = 0\n\n\n@st.cache_resource\ndef replay_element():\n    st.session_state.run_counter += 1\n    st.markdown(f\"Cache executions: {st.session_state.run_counter}\")\n    return st.session_state.run_counter\n\n\nif st.button(\"Cached function with element replay\"):\n    st.write(\"Cache return\", replay_element())\n", "e2e_playwright/st_date_input.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom datetime import date, datetime\n\nimport streamlit as st\nfrom streamlit import runtime\n\nleading_indent_regular_text_tooltip = \"\"\"\nThis is a regular text block!\nTest1\nTest2\n\n\"\"\"\n\nv1 = st.date_input(\n    \"Single date\",\n    date(1970, 1, 1),\n    min_value=date(1970, 1, 1),\n    help=leading_indent_regular_text_tooltip,\n)\nst.write(\"Value 1:\", v1)\n\nv2 = st.date_input(\"Single datetime\", datetime(2019, 7, 6, 21, 15), help=\"Help text\")\nst.write(\"Value 2:\", v2)\n\nv3 = st.date_input(\"Range, no date\", [])\nst.write(\"Value 3:\", v3)\n\nv4 = st.date_input(\"Range, one date\", [date(2019, 7, 6)])\nst.write(\"Value 4:\", v4)\n\nv5 = st.date_input(\"Range, two dates\", [date(2019, 7, 6), date(2019, 7, 8)])\nst.write(\"Value 5:\", v5)\n\nv6 = st.date_input(\"Disabled, no date\", [], disabled=True)\nst.write(\"Value 6:\", v6)\n\nv7 = st.date_input(\n    \"Label hidden\", datetime(2019, 7, 6, 21, 15), label_visibility=\"hidden\"\n)\nst.write(\"Value 7:\", v7)\n\nv8 = st.date_input(\n    \"Label collapsed\", datetime(2019, 7, 6, 21, 15), label_visibility=\"collapsed\"\n)\nst.write(\"Value 8:\", v8)\n\nv9 = st.date_input(\"Single date with format\", date(1970, 1, 1), format=\"MM-DD-YYYY\")\nst.write(\"Value 9:\", v9)\n\nv10 = st.date_input(\n    \"Range, two dates with format\",\n    [date(2019, 7, 6), date(2019, 7, 8)],\n    format=\"MM/DD/YYYY\",\n)\nst.write(\"Value 10:\", v10)\n\nv11 = st.date_input(\"Range, no date with format\", [], format=\"DD.MM.YYYY\")\nst.write(\"Value 11:\", v11)\n\n\nif runtime.exists():\n\n    def on_change():\n        st.session_state.date_input_changed = True\n        st.text(\"Date input changed callback\")\n\n    st.date_input(\n        \"Single date with callback\",\n        date(1970, 1, 1),\n        min_value=date(1970, 1, 1),\n        key=\"date_input_12\",\n        on_change=on_change,\n    )\n    st.write(\"Value 12:\", st.session_state.date_input_12)\n    st.write(\"Date Input Changed:\", st.session_state.get(\"date_input_changed\") is True)\n    # Reset to False:\n    st.session_state.date_input_changed = False\n\nv13 = st.date_input(\"Empty value\", value=None)\nst.write(\"Value 13:\", v13)\n\nif \"date_input_14\" not in st.session_state:\n    st.session_state[\"date_input_14\"] = date(1970, 2, 3)\n\nv14 = st.date_input(\n    \"Value from state\",\n    value=None,\n    key=\"date_input_14\",\n)\nst.write(\"Value 14:\", v14)\n", "e2e_playwright/websocket_disconnect.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom datetime import date, time\n\nimport streamlit as st\n\noptions = (\"female\", \"male\")\n\nw1 = st.checkbox(\"I am human\", True)\n\nw2 = st.slider(\"Age\", 0, 100, 25, 1)\nst.write(\"Value 1:\", w2)\n\nw3 = st.text_area(\"Comments\", \"Streamlit is awesomeness!\")\n\nw4 = st.button(\"Click me\")\n\nw5 = st.radio(\"Gender\", options, 1)\n\nw6 = st.text_input(\"Text input widget\", \"i iz input\")\n\nw7 = st.selectbox(\"Options\", options, 1)\n\nw8 = st.time_input(\"Set an alarm for\", time(8, 45))\n\nw9 = st.date_input(\"A date to celebrate\", date(2019, 7, 6))\n", "e2e_playwright/st_toast.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\nst.set_page_config(layout=\"wide\")\nst.chat_input(\"input here\")\nst.toast(\"This is a default toast message\", icon=\"\ud83d\udc36\")\nst.toast(\n    \"Random toast message that is a really really really really really really really long message, going way past the 3 line limit\",\n    icon=\"\ud83e\udd84\",\n)\n\nst.toast(\"Your edited image was saved!\", icon=\":material/cabin:\")\n", "e2e_playwright/st_add_rows.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport time\n\nimport altair as alt\nimport numpy as np\nimport pandas as pd\n\nimport streamlit as st\n\ndf = pd.DataFrame({\"a\": [1, 2], \"b\": [3, 4], \"c\": [5, 6]})\n\ntable_element = st.table(df)\ndataframe_element = st.dataframe(df)\nchart_element_1 = st.line_chart()\nchart_element_2 = st.line_chart(df)\n\n# 4 identical charts, built in different ways.\nvega_element_1 = st.vega_lite_chart(\n    df,\n    {\n        \"mark\": {\"type\": \"line\", \"point\": True},\n        \"encoding\": {\n            \"x\": {\"field\": \"a\", \"type\": \"quantitative\"},\n            \"y\": {\"field\": \"b\", \"type\": \"quantitative\"},\n        },\n    },\n    use_container_width=True,\n)\nvega_element_2 = st.vega_lite_chart(\n    {\n        \"datasets\": {\"foo\": df},\n        \"data\": {\"name\": \"foo\"},\n        \"mark\": {\"type\": \"line\", \"point\": True},\n        \"encoding\": {\n            \"x\": {\"field\": \"a\", \"type\": \"quantitative\"},\n            \"y\": {\"field\": \"b\", \"type\": \"quantitative\"},\n        },\n    },\n    use_container_width=True,\n)\nvega_element_3 = st.vega_lite_chart(\n    {\n        \"datasets\": {\"foo\": df},\n        \"data\": {\"name\": \"foo\"},\n        \"mark\": {\"type\": \"line\", \"point\": True},\n        \"encoding\": {\n            \"x\": {\"field\": \"a\", \"type\": \"quantitative\"},\n            \"y\": {\"field\": \"b\", \"type\": \"quantitative\"},\n        },\n    },\n    use_container_width=True,\n)\naltair_element = st.altair_chart(\n    alt.Chart(df).mark_line(point=True).encode(x=\"a\", y=\"b\").interactive(),\n    use_container_width=True,\n)\n\ntable_element.add_rows(df)\ndataframe_element.add_rows(df)\nchart_element_1.add_rows(df)\nchart_element_2.add_rows(df)\nvega_element_1.add_rows(df)\nvega_element_2.add_rows(df)\nvega_element_3.add_rows(foo=df)\naltair_element.add_rows(df)\n\n# The following example was failing due to an issue (#3653) in st.add_rows.\n# In the previous implementation of Quiver, we were mutating the Quiver element\n# in the addRows function, which prevented re-rendering of the line chart.\n# This example reproduces the issue, so that we don't repeat the same mistake\n# in the future.\n\ncurrent_time = pd.to_datetime(\"08:00:00 2021-01-01\", utc=True)\nsimulation_step = pd.Timedelta(seconds=10)\n\ndf1 = pd.DataFrame(data=[[current_time, 1]], columns=[\"t\", \"y\"]).set_index(\"t\")\nline_chart = st.line_chart(df1, use_container_width=True)\n\nfor count in range(5):\n    current_time += simulation_step\n    df2 = pd.DataFrame(data=[[current_time, count]], columns=[\"t\", \"y\"]).set_index(\"t\")\n    line_chart.add_rows(df2)\n    time.sleep(0.25)\n\n# Test that `add_rows` errors out when the dataframe dimensions don't match.\n# This should show an error!\ndataframe_element = st.dataframe(df)\ndataframe_element.add_rows(np.abs(np.random.randn(1, 6)))\n", "e2e_playwright/st_session_state.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\nfrom streamlit import runtime\n\nif runtime.exists():\n    if \"checkbox1\" not in st.session_state:\n        st.session_state.checkbox1 = True\n\n    def on_checkbox_change(changed_checkbox_number):\n        if changed_checkbox_number == 1:\n            st.session_state.checkbox2 = False\n        elif changed_checkbox_number == 2:\n            st.session_state.checkbox1 = False\n\n    st.checkbox(\n        label=\"Checkbox1\", key=\"checkbox1\", on_change=on_checkbox_change, args=(1,)\n    )\n    st.checkbox(\n        label=\"Checkbox2\", key=\"checkbox2\", on_change=on_checkbox_change, args=(2,)\n    )\n\n    if \"initialized\" not in st.session_state:\n        st.session_state[\"item_counter\"] = 0\n        st.session_state.attr_counter = 0\n\n        st.session_state.initialized = True\n\n    if st.button(\"inc_item_counter\"):\n        st.session_state[\"item_counter\"] += 1\n\n    if st.button(\"inc_attr_counter\"):\n        st.session_state.attr_counter += 1\n\n    if st.button(\"del_item_counter\"):\n        del st.session_state[\"item_counter\"]\n\n    if st.button(\"del_attr_counter\"):\n        del st.session_state.attr_counter\n\n    if \"item_counter\" in st.session_state:\n        st.write(f\"item_counter: {st.session_state['item_counter']}\")\n\n    if \"attr_counter\" in st.session_state:\n        st.write(f\"attr_counter: {st.session_state.attr_counter}\")\n\n    st.write(f\"len(st.session_state): {len(st.session_state)}\")\n    st.write(st.session_state)\n", "e2e_playwright/label_markdown.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport datetime\n\nimport streamlit as st\n\nvalid_label = \"**Bold Text** *Italicized* ~Strikethough~ `Code Block` \ud83d\udc36 :joy:\"\n\ncolor_label = (\n    \"Colored Text - :red[red] :blue[blue] :green[green] :violet[violet] :orange[orange]\"\n)\n\nlink_label = \"Label Link - [Streamlit](https://streamlit.io)\"\n\nimage = \"Image ![Image Text](https://dictionary.cambridge.org/us/images/thumb/corgi_noun_002_08554.jpg?version=5.0.297)\"\n\ntable = \"\"\"\n| Syntax | Description |\n| ----------- | ----------- |\n| Header | Title |\n| Paragraph | Text |\n\"\"\"\n\nheading_1 = \"# Heading 1\"\nheading_2 = \"## Heading 2\"\n\nordered_list = \"\"\"\n 1. First Item\n 2. Second Item\n\"\"\"\nunordered_list = \"\"\"\n - Item 1\n - Item 2\n\"\"\"\n\ntask_list = \"\"\"\n- [x] Write the press release\n- [ ] Update the website\n- [ ] Contact the media\n\"\"\"\n\nblockquote = \"> Testing Blockquote\"\n\nhorizontal_rule = \"\"\"\nHorizontal Rule:\n\n---\n\n\"\"\"\n\n# Invalid Markdown: images, table elements, headings, unordered/ordered lists, task lists, horizontal rules, & blockquotes\nwith st.container():\n    st.subheader(\n        \"\u274c Entirely Disallowed - Images, Table Elements, Headings, Lists, Blockquotes, Horizontal Rules\"\n    )\n    st.button(image)\n    st.checkbox(table)\n    st.radio(heading_1, [\"Option 1\", \"Option 2\", \"Option 3\"])\n    st.selectbox(heading_2, [\"Option 1\", \"Option 2\", \"Option 3\"])\n    st.multiselect(ordered_list, [\"Blue\", \"Purple\", \"Green\"])\n    st.slider(unordered_list, 0, 10, 1)\n    st.select_slider(task_list, [\"Blue\", \"Purple\", \"Green\"])\n    st.text_input(blockquote)\n    st.number_input(horizontal_rule)\n    st.text_area(image)\n    st.date_input(table, datetime.date(2000, 3, 7))\n    st.time_input(heading_1, datetime.time(8, 45))\n    st.file_uploader(heading_2)\n    st.color_picker(ordered_list)\n    st.metric(unordered_list, value=7, delta=0.5)\n    with st.expander(task_list):\n        st.write(\"Expanded!\")\n    tabA, tabB = st.tabs([blockquote, horizontal_rule])\n\n\n# Bold, italics, strikethrough, code, & shortcodes/emojis - allowed in all\nwith st.container():\n    st.subheader(\n        \"\u2705 Entirely Allowed - Bold, Italics, Strikethrough, Code, Shortcodes/Emojis\"\n    )\n    st.button(valid_label)\n    st.checkbox(valid_label)\n    st.radio(valid_label, [\"Option 1\", \"Option 2\", \"Option 3\"])\n    st.selectbox(valid_label, [\"Option 1\", \"Option 2\", \"Option 3\"])\n    st.multiselect(valid_label, [\"Blue\", \"Purple\", \"Green\"])\n    st.slider(valid_label, 0, 10, 1)\n    st.select_slider(valid_label, [\"Blue\", \"Purple\", \"Green\"])\n    st.text_input(valid_label)\n    st.number_input(valid_label)\n    st.text_area(valid_label)\n    st.date_input(valid_label, datetime.date(2000, 3, 7))\n    st.time_input(valid_label, datetime.time(8, 45))\n    st.file_uploader(valid_label)\n    st.color_picker(valid_label)\n    st.metric(valid_label, value=7, delta=0.5)\n    with st.expander(valid_label):\n        st.write(\"Expanded!\")\n    st.tabs(\n        [\n            \"**Bold Text**\",\n            \"*Italicized*\",\n            \"~Strikethough~\",\n            \"`Code Block`\",\n            \"\ud83d\udc36\",\n            \":joy:\",\n        ]\n    )\n\n\n# Colored text - allowed in all\nwith st.container():\n    st.subheader(\"\u2705 Entirely Allowed - Colored text\")\n    st.button(color_label)\n    st.checkbox(color_label)\n    st.radio(color_label, [\"Option 1\", \"Option 2\", \"Option 3\"])\n    st.selectbox(color_label, [\"Option 1\", \"Option 2\", \"Option 3\"])\n    st.multiselect(color_label, [\"Blue\", \"Purple\", \"Green\"])\n    st.slider(color_label, 0, 10, 1)\n    st.select_slider(color_label, [\"Blue\", \"Purple\", \"Green\"])\n    st.text_input(color_label)\n    st.number_input(color_label)\n    st.text_area(color_label)\n    st.date_input(color_label, datetime.date(2000, 3, 7))\n    st.time_input(color_label, datetime.time(8, 45))\n    st.file_uploader(color_label)\n    st.color_picker(color_label)\n    st.metric(color_label, value=7, delta=0.5)\n    with st.expander(color_label):\n        st.write(\"Expanded!\")\n    st.tabs(\n        [\n            \"Colored Text:\",\n            \":red[red]\",\n            \":blue[blue]\",\n            \":green[green]\",\n            \":violet[violet]\",\n            \":orange[orange]\",\n        ]\n    )\n\n\n# Links - only restricted in buttons\nwith st.container():\n    st.subheader(\"\u274c Disallowed in Buttons - Links\")\n    st.button(link_label)\nwith st.container():\n    st.subheader(\"\u2705 Allowed outside of buttons - Links\")\n    st.checkbox(link_label)\n    st.radio(\n        link_label,\n        [\"Option 1 - [Streamlit](https://streamlit.io)\", \"Option 2\", \"Option 3\"],\n    )\n    st.selectbox(link_label, [\"Option 1\", \"Option 2\", \"Option 3\"])\n    st.multiselect(link_label, [\"Blue\", \"Purple\", \"Green\"])\n    st.slider(link_label, 0, 10, 1)\n    st.select_slider(link_label, [\"Blue\", \"Purple\", \"Green\"])\n    st.text_input(link_label)\n    st.number_input(link_label)\n    st.text_area(link_label)\n    st.date_input(link_label, datetime.date(2000, 3, 7))\n    st.time_input(link_label, datetime.time(8, 45))\n    st.file_uploader(link_label)\n    st.color_picker(link_label)\n    st.metric(link_label, value=7, delta=0.5)\n    with st.expander(link_label):\n        st.write(\"Expanded!\")\n    st.tabs([link_label])\n\nst.selectbox(\"\", [])  # No label\n", "e2e_playwright/shared/app_utils.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport re\nfrom typing import Pattern\n\nfrom playwright.sync_api import Locator, Page, expect\n\nfrom e2e_playwright.conftest import wait_for_app_run\n\n\ndef get_checkbox(locator: Locator | Page, label: str | Pattern[str]) -> Locator:\n    \"\"\"Get a checkbox widget with the given label.\n\n    Parameters\n    ----------\n\n    locator : Locator\n        The locator to search for the element.\n\n    label : str or Pattern[str]\n        The label of the element to get.\n\n    Returns\n    -------\n    Locator\n        The element.\n    \"\"\"\n    element = locator.get_by_test_id(\"stCheckbox\").filter(has_text=label)\n    expect(element).to_be_visible()\n    return element\n\n\ndef get_image(locator: Locator | Page, caption: str | Pattern[str]) -> Locator:\n    \"\"\"Get an image element with the given caption.\n\n    Parameters\n    ----------\n\n    locator : Locator or Page\n        The locator to search for the element.\n\n    caption : str or Pattern[str]\n        The caption of the image element to get.\n\n    Returns\n    -------\n    Locator\n        The element.\n    \"\"\"\n    element = locator.get_by_test_id(\"stImage\").filter(\n        has=locator.get_by_test_id(\"stImageCaption\").filter(has_text=caption)\n    )\n    expect(element).to_be_visible()\n\n    return element\n\n\ndef get_button(locator: Locator | Page, label: str | Pattern[str]) -> Locator:\n    \"\"\"Get a button widget with the given label.\n\n    Parameters\n    ----------\n\n    locator : Locator\n        The locator to search for the element.\n\n    label : str or Pattern[str]\n        The label of the element to get.\n\n    Returns\n    -------\n    Locator\n        The element.\n    \"\"\"\n    element = (\n        locator.get_by_test_id(\"stButton\").filter(has_text=label).locator(\"button\")\n    )\n    expect(element).to_be_visible()\n    return element\n\n\ndef get_form_submit_button(\n    locator: Locator | Page, label: str | Pattern[str]\n) -> Locator:\n    \"\"\"Get a form submit button with the given label.\n\n    Parameters\n    ----------\n\n    locator : Locator\n        The locator to search for the element.\n\n    label : str or Pattern[str]\n        The label of the element to get.\n\n    Returns\n    -------\n    Locator\n        The element.\n    \"\"\"\n    element = locator.get_by_test_id(\"baseButton-secondaryFormSubmit\").filter(\n        has_text=label\n    )\n    expect(element).to_be_visible()\n    return element\n\n\ndef get_expander(locator: Locator | Page, label: str | Pattern[str]) -> Locator:\n    \"\"\"Get a expander container with the given label.\n\n    Parameters\n    ----------\n\n    locator : Locator\n        The locator to search for the expander.\n\n    label : str or Pattern[str]\n        The label of the expander to get.\n\n    Returns\n    -------\n    Locator\n        The expander container.\n    \"\"\"\n    element = locator.get_by_test_id(\"stExpander\").filter(\n        has=locator.locator(\"summary\").filter(has_text=label)\n    )\n    expect(element).to_be_visible()\n    return element\n\n\ndef get_markdown(\n    locator: Locator | Page, text_inside_markdown: str | Pattern[str]\n) -> Locator:\n    \"\"\"Get a markdown element with the given text inside.\n\n    Parameters\n    ----------\n\n    locator : Locator\n        The locator to search for the expander.\n\n    text_inside_markdown : str or Pattern[str]\n        Some text to use to identify the markdown element. The text should be contained\n        in the markdown content.\n\n    Returns\n    -------\n    Locator\n        The expander content.\n    \"\"\"\n    if isinstance(text_inside_markdown, str):\n        text_inside_markdown = re.compile(text_inside_markdown)\n\n    markdown_element = locator.get_by_test_id(\"stMarkdownContainer\").filter(\n        has_text=text_inside_markdown\n    )\n    expect(markdown_element).to_be_visible()\n    return markdown_element\n\n\ndef expect_prefixed_markdown(\n    locator: Locator | Page,\n    expected_prefix: str,\n    expected_markdown: str | Pattern[str],\n    exact_match: bool = False,\n) -> None:\n    \"\"\"Find the markdown with the prefix and then ensure that the\n    `expected_markdown` is in the text as well.\n\n    Splitting it into a `filter` and a `to_have_text` check has the advantage\n    that we see the diff in case of a mismatch; this would not be the case if we\n    just used the `filter`.\n\n    Only one markdown-element must be returned, otherwise an error is thrown.\n\n    Parameters\n    ----------\n    locator : Locator\n        The locator to search for the markdown element.\n\n    expected_prefix : str\n        The prefix of the markdown element.\n\n    expected_markdown : str or Pattern[str]\n        The markdown content that should be found. If a pattern is provided,\n        the text will be matched against this pattern.\n\n    exact_match : bool, optional\n        Whether the markdown should exactly match the `expected_markdown`, by default True.\n        Otherwise, the `expected_markdown` must be contained in the markdown content.\n\n    \"\"\"\n    selection_text = locator.get_by_test_id(\"stMarkdownContainer\").filter(\n        has_text=expected_prefix\n    )\n    if exact_match:\n        text_to_match: str | Pattern[str]\n        if isinstance(expected_markdown, Pattern):\n            # Recompile the pattern with the prefix:\n            text_to_match = re.compile(f\"{expected_prefix} {expected_markdown.pattern}\")\n        else:\n            text_to_match = f\"{expected_prefix} {expected_markdown}\"\n\n        expect(selection_text).to_have_text(text_to_match)\n    else:\n        expect(selection_text).to_contain_text(expected_markdown)\n\n\ndef expect_markdown(\n    locator: Locator | Page,\n    expected_message: str | Pattern[str],\n) -> None:\n    \"\"\"Expect an exception to be displayed in the app.\n\n    Parameters\n    ----------\n\n    locator : Locator\n        The locator to search for the exception element.\n\n    expected_markdown : str or Pattern[str]\n        The expected message to be displayed in the exception.\n    \"\"\"\n    markdown_el = (\n        locator.get_by_test_id(\"stMarkdown\")\n        .get_by_test_id(\"stMarkdownContainer\")\n        .filter(has_text=expected_message)\n    )\n    expect(markdown_el).to_be_visible()\n\n\ndef expect_exception(\n    locator: Locator | Page,\n    expected_message: str | Pattern[str],\n) -> None:\n    \"\"\"Expect an exception to be displayed in the app.\n\n    Parameters\n    ----------\n\n    locator : Locator\n        The locator to search for the exception element.\n\n    expected_markdown : str or Pattern[str]\n        The expected message to be displayed in the exception.\n    \"\"\"\n    exception_el = locator.get_by_test_id(\"stException\").filter(\n        has_text=expected_message\n    )\n    expect(exception_el).to_be_visible()\n\n\ndef click_checkbox(\n    page: Page,\n    label: str | Pattern[str],\n) -> None:\n    \"\"\"Click a checkbox with the given label\n    and wait for the app to run.\n\n    Parameters\n    ----------\n\n    page : Page\n        The page to click the button on.\n\n    label : str or Pattern[str]\n        The label of the button to click.\n    \"\"\"\n    checkbox_element = get_checkbox(page, label)\n    #  Click the checkbox label to be more reliable\n    checkbox_element.locator(\"label\").click()\n    wait_for_app_run(page)\n\n\ndef click_toggle(\n    page: Page,\n    label: str | Pattern[str],\n) -> None:\n    \"\"\"Click a toggle with the given label\n    and wait for the app to run.\n\n    Parameters\n    ----------\n\n    page : Page\n        The page to click the toggle on.\n\n    label : str or Pattern[str]\n        The label of the toggle to click.\n    \"\"\"\n    click_checkbox(page, label)\n\n\ndef click_button(\n    page: Page,\n    label: str | Pattern[str],\n) -> None:\n    \"\"\"Click a button with the given label\n    and wait for the app to run.\n\n    Parameters\n    ----------\n\n    page : Page\n        The page to click the button on.\n\n    label : str or Pattern[str]\n        The label of the button to click.\n    \"\"\"\n    button_element = get_button(page, label)\n    button_element.click()\n    wait_for_app_run(page)\n\n\ndef click_form_button(\n    page: Page,\n    label: str | Pattern[str],\n) -> None:\n    \"\"\"Click a form submit button with the given label\n    and wait for the app to run.\n\n    Parameters\n    ----------\n\n    page : Page\n        The page to click the button on.\n\n    label : str or Pattern[str]\n        The label of the button to click.\n    \"\"\"\n    button_element = get_form_submit_button(page, label)\n    button_element.click()\n    wait_for_app_run(page)\n\n\ndef expect_help_tooltip(\n    app: Locator | Page,\n    element_with_help_tooltip: Locator,\n    tooltip_text: str | Pattern[str],\n):\n    \"\"\"Expect a tooltip to be displayed when hovering over the help symbol of an element.\n\n    This only works for elements that have our shared help tooltip implemented.\n    It doesn't work for elements with a custom tooltip implementation, e.g. st.button.\n\n    The element gets unhovered after the tooltip is checked.\n\n    Parameters\n    ----------\n    app : Page\n        The page to search for the tooltip.\n\n    element_with_help_tooltip : Locator\n        The locator of the element with the help tooltip.\n\n    tooltip_text : str or Pattern[str]\n        The text of the tooltip to expect.\n    \"\"\"\n    hover_target = element_with_help_tooltip.get_by_test_id(\"stTooltipHoverTarget\")\n    expect(hover_target).to_be_visible()\n\n    tooltip_content = app.get_by_test_id(\"stTooltipContent\")\n    expect(tooltip_content).not_to_be_attached()\n\n    hover_target.hover()\n\n    expect(tooltip_content).to_be_visible()\n    expect(tooltip_content).to_have_text(tooltip_text)\n\n    # reset the hovering in case this method is called multiple times in the same test\n    app.get_by_test_id(\"stApp\").hover(\n        position={\"x\": 0, \"y\": 0}, no_wait_after=True, force=True\n    )\n    expect(tooltip_content).not_to_be_attached()\n", "e2e_playwright/shared/__init__.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n", "e2e_playwright/multipage_apps_v2/page_3.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\nst.subheader(\"Page 3\")\nx = st.slider(\"x\")\nst.markdown(f\"x is {x}\")\n", "e2e_playwright/multipage_apps_v2/page_2.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\nst.subheader(\"Page 2\")\n\npage_6 = st.button(\"page_6\")\nif page_6:\n    st.switch_page(\"page_6.py\")\n\nif st.button(\"Throw exception\"):\n    raise Exception(\"This is a test exception\")\n", "e2e_playwright/multipage_apps_v2/\ud83e\udd92_page_4.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\nst.header(\"Page 4\")\n\nwith st.sidebar:\n    st.page_link(\"page_2.py\", label=\"Page 2\", icon=\":material/article:\")\n    st.page_link(\"page_3.py\", label=\"Page 3\", icon=\"\ud83d\udcc8\")\n", "e2e_playwright/multipage_apps_v2/mpa_v2_basics.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport pathlib\n\nfrom PIL import Image\n\nimport streamlit as st\n\nparent_directory = pathlib.Path(__file__).parent.parent / \"multipage_apps\"\nsmall_logo = Image.open(str(parent_directory / \"small-streamlit.png\"))\n\nlogo = Image.open(str(parent_directory / \"full-streamlit.png\"))\n\nst.logo(logo, link=\"https://www.example.com\", icon_image=small_logo)\n\nst.header(\"Main Page\")\nx = st.slider(\"x\")\n\nst.write(f\"x is {x}\")\n\nset_default = bool(st.query_params.get(\"default\", False))\n\npage2 = st.Page(\"page_2.py\")\npage3 = st.Page(\"page_3.py\", title=\"Different Title\")\npage4 = st.Page(\"\ud83e\udd92_page_4.py\")\npage5 = st.Page(\"page_5.py\", icon=\":material/settings:\")\npage6 = st.Page(\"page_6_slow_page.py\", title=\"slow page\")\n\n\ndef page_7():\n    st.header(\"Page 7\")\n    x = st.slider(\"y\")\n    st.write(f\"y is {x}\")\n\n\ndef page_8():\n    st.header(\"Page 8\")\n\n\ndef page_9():\n    st.header(\"Page 9\")\n\n\ndef page_10():\n    st.header(\"Page 10\")\n\n    @st.experimental_fragment\n    def get_input():\n        st.text_input(\"Some input\")\n        if st.button(\"Submit\"):\n            st.rerun()\n\n    get_input()\n\n\npage7 = st.Page(page_7, default=set_default)\npage8 = st.Page(page_8, url_path=\"my_url_path\")\npage9 = st.Page(page_9)\npage10 = st.Page(page_10)\npage11 = st.Page(page_8, title=\"page 11\", url_path=\"page_11\")\npage12 = st.Page(page_9, title=\"page 12\", url_path=\"page_12\")\n\nhide_sidebar = st.checkbox(\"Hide sidebar\")\ndynamic_nav = st.checkbox(\"Change navigation dynamically\")\npg = st.navigation(\n    (\n        [page2, page3, page5, page9]\n        if dynamic_nav\n        else {\n            \"Section 1\": [page2, page3],\n            \"Section 2\": [page4, page5],\n            \"Section 3\": [page6],\n            \"Section 4\": [page7, page8, page9],\n            \"Section 5\": [page10, page11, page12],\n        }\n    ),\n    position=\"hidden\" if hide_sidebar else \"sidebar\",\n)\n\nif st.button(\"page 5\"):\n    st.switch_page(\"page_5.py\")\n\nif st.button(\"page 9\"):\n    st.switch_page(page9)\n\nif st.checkbox(\"Show sidebar elements\"):\n    st.sidebar.write(\"Sidebar content\")\n\npg.run()\n\nst.page_link(\"page_5.py\", label=\"page 5 page link\")\n\nst.page_link(page9, label=\"page 9 page link\")\n\nst.write(\"End of Script\")\n", "e2e_playwright/multipage_apps_v2/mpa_v2_initial_load.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\npage = st.navigation([st.Page(\"page_5.py\")])\npage.run()\n", "e2e_playwright/multipage_apps_v2/page_5.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\nst.header(\"Page 5\")\n\nif \"test_value\" not in st.session_state:\n    st.session_state.test_value = False\n\n\ndef handle_change():\n    st.session_state.test_value = True\n\n\nst.checkbox(\"Checkbox 1\", on_change=handle_change)\nst.checkbox(\"Checkbox 2\")\n\nst.write(\"test_value: \", st.session_state.test_value)\n", "e2e_playwright/multipage_apps_v2/__init__.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n", "e2e_playwright/multipage_apps_v2/page_6_slow_page.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport time\n\nimport streamlit as st\n\nst.header(\"Page 6\")\n\nwith st.sidebar:\n    st.write(\"Sidebar\")\n    color = st.color_picker(\"Pick a color\")\n    st.write(\"You picked:\", color)\n    st.divider()\n    st.text_area(\"Some random text:\", height=500)\n\n# add a sleep timer to simulate a slow loading page. This allows us for example\n# to simulate navigating away from a partially loaded page\ntime.sleep(5)\nst.write(\"Finished sleeping for 5 seconds.\")\n", "e2e_playwright/multipage_apps/mpa_configure_sidebar.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport pathlib\n\nfrom PIL import Image\n\nimport streamlit as st\n\nsmall_logo = Image.open(str(pathlib.Path(__file__).parent / \"small-streamlit.png\"))\n\nlogo = Image.open(str(pathlib.Path(__file__).parent / \"full-streamlit.png\"))\n\nst.header(\"App with no sidebar\")\n\nst.subheader(\"Page Navigation:\")\n\nst.logo(logo, link=\"https://www.example.com\", icon_image=small_logo)\n\n\ncolA, colB = st.columns(2)\n\nwith colA:\n    st.page_link(\"mpa_configure_sidebar.py\", label=\"Home\", icon=\"\ud83c\udfe0\")\n    st.page_link(\"pages/02_page2.py\", label=\"Page 2\", icon=\":material/article:\")\n    st.page_link(\"pages/03_page3.py\", label=\"Page 3\", icon=\"\ud83d\udcc8\", disabled=True)\n\nwith colB:\n    st.page_link(\"pages/04_page_with_duplicate_name.py\", label=\"Page 4\", icon=\"\ud83e\uddea\")\n    st.page_link(\"pages/05_page_with_duplicate_name.py\", label=\"Page 5\", icon=\"\ud83c\udf0e\")\n", "e2e_playwright/multipage_apps/mpa_v2_transition.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\nst.header(\"Main Page\")\n\npg = st.navigation(\n    [\n        st.Page(\"pages/02_page2.py\"),\n        st.Page(\"pages/03_page3.py\", default=True),\n        st.Page(\"pages/09_logo_page.py\"),\n    ]\n)\n\npg.run()\n\nst.write(\"End of Main Page\")\n", "e2e_playwright/multipage_apps/mpa_basics.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\nst.header(\"Main Page\")\nst.slider(\"x\")\n\nif st.button(\"`pages/02_page2.py`\"):\n    st.switch_page(\"pages/02_page2.py\")\n\nif st.button(\"`pages/08_slow_page.py`\"):\n    st.switch_page(\"pages/08_slow_page.py\")\n", "e2e_playwright/multipage_apps/__init__.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n", "e2e_playwright/multipage_apps/pages/07_page_7.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\nst.header(\"Page 7\")\n\nwith st.sidebar:\n    st.write(\"Sidebar\")\n    color = st.color_picker(\"Pick a color\")\n    st.write(\"You picked:\", color)\n    st.divider()\n    st.text_area(\"Some random text:\", height=500)\n", "e2e_playwright/multipage_apps/pages/06_page_6.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\nst.header(\"Page 6\")\n\nhome = st.button(\"`./mpa_basics.py`\")\nif home:\n    st.switch_page(\"./mpa_basics.py\")\n", "e2e_playwright/multipage_apps/pages/03_page3.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\nst.header(\"Page 3\")\nx = st.slider(\"x\")\nst.markdown(f\"x is {x}\")\n", "e2e_playwright/multipage_apps/pages/04_page_with_duplicate_name.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\nst.header(\"Page 4\")\n\nwith st.sidebar:\n    st.page_link(\"mpa_configure_sidebar.py\", label=\"Home\", icon=\"\ud83c\udfe0\")\n    st.page_link(\"pages/02_page2.py\", label=\"Page 2\", icon=\":material/article:\")\n    st.page_link(\"pages/03_page3.py\", label=\"Page 3\", icon=\"\ud83d\udcc8\")\n    st.page_link(\"pages/04_page_with_duplicate_name.py\", label=\"Page 4\", icon=\"\ud83e\uddea\")\n    st.page_link(\n        \"pages/05_page_with_duplicate_name.py\", label=\"Page 5\", icon=\"\ud83c\udf0e\", disabled=True\n    )\n", "e2e_playwright/multipage_apps/pages/08_slow_page.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport time\n\nimport streamlit as st\n\nst.header(\"Slow page\")\ntime.sleep(10)\n", "e2e_playwright/multipage_apps/pages/09_logo_page.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport pathlib\n\nfrom PIL import Image\n\nimport streamlit as st\n\nsmall_logo = Image.open(\n    str(pathlib.Path(__file__).parent.parent / \"small-streamlit.png\")\n)\n\nlogo = Image.open(str(pathlib.Path(__file__).parent.parent / \"full-streamlit.png\"))\n\nst.header(\"Logo page\")\nst.logo(logo, link=\"https://www.example.com\", icon_image=small_logo)\n\nwith st.sidebar:\n    st.radio(\"Example Sidebar Content\", [\"Home\", \"About\", \"Contact\"])\n", "e2e_playwright/multipage_apps/pages/05_page_with_duplicate_name.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\nst.header(\"Page 5\")\n", "e2e_playwright/multipage_apps/pages/02_page2.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\nst.header(\"Page 2\")\n\npage_6 = st.button(\"`pages/06_page_6.py`\")\nif page_6:\n    st.switch_page(\"pages/06_page_6.py\")\n", "e2e_playwright/custom_components/popular_components.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Test the components logic and that custom components work.\n\nThis test app includes some component actions as well as the top N most popular custom components based on our usage metrics.\nThe function for the component is imported when the respective option is selected in the selection-widget.\nAlso, some example action is executed on the component.\nIf the component cannot be imported or the component itself has some issue, e.g. some transitive import does not work,\nan exception is shown.\nThis is some guard for us to detect potential issues in case of refactorings etc.\n\nFollowing actions/components are tested:\n- components.html (this function and its import is popularily documented in some places)\n- extra-streamlit-components (CookieManager)\n- streamlit-ace\n- streamlit-antd-components\n- streamlit-aggrid\n- streamlit-autorefresh\n- streamlit-chat\n- streamlit-echarts\n- streamlit-folium\n- streamlit-option-menu\n- streamlit-url-fragment\n\"\"\"\n\nfrom __future__ import annotations\n\nfrom typing import Callable\n\nimport streamlit as st\n\n\ndef use_components_html():\n    # note that we import streamlit before and so this `components.html` working\n    # might be coincidental; this is the reason why we have dedicated tests for this kind of imports in the `st_components_v1_*` files\n    import streamlit.components.v1 as components\n\n    components.html(\"<div>Hello World!</div>\")\n\n\ndef use_components_iframe():\n    # note that we import streamlit before and so this `components.html` working\n    # might be coincidental; this is the reason why we have dedicated tests for this kind of imports in the `st_components_v1_*` files\n    import streamlit.components.v1 as components\n\n    st.write(str(components.iframe))\n\n\ndef use_components_declare_component():\n    import streamlit.components.v1 as components\n\n    st.write(str(components.declare_component))\n\n\n# Different custom components:\ndef use_streamlit_ace():\n    from streamlit_ace import st_ace\n\n    ## Spawn a new Ace editor\n    content = st_ace()\n    st.write(content)\n\n\ndef use_aggrid():\n    import numpy as np\n    import pandas as pd\n    from st_aggrid import AgGrid\n\n    np.random.seed(0)\n    df = pd.DataFrame(\n        np.random.choice(100, size=(100, 4)), columns=[\"A\", \"B\", \"C\", \"D\"]\n    )\n    AgGrid(df, height=200)\n\n\ndef use_antd():\n    import streamlit_antd_components as sac\n\n    btn = sac.buttons(\n        items=[\"button1\", \"button2\", \"button3\"],\n        index=0,\n        format_func=\"title\",\n        align=\"center\",\n        direction=\"horizontal\",\n        radius=\"lg\",\n        return_index=False,\n    )\n    st.write(f\"The selected button label is: {btn}\")\n\n\ndef use_autorefresh():\n    from streamlit_autorefresh import st_autorefresh\n\n    ## Run the autorefresh about every 2000 milliseconds (2 seconds) and stop\n    ## after it's been refreshed 100 times.\n    count = st_autorefresh(interval=2000, limit=100, key=\"fizzbuzzcounter\")\n    ## The function returns a counter for number of refreshes. This allows the\n    ## ability to make special requests at different intervals based on the count\n    if count == 0:\n        st.write(\"Count is zero\")\n    elif count % 3 == 0 and count % 5 == 0:\n        st.write(\"FizzBuzz\")\n    elif count % 3 == 0:\n        st.write(\"Fizz\")\n    elif count % 5 == 0:\n        st.write(\"Buzz\")\n    else:\n        st.write(f\"Count: {count}\")\n\n\ndef use_chat():\n    from streamlit_chat import message\n\n    message(\"My message\")\n    message(\"Hello bot!\", is_user=True)  # align's the message to the right\n\n\ndef use_echarts():\n    from streamlit_echarts import st_echarts\n\n    options = {\n        \"xAxis\": {\n            \"type\": \"category\",\n            \"data\": [\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"],\n        },\n        \"yAxis\": {\"type\": \"value\"},\n        \"series\": [{\"data\": [820, 932, 901, 934, 1290, 1330, 1320], \"type\": \"line\"}],\n    }\n    st_echarts(options=options)\n\n\ndef use_extra_streamlit_components():\n    from extra_streamlit_components import CookieManager\n\n    CookieManager()\n\n\ndef use_folium():\n    import folium\n    from streamlit_folium import st_folium\n\n    ## center on Liberty Bell, add marker\n    m = folium.Map(location=[39.949610, -75.150282], zoom_start=16)\n    folium.Marker(\n        [39.949610, -75.150282], popup=\"Liberty Bell\", tooltip=\"Liberty Bell\"\n    ).add_to(m)\n    ## call to render Folium map in Streamlit\n    st_data = st_folium(m, width=725)\n    st.write(st_data)\n\n\ndef use_option_menu():\n    from streamlit_option_menu import option_menu\n\n    key = \"my_option_menu\"\n\n    # TODO: uncomment the on_change callback as soon as streamlit-option-menu is updated and uses the new on_change callback\n    # def on_change():\n    #     selection = st.session_state[key]\n    #     st.write(f\"Selection changed to {selection}\")\n\n    with st.sidebar:\n        selected = option_menu(\n            \"Main Menu\",\n            [\"Home\", \"Settings\"],\n            icons=[\"house\", \"gear\"],\n            menu_icon=\"cast\",\n            default_index=1,\n            key=key,\n            # on_change=on_change,\n        )\n        st.write(selected)\n\n\ndef use_url_fragment():\n    from streamlit_url_fragment import get_fragment\n\n    current_value = get_fragment()\n    st.write(f\"Current value: {current_value!r}\")\n\n\n# ---\n\noptions: dict[str, Callable] = {\n    \"componentsHtml\": use_components_html,\n    \"componentsIframe\": use_components_iframe,\n    \"componentsDeclareComponent\": use_components_declare_component,\n    \"ace\": use_streamlit_ace,\n    \"aggrid\": use_aggrid,\n    \"antd\": use_antd,\n    \"autorefresh\": use_autorefresh,\n    \"chat\": use_chat,\n    \"echarts\": use_echarts,\n    \"extraStreamlitComponents\": use_extra_streamlit_components,\n    \"folium\": use_folium,\n    \"optionMenu\": use_option_menu,\n    \"urlFragment\": use_url_fragment,\n}\ncomponent_selection = st.selectbox(\"ComponentSelections\", options=options.keys())\nif component_selection:\n    options[component_selection]()\n", "e2e_playwright/custom_components/__init__.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n", "lib/setup.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport os\nimport sys\nfrom pathlib import Path\n\nfrom setuptools import find_packages, setup\nfrom setuptools.command.install import install\n\nTHIS_DIRECTORY = Path(__file__).parent\n\nVERSION = \"1.36.0\"  # PEP-440\n\n# IMPORTANT: We should try very hard *not* to add dependencies to Streamlit.\n# And if you do add one, make the required version as general as possible:\n# - Include relevant lower bound for any features we use from our dependencies\n# - Always include the lower bound as >= VERSION, to keep testing min versions easy\n# - And include an upper bound that's < NEXT_MAJOR_VERSION\nINSTALL_REQUIRES = [\n    \"altair>=4.0, <6\",\n    \"blinker>=1.0.0, <2\",\n    \"cachetools>=4.0, <6\",\n    \"click>=7.0, <9\",\n    \"numpy>=1.20, <3\",\n    \"packaging>=20, <25\",\n    # Lowest version with available wheel for 3.7 + amd64 + linux\n    \"pandas>=1.3.0, <3\",\n    \"pillow>=7.1.0, <11\",\n    # `protoc` < 3.20 is not able to generate protobuf code compatible with protobuf >= 3.20.\n    \"protobuf>=3.20, <6\",\n    # pyarrow is not semantically versioned, gets new major versions frequently, and\n    # doesn't tend to break the API on major version upgrades, so we don't put an\n    # upper bound on it.\n    \"pyarrow>=7.0\",\n    \"requests>=2.27, <3\",\n    \"rich>=10.14.0, <14\",\n    \"tenacity>=8.1.0, <9\",\n    \"toml>=0.10.1, <2\",\n    \"typing-extensions>=4.3.0, <5\",\n    # Don't require watchdog on MacOS, since it'll fail without xcode tools.\n    # Without watchdog, we fallback to a polling file watcher to check for app changes.\n    \"watchdog>=2.1.5, <5; platform_system != 'Darwin'\",\n]\n\n# We want to exclude some dependencies in our internal Snowpark conda distribution of\n# Streamlit. These dependencies will be installed normally for both regular conda builds\n# and PyPI builds (that is, for people installing streamlit using either\n# `pip install streamlit` or `conda install -c conda-forge streamlit`)\nSNOWPARK_CONDA_EXCLUDED_DEPENDENCIES = [\n    \"gitpython>=3.0.7, <4, !=3.1.19\",\n    \"pydeck>=0.8.0b4, <1\",\n    # Tornado 6.0.3 was the current Tornado version when Python 3.8, our earliest supported Python version,\n    # was released (Oct 14, 2019).\n    \"tornado>=6.0.3, <7\",\n]\n\nif not os.getenv(\"SNOWPARK_CONDA_BUILD\"):\n    INSTALL_REQUIRES.extend(SNOWPARK_CONDA_EXCLUDED_DEPENDENCIES)\n\nEXTRA_REQUIRES = {\n    \"snowflake\": [\n        \"snowflake-snowpark-python>=0.9.0; python_version<'3.12'\",\n        \"snowflake-connector-python>=2.8.0; python_version<'3.12'\",\n    ]\n}\n\n\nclass VerifyVersionCommand(install):\n    \"\"\"Custom command to verify that the git tag matches our version\"\"\"\n\n    description = \"verify that the git tag matches our version\"\n\n    def run(self):\n        tag = os.getenv(\"TAG\")\n\n        if tag != VERSION:\n            info = f\"Git tag: {tag} does not match the version of this app: {VERSION}\"\n            sys.exit(info)\n\n\nreadme_path = THIS_DIRECTORY / \"..\" / \"README.md\"\nif readme_path.exists():\n    long_description = readme_path.read_text()\nelse:\n    # In some build environments (specifically in conda), we may not have the README file\n    # readily available. In these cases, just let long_description be the empty string.\n    # Note that long_description isn't used at all in these build environments, so it\n    # being missing isn't problematic.\n    long_description = \"\"\n\nsetup(\n    name=\"streamlit\",\n    version=VERSION,\n    description=\"A faster way to build and share data apps\",\n    long_description=long_description,\n    long_description_content_type=\"text/markdown\",\n    url=\"https://streamlit.io\",\n    project_urls={\n        \"Source Code\": \"https://github.com/streamlit/streamlit\",\n        \"Bug Tracker\": \"https://github.com/streamlit/streamlit/issues\",\n        \"Release notes\": \"https://docs.streamlit.io/develop/quick-reference/changelog\",\n        \"Documentation\": \"https://docs.streamlit.io/\",\n        \"Community\": \"https://discuss.streamlit.io/\",\n        \"Twitter\": \"https://twitter.com/streamlit\",\n    },\n    author=\"Snowflake Inc\",\n    author_email=\"hello@streamlit.io\",\n    license=\"Apache License 2.0\",\n    classifiers=[\n        \"Development Status :: 5 - Production/Stable\",\n        \"Environment :: Console\",\n        \"Environment :: Web Environment\",\n        \"Intended Audience :: Developers\",\n        \"Intended Audience :: Science/Research\",\n        \"License :: OSI Approved :: Apache Software License\",\n        \"Programming Language :: Python :: 3.8\",\n        \"Programming Language :: Python :: 3.9\",\n        \"Programming Language :: Python :: 3.10\",\n        \"Programming Language :: Python :: 3.11\",\n        \"Programming Language :: Python :: 3.12\",\n        \"Topic :: Database :: Front-Ends\",\n        \"Topic :: Office/Business :: Financial :: Spreadsheet\",\n        \"Topic :: Scientific/Engineering :: Information Analysis\",\n        \"Topic :: Scientific/Engineering :: Visualization\",\n        \"Topic :: Software Development :: Libraries :: Application Frameworks\",\n        \"Topic :: Software Development :: Widget Sets\",\n    ],\n    # We exclude Python 3.9.7 from our compatible versions due to a bug in that version\n    # with typing.Protocol. See https://github.com/streamlit/streamlit/issues/5140 and\n    # https://bugs.python.org/issue45121\n    python_requires=\">=3.8, !=3.9.7\",\n    # PEP 561: https://mypy.readthedocs.io/en/stable/installed_packages.html\n    package_data={\"streamlit\": [\"py.typed\", \"hello/**/*.py\"]},\n    packages=find_packages(exclude=[\"tests\", \"tests.*\"]),\n    # Requirements\n    install_requires=INSTALL_REQUIRES,\n    extras_require=EXTRA_REQUIRES,\n    zip_safe=False,  # install source files not egg\n    include_package_data=True,  # copy html and friends\n    entry_points={\"console_scripts\": [\"streamlit = streamlit.web.cli:main\"]},\n    # For Windows so that streamlit * commands work ie.\n    # - streamlit version\n    # - streamlit hello\n    scripts=[\"bin/streamlit.cmd\"],\n    cmdclass={\n        \"verify\": VerifyVersionCommand,\n    },\n)\n", "lib/streamlit/source_util.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport re\nimport threading\nfrom pathlib import Path\nfrom typing import Any, Callable, Final, TypedDict, cast\n\nfrom blinker import Signal\nfrom typing_extensions import NotRequired, TypeAlias\n\nfrom streamlit.logger import get_logger\nfrom streamlit.string_util import extract_leading_emoji\nfrom streamlit.util import calc_md5\n\n_LOGGER: Final = get_logger(__name__)\n\nPageHash: TypeAlias = str\nPageName: TypeAlias = str\nScriptPath: TypeAlias = str\nIcon: TypeAlias = str\n\n\nclass PageInfo(TypedDict):\n    script_path: ScriptPath\n    page_script_hash: PageHash\n    icon: NotRequired[Icon]\n    page_name: NotRequired[PageName]\n    url_pathname: NotRequired[str]\n\n\ndef open_python_file(filename: str):\n    \"\"\"Open a read-only Python file taking proper care of its encoding.\n\n    In Python 3, we would like all files to be opened with utf-8 encoding.\n    However, some author like to specify PEP263 headers in their source files\n    with their own encodings. In that case, we should respect the author's\n    encoding.\n    \"\"\"\n    import tokenize\n\n    if hasattr(tokenize, \"open\"):  # Added in Python 3.2\n        # Open file respecting PEP263 encoding. If no encoding header is\n        # found, opens as utf-8.\n        return tokenize.open(filename)\n    else:\n        return open(filename, encoding=\"utf-8\")\n\n\nPAGE_FILENAME_REGEX = re.compile(r\"([0-9]*)[_ -]*(.*)\\.py\")\n\n\ndef page_sort_key(script_path: Path) -> tuple[float, str]:\n    matches = re.findall(PAGE_FILENAME_REGEX, script_path.name)\n\n    # Failing this assert should only be possible if script_path isn't a Python\n    # file, which should never happen.\n    assert len(matches) > 0, f\"{script_path} is not a Python file\"\n\n    [(number, label)] = matches\n    label = label.lower()\n\n    if number == \"\":\n        return (float(\"inf\"), label)\n\n    return (float(number), label)\n\n\ndef page_icon_and_name(script_path: Path) -> tuple[str, str]:\n    \"\"\"Compute the icon and name of a page from its script path.\n\n    This is *almost* the page name displayed in the nav UI, but it has\n    underscores instead of spaces. The reason we do this is because having\n    spaces in URLs both looks bad and is hard to deal with due to the need to\n    URL-encode them. To solve this, we only swap the underscores for spaces\n    right before we render page names.\n    \"\"\"\n    extraction = re.search(PAGE_FILENAME_REGEX, script_path.name)\n    if extraction is None:\n        return \"\", \"\"\n\n    # This cast to Any+type annotation weirdness is done because\n    # cast(re.Match[str], ...) explodes at runtime since Python interprets it\n    # as an attempt to index into re.Match instead of as a type annotation.\n    extraction: re.Match[str] = cast(Any, extraction)\n\n    icon_and_name = re.sub(\n        r\"[_ ]+\", \"_\", extraction.group(2)\n    ).strip() or extraction.group(1)\n\n    return extract_leading_emoji(icon_and_name)\n\n\n_pages_cache_lock = threading.RLock()\n_cached_pages: dict[PageHash, PageInfo] | None = None\n_on_pages_changed = Signal(doc=\"Emitted when the pages directory is changed\")\n\n\ndef invalidate_pages_cache() -> None:\n    global _cached_pages\n\n    _LOGGER.debug(\"Pages directory changed\")\n    with _pages_cache_lock:\n        _cached_pages = None\n\n    _on_pages_changed.send()\n\n\ndef get_pages(main_script_path_str: ScriptPath) -> dict[PageHash, PageInfo]:\n    global _cached_pages\n\n    # Avoid taking the lock if the pages cache hasn't been invalidated.\n    precached_pages = _cached_pages\n    if precached_pages is not None:\n        return precached_pages\n\n    with _pages_cache_lock:\n        # The cache may have been repopulated while we were waiting to grab\n        # the lock.\n        if _cached_pages is not None:\n            return _cached_pages\n\n        main_script_path = Path(main_script_path_str)\n        main_page_icon, main_page_name = page_icon_and_name(main_script_path)\n        main_script_hash = calc_md5(main_script_path_str)\n\n        # NOTE: We include the script_hash in the dict even though it is\n        #       already used as the key because that occasionally makes things\n        #       easier for us when we need to iterate over pages.\n        pages: dict[PageHash, PageInfo] = {\n            main_script_hash: {\n                \"page_script_hash\": main_script_hash,\n                \"page_name\": main_page_name,\n                \"icon\": main_page_icon,\n                \"script_path\": str(main_script_path.resolve()),\n            }\n        }\n\n        pages_dir = main_script_path.parent / \"pages\"\n        page_scripts = sorted(\n            [\n                f\n                for f in pages_dir.glob(\"*.py\")\n                if not f.name.startswith(\".\") and not f.name == \"__init__.py\"\n            ],\n            key=page_sort_key,\n        )\n\n        for script_path in page_scripts:\n            script_path_str = str(script_path.resolve())\n            pi, pn = page_icon_and_name(script_path)\n            psh = calc_md5(script_path_str)\n\n            pages[psh] = {\n                \"page_script_hash\": psh,\n                \"page_name\": pn,\n                \"icon\": pi,\n                \"script_path\": script_path_str,\n            }\n\n        _cached_pages = pages\n\n        return pages\n\n\ndef register_pages_changed_callback(\n    callback: Callable[[str], None],\n) -> Callable[[], None]:\n    def disconnect():\n        _on_pages_changed.disconnect(callback)\n\n    # weak=False so that we have control of when the pages changed\n    # callback is deregistered.\n    _on_pages_changed.connect(callback, weak=False)\n\n    return disconnect\n", "lib/streamlit/user_info.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom typing import TYPE_CHECKING, Iterator, Mapping, NoReturn, Union\n\nfrom streamlit.errors import StreamlitAPIException\nfrom streamlit.runtime.scriptrunner import get_script_run_ctx as _get_script_run_ctx\n\nif TYPE_CHECKING:\n    from streamlit.runtime.scriptrunner.script_run_context import UserInfo\n\n\ndef _get_user_info() -> UserInfo:\n    ctx = _get_script_run_ctx()\n    if ctx is None:\n        # TODO: Add appropriate warnings when ctx is missing\n        return {}\n    return ctx.user_info\n\n\nclass UserInfoProxy(Mapping[str, Union[str, None]]):\n    \"\"\"\n    A read-only, dict-like object for accessing information about current user.\n\n    ``st.experimental_user`` is dependant on the host platform running the\n    Streamlit app. If the host platform has not configured the function, it\n    will behave as it does in a locally running app.\n\n    Properties can by accessed via key or attribute notation. For example,\n    ``st.experimental_user[\"email\"]`` or ``st.experimental_user.email``.\n\n    Attributes\n    ----------\n    email : str\n        If running locally, this property returns the string literal\n        ``\"test@example.com\"``.\n\n        If running on Streamlit Community Cloud, this\n        property returns one of two values:\n\n        * ``None`` if the user is not logged in or not a member of the app's\\\n        workspace. Such users appear under anonymous pseudonyms in the app's\\\n        analytics.\n        * The user's email if the the user is logged in and a member of the\\\n        app's workspace. Such users are identified by their email in the app's\\\n        analytics.\n\n    \"\"\"\n\n    def __getitem__(self, key: str) -> str | None:\n        return _get_user_info()[key]\n\n    def __getattr__(self, key: str) -> str | None:\n        try:\n            return _get_user_info()[key]\n        except KeyError:\n            raise AttributeError\n\n    def __setattr__(self, name: str, value: str | None) -> NoReturn:\n        raise StreamlitAPIException(\"st.experimental_user cannot be modified\")\n\n    def __setitem__(self, name: str, value: str | None) -> NoReturn:\n        raise StreamlitAPIException(\"st.experimental_user cannot be modified\")\n\n    def __iter__(self) -> Iterator[str]:\n        return iter(_get_user_info())\n\n    def __len__(self) -> int:\n        return len(_get_user_info())\n\n    def to_dict(self) -> UserInfo:\n        \"\"\"\n        Get user info as a dictionary.\n\n        This method primarily exists for internal use and is not needed for\n        most cases. ``st.experimental_user`` returns an object that inherits from\n        ``dict`` by default.\n\n        Returns\n        -------\n        Dict[str,str]\n            A dictionary of the current user's information.\n        \"\"\"\n        return _get_user_info()\n", "lib/streamlit/url_util.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport re\nfrom typing import Final, Literal\nfrom urllib.parse import urlparse\n\nfrom typing_extensions import TypeAlias\n\nUrlSchema: TypeAlias = Literal[\"http\", \"https\", \"mailto\", \"data\"]\n\n\n# Regular expression for process_gitblob_url\n_GITBLOB_RE: Final = re.compile(\n    r\"(?P<base>https:\\/\\/?(gist\\.)?github.com\\/)\"\n    r\"(?P<account>([\\w\\.]+\\/){1,2})\"\n    r\"(?P<blob_or_raw>(blob|raw))?\"\n    r\"(?P<suffix>(.+)?)\"\n)\n\n\ndef process_gitblob_url(url: str) -> str:\n    \"\"\"Check url to see if it describes a GitHub Gist \"blob\" URL.\n\n    If so, returns a new URL to get the \"raw\" script.\n    If not, returns URL unchanged.\n    \"\"\"\n    # Matches github.com and gist.github.com.  Will not match githubusercontent.com.\n    # See this regex with explainer and sample text here: https://regexr.com/4odk3\n    match = _GITBLOB_RE.match(url)\n    if match:\n        mdict = match.groupdict()\n        # If it has \"blob\" in the url, replace this with \"raw\" and we're done.\n        if mdict[\"blob_or_raw\"] == \"blob\":\n            return \"{base}{account}raw{suffix}\".format(**mdict)\n\n        # If it is a \"raw\" url already, return untouched.\n        if mdict[\"blob_or_raw\"] == \"raw\":\n            return url\n\n        # It's a gist. Just tack \"raw\" on the end.\n        return url + \"/raw\"\n\n    return url\n\n\ndef get_hostname(url: str) -> str | None:\n    \"\"\"Return the hostname of a URL (with or without protocol).\"\"\"\n    # Just so urllib can parse the URL, make sure there's a protocol.\n    # (The actual protocol doesn't matter to us)\n    if \"://\" not in url:\n        url = f\"http://{url}\"\n\n    parsed = urlparse(url)\n    return parsed.hostname\n\n\ndef is_url(\n    url: str,\n    allowed_schemas: tuple[UrlSchema, ...] = (\"http\", \"https\"),\n) -> bool:\n    \"\"\"Check if a string looks like an URL.\n\n    This doesn't check if the URL is actually valid or reachable.\n\n    Parameters\n    ----------\n    url : str\n        The URL to check.\n\n    allowed_schemas : Tuple[str]\n        The allowed URL schemas. Default is (\"http\", \"https\").\n    \"\"\"\n    try:\n        result = urlparse(str(url))\n        if result.scheme not in allowed_schemas:\n            return False\n\n        if result.scheme in [\"http\", \"https\"]:\n            return bool(result.netloc)\n        elif result.scheme in [\"mailto\", \"data\"]:\n            return bool(result.path)\n\n    except ValueError:\n        return False\n    return False\n", "lib/streamlit/net_util.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom typing import Final\n\nfrom streamlit import util\nfrom streamlit.logger import get_logger\n\n_LOGGER: Final = get_logger(__name__)\n\n# URLs for checking the current machine's external IP address.\n_AWS_CHECK_IP: Final = \"http://checkip.amazonaws.com\"\n_AWS_CHECK_IP_HTTPS: Final = \"https://checkip.amazonaws.com\"\n\n_external_ip: str | None = None\n_internal_ip: str | None = None\n\n\ndef get_external_ip() -> str | None:\n    \"\"\"Get the *external* IP address of the current machine.\n\n    Returns\n    -------\n    string\n        The external IPv4 address of the current machine.\n\n    \"\"\"\n    global _external_ip\n\n    if _external_ip is not None:\n        return _external_ip\n\n    response = _make_blocking_http_get(_AWS_CHECK_IP, timeout=5)\n\n    if response is None:\n        response = _make_blocking_http_get(_AWS_CHECK_IP_HTTPS, timeout=5)\n\n    if _looks_like_an_ip_adress(response):\n        _external_ip = response\n    else:\n        _LOGGER.warning(\n            \"Did not auto detect external IP.\\nPlease go to %s for debugging hints.\",\n            util.HELP_DOC,\n        )\n        _external_ip = None\n\n    return _external_ip\n\n\ndef get_internal_ip() -> str | None:\n    \"\"\"Get the *local* IP address of the current machine.\n\n    From: https://stackoverflow.com/a/28950776\n\n    Returns\n    -------\n    string\n        The local IPv4 address of the current machine.\n\n    \"\"\"\n    global _internal_ip\n\n    if _internal_ip is not None:\n        return _internal_ip\n\n    import socket\n\n    with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as s:\n        try:\n            # Doesn't even have to be reachable\n            s.connect((\"8.8.8.8\", 1))\n            _internal_ip = s.getsockname()[0]\n        except Exception:\n            _internal_ip = \"127.0.0.1\"\n\n    return _internal_ip\n\n\ndef _make_blocking_http_get(url: str, timeout: float = 5) -> str | None:\n    import requests\n\n    try:\n        text = requests.get(url, timeout=timeout).text\n        if isinstance(text, str):\n            text = text.strip()\n        return text\n    except Exception:\n        return None\n\n\ndef _looks_like_an_ip_adress(address: str | None) -> bool:\n    if address is None:\n        return False\n\n    import socket\n\n    try:\n        socket.inet_pton(socket.AF_INET, address)\n        return True  # Yup, this is an IPv4 address!\n    except (AttributeError, OSError):\n        pass\n\n    try:\n        socket.inet_pton(socket.AF_INET6, address)\n        return True  # Yup, this is an IPv6 address!\n    except (AttributeError, OSError):\n        pass\n\n    # Nope, this is not an IP address.\n    return False\n", "lib/streamlit/error_util.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom typing import Final\n\nimport streamlit as st\nfrom streamlit import config\nfrom streamlit.errors import UncaughtAppException\nfrom streamlit.logger import get_logger\n\n_LOGGER: Final = get_logger(__name__)\n\n\ndef _print_rich_exception(e: BaseException) -> None:\n    from rich import box, panel\n\n    # Monkey patch the panel to use our custom box style\n    class ConfigurablePanel(panel.Panel):\n        def __init__(\n            self,\n            renderable,\n            box=box.Box(\"\u2500\u2500\u2500\u2500\\n    \\n\u2500\u2500\u2500\u2500\\n    \\n\u2500\u2500\u2500\u2500\\n\u2500\u2500\u2500\u2500\\n    \\n\u2500\u2500\u2500\u2500\\n\"),\n            **kwargs,\n        ):\n            super().__init__(renderable, box, **kwargs)\n\n    from rich import traceback as rich_traceback\n\n    rich_traceback.Panel = ConfigurablePanel  # type: ignore\n\n    # Configure console\n    from rich.console import Console\n\n    console = Console(\n        color_system=\"256\",\n        force_terminal=True,\n        width=88,\n        no_color=False,\n        tab_size=8,\n    )\n\n    # Import script_runner here to prevent circular import\n    import streamlit.runtime.scriptrunner.script_runner as script_runner\n\n    # Print exception via rich\n    console.print(\n        rich_traceback.Traceback.from_exception(\n            type(e),\n            e,\n            e.__traceback__,\n            width=88,\n            show_locals=False,\n            max_frames=100,\n            word_wrap=False,\n            extra_lines=3,\n            suppress=[script_runner],  # Ignore script runner\n        )\n    )\n\n\ndef handle_uncaught_app_exception(ex: BaseException) -> None:\n    \"\"\"Handle an exception that originated from a user app.\n\n    By default, we show exceptions directly in the browser. However,\n    if the user has disabled client error details, we display a generic\n    warning in the frontend instead.\n    \"\"\"\n    error_logged = False\n\n    if config.get_option(\"logger.enableRich\"):\n        try:\n            # Print exception via rich\n            # Rich is only a soft dependency\n            # -> if not installed, we will use the default traceback formatting\n            _print_rich_exception(ex)\n            error_logged = True\n        except Exception:\n            # Rich is not installed or not compatible to our config\n            # -> Use normal traceback formatting as fallback\n            # Catching all exceptions because we don't want to leave any possibility of breaking here.\n            error_logged = False\n\n    if config.get_option(\"client.showErrorDetails\"):\n        if not error_logged:\n            # TODO: Clean up the stack trace, so it doesn't include ScriptRunner.\n            _LOGGER.warning(\"Uncaught app exception\", exc_info=ex)\n        st.exception(ex)\n    else:\n        if not error_logged:\n            # Use LOGGER.error, rather than LOGGER.debug, since we don't\n            # show debug logs by default.\n            _LOGGER.error(\"Uncaught app exception\", exc_info=ex)\n        st.exception(UncaughtAppException(ex))\n", "lib/streamlit/platform.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Platform module.\"\"\"\n\nfrom __future__ import annotations\n\nfrom streamlit.proto.ForwardMsg_pb2 import ForwardMsg\nfrom streamlit.runtime.scriptrunner import get_script_run_ctx\n\n\ndef post_parent_message(message: str) -> None:\n    \"\"\"\n    Sends a string message to the parent window (when host configuration allows).\n    \"\"\"\n    ctx = get_script_run_ctx()\n    if ctx is None:\n        return\n\n    fwd_msg = ForwardMsg()\n    fwd_msg.parent_message.message = message\n    ctx.enqueue(fwd_msg)\n", "lib/streamlit/js_number.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport numbers\n\n\nclass JSNumberBoundsException(Exception):\n    pass\n\n\nclass JSNumber:\n    \"\"\"Utility class for exposing JavaScript Number constants.\"\"\"\n\n    # The largest int that can be represented with perfect precision\n    # in JavaScript.\n    MAX_SAFE_INTEGER = (1 << 53) - 1\n\n    # The smallest int that can be represented with perfect precision\n    # in JavaScript.\n    MIN_SAFE_INTEGER = -((1 << 53) - 1)\n\n    # The largest float that can be represented in JavaScript.\n    MAX_VALUE = 1.7976931348623157e308\n\n    # The closest number to zero that can be represented in JavaScript.\n    MIN_VALUE = 5e-324\n\n    # The largest negative float that can be represented in JavaScript.\n    MIN_NEGATIVE_VALUE = -MAX_VALUE\n\n    @classmethod\n    def validate_int_bounds(cls, value: int, value_name: str | None = None) -> None:\n        \"\"\"Validate that an int value can be represented with perfect precision\n        by a JavaScript Number.\n\n        Parameters\n        ----------\n        value : int\n        value_name : str or None\n            The name of the value parameter. If specified, this will be used\n            in any exception that is thrown.\n\n        Raises\n        ------\n        JSNumberBoundsException\n            Raised with a human-readable explanation if the value falls outside\n            JavaScript int bounds.\n\n        \"\"\"\n        if value_name is None:\n            value_name = \"value\"\n\n        if value < cls.MIN_SAFE_INTEGER:\n            raise JSNumberBoundsException(\n                f\"{value_name} ({value}) must be >= -((1 << 53) - 1)\"\n            )\n        elif value > cls.MAX_SAFE_INTEGER:\n            raise JSNumberBoundsException(\n                f\"{value_name} ({value}) must be <= (1 << 53) - 1\"\n            )\n\n    @classmethod\n    def validate_float_bounds(cls, value: int | float, value_name: str | None) -> None:\n        \"\"\"Validate that a float value can be represented by a JavaScript Number.\n\n        Parameters\n        ----------\n        value : float\n        value_name : str or None\n            The name of the value parameter. If specified, this will be used\n            in any exception that is thrown.\n\n        Raises\n        ------\n        JSNumberBoundsException\n            Raised with a human-readable explanation if the value falls outside\n            JavaScript float bounds.\n\n        \"\"\"\n        if value_name is None:\n            value_name = \"value\"\n\n        if not isinstance(value, (numbers.Integral, float)):\n            raise JSNumberBoundsException(f\"{value_name} ({value}) is not a float\")\n        elif value < cls.MIN_NEGATIVE_VALUE:\n            raise JSNumberBoundsException(\n                f\"{value_name} ({value}) must be >= -1.797e+308\"\n            )\n        elif value > cls.MAX_VALUE:\n            raise JSNumberBoundsException(\n                f\"{value_name} ({value}) must be <= 1.797e+308\"\n            )\n", "lib/streamlit/deprecation_util.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport functools\nfrom typing import Any, Callable, Final, TypeVar, cast\n\nimport streamlit\nfrom streamlit import config\nfrom streamlit.logger import get_logger\n\n_LOGGER: Final = get_logger(__name__)\n\nTFunc = TypeVar(\"TFunc\", bound=Callable[..., Any])\nTObj = TypeVar(\"TObj\", bound=object)\n\n\ndef _should_show_deprecation_warning_in_browser() -> bool:\n    \"\"\"True if we should print deprecation warnings to the browser.\"\"\"\n    return bool(config.get_option(\"client.showErrorDetails\"))\n\n\ndef show_deprecation_warning(message: str) -> None:\n    \"\"\"Show a deprecation warning message.\"\"\"\n    if _should_show_deprecation_warning_in_browser():\n        streamlit.warning(message)\n\n    # We always log deprecation warnings\n    _LOGGER.warning(message)\n\n\ndef make_deprecated_name_warning(\n    old_name: str,\n    new_name: str,\n    removal_date: str,\n    extra_message: str | None = None,\n    include_st_prefix: bool = True,\n) -> str:\n    if include_st_prefix:\n        old_name = f\"st.{old_name}\"\n        new_name = f\"st.{new_name}\"\n\n    return (\n        f\"Please replace `{old_name}` with `{new_name}`.\\n\\n\"\n        f\"`{old_name}` will be removed after {removal_date}.\"\n        + (f\"\\n\\n{extra_message}\" if extra_message else \"\")\n    )\n\n\ndef deprecate_func_name(\n    func: TFunc,\n    old_name: str,\n    removal_date: str,\n    extra_message: str | None = None,\n    name_override: str | None = None,\n) -> TFunc:\n    \"\"\"Wrap an `st` function whose name has changed.\n\n    Wrapped functions will run as normal, but will also show an st.warning\n    saying that the old name will be removed after removal_date.\n\n    (We generally set `removal_date` to 3 months from the deprecation date.)\n\n    Parameters\n    ----------\n    func\n        The `st.` function whose name has changed.\n\n    old_name\n        The function's deprecated name within __init__.py.\n\n    removal_date\n        A date like \"2020-01-01\", indicating the last day we'll guarantee\n        support for the deprecated name.\n\n    extra_message\n        An optional extra message to show in the deprecation warning.\n\n    name_override\n        An optional name to use in place of func.__name__.\n    \"\"\"\n\n    @functools.wraps(func)\n    def wrapped_func(*args, **kwargs):\n        result = func(*args, **kwargs)\n        show_deprecation_warning(\n            make_deprecated_name_warning(\n                old_name, name_override or func.__name__, removal_date, extra_message\n            )\n        )\n        return result\n\n    # Update the wrapped func's name & docstring so st.help does the right thing\n    wrapped_func.__name__ = old_name\n    wrapped_func.__doc__ = func.__doc__\n    return cast(TFunc, wrapped_func)\n\n\ndef deprecate_obj_name(\n    obj: TObj,\n    old_name: str,\n    new_name: str,\n    removal_date: str,\n    include_st_prefix: bool = True,\n) -> TObj:\n    \"\"\"Wrap an `st` object whose name has changed.\n\n    Wrapped objects will behave as normal, but will also show an st.warning\n    saying that the old name will be removed after `removal_date`.\n\n    (We generally set `removal_date` to 3 months from the deprecation date.)\n\n    Parameters\n    ----------\n    obj\n        The `st.` object whose name has changed.\n\n    old_name\n        The object's deprecated name within __init__.py.\n\n    new_name\n        The object's new name within __init__.py.\n\n    removal_date\n        A date like \"2020-01-01\", indicating the last day we'll guarantee\n        support for the deprecated name.\n\n    include_st_prefix\n        If False, does not prefix each of the object names in the deprecation\n        essage with `st.*`. Defaults to True.\n    \"\"\"\n\n    return _create_deprecated_obj_wrapper(\n        obj,\n        lambda: show_deprecation_warning(\n            make_deprecated_name_warning(\n                old_name, new_name, removal_date, include_st_prefix=include_st_prefix\n            )\n        ),\n    )\n\n\ndef _create_deprecated_obj_wrapper(obj: TObj, show_warning: Callable[[], Any]) -> TObj:\n    \"\"\"Create a wrapper for an object that has been deprecated. The first\n    time one of the object's properties or functions is accessed, the\n    given `show_warning` callback will be called.\n    \"\"\"\n    has_shown_warning = False\n\n    def maybe_show_warning() -> None:\n        # Call `show_warning` if it hasn't already been called once.\n        nonlocal has_shown_warning\n        if not has_shown_warning:\n            has_shown_warning = True\n            show_warning()\n\n    class Wrapper:\n        def __init__(self):\n            # Override all the Wrapped object's magic functions\n            for name in Wrapper._get_magic_functions(obj.__class__):\n                setattr(\n                    self.__class__,\n                    name,\n                    property(self._make_magic_function_proxy(name)),\n                )\n\n        def __getattr__(self, attr):\n            # We handle __getattr__ separately from our other magic\n            # functions. The wrapped class may not actually implement it,\n            # but we still need to implement it to call all its normal\n            # functions.\n            if attr in self.__dict__:\n                return getattr(self, attr)\n\n            maybe_show_warning()\n            return getattr(obj, attr)\n\n        @staticmethod\n        def _get_magic_functions(cls) -> list[str]:\n            # ignore the handful of magic functions we cannot override without\n            # breaking the Wrapper.\n            ignore = (\"__class__\", \"__dict__\", \"__getattribute__\", \"__getattr__\")\n            return [\n                name\n                for name in dir(cls)\n                if name not in ignore and name.startswith(\"__\")\n            ]\n\n        @staticmethod\n        def _make_magic_function_proxy(name):\n            def proxy(self, *args):\n                maybe_show_warning()\n                return getattr(obj, name)\n\n            return proxy\n\n    return cast(TObj, Wrapper())\n", "lib/streamlit/config.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Loads the configuration data.\"\"\"\n\nfrom __future__ import annotations\n\nimport copy\nimport os\nimport secrets\nimport threading\nfrom collections import OrderedDict\nfrom typing import Any, Callable\n\nfrom blinker import Signal\n\nfrom streamlit import config_util, development, env_util, file_util, util\nfrom streamlit.config_option import ConfigOption\nfrom streamlit.errors import StreamlitAPIException\n\n# Config System Global State #\n\n# Descriptions of each of the possible config sections.\n# (We use OrderedDict to make the order in which sections are declared in this\n# file be the same order as the sections appear with `streamlit config show`)\n_section_descriptions: dict[str, str] = OrderedDict(\n    _test=\"Special test section just used for unit tests.\"\n)\n\n# Ensures that we don't try to get or set config options when config.toml files\n# change so are re-parsed.\n_config_lock = threading.RLock()\n\n# Stores config options with their default values (or None if they don't have\n# a default) before they are updated with values from config.toml files, flags\n# to `streamlit run`, etc. Note that this and _config_options below are\n# OrderedDicts to ensure stable ordering when printed using\n# `streamlit config show`.\n_config_options_template: dict[str, ConfigOption] = OrderedDict()\n\n# Stores the current state of config options.\n_config_options: dict[str, ConfigOption] | None = None\n\n\n# Indicates that a config option was defined by the user.\n_USER_DEFINED = \"<user defined>\"\n\n# Indicates that a config option was defined either in an environment variable\n# or via command-line flag.\n_DEFINED_BY_FLAG = \"command-line argument or environment variable\"\n\n# Indicates that a config option was defined in an environment variable\n_DEFINED_BY_ENV_VAR = \"environment variable\"\n\n\ndef set_option(key: str, value: Any, where_defined: str = _USER_DEFINED) -> None:\n    \"\"\"Set config option.\n\n    Run `streamlit config show` in the terminal to see all available options.\n\n    This is an internal API. The public `st.set_option` API is implemented\n    in `set_user_option`.\n\n    Parameters\n    ----------\n    key : str\n        The config option key of the form \"section.optionName\". To see all\n        available options, run `streamlit config show` on a terminal.\n\n    value\n        The new value to assign to this config option.\n\n    where_defined : str\n        Tells the config system where this was set.\n    \"\"\"\n    with _config_lock:\n        # Ensure that our config files have been parsed.\n        get_config_options()\n        _set_option(key, value, where_defined)\n\n\ndef set_user_option(key: str, value: Any) -> None:\n    \"\"\"Set config option.\n\n    Currently, only the following config options can be set within the script itself:\n        * client.caching\n        * client.displayEnabled\n        * deprecation.*\n\n    Calling with any other options will raise StreamlitAPIException.\n\n    Run `streamlit config show` in the terminal to see all available options.\n\n    Parameters\n    ----------\n    key : str\n        The config option key of the form \"section.optionName\". To see all\n        available options, run `streamlit config show` on a terminal.\n\n    value\n        The new value to assign to this config option.\n\n    \"\"\"\n    try:\n        opt = _config_options_template[key]\n    except KeyError as ke:\n        raise StreamlitAPIException(f\"Unrecognized config option: {key}\") from ke\n    if opt.scriptable:\n        set_option(key, value)\n        return\n\n    raise StreamlitAPIException(\n        f\"{key} cannot be set on the fly. Set as command line option, e.g. streamlit run script.py --{key}, or in config.toml instead.\"\n    )\n\n\ndef get_option(key: str) -> Any:\n    \"\"\"Return the current value of a given Streamlit config option.\n\n    Run `streamlit config show` in the terminal to see all available options.\n\n    Parameters\n    ----------\n    key : str\n        The config option key of the form \"section.optionName\". To see all\n        available options, run `streamlit config show` on a terminal.\n    \"\"\"\n    with _config_lock:\n        config_options = get_config_options()\n\n        if key not in config_options:\n            raise RuntimeError(f'Config key \"{key}\" not defined.')\n        return config_options[key].value\n\n\ndef get_options_for_section(section: str) -> dict[str, Any]:\n    \"\"\"Get all of the config options for the given section.\n\n    Run `streamlit config show` in the terminal to see all available options.\n\n    Parameters\n    ----------\n    section : str\n        The name of the config section to fetch options for.\n\n    Returns\n    -------\n    dict[str, Any]\n        A dict mapping the names of the options in the given section (without\n        the section name as a prefix) to their values.\n    \"\"\"\n    with _config_lock:\n        config_options = get_config_options()\n\n        options_for_section = {}\n        for option in config_options.values():\n            if option.section == section:\n                options_for_section[option.name] = option.value\n        return options_for_section\n\n\ndef _create_section(section: str, description: str) -> None:\n    \"\"\"Create a config section and store it globally in this module.\"\"\"\n    assert (\n        section not in _section_descriptions\n    ), f'Cannot define section \"{section}\" twice.'\n    _section_descriptions[section] = description\n\n\ndef _create_option(\n    key: str,\n    description: str | None = None,\n    default_val: Any | None = None,\n    scriptable: bool = False,\n    visibility: str = \"visible\",\n    deprecated: bool = False,\n    deprecation_text: str | None = None,\n    expiration_date: str | None = None,\n    replaced_by: str | None = None,\n    type_: type = str,\n    sensitive: bool = False,\n) -> ConfigOption:\n    '''Create a ConfigOption and store it globally in this module.\n\n    There are two ways to create a ConfigOption:\n\n        (1) Simple, constant config options are created as follows:\n\n            _create_option('section.optionName',\n                description = 'Put the description here.',\n                default_val = 12345)\n\n        (2) More complex, programmable config options use decorator syntax to\n        resolve their values at runtime:\n\n            @_create_option('section.optionName')\n            def _section_option_name():\n                \"\"\"Put the description here.\"\"\"\n                return 12345\n\n    To achieve this sugar, _create_option() returns a *callable object* of type\n    ConfigObject, which then decorates the function.\n\n    NOTE: ConfigObjects call their evaluation functions *every time* the option\n    is requested. To prevent this, use the `streamlit.util.memoize` decorator as\n    follows:\n\n            @_create_option('section.memoizedOptionName')\n            @util.memoize\n            def _section_memoized_option_name():\n                \"\"\"Put the description here.\"\"\"\n\n                (This function is only called once.)\n                \"\"\"\n                return 12345\n\n    '''\n    option = ConfigOption(\n        key,\n        description=description,\n        default_val=default_val,\n        scriptable=scriptable,\n        visibility=visibility,\n        deprecated=deprecated,\n        deprecation_text=deprecation_text,\n        expiration_date=expiration_date,\n        replaced_by=replaced_by,\n        type_=type_,\n        sensitive=sensitive,\n    )\n    assert (\n        option.section in _section_descriptions\n    ), 'Section \"{}\" must be one of {}.'.format(\n        option.section,\n        \", \".join(_section_descriptions.keys()),\n    )\n    assert key not in _config_options_template, f'Cannot define option \"{key}\" twice.'\n    _config_options_template[key] = option\n    return option\n\n\ndef _delete_option(key: str) -> None:\n    \"\"\"Remove a ConfigOption by key from the global store.\n\n    Only for use in testing.\n    \"\"\"\n    try:\n        del _config_options_template[key]\n        assert (\n            _config_options is not None\n        ), \"_config_options should always be populated here.\"\n        del _config_options[key]\n    except Exception:\n        # We don't care if the option already doesn't exist.\n        pass\n\n\n# Config Section: Global #\n\n_create_section(\"global\", \"Global options that apply across all of Streamlit.\")\n\n_create_option(\n    \"global.disableWatchdogWarning\",\n    description=\"\"\"\n        By default, Streamlit checks if the Python watchdog module is available\n        and, if not, prints a warning asking for you to install it. The watchdog\n        module is not required, but highly recommended. It improves Streamlit's\n        ability to detect changes to files in your filesystem.\n\n        If you'd like to turn off this warning, set this to True.\n        \"\"\",\n    default_val=False,\n    type_=bool,\n    deprecated=True,\n    deprecation_text=\"global.disableWatchdogWarning has been deprecated and will be removed in a future version.\",\n    expiration_date=\"2024-01-20\",\n)\n\n\n_create_option(\n    \"global.disableWidgetStateDuplicationWarning\",\n    description=\"\"\"\n        By default, Streamlit displays a warning when a user sets both a widget\n        default value in the function defining the widget and a widget value via\n        the widget's key in `st.session_state`.\n\n        If you'd like to turn off this warning, set this to True.\n        \"\"\",\n    default_val=False,\n    type_=bool,\n)\n\n\n_create_option(\n    \"global.showWarningOnDirectExecution\",\n    description=\"\"\"\n        If True, will show a warning when you run a Streamlit-enabled script\n        via \"python my_script.py\".\n        \"\"\",\n    default_val=True,\n    type_=bool,\n)\n\n\n@_create_option(\"global.developmentMode\", visibility=\"hidden\", type_=bool)\ndef _global_development_mode() -> bool:\n    \"\"\"Are we in development mode.\n\n    This option defaults to True if and only if Streamlit wasn't installed\n    normally.\n    \"\"\"\n    return (\n        not env_util.is_pex()\n        and \"site-packages\" not in __file__\n        and \"dist-packages\" not in __file__\n        and \"__pypackages__\" not in __file__\n    )\n\n\n_create_option(\n    \"global.logLevel\",\n    description=\"\"\"Level of logging: 'error', 'warning', 'info', or 'debug'.\n\n    Default: 'info'\n    \"\"\",\n    deprecated=True,\n    deprecation_text=\"global.logLevel has been replaced with logger.level\",\n    expiration_date=\"2020-11-30\",\n    replaced_by=\"logger.level\",\n)\n\n_create_option(\n    \"global.e2eTest\",\n    description=\"Are we in an e2e (playwright) test? Set automatically when our e2e tests are running.\",\n    visibility=\"hidden\",\n    default_val=False,\n    type_=bool,\n)\n\n_create_option(\n    \"global.unitTest\",\n    description=\"Are we in a unit test?\",\n    visibility=\"hidden\",\n    default_val=False,\n    type_=bool,\n)\n\n_create_option(\n    \"global.appTest\",\n    description=\"Are we in an app test? Set automatically when the AppTest framework is running\",\n    visibility=\"hidden\",\n    default_val=False,\n    type_=bool,\n)\n\n_create_option(\n    \"global.suppressDeprecationWarnings\",\n    description=\"Hide deprecation warnings in the streamlit app.\",\n    visibility=\"hidden\",\n    default_val=False,\n    type_=bool,\n)\n\n_create_option(\n    \"global.minCachedMessageSize\",\n    description=\"\"\"Only cache ForwardMsgs that are greater than or equal to\n        this minimum.\"\"\",\n    visibility=\"hidden\",\n    default_val=10 * 1e3,\n    type_=float,\n)  # 10k\n\n_create_option(\n    \"global.maxCachedMessageAge\",\n    description=\"\"\"Expire cached ForwardMsgs whose age is greater than this\n        value. A message's age is defined by how many times its script has\n        finished running since the message has been accessed.\"\"\",\n    visibility=\"hidden\",\n    default_val=2,\n    type_=int,\n)\n\n_create_option(\n    \"global.storeCachedForwardMessagesInMemory\",\n    description=\"\"\"If True, store cached ForwardMsgs in backend memory.\n        This is an internal flag to validate a potential removal of the in-memory\n        forward message cache.\"\"\",\n    visibility=\"hidden\",\n    default_val=True,\n    type_=bool,\n)\n\n_create_option(\n    \"global.dataFrameSerialization\",\n    description=\"\"\"\n        DataFrame serialization.\n\n        Acceptable values:\n        - 'legacy': Serialize DataFrames using Streamlit's custom format. Slow\n          but battle-tested.\n        - 'arrow': Serialize DataFrames using Apache Arrow. Much faster and versatile.\"\"\",\n    default_val=\"arrow\",\n    type_=str,\n    deprecated=True,\n    deprecation_text=\"Legacy serialization has been removed. All dataframes will be serialized using Apache Arrow.\",\n    expiration_date=\"2023-11-01\",\n)\n\n# Config Section: Logger #\n_create_section(\"logger\", \"Settings to customize Streamlit log messages.\")\n\n\n@_create_option(\"logger.level\", type_=str)\ndef _logger_log_level() -> str:\n    \"\"\"Level of logging: 'error', 'warning', 'info', or 'debug'.\n\n    Default: 'info'\n    \"\"\"\n    if get_option(\"global.logLevel\"):\n        return str(get_option(\"global.logLevel\"))\n    elif get_option(\"global.developmentMode\"):\n        return \"debug\"\n    else:\n        return \"info\"\n\n\n@_create_option(\"logger.messageFormat\", type_=str)\ndef _logger_message_format() -> str:\n    \"\"\"String format for logging messages. If logger.datetimeFormat is set,\n    logger messages will default to `%(asctime)s.%(msecs)03d %(message)s`. See\n    [Python's documentation](https://docs.python.org/2.6/library/logging.html#formatter-objects)\n    for available attributes.\n\n    Default: \"%(asctime)s %(message)s\"\n    \"\"\"\n    if get_option(\"global.developmentMode\"):\n        from streamlit.logger import DEFAULT_LOG_MESSAGE\n\n        return DEFAULT_LOG_MESSAGE\n    else:\n        return \"%(asctime)s %(message)s\"\n\n\n_create_option(\n    \"logger.enableRich\",\n    description=\"\"\"\n        Controls whether uncaught app exceptions are logged via the rich library.\n\n        If True and if rich is installed, exception tracebacks will be logged with syntax highlighting and formatting.\n        Rich tracebacks are easier to read and show more code than standard Python tracebacks.\n\n        If set to False, the default Python traceback formatting will be used.\"\"\",\n    default_val=False,\n    visibility=\"hidden\",\n    type_=bool,\n    scriptable=True,\n)\n\n# Config Section: Client #\n\n_create_section(\"client\", \"Settings for scripts that use Streamlit.\")\n\n_create_option(\n    \"client.displayEnabled\",\n    description=\"\"\"If false, makes your Streamlit script not draw to a\n        Streamlit app.\"\"\",\n    default_val=True,\n    type_=bool,\n    scriptable=True,\n    deprecated=True,\n    deprecation_text=\"client.displayEnabled has been deprecated and will be removed in a future version.\",\n    expiration_date=\"2024-01-20\",\n)\n\n_create_option(\n    \"client.showErrorDetails\",\n    description=\"\"\"\n        Controls whether uncaught app exceptions and deprecation warnings\n        are displayed in the browser. By default, this is set to True and\n        Streamlit displays app exceptions and associated tracebacks, and\n        deprecation warnings, in the browser.\n\n        If set to False, deprecation warnings and full exception messages\n        will print to the console only. Exceptions will still display in the\n        browser with a generic error message. For now, the exception type and\n        traceback show in the browser also, but they will be removed in the\n        future.\"\"\",\n    default_val=True,\n    type_=bool,\n    scriptable=True,\n)\n\n_create_option(\n    \"client.toolbarMode\",\n    description=\"\"\"\n        Change the visibility of items in the toolbar, options menu,\n        and settings dialog (top right of the app).\n\n        Allowed values:\n        * \"auto\"      : Show the developer options if the app is accessed through\n                        localhost or through Streamlit Community Cloud as a developer.\n                        Hide them otherwise.\n        * \"developer\" : Show the developer options.\n        * \"viewer\"    : Hide the developer options.\n        * \"minimal\"   : Show only options set externally (e.g. through\n                        Streamlit Community Cloud) or through st.set_page_config.\n                        If there are no options left, hide the menu.\n\"\"\",\n    default_val=\"auto\",\n    type_=str,\n    scriptable=True,\n)\n\n_create_option(\n    \"client.showSidebarNavigation\",\n    description=\"\"\"Controls whether the default sidebar page navigation in a multi-page app is displayed.\"\"\",\n    default_val=True,\n    type_=bool,\n    scriptable=True,\n)\n\n# Config Section: Runner #\n\n_create_section(\"runner\", \"Settings for how Streamlit executes your script\")\n\n_create_option(\n    \"runner.magicEnabled\",\n    description=\"\"\"\n        Allows you to type a variable or string by itself in a single line of\n        Python code to write it to the app.\n        \"\"\",\n    default_val=True,\n    type_=bool,\n)\n\n_create_option(\n    \"runner.installTracer\",\n    description=\"\"\"\n        Install a Python tracer to allow you to stop or pause your script at\n        any point and introspect it. As a side-effect, this slows down your\n        script's execution.\n        \"\"\",\n    default_val=False,\n    type_=bool,\n    deprecated=True,\n    deprecation_text=\"runner.installTracer has been deprecated and will be removed in a future version.\",\n    expiration_date=\"2024-01-20\",\n)\n\n_create_option(\n    \"runner.fixMatplotlib\",\n    description=\"\"\"\n        Sets the MPLBACKEND environment variable to Agg inside Streamlit to\n        prevent Python crashing.\n        \"\"\",\n    default_val=True,\n    deprecated=True,\n    deprecation_text=\"runner.fixMatplotlib has been deprecated and will be removed in a future version.\",\n    expiration_date=\"2024-01-20\",\n    type_=bool,\n)\n\n_create_option(\n    \"runner.postScriptGC\",\n    description=\"\"\"\n        Run the Python Garbage Collector after each script execution. This\n        can help avoid excess memory use in Streamlit apps, but could\n        introduce delay in rerunning the app script for high-memory-use\n        applications.\n        \"\"\",\n    default_val=True,\n    type_=bool,\n    visibility=\"hidden\",\n)\n\n_create_option(\n    \"runner.fastReruns\",\n    description=\"\"\"\n        Handle script rerun requests immediately, rather than waiting for script\n        execution to reach a yield point. This makes Streamlit much more\n        responsive to user interaction, but it can lead to race conditions in\n        apps that mutate session_state data outside of explicit session_state\n        assignment statements.\n    \"\"\",\n    default_val=True,\n    type_=bool,\n)\n\n_create_option(\n    \"runner.enforceSerializableSessionState\",\n    description=\"\"\"\n        Raise an exception after adding unserializable data to Session State.\n        Some execution environments may require serializing all data in Session\n        State, so it may be useful to detect incompatibility during development,\n        or when the execution environment will stop supporting it in the future.\n    \"\"\",\n    default_val=False,\n    type_=bool,\n)\n\n_create_option(\n    \"runner.enumCoercion\",\n    description=\"\"\"\n        Adjust how certain 'options' widgets like radio, selectbox, and\n        multiselect coerce Enum members when the Enum class gets\n        re-defined during a script re-run.\n\n        Allowed values:\n        * \"off\": Disables Enum coercion.\n        * \"nameOnly\": Enum classes can be coerced if their member names match.\n        * \"nameAndValue\": Enum classes can be coerced if their member names AND\n          member values match.\n    \"\"\",\n    default_val=\"nameOnly\",\n    type_=str,\n)\n\n# Config Section: Server #\n\n_create_section(\"server\", \"Settings for the Streamlit server\")\n\n_create_option(\n    \"server.folderWatchBlacklist\",\n    description=\"\"\"List of folders that should not be watched for changes.\n\n    Relative paths will be taken as relative to the current working directory.\n\n    Example: ['/home/user1/env', 'relative/path/to/folder']\n    \"\"\",\n    default_val=[],\n)\n\n_create_option(\n    \"server.fileWatcherType\",\n    description=\"\"\"\n        Change the type of file watcher used by Streamlit, or turn it off\n        completely.\n\n        Allowed values:\n        * \"auto\"     : Streamlit will attempt to use the watchdog module, and\n                       falls back to polling if watchdog is not available.\n        * \"watchdog\" : Force Streamlit to use the watchdog module.\n        * \"poll\"     : Force Streamlit to always use polling.\n        * \"none\"     : Streamlit will not watch files.\n    \"\"\",\n    default_val=\"auto\",\n    type_=str,\n)\n\n\n@_create_option(\"server.cookieSecret\", type_=str, sensitive=True)\n@util.memoize\ndef _server_cookie_secret() -> str:\n    \"\"\"Symmetric key used to produce signed cookies. If deploying on multiple replicas, this should\n    be set to the same value across all replicas to ensure they all share the same secret.\n\n    Default: randomly generated secret key.\n    \"\"\"\n    return secrets.token_hex()\n\n\n@_create_option(\"server.headless\", type_=bool)\ndef _server_headless() -> bool:\n    \"\"\"If false, will attempt to open a browser window on start.\n\n    Default: false unless (1) we are on a Linux box where DISPLAY is unset, or\n    (2) we are running in the Streamlit Atom plugin.\n    \"\"\"\n    if env_util.IS_LINUX_OR_BSD and not os.getenv(\"DISPLAY\"):\n        # We're running in Linux and DISPLAY is unset\n        return True\n\n    if os.getenv(\"IS_RUNNING_IN_STREAMLIT_EDITOR_PLUGIN\") is not None:\n        # We're running within the Streamlit Atom plugin\n        return True\n\n    return False\n\n\n_create_option(\n    \"server.runOnSave\",\n    description=\"\"\"\n        Automatically rerun script when the file is modified on disk.\n        \"\"\",\n    default_val=False,\n    type_=bool,\n)\n\n_create_option(\n    \"server.allowRunOnSave\",\n    description=\"\"\"\n        Allows users to automatically rerun when app is updated.\n        \"\"\",\n    visibility=\"hidden\",\n    default_val=True,\n    type_=bool,\n)\n\n\n@_create_option(\"server.address\")\ndef _server_address() -> str | None:\n    \"\"\"The address where the server will listen for client and browser\n    connections. Use this if you want to bind the server to a specific address.\n    If set, the server will only be accessible from this address, and not from\n    any aliases (like localhost).\n\n    Default: (unset)\n    \"\"\"\n    return None\n\n\n_create_option(\n    \"server.port\",\n    description=\"\"\"\n        The port where the server will listen for browser connections.\n\n        Don't use port 3000 which is reserved for internal development.\n        \"\"\",\n    default_val=8501,\n    type_=int,\n)\n\n_create_option(\n    \"server.scriptHealthCheckEnabled\",\n    visibility=\"hidden\",\n    description=\"\"\"\n    Flag for enabling the script health check endpoint. It's used for checking if\n    a script loads successfully. On success, the endpoint will return a 200\n    HTTP status code. On failure, the endpoint will return a 503 HTTP status code.\n\n    Note: This is an experimental Streamlit internal API. The API is subject\n    to change anytime so this should be used at your own risk\n    \"\"\",\n    default_val=False,\n    type_=bool,\n)\n\n_create_option(\n    \"server.baseUrlPath\",\n    description=\"\"\"\n        The base path for the URL where Streamlit should be served from.\n        \"\"\",\n    default_val=\"\",\n    type_=str,\n)\n\n# TODO: Rename to server.enableCorsProtection.\n_create_option(\n    \"server.enableCORS\",\n    description=\"\"\"\n    Enables support for Cross-Origin Resource Sharing (CORS) protection, for added security.\n\n    Due to conflicts between CORS and XSRF, if `server.enableXsrfProtection` is on and\n    `server.enableCORS` is off at the same time, we will prioritize `server.enableXsrfProtection`.\n    \"\"\",\n    default_val=True,\n    type_=bool,\n)\n\n\n_create_option(\n    \"server.enableXsrfProtection\",\n    description=\"\"\"\n        Enables support for Cross-Site Request Forgery (XSRF) protection, for added security.\n\n        Due to conflicts between CORS and XSRF, if `server.enableXsrfProtection` is on and\n        `server.enableCORS` is off at the same time, we will prioritize `server.enableXsrfProtection`.\n        \"\"\",\n    default_val=True,\n    type_=bool,\n)\n\n_create_option(\n    \"server.maxUploadSize\",\n    description=\"\"\"\n        Max size, in megabytes, for files uploaded with the file_uploader.\n        \"\"\",\n    default_val=200,  # If this default is changed, please also update the docstring for `DeltaGenerator.file_uploader`.\n    type_=int,\n)\n\n_create_option(\n    \"server.maxMessageSize\",\n    description=\"\"\"\n        Max size, in megabytes, of messages that can be sent via the WebSocket connection.\n        \"\"\",\n    default_val=200,\n    type_=int,\n)\n\n_create_option(\n    \"server.enableArrowTruncation\",\n    description=\"\"\"\n        Enable automatically truncating all data structures that get serialized into Arrow (e.g. DataFrames)\n        to ensure that the size is under `server.maxMessageSize`.\n        \"\"\",\n    visibility=\"hidden\",\n    default_val=False,\n    scriptable=True,\n    type_=bool,\n)\n\n_create_option(\n    \"server.enableWebsocketCompression\",\n    description=\"\"\"\n        Enables support for websocket compression.\n        \"\"\",\n    default_val=False,\n    type_=bool,\n)\n\n_create_option(\n    \"server.enableStaticServing\",\n    description=\"\"\"\n        Enable serving files from a `static` directory in the running app's directory.\n        \"\"\",\n    default_val=False,\n    type_=bool,\n)\n\n# Config Section: Browser #\n\n_create_section(\"browser\", \"Configuration of non-UI browser options.\")\n\n\n_create_option(\n    \"browser.serverAddress\",\n    description=\"\"\"\n        Internet address where users should point their browsers in order to\n        connect to the app. Can be IP address or DNS name and path.\n\n        This is used to:\n        - Set the correct URL for CORS and XSRF protection purposes.\n        - Show the URL on the terminal\n        - Open the browser\n        \"\"\",\n    default_val=\"localhost\",\n    type_=str,\n)\n\n\n_create_option(\n    \"browser.gatherUsageStats\",\n    description=\"\"\"\n        Whether to send usage statistics to Streamlit.\n        \"\"\",\n    default_val=True,\n    type_=bool,\n)\n\n\n@_create_option(\"browser.serverPort\", type_=int)\ndef _browser_server_port() -> int:\n    \"\"\"Port where users should point their browsers in order to connect to the\n    app.\n\n    This is used to:\n    - Set the correct URL for XSRF protection purposes.\n    - Show the URL on the terminal (part of `streamlit run`).\n    - Open the browser automatically (part of `streamlit run`).\n\n    This option is for advanced use cases. To change the port of your app, use\n    `server.Port` instead. Don't use port 3000 which is reserved for internal\n    development.\n\n    Default: whatever value is set in server.port.\n    \"\"\"\n    return int(get_option(\"server.port\"))\n\n\n_SSL_PRODUCTION_WARNING = [\n    \"DO NOT USE THIS OPTION IN A PRODUCTION ENVIRONMENT. It has not gone through \"\n    \"security audits or performance tests. For the production environment, \"\n    \"we recommend performing SSL termination by the load balancer or the reverse proxy.\"\n]\n\n_create_option(\n    \"server.sslCertFile\",\n    description=(\n        f\"\"\"\n        Server certificate file for connecting via HTTPS.\n        Must be set at the same time as \"server.sslKeyFile\".\n\n        {_SSL_PRODUCTION_WARNING}\n        \"\"\"\n    ),\n)\n\n_create_option(\n    \"server.sslKeyFile\",\n    description=(\n        f\"\"\"\n        Cryptographic key file for connecting via HTTPS.\n        Must be set at the same time as \"server.sslCertFile\".\n\n        {_SSL_PRODUCTION_WARNING}\n        \"\"\"\n    ),\n)\n\n# Config Section: UI #\n\n_create_section(\"ui\", \"Configuration of UI elements displayed in the browser.\")\n\n_create_option(\n    \"ui.hideTopBar\",\n    description=\"\"\"\n    Flag to hide most of the UI elements found at the top of a Streamlit app.\n\n    NOTE: This does *not* hide the main menu in the top-right of an app.\n    \"\"\",\n    default_val=False,\n    type_=bool,\n    visibility=\"hidden\",\n)\n\n_create_option(\n    \"ui.hideSidebarNav\",\n    description=\"Flag to hide the sidebar page navigation component.\",\n    default_val=False,\n    type_=bool,\n    deprecated=True,\n    deprecation_text=\"ui.hideSidebarNav has been deprecated and replaced with client.showSidebarNavigation. It will be removed in a future version.\",\n    expiration_date=\"2024-01-20\",\n    visibility=\"hidden\",\n)\n\n\n# Config Section: Mapbox #\n\n_create_section(\"mapbox\", \"Mapbox configuration that is being used by DeckGL.\")\n\n_create_option(\n    \"mapbox.token\",\n    description=\"\"\"Configure Streamlit to use a custom Mapbox\n                token for elements like st.pydeck_chart and st.map.\n                To get a token for yourself, create an account at\n                https://mapbox.com. It's free (for moderate usage levels)!\"\"\",\n    default_val=\"\",\n    sensitive=True,\n)\n\n\n# Config Section: Magic #\n\n_create_section(\"magic\", \"Settings for how Streamlit pre-processes your script\")\n\n_create_option(\n    \"magic.displayRootDocString\",\n    description=\"\"\"\n        Streamlit's \"magic\" parser typically skips strings that appear to be\n        docstrings. When this flag is set to True, Streamlit will instead display\n        the root-level docstring in the app, just like any other magic string.\n        This is useful for things like notebooks.\n        \"\"\",\n    visibility=\"hidden\",\n    default_val=False,\n    type_=bool,\n)\n\n_create_option(\n    \"magic.displayLastExprIfNoSemicolon\",\n    description=\"\"\"\n        Make Streamlit's \"magic\" parser always display the last expression in the\n        root file if it has no semicolon at the end. This matches the behavior of\n        Jupyter notebooks, for example.\n        \"\"\",\n    visibility=\"hidden\",\n    default_val=False,\n    type_=bool,\n)\n\n\n# Config Section: deprecations\n\n_create_section(\"deprecation\", \"Configuration to show or hide deprecation warnings.\")\n\n_create_option(\n    \"deprecation.showfileUploaderEncoding\",\n    description=\"Set to false to disable the deprecation warning for the file uploader encoding.\",\n    default_val=True,\n    scriptable=True,\n    type_=bool,\n    deprecated=True,\n    deprecation_text=\"deprecation.showfileUploaderEncoding has been deprecated and will be removed in a future version.\",\n    expiration_date=\"2021-01-06\",\n)\n\n_create_option(\n    \"deprecation.showImageFormat\",\n    description=\"Set to false to disable the deprecation warning for the image format parameter.\",\n    default_val=True,\n    scriptable=True,\n    type_=bool,\n    deprecated=True,\n    deprecation_text=\"The format parameter for st.image has been removed.\",\n    expiration_date=\"2021-03-24\",\n)\n\n_create_option(\n    \"deprecation.showPyplotGlobalUse\",\n    description=\"Set to false to disable the deprecation warning for using the global pyplot instance.\",\n    default_val=True,\n    scriptable=True,\n    deprecated=True,\n    deprecation_text=\"The support for global pyplot instances is planned to be removed soon.\",\n    expiration_date=\"2024-04-15\",\n    type_=bool,\n)\n\n\n# Config Section: Custom Theme #\n\n_create_section(\"theme\", \"Settings to define a custom theme for your Streamlit app.\")\n\n_create_option(\n    \"theme.base\",\n    description=\"\"\"The preset Streamlit theme that your custom theme inherits from.\n    One of \"light\" or \"dark\".\"\"\",\n)\n\n_create_option(\n    \"theme.primaryColor\",\n    description=\"Primary accent color for interactive elements.\",\n)\n\n_create_option(\n    \"theme.backgroundColor\",\n    description=\"Background color for the main content area.\",\n)\n\n_create_option(\n    \"theme.secondaryBackgroundColor\",\n    description=\"Background color used for the sidebar and most interactive widgets.\",\n)\n\n_create_option(\n    \"theme.textColor\",\n    description=\"Color used for almost all text.\",\n)\n\n_create_option(\n    \"theme.font\",\n    description=\"\"\"\n      Font family for all text in the app, except code blocks. One of \"sans serif\",\n      \"serif\", or \"monospace\".\n    \"\"\",\n)\n\n\ndef get_where_defined(key: str) -> str:\n    \"\"\"Indicate where (e.g. in which file) this option was defined.\n\n    Parameters\n    ----------\n    key : str\n        The config option key of the form \"section.optionName\"\n\n    \"\"\"\n    with _config_lock:\n        config_options = get_config_options()\n\n        if key not in config_options:\n            raise RuntimeError('Config key \"%s\" not defined.' % key)\n        return config_options[key].where_defined\n\n\ndef _is_unset(option_name: str) -> bool:\n    \"\"\"Check if a given option has not been set by the user.\n\n    Parameters\n    ----------\n    option_name : str\n        The option to check\n\n\n    Returns\n    -------\n    bool\n        True if the option has not been set by the user.\n\n    \"\"\"\n    return get_where_defined(option_name) == ConfigOption.DEFAULT_DEFINITION\n\n\ndef is_manually_set(option_name: str) -> bool:\n    \"\"\"Check if a given option was actually defined by the user.\n\n    Parameters\n    ----------\n    option_name : str\n        The option to check\n\n\n    Returns\n    -------\n    bool\n        True if the option has been set by the user.\n\n    \"\"\"\n    return get_where_defined(option_name) not in (\n        ConfigOption.DEFAULT_DEFINITION,\n        ConfigOption.STREAMLIT_DEFINITION,\n    )\n\n\ndef show_config() -> None:\n    \"\"\"Print all config options to the terminal.\"\"\"\n    with _config_lock:\n        assert (\n            _config_options is not None\n        ), \"_config_options should always be populated here.\"\n        config_util.show_config(_section_descriptions, _config_options)\n\n\n# Load Config Files #\n\n\ndef _set_option(key: str, value: Any, where_defined: str) -> None:\n    \"\"\"Set a config option by key / value pair.\n\n    This function assumes that the _config_options dictionary has already been\n    populated and thus should only be used within this file and by tests.\n\n    Parameters\n    ----------\n    key : str\n        The key of the option, like \"logger.level\".\n    value\n        The value of the option.\n    where_defined : str\n        Tells the config system where this was set.\n\n    \"\"\"\n    assert (\n        _config_options is not None\n    ), \"_config_options should always be populated here.\"\n    if key not in _config_options:\n        # Import logger locally to prevent circular references\n        from streamlit.logger import get_logger\n\n        LOGGER = get_logger(__name__)\n\n        LOGGER.warning(\n            f'\"{key}\" is not a valid config option. If you previously had this config option set, it may have been removed.'\n        )\n\n    else:\n        _config_options[key].set_value(value, where_defined)\n\n\ndef _update_config_with_sensitive_env_var(config_options: dict[str, ConfigOption]):\n    \"\"\"Update the config system by parsing the environment variable.\n\n    This should only be called from get_config_options.\n    \"\"\"\n    for opt_name, opt_val in config_options.items():\n        if not opt_val.sensitive:\n            continue\n        env_var_value = os.environ.get(opt_val.env_var)\n        if env_var_value is None:\n            continue\n        _set_option(opt_name, env_var_value, _DEFINED_BY_ENV_VAR)\n\n\ndef _update_config_with_toml(raw_toml: str, where_defined: str) -> None:\n    \"\"\"Update the config system by parsing this string.\n\n    This should only be called from get_config_options.\n\n    Parameters\n    ----------\n    raw_toml : str\n        The TOML file to parse to update the config values.\n    where_defined : str\n        Tells the config system where this was set.\n\n    \"\"\"\n    import toml\n\n    parsed_config_file = toml.loads(raw_toml)\n\n    for section, options in parsed_config_file.items():\n        for name, value in options.items():\n            value = _maybe_read_env_variable(value)\n            _set_option(f\"{section}.{name}\", value, where_defined)\n\n\ndef _maybe_read_env_variable(value: Any) -> Any:\n    \"\"\"If value is \"env:foo\", return value of environment variable \"foo\".\n\n    If value is not in the shape above, returns the value right back.\n\n    Parameters\n    ----------\n    value : any\n        The value to check\n\n    Returns\n    -------\n    any\n        Either returns value right back, or the value of the environment\n        variable.\n\n    \"\"\"\n    if isinstance(value, str) and value.startswith(\"env:\"):\n        var_name = value[len(\"env:\") :]\n        env_var = os.environ.get(var_name)\n\n        if env_var is None:\n            # Import logger locally to prevent circular references\n            from streamlit.logger import get_logger\n\n            LOGGER = get_logger(__name__)\n\n            LOGGER.error(\"No environment variable called %s\" % var_name)\n        else:\n            return _maybe_convert_to_number(env_var)\n\n    return value\n\n\ndef _maybe_convert_to_number(v: Any) -> Any:\n    \"\"\"Convert v to int or float, or leave it as is.\"\"\"\n    try:\n        return int(v)\n    except Exception:\n        pass\n\n    try:\n        return float(v)\n    except Exception:\n        pass\n\n    return v\n\n\n# Allow outside modules to wait for the config file to be parsed before doing\n# something.\n_on_config_parsed = Signal(doc=\"Emitted when the config file is parsed.\")\n\nCONFIG_FILENAMES = [\n    file_util.get_streamlit_file_path(\"config.toml\"),\n    file_util.get_project_streamlit_file_path(\"config.toml\"),\n]\n\n\ndef get_config_options(\n    force_reparse=False, options_from_flags: dict[str, Any] | None = None\n) -> dict[str, ConfigOption]:\n    \"\"\"Create and return a dict mapping config option names to their values,\n    returning a cached dict if possible.\n\n    Config option values are sourced from the following locations. Values\n    set in locations further down the list overwrite those set earlier.\n      1. default values defined in this file\n      2. the global `~/.streamlit/config.toml` file\n      3. per-project `$CWD/.streamlit/config.toml` files\n      4. environment variables such as `STREAMLIT_SERVER_PORT`\n      5. command line flags passed to `streamlit run`\n\n    Parameters\n    ----------\n    force_reparse : bool\n        Force config files to be parsed so that we pick up any changes to them.\n\n    options_from_flags : dict[str, any] or None\n        Config options that we received via CLI flag.\n\n    Returns\n    -------\n    dict[str, ConfigOption]\n        An ordered dict that maps config option names to their values.\n    \"\"\"\n    global _config_options\n\n    if not options_from_flags:\n        options_from_flags = {}\n\n    # Avoid grabbing the lock in the case where there's nothing for us to do.\n    config_options = _config_options\n    if config_options and not force_reparse:\n        return config_options\n\n    with _config_lock:\n        # Short-circuit if config files were parsed while we were waiting on\n        # the lock.\n        if _config_options and not force_reparse:\n            return _config_options\n\n        old_options = _config_options\n        _config_options = copy.deepcopy(_config_options_template)\n\n        # Values set in files later in the CONFIG_FILENAMES list overwrite those\n        # set earlier.\n        for filename in CONFIG_FILENAMES:\n            if not os.path.exists(filename):\n                continue\n\n            with open(filename, encoding=\"utf-8\") as input:\n                file_contents = input.read()\n\n            _update_config_with_toml(file_contents, filename)\n\n        _update_config_with_sensitive_env_var(_config_options)\n\n        for opt_name, opt_val in options_from_flags.items():\n            _set_option(opt_name, opt_val, _DEFINED_BY_FLAG)\n\n        if old_options and config_util.server_option_changed(\n            old_options, _config_options\n        ):\n            # Import logger locally to prevent circular references.\n            from streamlit.logger import get_logger\n\n            LOGGER = get_logger(__name__)\n            LOGGER.warning(\n                \"An update to the [server] config option section was detected.\"\n                \" To have these changes be reflected, please restart streamlit.\"\n            )\n\n        _on_config_parsed.send()\n        return _config_options\n\n\ndef _check_conflicts() -> None:\n    # Node-related conflicts\n\n    # When using the Node server, we must always connect to 8501 (this is\n    # hard-coded in JS). Otherwise, the browser would decide what port to\n    # connect to based on window.location.port, which in dev is going to\n    # be (3000)\n\n    # Import logger locally to prevent circular references\n    from streamlit.logger import get_logger\n\n    LOGGER = get_logger(__name__)\n\n    if get_option(\"global.developmentMode\"):\n        assert _is_unset(\n            \"server.port\"\n        ), \"server.port does not work when global.developmentMode is true.\"\n\n        assert _is_unset(\n            \"browser.serverPort\"\n        ), \"browser.serverPort does not work when global.developmentMode is true.\"\n\n    # XSRF conflicts\n    if get_option(\"server.enableXsrfProtection\"):\n        if not get_option(\"server.enableCORS\") or get_option(\"global.developmentMode\"):\n            LOGGER.warning(\n                \"\"\"\nWarning: the config option 'server.enableCORS=false' is not compatible with 'server.enableXsrfProtection=true'.\nAs a result, 'server.enableCORS' is being overridden to 'true'.\n\nMore information:\nIn order to protect against CSRF attacks, we send a cookie with each request.\nTo do so, we must specify allowable origins, which places a restriction on\ncross-origin resource sharing.\n\nIf cross origin resource sharing is required, please disable server.enableXsrfProtection.\n            \"\"\"\n            )\n\n\ndef _set_development_mode() -> None:\n    development.is_development_mode = get_option(\"global.developmentMode\")\n\n\ndef on_config_parsed(\n    func: Callable[[], None], force_connect=False, lock=False\n) -> Callable[[], bool]:\n    \"\"\"Wait for the config file to be parsed then call func.\n\n    If the config file has already been parsed, just calls func immediately\n    unless force_connect is set.\n\n    Parameters\n    ----------\n    func : Callable[[], None]\n        A function to run on config parse.\n\n    force_connect : bool\n        Wait until the next config file parse to run func, even if config files\n        have already been parsed.\n\n    lock : bool\n        If set, grab _config_lock before running func.\n\n    Returns\n    -------\n    Callable[[], bool]\n        A function that the caller can use to deregister func.\n    \"\"\"\n\n    # We need to use the same receiver when we connect or disconnect on the\n    # Signal. If we don't do this, then the registered receiver won't be released\n    # leading to a memory leak because the Signal will keep a reference of the\n    # callable argument. When the callable argument is an object method, then\n    # the reference to that object won't be released.\n    def receiver(_):\n        return func_with_lock()\n\n    def disconnect():\n        return _on_config_parsed.disconnect(receiver)\n\n    def func_with_lock():\n        if lock:\n            with _config_lock:\n                func()\n        else:\n            func()\n\n    if force_connect or not _config_options:\n        # weak=False so that we have control of when the on_config_parsed\n        # callback is deregistered.\n        _on_config_parsed.connect(receiver, weak=False)\n    else:\n        func_with_lock()\n\n    return disconnect\n\n\n# Run _check_conflicts only once the config file is parsed in order to avoid\n# loops. We also need to grab the lock when running _check_conflicts since it\n# may edit config options based on the values of other config options.\non_config_parsed(_check_conflicts, lock=True)\non_config_parsed(_set_development_mode)\n", "lib/streamlit/color_util.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom typing import Any, Callable, Collection, Tuple, Union, cast\n\nfrom typing_extensions import TypeAlias\n\nfrom streamlit.errors import StreamlitAPIException\n\n# components go from 0.0 to 1.0\n# Supported by Pillow and pretty common.\nFloatRGBColorTuple: TypeAlias = Tuple[float, float, float]\nFloatRGBAColorTuple: TypeAlias = Tuple[float, float, float, float]\n\n# components go from 0 to 255\n# DeckGL uses these.\nIntRGBColorTuple: TypeAlias = Tuple[int, int, int]\nIntRGBAColorTuple: TypeAlias = Tuple[int, int, int, int]\n\n# components go from 0 to 255, except alpha goes from 0.0 to 1.0\n# CSS uses these.\nMixedRGBAColorTuple: TypeAlias = Tuple[int, int, int, float]\n\nColor4Tuple: TypeAlias = Union[\n    FloatRGBAColorTuple,\n    IntRGBAColorTuple,\n    MixedRGBAColorTuple,\n]\n\nColor3Tuple: TypeAlias = Union[\n    FloatRGBColorTuple,\n    IntRGBColorTuple,\n]\n\nColorTuple: TypeAlias = Union[Color4Tuple, Color3Tuple]\n\nIntColorTuple = Union[IntRGBColorTuple, IntRGBAColorTuple]\nCSSColorStr = Union[IntRGBAColorTuple, MixedRGBAColorTuple]\n\nColorStr: TypeAlias = str\n\nColor: TypeAlias = Union[ColorTuple, ColorStr]\nMaybeColor: TypeAlias = Union[str, Collection[Any]]\n\n\ndef to_int_color_tuple(color: MaybeColor) -> IntColorTuple:\n    \"\"\"Convert input into color tuple of type (int, int, int, int).\"\"\"\n    color_tuple = _to_color_tuple(\n        color,\n        rgb_formatter=_int_formatter,\n        alpha_formatter=_int_formatter,\n    )\n    return cast(IntColorTuple, color_tuple)\n\n\ndef to_css_color(color: MaybeColor) -> Color:\n    \"\"\"Convert input into a CSS-compatible color that Vega can use.\n\n    Inputs must be a hex string, rgb()/rgba() string, or a color tuple. Inputs may not be a CSS\n    color name, other CSS color function (like \"hsl(...)\"), etc.\n\n    See tests for more info.\n    \"\"\"\n    if is_css_color_like(color):\n        return cast(Color, color)\n\n    if is_color_tuple_like(color):\n        ctuple = cast(ColorTuple, color)\n        ctuple = _normalize_tuple(ctuple, _int_formatter, _float_formatter)\n        if len(ctuple) == 3:\n            return f\"rgb({ctuple[0]}, {ctuple[1]}, {ctuple[2]})\"\n        elif len(ctuple) == 4:\n            c4tuple = cast(MixedRGBAColorTuple, ctuple)\n            return f\"rgba({c4tuple[0]}, {c4tuple[1]}, {c4tuple[2]}, {c4tuple[3]})\"\n\n    raise InvalidColorException(color)\n\n\ndef is_css_color_like(color: MaybeColor) -> bool:\n    \"\"\"Check whether the input looks like something Vega can use.\n\n    This is meant to be lightweight, and not a definitive answer. The definitive solution is to try\n    to convert and see if an error is thrown.\n\n    NOTE: We only accept hex colors and color tuples as user input. So do not use this function to\n    validate user input! Instead use is_hex_color_like and is_color_tuple_like.\n    \"\"\"\n    return is_hex_color_like(color) or _is_cssrgb_color_like(color)\n\n\ndef is_hex_color_like(color: MaybeColor) -> bool:\n    \"\"\"Check whether the input looks like a hex color.\n\n    This is meant to be lightweight, and not a definitive answer. The definitive solution is to try\n    to convert and see if an error is thrown.\n    \"\"\"\n    return (\n        isinstance(color, str)\n        and color.startswith(\"#\")\n        and color[1:].isalnum()  # Alphanumeric\n        and len(color) in {4, 5, 7, 9}\n    )\n\n\ndef _is_cssrgb_color_like(color: MaybeColor) -> bool:\n    \"\"\"Check whether the input looks like a CSS rgb() or rgba() color string.\n\n    This is meant to be lightweight, and not a definitive answer. The definitive solution is to try\n    to convert and see if an error is thrown.\n\n    NOTE: We only accept hex colors and color tuples as user input. So do not use this function to\n    validate user input! Instead use is_hex_color_like and is_color_tuple_like.\n    \"\"\"\n    return isinstance(color, str) and (\n        color.startswith(\"rgb(\") or color.startswith(\"rgba(\")\n    )\n\n\ndef is_color_tuple_like(color: MaybeColor) -> bool:\n    \"\"\"Check whether the input looks like a tuple color.\n\n    This is meant to be lightweight, and not a definitive answer. The definitive solution is to try\n    to convert and see if an error is thrown.\n    \"\"\"\n    return (\n        isinstance(color, (tuple, list))\n        and len(color) in {3, 4}\n        and all(isinstance(c, (int, float)) for c in color)\n    )\n\n\ndef is_color_like(color: MaybeColor) -> bool:\n    \"\"\"A fairly lightweight check of whether the input is a color.\n\n    This isn't meant to be a definitive answer. The definitive solution is to\n    try to convert and see if an error is thrown.\n    \"\"\"\n    return is_css_color_like(color) or is_color_tuple_like(color)\n\n\n# Wrote our own hex-to-tuple parser to avoid bringing in a dependency.\ndef _to_color_tuple(\n    color: MaybeColor,\n    rgb_formatter: Callable[[float, MaybeColor], float],\n    alpha_formatter: Callable[[float, MaybeColor], float],\n):\n    \"\"\"Convert a potential color to a color tuple.\n\n    The exact type of color tuple this outputs is dictated by the formatter parameters.\n\n    The R, G, B components are transformed by rgb_formatter, and the alpha component is transformed\n    by alpha_formatter.\n\n    For example, to output a (float, float, float, int) color tuple, set rgb_formatter\n    to _float_formatter and alpha_formatter to _int_formatter.\n    \"\"\"\n    if is_hex_color_like(color):\n        hex_len = len(color)\n        color_hex = cast(str, color)\n\n        if hex_len == 4:\n            r = 2 * color_hex[1]\n            g = 2 * color_hex[2]\n            b = 2 * color_hex[3]\n            a = \"ff\"\n        elif hex_len == 5:\n            r = 2 * color_hex[1]\n            g = 2 * color_hex[2]\n            b = 2 * color_hex[3]\n            a = 2 * color_hex[4]\n        elif hex_len == 7:\n            r = color_hex[1:3]\n            g = color_hex[3:5]\n            b = color_hex[5:7]\n            a = \"ff\"\n        elif hex_len == 9:\n            r = color_hex[1:3]\n            g = color_hex[3:5]\n            b = color_hex[5:7]\n            a = color_hex[7:9]\n        else:\n            raise InvalidColorException(color)\n\n        try:\n            color = int(r, 16), int(g, 16), int(b, 16), int(a, 16)\n        except Exception as ex:\n            raise InvalidColorException(color) from ex\n\n    if is_color_tuple_like(color):\n        color_tuple = cast(ColorTuple, color)\n        return _normalize_tuple(color_tuple, rgb_formatter, alpha_formatter)\n\n    raise InvalidColorException(color)\n\n\ndef _normalize_tuple(\n    color: ColorTuple,\n    rgb_formatter: Callable[[float, MaybeColor], float],\n    alpha_formatter: Callable[[float, MaybeColor], float],\n) -> ColorTuple:\n    \"\"\"Parse color tuple using the specified color formatters.\n\n    The R, G, B components are transformed by rgb_formatter, and the alpha component is transformed\n    by alpha_formatter.\n\n    For example, to output a (float, float, float, int) color tuple, set rgb_formatter\n    to _float_formatter and alpha_formatter to _int_formatter.\n    \"\"\"\n    if len(color) == 3:\n        r = rgb_formatter(color[0], color)\n        g = rgb_formatter(color[1], color)\n        b = rgb_formatter(color[2], color)\n        return r, g, b\n\n    elif len(color) == 4:\n        color_4tuple = cast(Color4Tuple, color)\n        r = rgb_formatter(color_4tuple[0], color_4tuple)\n        g = rgb_formatter(color_4tuple[1], color_4tuple)\n        b = rgb_formatter(color_4tuple[2], color_4tuple)\n        alpha = alpha_formatter(color_4tuple[3], color_4tuple)\n        return r, g, b, alpha\n\n    raise InvalidColorException(color)\n\n\ndef _int_formatter(component: float, color: MaybeColor) -> int:\n    \"\"\"Convert a color component (float or int) to an int from 0 to 255.\n\n    Anything too small will become 0, and anything too large will become 255.\n    \"\"\"\n    if isinstance(component, float):\n        component = int(component * 255)\n\n    if isinstance(component, int):\n        return min(255, max(component, 0))\n\n    raise InvalidColorException(color)\n\n\ndef _float_formatter(component: float, color: MaybeColor) -> float:\n    \"\"\"Convert a color component (float or int) to a float from 0.0 to 1.0.\n\n    Anything too small will become 0.0, and anything too large will become 1.0.\n    \"\"\"\n    if isinstance(component, int):\n        component = component / 255.0\n\n    if isinstance(component, float):\n        return min(1.0, max(component, 0.0))\n\n    raise InvalidColorException(color)\n\n\nclass InvalidColorException(StreamlitAPIException):\n    def __init__(self, color, *args):\n        message = f\"\"\"This does not look like a valid color: {repr(color)}.\n\nColors must be in one of the following formats:\n\n* Hex string with 3, 4, 6, or 8 digits. Example: `'#00ff00'`\n* List or tuple with 3 or 4 components. Example: `[1.0, 0.5, 0, 0.2]`\n            \"\"\"\n        super().__init__(message, *args)\n", "lib/streamlit/cursor.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom typing import Any\n\nfrom streamlit import util\nfrom streamlit.runtime.scriptrunner import get_script_run_ctx\n\n\ndef make_delta_path(\n    root_container: int, parent_path: tuple[int, ...], index: int\n) -> list[int]:\n    delta_path = [root_container]\n    delta_path.extend(parent_path)\n    delta_path.append(index)\n    return delta_path\n\n\ndef get_container_cursor(\n    root_container: int | None,\n) -> RunningCursor | None:\n    \"\"\"Return the top-level RunningCursor for the given container.\n    This is the cursor that is used when user code calls something like\n    `st.foo` (which uses the main container) or `st.sidebar.foo` (which uses\n    the sidebar container).\n    \"\"\"\n    if root_container is None:\n        return None\n\n    ctx = get_script_run_ctx()\n\n    if ctx is None:\n        return None\n\n    if root_container in ctx.cursors:\n        return ctx.cursors[root_container]\n\n    cursor = RunningCursor(root_container=root_container)\n    ctx.cursors[root_container] = cursor\n    return cursor\n\n\nclass Cursor:\n    \"\"\"A pointer to a delta location in the app.\n\n    When adding an element to the app, you should always call\n    get_locked_cursor() on that element's respective Cursor.\n    \"\"\"\n\n    def __repr__(self) -> str:\n        return util.repr_(self)\n\n    @property\n    def root_container(self) -> int:\n        \"\"\"The top-level container this cursor lives within - either\n        RootContainer.MAIN or RootContainer.SIDEBAR.\n        \"\"\"\n        raise NotImplementedError()\n\n    @property\n    def parent_path(self) -> tuple[int, ...]:\n        \"\"\"The cursor's parent's path within its container.\"\"\"\n        raise NotImplementedError()\n\n    @property\n    def index(self) -> int:\n        \"\"\"The index of the Delta within its parent block.\"\"\"\n        raise NotImplementedError()\n\n    @property\n    def delta_path(self) -> list[int]:\n        \"\"\"The complete path of the delta pointed to by this cursor - its\n        container, parent path, and index.\n        \"\"\"\n        return make_delta_path(self.root_container, self.parent_path, self.index)\n\n    @property\n    def is_locked(self) -> bool:\n        raise NotImplementedError()\n\n    def get_locked_cursor(self, **props) -> LockedCursor:\n        raise NotImplementedError()\n\n    @property\n    def props(self) -> Any:\n        \"\"\"Other data in this cursor. This is a temporary measure that will go\n        away when we implement improved return values for elements.\n\n        This is only implemented in LockedCursor.\n        \"\"\"\n        raise NotImplementedError()\n\n\nclass RunningCursor(Cursor):\n    def __init__(self, root_container: int, parent_path: tuple[int, ...] = ()):\n        \"\"\"A moving pointer to a delta location in the app.\n\n        RunningCursors auto-increment to the next available location when you\n        call get_locked_cursor() on them.\n\n        Parameters\n        ----------\n        root_container: int\n            The root container this cursor lives in.\n        parent_path: tuple of ints\n          The full path of this cursor, consisting of the IDs of all ancestors.\n          The 0th item is the topmost ancestor.\n\n        \"\"\"\n        self._root_container = root_container\n        self._parent_path = parent_path\n        self._index = 0\n\n    @property\n    def root_container(self) -> int:\n        return self._root_container\n\n    @property\n    def parent_path(self) -> tuple[int, ...]:\n        return self._parent_path\n\n    @property\n    def index(self) -> int:\n        return self._index\n\n    @property\n    def is_locked(self) -> bool:\n        return False\n\n    def get_locked_cursor(self, **props) -> LockedCursor:\n        locked_cursor = LockedCursor(\n            root_container=self._root_container,\n            parent_path=self._parent_path,\n            index=self._index,\n            **props,\n        )\n\n        self._index += 1\n\n        return locked_cursor\n\n\nclass LockedCursor(Cursor):\n    def __init__(\n        self,\n        root_container: int,\n        parent_path: tuple[int, ...] = (),\n        index: int = 0,\n        **props,\n    ):\n        \"\"\"A locked pointer to a location in the app.\n\n        LockedCursors always point to the same location, even when you call\n        get_locked_cursor() on them.\n\n        Parameters\n        ----------\n        root_container: int\n            The root container this cursor lives in.\n        parent_path: tuple of ints\n          The full path of this cursor, consisting of the IDs of all ancestors. The\n          0th item is the topmost ancestor.\n        index: int\n        **props: any\n          Anything else you want to store in this cursor. This is a temporary\n          measure that will go away when we implement improved return values\n          for elements.\n\n        \"\"\"\n        self._root_container = root_container\n        self._index = index\n        self._parent_path = parent_path\n        self._props = props\n\n    @property\n    def root_container(self) -> int:\n        return self._root_container\n\n    @property\n    def parent_path(self) -> tuple[int, ...]:\n        return self._parent_path\n\n    @property\n    def index(self) -> int:\n        return self._index\n\n    @property\n    def is_locked(self) -> bool:\n        return True\n\n    def get_locked_cursor(self, **props) -> LockedCursor:\n        self._props = props\n        return self\n\n    @property\n    def props(self) -> Any:\n        return self._props\n", "lib/streamlit/code_util.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"A bunch of useful code utilities.\"\"\"\n\nfrom __future__ import annotations\n\nimport re\nfrom typing import Any\n\n\ndef extract_args(line: str) -> list[str]:\n    \"\"\"Parse argument strings from all outer parentheses in a line of code.\n\n    Parameters\n    ----------\n    line : str\n        A line of code\n\n    Returns\n    -------\n    list of strings\n        Contents of the outer parentheses\n\n    Example\n    -------\n    >>> line = 'foo(bar, baz), \"a\", my(func)'\n    >>> extract_args(line)\n    ['bar, baz', 'func']\n\n    \"\"\"\n    stack = 0\n    startIndex = None\n    results = []\n\n    for i, c in enumerate(line):\n        if c == \"(\":\n            if stack == 0:\n                startIndex = i + 1\n            stack += 1\n        elif c == \")\":\n            stack -= 1\n            if stack == 0:\n                results.append(line[startIndex:i])\n    return results\n\n\ndef get_method_args_from_code(args: list[Any], line: str) -> list[str]:\n    \"\"\"Parse arguments from a stringified arguments list inside parentheses\n\n    Parameters\n    ----------\n    args : list\n        A list where it's size matches the expected number of parsed arguments\n    line : str\n        Stringified line of code with method arguments inside parentheses\n\n    Returns\n    -------\n    list of strings\n        Parsed arguments\n\n    Example\n    -------\n    >>> line = 'foo(bar, baz, my(func, tion))'\n    >>>\n    >>> get_method_args_from_code(range(0, 3), line)\n    ['bar', 'baz', 'my(func, tion)']\n\n    \"\"\"\n    line_args = extract_args(line)[0]\n\n    # Split arguments, https://stackoverflow.com/a/26634150\n    if len(args) > 1:\n        inputs = re.split(r\",\\s*(?![^(){}[\\]]*\\))\", line_args)\n        assert len(inputs) == len(args), \"Could not split arguments\"\n    else:\n        inputs = [line_args]\n    return inputs\n", "lib/streamlit/delta_generator.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Allows us to create and absorb changes (aka Deltas) to elements.\"\"\"\n\nfrom __future__ import annotations\n\nimport sys\nfrom contextvars import ContextVar\nfrom copy import deepcopy\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    Callable,\n    Final,\n    Hashable,\n    Iterable,\n    Literal,\n    NoReturn,\n    TypeVar,\n    cast,\n)\n\nfrom typing_extensions import TypeAlias\n\nfrom streamlit import (\n    cli_util,\n    config,\n    cursor,\n    env_util,\n    logger,\n    runtime,\n    type_util,\n    util,\n)\nfrom streamlit.elements.alert import AlertMixin\nfrom streamlit.elements.arrow import ArrowMixin\nfrom streamlit.elements.balloons import BalloonsMixin\nfrom streamlit.elements.bokeh_chart import BokehMixin\nfrom streamlit.elements.code import CodeMixin\nfrom streamlit.elements.deck_gl_json_chart import PydeckMixin\nfrom streamlit.elements.doc_string import HelpMixin\nfrom streamlit.elements.empty import EmptyMixin\nfrom streamlit.elements.exception import ExceptionMixin\nfrom streamlit.elements.form import FormData, FormMixin, current_form_id\nfrom streamlit.elements.graphviz_chart import GraphvizMixin\nfrom streamlit.elements.heading import HeadingMixin\nfrom streamlit.elements.html import HtmlMixin\nfrom streamlit.elements.iframe import IframeMixin\nfrom streamlit.elements.image import ImageMixin\nfrom streamlit.elements.json import JsonMixin\nfrom streamlit.elements.layouts import LayoutsMixin\nfrom streamlit.elements.map import MapMixin\nfrom streamlit.elements.markdown import MarkdownMixin\nfrom streamlit.elements.media import MediaMixin\nfrom streamlit.elements.metric import MetricMixin\nfrom streamlit.elements.plotly_chart import PlotlyMixin\nfrom streamlit.elements.progress import ProgressMixin\nfrom streamlit.elements.pyplot import PyplotMixin\nfrom streamlit.elements.snow import SnowMixin\nfrom streamlit.elements.text import TextMixin\nfrom streamlit.elements.toast import ToastMixin\nfrom streamlit.elements.vega_charts import VegaChartsMixin\nfrom streamlit.elements.widgets.button import ButtonMixin\nfrom streamlit.elements.widgets.camera_input import CameraInputMixin\nfrom streamlit.elements.widgets.chat import ChatMixin\nfrom streamlit.elements.widgets.checkbox import CheckboxMixin\nfrom streamlit.elements.widgets.color_picker import ColorPickerMixin\nfrom streamlit.elements.widgets.data_editor import DataEditorMixin\nfrom streamlit.elements.widgets.file_uploader import FileUploaderMixin\nfrom streamlit.elements.widgets.multiselect import MultiSelectMixin\nfrom streamlit.elements.widgets.number_input import NumberInputMixin\nfrom streamlit.elements.widgets.radio import RadioMixin\nfrom streamlit.elements.widgets.select_slider import SelectSliderMixin\nfrom streamlit.elements.widgets.selectbox import SelectboxMixin\nfrom streamlit.elements.widgets.slider import SliderMixin\nfrom streamlit.elements.widgets.text_widgets import TextWidgetsMixin\nfrom streamlit.elements.widgets.time_widgets import TimeWidgetsMixin\nfrom streamlit.elements.write import WriteMixin\nfrom streamlit.errors import NoSessionContext, StreamlitAPIException\nfrom streamlit.proto import Block_pb2, ForwardMsg_pb2\nfrom streamlit.proto.RootContainer_pb2 import RootContainer\nfrom streamlit.runtime import caching\nfrom streamlit.runtime.scriptrunner import get_script_run_ctx\n\nif TYPE_CHECKING:\n    from google.protobuf.message import Message\n    from numpy import typing as npt\n    from pandas import DataFrame\n\n    from streamlit.cursor import Cursor\n    from streamlit.elements.arrow import Data\n    from streamlit.elements.lib.built_in_chart_utils import AddRowsMetadata\n\n\nMAX_DELTA_BYTES: Final[int] = 14 * 1024 * 1024  # 14MB\n\nValue = TypeVar(\"Value\")\nDG = TypeVar(\"DG\", bound=\"DeltaGenerator\")\n\n# Type aliases for Ancestor Block Types\nBlockType: TypeAlias = str\nAncestorBlockTypes: TypeAlias = Iterable[BlockType]\n\n\n_use_warning_has_been_displayed: bool = False\n\n\ndef _maybe_print_use_warning() -> None:\n    \"\"\"Print a warning if Streamlit is imported but not being run with `streamlit run`.\n    The warning is printed only once, and is printed using the root logger.\n    \"\"\"\n    global _use_warning_has_been_displayed\n\n    if not _use_warning_has_been_displayed:\n        _use_warning_has_been_displayed = True\n\n        warning = cli_util.style_for_cli(\"Warning:\", bold=True, fg=\"yellow\")\n\n        if env_util.is_repl():\n            logger.get_logger(\"root\").warning(\n                f\"\\n  {warning} to view a Streamlit app on a browser, use Streamlit in a file and\\n  run it with the following command:\\n\\n    streamlit run [FILE_NAME] [ARGUMENTS]\"\n            )\n\n        elif not runtime.exists() and config.get_option(\n            \"global.showWarningOnDirectExecution\"\n        ):\n            script_name = sys.argv[0]\n\n            logger.get_logger(\"root\").warning(\n                f\"\\n  {warning} to view this Streamlit app on a browser, run it with the following\\n  command:\\n\\n    streamlit run {script_name} [ARGUMENTS]\"\n            )\n\n\nclass DeltaGenerator(\n    AlertMixin,\n    BalloonsMixin,\n    BokehMixin,\n    ButtonMixin,\n    CameraInputMixin,\n    ChatMixin,\n    CheckboxMixin,\n    CodeMixin,\n    ColorPickerMixin,\n    EmptyMixin,\n    ExceptionMixin,\n    FileUploaderMixin,\n    FormMixin,\n    GraphvizMixin,\n    HeadingMixin,\n    HelpMixin,\n    HtmlMixin,\n    IframeMixin,\n    ImageMixin,\n    LayoutsMixin,\n    MarkdownMixin,\n    MapMixin,\n    MediaMixin,\n    MetricMixin,\n    MultiSelectMixin,\n    NumberInputMixin,\n    PlotlyMixin,\n    ProgressMixin,\n    PydeckMixin,\n    PyplotMixin,\n    RadioMixin,\n    SelectboxMixin,\n    SelectSliderMixin,\n    SliderMixin,\n    SnowMixin,\n    JsonMixin,\n    TextMixin,\n    TextWidgetsMixin,\n    TimeWidgetsMixin,\n    ToastMixin,\n    WriteMixin,\n    ArrowMixin,\n    VegaChartsMixin,\n    DataEditorMixin,\n):\n    \"\"\"Creator of Delta protobuf messages.\n\n    Parameters\n    ----------\n    root_container: BlockPath_pb2.BlockPath.ContainerValue or None\n      The root container for this DeltaGenerator. If None, this is a null\n      DeltaGenerator which doesn't print to the app at all (useful for\n      testing).\n\n    cursor: cursor.Cursor or None\n      This is either:\n      - None: if this is the running DeltaGenerator for a top-level\n        container (MAIN or SIDEBAR)\n      - RunningCursor: if this is the running DeltaGenerator for a\n        non-top-level container (created with dg.container())\n      - LockedCursor: if this is a locked DeltaGenerator returned by some\n        other DeltaGenerator method. E.g. the dg returned in dg =\n        st.text(\"foo\").\n\n    parent: DeltaGenerator\n      To support the `with dg` notation, DGs are arranged as a tree. Each DG\n      remembers its own parent, and the root of the tree is the main DG.\n\n    block_type: None or \"vertical\" or \"horizontal\" or \"column\" or \"expandable\"\n      If this is a block DG, we track its type to prevent nested columns/expanders\n\n    \"\"\"\n\n    # The pydoc below is for user consumption, so it doesn't talk about\n    # DeltaGenerator constructor parameters (which users should never use). For\n    # those, see above.\n    def __init__(\n        self,\n        root_container: int | None = RootContainer.MAIN,\n        cursor: Cursor | None = None,\n        parent: DeltaGenerator | None = None,\n        block_type: str | None = None,\n    ) -> None:\n        \"\"\"Inserts or updates elements in Streamlit apps.\n\n        As a user, you should never initialize this object by hand. Instead,\n        DeltaGenerator objects are initialized for you in two places:\n\n        1) When you call `dg = st.foo()` for some method \"foo\", sometimes `dg`\n        is a DeltaGenerator object. You can call methods on the `dg` object to\n        update the element `foo` that appears in the Streamlit app.\n\n        2) This is an internal detail, but `st.sidebar` itself is a\n        DeltaGenerator. That's why you can call `st.sidebar.foo()` to place\n        an element `foo` inside the sidebar.\n\n        \"\"\"\n        # Sanity check our Container + Cursor, to ensure that our Cursor\n        # is using the same Container that we are.\n        if (\n            root_container is not None\n            and cursor is not None\n            and root_container != cursor.root_container\n        ):\n            raise RuntimeError(\n                \"DeltaGenerator root_container and cursor.root_container must be the same\"\n            )\n\n        # Whether this DeltaGenerator is nested in the main area or sidebar.\n        # No relation to `st.container()`.\n        self._root_container = root_container\n\n        # NOTE: You should never use this directly! Instead, use self._cursor,\n        # which is a computed property that fetches the right cursor.\n        self._provided_cursor = cursor\n\n        self._parent = parent\n        self._block_type = block_type\n\n        # If this an `st.form` block, this will get filled in.\n        self._form_data: FormData | None = None\n\n        # Change the module of all mixin'ed functions to be st.delta_generator,\n        # instead of the original module (e.g. st.elements.markdown)\n        for mixin in self.__class__.__bases__:\n            for _, func in mixin.__dict__.items():\n                if callable(func):\n                    func.__module__ = self.__module__\n\n    def __repr__(self) -> str:\n        return util.repr_(self)\n\n    def __enter__(self) -> None:\n        # with block started\n        dg_stack.set(dg_stack.get() + (self,))\n\n    def __exit__(\n        self,\n        type: Any,\n        value: Any,\n        traceback: Any,\n    ) -> Literal[False]:\n        # with block ended\n\n        dg_stack.set(dg_stack.get()[:-1])\n\n        # Re-raise any exceptions\n        return False\n\n    @property\n    def _active_dg(self) -> DeltaGenerator:\n        \"\"\"Return the DeltaGenerator that's currently 'active'.\n        If we are the main DeltaGenerator, and are inside a `with` block that\n        creates a container, our active_dg is that container. Otherwise,\n        our active_dg is self.\n        \"\"\"\n        if self == self._main_dg:\n            # We're being invoked via an `st.foo` pattern - use the current\n            # `with` dg (aka the top of the stack).\n            last_context_stack_dg = get_last_dg_added_to_context_stack()\n            if last_context_stack_dg is not None:\n                return last_context_stack_dg\n\n        # We're being invoked via an `st.sidebar.foo` pattern - ignore the\n        # current `with` dg.\n        return self\n\n    @property\n    def _main_dg(self) -> DeltaGenerator:\n        \"\"\"Return this DeltaGenerator's root - that is, the top-level ancestor\n        DeltaGenerator that we belong to (this generally means the st._main\n        DeltaGenerator).\n        \"\"\"\n        return self._parent._main_dg if self._parent else self\n\n    def __getattr__(self, name: str) -> Callable[..., NoReturn]:\n        import streamlit as st\n\n        streamlit_methods = [\n            method_name for method_name in dir(st) if callable(getattr(st, method_name))\n        ]\n\n        def wrapper(*args: Any, **kwargs: Any) -> NoReturn:\n            if name in streamlit_methods:\n                if self._root_container == RootContainer.SIDEBAR:\n                    message = (\n                        f\"Method `{name}()` does not exist for \"\n                        f\"`st.sidebar`. Did you mean `st.{name}()`?\"\n                    )\n                else:\n                    message = (\n                        f\"Method `{name}()` does not exist for \"\n                        \"`DeltaGenerator` objects. Did you mean \"\n                        f\"`st.{name}()`?\"\n                    )\n            else:\n                message = f\"`{name}()` is not a valid Streamlit command.\"\n\n            raise StreamlitAPIException(message)\n\n        return wrapper\n\n    def __deepcopy__(self, _memo):\n        dg = DeltaGenerator(\n            root_container=self._root_container,\n            cursor=deepcopy(self._cursor),\n            parent=deepcopy(self._parent),\n            block_type=self._block_type,\n        )\n        dg._form_data = deepcopy(self._form_data)\n        return dg\n\n    @property\n    def _ancestors(self) -> Iterable[DeltaGenerator]:\n        current_dg: DeltaGenerator | None = self\n        while current_dg is not None:\n            yield current_dg\n            current_dg = current_dg._parent\n\n    @property\n    def _ancestor_block_types(self) -> AncestorBlockTypes:\n        \"\"\"Iterate all the block types used by this DeltaGenerator and all\n        its ancestor DeltaGenerators.\n        \"\"\"\n        for a in self._ancestors:\n            if a._block_type is not None:\n                yield a._block_type\n\n    def _count_num_of_parent_columns(\n        self, ancestor_block_types: AncestorBlockTypes\n    ) -> int:\n        return sum(\n            1 for ancestor_block in ancestor_block_types if ancestor_block == \"column\"\n        )\n\n    @property\n    def _cursor(self) -> Cursor | None:\n        \"\"\"Return our Cursor. This will be None if we're not running in a\n        ScriptThread - e.g., if we're running a \"bare\" script outside of\n        Streamlit.\n        \"\"\"\n        if self._provided_cursor is None:\n            return cursor.get_container_cursor(self._root_container)\n        else:\n            return self._provided_cursor\n\n    @property\n    def _is_top_level(self) -> bool:\n        return self._provided_cursor is None\n\n    @property\n    def id(self) -> str:\n        return str(id(self))\n\n    def _get_delta_path_str(self) -> str:\n        \"\"\"Returns the element's delta path as a string like \"[0, 2, 3, 1]\".\n\n        This uniquely identifies the element's position in the front-end,\n        which allows (among other potential uses) the MediaFileManager to maintain\n        session-specific maps of MediaFile objects placed with their \"coordinates\".\n\n        This way, users can (say) use st.image with a stream of different images,\n        and Streamlit will expire the older images and replace them in place.\n        \"\"\"\n        # Operate on the active DeltaGenerator, in case we're in a `with` block.\n        dg = self._active_dg\n        return str(dg._cursor.delta_path) if dg._cursor is not None else \"[]\"\n\n    def _enqueue(\n        self,\n        delta_type: str,\n        element_proto: Message,\n        add_rows_metadata: AddRowsMetadata | None = None,\n    ) -> DeltaGenerator:\n        \"\"\"Create NewElement delta, fill it, and enqueue it.\n\n        Parameters\n        ----------\n        delta_type : str\n            The name of the streamlit method being called\n        element_proto : proto\n            The actual proto in the NewElement type e.g. Alert/Button/Slider\n\n        Returns\n        -------\n        DeltaGenerator\n            Return a DeltaGenerator that can be used to modify the newly-created\n            element.\n        \"\"\"\n        # Operate on the active DeltaGenerator, in case we're in a `with` block.\n        dg = self._active_dg\n\n        ctx = get_script_run_ctx()\n        if ctx and ctx.current_fragment_id and _writes_directly_to_sidebar(dg):\n            raise StreamlitAPIException(\n                \"Calling `st.sidebar` in a function wrapped with `st.experimental_fragment` \"\n                \"is not supported. To write elements to the sidebar with a fragment, \"\n                \"call your fragment function inside a `with st.sidebar` context manager.\"\n            )\n\n        # Warn if an element is being changed but the user isn't running the streamlit server.\n        _maybe_print_use_warning()\n\n        # Copy the marshalled proto into the overall msg proto\n        msg = ForwardMsg_pb2.ForwardMsg()\n        msg_el_proto = getattr(msg.delta.new_element, delta_type)\n        msg_el_proto.CopyFrom(element_proto)\n\n        # Only enqueue message and fill in metadata if there's a container.\n        msg_was_enqueued = False\n        if dg._root_container is not None and dg._cursor is not None:\n            msg.metadata.delta_path[:] = dg._cursor.delta_path\n\n            _enqueue_message(msg)\n            msg_was_enqueued = True\n\n        if msg_was_enqueued:\n            # Get a DeltaGenerator that is locked to the current element\n            # position.\n            new_cursor = (\n                dg._cursor.get_locked_cursor(\n                    delta_type=delta_type, add_rows_metadata=add_rows_metadata\n                )\n                if dg._cursor is not None\n                else None\n            )\n\n            output_dg = DeltaGenerator(\n                root_container=dg._root_container,\n                cursor=new_cursor,\n                parent=dg,\n            )\n        else:\n            # If the message was not enqueued, just return self since it's a\n            # no-op from the point of view of the app.\n            output_dg = dg\n\n        # Save message for replay if we're called from within @st.cache_data or @st.cache_resource\n        caching.save_element_message(\n            delta_type,\n            element_proto,\n            invoked_dg_id=self.id,\n            used_dg_id=dg.id,\n            returned_dg_id=output_dg.id,\n        )\n\n        return output_dg\n\n    def _block(\n        self,\n        block_proto: Block_pb2.Block = Block_pb2.Block(),\n        dg_type: type | None = None,\n    ) -> DeltaGenerator:\n        # Operate on the active DeltaGenerator, in case we're in a `with` block.\n        dg = self._active_dg\n\n        # Prevent nested columns & expanders by checking all parents.\n        block_type = block_proto.WhichOneof(\"type\")\n        # Convert the generator to a list, so we can use it multiple times.\n        ancestor_block_types = list(dg._ancestor_block_types)\n        _check_nested_element_violation(self, block_type, ancestor_block_types)\n\n        if dg._root_container is None or dg._cursor is None:\n            return dg\n\n        msg = ForwardMsg_pb2.ForwardMsg()\n        msg.metadata.delta_path[:] = dg._cursor.delta_path\n        msg.delta.add_block.CopyFrom(block_proto)\n\n        # Normally we'd return a new DeltaGenerator that uses the locked cursor\n        # below. But in this case we want to return a DeltaGenerator that uses\n        # a brand new cursor for this new block we're creating.\n        block_cursor = cursor.RunningCursor(\n            root_container=dg._root_container,\n            parent_path=dg._cursor.parent_path + (dg._cursor.index,),\n        )\n\n        # `dg_type` param added for st.status container. It allows us to\n        # instantiate DeltaGenerator subclasses from the function.\n        if dg_type is None:\n            dg_type = DeltaGenerator\n\n        block_dg = cast(\n            DeltaGenerator,\n            dg_type(\n                root_container=dg._root_container,\n                cursor=block_cursor,\n                parent=dg,\n                block_type=block_type,\n            ),\n        )\n        # Blocks inherit their parent form ids.\n        # NOTE: Container form ids aren't set in proto.\n        block_dg._form_data = FormData(current_form_id(dg))\n\n        # Must be called to increment this cursor's index.\n        dg._cursor.get_locked_cursor(add_rows_metadata=None)\n        _enqueue_message(msg)\n\n        caching.save_block_message(\n            block_proto,\n            invoked_dg_id=self.id,\n            used_dg_id=dg.id,\n            returned_dg_id=block_dg.id,\n        )\n\n        return block_dg\n\n    def _arrow_add_rows(\n        self: DG,\n        data: Data = None,\n        **kwargs: (\n            DataFrame | npt.NDArray[Any] | Iterable[Any] | dict[Hashable, Any] | None\n        ),\n    ) -> DG | None:\n        \"\"\"Concatenate a dataframe to the bottom of the current one.\n\n        Parameters\n        ----------\n        data : pandas.DataFrame, pandas.Styler, numpy.ndarray, Iterable, dict, or None\n            Table to concat. Optional.\n\n        **kwargs : pandas.DataFrame, numpy.ndarray, Iterable, dict, or None\n            The named dataset to concat. Optional. You can only pass in 1\n            dataset (including the one in the data parameter).\n\n        Example\n        -------\n        >>> import streamlit as st\n        >>> import pandas as pd\n        >>> import numpy as np\n        >>>\n        >>> df1 = pd.DataFrame(\n        ...    np.random.randn(50, 20),\n        ...    columns=('col %d' % i for i in range(20)))\n        ...\n        >>> my_table = st.table(df1)\n        >>>\n        >>> df2 = pd.DataFrame(\n        ...    np.random.randn(50, 20),\n        ...    columns=('col %d' % i for i in range(20)))\n        ...\n        >>> my_table.add_rows(df2)\n        >>> # Now the table shown in the Streamlit app contains the data for\n        >>> # df1 followed by the data for df2.\n\n        You can do the same thing with plots. For example, if you want to add\n        more data to a line chart:\n\n        >>> # Assuming df1 and df2 from the example above still exist...\n        >>> my_chart = st.line_chart(df1)\n        >>> my_chart.add_rows(df2)\n        >>> # Now the chart shown in the Streamlit app contains the data for\n        >>> # df1 followed by the data for df2.\n\n        And for plots whose datasets are named, you can pass the data with a\n        keyword argument where the key is the name:\n\n        >>> my_chart = st.vega_lite_chart({\n        ...     'mark': 'line',\n        ...     'encoding': {'x': 'a', 'y': 'b'},\n        ...     'datasets': {\n        ...       'some_fancy_name': df1,  # <-- named dataset\n        ...      },\n        ...     'data': {'name': 'some_fancy_name'},\n        ... }),\n        >>> my_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword\n\n        \"\"\"\n        if self._root_container is None or self._cursor is None:\n            return self\n\n        if not self._cursor.is_locked:\n            raise StreamlitAPIException(\"Only existing elements can `add_rows`.\")\n\n        # Accept syntax st._arrow_add_rows(df).\n        if data is not None and len(kwargs) == 0:\n            name = \"\"\n        # Accept syntax st._arrow_add_rows(foo=df).\n        elif len(kwargs) == 1:\n            name, data = kwargs.popitem()\n        # Raise error otherwise.\n        else:\n            raise StreamlitAPIException(\n                \"Wrong number of arguments to add_rows().\"\n                \"Command requires exactly one dataset\"\n            )\n\n        # When doing _arrow_add_rows on an element that does not already have data\n        # (for example, st.line_chart() without any args), call the original\n        # st.foo() element with new data instead of doing a _arrow_add_rows().\n        if (\n            \"add_rows_metadata\" in self._cursor.props\n            and self._cursor.props[\"add_rows_metadata\"]\n            and self._cursor.props[\"add_rows_metadata\"].last_index is None\n        ):\n            st_method = getattr(\n                self, self._cursor.props[\"add_rows_metadata\"].chart_command\n            )\n            st_method(data, **kwargs)\n            return None\n\n        new_data, self._cursor.props[\"add_rows_metadata\"] = _prep_data_for_add_rows(\n            data,\n            self._cursor.props[\"add_rows_metadata\"],\n        )\n\n        msg = ForwardMsg_pb2.ForwardMsg()\n        msg.metadata.delta_path[:] = self._cursor.delta_path\n\n        import streamlit.elements.arrow as arrow_proto\n\n        default_uuid = str(hash(self._get_delta_path_str()))\n        arrow_proto.marshall(msg.delta.arrow_add_rows.data, new_data, default_uuid)\n\n        if name:\n            msg.delta.arrow_add_rows.name = name\n            msg.delta.arrow_add_rows.has_name = True\n\n        _enqueue_message(msg)\n\n        return self\n\n\nmain_dg = DeltaGenerator(root_container=RootContainer.MAIN)\nsidebar_dg = DeltaGenerator(root_container=RootContainer.SIDEBAR, parent=main_dg)\nevent_dg = DeltaGenerator(root_container=RootContainer.EVENT, parent=main_dg)\nbottom_dg = DeltaGenerator(root_container=RootContainer.BOTTOM, parent=main_dg)\n\n\n# The dg_stack tracks the currently active DeltaGenerator, and is pushed to when\n# a DeltaGenerator is entered via a `with` block. This is implemented as a ContextVar\n# so that different threads or async tasks can have their own stacks.\ndef get_default_dg_stack() -> tuple[DeltaGenerator, ...]:\n    return (main_dg,)\n\n\ndg_stack: ContextVar[tuple[DeltaGenerator, ...]] = ContextVar(\n    \"dg_stack\", default=get_default_dg_stack()\n)\n\n\ndef get_last_dg_added_to_context_stack() -> DeltaGenerator | None:\n    \"\"\"Get the last added DeltaGenerator of the stack in the current context.\n\n    Returns None if the stack has only one element or is empty for whatever reason.\n    \"\"\"\n    current_stack = dg_stack.get()\n    # If set to \"> 0\" and thus return the only delta generator in the stack - which logically makes more sense -, some unit tests\n    # fail. It looks like the reason is that they create their own main delta generator but do not populate the dg_stack correctly. However, to be on the safe-side,\n    # we keep the logic but leave the comment as shared knowledge for whoever will look into this in the future.\n    if len(current_stack) > 1:\n        return current_stack[-1]\n    return None\n\n\ndef _prep_data_for_add_rows(\n    data: Data,\n    add_rows_metadata: AddRowsMetadata | None,\n) -> tuple[Data, AddRowsMetadata | None]:\n    if not add_rows_metadata:\n        # When calling add_rows on st.table or st.dataframe we want styles to pass through.\n        return type_util.convert_anything_to_df(data, allow_styler=True), None\n\n    # If add_rows_metadata is set, it indicates that the add_rows used called\n    # on a chart based on our built-in chart commands.\n\n    # For built-in chart commands we have to reshape the data structure\n    # otherwise the input data and the actual data used\n    # by vega_lite will be different, and it will throw an error.\n    from streamlit.elements.lib.built_in_chart_utils import prep_chart_data_for_add_rows\n\n    return prep_chart_data_for_add_rows(data, add_rows_metadata)\n\n\ndef _enqueue_message(msg: ForwardMsg_pb2.ForwardMsg) -> None:\n    \"\"\"Enqueues a ForwardMsg proto to send to the app.\"\"\"\n    ctx = get_script_run_ctx()\n\n    if ctx is None:\n        raise NoSessionContext()\n\n    if ctx.current_fragment_id and msg.WhichOneof(\"type\") == \"delta\":\n        msg.delta.fragment_id = ctx.current_fragment_id\n\n    ctx.enqueue(msg)\n\n\ndef _writes_directly_to_sidebar(dg: DG) -> bool:\n    in_sidebar = any(a._root_container == RootContainer.SIDEBAR for a in dg._ancestors)\n    has_container = bool(len(list(dg._ancestor_block_types)))\n    return in_sidebar and not has_container\n\n\ndef _check_nested_element_violation(\n    dg: DeltaGenerator, block_type: str | None, ancestor_block_types: list[BlockType]\n) -> None:\n    \"\"\"Check if elements are nested in a forbidden way.\n\n    Raises\n    ------\n      StreamlitAPIException: throw if an invalid element nesting is detected.\n    \"\"\"\n\n    if block_type == \"column\":\n        num_of_parent_columns = dg._count_num_of_parent_columns(ancestor_block_types)\n        if dg._root_container == RootContainer.SIDEBAR and num_of_parent_columns > 0:\n            raise StreamlitAPIException(\n                \"Columns cannot be placed inside other columns in the sidebar. This is only possible in the main area of the app.\"\n            )\n        if num_of_parent_columns > 1:\n            raise StreamlitAPIException(\n                \"Columns can only be placed inside other columns up to one level of nesting.\"\n            )\n    if block_type == \"chat_message\" and block_type in ancestor_block_types:\n        raise StreamlitAPIException(\n            \"Chat messages cannot nested inside other chat messages.\"\n        )\n    if block_type == \"expandable\" and block_type in ancestor_block_types:\n        raise StreamlitAPIException(\n            \"Expanders may not be nested inside other expanders.\"\n        )\n    if block_type == \"popover\" and block_type in ancestor_block_types:\n        raise StreamlitAPIException(\"Popovers may not be nested inside other popovers.\")\n", "lib/streamlit/development.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Variables for dev purposes.\n\nThe main purpose of this module (right now at least) is to avoid a dependency\ncycle between streamlit.config and streamlit.logger.\n\"\"\"\n\nis_development_mode = False\n", "lib/streamlit/temporary_directory.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport shutil\nimport tempfile\n\nfrom streamlit import util\n\n# We provide our own context manager for temporary directory that wraps\n# tempfile.mkdtemp\n\n\nclass TemporaryDirectory:\n    \"\"\"Temporary directory context manager.\n\n    Creates a temporary directory that exists within the context manager scope.\n    It returns the path to the created directory.\n    Wrapper on top of tempfile.mkdtemp.\n\n    Parameters\n    ----------\n    suffix : str or None\n        Suffix to the filename.\n    prefix : str or None\n        Prefix to the filename.\n    dir : str or None\n        Enclosing directory.\n\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        self._args = args\n        self._kwargs = kwargs\n\n    def __repr__(self) -> str:\n        return util.repr_(self)\n\n    def __enter__(self):\n        self._path = tempfile.mkdtemp(*self._args, **self._kwargs)\n        return self._path\n\n    def __exit__(self, exc_type, exc_value, exc_traceback):\n        shutil.rmtree(self._path)\n", "lib/streamlit/config_util.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport re\n\nfrom streamlit import cli_util\nfrom streamlit.config_option import ConfigOption\n\n\ndef server_option_changed(\n    old_options: dict[str, ConfigOption], new_options: dict[str, ConfigOption]\n) -> bool:\n    \"\"\"Return True if and only if an option in the server section differs\n    between old_options and new_options.\n    \"\"\"\n    for opt_name in old_options.keys():\n        if not opt_name.startswith(\"server\"):\n            continue\n\n        old_val = old_options[opt_name].value\n        new_val = new_options[opt_name].value\n        if old_val != new_val:\n            return True\n\n    return False\n\n\ndef show_config(\n    section_descriptions: dict[str, str],\n    config_options: dict[str, ConfigOption],\n) -> None:\n    \"\"\"Print the given config sections/options to the terminal.\"\"\"\n\n    out = []\n    out.append(\n        _clean(\n            \"\"\"\n        # Below are all the sections and options you can have in\n        ~/.streamlit/config.toml.\n    \"\"\"\n        )\n    )\n\n    def append_desc(text):\n        out.append(\"# \" + cli_util.style_for_cli(text, bold=True))\n\n    def append_comment(text):\n        out.append(\"# \" + cli_util.style_for_cli(text))\n\n    def append_section(text):\n        out.append(cli_util.style_for_cli(text, bold=True, fg=\"green\"))\n\n    def append_setting(text):\n        out.append(cli_util.style_for_cli(text, fg=\"green\"))\n\n    for section, _ in section_descriptions.items():\n        # We inject a fake config section used for unit tests that we exclude here as\n        # its options are often missing required properties, which confuses the code\n        # below.\n        if section == \"_test\":\n            continue\n\n        section_options = {\n            k: v\n            for k, v in config_options.items()\n            if v.section == section and v.visibility == \"visible\" and not v.is_expired()\n        }\n\n        # Only show config header if section is non-empty.\n        if len(section_options) == 0:\n            continue\n\n        out.append(\"\")\n        append_section(\"[%s]\" % section)\n        out.append(\"\")\n\n        for key, option in section_options.items():\n            key = option.key.split(\".\")[1]\n            description_paragraphs = _clean_paragraphs(option.description or \"\")\n\n            last_paragraph_idx = len(description_paragraphs) - 1\n\n            for i, paragraph in enumerate(description_paragraphs):\n                # Split paragraph into lines\n                lines = paragraph.rstrip().split(\n                    \"\\n\"\n                )  # Remove trailing newline characters\n\n                # If the first line is empty, remove it\n                if lines and not lines[0].strip():\n                    lines = lines[1:]\n\n                # Choose function based on whether it's the first paragraph or not\n                append_func = append_desc if i == 0 else append_comment\n\n                # Add comment character to each line and add to out\n                for line in lines:\n                    append_func(line.lstrip())\n\n                # # Add a line break after a paragraph only if it's not the last paragraph\n                if i != last_paragraph_idx:\n                    out.append(\"\")\n\n            import toml\n\n            toml_default = toml.dumps({\"default\": option.default_val})\n            toml_default = toml_default[10:].strip()\n\n            if len(toml_default) > 0:\n                # Ensure a line break before appending \"Default\" comment, if not already there\n                if out[-1] != \"\":\n                    out.append(\"\")\n                append_comment(\"Default: %s\" % toml_default)\n            else:\n                # Don't say \"Default: (unset)\" here because this branch applies\n                # to complex config settings too.\n                pass\n\n            if option.deprecated:\n                append_comment(cli_util.style_for_cli(\"DEPRECATED.\", fg=\"yellow\"))\n                for line in _clean_paragraphs(option.deprecation_text):\n                    append_comment(line)\n                append_comment(\n                    \"This option will be removed on or after %s.\"\n                    % option.expiration_date\n                )\n\n            option_is_manually_set = (\n                option.where_defined != ConfigOption.DEFAULT_DEFINITION\n            )\n\n            if option_is_manually_set:\n                append_comment(\"The value below was set in %s\" % option.where_defined)\n\n            toml_setting = toml.dumps({key: option.value})\n\n            if len(toml_setting) == 0:\n                toml_setting = f\"# {key} =\\n\"\n            elif not option_is_manually_set:\n                toml_setting = f\"# {toml_setting}\"\n\n            append_setting(toml_setting)\n\n    cli_util.print_to_cli(\"\\n\".join(out))\n\n\ndef _clean(txt: str) -> str:\n    \"\"\"Replace sequences of multiple spaces with a single space, excluding newlines.\n\n    Preserves leading and trailing spaces, and does not modify spaces in between lines.\n    \"\"\"\n    return re.sub(\" +\", \" \", txt)\n\n\ndef _clean_paragraphs(txt: str) -> list[str]:\n    \"\"\"Split the text into paragraphs, preserve newlines within the paragraphs.\"\"\"\n    # Strip both leading and trailing newlines.\n    txt = txt.strip(\"\\n\")\n    paragraphs = txt.split(\"\\n\\n\")\n    cleaned_paragraphs = [\n        \"\\n\".join(_clean(line) for line in paragraph.split(\"\\n\"))\n        for paragraph in paragraphs\n    ]\n    return cleaned_paragraphs\n", "lib/streamlit/version.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom importlib.metadata import version as _version\nfrom typing import Final\n\nSTREAMLIT_VERSION_STRING: Final[str] = _version(\"streamlit\")\n", "lib/streamlit/util.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"A bunch of useful utilities.\"\"\"\n\nfrom __future__ import annotations\n\nimport dataclasses\nimport functools\nimport hashlib\nimport os\nimport subprocess\nimport sys\nfrom typing import Any, Callable, Final, Iterable, Mapping, TypeVar\n\nfrom streamlit import env_util\n\n# URL of Streamlit's help page.\nHELP_DOC: Final = \"https://docs.streamlit.io/\"\nFLOAT_EQUALITY_EPSILON: Final[float] = 0.000000000005\n\n# Due to security issue in md5 and sha1, usedforsecurity\n# argument is added to hashlib for python versions higher than 3.8\nHASHLIB_KWARGS: dict[str, Any] = (\n    {\"usedforsecurity\": False} if sys.version_info >= (3, 9) else {}\n)\n\n\ndef memoize(func: Callable[..., Any]) -> Callable[..., Any]:\n    \"\"\"Decorator to memoize the result of a no-args func.\"\"\"\n    result: list[Any] = []\n\n    @functools.wraps(func)\n    def wrapped_func():\n        if not result:\n            result.append(func())\n        return result[0]\n\n    return wrapped_func\n\n\ndef open_browser(url: str) -> None:\n    \"\"\"Open a web browser pointing to a given URL.\n\n    We use this function instead of Python's `webbrowser` module because this\n    way we can capture stdout/stderr to avoid polluting the terminal with the\n    browser's messages. For example, Chrome always prints things like \"Created\n    new window in existing browser session\", and those get on the user's way.\n\n    url : str\n        The URL. Must include the protocol.\n\n    \"\"\"\n    # Treat Windows separately because:\n    # 1. /dev/null doesn't exist.\n    # 2. subprocess.Popen(['start', url]) doesn't actually pop up the\n    #    browser even though 'start url' works from the command prompt.\n    # Fun!\n    # Also, use webbrowser if we are on Linux and xdg-open is not installed.\n    #\n    # We don't use the webbrowser module on Linux and Mac because some browsers\n    # (ahem... Chrome) always print \"Opening in existing browser session\" to\n    # the terminal, which is spammy and annoying. So instead we start the\n    # browser ourselves and send all its output to /dev/null.\n\n    if env_util.IS_WINDOWS:\n        _open_browser_with_webbrowser(url)\n        return\n    if env_util.IS_LINUX_OR_BSD:\n        if env_util.is_executable_in_path(\"xdg-open\"):\n            _open_browser_with_command(\"xdg-open\", url)\n            return\n        _open_browser_with_webbrowser(url)\n        return\n    if env_util.IS_DARWIN:\n        _open_browser_with_command(\"open\", url)\n        return\n\n    import platform\n\n    raise Error('Cannot open browser in platform \"%s\"' % platform.system())\n\n\ndef _open_browser_with_webbrowser(url: str) -> None:\n    import webbrowser\n\n    webbrowser.open(url)\n\n\ndef _open_browser_with_command(command: str, url: str) -> None:\n    cmd_line = [command, url]\n    with open(os.devnull, \"w\") as devnull:\n        subprocess.Popen(cmd_line, stdout=devnull, stderr=subprocess.STDOUT)\n\n\ndef repr_(self: Any) -> str:\n    \"\"\"A clean repr for a class, excluding both values that are likely defaults,\n    and those explicitly default for dataclasses.\n    \"\"\"\n    classname = self.__class__.__name__\n    # Most of the falsey value, but excluding 0 and 0.0, since those often have\n    # semantic meaning within streamlit.\n    defaults: list[Any] = [None, \"\", False, [], set(), {}]\n    if dataclasses.is_dataclass(self):\n        fields_vals = (\n            (f.name, getattr(self, f.name))\n            for f in dataclasses.fields(self)\n            if f.repr\n            and getattr(self, f.name) != f.default\n            and getattr(self, f.name) not in defaults\n        )\n    else:\n        fields_vals = ((f, v) for (f, v) in self.__dict__.items() if v not in defaults)\n\n    field_reprs = \", \".join(f\"{field}={value!r}\" for field, value in fields_vals)\n    return f\"{classname}({field_reprs})\"\n\n\n_Value = TypeVar(\"_Value\")\n\n\ndef index_(iterable: Iterable[_Value], x: _Value) -> int:\n    \"\"\"Return zero-based index of the first item whose value is equal to x.\n    Raises a ValueError if there is no such item.\n\n    We need a custom implementation instead of the built-in list .index() to\n    be compatible with NumPy array and Pandas Series.\n\n    Parameters\n    ----------\n    iterable : list, tuple, numpy.ndarray, pandas.Series\n    x : Any\n\n    Returns\n    -------\n    int\n    \"\"\"\n    for i, value in enumerate(iterable):\n        if x == value:\n            return i\n        elif isinstance(value, float) and isinstance(x, float):\n            if abs(x - value) < FLOAT_EQUALITY_EPSILON:\n                return i\n    raise ValueError(f\"{str(x)} is not in iterable\")\n\n\n_Key = TypeVar(\"_Key\", bound=str)\n\n\ndef lower_clean_dict_keys(dict: Mapping[_Key, _Value]) -> dict[str, _Value]:\n    return {k.lower().strip(): v for k, v in dict.items()}\n\n\n# TODO: Move this into errors.py? Replace with StreamlitAPIException?\nclass Error(Exception):\n    pass\n\n\ndef calc_md5(s: bytes | str) -> str:\n    \"\"\"Return the md5 hash of the given string.\"\"\"\n    h = hashlib.new(\"md5\", **HASHLIB_KWARGS)\n\n    b = s.encode(\"utf-8\") if isinstance(s, str) else s\n\n    h.update(b)\n    return h.hexdigest()\n\n\ndef exclude_keys_in_dict(\n    d: dict[str, Any], keys_to_exclude: list[str]\n) -> dict[str, Any]:\n    \"\"\"Returns new object but without keys defined in keys_to_exclude\"\"\"\n    return {\n        key: value for key, value in d.items() if key.lower() not in keys_to_exclude\n    }\n\n\ndef extract_key_query_params(\n    query_params: dict[str, list[str]], param_key: str\n) -> set[str]:\n    \"\"\"Extracts key (case-insensitive) query params from Dict, and returns them as Set of str.\"\"\"\n    return {\n        item.lower()\n        for sublist in [\n            [value.lower() for value in query_params[key]]\n            for key in query_params.keys()\n            if key.lower() == param_key and query_params.get(key)\n        ]\n        for item in sublist\n    }\n", "lib/streamlit/string_util.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport re\nimport textwrap\nfrom typing import TYPE_CHECKING, Any, Final, cast\n\nfrom streamlit.errors import StreamlitAPIException\n\nif TYPE_CHECKING:\n    from streamlit.type_util import SupportsStr\n\n_ALPHANUMERIC_CHAR_REGEX: Final = re.compile(r\"^[a-zA-Z0-9_&\\-\\. ]+$\")\n\n\ndef decode_ascii(string: bytes) -> str:\n    \"\"\"Decodes a string as ascii.\"\"\"\n    return string.decode(\"ascii\")\n\n\ndef clean_text(text: SupportsStr) -> str:\n    \"\"\"Convert an object to text, dedent it, and strip whitespace.\"\"\"\n    return textwrap.dedent(str(text)).strip()\n\n\ndef _contains_special_chars(text: str) -> bool:\n    \"\"\"Check if a string contains any special chars.\n\n    Special chars in that case are all chars that are not\n    alphanumeric, underscore, hyphen or whitespace.\n    \"\"\"\n    return re.match(_ALPHANUMERIC_CHAR_REGEX, text) is None if text else False\n\n\ndef is_emoji(text: str) -> bool:\n    \"\"\"Check if input string is a valid emoji.\"\"\"\n    if not _contains_special_chars(text):\n        return False\n\n    from streamlit.emojis import ALL_EMOJIS\n\n    return text.replace(\"\\U0000fe0f\", \"\") in ALL_EMOJIS\n\n\ndef is_material_icon(maybe_icon: str) -> bool:\n    \"\"\"Check if input string is a valid Material icon.\"\"\"\n    from streamlit.material_icon_names import ALL_MATERIAL_ICONS\n\n    return maybe_icon in ALL_MATERIAL_ICONS\n\n\ndef validate_icon_or_emoji(icon: str | None) -> str:\n    \"\"\"Validate an icon or emoji and return it in normalized format if valid.\"\"\"\n    if icon is not None and icon.startswith(\":material\"):\n        return validate_material_icon(icon)\n    return validate_emoji(icon)\n\n\ndef validate_emoji(maybe_emoji: str | None) -> str:\n    if maybe_emoji is None:\n        return \"\"\n\n    elif is_emoji(maybe_emoji):\n        return maybe_emoji\n    else:\n        raise StreamlitAPIException(\n            f'The value \"{maybe_emoji}\" is not a valid emoji. Shortcodes are not allowed, please use a single character instead.'\n        )\n\n\ndef validate_material_icon(maybe_material_icon: str | None) -> str:\n    \"\"\"Validate a Material icon shortcode and return the icon in\n    normalized format if valid.\"\"\"\n\n    supported_icon_packs = [\n        \"material\",\n    ]\n\n    if maybe_material_icon is None:\n        return \"\"\n\n    icon_regex = r\"^\\s*:(.+)\\/(.+):\\s*$\"\n    icon_match = re.match(icon_regex, maybe_material_icon)\n\n    if not icon_match:\n        raise StreamlitAPIException(\n            f'The value `\"{maybe_material_icon}\"` is not a valid Material icon. '\n            f\"Please use a Material icon shortcode like **`:material/thumb_up:`**\"\n        )\n\n    pack_name, icon_name = icon_match.groups()\n\n    if (\n        pack_name not in supported_icon_packs\n        or not icon_name\n        or not is_material_icon(icon_name)\n    ):\n        raise StreamlitAPIException(\n            f'The value `\"{maybe_material_icon}\"` is not a valid Material icon.'\n            f\" Please use a Material icon shortcode like **`:material/thumb_up:`**. \"\n        )\n\n    return f\":{pack_name}/{icon_name}:\"\n\n\ndef extract_leading_emoji(text: str) -> tuple[str, str]:\n    \"\"\"Return a tuple containing the first emoji found in the given string and\n    the rest of the string (minus an optional separator between the two).\n    \"\"\"\n\n    if not _contains_special_chars(text):\n        # If the string only contains basic alphanumerical chars and/or\n        # underscores, hyphen & whitespaces, then it's guaranteed that there\n        # is no emoji in the string.\n        return \"\", text\n\n    from streamlit.emojis import EMOJI_EXTRACTION_REGEX\n\n    re_match = re.search(EMOJI_EXTRACTION_REGEX, text)\n    if re_match is None:\n        return \"\", text\n\n    # This cast to Any+type annotation weirdness is done because\n    # cast(re.Match[str], ...) explodes at runtime since Python interprets it\n    # as an attempt to index into re.Match instead of as a type annotation.\n    re_match: re.Match[str] = cast(Any, re_match)\n    return re_match.group(1), re_match.group(2)\n\n\ndef max_char_sequence(string: str, char: str) -> int:\n    \"\"\"Returns the count of the max sequence of a given char in a string.\"\"\"\n    max_sequence = 0\n    current_sequence = 0\n    for c in string:\n        if c == char:\n            current_sequence += 1\n            max_sequence = max(max_sequence, current_sequence)\n        else:\n            current_sequence = 0\n\n    return max_sequence\n\n\nTEXTCHARS: Final = bytearray(\n    {7, 8, 9, 10, 12, 13, 27} | set(range(0x20, 0x100)) - {0x7F}\n)\n\n\ndef is_binary_string(inp: bytes) -> bool:\n    \"\"\"Guess if an input bytesarray can be encoded as a string.\"\"\"\n    # From https://stackoverflow.com/a/7392391\n    return bool(inp.translate(None, TEXTCHARS))\n\n\ndef simplify_number(num: int) -> str:\n    \"\"\"Simplifies number into Human readable format, returns str\"\"\"\n    num_converted = float(f\"{num:.2g}\")\n    magnitude = 0\n    while abs(num_converted) >= 1000:\n        magnitude += 1\n        num_converted /= 1000.0\n    return \"{}{}\".format(\n        f\"{num_converted:f}\".rstrip(\"0\").rstrip(\".\"),\n        [\"\", \"k\", \"m\", \"b\", \"t\"][magnitude],\n    )\n\n\n_OBJ_MEM_ADDRESS: Final = re.compile(\n    r\"^\\<[a-zA-Z_]+[a-zA-Z0-9<>._ ]* at 0x[0-9a-f]+\\>$\"\n)\n\n\ndef is_mem_address_str(string):\n    \"\"\"Returns True if the string looks like <foo blarg at 0x15ee6f9a0>.\"\"\"\n    if _OBJ_MEM_ADDRESS.match(string):\n        return True\n\n    return False\n\n\n_RE_CONTAINS_HTML: Final = re.compile(r\"(?:</[^<]+>)|(?:<[^<]+/>)\")\n\n\ndef probably_contains_html_tags(s: str) -> bool:\n    \"\"\"Returns True if the given string contains what seem to be HTML tags.\n\n    Note that false positives/negatives are possible, so this function should not be\n    used in contexts where complete correctness is required.\"\"\"\n    return bool(_RE_CONTAINS_HTML.search(s))\n", "lib/streamlit/git_util.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport os\nimport re\nfrom typing import Any\n\nfrom streamlit import util\n\n# Github has two URLs, one that is https and one that is ssh\nGITHUB_HTTP_URL = r\"^https://(www\\.)?github.com/(.+)/(.+)(?:.git)?$\"\nGITHUB_SSH_URL = r\"^git@github.com:(.+)/(.+)(?:.git)?$\"\n\n# We don't support git < 2.7, because we can't get repo info without\n# talking to the remote server, which results in the user being prompted\n# for credentials.\nMIN_GIT_VERSION = (2, 7, 0)\n\n\nclass GitRepo:\n    def __init__(self, path):\n        # If we have a valid repo, git_version will be a tuple of 3+ ints:\n        # (major, minor, patch, possible_additional_patch_number)\n        self.git_version: tuple[int, ...] | None = None\n\n        try:\n            import git\n\n            # GitPython is not fully typed, and mypy is outputting inconsistent\n            # type errors on Mac and Linux. We bypass type checking entirely\n            # by re-declaring the `git` import as an \"Any\".\n            git_package: Any = git\n            self.repo = git_package.Repo(path, search_parent_directories=True)\n            self.git_version = self.repo.git.version_info\n\n            if self.git_version >= MIN_GIT_VERSION:\n                git_root = self.repo.git.rev_parse(\"--show-toplevel\")\n                self.module = os.path.relpath(path, git_root)\n        except Exception:\n            # The git repo must be invalid for the following reasons:\n            #  * git binary or GitPython not installed\n            #  * No .git folder\n            #  * Corrupted .git folder\n            #  * Path is invalid\n            self.repo = None\n\n    def __repr__(self) -> str:\n        return util.repr_(self)\n\n    def is_valid(self) -> bool:\n        \"\"\"True if there's a git repo here, and git.version >= MIN_GIT_VERSION.\"\"\"\n        return (\n            self.repo is not None\n            and self.git_version is not None\n            and self.git_version >= MIN_GIT_VERSION\n        )\n\n    @property\n    def tracking_branch(self):\n        if not self.is_valid():\n            return None\n\n        if self.is_head_detached:\n            return None\n\n        return self.repo.active_branch.tracking_branch()\n\n    @property\n    def untracked_files(self):\n        if not self.is_valid():\n            return None\n\n        return self.repo.untracked_files\n\n    @property\n    def is_head_detached(self):\n        if not self.is_valid():\n            return False\n\n        return self.repo.head.is_detached\n\n    @property\n    def uncommitted_files(self):\n        if not self.is_valid():\n            return None\n\n        return [item.a_path for item in self.repo.index.diff(None)]\n\n    @property\n    def ahead_commits(self):\n        if not self.is_valid():\n            return None\n\n        try:\n            remote, branch_name = self.get_tracking_branch_remote()\n            remote_branch = f\"{remote.name}/{branch_name}\"\n\n            return list(self.repo.iter_commits(f\"{remote_branch}..{branch_name}\"))\n        except Exception:\n            return []\n\n    def get_tracking_branch_remote(self):\n        if not self.is_valid():\n            return None\n\n        tracking_branch = self.tracking_branch\n\n        if tracking_branch is None:\n            return None\n\n        remote_name, *branch = tracking_branch.name.split(\"/\")\n        branch_name = \"/\".join(branch)\n\n        return self.repo.remote(remote_name), branch_name\n\n    def is_github_repo(self) -> bool:\n        if not self.is_valid():\n            return False\n\n        remote_info = self.get_tracking_branch_remote()\n        if remote_info is None:\n            return False\n\n        remote, _branch = remote_info\n\n        for url in remote.urls:\n            if (\n                re.match(GITHUB_HTTP_URL, url) is not None\n                or re.match(GITHUB_SSH_URL, url) is not None\n            ):\n                return True\n\n        return False\n\n    def get_repo_info(self):\n        if not self.is_valid():\n            return None\n\n        remote_info = self.get_tracking_branch_remote()\n        if remote_info is None:\n            return None\n\n        remote, branch = remote_info\n\n        repo = None\n        for url in remote.urls:\n            https_matches = re.match(GITHUB_HTTP_URL, url)\n            ssh_matches = re.match(GITHUB_SSH_URL, url)\n            if https_matches is not None:\n                repo = f\"{https_matches.group(2)}/{https_matches.group(3)}\"\n                break\n\n            if ssh_matches is not None:\n                repo = f\"{ssh_matches.group(1)}/{ssh_matches.group(2)}\"\n                break\n\n        if repo is None:\n            return None\n\n        return repo, branch, self.module\n", "lib/streamlit/constants.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nEMBED_QUERY_PARAM = \"embed\"\nEMBED_OPTIONS_QUERY_PARAM = \"embed_options\"\nEMBED_QUERY_PARAMS_KEYS = [EMBED_QUERY_PARAM, EMBED_OPTIONS_QUERY_PARAM]\n", "lib/streamlit/folder_black_list.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport os\n\nfrom streamlit import config, file_util, util\n\n# The files in the folders below should always be blacklisted.\nDEFAULT_FOLDER_BLACKLIST = [\n    \"**/.*\",\n    \"**/anaconda\",\n    \"**/anaconda2\",\n    \"**/anaconda3\",\n    \"**/dist-packages\",\n    \"**/miniconda\",\n    \"**/miniconda2\",\n    \"**/miniconda3\",\n    \"**/node_modules\",\n    \"**/pyenv\",\n    \"**/site-packages\",\n    \"**/venv\",\n    \"**/virtualenv\",\n]\n\n\nclass FolderBlackList:\n    \"\"\"Implement a black list object with globbing.\n\n    Note\n    ----\n    Blacklist any path that matches a glob in `DEFAULT_FOLDER_BLACKLIST`.\n\n    \"\"\"\n\n    def __init__(self, folder_blacklist):\n        \"\"\"Constructor.\n\n        Parameters\n        ----------\n        folder_blacklist : list of str\n            list of folder names with globbing to blacklist.\n\n        \"\"\"\n        self._folder_blacklist = list(folder_blacklist)\n        self._folder_blacklist.extend(DEFAULT_FOLDER_BLACKLIST)\n\n        # Add the Streamlit lib folder when in dev mode, since otherwise we end\n        # up with weird situations where the ID of a class in one run is not\n        # the same as in another run.\n        if config.get_option(\"global.developmentMode\"):\n            self._folder_blacklist.append(os.path.dirname(__file__))\n\n    def __repr__(self) -> str:\n        return util.repr_(self)\n\n    def is_blacklisted(self, filepath):\n        \"\"\"Test if filepath is in the blacklist.\n\n        Parameters\n        ----------\n        filepath : str\n            File path that we intend to test.\n\n        \"\"\"\n        return any(\n            file_util.file_is_in_folder_glob(filepath, blacklisted_folder)\n            for blacklisted_folder in self._folder_blacklist\n        )\n", "lib/streamlit/errors.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom streamlit import util\n\n\nclass Error(Exception):\n    \"\"\"The base class for all exceptions thrown by Streamlit.\n\n    Should be used for exceptions raised due to user errors (typically via\n    StreamlitAPIException) as well as exceptions raised by Streamlit's internal\n    code.\n    \"\"\"\n\n    pass\n\n\nclass CustomComponentError(Error):\n    \"\"\"Exceptions thrown in the custom components code path.\"\"\"\n\n    pass\n\n\nclass DeprecationError(Error):\n    pass\n\n\nclass NoStaticFiles(Error):\n    pass\n\n\nclass NoSessionContext(Error):\n    pass\n\n\nclass MarkdownFormattedException(Error):\n    \"\"\"Exceptions with Markdown in their description.\n\n    Instances of this class can use markdown in their messages, which will get\n    nicely formatted on the frontend.\n    \"\"\"\n\n    pass\n\n\nclass UncaughtAppException(Error):\n    \"\"\"Catchall exception type for uncaught exceptions that occur during script execution.\"\"\"\n\n    def __init__(self, exc):\n        self.exc = exc\n\n\nclass StreamlitAPIException(MarkdownFormattedException):\n    \"\"\"Base class for Streamlit API exceptions.\n\n    An API exception should be thrown when user code interacts with the\n    Streamlit API incorrectly. (That is, when we throw an exception as a\n    result of a user's malformed `st.foo` call, it should be a\n    StreamlitAPIException or subclass.)\n\n    When displaying these exceptions on the frontend, we strip Streamlit\n    entries from the stack trace so that the user doesn't see a bunch of\n    noise related to Streamlit internals.\n\n    \"\"\"\n\n    def __repr__(self) -> str:\n        return util.repr_(self)\n\n\nclass DuplicateWidgetID(StreamlitAPIException):\n    pass\n\n\nclass UnserializableSessionStateError(StreamlitAPIException):\n    pass\n\n\nclass StreamlitAPIWarning(StreamlitAPIException, Warning):\n    \"\"\"Used to display a warning.\n\n    Note that this should not be \"raised\", but passed to st.exception\n    instead.\n    \"\"\"\n\n    def __init__(self, *args):\n        super().__init__(*args)\n        import inspect\n        import traceback\n\n        f = inspect.currentframe()\n        self.tacked_on_stack = traceback.extract_stack(f)\n\n    def __repr__(self) -> str:\n        return util.repr_(self)\n\n\nclass StreamlitDeprecationWarning(StreamlitAPIWarning):\n    \"\"\"Used to display a warning.\n\n    Note that this should not be \"raised\", but passed to st.exception\n    instead.\n    \"\"\"\n\n    def __init__(self, config_option, msg, *args):\n        message = \"\"\"\n{0}\n\nYou can disable this warning by disabling the config option:\n`{1}`\n\n```\nst.set_option('{1}', False)\n```\nor in your `.streamlit/config.toml`\n```\n[deprecation]\n{2} = false\n```\n    \"\"\".format(msg, config_option, config_option.split(\".\")[1])\n        super().__init__(message, *args)\n\n    def __repr__(self) -> str:\n        return util.repr_(self)\n\n\nclass StreamlitModuleNotFoundError(StreamlitAPIWarning):\n    \"\"\"Print a pretty message when a Streamlit command requires a dependency\n    that is not one of our core dependencies.\"\"\"\n\n    def __init__(self, module_name, *args):\n        message = (\n            f'This Streamlit command requires module \"{module_name}\" to be '\n            \"installed.\"\n        )\n        super().__init__(message, *args)\n", "lib/streamlit/material_icon_names.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# We use material icon names from font codepoint: https://github.com/google/material-design-icons/blob/master/variablefont/MaterialSymbolsOutlined%5BFILL%2CGRAD%2Copsz%2Cwght%5D.codepoints\n# TODO[Kajarenc], we can create a CI job that actually generates new icon names based on\n#  the latest material icons condepoint file, and if it is different, update the font.\n\n# fmt: off\nALL_MATERIAL_ICONS = {\"10k\", \"10mp\", \"11mp\", \"123\", \"12mp\", \"13mp\", \"14mp\", \"15mp\", \"16mp\", \"17mp\", \"18_up_rating\", \"18mp\", \"19mp\", \"1k\", \"1k_plus\", \"1x_mobiledata\", \"1x_mobiledata_badge\", \"20mp\", \"21mp\", \"22mp\", \"23mp\", \"24mp\", \"2d\", \"2k\", \"2k_plus\", \"2mp\", \"30fps\", \"30fps_select\", \"360\", \"3d_rotation\", \"3g_mobiledata\", \"3g_mobiledata_badge\", \"3k\", \"3k_plus\", \"3mp\", \"3p\", \"4g_mobiledata\", \"4g_mobiledata_badge\", \"4g_plus_mobiledata\", \"4k\", \"4k_plus\", \"4mp\", \"50mp\", \"5g\", \"5g_mobiledata_badge\", \"5k\", \"5k_plus\", \"5mp\", \"60fps\", \"60fps_select\", \"6_ft_apart\", \"6k\", \"6k_plus\", \"6mp\", \"7k\", \"7k_plus\", \"7mp\", \"8k\", \"8k_plus\", \"8mp\", \"9k\", \"9k_plus\", \"9mp\", \"abc\", \"ac_unit\", \"access_alarm\", \"access_alarms\", \"access_time\", \"access_time_filled\", \"accessibility\", \"accessibility_new\", \"accessible\", \"accessible_forward\", \"account_balance\", \"account_balance_wallet\", \"account_box\", \"account_child\", \"account_child_invert\", \"account_circle\", \"account_circle_filled\", \"account_circle_off\", \"account_tree\", \"action_key\", \"activity_zone\", \"acute\", \"ad\", \"ad_group\", \"ad_group_off\", \"ad_off\", \"ad_units\", \"adb\", \"add\", \"add_a_photo\", \"add_ad\", \"add_alarm\", \"add_alert\", \"add_box\", \"add_business\", \"add_call\", \"add_card\", \"add_chart\", \"add_circle\", \"add_circle_outline\", \"add_comment\", \"add_home\", \"add_home_work\", \"add_ic_call\", \"add_link\", \"add_location\", \"add_location_alt\", \"add_moderator\", \"add_notes\", \"add_photo_alternate\", \"add_reaction\", \"add_road\", \"add_shopping_cart\", \"add_task\", \"add_to_drive\", \"add_to_home_screen\", \"add_to_photos\", \"add_to_queue\", \"addchart\", \"adf_scanner\", \"adjust\", \"admin_meds\", \"admin_panel_settings\", \"ads_click\", \"agender\", \"agriculture\", \"air\", \"air_freshener\", \"air_purifier\", \"air_purifier_gen\", \"airline_seat_flat\", \"airline_seat_flat_angled\", \"airline_seat_individual_suite\", \"airline_seat_legroom_extra\", \"airline_seat_legroom_normal\", \"airline_seat_legroom_reduced\", \"airline_seat_recline_extra\", \"airline_seat_recline_normal\", \"airline_stops\", \"airlines\", \"airplane_ticket\", \"airplanemode_active\", \"airplanemode_inactive\", \"airplay\", \"airport_shuttle\", \"airware\", \"airwave\", \"alarm\", \"alarm_add\", \"alarm_off\", \"alarm_on\", \"alarm_smart_wake\", \"album\", \"align_center\", \"align_end\", \"align_flex_center\", \"align_flex_end\", \"align_flex_start\", \"align_horizontal_center\", \"align_horizontal_left\", \"align_horizontal_right\", \"align_items_stretch\", \"align_justify_center\", \"align_justify_flex_end\", \"align_justify_flex_start\", \"align_justify_space_around\", \"align_justify_space_between\", \"align_justify_space_even\", \"align_justify_stretch\", \"align_self_stretch\", \"align_space_around\", \"align_space_between\", \"align_space_even\", \"align_start\", \"align_stretch\", \"align_vertical_bottom\", \"align_vertical_center\", \"align_vertical_top\", \"all_inbox\", \"all_inclusive\", \"all_match\", \"all_out\", \"allergies\", \"allergy\", \"alt_route\", \"alternate_email\", \"altitude\", \"ambient_screen\", \"ambulance\", \"amend\", \"amp_stories\", \"analytics\", \"anchor\", \"android\", \"animation\", \"announcement\", \"aod\", \"aod_tablet\", \"aod_watch\", \"apartment\", \"api\", \"apk_document\", \"apk_install\", \"app_badging\", \"app_blocking\", \"app_promo\", \"app_registration\", \"app_settings_alt\", \"app_shortcut\", \"apparel\", \"approval\", \"approval_delegation\", \"apps\", \"apps_outage\", \"aq\", \"aq_indoor\", \"ar_on_you\", \"ar_stickers\", \"architecture\", \"archive\", \"area_chart\", \"arming_countdown\", \"arrow_and_edge\", \"arrow_back\", \"arrow_back_ios\", \"arrow_back_ios_new\", \"arrow_circle_down\", \"arrow_circle_left\", \"arrow_circle_right\", \"arrow_circle_up\", \"arrow_downward\", \"arrow_downward_alt\", \"arrow_drop_down\", \"arrow_drop_down_circle\", \"arrow_drop_up\", \"arrow_forward\", \"arrow_forward_ios\", \"arrow_insert\", \"arrow_left\", \"arrow_left_alt\", \"arrow_or_edge\", \"arrow_outward\", \"arrow_range\", \"arrow_right\", \"arrow_right_alt\", \"arrow_selector_tool\", \"arrow_split\", \"arrow_top_left\", \"arrow_top_right\", \"arrow_upward\", \"arrow_upward_alt\", \"arrows_more_down\", \"arrows_more_up\", \"arrows_outward\", \"art_track\", \"article\", \"article_shortcut\", \"artist\", \"aspect_ratio\", \"assessment\", \"assignment\", \"assignment_add\", \"assignment_ind\", \"assignment_late\", \"assignment_return\", \"assignment_returned\", \"assignment_turned_in\", \"assist_walker\", \"assistant\", \"assistant_device\", \"assistant_direction\", \"assistant_navigation\", \"assistant_on_hub\", \"assistant_photo\", \"assured_workload\", \"asterisk\", \"astrophotography_auto\", \"astrophotography_off\", \"atm\", \"atr\", \"attach_email\", \"attach_file\", \"attach_file_add\", \"attach_file_off\", \"attach_money\", \"attachment\", \"attractions\", \"attribution\", \"audio_description\", \"audio_file\", \"audio_video_receiver\", \"audiotrack\", \"auto_activity_zone\", \"auto_awesome\", \"auto_awesome_mosaic\", \"auto_awesome_motion\", \"auto_delete\", \"auto_detect_voice\", \"auto_draw_solid\", \"auto_fix\", \"auto_fix_high\", \"auto_fix_normal\", \"auto_fix_off\", \"auto_graph\", \"auto_label\", \"auto_meeting_room\", \"auto_mode\", \"auto_read_pause\", \"auto_read_play\", \"auto_schedule\", \"auto_stories\", \"auto_timer\", \"auto_towing\", \"auto_transmission\", \"auto_videocam\", \"autofps_select\", \"autopause\", \"autopay\", \"autoplay\", \"autorenew\", \"autostop\", \"av_timer\", \"avg_pace\", \"avg_time\", \"award_star\", \"azm\", \"baby_changing_station\", \"back_hand\", \"back_to_tab\", \"background_dot_large\", \"background_dot_small\", \"background_grid_small\", \"background_replace\", \"backlight_high\", \"backlight_high_off\", \"backlight_low\", \"backpack\", \"backspace\", \"backup\", \"backup_table\", \"badge\", \"badge_critical_battery\", \"bakery_dining\", \"balance\", \"balcony\", \"ballot\", \"bar_chart\", \"bar_chart_4_bars\", \"barcode\", \"barcode_reader\", \"barcode_scanner\", \"barefoot\", \"batch_prediction\", \"bath_outdoor\", \"bath_private\", \"bath_public_large\", \"bathroom\", \"bathtub\", \"battery_0_bar\", \"battery_1_bar\", \"battery_20\", \"battery_2_bar\", \"battery_30\", \"battery_3_bar\", \"battery_4_bar\", \"battery_50\", \"battery_5_bar\", \"battery_60\", \"battery_6_bar\", \"battery_80\", \"battery_90\", \"battery_alert\", \"battery_change\", \"battery_charging_20\", \"battery_charging_30\", \"battery_charging_50\", \"battery_charging_60\", \"battery_charging_80\", \"battery_charging_90\", \"battery_charging_full\", \"battery_error\", \"battery_full\", \"battery_full_alt\", \"battery_horiz_000\", \"battery_horiz_050\", \"battery_horiz_075\", \"battery_low\", \"battery_plus\", \"battery_profile\", \"battery_saver\", \"battery_share\", \"battery_status_good\", \"battery_std\", \"battery_unknown\", \"battery_vert_005\", \"battery_vert_020\", \"battery_vert_050\", \"battery_very_low\", \"beach_access\", \"bed\", \"bedroom_baby\", \"bedroom_child\", \"bedroom_parent\", \"bedtime\", \"bedtime_off\", \"beenhere\", \"bento\", \"bia\", \"bid_landscape\", \"bid_landscape_disabled\", \"bigtop_updates\", \"bike_scooter\", \"biotech\", \"blanket\", \"blender\", \"blind\", \"blinds\", \"blinds_closed\", \"block\", \"blood_pressure\", \"bloodtype\", \"bluetooth\", \"bluetooth_audio\", \"bluetooth_connected\", \"bluetooth_disabled\", \"bluetooth_drive\", \"bluetooth_searching\", \"blur_circular\", \"blur_linear\", \"blur_medium\", \"blur_off\", \"blur_on\", \"blur_short\", \"body_fat\", \"body_system\", \"bolt\", \"bomb\", \"book\", \"book_2\", \"book_3\", \"book_4\", \"book_5\", \"book_online\", \"bookmark\", \"bookmark_add\", \"bookmark_added\", \"bookmark_border\", \"bookmark_manager\", \"bookmark_remove\", \"bookmarks\", \"border_all\", \"border_bottom\", \"border_clear\", \"border_color\", \"border_horizontal\", \"border_inner\", \"border_left\", \"border_outer\", \"border_right\", \"border_style\", \"border_top\", \"border_vertical\", \"bottom_app_bar\", \"bottom_drawer\", \"bottom_navigation\", \"bottom_panel_close\", \"bottom_panel_open\", \"bottom_right_click\", \"bottom_sheets\", \"box\", \"box_add\", \"box_edit\", \"boy\", \"brand_awareness\", \"brand_family\", \"branding_watermark\", \"breakfast_dining\", \"breaking_news\", \"breaking_news_alt_1\", \"breastfeeding\", \"brightness_1\", \"brightness_2\", \"brightness_3\", \"brightness_4\", \"brightness_5\", \"brightness_6\", \"brightness_7\", \"brightness_alert\", \"brightness_auto\", \"brightness_empty\", \"brightness_high\", \"brightness_low\", \"brightness_medium\", \"bring_your_own_ip\", \"broadcast_on_home\", \"broadcast_on_personal\", \"broken_image\", \"browse\", \"browse_activity\", \"browse_gallery\", \"browser_not_supported\", \"browser_updated\", \"brunch_dining\", \"brush\", \"bubble\", \"bubble_chart\", \"bubbles\", \"bug_report\", \"build\", \"build_circle\", \"bungalow\", \"burst_mode\", \"bus_alert\", \"business\", \"business_center\", \"business_chip\", \"business_messages\", \"buttons_alt\", \"cabin\", \"cable\", \"cached\", \"cake\", \"cake_add\", \"calculate\", \"calendar_add_on\", \"calendar_apps_script\", \"calendar_clock\", \"calendar_month\", \"calendar_today\", \"calendar_view_day\", \"calendar_view_month\", \"calendar_view_week\", \"call\", \"call_end\", \"call_end_alt\", \"call_log\", \"call_made\", \"call_merge\", \"call_missed\", \"call_missed_outgoing\", \"call_quality\", \"call_received\", \"call_split\", \"call_to_action\", \"camera\", \"camera_alt\", \"camera_enhance\", \"camera_front\", \"camera_indoor\", \"camera_outdoor\", \"camera_rear\", \"camera_roll\", \"camera_video\", \"cameraswitch\", \"campaign\", \"camping\", \"cancel\", \"cancel_presentation\", \"cancel_schedule_send\", \"candle\", \"candlestick_chart\", \"captive_portal\", \"capture\", \"car_crash\", \"car_rental\", \"car_repair\", \"car_tag\", \"card_giftcard\", \"card_membership\", \"card_travel\", \"cardiology\", \"cards\", \"carpenter\", \"carry_on_bag\", \"carry_on_bag_checked\", \"carry_on_bag_inactive\", \"carry_on_bag_question\", \"cases\", \"casino\", \"cast\", \"cast_connected\", \"cast_for_education\", \"cast_pause\", \"cast_warning\", \"castle\", \"category\", \"celebration\", \"cell_merge\", \"cell_tower\", \"cell_wifi\", \"center_focus_strong\", \"center_focus_weak\", \"chair\", \"chair_alt\", \"chalet\", \"change_circle\", \"change_history\", \"charger\", \"charging_station\", \"chart_data\", \"chat\", \"chat_add_on\", \"chat_apps_script\", \"chat_bubble\", \"chat_bubble_outline\", \"chat_error\", \"chat_info\", \"chat_paste_go\", \"check\", \"check_box\", \"check_box_outline_blank\", \"check_circle\", \"check_circle_filled\", \"check_circle_outline\", \"check_in_out\", \"check_indeterminate_small\", \"check_small\", \"checkbook\", \"checked_bag\", \"checked_bag_question\", \"checklist\", \"checklist_rtl\", \"checkroom\", \"cheer\", \"chess\", \"chevron_left\", \"chevron_right\", \"child_care\", \"child_friendly\", \"chip_extraction\", \"chips\", \"chrome_reader_mode\", \"chromecast_2\", \"chromecast_device\", \"chronic\", \"church\", \"cinematic_blur\", \"circle\", \"circle_notifications\", \"circles\", \"circles_ext\", \"clarify\", \"class\", \"clean_hands\", \"cleaning\", \"cleaning_bucket\", \"cleaning_services\", \"clear\", \"clear_all\", \"clear_day\", \"clear_night\", \"climate_mini_split\", \"clinical_notes\", \"clock_loader_10\", \"clock_loader_20\", \"clock_loader_40\", \"clock_loader_60\", \"clock_loader_80\", \"clock_loader_90\", \"close\", \"close_fullscreen\", \"close_small\", \"closed_caption\", \"closed_caption_disabled\", \"closed_caption_off\", \"cloud\", \"cloud_circle\", \"cloud_done\", \"cloud_download\", \"cloud_off\", \"cloud_queue\", \"cloud_sync\", \"cloud_upload\", \"cloudy\", \"cloudy_filled\", \"cloudy_snowing\", \"co2\", \"co_present\", \"code\", \"code_blocks\", \"code_off\", \"coffee\", \"coffee_maker\", \"cognition\", \"collapse_all\", \"collapse_content\", \"collections\", \"collections_bookmark\", \"color_lens\", \"colorize\", \"colors\", \"comedy_mask\", \"comic_bubble\", \"comment\", \"comment_bank\", \"comments_disabled\", \"commit\", \"communication\", \"communities\", \"communities_filled\", \"commute\", \"compare\", \"compare_arrows\", \"compass_calibration\", \"component_exchange\", \"compost\", \"compress\", \"computer\", \"concierge\", \"conditions\", \"confirmation_number\", \"congenital\", \"connect_without_contact\", \"connected_tv\", \"connecting_airports\", \"construction\", \"contact_emergency\", \"contact_mail\", \"contact_page\", \"contact_phone\", \"contact_phone_filled\", \"contact_support\", \"contactless\", \"contactless_off\", \"contacts\", \"contacts_product\", \"content_copy\", \"content_cut\", \"content_paste\", \"content_paste_go\", \"content_paste_off\", \"content_paste_search\", \"contract\", \"contract_delete\", \"contract_edit\", \"contrast\", \"contrast_rtl_off\", \"control_camera\", \"control_point\", \"control_point_duplicate\", \"controller_gen\", \"conversion_path\", \"conversion_path_off\", \"conveyor_belt\", \"cookie\", \"cookie_off\", \"cooking\", \"cool_to_dry\", \"copy_all\", \"copyright\", \"coronavirus\", \"corporate_fare\", \"cottage\", \"counter_0\", \"counter_1\", \"counter_2\", \"counter_3\", \"counter_4\", \"counter_5\", \"counter_6\", \"counter_7\", \"counter_8\", \"counter_9\", \"countertops\", \"create\", \"create_new_folder\", \"credit_card\", \"credit_card_gear\", \"credit_card_heart\", \"credit_card_off\", \"credit_score\", \"crib\", \"crisis_alert\", \"crop\", \"crop_16_9\", \"crop_3_2\", \"crop_5_4\", \"crop_7_5\", \"crop_9_16\", \"crop_din\", \"crop_free\", \"crop_landscape\", \"crop_original\", \"crop_portrait\", \"crop_rotate\", \"crop_square\", \"crossword\", \"crowdsource\", \"cruelty_free\", \"css\", \"csv\", \"currency_bitcoin\", \"currency_exchange\", \"currency_franc\", \"currency_lira\", \"currency_pound\", \"currency_ruble\", \"currency_rupee\", \"currency_yen\", \"currency_yuan\", \"curtains\", \"curtains_closed\", \"custom_typography\", \"cut\", \"cycle\", \"cyclone\", \"dangerous\", \"dark_mode\", \"dashboard\", \"dashboard_customize\", \"data_alert\", \"data_array\", \"data_check\", \"data_exploration\", \"data_info_alert\", \"data_loss_prevention\", \"data_object\", \"data_saver_off\", \"data_saver_on\", \"data_table\", \"data_thresholding\", \"data_usage\", \"database\", \"dataset\", \"dataset_linked\", \"date_range\", \"deblur\", \"deceased\", \"decimal_decrease\", \"decimal_increase\", \"deck\", \"dehaze\", \"delete\", \"delete_forever\", \"delete_history\", \"delete_outline\", \"delete_sweep\", \"demography\", \"density_large\", \"density_medium\", \"density_small\", \"dentistry\", \"departure_board\", \"deployed_code\", \"deployed_code_account\", \"deployed_code_alert\", \"deployed_code_history\", \"deployed_code_update\", \"dermatology\", \"description\", \"deselect\", \"design_services\", \"desk\", \"deskphone\", \"desktop_access_disabled\", \"desktop_mac\", \"desktop_windows\", \"destruction\", \"details\", \"detection_and_zone\", \"detector\", \"detector_alarm\", \"detector_battery\", \"detector_co\", \"detector_offline\", \"detector_smoke\", \"detector_status\", \"developer_board\", \"developer_board_off\", \"developer_guide\", \"developer_mode\", \"developer_mode_tv\", \"device_hub\", \"device_reset\", \"device_thermostat\", \"device_unknown\", \"devices\", \"devices_fold\", \"devices_off\", \"devices_other\", \"devices_wearables\", \"dew_point\", \"diagnosis\", \"dialer_sip\", \"dialogs\", \"dialpad\", \"diamond\", \"dictionary\", \"difference\", \"digital_out_of_home\", \"digital_wellbeing\", \"dining\", \"dinner_dining\", \"directions\", \"directions_alt\", \"directions_alt_off\", \"directions_bike\", \"directions_boat\", \"directions_boat_filled\", \"directions_bus\", \"directions_bus_filled\", \"directions_car\", \"directions_car_filled\", \"directions_off\", \"directions_railway\", \"directions_railway_filled\", \"directions_run\", \"directions_subway\", \"directions_subway_filled\", \"directions_transit\", \"directions_transit_filled\", \"directions_walk\", \"directory_sync\", \"dirty_lens\", \"disabled_by_default\", \"disabled_visible\", \"disc_full\", \"discover_tune\", \"dishwasher\", \"dishwasher_gen\", \"display_external_input\", \"display_settings\", \"distance\", \"diversity_1\", \"diversity_2\", \"diversity_3\", \"diversity_4\", \"dns\", \"do_disturb\", \"do_disturb_alt\", \"do_disturb_off\", \"do_disturb_on\", \"do_not_disturb\", \"do_not_disturb_alt\", \"do_not_disturb_off\", \"do_not_disturb_on\", \"do_not_disturb_on_total_silence\", \"do_not_step\", \"do_not_touch\", \"dock\", \"dock_to_bottom\", \"dock_to_left\", \"dock_to_right\", \"docs_add_on\", \"docs_apps_script\", \"document_scanner\", \"domain\", \"domain_add\", \"domain_disabled\", \"domain_verification\", \"domain_verification_off\", \"domino_mask\", \"done\", \"done_all\", \"done_outline\", \"donut_large\", \"donut_small\", \"door_back\", \"door_front\", \"door_open\", \"door_sensor\", \"door_sliding\", \"doorbell\", \"doorbell_3p\", \"doorbell_chime\", \"double_arrow\", \"downhill_skiing\", \"download\", \"download_2\", \"download_done\", \"download_for_offline\", \"downloading\", \"draft\", \"draft_orders\", \"drafts\", \"drag_click\", \"drag_handle\", \"drag_indicator\", \"drag_pan\", \"draw\", \"draw_abstract\", \"draw_collage\", \"drawing_recognition\", \"dresser\", \"drive_eta\", \"drive_file_move\", \"drive_file_move_outline\", \"drive_file_move_rtl\", \"drive_file_rename_outline\", \"drive_folder_upload\", \"drive_fusiontable\", \"dropdown\", \"dry\", \"dry_cleaning\", \"dual_screen\", \"duo\", \"dvr\", \"dynamic_feed\", \"dynamic_form\", \"e911_avatar\", \"e911_emergency\", \"e_mobiledata\", \"e_mobiledata_badge\", \"earbuds\", \"earbuds_battery\", \"early_on\", \"earthquake\", \"east\", \"ecg\", \"ecg_heart\", \"eco\", \"eda\", \"edgesensor_high\", \"edgesensor_low\", \"edit\", \"edit_attributes\", \"edit_calendar\", \"edit_document\", \"edit_location\", \"edit_location_alt\", \"edit_note\", \"edit_notifications\", \"edit_off\", \"edit_road\", \"edit_square\", \"editor_choice\", \"egg\", \"egg_alt\", \"eject\", \"elderly\", \"elderly_woman\", \"electric_bike\", \"electric_bolt\", \"electric_car\", \"electric_meter\", \"electric_moped\", \"electric_rickshaw\", \"electric_scooter\", \"electrical_services\", \"elevation\", \"elevator\", \"email\", \"emergency\", \"emergency_heat\", \"emergency_heat_2\", \"emergency_home\", \"emergency_recording\", \"emergency_share\", \"emergency_share_off\", \"emoji_emotions\", \"emoji_events\", \"emoji_flags\", \"emoji_food_beverage\", \"emoji_nature\", \"emoji_objects\", \"emoji_people\", \"emoji_symbols\", \"emoji_transportation\", \"emoticon\", \"empty_dashboard\", \"enable\", \"encrypted\", \"endocrinology\", \"energy\", \"energy_program_saving\", \"energy_program_time_used\", \"energy_savings_leaf\", \"engineering\", \"enhanced_encryption\", \"ent\", \"enterprise\", \"enterprise_off\", \"equal\", \"equalizer\", \"error\", \"error_circle_rounded\", \"error_med\", \"error_outline\", \"escalator\", \"escalator_warning\", \"euro\", \"euro_symbol\", \"ev_charger\", \"ev_mobiledata_badge\", \"ev_shadow\", \"ev_shadow_add\", \"ev_shadow_minus\", \"ev_station\", \"event\", \"event_available\", \"event_busy\", \"event_list\", \"event_note\", \"event_repeat\", \"event_seat\", \"event_upcoming\", \"exclamation\", \"exercise\", \"exit_to_app\", \"expand\", \"expand_all\", \"expand_circle_down\", \"expand_circle_right\", \"expand_circle_up\", \"expand_content\", \"expand_less\", \"expand_more\", \"experiment\", \"explicit\", \"explore\", \"explore_nearby\", \"explore_off\", \"explosion\", \"export_notes\", \"exposure\", \"exposure_neg_1\", \"exposure_neg_2\", \"exposure_plus_1\", \"exposure_plus_2\", \"exposure_zero\", \"extension\", \"extension_off\", \"eyeglasses\", \"face\", \"face_2\", \"face_3\", \"face_4\", \"face_5\", \"face_6\", \"face_retouching_natural\", \"face_retouching_off\", \"face_unlock\", \"fact_check\", \"factory\", \"falling\", \"familiar_face_and_zone\", \"family_history\", \"family_home\", \"family_link\", \"family_restroom\", \"family_star\", \"farsight_digital\", \"fast_forward\", \"fast_rewind\", \"fastfood\", \"faucet\", \"favorite\", \"favorite_border\", \"fax\", \"feature_search\", \"featured_play_list\", \"featured_seasonal_and_gifts\", \"featured_video\", \"feed\", \"feedback\", \"female\", \"femur\", \"femur_alt\", \"fence\", \"fertile\", \"festival\", \"fiber_dvr\", \"fiber_manual_record\", \"fiber_new\", \"fiber_pin\", \"fiber_smart_record\", \"file_copy\", \"file_copy_off\", \"file_download\", \"file_download_done\", \"file_download_off\", \"file_map\", \"file_open\", \"file_present\", \"file_save\", \"file_save_off\", \"file_upload\", \"file_upload_off\", \"filter\", \"filter_1\", \"filter_2\", \"filter_3\", \"filter_4\", \"filter_5\", \"filter_6\", \"filter_7\", \"filter_8\", \"filter_9\", \"filter_9_plus\", \"filter_alt\", \"filter_alt_off\", \"filter_b_and_w\", \"filter_center_focus\", \"filter_drama\", \"filter_frames\", \"filter_hdr\", \"filter_list\", \"filter_list_alt\", \"filter_list_off\", \"filter_none\", \"filter_retrolux\", \"filter_tilt_shift\", \"filter_vintage\", \"finance\", \"finance_chip\", \"finance_mode\", \"find_in_page\", \"find_replace\", \"fingerprint\", \"fire_extinguisher\", \"fire_hydrant\", \"fire_truck\", \"fireplace\", \"first_page\", \"fit_page\", \"fit_screen\", \"fit_width\", \"fitness_center\", \"flag\", \"flag_circle\", \"flag_filled\", \"flaky\", \"flare\", \"flash_auto\", \"flash_off\", \"flash_on\", \"flashlight_off\", \"flashlight_on\", \"flatware\", \"flex_direction\", \"flex_no_wrap\", \"flex_wrap\", \"flight\", \"flight_class\", \"flight_land\", \"flight_takeoff\", \"flights_and_hotels\", \"flightsmode\", \"flip\", \"flip_camera_android\", \"flip_camera_ios\", \"flip_to_back\", \"flip_to_front\", \"flood\", \"floor\", \"floor_lamp\", \"flourescent\", \"flowsheet\", \"fluid\", \"fluid_balance\", \"fluid_med\", \"fluorescent\", \"flutter\", \"flutter_dash\", \"fmd_bad\", \"fmd_good\", \"foggy\", \"folded_hands\", \"folder\", \"folder_copy\", \"folder_data\", \"folder_delete\", \"folder_limited\", \"folder_managed\", \"folder_off\", \"folder_open\", \"folder_shared\", \"folder_special\", \"folder_supervised\", \"folder_zip\", \"follow_the_signs\", \"font_download\", \"font_download_off\", \"food_bank\", \"foot_bones\", \"footprint\", \"for_you\", \"forest\", \"fork_left\", \"fork_right\", \"forklift\", \"format_align_center\", \"format_align_justify\", \"format_align_left\", \"format_align_right\", \"format_bold\", \"format_clear\", \"format_color_fill\", \"format_color_reset\", \"format_color_text\", \"format_h1\", \"format_h2\", \"format_h3\", \"format_h4\", \"format_h5\", \"format_h6\", \"format_image_left\", \"format_image_right\", \"format_indent_decrease\", \"format_indent_increase\", \"format_ink_highlighter\", \"format_italic\", \"format_letter_spacing\", \"format_letter_spacing_2\", \"format_letter_spacing_standard\", \"format_letter_spacing_wide\", \"format_letter_spacing_wider\", \"format_line_spacing\", \"format_list_bulleted\", \"format_list_bulleted_add\", \"format_list_numbered\", \"format_list_numbered_rtl\", \"format_overline\", \"format_paint\", \"format_paragraph\", \"format_quote\", \"format_shapes\", \"format_size\", \"format_strikethrough\", \"format_text_clip\", \"format_text_overflow\", \"format_text_wrap\", \"format_textdirection_l_to_r\", \"format_textdirection_r_to_l\", \"format_underlined\", \"format_underlined_squiggle\", \"forms_add_on\", \"forms_apps_script\", \"fort\", \"forum\", \"forward\", \"forward_10\", \"forward_30\", \"forward_5\", \"forward_circle\", \"forward_media\", \"forward_to_inbox\", \"foundation\", \"frame_inspect\", \"frame_person\", \"frame_person_off\", \"frame_reload\", \"frame_source\", \"free_breakfast\", \"free_cancellation\", \"front_hand\", \"front_loader\", \"full_coverage\", \"full_hd\", \"full_stacked_bar_chart\", \"fullscreen\", \"fullscreen_exit\", \"function\", \"functions\", \"g_mobiledata\", \"g_mobiledata_badge\", \"g_translate\", \"gallery_thumbnail\", \"gamepad\", \"games\", \"garage\", \"garage_door\", \"garage_home\", \"garden_cart\", \"gas_meter\", \"gastroenterology\", \"gate\", \"gavel\", \"general_device\", \"generating_tokens\", \"genetics\", \"genres\", \"gesture\", \"gesture_select\", \"get_app\", \"gif\", \"gif_box\", \"girl\", \"gite\", \"glass_cup\", \"globe\", \"globe_asia\", \"globe_uk\", \"glucose\", \"glyphs\", \"go_to_line\", \"golf_course\", \"google_home_devices\", \"google_plus_reshare\", \"google_tv_remote\", \"google_wifi\", \"gpp_bad\", \"gpp_good\", \"gpp_maybe\", \"gps_fixed\", \"gps_not_fixed\", \"gps_off\", \"grade\", \"gradient\", \"grading\", \"grain\", \"graphic_eq\", \"grass\", \"grid_3x3\", \"grid_3x3_off\", \"grid_4x4\", \"grid_goldenratio\", \"grid_guides\", \"grid_off\", \"grid_on\", \"grid_view\", \"grocery\", \"group\", \"group_add\", \"group_off\", \"group_remove\", \"group_work\", \"grouped_bar_chart\", \"groups\", \"groups_2\", \"groups_3\", \"gynecology\", \"h_mobiledata\", \"h_mobiledata_badge\", \"h_plus_mobiledata\", \"h_plus_mobiledata_badge\", \"hail\", \"hallway\", \"hand_bones\", \"hand_gesture\", \"handshake\", \"handwriting_recognition\", \"handyman\", \"hangout_video\", \"hangout_video_off\", \"hard_drive\", \"hard_drive_2\", \"hardware\", \"hd\", \"hdr_auto\", \"hdr_auto_select\", \"hdr_enhanced_select\", \"hdr_off\", \"hdr_off_select\", \"hdr_on\", \"hdr_on_select\", \"hdr_plus\", \"hdr_plus_off\", \"hdr_strong\", \"hdr_weak\", \"headphones\", \"headphones_battery\", \"headset\", \"headset_mic\", \"headset_off\", \"healing\", \"health_and_beauty\", \"health_and_safety\", \"health_metrics\", \"heap_snapshot_large\", \"heap_snapshot_multiple\", \"heap_snapshot_thumbnail\", \"hearing\", \"hearing_disabled\", \"heart_broken\", \"heart_check\", \"heart_minus\", \"heart_plus\", \"heat\", \"heat_pump\", \"heat_pump_balance\", \"height\", \"helicopter\", \"help\", \"help_center\", \"help_clinic\", \"help_outline\", \"hematology\", \"hevc\", \"hexagon\", \"hide\", \"hide_image\", \"hide_source\", \"high_density\", \"high_quality\", \"high_res\", \"highlight\", \"highlight_keyboard_focus\", \"highlight_mouse_cursor\", \"highlight_off\", \"highlight_text_cursor\", \"highlighter_size_1\", \"highlighter_size_2\", \"highlighter_size_3\", \"highlighter_size_4\", \"highlighter_size_5\", \"hiking\", \"history\", \"history_edu\", \"history_off\", \"history_toggle_off\", \"hive\", \"hls\", \"hls_off\", \"holiday_village\", \"home\", \"home_and_garden\", \"home_app_logo\", \"home_filled\", \"home_health\", \"home_improvement_and_tools\", \"home_iot_device\", \"home_max\", \"home_max_dots\", \"home_mini\", \"home_pin\", \"home_repair_service\", \"home_speaker\", \"home_storage\", \"home_work\", \"horizontal_distribute\", \"horizontal_rule\", \"horizontal_split\", \"hot_tub\", \"hotel\", \"hotel_class\", \"hourglass\", \"hourglass_bottom\", \"hourglass_disabled\", \"hourglass_empty\", \"hourglass_full\", \"hourglass_top\", \"house\", \"house_siding\", \"house_with_shield\", \"houseboat\", \"household_supplies\", \"how_to_reg\", \"how_to_vote\", \"hr_resting\", \"html\", \"http\", \"https\", \"hub\", \"humerus\", \"humerus_alt\", \"humidity_high\", \"humidity_indoor\", \"humidity_low\", \"humidity_mid\", \"humidity_percentage\", \"hvac\", \"ice_skating\", \"icecream\", \"ifl\", \"iframe\", \"iframe_off\", \"image\", \"image_aspect_ratio\", \"image_not_supported\", \"image_search\", \"imagesearch_roller\", \"imagesmode\", \"immunology\", \"import_contacts\", \"import_export\", \"important_devices\", \"in_home_mode\", \"inactive_order\", \"inbox\", \"inbox_customize\", \"incomplete_circle\", \"indeterminate_check_box\", \"indeterminate_question_box\", \"info\", \"info_i\", \"infrared\", \"ink_eraser\", \"ink_eraser_off\", \"ink_highlighter\", \"ink_highlighter_move\", \"ink_marker\", \"ink_pen\", \"inpatient\", \"input\", \"input_circle\", \"insert_chart\", \"insert_chart_filled\", \"insert_chart_outlined\", \"insert_comment\", \"insert_drive_file\", \"insert_emoticon\", \"insert_invitation\", \"insert_link\", \"insert_page_break\", \"insert_photo\", \"insert_text\", \"insights\", \"install_desktop\", \"install_mobile\", \"instant_mix\", \"integration_instructions\", \"interactive_space\", \"interests\", \"interpreter_mode\", \"inventory\", \"inventory_2\", \"invert_colors\", \"invert_colors_off\", \"ios\", \"ios_share\", \"iron\", \"iso\", \"jamboard_kiosk\", \"javascript\", \"join\", \"join_full\", \"join_inner\", \"join_left\", \"join_right\", \"joystick\", \"jump_to_element\", \"kayaking\", \"kebab_dining\", \"kettle\", \"key\", \"key_off\", \"key_vertical\", \"key_visualizer\", \"keyboard\", \"keyboard_alt\", \"keyboard_arrow_down\", \"keyboard_arrow_left\", \"keyboard_arrow_right\", \"keyboard_arrow_up\", \"keyboard_backspace\", \"keyboard_capslock\", \"keyboard_capslock_badge\", \"keyboard_command_key\", \"keyboard_control_key\", \"keyboard_double_arrow_down\", \"keyboard_double_arrow_left\", \"keyboard_double_arrow_right\", \"keyboard_double_arrow_up\", \"keyboard_external_input\", \"keyboard_full\", \"keyboard_hide\", \"keyboard_keys\", \"keyboard_off\", \"keyboard_onscreen\", \"keyboard_option_key\", \"keyboard_previous_language\", \"keyboard_return\", \"keyboard_tab\", \"keyboard_tab_rtl\", \"keyboard_voice\", \"kid_star\", \"king_bed\", \"kitchen\", \"kitesurfing\", \"lab_panel\", \"lab_profile\", \"lab_research\", \"label\", \"label_important\", \"label_important_outline\", \"label_off\", \"label_outline\", \"labs\", \"lan\", \"landscape\", \"landslide\", \"language\", \"language_chinese_array\", \"language_chinese_cangjie\", \"language_chinese_dayi\", \"language_chinese_pinyin\", \"language_chinese_quick\", \"language_chinese_wubi\", \"language_french\", \"language_gb_english\", \"language_international\", \"language_japanese_kana\", \"language_korean_latin\", \"language_pinyin\", \"language_spanish\", \"language_us\", \"language_us_colemak\", \"language_us_dvorak\", \"laps\", \"laptop\", \"laptop_chromebook\", \"laptop_mac\", \"laptop_windows\", \"lasso_select\", \"last_page\", \"launch\", \"laundry\", \"layers\", \"layers_clear\", \"lda\", \"leaderboard\", \"leak_add\", \"leak_remove\", \"left_click\", \"left_panel_close\", \"left_panel_open\", \"legend_toggle\", \"lens\", \"lens_blur\", \"letter_switch\", \"library_add\", \"library_add_check\", \"library_books\", \"library_music\", \"license\", \"lift_to_talk\", \"light\", \"light_group\", \"light_mode\", \"light_off\", \"lightbulb\", \"lightbulb_circle\", \"lightbulb_outline\", \"lightning_stand\", \"line_axis\", \"line_curve\", \"line_end\", \"line_end_arrow\", \"line_end_arrow_notch\", \"line_end_circle\", \"line_end_diamond\", \"line_end_square\", \"line_start\", \"line_start_arrow\", \"line_start_arrow_notch\", \"line_start_circle\", \"line_start_diamond\", \"line_start_square\", \"line_style\", \"line_weight\", \"linear_scale\", \"link\", \"link_off\", \"linked_camera\", \"linked_services\", \"liquor\", \"list\", \"list_alt\", \"list_alt_add\", \"lists\", \"live_help\", \"live_tv\", \"living\", \"local_activity\", \"local_airport\", \"local_atm\", \"local_bar\", \"local_cafe\", \"local_car_wash\", \"local_convenience_store\", \"local_dining\", \"local_drink\", \"local_fire_department\", \"local_florist\", \"local_gas_station\", \"local_grocery_store\", \"local_hospital\", \"local_hotel\", \"local_laundry_service\", \"local_library\", \"local_mall\", \"local_movies\", \"local_offer\", \"local_parking\", \"local_pharmacy\", \"local_phone\", \"local_pizza\", \"local_play\", \"local_police\", \"local_post_office\", \"local_printshop\", \"local_see\", \"local_shipping\", \"local_taxi\", \"location_automation\", \"location_away\", \"location_chip\", \"location_city\", \"location_disabled\", \"location_home\", \"location_off\", \"location_on\", \"location_pin\", \"location_searching\", \"locator_tag\", \"lock\", \"lock_clock\", \"lock_open\", \"lock_open_right\", \"lock_outline\", \"lock_person\", \"lock_reset\", \"login\", \"logo_dev\", \"logout\", \"looks\", \"looks_3\", \"looks_4\", \"looks_5\", \"looks_6\", \"looks_one\", \"looks_two\", \"loop\", \"loupe\", \"low_density\", \"low_priority\", \"loyalty\", \"lte_mobiledata\", \"lte_mobiledata_badge\", \"lte_plus_mobiledata\", \"lte_plus_mobiledata_badge\", \"luggage\", \"lunch_dining\", \"lyrics\", \"macro_auto\", \"macro_off\", \"magic_button\", \"magic_exchange\", \"magic_tether\", \"magnification_large\", \"magnification_small\", \"magnify_docked\", \"magnify_fullscreen\", \"mail\", \"mail_lock\", \"mail_outline\", \"male\", \"man\", \"man_2\", \"man_3\", \"man_4\", \"manage_accounts\", \"manage_history\", \"manage_search\", \"manga\", \"manufacturing\", \"map\", \"maps_home_work\", \"maps_ugc\", \"margin\", \"mark_as_unread\", \"mark_chat_read\", \"mark_chat_unread\", \"mark_email_read\", \"mark_email_unread\", \"mark_unread_chat_alt\", \"markdown\", \"markdown_copy\", \"markdown_paste\", \"markunread\", \"markunread_mailbox\", \"masked_transitions\", \"masks\", \"match_case\", \"match_word\", \"matter\", \"maximize\", \"measuring_tape\", \"media_bluetooth_off\", \"media_bluetooth_on\", \"media_link\", \"media_output\", \"media_output_off\", \"mediation\", \"medical_information\", \"medical_mask\", \"medical_services\", \"medication\", \"medication_liquid\", \"meeting_room\", \"memory\", \"memory_alt\", \"menstrual_health\", \"menu\", \"menu_book\", \"menu_open\", \"merge\", \"merge_type\", \"message\", \"metabolism\", \"mfg_nest_yale_lock\", \"mic\", \"mic_double\", \"mic_external_off\", \"mic_external_on\", \"mic_none\", \"mic_off\", \"microbiology\", \"microwave\", \"microwave_gen\", \"military_tech\", \"mimo\", \"mimo_disconnect\", \"mindfulness\", \"minimize\", \"minor_crash\", \"mintmark\", \"missed_video_call\", \"missed_video_call_filled\", \"missing_controller\", \"mist\", \"mitre\", \"mixture_med\", \"mms\", \"mobile_friendly\", \"mobile_off\", \"mobile_screen_share\", \"mobiledata_off\", \"mode\", \"mode_comment\", \"mode_cool\", \"mode_cool_off\", \"mode_dual\", \"mode_edit\", \"mode_edit_outline\", \"mode_fan\", \"mode_fan_off\", \"mode_heat\", \"mode_heat_cool\", \"mode_heat_off\", \"mode_night\", \"mode_of_travel\", \"mode_off_on\", \"mode_standby\", \"model_training\", \"monetization_on\", \"money\", \"money_off\", \"money_off_csred\", \"monitor\", \"monitor_heart\", \"monitor_weight\", \"monitor_weight_gain\", \"monitor_weight_loss\", \"monitoring\", \"monochrome_photos\", \"mood\", \"mood_bad\", \"mop\", \"more\", \"more_down\", \"more_horiz\", \"more_time\", \"more_up\", \"more_vert\", \"mosque\", \"motion_blur\", \"motion_mode\", \"motion_photos_auto\", \"motion_photos_off\", \"motion_photos_on\", \"motion_photos_pause\", \"motion_photos_paused\", \"motion_sensor_active\", \"motion_sensor_alert\", \"motion_sensor_idle\", \"motion_sensor_urgent\", \"motorcycle\", \"mountain_flag\", \"mouse\", \"move\", \"move_down\", \"move_group\", \"move_item\", \"move_location\", \"move_selection_down\", \"move_selection_left\", \"move_selection_right\", \"move_selection_up\", \"move_to_inbox\", \"move_up\", \"moved_location\", \"movie\", \"movie_creation\", \"movie_edit\", \"movie_filter\", \"movie_info\", \"moving\", \"moving_beds\", \"moving_ministry\", \"mp\", \"multicooker\", \"multiline_chart\", \"multiple_stop\", \"museum\", \"music_cast\", \"music_note\", \"music_off\", \"music_video\", \"my_location\", \"mystery\", \"nat\", \"nature\", \"nature_people\", \"navigate_before\", \"navigate_next\", \"navigation\", \"near_me\", \"near_me_disabled\", \"nearby\", \"nearby_error\", \"nearby_off\", \"nephrology\", \"nest_audio\", \"nest_cam_floodlight\", \"nest_cam_indoor\", \"nest_cam_iq\", \"nest_cam_iq_outdoor\", \"nest_cam_magnet_mount\", \"nest_cam_outdoor\", \"nest_cam_stand\", \"nest_cam_wall_mount\", \"nest_cam_wired_stand\", \"nest_clock_farsight_analog\", \"nest_clock_farsight_digital\", \"nest_connect\", \"nest_detect\", \"nest_display\", \"nest_display_max\", \"nest_doorbell_visitor\", \"nest_eco_leaf\", \"nest_farsight_weather\", \"nest_found_savings\", \"nest_gale_wifi\", \"nest_heat_link_e\", \"nest_heat_link_gen_3\", \"nest_hello_doorbell\", \"nest_locator_tag\", \"nest_mini\", \"nest_multi_room\", \"nest_protect\", \"nest_remote\", \"nest_remote_comfort_sensor\", \"nest_secure_alarm\", \"nest_sunblock\", \"nest_tag\", \"nest_thermostat\", \"nest_thermostat_e_eu\", \"nest_thermostat_gen_3\", \"nest_thermostat_sensor\", \"nest_thermostat_sensor_eu\", \"nest_thermostat_zirconium_eu\", \"nest_true_radiant\", \"nest_wake_on_approach\", \"nest_wake_on_press\", \"nest_wifi_gale\", \"nest_wifi_mistral\", \"nest_wifi_point\", \"nest_wifi_point_vento\", \"nest_wifi_pro\", \"nest_wifi_pro_2\", \"nest_wifi_router\", \"network_cell\", \"network_check\", \"network_intelligence_history\", \"network_intelligence_update\", \"network_locked\", \"network_manage\", \"network_node\", \"network_ping\", \"network_wifi\", \"network_wifi_1_bar\", \"network_wifi_1_bar_locked\", \"network_wifi_2_bar\", \"network_wifi_2_bar_locked\", \"network_wifi_3_bar\", \"network_wifi_3_bar_locked\", \"network_wifi_locked\", \"neurology\", \"new_label\", \"new_releases\", \"new_window\", \"news\", \"newsmode\", \"newspaper\", \"newsstand\", \"next_plan\", \"next_week\", \"nfc\", \"night_shelter\", \"night_sight_auto\", \"night_sight_auto_off\", \"night_sight_max\", \"nightlife\", \"nightlight\", \"nightlight_round\", \"nights_stay\", \"no_accounts\", \"no_adult_content\", \"no_backpack\", \"no_crash\", \"no_drinks\", \"no_encryption\", \"no_encryption_gmailerrorred\", \"no_flash\", \"no_food\", \"no_luggage\", \"no_meals\", \"no_meeting_room\", \"no_photography\", \"no_sim\", \"no_sound\", \"no_stroller\", \"no_transfer\", \"noise_aware\", \"noise_control_off\", \"noise_control_on\", \"nordic_walking\", \"north\", \"north_east\", \"north_west\", \"not_accessible\", \"not_accessible_forward\", \"not_interested\", \"not_listed_location\", \"not_started\", \"note\", \"note_add\", \"note_alt\", \"note_stack\", \"note_stack_add\", \"notes\", \"notification_add\", \"notification_important\", \"notification_multiple\", \"notifications\", \"notifications_active\", \"notifications_none\", \"notifications_off\", \"notifications_paused\", \"notifications_unread\", \"numbers\", \"nutrition\", \"ods\", \"odt\", \"offline_bolt\", \"offline_pin\", \"offline_share\", \"oil_barrel\", \"on_device_training\", \"on_hub_device\", \"oncology\", \"ondemand_video\", \"online_prediction\", \"onsen\", \"opacity\", \"open_in_browser\", \"open_in_full\", \"open_in_new\", \"open_in_new_down\", \"open_in_new_off\", \"open_in_phone\", \"open_jam\", \"open_with\", \"ophthalmology\", \"oral_disease\", \"order_approve\", \"order_play\", \"orders\", \"orthopedics\", \"other_admission\", \"other_houses\", \"outbound\", \"outbox\", \"outbox_alt\", \"outdoor_garden\", \"outdoor_grill\", \"outgoing_mail\", \"outlet\", \"outlined_flag\", \"outpatient\", \"outpatient_med\", \"output\", \"output_circle\", \"oven\", \"oven_gen\", \"overview\", \"overview_key\", \"oxygen_saturation\", \"p2p\", \"pace\", \"pacemaker\", \"package\", \"package_2\", \"padding\", \"page_control\", \"page_info\", \"pageless\", \"pages\", \"pageview\", \"paid\", \"palette\", \"pallet\", \"pan_tool\", \"pan_tool_alt\", \"pan_zoom\", \"panorama\", \"panorama_fish_eye\", \"panorama_horizontal\", \"panorama_photosphere\", \"panorama_vertical\", \"panorama_wide_angle\", \"paragliding\", \"park\", \"partly_cloudy_day\", \"partly_cloudy_night\", \"partner_exchange\", \"partner_reports\", \"party_mode\", \"passkey\", \"password\", \"patient_list\", \"pattern\", \"pause\", \"pause_circle\", \"pause_circle_filled\", \"pause_circle_outline\", \"pause_presentation\", \"payment\", \"payments\", \"pedal_bike\", \"pediatrics\", \"pen_size_1\", \"pen_size_2\", \"pen_size_3\", \"pen_size_4\", \"pen_size_5\", \"pending\", \"pending_actions\", \"pentagon\", \"people\", \"people_alt\", \"people_outline\", \"percent\", \"performance_max\", \"pergola\", \"perm_camera_mic\", \"perm_contact_calendar\", \"perm_data_setting\", \"perm_device_information\", \"perm_identity\", \"perm_media\", \"perm_phone_msg\", \"perm_scan_wifi\", \"person\", \"person_2\", \"person_3\", \"person_4\", \"person_add\", \"person_add_alt\", \"person_add_disabled\", \"person_alert\", \"person_apron\", \"person_book\", \"person_cancel\", \"person_celebrate\", \"person_check\", \"person_edit\", \"person_filled\", \"person_off\", \"person_outline\", \"person_pin\", \"person_pin_circle\", \"person_play\", \"person_raised_hand\", \"person_remove\", \"person_search\", \"personal_bag\", \"personal_bag_off\", \"personal_bag_question\", \"personal_injury\", \"personal_places\", \"personal_video\", \"pest_control\", \"pest_control_rodent\", \"pet_supplies\", \"pets\", \"phishing\", \"phone\", \"phone_alt\", \"phone_android\", \"phone_bluetooth_speaker\", \"phone_callback\", \"phone_disabled\", \"phone_enabled\", \"phone_forwarded\", \"phone_in_talk\", \"phone_iphone\", \"phone_locked\", \"phone_missed\", \"phone_paused\", \"phonelink\", \"phonelink_erase\", \"phonelink_lock\", \"phonelink_off\", \"phonelink_ring\", \"phonelink_ring_off\", \"phonelink_setup\", \"photo\", \"photo_album\", \"photo_auto_merge\", \"photo_camera\", \"photo_camera_back\", \"photo_camera_front\", \"photo_filter\", \"photo_frame\", \"photo_library\", \"photo_prints\", \"photo_size_select_actual\", \"photo_size_select_large\", \"photo_size_select_small\", \"php\", \"physical_therapy\", \"piano\", \"piano_off\", \"picture_as_pdf\", \"picture_in_picture\", \"picture_in_picture_alt\", \"picture_in_picture_center\", \"picture_in_picture_large\", \"picture_in_picture_medium\", \"picture_in_picture_mobile\", \"picture_in_picture_off\", \"picture_in_picture_small\", \"pie_chart\", \"pie_chart_filled\", \"pie_chart_outline\", \"pie_chart_outlined\", \"pill\", \"pill_off\", \"pin\", \"pin_drop\", \"pin_end\", \"pin_invoke\", \"pinch\", \"pinch_zoom_in\", \"pinch_zoom_out\", \"pip\", \"pip_exit\", \"pivot_table_chart\", \"place\", \"place_item\", \"plagiarism\", \"planner_banner_ad_pt\", \"planner_review\", \"play_arrow\", \"play_circle\", \"play_disabled\", \"play_for_work\", \"play_lesson\", \"play_music\", \"play_pause\", \"play_shapes\", \"playing_cards\", \"playlist_add\", \"playlist_add_check\", \"playlist_add_check_circle\", \"playlist_add_circle\", \"playlist_play\", \"playlist_remove\", \"plumbing\", \"plus_one\", \"podcasts\", \"podiatry\", \"podium\", \"point_of_sale\", \"point_scan\", \"policy\", \"poll\", \"polyline\", \"polymer\", \"pool\", \"portable_wifi_off\", \"portrait\", \"position_bottom_left\", \"position_bottom_right\", \"position_top_right\", \"post\", \"post_add\", \"potted_plant\", \"power\", \"power_input\", \"power_off\", \"power_rounded\", \"power_settings_new\", \"prayer_times\", \"precision_manufacturing\", \"pregnancy\", \"pregnant_woman\", \"preliminary\", \"prescriptions\", \"present_to_all\", \"preview\", \"preview_off\", \"price_change\", \"price_check\", \"print\", \"print_add\", \"print_connect\", \"print_disabled\", \"print_error\", \"print_lock\", \"priority\", \"priority_high\", \"privacy\", \"privacy_tip\", \"private_connectivity\", \"problem\", \"procedure\", \"process_chart\", \"production_quantity_limits\", \"productivity\", \"progress_activity\", \"prompt_suggestion\", \"propane\", \"propane_tank\", \"psychiatry\", \"psychology\", \"psychology_alt\", \"public\", \"public_off\", \"publish\", \"published_with_changes\", \"pulmonology\", \"pulse_alert\", \"punch_clock\", \"push_pin\", \"qr_code\", \"qr_code_2\", \"qr_code_2_add\", \"qr_code_scanner\", \"query_builder\", \"query_stats\", \"question_answer\", \"question_exchange\", \"question_mark\", \"queue\", \"queue_music\", \"queue_play_next\", \"quick_phrases\", \"quick_reference\", \"quick_reference_all\", \"quick_reorder\", \"quickreply\", \"quiet_time\", \"quiet_time_active\", \"quiz\", \"r_mobiledata\", \"radar\", \"radio\", \"radio_button_checked\", \"radio_button_partial\", \"radio_button_unchecked\", \"radiology\", \"railway_alert\", \"rainy\", \"rainy_heavy\", \"rainy_light\", \"rainy_snow\", \"ramen_dining\", \"ramp_left\", \"ramp_right\", \"range_hood\", \"rate_review\", \"raven\", \"raw_off\", \"raw_on\", \"read_more\", \"readiness_score\", \"real_estate_agent\", \"rear_camera\", \"rebase\", \"rebase_edit\", \"receipt\", \"receipt_long\", \"recent_actors\", \"recent_patient\", \"recommend\", \"record_voice_over\", \"rectangle\", \"recycling\", \"redeem\", \"redo\", \"reduce_capacity\", \"refresh\", \"regular_expression\", \"relax\", \"release_alert\", \"remember_me\", \"reminder\", \"reminders_alt\", \"remote_gen\", \"remove\", \"remove_circle\", \"remove_circle_outline\", \"remove_done\", \"remove_from_queue\", \"remove_moderator\", \"remove_red_eye\", \"remove_road\", \"remove_selection\", \"remove_shopping_cart\", \"reopen_window\", \"reorder\", \"repartition\", \"repeat\", \"repeat_on\", \"repeat_one\", \"repeat_one_on\", \"replay\", \"replay_10\", \"replay_30\", \"replay_5\", \"replay_circle_filled\", \"reply\", \"reply_all\", \"report\", \"report_gmailerrorred\", \"report_off\", \"report_problem\", \"request_page\", \"request_quote\", \"reset_image\", \"reset_tv\", \"reset_wrench\", \"resize\", \"respiratory_rate\", \"responsive_layout\", \"restart_alt\", \"restaurant\", \"restaurant_menu\", \"restore\", \"restore_from_trash\", \"restore_page\", \"resume\", \"reviews\", \"rewarded_ads\", \"rheumatology\", \"rib_cage\", \"rice_bowl\", \"right_click\", \"right_panel_close\", \"right_panel_open\", \"ring_volume\", \"ring_volume_filled\", \"ripples\", \"robot\", \"robot_2\", \"rocket\", \"rocket_launch\", \"roller_shades\", \"roller_shades_closed\", \"roller_skating\", \"roofing\", \"room\", \"room_preferences\", \"room_service\", \"rotate_90_degrees_ccw\", \"rotate_90_degrees_cw\", \"rotate_left\", \"rotate_right\", \"roundabout_left\", \"roundabout_right\", \"rounded_corner\", \"route\", \"router\", \"routine\", \"rowing\", \"rss_feed\", \"rsvp\", \"rtt\", \"rubric\", \"rule\", \"rule_folder\", \"rule_settings\", \"run_circle\", \"running_with_errors\", \"rv_hookup\", \"safety_check\", \"safety_check_off\", \"safety_divider\", \"sailing\", \"salinity\", \"sanitizer\", \"satellite\", \"satellite_alt\", \"sauna\", \"save\", \"save_alt\", \"save_as\", \"saved_search\", \"savings\", \"scale\", \"scan\", \"scan_delete\", \"scanner\", \"scatter_plot\", \"scene\", \"schedule\", \"schedule_send\", \"schema\", \"school\", \"science\", \"science_off\", \"score\", \"scoreboard\", \"screen_lock_landscape\", \"screen_lock_portrait\", \"screen_lock_rotation\", \"screen_record\", \"screen_rotation\", \"screen_rotation_alt\", \"screen_rotation_up\", \"screen_search_desktop\", \"screen_share\", \"screenshot\", \"screenshot_frame\", \"screenshot_keyboard\", \"screenshot_monitor\", \"screenshot_region\", \"screenshot_tablet\", \"scrollable_header\", \"scuba_diving\", \"sd\", \"sd_card\", \"sd_card_alert\", \"sd_storage\", \"sdk\", \"search\", \"search_check\", \"search_hands_free\", \"search_off\", \"security\", \"security_key\", \"security_update\", \"security_update_good\", \"security_update_warning\", \"segment\", \"select\", \"select_all\", \"select_check_box\", \"select_to_speak\", \"select_window\", \"select_window_off\", \"self_care\", \"self_improvement\", \"sell\", \"send\", \"send_and_archive\", \"send_money\", \"send_time_extension\", \"send_to_mobile\", \"sensor_door\", \"sensor_occupied\", \"sensor_window\", \"sensors\", \"sensors_krx\", \"sensors_krx_off\", \"sensors_off\", \"sentiment_calm\", \"sentiment_content\", \"sentiment_dissatisfied\", \"sentiment_excited\", \"sentiment_extremely_dissatisfied\", \"sentiment_frustrated\", \"sentiment_neutral\", \"sentiment_sad\", \"sentiment_satisfied\", \"sentiment_satisfied_alt\", \"sentiment_stressed\", \"sentiment_very_dissatisfied\", \"sentiment_very_satisfied\", \"sentiment_worried\", \"service_toolbox\", \"set_meal\", \"settings\", \"settings_accessibility\", \"settings_account_box\", \"settings_alert\", \"settings_applications\", \"settings_b_roll\", \"settings_backup_restore\", \"settings_bluetooth\", \"settings_brightness\", \"settings_cell\", \"settings_cinematic_blur\", \"settings_ethernet\", \"settings_heart\", \"settings_input_antenna\", \"settings_input_component\", \"settings_input_composite\", \"settings_input_hdmi\", \"settings_input_svideo\", \"settings_motion_mode\", \"settings_night_sight\", \"settings_overscan\", \"settings_panorama\", \"settings_phone\", \"settings_photo_camera\", \"settings_power\", \"settings_remote\", \"settings_slow_motion\", \"settings_suggest\", \"settings_system_daydream\", \"settings_timelapse\", \"settings_video_camera\", \"settings_voice\", \"settop_component\", \"severe_cold\", \"shadow\", \"shadow_add\", \"shadow_minus\", \"shape_line\", \"shape_recognition\", \"shapes\", \"share\", \"share_location\", \"share_off\", \"share_reviews\", \"share_windows\", \"sheets_rtl\", \"shelf_auto_hide\", \"shelf_position\", \"shelves\", \"shield\", \"shield_lock\", \"shield_locked\", \"shield_moon\", \"shield_person\", \"shield_question\", \"shield_with_heart\", \"shield_with_house\", \"shift\", \"shift_lock\", \"shop\", \"shop_2\", \"shop_two\", \"shopping_bag\", \"shopping_basket\", \"shopping_cart\", \"shopping_cart_checkout\", \"shopping_cart_off\", \"shoppingmode\", \"short_stay\", \"short_text\", \"shortcut\", \"show_chart\", \"shower\", \"shuffle\", \"shuffle_on\", \"shutter_speed\", \"shutter_speed_add\", \"shutter_speed_minus\", \"sick\", \"side_navigation\", \"sign_language\", \"signal_cellular_0_bar\", \"signal_cellular_1_bar\", \"signal_cellular_2_bar\", \"signal_cellular_3_bar\", \"signal_cellular_4_bar\", \"signal_cellular_add\", \"signal_cellular_alt\", \"signal_cellular_alt_1_bar\", \"signal_cellular_alt_2_bar\", \"signal_cellular_connected_no_internet_0_bar\", \"signal_cellular_connected_no_internet_4_bar\", \"signal_cellular_no_sim\", \"signal_cellular_nodata\", \"signal_cellular_null\", \"signal_cellular_off\", \"signal_cellular_pause\", \"signal_disconnected\", \"signal_wifi_0_bar\", \"signal_wifi_4_bar\", \"signal_wifi_4_bar_lock\", \"signal_wifi_bad\", \"signal_wifi_connected_no_internet_4\", \"signal_wifi_off\", \"signal_wifi_statusbar_4_bar\", \"signal_wifi_statusbar_not_connected\", \"signal_wifi_statusbar_null\", \"signature\", \"signpost\", \"sim_card\", \"sim_card_alert\", \"sim_card_download\", \"single_bed\", \"sip\", \"skateboarding\", \"skeleton\", \"skillet\", \"skillet_cooktop\", \"skip_next\", \"skip_previous\", \"skull\", \"sledding\", \"sleep\", \"sleep_score\", \"slide_library\", \"sliders\", \"slideshow\", \"slow_motion_video\", \"smart_button\", \"smart_display\", \"smart_outlet\", \"smart_screen\", \"smart_toy\", \"smartphone\", \"smb_share\", \"smoke_free\", \"smoking_rooms\", \"sms\", \"sms_failed\", \"snippet_folder\", \"snooze\", \"snowboarding\", \"snowing\", \"snowing_heavy\", \"snowmobile\", \"snowshoeing\", \"soap\", \"social_distance\", \"social_leaderboard\", \"solar_power\", \"sort\", \"sort_by_alpha\", \"sos\", \"sound_detection_dog_barking\", \"sound_detection_glass_break\", \"sound_detection_loud_sound\", \"sound_sampler\", \"soup_kitchen\", \"source\", \"source_environment\", \"source_notes\", \"south\", \"south_america\", \"south_east\", \"south_west\", \"spa\", \"space_bar\", \"space_dashboard\", \"spatial_audio\", \"spatial_audio_off\", \"spatial_tracking\", \"speaker\", \"speaker_group\", \"speaker_notes\", \"speaker_notes_off\", \"speaker_phone\", \"special_character\", \"specific_gravity\", \"speech_to_text\", \"speed\", \"speed_0_5\", \"speed_1_2\", \"speed_1_5\", \"speed_2x\", \"spellcheck\", \"splitscreen\", \"splitscreen_add\", \"splitscreen_bottom\", \"splitscreen_left\", \"splitscreen_right\", \"splitscreen_top\", \"splitscreen_vertical_add\", \"spo2\", \"spoke\", \"sports\", \"sports_and_outdoors\", \"sports_bar\", \"sports_baseball\", \"sports_basketball\", \"sports_cricket\", \"sports_esports\", \"sports_football\", \"sports_golf\", \"sports_gymnastics\", \"sports_handball\", \"sports_hockey\", \"sports_kabaddi\", \"sports_martial_arts\", \"sports_mma\", \"sports_motorsports\", \"sports_rugby\", \"sports_score\", \"sports_soccer\", \"sports_tennis\", \"sports_volleyball\", \"sprinkler\", \"sprint\", \"square\", \"square_foot\", \"ssid_chart\", \"stack\", \"stack_off\", \"stack_star\", \"stacked_bar_chart\", \"stacked_email\", \"stacked_inbox\", \"stacked_line_chart\", \"stacks\", \"stadia_controller\", \"stadium\", \"stairs\", \"star\", \"star_border\", \"star_border_purple500\", \"star_half\", \"star_outline\", \"star_purple500\", \"star_rate\", \"star_rate_half\", \"stars\", \"start\", \"stat_0\", \"stat_1\", \"stat_2\", \"stat_3\", \"stat_minus_1\", \"stat_minus_2\", \"stat_minus_3\", \"stay_current_landscape\", \"stay_current_portrait\", \"stay_primary_landscape\", \"stay_primary_portrait\", \"step\", \"step_into\", \"step_out\", \"step_over\", \"steppers\", \"steps\", \"stethoscope\", \"stethoscope_arrow\", \"stethoscope_check\", \"sticky_note\", \"sticky_note_2\", \"stock_media\", \"stockpot\", \"stop\", \"stop_circle\", \"stop_screen_share\", \"storage\", \"store\", \"store_mall_directory\", \"storefront\", \"storm\", \"straight\", \"straighten\", \"strategy\", \"stream\", \"stream_apps\", \"streetview\", \"stress_management\", \"strikethrough_s\", \"stroke_full\", \"stroke_partial\", \"stroller\", \"style\", \"styler\", \"stylus\", \"stylus_laser_pointer\", \"stylus_note\", \"subdirectory_arrow_left\", \"subdirectory_arrow_right\", \"subheader\", \"subject\", \"subscript\", \"subscriptions\", \"subtitles\", \"subtitles_off\", \"subway\", \"summarize\", \"sunny\", \"sunny_snowing\", \"superscript\", \"supervised_user_circle\", \"supervised_user_circle_off\", \"supervisor_account\", \"support\", \"support_agent\", \"surfing\", \"surgical\", \"surround_sound\", \"swap_calls\", \"swap_driving_apps\", \"swap_driving_apps_wheel\", \"swap_horiz\", \"swap_horizontal_circle\", \"swap_vert\", \"swap_vertical_circle\", \"sweep\", \"swipe\", \"swipe_down\", \"swipe_down_alt\", \"swipe_left\", \"swipe_left_alt\", \"swipe_right\", \"swipe_right_alt\", \"swipe_up\", \"swipe_up_alt\", \"swipe_vertical\", \"switch\", \"switch_access\", \"switch_access_2\", \"switch_access_shortcut\", \"switch_access_shortcut_add\", \"switch_account\", \"switch_camera\", \"switch_left\", \"switch_right\", \"switch_video\", \"switches\", \"sword_rose\", \"swords\", \"symptoms\", \"synagogue\", \"sync\", \"sync_alt\", \"sync_disabled\", \"sync_lock\", \"sync_problem\", \"sync_saved_locally\", \"syringe\", \"system_security_update\", \"system_security_update_good\", \"system_security_update_warning\", \"system_update\", \"system_update_alt\", \"tab\", \"tab_close\", \"tab_close_right\", \"tab_duplicate\", \"tab_group\", \"tab_move\", \"tab_new_right\", \"tab_recent\", \"tab_unselected\", \"table\", \"table_bar\", \"table_chart\", \"table_chart_view\", \"table_lamp\", \"table_restaurant\", \"table_rows\", \"table_rows_narrow\", \"table_view\", \"tablet\", \"tablet_android\", \"tablet_mac\", \"tabs\", \"tactic\", \"tag\", \"tag_faces\", \"takeout_dining\", \"tamper_detection_off\", \"tamper_detection_on\", \"tap_and_play\", \"tapas\", \"target\", \"task\", \"task_alt\", \"taunt\", \"taxi_alert\", \"team_dashboard\", \"temp_preferences_custom\", \"temp_preferences_eco\", \"temple_buddhist\", \"temple_hindu\", \"tenancy\", \"terminal\", \"terrain\", \"text_ad\", \"text_decrease\", \"text_fields\", \"text_fields_alt\", \"text_format\", \"text_increase\", \"text_rotate_up\", \"text_rotate_vertical\", \"text_rotation_angledown\", \"text_rotation_angleup\", \"text_rotation_down\", \"text_rotation_none\", \"text_select_end\", \"text_select_jump_to_beginning\", \"text_select_jump_to_end\", \"text_select_move_back_character\", \"text_select_move_back_word\", \"text_select_move_down\", \"text_select_move_forward_character\", \"text_select_move_forward_word\", \"text_select_move_up\", \"text_select_start\", \"text_snippet\", \"text_to_speech\", \"textsms\", \"texture\", \"texture_add\", \"texture_minus\", \"theater_comedy\", \"theaters\", \"thermometer\", \"thermometer_add\", \"thermometer_gain\", \"thermometer_loss\", \"thermometer_minus\", \"thermostat\", \"thermostat_auto\", \"thermostat_carbon\", \"things_to_do\", \"thread_unread\", \"thumb_down\", \"thumb_down_alt\", \"thumb_down_filled\", \"thumb_down_off\", \"thumb_down_off_alt\", \"thumb_up\", \"thumb_up_alt\", \"thumb_up_filled\", \"thumb_up_off\", \"thumb_up_off_alt\", \"thumbnail_bar\", \"thumbs_up_down\", \"thunderstorm\", \"tibia\", \"tibia_alt\", \"time_auto\", \"time_to_leave\", \"timelapse\", \"timeline\", \"timer\", \"timer_10\", \"timer_10_alt_1\", \"timer_10_select\", \"timer_3\", \"timer_3_alt_1\", \"timer_3_select\", \"timer_off\", \"tips_and_updates\", \"tire_repair\", \"title\", \"toast\", \"toc\", \"today\", \"toggle_off\", \"toggle_on\", \"token\", \"toll\", \"tonality\", \"toolbar\", \"tools_flat_head\", \"tools_installation_kit\", \"tools_ladder\", \"tools_level\", \"tools_phillips\", \"tools_pliers_wire_stripper\", \"tools_power_drill\", \"tools_wrench\", \"tooltip\", \"top_panel_close\", \"top_panel_open\", \"topic\", \"tornado\", \"total_dissolved_solids\", \"touch_app\", \"touchpad_mouse\", \"touchpad_mouse_off\", \"tour\", \"toys\", \"toys_and_games\", \"toys_fan\", \"track_changes\", \"traffic\", \"trail_length\", \"trail_length_medium\", \"trail_length_short\", \"train\", \"tram\", \"transcribe\", \"transfer_within_a_station\", \"transform\", \"transgender\", \"transit_enterexit\", \"transition_chop\", \"transition_dissolve\", \"transition_fade\", \"transition_push\", \"transition_slide\", \"translate\", \"transportation\", \"travel\", \"travel_explore\", \"travel_luggage_and_bags\", \"trending_down\", \"trending_flat\", \"trending_up\", \"trip\", \"trip_origin\", \"trolley\", \"trophy\", \"troubleshoot\", \"try\", \"tsunami\", \"tsv\", \"tty\", \"tune\", \"tungsten\", \"turn_left\", \"turn_right\", \"turn_sharp_left\", \"turn_sharp_right\", \"turn_slight_left\", \"turn_slight_right\", \"turned_in\", \"turned_in_not\", \"tv\", \"tv_gen\", \"tv_guide\", \"tv_off\", \"tv_options_edit_channels\", \"tv_options_input_settings\", \"tv_remote\", \"tv_signin\", \"tv_with_assistant\", \"two_pager\", \"two_wheeler\", \"type_specimen\", \"u_turn_left\", \"u_turn_right\", \"ulna_radius\", \"ulna_radius_alt\", \"umbrella\", \"unarchive\", \"undo\", \"unfold_less\", \"unfold_less_double\", \"unfold_more\", \"unfold_more_double\", \"ungroup\", \"universal_currency\", \"universal_currency_alt\", \"universal_local\", \"unknown_2\", \"unknown_5\", \"unknown_document\", \"unknown_med\", \"unlicense\", \"unpublished\", \"unsubscribe\", \"upcoming\", \"update\", \"update_disabled\", \"upgrade\", \"upload\", \"upload_2\", \"upload_file\", \"urology\", \"usb\", \"usb_off\", \"user_attributes\", \"vaccines\", \"vacuum\", \"valve\", \"vape_free\", \"vaping_rooms\", \"variable_add\", \"variable_insert\", \"variable_remove\", \"variables\", \"ventilator\", \"verified\", \"verified_user\", \"vertical_align_bottom\", \"vertical_align_center\", \"vertical_align_top\", \"vertical_distribute\", \"vertical_shades\", \"vertical_shades_closed\", \"vertical_split\", \"vibration\", \"video_call\", \"video_camera_back\", \"video_camera_front\", \"video_camera_front_off\", \"video_chat\", \"video_file\", \"video_label\", \"video_library\", \"video_search\", \"video_settings\", \"video_stable\", \"videocam\", \"videocam_off\", \"videogame_asset\", \"videogame_asset_off\", \"view_agenda\", \"view_array\", \"view_carousel\", \"view_column\", \"view_column_2\", \"view_comfy\", \"view_comfy_alt\", \"view_compact\", \"view_compact_alt\", \"view_cozy\", \"view_day\", \"view_headline\", \"view_in_ar\", \"view_in_ar_new\", \"view_in_ar_off\", \"view_kanban\", \"view_list\", \"view_module\", \"view_quilt\", \"view_sidebar\", \"view_stream\", \"view_timeline\", \"view_week\", \"vignette\", \"villa\", \"visibility\", \"visibility_lock\", \"visibility_off\", \"vital_signs\", \"vitals\", \"voice_chat\", \"voice_over_off\", \"voice_selection\", \"voicemail\", \"volcano\", \"volume_down\", \"volume_down_alt\", \"volume_mute\", \"volume_off\", \"volume_up\", \"volunteer_activism\", \"voting_chip\", \"vpn_key\", \"vpn_key_alert\", \"vpn_key_off\", \"vpn_lock\", \"vr180_create2d\", \"vr180_create2d_off\", \"vrpano\", \"wall_art\", \"wall_lamp\", \"wallet\", \"wallpaper\", \"wallpaper_slideshow\", \"ward\", \"warehouse\", \"warning\", \"warning_amber\", \"warning_off\", \"wash\", \"watch\", \"watch_button_press\", \"watch_later\", \"watch_off\", \"watch_screentime\", \"watch_wake\", \"water\", \"water_bottle\", \"water_bottle_large\", \"water_damage\", \"water_do\", \"water_drop\", \"water_ec\", \"water_full\", \"water_heater\", \"water_lock\", \"water_loss\", \"water_lux\", \"water_medium\", \"water_orp\", \"water_ph\", \"water_pump\", \"water_voc\", \"waterfall_chart\", \"waves\", \"waving_hand\", \"wb_auto\", \"wb_cloudy\", \"wb_incandescent\", \"wb_iridescent\", \"wb_shade\", \"wb_sunny\", \"wb_twilight\", \"wc\", \"weather_hail\", \"weather_mix\", \"weather_snowy\", \"web\", \"web_asset\", \"web_asset_off\", \"web_stories\", \"web_traffic\", \"webhook\", \"weekend\", \"weight\", \"west\", \"whatshot\", \"wheelchair_pickup\", \"where_to_vote\", \"widgets\", \"width\", \"width_full\", \"width_normal\", \"width_wide\", \"wifi\", \"wifi_1_bar\", \"wifi_2_bar\", \"wifi_add\", \"wifi_calling\", \"wifi_calling_1\", \"wifi_calling_2\", \"wifi_calling_3\", \"wifi_channel\", \"wifi_find\", \"wifi_home\", \"wifi_lock\", \"wifi_notification\", \"wifi_off\", \"wifi_password\", \"wifi_protected_setup\", \"wifi_proxy\", \"wifi_tethering\", \"wifi_tethering_error\", \"wifi_tethering_off\", \"wind_power\", \"window\", \"window_closed\", \"window_open\", \"window_sensor\", \"wine_bar\", \"woman\", \"woman_2\", \"work\", \"work_alert\", \"work_history\", \"work_off\", \"work_outline\", \"work_update\", \"workflow\", \"workspace_premium\", \"workspaces\", \"workspaces_outline\", \"wounds_injuries\", \"wrap_text\", \"wrist\", \"wrong_location\", \"wysiwyg\", \"yard\", \"your_trips\", \"youtube_activity\", \"youtube_searched_for\", \"zone_person_alert\", \"zone_person_idle\", \"zone_person_urgent\", \"zoom_in\", \"zoom_in_map\", \"zoom_out\", \"zoom_out_map\", }\n", "lib/streamlit/file_util.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport contextlib\nimport errno\nimport io\nimport os\nfrom pathlib import Path\n\nfrom streamlit import env_util, util\nfrom streamlit.string_util import is_binary_string\n\n# Configuration and credentials are stored inside the ~/.streamlit folder\nCONFIG_FOLDER_NAME = \".streamlit\"\n\n# If enableStaticServing is enabled, static file served from the ./static folder\nAPP_STATIC_FOLDER_NAME = \"static\"\n\n\ndef get_encoded_file_data(\n    data: bytes, encoding: str = \"auto\"\n) -> io.StringIO | io.BytesIO:\n    \"\"\"Coerce bytes to a BytesIO or a StringIO.\n\n    Parameters\n    ----------\n    data : bytes\n    encoding : str\n\n    Returns\n    -------\n    BytesIO or StringIO\n        If the file's data is in a well-known textual format (or if the encoding\n        parameter is set), return a StringIO. Otherwise, return BytesIO.\n\n    \"\"\"\n    if encoding == \"auto\":\n        # If the file does not look like a pure binary file, assume\n        # it's utf-8. It would be great if we could guess it a little\n        # more smartly here, but it is what it is!\n        data_encoding = None if is_binary_string(data) else \"utf-8\"\n    else:\n        data_encoding = encoding\n\n    if data_encoding:\n        return io.StringIO(data.decode(data_encoding))\n\n    return io.BytesIO(data)\n\n\n@contextlib.contextmanager\ndef streamlit_read(path, binary=False):\n    \"\"\"Opens a context to read this file relative to the streamlit path.\n\n    For example:\n\n    with streamlit_read('foo.txt') as foo:\n        ...\n\n    opens the file `.streamlit/foo.txt`\n\n    path   - the path to write to (within the streamlit directory)\n    binary - set to True for binary IO\n    \"\"\"\n    filename = get_streamlit_file_path(path)\n    if os.stat(filename).st_size == 0:\n        raise util.Error('Read zero byte file: \"%s\"' % filename)\n\n    mode = \"r\"\n    if binary:\n        mode += \"b\"\n    with open(os.path.join(CONFIG_FOLDER_NAME, path), mode) as handle:\n        yield handle\n\n\n@contextlib.contextmanager\ndef streamlit_write(path, binary=False):\n    \"\"\"Opens a file for writing within the streamlit path, and\n    ensuring that the path exists. For example:\n\n        with streamlit_write('foo/bar.txt') as bar:\n            ...\n\n    opens the file .streamlit/foo/bar.txt for writing,\n    creating any necessary directories along the way.\n\n    path   - the path to write to (within the streamlit directory)\n    binary - set to True for binary IO\n    \"\"\"\n    mode = \"w\"\n    if binary:\n        mode += \"b\"\n    path = get_streamlit_file_path(path)\n    os.makedirs(os.path.dirname(path), exist_ok=True)\n    try:\n        with open(path, mode) as handle:\n            yield handle\n    except OSError as e:\n        msg = [\"Unable to write file: %s\" % os.path.abspath(path)]\n        if e.errno == errno.EINVAL and env_util.IS_DARWIN:\n            msg.append(\n                \"Python is limited to files below 2GB on OSX. \"\n                \"See https://bugs.python.org/issue24658\"\n            )\n        raise util.Error(\"\\n\".join(msg))\n\n\ndef get_static_dir() -> str:\n    \"\"\"Get the folder where static HTML/JS/CSS files live.\"\"\"\n    dirname = os.path.dirname(os.path.normpath(__file__))\n    return os.path.normpath(os.path.join(dirname, \"static\"))\n\n\ndef get_app_static_dir(main_script_path: str) -> str:\n    \"\"\"Get the folder where app static files live\"\"\"\n    main_script_path = Path(main_script_path)\n    static_dir = main_script_path.parent / APP_STATIC_FOLDER_NAME\n    return os.path.abspath(static_dir)\n\n\ndef get_streamlit_file_path(*filepath) -> str:\n    \"\"\"Return the full path to a file in ~/.streamlit.\n\n    This doesn't guarantee that the file (or its directory) exists.\n    \"\"\"\n    # os.path.expanduser works on OSX, Linux and Windows\n    home = os.path.expanduser(\"~\")\n    if home is None:\n        raise RuntimeError(\"No home directory.\")\n\n    return os.path.join(home, CONFIG_FOLDER_NAME, *filepath)\n\n\ndef get_project_streamlit_file_path(*filepath):\n    \"\"\"Return the full path to a filepath in ${CWD}/.streamlit.\n\n    This doesn't guarantee that the file (or its directory) exists.\n    \"\"\"\n    return os.path.join(os.getcwd(), CONFIG_FOLDER_NAME, *filepath)\n\n\ndef file_is_in_folder_glob(filepath: str, folderpath_glob: str) -> bool:\n    \"\"\"Test whether a file is in some folder with globbing support.\n\n    Parameters\n    ----------\n    filepath : str\n        A file path.\n    folderpath_glob: str\n        A path to a folder that may include globbing.\n\n    \"\"\"\n    # Make the glob always end with \"/*\" so we match files inside subfolders of\n    # folderpath_glob.\n    if not folderpath_glob.endswith(\"*\"):\n        if folderpath_glob.endswith(\"/\"):\n            folderpath_glob += \"*\"\n        else:\n            folderpath_glob += \"/*\"\n\n    import fnmatch\n\n    file_dir = os.path.dirname(filepath) + \"/\"\n    return fnmatch.fnmatch(file_dir, folderpath_glob)\n\n\ndef get_directory_size(directory: str) -> int:\n    \"\"\"Return the size of a directory in bytes.\"\"\"\n    total_size = 0\n    for dirpath, _, filenames in os.walk(directory):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            total_size += os.path.getsize(fp)\n    return total_size\n\n\ndef file_in_pythonpath(filepath: str) -> bool:\n    \"\"\"Test whether a filepath is in the same folder of a path specified in the PYTHONPATH env variable.\n\n\n    Parameters\n    ----------\n    filepath : str\n        An absolute file path.\n\n    Returns\n    -------\n    boolean\n        True if contained in PYTHONPATH, False otherwise. False if PYTHONPATH is not defined or empty.\n\n    \"\"\"\n    pythonpath = os.environ.get(\"PYTHONPATH\", \"\")\n    if len(pythonpath) == 0:\n        return False\n\n    absolute_paths = [os.path.abspath(path) for path in pythonpath.split(os.pathsep)]\n    return any(\n        file_is_in_folder_glob(os.path.normpath(filepath), path)\n        for path in absolute_paths\n    )\n\n\ndef normalize_path_join(*args):\n    \"\"\"Return the normalized path of the joined path.\n\n    Parameters\n    ----------\n    *args : str\n        The path components to join.\n\n    Returns\n    -------\n    str\n        The normalized path of the joined path.\n    \"\"\"\n    return os.path.normpath(os.path.join(*args))\n\n\ndef get_main_script_directory(main_script):\n    \"\"\"Return the full path to the main script directory.\n\n    Parameters\n    ----------\n    main_script : str\n        The main script path. The path can be an absolute path or a relative\n        path.\n\n    Returns\n    -------\n    str\n        The full path to the main script directory.\n    \"\"\"\n    main_script_path = normalize_path_join(os.getcwd(), main_script)\n\n    return os.path.dirname(main_script_path)\n", "lib/streamlit/config_option.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Class to store a key-value pair for the config system.\"\"\"\n\nfrom __future__ import annotations\n\nimport datetime\nimport re\nimport textwrap\nfrom typing import Any, Callable\n\nfrom streamlit import util\nfrom streamlit.case_converters import to_snake_case\n\n\nclass ConfigOption:\n    '''Stores a Streamlit configuration option.\n\n    A configuration option, like 'browser.serverPort', which indicates which port\n    to use when connecting to the proxy. There are two ways to create a\n    ConfigOption:\n\n    Simple ConfigOptions are created as follows:\n\n        ConfigOption('browser.serverPort',\n            description = 'Connect to the proxy at this port.',\n            default_val = 8501)\n\n    More complex config options resolve their values at runtime as follows:\n\n        @ConfigOption('browser.serverPort')\n        def _proxy_port():\n            \"\"\"Connect to the proxy at this port.\n\n            Defaults to 8501.\n            \"\"\"\n            return 8501\n\n    NOTE: For complex config options, the function is called each time the\n    option.value is evaluated!\n\n    Attributes\n    ----------\n    key : str\n        The fully qualified section.name\n    value : any\n        The value for this option. If this is a complex config option then\n        the callback is called EACH TIME value is evaluated.\n    section : str\n        The section of this option. Example: 'global'.\n    name : str\n        See __init__.\n    description : str\n        See __init__.\n    where_defined : str\n        Indicates which file set this config option.\n        ConfigOption.DEFAULT_DEFINITION means this file.\n    is_default: bool\n        True if the config value is equal to its default value.\n    visibility : {\"visible\", \"hidden\"}\n        See __init__.\n    scriptable : bool\n        See __init__.\n    deprecated: bool\n        See __init__.\n    deprecation_text : str or None\n        See __init__.\n    expiration_date : str or None\n        See __init__.\n    replaced_by : str or None\n        See __init__.\n    sensitive : bool\n        See __init__.\n    env_var: str\n        The name of the environment variable that can be used to set the option.\n    '''\n\n    # This is a special value for ConfigOption.where_defined which indicates\n    # that the option default was not overridden.\n    DEFAULT_DEFINITION = \"<default>\"\n\n    # This is a special value for ConfigOption.where_defined which indicates\n    # that the options was defined by Streamlit's own code.\n    STREAMLIT_DEFINITION = \"<streamlit>\"\n\n    def __init__(\n        self,\n        key: str,\n        description: str | None = None,\n        default_val: Any | None = None,\n        visibility: str = \"visible\",\n        scriptable: bool = False,\n        deprecated: bool = False,\n        deprecation_text: str | None = None,\n        expiration_date: str | None = None,\n        replaced_by: str | None = None,\n        type_: type = str,\n        sensitive: bool = False,\n    ):\n        \"\"\"Create a ConfigOption with the given name.\n\n        Parameters\n        ----------\n        key : str\n            Should be of the form \"section.optionName\"\n            Examples: server.name, deprecation.v1_0_featureName\n        description : str\n            Like a comment for the config option.\n        default_val : any\n            The value for this config option.\n        visibility : {\"visible\", \"hidden\"}\n            Whether this option should be shown to users.\n        scriptable : bool\n            Whether this config option can be set within a user script.\n        deprecated: bool\n            Whether this config option is deprecated.\n        deprecation_text : str or None\n            Required if deprecated == True. Set this to a string explaining\n            what to use instead.\n        expiration_date : str or None\n            Required if deprecated == True. set this to the date at which it\n            will no longer be accepted. Format: 'YYYY-MM-DD'.\n        replaced_by : str or None\n            If this is option has been deprecated in favor or another option,\n            set this to the path to the new option. Example:\n            'server.runOnSave'. If this is set, the 'deprecated' option\n            will automatically be set to True, and deprecation_text will have a\n            meaningful default (unless you override it).\n        type_ : one of str, int, float or bool\n            Useful to cast the config params sent by cmd option parameter.\n        sensitive: bool\n            Sensitive configuration options cannot be set by CLI parameter.\n        \"\"\"\n        # Parse out the section and name.\n        self.key = key\n        key_format = (\n            # Capture a group called \"section\"\n            r\"(?P<section>\"\n            # Matching text comprised of letters and numbers that begins\n            # with a lowercase letter with an optional \"_\" preceding it.\n            # Examples: \"_section\", \"section1\"\n            r\"\\_?[a-z][a-zA-Z0-9]*\"\n            r\")\"\n            # Separator between groups\n            r\"\\.\"\n            # Capture a group called \"name\"\n            r\"(?P<name>\"\n            # Match text comprised of letters and numbers beginning with a\n            # lowercase letter.\n            # Examples: \"name\", \"nameOfConfig\", \"config1\"\n            r\"[a-z][a-zA-Z0-9]*\"\n            r\")$\"\n        )\n        match = re.match(key_format, self.key)\n        assert match, f'Key \"{self.key}\" has invalid format.'\n        self.section, self.name = match.group(\"section\"), match.group(\"name\")\n\n        self.description = description\n\n        self.visibility = visibility\n        self.scriptable = scriptable\n        self.default_val = default_val\n        self.deprecated = deprecated\n        self.replaced_by = replaced_by\n        self.is_default = True\n        self._get_val_func: Callable[[], Any] | None = None\n        self.where_defined = ConfigOption.DEFAULT_DEFINITION\n        self.type = type_\n        self.sensitive = sensitive\n\n        if self.replaced_by:\n            self.deprecated = True\n            if deprecation_text is None:\n                deprecation_text = \"Replaced by %s.\" % self.replaced_by\n\n        if self.deprecated:\n            assert expiration_date, \"expiration_date is required for deprecated items\"\n            assert deprecation_text, \"deprecation_text is required for deprecated items\"\n            self.expiration_date = expiration_date\n            self.deprecation_text = textwrap.dedent(deprecation_text)\n\n        self.set_value(default_val)\n\n    def __repr__(self) -> str:\n        return util.repr_(self)\n\n    def __call__(self, get_val_func: Callable[[], Any]) -> ConfigOption:\n        \"\"\"Assign a function to compute the value for this option.\n\n        This method is called when ConfigOption is used as a decorator.\n\n        Parameters\n        ----------\n        get_val_func : function\n            A function which will be called to get the value of this parameter.\n            We will use its docString as the description.\n\n        Returns\n        -------\n        ConfigOption\n            Returns self, which makes testing easier. See config_test.py.\n\n        \"\"\"\n        assert (\n            get_val_func.__doc__\n        ), \"Complex config options require doc strings for their description.\"\n        self.description = get_val_func.__doc__\n        self._get_val_func = get_val_func\n        return self\n\n    @property\n    def value(self) -> Any:\n        \"\"\"Get the value of this config option.\"\"\"\n        if self._get_val_func is None:\n            return None\n        return self._get_val_func()\n\n    def set_value(self, value: Any, where_defined: str | None = None) -> None:\n        \"\"\"Set the value of this option.\n\n        Parameters\n        ----------\n        value\n            The new value for this parameter.\n        where_defined : str\n            New value to remember where this parameter was set.\n\n        \"\"\"\n        self._get_val_func = lambda: value\n\n        if where_defined is None:\n            self.where_defined = ConfigOption.DEFAULT_DEFINITION\n        else:\n            self.where_defined = where_defined\n\n        self.is_default = value == self.default_val\n\n        if self.deprecated and self.where_defined != ConfigOption.DEFAULT_DEFINITION:\n            details = {\n                \"key\": self.key,\n                \"file\": self.where_defined,\n                \"explanation\": self.deprecation_text,\n                \"date\": self.expiration_date,\n            }\n\n            if self.is_expired():\n                # Import here to avoid circular imports\n                from streamlit.logger import get_logger\n\n                LOGGER = get_logger(__name__)\n                LOGGER.error(\n                    textwrap.dedent(\n                        \"\"\"\n                    \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n                    %(key)s IS NO LONGER SUPPORTED.\n\n                    %(explanation)s\n\n                    Please update %(file)s.\n                    \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n                    \"\"\"\n                    )\n                    % details\n                )\n            else:\n                # Import here to avoid circular imports\n                from streamlit.logger import get_logger\n\n                LOGGER = get_logger(__name__)\n                LOGGER.warning(\n                    textwrap.dedent(\n                        \"\"\"\n                    \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n                    %(key)s IS DEPRECATED.\n                    %(explanation)s\n\n                    This option will be removed on or after %(date)s.\n\n                    Please update %(file)s.\n                    \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n                    \"\"\"\n                    )\n                    % details\n                )\n\n    def is_expired(self) -> bool:\n        \"\"\"Returns true if expiration_date is in the past.\"\"\"\n        if not self.deprecated:\n            return False\n\n        expiration_date = _parse_yyyymmdd_str(self.expiration_date)\n        now = datetime.datetime.now()\n        return now > expiration_date\n\n    @property\n    def env_var(self):\n        \"\"\"\n        Get the name of the environment variable that can be used to set the option.\n        \"\"\"\n        name = self.key.replace(\".\", \"_\")\n        return f\"STREAMLIT_{to_snake_case(name).upper()}\"\n\n\ndef _parse_yyyymmdd_str(date_str: str) -> datetime.datetime:\n    year, month, day = (int(token) for token in date_str.split(\"-\", 2))\n    return datetime.datetime(year, month, day)\n", "lib/streamlit/echo.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport ast\nimport contextlib\nimport re\nimport textwrap\nimport traceback\nfrom typing import Any, Iterable\n\nfrom streamlit.runtime.metrics_util import gather_metrics\n\n_SPACES_RE = re.compile(\"\\\\s*\")\n_EMPTY_LINE_RE = re.compile(\"\\\\s*\\n\")\n\n\n@gather_metrics(\"echo\")\n@contextlib.contextmanager\ndef echo(code_location=\"above\"):\n    \"\"\"Use in a `with` block to draw some code on the app, then execute it.\n\n    Parameters\n    ----------\n    code_location : \"above\" or \"below\"\n        Whether to show the echoed code before or after the results of the\n        executed code block.\n\n    Example\n    -------\n    >>> import streamlit as st\n    >>>\n    >>> with st.echo():\n    >>>     st.write('This code will be printed')\n\n    \"\"\"\n    from streamlit import code, empty, source_util, warning\n\n    if code_location == \"below\":\n        show_code = code\n        show_warning = warning\n    else:\n        placeholder = empty()\n        show_code = placeholder.code\n        show_warning = placeholder.warning\n\n    try:\n        # Get stack frame *before* running the echoed code. The frame's\n        # line number will point to the `st.echo` statement we're running.\n        frame = traceback.extract_stack()[-3]\n        filename, start_line = frame.filename, frame.lineno or 0\n\n        # Read the file containing the source code of the echoed statement.\n        with source_util.open_python_file(filename) as source_file:\n            source_lines = source_file.readlines()\n\n        # Use ast to parse the Python file and find the code block to display\n        root_node = ast.parse(\"\".join(source_lines))\n        line_to_node_map: dict[int, Any] = {}\n\n        def collect_body_statements(node: ast.AST) -> None:\n            if not hasattr(node, \"body\"):\n                return\n            for child in ast.iter_child_nodes(node):\n                # If child doesn't have \"lineno\", it is not something we could display\n                if hasattr(child, \"lineno\"):\n                    line_to_node_map[child.lineno] = child\n                    collect_body_statements(child)\n\n        collect_body_statements(root_node)\n\n        # In AST module the lineno (line numbers) are 1-indexed,\n        # so we decrease it by 1 to lookup in source lines list\n        echo_block_start_line = line_to_node_map[start_line].body[0].lineno - 1\n        echo_block_end_line = line_to_node_map[start_line].end_lineno\n        lines_to_display = source_lines[echo_block_start_line:echo_block_end_line]\n\n        code_string = textwrap.dedent(\"\".join(lines_to_display))\n\n        # Run the echoed code...\n        yield\n\n        # And draw the code string to the app!\n        show_code(code_string, \"python\")\n\n    except FileNotFoundError as err:\n        show_warning(\"Unable to display code. %s\" % err)\n\n\ndef _get_initial_indent(lines: Iterable[str]) -> int:\n    \"\"\"Return the indent of the first non-empty line in the list.\n    If all lines are empty, return 0.\n    \"\"\"\n    for line in lines:\n        indent = _get_indent(line)\n        if indent is not None:\n            return indent\n\n    return 0\n\n\ndef _get_indent(line: str) -> int | None:\n    \"\"\"Get the number of whitespaces at the beginning of the given line.\n    If the line is empty, or if it contains just whitespace and a newline,\n    return None.\n    \"\"\"\n    if _EMPTY_LINE_RE.match(line) is not None:\n        return None\n\n    match = _SPACES_RE.match(line)\n    return match.end() if match is not None else 0\n", "lib/streamlit/__main__.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom streamlit.web.cli import main\n\nif __name__ == \"__main__\":\n    # Set prog_name so that the Streamlit server sees the same command line\n    # string whether streamlit is called directly or via `python -m streamlit`.\n    main(prog_name=\"streamlit\")\n", "lib/streamlit/time_util.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport math\nfrom datetime import date, timedelta\nfrom typing import Literal, overload\n\nfrom streamlit.errors import MarkdownFormattedException, StreamlitAPIException\n\n\ndef adjust_years(input_date: date, years: int) -> date:\n    \"\"\"Add or subtract years from a date.\"\"\"\n    try:\n        # Attempt to directly add/subtract years\n        return input_date.replace(year=input_date.year + years)\n    except ValueError as err:\n        # Handle case for leap year date (February 29) that doesn't exist in the target year\n        # by moving the date to February 28\n        if input_date.month == 2 and input_date.day == 29:\n            return input_date.replace(year=input_date.year + years, month=2, day=28)\n\n        raise StreamlitAPIException(\n            f\"Date {input_date} does not exist in the target year {input_date.year + years}. \"\n            \"This should never happen. Please report this bug.\"\n        ) from err\n\n\nclass BadTimeStringError(StreamlitAPIException):\n    \"\"\"Raised when a bad time string argument is passed.\"\"\"\n\n    def __init__(self, t: str):\n        MarkdownFormattedException.__init__(\n            self,\n            \"Time string doesn't look right. It should be formatted as\"\n            f\"`'1d2h34m'` or `2 days`, for example. Got: {t}\",\n        )\n\n\n@overload\ndef time_to_seconds(\n    t: float | timedelta | str | None, *, coerce_none_to_inf: Literal[False]\n) -> float | None: ...\n\n\n@overload\ndef time_to_seconds(t: float | timedelta | str | None) -> float: ...\n\n\ndef time_to_seconds(\n    t: float | timedelta | str | None, *, coerce_none_to_inf: bool = True\n) -> float | None:\n    \"\"\"\n    Convert a time string value to a float representing \"number of seconds\".\n    \"\"\"\n    if coerce_none_to_inf and t is None:\n        return math.inf\n    if isinstance(t, timedelta):\n        return t.total_seconds()\n    if isinstance(t, str):\n        import numpy as np\n        import pandas as pd\n\n        try:\n            seconds: float = pd.Timedelta(t).total_seconds()\n\n            if np.isnan(seconds):\n                raise BadTimeStringError(t)\n\n            return seconds\n        except ValueError as ex:\n            raise BadTimeStringError(t) from ex\n\n    return t\n", "lib/streamlit/env_util.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport os\nimport platform\nimport re\nimport sys\n\n_system = platform.system()\nIS_WINDOWS = _system == \"Windows\"\nIS_DARWIN = _system == \"Darwin\"\nIS_LINUX_OR_BSD = (_system == \"Linux\") or (\"BSD\" in _system)\n\n\ndef is_pex() -> bool:\n    \"\"\"Return if streamlit running in pex.\n\n    Pex modifies sys.path so the pex file is the first path and that's\n    how we determine we're running in the pex file.\n    \"\"\"\n    if re.match(r\".*pex$\", sys.path[0]):\n        return True\n    return False\n\n\ndef is_repl() -> bool:\n    \"\"\"Return True if running in the Python REPL.\"\"\"\n    import inspect\n\n    root_frame = inspect.stack()[-1]\n    filename = root_frame[1]  # 1 is the filename field in this tuple.\n\n    if filename.endswith(os.path.join(\"bin\", \"ipython\")):\n        return True\n\n    # <stdin> is what the basic Python REPL calls the root frame's\n    # filename, and <string> is what iPython sometimes calls it.\n    if filename in (\"<stdin>\", \"<string>\"):\n        return True\n\n    return False\n\n\ndef is_executable_in_path(name: str) -> bool:\n    \"\"\"Check if executable is in OS path.\"\"\"\n    from shutil import which\n\n    return which(name) is not None\n", "lib/streamlit/__init__.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# isort: skip_file\n\n\"\"\"Streamlit.\n\nHow to use Streamlit in 3 seconds:\n\n    1. Write an app\n    >>> import streamlit as st\n    >>> st.write(anything_you_want)\n\n    2. Run your app\n    $ streamlit run my_script.py\n\n    3. Use your app\n    A new tab will open on your browser. That's your Streamlit app!\n\n    4. Modify your code, save it, and watch changes live on your browser.\n\nTake a look at the other commands in this module to find out what else\nStreamlit can do:\n\n    >>> dir(streamlit)\n\nOr try running our \"Hello World\":\n\n    $ streamlit hello\n\nFor more detailed info, see https://docs.streamlit.io.\n\"\"\"\n\n# IMPORTANT: Prefix with an underscore anything that the user shouldn't see.\n\nimport os as _os\n\n# Set Matplotlib backend to avoid a crash.\n# The default Matplotlib backend crashes Python on OSX when run on a thread\n# that's not the main thread, so here we set a safer backend as a fix.\n# This fix is OS-independent. We didn't see a good reason to make this\n# Mac-only. Consistency within Streamlit seemed more important.\n# IMPORTANT: This needs to run on top of all imports before any other\n# import of matplotlib could happen.\n_os.environ[\"MPLBACKEND\"] = \"Agg\"\n\n\n# Must be at the top, to avoid circular dependency.\nfrom streamlit import logger as _logger\nfrom streamlit import config as _config\nfrom streamlit.deprecation_util import deprecate_func_name as _deprecate_func_name\nfrom streamlit.version import STREAMLIT_VERSION_STRING as _STREAMLIT_VERSION_STRING\n\n# Give the package a version.\n__version__ = _STREAMLIT_VERSION_STRING\n\nfrom streamlit.delta_generator import (\n    main_dg as _main_dg,\n    sidebar_dg as _sidebar_dg,\n    event_dg as _event_dg,\n    bottom_dg as _bottom_dg,\n)\n\nfrom streamlit.elements.dialog_decorator import dialog_decorator as _dialog_decorator\nfrom streamlit.runtime.caching import (\n    cache_resource as _cache_resource,\n    cache_data as _cache_data,\n    cache as _cache,\n)\nfrom streamlit.runtime.connection_factory import (\n    connection_factory as _connection,\n)\nfrom streamlit.runtime.fragment import fragment as _fragment\nfrom streamlit.runtime.metrics_util import gather_metrics as _gather_metrics\nfrom streamlit.runtime.secrets import secrets_singleton as _secrets_singleton\nfrom streamlit.runtime.state import (\n    SessionStateProxy as _SessionStateProxy,\n    QueryParamsProxy as _QueryParamsProxy,\n)\nfrom streamlit.user_info import UserInfoProxy as _UserInfoProxy\nfrom streamlit.commands.experimental_query_params import (\n    get_query_params as _get_query_params,\n    set_query_params as _set_query_params,\n)\n\nimport streamlit.column_config as _column_config\n\n\n# Modules that the user should have access to. These are imported with the \"as\" syntax and the same name; note that renaming the import with \"as\" does not make it an explicit export.\n# In this case, you should import it with an underscore to make clear that it is internal and then assign it to a variable with the new intended name.\n# You can check the export behavior by running 'mypy --strict example_app.py', which disables implicit_reexport, where you use the respective command in the example_app.py Streamlit app.\n\nfrom streamlit.echo import echo as echo\nfrom streamlit.commands.logo import logo as logo\nfrom streamlit.commands.navigation import navigation as navigation\nfrom streamlit.navigation.page import Page as Page\nfrom streamlit.elements.spinner import spinner as spinner\n\nfrom streamlit.commands.page_config import set_page_config as set_page_config\nfrom streamlit.commands.execution_control import (\n    stop as stop,\n    rerun as rerun,\n    switch_page as switch_page,\n)\n\n\ndef _update_logger() -> None:\n    _logger.set_log_level(_config.get_option(\"logger.level\").upper())\n    _logger.update_formatter()\n    _logger.init_tornado_logs()\n\n\n# Make this file only depend on config option in an asynchronous manner. This\n# avoids a race condition when another file (such as a test file) tries to pass\n# in an alternative config.\n_config.on_config_parsed(_update_logger, True)\n\n\nsecrets = _secrets_singleton\n\n# DeltaGenerator methods:\n_main = _main_dg\nsidebar = _sidebar_dg\n_event = _event_dg\n_bottom = _bottom_dg\n\naltair_chart = _main.altair_chart\narea_chart = _main.area_chart\naudio = _main.audio\nballoons = _main.balloons\nbar_chart = _main.bar_chart\nbokeh_chart = _main.bokeh_chart\nbutton = _main.button\ncaption = _main.caption\ncamera_input = _main.camera_input\nchat_message = _main.chat_message\nchat_input = _main.chat_input\ncheckbox = _main.checkbox\ncode = _main.code\ncolumns = _main.columns\ntabs = _main.tabs\ncontainer = _main.container\ndataframe = _main.dataframe\ndata_editor = _main.data_editor\ndate_input = _main.date_input\ndivider = _main.divider\ndownload_button = _main.download_button\nexpander = _main.expander\npydeck_chart = _main.pydeck_chart\nempty = _main.empty\nerror = _main.error\nexception = _main.exception\nfile_uploader = _main.file_uploader\nform = _main.form\nform_submit_button = _main.form_submit_button\ngraphviz_chart = _main.graphviz_chart\nheader = _main.header\nhelp = _main.help\nhtml = _main.html\nimage = _main.image\ninfo = _main.info\njson = _main.json\nlatex = _main.latex\nline_chart = _main.line_chart\nlink_button = _main.link_button\nmap = _main.map\nmarkdown = _main.markdown\nmetric = _main.metric\nmultiselect = _main.multiselect\nnumber_input = _main.number_input\npage_link = _main.page_link\nplotly_chart = _main.plotly_chart\npopover = _main.popover\nprogress = _main.progress\npyplot = _main.pyplot\nradio = _main.radio\nscatter_chart = _main.scatter_chart\nselectbox = _main.selectbox\nselect_slider = _main.select_slider\nslider = _main.slider\nsnow = _main.snow\nsubheader = _main.subheader\nsuccess = _main.success\ntable = _main.table\ntext = _main.text\ntext_area = _main.text_area\ntext_input = _main.text_input\ntoggle = _main.toggle\ntime_input = _main.time_input\ntitle = _main.title\nvega_lite_chart = _main.vega_lite_chart\nvideo = _main.video\nwarning = _main.warning\nwrite = _main.write\nwrite_stream = _main.write_stream\ncolor_picker = _main.color_picker\nstatus = _main.status\n\n# Events - Note: these methods cannot be called directly on sidebar (ex: st.sidebar.toast)\ntoast = _event.toast\n\n# Config\n# We add the metrics tracking here, since importing\n# gather_metrics in config causes a circular dependency\nget_option = _gather_metrics(\"get_option\", _config.get_option)\nset_option = _gather_metrics(\"set_option\", _config.set_user_option)\n\n# Session State\nsession_state = _SessionStateProxy()\n\nquery_params = _QueryParamsProxy()\n\n# Caching\ncache_data = _cache_data\ncache_resource = _cache_resource\n# `st.cache` is deprecated and should be removed soon\ncache = _cache\n\n# Namespaces\ncolumn_config = _column_config\n\n# Connection\nconnection = _connection\n\n# Experimental APIs\nexperimental_dialog = _dialog_decorator\nexperimental_fragment = _fragment\nexperimental_user = _UserInfoProxy()\n\n_EXPERIMENTAL_QUERY_PARAMS_DEPRECATE_MSG = \"Refer to our [docs page](https://docs.streamlit.io/develop/api-reference/caching-and-state/st.query_params) for more information.\"\n\nexperimental_get_query_params = _deprecate_func_name(\n    _get_query_params,\n    \"experimental_get_query_params\",\n    \"2024-04-11\",\n    _EXPERIMENTAL_QUERY_PARAMS_DEPRECATE_MSG,\n    name_override=\"query_params\",\n)\nexperimental_set_query_params = _deprecate_func_name(\n    _set_query_params,\n    \"experimental_set_query_params\",\n    \"2024-04-11\",\n    _EXPERIMENTAL_QUERY_PARAMS_DEPRECATE_MSG,\n    name_override=\"query_params\",\n)\n\n\n# make it possible to call streamlit.components.v1.html etc. by importing it here\n# import in the very end to avoid partially-initialized module import errors, because\n# streamlit.components.v1 also uses some streamlit imports\nimport streamlit.components.v1  # noqa: F401\n", "lib/streamlit/column_config.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Column types that can be configured via the ``column_config`` parameter of ``st.dataframe`` and ``st.data_editor``.\"\"\"\n\nfrom __future__ import annotations\n\n__all__ = [\n    \"AreaChartColumn\",\n    \"Column\",\n    \"TextColumn\",\n    \"NumberColumn\",\n    \"BarChartColumn\",\n    \"CheckboxColumn\",\n    \"DatetimeColumn\",\n    \"ImageColumn\",\n    \"SelectboxColumn\",\n    \"ProgressColumn\",\n    \"LinkColumn\",\n    \"LineChartColumn\",\n    \"ListColumn\",\n    \"DateColumn\",\n    \"TimeColumn\",\n]\n\n\nfrom streamlit.elements.lib.column_types import (\n    AreaChartColumn,\n    BarChartColumn,\n    CheckboxColumn,\n    Column,\n    DateColumn,\n    DatetimeColumn,\n    ImageColumn,\n    LineChartColumn,\n    LinkColumn,\n    ListColumn,\n    NumberColumn,\n    ProgressColumn,\n    SelectboxColumn,\n    TextColumn,\n    TimeColumn,\n)\n", "lib/streamlit/case_converters.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport re\nfrom typing import Any, Callable\n\n\ndef to_upper_camel_case(snake_case_str: str) -> str:\n    \"\"\"Converts snake_case to UpperCamelCase.\n\n    Example\n    -------\n        foo_bar -> FooBar\n\n    \"\"\"\n    return \"\".join(map(str.title, snake_case_str.split(\"_\")))\n\n\ndef to_lower_camel_case(snake_case_str: str) -> str:\n    \"\"\"Converts snake_case to lowerCamelCase.\n\n    Example\n    -------\n        foo_bar -> fooBar\n        fooBar -> foobar\n\n    \"\"\"\n    words = snake_case_str.split(\"_\")\n    if len(words) > 1:\n        capitalized = [w.title() for w in words]\n        capitalized[0] = words[0]\n        return \"\".join(capitalized)\n    else:\n        return snake_case_str\n\n\ndef to_snake_case(camel_case_str: str) -> str:\n    \"\"\"Converts UpperCamelCase and lowerCamelCase to snake_case.\n\n    Examples\n    --------\n        fooBar -> foo_bar\n        BazBang -> baz_bang\n\n    \"\"\"\n    s1 = re.sub(\"(.)([A-Z][a-z]+)\", r\"\\1_\\2\", camel_case_str)\n    return re.sub(\"([a-z0-9])([A-Z])\", r\"\\1_\\2\", s1).lower()\n\n\ndef convert_dict_keys(\n    func: Callable[[str], str], in_dict: dict[Any, Any]\n) -> dict[Any, Any]:\n    \"\"\"Apply a conversion function to all keys in a dict.\n\n    Parameters\n    ----------\n    func : callable\n        The function to apply. Takes a str and returns a str.\n    in_dict : dict\n        The dictionary to convert. If some value in this dict is itself a dict,\n        it also gets recursively converted.\n\n    Returns\n    -------\n    dict\n        A new dict with all the contents of `in_dict`, but with the keys\n        converted by `func`.\n\n    \"\"\"\n    out_dict = {}\n    for k, v in in_dict.items():\n        converted_key = func(k)\n\n        if isinstance(v, dict):\n            out_dict[converted_key] = convert_dict_keys(func, v)\n        else:\n            out_dict[converted_key] = v\n    return out_dict\n", "lib/streamlit/cli_util.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Utilities related to the CLI.\"\"\"\n\nfrom __future__ import annotations\n\n\ndef print_to_cli(message: str, **kwargs) -> None:\n    \"\"\"Print a message to the terminal using click if available, else print\n    using the built-in print function.\n\n    You can provide any keyword arguments that click.secho supports.\n    \"\"\"\n    try:\n        import click\n\n        click.secho(message, **kwargs)\n    except ImportError:\n        print(message, flush=True)  # noqa: T201\n\n\ndef style_for_cli(message: str, **kwargs) -> str:\n    \"\"\"Style a message using click if available, else return the message\n    unchanged.\n\n    You can provide any keyword arguments that click.style supports.\n    \"\"\"\n\n    try:\n        import click\n\n        return click.style(message, **kwargs)\n    except ImportError:\n        return message\n", "lib/streamlit/logger.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Logging module.\"\"\"\n\nfrom __future__ import annotations\n\nimport logging\nimport sys\nfrom typing import Final\n\nDEFAULT_LOG_MESSAGE: Final = \"%(asctime)s %(levelname) -7s %(name)s: %(message)s\"\n\n# Loggers for each name are saved here.\n_loggers: dict[str, logging.Logger] = {}\n\n# The global log level is set here across all names.\n_global_log_level = logging.INFO\n\n\ndef set_log_level(level: str | int) -> None:\n    \"\"\"Set log level.\"\"\"\n    logger = get_logger(__name__)\n\n    if isinstance(level, str):\n        level = level.upper()\n    if level == \"CRITICAL\" or level == logging.CRITICAL:\n        log_level = logging.CRITICAL\n    elif level == \"ERROR\" or level == logging.ERROR:\n        log_level = logging.ERROR\n    elif level == \"WARNING\" or level == logging.WARNING:\n        log_level = logging.WARNING\n    elif level == \"INFO\" or level == logging.INFO:\n        log_level = logging.INFO\n    elif level == \"DEBUG\" or level == logging.DEBUG:\n        log_level = logging.DEBUG\n    else:\n        msg = 'undefined log level \"%s\"' % level\n        logger.critical(msg)\n        sys.exit(1)\n\n    for log in _loggers.values():\n        log.setLevel(log_level)\n\n    global _global_log_level\n    _global_log_level = log_level\n\n\ndef setup_formatter(logger: logging.Logger) -> None:\n    \"\"\"Set up the console formatter for a given logger.\"\"\"\n    # Deregister any previous console loggers.\n    if hasattr(logger, \"streamlit_console_handler\"):\n        logger.removeHandler(logger.streamlit_console_handler)\n\n    logger.streamlit_console_handler = logging.StreamHandler()  # type: ignore[attr-defined]\n\n    # Import here to avoid circular imports\n    from streamlit import config\n\n    if config._config_options:\n        # logger is required in ConfigOption.set_value\n        # Getting the config option before the config file has been parsed\n        # can create an infinite loop\n        message_format = config.get_option(\"logger.messageFormat\")\n    else:\n        message_format = DEFAULT_LOG_MESSAGE\n    formatter = logging.Formatter(fmt=message_format)\n    formatter.default_msec_format = \"%s.%03d\"\n    logger.streamlit_console_handler.setFormatter(formatter)  # type: ignore[attr-defined]\n\n    # Register the new console logger.\n    logger.addHandler(logger.streamlit_console_handler)  # type: ignore[attr-defined]\n\n\ndef update_formatter() -> None:\n    for log in _loggers.values():\n        setup_formatter(log)\n\n\ndef init_tornado_logs() -> None:\n    \"\"\"Set Tornado log levels.\n\n    This function does not import any Tornado code, so it's safe to call even\n    when Server is not running.\n    \"\"\"\n    # http://www.tornadoweb.org/en/stable/log.html\n    for log in (\"access\", \"application\", \"general\"):\n        # get_logger will set the log level for the logger with the given name.\n        get_logger(f\"tornado.{log}\")\n\n\ndef get_logger(name: str) -> logging.Logger:\n    \"\"\"Return a logger.\n\n    Parameters\n    ----------\n    name : str\n        The name of the logger to use. You should just pass in __name__.\n\n    Returns\n    -------\n    Logger\n\n    \"\"\"\n    if name in _loggers.keys():\n        return _loggers[name]\n\n    if name == \"root\":\n        logger = logging.getLogger(\"streamlit\")\n    else:\n        logger = logging.getLogger(name)\n\n    logger.setLevel(_global_log_level)\n    logger.propagate = False\n    setup_formatter(logger)\n\n    _loggers[name] = logger\n\n    return logger\n", "lib/streamlit/type_util.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"A bunch of useful utilities for dealing with types.\"\"\"\n\nfrom __future__ import annotations\n\nimport contextlib\nimport copy\nimport math\nimport re\nimport types\nfrom enum import Enum, EnumMeta, auto\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    Final,\n    Iterable,\n    Literal,\n    NamedTuple,\n    Protocol,\n    Sequence,\n    Tuple,\n    TypeVar,\n    Union,\n    cast,\n    get_args,\n    overload,\n)\n\nfrom typing_extensions import TypeAlias, TypeGuard\n\nimport streamlit as st\nfrom streamlit import config, errors, logger, string_util\nfrom streamlit.errors import StreamlitAPIException\n\nif TYPE_CHECKING:\n    import graphviz\n    import numpy as np\n    import pyarrow as pa\n    import sympy\n    from pandas import DataFrame, Index, Series\n    from pandas.core.indexing import _iLocIndexer\n    from pandas.io.formats.style import Styler\n    from pandas.io.formats.style_renderer import StyleRenderer\n    from plotly.graph_objs import Figure\n    from pydeck import Deck\n\n    from streamlit.runtime.secrets import Secrets\n\n\n# Maximum number of rows to request from an unevaluated (out-of-core) dataframe\nMAX_UNEVALUATED_DF_ROWS = 10000\n\n_LOGGER = logger.get_logger(__name__)\n\n# The array value field names are part of the larger set of possible value\n# field names. See the explanation for said set below. The message types\n# associated with these fields are distinguished by storing data in a `data`\n# field in their messages, meaning they need special treatment in certain\n# circumstances. Hence, they need their own, dedicated, sub-type.\nArrayValueFieldName: TypeAlias = Literal[\n    \"double_array_value\",\n    \"int_array_value\",\n    \"string_array_value\",\n]\n\n# A frozenset containing the allowed values of the ArrayValueFieldName type.\n# Useful for membership checking.\nARRAY_VALUE_FIELD_NAMES: Final = frozenset(\n    cast(\n        \"tuple[ArrayValueFieldName, ...]\",\n        # NOTE: get_args is not recursive, so this only works as long as\n        # ArrayValueFieldName remains flat.\n        get_args(ArrayValueFieldName),\n    )\n)\n\n# These are the possible field names that can be set in the `value` oneof-field\n# of the WidgetState message (schema found in .proto/WidgetStates.proto).\n# We need these as a literal type to ensure correspondence with the protobuf\n# schema in certain parts of the python code.\n# TODO(harahu): It would be preferable if this type was automatically derived\n#  from the protobuf schema, rather than manually maintained. Not sure how to\n#  achieve that, though.\nValueFieldName: TypeAlias = Literal[\n    ArrayValueFieldName,\n    \"arrow_value\",\n    \"bool_value\",\n    \"bytes_value\",\n    \"double_value\",\n    \"file_uploader_state_value\",\n    \"int_value\",\n    \"json_value\",\n    \"string_value\",\n    \"trigger_value\",\n    \"string_trigger_value\",\n]\n\nV_co = TypeVar(\n    \"V_co\",\n    covariant=True,  # https://peps.python.org/pep-0484/#covariance-and-contravariance\n)\n\nT = TypeVar(\"T\")\n\n\nclass DataFrameGenericAlias(Protocol[V_co]):\n    \"\"\"Technically not a GenericAlias, but serves the same purpose in\n    OptionSequence below, in that it is a type which admits DataFrame,\n    but is generic. This allows OptionSequence to be a fully generic type,\n    significantly increasing its usefulness.\n\n    We can't use types.GenericAlias, as it is only available from python>=3.9,\n    and isn't easily back-ported.\n    \"\"\"\n\n    @property\n    def iloc(self) -> _iLocIndexer: ...\n\n\nOptionSequence: TypeAlias = Union[\n    Iterable[V_co],\n    DataFrameGenericAlias[V_co],\n]\n\n\nKey: TypeAlias = Union[str, int]\n\nLabelVisibility = Literal[\"visible\", \"hidden\", \"collapsed\"]\n\nVegaLiteType = Literal[\"quantitative\", \"ordinal\", \"temporal\", \"nominal\"]\n\n\nclass SupportsStr(Protocol):\n    def __str__(self) -> str: ...\n\n\ndef is_array_value_field_name(obj: object) -> TypeGuard[ArrayValueFieldName]:\n    return obj in ARRAY_VALUE_FIELD_NAMES\n\n\n@overload\ndef is_type(\n    obj: object, fqn_type_pattern: Literal[\"pydeck.bindings.deck.Deck\"]\n) -> TypeGuard[Deck]: ...\n\n\n@overload\ndef is_type(\n    obj: object, fqn_type_pattern: Literal[\"plotly.graph_objs._figure.Figure\"]\n) -> TypeGuard[Figure]: ...\n\n\n@overload\ndef is_type(obj: object, fqn_type_pattern: str | re.Pattern[str]) -> bool: ...\n\n\ndef is_type(obj: object, fqn_type_pattern: str | re.Pattern[str]) -> bool:\n    \"\"\"Check type without importing expensive modules.\n\n    Parameters\n    ----------\n    obj : object\n        The object to type-check.\n    fqn_type_pattern : str or regex\n        The fully-qualified type string or a regular expression.\n        Regexes should start with `^` and end with `$`.\n\n    Example\n    -------\n\n    To check whether something is a Matplotlib Figure without importing\n    matplotlib, use:\n\n    >>> is_type(foo, 'matplotlib.figure.Figure')\n\n    \"\"\"\n    fqn_type = get_fqn_type(obj)\n    if isinstance(fqn_type_pattern, str):\n        return fqn_type_pattern == fqn_type\n    else:\n        return fqn_type_pattern.match(fqn_type) is not None\n\n\ndef get_fqn(the_type: type) -> str:\n    \"\"\"Get module.type_name for a given type.\"\"\"\n    return f\"{the_type.__module__}.{the_type.__qualname__}\"\n\n\ndef get_fqn_type(obj: object) -> str:\n    \"\"\"Get module.type_name for a given object.\"\"\"\n    return get_fqn(type(obj))\n\n\n_PANDAS_DF_TYPE_STR: Final = \"pandas.core.frame.DataFrame\"\n_PANDAS_INDEX_TYPE_STR: Final = \"pandas.core.indexes.base.Index\"\n_PANDAS_SERIES_TYPE_STR: Final = \"pandas.core.series.Series\"\n_PANDAS_STYLER_TYPE_STR: Final = \"pandas.io.formats.style.Styler\"\n_NUMPY_ARRAY_TYPE_STR: Final = \"numpy.ndarray\"\n_SNOWPARK_DF_TYPE_STR: Final = \"snowflake.snowpark.dataframe.DataFrame\"\n_SNOWPARK_DF_ROW_TYPE_STR: Final = \"snowflake.snowpark.row.Row\"\n_SNOWPARK_TABLE_TYPE_STR: Final = \"snowflake.snowpark.table.Table\"\n_PYSPARK_DF_TYPE_STR: Final = \"pyspark.sql.dataframe.DataFrame\"\n_MODIN_DF_TYPE_STR: Final = \"modin.pandas.dataframe.DataFrame\"\n_MODIN_SERIES_TYPE_STR: Final = \"modin.pandas.series.Series\"\n_SNOWPANDAS_DF_TYPE_STR: Final = \"snowflake.snowpark.modin.pandas.dataframe.DataFrame\"\n_SNOWPANDAS_SERIES_TYPE_STR: Final = \"snowflake.snowpark.modin.pandas.series.Series\"\n\n\n_DATAFRAME_LIKE_TYPES: Final[tuple[str, ...]] = (\n    _PANDAS_DF_TYPE_STR,\n    _PANDAS_INDEX_TYPE_STR,\n    _PANDAS_SERIES_TYPE_STR,\n    _PANDAS_STYLER_TYPE_STR,\n    _NUMPY_ARRAY_TYPE_STR,\n)\n\n# We show a special \"UnevaluatedDataFrame\" warning for cached funcs\n# that attempt to return one of these unserializable types:\nUNEVALUATED_DATAFRAME_TYPES = (\n    _MODIN_DF_TYPE_STR,\n    _MODIN_SERIES_TYPE_STR,\n    _PYSPARK_DF_TYPE_STR,\n    _SNOWPANDAS_DF_TYPE_STR,\n    _SNOWPANDAS_SERIES_TYPE_STR,\n    _SNOWPARK_DF_TYPE_STR,\n    _SNOWPARK_TABLE_TYPE_STR,\n)\n\nDataFrameLike: TypeAlias = \"Union[DataFrame, Index, Series, Styler]\"\n\n_DATAFRAME_COMPATIBLE_TYPES: Final[tuple[type, ...]] = (\n    dict,\n    list,\n    set,\n    tuple,\n    type(None),\n)\n\n_DataFrameCompatible: TypeAlias = Union[dict, list, set, Tuple[Any], None]\nDataFrameCompatible: TypeAlias = Union[_DataFrameCompatible, DataFrameLike]\n\n_BYTES_LIKE_TYPES: Final[tuple[type, ...]] = (\n    bytes,\n    bytearray,\n)\n\nBytesLike: TypeAlias = Union[bytes, bytearray]\n\n\nclass DataFormat(Enum):\n    \"\"\"DataFormat is used to determine the format of the data.\"\"\"\n\n    UNKNOWN = auto()\n    EMPTY = auto()  # None\n    PANDAS_DATAFRAME = auto()  # pd.DataFrame\n    PANDAS_SERIES = auto()  # pd.Series\n    PANDAS_INDEX = auto()  # pd.Index\n    NUMPY_LIST = auto()  # np.array[Scalar]\n    NUMPY_MATRIX = auto()  # np.array[List[Scalar]]\n    PYARROW_TABLE = auto()  # pyarrow.Table\n    SNOWPARK_OBJECT = auto()  # Snowpark DataFrame, Table, List[Row]\n    PYSPARK_OBJECT = auto()  # pyspark.DataFrame\n    MODIN_OBJECT = auto()  # Modin DataFrame, Series\n    SNOWPANDAS_OBJECT = auto()  # Snowpandas DataFrame, Series\n    PANDAS_STYLER = auto()  # pandas Styler\n    LIST_OF_RECORDS = auto()  # List[Dict[str, Scalar]]\n    LIST_OF_ROWS = auto()  # List[List[Scalar]]\n    LIST_OF_VALUES = auto()  # List[Scalar]\n    TUPLE_OF_VALUES = auto()  # Tuple[Scalar]\n    SET_OF_VALUES = auto()  # Set[Scalar]\n    COLUMN_INDEX_MAPPING = auto()  # {column: {index: value}}\n    COLUMN_VALUE_MAPPING = auto()  # {column: List[values]}\n    COLUMN_SERIES_MAPPING = auto()  # {column: Series(values)}\n    KEY_VALUE_DICT = auto()  # {index: value}\n\n\ndef is_dataframe(obj: object) -> TypeGuard[DataFrame]:\n    return is_type(obj, _PANDAS_DF_TYPE_STR)\n\n\ndef is_dataframe_like(obj: object) -> TypeGuard[DataFrameLike]:\n    return any(is_type(obj, t) for t in _DATAFRAME_LIKE_TYPES)\n\n\ndef is_unevaluated_data_object(obj: object) -> bool:\n    \"\"\"True if the object is one of the supported unevaluated data objects:\n\n    Currently supported objects are:\n    - Snowpark DataFrame / Table\n    - PySpark DataFrame\n    - Modin DataFrame / Series\n    - Snowpandas DataFrame / Series\n\n    Unevaluated means that the data is not yet in the local memory.\n    Unevaluated data objects are treated differently from other data objects by only\n    requesting a subset of the data instead of loading all data into th memory\n    \"\"\"\n    return (\n        is_snowpark_data_object(obj)\n        or is_pyspark_data_object(obj)\n        or is_snowpandas_data_object(obj)\n        or is_modin_data_object(obj)\n    )\n\n\ndef is_snowpark_data_object(obj: object) -> bool:\n    \"\"\"True if obj is a Snowpark DataFrame or Table.\"\"\"\n    return is_type(obj, _SNOWPARK_TABLE_TYPE_STR) or is_type(obj, _SNOWPARK_DF_TYPE_STR)\n\n\ndef is_snowpark_row_list(obj: object) -> bool:\n    \"\"\"True if obj is a list of snowflake.snowpark.row.Row.\"\"\"\n    if not isinstance(obj, list):\n        return False\n    if len(obj) < 1:\n        return False\n    if not hasattr(obj[0], \"__class__\"):\n        return False\n    return is_type(obj[0], _SNOWPARK_DF_ROW_TYPE_STR)\n\n\ndef is_pyspark_data_object(obj: object) -> bool:\n    \"\"\"True if obj is of type pyspark.sql.dataframe.DataFrame\"\"\"\n    return (\n        is_type(obj, _PYSPARK_DF_TYPE_STR)\n        and hasattr(obj, \"toPandas\")\n        and callable(obj.toPandas)\n    )\n\n\ndef is_modin_data_object(obj: object) -> bool:\n    \"\"\"True if obj is of Modin Dataframe or Series\"\"\"\n    return is_type(obj, _MODIN_DF_TYPE_STR) or is_type(obj, _MODIN_SERIES_TYPE_STR)\n\n\ndef is_snowpandas_data_object(obj: object) -> bool:\n    \"\"\"True if obj is a Snowpark Pandas DataFrame or Series.\"\"\"\n    return is_type(obj, _SNOWPANDAS_DF_TYPE_STR) or is_type(\n        obj, _SNOWPANDAS_SERIES_TYPE_STR\n    )\n\n\ndef is_dataframe_compatible(obj: object) -> TypeGuard[DataFrameCompatible]:\n    \"\"\"True if type that can be passed to convert_anything_to_df.\"\"\"\n    return is_dataframe_like(obj) or type(obj) in _DATAFRAME_COMPATIBLE_TYPES\n\n\ndef is_bytes_like(obj: object) -> TypeGuard[BytesLike]:\n    \"\"\"True if the type is considered bytes-like for the purposes of\n    protobuf data marshalling.\n    \"\"\"\n    return isinstance(obj, _BYTES_LIKE_TYPES)\n\n\ndef to_bytes(obj: BytesLike) -> bytes:\n    \"\"\"Converts the given object to bytes.\n\n    Only types for which `is_bytes_like` is true can be converted; anything\n    else will result in an exception.\n    \"\"\"\n    if isinstance(obj, bytearray):\n        return bytes(obj)\n    elif isinstance(obj, bytes):\n        return obj\n\n    raise RuntimeError(f\"{obj} is not convertible to bytes\")\n\n\n_SYMPY_RE: Final = re.compile(r\"^sympy.*$\")\n\n\ndef is_sympy_expession(obj: object) -> TypeGuard[sympy.Expr]:\n    \"\"\"True if input is a SymPy expression.\"\"\"\n    if not is_type(obj, _SYMPY_RE):\n        return False\n\n    try:\n        import sympy\n\n        return isinstance(obj, sympy.Expr)\n    except ImportError:\n        return False\n\n\n_ALTAIR_RE: Final = re.compile(r\"^altair\\.vegalite\\.v\\d+\\.api\\.\\w*Chart$\")\n\n\ndef is_altair_chart(obj: object) -> bool:\n    \"\"\"True if input looks like an Altair chart.\"\"\"\n    return is_type(obj, _ALTAIR_RE)\n\n\n_PILLOW_RE: Final = re.compile(r\"^PIL\\..*\")\n\n\ndef is_pillow_image(obj: object) -> bool:\n    \"\"\"True if input looks like a pillow image.\"\"\"\n    return is_type(obj, _PILLOW_RE)\n\n\ndef is_keras_model(obj: object) -> bool:\n    \"\"\"True if input looks like a Keras model.\"\"\"\n    return (\n        is_type(obj, \"keras.engine.sequential.Sequential\")\n        or is_type(obj, \"keras.engine.training.Model\")\n        or is_type(obj, \"tensorflow.python.keras.engine.sequential.Sequential\")\n        or is_type(obj, \"tensorflow.python.keras.engine.training.Model\")\n    )\n\n\n# We use a regex here to allow potential changes in the module path in the future.\n_OPENAI_CHUNK_RE: Final = re.compile(r\"^openai\\..+\\.ChatCompletionChunk$\")\n\n\ndef is_openai_chunk(obj: object) -> bool:\n    \"\"\"True if input looks like an OpenAI chat completion chunk.\"\"\"\n    return is_type(obj, _OPENAI_CHUNK_RE)\n\n\ndef is_list_of_scalars(data: Iterable[Any]) -> bool:\n    \"\"\"Check if the list only contains scalar values.\"\"\"\n    from pandas.api.types import infer_dtype\n\n    # Overview on all value that are interpreted as scalar:\n    # https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_scalar.html\n    return infer_dtype(data, skipna=True) not in [\"mixed\", \"unknown-array\"]\n\n\ndef is_plotly_chart(obj: object) -> TypeGuard[Figure | list[Any] | dict[str, Any]]:\n    \"\"\"True if input looks like a Plotly chart.\"\"\"\n    return (\n        is_type(obj, \"plotly.graph_objs._figure.Figure\")\n        or _is_list_of_plotly_objs(obj)\n        or _is_probably_plotly_dict(obj)\n    )\n\n\ndef is_graphviz_chart(\n    obj: object,\n) -> TypeGuard[graphviz.Graph | graphviz.Digraph]:\n    \"\"\"True if input looks like a GraphViz chart.\"\"\"\n    return (\n        # GraphViz < 0.18\n        is_type(obj, \"graphviz.dot.Graph\")\n        or is_type(obj, \"graphviz.dot.Digraph\")\n        # GraphViz >= 0.18\n        or is_type(obj, \"graphviz.graphs.Graph\")\n        or is_type(obj, \"graphviz.graphs.Digraph\")\n    )\n\n\ndef _is_plotly_obj(obj: object) -> bool:\n    \"\"\"True if input if from a type that lives in plotly.plotly_objs.\"\"\"\n    the_type = type(obj)\n    return the_type.__module__.startswith(\"plotly.graph_objs\")\n\n\ndef _is_list_of_plotly_objs(obj: object) -> TypeGuard[list[Any]]:\n    if not isinstance(obj, list):\n        return False\n    if len(obj) == 0:\n        return False\n    return all(_is_plotly_obj(item) for item in obj)\n\n\ndef _is_probably_plotly_dict(obj: object) -> TypeGuard[dict[str, Any]]:\n    if not isinstance(obj, dict):\n        return False\n\n    if len(obj.keys()) == 0:\n        return False\n\n    if any(k not in [\"config\", \"data\", \"frames\", \"layout\"] for k in obj.keys()):\n        return False\n\n    if any(_is_plotly_obj(v) for v in obj.values()):\n        return True\n\n    if any(_is_list_of_plotly_objs(v) for v in obj.values()):\n        return True\n\n    return False\n\n\ndef is_function(x: object) -> TypeGuard[types.FunctionType]:\n    \"\"\"Return True if x is a function.\"\"\"\n    return isinstance(x, types.FunctionType)\n\n\ndef is_namedtuple(x: object) -> TypeGuard[NamedTuple]:\n    t = type(x)\n    b = t.__bases__\n    if len(b) != 1 or b[0] is not tuple:\n        return False\n    f = getattr(t, \"_fields\", None)\n    if not isinstance(f, tuple):\n        return False\n    return all(type(n).__name__ == \"str\" for n in f)\n\n\ndef is_pandas_styler(obj: object) -> TypeGuard[Styler]:\n    return is_type(obj, _PANDAS_STYLER_TYPE_STR)\n\n\ndef is_pydeck(obj: object) -> TypeGuard[Deck]:\n    \"\"\"True if input looks like a pydeck chart.\"\"\"\n    return is_type(obj, \"pydeck.bindings.deck.Deck\")\n\n\ndef is_iterable(obj: object) -> TypeGuard[Iterable[Any]]:\n    try:\n        # The ignore statement here is intentional, as this is a\n        # perfectly fine way of checking for iterables.\n        iter(obj)  # type: ignore[call-overload]\n    except TypeError:\n        return False\n    return True\n\n\ndef is_streamlit_secrets_class(obj: object) -> TypeGuard[Secrets]:\n    \"\"\"True if obj is a Streamlit Secrets object.\"\"\"\n    return is_type(obj, \"streamlit.runtime.secrets.Secrets\")\n\n\ndef is_sequence(seq: Any) -> bool:\n    \"\"\"True if input looks like a sequence.\"\"\"\n    if isinstance(seq, str):\n        return False\n    try:\n        len(seq)\n    except Exception:\n        return False\n    return True\n\n\n@overload\ndef convert_anything_to_df(\n    data: Any,\n    max_unevaluated_rows: int = MAX_UNEVALUATED_DF_ROWS,\n    ensure_copy: bool = False,\n) -> DataFrame: ...\n\n\n@overload\ndef convert_anything_to_df(\n    data: Any,\n    max_unevaluated_rows: int = MAX_UNEVALUATED_DF_ROWS,\n    ensure_copy: bool = False,\n    allow_styler: bool = False,\n) -> DataFrame | Styler: ...\n\n\ndef convert_anything_to_df(\n    data: Any,\n    max_unevaluated_rows: int = MAX_UNEVALUATED_DF_ROWS,\n    ensure_copy: bool = False,\n    allow_styler: bool = False,\n) -> DataFrame | Styler:\n    \"\"\"Try to convert different formats to a Pandas Dataframe.\n\n    Parameters\n    ----------\n    data : ndarray, Iterable, dict, DataFrame, Styler, pa.Table, None, dict, list, or any\n\n    max_unevaluated_rows: int\n        If unevaluated data is detected this func will evaluate it,\n        taking max_unevaluated_rows, defaults to 10k and 100 for st.table\n\n    ensure_copy: bool\n        If True, make sure to always return a copy of the data. If False, it depends on the\n        type of the data. For example, a Pandas DataFrame will be returned as-is.\n\n    allow_styler: bool\n        If True, allows this to return a Pandas Styler object as well. If False, returns\n        a plain Pandas DataFrame (which, of course, won't contain the Styler's styles).\n\n    Returns\n    -------\n    pandas.DataFrame or pandas.Styler\n\n    \"\"\"\n    import pandas as pd\n\n    if is_type(data, _PANDAS_DF_TYPE_STR):\n        return data.copy() if ensure_copy else cast(pd.DataFrame, data)\n\n    if is_pandas_styler(data):\n        # Every Styler is a StyleRenderer. I'm casting to StyleRenderer here rather than to the more\n        # correct Styler becayse MyPy doesn't like when we cast to Styler. It complains .data\n        # doesn't exist, when it does in fact exist in the parent class StyleRenderer!\n        sr = cast(\"StyleRenderer\", data)\n\n        if allow_styler:\n            if ensure_copy:\n                out = copy.deepcopy(sr)\n                out.data = sr.data.copy()\n                return cast(\"Styler\", out)\n            else:\n                return data\n        else:\n            return cast(\"Styler\", sr.data.copy() if ensure_copy else sr.data)\n\n    if is_type(data, \"numpy.ndarray\"):\n        if len(data.shape) == 0:\n            return pd.DataFrame([])\n        return pd.DataFrame(data)\n\n    if is_modin_data_object(data):\n        data = data.head(max_unevaluated_rows)._to_pandas()\n\n        if isinstance(data, pd.Series):\n            data = data.to_frame()\n\n        if data.shape[0] == max_unevaluated_rows:\n            st.caption(\n                f\"\u26a0\ufe0f Showing only {string_util.simplify_number(max_unevaluated_rows)} rows. \"\n                \"Call `_to_pandas()` on the dataframe to show more.\"\n            )\n        return cast(pd.DataFrame, data)\n\n    if is_pyspark_data_object(data):\n        data = data.limit(max_unevaluated_rows).toPandas()\n        if data.shape[0] == max_unevaluated_rows:\n            st.caption(\n                f\"\u26a0\ufe0f Showing only {string_util.simplify_number(max_unevaluated_rows)} rows. \"\n                \"Call `toPandas()` on the dataframe to show more.\"\n            )\n        return cast(pd.DataFrame, data)\n\n    if is_snowpark_data_object(data):\n        data = data.limit(max_unevaluated_rows).to_pandas()\n        if data.shape[0] == max_unevaluated_rows:\n            st.caption(\n                f\"\u26a0\ufe0f Showing only {string_util.simplify_number(max_unevaluated_rows)} rows. \"\n                \"Call `to_pandas()` on the dataframe to show more.\"\n            )\n        return cast(pd.DataFrame, data)\n\n    if is_snowpandas_data_object(data):\n        data = data.head(max_unevaluated_rows).to_pandas()\n\n        if isinstance(data, pd.Series):\n            data = data.to_frame()\n\n        if data.shape[0] == max_unevaluated_rows:\n            st.caption(\n                f\"\u26a0\ufe0f Showing only {string_util.simplify_number(max_unevaluated_rows)} rows. \"\n                \"Call `to_pandas()` on the dataframe to show more.\"\n            )\n        return cast(pd.DataFrame, data)\n\n    # This is inefficient when data is a pyarrow.Table as it will be converted\n    # back to Arrow when marshalled to protobuf, but area/bar/line charts need\n    # DataFrame magic to generate the correct output.\n    if hasattr(data, \"to_pandas\"):\n        return cast(pd.DataFrame, data.to_pandas())\n\n    # Try to convert to pandas.DataFrame. This will raise an error is df is not\n    # compatible with the pandas.DataFrame constructor.\n    try:\n        return pd.DataFrame(data)\n\n    except ValueError as ex:\n        if isinstance(data, dict):\n            with contextlib.suppress(ValueError):\n                # Try to use index orient as back-up to support key-value dicts\n                return pd.DataFrame.from_dict(data, orient=\"index\")\n        raise errors.StreamlitAPIException(\n            f\"\"\"\nUnable to convert object of type `{type(data)}` to `pandas.DataFrame`.\nOffending object:\n```py\n{data}\n```\"\"\"\n        ) from ex\n\n\n@overload\ndef ensure_iterable(obj: Iterable[V_co]) -> Iterable[V_co]: ...\n\n\n@overload\ndef ensure_iterable(obj: OptionSequence[V_co]) -> Iterable[Any]: ...\n\n\ndef ensure_iterable(obj: OptionSequence[V_co] | Iterable[V_co]) -> Iterable[Any]:\n    \"\"\"Try to convert different formats to something iterable. Most inputs\n    are assumed to be iterable, but if we have a DataFrame, we can just\n    select the first column to iterate over. If the input is not iterable,\n    a TypeError is raised.\n\n    Parameters\n    ----------\n    obj : list, tuple, numpy.ndarray, pandas.Series, pandas.DataFrame, pyspark.sql.DataFrame, snowflake.snowpark.dataframe.DataFrame or snowflake.snowpark.table.Table\n\n    Returns\n    -------\n    iterable\n\n    \"\"\"\n\n    if is_unevaluated_data_object(obj):\n        obj = convert_anything_to_df(obj)\n\n    if is_dataframe(obj):\n        # Return first column as a pd.Series\n        # The type of the elements in this column is not known up front, hence\n        # the Iterable[Any] return type.\n        return cast(Iterable[Any], obj.iloc[:, 0])\n\n    if is_iterable(obj):\n        return obj\n\n    raise TypeError(\n        f\"Object is not an iterable and could not be converted to one. Object: {obj}\"\n    )\n\n\ndef ensure_indexable(obj: OptionSequence[V_co]) -> Sequence[V_co]:\n    \"\"\"Try to ensure a value is an indexable Sequence. If the collection already\n    is one, it has the index method that we need. Otherwise, convert it to a list.\n    \"\"\"\n    it = ensure_iterable(obj)\n    # This is an imperfect check because there is no guarantee that an `index`\n    # function actually does the thing we want.\n    index_fn = getattr(it, \"index\", None)\n    if callable(index_fn) and type(it) != EnumMeta:\n        # We return a shallow copy of the Sequence here because the return value of\n        # this function is saved in a widget serde class instance to be used in later\n        # script runs, and we don't want mutations to the options object passed to a\n        # widget affect the widget.\n        # (See https://github.com/streamlit/streamlit/issues/7534)\n        return copy.copy(cast(Sequence[V_co], it))\n    else:\n        return list(it)\n\n\ndef check_python_comparable(seq: Sequence[Any]) -> None:\n    \"\"\"Check if the sequence elements support \"python comparison\".\n    That means that the equality operator (==) returns a boolean value.\n    Which is not True for e.g. numpy arrays and pandas series.\"\"\"\n    try:\n        bool(seq[0] == seq[0])\n    except LookupError:\n        # In case of empty sequences, the check not raise an exception.\n        pass\n    except ValueError:\n        raise StreamlitAPIException(\n            \"Invalid option type provided. Options must be comparable, returning a \"\n            f\"boolean when used with *==*. \\n\\nGot **{type(seq[0]).__name__}**, \"\n            \"which cannot be compared. Refactor your code to use elements of \"\n            \"comparable types as options, e.g. use indices instead.\"\n        )\n\n\ndef is_pandas_version_less_than(v: str) -> bool:\n    \"\"\"Return True if the current Pandas version is less than the input version.\n\n    Parameters\n    ----------\n    v : str\n        Version string, e.g. \"0.25.0\"\n\n    Returns\n    -------\n    bool\n\n\n    Raises\n    ------\n    InvalidVersion\n        If the version strings are not valid.\n    \"\"\"\n    import pandas as pd\n\n    return is_version_less_than(pd.__version__, v)\n\n\ndef is_pyarrow_version_less_than(v: str) -> bool:\n    \"\"\"Return True if the current Pyarrow version is less than the input version.\n\n    Parameters\n    ----------\n    v : str\n        Version string, e.g. \"0.25.0\"\n\n    Returns\n    -------\n    bool\n\n\n    Raises\n    ------\n    InvalidVersion\n        If the version strings are not valid.\n\n    \"\"\"\n    import pyarrow as pa\n\n    return is_version_less_than(pa.__version__, v)\n\n\ndef is_altair_version_less_than(v: str) -> bool:\n    \"\"\"Return True if the current Altair version is less than the input version.\n\n    Parameters\n    ----------\n    v : str\n        Version string, e.g. \"0.25.0\"\n\n    Returns\n    -------\n    bool\n\n\n    Raises\n    ------\n    InvalidVersion\n        If the version strings are not valid.\n\n    \"\"\"\n    import altair as alt\n\n    return is_version_less_than(alt.__version__, v)\n\n\ndef is_version_less_than(v1: str, v2: str) -> bool:\n    \"\"\"Return True if the v1 version string is less than the v2 version string\n    based on semantic versioning.\n\n    Raises\n    ------\n    InvalidVersion\n        If the version strings are not valid.\n    \"\"\"\n    from packaging import version\n\n    return version.parse(v1) < version.parse(v2)\n\n\ndef _maybe_truncate_table(\n    table: pa.Table, truncated_rows: int | None = None\n) -> pa.Table:\n    \"\"\"Experimental feature to automatically truncate tables that\n    are larger than the maximum allowed message size. It needs to be enabled\n    via the server.enableArrowTruncation config option.\n\n    Parameters\n    ----------\n    table : pyarrow.Table\n        A table to truncate.\n\n    truncated_rows : int or None\n        The number of rows that have been truncated so far. This is used by\n        the recursion logic to keep track of the total number of truncated\n        rows.\n\n    \"\"\"\n\n    if config.get_option(\"server.enableArrowTruncation\"):\n        # This is an optimization problem: We don't know at what row\n        # the perfect cut-off is to comply with the max size. But we want to figure\n        # it out in as few iterations as possible. We almost always will cut out\n        # more than required to keep the iterations low.\n\n        # The maximum size allowed for protobuf messages in bytes:\n        max_message_size = int(config.get_option(\"server.maxMessageSize\") * 1e6)\n        # We add 1 MB for other overhead related to the protobuf message.\n        # This is a very conservative estimate, but it should be good enough.\n        table_size = int(table.nbytes + 1 * 1e6)\n        table_rows = table.num_rows\n\n        if table_rows > 1 and table_size > max_message_size:\n            # targeted rows == the number of rows the table should be truncated to.\n            # Calculate an approximation of how many rows we need to truncate to.\n            targeted_rows = math.ceil(table_rows * (max_message_size / table_size))\n            # Make sure to cut out at least a couple of rows to avoid running\n            # this logic too often since it is quite inefficient and could lead\n            # to infinity recursions without these precautions.\n            targeted_rows = math.floor(\n                max(\n                    min(\n                        # Cut out:\n                        # an additional 5% of the estimated num rows to cut out:\n                        targeted_rows - math.floor((table_rows - targeted_rows) * 0.05),\n                        # at least 1% of table size:\n                        table_rows - (table_rows * 0.01),\n                        # at least 5 rows:\n                        table_rows - 5,\n                    ),\n                    1,  # but it should always have at least 1 row\n                )\n            )\n            sliced_table = table.slice(0, targeted_rows)\n            return _maybe_truncate_table(\n                sliced_table, (truncated_rows or 0) + (table_rows - targeted_rows)\n            )\n\n        if truncated_rows:\n            displayed_rows = string_util.simplify_number(table.num_rows)\n            total_rows = string_util.simplify_number(table.num_rows + truncated_rows)\n\n            if displayed_rows == total_rows:\n                # If the simplified numbers are the same,\n                # we just display the exact numbers.\n                displayed_rows = str(table.num_rows)\n                total_rows = str(table.num_rows + truncated_rows)\n\n            st.caption(\n                f\"\u26a0\ufe0f Showing {displayed_rows} out of {total_rows} \"\n                \"rows due to data size limitations.\"\n            )\n\n    return table\n\n\ndef pyarrow_table_to_bytes(table: pa.Table) -> bytes:\n    \"\"\"Serialize pyarrow.Table to bytes using Apache Arrow.\n\n    Parameters\n    ----------\n    table : pyarrow.Table\n        A table to convert.\n\n    \"\"\"\n    try:\n        table = _maybe_truncate_table(table)\n    except RecursionError as err:\n        # This is a very unlikely edge case, but we want to make sure that\n        # it doesn't lead to unexpected behavior.\n        # If there is a recursion error, we just return the table as-is\n        # which will lead to the normal message limit exceed error.\n        _LOGGER.warning(\n            \"Recursion error while truncating Arrow table. This is not \"\n            \"supposed to happen.\",\n            exc_info=err,\n        )\n\n    import pyarrow as pa\n\n    # Convert table to bytes\n    sink = pa.BufferOutputStream()\n    writer = pa.RecordBatchStreamWriter(sink, table.schema)\n    writer.write_table(table)\n    writer.close()\n    return cast(bytes, sink.getvalue().to_pybytes())\n\n\ndef is_colum_type_arrow_incompatible(column: Series[Any] | Index) -> bool:\n    \"\"\"Return True if the column type is known to cause issues during Arrow conversion.\"\"\"\n    from pandas.api.types import infer_dtype, is_dict_like, is_list_like\n\n    if column.dtype.kind in [\n        \"c\",  # complex64, complex128, complex256\n    ]:\n        return True\n\n    if str(column.dtype) in {\n        # These period types are not yet supported by our frontend impl.\n        # See comments in Quiver.ts for more details.\n        \"period[B]\",\n        \"period[N]\",\n        \"period[ns]\",\n        \"period[U]\",\n        \"period[us]\",\n    }:\n        return True\n\n    if column.dtype == \"object\":\n        # The dtype of mixed type columns is always object, the actual type of the column\n        # values can be determined via the infer_dtype function:\n        # https://pandas.pydata.org/docs/reference/api/pandas.api.types.infer_dtype.html\n        inferred_type = infer_dtype(column, skipna=True)\n\n        if inferred_type in [\n            \"mixed-integer\",\n            \"complex\",\n        ]:\n            return True\n        elif inferred_type == \"mixed\":\n            # This includes most of the more complex/custom types (objects, dicts, lists, ...)\n            if len(column) == 0 or not hasattr(column, \"iloc\"):\n                # The column seems to be invalid, so we assume it is incompatible.\n                # But this would most likely never happen since empty columns\n                # cannot be mixed.\n                return True\n\n            # Get the first value to check if it is a supported list-like type.\n            first_value = column.iloc[0]\n\n            if (\n                not is_list_like(first_value)\n                # dicts are list-like, but have issues in Arrow JS (see comments in Quiver.ts)\n                or is_dict_like(first_value)\n                # Frozensets are list-like, but are not compatible with pyarrow.\n                or isinstance(first_value, frozenset)\n            ):\n                # This seems to be an incompatible list-like type\n                return True\n            return False\n    # We did not detect an incompatible type, so we assume it is compatible:\n    return False\n\n\ndef fix_arrow_incompatible_column_types(\n    df: DataFrame, selected_columns: list[str] | None = None\n) -> DataFrame:\n    \"\"\"Fix column types that are not supported by Arrow table.\n\n    This includes mixed types (e.g. mix of integers and strings)\n    as well as complex numbers (complex128 type). These types will cause\n    errors during conversion of the dataframe to an Arrow table.\n    It is fixed by converting all values of the column to strings\n    This is sufficient for displaying the data on the frontend.\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        A dataframe to fix.\n\n    selected_columns: List[str] or None\n        A list of columns to fix. If None, all columns are evaluated.\n\n    Returns\n    -------\n    The fixed dataframe.\n    \"\"\"\n    import pandas as pd\n\n    # Make a copy, but only initialize if necessary to preserve memory.\n    df_copy: DataFrame | None = None\n    for col in selected_columns or df.columns:\n        if is_colum_type_arrow_incompatible(df[col]):\n            if df_copy is None:\n                df_copy = df.copy()\n            df_copy[col] = df[col].astype(\"string\")\n\n    # The index can also contain mixed types\n    # causing Arrow issues during conversion.\n    # Skipping multi-indices since they won't return\n    # the correct value from infer_dtype\n    if not selected_columns and (\n        not isinstance(\n            df.index,\n            pd.MultiIndex,\n        )\n        and is_colum_type_arrow_incompatible(df.index)\n    ):\n        if df_copy is None:\n            df_copy = df.copy()\n        df_copy.index = df.index.astype(\"string\")\n    return df_copy if df_copy is not None else df\n\n\ndef data_frame_to_bytes(df: DataFrame) -> bytes:\n    \"\"\"Serialize pandas.DataFrame to bytes using Apache Arrow.\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        A dataframe to convert.\n\n    \"\"\"\n    import pyarrow as pa\n\n    try:\n        table = pa.Table.from_pandas(df)\n    except (pa.ArrowTypeError, pa.ArrowInvalid, pa.ArrowNotImplementedError) as ex:\n        _LOGGER.info(\n            \"Serialization of dataframe to Arrow table was unsuccessful due to: %s. \"\n            \"Applying automatic fixes for column types to make the dataframe Arrow-compatible.\",\n            ex,\n        )\n        df = fix_arrow_incompatible_column_types(df)\n        table = pa.Table.from_pandas(df)\n    return pyarrow_table_to_bytes(table)\n\n\ndef bytes_to_data_frame(source: bytes) -> DataFrame:\n    \"\"\"Convert bytes to pandas.DataFrame.\n\n    Using this function in production needs to make sure that\n    the pyarrow version >= 14.0.1.\n\n    Parameters\n    ----------\n    source : bytes\n        A bytes object to convert.\n\n    \"\"\"\n    import pyarrow as pa\n\n    reader = pa.RecordBatchStreamReader(source)\n    return reader.read_pandas()\n\n\ndef determine_data_format(input_data: Any) -> DataFormat:\n    \"\"\"Determine the data format of the input data.\n\n    Parameters\n    ----------\n    input_data : Any\n        The input data to determine the data format of.\n\n    Returns\n    -------\n    DataFormat\n        The data format of the input data.\n    \"\"\"\n    import numpy as np\n    import pandas as pd\n    import pyarrow as pa\n\n    if input_data is None:\n        return DataFormat.EMPTY\n    elif isinstance(input_data, pd.DataFrame):\n        return DataFormat.PANDAS_DATAFRAME\n    elif isinstance(input_data, np.ndarray):\n        if len(input_data.shape) == 1:\n            # For technical reasons, we need to distinguish one\n            # one-dimensional numpy array from multidimensional ones.\n            return DataFormat.NUMPY_LIST\n        return DataFormat.NUMPY_MATRIX\n    elif isinstance(input_data, pa.Table):\n        return DataFormat.PYARROW_TABLE\n    elif isinstance(input_data, pd.Series):\n        return DataFormat.PANDAS_SERIES\n    elif isinstance(input_data, pd.Index):\n        return DataFormat.PANDAS_INDEX\n    elif is_pandas_styler(input_data):\n        return DataFormat.PANDAS_STYLER\n    elif is_snowpark_data_object(input_data):\n        return DataFormat.SNOWPARK_OBJECT\n    elif is_modin_data_object(input_data):\n        return DataFormat.MODIN_OBJECT\n    elif is_snowpandas_data_object(input_data):\n        return DataFormat.SNOWPANDAS_OBJECT\n    elif is_pyspark_data_object(input_data):\n        return DataFormat.PYSPARK_OBJECT\n    elif isinstance(input_data, (list, tuple, set)):\n        if is_list_of_scalars(input_data):\n            # -> one-dimensional data structure\n            if isinstance(input_data, tuple):\n                return DataFormat.TUPLE_OF_VALUES\n            if isinstance(input_data, set):\n                return DataFormat.SET_OF_VALUES\n            return DataFormat.LIST_OF_VALUES\n        else:\n            # -> Multi-dimensional data structure\n            # This should always contain at least one element,\n            # otherwise the values type from infer_dtype would have been empty\n            first_element = next(iter(input_data))\n            if isinstance(first_element, dict):\n                return DataFormat.LIST_OF_RECORDS\n            if isinstance(first_element, (list, tuple, set)):\n                return DataFormat.LIST_OF_ROWS\n    elif isinstance(input_data, dict):\n        if not input_data:\n            return DataFormat.KEY_VALUE_DICT\n        if len(input_data) > 0:\n            first_value = next(iter(input_data.values()))\n            if isinstance(first_value, dict):\n                return DataFormat.COLUMN_INDEX_MAPPING\n            if isinstance(first_value, (list, tuple)):\n                return DataFormat.COLUMN_VALUE_MAPPING\n            if isinstance(first_value, pd.Series):\n                return DataFormat.COLUMN_SERIES_MAPPING\n            # In the future, we could potentially also support the tight & split formats here\n            if is_list_of_scalars(input_data.values()):\n                # Only use the key-value dict format if the values are only scalar values\n                return DataFormat.KEY_VALUE_DICT\n    return DataFormat.UNKNOWN\n\n\ndef _unify_missing_values(df: DataFrame) -> DataFrame:\n    \"\"\"Unify all missing values in a DataFrame to None.\n\n    Pandas uses a variety of values to represent missing values, including np.nan,\n    NaT, None, and pd.NA. This function replaces all of these values with None,\n    which is the only missing value type that is supported by all data\n    \"\"\"\n    import numpy as np\n\n    return df.fillna(np.nan).replace([np.nan], [None])\n\n\ndef convert_df_to_data_format(\n    df: DataFrame, data_format: DataFormat\n) -> (\n    DataFrame\n    | Series[Any]\n    | pa.Table\n    | np.ndarray[Any, np.dtype[Any]]\n    | tuple[Any]\n    | list[Any]\n    | set[Any]\n    | dict[str, Any]\n):\n    \"\"\"Convert a dataframe to the specified data format.\n\n    Parameters\n    ----------\n    df : pd.DataFrame\n        The dataframe to convert.\n\n    data_format : DataFormat\n        The data format to convert to.\n\n    Returns\n    -------\n    pd.DataFrame, pd.Series, pyarrow.Table, np.ndarray, list, set, tuple, or dict.\n        The converted dataframe.\n    \"\"\"\n\n    if data_format in [\n        DataFormat.EMPTY,\n        DataFormat.PANDAS_DATAFRAME,\n        DataFormat.SNOWPARK_OBJECT,\n        DataFormat.PYSPARK_OBJECT,\n        DataFormat.PANDAS_INDEX,\n        DataFormat.PANDAS_STYLER,\n        DataFormat.MODIN_OBJECT,\n        DataFormat.SNOWPANDAS_OBJECT,\n    ]:\n        return df\n    elif data_format == DataFormat.NUMPY_LIST:\n        import numpy as np\n\n        # It's a 1-dimensional array, so we only return\n        # the first column as numpy array\n        # Calling to_numpy() on the full DataFrame would result in:\n        # [[1], [2]] instead of [1, 2]\n        return np.ndarray(0) if df.empty else df.iloc[:, 0].to_numpy()\n    elif data_format == DataFormat.NUMPY_MATRIX:\n        import numpy as np\n\n        return np.ndarray(0) if df.empty else df.to_numpy()\n    elif data_format == DataFormat.PYARROW_TABLE:\n        import pyarrow as pa\n\n        return pa.Table.from_pandas(df)\n    elif data_format == DataFormat.PANDAS_SERIES:\n        # Select first column in dataframe and create a new series based on the values\n        if len(df.columns) != 1:\n            raise ValueError(\n                f\"DataFrame is expected to have a single column but has {len(df.columns)}.\"\n            )\n        return df[df.columns[0]]\n    elif data_format == DataFormat.LIST_OF_RECORDS:\n        return _unify_missing_values(df).to_dict(orient=\"records\")\n    elif data_format == DataFormat.LIST_OF_ROWS:\n        # to_numpy converts the dataframe to a list of rows\n        return _unify_missing_values(df).to_numpy().tolist()\n    elif data_format == DataFormat.COLUMN_INDEX_MAPPING:\n        return _unify_missing_values(df).to_dict(orient=\"dict\")\n    elif data_format == DataFormat.COLUMN_VALUE_MAPPING:\n        return _unify_missing_values(df).to_dict(orient=\"list\")\n    elif data_format == DataFormat.COLUMN_SERIES_MAPPING:\n        return df.to_dict(orient=\"series\")\n    elif data_format in [\n        DataFormat.LIST_OF_VALUES,\n        DataFormat.TUPLE_OF_VALUES,\n        DataFormat.SET_OF_VALUES,\n    ]:\n        df = _unify_missing_values(df)\n        return_list = []\n        if len(df.columns) == 1:\n            #  Get the first column and convert to list\n            return_list = df[df.columns[0]].tolist()\n        elif len(df.columns) >= 1:\n            raise ValueError(\n                f\"DataFrame is expected to have a single column but has {len(df.columns)}.\"\n            )\n        if data_format == DataFormat.TUPLE_OF_VALUES:\n            return tuple(return_list)\n        if data_format == DataFormat.SET_OF_VALUES:\n            return set(return_list)\n        return return_list\n    elif data_format == DataFormat.KEY_VALUE_DICT:\n        df = _unify_missing_values(df)\n        # The key is expected to be the index -> this will return the first column\n        # as a dict with index as key.\n        return {} if df.empty else df.iloc[:, 0].to_dict()\n\n    raise ValueError(f\"Unsupported input data format: {data_format}\")\n\n\n@overload\ndef to_key(key: None) -> None: ...\n\n\n@overload\ndef to_key(key: Key) -> str: ...\n\n\ndef to_key(key: Key | None) -> str | None:\n    if key is None:\n        return None\n    else:\n        return str(key)\n\n\ndef maybe_tuple_to_list(item: Any) -> Any:\n    \"\"\"Convert a tuple to a list. Leave as is if it's not a tuple.\"\"\"\n    return list(item) if isinstance(item, tuple) else item\n\n\ndef maybe_raise_label_warnings(label: str | None, label_visibility: str | None):\n    if not label:\n        _LOGGER.warning(\n            \"`label` got an empty value. This is discouraged for accessibility \"\n            \"reasons and may be disallowed in the future by raising an exception. \"\n            \"Please provide a non-empty label and hide it with label_visibility \"\n            \"if needed.\"\n        )\n    if label_visibility not in (\"visible\", \"hidden\", \"collapsed\"):\n        raise errors.StreamlitAPIException(\n            f\"Unsupported label_visibility option '{label_visibility}'. \"\n            f\"Valid values are 'visible', 'hidden' or 'collapsed'.\"\n        )\n\n\n# The code below is copied from Altair, and slightly modified.\n# We copy this code here so we don't depend on private Altair functions.\n# Source: https://github.com/altair-viz/altair/blob/62ca5e37776f5cecb27e83c1fbd5d685a173095d/altair/utils/core.py#L193\n\n\n# STREAMLIT MOD: I changed the type for the data argument from \"pd.Series\" to Series,\n# and the return type to a Union including a (str, list) tuple, since the function does\n# return that in some situations.\ndef infer_vegalite_type(\n    data: Series[Any],\n) -> VegaLiteType:\n    \"\"\"\n    From an array-like input, infer the correct vega typecode\n    ('ordinal', 'nominal', 'quantitative', or 'temporal')\n\n    Parameters\n    ----------\n    data: Numpy array or Pandas Series\n    \"\"\"\n    from pandas.api.types import infer_dtype\n\n    # STREAMLIT MOD: I'm using infer_dtype directly here, rather than using Altair's wrapper. Their\n    # wrapper is only there to support Pandas < 0.20, but Streamlit requires Pandas 1.3.\n    typ = infer_dtype(data)\n\n    if typ in [\n        \"floating\",\n        \"mixed-integer-float\",\n        \"integer\",\n        \"mixed-integer\",\n        \"complex\",\n    ]:\n        return \"quantitative\"\n\n    elif typ == \"categorical\" and data.cat.ordered:\n        # STREAMLIT MOD: The original code returns a tuple here:\n        # return (\"ordinal\", data.cat.categories.tolist())\n        # But returning the tuple here isn't compatible with our\n        # built-in chart implementation. And it also doesn't seem to be necessary.\n        # Altair already extracts the correct sort order somewhere else.\n        # More info about the issue here: https://github.com/streamlit/streamlit/issues/7776\n        return \"ordinal\"\n    elif typ in [\"string\", \"bytes\", \"categorical\", \"boolean\", \"mixed\", \"unicode\"]:\n        return \"nominal\"\n    elif typ in [\n        \"datetime\",\n        \"datetime64\",\n        \"timedelta\",\n        \"timedelta64\",\n        \"date\",\n        \"time\",\n        \"period\",\n    ]:\n        return \"temporal\"\n    else:\n        # STREAMLIT MOD: I commented this out since Streamlit doesn't have a warnings object.\n        # warnings.warn(\n        #     \"I don't know how to infer vegalite type from '{}'.  \"\n        #     \"Defaulting to nominal.\".format(typ),\n        #     stacklevel=1,\n        # )\n        return \"nominal\"\n\n\nE1 = TypeVar(\"E1\", bound=Enum)\nE2 = TypeVar(\"E2\", bound=Enum)\n\nALLOWED_ENUM_COERCION_CONFIG_SETTINGS = (\"off\", \"nameOnly\", \"nameAndValue\")\n\n\ndef coerce_enum(from_enum_value: E1, to_enum_class: type[E2]) -> E1 | E2:\n    \"\"\"Attempt to coerce an Enum value to another EnumMeta.\n\n    An Enum value of EnumMeta E1 is considered coercable to EnumType E2\n    if the EnumMeta __qualname__ match and the names of their members\n    match as well. (This is configurable in streamlist configs)\n    \"\"\"\n    if not isinstance(from_enum_value, Enum):\n        raise ValueError(\n            f\"Expected an Enum in the first argument. Got {type(from_enum_value)}\"\n        )\n    if not isinstance(to_enum_class, EnumMeta):\n        raise ValueError(\n            f\"Expected an EnumMeta/Type in the second argument. Got {type(to_enum_class)}\"\n        )\n    if isinstance(from_enum_value, to_enum_class):\n        return from_enum_value  # Enum is already a member, no coersion necessary\n\n    coercion_type = config.get_option(\"runner.enumCoercion\")\n    if coercion_type not in ALLOWED_ENUM_COERCION_CONFIG_SETTINGS:\n        raise errors.StreamlitAPIException(\n            \"Invalid value for config option runner.enumCoercion. \"\n            f\"Expected one of {ALLOWED_ENUM_COERCION_CONFIG_SETTINGS}, \"\n            f\"but got '{coercion_type}'.\"\n        )\n    if coercion_type == \"off\":\n        return from_enum_value  # do not attempt to coerce\n\n    # We now know this is an Enum AND the user has configured coercion enabled.\n    # Check if we do NOT meet the required conditions and log a failure message\n    # if that is the case.\n    from_enum_class = from_enum_value.__class__\n    if (\n        from_enum_class.__qualname__ != to_enum_class.__qualname__\n        or (\n            coercion_type == \"nameOnly\"\n            and set(to_enum_class._member_names_) != set(from_enum_class._member_names_)\n        )\n        or (\n            coercion_type == \"nameAndValue\"\n            and set(to_enum_class._value2member_map_)\n            != set(from_enum_class._value2member_map_)\n        )\n    ):\n        _LOGGER.debug(\"Failed to coerce %s to class %s\", from_enum_value, to_enum_class)\n        return from_enum_value  # do not attempt to coerce\n\n    # At this point we think the Enum is coercable, and we know\n    # E1 and E2 have the same member names. We convert from E1 to E2 using _name_\n    # (since user Enum subclasses can override the .name property in 3.11)\n    _LOGGER.debug(\"Coerced %s to class %s\", from_enum_value, to_enum_class)\n    return to_enum_class[from_enum_value._name_]\n", "lib/streamlit/emojis.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"A generated list with all existing emojis.\n\nDO NOT EDIT MANUALLY! The list in this file is generated by `scripts/update-emojis.py`.\n\nThis module gets lazy-loaded only when an emoji check is required (see string_util).\n\"\"\"\n\nimport re\n\n# fmt: off\n### EMOJIS START ###\nALL_EMOJIS = {\"#\u20e3\", \"#\ufe0f\u20e3\", \"*\u20e3\", \"*\ufe0f\u20e3\", \"0\u20e3\", \"0\ufe0f\u20e3\", \"1\u20e3\", \"1\ufe0f\u20e3\", \"2\u20e3\", \"2\ufe0f\u20e3\", \"3\u20e3\", \"3\ufe0f\u20e3\", \"4\u20e3\", \"4\ufe0f\u20e3\", \"5\u20e3\", \"5\ufe0f\u20e3\", \"6\u20e3\", \"6\ufe0f\u20e3\", \"7\u20e3\", \"7\ufe0f\u20e3\", \"8\u20e3\", \"8\ufe0f\u20e3\", \"9\u20e3\", \"9\ufe0f\u20e3\", \"\u00a9\", \"\u00a9\ufe0f\", \"\u00ae\", \"\u00ae\ufe0f\", \"\u203c\", \"\u203c\ufe0f\", \"\u2049\", \"\u2049\ufe0f\", \"\u2122\", \"\u2122\ufe0f\", \"\u2139\", \"\u2139\ufe0f\", \"\u2194\", \"\u2194\ufe0f\", \"\u2195\", \"\u2195\ufe0f\", \"\u2196\", \"\u2196\ufe0f\", \"\u2197\", \"\u2197\ufe0f\", \"\u2198\", \"\u2198\ufe0f\", \"\u2199\", \"\u2199\ufe0f\", \"\u21a9\", \"\u21a9\ufe0f\", \"\u21aa\", \"\u21aa\ufe0f\", \"\u231a\", \"\u231b\", \"\u2328\", \"\u2328\ufe0f\", \"\u23cf\", \"\u23cf\ufe0f\", \"\u23e9\", \"\u23ea\", \"\u23eb\", \"\u23ec\", \"\u23ed\", \"\u23ed\ufe0f\", \"\u23ee\", \"\u23ee\ufe0f\", \"\u23ef\", \"\u23ef\ufe0f\", \"\u23f0\", \"\u23f1\", \"\u23f1\ufe0f\", \"\u23f2\", \"\u23f2\ufe0f\", \"\u23f3\", \"\u23f8\", \"\u23f8\ufe0f\", \"\u23f9\", \"\u23f9\ufe0f\", \"\u23fa\", \"\u23fa\ufe0f\", \"\u24c2\", \"\u24c2\ufe0f\", \"\u25aa\", \"\u25aa\ufe0f\", \"\u25ab\", \"\u25ab\ufe0f\", \"\u25b6\", \"\u25b6\ufe0f\", \"\u25c0\", \"\u25c0\ufe0f\", \"\u25fb\", \"\u25fb\ufe0f\", \"\u25fc\", \"\u25fc\ufe0f\", \"\u25fd\", \"\u25fe\", \"\u2600\", \"\u2600\ufe0f\", \"\u2601\", \"\u2601\ufe0f\", \"\u2602\", \"\u2602\ufe0f\", \"\u2603\", \"\u2603\ufe0f\", \"\u2604\", \"\u2604\ufe0f\", \"\u260e\", \"\u260e\ufe0f\", \"\u2611\", \"\u2611\ufe0f\", \"\u2614\", \"\u2615\", \"\u2618\", \"\u2618\ufe0f\", \"\u261d\", \"\u261d\ufe0f\", \"\u261d\ud83c\udffb\", \"\u261d\ud83c\udffc\", \"\u261d\ud83c\udffd\", \"\u261d\ud83c\udffe\", \"\u261d\ud83c\udfff\", \"\u2620\", \"\u2620\ufe0f\", \"\u2622\", \"\u2622\ufe0f\", \"\u2623\", \"\u2623\ufe0f\", \"\u2626\", \"\u2626\ufe0f\", \"\u262a\", \"\u262a\ufe0f\", \"\u262e\", \"\u262e\ufe0f\", \"\u262f\", \"\u262f\ufe0f\", \"\u2638\", \"\u2638\ufe0f\", \"\u2639\", \"\u2639\ufe0f\", \"\u263a\", \"\u263a\ufe0f\", \"\u2640\", \"\u2640\ufe0f\", \"\u2642\", \"\u2642\ufe0f\", \"\u2648\", \"\u2649\", \"\u264a\", \"\u264b\", \"\u264c\", \"\u264d\", \"\u264e\", \"\u264f\", \"\u2650\", \"\u2651\", \"\u2652\", \"\u2653\", \"\u265f\", \"\u265f\ufe0f\", \"\u2660\", \"\u2660\ufe0f\", \"\u2663\", \"\u2663\ufe0f\", \"\u2665\", \"\u2665\ufe0f\", \"\u2666\", \"\u2666\ufe0f\", \"\u2668\", \"\u2668\ufe0f\", \"\u267b\", \"\u267b\ufe0f\", \"\u267e\", \"\u267e\ufe0f\", \"\u267f\", \"\u2692\", \"\u2692\ufe0f\", \"\u2693\", \"\u2694\", \"\u2694\ufe0f\", \"\u2695\", \"\u2695\ufe0f\", \"\u2696\", \"\u2696\ufe0f\", \"\u2697\", \"\u2697\ufe0f\", \"\u2699\", \"\u2699\ufe0f\", \"\u269b\", \"\u269b\ufe0f\", \"\u269c\", \"\u269c\ufe0f\", \"\u26a0\", \"\u26a0\ufe0f\", \"\u26a1\", \"\u26a7\", \"\u26a7\ufe0f\", \"\u26aa\", \"\u26ab\", \"\u26b0\", \"\u26b0\ufe0f\", \"\u26b1\", \"\u26b1\ufe0f\", \"\u26bd\", \"\u26be\", \"\u26c4\", \"\u26c5\", \"\u26c8\", \"\u26c8\ufe0f\", \"\u26ce\", \"\u26cf\", \"\u26cf\ufe0f\", \"\u26d1\", \"\u26d1\ufe0f\", \"\u26d3\", \"\u26d3\u200d\ud83d\udca5\", \"\u26d3\ufe0f\", \"\u26d3\ufe0f\u200d\ud83d\udca5\", \"\u26d4\", \"\u26e9\", \"\u26e9\ufe0f\", \"\u26ea\", \"\u26f0\", \"\u26f0\ufe0f\", \"\u26f1\", \"\u26f1\ufe0f\", \"\u26f2\", \"\u26f3\", \"\u26f4\", \"\u26f4\ufe0f\", \"\u26f5\", \"\u26f7\", \"\u26f7\ufe0f\", \"\u26f8\", \"\u26f8\ufe0f\", \"\u26f9\", \"\u26f9\u200d\u2640\", \"\u26f9\u200d\u2640\ufe0f\", \"\u26f9\u200d\u2642\", \"\u26f9\u200d\u2642\ufe0f\", \"\u26f9\ufe0f\", \"\u26f9\ufe0f\u200d\u2640\", \"\u26f9\ufe0f\u200d\u2640\ufe0f\", \"\u26f9\ufe0f\u200d\u2642\", \"\u26f9\ufe0f\u200d\u2642\ufe0f\", \"\u26f9\ud83c\udffb\", \"\u26f9\ud83c\udffb\u200d\u2640\", \"\u26f9\ud83c\udffb\u200d\u2640\ufe0f\", \"\u26f9\ud83c\udffb\u200d\u2642\", \"\u26f9\ud83c\udffb\u200d\u2642\ufe0f\", \"\u26f9\ud83c\udffc\", \"\u26f9\ud83c\udffc\u200d\u2640\", \"\u26f9\ud83c\udffc\u200d\u2640\ufe0f\", \"\u26f9\ud83c\udffc\u200d\u2642\", \"\u26f9\ud83c\udffc\u200d\u2642\ufe0f\", \"\u26f9\ud83c\udffd\", \"\u26f9\ud83c\udffd\u200d\u2640\", \"\u26f9\ud83c\udffd\u200d\u2640\ufe0f\", \"\u26f9\ud83c\udffd\u200d\u2642\", \"\u26f9\ud83c\udffd\u200d\u2642\ufe0f\", \"\u26f9\ud83c\udffe\", \"\u26f9\ud83c\udffe\u200d\u2640\", \"\u26f9\ud83c\udffe\u200d\u2640\ufe0f\", \"\u26f9\ud83c\udffe\u200d\u2642\", \"\u26f9\ud83c\udffe\u200d\u2642\ufe0f\", \"\u26f9\ud83c\udfff\", \"\u26f9\ud83c\udfff\u200d\u2640\", \"\u26f9\ud83c\udfff\u200d\u2640\ufe0f\", \"\u26f9\ud83c\udfff\u200d\u2642\", \"\u26f9\ud83c\udfff\u200d\u2642\ufe0f\", \"\u26fa\", \"\u26fd\", \"\u2702\", \"\u2702\ufe0f\", \"\u2705\", \"\u2708\", \"\u2708\ufe0f\", \"\u2709\", \"\u2709\ufe0f\", \"\u270a\", \"\u270a\ud83c\udffb\", \"\u270a\ud83c\udffc\", \"\u270a\ud83c\udffd\", \"\u270a\ud83c\udffe\", \"\u270a\ud83c\udfff\", \"\u270b\", \"\u270b\ud83c\udffb\", \"\u270b\ud83c\udffc\", \"\u270b\ud83c\udffd\", \"\u270b\ud83c\udffe\", \"\u270b\ud83c\udfff\", \"\u270c\", \"\u270c\ufe0f\", \"\u270c\ud83c\udffb\", \"\u270c\ud83c\udffc\", \"\u270c\ud83c\udffd\", \"\u270c\ud83c\udffe\", \"\u270c\ud83c\udfff\", \"\u270d\", \"\u270d\ufe0f\", \"\u270d\ud83c\udffb\", \"\u270d\ud83c\udffc\", \"\u270d\ud83c\udffd\", \"\u270d\ud83c\udffe\", \"\u270d\ud83c\udfff\", \"\u270f\", \"\u270f\ufe0f\", \"\u2712\", \"\u2712\ufe0f\", \"\u2714\", \"\u2714\ufe0f\", \"\u2716\", \"\u2716\ufe0f\", \"\u271d\", \"\u271d\ufe0f\", \"\u2721\", \"\u2721\ufe0f\", \"\u2728\", \"\u2733\", \"\u2733\ufe0f\", \"\u2734\", \"\u2734\ufe0f\", \"\u2744\", \"\u2744\ufe0f\", \"\u2747\", \"\u2747\ufe0f\", \"\u274c\", \"\u274e\", \"\u2753\", \"\u2754\", \"\u2755\", \"\u2757\", \"\u2763\", \"\u2763\ufe0f\", \"\u2764\", \"\u2764\u200d\ud83d\udd25\", \"\u2764\u200d\ud83e\ude79\", \"\u2764\ufe0f\", \"\u2764\ufe0f\u200d\ud83d\udd25\", \"\u2764\ufe0f\u200d\ud83e\ude79\", \"\u2795\", \"\u2796\", \"\u2797\", \"\u27a1\", \"\u27a1\ufe0f\", \"\u27b0\", \"\u27bf\", \"\u2934\", \"\u2934\ufe0f\", \"\u2935\", \"\u2935\ufe0f\", \"\u2b05\", \"\u2b05\ufe0f\", \"\u2b06\", \"\u2b06\ufe0f\", \"\u2b07\", \"\u2b07\ufe0f\", \"\u2b1b\", \"\u2b1c\", \"\u2b50\", \"\u2b55\", \"\u3030\", \"\u3030\ufe0f\", \"\u303d\", \"\u303d\ufe0f\", \"\u3297\", \"\u3297\ufe0f\", \"\u3299\", \"\u3299\ufe0f\", \"\ud83c\udc04\", \"\ud83c\udccf\", \"\ud83c\udd70\", \"\ud83c\udd70\ufe0f\", \"\ud83c\udd71\", \"\ud83c\udd71\ufe0f\", \"\ud83c\udd7e\", \"\ud83c\udd7e\ufe0f\", \"\ud83c\udd7f\", \"\ud83c\udd7f\ufe0f\", \"\ud83c\udd8e\", \"\ud83c\udd91\", \"\ud83c\udd92\", \"\ud83c\udd93\", \"\ud83c\udd94\", \"\ud83c\udd95\", \"\ud83c\udd96\", \"\ud83c\udd97\", \"\ud83c\udd98\", \"\ud83c\udd99\", \"\ud83c\udd9a\", \"\ud83c\udde6\ud83c\udde8\", \"\ud83c\udde6\ud83c\udde9\", \"\ud83c\udde6\ud83c\uddea\", \"\ud83c\udde6\ud83c\uddeb\", \"\ud83c\udde6\ud83c\uddec\", \"\ud83c\udde6\ud83c\uddee\", \"\ud83c\udde6\ud83c\uddf1\", \"\ud83c\udde6\ud83c\uddf2\", \"\ud83c\udde6\ud83c\uddf4\", \"\ud83c\udde6\ud83c\uddf6\", \"\ud83c\udde6\ud83c\uddf7\", \"\ud83c\udde6\ud83c\uddf8\", \"\ud83c\udde6\ud83c\uddf9\", \"\ud83c\udde6\ud83c\uddfa\", \"\ud83c\udde6\ud83c\uddfc\", \"\ud83c\udde6\ud83c\uddfd\", \"\ud83c\udde6\ud83c\uddff\", \"\ud83c\udde7\ud83c\udde6\", \"\ud83c\udde7\ud83c\udde7\", \"\ud83c\udde7\ud83c\udde9\", \"\ud83c\udde7\ud83c\uddea\", \"\ud83c\udde7\ud83c\uddeb\", \"\ud83c\udde7\ud83c\uddec\", \"\ud83c\udde7\ud83c\udded\", \"\ud83c\udde7\ud83c\uddee\", \"\ud83c\udde7\ud83c\uddef\", \"\ud83c\udde7\ud83c\uddf1\", \"\ud83c\udde7\ud83c\uddf2\", \"\ud83c\udde7\ud83c\uddf3\", \"\ud83c\udde7\ud83c\uddf4\", \"\ud83c\udde7\ud83c\uddf6\", \"\ud83c\udde7\ud83c\uddf7\", \"\ud83c\udde7\ud83c\uddf8\", \"\ud83c\udde7\ud83c\uddf9\", \"\ud83c\udde7\ud83c\uddfb\", \"\ud83c\udde7\ud83c\uddfc\", \"\ud83c\udde7\ud83c\uddfe\", \"\ud83c\udde7\ud83c\uddff\", \"\ud83c\udde8\ud83c\udde6\", \"\ud83c\udde8\ud83c\udde8\", \"\ud83c\udde8\ud83c\udde9\", \"\ud83c\udde8\ud83c\uddeb\", \"\ud83c\udde8\ud83c\uddec\", \"\ud83c\udde8\ud83c\udded\", \"\ud83c\udde8\ud83c\uddee\", \"\ud83c\udde8\ud83c\uddf0\", \"\ud83c\udde8\ud83c\uddf1\", \"\ud83c\udde8\ud83c\uddf2\", \"\ud83c\udde8\ud83c\uddf3\", \"\ud83c\udde8\ud83c\uddf4\", \"\ud83c\udde8\ud83c\uddf5\", \"\ud83c\udde8\ud83c\uddf7\", \"\ud83c\udde8\ud83c\uddfa\", \"\ud83c\udde8\ud83c\uddfb\", \"\ud83c\udde8\ud83c\uddfc\", \"\ud83c\udde8\ud83c\uddfd\", \"\ud83c\udde8\ud83c\uddfe\", \"\ud83c\udde8\ud83c\uddff\", \"\ud83c\udde9\ud83c\uddea\", \"\ud83c\udde9\ud83c\uddec\", \"\ud83c\udde9\ud83c\uddef\", \"\ud83c\udde9\ud83c\uddf0\", \"\ud83c\udde9\ud83c\uddf2\", \"\ud83c\udde9\ud83c\uddf4\", \"\ud83c\udde9\ud83c\uddff\", \"\ud83c\uddea\ud83c\udde6\", \"\ud83c\uddea\ud83c\udde8\", \"\ud83c\uddea\ud83c\uddea\", \"\ud83c\uddea\ud83c\uddec\", \"\ud83c\uddea\ud83c\udded\", \"\ud83c\uddea\ud83c\uddf7\", \"\ud83c\uddea\ud83c\uddf8\", \"\ud83c\uddea\ud83c\uddf9\", \"\ud83c\uddea\ud83c\uddfa\", \"\ud83c\uddeb\ud83c\uddee\", \"\ud83c\uddeb\ud83c\uddef\", \"\ud83c\uddeb\ud83c\uddf0\", \"\ud83c\uddeb\ud83c\uddf2\", \"\ud83c\uddeb\ud83c\uddf4\", \"\ud83c\uddeb\ud83c\uddf7\", \"\ud83c\uddec\ud83c\udde6\", \"\ud83c\uddec\ud83c\udde7\", \"\ud83c\uddec\ud83c\udde9\", \"\ud83c\uddec\ud83c\uddea\", \"\ud83c\uddec\ud83c\uddeb\", \"\ud83c\uddec\ud83c\uddec\", \"\ud83c\uddec\ud83c\udded\", \"\ud83c\uddec\ud83c\uddee\", \"\ud83c\uddec\ud83c\uddf1\", \"\ud83c\uddec\ud83c\uddf2\", \"\ud83c\uddec\ud83c\uddf3\", \"\ud83c\uddec\ud83c\uddf5\", \"\ud83c\uddec\ud83c\uddf6\", \"\ud83c\uddec\ud83c\uddf7\", \"\ud83c\uddec\ud83c\uddf8\", \"\ud83c\uddec\ud83c\uddf9\", \"\ud83c\uddec\ud83c\uddfa\", \"\ud83c\uddec\ud83c\uddfc\", \"\ud83c\uddec\ud83c\uddfe\", \"\ud83c\udded\ud83c\uddf0\", \"\ud83c\udded\ud83c\uddf2\", \"\ud83c\udded\ud83c\uddf3\", \"\ud83c\udded\ud83c\uddf7\", \"\ud83c\udded\ud83c\uddf9\", \"\ud83c\udded\ud83c\uddfa\", \"\ud83c\uddee\ud83c\udde8\", \"\ud83c\uddee\ud83c\udde9\", \"\ud83c\uddee\ud83c\uddea\", \"\ud83c\uddee\ud83c\uddf1\", \"\ud83c\uddee\ud83c\uddf2\", \"\ud83c\uddee\ud83c\uddf3\", \"\ud83c\uddee\ud83c\uddf4\", \"\ud83c\uddee\ud83c\uddf6\", \"\ud83c\uddee\ud83c\uddf7\", \"\ud83c\uddee\ud83c\uddf8\", \"\ud83c\uddee\ud83c\uddf9\", \"\ud83c\uddef\ud83c\uddea\", \"\ud83c\uddef\ud83c\uddf2\", \"\ud83c\uddef\ud83c\uddf4\", \"\ud83c\uddef\ud83c\uddf5\", \"\ud83c\uddf0\ud83c\uddea\", \"\ud83c\uddf0\ud83c\uddec\", \"\ud83c\uddf0\ud83c\udded\", \"\ud83c\uddf0\ud83c\uddee\", \"\ud83c\uddf0\ud83c\uddf2\", \"\ud83c\uddf0\ud83c\uddf3\", \"\ud83c\uddf0\ud83c\uddf5\", \"\ud83c\uddf0\ud83c\uddf7\", \"\ud83c\uddf0\ud83c\uddfc\", \"\ud83c\uddf0\ud83c\uddfe\", \"\ud83c\uddf0\ud83c\uddff\", \"\ud83c\uddf1\ud83c\udde6\", \"\ud83c\uddf1\ud83c\udde7\", \"\ud83c\uddf1\ud83c\udde8\", \"\ud83c\uddf1\ud83c\uddee\", \"\ud83c\uddf1\ud83c\uddf0\", \"\ud83c\uddf1\ud83c\uddf7\", \"\ud83c\uddf1\ud83c\uddf8\", \"\ud83c\uddf1\ud83c\uddf9\", \"\ud83c\uddf1\ud83c\uddfa\", \"\ud83c\uddf1\ud83c\uddfb\", \"\ud83c\uddf1\ud83c\uddfe\", \"\ud83c\uddf2\ud83c\udde6\", \"\ud83c\uddf2\ud83c\udde8\", \"\ud83c\uddf2\ud83c\udde9\", \"\ud83c\uddf2\ud83c\uddea\", \"\ud83c\uddf2\ud83c\uddeb\", \"\ud83c\uddf2\ud83c\uddec\", \"\ud83c\uddf2\ud83c\udded\", \"\ud83c\uddf2\ud83c\uddf0\", \"\ud83c\uddf2\ud83c\uddf1\", \"\ud83c\uddf2\ud83c\uddf2\", \"\ud83c\uddf2\ud83c\uddf3\", \"\ud83c\uddf2\ud83c\uddf4\", \"\ud83c\uddf2\ud83c\uddf5\", \"\ud83c\uddf2\ud83c\uddf6\", \"\ud83c\uddf2\ud83c\uddf7\", \"\ud83c\uddf2\ud83c\uddf8\", \"\ud83c\uddf2\ud83c\uddf9\", \"\ud83c\uddf2\ud83c\uddfa\", \"\ud83c\uddf2\ud83c\uddfb\", \"\ud83c\uddf2\ud83c\uddfc\", \"\ud83c\uddf2\ud83c\uddfd\", \"\ud83c\uddf2\ud83c\uddfe\", \"\ud83c\uddf2\ud83c\uddff\", \"\ud83c\uddf3\ud83c\udde6\", \"\ud83c\uddf3\ud83c\udde8\", \"\ud83c\uddf3\ud83c\uddea\", \"\ud83c\uddf3\ud83c\uddeb\", \"\ud83c\uddf3\ud83c\uddec\", \"\ud83c\uddf3\ud83c\uddee\", \"\ud83c\uddf3\ud83c\uddf1\", \"\ud83c\uddf3\ud83c\uddf4\", \"\ud83c\uddf3\ud83c\uddf5\", \"\ud83c\uddf3\ud83c\uddf7\", \"\ud83c\uddf3\ud83c\uddfa\", \"\ud83c\uddf3\ud83c\uddff\", \"\ud83c\uddf4\ud83c\uddf2\", \"\ud83c\uddf5\ud83c\udde6\", \"\ud83c\uddf5\ud83c\uddea\", \"\ud83c\uddf5\ud83c\uddeb\", \"\ud83c\uddf5\ud83c\uddec\", \"\ud83c\uddf5\ud83c\udded\", \"\ud83c\uddf5\ud83c\uddf0\", \"\ud83c\uddf5\ud83c\uddf1\", \"\ud83c\uddf5\ud83c\uddf2\", \"\ud83c\uddf5\ud83c\uddf3\", \"\ud83c\uddf5\ud83c\uddf7\", \"\ud83c\uddf5\ud83c\uddf8\", \"\ud83c\uddf5\ud83c\uddf9\", \"\ud83c\uddf5\ud83c\uddfc\", \"\ud83c\uddf5\ud83c\uddfe\", \"\ud83c\uddf6\ud83c\udde6\", \"\ud83c\uddf7\ud83c\uddea\", \"\ud83c\uddf7\ud83c\uddf4\", \"\ud83c\uddf7\ud83c\uddf8\", \"\ud83c\uddf7\ud83c\uddfa\", \"\ud83c\uddf7\ud83c\uddfc\", \"\ud83c\uddf8\ud83c\udde6\", \"\ud83c\uddf8\ud83c\udde7\", \"\ud83c\uddf8\ud83c\udde8\", \"\ud83c\uddf8\ud83c\udde9\", \"\ud83c\uddf8\ud83c\uddea\", \"\ud83c\uddf8\ud83c\uddec\", \"\ud83c\uddf8\ud83c\udded\", \"\ud83c\uddf8\ud83c\uddee\", \"\ud83c\uddf8\ud83c\uddef\", \"\ud83c\uddf8\ud83c\uddf0\", \"\ud83c\uddf8\ud83c\uddf1\", \"\ud83c\uddf8\ud83c\uddf2\", \"\ud83c\uddf8\ud83c\uddf3\", \"\ud83c\uddf8\ud83c\uddf4\", \"\ud83c\uddf8\ud83c\uddf7\", \"\ud83c\uddf8\ud83c\uddf8\", \"\ud83c\uddf8\ud83c\uddf9\", \"\ud83c\uddf8\ud83c\uddfb\", \"\ud83c\uddf8\ud83c\uddfd\", \"\ud83c\uddf8\ud83c\uddfe\", \"\ud83c\uddf8\ud83c\uddff\", \"\ud83c\uddf9\ud83c\udde6\", \"\ud83c\uddf9\ud83c\udde8\", \"\ud83c\uddf9\ud83c\udde9\", \"\ud83c\uddf9\ud83c\uddeb\", \"\ud83c\uddf9\ud83c\uddec\", \"\ud83c\uddf9\ud83c\udded\", \"\ud83c\uddf9\ud83c\uddef\", \"\ud83c\uddf9\ud83c\uddf0\", \"\ud83c\uddf9\ud83c\uddf1\", \"\ud83c\uddf9\ud83c\uddf2\", \"\ud83c\uddf9\ud83c\uddf3\", \"\ud83c\uddf9\ud83c\uddf4\", \"\ud83c\uddf9\ud83c\uddf7\", \"\ud83c\uddf9\ud83c\uddf9\", \"\ud83c\uddf9\ud83c\uddfb\", \"\ud83c\uddf9\ud83c\uddfc\", \"\ud83c\uddf9\ud83c\uddff\", \"\ud83c\uddfa\ud83c\udde6\", \"\ud83c\uddfa\ud83c\uddec\", \"\ud83c\uddfa\ud83c\uddf2\", \"\ud83c\uddfa\ud83c\uddf3\", \"\ud83c\uddfa\ud83c\uddf8\", \"\ud83c\uddfa\ud83c\uddfe\", \"\ud83c\uddfa\ud83c\uddff\", \"\ud83c\uddfb\ud83c\udde6\", \"\ud83c\uddfb\ud83c\udde8\", \"\ud83c\uddfb\ud83c\uddea\", \"\ud83c\uddfb\ud83c\uddec\", \"\ud83c\uddfb\ud83c\uddee\", \"\ud83c\uddfb\ud83c\uddf3\", \"\ud83c\uddfb\ud83c\uddfa\", \"\ud83c\uddfc\ud83c\uddeb\", \"\ud83c\uddfc\ud83c\uddf8\", \"\ud83c\uddfd\ud83c\uddf0\", \"\ud83c\uddfe\ud83c\uddea\", \"\ud83c\uddfe\ud83c\uddf9\", \"\ud83c\uddff\ud83c\udde6\", \"\ud83c\uddff\ud83c\uddf2\", \"\ud83c\uddff\ud83c\uddfc\", \"\ud83c\ude01\", \"\ud83c\ude02\", \"\ud83c\ude02\ufe0f\", \"\ud83c\ude1a\", \"\ud83c\ude2f\", \"\ud83c\ude32\", \"\ud83c\ude33\", \"\ud83c\ude34\", \"\ud83c\ude35\", \"\ud83c\ude36\", \"\ud83c\ude37\", \"\ud83c\ude37\ufe0f\", \"\ud83c\ude38\", \"\ud83c\ude39\", \"\ud83c\ude3a\", \"\ud83c\ude50\", \"\ud83c\ude51\", \"\ud83c\udf00\", \"\ud83c\udf01\", \"\ud83c\udf02\", \"\ud83c\udf03\", \"\ud83c\udf04\", \"\ud83c\udf05\", \"\ud83c\udf06\", \"\ud83c\udf07\", \"\ud83c\udf08\", \"\ud83c\udf09\", \"\ud83c\udf0a\", \"\ud83c\udf0b\", \"\ud83c\udf0c\", \"\ud83c\udf0d\", \"\ud83c\udf0e\", \"\ud83c\udf0f\", \"\ud83c\udf10\", \"\ud83c\udf11\", \"\ud83c\udf12\", \"\ud83c\udf13\", \"\ud83c\udf14\", \"\ud83c\udf15\", \"\ud83c\udf16\", \"\ud83c\udf17\", \"\ud83c\udf18\", \"\ud83c\udf19\", \"\ud83c\udf1a\", \"\ud83c\udf1b\", \"\ud83c\udf1c\", \"\ud83c\udf1d\", \"\ud83c\udf1e\", \"\ud83c\udf1f\", \"\ud83c\udf20\", \"\ud83c\udf21\", \"\ud83c\udf21\ufe0f\", \"\ud83c\udf24\", \"\ud83c\udf24\ufe0f\", \"\ud83c\udf25\", \"\ud83c\udf25\ufe0f\", \"\ud83c\udf26\", \"\ud83c\udf26\ufe0f\", \"\ud83c\udf27\", \"\ud83c\udf27\ufe0f\", \"\ud83c\udf28\", \"\ud83c\udf28\ufe0f\", \"\ud83c\udf29\", \"\ud83c\udf29\ufe0f\", \"\ud83c\udf2a\", \"\ud83c\udf2a\ufe0f\", \"\ud83c\udf2b\", \"\ud83c\udf2b\ufe0f\", \"\ud83c\udf2c\", \"\ud83c\udf2c\ufe0f\", \"\ud83c\udf2d\", \"\ud83c\udf2e\", \"\ud83c\udf2f\", \"\ud83c\udf30\", \"\ud83c\udf31\", \"\ud83c\udf32\", \"\ud83c\udf33\", \"\ud83c\udf34\", \"\ud83c\udf35\", \"\ud83c\udf36\", \"\ud83c\udf36\ufe0f\", \"\ud83c\udf37\", \"\ud83c\udf38\", \"\ud83c\udf39\", \"\ud83c\udf3a\", \"\ud83c\udf3b\", \"\ud83c\udf3c\", \"\ud83c\udf3d\", \"\ud83c\udf3e\", \"\ud83c\udf3f\", \"\ud83c\udf40\", \"\ud83c\udf41\", \"\ud83c\udf42\", \"\ud83c\udf43\", \"\ud83c\udf44\", \"\ud83c\udf44\u200d\ud83d\udfeb\", \"\ud83c\udf45\", \"\ud83c\udf46\", \"\ud83c\udf47\", \"\ud83c\udf48\", \"\ud83c\udf49\", \"\ud83c\udf4a\", \"\ud83c\udf4b\", \"\ud83c\udf4b\u200d\ud83d\udfe9\", \"\ud83c\udf4c\", \"\ud83c\udf4d\", \"\ud83c\udf4e\", \"\ud83c\udf4f\", \"\ud83c\udf50\", \"\ud83c\udf51\", \"\ud83c\udf52\", \"\ud83c\udf53\", \"\ud83c\udf54\", \"\ud83c\udf55\", \"\ud83c\udf56\", \"\ud83c\udf57\", \"\ud83c\udf58\", \"\ud83c\udf59\", \"\ud83c\udf5a\", \"\ud83c\udf5b\", \"\ud83c\udf5c\", \"\ud83c\udf5d\", \"\ud83c\udf5e\", \"\ud83c\udf5f\", \"\ud83c\udf60\", \"\ud83c\udf61\", \"\ud83c\udf62\", \"\ud83c\udf63\", \"\ud83c\udf64\", \"\ud83c\udf65\", \"\ud83c\udf66\", \"\ud83c\udf67\", \"\ud83c\udf68\", \"\ud83c\udf69\", \"\ud83c\udf6a\", \"\ud83c\udf6b\", \"\ud83c\udf6c\", \"\ud83c\udf6d\", \"\ud83c\udf6e\", \"\ud83c\udf6f\", \"\ud83c\udf70\", \"\ud83c\udf71\", \"\ud83c\udf72\", \"\ud83c\udf73\", \"\ud83c\udf74\", \"\ud83c\udf75\", \"\ud83c\udf76\", \"\ud83c\udf77\", \"\ud83c\udf78\", \"\ud83c\udf79\", \"\ud83c\udf7a\", \"\ud83c\udf7b\", \"\ud83c\udf7c\", \"\ud83c\udf7d\", \"\ud83c\udf7d\ufe0f\", \"\ud83c\udf7e\", \"\ud83c\udf7f\", \"\ud83c\udf80\", \"\ud83c\udf81\", \"\ud83c\udf82\", \"\ud83c\udf83\", \"\ud83c\udf84\", \"\ud83c\udf85\", \"\ud83c\udf85\ud83c\udffb\", \"\ud83c\udf85\ud83c\udffc\", \"\ud83c\udf85\ud83c\udffd\", \"\ud83c\udf85\ud83c\udffe\", \"\ud83c\udf85\ud83c\udfff\", \"\ud83c\udf86\", \"\ud83c\udf87\", \"\ud83c\udf88\", \"\ud83c\udf89\", \"\ud83c\udf8a\", \"\ud83c\udf8b\", \"\ud83c\udf8c\", \"\ud83c\udf8d\", \"\ud83c\udf8e\", \"\ud83c\udf8f\", \"\ud83c\udf90\", \"\ud83c\udf91\", \"\ud83c\udf92\", \"\ud83c\udf93\", \"\ud83c\udf96\", \"\ud83c\udf96\ufe0f\", \"\ud83c\udf97\", \"\ud83c\udf97\ufe0f\", \"\ud83c\udf99\", \"\ud83c\udf99\ufe0f\", \"\ud83c\udf9a\", \"\ud83c\udf9a\ufe0f\", \"\ud83c\udf9b\", \"\ud83c\udf9b\ufe0f\", \"\ud83c\udf9e\", \"\ud83c\udf9e\ufe0f\", \"\ud83c\udf9f\", \"\ud83c\udf9f\ufe0f\", \"\ud83c\udfa0\", \"\ud83c\udfa1\", \"\ud83c\udfa2\", \"\ud83c\udfa3\", \"\ud83c\udfa4\", \"\ud83c\udfa5\", \"\ud83c\udfa6\", \"\ud83c\udfa7\", \"\ud83c\udfa8\", \"\ud83c\udfa9\", \"\ud83c\udfaa\", \"\ud83c\udfab\", \"\ud83c\udfac\", \"\ud83c\udfad\", \"\ud83c\udfae\", \"\ud83c\udfaf\", \"\ud83c\udfb0\", \"\ud83c\udfb1\", \"\ud83c\udfb2\", \"\ud83c\udfb3\", \"\ud83c\udfb4\", \"\ud83c\udfb5\", \"\ud83c\udfb6\", \"\ud83c\udfb7\", \"\ud83c\udfb8\", \"\ud83c\udfb9\", \"\ud83c\udfba\", \"\ud83c\udfbb\", \"\ud83c\udfbc\", \"\ud83c\udfbd\", \"\ud83c\udfbe\", \"\ud83c\udfbf\", \"\ud83c\udfc0\", \"\ud83c\udfc1\", \"\ud83c\udfc2\", \"\ud83c\udfc2\ud83c\udffb\", \"\ud83c\udfc2\ud83c\udffc\", \"\ud83c\udfc2\ud83c\udffd\", \"\ud83c\udfc2\ud83c\udffe\", \"\ud83c\udfc2\ud83c\udfff\", \"\ud83c\udfc3\", \"\ud83c\udfc3\u200d\u2640\", \"\ud83c\udfc3\u200d\u2640\u200d\u27a1\", \"\ud83c\udfc3\u200d\u2640\u200d\u27a1\ufe0f\", \"\ud83c\udfc3\u200d\u2640\ufe0f\", \"\ud83c\udfc3\u200d\u2640\ufe0f\u200d\u27a1\", \"\ud83c\udfc3\u200d\u2640\ufe0f\u200d\u27a1\ufe0f\", \"\ud83c\udfc3\u200d\u2642\", \"\ud83c\udfc3\u200d\u2642\u200d\u27a1\", \"\ud83c\udfc3\u200d\u2642\u200d\u27a1\ufe0f\", \"\ud83c\udfc3\u200d\u2642\ufe0f\", \"\ud83c\udfc3\u200d\u2642\ufe0f\u200d\u27a1\", \"\ud83c\udfc3\u200d\u2642\ufe0f\u200d\u27a1\ufe0f\", \"\ud83c\udfc3\u200d\u27a1\", \"\ud83c\udfc3\u200d\u27a1\ufe0f\", \"\ud83c\udfc3\ud83c\udffb\", \"\ud83c\udfc3\ud83c\udffb\u200d\u2640\", \"\ud83c\udfc3\ud83c\udffb\u200d\u2640\u200d\u27a1\", \"\ud83c\udfc3\ud83c\udffb\u200d\u2640\u200d\u27a1\ufe0f\", \"\ud83c\udfc3\ud83c\udffb\u200d\u2640\ufe0f\", \"\ud83c\udfc3\ud83c\udffb\u200d\u2640\ufe0f\u200d\u27a1\", \"\ud83c\udfc3\ud83c\udffb\u200d\u2640\ufe0f\u200d\u27a1\ufe0f\", \"\ud83c\udfc3\ud83c\udffb\u200d\u2642\", \"\ud83c\udfc3\ud83c\udffb\u200d\u2642\u200d\u27a1\", \"\ud83c\udfc3\ud83c\udffb\u200d\u2642\u200d\u27a1\ufe0f\", \"\ud83c\udfc3\ud83c\udffb\u200d\u2642\ufe0f\", \"\ud83c\udfc3\ud83c\udffb\u200d\u2642\ufe0f\u200d\u27a1\", \"\ud83c\udfc3\ud83c\udffb\u200d\u2642\ufe0f\u200d\u27a1\ufe0f\", \"\ud83c\udfc3\ud83c\udffb\u200d\u27a1\", \"\ud83c\udfc3\ud83c\udffb\u200d\u27a1\ufe0f\", \"\ud83c\udfc3\ud83c\udffc\", \"\ud83c\udfc3\ud83c\udffc\u200d\u2640\", \"\ud83c\udfc3\ud83c\udffc\u200d\u2640\u200d\u27a1\", \"\ud83c\udfc3\ud83c\udffc\u200d\u2640\u200d\u27a1\ufe0f\", \"\ud83c\udfc3\ud83c\udffc\u200d\u2640\ufe0f\", \"\ud83c\udfc3\ud83c\udffc\u200d\u2640\ufe0f\u200d\u27a1\", \"\ud83c\udfc3\ud83c\udffc\u200d\u2640\ufe0f\u200d\u27a1\ufe0f\", \"\ud83c\udfc3\ud83c\udffc\u200d\u2642\", \"\ud83c\udfc3\ud83c\udffc\u200d\u2642\u200d\u27a1\", \"\ud83c\udfc3\ud83c\udffc\u200d\u2642\u200d\u27a1\ufe0f\", \"\ud83c\udfc3\ud83c\udffc\u200d\u2642\ufe0f\", \"\ud83c\udfc3\ud83c\udffc\u200d\u2642\ufe0f\u200d\u27a1\", \"\ud83c\udfc3\ud83c\udffc\u200d\u2642\ufe0f\u200d\u27a1\ufe0f\", \"\ud83c\udfc3\ud83c\udffc\u200d\u27a1\", \"\ud83c\udfc3\ud83c\udffc\u200d\u27a1\ufe0f\", \"\ud83c\udfc3\ud83c\udffd\", \"\ud83c\udfc3\ud83c\udffd\u200d\u2640\", \"\ud83c\udfc3\ud83c\udffd\u200d\u2640\u200d\u27a1\", \"\ud83c\udfc3\ud83c\udffd\u200d\u2640\u200d\u27a1\ufe0f\", \"\ud83c\udfc3\ud83c\udffd\u200d\u2640\ufe0f\", \"\ud83c\udfc3\ud83c\udffd\u200d\u2640\ufe0f\u200d\u27a1\", \"\ud83c\udfc3\ud83c\udffd\u200d\u2640\ufe0f\u200d\u27a1\ufe0f\", \"\ud83c\udfc3\ud83c\udffd\u200d\u2642\", \"\ud83c\udfc3\ud83c\udffd\u200d\u2642\u200d\u27a1\", \"\ud83c\udfc3\ud83c\udffd\u200d\u2642\u200d\u27a1\ufe0f\", \"\ud83c\udfc3\ud83c\udffd\u200d\u2642\ufe0f\", \"\ud83c\udfc3\ud83c\udffd\u200d\u2642\ufe0f\u200d\u27a1\", \"\ud83c\udfc3\ud83c\udffd\u200d\u2642\ufe0f\u200d\u27a1\ufe0f\", \"\ud83c\udfc3\ud83c\udffd\u200d\u27a1\", \"\ud83c\udfc3\ud83c\udffd\u200d\u27a1\ufe0f\", \"\ud83c\udfc3\ud83c\udffe\", \"\ud83c\udfc3\ud83c\udffe\u200d\u2640\", \"\ud83c\udfc3\ud83c\udffe\u200d\u2640\u200d\u27a1\", \"\ud83c\udfc3\ud83c\udffe\u200d\u2640\u200d\u27a1\ufe0f\", \"\ud83c\udfc3\ud83c\udffe\u200d\u2640\ufe0f\", \"\ud83c\udfc3\ud83c\udffe\u200d\u2640\ufe0f\u200d\u27a1\", \"\ud83c\udfc3\ud83c\udffe\u200d\u2640\ufe0f\u200d\u27a1\ufe0f\", \"\ud83c\udfc3\ud83c\udffe\u200d\u2642\", \"\ud83c\udfc3\ud83c\udffe\u200d\u2642\u200d\u27a1\", \"\ud83c\udfc3\ud83c\udffe\u200d\u2642\u200d\u27a1\ufe0f\", \"\ud83c\udfc3\ud83c\udffe\u200d\u2642\ufe0f\", \"\ud83c\udfc3\ud83c\udffe\u200d\u2642\ufe0f\u200d\u27a1\", \"\ud83c\udfc3\ud83c\udffe\u200d\u2642\ufe0f\u200d\u27a1\ufe0f\", \"\ud83c\udfc3\ud83c\udffe\u200d\u27a1\", \"\ud83c\udfc3\ud83c\udffe\u200d\u27a1\ufe0f\", \"\ud83c\udfc3\ud83c\udfff\", \"\ud83c\udfc3\ud83c\udfff\u200d\u2640\", \"\ud83c\udfc3\ud83c\udfff\u200d\u2640\u200d\u27a1\", \"\ud83c\udfc3\ud83c\udfff\u200d\u2640\u200d\u27a1\ufe0f\", \"\ud83c\udfc3\ud83c\udfff\u200d\u2640\ufe0f\", \"\ud83c\udfc3\ud83c\udfff\u200d\u2640\ufe0f\u200d\u27a1\", \"\ud83c\udfc3\ud83c\udfff\u200d\u2640\ufe0f\u200d\u27a1\ufe0f\", \"\ud83c\udfc3\ud83c\udfff\u200d\u2642\", \"\ud83c\udfc3\ud83c\udfff\u200d\u2642\u200d\u27a1\", \"\ud83c\udfc3\ud83c\udfff\u200d\u2642\u200d\u27a1\ufe0f\", \"\ud83c\udfc3\ud83c\udfff\u200d\u2642\ufe0f\", \"\ud83c\udfc3\ud83c\udfff\u200d\u2642\ufe0f\u200d\u27a1\", \"\ud83c\udfc3\ud83c\udfff\u200d\u2642\ufe0f\u200d\u27a1\ufe0f\", \"\ud83c\udfc3\ud83c\udfff\u200d\u27a1\", \"\ud83c\udfc3\ud83c\udfff\u200d\u27a1\ufe0f\", \"\ud83c\udfc4\", \"\ud83c\udfc4\u200d\u2640\", \"\ud83c\udfc4\u200d\u2640\ufe0f\", \"\ud83c\udfc4\u200d\u2642\", \"\ud83c\udfc4\u200d\u2642\ufe0f\", \"\ud83c\udfc4\ud83c\udffb\", \"\ud83c\udfc4\ud83c\udffb\u200d\u2640\", \"\ud83c\udfc4\ud83c\udffb\u200d\u2640\ufe0f\", \"\ud83c\udfc4\ud83c\udffb\u200d\u2642\", \"\ud83c\udfc4\ud83c\udffb\u200d\u2642\ufe0f\", \"\ud83c\udfc4\ud83c\udffc\", \"\ud83c\udfc4\ud83c\udffc\u200d\u2640\", \"\ud83c\udfc4\ud83c\udffc\u200d\u2640\ufe0f\", \"\ud83c\udfc4\ud83c\udffc\u200d\u2642\", \"\ud83c\udfc4\ud83c\udffc\u200d\u2642\ufe0f\", \"\ud83c\udfc4\ud83c\udffd\", \"\ud83c\udfc4\ud83c\udffd\u200d\u2640\", \"\ud83c\udfc4\ud83c\udffd\u200d\u2640\ufe0f\", \"\ud83c\udfc4\ud83c\udffd\u200d\u2642\", \"\ud83c\udfc4\ud83c\udffd\u200d\u2642\ufe0f\", \"\ud83c\udfc4\ud83c\udffe\", \"\ud83c\udfc4\ud83c\udffe\u200d\u2640\", \"\ud83c\udfc4\ud83c\udffe\u200d\u2640\ufe0f\", \"\ud83c\udfc4\ud83c\udffe\u200d\u2642\", \"\ud83c\udfc4\ud83c\udffe\u200d\u2642\ufe0f\", \"\ud83c\udfc4\ud83c\udfff\", \"\ud83c\udfc4\ud83c\udfff\u200d\u2640\", \"\ud83c\udfc4\ud83c\udfff\u200d\u2640\ufe0f\", \"\ud83c\udfc4\ud83c\udfff\u200d\u2642\", \"\ud83c\udfc4\ud83c\udfff\u200d\u2642\ufe0f\", \"\ud83c\udfc5\", \"\ud83c\udfc6\", \"\ud83c\udfc7\", \"\ud83c\udfc7\ud83c\udffb\", \"\ud83c\udfc7\ud83c\udffc\", \"\ud83c\udfc7\ud83c\udffd\", \"\ud83c\udfc7\ud83c\udffe\", \"\ud83c\udfc7\ud83c\udfff\", \"\ud83c\udfc8\", \"\ud83c\udfc9\", \"\ud83c\udfca\", \"\ud83c\udfca\u200d\u2640\", \"\ud83c\udfca\u200d\u2640\ufe0f\", \"\ud83c\udfca\u200d\u2642\", \"\ud83c\udfca\u200d\u2642\ufe0f\", \"\ud83c\udfca\ud83c\udffb\", \"\ud83c\udfca\ud83c\udffb\u200d\u2640\", \"\ud83c\udfca\ud83c\udffb\u200d\u2640\ufe0f\", \"\ud83c\udfca\ud83c\udffb\u200d\u2642\", \"\ud83c\udfca\ud83c\udffb\u200d\u2642\ufe0f\", \"\ud83c\udfca\ud83c\udffc\", \"\ud83c\udfca\ud83c\udffc\u200d\u2640\", \"\ud83c\udfca\ud83c\udffc\u200d\u2640\ufe0f\", \"\ud83c\udfca\ud83c\udffc\u200d\u2642\", \"\ud83c\udfca\ud83c\udffc\u200d\u2642\ufe0f\", \"\ud83c\udfca\ud83c\udffd\", \"\ud83c\udfca\ud83c\udffd\u200d\u2640\", \"\ud83c\udfca\ud83c\udffd\u200d\u2640\ufe0f\", \"\ud83c\udfca\ud83c\udffd\u200d\u2642\", \"\ud83c\udfca\ud83c\udffd\u200d\u2642\ufe0f\", \"\ud83c\udfca\ud83c\udffe\", \"\ud83c\udfca\ud83c\udffe\u200d\u2640\", \"\ud83c\udfca\ud83c\udffe\u200d\u2640\ufe0f\", \"\ud83c\udfca\ud83c\udffe\u200d\u2642\", \"\ud83c\udfca\ud83c\udffe\u200d\u2642\ufe0f\", \"\ud83c\udfca\ud83c\udfff\", \"\ud83c\udfca\ud83c\udfff\u200d\u2640\", \"\ud83c\udfca\ud83c\udfff\u200d\u2640\ufe0f\", \"\ud83c\udfca\ud83c\udfff\u200d\u2642\", \"\ud83c\udfca\ud83c\udfff\u200d\u2642\ufe0f\", \"\ud83c\udfcb\", \"\ud83c\udfcb\u200d\u2640\", \"\ud83c\udfcb\u200d\u2640\ufe0f\", \"\ud83c\udfcb\u200d\u2642\", \"\ud83c\udfcb\u200d\u2642\ufe0f\", \"\ud83c\udfcb\ufe0f\", \"\ud83c\udfcb\ufe0f\u200d\u2640\", \"\ud83c\udfcb\ufe0f\u200d\u2640\ufe0f\", \"\ud83c\udfcb\ufe0f\u200d\u2642\", \"\ud83c\udfcb\ufe0f\u200d\u2642\ufe0f\", \"\ud83c\udfcb\ud83c\udffb\", \"\ud83c\udfcb\ud83c\udffb\u200d\u2640\", \"\ud83c\udfcb\ud83c\udffb\u200d\u2640\ufe0f\", \"\ud83c\udfcb\ud83c\udffb\u200d\u2642\", \"\ud83c\udfcb\ud83c\udffb\u200d\u2642\ufe0f\", \"\ud83c\udfcb\ud83c\udffc\", \"\ud83c\udfcb\ud83c\udffc\u200d\u2640\", \"\ud83c\udfcb\ud83c\udffc\u200d\u2640\ufe0f\", \"\ud83c\udfcb\ud83c\udffc\u200d\u2642\", \"\ud83c\udfcb\ud83c\udffc\u200d\u2642\ufe0f\", \"\ud83c\udfcb\ud83c\udffd\", \"\ud83c\udfcb\ud83c\udffd\u200d\u2640\", \"\ud83c\udfcb\ud83c\udffd\u200d\u2640\ufe0f\", \"\ud83c\udfcb\ud83c\udffd\u200d\u2642\", \"\ud83c\udfcb\ud83c\udffd\u200d\u2642\ufe0f\", \"\ud83c\udfcb\ud83c\udffe\", \"\ud83c\udfcb\ud83c\udffe\u200d\u2640\", \"\ud83c\udfcb\ud83c\udffe\u200d\u2640\ufe0f\", \"\ud83c\udfcb\ud83c\udffe\u200d\u2642\", \"\ud83c\udfcb\ud83c\udffe\u200d\u2642\ufe0f\", \"\ud83c\udfcb\ud83c\udfff\", \"\ud83c\udfcb\ud83c\udfff\u200d\u2640\", \"\ud83c\udfcb\ud83c\udfff\u200d\u2640\ufe0f\", \"\ud83c\udfcb\ud83c\udfff\u200d\u2642\", \"\ud83c\udfcb\ud83c\udfff\u200d\u2642\ufe0f\", \"\ud83c\udfcc\", \"\ud83c\udfcc\u200d\u2640\", \"\ud83c\udfcc\u200d\u2640\ufe0f\", \"\ud83c\udfcc\u200d\u2642\", \"\ud83c\udfcc\u200d\u2642\ufe0f\", \"\ud83c\udfcc\ufe0f\", \"\ud83c\udfcc\ufe0f\u200d\u2640\", \"\ud83c\udfcc\ufe0f\u200d\u2640\ufe0f\", \"\ud83c\udfcc\ufe0f\u200d\u2642\", \"\ud83c\udfcc\ufe0f\u200d\u2642\ufe0f\", \"\ud83c\udfcc\ud83c\udffb\", \"\ud83c\udfcc\ud83c\udffb\u200d\u2640\", \"\ud83c\udfcc\ud83c\udffb\u200d\u2640\ufe0f\", \"\ud83c\udfcc\ud83c\udffb\u200d\u2642\", \"\ud83c\udfcc\ud83c\udffb\u200d\u2642\ufe0f\", \"\ud83c\udfcc\ud83c\udffc\", \"\ud83c\udfcc\ud83c\udffc\u200d\u2640\", \"\ud83c\udfcc\ud83c\udffc\u200d\u2640\ufe0f\", \"\ud83c\udfcc\ud83c\udffc\u200d\u2642\", \"\ud83c\udfcc\ud83c\udffc\u200d\u2642\ufe0f\", \"\ud83c\udfcc\ud83c\udffd\", \"\ud83c\udfcc\ud83c\udffd\u200d\u2640\", \"\ud83c\udfcc\ud83c\udffd\u200d\u2640\ufe0f\", \"\ud83c\udfcc\ud83c\udffd\u200d\u2642\", \"\ud83c\udfcc\ud83c\udffd\u200d\u2642\ufe0f\", \"\ud83c\udfcc\ud83c\udffe\", \"\ud83c\udfcc\ud83c\udffe\u200d\u2640\", \"\ud83c\udfcc\ud83c\udffe\u200d\u2640\ufe0f\", \"\ud83c\udfcc\ud83c\udffe\u200d\u2642\", \"\ud83c\udfcc\ud83c\udffe\u200d\u2642\ufe0f\", \"\ud83c\udfcc\ud83c\udfff\", \"\ud83c\udfcc\ud83c\udfff\u200d\u2640\", \"\ud83c\udfcc\ud83c\udfff\u200d\u2640\ufe0f\", \"\ud83c\udfcc\ud83c\udfff\u200d\u2642\", \"\ud83c\udfcc\ud83c\udfff\u200d\u2642\ufe0f\", \"\ud83c\udfcd\", \"\ud83c\udfcd\ufe0f\", \"\ud83c\udfce\", \"\ud83c\udfce\ufe0f\", \"\ud83c\udfcf\", \"\ud83c\udfd0\", \"\ud83c\udfd1\", \"\ud83c\udfd2\", \"\ud83c\udfd3\", \"\ud83c\udfd4\", \"\ud83c\udfd4\ufe0f\", \"\ud83c\udfd5\", \"\ud83c\udfd5\ufe0f\", \"\ud83c\udfd6\", \"\ud83c\udfd6\ufe0f\", \"\ud83c\udfd7\", \"\ud83c\udfd7\ufe0f\", \"\ud83c\udfd8\", \"\ud83c\udfd8\ufe0f\", \"\ud83c\udfd9\", \"\ud83c\udfd9\ufe0f\", \"\ud83c\udfda\", \"\ud83c\udfda\ufe0f\", \"\ud83c\udfdb\", \"\ud83c\udfdb\ufe0f\", \"\ud83c\udfdc\", \"\ud83c\udfdc\ufe0f\", \"\ud83c\udfdd\", \"\ud83c\udfdd\ufe0f\", \"\ud83c\udfde\", \"\ud83c\udfde\ufe0f\", \"\ud83c\udfdf\", \"\ud83c\udfdf\ufe0f\", \"\ud83c\udfe0\", \"\ud83c\udfe1\", \"\ud83c\udfe2\", \"\ud83c\udfe3\", \"\ud83c\udfe4\", \"\ud83c\udfe5\", \"\ud83c\udfe6\", \"\ud83c\udfe7\", \"\ud83c\udfe8\", \"\ud83c\udfe9\", \"\ud83c\udfea\", \"\ud83c\udfeb\", \"\ud83c\udfec\", \"\ud83c\udfed\", \"\ud83c\udfee\", \"\ud83c\udfef\", \"\ud83c\udff0\", \"\ud83c\udff3\", \"\ud83c\udff3\u200d\u26a7\", \"\ud83c\udff3\u200d\u26a7\ufe0f\", \"\ud83c\udff3\u200d\ud83c\udf08\", \"\ud83c\udff3\ufe0f\", \"\ud83c\udff3\ufe0f\u200d\u26a7\", \"\ud83c\udff3\ufe0f\u200d\u26a7\ufe0f\", \"\ud83c\udff3\ufe0f\u200d\ud83c\udf08\", \"\ud83c\udff4\", \"\ud83c\udff4\u200d\u2620\", \"\ud83c\udff4\u200d\u2620\ufe0f\", \"\ud83c\udff4\udb40\udc67\udb40\udc62\udb40\udc65\udb40\udc6e\udb40\udc67\udb40\udc7f\", \"\ud83c\udff4\udb40\udc67\udb40\udc62\udb40\udc73\udb40\udc63\udb40\udc74\udb40\udc7f\", \"\ud83c\udff4\udb40\udc67\udb40\udc62\udb40\udc77\udb40\udc6c\udb40\udc73\udb40\udc7f\", \"\ud83c\udff5\", \"\ud83c\udff5\ufe0f\", \"\ud83c\udff7\", \"\ud83c\udff7\ufe0f\", \"\ud83c\udff8\", \"\ud83c\udff9\", \"\ud83c\udffa\", \"\ud83c\udffb\", \"\ud83c\udffc\", \"\ud83c\udffd\", \"\ud83c\udffe\", \"\ud83c\udfff\", \"\ud83d\udc00\", \"\ud83d\udc01\", \"\ud83d\udc02\", \"\ud83d\udc03\", \"\ud83d\udc04\", \"\ud83d\udc05\", \"\ud83d\udc06\", \"\ud83d\udc07\", \"\ud83d\udc08\", \"\ud83d\udc08\u200d\u2b1b\", \"\ud83d\udc09\", \"\ud83d\udc0a\", \"\ud83d\udc0b\", \"\ud83d\udc0c\", \"\ud83d\udc0d\", \"\ud83d\udc0e\", \"\ud83d\udc0f\", \"\ud83d\udc10\", \"\ud83d\udc11\", \"\ud83d\udc12\", \"\ud83d\udc13\", \"\ud83d\udc14\", \"\ud83d\udc15\", \"\ud83d\udc15\u200d\ud83e\uddba\", \"\ud83d\udc16\", \"\ud83d\udc17\", \"\ud83d\udc18\", \"\ud83d\udc19\", \"\ud83d\udc1a\", \"\ud83d\udc1b\", \"\ud83d\udc1c\", \"\ud83d\udc1d\", \"\ud83d\udc1e\", \"\ud83d\udc1f\", \"\ud83d\udc20\", \"\ud83d\udc21\", \"\ud83d\udc22\", \"\ud83d\udc23\", \"\ud83d\udc24\", \"\ud83d\udc25\", \"\ud83d\udc26\", \"\ud83d\udc26\u200d\u2b1b\", \"\ud83d\udc26\u200d\ud83d\udd25\", \"\ud83d\udc27\", \"\ud83d\udc28\", \"\ud83d\udc29\", \"\ud83d\udc2a\", \"\ud83d\udc2b\", \"\ud83d\udc2c\", \"\ud83d\udc2d\", \"\ud83d\udc2e\", \"\ud83d\udc2f\", \"\ud83d\udc30\", \"\ud83d\udc31\", \"\ud83d\udc32\", \"\ud83d\udc33\", \"\ud83d\udc34\", \"\ud83d\udc35\", \"\ud83d\udc36\", \"\ud83d\udc37\", \"\ud83d\udc38\", \"\ud83d\udc39\", \"\ud83d\udc3a\", \"\ud83d\udc3b\", \"\ud83d\udc3b\u200d\u2744\", \"\ud83d\udc3b\u200d\u2744\ufe0f\", \"\ud83d\udc3c\", \"\ud83d\udc3d\", \"\ud83d\udc3e\", \"\ud83d\udc3f\", \"\ud83d\udc3f\ufe0f\", \"\ud83d\udc40\", \"\ud83d\udc41\", \"\ud83d\udc41\u200d\ud83d\udde8\", \"\ud83d\udc41\u200d\ud83d\udde8\ufe0f\", \"\ud83d\udc41\ufe0f\", \"\ud83d\udc41\ufe0f\u200d\ud83d\udde8\", \"\ud83d\udc41\ufe0f\u200d\ud83d\udde8\ufe0f\", \"\ud83d\udc42\", \"\ud83d\udc42\ud83c\udffb\", \"\ud83d\udc42\ud83c\udffc\", \"\ud83d\udc42\ud83c\udffd\", \"\ud83d\udc42\ud83c\udffe\", \"\ud83d\udc42\ud83c\udfff\", \"\ud83d\udc43\", \"\ud83d\udc43\ud83c\udffb\", \"\ud83d\udc43\ud83c\udffc\", \"\ud83d\udc43\ud83c\udffd\", \"\ud83d\udc43\ud83c\udffe\", \"\ud83d\udc43\ud83c\udfff\", \"\ud83d\udc44\", \"\ud83d\udc45\", \"\ud83d\udc46\", \"\ud83d\udc46\ud83c\udffb\", \"\ud83d\udc46\ud83c\udffc\", \"\ud83d\udc46\ud83c\udffd\", \"\ud83d\udc46\ud83c\udffe\", \"\ud83d\udc46\ud83c\udfff\", \"\ud83d\udc47\", \"\ud83d\udc47\ud83c\udffb\", \"\ud83d\udc47\ud83c\udffc\", \"\ud83d\udc47\ud83c\udffd\", \"\ud83d\udc47\ud83c\udffe\", \"\ud83d\udc47\ud83c\udfff\", \"\ud83d\udc48\", \"\ud83d\udc48\ud83c\udffb\", \"\ud83d\udc48\ud83c\udffc\", \"\ud83d\udc48\ud83c\udffd\", \"\ud83d\udc48\ud83c\udffe\", \"\ud83d\udc48\ud83c\udfff\", \"\ud83d\udc49\", \"\ud83d\udc49\ud83c\udffb\", \"\ud83d\udc49\ud83c\udffc\", \"\ud83d\udc49\ud83c\udffd\", \"\ud83d\udc49\ud83c\udffe\", \"\ud83d\udc49\ud83c\udfff\", \"\ud83d\udc4a\", \"\ud83d\udc4a\ud83c\udffb\", \"\ud83d\udc4a\ud83c\udffc\", \"\ud83d\udc4a\ud83c\udffd\", \"\ud83d\udc4a\ud83c\udffe\", \"\ud83d\udc4a\ud83c\udfff\", \"\ud83d\udc4b\", \"\ud83d\udc4b\ud83c\udffb\", \"\ud83d\udc4b\ud83c\udffc\", \"\ud83d\udc4b\ud83c\udffd\", \"\ud83d\udc4b\ud83c\udffe\", \"\ud83d\udc4b\ud83c\udfff\", \"\ud83d\udc4c\", \"\ud83d\udc4c\ud83c\udffb\", \"\ud83d\udc4c\ud83c\udffc\", \"\ud83d\udc4c\ud83c\udffd\", \"\ud83d\udc4c\ud83c\udffe\", \"\ud83d\udc4c\ud83c\udfff\", \"\ud83d\udc4d\", \"\ud83d\udc4d\ud83c\udffb\", \"\ud83d\udc4d\ud83c\udffc\", \"\ud83d\udc4d\ud83c\udffd\", \"\ud83d\udc4d\ud83c\udffe\", \"\ud83d\udc4d\ud83c\udfff\", \"\ud83d\udc4e\", \"\ud83d\udc4e\ud83c\udffb\", \"\ud83d\udc4e\ud83c\udffc\", \"\ud83d\udc4e\ud83c\udffd\", \"\ud83d\udc4e\ud83c\udffe\", \"\ud83d\udc4e\ud83c\udfff\", \"\ud83d\udc4f\", \"\ud83d\udc4f\ud83c\udffb\", \"\ud83d\udc4f\ud83c\udffc\", \"\ud83d\udc4f\ud83c\udffd\", \"\ud83d\udc4f\ud83c\udffe\", \"\ud83d\udc4f\ud83c\udfff\", \"\ud83d\udc50\", \"\ud83d\udc50\ud83c\udffb\", \"\ud83d\udc50\ud83c\udffc\", \"\ud83d\udc50\ud83c\udffd\", \"\ud83d\udc50\ud83c\udffe\", \"\ud83d\udc50\ud83c\udfff\", \"\ud83d\udc51\", \"\ud83d\udc52\", \"\ud83d\udc53\", \"\ud83d\udc54\", \"\ud83d\udc55\", \"\ud83d\udc56\", \"\ud83d\udc57\", \"\ud83d\udc58\", \"\ud83d\udc59\", \"\ud83d\udc5a\", \"\ud83d\udc5b\", \"\ud83d\udc5c\", \"\ud83d\udc5d\", \"\ud83d\udc5e\", \"\ud83d\udc5f\", \"\ud83d\udc60\", \"\ud83d\udc61\", \"\ud83d\udc62\", \"\ud83d\udc63\", \"\ud83d\udc64\", \"\ud83d\udc65\", \"\ud83d\udc66\", \"\ud83d\udc66\ud83c\udffb\", \"\ud83d\udc66\ud83c\udffc\", \"\ud83d\udc66\ud83c\udffd\", \"\ud83d\udc66\ud83c\udffe\", \"\ud83d\udc66\ud83c\udfff\", \"\ud83d\udc67\", \"\ud83d\udc67\ud83c\udffb\", \"\ud83d\udc67\ud83c\udffc\", \"\ud83d\udc67\ud83c\udffd\", \"\ud83d\udc67\ud83c\udffe\", \"\ud83d\udc67\ud83c\udfff\", \"\ud83d\udc68\", \"\ud83d\udc68\u200d\u2695\", \"\ud83d\udc68\u200d\u2695\ufe0f\", \"\ud83d\udc68\u200d\u2696\", \"\ud83d\udc68\u200d\u2696\ufe0f\", \"\ud83d\udc68\u200d\u2708\", \"\ud83d\udc68\u200d\u2708\ufe0f\", \"\ud83d\udc68\u200d\u2764\u200d\ud83d\udc68\", \"\ud83d\udc68\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\", \"\ud83d\udc68\u200d\u2764\ufe0f\u200d\ud83d\udc68\", \"\ud83d\udc68\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\", \"\ud83d\udc68\u200d\ud83c\udf3e\", \"\ud83d\udc68\u200d\ud83c\udf73\", \"\ud83d\udc68\u200d\ud83c\udf7c\", \"\ud83d\udc68\u200d\ud83c\udf93\", \"\ud83d\udc68\u200d\ud83c\udfa4\", \"\ud83d\udc68\u200d\ud83c\udfa8\", \"\ud83d\udc68\u200d\ud83c\udfeb\", \"\ud83d\udc68\u200d\ud83c\udfed\", \"\ud83d\udc68\u200d\ud83d\udc66\", \"\ud83d\udc68\u200d\ud83d\udc66\u200d\ud83d\udc66\", \"\ud83d\udc68\u200d\ud83d\udc67\", \"\ud83d\udc68\u200d\ud83d\udc67\u200d\ud83d\udc66\", \"\ud83d\udc68\u200d\ud83d\udc67\u200d\ud83d\udc67\", \"\ud83d\udc68\u200d\ud83d\udc68\u200d\ud83d\udc66\", \"\ud83d\udc68\u200d\ud83d\udc68\u200d\ud83d\udc66\u200d\ud83d\udc66\", \"\ud83d\udc68\u200d\ud83d\udc68\u200d\ud83d\udc67\", \"\ud83d\udc68\u200d\ud83d\udc68\u200d\ud83d\udc67\u200d\ud83d\udc66\", \"\ud83d\udc68\u200d\ud83d\udc68\u200d\ud83d\udc67\u200d\ud83d\udc67\", \"\ud83d\udc68\u200d\ud83d\udc69\u200d\ud83d\udc66\", \"\ud83d\udc68\u200d\ud83d\udc69\u200d\ud83d\udc66\u200d\ud83d\udc66\", \"\ud83d\udc68\u200d\ud83d\udc69\u200d\ud83d\udc67\", \"\ud83d\udc68\u200d\ud83d\udc69\u200d\ud83d\udc67\u200d\ud83d\udc66\", \"\ud83d\udc68\u200d\ud83d\udc69\u200d\ud83d\udc67\u200d\ud83d\udc67\", \"\ud83d\udc68\u200d\ud83d\udcbb\", \"\ud83d\udc68\u200d\ud83d\udcbc\", \"\ud83d\udc68\u200d\ud83d\udd27\", \"\ud83d\udc68\u200d\ud83d\udd2c\", \"\ud83d\udc68\u200d\ud83d\ude80\", \"\ud83d\udc68\u200d\ud83d\ude92\", \"\ud83d\udc68\u200d\ud83e\uddaf\", \"\ud83d\udc68\u200d\ud83e\uddaf\u200d\u27a1\", \"\ud83d\udc68\u200d\ud83e\uddaf\u200d\u27a1\ufe0f\", \"\ud83d\udc68\u200d\ud83e\uddb0\", \"\ud83d\udc68\u200d\ud83e\uddb1\", \"\ud83d\udc68\u200d\ud83e\uddb2\", \"\ud83d\udc68\u200d\ud83e\uddb3\", \"\ud83d\udc68\u200d\ud83e\uddbc\", \"\ud83d\udc68\u200d\ud83e\uddbc\u200d\u27a1\", \"\ud83d\udc68\u200d\ud83e\uddbc\u200d\u27a1\ufe0f\", \"\ud83d\udc68\u200d\ud83e\uddbd\", \"\ud83d\udc68\u200d\ud83e\uddbd\u200d\u27a1\", \"\ud83d\udc68\u200d\ud83e\uddbd\u200d\u27a1\ufe0f\", \"\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc68\ud83c\udffb\u200d\u2695\", \"\ud83d\udc68\ud83c\udffb\u200d\u2695\ufe0f\", \"\ud83d\udc68\ud83c\udffb\u200d\u2696\", \"\ud83d\udc68\ud83c\udffb\u200d\u2696\ufe0f\", \"\ud83d\udc68\ud83c\udffb\u200d\u2708\", \"\ud83d\udc68\ud83c\udffb\u200d\u2708\ufe0f\", \"\ud83d\udc68\ud83c\udffb\u200d\u2764\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc68\ud83c\udffb\u200d\u2764\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc68\ud83c\udffb\u200d\u2764\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc68\ud83c\udffb\u200d\u2764\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc68\ud83c\udffb\u200d\u2764\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc68\ud83c\udffb\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc68\ud83c\udffb\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc68\ud83c\udffb\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc68\ud83c\udffb\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc68\ud83c\udffb\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc68\ud83c\udffb\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc68\ud83c\udffb\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc68\ud83c\udffb\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc68\ud83c\udffb\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc68\ud83c\udffb\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc68\ud83c\udffb\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc68\ud83c\udffb\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc68\ud83c\udffb\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc68\ud83c\udffb\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc68\ud83c\udffb\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc68\ud83c\udffb\u200d\ud83c\udf3e\", \"\ud83d\udc68\ud83c\udffb\u200d\ud83c\udf73\", \"\ud83d\udc68\ud83c\udffb\u200d\ud83c\udf7c\", \"\ud83d\udc68\ud83c\udffb\u200d\ud83c\udf93\", \"\ud83d\udc68\ud83c\udffb\u200d\ud83c\udfa4\", \"\ud83d\udc68\ud83c\udffb\u200d\ud83c\udfa8\", \"\ud83d\udc68\ud83c\udffb\u200d\ud83c\udfeb\", \"\ud83d\udc68\ud83c\udffb\u200d\ud83c\udfed\", \"\ud83d\udc68\ud83c\udffb\u200d\ud83d\udcbb\", \"\ud83d\udc68\ud83c\udffb\u200d\ud83d\udcbc\", \"\ud83d\udc68\ud83c\udffb\u200d\ud83d\udd27\", \"\ud83d\udc68\ud83c\udffb\u200d\ud83d\udd2c\", \"\ud83d\udc68\ud83c\udffb\u200d\ud83d\ude80\", \"\ud83d\udc68\ud83c\udffb\u200d\ud83d\ude92\", \"\ud83d\udc68\ud83c\udffb\u200d\ud83e\udd1d\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc68\ud83c\udffb\u200d\ud83e\udd1d\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc68\ud83c\udffb\u200d\ud83e\udd1d\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc68\ud83c\udffb\u200d\ud83e\udd1d\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc68\ud83c\udffb\u200d\ud83e\uddaf\", \"\ud83d\udc68\ud83c\udffb\u200d\ud83e\uddaf\u200d\u27a1\", \"\ud83d\udc68\ud83c\udffb\u200d\ud83e\uddaf\u200d\u27a1\ufe0f\", \"\ud83d\udc68\ud83c\udffb\u200d\ud83e\uddb0\", \"\ud83d\udc68\ud83c\udffb\u200d\ud83e\uddb1\", \"\ud83d\udc68\ud83c\udffb\u200d\ud83e\uddb2\", \"\ud83d\udc68\ud83c\udffb\u200d\ud83e\uddb3\", \"\ud83d\udc68\ud83c\udffb\u200d\ud83e\uddbc\", \"\ud83d\udc68\ud83c\udffb\u200d\ud83e\uddbc\u200d\u27a1\", \"\ud83d\udc68\ud83c\udffb\u200d\ud83e\uddbc\u200d\u27a1\ufe0f\", \"\ud83d\udc68\ud83c\udffb\u200d\ud83e\uddbd\", \"\ud83d\udc68\ud83c\udffb\u200d\ud83e\uddbd\u200d\u27a1\", \"\ud83d\udc68\ud83c\udffb\u200d\ud83e\uddbd\u200d\u27a1\ufe0f\", \"\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc68\ud83c\udffc\u200d\u2695\", \"\ud83d\udc68\ud83c\udffc\u200d\u2695\ufe0f\", \"\ud83d\udc68\ud83c\udffc\u200d\u2696\", \"\ud83d\udc68\ud83c\udffc\u200d\u2696\ufe0f\", \"\ud83d\udc68\ud83c\udffc\u200d\u2708\", \"\ud83d\udc68\ud83c\udffc\u200d\u2708\ufe0f\", \"\ud83d\udc68\ud83c\udffc\u200d\u2764\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc68\ud83c\udffc\u200d\u2764\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc68\ud83c\udffc\u200d\u2764\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc68\ud83c\udffc\u200d\u2764\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc68\ud83c\udffc\u200d\u2764\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc68\ud83c\udffc\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc68\ud83c\udffc\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc68\ud83c\udffc\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc68\ud83c\udffc\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc68\ud83c\udffc\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc68\ud83c\udffc\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc68\ud83c\udffc\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc68\ud83c\udffc\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc68\ud83c\udffc\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc68\ud83c\udffc\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc68\ud83c\udffc\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc68\ud83c\udffc\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc68\ud83c\udffc\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc68\ud83c\udffc\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc68\ud83c\udffc\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc68\ud83c\udffc\u200d\ud83c\udf3e\", \"\ud83d\udc68\ud83c\udffc\u200d\ud83c\udf73\", \"\ud83d\udc68\ud83c\udffc\u200d\ud83c\udf7c\", \"\ud83d\udc68\ud83c\udffc\u200d\ud83c\udf93\", \"\ud83d\udc68\ud83c\udffc\u200d\ud83c\udfa4\", \"\ud83d\udc68\ud83c\udffc\u200d\ud83c\udfa8\", \"\ud83d\udc68\ud83c\udffc\u200d\ud83c\udfeb\", \"\ud83d\udc68\ud83c\udffc\u200d\ud83c\udfed\", \"\ud83d\udc68\ud83c\udffc\u200d\ud83d\udcbb\", \"\ud83d\udc68\ud83c\udffc\u200d\ud83d\udcbc\", \"\ud83d\udc68\ud83c\udffc\u200d\ud83d\udd27\", \"\ud83d\udc68\ud83c\udffc\u200d\ud83d\udd2c\", \"\ud83d\udc68\ud83c\udffc\u200d\ud83d\ude80\", \"\ud83d\udc68\ud83c\udffc\u200d\ud83d\ude92\", \"\ud83d\udc68\ud83c\udffc\u200d\ud83e\udd1d\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc68\ud83c\udffc\u200d\ud83e\udd1d\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc68\ud83c\udffc\u200d\ud83e\udd1d\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc68\ud83c\udffc\u200d\ud83e\udd1d\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc68\ud83c\udffc\u200d\ud83e\uddaf\", \"\ud83d\udc68\ud83c\udffc\u200d\ud83e\uddaf\u200d\u27a1\", \"\ud83d\udc68\ud83c\udffc\u200d\ud83e\uddaf\u200d\u27a1\ufe0f\", \"\ud83d\udc68\ud83c\udffc\u200d\ud83e\uddb0\", \"\ud83d\udc68\ud83c\udffc\u200d\ud83e\uddb1\", \"\ud83d\udc68\ud83c\udffc\u200d\ud83e\uddb2\", \"\ud83d\udc68\ud83c\udffc\u200d\ud83e\uddb3\", \"\ud83d\udc68\ud83c\udffc\u200d\ud83e\uddbc\", \"\ud83d\udc68\ud83c\udffc\u200d\ud83e\uddbc\u200d\u27a1\", \"\ud83d\udc68\ud83c\udffc\u200d\ud83e\uddbc\u200d\u27a1\ufe0f\", \"\ud83d\udc68\ud83c\udffc\u200d\ud83e\uddbd\", \"\ud83d\udc68\ud83c\udffc\u200d\ud83e\uddbd\u200d\u27a1\", \"\ud83d\udc68\ud83c\udffc\u200d\ud83e\uddbd\u200d\u27a1\ufe0f\", \"\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc68\ud83c\udffd\u200d\u2695\", \"\ud83d\udc68\ud83c\udffd\u200d\u2695\ufe0f\", \"\ud83d\udc68\ud83c\udffd\u200d\u2696\", \"\ud83d\udc68\ud83c\udffd\u200d\u2696\ufe0f\", \"\ud83d\udc68\ud83c\udffd\u200d\u2708\", \"\ud83d\udc68\ud83c\udffd\u200d\u2708\ufe0f\", \"\ud83d\udc68\ud83c\udffd\u200d\u2764\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc68\ud83c\udffd\u200d\u2764\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc68\ud83c\udffd\u200d\u2764\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc68\ud83c\udffd\u200d\u2764\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc68\ud83c\udffd\u200d\u2764\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc68\ud83c\udffd\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc68\ud83c\udffd\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc68\ud83c\udffd\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc68\ud83c\udffd\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc68\ud83c\udffd\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc68\ud83c\udffd\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc68\ud83c\udffd\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc68\ud83c\udffd\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc68\ud83c\udffd\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc68\ud83c\udffd\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc68\ud83c\udffd\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc68\ud83c\udffd\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc68\ud83c\udffd\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc68\ud83c\udffd\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc68\ud83c\udffd\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc68\ud83c\udffd\u200d\ud83c\udf3e\", \"\ud83d\udc68\ud83c\udffd\u200d\ud83c\udf73\", \"\ud83d\udc68\ud83c\udffd\u200d\ud83c\udf7c\", \"\ud83d\udc68\ud83c\udffd\u200d\ud83c\udf93\", \"\ud83d\udc68\ud83c\udffd\u200d\ud83c\udfa4\", \"\ud83d\udc68\ud83c\udffd\u200d\ud83c\udfa8\", \"\ud83d\udc68\ud83c\udffd\u200d\ud83c\udfeb\", \"\ud83d\udc68\ud83c\udffd\u200d\ud83c\udfed\", \"\ud83d\udc68\ud83c\udffd\u200d\ud83d\udcbb\", \"\ud83d\udc68\ud83c\udffd\u200d\ud83d\udcbc\", \"\ud83d\udc68\ud83c\udffd\u200d\ud83d\udd27\", \"\ud83d\udc68\ud83c\udffd\u200d\ud83d\udd2c\", \"\ud83d\udc68\ud83c\udffd\u200d\ud83d\ude80\", \"\ud83d\udc68\ud83c\udffd\u200d\ud83d\ude92\", \"\ud83d\udc68\ud83c\udffd\u200d\ud83e\udd1d\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc68\ud83c\udffd\u200d\ud83e\udd1d\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc68\ud83c\udffd\u200d\ud83e\udd1d\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc68\ud83c\udffd\u200d\ud83e\udd1d\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc68\ud83c\udffd\u200d\ud83e\uddaf\", \"\ud83d\udc68\ud83c\udffd\u200d\ud83e\uddaf\u200d\u27a1\", \"\ud83d\udc68\ud83c\udffd\u200d\ud83e\uddaf\u200d\u27a1\ufe0f\", \"\ud83d\udc68\ud83c\udffd\u200d\ud83e\uddb0\", \"\ud83d\udc68\ud83c\udffd\u200d\ud83e\uddb1\", \"\ud83d\udc68\ud83c\udffd\u200d\ud83e\uddb2\", \"\ud83d\udc68\ud83c\udffd\u200d\ud83e\uddb3\", \"\ud83d\udc68\ud83c\udffd\u200d\ud83e\uddbc\", \"\ud83d\udc68\ud83c\udffd\u200d\ud83e\uddbc\u200d\u27a1\", \"\ud83d\udc68\ud83c\udffd\u200d\ud83e\uddbc\u200d\u27a1\ufe0f\", \"\ud83d\udc68\ud83c\udffd\u200d\ud83e\uddbd\", \"\ud83d\udc68\ud83c\udffd\u200d\ud83e\uddbd\u200d\u27a1\", \"\ud83d\udc68\ud83c\udffd\u200d\ud83e\uddbd\u200d\u27a1\ufe0f\", \"\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc68\ud83c\udffe\u200d\u2695\", \"\ud83d\udc68\ud83c\udffe\u200d\u2695\ufe0f\", \"\ud83d\udc68\ud83c\udffe\u200d\u2696\", \"\ud83d\udc68\ud83c\udffe\u200d\u2696\ufe0f\", \"\ud83d\udc68\ud83c\udffe\u200d\u2708\", \"\ud83d\udc68\ud83c\udffe\u200d\u2708\ufe0f\", \"\ud83d\udc68\ud83c\udffe\u200d\u2764\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc68\ud83c\udffe\u200d\u2764\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc68\ud83c\udffe\u200d\u2764\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc68\ud83c\udffe\u200d\u2764\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc68\ud83c\udffe\u200d\u2764\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc68\ud83c\udffe\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc68\ud83c\udffe\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc68\ud83c\udffe\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc68\ud83c\udffe\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc68\ud83c\udffe\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc68\ud83c\udffe\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc68\ud83c\udffe\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc68\ud83c\udffe\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc68\ud83c\udffe\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc68\ud83c\udffe\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc68\ud83c\udffe\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc68\ud83c\udffe\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc68\ud83c\udffe\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc68\ud83c\udffe\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc68\ud83c\udffe\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc68\ud83c\udffe\u200d\ud83c\udf3e\", \"\ud83d\udc68\ud83c\udffe\u200d\ud83c\udf73\", \"\ud83d\udc68\ud83c\udffe\u200d\ud83c\udf7c\", \"\ud83d\udc68\ud83c\udffe\u200d\ud83c\udf93\", \"\ud83d\udc68\ud83c\udffe\u200d\ud83c\udfa4\", \"\ud83d\udc68\ud83c\udffe\u200d\ud83c\udfa8\", \"\ud83d\udc68\ud83c\udffe\u200d\ud83c\udfeb\", \"\ud83d\udc68\ud83c\udffe\u200d\ud83c\udfed\", \"\ud83d\udc68\ud83c\udffe\u200d\ud83d\udcbb\", \"\ud83d\udc68\ud83c\udffe\u200d\ud83d\udcbc\", \"\ud83d\udc68\ud83c\udffe\u200d\ud83d\udd27\", \"\ud83d\udc68\ud83c\udffe\u200d\ud83d\udd2c\", \"\ud83d\udc68\ud83c\udffe\u200d\ud83d\ude80\", \"\ud83d\udc68\ud83c\udffe\u200d\ud83d\ude92\", \"\ud83d\udc68\ud83c\udffe\u200d\ud83e\udd1d\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc68\ud83c\udffe\u200d\ud83e\udd1d\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc68\ud83c\udffe\u200d\ud83e\udd1d\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc68\ud83c\udffe\u200d\ud83e\udd1d\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc68\ud83c\udffe\u200d\ud83e\uddaf\", \"\ud83d\udc68\ud83c\udffe\u200d\ud83e\uddaf\u200d\u27a1\", \"\ud83d\udc68\ud83c\udffe\u200d\ud83e\uddaf\u200d\u27a1\ufe0f\", \"\ud83d\udc68\ud83c\udffe\u200d\ud83e\uddb0\", \"\ud83d\udc68\ud83c\udffe\u200d\ud83e\uddb1\", \"\ud83d\udc68\ud83c\udffe\u200d\ud83e\uddb2\", \"\ud83d\udc68\ud83c\udffe\u200d\ud83e\uddb3\", \"\ud83d\udc68\ud83c\udffe\u200d\ud83e\uddbc\", \"\ud83d\udc68\ud83c\udffe\u200d\ud83e\uddbc\u200d\u27a1\", \"\ud83d\udc68\ud83c\udffe\u200d\ud83e\uddbc\u200d\u27a1\ufe0f\", \"\ud83d\udc68\ud83c\udffe\u200d\ud83e\uddbd\", \"\ud83d\udc68\ud83c\udffe\u200d\ud83e\uddbd\u200d\u27a1\", \"\ud83d\udc68\ud83c\udffe\u200d\ud83e\uddbd\u200d\u27a1\ufe0f\", \"\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc68\ud83c\udfff\u200d\u2695\", \"\ud83d\udc68\ud83c\udfff\u200d\u2695\ufe0f\", \"\ud83d\udc68\ud83c\udfff\u200d\u2696\", \"\ud83d\udc68\ud83c\udfff\u200d\u2696\ufe0f\", \"\ud83d\udc68\ud83c\udfff\u200d\u2708\", \"\ud83d\udc68\ud83c\udfff\u200d\u2708\ufe0f\", \"\ud83d\udc68\ud83c\udfff\u200d\u2764\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc68\ud83c\udfff\u200d\u2764\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc68\ud83c\udfff\u200d\u2764\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc68\ud83c\udfff\u200d\u2764\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc68\ud83c\udfff\u200d\u2764\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc68\ud83c\udfff\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc68\ud83c\udfff\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc68\ud83c\udfff\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc68\ud83c\udfff\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc68\ud83c\udfff\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc68\ud83c\udfff\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc68\ud83c\udfff\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc68\ud83c\udfff\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc68\ud83c\udfff\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc68\ud83c\udfff\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc68\ud83c\udfff\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc68\ud83c\udfff\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc68\ud83c\udfff\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc68\ud83c\udfff\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc68\ud83c\udfff\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc68\ud83c\udfff\u200d\ud83c\udf3e\", \"\ud83d\udc68\ud83c\udfff\u200d\ud83c\udf73\", \"\ud83d\udc68\ud83c\udfff\u200d\ud83c\udf7c\", \"\ud83d\udc68\ud83c\udfff\u200d\ud83c\udf93\", \"\ud83d\udc68\ud83c\udfff\u200d\ud83c\udfa4\", \"\ud83d\udc68\ud83c\udfff\u200d\ud83c\udfa8\", \"\ud83d\udc68\ud83c\udfff\u200d\ud83c\udfeb\", \"\ud83d\udc68\ud83c\udfff\u200d\ud83c\udfed\", \"\ud83d\udc68\ud83c\udfff\u200d\ud83d\udcbb\", \"\ud83d\udc68\ud83c\udfff\u200d\ud83d\udcbc\", \"\ud83d\udc68\ud83c\udfff\u200d\ud83d\udd27\", \"\ud83d\udc68\ud83c\udfff\u200d\ud83d\udd2c\", \"\ud83d\udc68\ud83c\udfff\u200d\ud83d\ude80\", \"\ud83d\udc68\ud83c\udfff\u200d\ud83d\ude92\", \"\ud83d\udc68\ud83c\udfff\u200d\ud83e\udd1d\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc68\ud83c\udfff\u200d\ud83e\udd1d\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc68\ud83c\udfff\u200d\ud83e\udd1d\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc68\ud83c\udfff\u200d\ud83e\udd1d\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc68\ud83c\udfff\u200d\ud83e\uddaf\", \"\ud83d\udc68\ud83c\udfff\u200d\ud83e\uddaf\u200d\u27a1\", \"\ud83d\udc68\ud83c\udfff\u200d\ud83e\uddaf\u200d\u27a1\ufe0f\", \"\ud83d\udc68\ud83c\udfff\u200d\ud83e\uddb0\", \"\ud83d\udc68\ud83c\udfff\u200d\ud83e\uddb1\", \"\ud83d\udc68\ud83c\udfff\u200d\ud83e\uddb2\", \"\ud83d\udc68\ud83c\udfff\u200d\ud83e\uddb3\", \"\ud83d\udc68\ud83c\udfff\u200d\ud83e\uddbc\", \"\ud83d\udc68\ud83c\udfff\u200d\ud83e\uddbc\u200d\u27a1\", \"\ud83d\udc68\ud83c\udfff\u200d\ud83e\uddbc\u200d\u27a1\ufe0f\", \"\ud83d\udc68\ud83c\udfff\u200d\ud83e\uddbd\", \"\ud83d\udc68\ud83c\udfff\u200d\ud83e\uddbd\u200d\u27a1\", \"\ud83d\udc68\ud83c\udfff\u200d\ud83e\uddbd\u200d\u27a1\ufe0f\", \"\ud83d\udc69\", \"\ud83d\udc69\u200d\u2695\", \"\ud83d\udc69\u200d\u2695\ufe0f\", \"\ud83d\udc69\u200d\u2696\", \"\ud83d\udc69\u200d\u2696\ufe0f\", \"\ud83d\udc69\u200d\u2708\", \"\ud83d\udc69\u200d\u2708\ufe0f\", \"\ud83d\udc69\u200d\u2764\u200d\ud83d\udc68\", \"\ud83d\udc69\u200d\u2764\u200d\ud83d\udc69\", \"\ud83d\udc69\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\", \"\ud83d\udc69\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc69\", \"\ud83d\udc69\u200d\u2764\ufe0f\u200d\ud83d\udc68\", \"\ud83d\udc69\u200d\u2764\ufe0f\u200d\ud83d\udc69\", \"\ud83d\udc69\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\", \"\ud83d\udc69\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc69\", \"\ud83d\udc69\u200d\ud83c\udf3e\", \"\ud83d\udc69\u200d\ud83c\udf73\", \"\ud83d\udc69\u200d\ud83c\udf7c\", \"\ud83d\udc69\u200d\ud83c\udf93\", \"\ud83d\udc69\u200d\ud83c\udfa4\", \"\ud83d\udc69\u200d\ud83c\udfa8\", \"\ud83d\udc69\u200d\ud83c\udfeb\", \"\ud83d\udc69\u200d\ud83c\udfed\", \"\ud83d\udc69\u200d\ud83d\udc66\", \"\ud83d\udc69\u200d\ud83d\udc66\u200d\ud83d\udc66\", \"\ud83d\udc69\u200d\ud83d\udc67\", \"\ud83d\udc69\u200d\ud83d\udc67\u200d\ud83d\udc66\", \"\ud83d\udc69\u200d\ud83d\udc67\u200d\ud83d\udc67\", \"\ud83d\udc69\u200d\ud83d\udc69\u200d\ud83d\udc66\", \"\ud83d\udc69\u200d\ud83d\udc69\u200d\ud83d\udc66\u200d\ud83d\udc66\", \"\ud83d\udc69\u200d\ud83d\udc69\u200d\ud83d\udc67\", \"\ud83d\udc69\u200d\ud83d\udc69\u200d\ud83d\udc67\u200d\ud83d\udc66\", \"\ud83d\udc69\u200d\ud83d\udc69\u200d\ud83d\udc67\u200d\ud83d\udc67\", \"\ud83d\udc69\u200d\ud83d\udcbb\", \"\ud83d\udc69\u200d\ud83d\udcbc\", \"\ud83d\udc69\u200d\ud83d\udd27\", \"\ud83d\udc69\u200d\ud83d\udd2c\", \"\ud83d\udc69\u200d\ud83d\ude80\", \"\ud83d\udc69\u200d\ud83d\ude92\", \"\ud83d\udc69\u200d\ud83e\uddaf\", \"\ud83d\udc69\u200d\ud83e\uddaf\u200d\u27a1\", \"\ud83d\udc69\u200d\ud83e\uddaf\u200d\u27a1\ufe0f\", \"\ud83d\udc69\u200d\ud83e\uddb0\", \"\ud83d\udc69\u200d\ud83e\uddb1\", \"\ud83d\udc69\u200d\ud83e\uddb2\", \"\ud83d\udc69\u200d\ud83e\uddb3\", \"\ud83d\udc69\u200d\ud83e\uddbc\", \"\ud83d\udc69\u200d\ud83e\uddbc\u200d\u27a1\", \"\ud83d\udc69\u200d\ud83e\uddbc\u200d\u27a1\ufe0f\", \"\ud83d\udc69\u200d\ud83e\uddbd\", \"\ud83d\udc69\u200d\ud83e\uddbd\u200d\u27a1\", \"\ud83d\udc69\u200d\ud83e\uddbd\u200d\u27a1\ufe0f\", \"\ud83d\udc69\ud83c\udffb\", \"\ud83d\udc69\ud83c\udffb\u200d\u2695\", \"\ud83d\udc69\ud83c\udffb\u200d\u2695\ufe0f\", \"\ud83d\udc69\ud83c\udffb\u200d\u2696\", \"\ud83d\udc69\ud83c\udffb\u200d\u2696\ufe0f\", \"\ud83d\udc69\ud83c\udffb\u200d\u2708\", \"\ud83d\udc69\ud83c\udffb\u200d\u2708\ufe0f\", \"\ud83d\udc69\ud83c\udffb\u200d\u2764\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc69\ud83c\udffb\u200d\u2764\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc69\ud83c\udffb\u200d\u2764\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc69\ud83c\udffb\u200d\u2764\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc69\ud83c\udffb\u200d\u2764\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc69\ud83c\udffb\u200d\u2764\u200d\ud83d\udc69\ud83c\udffb\", \"\ud83d\udc69\ud83c\udffb\u200d\u2764\u200d\ud83d\udc69\ud83c\udffc\", \"\ud83d\udc69\ud83c\udffb\u200d\u2764\u200d\ud83d\udc69\ud83c\udffd\", \"\ud83d\udc69\ud83c\udffb\u200d\u2764\u200d\ud83d\udc69\ud83c\udffe\", \"\ud83d\udc69\ud83c\udffb\u200d\u2764\u200d\ud83d\udc69\ud83c\udfff\", \"\ud83d\udc69\ud83c\udffb\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc69\ud83c\udffb\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc69\ud83c\udffb\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc69\ud83c\udffb\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc69\ud83c\udffb\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc69\ud83c\udffb\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udffb\", \"\ud83d\udc69\ud83c\udffb\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udffc\", \"\ud83d\udc69\ud83c\udffb\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udffd\", \"\ud83d\udc69\ud83c\udffb\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udffe\", \"\ud83d\udc69\ud83c\udffb\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udfff\", \"\ud83d\udc69\ud83c\udffb\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc69\ud83c\udffb\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc69\ud83c\udffb\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc69\ud83c\udffb\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc69\ud83c\udffb\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc69\ud83c\udffb\u200d\u2764\ufe0f\u200d\ud83d\udc69\ud83c\udffb\", \"\ud83d\udc69\ud83c\udffb\u200d\u2764\ufe0f\u200d\ud83d\udc69\ud83c\udffc\", \"\ud83d\udc69\ud83c\udffb\u200d\u2764\ufe0f\u200d\ud83d\udc69\ud83c\udffd\", \"\ud83d\udc69\ud83c\udffb\u200d\u2764\ufe0f\u200d\ud83d\udc69\ud83c\udffe\", \"\ud83d\udc69\ud83c\udffb\u200d\u2764\ufe0f\u200d\ud83d\udc69\ud83c\udfff\", \"\ud83d\udc69\ud83c\udffb\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc69\ud83c\udffb\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc69\ud83c\udffb\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc69\ud83c\udffb\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc69\ud83c\udffb\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc69\ud83c\udffb\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udffb\", \"\ud83d\udc69\ud83c\udffb\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udffc\", \"\ud83d\udc69\ud83c\udffb\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udffd\", \"\ud83d\udc69\ud83c\udffb\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udffe\", \"\ud83d\udc69\ud83c\udffb\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udfff\", \"\ud83d\udc69\ud83c\udffb\u200d\ud83c\udf3e\", \"\ud83d\udc69\ud83c\udffb\u200d\ud83c\udf73\", \"\ud83d\udc69\ud83c\udffb\u200d\ud83c\udf7c\", \"\ud83d\udc69\ud83c\udffb\u200d\ud83c\udf93\", \"\ud83d\udc69\ud83c\udffb\u200d\ud83c\udfa4\", \"\ud83d\udc69\ud83c\udffb\u200d\ud83c\udfa8\", \"\ud83d\udc69\ud83c\udffb\u200d\ud83c\udfeb\", \"\ud83d\udc69\ud83c\udffb\u200d\ud83c\udfed\", \"\ud83d\udc69\ud83c\udffb\u200d\ud83d\udcbb\", \"\ud83d\udc69\ud83c\udffb\u200d\ud83d\udcbc\", \"\ud83d\udc69\ud83c\udffb\u200d\ud83d\udd27\", \"\ud83d\udc69\ud83c\udffb\u200d\ud83d\udd2c\", \"\ud83d\udc69\ud83c\udffb\u200d\ud83d\ude80\", \"\ud83d\udc69\ud83c\udffb\u200d\ud83d\ude92\", \"\ud83d\udc69\ud83c\udffb\u200d\ud83e\udd1d\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc69\ud83c\udffb\u200d\ud83e\udd1d\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc69\ud83c\udffb\u200d\ud83e\udd1d\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc69\ud83c\udffb\u200d\ud83e\udd1d\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc69\ud83c\udffb\u200d\ud83e\udd1d\u200d\ud83d\udc69\ud83c\udffc\", \"\ud83d\udc69\ud83c\udffb\u200d\ud83e\udd1d\u200d\ud83d\udc69\ud83c\udffd\", \"\ud83d\udc69\ud83c\udffb\u200d\ud83e\udd1d\u200d\ud83d\udc69\ud83c\udffe\", \"\ud83d\udc69\ud83c\udffb\u200d\ud83e\udd1d\u200d\ud83d\udc69\ud83c\udfff\", \"\ud83d\udc69\ud83c\udffb\u200d\ud83e\uddaf\", \"\ud83d\udc69\ud83c\udffb\u200d\ud83e\uddaf\u200d\u27a1\", \"\ud83d\udc69\ud83c\udffb\u200d\ud83e\uddaf\u200d\u27a1\ufe0f\", \"\ud83d\udc69\ud83c\udffb\u200d\ud83e\uddb0\", \"\ud83d\udc69\ud83c\udffb\u200d\ud83e\uddb1\", \"\ud83d\udc69\ud83c\udffb\u200d\ud83e\uddb2\", \"\ud83d\udc69\ud83c\udffb\u200d\ud83e\uddb3\", \"\ud83d\udc69\ud83c\udffb\u200d\ud83e\uddbc\", \"\ud83d\udc69\ud83c\udffb\u200d\ud83e\uddbc\u200d\u27a1\", \"\ud83d\udc69\ud83c\udffb\u200d\ud83e\uddbc\u200d\u27a1\ufe0f\", \"\ud83d\udc69\ud83c\udffb\u200d\ud83e\uddbd\", \"\ud83d\udc69\ud83c\udffb\u200d\ud83e\uddbd\u200d\u27a1\", \"\ud83d\udc69\ud83c\udffb\u200d\ud83e\uddbd\u200d\u27a1\ufe0f\", \"\ud83d\udc69\ud83c\udffc\", \"\ud83d\udc69\ud83c\udffc\u200d\u2695\", \"\ud83d\udc69\ud83c\udffc\u200d\u2695\ufe0f\", \"\ud83d\udc69\ud83c\udffc\u200d\u2696\", \"\ud83d\udc69\ud83c\udffc\u200d\u2696\ufe0f\", \"\ud83d\udc69\ud83c\udffc\u200d\u2708\", \"\ud83d\udc69\ud83c\udffc\u200d\u2708\ufe0f\", \"\ud83d\udc69\ud83c\udffc\u200d\u2764\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc69\ud83c\udffc\u200d\u2764\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc69\ud83c\udffc\u200d\u2764\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc69\ud83c\udffc\u200d\u2764\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc69\ud83c\udffc\u200d\u2764\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc69\ud83c\udffc\u200d\u2764\u200d\ud83d\udc69\ud83c\udffb\", \"\ud83d\udc69\ud83c\udffc\u200d\u2764\u200d\ud83d\udc69\ud83c\udffc\", \"\ud83d\udc69\ud83c\udffc\u200d\u2764\u200d\ud83d\udc69\ud83c\udffd\", \"\ud83d\udc69\ud83c\udffc\u200d\u2764\u200d\ud83d\udc69\ud83c\udffe\", \"\ud83d\udc69\ud83c\udffc\u200d\u2764\u200d\ud83d\udc69\ud83c\udfff\", \"\ud83d\udc69\ud83c\udffc\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc69\ud83c\udffc\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc69\ud83c\udffc\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc69\ud83c\udffc\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc69\ud83c\udffc\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc69\ud83c\udffc\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udffb\", \"\ud83d\udc69\ud83c\udffc\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udffc\", \"\ud83d\udc69\ud83c\udffc\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udffd\", \"\ud83d\udc69\ud83c\udffc\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udffe\", \"\ud83d\udc69\ud83c\udffc\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udfff\", \"\ud83d\udc69\ud83c\udffc\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc69\ud83c\udffc\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc69\ud83c\udffc\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc69\ud83c\udffc\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc69\ud83c\udffc\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc69\ud83c\udffc\u200d\u2764\ufe0f\u200d\ud83d\udc69\ud83c\udffb\", \"\ud83d\udc69\ud83c\udffc\u200d\u2764\ufe0f\u200d\ud83d\udc69\ud83c\udffc\", \"\ud83d\udc69\ud83c\udffc\u200d\u2764\ufe0f\u200d\ud83d\udc69\ud83c\udffd\", \"\ud83d\udc69\ud83c\udffc\u200d\u2764\ufe0f\u200d\ud83d\udc69\ud83c\udffe\", \"\ud83d\udc69\ud83c\udffc\u200d\u2764\ufe0f\u200d\ud83d\udc69\ud83c\udfff\", \"\ud83d\udc69\ud83c\udffc\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc69\ud83c\udffc\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc69\ud83c\udffc\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc69\ud83c\udffc\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc69\ud83c\udffc\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc69\ud83c\udffc\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udffb\", \"\ud83d\udc69\ud83c\udffc\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udffc\", \"\ud83d\udc69\ud83c\udffc\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udffd\", \"\ud83d\udc69\ud83c\udffc\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udffe\", \"\ud83d\udc69\ud83c\udffc\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udfff\", \"\ud83d\udc69\ud83c\udffc\u200d\ud83c\udf3e\", \"\ud83d\udc69\ud83c\udffc\u200d\ud83c\udf73\", \"\ud83d\udc69\ud83c\udffc\u200d\ud83c\udf7c\", \"\ud83d\udc69\ud83c\udffc\u200d\ud83c\udf93\", \"\ud83d\udc69\ud83c\udffc\u200d\ud83c\udfa4\", \"\ud83d\udc69\ud83c\udffc\u200d\ud83c\udfa8\", \"\ud83d\udc69\ud83c\udffc\u200d\ud83c\udfeb\", \"\ud83d\udc69\ud83c\udffc\u200d\ud83c\udfed\", \"\ud83d\udc69\ud83c\udffc\u200d\ud83d\udcbb\", \"\ud83d\udc69\ud83c\udffc\u200d\ud83d\udcbc\", \"\ud83d\udc69\ud83c\udffc\u200d\ud83d\udd27\", \"\ud83d\udc69\ud83c\udffc\u200d\ud83d\udd2c\", \"\ud83d\udc69\ud83c\udffc\u200d\ud83d\ude80\", \"\ud83d\udc69\ud83c\udffc\u200d\ud83d\ude92\", \"\ud83d\udc69\ud83c\udffc\u200d\ud83e\udd1d\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc69\ud83c\udffc\u200d\ud83e\udd1d\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc69\ud83c\udffc\u200d\ud83e\udd1d\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc69\ud83c\udffc\u200d\ud83e\udd1d\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc69\ud83c\udffc\u200d\ud83e\udd1d\u200d\ud83d\udc69\ud83c\udffb\", \"\ud83d\udc69\ud83c\udffc\u200d\ud83e\udd1d\u200d\ud83d\udc69\ud83c\udffd\", \"\ud83d\udc69\ud83c\udffc\u200d\ud83e\udd1d\u200d\ud83d\udc69\ud83c\udffe\", \"\ud83d\udc69\ud83c\udffc\u200d\ud83e\udd1d\u200d\ud83d\udc69\ud83c\udfff\", \"\ud83d\udc69\ud83c\udffc\u200d\ud83e\uddaf\", \"\ud83d\udc69\ud83c\udffc\u200d\ud83e\uddaf\u200d\u27a1\", \"\ud83d\udc69\ud83c\udffc\u200d\ud83e\uddaf\u200d\u27a1\ufe0f\", \"\ud83d\udc69\ud83c\udffc\u200d\ud83e\uddb0\", \"\ud83d\udc69\ud83c\udffc\u200d\ud83e\uddb1\", \"\ud83d\udc69\ud83c\udffc\u200d\ud83e\uddb2\", \"\ud83d\udc69\ud83c\udffc\u200d\ud83e\uddb3\", \"\ud83d\udc69\ud83c\udffc\u200d\ud83e\uddbc\", \"\ud83d\udc69\ud83c\udffc\u200d\ud83e\uddbc\u200d\u27a1\", \"\ud83d\udc69\ud83c\udffc\u200d\ud83e\uddbc\u200d\u27a1\ufe0f\", \"\ud83d\udc69\ud83c\udffc\u200d\ud83e\uddbd\", \"\ud83d\udc69\ud83c\udffc\u200d\ud83e\uddbd\u200d\u27a1\", \"\ud83d\udc69\ud83c\udffc\u200d\ud83e\uddbd\u200d\u27a1\ufe0f\", \"\ud83d\udc69\ud83c\udffd\", \"\ud83d\udc69\ud83c\udffd\u200d\u2695\", \"\ud83d\udc69\ud83c\udffd\u200d\u2695\ufe0f\", \"\ud83d\udc69\ud83c\udffd\u200d\u2696\", \"\ud83d\udc69\ud83c\udffd\u200d\u2696\ufe0f\", \"\ud83d\udc69\ud83c\udffd\u200d\u2708\", \"\ud83d\udc69\ud83c\udffd\u200d\u2708\ufe0f\", \"\ud83d\udc69\ud83c\udffd\u200d\u2764\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc69\ud83c\udffd\u200d\u2764\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc69\ud83c\udffd\u200d\u2764\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc69\ud83c\udffd\u200d\u2764\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc69\ud83c\udffd\u200d\u2764\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc69\ud83c\udffd\u200d\u2764\u200d\ud83d\udc69\ud83c\udffb\", \"\ud83d\udc69\ud83c\udffd\u200d\u2764\u200d\ud83d\udc69\ud83c\udffc\", \"\ud83d\udc69\ud83c\udffd\u200d\u2764\u200d\ud83d\udc69\ud83c\udffd\", \"\ud83d\udc69\ud83c\udffd\u200d\u2764\u200d\ud83d\udc69\ud83c\udffe\", \"\ud83d\udc69\ud83c\udffd\u200d\u2764\u200d\ud83d\udc69\ud83c\udfff\", \"\ud83d\udc69\ud83c\udffd\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc69\ud83c\udffd\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc69\ud83c\udffd\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc69\ud83c\udffd\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc69\ud83c\udffd\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc69\ud83c\udffd\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udffb\", \"\ud83d\udc69\ud83c\udffd\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udffc\", \"\ud83d\udc69\ud83c\udffd\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udffd\", \"\ud83d\udc69\ud83c\udffd\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udffe\", \"\ud83d\udc69\ud83c\udffd\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udfff\", \"\ud83d\udc69\ud83c\udffd\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc69\ud83c\udffd\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc69\ud83c\udffd\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc69\ud83c\udffd\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc69\ud83c\udffd\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc69\ud83c\udffd\u200d\u2764\ufe0f\u200d\ud83d\udc69\ud83c\udffb\", \"\ud83d\udc69\ud83c\udffd\u200d\u2764\ufe0f\u200d\ud83d\udc69\ud83c\udffc\", \"\ud83d\udc69\ud83c\udffd\u200d\u2764\ufe0f\u200d\ud83d\udc69\ud83c\udffd\", \"\ud83d\udc69\ud83c\udffd\u200d\u2764\ufe0f\u200d\ud83d\udc69\ud83c\udffe\", \"\ud83d\udc69\ud83c\udffd\u200d\u2764\ufe0f\u200d\ud83d\udc69\ud83c\udfff\", \"\ud83d\udc69\ud83c\udffd\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc69\ud83c\udffd\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc69\ud83c\udffd\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc69\ud83c\udffd\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc69\ud83c\udffd\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc69\ud83c\udffd\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udffb\", \"\ud83d\udc69\ud83c\udffd\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udffc\", \"\ud83d\udc69\ud83c\udffd\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udffd\", \"\ud83d\udc69\ud83c\udffd\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udffe\", \"\ud83d\udc69\ud83c\udffd\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udfff\", \"\ud83d\udc69\ud83c\udffd\u200d\ud83c\udf3e\", \"\ud83d\udc69\ud83c\udffd\u200d\ud83c\udf73\", \"\ud83d\udc69\ud83c\udffd\u200d\ud83c\udf7c\", \"\ud83d\udc69\ud83c\udffd\u200d\ud83c\udf93\", \"\ud83d\udc69\ud83c\udffd\u200d\ud83c\udfa4\", \"\ud83d\udc69\ud83c\udffd\u200d\ud83c\udfa8\", \"\ud83d\udc69\ud83c\udffd\u200d\ud83c\udfeb\", \"\ud83d\udc69\ud83c\udffd\u200d\ud83c\udfed\", \"\ud83d\udc69\ud83c\udffd\u200d\ud83d\udcbb\", \"\ud83d\udc69\ud83c\udffd\u200d\ud83d\udcbc\", \"\ud83d\udc69\ud83c\udffd\u200d\ud83d\udd27\", \"\ud83d\udc69\ud83c\udffd\u200d\ud83d\udd2c\", \"\ud83d\udc69\ud83c\udffd\u200d\ud83d\ude80\", \"\ud83d\udc69\ud83c\udffd\u200d\ud83d\ude92\", \"\ud83d\udc69\ud83c\udffd\u200d\ud83e\udd1d\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc69\ud83c\udffd\u200d\ud83e\udd1d\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc69\ud83c\udffd\u200d\ud83e\udd1d\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc69\ud83c\udffd\u200d\ud83e\udd1d\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc69\ud83c\udffd\u200d\ud83e\udd1d\u200d\ud83d\udc69\ud83c\udffb\", \"\ud83d\udc69\ud83c\udffd\u200d\ud83e\udd1d\u200d\ud83d\udc69\ud83c\udffc\", \"\ud83d\udc69\ud83c\udffd\u200d\ud83e\udd1d\u200d\ud83d\udc69\ud83c\udffe\", \"\ud83d\udc69\ud83c\udffd\u200d\ud83e\udd1d\u200d\ud83d\udc69\ud83c\udfff\", \"\ud83d\udc69\ud83c\udffd\u200d\ud83e\uddaf\", \"\ud83d\udc69\ud83c\udffd\u200d\ud83e\uddaf\u200d\u27a1\", \"\ud83d\udc69\ud83c\udffd\u200d\ud83e\uddaf\u200d\u27a1\ufe0f\", \"\ud83d\udc69\ud83c\udffd\u200d\ud83e\uddb0\", \"\ud83d\udc69\ud83c\udffd\u200d\ud83e\uddb1\", \"\ud83d\udc69\ud83c\udffd\u200d\ud83e\uddb2\", \"\ud83d\udc69\ud83c\udffd\u200d\ud83e\uddb3\", \"\ud83d\udc69\ud83c\udffd\u200d\ud83e\uddbc\", \"\ud83d\udc69\ud83c\udffd\u200d\ud83e\uddbc\u200d\u27a1\", \"\ud83d\udc69\ud83c\udffd\u200d\ud83e\uddbc\u200d\u27a1\ufe0f\", \"\ud83d\udc69\ud83c\udffd\u200d\ud83e\uddbd\", \"\ud83d\udc69\ud83c\udffd\u200d\ud83e\uddbd\u200d\u27a1\", \"\ud83d\udc69\ud83c\udffd\u200d\ud83e\uddbd\u200d\u27a1\ufe0f\", \"\ud83d\udc69\ud83c\udffe\", \"\ud83d\udc69\ud83c\udffe\u200d\u2695\", \"\ud83d\udc69\ud83c\udffe\u200d\u2695\ufe0f\", \"\ud83d\udc69\ud83c\udffe\u200d\u2696\", \"\ud83d\udc69\ud83c\udffe\u200d\u2696\ufe0f\", \"\ud83d\udc69\ud83c\udffe\u200d\u2708\", \"\ud83d\udc69\ud83c\udffe\u200d\u2708\ufe0f\", \"\ud83d\udc69\ud83c\udffe\u200d\u2764\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc69\ud83c\udffe\u200d\u2764\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc69\ud83c\udffe\u200d\u2764\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc69\ud83c\udffe\u200d\u2764\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc69\ud83c\udffe\u200d\u2764\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc69\ud83c\udffe\u200d\u2764\u200d\ud83d\udc69\ud83c\udffb\", \"\ud83d\udc69\ud83c\udffe\u200d\u2764\u200d\ud83d\udc69\ud83c\udffc\", \"\ud83d\udc69\ud83c\udffe\u200d\u2764\u200d\ud83d\udc69\ud83c\udffd\", \"\ud83d\udc69\ud83c\udffe\u200d\u2764\u200d\ud83d\udc69\ud83c\udffe\", \"\ud83d\udc69\ud83c\udffe\u200d\u2764\u200d\ud83d\udc69\ud83c\udfff\", \"\ud83d\udc69\ud83c\udffe\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc69\ud83c\udffe\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc69\ud83c\udffe\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc69\ud83c\udffe\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc69\ud83c\udffe\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc69\ud83c\udffe\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udffb\", \"\ud83d\udc69\ud83c\udffe\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udffc\", \"\ud83d\udc69\ud83c\udffe\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udffd\", \"\ud83d\udc69\ud83c\udffe\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udffe\", \"\ud83d\udc69\ud83c\udffe\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udfff\", \"\ud83d\udc69\ud83c\udffe\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc69\ud83c\udffe\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc69\ud83c\udffe\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc69\ud83c\udffe\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc69\ud83c\udffe\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc69\ud83c\udffe\u200d\u2764\ufe0f\u200d\ud83d\udc69\ud83c\udffb\", \"\ud83d\udc69\ud83c\udffe\u200d\u2764\ufe0f\u200d\ud83d\udc69\ud83c\udffc\", \"\ud83d\udc69\ud83c\udffe\u200d\u2764\ufe0f\u200d\ud83d\udc69\ud83c\udffd\", \"\ud83d\udc69\ud83c\udffe\u200d\u2764\ufe0f\u200d\ud83d\udc69\ud83c\udffe\", \"\ud83d\udc69\ud83c\udffe\u200d\u2764\ufe0f\u200d\ud83d\udc69\ud83c\udfff\", \"\ud83d\udc69\ud83c\udffe\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc69\ud83c\udffe\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc69\ud83c\udffe\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc69\ud83c\udffe\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc69\ud83c\udffe\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc69\ud83c\udffe\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udffb\", \"\ud83d\udc69\ud83c\udffe\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udffc\", \"\ud83d\udc69\ud83c\udffe\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udffd\", \"\ud83d\udc69\ud83c\udffe\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udffe\", \"\ud83d\udc69\ud83c\udffe\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udfff\", \"\ud83d\udc69\ud83c\udffe\u200d\ud83c\udf3e\", \"\ud83d\udc69\ud83c\udffe\u200d\ud83c\udf73\", \"\ud83d\udc69\ud83c\udffe\u200d\ud83c\udf7c\", \"\ud83d\udc69\ud83c\udffe\u200d\ud83c\udf93\", \"\ud83d\udc69\ud83c\udffe\u200d\ud83c\udfa4\", \"\ud83d\udc69\ud83c\udffe\u200d\ud83c\udfa8\", \"\ud83d\udc69\ud83c\udffe\u200d\ud83c\udfeb\", \"\ud83d\udc69\ud83c\udffe\u200d\ud83c\udfed\", \"\ud83d\udc69\ud83c\udffe\u200d\ud83d\udcbb\", \"\ud83d\udc69\ud83c\udffe\u200d\ud83d\udcbc\", \"\ud83d\udc69\ud83c\udffe\u200d\ud83d\udd27\", \"\ud83d\udc69\ud83c\udffe\u200d\ud83d\udd2c\", \"\ud83d\udc69\ud83c\udffe\u200d\ud83d\ude80\", \"\ud83d\udc69\ud83c\udffe\u200d\ud83d\ude92\", \"\ud83d\udc69\ud83c\udffe\u200d\ud83e\udd1d\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc69\ud83c\udffe\u200d\ud83e\udd1d\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc69\ud83c\udffe\u200d\ud83e\udd1d\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc69\ud83c\udffe\u200d\ud83e\udd1d\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc69\ud83c\udffe\u200d\ud83e\udd1d\u200d\ud83d\udc69\ud83c\udffb\", \"\ud83d\udc69\ud83c\udffe\u200d\ud83e\udd1d\u200d\ud83d\udc69\ud83c\udffc\", \"\ud83d\udc69\ud83c\udffe\u200d\ud83e\udd1d\u200d\ud83d\udc69\ud83c\udffd\", \"\ud83d\udc69\ud83c\udffe\u200d\ud83e\udd1d\u200d\ud83d\udc69\ud83c\udfff\", \"\ud83d\udc69\ud83c\udffe\u200d\ud83e\uddaf\", \"\ud83d\udc69\ud83c\udffe\u200d\ud83e\uddaf\u200d\u27a1\", \"\ud83d\udc69\ud83c\udffe\u200d\ud83e\uddaf\u200d\u27a1\ufe0f\", \"\ud83d\udc69\ud83c\udffe\u200d\ud83e\uddb0\", \"\ud83d\udc69\ud83c\udffe\u200d\ud83e\uddb1\", \"\ud83d\udc69\ud83c\udffe\u200d\ud83e\uddb2\", \"\ud83d\udc69\ud83c\udffe\u200d\ud83e\uddb3\", \"\ud83d\udc69\ud83c\udffe\u200d\ud83e\uddbc\", \"\ud83d\udc69\ud83c\udffe\u200d\ud83e\uddbc\u200d\u27a1\", \"\ud83d\udc69\ud83c\udffe\u200d\ud83e\uddbc\u200d\u27a1\ufe0f\", \"\ud83d\udc69\ud83c\udffe\u200d\ud83e\uddbd\", \"\ud83d\udc69\ud83c\udffe\u200d\ud83e\uddbd\u200d\u27a1\", \"\ud83d\udc69\ud83c\udffe\u200d\ud83e\uddbd\u200d\u27a1\ufe0f\", \"\ud83d\udc69\ud83c\udfff\", \"\ud83d\udc69\ud83c\udfff\u200d\u2695\", \"\ud83d\udc69\ud83c\udfff\u200d\u2695\ufe0f\", \"\ud83d\udc69\ud83c\udfff\u200d\u2696\", \"\ud83d\udc69\ud83c\udfff\u200d\u2696\ufe0f\", \"\ud83d\udc69\ud83c\udfff\u200d\u2708\", \"\ud83d\udc69\ud83c\udfff\u200d\u2708\ufe0f\", \"\ud83d\udc69\ud83c\udfff\u200d\u2764\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc69\ud83c\udfff\u200d\u2764\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc69\ud83c\udfff\u200d\u2764\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc69\ud83c\udfff\u200d\u2764\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc69\ud83c\udfff\u200d\u2764\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc69\ud83c\udfff\u200d\u2764\u200d\ud83d\udc69\ud83c\udffb\", \"\ud83d\udc69\ud83c\udfff\u200d\u2764\u200d\ud83d\udc69\ud83c\udffc\", \"\ud83d\udc69\ud83c\udfff\u200d\u2764\u200d\ud83d\udc69\ud83c\udffd\", \"\ud83d\udc69\ud83c\udfff\u200d\u2764\u200d\ud83d\udc69\ud83c\udffe\", \"\ud83d\udc69\ud83c\udfff\u200d\u2764\u200d\ud83d\udc69\ud83c\udfff\", \"\ud83d\udc69\ud83c\udfff\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc69\ud83c\udfff\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc69\ud83c\udfff\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc69\ud83c\udfff\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc69\ud83c\udfff\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc69\ud83c\udfff\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udffb\", \"\ud83d\udc69\ud83c\udfff\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udffc\", \"\ud83d\udc69\ud83c\udfff\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udffd\", \"\ud83d\udc69\ud83c\udfff\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udffe\", \"\ud83d\udc69\ud83c\udfff\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udfff\", \"\ud83d\udc69\ud83c\udfff\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc69\ud83c\udfff\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc69\ud83c\udfff\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc69\ud83c\udfff\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc69\ud83c\udfff\u200d\u2764\ufe0f\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc69\ud83c\udfff\u200d\u2764\ufe0f\u200d\ud83d\udc69\ud83c\udffb\", \"\ud83d\udc69\ud83c\udfff\u200d\u2764\ufe0f\u200d\ud83d\udc69\ud83c\udffc\", \"\ud83d\udc69\ud83c\udfff\u200d\u2764\ufe0f\u200d\ud83d\udc69\ud83c\udffd\", \"\ud83d\udc69\ud83c\udfff\u200d\u2764\ufe0f\u200d\ud83d\udc69\ud83c\udffe\", \"\ud83d\udc69\ud83c\udfff\u200d\u2764\ufe0f\u200d\ud83d\udc69\ud83c\udfff\", \"\ud83d\udc69\ud83c\udfff\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc69\ud83c\udfff\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc69\ud83c\udfff\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc69\ud83c\udfff\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc69\ud83c\udfff\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc68\ud83c\udfff\", \"\ud83d\udc69\ud83c\udfff\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udffb\", \"\ud83d\udc69\ud83c\udfff\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udffc\", \"\ud83d\udc69\ud83c\udfff\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udffd\", \"\ud83d\udc69\ud83c\udfff\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udffe\", \"\ud83d\udc69\ud83c\udfff\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83d\udc69\ud83c\udfff\", \"\ud83d\udc69\ud83c\udfff\u200d\ud83c\udf3e\", \"\ud83d\udc69\ud83c\udfff\u200d\ud83c\udf73\", \"\ud83d\udc69\ud83c\udfff\u200d\ud83c\udf7c\", \"\ud83d\udc69\ud83c\udfff\u200d\ud83c\udf93\", \"\ud83d\udc69\ud83c\udfff\u200d\ud83c\udfa4\", \"\ud83d\udc69\ud83c\udfff\u200d\ud83c\udfa8\", \"\ud83d\udc69\ud83c\udfff\u200d\ud83c\udfeb\", \"\ud83d\udc69\ud83c\udfff\u200d\ud83c\udfed\", \"\ud83d\udc69\ud83c\udfff\u200d\ud83d\udcbb\", \"\ud83d\udc69\ud83c\udfff\u200d\ud83d\udcbc\", \"\ud83d\udc69\ud83c\udfff\u200d\ud83d\udd27\", \"\ud83d\udc69\ud83c\udfff\u200d\ud83d\udd2c\", \"\ud83d\udc69\ud83c\udfff\u200d\ud83d\ude80\", \"\ud83d\udc69\ud83c\udfff\u200d\ud83d\ude92\", \"\ud83d\udc69\ud83c\udfff\u200d\ud83e\udd1d\u200d\ud83d\udc68\ud83c\udffb\", \"\ud83d\udc69\ud83c\udfff\u200d\ud83e\udd1d\u200d\ud83d\udc68\ud83c\udffc\", \"\ud83d\udc69\ud83c\udfff\u200d\ud83e\udd1d\u200d\ud83d\udc68\ud83c\udffd\", \"\ud83d\udc69\ud83c\udfff\u200d\ud83e\udd1d\u200d\ud83d\udc68\ud83c\udffe\", \"\ud83d\udc69\ud83c\udfff\u200d\ud83e\udd1d\u200d\ud83d\udc69\ud83c\udffb\", \"\ud83d\udc69\ud83c\udfff\u200d\ud83e\udd1d\u200d\ud83d\udc69\ud83c\udffc\", \"\ud83d\udc69\ud83c\udfff\u200d\ud83e\udd1d\u200d\ud83d\udc69\ud83c\udffd\", \"\ud83d\udc69\ud83c\udfff\u200d\ud83e\udd1d\u200d\ud83d\udc69\ud83c\udffe\", \"\ud83d\udc69\ud83c\udfff\u200d\ud83e\uddaf\", \"\ud83d\udc69\ud83c\udfff\u200d\ud83e\uddaf\u200d\u27a1\", \"\ud83d\udc69\ud83c\udfff\u200d\ud83e\uddaf\u200d\u27a1\ufe0f\", \"\ud83d\udc69\ud83c\udfff\u200d\ud83e\uddb0\", \"\ud83d\udc69\ud83c\udfff\u200d\ud83e\uddb1\", \"\ud83d\udc69\ud83c\udfff\u200d\ud83e\uddb2\", \"\ud83d\udc69\ud83c\udfff\u200d\ud83e\uddb3\", \"\ud83d\udc69\ud83c\udfff\u200d\ud83e\uddbc\", \"\ud83d\udc69\ud83c\udfff\u200d\ud83e\uddbc\u200d\u27a1\", \"\ud83d\udc69\ud83c\udfff\u200d\ud83e\uddbc\u200d\u27a1\ufe0f\", \"\ud83d\udc69\ud83c\udfff\u200d\ud83e\uddbd\", \"\ud83d\udc69\ud83c\udfff\u200d\ud83e\uddbd\u200d\u27a1\", \"\ud83d\udc69\ud83c\udfff\u200d\ud83e\uddbd\u200d\u27a1\ufe0f\", \"\ud83d\udc6a\", \"\ud83d\udc6b\", \"\ud83d\udc6b\ud83c\udffb\", \"\ud83d\udc6b\ud83c\udffc\", \"\ud83d\udc6b\ud83c\udffd\", \"\ud83d\udc6b\ud83c\udffe\", \"\ud83d\udc6b\ud83c\udfff\", \"\ud83d\udc6c\", \"\ud83d\udc6c\ud83c\udffb\", \"\ud83d\udc6c\ud83c\udffc\", \"\ud83d\udc6c\ud83c\udffd\", \"\ud83d\udc6c\ud83c\udffe\", \"\ud83d\udc6c\ud83c\udfff\", \"\ud83d\udc6d\", \"\ud83d\udc6d\ud83c\udffb\", \"\ud83d\udc6d\ud83c\udffc\", \"\ud83d\udc6d\ud83c\udffd\", \"\ud83d\udc6d\ud83c\udffe\", \"\ud83d\udc6d\ud83c\udfff\", \"\ud83d\udc6e\", \"\ud83d\udc6e\u200d\u2640\", \"\ud83d\udc6e\u200d\u2640\ufe0f\", \"\ud83d\udc6e\u200d\u2642\", \"\ud83d\udc6e\u200d\u2642\ufe0f\", \"\ud83d\udc6e\ud83c\udffb\", \"\ud83d\udc6e\ud83c\udffb\u200d\u2640\", \"\ud83d\udc6e\ud83c\udffb\u200d\u2640\ufe0f\", \"\ud83d\udc6e\ud83c\udffb\u200d\u2642\", \"\ud83d\udc6e\ud83c\udffb\u200d\u2642\ufe0f\", \"\ud83d\udc6e\ud83c\udffc\", \"\ud83d\udc6e\ud83c\udffc\u200d\u2640\", \"\ud83d\udc6e\ud83c\udffc\u200d\u2640\ufe0f\", \"\ud83d\udc6e\ud83c\udffc\u200d\u2642\", \"\ud83d\udc6e\ud83c\udffc\u200d\u2642\ufe0f\", \"\ud83d\udc6e\ud83c\udffd\", \"\ud83d\udc6e\ud83c\udffd\u200d\u2640\", \"\ud83d\udc6e\ud83c\udffd\u200d\u2640\ufe0f\", \"\ud83d\udc6e\ud83c\udffd\u200d\u2642\", \"\ud83d\udc6e\ud83c\udffd\u200d\u2642\ufe0f\", \"\ud83d\udc6e\ud83c\udffe\", \"\ud83d\udc6e\ud83c\udffe\u200d\u2640\", \"\ud83d\udc6e\ud83c\udffe\u200d\u2640\ufe0f\", \"\ud83d\udc6e\ud83c\udffe\u200d\u2642\", \"\ud83d\udc6e\ud83c\udffe\u200d\u2642\ufe0f\", \"\ud83d\udc6e\ud83c\udfff\", \"\ud83d\udc6e\ud83c\udfff\u200d\u2640\", \"\ud83d\udc6e\ud83c\udfff\u200d\u2640\ufe0f\", \"\ud83d\udc6e\ud83c\udfff\u200d\u2642\", \"\ud83d\udc6e\ud83c\udfff\u200d\u2642\ufe0f\", \"\ud83d\udc6f\", \"\ud83d\udc6f\u200d\u2640\", \"\ud83d\udc6f\u200d\u2640\ufe0f\", \"\ud83d\udc6f\u200d\u2642\", \"\ud83d\udc6f\u200d\u2642\ufe0f\", \"\ud83d\udc70\", \"\ud83d\udc70\u200d\u2640\", \"\ud83d\udc70\u200d\u2640\ufe0f\", \"\ud83d\udc70\u200d\u2642\", \"\ud83d\udc70\u200d\u2642\ufe0f\", \"\ud83d\udc70\ud83c\udffb\", \"\ud83d\udc70\ud83c\udffb\u200d\u2640\", \"\ud83d\udc70\ud83c\udffb\u200d\u2640\ufe0f\", \"\ud83d\udc70\ud83c\udffb\u200d\u2642\", \"\ud83d\udc70\ud83c\udffb\u200d\u2642\ufe0f\", \"\ud83d\udc70\ud83c\udffc\", \"\ud83d\udc70\ud83c\udffc\u200d\u2640\", \"\ud83d\udc70\ud83c\udffc\u200d\u2640\ufe0f\", \"\ud83d\udc70\ud83c\udffc\u200d\u2642\", \"\ud83d\udc70\ud83c\udffc\u200d\u2642\ufe0f\", \"\ud83d\udc70\ud83c\udffd\", \"\ud83d\udc70\ud83c\udffd\u200d\u2640\", \"\ud83d\udc70\ud83c\udffd\u200d\u2640\ufe0f\", \"\ud83d\udc70\ud83c\udffd\u200d\u2642\", \"\ud83d\udc70\ud83c\udffd\u200d\u2642\ufe0f\", \"\ud83d\udc70\ud83c\udffe\", \"\ud83d\udc70\ud83c\udffe\u200d\u2640\", \"\ud83d\udc70\ud83c\udffe\u200d\u2640\ufe0f\", \"\ud83d\udc70\ud83c\udffe\u200d\u2642\", \"\ud83d\udc70\ud83c\udffe\u200d\u2642\ufe0f\", \"\ud83d\udc70\ud83c\udfff\", \"\ud83d\udc70\ud83c\udfff\u200d\u2640\", \"\ud83d\udc70\ud83c\udfff\u200d\u2640\ufe0f\", \"\ud83d\udc70\ud83c\udfff\u200d\u2642\", \"\ud83d\udc70\ud83c\udfff\u200d\u2642\ufe0f\", \"\ud83d\udc71\", \"\ud83d\udc71\u200d\u2640\", \"\ud83d\udc71\u200d\u2640\ufe0f\", \"\ud83d\udc71\u200d\u2642\", \"\ud83d\udc71\u200d\u2642\ufe0f\", \"\ud83d\udc71\ud83c\udffb\", \"\ud83d\udc71\ud83c\udffb\u200d\u2640\", \"\ud83d\udc71\ud83c\udffb\u200d\u2640\ufe0f\", \"\ud83d\udc71\ud83c\udffb\u200d\u2642\", \"\ud83d\udc71\ud83c\udffb\u200d\u2642\ufe0f\", \"\ud83d\udc71\ud83c\udffc\", \"\ud83d\udc71\ud83c\udffc\u200d\u2640\", \"\ud83d\udc71\ud83c\udffc\u200d\u2640\ufe0f\", \"\ud83d\udc71\ud83c\udffc\u200d\u2642\", \"\ud83d\udc71\ud83c\udffc\u200d\u2642\ufe0f\", \"\ud83d\udc71\ud83c\udffd\", \"\ud83d\udc71\ud83c\udffd\u200d\u2640\", \"\ud83d\udc71\ud83c\udffd\u200d\u2640\ufe0f\", \"\ud83d\udc71\ud83c\udffd\u200d\u2642\", \"\ud83d\udc71\ud83c\udffd\u200d\u2642\ufe0f\", \"\ud83d\udc71\ud83c\udffe\", \"\ud83d\udc71\ud83c\udffe\u200d\u2640\", \"\ud83d\udc71\ud83c\udffe\u200d\u2640\ufe0f\", \"\ud83d\udc71\ud83c\udffe\u200d\u2642\", \"\ud83d\udc71\ud83c\udffe\u200d\u2642\ufe0f\", \"\ud83d\udc71\ud83c\udfff\", \"\ud83d\udc71\ud83c\udfff\u200d\u2640\", \"\ud83d\udc71\ud83c\udfff\u200d\u2640\ufe0f\", \"\ud83d\udc71\ud83c\udfff\u200d\u2642\", \"\ud83d\udc71\ud83c\udfff\u200d\u2642\ufe0f\", \"\ud83d\udc72\", \"\ud83d\udc72\ud83c\udffb\", \"\ud83d\udc72\ud83c\udffc\", \"\ud83d\udc72\ud83c\udffd\", \"\ud83d\udc72\ud83c\udffe\", \"\ud83d\udc72\ud83c\udfff\", \"\ud83d\udc73\", \"\ud83d\udc73\u200d\u2640\", \"\ud83d\udc73\u200d\u2640\ufe0f\", \"\ud83d\udc73\u200d\u2642\", \"\ud83d\udc73\u200d\u2642\ufe0f\", \"\ud83d\udc73\ud83c\udffb\", \"\ud83d\udc73\ud83c\udffb\u200d\u2640\", \"\ud83d\udc73\ud83c\udffb\u200d\u2640\ufe0f\", \"\ud83d\udc73\ud83c\udffb\u200d\u2642\", \"\ud83d\udc73\ud83c\udffb\u200d\u2642\ufe0f\", \"\ud83d\udc73\ud83c\udffc\", \"\ud83d\udc73\ud83c\udffc\u200d\u2640\", \"\ud83d\udc73\ud83c\udffc\u200d\u2640\ufe0f\", \"\ud83d\udc73\ud83c\udffc\u200d\u2642\", \"\ud83d\udc73\ud83c\udffc\u200d\u2642\ufe0f\", \"\ud83d\udc73\ud83c\udffd\", \"\ud83d\udc73\ud83c\udffd\u200d\u2640\", \"\ud83d\udc73\ud83c\udffd\u200d\u2640\ufe0f\", \"\ud83d\udc73\ud83c\udffd\u200d\u2642\", \"\ud83d\udc73\ud83c\udffd\u200d\u2642\ufe0f\", \"\ud83d\udc73\ud83c\udffe\", \"\ud83d\udc73\ud83c\udffe\u200d\u2640\", \"\ud83d\udc73\ud83c\udffe\u200d\u2640\ufe0f\", \"\ud83d\udc73\ud83c\udffe\u200d\u2642\", \"\ud83d\udc73\ud83c\udffe\u200d\u2642\ufe0f\", \"\ud83d\udc73\ud83c\udfff\", \"\ud83d\udc73\ud83c\udfff\u200d\u2640\", \"\ud83d\udc73\ud83c\udfff\u200d\u2640\ufe0f\", \"\ud83d\udc73\ud83c\udfff\u200d\u2642\", \"\ud83d\udc73\ud83c\udfff\u200d\u2642\ufe0f\", \"\ud83d\udc74\", \"\ud83d\udc74\ud83c\udffb\", \"\ud83d\udc74\ud83c\udffc\", \"\ud83d\udc74\ud83c\udffd\", \"\ud83d\udc74\ud83c\udffe\", \"\ud83d\udc74\ud83c\udfff\", \"\ud83d\udc75\", \"\ud83d\udc75\ud83c\udffb\", \"\ud83d\udc75\ud83c\udffc\", \"\ud83d\udc75\ud83c\udffd\", \"\ud83d\udc75\ud83c\udffe\", \"\ud83d\udc75\ud83c\udfff\", \"\ud83d\udc76\", \"\ud83d\udc76\ud83c\udffb\", \"\ud83d\udc76\ud83c\udffc\", \"\ud83d\udc76\ud83c\udffd\", \"\ud83d\udc76\ud83c\udffe\", \"\ud83d\udc76\ud83c\udfff\", \"\ud83d\udc77\", \"\ud83d\udc77\u200d\u2640\", \"\ud83d\udc77\u200d\u2640\ufe0f\", \"\ud83d\udc77\u200d\u2642\", \"\ud83d\udc77\u200d\u2642\ufe0f\", \"\ud83d\udc77\ud83c\udffb\", \"\ud83d\udc77\ud83c\udffb\u200d\u2640\", \"\ud83d\udc77\ud83c\udffb\u200d\u2640\ufe0f\", \"\ud83d\udc77\ud83c\udffb\u200d\u2642\", \"\ud83d\udc77\ud83c\udffb\u200d\u2642\ufe0f\", \"\ud83d\udc77\ud83c\udffc\", \"\ud83d\udc77\ud83c\udffc\u200d\u2640\", \"\ud83d\udc77\ud83c\udffc\u200d\u2640\ufe0f\", \"\ud83d\udc77\ud83c\udffc\u200d\u2642\", \"\ud83d\udc77\ud83c\udffc\u200d\u2642\ufe0f\", \"\ud83d\udc77\ud83c\udffd\", \"\ud83d\udc77\ud83c\udffd\u200d\u2640\", \"\ud83d\udc77\ud83c\udffd\u200d\u2640\ufe0f\", \"\ud83d\udc77\ud83c\udffd\u200d\u2642\", \"\ud83d\udc77\ud83c\udffd\u200d\u2642\ufe0f\", \"\ud83d\udc77\ud83c\udffe\", \"\ud83d\udc77\ud83c\udffe\u200d\u2640\", \"\ud83d\udc77\ud83c\udffe\u200d\u2640\ufe0f\", \"\ud83d\udc77\ud83c\udffe\u200d\u2642\", \"\ud83d\udc77\ud83c\udffe\u200d\u2642\ufe0f\", \"\ud83d\udc77\ud83c\udfff\", \"\ud83d\udc77\ud83c\udfff\u200d\u2640\", \"\ud83d\udc77\ud83c\udfff\u200d\u2640\ufe0f\", \"\ud83d\udc77\ud83c\udfff\u200d\u2642\", \"\ud83d\udc77\ud83c\udfff\u200d\u2642\ufe0f\", \"\ud83d\udc78\", \"\ud83d\udc78\ud83c\udffb\", \"\ud83d\udc78\ud83c\udffc\", \"\ud83d\udc78\ud83c\udffd\", \"\ud83d\udc78\ud83c\udffe\", \"\ud83d\udc78\ud83c\udfff\", \"\ud83d\udc79\", \"\ud83d\udc7a\", \"\ud83d\udc7b\", \"\ud83d\udc7c\", \"\ud83d\udc7c\ud83c\udffb\", \"\ud83d\udc7c\ud83c\udffc\", \"\ud83d\udc7c\ud83c\udffd\", \"\ud83d\udc7c\ud83c\udffe\", \"\ud83d\udc7c\ud83c\udfff\", \"\ud83d\udc7d\", \"\ud83d\udc7e\", \"\ud83d\udc7f\", \"\ud83d\udc80\", \"\ud83d\udc81\", \"\ud83d\udc81\u200d\u2640\", \"\ud83d\udc81\u200d\u2640\ufe0f\", \"\ud83d\udc81\u200d\u2642\", \"\ud83d\udc81\u200d\u2642\ufe0f\", \"\ud83d\udc81\ud83c\udffb\", \"\ud83d\udc81\ud83c\udffb\u200d\u2640\", \"\ud83d\udc81\ud83c\udffb\u200d\u2640\ufe0f\", \"\ud83d\udc81\ud83c\udffb\u200d\u2642\", \"\ud83d\udc81\ud83c\udffb\u200d\u2642\ufe0f\", \"\ud83d\udc81\ud83c\udffc\", \"\ud83d\udc81\ud83c\udffc\u200d\u2640\", \"\ud83d\udc81\ud83c\udffc\u200d\u2640\ufe0f\", \"\ud83d\udc81\ud83c\udffc\u200d\u2642\", \"\ud83d\udc81\ud83c\udffc\u200d\u2642\ufe0f\", \"\ud83d\udc81\ud83c\udffd\", \"\ud83d\udc81\ud83c\udffd\u200d\u2640\", \"\ud83d\udc81\ud83c\udffd\u200d\u2640\ufe0f\", \"\ud83d\udc81\ud83c\udffd\u200d\u2642\", \"\ud83d\udc81\ud83c\udffd\u200d\u2642\ufe0f\", \"\ud83d\udc81\ud83c\udffe\", \"\ud83d\udc81\ud83c\udffe\u200d\u2640\", \"\ud83d\udc81\ud83c\udffe\u200d\u2640\ufe0f\", \"\ud83d\udc81\ud83c\udffe\u200d\u2642\", \"\ud83d\udc81\ud83c\udffe\u200d\u2642\ufe0f\", \"\ud83d\udc81\ud83c\udfff\", \"\ud83d\udc81\ud83c\udfff\u200d\u2640\", \"\ud83d\udc81\ud83c\udfff\u200d\u2640\ufe0f\", \"\ud83d\udc81\ud83c\udfff\u200d\u2642\", \"\ud83d\udc81\ud83c\udfff\u200d\u2642\ufe0f\", \"\ud83d\udc82\", \"\ud83d\udc82\u200d\u2640\", \"\ud83d\udc82\u200d\u2640\ufe0f\", \"\ud83d\udc82\u200d\u2642\", \"\ud83d\udc82\u200d\u2642\ufe0f\", \"\ud83d\udc82\ud83c\udffb\", \"\ud83d\udc82\ud83c\udffb\u200d\u2640\", \"\ud83d\udc82\ud83c\udffb\u200d\u2640\ufe0f\", \"\ud83d\udc82\ud83c\udffb\u200d\u2642\", \"\ud83d\udc82\ud83c\udffb\u200d\u2642\ufe0f\", \"\ud83d\udc82\ud83c\udffc\", \"\ud83d\udc82\ud83c\udffc\u200d\u2640\", \"\ud83d\udc82\ud83c\udffc\u200d\u2640\ufe0f\", \"\ud83d\udc82\ud83c\udffc\u200d\u2642\", \"\ud83d\udc82\ud83c\udffc\u200d\u2642\ufe0f\", \"\ud83d\udc82\ud83c\udffd\", \"\ud83d\udc82\ud83c\udffd\u200d\u2640\", \"\ud83d\udc82\ud83c\udffd\u200d\u2640\ufe0f\", \"\ud83d\udc82\ud83c\udffd\u200d\u2642\", \"\ud83d\udc82\ud83c\udffd\u200d\u2642\ufe0f\", \"\ud83d\udc82\ud83c\udffe\", \"\ud83d\udc82\ud83c\udffe\u200d\u2640\", \"\ud83d\udc82\ud83c\udffe\u200d\u2640\ufe0f\", \"\ud83d\udc82\ud83c\udffe\u200d\u2642\", \"\ud83d\udc82\ud83c\udffe\u200d\u2642\ufe0f\", \"\ud83d\udc82\ud83c\udfff\", \"\ud83d\udc82\ud83c\udfff\u200d\u2640\", \"\ud83d\udc82\ud83c\udfff\u200d\u2640\ufe0f\", \"\ud83d\udc82\ud83c\udfff\u200d\u2642\", \"\ud83d\udc82\ud83c\udfff\u200d\u2642\ufe0f\", \"\ud83d\udc83\", \"\ud83d\udc83\ud83c\udffb\", \"\ud83d\udc83\ud83c\udffc\", \"\ud83d\udc83\ud83c\udffd\", \"\ud83d\udc83\ud83c\udffe\", \"\ud83d\udc83\ud83c\udfff\", \"\ud83d\udc84\", \"\ud83d\udc85\", \"\ud83d\udc85\ud83c\udffb\", \"\ud83d\udc85\ud83c\udffc\", \"\ud83d\udc85\ud83c\udffd\", \"\ud83d\udc85\ud83c\udffe\", \"\ud83d\udc85\ud83c\udfff\", \"\ud83d\udc86\", \"\ud83d\udc86\u200d\u2640\", \"\ud83d\udc86\u200d\u2640\ufe0f\", \"\ud83d\udc86\u200d\u2642\", \"\ud83d\udc86\u200d\u2642\ufe0f\", \"\ud83d\udc86\ud83c\udffb\", \"\ud83d\udc86\ud83c\udffb\u200d\u2640\", \"\ud83d\udc86\ud83c\udffb\u200d\u2640\ufe0f\", \"\ud83d\udc86\ud83c\udffb\u200d\u2642\", \"\ud83d\udc86\ud83c\udffb\u200d\u2642\ufe0f\", \"\ud83d\udc86\ud83c\udffc\", \"\ud83d\udc86\ud83c\udffc\u200d\u2640\", \"\ud83d\udc86\ud83c\udffc\u200d\u2640\ufe0f\", \"\ud83d\udc86\ud83c\udffc\u200d\u2642\", \"\ud83d\udc86\ud83c\udffc\u200d\u2642\ufe0f\", \"\ud83d\udc86\ud83c\udffd\", \"\ud83d\udc86\ud83c\udffd\u200d\u2640\", \"\ud83d\udc86\ud83c\udffd\u200d\u2640\ufe0f\", \"\ud83d\udc86\ud83c\udffd\u200d\u2642\", \"\ud83d\udc86\ud83c\udffd\u200d\u2642\ufe0f\", \"\ud83d\udc86\ud83c\udffe\", \"\ud83d\udc86\ud83c\udffe\u200d\u2640\", \"\ud83d\udc86\ud83c\udffe\u200d\u2640\ufe0f\", \"\ud83d\udc86\ud83c\udffe\u200d\u2642\", \"\ud83d\udc86\ud83c\udffe\u200d\u2642\ufe0f\", \"\ud83d\udc86\ud83c\udfff\", \"\ud83d\udc86\ud83c\udfff\u200d\u2640\", \"\ud83d\udc86\ud83c\udfff\u200d\u2640\ufe0f\", \"\ud83d\udc86\ud83c\udfff\u200d\u2642\", \"\ud83d\udc86\ud83c\udfff\u200d\u2642\ufe0f\", \"\ud83d\udc87\", \"\ud83d\udc87\u200d\u2640\", \"\ud83d\udc87\u200d\u2640\ufe0f\", \"\ud83d\udc87\u200d\u2642\", \"\ud83d\udc87\u200d\u2642\ufe0f\", \"\ud83d\udc87\ud83c\udffb\", \"\ud83d\udc87\ud83c\udffb\u200d\u2640\", \"\ud83d\udc87\ud83c\udffb\u200d\u2640\ufe0f\", \"\ud83d\udc87\ud83c\udffb\u200d\u2642\", \"\ud83d\udc87\ud83c\udffb\u200d\u2642\ufe0f\", \"\ud83d\udc87\ud83c\udffc\", \"\ud83d\udc87\ud83c\udffc\u200d\u2640\", \"\ud83d\udc87\ud83c\udffc\u200d\u2640\ufe0f\", \"\ud83d\udc87\ud83c\udffc\u200d\u2642\", \"\ud83d\udc87\ud83c\udffc\u200d\u2642\ufe0f\", \"\ud83d\udc87\ud83c\udffd\", \"\ud83d\udc87\ud83c\udffd\u200d\u2640\", \"\ud83d\udc87\ud83c\udffd\u200d\u2640\ufe0f\", \"\ud83d\udc87\ud83c\udffd\u200d\u2642\", \"\ud83d\udc87\ud83c\udffd\u200d\u2642\ufe0f\", \"\ud83d\udc87\ud83c\udffe\", \"\ud83d\udc87\ud83c\udffe\u200d\u2640\", \"\ud83d\udc87\ud83c\udffe\u200d\u2640\ufe0f\", \"\ud83d\udc87\ud83c\udffe\u200d\u2642\", \"\ud83d\udc87\ud83c\udffe\u200d\u2642\ufe0f\", \"\ud83d\udc87\ud83c\udfff\", \"\ud83d\udc87\ud83c\udfff\u200d\u2640\", \"\ud83d\udc87\ud83c\udfff\u200d\u2640\ufe0f\", \"\ud83d\udc87\ud83c\udfff\u200d\u2642\", \"\ud83d\udc87\ud83c\udfff\u200d\u2642\ufe0f\", \"\ud83d\udc88\", \"\ud83d\udc89\", \"\ud83d\udc8a\", \"\ud83d\udc8b\", \"\ud83d\udc8c\", \"\ud83d\udc8d\", \"\ud83d\udc8e\", \"\ud83d\udc8f\", \"\ud83d\udc8f\ud83c\udffb\", \"\ud83d\udc8f\ud83c\udffc\", \"\ud83d\udc8f\ud83c\udffd\", \"\ud83d\udc8f\ud83c\udffe\", \"\ud83d\udc8f\ud83c\udfff\", \"\ud83d\udc90\", \"\ud83d\udc91\", \"\ud83d\udc91\ud83c\udffb\", \"\ud83d\udc91\ud83c\udffc\", \"\ud83d\udc91\ud83c\udffd\", \"\ud83d\udc91\ud83c\udffe\", \"\ud83d\udc91\ud83c\udfff\", \"\ud83d\udc92\", \"\ud83d\udc93\", \"\ud83d\udc94\", \"\ud83d\udc95\", \"\ud83d\udc96\", \"\ud83d\udc97\", \"\ud83d\udc98\", \"\ud83d\udc99\", \"\ud83d\udc9a\", \"\ud83d\udc9b\", \"\ud83d\udc9c\", \"\ud83d\udc9d\", \"\ud83d\udc9e\", \"\ud83d\udc9f\", \"\ud83d\udca0\", \"\ud83d\udca1\", \"\ud83d\udca2\", \"\ud83d\udca3\", \"\ud83d\udca4\", \"\ud83d\udca5\", \"\ud83d\udca6\", \"\ud83d\udca7\", \"\ud83d\udca8\", \"\ud83d\udca9\", \"\ud83d\udcaa\", \"\ud83d\udcaa\ud83c\udffb\", \"\ud83d\udcaa\ud83c\udffc\", \"\ud83d\udcaa\ud83c\udffd\", \"\ud83d\udcaa\ud83c\udffe\", \"\ud83d\udcaa\ud83c\udfff\", \"\ud83d\udcab\", \"\ud83d\udcac\", \"\ud83d\udcad\", \"\ud83d\udcae\", \"\ud83d\udcaf\", \"\ud83d\udcb0\", \"\ud83d\udcb1\", \"\ud83d\udcb2\", \"\ud83d\udcb3\", \"\ud83d\udcb4\", \"\ud83d\udcb5\", \"\ud83d\udcb6\", \"\ud83d\udcb7\", \"\ud83d\udcb8\", \"\ud83d\udcb9\", \"\ud83d\udcba\", \"\ud83d\udcbb\", \"\ud83d\udcbc\", \"\ud83d\udcbd\", \"\ud83d\udcbe\", \"\ud83d\udcbf\", \"\ud83d\udcc0\", \"\ud83d\udcc1\", \"\ud83d\udcc2\", \"\ud83d\udcc3\", \"\ud83d\udcc4\", \"\ud83d\udcc5\", \"\ud83d\udcc6\", \"\ud83d\udcc7\", \"\ud83d\udcc8\", \"\ud83d\udcc9\", \"\ud83d\udcca\", \"\ud83d\udccb\", \"\ud83d\udccc\", \"\ud83d\udccd\", \"\ud83d\udcce\", \"\ud83d\udccf\", \"\ud83d\udcd0\", \"\ud83d\udcd1\", \"\ud83d\udcd2\", \"\ud83d\udcd3\", \"\ud83d\udcd4\", \"\ud83d\udcd5\", \"\ud83d\udcd6\", \"\ud83d\udcd7\", \"\ud83d\udcd8\", \"\ud83d\udcd9\", \"\ud83d\udcda\", \"\ud83d\udcdb\", \"\ud83d\udcdc\", \"\ud83d\udcdd\", \"\ud83d\udcde\", \"\ud83d\udcdf\", \"\ud83d\udce0\", \"\ud83d\udce1\", \"\ud83d\udce2\", \"\ud83d\udce3\", \"\ud83d\udce4\", \"\ud83d\udce5\", \"\ud83d\udce6\", \"\ud83d\udce7\", \"\ud83d\udce8\", \"\ud83d\udce9\", \"\ud83d\udcea\", \"\ud83d\udceb\", \"\ud83d\udcec\", \"\ud83d\udced\", \"\ud83d\udcee\", \"\ud83d\udcef\", \"\ud83d\udcf0\", \"\ud83d\udcf1\", \"\ud83d\udcf2\", \"\ud83d\udcf3\", \"\ud83d\udcf4\", \"\ud83d\udcf5\", \"\ud83d\udcf6\", \"\ud83d\udcf7\", \"\ud83d\udcf8\", \"\ud83d\udcf9\", \"\ud83d\udcfa\", \"\ud83d\udcfb\", \"\ud83d\udcfc\", \"\ud83d\udcfd\", \"\ud83d\udcfd\ufe0f\", \"\ud83d\udcff\", \"\ud83d\udd00\", \"\ud83d\udd01\", \"\ud83d\udd02\", \"\ud83d\udd03\", \"\ud83d\udd04\", \"\ud83d\udd05\", \"\ud83d\udd06\", \"\ud83d\udd07\", \"\ud83d\udd08\", \"\ud83d\udd09\", \"\ud83d\udd0a\", \"\ud83d\udd0b\", \"\ud83d\udd0c\", \"\ud83d\udd0d\", \"\ud83d\udd0e\", \"\ud83d\udd0f\", \"\ud83d\udd10\", \"\ud83d\udd11\", \"\ud83d\udd12\", \"\ud83d\udd13\", \"\ud83d\udd14\", \"\ud83d\udd15\", \"\ud83d\udd16\", \"\ud83d\udd17\", \"\ud83d\udd18\", \"\ud83d\udd19\", \"\ud83d\udd1a\", \"\ud83d\udd1b\", \"\ud83d\udd1c\", \"\ud83d\udd1d\", \"\ud83d\udd1e\", \"\ud83d\udd1f\", \"\ud83d\udd20\", \"\ud83d\udd21\", \"\ud83d\udd22\", \"\ud83d\udd23\", \"\ud83d\udd24\", \"\ud83d\udd25\", \"\ud83d\udd26\", \"\ud83d\udd27\", \"\ud83d\udd28\", \"\ud83d\udd29\", \"\ud83d\udd2a\", \"\ud83d\udd2b\", \"\ud83d\udd2c\", \"\ud83d\udd2d\", \"\ud83d\udd2e\", \"\ud83d\udd2f\", \"\ud83d\udd30\", \"\ud83d\udd31\", \"\ud83d\udd32\", \"\ud83d\udd33\", \"\ud83d\udd34\", \"\ud83d\udd35\", \"\ud83d\udd36\", \"\ud83d\udd37\", \"\ud83d\udd38\", \"\ud83d\udd39\", \"\ud83d\udd3a\", \"\ud83d\udd3b\", \"\ud83d\udd3c\", \"\ud83d\udd3d\", \"\ud83d\udd49\", \"\ud83d\udd49\ufe0f\", \"\ud83d\udd4a\", \"\ud83d\udd4a\ufe0f\", \"\ud83d\udd4b\", \"\ud83d\udd4c\", \"\ud83d\udd4d\", \"\ud83d\udd4e\", \"\ud83d\udd50\", \"\ud83d\udd51\", \"\ud83d\udd52\", \"\ud83d\udd53\", \"\ud83d\udd54\", \"\ud83d\udd55\", \"\ud83d\udd56\", \"\ud83d\udd57\", \"\ud83d\udd58\", \"\ud83d\udd59\", \"\ud83d\udd5a\", \"\ud83d\udd5b\", \"\ud83d\udd5c\", \"\ud83d\udd5d\", \"\ud83d\udd5e\", \"\ud83d\udd5f\", \"\ud83d\udd60\", \"\ud83d\udd61\", \"\ud83d\udd62\", \"\ud83d\udd63\", \"\ud83d\udd64\", \"\ud83d\udd65\", \"\ud83d\udd66\", \"\ud83d\udd67\", \"\ud83d\udd6f\", \"\ud83d\udd6f\ufe0f\", \"\ud83d\udd70\", \"\ud83d\udd70\ufe0f\", \"\ud83d\udd73\", \"\ud83d\udd73\ufe0f\", \"\ud83d\udd74\", \"\ud83d\udd74\ufe0f\", \"\ud83d\udd74\ud83c\udffb\", \"\ud83d\udd74\ud83c\udffc\", \"\ud83d\udd74\ud83c\udffd\", \"\ud83d\udd74\ud83c\udffe\", \"\ud83d\udd74\ud83c\udfff\", \"\ud83d\udd75\", \"\ud83d\udd75\u200d\u2640\", \"\ud83d\udd75\u200d\u2640\ufe0f\", \"\ud83d\udd75\u200d\u2642\", \"\ud83d\udd75\u200d\u2642\ufe0f\", \"\ud83d\udd75\ufe0f\", \"\ud83d\udd75\ufe0f\u200d\u2640\", \"\ud83d\udd75\ufe0f\u200d\u2640\ufe0f\", \"\ud83d\udd75\ufe0f\u200d\u2642\", \"\ud83d\udd75\ufe0f\u200d\u2642\ufe0f\", \"\ud83d\udd75\ud83c\udffb\", \"\ud83d\udd75\ud83c\udffb\u200d\u2640\", \"\ud83d\udd75\ud83c\udffb\u200d\u2640\ufe0f\", \"\ud83d\udd75\ud83c\udffb\u200d\u2642\", \"\ud83d\udd75\ud83c\udffb\u200d\u2642\ufe0f\", \"\ud83d\udd75\ud83c\udffc\", \"\ud83d\udd75\ud83c\udffc\u200d\u2640\", \"\ud83d\udd75\ud83c\udffc\u200d\u2640\ufe0f\", \"\ud83d\udd75\ud83c\udffc\u200d\u2642\", \"\ud83d\udd75\ud83c\udffc\u200d\u2642\ufe0f\", \"\ud83d\udd75\ud83c\udffd\", \"\ud83d\udd75\ud83c\udffd\u200d\u2640\", \"\ud83d\udd75\ud83c\udffd\u200d\u2640\ufe0f\", \"\ud83d\udd75\ud83c\udffd\u200d\u2642\", \"\ud83d\udd75\ud83c\udffd\u200d\u2642\ufe0f\", \"\ud83d\udd75\ud83c\udffe\", \"\ud83d\udd75\ud83c\udffe\u200d\u2640\", \"\ud83d\udd75\ud83c\udffe\u200d\u2640\ufe0f\", \"\ud83d\udd75\ud83c\udffe\u200d\u2642\", \"\ud83d\udd75\ud83c\udffe\u200d\u2642\ufe0f\", \"\ud83d\udd75\ud83c\udfff\", \"\ud83d\udd75\ud83c\udfff\u200d\u2640\", \"\ud83d\udd75\ud83c\udfff\u200d\u2640\ufe0f\", \"\ud83d\udd75\ud83c\udfff\u200d\u2642\", \"\ud83d\udd75\ud83c\udfff\u200d\u2642\ufe0f\", \"\ud83d\udd76\", \"\ud83d\udd76\ufe0f\", \"\ud83d\udd77\", \"\ud83d\udd77\ufe0f\", \"\ud83d\udd78\", \"\ud83d\udd78\ufe0f\", \"\ud83d\udd79\", \"\ud83d\udd79\ufe0f\", \"\ud83d\udd7a\", \"\ud83d\udd7a\ud83c\udffb\", \"\ud83d\udd7a\ud83c\udffc\", \"\ud83d\udd7a\ud83c\udffd\", \"\ud83d\udd7a\ud83c\udffe\", \"\ud83d\udd7a\ud83c\udfff\", \"\ud83d\udd87\", \"\ud83d\udd87\ufe0f\", \"\ud83d\udd8a\", \"\ud83d\udd8a\ufe0f\", \"\ud83d\udd8b\", \"\ud83d\udd8b\ufe0f\", \"\ud83d\udd8c\", \"\ud83d\udd8c\ufe0f\", \"\ud83d\udd8d\", \"\ud83d\udd8d\ufe0f\", \"\ud83d\udd90\", \"\ud83d\udd90\ufe0f\", \"\ud83d\udd90\ud83c\udffb\", \"\ud83d\udd90\ud83c\udffc\", \"\ud83d\udd90\ud83c\udffd\", \"\ud83d\udd90\ud83c\udffe\", \"\ud83d\udd90\ud83c\udfff\", \"\ud83d\udd95\", \"\ud83d\udd95\ud83c\udffb\", \"\ud83d\udd95\ud83c\udffc\", \"\ud83d\udd95\ud83c\udffd\", \"\ud83d\udd95\ud83c\udffe\", \"\ud83d\udd95\ud83c\udfff\", \"\ud83d\udd96\", \"\ud83d\udd96\ud83c\udffb\", \"\ud83d\udd96\ud83c\udffc\", \"\ud83d\udd96\ud83c\udffd\", \"\ud83d\udd96\ud83c\udffe\", \"\ud83d\udd96\ud83c\udfff\", \"\ud83d\udda4\", \"\ud83d\udda5\", \"\ud83d\udda5\ufe0f\", \"\ud83d\udda8\", \"\ud83d\udda8\ufe0f\", \"\ud83d\uddb1\", \"\ud83d\uddb1\ufe0f\", \"\ud83d\uddb2\", \"\ud83d\uddb2\ufe0f\", \"\ud83d\uddbc\", \"\ud83d\uddbc\ufe0f\", \"\ud83d\uddc2\", \"\ud83d\uddc2\ufe0f\", \"\ud83d\uddc3\", \"\ud83d\uddc3\ufe0f\", \"\ud83d\uddc4\", \"\ud83d\uddc4\ufe0f\", \"\ud83d\uddd1\", \"\ud83d\uddd1\ufe0f\", \"\ud83d\uddd2\", \"\ud83d\uddd2\ufe0f\", \"\ud83d\uddd3\", \"\ud83d\uddd3\ufe0f\", \"\ud83d\udddc\", \"\ud83d\udddc\ufe0f\", \"\ud83d\udddd\", \"\ud83d\udddd\ufe0f\", \"\ud83d\uddde\", \"\ud83d\uddde\ufe0f\", \"\ud83d\udde1\", \"\ud83d\udde1\ufe0f\", \"\ud83d\udde3\", \"\ud83d\udde3\ufe0f\", \"\ud83d\udde8\", \"\ud83d\udde8\ufe0f\", \"\ud83d\uddef\", \"\ud83d\uddef\ufe0f\", \"\ud83d\uddf3\", \"\ud83d\uddf3\ufe0f\", \"\ud83d\uddfa\", \"\ud83d\uddfa\ufe0f\", \"\ud83d\uddfb\", \"\ud83d\uddfc\", \"\ud83d\uddfd\", \"\ud83d\uddfe\", \"\ud83d\uddff\", \"\ud83d\ude00\", \"\ud83d\ude01\", \"\ud83d\ude02\", \"\ud83d\ude03\", \"\ud83d\ude04\", \"\ud83d\ude05\", \"\ud83d\ude06\", \"\ud83d\ude07\", \"\ud83d\ude08\", \"\ud83d\ude09\", \"\ud83d\ude0a\", \"\ud83d\ude0b\", \"\ud83d\ude0c\", \"\ud83d\ude0d\", \"\ud83d\ude0e\", \"\ud83d\ude0f\", \"\ud83d\ude10\", \"\ud83d\ude11\", \"\ud83d\ude12\", \"\ud83d\ude13\", \"\ud83d\ude14\", \"\ud83d\ude15\", \"\ud83d\ude16\", \"\ud83d\ude17\", \"\ud83d\ude18\", \"\ud83d\ude19\", \"\ud83d\ude1a\", \"\ud83d\ude1b\", \"\ud83d\ude1c\", \"\ud83d\ude1d\", \"\ud83d\ude1e\", \"\ud83d\ude1f\", \"\ud83d\ude20\", \"\ud83d\ude21\", \"\ud83d\ude22\", \"\ud83d\ude23\", \"\ud83d\ude24\", \"\ud83d\ude25\", \"\ud83d\ude26\", \"\ud83d\ude27\", \"\ud83d\ude28\", \"\ud83d\ude29\", \"\ud83d\ude2a\", \"\ud83d\ude2b\", \"\ud83d\ude2c\", \"\ud83d\ude2d\", \"\ud83d\ude2e\", \"\ud83d\ude2e\u200d\ud83d\udca8\", \"\ud83d\ude2f\", \"\ud83d\ude30\", \"\ud83d\ude31\", \"\ud83d\ude32\", \"\ud83d\ude33\", \"\ud83d\ude34\", \"\ud83d\ude35\", \"\ud83d\ude35\u200d\ud83d\udcab\", \"\ud83d\ude36\", \"\ud83d\ude36\u200d\ud83c\udf2b\", \"\ud83d\ude36\u200d\ud83c\udf2b\ufe0f\", \"\ud83d\ude37\", \"\ud83d\ude38\", \"\ud83d\ude39\", \"\ud83d\ude3a\", \"\ud83d\ude3b\", \"\ud83d\ude3c\", \"\ud83d\ude3d\", \"\ud83d\ude3e\", \"\ud83d\ude3f\", \"\ud83d\ude40\", \"\ud83d\ude41\", \"\ud83d\ude42\", \"\ud83d\ude42\u200d\u2194\", \"\ud83d\ude42\u200d\u2194\ufe0f\", \"\ud83d\ude42\u200d\u2195\", \"\ud83d\ude42\u200d\u2195\ufe0f\", \"\ud83d\ude43\", \"\ud83d\ude44\", \"\ud83d\ude45\", \"\ud83d\ude45\u200d\u2640\", \"\ud83d\ude45\u200d\u2640\ufe0f\", \"\ud83d\ude45\u200d\u2642\", \"\ud83d\ude45\u200d\u2642\ufe0f\", \"\ud83d\ude45\ud83c\udffb\", \"\ud83d\ude45\ud83c\udffb\u200d\u2640\", \"\ud83d\ude45\ud83c\udffb\u200d\u2640\ufe0f\", \"\ud83d\ude45\ud83c\udffb\u200d\u2642\", \"\ud83d\ude45\ud83c\udffb\u200d\u2642\ufe0f\", \"\ud83d\ude45\ud83c\udffc\", \"\ud83d\ude45\ud83c\udffc\u200d\u2640\", \"\ud83d\ude45\ud83c\udffc\u200d\u2640\ufe0f\", \"\ud83d\ude45\ud83c\udffc\u200d\u2642\", \"\ud83d\ude45\ud83c\udffc\u200d\u2642\ufe0f\", \"\ud83d\ude45\ud83c\udffd\", \"\ud83d\ude45\ud83c\udffd\u200d\u2640\", \"\ud83d\ude45\ud83c\udffd\u200d\u2640\ufe0f\", \"\ud83d\ude45\ud83c\udffd\u200d\u2642\", \"\ud83d\ude45\ud83c\udffd\u200d\u2642\ufe0f\", \"\ud83d\ude45\ud83c\udffe\", \"\ud83d\ude45\ud83c\udffe\u200d\u2640\", \"\ud83d\ude45\ud83c\udffe\u200d\u2640\ufe0f\", \"\ud83d\ude45\ud83c\udffe\u200d\u2642\", \"\ud83d\ude45\ud83c\udffe\u200d\u2642\ufe0f\", \"\ud83d\ude45\ud83c\udfff\", \"\ud83d\ude45\ud83c\udfff\u200d\u2640\", \"\ud83d\ude45\ud83c\udfff\u200d\u2640\ufe0f\", \"\ud83d\ude45\ud83c\udfff\u200d\u2642\", \"\ud83d\ude45\ud83c\udfff\u200d\u2642\ufe0f\", \"\ud83d\ude46\", \"\ud83d\ude46\u200d\u2640\", \"\ud83d\ude46\u200d\u2640\ufe0f\", \"\ud83d\ude46\u200d\u2642\", \"\ud83d\ude46\u200d\u2642\ufe0f\", \"\ud83d\ude46\ud83c\udffb\", \"\ud83d\ude46\ud83c\udffb\u200d\u2640\", \"\ud83d\ude46\ud83c\udffb\u200d\u2640\ufe0f\", \"\ud83d\ude46\ud83c\udffb\u200d\u2642\", \"\ud83d\ude46\ud83c\udffb\u200d\u2642\ufe0f\", \"\ud83d\ude46\ud83c\udffc\", \"\ud83d\ude46\ud83c\udffc\u200d\u2640\", \"\ud83d\ude46\ud83c\udffc\u200d\u2640\ufe0f\", \"\ud83d\ude46\ud83c\udffc\u200d\u2642\", \"\ud83d\ude46\ud83c\udffc\u200d\u2642\ufe0f\", \"\ud83d\ude46\ud83c\udffd\", \"\ud83d\ude46\ud83c\udffd\u200d\u2640\", \"\ud83d\ude46\ud83c\udffd\u200d\u2640\ufe0f\", \"\ud83d\ude46\ud83c\udffd\u200d\u2642\", \"\ud83d\ude46\ud83c\udffd\u200d\u2642\ufe0f\", \"\ud83d\ude46\ud83c\udffe\", \"\ud83d\ude46\ud83c\udffe\u200d\u2640\", \"\ud83d\ude46\ud83c\udffe\u200d\u2640\ufe0f\", \"\ud83d\ude46\ud83c\udffe\u200d\u2642\", \"\ud83d\ude46\ud83c\udffe\u200d\u2642\ufe0f\", \"\ud83d\ude46\ud83c\udfff\", \"\ud83d\ude46\ud83c\udfff\u200d\u2640\", \"\ud83d\ude46\ud83c\udfff\u200d\u2640\ufe0f\", \"\ud83d\ude46\ud83c\udfff\u200d\u2642\", \"\ud83d\ude46\ud83c\udfff\u200d\u2642\ufe0f\", \"\ud83d\ude47\", \"\ud83d\ude47\u200d\u2640\", \"\ud83d\ude47\u200d\u2640\ufe0f\", \"\ud83d\ude47\u200d\u2642\", \"\ud83d\ude47\u200d\u2642\ufe0f\", \"\ud83d\ude47\ud83c\udffb\", \"\ud83d\ude47\ud83c\udffb\u200d\u2640\", \"\ud83d\ude47\ud83c\udffb\u200d\u2640\ufe0f\", \"\ud83d\ude47\ud83c\udffb\u200d\u2642\", \"\ud83d\ude47\ud83c\udffb\u200d\u2642\ufe0f\", \"\ud83d\ude47\ud83c\udffc\", \"\ud83d\ude47\ud83c\udffc\u200d\u2640\", \"\ud83d\ude47\ud83c\udffc\u200d\u2640\ufe0f\", \"\ud83d\ude47\ud83c\udffc\u200d\u2642\", \"\ud83d\ude47\ud83c\udffc\u200d\u2642\ufe0f\", \"\ud83d\ude47\ud83c\udffd\", \"\ud83d\ude47\ud83c\udffd\u200d\u2640\", \"\ud83d\ude47\ud83c\udffd\u200d\u2640\ufe0f\", \"\ud83d\ude47\ud83c\udffd\u200d\u2642\", \"\ud83d\ude47\ud83c\udffd\u200d\u2642\ufe0f\", \"\ud83d\ude47\ud83c\udffe\", \"\ud83d\ude47\ud83c\udffe\u200d\u2640\", \"\ud83d\ude47\ud83c\udffe\u200d\u2640\ufe0f\", \"\ud83d\ude47\ud83c\udffe\u200d\u2642\", \"\ud83d\ude47\ud83c\udffe\u200d\u2642\ufe0f\", \"\ud83d\ude47\ud83c\udfff\", \"\ud83d\ude47\ud83c\udfff\u200d\u2640\", \"\ud83d\ude47\ud83c\udfff\u200d\u2640\ufe0f\", \"\ud83d\ude47\ud83c\udfff\u200d\u2642\", \"\ud83d\ude47\ud83c\udfff\u200d\u2642\ufe0f\", \"\ud83d\ude48\", \"\ud83d\ude49\", \"\ud83d\ude4a\", \"\ud83d\ude4b\", \"\ud83d\ude4b\u200d\u2640\", \"\ud83d\ude4b\u200d\u2640\ufe0f\", \"\ud83d\ude4b\u200d\u2642\", \"\ud83d\ude4b\u200d\u2642\ufe0f\", \"\ud83d\ude4b\ud83c\udffb\", \"\ud83d\ude4b\ud83c\udffb\u200d\u2640\", \"\ud83d\ude4b\ud83c\udffb\u200d\u2640\ufe0f\", \"\ud83d\ude4b\ud83c\udffb\u200d\u2642\", \"\ud83d\ude4b\ud83c\udffb\u200d\u2642\ufe0f\", \"\ud83d\ude4b\ud83c\udffc\", \"\ud83d\ude4b\ud83c\udffc\u200d\u2640\", \"\ud83d\ude4b\ud83c\udffc\u200d\u2640\ufe0f\", \"\ud83d\ude4b\ud83c\udffc\u200d\u2642\", \"\ud83d\ude4b\ud83c\udffc\u200d\u2642\ufe0f\", \"\ud83d\ude4b\ud83c\udffd\", \"\ud83d\ude4b\ud83c\udffd\u200d\u2640\", \"\ud83d\ude4b\ud83c\udffd\u200d\u2640\ufe0f\", \"\ud83d\ude4b\ud83c\udffd\u200d\u2642\", \"\ud83d\ude4b\ud83c\udffd\u200d\u2642\ufe0f\", \"\ud83d\ude4b\ud83c\udffe\", \"\ud83d\ude4b\ud83c\udffe\u200d\u2640\", \"\ud83d\ude4b\ud83c\udffe\u200d\u2640\ufe0f\", \"\ud83d\ude4b\ud83c\udffe\u200d\u2642\", \"\ud83d\ude4b\ud83c\udffe\u200d\u2642\ufe0f\", \"\ud83d\ude4b\ud83c\udfff\", \"\ud83d\ude4b\ud83c\udfff\u200d\u2640\", \"\ud83d\ude4b\ud83c\udfff\u200d\u2640\ufe0f\", \"\ud83d\ude4b\ud83c\udfff\u200d\u2642\", \"\ud83d\ude4b\ud83c\udfff\u200d\u2642\ufe0f\", \"\ud83d\ude4c\", \"\ud83d\ude4c\ud83c\udffb\", \"\ud83d\ude4c\ud83c\udffc\", \"\ud83d\ude4c\ud83c\udffd\", \"\ud83d\ude4c\ud83c\udffe\", \"\ud83d\ude4c\ud83c\udfff\", \"\ud83d\ude4d\", \"\ud83d\ude4d\u200d\u2640\", \"\ud83d\ude4d\u200d\u2640\ufe0f\", \"\ud83d\ude4d\u200d\u2642\", \"\ud83d\ude4d\u200d\u2642\ufe0f\", \"\ud83d\ude4d\ud83c\udffb\", \"\ud83d\ude4d\ud83c\udffb\u200d\u2640\", \"\ud83d\ude4d\ud83c\udffb\u200d\u2640\ufe0f\", \"\ud83d\ude4d\ud83c\udffb\u200d\u2642\", \"\ud83d\ude4d\ud83c\udffb\u200d\u2642\ufe0f\", \"\ud83d\ude4d\ud83c\udffc\", \"\ud83d\ude4d\ud83c\udffc\u200d\u2640\", \"\ud83d\ude4d\ud83c\udffc\u200d\u2640\ufe0f\", \"\ud83d\ude4d\ud83c\udffc\u200d\u2642\", \"\ud83d\ude4d\ud83c\udffc\u200d\u2642\ufe0f\", \"\ud83d\ude4d\ud83c\udffd\", \"\ud83d\ude4d\ud83c\udffd\u200d\u2640\", \"\ud83d\ude4d\ud83c\udffd\u200d\u2640\ufe0f\", \"\ud83d\ude4d\ud83c\udffd\u200d\u2642\", \"\ud83d\ude4d\ud83c\udffd\u200d\u2642\ufe0f\", \"\ud83d\ude4d\ud83c\udffe\", \"\ud83d\ude4d\ud83c\udffe\u200d\u2640\", \"\ud83d\ude4d\ud83c\udffe\u200d\u2640\ufe0f\", \"\ud83d\ude4d\ud83c\udffe\u200d\u2642\", \"\ud83d\ude4d\ud83c\udffe\u200d\u2642\ufe0f\", \"\ud83d\ude4d\ud83c\udfff\", \"\ud83d\ude4d\ud83c\udfff\u200d\u2640\", \"\ud83d\ude4d\ud83c\udfff\u200d\u2640\ufe0f\", \"\ud83d\ude4d\ud83c\udfff\u200d\u2642\", \"\ud83d\ude4d\ud83c\udfff\u200d\u2642\ufe0f\", \"\ud83d\ude4e\", \"\ud83d\ude4e\u200d\u2640\", \"\ud83d\ude4e\u200d\u2640\ufe0f\", \"\ud83d\ude4e\u200d\u2642\", \"\ud83d\ude4e\u200d\u2642\ufe0f\", \"\ud83d\ude4e\ud83c\udffb\", \"\ud83d\ude4e\ud83c\udffb\u200d\u2640\", \"\ud83d\ude4e\ud83c\udffb\u200d\u2640\ufe0f\", \"\ud83d\ude4e\ud83c\udffb\u200d\u2642\", \"\ud83d\ude4e\ud83c\udffb\u200d\u2642\ufe0f\", \"\ud83d\ude4e\ud83c\udffc\", \"\ud83d\ude4e\ud83c\udffc\u200d\u2640\", \"\ud83d\ude4e\ud83c\udffc\u200d\u2640\ufe0f\", \"\ud83d\ude4e\ud83c\udffc\u200d\u2642\", \"\ud83d\ude4e\ud83c\udffc\u200d\u2642\ufe0f\", \"\ud83d\ude4e\ud83c\udffd\", \"\ud83d\ude4e\ud83c\udffd\u200d\u2640\", \"\ud83d\ude4e\ud83c\udffd\u200d\u2640\ufe0f\", \"\ud83d\ude4e\ud83c\udffd\u200d\u2642\", \"\ud83d\ude4e\ud83c\udffd\u200d\u2642\ufe0f\", \"\ud83d\ude4e\ud83c\udffe\", \"\ud83d\ude4e\ud83c\udffe\u200d\u2640\", \"\ud83d\ude4e\ud83c\udffe\u200d\u2640\ufe0f\", \"\ud83d\ude4e\ud83c\udffe\u200d\u2642\", \"\ud83d\ude4e\ud83c\udffe\u200d\u2642\ufe0f\", \"\ud83d\ude4e\ud83c\udfff\", \"\ud83d\ude4e\ud83c\udfff\u200d\u2640\", \"\ud83d\ude4e\ud83c\udfff\u200d\u2640\ufe0f\", \"\ud83d\ude4e\ud83c\udfff\u200d\u2642\", \"\ud83d\ude4e\ud83c\udfff\u200d\u2642\ufe0f\", \"\ud83d\ude4f\", \"\ud83d\ude4f\ud83c\udffb\", \"\ud83d\ude4f\ud83c\udffc\", \"\ud83d\ude4f\ud83c\udffd\", \"\ud83d\ude4f\ud83c\udffe\", \"\ud83d\ude4f\ud83c\udfff\", \"\ud83d\ude80\", \"\ud83d\ude81\", \"\ud83d\ude82\", \"\ud83d\ude83\", \"\ud83d\ude84\", \"\ud83d\ude85\", \"\ud83d\ude86\", \"\ud83d\ude87\", \"\ud83d\ude88\", \"\ud83d\ude89\", \"\ud83d\ude8a\", \"\ud83d\ude8b\", \"\ud83d\ude8c\", \"\ud83d\ude8d\", \"\ud83d\ude8e\", \"\ud83d\ude8f\", \"\ud83d\ude90\", \"\ud83d\ude91\", \"\ud83d\ude92\", \"\ud83d\ude93\", \"\ud83d\ude94\", \"\ud83d\ude95\", \"\ud83d\ude96\", \"\ud83d\ude97\", \"\ud83d\ude98\", \"\ud83d\ude99\", \"\ud83d\ude9a\", \"\ud83d\ude9b\", \"\ud83d\ude9c\", \"\ud83d\ude9d\", \"\ud83d\ude9e\", \"\ud83d\ude9f\", \"\ud83d\udea0\", \"\ud83d\udea1\", \"\ud83d\udea2\", \"\ud83d\udea3\", \"\ud83d\udea3\u200d\u2640\", \"\ud83d\udea3\u200d\u2640\ufe0f\", \"\ud83d\udea3\u200d\u2642\", \"\ud83d\udea3\u200d\u2642\ufe0f\", \"\ud83d\udea3\ud83c\udffb\", \"\ud83d\udea3\ud83c\udffb\u200d\u2640\", \"\ud83d\udea3\ud83c\udffb\u200d\u2640\ufe0f\", \"\ud83d\udea3\ud83c\udffb\u200d\u2642\", \"\ud83d\udea3\ud83c\udffb\u200d\u2642\ufe0f\", \"\ud83d\udea3\ud83c\udffc\", \"\ud83d\udea3\ud83c\udffc\u200d\u2640\", \"\ud83d\udea3\ud83c\udffc\u200d\u2640\ufe0f\", \"\ud83d\udea3\ud83c\udffc\u200d\u2642\", \"\ud83d\udea3\ud83c\udffc\u200d\u2642\ufe0f\", \"\ud83d\udea3\ud83c\udffd\", \"\ud83d\udea3\ud83c\udffd\u200d\u2640\", \"\ud83d\udea3\ud83c\udffd\u200d\u2640\ufe0f\", \"\ud83d\udea3\ud83c\udffd\u200d\u2642\", \"\ud83d\udea3\ud83c\udffd\u200d\u2642\ufe0f\", \"\ud83d\udea3\ud83c\udffe\", \"\ud83d\udea3\ud83c\udffe\u200d\u2640\", \"\ud83d\udea3\ud83c\udffe\u200d\u2640\ufe0f\", \"\ud83d\udea3\ud83c\udffe\u200d\u2642\", \"\ud83d\udea3\ud83c\udffe\u200d\u2642\ufe0f\", \"\ud83d\udea3\ud83c\udfff\", \"\ud83d\udea3\ud83c\udfff\u200d\u2640\", \"\ud83d\udea3\ud83c\udfff\u200d\u2640\ufe0f\", \"\ud83d\udea3\ud83c\udfff\u200d\u2642\", \"\ud83d\udea3\ud83c\udfff\u200d\u2642\ufe0f\", \"\ud83d\udea4\", \"\ud83d\udea5\", \"\ud83d\udea6\", \"\ud83d\udea7\", \"\ud83d\udea8\", \"\ud83d\udea9\", \"\ud83d\udeaa\", \"\ud83d\udeab\", \"\ud83d\udeac\", \"\ud83d\udead\", \"\ud83d\udeae\", \"\ud83d\udeaf\", \"\ud83d\udeb0\", \"\ud83d\udeb1\", \"\ud83d\udeb2\", \"\ud83d\udeb3\", \"\ud83d\udeb4\", \"\ud83d\udeb4\u200d\u2640\", \"\ud83d\udeb4\u200d\u2640\ufe0f\", \"\ud83d\udeb4\u200d\u2642\", \"\ud83d\udeb4\u200d\u2642\ufe0f\", \"\ud83d\udeb4\ud83c\udffb\", \"\ud83d\udeb4\ud83c\udffb\u200d\u2640\", \"\ud83d\udeb4\ud83c\udffb\u200d\u2640\ufe0f\", \"\ud83d\udeb4\ud83c\udffb\u200d\u2642\", \"\ud83d\udeb4\ud83c\udffb\u200d\u2642\ufe0f\", \"\ud83d\udeb4\ud83c\udffc\", \"\ud83d\udeb4\ud83c\udffc\u200d\u2640\", \"\ud83d\udeb4\ud83c\udffc\u200d\u2640\ufe0f\", \"\ud83d\udeb4\ud83c\udffc\u200d\u2642\", \"\ud83d\udeb4\ud83c\udffc\u200d\u2642\ufe0f\", \"\ud83d\udeb4\ud83c\udffd\", \"\ud83d\udeb4\ud83c\udffd\u200d\u2640\", \"\ud83d\udeb4\ud83c\udffd\u200d\u2640\ufe0f\", \"\ud83d\udeb4\ud83c\udffd\u200d\u2642\", \"\ud83d\udeb4\ud83c\udffd\u200d\u2642\ufe0f\", \"\ud83d\udeb4\ud83c\udffe\", \"\ud83d\udeb4\ud83c\udffe\u200d\u2640\", \"\ud83d\udeb4\ud83c\udffe\u200d\u2640\ufe0f\", \"\ud83d\udeb4\ud83c\udffe\u200d\u2642\", \"\ud83d\udeb4\ud83c\udffe\u200d\u2642\ufe0f\", \"\ud83d\udeb4\ud83c\udfff\", \"\ud83d\udeb4\ud83c\udfff\u200d\u2640\", \"\ud83d\udeb4\ud83c\udfff\u200d\u2640\ufe0f\", \"\ud83d\udeb4\ud83c\udfff\u200d\u2642\", \"\ud83d\udeb4\ud83c\udfff\u200d\u2642\ufe0f\", \"\ud83d\udeb5\", \"\ud83d\udeb5\u200d\u2640\", \"\ud83d\udeb5\u200d\u2640\ufe0f\", \"\ud83d\udeb5\u200d\u2642\", \"\ud83d\udeb5\u200d\u2642\ufe0f\", \"\ud83d\udeb5\ud83c\udffb\", \"\ud83d\udeb5\ud83c\udffb\u200d\u2640\", \"\ud83d\udeb5\ud83c\udffb\u200d\u2640\ufe0f\", \"\ud83d\udeb5\ud83c\udffb\u200d\u2642\", \"\ud83d\udeb5\ud83c\udffb\u200d\u2642\ufe0f\", \"\ud83d\udeb5\ud83c\udffc\", \"\ud83d\udeb5\ud83c\udffc\u200d\u2640\", \"\ud83d\udeb5\ud83c\udffc\u200d\u2640\ufe0f\", \"\ud83d\udeb5\ud83c\udffc\u200d\u2642\", \"\ud83d\udeb5\ud83c\udffc\u200d\u2642\ufe0f\", \"\ud83d\udeb5\ud83c\udffd\", \"\ud83d\udeb5\ud83c\udffd\u200d\u2640\", \"\ud83d\udeb5\ud83c\udffd\u200d\u2640\ufe0f\", \"\ud83d\udeb5\ud83c\udffd\u200d\u2642\", \"\ud83d\udeb5\ud83c\udffd\u200d\u2642\ufe0f\", \"\ud83d\udeb5\ud83c\udffe\", \"\ud83d\udeb5\ud83c\udffe\u200d\u2640\", \"\ud83d\udeb5\ud83c\udffe\u200d\u2640\ufe0f\", \"\ud83d\udeb5\ud83c\udffe\u200d\u2642\", \"\ud83d\udeb5\ud83c\udffe\u200d\u2642\ufe0f\", \"\ud83d\udeb5\ud83c\udfff\", \"\ud83d\udeb5\ud83c\udfff\u200d\u2640\", \"\ud83d\udeb5\ud83c\udfff\u200d\u2640\ufe0f\", \"\ud83d\udeb5\ud83c\udfff\u200d\u2642\", \"\ud83d\udeb5\ud83c\udfff\u200d\u2642\ufe0f\", \"\ud83d\udeb6\", \"\ud83d\udeb6\u200d\u2640\", \"\ud83d\udeb6\u200d\u2640\u200d\u27a1\", \"\ud83d\udeb6\u200d\u2640\u200d\u27a1\ufe0f\", \"\ud83d\udeb6\u200d\u2640\ufe0f\", \"\ud83d\udeb6\u200d\u2640\ufe0f\u200d\u27a1\", \"\ud83d\udeb6\u200d\u2640\ufe0f\u200d\u27a1\ufe0f\", \"\ud83d\udeb6\u200d\u2642\", \"\ud83d\udeb6\u200d\u2642\u200d\u27a1\", \"\ud83d\udeb6\u200d\u2642\u200d\u27a1\ufe0f\", \"\ud83d\udeb6\u200d\u2642\ufe0f\", \"\ud83d\udeb6\u200d\u2642\ufe0f\u200d\u27a1\", \"\ud83d\udeb6\u200d\u2642\ufe0f\u200d\u27a1\ufe0f\", \"\ud83d\udeb6\u200d\u27a1\", \"\ud83d\udeb6\u200d\u27a1\ufe0f\", \"\ud83d\udeb6\ud83c\udffb\", \"\ud83d\udeb6\ud83c\udffb\u200d\u2640\", \"\ud83d\udeb6\ud83c\udffb\u200d\u2640\u200d\u27a1\", \"\ud83d\udeb6\ud83c\udffb\u200d\u2640\u200d\u27a1\ufe0f\", \"\ud83d\udeb6\ud83c\udffb\u200d\u2640\ufe0f\", \"\ud83d\udeb6\ud83c\udffb\u200d\u2640\ufe0f\u200d\u27a1\", \"\ud83d\udeb6\ud83c\udffb\u200d\u2640\ufe0f\u200d\u27a1\ufe0f\", \"\ud83d\udeb6\ud83c\udffb\u200d\u2642\", \"\ud83d\udeb6\ud83c\udffb\u200d\u2642\u200d\u27a1\", \"\ud83d\udeb6\ud83c\udffb\u200d\u2642\u200d\u27a1\ufe0f\", \"\ud83d\udeb6\ud83c\udffb\u200d\u2642\ufe0f\", \"\ud83d\udeb6\ud83c\udffb\u200d\u2642\ufe0f\u200d\u27a1\", \"\ud83d\udeb6\ud83c\udffb\u200d\u2642\ufe0f\u200d\u27a1\ufe0f\", \"\ud83d\udeb6\ud83c\udffb\u200d\u27a1\", \"\ud83d\udeb6\ud83c\udffb\u200d\u27a1\ufe0f\", \"\ud83d\udeb6\ud83c\udffc\", \"\ud83d\udeb6\ud83c\udffc\u200d\u2640\", \"\ud83d\udeb6\ud83c\udffc\u200d\u2640\u200d\u27a1\", \"\ud83d\udeb6\ud83c\udffc\u200d\u2640\u200d\u27a1\ufe0f\", \"\ud83d\udeb6\ud83c\udffc\u200d\u2640\ufe0f\", \"\ud83d\udeb6\ud83c\udffc\u200d\u2640\ufe0f\u200d\u27a1\", \"\ud83d\udeb6\ud83c\udffc\u200d\u2640\ufe0f\u200d\u27a1\ufe0f\", \"\ud83d\udeb6\ud83c\udffc\u200d\u2642\", \"\ud83d\udeb6\ud83c\udffc\u200d\u2642\u200d\u27a1\", \"\ud83d\udeb6\ud83c\udffc\u200d\u2642\u200d\u27a1\ufe0f\", \"\ud83d\udeb6\ud83c\udffc\u200d\u2642\ufe0f\", \"\ud83d\udeb6\ud83c\udffc\u200d\u2642\ufe0f\u200d\u27a1\", \"\ud83d\udeb6\ud83c\udffc\u200d\u2642\ufe0f\u200d\u27a1\ufe0f\", \"\ud83d\udeb6\ud83c\udffc\u200d\u27a1\", \"\ud83d\udeb6\ud83c\udffc\u200d\u27a1\ufe0f\", \"\ud83d\udeb6\ud83c\udffd\", \"\ud83d\udeb6\ud83c\udffd\u200d\u2640\", \"\ud83d\udeb6\ud83c\udffd\u200d\u2640\u200d\u27a1\", \"\ud83d\udeb6\ud83c\udffd\u200d\u2640\u200d\u27a1\ufe0f\", \"\ud83d\udeb6\ud83c\udffd\u200d\u2640\ufe0f\", \"\ud83d\udeb6\ud83c\udffd\u200d\u2640\ufe0f\u200d\u27a1\", \"\ud83d\udeb6\ud83c\udffd\u200d\u2640\ufe0f\u200d\u27a1\ufe0f\", \"\ud83d\udeb6\ud83c\udffd\u200d\u2642\", \"\ud83d\udeb6\ud83c\udffd\u200d\u2642\u200d\u27a1\", \"\ud83d\udeb6\ud83c\udffd\u200d\u2642\u200d\u27a1\ufe0f\", \"\ud83d\udeb6\ud83c\udffd\u200d\u2642\ufe0f\", \"\ud83d\udeb6\ud83c\udffd\u200d\u2642\ufe0f\u200d\u27a1\", \"\ud83d\udeb6\ud83c\udffd\u200d\u2642\ufe0f\u200d\u27a1\ufe0f\", \"\ud83d\udeb6\ud83c\udffd\u200d\u27a1\", \"\ud83d\udeb6\ud83c\udffd\u200d\u27a1\ufe0f\", \"\ud83d\udeb6\ud83c\udffe\", \"\ud83d\udeb6\ud83c\udffe\u200d\u2640\", \"\ud83d\udeb6\ud83c\udffe\u200d\u2640\u200d\u27a1\", \"\ud83d\udeb6\ud83c\udffe\u200d\u2640\u200d\u27a1\ufe0f\", \"\ud83d\udeb6\ud83c\udffe\u200d\u2640\ufe0f\", \"\ud83d\udeb6\ud83c\udffe\u200d\u2640\ufe0f\u200d\u27a1\", \"\ud83d\udeb6\ud83c\udffe\u200d\u2640\ufe0f\u200d\u27a1\ufe0f\", \"\ud83d\udeb6\ud83c\udffe\u200d\u2642\", \"\ud83d\udeb6\ud83c\udffe\u200d\u2642\u200d\u27a1\", \"\ud83d\udeb6\ud83c\udffe\u200d\u2642\u200d\u27a1\ufe0f\", \"\ud83d\udeb6\ud83c\udffe\u200d\u2642\ufe0f\", \"\ud83d\udeb6\ud83c\udffe\u200d\u2642\ufe0f\u200d\u27a1\", \"\ud83d\udeb6\ud83c\udffe\u200d\u2642\ufe0f\u200d\u27a1\ufe0f\", \"\ud83d\udeb6\ud83c\udffe\u200d\u27a1\", \"\ud83d\udeb6\ud83c\udffe\u200d\u27a1\ufe0f\", \"\ud83d\udeb6\ud83c\udfff\", \"\ud83d\udeb6\ud83c\udfff\u200d\u2640\", \"\ud83d\udeb6\ud83c\udfff\u200d\u2640\u200d\u27a1\", \"\ud83d\udeb6\ud83c\udfff\u200d\u2640\u200d\u27a1\ufe0f\", \"\ud83d\udeb6\ud83c\udfff\u200d\u2640\ufe0f\", \"\ud83d\udeb6\ud83c\udfff\u200d\u2640\ufe0f\u200d\u27a1\", \"\ud83d\udeb6\ud83c\udfff\u200d\u2640\ufe0f\u200d\u27a1\ufe0f\", \"\ud83d\udeb6\ud83c\udfff\u200d\u2642\", \"\ud83d\udeb6\ud83c\udfff\u200d\u2642\u200d\u27a1\", \"\ud83d\udeb6\ud83c\udfff\u200d\u2642\u200d\u27a1\ufe0f\", \"\ud83d\udeb6\ud83c\udfff\u200d\u2642\ufe0f\", \"\ud83d\udeb6\ud83c\udfff\u200d\u2642\ufe0f\u200d\u27a1\", \"\ud83d\udeb6\ud83c\udfff\u200d\u2642\ufe0f\u200d\u27a1\ufe0f\", \"\ud83d\udeb6\ud83c\udfff\u200d\u27a1\", \"\ud83d\udeb6\ud83c\udfff\u200d\u27a1\ufe0f\", \"\ud83d\udeb7\", \"\ud83d\udeb8\", \"\ud83d\udeb9\", \"\ud83d\udeba\", \"\ud83d\udebb\", \"\ud83d\udebc\", \"\ud83d\udebd\", \"\ud83d\udebe\", \"\ud83d\udebf\", \"\ud83d\udec0\", \"\ud83d\udec0\ud83c\udffb\", \"\ud83d\udec0\ud83c\udffc\", \"\ud83d\udec0\ud83c\udffd\", \"\ud83d\udec0\ud83c\udffe\", \"\ud83d\udec0\ud83c\udfff\", \"\ud83d\udec1\", \"\ud83d\udec2\", \"\ud83d\udec3\", \"\ud83d\udec4\", \"\ud83d\udec5\", \"\ud83d\udecb\", \"\ud83d\udecb\ufe0f\", \"\ud83d\udecc\", \"\ud83d\udecc\ud83c\udffb\", \"\ud83d\udecc\ud83c\udffc\", \"\ud83d\udecc\ud83c\udffd\", \"\ud83d\udecc\ud83c\udffe\", \"\ud83d\udecc\ud83c\udfff\", \"\ud83d\udecd\", \"\ud83d\udecd\ufe0f\", \"\ud83d\udece\", \"\ud83d\udece\ufe0f\", \"\ud83d\udecf\", \"\ud83d\udecf\ufe0f\", \"\ud83d\uded0\", \"\ud83d\uded1\", \"\ud83d\uded2\", \"\ud83d\uded5\", \"\ud83d\uded6\", \"\ud83d\uded7\", \"\ud83d\udedc\", \"\ud83d\udedd\", \"\ud83d\udede\", \"\ud83d\udedf\", \"\ud83d\udee0\", \"\ud83d\udee0\ufe0f\", \"\ud83d\udee1\", \"\ud83d\udee1\ufe0f\", \"\ud83d\udee2\", \"\ud83d\udee2\ufe0f\", \"\ud83d\udee3\", \"\ud83d\udee3\ufe0f\", \"\ud83d\udee4\", \"\ud83d\udee4\ufe0f\", \"\ud83d\udee5\", \"\ud83d\udee5\ufe0f\", \"\ud83d\udee9\", \"\ud83d\udee9\ufe0f\", \"\ud83d\udeeb\", \"\ud83d\udeec\", \"\ud83d\udef0\", \"\ud83d\udef0\ufe0f\", \"\ud83d\udef3\", \"\ud83d\udef3\ufe0f\", \"\ud83d\udef4\", \"\ud83d\udef5\", \"\ud83d\udef6\", \"\ud83d\udef7\", \"\ud83d\udef8\", \"\ud83d\udef9\", \"\ud83d\udefa\", \"\ud83d\udefb\", \"\ud83d\udefc\", \"\ud83d\udfe0\", \"\ud83d\udfe1\", \"\ud83d\udfe2\", \"\ud83d\udfe3\", \"\ud83d\udfe4\", \"\ud83d\udfe5\", \"\ud83d\udfe6\", \"\ud83d\udfe7\", \"\ud83d\udfe8\", \"\ud83d\udfe9\", \"\ud83d\udfea\", \"\ud83d\udfeb\", \"\ud83d\udff0\", \"\ud83e\udd0c\", \"\ud83e\udd0c\ud83c\udffb\", \"\ud83e\udd0c\ud83c\udffc\", \"\ud83e\udd0c\ud83c\udffd\", \"\ud83e\udd0c\ud83c\udffe\", \"\ud83e\udd0c\ud83c\udfff\", \"\ud83e\udd0d\", \"\ud83e\udd0e\", \"\ud83e\udd0f\", \"\ud83e\udd0f\ud83c\udffb\", \"\ud83e\udd0f\ud83c\udffc\", \"\ud83e\udd0f\ud83c\udffd\", \"\ud83e\udd0f\ud83c\udffe\", \"\ud83e\udd0f\ud83c\udfff\", \"\ud83e\udd10\", \"\ud83e\udd11\", \"\ud83e\udd12\", \"\ud83e\udd13\", \"\ud83e\udd14\", \"\ud83e\udd15\", \"\ud83e\udd16\", \"\ud83e\udd17\", \"\ud83e\udd18\", \"\ud83e\udd18\ud83c\udffb\", \"\ud83e\udd18\ud83c\udffc\", \"\ud83e\udd18\ud83c\udffd\", \"\ud83e\udd18\ud83c\udffe\", \"\ud83e\udd18\ud83c\udfff\", \"\ud83e\udd19\", \"\ud83e\udd19\ud83c\udffb\", \"\ud83e\udd19\ud83c\udffc\", \"\ud83e\udd19\ud83c\udffd\", \"\ud83e\udd19\ud83c\udffe\", \"\ud83e\udd19\ud83c\udfff\", \"\ud83e\udd1a\", \"\ud83e\udd1a\ud83c\udffb\", \"\ud83e\udd1a\ud83c\udffc\", \"\ud83e\udd1a\ud83c\udffd\", \"\ud83e\udd1a\ud83c\udffe\", \"\ud83e\udd1a\ud83c\udfff\", \"\ud83e\udd1b\", \"\ud83e\udd1b\ud83c\udffb\", \"\ud83e\udd1b\ud83c\udffc\", \"\ud83e\udd1b\ud83c\udffd\", \"\ud83e\udd1b\ud83c\udffe\", \"\ud83e\udd1b\ud83c\udfff\", \"\ud83e\udd1c\", \"\ud83e\udd1c\ud83c\udffb\", \"\ud83e\udd1c\ud83c\udffc\", \"\ud83e\udd1c\ud83c\udffd\", \"\ud83e\udd1c\ud83c\udffe\", \"\ud83e\udd1c\ud83c\udfff\", \"\ud83e\udd1d\", \"\ud83e\udd1d\ud83c\udffb\", \"\ud83e\udd1d\ud83c\udffc\", \"\ud83e\udd1d\ud83c\udffd\", \"\ud83e\udd1d\ud83c\udffe\", \"\ud83e\udd1d\ud83c\udfff\", \"\ud83e\udd1e\", \"\ud83e\udd1e\ud83c\udffb\", \"\ud83e\udd1e\ud83c\udffc\", \"\ud83e\udd1e\ud83c\udffd\", \"\ud83e\udd1e\ud83c\udffe\", \"\ud83e\udd1e\ud83c\udfff\", \"\ud83e\udd1f\", \"\ud83e\udd1f\ud83c\udffb\", \"\ud83e\udd1f\ud83c\udffc\", \"\ud83e\udd1f\ud83c\udffd\", \"\ud83e\udd1f\ud83c\udffe\", \"\ud83e\udd1f\ud83c\udfff\", \"\ud83e\udd20\", \"\ud83e\udd21\", \"\ud83e\udd22\", \"\ud83e\udd23\", \"\ud83e\udd24\", \"\ud83e\udd25\", \"\ud83e\udd26\", \"\ud83e\udd26\u200d\u2640\", \"\ud83e\udd26\u200d\u2640\ufe0f\", \"\ud83e\udd26\u200d\u2642\", \"\ud83e\udd26\u200d\u2642\ufe0f\", \"\ud83e\udd26\ud83c\udffb\", \"\ud83e\udd26\ud83c\udffb\u200d\u2640\", \"\ud83e\udd26\ud83c\udffb\u200d\u2640\ufe0f\", \"\ud83e\udd26\ud83c\udffb\u200d\u2642\", \"\ud83e\udd26\ud83c\udffb\u200d\u2642\ufe0f\", \"\ud83e\udd26\ud83c\udffc\", \"\ud83e\udd26\ud83c\udffc\u200d\u2640\", \"\ud83e\udd26\ud83c\udffc\u200d\u2640\ufe0f\", \"\ud83e\udd26\ud83c\udffc\u200d\u2642\", \"\ud83e\udd26\ud83c\udffc\u200d\u2642\ufe0f\", \"\ud83e\udd26\ud83c\udffd\", \"\ud83e\udd26\ud83c\udffd\u200d\u2640\", \"\ud83e\udd26\ud83c\udffd\u200d\u2640\ufe0f\", \"\ud83e\udd26\ud83c\udffd\u200d\u2642\", \"\ud83e\udd26\ud83c\udffd\u200d\u2642\ufe0f\", \"\ud83e\udd26\ud83c\udffe\", \"\ud83e\udd26\ud83c\udffe\u200d\u2640\", \"\ud83e\udd26\ud83c\udffe\u200d\u2640\ufe0f\", \"\ud83e\udd26\ud83c\udffe\u200d\u2642\", \"\ud83e\udd26\ud83c\udffe\u200d\u2642\ufe0f\", \"\ud83e\udd26\ud83c\udfff\", \"\ud83e\udd26\ud83c\udfff\u200d\u2640\", \"\ud83e\udd26\ud83c\udfff\u200d\u2640\ufe0f\", \"\ud83e\udd26\ud83c\udfff\u200d\u2642\", \"\ud83e\udd26\ud83c\udfff\u200d\u2642\ufe0f\", \"\ud83e\udd27\", \"\ud83e\udd28\", \"\ud83e\udd29\", \"\ud83e\udd2a\", \"\ud83e\udd2b\", \"\ud83e\udd2c\", \"\ud83e\udd2d\", \"\ud83e\udd2e\", \"\ud83e\udd2f\", \"\ud83e\udd30\", \"\ud83e\udd30\ud83c\udffb\", \"\ud83e\udd30\ud83c\udffc\", \"\ud83e\udd30\ud83c\udffd\", \"\ud83e\udd30\ud83c\udffe\", \"\ud83e\udd30\ud83c\udfff\", \"\ud83e\udd31\", \"\ud83e\udd31\ud83c\udffb\", \"\ud83e\udd31\ud83c\udffc\", \"\ud83e\udd31\ud83c\udffd\", \"\ud83e\udd31\ud83c\udffe\", \"\ud83e\udd31\ud83c\udfff\", \"\ud83e\udd32\", \"\ud83e\udd32\ud83c\udffb\", \"\ud83e\udd32\ud83c\udffc\", \"\ud83e\udd32\ud83c\udffd\", \"\ud83e\udd32\ud83c\udffe\", \"\ud83e\udd32\ud83c\udfff\", \"\ud83e\udd33\", \"\ud83e\udd33\ud83c\udffb\", \"\ud83e\udd33\ud83c\udffc\", \"\ud83e\udd33\ud83c\udffd\", \"\ud83e\udd33\ud83c\udffe\", \"\ud83e\udd33\ud83c\udfff\", \"\ud83e\udd34\", \"\ud83e\udd34\ud83c\udffb\", \"\ud83e\udd34\ud83c\udffc\", \"\ud83e\udd34\ud83c\udffd\", \"\ud83e\udd34\ud83c\udffe\", \"\ud83e\udd34\ud83c\udfff\", \"\ud83e\udd35\", \"\ud83e\udd35\u200d\u2640\", \"\ud83e\udd35\u200d\u2640\ufe0f\", \"\ud83e\udd35\u200d\u2642\", \"\ud83e\udd35\u200d\u2642\ufe0f\", \"\ud83e\udd35\ud83c\udffb\", \"\ud83e\udd35\ud83c\udffb\u200d\u2640\", \"\ud83e\udd35\ud83c\udffb\u200d\u2640\ufe0f\", \"\ud83e\udd35\ud83c\udffb\u200d\u2642\", \"\ud83e\udd35\ud83c\udffb\u200d\u2642\ufe0f\", \"\ud83e\udd35\ud83c\udffc\", \"\ud83e\udd35\ud83c\udffc\u200d\u2640\", \"\ud83e\udd35\ud83c\udffc\u200d\u2640\ufe0f\", \"\ud83e\udd35\ud83c\udffc\u200d\u2642\", \"\ud83e\udd35\ud83c\udffc\u200d\u2642\ufe0f\", \"\ud83e\udd35\ud83c\udffd\", \"\ud83e\udd35\ud83c\udffd\u200d\u2640\", \"\ud83e\udd35\ud83c\udffd\u200d\u2640\ufe0f\", \"\ud83e\udd35\ud83c\udffd\u200d\u2642\", \"\ud83e\udd35\ud83c\udffd\u200d\u2642\ufe0f\", \"\ud83e\udd35\ud83c\udffe\", \"\ud83e\udd35\ud83c\udffe\u200d\u2640\", \"\ud83e\udd35\ud83c\udffe\u200d\u2640\ufe0f\", \"\ud83e\udd35\ud83c\udffe\u200d\u2642\", \"\ud83e\udd35\ud83c\udffe\u200d\u2642\ufe0f\", \"\ud83e\udd35\ud83c\udfff\", \"\ud83e\udd35\ud83c\udfff\u200d\u2640\", \"\ud83e\udd35\ud83c\udfff\u200d\u2640\ufe0f\", \"\ud83e\udd35\ud83c\udfff\u200d\u2642\", \"\ud83e\udd35\ud83c\udfff\u200d\u2642\ufe0f\", \"\ud83e\udd36\", \"\ud83e\udd36\ud83c\udffb\", \"\ud83e\udd36\ud83c\udffc\", \"\ud83e\udd36\ud83c\udffd\", \"\ud83e\udd36\ud83c\udffe\", \"\ud83e\udd36\ud83c\udfff\", \"\ud83e\udd37\", \"\ud83e\udd37\u200d\u2640\", \"\ud83e\udd37\u200d\u2640\ufe0f\", \"\ud83e\udd37\u200d\u2642\", \"\ud83e\udd37\u200d\u2642\ufe0f\", \"\ud83e\udd37\ud83c\udffb\", \"\ud83e\udd37\ud83c\udffb\u200d\u2640\", \"\ud83e\udd37\ud83c\udffb\u200d\u2640\ufe0f\", \"\ud83e\udd37\ud83c\udffb\u200d\u2642\", \"\ud83e\udd37\ud83c\udffb\u200d\u2642\ufe0f\", \"\ud83e\udd37\ud83c\udffc\", \"\ud83e\udd37\ud83c\udffc\u200d\u2640\", \"\ud83e\udd37\ud83c\udffc\u200d\u2640\ufe0f\", \"\ud83e\udd37\ud83c\udffc\u200d\u2642\", \"\ud83e\udd37\ud83c\udffc\u200d\u2642\ufe0f\", \"\ud83e\udd37\ud83c\udffd\", \"\ud83e\udd37\ud83c\udffd\u200d\u2640\", \"\ud83e\udd37\ud83c\udffd\u200d\u2640\ufe0f\", \"\ud83e\udd37\ud83c\udffd\u200d\u2642\", \"\ud83e\udd37\ud83c\udffd\u200d\u2642\ufe0f\", \"\ud83e\udd37\ud83c\udffe\", \"\ud83e\udd37\ud83c\udffe\u200d\u2640\", \"\ud83e\udd37\ud83c\udffe\u200d\u2640\ufe0f\", \"\ud83e\udd37\ud83c\udffe\u200d\u2642\", \"\ud83e\udd37\ud83c\udffe\u200d\u2642\ufe0f\", \"\ud83e\udd37\ud83c\udfff\", \"\ud83e\udd37\ud83c\udfff\u200d\u2640\", \"\ud83e\udd37\ud83c\udfff\u200d\u2640\ufe0f\", \"\ud83e\udd37\ud83c\udfff\u200d\u2642\", \"\ud83e\udd37\ud83c\udfff\u200d\u2642\ufe0f\", \"\ud83e\udd38\", \"\ud83e\udd38\u200d\u2640\", \"\ud83e\udd38\u200d\u2640\ufe0f\", \"\ud83e\udd38\u200d\u2642\", \"\ud83e\udd38\u200d\u2642\ufe0f\", \"\ud83e\udd38\ud83c\udffb\", \"\ud83e\udd38\ud83c\udffb\u200d\u2640\", \"\ud83e\udd38\ud83c\udffb\u200d\u2640\ufe0f\", \"\ud83e\udd38\ud83c\udffb\u200d\u2642\", \"\ud83e\udd38\ud83c\udffb\u200d\u2642\ufe0f\", \"\ud83e\udd38\ud83c\udffc\", \"\ud83e\udd38\ud83c\udffc\u200d\u2640\", \"\ud83e\udd38\ud83c\udffc\u200d\u2640\ufe0f\", \"\ud83e\udd38\ud83c\udffc\u200d\u2642\", \"\ud83e\udd38\ud83c\udffc\u200d\u2642\ufe0f\", \"\ud83e\udd38\ud83c\udffd\", \"\ud83e\udd38\ud83c\udffd\u200d\u2640\", \"\ud83e\udd38\ud83c\udffd\u200d\u2640\ufe0f\", \"\ud83e\udd38\ud83c\udffd\u200d\u2642\", \"\ud83e\udd38\ud83c\udffd\u200d\u2642\ufe0f\", \"\ud83e\udd38\ud83c\udffe\", \"\ud83e\udd38\ud83c\udffe\u200d\u2640\", \"\ud83e\udd38\ud83c\udffe\u200d\u2640\ufe0f\", \"\ud83e\udd38\ud83c\udffe\u200d\u2642\", \"\ud83e\udd38\ud83c\udffe\u200d\u2642\ufe0f\", \"\ud83e\udd38\ud83c\udfff\", \"\ud83e\udd38\ud83c\udfff\u200d\u2640\", \"\ud83e\udd38\ud83c\udfff\u200d\u2640\ufe0f\", \"\ud83e\udd38\ud83c\udfff\u200d\u2642\", \"\ud83e\udd38\ud83c\udfff\u200d\u2642\ufe0f\", \"\ud83e\udd39\", \"\ud83e\udd39\u200d\u2640\", \"\ud83e\udd39\u200d\u2640\ufe0f\", \"\ud83e\udd39\u200d\u2642\", \"\ud83e\udd39\u200d\u2642\ufe0f\", \"\ud83e\udd39\ud83c\udffb\", \"\ud83e\udd39\ud83c\udffb\u200d\u2640\", \"\ud83e\udd39\ud83c\udffb\u200d\u2640\ufe0f\", \"\ud83e\udd39\ud83c\udffb\u200d\u2642\", \"\ud83e\udd39\ud83c\udffb\u200d\u2642\ufe0f\", \"\ud83e\udd39\ud83c\udffc\", \"\ud83e\udd39\ud83c\udffc\u200d\u2640\", \"\ud83e\udd39\ud83c\udffc\u200d\u2640\ufe0f\", \"\ud83e\udd39\ud83c\udffc\u200d\u2642\", \"\ud83e\udd39\ud83c\udffc\u200d\u2642\ufe0f\", \"\ud83e\udd39\ud83c\udffd\", \"\ud83e\udd39\ud83c\udffd\u200d\u2640\", \"\ud83e\udd39\ud83c\udffd\u200d\u2640\ufe0f\", \"\ud83e\udd39\ud83c\udffd\u200d\u2642\", \"\ud83e\udd39\ud83c\udffd\u200d\u2642\ufe0f\", \"\ud83e\udd39\ud83c\udffe\", \"\ud83e\udd39\ud83c\udffe\u200d\u2640\", \"\ud83e\udd39\ud83c\udffe\u200d\u2640\ufe0f\", \"\ud83e\udd39\ud83c\udffe\u200d\u2642\", \"\ud83e\udd39\ud83c\udffe\u200d\u2642\ufe0f\", \"\ud83e\udd39\ud83c\udfff\", \"\ud83e\udd39\ud83c\udfff\u200d\u2640\", \"\ud83e\udd39\ud83c\udfff\u200d\u2640\ufe0f\", \"\ud83e\udd39\ud83c\udfff\u200d\u2642\", \"\ud83e\udd39\ud83c\udfff\u200d\u2642\ufe0f\", \"\ud83e\udd3a\", \"\ud83e\udd3c\", \"\ud83e\udd3c\u200d\u2640\", \"\ud83e\udd3c\u200d\u2640\ufe0f\", \"\ud83e\udd3c\u200d\u2642\", \"\ud83e\udd3c\u200d\u2642\ufe0f\", \"\ud83e\udd3d\", \"\ud83e\udd3d\u200d\u2640\", \"\ud83e\udd3d\u200d\u2640\ufe0f\", \"\ud83e\udd3d\u200d\u2642\", \"\ud83e\udd3d\u200d\u2642\ufe0f\", \"\ud83e\udd3d\ud83c\udffb\", \"\ud83e\udd3d\ud83c\udffb\u200d\u2640\", \"\ud83e\udd3d\ud83c\udffb\u200d\u2640\ufe0f\", \"\ud83e\udd3d\ud83c\udffb\u200d\u2642\", \"\ud83e\udd3d\ud83c\udffb\u200d\u2642\ufe0f\", \"\ud83e\udd3d\ud83c\udffc\", \"\ud83e\udd3d\ud83c\udffc\u200d\u2640\", \"\ud83e\udd3d\ud83c\udffc\u200d\u2640\ufe0f\", \"\ud83e\udd3d\ud83c\udffc\u200d\u2642\", \"\ud83e\udd3d\ud83c\udffc\u200d\u2642\ufe0f\", \"\ud83e\udd3d\ud83c\udffd\", \"\ud83e\udd3d\ud83c\udffd\u200d\u2640\", \"\ud83e\udd3d\ud83c\udffd\u200d\u2640\ufe0f\", \"\ud83e\udd3d\ud83c\udffd\u200d\u2642\", \"\ud83e\udd3d\ud83c\udffd\u200d\u2642\ufe0f\", \"\ud83e\udd3d\ud83c\udffe\", \"\ud83e\udd3d\ud83c\udffe\u200d\u2640\", \"\ud83e\udd3d\ud83c\udffe\u200d\u2640\ufe0f\", \"\ud83e\udd3d\ud83c\udffe\u200d\u2642\", \"\ud83e\udd3d\ud83c\udffe\u200d\u2642\ufe0f\", \"\ud83e\udd3d\ud83c\udfff\", \"\ud83e\udd3d\ud83c\udfff\u200d\u2640\", \"\ud83e\udd3d\ud83c\udfff\u200d\u2640\ufe0f\", \"\ud83e\udd3d\ud83c\udfff\u200d\u2642\", \"\ud83e\udd3d\ud83c\udfff\u200d\u2642\ufe0f\", \"\ud83e\udd3e\", \"\ud83e\udd3e\u200d\u2640\", \"\ud83e\udd3e\u200d\u2640\ufe0f\", \"\ud83e\udd3e\u200d\u2642\", \"\ud83e\udd3e\u200d\u2642\ufe0f\", \"\ud83e\udd3e\ud83c\udffb\", \"\ud83e\udd3e\ud83c\udffb\u200d\u2640\", \"\ud83e\udd3e\ud83c\udffb\u200d\u2640\ufe0f\", \"\ud83e\udd3e\ud83c\udffb\u200d\u2642\", \"\ud83e\udd3e\ud83c\udffb\u200d\u2642\ufe0f\", \"\ud83e\udd3e\ud83c\udffc\", \"\ud83e\udd3e\ud83c\udffc\u200d\u2640\", \"\ud83e\udd3e\ud83c\udffc\u200d\u2640\ufe0f\", \"\ud83e\udd3e\ud83c\udffc\u200d\u2642\", \"\ud83e\udd3e\ud83c\udffc\u200d\u2642\ufe0f\", \"\ud83e\udd3e\ud83c\udffd\", \"\ud83e\udd3e\ud83c\udffd\u200d\u2640\", \"\ud83e\udd3e\ud83c\udffd\u200d\u2640\ufe0f\", \"\ud83e\udd3e\ud83c\udffd\u200d\u2642\", \"\ud83e\udd3e\ud83c\udffd\u200d\u2642\ufe0f\", \"\ud83e\udd3e\ud83c\udffe\", \"\ud83e\udd3e\ud83c\udffe\u200d\u2640\", \"\ud83e\udd3e\ud83c\udffe\u200d\u2640\ufe0f\", \"\ud83e\udd3e\ud83c\udffe\u200d\u2642\", \"\ud83e\udd3e\ud83c\udffe\u200d\u2642\ufe0f\", \"\ud83e\udd3e\ud83c\udfff\", \"\ud83e\udd3e\ud83c\udfff\u200d\u2640\", \"\ud83e\udd3e\ud83c\udfff\u200d\u2640\ufe0f\", \"\ud83e\udd3e\ud83c\udfff\u200d\u2642\", \"\ud83e\udd3e\ud83c\udfff\u200d\u2642\ufe0f\", \"\ud83e\udd3f\", \"\ud83e\udd40\", \"\ud83e\udd41\", \"\ud83e\udd42\", \"\ud83e\udd43\", \"\ud83e\udd44\", \"\ud83e\udd45\", \"\ud83e\udd47\", \"\ud83e\udd48\", \"\ud83e\udd49\", \"\ud83e\udd4a\", \"\ud83e\udd4b\", \"\ud83e\udd4c\", \"\ud83e\udd4d\", \"\ud83e\udd4e\", \"\ud83e\udd4f\", \"\ud83e\udd50\", \"\ud83e\udd51\", \"\ud83e\udd52\", \"\ud83e\udd53\", \"\ud83e\udd54\", \"\ud83e\udd55\", \"\ud83e\udd56\", \"\ud83e\udd57\", \"\ud83e\udd58\", \"\ud83e\udd59\", \"\ud83e\udd5a\", \"\ud83e\udd5b\", \"\ud83e\udd5c\", \"\ud83e\udd5d\", \"\ud83e\udd5e\", \"\ud83e\udd5f\", \"\ud83e\udd60\", \"\ud83e\udd61\", \"\ud83e\udd62\", \"\ud83e\udd63\", \"\ud83e\udd64\", \"\ud83e\udd65\", \"\ud83e\udd66\", \"\ud83e\udd67\", \"\ud83e\udd68\", \"\ud83e\udd69\", \"\ud83e\udd6a\", \"\ud83e\udd6b\", \"\ud83e\udd6c\", \"\ud83e\udd6d\", \"\ud83e\udd6e\", \"\ud83e\udd6f\", \"\ud83e\udd70\", \"\ud83e\udd71\", \"\ud83e\udd72\", \"\ud83e\udd73\", \"\ud83e\udd74\", \"\ud83e\udd75\", \"\ud83e\udd76\", \"\ud83e\udd77\", \"\ud83e\udd77\ud83c\udffb\", \"\ud83e\udd77\ud83c\udffc\", \"\ud83e\udd77\ud83c\udffd\", \"\ud83e\udd77\ud83c\udffe\", \"\ud83e\udd77\ud83c\udfff\", \"\ud83e\udd78\", \"\ud83e\udd79\", \"\ud83e\udd7a\", \"\ud83e\udd7b\", \"\ud83e\udd7c\", \"\ud83e\udd7d\", \"\ud83e\udd7e\", \"\ud83e\udd7f\", \"\ud83e\udd80\", \"\ud83e\udd81\", \"\ud83e\udd82\", \"\ud83e\udd83\", \"\ud83e\udd84\", \"\ud83e\udd85\", \"\ud83e\udd86\", \"\ud83e\udd87\", \"\ud83e\udd88\", \"\ud83e\udd89\", \"\ud83e\udd8a\", \"\ud83e\udd8b\", \"\ud83e\udd8c\", \"\ud83e\udd8d\", \"\ud83e\udd8e\", \"\ud83e\udd8f\", \"\ud83e\udd90\", \"\ud83e\udd91\", \"\ud83e\udd92\", \"\ud83e\udd93\", \"\ud83e\udd94\", \"\ud83e\udd95\", \"\ud83e\udd96\", \"\ud83e\udd97\", \"\ud83e\udd98\", \"\ud83e\udd99\", \"\ud83e\udd9a\", \"\ud83e\udd9b\", \"\ud83e\udd9c\", \"\ud83e\udd9d\", \"\ud83e\udd9e\", \"\ud83e\udd9f\", \"\ud83e\udda0\", \"\ud83e\udda1\", \"\ud83e\udda2\", \"\ud83e\udda3\", \"\ud83e\udda4\", \"\ud83e\udda5\", \"\ud83e\udda6\", \"\ud83e\udda7\", \"\ud83e\udda8\", \"\ud83e\udda9\", \"\ud83e\uddaa\", \"\ud83e\uddab\", \"\ud83e\uddac\", \"\ud83e\uddad\", \"\ud83e\uddae\", \"\ud83e\uddaf\", \"\ud83e\uddb0\", \"\ud83e\uddb1\", \"\ud83e\uddb2\", \"\ud83e\uddb3\", \"\ud83e\uddb4\", \"\ud83e\uddb5\", \"\ud83e\uddb5\ud83c\udffb\", \"\ud83e\uddb5\ud83c\udffc\", \"\ud83e\uddb5\ud83c\udffd\", \"\ud83e\uddb5\ud83c\udffe\", \"\ud83e\uddb5\ud83c\udfff\", \"\ud83e\uddb6\", \"\ud83e\uddb6\ud83c\udffb\", \"\ud83e\uddb6\ud83c\udffc\", \"\ud83e\uddb6\ud83c\udffd\", \"\ud83e\uddb6\ud83c\udffe\", \"\ud83e\uddb6\ud83c\udfff\", \"\ud83e\uddb7\", \"\ud83e\uddb8\", \"\ud83e\uddb8\u200d\u2640\", \"\ud83e\uddb8\u200d\u2640\ufe0f\", \"\ud83e\uddb8\u200d\u2642\", \"\ud83e\uddb8\u200d\u2642\ufe0f\", \"\ud83e\uddb8\ud83c\udffb\", \"\ud83e\uddb8\ud83c\udffb\u200d\u2640\", \"\ud83e\uddb8\ud83c\udffb\u200d\u2640\ufe0f\", \"\ud83e\uddb8\ud83c\udffb\u200d\u2642\", \"\ud83e\uddb8\ud83c\udffb\u200d\u2642\ufe0f\", \"\ud83e\uddb8\ud83c\udffc\", \"\ud83e\uddb8\ud83c\udffc\u200d\u2640\", \"\ud83e\uddb8\ud83c\udffc\u200d\u2640\ufe0f\", \"\ud83e\uddb8\ud83c\udffc\u200d\u2642\", \"\ud83e\uddb8\ud83c\udffc\u200d\u2642\ufe0f\", \"\ud83e\uddb8\ud83c\udffd\", \"\ud83e\uddb8\ud83c\udffd\u200d\u2640\", \"\ud83e\uddb8\ud83c\udffd\u200d\u2640\ufe0f\", \"\ud83e\uddb8\ud83c\udffd\u200d\u2642\", \"\ud83e\uddb8\ud83c\udffd\u200d\u2642\ufe0f\", \"\ud83e\uddb8\ud83c\udffe\", \"\ud83e\uddb8\ud83c\udffe\u200d\u2640\", \"\ud83e\uddb8\ud83c\udffe\u200d\u2640\ufe0f\", \"\ud83e\uddb8\ud83c\udffe\u200d\u2642\", \"\ud83e\uddb8\ud83c\udffe\u200d\u2642\ufe0f\", \"\ud83e\uddb8\ud83c\udfff\", \"\ud83e\uddb8\ud83c\udfff\u200d\u2640\", \"\ud83e\uddb8\ud83c\udfff\u200d\u2640\ufe0f\", \"\ud83e\uddb8\ud83c\udfff\u200d\u2642\", \"\ud83e\uddb8\ud83c\udfff\u200d\u2642\ufe0f\", \"\ud83e\uddb9\", \"\ud83e\uddb9\u200d\u2640\", \"\ud83e\uddb9\u200d\u2640\ufe0f\", \"\ud83e\uddb9\u200d\u2642\", \"\ud83e\uddb9\u200d\u2642\ufe0f\", \"\ud83e\uddb9\ud83c\udffb\", \"\ud83e\uddb9\ud83c\udffb\u200d\u2640\", \"\ud83e\uddb9\ud83c\udffb\u200d\u2640\ufe0f\", \"\ud83e\uddb9\ud83c\udffb\u200d\u2642\", \"\ud83e\uddb9\ud83c\udffb\u200d\u2642\ufe0f\", \"\ud83e\uddb9\ud83c\udffc\", \"\ud83e\uddb9\ud83c\udffc\u200d\u2640\", \"\ud83e\uddb9\ud83c\udffc\u200d\u2640\ufe0f\", \"\ud83e\uddb9\ud83c\udffc\u200d\u2642\", \"\ud83e\uddb9\ud83c\udffc\u200d\u2642\ufe0f\", \"\ud83e\uddb9\ud83c\udffd\", \"\ud83e\uddb9\ud83c\udffd\u200d\u2640\", \"\ud83e\uddb9\ud83c\udffd\u200d\u2640\ufe0f\", \"\ud83e\uddb9\ud83c\udffd\u200d\u2642\", \"\ud83e\uddb9\ud83c\udffd\u200d\u2642\ufe0f\", \"\ud83e\uddb9\ud83c\udffe\", \"\ud83e\uddb9\ud83c\udffe\u200d\u2640\", \"\ud83e\uddb9\ud83c\udffe\u200d\u2640\ufe0f\", \"\ud83e\uddb9\ud83c\udffe\u200d\u2642\", \"\ud83e\uddb9\ud83c\udffe\u200d\u2642\ufe0f\", \"\ud83e\uddb9\ud83c\udfff\", \"\ud83e\uddb9\ud83c\udfff\u200d\u2640\", \"\ud83e\uddb9\ud83c\udfff\u200d\u2640\ufe0f\", \"\ud83e\uddb9\ud83c\udfff\u200d\u2642\", \"\ud83e\uddb9\ud83c\udfff\u200d\u2642\ufe0f\", \"\ud83e\uddba\", \"\ud83e\uddbb\", \"\ud83e\uddbb\ud83c\udffb\", \"\ud83e\uddbb\ud83c\udffc\", \"\ud83e\uddbb\ud83c\udffd\", \"\ud83e\uddbb\ud83c\udffe\", \"\ud83e\uddbb\ud83c\udfff\", \"\ud83e\uddbc\", \"\ud83e\uddbd\", \"\ud83e\uddbe\", \"\ud83e\uddbf\", \"\ud83e\uddc0\", \"\ud83e\uddc1\", \"\ud83e\uddc2\", \"\ud83e\uddc3\", \"\ud83e\uddc4\", \"\ud83e\uddc5\", \"\ud83e\uddc6\", \"\ud83e\uddc7\", \"\ud83e\uddc8\", \"\ud83e\uddc9\", \"\ud83e\uddca\", \"\ud83e\uddcb\", \"\ud83e\uddcc\", \"\ud83e\uddcd\", \"\ud83e\uddcd\u200d\u2640\", \"\ud83e\uddcd\u200d\u2640\ufe0f\", \"\ud83e\uddcd\u200d\u2642\", \"\ud83e\uddcd\u200d\u2642\ufe0f\", \"\ud83e\uddcd\ud83c\udffb\", \"\ud83e\uddcd\ud83c\udffb\u200d\u2640\", \"\ud83e\uddcd\ud83c\udffb\u200d\u2640\ufe0f\", \"\ud83e\uddcd\ud83c\udffb\u200d\u2642\", \"\ud83e\uddcd\ud83c\udffb\u200d\u2642\ufe0f\", \"\ud83e\uddcd\ud83c\udffc\", \"\ud83e\uddcd\ud83c\udffc\u200d\u2640\", \"\ud83e\uddcd\ud83c\udffc\u200d\u2640\ufe0f\", \"\ud83e\uddcd\ud83c\udffc\u200d\u2642\", \"\ud83e\uddcd\ud83c\udffc\u200d\u2642\ufe0f\", \"\ud83e\uddcd\ud83c\udffd\", \"\ud83e\uddcd\ud83c\udffd\u200d\u2640\", \"\ud83e\uddcd\ud83c\udffd\u200d\u2640\ufe0f\", \"\ud83e\uddcd\ud83c\udffd\u200d\u2642\", \"\ud83e\uddcd\ud83c\udffd\u200d\u2642\ufe0f\", \"\ud83e\uddcd\ud83c\udffe\", \"\ud83e\uddcd\ud83c\udffe\u200d\u2640\", \"\ud83e\uddcd\ud83c\udffe\u200d\u2640\ufe0f\", \"\ud83e\uddcd\ud83c\udffe\u200d\u2642\", \"\ud83e\uddcd\ud83c\udffe\u200d\u2642\ufe0f\", \"\ud83e\uddcd\ud83c\udfff\", \"\ud83e\uddcd\ud83c\udfff\u200d\u2640\", \"\ud83e\uddcd\ud83c\udfff\u200d\u2640\ufe0f\", \"\ud83e\uddcd\ud83c\udfff\u200d\u2642\", \"\ud83e\uddcd\ud83c\udfff\u200d\u2642\ufe0f\", \"\ud83e\uddce\", \"\ud83e\uddce\u200d\u2640\", \"\ud83e\uddce\u200d\u2640\u200d\u27a1\", \"\ud83e\uddce\u200d\u2640\u200d\u27a1\ufe0f\", \"\ud83e\uddce\u200d\u2640\ufe0f\", \"\ud83e\uddce\u200d\u2640\ufe0f\u200d\u27a1\", \"\ud83e\uddce\u200d\u2640\ufe0f\u200d\u27a1\ufe0f\", \"\ud83e\uddce\u200d\u2642\", \"\ud83e\uddce\u200d\u2642\u200d\u27a1\", \"\ud83e\uddce\u200d\u2642\u200d\u27a1\ufe0f\", \"\ud83e\uddce\u200d\u2642\ufe0f\", \"\ud83e\uddce\u200d\u2642\ufe0f\u200d\u27a1\", \"\ud83e\uddce\u200d\u2642\ufe0f\u200d\u27a1\ufe0f\", \"\ud83e\uddce\u200d\u27a1\", \"\ud83e\uddce\u200d\u27a1\ufe0f\", \"\ud83e\uddce\ud83c\udffb\", \"\ud83e\uddce\ud83c\udffb\u200d\u2640\", \"\ud83e\uddce\ud83c\udffb\u200d\u2640\u200d\u27a1\", \"\ud83e\uddce\ud83c\udffb\u200d\u2640\u200d\u27a1\ufe0f\", \"\ud83e\uddce\ud83c\udffb\u200d\u2640\ufe0f\", \"\ud83e\uddce\ud83c\udffb\u200d\u2640\ufe0f\u200d\u27a1\", \"\ud83e\uddce\ud83c\udffb\u200d\u2640\ufe0f\u200d\u27a1\ufe0f\", \"\ud83e\uddce\ud83c\udffb\u200d\u2642\", \"\ud83e\uddce\ud83c\udffb\u200d\u2642\u200d\u27a1\", \"\ud83e\uddce\ud83c\udffb\u200d\u2642\u200d\u27a1\ufe0f\", \"\ud83e\uddce\ud83c\udffb\u200d\u2642\ufe0f\", \"\ud83e\uddce\ud83c\udffb\u200d\u2642\ufe0f\u200d\u27a1\", \"\ud83e\uddce\ud83c\udffb\u200d\u2642\ufe0f\u200d\u27a1\ufe0f\", \"\ud83e\uddce\ud83c\udffb\u200d\u27a1\", \"\ud83e\uddce\ud83c\udffb\u200d\u27a1\ufe0f\", \"\ud83e\uddce\ud83c\udffc\", \"\ud83e\uddce\ud83c\udffc\u200d\u2640\", \"\ud83e\uddce\ud83c\udffc\u200d\u2640\u200d\u27a1\", \"\ud83e\uddce\ud83c\udffc\u200d\u2640\u200d\u27a1\ufe0f\", \"\ud83e\uddce\ud83c\udffc\u200d\u2640\ufe0f\", \"\ud83e\uddce\ud83c\udffc\u200d\u2640\ufe0f\u200d\u27a1\", \"\ud83e\uddce\ud83c\udffc\u200d\u2640\ufe0f\u200d\u27a1\ufe0f\", \"\ud83e\uddce\ud83c\udffc\u200d\u2642\", \"\ud83e\uddce\ud83c\udffc\u200d\u2642\u200d\u27a1\", \"\ud83e\uddce\ud83c\udffc\u200d\u2642\u200d\u27a1\ufe0f\", \"\ud83e\uddce\ud83c\udffc\u200d\u2642\ufe0f\", \"\ud83e\uddce\ud83c\udffc\u200d\u2642\ufe0f\u200d\u27a1\", \"\ud83e\uddce\ud83c\udffc\u200d\u2642\ufe0f\u200d\u27a1\ufe0f\", \"\ud83e\uddce\ud83c\udffc\u200d\u27a1\", \"\ud83e\uddce\ud83c\udffc\u200d\u27a1\ufe0f\", \"\ud83e\uddce\ud83c\udffd\", \"\ud83e\uddce\ud83c\udffd\u200d\u2640\", \"\ud83e\uddce\ud83c\udffd\u200d\u2640\u200d\u27a1\", \"\ud83e\uddce\ud83c\udffd\u200d\u2640\u200d\u27a1\ufe0f\", \"\ud83e\uddce\ud83c\udffd\u200d\u2640\ufe0f\", \"\ud83e\uddce\ud83c\udffd\u200d\u2640\ufe0f\u200d\u27a1\", \"\ud83e\uddce\ud83c\udffd\u200d\u2640\ufe0f\u200d\u27a1\ufe0f\", \"\ud83e\uddce\ud83c\udffd\u200d\u2642\", \"\ud83e\uddce\ud83c\udffd\u200d\u2642\u200d\u27a1\", \"\ud83e\uddce\ud83c\udffd\u200d\u2642\u200d\u27a1\ufe0f\", \"\ud83e\uddce\ud83c\udffd\u200d\u2642\ufe0f\", \"\ud83e\uddce\ud83c\udffd\u200d\u2642\ufe0f\u200d\u27a1\", \"\ud83e\uddce\ud83c\udffd\u200d\u2642\ufe0f\u200d\u27a1\ufe0f\", \"\ud83e\uddce\ud83c\udffd\u200d\u27a1\", \"\ud83e\uddce\ud83c\udffd\u200d\u27a1\ufe0f\", \"\ud83e\uddce\ud83c\udffe\", \"\ud83e\uddce\ud83c\udffe\u200d\u2640\", \"\ud83e\uddce\ud83c\udffe\u200d\u2640\u200d\u27a1\", \"\ud83e\uddce\ud83c\udffe\u200d\u2640\u200d\u27a1\ufe0f\", \"\ud83e\uddce\ud83c\udffe\u200d\u2640\ufe0f\", \"\ud83e\uddce\ud83c\udffe\u200d\u2640\ufe0f\u200d\u27a1\", \"\ud83e\uddce\ud83c\udffe\u200d\u2640\ufe0f\u200d\u27a1\ufe0f\", \"\ud83e\uddce\ud83c\udffe\u200d\u2642\", \"\ud83e\uddce\ud83c\udffe\u200d\u2642\u200d\u27a1\", \"\ud83e\uddce\ud83c\udffe\u200d\u2642\u200d\u27a1\ufe0f\", \"\ud83e\uddce\ud83c\udffe\u200d\u2642\ufe0f\", \"\ud83e\uddce\ud83c\udffe\u200d\u2642\ufe0f\u200d\u27a1\", \"\ud83e\uddce\ud83c\udffe\u200d\u2642\ufe0f\u200d\u27a1\ufe0f\", \"\ud83e\uddce\ud83c\udffe\u200d\u27a1\", \"\ud83e\uddce\ud83c\udffe\u200d\u27a1\ufe0f\", \"\ud83e\uddce\ud83c\udfff\", \"\ud83e\uddce\ud83c\udfff\u200d\u2640\", \"\ud83e\uddce\ud83c\udfff\u200d\u2640\u200d\u27a1\", \"\ud83e\uddce\ud83c\udfff\u200d\u2640\u200d\u27a1\ufe0f\", \"\ud83e\uddce\ud83c\udfff\u200d\u2640\ufe0f\", \"\ud83e\uddce\ud83c\udfff\u200d\u2640\ufe0f\u200d\u27a1\", \"\ud83e\uddce\ud83c\udfff\u200d\u2640\ufe0f\u200d\u27a1\ufe0f\", \"\ud83e\uddce\ud83c\udfff\u200d\u2642\", \"\ud83e\uddce\ud83c\udfff\u200d\u2642\u200d\u27a1\", \"\ud83e\uddce\ud83c\udfff\u200d\u2642\u200d\u27a1\ufe0f\", \"\ud83e\uddce\ud83c\udfff\u200d\u2642\ufe0f\", \"\ud83e\uddce\ud83c\udfff\u200d\u2642\ufe0f\u200d\u27a1\", \"\ud83e\uddce\ud83c\udfff\u200d\u2642\ufe0f\u200d\u27a1\ufe0f\", \"\ud83e\uddce\ud83c\udfff\u200d\u27a1\", \"\ud83e\uddce\ud83c\udfff\u200d\u27a1\ufe0f\", \"\ud83e\uddcf\", \"\ud83e\uddcf\u200d\u2640\", \"\ud83e\uddcf\u200d\u2640\ufe0f\", \"\ud83e\uddcf\u200d\u2642\", \"\ud83e\uddcf\u200d\u2642\ufe0f\", \"\ud83e\uddcf\ud83c\udffb\", \"\ud83e\uddcf\ud83c\udffb\u200d\u2640\", \"\ud83e\uddcf\ud83c\udffb\u200d\u2640\ufe0f\", \"\ud83e\uddcf\ud83c\udffb\u200d\u2642\", \"\ud83e\uddcf\ud83c\udffb\u200d\u2642\ufe0f\", \"\ud83e\uddcf\ud83c\udffc\", \"\ud83e\uddcf\ud83c\udffc\u200d\u2640\", \"\ud83e\uddcf\ud83c\udffc\u200d\u2640\ufe0f\", \"\ud83e\uddcf\ud83c\udffc\u200d\u2642\", \"\ud83e\uddcf\ud83c\udffc\u200d\u2642\ufe0f\", \"\ud83e\uddcf\ud83c\udffd\", \"\ud83e\uddcf\ud83c\udffd\u200d\u2640\", \"\ud83e\uddcf\ud83c\udffd\u200d\u2640\ufe0f\", \"\ud83e\uddcf\ud83c\udffd\u200d\u2642\", \"\ud83e\uddcf\ud83c\udffd\u200d\u2642\ufe0f\", \"\ud83e\uddcf\ud83c\udffe\", \"\ud83e\uddcf\ud83c\udffe\u200d\u2640\", \"\ud83e\uddcf\ud83c\udffe\u200d\u2640\ufe0f\", \"\ud83e\uddcf\ud83c\udffe\u200d\u2642\", \"\ud83e\uddcf\ud83c\udffe\u200d\u2642\ufe0f\", \"\ud83e\uddcf\ud83c\udfff\", \"\ud83e\uddcf\ud83c\udfff\u200d\u2640\", \"\ud83e\uddcf\ud83c\udfff\u200d\u2640\ufe0f\", \"\ud83e\uddcf\ud83c\udfff\u200d\u2642\", \"\ud83e\uddcf\ud83c\udfff\u200d\u2642\ufe0f\", \"\ud83e\uddd0\", \"\ud83e\uddd1\", \"\ud83e\uddd1\u200d\u2695\", \"\ud83e\uddd1\u200d\u2695\ufe0f\", \"\ud83e\uddd1\u200d\u2696\", \"\ud83e\uddd1\u200d\u2696\ufe0f\", \"\ud83e\uddd1\u200d\u2708\", \"\ud83e\uddd1\u200d\u2708\ufe0f\", \"\ud83e\uddd1\u200d\ud83c\udf3e\", \"\ud83e\uddd1\u200d\ud83c\udf73\", \"\ud83e\uddd1\u200d\ud83c\udf7c\", \"\ud83e\uddd1\u200d\ud83c\udf84\", \"\ud83e\uddd1\u200d\ud83c\udf93\", \"\ud83e\uddd1\u200d\ud83c\udfa4\", \"\ud83e\uddd1\u200d\ud83c\udfa8\", \"\ud83e\uddd1\u200d\ud83c\udfeb\", \"\ud83e\uddd1\u200d\ud83c\udfed\", \"\ud83e\uddd1\u200d\ud83d\udcbb\", \"\ud83e\uddd1\u200d\ud83d\udcbc\", \"\ud83e\uddd1\u200d\ud83d\udd27\", \"\ud83e\uddd1\u200d\ud83d\udd2c\", \"\ud83e\uddd1\u200d\ud83d\ude80\", \"\ud83e\uddd1\u200d\ud83d\ude92\", \"\ud83e\uddd1\u200d\ud83e\udd1d\u200d\ud83e\uddd1\", \"\ud83e\uddd1\u200d\ud83e\uddaf\", \"\ud83e\uddd1\u200d\ud83e\uddaf\u200d\u27a1\", \"\ud83e\uddd1\u200d\ud83e\uddaf\u200d\u27a1\ufe0f\", \"\ud83e\uddd1\u200d\ud83e\uddb0\", \"\ud83e\uddd1\u200d\ud83e\uddb1\", \"\ud83e\uddd1\u200d\ud83e\uddb2\", \"\ud83e\uddd1\u200d\ud83e\uddb3\", \"\ud83e\uddd1\u200d\ud83e\uddbc\", \"\ud83e\uddd1\u200d\ud83e\uddbc\u200d\u27a1\", \"\ud83e\uddd1\u200d\ud83e\uddbc\u200d\u27a1\ufe0f\", \"\ud83e\uddd1\u200d\ud83e\uddbd\", \"\ud83e\uddd1\u200d\ud83e\uddbd\u200d\u27a1\", \"\ud83e\uddd1\u200d\ud83e\uddbd\u200d\u27a1\ufe0f\", \"\ud83e\uddd1\u200d\ud83e\uddd1\u200d\ud83e\uddd2\", \"\ud83e\uddd1\u200d\ud83e\uddd1\u200d\ud83e\uddd2\u200d\ud83e\uddd2\", \"\ud83e\uddd1\u200d\ud83e\uddd2\", \"\ud83e\uddd1\u200d\ud83e\uddd2\u200d\ud83e\uddd2\", \"\ud83e\uddd1\ud83c\udffb\", \"\ud83e\uddd1\ud83c\udffb\u200d\u2695\", \"\ud83e\uddd1\ud83c\udffb\u200d\u2695\ufe0f\", \"\ud83e\uddd1\ud83c\udffb\u200d\u2696\", \"\ud83e\uddd1\ud83c\udffb\u200d\u2696\ufe0f\", \"\ud83e\uddd1\ud83c\udffb\u200d\u2708\", \"\ud83e\uddd1\ud83c\udffb\u200d\u2708\ufe0f\", \"\ud83e\uddd1\ud83c\udffb\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83e\uddd1\ud83c\udffc\", \"\ud83e\uddd1\ud83c\udffb\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83e\uddd1\ud83c\udffd\", \"\ud83e\uddd1\ud83c\udffb\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83e\uddd1\ud83c\udffe\", \"\ud83e\uddd1\ud83c\udffb\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83e\uddd1\ud83c\udfff\", \"\ud83e\uddd1\ud83c\udffb\u200d\u2764\u200d\ud83e\uddd1\ud83c\udffc\", \"\ud83e\uddd1\ud83c\udffb\u200d\u2764\u200d\ud83e\uddd1\ud83c\udffd\", \"\ud83e\uddd1\ud83c\udffb\u200d\u2764\u200d\ud83e\uddd1\ud83c\udffe\", \"\ud83e\uddd1\ud83c\udffb\u200d\u2764\u200d\ud83e\uddd1\ud83c\udfff\", \"\ud83e\uddd1\ud83c\udffb\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83e\uddd1\ud83c\udffc\", \"\ud83e\uddd1\ud83c\udffb\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83e\uddd1\ud83c\udffd\", \"\ud83e\uddd1\ud83c\udffb\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83e\uddd1\ud83c\udffe\", \"\ud83e\uddd1\ud83c\udffb\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83e\uddd1\ud83c\udfff\", \"\ud83e\uddd1\ud83c\udffb\u200d\u2764\ufe0f\u200d\ud83e\uddd1\ud83c\udffc\", \"\ud83e\uddd1\ud83c\udffb\u200d\u2764\ufe0f\u200d\ud83e\uddd1\ud83c\udffd\", \"\ud83e\uddd1\ud83c\udffb\u200d\u2764\ufe0f\u200d\ud83e\uddd1\ud83c\udffe\", \"\ud83e\uddd1\ud83c\udffb\u200d\u2764\ufe0f\u200d\ud83e\uddd1\ud83c\udfff\", \"\ud83e\uddd1\ud83c\udffb\u200d\ud83c\udf3e\", \"\ud83e\uddd1\ud83c\udffb\u200d\ud83c\udf73\", \"\ud83e\uddd1\ud83c\udffb\u200d\ud83c\udf7c\", \"\ud83e\uddd1\ud83c\udffb\u200d\ud83c\udf84\", \"\ud83e\uddd1\ud83c\udffb\u200d\ud83c\udf93\", \"\ud83e\uddd1\ud83c\udffb\u200d\ud83c\udfa4\", \"\ud83e\uddd1\ud83c\udffb\u200d\ud83c\udfa8\", \"\ud83e\uddd1\ud83c\udffb\u200d\ud83c\udfeb\", \"\ud83e\uddd1\ud83c\udffb\u200d\ud83c\udfed\", \"\ud83e\uddd1\ud83c\udffb\u200d\ud83d\udcbb\", \"\ud83e\uddd1\ud83c\udffb\u200d\ud83d\udcbc\", \"\ud83e\uddd1\ud83c\udffb\u200d\ud83d\udd27\", \"\ud83e\uddd1\ud83c\udffb\u200d\ud83d\udd2c\", \"\ud83e\uddd1\ud83c\udffb\u200d\ud83d\ude80\", \"\ud83e\uddd1\ud83c\udffb\u200d\ud83d\ude92\", \"\ud83e\uddd1\ud83c\udffb\u200d\ud83e\udd1d\u200d\ud83e\uddd1\ud83c\udffb\", \"\ud83e\uddd1\ud83c\udffb\u200d\ud83e\udd1d\u200d\ud83e\uddd1\ud83c\udffc\", \"\ud83e\uddd1\ud83c\udffb\u200d\ud83e\udd1d\u200d\ud83e\uddd1\ud83c\udffd\", \"\ud83e\uddd1\ud83c\udffb\u200d\ud83e\udd1d\u200d\ud83e\uddd1\ud83c\udffe\", \"\ud83e\uddd1\ud83c\udffb\u200d\ud83e\udd1d\u200d\ud83e\uddd1\ud83c\udfff\", \"\ud83e\uddd1\ud83c\udffb\u200d\ud83e\uddaf\", \"\ud83e\uddd1\ud83c\udffb\u200d\ud83e\uddaf\u200d\u27a1\", \"\ud83e\uddd1\ud83c\udffb\u200d\ud83e\uddaf\u200d\u27a1\ufe0f\", \"\ud83e\uddd1\ud83c\udffb\u200d\ud83e\uddb0\", \"\ud83e\uddd1\ud83c\udffb\u200d\ud83e\uddb1\", \"\ud83e\uddd1\ud83c\udffb\u200d\ud83e\uddb2\", \"\ud83e\uddd1\ud83c\udffb\u200d\ud83e\uddb3\", \"\ud83e\uddd1\ud83c\udffb\u200d\ud83e\uddbc\", \"\ud83e\uddd1\ud83c\udffb\u200d\ud83e\uddbc\u200d\u27a1\", \"\ud83e\uddd1\ud83c\udffb\u200d\ud83e\uddbc\u200d\u27a1\ufe0f\", \"\ud83e\uddd1\ud83c\udffb\u200d\ud83e\uddbd\", \"\ud83e\uddd1\ud83c\udffb\u200d\ud83e\uddbd\u200d\u27a1\", \"\ud83e\uddd1\ud83c\udffb\u200d\ud83e\uddbd\u200d\u27a1\ufe0f\", \"\ud83e\uddd1\ud83c\udffc\", \"\ud83e\uddd1\ud83c\udffc\u200d\u2695\", \"\ud83e\uddd1\ud83c\udffc\u200d\u2695\ufe0f\", \"\ud83e\uddd1\ud83c\udffc\u200d\u2696\", \"\ud83e\uddd1\ud83c\udffc\u200d\u2696\ufe0f\", \"\ud83e\uddd1\ud83c\udffc\u200d\u2708\", \"\ud83e\uddd1\ud83c\udffc\u200d\u2708\ufe0f\", \"\ud83e\uddd1\ud83c\udffc\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83e\uddd1\ud83c\udffb\", \"\ud83e\uddd1\ud83c\udffc\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83e\uddd1\ud83c\udffd\", \"\ud83e\uddd1\ud83c\udffc\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83e\uddd1\ud83c\udffe\", \"\ud83e\uddd1\ud83c\udffc\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83e\uddd1\ud83c\udfff\", \"\ud83e\uddd1\ud83c\udffc\u200d\u2764\u200d\ud83e\uddd1\ud83c\udffb\", \"\ud83e\uddd1\ud83c\udffc\u200d\u2764\u200d\ud83e\uddd1\ud83c\udffd\", \"\ud83e\uddd1\ud83c\udffc\u200d\u2764\u200d\ud83e\uddd1\ud83c\udffe\", \"\ud83e\uddd1\ud83c\udffc\u200d\u2764\u200d\ud83e\uddd1\ud83c\udfff\", \"\ud83e\uddd1\ud83c\udffc\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83e\uddd1\ud83c\udffb\", \"\ud83e\uddd1\ud83c\udffc\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83e\uddd1\ud83c\udffd\", \"\ud83e\uddd1\ud83c\udffc\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83e\uddd1\ud83c\udffe\", \"\ud83e\uddd1\ud83c\udffc\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83e\uddd1\ud83c\udfff\", \"\ud83e\uddd1\ud83c\udffc\u200d\u2764\ufe0f\u200d\ud83e\uddd1\ud83c\udffb\", \"\ud83e\uddd1\ud83c\udffc\u200d\u2764\ufe0f\u200d\ud83e\uddd1\ud83c\udffd\", \"\ud83e\uddd1\ud83c\udffc\u200d\u2764\ufe0f\u200d\ud83e\uddd1\ud83c\udffe\", \"\ud83e\uddd1\ud83c\udffc\u200d\u2764\ufe0f\u200d\ud83e\uddd1\ud83c\udfff\", \"\ud83e\uddd1\ud83c\udffc\u200d\ud83c\udf3e\", \"\ud83e\uddd1\ud83c\udffc\u200d\ud83c\udf73\", \"\ud83e\uddd1\ud83c\udffc\u200d\ud83c\udf7c\", \"\ud83e\uddd1\ud83c\udffc\u200d\ud83c\udf84\", \"\ud83e\uddd1\ud83c\udffc\u200d\ud83c\udf93\", \"\ud83e\uddd1\ud83c\udffc\u200d\ud83c\udfa4\", \"\ud83e\uddd1\ud83c\udffc\u200d\ud83c\udfa8\", \"\ud83e\uddd1\ud83c\udffc\u200d\ud83c\udfeb\", \"\ud83e\uddd1\ud83c\udffc\u200d\ud83c\udfed\", \"\ud83e\uddd1\ud83c\udffc\u200d\ud83d\udcbb\", \"\ud83e\uddd1\ud83c\udffc\u200d\ud83d\udcbc\", \"\ud83e\uddd1\ud83c\udffc\u200d\ud83d\udd27\", \"\ud83e\uddd1\ud83c\udffc\u200d\ud83d\udd2c\", \"\ud83e\uddd1\ud83c\udffc\u200d\ud83d\ude80\", \"\ud83e\uddd1\ud83c\udffc\u200d\ud83d\ude92\", \"\ud83e\uddd1\ud83c\udffc\u200d\ud83e\udd1d\u200d\ud83e\uddd1\ud83c\udffb\", \"\ud83e\uddd1\ud83c\udffc\u200d\ud83e\udd1d\u200d\ud83e\uddd1\ud83c\udffc\", \"\ud83e\uddd1\ud83c\udffc\u200d\ud83e\udd1d\u200d\ud83e\uddd1\ud83c\udffd\", \"\ud83e\uddd1\ud83c\udffc\u200d\ud83e\udd1d\u200d\ud83e\uddd1\ud83c\udffe\", \"\ud83e\uddd1\ud83c\udffc\u200d\ud83e\udd1d\u200d\ud83e\uddd1\ud83c\udfff\", \"\ud83e\uddd1\ud83c\udffc\u200d\ud83e\uddaf\", \"\ud83e\uddd1\ud83c\udffc\u200d\ud83e\uddaf\u200d\u27a1\", \"\ud83e\uddd1\ud83c\udffc\u200d\ud83e\uddaf\u200d\u27a1\ufe0f\", \"\ud83e\uddd1\ud83c\udffc\u200d\ud83e\uddb0\", \"\ud83e\uddd1\ud83c\udffc\u200d\ud83e\uddb1\", \"\ud83e\uddd1\ud83c\udffc\u200d\ud83e\uddb2\", \"\ud83e\uddd1\ud83c\udffc\u200d\ud83e\uddb3\", \"\ud83e\uddd1\ud83c\udffc\u200d\ud83e\uddbc\", \"\ud83e\uddd1\ud83c\udffc\u200d\ud83e\uddbc\u200d\u27a1\", \"\ud83e\uddd1\ud83c\udffc\u200d\ud83e\uddbc\u200d\u27a1\ufe0f\", \"\ud83e\uddd1\ud83c\udffc\u200d\ud83e\uddbd\", \"\ud83e\uddd1\ud83c\udffc\u200d\ud83e\uddbd\u200d\u27a1\", \"\ud83e\uddd1\ud83c\udffc\u200d\ud83e\uddbd\u200d\u27a1\ufe0f\", \"\ud83e\uddd1\ud83c\udffd\", \"\ud83e\uddd1\ud83c\udffd\u200d\u2695\", \"\ud83e\uddd1\ud83c\udffd\u200d\u2695\ufe0f\", \"\ud83e\uddd1\ud83c\udffd\u200d\u2696\", \"\ud83e\uddd1\ud83c\udffd\u200d\u2696\ufe0f\", \"\ud83e\uddd1\ud83c\udffd\u200d\u2708\", \"\ud83e\uddd1\ud83c\udffd\u200d\u2708\ufe0f\", \"\ud83e\uddd1\ud83c\udffd\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83e\uddd1\ud83c\udffb\", \"\ud83e\uddd1\ud83c\udffd\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83e\uddd1\ud83c\udffc\", \"\ud83e\uddd1\ud83c\udffd\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83e\uddd1\ud83c\udffe\", \"\ud83e\uddd1\ud83c\udffd\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83e\uddd1\ud83c\udfff\", \"\ud83e\uddd1\ud83c\udffd\u200d\u2764\u200d\ud83e\uddd1\ud83c\udffb\", \"\ud83e\uddd1\ud83c\udffd\u200d\u2764\u200d\ud83e\uddd1\ud83c\udffc\", \"\ud83e\uddd1\ud83c\udffd\u200d\u2764\u200d\ud83e\uddd1\ud83c\udffe\", \"\ud83e\uddd1\ud83c\udffd\u200d\u2764\u200d\ud83e\uddd1\ud83c\udfff\", \"\ud83e\uddd1\ud83c\udffd\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83e\uddd1\ud83c\udffb\", \"\ud83e\uddd1\ud83c\udffd\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83e\uddd1\ud83c\udffc\", \"\ud83e\uddd1\ud83c\udffd\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83e\uddd1\ud83c\udffe\", \"\ud83e\uddd1\ud83c\udffd\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83e\uddd1\ud83c\udfff\", \"\ud83e\uddd1\ud83c\udffd\u200d\u2764\ufe0f\u200d\ud83e\uddd1\ud83c\udffb\", \"\ud83e\uddd1\ud83c\udffd\u200d\u2764\ufe0f\u200d\ud83e\uddd1\ud83c\udffc\", \"\ud83e\uddd1\ud83c\udffd\u200d\u2764\ufe0f\u200d\ud83e\uddd1\ud83c\udffe\", \"\ud83e\uddd1\ud83c\udffd\u200d\u2764\ufe0f\u200d\ud83e\uddd1\ud83c\udfff\", \"\ud83e\uddd1\ud83c\udffd\u200d\ud83c\udf3e\", \"\ud83e\uddd1\ud83c\udffd\u200d\ud83c\udf73\", \"\ud83e\uddd1\ud83c\udffd\u200d\ud83c\udf7c\", \"\ud83e\uddd1\ud83c\udffd\u200d\ud83c\udf84\", \"\ud83e\uddd1\ud83c\udffd\u200d\ud83c\udf93\", \"\ud83e\uddd1\ud83c\udffd\u200d\ud83c\udfa4\", \"\ud83e\uddd1\ud83c\udffd\u200d\ud83c\udfa8\", \"\ud83e\uddd1\ud83c\udffd\u200d\ud83c\udfeb\", \"\ud83e\uddd1\ud83c\udffd\u200d\ud83c\udfed\", \"\ud83e\uddd1\ud83c\udffd\u200d\ud83d\udcbb\", \"\ud83e\uddd1\ud83c\udffd\u200d\ud83d\udcbc\", \"\ud83e\uddd1\ud83c\udffd\u200d\ud83d\udd27\", \"\ud83e\uddd1\ud83c\udffd\u200d\ud83d\udd2c\", \"\ud83e\uddd1\ud83c\udffd\u200d\ud83d\ude80\", \"\ud83e\uddd1\ud83c\udffd\u200d\ud83d\ude92\", \"\ud83e\uddd1\ud83c\udffd\u200d\ud83e\udd1d\u200d\ud83e\uddd1\ud83c\udffb\", \"\ud83e\uddd1\ud83c\udffd\u200d\ud83e\udd1d\u200d\ud83e\uddd1\ud83c\udffc\", \"\ud83e\uddd1\ud83c\udffd\u200d\ud83e\udd1d\u200d\ud83e\uddd1\ud83c\udffd\", \"\ud83e\uddd1\ud83c\udffd\u200d\ud83e\udd1d\u200d\ud83e\uddd1\ud83c\udffe\", \"\ud83e\uddd1\ud83c\udffd\u200d\ud83e\udd1d\u200d\ud83e\uddd1\ud83c\udfff\", \"\ud83e\uddd1\ud83c\udffd\u200d\ud83e\uddaf\", \"\ud83e\uddd1\ud83c\udffd\u200d\ud83e\uddaf\u200d\u27a1\", \"\ud83e\uddd1\ud83c\udffd\u200d\ud83e\uddaf\u200d\u27a1\ufe0f\", \"\ud83e\uddd1\ud83c\udffd\u200d\ud83e\uddb0\", \"\ud83e\uddd1\ud83c\udffd\u200d\ud83e\uddb1\", \"\ud83e\uddd1\ud83c\udffd\u200d\ud83e\uddb2\", \"\ud83e\uddd1\ud83c\udffd\u200d\ud83e\uddb3\", \"\ud83e\uddd1\ud83c\udffd\u200d\ud83e\uddbc\", \"\ud83e\uddd1\ud83c\udffd\u200d\ud83e\uddbc\u200d\u27a1\", \"\ud83e\uddd1\ud83c\udffd\u200d\ud83e\uddbc\u200d\u27a1\ufe0f\", \"\ud83e\uddd1\ud83c\udffd\u200d\ud83e\uddbd\", \"\ud83e\uddd1\ud83c\udffd\u200d\ud83e\uddbd\u200d\u27a1\", \"\ud83e\uddd1\ud83c\udffd\u200d\ud83e\uddbd\u200d\u27a1\ufe0f\", \"\ud83e\uddd1\ud83c\udffe\", \"\ud83e\uddd1\ud83c\udffe\u200d\u2695\", \"\ud83e\uddd1\ud83c\udffe\u200d\u2695\ufe0f\", \"\ud83e\uddd1\ud83c\udffe\u200d\u2696\", \"\ud83e\uddd1\ud83c\udffe\u200d\u2696\ufe0f\", \"\ud83e\uddd1\ud83c\udffe\u200d\u2708\", \"\ud83e\uddd1\ud83c\udffe\u200d\u2708\ufe0f\", \"\ud83e\uddd1\ud83c\udffe\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83e\uddd1\ud83c\udffb\", \"\ud83e\uddd1\ud83c\udffe\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83e\uddd1\ud83c\udffc\", \"\ud83e\uddd1\ud83c\udffe\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83e\uddd1\ud83c\udffd\", \"\ud83e\uddd1\ud83c\udffe\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83e\uddd1\ud83c\udfff\", \"\ud83e\uddd1\ud83c\udffe\u200d\u2764\u200d\ud83e\uddd1\ud83c\udffb\", \"\ud83e\uddd1\ud83c\udffe\u200d\u2764\u200d\ud83e\uddd1\ud83c\udffc\", \"\ud83e\uddd1\ud83c\udffe\u200d\u2764\u200d\ud83e\uddd1\ud83c\udffd\", \"\ud83e\uddd1\ud83c\udffe\u200d\u2764\u200d\ud83e\uddd1\ud83c\udfff\", \"\ud83e\uddd1\ud83c\udffe\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83e\uddd1\ud83c\udffb\", \"\ud83e\uddd1\ud83c\udffe\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83e\uddd1\ud83c\udffc\", \"\ud83e\uddd1\ud83c\udffe\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83e\uddd1\ud83c\udffd\", \"\ud83e\uddd1\ud83c\udffe\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83e\uddd1\ud83c\udfff\", \"\ud83e\uddd1\ud83c\udffe\u200d\u2764\ufe0f\u200d\ud83e\uddd1\ud83c\udffb\", \"\ud83e\uddd1\ud83c\udffe\u200d\u2764\ufe0f\u200d\ud83e\uddd1\ud83c\udffc\", \"\ud83e\uddd1\ud83c\udffe\u200d\u2764\ufe0f\u200d\ud83e\uddd1\ud83c\udffd\", \"\ud83e\uddd1\ud83c\udffe\u200d\u2764\ufe0f\u200d\ud83e\uddd1\ud83c\udfff\", \"\ud83e\uddd1\ud83c\udffe\u200d\ud83c\udf3e\", \"\ud83e\uddd1\ud83c\udffe\u200d\ud83c\udf73\", \"\ud83e\uddd1\ud83c\udffe\u200d\ud83c\udf7c\", \"\ud83e\uddd1\ud83c\udffe\u200d\ud83c\udf84\", \"\ud83e\uddd1\ud83c\udffe\u200d\ud83c\udf93\", \"\ud83e\uddd1\ud83c\udffe\u200d\ud83c\udfa4\", \"\ud83e\uddd1\ud83c\udffe\u200d\ud83c\udfa8\", \"\ud83e\uddd1\ud83c\udffe\u200d\ud83c\udfeb\", \"\ud83e\uddd1\ud83c\udffe\u200d\ud83c\udfed\", \"\ud83e\uddd1\ud83c\udffe\u200d\ud83d\udcbb\", \"\ud83e\uddd1\ud83c\udffe\u200d\ud83d\udcbc\", \"\ud83e\uddd1\ud83c\udffe\u200d\ud83d\udd27\", \"\ud83e\uddd1\ud83c\udffe\u200d\ud83d\udd2c\", \"\ud83e\uddd1\ud83c\udffe\u200d\ud83d\ude80\", \"\ud83e\uddd1\ud83c\udffe\u200d\ud83d\ude92\", \"\ud83e\uddd1\ud83c\udffe\u200d\ud83e\udd1d\u200d\ud83e\uddd1\ud83c\udffb\", \"\ud83e\uddd1\ud83c\udffe\u200d\ud83e\udd1d\u200d\ud83e\uddd1\ud83c\udffc\", \"\ud83e\uddd1\ud83c\udffe\u200d\ud83e\udd1d\u200d\ud83e\uddd1\ud83c\udffd\", \"\ud83e\uddd1\ud83c\udffe\u200d\ud83e\udd1d\u200d\ud83e\uddd1\ud83c\udffe\", \"\ud83e\uddd1\ud83c\udffe\u200d\ud83e\udd1d\u200d\ud83e\uddd1\ud83c\udfff\", \"\ud83e\uddd1\ud83c\udffe\u200d\ud83e\uddaf\", \"\ud83e\uddd1\ud83c\udffe\u200d\ud83e\uddaf\u200d\u27a1\", \"\ud83e\uddd1\ud83c\udffe\u200d\ud83e\uddaf\u200d\u27a1\ufe0f\", \"\ud83e\uddd1\ud83c\udffe\u200d\ud83e\uddb0\", \"\ud83e\uddd1\ud83c\udffe\u200d\ud83e\uddb1\", \"\ud83e\uddd1\ud83c\udffe\u200d\ud83e\uddb2\", \"\ud83e\uddd1\ud83c\udffe\u200d\ud83e\uddb3\", \"\ud83e\uddd1\ud83c\udffe\u200d\ud83e\uddbc\", \"\ud83e\uddd1\ud83c\udffe\u200d\ud83e\uddbc\u200d\u27a1\", \"\ud83e\uddd1\ud83c\udffe\u200d\ud83e\uddbc\u200d\u27a1\ufe0f\", \"\ud83e\uddd1\ud83c\udffe\u200d\ud83e\uddbd\", \"\ud83e\uddd1\ud83c\udffe\u200d\ud83e\uddbd\u200d\u27a1\", \"\ud83e\uddd1\ud83c\udffe\u200d\ud83e\uddbd\u200d\u27a1\ufe0f\", \"\ud83e\uddd1\ud83c\udfff\", \"\ud83e\uddd1\ud83c\udfff\u200d\u2695\", \"\ud83e\uddd1\ud83c\udfff\u200d\u2695\ufe0f\", \"\ud83e\uddd1\ud83c\udfff\u200d\u2696\", \"\ud83e\uddd1\ud83c\udfff\u200d\u2696\ufe0f\", \"\ud83e\uddd1\ud83c\udfff\u200d\u2708\", \"\ud83e\uddd1\ud83c\udfff\u200d\u2708\ufe0f\", \"\ud83e\uddd1\ud83c\udfff\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83e\uddd1\ud83c\udffb\", \"\ud83e\uddd1\ud83c\udfff\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83e\uddd1\ud83c\udffc\", \"\ud83e\uddd1\ud83c\udfff\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83e\uddd1\ud83c\udffd\", \"\ud83e\uddd1\ud83c\udfff\u200d\u2764\u200d\ud83d\udc8b\u200d\ud83e\uddd1\ud83c\udffe\", \"\ud83e\uddd1\ud83c\udfff\u200d\u2764\u200d\ud83e\uddd1\ud83c\udffb\", \"\ud83e\uddd1\ud83c\udfff\u200d\u2764\u200d\ud83e\uddd1\ud83c\udffc\", \"\ud83e\uddd1\ud83c\udfff\u200d\u2764\u200d\ud83e\uddd1\ud83c\udffd\", \"\ud83e\uddd1\ud83c\udfff\u200d\u2764\u200d\ud83e\uddd1\ud83c\udffe\", \"\ud83e\uddd1\ud83c\udfff\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83e\uddd1\ud83c\udffb\", \"\ud83e\uddd1\ud83c\udfff\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83e\uddd1\ud83c\udffc\", \"\ud83e\uddd1\ud83c\udfff\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83e\uddd1\ud83c\udffd\", \"\ud83e\uddd1\ud83c\udfff\u200d\u2764\ufe0f\u200d\ud83d\udc8b\u200d\ud83e\uddd1\ud83c\udffe\", \"\ud83e\uddd1\ud83c\udfff\u200d\u2764\ufe0f\u200d\ud83e\uddd1\ud83c\udffb\", \"\ud83e\uddd1\ud83c\udfff\u200d\u2764\ufe0f\u200d\ud83e\uddd1\ud83c\udffc\", \"\ud83e\uddd1\ud83c\udfff\u200d\u2764\ufe0f\u200d\ud83e\uddd1\ud83c\udffd\", \"\ud83e\uddd1\ud83c\udfff\u200d\u2764\ufe0f\u200d\ud83e\uddd1\ud83c\udffe\", \"\ud83e\uddd1\ud83c\udfff\u200d\ud83c\udf3e\", \"\ud83e\uddd1\ud83c\udfff\u200d\ud83c\udf73\", \"\ud83e\uddd1\ud83c\udfff\u200d\ud83c\udf7c\", \"\ud83e\uddd1\ud83c\udfff\u200d\ud83c\udf84\", \"\ud83e\uddd1\ud83c\udfff\u200d\ud83c\udf93\", \"\ud83e\uddd1\ud83c\udfff\u200d\ud83c\udfa4\", \"\ud83e\uddd1\ud83c\udfff\u200d\ud83c\udfa8\", \"\ud83e\uddd1\ud83c\udfff\u200d\ud83c\udfeb\", \"\ud83e\uddd1\ud83c\udfff\u200d\ud83c\udfed\", \"\ud83e\uddd1\ud83c\udfff\u200d\ud83d\udcbb\", \"\ud83e\uddd1\ud83c\udfff\u200d\ud83d\udcbc\", \"\ud83e\uddd1\ud83c\udfff\u200d\ud83d\udd27\", \"\ud83e\uddd1\ud83c\udfff\u200d\ud83d\udd2c\", \"\ud83e\uddd1\ud83c\udfff\u200d\ud83d\ude80\", \"\ud83e\uddd1\ud83c\udfff\u200d\ud83d\ude92\", \"\ud83e\uddd1\ud83c\udfff\u200d\ud83e\udd1d\u200d\ud83e\uddd1\ud83c\udffb\", \"\ud83e\uddd1\ud83c\udfff\u200d\ud83e\udd1d\u200d\ud83e\uddd1\ud83c\udffc\", \"\ud83e\uddd1\ud83c\udfff\u200d\ud83e\udd1d\u200d\ud83e\uddd1\ud83c\udffd\", \"\ud83e\uddd1\ud83c\udfff\u200d\ud83e\udd1d\u200d\ud83e\uddd1\ud83c\udffe\", \"\ud83e\uddd1\ud83c\udfff\u200d\ud83e\udd1d\u200d\ud83e\uddd1\ud83c\udfff\", \"\ud83e\uddd1\ud83c\udfff\u200d\ud83e\uddaf\", \"\ud83e\uddd1\ud83c\udfff\u200d\ud83e\uddaf\u200d\u27a1\", \"\ud83e\uddd1\ud83c\udfff\u200d\ud83e\uddaf\u200d\u27a1\ufe0f\", \"\ud83e\uddd1\ud83c\udfff\u200d\ud83e\uddb0\", \"\ud83e\uddd1\ud83c\udfff\u200d\ud83e\uddb1\", \"\ud83e\uddd1\ud83c\udfff\u200d\ud83e\uddb2\", \"\ud83e\uddd1\ud83c\udfff\u200d\ud83e\uddb3\", \"\ud83e\uddd1\ud83c\udfff\u200d\ud83e\uddbc\", \"\ud83e\uddd1\ud83c\udfff\u200d\ud83e\uddbc\u200d\u27a1\", \"\ud83e\uddd1\ud83c\udfff\u200d\ud83e\uddbc\u200d\u27a1\ufe0f\", \"\ud83e\uddd1\ud83c\udfff\u200d\ud83e\uddbd\", \"\ud83e\uddd1\ud83c\udfff\u200d\ud83e\uddbd\u200d\u27a1\", \"\ud83e\uddd1\ud83c\udfff\u200d\ud83e\uddbd\u200d\u27a1\ufe0f\", \"\ud83e\uddd2\", \"\ud83e\uddd2\ud83c\udffb\", \"\ud83e\uddd2\ud83c\udffc\", \"\ud83e\uddd2\ud83c\udffd\", \"\ud83e\uddd2\ud83c\udffe\", \"\ud83e\uddd2\ud83c\udfff\", \"\ud83e\uddd3\", \"\ud83e\uddd3\ud83c\udffb\", \"\ud83e\uddd3\ud83c\udffc\", \"\ud83e\uddd3\ud83c\udffd\", \"\ud83e\uddd3\ud83c\udffe\", \"\ud83e\uddd3\ud83c\udfff\", \"\ud83e\uddd4\", \"\ud83e\uddd4\u200d\u2640\", \"\ud83e\uddd4\u200d\u2640\ufe0f\", \"\ud83e\uddd4\u200d\u2642\", \"\ud83e\uddd4\u200d\u2642\ufe0f\", \"\ud83e\uddd4\ud83c\udffb\", \"\ud83e\uddd4\ud83c\udffb\u200d\u2640\", \"\ud83e\uddd4\ud83c\udffb\u200d\u2640\ufe0f\", \"\ud83e\uddd4\ud83c\udffb\u200d\u2642\", \"\ud83e\uddd4\ud83c\udffb\u200d\u2642\ufe0f\", \"\ud83e\uddd4\ud83c\udffc\", \"\ud83e\uddd4\ud83c\udffc\u200d\u2640\", \"\ud83e\uddd4\ud83c\udffc\u200d\u2640\ufe0f\", \"\ud83e\uddd4\ud83c\udffc\u200d\u2642\", \"\ud83e\uddd4\ud83c\udffc\u200d\u2642\ufe0f\", \"\ud83e\uddd4\ud83c\udffd\", \"\ud83e\uddd4\ud83c\udffd\u200d\u2640\", \"\ud83e\uddd4\ud83c\udffd\u200d\u2640\ufe0f\", \"\ud83e\uddd4\ud83c\udffd\u200d\u2642\", \"\ud83e\uddd4\ud83c\udffd\u200d\u2642\ufe0f\", \"\ud83e\uddd4\ud83c\udffe\", \"\ud83e\uddd4\ud83c\udffe\u200d\u2640\", \"\ud83e\uddd4\ud83c\udffe\u200d\u2640\ufe0f\", \"\ud83e\uddd4\ud83c\udffe\u200d\u2642\", \"\ud83e\uddd4\ud83c\udffe\u200d\u2642\ufe0f\", \"\ud83e\uddd4\ud83c\udfff\", \"\ud83e\uddd4\ud83c\udfff\u200d\u2640\", \"\ud83e\uddd4\ud83c\udfff\u200d\u2640\ufe0f\", \"\ud83e\uddd4\ud83c\udfff\u200d\u2642\", \"\ud83e\uddd4\ud83c\udfff\u200d\u2642\ufe0f\", \"\ud83e\uddd5\", \"\ud83e\uddd5\ud83c\udffb\", \"\ud83e\uddd5\ud83c\udffc\", \"\ud83e\uddd5\ud83c\udffd\", \"\ud83e\uddd5\ud83c\udffe\", \"\ud83e\uddd5\ud83c\udfff\", \"\ud83e\uddd6\", \"\ud83e\uddd6\u200d\u2640\", \"\ud83e\uddd6\u200d\u2640\ufe0f\", \"\ud83e\uddd6\u200d\u2642\", \"\ud83e\uddd6\u200d\u2642\ufe0f\", \"\ud83e\uddd6\ud83c\udffb\", \"\ud83e\uddd6\ud83c\udffb\u200d\u2640\", \"\ud83e\uddd6\ud83c\udffb\u200d\u2640\ufe0f\", \"\ud83e\uddd6\ud83c\udffb\u200d\u2642\", \"\ud83e\uddd6\ud83c\udffb\u200d\u2642\ufe0f\", \"\ud83e\uddd6\ud83c\udffc\", \"\ud83e\uddd6\ud83c\udffc\u200d\u2640\", \"\ud83e\uddd6\ud83c\udffc\u200d\u2640\ufe0f\", \"\ud83e\uddd6\ud83c\udffc\u200d\u2642\", \"\ud83e\uddd6\ud83c\udffc\u200d\u2642\ufe0f\", \"\ud83e\uddd6\ud83c\udffd\", \"\ud83e\uddd6\ud83c\udffd\u200d\u2640\", \"\ud83e\uddd6\ud83c\udffd\u200d\u2640\ufe0f\", \"\ud83e\uddd6\ud83c\udffd\u200d\u2642\", \"\ud83e\uddd6\ud83c\udffd\u200d\u2642\ufe0f\", \"\ud83e\uddd6\ud83c\udffe\", \"\ud83e\uddd6\ud83c\udffe\u200d\u2640\", \"\ud83e\uddd6\ud83c\udffe\u200d\u2640\ufe0f\", \"\ud83e\uddd6\ud83c\udffe\u200d\u2642\", \"\ud83e\uddd6\ud83c\udffe\u200d\u2642\ufe0f\", \"\ud83e\uddd6\ud83c\udfff\", \"\ud83e\uddd6\ud83c\udfff\u200d\u2640\", \"\ud83e\uddd6\ud83c\udfff\u200d\u2640\ufe0f\", \"\ud83e\uddd6\ud83c\udfff\u200d\u2642\", \"\ud83e\uddd6\ud83c\udfff\u200d\u2642\ufe0f\", \"\ud83e\uddd7\", \"\ud83e\uddd7\u200d\u2640\", \"\ud83e\uddd7\u200d\u2640\ufe0f\", \"\ud83e\uddd7\u200d\u2642\", \"\ud83e\uddd7\u200d\u2642\ufe0f\", \"\ud83e\uddd7\ud83c\udffb\", \"\ud83e\uddd7\ud83c\udffb\u200d\u2640\", \"\ud83e\uddd7\ud83c\udffb\u200d\u2640\ufe0f\", \"\ud83e\uddd7\ud83c\udffb\u200d\u2642\", \"\ud83e\uddd7\ud83c\udffb\u200d\u2642\ufe0f\", \"\ud83e\uddd7\ud83c\udffc\", \"\ud83e\uddd7\ud83c\udffc\u200d\u2640\", \"\ud83e\uddd7\ud83c\udffc\u200d\u2640\ufe0f\", \"\ud83e\uddd7\ud83c\udffc\u200d\u2642\", \"\ud83e\uddd7\ud83c\udffc\u200d\u2642\ufe0f\", \"\ud83e\uddd7\ud83c\udffd\", \"\ud83e\uddd7\ud83c\udffd\u200d\u2640\", \"\ud83e\uddd7\ud83c\udffd\u200d\u2640\ufe0f\", \"\ud83e\uddd7\ud83c\udffd\u200d\u2642\", \"\ud83e\uddd7\ud83c\udffd\u200d\u2642\ufe0f\", \"\ud83e\uddd7\ud83c\udffe\", \"\ud83e\uddd7\ud83c\udffe\u200d\u2640\", \"\ud83e\uddd7\ud83c\udffe\u200d\u2640\ufe0f\", \"\ud83e\uddd7\ud83c\udffe\u200d\u2642\", \"\ud83e\uddd7\ud83c\udffe\u200d\u2642\ufe0f\", \"\ud83e\uddd7\ud83c\udfff\", \"\ud83e\uddd7\ud83c\udfff\u200d\u2640\", \"\ud83e\uddd7\ud83c\udfff\u200d\u2640\ufe0f\", \"\ud83e\uddd7\ud83c\udfff\u200d\u2642\", \"\ud83e\uddd7\ud83c\udfff\u200d\u2642\ufe0f\", \"\ud83e\uddd8\", \"\ud83e\uddd8\u200d\u2640\", \"\ud83e\uddd8\u200d\u2640\ufe0f\", \"\ud83e\uddd8\u200d\u2642\", \"\ud83e\uddd8\u200d\u2642\ufe0f\", \"\ud83e\uddd8\ud83c\udffb\", \"\ud83e\uddd8\ud83c\udffb\u200d\u2640\", \"\ud83e\uddd8\ud83c\udffb\u200d\u2640\ufe0f\", \"\ud83e\uddd8\ud83c\udffb\u200d\u2642\", \"\ud83e\uddd8\ud83c\udffb\u200d\u2642\ufe0f\", \"\ud83e\uddd8\ud83c\udffc\", \"\ud83e\uddd8\ud83c\udffc\u200d\u2640\", \"\ud83e\uddd8\ud83c\udffc\u200d\u2640\ufe0f\", \"\ud83e\uddd8\ud83c\udffc\u200d\u2642\", \"\ud83e\uddd8\ud83c\udffc\u200d\u2642\ufe0f\", \"\ud83e\uddd8\ud83c\udffd\", \"\ud83e\uddd8\ud83c\udffd\u200d\u2640\", \"\ud83e\uddd8\ud83c\udffd\u200d\u2640\ufe0f\", \"\ud83e\uddd8\ud83c\udffd\u200d\u2642\", \"\ud83e\uddd8\ud83c\udffd\u200d\u2642\ufe0f\", \"\ud83e\uddd8\ud83c\udffe\", \"\ud83e\uddd8\ud83c\udffe\u200d\u2640\", \"\ud83e\uddd8\ud83c\udffe\u200d\u2640\ufe0f\", \"\ud83e\uddd8\ud83c\udffe\u200d\u2642\", \"\ud83e\uddd8\ud83c\udffe\u200d\u2642\ufe0f\", \"\ud83e\uddd8\ud83c\udfff\", \"\ud83e\uddd8\ud83c\udfff\u200d\u2640\", \"\ud83e\uddd8\ud83c\udfff\u200d\u2640\ufe0f\", \"\ud83e\uddd8\ud83c\udfff\u200d\u2642\", \"\ud83e\uddd8\ud83c\udfff\u200d\u2642\ufe0f\", \"\ud83e\uddd9\", \"\ud83e\uddd9\u200d\u2640\", \"\ud83e\uddd9\u200d\u2640\ufe0f\", \"\ud83e\uddd9\u200d\u2642\", \"\ud83e\uddd9\u200d\u2642\ufe0f\", \"\ud83e\uddd9\ud83c\udffb\", \"\ud83e\uddd9\ud83c\udffb\u200d\u2640\", \"\ud83e\uddd9\ud83c\udffb\u200d\u2640\ufe0f\", \"\ud83e\uddd9\ud83c\udffb\u200d\u2642\", \"\ud83e\uddd9\ud83c\udffb\u200d\u2642\ufe0f\", \"\ud83e\uddd9\ud83c\udffc\", \"\ud83e\uddd9\ud83c\udffc\u200d\u2640\", \"\ud83e\uddd9\ud83c\udffc\u200d\u2640\ufe0f\", \"\ud83e\uddd9\ud83c\udffc\u200d\u2642\", \"\ud83e\uddd9\ud83c\udffc\u200d\u2642\ufe0f\", \"\ud83e\uddd9\ud83c\udffd\", \"\ud83e\uddd9\ud83c\udffd\u200d\u2640\", \"\ud83e\uddd9\ud83c\udffd\u200d\u2640\ufe0f\", \"\ud83e\uddd9\ud83c\udffd\u200d\u2642\", \"\ud83e\uddd9\ud83c\udffd\u200d\u2642\ufe0f\", \"\ud83e\uddd9\ud83c\udffe\", \"\ud83e\uddd9\ud83c\udffe\u200d\u2640\", \"\ud83e\uddd9\ud83c\udffe\u200d\u2640\ufe0f\", \"\ud83e\uddd9\ud83c\udffe\u200d\u2642\", \"\ud83e\uddd9\ud83c\udffe\u200d\u2642\ufe0f\", \"\ud83e\uddd9\ud83c\udfff\", \"\ud83e\uddd9\ud83c\udfff\u200d\u2640\", \"\ud83e\uddd9\ud83c\udfff\u200d\u2640\ufe0f\", \"\ud83e\uddd9\ud83c\udfff\u200d\u2642\", \"\ud83e\uddd9\ud83c\udfff\u200d\u2642\ufe0f\", \"\ud83e\uddda\", \"\ud83e\uddda\u200d\u2640\", \"\ud83e\uddda\u200d\u2640\ufe0f\", \"\ud83e\uddda\u200d\u2642\", \"\ud83e\uddda\u200d\u2642\ufe0f\", \"\ud83e\uddda\ud83c\udffb\", \"\ud83e\uddda\ud83c\udffb\u200d\u2640\", \"\ud83e\uddda\ud83c\udffb\u200d\u2640\ufe0f\", \"\ud83e\uddda\ud83c\udffb\u200d\u2642\", \"\ud83e\uddda\ud83c\udffb\u200d\u2642\ufe0f\", \"\ud83e\uddda\ud83c\udffc\", \"\ud83e\uddda\ud83c\udffc\u200d\u2640\", \"\ud83e\uddda\ud83c\udffc\u200d\u2640\ufe0f\", \"\ud83e\uddda\ud83c\udffc\u200d\u2642\", \"\ud83e\uddda\ud83c\udffc\u200d\u2642\ufe0f\", \"\ud83e\uddda\ud83c\udffd\", \"\ud83e\uddda\ud83c\udffd\u200d\u2640\", \"\ud83e\uddda\ud83c\udffd\u200d\u2640\ufe0f\", \"\ud83e\uddda\ud83c\udffd\u200d\u2642\", \"\ud83e\uddda\ud83c\udffd\u200d\u2642\ufe0f\", \"\ud83e\uddda\ud83c\udffe\", \"\ud83e\uddda\ud83c\udffe\u200d\u2640\", \"\ud83e\uddda\ud83c\udffe\u200d\u2640\ufe0f\", \"\ud83e\uddda\ud83c\udffe\u200d\u2642\", \"\ud83e\uddda\ud83c\udffe\u200d\u2642\ufe0f\", \"\ud83e\uddda\ud83c\udfff\", \"\ud83e\uddda\ud83c\udfff\u200d\u2640\", \"\ud83e\uddda\ud83c\udfff\u200d\u2640\ufe0f\", \"\ud83e\uddda\ud83c\udfff\u200d\u2642\", \"\ud83e\uddda\ud83c\udfff\u200d\u2642\ufe0f\", \"\ud83e\udddb\", \"\ud83e\udddb\u200d\u2640\", \"\ud83e\udddb\u200d\u2640\ufe0f\", \"\ud83e\udddb\u200d\u2642\", \"\ud83e\udddb\u200d\u2642\ufe0f\", \"\ud83e\udddb\ud83c\udffb\", \"\ud83e\udddb\ud83c\udffb\u200d\u2640\", \"\ud83e\udddb\ud83c\udffb\u200d\u2640\ufe0f\", \"\ud83e\udddb\ud83c\udffb\u200d\u2642\", \"\ud83e\udddb\ud83c\udffb\u200d\u2642\ufe0f\", \"\ud83e\udddb\ud83c\udffc\", \"\ud83e\udddb\ud83c\udffc\u200d\u2640\", \"\ud83e\udddb\ud83c\udffc\u200d\u2640\ufe0f\", \"\ud83e\udddb\ud83c\udffc\u200d\u2642\", \"\ud83e\udddb\ud83c\udffc\u200d\u2642\ufe0f\", \"\ud83e\udddb\ud83c\udffd\", \"\ud83e\udddb\ud83c\udffd\u200d\u2640\", \"\ud83e\udddb\ud83c\udffd\u200d\u2640\ufe0f\", \"\ud83e\udddb\ud83c\udffd\u200d\u2642\", \"\ud83e\udddb\ud83c\udffd\u200d\u2642\ufe0f\", \"\ud83e\udddb\ud83c\udffe\", \"\ud83e\udddb\ud83c\udffe\u200d\u2640\", \"\ud83e\udddb\ud83c\udffe\u200d\u2640\ufe0f\", \"\ud83e\udddb\ud83c\udffe\u200d\u2642\", \"\ud83e\udddb\ud83c\udffe\u200d\u2642\ufe0f\", \"\ud83e\udddb\ud83c\udfff\", \"\ud83e\udddb\ud83c\udfff\u200d\u2640\", \"\ud83e\udddb\ud83c\udfff\u200d\u2640\ufe0f\", \"\ud83e\udddb\ud83c\udfff\u200d\u2642\", \"\ud83e\udddb\ud83c\udfff\u200d\u2642\ufe0f\", \"\ud83e\udddc\", \"\ud83e\udddc\u200d\u2640\", \"\ud83e\udddc\u200d\u2640\ufe0f\", \"\ud83e\udddc\u200d\u2642\", \"\ud83e\udddc\u200d\u2642\ufe0f\", \"\ud83e\udddc\ud83c\udffb\", \"\ud83e\udddc\ud83c\udffb\u200d\u2640\", \"\ud83e\udddc\ud83c\udffb\u200d\u2640\ufe0f\", \"\ud83e\udddc\ud83c\udffb\u200d\u2642\", \"\ud83e\udddc\ud83c\udffb\u200d\u2642\ufe0f\", \"\ud83e\udddc\ud83c\udffc\", \"\ud83e\udddc\ud83c\udffc\u200d\u2640\", \"\ud83e\udddc\ud83c\udffc\u200d\u2640\ufe0f\", \"\ud83e\udddc\ud83c\udffc\u200d\u2642\", \"\ud83e\udddc\ud83c\udffc\u200d\u2642\ufe0f\", \"\ud83e\udddc\ud83c\udffd\", \"\ud83e\udddc\ud83c\udffd\u200d\u2640\", \"\ud83e\udddc\ud83c\udffd\u200d\u2640\ufe0f\", \"\ud83e\udddc\ud83c\udffd\u200d\u2642\", \"\ud83e\udddc\ud83c\udffd\u200d\u2642\ufe0f\", \"\ud83e\udddc\ud83c\udffe\", \"\ud83e\udddc\ud83c\udffe\u200d\u2640\", \"\ud83e\udddc\ud83c\udffe\u200d\u2640\ufe0f\", \"\ud83e\udddc\ud83c\udffe\u200d\u2642\", \"\ud83e\udddc\ud83c\udffe\u200d\u2642\ufe0f\", \"\ud83e\udddc\ud83c\udfff\", \"\ud83e\udddc\ud83c\udfff\u200d\u2640\", \"\ud83e\udddc\ud83c\udfff\u200d\u2640\ufe0f\", \"\ud83e\udddc\ud83c\udfff\u200d\u2642\", \"\ud83e\udddc\ud83c\udfff\u200d\u2642\ufe0f\", \"\ud83e\udddd\", \"\ud83e\udddd\u200d\u2640\", \"\ud83e\udddd\u200d\u2640\ufe0f\", \"\ud83e\udddd\u200d\u2642\", \"\ud83e\udddd\u200d\u2642\ufe0f\", \"\ud83e\udddd\ud83c\udffb\", \"\ud83e\udddd\ud83c\udffb\u200d\u2640\", \"\ud83e\udddd\ud83c\udffb\u200d\u2640\ufe0f\", \"\ud83e\udddd\ud83c\udffb\u200d\u2642\", \"\ud83e\udddd\ud83c\udffb\u200d\u2642\ufe0f\", \"\ud83e\udddd\ud83c\udffc\", \"\ud83e\udddd\ud83c\udffc\u200d\u2640\", \"\ud83e\udddd\ud83c\udffc\u200d\u2640\ufe0f\", \"\ud83e\udddd\ud83c\udffc\u200d\u2642\", \"\ud83e\udddd\ud83c\udffc\u200d\u2642\ufe0f\", \"\ud83e\udddd\ud83c\udffd\", \"\ud83e\udddd\ud83c\udffd\u200d\u2640\", \"\ud83e\udddd\ud83c\udffd\u200d\u2640\ufe0f\", \"\ud83e\udddd\ud83c\udffd\u200d\u2642\", \"\ud83e\udddd\ud83c\udffd\u200d\u2642\ufe0f\", \"\ud83e\udddd\ud83c\udffe\", \"\ud83e\udddd\ud83c\udffe\u200d\u2640\", \"\ud83e\udddd\ud83c\udffe\u200d\u2640\ufe0f\", \"\ud83e\udddd\ud83c\udffe\u200d\u2642\", \"\ud83e\udddd\ud83c\udffe\u200d\u2642\ufe0f\", \"\ud83e\udddd\ud83c\udfff\", \"\ud83e\udddd\ud83c\udfff\u200d\u2640\", \"\ud83e\udddd\ud83c\udfff\u200d\u2640\ufe0f\", \"\ud83e\udddd\ud83c\udfff\u200d\u2642\", \"\ud83e\udddd\ud83c\udfff\u200d\u2642\ufe0f\", \"\ud83e\uddde\", \"\ud83e\uddde\u200d\u2640\", \"\ud83e\uddde\u200d\u2640\ufe0f\", \"\ud83e\uddde\u200d\u2642\", \"\ud83e\uddde\u200d\u2642\ufe0f\", \"\ud83e\udddf\", \"\ud83e\udddf\u200d\u2640\", \"\ud83e\udddf\u200d\u2640\ufe0f\", \"\ud83e\udddf\u200d\u2642\", \"\ud83e\udddf\u200d\u2642\ufe0f\", \"\ud83e\udde0\", \"\ud83e\udde1\", \"\ud83e\udde2\", \"\ud83e\udde3\", \"\ud83e\udde4\", \"\ud83e\udde5\", \"\ud83e\udde6\", \"\ud83e\udde7\", \"\ud83e\udde8\", \"\ud83e\udde9\", \"\ud83e\uddea\", \"\ud83e\uddeb\", \"\ud83e\uddec\", \"\ud83e\udded\", \"\ud83e\uddee\", \"\ud83e\uddef\", \"\ud83e\uddf0\", \"\ud83e\uddf1\", \"\ud83e\uddf2\", \"\ud83e\uddf3\", \"\ud83e\uddf4\", \"\ud83e\uddf5\", \"\ud83e\uddf6\", \"\ud83e\uddf7\", \"\ud83e\uddf8\", \"\ud83e\uddf9\", \"\ud83e\uddfa\", \"\ud83e\uddfb\", \"\ud83e\uddfc\", \"\ud83e\uddfd\", \"\ud83e\uddfe\", \"\ud83e\uddff\", \"\ud83e\ude70\", \"\ud83e\ude71\", \"\ud83e\ude72\", \"\ud83e\ude73\", \"\ud83e\ude74\", \"\ud83e\ude75\", \"\ud83e\ude76\", \"\ud83e\ude77\", \"\ud83e\ude78\", \"\ud83e\ude79\", \"\ud83e\ude7a\", \"\ud83e\ude7b\", \"\ud83e\ude7c\", \"\ud83e\ude80\", \"\ud83e\ude81\", \"\ud83e\ude82\", \"\ud83e\ude83\", \"\ud83e\ude84\", \"\ud83e\ude85\", \"\ud83e\ude86\", \"\ud83e\ude87\", \"\ud83e\ude88\", \"\ud83e\ude90\", \"\ud83e\ude91\", \"\ud83e\ude92\", \"\ud83e\ude93\", \"\ud83e\ude94\", \"\ud83e\ude95\", \"\ud83e\ude96\", \"\ud83e\ude97\", \"\ud83e\ude98\", \"\ud83e\ude99\", \"\ud83e\ude9a\", \"\ud83e\ude9b\", \"\ud83e\ude9c\", \"\ud83e\ude9d\", \"\ud83e\ude9e\", \"\ud83e\ude9f\", \"\ud83e\udea0\", \"\ud83e\udea1\", \"\ud83e\udea2\", \"\ud83e\udea3\", \"\ud83e\udea4\", \"\ud83e\udea5\", \"\ud83e\udea6\", \"\ud83e\udea7\", \"\ud83e\udea8\", \"\ud83e\udea9\", \"\ud83e\udeaa\", \"\ud83e\udeab\", \"\ud83e\udeac\", \"\ud83e\udead\", \"\ud83e\udeae\", \"\ud83e\udeaf\", \"\ud83e\udeb0\", \"\ud83e\udeb1\", \"\ud83e\udeb2\", \"\ud83e\udeb3\", \"\ud83e\udeb4\", \"\ud83e\udeb5\", \"\ud83e\udeb6\", \"\ud83e\udeb7\", \"\ud83e\udeb8\", \"\ud83e\udeb9\", \"\ud83e\udeba\", \"\ud83e\udebb\", \"\ud83e\udebc\", \"\ud83e\udebd\", \"\ud83e\udebf\", \"\ud83e\udec0\", \"\ud83e\udec1\", \"\ud83e\udec2\", \"\ud83e\udec3\", \"\ud83e\udec3\ud83c\udffb\", \"\ud83e\udec3\ud83c\udffc\", \"\ud83e\udec3\ud83c\udffd\", \"\ud83e\udec3\ud83c\udffe\", \"\ud83e\udec3\ud83c\udfff\", \"\ud83e\udec4\", \"\ud83e\udec4\ud83c\udffb\", \"\ud83e\udec4\ud83c\udffc\", \"\ud83e\udec4\ud83c\udffd\", \"\ud83e\udec4\ud83c\udffe\", \"\ud83e\udec4\ud83c\udfff\", \"\ud83e\udec5\", \"\ud83e\udec5\ud83c\udffb\", \"\ud83e\udec5\ud83c\udffc\", \"\ud83e\udec5\ud83c\udffd\", \"\ud83e\udec5\ud83c\udffe\", \"\ud83e\udec5\ud83c\udfff\", \"\ud83e\udece\", \"\ud83e\udecf\", \"\ud83e\uded0\", \"\ud83e\uded1\", \"\ud83e\uded2\", \"\ud83e\uded3\", \"\ud83e\uded4\", \"\ud83e\uded5\", \"\ud83e\uded6\", \"\ud83e\uded7\", \"\ud83e\uded8\", \"\ud83e\uded9\", \"\ud83e\udeda\", \"\ud83e\udedb\", \"\ud83e\udee0\", \"\ud83e\udee1\", \"\ud83e\udee2\", \"\ud83e\udee3\", \"\ud83e\udee4\", \"\ud83e\udee5\", \"\ud83e\udee6\", \"\ud83e\udee7\", \"\ud83e\udee8\", \"\ud83e\udef0\", \"\ud83e\udef0\ud83c\udffb\", \"\ud83e\udef0\ud83c\udffc\", \"\ud83e\udef0\ud83c\udffd\", \"\ud83e\udef0\ud83c\udffe\", \"\ud83e\udef0\ud83c\udfff\", \"\ud83e\udef1\", \"\ud83e\udef1\ud83c\udffb\", \"\ud83e\udef1\ud83c\udffb\u200d\ud83e\udef2\ud83c\udffc\", \"\ud83e\udef1\ud83c\udffb\u200d\ud83e\udef2\ud83c\udffd\", \"\ud83e\udef1\ud83c\udffb\u200d\ud83e\udef2\ud83c\udffe\", \"\ud83e\udef1\ud83c\udffb\u200d\ud83e\udef2\ud83c\udfff\", \"\ud83e\udef1\ud83c\udffc\", \"\ud83e\udef1\ud83c\udffc\u200d\ud83e\udef2\ud83c\udffb\", \"\ud83e\udef1\ud83c\udffc\u200d\ud83e\udef2\ud83c\udffd\", \"\ud83e\udef1\ud83c\udffc\u200d\ud83e\udef2\ud83c\udffe\", \"\ud83e\udef1\ud83c\udffc\u200d\ud83e\udef2\ud83c\udfff\", \"\ud83e\udef1\ud83c\udffd\", \"\ud83e\udef1\ud83c\udffd\u200d\ud83e\udef2\ud83c\udffb\", \"\ud83e\udef1\ud83c\udffd\u200d\ud83e\udef2\ud83c\udffc\", \"\ud83e\udef1\ud83c\udffd\u200d\ud83e\udef2\ud83c\udffe\", \"\ud83e\udef1\ud83c\udffd\u200d\ud83e\udef2\ud83c\udfff\", \"\ud83e\udef1\ud83c\udffe\", \"\ud83e\udef1\ud83c\udffe\u200d\ud83e\udef2\ud83c\udffb\", \"\ud83e\udef1\ud83c\udffe\u200d\ud83e\udef2\ud83c\udffc\", \"\ud83e\udef1\ud83c\udffe\u200d\ud83e\udef2\ud83c\udffd\", \"\ud83e\udef1\ud83c\udffe\u200d\ud83e\udef2\ud83c\udfff\", \"\ud83e\udef1\ud83c\udfff\", \"\ud83e\udef1\ud83c\udfff\u200d\ud83e\udef2\ud83c\udffb\", \"\ud83e\udef1\ud83c\udfff\u200d\ud83e\udef2\ud83c\udffc\", \"\ud83e\udef1\ud83c\udfff\u200d\ud83e\udef2\ud83c\udffd\", \"\ud83e\udef1\ud83c\udfff\u200d\ud83e\udef2\ud83c\udffe\", \"\ud83e\udef2\", \"\ud83e\udef2\ud83c\udffb\", \"\ud83e\udef2\ud83c\udffc\", \"\ud83e\udef2\ud83c\udffd\", \"\ud83e\udef2\ud83c\udffe\", \"\ud83e\udef2\ud83c\udfff\", \"\ud83e\udef3\", \"\ud83e\udef3\ud83c\udffb\", \"\ud83e\udef3\ud83c\udffc\", \"\ud83e\udef3\ud83c\udffd\", \"\ud83e\udef3\ud83c\udffe\", \"\ud83e\udef3\ud83c\udfff\", \"\ud83e\udef4\", \"\ud83e\udef4\ud83c\udffb\", \"\ud83e\udef4\ud83c\udffc\", \"\ud83e\udef4\ud83c\udffd\", \"\ud83e\udef4\ud83c\udffe\", \"\ud83e\udef4\ud83c\udfff\", \"\ud83e\udef5\", \"\ud83e\udef5\ud83c\udffb\", \"\ud83e\udef5\ud83c\udffc\", \"\ud83e\udef5\ud83c\udffd\", \"\ud83e\udef5\ud83c\udffe\", \"\ud83e\udef5\ud83c\udfff\", \"\ud83e\udef6\", \"\ud83e\udef6\ud83c\udffb\", \"\ud83e\udef6\ud83c\udffc\", \"\ud83e\udef6\ud83c\udffd\", \"\ud83e\udef6\ud83c\udffe\", \"\ud83e\udef6\ud83c\udfff\", \"\ud83e\udef7\", \"\ud83e\udef7\ud83c\udffb\", \"\ud83e\udef7\ud83c\udffc\", \"\ud83e\udef7\ud83c\udffd\", \"\ud83e\udef7\ud83c\udffe\", \"\ud83e\udef7\ud83c\udfff\", \"\ud83e\udef8\", \"\ud83e\udef8\ud83c\udffb\", \"\ud83e\udef8\ud83c\udffc\", \"\ud83e\udef8\ud83c\udffd\", \"\ud83e\udef8\ud83c\udffe\", \"\ud83e\udef8\ud83c\udfff\"}\n### EMOJIS END ###\n\n\n# The ESCAPED_EMOJI list is sorted in descending order to make that longer emoji appear\n# first in the regex compiled below. This ensures that we grab the full emoji in a\n# multi-character emoji sequence that starts with a shorter emoji (emoji are weird...).\nESCAPED_EMOJI = [re.escape(e) for e in sorted(ALL_EMOJIS, reverse=True)]\nEMOJI_EXTRACTION_REGEX = re.compile(f\"^({'|'.join(ESCAPED_EMOJI)})[_ -]*(.*)\")\n", "lib/streamlit/commands/execution_control.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport os\nfrom typing import Final, NoReturn\n\nimport streamlit as st\nfrom streamlit.errors import NoSessionContext, StreamlitAPIException\nfrom streamlit.file_util import get_main_script_directory, normalize_path_join\nfrom streamlit.logger import get_logger\nfrom streamlit.navigation.page import StreamlitPage\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.runtime.scriptrunner import RerunData, get_script_run_ctx\n\n_LOGGER: Final = get_logger(__name__)\n\n\n@gather_metrics(\"stop\")\ndef stop() -> NoReturn:  # type: ignore[misc]\n    \"\"\"Stops execution immediately.\n\n    Streamlit will not run any statements after `st.stop()`.\n    We recommend rendering a message to explain why the script has stopped.\n\n    Example\n    -------\n    >>> import streamlit as st\n    >>>\n    >>> name = st.text_input('Name')\n    >>> if not name:\n    >>>   st.warning('Please input a name.')\n    >>>   st.stop()\n    >>> st.success('Thank you for inputting a name.')\n\n    \"\"\"\n    ctx = get_script_run_ctx()\n\n    if ctx and ctx.script_requests:\n        ctx.script_requests.request_stop()\n        # Force a yield point so the runner can stop\n        st.empty()\n\n\n@gather_metrics(\"rerun\")\ndef rerun() -> NoReturn:  # type: ignore[misc]\n    \"\"\"Rerun the script immediately.\n\n    When ``st.rerun()`` is called, the script is halted - no more statements will\n    be run, and the script will be queued to re-run from the top.\n    \"\"\"\n\n    ctx = get_script_run_ctx()\n\n    # TODO: (rerun[scope] project): in order to make it a fragment-scoped rerun, pass\n    # the fragment_id_queue to the RerunData object and add the following line:\n    # fragment_id_queue=[ctx.current_fragment_id] if scope == \"fragment\" else []\n    # The script_runner RerunException is checking for the fragment_id_queue to decide\n    # whether or not to reset the dg_stack.\n\n    if ctx and ctx.script_requests:\n        query_string = ctx.query_string\n        page_script_hash = ctx.page_script_hash\n\n        ctx.script_requests.request_rerun(\n            RerunData(\n                query_string=query_string,\n                page_script_hash=page_script_hash,\n            )\n        )\n        # Force a yield point so the runner can do the rerun\n        st.empty()\n\n\n@gather_metrics(\"switch_page\")\ndef switch_page(page: str | StreamlitPage) -> NoReturn:  # type: ignore[misc]\n    \"\"\"Programmatically switch the current page in a multipage app.\n\n    When ``st.switch_page`` is called, the current page execution stops and\n    the specified page runs as if the user clicked on it in the sidebar\n    navigation. The specified page must be recognized by Streamlit's multipage\n    architecture (your main Python file or a Python file in a ``pages/``\n    folder). Arbitrary Python scripts cannot be passed to ``st.switch_page``.\n\n    Parameters\n    ----------\n    page: str or st.Page\n        The file path (relative to the main script) or an st.Page indicating\n        the page to switch to.\n\n\n    Example\n    -------\n    Consider the following example given this file structure:\n\n    >>> your-repository/\n    >>> \u251c\u2500\u2500 pages/\n    >>> \u2502   \u251c\u2500\u2500 page_1.py\n    >>> \u2502   \u2514\u2500\u2500 page_2.py\n    >>> \u2514\u2500\u2500 your_app.py\n\n    >>> import streamlit as st\n    >>>\n    >>> if st.button(\"Home\"):\n    >>>     st.switch_page(\"your_app.py\")\n    >>> if st.button(\"Page 1\"):\n    >>>     st.switch_page(\"pages/page_1.py\")\n    >>> if st.button(\"Page 2\"):\n    >>>     st.switch_page(\"pages/page_2.py\")\n\n    .. output ::\n        https://doc-switch-page.streamlit.app/\n        height: 350px\n\n    \"\"\"\n\n    ctx = get_script_run_ctx()\n\n    if not ctx or not ctx.script_requests:\n        # This should never be the case\n        raise NoSessionContext()\n\n    page_script_hash = \"\"\n    if isinstance(page, StreamlitPage):\n        page_script_hash = page._script_hash\n    else:\n        main_script_directory = get_main_script_directory(ctx.main_script_path)\n        requested_page = os.path.realpath(\n            normalize_path_join(main_script_directory, page)\n        )\n        all_app_pages = ctx.pages_manager.get_pages().values()\n\n        matched_pages = [p for p in all_app_pages if p[\"script_path\"] == requested_page]\n\n        if len(matched_pages) == 0:\n            raise StreamlitAPIException(\n                f\"Could not find page: `{page}`. Must be the file path relative to the main script, from the directory: `{os.path.basename(main_script_directory)}`. Only the main app file and files in the `pages/` directory are supported.\"\n            )\n\n        page_script_hash = matched_pages[0][\"page_script_hash\"]\n\n    ctx.script_requests.request_rerun(\n        RerunData(\n            query_string=ctx.query_string,\n            page_script_hash=page_script_hash,\n        )\n    )\n    # Force a yield point so the runner can do the rerun\n    st.empty()\n", "lib/streamlit/commands/logo.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Handle App logos\"\"\"\n\nfrom __future__ import annotations\n\nfrom streamlit import url_util\nfrom streamlit.elements.image import AtomicImage, WidthBehaviour, image_to_url\nfrom streamlit.errors import StreamlitAPIException\nfrom streamlit.proto.ForwardMsg_pb2 import ForwardMsg\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.runtime.scriptrunner import get_script_run_ctx\n\n\ndef _invalid_logo_text(field_name: str):\n    return f\"The {field_name} passed to st.logo is invalid - See [documentation](https://docs.streamlit.io/develop/api-reference/media/st.logo) for more information on valid types\"\n\n\n@gather_metrics(\"logo\")\ndef logo(\n    image: AtomicImage,\n    *,  # keyword-only args:\n    link: str | None = None,\n    icon_image: AtomicImage | None = None,\n) -> None:\n    \"\"\"\n    Renders a logo in the upper-left corner of your app and its sidebar.\n\n    If ``st.logo`` is called multiple times within a page, Streamlit will\n    render the image passed in the last call. For the most consistent results,\n    call ``st.logo`` early in your page script and choose an image that works\n    well in both light and dark mode. Avoid empty margins around your image.\n\n    If your logo does not work well for both light and dark mode, consider\n    setting the theme and hiding the settings menu from users with the\n    `configuration option <https://docs.streamlit.io/develop/api-reference/configuration/config.toml>`_\n    ``client.toolbarMode=\"minimal\"``.\n\n    Parameters\n    ----------\n    image: Anything supported by st.image\n        The image to display in the upper-left corner of your app and its\n        sidebar. If ``icon_image`` is also provided, then Streamlit will only\n        display ``image`` in the sidebar.\n\n        Streamlit scales the image to a height of 24 pixels and a maximum\n        width of 240 pixels. Use images with an aspect ratio of 10:1 or less to\n        avoid distortion.\n    link : str or None\n        The external URL to open when a user clicks on the logo. The URL must\n        start with \"\\\\http://\" or \"\\\\https://\". If ``link`` is ``None`` (default),\n        the logo will not include a hyperlink.\n    icon_image: Anything supported by st.image or None\n        An alternate image to replace ``image`` in the upper-left corner of the\n        app's main body. If ``icon_image`` is ``None`` (default), Streamlit\n        will render ``image`` in the upper-left corner of the app and its\n        sidebar. Otherwise, Streamlit will render ``icon_image`` in the\n        upper-left corner of the app and ``image`` in the upper-left corner\n        of the sidebar.\n\n        Streamlit scales the image to a height of 24 pixels and a maximum\n        width of 240 pixels. Use images with an aspect ratio of 10:1 or less to\n        avoid distortion.\n\n    Examples\n    --------\n    A common design practice is to use a wider logo in the sidebar, and a\n    smaller, icon-styled logo in your app's main body.\n\n    >>> import streamlit as st\n    >>>\n    >>> st.logo(LOGO_URL_LARGE, link=\"https://streamlit.io/gallery\", icon_image=LOGO_URL_SMALL)\n\n    Try switching logos around in the following example:\n\n    >>> import streamlit as st\n    >>>\n    >>> HORIZONTAL_RED = \"images/horizontal_red.png\"\n    >>> ICON_RED = \"images/icon_red.png\"\n    >>> HORIZONTAL_BLUE = \"images/horizontal_blue.png\"\n    >>> ICON_BLUE = \"images/icon_blue.png\"\n    >>>\n    >>> options = [HORIZONTAL_RED, ICON_RED, HORIZONTAL_BLUE, ICON_BLUE]\n    >>> sidebar_logo = st.selectbox(\"Sidebar logo\", options, 0)\n    >>> main_body_logo = st.selectbox(\"Main body logo\", options, 1)\n    >>>\n    >>> st.logo(sidebar_logo, icon_image=main_body_logo)\n    >>> st.sidebar.markdown(\"Hi!\")\n\n    .. output::\n        https://doc-logo.streamlit.app/\n        height: 300px\n\n    \"\"\"\n\n    ctx = get_script_run_ctx()\n    if ctx is None:\n        return\n\n    fwd_msg = ForwardMsg()\n\n    try:\n        image_url = image_to_url(\n            image,\n            width=WidthBehaviour.AUTO,\n            clamp=False,\n            channels=\"RGB\",\n            output_format=\"auto\",\n            image_id=\"logo\",\n        )\n        fwd_msg.logo.image = image_url\n    except Exception as ex:\n        raise StreamlitAPIException(_invalid_logo_text(\"image\")) from ex\n\n    if link:\n        # Handle external links:\n        if url_util.is_url(link, (\"http\", \"https\")):\n            fwd_msg.logo.link = link\n        else:\n            raise StreamlitAPIException(\n                f\"Invalid link: {link} - the link param supports external links only and must start with either http:// or https://.\"\n            )\n\n    if icon_image:\n        try:\n            icon_image_url = image_to_url(\n                icon_image,\n                width=WidthBehaviour.AUTO,\n                clamp=False,\n                channels=\"RGB\",\n                output_format=\"auto\",\n                image_id=\"icon-image\",\n            )\n            fwd_msg.logo.icon_image = icon_image_url\n        except Exception as ex:\n            raise StreamlitAPIException(_invalid_logo_text(\"icon_image\")) from ex\n\n    ctx.enqueue(fwd_msg)\n", "lib/streamlit/commands/experimental_query_params.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport urllib.parse as parse\nfrom typing import Any\n\nfrom streamlit import util\nfrom streamlit.constants import (\n    EMBED_OPTIONS_QUERY_PARAM,\n    EMBED_QUERY_PARAM,\n    EMBED_QUERY_PARAMS_KEYS,\n)\nfrom streamlit.errors import StreamlitAPIException\nfrom streamlit.proto.ForwardMsg_pb2 import ForwardMsg\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.runtime.scriptrunner import get_script_run_ctx\n\n\n@gather_metrics(\"experimental_get_query_params\")\ndef get_query_params() -> dict[str, list[str]]:\n    \"\"\"Return the query parameters that is currently showing in the browser's URL bar.\n\n    Returns\n    -------\n    dict\n      The current query parameters as a dict. \"Query parameters\" are the part of the URL that comes\n      after the first \"?\".\n\n    Example\n    -------\n    Let's say the user's web browser is at\n    `http://localhost:8501/?show_map=True&selected=asia&selected=america`.\n    Then, you can get the query parameters using the following:\n\n    >>> import streamlit as st\n    >>>\n    >>> st.experimental_get_query_params()\n    {\"show_map\": [\"True\"], \"selected\": [\"asia\", \"america\"]}\n\n    Note that the values in the returned dict are *always* lists. This is\n    because we internally use Python's urllib.parse.parse_qs(), which behaves\n    this way. And this behavior makes sense when you consider that every item\n    in a query string is potentially a 1-element array.\n\n    \"\"\"\n    ctx = get_script_run_ctx()\n    if ctx is None:\n        return {}\n    ctx.mark_experimental_query_params_used()\n    # Return new query params dict, but without embed, embed_options query params\n    return util.exclude_keys_in_dict(\n        parse.parse_qs(ctx.query_string, keep_blank_values=True),\n        keys_to_exclude=EMBED_QUERY_PARAMS_KEYS,\n    )\n\n\n@gather_metrics(\"experimental_set_query_params\")\ndef set_query_params(**query_params: Any) -> None:\n    \"\"\"Set the query parameters that are shown in the browser's URL bar.\n\n    .. warning::\n        Query param `embed` cannot be set using this method.\n\n    Parameters\n    ----------\n    **query_params : dict\n        The query parameters to set, as key-value pairs.\n\n    Example\n    -------\n\n    To point the user's web browser to something like\n    \"http://localhost:8501/?show_map=True&selected=asia&selected=america\",\n    you would do the following:\n\n    >>> import streamlit as st\n    >>>\n    >>> st.experimental_set_query_params(\n    ...     show_map=True,\n    ...     selected=[\"asia\", \"america\"],\n    ... )\n\n    \"\"\"\n    ctx = get_script_run_ctx()\n    if ctx is None:\n        return\n    ctx.mark_experimental_query_params_used()\n\n    msg = ForwardMsg()\n    msg.page_info_changed.query_string = _ensure_no_embed_params(\n        query_params, ctx.query_string\n    )\n    ctx.query_string = msg.page_info_changed.query_string\n    ctx.enqueue(msg)\n\n\ndef _ensure_no_embed_params(\n    query_params: dict[str, list[str] | str], query_string: str\n) -> str:\n    \"\"\"Ensures there are no embed params set (raises StreamlitAPIException) if there is a try,\n    also makes sure old param values in query_string are preserved. Returns query_string : str.\n    \"\"\"\n    # Get query params dict without embed, embed_options params\n    query_params_without_embed = util.exclude_keys_in_dict(\n        query_params, keys_to_exclude=EMBED_QUERY_PARAMS_KEYS\n    )\n    if query_params != query_params_without_embed:\n        raise StreamlitAPIException(\n            \"Query param embed and embed_options (case-insensitive) cannot be set using set_query_params method.\"\n        )\n\n    all_current_params = parse.parse_qs(query_string, keep_blank_values=True)\n    current_embed_params = parse.urlencode(\n        {\n            EMBED_QUERY_PARAM: list(\n                util.extract_key_query_params(\n                    all_current_params, param_key=EMBED_QUERY_PARAM\n                )\n            ),\n            EMBED_OPTIONS_QUERY_PARAM: list(\n                util.extract_key_query_params(\n                    all_current_params, param_key=EMBED_OPTIONS_QUERY_PARAM\n                )\n            ),\n        },\n        doseq=True,\n    )\n    query_string = parse.urlencode(query_params, doseq=True)\n\n    if query_string:\n        separator = \"&\" if current_embed_params else \"\"\n        return separator.join([query_string, current_embed_params])\n    return current_embed_params\n", "lib/streamlit/commands/page_config.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport random\nfrom textwrap import dedent\nfrom typing import TYPE_CHECKING, Final, Literal, Mapping, Union, cast\n\nfrom typing_extensions import TypeAlias\n\nfrom streamlit.elements import image\nfrom streamlit.errors import StreamlitAPIException\nfrom streamlit.proto.ForwardMsg_pb2 import ForwardMsg as ForwardProto\nfrom streamlit.proto.PageConfig_pb2 import PageConfig as PageConfigProto\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.runtime.scriptrunner import get_script_run_ctx\nfrom streamlit.string_util import is_emoji, validate_material_icon\nfrom streamlit.url_util import is_url\nfrom streamlit.util import lower_clean_dict_keys\n\nif TYPE_CHECKING:\n    from typing_extensions import TypeGuard\n\nGET_HELP_KEY: Final = \"get help\"\nREPORT_A_BUG_KEY: Final = \"report a bug\"\nABOUT_KEY: Final = \"about\"\n\nPageIcon: TypeAlias = Union[image.AtomicImage, str]\nLayout: TypeAlias = Literal[\"centered\", \"wide\"]\nInitialSideBarState: TypeAlias = Literal[\"auto\", \"expanded\", \"collapsed\"]\n_GetHelp: TypeAlias = Literal[\"Get help\", \"Get Help\", \"get help\"]\n_ReportABug: TypeAlias = Literal[\"Report a bug\", \"report a bug\"]\n_About: TypeAlias = Literal[\"About\", \"about\"]\nMenuKey: TypeAlias = Literal[_GetHelp, _ReportABug, _About]\nMenuItems: TypeAlias = Mapping[MenuKey, Union[str, None]]\n\n# Emojis recommended by https://share.streamlit.io/rensdimmendaal/emoji-recommender/main/app/streamlit.py\n# for the term \"streamlit\". Watch out for zero-width joiners,\n# as they won't parse correctly in the list() call!\nRANDOM_EMOJIS: Final = list(\n    \"\ud83d\udd25\u2122\ud83c\udf89\ud83d\ude80\ud83c\udf0c\ud83d\udca3\u2728\ud83c\udf19\ud83c\udf86\ud83c\udf87\ud83d\udca5\ud83e\udd29\ud83e\udd19\ud83c\udf1b\ud83e\udd18\u2b06\ud83d\udca1\ud83e\udd2a\ud83e\udd42\u26a1\ud83d\udca8\ud83c\udf20\ud83c\udf8a\ud83c\udf7f\ud83d\ude1b\ud83d\udd2e\ud83e\udd1f\ud83c\udf03\ud83c\udf43\ud83c\udf7e\ud83d\udcab\u25aa\ud83c\udf34\ud83c\udf88\ud83c\udfac\ud83c\udf00\ud83c\udf84\ud83d\ude1d\u2614\u26fd\ud83c\udf42\ud83d\udc83\ud83d\ude0e\ud83c\udf78\ud83c\udfa8\ud83e\udd73\u2600\ud83d\ude0d\ud83c\udd71\ud83c\udf1e\ud83d\ude3b\ud83c\udf1f\ud83d\ude1c\ud83d\udca6\ud83d\udc85\ud83e\udd84\ud83d\ude0b\ud83d\ude09\ud83d\udc7b\ud83c\udf41\ud83e\udd24\ud83d\udc6f\ud83c\udf3b\u203c\ud83c\udf08\ud83d\udc4c\ud83c\udf83\ud83d\udc9b\ud83d\ude1a\ud83d\udd2b\ud83d\ude4c\ud83d\udc7d\ud83c\udf6c\ud83c\udf05\u2601\ud83c\udf77\ud83d\udc6d\u2615\ud83c\udf1a\ud83d\udc81\ud83d\udc45\ud83e\udd70\ud83c\udf5c\ud83d\ude0c\ud83c\udfa5\ud83d\udd7a\u2755\ud83e\udde1\u2604\ud83d\udc95\ud83c\udf7b\u2705\ud83c\udf38\ud83d\udeac\ud83e\udd13\ud83c\udf79\u00ae\u263a\ud83d\udcaa\ud83d\ude19\u2618\ud83e\udd20\u270a\ud83e\udd17\ud83c\udf75\ud83e\udd1e\ud83d\ude02\ud83d\udcaf\ud83d\ude0f\ud83d\udcfb\ud83c\udf82\ud83d\udc97\ud83d\udc9c\ud83c\udf0a\u2763\ud83c\udf1d\ud83d\ude18\ud83d\udc86\ud83e\udd11\ud83c\udf3f\ud83e\udd8b\ud83d\ude08\u26c4\ud83d\udebf\ud83d\ude0a\ud83c\udf39\ud83e\udd74\ud83d\ude3d\ud83d\udc8b\ud83d\ude2d\ud83d\udda4\ud83d\ude46\ud83d\udc50\u26aa\ud83d\udc9f\u2603\ud83d\ude48\ud83c\udf6d\ud83d\udcbb\ud83e\udd40\ud83d\ude97\ud83e\udd27\ud83c\udf5d\ud83d\udc8e\ud83d\udc93\ud83e\udd1d\ud83d\udc84\ud83d\udc96\ud83d\udd1e\u2049\u23f0\ud83d\udd4a\ud83c\udfa7\u2620\u2665\ud83c\udf33\ud83c\udffe\ud83d\ude49\u2b50\ud83d\udc8a\ud83c\udf73\ud83c\udf0e\ud83d\ude4a\ud83d\udcb8\u2764\ud83d\udd2a\ud83d\ude06\ud83c\udf3e\u2708\ud83d\udcda\ud83d\udc80\ud83c\udfe0\u270c\ud83c\udfc3\ud83c\udf35\ud83d\udea8\ud83d\udc82\ud83e\udd2b\ud83e\udd2d\ud83d\ude17\ud83d\ude04\ud83c\udf52\ud83d\udc4f\ud83d\ude43\ud83d\udd96\ud83d\udc9e\ud83d\ude05\ud83c\udf85\ud83c\udf44\ud83c\udd93\ud83d\udc49\ud83d\udca9\ud83d\udd0a\ud83e\udd37\u231a\ud83d\udc78\ud83d\ude07\ud83d\udeae\ud83d\udc8f\ud83d\udc73\ud83c\udffd\ud83d\udc98\ud83d\udcbf\ud83d\udc89\ud83d\udc60\ud83c\udfbc\ud83c\udfb6\ud83c\udfa4\ud83d\udc57\u2744\ud83d\udd10\ud83c\udfb5\ud83e\udd12\ud83c\udf70\ud83d\udc53\ud83c\udfc4\ud83c\udf32\ud83c\udfae\ud83d\ude42\ud83d\udcc8\ud83d\ude99\ud83d\udccd\ud83d\ude35\ud83d\udde3\u2757\ud83c\udf3a\ud83d\ude44\ud83d\udc44\ud83d\ude98\ud83e\udd7a\ud83c\udf0d\ud83c\udfe1\u2666\ud83d\udc8d\ud83c\udf31\ud83d\udc51\ud83d\udc59\u2611\ud83d\udc7e\ud83c\udf69\ud83e\udd76\ud83d\udce3\ud83c\udffc\ud83e\udd23\u262f\ud83d\udc75\ud83c\udf6b\u27a1\ud83c\udf80\ud83d\ude03\u270b\ud83c\udf5e\ud83d\ude47\ud83d\ude39\ud83d\ude4f\ud83d\udc7c\ud83d\udc1d\u26ab\ud83c\udf81\ud83c\udf6a\ud83d\udd28\ud83c\udf3c\ud83d\udc46\ud83d\udc40\ud83d\ude33\ud83c\udf0f\ud83d\udcd6\ud83d\udc43\ud83c\udfb8\ud83d\udc67\ud83d\udc87\ud83d\udd12\ud83d\udc99\ud83d\ude1e\u26c5\ud83c\udffb\ud83c\udf74\ud83d\ude3c\ud83d\uddff\ud83c\udf57\u2660\ud83e\udd81\u2714\ud83e\udd16\u262e\ud83d\udc22\ud83d\udc0e\ud83d\udca4\ud83d\ude00\ud83c\udf7a\ud83d\ude01\ud83d\ude34\ud83d\udcfa\u2639\ud83d\ude32\ud83d\udc4d\ud83c\udfad\ud83d\udc9a\ud83c\udf46\ud83c\udf4b\ud83d\udd35\ud83c\udfc1\ud83d\udd34\ud83d\udd14\ud83e\uddd0\ud83d\udc70\u260e\ud83c\udfc6\ud83e\udd21\ud83d\udc20\ud83d\udcf2\ud83d\ude4b\ud83d\udccc\ud83d\udc2c\u270d\ud83d\udd11\ud83d\udcf1\ud83d\udcb0\ud83d\udc31\ud83d\udca7\ud83c\udf93\ud83c\udf55\ud83d\udc5f\ud83d\udc23\ud83d\udc6b\ud83c\udf51\ud83d\ude38\ud83c\udf66\ud83d\udc41\ud83c\udd97\ud83c\udfaf\ud83d\udce2\ud83d\udeb6\ud83e\udd85\ud83d\udc27\ud83d\udca2\ud83c\udfc0\ud83d\udeab\ud83d\udc91\ud83d\udc1f\ud83c\udf3d\ud83c\udfca\ud83c\udf5f\ud83d\udc9d\ud83d\udcb2\ud83d\udc0d\ud83c\udf65\ud83d\udc38\u261d\u2663\ud83d\udc4a\u2693\u274c\ud83d\udc2f\ud83c\udfc8\ud83d\udcf0\ud83c\udf27\ud83d\udc7f\ud83d\udc33\ud83d\udcb7\ud83d\udc3a\ud83d\udcde\ud83c\udd92\ud83c\udf40\ud83e\udd10\ud83d\udeb2\ud83c\udf54\ud83d\udc79\ud83d\ude4d\ud83c\udf37\ud83d\ude4e\ud83d\udc25\ud83d\udcb5\ud83d\udd1d\ud83d\udcf8\u26a0\u2753\ud83c\udfa9\u2702\ud83c\udf7c\ud83d\ude11\u2b07\u26be\ud83c\udf4e\ud83d\udc94\ud83d\udc14\u26bd\ud83d\udcad\ud83c\udfcc\ud83d\udc37\ud83c\udf4d\u2716\ud83c\udf47\ud83d\udcdd\ud83c\udf4a\ud83d\udc19\ud83d\udc4b\ud83e\udd14\ud83e\udd4a\ud83d\uddfd\ud83d\udc11\ud83d\udc18\ud83d\udc30\ud83d\udc90\ud83d\udc34\u2640\ud83d\udc26\ud83c\udf53\u270f\ud83d\udc42\ud83c\udff4\ud83d\udc47\ud83c\udd98\ud83d\ude21\ud83c\udfc9\ud83d\udc69\ud83d\udc8c\ud83d\ude3a\u271d\ud83d\udc3c\ud83d\udc12\ud83d\udc36\ud83d\udc7a\ud83d\udd95\ud83d\udc6c\ud83c\udf49\ud83d\udc3b\ud83d\udc3e\u2b05\u23ec\u25b6\ud83d\udc6e\ud83c\udf4c\u2642\ud83d\udd38\ud83d\udc76\ud83d\udc2e\ud83d\udc6a\u26f3\ud83d\udc10\ud83c\udfbe\ud83d\udc15\ud83d\udc74\ud83d\udc28\ud83d\udc0a\ud83d\udd39\u00a9\ud83c\udfa3\ud83d\udc66\ud83d\udc63\ud83d\udc68\ud83d\udc48\ud83d\udcac\u2b55\ud83d\udcf9\ud83d\udcf7\"\n)\n\n# Also pick out some vanity emojis.\nENG_EMOJIS: Final = [\n    \"\ud83c\udf88\",  # st.balloons \ud83c\udf88\ud83c\udf88\n    \"\ud83e\udd13\",  # Abhi\n    \"\ud83c\udfc8\",  # Amey\n    \"\ud83d\udeb2\",  # Thiago\n    \"\ud83d\udc27\",  # Matteo\n    \"\ud83e\udd92\",  # Ken\n    \"\ud83d\udc33\",  # Karrie\n    \"\ud83d\udd79\ufe0f\",  # Jonathan\n    \"\ud83c\udde6\ud83c\uddf2\",  # Henrikh\n    \"\ud83c\udfb8\",  # Guido\n    \"\ud83e\udd88\",  # Austin\n    \"\ud83d\udc8e\",  # Emiliano\n    \"\ud83d\udc69\u200d\ud83c\udfa4\",  # Naomi\n    \"\ud83e\uddd9\u200d\u2642\ufe0f\",  # Jon\n    \"\ud83d\udc3b\",  # Brandon\n    \"\ud83c\udf8e\",  # James\n    # TODO: Solicit emojis from the rest of Streamlit\n]\n\n\ndef _get_favicon_string(page_icon: PageIcon) -> str:\n    \"\"\"Return the string to pass to the frontend to have it show\n    the given PageIcon.\n\n    If page_icon is a string that looks like an emoji (or an emoji shortcode),\n    we return it as-is. Otherwise we use `image_to_url` to return a URL.\n\n    (If `image_to_url` raises an error and page_icon is a string, return\n    the unmodified page_icon string instead of re-raising the error.)\n    \"\"\"\n\n    # Choose a random emoji.\n    if page_icon == \"random\":\n        return get_random_emoji()\n\n    # If page_icon is an emoji, return it as is.\n    if isinstance(page_icon, str) and is_emoji(page_icon):\n        return page_icon\n\n    if isinstance(page_icon, str) and page_icon.startswith(\":material\"):\n        return validate_material_icon(page_icon)\n\n    # Fall back to image_to_url.\n    try:\n        return image.image_to_url(\n            page_icon,\n            width=-1,  # Always use full width for favicons\n            clamp=False,\n            channels=\"RGB\",\n            output_format=\"auto\",\n            image_id=\"favicon\",\n        )\n    except Exception:\n        if isinstance(page_icon, str):\n            # This fall-thru handles emoji shortcode strings (e.g. \":shark:\"),\n            # which aren't valid filenames and so will cause an Exception from\n            # `image_to_url`.\n            return page_icon\n        raise\n\n\n@gather_metrics(\"set_page_config\")\ndef set_page_config(\n    page_title: str | None = None,\n    page_icon: PageIcon | None = None,\n    layout: Layout = \"centered\",\n    initial_sidebar_state: InitialSideBarState = \"auto\",\n    menu_items: MenuItems | None = None,\n) -> None:\n    \"\"\"\n    Configures the default settings of the page.\n\n    .. note::\n        This must be the first Streamlit command used on an app page, and must only\n        be set once per page.\n\n    Parameters\n    ----------\n    page_title: str or None\n        The page title, shown in the browser tab. If None, defaults to the\n        filename of the script (\"app.py\" would show \"app \u2022 Streamlit\").\n\n    page_icon : Anything supported by st.image, str, or None\n        The page favicon. If ``page_icon`` is ``None`` (default), the favicon\n        will be a monochrome Streamlit logo.\n\n        In addition to the types supported by ``st.image`` (like URLs or numpy\n        arrays), the following strings are valid:\n\n        * A single-character emoji. For example, you can set ``page_icon=\"\ud83e\udd88\"``.\n\n        * An emoji short code. For example, you can set ``page_icon=\":shark:\"``.\n          For a list of all supported codes, see\n          https://share.streamlit.io/streamlit/emoji-shortcodes.\n\n        * The string literal, ``\"random\"``. You can set ``page_icon=\"random\"``\n          to set a random emoji from the supported list above. Emoji icons are\n          courtesy of Twemoji and loaded from MaxCDN.\n\n        * An icon from the Material Symbols library (outlined style) in the\n          format ``\":material/icon_name:\"`` where \"icon_name\" is the name\n          of the icon in snake case.\n\n          For example, ``icon=\":material/thumb_up:\"`` will display the\n          Thumb Up icon. Find additional icons in the `Material Symbols \\\n          <https://fonts.google.com/icons?icon.set=Material+Symbols&icon.style=Outlined>`_\n          font library.\n\n        .. note::\n            Colors are not supported for Material icons. When you use a\n            Material icon for favicon, it will be black, regardless of browser\n            theme.\n\n    layout: \"centered\" or \"wide\"\n        How the page content should be laid out. Defaults to \"centered\",\n        which constrains the elements into a centered column of fixed width;\n        \"wide\" uses the entire screen.\n\n    initial_sidebar_state: \"auto\", \"expanded\", or \"collapsed\"\n        How the sidebar should start out. Defaults to \"auto\",\n        which hides the sidebar on small devices and shows it otherwise.\n        \"expanded\" shows the sidebar initially; \"collapsed\" hides it.\n        In most cases, you should just use \"auto\", otherwise the app will\n        look bad when embedded and viewed on mobile.\n\n    menu_items: dict\n        Configure the menu that appears on the top-right side of this app.\n        The keys in this dict denote the menu item you'd like to configure:\n\n        - \"Get help\": str or None\n            The URL this menu item should point to.\n            If None, hides this menu item.\n        - \"Report a Bug\": str or None\n            The URL this menu item should point to.\n            If None, hides this menu item.\n        - \"About\": str or None\n            A markdown string to show in the About dialog.\n            If None, only shows Streamlit's default About text.\n\n        The URL may also refer to an email address e.g. ``mailto:john@example.com``.\n\n    Example\n    -------\n    >>> import streamlit as st\n    >>>\n    >>> st.set_page_config(\n    ...     page_title=\"Ex-stream-ly Cool App\",\n    ...     page_icon=\"\ud83e\uddca\",\n    ...     layout=\"wide\",\n    ...     initial_sidebar_state=\"expanded\",\n    ...     menu_items={\n    ...         'Get Help': 'https://www.extremelycoolapp.com/help',\n    ...         'Report a bug': \"https://www.extremelycoolapp.com/bug\",\n    ...         'About': \"# This is a header. This is an *extremely* cool app!\"\n    ...     }\n    ... )\n    \"\"\"\n\n    msg = ForwardProto()\n\n    if page_title is not None:\n        msg.page_config_changed.title = page_title\n\n    if page_icon is not None:\n        msg.page_config_changed.favicon = _get_favicon_string(page_icon)\n\n    pb_layout: PageConfigProto.Layout.ValueType\n    if layout == \"centered\":\n        pb_layout = PageConfigProto.CENTERED\n    elif layout == \"wide\":\n        pb_layout = PageConfigProto.WIDE\n    else:\n        raise StreamlitAPIException(\n            f'`layout` must be \"centered\" or \"wide\" (got \"{layout}\")'\n        )\n    msg.page_config_changed.layout = pb_layout\n\n    pb_sidebar_state: PageConfigProto.SidebarState.ValueType\n    if initial_sidebar_state == \"auto\":\n        pb_sidebar_state = PageConfigProto.AUTO\n    elif initial_sidebar_state == \"expanded\":\n        pb_sidebar_state = PageConfigProto.EXPANDED\n    elif initial_sidebar_state == \"collapsed\":\n        pb_sidebar_state = PageConfigProto.COLLAPSED\n    else:\n        raise StreamlitAPIException(\n            \"`initial_sidebar_state` must be \"\n            '\"auto\" or \"expanded\" or \"collapsed\" '\n            f'(got \"{initial_sidebar_state}\")'\n        )\n\n    msg.page_config_changed.initial_sidebar_state = pb_sidebar_state\n\n    if menu_items is not None:\n        lowercase_menu_items = cast(MenuItems, lower_clean_dict_keys(menu_items))\n        validate_menu_items(lowercase_menu_items)\n        menu_items_proto = msg.page_config_changed.menu_items\n        set_menu_items_proto(lowercase_menu_items, menu_items_proto)\n\n    ctx = get_script_run_ctx()\n    if ctx is None:\n        return\n    ctx.enqueue(msg)\n\n\ndef get_random_emoji() -> str:\n    # Weigh our emojis 10x, cuz we're awesome!\n    # TODO: fix the random seed with a hash of the user's app code, for stability?\n    return random.choice(RANDOM_EMOJIS + 10 * ENG_EMOJIS)\n\n\ndef set_menu_items_proto(lowercase_menu_items, menu_items_proto) -> None:\n    if GET_HELP_KEY in lowercase_menu_items:\n        if lowercase_menu_items[GET_HELP_KEY] is not None:\n            menu_items_proto.get_help_url = lowercase_menu_items[GET_HELP_KEY]\n        else:\n            menu_items_proto.hide_get_help = True\n\n    if REPORT_A_BUG_KEY in lowercase_menu_items:\n        if lowercase_menu_items[REPORT_A_BUG_KEY] is not None:\n            menu_items_proto.report_a_bug_url = lowercase_menu_items[REPORT_A_BUG_KEY]\n        else:\n            menu_items_proto.hide_report_a_bug = True\n\n    if ABOUT_KEY in lowercase_menu_items:\n        if lowercase_menu_items[ABOUT_KEY] is not None:\n            menu_items_proto.about_section_md = dedent(lowercase_menu_items[ABOUT_KEY])\n\n\ndef validate_menu_items(menu_items: MenuItems) -> None:\n    for k, v in menu_items.items():\n        if not valid_menu_item_key(k):\n            raise StreamlitAPIException(\n                \"We only accept the keys: \"\n                '\"Get help\", \"Report a bug\", and \"About\" '\n                f'(\"{k}\" is not a valid key.)'\n            )\n        if v is not None and (\n            not is_url(v, (\"http\", \"https\", \"mailto\")) and k != ABOUT_KEY\n        ):\n            raise StreamlitAPIException(f'\"{v}\" is a not a valid URL!')\n\n\ndef valid_menu_item_key(key: str) -> TypeGuard[MenuKey]:\n    return key in {GET_HELP_KEY, REPORT_A_BUG_KEY, ABOUT_KEY}\n", "lib/streamlit/commands/navigation.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom pathlib import Path\nfrom typing import TYPE_CHECKING, Literal\n\nfrom typing_extensions import TypeAlias\n\nfrom streamlit.errors import StreamlitAPIException\nfrom streamlit.proto.ForwardMsg_pb2 import ForwardMsg\nfrom streamlit.proto.Navigation_pb2 import Navigation as NavigationProto\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.runtime.scriptrunner.script_run_context import (\n    ScriptRunContext,\n    get_script_run_ctx,\n)\n\nif TYPE_CHECKING:\n    from streamlit.navigation.page import StreamlitPage\n    from streamlit.source_util import PageHash, PageInfo\n\nSectionHeader: TypeAlias = str\n\n\ndef pages_from_nav_sections(\n    nav_sections: dict[SectionHeader, list[StreamlitPage]],\n) -> list[StreamlitPage]:\n    page_list = []\n    for pages in nav_sections.values():\n        for page in pages:\n            page_list.append(page)\n\n    return page_list\n\n\ndef send_page_not_found(ctx: ScriptRunContext):\n    msg = ForwardMsg()\n    msg.page_not_found.page_name = \"\"\n    ctx.enqueue(msg)\n\n\n@gather_metrics(\"navigation\")\ndef navigation(\n    pages: list[StreamlitPage] | dict[SectionHeader, list[StreamlitPage]],\n    *,\n    position: Literal[\"sidebar\", \"hidden\"] = \"sidebar\",\n) -> StreamlitPage:\n    \"\"\"\n    Configure the available pages in a multipage app.\n\n    Call ``st.navigation`` in your entrypoint file with one or more pages\n    defined by ``st.Page``. ``st.navigation`` returns the current page, which\n    can be executed using ``.run()`` method.\n\n    When using ``st.navigation``, your entrypoint file (the file passed to\n    ``streamlit run``) acts like a router or frame of common elements around\n    each of your pages. Streamlit executes the entrypoint file with every app\n    rerun. To execute the current page, you must call the ``.run()`` method on\n    the page object returned by ``st.navigation``.\n\n    The set of available pages can be updated with each rerun for dynamic\n    navigation. By default, ``st.navigation`` draws the available pages in the\n    side navigation if there is more than one page. This behavior can be\n    changed using the ``position`` keyword argument.\n\n    As soon as any session of your app executes the ``st.navigation`` command,\n    your app will ignore the ``pages/`` directory (across all sessions).\n\n    Parameters\n    ----------\n    pages: list[StreamlitPage] or dict[str, list[StreamlitPage]]\n        The available pages for the app.\n\n        To create labeled sections or page groupings within the navigation\n        menu, ``pages`` must be a dictionary. Each key is the label of a\n        section and each value is the list of ``StreamlitPage`` objects for\n        that section.\n\n        To create a navigation menu with no sections or page groupings,\n        ``pages`` must be a list of ``StreamlitPage`` objects.\n\n        Use ``st.Page`` to create ``StreamlitPage`` objects.\n\n    position: \"sidebar\" or \"hidden\"\n        The position of the navigation menu. If ``position`` is ``\"sidebar\"``\n        (default), the navigation widget appears at the top of the sidebar. If\n        ``position`` is ``\"hidden\"``, the navigation widget is not displayed.\n\n        If there is only one page in ``pages``, the navigation will be hidden\n        for any value of ``position``.\n\n    Returns\n    -------\n    StreamlitPage\n        The current page selected by the user.\n\n    Examples\n    --------\n    The following examples show possible entrypoint files, which is the file\n    you pass to ``streamlit run``. Your entrypoint file manages your app's\n    navigation and serves as a router between pages.\n\n    You can declare pages from callables or file paths.\n\n    >>> import streamlit as st\n    >>> from page_functions import page1\n    >>>\n    >>> pg = st.navigation([st.Page(page1), st.Page(\"page2.py\")])\n    >>> pg.run()\n\n    Use a dictionary to create sections within your navigation menu.\n\n    >>> import streamlit as st\n    >>>\n    >>> pages = {\n    ...     \"Your account\" : [\n    ...         st.Page(\"create_account.py\", title=\"Create your account\"),\n    ...         st.Page(\"manage_account.py\", title=\"Manage your account\")\n    ...     ],\n    ...     \"Resources\" : [\n    ...         st.Page(\"learn.py\", title=\"Learn about us\"),\n    ...         st.Page(\"trial.py\", title=\"Try it out\")\n    ...     ]\n    ... }\n    >>>\n    >>> pg = st.navigation(pages)\n    >>> pg.run()\n\n    Call widget functions in your entrypoint file when you want a widget to be\n    stateful across pages. Assign keys to your common widgets and access their\n    values through Session State within your pages.\n\n    >>> import streamlit as st\n    >>>\n    >>> def page1():\n    >>>     st.write(st.session_state.foo)\n    >>>\n    >>> def page2():\n    >>>     st.write(st.session_state.bar)\n    >>>\n    >>> # Widgets shared by all the pages\n    >>> st.sidebar.selectbox(\"Foo\", [\"A\", \"B\", \"C\"], key=\"foo\")\n    >>> st.sidebar.checkbox(\"Bar\", key=\"bar\")\n    >>>\n    >>> pg = st.navigation(st.Page(page1), st.Page(page2))\n    >>> pg.run()\n\n    \"\"\"\n    nav_sections = {\"\": pages} if isinstance(pages, list) else pages\n    page_list = pages_from_nav_sections(nav_sections)\n\n    if not page_list:\n        raise StreamlitAPIException(\n            \"`st.navigation` must be called with at least one `st.Page`.\"\n        )\n\n    default_page = None\n    pagehash_to_pageinfo: dict[PageHash, PageInfo] = {}\n\n    # This nested loop keeps track of two things:\n    # 1. the default page\n    # 2. the pagehash to pageinfo mapping\n    for section_header in nav_sections:\n        for page in nav_sections[section_header]:\n            if page._default:\n                if default_page is not None:\n                    raise StreamlitAPIException(\n                        \"Multiple Pages specified with `default=True`. \"\n                        \"At most one Page can be set to default.\"\n                    )\n                default_page = page\n\n            if isinstance(page._page, Path):\n                script_path = str(page._page)\n            else:\n                script_path = \"\"\n\n            script_hash = page._script_hash\n            if script_hash in pagehash_to_pageinfo:\n                # The page script hash is soley based on the url path\n                # So duplicate page script hashes are due to duplicate url paths\n                raise StreamlitAPIException(\n                    f\"Multiple Pages specified with URL pathname {page.url_path}. \"\n                    \"URL pathnames must be unique. The url pathname may be \"\n                    \"inferred from the filename, callable name, or title.\"\n                )\n\n            pagehash_to_pageinfo[script_hash] = {\n                \"page_script_hash\": script_hash,\n                \"page_name\": page.title,\n                \"icon\": page.icon,\n                \"script_path\": script_path,\n                \"url_pathname\": page.url_path,\n            }\n\n    if default_page is None:\n        default_page = page_list[0]\n        default_page._default = True\n\n    msg = ForwardMsg()\n    if position == \"hidden\":\n        msg.navigation.position = NavigationProto.Position.HIDDEN\n    else:\n        msg.navigation.position = NavigationProto.Position.SIDEBAR\n    msg.navigation.sections[:] = nav_sections.keys()\n    for section_header in nav_sections:\n        for page in nav_sections[section_header]:\n            p = msg.navigation.app_pages.add()\n            p.page_script_hash = page._script_hash\n            p.page_name = page.title\n            p.icon = page.icon\n            p.is_default = page._default\n            p.section_header = section_header\n            p.url_pathname = page.url_path\n\n    ctx = get_script_run_ctx()\n    if not ctx:\n        # This should never run in Streamlit, but we want to make sure that\n        # the function always returns a page\n        default_page._can_be_called = True\n        return default_page\n\n    # Inform our page manager about the set of pages we have\n    ctx.pages_manager.set_pages(pagehash_to_pageinfo)\n    found_page = ctx.pages_manager.get_page_script(\n        fallback_page_hash=default_page._script_hash\n    )\n\n    page_to_return = None\n    if found_page:\n        found_page_script_hash = found_page[\"page_script_hash\"]\n        matching_pages = [\n            p for p in page_list if p._script_hash == found_page_script_hash\n        ]\n        if len(matching_pages) > 0:\n            page_to_return = matching_pages[0]\n\n    if not page_to_return:\n        send_page_not_found(ctx)\n        page_to_return = default_page\n\n    # Ordain the page that can be called\n    page_to_return._can_be_called = True\n    msg.navigation.page_script_hash = page_to_return._script_hash\n    # Set the current page script hash to the page that is going to be executed\n    ctx.pages_manager.set_current_page_script_hash(page_to_return._script_hash)\n\n    # This will either navigation or yield if the page is not found\n    ctx.enqueue(msg)\n\n    return page_to_return\n", "lib/streamlit/commands/__init__.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n", "lib/streamlit/watcher/polling_path_watcher.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"A class that watches a given path via polling.\"\"\"\n\nfrom __future__ import annotations\n\nimport time\nfrom concurrent.futures import ThreadPoolExecutor\nfrom typing import Callable, Final\n\nfrom streamlit.logger import get_logger\nfrom streamlit.util import repr_\nfrom streamlit.watcher import util\n\n_LOGGER: Final = get_logger(__name__)\n\n_MAX_WORKERS: Final = 4\n_POLLING_PERIOD_SECS: Final = 0.2\n\n\nclass PollingPathWatcher:\n    \"\"\"Watches a path on disk via a polling loop.\"\"\"\n\n    _executor = ThreadPoolExecutor(max_workers=_MAX_WORKERS)\n\n    @staticmethod\n    def close_all() -> None:\n        \"\"\"Close top-level watcher object.\n\n        This is a no-op, and exists for interface parity with\n        EventBasedPathWatcher.\n        \"\"\"\n        _LOGGER.debug(\"Watcher closed\")\n\n    def __init__(\n        self,\n        path: str,\n        on_changed: Callable[[str], None],\n        *,  # keyword-only arguments:\n        glob_pattern: str | None = None,\n        allow_nonexistent: bool = False,\n    ) -> None:\n        \"\"\"Constructor.\n\n        You do not need to retain a reference to a PollingPathWatcher to\n        prevent it from being garbage collected. (The global _executor object\n        retains references to all active instances.)\n        \"\"\"\n        # TODO(vdonato): Modernize this by switching to pathlib.\n        self._path = path\n        self._on_changed = on_changed\n\n        self._glob_pattern = glob_pattern\n        self._allow_nonexistent = allow_nonexistent\n\n        self._active = True\n\n        self._modification_time = util.path_modification_time(\n            self._path, self._allow_nonexistent\n        )\n        self._md5 = util.calc_md5_with_blocking_retries(\n            self._path,\n            glob_pattern=self._glob_pattern,\n            allow_nonexistent=self._allow_nonexistent,\n        )\n        self._schedule()\n\n    def __repr__(self) -> str:\n        return repr_(self)\n\n    def _schedule(self) -> None:\n        def task():\n            time.sleep(_POLLING_PERIOD_SECS)\n            self._check_if_path_changed()\n\n        PollingPathWatcher._executor.submit(task)\n\n    def _check_if_path_changed(self) -> None:\n        if not self._active:\n            # Don't call self._schedule()\n            return\n\n        modification_time = util.path_modification_time(\n            self._path, self._allow_nonexistent\n        )\n        # We add modification_time != 0.0 check since on some file systems (s3fs/fuse)\n        # modification_time is always 0.0 because of file system limitations.\n        if modification_time != 0.0 and modification_time <= self._modification_time:\n            self._schedule()\n            return\n\n        self._modification_time = modification_time\n\n        md5 = util.calc_md5_with_blocking_retries(\n            self._path,\n            glob_pattern=self._glob_pattern,\n            allow_nonexistent=self._allow_nonexistent,\n        )\n        if md5 == self._md5:\n            self._schedule()\n            return\n\n        self._md5 = md5\n\n        _LOGGER.debug(\"Change detected: %s\", self._path)\n        self._on_changed(self._path)\n\n        self._schedule()\n\n    def close(self) -> None:\n        \"\"\"Stop watching the file system.\"\"\"\n        self._active = False\n", "lib/streamlit/watcher/local_sources_watcher.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport os\nimport sys\nfrom pathlib import Path\nfrom typing import TYPE_CHECKING, Any, Callable, Final, NamedTuple\n\nfrom streamlit import config, file_util\nfrom streamlit.folder_black_list import FolderBlackList\nfrom streamlit.logger import get_logger\nfrom streamlit.watcher.path_watcher import (\n    NoOpPathWatcher,\n    get_default_path_watcher_class,\n)\n\nif TYPE_CHECKING:\n    from types import ModuleType\n\n    from streamlit.runtime.pages_manager import PagesManager\n\n_LOGGER: Final = get_logger(__name__)\n\n\nclass WatchedModule(NamedTuple):\n    watcher: Any\n    module_name: Any\n\n\n# This needs to be initialized lazily to avoid calling config.get_option() and\n# thus initializing config options when this file is first imported.\nPathWatcher = None\n\n\nclass LocalSourcesWatcher:\n    def __init__(self, pages_manager: PagesManager):\n        self._pages_manager = pages_manager\n        self._main_script_path = os.path.abspath(self._pages_manager.main_script_path)\n        self._script_folder = os.path.dirname(self._main_script_path)\n        self._on_file_changed: list[Callable[[str], None]] = []\n        self._is_closed = False\n        self._cached_sys_modules: set[str] = set()\n\n        # Blacklist for folders that should not be watched\n        self._folder_black_list = FolderBlackList(\n            config.get_option(\"server.folderWatchBlacklist\")\n        )\n\n        self._watched_modules: dict[str, WatchedModule] = {}\n        self._watched_pages: set[str] = set()\n\n        self.update_watched_pages()\n\n    def update_watched_pages(self) -> None:\n        old_page_paths = self._watched_pages.copy()\n        new_pages_paths: set[str] = set()\n\n        for page_info in self._pages_manager.get_pages().values():\n            if not page_info[\"script_path\"]:\n                continue\n\n            new_pages_paths.add(page_info[\"script_path\"])\n            if page_info[\"script_path\"] not in self._watched_pages:\n                self._register_watcher(\n                    page_info[\"script_path\"],\n                    module_name=None,\n                )\n\n        for old_page_path in old_page_paths:\n            # Only remove pages that are no longer valid files\n            if old_page_path not in new_pages_paths and not os.path.isfile(\n                old_page_path\n            ):\n                self._deregister_watcher(old_page_path)\n                self._watched_pages.remove(old_page_path)\n\n        self._watched_pages = self._watched_pages.union(new_pages_paths)\n\n    def register_file_change_callback(self, cb: Callable[[str], None]) -> None:\n        self._on_file_changed.append(cb)\n\n    def on_file_changed(self, filepath):\n        if filepath not in self._watched_modules:\n            _LOGGER.error(\"Received event for non-watched file: %s\", filepath)\n            return\n\n        # Workaround:\n        # Delete all watched modules so we can guarantee changes to the\n        # updated module are reflected on reload.\n        #\n        # In principle, for reloading a given module, we only need to unload\n        # the module itself and all of the modules which import it (directly\n        # or indirectly) such that when we exec the application code, the\n        # changes are reloaded and reflected in the running application.\n        #\n        # However, determining all import paths for a given loaded module is\n        # non-trivial, and so as a workaround we simply unload all watched\n        # modules.\n        for wm in self._watched_modules.values():\n            if wm.module_name is not None and wm.module_name in sys.modules:\n                del sys.modules[wm.module_name]\n\n        for cb in self._on_file_changed:\n            cb(filepath)\n\n    def close(self):\n        for wm in self._watched_modules.values():\n            wm.watcher.close()\n        self._watched_modules = {}\n        self._watched_pages = set()\n        self._is_closed = True\n\n    def _register_watcher(self, filepath, module_name):\n        global PathWatcher\n        if PathWatcher is None:\n            PathWatcher = get_default_path_watcher_class()\n\n        if PathWatcher is NoOpPathWatcher:\n            return\n\n        try:\n            wm = WatchedModule(\n                watcher=PathWatcher(filepath, self.on_file_changed),\n                module_name=module_name,\n            )\n        except PermissionError:\n            # If you don't have permission to read this file, don't even add it\n            # to watchers.\n            return\n\n        self._watched_modules[filepath] = wm\n\n    def _deregister_watcher(self, filepath):\n        if filepath not in self._watched_modules:\n            return\n\n        if filepath == self._main_script_path:\n            return\n\n        wm = self._watched_modules[filepath]\n        wm.watcher.close()\n        del self._watched_modules[filepath]\n\n    def _file_is_new(self, filepath):\n        return filepath not in self._watched_modules\n\n    def _file_should_be_watched(self, filepath):\n        # Using short circuiting for performance.\n        return self._file_is_new(filepath) and (\n            file_util.file_is_in_folder_glob(filepath, self._script_folder)\n            or file_util.file_in_pythonpath(filepath)\n        )\n\n    def update_watched_modules(self):\n        if self._is_closed:\n            return\n\n        if set(sys.modules) != self._cached_sys_modules:\n            modules_paths = {\n                name: self._exclude_blacklisted_paths(get_module_paths(module))\n                for name, module in dict(sys.modules).items()\n            }\n            self._cached_sys_modules = set(sys.modules)\n            self._register_necessary_watchers(modules_paths)\n\n    def _register_necessary_watchers(self, module_paths: dict[str, set[str]]) -> None:\n        for name, paths in module_paths.items():\n            for path in paths:\n                if self._file_should_be_watched(path):\n                    self._register_watcher(str(Path(path).resolve()), name)\n\n    def _exclude_blacklisted_paths(self, paths: set[str]) -> set[str]:\n        return {p for p in paths if not self._folder_black_list.is_blacklisted(p)}\n\n\ndef get_module_paths(module: ModuleType) -> set[str]:\n    paths_extractors = [\n        # https://docs.python.org/3/reference/datamodel.html\n        # __file__ is the pathname of the file from which the module was loaded\n        # if it was loaded from a file.\n        # The __file__ attribute may be missing for certain types of modules\n        lambda m: [m.__file__],\n        # https://docs.python.org/3/reference/import.html#__spec__\n        # The __spec__ attribute is set to the module spec that was used\n        # when importing the module. one exception is __main__,\n        # where __spec__ is set to None in some cases.\n        # https://www.python.org/dev/peps/pep-0451/#id16\n        # \"origin\" in an import context means the system\n        # (or resource within a system) from which a module originates\n        # ... It is up to the loader to decide on how to interpret\n        # and use a module's origin, if at all.\n        lambda m: [m.__spec__.origin],\n        # https://www.python.org/dev/peps/pep-0420/\n        # Handling of \"namespace packages\" in which the __path__ attribute\n        # is a _NamespacePath object with a _path attribute containing\n        # the various paths of the package.\n        lambda m: list(m.__path__._path),\n    ]\n\n    all_paths = set()\n    for extract_paths in paths_extractors:\n        potential_paths = []\n        try:\n            potential_paths = extract_paths(module)\n        except AttributeError:\n            # Some modules might not have __file__ or __spec__ attributes.\n            pass\n        except Exception as e:\n            _LOGGER.warning(f\"Examining the path of {module.__name__} raised: {e}\")\n\n        all_paths.update(\n            [os.path.abspath(str(p)) for p in potential_paths if _is_valid_path(p)]\n        )\n    return all_paths\n\n\ndef _is_valid_path(path: str | None) -> bool:\n    return isinstance(path, str) and (os.path.isfile(path) or os.path.isdir(path))\n", "lib/streamlit/watcher/util.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"A bunch of useful utilities for the watcher.\n\nThese are functions that only make sense within the watcher. In particular,\nfunctions that use streamlit.config can go here to avoid a dependency cycle.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport hashlib\nimport os\nimport time\nfrom pathlib import Path\n\nfrom streamlit.util import HASHLIB_KWARGS\n\n# How many times to try to grab the MD5 hash.\n_MAX_RETRIES = 5\n\n# How long to wait between retries.\n_RETRY_WAIT_SECS = 0.1\n\n\ndef calc_md5_with_blocking_retries(\n    path: str,\n    *,  # keyword-only arguments:\n    glob_pattern: str | None = None,\n    allow_nonexistent: bool = False,\n) -> str:\n    \"\"\"Calculate the MD5 checksum of a given path.\n\n    For a file, this means calculating the md5 of the file's contents. For a\n    directory, we concatenate the directory's path with the names of all the\n    files in it and calculate the md5 of that.\n\n    IMPORTANT: This method calls time.sleep(), which blocks execution. So you\n    should only use this outside the main thread.\n    \"\"\"\n\n    if allow_nonexistent and not os.path.exists(path):\n        content = path.encode(\"UTF-8\")\n    elif os.path.isdir(path):\n        glob_pattern = glob_pattern or \"*\"\n        content = _stable_dir_identifier(path, glob_pattern).encode(\"UTF-8\")\n    else:\n        content = _get_file_content_with_blocking_retries(path)\n\n    md5 = hashlib.md5(**HASHLIB_KWARGS)\n    md5.update(content)\n\n    # Use hexdigest() instead of digest(), so it's easier to debug.\n    return md5.hexdigest()\n\n\ndef path_modification_time(path: str, allow_nonexistent: bool = False) -> float:\n    \"\"\"Return the modification time of a path (file or directory).\n\n    If allow_nonexistent is True and the path does not exist, we return 0.0 to\n    guarantee that any file/dir later created at the path has a later\n    modification time than the last time returned by this function for that\n    path.\n\n    If allow_nonexistent is False and no file/dir exists at the path, a\n    FileNotFoundError is raised (by os.stat).\n\n    For any path that does correspond to an existing file/dir, we return its\n    modification time.\n    \"\"\"\n    if allow_nonexistent and not os.path.exists(path):\n        return 0.0\n    return os.stat(path).st_mtime\n\n\ndef _get_file_content_with_blocking_retries(file_path: str) -> bytes:\n    content = b\"\"\n    # There's a race condition where sometimes file_path no longer exists when\n    # we try to read it (since the file is in the process of being written).\n    # So here we retry a few times using this loop. See issue #186.\n    for i in range(_MAX_RETRIES):\n        try:\n            with open(file_path, \"rb\") as f:\n                content = f.read()\n                break\n        except FileNotFoundError as e:\n            if i >= _MAX_RETRIES - 1:\n                raise e\n            time.sleep(_RETRY_WAIT_SECS)\n    return content\n\n\ndef _dirfiles(dir_path: str, glob_pattern: str) -> str:\n    p = Path(dir_path)\n    filenames = sorted(\n        [f.name for f in p.glob(glob_pattern) if not f.name.startswith(\".\")]\n    )\n    return \"+\".join(filenames)\n\n\ndef _stable_dir_identifier(dir_path: str, glob_pattern: str) -> str:\n    \"\"\"Wait for the files in a directory to look stable-ish before returning an id.\n\n    We do this to deal with problems that would otherwise arise from many tools\n    (e.g. git) and editors (e.g. vim) \"editing\" files (from the user's\n    perspective) by doing some combination of deleting, creating, and moving\n    various files under the hood.\n\n    Because of this, we're unable to rely on FileSystemEvents that we receive\n    from watchdog to determine when a file has been added to or removed from a\n    directory.\n\n    This is a bit of an unfortunate situation, but the approach we take here is\n    most likely fine as:\n      * The worst thing that can happen taking this approach is a false\n        positive page added/removed notification, which isn't too disastrous\n        and can just be ignored.\n      * It is impossible (that is, I'm fairly certain that the problem is\n        undecidable) to know whether a file created/deleted/moved event\n        corresponds to a legitimate file creation/deletion/move or is part of\n        some sequence of events that results in what the user sees as a file\n        \"edit\".\n    \"\"\"\n    dirfiles = _dirfiles(dir_path, glob_pattern)\n\n    for _ in range(_MAX_RETRIES):\n        time.sleep(_RETRY_WAIT_SECS)\n\n        new_dirfiles = _dirfiles(dir_path, glob_pattern)\n        if dirfiles == new_dirfiles:\n            break\n\n        dirfiles = new_dirfiles\n\n    return f\"{dir_path}+{dirfiles}\"\n", "lib/streamlit/watcher/path_watcher.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom typing import Callable, Type, Union\n\nimport streamlit.watcher\nfrom streamlit import cli_util, config, env_util\nfrom streamlit.watcher.polling_path_watcher import PollingPathWatcher\n\n\n# local_sources_watcher.py caches the return value of\n# get_default_path_watcher_class(), so it needs to differentiate between the\n# cases where it:\n#   1. has yet to call get_default_path_watcher_class()\n#   2. has called get_default_path_watcher_class(), which returned that no\n#      path watcher should be installed.\n# This forces us to define this stub class since the cached value equaling\n# None corresponds to case 1 above.\nclass NoOpPathWatcher:\n    def __init__(\n        self,\n        _path_str: str,\n        _on_changed: Callable[[str], None],\n        *,  # keyword-only arguments:\n        glob_pattern: str | None = None,\n        allow_nonexistent: bool = False,\n    ):\n        pass\n\n\n# EventBasedPathWatcher will be a stub and have no functional\n# implementation if its import failed (due to missing watchdog module),\n# so we can't reference it directly in this type.\nPathWatcherType = Union[\n    Type[\"streamlit.watcher.event_based_path_watcher.EventBasedPathWatcher\"],\n    Type[PollingPathWatcher],\n    Type[NoOpPathWatcher],\n]\n\n\ndef _is_watchdog_available() -> bool:\n    \"\"\"Check if the watchdog module is installed.\"\"\"\n    try:\n        import watchdog  # noqa: F401\n\n        return True\n    except ImportError:\n        return False\n\n\ndef report_watchdog_availability():\n    if (\n        not config.get_option(\"global.disableWatchdogWarning\")\n        and config.get_option(\"server.fileWatcherType\") not in [\"poll\", \"none\"]\n        and not _is_watchdog_available()\n    ):\n        msg = \"\\n  $ xcode-select --install\" if env_util.IS_DARWIN else \"\"\n\n        cli_util.print_to_cli(\n            \"  %s\" % \"For better performance, install the Watchdog module:\",\n            fg=\"blue\",\n            bold=True,\n        )\n        cli_util.print_to_cli(\n            \"\"\"%s\n  $ pip install watchdog\n            \"\"\"\n            % msg\n        )\n\n\ndef _watch_path(\n    path: str,\n    on_path_changed: Callable[[str], None],\n    watcher_type: str | None = None,\n    *,  # keyword-only arguments:\n    glob_pattern: str | None = None,\n    allow_nonexistent: bool = False,\n) -> bool:\n    \"\"\"Create a PathWatcher for the given path if we have a viable\n    PathWatcher class.\n\n    Parameters\n    ----------\n    path\n        Path to watch.\n    on_path_changed\n        Function that's called when the path changes.\n    watcher_type\n        Optional watcher_type string. If None, it will default to the\n        'server.fileWatcherType` config option.\n    glob_pattern\n        Optional glob pattern to use when watching a directory. If set, only\n        files matching the pattern will be counted as being created/deleted\n        within the watched directory.\n    allow_nonexistent\n        If True, allow the file or directory at the given path to be\n        nonexistent.\n\n    Returns\n    -------\n    bool\n        True if the path is being watched, or False if we have no\n        PathWatcher class.\n    \"\"\"\n    if watcher_type is None:\n        watcher_type = config.get_option(\"server.fileWatcherType\")\n\n    watcher_class = get_path_watcher_class(watcher_type)\n    if watcher_class is NoOpPathWatcher:\n        return False\n\n    watcher_class(\n        path,\n        on_path_changed,\n        glob_pattern=glob_pattern,\n        allow_nonexistent=allow_nonexistent,\n    )\n    return True\n\n\ndef watch_file(\n    path: str,\n    on_file_changed: Callable[[str], None],\n    watcher_type: str | None = None,\n) -> bool:\n    return _watch_path(path, on_file_changed, watcher_type)\n\n\ndef watch_dir(\n    path: str,\n    on_dir_changed: Callable[[str], None],\n    watcher_type: str | None = None,\n    *,  # keyword-only arguments:\n    glob_pattern: str | None = None,\n    allow_nonexistent: bool = False,\n) -> bool:\n    return _watch_path(\n        path,\n        on_dir_changed,\n        watcher_type,\n        glob_pattern=glob_pattern,\n        allow_nonexistent=allow_nonexistent,\n    )\n\n\ndef get_default_path_watcher_class() -> PathWatcherType:\n    \"\"\"Return the class to use for path changes notifications, based on the\n    server.fileWatcherType config option.\n    \"\"\"\n    return get_path_watcher_class(config.get_option(\"server.fileWatcherType\"))\n\n\ndef get_path_watcher_class(watcher_type: str) -> PathWatcherType:\n    \"\"\"Return the PathWatcher class that corresponds to the given watcher_type\n    string. Acceptable values are 'auto', 'watchdog', 'poll' and 'none'.\n    \"\"\"\n    if watcher_type in {\"watchdog\", \"auto\"} and _is_watchdog_available():\n        # Lazy-import this module to prevent unnecessary imports of the watchdog package.\n        from streamlit.watcher.event_based_path_watcher import EventBasedPathWatcher\n\n        return EventBasedPathWatcher\n    elif watcher_type == \"auto\":\n        return PollingPathWatcher\n    elif watcher_type == \"poll\":\n        return PollingPathWatcher\n    else:\n        return NoOpPathWatcher\n", "lib/streamlit/watcher/__init__.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\nfrom streamlit.watcher.local_sources_watcher import LocalSourcesWatcher\nfrom streamlit.watcher.path_watcher import (\n    report_watchdog_availability,\n    watch_dir,\n    watch_file,\n)\n\n__all__ = [\n    \"LocalSourcesWatcher\",\n    \"report_watchdog_availability\",\n    \"watch_dir\",\n    \"watch_file\",\n]\n", "lib/streamlit/watcher/event_based_path_watcher.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Declares the EventBasedPathWatcher class, which watches given paths in the file system.\n\nHow these classes work together\n-------------------------------\n\n- EventBasedPathWatcher : each instance of this is able to watch a single\n  file or directory at a given path so long as there's a browser interested in\n  it. This uses _MultiPathWatcher to watch paths.\n\n- _MultiPathWatcher : singleton that watches multiple paths. It does this by\n  holding a watchdog.observer.Observer object, and manages several\n  _FolderEventHandler instances. This creates _FolderEventHandlers as needed,\n  if the required folder is not already being watched. And it also tells\n  existing _FolderEventHandlers which paths it should be watching for.\n\n- _FolderEventHandler : event handler for when a folder is modified. You can\n  register paths in that folder that you're interested in. Then this object\n  listens to folder events, sees if registered paths changed, and fires\n  callbacks if so.\n\nThis module is lazy-loaded and used only if watchdog is installed.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport os\nimport threading\nfrom typing import TYPE_CHECKING, Callable, Final, cast\n\nfrom blinker import ANY, Signal\nfrom typing_extensions import Self\nfrom watchdog import events\nfrom watchdog.observers import Observer\n\nfrom streamlit.logger import get_logger\nfrom streamlit.util import repr_\nfrom streamlit.watcher import util\n\nif TYPE_CHECKING:\n    from watchdog.observers.api import ObservedWatch\n\n_LOGGER: Final = get_logger(__name__)\n\n\nclass EventBasedPathWatcher:\n    \"\"\"Watches a single path on disk using watchdog\"\"\"\n\n    @staticmethod\n    def close_all() -> None:\n        \"\"\"Close the _MultiPathWatcher singleton.\"\"\"\n        path_watcher = _MultiPathWatcher.get_singleton()\n        path_watcher.close()\n        _LOGGER.debug(\"Watcher closed\")\n\n    def __init__(\n        self,\n        path: str,\n        on_changed: Callable[[str], None],\n        *,  # keyword-only arguments:\n        glob_pattern: str | None = None,\n        allow_nonexistent: bool = False,\n    ) -> None:\n        \"\"\"Constructor for EventBasedPathWatchers.\n\n        Parameters\n        ----------\n        path : str\n            The path to watch.\n        on_changed : Callable[[str], None]\n            Callback to call when the path changes.\n        glob_pattern : str or None\n            A glob pattern to filter the files in a directory that should be\n            watched. Only relevant when creating an EventBasedPathWatcher on a\n            directory.\n        allow_nonexistent : bool\n            If True, the watcher will not raise an exception if the path does\n            not exist. This can be used to watch for the creation of a file or\n            directory at a given path.\n        \"\"\"\n        self._path = os.path.abspath(path)\n        self._on_changed = on_changed\n\n        path_watcher = _MultiPathWatcher.get_singleton()\n        path_watcher.watch_path(\n            self._path,\n            on_changed,\n            glob_pattern=glob_pattern,\n            allow_nonexistent=allow_nonexistent,\n        )\n        _LOGGER.debug(\"Watcher created for %s\", self._path)\n\n    def __repr__(self) -> str:\n        return repr_(self)\n\n    def close(self) -> None:\n        \"\"\"Stop watching the path corresponding to this EventBasedPathWatcher.\"\"\"\n        path_watcher = _MultiPathWatcher.get_singleton()\n        path_watcher.stop_watching_path(self._path, self._on_changed)\n\n\nclass _MultiPathWatcher:\n    \"\"\"Watches multiple paths.\"\"\"\n\n    _singleton: _MultiPathWatcher | None = None\n\n    @classmethod\n    def get_singleton(cls) -> _MultiPathWatcher:\n        \"\"\"Return the singleton _MultiPathWatcher object.\n\n        Instantiates one if necessary.\n        \"\"\"\n        if cls._singleton is None:\n            _LOGGER.debug(\"No singleton. Registering one.\")\n            _MultiPathWatcher()\n\n        return cast(\"_MultiPathWatcher\", _MultiPathWatcher._singleton)\n\n    # Don't allow constructor to be called more than once.\n    def __new__(cls) -> Self:\n        \"\"\"Constructor.\"\"\"\n        if _MultiPathWatcher._singleton is not None:\n            raise RuntimeError(\"Use .get_singleton() instead\")\n        return super().__new__(cls)\n\n    def __init__(self) -> None:\n        \"\"\"Constructor.\"\"\"\n        _MultiPathWatcher._singleton = self\n\n        # Map of folder_to_watch -> _FolderEventHandler.\n        self._folder_handlers: dict[str, _FolderEventHandler] = {}\n\n        # Used for mutation of _folder_handlers dict\n        self._lock = threading.Lock()\n\n        # The Observer object from the Watchdog module. Since this class is\n        # only instantiated once, we only have a single Observer in Streamlit,\n        # and it's in charge of watching all paths we're interested in.\n        self._observer = Observer()\n        self._observer.start()  # Start observer thread.\n\n    def __repr__(self) -> str:\n        return repr_(self)\n\n    def watch_path(\n        self,\n        path: str,\n        callback: Callable[[str], None],\n        *,  # keyword-only arguments:\n        glob_pattern: str | None = None,\n        allow_nonexistent: bool = False,\n    ) -> None:\n        \"\"\"Start watching a path.\"\"\"\n        folder_path = os.path.abspath(os.path.dirname(path))\n\n        with self._lock:\n            folder_handler = self._folder_handlers.get(folder_path)\n\n            if folder_handler is None:\n                folder_handler = _FolderEventHandler()\n                self._folder_handlers[folder_path] = folder_handler\n\n                folder_handler.watch = self._observer.schedule(\n                    folder_handler, folder_path, recursive=True\n                )\n\n            folder_handler.add_path_change_listener(\n                path,\n                callback,\n                glob_pattern=glob_pattern,\n                allow_nonexistent=allow_nonexistent,\n            )\n\n    def stop_watching_path(self, path: str, callback: Callable[[str], None]) -> None:\n        \"\"\"Stop watching a path.\"\"\"\n        folder_path = os.path.abspath(os.path.dirname(path))\n\n        with self._lock:\n            folder_handler = self._folder_handlers.get(folder_path)\n\n            if folder_handler is None:\n                _LOGGER.debug(\n                    \"Cannot stop watching path, because it is already not being \"\n                    \"watched. %s\",\n                    folder_path,\n                )\n                return\n\n            folder_handler.remove_path_change_listener(path, callback)\n\n            if not folder_handler.is_watching_paths():\n                self._observer.unschedule(folder_handler.watch)\n                del self._folder_handlers[folder_path]\n\n    def close(self) -> None:\n        with self._lock:\n            \"\"\"Close this _MultiPathWatcher object forever.\"\"\"\n            if len(self._folder_handlers) != 0:\n                self._folder_handlers = {}\n                _LOGGER.debug(\n                    \"Stopping observer thread even though there is a non-zero \"\n                    \"number of event observers!\"\n                )\n            else:\n                _LOGGER.debug(\"Stopping observer thread\")\n\n            self._observer.stop()\n            self._observer.join(timeout=5)\n\n\nclass WatchedPath:\n    \"\"\"Emits notifications when a single path is modified.\"\"\"\n\n    def __init__(\n        self,\n        md5: str,\n        modification_time: float,\n        *,  # keyword-only arguments:\n        glob_pattern: str | None = None,\n        allow_nonexistent: bool = False,\n    ):\n        self.md5 = md5\n        self.modification_time = modification_time\n\n        self.glob_pattern = glob_pattern\n        self.allow_nonexistent = allow_nonexistent\n\n        self.on_changed = Signal()\n\n    def __repr__(self) -> str:\n        return repr_(self)\n\n\nclass _FolderEventHandler(events.FileSystemEventHandler):\n    \"\"\"Listen to folder events. If certain paths change, fire a callback.\n\n    The super class, FileSystemEventHandler, listens to changes to *folders*,\n    but we need to listen to changes to *both* folders and files. I believe\n    this is a limitation of the Mac FSEvents system API, and the watchdog\n    library takes the lower common denominator.\n\n    So in this class we watch for folder events and then filter them based\n    on whether or not we care for the path the event is about.\n    \"\"\"\n\n    def __init__(self) -> None:\n        super().__init__()\n        self._watched_paths: dict[str, WatchedPath] = {}\n        self._lock = threading.Lock()  # for watched_paths mutations\n        self.watch: ObservedWatch | None = None\n\n    def __repr__(self) -> str:\n        return repr_(self)\n\n    def add_path_change_listener(\n        self,\n        path: str,\n        callback: Callable[[str], None],\n        *,  # keyword-only arguments:\n        glob_pattern: str | None = None,\n        allow_nonexistent: bool = False,\n    ) -> None:\n        \"\"\"Add a path to this object's event filter.\"\"\"\n        with self._lock:\n            watched_path = self._watched_paths.get(path, None)\n            if watched_path is None:\n                md5 = util.calc_md5_with_blocking_retries(\n                    path,\n                    glob_pattern=glob_pattern,\n                    allow_nonexistent=allow_nonexistent,\n                )\n                modification_time = util.path_modification_time(path, allow_nonexistent)\n                watched_path = WatchedPath(\n                    md5=md5,\n                    modification_time=modification_time,\n                    glob_pattern=glob_pattern,\n                    allow_nonexistent=allow_nonexistent,\n                )\n                self._watched_paths[path] = watched_path\n\n            watched_path.on_changed.connect(callback, weak=False)\n\n    def remove_path_change_listener(\n        self, path: str, callback: Callable[[str], None]\n    ) -> None:\n        \"\"\"Remove a path from this object's event filter.\"\"\"\n        with self._lock:\n            watched_path = self._watched_paths.get(path, None)\n            if watched_path is None:\n                return\n\n            watched_path.on_changed.disconnect(callback)\n            if not watched_path.on_changed.has_receivers_for(ANY):\n                del self._watched_paths[path]\n\n    def is_watching_paths(self) -> bool:\n        \"\"\"Return true if this object has 1+ paths in its event filter.\"\"\"\n        return len(self._watched_paths) > 0\n\n    def handle_path_change_event(self, event: events.FileSystemEvent) -> None:\n        \"\"\"Handle when a path (corresponding to a file or dir) is changed.\n\n        The events that can call this are modification, creation or moved\n        events.\n        \"\"\"\n\n        # Check for both modified and moved files, because many programs write\n        # to a backup file then rename (i.e. move) it.\n        if event.event_type == events.EVENT_TYPE_MODIFIED:\n            changed_path = event.src_path\n        elif event.event_type == events.EVENT_TYPE_MOVED:\n            # Teach mypy that this event has a dest_path, because it can't infer\n            # the desired subtype from the event_type check\n            event = cast(events.FileSystemMovedEvent, event)\n\n            _LOGGER.debug(\n                \"Move event: src %s; dest %s\", event.src_path, event.dest_path\n            )\n            changed_path = event.dest_path\n        # On OSX with VI, on save, the file is deleted, the swap file is\n        # modified and then the original file is created hence why we\n        # capture EVENT_TYPE_CREATED\n        elif event.event_type == events.EVENT_TYPE_CREATED:\n            changed_path = event.src_path\n        else:\n            _LOGGER.debug(\"Don't care about event type %s\", event.event_type)\n            return\n\n        changed_path = os.path.abspath(changed_path)\n\n        changed_path_info = self._watched_paths.get(changed_path, None)\n        if changed_path_info is None:\n            _LOGGER.debug(\n                \"Ignoring changed path %s.\\nWatched_paths: %s\",\n                changed_path,\n                self._watched_paths,\n            )\n            return\n\n        modification_time = util.path_modification_time(\n            changed_path, changed_path_info.allow_nonexistent\n        )\n\n        # We add modification_time != 0.0 check since on some file systems (s3fs/fuse)\n        # modification_time is always 0.0 because of file system limitations.\n        if (\n            modification_time != 0.0\n            and modification_time == changed_path_info.modification_time\n        ):\n            _LOGGER.debug(\"File/dir timestamp did not change: %s\", changed_path)\n            return\n\n        changed_path_info.modification_time = modification_time\n\n        new_md5 = util.calc_md5_with_blocking_retries(\n            changed_path,\n            glob_pattern=changed_path_info.glob_pattern,\n            allow_nonexistent=changed_path_info.allow_nonexistent,\n        )\n        if new_md5 == changed_path_info.md5:\n            _LOGGER.debug(\"File/dir MD5 did not change: %s\", changed_path)\n            return\n\n        _LOGGER.debug(\"File/dir MD5 changed: %s\", changed_path)\n        changed_path_info.md5 = new_md5\n        changed_path_info.on_changed.send(changed_path)\n\n    def on_created(self, event: events.FileSystemEvent) -> None:\n        self.handle_path_change_event(event)\n\n    def on_modified(self, event: events.FileSystemEvent) -> None:\n        self.handle_path_change_event(event)\n\n    def on_moved(self, event: events.FileSystemEvent) -> None:\n        self.handle_path_change_event(event)\n", "lib/streamlit/components/__init__.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n", "lib/streamlit/components/types/base_component_registry.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom abc import abstractmethod\nfrom typing import TYPE_CHECKING, Protocol\n\nif TYPE_CHECKING:\n    from streamlit.components.types.base_custom_component import BaseCustomComponent\n\n\nclass BaseComponentRegistry(Protocol):\n    \"\"\"Interface for ComponentRegistries.\"\"\"\n\n    @abstractmethod\n    def register_component(self, component: BaseCustomComponent) -> None:\n        \"\"\"Register a CustomComponent.\n\n        Parameters\n        ----------\n        component : CustomComponent\n            The component to register.\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_component_path(self, name: str) -> str | None:\n        \"\"\"Return the filesystem path for the component with the given name.\n\n        If no such component is registered, or if the component exists but is\n        being served from a URL, return None instead.\n\n        Parameters\n        ----------\n        name: name of the component\n\n        Returns\n        -------\n        str or None\n            The name of the specified component or None if no component with the given name has been registered.\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_module_name(self, name: str) -> str | None:\n        \"\"\"Return the module name for the component with the given name.\n\n        If no such component is registered, return None instead.\n\n        Parameters\n        ----------\n        name: name of the component\n\n        Returns\n        -------\n        str or None\n            The module_name of the specified component or None if no component with the given name has been registered.\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_component(self, name: str) -> BaseCustomComponent | None:\n        \"\"\"Return the registered component with the given name.\n\n        If no such component is registered, return None instead.\n\n        Parameters\n        ----------\n        name: name of the component\n\n        Returns\n        -------\n        component or None\n            The component with the provided name or None if component with the given name has been registered.\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_components(self) -> list[BaseCustomComponent]:\n        \"\"\"Returns a list of custom components that are registered in this registry.\n\n        Returns\n        -------\n        list[CustomComponents]\n            A list of registered custom components.\n        \"\"\"\n        raise NotImplementedError\n", "lib/streamlit/components/types/__init__.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n", "lib/streamlit/components/types/base_custom_component.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport os\nfrom abc import ABC, abstractmethod\nfrom typing import TYPE_CHECKING, Any\n\nfrom streamlit import util\nfrom streamlit.errors import StreamlitAPIException\n\nif TYPE_CHECKING:\n    from streamlit.runtime.state.common import WidgetCallback\n\n\nclass MarshallComponentException(StreamlitAPIException):\n    \"\"\"Class for exceptions generated during custom component marshalling.\"\"\"\n\n    pass\n\n\nclass BaseCustomComponent(ABC):\n    \"\"\"Interface for CustomComponents.\"\"\"\n\n    def __init__(\n        self,\n        name: str,\n        path: str | None = None,\n        url: str | None = None,\n        module_name: str | None = None,\n    ):\n        if (path is None and url is None) or (path is not None and url is not None):\n            raise StreamlitAPIException(\n                \"Either 'path' or 'url' must be set, but not both.\"\n            )\n\n        self._name = name\n        self._path = path\n        self._url = url\n        self._module_name = module_name\n\n    def __repr__(self) -> str:\n        return util.repr_(self)\n\n    def __call__(\n        self,\n        *args,\n        default: Any = None,\n        key: str | None = None,\n        on_change: WidgetCallback | None = None,\n        **kwargs,\n    ) -> Any:\n        \"\"\"An alias for create_instance.\"\"\"\n        return self.create_instance(\n            *args,\n            default=default,\n            key=key,\n            on_change=on_change,\n            **kwargs,\n        )\n\n    @property\n    def abspath(self) -> str | None:\n        if self._path is None:\n            return None\n        return os.path.abspath(self._path)\n\n    @property\n    def module_name(self) -> str | None:\n        return self._module_name\n\n    @property\n    def name(self) -> str:\n        return self._name\n\n    @property\n    def path(self) -> str | None:\n        return self._path\n\n    @property\n    def url(self) -> str | None:\n        return self._url\n\n    def __str__(self) -> str:\n        return f\"'{self.name}': {self.path if self.path is not None else self.url}\"\n\n    @abstractmethod\n    def __eq__(self, other) -> bool:\n        \"\"\"Equality operator.\"\"\"\n        return NotImplemented\n\n    @abstractmethod\n    def __ne__(self, other) -> bool:\n        \"\"\"Inequality operator.\"\"\"\n        return NotImplemented\n\n    @abstractmethod\n    def create_instance(\n        self,\n        *args,\n        default: Any = None,\n        key: str | None = None,\n        on_change: WidgetCallback | None = None,\n        **kwargs,\n    ) -> Any:\n        \"\"\"Create a new instance of the component.\n\n        Parameters\n        ----------\n        *args\n            Must be empty; all args must be named. (This parameter exists to\n            enforce correct use of the function.)\n        default: any or None\n            The default return value for the component. This is returned when\n            the component's frontend hasn't yet specified a value with\n            `setComponentValue`.\n        key: str or None\n            If not None, this is the user key we use to generate the\n            component's \"widget ID\".\n        on_change: WidgetCallback or None\n            An optional callback invoked when the widget's value changes. No arguments are passed to it.\n        **kwargs\n            Keyword args to pass to the component.\n\n        Raises\n        ------\n        MarshallComponentException\n            Raised when args is not empty or component cannot be marshalled.\n        StreamlitAPIException\n            Raised when PyArrow is not installed.\n\n        Returns\n        -------\n        any or None\n            The component's widget value.\n\n        \"\"\"\n        raise NotImplementedError\n", "lib/streamlit/components/v1/components.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# The components.py file exists because existing custom components have started\n# to rely on internals of the components package. For example, streamlit-option-menu accesses\n# [register_widget](https://github.com/victoryhb/streamlit-option-menu/blob/master/streamlit_option_menu/streamlit_callback.py#L28),\n# which is only a transitive import through `streamlit.components.v1.custom_component`.\n# Since we do not know what other internals are used out in the wild, let's try to\n# model the old behavior and not to break things.\n\nfrom streamlit.components.v1.component_registry import (\n    declare_component as declare_component,\n)\nfrom streamlit.components.v1.custom_component import *  # noqa: F403\n", "lib/streamlit/components/v1/component_registry.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport inspect\nimport os\nfrom typing import TYPE_CHECKING\n\nfrom streamlit.components.v1.custom_component import CustomComponent\nfrom streamlit.runtime import get_instance\nfrom streamlit.runtime.scriptrunner import get_script_run_ctx\n\nif TYPE_CHECKING:\n    from types import FrameType\n\n    from streamlit.components.types.base_component_registry import BaseComponentRegistry\n\n\ndef _get_module_name(caller_frame: FrameType) -> str:\n    # Get the caller's module name. `__name__` gives us the module's\n    # fully-qualified name, which includes its package.\n    module = inspect.getmodule(caller_frame)\n    assert module is not None\n    module_name = module.__name__\n\n    # If the caller was the main module that was executed (that is, if the\n    # user executed `python my_component.py`), then this name will be\n    # \"__main__\" instead of the actual package name. In this case, we use\n    # the main module's filename, sans `.py` extension, as the component name.\n    if module_name == \"__main__\":\n        file_path = inspect.getfile(caller_frame)\n        filename = os.path.basename(file_path)\n        module_name, _ = os.path.splitext(filename)\n\n    return module_name\n\n\ndef declare_component(\n    name: str,\n    path: str | None = None,\n    url: str | None = None,\n) -> CustomComponent:\n    \"\"\"Create a custom component and register it if there is a ``ScriptRunContext``.\n\n    The component is not registered when there is no ``ScriptRunContext``.\n    This can happen when a ``CustomComponent`` is executed as standalone\n    command (e.g. for testing).\n\n    To use this function, import it from the ``streamlit.components.v1``\n    module.\n\n    .. warning::\n        Using ``st.components.v1.declare_component`` directly (instead of\n        importing its module) is deprecated and will be disallowd in a later\n        version.\n\n    Parameters\n    ----------\n    name : str\n        A short, descriptive name for the component, like \"slider\".\n\n    path: str or None\n        The path to serve the component's frontend files from. If ``path`` is\n        ``None`` (default), Streamlit will server the component from the\n        location in ``url``. Either ``path`` or ``url`` must be specified, but\n        not both.\n\n    url: str or None\n        The URL that the component is served from. If ``url`` is ``None``\n        (default), Streamlit will server the component from the location in\n        ``path``. Either ``path`` or ``url`` must be specified, but not both.\n\n    Returns\n    -------\n    CustomComponent\n        A ``CustomComponent`` that can be called like a function.\n        Calling the component will create a new instance of the component\n        in the Streamlit app.\n\n    \"\"\"\n\n    # Get our stack frame.\n    current_frame: FrameType | None = inspect.currentframe()\n    assert current_frame is not None\n    # Get the stack frame of our calling function.\n    caller_frame = current_frame.f_back\n    assert caller_frame is not None\n    module_name = _get_module_name(caller_frame)\n\n    # Build the component name.\n    component_name = f\"{module_name}.{name}\"\n\n    # Create our component object, and register it.\n    component = CustomComponent(\n        name=component_name, path=path, url=url, module_name=module_name\n    )\n    # the ctx can be None if a custom component script is run outside of Streamlit, e.g. via 'python ...'\n    ctx = get_script_run_ctx()\n    if ctx is not None:\n        get_instance().component_registry.register_component(component)\n    return component\n\n\n# Keep for backwards-compatibility for now as we don't know whether existing custom\n# components use this method. We made significant refactors to the custom component\n# registry code in https://github.com/streamlit/streamlit/pull/8193 and after\n# that is out in the wild, we can follow-up with more refactorings, e.g. remove\n# the following class and method. When we do that, we should conduct some testing with\n# popular custom components.\nclass ComponentRegistry:\n    @classmethod\n    def instance(cls) -> BaseComponentRegistry:\n        \"\"\"Returns the ComponentRegistry of the runtime instance.\"\"\"\n\n        return get_instance().component_registry\n", "lib/streamlit/components/v1/component_arrow.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Data marshalling utilities for ArrowTable protobufs, which are used by\nCustomComponent for dataframe serialization.\n\"\"\"\n\nfrom __future__ import annotations\n\nfrom typing import TYPE_CHECKING, Any\n\nfrom streamlit import type_util\nfrom streamlit.elements.lib import pandas_styler_utils\n\nif TYPE_CHECKING:\n    from pandas import DataFrame, Index, Series\n\n    from streamlit.proto.Components_pb2 import ArrowTable as ArrowTableProto\n\n\ndef marshall(\n    proto: ArrowTableProto, data: Any, default_uuid: str | None = None\n) -> None:\n    \"\"\"Marshall data into an ArrowTable proto.\n\n    Parameters\n    ----------\n    proto : proto.ArrowTable\n        Output. The protobuf for a Streamlit ArrowTable proto.\n\n    data : pandas.DataFrame, pandas.Styler, numpy.ndarray, Iterable, dict, or None\n        Something that is or can be converted to a dataframe.\n\n    \"\"\"\n    if type_util.is_pandas_styler(data):\n        pandas_styler_utils.marshall_styler(proto, data, default_uuid)  # type: ignore\n\n    df = type_util.convert_anything_to_df(data)\n    _marshall_index(proto, df.index)\n    _marshall_columns(proto, df.columns)\n    _marshall_data(proto, df)\n\n\ndef _marshall_index(proto: ArrowTableProto, index: Index) -> None:\n    \"\"\"Marshall pandas.DataFrame index into an ArrowTable proto.\n\n    Parameters\n    ----------\n    proto : proto.ArrowTable\n        Output. The protobuf for a Streamlit ArrowTable proto.\n\n    index : pd.Index\n        Index to use for resulting frame.\n        Will default to RangeIndex (0, 1, 2, ..., n) if no index is provided.\n\n    \"\"\"\n    import pandas as pd\n\n    index = map(type_util.maybe_tuple_to_list, index.values)\n    index_df = pd.DataFrame(index)\n    proto.index = type_util.data_frame_to_bytes(index_df)\n\n\ndef _marshall_columns(proto: ArrowTableProto, columns: Series) -> None:\n    \"\"\"Marshall pandas.DataFrame columns into an ArrowTable proto.\n\n    Parameters\n    ----------\n    proto : proto.ArrowTable\n        Output. The protobuf for a Streamlit ArrowTable proto.\n\n    columns : Series\n        Column labels to use for resulting frame.\n        Will default to RangeIndex (0, 1, 2, ..., n) if no column labels are provided.\n\n    \"\"\"\n    import pandas as pd\n\n    columns = map(type_util.maybe_tuple_to_list, columns.values)\n    columns_df = pd.DataFrame(columns)\n    proto.columns = type_util.data_frame_to_bytes(columns_df)\n\n\ndef _marshall_data(proto: ArrowTableProto, df: DataFrame) -> None:\n    \"\"\"Marshall pandas.DataFrame data into an ArrowTable proto.\n\n    Parameters\n    ----------\n    proto : proto.ArrowTable\n        Output. The protobuf for a Streamlit ArrowTable proto.\n\n    df : pandas.DataFrame\n        A dataframe to marshall.\n\n    \"\"\"\n    proto.data = type_util.data_frame_to_bytes(df)\n\n\ndef arrow_proto_to_dataframe(proto: ArrowTableProto) -> DataFrame:\n    \"\"\"Convert ArrowTable proto to pandas.DataFrame.\n\n    Parameters\n    ----------\n    proto : proto.ArrowTable\n        Output. pandas.DataFrame\n\n    \"\"\"\n\n    if type_util.is_pyarrow_version_less_than(\"14.0.1\"):\n        raise RuntimeError(\n            \"The installed pyarrow version is not compatible with this component. \"\n            \"Please upgrade to 14.0.1 or higher: pip install -U pyarrow\"\n        )\n\n    import pandas as pd\n\n    data = type_util.bytes_to_data_frame(proto.data)\n    index = type_util.bytes_to_data_frame(proto.index)\n    columns = type_util.bytes_to_data_frame(proto.columns)\n\n    return pd.DataFrame(\n        data.values, index=index.values.T.tolist(), columns=columns.values.T.tolist()\n    )\n", "lib/streamlit/components/v1/__init__.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"\nThis directory contains the files and modules for the exposed API.\n\"\"\"\n\nimport streamlit\nfrom streamlit.components.v1.component_registry import declare_component\n\n# `html` and `iframe` are part of Custom Components, so they appear in this\n# `streamlit.components.v1` namespace.\nhtml = streamlit._main._html\niframe = streamlit._main._iframe\n\n__all__ = [\n    \"declare_component\",\n    \"html\",\n    \"iframe\",\n]\n", "lib/streamlit/components/v1/custom_component.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport json\nfrom typing import TYPE_CHECKING, Any\n\nfrom streamlit.components.types.base_custom_component import BaseCustomComponent\nfrom streamlit.delta_generator import main_dg\nfrom streamlit.elements.form import current_form_id\nfrom streamlit.elements.lib.policies import check_cache_replay_rules\nfrom streamlit.errors import StreamlitAPIException\nfrom streamlit.proto.Components_pb2 import ArrowTable as ArrowTableProto\nfrom streamlit.proto.Components_pb2 import SpecialArg\nfrom streamlit.proto.Element_pb2 import Element\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.runtime.scriptrunner import get_script_run_ctx\nfrom streamlit.runtime.state import NoValue, register_widget\nfrom streamlit.runtime.state.common import compute_widget_id\nfrom streamlit.type_util import is_bytes_like, is_dataframe_like, to_bytes\n\nif TYPE_CHECKING:\n    from streamlit.delta_generator import DeltaGenerator\n    from streamlit.runtime.state.common import WidgetCallback\n\n\nclass MarshallComponentException(StreamlitAPIException):\n    \"\"\"Class for exceptions generated during custom component marshalling.\"\"\"\n\n    pass\n\n\nclass CustomComponent(BaseCustomComponent):\n    \"\"\"A Custom Component declaration.\"\"\"\n\n    def __call__(\n        self,\n        *args,\n        default: Any = None,\n        key: str | None = None,\n        on_change: WidgetCallback | None = None,\n        **kwargs,\n    ) -> Any:\n        \"\"\"An alias for create_instance.\"\"\"\n        return self.create_instance(\n            *args,\n            default=default,\n            key=key,\n            on_change=on_change,\n            **kwargs,\n        )\n\n    @gather_metrics(\"create_instance\")\n    def create_instance(\n        self,\n        *args,\n        default: Any = None,\n        key: str | None = None,\n        on_change: WidgetCallback | None = None,\n        **kwargs,\n    ) -> Any:\n        \"\"\"Create a new instance of the component.\n\n        Parameters\n        ----------\n        *args\n            Must be empty; all args must be named. (This parameter exists to\n            enforce correct use of the function.)\n        default: any or None\n            The default return value for the component. This is returned when\n            the component's frontend hasn't yet specified a value with\n            `setComponentValue`.\n        key: str or None\n            If not None, this is the user key we use to generate the\n            component's \"widget ID\".\n        on_change: WidgetCallback or None\n            An optional callback invoked when the widget's value changes. No arguments are passed to it.\n        **kwargs\n            Keyword args to pass to the component.\n\n        Returns\n        -------\n        any or None\n            The component's widget value.\n\n        \"\"\"\n        if len(args) > 0:\n            raise MarshallComponentException(f\"Argument '{args[0]}' needs a label\")\n\n        try:\n            import pyarrow  # noqa: F401\n\n            from streamlit.components.v1 import component_arrow\n        except ImportError:\n            raise StreamlitAPIException(\n                \"\"\"To use Custom Components in Streamlit, you need to install\nPyArrow. To do so locally:\n\n`pip install pyarrow`\n\nAnd if you're using Streamlit Cloud, add \"pyarrow\" to your requirements.txt.\"\"\"\n            )\n\n        check_cache_replay_rules()\n        # In addition to the custom kwargs passed to the component, we also\n        # send the special 'default' and 'key' params to the component\n        # frontend.\n        all_args = dict(kwargs, **{\"default\": default, \"key\": key})\n\n        json_args = {}\n        special_args = []\n        for arg_name, arg_val in all_args.items():\n            if is_bytes_like(arg_val):\n                bytes_arg = SpecialArg()\n                bytes_arg.key = arg_name\n                bytes_arg.bytes = to_bytes(arg_val)\n                special_args.append(bytes_arg)\n            elif is_dataframe_like(arg_val):\n                dataframe_arg = SpecialArg()\n                dataframe_arg.key = arg_name\n                component_arrow.marshall(dataframe_arg.arrow_dataframe.data, arg_val)\n                special_args.append(dataframe_arg)\n            else:\n                json_args[arg_name] = arg_val\n\n        try:\n            serialized_json_args = json.dumps(json_args)\n        except Exception as ex:\n            raise MarshallComponentException(\n                \"Could not convert component args to JSON\", ex\n            )\n\n        def marshall_component(\n            dg: DeltaGenerator, element: Element\n        ) -> Any | type[NoValue]:\n            element.component_instance.component_name = self.name\n            element.component_instance.form_id = current_form_id(dg)\n            if self.url is not None:\n                element.component_instance.url = self.url\n\n            # Normally, a widget's element_hash (which determines\n            # its identity across multiple runs of an app) is computed\n            # by hashing its arguments. This means that, if any of the arguments\n            # to the widget are changed, Streamlit considers it a new widget\n            # instance and it loses its previous state.\n            #\n            # However! If a *component* has a `key` argument, then the\n            # component's hash identity is determined by entirely by\n            # `component_name + url + key`. This means that, when `key`\n            # exists, the component will maintain its identity even when its\n            # other arguments change, and the component's iframe won't be\n            # remounted on the frontend.\n\n            def marshall_element_args():\n                element.component_instance.json_args = serialized_json_args\n                element.component_instance.special_args.extend(special_args)\n\n            ctx = get_script_run_ctx()\n\n            if key is None:\n                marshall_element_args()\n                computed_id = compute_widget_id(\n                    \"component_instance\",\n                    user_key=key,\n                    name=self.name,\n                    form_id=current_form_id(dg),\n                    url=self.url,\n                    key=key,\n                    json_args=serialized_json_args,\n                    special_args=special_args,\n                    page=ctx.active_script_hash if ctx else None,\n                )\n            else:\n                computed_id = compute_widget_id(\n                    \"component_instance\",\n                    user_key=key,\n                    name=self.name,\n                    form_id=current_form_id(dg),\n                    url=self.url,\n                    key=key,\n                    page=ctx.active_script_hash if ctx else None,\n                )\n            element.component_instance.id = computed_id\n\n            def deserialize_component(ui_value, widget_id=\"\"):\n                # ui_value is an object from json, an ArrowTable proto, or a bytearray\n                return ui_value\n\n            component_state = register_widget(\n                element_type=\"component_instance\",\n                element_proto=element.component_instance,\n                user_key=key,\n                widget_func_name=self.name,\n                deserializer=deserialize_component,\n                serializer=lambda x: x,\n                ctx=ctx,\n                on_change_handler=on_change,\n            )\n            widget_value = component_state.value\n\n            if key is not None:\n                marshall_element_args()\n\n            if widget_value is None:\n                widget_value = default\n            elif isinstance(widget_value, ArrowTableProto):\n                widget_value = component_arrow.arrow_proto_to_dataframe(widget_value)\n            return widget_value\n\n        # We currently only support writing to st._main, but this will change\n        # when we settle on an improved API in a post-layout world.\n        dg = main_dg\n\n        element = Element()\n        return_value = marshall_component(dg, element)\n\n        dg._enqueue(\"component_instance\", element.component_instance)\n        return return_value\n\n    def __eq__(self, other) -> bool:\n        \"\"\"Equality operator.\"\"\"\n        return (\n            isinstance(other, CustomComponent)\n            and self.name == other.name\n            and self.path == other.path\n            and self.url == other.url\n            and self.module_name == other.module_name\n        )\n\n    def __ne__(self, other) -> bool:\n        \"\"\"Inequality operator.\"\"\"\n\n        # we have to use \"not X == Y\"\" here because if we use \"X != Y\" we call __ne__ again and end up in recursion\n        return not self == other\n\n    def __str__(self) -> str:\n        return f\"'{self.name}': {self.path if self.path is not None else self.url}\"\n", "lib/streamlit/components/lib/local_component_registry.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport os\nimport threading\nfrom typing import TYPE_CHECKING, Final\n\nfrom streamlit import util\nfrom streamlit.components.types.base_component_registry import BaseComponentRegistry\nfrom streamlit.errors import StreamlitAPIException\nfrom streamlit.logger import get_logger\n\nif TYPE_CHECKING:\n    from streamlit.components.types.base_custom_component import BaseCustomComponent\n\n_LOGGER: Final = get_logger(__name__)\n\n\nclass LocalComponentRegistry(BaseComponentRegistry):\n    def __init__(self) -> None:\n        self._components: dict[str, BaseCustomComponent] = {}\n        self._lock = threading.Lock()\n\n    def __repr__(self) -> str:\n        return util.repr_(self)\n\n    def register_component(self, component: BaseCustomComponent) -> None:\n        \"\"\"Register a CustomComponent.\n\n        Parameters\n        ----------\n        component : BaseCustomComponent\n            The component to register.\n        \"\"\"\n\n        # Validate the component's path\n        abspath = component.abspath\n        if abspath is not None and not os.path.isdir(abspath):\n            raise StreamlitAPIException(f\"No such component directory: '{abspath}'\")\n\n        with self._lock:\n            existing = self._components.get(component.name)\n            self._components[component.name] = component\n\n        if existing is not None and component != existing:\n            _LOGGER.warning(\n                \"%s overriding previously-registered %s\",\n                component,\n                existing,\n            )\n\n        _LOGGER.debug(\"Registered component %s\", component)\n\n    def get_component_path(self, name: str) -> str | None:\n        \"\"\"Return the filesystem path for the component with the given name.\n\n        If no such component is registered, or if the component exists but is\n        being served from a URL, return None instead.\n        \"\"\"\n        component = self._components.get(name, None)\n        return component.abspath if component is not None else None\n\n    def get_module_name(self, name: str) -> str | None:\n        component = self._components.get(name, None)\n        return component.module_name if component is not None else None\n\n    def get_component(self, name: str) -> BaseCustomComponent | None:\n        return self._components.get(name, None)\n\n    def get_components(self) -> list[BaseCustomComponent]:\n        return list(self._components.values())\n", "lib/streamlit/components/lib/__init__.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n", "lib/streamlit/proto/__init__.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# (This comment is here so the file exists in Git)\n", "lib/streamlit/runtime/media_file_storage.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom abc import abstractmethod\nfrom enum import Enum\nfrom typing import Protocol\n\n\nclass MediaFileKind(Enum):\n    # st.image, st.video, st.audio files\n    MEDIA = \"media\"\n\n    # st.download_button files\n    DOWNLOADABLE = \"downloadable\"\n\n\nclass MediaFileStorageError(Exception):\n    \"\"\"Exception class for errors raised by MediaFileStorage.\n\n    When running in \"development mode\", the full text of these errors\n    is displayed in the frontend, so errors should be human-readable\n    (and actionable).\n\n    When running in \"release mode\", errors are redacted on the\n    frontend; we instead show a generic \"Something went wrong!\" message.\n    \"\"\"\n\n\nclass MediaFileStorage(Protocol):\n    @abstractmethod\n    def load_and_get_id(\n        self,\n        path_or_data: str | bytes,\n        mimetype: str,\n        kind: MediaFileKind,\n        filename: str | None = None,\n    ) -> str:\n        \"\"\"Load the given file path or bytes into the manager and return\n        an ID that uniquely identifies it.\n\n        It's an error to pass a URL to this function. (Media stored at\n        external URLs can be served directly to the Streamlit frontend;\n        there's no need to store this data in MediaFileStorage.)\n\n        Parameters\n        ----------\n        path_or_data\n            A path to a file, or the file's raw data as bytes.\n\n        mimetype\n            The media's mimetype. Used to set the Content-Type header when\n            serving the media over HTTP.\n\n        kind\n            The kind of file this is: either MEDIA, or DOWNLOADABLE.\n\n        filename : str or None\n            Optional filename. Used to set the filename in the response header.\n\n        Returns\n        -------\n        str\n            The unique ID of the media file.\n\n        Raises\n        ------\n        MediaFileStorageError\n            Raised if the media can't be loaded (for example, if a file\n            path is invalid).\n\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_url(self, file_id: str) -> str:\n        \"\"\"Return a URL for a file in the manager.\n\n        Parameters\n        ----------\n        file_id\n            The file's ID, returned from load_media_and_get_id().\n\n        Returns\n        -------\n        str\n            A URL that the frontend can load the file from. Because this\n            URL may expire, it should not be cached!\n\n        Raises\n        ------\n        MediaFileStorageError\n            Raised if the manager doesn't contain an object with the given ID.\n\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def delete_file(self, file_id: str) -> None:\n        \"\"\"Delete a file from the manager.\n\n        This should be called when a given file is no longer referenced\n        by any connected client, so that the MediaFileStorage can free its\n        resources.\n\n        Calling `delete_file` on a file_id that doesn't exist is allowed,\n        and is a no-op. (This means that multiple `delete_file` calls with\n        the same file_id is not an error.)\n\n        Note: implementations can choose to ignore `delete_file` calls -\n        this function is a *suggestion*, not a *command*. Callers should\n        not rely on file deletion happening immediately (or at all).\n\n        Parameters\n        ----------\n        file_id\n            The file's ID, returned from load_media_and_get_id().\n\n        Returns\n        -------\n        None\n\n        Raises\n        ------\n        MediaFileStorageError\n            Raised if file deletion fails for any reason. Note that these\n            failures will generally not be shown on the frontend (file\n            deletion usually occurs on session disconnect).\n\n        \"\"\"\n        raise NotImplementedError\n", "lib/streamlit/runtime/memory_media_file_storage.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"MediaFileStorage implementation that stores files in memory.\"\"\"\n\nfrom __future__ import annotations\n\nimport contextlib\nimport hashlib\nimport mimetypes\nimport os.path\nfrom typing import Final, NamedTuple\n\nfrom streamlit.logger import get_logger\nfrom streamlit.runtime.media_file_storage import (\n    MediaFileKind,\n    MediaFileStorage,\n    MediaFileStorageError,\n)\nfrom streamlit.runtime.stats import CacheStat, CacheStatsProvider, group_stats\nfrom streamlit.util import HASHLIB_KWARGS\n\n_LOGGER: Final = get_logger(__name__)\n\n# Mimetype -> filename extension map for the `get_extension_for_mimetype`\n# function. We use Python's `mimetypes.guess_extension` for most mimetypes,\n# but (as of Python 3.9) `mimetypes.guess_extension(\"audio/wav\")` returns None,\n# so we handle it ourselves.\nPREFERRED_MIMETYPE_EXTENSION_MAP: Final = {\n    \"audio/wav\": \".wav\",\n    \"text/vtt\": \".vtt\",\n}\n\n\ndef _calculate_file_id(data: bytes, mimetype: str, filename: str | None = None) -> str:\n    \"\"\"Hash data, mimetype, and an optional filename to generate a stable file ID.\n\n    Parameters\n    ----------\n    data\n        Content of in-memory file in bytes. Other types will throw TypeError.\n    mimetype\n        Any string. Will be converted to bytes and used to compute a hash.\n    filename\n        Any string. Will be converted to bytes and used to compute a hash.\n    \"\"\"\n    filehash = hashlib.new(\"sha224\", **HASHLIB_KWARGS)\n    filehash.update(data)\n    filehash.update(bytes(mimetype.encode()))\n\n    if filename is not None:\n        filehash.update(bytes(filename.encode()))\n\n    return filehash.hexdigest()\n\n\ndef get_extension_for_mimetype(mimetype: str) -> str:\n    if mimetype in PREFERRED_MIMETYPE_EXTENSION_MAP:\n        return PREFERRED_MIMETYPE_EXTENSION_MAP[mimetype]\n\n    extension = mimetypes.guess_extension(mimetype, strict=False)\n    if extension is None:\n        return \"\"\n\n    return extension\n\n\nclass MemoryFile(NamedTuple):\n    \"\"\"A MediaFile stored in memory.\"\"\"\n\n    content: bytes\n    mimetype: str\n    kind: MediaFileKind\n    filename: str | None\n\n    @property\n    def content_size(self) -> int:\n        return len(self.content)\n\n\nclass MemoryMediaFileStorage(MediaFileStorage, CacheStatsProvider):\n    def __init__(self, media_endpoint: str):\n        \"\"\"Create a new MemoryMediaFileStorage instance\n\n        Parameters\n        ----------\n        media_endpoint\n            The name of the local endpoint that media is served from.\n            This endpoint should start with a forward-slash (e.g. \"/media\").\n        \"\"\"\n        self._files_by_id: dict[str, MemoryFile] = {}\n        self._media_endpoint = media_endpoint\n\n    def load_and_get_id(\n        self,\n        path_or_data: str | bytes,\n        mimetype: str,\n        kind: MediaFileKind,\n        filename: str | None = None,\n    ) -> str:\n        \"\"\"Add a file to the manager and return its ID.\"\"\"\n        file_data: bytes\n        if isinstance(path_or_data, str):\n            file_data = self._read_file(path_or_data)\n        else:\n            file_data = path_or_data\n\n        # Because our file_ids are stable, if we already have a file with the\n        # given ID, we don't need to create a new one.\n        file_id = _calculate_file_id(file_data, mimetype, filename)\n        if file_id not in self._files_by_id:\n            _LOGGER.debug(\"Adding media file %s\", file_id)\n            media_file = MemoryFile(\n                content=file_data, mimetype=mimetype, kind=kind, filename=filename\n            )\n            self._files_by_id[file_id] = media_file\n\n        return file_id\n\n    def get_file(self, filename: str) -> MemoryFile:\n        \"\"\"Return the MemoryFile with the given filename. Filenames are of the\n        form \"file_id.extension\". (Note that this is *not* the optional\n        user-specified filename for download files.)\n\n        Raises a MediaFileStorageError if no such file exists.\n        \"\"\"\n        file_id = os.path.splitext(filename)[0]\n        try:\n            return self._files_by_id[file_id]\n        except KeyError as e:\n            raise MediaFileStorageError(\n                f\"Bad filename '{filename}'. (No media file with id '{file_id}')\"\n            ) from e\n\n    def get_url(self, file_id: str) -> str:\n        \"\"\"Get a URL for a given media file. Raise a MediaFileStorageError if\n        no such file exists.\n        \"\"\"\n        media_file = self.get_file(file_id)\n        extension = get_extension_for_mimetype(media_file.mimetype)\n        return f\"{self._media_endpoint}/{file_id}{extension}\"\n\n    def delete_file(self, file_id: str) -> None:\n        \"\"\"Delete the file with the given ID.\"\"\"\n        # We swallow KeyErrors here - it's not an error to delete a file\n        # that doesn't exist.\n        with contextlib.suppress(KeyError):\n            del self._files_by_id[file_id]\n\n    def _read_file(self, filename: str) -> bytes:\n        \"\"\"Read a file into memory. Raise MediaFileStorageError if we can't.\"\"\"\n        try:\n            with open(filename, \"rb\") as f:\n                return f.read()\n        except Exception as ex:\n            raise MediaFileStorageError(f\"Error opening '{filename}'\") from ex\n\n    def get_stats(self) -> list[CacheStat]:\n        # We operate on a copy of our dict, to avoid race conditions\n        # with other threads that may be manipulating the cache.\n        files_by_id = self._files_by_id.copy()\n\n        stats: list[CacheStat] = [\n            CacheStat(\n                category_name=\"st_memory_media_file_storage\",\n                cache_name=\"\",\n                byte_length=len(file.content),\n            )\n            for _, file in files_by_id.items()\n        ]\n        return group_stats(stats)\n", "lib/streamlit/runtime/runtime.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport asyncio\nimport time\nimport traceback\nfrom dataclasses import dataclass, field\nfrom enum import Enum\nfrom typing import TYPE_CHECKING, Awaitable, Final, NamedTuple\n\nfrom streamlit import config\nfrom streamlit.components.lib.local_component_registry import LocalComponentRegistry\nfrom streamlit.logger import get_logger\nfrom streamlit.proto.ForwardMsg_pb2 import ForwardMsg\nfrom streamlit.runtime.app_session import AppSession\nfrom streamlit.runtime.caching import (\n    get_data_cache_stats_provider,\n    get_resource_cache_stats_provider,\n)\nfrom streamlit.runtime.caching.storage.local_disk_cache_storage import (\n    LocalDiskCacheStorageManager,\n)\nfrom streamlit.runtime.forward_msg_cache import (\n    ForwardMsgCache,\n    create_reference_msg,\n    populate_hash_if_needed,\n)\nfrom streamlit.runtime.media_file_manager import MediaFileManager\nfrom streamlit.runtime.memory_session_storage import MemorySessionStorage\nfrom streamlit.runtime.runtime_util import is_cacheable_msg\nfrom streamlit.runtime.script_data import ScriptData\nfrom streamlit.runtime.scriptrunner.script_cache import ScriptCache\nfrom streamlit.runtime.session_manager import (\n    ActiveSessionInfo,\n    SessionClient,\n    SessionClientDisconnectedError,\n    SessionManager,\n    SessionStorage,\n)\nfrom streamlit.runtime.state import (\n    SCRIPT_RUN_WITHOUT_ERRORS_KEY,\n    SessionStateStatProvider,\n)\nfrom streamlit.runtime.stats import StatsManager\nfrom streamlit.runtime.websocket_session_manager import WebsocketSessionManager\n\nif TYPE_CHECKING:\n    from streamlit.components.types.base_component_registry import BaseComponentRegistry\n    from streamlit.proto.BackMsg_pb2 import BackMsg\n    from streamlit.runtime.caching.storage import CacheStorageManager\n    from streamlit.runtime.media_file_storage import MediaFileStorage\n    from streamlit.runtime.uploaded_file_manager import UploadedFileManager\n\n# Wait for the script run result for 60s and if no result is available give up\nSCRIPT_RUN_CHECK_TIMEOUT: Final = 60\n\n_LOGGER: Final = get_logger(__name__)\n\n\nclass RuntimeStoppedError(Exception):\n    \"\"\"Raised by operations on a Runtime instance that is stopped.\"\"\"\n\n\n@dataclass(frozen=True)\nclass RuntimeConfig:\n    \"\"\"Config options for StreamlitRuntime.\"\"\"\n\n    # The filesystem path of the Streamlit script to run.\n    script_path: str\n\n    # DEPRECATED: We need to keep this field around for compatibility reasons, but we no\n    # longer use this anywhere.\n    command_line: str | None\n\n    # The storage backend for Streamlit's MediaFileManager.\n    media_file_storage: MediaFileStorage\n\n    # The upload file manager\n    uploaded_file_manager: UploadedFileManager\n\n    # The cache storage backend for Streamlit's st.cache_data.\n    cache_storage_manager: CacheStorageManager = field(\n        default_factory=LocalDiskCacheStorageManager\n    )\n\n    # The ComponentRegistry instance to use.\n    component_registry: BaseComponentRegistry = field(\n        default_factory=LocalComponentRegistry\n    )\n\n    # The SessionManager class to be used.\n    session_manager_class: type[SessionManager] = WebsocketSessionManager\n\n    # The SessionStorage instance for the SessionManager to use.\n    session_storage: SessionStorage = field(default_factory=MemorySessionStorage)\n\n    # True if the command used to start Streamlit was `streamlit hello`.\n    is_hello: bool = False\n\n    # TODO(vdonato): Eventually add a new fragment_storage_class field enabling the code\n    # creating a new Streamlit Runtime to configure the FragmentStorage instances\n    # created by each new AppSession. We choose not to do this for now to avoid adding\n    # additional complexity to RuntimeConfig/SessionManager/etc when it's unlikely\n    # we'll have a custom implementation of this class anytime soon.\n\n\nclass RuntimeState(Enum):\n    INITIAL = \"INITIAL\"\n    NO_SESSIONS_CONNECTED = \"NO_SESSIONS_CONNECTED\"\n    ONE_OR_MORE_SESSIONS_CONNECTED = \"ONE_OR_MORE_SESSIONS_CONNECTED\"\n    STOPPING = \"STOPPING\"\n    STOPPED = \"STOPPED\"\n\n\nclass AsyncObjects(NamedTuple):\n    \"\"\"Container for all asyncio objects that Runtime manages.\n    These cannot be initialized until the Runtime's eventloop is assigned.\n    \"\"\"\n\n    # The eventloop that Runtime is running on.\n    eventloop: asyncio.AbstractEventLoop\n\n    # Set after Runtime.stop() is called. Never cleared.\n    must_stop: asyncio.Event\n\n    # Set when a client connects; cleared when we have no connected clients.\n    has_connection: asyncio.Event\n\n    # Set after a ForwardMsg is enqueued; cleared when we flush ForwardMsgs.\n    need_send_data: asyncio.Event\n\n    # Completed when the Runtime has started.\n    started: asyncio.Future[None]\n\n    # Completed when the Runtime has stopped.\n    stopped: asyncio.Future[None]\n\n\nclass Runtime:\n    _instance: Runtime | None = None\n\n    @classmethod\n    def instance(cls) -> Runtime:\n        \"\"\"Return the singleton Runtime instance. Raise an Error if the\n        Runtime hasn't been created yet.\n        \"\"\"\n        if cls._instance is None:\n            raise RuntimeError(\"Runtime hasn't been created!\")\n        return cls._instance\n\n    @classmethod\n    def exists(cls) -> bool:\n        \"\"\"True if the singleton Runtime instance has been created.\n\n        When a Streamlit app is running in \"raw mode\" - that is, when the\n        app is run via `python app.py` instead of `streamlit run app.py` -\n        the Runtime will not exist, and various Streamlit functions need\n        to adapt.\n        \"\"\"\n        return cls._instance is not None\n\n    def __init__(self, config: RuntimeConfig):\n        \"\"\"Create a Runtime instance. It won't be started yet.\n\n        Runtime is *not* thread-safe. Its public methods are generally\n        safe to call only on the same thread that its event loop runs on.\n\n        Parameters\n        ----------\n        config\n            Config options.\n        \"\"\"\n        if Runtime._instance is not None:\n            raise RuntimeError(\"Runtime instance already exists!\")\n        Runtime._instance = self\n\n        # Will be created when we start.\n        self._async_objs: AsyncObjects | None = None\n\n        # The task that runs our main loop. We need to save a reference\n        # to it so that it doesn't get garbage collected while running.\n        self._loop_coroutine_task: asyncio.Task[None] | None = None\n\n        self._main_script_path = config.script_path\n        self._is_hello = config.is_hello\n\n        self._state = RuntimeState.INITIAL\n\n        # Initialize managers\n        self._component_registry = config.component_registry\n        self._message_cache = ForwardMsgCache()\n        self._uploaded_file_mgr = config.uploaded_file_manager\n        self._media_file_mgr = MediaFileManager(storage=config.media_file_storage)\n        self._cache_storage_manager = config.cache_storage_manager\n        self._script_cache = ScriptCache()\n\n        self._session_mgr = config.session_manager_class(\n            session_storage=config.session_storage,\n            uploaded_file_manager=self._uploaded_file_mgr,\n            script_cache=self._script_cache,\n            message_enqueued_callback=self._enqueued_some_message,\n        )\n\n        self._stats_mgr = StatsManager()\n        self._stats_mgr.register_provider(get_data_cache_stats_provider())\n        self._stats_mgr.register_provider(get_resource_cache_stats_provider())\n        self._stats_mgr.register_provider(self._message_cache)\n        self._stats_mgr.register_provider(self._uploaded_file_mgr)\n        self._stats_mgr.register_provider(SessionStateStatProvider(self._session_mgr))\n\n    @property\n    def state(self) -> RuntimeState:\n        return self._state\n\n    @property\n    def component_registry(self) -> BaseComponentRegistry:\n        return self._component_registry\n\n    @property\n    def message_cache(self) -> ForwardMsgCache:\n        return self._message_cache\n\n    @property\n    def uploaded_file_mgr(self) -> UploadedFileManager:\n        return self._uploaded_file_mgr\n\n    @property\n    def cache_storage_manager(self) -> CacheStorageManager:\n        return self._cache_storage_manager\n\n    @property\n    def media_file_mgr(self) -> MediaFileManager:\n        return self._media_file_mgr\n\n    @property\n    def stats_mgr(self) -> StatsManager:\n        return self._stats_mgr\n\n    @property\n    def stopped(self) -> Awaitable[None]:\n        \"\"\"A Future that completes when the Runtime's run loop has exited.\"\"\"\n        return self._get_async_objs().stopped\n\n    # NOTE: A few Runtime methods listed as threadsafe (get_client and\n    # is_active_session) currently rely on the implementation detail that\n    # WebsocketSessionManager's get_active_session_info and is_active_session methods\n    # happen to be threadsafe. This may change with future SessionManager implementations,\n    # at which point we'll need to formalize our thread safety rules for each\n    # SessionManager method.\n    def get_client(self, session_id: str) -> SessionClient | None:\n        \"\"\"Get the SessionClient for the given session_id, or None\n        if no such session exists.\n\n        Notes\n        -----\n        Threading: SAFE. May be called on any thread.\n        \"\"\"\n        session_info = self._session_mgr.get_active_session_info(session_id)\n        if session_info is None:\n            return None\n        return session_info.client\n\n    async def start(self) -> None:\n        \"\"\"Start the runtime. This must be called only once, before\n        any other functions are called.\n\n        When this coroutine returns, Streamlit is ready to accept new sessions.\n\n        Notes\n        -----\n        Threading: UNSAFE. Must be called on the eventloop thread.\n        \"\"\"\n\n        # Create our AsyncObjects. We need to have a running eventloop to\n        # instantiate our various synchronization primitives.\n        async_objs = AsyncObjects(\n            eventloop=asyncio.get_running_loop(),\n            must_stop=asyncio.Event(),\n            has_connection=asyncio.Event(),\n            need_send_data=asyncio.Event(),\n            started=asyncio.Future(),\n            stopped=asyncio.Future(),\n        )\n        self._async_objs = async_objs\n\n        self._loop_coroutine_task = asyncio.create_task(\n            self._loop_coroutine(), name=\"Runtime.loop_coroutine\"\n        )\n\n        await async_objs.started\n\n    def stop(self) -> None:\n        \"\"\"Request that Streamlit close all sessions and stop running.\n        Note that Streamlit won't stop running immediately.\n\n        Notes\n        -----\n        Threading: SAFE. May be called from any thread.\n        \"\"\"\n\n        async_objs = self._get_async_objs()\n\n        def stop_on_eventloop():\n            if self._state in (RuntimeState.STOPPING, RuntimeState.STOPPED):\n                return\n\n            _LOGGER.debug(\"Runtime stopping...\")\n            self._set_state(RuntimeState.STOPPING)\n            async_objs.must_stop.set()\n\n        async_objs.eventloop.call_soon_threadsafe(stop_on_eventloop)\n\n    def is_active_session(self, session_id: str) -> bool:\n        \"\"\"True if the session_id belongs to an active session.\n\n        Notes\n        -----\n        Threading: SAFE. May be called on any thread.\n        \"\"\"\n        return self._session_mgr.is_active_session(session_id)\n\n    def connect_session(\n        self,\n        client: SessionClient,\n        user_info: dict[str, str | None],\n        existing_session_id: str | None = None,\n        session_id_override: str | None = None,\n    ) -> str:\n        \"\"\"Create a new session (or connect to an existing one) and return its unique ID.\n\n        Parameters\n        ----------\n        client\n            A concrete SessionClient implementation for communicating with\n            the session's client.\n        user_info\n            A dict that contains information about the session's user. For now,\n            it only (optionally) contains the user's email address.\n\n            {\n                \"email\": \"example@example.com\"\n            }\n        existing_session_id\n            The ID of an existing session to reconnect to. If one is not provided, a new\n            session is created. Note that whether the Runtime's SessionManager supports\n            reconnecting to an existing session depends on the SessionManager that this\n            runtime is configured with.\n        session_id_override\n            The ID to assign to a new session being created with this method. Setting\n            this can be useful when the service that a Streamlit Runtime is running in\n            wants to tie the lifecycle of a Streamlit session to some other session-like\n            object that it manages. Only one of existing_session_id and\n            session_id_override should be set.\n\n        Returns\n        -------\n        str\n            The session's unique string ID.\n\n        Notes\n        -----\n        Threading: UNSAFE. Must be called on the eventloop thread.\n        \"\"\"\n        assert not (\n            existing_session_id and session_id_override\n        ), \"Only one of existing_session_id and session_id_override should be set!\"\n\n        if self._state in (RuntimeState.STOPPING, RuntimeState.STOPPED):\n            raise RuntimeStoppedError(f\"Can't connect_session (state={self._state})\")\n\n        session_id = self._session_mgr.connect_session(\n            client=client,\n            script_data=ScriptData(self._main_script_path, self._is_hello),\n            user_info=user_info,\n            existing_session_id=existing_session_id,\n            session_id_override=session_id_override,\n        )\n        self._set_state(RuntimeState.ONE_OR_MORE_SESSIONS_CONNECTED)\n        self._get_async_objs().has_connection.set()\n\n        return session_id\n\n    def create_session(\n        self,\n        client: SessionClient,\n        user_info: dict[str, str | None],\n        existing_session_id: str | None = None,\n        session_id_override: str | None = None,\n    ) -> str:\n        \"\"\"Create a new session (or connect to an existing one) and return its unique ID.\n\n        Notes\n        -----\n        This method is simply an alias for connect_session added for backwards\n        compatibility.\n        \"\"\"\n        _LOGGER.warning(\"create_session is deprecated! Use connect_session instead.\")\n        return self.connect_session(\n            client=client,\n            user_info=user_info,\n            existing_session_id=existing_session_id,\n            session_id_override=session_id_override,\n        )\n\n    def close_session(self, session_id: str) -> None:\n        \"\"\"Close and completely shut down a session.\n\n        This differs from disconnect_session in that it always completely shuts down a\n        session, permanently losing any associated state (session state, uploaded files,\n        etc.).\n\n        This function may be called multiple times for the same session,\n        which is not an error. (Subsequent calls just no-op.)\n\n        Parameters\n        ----------\n        session_id\n            The session's unique ID.\n\n        Notes\n        -----\n        Threading: UNSAFE. Must be called on the eventloop thread.\n        \"\"\"\n        session_info = self._session_mgr.get_session_info(session_id)\n        if session_info:\n            self._message_cache.remove_refs_for_session(session_info.session)\n            self._session_mgr.close_session(session_id)\n        self._on_session_disconnected()\n\n    def disconnect_session(self, session_id: str) -> None:\n        \"\"\"Disconnect a session. It will stop producing ForwardMsgs.\n\n        Differs from close_session because disconnected sessions can be reconnected to\n        for a brief window (depending on the SessionManager/SessionStorage\n        implementations used by the runtime).\n\n        This function may be called multiple times for the same session,\n        which is not an error. (Subsequent calls just no-op.)\n\n        Parameters\n        ----------\n        session_id\n            The session's unique ID.\n\n        Notes\n        -----\n        Threading: UNSAFE. Must be called on the eventloop thread.\n        \"\"\"\n        session_info = self._session_mgr.get_active_session_info(session_id)\n        if session_info:\n            # NOTE: Ideally, we'd like to keep ForwardMsgCache refs for a session around\n            # when a session is disconnected (and defer their cleanup until the session\n            # is garbage collected), but this would be difficult to do as the\n            # ForwardMsgCache is not thread safe, and we have no guarantee that the\n            # garbage collector will only run on the eventloop thread. Because of this,\n            # we clean up refs now and accept the risk that we're deleting cache entries\n            # that will be useful once the browser tab reconnects.\n            self._message_cache.remove_refs_for_session(session_info.session)\n            self._session_mgr.disconnect_session(session_id)\n        self._on_session_disconnected()\n\n    def handle_backmsg(self, session_id: str, msg: BackMsg) -> None:\n        \"\"\"Send a BackMsg to an active session.\n\n        Parameters\n        ----------\n        session_id\n            The session's unique ID.\n        msg\n            The BackMsg to deliver to the session.\n\n        Notes\n        -----\n        Threading: UNSAFE. Must be called on the eventloop thread.\n        \"\"\"\n        if self._state in (RuntimeState.STOPPING, RuntimeState.STOPPED):\n            raise RuntimeStoppedError(f\"Can't handle_backmsg (state={self._state})\")\n\n        session_info = self._session_mgr.get_active_session_info(session_id)\n        if session_info is None:\n            _LOGGER.debug(\n                \"Discarding BackMsg for disconnected session (id=%s)\", session_id\n            )\n            return\n\n        session_info.session.handle_backmsg(msg)\n\n    def handle_backmsg_deserialization_exception(\n        self, session_id: str, exc: BaseException\n    ) -> None:\n        \"\"\"Handle an Exception raised during deserialization of a BackMsg.\n\n        Parameters\n        ----------\n        session_id\n            The session's unique ID.\n        exc\n            The Exception.\n\n        Notes\n        -----\n        Threading: UNSAFE. Must be called on the eventloop thread.\n        \"\"\"\n        if self._state in (RuntimeState.STOPPING, RuntimeState.STOPPED):\n            raise RuntimeStoppedError(\n                f\"Can't handle_backmsg_deserialization_exception (state={self._state})\"\n            )\n\n        session_info = self._session_mgr.get_active_session_info(session_id)\n        if session_info is None:\n            _LOGGER.debug(\n                \"Discarding BackMsg Exception for disconnected session (id=%s)\",\n                session_id,\n            )\n            return\n\n        session_info.session.handle_backmsg_exception(exc)\n\n    @property\n    async def is_ready_for_browser_connection(self) -> tuple[bool, str]:\n        if self._state not in (\n            RuntimeState.INITIAL,\n            RuntimeState.STOPPING,\n            RuntimeState.STOPPED,\n        ):\n            return True, \"ok\"\n\n        return False, \"unavailable\"\n\n    async def does_script_run_without_error(self) -> tuple[bool, str]:\n        \"\"\"Load and execute the app's script to verify it runs without an error.\n\n        Returns\n        -------\n        (True, \"ok\") if the script completes without error, or (False, err_msg)\n        if the script raises an exception.\n\n        Notes\n        -----\n        Threading: UNSAFE. Must be called on the eventloop thread.\n        \"\"\"\n        # NOTE: We create an AppSession directly here instead of using the\n        # SessionManager intentionally. This isn't a \"real\" session and is only being\n        # used to test that the script runs without error.\n        session = AppSession(\n            script_data=ScriptData(self._main_script_path, self._is_hello),\n            uploaded_file_manager=self._uploaded_file_mgr,\n            script_cache=self._script_cache,\n            message_enqueued_callback=self._enqueued_some_message,\n            user_info={\"email\": \"test@test.com\"},\n        )\n\n        try:\n            session.request_rerun(None)\n\n            now = time.perf_counter()\n            while (\n                SCRIPT_RUN_WITHOUT_ERRORS_KEY not in session.session_state\n                and (time.perf_counter() - now) < SCRIPT_RUN_CHECK_TIMEOUT\n            ):\n                await asyncio.sleep(0.1)\n\n            if SCRIPT_RUN_WITHOUT_ERRORS_KEY not in session.session_state:\n                return False, \"timeout\"\n\n            ok = session.session_state[SCRIPT_RUN_WITHOUT_ERRORS_KEY]\n            msg = \"ok\" if ok else \"error\"\n\n            return ok, msg\n        finally:\n            session.shutdown()\n\n    def _set_state(self, new_state: RuntimeState) -> None:\n        _LOGGER.debug(\"Runtime state: %s -> %s\", self._state, new_state)\n        self._state = new_state\n\n    async def _loop_coroutine(self) -> None:\n        \"\"\"The main Runtime loop.\n\n        This function won't exit until `stop` is called.\n\n        Notes\n        -----\n        Threading: UNSAFE. Must be called on the eventloop thread.\n        \"\"\"\n\n        async_objs = self._get_async_objs()\n\n        try:\n            if self._state == RuntimeState.INITIAL:\n                self._set_state(RuntimeState.NO_SESSIONS_CONNECTED)\n            elif self._state == RuntimeState.ONE_OR_MORE_SESSIONS_CONNECTED:\n                pass\n            else:\n                raise RuntimeError(f\"Bad Runtime state at start: {self._state}\")\n\n            # Signal that we're started and ready to accept sessions\n            async_objs.started.set_result(None)\n\n            while not async_objs.must_stop.is_set():\n                if self._state == RuntimeState.NO_SESSIONS_CONNECTED:  # type: ignore[comparison-overlap]\n                    # mypy 1.4 incorrectly thinks this if-clause is unreachable,\n                    # because it thinks self._state must be INITIAL | ONE_OR_MORE_SESSIONS_CONNECTED.\n\n                    # Wait for new websocket connections (new sessions):\n                    _, pending_tasks = await asyncio.wait(  # type: ignore[unreachable]\n                        (\n                            asyncio.create_task(async_objs.must_stop.wait()),\n                            asyncio.create_task(async_objs.has_connection.wait()),\n                        ),\n                        return_when=asyncio.FIRST_COMPLETED,\n                    )\n                    # Clean up pending tasks to avoid memory leaks\n                    for task in pending_tasks:\n                        task.cancel()\n                elif self._state == RuntimeState.ONE_OR_MORE_SESSIONS_CONNECTED:\n                    async_objs.need_send_data.clear()\n\n                    for active_session_info in self._session_mgr.list_active_sessions():\n                        msg_list = active_session_info.session.flush_browser_queue()\n                        for msg in msg_list:\n                            try:\n                                self._send_message(active_session_info, msg)\n                            except SessionClientDisconnectedError:\n                                self._session_mgr.disconnect_session(\n                                    active_session_info.session.id\n                                )\n\n                            # Yield for a tick after sending a message.\n                            await asyncio.sleep(0)\n\n                    # Yield for a few milliseconds between session message\n                    # flushing.\n                    await asyncio.sleep(0.01)\n                else:\n                    # Break out of the thread loop if we encounter any other state.\n                    break\n\n                # Wait for new proto messages that need to be sent out:\n                _, pending_tasks = await asyncio.wait(\n                    (\n                        asyncio.create_task(async_objs.must_stop.wait()),\n                        asyncio.create_task(async_objs.need_send_data.wait()),\n                    ),\n                    return_when=asyncio.FIRST_COMPLETED,\n                )\n                # We need to cancel the pending tasks (the `must_stop` one in most situations).\n                # Otherwise, this would stack up one waiting task per loop\n                # (e.g. per forward message). These tasks cannot be garbage collected\n                # causing an increase in memory (-> memory leak).\n                for task in pending_tasks:\n                    task.cancel()\n\n            # Shut down all AppSessions.\n            for session_info in self._session_mgr.list_sessions():\n                # NOTE: We want to fully shut down sessions when the runtime stops for\n                # now, but this may change in the future if/when our notion of a session\n                # is no longer so tightly coupled to a browser tab.\n                self._session_mgr.close_session(session_info.session.id)\n\n            self._set_state(RuntimeState.STOPPED)\n            async_objs.stopped.set_result(None)\n\n        except Exception as e:\n            async_objs.stopped.set_exception(e)\n            traceback.print_exc()\n            _LOGGER.info(\n                \"\"\"\nPlease report this bug at https://github.com/streamlit/streamlit/issues.\n\"\"\"\n            )\n\n    def _send_message(self, session_info: ActiveSessionInfo, msg: ForwardMsg) -> None:\n        \"\"\"Send a message to a client.\n\n        If the client is likely to have already cached the message, we may\n        instead send a \"reference\" message that contains only the hash of the\n        message.\n\n        Parameters\n        ----------\n        session_info : ActiveSessionInfo\n            The ActiveSessionInfo associated with websocket\n        msg : ForwardMsg\n            The message to send to the client\n\n        Notes\n        -----\n        Threading: UNSAFE. Must be called on the eventloop thread.\n        \"\"\"\n        msg.metadata.cacheable = is_cacheable_msg(msg)\n        msg_to_send = msg\n        if msg.metadata.cacheable:\n            populate_hash_if_needed(msg)\n\n            if self._message_cache.has_message_reference(\n                msg, session_info.session, session_info.script_run_count\n            ):\n                # This session has probably cached this message. Send\n                # a reference instead.\n                _LOGGER.debug(\"Sending cached message ref (hash=%s)\", msg.hash)\n                msg_to_send = create_reference_msg(msg)\n\n            # Cache the message so it can be referenced in the future.\n            # If the message is already cached, this will reset its\n            # age.\n            _LOGGER.debug(\"Caching message (hash=%s)\", msg.hash)\n            self._message_cache.add_message(\n                msg, session_info.session, session_info.script_run_count\n            )\n\n        # If this was a `script_finished` message, we increment the\n        # script_run_count for this session, and update the cache\n        if (\n            msg.WhichOneof(\"type\") == \"script_finished\"\n            and msg.script_finished == ForwardMsg.FINISHED_SUCCESSFULLY\n        ):\n            _LOGGER.debug(\n                \"Script run finished successfully; \"\n                \"removing expired entries from MessageCache \"\n                \"(max_age=%s)\",\n                config.get_option(\"global.maxCachedMessageAge\"),\n            )\n            session_info.script_run_count += 1\n            self._message_cache.remove_expired_entries_for_session(\n                session_info.session, session_info.script_run_count\n            )\n\n        # Ship it off!\n        session_info.client.write_forward_msg(msg_to_send)\n\n    def _enqueued_some_message(self) -> None:\n        \"\"\"Callback called by AppSession after the AppSession has enqueued a\n        message. Sets the \"needs_send_data\" event, which causes our core\n        loop to wake up and flush client message queues.\n\n        Notes\n        -----\n        Threading: SAFE. May be called on any thread.\n        \"\"\"\n        async_objs = self._get_async_objs()\n        async_objs.eventloop.call_soon_threadsafe(async_objs.need_send_data.set)\n\n    def _get_async_objs(self) -> AsyncObjects:\n        \"\"\"Return our AsyncObjects instance. If the Runtime hasn't been\n        started, this will raise an error.\n        \"\"\"\n        if self._async_objs is None:\n            raise RuntimeError(\"Runtime hasn't started yet!\")\n        return self._async_objs\n\n    def _on_session_disconnected(self) -> None:\n        \"\"\"Set the runtime state to NO_SESSIONS_CONNECTED if the last active\n        session was disconnected.\n        \"\"\"\n        if (\n            self._state == RuntimeState.ONE_OR_MORE_SESSIONS_CONNECTED\n            and self._session_mgr.num_active_sessions() == 0\n        ):\n            self._get_async_objs().has_connection.clear()\n            self._set_state(RuntimeState.NO_SESSIONS_CONNECTED)\n", "lib/streamlit/runtime/media_file_manager.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Provides global MediaFileManager object as `media_file_manager`.\"\"\"\n\nfrom __future__ import annotations\n\nimport collections\nimport threading\nfrom typing import Final\n\nfrom streamlit.logger import get_logger\nfrom streamlit.runtime.media_file_storage import MediaFileKind, MediaFileStorage\n\n_LOGGER: Final = get_logger(__name__)\n\n\ndef _get_session_id() -> str:\n    \"\"\"Get the active AppSession's session_id.\"\"\"\n    from streamlit.runtime.scriptrunner import get_script_run_ctx\n\n    ctx = get_script_run_ctx()\n    if ctx is None:\n        # This is only None when running \"python myscript.py\" rather than\n        # \"streamlit run myscript.py\". In which case the session ID doesn't\n        # matter and can just be a constant, as there's only ever \"session\".\n        return \"dontcare\"\n    else:\n        return ctx.session_id\n\n\nclass MediaFileMetadata:\n    \"\"\"Metadata that the MediaFileManager needs for each file it manages.\"\"\"\n\n    def __init__(self, kind: MediaFileKind = MediaFileKind.MEDIA):\n        self._kind = kind\n        self._is_marked_for_delete = False\n\n    @property\n    def kind(self) -> MediaFileKind:\n        return self._kind\n\n    @property\n    def is_marked_for_delete(self) -> bool:\n        return self._is_marked_for_delete\n\n    def mark_for_delete(self) -> None:\n        self._is_marked_for_delete = True\n\n\nclass MediaFileManager:\n    \"\"\"In-memory file manager for MediaFile objects.\n\n    This keeps track of:\n    - Which files exist, and what their IDs are. This is important so we can\n      serve files by ID -- that's the whole point of this class!\n    - Which files are being used by which AppSession (by ID). This is\n      important so we can remove files from memory when no more sessions need\n      them.\n    - The exact location in the app where each file is being used (i.e. the\n      file's \"coordinates\"). This is is important so we can mark a file as \"not\n      being used by a certain session\" if it gets replaced by another file at\n      the same coordinates. For example, when doing an animation where the same\n      image is constantly replace with new frames. (This doesn't solve the case\n      where the file's coordinates keep changing for some reason, though! e.g.\n      if new elements keep being prepended to the app. Unlikely to happen, but\n      we should address it at some point.)\n    \"\"\"\n\n    def __init__(self, storage: MediaFileStorage):\n        self._storage = storage\n\n        # Dict of [file_id -> MediaFileMetadata]\n        self._file_metadata: dict[str, MediaFileMetadata] = {}\n\n        # Dict[session ID][coordinates] -> file_id.\n        self._files_by_session_and_coord: dict[str, dict[str, str]] = (\n            collections.defaultdict(dict)\n        )\n\n        # MediaFileManager is used from multiple threads, so all operations\n        # need to be protected with a Lock. (This is not an RLock, which\n        # means taking it multiple times from the same thread will deadlock.)\n        self._lock = threading.Lock()\n\n    def _get_inactive_file_ids(self) -> set[str]:\n        \"\"\"Compute the set of files that are stored in the manager, but are\n        not referenced by any active session. These are files that can be\n        safely deleted.\n\n        Thread safety: callers must hold `self._lock`.\n        \"\"\"\n        # Get the set of all our file IDs.\n        file_ids = set(self._file_metadata.keys())\n\n        # Subtract all IDs that are in use by each session\n        for session_file_ids_by_coord in self._files_by_session_and_coord.values():\n            file_ids.difference_update(session_file_ids_by_coord.values())\n\n        return file_ids\n\n    def remove_orphaned_files(self) -> None:\n        \"\"\"Remove all files that are no longer referenced by any active session.\n\n        Safe to call from any thread.\n        \"\"\"\n        _LOGGER.debug(\"Removing orphaned files...\")\n\n        with self._lock:\n            for file_id in self._get_inactive_file_ids():\n                file = self._file_metadata[file_id]\n                if file.kind == MediaFileKind.MEDIA:\n                    self._delete_file(file_id)\n                elif file.kind == MediaFileKind.DOWNLOADABLE:\n                    if file.is_marked_for_delete:\n                        self._delete_file(file_id)\n                    else:\n                        file.mark_for_delete()\n\n    def _delete_file(self, file_id: str) -> None:\n        \"\"\"Delete the given file from storage, and remove its metadata from\n        self._files_by_id.\n\n        Thread safety: callers must hold `self._lock`.\n        \"\"\"\n        _LOGGER.debug(\"Deleting File: %s\", file_id)\n        self._storage.delete_file(file_id)\n        del self._file_metadata[file_id]\n\n    def clear_session_refs(self, session_id: str | None = None) -> None:\n        \"\"\"Remove the given session's file references.\n\n        (This does not remove any files from the manager - you must call\n        `remove_orphaned_files` for that.)\n\n        Should be called whenever ScriptRunner completes and when a session ends.\n\n        Safe to call from any thread.\n        \"\"\"\n        if session_id is None:\n            session_id = _get_session_id()\n\n        _LOGGER.debug(\"Disconnecting files for session with ID %s\", session_id)\n\n        with self._lock:\n            if session_id in self._files_by_session_and_coord:\n                del self._files_by_session_and_coord[session_id]\n\n        _LOGGER.debug(\n            \"Sessions still active: %r\", self._files_by_session_and_coord.keys()\n        )\n\n        _LOGGER.debug(\n            \"Files: %s; Sessions with files: %s\",\n            len(self._file_metadata),\n            len(self._files_by_session_and_coord),\n        )\n\n    def add(\n        self,\n        path_or_data: bytes | str,\n        mimetype: str,\n        coordinates: str,\n        file_name: str | None = None,\n        is_for_static_download: bool = False,\n    ) -> str:\n        \"\"\"Add a new MediaFile with the given parameters and return its URL.\n\n        If an identical file already exists, return the existing URL\n        and registers the current session as a user.\n\n        Safe to call from any thread.\n\n        Parameters\n        ----------\n        path_or_data : bytes or str\n            If bytes: the media file's raw data. If str: the name of a file\n            to load from disk.\n        mimetype : str\n            The mime type for the file. E.g. \"audio/mpeg\".\n            This string will be used in the \"Content-Type\" header when the file\n            is served over HTTP.\n        coordinates : str\n            Unique string identifying an element's location.\n            Prevents memory leak of \"forgotten\" file IDs when element media\n            is being replaced-in-place (e.g. an st.image stream).\n            coordinates should be of the form: \"1.(3.-14).5\"\n        file_name : str or None\n            Optional file_name. Used to set the filename in the response header.\n        is_for_static_download: bool\n            Indicate that data stored for downloading as a file,\n            not as a media for rendering at page. [default: False]\n\n        Returns\n        -------\n        str\n            The url that the frontend can use to fetch the media.\n\n        Raises\n        ------\n        If a filename is passed, any Exception raised when trying to read the\n        file will be re-raised.\n        \"\"\"\n\n        session_id = _get_session_id()\n\n        with self._lock:\n            kind = (\n                MediaFileKind.DOWNLOADABLE\n                if is_for_static_download\n                else MediaFileKind.MEDIA\n            )\n            file_id = self._storage.load_and_get_id(\n                path_or_data, mimetype, kind, file_name\n            )\n            metadata = MediaFileMetadata(kind=kind)\n\n            self._file_metadata[file_id] = metadata\n            self._files_by_session_and_coord[session_id][coordinates] = file_id\n\n            return self._storage.get_url(file_id)\n", "lib/streamlit/runtime/session_manager.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom abc import abstractmethod\nfrom dataclasses import dataclass\nfrom typing import TYPE_CHECKING, Callable, Protocol, cast\n\nif TYPE_CHECKING:\n    from streamlit.proto.ForwardMsg_pb2 import ForwardMsg\n    from streamlit.runtime.app_session import AppSession\n    from streamlit.runtime.script_data import ScriptData\n    from streamlit.runtime.scriptrunner.script_cache import ScriptCache\n    from streamlit.runtime.uploaded_file_manager import UploadedFileManager\n\n\nclass SessionClientDisconnectedError(Exception):\n    \"\"\"Raised by operations on a disconnected SessionClient.\"\"\"\n\n\nclass SessionClient(Protocol):\n    \"\"\"Interface for sending data to a session's client.\"\"\"\n\n    @abstractmethod\n    def write_forward_msg(self, msg: ForwardMsg) -> None:\n        \"\"\"Deliver a ForwardMsg to the client.\n\n        If the SessionClient has been disconnected, it should raise a\n        SessionClientDisconnectedError.\n        \"\"\"\n        raise NotImplementedError\n\n\n@dataclass\nclass ActiveSessionInfo:\n    \"\"\"Type containing data related to an active session.\n\n    This type is nearly identical to SessionInfo. The difference is that when using it,\n    we are guaranteed that SessionClient is not None.\n    \"\"\"\n\n    client: SessionClient\n    session: AppSession\n    script_run_count: int = 0\n\n\n@dataclass\nclass SessionInfo:\n    \"\"\"Type containing data related to an AppSession.\n\n    For each AppSession, the Runtime tracks that session's\n    script_run_count. This is used to track the age of messages in\n    the ForwardMsgCache.\n    \"\"\"\n\n    client: SessionClient | None\n    session: AppSession\n    script_run_count: int = 0\n\n    def is_active(self) -> bool:\n        return self.client is not None\n\n    def to_active(self) -> ActiveSessionInfo:\n        assert self.is_active(), \"A SessionInfo with no client cannot be active!\"\n\n        # NOTE: The cast here (rather than copying this SessionInfo's fields into a new\n        # ActiveSessionInfo) is important as the Runtime expects to be able to mutate\n        # what's returned from get_active_session_info to increment script_run_count.\n        return cast(ActiveSessionInfo, self)\n\n\nclass SessionStorageError(Exception):\n    \"\"\"Exception class for errors raised by SessionStorage.\n\n    The original error that causes a SessionStorageError to be (re)raised will generally\n    be an I/O error specific to the concrete SessionStorage implementation.\n    \"\"\"\n\n\nclass SessionStorage(Protocol):\n    @abstractmethod\n    def get(self, session_id: str) -> SessionInfo | None:\n        \"\"\"Return the SessionInfo corresponding to session_id, or None if one does not\n        exist.\n\n        Parameters\n        ----------\n        session_id\n            The unique ID of the session being fetched.\n\n        Returns\n        -------\n        SessionInfo or None\n\n        Raises\n        ------\n        SessionStorageError\n            Raised if an error occurs while attempting to fetch the session. This will\n            generally happen if there is an error with the underlying storage backend\n            (e.g. if we lose our connection to it).\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def save(self, session_info: SessionInfo) -> None:\n        \"\"\"Save the given session.\n\n        Parameters\n        ----------\n        session_info\n            The SessionInfo being saved.\n\n        Raises\n        ------\n        SessionStorageError\n            Raised if an error occurs while saving the given session.\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def delete(self, session_id: str) -> None:\n        \"\"\"Mark the session corresponding to session_id for deletion and stop tracking\n        it.\n\n        Note that:\n          * Calling delete on an ID corresponding to a nonexistent session is a no-op.\n          * Calling delete on an ID should cause the given session to no longer be\n            tracked by this SessionStorage, but exactly when and how the session's data\n            is eventually cleaned up is a detail left up to the implementation.\n\n        Parameters\n        ----------\n        session_id\n            The unique ID of the session to delete.\n\n        Raises\n        ------\n        SessionStorageError\n            Raised if an error occurs while attempting to delete the session.\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def list(self) -> list[SessionInfo]:\n        \"\"\"List all sessions tracked by this SessionStorage.\n\n        Returns\n        -------\n        List[SessionInfo]\n\n        Raises\n        ------\n        SessionStorageError\n            Raised if an error occurs while attempting to list sessions.\n        \"\"\"\n        raise NotImplementedError\n\n\nclass SessionManager(Protocol):\n    \"\"\"SessionManagers are responsible for encapsulating all session lifecycle behavior\n    that the Streamlit Runtime may care about.\n\n    A SessionManager must define the following required methods:\n      * __init__\n      * connect_session\n      * close_session\n      * get_session_info\n      * list_sessions\n\n    SessionManager implementations may also choose to define the notions of active and\n    inactive sessions. The precise definitions of active/inactive are left to the\n    concrete implementation. SessionManagers that wish to differentiate between active\n    and inactive sessions should have the required methods listed above operate on *all*\n    sessions. Additionally, they should define the following methods for working with\n    active sessions:\n      * disconnect_session\n      * get_active_session_info\n      * is_active_session\n      * list_active_sessions\n\n    When active session-related methods are left undefined, their default\n    implementations are the naturally corresponding required methods.\n\n    The Runtime, unless there's a good reason to do otherwise, should generally work\n    with the active-session versions of a SessionManager's methods. There isn't currently\n    a need for us to be able to operate on inactive sessions stored in SessionStorage\n    outside of the SessionManager itself. However, it's highly likely that we'll\n    eventually have to do so, which is why the abstractions allow for this now.\n\n    Notes\n    -----\n    Threading: All SessionManager methods are *not* threadsafe -- they must be called\n    from the runtime's eventloop thread.\n    \"\"\"\n\n    @abstractmethod\n    def __init__(\n        self,\n        session_storage: SessionStorage,\n        uploaded_file_manager: UploadedFileManager,\n        script_cache: ScriptCache,\n        message_enqueued_callback: Callable[[], None] | None,\n    ) -> None:\n        \"\"\"Initialize a SessionManager with the given SessionStorage.\n\n        Parameters\n        ----------\n        session_storage\n            The SessionStorage instance backing this SessionManager.\n\n        uploaded_file_manager\n            Used to manage files uploaded by users via the Streamlit web client.\n\n        script_cache\n            ScriptCache instance. Caches user script bytecode.\n\n        message_enqueued_callback\n            A callback invoked after a message is enqueued to be sent to a web client.\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def connect_session(\n        self,\n        client: SessionClient,\n        script_data: ScriptData,\n        user_info: dict[str, str | None],\n        existing_session_id: str | None = None,\n        session_id_override: str | None = None,\n    ) -> str:\n        \"\"\"Create a new session or connect to an existing one.\n\n        Parameters\n        ----------\n        client\n            A concrete SessionClient implementation for communicating with\n            the session's client.\n        script_data\n            Contains parameters related to running a script.\n        user_info\n            A dict that contains information about the session's user. For now,\n            it only (optionally) contains the user's email address.\n\n            {\n                \"email\": \"example@example.com\"\n            }\n        existing_session_id\n            The ID of an existing session to reconnect to. If one is not provided, a new\n            session is created. Note that whether a SessionManager supports reconnecting\n            to an existing session is left up to the concrete SessionManager\n            implementation. Those that do not support reconnection should simply ignore\n            this argument.\n        session_id_override\n            The ID to assign to a new session being created with this method. Setting\n            this can be useful when the service that a Streamlit Runtime is running in\n            wants to tie the lifecycle of a Streamlit session to some other session-like\n            object that it manages. Only one of existing_session_id and\n            session_id_override should be set.\n\n        Returns\n        -------\n        str\n            The session's unique string ID.\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def close_session(self, session_id: str) -> None:\n        \"\"\"Close and completely delete the session with the given id.\n\n        This function may be called multiple times for the same session,\n        which is not an error. (Subsequent calls just no-op.)\n\n        Parameters\n        ----------\n        session_id\n            The session's unique ID.\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_session_info(self, session_id: str) -> SessionInfo | None:\n        \"\"\"Return the SessionInfo for the given id, or None if no such session\n        exists.\n\n        Parameters\n        ----------\n        session_id\n            The session's unique ID.\n\n        Returns\n        -------\n        SessionInfo or None\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def list_sessions(self) -> list[SessionInfo]:\n        \"\"\"Return the SessionInfo for all sessions managed by this SessionManager.\n\n        Returns\n        -------\n        List[SessionInfo]\n        \"\"\"\n        raise NotImplementedError\n\n    def num_sessions(self) -> int:\n        \"\"\"Return the number of sessions tracked by this SessionManager.\n\n        Subclasses of SessionManager shouldn't provide their own implementation of this\n        method without a *very* good reason.\n\n        Returns\n        -------\n        int\n        \"\"\"\n        return len(self.list_sessions())\n\n    # NOTE: The following methods only need to be overwritten when a concrete\n    # SessionManager implementation has a notion of active vs inactive sessions.\n    # If left unimplemented in a subclass, the default implementations of these methods\n    # call corresponding SessionManager methods in a natural way.\n\n    def disconnect_session(self, session_id: str) -> None:\n        \"\"\"Disconnect the given session.\n\n        This method should be idempotent.\n\n        Parameters\n        ----------\n        session_id\n            The session's unique ID.\n        \"\"\"\n        self.close_session(session_id)\n\n    def get_active_session_info(self, session_id: str) -> ActiveSessionInfo | None:\n        \"\"\"Return the ActiveSessionInfo for the given id, or None if either no such\n        session exists or the session is not active.\n\n        Parameters\n        ----------\n        session_id\n            The active session's unique ID.\n\n        Returns\n        -------\n        ActiveSessionInfo or None\n        \"\"\"\n        session = self.get_session_info(session_id)\n        if session is None or not session.is_active():\n            return None\n        return session.to_active()\n\n    def is_active_session(self, session_id: str) -> bool:\n        \"\"\"Return True if the given session exists and is active, False otherwise.\n\n        Returns\n        -------\n        bool\n        \"\"\"\n        return self.get_active_session_info(session_id) is not None\n\n    def list_active_sessions(self) -> list[ActiveSessionInfo]:\n        \"\"\"Return the session info for all active sessions tracked by this SessionManager.\n\n        Returns\n        -------\n        List[ActiveSessionInfo]\n        \"\"\"\n        return [s.to_active() for s in self.list_sessions()]\n\n    def num_active_sessions(self) -> int:\n        \"\"\"Return the number of active sessions tracked by this SessionManager.\n\n        Subclasses of SessionManager shouldn't provide their own implementation of this\n        method without a *very* good reason.\n\n        Returns\n        -------\n        int\n        \"\"\"\n        return len(self.list_active_sessions())\n", "lib/streamlit/runtime/fragment.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport contextlib\nimport hashlib\nimport inspect\nfrom abc import abstractmethod\nfrom copy import deepcopy\nfrom functools import wraps\nfrom typing import TYPE_CHECKING, Any, Callable, Protocol, TypeVar, overload\n\nfrom streamlit.proto.ForwardMsg_pb2 import ForwardMsg\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.runtime.scriptrunner import get_script_run_ctx\nfrom streamlit.runtime.scriptrunner.exec_code import exec_func_with_error_handling\nfrom streamlit.time_util import time_to_seconds\n\nif TYPE_CHECKING:\n    from datetime import timedelta\n\nF = TypeVar(\"F\", bound=Callable[..., Any])\nFragment = Callable[[], Any]\n\n\nclass FragmentStorage(Protocol):\n    \"\"\"A key-value store for Fragments. Used to implement the @st.experimental_fragment\n    decorator.\n\n    We intentionally define this as its own protocol despite how generic it appears to\n    be at first glance. The reason why is that, in any case where fragments aren't just\n    stored as Python closures in memory, storing and retrieving Fragments will generally\n    involve serializing and deserializing function bytecode, which is a tricky aspect\n    to implementing FragmentStorages that won't generally appear with our other *Storage\n    protocols.\n    \"\"\"\n\n    @abstractmethod\n    def get(self, key: str) -> Fragment:\n        \"\"\"Returns the stored fragment for the given key.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def set(self, key: str, value: Fragment) -> None:\n        \"\"\"Saves a fragment under the given key.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def delete(self, key: str) -> None:\n        \"\"\"Delete the fragment corresponding to the given key.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def clear(self) -> None:\n        \"\"\"Remove all fragments saved in this FragmentStorage.\"\"\"\n        raise NotImplementedError\n\n\n# NOTE: Ideally, we'd like to add a MemoryFragmentStorageStatProvider implementation to\n# keep track of memory usage due to fragments, but doing something like this ends up\n# being difficult in practice as the memory usage of a closure is hard to measure (the\n# vendored implementation of pympler.asizeof that we use elsewhere is unable to measure\n# the size of a function).\nclass MemoryFragmentStorage(FragmentStorage):\n    \"\"\"A simple, memory-backed implementation of FragmentStorage.\n\n    MemoryFragmentStorage is just a wrapper around a plain Python dict that complies with\n    the FragmentStorage protocol.\n    \"\"\"\n\n    def __init__(self):\n        self._fragments: dict[str, Fragment] = {}\n\n    def get(self, key: str) -> Fragment:\n        return self._fragments[key]\n\n    def set(self, key: str, value: Fragment) -> None:\n        self._fragments[key] = value\n\n    def delete(self, key: str) -> None:\n        del self._fragments[key]\n\n    def clear(self) -> None:\n        self._fragments.clear()\n\n\ndef _fragment(\n    func: F | None = None, *, run_every: int | float | timedelta | str | None = None\n) -> Callable[[F], F] | F:\n    \"\"\"Contains the actual fragment logic.\n\n    This function should be used by our internal functions that use fragments\n    under-the-hood, so that fragment metrics are not tracked for those elements\n    (note that the @gather_metrics annotation is only on the publicly exposed function)\n    \"\"\"\n\n    if func is None:\n        # Support passing the params via function decorator\n        def wrapper(f: F) -> F:\n            return fragment(\n                func=f,\n                run_every=run_every,\n            )\n\n        return wrapper\n    else:\n        non_optional_func = func\n\n    @wraps(non_optional_func)\n    def wrap(*args, **kwargs):\n        from streamlit.delta_generator import dg_stack\n\n        ctx = get_script_run_ctx()\n        if ctx is None:\n            return\n\n        cursors_snapshot = deepcopy(ctx.cursors)\n        dg_stack_snapshot = deepcopy(dg_stack.get())\n        active_dg = dg_stack_snapshot[-1]\n        h = hashlib.new(\"md5\")\n        h.update(\n            f\"{non_optional_func.__module__}.{non_optional_func.__qualname__}{active_dg._get_delta_path_str()}\".encode()\n        )\n        fragment_id = h.hexdigest()\n\n        # We intentionally want to capture the active script hash here to ensure\n        # that the fragment is associated with the correct script running.\n        initialized_active_script_hash = ctx.active_script_hash\n\n        def wrapped_fragment():\n            import streamlit as st\n\n            # NOTE: We need to call get_script_run_ctx here again and can't just use the\n            # value of ctx from above captured by the closure because subsequent\n            # fragment runs will generally run in a new script run, thus we'll have a\n            # new ctx.\n            ctx = get_script_run_ctx(suppress_warning=True)\n            assert ctx is not None\n\n            if ctx.fragment_ids_this_run:\n                # This script run is a run of one or more fragments. We restore the\n                # state of ctx.cursors and dg_stack to the snapshots we took when this\n                # fragment was declared.\n                ctx.cursors = deepcopy(cursors_snapshot)\n                dg_stack.set(deepcopy(dg_stack_snapshot))\n            else:\n                # Otherwise, we must be in a full script run. We need to temporarily set\n                # ctx.current_fragment_id so that elements corresponding to this\n                # fragment get tagged with the appropriate ID. ctx.current_fragment_id\n                # gets reset after the fragment function finishes running.\n                ctx.current_fragment_id = fragment_id\n\n            try:\n                # Make sure we set the active script hash to the same value\n                # for the fragment run as when defined upon initialization\n                # This ensures that elements (especially widgets) are tied\n                # to a consistent active script hash\n                active_hash_context = (\n                    ctx.pages_manager.run_with_active_hash(\n                        initialized_active_script_hash\n                    )\n                    if initialized_active_script_hash != ctx.active_script_hash\n                    else contextlib.nullcontext()\n                )\n                with active_hash_context:\n                    with st.container():\n                        ctx.current_fragment_delta_path = (\n                            active_dg._cursor.delta_path if active_dg._cursor else []\n                        )\n                        result = non_optional_func(*args, **kwargs)\n            finally:\n                ctx.current_fragment_id = None\n\n            return result\n\n        ctx.fragment_storage.set(fragment_id, wrapped_fragment)\n\n        if run_every:\n            msg = ForwardMsg()\n            msg.auto_rerun.interval = time_to_seconds(run_every)\n            msg.auto_rerun.fragment_id = fragment_id\n            ctx.enqueue(msg)\n\n        # Wrap the fragment function in the same try-except block as in a normal\n        # script_run so that for a main-app run (this execution) and a fragment-rerun\n        # the same execution and error-handling logic is used. This makes errors in the\n        # fragment appear in the fragment path also for the first execution here in\n        # context of a full app run.\n        result, _, _, _ = exec_func_with_error_handling(\n            wrapped_fragment, ctx, reraise_rerun_exception=True\n        )\n        return result\n\n    with contextlib.suppress(AttributeError):\n        # Make this a well-behaved decorator by preserving important function\n        # attributes.\n        wrap.__dict__.update(non_optional_func.__dict__)\n        wrap.__signature__ = inspect.signature(non_optional_func)  # type: ignore\n\n    return wrap\n\n\n@overload\ndef fragment(\n    func: F,\n    *,\n    run_every: int | float | timedelta | str | None = None,\n) -> F: ...\n\n\n# Support being able to pass parameters to this decorator (that is, being able to write\n# `@fragment(run_every=5.0)`).\n@overload\ndef fragment(\n    func: None = None,\n    *,\n    run_every: int | float | timedelta | str | None = None,\n) -> Callable[[F], F]: ...\n\n\n@gather_metrics(\"experimental_fragment\")\ndef fragment(\n    func: F | None = None,\n    *,\n    run_every: int | float | timedelta | str | None = None,\n) -> Callable[[F], F] | F:\n    \"\"\"Decorator to turn a function into a fragment which can rerun independently\\\n    of the full app.\n\n    When a user interacts with an input widget created inside a fragment,\n    Streamlit only reruns the fragment instead of the full app. If\n    ``run_every`` is set, Streamlit will also rerun the fragment at the\n    specified interval while the session is active, even if the user is not\n    interacting with your app.\n\n    To trigger an app rerun from inside a fragment, call ``st.rerun()``\n    directly. Any values from the fragment that need to be accessed from\n    the wider app should generally be stored in Session State.\n\n    When Streamlit element commands are called directly in a fragment, the\n    elements are cleared and redrawn on each fragment rerun, just like all\n    elements are redrawn on each app rerun. The rest of the app is persisted\n    during a fragment rerun. When a fragment renders elements into externally\n    created containers, the elements will not be cleared with each fragment\n    rerun. Instead, elements will accumulate in those containers with each\n    fragment rerun, until the next app rerun.\n\n    Calling ``st.sidebar`` in a fragment is not supported. To write elements to\n    the sidebar with a fragment, call your fragment function inside a\n    ``with st.sidebar`` context manager.\n\n    Fragment code can interact with Session State, imported modules, and\n    other Streamlit elements created outside the fragment. Note that these\n    interactions are additive across multiple fragment reruns. You are\n    responsible for handling any side effects of that behavior.\n\n    .. warning::\n        - Fragments can't contain other fragments. Additionally, using\n          fragments in widget callback functions is not supported.\n\n        - Fragments can only contain widgets in their main body. Fragments\n          can't render widgets to externally created containers.\n\n    Parameters\n    ----------\n    func: callable\n        The function to turn into a fragment.\n\n    run_every: int, float, timedelta, str, or None\n        The time interval between automatic fragment reruns. This can be one of\n        the following:\n\n            * ``None`` (default).\n            * An ``int`` or ``float`` specifying the interval in seconds.\n            * A string specifying the time in a format supported by `Pandas'\n              Timedelta constructor <https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.html>`_,\n              e.g. ``\"1d\"``, ``\"1.5 days\"``, or ``\"1h23s\"``.\n            * A ``timedelta`` object from `Python's built-in datetime library\n              <https://docs.python.org/3/library/datetime.html#timedelta-objects>`_,\n              e.g. ``timedelta(days=1)``.\n\n        If ``run_every`` is ``None``, the fragment will only rerun from\n        user-triggered events.\n\n    Examples\n    --------\n    The following example demonstrates basic usage of\n    ``@st.experimental_fragment``. As an anology, \"inflating balloons\" is a\n    slow process that happens outside of the fragment. \"Releasing balloons\" is\n    a quick process that happens inside of the fragment.\n\n    >>> import streamlit as st\n    >>> import time\n    >>>\n    >>> @st.experimental_fragment\n    >>> def release_the_balloons():\n    >>>     st.button(\"Release the balloons\", help=\"Fragment rerun\")\n    >>>     st.balloons()\n    >>>\n    >>> with st.spinner(\"Inflating balloons...\"):\n    >>>     time.sleep(5)\n    >>> release_the_balloons()\n    >>> st.button(\"Inflate more balloons\", help=\"Full rerun\")\n\n    .. output::\n        https://doc-fragment-balloons.streamlit.app/\n        height: 220px\n\n    This next example demonstrates how elements both inside and outside of a\n    fragement update with each app or fragment rerun. In this app, clicking\n    \"Rerun full app\" will increment both counters and update all values\n    displayed in the app. In contrast, clicking \"Rerun fragment\" will only\n    increment the counter within the fragment. In this case, the ``st.write``\n    command inside the fragment will update the app's frontend, but the two\n    ``st.write`` commands outside the fragment will not update the frontend.\n\n    >>> import streamlit as st\n    >>>\n    >>> if \"app_runs\" not in st.session_state:\n    >>>     st.session_state.app_runs = 0\n    >>>     st.session_state.fragment_runs = 0\n    >>>\n    >>> @st.experimental_fragment\n    >>> def fragment():\n    >>>     st.session_state.fragment_runs += 1\n    >>>     st.button(\"Rerun fragment\")\n    >>>     st.write(f\"Fragment says it ran {st.session_state.fragment_runs} times.\")\n    >>>\n    >>> st.session_state.app_runs += 1\n    >>> fragment()\n    >>> st.button(\"Rerun full app\")\n    >>> st.write(f\"Full app says it ran {st.session_state.app_runs} times.\")\n    >>> st.write(f\"Full app sees that fragment ran {st.session_state.fragment_runs} times.\")\n\n    .. output::\n        https://doc-fragment.streamlit.app/\n        height: 400px\n\n    You can also trigger an app rerun from inside a fragment by calling\n    ``st.rerun``.\n\n    >>> import streamlit as st\n    >>>\n    >>> if \"clicks\" not in st.session_state:\n    >>>     st.session_state.clicks = 0\n    >>>\n    >>> @st.experimental_fragment\n    >>> def count_to_five():\n    >>>     if st.button(\"Plus one!\"):\n    >>>         st.session_state.clicks += 1\n    >>>         if st.session_state.clicks % 5 == 0:\n    >>>             st.rerun()\n    >>>     return\n    >>>\n    >>> count_to_five()\n    >>> st.header(f\"Multiples of five clicks: {st.session_state.clicks // 5}\")\n    >>>\n    >>> if st.button(\"Check click count\"):\n    >>>     st.toast(f\"## Total clicks: {st.session_state.clicks}\")\n\n    .. output::\n        https://doc-fragment-rerun.streamlit.app/\n        height: 400px\n\n    \"\"\"\n    return _fragment(func, run_every=run_every)\n", "lib/streamlit/runtime/stats.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport itertools\nfrom abc import abstractmethod\nfrom typing import TYPE_CHECKING, NamedTuple, Protocol, runtime_checkable\n\nif TYPE_CHECKING:\n    from streamlit.proto.openmetrics_data_model_pb2 import Metric as MetricProto\n\n\nclass CacheStat(NamedTuple):\n    \"\"\"Describes a single cache entry.\n\n    Properties\n    ----------\n    category_name : str\n        A human-readable name for the cache \"category\" that the entry belongs\n        to - e.g. \"st.memo\", \"session_state\", etc.\n    cache_name : str\n        A human-readable name for cache instance that the entry belongs to.\n        For \"st.memo\" and other function decorator caches, this might be the\n        name of the cached function. If the cache category doesn't have\n        multiple separate cache instances, this can just be the empty string.\n    byte_length : int\n        The entry's memory footprint in bytes.\n    \"\"\"\n\n    category_name: str\n    cache_name: str\n    byte_length: int\n\n    def to_metric_str(self) -> str:\n        return f'cache_memory_bytes{{cache_type=\"{self.category_name}\",cache=\"{self.cache_name}\"}} {self.byte_length}'\n\n    def marshall_metric_proto(self, metric: MetricProto) -> None:\n        \"\"\"Fill an OpenMetrics `Metric` protobuf object.\"\"\"\n        label = metric.labels.add()\n        label.name = \"cache_type\"\n        label.value = self.category_name\n\n        label = metric.labels.add()\n        label.name = \"cache\"\n        label.value = self.cache_name\n\n        metric_point = metric.metric_points.add()\n        metric_point.gauge_value.int_value = self.byte_length\n\n\ndef group_stats(stats: list[CacheStat]) -> list[CacheStat]:\n    \"\"\"Group a list of CacheStats by category_name and cache_name and sum byte_length\"\"\"\n\n    def key_function(individual_stat):\n        return individual_stat.category_name, individual_stat.cache_name\n\n    result: list[CacheStat] = []\n\n    sorted_stats = sorted(stats, key=key_function)\n    grouped_stats = itertools.groupby(sorted_stats, key=key_function)\n\n    for (category_name, cache_name), single_group_stats in grouped_stats:\n        result.append(\n            CacheStat(\n                category_name=category_name,\n                cache_name=cache_name,\n                byte_length=sum(item.byte_length for item in single_group_stats),\n            )\n        )\n    return result\n\n\n@runtime_checkable\nclass CacheStatsProvider(Protocol):\n    @abstractmethod\n    def get_stats(self) -> list[CacheStat]:\n        raise NotImplementedError\n\n\nclass StatsManager:\n    def __init__(self):\n        self._cache_stats_providers: list[CacheStatsProvider] = []\n\n    def register_provider(self, provider: CacheStatsProvider) -> None:\n        \"\"\"Register a CacheStatsProvider with the manager.\n        This function is not thread-safe. Call it immediately after\n        creation.\n        \"\"\"\n        self._cache_stats_providers.append(provider)\n\n    def get_stats(self) -> list[CacheStat]:\n        \"\"\"Return a list containing all stats from each registered provider.\"\"\"\n        all_stats: list[CacheStat] = []\n        for provider in self._cache_stats_providers:\n            all_stats.extend(provider.get_stats())\n\n        return all_stats\n", "lib/streamlit/runtime/memory_uploaded_file_manager.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport uuid\nfrom collections import defaultdict\nfrom typing import Sequence\n\nfrom streamlit import util\nfrom streamlit.runtime.stats import CacheStat, group_stats\nfrom streamlit.runtime.uploaded_file_manager import (\n    UploadedFileManager,\n    UploadedFileRec,\n    UploadFileUrlInfo,\n)\n\n\nclass MemoryUploadedFileManager(UploadedFileManager):\n    \"\"\"Holds files uploaded by users of the running Streamlit app.\n    This class can be used safely from multiple threads simultaneously.\n    \"\"\"\n\n    def __init__(self, upload_endpoint: str):\n        self.file_storage: dict[str, dict[str, UploadedFileRec]] = defaultdict(dict)\n        self.endpoint = upload_endpoint\n\n    def get_files(\n        self, session_id: str, file_ids: Sequence[str]\n    ) -> list[UploadedFileRec]:\n        \"\"\"Return a  list of UploadedFileRec for a given sequence of file_ids.\n\n        Parameters\n        ----------\n        session_id\n            The ID of the session that owns the files.\n        file_ids\n            The sequence of ids associated with files to retrieve.\n\n        Returns\n        -------\n        List[UploadedFileRec]\n            A list of URL UploadedFileRec instances, each instance contains information\n            about uploaded file.\n        \"\"\"\n        session_storage = self.file_storage[session_id]\n        file_recs = []\n\n        for file_id in file_ids:\n            file_rec = session_storage.get(file_id, None)\n            if file_rec is not None:\n                file_recs.append(file_rec)\n\n        return file_recs\n\n    def remove_session_files(self, session_id: str) -> None:\n        \"\"\"Remove all files associated with a given session.\"\"\"\n        self.file_storage.pop(session_id, None)\n\n    def __repr__(self) -> str:\n        return util.repr_(self)\n\n    def add_file(\n        self,\n        session_id: str,\n        file: UploadedFileRec,\n    ) -> None:\n        \"\"\"\n        Safe to call from any thread.\n\n        Parameters\n        ----------\n        session_id\n            The ID of the session that owns the file.\n        file\n            The file to add.\n        \"\"\"\n\n        self.file_storage[session_id][file.file_id] = file\n\n    def remove_file(self, session_id, file_id):\n        \"\"\"Remove file with given file_id associated with a given session.\"\"\"\n        session_storage = self.file_storage[session_id]\n        session_storage.pop(file_id, None)\n\n    def get_upload_urls(\n        self, session_id: str, file_names: Sequence[str]\n    ) -> list[UploadFileUrlInfo]:\n        \"\"\"Return a list of UploadFileUrlInfo for a given sequence of file_names.\"\"\"\n        result = []\n        for _ in file_names:\n            file_id = str(uuid.uuid4())\n            result.append(\n                UploadFileUrlInfo(\n                    file_id=file_id,\n                    upload_url=f\"{self.endpoint}/{session_id}/{file_id}\",\n                    delete_url=f\"{self.endpoint}/{session_id}/{file_id}\",\n                )\n            )\n        return result\n\n    def get_stats(self) -> list[CacheStat]:\n        \"\"\"Return the manager's CacheStats.\n\n        Safe to call from any thread.\n        \"\"\"\n        # Flatten all files into a single list\n        all_files: list[UploadedFileRec] = []\n        # Make copy of self.file_storage for thread safety, to be sure\n        # that main storage won't be changed form other thread\n        file_storage_copy = self.file_storage.copy()\n\n        for session_storage in file_storage_copy.values():\n            all_files.extend(session_storage.values())\n\n        stats: list[CacheStat] = [\n            CacheStat(\n                category_name=\"UploadedFileManager\",\n                cache_name=\"\",\n                byte_length=len(file.data),\n            )\n            for file in all_files\n        ]\n        return group_stats(stats)\n", "lib/streamlit/runtime/uploaded_file_manager.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport io\nfrom abc import abstractmethod\nfrom typing import TYPE_CHECKING, NamedTuple, Protocol, Sequence\n\nfrom streamlit import util\nfrom streamlit.runtime.stats import CacheStatsProvider\n\nif TYPE_CHECKING:\n    from streamlit.proto.Common_pb2 import FileURLs as FileURLsProto\n\n\nclass UploadedFileRec(NamedTuple):\n    \"\"\"Metadata and raw bytes for an uploaded file. Immutable.\"\"\"\n\n    file_id: str\n    name: str\n    type: str\n    data: bytes\n\n\nclass UploadFileUrlInfo(NamedTuple):\n    \"\"\"Information we provide for single file in get_upload_urls\"\"\"\n\n    file_id: str\n    upload_url: str\n    delete_url: str\n\n\nclass DeletedFile(NamedTuple):\n    \"\"\"Represents a deleted file in deserialized values for st.file_uploader and\n    st.camera_input\n\n    Return this from st.file_uploader and st.camera_input deserialize (so they can\n    be used in session_state), when widget value contains file record that is missing\n    from the storage.\n    DeleteFile instances filtered out before return final value to the user in script,\n    or before sending to frontend.\"\"\"\n\n    file_id: str\n\n\nclass UploadedFile(io.BytesIO):\n    \"\"\"A mutable uploaded file.\n\n    This class extends BytesIO, which has copy-on-write semantics when\n    initialized with `bytes`.\n    \"\"\"\n\n    def __init__(self, record: UploadedFileRec, file_urls: FileURLsProto):\n        # BytesIO's copy-on-write semantics doesn't seem to be mentioned in\n        # the Python docs - possibly because it's a CPython-only optimization\n        # and not guaranteed to be in other Python runtimes. But it's detailed\n        # here: https://hg.python.org/cpython/rev/79a5fbe2c78f\n        super().__init__(record.data)\n        self.file_id = record.file_id\n        self.name = record.name\n        self.type = record.type\n        self.size = len(record.data)\n        self._file_urls = file_urls\n\n    def __eq__(self, other: object) -> bool:\n        if not isinstance(other, UploadedFile):\n            return NotImplemented\n        return self.file_id == other.file_id\n\n    def __repr__(self) -> str:\n        return util.repr_(self)\n\n\nclass UploadedFileManager(CacheStatsProvider, Protocol):\n    \"\"\"UploadedFileManager protocol, that should be implemented by the concrete\n    uploaded file managers.\n\n    It is responsible for:\n        - retrieving files by session_id and file_id for st.file_uploader and\n            st.camera_input\n        - cleaning up uploaded files associated with session on session end\n\n    It should be created during Runtime initialization.\n\n    Optionally UploadedFileManager could be responsible for issuing URLs which will be\n    used by frontend to upload files to.\n    \"\"\"\n\n    @abstractmethod\n    def get_files(\n        self, session_id: str, file_ids: Sequence[str]\n    ) -> list[UploadedFileRec]:\n        \"\"\"Return a  list of UploadedFileRec for a given sequence of file_ids.\n\n        Parameters\n        ----------\n        session_id\n            The ID of the session that owns the files.\n        file_ids\n            The sequence of ids associated with files to retrieve.\n\n        Returns\n        -------\n        List[UploadedFileRec]\n            A list of URL UploadedFileRec instances, each instance contains information\n            about uploaded file.\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def remove_session_files(self, session_id: str) -> None:\n        \"\"\"Remove all files associated with a given session.\"\"\"\n        raise NotImplementedError\n\n    def get_upload_urls(\n        self, session_id: str, file_names: Sequence[str]\n    ) -> list[UploadFileUrlInfo]:\n        \"\"\"Return a list of UploadFileUrlInfo for a given sequence of file_names.\n        Optional to implement, issuing of URLs could be done by other service.\n\n        Parameters\n        ----------\n        session_id\n            The ID of the session that request URLs.\n        file_names\n            The sequence of file names for which URLs are requested\n\n        Returns\n        -------\n        List[UploadFileUrlInfo]\n            A list of UploadFileUrlInfo instances, each instance contains information\n            about uploaded file URLs.\n        \"\"\"\n        raise NotImplementedError\n", "lib/streamlit/runtime/connection_factory.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport os\nimport re\nfrom typing import TYPE_CHECKING, Any, Final, Literal, TypeVar, overload\n\nfrom streamlit.connections import (\n    BaseConnection,\n    SnowflakeConnection,\n    SnowparkConnection,\n    SQLConnection,\n)\nfrom streamlit.deprecation_util import deprecate_obj_name\nfrom streamlit.errors import StreamlitAPIException\nfrom streamlit.runtime.caching import cache_resource\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.runtime.secrets import secrets_singleton\n\nif TYPE_CHECKING:\n    from datetime import timedelta\n\n# NOTE: Adding support for a new first party connection requires:\n#   1. Adding the new connection name and class to this dict.\n#   2. Writing two new @overloads for connection_factory (one for the case where the\n#      only the connection name is specified and another when both name and type are).\n#   3. Updating test_get_first_party_connection_helper in connection_factory_test.py.\nFIRST_PARTY_CONNECTIONS = {\n    \"snowflake\": SnowflakeConnection,\n    \"snowpark\": SnowparkConnection,\n    \"sql\": SQLConnection,\n}\nMODULE_EXTRACTION_REGEX = re.compile(r\"No module named \\'(.+)\\'\")\nMODULES_TO_PYPI_PACKAGES: Final[dict[str, str]] = {\n    \"MySQLdb\": \"mysqlclient\",\n    \"psycopg2\": \"psycopg2-binary\",\n    \"sqlalchemy\": \"sqlalchemy\",\n    \"snowflake\": \"snowflake-connector-python\",\n    \"snowflake.connector\": \"snowflake-connector-python\",\n    \"snowflake.snowpark\": \"snowflake-snowpark-python\",\n}\n\n# The BaseConnection bound is parameterized to `Any` below as subclasses of\n# BaseConnection are responsible for binding the type parameter of BaseConnection to a\n# concrete type, but the type it gets bound to isn't important to us here.\nConnectionClass = TypeVar(\"ConnectionClass\", bound=BaseConnection[Any])\n\n\n@gather_metrics(\"connection\")\ndef _create_connection(\n    name: str,\n    connection_class: type[ConnectionClass],\n    max_entries: int | None = None,\n    ttl: float | timedelta | None = None,\n    **kwargs,\n) -> ConnectionClass:\n    \"\"\"Create an instance of connection_class with the given name and kwargs.\n\n    The weird implementation of this function with the @cache_resource annotated\n    function defined internally is done to:\n      * Always @gather_metrics on the call even if the return value is a cached one.\n      * Allow the user to specify ttl and max_entries when calling st.connection.\n    \"\"\"\n\n    def __create_connection(\n        name: str, connection_class: type[ConnectionClass], **kwargs\n    ) -> ConnectionClass:\n        return connection_class(connection_name=name, **kwargs)\n\n    if not issubclass(connection_class, BaseConnection):\n        raise StreamlitAPIException(\n            f\"{connection_class} is not a subclass of BaseConnection!\"\n        )\n\n    # We modify our helper function's `__qualname__` here to work around default\n    # `@st.cache_resource` behavior. Otherwise, `st.connection` being called with\n    # different `ttl` or `max_entries` values will reset the cache with each call.\n    ttl_str = str(ttl).replace(  # Avoid adding extra `.` characters to `__qualname__`\n        \".\", \"_\"\n    )\n    __create_connection.__qualname__ = (\n        f\"{__create_connection.__qualname__}_{ttl_str}_{max_entries}\"\n    )\n    __create_connection = cache_resource(\n        max_entries=max_entries,\n        show_spinner=\"Running `st.connection(...)`.\",\n        ttl=ttl,\n    )(__create_connection)\n\n    return __create_connection(name, connection_class, **kwargs)\n\n\ndef _get_first_party_connection(connection_class: str):\n    if connection_class in FIRST_PARTY_CONNECTIONS:\n        return FIRST_PARTY_CONNECTIONS[connection_class]\n\n    raise StreamlitAPIException(\n        f\"Invalid connection '{connection_class}'. \"\n        f\"Supported connection classes: {FIRST_PARTY_CONNECTIONS}\"\n    )\n\n\n@overload\ndef connection_factory(\n    name: Literal[\"sql\"],\n    max_entries: int | None = None,\n    ttl: float | timedelta | None = None,\n    autocommit: bool = False,\n    **kwargs,\n) -> SQLConnection:\n    pass\n\n\n@overload\ndef connection_factory(\n    name: str,\n    type: Literal[\"sql\"],\n    max_entries: int | None = None,\n    ttl: float | timedelta | None = None,\n    autocommit: bool = False,\n    **kwargs,\n) -> SQLConnection:\n    pass\n\n\n@overload\ndef connection_factory(\n    name: Literal[\"snowflake\"],\n    max_entries: int | None = None,\n    ttl: float | timedelta | None = None,\n    autocommit: bool = False,\n    **kwargs,\n) -> SnowflakeConnection:\n    pass\n\n\n@overload\ndef connection_factory(\n    name: str,\n    type: Literal[\"snowflake\"],\n    max_entries: int | None = None,\n    ttl: float | timedelta | None = None,\n    autocommit: bool = False,\n    **kwargs,\n) -> SnowflakeConnection:\n    pass\n\n\n@overload\ndef connection_factory(\n    name: Literal[\"snowpark\"],\n    max_entries: int | None = None,\n    ttl: float | timedelta | None = None,\n    **kwargs,\n) -> SnowparkConnection:\n    pass\n\n\n@overload\ndef connection_factory(\n    name: str,\n    type: Literal[\"snowpark\"],\n    max_entries: int | None = None,\n    ttl: float | timedelta | None = None,\n    **kwargs,\n) -> SnowparkConnection:\n    pass\n\n\n@overload\ndef connection_factory(\n    name: str,\n    type: type[ConnectionClass],\n    max_entries: int | None = None,\n    ttl: float | timedelta | None = None,\n    **kwargs,\n) -> ConnectionClass:\n    pass\n\n\n@overload\ndef connection_factory(\n    name: str,\n    type: str | None = None,\n    max_entries: int | None = None,\n    ttl: float | timedelta | None = None,\n    **kwargs,\n) -> BaseConnection[Any]:\n    pass\n\n\ndef connection_factory(\n    name,\n    type=None,\n    max_entries=None,\n    ttl=None,\n    **kwargs,\n):\n    \"\"\"Create a new connection to a data store or API, or return an existing one.\n\n    Config options, credentials, secrets, etc. for connections are taken from various\n    sources:\n\n    - Any connection-specific configuration files.\n    - An app's ``secrets.toml`` files.\n    - The kwargs passed to this function.\n\n    Parameters\n    ----------\n    name : str\n        The connection name used for secrets lookup in ``[connections.<name>]``.\n        Type will be inferred from passing ``\"sql\"``, ``\"snowflake\"``, or ``\"snowpark\"``.\n    type : str, connection class, or None\n        The type of connection to create. It can be a keyword (``\"sql\"``, ``\"snowflake\"``,\n        or ``\"snowpark\"``), a path to an importable class, or an imported class reference.\n        All classes must extend ``st.connections.BaseConnection`` and implement the\n        ``_connect()`` method. If the type kwarg is None, a ``type`` field must be set in\n        the connection's section in ``secrets.toml``.\n    max_entries : int or None\n        The maximum number of connections to keep in the cache, or None\n        for an unbounded cache. (When a new entry is added to a full cache,\n        the oldest cached entry will be removed.) The default is None.\n    ttl : float, timedelta, or None\n        The maximum number of seconds to keep results in the cache, or\n        None if cached results should not expire. The default is None.\n    **kwargs : any\n        Additional connection specific kwargs that are passed to the Connection's\n        ``_connect()`` method. Learn more from the specific Connection's documentation.\n\n    Returns\n    -------\n    Connection object\n        An initialized Connection object of the specified type.\n\n    Examples\n    --------\n    The easiest way to create a first-party (SQL, Snowflake, or Snowpark) connection is\n    to use their default names and define corresponding sections in your ``secrets.toml``\n    file.\n\n    >>> import streamlit as st\n    >>> conn = st.connection(\"sql\") # Config section defined in [connections.sql] in secrets.toml.\n\n    Creating a SQLConnection with a custom name requires you to explicitly specify the\n    type. If type is not passed as a kwarg, it must be set in the appropriate section of\n    ``secrets.toml``.\n\n    >>> import streamlit as st\n    >>> conn1 = st.connection(\"my_sql_connection\", type=\"sql\") # Config section defined in [connections.my_sql_connection].\n    >>> conn2 = st.connection(\"my_other_sql_connection\") # type must be set in [connections.my_other_sql_connection].\n\n    Passing the full module path to the connection class that you want to use can be\n    useful, especially when working with a custom connection:\n\n    >>> import streamlit as st\n    >>> conn = st.connection(\"my_sql_connection\", type=\"streamlit.connections.SQLConnection\")\n\n    Finally, you can pass the connection class to use directly to this function. Doing\n    so allows static type checking tools such as ``mypy`` to infer the exact return\n    type of ``st.connection``.\n\n    >>> import streamlit as st\n    >>> from streamlit.connections import SQLConnection\n    >>> conn = st.connection(\"my_sql_connection\", type=SQLConnection)\n    \"\"\"\n    USE_ENV_PREFIX = \"env:\"\n\n    if name.startswith(USE_ENV_PREFIX):\n        # It'd be nice to use str.removeprefix() here, but we won't be able to do that\n        # until the minimium Python version we support is 3.9.\n        envvar_name = name[len(USE_ENV_PREFIX) :]\n        name = os.environ[envvar_name]\n\n    if type is None:\n        if name in FIRST_PARTY_CONNECTIONS:\n            # We allow users to simply write `st.connection(\"sql\")` instead of\n            # `st.connection(\"sql\", type=\"sql\")`.\n            type = _get_first_party_connection(name)\n        else:\n            # The user didn't specify a type, so we try to pull it out from their\n            # secrets.toml file. NOTE: we're okay with any of the dict lookups below\n            # exploding with a KeyError since, if type isn't explicitly specified here,\n            # it must be the case that it's defined in secrets.toml and should raise an\n            # Exception otherwise.\n            secrets_singleton.load_if_toml_exists()\n            type = secrets_singleton[\"connections\"][name][\"type\"]\n\n    # type is a nice kwarg name for the st.connection user but is annoying to work with\n    # since it conflicts with the builtin function name and thus gets syntax\n    # highlighted.\n    connection_class = type\n\n    if isinstance(connection_class, str):\n        # We assume that a connection_class specified via string is either the fully\n        # qualified name of a class (its module and exported classname) or the string\n        # literal shorthand for one of our first party connections. In the former case,\n        # connection_class will always contain a \".\" in its name.\n        if \".\" in connection_class:\n            parts = connection_class.split(\".\")\n            classname = parts.pop()\n\n            import importlib\n\n            connection_module = importlib.import_module(\".\".join(parts))\n            connection_class = getattr(connection_module, classname)\n        else:\n            connection_class = _get_first_party_connection(connection_class)\n\n    # At this point, connection_class should be of type Type[ConnectionClass].\n    try:\n        conn = _create_connection(\n            name, connection_class, max_entries=max_entries, ttl=ttl, **kwargs\n        )\n        if isinstance(conn, SnowparkConnection):\n            conn = deprecate_obj_name(\n                conn,\n                'connection(\"snowpark\")',\n                'connection(\"snowflake\")',\n                \"2024-04-01\",\n            )\n        return conn\n    except ModuleNotFoundError as e:\n        err_string = str(e)\n        missing_module = re.search(MODULE_EXTRACTION_REGEX, err_string)\n\n        extra_info = \"You may be missing a dependency required to use this connection.\"\n        if missing_module:\n            pypi_package = MODULES_TO_PYPI_PACKAGES.get(missing_module.group(1))\n            if pypi_package:\n                extra_info = f\"You need to install the '{pypi_package}' package to use this connection.\"\n\n        raise ModuleNotFoundError(f\"{str(e)}. {extra_info}\")\n", "lib/streamlit/runtime/credentials.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Manage the user's Streamlit credentials.\"\"\"\n\nfrom __future__ import annotations\n\nimport json\nimport os\nimport sys\nimport textwrap\nfrom datetime import datetime\nfrom typing import Final, NamedTuple, NoReturn\nfrom uuid import uuid4\n\nfrom streamlit import cli_util, env_util, file_util, util\nfrom streamlit.logger import get_logger\n\n_LOGGER: Final = get_logger(__name__)\n\n\nif env_util.IS_WINDOWS:\n    _CONFIG_FILE_PATH = r\"%userprofile%/.streamlit/config.toml\"\nelse:\n    _CONFIG_FILE_PATH = \"~/.streamlit/config.toml\"\n\n\nclass _Activation(NamedTuple):\n    email: str | None  # the user's email.\n    is_valid: bool  # whether the email is valid.\n\n\ndef email_prompt() -> str:\n    # Emoji can cause encoding errors on non-UTF-8 terminals\n    # (See https://github.com/streamlit/streamlit/issues/2284.)\n    # WT_SESSION is a Windows Terminal specific environment variable. If it exists,\n    # we are on the latest Windows Terminal that supports emojis\n    show_emoji = sys.stdout.encoding == \"utf-8\" and (\n        not env_util.IS_WINDOWS or os.environ.get(\"WT_SESSION\")\n    )\n\n    # IMPORTANT: Break the text below at 80 chars.\n    return f\"\"\"\n      {\"\ud83d\udc4b \" if show_emoji else \"\"}{cli_util.style_for_cli(\"Welcome to Streamlit!\", bold=True)}\n\n      If you\u2019d like to receive helpful onboarding emails, news, offers, promotions,\n      and the occasional swag, please enter your email address below. Otherwise,\n      leave this field blank.\n\n      {cli_util.style_for_cli(\"Email: \", fg=\"blue\")}\"\"\"\n\n\n_TELEMETRY_HEADLESS_TEXT = \"\"\"\nCollecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n\"\"\"\n\n\ndef _send_email(email: str) -> None:\n    \"\"\"Send the user's email to segment.io, if submitted\"\"\"\n    import requests\n\n    if email is None or \"@\" not in email:\n        return\n\n    headers = {\n        \"authority\": \"api.segment.io\",\n        \"accept\": \"*/*\",\n        \"accept-language\": \"en-US,en;q=0.9\",\n        \"content-type\": \"text/plain\",\n        \"origin\": \"localhost:8501\",\n        \"referer\": \"localhost:8501/\",\n    }\n\n    dt = datetime.utcnow().isoformat() + \"+00:00\"\n\n    data = {\n        \"anonymous_id\": None,\n        \"context\": {\n            \"library\": {\"name\": \"analytics-python\", \"version\": \"2.2.2\"},\n        },\n        \"messageId\": str(uuid4()),\n        \"timestamp\": dt,\n        \"event\": \"submittedEmail\",\n        \"traits\": {\n            \"authoremail\": email,\n            \"source\": \"provided_email\",\n        },\n        \"type\": \"track\",\n        \"userId\": email,\n        \"writeKey\": \"iCkMy7ymtJ9qYzQRXkQpnAJEq7D4NyMU\",\n    }\n\n    response = requests.post(\n        \"https://api.segment.io/v1/t\",\n        headers=headers,\n        data=json.dumps(data).encode(),\n    )\n\n    response.raise_for_status()\n\n\nclass Credentials:\n    \"\"\"Credentials class.\"\"\"\n\n    _singleton: Credentials | None = None\n\n    @classmethod\n    def get_current(cls):\n        \"\"\"Return the singleton instance.\"\"\"\n        if cls._singleton is None:\n            Credentials()\n\n        return Credentials._singleton\n\n    def __init__(self):\n        \"\"\"Initialize class.\"\"\"\n        if Credentials._singleton is not None:\n            raise RuntimeError(\n                \"Credentials already initialized. Use .get_current() instead\"\n            )\n\n        self.activation = None\n        self._conf_file = _get_credential_file_path()\n\n        Credentials._singleton = self\n\n    def __repr__(self) -> str:\n        return util.repr_(self)\n\n    def load(self, auto_resolve: bool = False) -> None:\n        \"\"\"Load from toml file.\"\"\"\n        if self.activation is not None:\n            _LOGGER.error(\"Credentials already loaded. Not rereading file.\")\n            return\n\n        import toml\n\n        try:\n            with open(self._conf_file) as f:\n                data = toml.load(f).get(\"general\")\n            if data is None:\n                raise Exception\n            self.activation = _verify_email(data.get(\"email\"))\n        except FileNotFoundError:\n            if auto_resolve:\n                self.activate(show_instructions=not auto_resolve)\n                return\n            raise RuntimeError(\n                'Credentials not found. Please run \"streamlit activate\".'\n            )\n        except Exception:\n            if auto_resolve:\n                self.reset()\n                self.activate(show_instructions=not auto_resolve)\n                return\n            raise Exception(\n                textwrap.dedent(\n                    \"\"\"\n                Unable to load credentials from %s.\n                Run \"streamlit reset\" and try again.\n                \"\"\"\n                )\n                % (self._conf_file)\n            )\n\n    def _check_activated(self, auto_resolve: bool = True) -> None:\n        \"\"\"Check if streamlit is activated.\n\n        Used by `streamlit run script.py`\n        \"\"\"\n        try:\n            self.load(auto_resolve)\n        except (Exception, RuntimeError) as e:\n            _exit(str(e))\n\n        if self.activation is None or not self.activation.is_valid:\n            _exit(\"Activation email not valid.\")\n\n    @classmethod\n    def reset(cls) -> None:\n        \"\"\"Reset credentials by removing file.\n\n        This is used by `streamlit activate reset` in case a user wants\n        to start over.\n        \"\"\"\n        c = Credentials.get_current()\n        c.activation = None\n\n        try:\n            os.remove(c._conf_file)\n        except OSError as e:\n            _LOGGER.error(\"Error removing credentials file: %s\" % e)\n\n    def save(self) -> None:\n        \"\"\"Save to toml file and send email.\"\"\"\n        from requests.exceptions import RequestException\n\n        if self.activation is None:\n            return\n\n        # Create intermediate directories if necessary\n        os.makedirs(os.path.dirname(self._conf_file), exist_ok=True)\n\n        # Write the file\n        data = {\"email\": self.activation.email}\n\n        import toml\n\n        with open(self._conf_file, \"w\") as f:\n            toml.dump({\"general\": data}, f)\n\n        try:\n            _send_email(self.activation.email)\n        except RequestException as e:\n            _LOGGER.error(f\"Error saving email: {e}\")\n\n    def activate(self, show_instructions: bool = True) -> None:\n        \"\"\"Activate Streamlit.\n\n        Used by `streamlit activate`.\n        \"\"\"\n        try:\n            self.load()\n        except RuntimeError:\n            # Runtime Error is raised if credentials file is not found. In that case,\n            # `self.activation` is None and we will show the activation prompt below.\n            pass\n\n        if self.activation:\n            if self.activation.is_valid:\n                _exit(\"Already activated\")\n            else:\n                _exit(\n                    \"Activation not valid. Please run \"\n                    \"`streamlit activate reset` then `streamlit activate`\"\n                )\n        else:\n            activated = False\n\n            while not activated:\n                import click\n\n                email = click.prompt(\n                    text=email_prompt(),\n                    prompt_suffix=\"\",\n                    default=\"\",\n                    show_default=False,\n                )\n\n                self.activation = _verify_email(email)\n                if self.activation.is_valid:\n                    self.save()\n                    # IMPORTANT: Break the text below at 80 chars.\n                    TELEMETRY_TEXT = \"\"\"\n  You can find our privacy policy at %(link)s\n\n  Summary:\n  - This open source library collects usage statistics.\n  - We cannot see and do not store information contained inside Streamlit apps,\n    such as text, charts, images, etc.\n  - Telemetry data is stored in servers in the United States.\n  - If you'd like to opt out, add the following to %(config)s,\n    creating that file if necessary:\n\n    [browser]\n    gatherUsageStats = false\n\"\"\" % {\n                        \"link\": cli_util.style_for_cli(\n                            \"https://streamlit.io/privacy-policy\", underline=True\n                        ),\n                        \"config\": cli_util.style_for_cli(_CONFIG_FILE_PATH),\n                    }\n\n                    cli_util.print_to_cli(TELEMETRY_TEXT)\n                    if show_instructions:\n                        # IMPORTANT: Break the text below at 80 chars.\n                        INSTRUCTIONS_TEXT = \"\"\"\n  %(start)s\n  %(prompt)s %(hello)s\n\"\"\" % {\n                            \"start\": cli_util.style_for_cli(\n                                \"Get started by typing:\", fg=\"blue\", bold=True\n                            ),\n                            \"prompt\": cli_util.style_for_cli(\"$\", fg=\"blue\"),\n                            \"hello\": cli_util.style_for_cli(\n                                \"streamlit hello\", bold=True\n                            ),\n                        }\n\n                        cli_util.print_to_cli(INSTRUCTIONS_TEXT)\n                    activated = True\n                else:  # pragma: nocover\n                    _LOGGER.error(\"Please try again.\")\n\n\ndef _verify_email(email: str) -> _Activation:\n    \"\"\"Verify the user's email address.\n\n    The email can either be an empty string (if the user chooses not to enter\n    it), or a string with a single '@' somewhere in it.\n\n    Parameters\n    ----------\n    email : str\n\n    Returns\n    -------\n    _Activation\n        An _Activation object. Its 'is_valid' property will be True only if\n        the email was validated.\n\n    \"\"\"\n    email = email.strip()\n\n    # We deliberately use simple email validation here\n    # since we do not use email address anywhere to send emails.\n    if len(email) > 0 and email.count(\"@\") != 1:\n        _LOGGER.error(\"That doesn't look like an email :(\")\n        return _Activation(None, False)\n\n    return _Activation(email, True)\n\n\ndef _exit(message: str) -> NoReturn:\n    \"\"\"Exit program with error.\"\"\"\n    _LOGGER.error(message)\n    sys.exit(-1)\n\n\ndef _get_credential_file_path() -> str:\n    return file_util.get_streamlit_file_path(\"credentials.toml\")\n\n\ndef _check_credential_file_exists() -> bool:\n    return os.path.exists(_get_credential_file_path())\n\n\ndef check_credentials() -> None:\n    \"\"\"Check credentials and potentially activate.\n\n    Note\n    ----\n    If there is no credential file and we are in headless mode, we should not\n    check, since credential would be automatically set to an empty string.\n\n    \"\"\"\n    from streamlit import config\n\n    if not _check_credential_file_exists() and config.get_option(\"server.headless\"):\n        if not config.is_manually_set(\"browser.gatherUsageStats\"):\n            # If not manually defined, show short message about usage stats gathering.\n            cli_util.print_to_cli(_TELEMETRY_HEADLESS_TEXT)\n        return\n    Credentials.get_current()._check_activated()\n", "lib/streamlit/runtime/secrets.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport os\nimport threading\nfrom copy import deepcopy\nfrom typing import (\n    Any,\n    Final,\n    ItemsView,\n    Iterator,\n    KeysView,\n    Mapping,\n    NoReturn,\n    ValuesView,\n)\n\nfrom blinker import Signal\n\nimport streamlit as st\nimport streamlit.watcher.path_watcher\nfrom streamlit import file_util, runtime\nfrom streamlit.logger import get_logger\n\n_LOGGER: Final = get_logger(__name__)\nSECRETS_FILE_LOCS: Final[list[str]] = [\n    file_util.get_streamlit_file_path(\"secrets.toml\"),\n    # NOTE: The order here is important! Project-level secrets should overwrite global\n    # secrets.\n    file_util.get_project_streamlit_file_path(\"secrets.toml\"),\n]\n\n\ndef _convert_to_dict(obj: Mapping[str, Any] | AttrDict) -> dict[str, Any]:\n    \"\"\"Convert Mapping or AttrDict objects to dictionaries.\"\"\"\n    if isinstance(obj, AttrDict):\n        return obj.to_dict()\n    return {k: v.to_dict() if isinstance(v, AttrDict) else v for k, v in obj.items()}\n\n\ndef _missing_attr_error_message(attr_name: str) -> str:\n    return (\n        f'st.secrets has no attribute \"{attr_name}\". '\n        f\"Did you forget to add it to secrets.toml or the app settings on Streamlit Cloud? \"\n        f\"More info: https://docs.streamlit.io/deploy/streamlit-community-cloud/deploy-your-app/secrets-management\"\n    )\n\n\ndef _missing_key_error_message(key: str) -> str:\n    return (\n        f'st.secrets has no key \"{key}\". '\n        f\"Did you forget to add it to secrets.toml or the app settings on Streamlit Cloud? \"\n        f\"More info: https://docs.streamlit.io/deploy/streamlit-community-cloud/deploy-your-app/secrets-management\"\n    )\n\n\nclass AttrDict(Mapping[str, Any]):\n    \"\"\"\n    We use AttrDict to wrap up dictionary values from secrets\n    to provide dot access to nested secrets\n    \"\"\"\n\n    def __init__(self, value):\n        self.__dict__[\"__nested_secrets__\"] = dict(value)\n\n    @staticmethod\n    def _maybe_wrap_in_attr_dict(value) -> Any:\n        if not isinstance(value, Mapping):\n            return value\n        else:\n            return AttrDict(value)\n\n    def __len__(self) -> int:\n        return len(self.__nested_secrets__)\n\n    def __iter__(self) -> Iterator[str]:\n        return iter(self.__nested_secrets__)\n\n    def __getitem__(self, key: str) -> Any:\n        try:\n            value = self.__nested_secrets__[key]\n            return self._maybe_wrap_in_attr_dict(value)\n        except KeyError:\n            raise KeyError(_missing_key_error_message(key))\n\n    def __getattr__(self, attr_name: str) -> Any:\n        try:\n            value = self.__nested_secrets__[attr_name]\n            return self._maybe_wrap_in_attr_dict(value)\n        except KeyError:\n            raise AttributeError(_missing_attr_error_message(attr_name))\n\n    def __repr__(self):\n        return repr(self.__nested_secrets__)\n\n    def __setitem__(self, key, value) -> NoReturn:\n        raise TypeError(\"Secrets does not support item assignment.\")\n\n    def __setattr__(self, key, value) -> NoReturn:\n        raise TypeError(\"Secrets does not support attribute assignment.\")\n\n    def to_dict(self) -> dict[str, Any]:\n        return deepcopy(self.__nested_secrets__)\n\n\nclass Secrets(Mapping[str, Any]):\n    \"\"\"A dict-like class that stores secrets.\n    Parses secrets.toml on-demand. Cannot be externally mutated.\n\n    Safe to use from multiple threads.\n    \"\"\"\n\n    def __init__(self, file_paths: list[str]):\n        # Our secrets dict.\n        self._secrets: Mapping[str, Any] | None = None\n        self._lock = threading.RLock()\n        self._file_watchers_installed = False\n        self._file_paths = file_paths\n\n        self.file_change_listener = Signal(\n            doc=\"Emitted when a `secrets.toml` file has been changed.\"\n        )\n\n    def load_if_toml_exists(self) -> bool:\n        \"\"\"Load secrets.toml files from disk if they exists. If none exist,\n        no exception will be raised. (If a file exists but is malformed,\n        an exception *will* be raised.)\n\n        Returns True if a secrets.toml file was successfully parsed, False otherwise.\n\n        Thread-safe.\n        \"\"\"\n        try:\n            self._parse(print_exceptions=False)\n            return True\n        except FileNotFoundError:\n            # No secrets.toml files exist. That's fine.\n            return False\n\n    def _reset(self) -> None:\n        \"\"\"Clear the secrets dictionary and remove any secrets that were\n        added to os.environ.\n\n        Thread-safe.\n        \"\"\"\n        with self._lock:\n            if self._secrets is None:\n                return\n\n            for k, v in self._secrets.items():\n                self._maybe_delete_environment_variable(k, v)\n            self._secrets = None\n\n    def _parse(self, print_exceptions: bool) -> Mapping[str, Any]:\n        \"\"\"Parse our secrets.toml files if they're not already parsed.\n        This function is safe to call from multiple threads.\n\n        Parameters\n        ----------\n        print_exceptions : bool\n            If True, then exceptions will be printed with `st.error` before\n            being re-raised.\n\n        Raises\n        ------\n        FileNotFoundError\n            Raised if secrets.toml doesn't exist.\n\n        \"\"\"\n        # Avoid taking a lock for the common case where secrets are already\n        # loaded.\n        secrets = self._secrets\n        if secrets is not None:\n            return secrets\n\n        with self._lock:\n            if self._secrets is not None:\n                return self._secrets\n\n            # It's fine for a user to only have one secrets.toml file defined, so\n            # we ignore individual FileNotFoundErrors when attempting to read files\n            # below and only raise an exception if we weren't able read *any* secrets\n            # file.\n            found_secrets_file = False\n            secrets = {}\n\n            for path in self._file_paths:\n                try:\n                    with open(path, encoding=\"utf-8\") as f:\n                        secrets_file_str = f.read()\n                    found_secrets_file = True\n                except FileNotFoundError:\n                    continue\n\n                try:\n                    import toml\n\n                    secrets.update(toml.loads(secrets_file_str))\n                except:\n                    if print_exceptions:\n                        st.error(f\"Error parsing secrets file at {path}\")\n                    raise\n\n            if not found_secrets_file:\n                err_msg = f\"No secrets files found. Valid paths for a secrets.toml file are: {', '.join(self._file_paths)}\"\n                if print_exceptions:\n                    st.error(err_msg)\n                raise FileNotFoundError(err_msg)\n\n            if len([p for p in self._file_paths if os.path.exists(p)]) > 1:\n                _LOGGER.info(\n                    f\"Secrets found in multiple locations: {', '.join(self._file_paths)}. \"\n                    \"When multiple secret.toml files exist, local secrets will take precedence over global secrets.\"\n                )\n\n            for k, v in secrets.items():\n                self._maybe_set_environment_variable(k, v)\n\n            self._secrets = secrets\n            self._maybe_install_file_watchers()\n\n            return self._secrets\n\n    def to_dict(self) -> dict[str, Any]:\n        \"\"\"Converts the secrets store into a nested dictionary, where nested AttrDict objects are also converted into dictionaries.\"\"\"\n        secrets = self._parse(True)\n        return _convert_to_dict(secrets)\n\n    @staticmethod\n    def _maybe_set_environment_variable(k: Any, v: Any) -> None:\n        \"\"\"Add the given key/value pair to os.environ if the value\n        is a string, int, or float.\n        \"\"\"\n        value_type = type(v)\n        if value_type in (str, int, float):\n            os.environ[k] = str(v)\n\n    @staticmethod\n    def _maybe_delete_environment_variable(k: Any, v: Any) -> None:\n        \"\"\"Remove the given key/value pair from os.environ if the value\n        is a string, int, or float.\n        \"\"\"\n        value_type = type(v)\n        if value_type in (str, int, float) and os.environ.get(k) == v:\n            del os.environ[k]\n\n    def _maybe_install_file_watchers(self) -> None:\n        with self._lock:\n            if self._file_watchers_installed:\n                return\n\n            for path in self._file_paths:\n                try:\n                    streamlit.watcher.path_watcher.watch_file(\n                        path,\n                        self._on_secrets_file_changed,\n                        watcher_type=\"poll\",\n                    )\n                except FileNotFoundError:\n                    # A user may only have one secrets.toml file defined, so we'd expect\n                    # FileNotFoundErrors to be raised when attempting to install a\n                    # watcher on the nonexistent ones.\n                    pass\n\n            # We set file_watchers_installed to True even if the installation attempt\n            # failed to avoid repeatedly trying to install it.\n            self._file_watchers_installed = True\n\n    def _on_secrets_file_changed(self, changed_file_path) -> None:\n        with self._lock:\n            _LOGGER.debug(\"Secrets file %s changed, reloading\", changed_file_path)\n            self._reset()\n            self._parse(print_exceptions=True)\n\n        # Emit a signal to notify receivers that the `secrets.toml` file\n        # has been changed.\n        self.file_change_listener.send()\n\n    def __getattr__(self, key: str) -> Any:\n        \"\"\"Return the value with the given key. If no such key\n        exists, raise an AttributeError.\n\n        Thread-safe.\n        \"\"\"\n        try:\n            value = self._parse(True)[key]\n            if not isinstance(value, Mapping):\n                return value\n            else:\n                return AttrDict(value)\n        # We add FileNotFoundError since __getattr__ is expected to only raise\n        # AttributeError. Without handling FileNotFoundError, unittests.mocks\n        # fails during mock creation on Python3.9\n        except (KeyError, FileNotFoundError):\n            raise AttributeError(_missing_attr_error_message(key))\n\n    def __getitem__(self, key: str) -> Any:\n        \"\"\"Return the value with the given key. If no such key\n        exists, raise a KeyError.\n\n        Thread-safe.\n        \"\"\"\n        try:\n            value = self._parse(True)[key]\n            if not isinstance(value, Mapping):\n                return value\n            else:\n                return AttrDict(value)\n        except KeyError:\n            raise KeyError(_missing_key_error_message(key))\n\n    def __repr__(self) -> str:\n        # If the runtime is NOT initialized, it is a method call outside\n        # the streamlit app, so we avoid reading the secrets file as it may not exist.\n        # If the runtime is initialized, display the contents of the file and\n        # the file must already exist.\n        \"\"\"A string representation of the contents of the dict. Thread-safe.\"\"\"\n        if not runtime.exists():\n            return f\"{self.__class__.__name__}(file_paths={self._file_paths!r})\"\n        return repr(self._parse(True))\n\n    def __len__(self) -> int:\n        \"\"\"The number of entries in the dict. Thread-safe.\"\"\"\n        return len(self._parse(True))\n\n    def has_key(self, k: str) -> bool:\n        \"\"\"True if the given key is in the dict. Thread-safe.\"\"\"\n        return k in self._parse(True)\n\n    def keys(self) -> KeysView[str]:\n        \"\"\"A view of the keys in the dict. Thread-safe.\"\"\"\n        return self._parse(True).keys()\n\n    def values(self) -> ValuesView[Any]:\n        \"\"\"A view of the values in the dict. Thread-safe.\"\"\"\n        return self._parse(True).values()\n\n    def items(self) -> ItemsView[str, Any]:\n        \"\"\"A view of the key-value items in the dict. Thread-safe.\"\"\"\n        return self._parse(True).items()\n\n    def __contains__(self, key: Any) -> bool:\n        \"\"\"True if the given key is in the dict. Thread-safe.\"\"\"\n        return key in self._parse(True)\n\n    def __iter__(self) -> Iterator[str]:\n        \"\"\"An iterator over the keys in the dict. Thread-safe.\"\"\"\n        return iter(self._parse(True))\n\n\nsecrets_singleton: Final = Secrets(SECRETS_FILE_LOCS)\n", "lib/streamlit/runtime/forward_msg_queue.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom typing import TYPE_CHECKING, Any\n\nfrom streamlit.proto.ForwardMsg_pb2 import ForwardMsg\n\nif TYPE_CHECKING:\n    from streamlit.proto.Delta_pb2 import Delta\n\n\nclass ForwardMsgQueue:\n    \"\"\"Accumulates a session's outgoing ForwardMsgs.\n\n    Each AppSession adds messages to its queue, and the Server periodically\n    flushes all session queues and delivers their messages to the appropriate\n    clients.\n\n    ForwardMsgQueue is not thread-safe - a queue should only be used from\n    a single thread.\n    \"\"\"\n\n    def __init__(self):\n        self._queue: list[ForwardMsg] = []\n        # A mapping of (delta_path -> _queue.indexof(msg)) for each\n        # Delta message in the queue. We use this for coalescing\n        # redundant outgoing Deltas (where a newer Delta supersedes\n        # an older Delta, with the same delta_path, that's still in the\n        # queue).\n        self._delta_index_map: dict[tuple[int, ...], int] = {}\n\n    def get_debug(self) -> dict[str, Any]:\n        from google.protobuf.json_format import MessageToDict\n\n        return {\n            \"queue\": [MessageToDict(m) for m in self._queue],\n            \"ids\": list(self._delta_index_map.keys()),\n        }\n\n    def is_empty(self) -> bool:\n        return len(self._queue) == 0\n\n    def enqueue(self, msg: ForwardMsg) -> None:\n        \"\"\"Add message into queue, possibly composing it with another message.\"\"\"\n        if not _is_composable_message(msg):\n            self._queue.append(msg)\n            return\n\n        # If there's a Delta message with the same delta_path already in\n        # the queue - meaning that it refers to the same location in\n        # the app - we attempt to combine this new Delta into the old\n        # one. This is an optimization that prevents redundant Deltas\n        # from being sent to the frontend.\n        delta_key = tuple(msg.metadata.delta_path)\n        if delta_key in self._delta_index_map:\n            index = self._delta_index_map[delta_key]\n            old_msg = self._queue[index]\n            composed_delta = _maybe_compose_deltas(old_msg.delta, msg.delta)\n            if composed_delta is not None:\n                new_msg = ForwardMsg()\n                new_msg.delta.CopyFrom(composed_delta)\n                new_msg.metadata.CopyFrom(msg.metadata)\n                self._queue[index] = new_msg\n                return\n\n        # No composition occurred. Append this message to the queue, and\n        # store its index for potential future composition.\n        self._delta_index_map[delta_key] = len(self._queue)\n        self._queue.append(msg)\n\n    def clear(self, retain_lifecycle_msgs: bool = False) -> None:\n        \"\"\"Clear the queue, potentially retaining lifecycle messages.\n\n        The retain_lifecycle_msgs argument exists because in some cases (in particular\n        when a currently running script is interrupted by a new BackMsg), we don't want\n        to remove certain messages from the queue as doing so may cause the client to\n        not hear about important script lifecycle events (such as the script being\n        stopped early in order to be rerun).\n        \"\"\"\n        if not retain_lifecycle_msgs:\n            self._queue = []\n        else:\n            self._queue = [\n                msg\n                for msg in self._queue\n                if msg.WhichOneof(\"type\")\n                in {\n                    \"script_finished\",\n                    \"session_status_changed\",\n                    \"parent_message\",\n                }\n            ]\n\n        self._delta_index_map = {}\n\n    def flush(self) -> list[ForwardMsg]:\n        \"\"\"Clear the queue and return a list of the messages it contained\n        before being cleared.\n        \"\"\"\n        queue = self._queue\n        self.clear()\n        return queue\n\n    def __len__(self) -> int:\n        return len(self._queue)\n\n\ndef _is_composable_message(msg: ForwardMsg) -> bool:\n    \"\"\"True if the ForwardMsg is potentially composable with other ForwardMsgs.\"\"\"\n    if not msg.HasField(\"delta\"):\n        # Non-delta messages are never composable.\n        return False\n\n    # We never compose add_rows messages in Python, because the add_rows\n    # operation can raise errors, and we don't have a good way of handling\n    # those errors in the message queue.\n    delta_type = msg.delta.WhichOneof(\"type\")\n    return delta_type != \"add_rows\" and delta_type != \"arrow_add_rows\"\n\n\ndef _maybe_compose_deltas(old_delta: Delta, new_delta: Delta) -> Delta | None:\n    \"\"\"Combines new_delta onto old_delta if possible.\n\n    If the combination takes place, the function returns a new Delta that\n    should replace old_delta in the queue.\n\n    If the new_delta is incompatible with old_delta, the function returns None.\n    In this case, the new_delta should just be appended to the queue as normal.\n    \"\"\"\n    old_delta_type = old_delta.WhichOneof(\"type\")\n    if old_delta_type == \"add_block\":\n        # We never replace add_block deltas, because blocks can have\n        # other dependent deltas later in the queue. For example:\n        #\n        #   placeholder = st.empty()\n        #   placeholder.columns(1)\n        #   placeholder.empty()\n        #\n        # The call to \"placeholder.columns(1)\" creates two blocks, a parent\n        # container with delta_path (0, 0), and a column child with\n        # delta_path (0, 0, 0). If the final \"placeholder.empty()\" Delta\n        # is composed with the parent container Delta, the frontend will\n        # throw an error when it tries to add that column child to what is\n        # now just an element, and not a block.\n        return None\n\n    new_delta_type = new_delta.WhichOneof(\"type\")\n    if new_delta_type == \"new_element\":\n        return new_delta\n\n    if new_delta_type == \"add_block\":\n        return new_delta\n\n    return None\n", "lib/streamlit/runtime/app_session.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport asyncio\nimport sys\nimport uuid\nfrom enum import Enum\nfrom typing import TYPE_CHECKING, Callable, Final\n\nimport streamlit.elements.exception as exception_utils\nfrom streamlit import config, runtime\nfrom streamlit.case_converters import to_snake_case\nfrom streamlit.logger import get_logger\nfrom streamlit.proto.ClientState_pb2 import ClientState\nfrom streamlit.proto.Common_pb2 import FileURLs, FileURLsRequest\nfrom streamlit.proto.ForwardMsg_pb2 import ForwardMsg\nfrom streamlit.proto.GitInfo_pb2 import GitInfo\nfrom streamlit.proto.NewSession_pb2 import (\n    Config,\n    CustomThemeConfig,\n    NewSession,\n    UserInfo,\n)\nfrom streamlit.runtime import caching\nfrom streamlit.runtime.forward_msg_queue import ForwardMsgQueue\nfrom streamlit.runtime.fragment import FragmentStorage, MemoryFragmentStorage\nfrom streamlit.runtime.metrics_util import Installation\nfrom streamlit.runtime.pages_manager import PagesManager\nfrom streamlit.runtime.scriptrunner import RerunData, ScriptRunner, ScriptRunnerEvent\nfrom streamlit.runtime.secrets import secrets_singleton\nfrom streamlit.version import STREAMLIT_VERSION_STRING\nfrom streamlit.watcher import LocalSourcesWatcher\n\nif TYPE_CHECKING:\n    from streamlit.proto.BackMsg_pb2 import BackMsg\n    from streamlit.proto.PagesChanged_pb2 import PagesChanged\n    from streamlit.runtime.script_data import ScriptData\n    from streamlit.runtime.scriptrunner.script_cache import ScriptCache\n    from streamlit.runtime.state import SessionState\n    from streamlit.runtime.uploaded_file_manager import UploadedFileManager\n    from streamlit.source_util import PageHash, PageInfo\n\n_LOGGER: Final = get_logger(__name__)\n\n\nclass AppSessionState(Enum):\n    APP_NOT_RUNNING = \"APP_NOT_RUNNING\"\n    APP_IS_RUNNING = \"APP_IS_RUNNING\"\n    SHUTDOWN_REQUESTED = \"SHUTDOWN_REQUESTED\"\n\n\ndef _generate_scriptrun_id() -> str:\n    \"\"\"Randomly generate a unique ID for a script execution.\"\"\"\n    return str(uuid.uuid4())\n\n\nclass AppSession:\n    \"\"\"\n    Contains session data for a single \"user\" of an active app\n    (that is, a connected browser tab).\n\n    Each AppSession has its own ScriptData, root DeltaGenerator, ScriptRunner,\n    and widget state.\n\n    An AppSession is attached to each thread involved in running its script.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        script_data: ScriptData,\n        uploaded_file_manager: UploadedFileManager,\n        script_cache: ScriptCache,\n        message_enqueued_callback: Callable[[], None] | None,\n        user_info: dict[str, str | None],\n        session_id_override: str | None = None,\n    ) -> None:\n        \"\"\"Initialize the AppSession.\n\n        Parameters\n        ----------\n        script_data\n            Object storing parameters related to running a script\n\n        uploaded_file_manager\n            Used to manage files uploaded by users via the Streamlit web client.\n\n        script_cache\n            The app's ScriptCache instance. Stores cached user scripts. ScriptRunner\n            uses the ScriptCache to avoid having to reload user scripts from disk\n            on each rerun.\n\n        message_enqueued_callback\n            After enqueuing a message, this callable notification will be invoked.\n\n        user_info\n            A dict that contains information about the current user. For now,\n            it only contains the user's email address.\n\n            {\n                \"email\": \"example@example.com\"\n            }\n\n            Information about the current user is optionally provided when a\n            websocket connection is initialized via the \"X-Streamlit-User\" header.\n\n        session_id_override\n            The ID to assign to this session. Setting this can be useful when the\n            service that a Streamlit Runtime is running in wants to tie the lifecycle of\n            a Streamlit session to some other session-like object that it manages.\n        \"\"\"\n        # Each AppSession has a unique string ID.\n        self.id = session_id_override or str(uuid.uuid4())\n\n        self._event_loop = asyncio.get_running_loop()\n        self._script_data = script_data\n        self._uploaded_file_mgr = uploaded_file_manager\n        self._script_cache = script_cache\n        self._pages_manager = PagesManager(\n            script_data.main_script_path, self._script_cache\n        )\n\n        # The browser queue contains messages that haven't yet been\n        # delivered to the browser. Periodically, the server flushes\n        # this queue and delivers its contents to the browser.\n        self._browser_queue = ForwardMsgQueue()\n        self._message_enqueued_callback = message_enqueued_callback\n\n        self._state = AppSessionState.APP_NOT_RUNNING\n\n        # Need to remember the client state here because when a script reruns\n        # due to the source code changing we need to pass in the previous client state.\n        self._client_state = ClientState()\n\n        self._local_sources_watcher: LocalSourcesWatcher | None = None\n        self._stop_config_listener: Callable[[], bool] | None = None\n        self._stop_pages_listener: Callable[[], None] | None = None\n\n        if config.get_option(\"server.fileWatcherType\") != \"none\":\n            self.register_file_watchers()\n\n        self._run_on_save = config.get_option(\"server.runOnSave\")\n\n        self._scriptrunner: ScriptRunner | None = None\n\n        # This needs to be lazily imported to avoid a dependency cycle.\n        from streamlit.runtime.state import SessionState\n\n        self._session_state = SessionState()\n        self._user_info = user_info\n\n        self._debug_last_backmsg_id: str | None = None\n\n        self._fragment_storage: FragmentStorage = MemoryFragmentStorage()\n\n        _LOGGER.debug(\"AppSession initialized (id=%s)\", self.id)\n\n    def __del__(self) -> None:\n        \"\"\"Ensure that we call shutdown() when an AppSession is garbage collected.\"\"\"\n        self.shutdown()\n\n    def register_file_watchers(self) -> None:\n        \"\"\"Register handlers to be called when various files are changed.\n\n        Files that we watch include:\n          * source files that already exist (for edits)\n          * `.py` files in the the main script's `pages/` directory (for file additions\n            and deletions)\n          * project and user-level config.toml files\n          * the project-level secrets.toml files\n\n        This method is called automatically on AppSession construction, but it may be\n        called again in the case when a session is disconnected and is being reconnect\n        to.\n        \"\"\"\n        if self._local_sources_watcher is None:\n            self._local_sources_watcher = LocalSourcesWatcher(self._pages_manager)\n\n        self._local_sources_watcher.register_file_change_callback(\n            self._on_source_file_changed\n        )\n        self._stop_config_listener = config.on_config_parsed(\n            self._on_source_file_changed, force_connect=True\n        )\n        self._stop_pages_listener = self._pages_manager.register_pages_changed_callback(\n            self._on_pages_changed\n        )\n        secrets_singleton.file_change_listener.connect(self._on_secrets_file_changed)\n\n    def disconnect_file_watchers(self) -> None:\n        \"\"\"Disconnect the file watcher handlers registered by register_file_watchers.\"\"\"\n        if self._local_sources_watcher is not None:\n            self._local_sources_watcher.close()\n        if self._stop_config_listener is not None:\n            self._stop_config_listener()\n        if self._stop_pages_listener is not None:\n            self._stop_pages_listener()\n\n        secrets_singleton.file_change_listener.disconnect(self._on_secrets_file_changed)\n\n        self._local_sources_watcher = None\n        self._stop_config_listener = None\n        self._stop_pages_listener = None\n\n    def flush_browser_queue(self) -> list[ForwardMsg]:\n        \"\"\"Clear the forward message queue and return the messages it contained.\n\n        The Server calls this periodically to deliver new messages\n        to the browser connected to this app.\n\n        Returns\n        -------\n        list[ForwardMsg]\n            The messages that were removed from the queue and should\n            be delivered to the browser.\n\n        \"\"\"\n        return self._browser_queue.flush()\n\n    def shutdown(self) -> None:\n        \"\"\"Shut down the AppSession.\n\n        It's an error to use a AppSession after it's been shut down.\n\n        \"\"\"\n        if self._state != AppSessionState.SHUTDOWN_REQUESTED:\n            _LOGGER.debug(\"Shutting down (id=%s)\", self.id)\n            # Clear any unused session files in upload file manager and media\n            # file manager\n            self._uploaded_file_mgr.remove_session_files(self.id)\n\n            if runtime.exists():\n                rt = runtime.get_instance()\n                rt.media_file_mgr.clear_session_refs(self.id)\n                rt.media_file_mgr.remove_orphaned_files()\n\n            # Shut down the ScriptRunner, if one is active.\n            # self._state must not be set to SHUTDOWN_REQUESTED until\n            # *after* this is called.\n            self.request_script_stop()\n\n            self._state = AppSessionState.SHUTDOWN_REQUESTED\n\n            # Disconnect all file watchers if we haven't already, although we will have\n            # generally already done so by the time we get here.\n            self.disconnect_file_watchers()\n\n    def _enqueue_forward_msg(self, msg: ForwardMsg) -> None:\n        \"\"\"Enqueue a new ForwardMsg to our browser queue.\n\n        This can be called on both the main thread and a ScriptRunner\n        run thread.\n\n        Parameters\n        ----------\n        msg : ForwardMsg\n            The message to enqueue\n\n        \"\"\"\n        if not config.get_option(\"client.displayEnabled\"):\n            return\n\n        if self._debug_last_backmsg_id:\n            msg.debug_last_backmsg_id = self._debug_last_backmsg_id\n\n        self._browser_queue.enqueue(msg)\n        if self._message_enqueued_callback:\n            self._message_enqueued_callback()\n\n    def handle_backmsg(self, msg: BackMsg) -> None:\n        \"\"\"Process a BackMsg.\"\"\"\n        try:\n            msg_type = msg.WhichOneof(\"type\")\n\n            if msg_type == \"rerun_script\":\n                if msg.debug_last_backmsg_id:\n                    self._debug_last_backmsg_id = msg.debug_last_backmsg_id\n\n                self._handle_rerun_script_request(msg.rerun_script)\n            elif msg_type == \"load_git_info\":\n                self._handle_git_information_request()\n            elif msg_type == \"clear_cache\":\n                self._handle_clear_cache_request()\n            elif msg_type == \"app_heartbeat\":\n                self._handle_app_heartbeat_request()\n            elif msg_type == \"set_run_on_save\":\n                self._handle_set_run_on_save_request(msg.set_run_on_save)\n            elif msg_type == \"stop_script\":\n                self._handle_stop_script_request()\n            elif msg_type == \"file_urls_request\":\n                self._handle_file_urls_request(msg.file_urls_request)\n            else:\n                _LOGGER.warning('No handler for \"%s\"', msg_type)\n\n        except Exception as ex:\n            _LOGGER.error(ex)\n            self.handle_backmsg_exception(ex)\n\n    def handle_backmsg_exception(self, e: BaseException) -> None:\n        \"\"\"Handle an Exception raised while processing a BackMsg from the browser.\"\"\"\n        # This does a few things:\n        # 1) Clears the current app in the browser.\n        # 2) Marks the current app as \"stopped\" in the browser.\n        # 3) HACK: Resets any script params that may have been broken (e.g. the\n        # command-line when rerunning with wrong argv[0])\n\n        self._on_scriptrunner_event(\n            self._scriptrunner, ScriptRunnerEvent.SCRIPT_STOPPED_WITH_SUCCESS\n        )\n        self._on_scriptrunner_event(\n            self._scriptrunner,\n            ScriptRunnerEvent.SCRIPT_STARTED,\n            page_script_hash=\"\",\n        )\n        self._on_scriptrunner_event(\n            self._scriptrunner, ScriptRunnerEvent.SCRIPT_STOPPED_WITH_SUCCESS\n        )\n\n        # Send an Exception message to the frontend.\n        # Because _on_scriptrunner_event does its work in an eventloop callback,\n        # this exception ForwardMsg *must* also be enqueued in a callback,\n        # so that it will be enqueued *after* the various ForwardMsgs that\n        # _on_scriptrunner_event sends.\n        self._event_loop.call_soon_threadsafe(\n            lambda: self._enqueue_forward_msg(self._create_exception_message(e))\n        )\n\n    def request_rerun(self, client_state: ClientState | None) -> None:\n        \"\"\"Signal that we're interested in running the script.\n\n        If the script is not already running, it will be started immediately.\n        Otherwise, a rerun will be requested.\n\n        Parameters\n        ----------\n        client_state : streamlit.proto.ClientState_pb2.ClientState | None\n            The ClientState protobuf to run the script with, or None\n            to use previous client state.\n\n        \"\"\"\n        if self._state == AppSessionState.SHUTDOWN_REQUESTED:\n            _LOGGER.warning(\"Discarding rerun request after shutdown\")\n            return\n\n        if client_state:\n            fragment_id = client_state.fragment_id\n\n            rerun_data = RerunData(\n                client_state.query_string,\n                client_state.widget_states,\n                client_state.page_script_hash,\n                client_state.page_name,\n                fragment_id_queue=[fragment_id] if fragment_id else [],\n            )\n        else:\n            rerun_data = RerunData()\n\n        if self._scriptrunner is not None:\n            if (\n                bool(config.get_option(\"runner.fastReruns\"))\n                and not rerun_data.fragment_id_queue\n            ):\n                # If fastReruns is enabled and this is *not* a rerun of a fragment,\n                # we don't send rerun requests to our existing ScriptRunner. Instead, we\n                # tell it to shut down. We'll then spin up a new ScriptRunner, below, to\n                # handle the rerun immediately.\n                self._scriptrunner.request_stop()\n                self._scriptrunner = None\n            else:\n                # Either fastReruns is not enabled or this RERUN request is a request to\n                # run a fragment. We send our current ScriptRunner a rerun request, and\n                # if it's accepted, we're done.\n                success = self._scriptrunner.request_rerun(rerun_data)\n                if success:\n                    return\n\n        # If we are here, then either we have no ScriptRunner, or our\n        # current ScriptRunner is shutting down and cannot handle a rerun\n        # request - so we'll create and start a new ScriptRunner.\n        self._create_scriptrunner(rerun_data)\n\n    def request_script_stop(self) -> None:\n        \"\"\"Request that the scriptrunner stop execution.\n\n        Does nothing if no scriptrunner exists.\n        \"\"\"\n        if self._scriptrunner is not None:\n            self._scriptrunner.request_stop()\n\n    def _create_scriptrunner(self, initial_rerun_data: RerunData) -> None:\n        \"\"\"Create and run a new ScriptRunner with the given RerunData.\"\"\"\n        self._scriptrunner = ScriptRunner(\n            session_id=self.id,\n            main_script_path=self._script_data.main_script_path,\n            session_state=self._session_state,\n            uploaded_file_mgr=self._uploaded_file_mgr,\n            script_cache=self._script_cache,\n            initial_rerun_data=initial_rerun_data,\n            user_info=self._user_info,\n            fragment_storage=self._fragment_storage,\n            pages_manager=self._pages_manager,\n        )\n        self._scriptrunner.on_event.connect(self._on_scriptrunner_event)\n        self._scriptrunner.start()\n\n    @property\n    def session_state(self) -> SessionState:\n        return self._session_state\n\n    def _should_rerun_on_file_change(self, filepath: str) -> bool:\n        pages = self._pages_manager.get_pages()\n\n        changed_page_script_hash = next(\n            filter(lambda k: pages[k][\"script_path\"] == filepath, pages),\n            None,\n        )\n\n        if changed_page_script_hash is not None:\n            current_page_script_hash = self._client_state.page_script_hash\n            return changed_page_script_hash == current_page_script_hash\n\n        return True\n\n    def _on_source_file_changed(self, filepath: str | None = None) -> None:\n        \"\"\"One of our source files changed. Clear the cache and schedule a rerun if\n        appropriate.\n        \"\"\"\n        self._script_cache.clear()\n\n        if filepath is not None and not self._should_rerun_on_file_change(filepath):\n            return\n\n        if self._run_on_save:\n            self.request_rerun(self._client_state)\n        else:\n            self._enqueue_forward_msg(self._create_file_change_message())\n\n    def _on_secrets_file_changed(self, _) -> None:\n        \"\"\"Called when `secrets.file_change_listener` emits a Signal.\"\"\"\n\n        # NOTE: At the time of writing, this function only calls\n        # `_on_source_file_changed`. The reason behind creating this function instead of\n        # just passing `_on_source_file_changed` to `connect` / `disconnect` directly is\n        # that every function that is passed to `connect` / `disconnect` must have at\n        # least one argument for `sender` (in this case we don't really care about it,\n        # thus `_`), and introducing an unnecessary argument to\n        # `_on_source_file_changed` just for this purpose sounded finicky.\n        self._on_source_file_changed()\n\n    def _on_pages_changed(self, _) -> None:\n        msg = ForwardMsg()\n        self._populate_app_pages(msg.pages_changed, self._pages_manager.get_pages())\n        self._enqueue_forward_msg(msg)\n\n        if self._local_sources_watcher is not None:\n            self._local_sources_watcher.update_watched_pages()\n\n    def _clear_queue(self) -> None:\n        self._browser_queue.clear(retain_lifecycle_msgs=True)\n\n    def _on_scriptrunner_event(\n        self,\n        sender: ScriptRunner | None,\n        event: ScriptRunnerEvent,\n        forward_msg: ForwardMsg | None = None,\n        exception: BaseException | None = None,\n        client_state: ClientState | None = None,\n        page_script_hash: str | None = None,\n        fragment_ids_this_run: set[str] | None = None,\n        pages: dict[PageHash, PageInfo] | None = None,\n    ) -> None:\n        \"\"\"Called when our ScriptRunner emits an event.\n\n        This is generally called from the sender ScriptRunner's script thread.\n        We forward the event on to _handle_scriptrunner_event_on_event_loop,\n        which will be called on the main thread.\n        \"\"\"\n        self._event_loop.call_soon_threadsafe(\n            lambda: self._handle_scriptrunner_event_on_event_loop(\n                sender,\n                event,\n                forward_msg,\n                exception,\n                client_state,\n                page_script_hash,\n                fragment_ids_this_run,\n                pages,\n            )\n        )\n\n    def _handle_scriptrunner_event_on_event_loop(\n        self,\n        sender: ScriptRunner | None,\n        event: ScriptRunnerEvent,\n        forward_msg: ForwardMsg | None = None,\n        exception: BaseException | None = None,\n        client_state: ClientState | None = None,\n        page_script_hash: str | None = None,\n        fragment_ids_this_run: set[str] | None = None,\n        pages: dict[PageHash, PageInfo] | None = None,\n    ) -> None:\n        \"\"\"Handle a ScriptRunner event.\n\n        This function must only be called on our eventloop thread.\n\n        Parameters\n        ----------\n        sender : ScriptRunner | None\n            The ScriptRunner that emitted the event. (This may be set to\n            None when called from `handle_backmsg_exception`, if no\n            ScriptRunner was active when the backmsg exception was raised.)\n\n        event : ScriptRunnerEvent\n            The event type.\n\n        forward_msg : ForwardMsg | None\n            The ForwardMsg to send to the frontend. Set only for the\n            ENQUEUE_FORWARD_MSG event.\n\n        exception : BaseException | None\n            An exception thrown during compilation. Set only for the\n            SCRIPT_STOPPED_WITH_COMPILE_ERROR event.\n\n        client_state : streamlit.proto.ClientState_pb2.ClientState | None\n            The ScriptRunner's final ClientState. Set only for the\n            SHUTDOWN event.\n\n        page_script_hash : str | None\n            A hash of the script path corresponding to the page currently being\n            run. Set only for the SCRIPT_STARTED event.\n\n        fragment_ids_this_run : set[str] | None\n            The fragment IDs of the fragments being executed in this script run. Only\n            set for the SCRIPT_STARTED event. If this value is falsy, this script run\n            must be for the full script.\n        \"\"\"\n\n        assert (\n            self._event_loop == asyncio.get_running_loop()\n        ), \"This function must only be called on the eventloop thread the AppSession was created on.\"\n\n        if sender is not self._scriptrunner:\n            # This event was sent by a non-current ScriptRunner; ignore it.\n            # This can happen after sppinng up a new ScriptRunner (to handle a\n            # rerun request, for example) while another ScriptRunner is still\n            # shutting down. The shutting-down ScriptRunner may still\n            # emit events.\n            _LOGGER.debug(\"Ignoring event from non-current ScriptRunner: %s\", event)\n            return\n\n        prev_state = self._state\n\n        if event == ScriptRunnerEvent.SCRIPT_STARTED:\n            if self._state != AppSessionState.SHUTDOWN_REQUESTED:\n                self._state = AppSessionState.APP_IS_RUNNING\n\n            assert (\n                page_script_hash is not None\n            ), \"page_script_hash must be set for the SCRIPT_STARTED event\"\n\n            # When running the full script, we clear the browser ForwardMsg queue since\n            # anything from a previous script run that has yet to be sent to the browser\n            # will be overwritten. For fragment runs, however, we don't want to do this\n            # as the ForwardMsgs in the queue may not correspond to the running\n            # fragment, so dropping the messages may result in the app missing\n            # information.\n            if not fragment_ids_this_run:\n                self._clear_queue()\n\n            self._enqueue_forward_msg(\n                self._create_new_session_message(\n                    page_script_hash, fragment_ids_this_run, pages\n                )\n            )\n\n        elif (\n            event == ScriptRunnerEvent.SCRIPT_STOPPED_WITH_SUCCESS\n            or event == ScriptRunnerEvent.SCRIPT_STOPPED_WITH_COMPILE_ERROR\n            or event == ScriptRunnerEvent.FRAGMENT_STOPPED_WITH_SUCCESS\n        ):\n            if self._state != AppSessionState.SHUTDOWN_REQUESTED:\n                self._state = AppSessionState.APP_NOT_RUNNING\n\n            if event == ScriptRunnerEvent.SCRIPT_STOPPED_WITH_SUCCESS:\n                status = ForwardMsg.FINISHED_SUCCESSFULLY\n            elif event == ScriptRunnerEvent.FRAGMENT_STOPPED_WITH_SUCCESS:\n                status = ForwardMsg.FINISHED_FRAGMENT_RUN_SUCCESSFULLY\n            else:\n                status = ForwardMsg.FINISHED_WITH_COMPILE_ERROR\n\n            self._enqueue_forward_msg(self._create_script_finished_message(status))\n            self._debug_last_backmsg_id = None\n\n            if (\n                event == ScriptRunnerEvent.SCRIPT_STOPPED_WITH_SUCCESS\n                or event == ScriptRunnerEvent.FRAGMENT_STOPPED_WITH_SUCCESS\n            ):\n                # The script completed successfully: update our\n                # LocalSourcesWatcher to account for any source code changes\n                # that change which modules should be watched.\n                if self._local_sources_watcher:\n                    self._local_sources_watcher.update_watched_modules()\n                    self._local_sources_watcher.update_watched_pages()\n            else:\n                # The script didn't complete successfully: send the exception\n                # to the frontend.\n                assert (\n                    exception is not None\n                ), \"exception must be set for the SCRIPT_STOPPED_WITH_COMPILE_ERROR event\"\n                msg = ForwardMsg()\n                exception_utils.marshall(\n                    msg.session_event.script_compilation_exception, exception\n                )\n                self._enqueue_forward_msg(msg)\n\n        elif event == ScriptRunnerEvent.SCRIPT_STOPPED_FOR_RERUN:\n            self._state = AppSessionState.APP_NOT_RUNNING\n            self._enqueue_forward_msg(\n                self._create_script_finished_message(\n                    ForwardMsg.FINISHED_EARLY_FOR_RERUN\n                )\n            )\n            if self._local_sources_watcher:\n                self._local_sources_watcher.update_watched_modules()\n\n        elif event == ScriptRunnerEvent.SHUTDOWN:\n            assert (\n                client_state is not None\n            ), \"client_state must be set for the SHUTDOWN event\"\n\n            if self._state == AppSessionState.SHUTDOWN_REQUESTED:\n                # Only clear media files if the script is done running AND the\n                # session is actually shutting down.\n                runtime.get_instance().media_file_mgr.clear_session_refs(self.id)\n\n            self._client_state = client_state\n            self._scriptrunner = None\n\n        elif event == ScriptRunnerEvent.ENQUEUE_FORWARD_MSG:\n            assert (\n                forward_msg is not None\n            ), \"null forward_msg in ENQUEUE_FORWARD_MSG event\"\n            self._enqueue_forward_msg(forward_msg)\n\n        # Send a message if our run state changed\n        app_was_running = prev_state == AppSessionState.APP_IS_RUNNING\n        app_is_running = self._state == AppSessionState.APP_IS_RUNNING\n        if app_is_running != app_was_running:\n            self._enqueue_forward_msg(self._create_session_status_changed_message())\n\n    def _create_session_status_changed_message(self) -> ForwardMsg:\n        \"\"\"Create and return a session_status_changed ForwardMsg.\"\"\"\n        msg = ForwardMsg()\n        msg.session_status_changed.run_on_save = self._run_on_save\n        msg.session_status_changed.script_is_running = (\n            self._state == AppSessionState.APP_IS_RUNNING\n        )\n        return msg\n\n    def _create_file_change_message(self) -> ForwardMsg:\n        \"\"\"Create and return a 'script_changed_on_disk' ForwardMsg.\"\"\"\n        msg = ForwardMsg()\n        msg.session_event.script_changed_on_disk = True\n        return msg\n\n    def _create_new_session_message(\n        self,\n        page_script_hash: str,\n        fragment_ids_this_run: set[str] | None = None,\n        pages: dict[PageHash, PageInfo] | None = None,\n    ) -> ForwardMsg:\n        \"\"\"Create and return a new_session ForwardMsg.\"\"\"\n        msg = ForwardMsg()\n\n        msg.new_session.script_run_id = _generate_scriptrun_id()\n        msg.new_session.name = self._script_data.name\n        msg.new_session.main_script_path = self._pages_manager.main_script_path\n        msg.new_session.main_script_hash = self._pages_manager.main_script_hash\n        msg.new_session.page_script_hash = page_script_hash\n\n        if fragment_ids_this_run:\n            msg.new_session.fragment_ids_this_run.extend(fragment_ids_this_run)\n\n        self._populate_app_pages(\n            msg.new_session, pages or self._pages_manager.get_pages()\n        )\n        _populate_config_msg(msg.new_session.config)\n        _populate_theme_msg(msg.new_session.custom_theme)\n\n        # Immutable session data. We send this every time a new session is\n        # started, to avoid having to track whether the client has already\n        # received it. It does not change from run to run; it's up to the\n        # to perform one-time initialization only once.\n        imsg = msg.new_session.initialize\n\n        _populate_user_info_msg(imsg.user_info)\n\n        imsg.environment_info.streamlit_version = STREAMLIT_VERSION_STRING\n        imsg.environment_info.python_version = \".\".join(map(str, sys.version_info))\n\n        imsg.session_status.run_on_save = self._run_on_save\n        imsg.session_status.script_is_running = (\n            self._state == AppSessionState.APP_IS_RUNNING\n        )\n\n        imsg.is_hello = self._script_data.is_hello\n        imsg.session_id = self.id\n\n        return msg\n\n    def _create_script_finished_message(\n        self, status: ForwardMsg.ScriptFinishedStatus.ValueType\n    ) -> ForwardMsg:\n        \"\"\"Create and return a script_finished ForwardMsg.\"\"\"\n        msg = ForwardMsg()\n        msg.script_finished = status\n        return msg\n\n    def _create_exception_message(self, e: BaseException) -> ForwardMsg:\n        \"\"\"Create and return an Exception ForwardMsg.\"\"\"\n        msg = ForwardMsg()\n        exception_utils.marshall(msg.delta.new_element.exception, e)\n        return msg\n\n    def _handle_git_information_request(self) -> None:\n        msg = ForwardMsg()\n\n        try:\n            from streamlit.git_util import GitRepo\n\n            repo = GitRepo(self._script_data.main_script_path)\n\n            repo_info = repo.get_repo_info()\n            if repo_info is None:\n                return\n\n            repository_name, branch, module = repo_info\n\n            if repository_name.endswith(\".git\"):\n                # Remove the .git extension from the repository name\n                repository_name = repository_name[:-4]\n\n            msg.git_info_changed.repository = repository_name\n            msg.git_info_changed.branch = branch\n            msg.git_info_changed.module = module\n\n            msg.git_info_changed.untracked_files[:] = repo.untracked_files\n            msg.git_info_changed.uncommitted_files[:] = repo.uncommitted_files\n\n            if repo.is_head_detached:\n                msg.git_info_changed.state = GitInfo.GitStates.HEAD_DETACHED\n            elif len(repo.ahead_commits) > 0:\n                msg.git_info_changed.state = GitInfo.GitStates.AHEAD_OF_REMOTE\n            else:\n                msg.git_info_changed.state = GitInfo.GitStates.DEFAULT\n\n            self._enqueue_forward_msg(msg)\n        except Exception as ex:\n            # Users may never even install Git in the first place, so this\n            # error requires no action. It can be useful for debugging.\n            _LOGGER.debug(\"Obtaining Git information produced an error\", exc_info=ex)\n\n    def _handle_rerun_script_request(\n        self, client_state: ClientState | None = None\n    ) -> None:\n        \"\"\"Tell the ScriptRunner to re-run its script.\n\n        Parameters\n        ----------\n        client_state : streamlit.proto.ClientState_pb2.ClientState | None\n            The ClientState protobuf to run the script with, or None\n            to use previous client state.\n\n        \"\"\"\n        self.request_rerun(client_state)\n\n    def _handle_stop_script_request(self) -> None:\n        \"\"\"Tell the ScriptRunner to stop running its script.\"\"\"\n        self.request_script_stop()\n\n    def _handle_clear_cache_request(self) -> None:\n        \"\"\"Clear this app's cache.\n\n        Because this cache is global, it will be cleared for all users.\n\n        \"\"\"\n        caching.cache_data.clear()\n        caching.cache_resource.clear()\n        self._session_state.clear()\n\n    def _handle_app_heartbeat_request(self) -> None:\n        \"\"\"Handle an incoming app heartbeat.\n\n        The heartbeat indicates the frontend is active and keeps the\n        websocket from going idle and disconnecting.\n\n        The actual handler here is a noop\n\n        \"\"\"\n        pass\n\n    def _handle_set_run_on_save_request(self, new_value: bool) -> None:\n        \"\"\"Change our run_on_save flag to the given value.\n\n        The browser will be notified of the change.\n\n        Parameters\n        ----------\n        new_value : bool\n            New run_on_save value\n\n        \"\"\"\n        self._run_on_save = new_value\n        self._enqueue_forward_msg(self._create_session_status_changed_message())\n\n    def _handle_file_urls_request(self, file_urls_request: FileURLsRequest) -> None:\n        \"\"\"Handle a file_urls_request BackMsg sent by the client.\"\"\"\n        msg = ForwardMsg()\n        msg.file_urls_response.response_id = file_urls_request.request_id\n\n        upload_url_infos = self._uploaded_file_mgr.get_upload_urls(\n            self.id, file_urls_request.file_names\n        )\n\n        for upload_url_info in upload_url_infos:\n            msg.file_urls_response.file_urls.append(\n                FileURLs(\n                    file_id=upload_url_info.file_id,\n                    upload_url=upload_url_info.upload_url,\n                    delete_url=upload_url_info.delete_url,\n                )\n            )\n\n        self._enqueue_forward_msg(msg)\n\n    def _populate_app_pages(\n        self, msg: NewSession | PagesChanged, pages: dict[PageHash, PageInfo]\n    ) -> None:\n        for page_script_hash, page_info in pages.items():\n            page_proto = msg.app_pages.add()\n\n            page_proto.page_script_hash = page_script_hash\n            page_proto.page_name = page_info[\"page_name\"]\n            page_proto.icon = page_info[\"icon\"]\n\n\n# Config.ToolbarMode.ValueType does not exist at runtime (only in the pyi stubs), so\n# we need to use quotes.\n# This field will be available at runtime as of protobuf 3.20.1, but\n# we are using an older version.\n# For details, see: https://github.com/protocolbuffers/protobuf/issues/8175\ndef _get_toolbar_mode() -> Config.ToolbarMode.ValueType:\n    config_key = \"client.toolbarMode\"\n    config_value = config.get_option(config_key)\n    enum_value: Config.ToolbarMode.ValueType | None = getattr(\n        Config.ToolbarMode, config_value.upper()\n    )\n    if enum_value is None:\n        allowed_values = \", \".join(k.lower() for k in Config.ToolbarMode.keys())\n        raise ValueError(\n            f\"Config {config_key!r} expects to have one of \"\n            f\"the following values: {allowed_values}. \"\n            f\"Current value: {config_value}\"\n        )\n    return enum_value\n\n\ndef _populate_config_msg(msg: Config) -> None:\n    msg.gather_usage_stats = config.get_option(\"browser.gatherUsageStats\")\n    msg.max_cached_message_age = config.get_option(\"global.maxCachedMessageAge\")\n    msg.allow_run_on_save = config.get_option(\"server.allowRunOnSave\")\n    msg.hide_top_bar = config.get_option(\"ui.hideTopBar\")\n    # ui.hideSidebarNav is deprecated, will be removed in the future\n    msg.hide_sidebar_nav = config.get_option(\"ui.hideSidebarNav\")\n    if config.get_option(\"client.showSidebarNavigation\") is False:\n        msg.hide_sidebar_nav = True\n    msg.toolbar_mode = _get_toolbar_mode()\n\n\ndef _populate_theme_msg(msg: CustomThemeConfig) -> None:\n    enum_encoded_options = {\"base\", \"font\"}\n    theme_opts = config.get_options_for_section(\"theme\")\n\n    if not any(theme_opts.values()):\n        return\n\n    for option_name, option_val in theme_opts.items():\n        if option_name not in enum_encoded_options and option_val is not None:\n            setattr(msg, to_snake_case(option_name), option_val)\n\n    # NOTE: If unset, base and font will default to the protobuf enum zero\n    # values, which are BaseTheme.LIGHT and FontFamily.SANS_SERIF,\n    # respectively. This is why we both don't handle the cases explicitly and\n    # also only log a warning when receiving invalid base/font options.\n    base_map = {\n        \"light\": msg.BaseTheme.LIGHT,\n        \"dark\": msg.BaseTheme.DARK,\n    }\n    base = theme_opts[\"base\"]\n    if base is not None:\n        if base not in base_map:\n            _LOGGER.warning(\n                f'\"{base}\" is an invalid value for theme.base.'\n                f\" Allowed values include {list(base_map.keys())}.\"\n                ' Setting theme.base to \"light\".'\n            )\n        else:\n            msg.base = base_map[base]\n\n    font_map = {\n        \"sans serif\": msg.FontFamily.SANS_SERIF,\n        \"serif\": msg.FontFamily.SERIF,\n        \"monospace\": msg.FontFamily.MONOSPACE,\n    }\n    font = theme_opts[\"font\"]\n    if font is not None:\n        if font not in font_map:\n            _LOGGER.warning(\n                f'\"{font}\" is an invalid value for theme.font.'\n                f\" Allowed values include {list(font_map.keys())}.\"\n                ' Setting theme.font to \"sans serif\".'\n            )\n        else:\n            msg.font = font_map[font]\n\n\ndef _populate_user_info_msg(msg: UserInfo) -> None:\n    msg.installation_id = Installation.instance().installation_id\n    msg.installation_id_v3 = Installation.instance().installation_id_v3\n", "lib/streamlit/runtime/__init__.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom streamlit.runtime.runtime import Runtime, RuntimeConfig, RuntimeState\nfrom streamlit.runtime.session_manager import (\n    SessionClient,\n    SessionClientDisconnectedError,\n)\n\n\ndef get_instance() -> Runtime:\n    \"\"\"Return the singleton Runtime instance. Raise an Error if the\n    Runtime hasn't been created yet.\n    \"\"\"\n    return Runtime.instance()\n\n\ndef exists() -> bool:\n    \"\"\"True if the singleton Runtime instance has been created.\n\n    When a Streamlit app is running in \"raw mode\" - that is, when the\n    app is run via `python app.py` instead of `streamlit run app.py` -\n    the Runtime will not exist, and various Streamlit functions need\n    to adapt.\n    \"\"\"\n    return Runtime.exists()\n\n\n__all__ = [\n    \"Runtime\",\n    \"RuntimeConfig\",\n    \"RuntimeState\",\n    \"SessionClient\",\n    \"SessionClientDisconnectedError\",\n    \"get_instance\",\n    \"exists\",\n]\n", "lib/streamlit/runtime/websocket_session_manager.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom typing import TYPE_CHECKING, Callable, Final, List, cast\n\nfrom streamlit.logger import get_logger\nfrom streamlit.runtime.app_session import AppSession\nfrom streamlit.runtime.session_manager import (\n    ActiveSessionInfo,\n    SessionClient,\n    SessionInfo,\n    SessionManager,\n    SessionStorage,\n)\n\nif TYPE_CHECKING:\n    from streamlit.runtime.script_data import ScriptData\n    from streamlit.runtime.scriptrunner.script_cache import ScriptCache\n    from streamlit.runtime.uploaded_file_manager import UploadedFileManager\n\n_LOGGER: Final = get_logger(__name__)\n\n\nclass WebsocketSessionManager(SessionManager):\n    \"\"\"A SessionManager used to manage sessions with lifecycles tied to those of a\n    browser tab's websocket connection.\n\n    WebsocketSessionManagers differentiate between \"active\" and \"inactive\" sessions.\n    Active sessions are those with a currently active websocket connection. Inactive\n    sessions are sessions without. Eventual cleanup of inactive sessions is a detail left\n    to the specific SessionStorage that a WebsocketSessionManager is instantiated with.\n    \"\"\"\n\n    def __init__(\n        self,\n        session_storage: SessionStorage,\n        uploaded_file_manager: UploadedFileManager,\n        script_cache: ScriptCache,\n        message_enqueued_callback: Callable[[], None] | None,\n    ) -> None:\n        self._session_storage = session_storage\n        self._uploaded_file_mgr = uploaded_file_manager\n        self._script_cache = script_cache\n        self._message_enqueued_callback = message_enqueued_callback\n\n        # Mapping of AppSession.id -> ActiveSessionInfo.\n        self._active_session_info_by_id: dict[str, ActiveSessionInfo] = {}\n\n    def connect_session(\n        self,\n        client: SessionClient,\n        script_data: ScriptData,\n        user_info: dict[str, str | None],\n        existing_session_id: str | None = None,\n        session_id_override: str | None = None,\n    ) -> str:\n        assert not (\n            existing_session_id and session_id_override\n        ), \"Only one of existing_session_id and session_id_override should be truthy\"\n\n        if existing_session_id in self._active_session_info_by_id:\n            _LOGGER.warning(\n                \"Session with id %s is already connected! Connecting to a new session.\",\n                existing_session_id,\n            )\n\n        session_info = (\n            existing_session_id\n            and existing_session_id not in self._active_session_info_by_id\n            and self._session_storage.get(existing_session_id)\n        )\n\n        if session_info:\n            existing_session = session_info.session\n            existing_session.register_file_watchers()\n\n            self._active_session_info_by_id[existing_session.id] = ActiveSessionInfo(\n                client,\n                existing_session,\n                session_info.script_run_count,\n            )\n            self._session_storage.delete(existing_session.id)\n\n            return existing_session.id\n\n        session = AppSession(\n            script_data=script_data,\n            uploaded_file_manager=self._uploaded_file_mgr,\n            script_cache=self._script_cache,\n            message_enqueued_callback=self._message_enqueued_callback,\n            user_info=user_info,\n            session_id_override=session_id_override,\n        )\n\n        _LOGGER.debug(\n            \"Created new session for client %s. Session ID: %s\", id(client), session.id\n        )\n\n        assert (\n            session.id not in self._active_session_info_by_id\n        ), f\"session.id '{session.id}' registered multiple times!\"\n\n        self._active_session_info_by_id[session.id] = ActiveSessionInfo(client, session)\n        return session.id\n\n    def disconnect_session(self, session_id: str) -> None:\n        if session_id in self._active_session_info_by_id:\n            active_session_info = self._active_session_info_by_id[session_id]\n            session = active_session_info.session\n\n            session.request_script_stop()\n            session.disconnect_file_watchers()\n\n            self._session_storage.save(\n                SessionInfo(\n                    client=None,\n                    session=session,\n                    script_run_count=active_session_info.script_run_count,\n                )\n            )\n            del self._active_session_info_by_id[session_id]\n\n    def get_active_session_info(self, session_id: str) -> ActiveSessionInfo | None:\n        return self._active_session_info_by_id.get(session_id)\n\n    def is_active_session(self, session_id: str) -> bool:\n        return session_id in self._active_session_info_by_id\n\n    def list_active_sessions(self) -> list[ActiveSessionInfo]:\n        return list(self._active_session_info_by_id.values())\n\n    def close_session(self, session_id: str) -> None:\n        if session_id in self._active_session_info_by_id:\n            active_session_info = self._active_session_info_by_id[session_id]\n            del self._active_session_info_by_id[session_id]\n            active_session_info.session.shutdown()\n            return\n\n        session_info = self._session_storage.get(session_id)\n        if session_info:\n            self._session_storage.delete(session_id)\n            session_info.session.shutdown()\n\n    def get_session_info(self, session_id: str) -> SessionInfo | None:\n        session_info = self.get_active_session_info(session_id)\n        if session_info:\n            return cast(SessionInfo, session_info)\n        return self._session_storage.get(session_id)\n\n    def list_sessions(self) -> list[SessionInfo]:\n        return (\n            cast(List[SessionInfo], self.list_active_sessions())\n            + self._session_storage.list()\n        )\n", "lib/streamlit/runtime/runtime_util.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Runtime-related utility functions\"\"\"\n\nfrom __future__ import annotations\n\nfrom typing import TYPE_CHECKING, Any\n\nfrom streamlit import config\nfrom streamlit.errors import MarkdownFormattedException, StreamlitAPIException\nfrom streamlit.runtime.forward_msg_cache import populate_hash_if_needed\n\nif TYPE_CHECKING:\n    from streamlit.proto.ForwardMsg_pb2 import ForwardMsg\n\n\nclass MessageSizeError(MarkdownFormattedException):\n    \"\"\"Exception raised when a websocket message is larger than the configured limit.\"\"\"\n\n    def __init__(self, failed_msg_str: Any):\n        msg = self._get_message(failed_msg_str)\n        super().__init__(msg)\n\n    def _get_message(self, failed_msg_str: Any) -> str:\n        # This needs to have zero indentation otherwise the markdown will render incorrectly.\n        return (\n            f\"\"\"\n**Data of size {len(failed_msg_str) / 1e6:.1f} MB exceeds the message size limit of {get_max_message_size_bytes() / 1e6} MB.**\n\nThis is often caused by a large chart or dataframe. Please decrease the amount of data sent\nto the browser, or increase the limit by setting the config option `server.maxMessageSize`.\n[Click here to learn more about config options](https://docs.streamlit.io/develop/api-reference/configuration/config.toml).\n\n_Note that increasing the limit may lead to long loading times and large memory consumption\nof the client's browser and the Streamlit server._\n\"\"\"\n        ).strip(\"\\n\")\n\n\nclass BadDurationStringError(StreamlitAPIException):\n    \"\"\"Raised when a bad duration argument string is passed.\"\"\"\n\n    def __init__(self, duration: str):\n        MarkdownFormattedException.__init__(\n            self,\n            \"TTL string doesn't look right. It should be formatted as\"\n            f\"`'1d2h34m'` or `2 days`, for example. Got: {duration}\",\n        )\n\n\ndef is_cacheable_msg(msg: ForwardMsg) -> bool:\n    \"\"\"True if the given message qualifies for caching.\"\"\"\n    if msg.WhichOneof(\"type\") in {\"ref_hash\", \"initialize\"}:\n        # Some message types never get cached\n        return False\n    return msg.ByteSize() >= int(config.get_option(\"global.minCachedMessageSize\"))\n\n\ndef serialize_forward_msg(msg: ForwardMsg) -> bytes:\n    \"\"\"Serialize a ForwardMsg to send to a client.\n\n    If the message is too large, it will be converted to an exception message\n    instead.\n    \"\"\"\n    populate_hash_if_needed(msg)\n    msg_str = msg.SerializeToString()\n\n    if len(msg_str) > get_max_message_size_bytes():\n        import streamlit.elements.exception as exception\n\n        # Overwrite the offending ForwardMsg.delta with an error to display.\n        # This assumes that the size limit wasn't exceeded due to metadata.\n        exception.marshall(msg.delta.new_element.exception, MessageSizeError(msg_str))\n        msg_str = msg.SerializeToString()\n\n    return msg_str\n\n\n# This needs to be initialized lazily to avoid calling config.get_option() and\n# thus initializing config options when this file is first imported.\n_max_message_size_bytes: int | None = None\n\n\ndef get_max_message_size_bytes() -> int:\n    \"\"\"Returns the max websocket message size in bytes.\n\n    This will lazyload the value from the config and store it in the global symbol table.\n    \"\"\"\n    global _max_message_size_bytes\n\n    if _max_message_size_bytes is None:\n        _max_message_size_bytes = config.get_option(\"server.maxMessageSize\") * int(1e6)\n\n    return _max_message_size_bytes\n", "lib/streamlit/runtime/metrics_util.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport contextlib\nimport inspect\nimport os\nimport sys\nimport threading\nimport time\nimport uuid\nfrom collections.abc import Sized\nfrom functools import wraps\nfrom typing import Any, Callable, Final, TypeVar, cast, overload\n\nfrom streamlit import config, util\nfrom streamlit.logger import get_logger\nfrom streamlit.proto.ForwardMsg_pb2 import ForwardMsg\nfrom streamlit.proto.PageProfile_pb2 import Argument, Command\n\n_LOGGER: Final = get_logger(__name__)\n\n# Limit the number of commands to keep the page profile message small\n# since Segment allows only a maximum of 32kb per event.\n_MAX_TRACKED_COMMANDS: Final = 200\n# Only track a maximum of 25 uses per unique command since some apps use\n# commands excessively (e.g. calling add_rows thousands of times in one rerun)\n# making the page profile useless.\n_MAX_TRACKED_PER_COMMAND: Final = 25\n\n# A mapping to convert from the actual name to preferred/shorter representations\n_OBJECT_NAME_MAPPING: Final = {\n    \"streamlit.delta_generator.DeltaGenerator\": \"DG\",\n    \"pandas.core.frame.DataFrame\": \"DataFrame\",\n    \"plotly.graph_objs._figure.Figure\": \"PlotlyFigure\",\n    \"bokeh.plotting.figure.Figure\": \"BokehFigure\",\n    \"matplotlib.figure.Figure\": \"MatplotlibFigure\",\n    \"pandas.io.formats.style.Styler\": \"PandasStyler\",\n    \"pandas.core.indexes.base.Index\": \"PandasIndex\",\n    \"pandas.core.series.Series\": \"PandasSeries\",\n    \"streamlit.connections.snowpark_connection.SnowparkConnection\": \"SnowparkConnection\",\n    \"streamlit.connections.sql_connection.SQLConnection\": \"SQLConnection\",\n}\n\n# A list of dependencies to check for attribution\n_ATTRIBUTIONS_TO_CHECK: Final = [\n    # DB Clients:\n    \"pymysql\",\n    \"MySQLdb\",\n    \"mysql\",\n    \"pymongo\",\n    \"ibis\",\n    \"boto3\",\n    \"psycopg2\",\n    \"psycopg3\",\n    \"sqlalchemy\",\n    \"elasticsearch\",\n    \"pyodbc\",\n    \"pymssql\",\n    \"cassandra\",\n    \"azure\",\n    \"redis\",\n    \"sqlite3\",\n    \"neo4j\",\n    \"duckdb\",\n    \"opensearchpy\",\n    \"supabase\",\n    # Dataframe Libraries:\n    \"polars\",\n    \"dask\",\n    \"vaex\",\n    \"modin\",\n    \"pyspark\",\n    \"cudf\",\n    \"xarray\",\n    \"ray\",\n    # ML & LLM Tools:\n    \"mistralai\",\n    \"openai\",\n    \"langchain\",\n    \"llama_index\",\n    \"llama_cpp\",\n    \"anthropic\",\n    \"pyllamacpp\",\n    \"cohere\",\n    \"transformers\",\n    \"nomic\",\n    \"diffusers\",\n    \"semantic_kernel\",\n    \"replicate\",\n    \"huggingface_hub\",\n    \"wandb\",\n    \"torch\",\n    \"tensorflow\",\n    \"trubrics\",\n    \"comet_ml\",\n    \"clarifai\",\n    \"reka\",\n    \"hegel\",\n    \"fastchat\",\n    \"assemblyai\",\n    \"openllm\",\n    \"embedchain\",\n    \"haystack\",\n    \"vllm\",\n    \"alpa\",\n    \"jinaai\",\n    \"guidance\",\n    \"litellm\",\n    \"comet_llm\",\n    \"instructor\",\n    \"xgboost\",\n    \"lightgbm\",\n    \"catboost\",\n    \"sklearn\",\n    # Workflow Tools:\n    \"prefect\",\n    \"luigi\",\n    \"airflow\",\n    \"dagster\",\n    # Vector Stores:\n    \"pgvector\",\n    \"faiss\",\n    \"annoy\",\n    \"pinecone\",\n    \"chromadb\",\n    \"weaviate\",\n    \"qdrant_client\",\n    \"pymilvus\",\n    \"lancedb\",\n    # Others:\n    \"datasets\",\n    \"snowflake\",\n    \"streamlit_extras\",\n    \"streamlit_pydantic\",\n    \"pydantic\",\n    \"plost\",\n]\n\n_ETC_MACHINE_ID_PATH = \"/etc/machine-id\"\n_DBUS_MACHINE_ID_PATH = \"/var/lib/dbus/machine-id\"\n\n\ndef _get_machine_id_v3() -> str:\n    \"\"\"Get the machine ID\n\n    This is a unique identifier for a user for tracking metrics in Segment,\n    that is broken in different ways in some Linux distros and Docker images.\n    - at times just a hash of '', which means many machines map to the same ID\n    - at times a hash of the same string, when running in a Docker container\n    \"\"\"\n\n    machine_id = str(uuid.getnode())\n    if os.path.isfile(_ETC_MACHINE_ID_PATH):\n        with open(_ETC_MACHINE_ID_PATH) as f:\n            machine_id = f.read()\n\n    elif os.path.isfile(_DBUS_MACHINE_ID_PATH):\n        with open(_DBUS_MACHINE_ID_PATH) as f:\n            machine_id = f.read()\n\n    return machine_id\n\n\nclass Installation:\n    _instance_lock = threading.Lock()\n    _instance: Installation | None = None\n\n    @classmethod\n    def instance(cls) -> Installation:\n        \"\"\"Returns the singleton Installation\"\"\"\n        # We use a double-checked locking optimization to avoid the overhead\n        # of acquiring the lock in the common case:\n        # https://en.wikipedia.org/wiki/Double-checked_locking\n        if cls._instance is None:\n            with cls._instance_lock:\n                if cls._instance is None:\n                    cls._instance = Installation()\n        return cls._instance\n\n    def __init__(self):\n        self.installation_id_v3 = str(\n            uuid.uuid5(uuid.NAMESPACE_DNS, _get_machine_id_v3())\n        )\n\n    def __repr__(self) -> str:\n        return util.repr_(self)\n\n    @property\n    def installation_id(self):\n        return self.installation_id_v3\n\n\ndef _get_type_name(obj: object) -> str:\n    \"\"\"Get a simplified name for the type of the given object.\"\"\"\n    with contextlib.suppress(Exception):\n        obj_type = obj if inspect.isclass(obj) else type(obj)\n        type_name = \"unknown\"\n        if hasattr(obj_type, \"__qualname__\"):\n            type_name = obj_type.__qualname__\n        elif hasattr(obj_type, \"__name__\"):\n            type_name = obj_type.__name__\n\n        if obj_type.__module__ != \"builtins\":\n            # Add the full module path\n            type_name = f\"{obj_type.__module__}.{type_name}\"\n\n        if type_name in _OBJECT_NAME_MAPPING:\n            type_name = _OBJECT_NAME_MAPPING[type_name]\n        return type_name\n    return \"failed\"\n\n\ndef _get_top_level_module(func: Callable[..., Any]) -> str:\n    \"\"\"Get the top level module for the given function.\"\"\"\n    module = inspect.getmodule(func)\n    if module is None or not module.__name__:\n        return \"unknown\"\n    return module.__name__.split(\".\")[0]\n\n\ndef _get_arg_metadata(arg: object) -> str | None:\n    \"\"\"Get metadata information related to the value of the given object.\"\"\"\n    with contextlib.suppress(Exception):\n        if isinstance(arg, (bool)):\n            return f\"val:{arg}\"\n\n        if isinstance(arg, Sized):\n            return f\"len:{len(arg)}\"\n\n    return None\n\n\ndef _get_command_telemetry(\n    _command_func: Callable[..., Any], _command_name: str, *args, **kwargs\n) -> Command:\n    \"\"\"Get telemetry information for the given callable and its arguments.\"\"\"\n    arg_keywords = inspect.getfullargspec(_command_func).args\n    self_arg: Any | None = None\n    arguments: list[Argument] = []\n    is_method = inspect.ismethod(_command_func)\n    name = _command_name\n\n    for i, arg in enumerate(args):\n        pos = i\n        if is_method:\n            # If func is a method, ignore the first argument (self)\n            i = i + 1\n\n        keyword = arg_keywords[i] if len(arg_keywords) > i else f\"{i}\"\n        if keyword == \"self\":\n            self_arg = arg\n            continue\n        argument = Argument(k=keyword, t=_get_type_name(arg), p=pos)\n\n        arg_metadata = _get_arg_metadata(arg)\n        if arg_metadata:\n            argument.m = arg_metadata\n        arguments.append(argument)\n    for kwarg, kwarg_value in kwargs.items():\n        argument = Argument(k=kwarg, t=_get_type_name(kwarg_value))\n\n        arg_metadata = _get_arg_metadata(kwarg_value)\n        if arg_metadata:\n            argument.m = arg_metadata\n        arguments.append(argument)\n\n    top_level_module = _get_top_level_module(_command_func)\n    if top_level_module != \"streamlit\":\n        # If the gather_metrics decorator is used outside of streamlit library\n        # we enforce a prefix to be added to the tracked command:\n        name = f\"external:{top_level_module}:{name}\"\n\n    if (\n        name == \"create_instance\"\n        and self_arg\n        and hasattr(self_arg, \"name\")\n        and self_arg.name\n    ):\n        name = f\"component:{self_arg.name}\"\n\n    return Command(name=name, args=arguments)\n\n\ndef to_microseconds(seconds: float) -> int:\n    \"\"\"Convert seconds into microseconds.\"\"\"\n    return int(seconds * 1_000_000)\n\n\nF = TypeVar(\"F\", bound=Callable[..., Any])\n\n\n@overload\ndef gather_metrics(\n    name: str,\n    func: F,\n) -> F: ...\n\n\n@overload\ndef gather_metrics(\n    name: str,\n    func: None = None,\n) -> Callable[[F], F]: ...\n\n\ndef gather_metrics(name: str, func: F | None = None) -> Callable[[F], F] | F:\n    \"\"\"Function decorator to add telemetry tracking to commands.\n\n    Parameters\n    ----------\n    func : callable\n    The function to track for telemetry.\n\n    name : str or None\n    Overwrite the function name with a custom name that is used for telemetry tracking.\n\n    Example\n    -------\n    >>> @st.gather_metrics\n    ... def my_command(url):\n    ...     return url\n\n    >>> @st.gather_metrics(name=\"custom_name\")\n    ... def my_command(url):\n    ...     return url\n    \"\"\"\n\n    if not name:\n        _LOGGER.warning(\"gather_metrics: name is empty\")\n        name = \"undefined\"\n\n    if func is None:\n        # Support passing the params via function decorator\n        def wrapper(f: F) -> F:\n            return gather_metrics(\n                name=name,\n                func=f,\n            )\n\n        return wrapper\n    else:\n        # To make mypy type narrow F | None -> F\n        non_optional_func = func\n\n    @wraps(non_optional_func)\n    def wrapped_func(*args, **kwargs):\n        from timeit import default_timer as timer\n\n        exec_start = timer()\n        # Local imports to prevent circular dependencies\n        from streamlit.runtime.scriptrunner import get_script_run_ctx\n        from streamlit.runtime.scriptrunner.exceptions import RerunException\n\n        ctx = get_script_run_ctx(suppress_warning=True)\n\n        tracking_activated = (\n            ctx is not None\n            and ctx.gather_usage_stats\n            and not ctx.command_tracking_deactivated\n            and len(ctx.tracked_commands)\n            < _MAX_TRACKED_COMMANDS  # Prevent too much memory usage\n        )\n\n        command_telemetry: Command | None = None\n        # This flag is needed to make sure that only the command (the outermost command)\n        # that deactivated tracking (via ctx.command_tracking_deactivated) is able to reset it\n        # again. This is important to prevent nested commands from reactivating tracking.\n        # At this point, we don't know yet if the command will deactivated tracking.\n        has_set_command_tracking_deactivated = False\n\n        if ctx and tracking_activated:\n            try:\n                command_telemetry = _get_command_telemetry(\n                    non_optional_func, name, *args, **kwargs\n                )\n\n                if (\n                    command_telemetry.name not in ctx.tracked_commands_counter\n                    or ctx.tracked_commands_counter[command_telemetry.name]\n                    < _MAX_TRACKED_PER_COMMAND\n                ):\n                    ctx.tracked_commands.append(command_telemetry)\n                ctx.tracked_commands_counter.update([command_telemetry.name])\n                # Deactivate tracking to prevent calls inside already tracked commands\n                ctx.command_tracking_deactivated = True\n                # The ctx.command_tracking_deactivated flag was set to True,\n                # we also need to set has_set_command_tracking_deactivated to True\n                # to make sure that this command is able to reset it again.\n                has_set_command_tracking_deactivated = True\n            except Exception as ex:\n                # Always capture all exceptions since we want to make sure that\n                # the telemetry never causes any issues.\n                _LOGGER.debug(\"Failed to collect command telemetry\", exc_info=ex)\n        try:\n            result = non_optional_func(*args, **kwargs)\n        except RerunException as ex:\n            # Duplicated from below, because static analysis tools get confused\n            # by deferring the rethrow.\n            if tracking_activated and command_telemetry:\n                command_telemetry.time = to_microseconds(timer() - exec_start)\n            raise ex\n        finally:\n            # Activate tracking again if command executes without any exceptions\n            # we only want to do that if this command has set the\n            # flag to deactivate tracking.\n            if ctx and has_set_command_tracking_deactivated:\n                ctx.command_tracking_deactivated = False\n\n        if tracking_activated and command_telemetry:\n            # Set the execution time to the measured value\n            command_telemetry.time = to_microseconds(timer() - exec_start)\n\n        return result\n\n    with contextlib.suppress(AttributeError):\n        # Make this a well-behaved decorator by preserving important function\n        # attributes.\n        wrapped_func.__dict__.update(non_optional_func.__dict__)\n        wrapped_func.__signature__ = inspect.signature(non_optional_func)  # type: ignore\n    return cast(F, wrapped_func)\n\n\ndef create_page_profile_message(\n    commands: list[Command],\n    exec_time: int,\n    prep_time: int,\n    uncaught_exception: str | None = None,\n) -> ForwardMsg:\n    \"\"\"Create and return the full PageProfile ForwardMsg.\"\"\"\n    # Local import to prevent circular dependencies\n    from streamlit.runtime.scriptrunner import get_script_run_ctx\n\n    msg = ForwardMsg()\n    page_profile = msg.page_profile\n\n    page_profile.commands.extend(commands)\n    page_profile.exec_time = exec_time\n    page_profile.prep_time = prep_time\n\n    page_profile.headless = config.get_option(\"server.headless\")\n\n    # Collect all config options that have been manually set\n    config_options: set[str] = set()\n    if config._config_options:\n        for option_name in config._config_options.keys():\n            if not config.is_manually_set(option_name):\n                # We only care about manually defined options\n                continue\n\n            config_option = config._config_options[option_name]\n            if config_option.is_default:\n                option_name = f\"{option_name}:default\"\n            config_options.add(option_name)\n\n    page_profile.config.extend(config_options)\n\n    # Check the predefined set of modules for attribution\n    attributions: set[str] = {\n        attribution\n        for attribution in _ATTRIBUTIONS_TO_CHECK\n        if attribution in sys.modules\n    }\n\n    page_profile.os = str(sys.platform)\n    page_profile.timezone = str(time.tzname)\n    page_profile.attributions.extend(attributions)\n\n    if uncaught_exception:\n        page_profile.uncaught_exception = uncaught_exception\n\n    if ctx := get_script_run_ctx():\n        page_profile.is_fragment_run = bool(ctx.fragment_ids_this_run)\n\n    return msg\n", "lib/streamlit/runtime/memory_session_storage.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom typing import MutableMapping\n\nfrom cachetools import TTLCache\n\nfrom streamlit.runtime.session_manager import SessionInfo, SessionStorage\n\n\nclass MemorySessionStorage(SessionStorage):\n    \"\"\"A SessionStorage that stores sessions in memory.\n\n    At most maxsize sessions are stored with a TTL of ttl seconds. This class is really\n    just a thin wrapper around cachetools.TTLCache that complies with the SessionStorage\n    protocol.\n    \"\"\"\n\n    # NOTE: The defaults for maxsize and ttl are chosen arbitrarily for now. These\n    # numbers are reasonable as the main problems we're trying to solve at the moment are\n    # caused by transient disconnects that are usually just short network blips. In the\n    # future, we may want to increase both to support use cases such as saving state for\n    # much longer periods of time. For example, we may want session state to persist if\n    # a user closes their laptop lid and comes back to an app hours later.\n    def __init__(\n        self,\n        maxsize: int = 128,\n        ttl_seconds: int = 2 * 60,  # 2 minutes\n    ) -> None:\n        \"\"\"Instantiate a new MemorySessionStorage.\n\n        Parameters\n        ----------\n        maxsize\n            The maximum number of sessions we allow to be stored in this\n            MemorySessionStorage. If an entry needs to be removed because we have\n            exceeded this number, either\n              * an expired entry is removed, or\n              * the least recently used entry is removed (if no entries have expired).\n\n        ttl_seconds\n            The time in seconds for an entry added to a MemorySessionStorage to live.\n            After this amount of time has passed for a given entry, it becomes\n            inaccessible and will be removed eventually.\n        \"\"\"\n\n        self._cache: MutableMapping[str, SessionInfo] = TTLCache(\n            maxsize=maxsize, ttl=ttl_seconds\n        )\n\n    def get(self, session_id: str) -> SessionInfo | None:\n        return self._cache.get(session_id, None)\n\n    def save(self, session_info: SessionInfo) -> None:\n        self._cache[session_info.session.id] = session_info\n\n    def delete(self, session_id: str) -> None:\n        del self._cache[session_id]\n\n    def list(self) -> list[SessionInfo]:\n        return list(self._cache.values())\n", "lib/streamlit/runtime/pages_manager.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport contextlib\nimport os\nimport threading\nfrom pathlib import Path\nfrom typing import TYPE_CHECKING, Any, Callable, Final\n\nfrom streamlit import source_util\nfrom streamlit.logger import get_logger\nfrom streamlit.util import calc_md5\nfrom streamlit.watcher import watch_dir\n\nif TYPE_CHECKING:\n    from streamlit.runtime.scriptrunner.script_cache import ScriptCache\n    from streamlit.source_util import PageHash, PageInfo, PageName, ScriptPath\n\n_LOGGER: Final = get_logger(__name__)\n\n\nclass PagesStrategyV1:\n    \"\"\"\n    Strategy for MPA v1. This strategy handles pages being set directly\n    by a call to `st.navigation`. The key differences here are:\n    - The pages are defined by the existence of a `pages` directory\n    - We will ensure one watcher is watching the scripts in the directory.\n    - Only one script runs for a full rerun.\n    - We know at the beginning the intended page script to run.\n\n    NOTE: Thread safety of the pages is handled by the source_util module\n    \"\"\"\n\n    is_watching_pages_dir: bool = False\n    pages_watcher_lock = threading.Lock()\n\n    # This is a static method because we only want to watch the pages directory\n    # once on initial load.\n    @staticmethod\n    def watch_pages_dir(pages_manager: PagesManager):\n        with PagesStrategyV1.pages_watcher_lock:\n            if PagesStrategyV1.is_watching_pages_dir:\n                return\n\n            def _handle_page_changed(_path: str) -> None:\n                source_util.invalidate_pages_cache()\n\n            main_script_path = Path(pages_manager.main_script_path)\n            pages_dir = main_script_path.parent / \"pages\"\n            watch_dir(\n                str(pages_dir),\n                _handle_page_changed,\n                glob_pattern=\"*.py\",\n                allow_nonexistent=True,\n            )\n            PagesStrategyV1.is_watching_pages_dir = True\n\n    def __init__(self, pages_manager: PagesManager, setup_watcher: bool = True):\n        self.pages_manager = pages_manager\n\n        if setup_watcher:\n            PagesStrategyV1.watch_pages_dir(pages_manager)\n\n    # In MPA v1, there's no difference between the active hash\n    # and the page script hash.\n    def get_active_script_hash(self) -> PageHash:\n        return self.pages_manager.current_page_hash\n\n    def set_active_script_hash(self, _page_hash: PageHash):\n        # Intentionally do nothing as MPA v1 active_script_hash does not\n        # differentiate the active_script_hash and the page_script_hash\n        pass\n\n    def get_initial_active_script(\n        self, page_script_hash: PageHash, page_name: PageName\n    ) -> PageInfo | None:\n        pages = self.get_pages()\n\n        if page_script_hash:\n            return pages.get(page_script_hash, None)\n        elif not page_script_hash and page_name:\n            # If a user navigates directly to a non-main page of an app, we get\n            # the first script run request before the list of pages has been\n            # sent to the frontend. In this case, we choose the first script\n            # with a name matching the requested page name.\n            return next(\n                filter(\n                    # There seems to be this weird bug with mypy where it\n                    # thinks that p can be None (which is impossible given the\n                    # types of pages), so we add `p and` at the beginning of\n                    # the predicate to circumvent this.\n                    lambda p: p and (p[\"page_name\"] == page_name),\n                    pages.values(),\n                ),\n                None,\n            )\n\n        # If no information about what page to run is given, default to\n        # running the main page.\n        # Safe because pages will at least contain the app's main page.\n        main_page_info = list(pages.values())[0]\n        return main_page_info\n\n    def get_pages(self) -> dict[PageHash, PageInfo]:\n        return source_util.get_pages(self.pages_manager.main_script_path)\n\n    def register_pages_changed_callback(\n        self,\n        callback: Callable[[str], None],\n    ) -> Callable[[], None]:\n        return source_util.register_pages_changed_callback(callback)\n\n    def set_pages(self, _pages: dict[PageHash, PageInfo]) -> None:\n        raise NotImplementedError(\"Unable to set pages in this V1 strategy\")\n\n    def get_page_script(self, _fallback_page_hash: PageHash) -> PageInfo | None:\n        raise NotImplementedError(\"Unable to get page script in this V1 strategy\")\n\n\nclass PagesStrategyV2:\n    \"\"\"\n    Strategy for MPA v2. This strategy handles pages being set directly\n    by a call to `st.navigation`. The key differences here are:\n    - The pages are set directly by the user\n    - The initial active script will always be the main script\n    - More than one script can run in a single app run (sequentially),\n      so we must keep track of the active script hash\n    - We rely on pages manager to retrieve the intended page script per run\n\n    NOTE: We don't provide any locks on the pages since the pages are not\n    shared across sessions. Only the user script thread can write to\n    pages and the event loop thread only reads\n    \"\"\"\n\n    def __init__(self, pages_manager: PagesManager, **kwargs):\n        self.pages_manager = pages_manager\n        self._active_script_hash: PageHash = self.pages_manager.main_script_hash\n        self._pages: dict[PageHash, PageInfo] | None = None\n\n    def get_active_script_hash(self) -> PageHash:\n        return self._active_script_hash\n\n    def set_active_script_hash(self, page_hash: PageHash):\n        self._active_script_hash = page_hash\n\n    def get_initial_active_script(\n        self, page_script_hash: PageHash, page_name: PageName\n    ) -> PageInfo:\n        return {\n            # We always run the main script in V2 as it's the common code\n            \"script_path\": self.pages_manager.main_script_path,\n            \"page_script_hash\": page_script_hash\n            or self.pages_manager.main_script_hash,  # Default Hash\n        }\n\n    def get_page_script(self, fallback_page_hash: PageHash) -> PageInfo | None:\n        if self._pages is None:\n            return None\n\n        if self.pages_manager.intended_page_script_hash:\n            # We assume that if initial page hash is specified, that a page should\n            # exist, so we check out the page script hash or the default page hash\n            # as a backup\n            return self._pages.get(\n                self.pages_manager.intended_page_script_hash,\n                self._pages.get(fallback_page_hash, None),\n            )\n        elif self.pages_manager.intended_page_name:\n            # If a user navigates directly to a non-main page of an app, the\n            # the page name can identify the page script to run\n            return next(\n                filter(\n                    # There seems to be this weird bug with mypy where it\n                    # thinks that p can be None (which is impossible given the\n                    # types of pages), so we add `p and` at the beginning of\n                    # the predicate to circumvent this.\n                    lambda p: p\n                    and (p[\"url_pathname\"] == self.pages_manager.intended_page_name),\n                    self._pages.values(),\n                ),\n                None,\n            )\n\n        return self._pages.get(fallback_page_hash, None)\n\n    def get_pages(self) -> dict[PageHash, PageInfo]:\n        # If pages are not set, provide the common page info where\n        # - the main script path is the executing script to start\n        # - the page script hash and name reflects the intended page requested\n        return self._pages or {\n            self.pages_manager.main_script_hash: {\n                \"page_script_hash\": self.pages_manager.intended_page_script_hash or \"\",\n                \"page_name\": self.pages_manager.intended_page_name or \"\",\n                \"icon\": \"\",\n                \"script_path\": self.pages_manager.main_script_path,\n            }\n        }\n\n    def set_pages(self, pages: dict[PageHash, PageInfo]) -> None:\n        self._pages = pages\n\n    def register_pages_changed_callback(\n        self,\n        callback: Callable[[str], None],\n    ) -> Callable[[], None]:\n        # V2 strategy does not handle any pages changed event\n        return lambda: None\n\n\nclass PagesManager:\n    \"\"\"\n    PagesManager is responsible for managing the set of pages based on the\n    strategy. By default, PagesManager uses V1 which relies on the original\n    assumption that there exists a `pages` directory with all the scripts.\n\n    If the `pages` are being set directly, the strategy is switched to V2.\n    This indicates someone has written an `st.navigation` call in their app\n    which informs us of the pages.\n\n    NOTE: Each strategy handles its own thread safety when accessing the pages\n    \"\"\"\n\n    DefaultStrategy: type[PagesStrategyV1 | PagesStrategyV2] = PagesStrategyV1\n\n    def __init__(\n        self,\n        main_script_path: ScriptPath,\n        script_cache: ScriptCache | None = None,\n        **kwargs,\n    ):\n        self._main_script_path = main_script_path\n        self._main_script_hash: PageHash = calc_md5(main_script_path)\n        self._current_page_hash: PageHash = self._main_script_hash\n        self.pages_strategy = PagesManager.DefaultStrategy(self, **kwargs)\n        self._script_cache = script_cache\n        self._intended_page_script_hash: PageHash | None = None\n        self._intended_page_name: PageName | None = None\n\n    @property\n    def current_page_hash(self) -> PageHash:\n        return self._current_page_hash\n\n    @property\n    def main_script_path(self) -> ScriptPath:\n        return self._main_script_path\n\n    @property\n    def main_script_hash(self) -> PageHash:\n        return self._main_script_hash\n\n    @property\n    def intended_page_name(self) -> PageName | None:\n        return self._intended_page_name\n\n    @property\n    def intended_page_script_hash(self) -> PageHash | None:\n        return self._intended_page_script_hash\n\n    def get_main_page(self) -> PageInfo:\n        return {\n            \"script_path\": self._main_script_path,\n            \"page_script_hash\": self._main_script_hash,\n        }\n\n    def get_current_page_script_hash(self) -> PageHash:\n        \"\"\"Gets the script hash of the associated page of a script.\"\"\"\n        return self._current_page_hash\n\n    def set_current_page_script_hash(self, page_hash: PageHash) -> None:\n        self._current_page_hash = page_hash\n\n    def get_active_script_hash(self) -> PageHash:\n        \"\"\"Gets the script hash of the currently executing script.\"\"\"\n        return self.pages_strategy.get_active_script_hash()\n\n    def set_active_script_hash(self, page_hash: PageHash):\n        return self.pages_strategy.set_active_script_hash(page_hash)\n\n    def reset_active_script_hash(self):\n        # This will only apply to the V2 strategy as V1 ignores the concept\n        self.set_active_script_hash(self.main_script_hash)\n\n    def set_script_intent(\n        self, page_script_hash: PageHash, page_name: PageName\n    ) -> None:\n        self._intended_page_script_hash = page_script_hash\n        self._intended_page_name = page_name\n\n    def get_initial_active_script(\n        self, page_script_hash: PageHash, page_name: PageName\n    ) -> PageInfo | None:\n        return self.pages_strategy.get_initial_active_script(\n            page_script_hash, page_name\n        )\n\n    @contextlib.contextmanager\n    def run_with_active_hash(self, page_hash: PageHash):\n        original_page_hash = self.get_active_script_hash()\n        self.set_active_script_hash(page_hash)\n        try:\n            yield\n        finally:\n            # in the event of any exception, ensure we set the active hash back\n            self.set_active_script_hash(original_page_hash)\n\n    def get_pages(self) -> dict[PageHash, PageInfo]:\n        return self.pages_strategy.get_pages()\n\n    def set_pages(self, pages: dict[PageHash, PageInfo]) -> None:\n        # Manually setting the pages indicates we are using MPA v2.\n        if isinstance(self.pages_strategy, PagesStrategyV1):\n            if os.path.exists(Path(self.main_script_path).parent / \"pages\"):\n                _LOGGER.warning(\n                    \"st.navigation was called in an app with a pages/ directory. This may cause unusual app behavior. You may want to rename the pages/ directory.\"\n                )\n            PagesManager.DefaultStrategy = PagesStrategyV2\n            self.pages_strategy = PagesStrategyV2(self)\n\n        self.pages_strategy.set_pages(pages)\n\n    def get_page_script(self, fallback_page_hash: PageHash = \"\") -> PageInfo | None:\n        # We assume the pages strategy is V2 cause this is used\n        # in the st.navigation call, but we just swallow the error\n        try:\n            return self.pages_strategy.get_page_script(fallback_page_hash)\n        except NotImplementedError:\n            return None\n\n    def register_pages_changed_callback(\n        self,\n        callback: Callable[[str], None],\n    ) -> Callable[[], None]:\n        \"\"\"Register a callback to be called when the set of pages changes.\n\n        The callback will be called with the path changed.\n        \"\"\"\n\n        return self.pages_strategy.register_pages_changed_callback(callback)\n\n    def get_page_script_byte_code(self, script_path: str) -> Any:\n        if self._script_cache is None:\n            # Returning an empty string for an empty script\n            return \"\"\n\n        return self._script_cache.get_bytecode(script_path)\n", "lib/streamlit/runtime/forward_msg_cache.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport hashlib\nfrom typing import TYPE_CHECKING, Final, MutableMapping\nfrom weakref import WeakKeyDictionary\n\nfrom streamlit import config, util\nfrom streamlit.logger import get_logger\nfrom streamlit.proto.ForwardMsg_pb2 import ForwardMsg\nfrom streamlit.runtime.stats import CacheStat, CacheStatsProvider, group_stats\nfrom streamlit.util import HASHLIB_KWARGS\n\nif TYPE_CHECKING:\n    from streamlit.runtime.app_session import AppSession\n\n_LOGGER: Final = get_logger(__name__)\n\n\ndef populate_hash_if_needed(msg: ForwardMsg) -> str:\n    \"\"\"Computes and assigns the unique hash for a ForwardMsg.\n\n    If the ForwardMsg already has a hash, this is a no-op.\n\n    Parameters\n    ----------\n    msg : ForwardMsg\n\n    Returns\n    -------\n    string\n        The message's hash, returned here for convenience. (The hash\n        will also be assigned to the ForwardMsg; callers do not need\n        to do this.)\n\n    \"\"\"\n    if msg.hash == \"\":\n        # Move the message's metadata aside. It's not part of the\n        # hash calculation.\n        metadata = msg.metadata\n        msg.ClearField(\"metadata\")\n\n        # MD5 is good enough for what we need, which is uniqueness.\n        hasher = hashlib.md5(**HASHLIB_KWARGS)\n        hasher.update(msg.SerializeToString())\n        msg.hash = hasher.hexdigest()\n\n        # Restore metadata.\n        msg.metadata.CopyFrom(metadata)\n\n    return msg.hash\n\n\ndef create_reference_msg(msg: ForwardMsg) -> ForwardMsg:\n    \"\"\"Create a ForwardMsg that refers to the given message via its hash.\n\n    The reference message will also get a copy of the source message's\n    metadata.\n\n    Parameters\n    ----------\n    msg : ForwardMsg\n        The ForwardMsg to create the reference to.\n\n    Returns\n    -------\n    ForwardMsg\n        A new ForwardMsg that \"points\" to the original message via the\n        ref_hash field.\n\n    \"\"\"\n    ref_msg = ForwardMsg()\n    ref_msg.ref_hash = populate_hash_if_needed(msg)\n    ref_msg.metadata.CopyFrom(msg.metadata)\n    return ref_msg\n\n\nclass ForwardMsgCache(CacheStatsProvider):\n    \"\"\"A cache of ForwardMsgs.\n\n    Large ForwardMsgs (e.g. those containing big DataFrame payloads) are\n    stored in this cache. The server can choose to send a ForwardMsg's hash,\n    rather than the message itself, to a client. Clients can then\n    request messages from this cache via another endpoint.\n\n    This cache is *not* thread safe. It's intended to only be accessed by\n    the server thread.\n\n    \"\"\"\n\n    class Entry:\n        \"\"\"Cache entry.\n\n        Stores the cached message, and the set of AppSessions\n        that we've sent the cached message to.\n\n        \"\"\"\n\n        def __init__(self, msg: ForwardMsg | None):\n            self.msg = msg\n            self._session_script_run_counts: MutableMapping[AppSession, int] = (\n                WeakKeyDictionary()\n            )\n\n        def __repr__(self) -> str:\n            return util.repr_(self)\n\n        def add_session_ref(self, session: AppSession, script_run_count: int) -> None:\n            \"\"\"Adds a reference to a AppSession that has referenced\n            this Entry's message.\n\n            Parameters\n            ----------\n            session : AppSession\n            script_run_count : int\n                The session's run count at the time of the call\n\n            \"\"\"\n            prev_run_count = self._session_script_run_counts.get(session, 0)\n            if script_run_count < prev_run_count:\n                _LOGGER.error(\n                    \"New script_run_count (%s) is < prev_run_count (%s). \"\n                    \"This should never happen!\" % (script_run_count, prev_run_count)\n                )\n                script_run_count = prev_run_count\n            self._session_script_run_counts[session] = script_run_count\n\n        def has_session_ref(self, session: AppSession) -> bool:\n            return session in self._session_script_run_counts\n\n        def get_session_ref_age(\n            self, session: AppSession, script_run_count: int\n        ) -> int:\n            \"\"\"The age of the given session's reference to the Entry,\n            given a new script_run_count.\n\n            \"\"\"\n            return script_run_count - self._session_script_run_counts[session]\n\n        def remove_session_ref(self, session: AppSession) -> None:\n            del self._session_script_run_counts[session]\n\n        def has_refs(self) -> bool:\n            \"\"\"True if this Entry has references from any AppSession.\n\n            If not, it can be removed from the cache.\n            \"\"\"\n            return len(self._session_script_run_counts) > 0\n\n    def __init__(self):\n        self._entries: dict[str, ForwardMsgCache.Entry] = {}\n\n    def __repr__(self) -> str:\n        return util.repr_(self)\n\n    def add_message(\n        self, msg: ForwardMsg, session: AppSession, script_run_count: int\n    ) -> None:\n        \"\"\"Add a ForwardMsg to the cache.\n\n        The cache will also record a reference to the given AppSession,\n        so that it can track which sessions have already received\n        each given ForwardMsg.\n\n        Parameters\n        ----------\n        msg : ForwardMsg\n        session : AppSession\n        script_run_count : int\n            The number of times the session's script has run\n\n        \"\"\"\n        populate_hash_if_needed(msg)\n        entry = self._entries.get(msg.hash, None)\n        if entry is None:\n            if config.get_option(\"global.storeCachedForwardMessagesInMemory\"):\n                entry = ForwardMsgCache.Entry(msg)\n            else:\n                entry = ForwardMsgCache.Entry(None)\n            self._entries[msg.hash] = entry\n        entry.add_session_ref(session, script_run_count)\n\n    def get_message(self, hash: str) -> ForwardMsg | None:\n        \"\"\"Return the message with the given ID if it exists in the cache.\n\n        Parameters\n        ----------\n        hash : str\n            The id of the message to retrieve.\n\n        Returns\n        -------\n        ForwardMsg | None\n\n        \"\"\"\n        entry = self._entries.get(hash, None)\n        return entry.msg if entry else None\n\n    def has_message_reference(\n        self, msg: ForwardMsg, session: AppSession, script_run_count: int\n    ) -> bool:\n        \"\"\"Return True if a session has a reference to a message.\"\"\"\n        populate_hash_if_needed(msg)\n\n        entry = self._entries.get(msg.hash, None)\n        if entry is None or not entry.has_session_ref(session):\n            return False\n\n        # Ensure we're not expired\n        age = entry.get_session_ref_age(session, script_run_count)\n        return age <= int(config.get_option(\"global.maxCachedMessageAge\"))\n\n    def remove_refs_for_session(self, session: AppSession) -> None:\n        \"\"\"Remove refs for all entries for the given session.\n\n        This should be called when an AppSession is disconnected or closed.\n\n        Parameters\n        ----------\n        session : AppSession\n        \"\"\"\n\n        # Operate on a copy of our entries dict.\n        # We may be deleting from it.\n        for msg_hash, entry in self._entries.copy().items():\n            if entry.has_session_ref(session):\n                entry.remove_session_ref(session)\n\n            if not entry.has_refs():\n                # The entry has no more references. Remove it from\n                # the cache completely.\n                del self._entries[msg_hash]\n\n    def remove_expired_entries_for_session(\n        self, session: AppSession, script_run_count: int\n    ) -> None:\n        \"\"\"Remove any cached messages that have expired from the given session.\n\n        This should be called each time a AppSession finishes executing.\n\n        Parameters\n        ----------\n        session : AppSession\n        script_run_count : int\n            The number of times the session's script has run\n\n        \"\"\"\n        max_age = config.get_option(\"global.maxCachedMessageAge\")\n\n        # Operate on a copy of our entries dict.\n        # We may be deleting from it.\n        for msg_hash, entry in self._entries.copy().items():\n            if not entry.has_session_ref(session):\n                continue\n\n            age = entry.get_session_ref_age(session, script_run_count)\n            if age > max_age:\n                _LOGGER.debug(\n                    \"Removing expired entry [session=%s, hash=%s, age=%s]\",\n                    id(session),\n                    msg_hash,\n                    age,\n                )\n                entry.remove_session_ref(session)\n                if not entry.has_refs():\n                    # The entry has no more references. Remove it from\n                    # the cache completely.\n                    del self._entries[msg_hash]\n\n    def clear(self) -> None:\n        \"\"\"Remove all entries from the cache\"\"\"\n        self._entries.clear()\n\n    def get_stats(self) -> list[CacheStat]:\n        stats: list[CacheStat] = [\n            CacheStat(\n                category_name=\"ForwardMessageCache\",\n                cache_name=\"\",\n                byte_length=entry.msg.ByteSize() if entry.msg is not None else 0,\n            )\n            for _, entry in self._entries.items()\n        ]\n        return group_stats(stats)\n", "lib/streamlit/runtime/scriptrunner/script_runner.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport gc\nimport sys\nimport threading\nimport types\nfrom contextlib import contextmanager\nfrom enum import Enum\nfrom timeit import default_timer as timer\nfrom typing import TYPE_CHECKING, Callable, Final\n\nfrom blinker import Signal\n\nfrom streamlit import config, runtime, util\nfrom streamlit.logger import get_logger\nfrom streamlit.proto.ClientState_pb2 import ClientState\nfrom streamlit.proto.ForwardMsg_pb2 import ForwardMsg\nfrom streamlit.runtime.scriptrunner.exceptions import RerunException, StopException\nfrom streamlit.runtime.scriptrunner.exec_code import exec_func_with_error_handling\nfrom streamlit.runtime.scriptrunner.script_cache import ScriptCache\nfrom streamlit.runtime.scriptrunner.script_requests import (\n    RerunData,\n    ScriptRequests,\n    ScriptRequestType,\n)\nfrom streamlit.runtime.scriptrunner.script_run_context import (\n    ScriptRunContext,\n    add_script_run_ctx,\n    get_script_run_ctx,\n)\nfrom streamlit.runtime.state import (\n    SCRIPT_RUN_WITHOUT_ERRORS_KEY,\n    SafeSessionState,\n    SessionState,\n)\nfrom streamlit.vendor.ipython.modified_sys_path import modified_sys_path\n\nif TYPE_CHECKING:\n    from streamlit.runtime.fragment import FragmentStorage\n    from streamlit.runtime.pages_manager import PagesManager\n    from streamlit.runtime.scriptrunner.script_cache import ScriptCache\n    from streamlit.runtime.uploaded_file_manager import UploadedFileManager\n\n_LOGGER: Final = get_logger(__name__)\n\n\nclass ScriptRunnerEvent(Enum):\n    # \"Control\" events. These are emitted when the ScriptRunner's state changes.\n\n    # The script started running.\n    SCRIPT_STARTED = \"SCRIPT_STARTED\"\n\n    # The script run stopped because of a compile error.\n    SCRIPT_STOPPED_WITH_COMPILE_ERROR = \"SCRIPT_STOPPED_WITH_COMPILE_ERROR\"\n\n    # The script run stopped because it ran to completion, or was\n    # interrupted by the user.\n    SCRIPT_STOPPED_WITH_SUCCESS = \"SCRIPT_STOPPED_WITH_SUCCESS\"\n\n    # The script run stopped in order to start a script run with newer widget state.\n    SCRIPT_STOPPED_FOR_RERUN = \"SCRIPT_STOPPED_FOR_RERUN\"\n\n    # The script run corresponding to a fragment ran to completion, or was interrupted\n    # by the user.\n    FRAGMENT_STOPPED_WITH_SUCCESS = \"FRAGMENT_STOPPED_WITH_SUCCESS\"\n\n    # The ScriptRunner is done processing the ScriptEventQueue and\n    # is shut down.\n    SHUTDOWN = \"SHUTDOWN\"\n\n    # \"Data\" events. These are emitted when the ScriptRunner's script has\n    # data to send to the frontend.\n\n    # The script has a ForwardMsg to send to the frontend.\n    ENQUEUE_FORWARD_MSG = \"ENQUEUE_FORWARD_MSG\"\n\n\n\"\"\"\nNote [Threading]\nThere are two kinds of threads in Streamlit, the main thread and script threads.\nThe main thread is started by invoking the Streamlit CLI, and bootstraps the\nframework and runs the Tornado webserver.\nA script thread is created by a ScriptRunner when it starts. The script thread\nis where the ScriptRunner executes, including running the user script itself,\nprocessing messages to/from the frontend, and all the Streamlit library function\ncalls in the user script.\nIt is possible for the user script to spawn its own threads, which could call\nStreamlit functions. We restrict the ScriptRunner's execution control to the\nscript thread. Calling Streamlit functions from other threads is unlikely to\nwork correctly due to lack of ScriptRunContext, so we may add a guard against\nit in the future.\n\"\"\"\n\n\nclass ScriptRunner:\n    def __init__(\n        self,\n        session_id: str,\n        main_script_path: str,\n        session_state: SessionState,\n        uploaded_file_mgr: UploadedFileManager,\n        script_cache: ScriptCache,\n        initial_rerun_data: RerunData,\n        user_info: dict[str, str | None],\n        fragment_storage: FragmentStorage,\n        pages_manager: PagesManager,\n    ):\n        \"\"\"Initialize the ScriptRunner.\n\n        (The ScriptRunner won't start executing until start() is called.)\n\n        Parameters\n        ----------\n        session_id\n            The AppSession's id.\n\n        main_script_path\n            Path to our main app script.\n\n        session_state\n            The AppSession's SessionState instance.\n\n        uploaded_file_mgr\n            The File manager to store the data uploaded by the file_uploader widget.\n\n        script_cache\n            A ScriptCache instance.\n\n        initial_rerun_data\n            RerunData to initialize this ScriptRunner with.\n\n        user_info\n            A dict that contains information about the current user. For now,\n            it only contains the user's email address.\n\n            {\n                \"email\": \"example@example.com\"\n            }\n\n            Information about the current user is optionally provided when a\n            websocket connection is initialized via the \"X-Streamlit-User\" header.\n\n        fragment_storage\n            The AppSession's FragmentStorage instance.\n        \"\"\"\n        self._session_id = session_id\n        self._main_script_path = main_script_path\n        self._session_state = SafeSessionState(\n            session_state, yield_callback=self._maybe_handle_execution_control_request\n        )\n        self._uploaded_file_mgr = uploaded_file_mgr\n        self._script_cache = script_cache\n        self._user_info = user_info\n        self._fragment_storage = fragment_storage\n\n        self._pages_manager = pages_manager\n        self._requests = ScriptRequests()\n        self._requests.request_rerun(initial_rerun_data)\n\n        self.on_event = Signal(\n            doc=\"\"\"Emitted when a ScriptRunnerEvent occurs.\n\n            This signal is generally emitted on the ScriptRunner's script\n            thread (which is *not* the same thread that the ScriptRunner was\n            created on).\n\n            Parameters\n            ----------\n            sender: ScriptRunner\n                The sender of the event (this ScriptRunner).\n\n            event : ScriptRunnerEvent\n\n            forward_msg : ForwardMsg | None\n                The ForwardMsg to send to the frontend. Set only for the\n                ENQUEUE_FORWARD_MSG event.\n\n            exception : BaseException | None\n                Our compile error. Set only for the\n                SCRIPT_STOPPED_WITH_COMPILE_ERROR event.\n\n            widget_states : streamlit.proto.WidgetStates_pb2.WidgetStates | None\n                The ScriptRunner's final WidgetStates. Set only for the\n                SHUTDOWN event.\n            \"\"\"\n        )\n\n        # Set to true while we're executing. Used by\n        # _maybe_handle_execution_control_request.\n        self._execing = False\n\n        # This is initialized in start()\n        self._script_thread: threading.Thread | None = None\n\n    def __repr__(self) -> str:\n        return util.repr_(self)\n\n    def request_stop(self) -> None:\n        \"\"\"Request that the ScriptRunner stop running its script and\n        shut down. The ScriptRunner will handle this request when it reaches\n        an interrupt point.\n\n        Safe to call from any thread.\n        \"\"\"\n        self._requests.request_stop()\n\n    def request_rerun(self, rerun_data: RerunData) -> bool:\n        \"\"\"Request that the ScriptRunner interrupt its currently-running\n        script and restart it.\n\n        If the ScriptRunner has been stopped, this request can't be honored:\n        return False.\n\n        Otherwise, record the request and return True. The ScriptRunner will\n        handle the rerun request as soon as it reaches an interrupt point.\n\n        Safe to call from any thread.\n        \"\"\"\n        return self._requests.request_rerun(rerun_data)\n\n    def start(self) -> None:\n        \"\"\"Start a new thread to process the ScriptEventQueue.\n\n        This must be called only once.\n\n        \"\"\"\n        if self._script_thread is not None:\n            raise Exception(\"ScriptRunner was already started\")\n\n        self._script_thread = threading.Thread(\n            target=self._run_script_thread,\n            name=\"ScriptRunner.scriptThread\",\n        )\n        self._script_thread.start()\n\n    def _get_script_run_ctx(self) -> ScriptRunContext:\n        \"\"\"Get the ScriptRunContext for the current thread.\n\n        Returns\n        -------\n        ScriptRunContext\n            The ScriptRunContext for the current thread.\n\n        Raises\n        ------\n        AssertionError\n            If called outside of a ScriptRunner thread.\n        RuntimeError\n            If there is no ScriptRunContext for the current thread.\n\n        \"\"\"\n        assert self._is_in_script_thread()\n\n        ctx = get_script_run_ctx()\n        if ctx is None:\n            # This should never be possible on the script_runner thread.\n            raise RuntimeError(\n                \"ScriptRunner thread has a null ScriptRunContext. \"\n                \"Something has gone very wrong!\"\n            )\n        return ctx\n\n    def _run_script_thread(self) -> None:\n        \"\"\"The entry point for the script thread.\n\n        Processes the ScriptRequestQueue, which will at least contain the RERUN\n        request that will trigger the first script-run.\n\n        When the ScriptRequestQueue is empty, or when a SHUTDOWN request is\n        dequeued, this function will exit and its thread will terminate.\n        \"\"\"\n        assert self._is_in_script_thread()\n\n        _LOGGER.debug(\"Beginning script thread\")\n\n        # Create and attach the thread's ScriptRunContext\n        ctx = ScriptRunContext(\n            session_id=self._session_id,\n            _enqueue=self._enqueue_forward_msg,\n            script_requests=self._requests,\n            query_string=\"\",\n            session_state=self._session_state,\n            uploaded_file_mgr=self._uploaded_file_mgr,\n            main_script_path=self._main_script_path,\n            user_info=self._user_info,\n            gather_usage_stats=bool(config.get_option(\"browser.gatherUsageStats\")),\n            fragment_storage=self._fragment_storage,\n            pages_manager=self._pages_manager,\n        )\n        add_script_run_ctx(threading.current_thread(), ctx)\n\n        request = self._requests.on_scriptrunner_ready()\n        while request.type == ScriptRequestType.RERUN:\n            # When the script thread starts, we'll have a pending rerun\n            # request that we'll handle immediately. When the script finishes,\n            # it's possible that another request has come in that we need to\n            # handle, which is why we call _run_script in a loop.\n            self._run_script(request.rerun_data)\n            request = self._requests.on_scriptrunner_ready()\n\n        assert request.type == ScriptRequestType.STOP\n\n        # Send a SHUTDOWN event before exiting, so some state can be saved\n        # for use in a future script run when not triggered by the client.\n        client_state = ClientState()\n        client_state.query_string = ctx.query_string\n        client_state.page_script_hash = ctx.page_script_hash\n        self.on_event.send(\n            self, event=ScriptRunnerEvent.SHUTDOWN, client_state=client_state\n        )\n\n    def _is_in_script_thread(self) -> bool:\n        \"\"\"True if the calling function is running in the script thread\"\"\"\n        return self._script_thread == threading.current_thread()\n\n    def _enqueue_forward_msg(self, msg: ForwardMsg) -> None:\n        \"\"\"Enqueue a ForwardMsg to our browser queue.\n        This private function is called by ScriptRunContext only.\n\n        It may be called from the script thread OR the main thread.\n        \"\"\"\n        # Whenever we enqueue a ForwardMsg, we also handle any pending\n        # execution control request. This means that a script can be\n        # cleanly interrupted and stopped inside most `st.foo` calls.\n        #\n        # (If \"runner.installTracer\" is true, then we'll actually be\n        # handling these requests in a callback called after every Python\n        # instruction instead.)\n        if not config.get_option(\"runner.installTracer\"):\n            self._maybe_handle_execution_control_request()\n\n        # Pass the message to our associated AppSession.\n        self.on_event.send(\n            self, event=ScriptRunnerEvent.ENQUEUE_FORWARD_MSG, forward_msg=msg\n        )\n\n    def _maybe_handle_execution_control_request(self) -> None:\n        \"\"\"Check our current ScriptRequestState to see if we have a\n        pending STOP or RERUN request.\n\n        This function is called every time the app script enqueues a\n        ForwardMsg, which means that most `st.foo` commands - which generally\n        involve sending a ForwardMsg to the frontend - act as implicit\n        yield points in the script's execution.\n        \"\"\"\n        if not self._is_in_script_thread():\n            # We can only handle execution_control_request if we're on the\n            # script execution thread. However, it's possible for deltas to\n            # be enqueued (and, therefore, for this function to be called)\n            # in separate threads, so we check for that here.\n            return\n\n        if not self._execing:\n            # If the _execing flag is not set, we're not actually inside\n            # an exec() call. This happens when our script exec() completes,\n            # we change our state to STOPPED, and a statechange-listener\n            # enqueues a new ForwardEvent\n            return\n\n        request = self._requests.on_scriptrunner_yield()\n        if request is None:\n            # No RERUN or STOP request.\n            return\n\n        if request.type == ScriptRequestType.RERUN:\n            raise RerunException(request.rerun_data)\n\n        assert request.type == ScriptRequestType.STOP\n        raise StopException()\n\n    def _install_tracer(self) -> None:\n        \"\"\"Install function that runs before each line of the script.\"\"\"\n\n        def trace_calls(frame, event, arg):\n            self._maybe_handle_execution_control_request()\n            return trace_calls\n\n        # Python interpreters are not required to implement sys.settrace.\n        if hasattr(sys, \"settrace\"):\n            sys.settrace(trace_calls)\n\n    @contextmanager\n    def _set_execing_flag(self):\n        \"\"\"A context for setting the ScriptRunner._execing flag.\n\n        Used by _maybe_handle_execution_control_request to ensure that\n        we only handle requests while we're inside an exec() call\n        \"\"\"\n        if self._execing:\n            raise RuntimeError(\"Nested set_execing_flag call\")\n        self._execing = True\n        try:\n            yield\n        finally:\n            self._execing = False\n\n    def _run_script(self, rerun_data: RerunData) -> None:\n        \"\"\"Run our script.\n\n        Parameters\n        ----------\n        rerun_data: RerunData\n            The RerunData to use.\n\n        \"\"\"\n\n        assert self._is_in_script_thread()\n\n        # An explicit loop instead of recursion to avoid stack overflows\n        while True:\n            _LOGGER.debug(\"Running script %s\", rerun_data)\n            start_time: float = timer()\n            prep_time: float = 0  # This will be overwritten once preparations are done.\n\n            # Reset DeltaGenerators, widgets, media files.\n            runtime.get_instance().media_file_mgr.clear_session_refs()\n\n            self._pages_manager.set_script_intent(\n                rerun_data.page_script_hash, rerun_data.page_name\n            )\n            active_script = self._pages_manager.get_initial_active_script(\n                rerun_data.page_script_hash, rerun_data.page_name\n            )\n            main_page_info = self._pages_manager.get_main_page()\n            uncaught_exception = None\n\n            page_script_hash = (\n                active_script[\"page_script_hash\"]\n                if active_script is not None\n                else main_page_info[\"page_script_hash\"]\n            )\n\n            fragment_ids_this_run = set(rerun_data.fragment_id_queue)\n\n            ctx = self._get_script_run_ctx()\n            # Clear widget state on page change. This normally happens implicitly\n            # in the script run cleanup steps, but doing it explicitly ensures\n            # it happens even if a script run was interrupted.\n            previous_page_script_hash = ctx.page_script_hash\n            if previous_page_script_hash != page_script_hash:\n                # Page changed, enforce reset widget state where possible.\n                # This enforcement matters when a new script thread is started\n                # before the previous script run is completed (from user\n                # interaction). Use the widget ids from the rerun data to\n                # maintain some widget state, as the rerun data should\n                # contain the latest widget ids from the frontend.\n                widget_ids: set[str] = set()\n\n                if (\n                    rerun_data.widget_states is not None\n                    and rerun_data.widget_states.widgets is not None\n                ):\n                    widget_ids = {w.id for w in rerun_data.widget_states.widgets}\n                self._session_state.on_script_finished(widget_ids)\n\n            ctx.reset(\n                query_string=rerun_data.query_string,\n                page_script_hash=page_script_hash,\n                fragment_ids_this_run=fragment_ids_this_run,\n            )\n            self._pages_manager.reset_active_script_hash()\n\n            self.on_event.send(\n                self,\n                event=ScriptRunnerEvent.SCRIPT_STARTED,\n                page_script_hash=page_script_hash,\n                fragment_ids_this_run=fragment_ids_this_run,\n                pages=self._pages_manager.get_pages(),\n            )\n\n            # Compile the script. Any errors thrown here will be surfaced\n            # to the user via a modal dialog in the frontend, and won't result\n            # in their previous script elements disappearing.\n            try:\n                if active_script is not None:\n                    script_path = active_script[\"script_path\"]\n                else:\n                    # page must not be found\n                    script_path = main_page_info[\"script_path\"]\n\n                    # At this point, we know that either\n                    #   * the script corresponding to the hash requested no longer\n                    #     exists, or\n                    #   * we were not able to find a script with the requested page\n                    #     name.\n                    # In both of these cases, we want to send a page_not_found\n                    # message to the frontend.\n                    msg = ForwardMsg()\n                    msg.page_not_found.page_name = rerun_data.page_name\n                    ctx.enqueue(msg)\n\n                code = self._script_cache.get_bytecode(script_path)\n\n            except Exception as ex:\n                # We got a compile error. Send an error event and bail immediately.\n                _LOGGER.debug(\"Fatal script error: %s\", ex)\n                self._session_state[SCRIPT_RUN_WITHOUT_ERRORS_KEY] = False\n                self.on_event.send(\n                    self,\n                    event=ScriptRunnerEvent.SCRIPT_STOPPED_WITH_COMPILE_ERROR,\n                    exception=ex,\n                )\n                return\n\n            # If we get here, we've successfully compiled our script. The next step\n            # is to run it. Errors thrown during execution will be shown to the\n            # user as ExceptionElements.\n\n            if config.get_option(\"runner.installTracer\"):\n                self._install_tracer()\n\n            # Create fake module. This gives us a name global namespace to\n            # execute the code in.\n            module = self._new_module(\"__main__\")\n\n            # Install the fake module as the __main__ module. This allows\n            # the pickle module to work inside the user's code, since it now\n            # can know the module where the pickled objects stem from.\n            # IMPORTANT: This means we can't use \"if __name__ == '__main__'\" in\n            # our code, as it will point to the wrong module!!!\n            sys.modules[\"__main__\"] = module\n\n            # Add special variables to the module's globals dict.\n            # Note: The following is a requirement for the CodeHasher to\n            # work correctly. The CodeHasher is scoped to\n            # files contained in the directory of __main__.__file__, which we\n            # assume is the main script directory.\n            module.__dict__[\"__file__\"] = script_path\n\n            def code_to_exec(code=code, module=module, ctx=ctx, rerun_data=rerun_data):\n                with modified_sys_path(\n                    self._main_script_path\n                ), self._set_execing_flag():\n                    # Run callbacks for widgets whose values have changed.\n                    if rerun_data.widget_states is not None:\n                        self._session_state.on_script_will_rerun(\n                            rerun_data.widget_states\n                        )\n\n                    ctx.on_script_start()\n\n                    if rerun_data.fragment_id_queue:\n                        for fragment_id in rerun_data.fragment_id_queue:\n                            try:\n                                wrapped_fragment = self._fragment_storage.get(\n                                    fragment_id\n                                )\n                                ctx.current_fragment_id = fragment_id\n                                wrapped_fragment()\n\n                            except KeyError:\n                                raise RuntimeError(\n                                    f\"Could not find fragment with id {fragment_id}\"\n                                )\n                    else:\n                        self._fragment_storage.clear()\n                        exec(code, module.__dict__)\n\n                    self._session_state.maybe_check_serializable()\n                    # check for control requests, e.g. rerun requests have arrived\n                    self._maybe_handle_execution_control_request()\n\n            prep_time = timer() - start_time\n            (\n                _,\n                run_without_errors,\n                rerun_exception_data,\n                premature_stop,\n            ) = exec_func_with_error_handling(code_to_exec, ctx)\n            # setting the session state here triggers a yield-callback call\n            # which reads self._requests and checks for rerun data\n            self._session_state[SCRIPT_RUN_WITHOUT_ERRORS_KEY] = run_without_errors\n\n            if rerun_exception_data:\n                # The handling for when a full script run or a fragment is stopped early\n                # is the same, so we only have one ScriptRunnerEvent for this scenario.\n                finished_event = ScriptRunnerEvent.SCRIPT_STOPPED_FOR_RERUN\n            elif rerun_data.fragment_id_queue:\n                finished_event = ScriptRunnerEvent.FRAGMENT_STOPPED_WITH_SUCCESS\n            else:\n                finished_event = ScriptRunnerEvent.SCRIPT_STOPPED_WITH_SUCCESS\n\n            if ctx.gather_usage_stats:\n                try:\n                    # Prevent issues with circular import\n                    from streamlit.runtime.metrics_util import (\n                        create_page_profile_message,\n                        to_microseconds,\n                    )\n\n                    # Create and send page profile information\n                    ctx.enqueue(\n                        create_page_profile_message(\n                            ctx.tracked_commands,\n                            exec_time=to_microseconds(timer() - start_time),\n                            prep_time=to_microseconds(prep_time),\n                            uncaught_exception=(\n                                type(uncaught_exception).__name__\n                                if uncaught_exception\n                                else None\n                            ),\n                        )\n                    )\n                except Exception as ex:\n                    # Always capture all exceptions since we want to make sure that\n                    # the telemetry never causes any issues.\n                    _LOGGER.debug(\"Failed to create page profile\", exc_info=ex)\n            self._on_script_finished(ctx, finished_event, premature_stop)\n\n            # # Use _log_if_error() to make sure we never ever ever stop running the\n            # # script without meaning to.\n            _log_if_error(_clean_problem_modules)\n\n            if rerun_exception_data is not None:\n                rerun_data = rerun_exception_data\n            else:\n                break\n\n    def _on_script_finished(\n        self, ctx: ScriptRunContext, event: ScriptRunnerEvent, premature_stop: bool\n    ) -> None:\n        \"\"\"Called when our script finishes executing, even if it finished\n        early with an exception. We perform post-run cleanup here.\n        \"\"\"\n        # Tell session_state to update itself in response\n        if not premature_stop:\n            self._session_state.on_script_finished(ctx.widget_ids_this_run)\n\n        # Signal that the script has finished. (We use SCRIPT_STOPPED_WITH_SUCCESS\n        # even if we were stopped with an exception.)\n        self.on_event.send(self, event=event)\n\n        # Remove orphaned files now that the script has run and files in use\n        # are marked as active.\n        runtime.get_instance().media_file_mgr.remove_orphaned_files()\n\n        # Force garbage collection to run, to help avoid memory use building up\n        # This is usually not an issue, but sometimes GC takes time to kick in and\n        # causes apps to go over resource limits, and forcing it to run between\n        # script runs is low cost, since we aren't doing much work anyway.\n        if config.get_option(\"runner.postScriptGC\"):\n            gc.collect(2)\n\n    def _new_module(self, name: str) -> types.ModuleType:\n        \"\"\"Create a new module with the given name.\"\"\"\n        return types.ModuleType(name)\n\n\ndef _clean_problem_modules() -> None:\n    \"\"\"Some modules are stateful, so we have to clear their state.\"\"\"\n\n    if \"keras\" in sys.modules:\n        try:\n            keras = sys.modules[\"keras\"]\n            keras.backend.clear_session()\n        except Exception:\n            # We don't want to crash the app if we can't clear the Keras session.\n            pass\n\n    if \"matplotlib.pyplot\" in sys.modules:\n        try:\n            plt = sys.modules[\"matplotlib.pyplot\"]\n            plt.close(\"all\")\n        except Exception:\n            # We don't want to crash the app if we can't close matplotlib\n            pass\n\n\n# The reason this is not a decorator is because we want to make it clear at the\n# calling location that this function is being used.\ndef _log_if_error(fn: Callable[[], None]) -> None:\n    try:\n        fn()\n    except Exception as e:\n        _LOGGER.warning(e)\n", "lib/streamlit/runtime/scriptrunner/magic_funcs.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom typing import Any\n\nfrom streamlit.runtime.metrics_util import gather_metrics\n\n\n@gather_metrics(\"magic\")\ndef transparent_write(*args: Any) -> Any:\n    \"\"\"The function that gets magic-ified into Streamlit apps.\n    This is just st.write, but returns the arguments you passed to it.\n    \"\"\"\n    import streamlit as st\n\n    st.write(*args)\n    if len(args) == 1:\n        return args[0]\n    return args\n", "lib/streamlit/runtime/scriptrunner/script_run_context.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport collections\nimport threading\nfrom dataclasses import dataclass, field\nfrom typing import TYPE_CHECKING, Callable, Counter, Dict, Final, Union\nfrom urllib import parse\n\nfrom typing_extensions import TypeAlias\n\nfrom streamlit import runtime\nfrom streamlit.errors import StreamlitAPIException\nfrom streamlit.logger import get_logger\n\nif TYPE_CHECKING:\n    from streamlit.cursor import RunningCursor\n    from streamlit.proto.ForwardMsg_pb2 import ForwardMsg\n    from streamlit.proto.PageProfile_pb2 import Command\n    from streamlit.runtime.fragment import FragmentStorage\n    from streamlit.runtime.pages_manager import PagesManager\n    from streamlit.runtime.scriptrunner.script_requests import ScriptRequests\n    from streamlit.runtime.state import SafeSessionState\n    from streamlit.runtime.uploaded_file_manager import UploadedFileManager\n_LOGGER: Final = get_logger(__name__)\n\nUserInfo: TypeAlias = Dict[str, Union[str, None]]\n\n\n@dataclass\nclass ScriptRunContext:\n    \"\"\"A context object that contains data for a \"script run\" - that is,\n    data that's scoped to a single ScriptRunner execution (and therefore also\n    scoped to a single connected \"session\").\n\n    ScriptRunContext is used internally by virtually every `st.foo()` function.\n    It is accessed only from the script thread that's created by ScriptRunner,\n    or from app-created helper threads that have been \"attached\" to the\n    ScriptRunContext via `add_script_run_ctx`.\n\n    Streamlit code typically retrieves the active ScriptRunContext via the\n    `get_script_run_ctx` function.\n    \"\"\"\n\n    session_id: str\n    _enqueue: Callable[[ForwardMsg], None]\n    query_string: str\n    session_state: SafeSessionState\n    uploaded_file_mgr: UploadedFileManager\n    main_script_path: str\n    user_info: UserInfo\n    fragment_storage: FragmentStorage\n    pages_manager: PagesManager\n\n    gather_usage_stats: bool = False\n    command_tracking_deactivated: bool = False\n    tracked_commands: list[Command] = field(default_factory=list)\n    tracked_commands_counter: Counter[str] = field(default_factory=collections.Counter)\n    _set_page_config_allowed: bool = True\n    _has_script_started: bool = False\n    widget_ids_this_run: set[str] = field(default_factory=set)\n    widget_user_keys_this_run: set[str] = field(default_factory=set)\n    form_ids_this_run: set[str] = field(default_factory=set)\n    cursors: dict[int, RunningCursor] = field(default_factory=dict)\n    script_requests: ScriptRequests | None = None\n    current_fragment_id: str | None = None\n    fragment_ids_this_run: set[str] | None = None\n    # we allow only one dialog to be open at the same time\n    has_dialog_opened: bool = False\n    # If true, it indicates that we are in a cached function that disallows\n    # the usage of widgets.\n    disallow_cached_widget_usage: bool = False\n\n    # TODO(willhuang1997): Remove this variable when experimental query params are removed\n    _experimental_query_params_used = False\n    _production_query_params_used = False\n\n    @property\n    def page_script_hash(self):\n        return self.pages_manager.get_current_page_script_hash()\n\n    @property\n    def active_script_hash(self):\n        return self.pages_manager.get_active_script_hash()\n\n    def reset(\n        self,\n        query_string: str = \"\",\n        page_script_hash: str = \"\",\n        fragment_ids_this_run: set[str] | None = None,\n    ) -> None:\n        self.cursors = {}\n        self.widget_ids_this_run = set()\n        self.widget_user_keys_this_run = set()\n        self.form_ids_this_run = set()\n        self.query_string = query_string\n        self.pages_manager.set_current_page_script_hash(page_script_hash)\n        # Permit set_page_config when the ScriptRunContext is reused on a rerun\n        self._set_page_config_allowed = True\n        self._has_script_started = False\n        self.command_tracking_deactivated: bool = False\n        self.tracked_commands = []\n        self.tracked_commands_counter = collections.Counter()\n        self.current_fragment_id = None\n        self.current_fragment_delta_path: list[int] = []\n        self.fragment_ids_this_run = fragment_ids_this_run\n        self.has_dialog_opened = False\n        self.disallow_cached_widget_usage = False\n\n        parsed_query_params = parse.parse_qs(query_string, keep_blank_values=True)\n        with self.session_state.query_params() as qp:\n            qp.clear_with_no_forward_msg()\n            for key, val in parsed_query_params.items():\n                if len(val) == 0:\n                    qp.set_with_no_forward_msg(key, val=\"\")\n                elif len(val) == 1:\n                    qp.set_with_no_forward_msg(key, val=val[-1])\n                else:\n                    qp.set_with_no_forward_msg(key, val)\n\n    def on_script_start(self) -> None:\n        self._has_script_started = True\n\n    def enqueue(self, msg: ForwardMsg) -> None:\n        \"\"\"Enqueue a ForwardMsg for this context's session.\"\"\"\n        if msg.HasField(\"page_config_changed\") and not self._set_page_config_allowed:\n            raise StreamlitAPIException(\n                \"`set_page_config()` can only be called once per app page, \"\n                \"and must be called as the first Streamlit command in your script.\\n\\n\"\n                \"For more information refer to the [docs]\"\n                \"(https://docs.streamlit.io/develop/api-reference/configuration/st.set_page_config).\"\n            )\n\n        # We want to disallow set_page config if one of the following occurs:\n        # - set_page_config was called on this message\n        # - The script has already started and a different st call occurs (a delta)\n        if msg.HasField(\"page_config_changed\") or (\n            msg.HasField(\"delta\") and self._has_script_started\n        ):\n            self._set_page_config_allowed = False\n\n        msg.metadata.active_script_hash = self.active_script_hash\n\n        # Pass the message up to our associated ScriptRunner.\n        self._enqueue(msg)\n\n    def ensure_single_query_api_used(self):\n        if self._experimental_query_params_used and self._production_query_params_used:\n            raise StreamlitAPIException(\n                \"Using `st.query_params` together with either `st.experimental_get_query_params` \"\n                \"or `st.experimental_set_query_params` is not supported. Please convert your app \"\n                \"to only use `st.query_params`\"\n            )\n\n    def mark_experimental_query_params_used(self):\n        self._experimental_query_params_used = True\n        self.ensure_single_query_api_used()\n\n    def mark_production_query_params_used(self):\n        self._production_query_params_used = True\n        self.ensure_single_query_api_used()\n\n\nSCRIPT_RUN_CONTEXT_ATTR_NAME: Final = \"streamlit_script_run_ctx\"\n\n\ndef add_script_run_ctx(\n    thread: threading.Thread | None = None, ctx: ScriptRunContext | None = None\n):\n    \"\"\"Adds the current ScriptRunContext to a newly-created thread.\n\n    This should be called from this thread's parent thread,\n    before the new thread starts.\n\n    Parameters\n    ----------\n    thread : threading.Thread\n        The thread to attach the current ScriptRunContext to.\n    ctx : ScriptRunContext or None\n        The ScriptRunContext to add, or None to use the current thread's\n        ScriptRunContext.\n\n    Returns\n    -------\n    threading.Thread\n        The same thread that was passed in, for chaining.\n\n    \"\"\"\n    if thread is None:\n        thread = threading.current_thread()\n    if ctx is None:\n        ctx = get_script_run_ctx()\n    if ctx is not None:\n        setattr(thread, SCRIPT_RUN_CONTEXT_ATTR_NAME, ctx)\n    return thread\n\n\ndef get_script_run_ctx(suppress_warning: bool = False) -> ScriptRunContext | None:\n    \"\"\"\n    Parameters\n    ----------\n    suppress_warning : bool\n        If True, don't log a warning if there's no ScriptRunContext.\n    Returns\n    -------\n    ScriptRunContext | None\n        The current thread's ScriptRunContext, or None if it doesn't have one.\n\n    \"\"\"\n    thread = threading.current_thread()\n    ctx: ScriptRunContext | None = getattr(thread, SCRIPT_RUN_CONTEXT_ATTR_NAME, None)\n    if ctx is None and runtime.exists() and not suppress_warning:\n        # Only warn about a missing ScriptRunContext if suppress_warning is False, and\n        # we were started via `streamlit run`. Otherwise, the user is likely running a\n        # script \"bare\", and doesn't need to be warned about streamlit\n        # bits that are irrelevant when not connected to a session.\n        _LOGGER.warning(\"Thread '%s': missing ScriptRunContext\", thread.name)\n\n    return ctx\n\n\n# Needed to avoid circular dependencies while running tests.\nimport streamlit  # noqa: E402, F401\n", "lib/streamlit/runtime/scriptrunner/exceptions.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom streamlit.runtime.scriptrunner.script_requests import RerunData\nfrom streamlit.util import repr_\n\n\nclass ScriptControlException(Exception):\n    \"\"\"Base exception for ScriptRunner.\"\"\"\n\n    pass\n\n\nclass StopException(ScriptControlException):\n    \"\"\"Silently stop the execution of the user's script.\"\"\"\n\n    pass\n\n\nclass RerunException(ScriptControlException):\n    \"\"\"Silently stop and rerun the user's script.\"\"\"\n\n    def __init__(self, rerun_data: RerunData):\n        \"\"\"Construct a RerunException\n\n        Parameters\n        ----------\n        rerun_data : RerunData\n            The RerunData that should be used to rerun the script\n        \"\"\"\n        self.rerun_data = rerun_data\n\n    def __repr__(self) -> str:\n        return repr_(self)\n", "lib/streamlit/runtime/scriptrunner/exec_code.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom typing import TYPE_CHECKING, Any, Callable\n\nfrom streamlit.error_util import handle_uncaught_app_exception\nfrom streamlit.runtime.scriptrunner.exceptions import RerunException, StopException\n\nif TYPE_CHECKING:\n    from streamlit.runtime.scriptrunner.script_requests import RerunData\n    from streamlit.runtime.scriptrunner.script_run_context import ScriptRunContext\n\n\ndef exec_func_with_error_handling(\n    func: Callable[[], None],\n    ctx: ScriptRunContext,\n    *,\n    reraise_rerun_exception: bool = False,\n) -> tuple[Any | None, bool, RerunData | None, bool]:\n    \"\"\"Execute the passed function wrapped in a try/except block.\n\n    This function is called by the script runner to execute the user's script or\n    fragment reruns, but also for the execution of fragment code in context of a normal\n    app run. This wrapper ensures that handle_uncaught_exception messages show up in the\n    correct context.\n\n    Parameters\n    ----------\n    func : callable\n        The function to execute wrapped in the try/except block.\n    ctx : ScriptRunContext\n        The context in which the script is being run.\n    reraise_rerun_exception : bool, default False\n        If True, an occuring RerunException will be raised instead of handled. This can\n        be used if this function is called outside of the script_run context and we want\n        the script_runner to react on the rerun exception.\n\n    Returns\n    -------\n    tuple\n        A tuple containing:\n        - The result of the passed function.\n        - A boolean indicating whether the script ran without errors (RerunException and\n            StopException don't count as errors).\n        - The RerunData instance belonging to a RerunException if the script was\n            interrupted by a RerunException.\n        - A boolean indicating whether the script was stopped prematurely (False for\n            RerunExceptions, True for all other exceptions).\n    \"\"\"\n\n    # Avoid circular imports\n    from streamlit.delta_generator import dg_stack, get_default_dg_stack\n\n    run_without_errors = True\n\n    # This will be set to a RerunData instance if our execution\n    # is interrupted by a RerunException.\n    rerun_exception_data: RerunData | None = None\n\n    # Saving and restoring our original cursors/dg_stack is needed\n    # specifically to handle the case where a RerunException is raised while\n    # running a fragment. In this case, we need to restore both to their states\n    # at the start of the script run to ensure that we write to the correct\n    # places in the app during the rerun (without this, ctx.cursors and dg_stack\n    # will still be set to the snapshots they were restored from when running\n    # the fragment).\n    original_cursors = ctx.cursors\n    original_dg_stack = dg_stack.get()\n\n    # If the script stops early, we don't want to remove unseen widgets,\n    # so we track this to potentially skip session state cleanup later.\n    premature_stop: bool = False\n\n    # The result of the passed function\n    result: Any | None = None\n\n    try:\n        result = func()\n    except RerunException as e:\n        if reraise_rerun_exception:\n            raise e\n\n        rerun_exception_data = e.rerun_data\n        if rerun_exception_data.fragment_id_queue:\n            # This is a fragment-specific rerun, so we need to restore the stack\n            ctx.cursors = original_cursors\n            dg_stack.set(original_dg_stack)\n        else:\n            # If it is a full-app rerun, the stack needs to be refreshed.\n            # We should land here when `st.rerun` is called from within a\n            # fragment. Since we re-use the same thread, we have to clear the\n            # stack or otherwise we might render the main app in the old\n            # fragment's dg_stack.\n            ctx.cursors.clear()\n            dg_stack.set(get_default_dg_stack())\n        # Interruption due to a rerun is usually from `st.rerun()`, which\n        # we want to count as a script completion so triggers reset.\n        # It is also possible for this to happen if fast reruns is off,\n        # but this is very rare.\n        premature_stop = False\n\n    except StopException:\n        # This is thrown when the script executes `st.stop()`.\n        # We don't have to do anything here.\n        premature_stop = True\n\n    except Exception as ex:\n        run_without_errors = False\n        uncaught_exception = ex\n        handle_uncaught_app_exception(uncaught_exception)\n        premature_stop = True\n\n    return result, run_without_errors, rerun_exception_data, premature_stop\n", "lib/streamlit/runtime/scriptrunner/script_cache.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport os.path\nimport threading\nfrom typing import Any\n\nfrom streamlit import config\nfrom streamlit.runtime.scriptrunner import magic\nfrom streamlit.source_util import open_python_file\n\n\nclass ScriptCache:\n    \"\"\"Thread-safe cache of Python script bytecode.\"\"\"\n\n    def __init__(self):\n        # Mapping of script_path: bytecode\n        self._cache: dict[str, Any] = {}\n        self._lock = threading.Lock()\n\n    def clear(self) -> None:\n        \"\"\"Remove all entries from the cache.\n\n        Notes\n        -----\n        Threading: SAFE. May be called on any thread.\n        \"\"\"\n        with self._lock:\n            self._cache.clear()\n\n    def get_bytecode(self, script_path: str) -> Any:\n        \"\"\"Return the bytecode for the Python script at the given path.\n\n        If the bytecode is not already in the cache, the script will be\n        compiled first.\n\n        Raises\n        ------\n        Any Exception raised while reading or compiling the script.\n\n        Notes\n        -----\n        Threading: SAFE. May be called on any thread.\n        \"\"\"\n\n        script_path = os.path.abspath(script_path)\n\n        with self._lock:\n            bytecode = self._cache.get(script_path, None)\n            if bytecode is not None:\n                # Fast path: the code is already cached.\n                return bytecode\n\n            # Populate the cache\n            with open_python_file(script_path) as f:\n                filebody = f.read()\n\n            if config.get_option(\"runner.magicEnabled\"):\n                filebody = magic.add_magic(filebody, script_path)\n\n            bytecode = compile(  # type: ignore\n                filebody,\n                # Pass in the file path so it can show up in exceptions.\n                script_path,\n                # We're compiling entire blocks of Python, so we need \"exec\"\n                # mode (as opposed to \"eval\" or \"single\").\n                mode=\"exec\",\n                # Don't inherit any flags or \"future\" statements.\n                flags=0,\n                dont_inherit=1,\n                # Use the default optimization options.\n                optimize=-1,\n            )\n\n            self._cache[script_path] = bytecode\n            return bytecode\n", "lib/streamlit/runtime/scriptrunner/magic.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport ast\nfrom typing import Any, Final\n\nfrom streamlit import config\n\n# When a Streamlit app is magicified, we insert a `magic_funcs` import near the top of\n# its module's AST:\n# import streamlit.runtime.scriptrunner.magic_funcs as __streamlitmagic__\nMAGIC_MODULE_NAME: Final = \"__streamlitmagic__\"\n\n\ndef add_magic(code: str, script_path: str) -> Any:\n    \"\"\"Modifies the code to support magic Streamlit commands.\n\n    Parameters\n    ----------\n    code : str\n        The Python code.\n    script_path : str\n        The path to the script file.\n\n    Returns\n    -------\n    ast.Module\n        The syntax tree for the code.\n\n    \"\"\"\n    # Pass script_path so we get pretty exceptions.\n    tree = ast.parse(code, script_path, \"exec\")\n\n    file_ends_in_semicolon = _does_file_end_in_semicolon(tree, code)\n\n    return _modify_ast_subtree(\n        tree, is_root=True, file_ends_in_semicolon=file_ends_in_semicolon\n    )\n\n\ndef _modify_ast_subtree(\n    tree: Any,\n    body_attr: str = \"body\",\n    is_root: bool = False,\n    file_ends_in_semicolon: bool = False,\n):\n    \"\"\"Parses magic commands and modifies the given AST (sub)tree.\"\"\"\n\n    body = getattr(tree, body_attr)\n\n    for i, node in enumerate(body):\n        node_type = type(node)\n\n        # Recursively parses the content of the statements\n        # `with`, `for` and `while`, as well as function definitions.\n        # Also covers their async counterparts\n        if (\n            node_type is ast.FunctionDef\n            or node_type is ast.With\n            or node_type is ast.For\n            or node_type is ast.While\n            or node_type is ast.AsyncFunctionDef\n            or node_type is ast.AsyncWith\n            or node_type is ast.AsyncFor\n        ):\n            _modify_ast_subtree(node)\n\n        # Recursively parses methods in a class.\n        elif node_type is ast.ClassDef:\n            for inner_node in node.body:\n                if type(inner_node) in {ast.FunctionDef, ast.AsyncFunctionDef}:\n                    _modify_ast_subtree(inner_node)\n\n        # Recursively parses the contents of try statements,\n        # all their handlers (except and else) and the finally body\n        elif node_type is ast.Try:\n            for j, inner_node in enumerate(node.handlers):\n                node.handlers[j] = _modify_ast_subtree(inner_node)\n            finally_node = _modify_ast_subtree(node, body_attr=\"finalbody\")\n            node.finalbody = finally_node.finalbody\n            _modify_ast_subtree(node)\n\n        # Recursively parses if blocks, as well as their else/elif blocks\n        # (else/elif are both mapped to orelse)\n        # it intentionally does not parse the test expression.\n        elif node_type is ast.If:\n            _modify_ast_subtree(node)\n            _modify_ast_subtree(node, \"orelse\")\n\n        # Convert standalone expression nodes to st.write\n        elif node_type is ast.Expr:\n            value = _get_st_write_from_expr(\n                node,\n                i,\n                parent_type=type(tree),\n                is_root=is_root,\n                is_last_expr=(i == len(body) - 1),\n                file_ends_in_semicolon=file_ends_in_semicolon,\n            )\n            if value is not None:\n                node.value = value\n\n    if is_root:\n        # Import Streamlit so we can use it in the new_value above.\n        _insert_import_statement(tree)\n\n    ast.fix_missing_locations(tree)\n\n    return tree\n\n\ndef _insert_import_statement(tree: Any) -> None:\n    \"\"\"Insert Streamlit import statement at the top(ish) of the tree.\"\"\"\n\n    st_import = _build_st_import_statement()\n\n    # If the 0th node is already an import statement, put the Streamlit\n    # import below that, so we don't break \"from __future__ import\".\n    if tree.body and type(tree.body[0]) in {ast.ImportFrom, ast.Import}:\n        tree.body.insert(1, st_import)\n\n    # If the 0th node is a docstring and the 1st is an import statement,\n    # put the Streamlit import below those, so we don't break \"from\n    # __future__ import\".\n    elif (\n        len(tree.body) > 1\n        and (\n            type(tree.body[0]) is ast.Expr\n            and _is_string_constant_node(tree.body[0].value)\n        )\n        and type(tree.body[1]) in {ast.ImportFrom, ast.Import}\n    ):\n        tree.body.insert(2, st_import)\n\n    else:\n        tree.body.insert(0, st_import)\n\n\ndef _build_st_import_statement():\n    \"\"\"Build AST node for `import magic_funcs as __streamlitmagic__`.\"\"\"\n    return ast.Import(\n        names=[\n            ast.alias(\n                name=\"streamlit.runtime.scriptrunner.magic_funcs\",\n                asname=MAGIC_MODULE_NAME,\n            )\n        ]\n    )\n\n\ndef _build_st_write_call(nodes):\n    \"\"\"Build AST node for `__streamlitmagic__.transparent_write(*nodes)`.\"\"\"\n    return ast.Call(\n        func=ast.Attribute(\n            attr=\"transparent_write\",\n            value=ast.Name(id=MAGIC_MODULE_NAME, ctx=ast.Load()),\n            ctx=ast.Load(),\n        ),\n        args=nodes,\n        keywords=[],\n    )\n\n\ndef _get_st_write_from_expr(\n    node, i, parent_type, is_root, is_last_expr, file_ends_in_semicolon\n):\n    # Don't wrap function calls\n    # (Unless the function call happened at the end of the root node, AND\n    # magic.displayLastExprIfNoSemicolon is True. This allows us to support notebook-like\n    # behavior, where we display the last function in a cell)\n    if type(node.value) is ast.Call and not _is_displayable_last_expr(\n        is_root, is_last_expr, file_ends_in_semicolon\n    ):\n        return None\n\n    # Don't wrap DocString nodes\n    # (Unless magic.displayRootDocString, in which case we do wrap the root-level\n    # docstring with st.write. This allows us to support notebook-like behavior\n    # where you can have a cell with a markdown string)\n    if _is_docstring_node(\n        node.value, i, parent_type\n    ) and not _should_display_docstring_like_node_anyway(is_root):\n        return None\n\n    # Don't wrap yield nodes\n    if type(node.value) is ast.Yield or type(node.value) is ast.YieldFrom:\n        return None\n\n    # Don't wrap await nodes\n    if type(node.value) is ast.Await:\n        return None\n\n    # If tuple, call st.write(*the_tuple). This allows us to add a comma at the end of a\n    # statement to turn it into an expression that should be st-written. Ex:\n    # \"np.random.randn(1000, 2),\"\n    if type(node.value) is ast.Tuple:\n        args = node.value.elts\n        st_write = _build_st_write_call(args)\n\n    # st.write all strings.\n    elif type(node.value) is ast.Str:\n        args = [node.value]\n        st_write = _build_st_write_call(args)\n\n    # st.write all variables.\n    elif type(node.value) is ast.Name:\n        args = [node.value]\n        st_write = _build_st_write_call(args)\n\n    # st.write everything else\n    else:\n        args = [node.value]\n        st_write = _build_st_write_call(args)\n\n    return st_write\n\n\ndef _is_string_constant_node(node) -> bool:\n    return isinstance(node, ast.Constant) and isinstance(node.value, str)\n\n\ndef _is_docstring_node(node, node_index, parent_type) -> bool:\n    return (\n        node_index == 0\n        and _is_string_constant_node(node)\n        and parent_type in {ast.FunctionDef, ast.AsyncFunctionDef, ast.Module}\n    )\n\n\ndef _does_file_end_in_semicolon(tree, code: str) -> bool:\n    file_ends_in_semicolon = False\n\n    # Avoid spending time with this operation if magic.displayLastExprIfNoSemicolon is\n    # not set.\n    if config.get_option(\"magic.displayLastExprIfNoSemicolon\"):\n        last_line_num = getattr(tree.body[-1], \"end_lineno\", None)\n\n        if last_line_num is not None:\n            last_line_str: str = code.split(\"\\n\")[last_line_num - 1]\n            file_ends_in_semicolon = last_line_str.strip(\" \").endswith(\";\")\n\n    return file_ends_in_semicolon\n\n\ndef _is_displayable_last_expr(\n    is_root: bool, is_last_expr: bool, file_ends_in_semicolon: bool\n) -> bool:\n    return (\n        # This is a \"displayable last expression\" if...\n        # ...it's actually the last expression...\n        is_last_expr\n        # ...in the root scope...\n        and is_root\n        # ...it does not end in a semicolon...\n        and not file_ends_in_semicolon\n        # ...and this config option is telling us to show it\n        and config.get_option(\"magic.displayLastExprIfNoSemicolon\")\n    )\n\n\ndef _should_display_docstring_like_node_anyway(is_root: bool) -> bool:\n    return config.get_option(\"magic.displayRootDocString\") and is_root\n", "lib/streamlit/runtime/scriptrunner/script_requests.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport threading\nfrom dataclasses import dataclass, field\nfrom enum import Enum\nfrom typing import TYPE_CHECKING, cast\n\nfrom streamlit import util\nfrom streamlit.runtime.state import coalesce_widget_states\n\nif TYPE_CHECKING:\n    from streamlit.proto.WidgetStates_pb2 import WidgetStates\n\n\nclass ScriptRequestType(Enum):\n    # The ScriptRunner should continue running its script.\n    CONTINUE = \"CONTINUE\"\n\n    # If the script is running, it should be stopped as soon\n    # as the ScriptRunner reaches an interrupt point.\n    # This is a terminal state.\n    STOP = \"STOP\"\n\n    # A script rerun has been requested. The ScriptRunner should\n    # handle this request as soon as it reaches an interrupt point.\n    RERUN = \"RERUN\"\n\n\n@dataclass(frozen=True)\nclass RerunData:\n    \"\"\"Data attached to RERUN requests. Immutable.\"\"\"\n\n    query_string: str = \"\"\n    widget_states: WidgetStates | None = None\n    page_script_hash: str = \"\"\n    page_name: str = \"\"\n    fragment_id_queue: list[str] = field(default_factory=list)\n\n    def __repr__(self) -> str:\n        return util.repr_(self)\n\n\n@dataclass(frozen=True)\nclass ScriptRequest:\n    \"\"\"A STOP or RERUN request and associated data.\"\"\"\n\n    type: ScriptRequestType\n    _rerun_data: RerunData | None = None\n\n    @property\n    def rerun_data(self) -> RerunData:\n        if self.type is not ScriptRequestType.RERUN:\n            raise RuntimeError(\"RerunData is only set for RERUN requests.\")\n        return cast(RerunData, self._rerun_data)\n\n    def __repr__(self) -> str:\n        return util.repr_(self)\n\n\nclass ScriptRequests:\n    \"\"\"An interface for communicating with a ScriptRunner. Thread-safe.\n\n    AppSession makes requests of a ScriptRunner through this class, and\n    ScriptRunner handles those requests.\n    \"\"\"\n\n    def __init__(self):\n        self._lock = threading.Lock()\n        self._state = ScriptRequestType.CONTINUE\n        self._rerun_data = RerunData()\n\n    def request_stop(self) -> None:\n        \"\"\"Request that the ScriptRunner stop running. A stopped ScriptRunner\n        can't be used anymore. STOP requests succeed unconditionally.\n        \"\"\"\n        with self._lock:\n            self._state = ScriptRequestType.STOP\n\n    def request_rerun(self, new_data: RerunData) -> bool:\n        \"\"\"Request that the ScriptRunner rerun its script.\n\n        If the ScriptRunner has been stopped, this request can't be honored:\n        return False.\n\n        Otherwise, record the request and return True. The ScriptRunner will\n        handle the rerun request as soon as it reaches an interrupt point.\n        \"\"\"\n\n        with self._lock:\n            if self._state == ScriptRequestType.STOP:\n                # We can't rerun after being stopped.\n                return False\n\n            if self._state == ScriptRequestType.CONTINUE:\n                # The script is currently running, and we haven't received a request to\n                # rerun it as of yet. We can handle a rerun request unconditionally so\n                # just change self._state and set self._rerun_data.\n                self._state = ScriptRequestType.RERUN\n                self._rerun_data = new_data\n                return True\n\n            if self._state == ScriptRequestType.RERUN:\n                # We already have an existing Rerun request, so we can coalesce the new\n                # rerun request into the existing one.\n\n                coalesced_states = coalesce_widget_states(\n                    self._rerun_data.widget_states, new_data.widget_states\n                )\n\n                if new_data.fragment_id_queue:\n                    # This RERUN request corresponds to a fragment run. We append the\n                    # new fragment ID to the end of the current fragment_id_queue if it\n                    # isn't already contained in it.\n                    fragment_id_queue = [*self._rerun_data.fragment_id_queue]\n                    if (\n                        # new_data.fragment_id_queue is always a singleton\n                        (new_fragment_id := new_data.fragment_id_queue[0])\n                        not in fragment_id_queue\n                    ):\n                        fragment_id_queue.append(new_fragment_id)\n                else:\n                    # Otherwise, this is a request to rerun the full script, so we want\n                    # to clear out any fragments we have queued to run since they'll all\n                    # be run with the full script anyway.\n                    fragment_id_queue = []\n\n                self._rerun_data = RerunData(\n                    query_string=new_data.query_string,\n                    widget_states=coalesced_states,\n                    page_script_hash=new_data.page_script_hash,\n                    page_name=new_data.page_name,\n                    fragment_id_queue=fragment_id_queue,\n                )\n\n                return True\n\n            # We'll never get here\n            raise RuntimeError(f\"Unrecognized ScriptRunnerState: {self._state}\")\n\n    def on_scriptrunner_yield(self) -> ScriptRequest | None:\n        \"\"\"Called by the ScriptRunner when it's at a yield point.\n\n        If we have no request or a RERUN request corresponding to one or more fragments,\n        return None.\n\n        If we have a (full script) RERUN request, return the request and set our internal\n        state to CONTINUE.\n\n        If we have a STOP request, return the request and remain stopped.\n        \"\"\"\n        if self._state == ScriptRequestType.CONTINUE or (\n            # Reruns corresponding to fragments should *not* cancel the current script\n            # run as doing so will affect elements outside of the fragment.\n            self._state == ScriptRequestType.RERUN\n            and self._rerun_data.fragment_id_queue\n        ):\n            # We avoid taking the lock in the common cases of having no request and\n            # having a RERUN request corresponding to >=1 fragments. If a STOP or\n            # (full script) RERUN request is received between the `if` and `return`, it\n            # will be handled at the next `on_scriptrunner_yield`, or when\n            # `on_scriptrunner_ready` is called.\n            return None\n\n        with self._lock:\n            if self._state == ScriptRequestType.RERUN:\n                if self._rerun_data.fragment_id_queue:\n                    return None\n\n                self._state = ScriptRequestType.CONTINUE\n                return ScriptRequest(ScriptRequestType.RERUN, self._rerun_data)\n\n            assert self._state == ScriptRequestType.STOP\n            return ScriptRequest(ScriptRequestType.STOP)\n\n    def on_scriptrunner_ready(self) -> ScriptRequest:\n        \"\"\"Called by the ScriptRunner when it's about to run its script for\n        the first time, and also after its script has successfully completed.\n\n        If we have a RERUN request, return the request and set\n        our internal state to CONTINUE.\n\n        If we have a STOP request or no request, set our internal state\n        to STOP.\n        \"\"\"\n        with self._lock:\n            if self._state == ScriptRequestType.RERUN:\n                self._state = ScriptRequestType.CONTINUE\n                return ScriptRequest(ScriptRequestType.RERUN, self._rerun_data)\n\n            # If we don't have a rerun request, unconditionally change our\n            # state to STOP.\n            self._state = ScriptRequestType.STOP\n            return ScriptRequest(ScriptRequestType.STOP)\n", "lib/streamlit/runtime/scriptrunner/__init__.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom streamlit.runtime.scriptrunner.exceptions import RerunException, StopException\nfrom streamlit.runtime.scriptrunner.script_requests import RerunData\nfrom streamlit.runtime.scriptrunner.script_run_context import (\n    ScriptRunContext,\n    add_script_run_ctx,\n    get_script_run_ctx,\n)\nfrom streamlit.runtime.scriptrunner.script_runner import ScriptRunner, ScriptRunnerEvent\n\n__all__ = [\n    \"RerunData\",\n    \"ScriptRunContext\",\n    \"add_script_run_ctx\",\n    \"get_script_run_ctx\",\n    \"RerunException\",\n    \"ScriptRunner\",\n    \"ScriptRunnerEvent\",\n    \"StopException\",\n]\n", "lib/streamlit/runtime/caching/cache_utils.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Common cache logic shared by st.cache_data and st.cache_resource.\"\"\"\n\nfrom __future__ import annotations\n\nimport functools\nimport hashlib\nimport inspect\nimport threading\nimport time\nfrom abc import abstractmethod\nfrom collections import defaultdict\nfrom typing import TYPE_CHECKING, Any, Callable, Final\n\nfrom streamlit import type_util\nfrom streamlit.elements.spinner import spinner\nfrom streamlit.logger import get_logger\nfrom streamlit.runtime.caching.cache_errors import (\n    CacheError,\n    CacheKeyNotFoundError,\n    UnevaluatedDataFrameError,\n    UnhashableParamError,\n    UnhashableTypeError,\n    UnserializableReturnValueError,\n    get_cached_func_name_md,\n)\nfrom streamlit.runtime.caching.cached_message_replay import (\n    CachedMessageReplayContext,\n    CachedResult,\n    MsgData,\n    replay_cached_messages,\n)\nfrom streamlit.runtime.caching.hashing import HashFuncsDict, update_hash\nfrom streamlit.type_util import UNEVALUATED_DATAFRAME_TYPES\nfrom streamlit.util import HASHLIB_KWARGS\n\nif TYPE_CHECKING:\n    from types import FunctionType\n\n    from streamlit.runtime.caching.cache_type import CacheType\n\n_LOGGER: Final = get_logger(__name__)\n\n# The timer function we use with TTLCache. This is the default timer func, but\n# is exposed here as a constant so that it can be patched in unit tests.\nTTLCACHE_TIMER = time.monotonic\n\n\nclass Cache:\n    \"\"\"Function cache interface. Caches persist across script runs.\"\"\"\n\n    def __init__(self):\n        self._value_locks: dict[str, threading.Lock] = defaultdict(threading.Lock)\n        self._value_locks_lock = threading.Lock()\n\n    @abstractmethod\n    def read_result(self, value_key: str) -> CachedResult:\n        \"\"\"Read a value and associated messages from the cache.\n\n        Raises\n        ------\n        CacheKeyNotFoundError\n            Raised if value_key is not in the cache.\n\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def write_result(self, value_key: str, value: Any, messages: list[MsgData]) -> None:\n        \"\"\"Write a value and associated messages to the cache, overwriting any existing\n        result that uses the value_key.\n        \"\"\"\n        # We *could* `del self._value_locks[value_key]` here, since nobody will be taking\n        # a compute_value_lock for this value_key after the result is written.\n        raise NotImplementedError\n\n    def compute_value_lock(self, value_key: str) -> threading.Lock:\n        \"\"\"Return the lock that should be held while computing a new cached value.\n        In a popular app with a cache that hasn't been pre-warmed, many sessions may try\n        to access a not-yet-cached value simultaneously. We use a lock to ensure that\n        only one of those sessions computes the value, and the others block until\n        the value is computed.\n        \"\"\"\n        with self._value_locks_lock:\n            return self._value_locks[value_key]\n\n    def clear(self, key: str | None = None):\n        \"\"\"Clear values from this cache.\n        If no argument is passed, all items are cleared from the cache.\n        A key can be passed to clear that key from the cache only.\"\"\"\n        with self._value_locks_lock:\n            if not key:\n                self._value_locks.clear()\n            elif key in self._value_locks:\n                del self._value_locks[key]\n        self._clear(key=key)\n\n    @abstractmethod\n    def _clear(self, key: str | None = None) -> None:\n        \"\"\"Subclasses must implement this to perform cache-clearing logic.\"\"\"\n        raise NotImplementedError\n\n\nclass CachedFuncInfo:\n    \"\"\"Encapsulates data for a cached function instance.\n\n    CachedFuncInfo instances are scoped to a single script run - they're not\n    persistent.\n    \"\"\"\n\n    def __init__(\n        self,\n        func: FunctionType,\n        show_spinner: bool | str,\n        allow_widgets: bool,\n        hash_funcs: HashFuncsDict | None,\n    ):\n        self.func = func\n        self.show_spinner = show_spinner\n        self.allow_widgets = allow_widgets\n        self.hash_funcs = hash_funcs\n\n    @property\n    def cache_type(self) -> CacheType:\n        raise NotImplementedError\n\n    @property\n    def cached_message_replay_ctx(self) -> CachedMessageReplayContext:\n        raise NotImplementedError\n\n    def get_function_cache(self, function_key: str) -> Cache:\n        \"\"\"Get or create the function cache for the given key.\"\"\"\n        raise NotImplementedError\n\n\ndef make_cached_func_wrapper(info: CachedFuncInfo) -> Callable[..., Any]:\n    \"\"\"Create a callable wrapper around a CachedFunctionInfo.\n\n    Calling the wrapper will return the cached value if it's already been\n    computed, and will call the underlying function to compute and cache the\n    value otherwise.\n\n    The wrapper also has a `clear` function that can be called to clear\n    some or all of the wrapper's cached values.\n    \"\"\"\n    cached_func = CachedFunc(info)\n\n    # We'd like to simply return `cached_func`, which is already a Callable.\n    # But using `functools.update_wrapper` on the CachedFunc instance\n    # itself results in errors when our caching decorators are used to decorate\n    # member functions. (See https://github.com/streamlit/streamlit/issues/6109)\n\n    @functools.wraps(info.func)\n    def wrapper(*args, **kwargs):\n        return cached_func(*args, **kwargs)\n\n    # Give our wrapper its `clear` function.\n    # (This results in a spurious mypy error that we suppress.)\n    wrapper.clear = cached_func.clear  # type: ignore\n\n    return wrapper\n\n\nclass CachedFunc:\n    def __init__(self, info: CachedFuncInfo):\n        self._info = info\n        self._function_key = _make_function_key(info.cache_type, info.func)\n\n    def __call__(self, *args, **kwargs) -> Any:\n        \"\"\"The wrapper. We'll only call our underlying function on a cache miss.\"\"\"\n\n        name = self._info.func.__qualname__\n\n        if isinstance(self._info.show_spinner, bool):\n            if len(args) == 0 and len(kwargs) == 0:\n                message = f\"Running `{name}()`.\"\n            else:\n                message = f\"Running `{name}(...)`.\"\n        else:\n            message = self._info.show_spinner\n\n        if self._info.show_spinner or isinstance(self._info.show_spinner, str):\n            with spinner(message, _cache=True):\n                return self._get_or_create_cached_value(args, kwargs)\n        else:\n            return self._get_or_create_cached_value(args, kwargs)\n\n    def _get_or_create_cached_value(\n        self, func_args: tuple[Any, ...], func_kwargs: dict[str, Any]\n    ) -> Any:\n        # Retrieve the function's cache object. We must do this \"just-in-time\"\n        # (as opposed to in the constructor), because caches can be invalidated\n        # at any time.\n        cache = self._info.get_function_cache(self._function_key)\n\n        # Generate the key for the cached value. This is based on the\n        # arguments passed to the function.\n        value_key = _make_value_key(\n            cache_type=self._info.cache_type,\n            func=self._info.func,\n            func_args=func_args,\n            func_kwargs=func_kwargs,\n            hash_funcs=self._info.hash_funcs,\n        )\n\n        try:\n            cached_result = cache.read_result(value_key)\n            return self._handle_cache_hit(cached_result)\n        except CacheKeyNotFoundError:\n            pass\n        return self._handle_cache_miss(cache, value_key, func_args, func_kwargs)\n\n    def _handle_cache_hit(self, result: CachedResult) -> Any:\n        \"\"\"Handle a cache hit: replay the result's cached messages, and return its value.\"\"\"\n        replay_cached_messages(\n            result,\n            self._info.cache_type,\n            self._info.func,\n        )\n        return result.value\n\n    def _handle_cache_miss(\n        self,\n        cache: Cache,\n        value_key: str,\n        func_args: tuple[Any, ...],\n        func_kwargs: dict[str, Any],\n    ) -> Any:\n        \"\"\"Handle a cache miss: compute a new cached value, write it back to the cache,\n        and return that newly-computed value.\n        \"\"\"\n\n        # Implementation notes:\n        # - We take a \"compute_value_lock\" before computing our value. This ensures that\n        #   multiple sessions don't try to compute the same value simultaneously.\n        #\n        # - We use a different lock for each value_key, as opposed to a single lock for\n        #   the entire cache, so that unrelated value computations don't block on each other.\n        #\n        # - When retrieving a cache entry that may not yet exist, we use a \"double-checked locking\"\n        #   strategy: first we try to retrieve the cache entry without taking a value lock. (This\n        #   happens in `_get_or_create_cached_value()`.) If that fails because the value hasn't\n        #   been computed yet, we take the value lock and then immediately try to retrieve cache entry\n        #   *again*, while holding the lock. If the cache entry exists at this point, it means that\n        #   another thread computed the value before us.\n        #\n        #   This means that the happy path (\"cache entry exists\") is a wee bit faster because\n        #   no lock is acquired. But the unhappy path (\"cache entry needs to be recomputed\") is\n        #   a wee bit slower, because we do two lookups for the entry.\n\n        with cache.compute_value_lock(value_key):\n            # We've acquired the lock - but another thread may have acquired it first\n            # and already computed the value. So we need to test for a cache hit again,\n            # before computing.\n            try:\n                cached_result = cache.read_result(value_key)\n                # Another thread computed the value before us. Early exit!\n                return self._handle_cache_hit(cached_result)\n\n            except CacheKeyNotFoundError:\n                pass\n\n            # We acquired the lock before any other thread. Compute the value!\n            with self._info.cached_message_replay_ctx.calling_cached_function(\n                self._info.func, self._info.allow_widgets\n            ):\n                computed_value = self._info.func(*func_args, **func_kwargs)\n\n            # We've computed our value, and now we need to write it back to the cache\n            # along with any \"replay messages\" that were generated during value computation.\n            messages = self._info.cached_message_replay_ctx._most_recent_messages\n            try:\n                cache.write_result(value_key, computed_value, messages)\n                return computed_value\n            except (CacheError, RuntimeError):\n                # An exception was thrown while we tried to write to the cache. Report it to the user.\n                # (We catch `RuntimeError` here because it will be raised by Apache Spark if we do not\n                # collect dataframe before using `st.cache_data`.)\n                if True in [\n                    type_util.is_type(computed_value, type_name)\n                    for type_name in UNEVALUATED_DATAFRAME_TYPES\n                ]:\n                    # If the returned value is an unevaluated dataframe, raise an error.\n                    # Unevaluated dataframes are not yet in the local memory, which also\n                    # means they cannot be properly cached (serialized).\n                    raise UnevaluatedDataFrameError(\n                        f\"\"\"\n                        The function {get_cached_func_name_md(self._info.func)} is decorated with `st.cache_data` but it returns an unevaluated dataframe\n                        of type `{type_util.get_fqn_type(computed_value)}`. Please call `collect()` or `to_pandas()` on the dataframe before returning it,\n                        so `st.cache_data` can serialize and cache it.\"\"\"\n                    )\n                raise UnserializableReturnValueError(\n                    return_value=computed_value, func=self._info.func\n                )\n\n    def clear(self, *args, **kwargs):\n        \"\"\"Clear the cached function's associated cache.\n\n        If no arguments are passed, Streamlit will clear all values cached for\n        the function. If arguments are passed, Streamlit will clear the cached\n        value for these arguments only.\n\n        Parameters\n        ----------\n        *args: Any\n            Arguments of the cached functions.\n        **kwargs: Any\n            Keyword arguments of the cached function.\n\n        Example\n        -------\n        >>> import streamlit as st\n        >>> import time\n        >>>\n        >>> @st.cache_data\n        >>> def foo(bar):\n        >>>     time.sleep(2)\n        >>>     st.write(f\"Executed foo({bar}).\")\n        >>>     return bar\n        >>>\n        >>> if st.button(\"Clear all cached values for `foo`\", on_click=foo.clear):\n        >>>     foo.clear()\n        >>>\n        >>> if st.button(\"Clear the cached value of `foo(1)`\"):\n        >>>     foo.clear(1)\n        >>>\n        >>> foo(1)\n        >>> foo(2)\n\n        \"\"\"\n        cache = self._info.get_function_cache(self._function_key)\n        if args or kwargs:\n            key = _make_value_key(\n                cache_type=self._info.cache_type,\n                func=self._info.func,\n                func_args=args,\n                func_kwargs=kwargs,\n                hash_funcs=self._info.hash_funcs,\n            )\n        else:\n            key = None\n        cache.clear(key=key)\n\n\ndef _make_value_key(\n    cache_type: CacheType,\n    func: FunctionType,\n    func_args: tuple[Any, ...],\n    func_kwargs: dict[str, Any],\n    hash_funcs: HashFuncsDict | None,\n) -> str:\n    \"\"\"Create the key for a value within a cache.\n\n    This key is generated from the function's arguments. All arguments\n    will be hashed, except for those named with a leading \"_\".\n\n    Raises\n    ------\n    StreamlitAPIException\n        Raised (with a nicely-formatted explanation message) if we encounter\n        an un-hashable arg.\n    \"\"\"\n\n    # Create a (name, value) list of all *args and **kwargs passed to the\n    # function.\n    arg_pairs: list[tuple[str | None, Any]] = []\n    for arg_idx in range(len(func_args)):\n        arg_name = _get_positional_arg_name(func, arg_idx)\n        arg_pairs.append((arg_name, func_args[arg_idx]))\n\n    for kw_name, kw_val in func_kwargs.items():\n        # **kwargs ordering is preserved, per PEP 468\n        # https://www.python.org/dev/peps/pep-0468/, so this iteration is\n        # deterministic.\n        arg_pairs.append((kw_name, kw_val))\n\n    # Create the hash from each arg value, except for those args whose name\n    # starts with \"_\". (Underscore-prefixed args are deliberately excluded from\n    # hashing.)\n    args_hasher = hashlib.new(\"md5\", **HASHLIB_KWARGS)\n    for arg_name, arg_value in arg_pairs:\n        if arg_name is not None and arg_name.startswith(\"_\"):\n            _LOGGER.debug(\"Not hashing %s because it starts with _\", arg_name)\n            continue\n\n        try:\n            update_hash(\n                arg_name,\n                hasher=args_hasher,\n                cache_type=cache_type,\n                hash_source=func,\n            )\n            # we call update_hash twice here, first time for `arg_name`\n            # without `hash_funcs`, and second time for `arg_value` with hash_funcs\n            # to evaluate user defined `hash_funcs` only for computing `arg_value` hash.\n            update_hash(\n                arg_value,\n                hasher=args_hasher,\n                cache_type=cache_type,\n                hash_funcs=hash_funcs,\n                hash_source=func,\n            )\n        except UnhashableTypeError as exc:\n            raise UnhashableParamError(cache_type, func, arg_name, arg_value, exc)\n\n    value_key = args_hasher.hexdigest()\n    _LOGGER.debug(\"Cache key: %s\", value_key)\n\n    return value_key\n\n\ndef _make_function_key(cache_type: CacheType, func: FunctionType) -> str:\n    \"\"\"Create the unique key for a function's cache.\n\n    A function's key is stable across reruns of the app, and changes when\n    the function's source code changes.\n    \"\"\"\n    func_hasher = hashlib.new(\"md5\", **HASHLIB_KWARGS)\n\n    # Include the function's __module__ and __qualname__ strings in the hash.\n    # This means that two identical functions in different modules\n    # will not share a hash; it also means that two identical *nested*\n    # functions in the same module will not share a hash.\n    update_hash(\n        (func.__module__, func.__qualname__),\n        hasher=func_hasher,\n        cache_type=cache_type,\n        hash_source=func,\n    )\n\n    # Include the function's source code in its hash. If the source code can't\n    # be retrieved, fall back to the function's bytecode instead.\n    source_code: str | bytes\n    try:\n        source_code = inspect.getsource(func)\n    except OSError as e:\n        _LOGGER.debug(\n            \"Failed to retrieve function's source code when building its key; falling back to bytecode. err={0}\",\n            e,\n        )\n        source_code = func.__code__.co_code\n\n    update_hash(\n        source_code, hasher=func_hasher, cache_type=cache_type, hash_source=func\n    )\n\n    cache_key = func_hasher.hexdigest()\n    return cache_key\n\n\ndef _get_positional_arg_name(func: FunctionType, arg_index: int) -> str | None:\n    \"\"\"Return the name of a function's positional argument.\n\n    If arg_index is out of range, or refers to a parameter that is not a\n    named positional argument (e.g. an *args, **kwargs, or keyword-only param),\n    return None instead.\n    \"\"\"\n    if arg_index < 0:\n        return None\n\n    params: list[inspect.Parameter] = list(inspect.signature(func).parameters.values())\n    if arg_index >= len(params):\n        return None\n\n    if params[arg_index].kind in (\n        inspect.Parameter.POSITIONAL_OR_KEYWORD,\n        inspect.Parameter.POSITIONAL_ONLY,\n    ):\n        return params[arg_index].name\n\n    return None\n", "lib/streamlit/runtime/caching/hashing.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Hashing for st.cache_data and st.cache_resource.\"\"\"\n\nfrom __future__ import annotations\n\nimport collections\nimport dataclasses\nimport datetime\nimport functools\nimport hashlib\nimport inspect\nimport io\nimport os\nimport pickle\nimport sys\nimport tempfile\nimport threading\nimport uuid\nimport weakref\nfrom enum import Enum\nfrom typing import Any, Callable, Dict, Final, Pattern, Type, Union\n\nfrom typing_extensions import TypeAlias\n\nfrom streamlit import type_util, util\nfrom streamlit.errors import StreamlitAPIException\nfrom streamlit.runtime.caching.cache_errors import UnhashableTypeError\nfrom streamlit.runtime.caching.cache_type import CacheType\nfrom streamlit.runtime.uploaded_file_manager import UploadedFile\nfrom streamlit.util import HASHLIB_KWARGS\n\n# If a dataframe has more than this many rows, we consider it large and hash a sample.\n_PANDAS_ROWS_LARGE: Final = 100000\n_PANDAS_SAMPLE_SIZE: Final = 10000\n\n# Similar to dataframes, we also sample large numpy arrays.\n_NP_SIZE_LARGE: Final = 1000000\n_NP_SAMPLE_SIZE: Final = 100000\n\nHashFuncsDict: TypeAlias = Dict[Union[str, Type[Any]], Callable[[Any], Any]]\n\n# Arbitrary item to denote where we found a cycle in a hashed object.\n# This allows us to hash self-referencing lists, dictionaries, etc.\n_CYCLE_PLACEHOLDER: Final = (\n    b\"streamlit-57R34ML17-hesamagicalponyflyingthroughthesky-CYCLE\"\n)\n\n\nclass UserHashError(StreamlitAPIException):\n    def __init__(\n        self,\n        orig_exc,\n        object_to_hash,\n        hash_func,\n        cache_type: CacheType | None = None,\n    ):\n        self.alternate_name = type(orig_exc).__name__\n        self.hash_func = hash_func\n        self.cache_type = cache_type\n\n        msg = self._get_message_from_func(orig_exc, object_to_hash)\n\n        super().__init__(msg)\n        self.with_traceback(orig_exc.__traceback__)\n\n    def _get_message_from_func(self, orig_exc, cached_func):\n        args = self._get_error_message_args(orig_exc, cached_func)\n\n        return (\n            \"\"\"\n%(orig_exception_desc)s\n\nThis error is likely due to a bug in %(hash_func_name)s, which is a\nuser-defined hash function that was passed into the `%(cache_primitive)s` decorator of\n%(object_desc)s.\n\n%(hash_func_name)s failed when hashing an object of type\n`%(failed_obj_type_str)s`.  If you don't know where that object is coming from,\ntry looking at the hash chain below for an object that you do recognize, then\npass that to `hash_funcs` instead:\n\n```\n%(hash_stack)s\n```\n\nIf you think this is actually a Streamlit bug, please\n[file a bug report here](https://github.com/streamlit/streamlit/issues/new/choose).\n\"\"\"\n            % args\n        ).strip(\"\\n\")\n\n    def _get_error_message_args(\n        self,\n        orig_exc: BaseException,\n        failed_obj: Any,\n    ) -> dict[str, Any]:\n        hash_source = hash_stacks.current.hash_source\n\n        failed_obj_type_str = type_util.get_fqn_type(failed_obj)\n\n        if hash_source is None:\n            object_desc = \"something\"\n        else:\n            if hasattr(hash_source, \"__name__\"):\n                object_desc = f\"`{hash_source.__name__}()`\"\n            else:\n                object_desc = \"a function\"\n\n        decorator_name = \"\"\n        if self.cache_type is CacheType.RESOURCE:\n            decorator_name = \"@st.cache_resource\"\n        elif self.cache_type is CacheType.DATA:\n            decorator_name = \"@st.cache_data\"\n\n        if hasattr(self.hash_func, \"__name__\"):\n            hash_func_name = f\"`{self.hash_func.__name__}()`\"\n        else:\n            hash_func_name = \"a function\"\n\n        return {\n            \"orig_exception_desc\": str(orig_exc),\n            \"failed_obj_type_str\": failed_obj_type_str,\n            \"hash_stack\": hash_stacks.current.pretty_print(),\n            \"object_desc\": object_desc,\n            \"cache_primitive\": decorator_name,\n            \"hash_func_name\": hash_func_name,\n        }\n\n\ndef update_hash(\n    val: Any,\n    hasher,\n    cache_type: CacheType,\n    hash_source: Callable[..., Any] | None = None,\n    hash_funcs: HashFuncsDict | None = None,\n) -> None:\n    \"\"\"Updates a hashlib hasher with the hash of val.\n\n    This is the main entrypoint to hashing.py.\n    \"\"\"\n\n    hash_stacks.current.hash_source = hash_source\n\n    ch = _CacheFuncHasher(cache_type, hash_funcs)\n    ch.update(hasher, val)\n\n\nclass _HashStack:\n    \"\"\"Stack of what has been hashed, for debug and circular reference detection.\n\n    This internally keeps 1 stack per thread.\n\n    Internally, this stores the ID of pushed objects rather than the objects\n    themselves because otherwise the \"in\" operator inside __contains__ would\n    fail for objects that don't return a boolean for \"==\" operator. For\n    example, arr == 10 where arr is a NumPy array returns another NumPy array.\n    This causes the \"in\" to crash since it expects a boolean.\n    \"\"\"\n\n    def __init__(self):\n        self._stack: collections.OrderedDict[int, list[Any]] = collections.OrderedDict()\n        # A function that we decorate with streamlit cache\n        # primitive (st.cache_data or st.cache_resource).\n        self.hash_source: Callable[..., Any] | None = None\n\n    def __repr__(self) -> str:\n        return util.repr_(self)\n\n    def push(self, val: Any):\n        self._stack[id(val)] = val\n\n    def pop(self):\n        self._stack.popitem()\n\n    def __contains__(self, val: Any):\n        return id(val) in self._stack\n\n    def pretty_print(self) -> str:\n        def to_str(v: Any) -> str:\n            try:\n                return f\"Object of type {type_util.get_fqn_type(v)}: {str(v)}\"\n            except Exception:\n                return \"<Unable to convert item to string>\"\n\n        return \"\\n\".join(to_str(x) for x in reversed(self._stack.values()))\n\n\nclass _HashStacks:\n    \"\"\"Stacks of what has been hashed, with at most 1 stack per thread.\"\"\"\n\n    def __init__(self):\n        self._stacks: weakref.WeakKeyDictionary[threading.Thread, _HashStack] = (\n            weakref.WeakKeyDictionary()\n        )\n\n    def __repr__(self) -> str:\n        return util.repr_(self)\n\n    @property\n    def current(self) -> _HashStack:\n        current_thread = threading.current_thread()\n\n        stack = self._stacks.get(current_thread, None)\n\n        if stack is None:\n            stack = _HashStack()\n            self._stacks[current_thread] = stack\n\n        return stack\n\n\nhash_stacks = _HashStacks()\n\n\ndef _int_to_bytes(i: int) -> bytes:\n    num_bytes = (i.bit_length() + 8) // 8\n    return i.to_bytes(num_bytes, \"little\", signed=True)\n\n\ndef _float_to_bytes(f: float) -> bytes:\n    # Lazy-load for performance reasons.\n    import struct\n\n    # Floats are 64bit in Python, so we need to use the \"d\" format.\n    return struct.pack(\"<d\", f)\n\n\ndef _key(obj: Any | None) -> Any:\n    \"\"\"Return key for memoization.\"\"\"\n\n    if obj is None:\n        return None\n\n    def is_simple(obj):\n        return (\n            isinstance(obj, bytes)\n            or isinstance(obj, bytearray)\n            or isinstance(obj, str)\n            or isinstance(obj, float)\n            or isinstance(obj, int)\n            or isinstance(obj, bool)\n            or isinstance(obj, uuid.UUID)\n            or obj is None\n        )\n\n    if is_simple(obj):\n        return obj\n\n    if isinstance(obj, tuple):\n        if all(map(is_simple, obj)):\n            return obj\n\n    if isinstance(obj, list):\n        if all(map(is_simple, obj)):\n            return (\"__l\", tuple(obj))\n\n    if inspect.isbuiltin(obj) or inspect.isroutine(obj) or inspect.iscode(obj):\n        return id(obj)\n\n    return NoResult\n\n\nclass _CacheFuncHasher:\n    \"\"\"A hasher that can hash objects with cycles.\"\"\"\n\n    def __init__(self, cache_type: CacheType, hash_funcs: HashFuncsDict | None = None):\n        # Can't use types as the keys in the internal _hash_funcs because\n        # we always remove user-written modules from memory when rerunning a\n        # script in order to reload it and grab the latest code changes.\n        # (See LocalSourcesWatcher.py:on_file_changed) This causes\n        # the type object to refer to different underlying class instances each run,\n        # so type-based comparisons fail. To solve this, we use the types converted\n        # to fully-qualified strings as keys in our internal dict.\n        self._hash_funcs: HashFuncsDict\n        if hash_funcs:\n            self._hash_funcs = {\n                k if isinstance(k, str) else type_util.get_fqn(k): v\n                for k, v in hash_funcs.items()\n            }\n        else:\n            self._hash_funcs = {}\n        self._hashes: dict[Any, bytes] = {}\n\n        # The number of the bytes in the hash.\n        self.size = 0\n\n        self.cache_type = cache_type\n\n    def __repr__(self) -> str:\n        return util.repr_(self)\n\n    def to_bytes(self, obj: Any) -> bytes:\n        \"\"\"Add memoization to _to_bytes and protect against cycles in data structures.\"\"\"\n        tname = type(obj).__qualname__.encode()\n        key = (tname, _key(obj))\n\n        # Memoize if possible.\n        if key[1] is not NoResult:\n            if key in self._hashes:\n                return self._hashes[key]\n\n        # Break recursive cycles.\n        if obj in hash_stacks.current:\n            return _CYCLE_PLACEHOLDER\n\n        hash_stacks.current.push(obj)\n\n        try:\n            # Hash the input\n            b = b\"%s:%s\" % (tname, self._to_bytes(obj))\n\n            # Hmmm... It's possible that the size calculation is wrong. When we\n            # call to_bytes inside _to_bytes things get double-counted.\n            self.size += sys.getsizeof(b)\n\n            if key[1] is not NoResult:\n                self._hashes[key] = b\n\n        finally:\n            # In case an UnhashableTypeError (or other) error is thrown, clean up the\n            # stack so we don't get false positives in future hashing calls\n            hash_stacks.current.pop()\n\n        return b\n\n    def update(self, hasher, obj: Any) -> None:\n        \"\"\"Update the provided hasher with the hash of an object.\"\"\"\n        b = self.to_bytes(obj)\n        hasher.update(b)\n\n    def _to_bytes(self, obj: Any) -> bytes:\n        \"\"\"Hash objects to bytes, including code with dependencies.\n\n        Python's built in `hash` does not produce consistent results across\n        runs.\n        \"\"\"\n\n        h = hashlib.new(\"md5\", **HASHLIB_KWARGS)\n\n        if type_util.is_type(obj, \"unittest.mock.Mock\") or type_util.is_type(\n            obj, \"unittest.mock.MagicMock\"\n        ):\n            # Mock objects can appear to be infinitely\n            # deep, so we don't try to hash them at all.\n            return self.to_bytes(id(obj))\n\n        elif isinstance(obj, bytes) or isinstance(obj, bytearray):\n            return obj\n\n        elif type_util.get_fqn_type(obj) in self._hash_funcs:\n            # Escape hatch for unsupported objects\n            hash_func = self._hash_funcs[type_util.get_fqn_type(obj)]\n            try:\n                output = hash_func(obj)\n            except Exception as ex:\n                raise UserHashError(\n                    ex, obj, hash_func=hash_func, cache_type=self.cache_type\n                ) from ex\n            return self.to_bytes(output)\n\n        elif isinstance(obj, str):\n            return obj.encode()\n\n        elif isinstance(obj, float):\n            return _float_to_bytes(obj)\n\n        elif isinstance(obj, int):\n            return _int_to_bytes(obj)\n\n        elif isinstance(obj, uuid.UUID):\n            return obj.bytes\n\n        elif isinstance(obj, datetime.datetime):\n            return obj.isoformat().encode()\n\n        elif isinstance(obj, (list, tuple)):\n            for item in obj:\n                self.update(h, item)\n            return h.digest()\n\n        elif isinstance(obj, dict):\n            for item in obj.items():\n                self.update(h, item)\n            return h.digest()\n\n        elif obj is None:\n            return b\"0\"\n\n        elif obj is True:\n            return b\"1\"\n\n        elif obj is False:\n            return b\"0\"\n\n        elif dataclasses.is_dataclass(obj):\n            return self.to_bytes(dataclasses.asdict(obj))\n\n        elif isinstance(obj, Enum):\n            return str(obj).encode()\n\n        elif type_util.is_type(obj, \"pandas.core.series.Series\"):\n            import pandas as pd\n\n            self.update(h, obj.size)\n            self.update(h, obj.dtype.name)\n\n            if len(obj) >= _PANDAS_ROWS_LARGE:\n                obj = obj.sample(n=_PANDAS_SAMPLE_SIZE, random_state=0)\n\n            try:\n                self.update(h, pd.util.hash_pandas_object(obj).values.tobytes())\n                return h.digest()\n            except TypeError:\n                # Use pickle if pandas cannot hash the object for example if\n                # it contains unhashable objects.\n                return b\"%s\" % pickle.dumps(obj, pickle.HIGHEST_PROTOCOL)\n\n        elif type_util.is_type(obj, \"pandas.core.frame.DataFrame\"):\n            import pandas as pd\n\n            self.update(h, obj.shape)\n\n            if len(obj) >= _PANDAS_ROWS_LARGE:\n                obj = obj.sample(n=_PANDAS_SAMPLE_SIZE, random_state=0)\n            try:\n                column_hash_bytes = self.to_bytes(\n                    pd.util.hash_pandas_object(obj.dtypes)\n                )\n                self.update(h, column_hash_bytes)\n                values_hash_bytes = self.to_bytes(pd.util.hash_pandas_object(obj))\n                self.update(h, values_hash_bytes)\n                return h.digest()\n            except TypeError:\n                # Use pickle if pandas cannot hash the object for example if\n                # it contains unhashable objects.\n                return b\"%s\" % pickle.dumps(obj, pickle.HIGHEST_PROTOCOL)\n\n        elif type_util.is_type(obj, \"numpy.ndarray\"):\n            self.update(h, obj.shape)\n            self.update(h, str(obj.dtype))\n\n            if obj.size >= _NP_SIZE_LARGE:\n                import numpy as np\n\n                state = np.random.RandomState(0)\n                obj = state.choice(obj.flat, size=_NP_SAMPLE_SIZE)\n\n            self.update(h, obj.tobytes())\n            return h.digest()\n        elif type_util.is_type(obj, \"PIL.Image.Image\"):\n            import numpy as np\n\n            # we don't just hash the results of obj.tobytes() because we want to use\n            # the sampling logic for numpy data\n            np_array = np.frombuffer(obj.tobytes(), dtype=\"uint8\")\n            return self.to_bytes(np_array)\n\n        elif inspect.isbuiltin(obj):\n            return bytes(obj.__name__.encode())\n\n        elif type_util.is_type(obj, \"builtins.mappingproxy\") or type_util.is_type(\n            obj, \"builtins.dict_items\"\n        ):\n            return self.to_bytes(dict(obj))\n\n        elif type_util.is_type(obj, \"builtins.getset_descriptor\"):\n            return bytes(obj.__qualname__.encode())\n\n        elif isinstance(obj, UploadedFile):\n            # UploadedFile is a BytesIO (thus IOBase) but has a name.\n            # It does not have a timestamp so this must come before\n            # temporary files\n            self.update(h, obj.name)\n            self.update(h, obj.tell())\n            self.update(h, obj.getvalue())\n            return h.digest()\n\n        elif hasattr(obj, \"name\") and (\n            isinstance(obj, io.IOBase)\n            # Handle temporary files used during testing\n            or isinstance(obj, tempfile._TemporaryFileWrapper)\n        ):\n            # Hash files as name + last modification date + offset.\n            # NB: we're using hasattr(\"name\") to differentiate between\n            # on-disk and in-memory StringIO/BytesIO file representations.\n            # That means that this condition must come *before* the next\n            # condition, which just checks for StringIO/BytesIO.\n            obj_name = getattr(obj, \"name\", \"wonthappen\")  # Just to appease MyPy.\n            self.update(h, obj_name)\n            self.update(h, os.path.getmtime(obj_name))\n            self.update(h, obj.tell())\n            return h.digest()\n\n        elif isinstance(obj, Pattern):\n            return self.to_bytes([obj.pattern, obj.flags])\n\n        elif isinstance(obj, io.StringIO) or isinstance(obj, io.BytesIO):\n            # Hash in-memory StringIO/BytesIO by their full contents\n            # and seek position.\n            self.update(h, obj.tell())\n            self.update(h, obj.getvalue())\n            return h.digest()\n\n        elif type_util.is_type(obj, \"numpy.ufunc\"):\n            # For numpy.remainder, this returns remainder.\n            return bytes(obj.__name__.encode())\n\n        elif inspect.ismodule(obj):\n            # TODO: Figure out how to best show this kind of warning to the\n            # user. In the meantime, show nothing. This scenario is too common,\n            # so the current warning is quite annoying...\n            # st.warning(('Streamlit does not support hashing modules. '\n            #             'We did not hash `%s`.') % obj.__name__)\n            # TODO: Hash more than just the name for internal modules.\n            return self.to_bytes(obj.__name__)\n\n        elif inspect.isclass(obj):\n            # TODO: Figure out how to best show this kind of warning to the\n            # user. In the meantime, show nothing. This scenario is too common,\n            # (e.g. in every \"except\" statement) so the current warning is\n            # quite annoying...\n            # st.warning(('Streamlit does not support hashing classes. '\n            #             'We did not hash `%s`.') % obj.__name__)\n            # TODO: Hash more than just the name of classes.\n            return self.to_bytes(obj.__name__)\n\n        elif isinstance(obj, functools.partial):\n            # The return value of functools.partial is not a plain function:\n            # it's a callable object that remembers the original function plus\n            # the values you pickled into it. So here we need to special-case it.\n            self.update(h, obj.args)\n            self.update(h, obj.func)\n            self.update(h, obj.keywords)\n            return h.digest()\n\n        else:\n            # As a last resort, hash the output of the object's __reduce__ method\n            try:\n                reduce_data = obj.__reduce__()\n            except Exception as ex:\n                raise UnhashableTypeError() from ex\n\n            for item in reduce_data:\n                self.update(h, item)\n            return h.digest()\n\n\nclass NoResult:\n    \"\"\"Placeholder class for return values when None is meaningful.\"\"\"\n\n    pass\n", "lib/streamlit/runtime/caching/legacy_cache_api.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"A library of caching utilities.\"\"\"\n\nfrom __future__ import annotations\n\nfrom typing import TYPE_CHECKING, Any, Callable, TypeVar\n\nfrom streamlit import deprecation_util\nfrom streamlit.runtime.caching import CACHE_DOCS_URL\nfrom streamlit.runtime.metrics_util import gather_metrics\n\nif TYPE_CHECKING:\n    from streamlit.runtime.caching.hashing import HashFuncsDict\n\n# Type-annotate the decorator function.\n# (See https://mypy.readthedocs.io/en/stable/generics.html#decorator-factories)\nF = TypeVar(\"F\", bound=Callable[..., Any])\n\n\n@gather_metrics(\"cache\")\ndef cache(\n    func: F | None = None,\n    persist: bool = False,\n    allow_output_mutation: bool = False,\n    show_spinner: bool = True,\n    suppress_st_warning: bool = False,\n    hash_funcs: HashFuncsDict | None = None,\n    max_entries: int | None = None,\n    ttl: float | None = None,\n):\n    \"\"\"Legacy caching decorator (deprecated).\n\n    Legacy caching with ``st.cache`` has been removed from Streamlit. This is\n    now an alias for ``st.cache_data`` and ``st.cache_resource``.\n\n    Parameters\n    ----------\n    func : callable\n        The function to cache. Streamlit hashes the function's source code.\n\n    persist : bool\n        Whether to persist the cache on disk.\n\n    allow_output_mutation : bool\n        Whether to use ``st.cache_data`` or ``st.cache_resource``. If this is\n        ``False`` (default), the arguments are passed to ``st.cache_data``. If\n        this is ``True``, the arguments are passed to ``st.cache_resource``.\n\n    show_spinner : bool\n        Enable the spinner. Default is ``True`` to show a spinner when there is\n        a \"cache miss\" and the cached data is being created.\n\n    suppress_st_warning : bool\n        This is not used.\n\n    hash_funcs : dict or None\n        Mapping of types or fully qualified names to hash functions. This is used to override\n        the behavior of the hasher inside Streamlit's caching mechanism: when the hasher\n        encounters an object, it will first check to see if its type matches a key in this\n        dict and, if so, will use the provided function to generate a hash for it. See below\n        for an example of how this can be used.\n\n    max_entries : int or None\n        The maximum number of entries to keep in the cache, or ``None``\n        for an unbounded cache. (When a new entry is added to a full cache,\n        the oldest cached entry will be removed.) The default is ``None``.\n\n    ttl : float or None\n        The maximum number of seconds to keep an entry in the cache, or\n        None if cache entries should not expire. The default is None.\n\n    Example\n    -------\n    >>> import streamlit as st\n    >>>\n    >>> @st.cache\n    ... def fetch_and_clean_data(url):\n    ...     # Fetch data from URL here, and then clean it up.\n    ...     return data\n    ...\n    >>> d1 = fetch_and_clean_data(DATA_URL_1)\n    >>> # Actually executes the function, since this is the first time it was\n    >>> # encountered.\n    >>>\n    >>> d2 = fetch_and_clean_data(DATA_URL_1)\n    >>> # Does not execute the function. Instead, returns its previously computed\n    >>> # value. This means that now the data in d1 is the same as in d2.\n    >>>\n    >>> d3 = fetch_and_clean_data(DATA_URL_2)\n    >>> # This is a different URL, so the function executes.\n\n    To set the ``persist`` parameter, use this command as follows:\n\n    >>> @st.cache(persist=True)\n    ... def fetch_and_clean_data(url):\n    ...     # Fetch data from URL here, and then clean it up.\n    ...     return data\n\n    To disable hashing return values, set the ``allow_output_mutation`` parameter to ``True``:\n\n    >>> @st.cache(allow_output_mutation=True)\n    ... def fetch_and_clean_data(url):\n    ...     # Fetch data from URL here, and then clean it up.\n    ...     return data\n\n\n    To override the default hashing behavior, pass a custom hash function.\n    You can do that by mapping a type (e.g. ``MongoClient``) to a hash function (``id``) like this:\n\n    >>> @st.cache(hash_funcs={MongoClient: id})\n    ... def connect_to_database(url):\n    ...     return MongoClient(url)\n\n    Alternatively, you can map the type's fully-qualified name\n    (e.g. ``\"pymongo.mongo_client.MongoClient\"``) to the hash function instead:\n\n    >>> @st.cache(hash_funcs={\"pymongo.mongo_client.MongoClient\": id})\n    ... def connect_to_database(url):\n    ...     return MongoClient(url)\n\n    \"\"\"\n    import streamlit as st\n\n    deprecation_util.show_deprecation_warning(\n        f\"\"\"\n`st.cache` is deprecated and will be removed soon. Please use one of Streamlit's new caching commands, `st.cache_data` or `st.cache_resource`.\nMore information [in our docs]({CACHE_DOCS_URL}).\n\n**Note**: The behavior of `st.cache` was updated in Streamlit 1.36 to the new caching logic used by `st.cache_data` and `st.cache_resource`.\nThis might lead to some problems or unexpected behavior in certain edge cases.\n\"\"\"\n    )\n\n    # suppress_st_warning is unused since its not supported by the new caching commands\n\n    if allow_output_mutation:\n        return st.cache_resource(  # type: ignore\n            func,\n            show_spinner=show_spinner,\n            hash_funcs=hash_funcs,\n            max_entries=max_entries,\n            ttl=ttl,\n        )\n\n    return st.cache_data(  # type: ignore\n        func,\n        persist=persist,\n        show_spinner=show_spinner,\n        hash_funcs=hash_funcs,\n        max_entries=max_entries,\n        ttl=ttl,\n    )\n", "lib/streamlit/runtime/caching/cached_message_replay.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport contextlib\nimport hashlib\nimport threading\nfrom dataclasses import dataclass\nfrom typing import TYPE_CHECKING, Any, Iterator, Literal, Union\n\nimport streamlit as st\nfrom streamlit import runtime, util\nfrom streamlit.deprecation_util import show_deprecation_warning\nfrom streamlit.runtime.caching.cache_errors import CacheReplayClosureError\nfrom streamlit.runtime.caching.hashing import update_hash\nfrom streamlit.runtime.scriptrunner.script_run_context import (\n    ScriptRunContext,\n    get_script_run_ctx,\n)\nfrom streamlit.util import HASHLIB_KWARGS\n\nif TYPE_CHECKING:\n    from types import FunctionType\n\n    from google.protobuf.message import Message\n\n    from streamlit.delta_generator import DeltaGenerator\n    from streamlit.proto.Block_pb2 import Block\n    from streamlit.runtime.caching.cache_type import CacheType\n    from streamlit.runtime.state.common import WidgetMetadata\n\n\n@dataclass(frozen=True)\nclass WidgetMsgMetadata:\n    \"\"\"Everything needed for replaying a widget and treating it as an implicit\n    argument to a cached function, beyond what is stored for all elements.\n    \"\"\"\n\n    widget_id: str\n    widget_value: Any\n    metadata: WidgetMetadata[Any]\n\n\n@dataclass(frozen=True)\nclass MediaMsgData:\n    media: bytes | str\n    mimetype: str\n    media_id: str\n\n\n@dataclass(frozen=True)\nclass ElementMsgData:\n    \"\"\"An element's message and related metadata for\n    replaying that element's function call.\n\n    widget_metadata is filled in if and only if this element is a widget.\n    media_data is filled in iff this is a media element (image, audio, video).\n    \"\"\"\n\n    delta_type: str\n    message: Message\n    id_of_dg_called_on: str\n    returned_dgs_id: str\n    widget_metadata: WidgetMsgMetadata | None = None\n    media_data: list[MediaMsgData] | None = None\n\n\n@dataclass(frozen=True)\nclass BlockMsgData:\n    message: Block\n    id_of_dg_called_on: str\n    returned_dgs_id: str\n\n\nMsgData = Union[ElementMsgData, BlockMsgData]\n\n\"\"\"\nNote [Cache result structure]\n\nThe cache for a decorated function's results is split into two parts to enable\nhandling widgets invoked by the function.\n\nWidgets act as implicit additional inputs to the cached function, so they should\nbe used when deriving the cache key. However, we don't know what widgets are\ninvolved without first calling the function! So, we use the first execution\nof the function with a particular cache key to record what widgets are used,\nand use the current values of those widgets to derive a second cache key to\nlook up the function execution's results. The combination of first and second\ncache keys act as one true cache key, just split up because the second part depends\non the first.\n\nWe need to treat widgets as implicit arguments of the cached function, because\nthe behavior of the function, including what elements are created and what it\nreturns, can be and usually will be influenced by the values of those widgets.\nFor example:\n> @st.cache_data\n> def example_fn(x):\n>     y = x + 1\n>     if st.checkbox(\"hi\"):\n>         st.write(\"you checked the thing\")\n>         y = 0\n>     return y\n>\n> example_fn(2)\n\nIf the checkbox is checked, the function call should return 0 and the checkbox and\nmessage should be rendered. If the checkbox isn't checked, only the checkbox should\nrender, and the function will return 3.\n\n\nThere is a small catch in this. Since what widgets execute could depend on the values of\nany prior widgets, if we replace the `st.write` call in the example with a slider,\nthe first time it runs, we would miss the slider because it wasn't called,\nso when we later execute the function with the checkbox checked, the widget cache key\nwould not include the state of the slider, and would incorrectly get a cache hit\nfor a different slider value.\n\nIn principle the cache could be function+args key -> 1st widget key -> 2nd widget key\n... -> final widget key, with each widget dependent on the exact values of the widgets\nseen prior. This would prevent unnecessary cache misses due to differing values of widgets\nthat wouldn't affect the function's execution because they aren't even created.\nBut this would add even more complexity and both conceptual and runtime overhead, so it is\nunclear if it would be worth doing.\n\nInstead, we can keep the widgets as one cache key, and if we encounter a new widget\nwhile executing the function, we just update the list of widgets to include it.\nThis will cause existing cached results to be invalidated, which is bad, but to\navoid it we would need to keep around the full list of widgets and values for each\nwidget cache key so we could compute the updated key, which is probably too expensive\nto be worth it.\n\"\"\"\n\n\n@dataclass\nclass CachedResult:\n    \"\"\"The full results of calling a cache-decorated function, enough to\n    replay the st functions called while executing it.\n    \"\"\"\n\n    value: Any\n    messages: list[MsgData]\n    main_id: str\n    sidebar_id: str\n\n\n@dataclass\nclass MultiCacheResults:\n    \"\"\"Widgets called by a cache-decorated function, and a mapping of the\n    widget-derived cache key to the final results of executing the function.\n    \"\"\"\n\n    widget_ids: set[str]\n    results: dict[str, CachedResult]\n\n    def get_current_widget_key(\n        self, ctx: ScriptRunContext, cache_type: CacheType\n    ) -> str:\n        state = ctx.session_state\n        # Compute the key using only widgets that have values. A missing widget\n        # can be ignored because we only care about getting different keys\n        # for different widget values, and for that purpose doing nothing\n        # to the running hash is just as good as including the widget with a\n        # sentinel value. But by excluding it, we might get to reuse a result\n        # saved before we knew about that widget.\n        widget_values = [\n            (wid, state[wid]) for wid in sorted(self.widget_ids) if wid in state\n        ]\n        widget_key = _make_widget_key(widget_values, cache_type)\n        return widget_key\n\n\n\"\"\"\nNote [DeltaGenerator method invocation]\nThere are two top level DG instances defined for all apps:\n`main`, which is for putting elements in the main part of the app\n`sidebar`, for the sidebar\n\nThere are 3 different ways an st function can be invoked:\n1. Implicitly on the main DG instance (plain `st.foo` calls)\n2. Implicitly in an active contextmanager block (`st.foo` within a `with st.container` context)\n3. Explicitly on a DG instance (`st.sidebar.foo`, `my_column_1.foo`)\n\nTo simplify replaying messages from a cached function result, we convert all of these\nto explicit invocations. How they get rewritten depends on if the invocation was\nimplicit vs explicit, and if the target DG has been seen/produced during replay.\n\nImplicit invocation on a known DG -> Explicit invocation on that DG\nImplicit invocation on an unknown DG -> Rewrite as explicit invocation on main\n    with st.container():\n        my_cache_decorated_function()\n\n    This is situation 2 above, and the DG is a block entirely outside our function call,\n    so we interpret it as \"put this element in the enclosing contextmanager block\"\n    (or main if there isn't one), which is achieved by invoking on main.\nExplicit invocation on a known DG -> No change needed\nExplicit invocation on an unknown DG -> Raise an error\n    We have no way to identify the target DG, and it may not even be present in the\n    current script run, so the least surprising thing to do is raise an error.\n\n\"\"\"\n\n\nclass CachedMessageReplayContext(threading.local):\n    \"\"\"A utility for storing messages generated by `st` commands called inside\n    a cached function.\n\n    Data is stored in a thread-local object, so it's safe to use an instance\n    of this class across multiple threads.\n    \"\"\"\n\n    def __init__(self, cache_type: CacheType):\n        self._cached_message_stack: list[list[MsgData]] = []\n        self._seen_dg_stack: list[set[str]] = []\n        self._most_recent_messages: list[MsgData] = []\n        self._registered_metadata: WidgetMetadata[Any] | None = None\n        self._media_data: list[MediaMsgData] = []\n        self._cache_type = cache_type\n        self._allow_widgets: bool = False\n\n    def __repr__(self) -> str:\n        return util.repr_(self)\n\n    @contextlib.contextmanager\n    def calling_cached_function(\n        self, func: FunctionType, allow_widgets: bool\n    ) -> Iterator[None]:\n        \"\"\"Context manager that should wrap the invocation of a cached function.\n        It allows us to track any `st.foo` messages that are generated from inside the function\n        for playback during cache retrieval.\n        \"\"\"\n        self._cached_message_stack.append([])\n        self._seen_dg_stack.append(set())\n        self._allow_widgets = allow_widgets\n\n        nested_call = False\n        ctx = get_script_run_ctx()\n        if ctx:\n            if ctx.disallow_cached_widget_usage:\n                # The disallow_cached_widget_usage is already set to true.\n                # This indicates that this cached function run is called from another\n                # cached function that disallows widget usage.\n                # We need to deactivate the widget usage for this cached function run\n                # even if it was allowed.\n                self._allow_widgets = False\n                nested_call = True\n\n            if not self._allow_widgets:\n                # If we're in a cached function that disallows widget usage, we need to set\n                # the disallow_cached_widget_usage to true for this cached function run\n                # to prevent widget usage (triggers a warning).\n                ctx.disallow_cached_widget_usage = True\n        try:\n            yield\n        finally:\n            self._most_recent_messages = self._cached_message_stack.pop()\n            self._seen_dg_stack.pop()\n            if ctx and not nested_call:\n                # Reset the disallow_cached_widget_usage flag. But only if this\n                # is not nested inside a cached function that disallows widget usage.\n                ctx.disallow_cached_widget_usage = False\n\n    def save_element_message(\n        self,\n        delta_type: str,\n        element_proto: Message,\n        invoked_dg_id: str,\n        used_dg_id: str,\n        returned_dg_id: str,\n    ) -> None:\n        \"\"\"Record the element protobuf as having been produced during any currently\n        executing cached functions, so they can be replayed any time the function's\n        execution is skipped because they're in the cache.\n        \"\"\"\n        if not runtime.exists():\n            return\n        if len(self._cached_message_stack) >= 1:\n            id_to_save = self.select_dg_to_save(invoked_dg_id, used_dg_id)\n\n            # Widget replay is deprecated and will be removed soon:\n            # https://github.com/streamlit/streamlit/pull/8817.\n            # Therefore, its fine to keep this part a bit messy for now.\n\n            if (\n                hasattr(element_proto, \"id\")\n                and element_proto.id\n                and self._registered_metadata\n            ):\n                # The element has an ID and has associated widget metadata\n                # -> looks like a valid registered widget\n                widget_meta = WidgetMsgMetadata(\n                    element_proto.id, None, metadata=self._registered_metadata\n                )\n            else:\n                widget_meta = None\n\n            media_data = self._media_data\n\n            element_msg_data = ElementMsgData(\n                delta_type,\n                element_proto,\n                id_to_save,\n                returned_dg_id,\n                widget_meta,\n                media_data,\n            )\n            for msgs in self._cached_message_stack:\n                if self._allow_widgets or widget_meta is None:\n                    msgs.append(element_msg_data)\n\n        # Reset instance state, now that it has been used for the\n        # associated element.\n        self._media_data = []\n        self._registered_metadata = None\n\n        for s in self._seen_dg_stack:\n            s.add(returned_dg_id)\n\n    def save_block_message(\n        self,\n        block_proto: Block,\n        invoked_dg_id: str,\n        used_dg_id: str,\n        returned_dg_id: str,\n    ) -> None:\n        id_to_save = self.select_dg_to_save(invoked_dg_id, used_dg_id)\n        for msgs in self._cached_message_stack:\n            msgs.append(BlockMsgData(block_proto, id_to_save, returned_dg_id))\n        for s in self._seen_dg_stack:\n            s.add(returned_dg_id)\n\n    def select_dg_to_save(self, invoked_id: str, acting_on_id: str) -> str:\n        \"\"\"Select the id of the DG that this message should be invoked on\n        during message replay.\n\n        See Note [DeltaGenerator method invocation]\n\n        invoked_id is the DG the st function was called on, usually `st._main`.\n        acting_on_id is the DG the st function ultimately runs on, which may be different\n        if the invoked DG delegated to another one because it was in a `with` block.\n        \"\"\"\n        if len(self._seen_dg_stack) > 0 and acting_on_id in self._seen_dg_stack[-1]:\n            return acting_on_id\n        else:\n            return invoked_id\n\n    def save_widget_metadata(self, metadata: WidgetMetadata[Any]) -> None:\n        self._registered_metadata = metadata\n\n    def save_image_data(\n        self, image_data: bytes | str, mimetype: str, image_id: str\n    ) -> None:\n        self._media_data.append(MediaMsgData(image_data, mimetype, image_id))\n\n\ndef replay_cached_messages(\n    result: CachedResult, cache_type: CacheType, cached_func: FunctionType\n) -> None:\n    \"\"\"Replay the st element function calls that happened when executing a\n    cache-decorated function.\n\n    When a cache function is executed, we record the element and block messages\n    produced, and use those to reproduce the DeltaGenerator calls, so the elements\n    will appear in the web app even when execution of the function is skipped\n    because the result was cached.\n\n    To make this work, for each st function call we record an identifier for the\n    DG it was effectively called on (see Note [DeltaGenerator method invocation]).\n    We also record the identifier for each DG returned by an st function call, if\n    it returns one. Then, for each recorded message, we get the current DG instance\n    corresponding to the DG the message was originally called on, and enqueue the\n    message using that, recording any new DGs produced in case a later st function\n    call is on one of them.\n    \"\"\"\n    from streamlit.delta_generator import DeltaGenerator\n    from streamlit.runtime.state.widgets import register_widget_from_metadata\n\n    # Maps originally recorded dg ids to this script run's version of that dg\n    returned_dgs: dict[str, DeltaGenerator] = {}\n    returned_dgs[result.main_id] = st._main\n    returned_dgs[result.sidebar_id] = st.sidebar\n    ctx = get_script_run_ctx()\n\n    try:\n        for msg in result.messages:\n            if isinstance(msg, ElementMsgData):\n                if msg.widget_metadata is not None:\n                    register_widget_from_metadata(\n                        msg.widget_metadata.metadata,\n                        ctx,\n                        None,\n                        msg.delta_type,\n                    )\n                if msg.media_data is not None:\n                    for data in msg.media_data:\n                        runtime.get_instance().media_file_mgr.add(\n                            data.media, data.mimetype, data.media_id\n                        )\n                dg = returned_dgs[msg.id_of_dg_called_on]\n                maybe_dg = dg._enqueue(msg.delta_type, msg.message)\n                if isinstance(maybe_dg, DeltaGenerator):\n                    returned_dgs[msg.returned_dgs_id] = maybe_dg\n            elif isinstance(msg, BlockMsgData):\n                dg = returned_dgs[msg.id_of_dg_called_on]\n                new_dg = dg._block(msg.message)\n                returned_dgs[msg.returned_dgs_id] = new_dg\n    except KeyError:\n        raise CacheReplayClosureError(cache_type, cached_func)\n\n\ndef _make_widget_key(widgets: list[tuple[str, Any]], cache_type: CacheType) -> str:\n    \"\"\"Generate a key for the given list of widgets used in a cache-decorated function.\n\n    Keys are generated by hashing the IDs and values of the widgets in the given list.\n    \"\"\"\n    func_hasher = hashlib.new(\"md5\", **HASHLIB_KWARGS)\n    for widget_id_val in widgets:\n        update_hash(widget_id_val, func_hasher, cache_type)\n\n    return func_hasher.hexdigest()\n\n\ndef show_widget_replay_deprecation(\n    decorator: Literal[\"cache_data\", \"cache_resource\"],\n) -> None:\n    show_deprecation_warning(\n        \"The `experimental_allow_widgets` parameter is deprecated and will be removed \"\n        \"in a future release. Please remove the `experimental_allow_widgets` parameter \"\n        f\"from the `@st.{decorator}` decorator and move all widget commands outside of \"\n        \"cached functions.\\n\\nTo speed up your app, we recommend moving your widgets into fragments. \"\n        \"Find out more about fragments in [our docs](https://docs.streamlit.io/develop/api-reference/execution-flow/st.fragment). \"\n        \"\\n\\nIf you have a specific use-case that requires the `experimental_allow_widgets` functionality, \"\n        \"please tell us via an [issue on Github](https://github.com/streamlit/streamlit/issues).\"\n    )\n", "lib/streamlit/runtime/caching/cache_resource_api.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"@st.cache_resource implementation\"\"\"\n\nfrom __future__ import annotations\n\nimport math\nimport threading\nimport types\nfrom typing import TYPE_CHECKING, Any, Callable, Final, TypeVar, cast, overload\n\nfrom cachetools import TTLCache\nfrom typing_extensions import TypeAlias\n\nimport streamlit as st\nfrom streamlit.logger import get_logger\nfrom streamlit.runtime.caching import cache_utils\nfrom streamlit.runtime.caching.cache_errors import CacheKeyNotFoundError\nfrom streamlit.runtime.caching.cache_type import CacheType\nfrom streamlit.runtime.caching.cache_utils import (\n    Cache,\n    CachedFuncInfo,\n    make_cached_func_wrapper,\n)\nfrom streamlit.runtime.caching.cached_message_replay import (\n    CachedMessageReplayContext,\n    CachedResult,\n    ElementMsgData,\n    MsgData,\n    MultiCacheResults,\n    show_widget_replay_deprecation,\n)\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.runtime.scriptrunner.script_run_context import get_script_run_ctx\nfrom streamlit.runtime.stats import CacheStat, CacheStatsProvider, group_stats\nfrom streamlit.time_util import time_to_seconds\n\nif TYPE_CHECKING:\n    from datetime import timedelta\n\n    from streamlit.runtime.caching.hashing import HashFuncsDict\n\n_LOGGER: Final = get_logger(__name__)\n\n\nCACHE_RESOURCE_MESSAGE_REPLAY_CTX = CachedMessageReplayContext(CacheType.RESOURCE)\n\nValidateFunc: TypeAlias = Callable[[Any], bool]\n\n\ndef _equal_validate_funcs(a: ValidateFunc | None, b: ValidateFunc | None) -> bool:\n    \"\"\"True if the two validate functions are equal for the purposes of\n    determining whether a given function cache needs to be recreated.\n    \"\"\"\n    # To \"properly\" test for function equality here, we'd need to compare function bytecode.\n    # For performance reasons, We've decided not to do that for now.\n    return (a is None and b is None) or (a is not None and b is not None)\n\n\nclass ResourceCaches(CacheStatsProvider):\n    \"\"\"Manages all ResourceCache instances\"\"\"\n\n    def __init__(self):\n        self._caches_lock = threading.Lock()\n        self._function_caches: dict[str, ResourceCache] = {}\n\n    def get_cache(\n        self,\n        key: str,\n        display_name: str,\n        max_entries: int | float | None,\n        ttl: float | timedelta | str | None,\n        validate: ValidateFunc | None,\n        allow_widgets: bool,\n    ) -> ResourceCache:\n        \"\"\"Return the mem cache for the given key.\n\n        If it doesn't exist, create a new one with the given params.\n        \"\"\"\n        if max_entries is None:\n            max_entries = math.inf\n\n        ttl_seconds = time_to_seconds(ttl)\n\n        # Get the existing cache, if it exists, and validate that its params\n        # haven't changed.\n        with self._caches_lock:\n            cache = self._function_caches.get(key)\n            if (\n                cache is not None\n                and cache.ttl_seconds == ttl_seconds\n                and cache.max_entries == max_entries\n                and _equal_validate_funcs(cache.validate, validate)\n            ):\n                return cache\n\n            # Create a new cache object and put it in our dict\n            _LOGGER.debug(\"Creating new ResourceCache (key=%s)\", key)\n            cache = ResourceCache(\n                key=key,\n                display_name=display_name,\n                max_entries=max_entries,\n                ttl_seconds=ttl_seconds,\n                validate=validate,\n                allow_widgets=allow_widgets,\n            )\n            self._function_caches[key] = cache\n            return cache\n\n    def clear_all(self) -> None:\n        \"\"\"Clear all resource caches.\"\"\"\n        with self._caches_lock:\n            self._function_caches = {}\n\n    def get_stats(self) -> list[CacheStat]:\n        with self._caches_lock:\n            # Shallow-clone our caches. We don't want to hold the global\n            # lock during stats-gathering.\n            function_caches = self._function_caches.copy()\n\n        stats: list[CacheStat] = []\n        for cache in function_caches.values():\n            stats.extend(cache.get_stats())\n        return group_stats(stats)\n\n\n# Singleton ResourceCaches instance\n_resource_caches = ResourceCaches()\n\n\ndef get_resource_cache_stats_provider() -> CacheStatsProvider:\n    \"\"\"Return the StatsProvider for all @st.cache_resource functions.\"\"\"\n    return _resource_caches\n\n\nclass CachedResourceFuncInfo(CachedFuncInfo):\n    \"\"\"Implements the CachedFuncInfo interface for @st.cache_resource\"\"\"\n\n    def __init__(\n        self,\n        func: types.FunctionType,\n        show_spinner: bool | str,\n        max_entries: int | None,\n        ttl: float | timedelta | str | None,\n        validate: ValidateFunc | None,\n        allow_widgets: bool,\n        hash_funcs: HashFuncsDict | None = None,\n    ):\n        super().__init__(\n            func,\n            show_spinner=show_spinner,\n            allow_widgets=allow_widgets,\n            hash_funcs=hash_funcs,\n        )\n        self.max_entries = max_entries\n        self.ttl = ttl\n        self.validate = validate\n\n    @property\n    def cache_type(self) -> CacheType:\n        return CacheType.RESOURCE\n\n    @property\n    def cached_message_replay_ctx(self) -> CachedMessageReplayContext:\n        return CACHE_RESOURCE_MESSAGE_REPLAY_CTX\n\n    @property\n    def display_name(self) -> str:\n        \"\"\"A human-readable name for the cached function\"\"\"\n        return f\"{self.func.__module__}.{self.func.__qualname__}\"\n\n    def get_function_cache(self, function_key: str) -> Cache:\n        return _resource_caches.get_cache(\n            key=function_key,\n            display_name=self.display_name,\n            max_entries=self.max_entries,\n            ttl=self.ttl,\n            validate=self.validate,\n            allow_widgets=self.allow_widgets,\n        )\n\n\nclass CacheResourceAPI:\n    \"\"\"Implements the public st.cache_resource API: the @st.cache_resource decorator,\n    and st.cache_resource.clear().\n    \"\"\"\n\n    def __init__(self, decorator_metric_name: str):\n        \"\"\"Create a CacheResourceAPI instance.\n\n        Parameters\n        ----------\n        decorator_metric_name\n            The metric name to record for decorator usage.\n        \"\"\"\n\n        # Parameterize the decorator metric name.\n        # (Ignore spurious mypy complaints - https://github.com/python/mypy/issues/2427)\n        self._decorator = gather_metrics(decorator_metric_name, self._decorator)  # type: ignore\n\n    # Type-annotate the decorator function.\n    # (See https://mypy.readthedocs.io/en/stable/generics.html#decorator-factories)\n\n    F = TypeVar(\"F\", bound=Callable[..., Any])\n\n    # Bare decorator usage\n    @overload\n    def __call__(self, func: F) -> F: ...\n\n    # Decorator with arguments\n    @overload\n    def __call__(\n        self,\n        *,\n        ttl: float | timedelta | str | None = None,\n        max_entries: int | None = None,\n        show_spinner: bool | str = True,\n        validate: ValidateFunc | None = None,\n        experimental_allow_widgets: bool = False,\n        hash_funcs: HashFuncsDict | None = None,\n    ) -> Callable[[F], F]: ...\n\n    def __call__(\n        self,\n        func: F | None = None,\n        *,\n        ttl: float | timedelta | str | None = None,\n        max_entries: int | None = None,\n        show_spinner: bool | str = True,\n        validate: ValidateFunc | None = None,\n        experimental_allow_widgets: bool = False,\n        hash_funcs: HashFuncsDict | None = None,\n    ):\n        return self._decorator(\n            func,\n            ttl=ttl,\n            max_entries=max_entries,\n            show_spinner=show_spinner,\n            validate=validate,\n            experimental_allow_widgets=experimental_allow_widgets,\n            hash_funcs=hash_funcs,\n        )\n\n    def _decorator(\n        self,\n        func: F | None,\n        *,\n        ttl: float | timedelta | str | None,\n        max_entries: int | None,\n        show_spinner: bool | str,\n        validate: ValidateFunc | None,\n        experimental_allow_widgets: bool,\n        hash_funcs: HashFuncsDict | None = None,\n    ):\n        \"\"\"Decorator to cache functions that return global resources (e.g. database connections, ML models).\n\n        Cached objects are shared across all users, sessions, and reruns. They\n        must be thread-safe because they can be accessed from multiple threads\n        concurrently. If thread safety is an issue, consider using ``st.session_state``\n        to store resources per session instead.\n\n        You can clear a function's cache with ``func.clear()`` or clear the entire\n        cache with ``st.cache_resource.clear()``.\n\n        To cache data, use ``st.cache_data`` instead. Learn more about caching at\n        https://docs.streamlit.io/develop/concepts/architecture/caching.\n\n        Parameters\n        ----------\n        func : callable\n            The function that creates the cached resource. Streamlit hashes the\n            function's source code.\n\n        ttl : float, timedelta, str, or None\n            The maximum time to keep an entry in the cache. Can be one of:\n\n            * ``None`` if cache entries should never expire (default).\n            * A number specifying the time in seconds.\n            * A string specifying the time in a format supported by `Pandas's\n              Timedelta constructor <https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.html>`_,\n              e.g. ``\"1d\"``, ``\"1.5 days\"``, or ``\"1h23s\"``.\n            * A ``timedelta`` object from `Python's built-in datetime library\n              <https://docs.python.org/3/library/datetime.html#timedelta-objects>`_,\n              e.g. ``timedelta(days=1)``.\n\n        max_entries : int or None\n            The maximum number of entries to keep in the cache, or None\n            for an unbounded cache. When a new entry is added to a full cache,\n            the oldest cached entry will be removed. Defaults to None.\n\n        show_spinner : bool or str\n            Enable the spinner. Default is True to show a spinner when there is\n            a \"cache miss\" and the cached resource is being created. If string,\n            value of show_spinner param will be used for spinner text.\n\n        validate : callable or None\n            An optional validation function for cached data. ``validate`` is called\n            each time the cached value is accessed. It receives the cached value as\n            its only parameter and it must return a boolean. If ``validate`` returns\n            False, the current cached value is discarded, and the decorated function\n            is called to compute a new value. This is useful e.g. to check the\n            health of database connections.\n\n        experimental_allow_widgets : bool\n            Allow widgets to be used in the cached function. Defaults to False.\n            Support for widgets in cached functions is currently experimental.\n            Setting this parameter to True may lead to excessive memory use since the\n            widget value is treated as an additional input parameter to the cache.\n\n        hash_funcs : dict or None\n            Mapping of types or fully qualified names to hash functions.\n            This is used to override the behavior of the hasher inside Streamlit's\n            caching mechanism: when the hasher encounters an object, it will first\n            check to see if its type matches a key in this dict and, if so, will use\n            the provided function to generate a hash for it. See below for an example\n            of how this can be used.\n\n        .. deprecated::\n            ``experimental_allow_widgets`` is deprecated and will be removed in\n            a later version.\n\n        Example\n        -------\n        >>> import streamlit as st\n        >>>\n        >>> @st.cache_resource\n        ... def get_database_session(url):\n        ...     # Create a database session object that points to the URL.\n        ...     return session\n        ...\n        >>> s1 = get_database_session(SESSION_URL_1)\n        >>> # Actually executes the function, since this is the first time it was\n        >>> # encountered.\n        >>>\n        >>> s2 = get_database_session(SESSION_URL_1)\n        >>> # Does not execute the function. Instead, returns its previously computed\n        >>> # value. This means that now the connection object in s1 is the same as in s2.\n        >>>\n        >>> s3 = get_database_session(SESSION_URL_2)\n        >>> # This is a different URL, so the function executes.\n\n        By default, all parameters to a cache_resource function must be hashable.\n        Any parameter whose name begins with ``_`` will not be hashed. You can use\n        this as an \"escape hatch\" for parameters that are not hashable:\n\n        >>> import streamlit as st\n        >>>\n        >>> @st.cache_resource\n        ... def get_database_session(_sessionmaker, url):\n        ...     # Create a database connection object that points to the URL.\n        ...     return connection\n        ...\n        >>> s1 = get_database_session(create_sessionmaker(), DATA_URL_1)\n        >>> # Actually executes the function, since this is the first time it was\n        >>> # encountered.\n        >>>\n        >>> s2 = get_database_session(create_sessionmaker(), DATA_URL_1)\n        >>> # Does not execute the function. Instead, returns its previously computed\n        >>> # value - even though the _sessionmaker parameter was different\n        >>> # in both calls.\n\n        A cache_resource function's cache can be procedurally cleared:\n\n        >>> import streamlit as st\n        >>>\n        >>> @st.cache_resource\n        ... def get_database_session(_sessionmaker, url):\n        ...     # Create a database connection object that points to the URL.\n        ...     return connection\n        ...\n        >>> fetch_and_clean_data.clear(_sessionmaker, \"https://streamlit.io/\")\n        >>> # Clear the cached entry for the arguments provided.\n        >>>\n        >>> get_database_session.clear()\n        >>> # Clear all cached entries for this function.\n\n        To override the default hashing behavior, pass a custom hash function.\n        You can do that by mapping a type (e.g. ``Person``) to a hash\n        function (``str``) like this:\n\n        >>> import streamlit as st\n        >>> from pydantic import BaseModel\n        >>>\n        >>> class Person(BaseModel):\n        ...     name: str\n        >>>\n        >>> @st.cache_resource(hash_funcs={Person: str})\n        ... def get_person_name(person: Person):\n        ...     return person.name\n\n        Alternatively, you can map the type's fully-qualified name\n        (e.g. ``\"__main__.Person\"``) to the hash function instead:\n\n        >>> import streamlit as st\n        >>> from pydantic import BaseModel\n        >>>\n        >>> class Person(BaseModel):\n        ...     name: str\n        >>>\n        >>> @st.cache_resource(hash_funcs={\"__main__.Person\": str})\n        ... def get_person_name(person: Person):\n        ...     return person.name\n        \"\"\"\n        if experimental_allow_widgets:\n            show_widget_replay_deprecation(\"cache_resource\")\n\n        # Support passing the params via function decorator, e.g.\n        # @st.cache_resource(show_spinner=False)\n        if func is None:\n            return lambda f: make_cached_func_wrapper(\n                CachedResourceFuncInfo(\n                    func=f,\n                    show_spinner=show_spinner,\n                    max_entries=max_entries,\n                    ttl=ttl,\n                    validate=validate,\n                    allow_widgets=experimental_allow_widgets,\n                    hash_funcs=hash_funcs,\n                )\n            )\n\n        return make_cached_func_wrapper(\n            CachedResourceFuncInfo(\n                func=cast(types.FunctionType, func),\n                show_spinner=show_spinner,\n                max_entries=max_entries,\n                ttl=ttl,\n                validate=validate,\n                allow_widgets=experimental_allow_widgets,\n                hash_funcs=hash_funcs,\n            )\n        )\n\n    @gather_metrics(\"clear_resource_caches\")\n    def clear(self) -> None:\n        \"\"\"Clear all cache_resource caches.\"\"\"\n        _resource_caches.clear_all()\n\n\nclass ResourceCache(Cache):\n    \"\"\"Manages cached values for a single st.cache_resource function.\"\"\"\n\n    def __init__(\n        self,\n        key: str,\n        max_entries: float,\n        ttl_seconds: float,\n        validate: ValidateFunc | None,\n        display_name: str,\n        allow_widgets: bool,\n    ):\n        super().__init__()\n        self.key = key\n        self.display_name = display_name\n        self._mem_cache: TTLCache[str, MultiCacheResults] = TTLCache(\n            maxsize=max_entries, ttl=ttl_seconds, timer=cache_utils.TTLCACHE_TIMER\n        )\n        self._mem_cache_lock = threading.Lock()\n        self.validate = validate\n        self.allow_widgets = allow_widgets\n\n    @property\n    def max_entries(self) -> float:\n        return self._mem_cache.maxsize\n\n    @property\n    def ttl_seconds(self) -> float:\n        return self._mem_cache.ttl\n\n    def read_result(self, key: str) -> CachedResult:\n        \"\"\"Read a value and associated messages from the cache.\n        Raise `CacheKeyNotFoundError` if the value doesn't exist.\n        \"\"\"\n        with self._mem_cache_lock:\n            if key not in self._mem_cache:\n                # key does not exist in cache.\n                raise CacheKeyNotFoundError()\n\n            multi_results: MultiCacheResults = self._mem_cache[key]\n\n            ctx = get_script_run_ctx()\n            if not ctx:\n                # ScriptRunCtx does not exist (we're probably running in \"raw\" mode).\n                raise CacheKeyNotFoundError()\n\n            widget_key = multi_results.get_current_widget_key(ctx, CacheType.RESOURCE)\n            if widget_key not in multi_results.results:\n                # widget_key does not exist in cache (this combination of widgets hasn't been\n                # seen for the value_key yet).\n                raise CacheKeyNotFoundError()\n\n            result = multi_results.results[widget_key]\n\n            if self.validate is not None and not self.validate(result.value):\n                # Validate failed: delete the entry and raise an error.\n                del multi_results.results[widget_key]\n                raise CacheKeyNotFoundError()\n\n            return result\n\n    @gather_metrics(\"_cache_resource_object\")\n    def write_result(self, key: str, value: Any, messages: list[MsgData]) -> None:\n        \"\"\"Write a value and associated messages to the cache.\"\"\"\n        ctx = get_script_run_ctx()\n        if ctx is None:\n            return\n\n        main_id = st._main.id\n        sidebar_id = st.sidebar.id\n        if self.allow_widgets:\n            widgets = {\n                msg.widget_metadata.widget_id\n                for msg in messages\n                if isinstance(msg, ElementMsgData) and msg.widget_metadata is not None\n            }\n        else:\n            widgets = set()\n\n        with self._mem_cache_lock:\n            try:\n                multi_results = self._mem_cache[key]\n            except KeyError:\n                multi_results = MultiCacheResults(widget_ids=widgets, results={})\n\n            multi_results.widget_ids.update(widgets)\n            widget_key = multi_results.get_current_widget_key(ctx, CacheType.RESOURCE)\n\n            result = CachedResult(value, messages, main_id, sidebar_id)\n            multi_results.results[widget_key] = result\n            self._mem_cache[key] = multi_results\n\n    def _clear(self, key: str | None = None) -> None:\n        with self._mem_cache_lock:\n            if key is None:\n                self._mem_cache.clear()\n            elif key in self._mem_cache:\n                del self._mem_cache[key]\n\n    def get_stats(self) -> list[CacheStat]:\n        # Shallow clone our cache. Computing item sizes is potentially\n        # expensive, and we want to minimize the time we spend holding\n        # the lock.\n        with self._mem_cache_lock:\n            cache_entries = list(self._mem_cache.values())\n\n        # Lazy-load vendored package to prevent import of numpy\n        from streamlit.vendor.pympler.asizeof import asizeof\n\n        return [\n            CacheStat(\n                category_name=\"st_cache_resource\",\n                cache_name=self.display_name,\n                byte_length=asizeof(entry),\n            )\n            for entry in cache_entries\n        ]\n", "lib/streamlit/runtime/caching/__init__.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom typing import TYPE_CHECKING, Any\n\nfrom streamlit.runtime.caching.cache_data_api import (\n    CACHE_DATA_MESSAGE_REPLAY_CTX,\n    CacheDataAPI,\n    get_data_cache_stats_provider,\n)\nfrom streamlit.runtime.caching.cache_errors import CACHE_DOCS_URL\nfrom streamlit.runtime.caching.cache_resource_api import (\n    CACHE_RESOURCE_MESSAGE_REPLAY_CTX,\n    CacheResourceAPI,\n    get_resource_cache_stats_provider,\n)\nfrom streamlit.runtime.caching.legacy_cache_api import cache as _cache\n\nif TYPE_CHECKING:\n    from google.protobuf.message import Message\n\n    from streamlit.proto.Block_pb2 import Block\n    from streamlit.runtime.state.common import WidgetMetadata\n\n\ndef save_element_message(\n    delta_type: str,\n    element_proto: Message,\n    invoked_dg_id: str,\n    used_dg_id: str,\n    returned_dg_id: str,\n) -> None:\n    \"\"\"Save the message for an element to a thread-local callstack, so it can\n    be used later to replay the element when a cache-decorated function's\n    execution is skipped.\n    \"\"\"\n    CACHE_DATA_MESSAGE_REPLAY_CTX.save_element_message(\n        delta_type, element_proto, invoked_dg_id, used_dg_id, returned_dg_id\n    )\n    CACHE_RESOURCE_MESSAGE_REPLAY_CTX.save_element_message(\n        delta_type, element_proto, invoked_dg_id, used_dg_id, returned_dg_id\n    )\n\n\ndef save_block_message(\n    block_proto: Block,\n    invoked_dg_id: str,\n    used_dg_id: str,\n    returned_dg_id: str,\n) -> None:\n    \"\"\"Save the message for a block to a thread-local callstack, so it can\n    be used later to replay the block when a cache-decorated function's\n    execution is skipped.\n    \"\"\"\n    CACHE_DATA_MESSAGE_REPLAY_CTX.save_block_message(\n        block_proto, invoked_dg_id, used_dg_id, returned_dg_id\n    )\n    CACHE_RESOURCE_MESSAGE_REPLAY_CTX.save_block_message(\n        block_proto, invoked_dg_id, used_dg_id, returned_dg_id\n    )\n\n\ndef save_widget_metadata(metadata: WidgetMetadata[Any]) -> None:\n    \"\"\"Save a widget's metadata to a thread-local callstack, so the widget\n    can be registered again when that widget is replayed.\n    \"\"\"\n    CACHE_DATA_MESSAGE_REPLAY_CTX.save_widget_metadata(metadata)\n    CACHE_RESOURCE_MESSAGE_REPLAY_CTX.save_widget_metadata(metadata)\n\n\ndef save_media_data(image_data: bytes | str, mimetype: str, image_id: str) -> None:\n    CACHE_DATA_MESSAGE_REPLAY_CTX.save_image_data(image_data, mimetype, image_id)\n    CACHE_RESOURCE_MESSAGE_REPLAY_CTX.save_image_data(image_data, mimetype, image_id)\n\n\n# Create and export public API singletons.\ncache_data = CacheDataAPI(decorator_metric_name=\"cache_data\")\ncache_resource = CacheResourceAPI(decorator_metric_name=\"cache_resource\")\n# TODO(lukasmasuch): This is the legacy cache API name which is deprecated\n# and it should be removed in the future.\ncache = _cache\n\n\n__all__ = [\n    \"cache\",\n    \"CACHE_DOCS_URL\",\n    \"save_element_message\",\n    \"save_block_message\",\n    \"save_widget_metadata\",\n    \"save_media_data\",\n    \"get_data_cache_stats_provider\",\n    \"get_resource_cache_stats_provider\",\n    \"cache_data\",\n    \"cache_resource\",\n]\n", "lib/streamlit/runtime/caching/cache_errors.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom typing import TYPE_CHECKING, Any\n\nfrom streamlit import type_util\nfrom streamlit.errors import MarkdownFormattedException, StreamlitAPIException\nfrom streamlit.runtime.caching.cache_type import CacheType, get_decorator_api_name\n\nif TYPE_CHECKING:\n    from types import FunctionType\n\nCACHE_DOCS_URL = \"https://docs.streamlit.io/develop/concepts/architecture/caching\"\n\n\ndef get_cached_func_name_md(func: Any) -> str:\n    \"\"\"Get markdown representation of the function name.\"\"\"\n    if hasattr(func, \"__name__\"):\n        return \"`%s()`\" % func.__name__\n    elif hasattr(type(func), \"__name__\"):\n        return f\"`{type(func).__name__}`\"\n    return f\"`{type(func)}`\"\n\n\ndef get_return_value_type(return_value: Any) -> str:\n    if hasattr(return_value, \"__module__\") and hasattr(type(return_value), \"__name__\"):\n        return f\"`{return_value.__module__}.{type(return_value).__name__}`\"\n    return get_cached_func_name_md(return_value)\n\n\nclass UnhashableTypeError(Exception):\n    pass\n\n\nclass UnhashableParamError(StreamlitAPIException):\n    def __init__(\n        self,\n        cache_type: CacheType,\n        func: FunctionType,\n        arg_name: str | None,\n        arg_value: Any,\n        orig_exc: BaseException,\n    ):\n        msg = self._create_message(cache_type, func, arg_name, arg_value)\n        super().__init__(msg)\n        self.with_traceback(orig_exc.__traceback__)\n\n    @staticmethod\n    def _create_message(\n        cache_type: CacheType,\n        func: FunctionType,\n        arg_name: str | None,\n        arg_value: Any,\n    ) -> str:\n        arg_name_str = arg_name if arg_name is not None else \"(unnamed)\"\n        arg_type = type_util.get_fqn_type(arg_value)\n        func_name = func.__name__\n        arg_replacement_name = f\"_{arg_name}\" if arg_name is not None else \"_arg\"\n\n        return (\n            f\"\"\"\nCannot hash argument '{arg_name_str}' (of type `{arg_type}`) in '{func_name}'.\n\nTo address this, you can tell Streamlit not to hash this argument by adding a\nleading underscore to the argument's name in the function signature:\n\n```\n@st.{get_decorator_api_name(cache_type)}\ndef {func_name}({arg_replacement_name}, ...):\n    ...\n```\n            \"\"\"\n        ).strip(\"\\n\")\n\n\nclass CacheKeyNotFoundError(Exception):\n    pass\n\n\nclass CacheError(Exception):\n    pass\n\n\nclass CacheReplayClosureError(StreamlitAPIException):\n    def __init__(\n        self,\n        cache_type: CacheType,\n        cached_func: FunctionType,\n    ):\n        func_name = get_cached_func_name_md(cached_func)\n        decorator_name = get_decorator_api_name(cache_type)\n\n        msg = (\n            f\"\"\"\nWhile running {func_name}, a streamlit element is called on some layout block created outside the function.\nThis is incompatible with replaying the cached effect of that element, because the\nthe referenced block might not exist when the replay happens.\n\nHow to fix this:\n* Move the creation of $THING inside {func_name}.\n* Move the call to the streamlit element outside of {func_name}.\n* Remove the `@st.{decorator_name}` decorator from {func_name}.\n            \"\"\"\n        ).strip(\"\\n\")\n\n        super().__init__(msg)\n\n\nclass UnserializableReturnValueError(MarkdownFormattedException):\n    def __init__(self, func: FunctionType, return_value: FunctionType):\n        MarkdownFormattedException.__init__(\n            self,\n            f\"\"\"\n            Cannot serialize the return value (of type {get_return_value_type(return_value)}) in {get_cached_func_name_md(func)}.\n            `st.cache_data` uses [pickle](https://docs.python.org/3/library/pickle.html) to\n            serialize the function\u2019s return value and safely store it in the cache without mutating the original object. Please convert the return value to a pickle-serializable type.\n            If you want to cache unserializable objects such as database connections or Tensorflow\n            sessions, use `st.cache_resource` instead (see [our docs]({CACHE_DOCS_URL}) for differences).\"\"\",\n        )\n\n\nclass UnevaluatedDataFrameError(StreamlitAPIException):\n    \"\"\"Used to display a message about uncollected dataframe being used\"\"\"\n\n    pass\n", "lib/streamlit/runtime/caching/cache_type.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport enum\n\n\nclass CacheType(enum.Enum):\n    \"\"\"The function cache types we implement.\"\"\"\n\n    DATA = \"DATA\"\n    RESOURCE = \"RESOURCE\"\n\n\ndef get_decorator_api_name(cache_type: CacheType) -> str:\n    \"\"\"Return the name of the public decorator API for the given CacheType.\"\"\"\n    if cache_type is CacheType.DATA:\n        return \"cache_data\"\n    if cache_type is CacheType.RESOURCE:\n        return \"cache_resource\"\n    raise RuntimeError(f\"Unrecognized CacheType '{cache_type}'\")\n", "lib/streamlit/runtime/caching/storage/dummy_cache_storage.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nfrom __future__ import annotations\n\nfrom streamlit.runtime.caching.storage.cache_storage_protocol import (\n    CacheStorage,\n    CacheStorageContext,\n    CacheStorageKeyNotFoundError,\n    CacheStorageManager,\n)\nfrom streamlit.runtime.caching.storage.in_memory_cache_storage_wrapper import (\n    InMemoryCacheStorageWrapper,\n)\n\n\nclass MemoryCacheStorageManager(CacheStorageManager):\n    def create(self, context: CacheStorageContext) -> CacheStorage:\n        \"\"\"Creates a new cache storage instance wrapped with in-memory cache layer\"\"\"\n        persist_storage = DummyCacheStorage()\n        return InMemoryCacheStorageWrapper(\n            persist_storage=persist_storage, context=context\n        )\n\n    def clear_all(self) -> None:\n        raise NotImplementedError\n\n    def check_context(self, context: CacheStorageContext) -> None:\n        pass\n\n\nclass DummyCacheStorage(CacheStorage):\n    def get(self, key: str) -> bytes:\n        \"\"\"\n        Dummy gets the value for a given key,\n        always raises an CacheStorageKeyNotFoundError\n        \"\"\"\n        raise CacheStorageKeyNotFoundError(\"Key not found in dummy cache\")\n\n    def set(self, key: str, value: bytes) -> None:\n        pass\n\n    def delete(self, key: str) -> None:\n        pass\n\n    def clear(self) -> None:\n        pass\n\n    def close(self) -> None:\n        pass\n", "lib/streamlit/runtime/caching/storage/cache_storage_protocol.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Declares the CacheStorageContext dataclass, which contains parameter information for\neach function decorated by `@st.cache_data` (for example: ttl, max_entries etc.)\n\nDeclares the CacheStorageManager protocol, which implementations are used\nto create CacheStorage instances and to optionally clear all cache storages,\nthat were created by this manager, and to check if the context is valid for the storage.\n\nDeclares the CacheStorage protocol, which implementations are used to store cached\nvalues for a single `@st.cache_data` decorated function serialized as bytes.\n\nHow these classes work together\n-------------------------------\n- CacheStorageContext : this is a dataclass that contains the parameters from\n`@st.cache_data` that are passed to the CacheStorageManager.create() method.\n\n- CacheStorageManager : each instance of this is able to create CacheStorage\ninstances, and optionally to clear data of all cache storages.\n\n- CacheStorage : each instance of this is able to get, set, delete, and clear\nentries for a single `@st.cache_data` decorated function.\n\n  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n  \u2502                               \u2502\n  \u2502    CacheStorageManager        \u2502\n  \u2502                               \u2502\n  \u2502     - clear_all(optional)     \u2502\n  \u2502     - check_context           \u2502\n  \u2502                               \u2502\n  \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2502\n     \u2502                \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n     \u2502                \u2502  CacheStorage        \u2502\n     \u2502 create(context)\u2502                      \u2502\n     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba    - get             \u2502\n                      \u2502    - set             \u2502\n                      \u2502    - delete          \u2502\n                      \u2502    - close (optional)\u2502\n                      \u2502    - clear           \u2502\n                      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\"\"\"\n\nfrom __future__ import annotations\n\nfrom abc import abstractmethod\nfrom dataclasses import dataclass\nfrom typing import Literal, Protocol\n\n\nclass CacheStorageError(Exception):\n    \"\"\"Base exception raised by the cache storage\"\"\"\n\n\nclass CacheStorageKeyNotFoundError(CacheStorageError):\n    \"\"\"Raised when the key is not found in the cache storage\"\"\"\n\n\nclass InvalidCacheStorageContext(CacheStorageError):\n    \"\"\"Raised if the cache storage manager is not able to work with\n    provided CacheStorageContext.\n    \"\"\"\n\n\n@dataclass(frozen=True)\nclass CacheStorageContext:\n    \"\"\"Context passed to the cache storage during initialization\n    This is the normalized parameters that are passed to CacheStorageManager.create()\n    method.\n\n    Parameters\n    ----------\n    function_key: str\n        A hash computed based on function name and source code decorated\n        by `@st.cache_data`\n\n    function_display_name: str\n        The display name of the function that is decorated by `@st.cache_data`\n\n    ttl_seconds : float or None\n        The time-to-live for the keys in storage, in seconds. If None, the entry\n        will never expire.\n\n    max_entries : int or None\n        The maximum number of entries to store in the cache storage.\n        If None, the cache storage will not limit the number of entries.\n\n    persist : Literal[\"disk\"] or None\n        The persistence mode for the cache storage.\n        Legacy parameter, that used in Streamlit current cache storage implementation.\n        Could be ignored by cache storage implementation, if storage does not support\n        persistence or it persistent by default.\n    \"\"\"\n\n    function_key: str\n    function_display_name: str\n    ttl_seconds: float | None = None\n    max_entries: int | None = None\n    persist: Literal[\"disk\"] | None = None\n\n\nclass CacheStorage(Protocol):\n    \"\"\"Cache storage protocol, that should be implemented by the concrete cache storages.\n    Used to store cached values for a single `@st.cache_data` decorated function\n    serialized as bytes.\n\n    CacheStorage instances should be created by `CacheStorageManager.create()` method.\n\n    Notes\n    -----\n    Threading: The methods of this protocol could be called from multiple threads.\n    This is a responsibility of the concrete implementation to ensure thread safety\n    guarantees.\n    \"\"\"\n\n    @abstractmethod\n    def get(self, key: str) -> bytes:\n        \"\"\"Returns the stored value for the key.\n\n        Raises\n        ------\n        CacheStorageKeyNotFoundError\n            Raised if the key is not in the storage.\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def set(self, key: str, value: bytes) -> None:\n        \"\"\"Sets the value for a given key\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def delete(self, key: str) -> None:\n        \"\"\"Delete a given key\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def clear(self) -> None:\n        \"\"\"Remove all keys for the storage\"\"\"\n        raise NotImplementedError\n\n    def close(self) -> None:\n        \"\"\"Closes the cache storage, it is optional to implement, and should be used\n        to close open resources, before we delete the storage instance.\n        e.g. close the database connection etc.\n        \"\"\"\n        pass\n\n\nclass CacheStorageManager(Protocol):\n    \"\"\"Cache storage manager protocol, that should be implemented by the concrete\n    cache storage managers.\n\n    It is responsible for:\n        - Creating cache storage instances for the specific\n        decorated functions,\n        - Validating the context for the cache storages.\n        - Optionally clearing all cache storages in optimal way.\n\n    It should be created during Runtime initialization.\n    \"\"\"\n\n    @abstractmethod\n    def create(self, context: CacheStorageContext) -> CacheStorage:\n        \"\"\"Creates a new cache storage instance\n        Please note that the ttl, max_entries and other context fields are specific\n        for whole storage, not for individual key.\n\n        Notes\n        -----\n        Threading: Should be safe to call from any thread.\n        \"\"\"\n        raise NotImplementedError\n\n    def clear_all(self) -> None:\n        \"\"\"Remove everything what possible from the cache storages in optimal way.\n        meaningful default behaviour is to raise NotImplementedError, so this is not\n        abstractmethod.\n\n        The method is optional to implement: cache data API will fall back to remove\n        all available storages one by one via storage.clear() method\n        if clear_all raises NotImplementedError.\n\n        Raises\n        ------\n        NotImplementedError\n            Raised if the storage manager does not provide an ability to clear\n            all storages at once in optimal way.\n\n        Notes\n        -----\n        Threading: This method could be called from multiple threads.\n        This is a responsibility of the concrete implementation to ensure\n        thread safety guarantees.\n        \"\"\"\n        raise NotImplementedError\n\n    def check_context(self, context: CacheStorageContext) -> None:\n        \"\"\"Checks if the context is valid for the storage manager.\n        This method should not return anything, but log message or raise an exception\n        if the context is invalid.\n\n        In case of raising an exception, we not handle it and let the exception to be\n        propagated.\n\n        check_context is called only once at the moment of creating `@st.cache_data`\n        decorator for specific function, so it is not called for every cache hit.\n\n        Parameters\n        ----------\n        context: CacheStorageContext\n            The context to check for the storage manager, dummy function_key in context\n            will be used, since it is not computed at the point of calling this method.\n\n        Raises\n        ------\n        InvalidCacheStorageContext\n            Raised if the cache storage manager is not able to work with provided\n            CacheStorageContext. When possible we should log message instead, since\n            this exception will be propagated to the user.\n\n        Notes\n        -----\n        Threading: Should be safe to call from any thread.\n        \"\"\"\n\n        pass\n", "lib/streamlit/runtime/caching/storage/in_memory_cache_storage_wrapper.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nfrom __future__ import annotations\n\nimport math\nimport threading\n\nfrom cachetools import TTLCache\n\nfrom streamlit.logger import get_logger\nfrom streamlit.runtime.caching import cache_utils\nfrom streamlit.runtime.caching.storage.cache_storage_protocol import (\n    CacheStorage,\n    CacheStorageContext,\n    CacheStorageKeyNotFoundError,\n)\nfrom streamlit.runtime.stats import CacheStat\n\n_LOGGER = get_logger(__name__)\n\n\nclass InMemoryCacheStorageWrapper(CacheStorage):\n    \"\"\"\n    In-memory cache storage wrapper.\n\n    This class wraps a cache storage and adds an in-memory cache front layer,\n    which is used to reduce the number of calls to the storage.\n\n    The in-memory cache is a TTL cache, which means that the entries are\n    automatically removed if a given time to live (TTL) has passed.\n\n    The in-memory cache is also an LRU cache, which means that the entries\n    are automatically removed if the cache size exceeds a given maxsize.\n\n    If the storage implements its strategy for maxsize, it is recommended\n    (but not necessary) that the storage implement the same LRU strategy,\n    otherwise a situation may arise when different items are deleted from\n    the memory cache and from the storage.\n\n    Notes\n    -----\n    Threading: in-memory caching layer is thread safe: we hold self._mem_cache_lock for\n    working with this self._mem_cache object.\n    However, we do not hold this lock when calling into the underlying storage,\n    so it is the responsibility of the that storage to ensure that it is safe to use\n    it from multiple threads.\n    \"\"\"\n\n    def __init__(self, persist_storage: CacheStorage, context: CacheStorageContext):\n        self.function_key = context.function_key\n        self.function_display_name = context.function_display_name\n        self._ttl_seconds = context.ttl_seconds\n        self._max_entries = context.max_entries\n        self._mem_cache: TTLCache[str, bytes] = TTLCache(\n            maxsize=self.max_entries,\n            ttl=self.ttl_seconds,\n            timer=cache_utils.TTLCACHE_TIMER,\n        )\n        self._mem_cache_lock = threading.Lock()\n        self._persist_storage = persist_storage\n\n    @property\n    def ttl_seconds(self) -> float:\n        return self._ttl_seconds if self._ttl_seconds is not None else math.inf\n\n    @property\n    def max_entries(self) -> float:\n        return float(self._max_entries) if self._max_entries is not None else math.inf\n\n    def get(self, key: str) -> bytes:\n        \"\"\"\n        Returns the stored value for the key or raise CacheStorageKeyNotFoundError if\n        the key is not found\n        \"\"\"\n        try:\n            entry_bytes = self._read_from_mem_cache(key)\n        except CacheStorageKeyNotFoundError:\n            entry_bytes = self._persist_storage.get(key)\n            self._write_to_mem_cache(key, entry_bytes)\n        return entry_bytes\n\n    def set(self, key: str, value: bytes) -> None:\n        \"\"\"Sets the value for a given key\"\"\"\n        self._write_to_mem_cache(key, value)\n        self._persist_storage.set(key, value)\n\n    def delete(self, key: str) -> None:\n        \"\"\"Delete a given key\"\"\"\n        self._remove_from_mem_cache(key)\n        self._persist_storage.delete(key)\n\n    def clear(self) -> None:\n        \"\"\"Delete all keys for the in memory cache, and also the persistent storage\"\"\"\n        with self._mem_cache_lock:\n            self._mem_cache.clear()\n        self._persist_storage.clear()\n\n    def get_stats(self) -> list[CacheStat]:\n        \"\"\"Returns a list of stats in bytes for the cache memory storage per item\"\"\"\n        stats = []\n\n        with self._mem_cache_lock:\n            for item in self._mem_cache.values():\n                stats.append(\n                    CacheStat(\n                        category_name=\"st_cache_data\",\n                        cache_name=self.function_display_name,\n                        byte_length=len(item),\n                    )\n                )\n        return stats\n\n    def close(self) -> None:\n        \"\"\"Closes the cache storage\"\"\"\n        self._persist_storage.close()\n\n    def _read_from_mem_cache(self, key: str) -> bytes:\n        with self._mem_cache_lock:\n            if key in self._mem_cache:\n                entry = bytes(self._mem_cache[key])\n                _LOGGER.debug(\"Memory cache HIT: %s\", key)\n                return entry\n\n            else:\n                _LOGGER.debug(\"Memory cache MISS: %s\", key)\n                raise CacheStorageKeyNotFoundError(\"Key not found in mem cache\")\n\n    def _write_to_mem_cache(self, key: str, entry_bytes: bytes) -> None:\n        with self._mem_cache_lock:\n            self._mem_cache[key] = entry_bytes\n\n    def _remove_from_mem_cache(self, key: str) -> None:\n        with self._mem_cache_lock:\n            self._mem_cache.pop(key, None)\n", "lib/streamlit/runtime/caching/storage/local_disk_cache_storage.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Declares the LocalDiskCacheStorageManager class, which is used\nto create LocalDiskCacheStorage instances wrapped by InMemoryCacheStorageWrapper,\nInMemoryCacheStorageWrapper wrapper allows to have first layer of in-memory cache,\nbefore accessing to LocalDiskCacheStorage itself.\n\nDeclares the LocalDiskCacheStorage class, which is used to store cached\nvalues on disk.\n\nHow these classes work together\n-------------------------------\n\n- LocalDiskCacheStorageManager : each instance of this is able\nto create LocalDiskCacheStorage instances wrapped by InMemoryCacheStorageWrapper,\nand to clear data from cache storage folder. It is also LocalDiskCacheStorageManager\nresponsibility to check if the context is valid for the storage, and to log warning\nif the context is not valid.\n\n- LocalDiskCacheStorage : each instance of this is able to get, set, delete, and clear\nentries from disk for a single `@st.cache_data` decorated function if `persist=\"disk\"`\nis used in CacheStorageContext.\n\n\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502  LocalDiskCacheStorageManager \u2502\n    \u2502                               \u2502\n    \u2502     - clear_all               \u2502\n    \u2502     - check_context           \u2502\n    \u2502                               \u2502\n    \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502\n       \u2502                \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n       \u2502                \u2502                              \u2502\n       \u2502 create(context)\u2502  InMemoryCacheStorageWrapper \u2502\n       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba                              \u2502\n                        \u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n                        \u2502    \u2502                     \u2502   \u2502\n                        \u2502    \u2502   LocalDiskStorage  \u2502   \u2502\n                        \u2502    \u2502                     \u2502   \u2502\n                        \u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n                        \u2502                              \u2502\n                        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n\"\"\"\n\nfrom __future__ import annotations\n\nimport math\nimport os\nimport shutil\nfrom typing import Final\n\nfrom streamlit import util\nfrom streamlit.file_util import get_streamlit_file_path, streamlit_read, streamlit_write\nfrom streamlit.logger import get_logger\nfrom streamlit.runtime.caching.storage.cache_storage_protocol import (\n    CacheStorage,\n    CacheStorageContext,\n    CacheStorageError,\n    CacheStorageKeyNotFoundError,\n    CacheStorageManager,\n)\nfrom streamlit.runtime.caching.storage.in_memory_cache_storage_wrapper import (\n    InMemoryCacheStorageWrapper,\n)\n\n_LOGGER: Final = get_logger(__name__)\n\n# Streamlit directory where persisted @st.cache_data objects live.\n# (This is the same directory that @st.cache persisted objects live.\n# But @st.cache_data uses a different extension, so they don't overlap.)\n_CACHE_DIR_NAME: Final = \"cache\"\n\n# The extension for our persisted @st.cache_data objects.\n# (`@st.cache_data` was originally called `@st.memo`)\n_CACHED_FILE_EXTENSION: Final = \"memo\"\n\n\nclass LocalDiskCacheStorageManager(CacheStorageManager):\n    def create(self, context: CacheStorageContext) -> CacheStorage:\n        \"\"\"Creates a new cache storage instance wrapped with in-memory cache layer\"\"\"\n        persist_storage = LocalDiskCacheStorage(context)\n        return InMemoryCacheStorageWrapper(\n            persist_storage=persist_storage, context=context\n        )\n\n    def clear_all(self) -> None:\n        cache_path = get_cache_folder_path()\n        if os.path.isdir(cache_path):\n            shutil.rmtree(cache_path)\n\n    def check_context(self, context: CacheStorageContext) -> None:\n        if (\n            context.persist == \"disk\"\n            and context.ttl_seconds is not None\n            and not math.isinf(context.ttl_seconds)\n        ):\n            _LOGGER.warning(\n                f\"The cached function '{context.function_display_name}' has a TTL \"\n                \"that will be ignored. Persistent cached functions currently don't \"\n                \"support TTL.\"\n            )\n\n\nclass LocalDiskCacheStorage(CacheStorage):\n    \"\"\"Cache storage that persists data to disk\n    This is the default cache persistence layer for `@st.cache_data`\n    \"\"\"\n\n    def __init__(self, context: CacheStorageContext):\n        self.function_key = context.function_key\n        self.persist = context.persist\n        self._ttl_seconds = context.ttl_seconds\n        self._max_entries = context.max_entries\n\n    @property\n    def ttl_seconds(self) -> float:\n        return self._ttl_seconds if self._ttl_seconds is not None else math.inf\n\n    @property\n    def max_entries(self) -> float:\n        return float(self._max_entries) if self._max_entries is not None else math.inf\n\n    def get(self, key: str) -> bytes:\n        \"\"\"\n        Returns the stored value for the key if persisted,\n        raise CacheStorageKeyNotFoundError if not found, or not configured\n        with persist=\"disk\"\n        \"\"\"\n        if self.persist == \"disk\":\n            path = self._get_cache_file_path(key)\n            try:\n                with streamlit_read(path, binary=True) as input:\n                    value = input.read()\n                    _LOGGER.debug(\"Disk cache HIT: %s\", key)\n                    return bytes(value)\n            except FileNotFoundError:\n                raise CacheStorageKeyNotFoundError(\"Key not found in disk cache\")\n            except Exception as ex:\n                _LOGGER.error(ex)\n                raise CacheStorageError(\"Unable to read from cache\") from ex\n        else:\n            raise CacheStorageKeyNotFoundError(\n                f\"Local disk cache storage is disabled (persist={self.persist})\"\n            )\n\n    def set(self, key: str, value: bytes) -> None:\n        \"\"\"Sets the value for a given key\"\"\"\n        if self.persist == \"disk\":\n            path = self._get_cache_file_path(key)\n            try:\n                with streamlit_write(path, binary=True) as output:\n                    output.write(value)\n            except util.Error as e:\n                _LOGGER.debug(e)\n                # Clean up file so we don't leave zero byte files.\n                try:\n                    os.remove(path)\n                except (FileNotFoundError, OSError):\n                    # If we can't remove the file, it's not a big deal.\n                    pass\n                raise CacheStorageError(\"Unable to write to cache\") from e\n\n    def delete(self, key: str) -> None:\n        \"\"\"Delete a cache file from disk. If the file does not exist on disk,\n        return silently. If another exception occurs, log it. Does not throw.\n        \"\"\"\n        if self.persist == \"disk\":\n            path = self._get_cache_file_path(key)\n            try:\n                os.remove(path)\n            except FileNotFoundError:\n                # The file is already removed.\n                pass\n            except Exception as ex:\n                _LOGGER.exception(\n                    \"Unable to remove a file from the disk cache\", exc_info=ex\n                )\n\n    def clear(self) -> None:\n        \"\"\"Delete all keys for the current storage\"\"\"\n        cache_dir = get_cache_folder_path()\n\n        if os.path.isdir(cache_dir):\n            # We try to remove all files in the cache directory that start with\n            # the function key, whether `clear` called for `self.persist`\n            # storage or not, to avoid leaving orphaned files in the cache directory.\n            for file_name in os.listdir(cache_dir):\n                if self._is_cache_file(file_name):\n                    os.remove(os.path.join(cache_dir, file_name))\n\n    def close(self) -> None:\n        \"\"\"Dummy implementation of close, we don't need to actually \"close\" anything\"\"\"\n\n    def _get_cache_file_path(self, value_key: str) -> str:\n        \"\"\"Return the path of the disk cache file for the given value.\"\"\"\n        cache_dir = get_cache_folder_path()\n        return os.path.join(\n            cache_dir, f\"{self.function_key}-{value_key}.{_CACHED_FILE_EXTENSION}\"\n        )\n\n    def _is_cache_file(self, fname: str) -> bool:\n        \"\"\"Return true if the given file name is a cache file for this storage.\"\"\"\n        return fname.startswith(f\"{self.function_key}-\") and fname.endswith(\n            f\".{_CACHED_FILE_EXTENSION}\"\n        )\n\n\ndef get_cache_folder_path() -> str:\n    return get_streamlit_file_path(_CACHE_DIR_NAME)\n", "lib/streamlit/runtime/caching/storage/__init__.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom streamlit.runtime.caching.storage.cache_storage_protocol import (\n    CacheStorage,\n    CacheStorageContext,\n    CacheStorageError,\n    CacheStorageKeyNotFoundError,\n    CacheStorageManager,\n)\n\n__all__ = [\n    \"CacheStorage\",\n    \"CacheStorageContext\",\n    \"CacheStorageError\",\n    \"CacheStorageKeyNotFoundError\",\n    \"CacheStorageManager\",\n]\n", "lib/streamlit/runtime/state/common.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Functions and data structures shared by session_state.py and widgets.py\"\"\"\n\nfrom __future__ import annotations\n\nimport hashlib\nfrom dataclasses import dataclass, field\nfrom datetime import date, datetime, time, timedelta\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    Callable,\n    Dict,\n    Final,\n    Generic,\n    Iterable,\n    Tuple,\n    TypeVar,\n    Union,\n)\n\nfrom google.protobuf.message import Message\nfrom typing_extensions import TypeAlias\n\nfrom streamlit import config, util\nfrom streamlit.errors import StreamlitAPIException\nfrom streamlit.proto.Arrow_pb2 import Arrow\nfrom streamlit.proto.ArrowVegaLiteChart_pb2 import ArrowVegaLiteChart\nfrom streamlit.proto.Button_pb2 import Button\nfrom streamlit.proto.CameraInput_pb2 import CameraInput\nfrom streamlit.proto.ChatInput_pb2 import ChatInput\nfrom streamlit.proto.Checkbox_pb2 import Checkbox\nfrom streamlit.proto.ColorPicker_pb2 import ColorPicker\nfrom streamlit.proto.Components_pb2 import ComponentInstance\nfrom streamlit.proto.DateInput_pb2 import DateInput\nfrom streamlit.proto.DownloadButton_pb2 import DownloadButton\nfrom streamlit.proto.FileUploader_pb2 import FileUploader\nfrom streamlit.proto.MultiSelect_pb2 import MultiSelect\nfrom streamlit.proto.NumberInput_pb2 import NumberInput\nfrom streamlit.proto.PlotlyChart_pb2 import PlotlyChart\nfrom streamlit.proto.Radio_pb2 import Radio\nfrom streamlit.proto.Selectbox_pb2 import Selectbox\nfrom streamlit.proto.Slider_pb2 import Slider\nfrom streamlit.proto.TextArea_pb2 import TextArea\nfrom streamlit.proto.TextInput_pb2 import TextInput\nfrom streamlit.proto.TimeInput_pb2 import TimeInput\nfrom streamlit.util import HASHLIB_KWARGS\n\nif TYPE_CHECKING:\n    from builtins import ellipsis\n\n    from streamlit.runtime.scriptrunner.script_run_context import ScriptRunContext\n    from streamlit.runtime.state.widgets import NoValue\n    from streamlit.type_util import ValueFieldName\n\n\n# Protobuf types for all widgets.\nWidgetProto: TypeAlias = Union[\n    Arrow,\n    ArrowVegaLiteChart,\n    Button,\n    CameraInput,\n    ChatInput,\n    Checkbox,\n    ColorPicker,\n    ComponentInstance,\n    DateInput,\n    DownloadButton,\n    FileUploader,\n    MultiSelect,\n    NumberInput,\n    PlotlyChart,\n    Radio,\n    Selectbox,\n    Slider,\n    TextArea,\n    TextInput,\n    TimeInput,\n]\n\nGENERATED_WIDGET_ID_PREFIX: Final = \"$$WIDGET_ID\"\nTESTING_KEY = \"$$STREAMLIT_INTERNAL_KEY_TESTING\"\n\n\nT = TypeVar(\"T\")\nT_co = TypeVar(\"T_co\", covariant=True)\n\n\nWidgetArgs: TypeAlias = Tuple[Any, ...]\nWidgetKwargs: TypeAlias = Dict[str, Any]\nWidgetCallback: TypeAlias = Callable[..., None]\n\n# A deserializer receives the value from whatever field is set on the\n# WidgetState proto, and returns a regular python value. A serializer\n# receives a regular python value, and returns something suitable for\n# a value field on WidgetState proto. They should be inverses.\nWidgetDeserializer: TypeAlias = Callable[[Any, str], T]\nWidgetSerializer: TypeAlias = Callable[[T], Any]\n\n\n@dataclass(frozen=True)\nclass WidgetMetadata(Generic[T]):\n    \"\"\"Metadata associated with a single widget. Immutable.\"\"\"\n\n    id: str\n    deserializer: WidgetDeserializer[T] = field(repr=False)\n    serializer: WidgetSerializer[T] = field(repr=False)\n    value_type: ValueFieldName\n\n    # An optional user-code callback invoked when the widget's value changes.\n    # Widget callbacks are called at the start of a script run, before the\n    # body of the script is executed.\n    callback: WidgetCallback | None = None\n    callback_args: WidgetArgs | None = None\n    callback_kwargs: WidgetKwargs | None = None\n\n    fragment_id: str | None = None\n\n    def __repr__(self) -> str:\n        return util.repr_(self)\n\n\n@dataclass(frozen=True)\nclass RegisterWidgetResult(Generic[T_co]):\n    \"\"\"Result returned by the `register_widget` family of functions/methods.\n\n    Should be usable by widget code to determine what value to return, and\n    whether to update the UI.\n\n    Parameters\n    ----------\n    value : T_co\n        The widget's current value, or, in cases where the true widget value\n        could not be determined, an appropriate fallback value.\n\n        This value should be returned by the widget call.\n    value_changed : bool\n        True if the widget's value is different from the value most recently\n        returned from the frontend.\n\n        Implies an update to the frontend is needed.\n    \"\"\"\n\n    value: T_co\n    value_changed: bool\n\n    @classmethod\n    def failure(\n        cls, deserializer: WidgetDeserializer[T_co]\n    ) -> RegisterWidgetResult[T_co]:\n        \"\"\"The canonical way to construct a RegisterWidgetResult in cases\n        where the true widget value could not be determined.\n        \"\"\"\n        return cls(value=deserializer(None, \"\"), value_changed=False)\n\n\nPROTO_SCALAR_VALUE = Union[float, int, bool, str, bytes]\nSAFE_VALUES = Union[\n    date,\n    time,\n    datetime,\n    timedelta,\n    None,\n    \"NoValue\",\n    \"ellipsis\",\n    Message,\n    PROTO_SCALAR_VALUE,\n]\n\n\ndef compute_widget_id(\n    element_type: str,\n    user_key: str | None = None,\n    **kwargs: SAFE_VALUES | Iterable[SAFE_VALUES],\n) -> str:\n    \"\"\"Compute the widget id for the given widget. This id is stable: a given\n    set of inputs to this function will always produce the same widget id output.\n\n    Only stable, deterministic values should be used to compute widget ids. Using\n    nondeterministic values as inputs can cause the resulting widget id to\n    change between runs.\n\n    The widget id includes the user_key so widgets with identical arguments can\n    use it to be distinct.\n\n    The widget id includes an easily identified prefix, and the user_key as a\n    suffix, to make it easy to identify it and know if a key maps to it.\n    \"\"\"\n    h = hashlib.new(\"md5\", **HASHLIB_KWARGS)\n    h.update(element_type.encode(\"utf-8\"))\n    # This will iterate in a consistent order when the provided arguments have\n    # consistent order; dicts are always in insertion order.\n    for k, v in kwargs.items():\n        h.update(str(k).encode(\"utf-8\"))\n        h.update(str(v).encode(\"utf-8\"))\n    return f\"{GENERATED_WIDGET_ID_PREFIX}-{h.hexdigest()}-{user_key}\"\n\n\ndef user_key_from_widget_id(widget_id: str) -> str | None:\n    \"\"\"Return the user key portion of a widget id, or None if the id does not\n    have a user key.\n\n    TODO This will incorrectly indicate no user key if the user actually provides\n    \"None\" as a key, but we can't avoid this kind of problem while storing the\n    string representation of the no-user-key sentinel as part of the widget id.\n    \"\"\"\n    user_key: str | None = widget_id.split(\"-\", maxsplit=2)[-1]\n    user_key = None if user_key == \"None\" else user_key\n    return user_key\n\n\ndef is_widget_id(key: str) -> bool:\n    \"\"\"True if the given session_state key has the structure of a widget ID.\"\"\"\n    return key.startswith(GENERATED_WIDGET_ID_PREFIX)\n\n\ndef is_keyed_widget_id(key: str) -> bool:\n    \"\"\"True if the given session_state key has the structure of a widget ID with a user_key.\"\"\"\n    return is_widget_id(key) and not key.endswith(\"-None\")\n\n\ndef require_valid_user_key(key: str) -> None:\n    \"\"\"Raise an Exception if the given user_key is invalid.\"\"\"\n    if is_widget_id(key):\n        raise StreamlitAPIException(\n            f\"Keys beginning with {GENERATED_WIDGET_ID_PREFIX} are reserved.\"\n        )\n\n\ndef save_for_app_testing(ctx: ScriptRunContext, k: str, v: Any):\n    if config.get_option(\"global.appTest\"):\n        try:\n            ctx.session_state[TESTING_KEY][k] = v\n        except KeyError:\n            ctx.session_state[TESTING_KEY] = {k: v}\n", "lib/streamlit/runtime/state/safe_session_state.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport threading\nfrom contextlib import contextmanager\nfrom typing import TYPE_CHECKING, Any, Callable, Iterator\n\nif TYPE_CHECKING:\n    from streamlit.proto.WidgetStates_pb2 import WidgetState as WidgetStateProto\n    from streamlit.proto.WidgetStates_pb2 import WidgetStates as WidgetStatesProto\n    from streamlit.runtime.state.common import RegisterWidgetResult, T, WidgetMetadata\n    from streamlit.runtime.state.query_params import QueryParams\n    from streamlit.runtime.state.session_state import SessionState\n\n\nclass SafeSessionState:\n    \"\"\"Thread-safe wrapper around SessionState.\n\n    When AppSession gets a re-run request, it can interrupt its existing\n    ScriptRunner and spin up a new ScriptRunner to handle the request.\n    When this happens, the existing ScriptRunner will continue executing\n    its script until it reaches a yield point - but during this time, it\n    must not mutate its SessionState.\n    \"\"\"\n\n    _state: SessionState\n    _lock: threading.RLock\n    _yield_callback: Callable[[], None]\n\n    def __init__(self, state: SessionState, yield_callback: Callable[[], None]):\n        # Fields must be set using the object's setattr method to avoid\n        # infinite recursion from trying to look up the fields we're setting.\n        object.__setattr__(self, \"_state\", state)\n        # TODO: we'd prefer this be a threading.Lock instead of RLock -\n        #  but `call_callbacks` first needs to be rewritten.\n        object.__setattr__(self, \"_lock\", threading.RLock())\n        object.__setattr__(self, \"_yield_callback\", yield_callback)\n\n    def register_widget(\n        self, metadata: WidgetMetadata[T], user_key: str | None\n    ) -> RegisterWidgetResult[T]:\n        self._yield_callback()\n        with self._lock:\n            return self._state.register_widget(metadata, user_key)\n\n    def on_script_will_rerun(self, latest_widget_states: WidgetStatesProto) -> None:\n        self._yield_callback()\n        with self._lock:\n            # TODO: rewrite this to copy the callbacks list into a local\n            #  variable so that we don't need to hold our lock for the\n            #  duration. (This will also allow us to downgrade our RLock\n            #  to a Lock.)\n            self._state.on_script_will_rerun(latest_widget_states)\n\n    def on_script_finished(self, widget_ids_this_run: set[str]) -> None:\n        with self._lock:\n            self._state.on_script_finished(widget_ids_this_run)\n\n    def maybe_check_serializable(self) -> None:\n        with self._lock:\n            self._state.maybe_check_serializable()\n\n    def get_widget_states(self) -> list[WidgetStateProto]:\n        \"\"\"Return a list of serialized widget values for each widget with a value.\"\"\"\n        with self._lock:\n            return self._state.get_widget_states()\n\n    def is_new_state_value(self, user_key: str) -> bool:\n        with self._lock:\n            return self._state.is_new_state_value(user_key)\n\n    @property\n    def filtered_state(self) -> dict[str, Any]:\n        \"\"\"The combined session and widget state, excluding keyless widgets.\"\"\"\n        with self._lock:\n            return self._state.filtered_state\n\n    def __getitem__(self, key: str) -> Any:\n        self._yield_callback()\n        with self._lock:\n            return self._state[key]\n\n    def __setitem__(self, key: str, value: Any) -> None:\n        self._yield_callback()\n        with self._lock:\n            self._state[key] = value\n\n    def __delitem__(self, key: str) -> None:\n        self._yield_callback()\n        with self._lock:\n            del self._state[key]\n\n    def __contains__(self, key: str) -> bool:\n        self._yield_callback()\n        with self._lock:\n            return key in self._state\n\n    def __getattr__(self, key: str) -> Any:\n        try:\n            return self[key]\n        except KeyError:\n            raise AttributeError(f\"{key} not found in session_state.\")\n\n    def __setattr__(self, key: str, value: Any) -> None:\n        self[key] = value\n\n    def __delattr__(self, key: str) -> None:\n        try:\n            del self[key]\n        except KeyError:\n            raise AttributeError(f\"{key} not found in session_state.\")\n\n    def __repr__(self):\n        \"\"\"Presents itself as a simple dict of the underlying SessionState instance\"\"\"\n        kv = ((k, self._state[k]) for k in self._state._keys())\n        s = \", \".join(f\"{k}: {v!r}\" for k, v in kv)\n        return f\"{{{s}}}\"\n\n    @contextmanager\n    def query_params(self) -> Iterator[QueryParams]:\n        self._yield_callback()\n        with self._lock:\n            yield self._state.query_params\n", "lib/streamlit/runtime/state/query_params_proxy.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom typing import TYPE_CHECKING, Iterable, Iterator, MutableMapping, overload\n\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.runtime.state.query_params import missing_key_error_message\nfrom streamlit.runtime.state.session_state_proxy import get_session_state\n\nif TYPE_CHECKING:\n    from _typeshed import SupportsKeysAndGetItem\n\n\nclass QueryParamsProxy(MutableMapping[str, str]):\n    \"\"\"\n    A stateless singleton that proxies ``st.query_params`` interactions\n    to the current script thread's QueryParams instance.\n    \"\"\"\n\n    def __iter__(self) -> Iterator[str]:\n        with get_session_state().query_params() as qp:\n            return iter(qp)\n\n    def __len__(self) -> int:\n        with get_session_state().query_params() as qp:\n            return len(qp)\n\n    def __str__(self) -> str:\n        with get_session_state().query_params() as qp:\n            return str(qp)\n\n    @gather_metrics(\"query_params.get_item\")\n    def __getitem__(self, key: str) -> str:\n        with get_session_state().query_params() as qp:\n            return qp[key]\n\n    def __delitem__(self, key: str) -> None:\n        with get_session_state().query_params() as qp:\n            del qp[key]\n\n    @gather_metrics(\"query_params.set_item\")\n    def __setitem__(self, key: str, value: str | Iterable[str]) -> None:\n        with get_session_state().query_params() as qp:\n            qp[key] = value\n\n    @gather_metrics(\"query_params.get_attr\")\n    def __getattr__(self, key: str) -> str:\n        with get_session_state().query_params() as qp:\n            try:\n                return qp[key]\n            except KeyError:\n                raise AttributeError(missing_key_error_message(key))\n\n    def __delattr__(self, key: str) -> None:\n        with get_session_state().query_params() as qp:\n            try:\n                del qp[key]\n            except KeyError:\n                raise AttributeError(missing_key_error_message(key))\n\n    @overload\n    def update(\n        self, mapping: SupportsKeysAndGetItem[str, str | Iterable[str]], /, **kwds: str\n    ) -> None: ...\n\n    @overload\n    def update(\n        self, keys_and_values: Iterable[tuple[str, str | Iterable[str]]], /, **kwds: str\n    ) -> None: ...\n\n    @overload\n    def update(self, **kwds: str | Iterable[str]) -> None: ...\n\n    def update(self, other=(), /, **kwds):\n        \"\"\"\n        Update one or more values in query_params at once from a dictionary or\n        dictionary-like object.\n\n        See `Mapping.update()` from Python's `collections` library.\n\n        Parameters\n        ----------\n        other: SupportsKeysAndGetItem[str, str] | Iterable[tuple[str, str]]\n            A dictionary or mapping of strings to strings.\n        **kwds: str\n            Additional key/value pairs to update passed as keyword arguments.\n        \"\"\"\n        with get_session_state().query_params() as qp:\n            qp.update(other, **kwds)\n\n    @gather_metrics(\"query_params.set_attr\")\n    def __setattr__(self, key: str, value: str | Iterable[str]) -> None:\n        with get_session_state().query_params() as qp:\n            qp[key] = value\n\n    @gather_metrics(\"query_params.get_all\")\n    def get_all(self, key: str) -> list[str]:\n        \"\"\"\n        Get a list of all query parameter values associated to a given key.\n\n        When a key is repeated as a query parameter within the URL, this method\n        allows all values to be obtained. In contrast, dict-like methods only\n        retrieve the last value when a key is repeated in the URL.\n\n        Parameters\n        ----------\n        key: str\n            The label of the query parameter in the URL.\n\n        Returns\n        -------\n        List[str]\n            A list of values associated to the given key. May return zero, one,\n            or multiple values.\n        \"\"\"\n        with get_session_state().query_params() as qp:\n            return qp.get_all(key)\n\n    @gather_metrics(\"query_params.clear\")\n    def clear(self) -> None:\n        \"\"\"\n        Clear all query parameters from the URL of the app.\n\n        Returns\n        -------\n        None\n        \"\"\"\n        with get_session_state().query_params() as qp:\n            qp.clear()\n\n    @gather_metrics(\"query_params.to_dict\")\n    def to_dict(self) -> dict[str, str]:\n        \"\"\"\n        Get all query parameters as a dictionary.\n\n        This method primarily exists for internal use and is not needed for\n        most cases. ``st.query_params`` returns an object that inherits from\n        ``dict`` by default.\n\n        When a key is repeated as a query parameter within the URL, this method\n        will return only the last value of each unique key.\n\n        Returns\n        -------\n        Dict[str,str]\n            A dictionary of the current query paramters in the app's URL.\n        \"\"\"\n        with get_session_state().query_params() as qp:\n            return qp.to_dict()\n\n    @overload\n    def from_dict(\n        self, keys_and_values: Iterable[tuple[str, str | Iterable[str]]]\n    ) -> None: ...\n\n    @overload\n    def from_dict(\n        self, mapping: SupportsKeysAndGetItem[str, str | Iterable[str]]\n    ) -> None: ...\n\n    @gather_metrics(\"query_params.from_dict\")\n    def from_dict(self, params):\n        \"\"\"\n        Set all of the query parameters from a dictionary or dictionary-like object.\n\n        This method primarily exists for advanced users who want to control\n        multiple query parameters in a single update. To set individual query\n        parameters, use key or attribute notation instead.\n\n        This method inherits limitations from ``st.query_params`` and can't be\n        used to set embedding options as described in `Embed your app \\\n        <https://docs.streamlit.io/deploy/streamlit-community-cloud/share-your-app/embed-your-app#embed-options>`_.\n\n        To handle repeated keys, the value in a key-value pair should be a list.\n\n        .. note::\n            ``.from_dict()`` is not a direct inverse of ``.to_dict()`` if\n            you are working with repeated keys. A true inverse operation is\n            ``{key: st.query_params.get_all(key) for key st.query_params}``.\n\n        Parameters\n        ----------\n        params: dict\n            A dictionary used to replace the current query parameters.\n\n        Example\n        -------\n        >>> import streamlit as st\n        >>>\n        >>> st.query_params.from_dict({\"foo\": \"bar\", \"baz\": [1, \"two\"]})\n\n        \"\"\"\n        with get_session_state().query_params() as qp:\n            return qp.from_dict(params)\n", "lib/streamlit/runtime/state/session_state_proxy.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom typing import Any, Final, Iterator, MutableMapping\n\nfrom streamlit import logger as _logger\nfrom streamlit import runtime\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.runtime.state.common import require_valid_user_key\nfrom streamlit.runtime.state.safe_session_state import SafeSessionState\nfrom streamlit.runtime.state.session_state import SessionState\nfrom streamlit.type_util import Key\n\n_LOGGER: Final = _logger.get_logger(__name__)\n\n\n_state_use_warning_already_displayed: bool = False\n# The mock session state is used as a fallback if the script is run without `streamlit run`\n_mock_session_state: SafeSessionState | None = None\n\n\ndef get_session_state() -> SafeSessionState:\n    \"\"\"Get the SessionState object for the current session.\n\n    Note that in streamlit scripts, this function should not be called\n    directly. Instead, SessionState objects should be accessed via\n    st.session_state.\n    \"\"\"\n    global _state_use_warning_already_displayed\n    from streamlit.runtime.scriptrunner import get_script_run_ctx\n\n    ctx = get_script_run_ctx()\n\n    # If there is no script run context because the script is run bare, we\n    # use a global mock session state version to allow bare script execution (via python script.py)\n    if ctx is None:\n        if not _state_use_warning_already_displayed:\n            _state_use_warning_already_displayed = True\n            if not runtime.exists():\n                _LOGGER.warning(\n                    \"Session state does not function when running a script without `streamlit run`\"\n                )\n\n        global _mock_session_state\n\n        if _mock_session_state is None:\n            # Lazy initialize the mock session state\n            _mock_session_state = SafeSessionState(SessionState(), lambda: None)\n        return _mock_session_state\n    return ctx.session_state\n\n\nclass SessionStateProxy(MutableMapping[Key, Any]):\n    \"\"\"A stateless singleton that proxies `st.session_state` interactions\n    to the current script thread's SessionState instance.\n\n    The proxy API differs slightly from SessionState: it does not allow\n    callers to get, set, or iterate over \"keyless\" widgets (that is, widgets\n    that were created without a user_key, and have autogenerated keys).\n    \"\"\"\n\n    def __iter__(self) -> Iterator[Any]:\n        \"\"\"Iterator over user state and keyed widget values.\"\"\"\n        # TODO: this is unsafe if fastReruns is true! Let's deprecate/remove.\n        return iter(get_session_state().filtered_state)\n\n    def __len__(self) -> int:\n        \"\"\"Number of user state and keyed widget values in session_state.\"\"\"\n        return len(get_session_state().filtered_state)\n\n    def __str__(self) -> str:\n        \"\"\"String representation of user state and keyed widget values.\"\"\"\n        return str(get_session_state().filtered_state)\n\n    def __getitem__(self, key: Key) -> Any:\n        \"\"\"Return the state or widget value with the given key.\n\n        Raises\n        ------\n        StreamlitAPIException\n            If the key is not a valid SessionState user key.\n        \"\"\"\n        key = str(key)\n        require_valid_user_key(key)\n        return get_session_state()[key]\n\n    @gather_metrics(\"session_state.set_item\")\n    def __setitem__(self, key: Key, value: Any) -> None:\n        \"\"\"Set the value of the given key.\n\n        Raises\n        ------\n        StreamlitAPIException\n            If the key is not a valid SessionState user key.\n        \"\"\"\n        key = str(key)\n        require_valid_user_key(key)\n        get_session_state()[key] = value\n\n    def __delitem__(self, key: Key) -> None:\n        \"\"\"Delete the value with the given key.\n\n        Raises\n        ------\n        StreamlitAPIException\n            If the key is not a valid SessionState user key.\n        \"\"\"\n        key = str(key)\n        require_valid_user_key(key)\n        del get_session_state()[key]\n\n    def __getattr__(self, key: str) -> Any:\n        try:\n            return self[key]\n        except KeyError:\n            raise AttributeError(_missing_attr_error_message(key))\n\n    @gather_metrics(\"session_state.set_attr\")\n    def __setattr__(self, key: str, value: Any) -> None:\n        self[key] = value\n\n    def __delattr__(self, key: str) -> None:\n        try:\n            del self[key]\n        except KeyError:\n            raise AttributeError(_missing_attr_error_message(key))\n\n    def to_dict(self) -> dict[str, Any]:\n        \"\"\"Return a dict containing all session_state and keyed widget values.\"\"\"\n        return get_session_state().filtered_state\n\n\ndef _missing_attr_error_message(attr_name: str) -> str:\n    return (\n        f'st.session_state has no attribute \"{attr_name}\". Did you forget to initialize it? '\n        f\"More info: https://docs.streamlit.io/develop/concepts/architecture/session-state#initialization\"\n    )\n", "lib/streamlit/runtime/state/__init__.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom streamlit.runtime.state.common import WidgetArgs, WidgetCallback, WidgetKwargs\nfrom streamlit.runtime.state.query_params_proxy import QueryParamsProxy\nfrom streamlit.runtime.state.safe_session_state import SafeSessionState\nfrom streamlit.runtime.state.session_state import (\n    SCRIPT_RUN_WITHOUT_ERRORS_KEY,\n    SessionState,\n    SessionStateStatProvider,\n)\nfrom streamlit.runtime.state.session_state_proxy import (\n    SessionStateProxy,\n    get_session_state,\n)\nfrom streamlit.runtime.state.widgets import (\n    NoValue,\n    coalesce_widget_states,\n    register_widget,\n)\n\n__all__ = [\n    \"WidgetArgs\",\n    \"WidgetCallback\",\n    \"WidgetKwargs\",\n    \"QueryParamsProxy\",\n    \"SafeSessionState\",\n    \"SCRIPT_RUN_WITHOUT_ERRORS_KEY\",\n    \"SessionState\",\n    \"SessionStateStatProvider\",\n    \"SessionStateProxy\",\n    \"get_session_state\",\n    \"NoValue\",\n    \"coalesce_widget_states\",\n    \"register_widget\",\n]\n", "lib/streamlit/runtime/state/session_state.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport json\nimport pickle\nfrom copy import deepcopy\nfrom dataclasses import dataclass, field, replace\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    Final,\n    Iterator,\n    KeysView,\n    List,\n    MutableMapping,\n    Union,\n    cast,\n)\n\nfrom typing_extensions import TypeAlias\n\nimport streamlit as st\nfrom streamlit import config, util\nfrom streamlit.errors import StreamlitAPIException, UnserializableSessionStateError\nfrom streamlit.proto.WidgetStates_pb2 import WidgetState as WidgetStateProto\nfrom streamlit.proto.WidgetStates_pb2 import WidgetStates as WidgetStatesProto\nfrom streamlit.runtime.state.common import (\n    RegisterWidgetResult,\n    T,\n    WidgetMetadata,\n    is_keyed_widget_id,\n    is_widget_id,\n)\nfrom streamlit.runtime.state.query_params import QueryParams\nfrom streamlit.runtime.stats import CacheStat, CacheStatsProvider, group_stats\nfrom streamlit.type_util import ValueFieldName, is_array_value_field_name\n\nif TYPE_CHECKING:\n    from streamlit.runtime.session_manager import SessionManager\n\n\nSTREAMLIT_INTERNAL_KEY_PREFIX: Final = \"$$STREAMLIT_INTERNAL_KEY\"\nSCRIPT_RUN_WITHOUT_ERRORS_KEY: Final = (\n    f\"{STREAMLIT_INTERNAL_KEY_PREFIX}_SCRIPT_RUN_WITHOUT_ERRORS\"\n)\n\n\n@dataclass(frozen=True)\nclass Serialized:\n    \"\"\"A widget value that's serialized to a protobuf. Immutable.\"\"\"\n\n    value: WidgetStateProto\n\n\n@dataclass(frozen=True)\nclass Value:\n    \"\"\"A widget value that's not serialized. Immutable.\"\"\"\n\n    value: Any\n\n\nWState: TypeAlias = Union[Value, Serialized]\n\n\n@dataclass\nclass WStates(MutableMapping[str, Any]):\n    \"\"\"A mapping of widget IDs to values. Widget values can be stored in\n    serialized or deserialized form, but when values are retrieved from the\n    mapping, they'll always be deserialized.\n    \"\"\"\n\n    states: dict[str, WState] = field(default_factory=dict)\n    widget_metadata: dict[str, WidgetMetadata[Any]] = field(default_factory=dict)\n\n    def __repr__(self):\n        return util.repr_(self)\n\n    def __getitem__(self, k: str) -> Any:\n        \"\"\"Return the value of the widget with the given key.\n        If the widget's value is currently stored in serialized form, it\n        will be deserialized first.\n        \"\"\"\n        wstate = self.states.get(k)\n        if wstate is None:\n            raise KeyError(k)\n\n        if isinstance(wstate, Value):\n            # The widget's value is already deserialized - return it directly.\n            return wstate.value\n\n        # The widget's value is serialized. We deserialize it, and return\n        # the deserialized value.\n\n        metadata = self.widget_metadata.get(k)\n        if metadata is None:\n            # No deserializer, which should only happen if state is\n            # gotten from a reconnecting browser and the script is\n            # trying to access it. Pretend it doesn't exist.\n            raise KeyError(k)\n        value_field_name = cast(\n            ValueFieldName,\n            wstate.value.WhichOneof(\"value\"),\n        )\n        value = (\n            wstate.value.__getattribute__(value_field_name)\n            if value_field_name  # Field name is None if the widget value was cleared\n            else None\n        )\n\n        if is_array_value_field_name(value_field_name):\n            # Array types are messages with data in a `data` field\n            value = value.data\n        elif value_field_name == \"json_value\":\n            value = json.loads(value)\n\n        deserialized = metadata.deserializer(value, metadata.id)\n\n        # Update metadata to reflect information from WidgetState proto\n        self.set_widget_metadata(\n            replace(\n                metadata,\n                value_type=value_field_name,\n            )\n        )\n\n        self.states[k] = Value(deserialized)\n        return deserialized\n\n    def __setitem__(self, k: str, v: WState) -> None:\n        self.states[k] = v\n\n    def __delitem__(self, k: str) -> None:\n        del self.states[k]\n\n    def __len__(self) -> int:\n        return len(self.states)\n\n    def __iter__(self):\n        # For this and many other methods, we can't simply delegate to the\n        # states field, because we need to invoke `__getitem__` for any\n        # values, to handle deserialization and unwrapping of values.\n        yield from self.states\n\n    def keys(self) -> KeysView[str]:\n        return KeysView(self.states)\n\n    def items(self) -> set[tuple[str, Any]]:  # type: ignore[override]\n        return {(k, self[k]) for k in self}\n\n    def values(self) -> set[Any]:  # type: ignore[override]\n        return {self[wid] for wid in self}\n\n    def update(self, other: WStates) -> None:  # type: ignore[override]\n        \"\"\"Copy all widget values and metadata from 'other' into this mapping,\n        overwriting any data in this mapping that's also present in 'other'.\n        \"\"\"\n        self.states.update(other.states)\n        self.widget_metadata.update(other.widget_metadata)\n\n    def set_widget_from_proto(self, widget_state: WidgetStateProto) -> None:\n        \"\"\"Set a widget's serialized value, overwriting any existing value it has.\"\"\"\n        self[widget_state.id] = Serialized(widget_state)\n\n    def set_from_value(self, k: str, v: Any) -> None:\n        \"\"\"Set a widget's deserialized value, overwriting any existing value it has.\"\"\"\n        self[k] = Value(v)\n\n    def set_widget_metadata(self, widget_meta: WidgetMetadata[Any]) -> None:\n        \"\"\"Set a widget's metadata, overwriting any existing metadata it has.\"\"\"\n        self.widget_metadata[widget_meta.id] = widget_meta\n\n    def remove_stale_widgets(\n        self,\n        active_widget_ids: set[str],\n        fragment_ids_this_run: set[str] | None,\n    ) -> None:\n        \"\"\"Remove widget state for stale widgets.\"\"\"\n        self.states = {\n            k: v\n            for k, v in self.states.items()\n            if not _is_stale_widget(\n                self.widget_metadata.get(k),\n                active_widget_ids,\n                fragment_ids_this_run,\n            )\n        }\n\n    def get_serialized(self, k: str) -> WidgetStateProto | None:\n        \"\"\"Get the serialized value of the widget with the given id.\n\n        If the widget doesn't exist, return None. If the widget exists but\n        is not in serialized form, it will be serialized first.\n        \"\"\"\n\n        item = self.states.get(k)\n        if item is None:\n            # No such widget: return None.\n            return None\n\n        if isinstance(item, Serialized):\n            # Widget value is serialized: return it directly.\n            return item.value\n\n        # Widget value is not serialized: serialize it first!\n        metadata = self.widget_metadata.get(k)\n        if metadata is None:\n            # We're missing the widget's metadata. (Can this happen?)\n            return None\n\n        widget = WidgetStateProto()\n        widget.id = k\n\n        field = metadata.value_type\n        serialized = metadata.serializer(item.value)\n\n        if is_array_value_field_name(field):\n            arr = getattr(widget, field)\n            arr.data.extend(serialized)\n        elif field == \"json_value\":\n            setattr(widget, field, json.dumps(serialized))\n        elif field == \"file_uploader_state_value\":\n            widget.file_uploader_state_value.CopyFrom(serialized)\n        elif field == \"string_trigger_value\":\n            widget.string_trigger_value.CopyFrom(serialized)\n        elif field is not None and serialized is not None:\n            # If the field is None, the widget value was cleared\n            # by the user and therefore is None. But we cannot\n            # set it to None here, since the proto properties are\n            # not nullable. So we just don't set it.\n            setattr(widget, field, serialized)\n\n        return widget\n\n    def as_widget_states(self) -> list[WidgetStateProto]:\n        \"\"\"Return a list of serialized widget values for each widget with a value.\"\"\"\n        states = [\n            self.get_serialized(widget_id)\n            for widget_id in self.states.keys()\n            if self.get_serialized(widget_id)\n        ]\n        states = cast(List[WidgetStateProto], states)\n        return states\n\n    def call_callback(self, widget_id: str) -> None:\n        \"\"\"Call the given widget's callback and return the callback's\n        return value. If the widget has no callback, return None.\n\n        If the widget doesn't exist, raise an Exception.\n        \"\"\"\n        metadata = self.widget_metadata.get(widget_id)\n        assert metadata is not None\n        callback = metadata.callback\n        if callback is None:\n            return\n\n        args = metadata.callback_args or ()\n        kwargs = metadata.callback_kwargs or {}\n        callback(*args, **kwargs)\n\n\ndef _missing_key_error_message(key: str) -> str:\n    return (\n        f'st.session_state has no key \"{key}\". Did you forget to initialize it? '\n        f\"More info: https://docs.streamlit.io/develop/concepts/architecture/session-state#initialization\"\n    )\n\n\n@dataclass\nclass SessionState:\n    \"\"\"SessionState allows users to store values that persist between app\n    reruns.\n\n    Example\n    -------\n    >>> if \"num_script_runs\" not in st.session_state:\n    ...     st.session_state.num_script_runs = 0\n    >>> st.session_state.num_script_runs += 1\n    >>> st.write(st.session_state.num_script_runs)  # writes 1\n\n    The next time your script runs, the value of\n    st.session_state.num_script_runs will be preserved.\n    >>> st.session_state.num_script_runs += 1\n    >>> st.write(st.session_state.num_script_runs)  # writes 2\n    \"\"\"\n\n    # All the values from previous script runs, squished together to save memory\n    _old_state: dict[str, Any] = field(default_factory=dict)\n\n    # Values set in session state during the current script run, possibly for\n    # setting a widget's value. Keyed by a user provided string.\n    _new_session_state: dict[str, Any] = field(default_factory=dict)\n\n    # Widget values from the frontend, usually one changing prompted the script rerun\n    _new_widget_state: WStates = field(default_factory=WStates)\n\n    # Keys used for widgets will be eagerly converted to the matching widget id\n    _key_id_mapping: dict[str, str] = field(default_factory=dict)\n\n    # query params are stored in session state because query params will be tied with widget state at one point.\n    query_params: QueryParams = field(default_factory=QueryParams)\n\n    def __repr__(self):\n        return util.repr_(self)\n\n    # is it possible for a value to get through this without being deserialized?\n    def _compact_state(self) -> None:\n        \"\"\"Copy all current session_state and widget_state values into our\n        _old_state dict, and then clear our current session_state and\n        widget_state.\n        \"\"\"\n        for key_or_wid in self:\n            try:\n                self._old_state[key_or_wid] = self[key_or_wid]\n            except KeyError:\n                # handle key errors from widget state not having metadata gracefully\n                # https://github.com/streamlit/streamlit/issues/7206\n                pass\n        self._new_session_state.clear()\n        self._new_widget_state.clear()\n\n    def clear(self) -> None:\n        \"\"\"Reset self completely, clearing all current and old values.\"\"\"\n        self._old_state.clear()\n        self._new_session_state.clear()\n        self._new_widget_state.clear()\n        self._key_id_mapping.clear()\n\n    @property\n    def filtered_state(self) -> dict[str, Any]:\n        \"\"\"The combined session and widget state, excluding keyless widgets.\"\"\"\n\n        wid_key_map = self._reverse_key_wid_map\n\n        state: dict[str, Any] = {}\n\n        # We can't write `for k, v in self.items()` here because doing so will\n        # run into a `KeyError` if widget metadata has been cleared (which\n        # happens when the streamlit server restarted or the cache was cleared),\n        # then we receive a widget's state from a browser.\n        for k in self._keys():\n            if not is_widget_id(k) and not _is_internal_key(k):\n                state[k] = self[k]\n            elif is_keyed_widget_id(k):\n                try:\n                    key = wid_key_map[k]\n                    state[key] = self[k]\n                except KeyError:\n                    # Widget id no longer maps to a key, it is a not yet\n                    # cleared value in old state for a reset widget\n                    pass\n\n        return state\n\n    @property\n    def _reverse_key_wid_map(self) -> dict[str, str]:\n        \"\"\"Return a mapping of widget_id : widget_key.\"\"\"\n        wid_key_map = {v: k for k, v in self._key_id_mapping.items()}\n        return wid_key_map\n\n    def _keys(self) -> set[str]:\n        \"\"\"All keys active in Session State, with widget keys converted\n        to widget ids when one is known. (This includes autogenerated keys\n        for widgets that don't have user_keys defined, and which aren't\n        exposed to user code.)\n        \"\"\"\n        old_keys = {self._get_widget_id(k) for k in self._old_state.keys()}\n        new_widget_keys = set(self._new_widget_state.keys())\n        new_session_state_keys = {\n            self._get_widget_id(k) for k in self._new_session_state.keys()\n        }\n        return old_keys | new_widget_keys | new_session_state_keys\n\n    def is_new_state_value(self, user_key: str) -> bool:\n        \"\"\"True if a value with the given key is in the current session state.\"\"\"\n        return user_key in self._new_session_state\n\n    def __iter__(self) -> Iterator[Any]:\n        \"\"\"Return an iterator over the keys of the SessionState.\n        This is a shortcut for `iter(self.keys())`\n        \"\"\"\n        return iter(self._keys())\n\n    def __len__(self) -> int:\n        \"\"\"Return the number of items in SessionState.\"\"\"\n        return len(self._keys())\n\n    def __getitem__(self, key: str) -> Any:\n        wid_key_map = self._reverse_key_wid_map\n        widget_id = self._get_widget_id(key)\n\n        if widget_id in wid_key_map and widget_id == key:\n            # the \"key\" is a raw widget id, so get its associated user key for lookup\n            key = wid_key_map[widget_id]\n        try:\n            return self._getitem(widget_id, key)\n        except KeyError:\n            raise KeyError(_missing_key_error_message(key))\n\n    def _getitem(self, widget_id: str | None, user_key: str | None) -> Any:\n        \"\"\"Get the value of an entry in Session State, using either the\n        user-provided key or a widget id as appropriate for the internal dict\n        being accessed.\n\n        At least one of the arguments must have a value.\n        \"\"\"\n        assert user_key is not None or widget_id is not None\n\n        if user_key is not None:\n            try:\n                return self._new_session_state[user_key]\n            except KeyError:\n                pass\n\n        if widget_id is not None:\n            try:\n                return self._new_widget_state[widget_id]\n            except KeyError:\n                pass\n\n        # Typically, there won't be both a widget id and an associated state key in\n        # old state at the same time, so the order we check is arbitrary.\n        # The exception is if session state is set and then a later run has\n        # a widget created, so the widget id entry should be newer.\n        # The opposite case shouldn't happen, because setting the value of a widget\n        # through session state will result in the next widget state reflecting that\n        # value.\n        if widget_id is not None:\n            try:\n                return self._old_state[widget_id]\n            except KeyError:\n                pass\n\n        if user_key is not None:\n            try:\n                return self._old_state[user_key]\n            except KeyError:\n                pass\n\n        # We'll never get here\n        raise KeyError\n\n    def __setitem__(self, user_key: str, value: Any) -> None:\n        \"\"\"Set the value of the session_state entry with the given user_key.\n\n        If the key corresponds to a widget or form that's been instantiated\n        during the current script run, raise a StreamlitAPIException instead.\n        \"\"\"\n        from streamlit.runtime.scriptrunner import get_script_run_ctx\n\n        ctx = get_script_run_ctx()\n\n        if ctx is not None:\n            widget_id = self._key_id_mapping.get(user_key, None)\n            widget_ids = ctx.widget_ids_this_run\n            form_ids = ctx.form_ids_this_run\n\n            if widget_id in widget_ids or user_key in form_ids:\n                raise StreamlitAPIException(\n                    f\"`st.session_state.{user_key}` cannot be modified after the widget\"\n                    f\" with key `{user_key}` is instantiated.\"\n                )\n\n        self._new_session_state[user_key] = value\n\n    def __delitem__(self, key: str) -> None:\n        widget_id = self._get_widget_id(key)\n\n        if not (key in self or widget_id in self):\n            raise KeyError(_missing_key_error_message(key))\n\n        if key in self._new_session_state:\n            del self._new_session_state[key]\n\n        if key in self._old_state:\n            del self._old_state[key]\n\n        if key in self._key_id_mapping:\n            del self._key_id_mapping[key]\n\n        if widget_id in self._new_widget_state:\n            del self._new_widget_state[widget_id]\n\n        if widget_id in self._old_state:\n            del self._old_state[widget_id]\n\n    def set_widgets_from_proto(self, widget_states: WidgetStatesProto) -> None:\n        \"\"\"Set the value of all widgets represented in the given WidgetStatesProto.\"\"\"\n        for state in widget_states.widgets:\n            self._new_widget_state.set_widget_from_proto(state)\n\n    def on_script_will_rerun(self, latest_widget_states: WidgetStatesProto) -> None:\n        \"\"\"Called by ScriptRunner before its script re-runs.\n\n        Update widget data and call callbacks on widgets whose value changed\n        between the previous and current script runs.\n        \"\"\"\n        # Clear any triggers that weren't reset because the script was disconnected\n        self._reset_triggers()\n        self._compact_state()\n        self.set_widgets_from_proto(latest_widget_states)\n        self._call_callbacks()\n\n    def _call_callbacks(self) -> None:\n        \"\"\"Call any callback associated with each widget whose value\n        changed between the previous and current script runs.\n        \"\"\"\n        from streamlit.runtime.scriptrunner import RerunException\n\n        changed_widget_ids = [\n            wid for wid in self._new_widget_state if self._widget_changed(wid)\n        ]\n        for wid in changed_widget_ids:\n            try:\n                self._new_widget_state.call_callback(wid)\n            except RerunException:\n                st.warning(\"Calling st.rerun() within a callback is a no-op.\")\n\n    def _widget_changed(self, widget_id: str) -> bool:\n        \"\"\"True if the given widget's value changed between the previous\n        script run and the current script run.\n        \"\"\"\n        new_value = self._new_widget_state.get(widget_id)\n        old_value = self._old_state.get(widget_id)\n        changed: bool = new_value != old_value\n        return changed\n\n    def on_script_finished(self, widget_ids_this_run: set[str]) -> None:\n        \"\"\"Called by ScriptRunner after its script finishes running.\n         Updates widgets to prepare for the next script run.\n\n        Parameters\n        ----------\n        widget_ids_this_run: set[str]\n            The IDs of the widgets that were accessed during the script\n            run. Any widget state whose ID does *not* appear in this set\n            is considered \"stale\" and will be removed.\n        \"\"\"\n        self._reset_triggers()\n        self._remove_stale_widgets(widget_ids_this_run)\n\n    def _reset_triggers(self) -> None:\n        \"\"\"Set all trigger values in our state dictionary to False.\"\"\"\n        for state_id in self._new_widget_state:\n            metadata = self._new_widget_state.widget_metadata.get(state_id)\n            if metadata is not None:\n                if metadata.value_type == \"trigger_value\":\n                    self._new_widget_state[state_id] = Value(False)\n                elif metadata.value_type == \"string_trigger_value\":\n                    self._new_widget_state[state_id] = Value(None)\n\n        for state_id in self._old_state:\n            metadata = self._new_widget_state.widget_metadata.get(state_id)\n            if metadata is not None:\n                if metadata.value_type == \"trigger_value\":\n                    self._old_state[state_id] = False\n                elif metadata.value_type == \"string_trigger_value\":\n                    self._old_state[state_id] = None\n\n    def _remove_stale_widgets(self, active_widget_ids: set[str]) -> None:\n        \"\"\"Remove widget state for widgets whose ids aren't in `active_widget_ids`.\"\"\"\n        # Avoid circular imports.\n        from streamlit.runtime.scriptrunner import get_script_run_ctx\n\n        ctx = get_script_run_ctx()\n        if ctx is None:\n            return\n\n        self._new_widget_state.remove_stale_widgets(\n            active_widget_ids,\n            ctx.fragment_ids_this_run,\n        )\n\n        # Remove entries from _old_state corresponding to\n        # widgets not in widget_ids.\n        self._old_state = {\n            k: v\n            for k, v in self._old_state.items()\n            if (\n                not is_widget_id(k)\n                or not _is_stale_widget(\n                    self._new_widget_state.widget_metadata.get(k),\n                    active_widget_ids,\n                    ctx.fragment_ids_this_run,\n                )\n            )\n        }\n\n    def _set_widget_metadata(self, widget_metadata: WidgetMetadata[Any]) -> None:\n        \"\"\"Set a widget's metadata.\"\"\"\n        widget_id = widget_metadata.id\n        self._new_widget_state.widget_metadata[widget_id] = widget_metadata\n\n    def get_widget_states(self) -> list[WidgetStateProto]:\n        \"\"\"Return a list of serialized widget values for each widget with a value.\"\"\"\n        return self._new_widget_state.as_widget_states()\n\n    def _get_widget_id(self, k: str) -> str:\n        \"\"\"Turns a value that might be a widget id or a user provided key into\n        an appropriate widget id.\n        \"\"\"\n        return self._key_id_mapping.get(k, k)\n\n    def _set_key_widget_mapping(self, widget_id: str, user_key: str) -> None:\n        self._key_id_mapping[user_key] = widget_id\n\n    def register_widget(\n        self, metadata: WidgetMetadata[T], user_key: str | None\n    ) -> RegisterWidgetResult[T]:\n        \"\"\"Register a widget with the SessionState.\n\n        Returns\n        -------\n        RegisterWidgetResult[T]\n            Contains the widget's current value, and a bool that will be True\n            if the frontend needs to be updated with the current value.\n        \"\"\"\n        widget_id = metadata.id\n\n        self._set_widget_metadata(metadata)\n        if user_key is not None:\n            # If the widget has a user_key, update its user_key:widget_id mapping\n            self._set_key_widget_mapping(widget_id, user_key)\n\n        if widget_id not in self and (user_key is None or user_key not in self):\n            # This is the first time the widget is registered, so we save its\n            # value in widget state.\n            deserializer = metadata.deserializer\n            initial_widget_value = deepcopy(deserializer(None, metadata.id))\n            self._new_widget_state.set_from_value(widget_id, initial_widget_value)\n\n        # Get the current value of the widget for use as its return value.\n        # We return a copy, so that reference types can't be accidentally\n        # mutated by user code.\n        widget_value = cast(T, self[widget_id])\n        widget_value = deepcopy(widget_value)\n\n        # widget_value_changed indicates to the caller that the widget's\n        # current value is different from what is in the frontend.\n        widget_value_changed = user_key is not None and self.is_new_state_value(\n            user_key\n        )\n\n        return RegisterWidgetResult(widget_value, widget_value_changed)\n\n    def __contains__(self, key: str) -> bool:\n        try:\n            self[key]\n        except KeyError:\n            return False\n        else:\n            return True\n\n    def get_stats(self) -> list[CacheStat]:\n        # Lazy-load vendored package to prevent import of numpy\n        from streamlit.vendor.pympler.asizeof import asizeof\n\n        stat = CacheStat(\"st_session_state\", \"\", asizeof(self))\n        return [stat]\n\n    def _check_serializable(self) -> None:\n        \"\"\"Verify that everything added to session state can be serialized.\n        We use pickleability as the metric for serializability, and test for\n        pickleability by just trying it.\n        \"\"\"\n        for k in self:\n            try:\n                pickle.dumps(self[k])\n            except Exception as e:\n                err_msg = f\"\"\"Cannot serialize the value (of type `{type(self[k])}`) of '{k}' in st.session_state.\n                Streamlit has been configured to use [pickle](https://docs.python.org/3/library/pickle.html) to\n                serialize session_state values. Please convert the value to a pickle-serializable type. To learn\n                more about this behavior, see [our docs](https://docs.streamlit.io/knowledge-base/using-streamlit/serializable-session-state). \"\"\"\n                raise UnserializableSessionStateError(err_msg) from e\n\n    def maybe_check_serializable(self) -> None:\n        \"\"\"Verify that session state can be serialized, if the relevant config\n        option is set.\n\n        See `_check_serializable` for details.\"\"\"\n        if config.get_option(\"runner.enforceSerializableSessionState\"):\n            self._check_serializable()\n\n\ndef _is_internal_key(key: str) -> bool:\n    return key.startswith(STREAMLIT_INTERNAL_KEY_PREFIX)\n\n\ndef _is_stale_widget(\n    metadata: WidgetMetadata[Any] | None,\n    active_widget_ids: set[str],\n    fragment_ids_this_run: set[str] | None,\n) -> bool:\n    if not metadata:\n        return True\n    elif metadata.id in active_widget_ids:\n        return False\n    # If we're running 1 or more fragments, but this widget is unrelated to any of the\n    # fragments that we're running, then it should not be marked as stale as its value\n    # may still be needed for a future fragment run or full script run.\n    elif fragment_ids_this_run and metadata.fragment_id not in fragment_ids_this_run:\n        return False\n    return True\n\n\n@dataclass\nclass SessionStateStatProvider(CacheStatsProvider):\n    _session_mgr: SessionManager\n\n    def get_stats(self) -> list[CacheStat]:\n        stats: list[CacheStat] = []\n        for session_info in self._session_mgr.list_active_sessions():\n            session_state = session_info.session.session_state\n            stats.extend(session_state.get_stats())\n        return group_stats(stats)\n", "lib/streamlit/runtime/state/query_params.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom dataclasses import dataclass, field\nfrom typing import TYPE_CHECKING, Iterable, Iterator, MutableMapping\nfrom urllib import parse\n\nfrom streamlit.constants import EMBED_QUERY_PARAMS_KEYS\nfrom streamlit.errors import StreamlitAPIException\nfrom streamlit.proto.ForwardMsg_pb2 import ForwardMsg\n\nif TYPE_CHECKING:\n    from _typeshed import SupportsKeysAndGetItem\n\n\n@dataclass\nclass QueryParams(MutableMapping[str, str]):\n    \"\"\"A lightweight wrapper of a dict that sends forwardMsgs when state changes.\n    It stores str keys with str and List[str] values.\n    \"\"\"\n\n    _query_params: dict[str, list[str] | str] = field(default_factory=dict)\n\n    def __iter__(self) -> Iterator[str]:\n        self._ensure_single_query_api_used()\n\n        return iter(\n            key\n            for key in self._query_params.keys()\n            if key not in EMBED_QUERY_PARAMS_KEYS\n        )\n\n    def __getitem__(self, key: str) -> str:\n        \"\"\"Retrieves a value for a given key in query parameters.\n        Returns the last item in a list or an empty string if empty.\n        If the key is not present, raise KeyError.\n        \"\"\"\n        self._ensure_single_query_api_used()\n        try:\n            if key in EMBED_QUERY_PARAMS_KEYS:\n                raise KeyError(missing_key_error_message(key))\n            value = self._query_params[key]\n            if isinstance(value, list):\n                if len(value) == 0:\n                    return \"\"\n                else:\n                    # Return the last value to mimic Tornado's behavior\n                    # https://www.tornadoweb.org/en/stable/web.html#tornado.web.RequestHandler.get_query_argument\n                    return value[-1]\n            return value\n        except KeyError:\n            raise KeyError(missing_key_error_message(key))\n\n    def __setitem__(self, key: str, value: str | Iterable[str]) -> None:\n        self._ensure_single_query_api_used()\n        self.__set_item_internal(key, value)\n        self._send_query_param_msg()\n\n    def __set_item_internal(self, key: str, value: str | Iterable[str]) -> None:\n        if isinstance(value, dict):\n            raise StreamlitAPIException(\n                f\"You cannot set a query params key `{key}` to a dictionary.\"\n            )\n\n        if key in EMBED_QUERY_PARAMS_KEYS:\n            raise StreamlitAPIException(\n                \"Query param embed and embed_options (case-insensitive) cannot be set programmatically.\"\n            )\n        # Type checking users should handle the string serialization themselves\n        # We will accept any type for the list and serialize to str just in case\n        if isinstance(value, Iterable) and not isinstance(value, str):\n            self._query_params[key] = [str(item) for item in value]\n        else:\n            self._query_params[key] = str(value)\n\n    def __delitem__(self, key: str) -> None:\n        self._ensure_single_query_api_used()\n        try:\n            if key in EMBED_QUERY_PARAMS_KEYS:\n                raise KeyError(missing_key_error_message(key))\n            del self._query_params[key]\n            self._send_query_param_msg()\n        except KeyError:\n            raise KeyError(missing_key_error_message(key))\n\n    def update(\n        self,\n        other: Iterable[tuple[str, str | Iterable[str]]]\n        | SupportsKeysAndGetItem[str, str | Iterable[str]] = (),\n        /,\n        **kwds: str,\n    ):\n        # This overrides the `update` provided by MutableMapping\n        # to ensure only one one ForwardMsg is sent.\n        self._ensure_single_query_api_used()\n        if hasattr(other, \"keys\") and hasattr(other, \"__getitem__\"):\n            for key in other.keys():\n                self.__set_item_internal(key, other[key])\n        else:\n            for key, value in other:\n                self.__set_item_internal(key, value)\n        for key, value in kwds.items():\n            self.__set_item_internal(key, value)\n        self._send_query_param_msg()\n\n    def get_all(self, key: str) -> list[str]:\n        self._ensure_single_query_api_used()\n        if key not in self._query_params or key in EMBED_QUERY_PARAMS_KEYS:\n            return []\n        value = self._query_params[key]\n        return value if isinstance(value, list) else [value]\n\n    def __len__(self) -> int:\n        self._ensure_single_query_api_used()\n        return len(\n            {key for key in self._query_params if key not in EMBED_QUERY_PARAMS_KEYS}\n        )\n\n    def __str__(self) -> str:\n        self._ensure_single_query_api_used()\n        return str(self._query_params)\n\n    def _send_query_param_msg(self) -> None:\n        # Avoid circular imports\n        from streamlit.runtime.scriptrunner import get_script_run_ctx\n\n        ctx = get_script_run_ctx()\n        if ctx is None:\n            return\n        self._ensure_single_query_api_used()\n\n        msg = ForwardMsg()\n        msg.page_info_changed.query_string = parse.urlencode(\n            self._query_params, doseq=True\n        )\n        ctx.query_string = msg.page_info_changed.query_string\n        ctx.enqueue(msg)\n\n    def clear(self) -> None:\n        self._ensure_single_query_api_used()\n        self.clear_with_no_forward_msg(preserve_embed=True)\n        self._send_query_param_msg()\n\n    def to_dict(self) -> dict[str, str]:\n        self._ensure_single_query_api_used()\n        # return the last query param if multiple values are set\n        return {\n            key: self[key]\n            for key in self._query_params\n            if key not in EMBED_QUERY_PARAMS_KEYS\n        }\n\n    def from_dict(\n        self,\n        _dict: Iterable[tuple[str, str | Iterable[str]]]\n        | SupportsKeysAndGetItem[str, str | Iterable[str]],\n    ):\n        self._ensure_single_query_api_used()\n        old_value = self._query_params.copy()\n        self.clear_with_no_forward_msg(preserve_embed=True)\n        try:\n            self.update(_dict)\n        except StreamlitAPIException:\n            # restore the original from before we made any changes.\n            self._query_params = old_value\n            raise\n\n    def set_with_no_forward_msg(self, key: str, val: list[str] | str) -> None:\n        self._query_params[key] = val\n\n    def clear_with_no_forward_msg(self, preserve_embed: bool = False) -> None:\n        self._query_params = {\n            key: value\n            for key, value in self._query_params.items()\n            if key in EMBED_QUERY_PARAMS_KEYS and preserve_embed\n        }\n\n    def _ensure_single_query_api_used(self):\n        # Avoid circular imports\n        from streamlit.runtime.scriptrunner import get_script_run_ctx\n\n        ctx = get_script_run_ctx()\n        if ctx is None:\n            return\n        ctx.mark_production_query_params_used()\n\n\ndef missing_key_error_message(key: str) -> str:\n    return f'st.query_params has no key \"{key}\". Did you forget to initialize it?'\n", "lib/streamlit/runtime/state/widgets.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport textwrap\nfrom types import MappingProxyType\nfrom typing import TYPE_CHECKING, Final, Mapping\n\nfrom typing_extensions import TypeAlias\n\nfrom streamlit.errors import DuplicateWidgetID\nfrom streamlit.proto.WidgetStates_pb2 import WidgetState, WidgetStates\nfrom streamlit.runtime.state.common import (\n    RegisterWidgetResult,\n    T,\n    WidgetArgs,\n    WidgetCallback,\n    WidgetDeserializer,\n    WidgetKwargs,\n    WidgetMetadata,\n    WidgetProto,\n    WidgetSerializer,\n    user_key_from_widget_id,\n)\n\nif TYPE_CHECKING:\n    from streamlit.runtime.scriptrunner import ScriptRunContext\n    from streamlit.type_util import ValueFieldName\n\n\nElementType: TypeAlias = str\n\n# NOTE: We use this table to start with a best-effort guess for the value_type\n# of each widget. Once we actually receive a proto for a widget from the\n# frontend, the guess is updated to be the correct type. Unfortunately, we're\n# not able to always rely on the proto as the type may be needed earlier.\n# Thankfully, in these cases (when value_type == \"trigger_value\"), the static\n# table here being slightly inaccurate should never pose a problem.\nELEMENT_TYPE_TO_VALUE_TYPE: Final[Mapping[ElementType, ValueFieldName]] = (\n    MappingProxyType(\n        {\n            \"button\": \"trigger_value\",\n            \"camera_input\": \"file_uploader_state_value\",\n            \"checkbox\": \"bool_value\",\n            \"chat_input\": \"string_trigger_value\",\n            \"color_picker\": \"string_value\",\n            \"component_instance\": \"json_value\",\n            \"data_editor\": \"string_value\",\n            \"dataframe\": \"string_value\",\n            \"date_input\": \"string_array_value\",\n            \"download_button\": \"trigger_value\",\n            \"file_uploader\": \"file_uploader_state_value\",\n            \"multiselect\": \"int_array_value\",\n            \"number_input\": \"double_value\",\n            \"plotly_chart\": \"string_value\",\n            \"radio\": \"int_value\",\n            \"selectbox\": \"int_value\",\n            \"slider\": \"double_array_value\",\n            \"text_area\": \"string_value\",\n            \"text_input\": \"string_value\",\n            \"time_input\": \"string_value\",\n            \"vega_lite_chart\": \"string_value\",\n        }\n    )\n)\n\n\nclass NoValue:\n    \"\"\"Return this from DeltaGenerator.foo_widget() when you want the st.foo_widget()\n    call to return None. This is needed because `DeltaGenerator._enqueue`\n    replaces `None` with a `DeltaGenerator` (for use in non-widget elements).\n    \"\"\"\n\n    pass\n\n\ndef register_widget(\n    element_type: ElementType,\n    element_proto: WidgetProto,\n    deserializer: WidgetDeserializer[T],\n    serializer: WidgetSerializer[T],\n    ctx: ScriptRunContext | None,\n    user_key: str | None = None,\n    widget_func_name: str | None = None,\n    on_change_handler: WidgetCallback | None = None,\n    args: WidgetArgs | None = None,\n    kwargs: WidgetKwargs | None = None,\n) -> RegisterWidgetResult[T]:\n    \"\"\"Register a widget with Streamlit, and return its current value.\n    NOTE: This function should be called after the proto has been filled.\n\n    Parameters\n    ----------\n    element_type : ElementType\n        The type of the element as stored in proto.\n    element_proto : WidgetProto\n        The proto of the specified type (e.g. Button/Multiselect/Slider proto)\n    deserializer : WidgetDeserializer[T]\n        Called to convert a widget's protobuf value to the value returned by\n        its st.<widget_name> function.\n    serializer : WidgetSerializer[T]\n        Called to convert a widget's value to its protobuf representation.\n    ctx : ScriptRunContext or None\n        Used to ensure uniqueness of widget IDs, and to look up widget values.\n    user_key : str or None\n        Optional user-specified string to use as the widget ID.\n        If this is None, we'll generate an ID by hashing the element.\n    widget_func_name : str or None\n        The widget's DeltaGenerator function name, if it's different from\n        its element_type. Custom components are a special case: they all have\n        the element_type \"component_instance\", but are instantiated with\n        dynamically-named functions.\n    on_change_handler : WidgetCallback or None\n        An optional callback invoked when the widget's value changes.\n    args : WidgetArgs or None\n        args to pass to on_change_handler when invoked\n    kwargs : WidgetKwargs or None\n        kwargs to pass to on_change_handler when invoked\n\n    Returns\n    -------\n    register_widget_result : RegisterWidgetResult[T]\n        Provides information on which value to return to the widget caller,\n        and whether the UI needs updating.\n\n        - Unhappy path:\n            - Our ScriptRunContext doesn't exist (meaning that we're running\n            as a \"bare script\" outside streamlit).\n            - We are disconnected from the SessionState instance.\n            In both cases we'll return a fallback RegisterWidgetResult[T].\n        - Happy path:\n            - The widget has already been registered on a previous run but the\n            user hasn't interacted with it on the client. The widget will have\n            the default value it was first created with. We then return a\n            RegisterWidgetResult[T], containing this value.\n            - The widget has already been registered and the user *has*\n            interacted with it. The widget will have that most recent\n            user-specified value. We then return a RegisterWidgetResult[T],\n            containing this value.\n\n        For both paths a widget return value is provided, allowing the widgets\n        to be used in a non-streamlit setting.\n    \"\"\"\n    # Create the widget's updated metadata, and register it with session_state.\n    metadata = WidgetMetadata(\n        element_proto.id,\n        deserializer,\n        serializer,\n        value_type=ELEMENT_TYPE_TO_VALUE_TYPE[element_type],\n        callback=on_change_handler,\n        callback_args=args,\n        callback_kwargs=kwargs,\n        fragment_id=ctx.current_fragment_id if ctx else None,\n    )\n    return register_widget_from_metadata(metadata, ctx, widget_func_name, element_type)\n\n\ndef register_widget_from_metadata(\n    metadata: WidgetMetadata[T],\n    ctx: ScriptRunContext | None,\n    widget_func_name: str | None,\n    element_type: ElementType,\n) -> RegisterWidgetResult[T]:\n    \"\"\"Register a widget and return its value, using an already constructed\n    `WidgetMetadata`.\n\n    This is split out from `register_widget` to allow caching code to replay\n    widgets by saving and reusing the completed metadata.\n\n    See `register_widget` for details on what this returns.\n    \"\"\"\n    # Local import to avoid import cycle\n    import streamlit.runtime.caching as caching\n\n    if ctx is None:\n        # Early-out if we don't have a script run context (which probably means\n        # we're running as a \"bare\" Python script, and not via `streamlit run`).\n        return RegisterWidgetResult.failure(deserializer=metadata.deserializer)\n\n    widget_id = metadata.id\n    user_key = user_key_from_widget_id(widget_id)\n\n    # Ensure another widget with the same user key hasn't already been registered.\n    if user_key is not None:\n        if user_key not in ctx.widget_user_keys_this_run:\n            ctx.widget_user_keys_this_run.add(user_key)\n        else:\n            raise DuplicateWidgetID(\n                _build_duplicate_widget_message(\n                    widget_func_name if widget_func_name is not None else element_type,\n                    user_key,\n                )\n            )\n\n    # Ensure another widget with the same id hasn't already been registered.\n    new_widget = widget_id not in ctx.widget_ids_this_run\n    if new_widget:\n        ctx.widget_ids_this_run.add(widget_id)\n    else:\n        raise DuplicateWidgetID(\n            _build_duplicate_widget_message(\n                widget_func_name if widget_func_name is not None else element_type,\n                user_key,\n            )\n        )\n    # Save the widget metadata for cached result replay\n    caching.save_widget_metadata(metadata)\n    return ctx.session_state.register_widget(metadata, user_key)\n\n\ndef coalesce_widget_states(\n    old_states: WidgetStates | None, new_states: WidgetStates | None\n) -> WidgetStates | None:\n    \"\"\"Coalesce an older WidgetStates into a newer one, and return a new\n    WidgetStates containing the result.\n\n    For most widget values, we just take the latest version.\n\n    However, any trigger_values (which are set by buttons) that are True in\n    `old_states` will be set to True in the coalesced result, so that button\n    presses don't go missing.\n    \"\"\"\n    if not old_states and not new_states:\n        return None\n    elif not old_states:\n        return new_states\n    elif not new_states:\n        return old_states\n\n    states_by_id: dict[str, WidgetState] = {\n        wstate.id: wstate for wstate in new_states.widgets\n    }\n\n    trigger_value_types = [(\"trigger_value\", False), (\"string_trigger_value\", None)]\n    for old_state in old_states.widgets:\n        for trigger_value_type, unset_value in trigger_value_types:\n            if (\n                old_state.WhichOneof(\"value\") == trigger_value_type\n                and old_state.trigger_value != unset_value\n            ):\n                # Ensure the corresponding new_state is also a trigger;\n                # otherwise, a widget that was previously a button but no longer is\n                # could get a bad value.\n                new_trigger_val = states_by_id.get(old_state.id)\n                if (\n                    new_trigger_val\n                    and new_trigger_val.WhichOneof(\"value\") == trigger_value_type\n                ):\n                    states_by_id[old_state.id] = old_state\n\n    coalesced = WidgetStates()\n    coalesced.widgets.extend(states_by_id.values())\n\n    return coalesced\n\n\ndef _build_duplicate_widget_message(\n    widget_func_name: str, user_key: str | None = None\n) -> str:\n    if user_key is not None:\n        message = textwrap.dedent(\n            \"\"\"\n            There are multiple widgets with the same `key='{user_key}'`.\n\n            To fix this, please make sure that the `key` argument is unique for each\n            widget you create.\n            \"\"\"\n        )\n    else:\n        message = textwrap.dedent(\n            \"\"\"\n            There are multiple identical `st.{widget_type}` widgets with the\n            same generated key.\n\n            When a widget is created, it's assigned an internal key based on\n            its structure. Multiple widgets with an identical structure will\n            result in the same internal key, which causes this error.\n\n            To fix this error, please pass a unique `key` argument to\n            `st.{widget_type}`.\n            \"\"\"\n        )\n\n    return message.strip(\"\\n\").format(widget_type=widget_func_name, user_key=user_key)\n", "lib/streamlit/connections/base_connection.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport json\nfrom abc import ABC, abstractmethod\nfrom typing import Any, Generic, TypeVar\n\nfrom streamlit.runtime.secrets import AttrDict, secrets_singleton\nfrom streamlit.util import calc_md5\n\nRawConnectionT = TypeVar(\"RawConnectionT\")\n\n\nclass BaseConnection(ABC, Generic[RawConnectionT]):\n    \"\"\"The abstract base class that all Streamlit Connections must inherit from.\n\n    This base class provides connection authors with a standardized way to hook into the\n    ``st.connection()`` factory function: connection authors are required to provide an\n    implementation for the abstract method ``_connect`` in their subclasses.\n\n    Additionally, it also provides a few methods/properties designed to make\n    implementation of connections more convenient. See the docstrings for each of the\n    methods of this class for more information\n\n    .. note::\n        While providing an implementation of ``_connect`` is technically all that's\n        required to define a valid connection, connections should also provide the user\n        with context-specific ways of interacting with the underlying connection object.\n        For example, the first-party SQLConnection provides a ``query()`` method for\n        reads and a ``session`` property for more complex operations.\n    \"\"\"\n\n    def __init__(self, connection_name: str, **kwargs) -> None:\n        \"\"\"Create a BaseConnection.\n\n        This constructor is called by the connection factory machinery when a user\n        script calls ``st.connection()``.\n\n        Subclasses of BaseConnection that want to overwrite this method should take care\n        to also call the base class' implementation.\n\n        Parameters\n        ----------\n        connection_name : str\n            The name of this connection. This corresponds to the\n            ``[connections.<connection_name>]`` config section in ``st.secrets``.\n        kwargs : dict\n            Any other kwargs to pass to this connection class' ``_connect`` method.\n\n        Returns\n        -------\n        None\n        \"\"\"\n        self._connection_name = connection_name\n        self._kwargs = kwargs\n\n        self._config_section_hash = calc_md5(json.dumps(self._secrets.to_dict()))\n        secrets_singleton.file_change_listener.connect(self._on_secrets_changed)\n\n        self._raw_instance: RawConnectionT | None = self._connect(**kwargs)\n\n    def __del__(self) -> None:\n        secrets_singleton.file_change_listener.disconnect(self._on_secrets_changed)\n\n    def __getattribute__(self, name: str) -> Any:\n        try:\n            return object.__getattribute__(self, name)\n        except AttributeError as e:\n            if hasattr(self._instance, name):\n                raise AttributeError(\n                    f\"`{name}` doesn't exist here, but you can call `._instance.{name}` instead\"\n                )\n            raise e\n\n    def _repr_html_(self) -> str:\n        \"\"\"Return a human-friendly markdown string describing this connection.\n\n        This is the string that will be written to the app if a user calls\n        ``st.write(this_connection)``. Subclasses of BaseConnection can freely overwrite\n        this method if desired.\n\n        Returns\n        -------\n        str\n        \"\"\"\n        module_name = getattr(self, \"__module__\", None)\n        class_name = type(self).__name__\n\n        cfg = (\n            f\"- Configured from `[connections.{self._connection_name}]`\"\n            if len(self._secrets)\n            else \"\"\n        )\n\n        return f\"\"\"\n---\n**st.connection {self._connection_name} built from `{module_name}.{class_name}`**\n{cfg}\n- Learn more using `st.help()`\n---\n\"\"\"\n\n    # Methods with default implementations that we don't expect subclasses to want or\n    # need to overwrite.\n    def _on_secrets_changed(self, _) -> None:\n        \"\"\"Reset the raw connection object when this connection's secrets change.\n\n        We don't expect either user scripts or connection authors to have to use or\n        overwrite this method.\n        \"\"\"\n        new_hash = calc_md5(json.dumps(self._secrets.to_dict()))\n\n        # Only reset the connection if the secrets file section specific to this\n        # connection has changed.\n        if new_hash != self._config_section_hash:\n            self._config_section_hash = new_hash\n            self.reset()\n\n    @property\n    def _secrets(self) -> AttrDict:\n        \"\"\"Get the secrets for this connection from the corresponding st.secrets section.\n\n        We expect this property to be used primarily by connection authors when they\n        are implementing their class' ``_connect`` method. User scripts should, for the\n        most part, have no reason to use this property.\n        \"\"\"\n        connections_section = None\n        if secrets_singleton.load_if_toml_exists():\n            connections_section = secrets_singleton.get(\"connections\")\n\n        if type(connections_section) is not AttrDict:\n            return AttrDict({})\n\n        return connections_section.get(self._connection_name, AttrDict({}))\n\n    def reset(self) -> None:\n        \"\"\"Reset this connection so that it gets reinitialized the next time it's used.\n\n        This method can be useful when a connection has become stale, an auth token has\n        expired, or in similar scenarios where a broken connection might be fixed by\n        reinitializing it. Note that some connection methods may already use ``reset()``\n        in their error handling code.\n\n        Example\n        -------\n        >>> import streamlit as st\n        >>>\n        >>> conn = st.connection(\"my_conn\")\n        >>>\n        >>> # Reset the connection before using it if it isn't healthy\n        >>> # Note: is_healthy() isn't a real method and is just shown for example here.\n        >>> if not conn.is_healthy():\n        ...     conn.reset()\n        ...\n        >>> # Do stuff with conn...\n        \"\"\"\n        self._raw_instance = None\n\n    @property\n    def _instance(self) -> RawConnectionT:\n        \"\"\"Get an instance of the underlying connection, creating a new one if needed.\"\"\"\n        if self._raw_instance is None:\n            self._raw_instance = self._connect(**self._kwargs)\n\n        return self._raw_instance\n\n    # Abstract fields/methods that subclasses of BaseConnection must implement\n    @abstractmethod\n    def _connect(self, **kwargs) -> RawConnectionT:\n        \"\"\"Create an instance of an underlying connection object.\n\n        This abstract method is the one method that we require subclasses of\n        BaseConnection to provide an implementation for. It is called when first\n        creating a connection and when reconnecting after a connection is reset.\n\n        Parameters\n        ----------\n        kwargs : dict\n\n        Returns\n        -------\n        RawConnectionT\n            The underlying connection object.\n        \"\"\"\n        raise NotImplementedError\n", "lib/streamlit/connections/snowflake_connection.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# NOTE: We won't always be able to import from snowflake.{connector, snowpark}.* so need\n# the `type: ignore` comment below, but that comment will explode if `warn-unused-ignores`\n# is turned on when the package is available. Unfortunately, mypy doesn't provide a good\n# way to configure this at a per-line level :(\n# mypy: no-warn-unused-ignores\n\nfrom __future__ import annotations\n\nfrom typing import TYPE_CHECKING, cast\n\nfrom streamlit.connections import BaseConnection\nfrom streamlit.connections.util import running_in_sis\nfrom streamlit.errors import StreamlitAPIException\nfrom streamlit.runtime.caching import cache_data\n\nif TYPE_CHECKING:\n    from datetime import timedelta\n\n    from pandas import DataFrame\n    from snowflake.connector.cursor import SnowflakeCursor  # type:ignore[import]\n    from snowflake.snowpark.session import Session  # type:ignore[import]\n\n    from snowflake.connector import (  # type:ignore[import] # isort: skip\n        SnowflakeConnection as InternalSnowflakeConnection,\n    )\n\n\nclass SnowflakeConnection(BaseConnection[\"InternalSnowflakeConnection\"]):\n    \"\"\"A connection to Snowflake using the Snowflake Python Connector. Initialize using\n    ``st.connection(\"<name>\", type=\"snowflake\")``.\n\n    SnowflakeConnection supports direct SQL querying using ``.query(\"...\")``, access to\n    the underlying Snowflake Python Connector object with ``.raw_connection``, and other\n    convenience functions. See the methods below for more information.\n    SnowflakeConnections should always be created using ``st.connection()``, **not**\n    initialized directly.\n    \"\"\"\n\n    def _connect(self, **kwargs) -> InternalSnowflakeConnection:\n        import snowflake.connector  # type:ignore[import]\n        from snowflake.connector import Error as SnowflakeError  # type:ignore[import]\n\n        # If we're running in SiS, just call get_active_session() and retrieve the\n        # lower-level connection from it.\n        if running_in_sis():\n            from snowflake.snowpark.context import (  # type:ignore[import]  # isort: skip\n                get_active_session,\n            )\n\n            session = get_active_session()\n\n            if hasattr(session, \"connection\"):\n                return session.connection\n            # session.connection is only a valid attr in more recent versions of\n            # snowflake-connector-python, so we fall back to grabbing\n            # session._conn._conn if `.connection` is unavailable.\n            return session._conn._conn\n\n        # We require qmark-style parameters everywhere for consistency across different\n        # environments where SnowflakeConnections may be used.\n        snowflake.connector.paramstyle = \"qmark\"\n\n        # Otherwise, attempt to create a new connection from whatever credentials we\n        # have available.\n        try:\n            st_secrets = self._secrets.to_dict()\n            if len(st_secrets):\n                conn_kwargs = {**st_secrets, **kwargs}\n                return snowflake.connector.connect(**conn_kwargs)\n\n            # session.connector.connection.CONFIG_MANAGER is only available in more recent\n            # versions of snowflake-connector-python.\n            if hasattr(snowflake.connector.connection, \"CONFIG_MANAGER\"):\n                config_mgr = snowflake.connector.connection.CONFIG_MANAGER\n\n                default_connection_name = \"default\"\n                try:\n                    default_connection_name = config_mgr[\"default_connection_name\"]\n                except snowflake.connector.errors.ConfigSourceError:\n                    # Similarly, config_mgr[\"default_connection_name\"] only exists in even\n                    # later versions of recent versions. if it doesn't, we just use\n                    # \"default\" as the default connection name.\n                    pass\n\n                connection_name = (\n                    default_connection_name\n                    if self._connection_name == \"snowflake\"\n                    else self._connection_name\n                )\n                return snowflake.connector.connect(\n                    connection_name=connection_name,\n                    **kwargs,\n                )\n\n            return snowflake.connector.connect(**kwargs)\n        except SnowflakeError as e:\n            if not len(st_secrets) and not len(kwargs):\n                raise StreamlitAPIException(\n                    \"Missing Snowflake connection configuration. \"\n                    \"Did you forget to set this in `secrets.toml`, a Snowflake configuration file, \"\n                    \"or as kwargs to `st.connection`? \"\n                    \"See the [SnowflakeConnection configuration documentation](https://docs.streamlit.io/st.connections.snowflakeconnection-configuration) \"\n                    \"for more details and examples.\"\n                )\n            raise e\n\n    def query(\n        self,\n        sql: str,\n        *,  # keyword-only arguments:\n        ttl: float | int | timedelta | None = None,\n        show_spinner: bool | str = \"Running `snowflake.query(...)`.\",\n        params=None,\n        **kwargs,\n    ) -> DataFrame:\n        \"\"\"Run a read-only SQL query.\n\n        This method implements both query result caching (with caching behavior\n        identical to that of using ``@st.cache_data``) as well as simple error handling/retries.\n\n        .. note::\n            Queries that are run without a specified ttl are cached indefinitely.\n\n        Parameters\n        ----------\n        sql : str\n            The read-only SQL query to execute.\n        ttl : float, int, timedelta or None\n            The maximum number of seconds to keep results in the cache, or\n            None if cached results should not expire. The default is None.\n        show_spinner : boolean or string\n            Enable the spinner. The default is to show a spinner when there is a\n            \"cache miss\" and the cached resource is being created. If a string, the value\n            of the show_spinner param will be used for the spinner text.\n        params : list, tuple, dict or None\n            List of parameters to pass to the execute method. This connector supports\n            binding data to a SQL statement using qmark bindings. For more information\n            and examples, see the `Snowflake Python Connector documentation\n            <https://docs.snowflake.com/en/developer-guide/python-connector/python-connector-example#using-qmark-or-numeric-binding>`_.\n            Default is None.\n\n        Returns\n        -------\n        pandas.DataFrame\n            The result of running the query, formatted as a pandas DataFrame.\n\n        Example\n        -------\n        >>> import streamlit as st\n        >>>\n        >>> conn = st.connection(\"snowflake\")\n        >>> df = conn.query(\"select * from pet_owners\")\n        >>> st.dataframe(df)\n        \"\"\"\n        from snowflake.connector.errors import ProgrammingError  # type: ignore[import]\n        from snowflake.connector.network import (  # type: ignore[import]\n            BAD_REQUEST_GS_CODE,\n            ID_TOKEN_EXPIRED_GS_CODE,\n            MASTER_TOKEN_EXPIRED_GS_CODE,\n            MASTER_TOKEN_INVALD_GS_CODE,\n            MASTER_TOKEN_NOTFOUND_GS_CODE,\n            SESSION_EXPIRED_GS_CODE,\n        )\n        from tenacity import retry, retry_if_exception, stop_after_attempt, wait_fixed\n\n        retryable_error_codes = {\n            int(code)\n            for code in (\n                ID_TOKEN_EXPIRED_GS_CODE,\n                SESSION_EXPIRED_GS_CODE,\n                MASTER_TOKEN_NOTFOUND_GS_CODE,\n                MASTER_TOKEN_EXPIRED_GS_CODE,\n                MASTER_TOKEN_INVALD_GS_CODE,\n                BAD_REQUEST_GS_CODE,\n            )\n        }\n\n        @retry(\n            after=lambda _: self.reset(),\n            stop=stop_after_attempt(3),\n            reraise=True,\n            # We don't have to implement retries ourself for most error types as the\n            # `snowflake-connector-python` library already implements retries for\n            # retryable HTTP errors.\n            retry=retry_if_exception(\n                lambda e: isinstance(e, ProgrammingError)\n                and hasattr(e, \"errno\")\n                and e.errno in retryable_error_codes\n            ),\n            wait=wait_fixed(1),\n        )\n        def _query(sql: str) -> DataFrame:\n            cur = self._instance.cursor()\n            cur.execute(sql, params=params, **kwargs)\n            return cur.fetch_pandas_all()\n\n        # We modify our helper function's `__qualname__` here to work around default\n        # `@st.cache_data` behavior. Otherwise, `.query()` being called with different\n        # `ttl` values will reset the cache with each call, and the query caches won't\n        # be scoped by connection.\n        ttl_str = str(  # Avoid adding extra `.` characters to `__qualname__`\n            ttl\n        ).replace(\".\", \"_\")\n        _query.__qualname__ = f\"{_query.__qualname__}_{self._connection_name}_{ttl_str}\"\n        _query = cache_data(\n            show_spinner=show_spinner,\n            ttl=ttl,\n        )(_query)\n\n        return _query(sql)\n\n    def write_pandas(\n        self,\n        df: DataFrame,\n        table_name: str,\n        database: str | None = None,\n        schema: str | None = None,\n        chunk_size: int | None = None,\n        **kwargs,\n    ) -> tuple[bool, int, int]:\n        \"\"\"Call snowflake.connector.pandas_tools.write_pandas with this connection.\n\n        This convenience method is simply a thin wrapper around the ``write_pandas``\n        function of the same name from ``snowflake.connector.pandas_tools``. For more\n        information, see the `Snowflake Python Connector documentation\n        <https://docs.snowflake.com/en/developer-guide/python-connector/python-connector-api#write_pandas>`_.\n\n        Returns\n        -------\n        tuple[bool, int, int]\n            A tuple containing three values:\n                1. A bool that is True if the write was successful.\n                2. An int giving the number of chunks of data that were copied.\n                3. An int giving the number of rows that were inserted.\n        \"\"\"\n        from snowflake.connector.pandas_tools import write_pandas  # type:ignore[import]\n\n        success, nchunks, nrows, _ = write_pandas(\n            conn=self._instance,\n            df=df,\n            table_name=table_name,\n            database=database,\n            schema=schema,\n            chunk_size=chunk_size,\n            **kwargs,\n        )\n\n        return (success, nchunks, nrows)\n\n    def cursor(self) -> SnowflakeCursor:\n        \"\"\"Return a PEP 249-compliant cursor object.\n\n        For more information, see the `Snowflake Python Connector documentation\n        <https://docs.snowflake.com/en/developer-guide/python-connector/python-connector-api#object-cursor>`_.\n        \"\"\"\n        return self._instance.cursor()\n\n    @property\n    def raw_connection(self) -> InternalSnowflakeConnection:\n        \"\"\"Access the underlying Snowflake Python connector object.\n\n        Information on how to use the Snowflake Python Connector can be found in the\n        `Snowflake Python Connector documentation <https://docs.snowflake.com/en/developer-guide/python-connector/python-connector-example>`_.\n        \"\"\"\n        return self._instance\n\n    def session(self) -> Session:\n        \"\"\"Create a new Snowpark Session from this connection.\n\n        Information on how to use Snowpark sessions can be found in the `Snowpark documentation\n        <https://docs.snowflake.com/en/developer-guide/snowpark/python/working-with-dataframes>`_.\n        \"\"\"\n        from snowflake.snowpark.context import get_active_session  # type:ignore[import]\n        from snowflake.snowpark.session import Session  # type:ignore[import]\n\n        if running_in_sis():\n            return get_active_session()\n\n        return cast(\n            Session, Session.builder.configs({\"connection\": self._instance}).create()\n        )\n", "lib/streamlit/connections/util.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# NOTE: We won't always be able to import from snowflake.connector.connection so need the\n# `type: ignore` comment below, but that comment will explode if `warn-unused-ignores` is\n# turned on when the package is available. Unfortunately, mypy doesn't provide a good\n# way to configure this at a per-line level :(\n# mypy: no-warn-unused-ignores\n\nfrom __future__ import annotations\n\nimport os\nfrom typing import Any, Collection, cast\n\nSNOWSQL_CONNECTION_FILE = \"~/.snowsql/config\"\n\n\ndef extract_from_dict(\n    keys: Collection[str], source_dict: dict[str, Any]\n) -> dict[str, Any]:\n    \"\"\"Extract the specified keys from source_dict and return them in a new dict.\n\n    Parameters\n    ----------\n    keys : Collection[str]\n        The keys to extract from source_dict.\n    source_dict : Dict[str, Any]\n        The dict to extract keys from. Note that this function mutates source_dict.\n\n    Returns\n    -------\n    Dict[str, Any]\n        A new dict containing the keys/values extracted from source_dict.\n    \"\"\"\n    d = {}\n\n    for k in keys:\n        if k in source_dict:\n            d[k] = source_dict.pop(k)\n\n    return d\n\n\ndef load_from_snowsql_config_file(connection_name: str) -> dict[str, Any]:\n    \"\"\"Loads the dictionary from snowsql config file.\"\"\"\n    snowsql_config_file = os.path.expanduser(SNOWSQL_CONNECTION_FILE)\n    if not os.path.exists(snowsql_config_file):\n        return {}\n\n    # Lazy-load config parser for better import / startup performance\n    import configparser\n\n    config = configparser.ConfigParser(inline_comment_prefixes=\"#\")\n    config.read(snowsql_config_file)\n\n    if f\"connections.{connection_name}\" in config:\n        raw_conn_params = config[f\"connections.{connection_name}\"]\n    elif \"connections\" in config:\n        raw_conn_params = config[\"connections\"]\n    else:\n        return {}\n\n    conn_params = {\n        k.replace(\"name\", \"\"): v.strip('\"') for k, v in raw_conn_params.items()\n    }\n\n    if \"db\" in conn_params:\n        conn_params[\"database\"] = conn_params[\"db\"]\n        del conn_params[\"db\"]\n\n    return conn_params\n\n\ndef running_in_sis() -> bool:\n    \"\"\"Return whether this app is running in SiS.\"\"\"\n    try:\n        from snowflake.snowpark._internal.utils import (  # type: ignore[import]  # isort: skip\n            is_in_stored_procedure,\n        )\n\n        return cast(bool, is_in_stored_procedure())\n    except ModuleNotFoundError:\n        return False\n", "lib/streamlit/connections/snowpark_connection.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# NOTE: We won't always be able to import from snowflake.snowpark.session so need the\n# `type: ignore` comment below, but that comment will explode if `warn-unused-ignores` is\n# turned on when the package is available. Unfortunately, mypy doesn't provide a good\n# way to configure this at a per-line level :(\n# mypy: no-warn-unused-ignores\n\nfrom __future__ import annotations\n\nimport threading\nfrom collections import ChainMap\nfrom contextlib import contextmanager\nfrom typing import TYPE_CHECKING, Iterator, cast\n\nfrom streamlit.connections import BaseConnection\nfrom streamlit.connections.util import (\n    SNOWSQL_CONNECTION_FILE,\n    load_from_snowsql_config_file,\n    running_in_sis,\n)\nfrom streamlit.errors import StreamlitAPIException\nfrom streamlit.runtime.caching import cache_data\n\nif TYPE_CHECKING:\n    from datetime import timedelta\n\n    from pandas import DataFrame\n    from snowflake.snowpark.session import Session  # type:ignore[import]\n\n\n_REQUIRED_CONNECTION_PARAMS = {\"account\"}\n\n\nclass SnowparkConnection(BaseConnection[\"Session\"]):\n    \"\"\"A connection to Snowpark using snowflake.snowpark.session.Session. Initialize using\n    ``st.connection(\"<name>\", type=\"snowpark\")``.\n\n    In addition to providing access to the Snowpark Session, SnowparkConnection supports\n    direct SQL querying using ``query(\"...\")`` and thread safe access using\n    ``with conn.safe_session():``. See methods below for more information.\n    SnowparkConnections should always be created using ``st.connection()``, **not**\n    initialized directly.\n\n    .. note::\n        We don't expect this iteration of SnowparkConnection to be able to scale\n        well in apps with many concurrent users due to the lock contention that will occur\n        over the single underlying Session object under high load.\n    \"\"\"\n\n    def __init__(self, connection_name: str, **kwargs) -> None:\n        self._lock = threading.RLock()\n        super().__init__(connection_name, **kwargs)\n\n    def _connect(self, **kwargs) -> Session:\n        from snowflake.snowpark.context import get_active_session  # type:ignore[import]\n        from snowflake.snowpark.session import Session\n\n        # If we're running in SiS, just call get_active_session(). Otherwise, attempt to\n        # create a new session from whatever credentials we have available.\n        if running_in_sis():\n            return get_active_session()\n\n        conn_params = ChainMap(\n            kwargs,\n            self._secrets.to_dict(),\n            load_from_snowsql_config_file(self._connection_name),\n        )\n\n        if not len(conn_params):\n            raise StreamlitAPIException(\n                \"Missing Snowpark connection configuration. \"\n                f\"Did you forget to set this in `secrets.toml`, `{SNOWSQL_CONNECTION_FILE}`, \"\n                \"or as kwargs to `st.connection`?\"\n            )\n\n        for p in _REQUIRED_CONNECTION_PARAMS:\n            if p not in conn_params:\n                raise StreamlitAPIException(f\"Missing Snowpark connection param: {p}\")\n\n        return cast(Session, Session.builder.configs(conn_params).create())\n\n    def query(\n        self,\n        sql: str,\n        ttl: float | int | timedelta | None = None,\n    ) -> DataFrame:\n        \"\"\"Run a read-only SQL query.\n\n        This method implements both query result caching (with caching behavior\n        identical to that of using ``@st.cache_data``) as well as simple error handling/retries.\n\n        .. note::\n            Queries that are run without a specified ttl are cached indefinitely.\n\n        Parameters\n        ----------\n        sql : str\n            The read-only SQL query to execute.\n        ttl : float, int, timedelta or None\n            The maximum number of seconds to keep results in the cache, or\n            None if cached results should not expire. The default is None.\n\n        Returns\n        -------\n        pandas.DataFrame\n            The result of running the query, formatted as a pandas DataFrame.\n\n        Example\n        -------\n        >>> import streamlit as st\n        >>>\n        >>> conn = st.connection(\"snowpark\")\n        >>> df = conn.query(\"select * from pet_owners\")\n        >>> st.dataframe(df)\n        \"\"\"\n        from snowflake.snowpark.exceptions import (  # type:ignore[import]\n            SnowparkServerException,\n        )\n        from tenacity import (\n            retry,\n            retry_if_exception_type,\n            stop_after_attempt,\n            wait_fixed,\n        )\n\n        @retry(\n            after=lambda _: self.reset(),\n            stop=stop_after_attempt(3),\n            reraise=True,\n            retry=retry_if_exception_type(SnowparkServerException),\n            wait=wait_fixed(1),\n        )\n        def _query(sql: str) -> DataFrame:\n            with self._lock:\n                return self._instance.sql(sql).to_pandas()\n\n        # We modify our helper function's `__qualname__` here to work around default\n        # `@st.cache_data` behavior. Otherwise, `.query()` being called with different\n        # `ttl` values will reset the cache with each call, and the query caches won't\n        # be scoped by connection.\n        ttl_str = str(  # Avoid adding extra `.` characters to `__qualname__`\n            ttl\n        ).replace(\".\", \"_\")\n        _query.__qualname__ = f\"{_query.__qualname__}_{self._connection_name}_{ttl_str}\"\n        _query = cache_data(\n            show_spinner=\"Running `snowpark.query(...)`.\",\n            ttl=ttl,\n        )(_query)\n\n        return _query(sql)\n\n    @property\n    def session(self) -> Session:\n        \"\"\"Access the underlying Snowpark session.\n\n        .. note::\n            Snowpark sessions are **not** thread safe. Users of this method are\n            responsible for ensuring that access to the session returned by this method is\n            done in a thread-safe manner. For most users, we recommend using the thread-safe\n            safe_session() method and a ``with`` block.\n\n        Information on how to use Snowpark sessions can be found in the `Snowpark documentation\n        <https://docs.snowflake.com/en/developer-guide/snowpark/python/working-with-dataframes>`_.\n\n        Example\n        -------\n        >>> import streamlit as st\n        >>>\n        >>> session = st.connection(\"snowpark\").session\n        >>> df = session.table(\"mytable\").limit(10).to_pandas()\n        >>> st.dataframe(df)\n        \"\"\"\n        return self._instance\n\n    @contextmanager\n    def safe_session(self) -> Iterator[Session]:\n        \"\"\"Grab the underlying Snowpark session in a thread-safe manner.\n\n        As operations on a Snowpark session are not thread safe, we need to take care\n        when using a session in the context of a Streamlit app where each script run\n        occurs in its own thread. Using the contextmanager pattern to do this ensures\n        that access on this connection's underlying Session is done in a thread-safe\n        manner.\n\n        Information on how to use Snowpark sessions can be found in the `Snowpark documentation\n        <https://docs.snowflake.com/en/developer-guide/snowpark/python/working-with-dataframes>`_.\n\n        Example\n        -------\n        >>> import streamlit as st\n        >>>\n        >>> conn = st.connection(\"snowpark\")\n        >>> with conn.safe_session() as session:\n        ...     df = session.table(\"mytable\").limit(10).to_pandas()\n        ...\n        >>> st.dataframe(df)\n        \"\"\"\n        with self._lock:\n            yield self.session\n", "lib/streamlit/connections/sql_connection.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom collections import ChainMap\nfrom copy import deepcopy\nfrom typing import TYPE_CHECKING, cast\n\nfrom streamlit.connections import BaseConnection\nfrom streamlit.connections.util import extract_from_dict\nfrom streamlit.errors import StreamlitAPIException\nfrom streamlit.runtime.caching import cache_data\n\nif TYPE_CHECKING:\n    from datetime import timedelta\n\n    from pandas import DataFrame\n    from sqlalchemy.engine import Connection as SQLAlchemyConnection\n    from sqlalchemy.engine.base import Engine\n    from sqlalchemy.orm import Session\n\n\n_ALL_CONNECTION_PARAMS = {\n    \"url\",\n    \"driver\",\n    \"dialect\",\n    \"username\",\n    \"password\",\n    \"host\",\n    \"port\",\n    \"database\",\n    \"query\",\n}\n_REQUIRED_CONNECTION_PARAMS = {\"dialect\", \"username\", \"host\"}\n\n\nclass SQLConnection(BaseConnection[\"Engine\"]):\n    \"\"\"A connection to a SQL database using a SQLAlchemy Engine. Initialize using ``st.connection(\"<name>\", type=\"sql\")``.\n\n    SQLConnection provides the ``query()`` convenience method, which can be used to\n    run simple read-only queries with both caching and simple error handling/retries.\n    More complex DB interactions can be performed by using the ``.session`` property\n    to receive a regular SQLAlchemy Session.\n\n    SQLConnections should always be created using ``st.connection()``, **not**\n    initialized directly. Connection parameters for a SQLConnection can be specified\n    using either ``st.secrets`` or ``**kwargs``. Some frequently used parameters include:\n\n    - **url** or arguments for `sqlalchemy.engine.URL.create()\n      <https://docs.sqlalchemy.org/en/20/core/engines.html#sqlalchemy.engine.URL.create>`_.\n      Most commonly it includes a dialect, host, database, username and password.\n\n    - **create_engine_kwargs** can be passed via ``st.secrets``, such as for\n      `snowflake-sqlalchemy <https://github.com/snowflakedb/snowflake-sqlalchemy#key-pair-authentication-support>`_\n      or `Google BigQuery <https://github.com/googleapis/python-bigquery-sqlalchemy#authentication>`_.\n      These can also be passed directly as ``**kwargs`` to connection().\n\n    - **autocommit=True** to run with isolation level ``AUTOCOMMIT``. Default is False.\n\n    Example\n    -------\n    >>> import streamlit as st\n    >>>\n    >>> conn = st.connection(\"sql\")\n    >>> df = conn.query(\"select * from pet_owners\")\n    >>> st.dataframe(df)\n    \"\"\"\n\n    def _connect(self, autocommit: bool = False, **kwargs) -> Engine:\n        import sqlalchemy\n\n        kwargs = deepcopy(kwargs)\n        conn_param_kwargs = extract_from_dict(_ALL_CONNECTION_PARAMS, kwargs)\n        conn_params = ChainMap(conn_param_kwargs, self._secrets.to_dict())\n\n        if not len(conn_params):\n            raise StreamlitAPIException(\n                \"Missing SQL DB connection configuration. \"\n                \"Did you forget to set this in `secrets.toml` or as kwargs to `st.connection`?\"\n            )\n\n        if \"url\" in conn_params:\n            url = sqlalchemy.engine.make_url(conn_params[\"url\"])\n        else:\n            for p in _REQUIRED_CONNECTION_PARAMS:\n                if p not in conn_params:\n                    raise StreamlitAPIException(f\"Missing SQL DB connection param: {p}\")\n\n            drivername = conn_params[\"dialect\"] + (\n                f\"+{conn_params['driver']}\" if \"driver\" in conn_params else \"\"\n            )\n\n            url = sqlalchemy.engine.URL.create(\n                drivername=drivername,\n                username=conn_params[\"username\"],\n                password=conn_params.get(\"password\"),\n                host=conn_params[\"host\"],\n                port=int(conn_params[\"port\"]) if \"port\" in conn_params else None,\n                database=conn_params.get(\"database\"),\n                query=conn_params[\"query\"] if \"query\" in conn_params else None,\n            )\n\n        create_engine_kwargs = ChainMap(\n            kwargs, self._secrets.get(\"create_engine_kwargs\", {})\n        )\n        eng = sqlalchemy.create_engine(url, **create_engine_kwargs)\n\n        if autocommit:\n            return cast(\"Engine\", eng.execution_options(isolation_level=\"AUTOCOMMIT\"))\n        else:\n            return cast(\"Engine\", eng)\n\n    def query(\n        self,\n        sql: str,\n        *,  # keyword-only arguments:\n        show_spinner: bool | str = \"Running `sql.query(...)`.\",\n        ttl: float | int | timedelta | None = None,\n        index_col: str | list[str] | None = None,\n        chunksize: int | None = None,\n        params=None,\n        **kwargs,\n    ) -> DataFrame:\n        \"\"\"Run a read-only query.\n\n        This method implements both query result caching (with caching behavior\n        identical to that of using ``@st.cache_data``) as well as simple error handling/retries.\n\n        .. note::\n            Queries that are run without a specified ttl are cached indefinitely.\n\n        Aside from the ``ttl`` kwarg, all kwargs passed to this function are passed down\n        to |pandas.read_sql|_\n        and have the behavior described in the pandas documentation.\n\n        .. |pandas.read_sql| replace:: ``pandas.read_sql``\n        .. _pandas.read_sql: https://pandas.pydata.org/docs/reference/api/pandas.read_sql.html\n\n        Parameters\n        ----------\n        sql : str\n            The read-only SQL query to execute.\n        show_spinner : boolean or string\n            Enable the spinner. The default is to show a spinner when there is a\n            \"cache miss\" and the cached resource is being created. If a string, the value\n            of the show_spinner param will be used for the spinner text.\n        ttl : float, int, timedelta or None\n            The maximum number of seconds to keep results in the cache, or\n            None if cached results should not expire. The default is None.\n        index_col : str, list of str, or None\n            Column(s) to set as index(MultiIndex). Default is None.\n        chunksize : int or None\n            If specified, return an iterator where chunksize is the number of\n            rows to include in each chunk. Default is None.\n        params : list, tuple, dict or None\n            List of parameters to pass to the execute method. The syntax used to pass\n            parameters is database driver dependent. Check your database driver\n            documentation for which of the five syntax styles, described in `PEP 249\n            paramstyle <https://peps.python.org/pep-0249/#paramstyle>`_, is supported.\n            Default is None.\n        **kwargs: dict\n            Additional keyword arguments are passed to |pandas.read_sql|_.\n\n            .. |pandas.read_sql| replace:: ``pandas.read_sql``\n            .. _pandas.read_sql: https://pandas.pydata.org/docs/reference/api/pandas.read_sql.html\n\n        Returns\n        -------\n        pandas.DataFrame\n            The result of running the query, formatted as a pandas DataFrame.\n\n        Example\n        -------\n        >>> import streamlit as st\n        >>>\n        >>> conn = st.connection(\"sql\")\n        >>> df = conn.query(\"select * from pet_owners where owner = :owner\", ttl=3600, params={\"owner\":\"barbara\"})\n        >>> st.dataframe(df)\n        \"\"\"\n\n        from sqlalchemy import text\n        from sqlalchemy.exc import DatabaseError, InternalError, OperationalError\n        from tenacity import (\n            retry,\n            retry_if_exception_type,\n            stop_after_attempt,\n            wait_fixed,\n        )\n\n        @retry(\n            after=lambda _: self.reset(),\n            stop=stop_after_attempt(3),\n            reraise=True,\n            retry=retry_if_exception_type(\n                (DatabaseError, InternalError, OperationalError)\n            ),\n            wait=wait_fixed(1),\n        )\n        def _query(\n            sql: str,\n            index_col=None,\n            chunksize=None,\n            params=None,\n            **kwargs,\n        ) -> DataFrame:\n            import pandas as pd\n\n            instance = self._instance.connect()\n            return pd.read_sql(\n                text(sql),\n                instance,\n                index_col=index_col,\n                chunksize=chunksize,\n                params=params,\n                **kwargs,\n            )\n\n        # We modify our helper function's `__qualname__` here to work around default\n        # `@st.cache_data` behavior. Otherwise, `.query()` being called with different\n        # `ttl` values will reset the cache with each call, and the query caches won't\n        # be scoped by connection.\n        ttl_str = str(  # Avoid adding extra `.` characters to `__qualname__`\n            ttl\n        ).replace(\".\", \"_\")\n        _query.__qualname__ = f\"{_query.__qualname__}_{self._connection_name}_{ttl_str}\"\n        _query = cache_data(\n            show_spinner=show_spinner,\n            ttl=ttl,\n        )(_query)\n\n        return _query(\n            sql,\n            index_col=index_col,\n            chunksize=chunksize,\n            params=params,\n            **kwargs,\n        )\n\n    def connect(self) -> SQLAlchemyConnection:\n        \"\"\"Call ``.connect()`` on the underlying SQLAlchemy Engine, returning a new\\\n        ``sqlalchemy.engine.Connection`` object.\n\n        Calling this method is equivalent to calling ``self._instance.connect()``.\n\n        NOTE: This method should not be confused with the internal ``_connect`` method used\n        to implement a Streamlit Connection.\n        \"\"\"\n        return self._instance.connect()\n\n    @property\n    def engine(self) -> Engine:\n        \"\"\"The underlying SQLAlchemy Engine.\n\n        This is equivalent to accessing ``self._instance``.\n        \"\"\"\n        return self._instance\n\n    @property\n    def driver(self) -> str:\n        \"\"\"The name of the driver used by the underlying SQLAlchemy Engine.\n\n        This is equivalent to accessing ``self._instance.driver``.\n        \"\"\"\n        return self._instance.driver\n\n    @property\n    def session(self) -> Session:\n        \"\"\"Return a SQLAlchemy Session.\n\n        Users of this connection should use the contextmanager pattern for writes,\n        transactions, and anything more complex than simple read queries.\n\n        See the usage example below, which assumes we have a table ``numbers`` with a\n        single integer column ``val``. The `SQLAlchemy\n        <https://docs.sqlalchemy.org/en/20/orm/session_basics.html>`_ docs also contain\n        much more information on the usage of sessions.\n\n        Example\n        -------\n        >>> import streamlit as st\n        >>> conn = st.connection(\"sql\")\n        >>> n = st.slider(\"Pick a number\")\n        >>> if st.button(\"Add the number!\"):\n        ...     with conn.session as session:\n        ...         session.execute(\"INSERT INTO numbers (val) VALUES (:n);\", {\"n\": n})\n        ...         session.commit()\n        \"\"\"\n        from sqlalchemy.orm import Session\n\n        return Session(self._instance)\n\n    # NOTE: This more or less duplicates the default implementation in\n    # BaseConnection so that we can add another bullet point between the\n    # \"Configured from\" and \"Learn more\" items :/\n    def _repr_html_(self) -> str:\n        module_name = getattr(self, \"__module__\", None)\n        class_name = type(self).__name__\n\n        cfg = (\n            f\"- Configured from `[connections.{self._connection_name}]`\"\n            if len(self._secrets)\n            else \"\"\n        )\n\n        with self.session as s:\n            dialect = s.bind.dialect.name if s.bind is not None else \"unknown\"\n\n        return f\"\"\"\n---\n**st.connection {self._connection_name} built from `{module_name}.{class_name}`**\n{cfg}\n- Dialect: `{dialect}`\n- Learn more using `st.help()`\n---\n\"\"\"\n", "lib/streamlit/connections/__init__.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom streamlit.connections.base_connection import BaseConnection\nfrom streamlit.connections.snowflake_connection import SnowflakeConnection\nfrom streamlit.connections.snowpark_connection import SnowparkConnection\nfrom streamlit.connections.sql_connection import SQLConnection\n\nExperimentalBaseConnection = BaseConnection\n\n__all__ = [\n    \"BaseConnection\",\n    \"SnowflakeConnection\",\n    \"SnowparkConnection\",\n    \"SQLConnection\",\n    \"ExperimentalBaseConnection\",\n]\n", "lib/streamlit/elements/heading.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom enum import Enum\nfrom typing import TYPE_CHECKING, Literal, Union, cast\n\nfrom typing_extensions import TypeAlias\n\nfrom streamlit.errors import StreamlitAPIException\nfrom streamlit.proto.Heading_pb2 import Heading as HeadingProto\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.string_util import clean_text\n\nif TYPE_CHECKING:\n    from streamlit.delta_generator import DeltaGenerator\n    from streamlit.type_util import SupportsStr\n\n\nclass HeadingProtoTag(Enum):\n    TITLE_TAG = \"h1\"\n    HEADER_TAG = \"h2\"\n    SUBHEADER_TAG = \"h3\"\n\n\nAnchor: TypeAlias = Union[str, Literal[False], None]\nDivider: TypeAlias = Union[bool, str, None]\n\n\nclass HeadingMixin:\n    @gather_metrics(\"header\")\n    def header(\n        self,\n        body: SupportsStr,\n        anchor: Anchor = None,\n        *,  # keyword-only arguments:\n        help: str | None = None,\n        divider: Divider = False,\n    ) -> DeltaGenerator:\n        \"\"\"Display text in header formatting.\n\n        Parameters\n        ----------\n        body : str\n            The text to display as Github-flavored Markdown. Syntax\n            information can be found at: https://github.github.com/gfm.\n\n            This also supports:\n\n            * Emoji shortcodes, such as ``:+1:``  and ``:sunglasses:``.\n              For a list of all supported codes,\n              see https://share.streamlit.io/streamlit/emoji-shortcodes.\n\n            * LaTeX expressions, by wrapping them in \"$\" or \"$$\" (the \"$$\"\n              must be on their own lines). Supported LaTeX functions are listed\n              at https://katex.org/docs/supported.html.\n\n            * Colored text and background colors for text, using the syntax\n              ``:color[text to be colored]`` and ``:color-background[text to be colored]``,\n              respectively. ``color`` must be replaced with any of the following\n              supported colors: blue, green, orange, red, violet, gray/grey, rainbow.\n              For example, you can use ``:orange[your text here]`` or\n              ``:blue-background[your text here]``.\n\n        anchor : str or False\n            The anchor name of the header that can be accessed with #anchor\n            in the URL. If omitted, it generates an anchor using the body.\n            If False, the anchor is not shown in the UI.\n\n        help : str\n            An optional tooltip that gets displayed next to the header.\n\n        divider : bool or \u201cblue\u201d, \u201cgreen\u201d, \u201corange\u201d, \u201cred\u201d, \u201cviolet\u201d, \u201cgray\u201d/\"grey\", or \u201crainbow\u201d\n            Shows a colored divider below the header. If True, successive\n            headers will cycle through divider colors. That is, the first\n            header will have a blue line, the second header will have a\n            green line, and so on. If a string, the color can be set to one of\n            the following: blue, green, orange, red, violet, gray/grey, or\n            rainbow.\n\n        Examples\n        --------\n        >>> import streamlit as st\n        >>>\n        >>> st.header('This is a header with a divider', divider='rainbow')\n        >>> st.header('_Streamlit_ is :blue[cool] :sunglasses:')\n\n        .. output::\n           https://doc-header.streamlit.app/\n           height: 220px\n\n        \"\"\"\n        return self.dg._enqueue(\n            \"heading\",\n            HeadingMixin._create_heading_proto(\n                tag=HeadingProtoTag.HEADER_TAG,\n                body=body,\n                anchor=anchor,\n                help=help,\n                divider=divider,\n            ),\n        )\n\n    @gather_metrics(\"subheader\")\n    def subheader(\n        self,\n        body: SupportsStr,\n        anchor: Anchor = None,\n        *,  # keyword-only arguments:\n        help: str | None = None,\n        divider: Divider = False,\n    ) -> DeltaGenerator:\n        \"\"\"Display text in subheader formatting.\n\n        Parameters\n        ----------\n        body : str\n            The text to display as Github-flavored Markdown. Syntax\n            information can be found at: https://github.github.com/gfm.\n\n            This also supports:\n\n            * Emoji shortcodes, such as ``:+1:``  and ``:sunglasses:``.\n              For a list of all supported codes,\n              see https://share.streamlit.io/streamlit/emoji-shortcodes.\n\n            * LaTeX expressions, by wrapping them in \"$\" or \"$$\" (the \"$$\"\n              must be on their own lines). Supported LaTeX functions are listed\n              at https://katex.org/docs/supported.html.\n\n            * Colored text and background colors for text, using the syntax\n              ``:color[text to be colored]`` and ``:color-background[text to be colored]``,\n              respectively. ``color`` must be replaced with any of the following\n              supported colors: blue, green, orange, red, violet, gray/grey, rainbow.\n              For example, you can use ``:orange[your text here]`` or\n              ``:blue-background[your text here]``.\n\n        anchor : str or False\n            The anchor name of the header that can be accessed with #anchor\n            in the URL. If omitted, it generates an anchor using the body.\n            If False, the anchor is not shown in the UI.\n\n        help : str\n            An optional tooltip that gets displayed next to the subheader.\n\n        divider : bool or \u201cblue\u201d, \u201cgreen\u201d, \u201corange\u201d, \u201cred\u201d, \u201cviolet\u201d, \u201cgray\u201d/\"grey\", or \u201crainbow\u201d\n            Shows a colored divider below the header. If True, successive\n            headers will cycle through divider colors. That is, the first\n            header will have a blue line, the second header will have a\n            green line, and so on. If a string, the color can be set to one of\n            the following: blue, green, orange, red, violet, gray/grey, or\n            rainbow.\n\n        Examples\n        --------\n        >>> import streamlit as st\n        >>>\n        >>> st.subheader('This is a subheader with a divider', divider='rainbow')\n        >>> st.subheader('_Streamlit_ is :blue[cool] :sunglasses:')\n\n        .. output::\n           https://doc-subheader.streamlit.app/\n           height: 220px\n\n        \"\"\"\n        return self.dg._enqueue(\n            \"heading\",\n            HeadingMixin._create_heading_proto(\n                tag=HeadingProtoTag.SUBHEADER_TAG,\n                body=body,\n                anchor=anchor,\n                help=help,\n                divider=divider,\n            ),\n        )\n\n    @gather_metrics(\"title\")\n    def title(\n        self,\n        body: SupportsStr,\n        anchor: Anchor = None,\n        *,  # keyword-only arguments:\n        help: str | None = None,\n    ) -> DeltaGenerator:\n        \"\"\"Display text in title formatting.\n\n        Each document should have a single `st.title()`, although this is not\n        enforced.\n\n        Parameters\n        ----------\n        body : str\n            The text to display as Github-flavored Markdown. Syntax\n            information can be found at: https://github.github.com/gfm.\n\n            This also supports:\n\n            * Emoji shortcodes, such as ``:+1:``  and ``:sunglasses:``.\n              For a list of all supported codes,\n              see https://share.streamlit.io/streamlit/emoji-shortcodes.\n\n            * LaTeX expressions, by wrapping them in \"$\" or \"$$\" (the \"$$\"\n              must be on their own lines). Supported LaTeX functions are listed\n              at https://katex.org/docs/supported.html.\n\n            * Colored text and background colors for text, using the syntax\n              ``:color[text to be colored]`` and ``:color-background[text to be colored]``,\n              respectively. ``color`` must be replaced with any of the following\n              supported colors: blue, green, orange, red, violet, gray/grey, rainbow.\n              For example, you can use ``:orange[your text here]`` or\n              ``:blue-background[your text here]``.\n\n        anchor : str or False\n            The anchor name of the header that can be accessed with #anchor\n            in the URL. If omitted, it generates an anchor using the body.\n            If False, the anchor is not shown in the UI.\n\n        help : str\n            An optional tooltip that gets displayed next to the title.\n\n        Examples\n        --------\n        >>> import streamlit as st\n        >>>\n        >>> st.title('This is a title')\n        >>> st.title('_Streamlit_ is :blue[cool] :sunglasses:')\n\n        .. output::\n           https://doc-title.streamlit.app/\n           height: 220px\n\n        \"\"\"\n        return self.dg._enqueue(\n            \"heading\",\n            HeadingMixin._create_heading_proto(\n                tag=HeadingProtoTag.TITLE_TAG, body=body, anchor=anchor, help=help\n            ),\n        )\n\n    @property\n    def dg(self) -> DeltaGenerator:\n        \"\"\"Get our DeltaGenerator.\"\"\"\n        return cast(\"DeltaGenerator\", self)\n\n    @staticmethod\n    def _handle_divider_color(divider: Divider) -> str:\n        if divider is True:\n            return \"auto\"\n        valid_colors = [\n            \"blue\",\n            \"green\",\n            \"orange\",\n            \"red\",\n            \"violet\",\n            \"gray\",\n            \"grey\",\n            \"rainbow\",\n        ]\n        if divider in valid_colors:\n            return cast(str, divider)\n        else:\n            raise StreamlitAPIException(\n                f\"Divider parameter has invalid value: `{divider}`. Please choose from: {', '.join(valid_colors)}.\"\n            )\n\n    @staticmethod\n    def _create_heading_proto(\n        tag: HeadingProtoTag,\n        body: SupportsStr,\n        anchor: Anchor = None,\n        help: str | None = None,\n        divider: Divider = False,\n    ) -> HeadingProto:\n        proto = HeadingProto()\n        proto.tag = tag.value\n        proto.body = clean_text(body)\n        if divider:\n            proto.divider = HeadingMixin._handle_divider_color(divider)\n        if anchor is not None:\n            if anchor is False:\n                proto.hide_anchor = True\n            elif isinstance(anchor, str):\n                proto.anchor = anchor\n            elif anchor is True:  # type: ignore\n                raise StreamlitAPIException(\n                    \"Anchor parameter has invalid value: %s. \"\n                    \"Supported values: None, any string or False\" % anchor\n                )\n            else:\n                raise StreamlitAPIException(\n                    \"Anchor parameter has invalid type: %s. \"\n                    \"Supported values: None, any string or False\"\n                    % type(anchor).__name__\n                )\n\n        if help:\n            proto.help = help\n        return proto\n", "lib/streamlit/elements/exception.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport os\nimport traceback\nfrom typing import TYPE_CHECKING, Final, cast\n\nimport streamlit\nfrom streamlit.errors import (\n    MarkdownFormattedException,\n    StreamlitAPIException,\n    StreamlitAPIWarning,\n    StreamlitDeprecationWarning,\n    UncaughtAppException,\n)\nfrom streamlit.logger import get_logger\nfrom streamlit.proto.Exception_pb2 import Exception as ExceptionProto\nfrom streamlit.runtime.metrics_util import gather_metrics\n\nif TYPE_CHECKING:\n    from streamlit.delta_generator import DeltaGenerator\n\n_LOGGER: Final = get_logger(__name__)\n\n# When client.showErrorDetails is False, we show a generic warning in the\n# frontend when we encounter an uncaught app exception.\n_GENERIC_UNCAUGHT_EXCEPTION_TEXT: Final = \"This app has encountered an error. The original error message is redacted to prevent data leaks.  Full error details have been recorded in the logs (if you're on Streamlit Cloud, click on 'Manage app' in the lower right of your app).\"\n\n# Extract the streamlit package path. Make it absolute, resolve aliases, and\n# ensure there's a trailing path separator\n_STREAMLIT_DIR: Final = os.path.join(\n    os.path.realpath(os.path.dirname(streamlit.__file__)), \"\"\n)\n\n\nclass ExceptionMixin:\n    @gather_metrics(\"exception\")\n    def exception(self, exception: BaseException) -> DeltaGenerator:\n        \"\"\"Display an exception.\n\n        Parameters\n        ----------\n        exception : Exception\n            The exception to display.\n\n        Example\n        -------\n        >>> import streamlit as st\n        >>>\n        >>> e = RuntimeError('This is an exception of type RuntimeError')\n        >>> st.exception(e)\n\n        \"\"\"\n        exception_proto = ExceptionProto()\n        marshall(exception_proto, exception)\n        return self.dg._enqueue(\"exception\", exception_proto)\n\n    @property\n    def dg(self) -> DeltaGenerator:\n        \"\"\"Get our DeltaGenerator.\"\"\"\n        return cast(\"DeltaGenerator\", self)\n\n\ndef marshall(exception_proto: ExceptionProto, exception: BaseException) -> None:\n    \"\"\"Marshalls an Exception.proto message.\n\n    Parameters\n    ----------\n    exception_proto : Exception.proto\n        The Exception protobuf to fill out\n\n    exception : BaseException\n        The exception whose data we're extracting\n    \"\"\"\n    # If this is a StreamlitAPIException, we prune all Streamlit entries\n    # from the exception's stack trace.\n    is_api_exception = isinstance(exception, StreamlitAPIException)\n    is_deprecation_exception = isinstance(exception, StreamlitDeprecationWarning)\n    is_markdown_exception = isinstance(exception, MarkdownFormattedException)\n    is_uncaught_app_exception = isinstance(exception, UncaughtAppException)\n\n    stack_trace = (\n        []\n        if is_deprecation_exception\n        else _get_stack_trace_str_list(\n            exception, strip_streamlit_stack_entries=is_api_exception\n        )\n    )\n\n    # Some exceptions (like UserHashError) have an alternate_name attribute so\n    # we can pretend to the user that the exception is called something else.\n    if getattr(exception, \"alternate_name\", None) is not None:\n        exception_proto.type = exception.alternate_name  # type: ignore[attr-defined]\n    else:\n        exception_proto.type = type(exception).__name__\n\n    exception_proto.stack_trace.extend(stack_trace)\n    exception_proto.is_warning = isinstance(exception, Warning)\n\n    try:\n        if isinstance(exception, SyntaxError):\n            # SyntaxErrors have additional fields (filename, text, lineno,\n            # offset) that we can use for a nicely-formatted message telling\n            # the user what to fix.\n            exception_proto.message = _format_syntax_error_message(exception)\n        else:\n            exception_proto.message = str(exception).strip()\n            exception_proto.message_is_markdown = is_markdown_exception\n\n    except Exception as str_exception:\n        # Sometimes the exception's __str__/__unicode__ method itself\n        # raises an error.\n        exception_proto.message = \"\"\n        _LOGGER.warning(\n            \"\"\"\n\nStreamlit was unable to parse the data from an exception in the user's script.\nThis is usually due to a bug in the Exception object itself. Here is some info\nabout that Exception object, so you can report a bug to the original author:\n\nException type:\n  %(etype)s\n\nProblem:\n  %(str_exception)s\n\nTraceback:\n%(str_exception_tb)s\n\n        \"\"\"\n            % {\n                \"etype\": type(exception).__name__,\n                \"str_exception\": str_exception,\n                \"str_exception_tb\": \"\\n\".join(_get_stack_trace_str_list(str_exception)),\n            }\n        )\n\n    if is_uncaught_app_exception:\n        uae = cast(UncaughtAppException, exception)\n        exception_proto.message = _GENERIC_UNCAUGHT_EXCEPTION_TEXT\n        type_str = str(type(uae.exc))\n        exception_proto.type = type_str.replace(\"<class '\", \"\").replace(\"'>\", \"\")\n\n\ndef _format_syntax_error_message(exception: SyntaxError) -> str:\n    \"\"\"Returns a nicely formatted SyntaxError message that emulates\n    what the Python interpreter outputs, e.g.:\n\n    > File \"raven.py\", line 3\n    >   st.write('Hello world!!'))\n    >                            ^\n    > SyntaxError: invalid syntax\n\n    \"\"\"\n    if exception.text:\n        if exception.offset is not None:\n            caret_indent = \" \" * max(exception.offset - 1, 0)\n        else:\n            caret_indent = \"\"\n\n        return (\n            'File \"%(filename)s\", line %(lineno)s\\n'\n            \"  %(text)s\\n\"\n            \"  %(caret_indent)s^\\n\"\n            \"%(errname)s: %(msg)s\"\n            % {\n                \"filename\": exception.filename,\n                \"lineno\": exception.lineno,\n                \"text\": exception.text.rstrip(),\n                \"caret_indent\": caret_indent,\n                \"errname\": type(exception).__name__,\n                \"msg\": exception.msg,\n            }\n        )\n    # If a few edge cases, SyntaxErrors don't have all these nice fields. So we\n    # have a fall back here.\n    # Example edge case error message: encoding declaration in Unicode string\n    return str(exception)\n\n\ndef _get_stack_trace_str_list(\n    exception: BaseException, strip_streamlit_stack_entries: bool = False\n) -> list[str]:\n    \"\"\"Get the stack trace for the given exception.\n\n    Parameters\n    ----------\n    exception : BaseException\n        The exception to extract the traceback from\n\n    strip_streamlit_stack_entries : bool\n        If True, all traceback entries that are in the Streamlit package\n        will be removed from the list. We do this for exceptions that result\n        from incorrect usage of Streamlit APIs, so that the user doesn't see\n        a bunch of noise about ScriptRunner, DeltaGenerator, etc.\n\n    Returns\n    -------\n    list\n        The exception traceback as a list of strings\n\n    \"\"\"\n    extracted_traceback: traceback.StackSummary | None = None\n    if isinstance(exception, StreamlitAPIWarning):\n        extracted_traceback = exception.tacked_on_stack\n    elif hasattr(exception, \"__traceback__\"):\n        extracted_traceback = traceback.extract_tb(exception.__traceback__)\n\n    if isinstance(exception, UncaughtAppException):\n        extracted_traceback = traceback.extract_tb(exception.exc.__traceback__)\n\n    # Format the extracted traceback and add it to the protobuf element.\n    if extracted_traceback is None:\n        stack_trace_str_list = [\n            \"Cannot extract the stack trace for this exception. \"\n            \"Try calling exception() within the `catch` block.\"\n        ]\n    else:\n        if strip_streamlit_stack_entries:\n            extracted_frames = _get_nonstreamlit_traceback(extracted_traceback)\n            stack_trace_str_list = traceback.format_list(extracted_frames)\n        else:\n            stack_trace_str_list = traceback.format_list(extracted_traceback)\n\n    stack_trace_str_list = [item.strip() for item in stack_trace_str_list]\n\n    return stack_trace_str_list\n\n\ndef _is_in_streamlit_package(file: str) -> bool:\n    \"\"\"True if the given file is part of the streamlit package.\"\"\"\n    try:\n        common_prefix = os.path.commonprefix([os.path.realpath(file), _STREAMLIT_DIR])\n    except ValueError:\n        # Raised if paths are on different drives.\n        return False\n\n    return common_prefix == _STREAMLIT_DIR\n\n\ndef _get_nonstreamlit_traceback(\n    extracted_tb: traceback.StackSummary,\n) -> list[traceback.FrameSummary]:\n    return [\n        entry for entry in extracted_tb if not _is_in_streamlit_package(entry.filename)\n    ]\n", "lib/streamlit/elements/map.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"A wrapper for simple PyDeck scatter charts.\"\"\"\n\nfrom __future__ import annotations\n\nimport copy\nimport hashlib\nimport json\nfrom typing import TYPE_CHECKING, Any, Collection, Dict, Final, Iterable, Union, cast\n\nfrom typing_extensions import TypeAlias\n\nimport streamlit.elements.deck_gl_json_chart as deck_gl_json_chart\nfrom streamlit import config, type_util\nfrom streamlit.color_util import Color, IntColorTuple, is_color_like, to_int_color_tuple\nfrom streamlit.errors import StreamlitAPIException\nfrom streamlit.proto.DeckGlJsonChart_pb2 import DeckGlJsonChart as DeckGlJsonChartProto\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.util import HASHLIB_KWARGS\n\nif TYPE_CHECKING:\n    from pandas import DataFrame\n    from pandas.io.formats.style import Styler\n\n    from streamlit.delta_generator import DeltaGenerator\n\n\nData: TypeAlias = Union[\n    \"DataFrame\",\n    \"Styler\",\n    Iterable[Any],\n    Dict[Any, Any],\n    None,\n]\n\n# Map used as the basis for st.map.\n_DEFAULT_MAP: Final[dict[str, Any]] = dict(deck_gl_json_chart.EMPTY_MAP)\n\n# Other default parameters for st.map.\n_DEFAULT_LAT_COL_NAMES: Final = {\"lat\", \"latitude\", \"LAT\", \"LATITUDE\"}\n_DEFAULT_LON_COL_NAMES: Final = {\"lon\", \"longitude\", \"LON\", \"LONGITUDE\"}\n_DEFAULT_COLOR: Final = (200, 30, 0, 160)\n_DEFAULT_SIZE: Final = 100\n_DEFAULT_ZOOM_LEVEL: Final = 12\n_ZOOM_LEVELS: Final = [\n    360,\n    180,\n    90,\n    45,\n    22.5,\n    11.25,\n    5.625,\n    2.813,\n    1.406,\n    0.703,\n    0.352,\n    0.176,\n    0.088,\n    0.044,\n    0.022,\n    0.011,\n    0.005,\n    0.003,\n    0.001,\n    0.0005,\n    0.00025,\n]\n\n\nclass MapMixin:\n    @gather_metrics(\"map\")\n    def map(\n        self,\n        data: Data = None,\n        *,\n        latitude: str | None = None,\n        longitude: str | None = None,\n        color: None | str | Color = None,\n        size: None | str | float = None,\n        zoom: int | None = None,\n        use_container_width: bool = True,\n    ) -> DeltaGenerator:\n        \"\"\"Display a map with a scatterplot overlaid onto it.\n\n        This is a wrapper around ``st.pydeck_chart`` to quickly create\n        scatterplot charts on top of a map, with auto-centering and auto-zoom.\n\n        When using this command, Mapbox provides the map tiles to render map\n        content. Note that Mapbox is a third-party product and Streamlit accepts\n        no responsibility or liability of any kind for Mapbox or for any content\n        or information made available by Mapbox.\n\n        Mapbox requires users to register and provide a token before users can\n        request map tiles. Currently, Streamlit provides this token for you, but\n        this could change at any time. We strongly recommend all users create and\n        use their own personal Mapbox token to avoid any disruptions to their\n        experience. You can do this with the ``mapbox.token`` config option. The\n        use of Mapbox is governed by Mapbox's Terms of Use.\n\n        To get a token for yourself, create an account at https://mapbox.com.\n        For more info on how to set config options, see\n        https://docs.streamlit.io/develop/api-reference/configuration/config.toml.\n\n        Parameters\n        ----------\n        data : pandas.DataFrame, pandas.Styler, pyarrow.Table, pyspark.sql.DataFrame,\\\n            snowflake.snowpark.dataframe.DataFrame, snowflake.snowpark.table.Table,\\\n            Iterable, dict, or None\n\n            The data to be plotted.\n\n        latitude : str or None\n            The name of the column containing the latitude coordinates of\n            the datapoints in the chart.\n\n            If None, the latitude data will come from any column named 'lat',\n            'latitude', 'LAT', or 'LATITUDE'.\n\n        longitude : str or None\n            The name of the column containing the longitude coordinates of\n            the datapoints in the chart.\n\n            If None, the longitude data will come from any column named 'lon',\n            'longitude', 'LON', or 'LONGITUDE'.\n\n        color : str or tuple or None\n            The color of the circles representing each datapoint.\n\n            Can be:\n\n            * None, to use the default color.\n            * A hex string like \"#ffaa00\" or \"#ffaa0088\".\n            * An RGB or RGBA tuple with the red, green, blue, and alpha\n              components specified as ints from 0 to 255 or floats from 0.0 to\n              1.0.\n            * The name of the column to use for the color. Cells in this column\n              should contain colors represented as a hex string or color tuple,\n              as described above.\n\n        size : str or float or None\n            The size of the circles representing each point, in meters.\n\n            This can be:\n\n            * None, to use the default size.\n            * A number like 100, to specify a single size to use for all\n              datapoints.\n            * The name of the column to use for the size. This allows each\n              datapoint to be represented by a circle of a different size.\n\n        zoom : int\n            Zoom level as specified in\n            https://wiki.openstreetmap.org/wiki/Zoom_levels.\n\n        use_container_width : bool\n            Whether to override the map's native width with the width of\n            the parent container. If ``use_container_width`` is ``True``\n            (default), Streamlit sets the width of the map to match the width\n            of the parent container. If ``use_container_width`` is ``False``,\n            Streamlit sets the width of the chart to fit its contents according\n            to the plotting library, up to the width of the parent container.\n\n        Examples\n        --------\n        >>> import streamlit as st\n        >>> import pandas as pd\n        >>> import numpy as np\n        >>>\n        >>> df = pd.DataFrame(\n        ...     np.random.randn(1000, 2) / [50, 50] + [37.76, -122.4],\n        ...     columns=['lat', 'lon'])\n        ...\n        >>> st.map(df)\n\n        .. output::\n           https://doc-map.streamlit.app/\n           height: 600px\n\n        You can also customize the size and color of the datapoints:\n\n        >>> st.map(df, size=20, color='#0044ff')\n\n        And finally, you can choose different columns to use for the latitude\n        and longitude components, as well as set size and color of each\n        datapoint dynamically based on other columns:\n\n        >>> import streamlit as st\n        >>> import pandas as pd\n        >>> import numpy as np\n        >>>\n        >>> df = pd.DataFrame({\n        ...     \"col1\": np.random.randn(1000) / 50 + 37.76,\n        ...     \"col2\": np.random.randn(1000) / 50 + -122.4,\n        ...     \"col3\": np.random.randn(1000) * 100,\n        ...     \"col4\": np.random.rand(1000, 4).tolist(),\n        ... })\n        >>>\n        >>> st.map(df,\n        ...     latitude='col1',\n        ...     longitude='col2',\n        ...     size='col3',\n        ...     color='col4')\n\n        .. output::\n           https://doc-map-color.streamlit.app/\n           height: 600px\n\n        \"\"\"\n        # This feature was turned off while we investigate why different\n        # map styles cause DeckGL to crash.\n        #\n        # For reference, this was the docstring for map_style:\n        #\n        #   map_style : str or None\n        #       One of Mapbox's map style URLs. A full list can be found here:\n        #       https://docs.mapbox.com/api/maps/styles/#mapbox-styles\n        #\n        #       This feature requires a Mapbox token. See the top of these docs\n        #       for information on how to get one and set it up in Streamlit.\n        #\n        map_style = None\n        map_proto = DeckGlJsonChartProto()\n        deck_gl_json = to_deckgl_json(\n            data, latitude, longitude, size, color, map_style, zoom\n        )\n        marshall(map_proto, deck_gl_json, use_container_width)\n        return self.dg._enqueue(\"deck_gl_json_chart\", map_proto)\n\n    @property\n    def dg(self) -> DeltaGenerator:\n        \"\"\"Get our DeltaGenerator.\"\"\"\n        return cast(\"DeltaGenerator\", self)\n\n\ndef to_deckgl_json(\n    data: Data,\n    lat: str | None,\n    lon: str | None,\n    size: None | str | float,\n    color: None | str | Collection[float],\n    map_style: str | None,\n    zoom: int | None,\n) -> str:\n    if data is None:\n        return json.dumps(_DEFAULT_MAP)\n\n    # TODO(harahu): iterables don't have the empty attribute. This is either\n    # a bug, or the documented data type is too broad. One or the other\n    # should be addressed\n    if hasattr(data, \"empty\") and data.empty:\n        return json.dumps(_DEFAULT_MAP)\n\n    df = type_util.convert_anything_to_df(data)\n\n    lat_col_name = _get_lat_or_lon_col_name(df, \"latitude\", lat, _DEFAULT_LAT_COL_NAMES)\n    lon_col_name = _get_lat_or_lon_col_name(\n        df, \"longitude\", lon, _DEFAULT_LON_COL_NAMES\n    )\n    size_arg, size_col_name = _get_value_and_col_name(df, size, _DEFAULT_SIZE)\n    color_arg, color_col_name = _get_value_and_col_name(df, color, _DEFAULT_COLOR)\n\n    # Drop columns we're not using.\n    # (Sort for tests)\n    used_columns = sorted(\n        [\n            c\n            for c in {lat_col_name, lon_col_name, size_col_name, color_col_name}\n            if c is not None\n        ]\n    )\n    df = df[used_columns]\n\n    color_arg = _convert_color_arg_or_column(df, color_arg, color_col_name)\n\n    zoom, center_lat, center_lon = _get_viewport_details(\n        df, lat_col_name, lon_col_name, zoom\n    )\n\n    default = copy.deepcopy(_DEFAULT_MAP)\n    default[\"initialViewState\"][\"latitude\"] = center_lat\n    default[\"initialViewState\"][\"longitude\"] = center_lon\n    default[\"initialViewState\"][\"zoom\"] = zoom\n    default[\"layers\"] = [\n        {\n            \"@@type\": \"ScatterplotLayer\",\n            \"getPosition\": f\"@@=[{lon_col_name}, {lat_col_name}]\",\n            \"getRadius\": size_arg,\n            \"radiusMinPixels\": 3,\n            \"radiusUnits\": \"meters\",\n            \"getFillColor\": color_arg,\n            \"data\": df.to_dict(\"records\"),\n        }\n    ]\n\n    if map_style:\n        if not config.get_option(\"mapbox.token\"):\n            raise StreamlitAPIException(\n                \"You need a Mapbox token in order to select a map type. \"\n                \"Refer to the docs for st.map for more information.\"\n            )\n        default[\"mapStyle\"] = map_style\n\n    return json.dumps(default)\n\n\ndef _get_lat_or_lon_col_name(\n    data: DataFrame,\n    human_readable_name: str,\n    col_name_from_user: str | None,\n    default_col_names: set[str],\n) -> str:\n    \"\"\"Returns the column name to be used for latitude or longitude.\"\"\"\n\n    if isinstance(col_name_from_user, str) and col_name_from_user in data.columns:\n        col_name = col_name_from_user\n\n    else:\n        # Try one of the default col_names:\n        candidate_col_name = None\n\n        for c in default_col_names:\n            if c in data.columns:\n                candidate_col_name = c\n                break\n\n        if candidate_col_name is None:\n            formatted_allowed_col_name = \", \".join(map(repr, sorted(default_col_names)))\n            formmated_col_names = \", \".join(map(repr, list(data.columns)))\n\n            raise StreamlitAPIException(\n                f\"Map data must contain a {human_readable_name} column named: \"\n                f\"{formatted_allowed_col_name}. Existing columns: {formmated_col_names}\"\n            )\n        else:\n            col_name = candidate_col_name\n\n    # Check that the column is well-formed.\n    # IMPLEMENTATION NOTE: We can't use isnull().values.any() because .values can return\n    # ExtensionArrays, which don't have a .any() method.\n    # (Read about ExtensionArrays here: # https://pandas.pydata.org/community/blog/extension-arrays.html)\n    # However, after a performance test I found the solution below runs basically as\n    # fast as .values.any().\n    if any(data[col_name].isnull().array):\n        raise StreamlitAPIException(\n            f\"Column {col_name} is not allowed to contain null values, such \"\n            \"as NaN, NaT, or None.\"\n        )\n\n    return col_name\n\n\ndef _get_value_and_col_name(\n    data: DataFrame,\n    value_or_name: Any,\n    default_value: Any,\n) -> tuple[Any, str | None]:\n    \"\"\"Take a value_or_name passed in by the Streamlit developer and return a PyDeck\n    argument and column name for that property.\n\n    This is used for the size and color properties of the chart.\n\n    Example:\n    - If the user passes size=None, this returns the default size value and no column.\n    - If the user passes size=42, this returns 42 and no column.\n    - If the user passes size=\"my_col_123\", this returns \"@@=my_col_123\" and \"my_col_123\".\n    \"\"\"\n\n    pydeck_arg: str | float\n\n    if isinstance(value_or_name, str) and value_or_name in data.columns:\n        col_name = value_or_name\n        pydeck_arg = f\"@@={col_name}\"\n    else:\n        col_name = None\n\n        if value_or_name is None:\n            pydeck_arg = default_value\n        else:\n            pydeck_arg = value_or_name\n\n    return pydeck_arg, col_name\n\n\ndef _convert_color_arg_or_column(\n    data: DataFrame,\n    color_arg: str | Color,\n    color_col_name: str | None,\n) -> None | str | IntColorTuple:\n    \"\"\"Converts color to a format accepted by PyDeck.\n\n    For example:\n    - If color_arg is \"#fff\", then returns (255, 255, 255, 255).\n    - If color_col_name is \"my_col_123\", then it converts everything in column my_col_123 to\n      an accepted color format such as (0, 100, 200, 255).\n\n    NOTE: This function mutates the data argument.\n    \"\"\"\n\n    color_arg_out: None | str | IntColorTuple = None\n\n    if color_col_name is not None:\n        # Convert color column to the right format.\n        if len(data[color_col_name]) > 0 and is_color_like(data[color_col_name].iat[0]):\n            # Use .loc[] to avoid a SettingWithCopyWarning in some cases.\n            data.loc[:, color_col_name] = data.loc[:, color_col_name].map(\n                to_int_color_tuple\n            )\n        else:\n            raise StreamlitAPIException(\n                f'Column \"{color_col_name}\" does not appear to contain valid colors.'\n            )\n\n        # This is guaranteed to be a str because of _get_value_and_col_name\n        assert isinstance(color_arg, str)\n        color_arg_out = color_arg\n\n    elif color_arg is not None:\n        color_arg_out = to_int_color_tuple(color_arg)\n\n    return color_arg_out\n\n\ndef _get_viewport_details(\n    data: DataFrame, lat_col_name: str, lon_col_name: str, zoom: int | None\n) -> tuple[int, float, float]:\n    \"\"\"Auto-set viewport when not fully specified by user.\"\"\"\n    min_lat = data[lat_col_name].min()\n    max_lat = data[lat_col_name].max()\n    min_lon = data[lon_col_name].min()\n    max_lon = data[lon_col_name].max()\n    center_lat = (max_lat + min_lat) / 2.0\n    center_lon = (max_lon + min_lon) / 2.0\n    range_lon = abs(max_lon - min_lon)\n    range_lat = abs(max_lat - min_lat)\n\n    if zoom is None:\n        if range_lon > range_lat:\n            longitude_distance = range_lon\n        else:\n            longitude_distance = range_lat\n        zoom = _get_zoom_level(longitude_distance)\n\n    return zoom, center_lat, center_lon\n\n\ndef _get_zoom_level(distance: float) -> int:\n    \"\"\"Get the zoom level for a given distance in degrees.\n\n    See https://wiki.openstreetmap.org/wiki/Zoom_levels for reference.\n\n    Parameters\n    ----------\n    distance : float\n        How many degrees of longitude should fit in the map.\n\n    Returns\n    -------\n    int\n        The zoom level, from 0 to 20.\n\n    \"\"\"\n    for i in range(len(_ZOOM_LEVELS) - 1):\n        if _ZOOM_LEVELS[i + 1] < distance <= _ZOOM_LEVELS[i]:\n            return i\n\n    # For small number of points the default zoom level will be used.\n    return _DEFAULT_ZOOM_LEVEL\n\n\ndef marshall(\n    pydeck_proto: DeckGlJsonChartProto,\n    pydeck_json: str,\n    use_container_width: bool,\n) -> None:\n    json_bytes = pydeck_json.encode(\"utf-8\")\n    id = hashlib.md5(json_bytes, **HASHLIB_KWARGS).hexdigest()\n\n    pydeck_proto.json = pydeck_json\n    pydeck_proto.use_container_width = use_container_width\n\n    pydeck_proto.id = id\n", "lib/streamlit/elements/html.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport os\nfrom typing import TYPE_CHECKING, cast\n\nfrom streamlit.proto.Html_pb2 import Html as HtmlProto\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.string_util import clean_text\n\nif TYPE_CHECKING:\n    from streamlit.delta_generator import DeltaGenerator\n\n\nclass HtmlMixin:\n    @gather_metrics(\"html\")\n    def html(\n        self,\n        body: str,\n    ) -> DeltaGenerator:\n        \"\"\"Insert HTML into your app.\n\n        Adding custom HTML to your app impacts safety, styling, and\n        maintainability. We sanitize HTML with `DOMPurify\n        <https://github.com/cure53/DOMPurify>`_, but inserting HTML remains a\n        developer risk. Passing untrusted code to ``st.html`` or dynamically\n        loading external code can increase the risk of vulnerabilities in your\n        app.\n\n        ``st.html`` content is **not** iframed. Executing JavaScript is not\n        supported at this time.\n\n        Parameters\n        ----------\n        body : str\n            The HTML code to insert, or path to an HTML code file which is\n            loaded and inserted.\n\n            If the provided string is the path of a local file, Streamlit will\n            load the file and render its contents as HTML. Otherwise, Streamlit\n            will render the string directly as HTML.\n\n        Example\n        -------\n        >>> import streamlit as st\n        >>>\n        >>> st.html(\"<p><span style='text-decoration: line-through double red;'>Oops</span>!</p>\")\n\n        .. output::\n           https://doc-html.streamlit.app/\n           height: 300px\n\n        \"\"\"\n        html_proto = HtmlProto()\n        # Check if the body is a file path\n        if os.path.isfile(body):\n            with open(body, encoding=\"utf-8\") as f:\n                html_proto.body = f.read()\n        else:\n            html_proto.body = clean_text(body)\n        return self.dg._enqueue(\"html\", html_proto)\n\n    @property\n    def dg(self) -> DeltaGenerator:\n        \"\"\"Get our DeltaGenerator.\"\"\"\n        return cast(\"DeltaGenerator\", self)\n", "lib/streamlit/elements/arrow.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport json\nfrom dataclasses import dataclass\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    Dict,\n    Final,\n    Iterable,\n    List,\n    Literal,\n    TypedDict,\n    Union,\n    cast,\n    overload,\n)\n\nfrom typing_extensions import TypeAlias\n\nfrom streamlit import type_util\nfrom streamlit.elements.lib.column_config_utils import (\n    INDEX_IDENTIFIER,\n    ColumnConfigMappingInput,\n    apply_data_specific_configs,\n    marshall_column_config,\n    process_config_mapping,\n    update_column_config,\n)\nfrom streamlit.elements.lib.event_utils import AttributeDictionary\nfrom streamlit.elements.lib.pandas_styler_utils import marshall_styler\nfrom streamlit.elements.lib.policies import (\n    check_cache_replay_rules,\n    check_callback_rules,\n    check_session_state_rules,\n)\nfrom streamlit.errors import StreamlitAPIException\nfrom streamlit.proto.Arrow_pb2 import Arrow as ArrowProto\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.runtime.scriptrunner import get_script_run_ctx\nfrom streamlit.runtime.state import WidgetCallback, register_widget\nfrom streamlit.runtime.state.common import compute_widget_id\nfrom streamlit.type_util import Key, to_key\n\nif TYPE_CHECKING:\n    import pyarrow as pa\n    from numpy import ndarray\n    from pandas import DataFrame, Index, Series\n    from pandas.io.formats.style import Styler\n\n    from streamlit.delta_generator import DeltaGenerator\n\nData: TypeAlias = Union[\n    \"DataFrame\",\n    \"Series\",\n    \"Styler\",\n    \"Index\",\n    \"pa.Table\",\n    \"ndarray\",\n    Iterable,\n    Dict[str, List[Any]],\n    None,\n]\n\nSelectionMode: TypeAlias = Literal[\n    \"single-row\", \"multi-row\", \"single-column\", \"multi-column\"\n]\n_SELECTION_MODES: Final[set[SelectionMode]] = {\n    \"single-row\",\n    \"multi-row\",\n    \"single-column\",\n    \"multi-column\",\n}\n\n\nclass DataframeSelectionState(TypedDict, total=False):\n    \"\"\"\n    The schema for the dataframe selection state.\n\n    The selection state is stored in a dictionary-like object that suports both\n    key and attribute notation. Selection states cannot be programmatically\n    changed or set through Session State.\n\n    .. warning::\n        If a user sorts a dataframe, row selections will be reset. If your\n        users need to sort and filter the dataframe to make selections, direct\n        them to use the search function in the dataframe toolbar instead.\n\n    Attributes\n    ----------\n    rows : list[int]\n        The selected rows, identified by their integer position. The integer\n        positions match the original dataframe, even if the user sorts the\n        dataframe in their browser. For a ``pandas.DataFrame``, you can\n        retrieve data from its interger position using methods like ``.iloc[]``\n        or ``.iat[]``.\n    columns : list[str]\n        The selected columns, identified by their names.\n\n    Example\n    -------\n    The following example has multi-row and multi-column selections enabled.\n    Try selecting some rows. To select multiple columns, hold ``Ctrl`` while\n    selecting columns. Hold ``Shift`` to select a range of columns.\n\n    >>> import streamlit as st\n    >>> import pandas as pd\n    >>> import numpy as np\n    >>>\n    >>> if \"df\" not in st.session_state:\n    >>>     st.session_state.df = pd.DataFrame(\n    ...         np.random.randn(12, 5), columns=[\"a\", \"b\", \"c\", \"d\", \"e\"]\n    ...     )\n    >>>\n    >>> event = st.dataframe(\n    ...     st.session_state.df,\n    ...     key=\"data\",\n    ...     on_select=\"rerun\",\n    ...     selection_mode=[\"multi-row\", \"multi-column\"],\n    ... )\n    >>>\n    >>> event.selection\n\n    .. output::\n        https://doc-dataframe-events-selection-state.streamlit.app\n        height: 600px\n\n    \"\"\"\n\n    rows: list[int]\n    columns: list[str]\n\n\nclass DataframeState(TypedDict, total=False):\n    \"\"\"\n    The schema for the dataframe event state.\n\n    The event state is stored in a dictionary-like object that suports both\n    key and attribute notation. Event states cannot be programmatically\n    changed or set through Session State.\n\n    Only selection events are supported at this time.\n\n    Attributes\n    ----------\n    selection : dict\n        The state of the ``on_select`` event. This attribure returns a\n        dictionary-like object that supports both key and attribute notation.\n        The attributes are described by the ``DataframeSelectionState``\n        dictionary schema.\n\n\n    \"\"\"\n\n    selection: DataframeSelectionState\n\n\n@dataclass\nclass DataframeSelectionSerde:\n    \"\"\"DataframeSelectionSerde is used to serialize and deserialize the dataframe selection state.\"\"\"\n\n    def deserialize(self, ui_value: str | None, widget_id: str = \"\") -> DataframeState:\n        empty_selection_state: DataframeState = {\n            \"selection\": {\n                \"rows\": [],\n                \"columns\": [],\n            },\n        }\n        selection_state: DataframeState = (\n            empty_selection_state if ui_value is None else json.loads(ui_value)\n        )\n\n        if \"selection\" not in selection_state:\n            selection_state = empty_selection_state\n\n        return cast(DataframeState, AttributeDictionary(selection_state))\n\n    def serialize(self, editing_state: DataframeState) -> str:\n        return json.dumps(editing_state, default=str)\n\n\ndef parse_selection_mode(\n    selection_mode: SelectionMode | Iterable[SelectionMode],\n) -> set[ArrowProto.SelectionMode.ValueType]:\n    \"\"\"Parse and check the user provided selection modes.\"\"\"\n    if isinstance(selection_mode, str):\n        # Only a single selection mode was passed\n        selection_mode_set = {selection_mode}\n    else:\n        # Multiple selection modes were passed\n        selection_mode_set = set(selection_mode)\n\n    if not selection_mode_set.issubset(_SELECTION_MODES):\n        raise StreamlitAPIException(\n            f\"Invalid selection mode: {selection_mode}. \"\n            f\"Valid options are: {_SELECTION_MODES}\"\n        )\n\n    if selection_mode_set.issuperset({\"single-row\", \"multi-row\"}):\n        raise StreamlitAPIException(\n            \"Only one of `single-row` or `multi-row` can be selected as selection mode.\"\n        )\n\n    if selection_mode_set.issuperset({\"single-column\", \"multi-column\"}):\n        raise StreamlitAPIException(\n            \"Only one of `single-column` or `multi-column` can be selected as selection mode.\"\n        )\n\n    parsed_selection_modes = []\n    for selection_mode in selection_mode_set:\n        if selection_mode == \"single-row\":\n            parsed_selection_modes.append(ArrowProto.SelectionMode.SINGLE_ROW)\n        elif selection_mode == \"multi-row\":\n            parsed_selection_modes.append(ArrowProto.SelectionMode.MULTI_ROW)\n        elif selection_mode == \"single-column\":\n            parsed_selection_modes.append(ArrowProto.SelectionMode.SINGLE_COLUMN)\n        elif selection_mode == \"multi-column\":\n            parsed_selection_modes.append(ArrowProto.SelectionMode.MULTI_COLUMN)\n    return set(parsed_selection_modes)\n\n\nclass ArrowMixin:\n    @overload\n    def dataframe(\n        self,\n        data: Data = None,\n        width: int | None = None,\n        height: int | None = None,\n        *,\n        use_container_width: bool = False,\n        hide_index: bool | None = None,\n        column_order: Iterable[str] | None = None,\n        column_config: ColumnConfigMappingInput | None = None,\n        key: Key | None = None,\n        on_select: Literal[\"ignore\"],  # No default value here to make it work with mypy\n        selection_mode: SelectionMode | Iterable[SelectionMode] = \"multi-row\",\n    ) -> DeltaGenerator: ...\n\n    @overload\n    def dataframe(\n        self,\n        data: Data = None,\n        width: int | None = None,\n        height: int | None = None,\n        *,\n        use_container_width: bool = False,\n        hide_index: bool | None = None,\n        column_order: Iterable[str] | None = None,\n        column_config: ColumnConfigMappingInput | None = None,\n        key: Key | None = None,\n        on_select: Literal[\"rerun\"] | WidgetCallback = \"rerun\",\n        selection_mode: SelectionMode | Iterable[SelectionMode] = \"multi-row\",\n    ) -> DataframeState: ...\n\n    @gather_metrics(\"dataframe\")\n    def dataframe(\n        self,\n        data: Data = None,\n        width: int | None = None,\n        height: int | None = None,\n        *,\n        use_container_width: bool = False,\n        hide_index: bool | None = None,\n        column_order: Iterable[str] | None = None,\n        column_config: ColumnConfigMappingInput | None = None,\n        key: Key | None = None,\n        on_select: Literal[\"ignore\", \"rerun\"] | WidgetCallback = \"ignore\",\n        selection_mode: SelectionMode | Iterable[SelectionMode] = \"multi-row\",\n    ) -> DeltaGenerator | DataframeState:\n        \"\"\"Display a dataframe as an interactive table.\n\n        This command works with dataframes from Pandas, PyArrow, Snowpark, and PySpark.\n        It can also display several other types that can be converted to dataframes,\n        e.g. numpy arrays, lists, sets and dictionaries.\n\n        Parameters\n        ----------\n        data : pandas.DataFrame, pandas.Series, pandas.Styler, pandas.Index, \\\n            pyarrow.Table, numpy.ndarray, pyspark.sql.DataFrame, snowflake.snowpark.dataframe.DataFrame, \\\n            snowflake.snowpark.table.Table, Iterable, dict, or None\n            The data to display.\n\n            If ``data`` is a ``pandas.Styler``, it will be used to style its\n            underlying ``pandas.DataFrame``. Streamlit supports custom cell\n            values and colors. It does not support some of the more exotic\n            pandas styling features, like bar charts, hovering, and captions.\n\n        width : int or None\n            Desired width of the dataframe expressed in pixels. If ``width`` is\n            ``None`` (default), Streamlit sets the dataframe width to fit its\n            contents up to the width of the parent container. If ``width`` is\n            greater than the width of the parent container, Streamlit sets the\n            dataframe width to match the width of the parent container.\n\n        height : int or None\n            Desired height of the dataframe expressed in pixels. If ``height``\n            is ``None`` (default), Streamlit sets the height to show at most\n            ten rows. Vertical scrolling within the dataframe element is\n            enabled when the height does not accomodate all rows.\n\n        use_container_width : bool\n            Whether to override ``width`` with the width of the parent\n            container. If ``use_container_width`` is ``False`` (default),\n            Streamlit sets the dataframe's width according to ``width``. If\n            ``use_container_width`` is ``True``, Streamlit sets the width of\n            the dataframe to match the width of the parent container.\n\n        hide_index : bool or None\n            Whether to hide the index column(s). If ``hide_index`` is ``None``\n            (default), the visibility of index columns is automatically\n            determined based on the data.\n\n        column_order : Iterable of str or None\n            The ordered list of columns to display. If ``column_order`` is\n            ``None`` (default), Streamlit displays all columns in the order\n            inherited from the underlying data structure. If ``column_order``\n            is a list, the indicated columns will display in the order they\n            appear within the list. Columns may be omitted or repeated within\n            the list.\n\n            For example, ``column_order=(\"col2\", \"col1\")`` will display\n            ``\"col2\"`` first, followed by ``\"col1\"``, and will hide all other\n            non-index columns.\n\n        column_config : dict or None\n            Configuration to customize how columns display. If ``column_config``\n            is ``None`` (default), columns are styled based on the underlying\n            data type of each column.\n\n            Column configuration can modify column names, visibility, type,\n            width, or format, among other things. ``column_config`` must be a\n            dictionary where each key is a column name and the associated value\n            is one of the following:\n\n            * ``None``: Streamlit hides the column.\n\n            * A string: Streamlit changes the display label of the column to\n              the given string.\n\n            * A column type within ``st.column_config``: Streamlit applies the\n              defined configuration to the column. For example, use\n              ``st.column_config.NumberColumn(\"Dollar values\u201d, format=\u201d$ %d\")``\n              to change the displayed name of the column to \"Dollar values\"\n              and add a \"$\" prefix in each cell. For more info on the\n              available column types and config options, see\n              `Column configuration <https://docs.streamlit.io/develop/api-reference/data/st.column_config>`_.\n\n            To configure the index column(s), use ``_index`` as the column name.\n\n        key : str\n            An optional string to use for giving this element a stable\n            identity. If ``key`` is ``None`` (default), this element's identity\n            will be determined based on the values of the other parameters.\n\n            Additionally, if selections are activated and ``key`` is provided,\n            Streamlit will register the key in Session State to store the\n            selection state. The selection state is read-only.\n\n        on_select : \"ignore\" or \"rerun\" or callable\n            How the dataframe should respond to user selection events. This\n            controls whether or not the dataframe behaves like an input widget.\n            ``on_select`` can be one of the following:\n\n            - ``\"ignore\"`` (default): Streamlit will not react to any selection\n              events in the dataframe. The dataframe will not behave like an\n              input widget.\n\n            - ``\"rerun\"``: Streamlit will rerun the app when the user selects\n              rows or columns in the dataframe. In this case, ``st.dataframe``\n              will return the selection data as a dictionary.\n\n            - A ``callable``: Streamlit will rerun the app and execute the\n              ``callable`` as a callback function before the rest of the app.\n              In this case, ``st.dataframe`` will return the selection data\n              as a dictionary.\n\n        selection_mode : \"single-row\", \"multi-row\", single-column\", \\\n            \"multi-column\", or Iterable of these\n            The types of selections Streamlit should allow. This can be one of\n            the following:\n\n            - \"multi-row\" (default): Multiple rows can be selected at a time.\n            - \"single-row\": Only one row can be selected at a time.\n            - \"multi-column\": Multiple columns can be selected at a time.\n            - \"single-column\": Only one column can be selected at a time.\n            - An ``Iterable`` of the above options: The table will allow\n              selection based on the modes specified.\n\n            When column selections are enabled, column sorting is disabled.\n\n        Returns\n        -------\n        element or dict\n            If ``on_select`` is ``\"ignore\"`` (default), this method returns an\n            internal placeholder for the dataframe element that can be used\n            with the ``.add_rows()`` method. Otherwise, this method returns a\n            dictionary-like object that supports both key and attribute\n            notation. The attributes are described by the ``DataframeState``\n            dictionary schema.\n\n        Examples\n        --------\n        >>> import streamlit as st\n        >>> import pandas as pd\n        >>> import numpy as np\n        >>>\n        >>> df = pd.DataFrame(np.random.randn(50, 20), columns=(\"col %d\" % i for i in range(20)))\n        >>>\n        >>> st.dataframe(df)  # Same as st.write(df)\n\n        .. output::\n           https://doc-dataframe.streamlit.app/\n           height: 500px\n\n        You can also pass a Pandas Styler object to change the style of\n        the rendered DataFrame:\n\n        >>> import streamlit as st\n        >>> import pandas as pd\n        >>> import numpy as np\n        >>>\n        >>> df = pd.DataFrame(np.random.randn(10, 20), columns=(\"col %d\" % i for i in range(20)))\n        >>>\n        >>> st.dataframe(df.style.highlight_max(axis=0))\n\n        .. output::\n           https://doc-dataframe1.streamlit.app/\n           height: 500px\n\n        Or you can customize the dataframe via ``column_config``, ``hide_index``, or ``column_order``:\n\n        >>> import random\n        >>> import pandas as pd\n        >>> import streamlit as st\n        >>>\n        >>> df = pd.DataFrame(\n        >>>     {\n        >>>         \"name\": [\"Roadmap\", \"Extras\", \"Issues\"],\n        >>>         \"url\": [\"https://roadmap.streamlit.app\", \"https://extras.streamlit.app\", \"https://issues.streamlit.app\"],\n        >>>         \"stars\": [random.randint(0, 1000) for _ in range(3)],\n        >>>         \"views_history\": [[random.randint(0, 5000) for _ in range(30)] for _ in range(3)],\n        >>>     }\n        >>> )\n        >>> st.dataframe(\n        >>>     df,\n        >>>     column_config={\n        >>>         \"name\": \"App name\",\n        >>>         \"stars\": st.column_config.NumberColumn(\n        >>>             \"Github Stars\",\n        >>>             help=\"Number of stars on GitHub\",\n        >>>             format=\"%d \u2b50\",\n        >>>         ),\n        >>>         \"url\": st.column_config.LinkColumn(\"App URL\"),\n        >>>         \"views_history\": st.column_config.LineChartColumn(\n        >>>             \"Views (past 30 days)\", y_min=0, y_max=5000\n        >>>         ),\n        >>>     },\n        >>>     hide_index=True,\n        >>> )\n\n        .. output::\n           https://doc-dataframe-config.streamlit.app/\n           height: 350px\n\n        \"\"\"\n        import pyarrow as pa\n\n        if on_select not in [\"ignore\", \"rerun\"] and not callable(on_select):\n            raise StreamlitAPIException(\n                f\"You have passed {on_select} to `on_select`. But only 'ignore', 'rerun', or a callable is supported.\"\n            )\n\n        key = to_key(key)\n        is_selection_activated = on_select != \"ignore\"\n\n        if is_selection_activated:\n            # Run some checks that are only relevant when selections are activated\n            check_cache_replay_rules()\n            if callable(on_select):\n                check_callback_rules(self.dg, on_select)\n            check_session_state_rules(default_value=None, key=key, writes_allowed=False)\n\n        # Convert the user provided column config into the frontend compatible format:\n        column_config_mapping = process_config_mapping(column_config)\n\n        proto = ArrowProto()\n        proto.use_container_width = use_container_width\n        if width:\n            proto.width = width\n        if height:\n            proto.height = height\n\n        if column_order:\n            proto.column_order[:] = column_order\n\n        proto.editing_mode = ArrowProto.EditingMode.READ_ONLY\n\n        if isinstance(data, pa.Table):\n            # For pyarrow tables, we can just serialize the table directly\n            proto.data = type_util.pyarrow_table_to_bytes(data)\n        else:\n            # For all other data formats, we need to convert them to a pandas.DataFrame\n            # thereby, we also apply some data specific configs\n\n            # Determine the input data format\n            data_format = type_util.determine_data_format(data)\n\n            if type_util.is_pandas_styler(data):\n                # If pandas.Styler uuid is not provided, a hash of the position\n                # of the element will be used. This will cause a rerender of the table\n                # when the position of the element is changed.\n                delta_path = self.dg._get_delta_path_str()\n                default_uuid = str(hash(delta_path))\n                marshall_styler(proto, data, default_uuid)\n\n            # Convert the input data into a pandas.DataFrame\n            data_df = type_util.convert_anything_to_df(data, ensure_copy=False)\n            apply_data_specific_configs(\n                column_config_mapping,\n                data_df,\n                data_format,\n                check_arrow_compatibility=False,\n            )\n            # Serialize the data to bytes:\n            proto.data = type_util.data_frame_to_bytes(data_df)\n\n        if hide_index is not None:\n            update_column_config(\n                column_config_mapping, INDEX_IDENTIFIER, {\"hidden\": hide_index}\n            )\n        marshall_column_config(proto, column_config_mapping)\n\n        if is_selection_activated:\n            # Import here to avoid circular imports\n            from streamlit.elements.form import current_form_id\n\n            # If selection events are activated, we need to register the dataframe\n            # element as a widget.\n            proto.selection_mode.extend(parse_selection_mode(selection_mode))\n            proto.form_id = current_form_id(self.dg)\n\n            ctx = get_script_run_ctx()\n            proto.id = compute_widget_id(\n                \"dataframe\",\n                user_key=key,\n                data=proto.data,\n                width=width,\n                height=height,\n                use_container_width=use_container_width,\n                column_order=proto.column_order,\n                column_config=proto.columns,\n                key=key,\n                selection_mode=selection_mode,\n                is_selection_activated=is_selection_activated,\n                form_id=proto.form_id,\n                page=ctx.page_script_hash if ctx else None,\n            )\n\n            serde = DataframeSelectionSerde()\n            widget_state = register_widget(\n                \"dataframe\",\n                proto,\n                user_key=key,\n                on_change_handler=on_select if callable(on_select) else None,\n                deserializer=serde.deserialize,\n                serializer=serde.serialize,\n                ctx=ctx,\n            )\n            self.dg._enqueue(\"arrow_data_frame\", proto)\n            return cast(DataframeState, widget_state.value)\n        else:\n            return self.dg._enqueue(\"arrow_data_frame\", proto)\n\n    @gather_metrics(\"table\")\n    def table(self, data: Data = None) -> DeltaGenerator:\n        \"\"\"Display a static table.\n\n        This differs from ``st.dataframe`` in that the table in this case is\n        static: its entire contents are laid out directly on the page.\n\n        Parameters\n        ----------\n        data : pandas.DataFrame, pandas.Styler, pyarrow.Table, numpy.ndarray, pyspark.sql.DataFrame, snowflake.snowpark.dataframe.DataFrame, snowflake.snowpark.table.Table, Iterable, dict, or None\n            The table data.\n\n        Example\n        -------\n        >>> import streamlit as st\n        >>> import pandas as pd\n        >>> import numpy as np\n        >>>\n        >>> df = pd.DataFrame(np.random.randn(10, 5), columns=(\"col %d\" % i for i in range(5)))\n        >>>\n        >>> st.table(df)\n\n        .. output::\n           https://doc-table.streamlit.app/\n           height: 480px\n\n        \"\"\"\n\n        # Check if data is uncollected, and collect it but with 100 rows max, instead of 10k rows, which is done in all other cases.\n        # Avoid this and use 100 rows in st.table, because large tables render slowly, take too much screen space, and can crush the app.\n        if type_util.is_unevaluated_data_object(data):\n            data = type_util.convert_anything_to_df(data, max_unevaluated_rows=100)\n\n        # If pandas.Styler uuid is not provided, a hash of the position\n        # of the element will be used. This will cause a rerender of the table\n        # when the position of the element is changed.\n        delta_path = self.dg._get_delta_path_str()\n        default_uuid = str(hash(delta_path))\n\n        proto = ArrowProto()\n        marshall(proto, data, default_uuid)\n        return self.dg._enqueue(\"arrow_table\", proto)\n\n    @gather_metrics(\"add_rows\")\n    def add_rows(self, data: Data = None, **kwargs) -> DeltaGenerator | None:\n        \"\"\"Concatenate a dataframe to the bottom of the current one.\n\n        Parameters\n        ----------\n        data : pandas.DataFrame, pandas.Styler, pyarrow.Table, numpy.ndarray, pyspark.sql.DataFrame, snowflake.snowpark.dataframe.DataFrame, Iterable, dict, or None\n            Table to concat. Optional.\n\n        **kwargs : pandas.DataFrame, numpy.ndarray, Iterable, dict, or None\n            The named dataset to concat. Optional. You can only pass in 1\n            dataset (including the one in the data parameter).\n\n        Example\n        -------\n        >>> import streamlit as st\n        >>> import pandas as pd\n        >>> import numpy as np\n        >>>\n        >>> df1 = pd.DataFrame(np.random.randn(50, 20), columns=(\"col %d\" % i for i in range(20)))\n        >>>\n        >>> my_table = st.table(df1)\n        >>>\n        >>> df2 = pd.DataFrame(np.random.randn(50, 20), columns=(\"col %d\" % i for i in range(20)))\n        >>>\n        >>> my_table.add_rows(df2)\n        >>> # Now the table shown in the Streamlit app contains the data for\n        >>> # df1 followed by the data for df2.\n\n        You can do the same thing with plots. For example, if you want to add\n        more data to a line chart:\n\n        >>> # Assuming df1 and df2 from the example above still exist...\n        >>> my_chart = st.line_chart(df1)\n        >>> my_chart.add_rows(df2)\n        >>> # Now the chart shown in the Streamlit app contains the data for\n        >>> # df1 followed by the data for df2.\n\n        And for plots whose datasets are named, you can pass the data with a\n        keyword argument where the key is the name:\n\n        >>> my_chart = st.vega_lite_chart({\n        ...     'mark': 'line',\n        ...     'encoding': {'x': 'a', 'y': 'b'},\n        ...     'datasets': {\n        ...       'some_fancy_name': df1,  # <-- named dataset\n        ...      },\n        ...     'data': {'name': 'some_fancy_name'},\n        ... }),\n        >>> my_chart.add_rows(some_fancy_name=df2)  # <-- name used as keyword\n\n        \"\"\"\n        return self.dg._arrow_add_rows(data, **kwargs)\n\n    @property\n    def dg(self) -> DeltaGenerator:\n        \"\"\"Get our DeltaGenerator.\"\"\"\n        return cast(\"DeltaGenerator\", self)\n\n\ndef marshall(proto: ArrowProto, data: Data, default_uuid: str | None = None) -> None:\n    \"\"\"Marshall pandas.DataFrame into an Arrow proto.\n\n    Parameters\n    ----------\n    proto : proto.Arrow\n        Output. The protobuf for Streamlit Arrow proto.\n\n    data : pandas.DataFrame, pandas.Styler, pyarrow.Table, numpy.ndarray, pyspark.sql.DataFrame, snowflake.snowpark.DataFrame, Iterable, dict, or None\n        Something that is or can be converted to a dataframe.\n\n    default_uuid : str | None\n        If pandas.Styler UUID is not provided, this value will be used.\n        This attribute is optional and only used for pandas.Styler, other elements\n        (e.g. charts) can ignore it.\n\n    \"\"\"\n    import pyarrow as pa\n\n    if type_util.is_pandas_styler(data):\n        # default_uuid is a string only if the data is a `Styler`,\n        # and `None` otherwise.\n        assert isinstance(\n            default_uuid, str\n        ), \"Default UUID must be a string for Styler data.\"\n        marshall_styler(proto, data, default_uuid)\n\n    if isinstance(data, pa.Table):\n        proto.data = type_util.pyarrow_table_to_bytes(data)\n    else:\n        df = type_util.convert_anything_to_df(data)\n        proto.data = type_util.data_frame_to_bytes(df)\n", "lib/streamlit/elements/form.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nfrom __future__ import annotations\n\nimport textwrap\nfrom typing import TYPE_CHECKING, Literal, NamedTuple, cast\n\nfrom streamlit import runtime\nfrom streamlit.errors import StreamlitAPIException\nfrom streamlit.proto import Block_pb2\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.runtime.scriptrunner import ScriptRunContext, get_script_run_ctx\n\nif TYPE_CHECKING:\n    from streamlit.delta_generator import DeltaGenerator\n    from streamlit.runtime.state import WidgetArgs, WidgetCallback, WidgetKwargs\n\n\nclass FormData(NamedTuple):\n    \"\"\"Form data stored on a DeltaGenerator.\"\"\"\n\n    # The form's unique ID.\n    form_id: str\n\n\ndef _current_form(this_dg: DeltaGenerator) -> FormData | None:\n    \"\"\"Find the FormData for the given DeltaGenerator.\n\n    Forms are blocks, and can have other blocks nested inside them.\n    To find the current form, we walk up the dg_stack until we find\n    a DeltaGenerator that has FormData.\n    \"\"\"\n    # Avoid circular imports.\n    from streamlit.delta_generator import dg_stack\n\n    if not runtime.exists():\n        return None\n\n    if this_dg._form_data is not None:\n        return this_dg._form_data\n\n    if this_dg == this_dg._main_dg:\n        # We were created via an `st.foo` call.\n        # Walk up the dg_stack to see if we're nested inside a `with st.form` statement.\n        for dg in reversed(dg_stack.get()):\n            if dg._form_data is not None:\n                return dg._form_data\n    else:\n        # We were created via an `dg.foo` call.\n        # Take a look at our parent's form data to see if we're nested inside a form.\n        parent = this_dg._parent\n        if parent is not None and parent._form_data is not None:\n            return parent._form_data\n\n    return None\n\n\ndef current_form_id(dg: DeltaGenerator) -> str:\n    \"\"\"Return the form_id for the current form, or the empty string if we're\n    not inside an `st.form` block.\n\n    (We return the empty string, instead of None, because this value is\n    assigned to protobuf message fields, and None is not valid.)\n    \"\"\"\n    form_data = _current_form(dg)\n    if form_data is None:\n        return \"\"\n    return form_data.form_id\n\n\ndef is_in_form(dg: DeltaGenerator) -> bool:\n    \"\"\"True if the DeltaGenerator is inside an st.form block.\"\"\"\n    return current_form_id(dg) != \"\"\n\n\ndef _build_duplicate_form_message(user_key: str | None = None) -> str:\n    if user_key is not None:\n        message = textwrap.dedent(\n            f\"\"\"\n            There are multiple identical forms with `key='{user_key}'`.\n\n            To fix this, please make sure that the `key` argument is unique for\n            each `st.form` you create.\n            \"\"\"\n        )\n    else:\n        message = textwrap.dedent(\n            \"\"\"\n            There are multiple identical forms with the same generated key.\n\n            When a form is created, it's assigned an internal key based on\n            its structure. Multiple forms with an identical structure will\n            result in the same internal key, which causes this error.\n\n            To fix this error, please pass a unique `key` argument to\n            `st.form`.\n            \"\"\"\n        )\n\n    return message.strip(\"\\n\")\n\n\nclass FormMixin:\n    @gather_metrics(\"form\")\n    def form(\n        self, key: str, clear_on_submit: bool = False, *, border: bool = True\n    ) -> DeltaGenerator:\n        \"\"\"Create a form that batches elements together with a \"Submit\" button.\n\n        A form is a container that visually groups other elements and\n        widgets together, and contains a Submit button. When the form's\n        Submit button is pressed, all widget values inside the form will be\n        sent to Streamlit in a batch.\n\n        To add elements to a form object, you can use ``with`` notation\n        (preferred) or just call methods directly on the form. See\n        examples below.\n\n        Forms have a few constraints:\n\n        * Every form must contain a ``st.form_submit_button``.\n        * ``st.button`` and ``st.download_button`` cannot be added to a form.\n        * Forms can appear anywhere in your app (sidebar, columns, etc),\n          but they cannot be embedded inside other forms.\n        * Within a form, the only widget that can have a callback function is\n          ``st.form_submit_button``.\n\n        Parameters\n        ----------\n        key : str\n            A string that identifies the form. Each form must have its own\n            key. (This key is not displayed to the user in the interface.)\n        clear_on_submit : bool\n            If True, all widgets inside the form will be reset to their default\n            values after the user presses the Submit button. Defaults to False.\n            (Note that Custom Components are unaffected by this flag, and\n            will not be reset to their defaults on form submission.)\n        border : bool\n            Whether to show a border around the form. Defaults to True.\n\n            .. note::\n                Not showing a border can be confusing to viewers since interacting with a\n                widget in the form will do nothing. You should only remove the border if\n                there's another border (e.g. because of an expander) or the form is small\n                (e.g. just a text input and a submit button).\n\n        Examples\n        --------\n        Inserting elements using ``with`` notation:\n\n        >>> import streamlit as st\n        >>>\n        >>> with st.form(\"my_form\"):\n        ...    st.write(\"Inside the form\")\n        ...    slider_val = st.slider(\"Form slider\")\n        ...    checkbox_val = st.checkbox(\"Form checkbox\")\n        ...\n        ...    # Every form must have a submit button.\n        ...    submitted = st.form_submit_button(\"Submit\")\n        ...    if submitted:\n        ...        st.write(\"slider\", slider_val, \"checkbox\", checkbox_val)\n        ...\n        >>> st.write(\"Outside the form\")\n\n        .. output::\n           https://doc-form1.streamlit.app/\n           height: 425px\n\n        Inserting elements out of order:\n\n        >>> import streamlit as st\n        >>>\n        >>> form = st.form(\"my_form\")\n        >>> form.slider(\"Inside the form\")\n        >>> st.slider(\"Outside the form\")\n        >>>\n        >>> # Now add a submit button to the form:\n        >>> form.form_submit_button(\"Submit\")\n\n        .. output::\n           https://doc-form2.streamlit.app/\n           height: 375px\n\n        \"\"\"\n        # Import this here to avoid circular imports.\n        from streamlit.elements.lib.policies import (\n            check_cache_replay_rules,\n            check_session_state_rules,\n        )\n\n        if is_in_form(self.dg):\n            raise StreamlitAPIException(\"Forms cannot be nested in other forms.\")\n\n        check_cache_replay_rules()\n        check_session_state_rules(default_value=None, key=key, writes_allowed=False)\n\n        # A form is uniquely identified by its key.\n        form_id = key\n\n        ctx = get_script_run_ctx()\n        if ctx is not None:\n            new_form_id = form_id not in ctx.form_ids_this_run\n            if new_form_id:\n                ctx.form_ids_this_run.add(form_id)\n            else:\n                raise StreamlitAPIException(_build_duplicate_form_message(key))\n\n        block_proto = Block_pb2.Block()\n        block_proto.form.form_id = form_id\n        block_proto.form.clear_on_submit = clear_on_submit\n        block_proto.form.border = border\n        block_dg = self.dg._block(block_proto)\n\n        # Attach the form's button info to the newly-created block's\n        # DeltaGenerator.\n        block_dg._form_data = FormData(form_id)\n        return block_dg\n\n    @gather_metrics(\"form_submit_button\")\n    def form_submit_button(\n        self,\n        label: str = \"Submit\",\n        help: str | None = None,\n        on_click: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        *,  # keyword-only arguments:\n        type: Literal[\"primary\", \"secondary\"] = \"secondary\",\n        disabled: bool = False,\n        use_container_width: bool = False,\n    ) -> bool:\n        \"\"\"Display a form submit button.\n\n        When this button is clicked, all widget values inside the form will be\n        sent to Streamlit in a batch.\n\n        Every form must have a form_submit_button. A form_submit_button\n        cannot exist outside a form.\n\n        For more information about forms, check out our\n        `blog post <https://blog.streamlit.io/introducing-submit-button-and-forms/>`_.\n\n        Parameters\n        ----------\n        label : str\n            A short label explaining to the user what this button is for.\n            Defaults to \"Submit\".\n        help : str or None\n            A tooltip that gets displayed when the button is hovered over.\n            Defaults to None.\n        on_click : callable\n            An optional callback invoked when this button is clicked.\n        args : tuple\n            An optional tuple of args to pass to the callback.\n        kwargs : dict\n            An optional dict of kwargs to pass to the callback.\n        type : \"secondary\" or \"primary\"\n            An optional string that specifies the button type. Can be \"primary\" for a\n            button with additional emphasis or \"secondary\" for a normal button. Defaults\n            to \"secondary\".\n        disabled : bool\n            An optional boolean, which disables the button if set to True. The\n            default is False.\n        use_container_width : bool\n            Whether to expand the button's width to fill its parent container.\n            If ``use_container_width`` is ``False`` (default), Streamlit sizes\n            the button to fit its contents. If ``use_container_width`` is\n            ``True``, the width of the button matches its parent container.\n\n            In both cases, if the contents of the button are wider than the\n            parent container, the contents will line wrap.\n\n        Returns\n        -------\n        bool\n            True if the button was clicked.\n        \"\"\"\n        ctx = get_script_run_ctx()\n\n        # Checks whether the entered button type is one of the allowed options - either \"primary\" or \"secondary\"\n        if type not in [\"primary\", \"secondary\"]:\n            raise StreamlitAPIException(\n                'The type argument to st.button must be \"primary\" or \"secondary\". \\n'\n                f'The argument passed was \"{type}\".'\n            )\n\n        return self._form_submit_button(\n            label=label,\n            help=help,\n            on_click=on_click,\n            args=args,\n            kwargs=kwargs,\n            type=type,\n            disabled=disabled,\n            use_container_width=use_container_width,\n            ctx=ctx,\n        )\n\n    def _form_submit_button(\n        self,\n        label: str = \"Submit\",\n        help: str | None = None,\n        on_click: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        *,  # keyword-only arguments:\n        type: Literal[\"primary\", \"secondary\"] = \"secondary\",\n        disabled: bool = False,\n        use_container_width: bool = False,\n        ctx: ScriptRunContext | None = None,\n    ) -> bool:\n        form_id = current_form_id(self.dg)\n        submit_button_key = f\"FormSubmitter:{form_id}-{label}\"\n        return self.dg._button(\n            label=label,\n            key=submit_button_key,\n            help=help,\n            is_form_submitter=True,\n            on_click=on_click,\n            args=args,\n            kwargs=kwargs,\n            type=type,\n            disabled=disabled,\n            use_container_width=use_container_width,\n            ctx=ctx,\n        )\n\n    @property\n    def dg(self) -> DeltaGenerator:\n        \"\"\"Get our DeltaGenerator.\"\"\"\n        return cast(\"DeltaGenerator\", self)\n", "lib/streamlit/elements/progress.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport math\nfrom typing import TYPE_CHECKING, Union, cast\n\nfrom typing_extensions import TypeAlias\n\nfrom streamlit.errors import StreamlitAPIException\nfrom streamlit.proto.Progress_pb2 import Progress as ProgressProto\nfrom streamlit.string_util import clean_text\n\nif TYPE_CHECKING:\n    from streamlit.delta_generator import DeltaGenerator\n\n\n# Currently, equates to just float, but we can't use `numbers.Real` due to\n# https://github.com/python/mypy/issues/3186\nFloatOrInt: TypeAlias = Union[int, float]\n\n\ndef _check_float_between(value: float, low: float = 0.0, high: float = 1.0) -> bool:\n    \"\"\"\n    Checks given value is 'between' the bounds of [low, high],\n    considering close values around bounds are acceptable input\n\n    Notes\n    -----\n    This check is required for handling values that are slightly above or below the\n    acceptable range, for example -0.0000000000021, 1.0000000000000013.\n    These values are little off the conventional 0.0 <= x <= 1.0 condition\n    due to floating point operations, but should still be considered acceptable input.\n\n    Parameters\n    ----------\n    value : float\n    low : float\n    high : float\n\n    \"\"\"\n    return (\n        (low <= value <= high)\n        or math.isclose(value, low, rel_tol=1e-9, abs_tol=1e-9)\n        or math.isclose(value, high, rel_tol=1e-9, abs_tol=1e-9)\n    )\n\n\ndef _get_value(value):\n    if isinstance(value, int):\n        if 0 <= value <= 100:\n            return value\n        else:\n            raise StreamlitAPIException(\n                \"Progress Value has invalid value [0, 100]: %d\" % value\n            )\n\n    elif isinstance(value, float):\n        if _check_float_between(value, low=0.0, high=1.0):\n            return int(value * 100)\n        else:\n            raise StreamlitAPIException(\n                \"Progress Value has invalid value [0.0, 1.0]: %f\" % value\n            )\n    else:\n        raise StreamlitAPIException(\n            \"Progress Value has invalid type: %s\" % type(value).__name__\n        )\n\n\ndef _get_text(text: str | None) -> str | None:\n    if text is None:\n        return None\n    if isinstance(text, str):\n        return clean_text(text)\n    raise StreamlitAPIException(\n        f\"Progress Text is of type {str(type(text))}, which is not an accepted type.\"\n        \"Text only accepts: str. Please convert the text to an accepted type.\"\n    )\n\n\nclass ProgressMixin:\n    def progress(self, value: FloatOrInt, text: str | None = None) -> DeltaGenerator:\n        r\"\"\"Display a progress bar.\n\n        Parameters\n        ----------\n        value : int or float\n            0 <= value <= 100 for int\n\n            0.0 <= value <= 1.0 for float\n\n        text : str or None\n            A message to display above the progress bar. The text can optionally\n            contain Markdown and supports the following elements: Bold, Italics,\n            Strikethroughs, Inline Code, Emojis, and Links.\n\n            This also supports:\n\n            * Emoji shortcodes, such as ``:+1:``  and ``:sunglasses:``.\n              For a list of all supported codes,\n              see https://share.streamlit.io/streamlit/emoji-shortcodes.\n\n            * LaTeX expressions, by wrapping them in \"$\" or \"$$\" (the \"$$\"\n              must be on their own lines). Supported LaTeX functions are listed\n              at https://katex.org/docs/supported.html.\n\n            * Colored text and background colors for text, using the syntax\n              ``:color[text to be colored]`` and ``:color-background[text to be colored]``,\n              respectively. ``color`` must be replaced with any of the following\n              supported colors: blue, green, orange, red, violet, gray/grey, rainbow.\n              For example, you can use ``:orange[your text here]`` or\n              ``:blue-background[your text here]``.\n\n            Unsupported elements are unwrapped so only their children (text contents) render.\n            Display unsupported elements as literal characters by\n            backslash-escaping them. E.g. ``1\\. Not an ordered list``.\n\n        Example\n        -------\n        Here is an example of a progress bar increasing over time and disappearing when it reaches completion:\n\n        >>> import streamlit as st\n        >>> import time\n        >>>\n        >>> progress_text = \"Operation in progress. Please wait.\"\n        >>> my_bar = st.progress(0, text=progress_text)\n        >>>\n        >>> for percent_complete in range(100):\n        ...     time.sleep(0.01)\n        ...     my_bar.progress(percent_complete + 1, text=progress_text)\n        >>> time.sleep(1)\n        >>> my_bar.empty()\n        >>>\n        >>> st.button(\"Rerun\")\n\n        .. output::\n           https://doc-status-progress.streamlit.app/\n           height: 220px\n\n        \"\"\"\n        # TODO: standardize numerical type checking across st.* functions.\n        progress_proto = ProgressProto()\n        progress_proto.value = _get_value(value)\n        text = _get_text(text)\n        if text is not None:\n            progress_proto.text = text\n        return self.dg._enqueue(\"progress\", progress_proto)\n\n    @property\n    def dg(self) -> DeltaGenerator:\n        \"\"\"Get our DeltaGenerator.\"\"\"\n        return cast(\"DeltaGenerator\", self)\n", "lib/streamlit/elements/toast.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom typing import TYPE_CHECKING, cast\n\nfrom streamlit.errors import StreamlitAPIException\nfrom streamlit.proto.Toast_pb2 import Toast as ToastProto\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.string_util import clean_text, validate_icon_or_emoji\n\nif TYPE_CHECKING:\n    from streamlit.delta_generator import DeltaGenerator\n    from streamlit.type_util import SupportsStr\n\n\ndef validate_text(toast_text: SupportsStr) -> SupportsStr:\n    if str(toast_text) == \"\":\n        raise StreamlitAPIException(\n            \"Toast body cannot be blank - please provide a message.\"\n        )\n    else:\n        return toast_text\n\n\nclass ToastMixin:\n    @gather_metrics(\"toast\")\n    def toast(\n        self,\n        body: SupportsStr,\n        *,  # keyword-only args:\n        icon: str | None = None,\n    ) -> DeltaGenerator:\n        \"\"\"Display a short message, known as a notification \"toast\".\n        The toast appears in the app's bottom-right corner and disappears after four seconds.\n\n        .. warning::\n            ``st.toast`` is not compatible with Streamlit's `caching \\\n            <https://docs.streamlit.io/develop/concepts/architecture/caching>`_ and\n            cannot be called within a cached function.\n\n        Parameters\n        ----------\n        body : str\n            The string to display as Github-flavored Markdown. Syntax\n            information can be found at: https://github.github.com/gfm.\n\n            This also supports:\n\n            * Emoji shortcodes, such as ``:+1:``  and ``:sunglasses:``.\n              For a list of all supported codes,\n              see https://share.streamlit.io/streamlit/emoji-shortcodes.\n\n            * LaTeX expressions, by wrapping them in \"$\" or \"$$\" (the \"$$\"\n              must be on their own lines). Supported LaTeX functions are listed\n              at https://katex.org/docs/supported.html.\n\n            * Colored text and background colors for text, using the syntax\n              ``:color[text to be colored]`` and ``:color-background[text to be colored]``,\n              respectively. ``color`` must be replaced with any of the following\n              supported colors: blue, green, orange, red, violet, gray/grey, rainbow.\n              For example, you can use ``:orange[your text here]`` or\n              ``:blue-background[your text here]``.\n\n        icon : str, None\n            An optional emoji or icon to display next to the alert. If ``icon``\n            is ``None`` (default), no icon is displayed. If ``icon`` is a\n            string, the following options are valid:\n\n            * A single-character emoji. For example, you can set ``icon=\"\ud83d\udea8\"``\n              or ``icon=\"\ud83d\udd25\"``. Emoji short codes are not supported.\n\n            * An icon from the Material Symbols library (outlined style) in the\n              format ``\":material/icon_name:\"`` where \"icon_name\" is the name\n              of the icon in snake case.\n\n              For example, ``icon=\":material/thumb_up:\"`` will display the\n              Thumb Up icon. Find additional icons in the `Material Symbols \\\n              <https://fonts.google.com/icons?icon.set=Material+Symbols&icon.style=Outlined>`_\n              font library.\n\n        Example\n        -------\n        >>> import streamlit as st\n        >>>\n        >>> st.toast('Your edited image was saved!', icon='\ud83d\ude0d')\n        \"\"\"\n        toast_proto = ToastProto()\n        toast_proto.body = clean_text(validate_text(body))\n        toast_proto.icon = validate_icon_or_emoji(icon)\n        return self.dg._enqueue(\"toast\", toast_proto)\n\n    @property\n    def dg(self) -> DeltaGenerator:\n        \"\"\"Get our DeltaGenerator.\"\"\"\n        return cast(\"DeltaGenerator\", self)\n", "lib/streamlit/elements/spinner.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport contextlib\nimport threading\nfrom typing import Iterator\n\nimport streamlit as st\nfrom streamlit.runtime.scriptrunner import add_script_run_ctx\n\n\n@contextlib.contextmanager\ndef spinner(text: str = \"In progress...\", *, _cache: bool = False) -> Iterator[None]:\n    \"\"\"Temporarily displays a message while executing a block of code.\n\n    Parameters\n    ----------\n    text : str\n        A message to display while executing that block\n\n    Example\n    -------\n\n    >>> import time\n    >>> import streamlit as st\n    >>>\n    >>> with st.spinner('Wait for it...'):\n    >>>     time.sleep(5)\n    >>> st.success('Done!')\n\n    \"\"\"\n    from streamlit.proto.Spinner_pb2 import Spinner as SpinnerProto\n    from streamlit.string_util import clean_text\n\n    message = st.empty()\n\n    # Set the message 0.5 seconds in the future to avoid annoying\n    # flickering if this spinner runs too quickly.\n    DELAY_SECS = 0.5\n    display_message = True\n    display_message_lock = threading.Lock()\n\n    try:\n\n        def set_message():\n            with display_message_lock:\n                if display_message:\n                    spinner_proto = SpinnerProto()\n                    spinner_proto.text = clean_text(text)\n                    spinner_proto.cache = _cache\n                    message._enqueue(\"spinner\", spinner_proto)\n\n        add_script_run_ctx(threading.Timer(DELAY_SECS, set_message)).start()\n\n        # Yield control back to the context.\n        yield\n    finally:\n        if display_message_lock:\n            with display_message_lock:\n                display_message = False\n            if \"chat_message\" in set(message._active_dg._ancestor_block_types):\n                # Temporary stale element fix:\n                # For chat messages, we are resetting the spinner placeholder to an\n                # empty container instead of an empty placeholder (st.empty) to have\n                # it removed from the delta path. Empty containers are ignored in the\n                # frontend since they are configured with allow_empty=False. This\n                # prevents issues with stale elements caused by the spinner being\n                # rendered only in some situations (e.g. for caching).\n                message.container()\n            else:\n                message.empty()\n", "lib/streamlit/elements/snow.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom typing import TYPE_CHECKING, cast\n\nfrom streamlit.proto.Snow_pb2 import Snow as SnowProto\nfrom streamlit.runtime.metrics_util import gather_metrics\n\nif TYPE_CHECKING:\n    from streamlit.delta_generator import DeltaGenerator\n\n\nclass SnowMixin:\n    @gather_metrics(\"snow\")\n    def snow(self) -> DeltaGenerator:\n        \"\"\"Draw celebratory snowfall.\n\n        Example\n        -------\n        >>> import streamlit as st\n        >>>\n        >>> st.snow()\n\n        ...then watch your app and get ready for a cool celebration!\n\n        \"\"\"\n        snow_proto = SnowProto()\n        snow_proto.show = True\n        return self.dg._enqueue(\"snow\", snow_proto)\n\n    @property\n    def dg(self) -> DeltaGenerator:\n        \"\"\"Get our DeltaGenerator.\"\"\"\n        return cast(\"DeltaGenerator\", self)\n", "lib/streamlit/elements/alert.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom typing import TYPE_CHECKING, cast\n\nfrom streamlit.proto.Alert_pb2 import Alert as AlertProto\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.string_util import clean_text, validate_icon_or_emoji\n\nif TYPE_CHECKING:\n    from streamlit.delta_generator import DeltaGenerator\n    from streamlit.type_util import SupportsStr\n\n\nclass AlertMixin:\n    @gather_metrics(\"error\")\n    def error(\n        self,\n        body: SupportsStr,\n        *,  # keyword-only args:\n        icon: str | None = None,\n    ) -> DeltaGenerator:\n        \"\"\"Display error message.\n\n        Parameters\n        ----------\n        body : str\n            The error text to display.\n        icon : str, None\n            An optional emoji or icon to display next to the alert. If ``icon``\n            is ``None`` (default), no icon is displayed. If ``icon`` is a\n            string, the following options are valid:\n\n            * A single-character emoji. For example, you can set ``icon=\"\ud83d\udea8\"``\n              or ``icon=\"\ud83d\udd25\"``. Emoji short codes are not supported.\n\n            * An icon from the Material Symbols library (outlined style) in the\n              format ``\":material/icon_name:\"`` where \"icon_name\" is the name\n              of the icon in snake case.\n\n              For example, ``icon=\":material/thumb_up:\"`` will display the\n              Thumb Up icon. Find additional icons in the `Material Symbols \\\n              <https://fonts.google.com/icons?icon.set=Material+Symbols&icon.style=Outlined>`_\n              font library.\n\n        Example\n        -------\n        >>> import streamlit as st\n        >>>\n        >>> st.error('This is an error', icon=\"\ud83d\udea8\")\n\n        \"\"\"\n        alert_proto = AlertProto()\n\n        alert_proto.icon = validate_icon_or_emoji(icon)\n        alert_proto.body = clean_text(body)\n        alert_proto.format = AlertProto.ERROR\n        return self.dg._enqueue(\"alert\", alert_proto)\n\n    @gather_metrics(\"warning\")\n    def warning(\n        self,\n        body: SupportsStr,\n        *,  # keyword-only args:\n        icon: str | None = None,\n    ) -> DeltaGenerator:\n        \"\"\"Display warning message.\n\n        Parameters\n        ----------\n        body : str\n            The warning text to display.\n        icon : str, None\n            An optional emoji or icon to display next to the alert. If ``icon``\n            is ``None`` (default), no icon is displayed. If ``icon`` is a\n            string, the following options are valid:\n\n            * A single-character emoji. For example, you can set ``icon=\"\ud83d\udea8\"``\n              or ``icon=\"\ud83d\udd25\"``. Emoji short codes are not supported.\n\n            * An icon from the Material Symbols library (outlined style) in the\n              format ``\":material/icon_name:\"`` where \"icon_name\" is the name\n              of the icon in snake case.\n\n              For example, ``icon=\":material/thumb_up:\"`` will display the\n              Thumb Up icon. Find additional icons in the `Material Symbols \\\n              <https://fonts.google.com/icons?icon.set=Material+Symbols&icon.style=Outlined>`_\n              font library.\n\n        Example\n        -------\n        >>> import streamlit as st\n        >>>\n        >>> st.warning('This is a warning', icon=\"\u26a0\ufe0f\")\n\n        \"\"\"\n        alert_proto = AlertProto()\n        alert_proto.body = clean_text(body)\n        alert_proto.icon = validate_icon_or_emoji(icon)\n        alert_proto.format = AlertProto.WARNING\n        return self.dg._enqueue(\"alert\", alert_proto)\n\n    @gather_metrics(\"info\")\n    def info(\n        self,\n        body: SupportsStr,\n        *,  # keyword-only args:\n        icon: str | None = None,\n    ) -> DeltaGenerator:\n        \"\"\"Display an informational message.\n\n        Parameters\n        ----------\n        body : str\n            The info text to display.\n        icon : str, None\n            An optional emoji or icon to display next to the alert. If ``icon``\n            is ``None`` (default), no icon is displayed. If ``icon`` is a\n            string, the following options are valid:\n\n            * A single-character emoji. For example, you can set ``icon=\"\ud83d\udea8\"``\n              or ``icon=\"\ud83d\udd25\"``. Emoji short codes are not supported.\n\n            * An icon from the Material Symbols library (outlined style) in the\n              format ``\":material/icon_name:\"`` where \"icon_name\" is the name\n              of the icon in snake case.\n\n              For example, ``icon=\":material/thumb_up:\"`` will display the\n              Thumb Up icon. Find additional icons in the `Material Symbols \\\n              <https://fonts.google.com/icons?icon.set=Material+Symbols&icon.style=Outlined>`_\n              font library.\n\n        Example\n        -------\n        >>> import streamlit as st\n        >>>\n        >>> st.info('This is a purely informational message', icon=\"\u2139\ufe0f\")\n\n        \"\"\"\n\n        alert_proto = AlertProto()\n        alert_proto.body = clean_text(body)\n        alert_proto.icon = validate_icon_or_emoji(icon)\n        alert_proto.format = AlertProto.INFO\n        return self.dg._enqueue(\"alert\", alert_proto)\n\n    @gather_metrics(\"success\")\n    def success(\n        self,\n        body: SupportsStr,\n        *,  # keyword-only args:\n        icon: str | None = None,\n    ) -> DeltaGenerator:\n        \"\"\"Display a success message.\n\n        Parameters\n        ----------\n        body : str\n            The success text to display.\n        icon : str, None\n            An optional emoji or icon to display next to the alert. If ``icon``\n            is ``None`` (default), no icon is displayed. If ``icon`` is a\n            string, the following options are valid:\n\n            * A single-character emoji. For example, you can set ``icon=\"\ud83d\udea8\"``\n              or ``icon=\"\ud83d\udd25\"``. Emoji short codes are not supported.\n\n            * An icon from the Material Symbols library (outlined style) in the\n              format ``\":material/icon_name:\"`` where \"icon_name\" is the name\n              of the icon in snake case.\n\n              For example, ``icon=\":material/thumb_up:\"`` will display the\n              Thumb Up icon. Find additional icons in the `Material Symbols \\\n              <https://fonts.google.com/icons?icon.set=Material+Symbols&icon.style=Outlined>`_\n              font library.\n\n        Example\n        -------\n        >>> import streamlit as st\n        >>>\n        >>> st.success('This is a success message!', icon=\"\u2705\")\n\n        \"\"\"\n        alert_proto = AlertProto()\n        alert_proto.body = clean_text(body)\n        alert_proto.icon = validate_icon_or_emoji(icon)\n        alert_proto.format = AlertProto.SUCCESS\n        return self.dg._enqueue(\"alert\", alert_proto)\n\n    @property\n    def dg(self) -> DeltaGenerator:\n        \"\"\"Get our DeltaGenerator.\"\"\"\n        return cast(\"DeltaGenerator\", self)\n", "lib/streamlit/elements/dialog_decorator.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom functools import wraps\nfrom typing import TYPE_CHECKING, Callable, TypeVar, cast, overload\n\nfrom streamlit.delta_generator import event_dg, get_last_dg_added_to_context_stack\nfrom streamlit.errors import StreamlitAPIException\nfrom streamlit.runtime.fragment import _fragment\nfrom streamlit.runtime.metrics_util import gather_metrics\n\nif TYPE_CHECKING:\n    from streamlit.elements.lib.dialog import DialogWidth\n\n\ndef _assert_no_nested_dialogs() -> None:\n    \"\"\"Check the current stack for existing DeltaGenerator's of type 'dialog'.\n    Note that the check like this only works when Dialog is called as a context manager, as this populates the dg_stack in delta_generator correctly.\n\n    This does not detect the edge case in which someone calls, for example, `with st.sidebar` inside of a dialog function and opens a dialog in there,\n    as `with st.sidebar` pushes the new DeltaGenerator to the stack. In order to check for that edge case, we could try to check all DeltaGenerators in the stack,\n    and not only the last one. Since we deem this to be an edge case, we lean towards simplicity here.\n\n    Raises\n    ------\n    StreamlitAPIException\n        Raised if the user tries to nest dialogs inside of each other.\n    \"\"\"\n    last_dg_in_current_context = get_last_dg_added_to_context_stack()\n    if last_dg_in_current_context and \"dialog\" in set(\n        last_dg_in_current_context._ancestor_block_types\n    ):\n        raise StreamlitAPIException(\"Dialogs may not be nested inside other dialogs.\")\n\n\nF = TypeVar(\"F\", bound=Callable[..., None])\n\n\ndef _dialog_decorator(\n    non_optional_func: F, title: str, *, width: DialogWidth = \"small\"\n) -> F:\n    if title is None or title == \"\":\n        raise StreamlitAPIException(\n            'A non-empty `title` argument has to be provided for dialogs, for example `@st.experimental_dialog(\"Example Title\")`.'\n        )\n\n    @wraps(non_optional_func)\n    def wrap(*args, **kwargs) -> None:\n        _assert_no_nested_dialogs()\n        # Call the Dialog on the event_dg because it lives outside of the normal\n        # Streamlit UI flow. For example, if it is called from the sidebar, it should not\n        # inherit the sidebar theming.\n        dialog = event_dg._dialog(title=title, dismissible=True, width=width)\n        dialog.open()\n\n        def dialog_content() -> None:\n            # if the dialog should be closed, st.rerun() has to be called (same behavior as with st.fragment)\n            _ = non_optional_func(*args, **kwargs)\n            return None\n\n        # the fragment decorator has multiple return types so that you can pass arguments to it. Here we know the return type, so we cast\n        fragmented_dialog_content = cast(Callable[[], None], _fragment(dialog_content))\n        with dialog:\n            fragmented_dialog_content()\n            return None\n\n    return cast(F, wrap)\n\n\n@overload\ndef dialog_decorator(\n    title: str, *, width: DialogWidth = \"small\"\n) -> Callable[[F], F]: ...\n\n\n# 'title' can be a function since `dialog_decorator` is a decorator. We just call it 'title' here though\n# to make the user-doc more friendly as we want the user to pass a title, not a function.\n# The user is supposed to call it like @st.dialog(\"my_title\") , which makes 'title' a positional arg, hence\n# this 'trick'. The overload is required to have a good type hint for the decorated function args.\n@overload\ndef dialog_decorator(title: F, *, width: DialogWidth = \"small\") -> F: ...\n\n\n@gather_metrics(\"experimental_dialog\")\ndef dialog_decorator(\n    title: F | str, *, width: DialogWidth = \"small\"\n) -> F | Callable[[F], F]:\n    \"\"\"Function decorator to create a modal dialog.\n\n    A function decorated with ``@st.experimental_dialog`` becomes a dialog\n    function. When you call a dialog function, Streamlit inserts a modal dialog\n    into your app. Streamlit element commands called within the dialog function\n    render inside the modal dialog.\n\n    The dialog function can accept arguments that can be passed when it is\n    called. Any values from the dialog that need to be accessed from the wider\n    app should generally be stored in Session State.\n\n    A user can dismiss a modal dialog by clicking outside of it, clicking the\n    \"**X**\" in its upper-right corner, or pressing``ESC`` on their keyboard.\n    Dismissing a modal dialog does not trigger an app rerun. To close the modal\n    dialog programmatically, call ``st.rerun()`` explicitly inside of the\n    dialog function.\n\n    ``st.experimental_dialog`` inherits behavior from |st.experimental_fragment|_.\n    When a user interacts with an input widget created inside a dialog function,\n    Streamlit only reruns the dialog function instead of the full script.\n\n    Calling ``st.sidebar`` in a dialog function is not supported.\n\n    Dialog code can interact with Session State, imported modules, and other\n    Streamlit elements created outside the dialog. Note that these interactions\n    are additive across multiple dialog reruns. You are responsible for\n    handling any side effects of that behavior.\n\n    .. warning::\n        Only one dialog function may be called in a script run, which means\n        that only one dialog can be open at any given time. Since a dialog is\n        also a fragment, all fragment limitations apply. Dialogs can't contain\n        fragments, and fragments can't contain dialogs. Using dialogs in widget\n        callback functions is not supported.\n\n    .. |st.experimental_fragment| replace:: ``st.experimental_fragment``\n    .. _st.experimental_fragment: https://docs.streamlit.io/develop/api-reference/execution-flow/st.fragment\n\n    Parameters\n    ----------\n    title : str\n        The title to display at the top of the modal dialog. It cannot be empty.\n    width : \"small\", \"large\"\n        The width of the modal dialog. If ``width`` is ``\"small`` (default), the\n        modal dialog will be 500 pixels wide. If ``width`` is ``\"large\"``, the\n        modal dialog will be about 750 pixels wide.\n\n    Examples\n    --------\n    The following example demonstrates the basic usage of ``@st.experimental_dialog``.\n    In this app, clicking \"**A**\" or \"**B**\" will open a modal dialog and prompt you\n    to enter a reason for your vote. In the modal dialog, click \"**Submit**\" to record\n    your vote into Session State and rerun the app. This will close the modal dialog\n    since the dialog function is not called during the full-script rerun.\n\n    >>> import streamlit as st\n    >>>\n    >>> @st.experimental_dialog(\"Cast your vote\")\n    >>> def vote(item):\n    >>>     st.write(f\"Why is {item} your favorite?\")\n    >>>     reason = st.text_input(\"Because...\")\n    >>>     if st.button(\"Submit\"):\n    >>>         st.session_state.vote = {\"item\": item, \"reason\": reason}\n    >>>         st.rerun()\n    >>>\n    >>> if \"vote\" not in st.session_state:\n    >>>     st.write(\"Vote for your favorite\")\n    >>>     if st.button(\"A\"):\n    >>>         vote(\"A\")\n    >>>     if st.button(\"B\"):\n    >>>         vote(\"B\")\n    >>> else:\n    >>>     f\"You voted for {st.session_state.vote['item']} because {st.session_state.vote['reason']}\"\n\n    .. output::\n        https://doc-modal-dialog.streamlit.app/\n        height: 350px\n\n    \"\"\"\n\n    func_or_title = title\n    if isinstance(func_or_title, str):\n        # Support passing the params via function decorator\n        def wrapper(f: F) -> F:\n            title: str = func_or_title\n            return _dialog_decorator(non_optional_func=f, title=title, width=width)\n\n        return wrapper\n\n    func: F = func_or_title\n    return _dialog_decorator(func, \"\", width=width)\n", "lib/streamlit/elements/write.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport dataclasses\nimport inspect\nimport json\nimport types\nfrom io import StringIO\nfrom typing import TYPE_CHECKING, Any, Callable, Final, Generator, Iterable, List, cast\n\nfrom streamlit import type_util\nfrom streamlit.errors import StreamlitAPIException\nfrom streamlit.logger import get_logger\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.runtime.state import QueryParamsProxy, SessionStateProxy\nfrom streamlit.string_util import (\n    is_mem_address_str,\n    max_char_sequence,\n    probably_contains_html_tags,\n)\nfrom streamlit.user_info import UserInfoProxy\n\nif TYPE_CHECKING:\n    from streamlit.delta_generator import DeltaGenerator\n\n\n# Special methods:\nHELP_TYPES: Final[tuple[type[Any], ...]] = (\n    types.BuiltinFunctionType,\n    types.BuiltinMethodType,\n    types.FunctionType,\n    types.MethodType,\n    types.ModuleType,\n)\n\n_LOGGER: Final = get_logger(__name__)\n\n_TEXT_CURSOR: Final = \"\u2595\"\n\n\nclass StreamingOutput(List[Any]):\n    pass\n\n\nclass WriteMixin:\n    @gather_metrics(\"write_stream\")\n    def write_stream(\n        self, stream: Callable[..., Any] | Generator[Any, Any, Any] | Iterable[Any]\n    ) -> list[Any] | str:\n        \"\"\"Stream a generator, iterable, or stream-like sequence to the app.\n\n        ``st.write_stream`` iterates through the given sequences and writes all\n        chunks to the app. String chunks will be written using a typewriter effect.\n        Other data types will be written using ``st.write``.\n\n        Parameters\n        ----------\n        stream : Callable, Generator, Iterable, OpenAI Stream, or LangChain Stream\n            The generator or iterable to stream.\n\n            .. note::\n                To use additional LLM libraries, you can create a wrapper to\n                manually define a generator function and include custom output\n                parsing.\n\n        Returns\n        -------\n        str or list\n            The full response. If the streamed output only contains text, this\n            is a string. Otherwise, this is a list of all the streamed objects.\n            The return value is fully compatible as input for ``st.write``.\n\n        Example\n        -------\n        You can pass an OpenAI stream as shown in our tutorial, `Build a \\\n        basic LLM chat app <https://docs.streamlit.io/develop/tutorials/llms\\\n        /build-conversational-apps#build-a-chatgpt-like-app>`_. Alternatively,\n        you can pass a generic generator function as input:\n\n        >>> import time\n        >>> import numpy as np\n        >>> import pandas as pd\n        >>> import streamlit as st\n        >>>\n        >>> _LOREM_IPSUM = \\\"\\\"\\\"\n        >>> Lorem ipsum dolor sit amet, **consectetur adipiscing** elit, sed do eiusmod tempor\n        >>> incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis\n        >>> nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.\n        >>> \\\"\\\"\\\"\n        >>>\n        >>>\n        >>> def stream_data():\n        >>>     for word in _LOREM_IPSUM.split(\" \"):\n        >>>         yield word + \" \"\n        >>>         time.sleep(0.02)\n        >>>\n        >>>     yield pd.DataFrame(\n        >>>         np.random.randn(5, 10),\n        >>>         columns=[\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\"],\n        >>>     )\n        >>>\n        >>>     for word in _LOREM_IPSUM.split(\" \"):\n        >>>         yield word + \" \"\n        >>>         time.sleep(0.02)\n        >>>\n        >>>\n        >>> if st.button(\"Stream data\"):\n        >>>     st.write_stream(stream_data)\n\n        ..  output::\n            https://doc-write-stream-data.streamlit.app/\n            height: 550px\n\n        \"\"\"\n\n        # Just apply some basic checks for common iterable types that should\n        # not be passed in here.\n        if isinstance(stream, str) or type_util.is_dataframe_like(stream):\n            raise StreamlitAPIException(\n                \"`st.write_stream` expects a generator or stream-like object as input \"\n                f\"not {type(stream)}. Please use `st.write` instead for \"\n                \"this data type.\"\n            )\n\n        stream_container: DeltaGenerator | None = None\n        streamed_response: str = \"\"\n        written_content: list[Any] = StreamingOutput()\n\n        def flush_stream_response():\n            \"\"\"Write the full response to the app.\"\"\"\n            nonlocal streamed_response\n            nonlocal stream_container\n\n            if streamed_response and stream_container:\n                # Replace the stream_container element the full response\n                stream_container.markdown(streamed_response)\n                written_content.append(streamed_response)\n                stream_container = None\n                streamed_response = \"\"\n\n        # Make sure we have a generator and not just a generator function.\n        stream = stream() if inspect.isgeneratorfunction(stream) else stream\n\n        try:\n            iter(stream)  # type: ignore\n        except TypeError as exc:\n            raise StreamlitAPIException(\n                f\"The provided input (type: {type(stream)}) cannot be iterated. \"\n                \"Please make sure that it is a generator, generator function or iterable.\"\n            ) from exc\n\n        # Iterate through the generator and write each chunk to the app\n        # with a type writer effect.\n        for chunk in stream:  # type: ignore\n            if type_util.is_openai_chunk(chunk):\n                # Try to convert OpenAI chat completion chunk to a string:\n                try:\n                    if len(chunk.choices) == 0:\n                        # The choices list can be empty. E.g. when using the\n                        # AzureOpenAI client, the first chunk will always be empty.\n                        chunk = \"\"\n                    else:\n                        chunk = chunk.choices[0].delta.content or \"\"\n                except AttributeError as err:\n                    raise StreamlitAPIException(\n                        \"Failed to parse the OpenAI ChatCompletionChunk. \"\n                        \"The most likely cause is a change of the chunk object structure \"\n                        \"due to a recent OpenAI update. You might be able to fix this \"\n                        \"by downgrading the OpenAI library or upgrading Streamlit. Also, \"\n                        \"please report this issue to: https://github.com/streamlit/streamlit/issues.\"\n                    ) from err\n\n            if type_util.is_type(chunk, \"langchain_core.messages.ai.AIMessageChunk\"):\n                # Try to convert LangChain message chunk to a string:\n                try:\n                    chunk = chunk.content or \"\"\n                except AttributeError as err:\n                    raise StreamlitAPIException(\n                        \"Failed to parse the LangChain AIMessageChunk. \"\n                        \"The most likely cause is a change of the chunk object structure \"\n                        \"due to a recent LangChain update. You might be able to fix this \"\n                        \"by downgrading the OpenAI library or upgrading Streamlit. Also, \"\n                        \"please report this issue to: https://github.com/streamlit/streamlit/issues.\"\n                    ) from err\n\n            if isinstance(chunk, str):\n                if not chunk:\n                    # Empty strings can be ignored\n                    continue\n\n                first_text = False\n                if not stream_container:\n                    stream_container = self.dg.empty()\n                    first_text = True\n                streamed_response += chunk\n                # Only add the streaming symbol on the second text chunk\n                stream_container.markdown(\n                    streamed_response + (\"\" if first_text else _TEXT_CURSOR),\n                )\n            elif callable(chunk):\n                flush_stream_response()\n                chunk()\n            else:\n                flush_stream_response()\n                self.write(chunk)\n                written_content.append(chunk)\n\n        flush_stream_response()\n\n        if not written_content:\n            # If nothing was streamed, return an empty string.\n            return \"\"\n        elif len(written_content) == 1 and isinstance(written_content[0], str):\n            # If the output only contains a single string, return it as a string\n            return written_content[0]\n\n        # Otherwise return it as a list of write-compatible objects\n        return written_content\n\n    @gather_metrics(\"write\")\n    def write(self, *args: Any, unsafe_allow_html: bool = False, **kwargs) -> None:\n        \"\"\"Write arguments to the app.\n\n        This is the Swiss Army knife of Streamlit commands: it does different\n        things depending on what you throw at it. Unlike other Streamlit commands,\n        write() has some unique properties:\n\n        1. You can pass in multiple arguments, all of which will be written.\n        2. Its behavior depends on the input types as follows.\n        3. It returns None, so its \"slot\" in the App cannot be reused.\n\n        Parameters\n        ----------\n        *args : any\n            One or many objects to print to the App.\n\n            Arguments are handled as follows:\n\n            - write(string)         : Prints the formatted Markdown string, with\n                support for LaTeX expression, emoji shortcodes, and colored text.\n                See docs for st.markdown for more.\n            - write(data_frame)     : Displays the DataFrame as a table.\n            - write(error)          : Prints an exception specially.\n            - write(func)           : Displays information about a function.\n            - write(module)         : Displays information about the module.\n            - write(class)          : Displays information about a class.\n            - write(dict)           : Displays dict in an interactive widget.\n            - write(mpl_fig)        : Displays a Matplotlib figure.\n            - write(generator)      : Streams the output of a generator.\n            - write(openai.Stream)  : Streams the output of an OpenAI stream.\n            - write(altair)         : Displays an Altair chart.\n            - write(PIL.Image)      : Displays an image.\n            - write(keras)          : Displays a Keras model.\n            - write(graphviz)       : Displays a Graphviz graph.\n            - write(plotly_fig)     : Displays a Plotly figure.\n            - write(bokeh_fig)      : Displays a Bokeh figure.\n            - write(sympy_expr)     : Prints SymPy expression using LaTeX.\n            - write(htmlable)       : Prints _repr_html_() for the object if available.\n            - write(obj)            : Prints str(obj) if otherwise unknown.\n\n        unsafe_allow_html : bool\n            Whether to render HTML within ``*args``. This only applies to\n            strings or objects falling back on ``_repr_html_()``. If this is\n            ``False`` (default), any HTML tags found in ``body`` will be\n            escaped and therefore treated as raw text. If this is ``True``, any\n            HTML expressions within ``body`` will be rendered.\n\n            Adding custom HTML to your app impacts safety, styling, and\n            maintainability.\n\n            .. note::\n                If you only want to insert HTML or CSS without Markdown text,\n                we recommend using ``st.html`` instead.\n\n        **kwargs : any\n            Keyword arguments. Not used.\n\n        .. deprecated::\n            ``**kwargs`` is deprecated and will be removed in a later version.\n            Use other, more specific Streamlit commands to pass additional\n            keyword arguments.\n\n\n        Example\n        -------\n\n        Its basic use case is to draw Markdown-formatted text, whenever the\n        input is a string:\n\n        >>> import streamlit as st\n        >>>\n        >>> st.write('Hello, *World!* :sunglasses:')\n\n        ..  output::\n            https://doc-write1.streamlit.app/\n            height: 150px\n\n        As mentioned earlier, ``st.write()`` also accepts other data formats, such as\n        numbers, data frames, styled data frames, and assorted objects:\n\n        >>> import streamlit as st\n        >>> import pandas as pd\n        >>>\n        >>> st.write(1234)\n        >>> st.write(pd.DataFrame({\n        ...     'first column': [1, 2, 3, 4],\n        ...     'second column': [10, 20, 30, 40],\n        ... }))\n\n        ..  output::\n            https://doc-write2.streamlit.app/\n            height: 350px\n\n        Finally, you can pass in multiple arguments to do things like:\n\n        >>> import streamlit as st\n        >>>\n        >>> st.write('1 + 1 = ', 2)\n        >>> st.write('Below is a DataFrame:', data_frame, 'Above is a dataframe.')\n\n        ..  output::\n            https://doc-write3.streamlit.app/\n            height: 410px\n\n        Oh, one more thing: ``st.write`` accepts chart objects too! For example:\n\n        >>> import streamlit as st\n        >>> import pandas as pd\n        >>> import numpy as np\n        >>> import altair as alt\n        >>>\n        >>> df = pd.DataFrame(\n        ...     np.random.randn(200, 3),\n        ...     columns=['a', 'b', 'c'])\n        ...\n        >>> c = alt.Chart(df).mark_circle().encode(\n        ...     x='a', y='b', size='c', color='c', tooltip=['a', 'b', 'c'])\n        >>>\n        >>> st.write(c)\n\n        ..  output::\n            https://doc-vega-lite-chart.streamlit.app/\n            height: 300px\n\n        \"\"\"\n        if kwargs:\n            _LOGGER.warning(\n                'Invalid arguments were passed to \"st.write\" function. Support for '\n                \"passing such unknown keywords arguments will be dropped in future. \"\n                \"Invalid arguments were: %s\",\n                kwargs,\n            )\n\n        string_buffer: list[str] = []\n\n        # This bans some valid cases like: e = st.empty(); e.write(\"a\", \"b\").\n        # BUT: 1) such cases are rare, 2) this rule is easy to understand,\n        # and 3) this rule should be removed once we have st.container()\n        if not self.dg._is_top_level and len(args) > 1:\n            raise StreamlitAPIException(\n                \"Cannot replace a single element with multiple elements.\\n\\n\"\n                \"The `write()` method only supports multiple elements when \"\n                \"inserting elements rather than replacing. That is, only \"\n                \"when called as `st.write()` or `st.sidebar.write()`.\"\n            )\n\n        def flush_buffer():\n            if string_buffer:\n                text_content = \" \".join(string_buffer)\n                # The usage of empty here prevents\n                # some grey out effects:\n                text_container = self.dg.empty()\n                text_container.markdown(\n                    text_content,\n                    unsafe_allow_html=unsafe_allow_html,\n                )\n                string_buffer[:] = []\n\n        for arg in args:\n            # Order matters!\n            if isinstance(arg, str):\n                string_buffer.append(arg)\n            elif isinstance(arg, StreamingOutput):\n                flush_buffer()\n                for item in arg:\n                    if callable(item):\n                        flush_buffer()\n                        item()\n                    else:\n                        self.write(item, unsafe_allow_html=unsafe_allow_html)\n            elif type_util.is_unevaluated_data_object(\n                arg\n            ) or type_util.is_snowpark_row_list(arg):\n                flush_buffer()\n                self.dg.dataframe(arg)\n            elif type_util.is_dataframe_like(arg):\n                import numpy as np\n\n                flush_buffer()\n                if len(np.shape(arg)) > 2:\n                    self.dg.text(arg)\n                else:\n                    self.dg.dataframe(arg)\n            elif isinstance(arg, Exception):\n                flush_buffer()\n                self.dg.exception(arg)\n            elif type_util.is_altair_chart(arg):\n                flush_buffer()\n                self.dg.altair_chart(arg)\n            elif type_util.is_type(arg, \"matplotlib.figure.Figure\"):\n                flush_buffer()\n                self.dg.pyplot(arg)\n            elif type_util.is_plotly_chart(arg):\n                flush_buffer()\n                self.dg.plotly_chart(arg)\n            elif type_util.is_type(arg, \"bokeh.plotting.figure.Figure\"):\n                flush_buffer()\n                self.dg.bokeh_chart(arg)\n            elif type_util.is_graphviz_chart(arg):\n                flush_buffer()\n                self.dg.graphviz_chart(arg)\n            elif type_util.is_sympy_expession(arg):\n                flush_buffer()\n                self.dg.latex(arg)\n            elif type_util.is_pillow_image(arg):\n                flush_buffer()\n                self.dg.image(arg)\n            elif type_util.is_keras_model(arg):\n                from tensorflow.python.keras.utils import vis_utils\n\n                flush_buffer()\n                dot = vis_utils.model_to_dot(arg)\n                self.dg.graphviz_chart(dot.to_string())\n            elif isinstance(\n                arg, (dict, list, SessionStateProxy, UserInfoProxy, QueryParamsProxy)\n            ):\n                flush_buffer()\n                self.dg.json(arg)\n            elif type_util.is_namedtuple(arg):\n                flush_buffer()\n                self.dg.json(json.dumps(arg._asdict()))\n            elif type_util.is_pydeck(arg):\n                flush_buffer()\n                self.dg.pydeck_chart(arg)\n            elif isinstance(arg, StringIO):\n                flush_buffer()\n                self.dg.markdown(arg.getvalue())\n            elif (\n                inspect.isgenerator(arg)\n                or inspect.isgeneratorfunction(arg)\n                or type_util.is_type(arg, \"openai.Stream\")\n            ):\n                flush_buffer()\n                self.write_stream(arg)\n            elif isinstance(arg, HELP_TYPES):\n                flush_buffer()\n                self.dg.help(arg)\n            elif dataclasses.is_dataclass(arg):\n                flush_buffer()\n                self.dg.help(arg)\n            elif inspect.isclass(arg):\n                flush_buffer()\n                # We cast arg to type here to appease mypy, due to bug in mypy:\n                # https://github.com/python/mypy/issues/12933\n                self.dg.help(cast(type, arg))\n            elif (\n                hasattr(arg, \"_repr_html_\")\n                and callable(arg._repr_html_)\n                and (repr_html := arg._repr_html_())\n                and (unsafe_allow_html or not probably_contains_html_tags(repr_html))\n            ):\n                # We either explicitly allow HTML or infer it's not HTML\n                self.dg.markdown(repr_html, unsafe_allow_html=unsafe_allow_html)\n            elif type_util.is_streamlit_secrets_class(arg):\n                flush_buffer()\n                self.dg.json(arg.to_dict())\n            else:\n                stringified_arg = str(arg)\n\n                if is_mem_address_str(stringified_arg):\n                    flush_buffer()\n                    self.dg.help(arg)\n\n                elif \"\\n\" in stringified_arg:\n                    # With a multi-line string, use a preformatted block\n                    # To fully escape backticks, we wrap with backticks larger than\n                    # the largest sequence of backticks in the string.\n                    backtick_count = max(3, max_char_sequence(stringified_arg, \"`\") + 1)\n                    backtick_wrapper = \"`\" * backtick_count\n                    string_buffer.append(\n                        f\"{backtick_wrapper}\\n{stringified_arg}\\n{backtick_wrapper}\"\n                    )\n                else:\n                    # With a single-line string, use a preformatted text\n                    # To fully escape backticks, we wrap with backticks larger than\n                    # the largest sequence of backticks in the string.\n                    backtick_count = max_char_sequence(stringified_arg, \"`\") + 1\n                    backtick_wrapper = \"`\" * backtick_count\n                    string_buffer.append(\n                        f\"{backtick_wrapper}{stringified_arg}{backtick_wrapper}\"\n                    )\n\n        flush_buffer()\n\n    @property\n    def dg(self) -> DeltaGenerator:\n        \"\"\"Get our DeltaGenerator.\"\"\"\n        return cast(\"DeltaGenerator\", self)\n", "lib/streamlit/elements/graphviz_chart.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Streamlit support for GraphViz charts.\"\"\"\n\nfrom __future__ import annotations\n\nimport hashlib\nfrom typing import TYPE_CHECKING, Union, cast\n\nfrom typing_extensions import TypeAlias\n\nfrom streamlit import type_util\nfrom streamlit.errors import StreamlitAPIException\nfrom streamlit.proto.GraphVizChart_pb2 import GraphVizChart as GraphVizChartProto\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.util import HASHLIB_KWARGS\n\nif TYPE_CHECKING:\n    import graphviz\n\n    from streamlit.delta_generator import DeltaGenerator\n\nFigureOrDot: TypeAlias = Union[\"graphviz.Graph\", \"graphviz.Digraph\", str]\n\n\nclass GraphvizMixin:\n    @gather_metrics(\"graphviz_chart\")\n    def graphviz_chart(\n        self,\n        figure_or_dot: FigureOrDot,\n        use_container_width: bool = False,\n    ) -> DeltaGenerator:\n        \"\"\"Display a graph using the dagre-d3 library.\n\n        Parameters\n        ----------\n        figure_or_dot : graphviz.dot.Graph, graphviz.dot.Digraph, str\n            The Graphlib graph object or dot string to display\n\n        use_container_width : bool\n            Whether to override the figure's native width with the width of\n            the parent container. If ``use_container_width`` is ``False``\n            (default), Streamlit sets the width of the chart to fit its contents\n            according to the plotting library, up to the width of the parent\n            container. If ``use_container_width`` is ``True``, Streamlit sets\n            the width of the figure to match the width of the parent container.\n\n        Example\n        -------\n        >>> import streamlit as st\n        >>> import graphviz\n        >>>\n        >>> # Create a graphlib graph object\n        >>> graph = graphviz.Digraph()\n        >>> graph.edge('run', 'intr')\n        >>> graph.edge('intr', 'runbl')\n        >>> graph.edge('runbl', 'run')\n        >>> graph.edge('run', 'kernel')\n        >>> graph.edge('kernel', 'zombie')\n        >>> graph.edge('kernel', 'sleep')\n        >>> graph.edge('kernel', 'runmem')\n        >>> graph.edge('sleep', 'swap')\n        >>> graph.edge('swap', 'runswap')\n        >>> graph.edge('runswap', 'new')\n        >>> graph.edge('runswap', 'runmem')\n        >>> graph.edge('new', 'runmem')\n        >>> graph.edge('sleep', 'runmem')\n        >>>\n        >>> st.graphviz_chart(graph)\n\n        Or you can render the chart from the graph using GraphViz's Dot\n        language:\n\n        >>> st.graphviz_chart('''\n            digraph {\n                run -> intr\n                intr -> runbl\n                runbl -> run\n                run -> kernel\n                kernel -> zombie\n                kernel -> sleep\n                kernel -> runmem\n                sleep -> swap\n                swap -> runswap\n                runswap -> new\n                runswap -> runmem\n                new -> runmem\n                sleep -> runmem\n            }\n        ''')\n\n        .. output::\n           https://doc-graphviz-chart.streamlit.app/\n           height: 600px\n\n        \"\"\"\n        # Generate element ID from delta path\n        delta_path = self.dg._get_delta_path_str()\n        element_id = hashlib.md5(delta_path.encode(), **HASHLIB_KWARGS).hexdigest()\n\n        graphviz_chart_proto = GraphVizChartProto()\n\n        marshall(graphviz_chart_proto, figure_or_dot, use_container_width, element_id)\n        return self.dg._enqueue(\"graphviz_chart\", graphviz_chart_proto)\n\n    @property\n    def dg(self) -> DeltaGenerator:\n        \"\"\"Get our DeltaGenerator.\"\"\"\n        return cast(\"DeltaGenerator\", self)\n\n\ndef marshall(\n    proto: GraphVizChartProto,\n    figure_or_dot: FigureOrDot,\n    use_container_width: bool,\n    element_id: str,\n) -> None:\n    \"\"\"Construct a GraphViz chart object.\n\n    See DeltaGenerator.graphviz_chart for docs.\n    \"\"\"\n\n    if type_util.is_graphviz_chart(figure_or_dot):\n        dot = figure_or_dot.source\n        engine = figure_or_dot.engine\n    elif isinstance(figure_or_dot, str):\n        dot = figure_or_dot\n        engine = \"dot\"\n    else:\n        raise StreamlitAPIException(\n            \"Unhandled type for graphviz chart: %s\" % type(figure_or_dot)\n        )\n\n    proto.spec = dot\n    proto.engine = engine\n    proto.use_container_width = use_container_width\n    proto.element_id = element_id\n", "lib/streamlit/elements/json.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport json\nfrom typing import TYPE_CHECKING, Any, cast\n\nfrom streamlit.proto.Json_pb2 import Json as JsonProto\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.runtime.state import QueryParamsProxy, SessionStateProxy\nfrom streamlit.user_info import UserInfoProxy\n\nif TYPE_CHECKING:\n    from streamlit.delta_generator import DeltaGenerator\n\n\ndef _ensure_serialization(o: object) -> str | list[Any]:\n    \"\"\"A repr function for json.dumps default arg, which tries to serialize sets as lists\"\"\"\n    if isinstance(o, set):\n        return list(o)\n    return repr(o)\n\n\nclass JsonMixin:\n    @gather_metrics(\"json\")\n    def json(\n        self,\n        body: object,\n        *,  # keyword-only arguments:\n        expanded: bool = True,\n    ) -> DeltaGenerator:\n        \"\"\"Display object or string as a pretty-printed JSON string.\n\n        Parameters\n        ----------\n        body : object or str\n            The object to print as JSON. All referenced objects should be\n            serializable to JSON as well. If object is a string, we assume it\n            contains serialized JSON.\n\n        expanded : bool\n            An optional boolean that allows the user to set whether the initial\n            state of this json element should be expanded. Defaults to True.\n\n        Example\n        -------\n        >>> import streamlit as st\n        >>>\n        >>> st.json({\n        ...     'foo': 'bar',\n        ...     'baz': 'boz',\n        ...     'stuff': [\n        ...         'stuff 1',\n        ...         'stuff 2',\n        ...         'stuff 3',\n        ...         'stuff 5',\n        ...     ],\n        ... })\n\n        .. output::\n           https://doc-json.streamlit.app/\n           height: 385px\n\n        \"\"\"\n        import streamlit as st\n\n        if isinstance(body, (SessionStateProxy, UserInfoProxy, QueryParamsProxy)):\n            body = body.to_dict()\n\n        if not isinstance(body, str):\n            try:\n                # Serialize body to string and try to interpret sets as lists\n                body = json.dumps(body, default=_ensure_serialization)\n            except TypeError as err:\n                st.warning(\n                    \"Warning: this data structure was not fully serializable as \"\n                    f\"JSON due to one or more unexpected keys.  (Error was: {err})\"\n                )\n                body = json.dumps(body, skipkeys=True, default=_ensure_serialization)\n\n        json_proto = JsonProto()\n        json_proto.body = body\n        json_proto.expanded = expanded\n        return self.dg._enqueue(\"json\", json_proto)\n\n    @property\n    def dg(self) -> DeltaGenerator:\n        \"\"\"Get our DeltaGenerator.\"\"\"\n        return cast(\"DeltaGenerator\", self)\n", "lib/streamlit/elements/metric.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom dataclasses import dataclass\nfrom textwrap import dedent\nfrom typing import TYPE_CHECKING, Literal, Union, cast\n\nfrom typing_extensions import TypeAlias\n\nfrom streamlit.elements.lib.utils import get_label_visibility_proto_value\nfrom streamlit.errors import StreamlitAPIException\nfrom streamlit.proto.Metric_pb2 import Metric as MetricProto\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.string_util import clean_text\nfrom streamlit.type_util import LabelVisibility, maybe_raise_label_warnings\n\nif TYPE_CHECKING:\n    import numpy as np\n\n    from streamlit.delta_generator import DeltaGenerator\n\n\nValue: TypeAlias = Union[\"np.integer\", \"np.floating\", float, int, str, None]\nDelta: TypeAlias = Union[float, int, str, None]\nDeltaColor: TypeAlias = Literal[\"normal\", \"inverse\", \"off\"]\n\n\n@dataclass(frozen=True)\nclass MetricColorAndDirection:\n    color: MetricProto.MetricColor.ValueType\n    direction: MetricProto.MetricDirection.ValueType\n\n\nclass MetricMixin:\n    @gather_metrics(\"metric\")\n    def metric(\n        self,\n        label: str,\n        value: Value,\n        delta: Delta = None,\n        delta_color: DeltaColor = \"normal\",\n        help: str | None = None,\n        label_visibility: LabelVisibility = \"visible\",\n    ) -> DeltaGenerator:\n        r\"\"\"Display a metric in big bold font, with an optional indicator of how the metric changed.\n\n        Tip: If you want to display a large number, it may be a good idea to\n        shorten it using packages like `millify <https://github.com/azaitsev/millify>`_\n        or `numerize <https://github.com/davidsa03/numerize>`_. E.g. ``1234`` can be\n        displayed as ``1.2k`` using ``st.metric(\"Short number\", millify(1234))``.\n\n        Parameters\n        ----------\n        label : str\n            The header or title for the metric. The label can optionally contain\n            Markdown and supports the following elements: Bold, Italics,\n            Strikethroughs, Inline Code, Emojis, and Links.\n\n            This also supports:\n\n            * Emoji shortcodes, such as ``:+1:``  and ``:sunglasses:``.\n              For a list of all supported codes,\n              see https://share.streamlit.io/streamlit/emoji-shortcodes.\n\n            * LaTeX expressions, by wrapping them in \"$\" or \"$$\" (the \"$$\"\n              must be on their own lines). Supported LaTeX functions are listed\n              at https://katex.org/docs/supported.html.\n\n            * Colored text and background colors for text, using the syntax\n              ``:color[text to be colored]`` and ``:color-background[text to be colored]``,\n              respectively. ``color`` must be replaced with any of the following\n              supported colors: blue, green, orange, red, violet, gray/grey, rainbow.\n              For example, you can use ``:orange[your text here]`` or\n              ``:blue-background[your text here]``.\n\n            Unsupported elements are unwrapped so only their children (text contents) render.\n            Display unsupported elements as literal characters by\n            backslash-escaping them. E.g. ``1\\. Not an ordered list``.\n        value : int, float, str, or None\n             Value of the metric. None is rendered as a long dash.\n        delta : int, float, str, or None\n            Indicator of how the metric changed, rendered with an arrow below\n            the metric. If delta is negative (int/float) or starts with a minus\n            sign (str), the arrow points down and the text is red; else the\n            arrow points up and the text is green. If None (default), no delta\n            indicator is shown.\n        delta_color : \"normal\", \"inverse\", or \"off\"\n             If \"normal\" (default), the delta indicator is shown as described\n             above. If \"inverse\", it is red when positive and green when\n             negative. This is useful when a negative change is considered\n             good, e.g. if cost decreased. If \"off\", delta is  shown in gray\n             regardless of its value.\n        help : str\n            An optional tooltip that gets displayed next to the metric label.\n        label_visibility : \"visible\", \"hidden\", or \"collapsed\"\n            The visibility of the label. If \"hidden\", the label doesn't show but there\n            is still empty space for it (equivalent to label=\"\").\n            If \"collapsed\", both the label and the space are removed. Default is\n            \"visible\".\n\n        Example\n        -------\n        >>> import streamlit as st\n        >>>\n        >>> st.metric(label=\"Temperature\", value=\"70 \u00b0F\", delta=\"1.2 \u00b0F\")\n\n        .. output::\n            https://doc-metric-example1.streamlit.app/\n            height: 210px\n\n        ``st.metric`` looks especially nice in combination with ``st.columns``:\n\n        >>> import streamlit as st\n        >>>\n        >>> col1, col2, col3 = st.columns(3)\n        >>> col1.metric(\"Temperature\", \"70 \u00b0F\", \"1.2 \u00b0F\")\n        >>> col2.metric(\"Wind\", \"9 mph\", \"-8%\")\n        >>> col3.metric(\"Humidity\", \"86%\", \"4%\")\n\n        .. output::\n            https://doc-metric-example2.streamlit.app/\n            height: 210px\n\n        The delta indicator color can also be inverted or turned off:\n\n        >>> import streamlit as st\n        >>>\n        >>> st.metric(label=\"Gas price\", value=4, delta=-0.5,\n        ...     delta_color=\"inverse\")\n        >>>\n        >>> st.metric(label=\"Active developers\", value=123, delta=123,\n        ...     delta_color=\"off\")\n\n        .. output::\n            https://doc-metric-example3.streamlit.app/\n            height: 320px\n\n        \"\"\"\n        maybe_raise_label_warnings(label, label_visibility)\n\n        metric_proto = MetricProto()\n        metric_proto.body = _parse_value(value)\n        metric_proto.label = _parse_label(label)\n        metric_proto.delta = _parse_delta(delta)\n        if help is not None:\n            metric_proto.help = dedent(help)\n\n        color_and_direction = _determine_delta_color_and_direction(\n            cast(DeltaColor, clean_text(delta_color)), delta\n        )\n        metric_proto.color = color_and_direction.color\n        metric_proto.direction = color_and_direction.direction\n        metric_proto.label_visibility.value = get_label_visibility_proto_value(\n            label_visibility\n        )\n\n        return self.dg._enqueue(\"metric\", metric_proto)\n\n    @property\n    def dg(self) -> DeltaGenerator:\n        return cast(\"DeltaGenerator\", self)\n\n\ndef _parse_label(label: str) -> str:\n    if not isinstance(label, str):\n        raise TypeError(\n            f\"'{str(label)}' is of type {str(type(label))}, which is not an accepted type.\"\n            \" label only accepts: str. Please convert the label to an accepted type.\"\n        )\n    return label\n\n\ndef _parse_value(value: Value) -> str:\n    if value is None:\n        return \"\u2014\"\n    if isinstance(value, int) or isinstance(value, float) or isinstance(value, str):\n        return str(value)\n    elif hasattr(value, \"item\"):\n        # Add support for numpy values (e.g. int16, float64, etc.)\n        try:\n            # Item could also be just a variable, so we use try, except\n            if isinstance(value.item(), float) or isinstance(value.item(), int):\n                return str(value.item())\n        except Exception:\n            # If the numpy item is not a valid value, the TypeError below will be raised.\n            pass\n\n    raise TypeError(\n        f\"'{str(value)}' is of type {str(type(value))}, which is not an accepted type.\"\n        \" value only accepts: int, float, str, or None.\"\n        \" Please convert the value to an accepted type.\"\n    )\n\n\ndef _parse_delta(delta: Delta) -> str:\n    if delta is None or delta == \"\":\n        return \"\"\n    if isinstance(delta, str):\n        return dedent(delta)\n    elif isinstance(delta, int) or isinstance(delta, float):\n        return str(delta)\n    else:\n        raise TypeError(\n            f\"'{str(delta)}' is of type {str(type(delta))}, which is not an accepted type.\"\n            \" delta only accepts: int, float, str, or None.\"\n            \" Please convert the value to an accepted type.\"\n        )\n\n\ndef _determine_delta_color_and_direction(\n    delta_color: DeltaColor,\n    delta: Delta,\n) -> MetricColorAndDirection:\n    if delta_color not in {\"normal\", \"inverse\", \"off\"}:\n        raise StreamlitAPIException(\n            f\"'{str(delta_color)}' is not an accepted value. delta_color only accepts: \"\n            \"'normal', 'inverse', or 'off'\"\n        )\n\n    if delta is None or delta == \"\":\n        return MetricColorAndDirection(\n            color=MetricProto.MetricColor.GRAY,\n            direction=MetricProto.MetricDirection.NONE,\n        )\n\n    if _is_negative_delta(delta):\n        if delta_color == \"normal\":\n            cd_color = MetricProto.MetricColor.RED\n        elif delta_color == \"inverse\":\n            cd_color = MetricProto.MetricColor.GREEN\n        else:\n            cd_color = MetricProto.MetricColor.GRAY\n        cd_direction = MetricProto.MetricDirection.DOWN\n    else:\n        if delta_color == \"normal\":\n            cd_color = MetricProto.MetricColor.GREEN\n        elif delta_color == \"inverse\":\n            cd_color = MetricProto.MetricColor.RED\n        else:\n            cd_color = MetricProto.MetricColor.GRAY\n        cd_direction = MetricProto.MetricDirection.UP\n\n    return MetricColorAndDirection(\n        color=cd_color,\n        direction=cd_direction,\n    )\n\n\ndef _is_negative_delta(delta: Delta) -> bool:\n    return dedent(str(delta)).startswith(\"-\")\n", "lib/streamlit/elements/bokeh_chart.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"A Python wrapper around Bokeh.\"\"\"\n\nfrom __future__ import annotations\n\nimport hashlib\nimport json\nfrom typing import TYPE_CHECKING, Final, cast\n\nfrom streamlit.errors import StreamlitAPIException\nfrom streamlit.proto.BokehChart_pb2 import BokehChart as BokehChartProto\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.util import HASHLIB_KWARGS\n\nif TYPE_CHECKING:\n    from bokeh.plotting.figure import Figure\n\n    from streamlit.delta_generator import DeltaGenerator\n\nST_BOKEH_VERSION: Final = \"2.4.3\"\n\n\nclass BokehMixin:\n    @gather_metrics(\"bokeh_chart\")\n    def bokeh_chart(\n        self,\n        figure: Figure,\n        use_container_width: bool = False,\n    ) -> DeltaGenerator:\n        \"\"\"Display an interactive Bokeh chart.\n\n        Bokeh is a charting library for Python. The arguments to this function\n        closely follow the ones for Bokeh's ``show`` function. You can find\n        more about Bokeh at https://bokeh.pydata.org.\n\n        To show Bokeh charts in Streamlit, call ``st.bokeh_chart``\n        wherever you would call Bokeh's ``show``.\n\n        Parameters\n        ----------\n        figure : bokeh.plotting.figure.Figure\n            A Bokeh figure to plot.\n\n        use_container_width : bool\n            Whether to override the figure's native width with the width of\n            the parent container. If ``use_container_width`` is ``False``\n            (default), Streamlit sets the width of the chart to fit its contents\n            according to the plotting library, up to the width of the parent\n            container. If ``use_container_width`` is ``True``, Streamlit sets\n            the width of the figure to match the width of the parent container.\n\n        Example\n        -------\n        >>> import streamlit as st\n        >>> from bokeh.plotting import figure\n        >>>\n        >>> x = [1, 2, 3, 4, 5]\n        >>> y = [6, 7, 2, 4, 5]\n        >>>\n        >>> p = figure(\n        ...     title='simple line example',\n        ...     x_axis_label='x',\n        ...     y_axis_label='y')\n        ...\n        >>> p.line(x, y, legend_label='Trend', line_width=2)\n        >>>\n        >>> st.bokeh_chart(p, use_container_width=True)\n\n        .. output::\n           https://doc-bokeh-chart.streamlit.app/\n           height: 700px\n\n        \"\"\"\n        import bokeh\n\n        if bokeh.__version__ != ST_BOKEH_VERSION:\n            raise StreamlitAPIException(\n                f\"Streamlit only supports Bokeh version {ST_BOKEH_VERSION}, \"\n                f\"but you have version {bokeh.__version__} installed. Please \"\n                f\"run `pip install --force-reinstall --no-deps bokeh==\"\n                f\"{ST_BOKEH_VERSION}` to install the correct version.\"\n            )\n\n        # Generate element ID from delta path\n        delta_path = self.dg._get_delta_path_str()\n\n        element_id = hashlib.md5(delta_path.encode(), **HASHLIB_KWARGS).hexdigest()\n        bokeh_chart_proto = BokehChartProto()\n        marshall(bokeh_chart_proto, figure, use_container_width, element_id)\n        return self.dg._enqueue(\"bokeh_chart\", bokeh_chart_proto)\n\n    @property\n    def dg(self) -> DeltaGenerator:\n        \"\"\"Get our DeltaGenerator.\"\"\"\n        return cast(\"DeltaGenerator\", self)\n\n\ndef marshall(\n    proto: BokehChartProto,\n    figure: Figure,\n    use_container_width: bool,\n    element_id: str,\n) -> None:\n    \"\"\"Construct a Bokeh chart object.\n\n    See DeltaGenerator.bokeh_chart for docs.\n    \"\"\"\n    from bokeh.embed import json_item\n\n    data = json_item(figure)\n    proto.figure = json.dumps(data)\n    proto.use_container_width = use_container_width\n    proto.element_id = element_id\n", "lib/streamlit/elements/image.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Some casts in this file are only occasionally necessary depending on the\n# user's Python version, and mypy doesn't have a good way of toggling this\n# specific config option at a per-line level.\n# mypy: no-warn-unused-ignores\n\n\"\"\"Image marshalling.\"\"\"\n\nfrom __future__ import annotations\n\nimport io\nimport os\nimport re\nfrom enum import IntEnum\nfrom typing import TYPE_CHECKING, Final, List, Literal, Sequence, Union, cast\n\nfrom typing_extensions import TypeAlias\n\nfrom streamlit import runtime, url_util\nfrom streamlit.errors import StreamlitAPIException\nfrom streamlit.proto.Image_pb2 import ImageList as ImageListProto\nfrom streamlit.runtime import caching\nfrom streamlit.runtime.metrics_util import gather_metrics\n\nif TYPE_CHECKING:\n    from typing import Any\n\n    import numpy.typing as npt\n    from PIL import GifImagePlugin, Image, ImageFile\n\n    from streamlit.delta_generator import DeltaGenerator\n\n# This constant is related to the frontend maximum content width specified\n# in App.jsx main container\n# 730 is the max width of element-container in the frontend, and 2x is for high\n# DPI.\nMAXIMUM_CONTENT_WIDTH: Final[int] = 2 * 730\n\nPILImage: TypeAlias = Union[\n    \"ImageFile.ImageFile\", \"Image.Image\", \"GifImagePlugin.GifImageFile\"\n]\nAtomicImage: TypeAlias = Union[PILImage, \"npt.NDArray[Any]\", io.BytesIO, str, bytes]\nImageOrImageList: TypeAlias = Union[AtomicImage, List[AtomicImage]]\nUseColumnWith: TypeAlias = Union[Literal[\"auto\", \"always\", \"never\"], bool, None]\nChannels: TypeAlias = Literal[\"RGB\", \"BGR\"]\nImageFormat: TypeAlias = Literal[\"JPEG\", \"PNG\", \"GIF\"]\nImageFormatOrAuto: TypeAlias = Literal[ImageFormat, \"auto\"]\n\n\nclass WidthBehaviour(IntEnum):\n    \"\"\"\n    Special values that are recognized by the frontend and allow us to change the\n    behavior of the displayed image.\n    \"\"\"\n\n    ORIGINAL = -1\n    COLUMN = -2\n    AUTO = -3\n\n\nWidthBehaviour.ORIGINAL.__doc__ = \"\"\"Display the image at its original width\"\"\"\nWidthBehaviour.COLUMN.__doc__ = (\n    \"\"\"Display the image at the width of the column it's in.\"\"\"\n)\nWidthBehaviour.AUTO.__doc__ = \"\"\"Display the image at its original width, unless it\nwould exceed the width of its column in which case clamp it to\nits column width\"\"\"\n\n\nclass ImageMixin:\n    @gather_metrics(\"image\")\n    def image(\n        self,\n        image: ImageOrImageList,\n        # TODO: Narrow type of caption, dependent on type of image,\n        #  by way of overload\n        caption: str | list[str] | None = None,\n        width: int | None = None,\n        use_column_width: UseColumnWith = None,\n        clamp: bool = False,\n        channels: Channels = \"RGB\",\n        output_format: ImageFormatOrAuto = \"auto\",\n    ) -> DeltaGenerator:\n        \"\"\"Display an image or list of images.\n\n        Parameters\n        ----------\n        image : numpy.ndarray, [numpy.ndarray], BytesIO, str, or [str]\n            Monochrome image of shape (w,h) or (w,h,1)\n            OR a color image of shape (w,h,3)\n            OR an RGBA image of shape (w,h,4)\n            OR a URL to fetch the image from\n            OR a path of a local image file\n            OR an SVG XML string like `<svg xmlns=...</svg>`\n            OR a list of one of the above, to display multiple images.\n        caption : str or list of str\n            Image caption. If displaying multiple images, caption should be a\n            list of captions (one for each image).\n        width : int or None\n            Image width. None means use the image width,\n            but do not exceed the width of the column.\n            Should be set for SVG images, as they have no default image width.\n        use_column_width : \"auto\", \"always\", \"never\", or bool\n            If \"auto\", set the image's width to its natural size,\n            but do not exceed the width of the column.\n            If \"always\" or True, set the image's width to the column width.\n            If \"never\" or False, set the image's width to its natural size.\n            Note: if set, `use_column_width` takes precedence over the `width` parameter.\n        clamp : bool\n            Clamp image pixel values to a valid range ([0-255] per channel).\n            This is only meaningful for byte array images; the parameter is\n            ignored for image URLs. If this is not set, and an image has an\n            out-of-range value, an error will be thrown.\n        channels : \"RGB\" or \"BGR\"\n            If image is an nd.array, this parameter denotes the format used to\n            represent color information. Defaults to \"RGB\", meaning\n            `image[:, :, 0]` is the red channel, `image[:, :, 1]` is green, and\n            `image[:, :, 2]` is blue. For images coming from libraries like\n            OpenCV you should set this to \"BGR\", instead.\n        output_format : \"JPEG\", \"PNG\", or \"auto\"\n            This parameter specifies the format to use when transferring the\n            image data. Photos should use the JPEG format for lossy compression\n            while diagrams should use the PNG format for lossless compression.\n            Defaults to \"auto\" which identifies the compression type based\n            on the type and format of the image argument.\n\n        Example\n        -------\n        >>> import streamlit as st\n        >>> st.image('sunrise.jpg', caption='Sunrise by the mountains')\n\n        .. output::\n           https://doc-image.streamlit.app/\n           height: 710px\n\n        \"\"\"\n\n        if use_column_width == \"auto\" or (use_column_width is None and width is None):\n            width = WidthBehaviour.AUTO\n        elif use_column_width == \"always\" or use_column_width is True:\n            width = WidthBehaviour.COLUMN\n        elif width is None:\n            width = WidthBehaviour.ORIGINAL\n        elif width <= 0:\n            raise StreamlitAPIException(\"Image width must be positive.\")\n\n        image_list_proto = ImageListProto()\n        marshall_images(\n            self.dg._get_delta_path_str(),\n            image,\n            caption,\n            width,\n            image_list_proto,\n            clamp,\n            channels,\n            output_format,\n        )\n        return self.dg._enqueue(\"imgs\", image_list_proto)\n\n    @property\n    def dg(self) -> DeltaGenerator:\n        \"\"\"Get our DeltaGenerator.\"\"\"\n        return cast(\"DeltaGenerator\", self)\n\n\ndef _image_may_have_alpha_channel(image: PILImage) -> bool:\n    if image.mode in (\"RGBA\", \"LA\", \"P\"):\n        return True\n    else:\n        return False\n\n\ndef _image_is_gif(image: PILImage) -> bool:\n    return bool(image.format == \"GIF\")\n\n\ndef _validate_image_format_string(\n    image_data: bytes | PILImage, format: str\n) -> ImageFormat:\n    \"\"\"Return either \"JPEG\", \"PNG\", or \"GIF\", based on the input `format` string.\n\n    - If `format` is \"JPEG\" or \"JPG\" (or any capitalization thereof), return \"JPEG\"\n    - If `format` is \"PNG\" (or any capitalization thereof), return \"PNG\"\n    - For all other strings, return \"PNG\" if the image has an alpha channel,\n    \"GIF\" if the image is a GIF, and \"JPEG\" otherwise.\n    \"\"\"\n    format = format.upper()\n    if format == \"JPEG\" or format == \"PNG\":\n        return cast(ImageFormat, format)\n\n    # We are forgiving on the spelling of JPEG\n    if format == \"JPG\":\n        return \"JPEG\"\n\n    if isinstance(image_data, bytes):\n        from PIL import Image\n\n        pil_image = Image.open(io.BytesIO(image_data))\n    else:\n        pil_image = image_data\n\n    if _image_is_gif(pil_image):\n        return \"GIF\"\n\n    if _image_may_have_alpha_channel(pil_image):\n        return \"PNG\"\n\n    return \"JPEG\"\n\n\ndef _PIL_to_bytes(\n    image: PILImage,\n    format: ImageFormat = \"JPEG\",\n    quality: int = 100,\n) -> bytes:\n    \"\"\"Convert a PIL image to bytes.\"\"\"\n    tmp = io.BytesIO()\n\n    # User must have specified JPEG, so we must convert it\n    if format == \"JPEG\" and _image_may_have_alpha_channel(image):\n        image = image.convert(\"RGB\")\n\n    image.save(tmp, format=format, quality=quality)\n\n    return tmp.getvalue()\n\n\ndef _BytesIO_to_bytes(data: io.BytesIO) -> bytes:\n    data.seek(0)\n    return data.getvalue()\n\n\ndef _np_array_to_bytes(array: npt.NDArray[Any], output_format: str = \"JPEG\") -> bytes:\n    import numpy as np\n    from PIL import Image\n\n    img = Image.fromarray(array.astype(np.uint8))\n    format = _validate_image_format_string(img, output_format)\n\n    return _PIL_to_bytes(img, format)\n\n\ndef _4d_to_list_3d(array: npt.NDArray[Any]) -> list[npt.NDArray[Any]]:\n    return [array[i, :, :, :] for i in range(0, array.shape[0])]\n\n\ndef _verify_np_shape(array: npt.NDArray[Any]) -> npt.NDArray[Any]:\n    if len(array.shape) not in (2, 3):\n        raise StreamlitAPIException(\"Numpy shape has to be of length 2 or 3.\")\n    if len(array.shape) == 3 and array.shape[-1] not in (1, 3, 4):\n        raise StreamlitAPIException(\n            \"Channel can only be 1, 3, or 4 got %d. Shape is %s\"\n            % (array.shape[-1], str(array.shape))\n        )\n\n    # If there's only one channel, convert is to x, y\n    if len(array.shape) == 3 and array.shape[-1] == 1:\n        array = array[:, :, 0]\n\n    return array\n\n\ndef _get_image_format_mimetype(image_format: ImageFormat) -> str:\n    \"\"\"Get the mimetype string for the given ImageFormat.\"\"\"\n    return f\"image/{image_format.lower()}\"\n\n\ndef _ensure_image_size_and_format(\n    image_data: bytes, width: int, image_format: ImageFormat\n) -> bytes:\n    \"\"\"Resize an image if it exceeds the given width, or if exceeds\n    MAXIMUM_CONTENT_WIDTH. Ensure the image's format corresponds to the given\n    ImageFormat. Return the (possibly resized and reformatted) image bytes.\n    \"\"\"\n    from PIL import Image\n\n    pil_image = Image.open(io.BytesIO(image_data))\n    actual_width, actual_height = pil_image.size\n\n    if width < 0 and actual_width > MAXIMUM_CONTENT_WIDTH:\n        width = MAXIMUM_CONTENT_WIDTH\n\n    if width > 0 and actual_width > width:\n        # We need to resize the image.\n        new_height = int(1.0 * actual_height * width / actual_width)\n        # pillow reexports Image.Resampling.BILINEAR as Image.BILINEAR for backwards\n        # compatibility reasons, so we use the reexport to support older pillow\n        # versions. The types don't seem to reflect this, though, hence the type: ignore\n        # below.\n        pil_image = pil_image.resize((width, new_height), resample=Image.BILINEAR)  # type: ignore[attr-defined]\n        return _PIL_to_bytes(pil_image, format=image_format, quality=90)\n\n    if pil_image.format != image_format:\n        # We need to reformat the image.\n        return _PIL_to_bytes(pil_image, format=image_format, quality=90)\n\n    # No resizing or reformatting necessary - return the original bytes.\n    return image_data\n\n\ndef _clip_image(image: npt.NDArray[Any], clamp: bool) -> npt.NDArray[Any]:\n    import numpy as np\n\n    data = image\n    if issubclass(image.dtype.type, np.floating):\n        if clamp:\n            data = np.clip(image, 0, 1.0)\n        else:\n            if np.amin(image) < 0.0 or np.amax(image) > 1.0:\n                raise RuntimeError(\"Data is outside [0.0, 1.0] and clamp is not set.\")\n        data = data * 255\n    else:\n        if clamp:\n            data = np.clip(image, 0, 255)\n        else:\n            if np.amin(image) < 0 or np.amax(image) > 255:\n                raise RuntimeError(\"Data is outside [0, 255] and clamp is not set.\")\n    return data\n\n\ndef image_to_url(\n    image: AtomicImage,\n    width: int,\n    clamp: bool,\n    channels: Channels,\n    output_format: ImageFormatOrAuto,\n    image_id: str,\n) -> str:\n    \"\"\"Return a URL that an image can be served from.\n    If `image` is already a URL, return it unmodified.\n    Otherwise, add the image to the MediaFileManager and return the URL.\n\n    (When running in \"raw\" mode, we won't actually load data into the\n    MediaFileManager, and we'll return an empty URL.)\n    \"\"\"\n    import numpy as np\n    from PIL import Image, ImageFile\n\n    image_data: bytes\n\n    # Strings\n    if isinstance(image, str):\n        if not os.path.isfile(image) and url_util.is_url(\n            image, allowed_schemas=(\"http\", \"https\", \"data\")\n        ):\n            # If it's a url, return it directly.\n            return image\n\n        if image.endswith(\".svg\") and os.path.isfile(image):\n            # Unpack local SVG image file to an SVG string\n            with open(image) as textfile:\n                image = textfile.read()\n\n        # Following regex allows svg image files to start either via a \"<?xml...>\" tag\n        # eventually followed by a \"<svg...>\" tag or directly starting with a \"<svg>\" tag\n        if re.search(r\"(^\\s?(<\\?xml[\\s\\S]*<svg\\s)|^\\s?<svg\\s|^\\s?<svg>\\s)\", image):\n            if \"xmlns\" not in image:\n                # The xmlns attribute is required for SVGs to render in an img tag.\n                # If it's not present, we add to the first SVG tag:\n                image = image.replace(\n                    \"<svg\", '<svg xmlns=\"http://www.w3.org/2000/svg\" ', 1\n                )\n            # Convert to base64 to prevent issues with encoding:\n            import base64\n\n            image_b64_encoded = base64.b64encode(image.encode(\"utf-8\")).decode(\"utf-8\")\n            # Return SVG as data URI:\n            return f\"data:image/svg+xml;base64,{image_b64_encoded}\"\n\n        # Otherwise, try to open it as a file.\n        try:\n            with open(image, \"rb\") as f:\n                image_data = f.read()\n        except Exception:\n            # When we aren't able to open the image file, we still pass the path to\n            # the MediaFileManager - its storage backend may have access to files\n            # that Streamlit does not.\n            import mimetypes\n\n            mimetype, _ = mimetypes.guess_type(image)\n            if mimetype is None:\n                mimetype = \"application/octet-stream\"\n\n            url = runtime.get_instance().media_file_mgr.add(image, mimetype, image_id)\n            caching.save_media_data(image, mimetype, image_id)\n            return url\n\n    # PIL Images\n    elif isinstance(image, (ImageFile.ImageFile, Image.Image)):\n        format = _validate_image_format_string(image, output_format)\n        image_data = _PIL_to_bytes(image, format)\n\n    # BytesIO\n    # Note: This doesn't support SVG. We could convert to png (cairosvg.svg2png)\n    # or just decode BytesIO to string and handle that way.\n    elif isinstance(image, io.BytesIO):\n        image_data = _BytesIO_to_bytes(image)\n\n    # Numpy Arrays (ie opencv)\n    elif isinstance(image, np.ndarray):\n        image = _clip_image(\n            _verify_np_shape(image),\n            clamp,\n        )\n\n        if channels == \"BGR\":\n            if len(image.shape) == 3:\n                image = image[:, :, [2, 1, 0]]\n            else:\n                raise StreamlitAPIException(\n                    'When using `channels=\"BGR\"`, the input image should '\n                    \"have exactly 3 color channels\"\n                )\n\n        # Depending on the version of numpy that the user has installed, the\n        # typechecker may not be able to deduce that indexing into a\n        # `npt.NDArray[Any]` returns a `npt.NDArray[Any]`, so we need to\n        # ignore redundant casts below.\n        image_data = _np_array_to_bytes(\n            array=cast(\"npt.NDArray[Any]\", image),  # type: ignore[redundant-cast]\n            output_format=output_format,\n        )\n\n    # Raw bytes\n    else:\n        image_data = image\n\n    # Determine the image's format, resize it, and get its mimetype\n    image_format = _validate_image_format_string(image_data, output_format)\n    image_data = _ensure_image_size_and_format(image_data, width, image_format)\n    mimetype = _get_image_format_mimetype(image_format)\n\n    if runtime.exists():\n        url = runtime.get_instance().media_file_mgr.add(image_data, mimetype, image_id)\n        caching.save_media_data(image_data, mimetype, image_id)\n        return url\n    else:\n        # When running in \"raw mode\", we can't access the MediaFileManager.\n        return \"\"\n\n\ndef marshall_images(\n    coordinates: str,\n    image: ImageOrImageList,\n    caption: str | npt.NDArray[Any] | list[str] | None,\n    width: int | WidthBehaviour,\n    proto_imgs: ImageListProto,\n    clamp: bool,\n    channels: Channels = \"RGB\",\n    output_format: ImageFormatOrAuto = \"auto\",\n) -> None:\n    \"\"\"Fill an ImageListProto with a list of images and their captions.\n\n    The images will be resized and reformatted as necessary.\n\n    Parameters\n    ----------\n    coordinates\n        A string indentifying the images' location in the frontend.\n    image\n        The image or images to include in the ImageListProto.\n    caption\n        Image caption. If displaying multiple images, caption should be a\n        list of captions (one for each image).\n    width\n        The desired width of the image or images. This parameter will be\n        passed to the frontend.\n        Positive values set the image width explicitly.\n        Negative values has some special. For details, see: `WidthBehaviour`\n    proto_imgs\n        The ImageListProto to fill in.\n    clamp\n        Clamp image pixel values to a valid range ([0-255] per channel).\n        This is only meaningful for byte array images; the parameter is\n        ignored for image URLs. If this is not set, and an image has an\n        out-of-range value, an error will be thrown.\n    channels\n        If image is an nd.array, this parameter denotes the format used to\n        represent color information. Defaults to 'RGB', meaning\n        `image[:, :, 0]` is the red channel, `image[:, :, 1]` is green, and\n        `image[:, :, 2]` is blue. For images coming from libraries like\n        OpenCV you should set this to 'BGR', instead.\n    output_format\n        This parameter specifies the format to use when transferring the\n        image data. Photos should use the JPEG format for lossy compression\n        while diagrams should use the PNG format for lossless compression.\n        Defaults to 'auto' which identifies the compression type based\n        on the type and format of the image argument.\n    \"\"\"\n    import numpy as np\n\n    channels = cast(Channels, channels.upper())\n\n    # Turn single image and caption into one element list.\n    images: Sequence[AtomicImage]\n    if isinstance(image, list):\n        images = image\n    elif isinstance(image, np.ndarray) and len(image.shape) == 4:\n        images = _4d_to_list_3d(image)\n    else:\n        images = [image]\n\n    if isinstance(caption, list):\n        captions: Sequence[str | None] = caption\n    else:\n        if isinstance(caption, str):\n            captions = [caption]\n        # You can pass in a 1-D Numpy array as captions.\n        elif isinstance(caption, np.ndarray) and len(caption.shape) == 1:\n            captions = caption.tolist()\n        # If there are no captions then make the captions list the same size\n        # as the images list.\n        elif caption is None:\n            captions = [None] * len(images)\n        else:\n            captions = [str(caption)]\n\n    assert isinstance(\n        captions, list\n    ), \"If image is a list then caption should be as well\"\n    assert len(captions) == len(images), \"Cannot pair %d captions with %d images.\" % (\n        len(captions),\n        len(images),\n    )\n\n    proto_imgs.width = int(width)\n    # Each image in an image list needs to be kept track of at its own coordinates.\n    for coord_suffix, (image, caption) in enumerate(zip(images, captions)):\n        proto_img = proto_imgs.imgs.add()\n        if caption is not None:\n            proto_img.caption = str(caption)\n\n        # We use the index of the image in the input image list to identify this image inside\n        # MediaFileManager. For this, we just add the index to the image's \"coordinates\".\n        image_id = \"%s-%i\" % (coordinates, coord_suffix)\n\n        proto_img.url = image_to_url(\n            image, width, clamp, channels, output_format, image_id\n        )\n", "lib/streamlit/elements/media.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport io\nimport re\nfrom datetime import timedelta\nfrom pathlib import Path\nfrom typing import TYPE_CHECKING, Dict, Final, Union, cast\n\nfrom typing_extensions import TypeAlias\n\nimport streamlit as st\nfrom streamlit import runtime, type_util, url_util\nfrom streamlit.elements.lib.subtitle_utils import process_subtitle_data\nfrom streamlit.errors import StreamlitAPIException\nfrom streamlit.proto.Audio_pb2 import Audio as AudioProto\nfrom streamlit.proto.Video_pb2 import Video as VideoProto\nfrom streamlit.runtime import caching\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.runtime.scriptrunner import get_script_run_ctx\nfrom streamlit.runtime.state.common import compute_widget_id\nfrom streamlit.time_util import time_to_seconds\n\nif TYPE_CHECKING:\n    from typing import Any\n\n    from numpy import typing as npt\n\n    from streamlit.delta_generator import DeltaGenerator\n\nMediaData: TypeAlias = Union[\n    str, bytes, io.BytesIO, io.RawIOBase, io.BufferedReader, \"npt.NDArray[Any]\", None\n]\n\nSubtitleData: TypeAlias = Union[\n    str, Path, bytes, io.BytesIO, Dict[str, Union[str, Path, bytes, io.BytesIO]], None\n]\n\nMediaTime: TypeAlias = Union[int, float, timedelta, str]\n\nTIMEDELTA_PARSE_ERROR_MESSAGE: Final = (\n    \"Failed to convert '{param_name}' to a timedelta. \"\n    \"Please use a string in a format supported by \"\n    \"[Pandas Timedelta constructor]\"\n    \"(https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.html), \"\n    'e.g. `\"10s\"`, `\"15 seconds\"`, or `\"1h23s\"`. Got: {param_value}'\n)\n\n\nclass MediaMixin:\n    @gather_metrics(\"audio\")\n    def audio(\n        self,\n        data: MediaData,\n        format: str = \"audio/wav\",\n        start_time: MediaTime = 0,\n        *,\n        sample_rate: int | None = None,\n        end_time: MediaTime | None = None,\n        loop: bool = False,\n        autoplay: bool = False,\n    ) -> DeltaGenerator:\n        \"\"\"Display an audio player.\n\n        Parameters\n        ----------\n        data : str, bytes, BytesIO, numpy.ndarray, or file\n            Raw audio data, filename, or a URL pointing to the file to load.\n            Raw data formats must include all necessary file headers to match the file\n            format specified via ``format``.\n            If ``data`` is a numpy array, it must either be a 1D array of the waveform\n            or a 2D array of shape ``(num_channels, num_samples)`` with waveforms\n            for all channels. See the default channel order at\n            http://msdn.microsoft.com/en-us/library/windows/hardware/dn653308(v=vs.85).aspx\n\n        format : str\n            The mime type for the audio file. Defaults to ``\"audio/wav\"``.\n            See https://tools.ietf.org/html/rfc4281 for more info.\n\n        start_time: int, float, timedelta, str, or None\n            The time from which the element should start playing. This can be\n            one of the following:\n\n            * ``None`` (default): The element plays from the beginning.\n            * An``int`` or ``float`` specifying the time in seconds. ``float``\n              values are rounded down to whole seconds.\n            * A string specifying the time in a format supported by `Pandas'\n              Timedelta constructor <https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.html>`_,\n              e.g. ``\"2 minute\"``, ``\"20s\"``, or ``\"1m14s\"``.\n            * A ``timedelta`` object from `Python's built-in datetime library\n              <https://docs.python.org/3/library/datetime.html#timedelta-objects>`_,\n              e.g. ``timedelta(seconds=70)``.\n        sample_rate: int or None\n            The sample rate of the audio data in samples per second. Only required if\n            ``data`` is a numpy array.\n        end_time: int, float, timedelta, str, or None\n            The time at which the element should stop playing. This can be\n            one of the following:\n\n            * ``None`` (default): The element plays through to the end.\n            * An ``int`` or ``float`` specifying the time in seconds. ``float``\n              values are rounded down to whole seconds.\n            * A string specifying the time in a format supported by `Pandas'\n              Timedelta constructor <https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.html>`_,\n              e.g. ``\"2 minute\"``, ``\"20s\"``, or ``\"1m14s\"``.\n            * A ``timedelta`` object from `Python's built-in datetime library\n              <https://docs.python.org/3/library/datetime.html#timedelta-objects>`_,\n              e.g. ``timedelta(seconds=70)``.\n        loop: bool\n            Whether the audio should loop playback.\n        autoplay: bool\n            Whether the audio file should start playing automatically. This is\n            ``False`` by default. Browsers will not autoplay audio files if the\n            user has not interacted with the page by clicking somewhere.\n\n        Examples\n        --------\n        To display an audio player for a local file, specify the file's string\n        path and format.\n\n        >>> import streamlit as st\n        >>>\n        >>> st.audio(\"cat-purr.mp3\", format=\"audio/mpeg\", loop=True)\n\n        .. output::\n           https://doc-audio-purr.streamlit.app/\n           height: 250px\n\n        You can also pass ``bytes`` or ``numpy.ndarray`` objects to ``st.audio``.\n\n        >>> import streamlit as st\n        >>> import numpy as np\n        >>>\n        >>> audio_file = open(\"myaudio.ogg\", \"rb\")\n        >>> audio_bytes = audio_file.read()\n        >>>\n        >>> st.audio(audio_bytes, format=\"audio/ogg\")\n        >>>\n        >>> sample_rate = 44100  # 44100 samples per second\n        >>> seconds = 2  # Note duration of 2 seconds\n        >>> frequency_la = 440  # Our played note will be 440 Hz\n        >>> # Generate array with seconds*sample_rate steps, ranging between 0 and seconds\n        >>> t = np.linspace(0, seconds, seconds * sample_rate, False)\n        >>> # Generate a 440 Hz sine wave\n        >>> note_la = np.sin(frequency_la * t * 2 * np.pi)\n        >>>\n        >>> st.audio(note_la, sample_rate=sample_rate)\n\n        .. output::\n           https://doc-audio.streamlit.app/\n           height: 865px\n\n        \"\"\"\n        start_time, end_time = _parse_start_time_end_time(start_time, end_time)\n\n        audio_proto = AudioProto()\n        coordinates = self.dg._get_delta_path_str()\n\n        is_data_numpy_array = type_util.is_type(data, \"numpy.ndarray\")\n\n        if is_data_numpy_array and sample_rate is None:\n            raise StreamlitAPIException(\n                \"`sample_rate` must be specified when `data` is a numpy array.\"\n            )\n        if not is_data_numpy_array and sample_rate is not None:\n            st.warning(\n                \"Warning: `sample_rate` will be ignored since data is not a numpy \"\n                \"array.\"\n            )\n\n        marshall_audio(\n            coordinates,\n            audio_proto,\n            data,\n            format,\n            start_time,\n            sample_rate,\n            end_time,\n            loop,\n            autoplay,\n        )\n        return self.dg._enqueue(\"audio\", audio_proto)\n\n    @gather_metrics(\"video\")\n    def video(\n        self,\n        data: MediaData,\n        format: str = \"video/mp4\",\n        start_time: MediaTime = 0,\n        *,  # keyword-only arguments:\n        subtitles: SubtitleData = None,\n        end_time: MediaTime | None = None,\n        loop: bool = False,\n        autoplay: bool = False,\n        muted: bool = False,\n    ) -> DeltaGenerator:\n        \"\"\"Display a video player.\n\n        Parameters\n        ----------\n        data : str, bytes, io.BytesIO, numpy.ndarray, or file\n            Raw video data, filename, or URL pointing to a video to load.\n            Includes support for YouTube URLs.\n            Numpy arrays and raw data formats must include all necessary file\n            headers to match specified file format.\n\n        format : str\n            The mime type for the video file. Defaults to ``\"video/mp4\"``.\n            See https://tools.ietf.org/html/rfc4281 for more info.\n\n        start_time: int, float, timedelta, str, or None\n            The time from which the element should start playing. This can be\n            one of the following:\n\n            * ``None`` (default): The element plays from the beginning.\n            * An ``int`` or ``float`` specifying the time in seconds. ``float``\n              values are rounded down to whole seconds.\n            * A string specifying the time in a format supported by `Pandas'\n              Timedelta constructor <https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.html>`_,\n              e.g. ``\"2 minute\"``, ``\"20s\"``, or ``\"1m14s\"``.\n            * A ``timedelta`` object from `Python's built-in datetime library\n              <https://docs.python.org/3/library/datetime.html#timedelta-objects>`_,\n              e.g. ``timedelta(seconds=70)``.\n        subtitles: str, bytes, Path, io.BytesIO, or dict\n            Optional subtitle data for the video, supporting several input types:\n\n            * ``None`` (default): No subtitles.\n\n            * A string, bytes, or Path: File path to a subtitle file in ``.vtt`` or ``.srt`` formats, or\n              the raw content of subtitles conforming to these formats.\n              If providing raw content, the string must adhere to the WebVTT or SRT\n              format specifications.\n\n            * io.BytesIO: A BytesIO stream that contains valid ``.vtt`` or ``.srt``\n              formatted subtitle data.\n\n            * A dictionary: Pairs of labels and file paths or raw subtitle content in\n              ``.vtt`` or ``.srt`` formats to enable multiple subtitle tracks.\n              The label will be shown in the video player. Example:\n              ``{\"English\": \"path/to/english.vtt\", \"French\": \"path/to/french.srt\"}``\n\n            When provided, subtitles are displayed by default. For multiple\n            tracks, the first one is displayed by default. If you don't want any\n            subtitles displayed by default, use an empty string for the value\n            in a dictrionary's first pair: ``{\"None\": \"\", \"English\": \"path/to/english.vtt\"}``\n\n            Not supported for YouTube videos.\n        end_time: int, float, timedelta, str, or None\n            The time at which the element should stop playing. This can be\n            one of the following:\n\n            * ``None`` (default): The element plays through to the end.\n            * An ``int`` or ``float`` specifying the time in seconds. ``float``\n              values are rounded down to whole seconds.\n            * A string specifying the time in a format supported by `Pandas'\n              Timedelta constructor <https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.html>`_,\n              e.g. ``\"2 minute\"``, ``\"20s\"``, or ``\"1m14s\"``.\n            * A ``timedelta`` object from `Python's built-in datetime library\n              <https://docs.python.org/3/library/datetime.html#timedelta-objects>`_,\n              e.g. ``timedelta(seconds=70)``.\n        loop: bool\n            Whether the video should loop playback.\n        autoplay: bool\n            Whether the video should start playing automatically. This is\n            ``False`` by default. Browsers will not autoplay unmuted videos\n            if the user has not interacted with the page by clicking somewhere.\n            To enable autoplay without user interaction, you must also set\n            ``muted=True``.\n        muted: bool\n            Whether the video should play with the audio silenced. This is\n            ``False`` by default. Use this in conjunction with ``autoplay=True``\n            to enable autoplay without user interaction.\n\n        Example\n        -------\n        >>> import streamlit as st\n        >>>\n        >>> video_file = open('myvideo.mp4', 'rb')\n        >>> video_bytes = video_file.read()\n        >>>\n        >>> st.video(video_bytes)\n\n        .. output::\n           https://doc-video.streamlit.app/\n           height: 700px\n\n        When you include subtitles, they will be turned on by default. A viewer\n        can turn off the subtitles (or captions) from the browser's default video\n        control menu, usually located in the lower-right corner of the video.\n\n        Here is a simple VTT file (``subtitles.vtt``):\n\n        >>> WEBVTT\n        >>>\n        >>> 0:00:01.000 --> 0:00:02.000\n        >>> Look!\n        >>>\n        >>> 0:00:03.000 --> 0:00:05.000\n        >>> Look at the pretty stars!\n\n        If the above VTT file lives in the same directory as your app, you can\n        add subtitles like so:\n\n        >>> import streamlit as st\n        >>>\n        >>> VIDEO_URL = \"https://example.com/not-youtube.mp4\"\n        >>> st.video(VIDEO_URL, subtitles=\"subtitles.vtt\")\n\n        .. output::\n           https://doc-video-subtitles.streamlit.app/\n           height: 700px\n\n        See additional examples of supported subtitle input types in our\n        `video subtitles feature demo <https://doc-video-subtitle-inputs.streamlit.app/>`_.\n\n        .. note::\n           Some videos may not display if they are encoded using MP4V (which is an export option in OpenCV), as this codec is\n           not widely supported by browsers. Converting your video to H.264 will allow the video to be displayed in Streamlit.\n           See this `StackOverflow post <https://stackoverflow.com/a/49535220/2394542>`_ or this\n           `Streamlit forum post <https://discuss.streamlit.io/t/st-video-doesnt-show-opencv-generated-mp4/3193/2>`_\n           for more information.\n\n        \"\"\"\n        start_time, end_time = _parse_start_time_end_time(start_time, end_time)\n\n        video_proto = VideoProto()\n        coordinates = self.dg._get_delta_path_str()\n        marshall_video(\n            coordinates,\n            video_proto,\n            data,\n            format,\n            start_time,\n            subtitles,\n            end_time,\n            loop,\n            autoplay,\n            muted,\n        )\n        return self.dg._enqueue(\"video\", video_proto)\n\n    @property\n    def dg(self) -> DeltaGenerator:\n        \"\"\"Get our DeltaGenerator.\"\"\"\n        return cast(\"DeltaGenerator\", self)\n\n\n# Regular expression from\n# https://gist.github.com/rodrigoborgesdeoliveira/987683cfbfcc8d800192da1e73adc486?permalink_comment_id=4645864#gistcomment-4645864\n# Covers any youtube URL (incl. shortlinks and embed links) and extracts its video code.\nYOUTUBE_RE: Final = r\"^((https?://(?:www\\.)?(?:m\\.)?youtube\\.com))/((?:oembed\\?url=https?%3A//(?:www\\.)youtube.com/watch\\?(?:v%3D)(?P<video_id_1>[\\w\\-]{10,20})&format=json)|(?:attribution_link\\?a=.*watch(?:%3Fv%3D|%3Fv%3D)(?P<video_id_2>[\\w\\-]{10,20}))(?:%26feature.*))|(https?:)?(\\/\\/)?((www\\.|m\\.)?youtube(-nocookie)?\\.com\\/((watch)?\\?(app=desktop&)?(feature=\\w*&)?v=|embed\\/|v\\/|e\\/)|youtu\\.be\\/)(?P<video_id_3>[\\w\\-]{10,20})\"\n\n\ndef _reshape_youtube_url(url: str) -> str | None:\n    \"\"\"Return whether URL is any kind of YouTube embed or watch link.  If so,\n    reshape URL into an embed link suitable for use in an iframe.\n\n    If not a YouTube URL, return None.\n\n    Parameters\n    ----------\n        url : str\n\n    Example\n    -------\n    >>> print(_reshape_youtube_url('https://youtu.be/_T8LGqJtuGc'))\n\n    .. output::\n        https://www.youtube.com/embed/_T8LGqJtuGc\n    \"\"\"\n    match = re.match(YOUTUBE_RE, url)\n    if match:\n        code = (\n            match.group(\"video_id_1\")\n            or match.group(\"video_id_2\")\n            or match.group(\"video_id_3\")\n        )\n        return f\"https://www.youtube.com/embed/{code}\"\n    return None\n\n\ndef _marshall_av_media(\n    coordinates: str,\n    proto: AudioProto | VideoProto,\n    data: MediaData,\n    mimetype: str,\n) -> None:\n    \"\"\"Fill audio or video proto based on contents of data.\n\n    Given a string, check if it's a url; if so, send it out without modification.\n    Otherwise assume strings are filenames and let any OS errors raise.\n\n    Load data either from file or through bytes-processing methods into a\n    MediaFile object.  Pack proto with generated Tornado-based URL.\n\n    (When running in \"raw\" mode, we won't actually load data into the\n    MediaFileManager, and we'll return an empty URL.)\n    \"\"\"\n    # Audio and Video methods have already checked if this is a URL by this point.\n\n    if data is None:\n        # Allow empty values so media players can be shown without media.\n        return\n\n    data_or_filename: bytes | str\n    if isinstance(data, (str, bytes)):\n        # Pass strings and bytes through unchanged\n        data_or_filename = data\n    elif isinstance(data, io.BytesIO):\n        data.seek(0)\n        data_or_filename = data.getvalue()\n    elif isinstance(data, io.RawIOBase) or isinstance(data, io.BufferedReader):\n        data.seek(0)\n        read_data = data.read()\n        if read_data is None:\n            return\n        else:\n            data_or_filename = read_data\n    elif type_util.is_type(data, \"numpy.ndarray\"):\n        data_or_filename = data.tobytes()\n    else:\n        raise RuntimeError(\"Invalid binary data format: %s\" % type(data))\n\n    if runtime.exists():\n        file_url = runtime.get_instance().media_file_mgr.add(\n            data_or_filename, mimetype, coordinates\n        )\n        caching.save_media_data(data_or_filename, mimetype, coordinates)\n    else:\n        # When running in \"raw mode\", we can't access the MediaFileManager.\n        file_url = \"\"\n\n    proto.url = file_url\n\n\ndef marshall_video(\n    coordinates: str,\n    proto: VideoProto,\n    data: MediaData,\n    mimetype: str = \"video/mp4\",\n    start_time: int = 0,\n    subtitles: SubtitleData = None,\n    end_time: int | None = None,\n    loop: bool = False,\n    autoplay: bool = False,\n    muted: bool = False,\n) -> None:\n    \"\"\"Marshalls a video proto, using url processors as needed.\n\n    Parameters\n    ----------\n    coordinates : str\n    proto : the proto to fill. Must have a string field called \"data\".\n    data : str, bytes, BytesIO, numpy.ndarray, or file opened with\n           io.open().\n        Raw video data or a string with a URL pointing to the video\n        to load. Includes support for YouTube URLs.\n        If passing the raw data, this must include headers and any other\n        bytes required in the actual file.\n    mimetype : str\n        The mime type for the video file. Defaults to 'video/mp4'.\n        See https://tools.ietf.org/html/rfc4281 for more info.\n    start_time : int\n        The time from which this element should start playing. (default: 0)\n    subtitles: str, dict, or io.BytesIO\n        Optional subtitle data for the video, supporting several input types:\n        * None (default): No subtitles.\n        * A string: File path to a subtitle file in '.vtt' or '.srt' formats, or the raw content of subtitles conforming to these formats.\n            If providing raw content, the string must adhere to the WebVTT or SRT format specifications.\n        * A dictionary: Pairs of labels and file paths or raw subtitle content in '.vtt' or '.srt' formats.\n            Enables multiple subtitle tracks. The label will be shown in the video player.\n            Example: {'English': 'path/to/english.vtt', 'French': 'path/to/french.srt'}\n        * io.BytesIO: A BytesIO stream that contains valid '.vtt' or '.srt' formatted subtitle data.\n        When provided, subtitles are displayed by default. For multiple tracks, the first one is displayed by default.\n        Not supported for YouTube videos.\n    end_time: int\n            The time at which this element should stop playing\n    loop: bool\n        Whether the video should loop playback.\n    autoplay: bool\n        Whether the video should start playing automatically.\n        Browsers will not autoplay video files if the user has not interacted with\n        the page yet, for example by clicking on the page while it loads.\n        To enable autoplay without user interaction, you can set muted=True.\n        Defaults to False.\n    muted: bool\n        Whether the video should play with the audio silenced. This can be used to\n        enable autoplay without user interaction. Defaults to False.\n    \"\"\"\n\n    if start_time < 0 or (end_time is not None and end_time <= start_time):\n        raise StreamlitAPIException(\"Invalid start_time and end_time combination.\")\n\n    proto.start_time = start_time\n    proto.muted = muted\n\n    if end_time is not None:\n        proto.end_time = end_time\n    proto.loop = loop\n\n    # \"type\" distinguishes between YouTube and non-YouTube links\n    proto.type = VideoProto.Type.NATIVE\n\n    if isinstance(data, str) and url_util.is_url(\n        data, allowed_schemas=(\"http\", \"https\", \"data\")\n    ):\n        if youtube_url := _reshape_youtube_url(data):\n            proto.url = youtube_url\n            proto.type = VideoProto.Type.YOUTUBE_IFRAME\n            if subtitles:\n                raise StreamlitAPIException(\n                    \"Subtitles are not supported for YouTube videos.\"\n                )\n        else:\n            proto.url = data\n\n    else:\n        _marshall_av_media(coordinates, proto, data, mimetype)\n\n    if subtitles:\n        subtitle_items: list[tuple[str, str | Path | bytes | io.BytesIO]] = []\n\n        # Single subtitle\n        if isinstance(subtitles, (str, bytes, io.BytesIO, Path)):\n            subtitle_items.append((\"default\", subtitles))\n        # Multiple subtitles\n        elif isinstance(subtitles, dict):\n            subtitle_items.extend(subtitles.items())\n        else:\n            raise StreamlitAPIException(\n                f\"Unsupported data type for subtitles: {type(subtitles)}. \"\n                f\"Only str (file paths) and dict are supported.\"\n            )\n\n        for label, subtitle_data in subtitle_items:\n            sub = proto.subtitles.add()\n            sub.label = label or \"\"\n\n            # Coordinates used in media_file_manager to identify the place of\n            # element, in case of subtitle, we use same video coordinates\n            # with suffix.\n            # It is not aligned with common coordinates format, but in\n            # media_file_manager we use it just as unique identifier, so it is fine.\n            subtitle_coordinates = f\"{coordinates}[subtitle{label}]\"\n            try:\n                sub.url = process_subtitle_data(\n                    subtitle_coordinates, subtitle_data, label\n                )\n            except (TypeError, ValueError) as original_err:\n                raise StreamlitAPIException(\n                    f\"Failed to process the provided subtitle: {label}\"\n                ) from original_err\n\n    if autoplay:\n        ctx = get_script_run_ctx()\n        proto.autoplay = autoplay\n        id = compute_widget_id(\n            \"video\",\n            url=proto.url,\n            mimetype=mimetype,\n            start_time=start_time,\n            end_time=end_time,\n            loop=loop,\n            autoplay=autoplay,\n            muted=muted,\n            page=ctx.active_script_hash if ctx else None,\n        )\n\n        proto.id = id\n\n\ndef _parse_start_time_end_time(\n    start_time: MediaTime, end_time: MediaTime | None\n) -> tuple[int, int | None]:\n    \"\"\"Parse start_time and end_time and return them as int.\"\"\"\n\n    try:\n        maybe_start_time = time_to_seconds(start_time, coerce_none_to_inf=False)\n        if maybe_start_time is None:\n            raise ValueError\n        start_time = int(maybe_start_time)\n    except (StreamlitAPIException, ValueError):\n        error_msg = TIMEDELTA_PARSE_ERROR_MESSAGE.format(\n            param_name=\"start_time\", param_value=start_time\n        )\n        raise StreamlitAPIException(error_msg) from None\n\n    try:\n        end_time = time_to_seconds(end_time, coerce_none_to_inf=False)\n        if end_time is not None:\n            end_time = int(end_time)\n    except StreamlitAPIException:\n        error_msg = TIMEDELTA_PARSE_ERROR_MESSAGE.format(\n            param_name=\"end_time\", param_value=end_time\n        )\n        raise StreamlitAPIException(error_msg) from None\n\n    return start_time, end_time\n\n\ndef _validate_and_normalize(data: npt.NDArray[Any]) -> tuple[bytes, int]:\n    \"\"\"Validates and normalizes numpy array data.\n    We validate numpy array shape (should be 1d or 2d)\n    We normalize input data to int16 [-32768, 32767] range.\n\n    Parameters\n    ----------\n    data : numpy array\n        numpy array to be validated and normalized\n\n    Returns\n    -------\n    Tuple of (bytes, int)\n        (bytes, nchan)\n        where\n         - bytes : bytes of normalized numpy array converted to int16\n         - nchan : number of channels for audio signal. 1 for mono, or 2 for stereo.\n    \"\"\"\n    # we import numpy here locally to import it only when needed (when numpy array given\n    # to st.audio data)\n    import numpy as np\n\n    data: npt.NDArray[Any] = np.array(data, dtype=float)\n\n    if len(data.shape) == 1:\n        nchan = 1\n    elif len(data.shape) == 2:\n        # In wave files,channels are interleaved. E.g.,\n        # \"L1R1L2R2...\" for stereo. See\n        # http://msdn.microsoft.com/en-us/library/windows/hardware/dn653308(v=vs.85).aspx\n        # for channel ordering\n        nchan = data.shape[0]\n        data = data.T.ravel()\n    else:\n        raise StreamlitAPIException(\"Numpy array audio input must be a 1D or 2D array.\")\n\n    if data.size == 0:\n        return data.astype(np.int16).tobytes(), nchan\n\n    max_abs_value = np.max(np.abs(data))\n    # 16-bit samples are stored as 2's-complement signed integers,\n    # ranging from -32768 to 32767.\n    # scaled_data is PCM 16 bit numpy array, that's why we multiply [-1, 1] float\n    # values to 32_767 == 2 ** 15 - 1.\n    np_array = (data / max_abs_value) * 32767\n    scaled_data = np_array.astype(np.int16)\n    return scaled_data.tobytes(), nchan\n\n\ndef _make_wav(data: npt.NDArray[Any], sample_rate: int) -> bytes:\n    \"\"\"\n    Transform a numpy array to a PCM bytestring\n    We use code from IPython display module to convert numpy array to wave bytes\n    https://github.com/ipython/ipython/blob/1015c392f3d50cf4ff3e9f29beede8c1abfdcb2a/IPython/lib/display.py#L146\n    \"\"\"\n    # we import wave here locally to import it only when needed (when numpy array given\n    # to st.audio data)\n    import wave\n\n    scaled, nchan = _validate_and_normalize(data)\n\n    with io.BytesIO() as fp, wave.open(fp, mode=\"wb\") as waveobj:\n        waveobj.setnchannels(nchan)\n        waveobj.setframerate(sample_rate)\n        waveobj.setsampwidth(2)\n        waveobj.setcomptype(\"NONE\", \"NONE\")\n        waveobj.writeframes(scaled)\n        return fp.getvalue()\n\n\ndef _maybe_convert_to_wav_bytes(data: MediaData, sample_rate: int | None) -> MediaData:\n    \"\"\"Convert data to wav bytes if the data type is numpy array.\"\"\"\n    if type_util.is_type(data, \"numpy.ndarray\") and sample_rate is not None:\n        data = _make_wav(cast(\"npt.NDArray[Any]\", data), sample_rate)\n    return data\n\n\ndef marshall_audio(\n    coordinates: str,\n    proto: AudioProto,\n    data: MediaData,\n    mimetype: str = \"audio/wav\",\n    start_time: int = 0,\n    sample_rate: int | None = None,\n    end_time: int | None = None,\n    loop: bool = False,\n    autoplay: bool = False,\n) -> None:\n    \"\"\"Marshalls an audio proto, using data and url processors as needed.\n\n    Parameters\n    ----------\n    coordinates : str\n    proto : The proto to fill. Must have a string field called \"url\".\n    data : str, bytes, BytesIO, numpy.ndarray, or file opened with\n            io.open()\n        Raw audio data or a string with a URL pointing to the file to load.\n        If passing the raw data, this must include headers and any other bytes\n        required in the actual file.\n    mimetype : str\n        The mime type for the audio file. Defaults to \"audio/wav\".\n        See https://tools.ietf.org/html/rfc4281 for more info.\n    start_time : int\n        The time from which this element should start playing. (default: 0)\n    sample_rate: int or None\n        Optional param to provide sample_rate in case of numpy array\n    end_time: int\n        The time at which this element should stop playing\n    loop: bool\n        Whether the audio should loop playback.\n    autoplay : bool\n        Whether the audio should start playing automatically.\n        Browsers will not autoplay audio files if the user has not interacted with the page yet.\n    \"\"\"\n\n    proto.start_time = start_time\n    if end_time is not None:\n        proto.end_time = end_time\n    proto.loop = loop\n\n    if isinstance(data, str) and url_util.is_url(\n        data, allowed_schemas=(\"http\", \"https\", \"data\")\n    ):\n        proto.url = data\n\n    else:\n        data = _maybe_convert_to_wav_bytes(data, sample_rate)\n        _marshall_av_media(coordinates, proto, data, mimetype)\n\n    if autoplay:\n        ctx = get_script_run_ctx()\n        proto.autoplay = autoplay\n        id = compute_widget_id(\n            \"audio\",\n            url=proto.url,\n            mimetype=mimetype,\n            start_time=start_time,\n            sample_rate=sample_rate,\n            end_time=end_time,\n            loop=loop,\n            autoplay=autoplay,\n            page=ctx.active_script_hash if ctx else None,\n        )\n        proto.id = id\n", "lib/streamlit/elements/balloons.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom typing import TYPE_CHECKING, cast\n\nfrom streamlit.proto.Balloons_pb2 import Balloons as BalloonsProto\nfrom streamlit.runtime.metrics_util import gather_metrics\n\nif TYPE_CHECKING:\n    from streamlit.delta_generator import DeltaGenerator\n\n\nclass BalloonsMixin:\n    @gather_metrics(\"balloons\")\n    def balloons(self) -> DeltaGenerator:\n        \"\"\"Draw celebratory balloons.\n\n        Example\n        -------\n        >>> import streamlit as st\n        >>>\n        >>> st.balloons()\n\n        ...then watch your app and get ready for a celebration!\n\n        \"\"\"\n        balloons_proto = BalloonsProto()\n        balloons_proto.show = True\n        return self.dg._enqueue(\"balloons\", balloons_proto)\n\n    @property\n    def dg(self) -> DeltaGenerator:\n        \"\"\"Get our DeltaGenerator.\"\"\"\n        return cast(\"DeltaGenerator\", self)\n", "lib/streamlit/elements/pyplot.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Streamlit support for Matplotlib PyPlot charts.\"\"\"\n\nfrom __future__ import annotations\n\nimport io\nfrom typing import TYPE_CHECKING, Any, cast\n\nimport streamlit.elements.image as image_utils\nfrom streamlit import config\nfrom streamlit.errors import StreamlitDeprecationWarning\nfrom streamlit.proto.Image_pb2 import ImageList as ImageListProto\nfrom streamlit.runtime.metrics_util import gather_metrics\n\nif TYPE_CHECKING:\n    from matplotlib.figure import Figure\n\n    from streamlit.delta_generator import DeltaGenerator\n\n\nclass PyplotMixin:\n    @gather_metrics(\"pyplot\")\n    def pyplot(\n        self,\n        fig: Figure | None = None,\n        clear_figure: bool | None = None,\n        use_container_width: bool = True,\n        **kwargs: Any,\n    ) -> DeltaGenerator:\n        \"\"\"Display a matplotlib.pyplot figure.\n\n        Parameters\n        ----------\n        fig : Matplotlib Figure\n            The figure to plot. When this argument isn't specified, this\n            function will render the global figure (but this is deprecated,\n            as described below)\n\n        clear_figure : bool\n            If True, the figure will be cleared after being rendered.\n            If False, the figure will not be cleared after being rendered.\n            If left unspecified, we pick a default based on the value of ``fig``.\n\n            * If ``fig`` is set, defaults to ``False``.\n\n            * If ``fig`` is not set, defaults to ``True``. This simulates Jupyter's\n              approach to matplotlib rendering.\n\n        use_container_width : bool\n            Whether to override the figure's native width with the width of\n            the parent container. If ``use_container_width`` is ``True``\n            (default), Streamlit sets the width of the figure to match the\n            width of the parent container. If ``use_container_width`` is\n            ``False``, Streamlit sets the width of the chart to fit its\n            contents according to the plotting library, up to the width of the\n            parent container.\n\n        **kwargs : any\n            Arguments to pass to Matplotlib's savefig function.\n\n        Example\n        -------\n        >>> import streamlit as st\n        >>> import matplotlib.pyplot as plt\n        >>> import numpy as np\n        >>>\n        >>> arr = np.random.normal(1, 1, size=100)\n        >>> fig, ax = plt.subplots()\n        >>> ax.hist(arr, bins=20)\n        >>>\n        >>> st.pyplot(fig)\n\n        .. output::\n           https://doc-pyplot.streamlit.app/\n           height: 630px\n\n        Notes\n        -----\n        .. note::\n           Deprecation warning. After December 1st, 2020, we will remove the ability\n           to specify no arguments in `st.pyplot()`, as that requires the use of\n           Matplotlib's global figure object, which is not thread-safe. So\n           please always pass a figure object as shown in the example section\n           above.\n\n        Matplotlib supports several types of \"backends\". If you're getting an\n        error using Matplotlib with Streamlit, try setting your backend to \"TkAgg\"::\n\n            echo \"backend: TkAgg\" >> ~/.matplotlib/matplotlibrc\n\n        For more information, see https://matplotlib.org/faq/usage_faq.html.\n\n        \"\"\"\n\n        if not fig and config.get_option(\"deprecation.showPyplotGlobalUse\"):\n            self.dg.exception(PyplotGlobalUseWarning())\n\n        image_list_proto = ImageListProto()\n        marshall(\n            self.dg._get_delta_path_str(),\n            image_list_proto,\n            fig,\n            clear_figure,\n            use_container_width,\n            **kwargs,\n        )\n        return self.dg._enqueue(\"imgs\", image_list_proto)\n\n    @property\n    def dg(self) -> DeltaGenerator:\n        \"\"\"Get our DeltaGenerator.\"\"\"\n        return cast(\"DeltaGenerator\", self)\n\n\ndef marshall(\n    coordinates: str,\n    image_list_proto: ImageListProto,\n    fig: Figure | None = None,\n    clear_figure: bool | None = True,\n    use_container_width: bool = True,\n    **kwargs: Any,\n) -> None:\n    try:\n        import matplotlib.pyplot as plt\n\n        plt.ioff()\n    except ImportError:\n        raise ImportError(\"pyplot() command requires matplotlib\")\n\n    # You can call .savefig() on a Figure object or directly on the pyplot\n    # module, in which case you're doing it to the latest Figure.\n    if not fig:\n        if clear_figure is None:\n            clear_figure = True\n\n        fig = cast(\"Figure\", plt)\n\n    # Normally, dpi is set to 'figure', and the figure's dpi is set to 100.\n    # So here we pick double of that to make things look good in a high\n    # DPI display.\n    options = {\"bbox_inches\": \"tight\", \"dpi\": 200, \"format\": \"png\"}\n\n    # If some options are passed in from kwargs then replace the values in\n    # options with the ones from kwargs\n    options = {a: kwargs.get(a, b) for a, b in options.items()}\n    # Merge options back into kwargs.\n    kwargs.update(options)\n\n    image = io.BytesIO()\n    fig.savefig(image, **kwargs)\n    image_width = (\n        image_utils.WidthBehaviour.COLUMN\n        if use_container_width\n        else image_utils.WidthBehaviour.ORIGINAL\n    )\n    image_utils.marshall_images(\n        coordinates=coordinates,\n        image=image,\n        caption=None,\n        width=image_width,\n        proto_imgs=image_list_proto,\n        clamp=False,\n        channels=\"RGB\",\n        output_format=\"PNG\",\n    )\n\n    # Clear the figure after rendering it. This means that subsequent\n    # plt calls will be starting fresh.\n    if clear_figure:\n        fig.clf()\n\n\nclass PyplotGlobalUseWarning(StreamlitDeprecationWarning):\n    def __init__(self) -> None:\n        super().__init__(\n            msg=self._get_message(), config_option=\"deprecation.showPyplotGlobalUse\"\n        )\n\n    def _get_message(self) -> str:\n        return \"\"\"\nYou are calling `st.pyplot()` without any arguments. After December 1st, 2020,\nwe will remove the ability to do this as it requires the use of Matplotlib's global\nfigure object, which is not thread-safe.\n\nTo future-proof this code, you should pass in a figure as shown below:\n\n```python\n>>> fig, ax = plt.subplots()\n>>> ax.scatter([1, 2, 3], [1, 2, 3])\n>>>    ... other plotting actions ...\n>>> st.pyplot(fig)\n```\n\"\"\"\n", "lib/streamlit/elements/iframe.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom typing import TYPE_CHECKING, cast\n\nfrom streamlit.proto.IFrame_pb2 import IFrame as IFrameProto\nfrom streamlit.runtime.metrics_util import gather_metrics\n\nif TYPE_CHECKING:\n    from streamlit.delta_generator import DeltaGenerator\n\n\nclass IframeMixin:\n    @gather_metrics(\"_iframe\")\n    def _iframe(\n        self,\n        src: str,\n        width: int | None = None,\n        height: int | None = None,\n        scrolling: bool = False,\n    ) -> DeltaGenerator:\n        \"\"\"Load a remote URL in an iframe.\n\n        To use this function, import it from the ``streamlit.components.v1``\n        module.\n\n        .. warning::\n            Using ``st.components.v1.iframe`` directly (instead of importing\n            its module) is deprecated and will be disallowd in a later version.\n\n        Parameters\n        ----------\n        src : str\n            The URL of the page to embed.\n\n        width : int\n            The width of the iframe in CSS pixels. By default, this is the\n            app's default element width.\n\n        height : int\n            The height of the frame in CSS pixels. By default, this is ``150``.\n\n        scrolling : bool\n            Whether to allow scrolling in the iframe. If this ``False``\n            (default), Streamlit crops any content larger than the iframe and\n            does not show a scrollbar. If this is ``True``, Streamlit shows a\n            scrollbar when the content is larger than the iframe.\n\n        Example\n        -------\n\n        >>> import streamlit.components.v1 as components\n        >>>\n        >>> components.iframe(\"https://example.com\", height=500)\n\n        \"\"\"\n        iframe_proto = IFrameProto()\n        marshall(\n            iframe_proto,\n            src=src,\n            width=width,\n            height=height,\n            scrolling=scrolling,\n        )\n        return self.dg._enqueue(\"iframe\", iframe_proto)\n\n    @gather_metrics(\"_html\")\n    def _html(\n        self,\n        html: str,\n        width: int | None = None,\n        height: int | None = None,\n        scrolling: bool = False,\n    ) -> DeltaGenerator:\n        \"\"\"Display an HTML string in an iframe.\n\n        To use this function, import it from the ``streamlit.components.v1``\n        module.\n\n        If you want to insert HTML text into your app without an iframe, try\n        ``st.html`` instead.\n\n        .. warning::\n            Using ``st.components.v1.html`` directly (instead of importing\n            its module) is deprecated and will be disallowd in a later version.\n\n        Parameters\n        ----------\n        html : str\n            The HTML string to embed in the iframe.\n\n        width : int\n            The width of the iframe in CSS pixels. By default, this is the\n            app's default element width.\n\n        height : int\n            The height of the frame in CSS pixels. By default, this is ``150``.\n\n        scrolling : bool\n            Whether to allow scrolling in the iframe. If this ``False``\n            (default), Streamlit crops any content larger than the iframe and\n            does not show a scrollbar. If this is ``True``, Streamlit shows a\n            scrollbar when the content is larger than the iframe.\n\n        Example\n        -------\n\n        >>> import streamlit.components.v1 as components\n        >>>\n        >>> components.html(\n        >>>     \"<p><span style='text-decoration: line-through double red;'>Oops</span>!</p>\"\n        >>> )\n\n        \"\"\"\n        iframe_proto = IFrameProto()\n        marshall(\n            iframe_proto,\n            srcdoc=html,\n            width=width,\n            height=height,\n            scrolling=scrolling,\n        )\n        return self.dg._enqueue(\"iframe\", iframe_proto)\n\n    @property\n    def dg(self) -> DeltaGenerator:\n        \"\"\"Get our DeltaGenerator.\"\"\"\n        return cast(\"DeltaGenerator\", self)\n\n\ndef marshall(\n    proto: IFrameProto,\n    src: str | None = None,\n    srcdoc: str | None = None,\n    width: int | None = None,\n    height: int | None = None,\n    scrolling: bool = False,\n) -> None:\n    \"\"\"Marshalls data into an IFrame proto.\n\n    These parameters correspond directly to <iframe> attributes, which are\n    described in more detail at\n    https://developer.mozilla.org/en-US/docs/Web/HTML/Element/iframe.\n\n    Parameters\n    ----------\n    proto : IFrame protobuf\n        The protobuf object to marshall data into.\n    src : str\n        The URL of the page to embed.\n    srcdoc : str\n        Inline HTML to embed. Overrides src.\n    width : int\n        The width of the frame in CSS pixels. Defaults to the app's\n        default element width.\n    height : int\n        The height of the frame in CSS pixels. Defaults to 150.\n    scrolling : bool\n        If true, show a scrollbar when the content is larger than the iframe.\n        Otherwise, never show a scrollbar.\n\n    \"\"\"\n    if src is not None:\n        proto.src = src\n\n    if srcdoc is not None:\n        proto.srcdoc = srcdoc\n\n    if width is not None:\n        proto.width = width\n        proto.has_width = True\n\n    if height is not None:\n        proto.height = height\n    else:\n        proto.height = 150\n\n    proto.scrolling = scrolling\n", "lib/streamlit/elements/deck_gl_json_chart.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport hashlib\nimport json\nfrom typing import TYPE_CHECKING, Any, Final, Mapping, cast\n\nfrom streamlit import config\nfrom streamlit.proto.DeckGlJsonChart_pb2 import DeckGlJsonChart as PydeckProto\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.util import HASHLIB_KWARGS\n\nif TYPE_CHECKING:\n    from pydeck import Deck\n\n    from streamlit.delta_generator import DeltaGenerator\n\n\n# Mapping used when no data is passed.\nEMPTY_MAP: Final[Mapping[str, Any]] = {\n    \"initialViewState\": {\"latitude\": 0, \"longitude\": 0, \"pitch\": 0, \"zoom\": 1},\n}\n\n\nclass PydeckMixin:\n    @gather_metrics(\"pydeck_chart\")\n    def pydeck_chart(\n        self,\n        pydeck_obj: Deck | None = None,\n        use_container_width: bool = False,\n    ) -> DeltaGenerator:\n        \"\"\"Draw a chart using the PyDeck library.\n\n        This supports 3D maps, point clouds, and more! More info about PyDeck\n        at https://deckgl.readthedocs.io/en/latest/.\n\n        These docs are also quite useful:\n\n        - DeckGL docs: https://github.com/uber/deck.gl/tree/master/docs\n        - DeckGL JSON docs: https://github.com/uber/deck.gl/tree/master/modules/json\n\n        When using this command, Mapbox provides the map tiles to render map\n        content. Note that Mapbox is a third-party product and Streamlit accepts\n        no responsibility or liability of any kind for Mapbox or for any content\n        or information made available by Mapbox.\n\n        Mapbox requires users to register and provide a token before users can\n        request map tiles. Currently, Streamlit provides this token for you, but\n        this could change at any time. We strongly recommend all users create and\n        use their own personal Mapbox token to avoid any disruptions to their\n        experience. You can do this with the ``mapbox.token`` config option. The\n        use of Mapbox is governed by Mapbox's Terms of Use.\n\n        To get a token for yourself, create an account at https://mapbox.com.\n        For more info on how to set config options, see\n        https://docs.streamlit.io/develop/api-reference/configuration/config.toml.\n\n        Parameters\n        ----------\n        pydeck_obj: pydeck.Deck or None\n            Object specifying the PyDeck chart to draw.\n        use_container_width : bool\n            Whether to override the figure's native width with the width of\n            the parent container. If ``use_container_width`` is ``False``\n            (default), Streamlit sets the width of the chart to fit its contents\n            according to the plotting library, up to the width of the parent\n            container. If ``use_container_width`` is ``True``, Streamlit sets\n            the width of the figure to match the width of the parent container.\n\n        Example\n        -------\n        Here's a chart using a HexagonLayer and a ScatterplotLayer. It uses either the\n        light or dark map style, based on which Streamlit theme is currently active:\n\n        >>> import streamlit as st\n        >>> import pandas as pd\n        >>> import numpy as np\n        >>> import pydeck as pdk\n        >>>\n        >>> chart_data = pd.DataFrame(\n        ...    np.random.randn(1000, 2) / [50, 50] + [37.76, -122.4],\n        ...    columns=['lat', 'lon'])\n        >>>\n        >>> st.pydeck_chart(pdk.Deck(\n        ...     map_style=None,\n        ...     initial_view_state=pdk.ViewState(\n        ...         latitude=37.76,\n        ...         longitude=-122.4,\n        ...         zoom=11,\n        ...         pitch=50,\n        ...     ),\n        ...     layers=[\n        ...         pdk.Layer(\n        ...            'HexagonLayer',\n        ...            data=chart_data,\n        ...            get_position='[lon, lat]',\n        ...            radius=200,\n        ...            elevation_scale=4,\n        ...            elevation_range=[0, 1000],\n        ...            pickable=True,\n        ...            extruded=True,\n        ...         ),\n        ...         pdk.Layer(\n        ...             'ScatterplotLayer',\n        ...             data=chart_data,\n        ...             get_position='[lon, lat]',\n        ...             get_color='[200, 30, 0, 160]',\n        ...             get_radius=200,\n        ...         ),\n        ...     ],\n        ... ))\n\n        .. output::\n           https://doc-pydeck-chart.streamlit.app/\n           height: 530px\n\n        .. note::\n           To make the PyDeck chart's style consistent with Streamlit's theme,\n           you can set ``map_style=None`` in the ``pydeck.Deck`` object.\n\n        \"\"\"\n        pydeck_proto = PydeckProto()\n        marshall(pydeck_proto, pydeck_obj, use_container_width)\n        return self.dg._enqueue(\"deck_gl_json_chart\", pydeck_proto)\n\n    @property\n    def dg(self) -> DeltaGenerator:\n        \"\"\"Get our DeltaGenerator.\"\"\"\n        return cast(\"DeltaGenerator\", self)\n\n\ndef _get_pydeck_tooltip(pydeck_obj: Deck | None) -> dict[str, str] | None:\n    if pydeck_obj is None:\n        return None\n\n    # For pydeck <0.8.1 or pydeck>=0.8.1 when jupyter extra is installed.\n    desk_widget = getattr(pydeck_obj, \"deck_widget\", None)\n    if desk_widget is not None and isinstance(desk_widget.tooltip, dict):\n        return desk_widget.tooltip\n\n    # For pydeck >=0.8.1 when jupyter extra is not installed.\n    # For details, see: https://github.com/visgl/deck.gl/pull/7125/files\n    tooltip = getattr(pydeck_obj, \"_tooltip\", None)\n    if tooltip is not None and isinstance(tooltip, dict):\n        return tooltip\n\n    return None\n\n\ndef marshall(\n    pydeck_proto: PydeckProto,\n    pydeck_obj: Deck | None,\n    use_container_width: bool,\n) -> None:\n    if pydeck_obj is None:\n        spec = json.dumps(EMPTY_MAP)\n        id = \"\"\n    else:\n        spec = pydeck_obj.to_json()\n        json_string = json.dumps(spec)\n        json_bytes = json_string.encode(\"utf-8\")\n        id = hashlib.md5(json_bytes, **HASHLIB_KWARGS).hexdigest()\n\n    pydeck_proto.json = spec\n    pydeck_proto.use_container_width = use_container_width\n\n    pydeck_proto.id = id\n\n    tooltip = _get_pydeck_tooltip(pydeck_obj)\n    if tooltip:\n        pydeck_proto.tooltip = json.dumps(tooltip)\n\n    mapbox_token = config.get_option(\"mapbox.token\")\n    if mapbox_token:\n        pydeck_proto.mapbox_token = mapbox_token\n", "lib/streamlit/elements/empty.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom typing import TYPE_CHECKING, cast\n\nfrom streamlit.proto.Empty_pb2 import Empty as EmptyProto\nfrom streamlit.proto.Skeleton_pb2 import Skeleton as SkeletonProto\nfrom streamlit.runtime.metrics_util import gather_metrics\n\nif TYPE_CHECKING:\n    from streamlit.delta_generator import DeltaGenerator\n\n\nclass EmptyMixin:\n    @gather_metrics(\"empty\")\n    def empty(self) -> DeltaGenerator:\n        \"\"\"Insert a single-element container.\n\n        Inserts a container into your app that can be used to hold a single element.\n        This allows you to, for example, remove elements at any point, or replace\n        several elements at once (using a child multi-element container).\n\n        To insert/replace/clear an element on the returned container, you can\n        use ``with`` notation or just call methods directly on the returned object.\n        See examples below.\n\n        Examples\n        --------\n        Overwriting elements in-place using ``with`` notation:\n\n        >>> import streamlit as st\n        >>> import time\n        >>>\n        >>> with st.empty():\n        ...     for seconds in range(60):\n        ...         st.write(f\"\u23f3 {seconds} seconds have passed\")\n        ...         time.sleep(1)\n        ...     st.write(\"\u2714\ufe0f 1 minute over!\")\n\n        Replacing several elements, then clearing them:\n\n        >>> import streamlit as st\n        >>>\n        >>> placeholder = st.empty()\n        >>>\n        >>> # Replace the placeholder with some text:\n        >>> placeholder.text(\"Hello\")\n        >>>\n        >>> # Replace the text with a chart:\n        >>> placeholder.line_chart({\"data\": [1, 5, 2, 6]})\n        >>>\n        >>> # Replace the chart with several elements:\n        >>> with placeholder.container():\n        ...     st.write(\"This is one element\")\n        ...     st.write(\"This is another\")\n        ...\n        >>> # Clear all those elements:\n        >>> placeholder.empty()\n\n        \"\"\"\n        empty_proto = EmptyProto()\n        return self.dg._enqueue(\"empty\", empty_proto)\n\n    @gather_metrics(\"_skeleton\")\n    def _skeleton(self, *, height: int | None = None) -> DeltaGenerator:\n        \"\"\"Insert a single-element container which displays a \"skeleton\" placeholder.\n\n        Inserts a container into your app that can be used to hold a single element.\n        This allows you to, for example, remove elements at any point, or replace\n        several elements at once (using a child multi-element container).\n\n        To insert/replace/clear an element on the returned container, you can\n        use ``with`` notation or just call methods directly on the returned object.\n        See some of the examples below.\n\n        This is an internal method and should not be used directly.\n\n        Parameters\n        ----------\n        height: int or None\n            Desired height of the skeleton expressed in pixels. If None, a\n            default height is used.\n        \"\"\"\n        skeleton_proto = SkeletonProto()\n        if height:\n            skeleton_proto.height = height\n        return self.dg._enqueue(\"skeleton\", skeleton_proto)\n\n    @property\n    def dg(self) -> DeltaGenerator:\n        \"\"\"Get our DeltaGenerator.\"\"\"\n        return cast(\"DeltaGenerator\", self)\n", "lib/streamlit/elements/__init__.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n", "lib/streamlit/elements/text.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom typing import TYPE_CHECKING, cast\n\nfrom streamlit.proto.Text_pb2 import Text as TextProto\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.string_util import clean_text\n\nif TYPE_CHECKING:\n    from streamlit.delta_generator import DeltaGenerator\n    from streamlit.type_util import SupportsStr\n\n\nclass TextMixin:\n    @gather_metrics(\"text\")\n    def text(\n        self,\n        body: SupportsStr,\n        *,  # keyword-only arguments:\n        help: str | None = None,\n    ) -> DeltaGenerator:\n        \"\"\"Write fixed-width and preformatted text.\n\n        Parameters\n        ----------\n        body : str\n            The string to display.\n\n        help : str\n            An optional tooltip that gets displayed next to the text.\n\n        Example\n        -------\n        >>> import streamlit as st\n        >>>\n        >>> st.text('This is some text.')\n\n        \"\"\"\n        text_proto = TextProto()\n        text_proto.body = clean_text(body)\n        if help:\n            text_proto.help = help\n        return self.dg._enqueue(\"text\", text_proto)\n\n    @property\n    def dg(self) -> DeltaGenerator:\n        \"\"\"Get our DeltaGenerator.\"\"\"\n        return cast(\"DeltaGenerator\", self)\n", "lib/streamlit/elements/plotly_chart.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Streamlit support for Plotly charts.\"\"\"\n\nfrom __future__ import annotations\n\nimport json\nfrom dataclasses import dataclass\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    Dict,\n    Final,\n    Iterable,\n    List,\n    Literal,\n    TypedDict,\n    Union,\n    cast,\n    overload,\n)\n\nfrom typing_extensions import TypeAlias\n\nfrom streamlit import type_util\nfrom streamlit.deprecation_util import show_deprecation_warning\nfrom streamlit.elements.form import current_form_id\nfrom streamlit.elements.lib.event_utils import AttributeDictionary\nfrom streamlit.elements.lib.policies import (\n    check_cache_replay_rules,\n    check_callback_rules,\n    check_fragment_path_policy,\n    check_session_state_rules,\n)\nfrom streamlit.elements.lib.streamlit_plotly_theme import (\n    configure_streamlit_plotly_theme,\n)\nfrom streamlit.errors import StreamlitAPIException\nfrom streamlit.proto.PlotlyChart_pb2 import PlotlyChart as PlotlyChartProto\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.runtime.scriptrunner import get_script_run_ctx\nfrom streamlit.runtime.state import WidgetCallback, register_widget\nfrom streamlit.runtime.state.common import compute_widget_id\nfrom streamlit.type_util import Key, to_key\n\nif TYPE_CHECKING:\n    import matplotlib\n    import plotly.graph_objs as go\n    from plotly.basedatatypes import BaseFigure\n\n    from streamlit.delta_generator import DeltaGenerator\n\n# We need to configure the Plotly theme before any Plotly figures are created:\nconfigure_streamlit_plotly_theme()\n\n_AtomicFigureOrData: TypeAlias = Union[\n    \"go.Figure\",\n    \"go.Data\",\n]\nFigureOrData: TypeAlias = Union[\n    _AtomicFigureOrData,\n    List[_AtomicFigureOrData],\n    # It is kind of hard to figure out exactly what kind of dict is supported\n    # here, as plotly hasn't embraced typing yet. This version is chosen to\n    # align with the docstring.\n    Dict[str, _AtomicFigureOrData],\n    \"BaseFigure\",\n    \"matplotlib.figure.Figure\",\n]\n\nSelectionMode: TypeAlias = Literal[\"lasso\", \"points\", \"box\"]\n_SELECTION_MODES: Final[set[SelectionMode]] = {\"lasso\", \"points\", \"box\"}\n\n\nclass PlotlySelectionState(TypedDict, total=False):\n    \"\"\"\n    The schema for the Plotly chart selection state.\n\n    The selection state is stored in a dictionary-like object that suports both\n    key and attribute notation. Selection states cannot be programmatically\n    changed or set through Session State.\n\n    Attributes\n    ----------\n    points : list[dict[str, Any]]\n        The selected data points in the chart, including the data points\n        selected by the box and lasso mode. The data includes the values\n        associated to each point and a point index used to populate\n        ``point_indices``. If additional information has been assigned to your\n        points, such as size or legend group, this is also included.\n\n    point_indices : list[int]\n        The numerical indices of all selected data points in the chart. The\n        details of each identified point are included in ``points``.\n\n    box : list[dict[str, Any]]\n        The metadata related to the box selection. This includes the\n        coordinates of the selected area.\n\n    lasso : list[dict[str, Any]]\n        The metadata related to the lasso selection. This includes the\n        coordinates of the selected area.\n\n    Example\n    -------\n    When working with more complicated graphs, the ``points`` attribute\n    displays additional information. Try selecting points in the following\n    example:\n\n    >>> import streamlit as st\n    >>> import plotly.express as px\n    >>>\n    >>> df = px.data.iris()\n    >>> fig = px.scatter(\n    ...     df,\n    ...     x=\"sepal_width\",\n    ...     y=\"sepal_length\",\n    ...     color=\"species\",\n    ...     size=\"petal_length\",\n    ...     hover_data=[\"petal_width\"],\n    ... )\n    >>>\n    >>> event = st.plotly_chart(fig, key=\"iris\", on_select=\"rerun\")\n    >>>\n    >>> event.selection\n\n    .. output::\n        https://doc-chart-events-plotly-selection-state.streamlit.app\n        height: 600px\n\n    This is an example of the selection state when selecting a single point:\n\n    >>> {\n    >>>   \"points\": [\n    >>>     {\n    >>>       \"curve_number\": 2,\n    >>>       \"point_number\": 9,\n    >>>       \"point_index\": 9,\n    >>>       \"x\": 3.6,\n    >>>       \"y\": 7.2,\n    >>>       \"customdata\": [\n    >>>         2.5\n    >>>       ],\n    >>>       \"marker_size\": 6.1,\n    >>>       \"legendgroup\": \"virginica\"\n    >>>     }\n    >>>   ],\n    >>>   \"point_indices\": [\n    >>>     9\n    >>>   ],\n    >>>   \"box\": [],\n    >>>   \"lasso\": []\n    >>> }\n\n    \"\"\"\n\n    points: list[dict[str, Any]]\n    point_indices: list[int]\n    box: list[dict[str, Any]]\n    lasso: list[dict[str, Any]]\n\n\nclass PlotlyState(TypedDict, total=False):\n    \"\"\"\n    The schema for the Plotly chart event state.\n\n    The event state is stored in a dictionary-like object that suports both\n    key and attribute notation. Event states cannot be programmatically\n    changed or set through Session State.\n\n    Only selection events are supported at this time.\n\n    Attributes\n    ----------\n    selection : dict\n        The state of the ``on_select`` event. This attribure returns a\n        dictionary-like object that supports both key and attribute notation.\n        The attributes are described by the ``PlotlySelectionState`` dictionary\n        schema.\n\n    Example\n    -------\n    Try selecting points by any of the three available methods (direct click,\n    box, or lasso). The current selection state is available through Session\n    State or as the output of the chart function.\n\n    >>> import streamlit as st\n    >>> import plotly.express as px\n    >>>\n    >>> df = px.data.iris()  # iris is a pandas DataFrame\n    >>> fig = px.scatter(df, x=\"sepal_width\", y=\"sepal_length\")\n    >>>\n    >>> event = st.plotly_chart(fig, key=\"iris\", on_select=\"rerun\")\n    >>>\n    >>> event\n\n    .. output::\n        https://doc-chart-events-plotly-state.streamlit.app\n        height: 600px\n\n    \"\"\"\n\n    selection: PlotlySelectionState\n\n\n@dataclass\nclass PlotlyChartSelectionSerde:\n    \"\"\"PlotlyChartSelectionSerde is used to serialize and deserialize the Plotly Chart selection state.\"\"\"\n\n    def deserialize(self, ui_value: str | None, widget_id: str = \"\") -> PlotlyState:\n        empty_selection_state: PlotlyState = {\n            \"selection\": {\n                \"points\": [],\n                \"point_indices\": [],\n                \"box\": [],\n                \"lasso\": [],\n            },\n        }\n\n        selection_state = (\n            empty_selection_state\n            if ui_value is None\n            else cast(PlotlyState, AttributeDictionary(json.loads(ui_value)))\n        )\n\n        if \"selection\" not in selection_state:\n            selection_state = empty_selection_state\n\n        return cast(PlotlyState, AttributeDictionary(selection_state))\n\n    def serialize(self, selection_state: PlotlyState) -> str:\n        return json.dumps(selection_state, default=str)\n\n\ndef parse_selection_mode(\n    selection_mode: SelectionMode | Iterable[SelectionMode],\n) -> set[PlotlyChartProto.SelectionMode.ValueType]:\n    \"\"\"Parse and check the user provided selection modes.\"\"\"\n    if isinstance(selection_mode, str):\n        # Only a single selection mode was passed\n        selection_mode_set = {selection_mode}\n    else:\n        # Multiple selection modes were passed\n        selection_mode_set = set(selection_mode)\n\n    if not selection_mode_set.issubset(_SELECTION_MODES):\n        raise StreamlitAPIException(\n            f\"Invalid selection mode: {selection_mode}. \"\n            f\"Valid options are: {_SELECTION_MODES}\"\n        )\n\n    parsed_selection_modes = []\n    for selection_mode in selection_mode_set:\n        if selection_mode == \"points\":\n            parsed_selection_modes.append(PlotlyChartProto.SelectionMode.POINTS)\n        elif selection_mode == \"lasso\":\n            parsed_selection_modes.append(PlotlyChartProto.SelectionMode.LASSO)\n        elif selection_mode == \"box\":\n            parsed_selection_modes.append(PlotlyChartProto.SelectionMode.BOX)\n    return set(parsed_selection_modes)\n\n\nclass PlotlyMixin:\n    @overload\n    def plotly_chart(\n        self,\n        figure_or_data: FigureOrData,\n        use_container_width: bool = False,\n        *,\n        theme: Literal[\"streamlit\"] | None = \"streamlit\",\n        key: Key | None = None,\n        on_select: Literal[\"ignore\"],  # No default value here to make it work with mypy\n        selection_mode: SelectionMode | Iterable[SelectionMode] = (\n            \"points\",\n            \"box\",\n            \"lasso\",\n        ),\n        **kwargs: Any,\n    ) -> DeltaGenerator: ...\n\n    @overload\n    def plotly_chart(\n        self,\n        figure_or_data: FigureOrData,\n        use_container_width: bool = False,\n        *,\n        theme: Literal[\"streamlit\"] | None = \"streamlit\",\n        key: Key | None = None,\n        on_select: Literal[\"rerun\"] | WidgetCallback = \"rerun\",\n        selection_mode: SelectionMode | Iterable[SelectionMode] = (\n            \"points\",\n            \"box\",\n            \"lasso\",\n        ),\n        **kwargs: Any,\n    ) -> PlotlyState: ...\n\n    @gather_metrics(\"plotly_chart\")\n    def plotly_chart(\n        self,\n        figure_or_data: FigureOrData,\n        use_container_width: bool = False,\n        *,\n        theme: Literal[\"streamlit\"] | None = \"streamlit\",\n        key: Key | None = None,\n        on_select: Literal[\"rerun\", \"ignore\"] | WidgetCallback = \"ignore\",\n        selection_mode: SelectionMode | Iterable[SelectionMode] = (\n            \"points\",\n            \"box\",\n            \"lasso\",\n        ),\n        **kwargs: Any,\n    ) -> DeltaGenerator | PlotlyState:\n        \"\"\"Display an interactive Plotly chart.\n\n        `Plotly <https://plot.ly/python>`_ is a charting library for Python.\n        The arguments to this function closely follow the ones for Plotly's\n        ``plot()`` function.\n\n        To show Plotly charts in Streamlit, call ``st.plotly_chart`` wherever\n        you would call Plotly's ``py.plot`` or ``py.iplot``.\n\n        Parameters\n        ----------\n        figure_or_data : plotly.graph_objs.Figure, plotly.graph_objs.Data,\\\n            or dict/list of plotly.graph_objs.Figure/Data\n\n            The Plotly ``Figure`` or ``Data`` object to render. See\n            https://plot.ly/python/ for examples of graph descriptions.\n\n        use_container_width : bool\n            Whether to override the figure's native width with the width of\n            the parent container. If ``use_container_width`` is ``False``\n            (default), Streamlit sets the width of the chart to fit its contents\n            according to the plotting library, up to the width of the parent\n            container. If ``use_container_width`` is ``True``, Streamlit sets\n            the width of the figure to match the width of the parent container.\n\n        theme : \"streamlit\" or None\n            The theme of the chart. If ``theme`` is ``\"streamlit\"`` (default),\n            Streamlit uses its own design default. If ``theme`` is ``None``,\n            Streamlit falls back to the default behavior of the library.\n\n        key : str\n            An optional string to use for giving this element a stable\n            identity. If ``key`` is ``None`` (default), this element's identity\n            will be determined based on the values of the other parameters.\n\n            Additionally, if selections are activated and ``key`` is provided,\n            Streamlit will register the key in Session State to store the\n            selection state. The selection state is read-only.\n\n        on_select : \"ignore\" or \"rerun\" or callable\n            How the figure should respond to user selection events. This\n            controls whether or not the figure behaves like an input widget.\n            ``on_select`` can be one of the following:\n\n            - ``\"ignore\"`` (default): Streamlit will not react to any selection\n              events in the chart. The figure will not behave like an input\n              widget.\n\n            - ``\"rerun\"``: Streamlit will rerun the app when the user selects\n              data in the chart. In this case, ``st.plotly_chart`` will return\n              the selection data as a dictionary.\n\n            - A ``callable``: Streamlit will rerun the app and execute the\n              ``callable`` as a callback function before the rest of the app.\n              In this case, ``st.plotly_chart`` will return the selection data\n              as a dictionary.\n\n        selection_mode : \"points\", \"box\", \"lasso\" or an Iterable of these\n            The selection mode of the chart. This can be one of the following:\n\n            - ``\"points\"``: The chart will allow selections based on individual\n              data points.\n            - ``\"box\"``: The chart will allow selections based on rectangular\n              areas.\n            - ``\"lasso\"``: The chart will allow selections based on freeform\n              areas.\n            - An ``Iterable`` of the above options: The chart will allow\n              selections based on the modes specified.\n\n            All selections modes are activated by default.\n\n        **kwargs\n            Any argument accepted by Plotly's ``plot()`` function.\n\n        Returns\n        -------\n        element or dict\n            If ``on_select`` is ``\"ignore\"`` (default), this method returns an\n            internal placeholder for the chart element. Otherwise, this method\n            returns a dictionary-like object that supports both key and\n            attribute notation. The attributes are described by the\n            ``PlotlyState`` dictionary schema.\n\n        Example\n        -------\n        The example below comes straight from the examples at\n        https://plot.ly/python. Note that ``plotly.figure_factory`` requires\n        ``scipy`` to run.\n\n        >>> import streamlit as st\n        >>> import numpy as np\n        >>> import plotly.figure_factory as ff\n        >>>\n        >>> # Add histogram data\n        >>> x1 = np.random.randn(200) - 2\n        >>> x2 = np.random.randn(200)\n        >>> x3 = np.random.randn(200) + 2\n        >>>\n        >>> # Group data together\n        >>> hist_data = [x1, x2, x3]\n        >>>\n        >>> group_labels = ['Group 1', 'Group 2', 'Group 3']\n        >>>\n        >>> # Create distplot with custom bin_size\n        >>> fig = ff.create_distplot(\n        ...         hist_data, group_labels, bin_size=[.1, .25, .5])\n        >>>\n        >>> # Plot!\n        >>> st.plotly_chart(fig, use_container_width=True)\n\n        .. output::\n           https://doc-plotly-chart.streamlit.app/\n           height: 550px\n\n        \"\"\"\n        import plotly.io\n        import plotly.tools\n\n        # NOTE: \"figure_or_data\" is the name used in Plotly's .plot() method\n        # for their main parameter. I don't like the name, but it's best to\n        # keep it in sync with what Plotly calls it.\n\n        if \"sharing\" in kwargs:\n            show_deprecation_warning(\n                \"The `sharing` parameter has been deprecated and will be removed in a future release. \"\n                \"Plotly charts will always be rendered using Streamlit's offline mode.\"\n            )\n\n        if theme not in [\"streamlit\", None]:\n            raise StreamlitAPIException(\n                f'You set theme=\"{theme}\" while Streamlit charts only support theme=\u201dstreamlit\u201d or theme=None to fallback to the default library theme.'\n            )\n\n        if on_select not in [\"ignore\", \"rerun\"] and not callable(on_select):\n            raise StreamlitAPIException(\n                f\"You have passed {on_select} to `on_select`. But only 'ignore', 'rerun', or a callable is supported.\"\n            )\n\n        key = to_key(key)\n        is_selection_activated = on_select != \"ignore\"\n\n        if is_selection_activated:\n            # Run some checks that are only relevant when selections are activated\n\n            check_fragment_path_policy(self.dg)\n            check_cache_replay_rules()\n            if callable(on_select):\n                check_callback_rules(self.dg, on_select)\n            check_session_state_rules(default_value=None, key=key, writes_allowed=False)\n\n        if type_util.is_type(figure_or_data, \"matplotlib.figure.Figure\"):\n            # Convert matplotlib figure to plotly figure:\n            figure = plotly.tools.mpl_to_plotly(figure_or_data)\n        else:\n            figure = plotly.tools.return_figure_from_figure_or_data(\n                figure_or_data, validate_figure=True\n            )\n\n        plotly_chart_proto = PlotlyChartProto()\n        plotly_chart_proto.use_container_width = use_container_width\n        plotly_chart_proto.theme = theme or \"\"\n        plotly_chart_proto.form_id = current_form_id(self.dg)\n\n        config = dict(kwargs.get(\"config\", {}))\n        # Copy over some kwargs to config dict. Plotly does the same in plot().\n        config.setdefault(\"showLink\", kwargs.get(\"show_link\", False))\n        config.setdefault(\"linkText\", kwargs.get(\"link_text\", False))\n\n        plotly_chart_proto.spec = plotly.io.to_json(figure, validate=False)\n        plotly_chart_proto.config = json.dumps(config)\n\n        ctx = get_script_run_ctx()\n\n        # We are computing the widget id for all plotly uses\n        # to also allow non-widget Plotly charts to keep their state\n        # when the frontend component gets unmounted and remounted.\n        plotly_chart_proto.id = compute_widget_id(\n            \"plotly_chart\",\n            user_key=key,\n            key=key,\n            plotly_spec=plotly_chart_proto.spec,\n            plotly_config=plotly_chart_proto.config,\n            selection_mode=selection_mode,\n            is_selection_activated=is_selection_activated,\n            theme=theme,\n            form_id=plotly_chart_proto.form_id,\n            use_container_width=use_container_width,\n            page=ctx.active_script_hash if ctx else None,\n        )\n\n        if is_selection_activated:\n            # Selections are activated, treat plotly chart as a widget:\n            plotly_chart_proto.selection_mode.extend(\n                parse_selection_mode(selection_mode)\n            )\n\n            serde = PlotlyChartSelectionSerde()\n\n            widget_state = register_widget(\n                \"plotly_chart\",\n                plotly_chart_proto,\n                user_key=key,\n                on_change_handler=on_select if callable(on_select) else None,\n                deserializer=serde.deserialize,\n                serializer=serde.serialize,\n                ctx=ctx,\n            )\n\n            self.dg._enqueue(\"plotly_chart\", plotly_chart_proto)\n            return cast(PlotlyState, widget_state.value)\n        else:\n            return self.dg._enqueue(\"plotly_chart\", plotly_chart_proto)\n\n    @property\n    def dg(self) -> DeltaGenerator:\n        \"\"\"Get our DeltaGenerator.\"\"\"\n        return cast(\"DeltaGenerator\", self)\n", "lib/streamlit/elements/markdown.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom typing import TYPE_CHECKING, Final, cast\n\nfrom streamlit.proto.Markdown_pb2 import Markdown as MarkdownProto\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.string_util import clean_text\nfrom streamlit.type_util import SupportsStr, is_sympy_expession\n\nif TYPE_CHECKING:\n    import sympy\n\n    from streamlit.delta_generator import DeltaGenerator\n\nMARKDOWN_HORIZONTAL_RULE_EXPRESSION: Final = \"---\"\n\n\nclass MarkdownMixin:\n    @gather_metrics(\"markdown\")\n    def markdown(\n        self,\n        body: SupportsStr,\n        unsafe_allow_html: bool = False,\n        *,  # keyword-only arguments:\n        help: str | None = None,\n    ) -> DeltaGenerator:\n        r\"\"\"Display string formatted as Markdown.\n\n        Parameters\n        ----------\n        body : str\n            The string to display as Github-flavored Markdown. Syntax\n            information can be found at: https://github.github.com/gfm.\n\n            This also supports:\n\n            * Emoji shortcodes, such as ``:+1:``  and ``:sunglasses:``.\n              For a list of all supported codes,\n              see https://share.streamlit.io/streamlit/emoji-shortcodes.\n\n            * LaTeX expressions, by wrapping them in \"$\" or \"$$\" (the \"$$\"\n              must be on their own lines). Supported LaTeX functions are listed\n              at https://katex.org/docs/supported.html.\n\n            * Colored text and background colors for text, using the syntax\n              ``:color[text to be colored]`` and ``:color-background[text to be colored]``,\n              respectively. ``color`` must be replaced with any of the following\n              supported colors: blue, green, orange, red, violet, gray/grey, rainbow.\n              For example, you can use ``:orange[your text here]`` or\n              ``:blue-background[your text here]``.\n\n        unsafe_allow_html : bool\n            Whether to render HTML within ``body``. If this is ``False``\n            (default), any HTML tags found in ``body`` will be escaped and\n            therefore treated as raw text. If this is ``True``, any HTML\n            expressions within ``body`` will be rendered.\n\n            Adding custom HTML to your app impacts safety, styling, and\n            maintainability.\n\n            .. note::\n                If you only want to insert HTML or CSS without Markdown text,\n                we recommend using ``st.html`` instead.\n\n        help : str\n            An optional tooltip that gets displayed next to the Markdown.\n\n        Examples\n        --------\n        >>> import streamlit as st\n        >>>\n        >>> st.markdown(\"*Streamlit* is **really** ***cool***.\")\n        >>> st.markdown('''\n        ...     :red[Streamlit] :orange[can] :green[write] :blue[text] :violet[in]\n        ...     :gray[pretty] :rainbow[colors] and :blue-background[highlight] text.''')\n        >>> st.markdown(\"Here's a bouquet &mdash;\\\n        ...             :tulip::cherry_blossom::rose::hibiscus::sunflower::blossom:\")\n        >>>\n        >>> multi = '''If you end a line with two spaces,\n        ... a soft return is used for the next line.\n        ...\n        ... Two (or more) newline characters in a row will result in a hard return.\n        ... '''\n        >>> st.markdown(multi)\n\n        .. output::\n           https://doc-markdown.streamlit.app/\n           height: 350px\n\n        \"\"\"\n        markdown_proto = MarkdownProto()\n\n        markdown_proto.body = clean_text(body)\n        markdown_proto.allow_html = unsafe_allow_html\n        markdown_proto.element_type = MarkdownProto.Type.NATIVE\n        if help:\n            markdown_proto.help = help\n\n        return self.dg._enqueue(\"markdown\", markdown_proto)\n\n    @gather_metrics(\"code\")\n    def code(\n        self,\n        body: SupportsStr,\n        language: str | None = \"python\",\n    ) -> DeltaGenerator:\n        \"\"\"Display a code block with optional syntax highlighting.\n\n        (This is a convenience wrapper around `st.markdown()`)\n\n        Parameters\n        ----------\n        body : str\n            The string to display as code.\n\n        language : str or None\n            The language that the code is written in, for syntax highlighting.\n            If ``None``, the code will be unstyled. Defaults to ``\"python\"``.\n\n            For a list of available ``language`` values, see:\n\n            https://github.com/react-syntax-highlighter/react-syntax-highlighter/blob/master/AVAILABLE_LANGUAGES_PRISM.MD\n\n        Example\n        -------\n        >>> import streamlit as st\n        >>>\n        >>> code = '''def hello():\n        ...     print(\"Hello, Streamlit!\")'''\n        >>> st.code(code, language='python')\n\n        \"\"\"\n        code_proto = MarkdownProto()\n        markdown = f'```{language or \"\"}\\n{body}\\n```'\n        code_proto.body = clean_text(markdown)\n        code_proto.element_type = MarkdownProto.Type.CODE\n        return self.dg._enqueue(\"markdown\", code_proto)\n\n    @gather_metrics(\"caption\")\n    def caption(\n        self,\n        body: SupportsStr,\n        unsafe_allow_html: bool = False,\n        *,  # keyword-only arguments:\n        help: str | None = None,\n    ) -> DeltaGenerator:\n        \"\"\"Display text in small font.\n\n        This should be used for captions, asides, footnotes, sidenotes, and\n        other explanatory text.\n\n        Parameters\n        ----------\n        body : str\n            The text to display as Github-flavored Markdown. Syntax\n            information can be found at: https://github.github.com/gfm.\n\n            This also supports:\n\n            * Emoji shortcodes, such as ``:+1:``  and ``:sunglasses:``.\n              For a list of all supported codes,\n              see https://share.streamlit.io/streamlit/emoji-shortcodes.\n\n            * LaTeX expressions, by wrapping them in \"$\" or \"$$\" (the \"$$\"\n              must be on their own lines). Supported LaTeX functions are listed\n              at https://katex.org/docs/supported.html.\n\n            * Colored text and background colors for text, using the syntax\n              ``:color[text to be colored]`` and ``:color-background[text to be colored]``,\n              respectively. ``color`` must be replaced with any of the following\n              supported colors: blue, green, orange, red, violet, gray/grey, rainbow.\n              For example, you can use ``:orange[your text here]`` or\n              ``:blue-background[your text here]``.\n\n        unsafe_allow_html : bool\n            Whether to render HTML within ``body``. If this is ``False``\n            (default), any HTML tags found in ``body`` will be escaped and\n            therefore treated as raw text. If this is ``True``, any HTML\n            expressions within ``body`` will be rendered.\n\n            Adding custom HTML to your app impacts safety, styling, and\n            maintainability.\n\n            .. note::\n                If you only want to insert HTML or CSS without Markdown text,\n                we recommend using ``st.html`` instead.\n\n        help : str\n            An optional tooltip that gets displayed next to the caption.\n\n        Examples\n        --------\n        >>> import streamlit as st\n        >>>\n        >>> st.caption('This is a string that explains something above.')\n        >>> st.caption('A caption with _italics_ :blue[colors] and emojis :sunglasses:')\n\n        \"\"\"\n        caption_proto = MarkdownProto()\n        caption_proto.body = clean_text(body)\n        caption_proto.allow_html = unsafe_allow_html\n        caption_proto.is_caption = True\n        caption_proto.element_type = MarkdownProto.Type.CAPTION\n        if help:\n            caption_proto.help = help\n        return self.dg._enqueue(\"markdown\", caption_proto)\n\n    @gather_metrics(\"latex\")\n    def latex(\n        self,\n        body: SupportsStr | sympy.Expr,\n        *,  # keyword-only arguments:\n        help: str | None = None,\n    ) -> DeltaGenerator:\n        # This docstring needs to be \"raw\" because of the backslashes in the\n        # example below.\n        r\"\"\"Display mathematical expressions formatted as LaTeX.\n\n        Supported LaTeX functions are listed at\n        https://katex.org/docs/supported.html.\n\n        Parameters\n        ----------\n        body : str or SymPy expression\n            The string or SymPy expression to display as LaTeX. If str, it's\n            a good idea to use raw Python strings since LaTeX uses backslashes\n            a lot.\n\n        help : str\n            An optional tooltip that gets displayed next to the LaTeX expression.\n\n\n        Example\n        -------\n        >>> import streamlit as st\n        >>>\n        >>> st.latex(r'''\n        ...     a + ar + a r^2 + a r^3 + \\cdots + a r^{n-1} =\n        ...     \\sum_{k=0}^{n-1} ar^k =\n        ...     a \\left(\\frac{1-r^{n}}{1-r}\\right)\n        ...     ''')\n\n        \"\"\"\n        if is_sympy_expession(body):\n            import sympy\n\n            body = sympy.latex(body)\n\n        latex_proto = MarkdownProto()\n        latex_proto.body = \"$$\\n%s\\n$$\" % clean_text(body)\n        latex_proto.element_type = MarkdownProto.Type.LATEX\n        if help:\n            latex_proto.help = help\n        return self.dg._enqueue(\"markdown\", latex_proto)\n\n    @gather_metrics(\"divider\")\n    def divider(self) -> DeltaGenerator:\n        \"\"\"Display a horizontal rule.\n\n        .. note::\n            You can achieve the same effect with st.write(\"---\") or\n            even just \"---\" in your script (via magic).\n\n        Example\n        -------\n        >>> import streamlit as st\n        >>>\n        >>> st.divider()\n\n        \"\"\"\n        divider_proto = MarkdownProto()\n        divider_proto.body = MARKDOWN_HORIZONTAL_RULE_EXPRESSION\n        divider_proto.element_type = MarkdownProto.Type.DIVIDER\n        return self.dg._enqueue(\"markdown\", divider_proto)\n\n    @property\n    def dg(self) -> DeltaGenerator:\n        \"\"\"Get our DeltaGenerator.\"\"\"\n        return cast(\"DeltaGenerator\", self)\n", "lib/streamlit/elements/vega_charts.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Collection of chart commands that are rendered via our vega-lite chart component.\"\"\"\n\nfrom __future__ import annotations\n\nimport hashlib\nimport json\nimport re\nfrom contextlib import nullcontext\nfrom dataclasses import dataclass\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    Final,\n    Iterable,\n    Literal,\n    Sequence,\n    TypedDict,\n    cast,\n    overload,\n)\n\nfrom typing_extensions import TypeAlias\n\nimport streamlit.elements.lib.dicttools as dicttools\nfrom streamlit import type_util\nfrom streamlit.elements.lib.built_in_chart_utils import (\n    AddRowsMetadata,\n    ChartType,\n    generate_chart,\n)\nfrom streamlit.elements.lib.event_utils import AttributeDictionary\nfrom streamlit.elements.lib.policies import (\n    check_cache_replay_rules,\n    check_callback_rules,\n    check_fragment_path_policy,\n    check_session_state_rules,\n)\nfrom streamlit.errors import StreamlitAPIException\nfrom streamlit.proto.ArrowVegaLiteChart_pb2 import (\n    ArrowVegaLiteChart as ArrowVegaLiteChartProto,\n)\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.runtime.scriptrunner import get_script_run_ctx\nfrom streamlit.runtime.state import register_widget\nfrom streamlit.runtime.state.common import compute_widget_id\nfrom streamlit.type_util import Key, to_key\nfrom streamlit.util import HASHLIB_KWARGS\n\nif TYPE_CHECKING:\n    import altair as alt\n\n    from streamlit.color_util import Color\n    from streamlit.delta_generator import DeltaGenerator\n    from streamlit.elements.arrow import Data\n    from streamlit.runtime.state import WidgetCallback\n\n# See https://vega.github.io/vega-lite/docs/encoding.html\n_CHANNELS: Final = {\n    \"x\",\n    \"y\",\n    \"x2\",\n    \"y2\",\n    \"xError\",\n    \"xError2\",\n    \"yError\",\n    \"yError2\",\n    \"longitude\",\n    \"latitude\",\n    \"color\",\n    \"opacity\",\n    \"fillOpacity\",\n    \"strokeOpacity\",\n    \"strokeWidth\",\n    \"size\",\n    \"shape\",\n    \"text\",\n    \"tooltip\",\n    \"href\",\n    \"key\",\n    \"order\",\n    \"detail\",\n    \"facet\",\n    \"row\",\n    \"column\",\n}\n\nVegaLiteSpec: TypeAlias = \"dict[str, Any]\"\n\n\nclass VegaLiteState(TypedDict, total=False):\n    \"\"\"\n    The schema for the Vega-Lite event state.\n\n    The event state is stored in a dictionary-like object that suports both\n    key and attribute notation. Event states cannot be programmatically\n    changed or set through Session State.\n\n    Only selection events are supported at this time.\n\n    Attributes\n    ----------\n    selection : dict\n        The state of the ``on_select`` event. This attribure returns a\n        dictionary-like object that supports both key and attribute notation.\n        The name of each Vega-Lite selection parameter becomes an attribute in\n        the ``selection`` dictionary. The format of the data within each\n        attribute is determined by the selection parameter definition within\n        Vega-Lite.\n\n    Examples\n    --------\n    The following two examples have equivalent definitions. Each one has a\n    point and interval selection parameter include in the chart definition.\n    The point seleciton parameter is named ``\"point_selection\"``. The interval\n    or box selection parameter is named ``\"interval_selection\"``.\n\n    The follow example uses ``st.altair_chart``:\n\n    >>> import streamlit as st\n    >>> import pandas as pd\n    >>> import numpy as np\n    >>> import altair as alt\n    >>>\n    >>> if \"data\" not in st.session_state:\n    >>>     st.session_state.data = pd.DataFrame(\n    ...         np.random.randn(20, 3), columns=[\"a\", \"b\", \"c\"]\n    ...     )\n    >>> df = st.session_state.data\n    >>>\n    >>> point_selector = alt.selection_point(\"point_selection\")\n    >>> interval_selector = alt.selection_interval(\"interval_selection\")\n    >>> chart = (\n    ...     alt.Chart(df)\n    ...     .mark_circle()\n    ...     .encode(\n    ...         x=\"a\",\n    ...         y=\"b\",\n    ...         size=\"c\",\n    ...         color=\"c\",\n    ...         tooltip=[\"a\", \"b\", \"c\"],\n    ...         fillOpacity=alt.condition(point_selector, alt.value(1), alt.value(0.3)),\n    ...     )\n    ...     .add_params(point_selector, interval_selector)\n    ... )\n    >>>\n    >>> event = st.altair_chart(chart, key=\"alt_chart\", on_select=\"rerun\")\n    >>>\n    >>> event\n\n    The following example uses ``st.vega_lite_chart``:\n\n    >>> import streamlit as st\n    >>> import pandas as pd\n    >>> import numpy as np\n    >>>\n    >>> if \"data\" not in st.session_state:\n    >>>     st.session_state.data = pd.DataFrame(\n    ...         np.random.randn(20, 3), columns=[\"a\", \"b\", \"c\"]\n    ...     )\n    >>>\n    >>> spec = {\n    ...     \"mark\": {\"type\": \"circle\", \"tooltip\": True},\n    ...     \"params\": [\n    ...         {\"name\": \"interval_selection\", \"select\": \"interval\"},\n    ...         {\"name\": \"point_selection\", \"select\": \"point\"},\n    ...     ],\n    ...     \"encoding\": {\n    ...         \"x\": {\"field\": \"a\", \"type\": \"quantitative\"},\n    ...         \"y\": {\"field\": \"b\", \"type\": \"quantitative\"},\n    ...         \"size\": {\"field\": \"c\", \"type\": \"quantitative\"},\n    ...         \"color\": {\"field\": \"c\", \"type\": \"quantitative\"},\n    ...         \"fillOpacity\": {\n    ...             \"condition\": {\"param\": \"point_selection\", \"value\": 1},\n    ...             \"value\": 0.3,\n    ...         },\n    ...     },\n    ... }\n    >>>\n    >>> event = st.vega_lite_chart(st.session_state.data, spec, key=\"vega_chart\", on_select=\"rerun\")\n    >>>\n    >>> event\n\n    Try selecting points in this interactive example. When you click a point,\n    the selection will appear under the attribute, ``\"point_selection\"``, which\n    is the name given to the point selection parameter. Similarly, when you\n    make an interval selection, it will appear under the attribute\n    ``\"interval_selection\"``. You can give your selection parameters other\n    names if desired.\n\n    If you hold ``Shift`` while selecting points, existing point selections\n    will be preserved. Interval selections are not preserved when making\n    additional selections.\n\n    .. output::\n        https://doc-chart-events-vega-lite-state.streamlit.app\n        height: 600px\n\n    \"\"\"\n\n    selection: AttributeDictionary\n\n\n@dataclass\nclass VegaLiteStateSerde:\n    \"\"\"VegaLiteStateSerde is used to serialize and deserialize the VegaLite Chart state.\"\"\"\n\n    selection_parameters: Sequence[str]\n\n    def deserialize(self, ui_value: str | None, widget_id: str = \"\") -> VegaLiteState:\n        empty_selection_state: VegaLiteState = {\n            \"selection\": AttributeDictionary(\n                # Initialize the select state with empty dictionaries for each selection parameter.\n                {param: {} for param in self.selection_parameters}\n            ),\n        }\n\n        selection_state = (\n            empty_selection_state\n            if ui_value is None\n            else cast(VegaLiteState, AttributeDictionary(json.loads(ui_value)))\n        )\n\n        if \"selection\" not in selection_state:\n            selection_state = empty_selection_state\n\n        return cast(VegaLiteState, AttributeDictionary(selection_state))\n\n    def serialize(self, selection_state: VegaLiteState) -> str:\n        return json.dumps(selection_state, default=str)\n\n\ndef _prepare_vega_lite_spec(\n    spec: VegaLiteSpec,\n    use_container_width: bool = False,\n    **kwargs,\n) -> VegaLiteSpec:\n    if len(kwargs):\n        # Support passing in kwargs. Example:\n        #   marshall(proto, {foo: 'bar'}, baz='boz')\n        # Merge spec with unflattened kwargs, where kwargs take precedence.\n        # This only works for string keys, but kwarg keys are strings anyways.\n        spec = dict(spec, **dicttools.unflatten(kwargs, _CHANNELS))\n    else:\n        # Clone the spec dict, since we may be mutating it.\n        spec = dict(spec)\n\n    if len(spec) == 0:\n        raise StreamlitAPIException(\"Vega-Lite charts require a non-empty spec dict.\")\n\n    if \"autosize\" not in spec:\n        # type fit does not work for many chart types. This change focuses\n        # on vconcat with use_container_width=True as there are unintended\n        # consequences of changing the default autosize for all charts.\n        # fit-x fits the width and height can be adjusted.\n        if \"vconcat\" in spec and use_container_width:\n            spec[\"autosize\"] = {\"type\": \"fit-x\", \"contains\": \"padding\"}\n        else:\n            spec[\"autosize\"] = {\"type\": \"fit\", \"contains\": \"padding\"}\n\n    return spec\n\n\ndef _serialize_data(data: Any) -> bytes:\n    \"\"\"Serialize the any type of data structure to Arrow IPC format (bytes).\"\"\"\n    import pyarrow as pa\n\n    if isinstance(data, pa.Table):\n        return type_util.pyarrow_table_to_bytes(data)\n\n    df = type_util.convert_anything_to_df(data)\n    return type_util.data_frame_to_bytes(df)\n\n\ndef _marshall_chart_data(\n    proto: ArrowVegaLiteChartProto,\n    spec: VegaLiteSpec,\n    data: Data = None,\n) -> None:\n    \"\"\"Adds the data to the proto and removes it from the spec dict.\n    These operations will happen in-place.\"\"\"\n\n    # Pull data out of spec dict when it's in a 'datasets' key:\n    #   datasets: {foo: df1_bytes, bar: df2_bytes}, ...}\n    if \"datasets\" in spec:\n        for dataset_name, dataset_data in spec[\"datasets\"].items():\n            dataset = proto.datasets.add()\n            dataset.name = str(dataset_name)\n            dataset.has_name = True\n            # The ID transformer (id_transform function registered before conversion to dict)\n            # already serializes the data into Arrow IPC format (bytes) when the Altair object\n            # gets converted into the vega-lite spec dict.\n            # If its already in bytes, we don't need to serialize it here again.\n            # We just need to pass the data information into the correct proto fields.\n\n            # TODO(lukasmasuch): Are there any other cases where we need to serialize the data\n            #                    or can we remove the _serialize_data here?\n            dataset.data.data = (\n                dataset_data\n                if isinstance(dataset_data, bytes)\n                else _serialize_data(dataset_data)\n            )\n        del spec[\"datasets\"]\n\n    # Pull data out of spec dict when it's in a top-level 'data' key:\n    #   {data: df}\n    #   {data: {values: df, ...}}\n    #   {data: {url: 'url'}}\n    #   {data: {name: 'foo'}}\n    if \"data\" in spec:\n        data_spec = spec[\"data\"]\n\n        if isinstance(data_spec, dict):\n            if \"values\" in data_spec:\n                data = data_spec[\"values\"]\n                del spec[\"data\"]\n        else:\n            data = data_spec\n            del spec[\"data\"]\n\n    if data is not None:\n        proto.data.data = _serialize_data(data)\n\n\ndef _convert_altair_to_vega_lite_spec(altair_chart: alt.Chart) -> VegaLiteSpec:\n    \"\"\"Convert an Altair chart object to a Vega-Lite chart spec.\"\"\"\n    import altair as alt\n\n    # Normally altair_chart.to_dict() would transform the dataframe used by the\n    # chart into an array of dictionaries. To avoid that, we install a\n    # transformer that replaces datasets with a reference by the object id of\n    # the dataframe. We then fill in the dataset manually later on.\n\n    datasets = {}\n\n    def id_transform(data) -> dict[str, str]:\n        \"\"\"Altair data transformer that serializes the data,\n        creates a stable name based on the hash of the data,\n        stores the bytes into the datasets mapping and\n        returns this name to have it be used in Altair.\n        \"\"\"\n        # Already serialize the data to be able to create a stable\n        # dataset name:\n        data_bytes = _serialize_data(data)\n        # Use the md5 hash of the data as the name:\n        h = hashlib.new(\"md5\", **HASHLIB_KWARGS)\n        h.update(str(data_bytes).encode(\"utf-8\"))\n        name = h.hexdigest()\n\n        datasets[name] = data_bytes\n        return {\"name\": name}\n\n    alt.data_transformers.register(\"id\", id_transform)  # type: ignore[attr-defined,unused-ignore]\n\n    # The default altair theme has some width/height defaults defined\n    # which are not useful for Streamlit. Therefore, we change the theme to\n    # \"none\" to avoid those defaults.\n    with alt.themes.enable(\"none\") if alt.themes.active == \"default\" else nullcontext():  # type: ignore[attr-defined,unused-ignore]\n        with alt.data_transformers.enable(\"id\"):  # type: ignore[attr-defined,unused-ignore]\n            chart_dict = altair_chart.to_dict()\n\n    # Put datasets back into the chart dict:\n    chart_dict[\"datasets\"] = datasets\n    return chart_dict\n\n\ndef _disallow_multi_view_charts(spec: VegaLiteSpec) -> None:\n    \"\"\"Raise an exception if the spec contains a multi-view chart (view composition).\n\n    This is intended to be used as a temporary solution to prevent selections on\n    multi-view charts. There are too many edge cases to handle selections on these\n    charts correctly, so we're disallowing them for now.\n\n    More information about view compositions: https://vega.github.io/vega-lite/docs/composition.html\n    \"\"\"\n\n    if (\n        any(key in spec for key in [\"layer\", \"hconcat\", \"vconcat\", \"concat\", \"spec\"])\n        or \"encoding\" not in spec\n    ):\n        raise StreamlitAPIException(\n            \"Selections are not yet supported for multi-view charts (chart compositions). \"\n            \"If you would like to use selections on multi-view charts, please upvote \"\n            \"this [Github issue](https://github.com/streamlit/streamlit/issues/8643).\"\n        )\n\n\ndef _extract_selection_parameters(spec: VegaLiteSpec) -> set[str]:\n    \"\"\"Extract the names of all valid selection parameters from the spec.\"\"\"\n    if not spec or \"params\" not in spec:\n        return set()\n\n    param_names = set()\n\n    for param in spec[\"params\"]:\n        # Check if it looks like a valid selection parameter:\n        # https://vega.github.io/vega-lite/docs/selection.html\n        if param.get(\"name\") and param.get(\"select\"):\n            # Selection found, just return here to not show the exception.\n            param_names.add(param[\"name\"])\n\n    return param_names\n\n\ndef _parse_selection_mode(\n    spec: VegaLiteSpec,\n    selection_mode: str | Iterable[str] | None,\n) -> list[str]:\n    \"\"\"Parse and check the user provided selection modes.\n\n    This will raise an exception if no valid selection parameters are found in the spec\n    or if the user provided selection modes are not defined in the spec.\n\n    Parameters\n    ----------\n    spec : VegaLiteSpec\n        The Vega-Lite chart specification.\n\n    selection_mode : str, Iterable[str], or None\n        The user provided selection mode(s).\n\n    Returns\n    -------\n    list[str]\n        The parsed selection mode(s) that should be activated.\n    \"\"\"\n\n    # Extract all selection parameters from the spec:\n    all_selection_params = _extract_selection_parameters(spec)\n\n    if not all_selection_params:\n        raise StreamlitAPIException(\n            \"Selections are activated, but the provided chart spec does not \"\n            \"have any selections defined. To add selections to `st.altair_chart`, check out the documentation \"\n            \"[here](https://altair-viz.github.io/user_guide/interactions.html#selections-capturing-chart-interactions). \"\n            \"For adding selections to `st.vega_lite_chart`, take a look \"\n            \"at the specification [here](https://vega.github.io/vega-lite/docs/selection.html).\"\n        )\n\n    if selection_mode is None:\n        # Activate all selection parameters:\n        return sorted(all_selection_params)\n\n    if isinstance(selection_mode, str):\n        # Convert single string to list:\n        selection_mode = [selection_mode]\n\n    # Check that all provided selection parameters are defined in the spec:\n    for selection_name in selection_mode:\n        if selection_name not in all_selection_params:\n            raise StreamlitAPIException(\n                f\"Selection parameter '{selection_name}' is not defined in the chart spec. \"\n                f\"Available selection parameters are: {all_selection_params}.\"\n            )\n    return sorted(selection_mode)\n\n\ndef _reset_counter_pattern(prefix: str, vega_spec: str) -> str:\n    \"\"\"Altair uses a global counter for unnamed parameters and views.\n    We need to reset these counters on a spec-level to make the\n    spec stable across reruns and avoid changes to the element ID.\n    \"\"\"\n    pattern = re.compile(rf'\"{prefix}\\d+\"')\n    # Get all matches without duplicates in order of appearance.\n    # Using a set here would not guarantee the order of appearance,\n    # which might lead to different replacements on each run.\n    # The order of the spec from Altair is expected to stay stable\n    # within the same session / Altair version.\n    # The order might change with Altair updates, but that's not really\n    # a case that is relevant for us since we mainly care about having\n    # this stable within a session.\n    if matches := list(dict.fromkeys(pattern.findall(vega_spec))):\n        # Add a prefix to the replacement to avoid\n        # replacing instances that already have been replaced before.\n        # The prefix here is arbitrarily chosen with the main goal\n        # that its extremely unlikely to already be part of the spec:\n        replacement_prefix = \"__replace_prefix_o9hd101n22e1__\"\n\n        # Replace all matches with a counter starting from 1\n        # We start from 1 to imitate the altair behavior.\n        for counter, match in enumerate(matches, start=1):\n            vega_spec = vega_spec.replace(\n                match, f'\"{replacement_prefix}{prefix}{counter}\"'\n            )\n\n        # Remove the prefix again from all replacements:\n        vega_spec = vega_spec.replace(replacement_prefix, \"\")\n    return vega_spec\n\n\ndef _stabilize_vega_json_spec(vega_spec: str) -> str:\n    \"\"\"Makes the chart spec stay stable across reruns and sessions.\n\n    Altair auto creates names for unnamed parameters & views. It uses a global counter\n    for the naming which will result in a different spec on every rerun.\n    In Streamlit, we need the spec to be stable across reruns and sessions to prevent the chart\n    from getting a new identity. So we need to replace the names with counter with a stable name.\n    Having a stable chart spec is also important for features like forward message cache,\n    where we don't want to have changing messages on every rerun.\n\n    Parameter counter:\n    https://github.com/vega/altair/blob/f345cd9368ae2bbc98628e9245c93fa9fb582621/altair/vegalite/v5/api.py#L196\n\n    View counter:\n    https://github.com/vega/altair/blob/f345cd9368ae2bbc98628e9245c93fa9fb582621/altair/vegalite/v5/api.py#L2885\n\n    This is temporary solution waiting for a fix for this issue:\n    https://github.com/vega/altair/issues/3416\n\n    Other solutions we considered:\n     - working on the dict object: this would require to iterate through the object and do the\n       same kind of replacement; though we would need to know the structure and since we need\n       the spec in String-format anyways, we deemed that executing the replacement on the\n       String is the better alternative\n     - resetting the counter: the counter is incremented already when the chart object is created\n       (see this GitHub issue comment https://github.com/vega/altair/issues/3416#issuecomment-2098530464),\n       so it would be too late here to reset the counter with a thread-lock to prevent interference\n       between sessions\n    \"\"\"\n\n    # We only want to apply these replacements if it is really necessary\n    # since there is a risk that we replace names that where chosen by the user\n    # and thereby introduce unwanted side effects.\n\n    # We only need to apply the param_ fix if there are actually parameters defined\n    # somewhere in the spec. We can check for this by looking for the '\"params\"' key.\n    # This isn't a perfect check, but good enough to prevent unnecessary executions\n    # for the majority of charts.\n    if '\"params\"' in vega_spec:\n        vega_spec = _reset_counter_pattern(\"param_\", vega_spec)\n\n    # Simple check if the spec contains a composite chart:\n    # https://vega.github.io/vega-lite/docs/composition.html\n    # Other charts will not contain the `view_` name,\n    # so its better to not replace this pattern.\n    if re.search(r'\"(vconcat|hconcat|facet|layer|concat|repeat)\"', vega_spec):\n        vega_spec = _reset_counter_pattern(\"view_\", vega_spec)\n    return vega_spec\n\n\nclass VegaChartsMixin:\n    \"\"\"Mix-in class for all vega-related chart commands.\n\n    Altair is a python wrapper on top of the vega-lite spec. And our\n    built-in chart commands are just another layer on-top of Altair.\n    All of these chart commands will be eventually converted to a vega-lite\n    spec and rendered using the same vega-lite chart component.\n    \"\"\"\n\n    @gather_metrics(\"line_chart\")\n    def line_chart(\n        self,\n        data: Data = None,\n        *,\n        x: str | None = None,\n        y: str | Sequence[str] | None = None,\n        x_label: str | None = None,\n        y_label: str | None = None,\n        color: str | Color | list[Color] | None = None,\n        width: int | None = None,\n        height: int | None = None,\n        use_container_width: bool = True,\n    ) -> DeltaGenerator:\n        \"\"\"Display a line chart.\n\n        This is syntax-sugar around ``st.altair_chart``. The main difference\n        is this command uses the data's own column and indices to figure out\n        the chart's Altair spec. As a result this is easier to use for many\n        \"just plot this\" scenarios, while being less customizable.\n\n        If ``st.line_chart`` does not guess the data specification\n        correctly, try specifying your desired chart using ``st.altair_chart``.\n\n        Parameters\n        ----------\n        data : pandas.DataFrame, pandas.Styler, pyarrow.Table, numpy.ndarray, \\\n            pyspark.sql.DataFrame, snowflake.snowpark.dataframe.DataFrame, \\\n            snowflake.snowpark.table.Table, Iterable, dict or None\n            Data to be plotted.\n\n        x : str or None\n            Column name or key associated to the x-axis data. If ``x`` is\n            ``None`` (default), Streamlit uses the data index for the x-axis\n            values.\n\n        y : str, Sequence of str, or None\n            Column name(s) or key(s) associated to the y-axis data. If this is\n            ``None`` (default), Streamlit draws the data of all remaining\n            columns as data series. If this is a ``Sequence`` of strings,\n            Streamlit draws several series on the same chart by melting your\n            wide-format table into a long-format table behind the scenes.\n\n        x_label : str or None\n            The label for the x-axis. If this is ``None`` (default), Streamlit\n            will use the column name specified in ``x`` if available, or else\n            no label will be displayed.\n\n        y_label : str or None\n            The label for the y-axis. If this is ``None`` (default), Streamlit\n            will use the column name(s) specified in ``y`` if available, or\n            else no label will be displayed.\n\n        color : str, tuple, Sequence of str, Sequence of tuple, or None\n            The color to use for different lines in this chart.\n\n            For a line chart with just one line, this can be:\n\n            * None, to use the default color.\n            * A hex string like \"#ffaa00\" or \"#ffaa0088\".\n            * An RGB or RGBA tuple with the red, green, blue, and alpha\n              components specified as ints from 0 to 255 or floats from 0.0 to\n              1.0.\n\n            For a line chart with multiple lines, where the dataframe is in\n            long format (that is, y is None or just one column), this can be:\n\n            * None, to use the default colors.\n            * The name of a column in the dataset. Data points will be grouped\n              into lines of the same color based on the value of this column.\n              In addition, if the values in this column match one of the color\n              formats above (hex string or color tuple), then that color will\n              be used.\n\n              For example: if the dataset has 1000 rows, but this column only\n              contains the values \"adult\", \"child\", and \"baby\", then those 1000\n              datapoints will be grouped into three lines whose colors will be\n              automatically selected from the default palette.\n\n              But, if for the same 1000-row dataset, this column contained\n              the values \"#ffaa00\", \"#f0f\", \"#0000ff\", then then those 1000\n              datapoints would still be grouped into three lines, but their\n              colors would be \"#ffaa00\", \"#f0f\", \"#0000ff\" this time around.\n\n            For a line chart with multiple lines, where the dataframe is in\n            wide format (that is, y is a Sequence of columns), this can be:\n\n            * None, to use the default colors.\n            * A list of string colors or color tuples to be used for each of\n              the lines in the chart. This list should have the same length\n              as the number of y values (e.g. ``color=[\"#fd0\", \"#f0f\", \"#04f\"]``\n              for three lines).\n\n        width : int or None\n            Desired width of the chart expressed in pixels. If ``width`` is\n            ``None`` (default), Streamlit sets the width of the chart to fit\n            its contents according to the plotting library, up to the width of\n            the parent container. If ``width`` is greater than the width of the\n            parent container, Streamlit sets the chart width to match the width\n            of the parent container.\n\n            To use ``width``, you must set ``use_container_width=False``.\n\n        height : int or None\n            Desired height of the chart expressed in pixels. If ``height`` is\n            ``None`` (default), Streamlit sets the height of the chart to fit\n            its contents according to the plotting library.\n\n        use_container_width : bool\n            Whether to override ``width`` with the width of the parent\n            container. If ``use_container_width`` is ``True`` (default),\n            Streamlit sets the width of the chart to match the width of the\n            parent container. If ``use_container_width`` is ``False``,\n            Streamlit sets the chart's width according to ``width``.\n\n        Examples\n        --------\n        >>> import streamlit as st\n        >>> import pandas as pd\n        >>> import numpy as np\n        >>>\n        >>> chart_data = pd.DataFrame(np.random.randn(20, 3), columns=[\"a\", \"b\", \"c\"])\n        >>>\n        >>> st.line_chart(chart_data)\n\n        .. output::\n           https://doc-line-chart.streamlit.app/\n           height: 440px\n\n        You can also choose different columns to use for x and y, as well as set\n        the color dynamically based on a 3rd column (assuming your dataframe is in\n        long format):\n\n        >>> import streamlit as st\n        >>> import pandas as pd\n        >>> import numpy as np\n        >>>\n        >>> chart_data = pd.DataFrame(\n        ...    {\n        ...        \"col1\": np.random.randn(20),\n        ...        \"col2\": np.random.randn(20),\n        ...        \"col3\": np.random.choice([\"A\", \"B\", \"C\"], 20),\n        ...    }\n        ... )\n        >>>\n        >>> st.line_chart(chart_data, x=\"col1\", y=\"col2\", color=\"col3\")\n\n        .. output::\n           https://doc-line-chart1.streamlit.app/\n           height: 440px\n\n        Finally, if your dataframe is in wide format, you can group multiple\n        columns under the y argument to show multiple lines with different\n        colors:\n\n        >>> import streamlit as st\n        >>> import pandas as pd\n        >>> import numpy as np\n        >>>\n        >>> chart_data = pd.DataFrame(np.random.randn(20, 3), columns=[\"col1\", \"col2\", \"col3\"])\n        >>>\n        >>> st.line_chart(\n        ...    chart_data, x=\"col1\", y=[\"col2\", \"col3\"], color=[\"#FF0000\", \"#0000FF\"]  # Optional\n        ... )\n\n        .. output::\n           https://doc-line-chart2.streamlit.app/\n           height: 440px\n\n        \"\"\"\n\n        chart, add_rows_metadata = generate_chart(\n            chart_type=ChartType.LINE,\n            data=data,\n            x_from_user=x,\n            y_from_user=y,\n            x_axis_label=x_label,\n            y_axis_label=y_label,\n            color_from_user=color,\n            size_from_user=None,\n            width=width,\n            height=height,\n        )\n        return cast(\n            \"DeltaGenerator\",\n            self._altair_chart(\n                chart,\n                use_container_width=use_container_width,\n                theme=\"streamlit\",\n                add_rows_metadata=add_rows_metadata,\n            ),\n        )\n\n    @gather_metrics(\"area_chart\")\n    def area_chart(\n        self,\n        data: Data = None,\n        *,\n        x: str | None = None,\n        y: str | Sequence[str] | None = None,\n        x_label: str | None = None,\n        y_label: str | None = None,\n        color: str | Color | list[Color] | None = None,\n        width: int | None = None,\n        height: int | None = None,\n        use_container_width: bool = True,\n    ) -> DeltaGenerator:\n        \"\"\"Display an area chart.\n\n        This is syntax-sugar around ``st.altair_chart``. The main difference\n        is this command uses the data's own column and indices to figure out\n        the chart's Altair spec. As a result this is easier to use for many\n        \"just plot this\" scenarios, while being less customizable.\n\n        If ``st.area_chart`` does not guess the data specification\n        correctly, try specifying your desired chart using ``st.altair_chart``.\n\n        Parameters\n        ----------\n        data : pandas.DataFrame, pandas.Styler, pyarrow.Table, numpy.ndarray, \\\n            pyspark.sql.DataFrame, snowflake.snowpark.dataframe.DataFrame, \\\n            snowflake.snowpark.table.Table, Iterable, or dict\n            Data to be plotted.\n\n        x : str or None\n            Column name or key associated to the x-axis data. If ``x`` is\n            ``None`` (default), Streamlit uses the data index for the x-axis\n            values.\n\n        y : str, Sequence of str, or None\n            Column name(s) or key(s) associated to the y-axis data. If this is\n            ``None`` (default), Streamlit draws the data of all remaining\n            columns as data series. If this is a ``Sequence`` of strings,\n            Streamlit draws several series on the same chart by melting your\n            wide-format table into a long-format table behind the scenes.\n\n        x_label : str or None\n            The label for the x-axis. If this is ``None`` (default), Streamlit\n            will use the column name specified in ``x`` if available, or else\n            no label will be displayed.\n\n        y_label : str or None\n            The label for the y-axis. If this is ``None`` (default), Streamlit\n            will use the column name(s) specified in ``y`` if available, or\n            else no label will be displayed.\n\n        color : str, tuple, Sequence of str, Sequence of tuple, or None\n            The color to use for different series in this chart.\n\n            For an area chart with just 1 series, this can be:\n\n            * None, to use the default color.\n            * A hex string like \"#ffaa00\" or \"#ffaa0088\".\n            * An RGB or RGBA tuple with the red, green, blue, and alpha\n              components specified as ints from 0 to 255 or floats from 0.0 to\n              1.0.\n\n            For an area chart with multiple series, where the dataframe is in\n            long format (that is, y is None or just one column), this can be:\n\n            * None, to use the default colors.\n            * The name of a column in the dataset. Data points will be grouped\n              into series of the same color based on the value of this column.\n              In addition, if the values in this column match one of the color\n              formats above (hex string or color tuple), then that color will\n              be used.\n\n              For example: if the dataset has 1000 rows, but this column only\n              contains the values \"adult\", \"child\", and \"baby\", then those 1000\n              datapoints will be grouped into three series whose colors will be\n              automatically selected from the default palette.\n\n              But, if for the same 1000-row dataset, this column contained\n              the values \"#ffaa00\", \"#f0f\", \"#0000ff\", then then those 1000\n              datapoints would still be grouped into 3 series, but their\n              colors would be \"#ffaa00\", \"#f0f\", \"#0000ff\" this time around.\n\n            For an area chart with multiple series, where the dataframe is in\n            wide format (that is, y is a Sequence of columns), this can be:\n\n            * None, to use the default colors.\n            * A list of string colors or color tuples to be used for each of\n              the series in the chart. This list should have the same length\n              as the number of y values (e.g. ``color=[\"#fd0\", \"#f0f\", \"#04f\"]``\n              for three lines).\n\n        width : int or None\n            Desired width of the chart expressed in pixels. If ``width`` is\n            ``None`` (default), Streamlit sets the width of the chart to fit\n            its contents according to the plotting library, up to the width of\n            the parent container. If ``width`` is greater than the width of the\n            parent container, Streamlit sets the chart width to match the width\n            of the parent container.\n\n            To use ``width``, you must set ``use_container_width=False``.\n\n        height : int or None\n            Desired height of the chart expressed in pixels. If ``height`` is\n            ``None`` (default), Streamlit sets the height of the chart to fit\n            its contents according to the plotting library.\n\n        use_container_width : bool\n            Whether to override ``width`` with the width of the parent\n            container. If ``use_container_width`` is ``True`` (default),\n            Streamlit sets the width of the chart to match the width of the\n            parent container. If ``use_container_width`` is ``False``,\n            Streamlit sets the chart's width according to ``width``.\n\n        Examples\n        --------\n        >>> import streamlit as st\n        >>> import pandas as pd\n        >>> import numpy as np\n        >>>\n        >>> chart_data = pd.DataFrame(np.random.randn(20, 3), columns=[\"a\", \"b\", \"c\"])\n        >>>\n        >>> st.area_chart(chart_data)\n\n        .. output::\n           https://doc-area-chart.streamlit.app/\n           height: 440px\n\n        You can also choose different columns to use for x and y, as well as set\n        the color dynamically based on a 3rd column (assuming your dataframe is in\n        long format):\n\n        >>> import streamlit as st\n        >>> import pandas as pd\n        >>> import numpy as np\n        >>>\n        >>> chart_data = pd.DataFrame(\n        ...    {\n        ...        \"col1\": np.random.randn(20),\n        ...        \"col2\": np.random.randn(20),\n        ...        \"col3\": np.random.choice([\"A\", \"B\", \"C\"], 20),\n        ...    }\n        ... )\n        >>>\n        >>> st.area_chart(chart_data, x=\"col1\", y=\"col2\", color=\"col3\")\n\n        .. output::\n           https://doc-area-chart1.streamlit.app/\n           height: 440px\n\n        Finally, if your dataframe is in wide format, you can group multiple\n        columns under the y argument to show multiple series with different\n        colors:\n\n        >>> import streamlit as st\n        >>> import pandas as pd\n        >>> import numpy as np\n        >>>\n        >>> chart_data = pd.DataFrame(np.random.randn(20, 3), columns=[\"col1\", \"col2\", \"col3\"])\n        >>>\n        >>> st.area_chart(\n        ...    chart_data, x=\"col1\", y=[\"col2\", \"col3\"], color=[\"#FF0000\", \"#0000FF\"]  # Optional\n        ... )\n\n        .. output::\n           https://doc-area-chart2.streamlit.app/\n           height: 440px\n\n        \"\"\"\n\n        chart, add_rows_metadata = generate_chart(\n            chart_type=ChartType.AREA,\n            data=data,\n            x_from_user=x,\n            y_from_user=y,\n            x_axis_label=x_label,\n            y_axis_label=y_label,\n            color_from_user=color,\n            size_from_user=None,\n            width=width,\n            height=height,\n        )\n        return cast(\n            \"DeltaGenerator\",\n            self._altair_chart(\n                chart,\n                use_container_width=use_container_width,\n                theme=\"streamlit\",\n                add_rows_metadata=add_rows_metadata,\n            ),\n        )\n\n    @gather_metrics(\"bar_chart\")\n    def bar_chart(\n        self,\n        data: Data = None,\n        *,\n        x: str | None = None,\n        y: str | Sequence[str] | None = None,\n        x_label: str | None = None,\n        y_label: str | None = None,\n        color: str | Color | list[Color] | None = None,\n        horizontal: bool = False,\n        width: int | None = None,\n        height: int | None = None,\n        use_container_width: bool = True,\n    ) -> DeltaGenerator:\n        \"\"\"Display a bar chart.\n\n        This is syntax-sugar around ``st.altair_chart``. The main difference\n        is this command uses the data's own column and indices to figure out\n        the chart's Altair spec. As a result this is easier to use for many\n        \"just plot this\" scenarios, while being less customizable.\n\n        If ``st.bar_chart`` does not guess the data specification\n        correctly, try specifying your desired chart using ``st.altair_chart``.\n\n        Parameters\n        ----------\n        data : pandas.DataFrame, pandas.Styler, pyarrow.Table, numpy.ndarray, \\\n            pyspark.sql.DataFrame, snowflake.snowpark.dataframe.DataFrame, \\\n            snowflake.snowpark.table.Table, Iterable, or dict\n            Data to be plotted.\n\n        x : str or None\n            Column name or key associated to the x-axis data. If ``x`` is\n            ``None`` (default), Streamlit uses the data index for the x-axis\n            values.\n\n        y : str, Sequence of str, or None\n            Column name(s) or key(s) associated to the y-axis data. If this is\n            ``None`` (default), Streamlit draws the data of all remaining\n            columns as data series. If this is a ``Sequence`` of strings,\n            Streamlit draws several series on the same chart by melting your\n            wide-format table into a long-format table behind the scenes.\n\n        x_label : str or None\n            The label for the x-axis. If this is ``None`` (default), Streamlit\n            will use the column name specified in ``x`` if available, or else\n            no label will be displayed.\n\n        y_label : str or None\n            The label for the y-axis. If this is ``None`` (default), Streamlit\n            will use the column name(s) specified in ``y`` if available, or\n            else no label will be displayed.\n\n        color : str, tuple, Sequence of str, Sequence of tuple, or None\n            The color to use for different series in this chart.\n\n            For a bar chart with just one series, this can be:\n\n            * None, to use the default color.\n            * A hex string like \"#ffaa00\" or \"#ffaa0088\".\n            * An RGB or RGBA tuple with the red, green, blue, and alpha\n              components specified as ints from 0 to 255 or floats from 0.0 to\n              1.0.\n\n            For a bar chart with multiple series, where the dataframe is in\n            long format (that is, y is None or just one column), this can be:\n\n            * None, to use the default colors.\n            * The name of a column in the dataset. Data points will be grouped\n              into series of the same color based on the value of this column.\n              In addition, if the values in this column match one of the color\n              formats above (hex string or color tuple), then that color will\n              be used.\n\n              For example: if the dataset has 1000 rows, but this column only\n              contains the values \"adult\", \"child\", and \"baby\", then those 1000\n              datapoints will be grouped into three series whose colors will be\n              automatically selected from the default palette.\n\n              But, if for the same 1000-row dataset, this column contained\n              the values \"#ffaa00\", \"#f0f\", \"#0000ff\", then then those 1000\n              datapoints would still be grouped into 3 series, but their\n              colors would be \"#ffaa00\", \"#f0f\", \"#0000ff\" this time around.\n\n            For a bar chart with multiple series, where the dataframe is in\n            wide format (that is, y is a Sequence of columns), this can be:\n\n            * None, to use the default colors.\n            * A list of string colors or color tuples to be used for each of\n              the series in the chart. This list should have the same length\n              as the number of y values (e.g. ``color=[\"#fd0\", \"#f0f\", \"#04f\"]``\n              for three lines).\n\n        horizontal : bool\n            Whether to make the bars horizontal. If this is ``False``\n            (default), the bars display vertically. If this is ``True``,\n            Streamlit swaps the x-axis and y-axis and the bars display\n            horizontally.\n\n        width : int or None\n            Desired width of the chart expressed in pixels. If ``width`` is\n            ``None`` (default), Streamlit sets the width of the chart to fit\n            its contents according to the plotting library, up to the width of\n            the parent container. If ``width`` is greater than the width of the\n            parent container, Streamlit sets the chart width to match the width\n            of the parent container.\n\n            To use ``width``, you must set ``use_container_width=False``.\n\n        height : int or None\n            Desired height of the chart expressed in pixels. If ``height`` is\n            ``None`` (default), Streamlit sets the height of the chart to fit\n            its contents according to the plotting library.\n\n        use_container_width : bool\n            Whether to override ``width`` with the width of the parent\n            container. If ``use_container_width`` is ``True`` (default),\n            Streamlit sets the width of the chart to match the width of the\n            parent container. If ``use_container_width`` is ``False``,\n            Streamlit sets the chart's width according to ``width``.\n\n        Examples\n        --------\n        >>> import streamlit as st\n        >>> import pandas as pd\n        >>> import numpy as np\n        >>>\n        >>> chart_data = pd.DataFrame(np.random.randn(20, 3), columns=[\"a\", \"b\", \"c\"])\n        >>>\n        >>> st.bar_chart(chart_data)\n\n        .. output::\n           https://doc-bar-chart.streamlit.app/\n           height: 440px\n\n        You can also choose different columns to use for x and y, as well as set\n        the color dynamically based on a 3rd column (assuming your dataframe is in\n        long format):\n\n        >>> import streamlit as st\n        >>> import pandas as pd\n        >>> import numpy as np\n        >>>\n        >>> chart_data = pd.DataFrame(\n        ...    {\n        ...        \"col1\": list(range(20)) * 3,\n        ...        \"col2\": np.random.randn(60),\n        ...        \"col3\": [\"A\"] * 20 + [\"B\"] * 20 + [\"C\"] * 20,\n        ...    }\n        ... )\n        >>>\n        >>> st.bar_chart(chart_data, x=\"col1\", y=\"col2\", color=\"col3\")\n\n        .. output::\n           https://doc-bar-chart1.streamlit.app/\n           height: 440px\n\n        If your dataframe is in wide format, you can group multiple\n        columns under the y argument to show multiple series with different\n        colors:\n\n        >>> import streamlit as st\n        >>> import pandas as pd\n        >>> import numpy as np\n        >>>\n        >>> chart_data = pd.DataFrame(\n        ...    {\"col1\": list(range(20)), \"col2\": np.random.randn(20), \"col3\": np.random.randn(20)}\n        ... )\n        >>>\n        >>> st.bar_chart(\n        ...    chart_data, x=\"col1\", y=[\"col2\", \"col3\"], color=[\"#FF0000\", \"#0000FF\"]  # Optional\n        ... )\n\n        .. output::\n           https://doc-bar-chart2.streamlit.app/\n           height: 440px\n\n        You can rotate your bar charts to display horizontally.\n\n        >>> import streamlit as st\n        >>> from vega_datasets import data\n        >>>\n        >>> source = data.barley()\n        >>>\n        >>> st.bar_chart(source, x=\"variety\", y=\"yield\", color=\"site\", horizontal=True)\n\n        .. output::\n           https://doc-bar-chart-horizontal.streamlit.app/\n           height: 440px\n\n        \"\"\"\n\n        bar_chart_type = (\n            ChartType.HORIZONTAL_BAR if horizontal else ChartType.VERTICAL_BAR\n        )\n\n        chart, add_rows_metadata = generate_chart(\n            chart_type=bar_chart_type,\n            data=data,\n            x_from_user=x,\n            y_from_user=y,\n            x_axis_label=x_label,\n            y_axis_label=y_label,\n            color_from_user=color,\n            size_from_user=None,\n            width=width,\n            height=height,\n        )\n        return cast(\n            \"DeltaGenerator\",\n            self._altair_chart(\n                chart,\n                use_container_width=use_container_width,\n                theme=\"streamlit\",\n                add_rows_metadata=add_rows_metadata,\n            ),\n        )\n\n    @gather_metrics(\"scatter_chart\")\n    def scatter_chart(\n        self,\n        data: Data = None,\n        *,\n        x: str | None = None,\n        y: str | Sequence[str] | None = None,\n        x_label: str | None = None,\n        y_label: str | None = None,\n        color: str | Color | list[Color] | None = None,\n        size: str | float | int | None = None,\n        width: int | None = None,\n        height: int | None = None,\n        use_container_width: bool = True,\n    ) -> DeltaGenerator:\n        \"\"\"Display a scatterplot chart.\n\n        This is syntax-sugar around ``st.altair_chart``. The main difference\n        is this command uses the data's own column and indices to figure out\n        the chart's Altair spec. As a result this is easier to use for many\n        \"just plot this\" scenarios, while being less customizable.\n\n        If ``st.scatter_chart`` does not guess the data specification correctly,\n        try specifying your desired chart using ``st.altair_chart``.\n\n        Parameters\n        ----------\n        data : pandas.DataFrame, pandas.Styler, pyarrow.Table, numpy.ndarray, \\\n            pyspark.sql.DataFrame, snowflake.snowpark.dataframe.DataFrame, \\\n            snowflake.snowpark.table.Table, Iterable, dict or None\n            Data to be plotted.\n\n        x : str or None\n            Column name or key associated to the x-axis data. If ``x`` is\n            ``None`` (default), Streamlit uses the data index for the x-axis\n            values.\n\n        y : str, Sequence of str, or None\n            Column name(s) or key(s) associated to the y-axis data. If this is\n            ``None`` (default), Streamlit draws the data of all remaining\n            columns as data series. If this is a ``Sequence`` of strings,\n            Streamlit draws several series on the same chart by melting your\n            wide-format table into a long-format table behind the scenes.\n\n        x_label : str or None\n            The label for the x-axis. If this is ``None`` (default), Streamlit\n            will use the column name specified in ``x`` if available, or else\n            no label will be displayed.\n\n        y_label : str or None\n            The label for the y-axis. If this is ``None`` (default), Streamlit\n            will use the column name(s) specified in ``y`` if available, or\n            else no label will be displayed.\n\n        color : str, tuple, Sequence of str, Sequence of tuple, or None\n            The color of the circles representing each datapoint.\n\n            This can be:\n\n            * None, to use the default color.\n            * A hex string like \"#ffaa00\" or \"#ffaa0088\".\n            * An RGB or RGBA tuple with the red, green, blue, and alpha\n              components specified as ints from 0 to 255 or floats from 0.0 to\n              1.0.\n            * The name of a column in the dataset where the color of that\n              datapoint will come from.\n\n              If the values in this column are in one of the color formats\n              above (hex string or color tuple), then that color will be used.\n\n              Otherwise, the color will be automatically picked from the\n              default palette.\n\n              For example: if the dataset has 1000 rows, but this column only\n              contains the values \"adult\", \"child\", and \"baby\", then those 1000\n              datapoints be shown using three colors from the default palette.\n\n              But if this column only contains floats or ints, then those\n              1000 datapoints will be shown using a colors from a continuous\n              color gradient.\n\n              Finally, if this column only contains the values \"#ffaa00\",\n              \"#f0f\", \"#0000ff\", then then each of those 1000 datapoints will\n              be assigned \"#ffaa00\", \"#f0f\", or \"#0000ff\" as appropriate.\n\n            If the dataframe is in wide format (that is, y is a Sequence of\n            columns), this can also be:\n\n            * A list of string colors or color tuples to be used for each of\n              the series in the chart. This list should have the same length\n              as the number of y values (e.g. ``color=[\"#fd0\", \"#f0f\", \"#04f\"]``\n              for three series).\n\n        size : str, float, int, or None\n            The size of the circles representing each point.\n\n            This can be:\n\n            * A number like 100, to specify a single size to use for all\n              datapoints.\n            * The name of the column to use for the size. This allows each\n              datapoint to be represented by a circle of a different size.\n\n        width : int or None\n            Desired width of the chart expressed in pixels. If ``width`` is\n            ``None`` (default), Streamlit sets the width of the chart to fit\n            its contents according to the plotting library, up to the width of\n            the parent container. If ``width`` is greater than the width of the\n            parent container, Streamlit sets the chart width to match the width\n            of the parent container.\n\n            To use ``width``, you must set ``use_container_width=False``.\n\n        height : int or None\n            Desired height of the chart expressed in pixels. If ``height`` is\n            ``None`` (default), Streamlit sets the height of the chart to fit\n            its contents according to the plotting library.\n\n        use_container_width : bool\n            Whether to override ``width`` with the width of the parent\n            container. If ``use_container_width`` is ``True`` (default),\n            Streamlit sets the width of the chart to match the width of the\n            parent container. If ``use_container_width`` is ``False``,\n            Streamlit sets the chart's width according to ``width``.\n\n        Examples\n        --------\n        >>> import streamlit as st\n        >>> import pandas as pd\n        >>> import numpy as np\n        >>>\n        >>> chart_data = pd.DataFrame(np.random.randn(20, 3), columns=[\"a\", \"b\", \"c\"])\n        >>>\n        >>> st.scatter_chart(chart_data)\n\n        .. output::\n           https://doc-scatter-chart.streamlit.app/\n           height: 440px\n\n        You can also choose different columns to use for x and y, as well as set\n        the color dynamically based on a 3rd column (assuming your dataframe is in\n        long format):\n\n        >>> import streamlit as st\n        >>> import pandas as pd\n        >>> import numpy as np\n        >>>\n        >>> chart_data = pd.DataFrame(np.random.randn(20, 3), columns=[\"col1\", \"col2\", \"col3\"])\n        >>> chart_data['col4'] = np.random.choice(['A','B','C'], 20)\n        >>>\n        >>> st.scatter_chart(\n        ...     chart_data,\n        ...     x='col1',\n        ...     y='col2',\n        ...     color='col4',\n        ...     size='col3',\n        ... )\n\n        .. output::\n           https://doc-scatter-chart1.streamlit.app/\n           height: 440px\n\n        Finally, if your dataframe is in wide format, you can group multiple\n        columns under the y argument to show multiple series with different\n        colors:\n\n        >>> import streamlit as st\n        >>> import pandas as pd\n        >>> import numpy as np\n        >>>\n        >>> chart_data = pd.DataFrame(np.random.randn(20, 4), columns=[\"col1\", \"col2\", \"col3\", \"col4\"])\n        >>>\n        >>> st.scatter_chart(\n        ...     chart_data,\n        ...     x='col1',\n        ...     y=['col2', 'col3'],\n        ...     size='col4',\n        ...     color=['#FF0000', '#0000FF'],  # Optional\n        ... )\n\n        .. output::\n           https://doc-scatter-chart2.streamlit.app/\n           height: 440px\n\n        \"\"\"\n\n        chart, add_rows_metadata = generate_chart(\n            chart_type=ChartType.SCATTER,\n            data=data,\n            x_from_user=x,\n            y_from_user=y,\n            x_axis_label=x_label,\n            y_axis_label=y_label,\n            color_from_user=color,\n            size_from_user=size,\n            width=width,\n            height=height,\n        )\n        return cast(\n            \"DeltaGenerator\",\n            self._altair_chart(\n                chart,\n                use_container_width=use_container_width,\n                theme=\"streamlit\",\n                add_rows_metadata=add_rows_metadata,\n            ),\n        )\n\n    @overload\n    def altair_chart(\n        self,\n        altair_chart: alt.Chart,\n        *,\n        use_container_width: bool = False,\n        theme: Literal[\"streamlit\"] | None = \"streamlit\",\n        key: Key | None = None,\n        on_select: Literal[\"ignore\"],  # No default value here to make it work with mypy\n        selection_mode: str | Iterable[str] | None = None,\n    ) -> DeltaGenerator: ...\n\n    @overload\n    def altair_chart(\n        self,\n        altair_chart: alt.Chart,\n        *,\n        use_container_width: bool = False,\n        theme: Literal[\"streamlit\"] | None = \"streamlit\",\n        key: Key | None = None,\n        on_select: Literal[\"rerun\"] | WidgetCallback = \"rerun\",\n        selection_mode: str | Iterable[str] | None = None,\n    ) -> VegaLiteState: ...\n\n    @gather_metrics(\"altair_chart\")\n    def altair_chart(\n        self,\n        altair_chart: alt.Chart,\n        *,\n        use_container_width: bool = False,\n        theme: Literal[\"streamlit\"] | None = \"streamlit\",\n        key: Key | None = None,\n        on_select: Literal[\"rerun\", \"ignore\"] | WidgetCallback = \"ignore\",\n        selection_mode: str | Iterable[str] | None = None,\n    ) -> DeltaGenerator | VegaLiteState:\n        \"\"\"Display a chart using the Vega-Altair library.\n\n        `Vega-Altair <https://altair-viz.github.io/>`_ is a declarative\n        statistical visualization library for Python, based on Vega and\n        Vega-Lite.\n\n        Parameters\n        ----------\n        altair_chart : altair.Chart\n            The Altair chart object to display. See\n            https://altair-viz.github.io/gallery/ for examples of graph\n            descriptions.\n\n        use_container_width : bool\n            Whether to override the figure's native width with the width of\n            the parent container. If ``use_container_width`` is ``False``\n            (default), Streamlit sets the width of the chart to fit its contents\n            according to the plotting library, up to the width of the parent\n            container. If ``use_container_width`` is ``True``, Streamlit sets\n            the width of the figure to match the width of the parent container.\n\n        theme : \"streamlit\" or None\n            The theme of the chart. If ``theme`` is ``\"streamlit\"`` (default),\n            Streamlit uses its own design default. If ``theme`` is ``None``,\n            Streamlit falls back to the default behavior of the library.\n\n        key : str\n            An optional string to use for giving this element a stable\n            identity. If ``key`` is ``None`` (default), this element's identity\n            will be determined based on the values of the other parameters.\n\n            Additionally, if selections are activated and ``key`` is provided,\n            Streamlit will register the key in Session State to store the\n            selection state. The selection state is read-only.\n\n        on_select : \"ignore\", \"rerun\", or callable\n            How the figure should respond to user selection events. This\n            controls whether or not the figure behaves like an input widget.\n            ``on_select`` can be one of the following:\n\n            - ``\"ignore\"`` (default): Streamlit will not react to any selection\n              events in the chart. The figure will not behave like an input\n              widget.\n\n            - ``\"rerun\"``: Streamlit will rerun the app when the user selects\n              data in the chart. In this case, ``st.altair_chart`` will return\n              the selection data as a dictionary.\n\n            - A ``callable``: Streamlit will rerun the app and execute the\n              ``callable`` as a callback function before the rest of the app.\n              In this case, ``st.altair_chart`` will return the selection data\n              as a dictionary.\n\n            To use selection events, the object passed to ``altair_chart`` must\n            include selection paramters. To learn about defining interactions\n            in Altair and how to declare selection-type parameters, see\n            `Interactive Charts \\\n            <https://altair-viz.github.io/user_guide/interactions.html>`_\n            in Altair's documentation.\n\n        selection_mode : str or Iterable of str\n            The selection parameters Streamlit should use. If\n            ``selection_mode`` is ``None`` (default), Streamlit will use all\n            selection parameters defined in the chart's Altair spec.\n\n            When Streamlit uses a selection parameter, selections from that\n            parameter will trigger a rerun and be included in the selection\n            state. When Streamlit does not use a selection parameter,\n            selections from that parameter will not trigger a rerun and not be\n            included in the selection state.\n\n            Selection parameters are identified by their ``name`` property.\n\n        Returns\n        -------\n        element or dict\n            If ``on_select`` is ``\"ignore\"`` (default), this method returns an\n            internal placeholder for the chart element that can be used with\n            the ``.add_rows()`` method. Otherwise, this method returns a\n            dictionary-like object that supports both key and attribute\n            notation. The attributes are described by the ``VegaLiteState``\n            dictionary schema.\n\n        Example\n        -------\n\n        >>> import streamlit as st\n        >>> import pandas as pd\n        >>> import numpy as np\n        >>> import altair as alt\n        >>>\n        >>> chart_data = pd.DataFrame(np.random.randn(20, 3), columns=[\"a\", \"b\", \"c\"])\n        >>>\n        >>> c = (\n        ...    alt.Chart(chart_data)\n        ...    .mark_circle()\n        ...    .encode(x=\"a\", y=\"b\", size=\"c\", color=\"c\", tooltip=[\"a\", \"b\", \"c\"])\n        ... )\n        >>>\n        >>> st.altair_chart(c, use_container_width=True)\n\n        .. output::\n           https://doc-vega-lite-chart.streamlit.app/\n           height: 450px\n\n        \"\"\"\n        return self._altair_chart(\n            altair_chart=altair_chart,\n            use_container_width=use_container_width,\n            theme=theme,\n            key=key,\n            on_select=on_select,\n            selection_mode=selection_mode,\n        )\n\n    @overload\n    def vega_lite_chart(\n        self,\n        data: Data = None,\n        spec: VegaLiteSpec | None = None,\n        *,\n        use_container_width: bool = False,\n        theme: Literal[\"streamlit\"] | None = \"streamlit\",\n        key: Key | None = None,\n        on_select: Literal[\"ignore\"],  # No default value here to make it work with mypy\n        selection_mode: str | Iterable[str] | None = None,\n        **kwargs: Any,\n    ) -> DeltaGenerator: ...\n\n    @overload\n    def vega_lite_chart(\n        self,\n        data: Data = None,\n        spec: VegaLiteSpec | None = None,\n        *,\n        use_container_width: bool = False,\n        theme: Literal[\"streamlit\"] | None = \"streamlit\",\n        key: Key | None = None,\n        on_select: Literal[\"rerun\"] | WidgetCallback = \"rerun\",\n        selection_mode: str | Iterable[str] | None = None,\n        **kwargs: Any,\n    ) -> VegaLiteState: ...\n\n    @gather_metrics(\"vega_lite_chart\")\n    def vega_lite_chart(\n        self,\n        data: Data = None,\n        spec: VegaLiteSpec | None = None,\n        *,\n        use_container_width: bool = False,\n        theme: Literal[\"streamlit\"] | None = \"streamlit\",\n        key: Key | None = None,\n        on_select: Literal[\"rerun\", \"ignore\"] | WidgetCallback = \"ignore\",\n        selection_mode: str | Iterable[str] | None = None,\n        **kwargs: Any,\n    ) -> DeltaGenerator | VegaLiteState:\n        \"\"\"Display a chart using the Vega-Lite library.\n\n        `Vega-Lite <https://vega.github.io/vega-lite/>`_ is a high-level\n        grammar for defining interactive graphics.\n\n        Parameters\n        ----------\n        data : pandas.DataFrame, pandas.Styler, pyarrow.Table, numpy.ndarray, Iterable, dict, or None\n            Either the data to be plotted or a Vega-Lite spec containing the\n            data (which more closely follows the Vega-Lite API).\n\n        spec : dict or None\n            The Vega-Lite spec for the chart. If ``spec`` is ``None`` (default),\n            Streamlit uses the spec passed in ``data``. You cannot pass a spec\n            to both ``data`` and ``spec``. See\n            https://vega.github.io/vega-lite/docs/ for more info.\n\n        use_container_width : bool\n            Whether to override the figure's native width with the width of\n            the parent container. If ``use_container_width`` is ``False``\n            (default), Streamlit sets the width of the chart to fit its contents\n            according to the plotting library, up to the width of the parent\n            container. If ``use_container_width`` is ``True``, Streamlit sets\n            the width of the figure to match the width of the parent container.\n\n        theme : \"streamlit\" or None\n            The theme of the chart. If ``theme`` is ``\"streamlit\"`` (default),\n            Streamlit uses its own design default. If ``theme`` is ``None``,\n            Streamlit falls back to the default behavior of the library.\n\n        key : str\n            An optional string to use for giving this element a stable\n            identity. If ``key`` is ``None`` (default), this element's identity\n            will be determined based on the values of the other parameters.\n\n            Additionally, if selections are activated and ``key`` is provided,\n            Streamlit will register the key in Session State to store the\n            selection state. The selection state is read-only.\n\n        on_select : \"ignore\", \"rerun\", or callable\n            How the figure should respond to user selection events. This\n            controls whether or not the figure behaves like an input widget.\n            ``on_select`` can be one of the following:\n\n            - ``\"ignore\"`` (default): Streamlit will not react to any selection\n              events in the chart. The figure will not behave like an input\n              widget.\n\n            - ``\"rerun\"``: Streamlit will rerun the app when the user selects\n              data in the chart. In this case, ``st.vega_lite_chart`` will\n              return the selection data as a dictionary.\n\n            - A ``callable``: Streamlit will rerun the app and execute the\n              ``callable`` as a callback function before the rest of the app.\n              In this case, ``st.vega_lite_chart`` will return the selection data\n              as a dictionary.\n\n            To use selection events, the Vega-Lite spec defined in ``data`` or\n            ``spec`` must include selection parameters from the the charting\n            library. To learn about defining interactions in Vega-Lite, see\n            `Dynamic Behaviors with Parameters \\\n            <https://vega.github.io/vega-lite/docs/parameter.html>`_\n            in Vega-Lite's documentation.\n\n        selection_mode : str or Iterable of str\n            The selection parameters Streamlit should use. If\n            ``selection_mode`` is ``None`` (default), Streamlit will use all\n            selection parameters defined in the chart's Vega-Lite spec.\n\n            When Streamlit uses a selection parameter, selections from that\n            parameter will trigger a rerun and be included in the selection\n            state. When Streamlit does not use a selection parameter,\n            selections from that parameter will not trigger a rerun and not be\n            included in the selection state.\n\n            Selection parameters are identified by their ``name`` property.\n\n        **kwargs : any\n            The Vega-Lite spec for the chart as keywords. This is an alternative\n            to ``spec``.\n\n        Returns\n        -------\n        element or dict\n            If ``on_select`` is ``\"ignore\"`` (default), this method returns an\n            internal placeholder for the chart element that can be used with\n            the ``.add_rows()`` method. Otherwise, this method returns a\n            dictionary-like object that supports both key and attribute\n            notation. The attributes are described by the ``VegaLiteState``\n            dictionary schema.\n\n        Example\n        -------\n        >>> import streamlit as st\n        >>> import pandas as pd\n        >>> import numpy as np\n        >>>\n        >>> chart_data = pd.DataFrame(np.random.randn(200, 3), columns=[\"a\", \"b\", \"c\"])\n        >>>\n        >>> st.vega_lite_chart(\n        ...    chart_data,\n        ...    {\n        ...        \"mark\": {\"type\": \"circle\", \"tooltip\": True},\n        ...        \"encoding\": {\n        ...            \"x\": {\"field\": \"a\", \"type\": \"quantitative\"},\n        ...            \"y\": {\"field\": \"b\", \"type\": \"quantitative\"},\n        ...            \"size\": {\"field\": \"c\", \"type\": \"quantitative\"},\n        ...            \"color\": {\"field\": \"c\", \"type\": \"quantitative\"},\n        ...        },\n        ...    },\n        ... )\n\n        .. output::\n           https://doc-vega-lite-chart.streamlit.app/\n           height: 450px\n\n        Examples of Vega-Lite usage without Streamlit can be found at\n        https://vega.github.io/vega-lite/examples/. Most of those can be easily\n        translated to the syntax shown above.\n\n        \"\"\"\n        return self._vega_lite_chart(\n            data=data,\n            spec=spec,\n            use_container_width=use_container_width,\n            theme=theme,\n            key=key,\n            on_select=on_select,\n            selection_mode=selection_mode,\n            **kwargs,\n        )\n\n    def _altair_chart(\n        self,\n        altair_chart: alt.Chart,\n        use_container_width: bool = False,\n        theme: Literal[\"streamlit\"] | None = \"streamlit\",\n        key: Key | None = None,\n        on_select: Literal[\"rerun\", \"ignore\"] | WidgetCallback = \"ignore\",\n        selection_mode: str | Iterable[str] | None = None,\n        add_rows_metadata: AddRowsMetadata | None = None,\n    ) -> DeltaGenerator | VegaLiteState:\n        \"\"\"Internal method to enqueue a vega-lite chart element based on an Altair chart.\n\n        See the `altair_chart` method docstring for more information.\n        \"\"\"\n\n        if type_util.is_altair_version_less_than(\"5.0.0\") and on_select != \"ignore\":\n            raise StreamlitAPIException(\n                \"Streamlit does not support selections with Altair 4.x. Please upgrade to Version 5. \"\n                \"If you would like to use Altair 4.x with selections, please upvote \"\n                \"this [Github issue](https://github.com/streamlit/streamlit/issues/8516).\"\n            )\n\n        vega_lite_spec = _convert_altair_to_vega_lite_spec(altair_chart)\n        return self._vega_lite_chart(\n            data=None,  # The data is already part of the spec\n            spec=vega_lite_spec,\n            use_container_width=use_container_width,\n            theme=theme,\n            key=key,\n            on_select=on_select,\n            selection_mode=selection_mode,\n            add_rows_metadata=add_rows_metadata,\n        )\n\n    def _vega_lite_chart(\n        self,\n        data: Data = None,\n        spec: VegaLiteSpec | None = None,\n        use_container_width: bool = False,\n        theme: Literal[\"streamlit\"] | None = \"streamlit\",\n        key: Key | None = None,\n        on_select: Literal[\"rerun\", \"ignore\"] | WidgetCallback = \"ignore\",\n        selection_mode: str | Iterable[str] | None = None,\n        add_rows_metadata: AddRowsMetadata | None = None,\n        **kwargs: Any,\n    ) -> DeltaGenerator | VegaLiteState:\n        \"\"\"Internal method to enqueue a vega-lite chart element based on a vega-lite spec.\n\n        See the `vega_lite_chart` method docstring for more information.\n        \"\"\"\n\n        if theme not in [\"streamlit\", None]:\n            raise StreamlitAPIException(\n                f'You set theme=\"{theme}\" while Streamlit charts only support theme=\u201dstreamlit\u201d or theme=None to fallback to the default library theme.'\n            )\n\n        if on_select not in [\"ignore\", \"rerun\"] and not callable(on_select):\n            raise StreamlitAPIException(\n                f\"You have passed {on_select} to `on_select`. But only 'ignore', 'rerun', or a callable is supported.\"\n            )\n\n        key = to_key(key)\n        is_selection_activated = on_select != \"ignore\"\n\n        if is_selection_activated:\n            # Run some checks that are only relevant when selections are activated\n\n            check_fragment_path_policy(self.dg)\n            check_cache_replay_rules()\n            if callable(on_select):\n                check_callback_rules(self.dg, on_select)\n            check_session_state_rules(default_value=None, key=key, writes_allowed=False)\n\n        # Support passing data inside spec['datasets'] and spec['data'].\n        # (The data gets pulled out of the spec dict later on.)\n        if isinstance(data, dict) and spec is None:\n            spec = data\n            data = None\n\n        if spec is None:\n            spec = {}\n\n        vega_lite_proto = ArrowVegaLiteChartProto()\n\n        spec = _prepare_vega_lite_spec(spec, use_container_width, **kwargs)\n        _marshall_chart_data(vega_lite_proto, spec, data)\n\n        # Prevent the spec from changing across reruns:\n        vega_lite_proto.spec = _stabilize_vega_json_spec(json.dumps(spec))\n        vega_lite_proto.use_container_width = use_container_width\n        vega_lite_proto.theme = theme or \"\"\n\n        if is_selection_activated:\n            # Import here to avoid circular imports\n            from streamlit.elements.form import current_form_id\n\n            # Load the stabilized spec again as a dict:\n            final_spec = json.loads(vega_lite_proto.spec)\n            # Temporary limitation to disallow multi-view charts (compositions) with selections.\n            _disallow_multi_view_charts(final_spec)\n\n            # Parse and check the specified selection modes\n            parsed_selection_modes = _parse_selection_mode(final_spec, selection_mode)\n            vega_lite_proto.selection_mode.extend(parsed_selection_modes)\n\n            vega_lite_proto.form_id = current_form_id(self.dg)\n\n            ctx = get_script_run_ctx()\n            vega_lite_proto.id = compute_widget_id(\n                \"arrow_vega_lite_chart\",\n                user_key=key,\n                key=key,\n                vega_lite_spec=vega_lite_proto.spec,\n                # The data is either in vega_lite_proto.data.data\n                # or in a named dataset in vega_lite_proto.datasets\n                vega_lite_data=vega_lite_proto.data.data,\n                # Its enough to just use the names here since they are expected\n                # to contain hashes based on the dataset data.\n                named_datasets=[dataset.name for dataset in vega_lite_proto.datasets],\n                theme=theme,\n                use_container_width=use_container_width,\n                selection_mode=parsed_selection_modes,\n                form_id=vega_lite_proto.form_id,\n                page=ctx.page_script_hash if ctx else None,\n            )\n\n            serde = VegaLiteStateSerde(parsed_selection_modes)\n\n            widget_state = register_widget(\n                \"vega_lite_chart\",\n                vega_lite_proto,\n                user_key=key,\n                on_change_handler=on_select if callable(on_select) else None,\n                deserializer=serde.deserialize,\n                serializer=serde.serialize,\n                ctx=ctx,\n            )\n\n            self.dg._enqueue(\n                \"arrow_vega_lite_chart\",\n                vega_lite_proto,\n                add_rows_metadata=add_rows_metadata,\n            )\n            return cast(VegaLiteState, widget_state.value)\n        # If its not used with selections activated, just return\n        # the delta generator related to this element.\n        return self.dg._enqueue(\n            \"arrow_vega_lite_chart\",\n            vega_lite_proto,\n            add_rows_metadata=add_rows_metadata,\n        )\n\n    @property\n    def dg(self) -> DeltaGenerator:\n        \"\"\"Get our DeltaGenerator.\"\"\"\n        return cast(\"DeltaGenerator\", self)\n", "lib/streamlit/elements/layouts.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom typing import TYPE_CHECKING, Literal, Sequence, Union, cast\n\nfrom typing_extensions import TypeAlias\n\nfrom streamlit.errors import StreamlitAPIException\nfrom streamlit.proto.Block_pb2 import Block as BlockProto\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.string_util import validate_icon_or_emoji\n\nif TYPE_CHECKING:\n    from streamlit.delta_generator import DeltaGenerator\n    from streamlit.elements.lib.dialog import Dialog\n    from streamlit.elements.lib.mutable_status_container import StatusContainer\n\nSpecType: TypeAlias = Union[int, Sequence[Union[int, float]]]\n\n\nclass LayoutsMixin:\n    @gather_metrics(\"container\")\n    def container(\n        self, *, height: int | None = None, border: bool | None = None\n    ) -> DeltaGenerator:\n        \"\"\"Insert a multi-element container.\n\n        Inserts an invisible container into your app that can be used to hold\n        multiple elements. This allows you to, for example, insert multiple\n        elements into your app out of order.\n\n        To add elements to the returned container, you can use the ``with`` notation\n        (preferred) or just call methods directly on the returned object. See\n        examples below.\n\n        Parameters\n        ----------\n        height : int or None\n            Desired height of the container expressed in pixels. If ``None`` (default)\n            the container grows to fit its content. If a fixed height, scrolling is\n            enabled for large content and a grey border is shown around the container\n            to visually separate its scroll surface from the rest of the app.\n\n            .. note::\n                Use containers with scroll sparingly. If you do, try to keep\n                the height small (below 500 pixels). Otherwise, the scroll\n                surface of the container might cover the majority of the screen\n                on mobile devices, which makes it hard to scroll the rest of the app.\n\n        border : bool or None\n            Whether to show a border around the container. If ``None`` (default), a\n            border is shown if the container is set to a fixed height and not\n            shown otherwise.\n\n\n        Examples\n        --------\n        Inserting elements using ``with`` notation:\n\n        >>> import streamlit as st\n        >>>\n        >>> with st.container():\n        ...    st.write(\"This is inside the container\")\n        ...\n        ...    # You can call any Streamlit command, including custom components:\n        ...    st.bar_chart(np.random.randn(50, 3))\n        ...\n        >>> st.write(\"This is outside the container\")\n\n        .. output ::\n            https://doc-container1.streamlit.app/\n            height: 520px\n\n        Inserting elements out of order:\n\n        >>> import streamlit as st\n        >>>\n        >>> container = st.container(border=True)\n        >>> container.write(\"This is inside the container\")\n        >>> st.write(\"This is outside the container\")\n        >>>\n        >>> # Now insert some more in the container\n        >>> container.write(\"This is inside too\")\n\n        .. output ::\n            https://doc-container2.streamlit.app/\n            height: 300px\n\n        Using ``height`` to make a grid:\n\n        >>> import streamlit as st\n        >>>\n        >>> row1 = st.columns(3)\n        >>> row2 = st.columns(3)\n        >>>\n        >>> for col in row1 + row2:\n        >>>     tile = col.container(height=120)\n        >>>     tile.title(\":balloon:\")\n\n        .. output ::\n            https://doc-container3.streamlit.app/\n            height: 350px\n\n        Using ``height`` to create a scrolling container for long content:\n\n        >>> import streamlit as st\n        >>>\n        >>> long_text = \"Lorem ipsum. \" * 1000\n        >>>\n        >>> with st.container(height=300):\n        >>>     st.markdown(long_text)\n\n        .. output ::\n            https://doc-container4.streamlit.app/\n            height: 400px\n\n        \"\"\"\n        block_proto = BlockProto()\n        block_proto.allow_empty = False\n        block_proto.vertical.border = border or False\n\n        if height:\n            # Activate scrolling container behavior:\n            block_proto.allow_empty = True\n            block_proto.vertical.height = height\n            if border is None:\n                # If border is None, we activated the\n                # border as default setting for scrolling\n                # containers.\n                block_proto.vertical.border = True\n\n        return self.dg._block(block_proto)\n\n    @gather_metrics(\"columns\")\n    def columns(\n        self,\n        spec: SpecType,\n        *,\n        gap: Literal[\"small\", \"medium\", \"large\"] = \"small\",\n        vertical_alignment: Literal[\"top\", \"center\", \"bottom\"] = \"top\",\n    ) -> list[DeltaGenerator]:\n        \"\"\"Insert containers laid out as side-by-side columns.\n\n        Inserts a number of multi-element containers laid out side-by-side and\n        returns a list of container objects.\n\n        To add elements to the returned containers, you can use the ``with`` notation\n        (preferred) or just call methods directly on the returned object. See\n        examples below.\n\n        Columns can only be placed inside other columns up to one level of nesting.\n\n        .. warning::\n            Columns cannot be placed inside other columns in the sidebar. This\n            is only possible in the main area of the app.\n\n        Parameters\n        ----------\n        spec : int or Iterable of numbers\n            Controls the number and width of columns to insert. Can be one of:\n\n            * An integer that specifies the number of columns. All columns have equal\n              width in this case.\n            * An Iterable of numbers (int or float) that specify the relative width of\n              each column. E.g. ``[0.7, 0.3]`` creates two columns where the first\n              one takes up 70% of the available with and the second one takes up 30%.\n              Or ``[1, 2, 3]`` creates three columns where the second one is two times\n              the width of the first one, and the third one is three times that width.\n\n        gap : \"small\", \"medium\", or \"large\"\n            The size of the gap between the columns. The default is ``\"small\"``.\n\n        vertical_alignment : \"top\", \"center\", or \"bottom\"\n            The vertical alignment of the content inside the columns. The\n            default is ``\"top\"``.\n\n        Returns\n        -------\n        list of containers\n            A list of container objects.\n\n        Examples\n        --------\n        You can use the ``with`` notation to insert any element into a column:\n\n        >>> import streamlit as st\n        >>>\n        >>> col1, col2, col3 = st.columns(3)\n        >>>\n        >>> with col1:\n        ...    st.header(\"A cat\")\n        ...    st.image(\"https://static.streamlit.io/examples/cat.jpg\")\n        ...\n        >>> with col2:\n        ...    st.header(\"A dog\")\n        ...    st.image(\"https://static.streamlit.io/examples/dog.jpg\")\n        ...\n        >>> with col3:\n        ...    st.header(\"An owl\")\n        ...    st.image(\"https://static.streamlit.io/examples/owl.jpg\")\n\n        .. output ::\n            https://doc-columns1.streamlit.app/\n            height: 620px\n\n        Or you can just call methods directly on the returned objects:\n\n        >>> import streamlit as st\n        >>> import numpy as np\n        >>>\n        >>> col1, col2 = st.columns([3, 1])\n        >>> data = np.random.randn(10, 1)\n        >>>\n        >>> col1.subheader(\"A wide column with a chart\")\n        >>> col1.line_chart(data)\n        >>>\n        >>> col2.subheader(\"A narrow column with the data\")\n        >>> col2.write(data)\n\n        .. output ::\n            https://doc-columns2.streamlit.app/\n            height: 550px\n\n        Use ``vertical_alignment=\"bottom\"`` to align widgets.\n\n        >>> import streamlit as st\n        >>>\n        >>> left, middle, right = st.columns(3, vertical_alignment=\"bottom\")\n        >>>\n        >>> left.text_input(\"Write something\")\n        >>> middle.button(\"Click me\", use_container_width=True)\n        >>> right.checkbox(\"Check me\")\n\n        .. output ::\n            https://doc-columns-bottom-widgets.streamlit.app/\n            height: 200px\n\n        Adjust vertical alignment to customize your grid layouts.\n\n        >>> import streamlit as st\n        >>> import numpy as np\n        >>>\n        >>> vertical_alignment = st.selectbox(\n        >>>     \"Vertical alignment\", [\"top\", \"center\", \"bottom\"], index=2\n        >>> )\n        >>>\n        >>> left, middle, right = st.columns(3, vertical_alignment=vertical_alignment)\n        >>> left.image(\"https://static.streamlit.io/examples/cat.jpg\")\n        >>> middle.image(\"https://static.streamlit.io/examples/dog.jpg\")\n        >>> right.image(\"https://static.streamlit.io/examples/owl.jpg\")\n\n        .. output ::\n            https://doc-columns-vertical-alignment.streamlit.app/\n            height: 600px\n\n        \"\"\"\n        weights = spec\n        if isinstance(weights, int):\n            # If the user provided a single number, expand into equal weights.\n            # E.g. (1,) * 3 => (1, 1, 1)\n            # NOTE: A negative/zero spec will expand into an empty tuple.\n            weights = (1,) * weights\n\n        if len(weights) == 0 or any(weight <= 0 for weight in weights):\n            raise StreamlitAPIException(\n                \"The input argument to st.columns must be either a \"\n                \"positive integer or a list of positive numeric weights. \"\n                \"See [documentation](https://docs.streamlit.io/develop/api-reference/layout/st.columns) \"\n                \"for more information.\"\n            )\n\n        vertical_alignment_mapping: dict[\n            str, BlockProto.Column.VerticalAlignment.ValueType\n        ] = {\n            \"top\": BlockProto.Column.VerticalAlignment.TOP,\n            \"center\": BlockProto.Column.VerticalAlignment.CENTER,\n            \"bottom\": BlockProto.Column.VerticalAlignment.BOTTOM,\n        }\n\n        if vertical_alignment not in vertical_alignment_mapping:\n            raise StreamlitAPIException(\n                'The `vertical_alignment` argument to st.columns must be \"top\", \"center\", or \"bottom\". \\n'\n                f\"The argument passed was {vertical_alignment}.\"\n            )\n\n        def column_gap(gap):\n            if isinstance(gap, str):\n                gap_size = gap.lower()\n                valid_sizes = [\"small\", \"medium\", \"large\"]\n\n                if gap_size in valid_sizes:\n                    return gap_size\n\n            raise StreamlitAPIException(\n                'The gap argument to st.columns must be \"small\", \"medium\", or \"large\". \\n'\n                f\"The argument passed was {gap}.\"\n            )\n\n        gap_size = column_gap(gap)\n\n        def column_proto(normalized_weight: float) -> BlockProto:\n            col_proto = BlockProto()\n            col_proto.column.weight = normalized_weight\n            col_proto.column.gap = gap_size\n            col_proto.column.vertical_alignment = vertical_alignment_mapping[\n                vertical_alignment\n            ]\n            col_proto.allow_empty = True\n            return col_proto\n\n        block_proto = BlockProto()\n        block_proto.horizontal.gap = gap_size\n        row = self.dg._block(block_proto)\n        total_weight = sum(weights)\n        return [row._block(column_proto(w / total_weight)) for w in weights]\n\n    @gather_metrics(\"tabs\")\n    def tabs(self, tabs: Sequence[str]) -> Sequence[DeltaGenerator]:\n        r\"\"\"Insert containers separated into tabs.\n\n        Inserts a number of multi-element containers as tabs.\n        Tabs are a navigational element that allows users to easily\n        move between groups of related content.\n\n        To add elements to the returned containers, you can use the ``with`` notation\n        (preferred) or just call methods directly on the returned object. See\n        examples below.\n\n        .. warning::\n            All the content of every tab is always sent to and rendered on the frontend.\n            Conditional rendering is currently not supported.\n\n        Parameters\n        ----------\n        tabs : list of str\n            Creates a tab for each string in the list. The first tab is selected by default.\n            The string is used as the name of the tab and can optionally contain Markdown,\n            supporting the following elements: Bold, Italics, Strikethroughs, Inline Code,\n            Emojis, and Links.\n\n            This also supports:\n\n            * Emoji shortcodes, such as ``:+1:``  and ``:sunglasses:``.\n              For a list of all supported codes,\n              see https://share.streamlit.io/streamlit/emoji-shortcodes.\n\n            * LaTeX expressions, by wrapping them in \"$\" or \"$$\" (the \"$$\"\n              must be on their own lines). Supported LaTeX functions are listed\n              at https://katex.org/docs/supported.html.\n\n            * Colored text and background colors for text, using the syntax\n              ``:color[text to be colored]`` and ``:color-background[text to be colored]``,\n              respectively. ``color`` must be replaced with any of the following\n              supported colors: blue, green, orange, red, violet, gray/grey, rainbow.\n              For example, you can use ``:orange[your text here]`` or\n              ``:blue-background[your text here]``.\n\n            Unsupported elements are unwrapped so only their children (text contents) render.\n            Display unsupported elements as literal characters by\n            backslash-escaping them. E.g. ``1\\. Not an ordered list``.\n\n        Returns\n        -------\n        list of containers\n            A list of container objects.\n\n        Examples\n        --------\n        You can use the ``with`` notation to insert any element into a tab:\n\n        >>> import streamlit as st\n        >>>\n        >>> tab1, tab2, tab3 = st.tabs([\"Cat\", \"Dog\", \"Owl\"])\n        >>>\n        >>> with tab1:\n        ...    st.header(\"A cat\")\n        ...    st.image(\"https://static.streamlit.io/examples/cat.jpg\", width=200)\n        ...\n        >>> with tab2:\n        ...    st.header(\"A dog\")\n        ...    st.image(\"https://static.streamlit.io/examples/dog.jpg\", width=200)\n        ...\n        >>> with tab3:\n        ...    st.header(\"An owl\")\n        ...    st.image(\"https://static.streamlit.io/examples/owl.jpg\", width=200)\n\n        .. output ::\n            https://doc-tabs1.streamlit.app/\n            height: 620px\n\n        Or you can just call methods directly on the returned objects:\n\n        >>> import streamlit as st\n        >>> import numpy as np\n        >>>\n        >>> tab1, tab2 = st.tabs([\"\ud83d\udcc8 Chart\", \"\ud83d\uddc3 Data\"])\n        >>> data = np.random.randn(10, 1)\n        >>>\n        >>> tab1.subheader(\"A tab with a chart\")\n        >>> tab1.line_chart(data)\n        >>>\n        >>> tab2.subheader(\"A tab with the data\")\n        >>> tab2.write(data)\n\n\n        .. output ::\n            https://doc-tabs2.streamlit.app/\n            height: 700px\n\n        \"\"\"\n        if not tabs:\n            raise StreamlitAPIException(\n                \"The input argument to st.tabs must contain at least one tab label.\"\n            )\n\n        if any(not isinstance(tab, str) for tab in tabs):\n            raise StreamlitAPIException(\n                \"The tabs input list to st.tabs is only allowed to contain strings.\"\n            )\n\n        def tab_proto(label: str) -> BlockProto:\n            tab_proto = BlockProto()\n            tab_proto.tab.label = label\n            tab_proto.allow_empty = True\n            return tab_proto\n\n        block_proto = BlockProto()\n        block_proto.tab_container.SetInParent()\n        tab_container = self.dg._block(block_proto)\n        return tuple(tab_container._block(tab_proto(tab_label)) for tab_label in tabs)\n\n    @gather_metrics(\"expander\")\n    def expander(\n        self,\n        label: str,\n        expanded: bool = False,\n        *,\n        icon: str | None = None,\n    ) -> DeltaGenerator:\n        r\"\"\"Insert a multi-element container that can be expanded/collapsed.\n\n        Inserts a container into your app that can be used to hold multiple elements\n        and can be expanded or collapsed by the user. When collapsed, all that is\n        visible is the provided label.\n\n        To add elements to the returned container, you can use the ``with`` notation\n        (preferred) or just call methods directly on the returned object. See\n        examples below.\n\n        .. warning::\n            Currently, you may not put expanders inside another expander.\n\n        Parameters\n        ----------\n        label : str\n            A string to use as the header for the expander. The label can optionally\n            contain Markdown and supports the following elements: Bold, Italics,\n            Strikethroughs, Inline Code, Emojis, and Links.\n\n            This also supports:\n\n            * Emoji shortcodes, such as ``:+1:``  and ``:sunglasses:``.\n              For a list of all supported codes,\n              see https://share.streamlit.io/streamlit/emoji-shortcodes.\n\n            * LaTeX expressions, by wrapping them in \"$\" or \"$$\" (the \"$$\"\n              must be on their own lines). Supported LaTeX functions are listed\n              at https://katex.org/docs/supported.html.\n\n            * Colored text and background colors for text, using the syntax\n              ``:color[text to be colored]`` and ``:color-background[text to be colored]``,\n              respectively. ``color`` must be replaced with any of the following\n              supported colors: blue, green, orange, red, violet, gray/grey, rainbow.\n              For example, you can use ``:orange[your text here]`` or\n              ``:blue-background[your text here]``.\n\n            Unsupported elements are unwrapped so only their children (text contents) render.\n            Display unsupported elements as literal characters by\n            backslash-escaping them. E.g. ``1\\. Not an ordered list``.\n\n        expanded : bool\n            If True, initializes the expander in \"expanded\" state. Defaults to\n            False (collapsed).\n\n        icon : str, None\n            An optional emoji or icon to display next to the expander label. If ``icon``\n            is ``None`` (default), no icon is displayed. If ``icon`` is a\n            string, the following options are valid:\n\n            * A single-character emoji. For example, you can set ``icon=\"\ud83d\udea8\"``\n              or ``icon=\"\ud83d\udd25\"``. Emoji short codes are not supported.\n\n            * An icon from the Material Symbols library (outlined style) in the\n              format ``\":material/icon_name:\"`` where \"icon_name\" is the name\n              of the icon in snake case.\n\n              For example, ``icon=\":material/thumb_up:\"`` will display the\n              Thumb Up icon. Find additional icons in the `Material Symbols \\\n              <https://fonts.google.com/icons?icon.set=Material+Symbols&icon.style=Outlined>`_\n              font library.\n\n        Examples\n        --------\n        You can use the ``with`` notation to insert any element into an expander\n\n        >>> import streamlit as st\n        >>>\n        >>> st.bar_chart({\"data\": [1, 5, 2, 6, 2, 1]})\n        >>>\n        >>> with st.expander(\"See explanation\"):\n        ...     st.write('''\n        ...         The chart above shows some numbers I picked for you.\n        ...         I rolled actual dice for these, so they're *guaranteed* to\n        ...         be random.\n        ...     ''')\n        ...     st.image(\"https://static.streamlit.io/examples/dice.jpg\")\n\n        .. output ::\n            https://doc-expander.streamlit.app/\n            height: 750px\n\n        Or you can just call methods directly on the returned objects:\n\n        >>> import streamlit as st\n        >>>\n        >>> st.bar_chart({\"data\": [1, 5, 2, 6, 2, 1]})\n        >>>\n        >>> expander = st.expander(\"See explanation\")\n        >>> expander.write('''\n        ...     The chart above shows some numbers I picked for you.\n        ...     I rolled actual dice for these, so they're *guaranteed* to\n        ...     be random.\n        ... ''')\n        >>> expander.image(\"https://static.streamlit.io/examples/dice.jpg\")\n\n        .. output ::\n            https://doc-expander.streamlit.app/\n            height: 750px\n\n        \"\"\"\n        if label is None:\n            raise StreamlitAPIException(\"A label is required for an expander\")\n\n        expandable_proto = BlockProto.Expandable()\n        expandable_proto.expanded = expanded\n        expandable_proto.label = label\n        if icon is not None:\n            expandable_proto.icon = validate_icon_or_emoji(icon)\n\n        block_proto = BlockProto()\n        block_proto.allow_empty = False\n        block_proto.expandable.CopyFrom(expandable_proto)\n\n        return self.dg._block(block_proto=block_proto)\n\n    @gather_metrics(\"popover\")\n    def popover(\n        self,\n        label: str,\n        *,\n        help: str | None = None,\n        disabled: bool = False,\n        use_container_width: bool = False,\n    ) -> DeltaGenerator:\n        r\"\"\"Insert a popover container.\n\n        Inserts a multi-element container as a popover. It consists of a button-like\n        element and a container that opens when the button is clicked.\n\n        Opening and closing the popover will not trigger a rerun. Interacting\n        with widgets inside of an open popover will rerun the app while keeping\n        the popover open. Clicking outside of the popover will close it.\n\n        To add elements to the returned container, you can use the \"with\"\n        notation (preferred) or just call methods directly on the returned object.\n        See examples below.\n\n        .. warning::\n            You may not put a popover inside another popover.\n\n        Parameters\n        ----------\n        label : str\n            The label of the button that opens the popover container.\n            The label can optionally contain Markdown and supports the\n            following elements: Bold, Italics, Strikethroughs, Inline Code,\n            Emojis, and Links.\n\n            This also supports:\n\n            * Emoji shortcodes, such as ``:+1:``  and ``:sunglasses:``.\n                For a list of all supported codes,\n                see https://share.streamlit.io/streamlit/emoji-shortcodes.\n\n            * LaTeX expressions, by wrapping them in \"$\" or \"$$\" (the \"$$\"\n                must be on their own lines). Supported LaTeX functions are listed\n                at https://katex.org/docs/supported.html.\n\n            * Colored text and background colors for text, using the syntax\n              ``:color[text to be colored]`` and ``:color-background[text to be colored]``,\n              respectively. ``color`` must be replaced with any of the following\n              supported colors: blue, green, orange, red, violet, gray/grey, rainbow.\n              For example, you can use ``:orange[your text here]`` or\n              ``:blue-background[your text here]``.\n\n            Unsupported elements are unwrapped so only their children (text contents) render.\n            Display unsupported elements as literal characters by\n            backslash-escaping them. E.g. ``1\\. Not an ordered list``.\n\n        help : str\n            An optional tooltip that gets displayed when the popover button is\n            hovered over.\n\n        disabled : bool\n            An optional boolean, which disables the popover button if set to\n            True. The default is False.\n\n        use_container_width : bool\n            Whether to expand the button's width to fill its parent container.\n            If ``use_container_width`` is ``False`` (default), Streamlit sizes\n            the button to fit its contents. If ``use_container_width`` is\n            ``True``, the width of the button matches its parent container.\n\n            In both cases, if the contents of the button are wider than the\n            parent container, the contents will line wrap.\n\n            The popover containter's minimimun width matches the width of its\n            button. The popover container may be wider than its button to fit\n            the container's contents.\n\n        Examples\n        --------\n        You can use the ``with`` notation to insert any element into a popover:\n\n        >>> import streamlit as st\n        >>>\n        >>> with st.popover(\"Open popover\"):\n        >>>     st.markdown(\"Hello World \ud83d\udc4b\")\n        >>>     name = st.text_input(\"What's your name?\")\n        >>>\n        >>> st.write(\"Your name:\", name)\n\n        .. output ::\n            https://doc-popover.streamlit.app/\n            height: 400px\n\n        Or you can just call methods directly on the returned objects:\n\n        >>> import streamlit as st\n        >>>\n        >>> popover = st.popover(\"Filter items\")\n        >>> red = popover.checkbox(\"Show red items.\", True)\n        >>> blue = popover.checkbox(\"Show blue items.\", True)\n        >>>\n        >>> if red:\n        ...     st.write(\":red[This is a red item.]\")\n        >>> if blue:\n        ...     st.write(\":blue[This is a blue item.]\")\n\n        .. output ::\n            https://doc-popover2.streamlit.app/\n            height: 400px\n        \"\"\"\n        if label is None:\n            raise StreamlitAPIException(\"A label is required for a popover\")\n\n        popover_proto = BlockProto.Popover()\n        popover_proto.label = label\n        popover_proto.use_container_width = use_container_width\n        popover_proto.disabled = disabled\n        if help:\n            popover_proto.help = str(help)\n\n        block_proto = BlockProto()\n        block_proto.allow_empty = True\n        block_proto.popover.CopyFrom(popover_proto)\n\n        return self.dg._block(block_proto=block_proto)\n\n    @gather_metrics(\"status\")\n    def status(\n        self,\n        label: str,\n        *,\n        expanded: bool = False,\n        state: Literal[\"running\", \"complete\", \"error\"] = \"running\",\n    ) -> StatusContainer:\n        r\"\"\"Insert a status container to display output from long-running tasks.\n\n        Inserts a container into your app that is typically used to show the status and\n        details of a process or task. The container can hold multiple elements and can\n        be expanded or collapsed by the user similar to ``st.expander``.\n        When collapsed, all that is visible is the status icon and label.\n\n        The label, state, and expanded state can all be updated by calling ``.update()``\n        on the returned object. To add elements to the returned container, you can\n        use ``with`` notation (preferred) or just call methods directly on the returned\n        object.\n\n        By default, ``st.status()`` initializes in the \"running\" state. When called using\n        ``with`` notation, it automatically updates to the \"complete\" state at the end\n        of the \"with\" block. See examples below for more details.\n\n        Parameters\n        ----------\n\n        label : str\n            The initial label of the status container. The label can optionally\n            contain Markdown and supports the following elements: Bold,\n            Italics, Strikethroughs, Inline Code, Emojis, and Links.\n\n            This also supports:\n\n            * Emoji shortcodes, such as ``:+1:``  and ``:sunglasses:``.\n              For a list of all supported codes,\n              see https://share.streamlit.io/streamlit/emoji-shortcodes.\n\n            * LaTeX expressions, by wrapping them in \"$\" or \"$$\" (the \"$$\"\n              must be on their own lines). Supported LaTeX functions are listed\n              at https://katex.org/docs/supported.html.\n\n            * Colored text and background colors for text, using the syntax\n              ``:color[text to be colored]`` and ``:color-background[text to be colored]``,\n              respectively. ``color`` must be replaced with any of the following\n              supported colors: blue, green, orange, red, violet, gray/grey, rainbow.\n              For example, you can use ``:orange[your text here]`` or\n              ``:blue-background[your text here]``.\n\n            Unsupported elements are unwrapped so only their children (text contents)\n            render. Display unsupported elements as literal characters by\n            backslash-escaping them. E.g. ``1\\. Not an ordered list``.\n\n        expanded : bool\n            If True, initializes the status container in \"expanded\" state. Defaults to\n            False (collapsed).\n\n        state : \"running\", \"complete\", or \"error\"\n            The initial state of the status container which determines which icon is\n            shown:\n\n            * ``running`` (default): A spinner icon is shown.\n\n            * ``complete``: A checkmark icon is shown.\n\n            * ``error``: An error icon is shown.\n\n        Returns\n        -------\n\n        StatusContainer\n            A mutable status container that can hold multiple elements. The label, state,\n            and expanded state can be updated after creation via ``.update()``.\n\n        Examples\n        --------\n\n        You can use the ``with`` notation to insert any element into an status container:\n\n        >>> import time\n        >>> import streamlit as st\n        >>>\n        >>> with st.status(\"Downloading data...\"):\n        ...     st.write(\"Searching for data...\")\n        ...     time.sleep(2)\n        ...     st.write(\"Found URL.\")\n        ...     time.sleep(1)\n        ...     st.write(\"Downloading data...\")\n        ...     time.sleep(1)\n        >>>\n        >>> st.button(\"Rerun\")\n\n        .. output ::\n            https://doc-status.streamlit.app/\n            height: 300px\n\n        You can also use ``.update()`` on the container to change the label, state,\n        or expanded state:\n\n        >>> import time\n        >>> import streamlit as st\n        >>>\n        >>> with st.status(\"Downloading data...\", expanded=True) as status:\n        ...     st.write(\"Searching for data...\")\n        ...     time.sleep(2)\n        ...     st.write(\"Found URL.\")\n        ...     time.sleep(1)\n        ...     st.write(\"Downloading data...\")\n        ...     time.sleep(1)\n        ...     status.update(label=\"Download complete!\", state=\"complete\", expanded=False)\n        >>>\n        >>> st.button(\"Rerun\")\n\n        .. output ::\n            https://doc-status-update.streamlit.app/\n            height: 300px\n\n        \"\"\"\n        # We need to import StatusContainer here to avoid a circular import\n        from streamlit.elements.lib.mutable_status_container import StatusContainer\n\n        return StatusContainer._create(\n            self.dg, label=label, expanded=expanded, state=state\n        )\n\n    def _dialog(\n        self,\n        title: str,\n        *,\n        dismissible: bool = True,\n        width: Literal[\"small\", \"large\"] = \"small\",\n    ) -> Dialog:\n        \"\"\"Inserts the dialog container.\n\n        Marked as internal because it is used by the dialog_decorator and is not supposed to be used directly.\n        The dialog_decorator also has a more descriptive docstring since it is user-facing.\n        \"\"\"\n\n        # We need to import Dialog here to avoid a circular import\n        from streamlit.elements.lib.dialog import Dialog\n\n        return Dialog._create(self.dg, title, dismissible=dismissible, width=width)\n\n    @property\n    def dg(self) -> DeltaGenerator:\n        \"\"\"Get our DeltaGenerator.\"\"\"\n        return cast(\"DeltaGenerator\", self)\n", "lib/streamlit/elements/code.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom typing import TYPE_CHECKING, cast\n\nfrom streamlit.proto.Code_pb2 import Code as CodeProto\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.string_util import clean_text\n\nif TYPE_CHECKING:\n    from streamlit.delta_generator import DeltaGenerator\n    from streamlit.type_util import SupportsStr\n\n\nclass CodeMixin:\n    @gather_metrics(\"code\")\n    def code(\n        self,\n        body: SupportsStr,\n        language: str | None = \"python\",\n        line_numbers: bool = False,\n    ) -> DeltaGenerator:\n        \"\"\"Display a code block with optional syntax highlighting.\n\n        Parameters\n        ----------\n        body : str\n            The string to display as code.\n\n        language : str or None\n            The language that the code is written in, for syntax highlighting.\n            If ``None``, the code will be unstyled. Defaults to ``\"python\"``.\n\n            For a list of available ``language`` values, see:\n\n            https://github.com/react-syntax-highlighter/react-syntax-highlighter/blob/master/AVAILABLE_LANGUAGES_PRISM.MD\n\n        line_numbers : bool\n            An optional boolean indicating whether to show line numbers to the\n            left of the code block. Defaults to ``False``.\n\n        Example\n        -------\n        >>> import streamlit as st\n        >>>\n        >>> code = '''def hello():\n        ...     print(\"Hello, Streamlit!\")'''\n        >>> st.code(code, language='python')\n\n        \"\"\"\n        code_proto = CodeProto()\n        code_proto.code_text = clean_text(body)\n        code_proto.language = language or \"plaintext\"\n        code_proto.show_line_numbers = line_numbers\n        return self.dg._enqueue(\"code\", code_proto)\n\n    @property\n    def dg(self) -> DeltaGenerator:\n        \"\"\"Get our DeltaGenerator.\"\"\"\n        return cast(\"DeltaGenerator\", self)\n", "lib/streamlit/elements/lib/dialog.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport time\nfrom typing import TYPE_CHECKING, Literal, cast\n\nfrom typing_extensions import Self, TypeAlias\n\nfrom streamlit.delta_generator import DeltaGenerator, _enqueue_message\nfrom streamlit.errors import StreamlitAPIException\nfrom streamlit.proto.Block_pb2 import Block as BlockProto\nfrom streamlit.proto.ForwardMsg_pb2 import ForwardMsg\nfrom streamlit.runtime.scriptrunner import get_script_run_ctx\n\nif TYPE_CHECKING:\n    from types import TracebackType\n\n    from streamlit.cursor import Cursor\n\nDialogWidth: TypeAlias = Literal[\"small\", \"large\"]\n\n\ndef _process_dialog_width_input(\n    width: DialogWidth,\n) -> BlockProto.Dialog.DialogWidth.ValueType:\n    \"\"\"Maps the user-provided literal to a value of the DialogWidth proto enum.\n\n    Returns the mapped enum field for \"small\" by default and otherwise the mapped type.\n    \"\"\"\n    if width == \"large\":\n        return BlockProto.Dialog.DialogWidth.LARGE\n\n    return BlockProto.Dialog.DialogWidth.SMALL\n\n\ndef _assert_first_dialog_to_be_opened(should_open: bool) -> None:\n    \"\"\"Check whether a dialog has already been opened in the same script run.\n\n    Only one dialog is supposed to be opened. The check is implemented in a way\n    that for a script run, the open function can only be called once.\n    One dialog at a time is a product decision and not a technical one.\n\n    Raises\n    ------\n    StreamlitAPIException\n        Raised when a dialog has already been opened in the current script run.\n    \"\"\"\n    script_run_ctx = get_script_run_ctx()\n    # We don't reset the ctx.has_dialog_opened when the flag is False because\n    # it is reset in a new scriptrun anyways. If the execution model ever changes,\n    # this might need to change.\n    if should_open and script_run_ctx:\n        if script_run_ctx.has_dialog_opened:\n            raise StreamlitAPIException(\n                \"Only one dialog is allowed to be opened at the same time. Please make sure to not call a dialog-decorated function more than once in a script run.\"\n            )\n        script_run_ctx.has_dialog_opened = True\n\n\nclass Dialog(DeltaGenerator):\n    @staticmethod\n    def _create(\n        parent: DeltaGenerator,\n        title: str,\n        *,\n        dismissible: bool = True,\n        width: DialogWidth = \"small\",\n    ) -> Dialog:\n        block_proto = BlockProto()\n        block_proto.dialog.title = title\n        block_proto.dialog.dismissible = dismissible\n        block_proto.dialog.width = _process_dialog_width_input(width)\n\n        # We store the delta path here, because in _update we enqueue a new proto message to update the\n        # open status. Without this, the dialog content is gone when the _update message is sent\n        delta_path: list[int] = (\n            parent._active_dg._cursor.delta_path if parent._active_dg._cursor else []\n        )\n        dialog = cast(Dialog, parent._block(block_proto=block_proto, dg_type=Dialog))\n\n        dialog._delta_path = delta_path\n        dialog._current_proto = block_proto\n        # We add a sleep here to give the web app time to react to the update. Otherwise,\n        #  we might run into issues where the dialog cannot be opened again after closing\n        time.sleep(0.05)\n        return dialog\n\n    def __init__(\n        self,\n        root_container: int | None,\n        cursor: Cursor | None,\n        parent: DeltaGenerator | None,\n        block_type: str | None,\n    ):\n        super().__init__(root_container, cursor, parent, block_type)\n\n        # Initialized in `_create()`:\n        self._current_proto: BlockProto | None = None\n        self._delta_path: list[int] | None = None\n\n    def _update(self, should_open: bool):\n        \"\"\"Send an updated proto message to indicate the open-status for the dialog.\"\"\"\n\n        assert self._current_proto is not None, \"Dialog not correctly initialized!\"\n        assert self._delta_path is not None, \"Dialog not correctly initialized!\"\n        _assert_first_dialog_to_be_opened(should_open)\n        msg = ForwardMsg()\n        msg.metadata.delta_path[:] = self._delta_path\n        msg.delta.add_block.CopyFrom(self._current_proto)\n        msg.delta.add_block.dialog.is_open = should_open\n\n        self._current_proto = msg.delta.add_block\n\n        # We add a sleep here to give the web app time to react to the update. Otherwise,\n        #  we might run into issues where the dialog cannot be opened again after closing\n        time.sleep(0.05)\n        _enqueue_message(msg)\n\n    def open(self) -> None:\n        self._update(True)\n\n    def close(self) -> None:\n        self._update(False)\n\n    def __enter__(self) -> Self:  # type: ignore[override]\n        # This is a little dubious: we're returning a different type than\n        # our superclass' `__enter__` function. Maybe DeltaGenerator.__enter__\n        # should always return `self`?\n        super().__enter__()\n        return self\n\n    def __exit__(\n        self,\n        exc_type: type[BaseException] | None,\n        exc_val: BaseException | None,\n        exc_tb: TracebackType | None,\n    ) -> Literal[False]:\n        return super().__exit__(exc_type, exc_val, exc_tb)\n", "lib/streamlit/elements/lib/streamlit_plotly_theme.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport contextlib\n\n\ndef configure_streamlit_plotly_theme() -> None:\n    \"\"\"Configure the Streamlit chart theme for Plotly.\n\n    The theme is only configured if Plotly is installed.\n    \"\"\"\n    # We do nothing if Plotly is not installed. This is expected since Plotly is an optional dependency.\n    with contextlib.suppress(ImportError):\n        import plotly.graph_objects as go\n        import plotly.io as pio\n\n        # This is the streamlit theme for plotly where we pass in a template.data\n        # and a template.layout.\n        # Template.data is for changing specific graph properties in a general aspect\n        # such as Contour plots or Waterfall plots.\n        # Template.layout is for changing things such as the x axis and fonts and other\n        # general layout properties for general graphs.\n        # We pass in temporary colors to the frontend and the frontend will replace\n        # those colors because we want to change colors based on the background color.\n        # Start at #0000001 because developers may be likely to use #000000\n        CATEGORY_0 = \"#000001\"\n        CATEGORY_1 = \"#000002\"\n        CATEGORY_2 = \"#000003\"\n        CATEGORY_3 = \"#000004\"\n        CATEGORY_4 = \"#000005\"\n        CATEGORY_5 = \"#000006\"\n        CATEGORY_6 = \"#000007\"\n        CATEGORY_7 = \"#000008\"\n        CATEGORY_8 = \"#000009\"\n        CATEGORY_9 = \"#000010\"\n\n        SEQUENTIAL_0 = \"#000011\"\n        SEQUENTIAL_1 = \"#000012\"\n        SEQUENTIAL_2 = \"#000013\"\n        SEQUENTIAL_3 = \"#000014\"\n        SEQUENTIAL_4 = \"#000015\"\n        SEQUENTIAL_5 = \"#000016\"\n        SEQUENTIAL_6 = \"#000017\"\n        SEQUENTIAL_7 = \"#000018\"\n        SEQUENTIAL_8 = \"#000019\"\n        SEQUENTIAL_9 = \"#000020\"\n\n        DIVERGING_0 = \"#000021\"\n        DIVERGING_1 = \"#000022\"\n        DIVERGING_2 = \"#000023\"\n        DIVERGING_3 = \"#000024\"\n        DIVERGING_4 = \"#000025\"\n        DIVERGING_5 = \"#000026\"\n        DIVERGING_6 = \"#000027\"\n        DIVERGING_7 = \"#000028\"\n        DIVERGING_8 = \"#000029\"\n        DIVERGING_9 = \"#000030\"\n        DIVERGING_10 = \"#000031\"\n\n        INCREASING = \"#000032\"\n        DECREASING = \"#000033\"\n        TOTAL = \"#000034\"\n\n        GRAY_70 = \"#000036\"\n        GRAY_90 = \"#000037\"\n        BG_COLOR = \"#000038\"\n        FADED_TEXT_05 = \"#000039\"\n        BG_MIX = \"#000040\"\n\n        # Plotly represents continuous colorscale through an array of pairs.\n        # The pair's first index is the starting point and the next pair's first index is the end point.\n        # The pair's second index is the starting color and the next pair's second index is the end color.\n        # For more information, please refer to https://plotly.com/python/colorscales/\n\n        streamlit_colorscale = [\n            [0.0, SEQUENTIAL_0],\n            [0.1111111111111111, SEQUENTIAL_1],\n            [0.2222222222222222, SEQUENTIAL_2],\n            [0.3333333333333333, SEQUENTIAL_3],\n            [0.4444444444444444, SEQUENTIAL_4],\n            [0.5555555555555556, SEQUENTIAL_5],\n            [0.6666666666666666, SEQUENTIAL_6],\n            [0.7777777777777778, SEQUENTIAL_7],\n            [0.8888888888888888, SEQUENTIAL_8],\n            [1.0, SEQUENTIAL_9],\n        ]\n\n        pio.templates[\"streamlit\"] = go.layout.Template(\n            data=go.layout.template.Data(\n                candlestick=[\n                    go.layout.template.data.Candlestick(\n                        decreasing=go.candlestick.Decreasing(\n                            line=go.candlestick.decreasing.Line(color=DECREASING)\n                        ),\n                        increasing=go.candlestick.Increasing(\n                            line=go.candlestick.increasing.Line(color=INCREASING)\n                        ),\n                    )\n                ],\n                contour=[\n                    go.layout.template.data.Contour(colorscale=streamlit_colorscale)\n                ],\n                contourcarpet=[\n                    go.layout.template.data.Contourcarpet(\n                        colorscale=streamlit_colorscale\n                    )\n                ],\n                heatmap=[\n                    go.layout.template.data.Heatmap(colorscale=streamlit_colorscale)\n                ],\n                histogram2d=[\n                    go.layout.template.data.Histogram2d(colorscale=streamlit_colorscale)\n                ],\n                icicle=[\n                    go.layout.template.data.Icicle(\n                        textfont=go.icicle.Textfont(color=\"white\")\n                    )\n                ],\n                sankey=[\n                    go.layout.template.data.Sankey(\n                        textfont=go.sankey.Textfont(color=GRAY_70)\n                    )\n                ],\n                scatter=[\n                    go.layout.template.data.Scatter(\n                        marker=go.scatter.Marker(line=go.scatter.marker.Line(width=0))\n                    )\n                ],\n                table=[\n                    go.layout.template.data.Table(\n                        cells=go.table.Cells(\n                            fill=go.table.cells.Fill(color=BG_COLOR),\n                            font=go.table.cells.Font(color=GRAY_90),\n                            line=go.table.cells.Line(color=FADED_TEXT_05),\n                        ),\n                        header=go.table.Header(\n                            font=go.table.header.Font(color=GRAY_70),\n                            line=go.table.header.Line(color=FADED_TEXT_05),\n                            fill=go.table.header.Fill(color=BG_MIX),\n                        ),\n                    )\n                ],\n                waterfall=[\n                    go.layout.template.data.Waterfall(\n                        increasing=go.waterfall.Increasing(\n                            marker=go.waterfall.increasing.Marker(color=INCREASING)\n                        ),\n                        decreasing=go.waterfall.Decreasing(\n                            marker=go.waterfall.decreasing.Marker(color=DECREASING)\n                        ),\n                        totals=go.waterfall.Totals(\n                            marker=go.waterfall.totals.Marker(color=TOTAL)\n                        ),\n                        connector=go.waterfall.Connector(\n                            line=go.waterfall.connector.Line(color=GRAY_70, width=2)\n                        ),\n                    )\n                ],\n            ),\n            layout=go.Layout(\n                colorway=[\n                    CATEGORY_0,\n                    CATEGORY_1,\n                    CATEGORY_2,\n                    CATEGORY_3,\n                    CATEGORY_4,\n                    CATEGORY_5,\n                    CATEGORY_6,\n                    CATEGORY_7,\n                    CATEGORY_8,\n                    CATEGORY_9,\n                ],\n                colorscale=go.layout.Colorscale(\n                    sequential=streamlit_colorscale,\n                    sequentialminus=streamlit_colorscale,\n                    diverging=[\n                        [0.0, DIVERGING_0],\n                        [0.1, DIVERGING_1],\n                        [0.2, DIVERGING_2],\n                        [0.3, DIVERGING_3],\n                        [0.4, DIVERGING_4],\n                        [0.5, DIVERGING_5],\n                        [0.6, DIVERGING_6],\n                        [0.7, DIVERGING_7],\n                        [0.8, DIVERGING_8],\n                        [0.9, DIVERGING_9],\n                        [1.0, DIVERGING_10],\n                    ],\n                ),\n                coloraxis=go.layout.Coloraxis(colorscale=streamlit_colorscale),\n            ),\n        )\n\n        pio.templates.default = \"streamlit\"\n", "lib/streamlit/elements/lib/dicttools.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Tools for working with dicts.\"\"\"\n\nfrom __future__ import annotations\n\nfrom typing import Any, Mapping\n\n\ndef _unflatten_single_dict(flat_dict: dict[Any, Any]) -> dict[Any, Any]:\n    \"\"\"Convert a flat dict of key-value pairs to dict tree.\n\n    Example\n    -------\n\n        _unflatten_single_dict({\n          foo_bar_baz: 123,\n          foo_bar_biz: 456,\n          x_bonks: 'hi',\n        })\n\n        # Returns:\n        # {\n        #   foo: {\n        #     bar: {\n        #       baz: 123,\n        #       biz: 456,\n        #     },\n        #   },\n        #   x: {\n        #     bonks: 'hi'\n        #   }\n        # }\n\n    Parameters\n    ----------\n    flat_dict : dict\n        A one-level dict where keys are fully-qualified paths separated by\n        underscores.\n\n    Returns\n    -------\n    dict\n        A tree made of dicts inside of dicts.\n\n    \"\"\"\n    out: dict[str, Any] = {}\n    for pathstr, v in flat_dict.items():\n        path = pathstr.split(\"_\")\n\n        prev_dict: dict[str, Any] | None = None\n        curr_dict = out\n\n        for k in path:\n            if k not in curr_dict:\n                curr_dict[k] = {}\n            prev_dict = curr_dict\n            curr_dict = curr_dict[k]\n\n        if prev_dict is not None:\n            prev_dict[k] = v\n\n    return out\n\n\ndef unflatten(\n    flat_dict: dict[Any, Any], encodings: set[str] | None = None\n) -> dict[Any, Any]:\n    \"\"\"Converts a flat dict of key-value pairs to a spec tree.\n\n    Example\n    -------\n        unflatten({\n          foo_bar_baz: 123,\n          foo_bar_biz: 456,\n          x_bonks: 'hi',\n        }, ['x'])\n\n        # Returns:\n        # {\n        #   foo: {\n        #     bar: {\n        #       baz: 123,\n        #       biz: 456,\n        #     },\n        #   },\n        #   encoding: {  # This gets added automatically\n        #     x: {\n        #       bonks: 'hi'\n        #     }\n        #   }\n        # }\n\n    Args\n    ----\n    flat_dict: dict\n        A flat dict where keys are fully-qualified paths separated by\n        underscores.\n\n    encodings: set\n        Key names that should be automatically moved into the 'encoding' key.\n\n    Returns\n    -------\n    A tree made of dicts inside of dicts.\n    \"\"\"\n    if encodings is None:\n        encodings = set()\n\n    out_dict = _unflatten_single_dict(flat_dict)\n\n    for k, v in list(out_dict.items()):\n        # Unflatten child dicts:\n        if isinstance(v, dict):\n            v = unflatten(v, encodings)\n        elif hasattr(v, \"__iter__\"):\n            for i, child in enumerate(v):\n                if isinstance(child, dict):\n                    v[i] = unflatten(child, encodings)\n\n        # Move items into 'encoding' if needed:\n        if k in encodings:\n            if \"encoding\" not in out_dict:\n                out_dict[\"encoding\"] = {}\n            out_dict[\"encoding\"][k] = v\n            out_dict.pop(k)\n\n    return out_dict\n\n\ndef remove_none_values(input_dict: Mapping[Any, Any]) -> dict[Any, Any]:\n    \"\"\"Remove all keys with None values from a dict.\"\"\"\n    new_dict = {}\n    for key, val in input_dict.items():\n        if isinstance(val, dict):\n            val = remove_none_values(val)\n        if val is not None:\n            new_dict[key] = val\n    return new_dict\n", "lib/streamlit/elements/lib/mutable_status_container.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport time\nfrom typing import TYPE_CHECKING, Literal, cast\n\nfrom typing_extensions import Self, TypeAlias\n\nfrom streamlit.delta_generator import DeltaGenerator, _enqueue_message\nfrom streamlit.errors import StreamlitAPIException\nfrom streamlit.proto.Block_pb2 import Block as BlockProto\nfrom streamlit.proto.ForwardMsg_pb2 import ForwardMsg\n\nif TYPE_CHECKING:\n    from types import TracebackType\n\n    from streamlit.cursor import Cursor\n\nStates: TypeAlias = Literal[\"running\", \"complete\", \"error\"]\n\n\nclass StatusContainer(DeltaGenerator):\n    @staticmethod\n    def _create(\n        parent: DeltaGenerator,\n        label: str,\n        expanded: bool = False,\n        state: States = \"running\",\n    ) -> StatusContainer:\n        expandable_proto = BlockProto.Expandable()\n        expandable_proto.expanded = expanded\n        expandable_proto.label = label or \"\"\n\n        if state == \"running\":\n            expandable_proto.icon = \"spinner\"\n        elif state == \"complete\":\n            expandable_proto.icon = \":material/check:\"\n        elif state == \"error\":\n            expandable_proto.icon = \":material/error:\"\n        else:\n            raise StreamlitAPIException(\n                f\"Unknown state ({state}). Must be one of 'running', 'complete', or 'error'.\"\n            )\n\n        block_proto = BlockProto()\n        block_proto.allow_empty = True\n        block_proto.expandable.CopyFrom(expandable_proto)\n\n        delta_path: list[int] = (\n            parent._active_dg._cursor.delta_path if parent._active_dg._cursor else []\n        )\n\n        status_container = cast(\n            StatusContainer,\n            parent._block(block_proto=block_proto, dg_type=StatusContainer),\n        )\n\n        # Apply initial configuration\n        status_container._delta_path = delta_path\n        status_container._current_proto = block_proto\n        status_container._current_state = state\n\n        # We need to sleep here for a very short time to prevent issues when\n        # the status is updated too quickly. If an .update() directly follows the\n        # the initialization, sometimes only the latest update is applied.\n        # Adding a short timeout here allows the frontend to render the update before.\n        time.sleep(0.05)\n\n        return status_container\n\n    def __init__(\n        self,\n        root_container: int | None,\n        cursor: Cursor | None,\n        parent: DeltaGenerator | None,\n        block_type: str | None,\n    ):\n        super().__init__(root_container, cursor, parent, block_type)\n\n        # Initialized in `_create()`:\n        self._current_proto: BlockProto | None = None\n        self._current_state: States | None = None\n        self._delta_path: list[int] | None = None\n\n    def update(\n        self,\n        *,\n        label: str | None = None,\n        expanded: bool | None = None,\n        state: States | None = None,\n    ) -> None:\n        \"\"\"Update the status container.\n\n        Only specified arguments are updated. Container contents and unspecified\n        arguments remain unchanged.\n\n        Parameters\n        ----------\n        label : str or None\n            A new label of the status container. If None, the label is not\n            changed.\n\n        expanded : bool or None\n            The new expanded state of the status container. If None,\n            the expanded state is not changed.\n\n        state : \"running\", \"complete\", \"error\", or None\n            The new state of the status container. This mainly changes the\n            icon. If None, the state is not changed.\n        \"\"\"\n        assert self._current_proto is not None, \"Status not correctly initialized!\"\n        assert self._delta_path is not None, \"Status not correctly initialized!\"\n\n        msg = ForwardMsg()\n        msg.metadata.delta_path[:] = self._delta_path\n        msg.delta.add_block.CopyFrom(self._current_proto)\n\n        if expanded is not None:\n            msg.delta.add_block.expandable.expanded = expanded\n        else:\n            msg.delta.add_block.expandable.ClearField(\"expanded\")\n\n        if label is not None:\n            msg.delta.add_block.expandable.label = label\n\n        if state is not None:\n            if state == \"running\":\n                msg.delta.add_block.expandable.icon = \"spinner\"\n            elif state == \"complete\":\n                msg.delta.add_block.expandable.icon = \":material/check:\"\n            elif state == \"error\":\n                msg.delta.add_block.expandable.icon = \":material/error:\"\n            else:\n                raise StreamlitAPIException(\n                    f\"Unknown state ({state}). Must be one of 'running', 'complete', or 'error'.\"\n                )\n            self._current_state = state\n\n        self._current_proto = msg.delta.add_block\n        _enqueue_message(msg)\n\n    def __enter__(self) -> Self:  # type: ignore[override]\n        # This is a little dubious: we're returning a different type than\n        # our superclass' `__enter__` function. Maybe DeltaGenerator.__enter__\n        # should always return `self`?\n        super().__enter__()\n        return self\n\n    def __exit__(\n        self,\n        exc_type: type[BaseException] | None,\n        exc_val: BaseException | None,\n        exc_tb: TracebackType | None,\n    ) -> Literal[False]:\n        # Only update if the current state is running\n        if self._current_state == \"running\":\n            # We need to sleep here for a very short time to prevent issues when\n            # the status is updated too quickly. If an .update() is directly followed\n            # by the exit of the context manager, sometimes only the last update\n            # (to complete) is applied. Adding a short timeout here allows the frontend\n            # to render the update before.\n            time.sleep(0.05)\n            if exc_type is not None:\n                # If an exception was raised in the context,\n                # we want to update the status to error.\n                self.update(state=\"error\")\n            else:\n                self.update(state=\"complete\")\n        return super().__exit__(exc_type, exc_val, exc_tb)\n", "lib/streamlit/elements/lib/utils.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom enum import Enum, EnumMeta\nfrom typing import TYPE_CHECKING, Any, Iterable, Sequence, overload\n\nfrom streamlit import type_util\nfrom streamlit.proto.LabelVisibilityMessage_pb2 import LabelVisibilityMessage\nfrom streamlit.runtime.state.common import RegisterWidgetResult\n\nif TYPE_CHECKING:\n    from streamlit.type_util import T\n\n\ndef get_label_visibility_proto_value(\n    label_visibility_string: type_util.LabelVisibility,\n) -> LabelVisibilityMessage.LabelVisibilityOptions.ValueType:\n    \"\"\"Returns one of LabelVisibilityMessage enum constants.py based on string value.\"\"\"\n\n    if label_visibility_string == \"visible\":\n        return LabelVisibilityMessage.LabelVisibilityOptions.VISIBLE\n    elif label_visibility_string == \"hidden\":\n        return LabelVisibilityMessage.LabelVisibilityOptions.HIDDEN\n    elif label_visibility_string == \"collapsed\":\n        return LabelVisibilityMessage.LabelVisibilityOptions.COLLAPSED\n\n    raise ValueError(f\"Unknown label visibility value: {label_visibility_string}\")\n\n\n@overload\ndef maybe_coerce_enum(\n    register_widget_result: RegisterWidgetResult[Enum],\n    options: type[Enum],\n    opt_sequence: Sequence[Any],\n) -> RegisterWidgetResult[Enum]: ...\n\n\n@overload\ndef maybe_coerce_enum(\n    register_widget_result: RegisterWidgetResult[T],\n    options: type_util.OptionSequence[T],\n    opt_sequence: Sequence[T],\n) -> RegisterWidgetResult[T]: ...\n\n\ndef maybe_coerce_enum(register_widget_result, options, opt_sequence):\n    \"\"\"Maybe Coerce a RegisterWidgetResult with an Enum member value to\n    RegisterWidgetResult[option] if option is an EnumType, otherwise just return\n    the original RegisterWidgetResult.\"\"\"\n\n    # If the value is not a Enum, return early\n    if not isinstance(register_widget_result.value, Enum):\n        return register_widget_result\n\n    coerce_class: EnumMeta | None\n    if isinstance(options, EnumMeta):\n        coerce_class = options\n    else:\n        coerce_class = _extract_common_class_from_iter(opt_sequence)\n        if coerce_class is None:\n            return register_widget_result\n\n    return RegisterWidgetResult(\n        type_util.coerce_enum(register_widget_result.value, coerce_class),\n        register_widget_result.value_changed,\n    )\n\n\n# slightly ugly typing because TypeVars with Generic Bounds are not supported\n# (https://github.com/python/typing/issues/548)\n@overload\ndef maybe_coerce_enum_sequence(\n    register_widget_result: RegisterWidgetResult[list[T]],\n    options: type_util.OptionSequence[T],\n    opt_sequence: Sequence[T],\n) -> RegisterWidgetResult[list[T]]: ...\n\n\n@overload\ndef maybe_coerce_enum_sequence(\n    register_widget_result: RegisterWidgetResult[tuple[T, T]],\n    options: type_util.OptionSequence[T],\n    opt_sequence: Sequence[T],\n) -> RegisterWidgetResult[tuple[T, T]]: ...\n\n\ndef maybe_coerce_enum_sequence(register_widget_result, options, opt_sequence):\n    \"\"\"Maybe Coerce a RegisterWidgetResult with a sequence of Enum members as value\n    to RegisterWidgetResult[Sequence[option]] if option is an EnumType, otherwise just return\n    the original RegisterWidgetResult.\"\"\"\n\n    # If not all widget values are Enums, return early\n    if not all(isinstance(val, Enum) for val in register_widget_result.value):\n        return register_widget_result\n\n    # Extract the class to coerce\n    coerce_class: EnumMeta | None\n    if isinstance(options, EnumMeta):\n        coerce_class = options\n    else:\n        coerce_class = _extract_common_class_from_iter(opt_sequence)\n        if coerce_class is None:\n            return register_widget_result\n\n    # Return a new RegisterWidgetResult with the coerced enum values sequence\n    return RegisterWidgetResult(\n        type(register_widget_result.value)(\n            type_util.coerce_enum(val, coerce_class)\n            for val in register_widget_result.value\n        ),\n        register_widget_result.value_changed,\n    )\n\n\ndef _extract_common_class_from_iter(iterable: Iterable[Any]) -> Any:\n    \"\"\"Return the common class of all elements in a iterable if they share one.\n    Otherwise, return None.\"\"\"\n    try:\n        inner_iter = iter(iterable)\n        first_class = type(next(inner_iter))\n    except StopIteration:\n        return None\n    if all(type(item) is first_class for item in inner_iter):\n        return first_class\n    return None\n", "lib/streamlit/elements/lib/subtitle_utils.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport hashlib\nimport io\nimport os\nimport re\nfrom pathlib import Path\n\nfrom streamlit import runtime\nfrom streamlit.runtime import caching\n\n# Regular expression to match the SRT timestamp format\n# It matches the\n# \"hours:minutes:seconds,milliseconds --> hours:minutes:seconds,milliseconds\" format\nSRT_VALIDATION_REGEX = r\"\\d{2}:\\d{2}:\\d{2},\\d{3} --> \\d{2}:\\d{2}:\\d{2},\\d{3}\"\n\nSRT_CONVERSION_REGEX = r\"(\\d{2}:\\d{2}:\\d{2}),(\\d{3})\"\n\nSUBTITLE_ALLOWED_FORMATS = (\".srt\", \".vtt\")\n\n\ndef _is_srt(stream: str | io.BytesIO | bytes) -> bool:\n    # Handle raw bytes\n    if isinstance(stream, bytes):\n        stream = io.BytesIO(stream)\n\n    # Convert str to io.BytesIO if 'stream' is a string\n    if isinstance(stream, str):\n        stream = io.BytesIO(stream.encode(\"utf-8\"))\n\n    # Set the stream position to the beginning in case it's been moved\n    stream.seek(0)\n\n    # Read enough bytes to reliably check for SRT patterns\n    # This might be adjusted, but 33 bytes should be enough to read the first numeric\n    # line, the full timestamp line, and a bit of the next line\n    header = stream.read(33)\n\n    try:\n        header_str = header.decode(\"utf-8\").strip()  # Decode and strip whitespace\n    except UnicodeDecodeError:\n        # If it's not valid utf-8, it's probably not a valid SRT file\n        return False\n\n    # Split the header into lines and process them\n    lines = header_str.split(\"\\n\")\n\n    # Check for the pattern of an SRT file: digit(s), newline, timestamp\n    if len(lines) >= 2 and lines[0].isdigit():\n        match = re.search(SRT_VALIDATION_REGEX, lines[1])\n        if match:\n            return True\n\n    return False\n\n\ndef _srt_to_vtt(srt_data: str | bytes) -> bytes:\n    \"\"\"\n    Convert subtitles from SubRip (.srt) format to WebVTT (.vtt) format.\n    This function accepts the content of the .srt file either as a string\n    or as a BytesIO stream.\n    Parameters\n    ----------\n    srt_data : str or bytes\n        The content of the .srt file as a string or a bytes stream.\n    Returns\n    -------\n    bytes\n        The content converted into .vtt format.\n    \"\"\"\n\n    # If the input is a bytes stream, convert it to a string\n    if isinstance(srt_data, bytes):\n        # Decode the bytes to a UTF-8 string\n        try:\n            srt_data = srt_data.decode(\"utf-8\")\n        except UnicodeDecodeError as e:\n            raise ValueError(\"Could not decode the input stream as UTF-8.\") from e\n    if not isinstance(srt_data, str):\n        # If it's not a string by this point, something is wrong.\n        raise TypeError(\n            f\"Input must be a string or a bytes stream, not {type(srt_data)}.\"\n        )\n\n    # Replace SubRip timing with WebVTT timing\n    vtt_data = re.sub(SRT_CONVERSION_REGEX, r\"\\1.\\2\", srt_data)\n\n    # Add WebVTT file header\n    vtt_content = \"WEBVTT\\n\\n\" + vtt_data\n    # Convert the vtt content to bytes\n    vtt_content = vtt_content.strip().encode(\"utf-8\")\n\n    return vtt_content\n\n\ndef _handle_string_or_path_data(data_or_path: str | Path) -> bytes:\n    \"\"\"Handles string data, either as a file path or raw content.\"\"\"\n    if os.path.isfile(data_or_path):\n        path = Path(data_or_path)\n        file_extension = path.suffix.lower()\n\n        if file_extension not in SUBTITLE_ALLOWED_FORMATS:\n            raise ValueError(\n                f\"Incorrect subtitle format {file_extension}. Subtitles must be in \"\n                f\"one of the following formats: {', '.join(SUBTITLE_ALLOWED_FORMATS)}\"\n            )\n        with open(data_or_path, \"rb\") as file:\n            content = file.read()\n        return _srt_to_vtt(content) if file_extension == \".srt\" else content\n    elif isinstance(data_or_path, Path):\n        raise ValueError(f\"File {data_or_path} does not exist.\")\n\n    content_string = data_or_path.strip()\n\n    if content_string.startswith(\"WEBVTT\") or content_string == \"\":\n        return content_string.encode(\"utf-8\")\n    elif _is_srt(content_string):\n        return _srt_to_vtt(content_string)\n    raise ValueError(\"The provided string neither matches valid VTT nor SRT format.\")\n\n\ndef _handle_stream_data(stream: io.BytesIO) -> bytes:\n    \"\"\"Handles io.BytesIO data, converting SRT to VTT content if needed.\"\"\"\n    stream.seek(0)\n    stream_data = stream.getvalue()\n    return _srt_to_vtt(stream_data) if _is_srt(stream) else stream_data\n\n\ndef _handle_bytes_data(data: bytes) -> bytes:\n    \"\"\"Handles io.BytesIO data, converting SRT to VTT content if needed.\"\"\"\n    return _srt_to_vtt(data) if _is_srt(data) else data\n\n\ndef process_subtitle_data(\n    coordinates: str,\n    data: str | bytes | Path | io.BytesIO,\n    label: str,\n) -> str:\n    # Determine the type of data and process accordingly\n    if isinstance(data, (str, Path)):\n        subtitle_data = _handle_string_or_path_data(data)\n    elif isinstance(data, io.BytesIO):\n        subtitle_data = _handle_stream_data(data)\n    elif isinstance(data, bytes):\n        subtitle_data = _handle_bytes_data(data)\n    else:\n        raise TypeError(f\"Invalid binary data format for subtitle: {type(data)}.\")\n\n    if runtime.exists():\n        filename = hashlib.md5(label.encode()).hexdigest()\n        # Save the processed data and return the file URL\n        file_url = runtime.get_instance().media_file_mgr.add(\n            path_or_data=subtitle_data,\n            mimetype=\"text/vtt\",\n            coordinates=coordinates,\n            file_name=f\"{filename}.vtt\",\n        )\n        caching.save_media_data(subtitle_data, \"text/vtt\", coordinates)\n        return file_url\n    else:\n        # When running in \"raw mode\", we can't access the MediaFileManager.\n        return \"\"\n", "lib/streamlit/elements/lib/column_config_utils.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport copy\nimport json\nfrom enum import Enum\nfrom typing import TYPE_CHECKING, Dict, Final, Literal, Mapping, Union\n\nfrom typing_extensions import TypeAlias\n\nfrom streamlit.elements.lib.column_types import ColumnConfig, ColumnType\nfrom streamlit.elements.lib.dicttools import remove_none_values\nfrom streamlit.errors import StreamlitAPIException\nfrom streamlit.type_util import DataFormat, is_colum_type_arrow_incompatible\n\nif TYPE_CHECKING:\n    import pyarrow as pa\n    from pandas import DataFrame, Index, Series\n\n    from streamlit.proto.Arrow_pb2 import Arrow as ArrowProto\n\n\n# The index identifier can be used to apply configuration options\nIndexIdentifierType = Literal[\"_index\"]\nINDEX_IDENTIFIER: IndexIdentifierType = \"_index\"\n\n# This is used as prefix for columns that are configured via the numerical position.\n# The integer value is converted into a string key with this prefix.\n# This needs to match with the prefix configured in the frontend.\n_NUMERICAL_POSITION_PREFIX = \"_pos:\"\n\n\n# The column data kind is used to describe the type of the data within the column.\nclass ColumnDataKind(str, Enum):\n    INTEGER = \"integer\"\n    FLOAT = \"float\"\n    DATE = \"date\"\n    TIME = \"time\"\n    DATETIME = \"datetime\"\n    BOOLEAN = \"boolean\"\n    STRING = \"string\"\n    TIMEDELTA = \"timedelta\"\n    PERIOD = \"period\"\n    INTERVAL = \"interval\"\n    BYTES = \"bytes\"\n    DECIMAL = \"decimal\"\n    COMPLEX = \"complex\"\n    LIST = \"list\"\n    DICT = \"dict\"\n    EMPTY = \"empty\"\n    UNKNOWN = \"unknown\"\n\n\n# The dataframe schema is a mapping from the name of the column\n# in the underlying dataframe to the column data kind.\n# The index column uses `_index` as name.\nDataframeSchema: TypeAlias = Dict[str, ColumnDataKind]\n\n# This mapping contains all editable column types mapped to the data kinds\n# that the column type is compatible for editing.\n_EDITING_COMPATIBILITY_MAPPING: Final[dict[ColumnType, list[ColumnDataKind]]] = {\n    \"text\": [ColumnDataKind.STRING, ColumnDataKind.EMPTY],\n    \"number\": [\n        ColumnDataKind.INTEGER,\n        ColumnDataKind.FLOAT,\n        ColumnDataKind.DECIMAL,\n        ColumnDataKind.STRING,\n        ColumnDataKind.TIMEDELTA,\n        ColumnDataKind.EMPTY,\n    ],\n    \"checkbox\": [\n        ColumnDataKind.BOOLEAN,\n        ColumnDataKind.STRING,\n        ColumnDataKind.INTEGER,\n        ColumnDataKind.EMPTY,\n    ],\n    \"selectbox\": [\n        ColumnDataKind.STRING,\n        ColumnDataKind.BOOLEAN,\n        ColumnDataKind.INTEGER,\n        ColumnDataKind.FLOAT,\n        ColumnDataKind.EMPTY,\n    ],\n    \"date\": [ColumnDataKind.DATE, ColumnDataKind.DATETIME, ColumnDataKind.EMPTY],\n    \"time\": [ColumnDataKind.TIME, ColumnDataKind.DATETIME, ColumnDataKind.EMPTY],\n    \"datetime\": [\n        ColumnDataKind.DATETIME,\n        ColumnDataKind.DATE,\n        ColumnDataKind.TIME,\n        ColumnDataKind.EMPTY,\n    ],\n    \"link\": [ColumnDataKind.STRING, ColumnDataKind.EMPTY],\n}\n\n\ndef is_type_compatible(column_type: ColumnType, data_kind: ColumnDataKind) -> bool:\n    \"\"\"Check if the column type is compatible with the underlying data kind.\n\n    This check only applies to editable column types (e.g. number or text).\n    Non-editable column types (e.g. bar_chart or image) can be configured for\n    all data kinds (this might change in the future).\n\n    Parameters\n    ----------\n    column_type : ColumnType\n        The column type to check.\n\n    data_kind : ColumnDataKind\n        The data kind to check.\n\n    Returns\n    -------\n    bool\n        True if the column type is compatible with the data kind, False otherwise.\n    \"\"\"\n\n    if column_type not in _EDITING_COMPATIBILITY_MAPPING:\n        return True\n\n    return data_kind in _EDITING_COMPATIBILITY_MAPPING[column_type]\n\n\ndef _determine_data_kind_via_arrow(field: pa.Field) -> ColumnDataKind:\n    \"\"\"Determine the data kind via the arrow type information.\n\n    The column data kind refers to the shared data type of the values\n    in the column (e.g. int, float, str, bool).\n\n    Parameters\n    ----------\n\n    field : pa.Field\n        The arrow field from the arrow table schema.\n\n    Returns\n    -------\n    ColumnDataKind\n        The data kind of the field.\n    \"\"\"\n    import pyarrow as pa\n\n    field_type = field.type\n    if pa.types.is_integer(field_type):\n        return ColumnDataKind.INTEGER\n\n    if pa.types.is_floating(field_type):\n        return ColumnDataKind.FLOAT\n\n    if pa.types.is_boolean(field_type):\n        return ColumnDataKind.BOOLEAN\n\n    if pa.types.is_string(field_type):\n        return ColumnDataKind.STRING\n\n    if pa.types.is_date(field_type):\n        return ColumnDataKind.DATE\n\n    if pa.types.is_time(field_type):\n        return ColumnDataKind.TIME\n\n    if pa.types.is_timestamp(field_type):\n        return ColumnDataKind.DATETIME\n\n    if pa.types.is_duration(field_type):\n        return ColumnDataKind.TIMEDELTA\n\n    if pa.types.is_list(field_type):\n        return ColumnDataKind.LIST\n\n    if pa.types.is_decimal(field_type):\n        return ColumnDataKind.DECIMAL\n\n    if pa.types.is_null(field_type):\n        return ColumnDataKind.EMPTY\n\n    # Interval does not seem to work correctly:\n    # if pa.types.is_interval(field_type):\n    #     return ColumnDataKind.INTERVAL\n\n    if pa.types.is_binary(field_type):\n        return ColumnDataKind.BYTES\n\n    if pa.types.is_struct(field_type):\n        return ColumnDataKind.DICT\n\n    return ColumnDataKind.UNKNOWN\n\n\ndef _determine_data_kind_via_pandas_dtype(\n    column: Series | Index,\n) -> ColumnDataKind:\n    \"\"\"Determine the data kind by using the pandas dtype.\n\n    The column data kind refers to the shared data type of the values\n    in the column (e.g. int, float, str, bool).\n\n    Parameters\n    ----------\n    column : pd.Series, pd.Index\n        The column for which the data kind should be determined.\n\n    Returns\n    -------\n    ColumnDataKind\n        The data kind of the column.\n    \"\"\"\n    import pandas as pd\n\n    column_dtype = column.dtype\n    if pd.api.types.is_bool_dtype(column_dtype):\n        return ColumnDataKind.BOOLEAN\n\n    if pd.api.types.is_integer_dtype(column_dtype):\n        return ColumnDataKind.INTEGER\n\n    if pd.api.types.is_float_dtype(column_dtype):\n        return ColumnDataKind.FLOAT\n\n    if pd.api.types.is_datetime64_any_dtype(column_dtype):\n        return ColumnDataKind.DATETIME\n\n    if pd.api.types.is_timedelta64_dtype(column_dtype):\n        return ColumnDataKind.TIMEDELTA\n\n    if isinstance(column_dtype, pd.PeriodDtype):\n        return ColumnDataKind.PERIOD\n\n    if isinstance(column_dtype, pd.IntervalDtype):\n        return ColumnDataKind.INTERVAL\n\n    if pd.api.types.is_complex_dtype(column_dtype):\n        return ColumnDataKind.COMPLEX\n\n    if pd.api.types.is_object_dtype(\n        column_dtype\n    ) is False and pd.api.types.is_string_dtype(column_dtype):\n        # The is_string_dtype\n        return ColumnDataKind.STRING\n\n    return ColumnDataKind.UNKNOWN\n\n\ndef _determine_data_kind_via_inferred_type(\n    column: Series | Index,\n) -> ColumnDataKind:\n    \"\"\"Determine the data kind by inferring it from the underlying data.\n\n    The column data kind refers to the shared data type of the values\n    in the column (e.g. int, float, str, bool).\n\n    Parameters\n    ----------\n    column : pd.Series, pd.Index\n        The column to determine the data kind for.\n\n    Returns\n    -------\n    ColumnDataKind\n        The data kind of the column.\n    \"\"\"\n    from pandas.api.types import infer_dtype\n\n    inferred_type = infer_dtype(column)\n\n    if inferred_type == \"string\":\n        return ColumnDataKind.STRING\n\n    if inferred_type == \"bytes\":\n        return ColumnDataKind.BYTES\n\n    if inferred_type in [\"floating\", \"mixed-integer-float\"]:\n        return ColumnDataKind.FLOAT\n\n    if inferred_type == \"integer\":\n        return ColumnDataKind.INTEGER\n\n    if inferred_type == \"decimal\":\n        return ColumnDataKind.DECIMAL\n\n    if inferred_type == \"complex\":\n        return ColumnDataKind.COMPLEX\n\n    if inferred_type == \"boolean\":\n        return ColumnDataKind.BOOLEAN\n\n    if inferred_type in [\"datetime64\", \"datetime\"]:\n        return ColumnDataKind.DATETIME\n\n    if inferred_type == \"date\":\n        return ColumnDataKind.DATE\n\n    if inferred_type in [\"timedelta64\", \"timedelta\"]:\n        return ColumnDataKind.TIMEDELTA\n\n    if inferred_type == \"time\":\n        return ColumnDataKind.TIME\n\n    if inferred_type == \"period\":\n        return ColumnDataKind.PERIOD\n\n    if inferred_type == \"interval\":\n        return ColumnDataKind.INTERVAL\n\n    if inferred_type == \"empty\":\n        return ColumnDataKind.EMPTY\n\n    # Unused types: mixed, unknown-array, categorical, mixed-integer\n\n    return ColumnDataKind.UNKNOWN\n\n\ndef _determine_data_kind(\n    column: Series | Index, field: pa.Field | None = None\n) -> ColumnDataKind:\n    \"\"\"Determine the data kind of a column.\n\n    The column data kind refers to the shared data type of the values\n    in the column (e.g. int, float, str, bool).\n\n    Parameters\n    ----------\n    column : pd.Series, pd.Index\n        The column to determine the data kind for.\n    field : pa.Field, optional\n        The arrow field from the arrow table schema.\n\n    Returns\n    -------\n    ColumnDataKind\n        The data kind of the column.\n    \"\"\"\n    import pandas as pd\n\n    if isinstance(column.dtype, pd.CategoricalDtype):\n        # Categorical columns can have different underlying data kinds\n        # depending on the categories.\n        return _determine_data_kind_via_inferred_type(column.dtype.categories)\n\n    if field is not None:\n        data_kind = _determine_data_kind_via_arrow(field)\n        if data_kind != ColumnDataKind.UNKNOWN:\n            return data_kind\n\n    if column.dtype.name == \"object\":\n        # If dtype is object, we need to infer the type from the column\n        return _determine_data_kind_via_inferred_type(column)\n    return _determine_data_kind_via_pandas_dtype(column)\n\n\ndef determine_dataframe_schema(\n    data_df: DataFrame, arrow_schema: pa.Schema\n) -> DataframeSchema:\n    \"\"\"Determine the schema of a dataframe.\n\n    Parameters\n    ----------\n    data_df : pd.DataFrame\n        The dataframe to determine the schema of.\n    arrow_schema : pa.Schema\n        The Arrow schema of the dataframe.\n\n    Returns\n    -------\n\n    DataframeSchema\n        A mapping that contains the detected data type for the index and columns.\n        The key is the column name in the underlying dataframe or ``_index`` for index columns.\n    \"\"\"\n\n    dataframe_schema: DataframeSchema = {}\n\n    # Add type of index:\n    # TODO(lukasmasuch): We need to apply changes here to support multiindex.\n    dataframe_schema[INDEX_IDENTIFIER] = _determine_data_kind(data_df.index)\n\n    # Add types for all columns:\n    for i, column in enumerate(data_df.items()):\n        column_name, column_data = column\n        dataframe_schema[column_name] = _determine_data_kind(\n            column_data, arrow_schema.field(i)\n        )\n    return dataframe_schema\n\n\n# A mapping of column names/IDs to column configs.\nColumnConfigMapping: TypeAlias = Dict[Union[IndexIdentifierType, str], ColumnConfig]\nColumnConfigMappingInput: TypeAlias = Mapping[\n    Union[IndexIdentifierType, str],\n    Union[ColumnConfig, None, str],\n]\n\n\ndef process_config_mapping(\n    column_config: ColumnConfigMappingInput | None = None,\n) -> ColumnConfigMapping:\n    \"\"\"Transforms a user-provided column config mapping into a valid column config mapping\n    that can be used by the frontend.\n\n    Parameters\n    ----------\n    column_config: dict or None\n        The user-provided column config mapping.\n\n    Returns\n    -------\n    dict\n        The transformed column config mapping.\n    \"\"\"\n    if column_config is None:\n        return {}\n\n    transformed_column_config: ColumnConfigMapping = {}\n    for column, config in column_config.items():\n        if config is None:\n            transformed_column_config[column] = ColumnConfig(hidden=True)\n        elif isinstance(config, str):\n            transformed_column_config[column] = ColumnConfig(label=config)\n        elif isinstance(config, dict):\n            # Ensure that the column config objects are cloned\n            # since we will apply in-place changes to it.\n            transformed_column_config[column] = copy.deepcopy(config)\n        else:\n            raise StreamlitAPIException(\n                f\"Invalid column config for column `{column}`. \"\n                f\"Expected `None`, `str` or `dict`, but got `{type(config)}`.\"\n            )\n    return transformed_column_config\n\n\ndef update_column_config(\n    column_config_mapping: ColumnConfigMapping, column: str, column_config: ColumnConfig\n) -> None:\n    \"\"\"Updates the column config value for a single column within the mapping.\n\n    Parameters\n    ----------\n\n    column_config_mapping : ColumnConfigMapping\n        The column config mapping to update.\n\n    column : str\n        The column to update the config value for.\n\n    column_config : ColumnConfig\n        The column config to update.\n    \"\"\"\n\n    if column not in column_config_mapping:\n        column_config_mapping[column] = {}\n\n    column_config_mapping[column].update(column_config)\n\n\ndef apply_data_specific_configs(\n    columns_config: ColumnConfigMapping,\n    data_df: DataFrame,\n    data_format: DataFormat,\n    check_arrow_compatibility: bool = False,\n) -> None:\n    \"\"\"Apply data specific configurations to the provided dataframe.\n\n    This will apply inplace changes to the dataframe and the column configurations\n    depending on the data format.\n\n    Parameters\n    ----------\n    columns_config : ColumnConfigMapping\n        A mapping of column names/ids to column configurations.\n\n    data_df : pd.DataFrame\n        The dataframe to apply the configurations to.\n\n    data_format : DataFormat\n        The format of the data.\n\n    check_arrow_compatibility : bool\n        Whether to check if the data is compatible with arrow.\n    \"\"\"\n    import pandas as pd\n\n    # Deactivate editing for columns that are not compatible with arrow\n    if check_arrow_compatibility:\n        for column_name, column_data in data_df.items():\n            if is_colum_type_arrow_incompatible(column_data):\n                update_column_config(columns_config, column_name, {\"disabled\": True})\n                # Convert incompatible type to string\n                data_df[column_name] = column_data.astype(\"string\")\n\n    # Pandas adds a range index as default to all datastructures\n    # but for most of the non-pandas data objects it is unnecessary\n    # to show this index to the user. Therefore, we will hide it as default.\n    if data_format in [\n        DataFormat.SET_OF_VALUES,\n        DataFormat.TUPLE_OF_VALUES,\n        DataFormat.LIST_OF_VALUES,\n        DataFormat.NUMPY_LIST,\n        DataFormat.NUMPY_MATRIX,\n        DataFormat.LIST_OF_RECORDS,\n        DataFormat.LIST_OF_ROWS,\n        DataFormat.COLUMN_VALUE_MAPPING,\n    ]:\n        update_column_config(columns_config, INDEX_IDENTIFIER, {\"hidden\": True})\n\n    # Rename the first column to \"value\" for some of the data formats\n    if data_format in [\n        DataFormat.SET_OF_VALUES,\n        DataFormat.TUPLE_OF_VALUES,\n        DataFormat.LIST_OF_VALUES,\n        DataFormat.NUMPY_LIST,\n        DataFormat.KEY_VALUE_DICT,\n    ]:\n        # Pandas automatically names the first column \"0\"\n        # We rename it to \"value\" in selected cases to make it more descriptive\n        data_df.rename(columns={0: \"value\"}, inplace=True)\n\n    if not isinstance(data_df.index, pd.RangeIndex):\n        # If the index is not a range index, we will configure it as required\n        # since the user is required to provide a (unique) value for editing.\n        update_column_config(columns_config, INDEX_IDENTIFIER, {\"required\": True})\n\n\ndef _convert_column_config_to_json(column_config_mapping: ColumnConfigMapping) -> str:\n    try:\n        # Ignore all None values and prefix columns specified by numerical index:\n        return json.dumps(\n            {\n                (\n                    f\"{_NUMERICAL_POSITION_PREFIX}{str(k)}\" if isinstance(k, int) else k\n                ): v\n                for (k, v) in remove_none_values(column_config_mapping).items()\n            },\n            allow_nan=False,\n        )\n    except ValueError as ex:\n        raise StreamlitAPIException(\n            f\"The provided column config cannot be serialized into JSON: {ex}\"\n        ) from ex\n\n\ndef marshall_column_config(\n    proto: ArrowProto, column_config_mapping: ColumnConfigMapping\n) -> None:\n    \"\"\"Marshall the column config into the Arrow proto.\n\n    Parameters\n    ----------\n    proto : ArrowProto\n        The proto to marshall into.\n\n    column_config_mapping : ColumnConfigMapping\n        The column config to marshall.\n    \"\"\"\n\n    proto.columns = _convert_column_config_to_json(column_config_mapping)\n", "lib/streamlit/elements/lib/policies.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom typing import TYPE_CHECKING, Any\n\nfrom streamlit import config, runtime\nfrom streamlit.elements.form import is_in_form\nfrom streamlit.errors import StreamlitAPIException, StreamlitAPIWarning\nfrom streamlit.runtime.scriptrunner.script_run_context import get_script_run_ctx\nfrom streamlit.runtime.state import WidgetCallback, get_session_state\n\nif TYPE_CHECKING:\n    from streamlit.delta_generator import DeltaGenerator\n\n\ndef check_callback_rules(dg: DeltaGenerator, on_change: WidgetCallback | None) -> None:\n    \"\"\"Ensures that widgets other than `st.form_submit` within a form don't have an on_change callback set.\n\n    Raises\n    ------\n    StreamlitAPIException:\n        Raised when the described rule is violated.\n    \"\"\"\n\n    if runtime.exists() and is_in_form(dg) and on_change is not None:\n        raise StreamlitAPIException(\n            \"With forms, callbacks can only be defined on the `st.form_submit_button`.\"\n            \" Defining callbacks on other widgets inside a form is not allowed.\"\n        )\n\n\n_shown_default_value_warning: bool = False\n\n\ndef check_session_state_rules(\n    default_value: Any, key: str | None, writes_allowed: bool = True\n) -> None:\n    \"\"\"Ensures that no values are set for widgets with the given key when writing is not allowed.\n\n    Additionally, if `global.disableWidgetStateDuplicationWarning` is False a warning is shown when a widget has a default value but its value is also set via session state.\n\n    Raises\n    ------\n    StreamlitAPIException:\n        Raised when the described rule is violated.\n    \"\"\"\n    global _shown_default_value_warning\n\n    if key is None or not runtime.exists():\n        return\n\n    session_state = get_session_state()\n    if not session_state.is_new_state_value(key):\n        return\n\n    if not writes_allowed:\n        raise StreamlitAPIException(\n            f'Values for the widget with key \"{key}\" cannot be set using `st.session_state`.'\n        )\n\n    if (\n        default_value is not None\n        and not _shown_default_value_warning\n        and not config.get_option(\"global.disableWidgetStateDuplicationWarning\")\n    ):\n        from streamlit import warning\n\n        warning(\n            f'The widget with key \"{key}\" was created with a default value but'\n            \" also had its value set via the Session State API.\"\n        )\n        _shown_default_value_warning = True\n\n\nclass CachedWidgetWarning(StreamlitAPIWarning):\n    def __init__(self):\n        super().__init__(\n            \"\"\"\nYour script uses a widget command in a cached function\n(function decorated with `@st.cache_data` or `@st.cache_resource`).\nThis code will only be called when we detect a cache \"miss\",\nwhich can lead to unexpected results.\n\nTo fix this, move all widget commands outside the cached function.\n\"\"\"\n        )\n\n\ndef check_cache_replay_rules() -> None:\n    \"\"\"Check if a widget is allowed to be used in the current context.\n    More specifically, this checks if the current context is inside a\n    cached function that disallows widget usage. If so, it raises a warning.\n\n    If there are other similar checks in the future, we could extend this\n    function to check for those as well. And rename it to check_widget_usage_rules.\n    \"\"\"\n    if runtime.exists():\n        ctx = get_script_run_ctx()\n        if ctx and ctx.disallow_cached_widget_usage:\n            from streamlit import exception\n\n            # We use an exception here to show a proper stack trace\n            # that indicates to the user where the issue is.\n            exception(CachedWidgetWarning())\n\n\n_fragment_writes_widget_to_outside_error = (\n    \"Fragments cannot write to elements outside of their container.\"\n)\n\n\ndef check_fragment_path_policy(dg: DeltaGenerator):\n    ctx = get_script_run_ctx()\n    # Check is only relevant for fragments\n    if ctx is None or ctx.current_fragment_id is None:\n        return\n\n    current_fragment_delta_path = ctx.current_fragment_delta_path\n    current_cursor = dg._active_dg._cursor\n    if current_cursor is None:\n        return\n\n    current_cursor_delta_path = current_cursor.delta_path\n\n    # the elements delta path cannot be smaller than the fragment's delta path if it is inside of the fragment\n    if len(current_cursor_delta_path) < len(current_fragment_delta_path):\n        raise StreamlitAPIException(_fragment_writes_widget_to_outside_error)\n\n    # all path indices of the fragment-path must occur in the inner-elements delta path, otherwise it is outside of the fragment container\n    for index, path_index in enumerate(current_fragment_delta_path):\n        if current_cursor_delta_path[index] != path_index:\n            raise StreamlitAPIException(_fragment_writes_widget_to_outside_error)\n", "lib/streamlit/elements/lib/event_utils.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom typing import Any, Dict\n\n\nclass AttributeDictionary(Dict[Any, Any]):\n    \"\"\"\n    A dictionary subclass that supports attribute-style access.\n\n    This class extends the functionality of a standard dictionary to allow items to be accessed\n    via attribute-style dot notation in addition to the traditional key-based access. If a dictionary\n    item is accessed and is itself a dictionary, it is automatically wrapped in another `AttributeDictionary`,\n    enabling recursive attribute-style access.\n    \"\"\"\n\n    def __getattr__(self, key):\n        try:\n            item = self.__getitem__(key)\n            return AttributeDictionary(item) if isinstance(item, dict) else item\n        except KeyError as err:\n            raise AttributeError(\n                f\"'{type(self).__name__}' object has no attribute '{key}'\"\n            ) from err\n\n    __setattr__ = dict.__setitem__\n", "lib/streamlit/elements/lib/column_types.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport datetime\nfrom typing import Iterable, Literal, TypedDict\n\nfrom typing_extensions import NotRequired, TypeAlias\n\nfrom streamlit.runtime.metrics_util import gather_metrics\n\nColumnWidth: TypeAlias = Literal[\"small\", \"medium\", \"large\"]\n\n# Type alias that represents all available column types\n# which are configurable by the user.\nColumnType: TypeAlias = Literal[\n    \"object\",\n    \"text\",\n    \"number\",\n    \"checkbox\",\n    \"selectbox\",\n    \"list\",\n    \"datetime\",\n    \"date\",\n    \"time\",\n    \"link\",\n    \"line_chart\",\n    \"bar_chart\",\n    \"area_chart\",\n    \"image\",\n    \"progress\",\n]\n\n\nclass NumberColumnConfig(TypedDict):\n    type: Literal[\"number\"]\n    format: NotRequired[str | None]\n    min_value: NotRequired[int | float | None]\n    max_value: NotRequired[int | float | None]\n    step: NotRequired[int | float | None]\n\n\nclass TextColumnConfig(TypedDict):\n    type: Literal[\"text\"]\n    max_chars: NotRequired[int | None]\n    validate: NotRequired[str | None]\n\n\nclass CheckboxColumnConfig(TypedDict):\n    type: Literal[\"checkbox\"]\n\n\nclass SelectboxColumnConfig(TypedDict):\n    type: Literal[\"selectbox\"]\n    options: NotRequired[list[str | int | float] | None]\n\n\nclass LinkColumnConfig(TypedDict):\n    type: Literal[\"link\"]\n    max_chars: NotRequired[int | None]\n    validate: NotRequired[str | None]\n    display_text: NotRequired[str | None]\n\n\nclass BarChartColumnConfig(TypedDict):\n    type: Literal[\"bar_chart\"]\n    y_min: NotRequired[int | float | None]\n    y_max: NotRequired[int | float | None]\n\n\nclass LineChartColumnConfig(TypedDict):\n    type: Literal[\"line_chart\"]\n    y_min: NotRequired[int | float | None]\n    y_max: NotRequired[int | float | None]\n\n\nclass AreaChartColumnConfig(TypedDict):\n    type: Literal[\"area_chart\"]\n    y_min: NotRequired[int | float | None]\n    y_max: NotRequired[int | float | None]\n\n\nclass ImageColumnConfig(TypedDict):\n    type: Literal[\"image\"]\n\n\nclass ListColumnConfig(TypedDict):\n    type: Literal[\"list\"]\n\n\nclass DatetimeColumnConfig(TypedDict):\n    type: Literal[\"datetime\"]\n    format: NotRequired[str | None]\n    min_value: NotRequired[str | None]\n    max_value: NotRequired[str | None]\n    step: NotRequired[int | float | None]\n    timezone: NotRequired[str | None]\n\n\nclass TimeColumnConfig(TypedDict):\n    type: Literal[\"time\"]\n    format: NotRequired[str | None]\n    min_value: NotRequired[str | None]\n    max_value: NotRequired[str | None]\n    step: NotRequired[int | float | None]\n\n\nclass DateColumnConfig(TypedDict):\n    type: Literal[\"date\"]\n    format: NotRequired[str | None]\n    min_value: NotRequired[str | None]\n    max_value: NotRequired[str | None]\n    step: NotRequired[int | None]\n\n\nclass ProgressColumnConfig(TypedDict):\n    type: Literal[\"progress\"]\n    format: NotRequired[str | None]\n    min_value: NotRequired[int | float | None]\n    max_value: NotRequired[int | float | None]\n\n\nclass ColumnConfig(TypedDict, total=False):\n    \"\"\"Configuration options for columns in ``st.dataframe`` and ``st.data_editor``.\n\n    Parameters\n    ----------\n\n    label: str or None\n        The label shown at the top of the column. If None (default),\n        the column name is used.\n\n    width: \"small\", \"medium\", \"large\", or None\n        The display width of the column. Can be one of \"small\", \"medium\", or \"large\".\n        If None (default), the column will be sized to fit the cell contents.\n\n    help: str or None\n        An optional tooltip that gets displayed when hovering over the column label.\n\n    disabled: bool or None\n        Whether editing should be disabled for this column. Defaults to False.\n\n    required: bool or None\n        Whether edited cells in the column need to have a value. If True, an edited cell\n        can only be submitted if it has a value other than None. Defaults to False.\n\n    default: str, bool, int, float, or None\n        Specifies the default value in this column when a new row is added by the user.\n\n    hidden: bool or None\n        Whether to hide the column. Defaults to False.\n\n    type_config: dict or str or None\n        Configure a column type and type specific options.\n    \"\"\"\n\n    label: str | None\n    width: ColumnWidth | None\n    help: str | None\n    hidden: bool | None\n    disabled: bool | None\n    required: bool | None\n    default: str | bool | int | float | None\n    alignment: Literal[\"left\", \"center\", \"right\"] | None\n    type_config: (\n        NumberColumnConfig\n        | TextColumnConfig\n        | CheckboxColumnConfig\n        | SelectboxColumnConfig\n        | LinkColumnConfig\n        | ListColumnConfig\n        | DatetimeColumnConfig\n        | DateColumnConfig\n        | TimeColumnConfig\n        | ProgressColumnConfig\n        | LineChartColumnConfig\n        | BarChartColumnConfig\n        | AreaChartColumnConfig\n        | ImageColumnConfig\n        | None\n    )\n\n\n@gather_metrics(\"column_config.Column\")\ndef Column(\n    label: str | None = None,\n    *,\n    width: ColumnWidth | None = None,\n    help: str | None = None,\n    disabled: bool | None = None,\n    required: bool | None = None,\n) -> ColumnConfig:\n    \"\"\"Configure a generic column in ``st.dataframe`` or ``st.data_editor``.\n\n    The type of the column will be automatically inferred from the data type.\n    This command needs to be used in the ``column_config`` parameter of ``st.dataframe``\n    or ``st.data_editor``.\n\n    To change the type of the column and enable type-specific configuration options,\n    use one of the column types in the ``st.column_config`` namespace,\n    e.g. ``st.column_config.NumberColumn``.\n\n    Parameters\n    ----------\n\n    label: str or None\n        The label shown at the top of the column. If None (default),\n        the column name is used.\n\n    width: \"small\", \"medium\", \"large\", or None\n        The display width of the column. Can be one of \"small\", \"medium\", or \"large\".\n        If None (default), the column will be sized to fit the cell contents.\n\n    help: str or None\n        An optional tooltip that gets displayed when hovering over the column label.\n\n    disabled: bool or None\n        Whether editing should be disabled for this column. Defaults to False.\n\n    required: bool or None\n        Whether edited cells in the column need to have a value. If True, an edited cell\n        can only be submitted if it has a value other than None. Defaults to False.\n\n    Examples\n    --------\n\n    >>> import pandas as pd\n    >>> import streamlit as st\n    >>>\n    >>> data_df = pd.DataFrame(\n    >>>     {\n    >>>         \"widgets\": [\"st.selectbox\", \"st.number_input\", \"st.text_area\", \"st.button\"],\n    >>>     }\n    >>> )\n    >>>\n    >>> st.data_editor(\n    >>>     data_df,\n    >>>     column_config={\n    >>>         \"widgets\": st.column_config.Column(\n    >>>             \"Streamlit Widgets\",\n    >>>             help=\"Streamlit **widget** commands \ud83c\udf88\",\n    >>>             width=\"medium\",\n    >>>             required=True,\n    >>>         )\n    >>>     },\n    >>>     hide_index=True,\n    >>>     num_rows=\"dynamic\",\n    >>> )\n\n    .. output::\n        https://doc-column.streamlit.app/\n        height: 300px\n    \"\"\"\n    return ColumnConfig(\n        label=label, width=width, help=help, disabled=disabled, required=required\n    )\n\n\n@gather_metrics(\"column_config.NumberColumn\")\ndef NumberColumn(\n    label: str | None = None,\n    *,\n    width: ColumnWidth | None = None,\n    help: str | None = None,\n    disabled: bool | None = None,\n    required: bool | None = None,\n    default: int | float | None = None,\n    format: str | None = None,\n    min_value: int | float | None = None,\n    max_value: int | float | None = None,\n    step: int | float | None = None,\n) -> ColumnConfig:\n    \"\"\"Configure a number column in ``st.dataframe`` or ``st.data_editor``.\n\n    This is the default column type for integer and float values. This command needs to\n    be used in the ``column_config`` parameter of ``st.dataframe`` or ``st.data_editor``.\n    When used with ``st.data_editor``, editing will be enabled with a numeric input widget.\n\n    Parameters\n    ----------\n\n    label: str or None\n        The label shown at the top of the column. If None (default),\n        the column name is used.\n\n    width: \"small\", \"medium\", \"large\", or None\n        The display width of the column. Can be one of \"small\", \"medium\", or \"large\".\n        If None (default), the column will be sized to fit the cell contents.\n\n    help: str or None\n        An optional tooltip that gets displayed when hovering over the column label.\n\n    disabled: bool or None\n        Whether editing should be disabled for this column. Defaults to False.\n\n    required: bool or None\n        Whether edited cells in the column need to have a value. If True, an edited cell\n        can only be submitted if it has a value other than None. Defaults to False.\n\n    default: int, float, or None\n        Specifies the default value in this column when a new row is added by the user.\n\n    format : str or None\n        A printf-style format string controlling how numbers are displayed.\n        This does not impact the return value. Valid formatters: %d %e %f %g %i %u.\n        You can also add prefixes and suffixes, e.g. ``\"$ %.2f\"`` to show a dollar prefix.\n\n    min_value : int, float, or None\n        The minimum value that can be entered.\n        If None (default), there will be no minimum.\n\n    max_value : int, float, or None\n        The maximum value that can be entered.\n        If None (default), there will be no maximum.\n\n    step: int, float, or None\n        The stepping interval. Specifies the precision of numbers that can be entered.\n        If None (default), uses 1 for integers and unrestricted precision for floats.\n\n    Examples\n    --------\n\n    >>> import pandas as pd\n    >>> import streamlit as st\n    >>>\n    >>> data_df = pd.DataFrame(\n    >>>     {\n    >>>         \"price\": [20, 950, 250, 500],\n    >>>     }\n    >>> )\n    >>>\n    >>> st.data_editor(\n    >>>     data_df,\n    >>>     column_config={\n    >>>         \"price\": st.column_config.NumberColumn(\n    >>>             \"Price (in USD)\",\n    >>>             help=\"The price of the product in USD\",\n    >>>             min_value=0,\n    >>>             max_value=1000,\n    >>>             step=1,\n    >>>             format=\"$%d\",\n    >>>         )\n    >>>     },\n    >>>     hide_index=True,\n    >>> )\n\n    .. output::\n        https://doc-number-column.streamlit.app/\n        height: 300px\n    \"\"\"\n\n    return ColumnConfig(\n        label=label,\n        width=width,\n        help=help,\n        disabled=disabled,\n        required=required,\n        default=default,\n        type_config=NumberColumnConfig(\n            type=\"number\",\n            min_value=min_value,\n            max_value=max_value,\n            format=format,\n            step=step,\n        ),\n    )\n\n\n@gather_metrics(\"column_config.TextColumn\")\ndef TextColumn(\n    label: str | None = None,\n    *,\n    width: ColumnWidth | None = None,\n    help: str | None = None,\n    disabled: bool | None = None,\n    required: bool | None = None,\n    default: str | None = None,\n    max_chars: int | None = None,\n    validate: str | None = None,\n) -> ColumnConfig:\n    r\"\"\"Configure a text column in ``st.dataframe`` or ``st.data_editor``.\n\n    This is the default column type for string values. This command needs to be used in the\n    ``column_config`` parameter of ``st.dataframe`` or ``st.data_editor``. When used with\n    ``st.data_editor``, editing will be enabled with a text input widget.\n\n    Parameters\n    ----------\n\n    label: str or None\n        The label shown at the top of the column. If None (default),\n        the column name is used.\n\n    width: \"small\", \"medium\", \"large\", or None\n        The display width of the column. Can be one of \"small\", \"medium\", or \"large\".\n        If None (default), the column will be sized to fit the cell contents.\n\n    help: str or None\n        An optional tooltip that gets displayed when hovering over the column label.\n\n    disabled: bool or None\n        Whether editing should be disabled for this column. Defaults to False.\n\n    required: bool or None\n        Whether edited cells in the column need to have a value. If True, an edited cell\n        can only be submitted if it has a value other than None. Defaults to False.\n\n    default: str or None\n        Specifies the default value in this column when a new row is added by the user.\n\n    max_chars: int or None\n        The maximum number of characters that can be entered. If None (default),\n        there will be no maximum.\n\n    validate: str or None\n        A regular expression (JS flavor, e.g. ``\"^[a-z]+$\"``) that edited values are validated against.\n        If the input is invalid, it will not be submitted.\n\n    Examples\n    --------\n\n    >>> import pandas as pd\n    >>> import streamlit as st\n    >>>\n    >>> data_df = pd.DataFrame(\n    >>>     {\n    >>>         \"widgets\": [\"st.selectbox\", \"st.number_input\", \"st.text_area\", \"st.button\"],\n    >>>     }\n    >>> )\n    >>>\n    >>> st.data_editor(\n    >>>     data_df,\n    >>>     column_config={\n    >>>         \"widgets\": st.column_config.TextColumn(\n    >>>             \"Widgets\",\n    >>>             help=\"Streamlit **widget** commands \ud83c\udf88\",\n    >>>             default=\"st.\",\n    >>>             max_chars=50,\n    >>>             validate=\"^st\\.[a-z_]+$\",\n    >>>         )\n    >>>     },\n    >>>     hide_index=True,\n    >>> )\n\n    .. output::\n        https://doc-text-column.streamlit.app/\n        height: 300px\n    \"\"\"\n\n    return ColumnConfig(\n        label=label,\n        width=width,\n        help=help,\n        disabled=disabled,\n        required=required,\n        default=default,\n        type_config=TextColumnConfig(\n            type=\"text\", max_chars=max_chars, validate=validate\n        ),\n    )\n\n\n@gather_metrics(\"column_config.LinkColumn\")\ndef LinkColumn(\n    label: str | None = None,\n    *,\n    width: ColumnWidth | None = None,\n    help: str | None = None,\n    disabled: bool | None = None,\n    required: bool | None = None,\n    default: str | None = None,\n    max_chars: int | None = None,\n    validate: str | None = None,\n    display_text: str | None = None,\n) -> ColumnConfig:\n    \"\"\"Configure a link column in ``st.dataframe`` or ``st.data_editor``.\n\n    The cell values need to be string and will be shown as clickable links.\n    This command needs to be used in the column_config parameter of ``st.dataframe``\n    or ``st.data_editor``. When used with ``st.data_editor``, editing will be enabled\n    with a text input widget.\n\n    Parameters\n    ----------\n\n    label: str or None\n        The label shown at the top of the column. If None (default),\n        the column name is used.\n\n    width: \"small\", \"medium\", \"large\", or None\n        The display width of the column. Can be one of \"small\", \"medium\", or \"large\".\n        If None (default), the column will be sized to fit the cell contents.\n\n    help: str or None\n        An optional tooltip that gets displayed when hovering over the column label.\n\n    disabled: bool or None\n        Whether editing should be disabled for this column. Defaults to False.\n\n    required: bool or None\n        Whether edited cells in the column need to have a value. If True, an edited cell\n        can only be submitted if it has a value other than None. Defaults to False.\n\n    default: str or None\n        Specifies the default value in this column when a new row is added by the user.\n\n    max_chars: int or None\n        The maximum number of characters that can be entered. If None (default),\n        there will be no maximum.\n\n    validate: str or None\n        A regular expression (JS flavor, e.g. ``\"^https://.+$\"``) that edited values are validated against.\n        If the input is invalid, it will not be submitted.\n\n    display_text: str or None\n        The text that is displayed in the cell. Can be one of:\n\n        * ``None`` (default) to display the URL itself.\n\n        * A string that is displayed in every cell, e.g. ``\"Open link\"``.\n\n        * A regular expression (JS flavor, detected by usage of parentheses)\n          to extract a part of the URL via a capture group, e.g. ``\"https://(.*?)\\\\.example\\\\.com\"``\n          to extract the display text \"foo\" from the URL \"\\\\https://foo.example.com\".\n\n        .. Comment: The backslash in front of foo.example.com prevents a hyperlink.\n\n        For more complex cases, you may use `Pandas Styler's format \\\n        <https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.format.html>`_\n        function on the underlying dataframe. Note that this makes the app slow,\n        doesn't work with editable columns, and might be removed in the future.\n\n    Examples\n    --------\n\n    >>> import pandas as pd\n    >>> import streamlit as st\n    >>>\n    >>> data_df = pd.DataFrame(\n    >>>     {\n    >>>         \"apps\": [\n    >>>             \"https://roadmap.streamlit.app\",\n    >>>             \"https://extras.streamlit.app\",\n    >>>             \"https://issues.streamlit.app\",\n    >>>             \"https://30days.streamlit.app\",\n    >>>         ],\n    >>>         \"creator\": [\n    >>>             \"https://github.com/streamlit\",\n    >>>             \"https://github.com/arnaudmiribel\",\n    >>>             \"https://github.com/streamlit\",\n    >>>             \"https://github.com/streamlit\",\n    >>>         ],\n    >>>     }\n    >>> )\n    >>>\n    >>> st.data_editor(\n    >>>     data_df,\n    >>>     column_config={\n    >>>         \"apps\": st.column_config.LinkColumn(\n    >>>             \"Trending apps\",\n    >>>             help=\"The top trending Streamlit apps\",\n    >>>             validate=\"^https://[a-z]+\\\\.streamlit\\\\.app$\",\n    >>>             max_chars=100,\n    >>>             display_text=\"https://(.*?)\\\\.streamlit\\\\.app\"\n    >>>         ),\n    >>>         \"creator\": st.column_config.LinkColumn(\n    >>>             \"App Creator\", display_text=\"Open profile\"\n    >>>         ),\n    >>>     },\n    >>>     hide_index=True,\n    >>> )\n\n    .. output::\n        https://doc-link-column.streamlit.app/\n        height: 300px\n    \"\"\"\n\n    return ColumnConfig(\n        label=label,\n        width=width,\n        help=help,\n        disabled=disabled,\n        required=required,\n        default=default,\n        type_config=LinkColumnConfig(\n            type=\"link\",\n            max_chars=max_chars,\n            validate=validate,\n            display_text=display_text,\n        ),\n    )\n\n\n@gather_metrics(\"column_config.CheckboxColumn\")\ndef CheckboxColumn(\n    label: str | None = None,\n    *,\n    width: ColumnWidth | None = None,\n    help: str | None = None,\n    disabled: bool | None = None,\n    required: bool | None = None,\n    default: bool | None = None,\n) -> ColumnConfig:\n    \"\"\"Configure a checkbox column in ``st.dataframe`` or ``st.data_editor``.\n\n    This is the default column type for boolean values. This command needs to be used in\n    the ``column_config`` parameter of ``st.dataframe`` or ``st.data_editor``.\n    When used with ``st.data_editor``, editing will be enabled with a checkbox widget.\n\n    Parameters\n    ----------\n\n    label: str or None\n        The label shown at the top of the column. If None (default),\n        the column name is used.\n\n    width: \"small\", \"medium\", \"large\", or None\n        The display width of the column. Can be one of \"small\", \"medium\", or \"large\".\n        If None (default), the column will be sized to fit the cell contents.\n\n    help: str or None\n        An optional tooltip that gets displayed when hovering over the column label.\n\n    disabled: bool or None\n        Whether editing should be disabled for this column. Defaults to False.\n\n    required: bool or None\n        Whether edited cells in the column need to have a value. If True, an edited cell\n        can only be submitted if it has a value other than None. Defaults to False.\n\n    default: bool or None\n        Specifies the default value in this column when a new row is added by the user.\n\n    Examples\n    --------\n\n    >>> import pandas as pd\n    >>> import streamlit as st\n    >>>\n    >>> data_df = pd.DataFrame(\n    >>>     {\n    >>>         \"widgets\": [\"st.selectbox\", \"st.number_input\", \"st.text_area\", \"st.button\"],\n    >>>         \"favorite\": [True, False, False, True],\n    >>>     }\n    >>> )\n    >>>\n    >>> st.data_editor(\n    >>>     data_df,\n    >>>     column_config={\n    >>>         \"favorite\": st.column_config.CheckboxColumn(\n    >>>             \"Your favorite?\",\n    >>>             help=\"Select your **favorite** widgets\",\n    >>>             default=False,\n    >>>         )\n    >>>     },\n    >>>     disabled=[\"widgets\"],\n    >>>     hide_index=True,\n    >>> )\n\n    .. output::\n        https://doc-checkbox-column.streamlit.app/\n        height: 300px\n    \"\"\"\n\n    return ColumnConfig(\n        label=label,\n        width=width,\n        help=help,\n        disabled=disabled,\n        required=required,\n        default=default,\n        type_config=CheckboxColumnConfig(type=\"checkbox\"),\n    )\n\n\n@gather_metrics(\"column_config.SelectboxColumn\")\ndef SelectboxColumn(\n    label: str | None = None,\n    *,\n    width: ColumnWidth | None = None,\n    help: str | None = None,\n    disabled: bool | None = None,\n    required: bool | None = None,\n    default: str | int | float | None = None,\n    options: Iterable[str | int | float] | None = None,\n) -> ColumnConfig:\n    \"\"\"Configure a selectbox column in ``st.dataframe`` or ``st.data_editor``.\n\n    This is the default column type for Pandas categorical values. This command needs to\n    be used in the ``column_config`` parameter of ``st.dataframe`` or ``st.data_editor``.\n    When used with ``st.data_editor``, editing will be enabled with a selectbox widget.\n\n    Parameters\n    ----------\n\n    label: str or None\n        The label shown at the top of the column. If None (default),\n        the column name is used.\n\n    width: \"small\", \"medium\", \"large\", or None\n        The display width of the column. Can be one of \"small\", \"medium\", or \"large\".\n        If None (default), the column will be sized to fit the cell contents.\n\n    help: str or None\n        An optional tooltip that gets displayed when hovering over the column label.\n\n    disabled: bool or None\n        Whether editing should be disabled for this column. Defaults to False.\n\n    required: bool or None\n        Whether edited cells in the column need to have a value. If True, an edited cell\n        can only be submitted if it has a value other than None. Defaults to False.\n\n    default: str, int, float, bool, or None\n        Specifies the default value in this column when a new row is added by the user.\n\n    options: Iterable of str or None\n        The options that can be selected during editing. If None (default), this will be\n        inferred from the underlying dataframe column if its dtype is \"category\"\n        (`see Pandas docs on categorical data <https://pandas.pydata.org/docs/user_guide/categorical.html>`_).\n\n    Examples\n    --------\n\n    >>> import pandas as pd\n    >>> import streamlit as st\n    >>>\n    >>> data_df = pd.DataFrame(\n    >>>     {\n    >>>         \"category\": [\n    >>>             \"\ud83d\udcca Data Exploration\",\n    >>>             \"\ud83d\udcc8 Data Visualization\",\n    >>>             \"\ud83e\udd16 LLM\",\n    >>>             \"\ud83d\udcca Data Exploration\",\n    >>>         ],\n    >>>     }\n    >>> )\n    >>>\n    >>> st.data_editor(\n    >>>     data_df,\n    >>>     column_config={\n    >>>         \"category\": st.column_config.SelectboxColumn(\n    >>>             \"App Category\",\n    >>>             help=\"The category of the app\",\n    >>>             width=\"medium\",\n    >>>             options=[\n    >>>                 \"\ud83d\udcca Data Exploration\",\n    >>>                 \"\ud83d\udcc8 Data Visualization\",\n    >>>                 \"\ud83e\udd16 LLM\",\n    >>>             ],\n    >>>             required=True,\n    >>>         )\n    >>>     },\n    >>>     hide_index=True,\n    >>> )\n\n    .. output::\n        https://doc-selectbox-column.streamlit.app/\n        height: 300px\n    \"\"\"\n\n    return ColumnConfig(\n        label=label,\n        width=width,\n        help=help,\n        disabled=disabled,\n        required=required,\n        default=default,\n        type_config=SelectboxColumnConfig(\n            type=\"selectbox\", options=list(options) if options is not None else None\n        ),\n    )\n\n\n@gather_metrics(\"column_config.BarChartColumn\")\ndef BarChartColumn(\n    label: str | None = None,\n    *,\n    width: ColumnWidth | None = None,\n    help: str | None = None,\n    y_min: int | float | None = None,\n    y_max: int | float | None = None,\n) -> ColumnConfig:\n    \"\"\"Configure a bar chart column in ``st.dataframe`` or ``st.data_editor``.\n\n    Cells need to contain a list of numbers. Chart columns are not editable\n    at the moment. This command needs to be used in the ``column_config`` parameter\n    of ``st.dataframe`` or ``st.data_editor``.\n\n    Parameters\n    ----------\n\n    label: str or None\n        The label shown at the top of the column. If None (default),\n        the column name is used.\n\n    width: \"small\", \"medium\", \"large\", or None\n        The display width of the column. Can be one of \"small\", \"medium\", or \"large\".\n        If None (default), the column will be sized to fit the cell contents.\n\n    help: str or None\n        An optional tooltip that gets displayed when hovering over the column label.\n\n    y_min: int, float, or None\n        The minimum value on the y-axis for all cells in the column.\n        If None (default), every cell will use the minimum of its data.\n\n    y_max: int, float, or None\n        The maximum value on the y-axis for all cells in the column. If None (default),\n        every cell will use the maximum of its data.\n\n    Examples\n    --------\n\n    >>> import pandas as pd\n    >>> import streamlit as st\n    >>>\n    >>> data_df = pd.DataFrame(\n    >>>     {\n    >>>         \"sales\": [\n    >>>             [0, 4, 26, 80, 100, 40],\n    >>>             [80, 20, 80, 35, 40, 100],\n    >>>             [10, 20, 80, 80, 70, 0],\n    >>>             [10, 100, 20, 100, 30, 100],\n    >>>         ],\n    >>>     }\n    >>> )\n    >>>\n    >>> st.data_editor(\n    >>>     data_df,\n    >>>     column_config={\n    >>>         \"sales\": st.column_config.BarChartColumn(\n    >>>             \"Sales (last 6 months)\",\n    >>>             help=\"The sales volume in the last 6 months\",\n    >>>             y_min=0,\n    >>>             y_max=100,\n    >>>         ),\n    >>>     },\n    >>>     hide_index=True,\n    >>> )\n\n    .. output::\n        https://doc-barchart-column.streamlit.app/\n        height: 300px\n    \"\"\"\n\n    return ColumnConfig(\n        label=label,\n        width=width,\n        help=help,\n        type_config=BarChartColumnConfig(type=\"bar_chart\", y_min=y_min, y_max=y_max),\n    )\n\n\n@gather_metrics(\"column_config.LineChartColumn\")\ndef LineChartColumn(\n    label: str | None = None,\n    *,\n    width: ColumnWidth | None = None,\n    help: str | None = None,\n    y_min: int | float | None = None,\n    y_max: int | float | None = None,\n) -> ColumnConfig:\n    \"\"\"Configure a line chart column in ``st.dataframe`` or ``st.data_editor``.\n\n    Cells need to contain a list of numbers. Chart columns are not editable\n    at the moment. This command needs to be used in the ``column_config`` parameter\n    of ``st.dataframe`` or ``st.data_editor``.\n\n    Parameters\n    ----------\n\n    label: str or None\n        The label shown at the top of the column. If None (default),\n        the column name is used.\n\n    width: \"small\", \"medium\", \"large\", or None\n        The display width of the column. Can be one of \"small\", \"medium\", or \"large\".\n        If None (default), the column will be sized to fit the cell contents.\n\n    help: str or None\n        An optional tooltip that gets displayed when hovering over the column label.\n\n    y_min: int, float, or None\n        The minimum value on the y-axis for all cells in the column.\n        If None (default), every cell will use the minimum of its data.\n\n    y_max: int, float, or None\n        The maximum value on the y-axis for all cells in the column. If None (default),\n        every cell will use the maximum of its data.\n\n    Examples\n    --------\n\n    >>> import pandas as pd\n    >>> import streamlit as st\n    >>>\n    >>> data_df = pd.DataFrame(\n    >>>     {\n    >>>         \"sales\": [\n    >>>             [0, 4, 26, 80, 100, 40],\n    >>>             [80, 20, 80, 35, 40, 100],\n    >>>             [10, 20, 80, 80, 70, 0],\n    >>>             [10, 100, 20, 100, 30, 100],\n    >>>         ],\n    >>>     }\n    >>> )\n    >>>\n    >>> st.data_editor(\n    >>>     data_df,\n    >>>     column_config={\n    >>>         \"sales\": st.column_config.LineChartColumn(\n    >>>             \"Sales (last 6 months)\",\n    >>>             width=\"medium\",\n    >>>             help=\"The sales volume in the last 6 months\",\n    >>>             y_min=0,\n    >>>             y_max=100,\n    >>>          ),\n    >>>     },\n    >>>     hide_index=True,\n    >>> )\n\n    .. output::\n        https://doc-linechart-column.streamlit.app/\n        height: 300px\n    \"\"\"\n\n    return ColumnConfig(\n        label=label,\n        width=width,\n        help=help,\n        type_config=LineChartColumnConfig(type=\"line_chart\", y_min=y_min, y_max=y_max),\n    )\n\n\n@gather_metrics(\"column_config.AreaChartColumn\")\ndef AreaChartColumn(\n    label: str | None = None,\n    *,\n    width: ColumnWidth | None = None,\n    help: str | None = None,\n    y_min: int | float | None = None,\n    y_max: int | float | None = None,\n) -> ColumnConfig:\n    \"\"\"Configure an area chart column in ``st.dataframe`` or ``st.data_editor``.\n\n    Cells need to contain a list of numbers. Chart columns are not editable\n    at the moment. This command needs to be used in the ``column_config`` parameter\n    of ``st.dataframe`` or ``st.data_editor``.\n\n    Parameters\n    ----------\n\n    label: str or None\n        The label shown at the top of the column. If None (default),\n        the column name is used.\n\n    width: \"small\", \"medium\", \"large\", or None\n        The display width of the column. Can be one of \"small\", \"medium\", or \"large\".\n        If None (default), the column will be sized to fit the cell contents.\n\n    help: str or None\n        An optional tooltip that gets displayed when hovering over the column label.\n\n    y_min: int, float, or None\n        The minimum value on the y-axis for all cells in the column.\n        If None (default), every cell will use the minimum of its data.\n\n    y_max: int, float, or None\n        The maximum value on the y-axis for all cells in the column. If None (default),\n        every cell will use the maximum of its data.\n\n    Examples\n    --------\n\n    >>> import pandas as pd\n    >>> import streamlit as st\n    >>>\n    >>> data_df = pd.DataFrame(\n    >>>     {\n    >>>         \"sales\": [\n    >>>             [0, 4, 26, 80, 100, 40],\n    >>>             [80, 20, 80, 35, 40, 100],\n    >>>             [10, 20, 80, 80, 70, 0],\n    >>>             [10, 100, 20, 100, 30, 100],\n    >>>         ],\n    >>>     }\n    >>> )\n    >>>\n    >>> st.data_editor(\n    >>>     data_df,\n    >>>     column_config={\n    >>>         \"sales\": st.column_config.AreaChartColumn(\n    >>>             \"Sales (last 6 months)\",\n    >>>             width=\"medium\",\n    >>>             help=\"The sales volume in the last 6 months\",\n    >>>             y_min=0,\n    >>>             y_max=100,\n    >>>          ),\n    >>>     },\n    >>>     hide_index=True,\n    >>> )\n\n    .. output::\n        https://doc-areachart-column.streamlit.app/\n        height: 300px\n    \"\"\"\n\n    return ColumnConfig(\n        label=label,\n        width=width,\n        help=help,\n        type_config=AreaChartColumnConfig(type=\"area_chart\", y_min=y_min, y_max=y_max),\n    )\n\n\n@gather_metrics(\"column_config.ImageColumn\")\ndef ImageColumn(\n    label: str | None = None,\n    *,\n    width: ColumnWidth | None = None,\n    help: str | None = None,\n):\n    \"\"\"Configure an image column in ``st.dataframe`` or ``st.data_editor``.\n\n    The cell values need to be one of:\n\n    * A URL to fetch the image from. This can also be a relative URL of an image\n      deployed via `static file serving <https://docs.streamlit.io/develop/concepts/configuration/serving-static-files>`_.\n      Note that you can NOT use an arbitrary local image if it is not available through\n      a public URL.\n    * A data URL containing an SVG XML like ``data:image/svg+xml;utf8,<svg xmlns=...</svg>``.\n    * A data URL containing a Base64 encoded image like ``data:image/png;base64,iVBO...``.\n\n    Image columns are not editable at the moment. This command needs to be used in the\n    ``column_config`` parameter of ``st.dataframe`` or ``st.data_editor``.\n\n    Parameters\n    ----------\n\n    label: str or None\n        The label shown at the top of the column. If None (default),\n        the column name is used.\n\n    width: \"small\", \"medium\", \"large\", or None\n        The display width of the column. Can be one of \"small\", \"medium\", or \"large\".\n        If None (default), the column will be sized to fit the cell contents.\n\n    help: str or None\n        An optional tooltip that gets displayed when hovering over the column label.\n\n    Examples\n    --------\n\n    >>> import pandas as pd\n    >>> import streamlit as st\n    >>>\n    >>> data_df = pd.DataFrame(\n    >>>     {\n    >>>         \"apps\": [\n    >>>             \"https://storage.googleapis.com/s4a-prod-share-preview/default/st_app_screenshot_image/5435b8cb-6c6c-490b-9608-799b543655d3/Home_Page.png\",\n    >>>             \"https://storage.googleapis.com/s4a-prod-share-preview/default/st_app_screenshot_image/ef9a7627-13f2-47e5-8f65-3f69bb38a5c2/Home_Page.png\",\n    >>>             \"https://storage.googleapis.com/s4a-prod-share-preview/default/st_app_screenshot_image/31b99099-8eae-4ff8-aa89-042895ed3843/Home_Page.png\",\n    >>>             \"https://storage.googleapis.com/s4a-prod-share-preview/default/st_app_screenshot_image/6a399b09-241e-4ae7-a31f-7640dc1d181e/Home_Page.png\",\n    >>>         ],\n    >>>     }\n    >>> )\n    >>>\n    >>> st.data_editor(\n    >>>     data_df,\n    >>>     column_config={\n    >>>         \"apps\": st.column_config.ImageColumn(\n    >>>             \"Preview Image\", help=\"Streamlit app preview screenshots\"\n    >>>         )\n    >>>     },\n    >>>     hide_index=True,\n    >>> )\n\n    .. output::\n        https://doc-image-column.streamlit.app/\n        height: 300px\n    \"\"\"\n    return ColumnConfig(\n        label=label, width=width, help=help, type_config=ImageColumnConfig(type=\"image\")\n    )\n\n\n@gather_metrics(\"column_config.ListColumn\")\ndef ListColumn(\n    label: str | None = None,\n    *,\n    width: ColumnWidth | None = None,\n    help: str | None = None,\n):\n    \"\"\"Configure a list column in ``st.dataframe`` or ``st.data_editor``.\n\n    This is the default column type for list-like values. List columns are not editable\n    at the moment. This command needs to be used in the ``column_config`` parameter of\n    ``st.dataframe`` or ``st.data_editor``.\n\n    Parameters\n    ----------\n\n    label: str or None\n        The label shown at the top of the column. If None (default),\n        the column name is used.\n\n    width: \"small\", \"medium\", \"large\", or None\n        The display width of the column. Can be one of \"small\", \"medium\", or \"large\".\n        If None (default), the column will be sized to fit the cell contents.\n\n    help: str or None\n        An optional tooltip that gets displayed when hovering over the column label.\n\n    Examples\n    --------\n\n    >>> import pandas as pd\n    >>> import streamlit as st\n    >>>\n    >>> data_df = pd.DataFrame(\n    >>>     {\n    >>>         \"sales\": [\n    >>>             [0, 4, 26, 80, 100, 40],\n    >>>             [80, 20, 80, 35, 40, 100],\n    >>>             [10, 20, 80, 80, 70, 0],\n    >>>             [10, 100, 20, 100, 30, 100],\n    >>>         ],\n    >>>     }\n    >>> )\n    >>>\n    >>> st.data_editor(\n    >>>     data_df,\n    >>>     column_config={\n    >>>         \"sales\": st.column_config.ListColumn(\n    >>>             \"Sales (last 6 months)\",\n    >>>             help=\"The sales volume in the last 6 months\",\n    >>>             width=\"medium\",\n    >>>         ),\n    >>>     },\n    >>>     hide_index=True,\n    >>> )\n\n    .. output::\n        https://doc-list-column.streamlit.app/\n        height: 300px\n    \"\"\"\n    return ColumnConfig(\n        label=label, width=width, help=help, type_config=ListColumnConfig(type=\"list\")\n    )\n\n\n@gather_metrics(\"column_config.DatetimeColumn\")\ndef DatetimeColumn(\n    label: str | None = None,\n    *,\n    width: ColumnWidth | None = None,\n    help: str | None = None,\n    disabled: bool | None = None,\n    required: bool | None = None,\n    default: datetime.datetime | None = None,\n    format: str | None = None,\n    min_value: datetime.datetime | None = None,\n    max_value: datetime.datetime | None = None,\n    step: int | float | datetime.timedelta | None = None,\n    timezone: str | None = None,\n) -> ColumnConfig:\n    \"\"\"Configure a datetime column in ``st.dataframe`` or ``st.data_editor``.\n\n    This is the default column type for datetime values. This command needs to be\n    used in the ``column_config`` parameter of ``st.dataframe`` or\n    ``st.data_editor``. When used with ``st.data_editor``, editing will be enabled\n    with a datetime picker widget.\n\n    Parameters\n    ----------\n\n    label: str or None\n        The label shown at the top of the column. If None (default),\n        the column name is used.\n\n    width: \"small\", \"medium\", \"large\", or None\n        The display width of the column. Can be one of \"small\", \"medium\", or \"large\".\n        If None (default), the column will be sized to fit the cell contents.\n\n    help: str or None\n        An optional tooltip that gets displayed when hovering over the column label.\n\n    disabled: bool or None\n        Whether editing should be disabled for this column. Defaults to False.\n\n    required: bool or None\n        Whether edited cells in the column need to have a value. If True, an edited cell\n        can only be submitted if it has a value other than None. Defaults to False.\n\n    default: datetime.datetime or None\n        Specifies the default value in this column when a new row is added by the user.\n\n    format: str or None\n        A momentJS format string controlling how datetimes are displayed. See\n        `momentJS docs <https://momentjs.com/docs/#/displaying/format/>`_ for available\n        formats. If None (default), uses ``YYYY-MM-DD HH:mm:ss``.\n\n    min_value: datetime.datetime or None\n        The minimum datetime that can be entered.\n        If None (default), there will be no minimum.\n\n    max_value: datetime.datetime or None\n        The maximum datetime that can be entered.\n        If None (default), there will be no maximum.\n\n    step: int, float, datetime.timedelta, or None\n        The stepping interval in seconds. If None (default), the step will be 1 second.\n\n    timezone: str or None\n        The timezone of this column. If None (default),\n        the timezone is inferred from the underlying data.\n\n    Examples\n    --------\n\n    >>> from datetime import datetime\n    >>> import pandas as pd\n    >>> import streamlit as st\n    >>>\n    >>> data_df = pd.DataFrame(\n    >>>     {\n    >>>         \"appointment\": [\n    >>>             datetime(2024, 2, 5, 12, 30),\n    >>>             datetime(2023, 11, 10, 18, 0),\n    >>>             datetime(2024, 3, 11, 20, 10),\n    >>>             datetime(2023, 9, 12, 3, 0),\n    >>>         ]\n    >>>     }\n    >>> )\n    >>>\n    >>> st.data_editor(\n    >>>     data_df,\n    >>>     column_config={\n    >>>         \"appointment\": st.column_config.DatetimeColumn(\n    >>>             \"Appointment\",\n    >>>             min_value=datetime(2023, 6, 1),\n    >>>             max_value=datetime(2025, 1, 1),\n    >>>             format=\"D MMM YYYY, h:mm a\",\n    >>>             step=60,\n    >>>         ),\n    >>>     },\n    >>>     hide_index=True,\n    >>> )\n\n    .. output::\n        https://doc-datetime-column.streamlit.app/\n        height: 300px\n    \"\"\"\n\n    return ColumnConfig(\n        label=label,\n        width=width,\n        help=help,\n        disabled=disabled,\n        required=required,\n        default=None if default is None else default.isoformat(),\n        type_config=DatetimeColumnConfig(\n            type=\"datetime\",\n            format=format,\n            min_value=None if min_value is None else min_value.isoformat(),\n            max_value=None if max_value is None else max_value.isoformat(),\n            step=step.total_seconds() if isinstance(step, datetime.timedelta) else step,\n            timezone=timezone,\n        ),\n    )\n\n\n@gather_metrics(\"column_config.TimeColumn\")\ndef TimeColumn(\n    label: str | None = None,\n    *,\n    width: ColumnWidth | None = None,\n    help: str | None = None,\n    disabled: bool | None = None,\n    required: bool | None = None,\n    default: datetime.time | None = None,\n    format: str | None = None,\n    min_value: datetime.time | None = None,\n    max_value: datetime.time | None = None,\n    step: int | float | datetime.timedelta | None = None,\n) -> ColumnConfig:\n    \"\"\"Configure a time column in ``st.dataframe`` or ``st.data_editor``.\n\n    This is the default column type for time values. This command needs to be used in\n    the ``column_config`` parameter of ``st.dataframe`` or ``st.data_editor``. When\n    used with ``st.data_editor``, editing will be enabled with a time picker widget.\n\n    Parameters\n    ----------\n\n    label: str or None\n        The label shown at the top of the column. If None (default),\n        the column name is used.\n\n    width: \"small\", \"medium\", \"large\", or None\n        The display width of the column. Can be one of \"small\", \"medium\", or \"large\".\n        If None (default), the column will be sized to fit the cell contents.\n\n    help: str or None\n        An optional tooltip that gets displayed when hovering over the column label.\n\n    disabled: bool or None\n        Whether editing should be disabled for this column. Defaults to False.\n\n    required: bool or None\n        Whether edited cells in the column need to have a value. If True, an edited cell\n        can only be submitted if it has a value other than None. Defaults to False.\n\n    default: datetime.time or None\n        Specifies the default value in this column when a new row is added by the user.\n\n    format: str or None\n        A momentJS format string controlling how times are displayed. See\n        `momentJS docs <https://momentjs.com/docs/#/displaying/format/>`_ for available\n        formats. If None (default), uses ``HH:mm:ss``.\n\n    min_value: datetime.time or None\n        The minimum time that can be entered.\n        If None (default), there will be no minimum.\n\n    max_value: datetime.time or None\n        The maximum time that can be entered.\n        If None (default), there will be no maximum.\n\n    step: int, float, datetime.timedelta, or None\n        The stepping interval in seconds. If None (default), the step will be 1 second.\n\n    Examples\n    --------\n\n    >>> from datetime import time\n    >>> import pandas as pd\n    >>> import streamlit as st\n    >>>\n    >>> data_df = pd.DataFrame(\n    >>>     {\n    >>>         \"appointment\": [\n    >>>             time(12, 30),\n    >>>             time(18, 0),\n    >>>             time(9, 10),\n    >>>             time(16, 25),\n    >>>         ]\n    >>>     }\n    >>> )\n    >>>\n    >>> st.data_editor(\n    >>>     data_df,\n    >>>     column_config={\n    >>>         \"appointment\": st.column_config.TimeColumn(\n    >>>             \"Appointment\",\n    >>>             min_value=time(8, 0, 0),\n    >>>             max_value=time(19, 0, 0),\n    >>>             format=\"hh:mm a\",\n    >>>             step=60,\n    >>>         ),\n    >>>     },\n    >>>     hide_index=True,\n    >>> )\n\n    .. output::\n        https://doc-time-column.streamlit.app/\n        height: 300px\n    \"\"\"\n\n    return ColumnConfig(\n        label=label,\n        width=width,\n        help=help,\n        disabled=disabled,\n        required=required,\n        default=None if default is None else default.isoformat(),\n        type_config=TimeColumnConfig(\n            type=\"time\",\n            format=format,\n            min_value=None if min_value is None else min_value.isoformat(),\n            max_value=None if max_value is None else max_value.isoformat(),\n            step=step.total_seconds() if isinstance(step, datetime.timedelta) else step,\n        ),\n    )\n\n\n@gather_metrics(\"column_config.DateColumn\")\ndef DateColumn(\n    label: str | None = None,\n    *,\n    width: ColumnWidth | None = None,\n    help: str | None = None,\n    disabled: bool | None = None,\n    required: bool | None = None,\n    default: datetime.date | None = None,\n    format: str | None = None,\n    min_value: datetime.date | None = None,\n    max_value: datetime.date | None = None,\n    step: int | None = None,\n) -> ColumnConfig:\n    \"\"\"Configure a date column in ``st.dataframe`` or ``st.data_editor``.\n\n    This is the default column type for date values. This command needs to be used in\n    the ``column_config`` parameter of ``st.dataframe`` or ``st.data_editor``. When used\n    with ``st.data_editor``, editing will be enabled with a date picker widget.\n\n    Parameters\n    ----------\n\n    label: str or None\n        The label shown at the top of the column. If None (default),\n        the column name is used.\n\n    width: \"small\", \"medium\", \"large\", or None\n        The display width of the column. Can be one of \"small\", \"medium\", or \"large\".\n        If None (default), the column will be sized to fit the cell contents.\n\n    help: str or None\n        An optional tooltip that gets displayed when hovering over the column label.\n\n    disabled: bool or None\n        Whether editing should be disabled for this column. Defaults to False.\n\n    required: bool or None\n        Whether edited cells in the column need to have a value. If True, an edited cell\n        can only be submitted if it has a value other than None. Defaults to False.\n\n    default: datetime.date or None\n        Specifies the default value in this column when a new row is added by the user.\n\n    format: str or None\n        A momentJS format string controlling how times are displayed. See\n        `momentJS docs <https://momentjs.com/docs/#/displaying/format/>`_ for available\n        formats. If None (default), uses ``YYYY-MM-DD``.\n\n    min_value: datetime.date or None\n        The minimum date that can be entered.\n        If None (default), there will be no minimum.\n\n    max_value: datetime.date or None\n        The maximum date that can be entered.\n        If None (default), there will be no maximum.\n\n    step: int or None\n        The stepping interval in days. If None (default), the step will be 1 day.\n\n    Examples\n    --------\n\n    >>> from datetime import date\n    >>> import pandas as pd\n    >>> import streamlit as st\n    >>>\n    >>> data_df = pd.DataFrame(\n    >>>     {\n    >>>         \"birthday\": [\n    >>>             date(1980, 1, 1),\n    >>>             date(1990, 5, 3),\n    >>>             date(1974, 5, 19),\n    >>>             date(2001, 8, 17),\n    >>>         ]\n    >>>     }\n    >>> )\n    >>>\n    >>> st.data_editor(\n    >>>     data_df,\n    >>>     column_config={\n    >>>         \"birthday\": st.column_config.DateColumn(\n    >>>             \"Birthday\",\n    >>>             min_value=date(1900, 1, 1),\n    >>>             max_value=date(2005, 1, 1),\n    >>>             format=\"DD.MM.YYYY\",\n    >>>             step=1,\n    >>>         ),\n    >>>     },\n    >>>     hide_index=True,\n    >>> )\n\n    .. output::\n        https://doc-date-column.streamlit.app/\n        height: 300px\n    \"\"\"\n    return ColumnConfig(\n        label=label,\n        width=width,\n        help=help,\n        disabled=disabled,\n        required=required,\n        default=None if default is None else default.isoformat(),\n        type_config=DateColumnConfig(\n            type=\"date\",\n            format=format,\n            min_value=None if min_value is None else min_value.isoformat(),\n            max_value=None if max_value is None else max_value.isoformat(),\n            step=step,\n        ),\n    )\n\n\n@gather_metrics(\"column_config.ProgressColumn\")\ndef ProgressColumn(\n    label: str | None = None,\n    *,\n    width: ColumnWidth | None = None,\n    help: str | None = None,\n    format: str | None = None,\n    min_value: int | float | None = None,\n    max_value: int | float | None = None,\n) -> ColumnConfig:\n    \"\"\"Configure a progress column in ``st.dataframe`` or ``st.data_editor``.\n\n    Cells need to contain a number. Progress columns are not editable at the moment.\n    This command needs to be used in the ``column_config`` parameter of ``st.dataframe``\n    or ``st.data_editor``.\n\n    Parameters\n    ----------\n\n    label : str or None\n        The label shown at the top of the column. If None (default),\n        the column name is used.\n\n    width : \"small\", \"medium\", \"large\", or None\n        The display width of the column. Can be one of \"small\", \"medium\", or \"large\".\n        If None (default), the column will be sized to fit the cell contents.\n\n    help : str or None\n        An optional tooltip that gets displayed when hovering over the column label.\n\n    format : str or None\n        A printf-style format string controlling how numbers are displayed.\n        Valid formatters: %d %e %f %g %i %u. You can also add prefixes and suffixes,\n        e.g. ``\"$ %.2f\"`` to show a dollar prefix.\n\n    min_value : int, float, or None\n        The minimum value of the progress bar.\n        If None (default), will be 0.\n\n    max_value : int, float, or None\n        The minimum value of the progress bar. If None (default), will be 100 for\n        integer values and 1 for float values.\n\n    Examples\n    --------\n\n    >>> import pandas as pd\n    >>> import streamlit as st\n    >>>\n    >>> data_df = pd.DataFrame(\n    >>>     {\n    >>>         \"sales\": [200, 550, 1000, 80],\n    >>>     }\n    >>> )\n    >>>\n    >>> st.data_editor(\n    >>>     data_df,\n    >>>     column_config={\n    >>>         \"sales\": st.column_config.ProgressColumn(\n    >>>             \"Sales volume\",\n    >>>             help=\"The sales volume in USD\",\n    >>>             format=\"$%f\",\n    >>>             min_value=0,\n    >>>             max_value=1000,\n    >>>         ),\n    >>>     },\n    >>>     hide_index=True,\n    >>> )\n\n    .. output::\n        https://doc-progress-column.streamlit.app/\n        height: 300px\n    \"\"\"\n\n    return ColumnConfig(\n        label=label,\n        width=width,\n        help=help,\n        type_config=ProgressColumnConfig(\n            type=\"progress\",\n            format=format,\n            min_value=min_value,\n            max_value=max_value,\n        ),\n    )\n", "lib/streamlit/elements/lib/built_in_chart_utils.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Utilities for our built-in charts commands.\"\"\"\n\nfrom __future__ import annotations\n\nfrom dataclasses import dataclass\nfrom datetime import date\nfrom enum import Enum\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    Collection,\n    Final,\n    Hashable,\n    Sequence,\n    TypedDict,\n    cast,\n)\n\nfrom streamlit import type_util\nfrom streamlit.color_util import (\n    Color,\n    is_color_like,\n    is_color_tuple_like,\n    is_hex_color_like,\n    to_css_color,\n)\nfrom streamlit.errors import Error, StreamlitAPIException\n\nif TYPE_CHECKING:\n    import altair as alt\n    import pandas as pd\n\n    from streamlit.elements.arrow import Data\n    from streamlit.type_util import DataFrameCompatible\n\n\nclass PrepDataColumns(TypedDict):\n    \"\"\"Columns used for the prep_data step in Altair Arrow charts.\"\"\"\n\n    x_column: str | None\n    y_column_list: list[str]\n    color_column: str | None\n    size_column: str | None\n\n\n@dataclass\nclass AddRowsMetadata:\n    \"\"\"Metadata needed by add_rows on native charts.\n\n    This class is used to pass some important info to add_rows.\n    \"\"\"\n\n    chart_command: str\n    last_index: Hashable | None\n    columns: PrepDataColumns\n\n\nclass ChartType(Enum):\n    AREA = {\"mark_type\": \"area\", \"command\": \"area_chart\"}\n    VERTICAL_BAR = {\"mark_type\": \"bar\", \"command\": \"bar_chart\", \"horizontal\": False}\n    HORIZONTAL_BAR = {\"mark_type\": \"bar\", \"command\": \"bar_chart\", \"horizontal\": True}\n    LINE = {\"mark_type\": \"line\", \"command\": \"line_chart\"}\n    SCATTER = {\"mark_type\": \"circle\", \"command\": \"scatter_chart\"}\n\n\n# Color and size legends need different title paddings in order for them\n# to be vertically aligned.\n#\n# NOTE: I don't think it's possible to *perfectly* align the size and\n# color legends in all instances, since the \"size\" circles vary in size based\n# on the data, and their container is top-aligned with the color container. But\n# through trial-and-error I found this value to be a good enough middle ground.\n# See e2e/scripts/st_arrow_scatter_chart.py for some alignment tests.\n#\n# NOTE #2: In theory, we could move COLOR_LEGEND_SETTINGS into\n# ArrowVegaLiteChart/CustomTheme.tsx, but this would impact existing behavior.\n# (See https://github.com/streamlit/streamlit/pull/7164#discussion_r1307707345)\n_COLOR_LEGEND_SETTINGS: Final = {\"titlePadding\": 5, \"offset\": 5, \"orient\": \"bottom\"}\n_SIZE_LEGEND_SETTINGS: Final = {\"titlePadding\": 0.5, \"offset\": 5, \"orient\": \"bottom\"}\n\n# User-readable names to give the index and melted columns.\n_SEPARATED_INDEX_COLUMN_TITLE: Final = \"index\"\n_MELTED_Y_COLUMN_TITLE: Final = \"value\"\n_MELTED_COLOR_COLUMN_TITLE: Final = \"color\"\n\n# Crazy internal (non-user-visible) names for the index and melted columns, in order to\n# avoid collision with existing column names. The suffix below was generated with an\n# online random number generator. Rationale: because it makes it even less likely to\n# lead to a conflict than something that's human-readable (like \"--streamlit-fake-field\"\n# or something).\n_PROTECTION_SUFFIX: Final = \"--p5bJXXpQgvPz6yvQMFiy\"\n_SEPARATED_INDEX_COLUMN_NAME: Final = _SEPARATED_INDEX_COLUMN_TITLE + _PROTECTION_SUFFIX\n_MELTED_Y_COLUMN_NAME: Final = _MELTED_Y_COLUMN_TITLE + _PROTECTION_SUFFIX\n_MELTED_COLOR_COLUMN_NAME: Final = _MELTED_COLOR_COLUMN_TITLE + _PROTECTION_SUFFIX\n\n# Name we use for a column we know doesn't exist in the data, to address a Vega-Lite rendering bug\n# where empty charts need x, y encodings set in order to take up space.\n_NON_EXISTENT_COLUMN_NAME: Final = \"DOES_NOT_EXIST\" + _PROTECTION_SUFFIX\n\n\ndef generate_chart(\n    chart_type: ChartType,\n    data: Data | None,\n    x_from_user: str | None = None,\n    y_from_user: str | Sequence[str] | None = None,\n    x_axis_label: str | None = None,\n    y_axis_label: str | None = None,\n    color_from_user: str | Color | list[Color] | None = None,\n    size_from_user: str | float | None = None,\n    width: int | None = None,\n    height: int | None = None,\n) -> tuple[alt.Chart, AddRowsMetadata]:\n    \"\"\"Function to use the chart's type, data columns and indices to figure out the chart's spec.\"\"\"\n    import altair as alt\n\n    df = type_util.convert_anything_to_df(data, ensure_copy=True)\n\n    # From now on, use \"df\" instead of \"data\". Deleting \"data\" to guarantee we follow this.\n    del data\n\n    # Convert arguments received from the user to things Vega-Lite understands.\n    # Get name of column to use for x.\n    x_column = _parse_x_column(df, x_from_user)\n    # Get name of columns to use for y.\n    y_column_list = _parse_y_columns(df, y_from_user, x_column)\n    # Get name of column to use for color, or constant value to use. Any/both could be None.\n    color_column, color_value = _parse_generic_column(df, color_from_user)\n    # Get name of column to use for size, or constant value to use. Any/both could be None.\n    size_column, size_value = _parse_generic_column(df, size_from_user)\n\n    # Store some info so we can use it in add_rows.\n    add_rows_metadata = AddRowsMetadata(\n        # The st command that was used to generate this chart.\n        chart_command=chart_type.value[\"command\"],\n        # The last index of df so we can adjust the input df in add_rows:\n        last_index=_last_index_for_melted_dataframes(df),\n        # This is the input to prep_data (except for the df):\n        columns={\n            \"x_column\": x_column,\n            \"y_column_list\": y_column_list,\n            \"color_column\": color_column,\n            \"size_column\": size_column,\n        },\n    )\n\n    # At this point, all foo_column variables are either None/empty or contain actual\n    # columns that are guaranteed to exist.\n\n    df, x_column, y_column, color_column, size_column = _prep_data(\n        df, x_column, y_column_list, color_column, size_column\n    )\n\n    # At this point, x_column is only None if user did not provide one AND df is empty.\n\n    if chart_type == ChartType.HORIZONTAL_BAR:\n        # Handle horizontal bar chart - switches x and y data:\n        x_encoding = _get_x_encoding(\n            df, y_column, y_from_user, x_axis_label, chart_type\n        )\n        y_encoding = _get_y_encoding(\n            df, x_column, x_from_user, y_axis_label, chart_type\n        )\n    else:\n        x_encoding = _get_x_encoding(\n            df, x_column, x_from_user, x_axis_label, chart_type\n        )\n        y_encoding = _get_y_encoding(\n            df, y_column, y_from_user, y_axis_label, chart_type\n        )\n\n    # Create a Chart with x and y encodings.\n    chart = alt.Chart(\n        data=df,\n        mark=chart_type.value[\"mark_type\"],\n        width=width or 0,\n        height=height or 0,\n    ).encode(\n        x=x_encoding,\n        y=y_encoding,\n    )\n\n    # Set up opacity encoding.\n    opacity_enc = _get_opacity_encoding(chart_type, color_column)\n    if opacity_enc is not None:\n        chart = chart.encode(opacity=opacity_enc)\n\n    # Set up color encoding.\n    color_enc = _get_color_encoding(\n        df, color_value, color_column, y_column_list, color_from_user\n    )\n    if color_enc is not None:\n        chart = chart.encode(color=color_enc)\n\n    # Set up size encoding.\n    size_enc = _get_size_encoding(chart_type, size_column, size_value)\n    if size_enc is not None:\n        chart = chart.encode(size=size_enc)\n\n    # Set up tooltip encoding.\n    if x_column is not None and y_column is not None:\n        chart = chart.encode(\n            tooltip=_get_tooltip_encoding(\n                x_column,\n                y_column,\n                size_column,\n                color_column,\n                color_enc,\n            )\n        )\n\n    return chart.interactive(), add_rows_metadata\n\n\ndef prep_chart_data_for_add_rows(\n    data: Data,\n    add_rows_metadata: AddRowsMetadata,\n) -> tuple[Data, AddRowsMetadata]:\n    \"\"\"Prepares the data for add_rows on our built-in charts.\n\n    This includes aspects like conversion of the data to Pandas DataFrame,\n    changes to the index, and melting the data if needed.\n    \"\"\"\n    import pandas as pd\n\n    df = cast(pd.DataFrame, type_util.convert_anything_to_df(data))\n\n    # Make range indices start at last_index.\n    if isinstance(df.index, pd.RangeIndex):\n        old_step = _get_pandas_index_attr(df, \"step\")\n\n        # We have to drop the predefined index\n        df = df.reset_index(drop=True)\n\n        old_stop = _get_pandas_index_attr(df, \"stop\")\n\n        if old_step is None or old_stop is None:\n            raise StreamlitAPIException(\"'RangeIndex' object has no attribute 'step'\")\n\n        start = add_rows_metadata.last_index + old_step\n        stop = add_rows_metadata.last_index + old_step + old_stop\n\n        df.index = pd.RangeIndex(start=start, stop=stop, step=old_step)\n        add_rows_metadata.last_index = stop - 1\n\n    out_data, *_ = _prep_data(df, **add_rows_metadata.columns)\n\n    return out_data, add_rows_metadata\n\n\ndef _get_pandas_index_attr(\n    data: pd.DataFrame | pd.Series,\n    attr: str,\n) -> Any | None:\n    return getattr(data.index, attr, None)\n\n\ndef _prep_data(\n    df: pd.DataFrame,\n    x_column: str | None,\n    y_column_list: list[str],\n    color_column: str | None,\n    size_column: str | None,\n) -> tuple[pd.DataFrame, str | None, str | None, str | None, str | None]:\n    \"\"\"Prepares the data for charting. This is also used in add_rows.\n\n    Returns the prepared dataframe and the new names of the x column (taking the index reset into\n    consideration) and y, color, and size columns.\n    \"\"\"\n\n    # If y is provided, but x is not, we'll use the index as x.\n    # So we need to pull the index into its own column.\n    x_column = _maybe_reset_index_in_place(df, x_column, y_column_list)\n\n    # Drop columns we're not using.\n    selected_data = _drop_unused_columns(\n        df, x_column, color_column, size_column, *y_column_list\n    )\n\n    # Maybe convert color to Vega colors.\n    _maybe_convert_color_column_in_place(selected_data, color_column)\n\n    # Make sure all columns have string names.\n    (\n        x_column,\n        y_column_list,\n        color_column,\n        size_column,\n    ) = _convert_col_names_to_str_in_place(\n        selected_data, x_column, y_column_list, color_column, size_column\n    )\n\n    # Maybe melt data from wide format into long format.\n    melted_data, y_column, color_column = _maybe_melt(\n        selected_data, x_column, y_column_list, color_column, size_column\n    )\n\n    # Return the data, but also the new names to use for x, y, and color.\n    return melted_data, x_column, y_column, color_column, size_column\n\n\ndef _last_index_for_melted_dataframes(\n    data: DataFrameCompatible | Any,\n) -> Hashable | None:\n    if type_util.is_dataframe_compatible(data):\n        data = type_util.convert_anything_to_df(data)\n\n        if data.index.size > 0:\n            return cast(Hashable, data.index[-1])\n\n    return None\n\n\ndef _is_date_column(df: pd.DataFrame, name: str | None) -> bool:\n    \"\"\"True if the column with the given name stores datetime.date values.\n\n    This function just checks the first value in the given column, so\n    it's meaningful only for columns whose values all share the same type.\n\n    Parameters\n    ----------\n    df : pd.DataFrame\n    name : str\n        The column name\n\n    Returns\n    -------\n    bool\n\n    \"\"\"\n    if name is None:\n        return False\n\n    column = df[name]\n    if column.size == 0:\n        return False\n\n    return isinstance(column.iloc[0], date)\n\n\ndef _melt_data(\n    df: pd.DataFrame,\n    columns_to_leave_alone: list[str],\n    columns_to_melt: list[str] | None,\n    new_y_column_name: str,\n    new_color_column_name: str,\n) -> pd.DataFrame:\n    \"\"\"Converts a wide-format dataframe to a long-format dataframe.\n\n    You can find more info about melting on the Pandas documentation:\n    https://pandas.pydata.org/docs/reference/api/pandas.melt.html\n\n    Parameters\n    ----------\n    df : pd.DataFrame\n        The dataframe to melt.\n    columns_to_leave_alone : list[str]\n        The columns to leave as they are.\n    columns_to_melt : list[str]\n        The columns to melt.\n    new_y_column_name : str\n        The name of the new column that will store the values of the melted columns.\n    new_color_column_name : str\n        The name of column that will store the original column names.\n\n    Returns\n    -------\n    pd.DataFrame\n        The melted dataframe.\n\n\n    Examples\n    --------\n\n    >>> import pandas as pd\n    >>> df = pd.DataFrame({\n    ...     \"a\": [1, 2, 3],\n    ...     \"b\": [4, 5, 6],\n    ...     \"c\": [7, 8, 9],\n    ... })\n    >>> _melt_data(df, [\"a\"], [\"b\", \"c\"], \"value\", \"color\")\n    >>>    a color  value\n    >>> 0  1        b      4\n    >>> 1  2        b      5\n    >>> 2  3        b      6\n    >>> ...\n\n    \"\"\"\n    import pandas as pd\n    from pandas.api.types import infer_dtype\n\n    melted_df = pd.melt(\n        df,\n        id_vars=columns_to_leave_alone,\n        value_vars=columns_to_melt,\n        var_name=new_color_column_name,\n        value_name=new_y_column_name,\n    )\n\n    y_series = melted_df[new_y_column_name]\n    if (\n        y_series.dtype == \"object\"\n        and \"mixed\" in infer_dtype(y_series)\n        and len(y_series.unique()) > 100\n    ):\n        raise StreamlitAPIException(\n            \"The columns used for rendering the chart contain too many values with mixed types. Please select the columns manually via the y parameter.\"\n        )\n\n    # Arrow has problems with object types after melting two different dtypes\n    # pyarrow.lib.ArrowTypeError: \"Expected a <TYPE> object, got a object\"\n    fixed_df = type_util.fix_arrow_incompatible_column_types(\n        melted_df,\n        selected_columns=[\n            *columns_to_leave_alone,\n            new_color_column_name,\n            new_y_column_name,\n        ],\n    )\n\n    return fixed_df\n\n\ndef _maybe_reset_index_in_place(\n    df: pd.DataFrame, x_column: str | None, y_column_list: list[str]\n) -> str | None:\n    if x_column is None and len(y_column_list) > 0:\n        if df.index.name is None:\n            # Pick column name that is unlikely to collide with user-given names.\n            x_column = _SEPARATED_INDEX_COLUMN_NAME\n        else:\n            # Reuse index's name for the new column.\n            x_column = df.index.name\n\n        df.index.name = x_column\n        df.reset_index(inplace=True)\n\n    return x_column\n\n\ndef _drop_unused_columns(df: pd.DataFrame, *column_names: str | None) -> pd.DataFrame:\n    \"\"\"Returns a subset of df, selecting only column_names that aren't None.\"\"\"\n\n    # We can't just call set(col_names) because sets don't have stable ordering,\n    # which means tests that depend on ordering will fail.\n    # Performance-wise, it's not a problem, though, since this function is only ever\n    # used on very small lists.\n    seen = set()\n    keep = []\n\n    for x in column_names:\n        if x is None:\n            continue\n        if x in seen:\n            continue\n        seen.add(x)\n        keep.append(x)\n\n    return df[keep]\n\n\ndef _maybe_convert_color_column_in_place(df: pd.DataFrame, color_column: str | None):\n    \"\"\"If needed, convert color column to a format Vega understands.\"\"\"\n    if color_column is None or len(df[color_column]) == 0:\n        return\n\n    first_color_datum = df[color_column].iat[0]\n\n    if is_hex_color_like(first_color_datum):\n        # Hex is already CSS-valid.\n        pass\n    elif is_color_tuple_like(first_color_datum):\n        # Tuples need to be converted to CSS-valid.\n        df[color_column] = df[color_column].map(to_css_color)\n    else:\n        # Other kinds of colors columns (i.e. pure numbers or nominal strings) shouldn't\n        # be converted since they are treated by Vega-Lite as sequential or categorical colors.\n        pass\n\n\ndef _convert_col_names_to_str_in_place(\n    df: pd.DataFrame,\n    x_column: str | None,\n    y_column_list: list[str],\n    color_column: str | None,\n    size_column: str | None,\n) -> tuple[str | None, list[str], str | None, str | None]:\n    \"\"\"Converts column names to strings, since Vega-Lite does not accept ints, etc.\"\"\"\n    import pandas as pd\n\n    column_names = list(df.columns)  # list() converts RangeIndex, etc, to regular list.\n    str_column_names = [str(c) for c in column_names]\n    df.columns = pd.Index(str_column_names)\n\n    return (\n        None if x_column is None else str(x_column),\n        [str(c) for c in y_column_list],\n        None if color_column is None else str(color_column),\n        None if size_column is None else str(size_column),\n    )\n\n\ndef _parse_generic_column(\n    df: pd.DataFrame, column_or_value: Any\n) -> tuple[str | None, Any]:\n    if isinstance(column_or_value, str) and column_or_value in df.columns:\n        column_name = column_or_value\n        value = None\n    else:\n        column_name = None\n        value = column_or_value\n\n    return column_name, value\n\n\ndef _parse_x_column(df: pd.DataFrame, x_from_user: str | None) -> str | None:\n    if x_from_user is None:\n        return None\n\n    elif isinstance(x_from_user, str):\n        if x_from_user not in df.columns:\n            raise StreamlitColumnNotFoundError(df, x_from_user)\n\n        return x_from_user\n\n    else:\n        raise StreamlitAPIException(\n            \"x parameter should be a column name (str) or None to use the \"\n            f\" dataframe's index. Value given: {x_from_user} \"\n            f\"(type {type(x_from_user)})\"\n        )\n\n\ndef _parse_y_columns(\n    df: pd.DataFrame,\n    y_from_user: str | Sequence[str] | None,\n    x_column: str | None,\n) -> list[str]:\n    y_column_list: list[str] = []\n\n    if y_from_user is None:\n        y_column_list = list(df.columns)\n\n    elif isinstance(y_from_user, str):\n        y_column_list = [y_from_user]\n\n    elif type_util.is_sequence(y_from_user):\n        y_column_list = [str(col) for col in y_from_user]\n\n    else:\n        raise StreamlitAPIException(\n            \"y parameter should be a column name (str) or list thereof. \"\n            f\"Value given: {y_from_user} (type {type(y_from_user)})\"\n        )\n\n    for col in y_column_list:\n        if col not in df.columns:\n            raise StreamlitColumnNotFoundError(df, col)\n\n    # y_column_list should only include x_column when user explicitly asked for it.\n    if x_column in y_column_list and (not y_from_user or x_column not in y_from_user):\n        y_column_list.remove(x_column)\n\n    return y_column_list\n\n\ndef _get_opacity_encoding(\n    chart_type: ChartType, color_column: str | None\n) -> alt.OpacityValue | None:\n    import altair as alt\n\n    if color_column and chart_type == ChartType.AREA:\n        return alt.OpacityValue(0.7)\n\n    return None\n\n\ndef _get_axis_config(df: pd.DataFrame, column_name: str | None, grid: bool) -> alt.Axis:\n    import altair as alt\n    from pandas.api.types import is_integer_dtype\n\n    if column_name is not None and is_integer_dtype(df[column_name]):\n        # Use a max tick size of 1 for integer columns (prevents zoom into float numbers)\n        # and deactivate grid lines for x-axis\n        return alt.Axis(tickMinStep=1, grid=grid)\n\n    return alt.Axis(grid=grid)\n\n\ndef _maybe_melt(\n    df: pd.DataFrame,\n    x_column: str | None,\n    y_column_list: list[str],\n    color_column: str | None,\n    size_column: str | None,\n) -> tuple[pd.DataFrame, str | None, str | None]:\n    \"\"\"If multiple columns are set for y, melt the dataframe into long format.\"\"\"\n    y_column: str | None\n\n    if len(y_column_list) == 0:\n        y_column = None\n    elif len(y_column_list) == 1:\n        y_column = y_column_list[0]\n    elif x_column is not None:\n        # Pick column names that are unlikely to collide with user-given names.\n        y_column = _MELTED_Y_COLUMN_NAME\n        color_column = _MELTED_COLOR_COLUMN_NAME\n\n        columns_to_leave_alone = [x_column]\n        if size_column:\n            columns_to_leave_alone.append(size_column)\n\n        df = _melt_data(\n            df=df,\n            columns_to_leave_alone=columns_to_leave_alone,\n            columns_to_melt=y_column_list,\n            new_y_column_name=y_column,\n            new_color_column_name=color_column,\n        )\n\n    return df, y_column, color_column\n\n\ndef _get_x_encoding(\n    df: pd.DataFrame,\n    x_column: str | None,\n    x_from_user: str | Sequence[str] | None,\n    x_axis_label: str | None,\n    chart_type: ChartType,\n) -> alt.X:\n    import altair as alt\n\n    if x_column is None:\n        # If no field is specified, the full axis disappears when no data is present.\n        # Maybe a bug in vega-lite? So we pass a field that doesn't exist.\n        x_field = _NON_EXISTENT_COLUMN_NAME\n        x_title = \"\"\n    elif x_column == _SEPARATED_INDEX_COLUMN_NAME:\n        # If the x column name is the crazy anti-collision name we gave it, then need to set\n        # up a title so we never show the crazy name to the user.\n        x_field = x_column\n        # Don't show a label in the x axis (not even a nice label like\n        # SEPARATED_INDEX_COLUMN_TITLE) when we pull the x axis from the index.\n        x_title = \"\"\n    else:\n        x_field = x_column\n\n        # Only show a label in the x axis if the user passed a column explicitly. We\n        # could go either way here, but I'm keeping this to avoid breaking the existing\n        # behavior.\n        if x_from_user is None:\n            x_title = \"\"\n        else:\n            x_title = x_column\n\n    # User specified x-axis label takes precedence\n    if x_axis_label is not None:\n        x_title = x_axis_label\n\n    # grid lines on x axis for horizontal bar charts only\n    grid = True if chart_type == ChartType.HORIZONTAL_BAR else False\n\n    return alt.X(\n        x_field,\n        title=x_title,\n        type=_get_x_encoding_type(df, chart_type, x_column),\n        scale=alt.Scale(),\n        axis=_get_axis_config(df, x_column, grid=grid),\n    )\n\n\ndef _get_y_encoding(\n    df: pd.DataFrame,\n    y_column: str | None,\n    y_from_user: str | Sequence[str] | None,\n    y_axis_label: str | None,\n    chart_type: ChartType,\n) -> alt.Y:\n    import altair as alt\n\n    if y_column is None:\n        # If no field is specified, the full axis disappears when no data is present.\n        # Maybe a bug in vega-lite? So we pass a field that doesn't exist.\n        y_field = _NON_EXISTENT_COLUMN_NAME\n        y_title = \"\"\n    elif y_column == _MELTED_Y_COLUMN_NAME:\n        # If the y column name is the crazy anti-collision name we gave it, then need to set\n        # up a title so we never show the crazy name to the user.\n        y_field = y_column\n        # Don't show a label in the y axis (not even a nice label like\n        # MELTED_Y_COLUMN_TITLE) when we pull the x axis from the index.\n        y_title = \"\"\n    else:\n        y_field = y_column\n\n        # Only show a label in the y axis if the user passed a column explicitly. We\n        # could go either way here, but I'm keeping this to avoid breaking the existing\n        # behavior.\n        if y_from_user is None:\n            y_title = \"\"\n        else:\n            y_title = y_column\n\n    # User specified y-axis label takes precedence\n    if y_axis_label is not None:\n        y_title = y_axis_label\n\n    # grid lines on y axis for all charts except horizontal bar charts\n    grid = False if chart_type == ChartType.HORIZONTAL_BAR else True\n\n    return alt.Y(\n        field=y_field,\n        title=y_title,\n        type=_get_y_encoding_type(df, chart_type, y_column),\n        scale=alt.Scale(),\n        axis=_get_axis_config(df, y_column, grid=grid),\n    )\n\n\ndef _get_color_encoding(\n    df: pd.DataFrame,\n    color_value: Color | None,\n    color_column: str | None,\n    y_column_list: list[str],\n    color_from_user: str | Color | list[Color] | None,\n) -> alt.Color | alt.ColorValue | None:\n    import altair as alt\n\n    has_color_value = color_value not in [None, [], ()]  # type: ignore[comparison-overlap]\n\n    # If user passed a color value, that should win over colors coming from the\n    # color column (be they manual or auto-assigned due to melting)\n    if has_color_value:\n        # If the color value is color-like, return that.\n        if is_color_like(cast(Any, color_value)):\n            if len(y_column_list) != 1:\n                raise StreamlitColorLengthError([color_value], y_column_list)\n\n            return alt.ColorValue(to_css_color(cast(Any, color_value)))\n\n        # If the color value is a list of colors of approriate length, return that.\n        elif isinstance(color_value, (list, tuple)):\n            color_values = cast(Collection[Color], color_value)\n\n            if len(color_values) != len(y_column_list):\n                raise StreamlitColorLengthError(color_values, y_column_list)\n\n            if len(color_value) == 1:\n                return alt.ColorValue(to_css_color(cast(Any, color_value[0])))\n            else:\n                return alt.Color(\n                    field=color_column,\n                    scale=alt.Scale(range=[to_css_color(c) for c in color_values]),\n                    legend=_COLOR_LEGEND_SETTINGS,\n                    type=\"nominal\",\n                    title=\" \",\n                )\n\n        raise StreamlitInvalidColorError(df, color_from_user)\n\n    elif color_column is not None:\n        column_type: str | tuple[str, list[Any]]\n\n        if color_column == _MELTED_COLOR_COLUMN_NAME:\n            column_type = \"nominal\"\n        else:\n            column_type = type_util.infer_vegalite_type(df[color_column])\n\n        color_enc = alt.Color(\n            field=color_column, legend=_COLOR_LEGEND_SETTINGS, type=column_type\n        )\n\n        # Fix title if DF was melted\n        if color_column == _MELTED_COLOR_COLUMN_NAME:\n            # This has to contain an empty space, otherwise the\n            # full y-axis disappears (maybe a bug in vega-lite)?\n            color_enc[\"title\"] = \" \"\n\n        # If the 0th element in the color column looks like a color, we'll use the color column's\n        # values as the colors in our chart.\n        elif len(df[color_column]) and is_color_like(df[color_column].iat[0]):\n            color_range = [to_css_color(c) for c in df[color_column].unique()]\n            color_enc[\"scale\"] = alt.Scale(range=color_range)\n            # Don't show the color legend, because it will just show text with the color values,\n            # like #f00, #00f, etc, which are not user-readable.\n            color_enc[\"legend\"] = None\n\n        # Otherwise, let Vega-Lite auto-assign colors.\n        # This codepath is typically reached when the color column contains numbers (in which case\n        # Vega-Lite uses a color gradient to represent them) or strings (in which case Vega-Lite\n        # assigns one color for each unique value).\n        else:\n            pass\n\n        return color_enc\n\n    return None\n\n\ndef _get_size_encoding(\n    chart_type: ChartType,\n    size_column: str | None,\n    size_value: str | float | None,\n) -> alt.Size | alt.SizeValue | None:\n    import altair as alt\n\n    if chart_type == ChartType.SCATTER:\n        if size_column is not None:\n            return alt.Size(\n                size_column,\n                legend=_SIZE_LEGEND_SETTINGS,\n            )\n\n        elif isinstance(size_value, (float, int)):\n            return alt.SizeValue(size_value)\n        elif size_value is None:\n            return alt.SizeValue(100)\n        else:\n            raise StreamlitAPIException(\n                f\"This does not look like a valid size: {repr(size_value)}\"\n            )\n\n    elif size_column is not None or size_value is not None:\n        raise Error(\n            f\"Chart type {chart_type.name} does not support size argument. \"\n            \"This should never happen!\"\n        )\n\n    return None\n\n\ndef _get_tooltip_encoding(\n    x_column: str,\n    y_column: str,\n    size_column: str | None,\n    color_column: str | None,\n    color_enc: alt.Color | alt.ColorValue | None,\n) -> list[alt.Tooltip]:\n    import altair as alt\n\n    tooltip = []\n\n    # If the x column name is the crazy anti-collision name we gave it, then need to set\n    # up a tooltip title so we never show the crazy name to the user.\n    if x_column == _SEPARATED_INDEX_COLUMN_NAME:\n        tooltip.append(alt.Tooltip(x_column, title=_SEPARATED_INDEX_COLUMN_TITLE))\n    else:\n        tooltip.append(alt.Tooltip(x_column))\n\n    # If the y column name is the crazy anti-collision name we gave it, then need to set\n    # up a tooltip title so we never show the crazy name to the user.\n    if y_column == _MELTED_Y_COLUMN_NAME:\n        tooltip.append(\n            alt.Tooltip(\n                y_column,\n                title=_MELTED_Y_COLUMN_TITLE,\n                type=\"quantitative\",  # Just picked something random. Doesn't really matter!\n            )\n        )\n    else:\n        tooltip.append(alt.Tooltip(y_column))\n\n    # If we earlier decided that there should be no color legend, that's because the\n    # user passed a color column with actual color values (like \"#ff0\"), so we should\n    # not show the color values in the tooltip.\n    if color_column and getattr(color_enc, \"legend\", True) is not None:\n        # Use a human-readable title for the color.\n        if color_column == _MELTED_COLOR_COLUMN_NAME:\n            tooltip.append(\n                alt.Tooltip(\n                    color_column,\n                    title=_MELTED_COLOR_COLUMN_TITLE,\n                    type=\"nominal\",\n                )\n            )\n        else:\n            tooltip.append(alt.Tooltip(color_column))\n\n    if size_column:\n        tooltip.append(alt.Tooltip(size_column))\n\n    return tooltip\n\n\ndef _get_x_encoding_type(\n    df: pd.DataFrame, chart_type: ChartType, x_column: str | None\n) -> type_util.VegaLiteType:\n    if x_column is None:\n        return \"quantitative\"  # Anything. If None, Vega-Lite may hide the axis.\n\n    # Vertical bar charts should have a discrete (ordinal) x-axis, UNLESS type is date/time\n    # https://github.com/streamlit/streamlit/pull/2097#issuecomment-714802475\n    if chart_type == ChartType.VERTICAL_BAR and not _is_date_column(df, x_column):\n        return \"ordinal\"\n\n    return type_util.infer_vegalite_type(df[x_column])\n\n\ndef _get_y_encoding_type(\n    df: pd.DataFrame, chart_type: ChartType, y_column: str | None\n) -> type_util.VegaLiteType:\n    # Horizontal bar charts should have a discrete (ordinal) y-axis, UNLESS type is date/time\n    if chart_type == ChartType.HORIZONTAL_BAR and not _is_date_column(df, y_column):\n        return \"ordinal\"\n\n    if y_column:\n        return type_util.infer_vegalite_type(df[y_column])\n\n    return \"quantitative\"  # Pick anything. If undefined, Vega-Lite may hide the axis.\n\n\nclass StreamlitColumnNotFoundError(StreamlitAPIException):\n    def __init__(self, df, col_name, *args):\n        available_columns = \", \".join(str(c) for c in list(df.columns))\n        message = (\n            f'Data does not have a column named `\"{col_name}\"`. '\n            f\"Available columns are `{available_columns}`\"\n        )\n        super().__init__(message, *args)\n\n\nclass StreamlitInvalidColorError(StreamlitAPIException):\n    def __init__(self, df, color_from_user, *args):\n        \", \".join(str(c) for c in list(df.columns))\n        message = f\"\"\"\nThis does not look like a valid color argument: `{color_from_user}`.\n\nThe color argument can be:\n\n* A hex string like \"#ffaa00\" or \"#ffaa0088\".\n* An RGB or RGBA tuple with the red, green, blue, and alpha\n  components specified as ints from 0 to 255 or floats from 0.0 to\n  1.0.\n* The name of a column.\n* Or a list of colors, matching the number of y columns to draw.\n        \"\"\"\n        super().__init__(message, *args)\n\n\nclass StreamlitColorLengthError(StreamlitAPIException):\n    def __init__(self, color_values, y_column_list, *args):\n        message = (\n            f\"The list of colors `{color_values}` must have the same \"\n            \"length as the list of columns to be colored \"\n            f\"`{y_column_list}`.\"\n        )\n        super().__init__(message, *args)\n", "lib/streamlit/elements/lib/__init__.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n", "lib/streamlit/elements/lib/pandas_styler_utils.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom typing import TYPE_CHECKING, Any, Mapping, TypeVar\n\nfrom streamlit import type_util\nfrom streamlit.errors import StreamlitAPIException\n\nif TYPE_CHECKING:\n    from pandas import DataFrame\n    from pandas.io.formats.style import Styler\n\n    from streamlit.proto.Arrow_pb2 import Arrow as ArrowProto\n\n\ndef marshall_styler(proto: ArrowProto, styler: Styler, default_uuid: str) -> None:\n    \"\"\"Marshall pandas.Styler into an Arrow proto.\n\n    Parameters\n    ----------\n    proto : proto.Arrow\n        Output. The protobuf for Streamlit Arrow proto.\n\n    styler : pandas.Styler\n        Helps style a DataFrame or Series according to the data with HTML and CSS.\n\n    default_uuid : str\n        If pandas.Styler uuid is not provided, this value will be used.\n\n    \"\"\"\n    import pandas as pd\n\n    styler_data_df: pd.DataFrame = styler.data\n    if styler_data_df.size > int(pd.options.styler.render.max_elements):\n        raise StreamlitAPIException(\n            f\"The dataframe has `{styler_data_df.size}` cells, but the maximum number \"\n            \"of cells allowed to be rendered by Pandas Styler is configured to \"\n            f\"`{pd.options.styler.render.max_elements}`. To allow more cells to be \"\n            'styled, you can change the `\"styler.render.max_elements\"` config. For example: '\n            f'`pd.set_option(\"styler.render.max_elements\", {styler_data_df.size})`'\n        )\n\n    # pandas.Styler uuid should be set before _compute is called.\n    _marshall_uuid(proto, styler, default_uuid)\n\n    # We're using protected members of pandas.Styler to get styles,\n    # which is not ideal and could break if the interface changes.\n    styler._compute()\n\n    pandas_styles = styler._translate(False, False)\n\n    _marshall_caption(proto, styler)\n    _marshall_styles(proto, styler, pandas_styles)\n    _marshall_display_values(proto, styler_data_df, pandas_styles)\n\n\ndef _marshall_uuid(proto: ArrowProto, styler: Styler, default_uuid: str) -> None:\n    \"\"\"Marshall pandas.Styler uuid into an Arrow proto.\n\n    Parameters\n    ----------\n    proto : proto.Arrow\n        Output. The protobuf for Streamlit Arrow proto.\n\n    styler : pandas.Styler\n        Helps style a DataFrame or Series according to the data with HTML and CSS.\n\n    default_uuid : str\n        If pandas.Styler uuid is not provided, this value will be used.\n\n    \"\"\"\n    if styler.uuid is None:\n        styler.set_uuid(default_uuid)\n\n    proto.styler.uuid = str(styler.uuid)\n\n\ndef _marshall_caption(proto: ArrowProto, styler: Styler) -> None:\n    \"\"\"Marshall pandas.Styler caption into an Arrow proto.\n\n    Parameters\n    ----------\n    proto : proto.Arrow\n        Output. The protobuf for Streamlit Arrow proto.\n\n    styler : pandas.Styler\n        Helps style a DataFrame or Series according to the data with HTML and CSS.\n\n    \"\"\"\n    if styler.caption is not None:\n        proto.styler.caption = styler.caption\n\n\ndef _marshall_styles(\n    proto: ArrowProto, styler: Styler, styles: Mapping[str, Any]\n) -> None:\n    \"\"\"Marshall pandas.Styler styles into an Arrow proto.\n\n    Parameters\n    ----------\n    proto : proto.Arrow\n        Output. The protobuf for Streamlit Arrow proto.\n\n    styler : pandas.Styler\n        Helps style a DataFrame or Series according to the data with HTML and CSS.\n\n    styles : dict\n        pandas.Styler translated styles.\n\n    \"\"\"\n    css_rules = []\n\n    if \"table_styles\" in styles:\n        table_styles = styles[\"table_styles\"]\n        table_styles = _trim_pandas_styles(table_styles)\n        for style in table_styles:\n            # styles in \"table_styles\" have a space\n            # between the uuid and selector.\n            rule = _pandas_style_to_css(\n                \"table_styles\", style, styler.uuid, separator=\" \"\n            )\n            css_rules.append(rule)\n\n    if \"cellstyle\" in styles:\n        cellstyle = styles[\"cellstyle\"]\n        cellstyle = _trim_pandas_styles(cellstyle)\n        for style in cellstyle:\n            rule = _pandas_style_to_css(\"cell_style\", style, styler.uuid)\n            css_rules.append(rule)\n\n    if len(css_rules) > 0:\n        proto.styler.styles = \"\\n\".join(css_rules)\n\n\nM = TypeVar(\"M\", bound=Mapping[str, Any])\n\n\ndef _trim_pandas_styles(styles: list[M]) -> list[M]:\n    \"\"\"Filter out empty styles.\n\n    Every cell will have a class, but the list of props\n    may just be [['', '']].\n\n    Parameters\n    ----------\n    styles : list\n        pandas.Styler translated styles.\n\n    \"\"\"\n    return [x for x in styles if any(any(y) for y in x[\"props\"])]\n\n\ndef _pandas_style_to_css(\n    style_type: str,\n    style: Mapping[str, Any],\n    uuid: str,\n    separator: str = \"\",\n) -> str:\n    \"\"\"Convert pandas.Styler translated style to CSS.\n\n    Parameters\n    ----------\n    style_type : str\n        Either \"table_styles\" or \"cell_style\".\n\n    style : dict\n        pandas.Styler translated style.\n\n    uuid : str\n        pandas.Styler uuid.\n\n    separator : str\n        A string separator used between table and cell selectors.\n\n    \"\"\"\n    declarations = []\n    for css_property, css_value in style[\"props\"]:\n        declaration = css_property.strip() + \": \" + css_value.strip()\n        declarations.append(declaration)\n\n    table_selector = f\"#T_{uuid}\"\n\n    # In pandas >= 1.1.0\n    # translated_style[\"cellstyle\"] has the following shape:\n    # [\n    #   {\n    #       \"props\": [(\"color\", \" black\"), (\"background-color\", \"orange\"), (\"\", \"\")],\n    #       \"selectors\": [\"row0_col0\"]\n    #   }\n    #   ...\n    # ]\n    if style_type == \"table_styles\":\n        cell_selectors = [style[\"selector\"]]\n    else:\n        cell_selectors = style[\"selectors\"]\n\n    selectors = []\n    for cell_selector in cell_selectors:\n        selectors.append(table_selector + separator + cell_selector)\n    selector = \", \".join(selectors)\n\n    declaration_block = \"; \".join(declarations)\n    rule_set = selector + \" { \" + declaration_block + \" }\"\n\n    return rule_set\n\n\ndef _marshall_display_values(\n    proto: ArrowProto, df: DataFrame, styles: Mapping[str, Any]\n) -> None:\n    \"\"\"Marshall pandas.Styler display values into an Arrow proto.\n\n    Parameters\n    ----------\n    proto : proto.Arrow\n        Output. The protobuf for Streamlit Arrow proto.\n\n    df : pandas.DataFrame\n        A dataframe with original values.\n\n    styles : dict\n        pandas.Styler translated styles.\n\n    \"\"\"\n    new_df = _use_display_values(df, styles)\n    proto.styler.display_values = type_util.data_frame_to_bytes(new_df)\n\n\ndef _use_display_values(df: DataFrame, styles: Mapping[str, Any]) -> DataFrame:\n    \"\"\"Create a new pandas.DataFrame where display values are used instead of original ones.\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        A dataframe with original values.\n\n    styles : dict\n        pandas.Styler translated styles.\n\n    \"\"\"\n    import re\n\n    # If values in a column are not of the same type, Arrow\n    # serialization would fail. Thus, we need to cast all values\n    # of the dataframe to strings before assigning them display values.\n    new_df = df.astype(str)\n\n    cell_selector_regex = re.compile(r\"row(\\d+)_col(\\d+)\")\n    if \"body\" in styles:\n        rows = styles[\"body\"]\n        for row in rows:\n            for cell in row:\n                if \"id\" in cell:\n                    if match := cell_selector_regex.match(cell[\"id\"]):\n                        r, c = map(int, match.groups())\n                        new_df.iat[r, c] = str(cell[\"display_value\"])\n\n    return new_df\n", "lib/streamlit/elements/widgets/number_input.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport numbers\nfrom dataclasses import dataclass\nfrom textwrap import dedent\nfrom typing import TYPE_CHECKING, Literal, Union, cast, overload\n\nfrom typing_extensions import TypeAlias\n\nfrom streamlit.elements.form import current_form_id\nfrom streamlit.elements.lib.policies import (\n    check_cache_replay_rules,\n    check_callback_rules,\n    check_fragment_path_policy,\n    check_session_state_rules,\n)\nfrom streamlit.elements.lib.utils import get_label_visibility_proto_value\nfrom streamlit.errors import StreamlitAPIException\nfrom streamlit.js_number import JSNumber, JSNumberBoundsException\nfrom streamlit.proto.NumberInput_pb2 import NumberInput as NumberInputProto\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.runtime.scriptrunner import ScriptRunContext, get_script_run_ctx\nfrom streamlit.runtime.state import (\n    WidgetArgs,\n    WidgetCallback,\n    WidgetKwargs,\n    get_session_state,\n    register_widget,\n)\nfrom streamlit.runtime.state.common import compute_widget_id\nfrom streamlit.type_util import Key, LabelVisibility, maybe_raise_label_warnings, to_key\n\nif TYPE_CHECKING:\n    from streamlit.delta_generator import DeltaGenerator\n\n\nNumber: TypeAlias = Union[int, float]\n\n\n@dataclass\nclass NumberInputSerde:\n    value: Number | None\n    data_type: int\n\n    def serialize(self, v: Number | None) -> Number | None:\n        return v\n\n    def deserialize(\n        self, ui_value: Number | None, widget_id: str = \"\"\n    ) -> Number | None:\n        val: Number | None = ui_value if ui_value is not None else self.value\n\n        if val is not None and self.data_type == NumberInputProto.INT:\n            val = int(val)\n\n        return val\n\n\nclass NumberInputMixin:\n    @overload\n    def number_input(\n        self,\n        label: str,\n        min_value: Number | None = None,\n        max_value: Number | None = None,\n        value: Number | Literal[\"min\"] = \"min\",\n        step: Number | None = None,\n        format: str | None = None,\n        key: Key | None = None,\n        help: str | None = None,\n        on_change: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        *,  # keyword-only arguments:\n        placeholder: str | None = None,\n        disabled: bool = False,\n        label_visibility: LabelVisibility = \"visible\",\n    ) -> Number:\n        pass\n\n    @overload\n    def number_input(\n        self,\n        label: str,\n        min_value: Number | None = None,\n        max_value: Number | None = None,\n        value: None = None,\n        step: Number | None = None,\n        format: str | None = None,\n        key: Key | None = None,\n        help: str | None = None,\n        on_change: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        *,  # keyword-only arguments:\n        placeholder: str | None = None,\n        disabled: bool = False,\n        label_visibility: LabelVisibility = \"visible\",\n    ) -> Number | None:\n        pass\n\n    @gather_metrics(\"number_input\")\n    def number_input(\n        self,\n        label: str,\n        min_value: Number | None = None,\n        max_value: Number | None = None,\n        value: Number | Literal[\"min\"] | None = \"min\",\n        step: Number | None = None,\n        format: str | None = None,\n        key: Key | None = None,\n        help: str | None = None,\n        on_change: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        *,  # keyword-only arguments:\n        placeholder: str | None = None,\n        disabled: bool = False,\n        label_visibility: LabelVisibility = \"visible\",\n    ) -> Number | None:\n        r\"\"\"Display a numeric input widget.\n\n        .. note::\n            Integer values exceeding +/- ``(1<<53) - 1`` cannot be accurately\n            stored or returned by the widget due to serialization contstraints\n            between the Python server and JavaScript client. You must handle\n            such numbers as floats, leading to a loss in precision.\n\n        Parameters\n        ----------\n        label : str\n            A short label explaining to the user what this input is for.\n            The label can optionally contain Markdown and supports the following\n            elements: Bold, Italics, Strikethroughs, Inline Code, Emojis, and Links.\n\n            This also supports:\n\n            * Emoji shortcodes, such as ``:+1:``  and ``:sunglasses:``.\n              For a list of all supported codes,\n              see https://share.streamlit.io/streamlit/emoji-shortcodes.\n\n            * LaTeX expressions, by wrapping them in \"$\" or \"$$\" (the \"$$\"\n              must be on their own lines). Supported LaTeX functions are listed\n              at https://katex.org/docs/supported.html.\n\n            * Colored text and background colors for text, using the syntax\n              ``:color[text to be colored]`` and ``:color-background[text to be colored]``,\n              respectively. ``color`` must be replaced with any of the following\n              supported colors: blue, green, orange, red, violet, gray/grey, rainbow.\n              For example, you can use ``:orange[your text here]`` or\n              ``:blue-background[your text here]``.\n\n            Unsupported elements are unwrapped so only their children (text contents) render.\n            Display unsupported elements as literal characters by\n            backslash-escaping them. E.g. ``1\\. Not an ordered list``.\n\n            For accessibility reasons, you should never set an empty label (label=\"\")\n            but hide it with label_visibility if needed. In the future, we may disallow\n            empty labels by raising an exception.\n        min_value : int, float, or None\n            The minimum permitted value.\n            If None, there will be no minimum.\n        max_value : int, float, or None\n            The maximum permitted value.\n            If None, there will be no maximum.\n        value : int, float, \"min\" or None\n            The value of this widget when it first renders. If ``None``, will initialize\n            empty and return ``None`` until the user provides input.\n            If \"min\" (default), will initialize with min_value, or 0.0 if\n            min_value is None.\n        step : int, float, or None\n            The stepping interval.\n            Defaults to 1 if the value is an int, 0.01 otherwise.\n            If the value is not specified, the format parameter will be used.\n        format : str or None\n            A printf-style format string controlling how the interface should\n            display numbers. Output must be purely numeric. This does not impact\n            the return value. Valid formatters: %d %e %f %g %i %u\n        key : str or int\n            An optional string or integer to use as the unique key for the widget.\n            If this is omitted, a key will be generated for the widget\n            based on its content. Multiple widgets of the same type may\n            not share the same key.\n        help : str\n            An optional tooltip that gets displayed next to the input.\n        on_change : callable\n            An optional callback invoked when this number_input's value changes.\n        args : tuple\n            An optional tuple of args to pass to the callback.\n        kwargs : dict\n            An optional dict of kwargs to pass to the callback.\n        placeholder : str or None\n            An optional string displayed when the number input is empty.\n            If None, no placeholder is displayed.\n        disabled : bool\n            An optional boolean, which disables the number input if set to\n            True. The default is False.\n        label_visibility : \"visible\", \"hidden\", or \"collapsed\"\n            The visibility of the label. If \"hidden\", the label doesn't show but there\n            is still empty space for it above the widget (equivalent to label=\"\").\n            If \"collapsed\", both the label and the space are removed. Default is\n            \"visible\".\n\n        Returns\n        -------\n        int or float or None\n            The current value of the numeric input widget or ``None`` if the widget\n            is empty. The return type will match the data type of the value parameter.\n\n        Example\n        -------\n        >>> import streamlit as st\n        >>>\n        >>> number = st.number_input(\"Insert a number\")\n        >>> st.write(\"The current number is \", number)\n\n        .. output::\n           https://doc-number-input.streamlit.app/\n           height: 260px\n\n        To initialize an empty number input, use ``None`` as the value:\n\n        >>> import streamlit as st\n        >>>\n        >>> number = st.number_input(\"Insert a number\", value=None, placeholder=\"Type a number...\")\n        >>> st.write(\"The current number is \", number)\n\n        .. output::\n           https://doc-number-input-empty.streamlit.app/\n           height: 260px\n\n        \"\"\"\n        ctx = get_script_run_ctx()\n        return self._number_input(\n            label=label,\n            min_value=min_value,\n            max_value=max_value,\n            value=value,\n            step=step,\n            format=format,\n            key=key,\n            help=help,\n            on_change=on_change,\n            args=args,\n            kwargs=kwargs,\n            placeholder=placeholder,\n            disabled=disabled,\n            label_visibility=label_visibility,\n            ctx=ctx,\n        )\n\n    def _number_input(\n        self,\n        label: str,\n        min_value: Number | None = None,\n        max_value: Number | None = None,\n        value: Number | Literal[\"min\"] | None = \"min\",\n        step: Number | None = None,\n        format: str | None = None,\n        key: Key | None = None,\n        help: str | None = None,\n        on_change: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        *,  # keyword-only arguments:\n        placeholder: str | None = None,\n        disabled: bool = False,\n        label_visibility: LabelVisibility = \"visible\",\n        ctx: ScriptRunContext | None = None,\n    ) -> Number | None:\n        key = to_key(key)\n\n        check_fragment_path_policy(self.dg)\n        check_cache_replay_rules()\n        check_callback_rules(self.dg, on_change)\n        check_session_state_rules(\n            default_value=value if value != \"min\" else None, key=key\n        )\n        maybe_raise_label_warnings(label, label_visibility)\n\n        id = compute_widget_id(\n            \"number_input\",\n            user_key=key,\n            label=label,\n            min_value=min_value,\n            max_value=max_value,\n            value=value,\n            step=step,\n            format=format,\n            key=key,\n            help=help,\n            placeholder=None if placeholder is None else str(placeholder),\n            form_id=current_form_id(self.dg),\n            page=ctx.active_script_hash if ctx else None,\n        )\n\n        # Ensure that all arguments are of the same type.\n        number_input_args = [min_value, max_value, value, step]\n\n        int_args = all(\n            isinstance(a, (numbers.Integral, type(None), str))\n            for a in number_input_args\n        )\n\n        float_args = all(\n            isinstance(a, (float, type(None), str)) for a in number_input_args\n        )\n\n        if not int_args and not float_args:\n            raise StreamlitAPIException(\n                \"All numerical arguments must be of the same type.\"\n                f\"\\n`value` has {type(value).__name__} type.\"\n                f\"\\n`min_value` has {type(min_value).__name__} type.\"\n                f\"\\n`max_value` has {type(max_value).__name__} type.\"\n                f\"\\n`step` has {type(step).__name__} type.\"\n            )\n\n        session_state = get_session_state().filtered_state\n        if key is not None and key in session_state and session_state[key] is None:\n            value = None\n\n        if value == \"min\":\n            if min_value is not None:\n                value = min_value\n            elif int_args and float_args:\n                value = 0.0  # if no values are provided, defaults to float\n            elif int_args:\n                value = 0\n            else:\n                value = 0.0\n\n        int_value = isinstance(value, numbers.Integral)\n        float_value = isinstance(value, float)\n\n        if value is None:\n            if int_args and not float_args:\n                # Select int type if all relevant args are ints:\n                int_value = True\n            else:\n                # Otherwise, defaults to float:\n                float_value = True\n\n        if format is None:\n            format = \"%d\" if int_value else \"%0.2f\"\n\n        # Warn user if they format an int type as a float or vice versa.\n        if format in [\"%d\", \"%u\", \"%i\"] and float_value:\n            import streamlit as st\n\n            st.warning(\n                \"Warning: NumberInput value below has type float,\"\n                f\" but format {format} displays as integer.\"\n            )\n        elif format[-1] == \"f\" and int_value:\n            import streamlit as st\n\n            st.warning(\n                \"Warning: NumberInput value below has type int so is\"\n                f\" displayed as int despite format string {format}.\"\n            )\n\n        if step is None:\n            step = 1 if int_value else 0.01\n\n        try:\n            float(format % 2)\n        except (TypeError, ValueError):\n            raise StreamlitAPIException(\n                \"Format string for st.number_input contains invalid characters: %s\"\n                % format\n            )\n\n        # Ensure that the value matches arguments' types.\n        all_ints = int_value and int_args\n\n        if min_value is not None and value is not None and min_value > value:\n            raise StreamlitAPIException(\n                f\"The default `value` {value} must be greater than or equal to the `min_value` {min_value}\"\n            )\n        if max_value is not None and value is not None and max_value < value:\n            raise StreamlitAPIException(\n                f\"The default `value` {value} must be less than or equal to the `max_value` {max_value}\"\n            )\n\n        # Bounds checks. JSNumber produces human-readable exceptions that\n        # we simply re-package as StreamlitAPIExceptions.\n        try:\n            if all_ints:\n                if min_value is not None:\n                    JSNumber.validate_int_bounds(int(min_value), \"`min_value`\")\n                if max_value is not None:\n                    JSNumber.validate_int_bounds(int(max_value), \"`max_value`\")\n                if step is not None:\n                    JSNumber.validate_int_bounds(int(step), \"`step`\")\n                if value is not None:\n                    JSNumber.validate_int_bounds(int(value), \"`value`\")\n            else:\n                if min_value is not None:\n                    JSNumber.validate_float_bounds(min_value, \"`min_value`\")\n                if max_value is not None:\n                    JSNumber.validate_float_bounds(max_value, \"`max_value`\")\n                if step is not None:\n                    JSNumber.validate_float_bounds(step, \"`step`\")\n                if value is not None:\n                    JSNumber.validate_float_bounds(value, \"`value`\")\n        except JSNumberBoundsException as e:\n            raise StreamlitAPIException(str(e))\n\n        data_type = NumberInputProto.INT if all_ints else NumberInputProto.FLOAT\n\n        number_input_proto = NumberInputProto()\n        number_input_proto.id = id\n        number_input_proto.data_type = data_type\n        number_input_proto.label = label\n        if value is not None:\n            number_input_proto.default = value\n        if placeholder is not None:\n            number_input_proto.placeholder = str(placeholder)\n        number_input_proto.form_id = current_form_id(self.dg)\n        number_input_proto.disabled = disabled\n        number_input_proto.label_visibility.value = get_label_visibility_proto_value(\n            label_visibility\n        )\n\n        if help is not None:\n            number_input_proto.help = dedent(help)\n\n        if min_value is not None:\n            number_input_proto.min = min_value\n            number_input_proto.has_min = True\n\n        if max_value is not None:\n            number_input_proto.max = max_value\n            number_input_proto.has_max = True\n\n        if step is not None:\n            number_input_proto.step = step\n\n        if format is not None:\n            number_input_proto.format = format\n\n        serde = NumberInputSerde(value, data_type)\n        widget_state = register_widget(\n            \"number_input\",\n            number_input_proto,\n            user_key=key,\n            on_change_handler=on_change,\n            args=args,\n            kwargs=kwargs,\n            deserializer=serde.deserialize,\n            serializer=serde.serialize,\n            ctx=ctx,\n        )\n\n        if widget_state.value_changed:\n            if widget_state.value is not None:\n                number_input_proto.value = widget_state.value\n            number_input_proto.set_value = True\n\n        self.dg._enqueue(\"number_input\", number_input_proto)\n        return widget_state.value\n\n    @property\n    def dg(self) -> DeltaGenerator:\n        \"\"\"Get our DeltaGenerator.\"\"\"\n        return cast(\"DeltaGenerator\", self)\n", "lib/streamlit/elements/widgets/slider.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom dataclasses import dataclass\nfrom datetime import date, datetime, time, timedelta, timezone, tzinfo\nfrom numbers import Integral, Real\nfrom textwrap import dedent\nfrom typing import TYPE_CHECKING, Any, Final, Sequence, Tuple, TypeVar, Union, cast\n\nfrom typing_extensions import TypeAlias\n\nfrom streamlit.elements.form import current_form_id\nfrom streamlit.elements.lib.policies import (\n    check_cache_replay_rules,\n    check_callback_rules,\n    check_fragment_path_policy,\n    check_session_state_rules,\n)\nfrom streamlit.elements.lib.utils import get_label_visibility_proto_value\nfrom streamlit.errors import StreamlitAPIException\nfrom streamlit.js_number import JSNumber, JSNumberBoundsException\nfrom streamlit.proto.Slider_pb2 import Slider as SliderProto\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.runtime.scriptrunner import ScriptRunContext, get_script_run_ctx\nfrom streamlit.runtime.state import (\n    WidgetArgs,\n    WidgetCallback,\n    WidgetKwargs,\n    get_session_state,\n    register_widget,\n)\nfrom streamlit.runtime.state.common import compute_widget_id\nfrom streamlit.type_util import Key, LabelVisibility, maybe_raise_label_warnings, to_key\n\nif TYPE_CHECKING:\n    from streamlit.delta_generator import DeltaGenerator\n\nSliderScalarT = TypeVar(\"SliderScalarT\", int, float, date, time, datetime)\n\nStep: TypeAlias = Union[int, float, timedelta]\nSliderScalar: TypeAlias = Union[int, float, date, time, datetime]\n\nSliderValueGeneric: TypeAlias = Union[\n    SliderScalarT,\n    Sequence[SliderScalarT],\n]\nSliderValue: TypeAlias = Union[\n    SliderValueGeneric[int],\n    SliderValueGeneric[float],\n    SliderValueGeneric[date],\n    SliderValueGeneric[time],\n    SliderValueGeneric[datetime],\n]\n\nSliderReturnGeneric: TypeAlias = Union[\n    SliderScalarT,\n    Tuple[SliderScalarT],\n    Tuple[SliderScalarT, SliderScalarT],\n]\nSliderReturn: TypeAlias = Union[\n    SliderReturnGeneric[int],\n    SliderReturnGeneric[float],\n    SliderReturnGeneric[date],\n    SliderReturnGeneric[time],\n    SliderReturnGeneric[datetime],\n]\n\nSECONDS_TO_MICROS: Final = 1000 * 1000\nDAYS_TO_MICROS: Final = 24 * 60 * 60 * SECONDS_TO_MICROS\n\nUTC_EPOCH: Final = datetime(1970, 1, 1, tzinfo=timezone.utc)\n\n\ndef _time_to_datetime(time_: time) -> datetime:\n    # Note, here we pick an arbitrary date well after Unix epoch.\n    # This prevents pre-epoch timezone issues (https://bugs.python.org/issue36759)\n    # We're dropping the date from datetime later, anyway.\n    return datetime.combine(date(2000, 1, 1), time_)\n\n\ndef _date_to_datetime(date_: date) -> datetime:\n    return datetime.combine(date_, time())\n\n\ndef _delta_to_micros(delta: timedelta) -> int:\n    return (\n        delta.microseconds\n        + delta.seconds * SECONDS_TO_MICROS\n        + delta.days * DAYS_TO_MICROS\n    )\n\n\ndef _datetime_to_micros(dt: datetime) -> int:\n    # The frontend is not aware of timezones and only expects a UTC-based\n    # timestamp (in microseconds). Since we want to show the date/time exactly\n    # as it is in the given datetime object, we just set the tzinfo to UTC and\n    # do not do any timezone conversions. Only the backend knows about\n    # original timezone and will replace the UTC timestamp in the deserialization.\n    utc_dt = dt.replace(tzinfo=timezone.utc)\n    return _delta_to_micros(utc_dt - UTC_EPOCH)\n\n\ndef _micros_to_datetime(micros: int, orig_tz: tzinfo | None) -> datetime:\n    \"\"\"Restore times/datetimes to original timezone (dates are always naive)\"\"\"\n    utc_dt = UTC_EPOCH + timedelta(microseconds=micros)\n    # Add the original timezone. No conversion is required here,\n    # since in the serialization, we also just replace the timestamp with UTC.\n    return utc_dt.replace(tzinfo=orig_tz)\n\n\n@dataclass\nclass SliderSerde:\n    value: list[float]\n    data_type: int\n    single_value: bool\n    orig_tz: tzinfo | None\n\n    def deserialize(self, ui_value: list[float] | None, widget_id: str = \"\"):\n        if ui_value is not None:\n            val: Any = ui_value\n        else:\n            # Widget has not been used; fallback to the original value,\n            val = self.value\n\n        # The widget always returns a float array, so fix the return type if necessary\n        if self.data_type == SliderProto.INT:\n            val = [int(v) for v in val]\n        if self.data_type == SliderProto.DATETIME:\n            val = [_micros_to_datetime(int(v), self.orig_tz) for v in val]\n        if self.data_type == SliderProto.DATE:\n            val = [_micros_to_datetime(int(v), self.orig_tz).date() for v in val]\n        if self.data_type == SliderProto.TIME:\n            val = [\n                _micros_to_datetime(int(v), self.orig_tz)\n                .time()\n                .replace(tzinfo=self.orig_tz)\n                for v in val\n            ]\n        return val[0] if self.single_value else tuple(val)\n\n    def serialize(self, v: Any) -> list[Any]:\n        range_value = isinstance(v, (list, tuple))\n        value = list(v) if range_value else [v]\n        if self.data_type == SliderProto.DATE:\n            value = [_datetime_to_micros(_date_to_datetime(v)) for v in value]\n        if self.data_type == SliderProto.TIME:\n            value = [_datetime_to_micros(_time_to_datetime(v)) for v in value]\n        if self.data_type == SliderProto.DATETIME:\n            value = [_datetime_to_micros(v) for v in value]\n        return value\n\n\nclass SliderMixin:\n    @gather_metrics(\"slider\")\n    def slider(\n        self,\n        label: str,\n        min_value: SliderScalar | None = None,\n        max_value: SliderScalar | None = None,\n        value: SliderValue | None = None,\n        step: Step | None = None,\n        format: str | None = None,\n        key: Key | None = None,\n        help: str | None = None,\n        on_change: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        *,  # keyword-only arguments:\n        disabled: bool = False,\n        label_visibility: LabelVisibility = \"visible\",\n        # TODO(harahu): Add overload definitions. The return type is\n        #  `SliderReturn`, in reality, but the return type is left as `Any`\n        #  until we have proper overload definitions in place. Otherwise the\n        #  user would have to cast the return value more often than not, which\n        #  can be annoying.\n    ) -> Any:\n        r\"\"\"Display a slider widget.\n\n        This supports int, float, date, time, and datetime types.\n\n        This also allows you to render a range slider by passing a two-element\n        tuple or list as the ``value``.\n\n        The difference between ``st.slider`` and ``st.select_slider`` is that\n        ``slider`` only accepts numerical or date/time data and takes a range as\n        input, while ``select_slider`` accepts any datatype and takes an iterable\n        set of options.\n\n        .. note::\n            Integer values exceeding +/- ``(1<<53) - 1`` cannot be accurately\n            stored or returned by the widget due to serialization contstraints\n            between the Python server and JavaScript client. You must handle\n            such numbers as floats, leading to a loss in precision.\n\n        Parameters\n        ----------\n        label : str\n            A short label explaining to the user what this slider is for.\n            The label can optionally contain Markdown and supports the following\n            elements: Bold, Italics, Strikethroughs, Inline Code, Emojis, and Links.\n\n            This also supports:\n\n            * Emoji shortcodes, such as ``:+1:``  and ``:sunglasses:``.\n              For a list of all supported codes,\n              see https://share.streamlit.io/streamlit/emoji-shortcodes.\n\n            * LaTeX expressions, by wrapping them in \"$\" or \"$$\" (the \"$$\"\n              must be on their own lines). Supported LaTeX functions are listed\n              at https://katex.org/docs/supported.html.\n\n            * Colored text and background colors for text, using the syntax\n              ``:color[text to be colored]`` and ``:color-background[text to be colored]``,\n              respectively. ``color`` must be replaced with any of the following\n              supported colors: blue, green, orange, red, violet, gray/grey, rainbow.\n              For example, you can use ``:orange[your text here]`` or\n              ``:blue-background[your text here]``.\n\n            Unsupported elements are unwrapped so only their children (text contents) render.\n            Display unsupported elements as literal characters by\n            backslash-escaping them. E.g. ``1\\. Not an ordered list``.\n\n            For accessibility reasons, you should never set an empty label (label=\"\")\n            but hide it with label_visibility if needed. In the future, we may disallow\n            empty labels by raising an exception.\n        min_value : a supported type or None\n            The minimum permitted value.\n            Defaults to 0 if the value is an int, 0.0 if a float,\n            value - timedelta(days=14) if a date/datetime, time.min if a time\n        max_value : a supported type or None\n            The maximum permitted value.\n            Defaults to 100 if the value is an int, 1.0 if a float,\n            value + timedelta(days=14) if a date/datetime, time.max if a time\n        value : a supported type or a tuple/list of supported types or None\n            The value of the slider when it first renders. If a tuple/list\n            of two values is passed here, then a range slider with those lower\n            and upper bounds is rendered. For example, if set to `(1, 10)` the\n            slider will have a selectable range between 1 and 10.\n            Defaults to min_value.\n        step : int, float, timedelta, or None\n            The stepping interval.\n            Defaults to 1 if the value is an int, 0.01 if a float,\n            timedelta(days=1) if a date/datetime, timedelta(minutes=15) if a time\n            (or if max_value - min_value < 1 day)\n        format : str or None\n            A printf-style format string controlling how the interface should\n            display numbers. This does not impact the return value.\n            Formatter for int/float supports: %d %e %f %g %i\n            Formatter for date/time/datetime uses Moment.js notation:\n            https://momentjs.com/docs/#/displaying/format/\n        key : str or int\n            An optional string or integer to use as the unique key for the widget.\n            If this is omitted, a key will be generated for the widget\n            based on its content. Multiple widgets of the same type may\n            not share the same key.\n        help : str\n            An optional tooltip that gets displayed next to the slider.\n        on_change : callable\n            An optional callback invoked when this slider's value changes.\n        args : tuple\n            An optional tuple of args to pass to the callback.\n        kwargs : dict\n            An optional dict of kwargs to pass to the callback.\n        disabled : bool\n            An optional boolean, which disables the slider if set to True. The\n            default is False.\n        label_visibility : \"visible\", \"hidden\", or \"collapsed\"\n            The visibility of the label. If \"hidden\", the label doesn't show but there\n            is still empty space for it above the widget (equivalent to label=\"\").\n            If \"collapsed\", both the label and the space are removed. Default is\n            \"visible\".\n\n\n        Returns\n        -------\n        int/float/date/time/datetime or tuple of int/float/date/time/datetime\n            The current value of the slider widget. The return type will match\n            the data type of the value parameter.\n\n        Examples\n        --------\n        >>> import streamlit as st\n        >>>\n        >>> age = st.slider(\"How old are you?\", 0, 130, 25)\n        >>> st.write(\"I'm \", age, \"years old\")\n\n        And here's an example of a range slider:\n\n        >>> import streamlit as st\n        >>>\n        >>> values = st.slider(\n        ...     \"Select a range of values\",\n        ...     0.0, 100.0, (25.0, 75.0))\n        >>> st.write(\"Values:\", values)\n\n        This is a range time slider:\n\n        >>> import streamlit as st\n        >>> from datetime import time\n        >>>\n        >>> appointment = st.slider(\n        ...     \"Schedule your appointment:\",\n        ...     value=(time(11, 30), time(12, 45)))\n        >>> st.write(\"You're scheduled for:\", appointment)\n\n        Finally, a datetime slider:\n\n        >>> import streamlit as st\n        >>> from datetime import datetime\n        >>>\n        >>> start_time = st.slider(\n        ...     \"When do you start?\",\n        ...     value=datetime(2020, 1, 1, 9, 30),\n        ...     format=\"MM/DD/YY - hh:mm\")\n        >>> st.write(\"Start time:\", start_time)\n\n        .. output::\n           https://doc-slider.streamlit.app/\n           height: 300px\n\n        \"\"\"\n        ctx = get_script_run_ctx()\n        return self._slider(\n            label=label,\n            min_value=min_value,\n            max_value=max_value,\n            value=value,\n            step=step,\n            format=format,\n            key=key,\n            help=help,\n            on_change=on_change,\n            args=args,\n            kwargs=kwargs,\n            disabled=disabled,\n            label_visibility=label_visibility,\n            ctx=ctx,\n        )\n\n    def _slider(\n        self,\n        label: str,\n        min_value=None,\n        max_value=None,\n        value=None,\n        step: Step | None = None,\n        format: str | None = None,\n        key: Key | None = None,\n        help: str | None = None,\n        on_change: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        *,  # keyword-only arguments:\n        disabled: bool = False,\n        label_visibility: LabelVisibility = \"visible\",\n        ctx: ScriptRunContext | None = None,\n    ) -> SliderReturn:\n        key = to_key(key)\n\n        check_fragment_path_policy(self.dg)\n        check_cache_replay_rules()\n        check_callback_rules(self.dg, on_change)\n        check_session_state_rules(default_value=value, key=key)\n        maybe_raise_label_warnings(label, label_visibility)\n\n        id = compute_widget_id(\n            \"slider\",\n            user_key=key,\n            label=label,\n            min_value=min_value,\n            max_value=max_value,\n            value=value,\n            step=step,\n            format=format,\n            key=key,\n            help=help,\n            form_id=current_form_id(self.dg),\n            page=ctx.active_script_hash if ctx else None,\n        )\n\n        SUPPORTED_TYPES = {\n            Integral: SliderProto.INT,\n            Real: SliderProto.FLOAT,\n            datetime: SliderProto.DATETIME,\n            date: SliderProto.DATE,\n            time: SliderProto.TIME,\n        }\n        TIMELIKE_TYPES = (SliderProto.DATETIME, SliderProto.TIME, SliderProto.DATE)\n\n        if value is None:\n            # We need to know if this is a single or range slider, but don't have\n            # a default value, so we check if session_state can tell us.\n            # We already calcluated the id, so there is no risk of this causing\n            # the id to change.\n\n            single_value = True\n\n            session_state = get_session_state().filtered_state\n\n            if key is not None and key in session_state:\n                state_value = session_state[key]\n                single_value = isinstance(state_value, tuple(SUPPORTED_TYPES.keys()))\n\n            if single_value:\n                value = min_value if min_value is not None else 0\n            else:\n                mn = min_value if min_value is not None else 0\n                mx = max_value if max_value is not None else 100\n                value = [mn, mx]\n\n        # Ensure that the value is either a single value or a range of values.\n        single_value = isinstance(value, tuple(SUPPORTED_TYPES.keys()))\n        range_value = isinstance(value, (list, tuple)) and len(value) in (0, 1, 2)\n        if not single_value and not range_value:\n            raise StreamlitAPIException(\n                \"Slider value should either be an int/float/datetime or a list/tuple of \"\n                \"0 to 2 ints/floats/datetimes\"\n            )\n\n        # Simplify future logic by always making value a list\n        if single_value:\n            value = [value]\n\n        def value_to_generic_type(v):\n            if isinstance(v, Integral):\n                return SUPPORTED_TYPES[Integral]\n            elif isinstance(v, Real):\n                return SUPPORTED_TYPES[Real]\n            else:\n                return SUPPORTED_TYPES[type(v)]\n\n        def all_same_type(items):\n            return len(set(map(value_to_generic_type, items))) < 2\n\n        if not all_same_type(value):\n            raise StreamlitAPIException(\n                \"Slider tuple/list components must be of the same type.\\n\"\n                f\"But were: {list(map(type, value))}\"\n            )\n\n        if len(value) == 0:\n            data_type = SliderProto.INT\n        else:\n            data_type = value_to_generic_type(value[0])\n\n        datetime_min = time.min\n        datetime_max = time.max\n        if data_type == SliderProto.TIME:\n            datetime_min = time.min.replace(tzinfo=value[0].tzinfo)\n            datetime_max = time.max.replace(tzinfo=value[0].tzinfo)\n        if data_type in (SliderProto.DATETIME, SliderProto.DATE):\n            datetime_min = value[0] - timedelta(days=14)\n            datetime_max = value[0] + timedelta(days=14)\n\n        DEFAULTS = {\n            SliderProto.INT: {\n                \"min_value\": 0,\n                \"max_value\": 100,\n                \"step\": 1,\n                \"format\": \"%d\",\n            },\n            SliderProto.FLOAT: {\n                \"min_value\": 0.0,\n                \"max_value\": 1.0,\n                \"step\": 0.01,\n                \"format\": \"%0.2f\",\n            },\n            SliderProto.DATETIME: {\n                \"min_value\": datetime_min,\n                \"max_value\": datetime_max,\n                \"step\": timedelta(days=1),\n                \"format\": \"YYYY-MM-DD\",\n            },\n            SliderProto.DATE: {\n                \"min_value\": datetime_min,\n                \"max_value\": datetime_max,\n                \"step\": timedelta(days=1),\n                \"format\": \"YYYY-MM-DD\",\n            },\n            SliderProto.TIME: {\n                \"min_value\": datetime_min,\n                \"max_value\": datetime_max,\n                \"step\": timedelta(minutes=15),\n                \"format\": \"HH:mm\",\n            },\n        }\n\n        if min_value is None:\n            min_value = DEFAULTS[data_type][\"min_value\"]\n        if max_value is None:\n            max_value = DEFAULTS[data_type][\"max_value\"]\n        if step is None:\n            step = cast(Step, DEFAULTS[data_type][\"step\"])\n            if data_type in (\n                SliderProto.DATETIME,\n                SliderProto.DATE,\n            ) and max_value - min_value < timedelta(days=1):\n                step = timedelta(minutes=15)\n        if format is None:\n            format = cast(str, DEFAULTS[data_type][\"format\"])\n\n        if step == 0:\n            raise StreamlitAPIException(\n                \"Slider components cannot be passed a `step` of 0.\"\n            )\n\n        # Ensure that all arguments are of the same type.\n        slider_args = [min_value, max_value, step]\n        int_args = all(isinstance(a, Integral) for a in slider_args)\n        float_args = all(\n            isinstance(a, Real) and not isinstance(a, Integral) for a in slider_args\n        )\n        # When min and max_value are the same timelike, step should be a timedelta\n        timelike_args = (\n            data_type in TIMELIKE_TYPES\n            and isinstance(step, timedelta)\n            and type(min_value) == type(max_value)\n        )\n\n        if not int_args and not float_args and not timelike_args:\n            raise StreamlitAPIException(\n                \"Slider value arguments must be of matching types.\"\n                \"\\n`min_value` has %(min_type)s type.\"\n                \"\\n`max_value` has %(max_type)s type.\"\n                \"\\n`step` has %(step)s type.\"\n                % {\n                    \"min_type\": type(min_value).__name__,\n                    \"max_type\": type(max_value).__name__,\n                    \"step\": type(step).__name__,\n                }\n            )\n\n        # Ensure that the value matches arguments' types.\n        all_ints = data_type == SliderProto.INT and int_args\n        all_floats = data_type == SliderProto.FLOAT and float_args\n        all_timelikes = data_type in TIMELIKE_TYPES and timelike_args\n\n        if not all_ints and not all_floats and not all_timelikes:\n            raise StreamlitAPIException(\n                \"Both value and arguments must be of the same type.\"\n                \"\\n`value` has %(value_type)s type.\"\n                \"\\n`min_value` has %(min_type)s type.\"\n                \"\\n`max_value` has %(max_type)s type.\"\n                % {\n                    \"value_type\": type(value).__name__,\n                    \"min_type\": type(min_value).__name__,\n                    \"max_type\": type(max_value).__name__,\n                }\n            )\n\n        # Ensure that min <= value(s) <= max, adjusting the bounds as necessary.\n        min_value = min(min_value, max_value)\n        max_value = max(min_value, max_value)\n        if len(value) == 1:\n            min_value = min(value[0], min_value)\n            max_value = max(value[0], max_value)\n        elif len(value) == 2:\n            start, end = value\n            if start > end:\n                # Swap start and end, since they seem reversed\n                start, end = end, start\n                value = start, end\n            min_value = min(start, min_value)\n            max_value = max(end, max_value)\n        else:\n            # Empty list, so let's just use the outer bounds\n            value = [min_value, max_value]\n\n        # Bounds checks. JSNumber produces human-readable exceptions that\n        # we simply re-package as StreamlitAPIExceptions.\n        # (We check `min_value` and `max_value` here; `value` and `step` are\n        # already known to be in the [min_value, max_value] range.)\n        try:\n            if all_ints:\n                JSNumber.validate_int_bounds(min_value, \"`min_value`\")\n                JSNumber.validate_int_bounds(max_value, \"`max_value`\")\n            elif all_floats:\n                JSNumber.validate_float_bounds(min_value, \"`min_value`\")\n                JSNumber.validate_float_bounds(max_value, \"`max_value`\")\n            elif all_timelikes:\n                # No validation yet. TODO: check between 0001-01-01 to 9999-12-31\n                pass\n        except JSNumberBoundsException as e:\n            raise StreamlitAPIException(str(e))\n\n        orig_tz = None\n        # Convert dates or times into datetimes\n        if data_type == SliderProto.TIME:\n            value = list(map(_time_to_datetime, value))\n            min_value = _time_to_datetime(min_value)\n            max_value = _time_to_datetime(max_value)\n\n        if data_type == SliderProto.DATE:\n            value = list(map(_date_to_datetime, value))\n            min_value = _date_to_datetime(min_value)\n            max_value = _date_to_datetime(max_value)\n\n        # The frontend will error if the values are equal, so checking here\n        # lets us produce a nicer python error message and stack trace.\n        if min_value == max_value:\n            raise StreamlitAPIException(\n                \"Slider `min_value` must be less than the `max_value`.\"\n                f\"\\nThe values were {min_value} and {max_value}.\"\n            )\n\n        # Now, convert to microseconds (so we can serialize datetime to a long)\n        if data_type in TIMELIKE_TYPES:\n            # Restore times/datetimes to original timezone (dates are always naive)\n            orig_tz = (\n                value[0].tzinfo\n                if data_type in (SliderProto.TIME, SliderProto.DATETIME)\n                else None\n            )\n\n            value = list(map(_datetime_to_micros, value))\n            min_value = _datetime_to_micros(min_value)\n            max_value = _datetime_to_micros(max_value)\n            step = _delta_to_micros(cast(timedelta, step))\n\n        # It would be great if we could guess the number of decimal places from\n        # the `step` argument, but this would only be meaningful if step were a\n        # decimal. As a possible improvement we could make this function accept\n        # decimals and/or use some heuristics for floats.\n\n        slider_proto = SliderProto()\n        slider_proto.type = SliderProto.Type.SLIDER\n        slider_proto.id = id\n        slider_proto.label = label\n        slider_proto.format = format\n        slider_proto.default[:] = value\n        slider_proto.min = min_value\n        slider_proto.max = max_value\n        slider_proto.step = cast(float, step)\n        slider_proto.data_type = data_type\n        slider_proto.options[:] = []\n        slider_proto.form_id = current_form_id(self.dg)\n        slider_proto.disabled = disabled\n        slider_proto.label_visibility.value = get_label_visibility_proto_value(\n            label_visibility\n        )\n\n        if help is not None:\n            slider_proto.help = dedent(help)\n\n        serde = SliderSerde(value, data_type, single_value, orig_tz)\n\n        widget_state = register_widget(\n            \"slider\",\n            slider_proto,\n            user_key=key,\n            on_change_handler=on_change,\n            args=args,\n            kwargs=kwargs,\n            deserializer=serde.deserialize,\n            serializer=serde.serialize,\n            ctx=ctx,\n        )\n\n        if widget_state.value_changed:\n            slider_proto.value[:] = serde.serialize(widget_state.value)\n            slider_proto.set_value = True\n\n        self.dg._enqueue(\"slider\", slider_proto)\n        return cast(SliderReturn, widget_state.value)\n\n    @property\n    def dg(self) -> DeltaGenerator:\n        \"\"\"Get our DeltaGenerator.\"\"\"\n        return cast(\"DeltaGenerator\", self)\n", "lib/streamlit/elements/widgets/checkbox.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom dataclasses import dataclass\nfrom textwrap import dedent\nfrom typing import TYPE_CHECKING, cast\n\nfrom streamlit.elements.form import current_form_id\nfrom streamlit.elements.lib.policies import (\n    check_cache_replay_rules,\n    check_callback_rules,\n    check_fragment_path_policy,\n    check_session_state_rules,\n)\nfrom streamlit.elements.lib.utils import get_label_visibility_proto_value\nfrom streamlit.proto.Checkbox_pb2 import Checkbox as CheckboxProto\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.runtime.scriptrunner import ScriptRunContext, get_script_run_ctx\nfrom streamlit.runtime.state import (\n    WidgetArgs,\n    WidgetCallback,\n    WidgetKwargs,\n    register_widget,\n)\nfrom streamlit.runtime.state.common import compute_widget_id\nfrom streamlit.type_util import Key, LabelVisibility, maybe_raise_label_warnings, to_key\n\nif TYPE_CHECKING:\n    from streamlit.delta_generator import DeltaGenerator\n\n\n@dataclass\nclass CheckboxSerde:\n    value: bool\n\n    def serialize(self, v: bool) -> bool:\n        return bool(v)\n\n    def deserialize(self, ui_value: bool | None, widget_id: str = \"\") -> bool:\n        return bool(ui_value if ui_value is not None else self.value)\n\n\nclass CheckboxMixin:\n    @gather_metrics(\"checkbox\")\n    def checkbox(\n        self,\n        label: str,\n        value: bool = False,\n        key: Key | None = None,\n        help: str | None = None,\n        on_change: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        *,  # keyword-only arguments:\n        disabled: bool = False,\n        label_visibility: LabelVisibility = \"visible\",\n    ) -> bool:\n        r\"\"\"Display a checkbox widget.\n\n        Parameters\n        ----------\n        label : str\n            A short label explaining to the user what this checkbox is for.\n            The label can optionally contain Markdown and supports the following\n            elements: Bold, Italics, Strikethroughs, Inline Code, Emojis, and Links.\n\n            This also supports:\n\n            * Emoji shortcodes, such as ``:+1:``  and ``:sunglasses:``.\n              For a list of all supported codes,\n              see https://share.streamlit.io/streamlit/emoji-shortcodes.\n\n            * LaTeX expressions, by wrapping them in \"$\" or \"$$\" (the \"$$\"\n              must be on their own lines). Supported LaTeX functions are listed\n              at https://katex.org/docs/supported.html.\n\n            * Colored text and background colors for text, using the syntax\n              ``:color[text to be colored]`` and ``:color-background[text to be colored]``,\n              respectively. ``color`` must be replaced with any of the following\n              supported colors: blue, green, orange, red, violet, gray/grey, rainbow.\n              For example, you can use ``:orange[your text here]`` or\n              ``:blue-background[your text here]``.\n\n            Unsupported elements are unwrapped so only their children (text contents) render.\n            Display unsupported elements as literal characters by\n            backslash-escaping them. E.g. ``1\\. Not an ordered list``.\n\n            For accessibility reasons, you should never set an empty label (label=\"\")\n            but hide it with label_visibility if needed. In the future, we may disallow\n            empty labels by raising an exception.\n        value : bool\n            Preselect the checkbox when it first renders. This will be\n            cast to bool internally.\n        key : str or int\n            An optional string or integer to use as the unique key for the widget.\n            If this is omitted, a key will be generated for the widget\n            based on its content. Multiple widgets of the same type may\n            not share the same key.\n        help : str\n            An optional tooltip that gets displayed next to the checkbox.\n        on_change : callable\n            An optional callback invoked when this checkbox's value changes.\n        args : tuple\n            An optional tuple of args to pass to the callback.\n        kwargs : dict\n            An optional dict of kwargs to pass to the callback.\n        disabled : bool\n            An optional boolean, which disables the checkbox if set to True.\n            The default is False.\n        label_visibility : \"visible\", \"hidden\", or \"collapsed\"\n            The visibility of the label. If \"hidden\", the label doesn't show but there\n            is still empty space for it (equivalent to label=\"\").\n            If \"collapsed\", both the label and the space are removed. Default is\n            \"visible\".\n\n        Returns\n        -------\n        bool\n            Whether or not the checkbox is checked.\n\n        Example\n        -------\n        >>> import streamlit as st\n        >>>\n        >>> agree = st.checkbox(\"I agree\")\n        >>>\n        >>> if agree:\n        ...     st.write(\"Great!\")\n\n        .. output::\n           https://doc-checkbox.streamlit.app/\n           height: 220px\n\n        \"\"\"\n        ctx = get_script_run_ctx()\n        return self._checkbox(\n            label=label,\n            value=value,\n            key=key,\n            help=help,\n            on_change=on_change,\n            args=args,\n            kwargs=kwargs,\n            disabled=disabled,\n            label_visibility=label_visibility,\n            type=CheckboxProto.StyleType.DEFAULT,\n            ctx=ctx,\n        )\n\n    @gather_metrics(\"toggle\")\n    def toggle(\n        self,\n        label: str,\n        value: bool = False,\n        key: Key | None = None,\n        help: str | None = None,\n        on_change: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        *,  # keyword-only arguments:\n        disabled: bool = False,\n        label_visibility: LabelVisibility = \"visible\",\n    ) -> bool:\n        r\"\"\"Display a toggle widget.\n\n        Parameters\n        ----------\n        label : str\n            A short label explaining to the user what this toggle is for.\n            The label can optionally contain Markdown and supports the following\n            elements: Bold, Italics, Strikethroughs, Inline Code, Emojis, and Links.\n\n            This also supports:\n\n            * Emoji shortcodes, such as ``:+1:``  and ``:sunglasses:``.\n              For a list of all supported codes,\n              see https://share.streamlit.io/streamlit/emoji-shortcodes.\n\n            * LaTeX expressions, by wrapping them in \"$\" or \"$$\" (the \"$$\"\n              must be on their own lines). Supported LaTeX functions are listed\n              at https://katex.org/docs/supported.html.\n\n            * Colored text and background colors for text, using the syntax\n              ``:color[text to be colored]`` and ``:color-background[text to be colored]``,\n              respectively. ``color`` must be replaced with any of the following\n              supported colors: blue, green, orange, red, violet, gray/grey, rainbow.\n              For example, you can use ``:orange[your text here]`` or\n              ``:blue-background[your text here]``.\n\n            Unsupported elements are unwrapped so only their children (text contents) render.\n            Display unsupported elements as literal characters by\n            backslash-escaping them. E.g. ``1\\. Not an ordered list``.\n\n            For accessibility reasons, you should never set an empty label (label=\"\")\n            but hide it with label_visibility if needed. In the future, we may disallow\n            empty labels by raising an exception.\n        value : bool\n            Preselect the toggle when it first renders. This will be\n            cast to bool internally.\n        key : str or int\n            An optional string or integer to use as the unique key for the widget.\n            If this is omitted, a key will be generated for the widget\n            based on its content. Multiple widgets of the same type may\n            not share the same key.\n        help : str\n            An optional tooltip that gets displayed next to the toggle.\n        on_change : callable\n            An optional callback invoked when this toggle's value changes.\n        args : tuple\n            An optional tuple of args to pass to the callback.\n        kwargs : dict\n            An optional dict of kwargs to pass to the callback.\n        disabled : bool\n            An optional boolean, which disables the toggle if set to True.\n            The default is False.\n        label_visibility : \"visible\", \"hidden\", or \"collapsed\"\n            The visibility of the label. If \"hidden\", the label doesn't show but there\n            is still empty space for it (equivalent to label=\"\").\n            If \"collapsed\", both the label and the space are removed. Default is\n            \"visible\".\n\n        Returns\n        -------\n        bool\n            Whether or not the toggle is checked.\n\n        Example\n        -------\n        >>> import streamlit as st\n        >>>\n        >>> on = st.toggle(\"Activate feature\")\n        >>>\n        >>> if on:\n        ...     st.write(\"Feature activated!\")\n\n        .. output::\n           https://doc-toggle.streamlit.app/\n           height: 220px\n\n        \"\"\"\n        ctx = get_script_run_ctx()\n        return self._checkbox(\n            label=label,\n            value=value,\n            key=key,\n            help=help,\n            on_change=on_change,\n            args=args,\n            kwargs=kwargs,\n            disabled=disabled,\n            label_visibility=label_visibility,\n            type=CheckboxProto.StyleType.TOGGLE,\n            ctx=ctx,\n        )\n\n    def _checkbox(\n        self,\n        label: str,\n        value: bool = False,\n        key: Key | None = None,\n        help: str | None = None,\n        on_change: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        *,  # keyword-only arguments:\n        disabled: bool = False,\n        label_visibility: LabelVisibility = \"visible\",\n        type: CheckboxProto.StyleType.ValueType = CheckboxProto.StyleType.DEFAULT,\n        ctx: ScriptRunContext | None = None,\n    ) -> bool:\n        key = to_key(key)\n\n        check_fragment_path_policy(self.dg)\n        check_cache_replay_rules()\n        check_callback_rules(self.dg, on_change)\n        check_session_state_rules(\n            default_value=None if value is False else value, key=key\n        )\n        maybe_raise_label_warnings(label, label_visibility)\n\n        id = compute_widget_id(\n            \"toggle\" if type == CheckboxProto.StyleType.TOGGLE else \"checkbox\",\n            user_key=key,\n            label=label,\n            value=bool(value),\n            key=key,\n            help=help,\n            form_id=current_form_id(self.dg),\n            page=ctx.active_script_hash if ctx else None,\n        )\n\n        checkbox_proto = CheckboxProto()\n        checkbox_proto.id = id\n        checkbox_proto.label = label\n        checkbox_proto.default = bool(value)\n        checkbox_proto.type = type\n        checkbox_proto.form_id = current_form_id(self.dg)\n        checkbox_proto.disabled = disabled\n        checkbox_proto.label_visibility.value = get_label_visibility_proto_value(\n            label_visibility\n        )\n\n        if help is not None:\n            checkbox_proto.help = dedent(help)\n\n        serde = CheckboxSerde(value)\n\n        checkbox_state = register_widget(\n            \"checkbox\",\n            checkbox_proto,\n            user_key=key,\n            on_change_handler=on_change,\n            args=args,\n            kwargs=kwargs,\n            deserializer=serde.deserialize,\n            serializer=serde.serialize,\n            ctx=ctx,\n        )\n\n        if checkbox_state.value_changed:\n            checkbox_proto.value = checkbox_state.value\n            checkbox_proto.set_value = True\n\n        self.dg._enqueue(\"checkbox\", checkbox_proto)\n        return checkbox_state.value\n\n    @property\n    def dg(self) -> DeltaGenerator:\n        \"\"\"Get our DeltaGenerator.\"\"\"\n        return cast(\"DeltaGenerator\", self)\n", "lib/streamlit/elements/widgets/radio.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom dataclasses import dataclass\nfrom textwrap import dedent\nfrom typing import TYPE_CHECKING, Any, Callable, Generic, Sequence, cast\n\nfrom streamlit.elements.form import current_form_id\nfrom streamlit.elements.lib.policies import (\n    check_cache_replay_rules,\n    check_callback_rules,\n    check_fragment_path_policy,\n    check_session_state_rules,\n)\nfrom streamlit.elements.lib.utils import (\n    get_label_visibility_proto_value,\n    maybe_coerce_enum,\n)\nfrom streamlit.errors import StreamlitAPIException\nfrom streamlit.proto.Radio_pb2 import Radio as RadioProto\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.runtime.scriptrunner import ScriptRunContext, get_script_run_ctx\nfrom streamlit.runtime.state import (\n    WidgetArgs,\n    WidgetCallback,\n    WidgetKwargs,\n    get_session_state,\n    register_widget,\n)\nfrom streamlit.runtime.state.common import compute_widget_id, save_for_app_testing\nfrom streamlit.type_util import (\n    Key,\n    LabelVisibility,\n    OptionSequence,\n    T,\n    check_python_comparable,\n    ensure_indexable,\n    maybe_raise_label_warnings,\n    to_key,\n)\nfrom streamlit.util import index_\n\nif TYPE_CHECKING:\n    from streamlit.delta_generator import DeltaGenerator\n\n\n@dataclass\nclass RadioSerde(Generic[T]):\n    options: Sequence[T]\n    index: int | None\n\n    def serialize(self, v: object) -> int | None:\n        if v is None:\n            return None\n\n        return 0 if len(self.options) == 0 else index_(self.options, v)\n\n    def deserialize(\n        self,\n        ui_value: int | None,\n        widget_id: str = \"\",\n    ) -> T | None:\n        idx = ui_value if ui_value is not None else self.index\n\n        return (\n            self.options[idx]\n            if idx is not None\n            and len(self.options) > 0\n            and self.options[idx] is not None\n            else None\n        )\n\n\nclass RadioMixin:\n    @gather_metrics(\"radio\")\n    def radio(\n        self,\n        label: str,\n        options: OptionSequence[T],\n        index: int | None = 0,\n        format_func: Callable[[Any], Any] = str,\n        key: Key | None = None,\n        help: str | None = None,\n        on_change: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        *,  # keyword-only args:\n        disabled: bool = False,\n        horizontal: bool = False,\n        captions: Sequence[str] | None = None,\n        label_visibility: LabelVisibility = \"visible\",\n    ) -> T | None:\n        r\"\"\"Display a radio button widget.\n\n        Parameters\n        ----------\n        label : str\n            A short label explaining to the user what this radio group is for.\n            The label can optionally contain Markdown and supports the following\n            elements: Bold, Italics, Strikethroughs, Inline Code, Emojis, and Links.\n\n            This also supports:\n\n            * Emoji shortcodes, such as ``:+1:``  and ``:sunglasses:``.\n              For a list of all supported codes,\n              see https://share.streamlit.io/streamlit/emoji-shortcodes.\n\n            * LaTeX expressions, by wrapping them in \"$\" or \"$$\" (the \"$$\"\n              must be on their own lines). Supported LaTeX functions are listed\n              at https://katex.org/docs/supported.html.\n\n            * Colored text and background colors for text, using the syntax\n              ``:color[text to be colored]`` and ``:color-background[text to be colored]``,\n              respectively. ``color`` must be replaced with any of the following\n              supported colors: blue, green, orange, red, violet, gray/grey, rainbow.\n              For example, you can use ``:orange[your text here]`` or\n              ``:blue-background[your text here]``.\n\n            Unsupported elements are unwrapped so only their children (text contents) render.\n            Display unsupported elements as literal characters by\n            backslash-escaping them. E.g. ``1\\. Not an ordered list``.\n\n            For accessibility reasons, you should never set an empty label (label=\"\")\n            but hide it with label_visibility if needed. In the future, we may disallow\n            empty labels by raising an exception.\n        options : Iterable\n            Labels for the select options in an Iterable. For example, this can\n            be a list, numpy.ndarray, pandas.Series, pandas.DataFrame, or\n            pandas.Index. For pandas.DataFrame, the first column is used.\n\n            Labels can include markdown as described in the ``label`` parameter\n            and will be cast to str internally by default.\n        index : int or None\n            The index of the preselected option on first render. If ``None``,\n            will initialize empty and return ``None`` until the user selects an option.\n            Defaults to 0 (the first option).\n        format_func : function\n            Function to modify the display of radio options. It receives\n            the raw option as an argument and should output the label to be\n            shown for that option. This has no impact on the return value of\n            the radio.\n        key : str or int\n            An optional string or integer to use as the unique key for the widget.\n            If this is omitted, a key will be generated for the widget\n            based on its content. Multiple widgets of the same type may\n            not share the same key.\n        help : str\n            An optional tooltip that gets displayed next to the radio.\n        on_change : callable\n            An optional callback invoked when this radio's value changes.\n        args : tuple\n            An optional tuple of args to pass to the callback.\n        kwargs : dict\n            An optional dict of kwargs to pass to the callback.\n        disabled : bool\n            An optional boolean, which disables the radio button if set to\n            True. The default is False.\n        horizontal : bool\n            An optional boolean, which orients the radio group horizontally.\n            The default is false (vertical buttons).\n        captions : iterable of str or None\n            A list of captions to show below each radio button. If None (default),\n            no captions are shown.\n        label_visibility : \"visible\", \"hidden\", or \"collapsed\"\n            The visibility of the label. If \"hidden\", the label doesn't show but there\n            is still empty space for it above the widget (equivalent to label=\"\").\n            If \"collapsed\", both the label and the space are removed. Default is\n            \"visible\".\n\n        Returns\n        -------\n        any\n            The selected option or ``None`` if no option is selected.\n\n        Example\n        -------\n        >>> import streamlit as st\n        >>>\n        >>> genre = st.radio(\n        ...     \"What's your favorite movie genre\",\n        ...     [\":rainbow[Comedy]\", \"***Drama***\", \"Documentary :movie_camera:\"],\n        ...     captions = [\"Laugh out loud.\", \"Get the popcorn.\", \"Never stop learning.\"])\n        >>>\n        >>> if genre == \":rainbow[Comedy]\":\n        ...     st.write(\"You selected comedy.\")\n        ... else:\n        ...     st.write(\"You didn't select comedy.\")\n\n        .. output::\n           https://doc-radio.streamlit.app/\n           height: 300px\n\n        To initialize an empty radio widget, use ``None`` as the index value:\n\n        >>> import streamlit as st\n        >>>\n        >>> genre = st.radio(\n        ...     \"What's your favorite movie genre\",\n        ...     [\":rainbow[Comedy]\", \"***Drama***\", \"Documentary :movie_camera:\"],\n        ...     index=None,\n        ... )\n        >>>\n        >>> st.write(\"You selected:\", genre)\n\n        .. output::\n           https://doc-radio-empty.streamlit.app/\n           height: 300px\n\n        \"\"\"\n        ctx = get_script_run_ctx()\n        return self._radio(\n            label=label,\n            options=options,\n            index=index,\n            format_func=format_func,\n            key=key,\n            help=help,\n            on_change=on_change,\n            args=args,\n            kwargs=kwargs,\n            disabled=disabled,\n            horizontal=horizontal,\n            captions=captions,\n            label_visibility=label_visibility,\n            ctx=ctx,\n        )\n\n    def _radio(\n        self,\n        label: str,\n        options: OptionSequence[T],\n        index: int | None = 0,\n        format_func: Callable[[Any], Any] = str,\n        key: Key | None = None,\n        help: str | None = None,\n        on_change: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        *,  # keyword-only args:\n        disabled: bool = False,\n        horizontal: bool = False,\n        label_visibility: LabelVisibility = \"visible\",\n        captions: Sequence[str] | None = None,\n        ctx: ScriptRunContext | None,\n    ) -> T | None:\n        key = to_key(key)\n\n        check_fragment_path_policy(self.dg)\n        check_cache_replay_rules()\n        check_callback_rules(self.dg, on_change)\n        check_session_state_rules(default_value=None if index == 0 else index, key=key)\n        maybe_raise_label_warnings(label, label_visibility)\n\n        opt = ensure_indexable(options)\n        check_python_comparable(opt)\n\n        id = compute_widget_id(\n            \"radio\",\n            user_key=key,\n            label=label,\n            options=[str(format_func(option)) for option in opt],\n            index=index,\n            key=key,\n            help=help,\n            horizontal=horizontal,\n            captions=captions,\n            form_id=current_form_id(self.dg),\n            page=ctx.active_script_hash if ctx else None,\n        )\n\n        if not isinstance(index, int) and index is not None:\n            raise StreamlitAPIException(\n                \"Radio Value has invalid type: %s\" % type(index).__name__\n            )\n\n        if index is not None and len(opt) > 0 and not 0 <= index < len(opt):\n            raise StreamlitAPIException(\n                \"Radio index must be between 0 and length of options\"\n            )\n\n        def handle_captions(caption: str | None) -> str:\n            if caption is None:\n                return \"\"\n            elif isinstance(caption, str):\n                return caption\n            else:\n                raise StreamlitAPIException(\n                    f\"Radio captions must be strings. Passed type: {type(caption).__name__}\"\n                )\n\n        session_state = get_session_state().filtered_state\n        if key is not None and key in session_state and session_state[key] is None:\n            index = None\n\n        radio_proto = RadioProto()\n        radio_proto.id = id\n        radio_proto.label = label\n        if index is not None:\n            radio_proto.default = index\n        radio_proto.options[:] = [str(format_func(option)) for option in opt]\n        radio_proto.form_id = current_form_id(self.dg)\n        radio_proto.horizontal = horizontal\n        radio_proto.disabled = disabled\n        radio_proto.label_visibility.value = get_label_visibility_proto_value(\n            label_visibility\n        )\n\n        if captions is not None:\n            radio_proto.captions[:] = map(handle_captions, captions)\n\n        if help is not None:\n            radio_proto.help = dedent(help)\n\n        serde = RadioSerde(opt, index)\n\n        widget_state = register_widget(\n            \"radio\",\n            radio_proto,\n            user_key=key,\n            on_change_handler=on_change,\n            args=args,\n            kwargs=kwargs,\n            deserializer=serde.deserialize,\n            serializer=serde.serialize,\n            ctx=ctx,\n        )\n        widget_state = maybe_coerce_enum(widget_state, options, opt)\n\n        if widget_state.value_changed:\n            if widget_state.value is not None:\n                serialized_value = serde.serialize(widget_state.value)\n                if serialized_value is not None:\n                    radio_proto.value = serialized_value\n            radio_proto.set_value = True\n\n        if ctx:\n            save_for_app_testing(ctx, id, format_func)\n        self.dg._enqueue(\"radio\", radio_proto)\n        return widget_state.value\n\n    @property\n    def dg(self) -> DeltaGenerator:\n        \"\"\"Get our DeltaGenerator.\"\"\"\n        return cast(\"DeltaGenerator\", self)\n", "lib/streamlit/elements/widgets/multiselect.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom dataclasses import dataclass\nfrom textwrap import dedent\nfrom typing import TYPE_CHECKING, Any, Callable, Generic, Sequence, cast, overload\n\nfrom streamlit.elements.form import current_form_id\nfrom streamlit.elements.lib.policies import (\n    check_cache_replay_rules,\n    check_callback_rules,\n    check_fragment_path_policy,\n    check_session_state_rules,\n)\nfrom streamlit.elements.lib.utils import (\n    get_label_visibility_proto_value,\n    maybe_coerce_enum_sequence,\n)\nfrom streamlit.errors import StreamlitAPIException\nfrom streamlit.proto.MultiSelect_pb2 import MultiSelect as MultiSelectProto\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.runtime.scriptrunner import ScriptRunContext, get_script_run_ctx\nfrom streamlit.runtime.state import (\n    WidgetArgs,\n    WidgetCallback,\n    WidgetKwargs,\n    register_widget,\n)\nfrom streamlit.runtime.state.common import compute_widget_id, save_for_app_testing\nfrom streamlit.type_util import (\n    Key,\n    LabelVisibility,\n    OptionSequence,\n    T,\n    check_python_comparable,\n    ensure_indexable,\n    is_iterable,\n    is_type,\n    maybe_raise_label_warnings,\n    to_key,\n)\n\nif TYPE_CHECKING:\n    from streamlit.delta_generator import DeltaGenerator\n\n\n@overload\ndef _check_and_convert_to_indices(  # type: ignore[misc]\n    opt: Sequence[Any], default_values: None\n) -> list[int] | None: ...\n\n\n@overload\ndef _check_and_convert_to_indices(\n    opt: Sequence[Any], default_values: Sequence[Any] | Any\n) -> list[int]: ...\n\n\ndef _check_and_convert_to_indices(\n    opt: Sequence[Any], default_values: Sequence[Any] | Any | None\n) -> list[int] | None:\n    \"\"\"Perform validation checks and return indices based on the default values.\"\"\"\n    if default_values is None and None not in opt:\n        return None\n\n    if not isinstance(default_values, list):\n        # This if is done before others because calling if not x (done\n        # right below) when x is of type pd.Series() or np.array() throws a\n        # ValueError exception.\n        if is_type(default_values, \"numpy.ndarray\") or is_type(\n            default_values, \"pandas.core.series.Series\"\n        ):\n            default_values = list(cast(Sequence[Any], default_values))\n        elif (\n            isinstance(default_values, (tuple, set))\n            or default_values\n            and default_values not in opt\n        ):\n            default_values = list(default_values)\n        else:\n            default_values = [default_values]\n    for value in default_values:\n        if value not in opt:\n            raise StreamlitAPIException(\n                f\"The default value '{value}' is part of the options. \"\n                \"Please make sure that every default values also exists in the options.\"\n            )\n\n    return [opt.index(value) for value in default_values]\n\n\ndef _get_default_count(default: Sequence[Any] | Any | None) -> int:\n    if default is None:\n        return 0\n    if not is_iterable(default):\n        return 1\n    return len(cast(Sequence[Any], default))\n\n\ndef _get_over_max_options_message(current_selections: int, max_selections: int):\n    curr_selections_noun = \"option\" if current_selections == 1 else \"options\"\n    max_selections_noun = \"option\" if max_selections == 1 else \"options\"\n    return f\"\"\"\nMultiselect has {current_selections} {curr_selections_noun} selected but `max_selections`\nis set to {max_selections}. This happened because you either gave too many options to `default`\nor you manipulated the widget's state through `st.session_state`. Note that\nthe latter can happen before the line indicated in the traceback.\nPlease select at most {max_selections} {max_selections_noun}.\n\"\"\"\n\n\n@dataclass\nclass MultiSelectSerde(Generic[T]):\n    options: Sequence[T]\n    default_value: list[int]\n\n    def serialize(self, value: list[T]) -> list[int]:\n        return _check_and_convert_to_indices(self.options, value)\n\n    def deserialize(\n        self,\n        ui_value: list[int] | None,\n        widget_id: str = \"\",\n    ) -> list[T]:\n        current_value: list[int] = (\n            ui_value if ui_value is not None else self.default_value\n        )\n        return [self.options[i] for i in current_value]\n\n\nclass MultiSelectMixin:\n    @gather_metrics(\"multiselect\")\n    def multiselect(\n        self,\n        label: str,\n        options: OptionSequence[T],\n        default: Any | None = None,\n        format_func: Callable[[Any], Any] = str,\n        key: Key | None = None,\n        help: str | None = None,\n        on_change: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        *,  # keyword-only arguments:\n        max_selections: int | None = None,\n        placeholder: str = \"Choose an option\",\n        disabled: bool = False,\n        label_visibility: LabelVisibility = \"visible\",\n    ) -> list[T]:\n        r\"\"\"Display a multiselect widget.\n        The multiselect widget starts as empty.\n\n        Parameters\n        ----------\n        label : str\n            A short label explaining to the user what this select widget is for.\n            The label can optionally contain Markdown and supports the following\n            elements: Bold, Italics, Strikethroughs, Inline Code, Emojis, and Links.\n\n            This also supports:\n\n            * Emoji shortcodes, such as ``:+1:``  and ``:sunglasses:``.\n              For a list of all supported codes,\n              see https://share.streamlit.io/streamlit/emoji-shortcodes.\n\n            * LaTeX expressions, by wrapping them in \"$\" or \"$$\" (the \"$$\"\n              must be on their own lines). Supported LaTeX functions are listed\n              at https://katex.org/docs/supported.html.\n\n            * Colored text and background colors for text, using the syntax\n              ``:color[text to be colored]`` and ``:color-background[text to be colored]``,\n              respectively. ``color`` must be replaced with any of the following\n              supported colors: blue, green, orange, red, violet, gray/grey, rainbow.\n              For example, you can use ``:orange[your text here]`` or\n              ``:blue-background[your text here]``.\n\n            Unsupported elements are unwrapped so only their children (text contents) render.\n            Display unsupported elements as literal characters by\n            backslash-escaping them. E.g. ``1\\. Not an ordered list``.\n\n            For accessibility reasons, you should never set an empty label (label=\"\")\n            but hide it with label_visibility if needed. In the future, we may disallow\n            empty labels by raising an exception.\n        options : Iterable\n            Labels for the select options in an Iterable. For example, this can\n            be a list, numpy.ndarray, pandas.Series, pandas.DataFrame, or\n            pandas.Index. For pandas.DataFrame, the first column is used.\n            Each label will be cast to str internally by default.\n        default: Iterable of V, V, or None\n            List of default values. Can also be a single value.\n        format_func : function\n            Function to modify the display of selectbox options. It receives\n            the raw option as an argument and should output the label to be\n            shown for that option. This has no impact on the return value of\n            the multiselect.\n        key : str or int\n            An optional string or integer to use as the unique key for the widget.\n            If this is omitted, a key will be generated for the widget\n            based on its content. Multiple widgets of the same type may\n            not share the same key.\n        help : str\n            An optional tooltip that gets displayed next to the multiselect.\n        on_change : callable\n            An optional callback invoked when this multiselect's value changes.\n        args : tuple\n            An optional tuple of args to pass to the callback.\n        kwargs : dict\n            An optional dict of kwargs to pass to the callback.\n        max_selections : int\n            The max selections that can be selected at a time.\n        placeholder : str\n            A string to display when no options are selected. Defaults to 'Choose an option'.\n        disabled : bool\n            An optional boolean, which disables the multiselect widget if set\n            to True. The default is False. This argument can only be supplied\n            by keyword.\n        label_visibility : \"visible\", \"hidden\", or \"collapsed\"\n            The visibility of the label. If \"hidden\", the label doesn't show but there\n            is still empty space for it above the widget (equivalent to label=\"\").\n            If \"collapsed\", both the label and the space are removed. Default is\n            \"visible\".\n\n        Returns\n        -------\n        list\n            A list with the selected options\n\n        Example\n        -------\n        >>> import streamlit as st\n        >>>\n        >>> options = st.multiselect(\n        ...     \"What are your favorite colors\",\n        ...     [\"Green\", \"Yellow\", \"Red\", \"Blue\"],\n        ...     [\"Yellow\", \"Red\"])\n        >>>\n        >>> st.write(\"You selected:\", options)\n\n        .. output::\n           https://doc-multiselect.streamlit.app/\n           height: 420px\n\n        \"\"\"\n        ctx = get_script_run_ctx()\n        return self._multiselect(\n            label=label,\n            options=options,\n            default=default,\n            format_func=format_func,\n            key=key,\n            help=help,\n            on_change=on_change,\n            args=args,\n            kwargs=kwargs,\n            max_selections=max_selections,\n            placeholder=placeholder,\n            disabled=disabled,\n            label_visibility=label_visibility,\n            ctx=ctx,\n        )\n\n    def _multiselect(\n        self,\n        label: str,\n        options: OptionSequence[T],\n        default: Sequence[Any] | Any | None = None,\n        format_func: Callable[[Any], Any] = str,\n        key: Key | None = None,\n        help: str | None = None,\n        on_change: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        *,  # keyword-only arguments:\n        max_selections: int | None = None,\n        placeholder: str = \"Choose an option\",\n        disabled: bool = False,\n        label_visibility: LabelVisibility = \"visible\",\n        ctx: ScriptRunContext | None = None,\n    ) -> list[T]:\n        key = to_key(key)\n\n        check_fragment_path_policy(self.dg)\n        check_cache_replay_rules()\n        check_callback_rules(self.dg, on_change)\n        check_session_state_rules(default_value=default, key=key)\n        maybe_raise_label_warnings(label, label_visibility)\n\n        opt = ensure_indexable(options)\n        check_python_comparable(opt)\n\n        indices = _check_and_convert_to_indices(opt, default)\n\n        id = compute_widget_id(\n            \"multiselect\",\n            user_key=key,\n            label=label,\n            options=[str(format_func(option)) for option in opt],\n            default=indices,\n            key=key,\n            help=help,\n            max_selections=max_selections,\n            placeholder=placeholder,\n            form_id=current_form_id(self.dg),\n            page=ctx.active_script_hash if ctx else None,\n        )\n\n        default_value: list[int] = [] if indices is None else indices\n\n        multiselect_proto = MultiSelectProto()\n        multiselect_proto.id = id\n        multiselect_proto.label = label\n        multiselect_proto.default[:] = default_value\n        multiselect_proto.options[:] = [str(format_func(option)) for option in opt]\n        multiselect_proto.form_id = current_form_id(self.dg)\n        multiselect_proto.max_selections = max_selections or 0\n        multiselect_proto.placeholder = placeholder\n        multiselect_proto.disabled = disabled\n        multiselect_proto.label_visibility.value = get_label_visibility_proto_value(\n            label_visibility\n        )\n\n        if help is not None:\n            multiselect_proto.help = dedent(help)\n\n        serde = MultiSelectSerde(opt, default_value)\n\n        widget_state = register_widget(\n            \"multiselect\",\n            multiselect_proto,\n            user_key=key,\n            on_change_handler=on_change,\n            args=args,\n            kwargs=kwargs,\n            deserializer=serde.deserialize,\n            serializer=serde.serialize,\n            ctx=ctx,\n        )\n        default_count = _get_default_count(widget_state.value)\n        if max_selections and default_count > max_selections:\n            raise StreamlitAPIException(\n                _get_over_max_options_message(default_count, max_selections)\n            )\n        widget_state = maybe_coerce_enum_sequence(widget_state, options, opt)\n\n        if widget_state.value_changed:\n            multiselect_proto.value[:] = serde.serialize(widget_state.value)\n            multiselect_proto.set_value = True\n\n        if ctx:\n            save_for_app_testing(ctx, id, format_func)\n        self.dg._enqueue(\"multiselect\", multiselect_proto)\n        return widget_state.value\n\n    @property\n    def dg(self) -> DeltaGenerator:\n        \"\"\"Get our DeltaGenerator.\"\"\"\n        return cast(\"DeltaGenerator\", self)\n", "lib/streamlit/elements/widgets/file_uploader.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom dataclasses import dataclass\nfrom textwrap import dedent\nfrom typing import TYPE_CHECKING, List, Literal, Sequence, Union, cast, overload\n\nfrom typing_extensions import TypeAlias\n\nfrom streamlit import config\nfrom streamlit.elements.form import current_form_id\nfrom streamlit.elements.lib.policies import (\n    check_cache_replay_rules,\n    check_callback_rules,\n    check_fragment_path_policy,\n    check_session_state_rules,\n)\nfrom streamlit.elements.lib.utils import get_label_visibility_proto_value\nfrom streamlit.proto.Common_pb2 import FileUploaderState as FileUploaderStateProto\nfrom streamlit.proto.Common_pb2 import UploadedFileInfo as UploadedFileInfoProto\nfrom streamlit.proto.FileUploader_pb2 import FileUploader as FileUploaderProto\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.runtime.scriptrunner import ScriptRunContext, get_script_run_ctx\nfrom streamlit.runtime.state import (\n    WidgetArgs,\n    WidgetCallback,\n    WidgetKwargs,\n    register_widget,\n)\nfrom streamlit.runtime.state.common import compute_widget_id\nfrom streamlit.runtime.uploaded_file_manager import DeletedFile, UploadedFile\nfrom streamlit.type_util import Key, LabelVisibility, maybe_raise_label_warnings, to_key\n\nif TYPE_CHECKING:\n    from streamlit.delta_generator import DeltaGenerator\n\nSomeUploadedFiles: TypeAlias = Union[\n    UploadedFile,\n    DeletedFile,\n    List[Union[UploadedFile, DeletedFile]],\n    None,\n]\n\n\nTYPE_PAIRS = [\n    (\".jpg\", \".jpeg\"),\n    (\".mpg\", \".mpeg\"),\n    (\".mp4\", \".mpeg4\"),\n    (\".tif\", \".tiff\"),\n    (\".htm\", \".html\"),\n]\n\n\ndef _get_upload_files(\n    widget_value: FileUploaderStateProto | None,\n) -> list[UploadedFile | DeletedFile]:\n    if widget_value is None:\n        return []\n\n    ctx = get_script_run_ctx()\n    if ctx is None:\n        return []\n\n    uploaded_file_info = widget_value.uploaded_file_info\n    if len(uploaded_file_info) == 0:\n        return []\n\n    file_recs_list = ctx.uploaded_file_mgr.get_files(\n        session_id=ctx.session_id,\n        file_ids=[f.file_id for f in uploaded_file_info],\n    )\n\n    file_recs = {f.file_id: f for f in file_recs_list}\n\n    collected_files: list[UploadedFile | DeletedFile] = []\n\n    for f in uploaded_file_info:\n        maybe_file_rec = file_recs.get(f.file_id)\n        if maybe_file_rec is not None:\n            uploaded_file = UploadedFile(maybe_file_rec, f.file_urls)\n            collected_files.append(uploaded_file)\n        else:\n            collected_files.append(DeletedFile(f.file_id))\n\n    return collected_files\n\n\n@dataclass\nclass FileUploaderSerde:\n    accept_multiple_files: bool\n\n    def deserialize(\n        self, ui_value: FileUploaderStateProto | None, widget_id: str\n    ) -> SomeUploadedFiles:\n        upload_files = _get_upload_files(ui_value)\n\n        if len(upload_files) == 0:\n            return_value: SomeUploadedFiles = [] if self.accept_multiple_files else None\n        else:\n            return_value = (\n                upload_files if self.accept_multiple_files else upload_files[0]\n            )\n        return return_value\n\n    def serialize(self, files: SomeUploadedFiles) -> FileUploaderStateProto:\n        state_proto = FileUploaderStateProto()\n\n        if not files:\n            return state_proto\n        elif not isinstance(files, list):\n            files = [files]\n\n        for f in files:\n            if isinstance(f, DeletedFile):\n                continue\n            file_info: UploadedFileInfoProto = state_proto.uploaded_file_info.add()\n            file_info.file_id = f.file_id\n            file_info.name = f.name\n            file_info.size = f.size\n            file_info.file_urls.CopyFrom(f._file_urls)\n\n        return state_proto\n\n\nclass FileUploaderMixin:\n    # Multiple overloads are defined on `file_uploader()` below to represent\n    # the different return types of `file_uploader()`.\n    # These return types differ according to the value of the `accept_multiple_files` argument.\n    # There are 2 associated variables, each with 2 options.\n    # 1. The `accept_multiple_files` argument is set as `True`,\n    #    or it is set as `False` or omitted, in which case the default value `False`.\n    # 2. The `type` argument may or may not be provided as a keyword-only argument.\n    # There must be 2x2=4 overloads to cover all the possible arguments,\n    # as these overloads must be mutually exclusive for mypy.\n\n    # 1. type is given as not a keyword-only argument\n    # 2. accept_multiple_files = True\n    @overload\n    def file_uploader(\n        self,\n        label: str,\n        type: str | Sequence[str] | None,\n        accept_multiple_files: Literal[True],\n        key: Key | None = None,\n        help: str | None = None,\n        on_change: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        *,\n        disabled: bool = False,\n        label_visibility: LabelVisibility = \"visible\",\n    ) -> list[UploadedFile] | None: ...\n\n    # 1. type is given as not a keyword-only argument\n    # 2. accept_multiple_files = False or omitted\n    @overload\n    def file_uploader(\n        self,\n        label: str,\n        type: str | Sequence[str] | None,\n        accept_multiple_files: Literal[False] = False,\n        key: Key | None = None,\n        help: str | None = None,\n        on_change: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        *,\n        disabled: bool = False,\n        label_visibility: LabelVisibility = \"visible\",\n    ) -> UploadedFile | None: ...\n\n    # The following 2 overloads represent the cases where\n    # the `type` argument is a keyword-only argument.\n    # See https://github.com/python/mypy/issues/4020#issuecomment-737600893\n    # for the related discussions and examples.\n\n    # 1. type is skipped or a keyword argument\n    # 2. accept_multiple_files = True\n    @overload\n    def file_uploader(\n        self,\n        label: str,\n        *,\n        accept_multiple_files: Literal[True],\n        type: str | Sequence[str] | None = None,\n        key: Key | None = None,\n        help: str | None = None,\n        on_change: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        disabled: bool = False,\n        label_visibility: LabelVisibility = \"visible\",\n    ) -> list[UploadedFile] | None: ...\n\n    # 1. type is skipped or a keyword argument\n    # 2. accept_multiple_files = False or omitted\n    @overload\n    def file_uploader(\n        self,\n        label: str,\n        *,\n        accept_multiple_files: Literal[False] = False,\n        type: str | Sequence[str] | None = None,\n        key: Key | None = None,\n        help: str | None = None,\n        on_change: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        disabled: bool = False,\n        label_visibility: LabelVisibility = \"visible\",\n    ) -> UploadedFile | None: ...\n\n    @gather_metrics(\"file_uploader\")\n    def file_uploader(\n        self,\n        label: str,\n        type: str | Sequence[str] | None = None,\n        accept_multiple_files: bool = False,\n        key: Key | None = None,\n        help: str | None = None,\n        on_change: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        *,  # keyword-only arguments:\n        disabled: bool = False,\n        label_visibility: LabelVisibility = \"visible\",\n    ) -> UploadedFile | list[UploadedFile] | None:\n        r\"\"\"Display a file uploader widget.\n        By default, uploaded files are limited to 200MB. You can configure\n        this using the ``server.maxUploadSize`` config option. For more info\n        on how to set config options, see\n        https://docs.streamlit.io/develop/api-reference/configuration/config.toml\n\n        Parameters\n        ----------\n        label : str\n            A short label explaining to the user what this file uploader is for.\n            The label can optionally contain Markdown and supports the following\n            elements: Bold, Italics, Strikethroughs, Inline Code, Emojis, and Links.\n\n            This also supports:\n\n            * Emoji shortcodes, such as ``:+1:``  and ``:sunglasses:``.\n              For a list of all supported codes,\n              see https://share.streamlit.io/streamlit/emoji-shortcodes.\n\n            * LaTeX expressions, by wrapping them in \"$\" or \"$$\" (the \"$$\"\n              must be on their own lines). Supported LaTeX functions are listed\n              at https://katex.org/docs/supported.html.\n\n            * Colored text and background colors for text, using the syntax\n              ``:color[text to be colored]`` and ``:color-background[text to be colored]``,\n              respectively. ``color`` must be replaced with any of the following\n              supported colors: blue, green, orange, red, violet, gray/grey, rainbow.\n              For example, you can use ``:orange[your text here]`` or\n              ``:blue-background[your text here]``.\n\n            Unsupported elements are unwrapped so only their children (text contents) render.\n            Display unsupported elements as literal characters by\n            backslash-escaping them. E.g. ``1\\. Not an ordered list``.\n\n            For accessibility reasons, you should never set an empty label (label=\"\")\n            but hide it with label_visibility if needed. In the future, we may disallow\n            empty labels by raising an exception.\n\n        type : str or list of str or None\n            Array of allowed extensions. ['png', 'jpg']\n            The default is None, which means all extensions are allowed.\n\n        accept_multiple_files : bool\n            If True, allows the user to upload multiple files at the same time,\n            in which case the return value will be a list of files.\n            Default: False\n\n        key : str or int\n            An optional string or integer to use as the unique key for the widget.\n            If this is omitted, a key will be generated for the widget\n            based on its content. Multiple widgets of the same type may\n            not share the same key.\n\n        help : str\n            A tooltip that gets displayed next to the file uploader.\n\n        on_change : callable\n            An optional callback invoked when this file_uploader's value\n            changes.\n\n        args : tuple\n            An optional tuple of args to pass to the callback.\n\n        kwargs : dict\n            An optional dict of kwargs to pass to the callback.\n\n        disabled : bool\n            An optional boolean, which disables the file uploader if set to\n            True. The default is False. This argument can only be supplied by\n            keyword.\n        label_visibility : \"visible\", \"hidden\", or \"collapsed\"\n            The visibility of the label. If \"hidden\", the label doesn't show but there\n            is still empty space for it above the widget (equivalent to label=\"\").\n            If \"collapsed\", both the label and the space are removed. Default is\n            \"visible\".\n\n        Returns\n        -------\n        None or UploadedFile or list of UploadedFile\n            - If accept_multiple_files is False, returns either None or\n              an UploadedFile object.\n            - If accept_multiple_files is True, returns a list with the\n              uploaded files as UploadedFile objects. If no files were\n              uploaded, returns an empty list.\n\n            The UploadedFile class is a subclass of BytesIO, and therefore\n            it is \"file-like\". This means you can pass them anywhere where\n            a file is expected.\n\n        Examples\n        --------\n        Insert a file uploader that accepts a single file at a time:\n\n        >>> import streamlit as st\n        >>> import pandas as pd\n        >>> from io import StringIO\n        >>>\n        >>> uploaded_file = st.file_uploader(\"Choose a file\")\n        >>> if uploaded_file is not None:\n        ...     # To read file as bytes:\n        ...     bytes_data = uploaded_file.getvalue()\n        ...     st.write(bytes_data)\n        >>>\n        ...     # To convert to a string based IO:\n        ...     stringio = StringIO(uploaded_file.getvalue().decode(\"utf-8\"))\n        ...     st.write(stringio)\n        >>>\n        ...     # To read file as string:\n        ...     string_data = stringio.read()\n        ...     st.write(string_data)\n        >>>\n        ...     # Can be used wherever a \"file-like\" object is accepted:\n        ...     dataframe = pd.read_csv(uploaded_file)\n        ...     st.write(dataframe)\n\n        Insert a file uploader that accepts multiple files at a time:\n\n        >>> import streamlit as st\n        >>>\n        >>> uploaded_files = st.file_uploader(\"Choose a CSV file\", accept_multiple_files=True)\n        >>> for uploaded_file in uploaded_files:\n        ...     bytes_data = uploaded_file.read()\n        ...     st.write(\"filename:\", uploaded_file.name)\n        ...     st.write(bytes_data)\n\n        .. output::\n           https://doc-file-uploader.streamlit.app/\n           height: 375px\n\n        \"\"\"\n        ctx = get_script_run_ctx()\n        return self._file_uploader(\n            label=label,\n            type=type,\n            accept_multiple_files=accept_multiple_files,\n            key=key,\n            help=help,\n            on_change=on_change,\n            args=args,\n            kwargs=kwargs,\n            disabled=disabled,\n            label_visibility=label_visibility,\n            ctx=ctx,\n        )\n\n    def _file_uploader(\n        self,\n        label: str,\n        type: str | Sequence[str] | None = None,\n        accept_multiple_files: bool = False,\n        key: Key | None = None,\n        help: str | None = None,\n        on_change: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        *,  # keyword-only arguments:\n        label_visibility: LabelVisibility = \"visible\",\n        disabled: bool = False,\n        ctx: ScriptRunContext | None = None,\n    ) -> UploadedFile | list[UploadedFile] | None:\n        key = to_key(key)\n\n        check_fragment_path_policy(self.dg)\n        check_cache_replay_rules()\n        check_callback_rules(self.dg, on_change)\n        check_session_state_rules(default_value=None, key=key, writes_allowed=False)\n        maybe_raise_label_warnings(label, label_visibility)\n\n        id = compute_widget_id(\n            \"file_uploader\",\n            user_key=key,\n            label=label,\n            type=type,\n            accept_multiple_files=accept_multiple_files,\n            key=key,\n            help=help,\n            form_id=current_form_id(self.dg),\n            page=ctx.active_script_hash if ctx else None,\n        )\n\n        if type:\n            if isinstance(type, str):\n                type = [type]\n\n            # May need a regex or a library to validate file types are valid\n            # extensions.\n            type = [\n                file_type if file_type[0] == \".\" else f\".{file_type}\"\n                for file_type in type\n            ]\n\n            type = [t.lower() for t in type]\n\n            for x, y in TYPE_PAIRS:\n                if x in type and y not in type:\n                    type.append(y)\n                if y in type and x not in type:\n                    type.append(x)\n\n        file_uploader_proto = FileUploaderProto()\n        file_uploader_proto.id = id\n        file_uploader_proto.label = label\n        file_uploader_proto.type[:] = type if type is not None else []\n        file_uploader_proto.max_upload_size_mb = config.get_option(\n            \"server.maxUploadSize\"\n        )\n        file_uploader_proto.multiple_files = accept_multiple_files\n        file_uploader_proto.form_id = current_form_id(self.dg)\n        file_uploader_proto.disabled = disabled\n        file_uploader_proto.label_visibility.value = get_label_visibility_proto_value(\n            label_visibility\n        )\n\n        if help is not None:\n            file_uploader_proto.help = dedent(help)\n\n        serde = FileUploaderSerde(accept_multiple_files)\n\n        # FileUploader's widget value is a list of file IDs\n        # representing the current set of files that this uploader should\n        # know about.\n        widget_state = register_widget(\n            \"file_uploader\",\n            file_uploader_proto,\n            user_key=key,\n            on_change_handler=on_change,\n            args=args,\n            kwargs=kwargs,\n            deserializer=serde.deserialize,\n            serializer=serde.serialize,\n            ctx=ctx,\n        )\n\n        self.dg._enqueue(\"file_uploader\", file_uploader_proto)\n\n        if isinstance(widget_state.value, DeletedFile):\n            return None\n        elif isinstance(widget_state.value, list):\n            return [f for f in widget_state.value if not isinstance(f, DeletedFile)]\n\n        return widget_state.value\n\n    @property\n    def dg(self) -> DeltaGenerator:\n        \"\"\"Get our DeltaGenerator.\"\"\"\n        return cast(\"DeltaGenerator\", self)\n", "lib/streamlit/elements/widgets/select_slider.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom dataclasses import dataclass\nfrom textwrap import dedent\nfrom typing import TYPE_CHECKING, Any, Callable, Generic, Sequence, Tuple, cast\n\nfrom typing_extensions import TypeGuard\n\nfrom streamlit.elements.form import current_form_id\nfrom streamlit.elements.lib.policies import (\n    check_cache_replay_rules,\n    check_callback_rules,\n    check_session_state_rules,\n)\nfrom streamlit.elements.lib.utils import (\n    get_label_visibility_proto_value,\n    maybe_coerce_enum,\n    maybe_coerce_enum_sequence,\n)\nfrom streamlit.errors import StreamlitAPIException\nfrom streamlit.proto.Slider_pb2 import Slider as SliderProto\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.runtime.scriptrunner import ScriptRunContext, get_script_run_ctx\nfrom streamlit.runtime.state import (\n    WidgetArgs,\n    WidgetCallback,\n    WidgetKwargs,\n    register_widget,\n)\nfrom streamlit.runtime.state.common import (\n    RegisterWidgetResult,\n    compute_widget_id,\n    save_for_app_testing,\n)\nfrom streamlit.type_util import (\n    Key,\n    LabelVisibility,\n    OptionSequence,\n    T,\n    check_python_comparable,\n    ensure_indexable,\n    maybe_raise_label_warnings,\n    to_key,\n)\nfrom streamlit.util import index_\n\nif TYPE_CHECKING:\n    from streamlit.delta_generator import DeltaGenerator\n\n\ndef _is_range_value(value: T | Sequence[T]) -> TypeGuard[Sequence[T]]:\n    return isinstance(value, (list, tuple))\n\n\n@dataclass\nclass SelectSliderSerde(Generic[T]):\n    options: Sequence[T]\n    value: list[int]\n    is_range_value: bool\n\n    def serialize(self, v: object) -> list[int]:\n        return self._as_index_list(v)\n\n    def deserialize(\n        self,\n        ui_value: list[int] | None,\n        widget_id: str = \"\",\n    ) -> T | tuple[T, T]:\n        if not ui_value:\n            # Widget has not been used; fallback to the original value,\n            ui_value = self.value\n\n        # The widget always returns floats, so convert to ints before indexing\n        return_value: tuple[T, T] = cast(\n            Tuple[T, T],\n            tuple(self.options[int(x)] for x in ui_value),\n        )\n\n        # If the original value was a list/tuple, so will be the output (and vice versa)\n        return return_value if self.is_range_value else return_value[0]\n\n    def _as_index_list(self, v: object) -> list[int]:\n        if _is_range_value(v):\n            slider_value = [index_(self.options, val) for val in v]\n            start, end = slider_value\n            if start > end:\n                slider_value = [end, start]\n            return slider_value\n        else:\n            return [index_(self.options, v)]\n\n\nclass SelectSliderMixin:\n    @gather_metrics(\"select_slider\")\n    def select_slider(\n        self,\n        label: str,\n        options: OptionSequence[T] = (),\n        value: object = None,\n        format_func: Callable[[Any], Any] = str,\n        key: Key | None = None,\n        help: str | None = None,\n        on_change: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        *,  # keyword-only arguments:\n        disabled: bool = False,\n        label_visibility: LabelVisibility = \"visible\",\n    ) -> T | tuple[T, T]:\n        r\"\"\"\n        Display a slider widget to select items from a list.\n\n        This also allows you to render a range slider by passing a two-element\n        tuple or list as the ``value``.\n\n        The difference between ``st.select_slider`` and ``st.slider`` is that\n        ``select_slider`` accepts any datatype and takes an iterable set of\n        options, while ``st.slider`` only accepts numerical or date/time data and\n        takes a range as input.\n\n        Parameters\n        ----------\n        label : str\n            A short label explaining to the user what this slider is for.\n            The label can optionally contain Markdown and supports the following\n            elements: Bold, Italics, Strikethroughs, Inline Code, Emojis, and Links.\n\n            This also supports:\n\n            * Emoji shortcodes, such as ``:+1:``  and ``:sunglasses:``.\n              For a list of all supported codes,\n              see https://share.streamlit.io/streamlit/emoji-shortcodes.\n\n            * LaTeX expressions, by wrapping them in \"$\" or \"$$\" (the \"$$\"\n              must be on their own lines). Supported LaTeX functions are listed\n              at https://katex.org/docs/supported.html.\n\n            * Colored text and background colors for text, using the syntax\n              ``:color[text to be colored]`` and ``:color-background[text to be colored]``,\n              respectively. ``color`` must be replaced with any of the following\n              supported colors: blue, green, orange, red, violet, gray/grey, rainbow.\n              For example, you can use ``:orange[your text here]`` or\n              ``:blue-background[your text here]``.\n\n            Unsupported elements are unwrapped so only their children (text contents) render.\n            Display unsupported elements as literal characters by\n            backslash-escaping them. E.g. ``1\\. Not an ordered list``.\n\n            For accessibility reasons, you should never set an empty label (label=\"\")\n            but hide it with label_visibility if needed. In the future, we may disallow\n            empty labels by raising an exception.\n        options : Iterable\n            Labels for the select options in an Iterable. For example, this can\n            be a list, numpy.ndarray, pandas.Series, pandas.DataFrame, or\n            pandas.Index. For pandas.DataFrame, the first column is used.\n            Each label will be cast to str internally by default.\n        value : a supported type or a tuple/list of supported types or None\n            The value of the slider when it first renders. If a tuple/list\n            of two values is passed here, then a range slider with those lower\n            and upper bounds is rendered. For example, if set to `(1, 10)` the\n            slider will have a selectable range between 1 and 10.\n            Defaults to first option.\n        format_func : function\n            Function to modify the display of the labels from the options.\n            argument. It receives the option as an argument and its output\n            will be cast to str.\n        key : str or int\n            An optional string or integer to use as the unique key for the widget.\n            If this is omitted, a key will be generated for the widget\n            based on its content. Multiple widgets of the same type may\n            not share the same key.\n        help : str\n            An optional tooltip that gets displayed next to the select slider.\n        on_change : callable\n            An optional callback invoked when this select_slider's value changes.\n        args : tuple\n            An optional tuple of args to pass to the callback.\n        kwargs : dict\n            An optional dict of kwargs to pass to the callback.\n        disabled : bool\n            An optional boolean, which disables the select slider if set to True.\n            The default is False.\n        label_visibility : \"visible\", \"hidden\", or \"collapsed\"\n            The visibility of the label. If \"hidden\", the label doesn't show but there\n            is still empty space for it above the widget (equivalent to label=\"\").\n            If \"collapsed\", both the label and the space are removed. Default is\n            \"visible\".\n\n        Returns\n        -------\n        any value or tuple of any value\n            The current value of the slider widget. The return type will match\n            the data type of the value parameter.\n\n        Examples\n        --------\n        >>> import streamlit as st\n        >>>\n        >>> color = st.select_slider(\n        ...     \"Select a color of the rainbow\",\n        ...     options=[\"red\", \"orange\", \"yellow\", \"green\", \"blue\", \"indigo\", \"violet\"])\n        >>> st.write(\"My favorite color is\", color)\n\n        And here's an example of a range select slider:\n\n        >>> import streamlit as st\n        >>>\n        >>> start_color, end_color = st.select_slider(\n        ...     \"Select a range of color wavelength\",\n        ...     options=[\"red\", \"orange\", \"yellow\", \"green\", \"blue\", \"indigo\", \"violet\"],\n        ...     value=(\"red\", \"blue\"))\n        >>> st.write(\"You selected wavelengths between\", start_color, \"and\", end_color)\n\n        .. output::\n           https://doc-select-slider.streamlit.app/\n           height: 450px\n\n        \"\"\"\n        ctx = get_script_run_ctx()\n        return self._select_slider(\n            label=label,\n            options=options,\n            value=value,\n            format_func=format_func,\n            key=key,\n            help=help,\n            on_change=on_change,\n            args=args,\n            kwargs=kwargs,\n            disabled=disabled,\n            label_visibility=label_visibility,\n            ctx=ctx,\n        )\n\n    def _select_slider(\n        self,\n        label: str,\n        options: OptionSequence[T] = (),\n        value: object = None,\n        format_func: Callable[[Any], Any] = str,\n        key: Key | None = None,\n        help: str | None = None,\n        on_change: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        disabled: bool = False,\n        label_visibility: LabelVisibility = \"visible\",\n        ctx: ScriptRunContext | None = None,\n    ) -> T | tuple[T, T]:\n        key = to_key(key)\n\n        check_cache_replay_rules()\n        check_callback_rules(self.dg, on_change)\n        check_session_state_rules(default_value=value, key=key)\n        maybe_raise_label_warnings(label, label_visibility)\n\n        opt = ensure_indexable(options)\n        check_python_comparable(opt)\n\n        if len(opt) == 0:\n            raise StreamlitAPIException(\"The `options` argument needs to be non-empty\")\n\n        def as_index_list(v: object) -> list[int]:\n            if _is_range_value(v):\n                slider_value = [index_(opt, val) for val in v]\n                start, end = slider_value\n                if start > end:\n                    slider_value = [end, start]\n                return slider_value\n            else:\n                # Simplify future logic by always making value a list\n                try:\n                    return [index_(opt, v)]\n                except ValueError:\n                    if value is not None:\n                        raise\n\n                    return [0]\n\n        # Convert element to index of the elements\n        slider_value = as_index_list(value)\n\n        id = compute_widget_id(\n            \"select_slider\",\n            user_key=key,\n            label=label,\n            options=[str(format_func(option)) for option in opt],\n            value=slider_value,\n            key=key,\n            help=help,\n            form_id=current_form_id(self.dg),\n            page=ctx.active_script_hash if ctx else None,\n        )\n\n        slider_proto = SliderProto()\n        slider_proto.id = id\n        slider_proto.type = SliderProto.Type.SELECT_SLIDER\n        slider_proto.label = label\n        slider_proto.format = \"%s\"\n        slider_proto.default[:] = slider_value\n        slider_proto.min = 0\n        slider_proto.max = len(opt) - 1\n        slider_proto.step = 1  # default for index changes\n        slider_proto.data_type = SliderProto.INT\n        slider_proto.options[:] = [str(format_func(option)) for option in opt]\n        slider_proto.form_id = current_form_id(self.dg)\n        slider_proto.disabled = disabled\n        slider_proto.label_visibility.value = get_label_visibility_proto_value(\n            label_visibility\n        )\n        if help is not None:\n            slider_proto.help = dedent(help)\n\n        serde = SelectSliderSerde(opt, slider_value, _is_range_value(value))\n\n        widget_state = register_widget(\n            \"slider\",\n            slider_proto,\n            user_key=key,\n            on_change_handler=on_change,\n            args=args,\n            kwargs=kwargs,\n            deserializer=serde.deserialize,\n            serializer=serde.serialize,\n            ctx=ctx,\n        )\n        if isinstance(widget_state.value, tuple):\n            widget_state = maybe_coerce_enum_sequence(\n                cast(RegisterWidgetResult[Tuple[T, T]], widget_state), options, opt\n            )\n        else:\n            widget_state = maybe_coerce_enum(widget_state, options, opt)\n\n        if widget_state.value_changed:\n            slider_proto.value[:] = serde.serialize(widget_state.value)\n            slider_proto.set_value = True\n\n        if ctx:\n            save_for_app_testing(ctx, id, format_func)\n\n        self.dg._enqueue(\"slider\", slider_proto)\n        return widget_state.value\n\n    @property\n    def dg(self) -> DeltaGenerator:\n        \"\"\"Get our DeltaGenerator.\"\"\"\n        return cast(\"DeltaGenerator\", self)\n", "lib/streamlit/elements/widgets/text_widgets.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom dataclasses import dataclass\nfrom textwrap import dedent\nfrom typing import TYPE_CHECKING, Literal, cast, overload\n\nfrom streamlit.elements.form import current_form_id\nfrom streamlit.elements.lib.policies import (\n    check_cache_replay_rules,\n    check_callback_rules,\n    check_fragment_path_policy,\n    check_session_state_rules,\n)\nfrom streamlit.elements.lib.utils import get_label_visibility_proto_value\nfrom streamlit.errors import StreamlitAPIException\nfrom streamlit.proto.TextArea_pb2 import TextArea as TextAreaProto\nfrom streamlit.proto.TextInput_pb2 import TextInput as TextInputProto\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.runtime.scriptrunner import ScriptRunContext, get_script_run_ctx\nfrom streamlit.runtime.state import (\n    WidgetArgs,\n    WidgetCallback,\n    WidgetKwargs,\n    get_session_state,\n    register_widget,\n)\nfrom streamlit.runtime.state.common import compute_widget_id\nfrom streamlit.type_util import (\n    Key,\n    LabelVisibility,\n    SupportsStr,\n    maybe_raise_label_warnings,\n    to_key,\n)\n\nif TYPE_CHECKING:\n    from streamlit.delta_generator import DeltaGenerator\n\n\n@dataclass\nclass TextInputSerde:\n    value: str | None\n\n    def deserialize(self, ui_value: str | None, widget_id: str = \"\") -> str | None:\n        return ui_value if ui_value is not None else self.value\n\n    def serialize(self, v: str | None) -> str | None:\n        return v\n\n\n@dataclass\nclass TextAreaSerde:\n    value: str | None\n\n    def deserialize(self, ui_value: str | None, widget_id: str = \"\") -> str | None:\n        return ui_value if ui_value is not None else self.value\n\n    def serialize(self, v: str | None) -> str | None:\n        return v\n\n\nclass TextWidgetsMixin:\n    @overload\n    def text_input(\n        self,\n        label: str,\n        value: str = \"\",\n        max_chars: int | None = None,\n        key: Key | None = None,\n        type: Literal[\"default\", \"password\"] = \"default\",\n        help: str | None = None,\n        autocomplete: str | None = None,\n        on_change: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        *,  # keyword-only arguments:\n        placeholder: str | None = None,\n        disabled: bool = False,\n        label_visibility: LabelVisibility = \"visible\",\n    ) -> str:\n        pass\n\n    @overload\n    def text_input(\n        self,\n        label: str,\n        value: SupportsStr | None = None,\n        max_chars: int | None = None,\n        key: Key | None = None,\n        type: Literal[\"default\", \"password\"] = \"default\",\n        help: str | None = None,\n        autocomplete: str | None = None,\n        on_change: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        *,  # keyword-only arguments:\n        placeholder: str | None = None,\n        disabled: bool = False,\n        label_visibility: LabelVisibility = \"visible\",\n    ) -> str | None:\n        pass\n\n    @gather_metrics(\"text_input\")\n    def text_input(\n        self,\n        label: str,\n        value: str | SupportsStr | None = \"\",\n        max_chars: int | None = None,\n        key: Key | None = None,\n        type: Literal[\"default\", \"password\"] = \"default\",\n        help: str | None = None,\n        autocomplete: str | None = None,\n        on_change: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        *,  # keyword-only arguments:\n        placeholder: str | None = None,\n        disabled: bool = False,\n        label_visibility: LabelVisibility = \"visible\",\n    ) -> str | None:\n        r\"\"\"Display a single-line text input widget.\n\n        Parameters\n        ----------\n        label : str\n            A short label explaining to the user what this input is for.\n            The label can optionally contain Markdown and supports the following\n            elements: Bold, Italics, Strikethroughs, Inline Code, Emojis, and Links.\n\n            This also supports:\n\n            * Emoji shortcodes, such as ``:+1:``  and ``:sunglasses:``.\n              For a list of all supported codes,\n              see https://share.streamlit.io/streamlit/emoji-shortcodes.\n\n            * LaTeX expressions, by wrapping them in \"$\" or \"$$\" (the \"$$\"\n              must be on their own lines). Supported LaTeX functions are listed\n              at https://katex.org/docs/supported.html.\n\n            * Colored text and background colors for text, using the syntax\n              ``:color[text to be colored]`` and ``:color-background[text to be colored]``,\n              respectively. ``color`` must be replaced with any of the following\n              supported colors: blue, green, orange, red, violet, gray/grey, rainbow.\n              For example, you can use ``:orange[your text here]`` or\n              ``:blue-background[your text here]``.\n\n            Unsupported elements are unwrapped so only their children (text contents) render.\n            Display unsupported elements as literal characters by\n            backslash-escaping them. E.g. ``1\\. Not an ordered list``.\n\n            For accessibility reasons, you should never set an empty label (label=\"\")\n            but hide it with label_visibility if needed. In the future, we may disallow\n            empty labels by raising an exception.\n        value : object or None\n            The text value of this widget when it first renders. This will be\n            cast to str internally. If ``None``, will initialize empty and\n            return ``None`` until the user provides input. Defaults to empty string.\n        max_chars : int or None\n            Max number of characters allowed in text input.\n        key : str or int\n            An optional string or integer to use as the unique key for the widget.\n            If this is omitted, a key will be generated for the widget\n            based on its content. Multiple widgets of the same type may\n            not share the same key.\n        type : \"default\" or \"password\"\n            The type of the text input. This can be either \"default\" (for\n            a regular text input), or \"password\" (for a text input that\n            masks the user's typed value). Defaults to \"default\".\n        help : str\n            An optional tooltip that gets displayed next to the input.\n        autocomplete : str\n            An optional value that will be passed to the <input> element's\n            autocomplete property. If unspecified, this value will be set to\n            \"new-password\" for \"password\" inputs, and the empty string for\n            \"default\" inputs. For more details, see https://developer.mozilla.org/en-US/docs/Web/HTML/Attributes/autocomplete\n        on_change : callable\n            An optional callback invoked when this text input's value changes.\n        args : tuple\n            An optional tuple of args to pass to the callback.\n        kwargs : dict\n            An optional dict of kwargs to pass to the callback.\n        placeholder : str or None\n            An optional string displayed when the text input is empty. If None,\n            no text is displayed.\n        disabled : bool\n            An optional boolean, which disables the text input if set to True.\n            The default is False.\n        label_visibility : \"visible\", \"hidden\", or \"collapsed\"\n            The visibility of the label. If \"hidden\", the label doesn't show but there\n            is still empty space for it above the widget (equivalent to label=\"\").\n            If \"collapsed\", both the label and the space are removed. Default is\n            \"visible\".\n\n        Returns\n        -------\n        str or None\n            The current value of the text input widget or ``None`` if no value has been\n            provided by the user.\n\n        Example\n        -------\n        >>> import streamlit as st\n        >>>\n        >>> title = st.text_input(\"Movie title\", \"Life of Brian\")\n        >>> st.write(\"The current movie title is\", title)\n\n        .. output::\n           https://doc-text-input.streamlit.app/\n           height: 260px\n\n        \"\"\"\n        ctx = get_script_run_ctx()\n        return self._text_input(\n            label=label,\n            value=value,\n            max_chars=max_chars,\n            key=key,\n            type=type,\n            help=help,\n            autocomplete=autocomplete,\n            on_change=on_change,\n            args=args,\n            kwargs=kwargs,\n            placeholder=placeholder,\n            disabled=disabled,\n            label_visibility=label_visibility,\n            ctx=ctx,\n        )\n\n    def _text_input(\n        self,\n        label: str,\n        value: SupportsStr | None = \"\",\n        max_chars: int | None = None,\n        key: Key | None = None,\n        type: str = \"default\",\n        help: str | None = None,\n        autocomplete: str | None = None,\n        on_change: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        *,  # keyword-only arguments:\n        placeholder: str | None = None,\n        disabled: bool = False,\n        label_visibility: LabelVisibility = \"visible\",\n        ctx: ScriptRunContext | None = None,\n    ) -> str | None:\n        key = to_key(key)\n\n        check_fragment_path_policy(self.dg)\n        check_cache_replay_rules()\n        check_callback_rules(self.dg, on_change)\n        check_session_state_rules(default_value=None if value == \"\" else value, key=key)\n        maybe_raise_label_warnings(label, label_visibility)\n\n        # Make sure value is always string or None:\n        value = str(value) if value is not None else None\n\n        id = compute_widget_id(\n            \"text_input\",\n            user_key=key,\n            label=label,\n            value=value,\n            max_chars=max_chars,\n            key=key,\n            type=type,\n            help=help,\n            autocomplete=autocomplete,\n            placeholder=str(placeholder),\n            form_id=current_form_id(self.dg),\n            page=ctx.active_script_hash if ctx else None,\n        )\n\n        session_state = get_session_state().filtered_state\n        if key is not None and key in session_state and session_state[key] is None:\n            value = None\n\n        text_input_proto = TextInputProto()\n        text_input_proto.id = id\n        text_input_proto.label = label\n        if value is not None:\n            text_input_proto.default = value\n        text_input_proto.form_id = current_form_id(self.dg)\n        text_input_proto.disabled = disabled\n        text_input_proto.label_visibility.value = get_label_visibility_proto_value(\n            label_visibility\n        )\n\n        if help is not None:\n            text_input_proto.help = dedent(help)\n\n        if max_chars is not None:\n            text_input_proto.max_chars = max_chars\n\n        if placeholder is not None:\n            text_input_proto.placeholder = str(placeholder)\n\n        if type == \"default\":\n            text_input_proto.type = TextInputProto.DEFAULT\n        elif type == \"password\":\n            text_input_proto.type = TextInputProto.PASSWORD\n        else:\n            raise StreamlitAPIException(\n                \"'%s' is not a valid text_input type. Valid types are 'default' and 'password'.\"\n                % type\n            )\n\n        # Marshall the autocomplete param. If unspecified, this will be\n        # set to \"new-password\" for password inputs.\n        if autocomplete is None:\n            autocomplete = \"new-password\" if type == \"password\" else \"\"\n        text_input_proto.autocomplete = autocomplete\n\n        serde = TextInputSerde(value)\n\n        widget_state = register_widget(\n            \"text_input\",\n            text_input_proto,\n            user_key=key,\n            on_change_handler=on_change,\n            args=args,\n            kwargs=kwargs,\n            deserializer=serde.deserialize,\n            serializer=serde.serialize,\n            ctx=ctx,\n        )\n\n        if widget_state.value_changed:\n            if widget_state.value is not None:\n                text_input_proto.value = widget_state.value\n            text_input_proto.set_value = True\n\n        self.dg._enqueue(\"text_input\", text_input_proto)\n        return widget_state.value\n\n    @overload\n    def text_area(\n        self,\n        label: str,\n        value: str = \"\",\n        height: int | None = None,\n        max_chars: int | None = None,\n        key: Key | None = None,\n        help: str | None = None,\n        on_change: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        *,  # keyword-only arguments:\n        placeholder: str | None = None,\n        disabled: bool = False,\n        label_visibility: LabelVisibility = \"visible\",\n    ) -> str:\n        pass\n\n    @overload\n    def text_area(\n        self,\n        label: str,\n        value: SupportsStr | None = None,\n        height: int | None = None,\n        max_chars: int | None = None,\n        key: Key | None = None,\n        help: str | None = None,\n        on_change: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        *,  # keyword-only arguments:\n        placeholder: str | None = None,\n        disabled: bool = False,\n        label_visibility: LabelVisibility = \"visible\",\n    ) -> str | None:\n        pass\n\n    @gather_metrics(\"text_area\")\n    def text_area(\n        self,\n        label: str,\n        value: str | SupportsStr | None = \"\",\n        height: int | None = None,\n        max_chars: int | None = None,\n        key: Key | None = None,\n        help: str | None = None,\n        on_change: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        *,  # keyword-only arguments:\n        placeholder: str | None = None,\n        disabled: bool = False,\n        label_visibility: LabelVisibility = \"visible\",\n    ) -> str | None:\n        r\"\"\"Display a multi-line text input widget.\n\n        Parameters\n        ----------\n        label : str\n            A short label explaining to the user what this input is for.\n            The label can optionally contain Markdown and supports the following\n            elements: Bold, Italics, Strikethroughs, Inline Code, Emojis, and Links.\n\n            This also supports:\n\n            * Emoji shortcodes, such as ``:+1:``  and ``:sunglasses:``.\n              For a list of all supported codes,\n              see https://share.streamlit.io/streamlit/emoji-shortcodes.\n\n            * LaTeX expressions, by wrapping them in \"$\" or \"$$\" (the \"$$\"\n              must be on their own lines). Supported LaTeX functions are listed\n              at https://katex.org/docs/supported.html.\n\n            * Colored text and background colors for text, using the syntax\n              ``:color[text to be colored]`` and ``:color-background[text to be colored]``,\n              respectively. ``color`` must be replaced with any of the following\n              supported colors: blue, green, orange, red, violet, gray/grey, rainbow.\n              For example, you can use ``:orange[your text here]`` or\n              ``:blue-background[your text here]``.\n\n            Unsupported elements are unwrapped so only their children (text contents) render.\n            Display unsupported elements as literal characters by\n            backslash-escaping them. E.g. ``1\\. Not an ordered list``.\n\n            For accessibility reasons, you should never set an empty label (label=\"\")\n            but hide it with label_visibility if needed. In the future, we may disallow\n            empty labels by raising an exception.\n        value : object or None\n            The text value of this widget when it first renders. This will be\n            cast to str internally. If ``None``, will initialize empty and\n            return ``None`` until the user provides input. Defaults to empty string.\n        height : int or None\n            Desired height of the UI element expressed in pixels. If None, a\n            default height is used.\n        max_chars : int or None\n            Maximum number of characters allowed in text area.\n        key : str or int\n            An optional string or integer to use as the unique key for the widget.\n            If this is omitted, a key will be generated for the widget\n            based on its content. Multiple widgets of the same type may\n            not share the same key.\n        help : str\n            An optional tooltip that gets displayed next to the textarea.\n        on_change : callable\n            An optional callback invoked when this text_area's value changes.\n        args : tuple\n            An optional tuple of args to pass to the callback.\n        kwargs : dict\n            An optional dict of kwargs to pass to the callback.\n        placeholder : str or None\n            An optional string displayed when the text area is empty. If None,\n            no text is displayed.\n        disabled : bool\n            An optional boolean, which disables the text area if set to True.\n            The default is False.\n        label_visibility : \"visible\", \"hidden\", or \"collapsed\"\n            The visibility of the label. If \"hidden\", the label doesn't show but there\n            is still empty space for it above the widget (equivalent to label=\"\").\n            If \"collapsed\", both the label and the space are removed. Default is\n            \"visible\".\n\n        Returns\n        -------\n        str or None\n            The current value of the text area widget or ``None`` if no value has been\n            provided by the user.\n\n        Example\n        -------\n        >>> import streamlit as st\n        >>>\n        >>> txt = st.text_area(\n        ...     \"Text to analyze\",\n        ...     \"It was the best of times, it was the worst of times, it was the age of \"\n        ...     \"wisdom, it was the age of foolishness, it was the epoch of belief, it \"\n        ...     \"was the epoch of incredulity, it was the season of Light, it was the \"\n        ...     \"season of Darkness, it was the spring of hope, it was the winter of \"\n        ...     \"despair, (...)\",\n        ...     )\n        >>>\n        >>> st.write(f\"You wrote {len(txt)} characters.\")\n\n        .. output::\n           https://doc-text-area.streamlit.app/\n           height: 300px\n\n        \"\"\"\n        ctx = get_script_run_ctx()\n        return self._text_area(\n            label=label,\n            value=value,\n            height=height,\n            max_chars=max_chars,\n            key=key,\n            help=help,\n            on_change=on_change,\n            args=args,\n            kwargs=kwargs,\n            placeholder=placeholder,\n            disabled=disabled,\n            label_visibility=label_visibility,\n            ctx=ctx,\n        )\n\n    def _text_area(\n        self,\n        label: str,\n        value: SupportsStr | None = \"\",\n        height: int | None = None,\n        max_chars: int | None = None,\n        key: Key | None = None,\n        help: str | None = None,\n        on_change: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        *,  # keyword-only arguments:\n        placeholder: str | None = None,\n        disabled: bool = False,\n        label_visibility: LabelVisibility = \"visible\",\n        ctx: ScriptRunContext | None = None,\n    ) -> str | None:\n        key = to_key(key)\n\n        check_fragment_path_policy(self.dg)\n        check_cache_replay_rules()\n        check_callback_rules(self.dg, on_change)\n        check_session_state_rules(default_value=None if value == \"\" else value, key=key)\n        maybe_raise_label_warnings(label, label_visibility)\n\n        value = str(value) if value is not None else None\n\n        id = compute_widget_id(\n            \"text_area\",\n            user_key=key,\n            label=label,\n            value=value,\n            height=height,\n            max_chars=max_chars,\n            key=key,\n            help=help,\n            placeholder=str(placeholder),\n            form_id=current_form_id(self.dg),\n            page=ctx.active_script_hash if ctx else None,\n        )\n\n        session_state = get_session_state().filtered_state\n        if key is not None and key in session_state and session_state[key] is None:\n            value = None\n\n        text_area_proto = TextAreaProto()\n        text_area_proto.id = id\n        text_area_proto.label = label\n        if value is not None:\n            text_area_proto.default = value\n        text_area_proto.form_id = current_form_id(self.dg)\n        text_area_proto.disabled = disabled\n        text_area_proto.label_visibility.value = get_label_visibility_proto_value(\n            label_visibility\n        )\n\n        if help is not None:\n            text_area_proto.help = dedent(help)\n\n        if height is not None:\n            text_area_proto.height = height\n\n        if max_chars is not None:\n            text_area_proto.max_chars = max_chars\n\n        if placeholder is not None:\n            text_area_proto.placeholder = str(placeholder)\n\n        serde = TextAreaSerde(value)\n        widget_state = register_widget(\n            \"text_area\",\n            text_area_proto,\n            user_key=key,\n            on_change_handler=on_change,\n            args=args,\n            kwargs=kwargs,\n            deserializer=serde.deserialize,\n            serializer=serde.serialize,\n            ctx=ctx,\n        )\n\n        if widget_state.value_changed:\n            if widget_state.value is not None:\n                text_area_proto.value = widget_state.value\n            text_area_proto.set_value = True\n\n        self.dg._enqueue(\"text_area\", text_area_proto)\n        return widget_state.value\n\n    @property\n    def dg(self) -> DeltaGenerator:\n        \"\"\"Get our DeltaGenerator.\"\"\"\n        return cast(\"DeltaGenerator\", self)\n", "lib/streamlit/elements/widgets/button.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport io\nimport os\nfrom dataclasses import dataclass\nfrom textwrap import dedent\nfrom typing import TYPE_CHECKING, BinaryIO, Final, Literal, TextIO, Union, cast\n\nfrom typing_extensions import TypeAlias\n\nfrom streamlit import runtime\nfrom streamlit.elements.form import current_form_id, is_in_form\nfrom streamlit.elements.lib.policies import (\n    check_cache_replay_rules,\n    check_callback_rules,\n    check_fragment_path_policy,\n    check_session_state_rules,\n)\nfrom streamlit.errors import StreamlitAPIException\nfrom streamlit.file_util import get_main_script_directory, normalize_path_join\nfrom streamlit.navigation.page import StreamlitPage\nfrom streamlit.proto.Button_pb2 import Button as ButtonProto\nfrom streamlit.proto.DownloadButton_pb2 import DownloadButton as DownloadButtonProto\nfrom streamlit.proto.LinkButton_pb2 import LinkButton as LinkButtonProto\nfrom streamlit.proto.PageLink_pb2 import PageLink as PageLinkProto\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.runtime.scriptrunner import ScriptRunContext, get_script_run_ctx\nfrom streamlit.runtime.state import (\n    WidgetArgs,\n    WidgetCallback,\n    WidgetKwargs,\n    register_widget,\n)\nfrom streamlit.runtime.state.common import compute_widget_id, save_for_app_testing\nfrom streamlit.string_util import validate_icon_or_emoji\nfrom streamlit.type_util import Key, to_key\nfrom streamlit.url_util import is_url\n\nif TYPE_CHECKING:\n    from streamlit.delta_generator import DeltaGenerator\n\nFORM_DOCS_INFO: Final = \"\"\"\n\nFor more information, refer to the\n[documentation for forms](https://docs.streamlit.io/develop/api-reference/execution-flow/st.form).\n\"\"\"\n\nDownloadButtonDataType: TypeAlias = Union[str, bytes, TextIO, BinaryIO, io.RawIOBase]\n\n\n@dataclass\nclass ButtonSerde:\n    def serialize(self, v: bool) -> bool:\n        return bool(v)\n\n    def deserialize(self, ui_value: bool | None, widget_id: str = \"\") -> bool:\n        return ui_value or False\n\n\nclass ButtonMixin:\n    @gather_metrics(\"button\")\n    def button(\n        self,\n        label: str,\n        key: Key | None = None,\n        help: str | None = None,\n        on_click: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        *,  # keyword-only arguments:\n        type: Literal[\"primary\", \"secondary\"] = \"secondary\",\n        disabled: bool = False,\n        use_container_width: bool = False,\n    ) -> bool:\n        r\"\"\"Display a button widget.\n\n        Parameters\n        ----------\n        label : str\n            A short label explaining to the user what this button is for.\n            The label can optionally contain Markdown and supports the following\n            elements: Bold, Italics, Strikethroughs, Inline Code, and Emojis.\n\n            This also supports:\n\n            * Emoji shortcodes, such as ``:+1:``  and ``:sunglasses:``.\n              For a list of all supported codes,\n              see https://share.streamlit.io/streamlit/emoji-shortcodes.\n\n            * LaTeX expressions, by wrapping them in \"$\" or \"$$\" (the \"$$\"\n              must be on their own lines). Supported LaTeX functions are listed\n              at https://katex.org/docs/supported.html.\n\n            * Colored text and background colors for text, using the syntax\n              ``:color[text to be colored]`` and ``:color-background[text to be colored]``,\n              respectively. ``color`` must be replaced with any of the following\n              supported colors: blue, green, orange, red, violet, gray/grey, rainbow.\n              For example, you can use ``:orange[your text here]`` or\n              ``:blue-background[your text here]``.\n\n            Unsupported elements are unwrapped so only their children (text contents) render.\n            Display unsupported elements as literal characters by\n            backslash-escaping them. E.g. ``1\\. Not an ordered list``.\n        key : str or int\n            An optional string or integer to use as the unique key for the widget.\n            If this is omitted, a key will be generated for the widget\n            based on its content. Multiple widgets of the same type may\n            not share the same key.\n        help : str\n            An optional tooltip that gets displayed when the button is\n            hovered over.\n        on_click : callable\n            An optional callback invoked when this button is clicked.\n        args : tuple\n            An optional tuple of args to pass to the callback.\n        kwargs : dict\n            An optional dict of kwargs to pass to the callback.\n        type : \"secondary\" or \"primary\"\n            An optional string that specifies the button type. Can be \"primary\" for a\n            button with additional emphasis or \"secondary\" for a normal button. Defaults\n            to \"secondary\".\n        disabled : bool\n            An optional boolean, which disables the button if set to True. The\n            default is False.\n        use_container_width : bool\n            Whether to expand the button's width to fill its parent container.\n            If ``use_container_width`` is ``False`` (default), Streamlit sizes\n            the button to fit its contents. If ``use_container_width`` is\n            ``True``, the width of the button matches its parent container.\n\n            In both cases, if the contents of the button are wider than the\n            parent container, the contents will line wrap.\n\n        Returns\n        -------\n        bool\n            True if the button was clicked on the last run of the app,\n            False otherwise.\n\n        Example\n        -------\n        >>> import streamlit as st\n        >>>\n        >>> st.button(\"Reset\", type=\"primary\")\n        >>> if st.button(\"Say hello\"):\n        ...     st.write(\"Why hello there\")\n        ... else:\n        ...     st.write(\"Goodbye\")\n\n        .. output::\n           https://doc-buton.streamlit.app/\n           height: 220px\n\n        \"\"\"\n        key = to_key(key)\n        ctx = get_script_run_ctx()\n\n        # Checks whether the entered button type is one of the allowed options - either \"primary\" or \"secondary\"\n        if type not in [\"primary\", \"secondary\"]:\n            raise StreamlitAPIException(\n                'The type argument to st.button must be \"primary\" or \"secondary\". \\n'\n                f'The argument passed was \"{type}\".'\n            )\n\n        return self.dg._button(\n            label,\n            key,\n            help,\n            is_form_submitter=False,\n            on_click=on_click,\n            args=args,\n            kwargs=kwargs,\n            disabled=disabled,\n            type=type,\n            use_container_width=use_container_width,\n            ctx=ctx,\n        )\n\n    @gather_metrics(\"download_button\")\n    def download_button(\n        self,\n        label: str,\n        data: DownloadButtonDataType,\n        file_name: str | None = None,\n        mime: str | None = None,\n        key: Key | None = None,\n        help: str | None = None,\n        on_click: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        *,  # keyword-only arguments:\n        type: Literal[\"primary\", \"secondary\"] = \"secondary\",\n        disabled: bool = False,\n        use_container_width: bool = False,\n    ) -> bool:\n        r\"\"\"Display a download button widget.\n\n        This is useful when you would like to provide a way for your users\n        to download a file directly from your app.\n\n        Note that the data to be downloaded is stored in-memory while the\n        user is connected, so it's a good idea to keep file sizes under a\n        couple hundred megabytes to conserve memory.\n\n        If you want to prevent your app from rerunning when a user clicks the\n        download button, wrap the download button in a `fragment\n        <https://docs.streamlit.io/develop/concepts/architecture/fragments>`_.\n\n        Parameters\n        ----------\n        label : str\n            A short label explaining to the user what this button is for.\n            The label can optionally contain Markdown and supports the following\n            elements: Bold, Italics, Strikethroughs, Inline Code, and Emojis.\n\n            This also supports:\n\n            * Emoji shortcodes, such as ``:+1:``  and ``:sunglasses:``.\n              For a list of all supported codes,\n              see https://share.streamlit.io/streamlit/emoji-shortcodes.\n\n            * LaTeX expressions, by wrapping them in \"$\" or \"$$\" (the \"$$\"\n              must be on their own lines). Supported LaTeX functions are listed\n              at https://katex.org/docs/supported.html.\n\n            * Colored text and background colors for text, using the syntax\n              ``:color[text to be colored]`` and ``:color-background[text to be colored]``,\n              respectively. ``color`` must be replaced with any of the following\n              supported colors: blue, green, orange, red, violet, gray/grey, rainbow.\n              For example, you can use ``:orange[your text here]`` or\n              ``:blue-background[your text here]``.\n\n            Unsupported elements are unwrapped so only their children (text contents)\n            render. Display unsupported elements as literal characters by\n            backslash-escaping them. E.g. ``1\\. Not an ordered list``.\n        data : str or bytes or file\n            The contents of the file to be downloaded. See example below for\n            caching techniques to avoid recomputing this data unnecessarily.\n        file_name: str\n            An optional string to use as the name of the file to be downloaded,\n            such as 'my_file.csv'. If not specified, the name will be\n            automatically generated.\n        mime : str or None\n            The MIME type of the data. If None, defaults to \"text/plain\"\n            (if data is of type *str* or is a textual *file*) or\n            \"application/octet-stream\" (if data is of type *bytes* or is a\n            binary *file*).\n        key : str or int\n            An optional string or integer to use as the unique key for the widget.\n            If this is omitted, a key will be generated for the widget\n            based on its content. Multiple widgets of the same type may\n            not share the same key.\n        help : str\n            An optional tooltip that gets displayed when the button is\n            hovered over.\n        on_click : callable\n            An optional callback invoked when this button is clicked.\n        args : tuple\n            An optional tuple of args to pass to the callback.\n        kwargs : dict\n            An optional dict of kwargs to pass to the callback.\n        type : \"secondary\" or \"primary\"\n            An optional string that specifies the button type. Can be \"primary\" for a\n            button with additional emphasis or \"secondary\" for a normal button. Defaults\n            to \"secondary\".\n        disabled : bool\n            An optional boolean, which disables the download button if set to\n            True. The default is False.\n        use_container_width : bool\n            Whether to expand the button's width to fill its parent container.\n            If ``use_container_width`` is ``False`` (default), Streamlit sizes\n            the button to fit its contents. If ``use_container_width`` is\n            ``True``, the width of the button matches its parent container.\n\n            In both cases, if the contents of the button are wider than the\n            parent container, the contents will line wrap.\n\n        Returns\n        -------\n        bool\n            True if the button was clicked on the last run of the app,\n            False otherwise.\n\n        Examples\n        --------\n        Download a large DataFrame as a CSV:\n\n        >>> import streamlit as st\n        >>>\n        >>> @st.cache_data\n        ... def convert_df(df):\n        ...     # IMPORTANT: Cache the conversion to prevent computation on every rerun\n        ...     return df.to_csv().encode(\"utf-8\")\n        >>>\n        >>> csv = convert_df(my_large_df)\n        >>>\n        >>> st.download_button(\n        ...     label=\"Download data as CSV\",\n        ...     data=csv,\n        ...     file_name=\"large_df.csv\",\n        ...     mime=\"text/csv\",\n        ... )\n\n        Download a string as a file:\n\n        >>> import streamlit as st\n        >>>\n        >>> text_contents = '''This is some text'''\n        >>> st.download_button(\"Download some text\", text_contents)\n\n        Download a binary file:\n\n        >>> import streamlit as st\n        >>>\n        >>> binary_contents = b\"example content\"\n        >>> # Defaults to \"application/octet-stream\"\n        >>> st.download_button(\"Download binary file\", binary_contents)\n\n        Download an image:\n\n        >>> import streamlit as st\n        >>>\n        >>> with open(\"flower.png\", \"rb\") as file:\n        ...     btn = st.download_button(\n        ...             label=\"Download image\",\n        ...             data=file,\n        ...             file_name=\"flower.png\",\n        ...             mime=\"image/png\"\n        ...           )\n\n        .. output::\n           https://doc-download-buton.streamlit.app/\n           height: 335px\n\n        \"\"\"\n        ctx = get_script_run_ctx()\n\n        if type not in [\"primary\", \"secondary\"]:\n            raise StreamlitAPIException(\n                'The type argument to st.button must be \"primary\" or \"secondary\". \\n'\n                f'The argument passed was \"{type}\".'\n            )\n\n        return self._download_button(\n            label=label,\n            data=data,\n            file_name=file_name,\n            mime=mime,\n            key=key,\n            help=help,\n            on_click=on_click,\n            args=args,\n            kwargs=kwargs,\n            disabled=disabled,\n            type=type,\n            use_container_width=use_container_width,\n            ctx=ctx,\n        )\n\n    @gather_metrics(\"link_button\")\n    def link_button(\n        self,\n        label: str,\n        url: str,\n        *,\n        help: str | None = None,\n        type: Literal[\"primary\", \"secondary\"] = \"secondary\",\n        disabled: bool = False,\n        use_container_width: bool = False,\n    ) -> DeltaGenerator:\n        r\"\"\"Display a link button element.\n\n        When clicked, a new tab will be opened to the specified URL. This will\n        create a new session for the user if directed within the app.\n\n        Parameters\n        ----------\n        label : str\n            A short label explaining to the user what this button is for.\n            The label can optionally contain Markdown and supports the following\n            elements: Bold, Italics, Strikethroughs, Inline Code, and Emojis.\n\n            This also supports:\n\n            * Emoji shortcodes, such as ``:+1:``  and ``:sunglasses:``.\n              For a list of all supported codes,\n              see https://share.streamlit.io/streamlit/emoji-shortcodes.\n\n            * LaTeX expressions, by wrapping them in \"$\" or \"$$\" (the \"$$\"\n              must be on their own lines). Supported LaTeX functions are listed\n              at https://katex.org/docs/supported.html.\n\n            * Colored text and background colors for text, using the syntax\n              ``:color[text to be colored]`` and ``:color-background[text to be colored]``,\n              respectively. ``color`` must be replaced with any of the following\n              supported colors: blue, green, orange, red, violet, gray/grey, rainbow.\n              For example, you can use ``:orange[your text here]`` or\n              ``:blue-background[your text here]``.\n\n            Unsupported elements are unwrapped so only their children (text contents)\n            render. Display unsupported elements as literal characters by\n            backslash-escaping them. E.g. ``1\\. Not an ordered list``.\n        url : str\n            The url to be opened on user click\n        help : str\n            An optional tooltip that gets displayed when the button is\n            hovered over.\n        type : \"secondary\" or \"primary\"\n            An optional string that specifies the button type. Can be \"primary\" for a\n            button with additional emphasis or \"secondary\" for a normal button. Defaults\n            to \"secondary\".\n        disabled : bool\n            An optional boolean, which disables the link button if set to\n            True. The default is False.\n        use_container_width : bool\n            Whether to expand the button's width to fill its parent container.\n            If ``use_container_width`` is ``False`` (default), Streamlit sizes\n            the button to fit its contents. If ``use_container_width`` is\n            ``True``, the width of the button matches its parent container.\n\n            In both cases, if the contents of the button are wider than the\n            parent container, the contents will line wrap.\n\n        Example\n        -------\n        >>> import streamlit as st\n        >>>\n        >>> st.link_button(\"Go to gallery\", \"https://streamlit.io/gallery\")\n\n        .. output::\n           https://doc-link-button.streamlit.app/\n           height: 200px\n\n        \"\"\"\n        # Checks whether the entered button type is one of the allowed options - either \"primary\" or \"secondary\"\n        if type not in [\"primary\", \"secondary\"]:\n            raise StreamlitAPIException(\n                'The type argument to st.link_button must be \"primary\" or \"secondary\". '\n                f'\\nThe argument passed was \"{type}\".'\n            )\n\n        return self._link_button(\n            label=label,\n            url=url,\n            help=help,\n            disabled=disabled,\n            type=type,\n            use_container_width=use_container_width,\n        )\n\n    @gather_metrics(\"page_link\")\n    def page_link(\n        self,\n        page: str | StreamlitPage,\n        *,\n        label: str | None = None,\n        icon: str | None = None,\n        help: str | None = None,\n        disabled: bool = False,\n        use_container_width: bool | None = None,\n    ) -> DeltaGenerator:\n        r\"\"\"Display a link to another page in a multipage app or to an external page.\n\n        If another page in a multipage app is specified, clicking ``st.page_link``\n        stops the current page execution and runs the specified page as if the\n        user clicked on it in the sidebar navigation.\n\n        If an external page is specified, clicking ``st.page_link`` opens a new\n        tab to the specified page. The current script run will continue if not\n        complete.\n\n        Parameters\n        ----------\n        page : str or st.Page\n            The file path (relative to the main script) or an st.Page indicating\n            the page to switch to. Alternatively, this can be the URL to an\n            external page (must start with \"http://\" or \"https://\").\n        label : str\n            The label for the page link. Labels are required for external pages.\n            Labels can optionally contain Markdown and supports the following\n            elements: Bold, Italics, Strikethroughs, Inline Code, and Emojis.\n\n            This also supports:\n\n            * Emoji shortcodes, such as ``:+1:``  and ``:sunglasses:``.\n              For a list of all supported codes,\n              see https://share.streamlit.io/streamlit/emoji-shortcodes.\n\n            * LaTeX expressions, by wrapping them in \"$\" or \"$$\" (the \"$$\"\n              must be on their own lines). Supported LaTeX functions are listed\n              at https://katex.org/docs/supported.html.\n\n            * Colored text and background colors for text, using the syntax\n              ``:color[text to be colored]`` and ``:color-background[text to be colored]``,\n              respectively. ``color`` must be replaced with any of the following\n              supported colors: blue, green, orange, red, violet, gray/grey, rainbow.\n              For example, you can use ``:orange[your text here]`` or\n              ``:blue-background[your text here]``.\n\n            Unsupported elements are unwrapped so only their children (text contents)\n            render. Display unsupported elements as literal characters by\n            backslash-escaping them. E.g. ``1\\. Not an ordered list``.\n        icon : str, None\n            An optional emoji or icon to display next to the button label. If ``icon``\n            is ``None`` (default), no icon is displayed. If ``icon`` is a\n            string, the following options are valid:\n\n            * A single-character emoji. For example, you can set ``icon=\"\ud83d\udea8\"``\n              or ``icon=\"\ud83d\udd25\"``. Emoji short codes are not supported.\n\n            * An icon from the Material Symbols library (outlined style) in the\n              format ``\":material/icon_name:\"`` where \"icon_name\" is the name\n              of the icon in snake case.\n\n              For example, ``icon=\":material/thumb_up:\"`` will display the\n              Thumb Up icon. Find additional icons in the `Material Symbols \\\n              <https://fonts.google.com/icons?icon.set=Material+Symbols&icon.style=Outlined>`_\n              font library.\n        help : str\n            An optional tooltip that gets displayed when the link is\n            hovered over.\n        disabled : bool\n            An optional boolean, which disables the page link if set to\n            ``True``. The default is ``False``.\n        use_container_width : bool\n            Whether to expand the link's width to fill its parent container.\n            The default is ``True`` for page links in the sidebar and ``False``\n            for those in the main app.\n\n        Example\n        -------\n        Consider the following example given this file structure:\n\n        >>> your-repository/\n        >>> \u251c\u2500\u2500 pages/\n        >>> \u2502   \u251c\u2500\u2500 page_1.py\n        >>> \u2502   \u2514\u2500\u2500 page_2.py\n        >>> \u2514\u2500\u2500 your_app.py\n\n        >>> import streamlit as st\n        >>>\n        >>> st.page_link(\"your_app.py\", label=\"Home\", icon=\"\ud83c\udfe0\")\n        >>> st.page_link(\"pages/page_1.py\", label=\"Page 1\", icon=\"1\ufe0f\u20e3\")\n        >>> st.page_link(\"pages/page_2.py\", label=\"Page 2\", icon=\"2\ufe0f\u20e3\", disabled=True)\n        >>> st.page_link(\"http://www.google.com\", label=\"Google\", icon=\"\ud83c\udf0e\")\n\n        The default navigation is shown here for comparison, but you can hide\n        the default navigation using the |client.showSidebarNavigation|_\n        configuration option. This allows you to create custom, dynamic\n        navigation menus for your apps!\n\n        .. |client.showSidebarNavigation| replace:: ``client.showSidebarNavigation``\n        .. _client.showSidebarNavigation: https://docs.streamlit.io/develop/api-reference/configuration/config.toml#client\n\n        .. output ::\n            https://doc-page-link.streamlit.app/\n            height: 350px\n\n        \"\"\"\n\n        return self._page_link(\n            page=page,\n            label=label,\n            icon=icon,\n            help=help,\n            disabled=disabled,\n            use_container_width=use_container_width,\n        )\n\n    def _download_button(\n        self,\n        label: str,\n        data: DownloadButtonDataType,\n        file_name: str | None = None,\n        mime: str | None = None,\n        key: Key | None = None,\n        help: str | None = None,\n        on_click: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        *,  # keyword-only arguments:\n        type: Literal[\"primary\", \"secondary\"] = \"secondary\",\n        disabled: bool = False,\n        use_container_width: bool = False,\n        ctx: ScriptRunContext | None = None,\n    ) -> bool:\n        key = to_key(key)\n\n        check_cache_replay_rules()\n        check_session_state_rules(default_value=None, key=key, writes_allowed=False)\n        check_callback_rules(self.dg, on_click)\n\n        id = compute_widget_id(\n            \"download_button\",\n            user_key=key,\n            label=label,\n            file_name=file_name,\n            mime=mime,\n            key=key,\n            help=help,\n            type=type,\n            use_container_width=use_container_width,\n            page=ctx.active_script_hash if ctx else None,\n        )\n\n        if is_in_form(self.dg):\n            raise StreamlitAPIException(\n                f\"`st.download_button()` can't be used in an `st.form()`.{FORM_DOCS_INFO}\"\n            )\n\n        download_button_proto = DownloadButtonProto()\n        download_button_proto.id = id\n        download_button_proto.use_container_width = use_container_width\n        download_button_proto.label = label\n        download_button_proto.default = False\n        download_button_proto.type = type\n        marshall_file(\n            self.dg._get_delta_path_str(), data, download_button_proto, mime, file_name\n        )\n        download_button_proto.disabled = disabled\n\n        if help is not None:\n            download_button_proto.help = dedent(help)\n\n        serde = ButtonSerde()\n\n        button_state = register_widget(\n            \"download_button\",\n            download_button_proto,\n            user_key=key,\n            on_change_handler=on_click,\n            args=args,\n            kwargs=kwargs,\n            deserializer=serde.deserialize,\n            serializer=serde.serialize,\n            ctx=ctx,\n        )\n\n        self.dg._enqueue(\"download_button\", download_button_proto)\n        return button_state.value\n\n    def _link_button(\n        self,\n        label: str,\n        url: str,\n        help: str | None,\n        *,  # keyword-only arguments:\n        type: Literal[\"primary\", \"secondary\"] = \"secondary\",\n        disabled: bool = False,\n        use_container_width: bool = False,\n    ) -> DeltaGenerator:\n        link_button_proto = LinkButtonProto()\n        link_button_proto.label = label\n        link_button_proto.url = url\n        link_button_proto.type = type\n        link_button_proto.use_container_width = use_container_width\n        link_button_proto.disabled = disabled\n\n        if help is not None:\n            link_button_proto.help = dedent(help)\n\n        return self.dg._enqueue(\"link_button\", link_button_proto)\n\n    def _page_link(\n        self,\n        page: str | StreamlitPage,\n        *,  # keyword-only arguments:\n        label: str | None = None,\n        icon: str | None = None,\n        help: str | None = None,\n        disabled: bool = False,\n        use_container_width: bool | None = None,\n    ) -> DeltaGenerator:\n        page_link_proto = PageLinkProto()\n        page_link_proto.disabled = disabled\n\n        if label is not None:\n            page_link_proto.label = label\n\n        if icon is not None:\n            page_link_proto.icon = validate_icon_or_emoji(icon)\n\n        if help is not None:\n            page_link_proto.help = dedent(help)\n\n        if use_container_width is not None:\n            page_link_proto.use_container_width = use_container_width\n\n        if isinstance(page, StreamlitPage):\n            page_link_proto.page_script_hash = page._script_hash\n            page_link_proto.page = page.url_path\n            if label is None:\n                page_link_proto.label = page.title\n        else:\n            # Handle external links:\n            if is_url(page):\n                if label is None or label == \"\":\n                    raise StreamlitAPIException(\n                        \"The label param is required for external links used with st.page_link - please provide a label.\"\n                    )\n                else:\n                    page_link_proto.page = page\n                    page_link_proto.external = True\n                    return self.dg._enqueue(\"page_link\", page_link_proto)\n\n            ctx = get_script_run_ctx()\n            ctx_main_script = \"\"\n            all_app_pages = {}\n            if ctx:\n                ctx_main_script = ctx.main_script_path\n                all_app_pages = ctx.pages_manager.get_pages()\n\n            main_script_directory = get_main_script_directory(ctx_main_script)\n            requested_page = os.path.realpath(\n                normalize_path_join(main_script_directory, page)\n            )\n\n            # Handle retrieving the page_script_hash & page\n            for page_data in all_app_pages.values():\n                full_path = page_data[\"script_path\"]\n                page_name = page_data[\"page_name\"]\n                if requested_page == full_path:\n                    if label is None:\n                        page_link_proto.label = page_name.replace(\"_\", \" \")\n                    page_link_proto.page_script_hash = page_data[\"page_script_hash\"]\n                    page_link_proto.page = page_name\n                    break\n\n        if page_link_proto.page_script_hash == \"\":\n            raise StreamlitAPIException(\n                f\"Could not find page: `{page}`. Must be the file path relative to the main script, from the directory: `{os.path.basename(main_script_directory)}`. Only the main app file and files in the `pages/` directory are supported.\"\n            )\n\n        return self.dg._enqueue(\"page_link\", page_link_proto)\n\n    def _button(\n        self,\n        label: str,\n        key: str | None,\n        help: str | None,\n        is_form_submitter: bool,\n        on_click: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        *,  # keyword-only arguments:\n        type: Literal[\"primary\", \"secondary\"] = \"secondary\",\n        disabled: bool = False,\n        use_container_width: bool = False,\n        ctx: ScriptRunContext | None = None,\n    ) -> bool:\n        key = to_key(key)\n\n        check_fragment_path_policy(self.dg)\n        if not is_form_submitter:\n            check_callback_rules(self.dg, on_click)\n        check_cache_replay_rules()\n        check_session_state_rules(default_value=None, key=key, writes_allowed=False)\n\n        id = compute_widget_id(\n            \"button\",\n            user_key=key,\n            label=label,\n            key=key,\n            help=help,\n            is_form_submitter=is_form_submitter,\n            type=type,\n            use_container_width=use_container_width,\n            page=ctx.active_script_hash if ctx else None,\n        )\n\n        # It doesn't make sense to create a button inside a form (except\n        # for the \"Form Submitter\" button that's automatically created in\n        # every form). We throw an error to warn the user about this.\n        # We omit this check for scripts running outside streamlit, because\n        # they will have no script_run_ctx.\n        if runtime.exists():\n            if is_in_form(self.dg) and not is_form_submitter:\n                raise StreamlitAPIException(\n                    f\"`st.button()` can't be used in an `st.form()`.{FORM_DOCS_INFO}\"\n                )\n            elif not is_in_form(self.dg) and is_form_submitter:\n                raise StreamlitAPIException(\n                    f\"`st.form_submit_button()` must be used inside an `st.form()`.{FORM_DOCS_INFO}\"\n                )\n\n        button_proto = ButtonProto()\n        button_proto.id = id\n        button_proto.label = label\n        button_proto.default = False\n        button_proto.is_form_submitter = is_form_submitter\n        button_proto.form_id = current_form_id(self.dg)\n        button_proto.type = type\n        button_proto.use_container_width = use_container_width\n        button_proto.disabled = disabled\n\n        if help is not None:\n            button_proto.help = dedent(help)\n\n        serde = ButtonSerde()\n\n        button_state = register_widget(\n            \"button\",\n            button_proto,\n            user_key=key,\n            on_change_handler=on_click,\n            args=args,\n            kwargs=kwargs,\n            deserializer=serde.deserialize,\n            serializer=serde.serialize,\n            ctx=ctx,\n        )\n\n        if ctx:\n            save_for_app_testing(ctx, id, button_state.value)\n        self.dg._enqueue(\"button\", button_proto)\n\n        return button_state.value\n\n    @property\n    def dg(self) -> DeltaGenerator:\n        \"\"\"Get our DeltaGenerator.\"\"\"\n        return cast(\"DeltaGenerator\", self)\n\n\ndef marshall_file(\n    coordinates: str,\n    data: DownloadButtonDataType,\n    proto_download_button: DownloadButtonProto,\n    mimetype: str | None,\n    file_name: str | None = None,\n) -> None:\n    data_as_bytes: bytes\n    if isinstance(data, str):\n        data_as_bytes = data.encode()\n        mimetype = mimetype or \"text/plain\"\n    elif isinstance(data, io.TextIOWrapper):\n        string_data = data.read()\n        data_as_bytes = string_data.encode()\n        mimetype = mimetype or \"text/plain\"\n    # Assume bytes; try methods until we run out.\n    elif isinstance(data, bytes):\n        data_as_bytes = data\n        mimetype = mimetype or \"application/octet-stream\"\n    elif isinstance(data, io.BytesIO):\n        data.seek(0)\n        data_as_bytes = data.getvalue()\n        mimetype = mimetype or \"application/octet-stream\"\n    elif isinstance(data, io.BufferedReader):\n        data.seek(0)\n        data_as_bytes = data.read()\n        mimetype = mimetype or \"application/octet-stream\"\n    elif isinstance(data, io.RawIOBase):\n        data.seek(0)\n        data_as_bytes = data.read() or b\"\"\n        mimetype = mimetype or \"application/octet-stream\"\n    else:\n        raise RuntimeError(\"Invalid binary data format: %s\" % type(data))\n\n    if runtime.exists():\n        file_url = runtime.get_instance().media_file_mgr.add(\n            data_as_bytes,\n            mimetype,\n            coordinates,\n            file_name=file_name,\n            is_for_static_download=True,\n        )\n    else:\n        # When running in \"raw mode\", we can't access the MediaFileManager.\n        file_url = \"\"\n\n    proto_download_button.url = file_url\n", "lib/streamlit/elements/widgets/chat.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom dataclasses import dataclass\nfrom enum import Enum\nfrom typing import TYPE_CHECKING, Literal, cast\n\nfrom streamlit import runtime\nfrom streamlit.elements.form import is_in_form\nfrom streamlit.elements.image import AtomicImage, WidthBehaviour, image_to_url\nfrom streamlit.elements.lib.policies import (\n    check_cache_replay_rules,\n    check_callback_rules,\n    check_fragment_path_policy,\n    check_session_state_rules,\n)\nfrom streamlit.errors import StreamlitAPIException\nfrom streamlit.proto.Block_pb2 import Block as BlockProto\nfrom streamlit.proto.ChatInput_pb2 import ChatInput as ChatInputProto\nfrom streamlit.proto.Common_pb2 import StringTriggerValue as StringTriggerValueProto\nfrom streamlit.proto.RootContainer_pb2 import RootContainer\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.runtime.scriptrunner import get_script_run_ctx\nfrom streamlit.runtime.state import (\n    WidgetArgs,\n    WidgetCallback,\n    WidgetKwargs,\n    register_widget,\n)\nfrom streamlit.runtime.state.common import compute_widget_id, save_for_app_testing\nfrom streamlit.string_util import is_emoji, validate_material_icon\nfrom streamlit.type_util import Key, to_key\n\nif TYPE_CHECKING:\n    from streamlit.delta_generator import DeltaGenerator\n\n\nclass PresetNames(str, Enum):\n    USER = \"user\"\n    ASSISTANT = \"assistant\"\n    AI = \"ai\"  # Equivalent to assistant\n    HUMAN = \"human\"  # Equivalent to user\n\n\ndef _process_avatar_input(\n    avatar: str | AtomicImage | None, delta_path: str\n) -> tuple[BlockProto.ChatMessage.AvatarType.ValueType, str]:\n    \"\"\"Detects the avatar type and prepares the avatar data for the frontend.\n\n    Parameters\n    ----------\n    avatar :\n        The avatar that was provided by the user.\n    delta_path : str\n        The delta path is used as media ID when a local image is served via the media\n        file manager.\n\n    Returns\n    -------\n    Tuple[AvatarType, str]\n        The detected avatar type and the prepared avatar data.\n    \"\"\"\n    AvatarType = BlockProto.ChatMessage.AvatarType\n\n    if avatar is None:\n        return AvatarType.ICON, \"\"\n    elif isinstance(avatar, str) and avatar in {item.value for item in PresetNames}:\n        # On the frontend, we only support \"assistant\" and \"user\" for the avatar.\n        return (\n            AvatarType.ICON,\n            (\n                \"assistant\"\n                if avatar in [PresetNames.AI, PresetNames.ASSISTANT]\n                else \"user\"\n            ),\n        )\n    elif isinstance(avatar, str) and is_emoji(avatar):\n        return AvatarType.EMOJI, avatar\n\n    elif isinstance(avatar, str) and avatar.startswith(\":material\"):\n        return AvatarType.ICON, validate_material_icon(avatar)\n    else:\n        try:\n            return AvatarType.IMAGE, image_to_url(\n                avatar,\n                width=WidthBehaviour.ORIGINAL,\n                clamp=False,\n                channels=\"RGB\",\n                output_format=\"auto\",\n                image_id=delta_path,\n            )\n        except Exception as ex:\n            raise StreamlitAPIException(\n                \"Failed to load the provided avatar value as an image.\"\n            ) from ex\n\n\n@dataclass\nclass ChatInputSerde:\n    def deserialize(\n        self, ui_value: StringTriggerValueProto | None, widget_id: str = \"\"\n    ) -> str | None:\n        if ui_value is None or not ui_value.HasField(\"data\"):\n            return None\n\n        return ui_value.data\n\n    def serialize(self, v: str | None) -> StringTriggerValueProto:\n        return StringTriggerValueProto(data=v)\n\n\nclass ChatMixin:\n    @gather_metrics(\"chat_message\")\n    def chat_message(\n        self,\n        name: Literal[\"user\", \"assistant\", \"ai\", \"human\"] | str,\n        *,\n        avatar: Literal[\"user\", \"assistant\"] | str | AtomicImage | None = None,\n    ) -> DeltaGenerator:\n        \"\"\"Insert a chat message container.\n\n        To add elements to the returned container, you can use ``with`` notation\n        (preferred) or just call methods directly on the returned object. See the\n        examples below.\n\n        Parameters\n        ----------\n        name : \"user\", \"assistant\", \"ai\", \"human\", or str\n            The name of the message author. Can be \"human\"/\"user\" or\n            \"ai\"/\"assistant\" to enable preset styling and avatars.\n\n            Currently, the name is not shown in the UI but is only set as an\n            accessibility label. For accessibility reasons, you should not use\n            an empty string.\n\n        avatar : Anything supported by st.image, str, or None\n            The avatar shown next to the message.\n\n            If ``avatar`` is ``None`` (default), the icon will be determined\n            from ``name`` as follows:\n\n            * If ``name`` is ``\"user\"`` or ``\"human\"``, the message will have a\n              default user icon.\n\n            * If ``name`` is ``\"ai\"`` or ``\"assistant\"``, the message will have\n              a default bot icon.\n\n            * For all other values of ``name``, the message will show the first\n              letter of the name.\n\n            In addition to the types supported by ``st.image`` (like URLs or numpy\n            arrays), the following strings are valid:\n\n            * A single-character emoji. For example, you can set ``avatar=\"\ud83e\uddd1\u200d\ud83d\udcbb\"``\n              or ``avatar=\"\ud83e\udd96\"``. Emoji short codes are not supported.\n\n            * An icon from the Material Symbols library (outlined style) in the\n              format ``\":material/icon_name:\"`` where \"icon_name\" is the name\n              of the icon in snake case.\n\n              For example, ``icon=\":material/thumb_up:\"`` will display the\n              Thumb Up icon. Find additional icons in the `Material Symbols \\\n              <https://fonts.google.com/icons?icon.set=Material+Symbols&icon.style=Outlined>`_\n              font library.\n\n        Returns\n        -------\n        Container\n            A single container that can hold multiple elements.\n\n        Examples\n        --------\n        You can use ``with`` notation to insert any element into an expander\n\n        >>> import streamlit as st\n        >>> import numpy as np\n        >>>\n        >>> with st.chat_message(\"user\"):\n        ...     st.write(\"Hello \ud83d\udc4b\")\n        ...     st.line_chart(np.random.randn(30, 3))\n\n        .. output ::\n            https://doc-chat-message-user.streamlit.app/\n            height: 450px\n\n        Or you can just call methods directly in the returned objects:\n\n        >>> import streamlit as st\n        >>> import numpy as np\n        >>>\n        >>> message = st.chat_message(\"assistant\")\n        >>> message.write(\"Hello human\")\n        >>> message.bar_chart(np.random.randn(30, 3))\n\n        .. output ::\n            https://doc-chat-message-user1.streamlit.app/\n            height: 450px\n\n        \"\"\"\n        if name is None:\n            raise StreamlitAPIException(\n                \"The author name is required for a chat message, please set it via the parameter `name`.\"\n            )\n\n        if avatar is None and (\n            name.lower() in {item.value for item in PresetNames} or is_emoji(name)\n        ):\n            # For selected labels, we are mapping the label to an avatar\n            avatar = name.lower()\n        avatar_type, converted_avatar = _process_avatar_input(\n            avatar, self.dg._get_delta_path_str()\n        )\n\n        message_container_proto = BlockProto.ChatMessage()\n        message_container_proto.name = name\n        message_container_proto.avatar = converted_avatar\n        message_container_proto.avatar_type = avatar_type\n        block_proto = BlockProto()\n        block_proto.allow_empty = True\n        block_proto.chat_message.CopyFrom(message_container_proto)\n\n        return self.dg._block(block_proto=block_proto)\n\n    @gather_metrics(\"chat_input\")\n    def chat_input(\n        self,\n        placeholder: str = \"Your message\",\n        *,\n        key: Key | None = None,\n        max_chars: int | None = None,\n        disabled: bool = False,\n        on_submit: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n    ) -> str | None:\n        \"\"\"Display a chat input widget.\n\n        Parameters\n        ----------\n        placeholder : str\n            A placeholder text shown when the chat input is empty. Defaults to\n            \"Your message\". For accessibility reasons, you should not use an\n            empty string.\n\n        key : str or int\n            An optional string or integer to use as the unique key for the widget.\n            If this is omitted, a key will be generated for the widget based on\n            its content. Multiple widgets of the same type may not share the same key.\n\n        max_chars : int or None\n            The maximum number of characters that can be entered. If ``None``\n            (default), there will be no maximum.\n\n        disabled : bool\n            Whether the chat input should be disabled. Defaults to ``False``.\n\n        on_submit : callable\n            An optional callback invoked when the chat input's value is submitted.\n\n        args : tuple\n            An optional tuple of args to pass to the callback.\n\n        kwargs : dict\n            An optional dict of kwargs to pass to the callback.\n\n        Returns\n        -------\n        str or None\n            The current (non-empty) value of the text input widget on the last\n            run of the app. Otherwise, ``None``.\n\n        Examples\n        --------\n        When ``st.chat_input`` is used in the main body of an app, it will be\n        pinned to the bottom of the page.\n\n        >>> import streamlit as st\n        >>>\n        >>> prompt = st.chat_input(\"Say something\")\n        >>> if prompt:\n        ...     st.write(f\"User has sent the following prompt: {prompt}\")\n\n        .. output ::\n            https://doc-chat-input.streamlit.app/\n            height: 350px\n\n        The chat input can also be used inline by nesting it inside any layout\n        container (container, columns, tabs, sidebar, etc). Create chat\n        interfaces embedded next to other content or have multiple chat bots!\n\n        >>> import streamlit as st\n        >>>\n        >>> with st.sidebar:\n        >>>     messages = st.container(height=300)\n        >>>     if prompt := st.chat_input(\"Say something\"):\n        >>>         messages.chat_message(\"user\").write(prompt)\n        >>>         messages.chat_message(\"assistant\").write(f\"Echo: {prompt}\")\n\n        .. output ::\n            https://doc-chat-input-inline.streamlit.app/\n            height: 350px\n        \"\"\"\n        # We default to an empty string here and disallow user choice intentionally\n        default = \"\"\n        key = to_key(key)\n\n        check_fragment_path_policy(self.dg)\n        check_cache_replay_rules()\n        check_callback_rules(self.dg, on_submit)\n        check_session_state_rules(default_value=default, key=key, writes_allowed=False)\n\n        ctx = get_script_run_ctx()\n        id = compute_widget_id(\n            \"chat_input\",\n            user_key=key,\n            key=key,\n            placeholder=placeholder,\n            max_chars=max_chars,\n            page=ctx.active_script_hash if ctx else None,\n        )\n\n        # It doesn't make sense to create a chat input inside a form.\n        # We throw an error to warn the user about this.\n        # We omit this check for scripts running outside streamlit, because\n        # they will have no script_run_ctx.\n        if runtime.exists():\n            if is_in_form(self.dg):\n                raise StreamlitAPIException(\n                    \"`st.chat_input()` can't be used in a `st.form()`.\"\n                )\n\n        # Determine the position of the chat input:\n        # Use bottom position if chat input is within the main container\n        # either directly or within a vertical container. If it has any\n        # other container types as parents, we use inline position.\n        ancestor_block_types = set(self.dg._active_dg._ancestor_block_types)\n        if (\n            self.dg._active_dg._root_container == RootContainer.MAIN\n            and not ancestor_block_types\n        ):\n            position = \"bottom\"\n        else:\n            position = \"inline\"\n\n        chat_input_proto = ChatInputProto()\n        chat_input_proto.id = id\n        chat_input_proto.placeholder = str(placeholder)\n\n        if max_chars is not None:\n            chat_input_proto.max_chars = max_chars\n\n        chat_input_proto.default = default\n\n        serde = ChatInputSerde()\n        widget_state = register_widget(\n            \"chat_input\",\n            chat_input_proto,\n            user_key=key,\n            on_change_handler=on_submit,\n            args=args,\n            kwargs=kwargs,\n            deserializer=serde.deserialize,\n            serializer=serde.serialize,\n            ctx=ctx,\n        )\n\n        chat_input_proto.disabled = disabled\n        if widget_state.value_changed and widget_state.value is not None:\n            chat_input_proto.value = widget_state.value\n            chat_input_proto.set_value = True\n\n        if ctx:\n            save_for_app_testing(ctx, id, widget_state.value)\n        if position == \"bottom\":\n            # We import it here to avoid circular imports.\n            from streamlit import _bottom\n\n            # We need to enqueue the chat input into the bottom container\n            # instead of the currently active dg.\n            _bottom._enqueue(\"chat_input\", chat_input_proto)\n        else:\n            self.dg._enqueue(\"chat_input\", chat_input_proto)\n\n        return widget_state.value if not widget_state.value_changed else None\n\n    @property\n    def dg(self) -> DeltaGenerator:\n        \"\"\"Get our DeltaGenerator.\"\"\"\n        return cast(\"DeltaGenerator\", self)\n", "lib/streamlit/elements/widgets/camera_input.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom dataclasses import dataclass\nfrom textwrap import dedent\nfrom typing import TYPE_CHECKING, Union, cast\n\nfrom typing_extensions import TypeAlias\n\nfrom streamlit.elements.form import current_form_id\nfrom streamlit.elements.lib.policies import (\n    check_cache_replay_rules,\n    check_callback_rules,\n    check_fragment_path_policy,\n    check_session_state_rules,\n)\nfrom streamlit.elements.lib.utils import get_label_visibility_proto_value\nfrom streamlit.elements.widgets.file_uploader import _get_upload_files\nfrom streamlit.proto.CameraInput_pb2 import CameraInput as CameraInputProto\nfrom streamlit.proto.Common_pb2 import FileUploaderState as FileUploaderStateProto\nfrom streamlit.proto.Common_pb2 import UploadedFileInfo as UploadedFileInfoProto\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.runtime.scriptrunner import ScriptRunContext, get_script_run_ctx\nfrom streamlit.runtime.state import (\n    WidgetArgs,\n    WidgetCallback,\n    WidgetKwargs,\n    register_widget,\n)\nfrom streamlit.runtime.state.common import compute_widget_id\nfrom streamlit.runtime.uploaded_file_manager import DeletedFile, UploadedFile\nfrom streamlit.type_util import Key, LabelVisibility, maybe_raise_label_warnings, to_key\n\nif TYPE_CHECKING:\n    from streamlit.delta_generator import DeltaGenerator\n\nSomeUploadedSnapshotFile: TypeAlias = Union[UploadedFile, DeletedFile, None]\n\n\n@dataclass\nclass CameraInputSerde:\n    def serialize(\n        self,\n        snapshot: SomeUploadedSnapshotFile,\n    ) -> FileUploaderStateProto:\n        state_proto = FileUploaderStateProto()\n\n        if snapshot is None or isinstance(snapshot, DeletedFile):\n            return state_proto\n\n        file_info: UploadedFileInfoProto = state_proto.uploaded_file_info.add()\n        file_info.file_id = snapshot.file_id\n        file_info.name = snapshot.name\n        file_info.size = snapshot.size\n        file_info.file_urls.CopyFrom(snapshot._file_urls)\n\n        return state_proto\n\n    def deserialize(\n        self, ui_value: FileUploaderStateProto | None, widget_id: str\n    ) -> SomeUploadedSnapshotFile:\n        upload_files = _get_upload_files(ui_value)\n        if len(upload_files) == 0:\n            return_value = None\n        else:\n            return_value = upload_files[0]\n        return return_value\n\n\nclass CameraInputMixin:\n    @gather_metrics(\"camera_input\")\n    def camera_input(\n        self,\n        label: str,\n        key: Key | None = None,\n        help: str | None = None,\n        on_change: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        *,  # keyword-only arguments:\n        disabled: bool = False,\n        label_visibility: LabelVisibility = \"visible\",\n    ) -> UploadedFile | None:\n        r\"\"\"Display a widget that returns pictures from the user's webcam.\n\n        Parameters\n        ----------\n        label : str\n            A short label explaining to the user what this widget is used for.\n            The label can optionally contain Markdown and supports the following\n            elements: Bold, Italics, Strikethroughs, Inline Code, Emojis, and Links.\n\n            This also supports:\n\n            * Emoji shortcodes, such as ``:+1:``  and ``:sunglasses:``.\n              For a list of all supported codes,\n              see https://share.streamlit.io/streamlit/emoji-shortcodes.\n\n            * LaTeX expressions, by wrapping them in \"$\" or \"$$\" (the \"$$\"\n              must be on their own lines). Supported LaTeX functions are listed\n              at https://katex.org/docs/supported.html.\n\n            * Colored text and background colors for text, using the syntax\n              ``:color[text to be colored]`` and ``:color-background[text to be colored]``,\n              respectively. ``color`` must be replaced with any of the following\n              supported colors: blue, green, orange, red, violet, gray/grey, rainbow.\n              For example, you can use ``:orange[your text here]`` or\n              ``:blue-background[your text here]``.\n\n            Unsupported elements are unwrapped so only their children (text contents) render.\n            Display unsupported elements as literal characters by\n            backslash-escaping them. E.g. ``1\\. Not an ordered list``.\n\n            For accessibility reasons, you should never set an empty label (label=\"\")\n            but hide it with label_visibility if needed. In the future, we may disallow\n            empty labels by raising an exception.\n\n        key : str or int\n            An optional string or integer to use as the unique key for the widget.\n            If this is omitted, a key will be generated for the widget\n            based on its content. Multiple widgets of the same type may\n            not share the same key.\n\n        help : str\n            A tooltip that gets displayed next to the camera input.\n\n        on_change : callable\n            An optional callback invoked when this camera_input's value\n            changes.\n\n        args : tuple\n            An optional tuple of args to pass to the callback.\n\n        kwargs : dict\n            An optional dict of kwargs to pass to the callback.\n\n        disabled : bool\n            An optional boolean, which disables the camera input if set to\n            True. Default is False.\n        label_visibility : \"visible\", \"hidden\", or \"collapsed\"\n            The visibility of the label. If \"hidden\", the label doesn't show but there\n            is still empty space for it above the widget (equivalent to label=\"\").\n            If \"collapsed\", both the label and the space are removed. Default is\n            \"visible\".\n\n        Returns\n        -------\n        None or UploadedFile\n            The UploadedFile class is a subclass of BytesIO, and therefore\n            it is \"file-like\". This means you can pass them anywhere where\n            a file is expected.\n\n        Examples\n        --------\n        >>> import streamlit as st\n        >>>\n        >>> picture = st.camera_input(\"Take a picture\")\n        >>>\n        >>> if picture:\n        ...     st.image(picture)\n\n        \"\"\"\n        ctx = get_script_run_ctx()\n        return self._camera_input(\n            label=label,\n            key=key,\n            help=help,\n            on_change=on_change,\n            args=args,\n            kwargs=kwargs,\n            disabled=disabled,\n            label_visibility=label_visibility,\n            ctx=ctx,\n        )\n\n    def _camera_input(\n        self,\n        label: str,\n        key: Key | None = None,\n        help: str | None = None,\n        on_change: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        *,  # keyword-only arguments:\n        disabled: bool = False,\n        label_visibility: LabelVisibility = \"visible\",\n        ctx: ScriptRunContext | None = None,\n    ) -> UploadedFile | None:\n        key = to_key(key)\n\n        check_fragment_path_policy(self.dg)\n        check_cache_replay_rules()\n        check_callback_rules(self.dg, on_change)\n        check_session_state_rules(default_value=None, key=key, writes_allowed=False)\n        maybe_raise_label_warnings(label, label_visibility)\n\n        id = compute_widget_id(\n            \"camera_input\",\n            user_key=key,\n            label=label,\n            key=key,\n            help=help,\n            form_id=current_form_id(self.dg),\n            page=ctx.active_script_hash if ctx else None,\n        )\n\n        camera_input_proto = CameraInputProto()\n        camera_input_proto.id = id\n        camera_input_proto.label = label\n        camera_input_proto.form_id = current_form_id(self.dg)\n        camera_input_proto.disabled = disabled\n        camera_input_proto.label_visibility.value = get_label_visibility_proto_value(\n            label_visibility\n        )\n\n        if help is not None:\n            camera_input_proto.help = dedent(help)\n\n        serde = CameraInputSerde()\n\n        camera_input_state = register_widget(\n            \"camera_input\",\n            camera_input_proto,\n            user_key=key,\n            on_change_handler=on_change,\n            args=args,\n            kwargs=kwargs,\n            deserializer=serde.deserialize,\n            serializer=serde.serialize,\n            ctx=ctx,\n        )\n\n        self.dg._enqueue(\"camera_input\", camera_input_proto)\n\n        if isinstance(camera_input_state.value, DeletedFile):\n            return None\n        return camera_input_state.value\n\n    @property\n    def dg(self) -> DeltaGenerator:\n        \"\"\"Get our DeltaGenerator.\"\"\"\n        return cast(\"DeltaGenerator\", self)\n", "lib/streamlit/elements/widgets/time_widgets.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nfrom __future__ import annotations\n\nimport re\nfrom dataclasses import dataclass\nfrom datetime import date, datetime, time, timedelta\nfrom textwrap import dedent\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    Final,\n    List,\n    Literal,\n    Sequence,\n    Tuple,\n    Union,\n    cast,\n    overload,\n)\n\nfrom typing_extensions import TypeAlias\n\nfrom streamlit.elements.form import current_form_id\nfrom streamlit.elements.lib.policies import (\n    check_cache_replay_rules,\n    check_callback_rules,\n    check_fragment_path_policy,\n    check_session_state_rules,\n)\nfrom streamlit.elements.lib.utils import get_label_visibility_proto_value\nfrom streamlit.errors import StreamlitAPIException\nfrom streamlit.proto.DateInput_pb2 import DateInput as DateInputProto\nfrom streamlit.proto.TimeInput_pb2 import TimeInput as TimeInputProto\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.runtime.scriptrunner import ScriptRunContext, get_script_run_ctx\nfrom streamlit.runtime.state import (\n    WidgetArgs,\n    WidgetCallback,\n    WidgetKwargs,\n    get_session_state,\n    register_widget,\n)\nfrom streamlit.runtime.state.common import compute_widget_id\nfrom streamlit.time_util import adjust_years\nfrom streamlit.type_util import Key, LabelVisibility, maybe_raise_label_warnings, to_key\n\nif TYPE_CHECKING:\n    from streamlit.delta_generator import DeltaGenerator\n\nSingleDateValue: TypeAlias = Union[date, datetime, None]\nDateValue: TypeAlias = Union[SingleDateValue, Sequence[SingleDateValue]]\nDateWidgetReturn: TypeAlias = Union[\n    date, Tuple[()], Tuple[date], Tuple[date, date], None\n]\n\nDEFAULT_STEP_MINUTES: Final = 15\nALLOWED_DATE_FORMATS: Final = re.compile(\n    r\"^(YYYY[/.\\-]MM[/.\\-]DD|DD[/.\\-]MM[/.\\-]YYYY|MM[/.\\-]DD[/.\\-]YYYY)$\"\n)\n\n\ndef _parse_date_value(\n    value: Literal[\"today\", \"default_value_today\"] | DateValue,\n) -> tuple[list[date] | None, bool]:\n    parsed_dates: list[date]\n    range_value: bool = False\n    if value is None:\n        return None, range_value\n    if value == \"today\":\n        parsed_dates = [datetime.now().date()]\n    elif value == \"default_value_today\":\n        parsed_dates = [datetime.now().date()]\n    elif isinstance(value, datetime):\n        parsed_dates = [value.date()]\n    elif isinstance(value, date):\n        parsed_dates = [value]\n    elif isinstance(value, (list, tuple)):\n        if len(value) not in {0, 1, 2}:\n            raise StreamlitAPIException(\n                \"DateInput value should either be an date/datetime or a list/tuple of \"\n                \"0 - 2 date/datetime values\"\n            )\n\n        parsed_dates = [v.date() if isinstance(v, datetime) else v for v in value]\n        range_value = True\n    else:\n        raise StreamlitAPIException(\n            \"DateInput value should either be an date/datetime or a list/tuple of \"\n            \"0 - 2 date/datetime values\"\n        )\n    return parsed_dates, range_value\n\n\ndef _parse_min_date(\n    min_value: SingleDateValue,\n    parsed_dates: Sequence[date] | None,\n) -> date:\n    parsed_min_date: date\n    if isinstance(min_value, datetime):\n        parsed_min_date = min_value.date()\n    elif isinstance(min_value, date):\n        parsed_min_date = min_value\n    elif min_value is None:\n        if parsed_dates:\n            parsed_min_date = adjust_years(parsed_dates[0], years=-10)\n        else:\n            parsed_min_date = adjust_years(date.today(), years=-10)\n    else:\n        raise StreamlitAPIException(\n            \"DateInput min should either be a date/datetime or None\"\n        )\n    return parsed_min_date\n\n\ndef _parse_max_date(\n    max_value: SingleDateValue,\n    parsed_dates: Sequence[date] | None,\n) -> date:\n    parsed_max_date: date\n    if isinstance(max_value, datetime):\n        parsed_max_date = max_value.date()\n    elif isinstance(max_value, date):\n        parsed_max_date = max_value\n    elif max_value is None:\n        if parsed_dates:\n            parsed_max_date = adjust_years(parsed_dates[-1], years=10)\n        else:\n            parsed_max_date = adjust_years(date.today(), years=10)\n    else:\n        raise StreamlitAPIException(\n            \"DateInput max should either be a date/datetime or None\"\n        )\n    return parsed_max_date\n\n\n@dataclass(frozen=True)\nclass _DateInputValues:\n    value: Sequence[date] | None\n    is_range: bool\n    max: date\n    min: date\n\n    @classmethod\n    def from_raw_values(\n        cls,\n        value: Literal[\"today\", \"default_value_today\"] | DateValue,\n        min_value: SingleDateValue,\n        max_value: SingleDateValue,\n    ) -> _DateInputValues:\n        parsed_value, is_range = _parse_date_value(value=value)\n        parsed_min = _parse_min_date(\n            min_value=min_value,\n            parsed_dates=parsed_value,\n        )\n        parsed_max = _parse_max_date(\n            max_value=max_value,\n            parsed_dates=parsed_value,\n        )\n\n        if value == \"default_value_today\":\n            v = cast(List[date], parsed_value)[0]\n            if v < parsed_min:\n                parsed_value = [parsed_min]\n            if v > parsed_max:\n                parsed_value = [parsed_max]\n\n        return cls(\n            value=parsed_value,\n            is_range=is_range,\n            min=parsed_min,\n            max=parsed_max,\n        )\n\n    def __post_init__(self) -> None:\n        if self.min > self.max:\n            raise StreamlitAPIException(\n                f\"The `min_value`, set to {self.min}, shouldn't be larger \"\n                f\"than the `max_value`, set to {self.max}.\"\n            )\n\n        if self.value:\n            start_value = self.value[0]\n            end_value = self.value[-1]\n\n            if (start_value < self.min) or (end_value > self.max):\n                raise StreamlitAPIException(\n                    f\"The default `value` of {self.value} \"\n                    f\"must lie between the `min_value` of {self.min} \"\n                    f\"and the `max_value` of {self.max}, inclusively.\"\n                )\n\n\n@dataclass\nclass TimeInputSerde:\n    value: time | None\n\n    def deserialize(self, ui_value: str | None, widget_id: Any = \"\") -> time | None:\n        return (\n            datetime.strptime(ui_value, \"%H:%M\").time()\n            if ui_value is not None\n            else self.value\n        )\n\n    def serialize(self, v: datetime | time | None) -> str | None:\n        if v is None:\n            return None\n        if isinstance(v, datetime):\n            v = v.time()\n        return time.strftime(v, \"%H:%M\")\n\n\n@dataclass\nclass DateInputSerde:\n    value: _DateInputValues\n\n    def deserialize(\n        self,\n        ui_value: Any,\n        widget_id: str = \"\",\n    ) -> DateWidgetReturn:\n        return_value: Sequence[date] | None\n        if ui_value is not None:\n            return_value = tuple(\n                datetime.strptime(v, \"%Y/%m/%d\").date() for v in ui_value\n            )\n        else:\n            return_value = self.value.value\n\n        if return_value is None or len(return_value) == 0:\n            return () if self.value.is_range else None\n\n        if not self.value.is_range:\n            return return_value[0]\n        return cast(DateWidgetReturn, tuple(return_value))\n\n    def serialize(self, v: DateWidgetReturn) -> list[str]:\n        if v is None:\n            return []\n\n        to_serialize = list(v) if isinstance(v, (list, tuple)) else [v]\n        return [date.strftime(v, \"%Y/%m/%d\") for v in to_serialize]\n\n\nclass TimeWidgetsMixin:\n    @overload\n    def time_input(\n        self,\n        label: str,\n        value: time | datetime | Literal[\"now\"] = \"now\",\n        key: Key | None = None,\n        help: str | None = None,\n        on_change: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        *,  # keyword-only arguments:\n        disabled: bool = False,\n        label_visibility: LabelVisibility = \"visible\",\n        step: int | timedelta = timedelta(minutes=DEFAULT_STEP_MINUTES),\n    ) -> time:\n        pass\n\n    @overload\n    def time_input(\n        self,\n        label: str,\n        value: None = None,\n        key: Key | None = None,\n        help: str | None = None,\n        on_change: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        *,  # keyword-only arguments:\n        disabled: bool = False,\n        label_visibility: LabelVisibility = \"visible\",\n        step: int | timedelta = timedelta(minutes=DEFAULT_STEP_MINUTES),\n    ) -> time | None:\n        pass\n\n    @gather_metrics(\"time_input\")\n    def time_input(\n        self,\n        label: str,\n        value: time | datetime | Literal[\"now\"] | None = \"now\",\n        key: Key | None = None,\n        help: str | None = None,\n        on_change: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        *,  # keyword-only arguments:\n        disabled: bool = False,\n        label_visibility: LabelVisibility = \"visible\",\n        step: int | timedelta = timedelta(minutes=DEFAULT_STEP_MINUTES),\n    ) -> time | None:\n        r\"\"\"Display a time input widget.\n\n        Parameters\n        ----------\n        label : str\n            A short label explaining to the user what this time input is for.\n            The label can optionally contain Markdown and supports the following\n            elements: Bold, Italics, Strikethroughs, Inline Code, Emojis, and Links.\n\n            This also supports:\n\n            * Emoji shortcodes, such as ``:+1:``  and ``:sunglasses:``.\n              For a list of all supported codes,\n              see https://share.streamlit.io/streamlit/emoji-shortcodes.\n\n            * LaTeX expressions, by wrapping them in \"$\" or \"$$\" (the \"$$\"\n              must be on their own lines). Supported LaTeX functions are listed\n              at https://katex.org/docs/supported.html.\n\n            * Colored text and background colors for text, using the syntax\n              ``:color[text to be colored]`` and ``:color-background[text to be colored]``,\n              respectively. ``color`` must be replaced with any of the following\n              supported colors: blue, green, orange, red, violet, gray/grey, rainbow.\n              For example, you can use ``:orange[your text here]`` or\n              ``:blue-background[your text here]``.\n\n            Unsupported elements are unwrapped so only their children (text contents) render.\n            Display unsupported elements as literal characters by\n            backslash-escaping them. E.g. ``1\\. Not an ordered list``.\n\n            For accessibility reasons, you should never set an empty label (label=\"\")\n            but hide it with label_visibility if needed. In the future, we may disallow\n            empty labels by raising an exception.\n        value : datetime.time/datetime.datetime, \"now\" or None\n            The value of this widget when it first renders. This will be\n            cast to str internally. If ``None``, will initialize empty and\n            return ``None`` until the user selects a time. If \"now\" (default),\n            will initialize with the current time.\n        key : str or int\n            An optional string or integer to use as the unique key for the widget.\n            If this is omitted, a key will be generated for the widget\n            based on its content. Multiple widgets of the same type may\n            not share the same key.\n        help : str\n            An optional tooltip that gets displayed next to the input.\n        on_change : callable\n            An optional callback invoked when this time_input's value changes.\n        args : tuple\n            An optional tuple of args to pass to the callback.\n        kwargs : dict\n            An optional dict of kwargs to pass to the callback.\n        disabled : bool\n            An optional boolean, which disables the time input if set to True.\n            The default is False.\n        label_visibility : \"visible\", \"hidden\", or \"collapsed\"\n            The visibility of the label. If \"hidden\", the label doesn't show but there\n            is still empty space for it above the widget (equivalent to label=\"\").\n            If \"collapsed\", both the label and the space are removed. Default is\n            \"visible\".\n        step : int or timedelta\n            The stepping interval in seconds. Defaults to 900, i.e. 15 minutes.\n            You can also pass a datetime.timedelta object.\n\n        Returns\n        -------\n        datetime.time or None\n            The current value of the time input widget or ``None`` if no time has been\n            selected.\n\n        Example\n        -------\n        >>> import datetime\n        >>> import streamlit as st\n        >>>\n        >>> t = st.time_input(\"Set an alarm for\", datetime.time(8, 45))\n        >>> st.write(\"Alarm is set for\", t)\n\n        .. output::\n           https://doc-time-input.streamlit.app/\n           height: 260px\n\n        To initialize an empty time input, use ``None`` as the value:\n\n        >>> import datetime\n        >>> import streamlit as st\n        >>>\n        >>> t = st.time_input(\"Set an alarm for\", value=None)\n        >>> st.write(\"Alarm is set for\", t)\n\n        .. output::\n           https://doc-time-input-empty.streamlit.app/\n           height: 260px\n\n        \"\"\"\n        ctx = get_script_run_ctx()\n        return self._time_input(\n            label=label,\n            value=value,\n            key=key,\n            help=help,\n            on_change=on_change,\n            args=args,\n            kwargs=kwargs,\n            disabled=disabled,\n            label_visibility=label_visibility,\n            step=step,\n            ctx=ctx,\n        )\n\n    def _time_input(\n        self,\n        label: str,\n        value: time | datetime | Literal[\"now\"] | None = \"now\",\n        key: Key | None = None,\n        help: str | None = None,\n        on_change: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        *,  # keyword-only arguments:\n        disabled: bool = False,\n        label_visibility: LabelVisibility = \"visible\",\n        step: int | timedelta = timedelta(minutes=DEFAULT_STEP_MINUTES),\n        ctx: ScriptRunContext | None = None,\n    ) -> time | None:\n        key = to_key(key)\n\n        check_fragment_path_policy(self.dg)\n        check_cache_replay_rules()\n        check_callback_rules(self.dg, on_change)\n        check_session_state_rules(\n            default_value=value if value != \"now\" else None, key=key\n        )\n        maybe_raise_label_warnings(label, label_visibility)\n\n        parsed_time: time | None\n        if value is None:\n            parsed_time = None\n        elif value == \"now\":\n            # Set value default.\n            parsed_time = datetime.now().time().replace(second=0, microsecond=0)\n        elif isinstance(value, datetime):\n            parsed_time = value.time().replace(second=0, microsecond=0)\n        elif isinstance(value, time):\n            parsed_time = value\n        else:\n            raise StreamlitAPIException(\n                \"The type of value should be one of datetime, time or None\"\n            )\n\n        id = compute_widget_id(\n            \"time_input\",\n            user_key=key,\n            label=label,\n            value=parsed_time if isinstance(value, (datetime, time)) else value,\n            key=key,\n            help=help,\n            step=step,\n            form_id=current_form_id(self.dg),\n            page=ctx.active_script_hash if ctx else None,\n        )\n        del value\n\n        session_state = get_session_state().filtered_state\n        if key is not None and key in session_state and session_state[key] is None:\n            parsed_time = None\n\n        time_input_proto = TimeInputProto()\n        time_input_proto.id = id\n        time_input_proto.label = label\n        if parsed_time is not None:\n            time_input_proto.default = time.strftime(parsed_time, \"%H:%M\")\n        time_input_proto.form_id = current_form_id(self.dg)\n        if not isinstance(step, (int, timedelta)):\n            raise StreamlitAPIException(\n                f\"`step` can only be `int` or `timedelta` but {type(step)} is provided.\"\n            )\n        if isinstance(step, timedelta):\n            step = step.seconds\n        if step < 60 or step > timedelta(hours=23).seconds:\n            raise StreamlitAPIException(\n                f\"`step` must be between 60 seconds and 23 hours but is currently set to {step} seconds.\"\n            )\n        time_input_proto.step = step\n        time_input_proto.disabled = disabled\n        time_input_proto.label_visibility.value = get_label_visibility_proto_value(\n            label_visibility\n        )\n\n        if help is not None:\n            time_input_proto.help = dedent(help)\n\n        serde = TimeInputSerde(parsed_time)\n        widget_state = register_widget(\n            \"time_input\",\n            time_input_proto,\n            user_key=key,\n            on_change_handler=on_change,\n            args=args,\n            kwargs=kwargs,\n            deserializer=serde.deserialize,\n            serializer=serde.serialize,\n            ctx=ctx,\n        )\n\n        if widget_state.value_changed:\n            if (serialized_value := serde.serialize(widget_state.value)) is not None:\n                time_input_proto.value = serialized_value\n            time_input_proto.set_value = True\n\n        self.dg._enqueue(\"time_input\", time_input_proto)\n        return widget_state.value\n\n    @gather_metrics(\"date_input\")\n    def date_input(\n        self,\n        label: str,\n        value: DateValue | Literal[\"today\"] = \"default_value_today\",  # type: ignore[assignment]\n        min_value: SingleDateValue = None,\n        max_value: SingleDateValue = None,\n        key: Key | None = None,\n        help: str | None = None,\n        on_change: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        *,  # keyword-only arguments:\n        format: str = \"YYYY/MM/DD\",\n        disabled: bool = False,\n        label_visibility: LabelVisibility = \"visible\",\n    ) -> DateWidgetReturn:\n        r\"\"\"Display a date input widget.\n\n        Parameters\n        ----------\n        label : str\n            A short label explaining to the user what this date input is for.\n            The label can optionally contain Markdown and supports the following\n            elements: Bold, Italics, Strikethroughs, Inline Code, Emojis, and Links.\n\n            This also supports:\n\n            * Emoji shortcodes, such as ``:+1:``  and ``:sunglasses:``.\n              For a list of all supported codes,\n              see https://share.streamlit.io/streamlit/emoji-shortcodes.\n\n            * LaTeX expressions, by wrapping them in \"$\" or \"$$\" (the \"$$\"\n              must be on their own lines). Supported LaTeX functions are listed\n              at https://katex.org/docs/supported.html.\n\n            * Colored text and background colors for text, using the syntax\n              ``:color[text to be colored]`` and ``:color-background[text to be colored]``,\n              respectively. ``color`` must be replaced with any of the following\n              supported colors: blue, green, orange, red, violet, gray/grey, rainbow.\n              For example, you can use ``:orange[your text here]`` or\n              ``:blue-background[your text here]``.\n\n            Unsupported elements are unwrapped so only their children (text contents) render.\n            Display unsupported elements as literal characters by\n            backslash-escaping them. E.g. ``1\\. Not an ordered list``.\n\n            For accessibility reasons, you should never set an empty label (label=\"\")\n            but hide it with label_visibility if needed. In the future, we may disallow\n            empty labels by raising an exception.\n        value : datetime.date or datetime.datetime or list/tuple of datetime.date or datetime.datetime, \"today\", or None\n            The value of this widget when it first renders. If a list/tuple with\n            0 to 2 date/datetime values is provided, the datepicker will allow\n            users to provide a range. If ``None``, will initialize empty and\n            return ``None`` until the user provides input. If \"today\" (default),\n            will initialize with today as a single-date picker.\n        min_value : datetime.date or datetime.datetime\n            The minimum selectable date. If value is a date, defaults to value - 10 years.\n            If value is the interval [start, end], defaults to start - 10 years.\n        max_value : datetime.date or datetime.datetime\n            The maximum selectable date. If value is a date, defaults to value + 10 years.\n            If value is the interval [start, end], defaults to end + 10 years.\n        key : str or int\n            An optional string or integer to use as the unique key for the widget.\n            If this is omitted, a key will be generated for the widget\n            based on its content. Multiple widgets of the same type may\n            not share the same key.\n        help : str\n            An optional tooltip that gets displayed next to the input.\n        on_change : callable\n            An optional callback invoked when this date_input's value changes.\n        args : tuple\n            An optional tuple of args to pass to the callback.\n        kwargs : dict\n            An optional dict of kwargs to pass to the callback.\n        format : str\n            A format string controlling how the interface should display dates.\n            Supports \"YYYY/MM/DD\" (default), \"DD/MM/YYYY\", or \"MM/DD/YYYY\".\n            You may also use a period (.) or hyphen (-) as separators.\n        disabled : bool\n            An optional boolean, which disables the date input if set to True.\n            The default is False.\n        label_visibility : \"visible\", \"hidden\", or \"collapsed\"\n            The visibility of the label. If \"hidden\", the label doesn't show but there\n            is still empty space for it above the widget (equivalent to label=\"\").\n            If \"collapsed\", both the label and the space are removed. Default is\n            \"visible\".\n\n\n        Returns\n        -------\n        datetime.date or a tuple with 0-2 dates or None\n            The current value of the date input widget or ``None`` if no date has been\n            selected.\n\n        Examples\n        --------\n        >>> import datetime\n        >>> import streamlit as st\n        >>>\n        >>> d = st.date_input(\"When's your birthday\", datetime.date(2019, 7, 6))\n        >>> st.write(\"Your birthday is:\", d)\n\n        .. output::\n           https://doc-date-input.streamlit.app/\n           height: 380px\n\n        >>> import datetime\n        >>> import streamlit as st\n        >>>\n        >>> today = datetime.datetime.now()\n        >>> next_year = today.year + 1\n        >>> jan_1 = datetime.date(next_year, 1, 1)\n        >>> dec_31 = datetime.date(next_year, 12, 31)\n        >>>\n        >>> d = st.date_input(\n        ...     \"Select your vacation for next year\",\n        ...     (jan_1, datetime.date(next_year, 1, 7)),\n        ...     jan_1,\n        ...     dec_31,\n        ...     format=\"MM.DD.YYYY\",\n        ... )\n        >>> d\n\n        .. output::\n           https://doc-date-input1.streamlit.app/\n           height: 380px\n\n        To initialize an empty date input, use ``None`` as the value:\n\n        >>> import datetime\n        >>> import streamlit as st\n        >>>\n        >>> d = st.date_input(\"When's your birthday\", value=None)\n        >>> st.write(\"Your birthday is:\", d)\n\n        .. output::\n           https://doc-date-input-empty.streamlit.app/\n           height: 380px\n\n        \"\"\"\n        ctx = get_script_run_ctx()\n        return self._date_input(\n            label=label,\n            value=value,\n            min_value=min_value,\n            max_value=max_value,\n            key=key,\n            help=help,\n            on_change=on_change,\n            args=args,\n            kwargs=kwargs,\n            disabled=disabled,\n            label_visibility=label_visibility,\n            format=format,\n            ctx=ctx,\n        )\n\n    def _date_input(\n        self,\n        label: str,\n        value: (\n            Literal[\"today\", \"default_value_today\"] | DateValue\n        ) = \"default_value_today\",\n        min_value: SingleDateValue = None,\n        max_value: SingleDateValue = None,\n        key: Key | None = None,\n        help: str | None = None,\n        on_change: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        *,  # keyword-only arguments:\n        format: str = \"YYYY/MM/DD\",\n        disabled: bool = False,\n        label_visibility: LabelVisibility = \"visible\",\n        ctx: ScriptRunContext | None = None,\n    ) -> DateWidgetReturn:\n        key = to_key(key)\n\n        check_fragment_path_policy(self.dg)\n        check_cache_replay_rules()\n        check_callback_rules(self.dg, on_change)\n        check_session_state_rules(\n            default_value=value if value != \"default_value_today\" else None, key=key\n        )\n        maybe_raise_label_warnings(label, label_visibility)\n\n        def parse_date_deterministic(\n            v: SingleDateValue | Literal[\"today\", \"default_value_today\"],\n        ) -> str | None:\n            if isinstance(v, datetime):\n                return date.strftime(v.date(), \"%Y/%m/%d\")\n            elif isinstance(v, date):\n                return date.strftime(v, \"%Y/%m/%d\")\n            return None\n\n        parsed_min_date = parse_date_deterministic(min_value)\n        parsed_max_date = parse_date_deterministic(max_value)\n\n        parsed: str | None | list[str | None]\n        if value == \"today\" or value == \"default_value_today\" or value is None:\n            parsed = None\n        elif isinstance(value, (datetime, date)):\n            parsed = parse_date_deterministic(value)\n        else:\n            parsed = [parse_date_deterministic(cast(SingleDateValue, v)) for v in value]\n\n        # TODO this is missing the error path, integrate with the dateinputvalues parsing\n\n        id = compute_widget_id(\n            \"date_input\",\n            user_key=key,\n            label=label,\n            value=parsed,\n            min_value=parsed_min_date,\n            max_value=parsed_max_date,\n            key=key,\n            help=help,\n            format=format,\n            form_id=current_form_id(self.dg),\n            page=ctx.active_script_hash if ctx else None,\n        )\n        if not bool(ALLOWED_DATE_FORMATS.match(format)):\n            raise StreamlitAPIException(\n                f\"The provided format (`{format}`) is not valid. DateInput format \"\n                \"should be one of `YYYY/MM/DD`, `DD/MM/YYYY`, or `MM/DD/YYYY` \"\n                \"and can also use a period (.) or hyphen (-) as separators.\"\n            )\n\n        parsed_values = _DateInputValues.from_raw_values(\n            value=value,\n            min_value=min_value,\n            max_value=max_value,\n        )\n\n        if value == \"default_value_today\":\n            # We need to know if this is a single or range date_input, but don't have\n            # a default value, so we check if session_state can tell us.\n            # We already calculated the id, so there is no risk of this causing\n            # the id to change.\n\n            session_state = get_session_state().filtered_state\n\n            if key is not None and key in session_state:\n                state_value = session_state[key]\n                parsed_values = _DateInputValues.from_raw_values(\n                    value=state_value,\n                    min_value=min_value,\n                    max_value=max_value,\n                )\n\n        del value, min_value, max_value\n\n        date_input_proto = DateInputProto()\n        date_input_proto.id = id\n        date_input_proto.is_range = parsed_values.is_range\n        date_input_proto.disabled = disabled\n        date_input_proto.label_visibility.value = get_label_visibility_proto_value(\n            label_visibility\n        )\n        date_input_proto.format = format\n        date_input_proto.label = label\n        if parsed_values.value is None:\n            # An empty array represents the empty state. The reason for using an empty\n            # array here is that we cannot optional keyword for repeated fields\n            # in protobuf.\n            date_input_proto.default[:] = []\n        else:\n            date_input_proto.default[:] = [\n                date.strftime(v, \"%Y/%m/%d\") for v in parsed_values.value\n            ]\n        date_input_proto.min = date.strftime(parsed_values.min, \"%Y/%m/%d\")\n        date_input_proto.max = date.strftime(parsed_values.max, \"%Y/%m/%d\")\n        date_input_proto.form_id = current_form_id(self.dg)\n\n        if help is not None:\n            date_input_proto.help = dedent(help)\n\n        serde = DateInputSerde(parsed_values)\n\n        widget_state = register_widget(\n            \"date_input\",\n            date_input_proto,\n            user_key=key,\n            on_change_handler=on_change,\n            args=args,\n            kwargs=kwargs,\n            deserializer=serde.deserialize,\n            serializer=serde.serialize,\n            ctx=ctx,\n        )\n\n        if widget_state.value_changed:\n            date_input_proto.value[:] = serde.serialize(widget_state.value)\n            date_input_proto.set_value = True\n\n        self.dg._enqueue(\"date_input\", date_input_proto)\n        return widget_state.value\n\n    @property\n    def dg(self) -> DeltaGenerator:\n        \"\"\"Get our DeltaGenerator.\"\"\"\n        return cast(\"DeltaGenerator\", self)\n", "lib/streamlit/elements/widgets/__init__.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n", "lib/streamlit/elements/widgets/selectbox.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nfrom __future__ import annotations\n\nfrom dataclasses import dataclass\nfrom textwrap import dedent\nfrom typing import TYPE_CHECKING, Any, Callable, Generic, Sequence, cast\n\nfrom streamlit.elements.form import current_form_id\nfrom streamlit.elements.lib.policies import (\n    check_cache_replay_rules,\n    check_callback_rules,\n    check_fragment_path_policy,\n    check_session_state_rules,\n)\nfrom streamlit.elements.lib.utils import (\n    get_label_visibility_proto_value,\n    maybe_coerce_enum,\n)\nfrom streamlit.errors import StreamlitAPIException\nfrom streamlit.proto.Selectbox_pb2 import Selectbox as SelectboxProto\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.runtime.scriptrunner import ScriptRunContext, get_script_run_ctx\nfrom streamlit.runtime.state import (\n    WidgetArgs,\n    WidgetCallback,\n    WidgetKwargs,\n    get_session_state,\n    register_widget,\n)\nfrom streamlit.runtime.state.common import compute_widget_id, save_for_app_testing\nfrom streamlit.type_util import (\n    Key,\n    LabelVisibility,\n    OptionSequence,\n    T,\n    check_python_comparable,\n    ensure_indexable,\n    maybe_raise_label_warnings,\n    to_key,\n)\nfrom streamlit.util import index_\n\nif TYPE_CHECKING:\n    from streamlit.delta_generator import DeltaGenerator\n\n\n@dataclass\nclass SelectboxSerde(Generic[T]):\n    options: Sequence[T]\n    index: int | None\n\n    def serialize(self, v: object) -> int | None:\n        if v is None:\n            return None\n        if len(self.options) == 0:\n            return 0\n        return index_(self.options, v)\n\n    def deserialize(\n        self,\n        ui_value: int | None,\n        widget_id: str = \"\",\n    ) -> T | None:\n        idx = ui_value if ui_value is not None else self.index\n        return self.options[idx] if idx is not None and len(self.options) > 0 else None\n\n\nclass SelectboxMixin:\n    @gather_metrics(\"selectbox\")\n    def selectbox(\n        self,\n        label: str,\n        options: OptionSequence[T],\n        index: int | None = 0,\n        format_func: Callable[[Any], Any] = str,\n        key: Key | None = None,\n        help: str | None = None,\n        on_change: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        *,  # keyword-only arguments:\n        placeholder: str = \"Choose an option\",\n        disabled: bool = False,\n        label_visibility: LabelVisibility = \"visible\",\n    ) -> T | None:\n        r\"\"\"Display a select widget.\n\n        Parameters\n        ----------\n        label : str\n            A short label explaining to the user what this select widget is for.\n            The label can optionally contain Markdown and supports the following\n            elements: Bold, Italics, Strikethroughs, Inline Code, Emojis, and Links.\n\n            This also supports:\n\n            * Emoji shortcodes, such as ``:+1:``  and ``:sunglasses:``.\n              For a list of all supported codes,\n              see https://share.streamlit.io/streamlit/emoji-shortcodes.\n\n            * LaTeX expressions, by wrapping them in \"$\" or \"$$\" (the \"$$\"\n              must be on their own lines). Supported LaTeX functions are listed\n              at https://katex.org/docs/supported.html.\n\n            * Colored text and background colors for text, using the syntax\n              ``:color[text to be colored]`` and ``:color-background[text to be colored]``,\n              respectively. ``color`` must be replaced with any of the following\n              supported colors: blue, green, orange, red, violet, gray/grey, rainbow.\n              For example, you can use ``:orange[your text here]`` or\n              ``:blue-background[your text here]``.\n\n            Unsupported elements are unwrapped so only their children (text contents) render.\n            Display unsupported elements as literal characters by\n            backslash-escaping them. E.g. ``1\\. Not an ordered list``.\n\n            For accessibility reasons, you should never set an empty label (label=\"\")\n            but hide it with label_visibility if needed. In the future, we may disallow\n            empty labels by raising an exception.\n        options : Iterable\n            Labels for the select options in an Iterable. For example, this can\n            be a list, numpy.ndarray, pandas.Series, pandas.DataFrame, or\n            pandas.Index. For pandas.DataFrame, the first column is used.\n            Each label will be cast to str internally by default.\n        index : int\n            The index of the preselected option on first render. If ``None``,\n            will initialize empty and return ``None`` until the user selects an option.\n            Defaults to 0 (the first option).\n        format_func : function\n            Function to modify the display of the labels. It receives the option\n            as an argument and its output will be cast to str.\n        key : str or int\n            An optional string or integer to use as the unique key for the widget.\n            If this is omitted, a key will be generated for the widget\n            based on its content. Multiple widgets of the same type may\n            not share the same key.\n        help : str\n            An optional tooltip that gets displayed next to the selectbox.\n        on_change : callable\n            An optional callback invoked when this selectbox's value changes.\n        args : tuple\n            An optional tuple of args to pass to the callback.\n        kwargs : dict\n            An optional dict of kwargs to pass to the callback.\n        placeholder : str\n            A string to display when no options are selected.\n            Defaults to \"Choose an option\".\n        disabled : bool\n            An optional boolean, which disables the selectbox if set to True.\n            The default is False.\n        label_visibility : \"visible\", \"hidden\", or \"collapsed\"\n            The visibility of the label. If \"hidden\", the label doesn't show but there\n            is still empty space for it above the widget (equivalent to label=\"\").\n            If \"collapsed\", both the label and the space are removed. Default is\n            \"visible\".\n\n        Returns\n        -------\n        any\n            The selected option or ``None`` if no option is selected.\n\n        Example\n        -------\n        >>> import streamlit as st\n        >>>\n        >>> option = st.selectbox(\n        ...     \"How would you like to be contacted?\",\n        ...     (\"Email\", \"Home phone\", \"Mobile phone\"))\n        >>>\n        >>> st.write(\"You selected:\", option)\n\n        .. output::\n           https://doc-selectbox.streamlit.app/\n           height: 320px\n\n        To initialize an empty selectbox, use ``None`` as the index value:\n\n        >>> import streamlit as st\n        >>>\n        >>> option = st.selectbox(\n        ...    \"How would you like to be contacted?\",\n        ...    (\"Email\", \"Home phone\", \"Mobile phone\"),\n        ...    index=None,\n        ...    placeholder=\"Select contact method...\",\n        ... )\n        >>>\n        >>> st.write(\"You selected:\", option)\n\n        .. output::\n           https://doc-selectbox-empty.streamlit.app/\n           height: 320px\n\n        \"\"\"\n        ctx = get_script_run_ctx()\n        return self._selectbox(\n            label=label,\n            options=options,\n            index=index,\n            format_func=format_func,\n            key=key,\n            help=help,\n            on_change=on_change,\n            args=args,\n            kwargs=kwargs,\n            placeholder=placeholder,\n            disabled=disabled,\n            label_visibility=label_visibility,\n            ctx=ctx,\n        )\n\n    def _selectbox(\n        self,\n        label: str,\n        options: OptionSequence[T],\n        index: int | None = 0,\n        format_func: Callable[[Any], Any] = str,\n        key: Key | None = None,\n        help: str | None = None,\n        on_change: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        *,  # keyword-only arguments:\n        placeholder: str = \"Choose an option\",\n        disabled: bool = False,\n        label_visibility: LabelVisibility = \"visible\",\n        ctx: ScriptRunContext | None = None,\n    ) -> T | None:\n        key = to_key(key)\n\n        check_fragment_path_policy(self.dg)\n        check_cache_replay_rules()\n        check_callback_rules(self.dg, on_change)\n        check_session_state_rules(default_value=None if index == 0 else index, key=key)\n        maybe_raise_label_warnings(label, label_visibility)\n\n        opt = ensure_indexable(options)\n        check_python_comparable(opt)\n\n        id = compute_widget_id(\n            \"selectbox\",\n            user_key=key,\n            label=label,\n            options=[str(format_func(option)) for option in opt],\n            index=index,\n            key=key,\n            help=help,\n            placeholder=placeholder,\n            form_id=current_form_id(self.dg),\n            page=ctx.active_script_hash if ctx else None,\n        )\n\n        if not isinstance(index, int) and index is not None:\n            raise StreamlitAPIException(\n                \"Selectbox Value has invalid type: %s\" % type(index).__name__\n            )\n\n        if index is not None and len(opt) > 0 and not 0 <= index < len(opt):\n            raise StreamlitAPIException(\n                \"Selectbox index must be greater than or equal to 0 and less than the length of options.\"\n            )\n\n        session_state = get_session_state().filtered_state\n        if key is not None and key in session_state and session_state[key] is None:\n            index = None\n\n        selectbox_proto = SelectboxProto()\n        selectbox_proto.id = id\n        selectbox_proto.label = label\n        if index is not None:\n            selectbox_proto.default = index\n        selectbox_proto.options[:] = [str(format_func(option)) for option in opt]\n        selectbox_proto.form_id = current_form_id(self.dg)\n        selectbox_proto.placeholder = placeholder\n        selectbox_proto.disabled = disabled\n        selectbox_proto.label_visibility.value = get_label_visibility_proto_value(\n            label_visibility\n        )\n\n        if help is not None:\n            selectbox_proto.help = dedent(help)\n\n        serde = SelectboxSerde(opt, index)\n\n        widget_state = register_widget(\n            \"selectbox\",\n            selectbox_proto,\n            user_key=key,\n            on_change_handler=on_change,\n            args=args,\n            kwargs=kwargs,\n            deserializer=serde.deserialize,\n            serializer=serde.serialize,\n            ctx=ctx,\n        )\n        widget_state = maybe_coerce_enum(widget_state, options, opt)\n\n        if widget_state.value_changed:\n            serialized_value = serde.serialize(widget_state.value)\n            if serialized_value is not None:\n                selectbox_proto.value = serialized_value\n            selectbox_proto.set_value = True\n\n        if ctx:\n            save_for_app_testing(ctx, id, format_func)\n        self.dg._enqueue(\"selectbox\", selectbox_proto)\n        return widget_state.value\n\n    @property\n    def dg(self) -> DeltaGenerator:\n        \"\"\"Get our DeltaGenerator.\"\"\"\n        return cast(\"DeltaGenerator\", self)\n", "lib/streamlit/elements/widgets/color_picker.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport re\nfrom dataclasses import dataclass\nfrom textwrap import dedent\nfrom typing import TYPE_CHECKING, cast\n\nfrom streamlit.elements.form import current_form_id\nfrom streamlit.elements.lib.policies import (\n    check_cache_replay_rules,\n    check_callback_rules,\n    check_fragment_path_policy,\n    check_session_state_rules,\n)\nfrom streamlit.elements.lib.utils import get_label_visibility_proto_value\nfrom streamlit.errors import StreamlitAPIException\nfrom streamlit.proto.ColorPicker_pb2 import ColorPicker as ColorPickerProto\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.runtime.scriptrunner import ScriptRunContext, get_script_run_ctx\nfrom streamlit.runtime.state import (\n    WidgetArgs,\n    WidgetCallback,\n    WidgetKwargs,\n    register_widget,\n)\nfrom streamlit.runtime.state.common import compute_widget_id\nfrom streamlit.type_util import Key, LabelVisibility, maybe_raise_label_warnings, to_key\n\nif TYPE_CHECKING:\n    from streamlit.delta_generator import DeltaGenerator\n\n\n@dataclass\nclass ColorPickerSerde:\n    value: str\n\n    def serialize(self, v: str) -> str:\n        return str(v)\n\n    def deserialize(self, ui_value: str | None, widget_id: str = \"\") -> str:\n        return str(ui_value if ui_value is not None else self.value)\n\n\nclass ColorPickerMixin:\n    @gather_metrics(\"color_picker\")\n    def color_picker(\n        self,\n        label: str,\n        value: str | None = None,\n        key: Key | None = None,\n        help: str | None = None,\n        on_change: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        *,  # keyword-only arguments:\n        disabled: bool = False,\n        label_visibility: LabelVisibility = \"visible\",\n    ) -> str:\n        r\"\"\"Display a color picker widget.\n\n        Parameters\n        ----------\n        label : str\n            A short label explaining to the user what this input is for.\n            The label can optionally contain Markdown and supports the following\n            elements: Bold, Italics, Strikethroughs, Inline Code, Emojis, and Links.\n\n            This also supports:\n\n            * Emoji shortcodes, such as ``:+1:``  and ``:sunglasses:``.\n              For a list of all supported codes,\n              see https://share.streamlit.io/streamlit/emoji-shortcodes.\n\n            * LaTeX expressions, by wrapping them in \"$\" or \"$$\" (the \"$$\"\n              must be on their own lines). Supported LaTeX functions are listed\n              at https://katex.org/docs/supported.html.\n\n            * Colored text and background colors for text, using the syntax\n              ``:color[text to be colored]`` and ``:color-background[text to be colored]``,\n              respectively. ``color`` must be replaced with any of the following\n              supported colors: blue, green, orange, red, violet, gray/grey, rainbow.\n              For example, you can use ``:orange[your text here]`` or\n              ``:blue-background[your text here]``.\n\n            Unsupported elements are unwrapped so only their children (text contents) render.\n            Display unsupported elements as literal characters by\n            backslash-escaping them. E.g. ``1\\. Not an ordered list``.\n\n            For accessibility reasons, you should never set an empty label (label=\"\")\n            but hide it with label_visibility if needed. In the future, we may disallow\n            empty labels by raising an exception.\n        value : str\n            The hex value of this widget when it first renders. If None,\n            defaults to black.\n        key : str or int\n            An optional string or integer to use as the unique key for the widget.\n            If this is omitted, a key will be generated for the widget\n            based on its content. Multiple widgets of the same type may\n            not share the same key.\n        help : str\n            An optional tooltip that gets displayed next to the color picker.\n        on_change : callable\n            An optional callback invoked when this color_picker's value\n            changes.\n        args : tuple\n            An optional tuple of args to pass to the callback.\n        kwargs : dict\n            An optional dict of kwargs to pass to the callback.\n        disabled : bool\n            An optional boolean, which disables the color picker if set to\n            True. The default is False. This argument can only be supplied by\n            keyword.\n        label_visibility : \"visible\", \"hidden\", or \"collapsed\"\n            The visibility of the label. If \"hidden\", the label doesn't show but there\n            is still empty space for it above the widget (equivalent to label=\"\").\n            If \"collapsed\", both the label and the space are removed. Default is\n            \"visible\".\n\n        Returns\n        -------\n        str\n            The selected color as a hex string.\n\n        Example\n        -------\n        >>> import streamlit as st\n        >>>\n        >>> color = st.color_picker(\"Pick A Color\", \"#00f900\")\n        >>> st.write(\"The current color is\", color)\n\n        .. output::\n           https://doc-color-picker.streamlit.app/\n           height: 335px\n\n        \"\"\"\n        ctx = get_script_run_ctx()\n        return self._color_picker(\n            label=label,\n            value=value,\n            key=key,\n            help=help,\n            on_change=on_change,\n            args=args,\n            kwargs=kwargs,\n            disabled=disabled,\n            label_visibility=label_visibility,\n            ctx=ctx,\n        )\n\n    def _color_picker(\n        self,\n        label: str,\n        value: str | None = None,\n        key: Key | None = None,\n        help: str | None = None,\n        on_change: WidgetCallback | None = None,\n        args: WidgetArgs | None = None,\n        kwargs: WidgetKwargs | None = None,\n        *,  # keyword-only arguments:\n        disabled: bool = False,\n        label_visibility: LabelVisibility = \"visible\",\n        ctx: ScriptRunContext | None = None,\n    ) -> str:\n        key = to_key(key)\n\n        check_fragment_path_policy(self.dg)\n        check_cache_replay_rules()\n        check_callback_rules(self.dg, on_change)\n        check_session_state_rules(default_value=value, key=key)\n        maybe_raise_label_warnings(label, label_visibility)\n\n        id = compute_widget_id(\n            \"color_picker\",\n            user_key=key,\n            label=label,\n            value=str(value),\n            key=key,\n            help=help,\n            form_id=current_form_id(self.dg),\n            page=ctx.active_script_hash if ctx else None,\n        )\n\n        # set value default\n        if value is None:\n            value = \"#000000\"\n\n        # make sure the value is a string\n        if not isinstance(value, str):\n            raise StreamlitAPIException(\n                \"\"\"\n                Color Picker Value has invalid type: %s. Expects a hex string\n                like '#00FFAA' or '#000'.\n                \"\"\"\n                % type(value).__name__\n            )\n\n        # validate the value and expects a hex string\n        match = re.match(r\"^#(?:[0-9a-fA-F]{3}){1,2}$\", value)\n\n        if not match:\n            raise StreamlitAPIException(\n                \"\"\"\n                '%s' is not a valid hex code for colors. Valid ones are like\n                '#00FFAA' or '#000'.\n                \"\"\"\n                % value\n            )\n\n        color_picker_proto = ColorPickerProto()\n        color_picker_proto.id = id\n        color_picker_proto.label = label\n        color_picker_proto.default = str(value)\n        color_picker_proto.form_id = current_form_id(self.dg)\n        color_picker_proto.disabled = disabled\n        color_picker_proto.label_visibility.value = get_label_visibility_proto_value(\n            label_visibility\n        )\n\n        if help is not None:\n            color_picker_proto.help = dedent(help)\n\n        serde = ColorPickerSerde(value)\n\n        widget_state = register_widget(\n            \"color_picker\",\n            color_picker_proto,\n            user_key=key,\n            on_change_handler=on_change,\n            args=args,\n            kwargs=kwargs,\n            deserializer=serde.deserialize,\n            serializer=serde.serialize,\n            ctx=ctx,\n        )\n\n        if widget_state.value_changed:\n            color_picker_proto.value = widget_state.value\n            color_picker_proto.set_value = True\n\n        self.dg._enqueue(\"color_picker\", color_picker_proto)\n        return widget_state.value\n\n    @property\n    def dg(self) -> DeltaGenerator:\n        \"\"\"Get our DeltaGenerator.\"\"\"\n        return cast(\"DeltaGenerator\", self)\n", "lib/streamlit/web/cli.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"A script which is run when the Streamlit package is executed.\"\"\"\n\nfrom __future__ import annotations\n\nimport os\nimport sys\nfrom typing import TYPE_CHECKING, Any, Callable, TypeVar\n\n# We cannot lazy-load click here because its used via decorators.\nimport click\n\nimport streamlit.runtime.caching as caching\nimport streamlit.web.bootstrap as bootstrap\nfrom streamlit import config as _config\nfrom streamlit.runtime.credentials import Credentials, check_credentials\nfrom streamlit.web.cache_storage_manager_config import (\n    create_default_cache_storage_manager,\n)\n\nif TYPE_CHECKING:\n    from streamlit.config_option import ConfigOption\n\nACCEPTED_FILE_EXTENSIONS = (\"py\", \"py3\")\n\nLOG_LEVELS = (\"error\", \"warning\", \"info\", \"debug\")\n\n\ndef _convert_config_option_to_click_option(\n    config_option: ConfigOption,\n) -> dict[str, Any]:\n    \"\"\"Composes given config option options as options for click lib.\"\"\"\n    option = f\"--{config_option.key}\"\n    param = config_option.key.replace(\".\", \"_\")\n    description = config_option.description\n    if config_option.deprecated:\n        if description is None:\n            description = \"\"\n        description += (\n            f\"\\n {config_option.deprecation_text} - {config_option.expiration_date}\"\n        )\n\n    return {\n        \"param\": param,\n        \"description\": description,\n        \"type\": config_option.type,\n        \"option\": option,\n        \"envvar\": config_option.env_var,\n    }\n\n\ndef _make_sensitive_option_callback(config_option: ConfigOption):\n    def callback(_ctx: click.Context, _param: click.Parameter, cli_value) -> None:\n        if cli_value is None:\n            return None\n        raise SystemExit(\n            f\"Setting {config_option.key!r} option using the CLI flag is not allowed. \"\n            f\"Set this option in the configuration file or environment \"\n            f\"variable: {config_option.env_var!r}\"\n        )\n\n    return callback\n\n\nF = TypeVar(\"F\", bound=Callable[..., Any])\n\n\ndef configurator_options(func: F) -> F:\n    \"\"\"Decorator that adds config param keys to click dynamically.\"\"\"\n    for _, value in reversed(_config._config_options_template.items()):\n        parsed_parameter = _convert_config_option_to_click_option(value)\n        if value.sensitive:\n            # Display a warning if the user tries to set sensitive\n            # options using the CLI and exit with non-zero code.\n            click_option_kwargs = {\n                \"expose_value\": False,\n                \"hidden\": True,\n                \"is_eager\": True,\n                \"callback\": _make_sensitive_option_callback(value),\n            }\n        else:\n            click_option_kwargs = {\n                \"show_envvar\": True,\n                \"envvar\": parsed_parameter[\"envvar\"],\n            }\n        config_option = click.option(\n            parsed_parameter[\"option\"],\n            parsed_parameter[\"param\"],\n            help=parsed_parameter[\"description\"],\n            type=parsed_parameter[\"type\"],\n            **click_option_kwargs,\n        )\n        func = config_option(func)\n    return func\n\n\ndef _download_remote(main_script_path: str, url_path: str) -> None:\n    \"\"\"Fetch remote file at url_path to main_script_path\"\"\"\n    import requests\n\n    with open(main_script_path, \"wb\") as fp:\n        try:\n            resp = requests.get(url_path)\n            resp.raise_for_status()\n            fp.write(resp.content)\n        except requests.exceptions.RequestException as e:\n            raise click.BadParameter(f\"Unable to fetch {url_path}.\\n{e}\")\n\n\n@click.group(context_settings={\"auto_envvar_prefix\": \"STREAMLIT\"})\n@click.option(\"--log_level\", show_default=True, type=click.Choice(LOG_LEVELS))\n@click.version_option(prog_name=\"Streamlit\")\ndef main(log_level=\"info\"):\n    \"\"\"Try out a demo with:\n\n        $ streamlit hello\n\n    Or use the line below to run your own script:\n\n        $ streamlit run your_script.py\n    \"\"\"\n\n    if log_level:\n        from streamlit.logger import get_logger\n\n        LOGGER = get_logger(__name__)\n        LOGGER.warning(\n            \"Setting the log level using the --log_level flag is unsupported.\"\n            \"\\nUse the --logger.level flag (after your streamlit command) instead.\"\n        )\n\n\n@main.command(\"help\")\ndef help():\n    \"\"\"Print this help message.\"\"\"\n    # We use _get_command_line_as_string to run some error checks but don't do\n    # anything with its return value.\n    _get_command_line_as_string()\n\n    assert len(sys.argv) == 2  # This is always true, but let's assert anyway.\n\n    # Pretend user typed 'streamlit --help' instead of 'streamlit help'.\n    sys.argv[1] = \"--help\"\n    main(prog_name=\"streamlit\")\n\n\n@main.command(\"version\")\ndef main_version():\n    \"\"\"Print Streamlit's version number.\"\"\"\n    # Pretend user typed 'streamlit --version' instead of 'streamlit version'\n    import sys\n\n    # We use _get_command_line_as_string to run some error checks but don't do\n    # anything with its return value.\n    _get_command_line_as_string()\n\n    assert len(sys.argv) == 2  # This is always true, but let's assert anyway.\n    sys.argv[1] = \"--version\"\n    main()\n\n\n@main.command(\"docs\")\ndef main_docs():\n    \"\"\"Show help in browser.\"\"\"\n    click.echo(\"Showing help page in browser...\")\n    from streamlit import util\n\n    util.open_browser(\"https://docs.streamlit.io\")\n\n\n@main.command(\"hello\")\n@configurator_options\ndef main_hello(**kwargs):\n    \"\"\"Runs the Hello World script.\"\"\"\n    from streamlit.hello import streamlit_app\n\n    bootstrap.load_config_options(flag_options=kwargs)\n    filename = streamlit_app.__file__\n    _main_run(filename, flag_options=kwargs)\n\n\n@main.command(\"run\")\n@configurator_options\n@click.argument(\"target\", required=True, envvar=\"STREAMLIT_RUN_TARGET\")\n@click.argument(\"args\", nargs=-1)\ndef main_run(target: str, args=None, **kwargs):\n    \"\"\"Run a Python script, piping stderr to Streamlit.\n\n    The script can be local or it can be an url. In the latter case, Streamlit\n    will download the script to a temporary file and runs this file.\n\n    \"\"\"\n    from streamlit import url_util\n\n    bootstrap.load_config_options(flag_options=kwargs)\n\n    _, extension = os.path.splitext(target)\n    if extension[1:] not in ACCEPTED_FILE_EXTENSIONS:\n        if extension[1:] == \"\":\n            raise click.BadArgumentUsage(\n                \"Streamlit requires raw Python (.py) files, but the provided file has no extension.\\nFor more information, please see https://docs.streamlit.io\"\n            )\n        else:\n            raise click.BadArgumentUsage(\n                f\"Streamlit requires raw Python (.py) files, not {extension}.\\nFor more information, please see https://docs.streamlit.io\"\n            )\n\n    if url_util.is_url(target):\n        from streamlit.temporary_directory import TemporaryDirectory\n\n        with TemporaryDirectory() as temp_dir:\n            from urllib.parse import urlparse\n\n            path = urlparse(target).path\n            main_script_path = os.path.join(\n                temp_dir, path.strip(\"/\").rsplit(\"/\", 1)[-1]\n            )\n            # if this is a GitHub/Gist blob url, convert to a raw URL first.\n            target = url_util.process_gitblob_url(target)\n            _download_remote(main_script_path, target)\n            _main_run(main_script_path, args, flag_options=kwargs)\n    else:\n        if not os.path.exists(target):\n            raise click.BadParameter(f\"File does not exist: {target}\")\n        _main_run(target, args, flag_options=kwargs)\n\n\ndef _get_command_line_as_string() -> str | None:\n    import subprocess\n\n    parent = click.get_current_context().parent\n    if parent is None:\n        return None\n\n    if \"streamlit.cli\" in parent.command_path:\n        raise RuntimeError(\n            \"Running streamlit via `python -m streamlit.cli <command>` is\"\n            \" unsupported. Please use `python -m streamlit <command>` instead.\"\n        )\n\n    cmd_line_as_list = [parent.command_path]\n    cmd_line_as_list.extend(sys.argv[1:])\n    return subprocess.list2cmdline(cmd_line_as_list)\n\n\ndef _main_run(\n    file,\n    args: list[str] | None = None,\n    flag_options: dict[str, Any] | None = None,\n) -> None:\n    if args is None:\n        args = []\n\n    if flag_options is None:\n        flag_options = {}\n\n    is_hello = _get_command_line_as_string() == \"streamlit hello\"\n\n    check_credentials()\n\n    bootstrap.run(file, is_hello, args, flag_options)\n\n\n# SUBCOMMAND: cache\n\n\n@main.group(\"cache\")\ndef cache():\n    \"\"\"Manage the Streamlit cache.\"\"\"\n    pass\n\n\n@cache.command(\"clear\")\ndef cache_clear():\n    \"\"\"Clear st.cache_data and st.cache_resource caches.\"\"\"\n\n    # in this `streamlit cache clear` cli command we cannot use the\n    # `cache_storage_manager from runtime (since runtime is not initialized)\n    # so we create a new cache_storage_manager instance that used in runtime,\n    # and call clear_all() method for it.\n    # This will not remove the in-memory cache.\n    cache_storage_manager = create_default_cache_storage_manager()\n    cache_storage_manager.clear_all()\n    caching.cache_resource.clear()\n\n\n# SUBCOMMAND: config\n\n\n@main.group(\"config\")\ndef config():\n    \"\"\"Manage Streamlit's config settings.\"\"\"\n    pass\n\n\n@config.command(\"show\")\n@configurator_options\ndef config_show(**kwargs):\n    \"\"\"Show all of Streamlit's config settings.\"\"\"\n\n    bootstrap.load_config_options(flag_options=kwargs)\n\n    _config.show_config()\n\n\n# SUBCOMMAND: activate\n\n\n@main.group(\"activate\", invoke_without_command=True)\n@click.pass_context\ndef activate(ctx):\n    \"\"\"Activate Streamlit by entering your email.\"\"\"\n    if not ctx.invoked_subcommand:\n        Credentials.get_current().activate()\n\n\n@activate.command(\"reset\")\ndef activate_reset():\n    \"\"\"Reset Activation Credentials.\"\"\"\n    Credentials.get_current().reset()\n\n\n# SUBCOMMAND: test\n\n\n@main.group(\"test\", hidden=True)\ndef test():\n    \"\"\"Internal-only commands used for testing.\n\n    These commands are not included in the output of `streamlit help`.\n    \"\"\"\n    pass\n\n\n@test.command(\"prog_name\")\ndef test_prog_name():\n    \"\"\"Assert that the program name is set to `streamlit test`.\n\n    This is used by our cli-smoke-tests to verify that the program name is set\n    to `streamlit ...` whether the streamlit binary is invoked directly or via\n    `python -m streamlit ...`.\n    \"\"\"\n    # We use _get_command_line_as_string to run some error checks but don't do\n    # anything with its return value.\n    _get_command_line_as_string()\n\n    parent = click.get_current_context().parent\n\n    assert parent is not None\n    assert parent.command_path == \"streamlit test\"\n\n\nif __name__ == \"__main__\":\n    main()\n", "lib/streamlit/web/cache_storage_manager_config.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom typing import TYPE_CHECKING\n\nfrom streamlit.runtime.caching.storage.local_disk_cache_storage import (\n    LocalDiskCacheStorageManager,\n)\n\nif TYPE_CHECKING:\n    from streamlit.runtime.caching.storage import CacheStorageManager\n\n\ndef create_default_cache_storage_manager() -> CacheStorageManager:\n    \"\"\"\n    Get the cache storage manager.\n    It would be used both in server.py and in cli.py to have unified cache storage\n\n    Returns\n    -------\n    CacheStorageManager\n        The cache storage manager.\n\n    \"\"\"\n    return LocalDiskCacheStorageManager()\n", "lib/streamlit/web/bootstrap.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport asyncio\nimport os\nimport signal\nimport sys\nfrom typing import Any, Final\n\nfrom streamlit import cli_util, config, env_util, file_util, net_util, secrets, util\nfrom streamlit.config import CONFIG_FILENAMES\nfrom streamlit.git_util import MIN_GIT_VERSION, GitRepo\nfrom streamlit.logger import get_logger\nfrom streamlit.watcher import report_watchdog_availability, watch_file\nfrom streamlit.web.server import Server, server_address_is_unix_socket, server_util\n\n_LOGGER: Final = get_logger(__name__)\n\n\n# The maximum possible total size of a static directory.\n# We agreed on these limitations for the initial release of static file sharing,\n# based on security concerns from the SiS and Community Cloud teams\nMAX_APP_STATIC_FOLDER_SIZE = 1 * 1024 * 1024 * 1024  # 1 GB\n\n\ndef _set_up_signal_handler(server: Server) -> None:\n    _LOGGER.debug(\"Setting up signal handler\")\n\n    def signal_handler(signal_number, stack_frame):\n        # The server will shut down its threads and exit its loop.\n        server.stop()\n\n    signal.signal(signal.SIGTERM, signal_handler)\n    signal.signal(signal.SIGINT, signal_handler)\n    if sys.platform == \"win32\":\n        signal.signal(signal.SIGBREAK, signal_handler)\n    else:\n        signal.signal(signal.SIGQUIT, signal_handler)\n\n\ndef _fix_sys_path(main_script_path: str) -> None:\n    \"\"\"Add the script's folder to the sys path.\n\n    Python normally does this automatically, but since we exec the script\n    ourselves we need to do it instead.\n    \"\"\"\n    sys.path.insert(0, os.path.dirname(main_script_path))\n\n\ndef _fix_tornado_crash() -> None:\n    \"\"\"Set default asyncio policy to be compatible with Tornado 6.\n\n    Tornado 6 (at least) is not compatible with the default\n    asyncio implementation on Windows. So here we\n    pick the older SelectorEventLoopPolicy when the OS is Windows\n    if the known-incompatible default policy is in use.\n\n    This has to happen as early as possible to make it a low priority and\n    overridable\n\n    See: https://github.com/tornadoweb/tornado/issues/2608\n\n    FIXME: if/when tornado supports the defaults in asyncio,\n    remove and bump tornado requirement for py38\n    \"\"\"\n    if env_util.IS_WINDOWS:\n        try:\n            from asyncio import (  # type: ignore[attr-defined]\n                WindowsProactorEventLoopPolicy,\n                WindowsSelectorEventLoopPolicy,\n            )\n        except ImportError:\n            pass\n            # Not affected\n        else:\n            if type(asyncio.get_event_loop_policy()) is WindowsProactorEventLoopPolicy:\n                # WindowsProactorEventLoopPolicy is not compatible with\n                # Tornado 6 fallback to the pre-3.8 default of Selector\n                asyncio.set_event_loop_policy(WindowsSelectorEventLoopPolicy())\n\n\ndef _fix_sys_argv(main_script_path: str, args: list[str]) -> None:\n    \"\"\"sys.argv needs to exclude streamlit arguments and parameters\n    and be set to what a user's script may expect.\n    \"\"\"\n    import sys\n\n    sys.argv = [main_script_path] + list(args)\n\n\ndef _on_server_start(server: Server) -> None:\n    _maybe_print_old_git_warning(server.main_script_path)\n    _maybe_print_static_folder_warning(server.main_script_path)\n    _print_url(server.is_running_hello)\n    report_watchdog_availability()\n\n    # Load secrets.toml if it exists. If the file doesn't exist, this\n    # function will return without raising an exception. We catch any parse\n    # errors and display them here.\n    try:\n        secrets.load_if_toml_exists()\n    except Exception as ex:\n        _LOGGER.error(\"Failed to load secrets.toml file\", exc_info=ex)\n\n    def maybe_open_browser():\n        if config.get_option(\"server.headless\"):\n            # Don't open browser when in headless mode.\n            return\n\n        if config.is_manually_set(\"browser.serverAddress\"):\n            addr = config.get_option(\"browser.serverAddress\")\n        elif config.is_manually_set(\"server.address\"):\n            if server_address_is_unix_socket():\n                # Don't open browser when server address is an unix socket\n                return\n            addr = config.get_option(\"server.address\")\n        else:\n            addr = \"localhost\"\n\n        util.open_browser(server_util.get_url(addr))\n\n    # Schedule the browser to open on the main thread.\n    asyncio.get_running_loop().call_soon(maybe_open_browser)\n\n\ndef _fix_pydeck_mapbox_api_warning() -> None:\n    \"\"\"Sets MAPBOX_API_KEY environment variable needed for PyDeck otherwise it will throw an exception\"\"\"\n\n    os.environ[\"MAPBOX_API_KEY\"] = config.get_option(\"mapbox.token\")\n\n\ndef _fix_pydantic_duplicate_validators_error():\n    \"\"\"Pydantic by default disallows to reuse of validators with the same name,\n    this combined with the Streamlit execution model leads to an error on the second\n    Streamlit script rerun if the Pydantic validator is registered\n    in the streamlit script.\n\n    It is important to note that the same issue exists for Pydantic validators inside\n    Jupyter notebooks, https://github.com/pydantic/pydantic/issues/312 and in order\n    to fix that in Pydantic they use the `in_ipython` function that checks that\n    Pydantic runs not in `ipython` environment.\n\n    Inside this function we patch `in_ipython` function to always return `True`.\n\n    This change will relax rules for writing Pydantic validators inside\n    Streamlit script a little bit, similar to how it works in jupyter,\n    which should not be critical.\n    \"\"\"\n    try:\n        from pydantic import class_validators\n\n        class_validators.in_ipython = lambda: True  # type: ignore[attr-defined]\n    except ImportError:\n        pass\n\n\ndef _maybe_print_static_folder_warning(main_script_path: str) -> None:\n    \"\"\"Prints a warning if the static folder is misconfigured.\"\"\"\n\n    if config.get_option(\"server.enableStaticServing\"):\n        static_folder_path = file_util.get_app_static_dir(main_script_path)\n        if not os.path.isdir(static_folder_path):\n            cli_util.print_to_cli(\n                f\"WARNING: Static file serving is enabled, but no static folder found \"\n                f\"at {static_folder_path}. To disable static file serving, \"\n                f\"set server.enableStaticServing to false.\",\n                fg=\"yellow\",\n            )\n        else:\n            # Raise warning when static folder size is larger than 1 GB\n            static_folder_size = file_util.get_directory_size(static_folder_path)\n\n            if static_folder_size > MAX_APP_STATIC_FOLDER_SIZE:\n                config.set_option(\"server.enableStaticServing\", False)\n                cli_util.print_to_cli(\n                    \"WARNING: Static folder size is larger than 1GB. \"\n                    \"Static file serving has been disabled.\",\n                    fg=\"yellow\",\n                )\n\n\ndef _print_url(is_running_hello: bool) -> None:\n    if is_running_hello:\n        title_message = \"Welcome to Streamlit. Check out our demo in your browser.\"\n    else:\n        title_message = \"You can now view your Streamlit app in your browser.\"\n\n    named_urls = []\n\n    if config.is_manually_set(\"browser.serverAddress\"):\n        named_urls = [\n            (\"URL\", server_util.get_url(config.get_option(\"browser.serverAddress\")))\n        ]\n\n    elif (\n        config.is_manually_set(\"server.address\") and not server_address_is_unix_socket()\n    ):\n        named_urls = [\n            (\"URL\", server_util.get_url(config.get_option(\"server.address\"))),\n        ]\n\n    elif server_address_is_unix_socket():\n        named_urls = [\n            (\"Unix Socket\", config.get_option(\"server.address\")),\n        ]\n\n    else:\n        named_urls = [\n            (\"Local URL\", server_util.get_url(\"localhost\")),\n        ]\n\n        internal_ip = net_util.get_internal_ip()\n        if internal_ip:\n            named_urls.append((\"Network URL\", server_util.get_url(internal_ip)))\n\n        if config.get_option(\"server.headless\"):\n            external_ip = net_util.get_external_ip()\n            if external_ip:\n                named_urls.append((\"External URL\", server_util.get_url(external_ip)))\n\n    cli_util.print_to_cli(\"\")\n    cli_util.print_to_cli(\"  %s\" % title_message, fg=\"blue\", bold=True)\n    cli_util.print_to_cli(\"\")\n\n    for url_name, url in named_urls:\n        cli_util.print_to_cli(f\"  {url_name}: \", nl=False, fg=\"blue\")\n        cli_util.print_to_cli(url, bold=True)\n\n    cli_util.print_to_cli(\"\")\n\n    if is_running_hello:\n        cli_util.print_to_cli(\"  Ready to create your own Python apps super quickly?\")\n        cli_util.print_to_cli(\"  Head over to \", nl=False)\n        cli_util.print_to_cli(\"https://docs.streamlit.io\", bold=True)\n        cli_util.print_to_cli(\"\")\n        cli_util.print_to_cli(\"  May you create awesome apps!\")\n        cli_util.print_to_cli(\"\")\n        cli_util.print_to_cli(\"\")\n\n\ndef _maybe_print_old_git_warning(main_script_path: str) -> None:\n    \"\"\"If our script is running in a Git repo, and we're running a very old\n    Git version, print a warning that Git integration will be unavailable.\n    \"\"\"\n    repo = GitRepo(main_script_path)\n    if (\n        not repo.is_valid()\n        and repo.git_version is not None\n        and repo.git_version < MIN_GIT_VERSION\n    ):\n        git_version_string = \".\".join(str(val) for val in repo.git_version)\n        min_version_string = \".\".join(str(val) for val in MIN_GIT_VERSION)\n        cli_util.print_to_cli(\"\")\n        cli_util.print_to_cli(\"  Git integration is disabled.\", fg=\"yellow\", bold=True)\n        cli_util.print_to_cli(\"\")\n        cli_util.print_to_cli(\n            f\"  Streamlit requires Git {min_version_string} or later, \"\n            f\"but you have {git_version_string}.\",\n            fg=\"yellow\",\n        )\n        cli_util.print_to_cli(\n            \"  Git is used by Streamlit Cloud (https://streamlit.io/cloud).\",\n            fg=\"yellow\",\n        )\n        cli_util.print_to_cli(\n            \"  To enable this feature, please update Git.\", fg=\"yellow\"\n        )\n\n\ndef load_config_options(flag_options: dict[str, Any]) -> None:\n    \"\"\"Load config options from config.toml files, then overlay the ones set by\n    flag_options.\n\n    The \"streamlit run\" command supports passing Streamlit's config options\n    as flags. This function reads through the config options set via flag,\n    massages them, and passes them to get_config_options() so that they\n    overwrite config option defaults and those loaded from config.toml files.\n\n    Parameters\n    ----------\n    flag_options : dict[str, Any]\n        A dict of config options where the keys are the CLI flag version of the\n        config option names.\n    \"\"\"\n    options_from_flags = {\n        name.replace(\"_\", \".\"): val\n        for name, val in flag_options.items()\n        if val is not None\n    }\n\n    # Force a reparse of config files (if they exist). The result is cached\n    # for future calls.\n    config.get_config_options(force_reparse=True, options_from_flags=options_from_flags)\n\n\ndef _install_config_watchers(flag_options: dict[str, Any]) -> None:\n    def on_config_changed(_path):\n        load_config_options(flag_options)\n\n    for filename in CONFIG_FILENAMES:\n        if os.path.exists(filename):\n            watch_file(filename, on_config_changed)\n\n\ndef run(\n    main_script_path: str,\n    is_hello: bool,\n    args: list[str],\n    flag_options: dict[str, Any],\n) -> None:\n    \"\"\"Run a script in a separate thread and start a server for the app.\n\n    This starts a blocking asyncio eventloop.\n    \"\"\"\n    _fix_sys_path(main_script_path)\n    _fix_tornado_crash()\n    _fix_sys_argv(main_script_path, args)\n    _fix_pydeck_mapbox_api_warning()\n    _fix_pydantic_duplicate_validators_error()\n    _install_config_watchers(flag_options)\n\n    # Create the server. It won't start running yet.\n    server = Server(main_script_path, is_hello)\n\n    async def run_server() -> None:\n        # Start the server\n        await server.start()\n        _on_server_start(server)\n\n        # Install a signal handler that will shut down the server\n        # and close all our threads\n        _set_up_signal_handler(server)\n\n        # Wait until `Server.stop` is called, either by our signal handler, or\n        # by a debug websocket session.\n        await server.stopped\n\n    # Run the server. This function will not return until the server is shut down.\n    asyncio.run(run_server())\n", "lib/streamlit/web/__init__.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n", "lib/streamlit/web/server/server_util.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Server related utility functions\"\"\"\n\nfrom __future__ import annotations\n\nfrom typing import TYPE_CHECKING, Final\nfrom urllib.parse import urljoin\n\nfrom streamlit import config, net_util, url_util\n\nif TYPE_CHECKING:\n    from tornado.web import RequestHandler\n\n# The port reserved for internal development.\nDEVELOPMENT_PORT: Final = 3000\n\n\ndef is_url_from_allowed_origins(url: str) -> bool:\n    \"\"\"Return True if URL is from allowed origins (for CORS purpose).\n\n    Allowed origins:\n    1. localhost\n    2. The internal and external IP addresses of the machine where this\n       function was called from.\n\n    If `server.enableCORS` is False, this allows all origins.\n    \"\"\"\n    if not config.get_option(\"server.enableCORS\"):\n        # Allow everything when CORS is disabled.\n        return True\n\n    hostname = url_util.get_hostname(url)\n\n    allowed_domains = [  # List[Union[str, Callable[[], Optional[str]]]]\n        # Check localhost first.\n        \"localhost\",\n        \"0.0.0.0\",\n        \"127.0.0.1\",\n        # Try to avoid making unnecessary HTTP requests by checking if the user\n        # manually specified a server address.\n        _get_server_address_if_manually_set,\n        # Then try the options that depend on HTTP requests or opening sockets.\n        net_util.get_internal_ip,\n        net_util.get_external_ip,\n    ]\n\n    for allowed_domain in allowed_domains:\n        if callable(allowed_domain):\n            allowed_domain = allowed_domain()\n\n        if allowed_domain is None:\n            continue\n\n        if hostname == allowed_domain:\n            return True\n\n    return False\n\n\ndef _get_server_address_if_manually_set() -> str | None:\n    if config.is_manually_set(\"browser.serverAddress\"):\n        return url_util.get_hostname(config.get_option(\"browser.serverAddress\"))\n    return None\n\n\ndef make_url_path_regex(*path, **kwargs) -> str:\n    \"\"\"Get a regex of the form ^/foo/bar/baz/?$ for a path (foo, bar, baz).\"\"\"\n    path = [x.strip(\"/\") for x in path if x]  # Filter out falsely components.\n    path_format = r\"^/%s/?$\" if kwargs.get(\"trailing_slash\", True) else r\"^/%s$\"\n    return path_format % \"/\".join(path)\n\n\ndef get_url(host_ip: str) -> str:\n    \"\"\"Get the URL for any app served at the given host_ip.\n\n    Parameters\n    ----------\n    host_ip : str\n        The IP address of the machine that is running the Streamlit Server.\n\n    Returns\n    -------\n    str\n        The URL.\n    \"\"\"\n    protocol = \"https\" if config.get_option(\"server.sslCertFile\") else \"http\"\n\n    port = _get_browser_address_bar_port()\n    base_path = config.get_option(\"server.baseUrlPath\").strip(\"/\")\n\n    if base_path:\n        base_path = \"/\" + base_path\n\n    host_ip = host_ip.strip(\"/\")\n    return f\"{protocol}://{host_ip}:{port}{base_path}\"\n\n\ndef _get_browser_address_bar_port() -> int:\n    \"\"\"Get the app URL that will be shown in the browser's address bar.\n\n    That is, this is the port where static assets will be served from. In dev,\n    this is different from the URL that will be used to connect to the\n    server-browser websocket.\n\n    \"\"\"\n    if config.get_option(\"global.developmentMode\"):\n        return DEVELOPMENT_PORT\n    return int(config.get_option(\"browser.serverPort\"))\n\n\ndef emit_endpoint_deprecation_notice(handler: RequestHandler, new_path: str) -> None:\n    \"\"\"\n    Emits the warning about deprecation of HTTP endpoint in the HTTP header.\n    \"\"\"\n    handler.set_header(\"Deprecation\", True)\n    new_url = urljoin(f\"{handler.request.protocol}://{handler.request.host}\", new_path)\n    handler.set_header(\"Link\", f'<{new_url}>; rel=\"alternate\"')\n", "lib/streamlit/web/server/upload_file_request_handler.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom typing import TYPE_CHECKING, Any, Callable\n\nimport tornado.httputil\nimport tornado.web\n\nfrom streamlit import config\nfrom streamlit.runtime.uploaded_file_manager import UploadedFileRec\nfrom streamlit.web.server import routes, server_util\n\nif TYPE_CHECKING:\n    from streamlit.runtime.memory_uploaded_file_manager import MemoryUploadedFileManager\n\n\nclass UploadFileRequestHandler(tornado.web.RequestHandler):\n    \"\"\"Implements the POST /upload_file endpoint.\"\"\"\n\n    def initialize(\n        self,\n        file_mgr: MemoryUploadedFileManager,\n        is_active_session: Callable[[str], bool],\n    ):\n        \"\"\"\n        Parameters\n        ----------\n        file_mgr : UploadedFileManager\n            The server's singleton UploadedFileManager. All file uploads\n            go here.\n        is_active_session:\n            A function that returns true if a session_id belongs to an active\n            session.\n        \"\"\"\n        self._file_mgr = file_mgr\n        self._is_active_session = is_active_session\n\n    def set_default_headers(self):\n        self.set_header(\"Access-Control-Allow-Methods\", \"PUT, OPTIONS, DELETE\")\n        self.set_header(\"Access-Control-Allow-Headers\", \"Content-Type\")\n        if config.get_option(\"server.enableXsrfProtection\"):\n            self.set_header(\n                \"Access-Control-Allow-Origin\",\n                server_util.get_url(config.get_option(\"browser.serverAddress\")),\n            )\n            self.set_header(\"Access-Control-Allow-Headers\", \"X-Xsrftoken, Content-Type\")\n            self.set_header(\"Vary\", \"Origin\")\n            self.set_header(\"Access-Control-Allow-Credentials\", \"true\")\n        elif routes.allow_cross_origin_requests():\n            self.set_header(\"Access-Control-Allow-Origin\", \"*\")\n\n    def options(self, **kwargs):\n        \"\"\"/OPTIONS handler for preflight CORS checks.\n\n        When a browser is making a CORS request, it may sometimes first\n        send an OPTIONS request, to check whether the server understands the\n        CORS protocol. This is optional, and doesn't happen for every request\n        or in every browser. If an OPTIONS request does get sent, and is not\n        then handled by the server, the browser will fail the underlying\n        request.\n\n        The proper way to handle this is to send a 204 response (\"no content\")\n        with the CORS headers attached. (These headers are automatically added\n        to every outgoing response, including OPTIONS responses,\n        via set_default_headers().)\n\n        See https://developer.mozilla.org/en-US/docs/Glossary/Preflight_request\n        \"\"\"\n        self.set_status(204)\n        self.finish()\n\n    def put(self, **kwargs):\n        \"\"\"Receive an uploaded file and add it to our UploadedFileManager.\"\"\"\n\n        args: dict[str, list[bytes]] = {}\n        files: dict[str, list[Any]] = {}\n\n        session_id = self.path_kwargs[\"session_id\"]\n        file_id = self.path_kwargs[\"file_id\"]\n\n        tornado.httputil.parse_body_arguments(\n            content_type=self.request.headers[\"Content-Type\"],\n            body=self.request.body,\n            arguments=args,\n            files=files,\n        )\n\n        try:\n            if not self._is_active_session(session_id):\n                raise Exception(\"Invalid session_id\")\n        except Exception as e:\n            self.send_error(400, reason=str(e))\n            return\n\n        uploaded_files: list[UploadedFileRec] = []\n\n        for _, flist in files.items():\n            for file in flist:\n                uploaded_files.append(\n                    UploadedFileRec(\n                        file_id=file_id,\n                        name=file[\"filename\"],\n                        type=file[\"content_type\"],\n                        data=file[\"body\"],\n                    )\n                )\n\n        if len(uploaded_files) != 1:\n            self.send_error(\n                400, reason=f\"Expected 1 file, but got {len(uploaded_files)}\"\n            )\n            return\n\n        self._file_mgr.add_file(session_id=session_id, file=uploaded_files[0])\n        self.set_status(204)\n\n    def delete(self, **kwargs):\n        \"\"\"Delete file request handler.\"\"\"\n        session_id = self.path_kwargs[\"session_id\"]\n        file_id = self.path_kwargs[\"file_id\"]\n\n        self._file_mgr.remove_file(session_id=session_id, file_id=file_id)\n        self.set_status(204)\n", "lib/streamlit/web/server/routes.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport os\nfrom typing import Final, Sequence\n\nimport tornado.web\n\nfrom streamlit import config, file_util\nfrom streamlit.logger import get_logger\nfrom streamlit.runtime.runtime_util import serialize_forward_msg\nfrom streamlit.web.server.server_util import emit_endpoint_deprecation_notice\n\n_LOGGER: Final = get_logger(__name__)\n\n\ndef allow_cross_origin_requests() -> bool:\n    \"\"\"True if cross-origin requests are allowed.\n\n    We only allow cross-origin requests when CORS protection has been disabled\n    with server.enableCORS=False or if using the Node server. When using the\n    Node server, we have a dev and prod port, which count as two origins.\n\n    \"\"\"\n    return not config.get_option(\"server.enableCORS\") or config.get_option(\n        \"global.developmentMode\"\n    )\n\n\nclass StaticFileHandler(tornado.web.StaticFileHandler):\n    def initialize(\n        self,\n        path: str,\n        default_filename: str | None = None,\n        reserved_paths: Sequence[str] = (),\n    ):\n        self._reserved_paths = reserved_paths\n\n        super().initialize(path, default_filename)\n\n    def set_extra_headers(self, path: str) -> None:\n        \"\"\"Disable cache for HTML files.\n\n        Other assets like JS and CSS are suffixed with their hash, so they can\n        be cached indefinitely.\n        \"\"\"\n        is_index_url = len(path) == 0\n\n        if is_index_url or path.endswith(\".html\"):\n            self.set_header(\"Cache-Control\", \"no-cache\")\n        else:\n            self.set_header(\"Cache-Control\", \"public\")\n\n    def validate_absolute_path(self, root: str, absolute_path: str) -> str | None:\n        try:\n            return super().validate_absolute_path(root, absolute_path)\n        except tornado.web.HTTPError as e:\n            # If the file is not found, and there are no reserved paths,\n            # we try to serve the default file and allow the frontend to handle the issue.\n            if e.status_code == 404:\n                if any(self.path.endswith(x) for x in self._reserved_paths):\n                    raise e\n\n                self.path = self.parse_url_path(self.default_filename or \"index.html\")\n                absolute_path = self.get_absolute_path(self.root, self.path)\n                return super().validate_absolute_path(root, absolute_path)\n\n            raise e\n\n    def write_error(self, status_code: int, **kwargs) -> None:\n        if status_code == 404:\n            index_file = os.path.join(file_util.get_static_dir(), \"index.html\")\n            self.render(index_file)\n        else:\n            super().write_error(status_code, **kwargs)\n\n\nclass AddSlashHandler(tornado.web.RequestHandler):\n    @tornado.web.addslash\n    def get(self):\n        pass\n\n\nclass _SpecialRequestHandler(tornado.web.RequestHandler):\n    \"\"\"Superclass for \"special\" endpoints, like /healthz.\"\"\"\n\n    def set_default_headers(self):\n        self.set_header(\"Cache-Control\", \"no-cache\")\n        if allow_cross_origin_requests():\n            self.set_header(\"Access-Control-Allow-Origin\", \"*\")\n\n    def options(self):\n        \"\"\"/OPTIONS handler for preflight CORS checks.\n\n        When a browser is making a CORS request, it may sometimes first\n        send an OPTIONS request, to check whether the server understands the\n        CORS protocol. This is optional, and doesn't happen for every request\n        or in every browser. If an OPTIONS request does get sent, and is not\n        then handled by the server, the browser will fail the underlying\n        request.\n\n        The proper way to handle this is to send a 204 response (\"no content\")\n        with the CORS headers attached. (These headers are automatically added\n        to every outgoing response, including OPTIONS responses,\n        via set_default_headers().)\n\n        See https://developer.mozilla.org/en-US/docs/Glossary/Preflight_request\n        \"\"\"\n        self.set_status(204)\n        self.finish()\n\n\nclass HealthHandler(_SpecialRequestHandler):\n    def initialize(self, callback):\n        \"\"\"Initialize the handler\n\n        Parameters\n        ----------\n        callback : callable\n            A function that returns True if the server is healthy\n\n        \"\"\"\n        self._callback = callback\n\n    async def get(self):\n        await self.handle_request()\n\n    # Some monitoring services only support the HTTP HEAD method for requests to\n    # healthcheck endpoints, so we support HEAD as well to play nicely with them.\n    async def head(self):\n        await self.handle_request()\n\n    async def handle_request(self):\n        if self.request.uri and \"_stcore/\" not in self.request.uri:\n            new_path = (\n                \"/_stcore/script-health-check\"\n                if \"script-health-check\" in self.request.uri\n                else \"/_stcore/health\"\n            )\n            emit_endpoint_deprecation_notice(self, new_path=new_path)\n\n        ok, msg = await self._callback()\n        if ok:\n            self.write(msg)\n            self.set_status(200)\n\n            # Tornado will set the _streamlit_xsrf cookie automatically for the page on\n            # request for the document. However, if the server is reset and\n            # server.enableXsrfProtection is updated, the browser does not reload the document.\n            # Manually setting the cookie on /healthz since it is pinged when the\n            # browser is disconnected from the server.\n            if config.get_option(\"server.enableXsrfProtection\"):\n                cookie_kwargs = self.settings.get(\"xsrf_cookie_kwargs\", {})\n                self.set_cookie(\n                    self.settings.get(\"xsrf_cookie_name\", \"_streamlit_xsrf\"),\n                    self.xsrf_token,\n                    **cookie_kwargs,\n                )\n\n        else:\n            # 503 = SERVICE_UNAVAILABLE\n            self.set_status(503)\n            self.write(msg)\n\n\n_DEFAULT_ALLOWED_MESSAGE_ORIGINS = [\n    # Community-cloud related domains.\n    # We can remove these in the future if community cloud\n    # provides those domains via the host-config endpoint.\n    \"https://devel.streamlit.test\",\n    \"https://*.streamlit.apptest\",\n    \"https://*.streamlitapp.test\",\n    \"https://*.streamlitapp.com\",\n    \"https://share.streamlit.io\",\n    \"https://share-demo.streamlit.io\",\n    \"https://share-head.streamlit.io\",\n    \"https://share-staging.streamlit.io\",\n    \"https://*.demo.streamlit.run\",\n    \"https://*.head.streamlit.run\",\n    \"https://*.staging.streamlit.run\",\n    \"https://*.streamlit.run\",\n    \"https://*.demo.streamlit.app\",\n    \"https://*.head.streamlit.app\",\n    \"https://*.staging.streamlit.app\",\n    \"https://*.streamlit.app\",\n]\n\n\nclass HostConfigHandler(_SpecialRequestHandler):\n    def initialize(self):\n        # Make a copy of the allowedOrigins list, since we might modify it later:\n        self._allowed_origins = _DEFAULT_ALLOWED_MESSAGE_ORIGINS.copy()\n\n        if (\n            config.get_option(\"global.developmentMode\")\n            and \"http://localhost\" not in self._allowed_origins\n        ):\n            # Allow messages from localhost in dev mode for testing of host <-> guest communication\n            self._allowed_origins.append(\"http://localhost\")\n\n    async def get(self) -> None:\n        self.write(\n            {\n                \"allowedOrigins\": self._allowed_origins,\n                \"useExternalAuthToken\": False,\n                # Default host configuration settings.\n                \"enableCustomParentMessages\": False,\n                \"enforceDownloadInNewTab\": False,\n            }\n        )\n        self.set_status(200)\n\n\nclass MessageCacheHandler(tornado.web.RequestHandler):\n    \"\"\"Returns ForwardMsgs from our MessageCache\"\"\"\n\n    def initialize(self, cache):\n        \"\"\"Initializes the handler.\n\n        Parameters\n        ----------\n        cache : MessageCache\n\n        \"\"\"\n        self._cache = cache\n\n    def set_default_headers(self):\n        if allow_cross_origin_requests():\n            self.set_header(\"Access-Control-Allow-Origin\", \"*\")\n\n    def get(self):\n        msg_hash = self.get_argument(\"hash\", None)\n        if not config.get_option(\"global.storeCachedForwardMessagesInMemory\"):\n            # We use rare status code here, to distinguish between normal 404s.\n            self.set_status(418)\n            self.finish()\n            return\n        if msg_hash is None:\n            # Hash is missing! This is a malformed request.\n            _LOGGER.error(\n                \"HTTP request for cached message is missing the hash attribute.\"\n            )\n            self.set_status(404)\n            raise tornado.web.Finish()\n\n        message = self._cache.get_message(msg_hash)\n        if message is None:\n            # Message not in our cache.\n            _LOGGER.error(\n                \"HTTP request for cached message could not be fulfilled. \"\n                \"No such message\"\n            )\n            self.set_status(404)\n            raise tornado.web.Finish()\n\n        _LOGGER.debug(\"MessageCache HIT\")\n        msg_str = serialize_forward_msg(message)\n        self.set_header(\"Content-Type\", \"application/octet-stream\")\n        self.write(msg_str)\n        self.set_status(200)\n\n    def options(self):\n        \"\"\"/OPTIONS handler for preflight CORS checks.\"\"\"\n        self.set_status(204)\n        self.finish()\n", "lib/streamlit/web/server/media_file_handler.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom urllib.parse import quote\n\nimport tornado.web\n\nfrom streamlit.logger import get_logger\nfrom streamlit.runtime.media_file_storage import MediaFileKind, MediaFileStorageError\nfrom streamlit.runtime.memory_media_file_storage import (\n    MemoryMediaFileStorage,\n    get_extension_for_mimetype,\n)\nfrom streamlit.web.server import allow_cross_origin_requests\n\n_LOGGER = get_logger(__name__)\n\n\nclass MediaFileHandler(tornado.web.StaticFileHandler):\n    _storage: MemoryMediaFileStorage\n\n    @classmethod\n    def initialize_storage(cls, storage: MemoryMediaFileStorage) -> None:\n        \"\"\"Set the MemoryMediaFileStorage object used by instances of this\n        handler. Must be called on server startup.\n        \"\"\"\n        # This is a class method, rather than an instance method, because\n        # `get_content()` is a class method and needs to access the storage\n        # instance.\n        cls._storage = storage\n\n    def set_default_headers(self) -> None:\n        if allow_cross_origin_requests():\n            self.set_header(\"Access-Control-Allow-Origin\", \"*\")\n\n    def set_extra_headers(self, path: str) -> None:\n        \"\"\"Add Content-Disposition header for downloadable files.\n\n        Set header value to \"attachment\" indicating that file should be saved\n        locally instead of displaying inline in browser.\n\n        We also set filename to specify the filename for downloaded files.\n        Used for serving downloadable files, like files stored via the\n        `st.download_button` widget.\n        \"\"\"\n        media_file = self._storage.get_file(path)\n\n        if media_file and media_file.kind == MediaFileKind.DOWNLOADABLE:\n            filename = media_file.filename\n\n            if not filename:\n                filename = f\"streamlit_download{get_extension_for_mimetype(media_file.mimetype)}\"\n\n            try:\n                # Check that the value can be encoded in latin1. Latin1 is\n                # the default encoding for headers.\n                filename.encode(\"latin1\")\n                file_expr = f'filename=\"{filename}\"'\n            except UnicodeEncodeError:\n                # RFC5987 syntax.\n                # See: https://datatracker.ietf.org/doc/html/rfc5987\n                file_expr = f\"filename*=utf-8''{quote(filename)}\"\n\n            self.set_header(\"Content-Disposition\", f\"attachment; {file_expr}\")\n\n    # Overriding StaticFileHandler to use the MediaFileManager\n    #\n    # From the Tornado docs:\n    # To replace all interaction with the filesystem (e.g. to serve\n    # static content from a database), override `get_content`,\n    # `get_content_size`, `get_modified_time`, `get_absolute_path`, and\n    # `validate_absolute_path`.\n    def validate_absolute_path(self, root: str, absolute_path: str) -> str:\n        try:\n            self._storage.get_file(absolute_path)\n        except MediaFileStorageError:\n            _LOGGER.error(\"MediaFileHandler: Missing file %s\", absolute_path)\n            raise tornado.web.HTTPError(404, \"not found\")\n\n        return absolute_path\n\n    def get_content_size(self) -> int:\n        abspath = self.absolute_path\n        if abspath is None:\n            return 0\n\n        media_file = self._storage.get_file(abspath)\n        return media_file.content_size\n\n    def get_modified_time(self) -> None:\n        # We do not track last modified time, but this can be improved to\n        # allow caching among files in the MediaFileManager\n        return None\n\n    @classmethod\n    def get_absolute_path(cls, root: str, path: str) -> str:\n        # All files are stored in memory, so the absolute path is just the\n        # path itself. In the MediaFileHandler, it's just the filename\n        return path\n\n    @classmethod\n    def get_content(\n        cls, abspath: str, start: int | None = None, end: int | None = None\n    ):\n        _LOGGER.debug(\"MediaFileHandler: GET %s\", abspath)\n\n        try:\n            # abspath is the hash as used `get_absolute_path`\n            media_file = cls._storage.get_file(abspath)\n        except Exception:\n            _LOGGER.error(\"MediaFileHandler: Missing file %s\", abspath)\n            return None\n\n        _LOGGER.debug(\n            \"MediaFileHandler: Sending %s file %s\", media_file.mimetype, abspath\n        )\n\n        # If there is no start and end, just return the full content\n        if start is None and end is None:\n            return media_file.content\n\n        if start is None:\n            start = 0\n        if end is None:\n            end = len(media_file.content)\n\n        # content is bytes that work just by slicing supplied by start and end\n        return media_file.content[start:end]\n", "lib/streamlit/web/server/stats_request_handler.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom typing import TYPE_CHECKING\n\nimport tornado.web\n\nfrom streamlit.web.server.server_util import emit_endpoint_deprecation_notice\n\nif TYPE_CHECKING:\n    from streamlit.proto.openmetrics_data_model_pb2 import MetricSet as MetricSetProto\n    from streamlit.runtime.stats import CacheStat, StatsManager\n\n\nclass StatsRequestHandler(tornado.web.RequestHandler):\n    def initialize(self, stats_manager: StatsManager) -> None:\n        self._manager = stats_manager\n\n    def set_default_headers(self):\n        # Avoid a circular import\n        from streamlit.web.server import allow_cross_origin_requests\n\n        if allow_cross_origin_requests():\n            self.set_header(\"Access-Control-Allow-Origin\", \"*\")\n\n    def options(self):\n        \"\"\"/OPTIONS handler for preflight CORS checks.\"\"\"\n        self.set_status(204)\n        self.finish()\n\n    def get(self) -> None:\n        if self.request.uri and \"_stcore/\" not in self.request.uri:\n            emit_endpoint_deprecation_notice(self, new_path=\"/_stcore/metrics\")\n\n        stats = self._manager.get_stats()\n\n        # If the request asked for protobuf output, we return a serialized\n        # protobuf. Else we return text.\n        if \"application/x-protobuf\" in self.request.headers.get_list(\"Accept\"):\n            self.write(self._stats_to_proto(stats).SerializeToString())\n            self.set_header(\"Content-Type\", \"application/x-protobuf\")\n            self.set_status(200)\n        else:\n            self.write(self._stats_to_text(self._manager.get_stats()))\n            self.set_header(\"Content-Type\", \"application/openmetrics-text\")\n            self.set_status(200)\n\n    @staticmethod\n    def _stats_to_text(stats: list[CacheStat]) -> str:\n        metric_type = \"# TYPE cache_memory_bytes gauge\"\n        metric_unit = \"# UNIT cache_memory_bytes bytes\"\n        metric_help = \"# HELP Total memory consumed by a cache.\"\n        openmetrics_eof = \"# EOF\\n\"\n\n        # Format: header, stats, EOF\n        result = [metric_type, metric_unit, metric_help]\n        result.extend(stat.to_metric_str() for stat in stats)\n        result.append(openmetrics_eof)\n\n        return \"\\n\".join(result)\n\n    @staticmethod\n    def _stats_to_proto(stats: list[CacheStat]) -> MetricSetProto:\n        # Lazy load the import of this proto message for better performance:\n        from streamlit.proto.openmetrics_data_model_pb2 import GAUGE\n        from streamlit.proto.openmetrics_data_model_pb2 import (\n            MetricSet as MetricSetProto,\n        )\n\n        metric_set = MetricSetProto()\n\n        metric_family = metric_set.metric_families.add()\n        metric_family.name = \"cache_memory_bytes\"\n        metric_family.type = GAUGE\n        metric_family.unit = \"bytes\"\n        metric_family.help = \"Total memory consumed by a cache.\"\n\n        for stat in stats:\n            metric_proto = metric_family.metrics.add()\n            stat.marshall_metric_proto(metric_proto)\n\n        metric_set = MetricSetProto()\n        metric_set.metric_families.append(metric_family)\n        return metric_set\n", "lib/streamlit/web/server/app_static_file_handler.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport mimetypes\nimport os\nfrom pathlib import Path\nfrom typing import Final\n\nimport tornado.web\n\nfrom streamlit.logger import get_logger\n\n_LOGGER: Final = get_logger(__name__)\n\n# We agreed on these limitations for the initial release of static file sharing,\n# based on security concerns from the SiS and Community Cloud teams\n# The maximum possible size of single serving static file.\nMAX_APP_STATIC_FILE_SIZE = 200 * 1024 * 1024  # 200 MB\n# The list of file extensions that we serve with the corresponding Content-Type header.\n# All files with other extensions will be served with Content-Type: text/plain\nSAFE_APP_STATIC_FILE_EXTENSIONS = (\".jpg\", \".jpeg\", \".png\", \".gif\", \".webp\")\n\n\nclass AppStaticFileHandler(tornado.web.StaticFileHandler):\n    def initialize(self, path: str, default_filename: str | None = None) -> None:\n        super().initialize(path, default_filename)\n        mimetypes.add_type(\"image/webp\", \".webp\")\n\n    def validate_absolute_path(self, root: str, absolute_path: str) -> str | None:\n        full_path = os.path.realpath(absolute_path)\n\n        if os.path.isdir(full_path):\n            # we don't want to serve directories, and serve only files\n            raise tornado.web.HTTPError(404)\n\n        if os.path.commonpath([full_path, root]) != root:\n            # Don't allow misbehaving clients to break out of the static files directory\n            _LOGGER.warning(\n                \"Serving files outside of the static directory is not supported\"\n            )\n            raise tornado.web.HTTPError(404)\n\n        if (\n            os.path.exists(full_path)\n            and os.path.getsize(full_path) > MAX_APP_STATIC_FILE_SIZE\n        ):\n            raise tornado.web.HTTPError(\n                404,\n                \"File is too large, its size should not exceed \"\n                f\"{MAX_APP_STATIC_FILE_SIZE} bytes\",\n                reason=\"File is too large\",\n            )\n\n        return super().validate_absolute_path(root, absolute_path)\n\n    def set_default_headers(self):\n        # CORS protection is disabled because we need access to this endpoint\n        # from the inner iframe.\n        self.set_header(\"Access-Control-Allow-Origin\", \"*\")\n\n    def set_extra_headers(self, path: str) -> None:\n        if Path(path).suffix not in SAFE_APP_STATIC_FILE_EXTENSIONS:\n            self.set_header(\"Content-Type\", \"text/plain\")\n        self.set_header(\"X-Content-Type-Options\", \"nosniff\")\n", "lib/streamlit/web/server/browser_websocket_handler.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport base64\nimport binascii\nimport json\nfrom typing import TYPE_CHECKING, Any, Awaitable, Final\n\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.netutil\nimport tornado.web\nimport tornado.websocket\nfrom tornado.websocket import WebSocketHandler\n\nfrom streamlit import config\nfrom streamlit.logger import get_logger\nfrom streamlit.proto.BackMsg_pb2 import BackMsg\nfrom streamlit.runtime import Runtime, SessionClient, SessionClientDisconnectedError\nfrom streamlit.runtime.runtime_util import serialize_forward_msg\nfrom streamlit.web.server.server_util import is_url_from_allowed_origins\n\nif TYPE_CHECKING:\n    from streamlit.proto.ForwardMsg_pb2 import ForwardMsg\n\n_LOGGER: Final = get_logger(__name__)\n\n\nclass BrowserWebSocketHandler(WebSocketHandler, SessionClient):\n    \"\"\"Handles a WebSocket connection from the browser\"\"\"\n\n    def initialize(self, runtime: Runtime) -> None:\n        self._runtime = runtime\n        self._session_id: str | None = None\n        # The XSRF cookie is normally set when xsrf_form_html is used, but in a\n        # pure-Javascript application that does not use any regular forms we just\n        # need to read the self.xsrf_token manually to set the cookie as a side\n        # effect. See https://www.tornadoweb.org/en/stable/guide/security.html#cross-site-request-forgery-protection\n        # for more details.\n        if config.get_option(\"server.enableXsrfProtection\"):\n            _ = self.xsrf_token\n\n    def check_origin(self, origin: str) -> bool:\n        \"\"\"Set up CORS.\"\"\"\n        return super().check_origin(origin) or is_url_from_allowed_origins(origin)\n\n    def write_forward_msg(self, msg: ForwardMsg) -> None:\n        \"\"\"Send a ForwardMsg to the browser.\"\"\"\n        try:\n            self.write_message(serialize_forward_msg(msg), binary=True)\n        except tornado.websocket.WebSocketClosedError as e:\n            raise SessionClientDisconnectedError from e\n\n    def select_subprotocol(self, subprotocols: list[str]) -> str | None:\n        \"\"\"Return the first subprotocol in the given list.\n\n        This method is used by Tornado to select a protocol when the\n        Sec-WebSocket-Protocol header is set in an HTTP Upgrade request.\n\n        NOTE: We repurpose the Sec-WebSocket-Protocol header here in a slightly\n        unfortunate (but necessary) way. The browser WebSocket API doesn't allow us to\n        set arbitrary HTTP headers, and this header is the only one where we have the\n        ability to set it to arbitrary values, so we use it to pass tokens (in this\n        case, the previous session ID to allow us to reconnect to it) from client to\n        server as the *third* value in the list.\n\n        The reason why the auth token is set as the third value is that:\n          * when Sec-WebSocket-Protocol is set, many clients expect the server to\n            respond with a selected subprotocol to use. We don't want that reply to be\n            the session token, so we by convention have the client always set the first\n            protocol to \"streamlit\" and select that.\n          * the second protocol in the list is reserved in some deployment environments\n            for an auth token that we currently don't use\n        \"\"\"\n        if subprotocols:\n            return subprotocols[0]\n\n        return None\n\n    def open(self, *args, **kwargs) -> Awaitable[None] | None:\n        # Extract user info from the X-Streamlit-User header\n        is_public_cloud_app = False\n\n        try:\n            header_content = self.request.headers[\"X-Streamlit-User\"]\n            payload = base64.b64decode(header_content)\n            user_obj = json.loads(payload)\n            email = user_obj[\"email\"]\n            is_public_cloud_app = user_obj[\"isPublicCloudApp\"]\n        except (KeyError, binascii.Error, json.decoder.JSONDecodeError):\n            email = \"test@example.com\"\n\n        user_info: dict[str, str | None] = {\n            \"email\": None if is_public_cloud_app else email\n        }\n\n        existing_session_id = None\n        try:\n            ws_protocols = [\n                p.strip()\n                for p in self.request.headers[\"Sec-Websocket-Protocol\"].split(\",\")\n            ]\n\n            if len(ws_protocols) >= 3:\n                # See the NOTE in the docstring of the `select_subprotocol` method above\n                # for a detailed explanation of why this is done.\n                existing_session_id = ws_protocols[2]\n        except KeyError:\n            # Just let existing_session_id=None if we run into any error while trying to\n            # extract it from the Sec-Websocket-Protocol header.\n            pass\n\n        self._session_id = self._runtime.connect_session(\n            client=self,\n            user_info=user_info,\n            existing_session_id=existing_session_id,\n        )\n        return None\n\n    def on_close(self) -> None:\n        if not self._session_id:\n            return\n        self._runtime.disconnect_session(self._session_id)\n        self._session_id = None\n\n    def get_compression_options(self) -> dict[Any, Any] | None:\n        \"\"\"Enable WebSocket compression.\n\n        Returning an empty dict enables websocket compression. Returning\n        None disables it.\n\n        (See the docstring in the parent class.)\n        \"\"\"\n        if config.get_option(\"server.enableWebsocketCompression\"):\n            return {}\n        return None\n\n    def on_message(self, payload: str | bytes) -> None:\n        if not self._session_id:\n            return\n\n        try:\n            if isinstance(payload, str):\n                # Sanity check. (The frontend should only be sending us bytes;\n                # Protobuf.ParseFromString does not accept str input.)\n                raise RuntimeError(\n                    \"WebSocket received an unexpected `str` message. \"\n                    \"(We expect `bytes` only.)\"\n                )\n\n            msg = BackMsg()\n            msg.ParseFromString(payload)\n            _LOGGER.debug(\"Received the following back message:\\n%s\", msg)\n\n        except Exception as ex:\n            _LOGGER.error(ex)\n            self._runtime.handle_backmsg_deserialization_exception(self._session_id, ex)\n            return\n\n        # \"debug_disconnect_websocket\" and \"debug_shutdown_runtime\" are special\n        # developmentMode-only messages used in e2e tests to test reconnect handling and\n        # disabling widgets.\n        if msg.WhichOneof(\"type\") == \"debug_disconnect_websocket\":\n            if config.get_option(\"global.developmentMode\") or config.get_option(\n                \"global.e2eTest\"\n            ):\n                self.close()\n            else:\n                _LOGGER.warning(\n                    \"Client tried to disconnect websocket when not in development mode or e2e testing.\"\n                )\n        elif msg.WhichOneof(\"type\") == \"debug_shutdown_runtime\":\n            if config.get_option(\"global.developmentMode\") or config.get_option(\n                \"global.e2eTest\"\n            ):\n                self._runtime.stop()\n            else:\n                _LOGGER.warning(\n                    \"Client tried to shut down runtime when not in development mode or e2e testing.\"\n                )\n        else:\n            # AppSession handles all other BackMsg types.\n            self._runtime.handle_backmsg(self._session_id, msg)\n", "lib/streamlit/web/server/__init__.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom streamlit.web.server.component_request_handler import ComponentRequestHandler\nfrom streamlit.web.server.routes import allow_cross_origin_requests\nfrom streamlit.web.server.server import Server, server_address_is_unix_socket\nfrom streamlit.web.server.stats_request_handler import StatsRequestHandler\n\n__all__ = [\n    \"ComponentRequestHandler\",\n    \"allow_cross_origin_requests\",\n    \"Server\",\n    \"server_address_is_unix_socket\",\n    \"StatsRequestHandler\",\n]\n", "lib/streamlit/web/server/component_request_handler.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport mimetypes\nimport os\nfrom typing import TYPE_CHECKING, Final\n\nimport tornado.web\n\nimport streamlit.web.server.routes\nfrom streamlit.logger import get_logger\n\nif TYPE_CHECKING:\n    from streamlit.components.types.base_component_registry import BaseComponentRegistry\n\n_LOGGER: Final = get_logger(__name__)\n\n\nclass ComponentRequestHandler(tornado.web.RequestHandler):\n    def initialize(self, registry: BaseComponentRegistry):\n        self._registry = registry\n\n    def get(self, path: str) -> None:\n        parts = path.split(\"/\")\n        component_name = parts[0]\n        component_root = self._registry.get_component_path(component_name)\n        if component_root is None:\n            self.write(\"not found\")\n            self.set_status(404)\n            return\n\n        # follow symlinks to get an accurate normalized path\n        component_root = os.path.realpath(component_root)\n        filename = \"/\".join(parts[1:])\n        abspath = os.path.realpath(os.path.join(component_root, filename))\n\n        # Do NOT expose anything outside of the component root.\n        if os.path.commonpath([component_root, abspath]) != component_root:\n            self.write(\"forbidden\")\n            self.set_status(403)\n            return\n        try:\n            with open(abspath, \"rb\") as file:\n                contents = file.read()\n        except OSError as e:\n            _LOGGER.error(\n                \"ComponentRequestHandler: GET %s read error\", abspath, exc_info=e\n            )\n            self.write(\"read error\")\n            self.set_status(404)\n            return\n\n        self.write(contents)\n        self.set_header(\"Content-Type\", self.get_content_type(abspath))\n\n        self.set_extra_headers(path)\n\n    def set_extra_headers(self, path: str) -> None:\n        \"\"\"Disable cache for HTML files.\n\n        Other assets like JS and CSS are suffixed with their hash, so they can\n        be cached indefinitely.\n        \"\"\"\n        is_index_url = len(path) == 0\n\n        if is_index_url or path.endswith(\".html\"):\n            self.set_header(\"Cache-Control\", \"no-cache\")\n        else:\n            self.set_header(\"Cache-Control\", \"public\")\n\n    def set_default_headers(self) -> None:\n        if streamlit.web.server.routes.allow_cross_origin_requests():\n            self.set_header(\"Access-Control-Allow-Origin\", \"*\")\n\n    def options(self) -> None:\n        \"\"\"/OPTIONS handler for preflight CORS checks.\"\"\"\n        self.set_status(204)\n        self.finish()\n\n    @staticmethod\n    def get_content_type(abspath: str) -> str:\n        \"\"\"Returns the ``Content-Type`` header to be used for this request.\n        From tornado.web.StaticFileHandler.\n        \"\"\"\n        mime_type, encoding = mimetypes.guess_type(abspath)\n        # per RFC 6713, use the appropriate type for a gzip compressed file\n        if encoding == \"gzip\":\n            return \"application/gzip\"\n        # As of 2015-07-21 there is no bzip2 encoding defined at\n        # http://www.iana.org/assignments/media-types/media-types.xhtml\n        # So for that (and any other encoding), use octet-stream.\n        elif encoding is not None:\n            return \"application/octet-stream\"\n        elif mime_type is not None:\n            return mime_type\n        # if mime_type not detected, use application/octet-stream\n        else:\n            return \"application/octet-stream\"\n\n    @staticmethod\n    def get_url(file_id: str) -> str:\n        \"\"\"Return the URL for a component file with the given ID.\"\"\"\n        return f\"components/{file_id}\"\n", "lib/streamlit/web/server/websocket_headers.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom streamlit import runtime\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.runtime.scriptrunner import get_script_run_ctx\nfrom streamlit.web.server.browser_websocket_handler import BrowserWebSocketHandler\n\n\n@gather_metrics(\"_get_websocket_headers\")\ndef _get_websocket_headers() -> dict[str, str] | None:\n    \"\"\"Return a copy of the HTTP request headers for the current session's\n    WebSocket connection. If there's no active session, return None instead.\n\n    Raise an error if the server is not running.\n\n    Note to the intrepid: this is an UNSUPPORTED, INTERNAL API. (We don't have plans\n    to remove it without a replacement, but we don't consider this a production-ready\n    function, and its signature may change without a deprecation warning.)\n    \"\"\"\n    ctx = get_script_run_ctx()\n    if ctx is None:\n        return None\n\n    session_client = runtime.get_instance().get_client(ctx.session_id)\n    if session_client is None:\n        return None\n\n    if not isinstance(session_client, BrowserWebSocketHandler):\n        raise RuntimeError(\n            f\"SessionClient is not a BrowserWebSocketHandler! ({session_client})\"\n        )\n\n    return dict(session_client.request.headers)\n", "lib/streamlit/web/server/server.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport errno\nimport logging\nimport os\nimport sys\nfrom pathlib import Path\nfrom typing import TYPE_CHECKING, Any, Awaitable, Final\n\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.netutil\nimport tornado.web\nimport tornado.websocket\nfrom tornado.httpserver import HTTPServer\n\nfrom streamlit import cli_util, config, file_util, util\nfrom streamlit.config_option import ConfigOption\nfrom streamlit.logger import get_logger\nfrom streamlit.runtime import Runtime, RuntimeConfig, RuntimeState\nfrom streamlit.runtime.memory_media_file_storage import MemoryMediaFileStorage\nfrom streamlit.runtime.memory_uploaded_file_manager import MemoryUploadedFileManager\nfrom streamlit.runtime.runtime_util import get_max_message_size_bytes\nfrom streamlit.web.cache_storage_manager_config import (\n    create_default_cache_storage_manager,\n)\nfrom streamlit.web.server.app_static_file_handler import AppStaticFileHandler\nfrom streamlit.web.server.browser_websocket_handler import BrowserWebSocketHandler\nfrom streamlit.web.server.component_request_handler import ComponentRequestHandler\nfrom streamlit.web.server.media_file_handler import MediaFileHandler\nfrom streamlit.web.server.routes import (\n    AddSlashHandler,\n    HealthHandler,\n    HostConfigHandler,\n    MessageCacheHandler,\n    StaticFileHandler,\n)\nfrom streamlit.web.server.server_util import DEVELOPMENT_PORT, make_url_path_regex\nfrom streamlit.web.server.stats_request_handler import StatsRequestHandler\nfrom streamlit.web.server.upload_file_request_handler import UploadFileRequestHandler\n\nif TYPE_CHECKING:\n    from ssl import SSLContext\n\n_LOGGER: Final = get_logger(__name__)\n\nTORNADO_SETTINGS = {\n    # Gzip HTTP responses.\n    \"compress_response\": True,\n    # Ping every 1s to keep WS alive.\n    # 2021.06.22: this value was previously 20s, and was causing\n    # connection instability for a small number of users. This smaller\n    # ping_interval fixes that instability.\n    # https://github.com/streamlit/streamlit/issues/3196\n    \"websocket_ping_interval\": 1,\n    # If we don't get a ping response within 30s, the connection\n    # is timed out.\n    \"websocket_ping_timeout\": 30,\n    \"xsrf_cookie_name\": \"_streamlit_xsrf\",\n}\n\n# When server.port is not available it will look for the next available port\n# up to MAX_PORT_SEARCH_RETRIES.\nMAX_PORT_SEARCH_RETRIES: Final = 100\n\n# When server.address starts with this prefix, the server will bind\n# to an unix socket.\nUNIX_SOCKET_PREFIX: Final = \"unix://\"\n\nMEDIA_ENDPOINT: Final = \"/media\"\nUPLOAD_FILE_ENDPOINT: Final = \"/_stcore/upload_file\"\nSTREAM_ENDPOINT: Final = r\"_stcore/stream\"\nMETRIC_ENDPOINT: Final = r\"(?:st-metrics|_stcore/metrics)\"\nMESSAGE_ENDPOINT: Final = r\"_stcore/message\"\nNEW_HEALTH_ENDPOINT: Final = \"_stcore/health\"\nHEALTH_ENDPOINT: Final = rf\"(?:healthz|{NEW_HEALTH_ENDPOINT})\"\nHOST_CONFIG_ENDPOINT: Final = r\"_stcore/host-config\"\nSCRIPT_HEALTH_CHECK_ENDPOINT: Final = (\n    r\"(?:script-health-check|_stcore/script-health-check)\"\n)\n\n\nclass RetriesExceeded(Exception):\n    pass\n\n\ndef server_port_is_manually_set() -> bool:\n    return config.is_manually_set(\"server.port\")\n\n\ndef server_address_is_unix_socket() -> bool:\n    address = config.get_option(\"server.address\")\n    return address is not None and address.startswith(UNIX_SOCKET_PREFIX)\n\n\ndef start_listening(app: tornado.web.Application) -> None:\n    \"\"\"Makes the server start listening at the configured port.\n\n    In case the port is already taken it tries listening to the next available\n    port.  It will error after MAX_PORT_SEARCH_RETRIES attempts.\n\n    \"\"\"\n    cert_file = config.get_option(\"server.sslCertFile\")\n    key_file = config.get_option(\"server.sslKeyFile\")\n    ssl_options = _get_ssl_options(cert_file, key_file)\n\n    http_server = HTTPServer(\n        app,\n        max_buffer_size=config.get_option(\"server.maxUploadSize\") * 1024 * 1024,\n        ssl_options=ssl_options,\n    )\n\n    if server_address_is_unix_socket():\n        start_listening_unix_socket(http_server)\n    else:\n        start_listening_tcp_socket(http_server)\n\n\ndef _get_ssl_options(cert_file: str | None, key_file: str | None) -> SSLContext | None:\n    if bool(cert_file) != bool(key_file):\n        _LOGGER.error(\n            \"Options 'server.sslCertFile' and 'server.sslKeyFile' must \"\n            \"be set together. Set missing options or delete existing options.\"\n        )\n        sys.exit(1)\n    if cert_file and key_file:\n        # ssl_ctx.load_cert_chain raise exception as below, but it is not\n        # sufficiently user-friendly\n        # FileNotFoundError: [Errno 2] No such file or directory\n        if not Path(cert_file).exists():\n            _LOGGER.error(\"Cert file '%s' does not exist.\", cert_file)\n            sys.exit(1)\n        if not Path(key_file).exists():\n            _LOGGER.error(\"Key file '%s' does not exist.\", key_file)\n            sys.exit(1)\n\n        import ssl\n\n        ssl_ctx = ssl.create_default_context(ssl.Purpose.CLIENT_AUTH)\n        # When the SSL certificate fails to load, an exception is raised as below,\n        # but it is not sufficiently user-friendly.\n        # ssl.SSLError: [SSL] PEM lib (_ssl.c:4067)\n        try:\n            ssl_ctx.load_cert_chain(cert_file, key_file)\n        except ssl.SSLError:\n            _LOGGER.error(\n                \"Failed to load SSL certificate. Make sure \"\n                \"cert file '%s' and key file '%s' are correct.\",\n                cert_file,\n                key_file,\n            )\n            sys.exit(1)\n\n        return ssl_ctx\n    return None\n\n\ndef start_listening_unix_socket(http_server: HTTPServer) -> None:\n    address = config.get_option(\"server.address\")\n    file_name = os.path.expanduser(address[len(UNIX_SOCKET_PREFIX) :])\n\n    unix_socket = tornado.netutil.bind_unix_socket(file_name)\n    http_server.add_socket(unix_socket)\n\n\ndef start_listening_tcp_socket(http_server: HTTPServer) -> None:\n    call_count = 0\n\n    port = None\n    while call_count < MAX_PORT_SEARCH_RETRIES:\n        address = config.get_option(\"server.address\")\n        port = config.get_option(\"server.port\")\n\n        if int(port) == DEVELOPMENT_PORT:\n            _LOGGER.warning(\n                \"Port %s is reserved for internal development. \"\n                \"It is strongly recommended to select an alternative port \"\n                \"for `server.port`.\",\n                DEVELOPMENT_PORT,\n            )\n\n        try:\n            http_server.listen(port, address)\n            break  # It worked! So let's break out of the loop.\n\n        except OSError as e:\n            if e.errno == errno.EADDRINUSE:\n                if server_port_is_manually_set():\n                    _LOGGER.error(\"Port %s is already in use\", port)\n                    sys.exit(1)\n                else:\n                    _LOGGER.debug(\n                        \"Port %s already in use, trying to use the next one.\", port\n                    )\n                    port += 1\n                    # Don't use the development port here:\n                    if port == DEVELOPMENT_PORT:\n                        port += 1\n\n                    config.set_option(\n                        \"server.port\", port, ConfigOption.STREAMLIT_DEFINITION\n                    )\n                    call_count += 1\n            else:\n                raise\n\n    if call_count >= MAX_PORT_SEARCH_RETRIES:\n        raise RetriesExceeded(\n            f\"Cannot start Streamlit server. Port {port} is already in use, and \"\n            f\"Streamlit was unable to find a free port after {MAX_PORT_SEARCH_RETRIES} attempts.\",\n        )\n\n\nclass Server:\n    def __init__(self, main_script_path: str, is_hello: bool):\n        \"\"\"Create the server. It won't be started yet.\"\"\"\n        _set_tornado_log_levels()\n\n        self._main_script_path = main_script_path\n\n        # Initialize MediaFileStorage and its associated endpoint\n        media_file_storage = MemoryMediaFileStorage(MEDIA_ENDPOINT)\n        MediaFileHandler.initialize_storage(media_file_storage)\n\n        uploaded_file_mgr = MemoryUploadedFileManager(UPLOAD_FILE_ENDPOINT)\n\n        self._runtime = Runtime(\n            RuntimeConfig(\n                script_path=main_script_path,\n                command_line=None,\n                media_file_storage=media_file_storage,\n                uploaded_file_manager=uploaded_file_mgr,\n                cache_storage_manager=create_default_cache_storage_manager(),\n                is_hello=is_hello,\n            ),\n        )\n\n        self._runtime.stats_mgr.register_provider(media_file_storage)\n\n    def __repr__(self) -> str:\n        return util.repr_(self)\n\n    @property\n    def main_script_path(self) -> str:\n        return self._main_script_path\n\n    async def start(self) -> None:\n        \"\"\"Start the server.\n\n        When this returns, Streamlit is ready to accept new sessions.\n        \"\"\"\n\n        _LOGGER.debug(\"Starting server...\")\n\n        app = self._create_app()\n        start_listening(app)\n\n        port = config.get_option(\"server.port\")\n        _LOGGER.debug(\"Server started on port %s\", port)\n\n        await self._runtime.start()\n\n    @property\n    def stopped(self) -> Awaitable[None]:\n        \"\"\"A Future that completes when the Server's run loop has exited.\"\"\"\n        return self._runtime.stopped\n\n    def _create_app(self) -> tornado.web.Application:\n        \"\"\"Create our tornado web app.\"\"\"\n        base = config.get_option(\"server.baseUrlPath\")\n\n        routes: list[Any] = [\n            (\n                make_url_path_regex(base, STREAM_ENDPOINT),\n                BrowserWebSocketHandler,\n                {\"runtime\": self._runtime},\n            ),\n            (\n                make_url_path_regex(base, HEALTH_ENDPOINT),\n                HealthHandler,\n                {\"callback\": lambda: self._runtime.is_ready_for_browser_connection},\n            ),\n            (\n                make_url_path_regex(base, MESSAGE_ENDPOINT),\n                MessageCacheHandler,\n                {\"cache\": self._runtime.message_cache},\n            ),\n            (\n                make_url_path_regex(base, METRIC_ENDPOINT),\n                StatsRequestHandler,\n                {\"stats_manager\": self._runtime.stats_mgr},\n            ),\n            (\n                make_url_path_regex(base, HOST_CONFIG_ENDPOINT),\n                HostConfigHandler,\n            ),\n            (\n                make_url_path_regex(\n                    base,\n                    rf\"{UPLOAD_FILE_ENDPOINT}/(?P<session_id>[^/]+)/(?P<file_id>[^/]+)\",\n                ),\n                UploadFileRequestHandler,\n                {\n                    \"file_mgr\": self._runtime.uploaded_file_mgr,\n                    \"is_active_session\": self._runtime.is_active_session,\n                },\n            ),\n            (\n                make_url_path_regex(base, f\"{MEDIA_ENDPOINT}/(.*)\"),\n                MediaFileHandler,\n                {\"path\": \"\"},\n            ),\n            (\n                make_url_path_regex(base, \"component/(.*)\"),\n                ComponentRequestHandler,\n                {\"registry\": self._runtime.component_registry},\n            ),\n        ]\n\n        if config.get_option(\"server.scriptHealthCheckEnabled\"):\n            routes.extend(\n                [\n                    (\n                        make_url_path_regex(base, SCRIPT_HEALTH_CHECK_ENDPOINT),\n                        HealthHandler,\n                        {\n                            \"callback\": lambda: self._runtime.does_script_run_without_error()\n                        },\n                    )\n                ]\n            )\n\n        if config.get_option(\"server.enableStaticServing\"):\n            routes.extend(\n                [\n                    (\n                        make_url_path_regex(base, \"app/static/(.*)\"),\n                        AppStaticFileHandler,\n                        {\"path\": file_util.get_app_static_dir(self.main_script_path)},\n                    ),\n                ]\n            )\n\n        if config.get_option(\"global.developmentMode\"):\n            _LOGGER.debug(\"Serving static content from the Node dev server\")\n        else:\n            static_path = file_util.get_static_dir()\n            _LOGGER.debug(\"Serving static content from %s\", static_path)\n\n            routes.extend(\n                [\n                    (\n                        make_url_path_regex(base, \"(.*)\"),\n                        StaticFileHandler,\n                        {\n                            \"path\": \"%s/\" % static_path,\n                            \"default_filename\": \"index.html\",\n                            \"reserved_paths\": [\n                                # These paths are required for identifying\n                                # the base url path.\n                                NEW_HEALTH_ENDPOINT,\n                                HOST_CONFIG_ENDPOINT,\n                            ],\n                        },\n                    ),\n                    (make_url_path_regex(base, trailing_slash=False), AddSlashHandler),\n                ]\n            )\n\n        return tornado.web.Application(\n            routes,\n            cookie_secret=config.get_option(\"server.cookieSecret\"),\n            xsrf_cookies=config.get_option(\"server.enableXsrfProtection\"),\n            # Set the websocket message size. The default value is too low.\n            websocket_max_message_size=get_max_message_size_bytes(),\n            **TORNADO_SETTINGS,  # type: ignore[arg-type]\n        )\n\n    @property\n    def browser_is_connected(self) -> bool:\n        return self._runtime.state == RuntimeState.ONE_OR_MORE_SESSIONS_CONNECTED\n\n    @property\n    def is_running_hello(self) -> bool:\n        from streamlit.hello import streamlit_app\n\n        return self._main_script_path == streamlit_app.__file__\n\n    def stop(self) -> None:\n        cli_util.print_to_cli(\"  Stopping...\", fg=\"blue\")\n        self._runtime.stop()\n\n\ndef _set_tornado_log_levels() -> None:\n    if not config.get_option(\"global.developmentMode\"):\n        # Hide logs unless they're super important.\n        # Example of stuff we don't care about: 404 about .js.map files.\n        logging.getLogger(\"tornado.access\").setLevel(logging.ERROR)\n        logging.getLogger(\"tornado.application\").setLevel(logging.ERROR)\n        logging.getLogger(\"tornado.general\").setLevel(logging.ERROR)\n", "lib/streamlit/navigation/page.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport types\nfrom pathlib import Path\nfrom typing import Callable\n\nfrom streamlit.errors import StreamlitAPIException\nfrom streamlit.runtime.metrics_util import gather_metrics\nfrom streamlit.runtime.scriptrunner.script_run_context import get_script_run_ctx\nfrom streamlit.source_util import page_icon_and_name\nfrom streamlit.string_util import validate_icon_or_emoji\nfrom streamlit.util import calc_md5\n\n\n@gather_metrics(\"Page\")\ndef Page(\n    page: str | Path | Callable[[], None],\n    *,\n    title: str | None = None,\n    icon: str | None = None,\n    url_path: str | None = None,\n    default: bool = False,\n):\n    \"\"\"Configure a page for\u00a0``st.navigation`` in a multipage app.\n\n    Call ``st.Page`` to initialize a ``StreamlitPage`` object, and pass it to\n    ``st.navigation`` to declare a page in your app.\n\n    When a user navigates to a page, ``st.navigation`` returns the selected\n    ``StreamlitPage`` object. Call ``StreamlitPage.run()`` on the returned page\n    to execute the page. You can only run the page returned by\n    ``st.navigation``, and you can only run it once per app rerun.\n\n    A page can be defined by a Python file or ``Callable``.\n\n    Parameters\n    ----------\n\n    page: str, Path, or callable\n        The page source as a ``Callable`` or path to a Python file. If the page\n        source is defined by a Python file, the path can be a string or\n        ``pathlib.Path`` object, but must be declared relative to the\n        entrypoint file. If the page source is defined by a ``Callable``, the\n        ``Callable`` can't accept arguments.\n\n    title: str or None\n        The title of the page. If this is ``None`` (default), the page title\n        (in the browser tab) and label (in the navigation menu) will be\n        inferred from the filename or callable name in ``page``. For more\n        information, see `Overview of multipage apps\n        <https://docs.streamlit.io/st.page.automatic-page-labels>`_.\n\n    icon: str or None\n        An optional emoji or icon to display next to the page title and label.\n        If ``icon`` is ``None`` (default), no icon is displayed next to the\n        page label in the navigation menu, and a Streamlit icon is displayed\n        next to the title (in the browser tab). If ``icon`` is a string, the\n        following options are valid:\n\n        * A single-character emoji. For example, you can set ``icon=\"\ud83d\udea8\"``\n            or ``icon=\"\ud83d\udd25\"``. Emoji short codes are not supported.\n\n        * An icon from the Material Symbols library (outlined style) in the\n            format ``\":material/icon_name:\"`` where \"icon_name\" is the name\n            of the icon in snake case.\n\n            For example, ``icon=\":material/thumb_up:\"`` will display the\n            Thumb Up icon. Find additional icons in the `Material Symbols \\\n            <https://fonts.google.com/icons?icon.set=Material+Symbols&icon.style=Outlined>`_\n            font library.\n\n    url_path: str or None\n        The page's URL pathname, which is the path relative to the app's root\n        URL. If this is ``None`` (default), the URL pathname will be inferred\n        from the filename or callable name in ``page``. For more information,\n        see `Overview of multipage apps\n        <https://docs.streamlit.io/st.page.automatic-page-urls>`_.\n\n        The default page will have a pathname of ``\"\"``, indicating the root\n        URL of the app. If you set ``default=True``, ``url_path`` is ignored.\n\n    default: bool\n        Whether this page is the default page to be shown when the app is\n        loaded. If ``default`` is ``False`` (default), the page will have a\n        nonempty URL pathname. However, if no default page is passed to\n        ``st.navigation`` and this is the first page, this page will become the\n        default page. If ``default`` is ``True``, then the page will have\n        an empty pathname and ``url_path`` will be ignored.\n\n    Returns\n    -------\n    StreamlitPage\n        The page object associated to the given script.\n\n    Example\n    -------\n    >>> import streamlit as st\n    >>>\n    >>> def page2():\n    >>>     st.title(\"Second page\")\n    >>>\n    >>> pg = st.navigation([\n    >>>\t    st.Page(\"page1.py\", title=\"First page\", icon=\"\ud83d\udd25\"),\n    >>>\t    st.Page(page2, title=\"Second page\", icon=\":material/favorite:\"),\n    >>> ])\n    >>> pg.run()\n    \"\"\"\n    return StreamlitPage(\n        page, title=title, icon=icon, url_path=url_path, default=default\n    )\n\n\nclass StreamlitPage:\n    \"\"\"A page within a multipage Streamlit app.\n\n    Use ``st.Page`` to initialize a ``StreamlitPage`` object.\n\n    Attributes\n    ----------\n    icon : str\n        The icon of the page.\n\n        If no icon was declared in ``st.Page``, this property returns ``\"\"``.\n\n    title : str\n        The title of the page.\n\n        Unless declared otherwise in ``st.Page``, the page title is inferred\n        from the filename or callable name. For more information, see\n        `Overview of multipage apps\n        <https://docs.streamlit.io/st.page.automatic-page-labels>`_.\n\n    url_path : str\n        The page's URL pathname, which is the path relative to the app's root\n        URL.\n\n        Unless declared otherwise in ``st.Page``, the URL pathname is inferred\n        from the filename or callable name. For more information, see\n        `Overview of multipage apps\n        <https://docs.streamlit.io/st.page.automatic-page-urls>`_.\n\n        The default page will always have a ``url_path`` of ``\"\"`` to indicate\n        the root URL (e.g. homepage).\n\n    \"\"\"\n\n    def __init__(\n        self,\n        page: str | Path | Callable[[], None],\n        *,\n        title: str | None = None,\n        icon: str | None = None,\n        url_path: str | None = None,\n        default: bool = False,\n    ):\n        ctx = get_script_run_ctx()\n        if not ctx:\n            return\n\n        main_path = Path(ctx.pages_manager.main_script_path).parent\n        if isinstance(page, str):\n            page = Path(page)\n        if isinstance(page, Path):\n            page = (main_path / page).resolve()\n\n            if not page.is_file():\n                raise StreamlitAPIException(\n                    f\"Unable to create Page. The file `{page.name}` could not be found.\"\n                )\n\n        inferred_name = \"\"\n        inferred_icon = \"\"\n        if isinstance(page, Path):\n            inferred_icon, inferred_name = page_icon_and_name(page)\n        elif hasattr(page, \"__name__\"):\n            inferred_name = str(page.__name__)\n        elif title is None:\n            # At this point, we know the page is not a string or a path, so it\n            # must be a callable. We expect it to have a __name__ attribute,\n            # but in special cases (e.g. a callable class instance), one may\n            # not exist. In that case, we should inform the user the title is\n            # mandatory.\n            raise StreamlitAPIException(\n                \"Cannot infer page title for Callable. Set the `title=` keyword argument.\"\n            )\n\n        self._page: Path | Callable[[], None] = page\n        self._title: str = title or inferred_name.replace(\"_\", \" \")\n        self._icon: str = icon or inferred_icon\n        if url_path is not None and url_path.strip() == \"\" and not default:\n            raise StreamlitAPIException(\n                \"The URL path cannot be an empty string unless the page is the default page.\"\n            )\n\n        self._url_path: str = inferred_name\n        if url_path is not None:\n            self._url_path = url_path.lstrip(\"/\")\n\n        if self._icon:\n            validate_icon_or_emoji(self._icon)\n\n        self._default: bool = default\n        # used by st.navigation to ordain a page as runnable\n        self._can_be_called: bool = False\n\n    @property\n    def title(self) -> str:\n        \"\"\"The title of the page.\n\n        Unless declared otherwise in ``st.Page``, the page title is inferred\n        from the filename or callable name. For more information, see\n        `Overview of multipage apps\n        <https://docs.streamlit.io/st.page.automatic-page-labels>`_.\n        \"\"\"\n        return self._title\n\n    @property\n    def icon(self) -> str:\n        \"\"\"The icon of the page.\n\n        If no icon was declared in ``st.Page``, this property returns ``\"\"``.\n        \"\"\"\n        return self._icon\n\n    @property\n    def url_path(self) -> str:\n        \"\"\"The page's URL pathname, which is the path relative to the app's \\\n        root URL.\n\n        Unless declared otherwise in ``st.Page``, the URL pathname is inferred\n        from the filename or callable name. For more information, see\n        `Overview of multipage apps\n        <https://docs.streamlit.io/st.page.automatic-page-urls>`_.\n\n        The default page will always have a ``url_path`` of ``\"\"`` to indicate\n        the root URL (e.g. homepage).\n        \"\"\"\n        return \"\" if self._default else self._url_path\n\n    def run(self) -> None:\n        \"\"\"Execute the page.\n\n        When a page is returned by ``st.navigation``, use the ``.run()`` method\n        within your entrypoint file to render the page. You can only call this\n        method on the page returned by ``st.navigation``. You can only call\n        this method once per run of your entrypoint file.\n\n        \"\"\"\n        if not self._can_be_called:\n            raise StreamlitAPIException(\n                \"This page cannot be called directly. Only the page returned from st.navigation can be called once.\"\n            )\n\n        self._can_be_called = False\n\n        ctx = get_script_run_ctx()\n        if not ctx:\n            return\n\n        with ctx.pages_manager.run_with_active_hash(self._script_hash):\n            if callable(self._page):\n                self._page()\n                return\n            else:\n                code = ctx.pages_manager.get_page_script_byte_code(str(self._page))\n\n                # We create a module named __page__ for this specific\n                # script. This is differentiate it from the `__main__` module\n                module = types.ModuleType(\"__page__\")\n                # We want __file__ to be the path to the script\n                module.__dict__[\"__file__\"] = self._page\n                exec(code, module.__dict__)\n\n    @property\n    def _script_hash(self) -> str:\n        return calc_md5(self._url_path)\n", "lib/streamlit/navigation/__init__.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n", "lib/streamlit/vendor/__init__.py": "", "lib/streamlit/vendor/pympler/asizeof.py": "# mypy: ignore-errors\n\n\"\"\"\nThis is a stripped-down of asizeof.py from the pympler module. It's vendored\nbecause pympler is unmaintained, while having a critical vulnerability.\n\nDifferences from the original asizeof module:\n- Removed code for running as __main__\n- Removed `adict`\n- `__all__` only includes `asizeof`\n\nThe *original* original copyright, license and disclaimer are at the end of this\nfile, exactly as they appeared in the pympler code. pympler itself is under the\nApache license, which appears in the project root.\n\nThe original module docstring that appears in pympler follows; note that some of\nit no longer pertains here, but it's preserved to document implementation\ndetails.\n\"\"\"\n\n\"\"\"\n**Public Functions** [#unsafe]_\n\n   Function **asizesof** returns a tuple containing the (approximate)\n   size in bytes for each given Python object separately.\n\n   Function **asized** returns for each object an instance of class\n   **Asized** containing all the size information of the object and\n   a tuple with the referents [#refs]_.\n\n   Functions **basicsize** and **itemsize** return the *basic-*\n   respectively *itemsize* of the given object, both in bytes.  For\n   objects as ``array.array``, ``numpy.array``, ``numpy.ndarray``,\n   etc. where the item size varies depending on the instance-specific\n   data type, function **itemsize** returns that item size.\n\n   Function **flatsize** returns the *flat size* of a Python object\n   in bytes defined as the *basic size* plus the *item size* times\n   the *length* of the given object.\n\n   Function **leng** returns the *length* of an object, like standard\n   function ``len`` but extended for several types.  E.g. the **leng**\n   of a multi-precision int (formerly long) is the number of ``digits``\n   [#digit]_.  The length of most *mutable* sequence objects includes\n   an estimate of the over-allocation and therefore, the **leng** value\n   may differ from the standard ``len`` result.  For objects like\n   ``array.array``, ``numpy.array``, ``numpy.ndarray``, etc. function\n   **leng** returns the proper number of items.\n\n   Function **refs** returns (a generator for) the referents [#refs]_\n   of the given object.\n\n**Public Classes** [#unsafe]_\n\n   Class **Asizer** may be used to accumulate the results of several\n   **asizeof** or **asizesof** calls.  After creating an **Asizer**\n   instance, use methods **asizeof** and **asizesof** as needed to\n   size any number of additional objects.\n\n   Call methods **exclude_refs** and/or **exclude_types** to exclude\n   references to respectively instances or types of certain objects.\n\n   Use one of the **print\\\\_...** methods to report the statistics.\n\n   An instance of class **Asized** is returned for each object sized\n   by the **asized** function or method.\n\n**Duplicate Objects**\n\n   Any duplicate, given objects are sized only once and the size\n   is included in the accumulated total only once.  But functions\n   **asizesof** and **asized** will return a size value respectively\n   an **Asized** instance for each given object, including duplicates.\n\n**Definitions** [#arb]_\n\n   The *length* of an objects like ``dict``, ``list``, ``set``,\n   ``str``, ``tuple``, etc. is defined as the number of items held\n   in or allocated by the object.  Held items are *references* to\n   other objects, called the *referents*.\n\n   The *size* of an object is defined as the sum of the *flat size*\n   of the object plus the sizes of any referents [#refs]_.  Referents\n   are visited recursively up to the specified detail level.  However,\n   the size of objects referenced multiple times is included only once\n   in the total *size*.\n\n   The *flat size* of an object is defined as the *basic size* of the\n   object plus the *item size* times the number of allocated *items*,\n   *references* to referents.  The *flat size* does include the size\n   for the *references* to the referents, but not the size of the\n   referents themselves.\n\n   The *flat size* returned by function *flatsize* equals the result\n   of function *asizeof* with options *code=True*, *ignored=False*,\n   *limit=0* and option *align* set to the same value.\n\n   The accurate *flat size* for an object is obtained from function\n   ``sys.getsizeof()`` where available.  Otherwise, the *length* and\n   *size* of sequence objects as ``dicts``, ``lists``, ``sets``, etc.\n   is based on an estimate for the number of allocated items.  As a\n   result, the reported *length* and *size* may differ substantially\n   from the actual *length* and *size*.\n\n   The *basic* and *item size* are obtained from the ``__basicsize__``\n   respectively ``__itemsize__`` attributes of the (type of the)\n   object.  Where necessary (e.g. sequence objects), a zero\n   ``__itemsize__`` is replaced by the size of a corresponding C type.\n\n   The overhead for Python's garbage collector (GC) is included in\n   the *basic size* of (GC managed) objects as well as the space\n   needed for ``refcounts`` (used only in certain Python builds).\n\n   Optionally, size values can be aligned to any power-of-2 multiple.\n\n**Size of (byte)code**\n\n   The *(byte)code size* of objects like classes, functions, methods,\n   modules, etc. can be included by setting option *code=True*.\n\n   Iterators are handled like sequences: iterated object(s) are sized\n   like *referents* [#refs]_, but only up to the specified level or\n   recursion *limit* (and only if function ``gc.get_referents()``\n   returns the referent object of iterators).\n\n   Generators are sized as *(byte)code* only, but the objects are\n   never generated and never sized.\n\n**New-style Classes**\n\n   All ``class``, instance and ``type`` objects are handled uniformly\n   such that instance objects are distinguished from class objects.\n\n   Class and type objects are represented as ``<class .... def>``\n   respectively ``<type ... def>`` where the ``... def`` suffix marks\n   the *definition object*.  Instances of  classes are shown as\n   ``<class module.name>`` without the ``... def`` suffix.\n\n**Ignored Objects**\n\n   To avoid excessive sizes, several object types are ignored [#arb]_\n   by default, e.g. built-in functions, built-in types and classes\n   [#bi]_, function globals and module referents.  However, any\n   instances thereof and module objects will be sized when passed as\n   given objects.  Ignored object types are included unless option\n   *ignored* is set accordingly.\n\n   In addition, many ``__...__`` attributes of callable objects are\n   ignored [#arb]_, except crucial ones, e.g. class attributes ``__dict__``,\n   ``__doc__``, ``__name__`` and ``__slots__``.  For more details, see\n   the type-specific ``_..._refs()`` and ``_len_...()`` functions below.\n\n.. rubric:: Footnotes\n.. [#unsafe] The functions and classes in this module are not thread-safe.\n\n.. [#refs] The *referents* of an object are the objects referenced *by*\n     that object.  For example, the *referents* of a ``list`` are the\n     objects held in the ``list``, the *referents* of a ``dict`` are\n     the key and value objects in the ``dict``, etc.\n\n.. [#arb] These definitions and other assumptions are rather arbitrary\n     and may need corrections or adjustments.\n\n.. [#digit] The C ``sizeof(digit)`` in bytes can be obtained from the\n     ``int.__itemsize__``  attribute or since Python 3.1+  also from\n     attribute ``sys.int_info.sizeof_digit``.  Function **leng**\n     determines the number of ``digits`` of a multi-precision int.\n\n.. [#bi] All ``type``s and ``class``es in modules named in private set\n     ``_ignored_modules`` are ignored like other, standard built-ins.\n\"\"\"\n\nimport sys\nimport types as Types\nimport warnings\nimport weakref as Weakref\nfrom inspect import isbuiltin, isclass, iscode, isframe, isfunction, ismethod, ismodule\nfrom math import log\nfrom os import curdir, linesep\nfrom struct import calcsize\n\n__all__ = [\"asizeof\"]\n__version__ = \"22.06.30\"\n\n_NN = \"\"\n_Not_vari = _NN  # non-variable item size\n\n# Any classes and types in modules named in set _ignored_modules\n# are ignored by default, like other built-ins classes and types\n_ignored_modules = {\n    int.__module__,\n    \"types\",\n    Exception.__module__,  # 'weakref'\n    __name__,\n}  # inluding this very module\n\n# Sizes of some primitive C types\n# XXX len(pack(T, 0)) == Struct(T).size == calcsize(T)\n_sizeof_Cbyte = calcsize(\"c\")  # sizeof(unsigned char)\n_sizeof_Clong = calcsize(\"l\")  # sizeof(long)\n_sizeof_Cvoidp = calcsize(\"P\")  # sizeof(void*)\n\n# sizeof(long) != sizeof(ssize_t) on LLP64\n_z_P_L = \"P\" if _sizeof_Clong < _sizeof_Cvoidp else \"L\"\n\n\ndef _calcsize(fmt):\n    \"\"\"Like struct.calcsize() but with 'z' for Py_ssize_t.\"\"\"\n    return calcsize(fmt.replace(\"z\", _z_P_L))\n\n\n# Defaults for some basic sizes with 'z' for C Py_ssize_t\n_sizeof_CPyCodeObject = _calcsize(\"Pz10P5i0P\")  # sizeof(PyCodeObject)\n_sizeof_CPyFrameObject = _calcsize(\"Pzz13P63i0P\")  # sizeof(PyFrameObject)\n_sizeof_CPyModuleObject = _calcsize(\"PzP0P\")  # sizeof(PyModuleObject)\n\n# Defaults for some item sizes with 'z' for C Py_ssize_t\n_sizeof_CPyDictEntry = _calcsize(\"z2P\")  # sizeof(PyDictEntry)\n_sizeof_Csetentry = _calcsize(\"lP\")  # sizeof(setentry)\n\n# Get character size for internal unicode representation in Python < 3.3\nu = \"\\0\".encode(\"utf-8\")\n_sizeof_Cunicode = len(u)\ndel u\n\ntry:  # Size of GC header, sizeof(PyGC_Head)\n    import _testcapi as t\n\n    _sizeof_CPyGC_Head = t.SIZEOF_PYGC_HEAD  # new in Python 2.6\nexcept (ImportError, AttributeError):  # sizeof(PyGC_Head)\n    # alignment should be to sizeof(long double) but there\n    # is no way to obtain that value, assume twice double\n    t = calcsize(\"2d\") - 1\n    _sizeof_CPyGC_Head = (_calcsize(\"2Pz\") + t) & ~t\n\n# Size of refcounts (Python debug build only)\nt = hasattr(sys, \"gettotalrefcount\")\n_sizeof_Crefcounts = _calcsize(\"2z\") if t else 0\ndel t\n\n# Some flags from .../Include/object.h\n_Py_TPFLAGS_HEAPTYPE = 1 << 9  # Py_TPFLAGS_HEAPTYPE\n_Py_TPFLAGS_HAVE_GC = 1 << 14  # Py_TPFLAGS_HAVE_GC\n\n_Type_type = type(type)  # == type and (new-style) class type\n\nfrom gc import get_objects as _getobjects\nfrom gc import get_referents as _getreferents  # containers only?\n\nif sys.platform == \"ios\":  # Apple iOS\n    _gc_getobjects = _getobjects\n\n    def _getobjects():  # PYCHOK expected\n        # avoid Pythonista3/Python 3+ crash\n        return tuple(o for o in _gc_getobjects() if not _isNULL(o))\n\n\n_getsizeof = sys.getsizeof  # sys.getsizeof() new in Python 2.6\n\n\n# Compatibility functions for more uniform\n# behavior across Python version 2.2 thu 3+\n\n\ndef _items(obj):  # dict only\n    \"\"\"Return iter-/generator, preferably.\"\"\"\n    o = getattr(obj, \"iteritems\", obj.items)\n    return o() if callable(o) else (o or ())\n\n\ndef _keys(obj):  # dict only\n    \"\"\"Return iter-/generator, preferably.\"\"\"\n    o = getattr(obj, \"iterkeys\", obj.keys)\n    return o() if callable(o) else (o or ())\n\n\ndef _values(obj):  # dict only\n    \"\"\"Return iter-/generator, preferably.\"\"\"\n    o = getattr(obj, \"itervalues\", obj.values)\n    return o() if callable(o) else (o or ())\n\n\n# 'cell' is holding data used in closures\nc = (lambda unused: (lambda: unused))(None)\n_cell_type = type(c.__closure__[0])  # type: ignore\ndel c\n\n\n# Private functions\n\n\ndef _basicsize(t, base=0, heap=False, obj=None):\n    \"\"\"Get non-zero basicsize of type,\n    including the header sizes.\n    \"\"\"\n    s = max(getattr(t, \"__basicsize__\", 0), base)\n    # include gc header size\n    if t != _Type_type:\n        h = getattr(t, \"__flags__\", 0) & _Py_TPFLAGS_HAVE_GC\n    elif heap:  # type, allocated on heap\n        h = True\n    else:  # None has no __flags__ attr\n        h = getattr(obj, \"__flags__\", 0) & _Py_TPFLAGS_HEAPTYPE\n    if h:\n        s += _sizeof_CPyGC_Head\n    # include reference counters\n    return s + _sizeof_Crefcounts\n\n\ndef _classof(obj, dflt=None):\n    \"\"\"Return the object's class object.\"\"\"\n    return getattr(obj, \"__class__\", dflt)\n\n\ndef _derive_typedef(typ):\n    \"\"\"Return single, existing super type typedef or None.\"\"\"\n    v = [v for v in _values(_typedefs) if _issubclass(typ, v.type)]\n    return v[0] if len(v) == 1 else None\n\n\ndef _dir2(obj, pref=_NN, excl=(), slots=None, itor=_NN):\n    \"\"\"Return an attribute name, object 2-tuple for certain\n    attributes or for the ``__slots__`` attributes of the\n    given object, but not both.  Any iterator referent\n    objects are returned with the given name if the\n    latter is non-empty.\n    \"\"\"\n    if slots:  # __slots__ attrs\n        if hasattr(obj, slots):\n            # collect all inherited __slots__ attrs\n            # from list, tuple, or dict __slots__,\n            # while removing any duplicate attrs\n            s = {}\n            for c in type(obj).mro():\n                n = _nameof(c)\n                for a in getattr(c, slots, ()):\n                    if a.startswith(\"__\"):\n                        a = \"_\" + n + a\n                    if hasattr(obj, a):\n                        s.setdefault(a, getattr(obj, a))\n            # assume __slots__ tuple-like is holding the values\n            # yield slots, _Slots(s)  # _keys(s) ... REMOVED,\n            # see _Slots.__doc__ further below\n            for t in _items(s):\n                yield t  # attr name, value\n    elif itor:  # iterator referents\n        for o in obj:  # iter(obj)\n            yield itor, o\n    else:  # regular attrs\n        for a in dir(obj):\n            if a.startswith(pref) and hasattr(obj, a) and a not in excl:\n                yield a, getattr(obj, a)\n\n\ndef _infer_dict(obj):\n    \"\"\"Return True for likely dict object via duck typing.\"\"\"\n    for attrs in ((\"items\", \"keys\", \"values\"), (\"iteritems\", \"iterkeys\", \"itervalues\")):\n        attrs += \"__len__\", \"get\", \"has_key\"  # 'update'\n        if all(callable(getattr(obj, a, None)) for a in attrs):\n            return True\n    return False\n\n\ndef _isbuiltin2(typ):\n    \"\"\"Return True for built-in types as in Python 2.\"\"\"\n    # range is no longer a built-in in Python 3+\n    return isbuiltin(typ) or (typ is range)\n\n\ndef _iscell(obj):\n    \"\"\"Return True if obj is a cell as used in a closure.\"\"\"\n    return isinstance(obj, _cell_type)\n\n\ndef _isdictype(obj):\n    \"\"\"Return True for known dict objects.\"\"\"\n    c = _classof(obj)\n    n = _nameof(c)\n    return n and n in _dict_types.get(_moduleof(c), ())\n\n\ndef _isframe(obj):\n    \"\"\"Return True for a stack frame object.\"\"\"\n    try:\n        return isframe(obj)\n    except ReferenceError:\n        return False\n\n\ndef _isignored(typ):\n    \"\"\"Is this a type or class to be ignored?\"\"\"\n    return _moduleof(typ) in _ignored_modules\n\n\ndef _isnamedtuple(obj):\n    \"\"\"Named tuples are identified via duck typing:\n    <http://www.Gossamer-Threads.com/lists/python/dev/1142178>\n    \"\"\"\n    return isinstance(obj, tuple) and hasattr(obj, \"_fields\")\n\n\ndef _isNULL(obj):\n    \"\"\"Prevent asizeof(all=True, ...) crash.\n\n    Sizing gc.get_objects() crashes in Pythonista3 with\n    Python 3.5.1 on iOS due to 1-tuple (<Null>,) object,\n    see <http://forum.omz-software.com/user/mrjean1>.\n    \"\"\"\n    return isinstance(obj, tuple) and len(obj) == 1 and repr(obj) == \"(<NULL>,)\"\n\n\ndef _issubclass(obj, Super):\n    \"\"\"Safe inspect.issubclass() returning None if Super is\n    *object* or if obj and Super are not a class or type.\n    \"\"\"\n    if Super is not object:\n        try:\n            return issubclass(obj, Super)\n        except TypeError:\n            pass\n    return None\n\n\ndef _itemsize(t, item=0):\n    \"\"\"Get non-zero itemsize of type.\"\"\"\n    # replace zero value with default\n    return getattr(t, \"__itemsize__\", 0) or item\n\n\ndef _kwdstr(**kwds):\n    \"\"\"Keyword arguments as a string.\"\"\"\n    return \", \".join(sorted(\"%s=%r\" % kv for kv in _items(kwds)))\n\n\ndef _lengstr(obj):\n    \"\"\"Object length as a string.\"\"\"\n    n = leng(obj)\n    if n is None:  # no len\n        r = _NN\n    else:\n        x = \"!\" if n > _len(obj) else _NN  # extended\n        r = \" leng %d%s\" % (n, x)\n    return r\n\n\ndef _moduleof(obj, dflt=_NN):\n    \"\"\"Return the object's module name.\"\"\"\n    return getattr(obj, \"__module__\", dflt)\n\n\ndef _nameof(obj, dflt=_NN):\n    \"\"\"Return the name of an object.\"\"\"\n    return getattr(obj, \"__name__\", dflt)\n\n\ndef _objs_opts_x(where, objs, all=None, **opts):\n    \"\"\"Return the given or 'all' objects plus\n    the remaining options and exclude flag\n    \"\"\"\n    if objs:  # given objects\n        t, x = objs, False\n    elif all in (False, None):\n        t, x = (), True\n    elif all is True:  # 'all' objects\n        t, x = _getobjects(), True\n    else:\n        raise _OptionError(where, all=all)\n    return t, opts, x\n\n\ndef _OptionError(where, Error=ValueError, **options):\n    \"\"\"Format an *Error* instance for invalid *option* or *options*.\"\"\"\n    t = _plural(len(options)), _nameof(where), _kwdstr(**options)\n    return Error(\"invalid option%s: %s(%s)\" % t)\n\n\ndef _p100(part, total, prec=1):\n    \"\"\"Return percentage as string.\"\"\"\n    t = float(total)\n    if t > 0:\n        p = part * 100.0 / t\n        r = \"%.*f%%\" % (prec, p)\n    else:\n        r = \"n/a\"\n    return r\n\n\ndef _plural(num):\n    \"\"\"Return 's' if *num* is not one.\"\"\"\n    return \"s\" if num != 1 else _NN\n\n\ndef _power_of_2(n):\n    \"\"\"Find the next power of 2.\"\"\"\n    p2 = 2 ** int(log(n, 2))\n    while n > p2:\n        p2 += p2\n    return p2\n\n\ndef _prepr(obj, clip=0):\n    \"\"\"Prettify and clip long repr() string.\"\"\"\n    return _repr(obj, clip=clip).strip(\"<>\").replace(\"'\", _NN)  # remove <''>\n\n\ndef _printf(fmt, *args, **print3options):\n    \"\"\"Formatted print to sys.stdout or given stream.\n\n    *print3options* -- some keyword arguments, like Python 3+ print.\n    \"\"\"\n    if print3options:  # like Python 3+\n        f = print3options.get(\"file\", None) or sys.stdout\n        if args:\n            f.write(fmt % args)\n        else:\n            f.write(fmt)\n        f.write(print3options.get(\"end\", linesep))\n        if print3options.get(\"flush\", False):\n            f.flush()\n    elif args:\n        print(fmt % args)\n    else:\n        print(fmt)\n\n\ndef _refs(obj, named, *attrs, **kwds):\n    \"\"\"Return specific attribute objects of an object.\"\"\"\n    if named:\n        _N = _NamedRef\n    else:\n\n        def _N(unused, o):\n            return o\n\n    for a in attrs:  # cf. inspect.getmembers()\n        if hasattr(obj, a):\n            yield _N(a, getattr(obj, a))\n    if kwds:  # kwds are _dir2() args\n        for a, o in _dir2(obj, **kwds):\n            yield _N(a, o)\n\n\ndef _repr(obj, clip=80):\n    \"\"\"Clip long repr() string.\"\"\"\n    try:  # safe repr()\n        r = repr(obj).replace(linesep, \"\\\\n\")\n    except Exception:\n        r = \"N/A\"\n    if len(r) > clip > 0:\n        h = (clip // 2) - 2\n        if h > 0:\n            r = r[:h] + \"....\" + r[-h:]\n    return r\n\n\ndef _SI(size, K=1024, i=\"i\"):\n    \"\"\"Return size as SI string.\"\"\"\n    if 1 < K <= size:\n        f = float(size)\n        for si in iter(\"KMGPTE\"):\n            f /= K\n            if f < K:\n                return \" or %.1f %s%sB\" % (f, si, i)\n    return _NN\n\n\ndef _SI2(size, **kwds):\n    \"\"\"Return size as regular plus SI string.\"\"\"\n    return str(size) + _SI(size, **kwds)\n\n\n# Type-specific referents functions\n\n\ndef _cell_refs(obj, named):\n    try:  # handle 'empty' cells\n        o = obj.cell_contents\n        if named:\n            o = _NamedRef(\"cell_contents\", o)\n        yield o\n    except (AttributeError, ValueError):\n        pass\n\n\ndef _class_refs(obj, named):\n    \"\"\"Return specific referents of a class object.\"\"\"\n    return _refs(\n        obj,\n        named,\n        \"__class__\",\n        \"__doc__\",\n        \"__mro__\",\n        \"__name__\",\n        \"__slots__\",\n        \"__weakref__\",\n        \"__dict__\",\n    )  # __dict__ last\n\n\ndef _co_refs(obj, named):\n    \"\"\"Return specific referents of a code object.\"\"\"\n    return _refs(obj, named, pref=\"co_\")\n\n\ndef _dict_refs(obj, named):\n    \"\"\"Return key and value objects of a dict/proxy.\"\"\"\n    try:\n        if named:\n            for k, v in _items(obj):\n                s = str(k)\n                yield _NamedRef(\"[K] \" + s, k)\n                s += \": \" + _repr(v)\n                yield _NamedRef(\"[V] \" + s, v)\n        else:\n            for k, v in _items(obj):\n                yield k\n                yield v\n    except (KeyError, ReferenceError, TypeError) as x:\n        warnings.warn(\"Iterating '%s': %r\" % (_classof(obj), x))\n\n\ndef _enum_refs(obj, named):\n    \"\"\"Return specific referents of an enumerate object.\"\"\"\n    return _refs(obj, named, \"__doc__\")\n\n\ndef _exc_refs(obj, named):\n    \"\"\"Return specific referents of an Exception object.\"\"\"\n    # .message raises DeprecationWarning in Python 2.6\n    return _refs(\n        obj, named, \"args\", \"filename\", \"lineno\", \"msg\", \"text\"\n    )  # , 'message', 'mixed'\n\n\ndef _file_refs(obj, named):\n    \"\"\"Return specific referents of a file object.\"\"\"\n    return _refs(obj, named, \"mode\", \"name\")\n\n\ndef _frame_refs(obj, named):\n    \"\"\"Return specific referents of a frame object.\"\"\"\n    return _refs(obj, named, pref=\"f_\")\n\n\ndef _func_refs(obj, named):\n    \"\"\"Return specific referents of a function or lambda object.\"\"\"\n    return _refs(\n        obj,\n        named,\n        \"__doc__\",\n        \"__name__\",\n        \"__code__\",\n        \"__closure__\",\n        pref=\"func_\",\n        excl=(\"func_globals\",),\n    )\n\n\ndef _gen_refs(obj, named):\n    \"\"\"Return the referent(s) of a generator (expression) object.\"\"\"\n    # only some gi_frame attrs, but none of\n    # the items to keep the generator intact\n    f = getattr(obj, \"gi_frame\", None)\n    return _refs(f, named, \"f_locals\", \"f_code\")\n\n\ndef _im_refs(obj, named):\n    \"\"\"Return specific referents of a method object.\"\"\"\n    return _refs(obj, named, \"__doc__\", \"__name__\", \"__code__\", pref=\"im_\")\n\n\ndef _inst_refs(obj, named):\n    \"\"\"Return specific referents of a class instance.\"\"\"\n    return _refs(obj, named, \"__dict__\", \"__class__\", slots=\"__slots__\")\n\n\ndef _iter_refs(obj, named):\n    \"\"\"Return the referent(s) of an iterator object.\"\"\"\n    r = _getreferents(obj)  # special case\n    return _refs(r, named, itor=_nameof(obj) or \"iteref\")\n\n\ndef _module_refs(obj, named):\n    \"\"\"Return specific referents of a module object.\"\"\"\n    n = _nameof(obj) == __name__  # i.e. this module\n    # ignore this very module, module is essentially a dict\n    return () if n else _dict_refs(obj.__dict__, named)\n\n\ndef _namedtuple_refs(obj, named):\n    \"\"\"Return specific referents of obj-as-sequence and slots but exclude dict.\"\"\"\n    for r in _refs(obj, named, \"__class__\", slots=\"__slots__\"):\n        yield r\n    for r in obj:\n        yield r\n\n\ndef _prop_refs(obj, named):\n    \"\"\"Return specific referents of a property object.\"\"\"\n    return _refs(obj, named, \"__doc__\", pref=\"f\")\n\n\ndef _seq_refs(obj, unused):  # named unused for PyChecker\n    \"\"\"Return specific referents of a frozen/set, list, tuple and xrange object.\"\"\"\n    return obj  # XXX for r in obj: yield r\n\n\ndef _stat_refs(obj, named):\n    \"\"\"Return referents of a os.stat object.\"\"\"\n    return _refs(obj, named, pref=\"st_\")\n\n\ndef _statvfs_refs(obj, named):\n    \"\"\"Return referents of a os.statvfs object.\"\"\"\n    return _refs(obj, named, pref=\"f_\")\n\n\ndef _tb_refs(obj, named):\n    \"\"\"Return specific referents of a traceback object.\"\"\"\n    return _refs(obj, named, pref=\"tb_\")\n\n\ndef _type_refs(obj, named):\n    \"\"\"Return specific referents of a type object.\"\"\"\n    return _refs(\n        obj,\n        named,\n        \"__doc__\",\n        \"__mro__\",\n        \"__name__\",\n        \"__slots__\",\n        \"__weakref__\",\n        \"__dict__\",\n    )\n\n\ndef _weak_refs(obj, unused):  # unused for named\n    \"\"\"Return weakly referent object.\"\"\"\n    try:  # ignore 'key' of KeyedRef\n        return (obj(),)\n    except Exception:  # XXX ReferenceError\n        return ()\n\n\n_all_refs = {\n    None,\n    _cell_refs,\n    _class_refs,\n    _co_refs,\n    _dict_refs,\n    _enum_refs,\n    _exc_refs,\n    _file_refs,\n    _frame_refs,\n    _func_refs,\n    _gen_refs,\n    _im_refs,\n    _inst_refs,\n    _iter_refs,\n    _module_refs,\n    _namedtuple_refs,\n    _prop_refs,\n    _seq_refs,\n    _stat_refs,\n    _statvfs_refs,\n    _tb_refs,\n    _type_refs,\n    _weak_refs,\n}  # type: Set[Union[None, Callable], ...]\n\n\n# Type-specific length functions\n\n\ndef _len(obj):\n    \"\"\"Safe len().\"\"\"\n    try:\n        return len(obj)\n    except TypeError:  # no len() nor __len__\n        return 0\n\n\ndef _len_bytearray(obj):\n    \"\"\"Bytearray size.\"\"\"\n    return obj.__alloc__()\n\n\ndef _len_code(obj):  # see .../Lib/test/test_sys.py\n    \"\"\"Length of code object (stack and variables only).\"\"\"\n    return (\n        _len(obj.co_freevars)\n        + obj.co_stacksize\n        + _len(obj.co_cellvars)\n        + obj.co_nlocals\n        - 1\n    )\n\n\ndef _len_dict(obj):\n    \"\"\"Dict length in items (estimate).\"\"\"\n    n = len(obj)  # active items\n    if n < 6:  # ma_smalltable ...\n        n = 0  # ... in basicsize\n    else:  # at least one unused\n        n = _power_of_2(n + 1)\n    return n\n\n\ndef _len_frame(obj):\n    \"\"\"Length of a frame object.\"\"\"\n    c = getattr(obj, \"f_code\", None)\n    return _len_code(c) if c else 0\n\n\n# _sizeof_Cdigit = sys.int_info.sizeof_digit  # sys.int_info in Python 3.1+\n# _bitsof_Cdigit = sys.int_info.bits_per_digit  # (_sizeof_Cdigit * 15) // 2\n# _Typedef(int).base = int.__basicsize__  # == _getsizeof(0)\n# _Typedef(int).item = int.__itemsize__  # == _sizeof_Cdigit\n\n\ndef _len_int(obj):\n    \"\"\"Length of *int* (multi-precision, formerly long) in Cdigits.\"\"\"\n    n = _getsizeof(obj, 0) - int.__basicsize__\n    return (n // int.__itemsize__) if n > 0 else 0\n\n\ndef _len_iter(obj):\n    \"\"\"Length (hint) of an iterator.\"\"\"\n    n = getattr(obj, \"__length_hint__\", None)\n    return n() if n and callable(n) else _len(obj)\n\n\ndef _len_list(obj):\n    \"\"\"Length of list (estimate).\"\"\"\n    n = len(obj)\n    # estimate over-allocation\n    if n > 8:\n        n += 6 + (n >> 3)\n    elif n:\n        n += 4\n    return n\n\n\ndef _len_module(obj):\n    \"\"\"Module length.\"\"\"\n    return _len(obj.__dict__)  # _len(dir(obj))\n\n\ndef _len_set(obj):\n    \"\"\"Length of frozen/set (estimate).\"\"\"\n    n = len(obj)\n    if n > 8:  # assume half filled\n        n = _power_of_2(n + n - 2)\n    elif n:  # at least 8\n        n = 8\n    return n\n\n\ndef _len_slice(obj):\n    \"\"\"Slice length.\"\"\"\n    try:\n        return (obj.stop - obj.start + 1) // obj.step\n    except (AttributeError, TypeError):\n        return 0\n\n\n# REMOVED, see _Slots.__doc__\n# def _len_slots(obj):\n#     '''Slots length.\n#     '''\n#     return len(obj) - 1\n\n\ndef _len_struct(obj):\n    \"\"\"Struct length in bytes.\"\"\"\n    try:\n        return obj.size\n    except AttributeError:\n        return 0\n\n\ndef _len_unicode(obj):\n    \"\"\"Unicode size.\"\"\"\n    return len(obj) + 1\n\n\n_all_lens = {\n    None,\n    _len,\n    _len_bytearray,\n    _len_code,\n    _len_dict,\n    _len_frame,\n    _len_int,\n    _len_iter,\n    _len_list,\n    _len_module,\n    _len_set,\n    _len_slice,\n    _len_struct,\n    _len_unicode,\n}  # type: Set[Union[None, Callable], ...]\n\n\n# More private functions and classes\n\n# _old_style = '*'  # marker, OBSOLETE\n# _new_style = _NN  # no marker\n\n\nclass _Claskey(object):\n    \"\"\"Wrapper for class objects.\"\"\"\n\n    __slots__ = (\"_obj\",)  # '_sty'\n\n    def __init__(self, obj):\n        self._obj = obj  # XXX Weakref.ref(obj)\n\n    #       self._sty = _new_style\n\n    def __str__(self):\n        r = str(self._obj)\n        return (r[:-1] + \" def>\") if r.endswith(\">\") else (r + \" def\")\n\n    __repr__ = __str__\n\n\n# For most objects, the object type is used as the key in the\n# _typedefs dict further below, except class and type objects\n# instances.  Those are wrapped with separate _Claskey or\n# _Instkey instances to be able (1) to distinguish class (and\n# type) instances from class (and type) definitions and (2)\n# to provide similar results for repr() and str() of classes\n# and instances.\n\n_claskeys = {}  # type: Dict[int, _Claskey]\n_NoneNone = None, None  # not a class\n\n\ndef _claskey(obj):\n    \"\"\"Wrap a class object.\"\"\"\n    i = id(obj)\n    try:\n        k = _claskeys[i]\n    except KeyError:\n        _claskeys[i] = k = _Claskey(obj)\n    return k\n\n\ndef _key2tuple(obj):  # PYCHOK expected\n    \"\"\"Return class and instance keys for a class.\"\"\"\n    t = type(obj) is _Type_type  # isclass(obj):\n    return (_claskey(obj), obj) if t else _NoneNone\n\n\ndef _objkey(obj):  # PYCHOK expected\n    \"\"\"Return the key for any object.\"\"\"\n    k = type(obj)\n    if k is _Type_type:  # isclass(obj):\n        k = _claskey(obj)\n    return k\n\n\nclass _NamedRef(object):\n    \"\"\"Store referred object along\n    with the name of the referent.\n    \"\"\"\n\n    __slots__ = (\"name\", \"ref\")\n\n    def __init__(self, name, ref):\n        self.name = name\n        self.ref = ref\n\n\n# class _Slots(tuple):\n#     '''Wrapper class for __slots__ attribute at class definition.\n#        The instance-specific __slots__ attributes are stored in\n#        a \"tuple-like\" space inside the instance, see Luciano\n#        Ramalho, \"Fluent Python\", page 274+, O'Reilly, 2016 or\n#        at <http://Books.Google.com/books>, then search for\n#        \"Fluent Python\" \"Space Savings with the __slots__\".\n#     '''\n#     pass\n\n\n# all kinds of _Typedefs\ni = sys.intern  # Python 3+\nt = (_kind_static, _kind_dynamic, _kind_derived, _kind_ignored, _kind_inferred) = (\n    i(\"static\"),\n    i(\"dynamic\"),\n    i(\"derived\"),\n    i(\"ignored\"),\n    i(\"inferred\"),\n)\n_all_kinds = set(t)\ndel i, t\n\n\nclass _Typedef(object):\n    \"\"\"Type definition class.\"\"\"\n\n    base = 0  # basic size in bytes\n    both = None  # both data and code if True, code only if False\n    item = 0  # item size in bytes\n    kind = None  # _kind_... value\n    leng = None  # _len_...() function or None\n    refs = None  # _..._refs() function or None\n    type = None  # original type\n    vari = None  # item size attr name or _Not_vari\n    xtyp = None  # if True, not _getsizeof'd\n\n    def __init__(self, **kwds):\n        self.reset(**kwds)\n\n    def __lt__(self, unused):  # for Python 3+\n        return True\n\n    def __repr__(self):\n        return repr(self.args())\n\n    def __str__(self):\n        t = [str(self.base), str(self.item)]\n        for f in (self.leng, self.refs):\n            t.append(_nameof(f) or \"n/a\")\n        if not self.both:\n            t.append(\"(code only)\")\n        return \", \".join(t)\n\n    def args(self):  # as args tuple\n        \"\"\"Return all attributes as arguments tuple.\"\"\"\n        return (\n            self.base,\n            self.item,\n            self.leng,\n            self.refs,\n            self.both,\n            self.kind,\n            self.type,\n            self.xtyp,\n        )\n\n    def dup(self, other=None, **kwds):\n        \"\"\"Duplicate attributes of dict or other typedef.\"\"\"\n        t = other or _dict_typedef\n        d = t.kwds()\n        d.update(kwds)\n        self.reset(**d)\n\n    def flat(self, obj, mask=0):\n        \"\"\"Return the aligned flat size.\"\"\"\n        s = self.base\n        if self.leng and self.item > 0:  # include items\n            s += self.leng(obj) * self.item\n        # workaround sys.getsizeof bug for _array types\n        # (in some Python versions) and for other types\n        # with variable .itemsize like numpy.arrays, etc.\n        if not self.xtyp:\n            s = _getsizeof(obj, s)\n        if mask:  # alignment mask\n            s = (s + mask) & ~mask\n        #           if (mask + 1) & mask:\n        #               raise _OptionError(self.flat, mask=mask)\n        return s\n\n    def format(self):\n        \"\"\"Return format dict.\"\"\"\n        a = _nameof(self.leng)\n        return dict(\n            leng=((\" (%s)\" % (a,)) if a else _NN),\n            item=\"var\" if self.vari else self.item,\n            code=_NN if self.both else \" (code only)\",\n            base=self.base,\n            kind=self.kind,\n        )\n\n    def kwds(self):\n        \"\"\"Return all attributes as keywords dict.\"\"\"\n        return dict(\n            base=self.base,\n            both=self.both,\n            item=self.item,\n            kind=self.kind,\n            leng=self.leng,\n            refs=self.refs,\n            type=self.type,\n            vari=self.vari,\n            xtyp=self.xtyp,\n        )\n\n    def reset(\n        self,\n        base=0,\n        item=0,\n        leng=None,\n        refs=None,\n        both=True,\n        kind=None,\n        type=None,\n        vari=_Not_vari,\n        xtyp=False,\n        **extra,\n    ):\n        \"\"\"Reset all specified typedef attributes.\"\"\"\n        v = vari or _Not_vari\n        if v != str(v):  # attr name\n            e = dict(vari=v)\n        elif base < 0:\n            e = dict(base=base)\n        elif both not in (False, True):\n            e = dict(both=both)\n        elif item < 0:\n            e = dict(item=item)\n        elif kind not in _all_kinds:\n            e = dict(kind=kind)\n        elif leng not in _all_lens:  # XXX or not callable(leng)\n            e = dict(leng=leng)\n        elif refs not in _all_refs:  # XXX or not callable(refs)\n            e = dict(refs=refs)\n        elif xtyp not in (False, True):\n            e = dict(xtyp=xtyp)\n        elif extra:\n            e = {}\n        else:\n            self.base = base\n            self.both = both\n            self.item = item\n            self.kind = kind\n            self.leng = leng\n            self.refs = refs\n            self.type = type  # unchecked, as-is\n            self.vari = v\n            self.xtyp = xtyp\n            return\n        e.update(extra)\n        raise _OptionError(self.reset, **e)\n\n    def save(self, t, base=0, heap=False):\n        \"\"\"Save this typedef plus its class typedef.\"\"\"\n        c, k = _key2tuple(t)\n        if k and k not in _typedefs:  # instance key\n            _typedefs[k] = self\n            if c and c not in _typedefs:  # class key\n                b = _basicsize(type(t), base=base, heap=heap)\n                k = _kind_ignored if _isignored(t) else self.kind\n                _typedefs[c] = _Typedef(\n                    base=b, both=False, kind=k, type=t, refs=_type_refs\n                )\n        elif t not in _typedefs:\n            if not _isbuiltin2(t):  # array, range, xrange in Python 2.x\n                s = \" \".join((self.vari, _moduleof(t), _nameof(t)))\n                s = \"%r %s %s\" % ((c, k), self.both, s.strip())\n                raise KeyError(\"typedef %r bad: %s\" % (self, s))\n\n            _typedefs[t] = _Typedef(\n                base=_basicsize(t, base=base), both=False, kind=_kind_ignored, type=t\n            )\n\n    def set(self, safe_len=False, **kwds):\n        \"\"\"Set one or more attributes.\"\"\"\n        if kwds:  # double check\n            d = self.kwds()\n            d.update(kwds)\n            self.reset(**d)\n        if safe_len and self.item:\n            self.leng = _len\n\n\n_typedefs = {}  # type: Dict[type, _Typedef]\n\n\ndef _typedef_both(\n    t,\n    base=0,\n    item=0,\n    leng=None,\n    refs=None,\n    kind=_kind_static,\n    heap=False,\n    vari=_Not_vari,\n):\n    \"\"\"Add new typedef for both data and code.\"\"\"\n    v = _Typedef(\n        base=_basicsize(t, base=base),\n        item=_itemsize(t, item),\n        refs=refs,\n        leng=leng,\n        both=True,\n        kind=kind,\n        type=t,\n        vari=vari,\n    )\n    v.save(t, base=base, heap=heap)\n    return v  # for _dict_typedef\n\n\ndef _typedef_code(t, base=0, refs=None, kind=_kind_static, heap=False):\n    \"\"\"Add new typedef for code only.\"\"\"\n    v = _Typedef(\n        base=_basicsize(t, base=base), refs=refs, both=False, kind=kind, type=t\n    )\n    v.save(t, base=base, heap=heap)\n    return v  # for _dict_typedef\n\n\n# Static typedefs for data and code types\n_typedef_both(complex)\n_typedef_both(float)\n_typedef_both(int, leng=_len_int)  # see _len_int\n_typedef_both(\n    list, refs=_seq_refs, leng=_len_list, item=_sizeof_Cvoidp\n)  # sizeof(PyObject*)\n_typedef_both(\n    tuple, refs=_seq_refs, leng=_len, item=_sizeof_Cvoidp\n)  # sizeof(PyObject*)\n_typedef_both(property, refs=_prop_refs)\n_typedef_both(type(Ellipsis))\n_typedef_both(type(None))\n\n# _Slots are \"tuple-like\", REMOVED see _Slots.__doc__\n# _typedef_both(_Slots, item=_sizeof_Cvoidp,\n#               leng=_len_slots,  # length less one\n#               refs=None,  # but no referents\n#               heap=True)  # plus head\n\n# dict, dictproxy, dict_proxy and other dict-like types\n_dict_typedef = _typedef_both(\n    dict, item=_sizeof_CPyDictEntry, leng=_len_dict, refs=_dict_refs\n)\n# XXX any class __dict__ is <type dict_proxy> in Python 3+?\n_typedef_both(\n    type(_Typedef.__dict__), item=_sizeof_CPyDictEntry, leng=_len_dict, refs=_dict_refs\n)\n# other dict-like classes and types may be derived or inferred,\n# provided the module and class name is listed here (see functions\n# _isdictype and _infer_dict for further details)\n_dict_types = dict(\n    UserDict=(\"IterableUserDict\", \"UserDict\"),\n    weakref=(\"WeakKeyDictionary\", \"WeakValueDictionary\"),\n)\ntry:  # <type module> is essentially a dict\n    _typedef_both(\n        Types.ModuleType,\n        base=_dict_typedef.base,\n        item=_dict_typedef.item + _sizeof_CPyModuleObject,\n        leng=_len_module,\n        refs=_module_refs,\n    )\nexcept AttributeError:  # missing\n    pass\n\n\n# Newer or obsolete types\nfrom array import array as _array  # array type\n\n\ndef _len_array(obj):\n    \"\"\"Array length (in bytes!).\"\"\"\n    return len(obj) * obj.itemsize\n\n\ndef _array_kwds(obj):\n    # since item size varies by the array data type, set\n    # itemsize to 1 byte and use _len_array in bytes;\n    # _getsizeof(array) returns array plus base size\n    b = max(56, _getsizeof(obj, 0) - _len_array(obj))\n    return dict(\n        base=b,\n        leng=_len_array,\n        item=_sizeof_Cbyte,\n        vari=\"itemsize\",  # array.itemsize\n        xtyp=True,\n    )  # never _getsizeof'd\n\n\n_all_lens.add(_len_array)  # type: ignore\n\ntry:  # bool has non-zero __itemsize__ in 3.0\n    _typedef_both(bool)\nexcept NameError:  # missing\n    pass\n\ntry:\n    _typedef_both(bytearray, item=_sizeof_Cbyte, leng=_len_bytearray)\nexcept NameError:  # bytearray new in 2.6, 3.0\n    pass\ntry:\n    if type(bytes) is not type(str):  # bytes is str in 2.6, bytes new in 2.6, 3.0\n        _typedef_both(bytes, item=_sizeof_Cbyte, leng=_len)  # bytes new in 2.6, 3.0\nexcept NameError:  # missing\n    pass\n# try:  # XXX like bytes\n#     _typedef_both(str8, item=_sizeof_Cbyte, leng=_len)  # str8 new in 2.6, 3.0\n# except NameError:  # missing\n#     pass\n\ntry:\n    _typedef_both(enumerate, refs=_enum_refs)\nexcept NameError:  # missing\n    pass\n\ntry:  # Exception is type in Python 3+\n    _typedef_both(Exception, refs=_exc_refs)\nexcept Exception:  # missing\n    pass\n\ntry:\n    _typedef_both(frozenset, item=_sizeof_Csetentry, leng=_len_set, refs=_seq_refs)\nexcept NameError:  # missing\n    pass\ntry:\n    _typedef_both(set, item=_sizeof_Csetentry, leng=_len_set, refs=_seq_refs)\nexcept NameError:  # missing\n    pass\n\ntry:  # not callable()\n    _typedef_both(Types.GetSetDescriptorType)\nexcept AttributeError:  # missing\n    pass\n\ntry:  # not callable()\n    _typedef_both(Types.MemberDescriptorType)\nexcept AttributeError:  # missing\n    pass\n\ntry:\n    _typedef_both(type(NotImplemented))  # == Types.NotImplementedType\nexcept NameError:  # missing\n    pass\n\ntry:  # MCCABE 19\n    import numpy as _numpy  # NumPy array, matrix, etc.\n\n    try:\n        _numpy_memmap = _numpy.memmap\n    except AttributeError:\n        _numpy_memmap = None\n    try:\n        from mmap import PAGESIZE as _PAGESIZE\n\n        if _PAGESIZE < 1024:\n            raise ImportError\n    except ImportError:\n        _PAGESIZE = 4096  # 4 KiB, typical\n\n    def _isnumpy(obj):\n        \"\"\"Return True for a NumPy arange, array, matrix, memmap, ndarray, etc. instance.\"\"\"\n        # not every numpy obj  hasattr(obj, 'base')\n        if (\n            hasattr(obj, \"dtype\")\n            and hasattr(obj, \"itemsize\")\n            and hasattr(obj, \"nbytes\")\n        ):\n            try:\n                return _moduleof(_classof(obj)).startswith(\"numpy\") or _moduleof(\n                    type(obj)\n                ).startswith(\"numpy\")\n            except (AttributeError, OSError, ValueError):  # on iOS/Pythonista\n                pass\n        return False\n\n    def _len_numpy(obj):\n        \"\"\"NumPy array, matrix, etc. length (in bytes!).\"\"\"\n        return obj.nbytes  # == obj.size * obj.itemsize\n\n    def _len_numpy_memmap(obj):\n        \"\"\"Approximate NumPy memmap in-memory size (in bytes!).\"\"\"\n        nb = int(obj.nbytes * _amapped)\n        # round up to multiple of virtual memory page size\n        return ((nb + _PAGESIZE - 1) // _PAGESIZE) * _PAGESIZE\n\n    def _numpy_kwds(obj):\n        t = type(obj)\n        # .nbytes is included in sys.sizeof size for most numpy\n        # objects except for numpy.memmap (and for the latter it\n        # is the length of the file to be memory-mapped which by\n        # default is the file size less the offset specified)\n        if t is _numpy_memmap:  # isinstance(obj, _numpy_memmap)\n            b, _len_, nb = 144, _len_numpy_memmap, 0\n        else:  # XXX 96, 128, 144 typical?\n            b, _len_, nb = 96, _len_numpy, obj.nbytes\n        # since item size depends on the nympy data type, set\n        # itemsize to 1 byte and use _len_numpy in bytes; note,\n        # function itemsize returns the actual size in bytes,\n        # function alen returns the length in number of items\n        return dict(\n            base=_getsizeof(obj, b) - nb,\n            item=_sizeof_Cbyte,  # not obj.itemsize!\n            leng=_len_,\n            refs=_numpy_refs,\n            vari=\"itemsize\",  # numpy.itemsize\n            xtyp=True,\n        )  # never _getsizeof'd\n\n    def _numpy_refs(obj, named):\n        \"\"\"Return the .base object for NumPy slices, views, etc.\"\"\"\n        return _refs(obj, named, \"base\")\n\n    _all_lens.add(_len_numpy)  # type: ignore\n    _all_lens.add(_len_numpy_memmap)  # type: ignore\n    _all_refs.add(_numpy_refs)  # type: ignore\n\nexcept ImportError:  # no NumPy\n    _numpy = _numpy_kwds = None  # type: ignore  # see function _typedef below\n\n    def _isnumpy(unused):  # PYCHOK expected\n        \"\"\"Not applicable, no NumPy.\"\"\"\n        return False\n\n\ntry:\n    _typedef_both(range)\nexcept NameError:  # missing\n    pass\n\ntry:\n    _typedef_both(reversed, refs=_enum_refs)\nexcept NameError:  # missing\n    pass\n\ntry:\n    _typedef_both(\n        slice, item=_sizeof_Cvoidp, leng=_len_slice\n    )  # XXX worst-case itemsize?\nexcept NameError:  # missing\n    pass\n\ntry:\n    from os import stat\n\n    _typedef_both(type(stat(curdir)), refs=_stat_refs)  # stat_result\nexcept ImportError:  # missing\n    pass\n\ntry:\n    from os import statvfs\n\n    _typedef_both(\n        type(statvfs(curdir)),\n        refs=_statvfs_refs,  # statvfs_result\n        item=_sizeof_Cvoidp,\n        leng=_len,\n    )\nexcept ImportError:  # missing\n    pass\n\ntry:\n    from struct import Struct  # only in Python 2.5 and 3.0\n\n    _typedef_both(Struct, item=_sizeof_Cbyte, leng=_len_struct)  # len in bytes\nexcept ImportError:  # missing\n    pass\n\ntry:\n    _typedef_both(Types.TracebackType, refs=_tb_refs)\nexcept AttributeError:  # missing\n    pass\n\n_typedef_both(str, leng=_len_unicode, item=_sizeof_Cunicode)\n\ntry:  # <type 'KeyedRef'>\n    _typedef_both(Weakref.KeyedRef, refs=_weak_refs, heap=True)  # plus head\nexcept AttributeError:  # missing\n    pass\n\ntry:  # <type 'weakproxy'>\n    _typedef_both(Weakref.ProxyType)\nexcept AttributeError:  # missing\n    pass\n\ntry:  # <type 'weakref'>\n    _typedef_both(Weakref.ReferenceType, refs=_weak_refs)\nexcept AttributeError:  # missing\n    pass\n\n# some other, callable types\n_typedef_code(object, kind=_kind_ignored)\n_typedef_code(super, kind=_kind_ignored)\n_typedef_code(_Type_type, kind=_kind_ignored)\n\ntry:\n    _typedef_code(classmethod, refs=_im_refs)\nexcept NameError:\n    pass\ntry:\n    _typedef_code(staticmethod, refs=_im_refs)\nexcept NameError:\n    pass\ntry:\n    _typedef_code(Types.MethodType, refs=_im_refs)\nexcept NameError:\n    pass\n\ntry:  # generator (expression), no itemsize, no len(), not callable()\n    _typedef_both(Types.GeneratorType, refs=_gen_refs)\nexcept AttributeError:  # missing\n    pass\n\ntry:  # <type 'weakcallableproxy'>\n    _typedef_code(Weakref.CallableProxyType, refs=_weak_refs)\nexcept AttributeError:  # missing\n    pass\n\n# any type-specific iterators\ns = [_items({}), _keys({}), _values({})]\ntry:  # reversed list and tuples iterators\n    s.extend([reversed([]), reversed(())])\nexcept NameError:  # missing\n    pass\n\ntry:  # callable-iterator\n    from re import finditer\n\n    s.append(finditer(_NN, _NN))\n    del finditer\nexcept ImportError:  # missing\n    pass\n\nfor t in _values(_typedefs):\n    if t.type and t.leng:\n        try:  # create an (empty) instance\n            s.append(t.type())\n        except TypeError:\n            pass\nfor t in s:\n    try:\n        i = iter(t)\n        _typedef_both(type(i), leng=_len_iter, refs=_iter_refs, item=0)  # no itemsize!\n    except (KeyError, TypeError):  # ignore non-iterables, duplicates, etc.\n        pass\ndel i, s, t\n\n\ndef _typedef(obj, derive=False, frames=False, infer=False):  # MCCABE 25\n    \"\"\"Create a new typedef for an object.\"\"\"\n    t = type(obj)\n    v = _Typedef(base=_basicsize(t, obj=obj), kind=_kind_dynamic, type=t)\n    #   _printf('new %r %r/%r %s', t, _basicsize(t), _itemsize(t), _repr(dir(obj)))\n    if ismodule(obj):  # handle module like dict\n        v.dup(\n            item=_dict_typedef.item + _sizeof_CPyModuleObject,\n            leng=_len_module,\n            refs=_module_refs,\n        )\n    elif _isframe(obj):\n        v.set(\n            base=_basicsize(t, base=_sizeof_CPyFrameObject, obj=obj),\n            item=_itemsize(t),\n            leng=_len_frame,\n            refs=_frame_refs,\n        )\n        if not frames:  # ignore frames\n            v.set(kind=_kind_ignored)\n    elif iscode(obj):\n        v.set(\n            base=_basicsize(t, base=_sizeof_CPyCodeObject, obj=obj),\n            item=_sizeof_Cvoidp,\n            leng=_len_code,\n            refs=_co_refs,\n            both=False,\n        )  # code only\n    elif callable(obj):\n        if isclass(obj):  # class or type\n            v.set(refs=_class_refs, both=False)  # code only\n            if _isignored(obj):\n                v.set(kind=_kind_ignored)\n        elif isbuiltin(obj):  # function or method\n            v.set(both=False, kind=_kind_ignored)  # code only\n        elif isfunction(obj):\n            v.set(refs=_func_refs, both=False)  # code only\n        elif ismethod(obj):\n            v.set(refs=_im_refs, both=False)  # code only\n        elif isclass(t):  # callable instance, e.g. SCons,\n            # handle like any other instance further below\n            v.set(item=_itemsize(t), safe_len=True, refs=_inst_refs)  # not code only!\n        else:\n            v.set(both=False)  # code only\n    elif _issubclass(t, dict):\n        v.dup(kind=_kind_derived)\n    elif _isdictype(obj) or (infer and _infer_dict(obj)):\n        v.dup(kind=_kind_inferred)\n    elif _iscell(obj):\n        v.set(item=_itemsize(t), refs=_cell_refs)\n    elif _isnamedtuple(obj):\n        v.set(refs=_namedtuple_refs)\n    elif _numpy and _isnumpy(obj):\n        v.set(**_numpy_kwds(obj))\n    elif isinstance(obj, _array):\n        v.set(**_array_kwds(obj))\n    elif _isignored(obj):\n        v.set(kind=_kind_ignored)\n    else:  # assume an instance of some class\n        if derive:\n            p = _derive_typedef(t)\n            if p:  # duplicate parent\n                v.dup(other=p, kind=_kind_derived)\n                return v\n        if _issubclass(t, Exception):\n            v.set(item=_itemsize(t), safe_len=True, refs=_exc_refs, kind=_kind_derived)\n        elif isinstance(obj, Exception):\n            v.set(item=_itemsize(t), safe_len=True, refs=_exc_refs)\n        else:\n            v.set(item=_itemsize(t), safe_len=True, refs=_inst_refs)\n    return v\n\n\nclass _Prof(object):\n    \"\"\"Internal type profile class.\"\"\"\n\n    high = 0  # largest size\n    number = 0  # number of (unique) objects\n    objref = None  # largest obj (weakref)\n    total = 0  # total size\n    weak = False  # objref is weakref(obj)\n\n    def __cmp__(self, other):\n        if self.total < other.total:\n            return -1\n        elif self.total > other.total:\n            return +1\n        elif self.number < other.number:\n            return -1\n        elif self.number > other.number:\n            return +1\n        return 0\n\n    def __lt__(self, other):  # for Python 3+\n        return self.__cmp__(other) < 0\n\n    def format(self, clip=0, grand=None):\n        \"\"\"Return format dict.\"\"\"\n        if self.number > 1:  # avg., plural\n            a, p = int(self.total / self.number), \"s\"\n        else:\n            a, p = self.total, _NN\n        o = self.objref\n        if self.weak:\n            o = o()\n        t = _SI2(self.total)\n        if grand:\n            t += \" (%s)\" % _p100(self.total, grand, prec=0)\n        return dict(\n            avg=_SI2(a),\n            high=_SI2(self.high),\n            lengstr=_lengstr(o),\n            obj=_repr(o, clip=clip),\n            plural=p,\n            total=t,\n        )\n\n    def update(self, obj, size):\n        \"\"\"Update this profile.\"\"\"\n        self.number += 1\n        self.total += size\n        if self.high < size:  # largest\n            self.high = size\n            try:  # prefer using weak ref\n                self.objref, self.weak = Weakref.ref(obj), True\n            except TypeError:\n                self.objref, self.weak = obj, False\n\n\nclass _Rank(object):\n    \"\"\"Internal largest object class.\"\"\"\n\n    deep = 0  # recursion depth\n    id = 0  # id(obj)\n    key = None  # Typedef\n    objref = None  # obj or Weakref.ref(obj)\n    pid = 0  # id(parent obj)\n    size = 0  # size in bytes\n    weak = False  # objref is Weakref.ref\n\n    def __init__(self, key, obj, size, deep, pid):\n        self.deep = deep\n        self.id = id(obj)\n        self.key = key\n        try:  # prefer using weak ref\n            self.objref, self.weak = Weakref.ref(obj), True\n        except TypeError:\n            self.objref, self.weak = obj, False\n        self.pid = pid\n        self.size = size\n\n    def format(self, clip=0, id2x={}):\n        \"\"\"Return this *rank* as string.\"\"\"\n\n        def _ix(_id):  # id or parent_id\n            return id2x.get(_id, \"?\")\n\n        o = self.objref() if self.weak else self.objref\n        d = (\" (at %s)\" % (self.deep,)) if self.deep > 0 else _NN\n        p = (\", pix %s\" % (_ix(self.pid),)) if self.pid else _NN\n        return \"%s: %s%s, ix %s%s%s\" % (\n            _prepr(self.key, clip=clip),\n            _repr(o, clip=clip),\n            _lengstr(o),\n            _ix(self.id),\n            d,\n            p,\n        )\n\n\nclass _Seen(dict):\n    \"\"\"Internal obj visits counter.\"\"\"\n\n    def again(self, key):\n        try:\n            s = self[key] + 1\n        except KeyError:\n            s = 1\n        if s > 0:\n            self[key] = s\n\n\n# Public classes\n\n\nclass Asized(object):\n    \"\"\"Stores the results of an **asized** object in the following\n    4 attributes:\n\n     *size* -- total size of the object (including referents)\n\n     *flat* -- flat size of the object (in bytes)\n\n     *name* -- name or ``repr`` of the object\n\n     *refs* -- tuple containing an **Asized** instance for each referent\n    \"\"\"\n\n    __slots__ = (\"flat\", \"name\", \"refs\", \"size\")\n\n    def __init__(self, size, flat, refs=(), name=None):\n        self.size = size  # total size\n        self.flat = flat  # flat size\n        self.name = name  # name, repr or None\n        self.refs = tuple(refs)\n\n    def __str__(self):\n        return \"size %r, flat %r, refs[%d], name %r\" % (\n            self.size,\n            self.flat,\n            len(self.refs),\n            self.name,\n        )\n\n    def format(\n        self,\n        format=\"%(name)s size=%(size)d flat=%(flat)d\",\n        depth=-1,\n        order_by=\"size\",\n        indent=_NN,\n    ):\n        \"\"\"Format the size information of the object and of all\n        sized referents as a string.\n\n         *format* -- Specifies the format per instance (with 'name',\n                     'size' and 'flat' as interpolation parameters)\n\n         *depth* -- Recursion level up to which the referents are\n                    printed (use -1 for unlimited)\n\n         *order_by* -- Control sort order of referents, valid choices\n                       are 'name', 'size' and 'flat'\n\n         *indent* -- Optional indentation (default '')\n        \"\"\"\n        t = indent + (format % dict(size=self.size, flat=self.flat, name=self.name))\n        if depth and self.refs:\n            rs = sorted(\n                self.refs,\n                key=lambda x: getattr(x, order_by),\n                reverse=order_by in (\"size\", \"flat\"),\n            )\n            rs = [\n                r.format(\n                    format=format,\n                    depth=depth - 1,\n                    order_by=order_by,\n                    indent=indent + \"    \",\n                )\n                for r in rs\n            ]\n            t = \"\\n\".join([t] + rs)\n        return t\n\n    def get(self, name, dflt=None):\n        \"\"\"Return the named referent (or *dflt* if not found).\"\"\"\n        for ref in self.refs:\n            if name == ref.name:\n                return ref\n        return dflt\n\n\nclass Asizer(object):\n    \"\"\"Sizer state and options to accumulate sizes.\"\"\"\n\n    _above_ = 1024  # rank only objs of size 1K+\n    _align_ = 8  # alignment, power-of-2\n    _clip_ = 80\n    _code_ = False\n    _cutoff_ = 0  # in percent\n    _derive_ = False\n    _detail_ = 0  # for Asized only\n    _frames_ = False\n    _infer_ = False\n    _limit_ = 100\n    _stats_ = 0\n\n    _depth = 0  # deepest recursion\n    _excl_d = None  # {}\n    _ign_d = _kind_ignored\n    _incl = _NN  # or ' (incl. code)'\n    _mask = 7  # see _align_\n    _missed = 0  # due to errors\n    _profile = False  # no profiling\n    _profs = None  # {}\n    _ranked = 0\n    _ranks = []  # type: List[_Rank] # sorted by decreasing size\n    _seen = None  # {}\n    _stream = None  # I/O stream for printing\n    _total = 0  # total size\n\n    def __init__(self, **opts):\n        \"\"\"New **Asizer** accumulator.\n\n        See this module documentation for more details.\n        See method **reset** for all available options and defaults.\n        \"\"\"\n        self._excl_d = {}\n        self.reset(**opts)\n\n    def _c100(self, stats):\n        \"\"\"Cutoff as percentage (for backward compatibility)\"\"\"\n        s = int(stats)\n        c = int((stats - s) * 100.0 + 0.5) or self.cutoff\n        return s, c\n\n    def _clear(self):\n        \"\"\"Clear state.\"\"\"\n        self._depth = 0  # recursion depth reached\n        self._incl = _NN  # or ' (incl. code)'\n        self._missed = 0  # due to errors\n        self._profile = False\n        self._profs = {}\n        self._ranked = 0\n        self._ranks = []\n        self._seen = _Seen()\n        self._total = 0  # total size\n        for k in _keys(self._excl_d):\n            self._excl_d[k] = 0\n        # don't size, profile or rank private, possibly large objs\n        m = sys.modules[__name__]\n        self.exclude_objs(\n            self,\n            self._excl_d,\n            self._profs,\n            self._ranks,\n            self._seen,\n            m,\n            m.__dict__,\n            m.__doc__,\n            _typedefs,\n        )\n\n    def _nameof(self, obj):\n        \"\"\"Return the object's name.\"\"\"\n        return _nameof(obj, _NN) or self._repr(obj)\n\n    def _prepr(self, obj):\n        \"\"\"Like **prepr()**.\"\"\"\n        return _prepr(obj, clip=self._clip_)\n\n    def _printf(self, fmt, *args, **print3options):\n        \"\"\"Print to sys.stdout or the configured stream if any is\n        specified and if the file keyword argument is not already\n        set in the **print3options** for this specific call.\n        \"\"\"\n        if self._stream and not print3options.get(\"file\", None):\n            if args:\n                fmt = fmt % args\n            _printf(fmt, file=self._stream, **print3options)\n        else:\n            _printf(fmt, *args, **print3options)\n\n    def _prof(self, key):\n        \"\"\"Get _Prof object.\"\"\"\n        p = self._profs.get(key, None)\n        if not p:\n            self._profs[key] = p = _Prof()\n            self.exclude_objs(p)  # XXX superfluous?\n        return p\n\n    def _rank(self, key, obj, size, deep, pid):\n        \"\"\"Rank 100 largest objects by size.\"\"\"\n        rs = self._ranks\n        # bisect, see <http://GitHub.com/python/cpython/blob/master/Lib/bisect.py>\n        i, j = 0, len(rs)\n        while i < j:\n            m = (i + j) // 2\n            if size < rs[m].size:\n                i = m + 1\n            else:\n                j = m\n        if i < 100:\n            r = _Rank(key, obj, size, deep, pid)\n            rs.insert(i, r)\n            self.exclude_objs(r)  # XXX superfluous?\n            while len(rs) > 100:\n                rs.pop()\n            # self._ranks[:] = rs[:100]\n        self._ranked += 1\n\n    def _repr(self, obj):\n        \"\"\"Like ``repr()``.\"\"\"\n        return _repr(obj, clip=self._clip_)\n\n    def _sizer(self, obj, pid, deep, sized):  # MCCABE 19\n        \"\"\"Size an object, recursively.\"\"\"\n        s, f, i = 0, 0, id(obj)\n        if i not in self._seen:\n            self._seen[i] = 1\n        elif deep or self._seen[i]:\n            # skip obj if seen before\n            # or if ref of a given obj\n            self._seen.again(i)\n            if sized:\n                s = sized(s, f, name=self._nameof(obj))\n                self.exclude_objs(s)\n            return s  # zero\n        else:  # deep == seen[i] == 0\n            self._seen.again(i)\n        try:\n            k, rs = _objkey(obj), []\n            if k in self._excl_d:\n                self._excl_d[k] += 1\n            else:\n                v = _typedefs.get(k, None)\n                if not v:  # new typedef\n                    _typedefs[k] = v = _typedef(\n                        obj,\n                        derive=self._derive_,\n                        frames=self._frames_,\n                        infer=self._infer_,\n                    )\n                if (v.both or self._code_) and v.kind is not self._ign_d:\n                    s = f = v.flat(obj, self._mask)  # flat size\n                    if self._profile:\n                        # profile based on *flat* size\n                        self._prof(k).update(obj, s)\n                    # recurse, but not for nested modules\n                    if v.refs and deep < self._limit_ and not (deep and ismodule(obj)):\n                        # add sizes of referents\n                        z, d = self._sizer, deep + 1\n                        if sized and deep < self._detail_:\n                            # use named referents\n                            self.exclude_objs(rs)\n                            for o in v.refs(obj, True):\n                                if isinstance(o, _NamedRef):\n                                    r = z(o.ref, i, d, sized)\n                                    r.name = o.name\n                                else:\n                                    r = z(o, i, d, sized)\n                                    r.name = self._nameof(o)\n                                rs.append(r)\n                                s += r.size\n                        else:  # just size and accumulate\n                            for o in v.refs(obj, False):\n                                s += z(o, i, d, None)\n                        # deepest recursion reached\n                        if self._depth < d:\n                            self._depth = d\n                if self._stats_ and s > self._above_ > 0:\n                    # rank based on *total* size\n                    self._rank(k, obj, s, deep, pid)\n        except RuntimeError:  # XXX RecursionLimitExceeded:\n            self._missed += 1\n        if not deep:\n            self._total += s  # accumulate\n        if sized:\n            s = sized(s, f, name=self._nameof(obj), refs=rs)\n            self.exclude_objs(s)\n        return s\n\n    def _sizes(self, objs, sized=None):\n        \"\"\"Return the size or an **Asized** instance for each\n        given object plus the total size.  The total includes\n        the size of duplicates only once.\n        \"\"\"\n        self.exclude_refs(*objs)  # skip refs to objs\n        s, t = {}, []\n        self.exclude_objs(s, t)\n        for o in objs:\n            i = id(o)\n            if i in s:  # duplicate\n                self._seen.again(i)\n            else:\n                s[i] = self._sizer(o, 0, 0, sized)\n            t.append(s[i])\n        return tuple(t)\n\n    @property\n    def above(self):\n        \"\"\"Get the large object size threshold (int).\"\"\"\n        return self._above_\n\n    @property\n    def align(self):\n        \"\"\"Get the size alignment (int).\"\"\"\n        return self._align_\n\n    def asized(self, *objs, **opts):\n        \"\"\"Size each object and return an **Asized** instance with\n        size information and referents up to the given detail\n        level (and with modified options, see method **set**).\n\n        If only one object is given, the return value is the\n        **Asized** instance for that object.  The **Asized** size\n        of duplicate and ignored objects will be zero.\n        \"\"\"\n        if opts:\n            self.set(**opts)\n        t = self._sizes(objs, Asized)\n        return t[0] if len(t) == 1 else t\n\n    def asizeof(self, *objs, **opts):\n        \"\"\"Return the combined size of the given objects\n        (with modified options, see method **set**).\n        \"\"\"\n        if opts:\n            self.set(**opts)\n        self.exclude_refs(*objs)  # skip refs to objs\n        return sum(self._sizer(o, 0, 0, None) for o in objs)\n\n    def asizesof(self, *objs, **opts):\n        \"\"\"Return the individual sizes of the given objects\n        (with modified options, see method  **set**).\n\n        The size of duplicate and ignored objects will be zero.\n        \"\"\"\n        if opts:\n            self.set(**opts)\n        return self._sizes(objs, None)\n\n    @property\n    def clip(self):\n        \"\"\"Get the clipped string length (int).\"\"\"\n        return self._clip_\n\n    @property\n    def code(self):\n        \"\"\"Size (byte) code (bool).\"\"\"\n        return self._code_\n\n    @property\n    def cutoff(self):\n        \"\"\"Stats cutoff (int).\"\"\"\n        return self._cutoff_\n\n    @property\n    def derive(self):\n        \"\"\"Derive types (bool).\"\"\"\n        return self._derive_\n\n    @property\n    def detail(self):\n        \"\"\"Get the detail level for **Asized** refs (int).\"\"\"\n        return self._detail_\n\n    @property\n    def duplicate(self):\n        \"\"\"Get the number of duplicate objects seen so far (int).\"\"\"\n        return sum(1 for v in _values(self._seen) if v > 1)  # == len\n\n    def exclude_objs(self, *objs):\n        \"\"\"Exclude the specified objects from sizing, profiling and ranking.\"\"\"\n        for o in objs:\n            self._seen.setdefault(id(o), -1)\n\n    def exclude_refs(self, *objs):\n        \"\"\"Exclude any references to the specified objects from sizing.\n\n        While any references to the given objects are excluded, the\n        objects will be sized if specified as positional arguments\n        in subsequent calls to methods **asizeof** and **asizesof**.\n        \"\"\"\n        for o in objs:\n            self._seen.setdefault(id(o), 0)\n\n    def exclude_types(self, *objs):\n        \"\"\"Exclude the specified object instances and types from sizing.\n\n        All instances and types of the given objects are excluded,\n        even objects specified as positional arguments in subsequent\n        calls to methods **asizeof** and **asizesof**.\n        \"\"\"\n        for o in objs:\n            for t in _key2tuple(o):\n                if t and t not in self._excl_d:\n                    self._excl_d[t] = 0\n\n    @property\n    def excluded(self):\n        \"\"\"Get the types being excluded (tuple).\"\"\"\n        return tuple(_keys(self._excl_d))\n\n    @property\n    def frames(self):\n        \"\"\"Ignore stack frames (bool).\"\"\"\n        return self._frames_\n\n    @property\n    def ignored(self):\n        \"\"\"Ignore certain types (bool).\"\"\"\n        return True if self._ign_d else False\n\n    @property\n    def infer(self):\n        \"\"\"Infer types (bool).\"\"\"\n        return self._infer_\n\n    @property\n    def limit(self):\n        \"\"\"Get the recursion limit (int).\"\"\"\n        return self._limit_\n\n    @property\n    def missed(self):\n        \"\"\"Get the number of objects missed due to errors (int).\"\"\"\n        return self._missed\n\n    def print_largest(self, w=0, cutoff=0, **print3options):\n        \"\"\"Print the largest objects.\n\n        The available options and defaults are:\n\n         *w=0*           -- indentation for each line\n\n         *cutoff=100*    -- number of largest objects to print\n\n         *print3options* -- some keyword arguments, like Python 3+ print\n        \"\"\"\n        c = int(cutoff) if cutoff else self._cutoff_\n        n = min(len(self._ranks), max(c, 0))\n        s = self._above_\n        if n > 0 and s > 0:\n            self._printf(\n                \"%s%*d largest object%s (of %d over %d bytes%s)\",\n                linesep,\n                w,\n                n,\n                _plural(n),\n                self._ranked,\n                s,\n                _SI(s),\n                **print3options,\n            )\n            id2x = dict((r.id, i) for i, r in enumerate(self._ranks))\n            for r in self._ranks[:n]:\n                s, t = r.size, r.format(self._clip_, id2x)\n                self._printf(\"%*d bytes%s: %s\", w, s, _SI(s), t, **print3options)\n\n    def print_profiles(self, w=0, cutoff=0, **print3options):\n        \"\"\"Print the profiles above *cutoff* percentage.\n\n        The available options and defaults are:\n\n             *w=0*           -- indentation for each line\n\n             *cutoff=0*      -- minimum percentage printed\n\n             *print3options* -- some keyword arguments, like Python 3+ print\n        \"\"\"\n        # get the profiles with non-zero size or count\n        t = [(v, k) for k, v in _items(self._profs) if v.total > 0 or v.number > 1]\n        if (len(self._profs) - len(t)) < 9:  # just show all\n            t = [(v, k) for k, v in _items(self._profs)]\n        if t:\n            s = _NN\n            if self._total:\n                s = \" (% of grand total)\"\n                c = int(cutoff) if cutoff else self._cutoff_\n                C = int(c * 0.01 * self._total)\n            else:\n                C = c = 0\n            self._printf(\n                \"%s%*d profile%s:  total%s, average, and largest flat size%s:  largest object\",\n                linesep,\n                w,\n                len(t),\n                _plural(len(t)),\n                s,\n                self._incl,\n                **print3options,\n            )\n            r = len(t)\n            t = [\n                (v, self._prepr(k)) for v, k in t\n            ]  # replace types with str for Python 3.11+\n            for v, k in sorted(t, reverse=True):\n                s = (\n                    \"object%(plural)s:  %(total)s, %(avg)s, %(high)s:  %(obj)s%(lengstr)s\"\n                    % v.format(self._clip_, self._total)\n                )\n                self._printf(\"%*d %s %s\", w, v.number, k, s, **print3options)\n                r -= 1\n                if r > 1 and v.total < C:\n                    self._printf(\"%+*d profiles below cutoff (%.0f%%)\", w, r, c)\n                    break\n            z = len(self._profs) - len(t)\n            if z > 0:\n                self._printf(\n                    \"%+*d %r object%s\", w, z, \"zero\", _plural(z), **print3options\n                )\n\n    def print_stats(\n        self, objs=(), opts={}, sized=(), sizes=(), stats=3, **print3options\n    ):\n        \"\"\"Prints the statistics.\n\n        The available options and defaults are:\n\n             *w=0*           -- indentation for each line\n\n             *objs=()*       -- optional, list of objects\n\n             *opts={}*       -- optional, dict of options used\n\n             *sized=()*      -- optional, tuple of **Asized** instances returned\n\n             *sizes=()*      -- optional, tuple of sizes returned\n\n             *stats=3*       -- print stats, see function **asizeof**\n\n             *print3options* -- some keyword arguments, like Python 3+ print\n        \"\"\"\n        s = min(opts.get(\"stats\", stats) or 0, self.stats)\n        if s > 0:  # print stats\n            w = len(str(self.missed + self.seen + self.total)) + 1\n            t = c = _NN\n            o = _kwdstr(**opts)\n            if o and objs:\n                c = \", \"\n            # print header line(s)\n            if sized and objs:\n                n = len(objs)\n                if n > 1:\n                    self._printf(\n                        \"%sasized(...%s%s) ...\", linesep, c, o, **print3options\n                    )\n                    for i in range(n):  # no enumerate in Python 2.2.3\n                        self._printf(\"%*d: %s\", w - 1, i, sized[i], **print3options)\n                else:\n                    self._printf(\"%sasized(%s): %s\", linesep, o, sized, **print3options)\n            elif sizes and objs:\n                self._printf(\"%sasizesof(...%s%s) ...\", linesep, c, o, **print3options)\n                for z, o in zip(sizes, objs):\n                    self._printf(\n                        \"%*d bytes%s%s:  %s\",\n                        w,\n                        z,\n                        _SI(z),\n                        self._incl,\n                        self._repr(o),\n                        **print3options,\n                    )\n            else:\n                if objs:\n                    t = self._repr(objs)\n                self._printf(\"%sasizeof(%s%s%s) ...\", linesep, t, c, o, **print3options)\n            # print summary\n            self.print_summary(w=w, objs=objs, **print3options)\n            # for backward compatibility, cutoff from fractional stats\n            s, c = self._c100(s)\n            self.print_largest(w=w, cutoff=c if s < 2 else 10, **print3options)\n            if s > 1:  # print profile\n                self.print_profiles(w=w, cutoff=c, **print3options)\n                if s > 2:  # print typedefs\n                    self.print_typedefs(w=w, **print3options)  # PYCHOK .print_largest?\n\n    def print_summary(self, w=0, objs=(), **print3options):\n        \"\"\"Print the summary statistics.\n\n        The available options and defaults are:\n\n             *w=0*           -- indentation for each line\n\n             *objs=()*       -- optional, list of objects\n\n             *print3options* -- some keyword arguments, like Python 3+ print\n        \"\"\"\n        self._printf(\n            \"%*d bytes%s%s\",\n            w,\n            self._total,\n            _SI(self._total),\n            self._incl,\n            **print3options,\n        )\n        if self._mask:\n            self._printf(\"%*d byte aligned\", w, self._mask + 1, **print3options)\n        self._printf(\"%*d byte sizeof(void*)\", w, _sizeof_Cvoidp, **print3options)\n        n = len(objs or ())\n        self._printf(\"%*d object%s %s\", w, n, _plural(n), \"given\", **print3options)\n        n = self.sized\n        self._printf(\"%*d object%s %s\", w, n, _plural(n), \"sized\", **print3options)\n        if self._excl_d:\n            n = sum(_values(self._excl_d))\n            self._printf(\n                \"%*d object%s %s\", w, n, _plural(n), \"excluded\", **print3options\n            )\n        n = self.seen\n        self._printf(\"%*d object%s %s\", w, n, _plural(n), \"seen\", **print3options)\n        n = self.ranked\n        if n > 0:\n            self._printf(\"%*d object%s %s\", w, n, _plural(n), \"ranked\", **print3options)\n        n = self.missed\n        self._printf(\"%*d object%s %s\", w, n, _plural(n), \"missed\", **print3options)\n        n = self.duplicate\n        self._printf(\"%*d duplicate%s\", w, n, _plural(n), **print3options)\n        if self._depth > 0:\n            self._printf(\"%*d deepest recursion\", w, self._depth, **print3options)\n\n    def print_typedefs(self, w=0, **print3options):\n        \"\"\"Print the types and dict tables.\n\n        The available options and defaults are:\n\n             *w=0*           -- indentation for each line\n\n             *print3options* -- some keyword arguments, like Python 3+ print\n        \"\"\"\n        for k in _all_kinds:\n            # XXX Python 3+ doesn't sort type objects\n            t = [\n                (self._prepr(a), v)\n                for a, v in _items(_typedefs)\n                if v.kind == k and (v.both or self._code_)\n            ]\n            if t:\n                self._printf(\n                    \"%s%*d %s type%s:  basicsize, itemsize, _len_(), _refs()\",\n                    linesep,\n                    w,\n                    len(t),\n                    k,\n                    _plural(len(t)),\n                    **print3options,\n                )\n                for a, v in sorted(t):\n                    self._printf(\"%*s %s:  %s\", w, _NN, a, v, **print3options)\n        # dict and dict-like classes\n        t = sum(len(v) for v in _values(_dict_types))\n        if t:\n            self._printf(\"%s%*d dict/-like classes:\", linesep, w, t, **print3options)\n            for m, v in _items(_dict_types):\n                self._printf(\"%*s %s:  %s\", w, _NN, m, self._prepr(v), **print3options)\n\n    @property\n    def ranked(self):\n        \"\"\"Get the number objects ranked by size so far (int).\"\"\"\n        return self._ranked\n\n    def reset(\n        self,\n        above=1024,\n        align=8,\n        clip=80,\n        code=False,  # PYCHOK too many args\n        cutoff=10,\n        derive=False,\n        detail=0,\n        frames=False,\n        ignored=True,\n        infer=False,\n        limit=100,\n        stats=0,\n        stream=None,\n        **extra,\n    ):\n        \"\"\"Reset sizing options, state, etc. to defaults.\n\n        The available options and default values are:\n\n             *above=0*      -- threshold for largest objects stats\n\n             *align=8*      -- size alignment\n\n             *code=False*   -- incl. (byte)code size\n\n             *cutoff=10*    -- limit large objects or profiles stats\n\n             *derive=False* -- derive from super type\n\n             *detail=0*     -- **Asized** refs level\n\n             *frames=False* -- ignore frame objects\n\n             *ignored=True* -- ignore certain types\n\n             *infer=False*  -- try to infer types\n\n             *limit=100*    -- recursion limit\n\n             *stats=0*      -- print statistics, see function **asizeof**\n\n             *stream=None*  -- output stream for printing\n\n        See function **asizeof** for a description of the options.\n        \"\"\"\n        if extra:\n            raise _OptionError(self.reset, Error=KeyError, **extra)\n        # options\n        self._above_ = above\n        self._align_ = align\n        self._clip_ = clip\n        self._code_ = code\n        self._cutoff_ = cutoff\n        self._derive_ = derive\n        self._detail_ = detail  # for Asized only\n        self._frames_ = frames\n        self._infer_ = infer\n        self._limit_ = limit\n        self._stats_ = stats\n        self._stream = stream\n        if ignored:\n            self._ign_d = _kind_ignored\n        else:\n            self._ign_d = None\n        # clear state\n        self._clear()\n        self.set(align=align, code=code, cutoff=cutoff, stats=stats)\n\n    @property\n    def seen(self):\n        \"\"\"Get the number objects seen so far (int).\"\"\"\n        return sum(v for v in _values(self._seen) if v > 0)\n\n    def set(\n        self,\n        above=None,\n        align=None,\n        code=None,\n        cutoff=None,\n        frames=None,\n        detail=None,\n        limit=None,\n        stats=None,\n    ):\n        \"\"\"Set some sizing options.  See also **reset**.\n\n        The available options are:\n\n             *above*  -- threshold for largest objects stats\n\n             *align*  -- size alignment\n\n             *code*   -- incl. (byte)code size\n\n             *cutoff* -- limit large objects or profiles stats\n\n             *detail* -- **Asized** refs level\n\n             *frames* -- size or ignore frame objects\n\n             *limit*  -- recursion limit\n\n             *stats*  -- print statistics, see function **asizeof**\n\n        Any options not set remain unchanged from the previous setting.\n        \"\"\"\n        # adjust\n        if above is not None:\n            self._above_ = int(above)\n        if align is not None:\n            if align > 1:\n                m = align - 1\n                if m & align:\n                    raise _OptionError(self.set, align=align)\n            else:\n                m = 0\n            self._align_ = align\n            self._mask = m\n        if code is not None:\n            self._code_ = code\n            if code:  # incl. (byte)code\n                self._incl = \" (incl. code)\"\n        if detail is not None:\n            self._detail_ = detail\n        if frames is not None:\n            self._frames_ = frames\n        if limit is not None:\n            self._limit_ = limit\n        if stats is not None:\n            if stats < 0:\n                raise _OptionError(self.set, stats=stats)\n            # for backward compatibility, cutoff from fractional stats\n            s, c = self._c100(stats)\n            self._cutoff_ = int(cutoff) if cutoff else c\n            self._stats_ = s\n            self._profile = s > 1  # profile types\n\n    @property\n    def sized(self):\n        \"\"\"Get the number objects sized so far (int).\"\"\"\n        return sum(1 for v in _values(self._seen) if v > 0)\n\n    @property\n    def stats(self):\n        \"\"\"Get the stats and cutoff setting (float).\"\"\"\n        return self._stats_  # + (self._cutoff_ * 0.01)\n\n    @property\n    def total(self):\n        \"\"\"Get the total size (in bytes) accumulated so far.\"\"\"\n        return self._total\n\n\ndef amapped(percentage=None):\n    \"\"\"Set/get approximate mapped memory usage as a percentage\n    of the mapped file size.\n\n    Sets the new percentage if not None and returns the\n    previously set percentage.\n\n    Applies only to *numpy.memmap* objects.\n    \"\"\"\n    global _amapped\n    p = _amapped * 100.0\n    if percentage is not None:\n        _amapped = max(0, min(1, percentage * 0.01))\n    return p\n\n\n_amapped = 0.01  # 0 <= percentage <= 1.0\n_asizer = Asizer()\n\n\ndef asized(*objs, **opts):\n    \"\"\"Return a tuple containing an **Asized** instance for each\n    object passed as positional argument.\n\n    The available options and defaults are:\n\n         *above=0*      -- threshold for largest objects stats\n\n         *align=8*      -- size alignment\n\n         *code=False*   -- incl. (byte)code size\n\n         *cutoff=10*    -- limit large objects or profiles stats\n\n         *derive=False* -- derive from super type\n\n         *detail=0*     -- Asized refs level\n\n         *frames=False* -- ignore stack frame objects\n\n         *ignored=True* -- ignore certain types\n\n         *infer=False*  -- try to infer types\n\n         *limit=100*    -- recursion limit\n\n         *stats=0*      -- print statistics\n\n    If only one object is given, the return value is the **Asized**\n    instance for that object.  Otherwise, the length of the returned\n    tuple matches the number of given objects.\n\n    The **Asized** size of duplicate and ignored objects will be zero.\n\n    Set *detail* to the desired referents level and *limit* to the\n    maximum recursion depth.\n\n    See function **asizeof** for descriptions of the other options.\n    \"\"\"\n    _asizer.reset(**opts)\n    if objs:\n        t = _asizer.asized(*objs)\n        _asizer.print_stats(objs, opts=opts, sized=t)  # show opts as _kwdstr\n        _asizer._clear()\n    else:\n        t = ()\n    return t\n\n\ndef asizeof(*objs, **opts):\n    \"\"\"Return the combined size (in bytes) of all objects passed\n    as positional arguments.\n\n    The available options and defaults are:\n\n         *above=0*      -- threshold for largest objects stats\n\n         *align=8*      -- size alignment\n\n         *clip=80*      -- clip ``repr()`` strings\n\n         *code=False*   -- incl. (byte)code size\n\n         *cutoff=10*    -- limit large objects or profiles stats\n\n         *derive=False* -- derive from super type\n\n         *frames=False* -- ignore stack frame objects\n\n         *ignored=True* -- ignore certain types\n\n         *infer=False*  -- try to infer types\n\n         *limit=100*    -- recursion limit\n\n         *stats=0*      -- print statistics\n\n    Set *align* to a power of 2 to align sizes.  Any value less\n    than 2 avoids size alignment.\n\n    If *all* is True and if no positional arguments are supplied.\n    size all current gc objects, including module, global and stack\n    frame objects.\n\n    A positive *clip* value truncates all repr() strings to at\n    most *clip* characters.\n\n    The (byte)code size of callable objects like functions,\n    methods, classes, etc. is included only if *code* is True.\n\n    If *derive* is True, new types are handled like an existing\n    (super) type provided there is one and only of those.\n\n    By default certain base types like object, super, etc. are\n    ignored.  Set *ignored* to False to include those.\n\n    If *infer* is True, new types are inferred from attributes\n    (only implemented for dict types on callable attributes\n    as get, has_key, items, keys and values).\n\n    Set *limit* to a positive value to accumulate the sizes of\n    the referents of each object, recursively up to the limit.\n    Using *limit=0* returns the sum of the flat sizes of the\n    given objects.  High *limit* values may cause runtime errors\n    and miss objects for sizing.\n\n    A positive value for *stats* prints up to 9 statistics, (1)\n    a summary of the number of objects sized and seen and a list\n    of the largests objects with size over *above* bytes, (2) a\n    simple profile of the sized objects by type and (3+) up to 6\n    tables showing the static, dynamic, derived, ignored, inferred\n    and dict types used, found respectively installed.\n    The fractional part of the *stats* value (x 100) is the number\n    of largest objects shown for (*stats*1.+) or the cutoff\n    percentage for simple profiles for (*stats*=2.+).  For example,\n    *stats=1.10* shows the summary and the 10 largest objects,\n    also the default.\n\n    See this module documentation for the definition of flat size.\n    \"\"\"\n    t, p, x = _objs_opts_x(asizeof, objs, **opts)\n    _asizer.reset(**p)\n    if t:\n        if x:  # don't size, profile or rank _getobjects tuple\n            _asizer.exclude_objs(t)\n        s = _asizer.asizeof(*t)\n        _asizer.print_stats(objs=t, opts=opts)  # show opts as _kwdstr\n        _asizer._clear()\n    else:\n        s = 0\n    return s\n\n\ndef asizesof(*objs, **opts):\n    \"\"\"Return a tuple containing the size (in bytes) of all objects\n    passed as positional arguments.\n\n    The available options and defaults are:\n\n         *above=1024*   -- threshold for largest objects stats\n\n         *align=8*      -- size alignment\n\n         *clip=80*      -- clip ``repr()`` strings\n\n         *code=False*   -- incl. (byte)code size\n\n         *cutoff=10*    -- limit large objects or profiles stats\n\n         *derive=False* -- derive from super type\n\n         *frames=False* -- ignore stack frame objects\n\n         *ignored=True* -- ignore certain types\n\n         *infer=False*  -- try to infer types\n\n         *limit=100*    -- recursion limit\n\n         *stats=0*      -- print statistics\n\n    See function **asizeof** for a description of the options.\n\n    The length of the returned tuple equals the number of given\n    objects.\n\n    The size of duplicate and ignored objects will be zero.\n    \"\"\"\n    _asizer.reset(**opts)\n    if objs:\n        t = _asizer.asizesof(*objs)\n        _asizer.print_stats(objs, opts=opts, sizes=t)  # show opts as _kwdstr\n        _asizer._clear()\n    else:\n        t = ()\n    return t\n\n\ndef _typedefof(obj, save=False, **opts):\n    \"\"\"Get the typedef for an object.\"\"\"\n    k = _objkey(obj)\n    v = _typedefs.get(k, None)\n    if not v:  # new typedef\n        v = _typedef(obj, **opts)\n        if save:\n            _typedefs[k] = v\n    return v\n\n\ndef basicsize(obj, **opts):\n    \"\"\"Return the basic size of an object (in bytes).\n\n    The available options and defaults are:\n\n        *derive=False* -- derive type from super type\n\n        *infer=False*  -- try to infer types\n\n        *save=False*   -- save the object's type definition if new\n\n    See this module documentation for the definition of *basic size*.\n    \"\"\"\n    b = t = _typedefof(obj, **opts)\n    if t:\n        b = t.base\n    return b\n\n\ndef flatsize(obj, align=0, **opts):\n    \"\"\"Return the flat size of an object (in bytes), optionally aligned\n    to the given power-of-2.\n\n    See function **basicsize** for a description of other available options.\n\n    See this module documentation for the definition of *flat size*.\n    \"\"\"\n    f = t = _typedefof(obj, **opts)\n    if t:\n        if align > 1:\n            m = align - 1\n            if m & align:\n                raise _OptionError(flatsize, align=align)\n        else:\n            m = 0\n        f = t.flat(obj, mask=m)\n    return f\n\n\ndef itemsize(obj, **opts):\n    \"\"\"Return the item size of an object (in bytes).\n\n    See function **basicsize** for a description of the available options.\n\n    See this module documentation for the definition of *item size*.\n    \"\"\"\n    i = t = _typedefof(obj, **opts)\n    if t:\n        i, v = t.item, t.vari\n        if v and i == _sizeof_Cbyte:\n            i = getattr(obj, v, i)\n    return i\n\n\ndef leng(obj, **opts):\n    \"\"\"Return the length of an object, in number of *items*.\n\n    See function **basicsize** for a description of the available options.\n    \"\"\"\n    n = t = _typedefof(obj, **opts)\n    if t:\n        n = t.leng\n        if n and callable(n):\n            i, v, n = t.item, t.vari, n(obj)\n            if v and i == _sizeof_Cbyte:\n                i = getattr(obj, v, i)\n                if i > _sizeof_Cbyte:\n                    n = n // i\n    return n\n\n\ndef named_refs(obj, **opts):\n    \"\"\"Return all named **referents** of an object (re-using\n    functionality from **asizeof**).\n\n    Does not return un-named *referents*, e.g. objects in a list.\n\n    See function **basicsize** for a description of the available options.\n    \"\"\"\n    rs = []\n    v = _typedefof(obj, **opts)\n    if v:\n        v = v.refs\n        if v and callable(v):\n            for r in v(obj, True):\n                try:\n                    rs.append((r.name, r.ref))\n                except AttributeError:\n                    pass\n    return rs\n\n\ndef refs(obj, **opts):\n    \"\"\"Return (a generator for) specific *referents* of an object.\n\n    See function **basicsize** for a description of the available options.\n    \"\"\"\n    v = _typedefof(obj, **opts)\n    if v:\n        v = v.refs\n        if v and callable(v):\n            v = v(obj, False)\n    return v\n\n\n# License from the initial version of this source file follows:\n\n# --------------------------------------------------------------------\n#       Copyright (c) 2002-2022 -- ProphICy Semiconductor, Inc.\n#                        All rights reserved.\n#\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions\n# are met:\n#\n# - Redistributions of source code must retain the above copyright\n#   notice, this list of conditions and the following disclaimer.\n#\n# - Redistributions in binary form must reproduce the above copyright\n#   notice, this list of conditions and the following disclaimer in\n#   the documentation and/or other materials provided with the\n#   distribution.\n#\n# - Neither the name of ProphICy Semiconductor, Inc. nor the names\n#   of its contributors may be used to endorse or promote products\n#   derived from this software without specific prior written\n#   permission.\n#\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n# \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS\n# FOR A PARTICULAR PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE\n# COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,\n# INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n# (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n# SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)\n# HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,\n# STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED\n# OF THE POSSIBILITY OF SUCH DAMAGE.\n# --------------------------------------------------------------------\n", "lib/streamlit/vendor/pympler/__init__.py": "", "lib/streamlit/vendor/ipython/modified_sys_path.py": "# BSD 3-Clause License\n#\n# - Copyright (c) 2008-Present, IPython Development Team\n# - Copyright (c) 2001-2007, Fernando Perez <fernando.perez@colorado.edu>\n# - Copyright (c) 2001, Janko Hauser <jhauser@zscout.de>\n# - Copyright (c) 2001, Nathaniel Gray <n8gray@caltech.edu>\n#\n# All rights reserved.\n#\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions are met:\n#\n# * Redistributions of source code must retain the above copyright notice, this\n#   list of conditions and the following disclaimer.\n\n# * Redistributions in binary form must reproduce the above copyright notice,\n#   this list of conditions and the following disclaimer in the documentation\n#   and/or other materials provided with the distribution.\n\n# * Neither the name of the copyright holder nor the names of its\n#   contributors may be used to endorse or promote products derived from\n#   this software without specific prior written permission.\n\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n# FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n# SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n# CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n# OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n# Code modified from IPython (BSD license)\n# Source: https://github.com/ipython/ipython/blob/master/IPython/utils/syspathcontext.py#L42\n\nimport sys\n\nfrom streamlit import util\n\n\nclass modified_sys_path:\n    \"\"\"A context for prepending a directory to sys.path for a second.\"\"\"\n\n    def __init__(self, main_script_path: str):\n        self._main_script_path = main_script_path\n        self._added_path = False\n\n    def __repr__(self) -> str:\n        return util.repr_(self)\n\n    def __enter__(self):\n        if self._main_script_path not in sys.path:\n            sys.path.insert(0, self._main_script_path)\n            self._added_path = True\n\n    def __exit__(self, type, value, traceback):\n        if self._added_path:\n            try:\n                sys.path.remove(self._main_script_path)\n            except ValueError:\n                # It's already removed.\n                pass\n\n        # Returning False causes any exceptions to be re-raised.\n        return False\n", "lib/streamlit/vendor/ipython/__init__.py": "", "lib/streamlit/external/__init__.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n", "lib/streamlit/external/langchain/streamlit_callback_handler.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"\nLangChain CallbackHandler that prints to streamlit.\n\nThis is a special API that's imported and used by LangChain itself. Any updates\nto the public API (the StreamlitCallbackHandler constructor, and the entirety\nof LLMThoughtLabeler) *must* remain backwards-compatible to avoid breaking\nLangChain.\n\nThis means that it's acceptable to add new optional kwargs to StreamlitCallbackHandler,\nbut no new positional args or required kwargs should be added, and no existing\nargs should be removed. If we need to overhaul the API, we must ensure that a\ncompatible API continues to exist.\n\nAny major change to the StreamlitCallbackHandler should be tested by importing\nthe API *from LangChain itself*.\n\nThis module is lazy-loaded.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport time\nfrom enum import Enum\nfrom typing import TYPE_CHECKING, Any, NamedTuple\n\nfrom langchain.callbacks.base import (  # type: ignore[import-not-found, unused-ignore]\n    BaseCallbackHandler,\n)\n\nfrom streamlit.runtime.metrics_util import gather_metrics\n\nif TYPE_CHECKING:\n    from langchain.schema import (  # type: ignore[import-not-found, unused-ignore]\n        AgentAction,\n        AgentFinish,\n        LLMResult,\n    )\n\n    from streamlit.delta_generator import DeltaGenerator\n    from streamlit.elements.lib.mutable_status_container import StatusContainer\n\n\ndef _convert_newlines(text: str) -> str:\n    \"\"\"Convert newline characters to markdown newline sequences\n    (space, space, newline).\n    \"\"\"\n    return text.replace(\"\\n\", \"  \\n\")\n\n\n# The maximum length of the \"input_str\" portion of a tool label.\n# Strings that are longer than this will be truncated with \"...\"\nMAX_TOOL_INPUT_STR_LENGTH = 60\n\n\nclass LLMThoughtState(Enum):\n    # The LLM is thinking about what to do next. We don't know which tool we'll run.\n    THINKING = \"THINKING\"\n    # The LLM has decided to run a tool. We don't have results from the tool yet.\n    RUNNING_TOOL = \"RUNNING_TOOL\"\n    # We have results from the tool.\n    COMPLETE = \"COMPLETE\"\n    # The LLM completed with an error.\n    ERROR = \"ERROR\"\n\n\nclass ToolRecord(NamedTuple):\n    name: str\n    input_str: str\n\n\nclass LLMThoughtLabeler:\n    \"\"\"\n    Generates markdown labels for LLMThought containers. Pass a custom\n    subclass of this to StreamlitCallbackHandler to override its default\n    labeling logic.\n    \"\"\"\n\n    def get_initial_label(self) -> str:\n        \"\"\"Return the markdown label for a new LLMThought that doesn't have\n        an associated tool yet.\n        \"\"\"\n        return \"Thinking...\"\n\n    def get_tool_label(self, tool: ToolRecord, is_complete: bool) -> str:\n        \"\"\"Return the label for an LLMThought that has an associated\n        tool.\n\n        Parameters\n        ----------\n        tool\n            The tool's ToolRecord\n\n        is_complete\n            True if the thought is complete; False if the thought\n            is still receiving input.\n\n        Returns\n        -------\n        The markdown label for the thought's container.\n\n        \"\"\"\n        input_str = tool.input_str\n        name = tool.name\n        if name == \"_Exception\":\n            name = \"Parsing error\"\n        input_str_len = min(MAX_TOOL_INPUT_STR_LENGTH, len(input_str))\n        input_str = input_str[:input_str_len]\n        if len(tool.input_str) > input_str_len:\n            input_str = input_str + \"...\"\n        input_str = input_str.replace(\"\\n\", \" \")\n        return f\"**{name}:** {input_str}\"\n\n    def get_final_agent_thought_label(self) -> str:\n        \"\"\"Return the markdown label for the agent's final thought -\n        the \"Now I have the answer\" thought, that doesn't involve\n        a tool.\n        \"\"\"\n        return \"**Complete!**\"\n\n\nclass LLMThought:\n    \"\"\"Encapsulates the Streamlit UI for a single LLM 'thought' during a LangChain Agent\n    run. Each tool usage gets its own thought; and runs also generally having a\n    concluding thought where the Agent determines that it has an answer to the prompt.\n\n    Each thought gets its own expander UI.\n    \"\"\"\n\n    def __init__(\n        self,\n        parent_container: DeltaGenerator,\n        labeler: LLMThoughtLabeler,\n        expanded: bool,\n        collapse_on_complete: bool,\n    ):\n        self._container = parent_container.status(\n            labeler.get_initial_label(), expanded=expanded\n        )\n\n        self._state = LLMThoughtState.THINKING\n        self._llm_token_stream = \"\"\n        self._llm_token_stream_placeholder: DeltaGenerator | None = None\n        self._last_tool: ToolRecord | None = None\n        self._collapse_on_complete = collapse_on_complete\n        self._labeler = labeler\n\n    @property\n    def container(self) -> StatusContainer:\n        \"\"\"The container we're writing into.\"\"\"\n        return self._container\n\n    @property\n    def last_tool(self) -> ToolRecord | None:\n        \"\"\"The last tool executed by this thought\"\"\"\n        return self._last_tool\n\n    def _reset_llm_token_stream(self) -> None:\n        if self._llm_token_stream_placeholder is not None:\n            self._llm_token_stream_placeholder.markdown(self._llm_token_stream)\n\n        self._llm_token_stream = \"\"\n        self._llm_token_stream_placeholder = None\n\n    def on_llm_start(self, serialized: dict[str, Any], prompts: list[str]) -> None:\n        self._reset_llm_token_stream()\n\n    def on_llm_new_token(self, token: str, **kwargs: Any) -> None:\n        # This is only called when the LLM is initialized with `streaming=True`\n        self._llm_token_stream += _convert_newlines(token)\n        if self._llm_token_stream_placeholder is None:\n            self._llm_token_stream_placeholder = self._container.empty()\n        self._llm_token_stream_placeholder.markdown(self._llm_token_stream + \"\u2595\")\n\n    def on_llm_end(self, response: LLMResult, **kwargs: Any) -> None:\n        # `response` is the concatenation of all the tokens received by the LLM.\n        # If we're receiving streaming tokens from `on_llm_new_token`, this response\n        # data is redundant\n        self._reset_llm_token_stream()\n        # set the container status to complete\n        self.complete(self._labeler.get_final_agent_thought_label())\n\n    def on_llm_error(self, error: BaseException, *args: Any, **kwargs: Any) -> None:\n        self._container.exception(error)\n        self._state = LLMThoughtState.ERROR\n        self.complete(\"LLM encountered an error...\")\n\n    def on_tool_start(\n        self, serialized: dict[str, Any], input_str: str, **kwargs: Any\n    ) -> None:\n        # Called with the name of the tool we're about to run (in `serialized[name]`),\n        # and its input. We change our container's label to be the tool name.\n        self._state = LLMThoughtState.RUNNING_TOOL\n        tool_name = serialized[\"name\"]\n        self._last_tool = ToolRecord(name=tool_name, input_str=input_str)\n        self._container.update(\n            label=self._labeler.get_tool_label(self._last_tool, is_complete=False),\n            state=\"running\",\n        )\n        if len(input_str) > MAX_TOOL_INPUT_STR_LENGTH:\n            # output is printed later in on_tool_end\n            self._container.markdown(f\"**Input:**\\n\\n{input_str}\\n\\n**Output:**\")\n\n    def on_tool_end(\n        self,\n        output: str,\n        color: str | None = None,\n        observation_prefix: str | None = None,\n        llm_prefix: str | None = None,\n        **kwargs: Any,\n    ) -> None:\n        self._container.markdown(output)\n\n    def on_tool_error(self, error: BaseException, *args: Any, **kwargs: Any) -> None:\n        self._container.markdown(\"**Tool encountered an error...**\")\n        self._container.exception(error)\n        self._container.update(state=\"error\")\n\n    def on_agent_action(\n        self, action: AgentAction, color: str | None = None, **kwargs: Any\n    ) -> Any:\n        # Called when we're about to kick off a new tool. The `action` data\n        # tells us the tool we're about to use, and the input we'll give it.\n        # We don't output anything here, because we'll receive this same data\n        # when `on_tool_start` is called immediately after.\n        pass\n\n    def complete(self, final_label: str | None = None) -> None:\n        \"\"\"Finish the thought.\"\"\"\n        if final_label is None and self._state == LLMThoughtState.RUNNING_TOOL:\n            assert (\n                self._last_tool is not None\n            ), \"_last_tool should never be null when _state == RUNNING_TOOL\"\n            final_label = self._labeler.get_tool_label(\n                self._last_tool, is_complete=True\n            )\n\n        if self._last_tool and self._last_tool.name == \"_Exception\":\n            self._state = LLMThoughtState.ERROR\n        elif self._state != LLMThoughtState.ERROR:\n            self._state = LLMThoughtState.COMPLETE\n\n        if self._collapse_on_complete:\n            # Add a quick delay to show the user the final output before we collapse\n            time.sleep(0.25)\n\n        self._container.update(\n            label=final_label,\n            expanded=False if self._collapse_on_complete else None,\n            state=\"error\" if self._state == LLMThoughtState.ERROR else \"complete\",\n        )\n\n\nclass StreamlitCallbackHandler(BaseCallbackHandler):\n    @gather_metrics(\"external.langchain.StreamlitCallbackHandler\")\n    def __init__(\n        self,\n        parent_container: DeltaGenerator,\n        *,\n        max_thought_containers: int = 4,\n        expand_new_thoughts: bool = False,\n        collapse_completed_thoughts: bool = False,\n        thought_labeler: LLMThoughtLabeler | None = None,\n    ):\n        \"\"\"Construct a new StreamlitCallbackHandler. This CallbackHandler is geared\n        towards use with a LangChain Agent; it displays the Agent's LLM and tool-usage\n        \"thoughts\" inside a series of Streamlit expanders.\n\n        Parameters\n        ----------\n\n        parent_container\n            The `st.container` that will contain all the Streamlit elements that the\n            Handler creates.\n\n        max_thought_containers\n\n            .. note::\n                This parameter is deprecated and is ignored in the latest version of\n                the callback handler.\n\n            The max number of completed LLM thought containers to show at once. When\n            this threshold is reached, a new thought will cause the oldest thoughts to\n            be collapsed into a \"History\" expander. Defaults to 4.\n\n        expand_new_thoughts\n            Each LLM \"thought\" gets its own `st.expander`. This param controls whether\n            that expander is expanded by default. Defaults to False.\n\n        collapse_completed_thoughts\n            If True, LLM thought expanders will be collapsed when completed.\n            Defaults to False.\n\n        thought_labeler\n            An optional custom LLMThoughtLabeler instance. If unspecified, the handler\n            will use the default thought labeling logic. Defaults to None.\n        \"\"\"\n        self._parent_container = parent_container\n        self._history_parent = parent_container.container()\n        self._current_thought: LLMThought | None = None\n        self._completed_thoughts: list[LLMThought] = []\n        self._max_thought_containers = max(max_thought_containers, 1)\n        self._expand_new_thoughts = expand_new_thoughts\n        self._collapse_completed_thoughts = collapse_completed_thoughts\n        self._thought_labeler = thought_labeler or LLMThoughtLabeler()\n\n    def _require_current_thought(self) -> LLMThought:\n        \"\"\"Return our current LLMThought. Raise an error if we have no current\n        thought.\n        \"\"\"\n        if self._current_thought is None:\n            raise RuntimeError(\"Current LLMThought is unexpectedly None!\")\n        return self._current_thought\n\n    def _get_last_completed_thought(self) -> LLMThought | None:\n        \"\"\"Return our most recent completed LLMThought, or None if we don't have one.\"\"\"\n        if len(self._completed_thoughts) > 0:\n            return self._completed_thoughts[len(self._completed_thoughts) - 1]\n        return None\n\n    def _complete_current_thought(self, final_label: str | None = None) -> None:\n        \"\"\"Complete the current thought, optionally assigning it a new label.\n        Add it to our _completed_thoughts list.\n        \"\"\"\n        thought = self._require_current_thought()\n        thought.complete(final_label)\n        self._completed_thoughts.append(thought)\n        self._current_thought = None\n\n    def on_llm_start(\n        self, serialized: dict[str, Any], prompts: list[str], **kwargs: Any\n    ) -> None:\n        if self._current_thought is None:\n            self._current_thought = LLMThought(\n                parent_container=self._parent_container,\n                expanded=self._expand_new_thoughts,\n                collapse_on_complete=self._collapse_completed_thoughts,\n                labeler=self._thought_labeler,\n            )\n\n        self._current_thought.on_llm_start(serialized, prompts)\n\n        # We don't prune_old_thought_containers here, because our container won't\n        # be visible until it has a child.\n\n    def on_llm_new_token(self, token: str, **kwargs: Any) -> None:\n        self._require_current_thought().on_llm_new_token(token, **kwargs)\n\n    def on_llm_end(self, response: LLMResult, **kwargs: Any) -> None:\n        self._require_current_thought().on_llm_end(response, **kwargs)\n\n    def on_llm_error(self, error: BaseException, *args: Any, **kwargs: Any) -> None:\n        self._require_current_thought().on_llm_error(error, **kwargs)\n\n    def on_tool_start(\n        self, serialized: dict[str, Any], input_str: str, **kwargs: Any\n    ) -> None:\n        self._require_current_thought().on_tool_start(serialized, input_str, **kwargs)\n\n    def on_tool_end(\n        self,\n        output: str,\n        color: str | None = None,\n        observation_prefix: str | None = None,\n        llm_prefix: str | None = None,\n        **kwargs: Any,\n    ) -> None:\n        self._require_current_thought().on_tool_end(\n            output, color, observation_prefix, llm_prefix, **kwargs\n        )\n        self._complete_current_thought()\n\n    def on_tool_error(self, error: BaseException, *args: Any, **kwargs: Any) -> None:\n        self._require_current_thought().on_tool_error(error, **kwargs)\n\n    def on_agent_action(\n        self, action: AgentAction, color: str | None = None, **kwargs: Any\n    ) -> Any:\n        self._require_current_thought().on_agent_action(action, color, **kwargs)\n\n    def on_agent_finish(\n        self, finish: AgentFinish, color: str | None = None, **kwargs: Any\n    ) -> None:\n        if self._current_thought is not None:\n            self._current_thought.complete(\n                self._thought_labeler.get_final_agent_thought_label()\n            )\n            self._current_thought = None\n", "lib/streamlit/external/langchain/__init__.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom streamlit.external.langchain.streamlit_callback_handler import (\n    LLMThoughtLabeler,\n    StreamlitCallbackHandler,\n)\n\n__all__ = [\n    \"LLMThoughtLabeler\",\n    \"StreamlitCallbackHandler\",\n]\n", "lib/streamlit/hello/Mapping_Demo.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom urllib.error import URLError\n\nimport pandas as pd\nimport pydeck as pdk\n\nimport streamlit as st\nfrom streamlit.hello.utils import show_code\n\n\ndef mapping_demo():\n    @st.cache_data\n    def from_data_file(filename):\n        url = (\n            \"https://raw.githubusercontent.com/streamlit/\"\n            \"example-data/master/hello/v1/%s\" % filename\n        )\n        return pd.read_json(url)\n\n    try:\n        ALL_LAYERS = {\n            \"Bike Rentals\": pdk.Layer(\n                \"HexagonLayer\",\n                data=from_data_file(\"bike_rental_stats.json\"),\n                get_position=[\"lon\", \"lat\"],\n                radius=200,\n                elevation_scale=4,\n                elevation_range=[0, 1000],\n                extruded=True,\n            ),\n            \"Bart Stop Exits\": pdk.Layer(\n                \"ScatterplotLayer\",\n                data=from_data_file(\"bart_stop_stats.json\"),\n                get_position=[\"lon\", \"lat\"],\n                get_color=[200, 30, 0, 160],\n                get_radius=\"[exits]\",\n                radius_scale=0.05,\n            ),\n            \"Bart Stop Names\": pdk.Layer(\n                \"TextLayer\",\n                data=from_data_file(\"bart_stop_stats.json\"),\n                get_position=[\"lon\", \"lat\"],\n                get_text=\"name\",\n                get_color=[0, 0, 0, 200],\n                get_size=10,\n                get_alignment_baseline=\"'bottom'\",\n            ),\n            \"Outbound Flow\": pdk.Layer(\n                \"ArcLayer\",\n                data=from_data_file(\"bart_path_stats.json\"),\n                get_source_position=[\"lon\", \"lat\"],\n                get_target_position=[\"lon2\", \"lat2\"],\n                get_source_color=[200, 30, 0, 160],\n                get_target_color=[200, 30, 0, 160],\n                auto_highlight=True,\n                width_scale=0.0001,\n                get_width=\"outbound\",\n                width_min_pixels=3,\n                width_max_pixels=30,\n            ),\n        }\n        st.sidebar.markdown(\"### Map Layers\")\n        selected_layers = [\n            layer\n            for layer_name, layer in ALL_LAYERS.items()\n            if st.sidebar.checkbox(layer_name, True)\n        ]\n        if selected_layers:\n            st.pydeck_chart(\n                pdk.Deck(\n                    map_style=None,\n                    initial_view_state={\n                        \"latitude\": 37.76,\n                        \"longitude\": -122.4,\n                        \"zoom\": 11,\n                        \"pitch\": 50,\n                    },\n                    layers=selected_layers,\n                )\n            )\n        else:\n            st.error(\"Please choose at least one layer above.\")\n    except URLError as e:\n        st.error(\n            \"\"\"\n            **This demo requires internet access.**\n            Connection error: %s\n        \"\"\"\n            % e.reason\n        )\n\n\nst.set_page_config(page_title=\"Mapping Demo\", page_icon=\"\ud83c\udf0d\")\nst.markdown(\"# Mapping Demo\")\nst.sidebar.header(\"Mapping Demo\")\nst.write(\n    \"\"\"This demo shows how to use\n[`st.pydeck_chart`](https://docs.streamlit.io/develop/api-reference/charts/st.pydeck_chart)\nto display geospatial data.\"\"\"\n)\n\nmapping_demo()\n\nshow_code(mapping_demo)\n", "lib/streamlit/hello/Dataframe_Demo.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom urllib.error import URLError\n\nimport altair as alt\nimport pandas as pd\n\nimport streamlit as st\nfrom streamlit.hello.utils import show_code\n\n\ndef data_frame_demo():\n    @st.cache_data\n    def get_UN_data():\n        AWS_BUCKET_URL = \"https://streamlit-demo-data.s3-us-west-2.amazonaws.com\"\n        df = pd.read_csv(AWS_BUCKET_URL + \"/agri.csv.gz\")\n        return df.set_index(\"Region\")\n\n    try:\n        df = get_UN_data()\n        countries = st.multiselect(\n            \"Choose countries\", list(df.index), [\"China\", \"United States of America\"]\n        )\n        if not countries:\n            st.error(\"Please select at least one country.\")\n        else:\n            data = df.loc[countries]\n            data /= 1000000.0\n            st.write(\"### Gross Agricultural Production ($B)\", data.sort_index())\n\n            data = data.T.reset_index()\n            data = pd.melt(data, id_vars=[\"index\"]).rename(\n                columns={\"index\": \"year\", \"value\": \"Gross Agricultural Product ($B)\"}\n            )\n            chart = (\n                alt.Chart(data)\n                .mark_area(opacity=0.3)\n                .encode(\n                    x=\"year:T\",\n                    y=alt.Y(\"Gross Agricultural Product ($B):Q\", stack=None),\n                    color=\"Region:N\",\n                )\n            )\n            st.altair_chart(chart, use_container_width=True)\n    except URLError as e:\n        st.error(\n            \"\"\"\n            **This demo requires internet access.**\n            Connection error: %s\n        \"\"\"\n            % e.reason\n        )\n\n\nst.set_page_config(page_title=\"DataFrame Demo\", page_icon=\"\ud83d\udcca\")\nst.markdown(\"# DataFrame Demo\")\nst.sidebar.header(\"DataFrame Demo\")\nst.write(\n    \"\"\"This demo shows how to use `st.write` to visualize Pandas DataFrames.\n(Data courtesy of the [UN Data Explorer](http://data.un.org/Explorer.aspx).)\"\"\"\n)\n\ndata_frame_demo()\n\nshow_code(data_frame_demo)\n", "lib/streamlit/hello/Animation_Demo.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom typing import Any\n\nimport numpy as np\n\nimport streamlit as st\nfrom streamlit.hello.utils import show_code\n\n\ndef animation_demo() -> None:\n    # Interactive Streamlit elements, like these sliders, return their value.\n    # This gives you an extremely simple interaction model.\n    iterations = st.sidebar.slider(\"Level of detail\", 2, 20, 10, 1)\n    separation = st.sidebar.slider(\"Separation\", 0.7, 2.0, 0.7885)\n\n    # Non-interactive elements return a placeholder to their location\n    # in the app. Here we're storing progress_bar to update it later.\n    progress_bar = st.sidebar.progress(0)\n\n    # These two elements will be filled in later, so we create a placeholder\n    # for them using st.empty()\n    frame_text = st.sidebar.empty()\n    image = st.empty()\n\n    m, n, s = 960, 640, 400\n    x = np.linspace(-m / s, m / s, num=m).reshape((1, m))\n    y = np.linspace(-n / s, n / s, num=n).reshape((n, 1))\n\n    for frame_num, a in enumerate(np.linspace(0.0, 4 * np.pi, 100)):\n        # Here were setting value for these two elements.\n        progress_bar.progress(frame_num)\n        frame_text.text(\"Frame %i/100\" % (frame_num + 1))\n\n        # Performing some fractal wizardry.\n        c = separation * np.exp(1j * a)\n        Z = np.tile(x, (n, 1)) + 1j * np.tile(y, (1, m))\n        C = np.full((n, m), c)\n        M: Any = np.full((n, m), True, dtype=bool)\n        N = np.zeros((n, m))\n\n        for i in range(iterations):\n            Z[M] = Z[M] * Z[M] + C[M]\n            M[np.abs(Z) > 2] = False\n            N[M] = i\n\n        # Update the image placeholder by calling the image() function on it.\n        image.image(1.0 - (N / N.max()), use_column_width=True)\n\n    # We clear elements by calling empty on them.\n    progress_bar.empty()\n    frame_text.empty()\n\n    # Streamlit widgets automatically run the script from top to bottom. Since\n    # this button is not connected to any other logic, it just causes a plain\n    # rerun.\n    st.button(\"Re-run\")\n\n\nst.set_page_config(page_title=\"Animation Demo\", page_icon=\"\ud83d\udcf9\")\nst.markdown(\"# Animation Demo\")\nst.sidebar.header(\"Animation Demo\")\nst.write(\n    \"\"\"This app shows how you can use Streamlit to build cool animations.\nIt displays an animated fractal based on the the Julia Set. Use the slider\nto tune different parameters.\"\"\"\n)\n\nanimation_demo()\n\nshow_code(animation_demo)\n", "lib/streamlit/hello/Plotting_Demo.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport time\n\nimport numpy as np\n\nimport streamlit as st\nfrom streamlit.hello.utils import show_code\n\n\ndef plotting_demo():\n    progress_bar = st.sidebar.progress(0)\n    status_text = st.sidebar.empty()\n    last_rows = np.random.randn(1, 1)\n    chart = st.line_chart(last_rows)\n\n    for i in range(1, 101):\n        new_rows = last_rows[-1, :] + np.random.randn(5, 1).cumsum(axis=0)\n        status_text.text(\"%i%% Complete\" % i)\n        chart.add_rows(new_rows)\n        progress_bar.progress(i)\n        last_rows = new_rows\n        time.sleep(0.05)\n\n    progress_bar.empty()\n\n    # Streamlit widgets automatically run the script from top to bottom. Since\n    # this button is not connected to any other logic, it just causes a plain\n    # rerun.\n    st.button(\"Re-run\")\n\n\nst.set_page_config(page_title=\"Plotting Demo\", page_icon=\"\ud83d\udcc8\")\nst.markdown(\"# Plotting Demo\")\nst.sidebar.header(\"Plotting Demo\")\nst.write(\n    \"\"\"This demo illustrates a combination of plotting and animation with\nStreamlit. We're generating a bunch of random numbers in a loop for around\n5 seconds. Enjoy!\"\"\"\n)\n\nplotting_demo()\n\nshow_code(plotting_demo)\n", "lib/streamlit/hello/Hello.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport streamlit as st\n\nst.set_page_config(\n    page_title=\"Hello\",\n    page_icon=\"\ud83d\udc4b\",\n)\n\nst.write(\"# Welcome to Streamlit! \ud83d\udc4b\")\n\nst.sidebar.success(\"Select a demo above.\")\n\nst.markdown(\n    \"\"\"\n    Streamlit is an open-source app framework built specifically for\n    Machine Learning and Data Science projects.\n    **\ud83d\udc48 Select a demo from the sidebar** to see some examples\n    of what Streamlit can do!\n    ### Want to learn more?\n    - Check out [streamlit.io](https://streamlit.io)\n    - Jump into our [documentation](https://docs.streamlit.io)\n    - Ask a question in our [community\n      forums](https://discuss.streamlit.io)\n    ### See more complex demos\n    - Use a neural net to [analyze the Udacity Self-driving Car Image\n      Dataset](https://github.com/streamlit/demo-self-driving)\n    - Explore a [New York City rideshare dataset](https://github.com/streamlit/demo-uber-nyc-pickups)\n\"\"\"\n)\n", "lib/streamlit/hello/utils.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport inspect\nimport textwrap\n\nimport streamlit as st\n\n\ndef show_code(demo):\n    \"\"\"Showing the code of the demo.\"\"\"\n    show_code = st.sidebar.checkbox(\"Show code\", True)\n    if show_code:\n        # Showing the code of the demo.\n        st.markdown(\"## Code\")\n        sourcelines, _ = inspect.getsourcelines(demo)\n        st.code(textwrap.dedent(\"\".join(sourcelines[1:])))\n", "lib/streamlit/hello/__init__.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n", "lib/streamlit/hello/streamlit_app.py": "# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2024)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom pathlib import Path\n\nimport streamlit as st\n\ndir_path = Path(__file__).parent\n\n\ndef run():\n    page = st.navigation(\n        [\n            st.Page(dir_path / \"Hello.py\"),\n            st.Page(dir_path / \"Animation_Demo.py\"),\n            st.Page(dir_path / \"Plotting_Demo.py\"),\n            st.Page(dir_path / \"Mapping_Demo.py\"),\n            st.Page(dir_path / \"Dataframe_Demo.py\"),\n        ]\n    )\n\n    page.run()\n\n\nif __name__ == \"__main__\":\n    run()\n"}