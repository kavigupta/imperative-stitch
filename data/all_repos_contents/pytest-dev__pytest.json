{"extra/get_issues.py": "from __future__ import annotations\n\nimport json\nfrom pathlib import Path\nimport sys\n\nimport requests\n\n\nissues_url = \"https://api.github.com/repos/pytest-dev/pytest/issues\"\n\n\ndef get_issues():\n    issues = []\n    url = issues_url\n    while 1:\n        get_data = {\"state\": \"all\"}\n        r = requests.get(url, params=get_data)\n        data = r.json()\n        if r.status_code == 403:\n            # API request limit exceeded\n            print(data[\"message\"])\n            sys.exit(1)\n        issues.extend(data)\n\n        # Look for next page\n        links = requests.utils.parse_header_links(r.headers[\"Link\"])\n        another_page = False\n        for link in links:\n            if link[\"rel\"] == \"next\":\n                url = link[\"url\"]\n                another_page = True\n        if not another_page:\n            return issues\n\n\ndef main(args):\n    cachefile = Path(args.cache)\n    if not cachefile.exists() or args.refresh:\n        issues = get_issues()\n        cachefile.write_text(json.dumps(issues), \"utf-8\")\n    else:\n        issues = json.loads(cachefile.read_text(\"utf-8\"))\n\n    open_issues = [x for x in issues if x[\"state\"] == \"open\"]\n\n    open_issues.sort(key=lambda x: x[\"number\"])\n    report(open_issues)\n\n\ndef _get_kind(issue):\n    labels = [label[\"name\"] for label in issue[\"labels\"]]\n    for key in (\"bug\", \"enhancement\", \"proposal\"):\n        if key in labels:\n            return key\n    return \"issue\"\n\n\ndef report(issues):\n    for issue in issues:\n        title = issue[\"title\"]\n        # body = issue[\"body\"]\n        kind = _get_kind(issue)\n        status = issue[\"state\"]\n        number = issue[\"number\"]\n        link = f\"https://github.com/pytest-dev/pytest/issues/{number}/\"\n        print(\"----\")\n        print(status, kind, link)\n        print(title)\n        # print()\n        # lines = body.split(\"\\n\")\n        # print(\"\\n\".join(lines[:3]))\n        # if len(lines) > 3 or len(body) > 240:\n        #    print(\"...\")\n    print(f\"\\n\\nFound {len(issues)} open issues\")\n\n\nif __name__ == \"__main__\":\n    import argparse\n\n    parser = argparse.ArgumentParser(\"process bitbucket issues\")\n    parser.add_argument(\n        \"--refresh\", action=\"store_true\", help=\"invalidate cache, refresh issues\"\n    )\n    parser.add_argument(\n        \"--cache\", action=\"store\", default=\"issues.json\", help=\"cache file\"\n    )\n    args = parser.parse_args()\n    main(args)\n", "bench/skip.py": "from __future__ import annotations\n\nimport pytest\n\n\nSKIP = True\n\n\n@pytest.mark.parametrize(\"x\", range(5000))\ndef test_foo(x):\n    if SKIP:\n        pytest.skip(\"heh\")\n", "bench/bench_argcomplete.py": "# 10000 iterations, just for relative comparison\n#                      2.7.5     3.3.2\n# FilesCompleter       75.1109   69.2116\n# FastFilesCompleter    0.7383    1.0760\nfrom __future__ import annotations\n\nimport timeit\n\n\nimports = [\n    \"from argcomplete.completers import FilesCompleter as completer\",\n    \"from _pytest._argcomplete import FastFilesCompleter as completer\",\n]\n\ncount = 1000  # only a few seconds\nsetup = \"%s\\nfc = completer()\"\nrun = 'fc(\"/d\")'\n\n\nif __name__ == \"__main__\":\n    print(timeit.timeit(run, setup=setup % imports[0], number=count))\n    print(timeit.timeit(run, setup=setup % imports[1], number=count))\n", "bench/manyparam.py": "from __future__ import annotations\n\nimport pytest\n\n\n@pytest.fixture(scope=\"module\", params=range(966))\ndef foo(request):\n    return request.param\n\n\ndef test_it(foo):\n    pass\n\n\ndef test_it2(foo):\n    pass\n", "bench/bench.py": "from __future__ import annotations\n\nimport sys\n\n\nif __name__ == \"__main__\":\n    import cProfile\n    import pstats\n\n    import pytest  # noqa: F401\n\n    script = sys.argv[1:] if len(sys.argv) > 1 else [\"empty.py\"]\n    cProfile.run(f\"pytest.cmdline.main({script!r})\", \"prof\")\n    p = pstats.Stats(\"prof\")\n    p.strip_dirs()\n    p.sort_stats(\"cumulative\")\n    print(p.print_stats(500))\n", "bench/empty.py": "from __future__ import annotations\n\n\nfor i in range(1000):\n    exec(\"def test_func_%d(): pass\" % i)\n", "bench/xunit.py": "from __future__ import annotations\n\n\nfor i in range(5000):\n    exec(\n        f\"\"\"\nclass Test{i}:\n    @classmethod\n    def setup_class(cls): pass\n    def test_1(self): pass\n    def test_2(self): pass\n    def test_3(self): pass\n\"\"\"\n    )\n", "scripts/release.py": "# mypy: disallow-untyped-defs\n\"\"\"Invoke development tasks.\"\"\"\n\nfrom __future__ import annotations\n\nimport argparse\nimport os\nfrom pathlib import Path\nfrom subprocess import call\nfrom subprocess import check_call\nfrom subprocess import check_output\n\nfrom colorama import Fore\nfrom colorama import init\n\n\ndef announce(version: str, template_name: str, doc_version: str) -> None:\n    \"\"\"Generates a new release announcement entry in the docs.\"\"\"\n    # Get our list of authors\n    stdout = check_output([\"git\", \"describe\", \"--abbrev=0\", \"--tags\"], encoding=\"UTF-8\")\n    last_version = stdout.strip()\n\n    stdout = check_output(\n        [\"git\", \"log\", f\"{last_version}..HEAD\", \"--format=%aN\"], encoding=\"UTF-8\"\n    )\n\n    contributors = {\n        name\n        for name in stdout.splitlines()\n        if not name.endswith(\"[bot]\") and name != \"pytest bot\"\n    }\n\n    template_text = (\n        Path(__file__).parent.joinpath(template_name).read_text(encoding=\"UTF-8\")\n    )\n\n    contributors_text = \"\\n\".join(f\"* {name}\" for name in sorted(contributors)) + \"\\n\"\n    text = template_text.format(\n        version=version, contributors=contributors_text, doc_version=doc_version\n    )\n\n    target = Path(__file__).parent.joinpath(f\"../doc/en/announce/release-{version}.rst\")\n    target.write_text(text, encoding=\"UTF-8\")\n    print(f\"{Fore.CYAN}[generate.announce] {Fore.RESET}Generated {target.name}\")\n\n    # Update index with the new release entry\n    index_path = Path(__file__).parent.joinpath(\"../doc/en/announce/index.rst\")\n    lines = index_path.read_text(encoding=\"UTF-8\").splitlines()\n    indent = \"   \"\n    for index, line in enumerate(lines):\n        if line.startswith(f\"{indent}release-\"):\n            new_line = indent + target.stem\n            if line != new_line:\n                lines.insert(index, new_line)\n                index_path.write_text(\"\\n\".join(lines) + \"\\n\", encoding=\"UTF-8\")\n                print(\n                    f\"{Fore.CYAN}[generate.announce] {Fore.RESET}Updated {index_path.name}\"\n                )\n            else:\n                print(\n                    f\"{Fore.CYAN}[generate.announce] {Fore.RESET}Skip {index_path.name} (already contains release)\"\n                )\n            break\n\n    check_call([\"git\", \"add\", str(target)])\n\n\ndef regen(version: str) -> None:\n    \"\"\"Call regendoc tool to update examples and pytest output in the docs.\"\"\"\n    print(f\"{Fore.CYAN}[generate.regen] {Fore.RESET}Updating docs\")\n    check_call(\n        [\"tox\", \"-e\", \"regen\"],\n        env={**os.environ, \"SETUPTOOLS_SCM_PRETEND_VERSION_FOR_PYTEST\": version},\n    )\n\n\ndef fix_formatting() -> None:\n    \"\"\"Runs pre-commit in all files to ensure they are formatted correctly\"\"\"\n    print(\n        f\"{Fore.CYAN}[generate.fix linting] {Fore.RESET}Fixing formatting using pre-commit\"\n    )\n    call([\"pre-commit\", \"run\", \"--all-files\"])\n\n\ndef check_links() -> None:\n    \"\"\"Runs sphinx-build to check links\"\"\"\n    print(f\"{Fore.CYAN}[generate.check_links] {Fore.RESET}Checking links\")\n    check_call([\"tox\", \"-e\", \"docs-checklinks\"])\n\n\ndef pre_release(\n    version: str, template_name: str, doc_version: str, *, skip_check_links: bool\n) -> None:\n    \"\"\"Generates new docs, release announcements and creates a local tag.\"\"\"\n    announce(version, template_name, doc_version)\n    regen(version)\n    changelog(version, write_out=True)\n    fix_formatting()\n    if not skip_check_links:\n        check_links()\n\n    msg = f\"Prepare release version {version}\"\n    check_call([\"git\", \"commit\", \"-a\", \"-m\", msg])\n\n    print()\n    print(f\"{Fore.CYAN}[generate.pre_release] {Fore.GREEN}All done!\")\n    print()\n    print(\"Please push your branch and open a PR.\")\n\n\ndef changelog(version: str, write_out: bool = False) -> None:\n    addopts = [] if write_out else [\"--draft\"]\n    check_call([\"towncrier\", \"--yes\", \"--version\", version, *addopts])\n\n\ndef main() -> None:\n    init(autoreset=True)\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"version\", help=\"Release version\")\n    parser.add_argument(\n        \"template_name\", help=\"Name of template file to use for release announcement\"\n    )\n    parser.add_argument(\n        \"doc_version\", help=\"For prereleases, the version to link to in the docs\"\n    )\n    parser.add_argument(\"--skip-check-links\", action=\"store_true\", default=False)\n    options = parser.parse_args()\n    pre_release(\n        options.version,\n        options.template_name,\n        options.doc_version,\n        skip_check_links=options.skip_check_links,\n    )\n\n\nif __name__ == \"__main__\":\n    main()\n", "scripts/update-plugin-list.py": "# mypy: disallow-untyped-defs\nfrom __future__ import annotations\n\nimport datetime\nimport pathlib\nimport re\nfrom textwrap import dedent\nfrom textwrap import indent\nfrom typing import Any\nfrom typing import Iterable\nfrom typing import Iterator\nfrom typing import TypedDict\n\nimport packaging.version\nimport platformdirs\nfrom requests_cache import CachedResponse\nfrom requests_cache import CachedSession\nfrom requests_cache import OriginalResponse\nfrom requests_cache import SQLiteCache\nimport tabulate\nfrom tqdm import tqdm\nimport wcwidth\n\n\nFILE_HEAD = r\"\"\"\n.. Note this file is autogenerated by scripts/update-plugin-list.py - usually weekly via github action\n\n.. _plugin-list:\n\nPytest Plugin List\n==================\n\nBelow is an automated compilation of ``pytest``` plugins available on `PyPI <https://pypi.org>`_.\nIt includes PyPI projects whose names begin with ``pytest-`` or ``pytest_`` and a handful of manually selected projects.\nPackages classified as inactive are excluded.\n\nFor detailed insights into how this list is generated,\nplease refer to `the update script <https://github.com/pytest-dev/pytest/blob/main/scripts/update-plugin-list.py>`_.\n\n.. warning::\n\n   Please be aware that this list is not a curated collection of projects\n   and does not undergo a systematic review process.\n   It serves purely as an informational resource to aid in the discovery of ``pytest`` plugins.\n\n   Do not presume any endorsement from the ``pytest`` project or its developers,\n   and always conduct your own quality assessment before incorporating any of these plugins into your own projects.\n\n\n.. The following conditional uses a different format for this list when\n   creating a PDF, because otherwise the table gets far too wide for the\n   page.\n\n\"\"\"\nDEVELOPMENT_STATUS_CLASSIFIERS = (\n    \"Development Status :: 1 - Planning\",\n    \"Development Status :: 2 - Pre-Alpha\",\n    \"Development Status :: 3 - Alpha\",\n    \"Development Status :: 4 - Beta\",\n    \"Development Status :: 5 - Production/Stable\",\n    \"Development Status :: 6 - Mature\",\n    \"Development Status :: 7 - Inactive\",\n)\nADDITIONAL_PROJECTS = {  # set of additional projects to consider as plugins\n    \"logassert\",\n    \"logot\",\n    \"nuts\",\n    \"flask_fixture\",\n}\n\n\ndef escape_rst(text: str) -> str:\n    \"\"\"Rudimentary attempt to escape special RST characters to appear as\n    plain text.\"\"\"\n    text = (\n        text.replace(\"*\", \"\\\\*\")\n        .replace(\"<\", \"\\\\<\")\n        .replace(\">\", \"\\\\>\")\n        .replace(\"`\", \"\\\\`\")\n    )\n    text = re.sub(r\"_\\b\", \"\", text)\n    return text\n\n\ndef project_response_with_refresh(\n    session: CachedSession, name: str, last_serial: int\n) -> OriginalResponse | CachedResponse:\n    \"\"\"Get a http cached pypi project\n\n    force refresh in case of last serial mismatch\n    \"\"\"\n    response = session.get(f\"https://pypi.org/pypi/{name}/json\")\n    if int(response.headers.get(\"X-PyPI-Last-Serial\", -1)) != last_serial:\n        response = session.get(f\"https://pypi.org/pypi/{name}/json\", refresh=True)\n    return response\n\n\ndef get_session() -> CachedSession:\n    \"\"\"Configures the requests-cache session\"\"\"\n    cache_path = platformdirs.user_cache_path(\"pytest-plugin-list\")\n    cache_path.mkdir(exist_ok=True, parents=True)\n    cache_file = cache_path.joinpath(\"http_cache.sqlite3\")\n    return CachedSession(backend=SQLiteCache(cache_file))\n\n\ndef pytest_plugin_projects_from_pypi(session: CachedSession) -> dict[str, int]:\n    response = session.get(\n        \"https://pypi.org/simple\",\n        headers={\"Accept\": \"application/vnd.pypi.simple.v1+json\"},\n        refresh=True,\n    )\n    return {\n        name: p[\"_last-serial\"]\n        for p in response.json()[\"projects\"]\n        if (\n            (name := p[\"name\"]).startswith((\"pytest-\", \"pytest_\"))\n            or name in ADDITIONAL_PROJECTS\n        )\n    }\n\n\nclass PluginInfo(TypedDict):\n    \"\"\"Relevant information about a plugin to generate the summary.\"\"\"\n\n    name: str\n    summary: str\n    last_release: str\n    status: str\n    requires: str\n\n\ndef iter_plugins() -> Iterator[PluginInfo]:\n    session = get_session()\n    name_2_serial = pytest_plugin_projects_from_pypi(session)\n\n    for name, last_serial in tqdm(name_2_serial.items(), smoothing=0):\n        response = project_response_with_refresh(session, name, last_serial)\n        if response.status_code == 404:\n            # Some packages, like pytest-azurepipelines42, are included in https://pypi.org/simple\n            # but return 404 on the JSON API. Skip.\n            continue\n        response.raise_for_status()\n        info = response.json()[\"info\"]\n        if \"Development Status :: 7 - Inactive\" in info[\"classifiers\"]:\n            continue\n        for classifier in DEVELOPMENT_STATUS_CLASSIFIERS:\n            if classifier in info[\"classifiers\"]:\n                status = classifier[22:]\n                break\n        else:\n            status = \"N/A\"\n        requires = \"N/A\"\n        if info[\"requires_dist\"]:\n            for requirement in info[\"requires_dist\"]:\n                if re.match(r\"pytest(?![-.\\w])\", requirement):\n                    requires = requirement\n                    break\n\n        def version_sort_key(version_string: str) -> Any:\n            \"\"\"\n            Return the sort key for the given version string\n            returned by the API.\n            \"\"\"\n            try:\n                return packaging.version.parse(version_string)\n            except packaging.version.InvalidVersion:\n                # Use a hard-coded pre-release version.\n                return packaging.version.Version(\"0.0.0alpha\")\n\n        releases = response.json()[\"releases\"]\n        for release in sorted(releases, key=version_sort_key, reverse=True):\n            if releases[release]:\n                release_date = datetime.date.fromisoformat(\n                    releases[release][-1][\"upload_time_iso_8601\"].split(\"T\")[0]\n                )\n                last_release = release_date.strftime(\"%b %d, %Y\")\n                break\n        name = f':pypi:`{info[\"name\"]}`'\n        summary = \"\"\n        if info[\"summary\"]:\n            summary = escape_rst(info[\"summary\"].replace(\"\\n\", \"\"))\n        yield {\n            \"name\": name,\n            \"summary\": summary.strip(),\n            \"last_release\": last_release,\n            \"status\": status,\n            \"requires\": requires,\n        }\n\n\ndef plugin_definitions(plugins: Iterable[PluginInfo]) -> Iterator[str]:\n    \"\"\"Return RST for the plugin list that fits better on a vertical page.\"\"\"\n    for plugin in plugins:\n        yield dedent(\n            f\"\"\"\n            {plugin['name']}\n               *last release*: {plugin[\"last_release\"]},\n               *status*: {plugin[\"status\"]},\n               *requires*: {plugin[\"requires\"]}\n\n               {plugin[\"summary\"]}\n            \"\"\"\n        )\n\n\ndef main() -> None:\n    plugins = [*iter_plugins()]\n\n    reference_dir = pathlib.Path(\"doc\", \"en\", \"reference\")\n\n    plugin_list = reference_dir / \"plugin_list.rst\"\n    with plugin_list.open(\"w\", encoding=\"UTF-8\") as f:\n        f.write(FILE_HEAD)\n        f.write(f\"This list contains {len(plugins)} plugins.\\n\\n\")\n        f.write(\".. only:: not latex\\n\\n\")\n\n        _ = wcwidth  # reference library that must exist for tabulate to work\n        plugin_table = tabulate.tabulate(plugins, headers=\"keys\", tablefmt=\"rst\")\n        f.write(indent(plugin_table, \"   \"))\n        f.write(\"\\n\\n\")\n\n        f.write(\".. only:: latex\\n\\n\")\n        f.write(indent(\"\".join(plugin_definitions(plugins)), \"  \"))\n\n\nif __name__ == \"__main__\":\n    main()\n", "scripts/prepare-release-pr.py": "# mypy: disallow-untyped-defs\n\"\"\"\nThis script is part of the pytest release process which is triggered manually in the Actions\ntab of the repository.\n\nThe user will need to enter the base branch to start the release from (for example\n``6.1.x`` or ``main``) and if it should be a major release.\n\nThe appropriate version will be obtained based on the given branch automatically.\n\nAfter that, it will create a release using the `release` tox environment, and push a new PR.\n\n**Token**: currently the token from the GitHub Actions is used, pushed with\n`pytest bot <pytestbot@gmail.com>` commit author.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport argparse\nfrom pathlib import Path\nimport re\nfrom subprocess import check_call\nfrom subprocess import check_output\nfrom subprocess import run\n\nfrom colorama import Fore\nfrom colorama import init\nfrom github3.repos import Repository\n\n\nclass InvalidFeatureRelease(Exception):\n    pass\n\n\nSLUG = \"pytest-dev/pytest\"\n\nPR_BODY = \"\"\"\\\nCreated by the [prepare release pr]\\\n(https://github.com/pytest-dev/pytest/actions/workflows/prepare-release-pr.yml) workflow.\n\nOnce all builds pass and it has been **approved** by one or more maintainers, start the \\\n[deploy](https://github.com/pytest-dev/pytest/actions/workflows/deploy.yml) workflow, using these parameters:\n\n* `Use workflow from`: `release-{version}`.\n* `Release version`: `{version}`.\n\nOr execute on the command line:\n\n```console\ngh workflow run deploy.yml -r release-{version} -f version={version}\n```\n\nAfter the workflow has been approved by a core maintainer, the package will be uploaded to PyPI automatically.\n\"\"\"\n\n\ndef login(token: str) -> Repository:\n    import github3\n\n    github = github3.login(token=token)\n    owner, repo = SLUG.split(\"/\")\n    return github.repository(owner, repo)\n\n\ndef prepare_release_pr(\n    base_branch: str, is_major: bool, token: str, prerelease: str\n) -> None:\n    print()\n    print(f\"Processing release for branch {Fore.CYAN}{base_branch}\")\n\n    check_call([\"git\", \"checkout\", f\"origin/{base_branch}\"])\n\n    changelog = Path(\"changelog\")\n\n    features = list(changelog.glob(\"*.feature.rst\"))\n    breaking = list(changelog.glob(\"*.breaking.rst\"))\n    is_feature_release = bool(features or breaking)\n\n    try:\n        version = find_next_version(\n            base_branch, is_major, is_feature_release, prerelease\n        )\n    except InvalidFeatureRelease as e:\n        print(f\"{Fore.RED}{e}\")\n        raise SystemExit(1) from None\n\n    print(f\"Version: {Fore.CYAN}{version}\")\n\n    release_branch = f\"release-{version}\"\n\n    run(\n        [\"git\", \"config\", \"user.name\", \"pytest bot\"],\n        check=True,\n    )\n    run(\n        [\"git\", \"config\", \"user.email\", \"pytestbot@gmail.com\"],\n        check=True,\n    )\n\n    run(\n        [\"git\", \"checkout\", \"-b\", release_branch, f\"origin/{base_branch}\"],\n        check=True,\n    )\n\n    print(f\"Branch {Fore.CYAN}{release_branch}{Fore.RESET} created.\")\n\n    if is_major:\n        template_name = \"release.major.rst\"\n    elif prerelease:\n        template_name = \"release.pre.rst\"\n    elif is_feature_release:\n        template_name = \"release.minor.rst\"\n    else:\n        template_name = \"release.patch.rst\"\n\n    # important to use tox here because we have changed branches, so dependencies\n    # might have changed as well\n    cmdline = [\n        \"tox\",\n        \"-e\",\n        \"release\",\n        \"--\",\n        version,\n        template_name,\n        release_branch,  # doc_version\n        \"--skip-check-links\",\n    ]\n    print(\"Running\", \" \".join(cmdline))\n    run(\n        cmdline,\n        check=True,\n    )\n\n    oauth_url = f\"https://{token}:x-oauth-basic@github.com/{SLUG}.git\"\n    run(\n        [\"git\", \"push\", oauth_url, f\"HEAD:{release_branch}\", \"--force\"],\n        check=True,\n    )\n    print(f\"Branch {Fore.CYAN}{release_branch}{Fore.RESET} pushed.\")\n\n    body = PR_BODY.format(version=version)\n    repo = login(token)\n    pr = repo.create_pull(\n        f\"Prepare release {version}\",\n        base=base_branch,\n        head=release_branch,\n        body=body,\n    )\n    print(f\"Pull request {Fore.CYAN}{pr.url}{Fore.RESET} created.\")\n\n\ndef find_next_version(\n    base_branch: str, is_major: bool, is_feature_release: bool, prerelease: str\n) -> str:\n    output = check_output([\"git\", \"tag\"], encoding=\"UTF-8\")\n    valid_versions = []\n    for v in output.splitlines():\n        m = re.match(r\"\\d.\\d.\\d+$\", v.strip())\n        if m:\n            valid_versions.append(tuple(int(x) for x in v.split(\".\")))\n\n    valid_versions.sort()\n    last_version = valid_versions[-1]\n\n    if is_major:\n        return f\"{last_version[0]+1}.0.0{prerelease}\"\n    elif is_feature_release:\n        return f\"{last_version[0]}.{last_version[1] + 1}.0{prerelease}\"\n    else:\n        return f\"{last_version[0]}.{last_version[1]}.{last_version[2] + 1}{prerelease}\"\n\n\ndef main() -> None:\n    init(autoreset=True)\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"base_branch\")\n    parser.add_argument(\"token\")\n    parser.add_argument(\"--major\", action=\"store_true\", default=False)\n    parser.add_argument(\"--prerelease\", default=\"\")\n    options = parser.parse_args()\n    prepare_release_pr(\n        base_branch=options.base_branch,\n        is_major=options.major,\n        token=options.token,\n        prerelease=options.prerelease,\n    )\n\n\nif __name__ == \"__main__\":\n    main()\n", "scripts/generate-gh-release-notes.py": "# mypy: disallow-untyped-defs\n\"\"\"\nScript used to generate a Markdown file containing only the changelog entries of a specific pytest release, which\nis then published as a GitHub Release during deploy (see workflows/deploy.yml).\n\nThe script requires ``pandoc`` to be previously installed in the system -- we need to convert from RST (the format of\nour CHANGELOG) into Markdown (which is required by GitHub Releases).\n\nRequires Python3.6+.\n\"\"\"\n\nfrom __future__ import annotations\n\nfrom pathlib import Path\nimport re\nimport sys\nfrom typing import Sequence\n\nimport pypandoc\n\n\ndef extract_changelog_entries_for(version: str) -> str:\n    p = Path(__file__).parent.parent / \"doc/en/changelog.rst\"\n    changelog_lines = p.read_text(encoding=\"UTF-8\").splitlines()\n\n    title_regex = re.compile(r\"pytest (\\d\\.\\d+\\.\\d+\\w*) \\(\\d{4}-\\d{2}-\\d{2}\\)\")\n    consuming_version = False\n    version_lines = []\n    for line in changelog_lines:\n        m = title_regex.match(line)\n        if m:\n            # Found the version we want: start to consume lines until we find the next version title.\n            if m.group(1) == version:\n                consuming_version = True\n            # Found a new version title while parsing the version we want: break out.\n            elif consuming_version:\n                break\n        if consuming_version:\n            version_lines.append(line)\n\n    return \"\\n\".join(version_lines)\n\n\ndef convert_rst_to_md(text: str) -> str:\n    result = pypandoc.convert_text(\n        text, \"md\", format=\"rst\", extra_args=[\"--wrap=preserve\"]\n    )\n    assert isinstance(result, str), repr(result)\n    return result\n\n\ndef main(argv: Sequence[str]) -> int:\n    if len(argv) != 3:\n        print(\"Usage: generate-gh-release-notes VERSION FILE\")\n        return 2\n\n    version, filename = argv[1:3]\n    print(f\"Generating GitHub release notes for version {version}\")\n    rst_body = extract_changelog_entries_for(version)\n    md_body = convert_rst_to_md(rst_body)\n    Path(filename).write_text(md_body, encoding=\"UTF-8\")\n    print()\n    print(f\"Done: {filename}\")\n    print()\n    return 0\n\n\nif __name__ == \"__main__\":\n    sys.exit(main(sys.argv))\n", "src/py.py": "# shim for pylib going away\n# if pylib is installed this file will get skipped\n# (`py/__init__.py` has higher precedence)\nfrom __future__ import annotations\n\nimport sys\n\nimport _pytest._py.error as error\nimport _pytest._py.path as path\n\n\nsys.modules[\"py.error\"] = error\nsys.modules[\"py.path\"] = path\n\n__all__ = [\"error\", \"path\"]\n"}