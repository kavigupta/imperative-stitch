{"bin/release.py": "#!/usr/bin/env python\n\nfrom __future__ import print_function\n\nfrom datetime import datetime\nimport os\nfrom os import path\nimport re\nimport shutil\nimport subprocess\nfrom subprocess import Popen\nimport sys\n\nSHARE_DIR = path.join(path.dirname(__file__), \"../share/\")\n\n\ndef run(args):\n    return Popen(args, stdout=sys.stdout, stderr=sys.stderr).wait()\n\n\nstatus = subprocess.check_output([\"git\", \"status\", \"--porcelain\"])\nif len(status) > 0:\n    print(\"Unclean working tree. Commit or stash changes first.\", file=sys.stderr)\n    sys.exit(1)\n\ntimestamp = datetime.utcnow().strftime(\"%Y-%m-%d %H:%M:%S +0000\")\n\ncht_curr = path.join(SHARE_DIR, \"cht.sh.txt\")\ncht_new = path.join(SHARE_DIR, \"cht.sh.txt.new\")\n\nre_version = re.compile(r\"^__CHTSH_VERSION=(.*)$\")\nre_timestamp = re.compile(r\"^__CHTSH_DATETIME=.*$\")\n\nwith open(cht_curr, \"rt\") as fin:\n    with open(cht_new, \"wt\") as fout:\n        for line in fin:\n            match = re_version.match(line)\n            if match:\n                version = int(match.group(1)) + 1\n                fout.write(\"__CHTSH_VERSION=%s\\n\" % version)\n                continue\n\n            match = re_timestamp.match(line)\n            if match:\n                fout.write('__CHTSH_DATETIME=\"%s\"\\n' % timestamp)\n                continue\n\n            fout.write(line)\n\nshutil.copymode(cht_curr, cht_new)\nos.remove(cht_curr)\nos.rename(cht_new, cht_curr)\n\nmessage = \"cht: v%s\" % version\nrun([\"git\", \"add\", cht_curr])\nrun([\"git\", \"commit\", \"-m\", message])\nrun([\"git\", \"tag\", \"cht@%s\" % version, \"-m\", message])\n", "bin/clean_cache.py": "import sys\nimport redis\nREDIS = redis.Redis(host='localhost', port=6379, db=0)\n\nfor key in sys.argv[1:]:\n    REDIS.delete(key)\n\n", "bin/srv.py": "#!/usr/bin/env python\n#\n# Serving cheat.sh with `gevent`\n#\n\nfrom gevent.monkey import patch_all\nfrom gevent.pywsgi import WSGIServer\npatch_all()\n\nimport os\nimport sys\n\nfrom app import app, CONFIG\n\n\nif '--debug' in sys.argv:\n    # Not all debug mode features are available under `gevent`\n    # https://github.com/pallets/flask/issues/3825\n    app.debug = True\n\nif 'CHEATSH_PORT' in os.environ:\n    port = int(os.environ.get('CHEATSH_PORT'))\nelse:\n    port = CONFIG['server.port']\n\nsrv = WSGIServer((CONFIG['server.bind'], port), app)\nprint(\"Starting gevent server on {}:{}\".format(srv.address[0], srv.address[1]))\nsrv.serve_forever()\n", "bin/app.py": "#!/usr/bin/env python\n# vim: set encoding=utf-8\n# pylint: disable=wrong-import-position,wrong-import-order\n\n\"\"\"\nMain server program.\n\nConfiguration parameters:\n\n    path.internal.malformed\n    path.internal.static\n    path.internal.templates\n    path.log.main\n    path.log.queries\n\"\"\"\n\nfrom __future__ import print_function\n\nimport sys\nif sys.version_info[0] < 3:\n    reload(sys)\n    sys.setdefaultencoding('utf8')\n\nimport sys\nimport logging\nimport os\nimport requests\nimport jinja2\nfrom flask import Flask, request, send_from_directory, redirect, Response\n\nsys.path.append(os.path.abspath(os.path.join(__file__, \"..\", \"..\", \"lib\")))\nfrom config import CONFIG\nfrom limits import Limits\nfrom cheat_wrapper import cheat_wrapper\nfrom post import process_post_request\nfrom options import parse_args\n\nfrom stateful_queries import save_query, last_query\n\n\nif not os.path.exists(os.path.dirname(CONFIG[\"path.log.main\"])):\n    os.makedirs(os.path.dirname(CONFIG[\"path.log.main\"]))\nlogging.basicConfig(\n    filename=CONFIG[\"path.log.main\"],\n    level=logging.DEBUG,\n    format='%(asctime)s %(message)s')\n# Fix Flask \"exception and request logging\" to `stderr`.\n#\n# When Flask's werkzeug detects that logging is already set, it\n# doesn't add its own logger that prints exceptions.\nstderr_handler = logging.StreamHandler()\nlogging.getLogger().addHandler(stderr_handler)\n#\n# Alter log format to disting log lines from everything else\nstderr_handler.setFormatter(logging.Formatter('%(filename)s:%(lineno)s: %(message)s'))\n#\n# Sometimes werkzeug starts logging before an app is imported\n# (https://github.com/pallets/werkzeug/issues/1969)\n# resulting in duplicating lines. In that case we need root\n# stderr handler to skip lines from werkzeug.\nclass SkipFlaskLogger(object):\n    def filter(self, record):\n        if record.name != 'werkzeug':\n            return True\nif logging.getLogger('werkzeug').handlers:\n    stderr_handler.addFilter(SkipFlaskLogger())\n\n\napp = Flask(__name__) # pylint: disable=invalid-name\napp.jinja_loader = jinja2.ChoiceLoader([\n    app.jinja_loader,\n    jinja2.FileSystemLoader(CONFIG[\"path.internal.templates\"])])\n\nLIMITS = Limits()\n\nPLAIN_TEXT_AGENTS = [\n    \"curl\",\n    \"httpie\",\n    \"lwp-request\",\n    \"wget\",\n    \"python-requests\",\n    \"openbsd ftp\",\n    \"powershell\",\n    \"fetch\",\n    \"aiohttp\",\n]\n\ndef _is_html_needed(user_agent):\n    \"\"\"\n    Basing on `user_agent`, return whether it needs HTML or ANSI\n    \"\"\"\n    return all([x not in user_agent for x in PLAIN_TEXT_AGENTS])\n\ndef is_result_a_script(query):\n    return query in [':cht.sh']\n\n@app.route('/files/<path:path>')\ndef send_static(path):\n    \"\"\"\n    Return static file `path`.\n    Can be served by the HTTP frontend.\n    \"\"\"\n    return send_from_directory(CONFIG[\"path.internal.static\"], path)\n\n@app.route('/favicon.ico')\ndef send_favicon():\n    \"\"\"\n    Return static file `favicon.ico`.\n    Can be served by the HTTP frontend.\n    \"\"\"\n    return send_from_directory(CONFIG[\"path.internal.static\"], 'favicon.ico')\n\n@app.route('/malformed-response.html')\ndef send_malformed():\n    \"\"\"\n    Return static file `malformed-response.html`.\n    Can be served by the HTTP frontend.\n    \"\"\"\n    dirname, filename = os.path.split(CONFIG[\"path.internal.malformed\"])\n    return send_from_directory(dirname, filename)\n\ndef log_query(ip_addr, found, topic, user_agent):\n    \"\"\"\n    Log processed query and some internal data\n    \"\"\"\n    log_entry = \"%s %s %s %s\\n\" % (ip_addr, found, topic, user_agent)\n    with open(CONFIG[\"path.log.queries\"], 'ab') as my_file:\n        my_file.write(log_entry.encode('utf-8'))\n\ndef get_request_ip(req):\n    \"\"\"\n    Extract IP address from `request`\n    \"\"\"\n\n    if req.headers.getlist(\"X-Forwarded-For\"):\n        ip_addr = req.headers.getlist(\"X-Forwarded-For\")[0]\n        if ip_addr.startswith('::ffff:'):\n            ip_addr = ip_addr[7:]\n    else:\n        ip_addr = req.remote_addr\n    if req.headers.getlist(\"X-Forwarded-For\"):\n        ip_addr = req.headers.getlist(\"X-Forwarded-For\")[0]\n        if ip_addr.startswith('::ffff:'):\n            ip_addr = ip_addr[7:]\n    else:\n        ip_addr = req.remote_addr\n\n    return ip_addr\n\ndef get_answer_language(request):\n    \"\"\"\n    Return preferred answer language based on\n    domain name, query arguments and headers\n    \"\"\"\n\n    def _parse_accept_language(accept_language):\n        languages = accept_language.split(\",\")\n        locale_q_pairs = []\n\n        for language in languages:\n            try:\n                if language.split(\";\")[0] == language:\n                    # no q => q = 1\n                    locale_q_pairs.append((language.strip(), \"1\"))\n                else:\n                    locale = language.split(\";\")[0].strip()\n                    weight = language.split(\";\")[1].split(\"=\")[1]\n                    locale_q_pairs.append((locale, weight))\n            except IndexError:\n                pass\n\n        return locale_q_pairs\n\n    def _find_supported_language(accepted_languages):\n        for lang_tuple in accepted_languages:\n            lang = lang_tuple[0]\n            if '-' in lang:\n                lang = lang.split('-', 1)[0]\n            return lang\n        return None\n\n    lang = None\n    hostname = request.headers['Host']\n    if hostname.endswith('.cheat.sh'):\n        lang = hostname[:-9]\n\n    if 'lang' in request.args:\n        lang = request.args.get('lang')\n\n    header_accept_language = request.headers.get('Accept-Language', '')\n    if lang is None and header_accept_language:\n        lang = _find_supported_language(\n            _parse_accept_language(header_accept_language))\n\n    return lang\n\ndef _proxy(*args, **kwargs):\n    # print \"method=\", request.method,\n    # print \"url=\", request.url.replace('/:shell-x/', ':3000/')\n    # print \"headers=\", {key: value for (key, value) in request.headers if key != 'Host'}\n    # print \"data=\", request.get_data()\n    # print \"cookies=\", request.cookies\n    # print \"allow_redirects=\", False\n\n    url_before, url_after = request.url.split('/:shell-x/', 1)\n    url = url_before + ':3000/'\n\n    if 'q' in request.args:\n        url_after = '?' + \"&\".join(\"arg=%s\" % x for x in request.args['q'].split())\n\n    url += url_after\n    print(url)\n    print(request.get_data())\n    resp = requests.request(\n        method=request.method,\n        url=url,\n        headers={key: value for (key, value) in request.headers if key != 'Host'},\n        data=request.get_data(),\n        cookies=request.cookies,\n        allow_redirects=False)\n\n    excluded_headers = ['content-encoding', 'content-length', 'transfer-encoding', 'connection']\n    headers = [(name, value) for (name, value) in resp.raw.headers.items()\n               if name.lower() not in excluded_headers]\n\n    response = Response(resp.content, resp.status_code, headers)\n    return response\n\n\n@app.route(\"/\", methods=['GET', 'POST'])\n@app.route(\"/<path:topic>\", methods=[\"GET\", \"POST\"])\ndef answer(topic=None):\n    \"\"\"\n    Main rendering function, it processes incoming weather queries.\n    Depending on user agent it returns output in HTML or ANSI format.\n\n    Incoming data:\n        request.args\n        request.headers\n        request.remote_addr\n        request.referrer\n        request.query_string\n    \"\"\"\n\n    user_agent = request.headers.get('User-Agent', '').lower()\n    html_needed = _is_html_needed(user_agent)\n    options = parse_args(request.args)\n\n    if topic in ['apple-touch-icon-precomposed.png', 'apple-touch-icon.png', 'apple-touch-icon-120x120-precomposed.png'] \\\n        or (topic is not None and any(topic.endswith('/'+x) for x in ['favicon.ico'])):\n        return ''\n\n    request_id = request.cookies.get('id')\n    if topic is not None and topic.lstrip('/') == ':last':\n        if request_id:\n            topic = last_query(request_id)\n        else:\n            return \"ERROR: you have to set id for your requests to use /:last\\n\"\n    else:\n        if request_id:\n            save_query(request_id, topic)\n\n    if request.method == 'POST':\n        process_post_request(request, html_needed)\n        if html_needed:\n            return redirect(\"/\")\n        return \"OK\\n\"\n\n    if 'topic' in request.args:\n        return redirect(\"/%s\" % request.args.get('topic'))\n\n    if topic is None:\n        topic = \":firstpage\"\n\n    if topic.startswith(':shell-x/'):\n        return _proxy()\n        #return requests.get('http://127.0.0.1:3000'+topic[8:]).text\n\n    lang = get_answer_language(request)\n    if lang:\n        options['lang'] = lang\n\n    ip_address = get_request_ip(request)\n    if '+' in topic:\n        not_allowed = LIMITS.check_ip(ip_address)\n        if not_allowed:\n            return \"429 %s\\n\" % not_allowed, 429\n\n    html_is_needed = _is_html_needed(user_agent) and not is_result_a_script(topic)\n    if html_is_needed:\n        output_format='html'\n    else:\n        output_format='ansi'\n    result, found = cheat_wrapper(topic, request_options=options, output_format=output_format)\n    if 'Please come back in several hours' in result and html_is_needed:\n        malformed_response = open(os.path.join(CONFIG[\"path.internal.malformed\"])).read()\n        return malformed_response\n\n    log_query(ip_address, found, topic, user_agent)\n    if html_is_needed:\n        return result\n    return Response(result, mimetype='text/plain')\n", "lib/fetch.py": "\"\"\"\nRepositories fetch and update\n\nThis module makes real network and OS interaction,\nand the adapters only say how exctly this interaction\nshould be done.\n\nConfiguration parameters:\n\n    * path.log.fetch\n\"\"\"\n\nfrom __future__ import print_function\n\nimport sys\nimport logging\nimport os\nimport subprocess\nimport textwrap\n\nfrom globals import fatal\nimport adapter\nimport cache\n\nfrom config import CONFIG\n\ndef _log(*message):\n    logging.info(*message)\n    if len(message) > 1:\n        message = message[0].rstrip(\"\\n\") % tuple(message[1:])\n    else:\n        message = message[0].rstrip(\"\\n\")\n\n    sys.stdout.write(message+\"\\n\")\n\ndef _run_cmd(cmd):\n    shell = isinstance(cmd, str)\n    process = subprocess.Popen(\n        cmd, shell=shell, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n    output = process.communicate()[0]\n    return process.returncode, output\n\ndef fetch_all(skip_existing=True):\n    \"\"\"\n    Fetch all known repositories mentioned in the adapters\n    \"\"\"\n\n    def _fetch_locations(known_location):\n        for location, adptr in known_location.items():\n            if location in existing_locations:\n                continue\n\n            cmd = adptr.fetch_command()\n            if not cmd:\n                continue\n\n            sys.stdout.write(\"Fetching %s...\" % (adptr))\n            sys.stdout.flush()\n            try:\n                process = subprocess.Popen(\n                    cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT,\n                    universal_newlines=True)\n            except OSError:\n                print(\"\\nERROR: %s\" % cmd)\n                raise\n            output = process.communicate()[0]\n            if process.returncode != 0:\n                sys.stdout.write(\"\\nERROR:\\n---\\n\" + output)\n                fatal(\"---\\nCould not fetch %s\" % adptr)\n            else:\n                print(\"Done\")\n\n    # Searching for location duplicates for different repositories\n    known_location = {}\n    for adptr in adapter.adapter.all_adapters():\n        location = adptr.local_repository_location()\n        if not location:\n            continue\n        if location in known_location \\\n            and adptr.repository_url() != known_location[location].repository_url():\n            fatal(\"Duplicate location: %s for %s and %s\"\n                  % (location, adptr, known_location[location]))\n        known_location[location] = adptr\n\n    # Parent directories creation\n    # target subdirectories will be create during the checkout process,\n    # but the parent directories should be created explicitly.\n    # Also we should make sure, that the target directory does not exist\n    existing_locations = []\n    for location in known_location:\n        if os.path.exists(location):\n            if skip_existing:\n                existing_locations.append(location)\n                print(\"Already exists %s\" % (location))\n            else:\n                fatal(\"%s already exists\" % location)\n\n        parent = os.path.dirname(location)\n        if os.path.exists(parent):\n            continue\n\n        os.makedirs(parent)\n\n    known_location = {k:v for k, v in known_location.items() if k not in existing_locations}\n    _fetch_locations(known_location)\n\ndef _update_adapter(adptr):\n    \"\"\"\n    Update implementation.\n\n    If `adptr` returns no update_command(), it is being ignored.\n    \"\"\"\n    os.chdir(adptr.local_repository_location())\n\n    cmd = adptr.update_command()\n    if not cmd:\n        return True\n\n    errorcode, output = _run_cmd(cmd)\n    if errorcode:\n        _log(\"\\nERROR:\\n---%s\\n\" % output.decode(\"utf-8\") + \"\\n---\\nCould not update %s\" % adptr)\n        return False\n\n    # Getting current repository state\n    # This state will be saved after the update procedure is finished\n    # (all cache entries invalidated)\n    cmd = adptr.current_state_command()\n    state = None\n    if cmd:\n        errorcode, state = _run_cmd(cmd)\n        if errorcode:\n            _log(\"\\nERROR:\\n---\\n\" + state + \"\\n---\\nCould not get repository state: %s\" % adptr)\n            return False\n        state = state.strip()\n\n    # Getting list of files that were changed\n    # that will be later converted to the list of the pages to be invalidated\n    cmd = adptr.get_updates_list_command()\n    updates = []\n    if cmd:\n        errorcode, output = _run_cmd(cmd)\n        output = output.decode(\"utf-8\")\n        if errorcode:\n            _log(\"\\nERROR:\\n---\\n\" + output + \"\\n---\\nCould not get list of pages to be updated: %s\" % adptr)\n            return False\n        updates = output.splitlines()\n\n    entries = adptr.get_updates_list(updates)\n    if entries:\n        _log(\"%s Entries to be updated: %s\", adptr, len(entries))\n\n    name = adptr.name()\n    for entry in entries:\n        cache_name = name + \":\" + entry\n        _log(\"+ invalidating %s\", cache_name)\n        cache.delete(cache_name)\n\n    if entries:\n        _log(\"Done\")\n\n    adptr.save_state(state)\n    return True\n\ndef update_all():\n    \"\"\"\n    Update all known repositories, mentioned in the adapters\n    and fetched locally.\n    If repository is not fetched, it is skipped.\n    \"\"\"\n\n    for adptr in adapter.adapter.all_adapters():\n        location = adptr.local_repository_location()\n        if not location:\n            continue\n        if not os.path.exists(location):\n            continue\n\n        _update_adapter(adptr)\n\ndef update_by_name(name):\n    \"\"\"\n    Find adapter by its `name` and update only it.\n    \"\"\"\n    pass\n\ndef _show_usage():\n    sys.stdout.write(textwrap.dedent(\"\"\"\n        Usage:\n\n            python lib/fetch.py [command]\n        \n        Commands:\n        \n            update-all      -- update all configured repositories\n            update [name]   -- update repository of the adapter `name`\n            fetch-all       -- fetch all configured repositories\n\n    \"\"\"))\n\ndef main(args):\n    \"\"\"\n    function for the initial repositories fetch and manual repositories updates\n    \"\"\"\n\n    if not args:\n        _show_usage()\n        sys.exit(0)\n\n    logdir = os.path.dirname(CONFIG[\"path.log.fetch\"])\n    if not os.path.exists(logdir):\n        os.makedirs(logdir)\n\n    logging.basicConfig(\n        filename=CONFIG[\"path.log.fetch\"],\n        level=logging.DEBUG,\n        format='%(asctime)s %(message)s')\n\n    if args[0] == 'fetch-all':\n        fetch_all()\n    elif args[0] == 'update':\n        update_by_name(sys.argv[1])\n    elif args[0] == 'update-all':\n        update_all()\n    else:\n        _show_usage()\n        sys.exit(0)\n\nif __name__ == '__main__':\n    main(sys.argv[1:])\n", "lib/options.py": "\"\"\"\nParse query arguments.\n\"\"\"\n\ndef parse_args(args):\n    \"\"\"\n    Parse arguments and options.\n    Replace short options with their long counterparts.\n    \"\"\"\n    result = {\n        'add_comments':  True,\n    }\n\n    query = \"\"\n    newargs = {}\n    for key, val in args.items():\n        if val == \"\" or val == [] or val == ['']:\n            query += key\n            continue\n        if val == 'True':\n            val = True\n        if val == 'False':\n            val = False\n        newargs[key] = val\n\n    options_meaning = {\n        \"c\": dict(add_comments=False, unindent_code=False),\n        \"C\": dict(add_comments=False, unindent_code=True),\n        \"Q\": dict(remove_text=True),\n        'q': dict(quiet=True),\n        'T': {'no-terminal': True},\n    }\n    for option, meaning in options_meaning.items():\n        if option in query:\n            result.update(meaning)\n\n    result.update(newargs)\n\n    return result\n", "lib/config.py": "\"\"\"\nGlobal configuration of the project.\n\nAll configurable parameters are stored in the global variable CONFIG,\nthe only variable which is exported from the module.\n\nDefault values of all configuration parameters are specified\nin the `_CONFIG` dictionary. Those parameters can be overridden\nby three means:\n    * config file `etc/config.yaml` located in the work dir\n    * config file `etc/config.yaml` located in the project dir\n      (if the work dir and the project dir are not the same)\n    * environment variables prefixed with `CHEATSH_`\n\nConfiguration placement priorities, from high to low:\n    * environment variables;\n    * configuration file in the workdir\n    * configuration file in the project dir\n    * default values specified in the `_CONFIG` dictionary\n\nIf the work dir and the project dir are not the same, we do not\nrecommend that you use the config file located in the project dir,\nexcept the cases when you use your own cheat.sh fork, and thus\nconfiguration is a part of the project repository.\nIn all other cases `WORKDIR/etc/config.yaml` should be preferred.\nLocation of this config file can be overridden by the `CHEATSH_PATH_CONFIG`\nenvironment variable.\n\nConfiguration parameters set by environment variables are mapped\nin this way:\n    * CHEATSH_ prefix is trimmed\n    * _ replaced with .\n    * the string is lowercased\n\nFor instance, an environment variable named `CHEATSH_SERVER_PORT`\nspecifies the value for the `server.port` configuration parameter.\n\nOnly parameters that imply scalar values (integer or string)\ncan be set using environment variables, for the rest config files\nshould be used. If a parameter implies an integer, and the value\nspecified by an environment variable is not an integer, it is ignored.\n\"\"\"\n\nfrom __future__ import print_function\nimport os\n\nfrom pygments.styles import get_all_styles\n#def get_all_styles():\n#    return []\n\n_ENV_VAR_PREFIX = \"CHEATSH\"\n\n_MYDIR = os.path.abspath(os.path.join(__file__, '..', '..'))\n\ndef _config_locations():\n    \"\"\"\n    Return three possible config locations\n    where configuration can be found:\n    * `_WORKDIR`, `_CONF_FILE_WORKDIR`, `_CONF_FILE_MYDIR`\n    \"\"\"\n\n    var = _ENV_VAR_PREFIX + '_PATH_WORKDIR'\n    workdir = os.environ[var] if var in os.environ \\\n        else os.path.join(os.environ['HOME'], '.cheat.sh')\n\n    var = _ENV_VAR_PREFIX + '_CONFIG'\n    conf_file_workdir = os.environ[var] if var in os.environ \\\n            else os.path.join(workdir, 'etc/config.yaml')\n\n    conf_file_mydir = os.path.join(_MYDIR, 'etc/config.yaml')\n    return workdir, conf_file_workdir, conf_file_mydir\n\n_WORKDIR, _CONF_FILE_WORKDIR, _CONF_FILE_MYDIR = _config_locations()\n\n_CONFIG = {\n    \"adapters.active\": [\n        \"tldr\",\n        \"cheat\",\n        \"fosdem\",\n        \"translation\",\n        \"rosetta\",\n        \"late.nz\",\n        \"question\",\n        \"cheat.sheets\",\n        \"cheat.sheets dir\",\n        \"learnxiny\",\n        \"rfc\",\n        \"oeis\",\n        \"chmod\",\n        ],\n    \"adapters.mandatory\": [\n        \"search\",\n        ],\n    \"cache.redis.db\": 0,\n    \"cache.redis.host\": \"localhost\",\n    \"cache.redis.port\": 6379,\n    \"cache.redis.prefix\": \"\",\n    \"cache.type\": \"redis\",\n    \"frontend.styles\": sorted(list(get_all_styles())),\n    \"log.level\": 4,\n    \"path.internal.ansi2html\": os.path.join(_MYDIR, \"share/ansi2html.sh\"),\n    \"path.internal.bin\": os.path.join(_MYDIR, \"bin\"),\n    \"path.internal.bin.upstream\": os.path.join(_MYDIR, \"bin\", \"upstream\"),\n    \"path.internal.malformed\": os.path.join(_MYDIR, \"share/static/malformed-response.html\"),\n    \"path.internal.pages\": os.path.join(_MYDIR, \"share\"),\n    \"path.internal.static\": os.path.join(_MYDIR, \"share/static\"),\n    \"path.internal.templates\": os.path.join(_MYDIR, \"share/templates\"),\n    \"path.internal.vim\": os.path.join(_MYDIR, \"share/vim\"),\n    \"path.log.main\": \"log/main.log\",\n    \"path.log.queries\": \"log/queries.log\",\n    \"path.log.fetch\": \"log/fetch.log\",\n    \"path.repositories\": \"upstream\",\n    \"path.spool\": \"spool\",\n    \"path.workdir\": _WORKDIR,\n    \"routing.pre\": [\n        (\"^$\", \"search\"),\n        (\"^[^/]*/rosetta(/|$)\", \"rosetta\"),\n        (\"^rfc/\", \"rfc\"),\n        (\"^oeis/\", \"oeis\"),\n        (\"^chmod/\", \"chmod\"),\n        (\"^:\", \"internal\"),\n        (\"/:list$\", \"internal\"),\n        (\"/$\", \"cheat.sheets dir\"),\n        ],\n    \"routing.main\": [\n        (\"\", \"cheat.sheets\"),\n        (\"\", \"cheat\"),\n        (\"\", \"tldr\"),\n        (\"\", \"late.nz\"),\n        (\"\", \"fosdem\"),\n        (\"\", \"learnxiny\"),\n    ],\n    \"routing.post\": [\n        (\"^[^/ +]*$\", \"unknown\"),\n        (\"^[a-z][a-z]-[a-z][a-z]$\", \"translation\"),\n        ],\n    \"routing.default\": \"question\",\n    \"upstream.url\": \"https://cheat.sh\",\n    \"upstream.timeout\": 5,\n    \"search.limit\": 20,\n    \"server.bind\": \"0.0.0.0\",\n    \"server.port\": 8002,\n    }\n\nclass Config(dict):\n    \"\"\"\n    configuration dictionary that handles relative\n    paths properly (making them relative to path.workdir)\n    \"\"\"\n\n    def _absolute_path(self, val):\n        if val.startswith('/'):\n            return val\n        return os.path.join(self['path.workdir'], val)\n\n    def __init__(self, *args, **kwargs):\n        dict.__init__(self)\n        self.update(*args, **kwargs)\n\n    def __setitem__(self, key, val):\n        if key.startswith('path.') and not val.startswith('/'):\n            val = self._absolute_path(val)\n        dict.__setitem__(self, key, val)\n\n    def update(self, *args, **kwargs):\n        \"\"\"\n        the built-in __init__ doesn't call update,\n        and the built-in update doesn't call __setitem__,\n        so `update` should be overridden\n        \"\"\"\n\n        newdict = dict(*args, **kwargs)\n        if 'path.workdir' in newdict:\n            self['path.workdir'] = newdict['path.workdir']\n\n        for key, val in newdict.items():\n            self[key] = val\n\ndef _load_config_from_environ(config):\n\n    update = {}\n    for key, val in config.items():\n        if not isinstance(val, str) or isinstance(val, int):\n            continue\n\n        env_var = _ENV_VAR_PREFIX + '_' + key.replace('.', '_').upper()\n        if not env_var in os.environ:\n            continue\n\n        env_val = os.environ[env_var]\n        if isinstance(val, int):\n            try:\n                env_val = int(env_val)\n            except (ValueError, TypeError):\n                continue\n\n        update[key] = env_val\n\n    return update\n\ndef _get_nested(data, key):\n    \"\"\"\n    Return value for a hierrachical key (like a.b.c).\n    Return None if nothing found.\n    If there is a key with . in the name, and a subdictionary,\n    the former is preferred:\n\n    >>> print(_get_nested({'a.b': 10, 'a':{'b': 20}}, 'a.b'))\n    10\n    >>> print(_get_nested({'a': {'b': 20}}, 'a.b'))\n    20\n    >>> print(_get_nested({'a': {'b': {'c': 30}}}, 'a.b.c'))\n    30\n    \"\"\"\n\n    if not data or not isinstance(data, dict):\n        return None\n    if '.' not in key:\n        return data.get(key)\n    if key in data:\n        return data[key]\n\n    parts = key.split('.')\n    for i in range(len(parts))[::-1]:\n        prefix = \".\".join(parts[:i])\n        if prefix in data:\n            return _get_nested(data[prefix], \".\".join(parts[i:]))\n\n    return None\n\ndef _load_config_from_file(default_config, filename):\n    import yaml\n\n    update = {}\n    if not os.path.exists(filename):\n        return update\n\n    with open(filename) as f:\n        newconfig = yaml.load(f.read(), Loader=yaml.SafeLoader)\n    for key, val in default_config.items():\n        newval = _get_nested(newconfig, key)\n        if newval is None:\n            continue\n\n        if isinstance(val, int):\n            try:\n                newval = int(newval)\n            except (ValueError, TypeError):\n                continue\n\n        update[key] = newval\n\n    return update\n\nCONFIG = Config()\nCONFIG.update(_CONFIG)\nCONFIG.update(_load_config_from_file(_CONFIG, _CONF_FILE_MYDIR))\nif _CONF_FILE_WORKDIR != _CONF_FILE_MYDIR:\n    CONFIG.update(_load_config_from_file(_CONFIG, _CONF_FILE_WORKDIR))\nCONFIG.update(_load_config_from_environ(_CONFIG))\n\nif __name__ == \"__main__\":\n    import doctest\n    doctest.testmod()\n", "lib/stateful_queries.py": "\"\"\"\nSupport for the stateful queries\n\"\"\"\n\nimport cache\n\ndef save_query(client_id, query):\n    \"\"\"\n    Save the last query `query` for the client `client_id`\n    \"\"\"\n    cache.put(\"l:%s\" % client_id, query)\n\ndef last_query(client_id):\n    \"\"\"\n    Return the last query for the client `client_id`\n    \"\"\"\n    return cache.get(\"l:%s\" % client_id)\n", "lib/search.py": "\"\"\"\nVery naive search implementation. Just a placeholder.\n\nExports:\n\n    find_answer_by_keyword()\n\nIt should be implemented on the adapter basis:\n\n    1. adapter.search(keyword) returns list of matching answers\n        * maybe with some initial weight\n    2. ranking is done\n    3. sorted results are returned\n    4. eage page are cut by keyword\n    5. results are paginated\n\nConfiguration parameters:\n\n    search.limit\n\"\"\"\n\nimport re\n\nfrom config import CONFIG\nfrom routing import get_answers, get_topics_list\n\ndef _limited_entry():\n    return {\n        'topic_type': 'LIMITED',\n        \"topic\": \"LIMITED\",\n        'answer': \"LIMITED TO %s ANSWERS\" % CONFIG['search.limit'],\n        'format': \"code\",\n    }\n\ndef _parse_options(options):\n    \"\"\"Parse search options string into optiond_dict\n    \"\"\"\n\n    if options is None:\n        return {}\n\n    search_options = {\n        'insensitive': 'i' in options,\n        'word_boundaries': 'b' in options,\n        'recursive': 'r' in options,\n    }\n    return search_options\n\ndef match(paragraph, keyword, options=None, options_dict=None):\n    \"\"\"Search for each keyword from `keywords` in `page`\n    and if all of them are found, return `True`.\n    Otherwise return `False`.\n\n    Several keywords can be joined together using ~\n    For example: ~ssh~passphrase\n    \"\"\"\n\n    if keyword is None:\n        return True\n\n    if '~' in keyword:\n        keywords = keyword.split('~')\n    else:\n        keywords = [keyword]\n\n    if options_dict is None:\n        options_dict = _parse_options(options)\n\n    for kwrd in keywords:\n        if not kwrd:\n            continue\n\n        regex = re.escape(kwrd)\n        if options_dict[\"word_boundaries\"]:\n            regex = r\"\\b%s\\b\" % kwrd\n\n        if options_dict[\"insensitive\"]:\n            if not re.search(regex, paragraph, re.IGNORECASE):\n                return False\n        else:\n            if not re.search(regex, paragraph):\n                return False\n    return True\n\ndef find_answers_by_keyword(directory, keyword, options=\"\", request_options=None):\n    \"\"\"\n    Search in the whole tree of all cheatsheets or in its subtree `directory`\n    by `keyword`\n    \"\"\"\n\n    options_dict = _parse_options(options)\n\n    answers_found = []\n    for topic in get_topics_list(skip_internal=True, skip_dirs=True):\n\n        if not topic.startswith(directory):\n            continue\n\n        subtopic = topic[len(directory):]\n        if not options_dict[\"recursive\"] and '/' in subtopic:\n            continue\n\n        answer_dicts = get_answers(topic, request_options=request_options)\n        for answer_dict in answer_dicts:\n            answer_text = answer_dict.get('answer', '')\n            # Temporary hotfix:\n            # In some cases answer_text may be 'bytes' and not 'str'\n            if type(b\"\") == type(answer_text):\n                answer_text = answer_text.decode(\"utf-8\")\n\n            if match(answer_text, keyword, options_dict=options_dict):\n                answers_found.append(answer_dict)\n\n        if len(answers_found) > CONFIG['search.limit']:\n            answers_found.append(\n                _limited_entry()\n            )\n            break\n\n    return answers_found\n", "lib/routing.py": "\"\"\"\nQueries routing and caching.\n\nExports:\n\n    get_topics_list()\n    get_answers()\n\"\"\"\n\nimport random\nimport re\nfrom typing import Any, Dict, List\n\nimport cache\nimport adapter.cheat_sheets\nimport adapter.cmd\nimport adapter.internal\nimport adapter.latenz\nimport adapter.learnxiny\nimport adapter.question\nimport adapter.rosetta\nfrom config import CONFIG\n\nclass Router(object):\n\n    \"\"\"\n    Implementation of query routing. Routing is based on `routing_table`\n    and the data exported by the adapters (functions `get_list()` and `is_found()`).\n\n    `get_topics_list()` returns available topics (accessible at /:list).\n    `get_answer_dict()` return answer for the query.\n    \"\"\"\n\n    def __init__(self):\n\n        self._cached_topics_list = []\n        self._cached_topic_type = {}\n\n        adapter_class = adapter.all_adapters(as_dict=True)\n\n        active_adapters = set(CONFIG['adapters.active'] + CONFIG['adapters.mandatory'])\n\n        self._adapter = {\n            \"internal\": adapter.internal.InternalPages(\n                get_topic_type=self.get_topic_type,\n                get_topics_list=self.get_topics_list),\n            \"unknown\": adapter.internal.UnknownPages(\n                get_topic_type=self.get_topic_type,\n                get_topics_list=self.get_topics_list),\n        }\n\n        for by_name in active_adapters:\n            if by_name not in self._adapter:\n                self._adapter[by_name] = adapter_class[by_name]()\n\n        self._topic_list = {\n            key: obj.get_list()\n            for key, obj in self._adapter.items()\n        }\n\n        self.routing_table = CONFIG[\"routing.main\"]\n        self.routing_table = CONFIG[\"routing.pre\"] + self.routing_table + CONFIG[\"routing.post\"]\n\n    def get_topics_list(self, skip_dirs=False, skip_internal=False):\n        \"\"\"\n        List of topics returned on /:list\n        \"\"\"\n\n        if self._cached_topics_list:\n            return self._cached_topics_list\n\n        skip = ['fosdem']\n        if skip_dirs:\n            skip.append(\"cheat.sheets dir\")\n        if skip_internal:\n            skip.append(\"internal\")\n        sources_to_merge = [x for x in self._adapter if x not in skip]\n\n        answer = {}\n        for key in sources_to_merge:\n            answer.update({name:key for name in self._topic_list[key]})\n        answer = sorted(set(answer.keys()))\n\n        self._cached_topics_list = answer\n        return answer\n\n    def get_topic_type(self, topic: str) -> List[str]:\n        \"\"\"\n        Return list of topic types for `topic`\n        or [\"unknown\"] if topic can't be determined.\n        \"\"\"\n\n        def __get_topic_type(topic: str) -> List[str]:\n            result = []\n            for regexp, route in self.routing_table:\n                if re.search(regexp, topic):\n                    if route in self._adapter:\n                        if self._adapter[route].is_found(topic):\n                            result.append(route)\n                    else:\n                        result.append(route)\n            if not result:\n                return [CONFIG[\"routing.default\"]]\n\n            # cut the default route off, if there are more than one route found\n            if len(result) > 1:\n                return result[:-1]\n            return result\n\n        if topic not in self._cached_topic_type:\n            self._cached_topic_type[topic] = __get_topic_type(topic)\n        return self._cached_topic_type[topic]\n\n    def _get_page_dict(self, query, topic_type, request_options=None):\n        \"\"\"\n        Return answer_dict for the `query`.\n        \"\"\"\n        return self._adapter[topic_type]\\\n               .get_page_dict(query, request_options=request_options)\n\n    def handle_if_random_request(self, topic):\n        \"\"\"\n        Check if the `query` is a :random one,\n        if yes we check its correctness and then randomly select a topic,\n        based on the provided prefix.\n\n        \"\"\"\n\n        def __select_random_topic(prefix, topic_list):\n            #Here we remove the special cases\n            cleaned_topic_list = [ x for x in topic_list if '/' not in x and ':' not in x]\n\n            #Here we still check that cleaned_topic_list in not empty\n            if not cleaned_topic_list:\n                return prefix\n                \n            random_topic = random.choice(cleaned_topic_list)\n            return prefix + random_topic\n        \n        if topic.endswith('/:random') or topic.lstrip('/') == ':random':\n            #We strip the :random part and see if the query is valid by running a get_topics_list()\n            if topic.lstrip('/') == ':random' :\n                 topic = topic.lstrip('/')\n            prefix = topic[:-7]\n            \n            topic_list = [x[len(prefix):]\n                         for x in self.get_topics_list()\n                         if x.startswith(prefix)]\n\n            if '' in topic_list: \n                topic_list.remove('')\n\n            if topic_list:                \n                # This is a correct formatted random query like /cpp/:random as the topic_list is not empty.\n                random_topic = __select_random_topic(prefix, topic_list)\n                return random_topic\n            else:\n                # This is a wrongly formatted random query like /xyxyxy/:random as the topic_list is empty\n                # we just strip the /:random and let the already implemented logic handle it.\n                wrongly_formatted_random = topic[:-8]\n                return wrongly_formatted_random\n\n        #Here if not a random requst, we just forward the topic\n        return topic\n    \n    def get_answers(self, topic: str, request_options:Dict[str, str] = None) -> List[Dict[str, Any]]:\n        \"\"\"\n        Find cheat sheets for the topic.\n\n        Args:\n            `topic` (str):    the name of the topic of the cheat sheet\n\n        Returns:\n            [answer_dict]:    list of answers (dictionaries)\n        \"\"\"\n        \n        # if topic specified as <topic_type>:<topic>,\n        # cut <topic_type> off\n        topic_type = \"\"\n        if re.match(\"[^/]+:\", topic):\n            topic_type, topic = topic.split(\":\", 1)\n\n        topic = self.handle_if_random_request(topic)\n        topic_types = self.get_topic_type(topic)\n\n        # if topic_type is specified explicitly,\n        # show pages only of that type\n        if topic_type and topic_type in topic_types:\n            topic_types = [topic_type]\n\n        # 'question' queries are pretty expensive, that's why they should be handled\n        # in a special way:\n        # we do not drop the old style cache entries and try to reuse them if possible\n        if topic_types == ['question']:\n            answer = cache.get('q:' + topic)\n            if answer:\n                if isinstance(answer, dict):\n                    return [answer]\n                return [{\n                    'topic': topic,\n                    'topic_type': 'question',\n                    'answer': answer,\n                    'format': 'text+code',\n                    }]\n\n            answer = self._get_page_dict(topic, topic_types[0], request_options=request_options)\n            if answer.get(\"cache\", True):\n                cache.put('q:' + topic, answer)\n            return [answer]\n\n        # Try to find cacheable queries in the cache.\n        # If answer was not found in the cache, resolve it in a normal way and save in the cache\n        answers = []\n        for topic_type in topic_types:\n\n            cache_entry_name = f\"{topic_type}:{topic}\"\n            cache_needed = self._adapter[topic_type].is_cache_needed()\n\n            if cache_needed:\n                answer = cache.get(cache_entry_name)\n                if not isinstance(answer, dict):\n                    answer = None\n                if answer:\n                    answers.append(answer)\n                    continue\n\n            answer = self._get_page_dict(topic, topic_type, request_options=request_options)\n            if isinstance(answer, dict):\n                if \"cache\" in answer:\n                    cache_needed = answer[\"cache\"]\n\n            if cache_needed and answer:\n                cache.put(cache_entry_name, answer)\n\n            answers.append(answer)\n\n        return answers\n\n# pylint: disable=invalid-name\n_ROUTER = Router()\nget_topics_list = _ROUTER.get_topics_list\nget_answers = _ROUTER.get_answers\n", "lib/cheat_wrapper.py": "\"\"\"\nMain cheat.sh wrapper.\nParse the query, get answers from getters (using get_answer),\nvisualize it using frontends and return the result.\n\nExports:\n\n    cheat_wrapper()\n\"\"\"\n\nimport re\nimport json\n\nfrom routing import get_answers, get_topics_list\nfrom search import find_answers_by_keyword\nfrom languages_data import LANGUAGE_ALIAS, rewrite_editor_section_name\nimport postprocessing\n\nimport frontend.html\nimport frontend.ansi\n\ndef _add_section_name(query):\n    # temporary solution before we don't find a fixed one\n    if ' ' not in query and '+' not in query:\n        return query\n    if '/' in query:\n        return query\n    if ' ' in query:\n        return re.sub(r' +', '/', query, count=1)\n    if '+' in query:\n        # replace only single + to avoid catching g++ and friends\n        return re.sub(r'([^\\+])\\+([^\\+])', r'\\1/\\2',  query, count=1)\n\ndef cheat_wrapper(query, request_options=None, output_format='ansi'):\n    \"\"\"\n    Function that delivers cheat sheet for `query`.\n    If `html` is True, the answer is formatted as HTML.\n    Additional request options specified in `request_options`.\n    \"\"\"\n\n    def _rewrite_aliases(word):\n        if word == ':bash.completion':\n            return ':bash_completion'\n        return word\n\n    def _rewrite_section_name(query):\n        \"\"\"\n        Rewriting special section names:\n        * EDITOR:NAME => emacs:go-mode\n        \"\"\"\n\n        if '/' not in query:\n            return query\n\n        section_name, rest = query.split('/', 1)\n\n        if ':' in section_name:\n            section_name = rewrite_editor_section_name(section_name)\n        section_name = LANGUAGE_ALIAS.get(section_name, section_name)\n\n        return \"%s/%s\" % (section_name, rest)\n\n    def _sanitize_query(query):\n        return re.sub('[<>\"]', '', query)\n\n    def _strip_hyperlink(query):\n        return re.sub('(,[0-9]+)+$', '', query)\n\n    def _parse_query(query):\n        topic = query\n        keyword = None\n        search_options = \"\"\n\n        keyword = None\n        if '~' in query:\n            topic = query\n            pos = topic.index('~')\n            keyword = topic[pos+1:]\n            topic = topic[:pos]\n\n            if '/' in keyword:\n                search_options = keyword[::-1]\n                search_options = search_options[:search_options.index('/')]\n                keyword = keyword[:-len(search_options)-1]\n\n        return topic, keyword, search_options\n\n    query = _sanitize_query(query)\n    query = _add_section_name(query)\n    query = _rewrite_aliases(query)\n    query = _rewrite_section_name(query)\n\n    # at the moment, we just remove trailing slashes\n    # so queries python/ and python are equal\n    # query = _strip_hyperlink(query.rstrip('/'))\n    topic, keyword, search_options = _parse_query(query)\n\n    if keyword:\n        answers = find_answers_by_keyword(\n            topic, keyword, options=search_options, request_options=request_options)\n    else:\n        answers = get_answers(topic, request_options=request_options)\n\n    answers = [\n        postprocessing.postprocess(\n            answer, keyword, search_options, request_options=request_options)\n        for answer in answers\n    ]\n\n    answer_data = {\n        'query': query,\n        'keyword': keyword,\n        'answers': answers,\n        }\n\n    if output_format == 'html':\n        answer_data['topics_list'] = get_topics_list()\n        return frontend.html.visualize(answer_data, request_options)\n    elif output_format == 'json':\n        return json.dumps(answer_data, indent=4)\n    return frontend.ansi.visualize(answer_data, request_options)\n", "lib/postprocessing.py": "import search\nimport fmt.comments\n\ndef postprocess(answer, keyword, options, request_options=None):\n    answer = _answer_add_comments(answer, request_options=request_options)\n    answer = _answer_filter_by_keyword(answer, keyword, options, request_options=request_options)\n    return answer\n\ndef _answer_add_comments(answer, request_options=None):\n\n    if answer['format'] != 'text+code':\n        return answer\n\n    topic = answer['topic']\n    if \"filetype\" in answer:\n        filetype = answer[\"filetype\"]\n    else:\n        filetype = 'bash'\n        if '/' in topic:\n            filetype = topic.split('/', 1)[0]\n            if filetype.startswith('q:'):\n                filetype = filetype[2:]\n\n    answer['answer'] = fmt.comments.beautify(\n        answer['answer'], filetype, request_options)\n    answer['format'] = 'code'\n    answer['filetype'] = filetype\n    return answer\n\ndef _answer_filter_by_keyword(answer, keyword, options, request_options=None):\n    answer['answer'] = _filter_by_keyword(answer['answer'], keyword, options)\n    return answer\n\ndef _filter_by_keyword(answer, keyword, options):\n\n    def _join_paragraphs(paragraphs):\n        answer = \"\\n\".join(paragraphs)\n        return answer\n\n    def _split_paragraphs(text):\n        answer = []\n        paragraph = \"\"\n        if isinstance(text, bytes):\n            text = text.decode(\"utf-8\")\n        for line in text.splitlines():\n            if line == \"\":\n                answer.append(paragraph)\n                paragraph = \"\"\n            else:\n                paragraph += line+\"\\n\"\n        answer.append(paragraph)\n        return answer\n\n    paragraphs = [p for p in _split_paragraphs(answer)\n                  if search.match(p, keyword, options=options)]\n    if not paragraphs:\n        return \"\"\n\n    return _join_paragraphs(paragraphs)\n", "lib/post.py": "\"\"\"\nPOST requests processing.\nCurrently used only for new cheat sheets submission.\n\nConfiguration parameters:\n\n    path.spool\n\"\"\"\n\nimport string\nimport os\nimport random\nfrom config import CONFIG\n\ndef _save_cheatsheet(topic_name, cheatsheet):\n    \"\"\"\n    Save posted cheat sheet `cheatsheet` with `topic_name`\n    in the spool directory\n    \"\"\"\n\n    nonce = ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(9))\n    filename = topic_name.replace('/', '.') + \".\" + nonce\n    filename = os.path.join(CONFIG[\"path.spool\"], filename)\n\n    open(filename, 'w').write(cheatsheet)\n\ndef process_post_request(req, topic):\n    \"\"\"\n    Process POST request `req`.\n    \"\"\"\n    for key, val in req.form.items():\n        if key == '':\n            if topic is None:\n                topic_name = \"UNNAMED\"\n            else:\n                topic_name = topic\n            cheatsheet = val\n        else:\n            if val == '':\n                if topic is None:\n                    topic_name = \"UNNAMED\"\n                else:\n                    topic_name = topic\n                cheatsheet = key\n            else:\n                topic_name = key\n                cheatsheet = val\n\n        _save_cheatsheet(topic_name, cheatsheet)\n", "lib/globals.py": "\"\"\"\nGlobal functions that our used everywhere in the project.\nPlease, no global variables here.\nFor the configuration related things see `config.py`\n\"\"\"\n\nfrom __future__ import print_function\n\nimport sys\nimport logging\n\ndef fatal(text):\n    \"\"\"\n    Fatal error function.\n\n    The function is being used in the standalone mode only\n    \"\"\"\n    sys.stderr.write(\"ERROR: %s\\n\" % text)\n    sys.exit(1)\n\ndef error(text):\n    \"\"\"\n    Log error `text` and produce a RuntimeError exception\n    \"\"\"\n    if not text.startswith(\"Too many queries\"):\n        print(text)\n    logging.error(\"ERROR %s\", text)\n    raise RuntimeError(text)\n\ndef log(text):\n    \"\"\"\n    Log error `text` (if it does not start with 'Too many queries')\n    \"\"\"\n    if not text.startswith(\"Too many queries\"):\n        print(text)\n        logging.info(text)\n", "lib/limits.py": "\"\"\"\nConnection limitation.\n\nNumber of connections from one IP is limited.\nWe have nothing against scripting and automated queries.\nEven the opposite, we encourage them. But there are some\nconnection limits that even we can't handle.\nCurrently the limits are quite restrictive, but they will be relaxed\nin the future.\n\nUsage:\n\n        limits = Limits()\n        not_allowed = limits.check_ip(ip_address)\n        if not_allowed:\n            return \"ERROR: %s\" % not_allowed\n\"\"\"\n\nimport time\nfrom globals import log\n\n_WHITELIST = ['5.9.243.177']\n\ndef _time_caps(minutes, hours, days):\n    return {\n        'min':   minutes,\n        'hour':  hours,\n        'day':   days,\n        }\n\nclass Limits(object):\n    \"\"\"\n    Queries limitation (by IP).\n\n    Exports:\n\n        check_ip(ip_address)\n    \"\"\"\n\n    def __init__(self):\n        self.intervals = ['min', 'hour', 'day']\n\n        self.divisor = _time_caps(60, 3600, 86400)\n        self.limit = _time_caps(30, 600, 1000)\n        self.last_update = _time_caps(0, 0, 0)\n\n        self.counter = {\n            'min':      {},\n            'hour':     {},\n            'day':      {},\n            }\n\n        self._clear_counters_if_needed()\n\n    def _log_visit(self, interval, ip_address):\n        if ip_address not in self.counter[interval]:\n            self.counter[interval][ip_address] = 0\n        self.counter[interval][ip_address] += 1\n\n    def _limit_exceeded(self, interval, ip_address):\n        visits = self.counter[interval][ip_address]\n        limit = self._get_limit(interval)\n        return  visits > limit\n\n    def _get_limit(self, interval):\n        return self.limit[interval]\n\n    def _report_excessive_visits(self, interval, ip_address):\n        log(\"%s LIMITED [%s for %s]\" % (ip_address, self._get_limit(interval), interval))\n\n    def check_ip(self, ip_address):\n        \"\"\"\n        Check if `ip_address` is allowed, and if not raise an RuntimeError exception.\n        Return True otherwise\n        \"\"\"\n        if ip_address in _WHITELIST:\n            return None\n        self._clear_counters_if_needed()\n        for interval in self.intervals:\n            self._log_visit(interval, ip_address)\n            if self._limit_exceeded(interval, ip_address):\n                self._report_excessive_visits(interval, ip_address)\n                return (\"Not so fast! Number of queries per %s is limited to %s\"\n                        % (interval, self._get_limit(interval)))\n        return None\n\n    def reset(self):\n        \"\"\"\n        Reset all counters for all IPs\n        \"\"\"\n        for interval in self.intervals:\n            self.counter[interval] = {}\n\n    def _clear_counters_if_needed(self):\n        current_time = int(time.time())\n        for interval in self.intervals:\n            if current_time // self.divisor[interval] != self.last_update[interval]:\n                self.counter[interval] = {}\n                self.last_update[interval] = current_time / self.divisor[interval]\n", "lib/cache.py": "\"\"\"\nCache implementation.\nCurrently only two types of cache are allowed:\n    * \"none\"    cache switched off\n    * \"redis\"   use redis for cache\n\nConfiguration parameters:\n\n    cache.type = redis | none\n    cache.redis.db\n    cache.redis.host\n    cache.redis.port\n\"\"\"\n\nimport os\nimport json\nfrom config import CONFIG\n\n_REDIS = None\nif CONFIG['cache.type'] == 'redis':\n    import redis\n    _REDIS = redis.Redis(\n        host=CONFIG['cache.redis.host'],\n        port=CONFIG['cache.redis.port'],\n        db=CONFIG['cache.redis.db'])\n\n_REDIS_PREFIX = ''\nif CONFIG.get(\"cache.redis.prefix\", \"\"):\n    _REDIS_PREFIX = CONFIG[\"cache.redis.prefix\"] + \":\"\n\ndef put(key, value):\n    \"\"\"\n    Save `value` with `key`, and serialize it if needed\n    \"\"\"\n\n    if _REDIS_PREFIX:\n        key = _REDIS_PREFIX + key\n\n    if CONFIG[\"cache.type\"] == \"redis\" and _REDIS:\n        if isinstance(value, (dict, list)):\n            value = json.dumps(value)\n\n        _REDIS.set(key, value)\n\ndef get(key):\n    \"\"\"\n    Read `value` by `key`, and deserialize it if needed\n    \"\"\"\n\n    if _REDIS_PREFIX:\n        key = _REDIS_PREFIX + key\n\n    if CONFIG[\"cache.type\"] == \"redis\" and _REDIS:\n        value = _REDIS.get(key)\n        try:\n            value = json.loads(value)\n        except (ValueError, TypeError):\n            pass\n        return value\n    return None\n\ndef delete(key):\n    \"\"\"\n    Remove `key` from the database\n    \"\"\"\n\n    if _REDIS:\n        if _REDIS_PREFIX:\n            key = _REDIS_PREFIX + key\n\n        _REDIS.delete(key)\n\n    return None\n", "lib/buttons.py": "TWITTER_BUTTON = \"\"\"\n<a href=\"https://twitter.com/igor_chubin\" class=\"twitter-follow-button\" data-show-count=\"false\" data-button=\"grey\">Follow @igor_chubin</a>\n<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>\n\"\"\"\n\nGITHUB_BUTTON = \"\"\"\n<!-- Place this tag where you want the button to render. -->\n<a aria-label=\"Star chubin/wttr.in on GitHub\" data-count-aria-label=\"# stargazers on GitHub\" data-count-api=\"/repos/chubin/cheat.sh#stargazers_count\" data-count-href=\"/chubin/cheat.sh/stargazers\" data-icon=\"octicon-star\" href=\"https://github.com/chubin/cheat.sh\" class=\"github-button\">cheat.sh</a>\n\"\"\"\n\nGITHUB_BUTTON_2 = \"\"\"\n<!-- Place this tag where you want the button to render. -->\n<a aria-label=\"Star chubin/cheat.sheets on GitHub\" data-count-aria-label=\"# stargazers on GitHub\" data-count-api=\"/repos/chubin/cheat.sheets#stargazers_count\" data-count-href=\"/chubin/cheat.sheets/stargazers\" data-icon=\"octicon-star\" href=\"https://github.com/chubin/cheat.sheets\" class=\"github-button\">cheat.sheets</a>\n\"\"\"\n\nGITHUB_BUTTON_FOOTER = \"\"\"\n<!-- Place this tag right after the last button or just before your close body tag. -->\n<script async defer id=\"github-bjs\" src=\"https://buttons.github.io/buttons.js\"></script>\n\"\"\"\n\n", "lib/standalone.py": "\"\"\"\nStandalone wrapper for the cheat.sh server.\n\"\"\"\n\nfrom __future__ import print_function\n\nimport sys\nimport textwrap\ntry:\n    import urlparse\nexcept ModuleNotFoundError:\n    import urllib.parse as urlparse\n\nimport config\nconfig.CONFIG[\"cache.type\"] = \"none\"\n\nimport cheat_wrapper\nimport options\n\ndef show_usage():\n    \"\"\"\n    Show how to use the program in the standalone mode\n    \"\"\"\n\n    print(textwrap.dedent(\"\"\"\n        Usage:\n\n            lib/standalone.py [OPTIONS] QUERY\n\n        For OPTIONS see :help\n    \"\"\")[1:-1])\n\ndef parse_cmdline(args):\n    \"\"\"\n    Parses command line arguments and returns\n    query and request_options\n    \"\"\"\n\n    if not args:\n        show_usage()\n        sys.exit(0)\n\n    query_string = \" \".join(args)\n    parsed = urlparse.urlparse(\"https://srv:0/%s\" % query_string)\n    request_options = options.parse_args(\n        urlparse.parse_qs(parsed.query, keep_blank_values=True))\n\n    query = parsed.path.lstrip(\"/\")\n    if not query:\n        query = \":firstpage\"\n\n    return query, request_options\n\n\ndef main(args):\n    \"\"\"\n    standalone wrapper for cheat_wrapper()\n    \"\"\"\n\n    query, request_options = parse_cmdline(args)\n    answer, _ = cheat_wrapper.cheat_wrapper(query, request_options=request_options)\n    sys.stdout.write(answer)\n\nif __name__ == '__main__':\n    main(sys.argv[1:])\n", "lib/fmt/internal.py": "\"\"\"\nColorize internal cheat sheets.\nWill be merged with panela later.\n\"\"\"\n\nimport re\n\nfrom colorama import Fore, Back, Style\nimport colored\n\nPALETTES = {\n    0: {\n        1: Fore.WHITE,\n        2: Style.DIM,\n    },\n    1: {\n        1: Fore.CYAN,\n        2: Fore.GREEN,\n        3: colored.fg('orange_3'),\n        4: Style.DIM,\n        5: Style.DIM,\n    },\n    2: {\n        1: Fore.RED,\n        2: Style.DIM,\n    },\n}\n\n\n\ndef _reverse_palette(code):\n    return {\n        1 : Fore.BLACK + _back_color(code),\n        2 : Style.DIM\n    }\n\ndef _back_color(code):\n    if code == 0 or (isinstance(code, str) and code.lower() == \"white\"):\n        return Back.WHITE\n    if code == 1 or (isinstance(code, str) and code.lower() == \"cyan\"):\n        return Back.CYAN\n    if code == 2 or (isinstance(code, str) and code.lower() == \"red\"):\n        return Back.RED\n\n    return Back.WHITE\n\ndef colorize_internal(text, palette_number=1):\n    \"\"\"\n    Colorize `text`, use `palette`\n    \"\"\"\n\n    palette = PALETTES[palette_number]\n    palette_reverse = _reverse_palette(palette_number)\n    def _process_text(text):\n        text = text.group()[1:-1]\n        factor = 1\n        if text.startswith('-'):\n            text = text[1:]\n            factor = -1\n        stripped = text.lstrip('0123456789')\n        return (text, stripped, factor)\n\n    def _extract_color_number(text, stripped, factor=1):\n        return int(text[:len(text)-len(stripped)])*factor\n\n    def _colorize_curlies_block(text):\n        text, stripped, factor = _process_text(text)\n        color_number = _extract_color_number(text, stripped, factor)\n\n        if stripped.startswith('='):\n            stripped = stripped[1:]\n\n        reverse = (color_number < 0)\n        if reverse:\n            color_number = -color_number\n\n        if reverse:\n            stripped = palette_reverse[color_number] + stripped + Style.RESET_ALL\n        else:\n            stripped = palette[color_number] + stripped + Style.RESET_ALL\n\n        return stripped\n\n    def _colorize_headers(text):\n        if text.group(0).endswith('\\n'):\n            newline = '\\n'\n        else:\n            newline = ''\n\n        color_number = 3\n        return palette[color_number] + text.group(0).strip() + Style.RESET_ALL + newline\n\n    text = re.sub(\"{.*?}\", _colorize_curlies_block, text)\n    text = re.sub(\"#(.*?)\\n\", _colorize_headers, text)\n    return text\n\ndef colorize_internal_firstpage_v1(answer):\n    \"\"\"\n    Colorize \"/:firstpage-v1\".\n    Legacy.\n    \"\"\"\n\n    def _colorize_line(line):\n        if line.startswith('T'):\n            line = colored.fg(\"grey_62\") + line + colored.attr('reset')\n            line = re.sub(r\"\\{(.*?)\\}\", colored.fg(\"orange_3\") + r\"\\1\"+colored.fg('grey_35'), line)\n            return line\n\n        line = re.sub(r\"\\[(F.*?)\\]\",\n                      colored.bg(\"black\") + colored.fg(\"cyan\") + r\"[\\1]\"+colored.attr('reset'),\n                      line)\n        line = re.sub(r\"\\[(g.*?)\\]\",\n                      colored.bg(\"dark_gray\")+colored.fg(\"grey_0\")+r\"[\\1]\"+colored.attr('reset'),\n                      line)\n        line = re.sub(r\"\\{(.*?)\\}\",\n                      colored.fg(\"orange_3\") + r\"\\1\"+colored.attr('reset'),\n                      line)\n        line = re.sub(r\"<(.*?)>\",\n                      colored.fg(\"cyan\") + r\"\\1\"+colored.attr('reset'),\n                      line)\n        return line\n\n    lines = answer.splitlines()\n    answer_lines = lines[:9]\n    answer_lines.append(colored.fg('grey_35')+lines[9]+colored.attr('reset'))\n    for line in lines[10:]:\n        answer_lines.append(_colorize_line(line))\n    answer = \"\\n\".join(answer_lines) + \"\\n\"\n\n    return answer\n", "lib/fmt/__init__.py": "", "lib/fmt/comments.py": "\"\"\"\nExtract text from the text-code stream and comment it.\n\nSupports three modes of normalization and commenting:\n\n    1. Don't add any comments\n    2. Add comments\n    3. Remove text, leave code only\n\nSince several operations are quite expensive,\nit actively uses caching.\n\nExported functions:\n\n    beautify(text, lang, options)\n    code_blocks(text)\n\nConfiguration parameters:\n\"\"\"\n\nfrom __future__ import print_function\n\nimport sys\nimport os\nimport textwrap\nimport hashlib\nimport re\nfrom itertools import groupby, chain\nfrom subprocess import Popen\nfrom tempfile import NamedTemporaryFile\n\nfrom config import CONFIG\nfrom languages_data import VIM_NAME\nimport cache\n\nFNULL = open(os.devnull, 'w')\nTEXT = 0\nCODE = 1\nUNDEFINED = -1\nCODE_WHITESPACE = -2\ndef _language_name(name):\n    return VIM_NAME.get(name, name)\n\n\ndef _remove_empty_lines_from_beginning(lines):\n    start = 0\n    while start < len(lines) and lines[start].strip() == '':\n        start += 1\n    lines = lines[start:]\n    return lines\n\ndef _remove_empty_lines_from_end(lines):\n    end = len(lines) - 1\n    while end >= 0 and lines[end].strip() == '':\n        end -= 1\n    lines = lines[:end+1]\n    return lines\n\ndef _cleanup_lines(lines):\n    \"\"\"\n    Cleanup `lines` a little bit: remove empty lines at the beginning\n    and at the end; remove too many empty lines in between.\n    \"\"\"\n    lines = _remove_empty_lines_from_beginning(lines)\n    lines = _remove_empty_lines_from_end(lines)\n    if lines == []:\n        return lines\n    # remove repeating empty lines\n    lines = list(chain.from_iterable(\n        [(list(x[1]) if x[0] else [''])\n         for x in groupby(lines, key=lambda x: x.strip() != '')]))\n\n    return lines\n\n\ndef _line_type(line):\n    \"\"\"\n    Classify each line and say which of them\n    are text (0) and which of them are code (1).\n\n    A line is considered to be code,\n    if it starts with four spaces.\n\n    A line is considerer to be text if it is not\n    empty and is not code.\n\n    If line is empty, it is considered to be\n    code if it surrounded but two other code lines,\n    or if it is the first/last line and it has\n    code on the other side.\n    \"\"\"\n    if line.strip() == '':\n        return UNDEFINED\n\n    # some line may start with spaces but still be not code.\n    # we need some heuristics here, but for the moment just\n    # whitelist such cases:\n    if line.strip().startswith('* ') or re.match(r'[0-9]+\\.', line.strip()):\n        return TEXT\n\n    if line.startswith('   '):\n        return CODE\n    return TEXT\n\ndef _classify_lines(lines):\n    line_types = [_line_type(line) for line in lines]\n\n    # pass 2:\n    # adding empty code lines to the code\n    for i in range(len(line_types) - 1):\n        if line_types[i] == CODE and line_types[i+1] == UNDEFINED:\n            line_types[i+1] = CODE_WHITESPACE\n            changed = True\n\n    for i in range(len(line_types) - 1)[::-1]:\n        if line_types[i] == UNDEFINED and line_types[i+1] == CODE:\n            line_types[i] = CODE_WHITESPACE\n            changed = True\n    line_types = [CODE if x == CODE_WHITESPACE else x for x in line_types]\n\n    # pass 3:\n    # fixing undefined line types (-1)\n    changed = True\n    while changed:\n        changed = False\n\n        # changing all lines types that are near the text\n\n        for i in range(len(line_types) - 1):\n            if line_types[i] == TEXT and line_types[i+1] == UNDEFINED:\n                line_types[i+1] = TEXT\n                changed = True\n\n        for i in range(len(line_types) - 1)[::-1]:\n            if line_types[i] == UNDEFINED and line_types[i+1] == TEXT:\n                line_types[i] = TEXT\n                changed = True\n\n    # everything what is still undefined, change to code type\n    line_types = [CODE if x == UNDEFINED else x for x in line_types]\n    return line_types\n\ndef _unindent_code(line, shift=0):\n    if shift == -1 and line != '':\n        return ' ' + line\n\n    if shift > 0 and line.startswith(' '*shift):\n        return line[shift:]\n\n    return line\n\ndef _wrap_lines(lines_classes, unindent_code=False):\n    \"\"\"\n    Wrap classified lines. Add the split lines to the stream.\n    If `unindent_code` is True, remove leading four spaces.\n    \"\"\"\n\n    result = []\n    for line_type, line_content in lines_classes:\n        if line_type == CODE:\n\n            shift = 3 if unindent_code else -1\n            result.append((line_type, _unindent_code(line_content, shift=shift)))\n        else:\n            if line_content.strip() == \"\":\n                result.append((line_type, \"\"))\n            for line in textwrap.fill(line_content).splitlines():\n                result.append((line_type, line))\n\n    return result\n\ndef _run_vim_script(script_lines, text_lines):\n    \"\"\"\n    Apply `script_lines` to `lines_classes`\n    and returns the result\n    \"\"\"\n\n    script_vim = NamedTemporaryFile(delete=True)\n    textfile = NamedTemporaryFile(delete=True)\n\n    open(script_vim.name, \"w\").write(\"\\n\".join(script_lines))\n    open(textfile.name, \"w\").write(\"\\n\".join(text_lines))\n\n    script_vim.file.close()\n    textfile.file.close()\n\n    my_env = os.environ.copy()\n    my_env['HOME'] = CONFIG[\"path.internal.vim\"]\n\n    cmd = [\"script\", \"-q\", \"-c\",\n           \"vim -S %s %s\" % (script_vim.name, textfile.name)]\n\n    Popen(cmd, shell=False,\n          stdin=open(os.devnull, 'r'),\n          stdout=FNULL, stderr=FNULL, env=my_env).communicate()\n\n    return open(textfile.name, \"r\").read()\n\ndef _commenting_script(lines_blocks, filetype):\n    script_lines = []\n    block_start = 1\n    for block in lines_blocks:\n        lines = list(block[1])\n\n        block_end = block_start + len(lines)-1\n\n        if block[0] == 0:\n            comment_type = 'sexy'\n            if block_end - block_start < 1 or filetype == 'ruby':\n                comment_type = 'comment'\n\n            script_lines.insert(0, \"%s,%s call NERDComment(1, '%s')\"\n                                % (block_start, block_end, comment_type))\n            script_lines.insert(0, \"%s,%s call NERDComment(1, 'uncomment')\"\n                                % (block_start, block_end))\n\n        block_start = block_end + 1\n\n    script_lines.insert(0, \"set ft=%s\" % _language_name(filetype))\n    script_lines.append(\"wq\")\n\n    return script_lines\n\ndef _beautify(text, filetype, add_comments=False, remove_text=False):\n    \"\"\"\n    Main function that actually does the whole beautification job.\n    \"\"\"\n\n    # We shift the code if and only if we either convert the text into comments\n    # or remove the text completely. Otherwise the code has to remain aligned\n    unindent_code = add_comments or remove_text\n\n    lines = [x.decode(\"utf-8\").rstrip('\\n') for x in text.splitlines()]\n    lines = _cleanup_lines(lines)\n    lines_classes = zip(_classify_lines(lines), lines)\n    lines_classes = _wrap_lines(lines_classes, unindent_code=unindent_code)\n\n    if remove_text:\n        lines = [line[1] for line in lines_classes if line[0] == 1]\n        lines = _cleanup_lines(lines)\n        output = \"\\n\".join(lines)\n        if not output.endswith('\\n'):\n            output += \"\\n\"\n    elif not add_comments:\n        output = \"\\n\".join(line[1] for line in lines_classes)\n    else:\n        lines_blocks = groupby(lines_classes, key=lambda x: x[0])\n        script_lines = _commenting_script(lines_blocks, filetype)\n        output = _run_vim_script(\n            script_lines,\n            [line for (_, line) in lines_classes])\n\n    return output\n\ndef code_blocks(text, wrap_lines=False, unindent_code=False):\n    \"\"\"\n    Split `text` into blocks of text and code.\n    Return list of tuples TYPE, TEXT\n    \"\"\"\n    text = text.encode('utf-8')\n\n    lines = [x.rstrip('\\n') for x in text.splitlines()]\n    lines_classes = zip(_classify_lines(lines), lines)\n\n    if wrap_lines:\n        lines_classes = _wrap_lines(lines_classes, unindent_code=unindent_code)\n\n    lines_blocks = groupby(lines_classes, key=lambda x: x[0])\n    answer = [(x[0], \"\\n\".join([y[1] for y in x[1]])+\"\\n\") for x in lines_blocks]\n    return answer\n\n\ndef beautify(text, lang, options):\n    \"\"\"\n    Process input `text` according to the specified `mode`.\n    Adds comments if needed, according to the `lang` rules.\n    Caches the results.\n    The whole work (except caching) is done by _beautify().\n    \"\"\"\n\n    options = options or {}\n    beauty_options = dict((k, v) for k, v in options.items() if k in\n                          ['add_comments', 'remove_text'])\n\n    mode = ''\n    if beauty_options.get('add_comments'):\n        mode += 'c'\n    if beauty_options.get('remove_text'):\n        mode += 'q'\n\n    if beauty_options == {}:\n        # if mode is unknown, just don't transform the text at all\n        return text\n\n    if isinstance(text, str):\n        text = text.encode('utf-8')\n    digest = \"t:%s:%s:%s\" % (hashlib.md5(text).hexdigest(), lang, mode)\n\n    # temporary added line that removes invalid cache entries\n    # that used wrong commenting methods\n    if lang in [\"git\", \"django\", \"flask\", \"cmake\"]:\n        cache.delete(digest)\n\n    answer = cache.get(digest)\n    if answer:\n        return answer\n    answer = _beautify(text, lang, **beauty_options)\n    cache.put(digest, answer)\n\n    return answer\n\ndef __main__():\n    text = sys.stdin.read()\n    filetype = sys.argv[1]\n    options = {\n        \"\": {},\n        \"c\": dict(add_comments=True),\n        \"C\": dict(add_comments=False),\n        \"q\": dict(remove_text=True),\n    }[sys.argv[2]]\n    result = beautify(text, filetype, options)\n    sys.stdout.write(result)\n\nif __name__ == '__main__':\n    __main__()\n", "lib/fmt/markdown.py": "\"\"\"\nMarkdown support.\n\nExports:\n    format_text(text, config=None, highlighter=None):\n\nUses external pygments formatters for highlighting (passed as an argument).\n\"\"\"\n\nimport re\nimport ansiwrap\nimport colored\n\ndef format_text(text, config=None, highlighter=None):\n    \"\"\"\n    Renders `text` according to markdown rules.\n    Uses `highlighter` for syntax highlighting.\n    Returns a dictionary with \"output\" and \"links\".\n    \"\"\"\n    return _format_section(text, config=config, highlighter=highlighter)\n\ndef _split_into_paragraphs(text):\n    return re.split('\\n\\n+', text)\n\ndef _colorize(text):\n    return \\\n        re.sub(\n            r\"`(.*?)`\",\n            colored.bg(\"dark_gray\") \\\n                + colored.fg(\"white\") \\\n                + \" \" + r\"\\1\" + \" \" \\\n                + colored.attr('reset'),\n            re.sub(\n                r\"\\*\\*(.*?)\\*\\*\",\n                colored.attr('bold') \\\n                    + colored.fg(\"white\") \\\n                    + r\"\\1\" \\\n                    + colored.attr('reset'),\n                text))\n\ndef _format_section(section_text, config=None, highlighter=None):\n\n    answer = ''\n\n    # cut code blocks\n    block_number = 0\n    while True:\n        section_text, replacements = re.subn(\n            '^```.*?^```',\n            'MULTILINE_BLOCK_%s' % block_number,\n            section_text,\n            1,\n            flags=re.S | re.MULTILINE)\n        block_number += 1\n        if not replacements:\n            break\n\n    # cut links\n    links = []\n    while True:\n        regexp = re.compile(r'\\[(.*?)\\]\\((.*?)\\)')\n        match = regexp.search(section_text)\n        if match:\n            links.append(match.group(0))\n            text = match.group(1)\n            # links are not yet supported\n            #\n            text = '\\x1B]8;;%s\\x1B\\\\\\\\%s\\x1B]8;;\\x1B\\\\\\\\' % (match.group(2), match.group(1))\n        else:\n            break\n\n\n        section_text, replacements = regexp.subn(\n            text, # 'LINK_%s' % len(links),\n            section_text,\n            1)\n        block_number += 1\n        if not replacements:\n            break\n\n    for paragraph in _split_into_paragraphs(section_text):\n        answer += \"\\n\".join(\n            ansiwrap.fill(_colorize(line)) + \"\\n\"\n            for line in paragraph.splitlines()) + \"\\n\"\n\n    return {\n        'ansi': answer,\n        'links': links\n    }\n", "lib/adapter/common.py": "class Adapter(object):\n    pass\n\nclass cheatAdapter(Adapter):\n    pass\n\n", "lib/adapter/cheat_cheat.py": "\"\"\"\nAdapter for https://github.com/cheat/cheat\n\nCheatsheets are located in `cheat/cheatsheets/`\nEach cheat sheet is a separate file without extension\n\"\"\"\n\n# pylint: disable=relative-import,abstract-method\n\nfrom .git_adapter import GitRepositoryAdapter\n\nclass Cheat(GitRepositoryAdapter):\n    \"\"\"\n    cheat/cheat adapter\n    \"\"\"\n\n    _adapter_name = \"cheat\"\n    _output_format = \"code\"\n    _cache_needed = True\n    _repository_url = \"https://github.com/cheat/cheatsheets\"\n    _cheatsheet_files_prefix = \"\"\n    _cheatsheet_file_mask = \"*\"\n", "lib/adapter/tldr.py": "\"\"\"\nAdapter for https://github.com/cheat/cheat\n\nCheatsheets are located in `pages/*/`\nEach cheat sheet is a separate file with extension .md\n\nThe pages are formatted with a markdown dialect\n\"\"\"\n\n# pylint: disable=relative-import,abstract-method\n\nimport re\nimport os\n\nfrom .git_adapter import GitRepositoryAdapter\n\nclass Tldr(GitRepositoryAdapter):\n\n    \"\"\"\n    tldr-pages/tldr adapter\n    \"\"\"\n\n    _adapter_name = \"tldr\"\n    _output_format = \"code\"\n    _cache_needed = True\n    _repository_url = \"https://github.com/tldr-pages/tldr\"\n    _cheatsheet_files_prefix = \"pages/*/\"\n    _cheatsheet_files_extension = \".md\"\n\n    @staticmethod\n    def _format_page(text):\n        \"\"\"\n        Trivial tldr Markdown implementation.\n\n        * Header goes until the first empty line after > prefixed lines.\n        * code surrounded with `` => code\n        * {{var}} => var\n        \"\"\"\n\n        answer = []\n        skip_empty = False\n        header = 2\n        for line in text.splitlines():\n            if line.strip() == '':\n                if skip_empty and not header:\n                    continue\n                if header == 1:\n                    header = 0\n                if header:\n                    continue\n            else:\n                skip_empty = False\n\n            if line.startswith('-'):\n                line = '# '+line[2:]\n                skip_empty = True\n            elif line.startswith('> '):\n                if header == 2:\n                    header = 1\n                line = '# '+line[2:]\n                skip_empty = True\n            elif line.startswith('`') and line.endswith('`'):\n                line = line[1:-1]\n                line = re.sub(r'{{(.*?)}}', r'\\1', line)\n\n            answer.append(line)\n\n        return \"\\n\".join(answer)\n\n    def _get_page(self, topic, request_options=None):\n        \"\"\"\n        Go through pages/{common,linux,osx,sunos,windows}/\n        and as soon as anything is found, format and return it.\n        \"\"\"\n\n        search_order = ['common', 'linux', 'osx', 'sunos', 'windows', \"android\"]\n        local_rep = self.local_repository_location()\n        ext = self._cheatsheet_files_extension\n\n        filename = None\n        for subdir in search_order:\n            _filename = os.path.join(\n                local_rep, 'pages', subdir, \"%s%s\" % (topic, ext))\n            if os.path.exists(_filename):\n                filename = _filename\n                break\n\n        if filename:\n            answer = self._format_page(open(filename, 'r').read())\n        else:\n            # though it should not happen\n            answer = ''\n\n        return answer\n\n    @classmethod\n    def get_updates_list(cls, updated_files_list):\n        \"\"\"\n        If a .md file was updated, invalidate cache\n        entry with the name of this file\n        \"\"\"\n        answer = []\n        ext = cls._cheatsheet_files_extension\n\n        for entry in updated_files_list:\n            if entry.endswith(ext):\n                answer.append(entry.split('/')[-1][:-len(ext)])\n        return answer\n", "lib/adapter/question.py": "\"\"\"\nConfiguration parameters:\n\n    path.internal.bin.upstream\n\"\"\"\n\n# pylint: disable=relative-import\n\nfrom __future__ import print_function\n\nimport os\nimport re\nfrom subprocess import Popen, PIPE\n\nfrom polyglot.detect import Detector\nfrom polyglot.detect.base import UnknownLanguage\n\nfrom config import CONFIG\nfrom languages_data import SO_NAME\nfrom .upstream import UpstreamAdapter\n\nNOT_FOUND_MESSAGE = \"\"\"404 NOT FOUND\n\nUnknown cheat sheet. Please try to reformulate your query.\nQuery format:\n\n    /LANG/QUESTION\n\nExamples:\n\n    /python/read+json\n    /golang/run+external+program\n    /js/regex+search\n\nSee /:help for more info.\n\nIf the problem persists, file a GitHub issue at\ngithub.com/chubin/cheat.sh or ping @igor_chubin\n\"\"\"\n\nclass Question(UpstreamAdapter):\n\n    \"\"\"\n    Answer to a programming language question, using Stackoverflow\n    as the main data source. Heavy lifting is done by an external\n    program `CONFIG[\"path.internal.bin.upstream\"]`.\n\n    If the program is not found, fallback to the superclass `UpstreamAdapter`,\n    which queries the upstream server (by default https://cheat.sh/)\n    for the answer\n    \"\"\"\n\n    _adapter_name = \"question\"\n    _output_format = \"text+code\"\n    _cache_needed = True\n\n    def _get_page(self, topic, request_options=None):\n        \"\"\"\n        Find answer for the `topic` question.\n        \"\"\"\n\n        if not os.path.exists(CONFIG[\"path.internal.bin.upstream\"]):\n            # if the upstream program is not found, use normal upstream adapter\n            self._output_format = \"ansi\"\n            return UpstreamAdapter._get_page(self, topic, request_options=request_options)\n\n        topic = topic.replace('+', ' ')\n\n        # if there is a language name in the section name,\n        # cut it off (de:python => python)\n        if '/' in topic:\n            section_name, topic = topic.split('/', 1)\n            if ':' in section_name:\n                _, section_name = section_name.split(':', 1)\n            section_name = SO_NAME.get(section_name, section_name)\n            topic = \"%s/%s\" % (section_name, topic)\n\n        # some clients send queries with - instead of + so we have to rewrite them to\n        topic = re.sub(r\"(?<!-)-\", ' ', topic)\n\n        topic_words = topic.split()\n\n        topic = \" \".join(topic_words)\n\n        lang = 'en'\n        try:\n            query_text = topic # \" \".join(topic)\n            query_text = re.sub('^[^/]*/+', '', query_text.rstrip('/'))\n            query_text = re.sub('/[0-9]+$', '', query_text)\n            query_text = re.sub('/[0-9]+$', '', query_text)\n            detector = Detector(query_text)\n            supposed_lang = detector.languages[0].code\n            if len(topic_words) > 2 \\\n                or supposed_lang in ['az', 'ru', 'uk', 'de', 'fr', 'es', 'it', 'nl']:\n                lang = supposed_lang\n            if supposed_lang.startswith('zh_') or supposed_lang == 'zh':\n                lang = 'zh'\n            elif supposed_lang.startswith('pt_'):\n                lang = 'pt'\n            if supposed_lang in ['ja', 'ko']:\n                lang = supposed_lang\n\n        except UnknownLanguage:\n            print(\"Unknown language (%s)\" % query_text)\n\n        if lang != 'en':\n            topic = ['--human-language', lang, topic]\n        else:\n            topic = [topic]\n\n        cmd = [CONFIG[\"path.internal.bin.upstream\"]] + topic\n        proc = Popen(cmd, stdin=open(os.devnull, \"r\"), stdout=PIPE, stderr=PIPE)\n        answer = proc.communicate()[0].decode('utf-8')\n\n        if not answer:\n            return NOT_FOUND_MESSAGE\n\n        return answer\n\n    def get_list(self, prefix=None):\n        return []\n\n    def is_found(self, topic):\n        return True\n", "lib/adapter/upstream.py": "\"\"\"\nAdapter for an external cheat sheets service (i.e. for cheat.sh)\n\nConfiguration parameters:\n\n    upstream.url\n    upstream.timeout\n\"\"\"\n\n# pylint: disable=relative-import\n\nimport textwrap\nimport requests\n\nfrom config import CONFIG\nfrom .adapter import Adapter\n\ndef _are_you_offline():\n    return textwrap.dedent(\n        \"\"\"\n         .\n                         Are you offline?\n            _________________\n           | | ___________ |o|   Though it could be theoretically possible\n           | | ___________ | |   to use cheat.sh fully offline,\n           | | ___________ | |   and for *the programming languages questions* too,\n           | | ___________ | |   this very feature is not yet implemented.\n           | |_____________| |\n           |     _______     |   If you find it useful, please visit\n           |    |       |   ||   https://github.com/chubin/issues/140\n           | DD |       |   V|   and drop a couple of lines to encourage\n           |____|_______|____|   the authors to develop it as soon as possible\n\n         .\n            \"\"\")\n\nclass UpstreamAdapter(Adapter):\n\n    \"\"\"\n    Connect to the upstream server `CONFIG[\"upstream.url\"]` and fetch\n    response from it. The response is supposed to have the \"ansi\" format.\n    If the server does not respond within `CONFIG[\"upstream.timeout\"]` seconds,\n    or if a connection error occurs, the \"are you offline\" banner is displayed.\n\n    Answers are by default cached; the failure answer is marked with the no-cache\n    property (\"cache\": False).\n    \"\"\"\n\n    _adapter_name = \"upstream\"\n    _output_format = \"ansi\"\n    _cache_needed = False\n\n    def _get_page(self, topic, request_options=None):\n\n        options_string = \"&\".join([\"%s=%s\" % (x, y) for (x, y) in request_options.items()])\n        url = CONFIG[\"upstream.url\"].rstrip('/') \\\n                + '/' + topic.lstrip('/') \\\n                + \"?\" + options_string\n        try:\n            response = requests.get(url, timeout=CONFIG[\"upstream.timeout\"])\n            answer = {\"cache\": False, \"answer\": response.text}\n        except requests.exceptions.ConnectionError:\n            answer = {\"cache\": False, \"answer\":_are_you_offline()}\n        return answer\n\n    def _get_list(self, prefix=None):\n        return []\n", "lib/adapter/internal.py": "\"\"\"\nConfiguration parameters:\n\n    frontend.styles\n    path.internal.pages\n\"\"\"\n\nimport sys\nimport os\nimport collections\n\ntry:\n    from rapidfuzz import process, fuzz\n    _USING_FUZZYWUZZY=False\nexcept ImportError:\n    from fuzzywuzzy import process, fuzz\n    _USING_FUZZYWUZZY=True\n\nfrom config import CONFIG\nfrom .adapter import Adapter\nfrom fmt.internal import colorize_internal\n\n_INTERNAL_TOPICS = [\n    \":cht.sh\",\n    \":bash_completion\",\n    \":emacs\",\n    \":emacs-ivy\",\n    \":firstpage\",\n    \":firstpage-v1\",\n    \":firstpage-v2\",\n    \":fish\",\n    \":help\",\n    \":intro\",\n    \":list\",\n    \":post\",\n    \":styles\",\n    \":styles-demo\",\n    \":vim\",\n    \":zsh\",\n    ]\n\n_COLORIZED_INTERNAL_TOPICS = [\n    ':intro',\n]\n\nclass InternalPages(Adapter):\n\n    _adapter_name = 'internal'\n    _output_format = 'ansi'\n\n    def __init__(self, get_topic_type=None, get_topics_list=None):\n        Adapter.__init__(self)\n        self.get_topic_type = get_topic_type\n        self.get_topics_list = get_topics_list\n\n    def _get_stat(self):\n        stat = collections.Counter([\n            self.get_topic_type(topic)\n            for topic in self.get_topics_list()\n        ])\n\n        answer = \"\"\n        for key, val in stat.items():\n            answer += \"%s %s\\n\" % (key, val)\n        return answer\n\n    @staticmethod\n    def get_list(prefix=None):\n        return _INTERNAL_TOPICS\n\n    def _get_list_answer(self, topic, request_options=None):\n        if '/' in topic:\n            topic_type, topic_name = topic.split('/', 1)\n            if topic_name == \":list\":\n                topic_list = [x[len(topic_type)+1:]\n                              for x in self.get_topics_list()\n                              if x.startswith(topic_type + \"/\")]\n                return \"\\n\".join(topic_list)+\"\\n\"\n\n        answer = \"\"\n        if topic == \":list\":\n            answer = \"\\n\".join(x for x in self.get_topics_list()) + \"\\n\"\n\n        return answer\n\n    def _get_page(self, topic, request_options=None):\n        if topic.endswith('/:list') or topic.lstrip('/') == ':list':\n            return self._get_list_answer(topic)\n\n        answer = \"\"\n        if topic == ':styles':\n            answer = \"\\n\".join(CONFIG[\"frontend.styles\"]) + \"\\n\"\n        elif topic == \":stat\":\n            answer = self._get_stat()+\"\\n\"\n        elif topic in _INTERNAL_TOPICS:\n            answer = open(os.path.join(CONFIG[\"path.internal.pages\"], topic[1:]+\".txt\"), \"r\").read()\n            if topic in _COLORIZED_INTERNAL_TOPICS:\n                answer = colorize_internal(answer)\n\n        return answer\n\n    def is_found(self, topic):\n        return (\n            topic in self.get_list()\n            or topic.endswith('/:list')\n        )\n\nclass UnknownPages(InternalPages):\n\n    _adapter_name = 'unknown'\n    _output_format = 'text'\n\n    @staticmethod\n    def get_list(prefix=None):\n        return []\n\n    @staticmethod\n    def is_found(topic):\n        return True\n\n    def _get_page(self, topic, request_options=None):\n        topics_list = self.get_topics_list()\n        if topic.startswith(':'):\n            topics_list = [x for x in topics_list if x.startswith(':')]\n        else:\n            topics_list = [x for x in topics_list if not x.startswith(':')]\n\n        if _USING_FUZZYWUZZY:\n            possible_topics = process.extract(topic, topics_list, scorer=fuzz.ratio)[:3]\n        else:\n            possible_topics = process.extract(topic, topics_list, limit=3, scorer=fuzz.ratio)\n        possible_topics_text = \"\\n\".join([(\"    * %s %s\" % (x[0], int(x[1]))) for x in possible_topics])\n        return \"\"\"\nUnknown topic.\nDo you mean one of these topics maybe?\n\n%s\n    \"\"\" % possible_topics_text\n\nclass Search(Adapter):\n\n    _adapter_name = 'search'\n    _output_format = 'text'\n    _cache_needed = False\n\n    @staticmethod\n    def get_list(prefix=None):\n        return []\n\n    def is_found(self, topic):\n        return False\n", "lib/adapter/latenz.py": "\"\"\"\nAdapter for the curlable latencies numbers (chubin/late.nz)\nThis module can be an example of a adapter for a python project.\n\nThe adapter exposes one page (\"latencies\") and several its aliases\n(\"latencies\", \"late.nz\", \"latency\")\n\"\"\"\n\n# pylint: disable=relative-import\n\nimport sys\nimport os\nfrom .git_adapter import GitRepositoryAdapter\n\nclass Latenz(GitRepositoryAdapter):\n\n    \"\"\"\n    chubin/late.nz Adapter\n    \"\"\"\n\n    _adapter_name = \"late.nz\"\n    _output_format = \"ansi\"\n    _repository_url = \"https://github.com/chubin/late.nz\"\n\n    def _get_page(self, topic, request_options=None):\n        sys.path.append(os.path.join(self.local_repository_location(), 'bin'))\n        import latencies\n        return latencies.render()\n\n    def _get_list(self, prefix=None):\n        return ['latencies']\n\n    def is_found(self, topic):\n        return topic.lower() in ['latencies', 'late.nz', 'latency']\n", "lib/adapter/learnxiny.py": "\"\"\"\nAdapters for the cheat sheets from the Learn X in Y project\n\nConfiguration parameters:\n\n    log.level\n\"\"\"\n\n# pylint: disable=relative-import\n\nfrom __future__ import print_function\nimport os\nimport re\nfrom config import CONFIG\nfrom .git_adapter import GitRepositoryAdapter\n\nclass LearnXinY(GitRepositoryAdapter):\n\n    \"\"\"\n    Adapter for the LearnXinY project\n    \"\"\"\n\n    _adapter_name = 'learnxiny'\n    _output_format = 'code'\n    _cache_needed = True\n    _repository_url = \"https://github.com/adambard/learnxinyminutes-docs\"\n\n    def __init__(self):\n        self.adapters = _ADAPTERS\n        GitRepositoryAdapter.__init__(self)\n\n    def _get_page(self, topic, request_options=None):\n        \"\"\"\n        Return cheat sheet for `topic`\n        or empty string if nothing found\n        \"\"\"\n        lang, topic = topic.split('/', 1)\n        if lang not in self.adapters:\n            return ''\n        return self.adapters[lang].get_page(topic)\n\n    def _get_list(self, prefix=None):\n        \"\"\"\n        Return list of all learnxiny topics\n        \"\"\"\n        answer = []\n        for language_adapter in self.adapters.values():\n            answer += language_adapter.get_list(prefix=True)\n        return answer\n\n    def is_found(self, topic):\n        \"\"\"\n        Return whether `topic` is a valid learnxiny topic\n        \"\"\"\n\n        if '/' not in topic:\n            return False\n\n        lang, topic = topic.split('/', 1)\n        if lang not in self.adapters:\n            return False\n\n        return self.adapters[lang].is_valid(topic)\n\nclass LearnXYAdapter(object):\n\n    \"\"\"\n    Parent class of all languages adapters\n    \"\"\"\n\n    _learn_xy_path = LearnXinY.local_repository_location()\n    _replace_with = {}\n    _filename = ''\n    prefix = ''\n    _replace_with = {}\n    _splitted = True\n    _block_cut_start = 2\n    _block_cut_end = 0\n\n    def __init__(self):\n        self._whole_cheatsheet = self._read_cheatsheet()\n        self._blocks = self._extract_blocks()\n\n        self._topics_list = [x for x, _ in self._blocks]\n        if \"Comments\" in self._topics_list:\n            self._topics_list = [x for x in self._topics_list if x != \"Comments\"] + [\"Comments\"]\n        self._topics_list += [\":learn\", \":list\"]\n        if self._whole_cheatsheet and CONFIG.get(\"log.level\") >= 5:\n            print(self.prefix, self._topics_list)\n\n    def _is_block_separator(self, before, now, after):\n        if (re.match(r'////////*', before)\n                and re.match(r'// ', now)\n                and re.match(r'////////*', after)):\n            block_name = re.sub(r'//\\s*', '', now).replace('(', '').replace(')', '')\n            block_name = '_'.join(block_name.strip(\", \").split())\n            for character in '/,':\n                block_name = block_name.replace(character, '')\n            for k in self._replace_with:\n                if k in block_name:\n                    block_name = self._replace_with[k]\n            return block_name\n        return None\n\n    def _cut_block(self, block, start_block=False):\n        if not start_block:\n            answer = block[self._block_cut_start:-self._block_cut_end]\n        if answer == []:\n            return answer\n        if answer[0].strip() == '':\n            answer = answer[1:]\n        if answer[-1].strip() == '':\n            answer = answer[:1]\n        return answer\n\n    def _read_cheatsheet(self):\n        filename = os.path.join(self._learn_xy_path, self._filename)\n\n        # if cheat sheets are not there (e.g. were not yet fetched),\n        # just skip it\n        if not os.path.exists(filename):\n            return None\n\n        with open(filename) as f_cheat_sheet:\n            code_mode = False\n            answer = []\n            for line in f_cheat_sheet.readlines():\n                if line.startswith('```'):\n                    if not code_mode:\n                        code_mode = True\n                        continue\n                    else:\n                        code_mode = False\n                if code_mode:\n                    answer.append(line.rstrip('\\n'))\n            return answer\n\n    def _extract_blocks(self):\n\n        if not self._splitted:\n            return []\n\n        lines = self._whole_cheatsheet\n        if lines is None:\n            return []\n\n        answer = []\n\n        block = []\n        block_name = \"Comments\"\n        for before, now, after in zip([\"\"]+lines, lines, lines[1:]):\n            new_block_name = self._is_block_separator(before, now, after)\n            if new_block_name:\n                if block_name:\n                    block_text = self._cut_block(block)\n                    if block_text != []:\n                        answer.append((block_name, block_text))\n                block_name = new_block_name\n                block = []\n                continue\n            else:\n                block.append(before)\n\n        answer.append((block_name, self._cut_block(block)))\n        return answer\n\n    def is_valid(self, name):\n        \"\"\"\n        Check whether topic `name` is valid.\n        \"\"\"\n\n        for topic_list in self._topics_list:\n            if topic_list == name:\n                return True\n        return False\n\n    def get_list(self, prefix=None):\n        \"\"\"\n        Get list of topics for `prefix`\n        \"\"\"\n        if prefix:\n            return [\"%s/%s\" % (self.prefix, x) for x in self._topics_list]\n        return self._topics_list\n\n    def get_page(self, name, partial=False):\n        \"\"\"\n        Return specified cheat sheet `name` for the language.\n        If `partial`, cheat sheet name may be shortened\n        \"\"\"\n\n        if name == \":list\":\n            return \"\\n\".join(self.get_list()) + \"\\n\"\n\n        if name == \":learn\":\n            if self._whole_cheatsheet:\n                return \"\\n\".join(self._whole_cheatsheet) + \"\\n\"\n            else:\n                return \"\"\n\n        if partial:\n            possible_names = []\n            for block_name, _ in self._blocks:\n                if block_name.startswith(name):\n                    possible_names.append(block_name)\n            if possible_names == [] or len(possible_names) > 1:\n                return None\n            name = possible_names[0]\n\n        for block_name, block_contents in self._blocks:\n            if block_name == name:\n                return \"\\n\".join(block_contents)\n\n        return None\n\n#\n# Specific programming languages LearnXY cheat sheets configurations\n# Contains much code for the moment; should contain data only\n# ideally should be replaced with YAML\n#\n\nclass LearnAwkAdapter(LearnXYAdapter):\n    \"Learn AWK in Y Minutes\"\n    prefix = \"awk\"\n    _filename = \"awk.html.markdown\"\n    _splitted = False\n\nclass LearnBashAdapter(LearnXYAdapter):\n    \"Learn Bash in Y Minutes\"\n    prefix = \"bash\"\n    _filename = \"bash.html.markdown\"\n    _splitted = False\n\nclass LearnBfAdapter(LearnXYAdapter):\n    \"Learn Brainfuck in Y Minutes\"\n    prefix = \"bf\"\n    _filename = \"bf.html.markdown\"\n    _splitted = False\n\nclass LearnCAdapter(LearnXYAdapter):\n    \"Learn C in Y Minutes\"\n    prefix = \"c\"\n    _filename = \"c.html.markdown\"\n    _splitted = False\n\nclass LearnChapelAdapter(LearnXYAdapter):\n    \"Learn Chapel in Y Minutes\"\n    prefix = \"chapel\"\n    _filename = \"chapel.html.markdown\"\n    _splitted = False\n\nclass LearnClojureAdapter(LearnXYAdapter):\n    \"\"\"\n    Learn Clojure in Y Minutes\n    \"\"\"\n\n    prefix = \"clojure\"\n    _filename = \"clojure.html.markdown\"\n\n    def _is_block_separator(self, before, now, after):\n        if (re.match(r'\\s*$', before)\n                and re.match(r';\\s*', now)\n                and re.match(r';;;;;;+', after)):\n            block_name = re.sub(r';\\s*', '', now)\n            block_name = '_'.join([x.strip(\",&:\") for x in  block_name.strip(\", \").split()])\n            return block_name\n        return None\n\n    @staticmethod\n    def _cut_block(block, start_block=False):\n        if not start_block:\n            answer = block[2:]\n        if answer[0].split() == '':\n            answer = answer[1:]\n        if answer[-1].split() == '':\n            answer = answer[:1]\n        return answer\n\nclass LearnCoffeeScriptAdapter(LearnXYAdapter):\n    \"Learn coffeescript in Y Minutes\"\n    prefix = \"coffee\"\n    _filename = \"coffeescript.html.markdown\"\n    _splitted = False\n\nclass LearnCppAdapter(LearnXYAdapter):\n    \"\"\"\n    Learn C++ in Y Minutes\n    \"\"\"\n\n    prefix = \"cpp\"\n    _filename = \"c++.html.markdown\"\n    _replace_with = {\n        'More_about_Objects': 'Prototypes',\n    }\n\n    def _is_block_separator(self, before, now, after):\n        if (re.match(r'////////*', before)\n                and re.match(r'// ', now)\n                and re.match(r'////////*', after)):\n            block_name = re.sub(r'//\\s*', '', now).replace('(', '').replace(')', '')\n            block_name = '_'.join(block_name.strip(\", \").split())\n            for character in '/,':\n                block_name = block_name.replace(character, '')\n            for k in self._replace_with:\n                if k in block_name:\n                    block_name = self._replace_with[k]\n            return block_name\n        return None\n\n    @staticmethod\n    def _cut_block(block, start_block=False):\n        answer = block[2:-1]\n        if answer == []:\n            return answer\n        if answer[0].split() == '':\n            answer = answer[1:]\n        if answer[-1].split() == '':\n            answer = answer[:1]\n        return answer\n\nclass LearnCsharpAdapter(LearnXYAdapter):\n    \"Learn C# in Y Minutes\"\n    prefix = \"csharp\"\n    _filename = \"csharp.html.markdown\"\n    _splitted = False\n\nclass LearnDAdapter(LearnXYAdapter):\n    \"Learn D in Y Minutes\"\n    prefix = \"d\"\n    _filename = \"d.html.markdown\"\n    _splitted = False\n\nclass LearnDartAdapter(LearnXYAdapter):\n    \"Learn Dart in Y Minutes\"\n    prefix = \"dart\"\n    _filename = \"dart.html.markdown\"\n    _splitted = False\n\nclass LearnFactorAdapter(LearnXYAdapter):\n    \"Learn Factor in Y Minutes\"\n    prefix = \"factor\"\n    _filename = \"factor.html.markdown\"\n    _splitted = False\n\nclass LearnForthAdapter(LearnXYAdapter):\n    \"Learn Forth in Y Minutes\"\n    prefix = \"forth\"\n    _filename = \"forth.html.markdown\"\n    _splitted = False\n\nclass LearnFsharpAdapter(LearnXYAdapter):\n    \"Learn F# in Y Minutes\"\n    prefix = \"fsharp\"\n    _filename = \"fsharp.html.markdown\"\n    _splitted = False\n\nclass LearnElispAdapter(LearnXYAdapter):\n    \"Learn Elisp in Y Minutes\"\n    prefix = \"elisp\"\n    _filename = \"elisp.html.markdown\"\n    _splitted = False\n\nclass LearnElixirAdapter(LearnXYAdapter):\n    \"\"\"\n    Learn Elixir in Y Minutes\n    \"\"\"\n\n    prefix = \"elixir\"\n    _filename = \"elixir.html.markdown\"\n    _replace_with = {\n        'More_about_Objects': 'Prototypes',\n    }\n\n    def _is_block_separator(self, before, now, after):\n        if (re.match(r'## ---*', before)\n                and re.match(r'## --', now)\n                and re.match(r'## ---*', after)):\n            block_name = re.sub(r'## --\\s*', '', now)\n            block_name = '_'.join(block_name.strip(\", \").split())\n            for character in '/,':\n                block_name = block_name.replace(character, '')\n            for k in self._replace_with:\n                if k in block_name:\n                    block_name = self._replace_with[k]\n            return block_name\n        return None\n\n    @staticmethod\n    def _cut_block(block, start_block=False):\n        answer = block[2:-1]\n        if answer[0].split() == '':\n            answer = answer[1:]\n        if answer[-1].split() == '':\n            answer = answer[:1]\n        return answer\n\nclass LearnElmAdapter(LearnXYAdapter):\n    \"\"\"\n    Learn Elm in Y Minutes\n    \"\"\"\n\n    prefix = \"elm\"\n    _filename = \"elm.html.markdown\"\n    _replace_with = {\n        'More_about_Objects': 'Prototypes',\n    }\n\n    def _is_block_separator(self, before, now, after):\n        if (re.match(r'\\s*', before)\n                and re.match(r'\\{--.*--\\}', now)\n                and re.match(r'\\s*', after)):\n            block_name = re.sub(r'\\{--+\\s*', '', now)\n            block_name = re.sub(r'--\\}', '', block_name)\n            block_name = '_'.join(block_name.strip(\", \").split())\n            for character in '/,':\n                block_name = block_name.replace(character, '')\n            for k in self._replace_with:\n                if k in block_name:\n                    block_name = self._replace_with[k]\n            return block_name\n        return None\n\n    @staticmethod\n    def _cut_block(block, start_block=False):\n        answer = block[2:-1]\n        if answer[0].split() == '':\n            answer = answer[1:]\n        if answer[-1].split() == '':\n            answer = answer[:1]\n        return answer\n\nclass LearnErlangAdapter(LearnXYAdapter):\n    \"\"\"\n    Learn Erlang in Y Minutes\n    \"\"\"\n\n    prefix = \"erlang\"\n    _filename = \"erlang.html.markdown\"\n\n    def _is_block_separator(self, before, now, after):\n        if (re.match('%%%%%%+', before)\n                and re.match(r'%%\\s+[0-9]+\\.', now)\n                and re.match('%%%%%%+', after)):\n            block_name = re.sub(r'%%+\\s+[0-9]+\\.\\s*', '', now)\n            block_name = '_'.join(block_name.strip('.').strip().split())\n            return block_name\n        return None\n\n    @staticmethod\n    def _cut_block(block, start_block=False):\n        answer = block[2:-1]\n        if answer[0].split() == '':\n            answer = answer[1:]\n        if answer[-1].split() == '':\n            answer = answer[:1]\n        return answer\n\nclass LearnFortranAdapter(LearnXYAdapter):\n    \"Learn Fortran in Y Minutes\"\n    prefix = \"fortran\"\n    _filename = \"fortran95.html.markdown\"\n    _splitted = False\n\nclass LearnGoAdapter(LearnXYAdapter):\n    \"Learn Go in Y Minutes\"\n    prefix = \"go\"\n    _filename = \"go.html.markdown\"\n    _splitted = False\n\nclass LearnGroovyAdapter(LearnXYAdapter):\n    \"Learn Groovy in Y Minutes\"\n    prefix = \"groovy\"\n    _filename = \"groovy.html.markdown\"\n    _splitted = False\n\nclass LearnJavaAdapter(LearnXYAdapter):\n    \"Learn Java in Y Minutes\"\n    prefix = \"java\"\n    _filename = \"java.html.markdown\"\n    _splitted = False\n\nclass LearnJavaScriptAdapter(LearnXYAdapter):\n    \"\"\"\n    Learn JavaScript in Y Minutes\n    \"\"\"\n    prefix = \"js\"\n    _filename = \"javascript.html.markdown\"\n    _replace_with = {\n        'More_about_Objects': 'Prototypes',\n    }\n\n    def _is_block_separator(self, before, now, after):\n        if (re.match('//////+', before)\n                and re.match(r'//+\\s+[0-9]+\\.', now)\n                and re.match(r'\\s*', after)):\n            block_name = re.sub(r'//+\\s+[0-9]+\\.\\s*', '', now)\n            block_name = '_'.join(block_name.strip(\", \").split())\n            for k in self._replace_with:\n                if k in block_name:\n                    block_name = self._replace_with[k]\n            return block_name\n        return None\n\n    @staticmethod\n    def _cut_block(block, start_block=False):\n        answer = block[2:-1]\n        if answer[0].split() == '':\n            answer = answer[1:]\n        if answer[-1].split() == '':\n            answer = answer[:1]\n        return answer\n\nclass LearnJuliaAdapter(LearnXYAdapter):\n    \"\"\"\n    Learn Julia in Y Minutes\n    \"\"\"\n    prefix = \"julia\"\n    _filename = \"julia.html.markdown\"\n\n    def _is_block_separator(self, before, now, after):\n        if (re.match('####+', before)\n                and re.match(r'##\\s*', now)\n                and re.match('####+', after)):\n            block_name = re.sub(r'##\\s+[0-9]+\\.\\s*', '', now)\n            block_name = '_'.join(block_name.strip(\", \").split())\n            return block_name\n        return None\n\n    @staticmethod\n    def _cut_block(block, start_block=False):\n        answer = block[2:-1]\n        if answer[0].split() == '':\n            answer = answer[1:]\n        if answer[-1].split() == '':\n            answer = answer[:1]\n        return answer\n\nclass LearnHaskellAdapter(LearnXYAdapter):\n    \"\"\"\n    Learn Haskell in Y Minutes\n    \"\"\"\n    prefix = \"haskell\"\n    _filename = \"haskell.html.markdown\"\n    _replace_with = {\n        'More_about_Objects': 'Prototypes',\n    }\n\n    def _is_block_separator(self, before, now, after):\n        if (re.match('------+', before)\n                and re.match(r'--+\\s+[0-9]+\\.', now)\n                and re.match('------+', after)):\n            block_name = re.sub(r'--+\\s+[0-9]+\\.\\s*', '', now)\n            block_name = '_'.join(block_name.strip(\", \").split())\n            for k in self._replace_with:\n                if k in block_name:\n                    block_name = self._replace_with[k]\n            return block_name\n        return None\n\n    @staticmethod\n    def _cut_block(block, start_block=False):\n        answer = block[2:-1]\n        if answer[0].split() == '':\n            answer = answer[1:]\n        if answer[-1].split() == '':\n            answer = answer[:1]\n        return answer\n\nclass LearnLispAdapter(LearnXYAdapter):\n    \"Learn Lisp in Y Minutes\"\n    prefix = \"lisp\"\n    _filename = \"common-lisp.html.markdown\"\n    _splitted = False\n\nclass LearnLuaAdapter(LearnXYAdapter):\n    \"\"\"\n    Learn Lua in Y Minutes\n    \"\"\"\n    prefix = \"lua\"\n    _filename = \"lua.html.markdown\"\n    _replace_with = {\n        '1_Metatables_and_metamethods': 'Metatables',\n        '2_Class-like_tables_and_inheritance': 'Class-like_tables',\n        'Variables_and_flow_control': 'Flow_control',\n    }\n\n    def _is_block_separator(self, before, now, after):\n        if (re.match('-----+', before)\n                and re.match('-------+', after)\n                and re.match(r'--\\s+[0-9]+\\.', now)):\n            block_name = re.sub(r'--+\\s+[0-9]+\\.\\s*', '', now)\n            block_name = '_'.join(block_name.strip('.').strip().split())\n            if block_name in self._replace_with:\n                block_name = self._replace_with[block_name]\n            return block_name\n        return None\n\n    @staticmethod\n    def _cut_block(block, start_block=False):\n        answer = block[2:-1]\n        if answer[0].split() == '':\n            answer = answer[1:]\n        if answer[-1].split() == '':\n            answer = answer[:1]\n        return answer\n\nclass LearnMathematicaAdapter(LearnXYAdapter):\n    \"Learn Mathematica in Y Minutes\"\n    prefix = \"mathematica\"\n    _filename = \"wolfram.html.markdown\"\n    _splitted = False\n\nclass LearnMatlabAdapter(LearnXYAdapter):\n    \"Learn Matlab in Y Minutes\"\n    prefix = \"matlab\"\n    _filename = \"matlab.html.markdown\"\n    _splitted = False\n\nclass LearnOctaveAdapter(LearnXYAdapter):\n    \"Learn Octave in Y Minutes\"\n    prefix = \"octave\"\n    _filename = \"matlab.html.markdown\"\n    _splitted = False\n\nclass LearnKotlinAdapter(LearnXYAdapter):\n    \"\"\"\n    Learn Kotlin in Y Minutes\n    \"\"\"\n    prefix = \"kotlin\"\n    _filename = \"kotlin.html.markdown\"\n\n    def _is_block_separator(self, before, now, after):\n        if (re.match('#######+', before)\n                and re.match('#######+', after)\n                and re.match(r'#+\\s+[0-9]+\\.', now)):\n            block_name = re.sub(r'#+\\s+[0-9]+\\.\\s*', '', now)\n            block_name = '_'.join(block_name.strip().split())\n            return block_name\n        return None\n\n    @staticmethod\n    def _cut_block(block, start_block=False):\n        answer = block[2:-1]\n        if answer[0].split() == '':\n            answer = answer[1:]\n        if answer[-1].split() == '':\n            answer = answer[:1]\n        return answer\n\nclass LearnObjectiveCAdapter(LearnXYAdapter):\n    \"Learn Objective C in Y Minutes\"\n    prefix = \"objective-c\"\n    _filename = \"objective-c.html.markdown\"\n    _splitted = False\n\nclass LearnOCamlAdapter(LearnXYAdapter):\n    \"\"\"\n    Learn OCaml in Y Minutes\n    \"\"\"\n    prefix = \"ocaml\"\n    _filename = \"ocaml.html.markdown\"\n    _replace_with = {\n        'More_about_Objects': 'Prototypes',\n    }\n\n    def _is_block_separator(self, before, now, after):\n        if (re.match(r'\\s*', before)\n                and re.match(r'\\(\\*\\*\\*+', now)\n                and re.match(r'\\s*', after)):\n            block_name = re.sub(r'\\(\\*\\*\\*+\\s*', '', now)\n            block_name = re.sub(r'\\s*\\*\\*\\*\\)', '', block_name)\n            block_name = '_'.join(block_name.strip(\", \").split())\n            for k in self._replace_with:\n                if k in block_name:\n                    block_name = self._replace_with[k]\n            return block_name\n        return None\n\n    @staticmethod\n    def _cut_block(block, start_block=False):\n        answer = block[2:-1]\n        if answer[0].split() == '':\n            answer = answer[1:]\n        if answer[-1].split() == '':\n            answer = answer[:1]\n        return answer\n\nclass LearnPerlAdapter(LearnXYAdapter):\n    \"\"\"\n    Learn Perl in Y Minutes\n    \"\"\"\n    prefix = \"perl\"\n    _filename = \"perl.html.markdown\"\n    _replace_with = {\n        'Conditional_and_looping_constructs': 'Control_Flow',\n        'Perl_variable_types': 'Types',\n        'Files_and_I/O': 'Files',\n        'Writing_subroutines': 'Subroutines',\n    }\n\n    def _is_block_separator(self, before, now, after):\n        if re.match(r'####+\\s+', now):\n            block_name = re.sub(r'#+\\s', '', now)\n            block_name = '_'.join(block_name.strip().split())\n            if block_name in self._replace_with:\n                block_name = self._replace_with[block_name]\n            return block_name\n        else:\n            return None\n\n    @staticmethod\n    def _cut_block(block, start_block=False):\n        if not start_block:\n            answer = block[2:]\n        if answer == []:\n            return answer\n        if answer[0].split() == '':\n            answer = answer[1:]\n        if answer[-1].split() == '':\n            answer = answer[:1]\n        return answer\n\nclass LearnPerl6Adapter(LearnXYAdapter):\n    \"Learn Perl 6 in Y Minutes\"\n    prefix = \"perl6\"\n    _filename = \"perl6.html.markdown\"\n    _splitted = False\n\nclass LearnPHPAdapter(LearnXYAdapter):\n    \"\"\"\n    Learn PHP in Y Minutes\n    \"\"\"\n    prefix = \"php\"\n    _filename = \"php.html.markdown\"\n\n    def _is_block_separator(self, before, now, after):\n        if (re.match(r'/\\*\\*\\*\\*\\*+', before)\n                and re.match(r'\\s*\\*/', after)\n                and re.match(r'\\s*\\*\\s*', now)):\n            block_name = re.sub(r'\\s*\\*\\s*', '', now)\n            block_name = re.sub(r'&', '', block_name)\n            block_name = '_'.join(block_name.strip().split())\n            return block_name\n        return None\n\n    @staticmethod\n    def _cut_block(block, start_block=False):\n        return block[2:]\n\nclass LearnPythonAdapter(LearnXYAdapter):\n    \"\"\"\n    Learn Python in Y Minutes\n    \"\"\"\n    prefix = \"python\"\n    _filename = \"python.html.markdown\"\n\n    def _is_block_separator(self, before, now, after):\n        if (re.match('#######+', before)\n                and re.match('#######+', after)\n                and re.match(r'#+\\s+[0-9]+\\.', now)):\n            block_name = re.sub(r'#+\\s+[0-9]+\\.\\s*', '', now)\n            block_name = '_'.join(block_name.strip().split())\n            return block_name\n        return None\n\n    @staticmethod\n    def _cut_block(block, start_block=False):\n        answer = block[2:-1]\n        if answer[0].split() == '':\n            answer = answer[1:]\n        if answer[-1].split() == '':\n            answer = answer[:1]\n        return answer\n\nclass LearnPython3Adapter(LearnXYAdapter):\n    \"Learn Python 3 in Y Minutes\"\n    prefix = \"python3\"\n    _filename = \"python3.html.markdown\"\n    _splitted = False\n\nclass LearnRAdapter(LearnXYAdapter):\n    \"Learn R in Y Minutes\"\n    prefix = \"r\"\n    _filename = \"r.html.markdown\"\n    _splitted = False\n\nclass LearnRacketAdapter(LearnXYAdapter):\n    \"Learn Racket in Y Minutes\"\n    prefix = \"racket\"\n    _filename = \"racket.html.markdown\"\n    _splitted = False\n\nclass LearnRubyAdapter(LearnXYAdapter):\n    \"\"\"\n    Learn Ruby in Y Minutes\n\n    Format of the file was changed, so we have to fix the function too.\n    This case is a good case for health check:\n    if number of extracted cheat sheets is suddenly became 1,\n    one should check the markup\n    \"\"\"\n    prefix = \"ruby\"\n    _filename = \"ruby.html.markdown\"\n\n    def _is_block_separator(self, before, now, after):\n        if (re.match('#######+', before)\n                and re.match('#######+', after)\n                and re.match(r'#+\\s+[0-9]+\\.', now)):\n            block_name = re.sub(r'#+\\s+[0-9]+\\.\\s*', '', now)\n            block_name = '_'.join(block_name.strip().split())\n            return block_name\n        return None\n\n    @staticmethod\n    def _cut_block(block, start_block=False):\n        answer = block[2:-1]\n        if answer[0].split() == '':\n            answer = answer[1:]\n        if answer[-1].split() == '':\n            answer = answer[:1]\n        return answer\n\nclass LearnRustAdapter(LearnXYAdapter):\n    \"Learn Rust in Y Minutes\"\n    prefix = \"rust\"\n    _filename = \"rust.html.markdown\"\n    _splitted = False\n\nclass LearnSolidityAdapter(LearnXYAdapter):\n    \"Learn Solidity in Y Minutes\"\n    prefix = \"solidity\"\n    _filename = \"solidity.html.markdown\"\n    _splitted = False\n\nclass LearnSwiftAdapter(LearnXYAdapter):\n    \"Learn Swift in Y Minutes\"\n    prefix = \"swift\"\n    _filename = \"swift.html.markdown\"\n    _splitted = False\n\nclass LearnTclAdapter(LearnXYAdapter):\n    \"Learn Tcl in Y Minutes\"\n    prefix = \"tcl\"\n    _filename = \"tcl.html.markdown\"\n    _splitted = False\n\nclass LearnTcshAdapter(LearnXYAdapter):\n    \"Learn Tcsh in Y Minutes\"\n    prefix = \"tcsh\"\n    _filename = \"tcsh.html.markdown\"\n    _splitted = False\n\nclass LearnVisualBasicAdapter(LearnXYAdapter):\n    \"Learn Visual Basic in Y Minutes\"\n    prefix = \"vb\"\n    _filename = \"visualbasic.html.markdown\"\n    _splitted = False\n\nclass LearnCMakeAdapter(LearnXYAdapter):\n    \"Learn CMake in Y Minutes\"\n    prefix = \"cmake\"\n    _filename = \"cmake.html.markdown\"\n    _splitted = False\n\nclass LearnNimAdapter(LearnXYAdapter):\n    \"Learn Nim in Y Minutes\"\n    prefix = \"nim\"\n    _filename = \"nim.html.markdown\"\n    _splitted = False\n\nclass LearnGitAdapter(LearnXYAdapter):\n    \"Learn Git in Y Minutes\"\n    prefix = \"git\"\n    _filename = \"git.html.markdown\"\n    _splitted = False\n\nclass LearnLatexAdapter(LearnXYAdapter):\n    \"Learn Nim in Y Minutes\"\n    prefix = \"latex\"\n    _filename = \"latex.html.markdown\"\n    _splitted = False\n\n_ADAPTERS = {cls.prefix: cls() for cls in vars()['LearnXYAdapter'].__subclasses__()}\n", "lib/adapter/adapter.py": "\"\"\"\n`Adapter`, base class of the adapters.\n\nConfiguration parameters:\n\n    path.repositories\n\"\"\"\n\nimport abc\nimport os\nfrom six import with_metaclass\nfrom config import CONFIG\n\nclass AdapterMC(type):\n    \"\"\"\n    Adapter Metaclass.\n    Defines string representation of adapters\n    \"\"\"\n    def __repr__(cls):\n        if hasattr(cls, '_class_repr'):\n            return getattr(cls, '_class_repr')()\n        return super(AdapterMC, cls).__repr__()\n\nclass Adapter(with_metaclass(AdapterMC, object)):\n    \"\"\"\n    An abstract class, defines methods:\n\n    (cheat sheets retrieval)\n    * get_list\n    * is_found\n    * is_cache_needed\n\n    (repositories management)\n    \" fetch\n    * update\n\n    and several properties that have to be set in each adapter subclass.\n\n    \"\"\"\n\n    _adapter_name = None\n    _output_format = 'code'\n    _cache_needed = False\n    _repository_url = None\n    _local_repository_location = None\n    _cheatsheet_files_prefix = \"\"\n    _cheatsheet_files_extension = \"\"\n    _pages_list = []\n\n    @classmethod\n    def _class_repr(cls):\n        return '[Adapter: %s (%s)]' % (cls._adapter_name, cls.__name__)\n\n    def __init__(self):\n        self._list = {None: self._get_list()}\n\n    @classmethod\n    def name(cls):\n        \"\"\"\n        Return name of the adapter\n        \"\"\"\n        return cls._adapter_name\n\n    @abc.abstractmethod\n    def _get_list(self, prefix=None):\n        return self._pages_list\n\n    def get_list(self, prefix=None):\n        \"\"\"\n        Return available pages for `prefix`\n        \"\"\"\n\n        if prefix in self._list:\n            return self._list[prefix]\n\n        self._list[prefix] = set(self._get_list(prefix=prefix))\n        return self._list[prefix]\n\n    def is_found(self, topic):\n        \"\"\"\n        check if `topic` is available\n        CAUTION: only root is checked\n        \"\"\"\n        return topic in self._list[None]\n\n    def is_cache_needed(self):\n        \"\"\"\n        Return True if answers should be cached.\n        Return False if answers should not be cached.\n        \"\"\"\n        return self._cache_needed\n\n    @staticmethod\n    def _format_page(text):\n        \"\"\"\n        Preformatting page hook.\n        Converts `text` (as in the initial repository)\n        to text (as to be displayed).\n        \"\"\"\n\n        return text\n\n    @abc.abstractmethod\n    def _get_page(self, topic, request_options=None):\n        \"\"\"\n        Return page for `topic`\n        \"\"\"\n        pass\n\n    def _get_output_format(self, topic):\n        if '/' in topic:\n            subquery = topic.split('/')[-1]\n        else:\n            subquery = topic\n\n        if subquery in [':list']:\n            return 'text'\n        return self._output_format\n\n    # pylint: disable=unused-argument\n    @staticmethod\n    def _get_filetype(topic):\n        \"\"\"\n        Return language name (filetype) for `topic`\n        \"\"\"\n        return None\n\n    def get_page_dict(self, topic, request_options=None):\n        \"\"\"\n        Return page dict for `topic`\n        \"\"\"\n\n        #\n        # if _get_page() returns a dict, use the dictionary\n        # for the answer. It is possible to specify some\n        # useful properties as the part of the answer\n        # (e.g. \"cache\")\n        # answer by _get_page() always overrides all default properties\n        #\n        answer = self._get_page(topic, request_options=request_options)\n        if not isinstance(answer, dict):\n            answer = {\"answer\": answer}\n\n        answer_dict = {\n            'topic': topic,\n            'topic_type': self._adapter_name,\n            'format': self._get_output_format(topic),\n            'cache': self._cache_needed,\n            }\n        answer_dict.update(answer)\n\n        # pylint: disable=assignment-from-none\n        filetype = self._get_filetype(topic)\n        if filetype:\n            answer_dict[\"filetype\"] = filetype\n        return answer_dict\n\n    @classmethod\n    def local_repository_location(cls, cheat_sheets_location=False):\n        \"\"\"\n        Return local repository location.\n        If name `self._repository_url` for the class is not specified, return None\n        It is possible that several adapters has the same repository_url,\n        in this case they should use the same local directory.\n        If for some reason the local repository location should be overridden\n        (e.g. if several different branches of the same repository are used)\n        if should set in `self._local_repository_location` of the adapter.\n        If `cheat_sheets_location` is specified, return path of the cheat sheets\n        directory instead of the repository directory.\n        \"\"\"\n\n        dirname = None\n\n        if cls._local_repository_location:\n            dirname = cls._local_repository_location\n\n        if not dirname and cls._repository_url:\n            dirname = cls._repository_url\n            if dirname.startswith('https://'):\n                dirname = dirname[8:]\n            elif dirname.startswith('http://'):\n                dirname = dirname[7:]\n\n        # if we did not manage to find out dirname up to this point,\n        # that means that neither repository url, not repository location\n        # is specified for the adapter, so it should be skipped\n        if not dirname:\n            return None\n\n        if dirname.startswith('/'):\n            return dirname\n\n        # it is possible that several repositories will\n        # be mapped to the same location name\n        # (because only the last part of the path is used)\n        # in this case provide the name in _local_repository_location\n        # (detected by fetch.py)\n        if '/' in dirname:\n            dirname = dirname.split('/')[-1]\n\n        path = os.path.join(CONFIG['path.repositories'], dirname)\n\n        if cheat_sheets_location:\n            path = os.path.join(path, cls._cheatsheet_files_prefix)\n\n        return path\n\n    @classmethod\n    def repository_url(cls):\n        \"\"\"\n        Return URL of the upstream repository\n        \"\"\"\n        return cls._repository_url\n\n    @classmethod\n    def fetch_command(cls):\n        \"\"\"\n        Initial fetch of the repository.\n        Return cmdline that has to be executed to fetch the repository.\n        Skipping if `self._repository_url` is not specified\n        \"\"\"\n        if not cls._repository_url:\n            return None\n\n        # in this case `fetch` has to be implemented\n        # in the distinct adapter subclass\n        raise RuntimeError(\n            \"Do not known how to handle this repository: %s\" % cls._repository_url)\n\n    @classmethod\n    def update_command(cls):\n        \"\"\"\n        Update of the repository.\n        Return cmdline that has to be executed to update the repository\n        inside `local_repository_location()`.\n        \"\"\"\n\n        if not cls._repository_url:\n            return None\n\n        local_repository_dir = cls.local_repository_location()\n        if not local_repository_dir:\n            return None\n\n        # in this case `update` has to be implemented\n        # in the distinct adapter subclass\n        raise RuntimeError(\n            \"Do not known how to handle this repository: %s\" % cls._repository_url)\n\n    @classmethod\n    def current_state_command(cls):\n        \"\"\"\n        Get current state of repository (current revision).\n        This is used to find what cache entries should be invalidated.\n        \"\"\"\n\n        if not cls._repository_url:\n            return None\n\n        local_repository_dir = cls.local_repository_location()\n        if not local_repository_dir:\n            return None\n\n        # in this case `update` has to be implemented\n        # in the distinct adapter subclass\n        raise RuntimeError(\n            \"Do not known how to handle this repository: %s\" % cls._repository_url)\n\n    @classmethod\n    def save_state(cls, state):\n        \"\"\"\n        Save state `state` of the repository.\n        Must be called after the cache clean up.\n        \"\"\"\n        local_repository_dir = cls.local_repository_location()\n        state_filename = os.path.join(local_repository_dir, '.cached_revision')\n        open(state_filename, 'w').write(state)\n\n    @classmethod\n    def get_state(cls):\n        \"\"\"\n        Return the saved `state` of the repository.\n        If state cannot be read, return None\n        \"\"\"\n\n        local_repository_dir = cls.local_repository_location()\n        state_filename = os.path.join(local_repository_dir, '.cached_revision')\n        state = None\n        if os.path.exists(state_filename):\n            state = open(state_filename, 'r').read()\n        return state\n\n    @classmethod\n    def get_updates_list_command(cls):\n        \"\"\"\n        Return the command to get the list of updates\n        since the last update whose id is saved as the repository state (`cached_state`).\n        The list is used to invalidate the cache.\n        \"\"\"\n        return None\n\n    @classmethod\n    def get_updates_list(cls, updated_files_list):\n        \"\"\"\n        Return the pages that have to be invalidated if the files `updates_files_list`\n        were updated in the repository.\n        \"\"\"\n        if not cls._cheatsheet_files_prefix:\n            return updated_files_list\n\n        answer = []\n        cut_len = len(cls._cheatsheet_files_prefix)\n        for entry in updated_files_list:\n            if entry.startswith(cls._cheatsheet_files_prefix):\n                answer.append(entry[cut_len:])\n            else:\n                answer.append(entry)\n        return answer\n\ndef all_adapters(as_dict=False):\n    \"\"\"\n    Return list of all known adapters\n    If `as_dict` is True, return dict {'name': adapter} instead of a list.\n    \"\"\"\n    def _all_subclasses(cls):\n        return set(cls.__subclasses__()).union(set(\n            [s for c in cls.__subclasses__() for s in _all_subclasses(c)]\n        ))\n\n    if as_dict:\n        return {x.name():x for x in _all_subclasses(Adapter)}\n    return list(_all_subclasses(Adapter))\n\ndef adapter_by_name(name):\n    \"\"\"\n    Return adapter having this name,\n    or None if nothing found\n    \"\"\"\n    return all_adapters(as_dict=True).get(name)\n", "lib/adapter/git_adapter.py": "\"\"\"\nImplementation of `GitRepositoryAdapter`, adapter that is used to handle git repositories\n\"\"\"\n\nimport glob\nimport os\n\nfrom .adapter import Adapter # pylint: disable=relative-import\n\ndef _get_filenames(path):\n    return [os.path.split(topic)[1] for topic in glob.glob(path)]\n\nclass RepositoryAdapter(Adapter):\n    \"\"\"\n    Implements methods needed to handle standard\n    repository based adapters.\n    \"\"\"\n\n    def _get_list(self, prefix=None):\n        \"\"\"\n        List of files in the cheat sheets directory\n        with the extension removed\n        \"\"\"\n\n        answer = _get_filenames(\n            os.path.join(\n                self.local_repository_location(),\n                self._cheatsheet_files_prefix,\n                '*'+self._cheatsheet_files_extension))\n\n        ext = self._cheatsheet_files_extension\n        if ext:\n            answer = [filename[:-len(ext)]\n                      for filename in answer\n                      if filename.endswith(ext)]\n\n        return answer\n\n    def _get_page(self, topic, request_options=None):\n\n        filename = os.path.join(\n            self.local_repository_location(),\n            self._cheatsheet_files_prefix,\n            topic)\n\n        if os.path.exists(filename) and not os.path.isdir(filename):\n            answer = self._format_page(open(filename, 'r').read())\n        else:\n            # though it should not happen\n            answer = \"%s:%s not found\" % (str(self.__class__), topic)\n\n        return answer\n\n\nclass GitRepositoryAdapter(RepositoryAdapter):    #pylint: disable=abstract-method\n    \"\"\"\n    Implements all methods needed to handle cache handling\n    for git-repository-based adapters\n    \"\"\"\n\n    @classmethod\n    def fetch_command(cls):\n        \"\"\"\n        Initial fetch of the repository.\n        Return cmdline that has to be executed to fetch the repository.\n        Skipping if `self._repository_url` is not specified\n        \"\"\"\n\n        if not cls._repository_url:\n            return None\n\n        if not cls._repository_url.startswith('https://github.com/'):\n            # in this case `fetch` has to be implemented\n            # in the distinct adapter subclass\n            raise RuntimeError(\n                \"Do not known how to handle this repository: %s\" % cls._repository_url)\n\n        local_repository_dir = cls.local_repository_location()\n        if not local_repository_dir:\n            return None\n\n        return ['git', 'clone', '--depth=1', cls._repository_url, local_repository_dir]\n\n    @classmethod\n    def update_command(cls):\n        \"\"\"\n        Update of the repository.\n        Return cmdline that has to be executed to update the repository\n        inside `local_repository_location()`.\n        \"\"\"\n\n        if not cls._repository_url:\n            return None\n\n        local_repository_dir = cls.local_repository_location()\n        if not local_repository_dir:\n            return None\n\n        if not cls._repository_url.startswith('https://github.com/'):\n            # in this case `update` has to be implemented\n            # in the distinct adapter subclass\n            raise RuntimeError(\n                \"Do not known how to handle this repository: %s\" % cls._repository_url)\n\n        return ['git', 'pull']\n\n    @classmethod\n    def current_state_command(cls):\n        \"\"\"\n        Get current state of repository (current revision).\n        This is used to find what cache entries should be invalidated.\n        \"\"\"\n\n        if not cls._repository_url:\n            return None\n\n        local_repository_dir = cls.local_repository_location()\n        if not local_repository_dir:\n            return None\n\n        if not cls._repository_url.startswith('https://github.com/'):\n            # in this case `update` has to be implemented\n            # in the distinct adapter subclass\n            raise RuntimeError(\n                \"Do not known how to handle this repository: %s\" % cls._repository_url)\n\n        return ['git', 'rev-parse', '--short', 'HEAD', \"--\"]\n\n    @classmethod\n    def save_state(cls, state):\n        \"\"\"\n        Save state `state` of the repository.\n        Must be called after the cache clean up.\n        \"\"\"\n        local_repository_dir = cls.local_repository_location()\n        state_filename = os.path.join(local_repository_dir, '.cached_revision')\n        open(state_filename, 'wb').write(state)\n\n    @classmethod\n    def get_state(cls):\n        \"\"\"\n        Return the saved `state` of the repository.\n        If state cannot be read, return None\n        \"\"\"\n\n        local_repository_dir = cls.local_repository_location()\n        state_filename = os.path.join(local_repository_dir, '.cached_revision')\n        state = None\n        if os.path.exists(state_filename):\n            state = open(state_filename, 'r').read()\n        return state\n\n    @classmethod\n    def get_updates_list_command(cls):\n        \"\"\"\n        Return list of updates since the last update whose id is saved as the repository state.\n        The list is used to invalidate the cache.\n        \"\"\"\n        current_state = cls.get_state()\n        if not current_state:\n            return ['git', 'ls-tree', '--full-tree', '-r', '--name-only', 'HEAD', \"--\"]\n        return ['git', 'diff', '--name-only', current_state, 'HEAD', \"--\"]\n", "lib/adapter/__init__.py": "\"\"\"\nImport all adapters from the current directory\nand make them available for import as\n    adapter_module.AdapterName\n\"\"\"\n\n# pylint: disable=wildcard-import,relative-import\n\nfrom os.path import dirname, basename, isfile, join\nimport glob\n\n__all__ = [\n    basename(f)[:-3]\n    for f in glob.glob(join(dirname(__file__), \"*.py\"))\n    if isfile(f) and not f.endswith('__init__.py')]\n\nfrom .adapter import all_adapters\nfrom . import *\n", "lib/adapter/cheat_sheets.py": "\"\"\"\nImplementation of the adapter for the native cheat.sh cheat sheets repository,\ncheat.sheets.  The cheat sheets repository is hierarchically structured: cheat\nsheets covering programming languages are are located in subdirectories.\n\"\"\"\n\n# pylint: disable=relative-import\n\nimport os\nimport glob\n\nfrom .git_adapter import GitRepositoryAdapter\n\ndef _remove_initial_underscore(filename):\n    if filename.startswith('_'):\n        filename = filename[1:]\n    return filename\n\ndef _sanitize_dirnames(filename, restore=False):\n    \"\"\"\n    Remove (or add) leading _ in the directories names in `filename`\n    The `restore` param means that the path name should be restored from the queryname,\n    i.e. conversion should be done in the opposite direction\n    \"\"\"\n    parts = filename.split('/')\n    newparts = []\n    for part in parts[:-1]:\n        if restore:\n            newparts.append('_'+part)\n            continue\n        if part.startswith('_'):\n            newparts.append(part[1:])\n        else:\n            newparts.append(part)\n    newparts.append(parts[-1])\n\n    return \"/\".join(newparts)\n\nclass CheatSheets(GitRepositoryAdapter):\n\n    \"\"\"\n    Adapter for the cheat.sheets cheat sheets.\n    \"\"\"\n\n    _adapter_name = \"cheat.sheets\"\n    _output_format = \"code\"\n    _repository_url = \"https://github.com/chubin/cheat.sheets\"\n    _cheatsheet_files_prefix = \"sheets/\"\n\n    def _get_list(self, prefix=None):\n        \"\"\"\n        Return all files on the first and the second level,\n        excluding directories and hidden files\n        \"\"\"\n\n        hidden_files = [\"_info.yaml\"]\n        answer = []\n        prefix = os.path.join(\n            self.local_repository_location(),\n            self._cheatsheet_files_prefix)\n        for mask in ['*', '*/*']:\n            template = os.path.join(\n                prefix,\n                mask)\n\n            answer += [\n                _sanitize_dirnames(f_name[len(prefix):])\n                for f_name in glob.glob(template)\n                if not os.path.isdir(f_name)\n                and os.path.basename(f_name) not in hidden_files]\n\n        return sorted(answer)\n\n    def _get_page(self, topic, request_options=None):\n\n        filename = os.path.join(\n            self.local_repository_location(),\n            self._cheatsheet_files_prefix,\n            _sanitize_dirnames(topic, restore=True))\n\n        if os.path.exists(filename):\n            answer = self._format_page(open(filename, 'r').read())\n        else:\n            # though it should not happen\n            answer = \"%s:%s not found\" % (str(self.__class__), topic)\n\n        return answer\n\nclass CheatSheetsDir(CheatSheets):\n\n    \"\"\"\n    Adapter for the cheat sheets directories.\n    Provides pages named according to subdirectories:\n        _dir => dir/\n\n    (currently only _get_list() is used; _get_page is shadowed\n    by the CheatSheets adapter)\n    \"\"\"\n\n    _adapter_name = \"cheat.sheets dir\"\n    _output_format = \"text\"\n\n    def _get_list(self, prefix=None):\n\n        template = os.path.join(\n            self.local_repository_location(),\n            self._cheatsheet_files_prefix,\n            '*')\n\n        answer = sorted([\n            _remove_initial_underscore(os.path.basename(f_name)) + \"/\"\n            for f_name in glob.glob(template)\n            if os.path.isdir(f_name)])\n\n        return answer\n\n    def _get_page(self, topic, request_options=None):\n        \"\"\"\n        Content of the `topic` dir is the list of the pages in the dir\n        \"\"\"\n\n        template = os.path.join(\n            self.local_repository_location(),\n            self._cheatsheet_files_prefix,\n            topic.rstrip('/'),\n            '*')\n\n        answer = sorted([\n            os.path.basename(f_name) for f_name in glob.glob(template)])\n        return \"\\n\".join(answer) + \"\\n\"\n\n    def is_found(self, topic):\n        return CheatSheets.is_found(self, topic.rstrip('/'))\n", "lib/adapter/rosetta.py": "\"\"\"\nImplementation of RosettaCode Adapter.\n\nExports:\n\n    Rosetta(GitRepositoryAdapter)\n\"\"\"\n\n# pylint: disable=relative-import\n\nimport os\nimport glob\nimport yaml\n\nfrom .git_adapter import GitRepositoryAdapter\nfrom .cheat_sheets import CheatSheets\n\nclass Rosetta(GitRepositoryAdapter):\n\n    \"\"\"\n    Adapter for RosettaCode\n    \"\"\"\n\n    _adapter_name = \"rosetta\"\n    _output_format = \"code\"\n    _local_repository_location = \"RosettaCodeData\"\n    _repository_url = \"https://github.com/acmeism/RosettaCodeData\"\n\n    __section_name = \"rosetta\"\n\n    def __init__(self):\n        GitRepositoryAdapter.__init__(self)\n        self._rosetta_code_name = self._load_rosetta_code_names()\n\n    @staticmethod\n    def _load_rosetta_code_names():\n        answer = {}\n\n        lang_files_location = CheatSheets.local_repository_location(cheat_sheets_location=True)\n        for filename in glob.glob(os.path.join(lang_files_location, '*/_info.yaml')):\n            text = open(filename, 'r').read()\n            data = yaml.load(text, Loader=yaml.SafeLoader)\n            if data is None:\n                continue\n            lang = os.path.basename(os.path.dirname(filename))\n            if lang.startswith('_'):\n                lang = lang[1:]\n            if 'rosetta' in data:\n                answer[lang] = data['rosetta']\n        return answer\n\n    def _rosetta_get_list(self, query, task=None):\n        if query not in self._rosetta_code_name:\n            return []\n\n        lang = self._rosetta_code_name[query]\n        answer = []\n        if task:\n            glob_path = os.path.join(self.local_repository_location(), 'Lang', lang, task, '*')\n        else:\n            glob_path = os.path.join(self.local_repository_location(), 'Lang', lang, '*')\n        for filename in glob.glob(glob_path):\n            taskname = os.path.basename(filename)\n            answer.append(taskname)\n\n        answer = \"\".join(\"%s\\n\" % x for x in sorted(answer))\n        return answer\n\n    @staticmethod\n    def _parse_query(query):\n        if '/' in query:\n            task, subquery = query.split('/', 1)\n        else:\n            task, subquery = query, None\n        return task, subquery\n\n    def _get_task(self, lang, query):\n        if lang not in self._rosetta_code_name:\n            return \"\"\n\n        task, subquery = self._parse_query(query)\n\n        if task == ':list':\n            return self._rosetta_get_list(lang)\n        if subquery == ':list':\n            return self._rosetta_get_list(lang, task=task)\n\n        # if it is not a number or the number is too big, just ignore it\n        index = 1\n        if subquery:\n            try:\n                index = int(subquery)\n            except ValueError:\n                pass\n\n        lang_name = self._rosetta_code_name[lang]\n\n        tasks = sorted(glob.glob(\n            os.path.join(self.local_repository_location(), 'Lang', lang_name, task, '*')))\n        if not tasks:\n            return \"\"\n\n        if len(tasks) < index or index < 1:\n            index = 1\n\n        answer_filename = tasks[index-1]\n        answer = open(answer_filename, 'r').read()\n\n        return answer\n\n    def _starting_page(self, query):\n        number_of_pages = self._rosetta_get_list(query)\n        answer = (\n            \"# %s pages available\\n\"\n            \"# use /:list to list\"\n        ) % number_of_pages\n        return answer\n\n    def _get_page(self, topic, request_options=None):\n\n        if '/' not in topic:\n            return self._rosetta_get_list(topic)\n\n        lang, topic = topic.split('/', 1)\n\n        # this part should be generalized\n        # currently we just remove the name of the adapter from the path\n        if topic == self.__section_name:\n            return self._starting_page(topic)\n\n        if topic.startswith(self.__section_name + '/'):\n            topic = topic[len(self.__section_name + '/'):]\n\n        return self._get_task(lang, topic)\n\n    def _get_list(self, prefix=None):\n        return []\n\n    def get_list(self, prefix=None):\n        answer = [self.__section_name]\n        for i in self._rosetta_code_name:\n            answer.append('%s/%s/' % (i, self.__section_name))\n        return answer\n\n    def is_found(self, _):\n        return True\n", "lib/adapter/cmd.py": "\"\"\"\n\"\"\"\n\n# pylint: disable=unused-argument,abstract-method\n\nimport os.path\nimport re\nfrom subprocess import Popen, PIPE\n\nfrom .adapter import Adapter\n\n\ndef _get_abspath(path):\n    \"\"\"Find absolute path of the specified `path`\n    according to its\n    \"\"\"\n\n    if path.startswith(\"/\"):\n        return path\n\n    import __main__\n    return os.path.join(\n        os.path.dirname(os.path.dirname(__main__.__file__)),\n        path)\n\nclass CommandAdapter(Adapter):\n    \"\"\"\n    \"\"\"\n\n    _command = []\n\n    def _get_command(self, topic, request_options=None):\n        return self._command\n\n    def _get_page(self, topic, request_options=None):\n        cmd = self._get_command(topic, request_options=request_options)\n        if cmd:\n            try:\n                proc = Popen(cmd, stdout=PIPE, stderr=PIPE)\n                answer = proc.communicate()[0].decode('utf-8', 'ignore')\n            except OSError:\n                return \"ERROR of the \\\"%s\\\" adapter: please create an issue\" % self._adapter_name\n            return answer\n        return \"\"\n\nclass Fosdem(CommandAdapter):\n\n    \"\"\"\n    Show the output of the `current-fosdem-slide` command,\n    which shows the current slide open in some terminal.\n    This was used during the talk at FOSDEM 2019.\n\n    https://www.youtube.com/watch?v=PmiK0JCdh5A\n\n    `sudo` is used here because the session was running under\n    a different user; to be able to use the command via sudo,\n    the following `/etc/suders` entry was added:\n\n    srv    ALL=(ALL:ALL) NOPASSWD: /usr/local/bin/current-fosdem-slide\n\n    Here `srv` is the user under which the cheat.sh server was running\n    \"\"\"\n\n    _adapter_name = \"fosdem\"\n    _output_format = \"ansi\"\n    _pages_list = [\":fosdem\"]\n    _command = [\"sudo\", \"/usr/local/bin/current-fosdem-slide\"]\n\nclass Translation(CommandAdapter):\n    \"\"\"\n    \"\"\"\n\n    _adapter_name = \"translation\"\n    _output_format = \"text\"\n    _cache_needed = True\n\n    def _get_page(self, topic, request_options=None):\n        from_, topic = topic.split('/', 1)\n        to_ = request_options.get('lang', 'en')\n        if '-' in from_:\n            from_, to_ = from_.split('-', 1)\n\n        return [\"/home/igor/cheat.sh/bin/get_translation\",\n                from_, to_, topic.replace('+', ' ')]\n\n\nclass AdapterRfc(CommandAdapter):\n    \"\"\"\n    Show RFC by its number.\n    Exported as: \"/rfc/NUMBER\"\n    \"\"\"\n\n    _adapter_name = \"rfc\"\n    _output_format = \"text\"\n    _cache_needed = True\n    _command = [\"share/adapters/rfc.sh\"]\n\n    def _get_command(self, topic, request_options=None):\n        cmd = self._command[:]\n        if not cmd[0].startswith(\"/\"):\n            cmd[0] = _get_abspath(cmd[0])\n\n        # cut rfc/ off\n        if topic.startswith(\"rfc/\"):\n            topic = topic[4:]\n\n        return cmd + [topic]\n\n    def _get_list(self, prefix=None):\n        return list(\"rfc/%s\" % x for x in range(1, 8649))\n\n    def is_found(self, topic):\n        return True\n\nclass AdapterOeis(CommandAdapter):\n    \"\"\"\n    Show OEIS by its number.\n    Exported as: \"/oeis/NUMBER\"\n    \"\"\"\n\n    _adapter_name = \"oeis\"\n    _output_format = \"text+code\"\n    _cache_needed = True\n    _command = [\"share/adapters/oeis.sh\"]\n\n    @staticmethod\n    def _get_filetype(topic):\n        if \"/\" in topic:\n            language = topic.split(\"/\")[-1].lower()\n            return language\n        return \"bash\"\n\n    def _get_command(self, topic, request_options=None):\n        cmd = self._command[:]\n        if not cmd[0].startswith(\"/\"):\n            cmd[0] = _get_abspath(cmd[0])\n\n        # cut oeis/ off\n        # Replace all non (alphanumeric, '-', ':') chars with Spaces to delimit args to oeis.sh\n        if topic.startswith(\"oeis/\"):\n            topic = topic[5:]\n\n            suffix = \"\"\n            if topic.endswith(\"/:list\"):\n                suffix = \" :list\"\n                topic = topic[:-6]\n\n            topic = re.sub('[^a-zA-Z0-9-:]+', ' ', topic) + suffix\n\n        return cmd + [topic]\n\n    def is_found(self, topic):\n        return True\n\nclass AdapterChmod(CommandAdapter):\n    \"\"\"\n    Show chmod numeric values and strings\n    Exported as: \"/chmod/NUMBER\"\n    \"\"\"\n\n    _adapter_name = \"chmod\"\n    _output_format = \"text\"\n    _cache_needed = True\n    _command = [\"share/adapters/chmod.sh\"]\n\n    def _get_command(self, topic, request_options=None):\n        cmd = self._command[:]\n\n        # cut chmod/ off\n        # remove all non (alphanumeric, '-') chars\n        if topic.startswith(\"chmod/\"):\n            topic = topic[6:]\n            topic = re.sub('[^a-zA-Z0-9-]', '', topic)\n\n\n        return cmd + [topic]\n\n    def is_found(self, topic):\n        return True\n", "lib/panela/panela_colors.py": "# vim: encoding=utf-8\n\nimport os\nimport sys\nimport colored\nimport itertools\nfrom globals import MYDIR\n\n\"\"\"\n\nAfter panela will be ready for it, it will be split out in a separate project,\nthat will be used for all chubin's console services.\nThere are several features that not yet implemented (see ___doc___ in Panela)\n\nTODO:\n    * html output\n    * png output\n\n\"\"\"\n\nfrom wcwidth import wcswidth\nfrom colors import find_nearest_color, HEX_TO_ANSI, rgb_from_str\nimport pyte\n\n# http://stackoverflow.com/questions/19782975/convert-rgb-color-to-the-nearest-color-in-palette-web-safe-color\n\ntry:\n    basestring        # Python 2\nexcept NameError:\n    basestring = str  # Python 3\n\n\ndef color_mapping(clr):\n    if clr == 'default':\n        return None\n    return clr\n\nclass Point(object):\n    \"\"\"\n    One point (character) on a terminal\n    \"\"\"\n    def __init__(self, char=None, foreground=None, background=None):\n        self.foreground = foreground\n        self.background = background\n        self.char = char\n\nclass Panela:\n\n    \"\"\"\n    To implement:\n\n    Blocks manipulation:\n\n        [*] copy\n        [*] crop\n        [*] cut\n        [*] extend\n        [ ] join\n        [ ] move\n        [*] paste\n        [*] strip\n\n    Colors manipulation:\n\n        [*] paint           foreground/background\n        [*] paint_line\n        [ ] paint_svg\n        [ ] fill            background\n        [ ] fill_line\n        [ ] fill_svg\n        [ ] trans\n\n    Drawing:\n\n        [*] put_point\n        [*] put_line\n        [*] put_circle\n        [*] put_rectangle\n\n    Printing and reading:\n        ansi            reads vt100 sequence\n    \"\"\"\n\n    def __init__(self, x=80, y=25, panela=None, field=None):\n\n        if panela:\n            self.field = [x for x in panela.field]\n            self.size_x = panela.size_x\n            self.size_y = panela.size_y\n            return\n\n        if field:\n            self.field = field\n            self.size_x = len(field[0])\n            self.size_y = len(field)\n            return\n\n        self.field = [[Point() for _ in range(x)] for _ in range(y)]\n        self.size_x = x\n        self.size_y = y\n\n    def in_field(self, col, row):\n        if col < 0:\n            return False\n        if row < 0:\n            return False\n        if col >= self.size_x:\n            return False\n        if row >= self.size_y:\n            return False\n        return True\n\n#\n# Blocks manipulation\n#\n\n    def copy(self, x1, y1, x2, y2):\n\n        if x1 < 0:\n            x1 += self.size_x\n        if x2 < 0:\n            x2 += self.size_x\n        if x1 > x2:\n            x1, x2 = x2, x1\n\n        if y1 < 0:\n            y1 += self.size_y\n        if y2 < 0:\n            y2 += self.size_y\n        if y1 > y2:\n            y1, y2 = y2, y1\n\n        field = [self.field[i] for i in range(y1, y2+1)]\n        field = [line[x1:x2+1] for line in field]\n\n        return Panela(field=field)\n\n    def cut(self, x1, y1, x2, y2):\n        \"\"\"\n        \"\"\"\n        if x1 < 0:\n            x1 += self.size_x\n        if x2 < 0:\n            x2 += self.size_x\n        if x1 > x2:\n            x1, x2 = x2, x1\n\n        if y1 < 0:\n            y1 += self.size_y\n        if y2 < 0:\n            y2 += self.size_y\n        if y1 > y2:\n            y1, y2 = y2, y1\n\n        copied = self.copy(x1, y1, x2, y2)\n\n        for y in range(y1, y2+1):\n            for x in range(x1, x2+1):\n                self.field[y][x] = Point()\n\n        return copied\n\n    def extend(self, cols=None, rows=None):\n        \"\"\"\n        Adds [cols] columns from the right\n        and [rows] rows from the bottom\n        \"\"\"\n        if cols and cols > 0:\n            self.field = [x + [Point() for _ in range(cols)] for x in self.field]\n            self.size_x += cols\n\n        if rows and rows > 0:\n            self.field = self.field + [[Point() for _ in range(self.size_x)] for _ in range(rows)]\n            self.size_y += rows\n\n    def crop(self, left=None, right=None, top=None, bottom=None):\n        \"\"\"\n        Crop panela.\n        Remove <left>, <right> columns from left or right,\n        and <top> and <bottom> rows from top and bottom.\n        \"\"\"\n\n        if left:\n            if left >= self.size_x:\n                left = self.size_x\n            self.field = [x[left:] for x in self.field]\n            self.size_x -= left\n\n        if right:\n            if right >= self.size_x:\n                right = self.size_x\n            self.field = [x[:-right] for x in self.field]\n            self.size_x -= right\n\n        if top:\n            if top >= self.size_y:\n                top = self.size_y\n            self.field = self.field[top:]\n            self.size_y -= top\n\n        if bottom:\n            if bottom >= self.size_y:\n                bottom = self.size_y\n            self.field = self.field[:-bottom]\n            self.size_y -= bottom\n\n    def paste(self, panela, x1, y1, extend=False, transparence=False):\n        \"\"\"\n        Paste <panela> starting at <x1>, <y1>.\n        If <extend> is True current panela space will be automatically extended\n        If <transparence> is True, then <panela> is overlaid and characters behind them are seen\n        \"\"\"\n\n        # FIXME:\n        #  negative x1, y1\n        #  x1,y1 > size_x, size_y\n\n        if extend:\n            x_extend = 0\n            y_extend = 0\n            if x1 + panela.size_x > self.size_x:\n                x_extend = x1 + panela.size_x - self.size_x\n            if y1 + panela.size_y > self.size_y:\n                y_extend = y1 + panela.size_y - self.size_y\n            self.extend(cols=x_extend, rows=y_extend)\n\n        for i in range(y1, min(self.size_y, y1+panela.size_y)):\n            for j in range(x1, min(self.size_x, x1+panela.size_x)):\n                if transparence:\n                    if panela.field[i-y1][j-x1].char and panela.field[i-y1][j-x1].char != \" \":\n                        if panela.field[i-y1][j-x1].foreground:\n                            self.field[i][j].foreground = panela.field[i-y1][j-x1].foreground\n                        if panela.field[i-y1][j-x1].background:\n                            self.field[i][j].background = panela.field[i-y1][j-x1].background\n                        self.field[i][j].char = panela.field[i-y1][j-x1].char\n                else:\n                    self.field[i][j] = panela.field[i-y1][j-x1]\n\n    def strip(self):\n        \"\"\"\n        Strip panela: remove empty spaces around panels rectangle\n        \"\"\"\n\n        def left_spaces(line):\n            answer = 0\n            for elem in line:\n                if not elem.char:\n                    answer += 1\n                else:\n                    break\n            return answer\n\n        def right_spaces(line):\n            return left_spaces(line[::-1])\n\n        def empty_line(line):\n            return left_spaces(line) == len(line)\n\n        left_space = []\n        right_space = []\n        for line in self.field:\n            left_space.append(left_spaces(line))\n            right_space.append(right_spaces(line))\n        left = min(left_space)\n        right = min(right_space)\n\n        top = 0\n        while top < self.size_y and empty_line(self.field[top]):\n            top += 1\n\n        bottom = 0\n        while bottom < self.size_y and empty_line(self.field[-(bottom+1)]):\n            bottom += 1\n\n        self.crop(left=left, right=right, top=top, bottom=bottom)\n\n#\n# Drawing and painting\n#\n\n    def put_point(self, col, row, char=None, color=None, background=None):\n        \"\"\"\n        Puts character with color and background color on the field.\n        Char can be a Point or a character.\n        \"\"\"\n\n        if not self.in_field(col, row):\n            return\n        if isinstance(char, Point):\n            self.field[row][col] = char\n        elif char is None:\n            if background:\n                self.field[row][col].background = background\n            if color:\n                self.field[row][col].foreground = color\n        else:\n            self.field[row][col] = Point(char=char, foreground=color, background=background)\n\n    def put_string(self, col, row, s=None, color=None, background=None):\n        \"\"\"\n        Put string <s> with foreground color <color> and background color <background>\n        ad <col>, <row>\n        \"\"\"\n        for i, c in enumerate(s):\n            self.put_point(col+i, row, c, color=color, background=background)\n\n    def put_line(self, x1, y1, x2, y2, char=None, color=None, background=None):\n        \"\"\"\n        Draw line (x1, y1) - (x2, y2) fith foreground color <color>, background color <background>\n        and character <char>, if specified.\n        \"\"\"\n\n        def get_line(start, end):\n            \"\"\"Bresenham's Line Algorithm\n            Produces a list of tuples from start and end\n\n            Source: http://www.roguebasin.com/index.php?title=Bresenham%27s_Line_Algorithm#Python\n\n            >>> points1 = get_line((0, 0), (3, 4))\n            >>> points2 = get_line((3, 4), (0, 0))\n            >>> assert(set(points1) == set(points2))\n            >>> print points1\n            [(0, 0), (1, 1), (1, 2), (2, 3), (3, 4)]\n            >>> print points2\n            [(3, 4), (2, 3), (1, 2), (1, 1), (0, 0)]\n            \"\"\"\n            # Setup initial conditions\n            x1, y1 = start\n            x2, y2 = end\n            dx = x2 - x1\n            dy = y2 - y1\n\n            # Determine how steep the line is\n            is_steep = abs(dy) > abs(dx)\n\n            # Rotate line\n            if is_steep:\n                x1, y1 = y1, x1\n                x2, y2 = y2, x2\n\n            # Swap start and end points if necessary and store swap state\n            swapped = False\n            if x1 > x2:\n                x1, x2 = x2, x1\n                y1, y2 = y2, y1\n                swapped = True\n\n            # Recalculate differentials\n            dx = x2 - x1\n            dy = y2 - y1\n\n            # Calculate error\n            error = int(dx / 2.0)\n            ystep = 1 if y1 < y2 else -1\n\n            # Iterate over bounding box generating points between start and end\n            y = y1\n            points = []\n            for x in range(x1, x2 + 1):\n                coord = (y, x) if is_steep else (x, y)\n                points.append(coord)\n                error -= abs(dy)\n                if error < 0:\n                    y += ystep\n                    error += dx\n\n            # Reverse the list if the coordinates were swapped\n            if swapped:\n                points.reverse()\n            return points\n\n        if color and not isinstance(color, basestring):\n            color_iter = itertools.cycle(color)\n        else:\n            color_iter = itertools.repeat(color)\n\n        if background and not isinstance(background, basestring):\n            background_iter = itertools.cycle(background)\n        else:\n            background_iter = itertools.repeat(background)\n\n        if char:\n            char_iter = itertools.cycle(char)\n        else:\n            char_iter = itertools.repeat(char)\n\n        for x, y in get_line((x1,y1), (x2, y2)):\n            char = next(char_iter)\n            color = next(color_iter)\n            background = next(background_iter)\n\n            self.put_point(x, y, char=char, color=color, background=background)\n\n    def paint(self, x1, y1, x2, y2, c1, c2=None, bg1=None, bg2=None, angle=None, angle_bg=None):\n        \"\"\"\n        Paint rectangle (x1,y1) (x2,y2) with foreground color c1 and background bg1 if specified.\n        If spefied colors c2/bg2, rectangle is painted with linear gradient (inclined under angle).\n        \"\"\"\n\n        def calculate_color(i, j):\n            if angle == None:\n                a = 0\n            else:\n                a = angle\n\n            r1, g1, b1 = rgb_from_str(c1)\n            r2, g2, b2 = rgb_from_str(c2)\n            k = 1.0*(j-x1)/(x2-x1)*(1-a)\n            l = 1.0*(i-y1)/(y2-y1)*a\n            r3, g3, b3 = int(r1 + 1.0*(r2-r1)*(k+l)), int(g1 + 1.0*(g2-g1)*(k+l)), int(b1 + 1.0*(b2-b1)*(k+l))\n\n            return \"#%02x%02x%02x\" % (r3, g3, b3)\n\n        def calculate_bg(i, j):\n            if angle_bg == None:\n                a = 0\n            else:\n                a = angle\n\n            r1, g1, b1 = rgb_from_str(bg1)\n            r2, g2, b2 = rgb_from_str(bg2)\n            k = 1.0*(j-x1)/(x2-x1)*(1-a)\n            l = 1.0*(i-y1)/(y2-y1)*a\n            r3, g3, b3 = int(r1 + 1.0*(r2-r1)*(k+l)), int(g1 + 1.0*(g2-g1)*(k+l)), int(b1 + 1.0*(b2-b1)*(k+l))\n\n            return \"#%02x%02x%02x\" % (r3, g3, b3)\n\n        if c2 == None:\n            for i in range(y1,y2):\n                for j in range(x1, x2):\n                    self.field[i][j].foreground = c1\n                    if bg1:\n                        if bg2:\n                            self.field[i][j].background = calculate_bg(i, j)\n                        else:\n                            self.field[i][j].background = bg1\n        else:\n            for i in range(y1,y2):\n                for j in range(x1, x2):\n                    self.field[i][j].foreground = calculate_color(i, j)\n                    if bg1:\n                        if bg2:\n                            self.field[i][j].background = calculate_bg(i, j)\n                        else:\n                            self.field[i][j].background = bg1\n\n        return self\n\n    def put_rectangle(self, x1, y1, x2, y2, char=None, frame=None, color=None, background=None):\n        \"\"\"\n        Draw rectangle (x1,y1), (x2,y2) using <char> character, <color> and <background> color\n        \"\"\"\n\n        frame_chars = {\n            'ascii':    u'++++-|',\n            'single':   u'\u250c\u2510\u2514\u2518\u2500\u2502',\n            'double':   u'\u250c\u2510\u2514\u2518\u2500\u2502',\n        }\n        if frame in frame_chars:\n            chars = frame_chars[frame]\n        else:\n            chars = char*6\n\n        for x in range(x1, x2):\n            self.put_point(x, y1, char=chars[4], color=color, background=background)\n            self.put_point(x, y2, char=chars[4], color=color, background=background)\n\n        for y in range(y1, y2):\n            self.put_point(x1, y, char=chars[5], color=color, background=background)\n            self.put_point(x2, y, char=chars[5], color=color, background=background)\n\n        self.put_point(x1, y1, char=chars[0], color=color, background=background)\n        self.put_point(x2, y1, char=chars[1], color=color, background=background)\n        self.put_point(x1, y2, char=chars[2], color=color, background=background)\n        self.put_point(x2, y2, char=chars[3], color=color, background=background)\n\n\n    def put_circle(self, x0, y0, radius, char=None, color=None, background=None):\n        \"\"\"\n        Draw cricle with center in (x, y) and radius r (x1,y1), (x2,y2)\n        using <char> character, <color> and <background> color\n        \"\"\"\n\n        def k(x):\n            return int(x*1.9)\n\n        f = 1 - radius\n        ddf_x = 1\n        ddf_y = -2 * radius\n        x = 0\n        y = radius\n        self.put_point(x0, y0 + radius, char=char, color=color, background=background)\n        self.put_point(x0, y0 - radius, char=char, color=color, background=background)\n        self.put_point(x0 + k(radius), y0, char=char, color=color, background=background)\n        self.put_point(x0 - k(radius), y0, char=char, color=color, background=background)\n     \n        char = \"x\"\n        while x < y:\n            if f >= 0: \n                y -= 1\n                ddf_y += 2\n                f += ddf_y\n            x += 1\n            ddf_x += 2\n            f += ddf_x    \n            self.put_point(x0 + k(x), y0 + y, char=char, color=color, background=background)\n            self.put_point(x0 - k(x), y0 + y, char=char, color=color, background=background)\n            self.put_point(x0 + k(x), y0 - y, char=char, color=color, background=background)\n            self.put_point(x0 - k(x), y0 - y, char=char, color=color, background=background)\n            self.put_point(x0 + k(y), y0 + x, char=char, color=color, background=background)\n            self.put_point(x0 - k(y), y0 + x, char=char, color=color, background=background)\n            self.put_point(x0 + k(y), y0 - x, char=char, color=color, background=background)\n            self.put_point(x0 - k(y), y0 - x, char=char, color=color, background=background)\n\n    def read_ansi(self, seq, x=0, y=0, transparence=True):\n        \"\"\"\n        Read ANSI sequence and render it to the panela starting from x and y.\n        If transparence is True, replace spaces with \"\"\n        \"\"\"\n        screen = pyte.screens.Screen(self.size_x, self.size_y+1)\n\n        stream = pyte.streams.ByteStream()\n        stream.attach(screen)\n\n        stream.feed(seq.replace('\\n', '\\r\\n'))\n\n        for i, line in sorted(screen.buffer.items(), key=lambda x: x[0]):\n            for j, char in sorted(line.items(), key=lambda x: x[0]):\n                if j >= self.size_x:\n                    break\n                self.field[i][j] = Point(char.data, color_mapping(char.fg), color_mapping(char.bg))\n\n    def __str__(self):\n        answer = \"\"\n        skip_next = False\n        for i, line in enumerate(self.field):\n            for j, c in enumerate(line):\n                fg_ansi = \"\"\n                bg_ansi = \"\"\n                stop = \"\"\n\n                if self.field[i][j].foreground:\n                    fg_ansi = '\\033[38;2;%s;%s;%sm' % rgb_from_str(self.field[i][j].foreground)\n                    stop = colored.attr(\"reset\")\n\n                if self.field[i][j].background:\n                    bg_ansi = '\\033[48;2;%s;%s;%sm' % rgb_from_str(self.field[i][j].background)\n                    stop = colored.attr(\"reset\")\n\n                char = c.char or \" \"\n                if not skip_next:\n                    answer += fg_ansi + bg_ansi + char.encode('utf-8') + stop\n                skip_next = wcswidth(char) == 2\n\n            # answer += \"...\\n\"\n            answer += \"\\n\"\n        return answer\n\n########################################################################################################\n\nclass Template(object):\n    def __init__(self):\n        self._mode = 'page'\n        self.page = []\n        self.mask = []\n        self.code = []\n        self.panela = None\n\n        self._colors = {\n            'A': '#00cc00',\n            'B': '#00cc00',\n            'C': '#00aacc',\n            'D': '#888888',\n            'E': '#cccc00',\n            'F': '#ff0000',\n            'H': '#22aa22',\n            'I': '#cc0000',\n            'J': '#000000',\n        }\n\n        self._bg_colors = {\n            'G': '#555555',\n            'J': '#555555',\n        }\n\n    def _process_line(self, line):\n        if line == 'mask':\n            self._mode = 'mask'\n        if line == '':\n            self._mode = 'code'\n\n    def read(self, filename):\n        \"\"\"\n        Read template from `filename`\n        \"\"\"\n        with open(filename) as f:\n            self._mode = 'page'\n            for line in f.readlines():\n                line = line.rstrip('\\n')\n                if line.startswith('==[') and line.endswith(']=='):\n                    self._process_line(line[3:-3].strip())\n                    continue\n\n                if self._mode == 'page':\n                    self.page.append(line)\n                elif self._mode == 'mask':\n                    self.mask.append(line)\n                elif self._mode == 'code':\n                    self.mask.append(line)\n\n    def apply_mask(self):\n\n        lines = self.page\n        x_size = max([len(x) for x in lines])\n        y_size = len(lines)\n\n        self.panela = Panela(x=x_size, y=y_size)\n        self.panela.read_ansi(\"\".join(\"%s\\n\" % x for x in self.page))\n\n        for i, line in enumerate(self.mask):\n            for j, char in enumerate(line):\n                if char in self._colors or char in self._bg_colors:\n                    color = self._colors.get(char)\n                    bg_color = self._bg_colors.get(char)\n                    self.panela.put_point(j, i, color=color, background=bg_color)\n\n    def show(self):\n\n        if self.panela:\n            return str(self.panela)\n\n        return self.page\n\ndef main():\n    \"Only for experiments\"\n\n    pagepath = os.path.join(MYDIR, \"share/firstpage-v2.pnl\")\n    template = Template()\n    template.read(pagepath)\n    template.apply_mask()\n    sys.stdout.write(template.show())\n\n\nif __name__ == '__main__':\n    main()\n", "lib/panela/colors.py": "import os\nimport json\n\nCOLORS_JSON = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'colors.json')\nCOLOR_TABLE = json.loads(open(COLORS_JSON, 'r').read())\nVALID_COLORS = [x['hexString'] for x in COLOR_TABLE]\nHEX_TO_ANSI = {x['hexString']:x['colorId'] for x in COLOR_TABLE}\n\ndef rgb_from_str(s):\n    # s starts with a #.  \n    r, g, b = int(s[1:3],16), int(s[3:5], 16),int(s[5:7], 16)  \n    return r, g, b \n\ndef find_nearest_color(hex_color):  \n    R, G, B = rgb_from_str(hex_color)\n    mindiff = None\n    for d in VALID_COLORS:  \n        r, g, b = rgb_from_str(d)  \n        diff = abs(R -r)*256 + abs(G-g)* 256 + abs(B- b)* 256   \n        if mindiff is None or diff < mindiff:  \n            mindiff = diff  \n            mincolorname = d  \n    return mincolorname \n\n\n", "lib/frontend/html.py": "\"\"\"\n\nConfiguration parameters:\n\n    path.internal.ansi2html\n\"\"\"\n\nimport sys\nimport os\nimport re\nfrom subprocess import Popen, PIPE\n\nMYDIR = os.path.abspath(os.path.join(__file__, '..', '..'))\nsys.path.append(\"%s/lib/\" % MYDIR)\n\n# pylint: disable=wrong-import-position\nfrom config import CONFIG\nfrom globals import error\nfrom buttons import TWITTER_BUTTON, GITHUB_BUTTON, GITHUB_BUTTON_FOOTER\nimport frontend.ansi\n\n# temporary having it here, but actually we have the same data\n# in the adapter module\nGITHUB_REPOSITORY = {\n    \"late.nz\"           :   'chubin/late.nz',\n    \"cheat.sheets\"      :   'chubin/cheat.sheets',\n    \"cheat.sheets dir\"  :   'chubin/cheat.sheets',\n    \"tldr\"              :   'tldr-pages/tldr',\n    \"cheat\"             :   'chrisallenlane/cheat',\n    \"learnxiny\"         :   'adambard/learnxinyminutes-docs',\n    \"internal\"          :   '',\n    \"search\"            :   '',\n    \"unknown\"           :   '',\n}\n\ndef visualize(answer_data, request_options):\n    query = answer_data['query']\n    answers = answer_data['answers']\n    topics_list = answer_data['topics_list']\n    editable = (len(answers) == 1 and answers[0]['topic_type'] == 'cheat.sheets')\n\n    repository_button = ''\n    if len(answers) == 1:\n        repository_button = _github_button(answers[0]['topic_type'])\n\n    result, found = frontend.ansi.visualize(answer_data, request_options)\n    return _render_html(query, result, editable, repository_button, topics_list, request_options), found\n\ndef _github_button(topic_type):\n\n    full_name = GITHUB_REPOSITORY.get(topic_type, '')\n    if not full_name:\n        return ''\n\n    short_name = full_name.split('/', 1)[1] # pylint: disable=unused-variable\n\n    button = (\n        \"<!-- Place this tag where you want the button to render. -->\"\n        '<a aria-label=\"Star %(full_name)s on GitHub\"'\n        ' data-count-aria-label=\"# stargazers on GitHub\"'\n        ' data-count-api=\"/repos/%(full_name)s#stargazers_count\"'\n        ' data-count-href=\"/%(full_name)s/stargazers\"'\n        ' data-icon=\"octicon-star\"'\n        ' href=\"https://github.com/%(full_name)s\"'\n        '  class=\"github-button\">%(short_name)s</a>'\n    ) % locals()\n    return button\n\ndef _render_html(query, result, editable, repository_button, topics_list, request_options):\n\n    def _html_wrapper(data):\n        \"\"\"\n        Convert ANSI text `data` to HTML\n        \"\"\"\n        cmd = [\"bash\", CONFIG['path.internal.ansi2html'], \"--palette=solarized\", \"--bg=dark\"]\n        try:\n            proc = Popen(cmd, stdin=PIPE, stdout=PIPE, stderr=PIPE)\n        except FileNotFoundError:\n            print(\"ERROR: %s\" % cmd)\n            raise\n        data = data.encode('utf-8')\n        stdout, stderr = proc.communicate(data)\n        if proc.returncode != 0:\n            error((stdout + stderr).decode('utf-8'))\n        return stdout.decode('utf-8')\n\n\n    result = result + \"\\n$\"\n    result = _html_wrapper(result)\n    title = \"<title>cheat.sh/%s</title>\" % query\n    submit_button = ('<input type=\"submit\" style=\"position: absolute;'\n                     ' left: -9999px; width: 1px; height: 1px;\" tabindex=\"-1\" />')\n    topic_list = ('<datalist id=\"topics\">%s</datalist>'\n                  % (\"\\n\".join(\"<option value='%s'></option>\" % x for x in topics_list)))\n\n    curl_line = \"<span class='pre'>$ curl cheat.sh/</span>\"\n    if query == ':firstpage':\n        query = \"\"\n    form_html = ('<form action=\"/\" method=\"GET\">'\n                 '%s%s'\n                 '<input'\n                 ' type=\"text\" value=\"%s\" name=\"topic\"'\n                 ' list=\"topics\" autofocus autocomplete=\"off\"/>'\n                 '%s'\n                 '</form>') \\\n                 % (submit_button, curl_line, query, topic_list)\n\n    edit_button = ''\n    if editable:\n        # It's possible that topic directory starts with omitted underscore\n        if '/' in query:\n            query = '_' + query\n        edit_page_link = 'https://github.com/chubin/cheat.sheets/edit/master/sheets/' + query\n        edit_button = (\n            '<pre style=\"position:absolute;padding-left:40em;overflow:visible;height:0;\">'\n            '[<a href=\"%s\" style=\"color:cyan\">edit</a>]'\n            '</pre>') % edit_page_link\n    result = re.sub(\"<pre>\", edit_button + form_html + \"<pre>\", result)\n    result = re.sub(\"<head>\", \"<head>\" + title, result)\n    if not request_options.get('quiet'):\n        result = result.replace('</body>',\n                                TWITTER_BUTTON \\\n                                + GITHUB_BUTTON \\\n                                + repository_button \\\n                                + GITHUB_BUTTON_FOOTER \\\n                                + '</body>')\n    return result\n", "lib/frontend/ansi.py": "\"\"\"\nANSI frontend.\n\nExports:\n    visualize(answer_data, request_options)\n\nFormat:\n    answer_data = {\n        'answers': '...',}\n\n    answers = [answer,...]\n\n    answer = {\n        'topic':        '...',\n        'topic_type':   '...',\n        'answer':       '...',\n        'format':       'ansi|code|markdown|text...',\n    }\n\nConfiguration parameters:\n\n    frontend.styles\n\"\"\"\n\nimport os\nimport sys\nimport re\n\nimport colored\nfrom pygments import highlight as pygments_highlight\nfrom pygments.formatters import Terminal256Formatter        # pylint: disable=no-name-in-module\n                                                            # pylint: disable=wrong-import-position\nsys.path.append(os.path.abspath(os.path.join(__file__, '..')))\nfrom config import CONFIG\nimport languages_data                                       # pylint: enable=wrong-import-position\n\nimport fmt.internal\nimport fmt.comments\n\ndef visualize(answer_data, request_options):\n    \"\"\"\n    Renders `answer_data` as ANSI output.\n    \"\"\"\n    answers = answer_data['answers']\n    return _visualize(answers, request_options, search_mode=bool(answer_data['keyword']))\n\nANSI_ESCAPE = re.compile(r'(\\x9B|\\x1B\\[)[0-?]*[ -\\/]*[@-~]')\ndef remove_ansi(sometext):\n    \"\"\"\n    Remove ANSI sequences from `sometext` and convert it into plaintext.\n    \"\"\"\n    return ANSI_ESCAPE.sub('', sometext)\n\ndef _limited_answer(answer):\n    return colored.bg('dark_goldenrod') + colored.fg('yellow_1') \\\n        + ' ' +  answer + ' ' \\\n        + colored.attr('reset') + \"\\n\"\n\ndef _colorize_ansi_answer(topic, answer, color_style,       # pylint: disable=too-many-arguments\n                          highlight_all=True, highlight_code=False,\n                          unindent_code=False, language=None):\n\n    color_style = color_style or \"native\"\n    lexer_class = languages_data.LEXER['bash']\n    if '/' in topic:\n        if language is None:\n            section_name = topic.split('/', 1)[0].lower()\n        else:\n            section_name = language\n        section_name = languages_data.get_lexer_name(section_name)\n        lexer_class = languages_data.LEXER.get(section_name, lexer_class)\n        if section_name == 'php':\n            answer = \"<?\\n%s?>\\n\" % answer\n\n    if highlight_all:\n        highlight = lambda answer: pygments_highlight(\n            answer, lexer_class(), Terminal256Formatter(style=color_style)).strip('\\n')+'\\n'\n    else:\n        highlight = lambda x: x\n\n    if highlight_code:\n        blocks = fmt.comments.code_blocks(\n            answer, wrap_lines=True, unindent_code=(4 if unindent_code else False))\n        highlighted_blocks = []\n        for block in blocks:\n            if block[0] == 1:\n                this_block = highlight(block[1])\n            else:\n                this_block = block[1].strip('\\n')+'\\n'\n            highlighted_blocks.append(this_block)\n\n        result = \"\\n\".join(highlighted_blocks)\n    else:\n        result = highlight(answer).lstrip('\\n')\n    return result\n\ndef _visualize(answers, request_options, search_mode=False):\n\n    highlight = not bool(request_options and request_options.get('no-terminal'))\n    color_style = (request_options or {}).get('style', '')\n    if color_style not in CONFIG['frontend.styles']:\n        color_style = ''\n\n    # if there is more than one answer,\n    # show the source of the answer\n    multiple_answers = len(answers) > 1\n\n    found = True\n    result = \"\"\n    for answer_dict in answers:\n        topic = answer_dict['topic']\n        topic_type = answer_dict['topic_type']\n        answer = answer_dict['answer']\n        found = found and not topic_type == 'unknown'\n\n        if multiple_answers and topic != 'LIMITED':\n            section_name = f\"{topic_type}:{topic}\"\n\n            if not highlight:\n                result += f\"#[{section_name}]\\n\"\n            else:\n                result += \"\".join([\n                    \"\\n\", colored.bg('dark_gray'), colored.attr(\"res_underlined\"),\n                    f\" {section_name} \",\n                    colored.attr(\"res_underlined\"), colored.attr('reset'), \"\\n\"])\n\n        if answer_dict['format'] in ['ansi', 'text']:\n            result += answer\n        elif topic == ':firstpage-v1':\n            result += fmt.internal.colorize_internal_firstpage_v1(answer)\n        elif topic == 'LIMITED':\n            result += _limited_answer(topic)\n        else:\n            result += _colorize_ansi_answer(\n                topic, answer, color_style,\n                highlight_all=highlight,\n                highlight_code=(topic_type == 'question'\n                                and not request_options.get('add_comments')\n                                and not request_options.get('remove_text')),\n                language=answer_dict.get(\"filetype\"))\n\n    if request_options.get('no-terminal'):\n        result = remove_ansi(result)\n\n    result = result.strip('\\n') + \"\\n\"\n    return result, found\n", "lib/frontend/__init__.py": ""}